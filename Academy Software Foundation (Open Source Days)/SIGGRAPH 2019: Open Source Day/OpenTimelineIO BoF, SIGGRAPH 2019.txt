Title: OpenTimelineIO BoF, SIGGRAPH 2019
Publication date: 2019-08-08
Playlist: SIGGRAPH 2019: Open Source Day
Description: 
	Progress update and open discussion about OpenTimelineIO, an API and interchange format for editorial cut information used in production at a variety of studios. Part of Open Source Day at SIGGRAPH 2019, hosted by Academy Software Foundation.

Speakers:
Joshua Minor, Pixar
Stephan Steinbach, Pixar
Josh Burnell, Dreamworks
Sean Wallitsch, Dreamworks
Thibault Saunier, Igalia
Simon Inwood, Imaginary Spaces
Mathieu Muller, Unity
Vince Cerundolo, Marvel
Eric Reinecke, Netflix
Captions: 
	                              good afternoon we're here to talk about                               open timeline IO my name is Joshua miner                               I work at Pixar here with my colleagues                               to fajn Steinbach we're gonna talk for a                               little bit about our sort of roadmap of                               the project and then we have five guest                               presenters to talk about how they're                               using it so but we wanted to start off                               with just a quick informal poll this has                                helped us in the past to kind of gauge                                who's using what technologies out there                                raise your hand if you are actively                                using OTO in some form okay okay awesome                                excellent raise your hand if you were                                using AAF in some form okay okay how                                about about split okay how about EDL                                okay all right final cut XML I ever okay                                and if you are brand-new to ot IO you                                don't really know that much about it                                okay and then are you using ot IO for                                exchange between one company to another                                company okay we got one all right                                excellent okay thank you so much okay so                                we're gonna just give kind of an update                                about the the project where we are with                                the Academy Software Foundation and the                                guest presenters and we'll leave some                                time for Q&A at the end so to start with                                roti IO just to remind you is it's a                                interchange format for editorial                                timeline information it's also an API                                for working with that data model and                                then we include a bunch of adapter                                plugins for converting to and from other                                file formats and we try to emphasize                                these sort of three aspects they're each                                independently valuable for different use                                cases the data model itself is about                                tracks and clips and cross dissolves and                                markers kind of usual sort of video                                editing concepts and importantly there's                                media references so we point out to                                where media is like external to the ot                                IO we don't bundle the pixels or the                                audio like in the file and so it's very                                similar to ETL or final                                xml and in that respect we also include                                a sort of debugging kind of diagnostic                                viewer program so this is showing you                                the structure of the timeline but it's                                not actually playing back media or                                anything like that and you can't edit                                things in here it's just kind of seeing                                like the timing of everything and the                                the track layout this is our URL it's                                all open source it's all there on github                                so feel free to check that out                                internally at Pixar you know we've been                                past few years sort of rolling that out                                through our pipeline kind of replacing a                                bunch of old legacy stuff there we've                                been using it since cocoa and then                                Incredibles                                                        upcoming film onward and all these shows                                beyond that as well                                and we're currently working on                                integrating it directly into our                                in-house animation system and just to                                kind of highlight that a little bit the                                sort of evolution we started on sort of                                Incredibles to era exporting EDL's                                converting that to ot IO and running it                                through our review system and onto our                                grading system and this allowed us to                                improve that pipeline and actually I                                could pass cross-dissolve information                                that previously was not supported in our                                pipeline but we could carried that                                through a ot IO moving beyond that on                                Toy Story                                                             of the avid and that gives us a much                                richer set of data coming out then the                                EDL's had AF is we classified it as kind                                of expensive to work with it's a little                                that's kind of like complicated so we                                right away convert that to ot IO and                                then everything downstream uses that ot                                IO representation to be sort of very                                accessible like easy way to find out                                what is the cut of the film in our model                                you know the Edit cut is changing                                dynamically on a you know day to day                                basis and so we want the downstream                                departments to be informed about what's                                going on with the cut in our sort of                                current film pipeline we can actually                                round-trip this information so we can                                have a AF coming out of avid turned into                                ot IO going into our review system or an                                 system all the others are downstream                                 departments but also those departments                                 importantly can their often making their                                 own playlists or their splicing in their                                 their latest renders those kinds of                                 things and so we can take those oti                                 o--'s and we can turn them back into an                                 AE I can go back into editorial and this                                 is really really helpful for that sort                                 of collaboration that round trips so                                 that you know for example the layout                                 Department can do a couple of different                                 you know cuts of the fill of a sequence                                 different Oscar alternate versions or                                 whatever they need to do and communicate                                 that back in anti editorial so that's                                 kind of how we're using it we may have                                 noticed that were part of the Academy                                 Software Foundation track today and                                 we're excited to announce that we've                                 just as of last week actually been                                 accepted into the incubation stage into                                 the Academy Software Foundation so we're                                 excited about that it's a cool new                                 community to join and this kind of we're                                 hoping this kind of aligns with our sort                                 of forward roadmap there's a couple of                                 things that we want to do that we can't                                 really do just by ourselves as just                                 Pixar you know we have a community of                                 contributors already but we really want                                 to try to make sure that the sort of                                 file format that we're creating is more                                 well specified so netflix is helping us                                 with that and we also want to aim for                                 more sort of native vendor integration                                 and I'll talk about that in a minute and                                 we also just want to have to make sure                                 that we're planning the future of the                                 project as a community-based thing                                 rather than like driven by a single                                 studio it's being successful for us we                                 like that but we think that the project                                 will be more healthy if it's more of a                                 community effort and so you know which                                 community well the the Academy Software                                 Foundation aligns very much with sort of                                 our identity as a as a animation studio                                 and as you know with Disney as a whole                                 and and reaching beyond that to all the                                 other members of sort of our community                                 so drilling in for a minute about the                                 vendor integration so our model right                                 now is you have some third-party                                 applications and maybe you have your                                 in-house tools                                 and we're doing a lot of file format                                 conversion to and from whatever sort of                                 mmm sort of native format um is used by                                 these applications so here we can take                                 an AAF turn it into ot IO do some                                 manipulations on it turn it into an RV                                 session file and show it in review and                                 so that's the model right now and                                 there's a lot of a castle or just kind                                 of like messiness around these these                                 conversions and it works in practice                                 we're able to customize things and it's                                 it's kind of ok but it's not like the                                 ideal situation but we'd rather have is                                 like native support in a lot of these                                 applications and we kind of like floated                                 this idea around with a lot of folks one                                 of the key things there was they didn't                                 a lot of these applications didn't want                                 to have a Python interpreter added to                                 their their application so we'll talk                                 about the C++ support in a little bit                                 but this is kind of where we want to go                                 and we also feel that by joining the                                 Academy Software Foundation and kind of                                 being more of a community driven thing                                 that the third-party vendors will                                 hopefully kind of see this as like                                 alignment but ok if we all sort of want                                 that like if that makes sense to                                 everybody                                 then that can be actually like a cost                                 savings across the industry it can be                                 some like facilitating that sort of                                 collaboration so currently we're still                                 following sort of production driven                                 priorities but we do want to kind of                                 shift to more of that community sort of                                 roadmap for the project we've been                                 accepted into the incubation stage and                                 part of that is that we actually need to                                 form our technical steering committee                                 and adopt a governance model and there's                                 some specific sort of procedural steps                                 as well as some technical steps so                                 actually this week we're reaching out to                                 the other sort open source projects to                                 find out like how does your governance                                 work you know how are you able to foster                                 a good sort of community involvement so                                 if you have thoughts on that if you've                                 seen it done well or badly or whatever                                 like find us and talk to us we'd love to                                 kind of learn from the                                 from the community that we're trying to                                 join and with that I'd like to hand it                                 over to Stefan who's going to talk about                                 the specifics of what we've been up to                                 on the project                                 hey everyone so I'm Stefan I work with                                 Josh on open time Leo and I'm gonna talk                                 a little bit that what we've been doing                                 since the last time we all met in                                 Vancouver so the work broadly falls into                                 three categories there's been as always                                 a bunch of work a lot from the community                                 on the adapters we've got some new                                 plug-in systems that were directly                                 requested by the community and then                                 finally I'll talk a little bit about the                                 C++ core that we've been working on a                                 lot over the last over the last couple                                 months so I'm the biggest one for us                                 internally is that we've built out                                 support for writing AFS as well as                                 reading them and I need to clarify this                                 a little bit we're writing composition                                 AF so there's no pixel data in these is                                 still just just track and information                                 but for our use case that's been already                                 super helpful and I also want to                                 specifically thank the cargo cult folks                                 out in New Zealand have supplied a ton                                 of test data which is really valuable                                 and I want to put that out there also                                 that if you're looking for a way to                                 contribute test data is super helpful                                 especially with the format as                                 complicated as AF but thanks to their                                 contributions we've gotten a lot more                                 robustness enhancements out of our AF                                 adapter and then of course as Josh                                 mentioned that's now been put in a                                 pretty heavy production use at Pixar                                 it's the main interface between our                                 editorial staff and our production                                 departments contributed from the                                 community we've got a Final Cut Pro X                                 XML adapter and then also a gstreamer                                 plug-in that will have one of our guest                                 presenters talk about a little bit in a                                 little bit so I'm going to talk a little                                 bit about some of the new plugins we've                                 introduced so if you're familiar with                                 the project you've probably come across                                 this idea of a media linker Josh alluded                                 to the fact that we don't we don't                                 encode any media instead we have these                                 media references and the idea is that                                 the media linker is a plug-in that you                                 author that has                                 you're you know your business logic for                                 your studio that tells OPI yo how and                                 where to find the media out on your                                 specific database dis farm whatever                                 however it is that you do it and the way                                 that we had done that is it runs once                                 per clip and what we found was that you                                 know it's it's specifically meant to                                 replace an edit that the only that media                                 reference and while we like the plugin                                 Ness of it we found that there's                                 actually a lot of other things that we                                 wanted to attach and we got some                                 requests from the community about this                                 as well so we introduced the idea of                                 hook scripts so these plugins are                                 modeled after get hooks if you've                                 encountered that and what they are it's                                 it's all Python and it's basically a                                 'get hook or sorry a hook script is a                                 function that takes a timeline and                                 returns a timeline and has the                                 opportunity to operate on the entire                                 timeline in one shot the hooks are                                 defined by the manifest so maybe it's                                 kind of hard to see here but on the                                 right this is what the plug-in manifest                                 looks like so you can you can point at a                                 particular hook script it lives in a                                 Python file and then you can attach that                                 hook to these events that we that we                                 described and you can you can define                                 your own events that your your own                                 plugins can call but the core API has a                                 hook that runs once after a file gets                                 read once after the media linker gets                                 run and then once before the media leav                                 sorry once before the adapter writes it                                 back out the disk so like one example                                 use cases maybe you have data that you                                 want to inject after you read the file                                 you do your stuff and then you strip it                                 back out again before you write it back                                 out because you're going to share it                                 with another studio or you don't want to                                 archive that data in there it's                                 transient or something so that's where                                 plugins like the hook step like the hook                                 scripts come in and I know we've had it                                 we've gotten feedback from the community                                 that these are starting to make their                                 way out there so if you're using these                                 things and you do have feedback please                                 let us know                                 also we've introduced the idea of a                                 schema dev plugin so the entire schema                                 system inside of open timeline IO the                                 base class for that is a serializable                                 object and it provides a whole bunch of                                 different functionality like you know                                 versioning the schema is doing version                                 upgrading serializing the data                                 those different pieces but we pretty                                 quickly hit this idea that like actually                                 they're a proprietary schema is that                                 we'd like to introduce as well and                                 that's what the schema def plug-in lets                                 you do so here's here's um the one from                                 the example well actually this this is                                 just showing the use case of the                                 serializable object is actually how the                                 manifest and plug-in system itself is                                 implemented but the schema def plug-in                                 is defined in python using the exact                                 same api as the core classes so if                                 you've looked inside the core you'll see                                 the serializable field and that it                                 inherits from serializable object and it                                 uses the write the type registry so it's                                 in an exact peer of the of the built-in                                 classes with the sort of special                                 exception that if if you don't have the                                 plug-in loaded ot IO will still                                 round-trip the data but instead of                                 giving you a concrete type in memory it                                 gives you an unknown schema object and                                 if you know what you're looking for you                                 can still access the data dictionary                                 that's on there it just won't give you                                 like a proper type with classes it                                 doesn't have enough information to do                                 that but it has the same versioning                                 system available to the core schemas and                                 you can put additional methods on there                                 as well so internally what we've done is                                 we've wrapped up a sort of metadata                                 container for Pixar metadata that                                 includes methods that knows how to like                                 look up information in the database or                                 you know populate various fields based                                 on information that's present and that                                 automatically serializes and deserialize                                 --is with with the timelines that we                                 encode like I mentioned if the plug-in                                 isn't present you'll get an unknown                                 schema object so all the data will still                                 round-trip correctly if the hope is that                                 if you you know had to hand the timeline                                 across to another studio that had a                                 different plug-in they could still give                                 you the thing back and you'd get the                                 original blobs that were in there but                                 you could also strip them out with a                                 hook function if you want it to so                                 obviously the like really huge amount of                                 work that we've been even if you                                 following along you've noticed it's been                                 a little bit quiet for the last like six                                 months or so we've been focused really                                 heavily on this but the branch has been                                 landed and master so if you look at the                                 repo                                 day and you install open timeline oh you                                 are getting the C++ core and that                                 process has been based on a ton of                                 community input like I know we talked to                                 a lot of you last year and over the last                                 couple years actually and gotten a lot                                 of feedback so just to drill in you know                                 we got the message we built it all on                                 boost yeah it's okay                                 but the one thing I did want to mention                                 is the other requests that that did come                                 up was that we use the hourglass pattern                                 we did not end up doing this we found                                 that it was going to significantly                                 increase the development time and the                                 use cases that we encountered                                 we just didn't need it so you know it's                                 something that can be added in later we                                 feel like we feel like it wasn't                                 necessary here but you know please give                                 us feedback if that if that is already a                                 deal-breaker for you on the flip side                                 though its header only dependencies the                                 thing is in a version namespace and it's                                 been built with thread safety in mind so                                 hopefully it's safe to include in your                                 application the dependencies that we                                 ended up using so optional light and any                                 are both actually just you know I forget                                 what the term is but there are C++                                    features that aren't present in the VFX                                 platform c++                                                           filling those gaps and when the effects                                 platform moves ahead we can strip those                                 out rapid json is being used for the                                 JSON parsing which is the same as USD                                 and then pi by and                                                  using to do the python binding so it's                                 been a pretty pretty pleasant that's                                 been a pretty good set of dependencies                                 and we feel like it's it should be                                 pretty easy to integrate in your system                                 and you don't have to build the Python                                 bindings if you don't want to that's an                                 optional piece I should say that so also                                 the part that we ported was not the                                 Python plugin so we actually left those                                 in Python from C++ you can read and                                 write the dot ot IO format and you can                                 still traverse and manipulate all the                                 data but if you want to use the if you                                 want to use the adapters you need to                                 you're going to need to do another trick                                 which I'll talk about in a second but                                 just to just to clarify this one thing                                 we heard from people is I was important                                 that                                 folks who don't want Python in there say                                 nonlinear editing system don't have to                                 actually introduce it as a dependency                                 that they can just get the core if they                                 want to read and write the format and                                 use the API but at the same time we                                 didn't want to throw away all the work                                 that's gone into those plugins and those                                 adapters is it's still super useful and                                 valuable to the project so what we're                                 what we're sort of proposing is because                                 it's you know JSON format that you can                                 do something in a Python sub shell if                                 you need to access those those adapters                                 and read the read the JSON back into                                 your system if you do need to go from                                 another format but as Josh mentioned                                 we're hoping that as time goes on we can                                 get more direct integration with the                                 vendors and we don't need as many of the                                 adapters to hook up workflows and                                 pipelines for first studio work pip                                 install and all the ways that you're                                 using open timeline o should still work                                 if it doesn't definitely let us know                                 that our hope is that the set up top UI                                 takes care of everything and it's out                                 there last week David Barrett did a ton                                 of the work at Pixar so I would like to                                 thank him for contributing the core and                                 the Python bindings and while he was in                                 there he also built preliminary Swift                                 bindings so if you need to run it on iOS                                 or Mac go ahead and try that out as well                                 ok so we're gonna we're going to hand it                                 over to our guest presenters who have                                 some really cool mini talks on how                                 they're using it in their pipelines and                                 first up we got DreamWorks so let's give                                 a hand to Josh and strong                                 [Applause]                                 hi my name is Sean Wallach                                 I am a lead department TD at DreamWorks                                 I'm working on our new pipeline X                                 project hey I'm Josh for now I'm part of                                 the media team I'm the tech lead and we                                 are focused on editorial and playback                                 tools we're going to talk a little bit                                 about how we're using ot IO to run                                 timings through the pipeline and I guess                                 the disclaimer is none of these images                                 are relevant very cool all right so we                                 came into this with a big desire of a                                 pipeline unified timing format a                                 DreamWorks has been making animated                                 movies for a long time but with that we                                 had a lot of assumptions about how                                 timing looked in our pipeline so we                                 usually assume things like                                               second or a nice single layer timeline                                 nice simple cross dissolves between our                                 shots and as we got our parts our                                 projects out more and more varied we                                 found more and more products for                                 breaking those rules and having more                                 requirements on them so as they broke                                 those rules and had more requirements                                 and started wanting to use different                                 editorial software from our standard                                 editorial software we kept having to                                 deal with proprietary EDL formats and                                 every new thing we got required a large                                 amount of ingestion work to make this                                 stuff work so be more varied as our                                 price low continues to become more                                 varied so do the demands that we have on                                 our editorial workflows all right he's                                 off microphone and I'm on microphone are                                 we good no all right well both be on                                 microphone so anyway our first idea was                                 to unify on an EDL format that was like                                 standard to one of our third-party                                 editors which will remain nameless but                                 we all know what it is we just weren't                                 able to do that there wasn't enough                                 color in it there wasn't enough stuff in                                 it and so it's similar to what was                                 mentioned before we had the AAF so we                                 went over to using the AAF but then that                                 was just kind of too rich for downstream                                 pipeline tools so we went to e to the ot                                 IO format                                 provided us a ground truth that we could                                 kind of keep everybody standard on and                                 then the OT i/o format allows us to                                 store our media in non-standard and                                 mixed locations so using media                                 references subclasses of media                                 references and resolvers we've been able                                 to move our media off disk for some                                 workflows now I'm on microphone as well                                 so I should mention that our current                                 implementation here refers to one of our                                 pipelines and Dreamworks is probably not                                 unique in that we have multiple                                 pipelines at our studio at the same time                                 as we migrate from one to another so                                 where it says current implementation                                 that's a current implementation that we                                 are talking about right now                                 our creative pipeline across most of our                                 pipeline fermentations though is that it                                 is fuelled by the editorial round trip                                 much like the Pixar presentation we just                                 went over                                 so editors publish the official timing                                 for a sequence artist view that timing                                 they can make suggestions to change shot                                 links shot order things like that they                                 do that with popular third-party                                 proprietary tools the editorial then can                                 ingest those changes they take some they                                 ignore others and they publish a new                                 official timing back out into the                                 pipeline so yeah we use ot IO is just                                 the interim with all those tools so it                                 comes out of editorial gets translated                                 into ot IO it gets ingested into the                                 next tool using ot IO that tool makes                                 its own changes and publishes out an OT                                 io the nice part is that it allows us to                                 well currently we're using those OTA O's                                 to track timing playback speed playback                                 order obviously in transitions so we're                                 still pretty basic but again we're able                                 to kind of keep share that media across                                 different type of storage services along                                 the way we're also storing metadata                                 inside of the OT O's so we're keeping                                 pipeline IDs in there this allows us to                                 keep track of what a shot actually is no                                 matter how much the clip information                                 itself changes and becomes                                 unrecognizable but in essence we're                                 giving everyone in the entire pipeline                                 the ability to contribute to the timing                                 of the sequence using a variety                                 of editors that we have in it they can                                 create new versions they can push it                                 back to editorial editorial then                                 round-trips it and we track the entire                                 thing yeah we have a lot of editors they                                 want to at each level of the pipeline                                 people want to be able to at least                                 suggest timing changes so last but not                                 least things that we're working on for                                 the future we are looking our next big                                 thing is going to be multi-layer                                 timelines like the ability to do stacks                                 and things like that live in the                                 timeline it would allow us to express                                 much richer multiple shot transitions                                 and picture-in-picture we do a lot of                                 picture-in-picture and tracking picture                                 and picture throughout the timeline in                                 an AF format is incredibly complicated                                 and in an EDL format is almost                                 impossible complex transitions kind of                                 falls out of that three movie                                 transitions things like that it's kind                                 of a stack it's kind of a                                 picture-in-picture it's neither of those                                 at the same time so tracking mat is                                 going to be a next big step native media                                 generated on the fly when you ingest the                                 oti oh that's essentially a hook script                                 which was kind of interesting so that's                                 one of our next big projects that were                                 kind of embarking on and then one the                                 ability to track the change of a shot                                 over time like the hierarchy of that                                 shot or history of that shot essentially                                 the ability to know that this was a                                 previous shot and now it's a production                                 shot and then it might become it might                                 be two shots that became one or one shot                                 that became two and tracking that                                 through the OT i/o timeline as it comes                                 in and out of editorial will be really                                 powerful for our tracking down stream so                                 ot IO has made a lot of aspects of our                                 timing pipeline a lot easier but as Josh                                 spoke to earlier right now we're still                                 having to do a bunch of the transition                                 layers between our applications so we're                                 excited if ot IO can get better support                                 in those aspects but also one thing                                 being able to rely on a single                                 documented format has been really nice                                 for timing data through the pipe through                                 the various pipeline because a lot of                                 applications don't even agree on how to                                 write certain data to certain data                                 formats or even what a certain data                                 format is and consists of so works                                 see with new versions of ot IO bring us                                 as the format library mature thanks hi                                 everyone i'm t-bo I work for Galia it's                                 an open source consultancy company                                 mostly specialized in web engines chrome                                 and and WebKit                                                     multimedia team where we work with J's                                 swimmer so just rumor is a                                 cross-platform open-source multimedia                                 framework so you can deal with audio and                                 video for anything you work with just                                 swimmer                                 it basically wraps other API is like the                                 Corazon code etc and then you can deal                                 with it with a standardized API on top                                 of all that it's installed on all Linux                                 distribution by default and it's used in                                 many industries such as TVs set-top                                 boxes rendering farms and things like                                 that and on top of that we have the gist                                 remelting services which is a high-level                                 API to do video editing only like                                 post-production video editing where we                                 introduce high-level concepts such as                                 timeline projects layer strikes etc so                                 what we thought would be very                                 interesting for us is to to integrate a                                 streamer and open time on Io                                 so what we started doing is implementing                                 XJS adapter inside open timeline area so                                 that we could convert it or cut from any                                 software any supported formats to to the                                 jet stream internal format X J's and the                                 other way also so that we are like                                 compatible with all formats supported by                                 over time                                                            implemented we wanted to have like                                 native support inside the just emerging                                 services for the open time                                             so we're implementing the GS o geofoam                                 ro which means that                                 you can load any file supported by OTO                                 or not you'll find itself inside just                                 amazing services and playback the                                 timeline as with any other as with                                 native XG s format so we have full                                 support of open timeline area inside the                                 destroy waiting services which means                                 that you can just play back J's lunch is                                 a very simple command-line tool that                                 allows you to you can describe a                                 timeline with a specific format or you                                 can load like an external timeline from                                 a file so here the first example we just                                 play a food Oh Cho and it just like                                 plays back doing everything internally                                 as if it was X J's file I mean yeah just                                 a description of the timeline we just                                 support it then you can render that in                                 the format you MA so here in the second                                 example we just load the food at audio                                 file Oh Jo and we're underway to                                 rendered food that MKV and we specify                                 the formats like we say okay we want                                 that to be in matroska with a v                                        codec and                                 opus has an audio codec so that just                                 like randos the timelines described by                                 the food a toteal file and we can also                                 use a J's lunch like Co version tool so                                 here we can just like launch food at XML                                 which will be in that case like Final                                 Cut Pro XML file and just save it on                                 disk so it's very similar to dojo                                 converting but we can just use like the                                 essence because that's a feature that we                                 already added it all like natively                                 supported in jazz so we can take avenjet                                 of take advantage of that I think you                                 missed the slide                                 this light was about we actually have                                 went one step down but all that and we                                 implement GSD mixer inside gstreamer so                                 that inside Jess trimmer we have like                                 full support of editorial files format                                 and like if you have a jet stream herb                                 bass player you can just play Final Cut                                 Pro let's say fire code profiles and we                                 internally just like run a GS timeline                                 and play it back as if it was like a                                 native multimedia file and all that                                 allows us to in video editing                                 application that choose the destroying                                 services we can just like load a file                                 that was edited in Final Cut Pro X for                                 example and then just load it in DTV                                 which is the video editing tool that we                                 build on top of the destroy building                                 services so it's pretty pretty nice and                                 in the future we are planning on moving                                 to for the GS Ocho for Mara would like                                 to use the C++ API some bits are missing                                 as you cannot like to do conversion with                                 the adapters with the plain C++ API                                 right now from what I can see something                                 to be done I guess and while walking                                 actually working on implementing listed                                 timeless in the XG so                                                  added support for nested timelines                                 recently in GS itself and now we'd just                                 leverage that you know Jo and all that                                 work is all in just from a master so you                                 can just grab it you have to build                                 master right now but like in six months                                 is going to be released all that our own                                 six months and then we provide binaries                                 for Mac Windows Linux obviously and and                                 iOS and Android also not very                                 interesting but is but you could use                                 that they are - thank you                                 okay next up we have unity percent hello                                 I'm Matthew Muller I'm the technical                                 project manager for film animation a                                 unity and hi I'm Simon would I help                                 animation studios use game technology                                 and we're their tech team behind                                 integration yeah so we've been working                                 with Simon's team for the past year to                                 improve the integration of unity into                                 production pipelines which are three                                 areas the inter up with DC sees a Python                                 integration into unity and our subject                                 which is open timeline IO which is based                                 on the Python integration we also have                                 images which have nothing to do and so                                 integrating editorial into a real-time                                 pipeline you get the control and                                 organization of your project over                                 sequences through the shots linking to a                                 media or portion of the media this media                                 can be a snapshot or video like in a                                 classic editorial thing but what is                                 unique about real-time is like you                                 actually actually get a live assembly                                 also control of a live media which is a                                 live assembly of your lighting your set                                 dressing your FX and so on and that you                                 can turn on and off so yeah a heavy use                                 of nested timelines is way so usage                                 storyboard you start to expect taking                                 the storyboard media and editorial you                                 can import it in unity editor as a                                 reference for blocking out placing                                 cameras placing actors maybe to mocap or                                 you can start some people start directly                                 blocking out in unity doing like again                                 placing characters doing previous doing                                 layout and exporting it as a reference                                 for for the animatic storyboard or even                                 the mood board and also we see upon                                 tamanna also as a good bridge to between                                 project many production management asset                                 management and actually assembling the                                 scenes together and following the                                 progress of the of the production and if                                 you connect the things the two things                                 going in and out basically you have the                                 editorial which happens at the place                                 where it makes sense you if it makes                                 sense to change the editorial in unity                                 because you have control over the media                                 it's good if you have somebody who is                                 using a third-party tool then you can                                 export it because it makes more sense                                 there let's see we actually have a video                                 in an open timeline area talk to show                                 that in action I hope it works yes                                 there's no music                                 I have to see                                 what's happening you okay yeah so we're                                 we're in we're in storyboard here we're                                 in                                 - boom storyboard Pro and so we're using                                 they're exporting system into edia                                 that's are really really fast you can                                 drag and drop it inside to unity                                 automatically it sends the timeline we                                 set up the the overlay on the in the                                 viewport and now we're showing like okay                                 well now I have that as a reference I                                 can start building out I can start                                 creating assets inside of unity using                                 their asset modeling tools but none of                                 this is in project management right now                                 okay now yet so now I can export its all                                 those stuff all those things who are                                 reference and they can be uploaded up                                 into shotgun or whatever your revision                                 tracking tool is and now we're going to                                 go back again so we can actually go back                                 again we can go back into we can do this                                 at the conform pop back into storyboard                                 as well so once you've made some changes                                 then you need some extra detail added to                                 place you can send it back to storyboard                                 so here we recall in the the sequence                                 and plus the editorial and then you can                                 load it automatically in the editing                                 file then you change the editing your                                 export back and when you open it again                                 in a in unity you have the editorial                                 which has changed we're seeing popping                                 up boom yeah that's it so yeah we've                                 been working on that for for the past                                 few months and it's accessible its                                 private alpha but we want to have as                                 soon as possible it usable by anyone                                 okay some of the features some of the                                 features yes we have the timeline                                 integration so it's integrated the LTI                                 outcomes into and builds a unity                                 timeline which we use the scripted                                 importer inside of unity so it's treated                                 as like a native unity asset now and you                                 can use you can render out a media clips                                 directly from the timeline using the                                 Unity recorder and then we're using the                                 adapters so we're doing the export out                                 and conform back using well EDL and XML                                 when we go over to like up the shotgun                                 or up                                 - boom or over to Adobe Premiere and                                 it's yeah it's fully customizable both                                 in Python and in c-sharp so the Python                                 for the unity plugin allows you to go                                 into c-sharp land as well so you can                                 start writing c-sharp ot IO code and                                 it's supported on Windows Linux Center                                 Wes and Mac and some of the future work                                 so we're building out a roadmap and                                 we're really curious to hear from you so                                 please come and see us next some of the                                 things we're thinking about is multi                                 takes the audio edit so that's why I'm                                 interested in the AAF going over into                                 Pro Tools transitions handing them at                                 least keeping them and not losing that                                 data doing the just-in-time                                 linking with the real-time media so if I                                 at the moment we expect the scene to be                                 there before we load the ot IO and then                                 we use the media linker to bind it we                                 want to do more work on the you know                                 export or publish and then back with the                                 conform and repeat as well as supporting                                 more editorial tools and inclusion as as                                 much she was saying you know it allows                                 us to have editorial wherever it makes                                 sense it's you to the first in is the                                 first in and the last doubt is that                                 that's the same now with ot IO we think                                 it's awesome because it allows the Edit                                 into actually in the game engine and let                                 the game engine be part part of that                                 story so one of the open questions is                                 about that linking of that linking of                                 shots to the real-time media how do we                                 how do we have what how does how does                                 that work and how does it make sense how                                 is he for example us like maybe USD                                 press open tomorrow and then you have                                 full control of the relationships                                 between your shots and your progression                                 so that would be great thank you thank                                 you                                 [Applause]                                 hi so my name is Vince Trinculo I'm a                                 senior software developer at Marvel                                 Studios and we started using open time                                 money oh about two years ago when I                                 started at Marvel to start using some                                 self-service stuff services - for our                                 editorial staff to do turnovers for our                                 di basically at Marvel we turnaround                                 movies pretty quickly and also a warning                                 there are no images in this one because                                 I'm not allowed to show you any so all                                 right so what Oh TA o provided us was a                                 reliable EDL parsing mechanism basically                                 our method of handing over her di is                                 using the traditional gmx                                               standard which is standard and since                                 this in Python it made us easy for us to                                 do a django development develop them                                 there it's self-service and since it's                                 self-service and it's a web we're using                                 a web integration there it makes it                                 accurate real-time feedback for                                 editorial staff and it allows us to                                 share our code easily within our                                 environment including any changes we                                 make for our customer development so in                                 its Django it's Python easy what we did                                 in in Okayama NATO was we extended it a                                 little bit we needed some extra many                                 they does so we added and unfortunately                                 haven't published this back into open                                 timeline arrows so we should talk about                                 doing that whether we want to do that or                                 not but our integration of Marvel has a                                 bit of a custom integration into the cmx                                                                                                         us to do all of our self services and                                 and that environment works pretty well                                 for us                                 oops and I'm sorry it supposed to be                                 animated and                                 that about it and it works pretty well                                 so thank you open timely oh hey everyone                                 my name is Eric Ronnie key and I work at                                 Netflix we're in the beginning of our                                 adoption of a IO but we're already                                 really excited to be contributing and                                 using it in a few places so today I'm                                 going to talk about two places where                                 we're using it one use case where I was                                 able to enhance a developer experience                                 taking advantage of the ot IO toolset                                 and then another place we were able to                                 create a new trailer conform workflow                                 using open timeline so the first one is                                 this a developer experience use case we                                 have a lot of these sort of one-minute                                 trailers that are cut in Adobe Premiere                                 by our in-house editing staff and what                                 they do is they start out with the full                                 set of finished videos from a TV series                                 and from that they select about a minute                                 worth of content to generate the trailer                                 so what's ended up happening is that oh                                 you know what I jumped ahead in my                                 explanation actually what we're going to                                 talk about first and this developer                                 experience is sort of the things that                                 end up falling on editors to do that                                 aren't really part of editorial ideally                                 in a film editor is working on selecting                                 bits of material from all these these                                 sources all your dailies to creatively                                  assemble that into a compelling story                                  unfortunately what ends up happening is                                  on editorial staff it'll fall to them to                                  do any sort of simple compositing                                  operation like just quickly cutting                                  together two clips or doing a quick                                  overlay that's not really something an                                  editor wants to do and it Rob's time                                  from them making creative decisions so                                  internally we've created a service that                                  will helps with being able to do these                                  sort of simple editorial operations and                                  this is what the the request format                                  for it what's like so if you look at it                                  you see there's a few tracks in there                                  each track is composed of a few clips                                  and it's a overlaying some graphics on                                  some base media it's you know pretty                                  simplistic but actually if you look at                                  this there are two errors when this                                  timeline renders out there is a big                                  blank spot in it and the audio ends too                                  early so can you see why that's                                  happening from this yeah                                  I'm not stupid great at converting in                                  and out of twenty at fourth forty eight                                  thousand twenty four thousand over one                                  third one thousand once in my head so                                  what I did is I went ahead and I built a                                  adapter which is something that opened                                  timeline il lets you do so we we built                                  this adapter we submit it to our                                  internal paper industry and that means                                  that any any developer within that Plex                                  can go ahead and pip install this ot IO                                  adapter for this specific service and                                  that gives them full support for                                  generating both reading and writing                                  those requests jason's                                  using the opening timeline io and                                  because we're an open timeline io that                                  gives us ot IO view now for free so now                                  that we look at this trailer with this                                  adapter support we can see why there's                                  that blank spot up here at the top and                                  you can see why the audio is ending                                  quickly what this does is this makes it                                  very easy for a service developer when                                  they run into an issue to get really                                  good visual feedback to explore their                                  timeline this is a simple case but                                  imagine once you get into timelines                                  they're two hours long and they have no                                  tons of tracks so that's been really                                  effective for us the second is the                                  trailer conform workflow now we're back                                  on the right track we have these                                  one-minute trailers we generate and what                                  they do is they start these editors                                  working premiere start with full seasons                                  of TV series that they're working from                                  and they cut these things down now we                                  are a cloud native we have cloud native                                  pipelines in our workflow                                  so those editors are working on proxy                                  material and the idea is that once                                  they've arrived at in edit a trailer                                  they'll pull down the ProRes and conform                                  that well there's issues with that it                                  can be able to a bit tough to download                                  all that data so what we've done is sort                                  of a two-pronged approach to adding                                  efficiency to this particular workflow                                  one we've created a premier panel                                  plug-in that will go and walk through                                  the timeline and analyze what's actually                                  used in the media and then secondly we                                  take that and we turn that into a very                                  simplified JSON format which is a                                  manifest of what frames were actually                                  used in the the output trailer so                                  actually if you look closely at this you                                  can notice that we're encoding open                                  timeline i/o style rational times and                                  you'll notice that right there that's an                                  enormous number that's a premier tick so                                  if we look at this and we say ok this is                                  the full set of episodes the full length                                  episodes and you'll notice that little                                  teeny one up there is the intro sequence                                  to this TV show and we apply that data                                  we had from before this is done in a                                  docker container that runs locally on                                  that machine this is the timeline of                                  what actually got used in that output                                  trailer so it's just those little                                  slivers all in there are the material                                  that's actually used so within the                                  stalker container running locally on the                                  editors machine we can then build a new                                  timeline where and we fill in all those                                  blank spaces with just black synthesized                                  frames and so we now have a timeline                                  where is all blank space with a locally                                  generated black frame and just the                                  little slivers where they're actually                                  using real content we can then use mxf                                  for app or sorry we use two pieces of                                  technology we have something called meds                                  FS that we use internally that allows us                                  to mount the frames that are actually                                  used and then by linking in those black                                  frames we can use the MXF wrapper to                                  pull our original                                  IMF frames in cash an IMF to local                                  storage that is only the stuff we need                                  so we're data German company let's talk                                  about the data of about four hours of                                  source content we only used about                                     seconds of it and the output trailer                                  that maps to about                                                     source material which means we only use                                                                                                          worth of frames so let's turn on to                                  download time if you're running at a                                  gigabit per second you go from you know                                  around                                                              download time this is time an editor can                                  then spend plussing out that trailer and                                  building something that's going to                                  connect our members with the content                                  they're going to love so that's about it                                  thank you guys very much                                  all right thank you to all of our guest                                  presenters it's really cool to see how                                  this is being used in all kinds of                                  really cool contexts just to wrap up we                                  want to talk about some of our like next                                  steps and there's a little bit of time                                  for Q&A some of the things on our                                  roadmap coming up are we have an                                  addition like a revision to how we                                  actually store time so I've got a lot in                                  a feedback that currently that we're                                  storing things as floating-point numbers                                  occasionally that ends up with some                                  roundoff errors and there's there's some                                  rough edges to that sometimes so we have                                  a proposal that we haven't posted                                  publicly yet but we've been sort of                                  working on to to move forward on that                                  and do something that we think will work                                  better we've also been working on the                                  timing effects and trying to handle like                                  a fancier more complicated ones and as                                  well as a redesigned to how we handle                                  the cost dissolves and chicken                                  transitions so a more like no easy way                                  of looking at that is we can look at                                  this sort of feature matrix so along one                                  side we have a bunch of features of ot                                  IO and then across the top we have like                                  all the different file formats and like                                  so was representing for each adapter can                                  we read and/or write these different                                  features of things so they can all                                  handle us you know single track of clips                                  but as we go down we've been sort of                                  building out more and more features so                                  the ones highlighted in blue are newly                                  added recently so the AF support is now                                  both read and write for most of those                                  there's a couple of pieces that need to                                  be filled in there the gstreamer adapter                                  is new and then where we're sort of                                  headed next with this is the kind of                                  fancy speed effects here so we have sort                                  of sporadic support for that in some of                                  the adapters and we have a conversation                                  going on with avid about trying to get                                  the non linear speed effects information                                  out of Media Composer and we're trying                                  to kind of thread a align there of not                                  bringing in all the complexity of the                                  superset of how everybody does timing                                  effects but to have like                                  nicer a middle ground that captures the                                  sort of creative intent of that and with                                  that I think we were open for Q&A we                                  have a few minutes um you can ask us or                                  any of the guest presenters for                                  questions                                  sorry two parts one could you go back to                                  the other slides as well we do the QA                                  there's a lot of good information there                                  second is I was wondering if you get                                  into a little bit more of the vendor                                  partnerships and software vendors                                  specifically who are participating in                                  how and how TI o support is going to be                                  integrated into those software packages                                  and used variety of ways anything that                                  you could share there sure we've had                                  some conversations with autodesk about                                  some of their products                                  we haven't gotten into super sort of                                  details with them yet and then we've had                                  some sort of you know pixar specific                                  conversations with avid and then some                                  informal conversations with the final                                  cut team and i think that's kind of part                                  of our hope with sort of representing                                  like a broader community through the                                  academy software foundation or just                                  through having more involvement for more                                  people that if we can create like a                                  stronger bond with with those those                                  third-party applications that we think                                  that would be great I mean seeing what                                  the unity folks just showed of like we                                  want that level of support in like all                                  the applications right and so having                                  having a company really sort of embrace                                  that and move forward on that like                                  devote resources to that I think that's                                  kind of like where we want this to go                                  but I would say it's sort of like early                                  days on some of those relationships and                                  I totally sympathize a lot of them are                                  sort of kind of waiting to see does this                                  have adoption you know this is something                                  they should spend time on and and I                                  think we're part of what we're trying to                                  show us yes this is like this was                                  growing in the industry people are                                  finding finding use for it but there's                                  definitely room to go ahead with that so                                  if you have a specific like third-party                                  applications that you really really want                                  ot IO support in like ask them directly                                  say hey you know Marvel wants this or                                  whatever your company is you know if we                                  really want this and that can help them                                  to kind of I can see the importance of                                  it                                  last question                                  so right now shotgun is said they were                                  working on some open timeline i/o based                                  stuff for doing like grease pencil type                                  overlays okay I'm curious if you have                                  any plans to either standardize some                                  kind of best practices or maybe there's                                  another format for that sort of thing I                                  know you said you're not really focused                                  on recording pixel data but maybe                                  there's some kind of standard way to do                                  that so I can imagine it could be really                                  useful if you're doing interchange on                                  timelines to sort of support those notes                                  hitting a lot of different targets you                                  can see you know the full graphical                                  overlay and time yeah it's interesting                                  our in-house animation system actually                                  has those kinds of overlays so we were                                  just talking about like how should we do                                  that should we embed that in the file                                  should we point to an external file that                                  those kinds of things so um I think we                                  don't have any concrete plans for that                                  right now                                  and actually that's the first I've heard                                  of the shotgun feature related to that                                  but I'm but we go we'd love to sort of                                  engage in that conversation I think one                                  of the other things that were kinda                                  hoping happens is that some of those                                  conversations happen a little more kind                                  of face-to-face or via email and like                                  the more we can draw those to sort of                                  happen on like either our mailing list                                  or the github issues or something so                                  that we can we can draw in the voices                                  that are that are interested in that and                                  can really participate in that because                                  certainly having having that variety of                                  people to work on it like there's some                                  really really good ideas that can come                                  from                                  maybe unexpected places or just fake                                  places that we don't have the contacts                                  for so so yeah oh the question was about                                  attaching like sketches like markup                                  overlay things like those drawings onto                                  the timeline all right I think we're out                                  of time thank you everybody for coming                                  out and feel free to find us afterwards
YouTube URL: https://www.youtube.com/watch?v=aGfR0pu3k6E


