Title: OpenCue BoF, SIGGRAPH 2019
Publication date: 2019-08-22
Playlist: SIGGRAPH 2019: Open Source Day
Description: 
	Learn more about roadmap plans for OpenCue, an open source, high-performance render manager for visual effects and animation, hosted at the Academy Software Foundation. 

Part of Open Source Day at SIGGRAPH 2019, hosted by Academy Software Foundation.

Speakers:
Todd Prives, Google
Brian Cipriano, Google
Ben Dines, Sony Pictures Imageworks
Captions: 
	                              good morning everyone welcome to the                               open queue birds of a feather here at                               SIGGRAPH                                                               a product manager at Google I'm just                               gonna be giving a very brief overview                               and then turning it over to the people                               that have been doing the the real work                               on this both Ben Dean's from Sony                               Imageworks who's been working with open                                queue for close to                                                   Cipriano who's a software engineer at                                Google who's been leading our open queue                                efforts on the TSC so again this is just                                gonna be very quick to intro from me but                                before I get started I would love to get                                a quick show of hands how many of you                                have downloaded open queue suite how                                many of you have used it on shots not                                even in production but just used it in                                shots not as sweet ok but again this is                                a you know that it's a very new product                                our new software offering for the                                Academy Software Foundation very                                different from a lot of the libraries                                that typically have been adopted and we                                understand it's gonna take time to ramp                                up and gain adoption so again it's just                                very exciting to see the progress we've                                made over the last year that Bryan's                                going to talk about and the fact that we                                have so many people here actually                                engaging with us and chatting so I'm                                gonna turn over to Ben who's gonna give                                a history of open cue from Sony                                Imageworks then he'll turn it over to                                Bryan who's gonna talk more about the                                the current status the work that was                                done to get it to an open-source product                                and then Bryan I'll talk about the                                roadmap we do want to leave a lot of                                time at the end for QA to get everyone's                                feedback on where they would like to see                                improvements whether I see the roadmap                                go and so on so with that again thanks                                for joining and I'll turn it over to Ben                                dine Smithsonian which works yeah so to                                get some started with some of the                                history of open queue it um these are                                some of the movies that it's worked on                                starting all the way back at the                                beginning with Cloudy with a Chance of                                Meatballs and recognize spider-verse and                                some other ones so yeah as mentioned the                                open queue started as a project called                                q                                                               rendering queuing software that we had                                at image works and it first became her                                first went into use about ten years ago                                and that was on Cloudy with a Chance of                                Meatballs                                Cloudy with a Chance of Meatballs was                                still using q                                                 development and so they were very much                                sort of stress testing it and and                                everything else as it went along and and                                that show delivered in July of                                         they peaked at if you can imagine                                     running cores so many what's interesting                                that was the first show to deliver on q                                 was not Cloudy with a Chance of                                Meatballs it was actually g-force who                                was scheduled to deliver in May of that                                year and in the last three weeks before                                delivery basically pulled a crazy Hail                                Mary and switched the entire show over                                to q                                                                 peaking at about                                                        it it worked out for them it was a                                smooth landing so some of the more                                recent improvements we've had have been                                adding cloud capability to q                                            the first the first cloud rendering that                                we were able to do with q                                             that was during Smurfs lost village and                                and that was entirely on AWS cores and                                it peaked around                                                     and it was about a year later that we                                then added GCP capability Google cloud                                to the to the to the queue and into our                                software that integrates everything and                                on Hotel Transylvania                                                first to actually take advantage of                                Google cloud processing we we actually                                peaked at about                                                       course for of the Google cores                                themselves and that was actually still                                in addition to another                                             Amazon cores currently where we are are                                our q                                                               about                                                                   our peak total running in our q                                  software was actually about a hundred                                 thousand and that was during the emoji                                 movie if you can imagine in in May of                                                                                                    thousand Amazon cores running along                                 on-prem course and uh so that's just of                                 the history I'll pass it on right now                                 hey thanks so yeah so we started so we                                 started working with Sony a few years                                 ago kind of kicking the idea around                                 about open sourcing their in-house                                 scheduler and things kind of went from                                 there so we did a lot of work to kind of                                 pull out some components and get it                                 ready for an open source release we when                                 it first kind of further arrived                                 it only supported Oracle that we kind of                                 knew that we had to support our database                                 options going forward so we added a                                 second database option in Postgres I was                                 also using a network layer called ice                                 that had some licensing problems so we                                 had to replace that with G RPC as well                                 for for networking and then we did a                                 whole bunch of other kind of code code                                 cleanup and general prep and                                 documentation and getting it ready for                                 release so that happens in January or                                 this year and yeah then a few months                                 later it was you know we proposed it as                                 an SWF project and it was accepted                                 shortly after that so we've been we've                                 been doing a lot of work to kind of get                                 it get it going since then and and move                                 it over into the a SWF so and the s Toby                                 F is great for that sort of stuff just                                 kind of providing like a lot of the                                 stuff that new projects needs so you                                 know the whole technical steering                                 committee structure even the process of                                 like you know taking notes and checking                                 them into your github repo so other                                 folks can can join in laters Ben has                                 been nice to have as well it was you                                 know big stuff like CI infrastructure so                                 we have we have a bunch of folks on the                                 on the on the TSC now folks from Google                                 Cloud Sony Netflix                                 we've got mattchambers who wrote q                                  originally at Sony and and we've had so                                 we've had some pretty good momentum                                 we've had about you know you can see the                                 stats up here we've had a pretty steady                                 amount of changes coming in per week                                 you know new new issues being reported                                 and bugs being fixed since since it's                                 been open sourced and yeah so so so far                                 our development has been pretty focused                                 on ace the a SWF stuff getting CI in                                 place like steady like stable CI in                                 place and all that and now we're kind of                                 turning our attention to the future so                                 we're kind of seeing where the TAC is in                                 the process of building a road map                                 basically and ands were excited to hear                                 what folks have to say and want to see                                 on that roadmap so I can shake it pull                                 up a full draft if we have time later                                 but the kind of main main big things                                 that are coming up our windows support                                 so right now it's pretty much Linux                                 Linux only for a lot of the components                                 got general resource limits so that                                 includes things like software licenses                                 that aren't taken account into the                                 schedule right now that's been a popular                                 request I think that that one is                                 actually in in review right now and                                 should be out released within the next                                 probably week or so built-in user                                 management so right now it kind of                                 operates on a pretty open permissions                                 model where folks can kind of you know                                 launch jobs and access whatever jobs                                 they want as long as they have access to                                 the system so you know that we want to                                 build in a full kind of user system that                                 integrates with what you got in-house                                 ideally you know things like Active                                 Directory and LDAP and stuff like that                                 and once we have the user management                                 this opens up a whole bunch of other                                 stuff we can do in particular having                                 like a fine-grained permissions model                                 for different resources within your with                                 your near open queue deployment and then                                 we want we want to expand a lot of the                                 host app plugins that we have so right                                 now technically you you can run any                                 software with open queue the the way                                 that it works is you know they're your                                 job submission constructs a basically                                 what's a bash command he sent through to                                 the render nodes at the end so any                                 software that you are using can work but                                 it is not the easiest thing to do if you                                 don't have a plugin for your for your                                 host app we have                                 my Anouk right now that you know                                 basically what it does is it's a light                                 layer that you know talks to the the DCC                                 app and prepopulates a lot of the things                                 builds the command for you and then and                                 then submits the job so we wanted we                                 want to do a lot of work to expand that                                 and we'd love to have other folks you                                 know contributing for the for the apps                                 that they'd like to see I think                                 blenders pretty far out at the top of                                 our list I think that's been in progress                                 we've made some steps toward that unless                                 the last few weeks                                 Houdini's on the list as well and                                 there's a whole other there's a long                                 list of them as well and then kind of                                 the the biggest bit of development work                                 that's coming up is the a big revamp of                                 the sketch of the actual scheduler                                 within the system right now you know if                                 you've taken a look at the open cue code                                 basically a lot of the a lot of the                                 scheduling is done in kind of it's all                                 database driven so complex queries                                 stored procedures that sort of thing                                 it's pretty hard to debug and expand and                                 maintain so we're gonna be doing or a                                 big revamp that that moves a lot of that                                 scheduling into into memory and this is                                 gonna this will open up a lot of kind of                                 advanced features that we can add such                                 as you know kind of adapt looks adaptive                                 scheduling customizable schedule or                                 logic stuff like that and yeah so that's                                 that's kind of what we're working on                                 that's what the the high-level view of                                 the roadmap looks like it is definitely                                 a draft right now and you know we'd love                                 to get feedback from from folks to see                                 what here what they'd like to see on                                 there so I think yeah we'll just kind of                                 open it up to open up to a QA right now                                 and if there's you know if anyone has an                                 EVE any feedback anything that they've                                 seen with open queue so far yeah we                                 thought to hear about it                                 not yet but we'll publish it yeah at the                                 end of this meeting and then we'll be                                 working on it we have a TSC meeting                                 tomorrow actually where we'll be kind of                                 incorporating the stuff we've we've                                 heard over the past few days and today                                 and then yeah we'll publish it at that                                 point                                 yeah so I would say we're about probably                                 sorry it's a little hard to say it's                                 probably a month or two away from                                 Windows support the big the biggest kind                                 of problem that we ran into was the                                 Python                                                                 of lack of lack of some of the binaries                                 that we were using for particularly PI                                 side in Windows we had to kind of go                                 through and start to convert everything                                 to Python                                                             you know I'm blocking that but there is                                 there is a lot of code in the system                                 that already handles windows and windows                                 scheduling so it's there shouldn't be a                                 lot of work after that to get done and                                 it's it doesn't really shouldn't really                                 place any any limitations on the                                 scheduler as far as we know yeah that's                                 right yeah                                 yeah I mean it's it's ready now you know                                 so many so many folks are using it in                                 production we've got a few different                                 ways that you can deploy it that or we                                 have a user guide that we've published                                 or an admin guide that outlines them                                 it's we do publish docker images of all                                 the main components so you can deploy                                 that if you're looking to or we also                                 have you know kind of basic build                                 instructions as well there's a you know                                 a few different steps that you a few                                 different components you need but                                 Johnson can you repeat the question                                 it's a combination it's uh all sorts of                                 different I think mostly Dell PowerEdge                                 render nodes and those are all connected                                 you know through our our network looking                                 at our systems right there um it's about                                 I think big network but then we have NFS                                 mounts where all the production data is                                 stored and so everything accesses it                                 through that so it's sort of a central                                 pool of data where where everything                                 reads everything else from it's it's                                 very network based that answers your                                 question okay okay yeah most of the                                 hosts are sixteen physical cores                                 thirty-two thread I think we have some                                 that are twenty forty Oh though you're                                 asking about the oh the server-side yeah                                 what does it take to run open here yeah                                 okay well it depends on the scale                                 I mean oh for fifty-five thousand I                                 would have to get back to you on some of                                 the specifics                                 yeah                                 yeah yeah we I think almost never have                                 server load related issues with with the                                 queue even with                                                    hundred thousand                                 yeah definitely it's it's you know                                 something that we have in minds but it's                                 there are enough benefits to the                                 development to doing that kind of                                 transition that it's something worth it                                 but the yeah there could there could                                 definitely be some increased resource                                 requirements as a result of that but                                 sorry right now it's basically multiple                                 master                                 so because everything is kind of                                 database focused everyone can kind of                                 you know play the same role in the                                 process yeah when we change it a memory                                 focus it'll get a little bit more                                 complicated where they'll probably be a                                 single scheduling node and the others                                 will be able to pick pick up the work if                                 that one drops off or or something like                                 that but definitely the you know we                                 always want to be able to support                                 multiple multiple servers here obviously                                 like reliance and reliability and                                 redundancy is it was pretty important                                 here for us                                 yeah definitely Greg do you want                                 Greg's muscle did working on that piece                                 how's it going I'm Greg software                                 engineer at Google yeah so the resource                                 management stuff is mostly about you                                 know imposing arbitrary limits on jobs                                 but particularly at the layer level so                                 open queue kind of has three tiers of                                 job structure you have a job which is a                                 large container of multiple layers a                                 layer is kind of a command that's                                 running against a frame range and then                                 you have individual frames running each                                 so you can impose any kind of limit you                                 want on the layer level and basically                                 it's just going to look at how many                                 types of jobs are running with that                                 limit what the resources are available                                 and do scheduling appropriately based on                                 that                                 I know I think I'm following you                                 correctly it's more for the the first                                 scenario you described we're basically                                 being able to do scheduling based on                                 license limitations is one of the main                                 priorities of a                                 no we'd love to talk about the about                                 advanced features yeah you know if we                                 want chat here or we also have a                                 developer's list as well which we can we                                 can share with you as well that'd be a                                 great place to start chatting about it                                 and and so what you'd like to see and                                 OPIC you yeah yeah and there's also that                                 we also have our public TSE meeting                                 tomorrow if you want to we're happy to                                 hear any any new proposals as well as                                 there                                 well they can probably talk a little bit                                 more about the specifics of it the Sony                                 folks but I will say that there there                                 isn't too much especially you need to do                                 you know once there's a there's a                                 component that runs on each of the                                 router notes called rqd when it's when                                 RTD starts up its gonna phone home back                                 to the back to the server back to the                                 Cuba it's called and those nodes will                                 basically be registered and ready to go                                 so as long as as long as you're on the                                 same network as Bucky bought then there                                 isn't really too much too much else that                                 he need to do but you do want to talk                                 about the specifics at all yeah I think                                 that covers most of it yeah in our case                                 you know we we peer to our network to                                 let's say Google's network in order to                                 have you know nice direct connection so                                 that everything was fast but but yeah                                 otherwise everything the the structure                                 of the queue itself the huge                                 infrastructure was still running exactly                                 as it was you know when everything is on                                 print                                 oh we did actually yes that's actually a                                 good question we are using preemptable                                 because it's about a quarter of a price                                 I think most of them have a policy of a                                                                                                        addition to being able to have it                                 preempted in our case that was                                 implemented in the the renderer itself                                 we have our own version of Arnold which                                 has the ability to sort of you know                                 write out a periodic checkpoint and so                                 you can start and restart stop restart                                 and and so that gave us the ability to                                 say okay well as long as they can give                                 us about you know                                                   before pre-empting the the host then we                                 can write out the temporary data and                                 then start it again somewhere else                                 and then which actually at that point                                 then the                                                                 deal because of that one you could at                                 least predict so yeah we've dealt with                                 it but it that's actually happening on                                 the software and of our renderer as                                 opposed to the actual queue itself                                 demand-based yeah we would we had a set                                 of scripts that would sort of scale up                                 and down our our cloud allocation as we                                 needed and so it was sort of based on                                 what the production itself would say you                                 know hey you know we're gonna have a                                 really busy render night you know let's                                 go up to you                                 you know from                                                           something like that but but but yeah                                 everything was based on sort of the the                                 load as it was on the cue and we had it                                 yeah we had it scaling alongside that                                 was those scripts separate from the                                 process of open cue code open cue                                 potentially in the future say oh I have                                 a lot of jobs I'm allowed to open up                                 more on GC GC P or whatever and get more                                 render nodes yeah I remember those                                 scripts were running alongside the cue                                 software as opposed to directly inside                                 of the cue system itself so it was kind                                 of more of a outside monitoring and yeah                                 tweaking the settings yeah yeah so                                 there's no that isn't built Adobe q yet                                 it is kind of an external process but                                 that's don't need something that we                                 haven't our eye on I think it comes up                                 comes up a lot with folks who'd like you                                 know all that data is in your schedule                                 already there's no reason why you need                                 someone making those manual decisions so                                 yeah that's something that we're looking                                 at yeah and also for the honored to say                                 about the preemptable event is that it                                 is kind of reliant on the software                                 itself to do any check pointing right                                 now the the system does handle knows                                 disappearing very well it's you know if                                 the node gets preempted then it's the                                 system flags that pretty quickly and it                                 gets removed from the pool so there                                 isn't really anything special you need                                 to do to deal with preemptable is it                                 just kind of you know the tasks will                                 fail and the nodes will drop off and                                 then those tasks get reviewed later                                 and if you do have checkpointing in use                                 with your software then you know the                                 software elves make use of that resume                                 the task for you it is sorry it is my                                 understanding that open queue has quite                                 a bit different from queue like you                                 mentioned change in the network protocol                                 may be running post-grad and open-source                                 version is Sony running open queue or                                 queue and are there plans to like                                 keeping                                 migrating SONET open queue and have that                                 rolling with the open source release yes                                 so they're in the process of migrating                                 over but they soon will be fully on the                                 open queue release and all of the it                                 actually kind of worked out because all                                 those components that we removed and                                 replaced we're all all mapped pretty                                 well to their replacements you know gr                                 PC and ice share a lot of similarities                                 Oracle and Postgres were almost entirely                                 compatible there were very few like code                                 changes we actually needed to to get all                                 that stuff working so the the transition                                 process should be should be pretty                                 smooth we haven't really run into any                                 any big problems in hi could you talk                                 about some of the maybe performance edge                                 cases just in terms of submitting a lot                                 of jobs for oh thank you to consider                                 sort of limits around that space and                                 what you did to kind of mitigate them or                                 as you move to the cloud and maybe                                 introduce more latency and and having                                 hosts and sort of weird locations or                                 things like that                                 Thanks yeah sure so when it comes to                                 moving to the cloud we have we have run                                 into too many problems actually but the                                 kind of network demands of our QDR are                                 pretty low and haven't really been                                 affected much by the latency involved I                                 think the I think file storage which                                 open queue doesn't really touch at all                                 is is much more of a concern than any                                 anything that comes up with the                                 scheduling itself or the render nodes in                                 terms of like lots of jobs                                 yeah                                 yeah do I don't talk about some of the                                 load-testing he did as part of the last                                 week conferences hi my name is Brennan                                 Doyle I'm a solution architect at Google                                 so the tool is not really intended to be                                 cloud only like we're trying we have                                 released an open-source tool that can                                 run anywhere but as a solution architect                                 with a background in visual effects that                                 we've been running a lot of we've been                                 stress testing it at Google ourselves                                 and as you mentioned a lot of what you                                 try to do when you're moving to the                                 cloud is make sure that the                                 infrastructure behind it is strong and                                 storage and Google has a great story                                 around networking we have a great story                                 around storage as well this is not a                                 Google presentation all the other clouds                                 are doing a great job as well but you                                 would want to connect with solution                                 architect or someone from the cloud that                                 you're running on to design your system                                 oh I think so would we we were we've run                                 some processes primarily through blender                                 and running jobs we've had upwards of                                                                                                          our scenarios oh yeah sorry that that                                 would be instances which would be                                 somewhere between a virtual cords and                                 sixteen depending on what we were doing                                 so the system should scale quite well                                 but you will want to talk to somebody                                 with cloud experience about like your                                 filers and what type of networking                                 you're using because that's likely to be                                 where you're gonna run into issues yeah                                 but in terms of we did throw a you know                                 I think thousands of jobs and tap a                                 simultaneous asset at the same time and                                 you know I think we've we uncovered a                                 few bugs in the process but once we made                                 a few a few small efficiency efficiency                                 changes things you know handle it pretty                                 well so it can handle a lot of                                 simultaneous work right now                                 I forget the exact it was thousands of                                 of tasks running at the same time right                                 we published some solutions around this                                 that you could find on the GCP website                                 by just looking up open Q and G CP and                                 there's like scene files that you can                                 download and examples of how to run                                 those so we've done a couple of things                                 one is like very small jobs and a lot of                                 them and then others are very big jobs                                 and not as many and open q does it's                                 been keeping up I don't plot number of                                 my manner remembering was about six or                                 eight thousand at a time are there are                                 there any design decisions being made to                                 help push forward things in a like a                                 multi-site workflow way where different                                 sites could actually share a single                                 supervisor and manage the work between                                 them and have some sort of native                                 understanding even of things like the                                 bandwidth between sites how much data                                 could actually travel across those tubes                                 and just actually like manage the                                 resources in a more holistic worldwide                                 kind of way mmm                                 yeah good coach so they're kind of like                                 to two parts that question right so it                                 currently with the obq does support a                                 multi-site deployment this is kind of                                 you know one of the benefits to this the                                 the current database driven model is you                                 to spin up more key box where ever                                 assign them different facilities and you                                 kind of are on your right each each                                 facility a term within open queue                                 operates independently so it just so it                                 takes care of its own facility and                                 you're all good so that is that's                                 something we'll have to maintain as they                                 move to more in memory approach and                                 makes make sure it that kind of system                                 still still works well because it's                                 important for a lot of folks are using a                                 system this kind of second part is like                                 yeah communicating requirements between                                 the two that is not really something                                 that open kudos right now I think a lot                                 of that comes down to file storage as                                 well like making sure your assets are in                                 the right place at the right time that                                 is really right now outside of the open                                 queue domain but it it definitely does                                 play into the scheduling store                                 various different requirements that need                                 to be in place for the job start so                                 that's something we'll be looking at                                 Tampa just around that how how much                                 history you can keep in the database if                                 it recommended like when you would                                 actually have to move records out of the                                 the Postgres database or is it seem like                                 it scales pretty well I don't think                                 right now that that ever really needs to                                 happen so there is a kind of auto                                 archiving built in so the database is                                 kind of split between primary tables and                                 history tables and as jobs finish they                                 get kind of moved all their data gets                                 kind of moved to the history table so                                 it's still there and accessible but the                                 as the actual scheduling is running it                                 is only working on the primary tables so                                 it stays quite fast so there's no there                                 should be no real like you know                                 archiving stuff that has to happen right                                 now with regard to local rendering could                                 you talk a little bit about any approach                                 that you already have to rendering                                 through the same code path so in other                                 words an artist wants to use their local                                 machine but still go through the same                                 code path so you say have a little say                                 blogging Resource Management cetera is                                 there something built in already to                                 handle that or is that something you'd                                 have to develop on top of oh thank you                                 yes I mean you can run an archaeon on                                 you know your local workstation and have                                 it read to register as a as a render                                 node and then it'll basically function                                 as a as a normal worker within the                                 system oh that's right yeah there's also                                 a kind of local scheduled feature that's                                 that's built into the job submission as                                 well so you can sketch you can schedule                                 work directly to your machine as well so                                 when and when rqd registers a render                                 node does it sort of introspect all of                                 its sort of properties and then report                                 those so so does that include local                                 storage as well yeah so it includes yeah                                 cores Ram local storage scratch storage                                 there are a few of other fields GPU                                 GPUs as well yep and that all gets kind                                 of bundled into this host report that                                 gets sent back to the cubot so and then                                 the cue bottle use that to kind of break                                 you know if you've configured it it'll                                 it can break that host up into different                                 slots for work basically so you know                                 core is a rammer whatever do you is                                 there any management of CPU affinity on                                 Linux I don't think we do any of that                                 right now how often does the host                                 connects                                 since that report to the database and                                 often how often does it sketchily works                                 what's the cycle I guess it's my                                 question hmm so the the report gets sent                                 is every                                                                yeah I say so so it's got this kind of                                 fallback method so it can be every three                                 seconds and then it kind of that'll fall                                 back is it as it stops working on stuff                                 and reports less less frequently and                                 sorry what was the the second part that                                 the scheduling cycle yeah so we're                                 finding that things gets so the                                 scheduling cycle is pretty much running                                 pretty much running constantly it'll                                 just finish the loop and keep working so                                 we're finding that even with when we                                 were up until the thousands of tasks                                 things were getting scheduled within I                                 don't know a few seconds I think right                                 we hope to actually improve that with                                 the with the in-memory scheduler we                                 think that we could do up do a much                                 quicker full pass of the farm and                                 basically schedule the entire farm in a                                 single pass like like within a second                                 yeah                                                                    can you talk a little bit about the fair                                 share mechanism like how you break up                                 the farm and how that's allocated and                                 how you decide what the most important                                 thing to get going is yeah Gregory are                                 you you're a little bit more familiar                                 with what that stuff right sorry you                                 talk a little bit about the fair share                                 mechanism like how you break up a                                 resource like a render farm into                                 multiple shows multiple departments and                                 talk about how you allocate those                                 resources across all of these                                 essentially competing shows so I                                 basically all of those are pretty much                                 features of a job right and I the                                 scheduler is gonna look at those                                 features and the available resources and                                 determine whether or not it will work on                                 the resources that are available pretty                                 much hosts are broken down into                                 available procs procs is not a term for                                 processors in this case but it's                                 basically a work slot and so you know                                 going to bin packing and stuff like that                                 that's the the mechanism for bin packing                                 there so is there like something                                 specific as far as the well so there's a                                 bunch of different ways to do fair share                                 right like there's just one big queue                                 and everybody's ranked in priority order                                 or you break up your farm into loose                                 allocations across the shows or you                                 break them up in hard allocations across                                 the shows like I'm curious what the                                 mechanism is for that got it yeah so                                 there's actually allocations and a show                                 can subscribe to particular allocations                                 of hosts so allocations being a bucket                                 for hosts and show                                 subscribe to multiple of those                                 allocations and it's really up to you as                                 far as how you want to configure your                                 breakdown to the farm so you can have it                                 be just one big flat pool that's shared                                 evenly and prioritized across everyone                                 or if you have you know a certain amount                                 of like quick jobs that you want to have                                 scheduled and you know a separate pool                                 reserved for those you can obviously set                                 that what type of Python MPI external                                 Python API do you have for open queue                                 and also okay the metrics and statistics                                 can we get back for completed jobs and                                 tasks yeah so the in terms of API there                                 is you know there's a Python API that we                                 publish all of the it's part of the main                                 the main repository that's up on github                                 all of our basically all of our                                 client-side tools are going through that                                 same Python API so the GUI uses that the                                 submission tools use that all the hosts                                 app plugins that we have right now is                                 that as well so there's a lot of new the                                 API is there as well as you know a bunch                                 of other kind of code samples of use if                                 you look at the what the existing Python                                 components are using to call into that                                 API in terms of like metrics that are                                 available so based on the information                                 that's stored in the history table you'd                                 be able to you know compile all of that                                 that there isn't actually there's                                 nothing built-in and not in the API for                                 for actually putting together kind of                                 rolled up metrics based on things like                                 that but I mean I've I've done a lot of                                 work just pulling the data using you                                 know the pandas and the data science                                 stack and just running everything                                 through that and that works very well                                 another blender question I assume you're                                 sending to blender instances and you're                                 rendering and cycles is that what you're                                 doing you said you were dispatching from                                 blender I know some of the studios I                                 work with we randomly get black frames                                 I think somebody wrote a script at one                                 of the studios to detect the black                                 frames is there any management of bad                                 frames it all built into the system                                 where it automatically does a turd we                                 have to rely upon Python scripts and                                 stuff like that yeah I don't think                                 there's anything like that built in                                 right now yeah I would be a though there                                 is you know the when you're submitting                                 jobs you can basically break your job as                                 many different stages as you want so you                                 can have a job structure that does like                                 preflight main render or some sort of                                 post process so that's probably what                                 you'd want to do is have a post process                                 that that doesn't check for bad frames                                 and you can then call into the Python                                 API to either submit a new job or or req                                 certain frames so this is a kind of                                 multi-tiered and it might be just say                                 the answer might be just hey it's just                                 how you configure it but um so for                                 example you have software that sometimes                                 it's licensed per user per machine so if                                 you're running you you want to benefit                                 from being able to use one license per                                 machine even though you have it broken                                 up into multiple instances but then also                                 if you remove the user from it then you                                 don't know who's doing the actual job so                                 can you talk a little bit about how you                                 guys configure those kind of things and                                 then also sorry also permissions on the                                 files at the end is that all client code                                 or do you have any mechanism around that                                 yeah so for the permissions on the files                                 there's not                                 I think there's any management of that                                 right now it does be so rqd will run as                                 the will run as the user that submitted                                 the job right yes I'm users model works                                 so when it writes it out it'll be owned                                 by the that user okay so you would have                                 the problem with a software that is                                 license per user that you'd be pulling                                 multiple license for a single machine                                 okay and there's no way to manipulate                                 that in the system to modify it going in                                 and out of the system I                                 so it's either one way or the other                                 right now so basically you could                                 configure all your jobs to run as a                                 single user a generic morning but you                                 can't do that on like a per job level                                 okay and there's no way going in and out                                 like to reassign it and then going back                                 out not at the                                 like open cue level yeah so are ya just                                 it was more curiosity mmm thanks thanks                                 I wanted if you can from a like a render                                 Wrangler perspective if you could talk                                 about what tools you make available for                                 job variation or exception or error                                 handling what what sort of mechanisms do                                 you provide for either scripts to do                                 that or sort of automatic detection yeah                                 so we do have kind of two in the GUI                                 there are two different sections really                                 there is a kind of artist view and then                                 there's a Wrangler view as well and this                                 is kind of pre-configured with a bunch                                 of different tools that help make it                                 easy to kind of drill down into                                 different parts of the farm see what's                                 happening where see you know quickly see                                 what kind of frames might be bad or                                 taking too much resources kind of stuff                                 so there are that is kind of built into                                 the GUI right now the GUI also is has a                                 very kind of extensible plug-in system                                 so like each panel in the GUI is                                 technically a plug-in that's that's                                 being run and it's a pretty simple                                 process to basically script up new new                                 panels and that as well so there's                                 something specific you'd like to see                                 then you know it's a few lines of code                                 and you can add a panel to the GUI to                                 see that sort of thing hi I should like                                 to ask about the submission API or the                                 job descriptions it seems to me that                                 with a project like this there's either                                 going to happen by accident or                                 intentionally a common Job Description                                 format for people to submit render jobs                                 can you talk about the submission API                                 how high or low level you're choosing to                                 place that yeah so there is so in terms                                 of like the job description itself there                                 are a few different layers at at its                                 base it does use a kind of XML                                 description you don't really have to                                 work with that directly we do have a                                 whole Python layer so it's basically                                 you're basically constructing Python                                 classes that represent pieces of the job                                 and then the                                 the system basically handles baking that                                 out into his XML later looking how high                                 or low level are those sort of pieces                                 then are you are you talking run this                                 command or are you talking do this                                 render against the script or do the                                 series of frames or right right so it's                                 basically run this commands it it passes                                 in a full a full commands with and there                                 are a few different placeholders that                                 you could put in that command like frame                                 number for example is the big one but                                 yeah there's really no there's really no                                 translation that's happening on the                                 server side for that it all gets                                 constructed client-side and that those                                 commands get pretty get passed through a                                 you know almost exactly to the to the                                 render nodes so that the the kind of                                 nice thing about that is there's you                                 know you don't really have to wait for                                 open queue to support any specific                                 software you can just you know construct                                 the the Job Description with the command                                 that you want to run whatever that is                                 you know you can do file are copying or                                 just whatever bash commands that are                                 available on the on those machines                                 right so we do have some kind of higher                                 level like kind of abstraction layers                                 for that in our it's called the PI                                 outline library which lets you is that                                 Python abstraction layer so you can kind                                 of work at a higher level in Python but                                 yeah that's not not strictly necessary                                 hi I had a question about user                                 interaction with the database and with                                 the queue bots is there any kind of                                 concern about users interacting with the                                 queue bots to get information about                                 their jobs while the queue bots are                                 still trying to schedule like I've seen                                 other queueing systems that will mirror                                 that database or maybe you spin up a                                 separate queue bought for their                                 interaction right so that is one of the                                 nice things about being able to have                                 multiple multiple qubits is you can kind                                 of as as load increases you can kind of                                 spin up more to deal with that because                                 the scheduling runs mostly separate from                                 the actual like API serving we haven't                                 really seen any any problems with like                                 API load slowing down scheduling as long                                 as it's more about API load competing                                 with other API calls but spending up                                 more key BOTS can alleviate that and one                                 of the nice one of the kind of benefits                                 of is migrating to in-memory scheduling                                 is then we could have one queue bought                                 that basically is dedicated to                                 scheduling and others that are dedicated                                 to API and I'm going to make sure that                                 there's no conflict there I think you                                 mentioned license management being a                                 future thing but I just don't know if                                 there's any mechanisms or any thoughts                                 about how to maximize license usage for                                 things that are like per node so for                                 example you know you pay one license per                                 node and then you want to be in all                                 those jobs from that kind in that node                                 but we felt really micromanaging it                                 which you know to have the licenses so                                 just want to enforce anything there or                                 any thoughts yeah I don't I don't think                                 we do licensing right now is that                                 correct because of this kind of                                 scheduling problems like right now our                                  QD isn't registering like what licenses                                  are available automatically based on you                                  know being able to collect information                                  from the node it would have to be                                  configured                                  by the user for that individual node and                                  basically that node added to a pool for                                  license consumption so the GUI for the                                  interface is all written in PI site if I                                  remember correctly yeah that's right                                  I'm just curious when you have like a                                  hundred thousand nodes updating that                                  table is that how slow does that get                                  because usually people go to C++ for                                  that instead of you relying on Python                                  right yeah so it is the GUI right now                                  was not really designed to view like the                                  entire list at once in fact it doesn't                                  even load the load the full list when                                  you post so you just don't do that in                                  the first day and there's a so there's                                  basically a search field so you so you                                  can basically search for whatever nodes                                  that you're looking for and you can just                                  put up put a star there and just let and                                  see the full list or you can kind of                                  drill down and there are cut there are a                                  few different panels for for viewing for                                  viewing the full farm structure as well                                  so you know there's a like there's one                                  tree view where you can see the                                  breakdown per facility and then                                  allocation you can you know view the                                  full list for whatever bucket of nodes                                  that you're looking for at the time as                                  well so and so you mentioned Python API                                  to communicate over the system is there                                  any event-driven API like you will get                                  notified when the job complete or here                                  or something you could subscribe to                                  another at the moment but that's coming                                  very soon that's in development right                                  now sorry another question as far as                                  matrix goals we went to a lot of talks                                  yesterday that people are talking about                                  matrix pipeline matrix and whatnot and                                  with Google having some machine learning                                  frameworks I wonder if it any thought                                  being put there like what matrix does                                  open queue currently retrieve and you                                  know there's fun stuff yeah I mean we've                                  we've been to a lot of those talks as                                  well and we're definitely attend shinto                                  what folks are asking for you know it's                                  the kind of metrics collection right now                                  is pretty basic                                  as it stands but we you know we kind of                                  understand how important that stuff is                                  and yeah                                  we definitely we definitely wanna do                                  more with that in the future so question                                  about composing the submissions itself                                  like is there is there any plan to build                                  a GUI or something where and I can                                  compose the submission graph and then                                  submit it to the open queue or do you                                  want to leave that to the this is the                                  application itself to compose using the                                  Python API the court is right so we do                                  have a an application right now it's                                  called queue submit it's part of in the                                  main repo just kind of what you're                                  looking for you can you know basically                                  add add various layers to your jobs you                                  can build up some you know kind of                                  linear job structure of maybe pre fly it                                  and render and comp kind of thing it                                  doesn't right now it doesn't do the full                                  like the full complex tree structure                                  that you're talking about but we're                                  definitely will definitely looking at                                  like expanding and building on that tool                                  in the future for for doing that so                                  do you want to build a complex workflow                                  Verena like you take the inputs and spit                                  the outputs from one DCC application                                  into the another one and you want to see                                  everything in a single submission graph                                  it depends on that so yeah as you                                  rightly said it is it can be studio                                  specific but I can see general patterns                                  for like the workflows because like all                                  the studios try to do the same kind of                                  workflow sets at some point                                  yeah basically having her having our Job                                  Description come with a lot of having                                  pie outline come with a lot of different                                  examples for how to get started but that                                  kind of thing                                  is there a language agnostic API like a                                  restful endpoints for interrogating jobs                                  yes so at all so we don't have a REST                                  API yet that's kind of planned for the                                  future right now it's all going through                                  G RPC so the the Python API is calling                                  those G RPC endpoints so yeah there's no                                  there's no reason that needs to be                                  Python specific exactly yeah you can                                  call Jay RPC directly there's also the                                  you know be the proto files that that                                  get used for that communication are                                  published along with alongside with the                                  code so that could get compiled into                                  whatever whatever language you're using                                  i guess i'm for maybe one more one or                                  two more                                  all right thanks                                  is there anything in built where you can                                  tell a job at a submission time to kill                                  itself after a certain amount of time or                                  to retry is that built in or is that                                  something that's going to be deferred to                                  some kind of monitoring that's external                                  let's see so we do have the we do have                                  auto retry built in configurable in                                  terms of killing itself after certain                                  out of time that's not that's not                                  something I've seen I think so right now                                  I'm just getting back to the render                                  wrangling aspect of things do you guys                                  have live log streaming with regular                                  expression analysis of it to be able to                                  do customer warnings or errors for                                  example yeah so we have so one of the                                  panels in the GUI will will stream the                                  log file of the of the task that you                                  have selected and you could do you can                                  do search within that there's a search                                  field within that panel I don't know                                  exactly how complex the like regex                                  expressions that can handle our over                                  it's just doing a kind of basic search                                  but that's the kind of thing we would                                  build out in the future yeah in terms of                                  like automatic alerting based on what's                                  coming from that log nothing like that                                  right now yeah that would be a probably                                  configured                                  your job description kind of have a                                  separate process that runs and watches                                  watches log files so in the event like a                                  network partition where your where your                                  render nodes no longer can communicate                                  with your with your server what what is                                  is there any particular behavior that if                                  there is there like a heartbeat do they                                  do they shutdown or do they just keep                                  rendering happily yeah so if they if                                  they lose connection to the server there                                  is a regular heartbeat that happens the                                  not sure exactly what the behavior on                                  the on the render node side is on the                                  server side those nodes will drop                                  they'll be flagged and then removed from                                  the pool after I don't know                                             or minute or something like that after                                  it misses a few heartbeats in terms of                                  how the how the actual render node                                  handles that I I believe it'll kind of                                  just keep keep going until it finishes                                  its current task and then it'll they                                  won't receive any new reports from the                                  queue bot so I'll just stop at that                                  point yes yeah if the heartbeat picks                                  back up it'll be added back in yeah this                                  kind of yeah this kind of happens a lot                                  in a especially in a cloud environment                                  we have preemptable is coming and going                                  and then they share the same name or                                  same IP address that this will get                                  handled fine yeah I have a question so                                  is there a mechanism to add in a pre                                  process and post process mechanism into                                  it or are we responsible for adding that                                  into our own scripts so you'd configure                                  that as part of as another layer in your                                  job basically because it's all using you                                  know because it has this kind of                                  low-level just build a command and pass                                  it to the render node there's not much                                  difference between a render itself and a                                  pre or post process so you would just                                  kind of add that as a other layer thank                                  you                                  yes yeah it is                                  so you can yeah oh just we yeah we're                                  being told me we need to wrap it up so                                  but we'll all be around so anyone with                                  any more questions definitely a more                                  technical side feel free to oh yeah and                                  our teeth we have our TSC meeting                                  tomorrow if folks want to show up to                                  that but it's supposed to posted on our                                  on our website on open q dot io CSC is                                  in room in room                                                                                                                                   thanks Emily thanks everyone                                  [Applause]
YouTube URL: https://www.youtube.com/watch?v=0gXT3sntiFg


