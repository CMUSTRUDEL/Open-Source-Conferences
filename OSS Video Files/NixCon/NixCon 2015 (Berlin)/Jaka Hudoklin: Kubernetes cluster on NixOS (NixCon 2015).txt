Title: Jaka Hudoklin: Kubernetes cluster on NixOS (NixCon 2015)
Publication date: 2020-10-29
Playlist: NixCon 2015 (Berlin)
Description: 
	
Captions: 
	00:00:05,279 --> 00:00:09,760
okay so welcome to the next uh

00:00:06,960 --> 00:00:10,480
session uh which is going to be done by

00:00:09,760 --> 00:00:14,240
jaka

00:00:10,480 --> 00:00:17,359
from ljana jaka as i have been told

00:00:14,240 --> 00:00:20,400
is a guitar player and programmer

00:00:17,359 --> 00:00:23,439
and long time next contributor

00:00:20,400 --> 00:00:25,119
working on systems stuff

00:00:23,439 --> 00:00:26,560
and that's what he's going to talk about

00:00:25,119 --> 00:00:31,840
today so

00:00:26,560 --> 00:00:31,840
welcome everybody jaka

00:00:34,399 --> 00:00:38,559
um hello uh welcome to my talk about

00:00:37,920 --> 00:00:41,920
running

00:00:38,559 --> 00:00:45,440
uh kubernetes on excise uh

00:00:41,920 --> 00:00:50,399
america and i we'll talk about why nyx

00:00:45,440 --> 00:00:50,399
and kubernetes are a great combination

00:00:50,640 --> 00:00:57,120
okay so something about me i'm uh

00:00:54,079 --> 00:00:59,840
as it says i'm full stack engineering

00:00:57,120 --> 00:01:01,440
javascript python c and different other

00:00:59,840 --> 00:01:04,559
languages

00:01:01,440 --> 00:01:09,360
with experience in provisioning

00:01:04,559 --> 00:01:09,360
and some embedded devices and security

00:01:09,439 --> 00:01:16,479
lately i'm mainly back in javascript

00:01:12,799 --> 00:01:21,520
developer but i'm an instructor involved

00:01:16,479 --> 00:01:25,360
in white spectrum of id fields

00:01:21,520 --> 00:01:27,280
one day i'm fixing bugs of incompetent

00:01:25,360 --> 00:01:28,560
front-end developers and on other days

00:01:27,280 --> 00:01:31,759
i'm doing some low-level

00:01:28,560 --> 00:01:31,759
hardware programming so

00:01:32,159 --> 00:01:38,320
so the projects i'm currently working is

00:01:36,000 --> 00:01:40,400
actually the first one is a startup

00:01:38,320 --> 00:01:42,960
called github

00:01:40,400 --> 00:01:44,320
and it's a new fintech platform for

00:01:42,960 --> 00:01:46,720
multi-currency

00:01:44,320 --> 00:01:48,240
payment trading and exchange it's based

00:01:46,720 --> 00:01:51,439
on ripple

00:01:48,240 --> 00:01:51,840
uh we already got the cmos and we had

00:01:51,439 --> 00:01:55,360
our

00:01:51,840 --> 00:01:57,680
um and it's uh

00:01:55,360 --> 00:01:58,960
currently we are just releasing our new

00:01:57,680 --> 00:02:02,159
product

00:01:58,960 --> 00:02:06,880
um that that is

00:02:02,159 --> 00:02:11,360
for um mostly for enterprise users

00:02:06,880 --> 00:02:14,480
and the other products

00:02:11,360 --> 00:02:17,440
i'm making is actually data-driven

00:02:14,480 --> 00:02:20,720
distributed task automation and

00:02:17,440 --> 00:02:24,480
aggregation work using graph databases

00:02:20,720 --> 00:02:28,560
and docker containers and all snakes

00:02:24,480 --> 00:02:31,440
and this this this project is

00:02:28,560 --> 00:02:32,480
actually making my free time and i also

00:02:31,440 --> 00:02:36,319
want to make

00:02:32,480 --> 00:02:39,360
a startup from it so

00:02:36,319 --> 00:02:43,599
and so when i started working

00:02:39,360 --> 00:02:44,560
on github uh we decided that we want to

00:02:43,599 --> 00:02:47,640
split

00:02:44,560 --> 00:02:49,440
um our infrastructure in many multiple

00:02:47,640 --> 00:02:52,879
microservices

00:02:49,440 --> 00:02:55,440
so we started to think uh how how can we

00:02:52,879 --> 00:02:58,640
deploy scalable infrastructure

00:02:55,440 --> 00:03:01,920
uh our developers wanted to use their

00:02:58,640 --> 00:03:05,840
docker for development uh

00:03:01,920 --> 00:03:08,640
and deployments so

00:03:05,840 --> 00:03:09,680
the questions were how how and but i

00:03:08,640 --> 00:03:12,319
still wanted to

00:03:09,680 --> 00:03:13,680
to use nexus and expect just for our

00:03:12,319 --> 00:03:17,120
deployments

00:03:13,680 --> 00:03:18,159
so the the question i uh the questions i

00:03:17,120 --> 00:03:20,480
had

00:03:18,159 --> 00:03:21,680
over how to deploy scalable nixios

00:03:20,480 --> 00:03:26,000
systems

00:03:21,680 --> 00:03:26,000
how to deploy scalable apps on top of

00:03:26,080 --> 00:03:32,239
of top mixers uh how to have

00:03:29,280 --> 00:03:35,360
reliable distributed storage and

00:03:32,239 --> 00:03:35,360
scalable monitoring

00:03:36,720 --> 00:03:44,560
so we need so i decided we need

00:03:39,840 --> 00:03:46,879
something like cluster process manager

00:03:44,560 --> 00:03:48,480
secure distributed overlay networking

00:03:46,879 --> 00:03:50,319
cloud balancer distributed and

00:03:48,480 --> 00:03:54,640
replicated storage

00:03:50,319 --> 00:03:58,640
um schedule for different resources like

00:03:54,640 --> 00:03:58,640
power networking storage

00:03:58,799 --> 00:04:03,200
and this all should be managed by some

00:04:01,120 --> 00:04:04,959
cluster manager and there should be some

00:04:03,200 --> 00:04:09,680
monitoring system

00:04:04,959 --> 00:04:09,680
to actually see what's going on um

00:04:09,840 --> 00:04:16,799
so um to do everything

00:04:13,599 --> 00:04:20,880
we have to start with

00:04:16,799 --> 00:04:26,560
with let's make an overview

00:04:20,880 --> 00:04:26,560
of what we have so um the first thing

00:04:26,720 --> 00:04:30,720
is decision of which container service

00:04:29,040 --> 00:04:32,850
manager we will use

00:04:30,720 --> 00:04:35,199
so in that case um

00:04:32,850 --> 00:04:37,840
[Music]

00:04:35,199 --> 00:04:38,960
we have different choices one one of the

00:04:37,840 --> 00:04:41,040
first is

00:04:38,960 --> 00:04:42,160
usage of systemd it's not like container

00:04:41,040 --> 00:04:45,199
manager

00:04:42,160 --> 00:04:47,759
but the the main real difference is

00:04:45,199 --> 00:04:50,320
for container managers they actually run

00:04:47,759 --> 00:04:53,440
processes in containers and for

00:04:50,320 --> 00:04:56,479
um and for

00:04:53,440 --> 00:04:59,440
and for example system also has

00:04:56,479 --> 00:05:00,639
this uh command called systemd and spawn

00:04:59,440 --> 00:05:04,400
that also runs

00:05:00,639 --> 00:05:07,360
uh process processes in containers

00:05:04,400 --> 00:05:08,080
and the other you you will probably know

00:05:07,360 --> 00:05:12,000
is

00:05:08,080 --> 00:05:14,160
docker um so main advantage of docker is

00:05:12,000 --> 00:05:16,720
that it's

00:05:14,160 --> 00:05:19,280
user friendly and provides hub of

00:05:16,720 --> 00:05:22,840
primary docker app containers

00:05:19,280 --> 00:05:25,840
it has two simple format for building

00:05:22,840 --> 00:05:25,840
containers

00:05:26,000 --> 00:05:31,120
and idea behind docker is that you run

00:05:30,800 --> 00:05:33,759
one

00:05:31,120 --> 00:05:34,400
app inside container not the whole os

00:05:33,759 --> 00:05:37,680
because

00:05:34,400 --> 00:05:38,560
if for comparison for example with lxt

00:05:37,680 --> 00:05:40,560
uh

00:05:38,560 --> 00:05:42,000
container manager where you usually run

00:05:40,560 --> 00:05:44,560
the the

00:05:42,000 --> 00:05:45,120
whole os inc in container of course you

00:05:44,560 --> 00:05:48,320
can

00:05:45,120 --> 00:05:51,520
i mean holo is called distro

00:05:48,320 --> 00:05:53,120
base image of course you can also do

00:05:51,520 --> 00:05:58,720
this with docker and with

00:05:53,120 --> 00:06:04,160
other um uh container managers but

00:05:58,720 --> 00:06:07,600
that's not uh how it should be done

00:06:04,160 --> 00:06:08,800
um okay the the rocket i don't know much

00:06:07,600 --> 00:06:11,919
about rockets

00:06:08,800 --> 00:06:13,360
it's a new thing developed by coreos uh

00:06:11,919 --> 00:06:16,800
it actually

00:06:13,360 --> 00:06:19,520
they defined some uh some specification

00:06:16,800 --> 00:06:20,479
the clarity specification for mod for

00:06:19,520 --> 00:06:24,000
building

00:06:20,479 --> 00:06:27,199
um for building images

00:06:24,000 --> 00:06:30,639
and it's a bit different from docker but

00:06:27,199 --> 00:06:35,360
um in in a sense that you can that

00:06:30,639 --> 00:06:37,280
it ha that is the

00:06:35,360 --> 00:06:39,120
it's a bit different from docker that it

00:06:37,280 --> 00:06:42,240
has more uh

00:06:39,120 --> 00:06:42,960
uh you can specify more things uh

00:06:42,240 --> 00:06:45,680
because

00:06:42,960 --> 00:06:46,000
uh docker has pretty much simple format

00:06:45,680 --> 00:06:48,160
for

00:06:46,000 --> 00:06:51,120
uh building images and as i said it's

00:06:48,160 --> 00:06:54,319
sometimes too simple

00:06:51,120 --> 00:06:56,240
um okay and then we

00:06:54,319 --> 00:06:58,160
let's go to the overlay networking why

00:06:56,240 --> 00:07:00,720
we need overlay networking

00:06:58,160 --> 00:07:02,560
it's actually to connect all these

00:07:00,720 --> 00:07:04,479
services together across different

00:07:02,560 --> 00:07:08,160
machines we are running

00:07:04,479 --> 00:07:09,599
because we don't want to to statically

00:07:08,160 --> 00:07:12,319
type in all the ips

00:07:09,599 --> 00:07:12,319
we just

00:07:13,039 --> 00:07:16,639
we just want to spawn these services

00:07:15,520 --> 00:07:18,319
across

00:07:16,639 --> 00:07:19,680
anywhere in the cluster and they should

00:07:18,319 --> 00:07:23,280
connect to

00:07:19,680 --> 00:07:26,160
or or other services they need

00:07:23,280 --> 00:07:28,479
so in that case we have a few choices we

00:07:26,160 --> 00:07:30,479
have open we switch

00:07:28,479 --> 00:07:31,520
as we will see later we use open we

00:07:30,479 --> 00:07:34,880
switch with

00:07:31,520 --> 00:07:37,440
uh ipsec networking or across

00:07:34,880 --> 00:07:38,080
our cluster but then we have also some

00:07:37,440 --> 00:07:41,360
other

00:07:38,080 --> 00:07:44,560
choices that um there are more

00:07:41,360 --> 00:07:47,759
docker related for example this wave

00:07:44,560 --> 00:07:49,599
uh that nail that that simply enables to

00:07:47,759 --> 00:07:49,919
connect multiple machines and i think

00:07:49,599 --> 00:07:53,440
they

00:07:49,919 --> 00:07:56,840
also use now openly switch as a back end

00:07:53,440 --> 00:08:01,280
uh core s flannel no flanner

00:07:56,840 --> 00:08:04,319
flannel uh that's um they

00:08:01,280 --> 00:08:06,479
of flannel is actually the

00:08:04,319 --> 00:08:07,360
it's not as optimized as open the speed

00:08:06,479 --> 00:08:10,720
because open

00:08:07,360 --> 00:08:14,000
switch has a kernel

00:08:10,720 --> 00:08:15,599
uh kernel support so it's actually a

00:08:14,000 --> 00:08:19,440
really low latency and

00:08:15,599 --> 00:08:21,759
with flannel you can there is

00:08:19,440 --> 00:08:23,440
a bit more latency because it's running

00:08:21,759 --> 00:08:27,120
in user space

00:08:23,440 --> 00:08:31,520
and um so in that sense

00:08:27,120 --> 00:08:35,680
it's lower but it connects to etcd tcd's

00:08:31,520 --> 00:08:39,200
uh distributed configuration storage

00:08:35,680 --> 00:08:41,279
so whenever a new machine comes to

00:08:39,200 --> 00:08:42,399
a network it automatically connects to

00:08:41,279 --> 00:08:45,440
this

00:08:42,399 --> 00:08:47,760
distributed networking

00:08:45,440 --> 00:08:47,760
and

00:08:49,200 --> 00:08:56,560
docker is now working on lip network

00:08:53,279 --> 00:08:59,839
and it's not as developed as

00:08:56,560 --> 00:08:59,839
other alternatives

00:08:59,920 --> 00:09:07,680
so to to be actually able to run

00:09:04,000 --> 00:09:11,120
our services across different machines

00:09:07,680 --> 00:09:15,040
we need to uh to have some kind of

00:09:11,120 --> 00:09:17,519
storage that's remotely available or

00:09:15,040 --> 00:09:18,560
are available on demand on specific

00:09:17,519 --> 00:09:21,600
server

00:09:18,560 --> 00:09:23,600
so in that sense uh uh uh

00:09:21,600 --> 00:09:25,600
we we have a choice of different

00:09:23,600 --> 00:09:28,959
distributed file systems

00:09:25,600 --> 00:09:31,760
uh like self glass rfs and extreme fs

00:09:28,959 --> 00:09:34,000
uh and also in cloud solutions like

00:09:31,760 --> 00:09:37,279
amazon elastic block storage

00:09:34,000 --> 00:09:40,720
uh in nexas currently

00:09:37,279 --> 00:09:44,800
uh there is a model for extreme fs

00:09:40,720 --> 00:09:47,920
uh that mate was working on and

00:09:44,800 --> 00:09:50,160
um i don't know how well does it work

00:09:47,920 --> 00:09:52,800
we still need i would really like to

00:09:50,160 --> 00:09:53,839
have unique size model for sap for

00:09:52,800 --> 00:09:56,320
glasstrap as

00:09:53,839 --> 00:09:57,440
that's better supported by cluster

00:09:56,320 --> 00:10:01,040
managers

00:09:57,440 --> 00:10:04,160
like kubernetes and also docker now

00:10:01,040 --> 00:10:07,040
um and then let's move to

00:10:04,160 --> 00:10:08,880
class managers that we can choose from

00:10:07,040 --> 00:10:12,720
uh the first i will talk

00:10:08,880 --> 00:10:15,760
more about later is google kubernetes

00:10:12,720 --> 00:10:18,800
and the others uh described now uh

00:10:15,760 --> 00:10:21,920
the the second one is core s fleet

00:10:18,800 --> 00:10:23,760
so uh fleet is actually a cluster

00:10:21,920 --> 00:10:28,160
manager that's managing

00:10:23,760 --> 00:10:28,640
uh system d services across the cluster

00:10:28,160 --> 00:10:32,240
it's

00:10:28,640 --> 00:10:32,720
uh it was actually i think develop

00:10:32,240 --> 00:10:36,399
before

00:10:32,720 --> 00:10:40,560
uh docker was you know so popular

00:10:36,399 --> 00:10:44,000
uh so but it's not so much

00:10:40,560 --> 00:10:45,279
uh developed now so um it's really nice

00:10:44,000 --> 00:10:48,560
because you can spawn

00:10:45,279 --> 00:10:51,839
on system day services

00:10:48,560 --> 00:10:56,320
across the cluster and also on

00:10:51,839 --> 00:10:56,320
probably nix nixos could use it

00:10:57,200 --> 00:11:03,680
the third one is docker swar swarm so

00:11:00,560 --> 00:11:04,959
um so docker is usually running as a

00:11:03,680 --> 00:11:08,240
single service

00:11:04,959 --> 00:11:09,519
that that manages your containers on a

00:11:08,240 --> 00:11:15,040
single house but

00:11:09,519 --> 00:11:18,560
if you use dockers forum it actually um

00:11:15,040 --> 00:11:20,640
distributes uh

00:11:18,560 --> 00:11:21,839
containers to many different nodes that

00:11:20,640 --> 00:11:24,079
are connected to

00:11:21,839 --> 00:11:24,880
to it so it actually exposes the same

00:11:24,079 --> 00:11:28,399
api

00:11:24,880 --> 00:11:31,839
api as um docker but uh

00:11:28,399 --> 00:11:36,160
but it can communicate with many

00:11:31,839 --> 00:11:39,120
machines and then you have um

00:11:36,160 --> 00:11:40,000
do actually docu is not here a class

00:11:39,120 --> 00:11:42,800
manager it's

00:11:40,000 --> 00:11:42,800
but i still

00:11:43,040 --> 00:11:48,720
put it on the list it's actually um

00:11:46,320 --> 00:11:51,200
like an open source heroku written in

00:11:48,720 --> 00:11:54,079
bash and it's

00:11:51,200 --> 00:11:54,800
it's really nice if you want to deploy

00:11:54,079 --> 00:11:58,000
something

00:11:54,800 --> 00:11:59,680
simple application um and then the last

00:11:58,000 --> 00:12:03,120
we have rancher

00:11:59,680 --> 00:12:03,920
uh rancher is a solution on on its own

00:12:03,120 --> 00:12:07,440
it's actually

00:12:03,920 --> 00:12:10,480
also using docker and it's actually

00:12:07,440 --> 00:12:13,519
providing its own overlay networking

00:12:10,480 --> 00:12:16,720
they they have pretty nice ui but

00:12:13,519 --> 00:12:17,920
i actually spoke with the guys from

00:12:16,720 --> 00:12:21,040
ancient and asked

00:12:17,920 --> 00:12:22,800
if because their solution could only be

00:12:21,040 --> 00:12:24,560
start from docker and then they

00:12:22,800 --> 00:12:28,240
provision everything

00:12:24,560 --> 00:12:31,279
and i asked them if uh if they could

00:12:28,240 --> 00:12:34,399
like provide an instructions how to

00:12:31,279 --> 00:12:36,800
to deploy it separately on the machines

00:12:34,399 --> 00:12:38,079
and they don't have this implant right

00:12:36,800 --> 00:12:40,160
now so

00:12:38,079 --> 00:12:42,320
but it would be really nice to see you

00:12:40,160 --> 00:12:46,399
rancher

00:12:42,320 --> 00:12:47,040
what um yeah maybe i forgot about mesos

00:12:46,399 --> 00:12:49,440
here yeah

00:12:47,040 --> 00:12:49,440
also

00:12:50,480 --> 00:12:58,000
yeah um mesos actually

00:12:53,760 --> 00:13:00,880
um but mesos mesos

00:12:58,000 --> 00:13:01,680
is actually also a class manager that

00:13:00,880 --> 00:13:04,959
can

00:13:01,680 --> 00:13:08,959
work with spawning

00:13:04,959 --> 00:13:12,320
not only containers but processes

00:13:08,959 --> 00:13:15,360
among the cluster and

00:13:12,320 --> 00:13:16,880
but it doesn't have built-in like

00:13:15,360 --> 00:13:19,680
support for networking

00:13:16,880 --> 00:13:20,959
and storage and stuff like that but it's

00:13:19,680 --> 00:13:23,279
uh

00:13:20,959 --> 00:13:24,240
it's really nice distributed scheduler

00:13:23,279 --> 00:13:26,880
it's uh

00:13:24,240 --> 00:13:28,160
and for example what would be nice to

00:13:26,880 --> 00:13:30,800
see is for example

00:13:28,160 --> 00:13:32,959
for hydra task for example use measures

00:13:30,800 --> 00:13:35,279
that's one

00:13:32,959 --> 00:13:36,720
nice just case because all other cluster

00:13:35,279 --> 00:13:38,800
managers are more for running

00:13:36,720 --> 00:13:39,920
applications but for example mesos is

00:13:38,800 --> 00:13:44,720
more for lining

00:13:39,920 --> 00:13:46,160
like i would say tasks but it can

00:13:44,720 --> 00:13:47,839
be used for different things but you

00:13:46,160 --> 00:13:48,480
have many more available here on this

00:13:47,839 --> 00:13:50,880
link

00:13:48,480 --> 00:13:52,160
it's actually if you google how to run

00:13:50,880 --> 00:13:53,920
how to scale docker

00:13:52,160 --> 00:13:56,079
containers in production you find the

00:13:53,920 --> 00:14:00,800
long lists of

00:13:56,079 --> 00:14:00,800
these solutions okay

00:14:01,040 --> 00:14:06,880
okay so now let's talk let's see

00:14:04,240 --> 00:14:09,839
something about docker and nyx

00:14:06,880 --> 00:14:10,639
um so docker is primarily used for

00:14:09,839 --> 00:14:14,480
running

00:14:10,639 --> 00:14:16,399
application other whole distros um

00:14:14,480 --> 00:14:17,839
and of course running knicks inside

00:14:16,399 --> 00:14:21,360
docker is easy

00:14:17,839 --> 00:14:24,639
a few benefits here we have compared to

00:14:21,360 --> 00:14:25,199
other docker images is that you can pick

00:14:24,639 --> 00:14:27,920
the

00:14:25,199 --> 00:14:28,959
exact version of nics and exact versions

00:14:27,920 --> 00:14:32,320
of packages

00:14:28,959 --> 00:14:35,600
because for example um

00:14:32,320 --> 00:14:37,360
if you if you use some other images like

00:14:35,600 --> 00:14:38,240
i don't know debian or ubuntu you can

00:14:37,360 --> 00:14:41,519
just

00:14:38,240 --> 00:14:45,440
select the which

00:14:41,519 --> 00:14:48,880
which review revision of this

00:14:45,440 --> 00:14:51,360
use and here you can actually pick the

00:14:48,880 --> 00:14:52,720
the commit you want like of course you

00:14:51,360 --> 00:14:55,760
can add a channel and then

00:14:52,720 --> 00:14:56,880
install whatever you want and yeah it's

00:14:55,760 --> 00:15:00,560
really simple we

00:14:56,880 --> 00:15:00,560
uh i just uh

00:15:00,959 --> 00:15:04,880
i actually just pushed a new nyx nyx

00:15:03,519 --> 00:15:08,079
image for nyx

00:15:04,880 --> 00:15:10,720
110 and

00:15:08,079 --> 00:15:12,240
so you can pretty much easily make a

00:15:10,720 --> 00:15:16,240
docker image

00:15:12,240 --> 00:15:16,240
and run it so

00:15:18,880 --> 00:15:23,440
you can try this yourself i will not

00:15:20,720 --> 00:15:23,440
turn this now

00:15:23,839 --> 00:15:30,320
oh okay this slide

00:15:27,360 --> 00:15:32,639
so what about running nexus in docker as

00:15:30,320 --> 00:15:34,800
i said

00:15:32,639 --> 00:15:38,560
actually you can run xos inside of

00:15:34,800 --> 00:15:41,839
containers use the privileged mode

00:15:38,560 --> 00:15:44,720
but you actually don't want to do that

00:15:41,839 --> 00:15:45,440
um because docker was not meant for that

00:15:44,720 --> 00:15:48,399
and

00:15:45,440 --> 00:15:49,759
um that's actually moral for if you want

00:15:48,399 --> 00:15:53,040
to like

00:15:49,759 --> 00:15:56,720
test uh or develop a nexus and

00:15:53,040 --> 00:15:56,720
you wouldn't do this in production

00:15:57,360 --> 00:16:01,839
now working i was working on service

00:16:00,160 --> 00:16:03,839
abstraction layer that would actually

00:16:01,839 --> 00:16:06,959
abstract the services

00:16:03,839 --> 00:16:08,959
and provide a way to run uh

00:16:06,959 --> 00:16:10,399
that you would be able to make like an

00:16:08,959 --> 00:16:13,519
excise config

00:16:10,399 --> 00:16:15,680
and then build uh and then

00:16:13,519 --> 00:16:16,800
make a separate container for every

00:16:15,680 --> 00:16:19,120
service

00:16:16,800 --> 00:16:19,839
and uh running this on cluster but

00:16:19,120 --> 00:16:22,320
currently

00:16:19,839 --> 00:16:24,639
i have different things to do so it's

00:16:22,320 --> 00:16:28,560
not in my priority list

00:16:24,639 --> 00:16:30,079
but i think it

00:16:28,560 --> 00:16:32,240
it would be a nice thing to do to

00:16:30,079 --> 00:16:34,720
actually separate services from excise

00:16:32,240 --> 00:16:38,000
because nixa is currently

00:16:34,720 --> 00:16:42,320
quite monolithic uh

00:16:38,000 --> 00:16:42,320
system that um

00:16:45,920 --> 00:16:52,560
so now now let's go

00:16:48,959 --> 00:16:54,320
to kubernetes um it's actually open

00:16:52,560 --> 00:16:57,360
sourced and announced by google

00:16:54,320 --> 00:17:01,440
in 2014 and influenced by

00:16:57,360 --> 00:17:05,760
google's book system it's written in go

00:17:01,440 --> 00:17:07,760
um like actually most of these things

00:17:05,760 --> 00:17:09,280
i showed you before is they are like

00:17:07,760 --> 00:17:12,319
written in go

00:17:09,280 --> 00:17:16,400
so um because

00:17:12,319 --> 00:17:19,679
uh mainly because goa allows to actually

00:17:16,400 --> 00:17:22,880
pretty easily build static uh

00:17:19,679 --> 00:17:25,439
static binaries and distribute them any

00:17:22,880 --> 00:17:26,480
and anywhere so that's also a google's

00:17:25,439 --> 00:17:30,840
approach

00:17:26,480 --> 00:17:34,720
currently how they're deploying stuff

00:17:30,840 --> 00:17:37,280
um so kubernetes uses docker

00:17:34,720 --> 00:17:38,960
us primary process manager but also has

00:17:37,280 --> 00:17:41,440
support for rocket

00:17:38,960 --> 00:17:43,120
so you can make a rocket image and run

00:17:41,440 --> 00:17:46,320
it in systemd

00:17:43,120 --> 00:17:50,480
and i think garbage was also

00:17:46,320 --> 00:17:52,960
working on making uh also wrote

00:17:50,480 --> 00:17:54,640
an article how to build a rocket image

00:17:52,960 --> 00:17:58,840
so maybe we could try and

00:17:54,640 --> 00:18:02,240
run it with kubernetes so

00:17:58,840 --> 00:18:05,200
um kubernetes has

00:18:02,240 --> 00:18:07,039
a lot of commits i would say a lot of

00:18:05,200 --> 00:18:09,360
contributors

00:18:07,039 --> 00:18:10,799
uh because mainly because it's supported

00:18:09,360 --> 00:18:14,080
by google and

00:18:10,799 --> 00:18:18,160
um it's currently for

00:18:14,080 --> 00:18:21,280
a pretty long time in stable release

00:18:18,160 --> 00:18:24,480
from the summer somewhere

00:18:21,280 --> 00:18:26,320
um so what does

00:18:24,480 --> 00:18:27,679
kubernetes provide it provides

00:18:26,320 --> 00:18:30,640
replication

00:18:27,679 --> 00:18:30,640
so um

00:18:31,200 --> 00:18:35,039
it actually manages docker containers

00:18:33,200 --> 00:18:37,039
across multiple machines

00:18:35,039 --> 00:18:39,039
it provides slow balancing so it has

00:18:37,039 --> 00:18:42,240
built-in load balancer

00:18:39,039 --> 00:18:44,240
um that that

00:18:42,240 --> 00:18:46,400
balances traffic across all the

00:18:44,240 --> 00:18:49,919
replicated services

00:18:46,400 --> 00:18:52,320
um it

00:18:49,919 --> 00:18:53,280
integrates with distributed storage just

00:18:52,320 --> 00:18:56,400
like ebs

00:18:53,280 --> 00:18:59,360
safe cluster fs nfs now

00:18:56,400 --> 00:19:01,039
the added support for this fiber file

00:18:59,360 --> 00:19:05,760
system

00:19:01,039 --> 00:19:08,799
um and there are also some other

00:19:05,760 --> 00:19:10,240
story just like git and secret storage

00:19:08,799 --> 00:19:14,000
so you can put secrets

00:19:10,240 --> 00:19:14,320
and stuff like that um it has supports

00:19:14,000 --> 00:19:17,520
for

00:19:14,320 --> 00:19:20,160
resource quota so you can say okay this

00:19:17,520 --> 00:19:21,360
uh this process i i only allow this

00:19:20,160 --> 00:19:23,120
process to take

00:19:21,360 --> 00:19:25,039
this much of ram and this much of

00:19:23,120 --> 00:19:27,919
processing power

00:19:25,039 --> 00:19:29,360
it has built-in support for logging and

00:19:27,919 --> 00:19:32,160
monitoring

00:19:29,360 --> 00:19:33,120
and it has a declarative configuration

00:19:32,160 --> 00:19:39,840
for

00:19:33,120 --> 00:19:39,840
us for uh actually for everything

00:19:40,240 --> 00:19:47,440
so kubernetes consists of many

00:19:44,240 --> 00:19:51,120
components and these are separated

00:19:47,440 --> 00:19:53,120
in microservices and

00:19:51,120 --> 00:19:54,400
here is the description of them though

00:19:53,120 --> 00:19:58,160
the first one is

00:19:54,400 --> 00:20:01,440
happy server it's http uh

00:19:58,160 --> 00:20:03,919
api service uh that with

00:20:01,440 --> 00:20:05,360
on which you connect and control uh

00:20:03,919 --> 00:20:08,159
kubernetes

00:20:05,360 --> 00:20:08,640
and the changes they made are applied by

00:20:08,159 --> 00:20:11,679
control

00:20:08,640 --> 00:20:14,720
manager um

00:20:11,679 --> 00:20:17,360
scheduler kubernetes scheduler schedule

00:20:14,720 --> 00:20:17,360
resources

00:20:17,840 --> 00:20:22,480
resources like servers so it decides

00:20:20,400 --> 00:20:25,600
where to put some containers

00:20:22,480 --> 00:20:28,880
and uh and

00:20:25,600 --> 00:20:32,320
to and it also now has support for

00:20:28,880 --> 00:20:34,320
allocating storage so we have if you

00:20:32,320 --> 00:20:36,960
have a bullet storage it

00:20:34,320 --> 00:20:38,159
it can't allocate it but it currently

00:20:36,960 --> 00:20:41,760
this only works on

00:20:38,159 --> 00:20:44,000
in google cloud uh then it has

00:20:41,760 --> 00:20:45,520
a proxy service it's like load balancing

00:20:44,000 --> 00:20:49,200
proxy across

00:20:45,520 --> 00:20:52,400
uh for um all the services

00:20:49,200 --> 00:20:56,080
we expose and it of course has

00:20:52,400 --> 00:20:59,120
uh this uh uh

00:20:56,080 --> 00:21:02,559
cubelet that's actually running the

00:20:59,120 --> 00:21:02,559
containers themselves so

00:21:03,200 --> 00:21:06,480
it's it manages containers and reports

00:21:05,679 --> 00:21:09,600
on

00:21:06,480 --> 00:21:12,480
on containers okay so

00:21:09,600 --> 00:21:14,240
here's the the schema so usually around

00:21:12,480 --> 00:21:16,559
one master with

00:21:14,240 --> 00:21:18,880
on which you have the applied uh api

00:21:16,559 --> 00:21:20,720
server scheduler control manager

00:21:18,880 --> 00:21:23,120
okay we have also here hipster it's

00:21:20,720 --> 00:21:27,440
actually a monitoring service

00:21:23,120 --> 00:21:29,679
for all uh for all these things um

00:21:27,440 --> 00:21:30,640
and then then you have many uh they

00:21:29,679 --> 00:21:33,520
called minions

00:21:30,640 --> 00:21:35,039
so many worker nodes where you have this

00:21:33,520 --> 00:21:38,400
key proxy that

00:21:35,039 --> 00:21:40,080
for load balancing uh cubelet for

00:21:38,400 --> 00:21:43,840
running services and also

00:21:40,080 --> 00:21:44,559
a dns service so they also integrate

00:21:43,840 --> 00:21:47,600
with this

00:21:44,559 --> 00:21:50,720
dns called sky dns that provides

00:21:47,600 --> 00:21:51,600
dns service for all the applications you

00:21:50,720 --> 00:21:54,640
run

00:21:51,600 --> 00:21:58,000
on kubernetes uh

00:21:54,640 --> 00:22:01,440
okay now my about some terms they use

00:21:58,000 --> 00:22:02,880
so namespace is a separate group for

00:22:01,440 --> 00:22:05,360
parts replication controls

00:22:02,880 --> 00:22:06,000
services so you can have like for

00:22:05,360 --> 00:22:08,799
example

00:22:06,000 --> 00:22:10,559
development and production namespace it

00:22:08,799 --> 00:22:11,520
actually doesn't provide a physical

00:22:10,559 --> 00:22:16,000
separation

00:22:11,520 --> 00:22:20,080
between uh containers themselves

00:22:16,000 --> 00:22:20,080
um it only provides uh

00:22:20,320 --> 00:22:24,400
logical one so for example one container

00:22:23,440 --> 00:22:28,240
can still

00:22:24,400 --> 00:22:31,600
communicate with other container if

00:22:28,240 --> 00:22:32,240
but you can actually write your own

00:22:31,600 --> 00:22:35,360
firewall

00:22:32,240 --> 00:22:37,760
plug-in that that would prevent this

00:22:35,360 --> 00:22:39,520
then there is a minion that's a worker

00:22:37,760 --> 00:22:42,640
node a pot

00:22:39,520 --> 00:22:43,039
uh they in a docker world you usually

00:22:42,640 --> 00:22:46,159
want

00:22:43,039 --> 00:22:49,360
around one container and then you

00:22:46,159 --> 00:22:53,120
can attach multiple containers together

00:22:49,360 --> 00:22:56,159
here actually you can run a set of

00:22:53,120 --> 00:22:58,480
containers on a single host and they

00:22:56,159 --> 00:23:00,080
actually share the same networking

00:22:58,480 --> 00:23:03,440
namespace so

00:23:00,080 --> 00:23:05,120
um that's that's pretty nice and they

00:23:03,440 --> 00:23:09,280
actually can share the file system

00:23:05,120 --> 00:23:12,400
between these containers

00:23:09,280 --> 00:23:14,320
then you have replication controller

00:23:12,400 --> 00:23:16,159
replication controller is a controller

00:23:14,320 --> 00:23:19,280
for for

00:23:16,159 --> 00:23:23,039
group of parts so you can say um

00:23:19,280 --> 00:23:26,159
okay i want to to deploy this

00:23:23,039 --> 00:23:29,440
these parts and i want to

00:23:26,159 --> 00:23:32,720
make this many replicas

00:23:29,440 --> 00:23:34,159
so it and

00:23:32,720 --> 00:23:36,400
and you define this in replication

00:23:34,159 --> 00:23:39,360
control we will see example later

00:23:36,400 --> 00:23:41,520
and then a service is a load balancer

00:23:39,360 --> 00:23:45,600
for a group of pots

00:23:41,520 --> 00:23:50,720
it's running on kubernetes

00:23:45,600 --> 00:23:56,000
okay so maybe let's make a demo

00:23:50,720 --> 00:23:56,000
okay so what we will do here is actually

00:23:56,720 --> 00:24:00,320
we will deploy on

00:24:00,559 --> 00:24:07,120
it doesn't show everything yeah

00:24:03,600 --> 00:24:09,120
okay it's okay uh so we will deploy

00:24:07,120 --> 00:24:10,240
uh here we have our application

00:24:09,120 --> 00:24:13,360
controller

00:24:10,240 --> 00:24:19,360
so um what we will make here is

00:24:13,360 --> 00:24:22,720
uh we will deploy two nginx containers

00:24:19,360 --> 00:24:22,720
no that's

00:24:23,120 --> 00:24:33,840
okay so let's do this

00:24:34,960 --> 00:24:39,520
okay so i i actually already have this

00:24:38,240 --> 00:24:41,840
deployed but i can

00:24:39,520 --> 00:24:41,840
um

00:24:42,640 --> 00:24:45,760
okay now first let's get replication

00:24:45,279 --> 00:24:47,440
control

00:24:45,760 --> 00:24:49,760
so we already can see that we have

00:24:47,440 --> 00:24:53,520
replication controller with

00:24:49,760 --> 00:24:53,520
of engine x with two replicas

00:24:54,080 --> 00:25:04,960
but we can delete this

00:25:01,520 --> 00:25:08,159
okay so it now deleted

00:25:04,960 --> 00:25:11,360
our application controller

00:25:08,159 --> 00:25:14,159
we can see that now and now we

00:25:11,360 --> 00:25:16,320
made create with this file we have on

00:25:14,159 --> 00:25:18,559
the top

00:25:16,320 --> 00:25:18,559
it's

00:25:20,559 --> 00:25:23,919
nginx controller

00:25:26,400 --> 00:25:30,159
okay so now we can see it's running fun

00:25:28,799 --> 00:25:31,919
replication controller in this

00:25:30,159 --> 00:25:32,960
replication controller it's running two

00:25:31,919 --> 00:25:35,200
parts

00:25:32,960 --> 00:25:36,799
one is one it has already started the

00:25:35,200 --> 00:25:40,840
other is

00:25:36,799 --> 00:25:44,559
almost started so now both are running

00:25:40,840 --> 00:25:45,279
um yeah actually maybe if i'm just my

00:25:44,559 --> 00:25:49,600
curl

00:25:45,279 --> 00:25:52,880
it would be just fine uh so it

00:25:49,600 --> 00:25:56,080
because i said these are exposed by dns

00:25:52,880 --> 00:25:59,520
so i can just make uh

00:25:56,080 --> 00:26:01,120
curl like nginx oh yeah

00:25:59,520 --> 00:26:02,640
i forget something we also have a

00:26:01,120 --> 00:26:06,240
service we also have to

00:26:02,640 --> 00:26:09,679
expose this so i already have

00:26:06,240 --> 00:26:12,480
a service available but i can delete it

00:26:09,679 --> 00:26:12,480
of course and

00:26:12,880 --> 00:26:16,320
nginx service

00:26:16,799 --> 00:26:22,080
and i can actually go to the next slide

00:26:18,960 --> 00:26:22,080
that shows the service

00:26:23,360 --> 00:26:32,080
so here is um maybe just describe this

00:26:29,279 --> 00:26:32,559
so here we have a service uh that's uh

00:26:32,080 --> 00:26:36,480
that

00:26:32,559 --> 00:26:39,120
selects all the um

00:26:36,480 --> 00:26:40,480
all the parts there that have label app

00:26:39,120 --> 00:26:44,000
engine x

00:26:40,480 --> 00:26:48,080
and it exposes port 8000

00:26:44,000 --> 00:26:52,480
um and target ports

00:26:48,080 --> 00:26:56,799
on the container is port 80.

00:26:52,480 --> 00:26:56,799
um so let's do this

00:27:01,679 --> 00:27:08,240
okay now we have service available

00:27:05,120 --> 00:27:11,679
it has it's ip dedicated

00:27:08,240 --> 00:27:11,679
uh so um

00:27:11,760 --> 00:27:17,360
it's every machine has to have

00:27:17,520 --> 00:27:22,559
ip space for for this services and for

00:27:21,360 --> 00:27:25,760
parts again

00:27:22,559 --> 00:27:29,200
now let's do this curl

00:27:25,760 --> 00:27:35,840
engine x service

00:27:29,200 --> 00:27:38,080
we got the food

00:27:35,840 --> 00:27:38,080
ah

00:27:42,799 --> 00:27:49,840
come on in just a second

00:27:51,200 --> 00:27:57,760
probably i have dns problems

00:27:54,559 --> 00:28:01,679
yeah i actually

00:27:57,760 --> 00:28:04,960
usually have different dns server

00:28:01,679 --> 00:28:04,960
let's see if now works

00:28:06,320 --> 00:28:11,520
no still not working

00:28:15,039 --> 00:28:17,840
what

00:28:18,640 --> 00:28:21,039
oh yeah

00:28:22,159 --> 00:28:27,440
oh yeah the different part yeah it's a

00:28:24,960 --> 00:28:31,039
wrong port it's 8080.

00:28:27,440 --> 00:28:34,640
thanks 80 000

00:28:31,039 --> 00:28:36,559
oh yeah so here is nginx responsing

00:28:34,640 --> 00:28:37,919
and it's loud balancing between these

00:28:36,559 --> 00:28:40,960
two pods that are

00:28:37,919 --> 00:28:44,799
running uh if you would have

00:28:40,960 --> 00:28:48,159
multiple machines it would uh run this

00:28:44,799 --> 00:28:49,360
uh uh these spots across multiple

00:28:48,159 --> 00:28:51,360
machines so it load

00:28:49,360 --> 00:28:52,640
so it provisioned them on different

00:28:51,360 --> 00:28:56,559
machines

00:28:52,640 --> 00:28:59,039
um that's what

00:28:56,559 --> 00:29:01,360
scheduler does okay and of course here

00:28:59,039 --> 00:29:03,840
we have some additional commands

00:29:01,360 --> 00:29:05,840
we can also have a get the logs of the

00:29:03,840 --> 00:29:06,559
of containers running in our classroom

00:29:05,840 --> 00:29:10,960
we can

00:29:06,559 --> 00:29:12,559
access some comment inside container and

00:29:10,960 --> 00:29:16,399
also have a shell

00:29:12,559 --> 00:29:16,399
to this container but

00:29:17,600 --> 00:29:21,520
okay now now about running kubernetes on

00:29:20,399 --> 00:29:25,120
excess

00:29:21,520 --> 00:29:28,320
uh i created an excess model

00:29:25,120 --> 00:29:29,919
and it says is deployed in production

00:29:28,320 --> 00:29:32,240
for longer period of time

00:29:29,919 --> 00:29:33,039
i actually been testing this for uh

00:29:32,240 --> 00:29:36,840
quite a long

00:29:33,039 --> 00:29:39,840
of time i think from version of

00:29:36,840 --> 00:29:43,440
0.6 and now it's uh

00:29:39,840 --> 00:29:46,480
now we have version 1 1.0

00:29:43,440 --> 00:29:50,320
so actually not the latest uh

00:29:46,480 --> 00:29:52,880
stable release which is 1.1 but

00:29:50,320 --> 00:29:54,320
um that's also what of most other

00:29:52,880 --> 00:29:57,600
distros have

00:29:54,320 --> 00:29:58,080
and it's actually to to actually deploy

00:29:57,600 --> 00:30:00,159
it

00:29:58,080 --> 00:30:01,679
it's actually just a few lines of nik

00:30:00,159 --> 00:30:03,520
size config

00:30:01,679 --> 00:30:05,200
so what you have to do it's like make a

00:30:03,520 --> 00:30:08,799
bridge interface

00:30:05,200 --> 00:30:13,200
you have to make to make this your

00:30:08,799 --> 00:30:17,200
server to be a rose of master and note

00:30:13,200 --> 00:30:19,840
and to actually just define the docker

00:30:17,200 --> 00:30:22,080
where on which interface that it should

00:30:19,840 --> 00:30:25,679
use this interface so in that case

00:30:22,080 --> 00:30:27,520
cbr0 interface so

00:30:25,679 --> 00:30:29,200
you here don't you don't see enable

00:30:27,520 --> 00:30:31,840
that's because

00:30:29,200 --> 00:30:33,279
with these roles you already defined

00:30:31,840 --> 00:30:36,880
that each

00:30:33,279 --> 00:30:39,039
kind of should be enabled but

00:30:36,880 --> 00:30:41,200
i will probably change this so you you

00:30:39,039 --> 00:30:42,720
will have to explicitly enable it but

00:30:41,200 --> 00:30:45,760
currently

00:30:42,720 --> 00:30:48,640
you just define of rows

00:30:45,760 --> 00:30:50,080
of services uh you can all of course

00:30:48,640 --> 00:30:53,039
also enable the

00:30:50,080 --> 00:30:53,600
the different components separately this

00:30:53,039 --> 00:30:56,000
is just

00:30:53,600 --> 00:30:58,080
a shortcut with these dot roles very

00:30:56,000 --> 00:31:05,840
defined master and

00:30:58,080 --> 00:31:05,840
and note

00:31:06,399 --> 00:31:11,360
um so but that's running only on a

00:31:09,760 --> 00:31:14,799
single note

00:31:11,360 --> 00:31:16,960
um for production environments we need

00:31:14,799 --> 00:31:18,320
at least a list cluster of three

00:31:16,960 --> 00:31:22,559
machines

00:31:18,320 --> 00:31:27,120
uh and one of which has to be a

00:31:22,559 --> 00:31:30,840
master and also minion also also worker

00:31:27,120 --> 00:31:32,080
and that's because usually in production

00:31:30,840 --> 00:31:35,519
um uh

00:31:32,080 --> 00:31:37,519
uh kubernetes depends on etcd

00:31:35,519 --> 00:31:38,799
uh it is it is this configuration

00:31:37,519 --> 00:31:42,080
storage and if we

00:31:38,799 --> 00:31:46,480
if we want to run it reliably we uh

00:31:42,080 --> 00:31:48,720
have to to have a quorum of

00:31:46,480 --> 00:31:49,840
uh to be at least two of three machines

00:31:48,720 --> 00:31:53,679
running

00:31:49,840 --> 00:31:56,640
uh so that three machines kind of make

00:31:53,679 --> 00:31:57,840
a cluster um that you can run in

00:31:56,640 --> 00:32:00,240
production

00:31:57,840 --> 00:32:02,480
and you also of course need to have an

00:32:00,240 --> 00:32:04,880
overlaid network thing so these machines

00:32:02,480 --> 00:32:06,320
have to be connected somehow and have

00:32:04,880 --> 00:32:08,080
rootable subnets so actually in

00:32:06,320 --> 00:32:10,399
kubernetes every machine

00:32:08,080 --> 00:32:10,399
gets

00:32:11,279 --> 00:32:18,559
gets its own subnet and um

00:32:14,320 --> 00:32:19,600
and so services that are deployed on

00:32:18,559 --> 00:32:22,720
different machines can

00:32:19,600 --> 00:32:25,600
talk together and

00:32:22,720 --> 00:32:27,120
have different ips that are routable to

00:32:25,600 --> 00:32:30,159
different servers based

00:32:27,120 --> 00:32:33,519
on ips uh

00:32:30,159 --> 00:32:37,440
so in our case on github we do it

00:32:33,519 --> 00:32:41,679
on amazon avs instances

00:32:37,440 --> 00:32:44,159
uh and we have virtual private cloud

00:32:41,679 --> 00:32:45,440
and on top of that virtual private cloud

00:32:44,159 --> 00:32:48,640
we are running

00:32:45,440 --> 00:32:51,679
uh open we switch

00:32:48,640 --> 00:32:54,960
connected with ipsec because

00:32:51,679 --> 00:32:59,200
because we don't just run

00:32:54,960 --> 00:33:02,320
instances on amazon but also in hetzner

00:32:59,200 --> 00:33:04,240
uh and with head start because we are

00:33:02,320 --> 00:33:06,399
communicating over the internet we need

00:33:04,240 --> 00:33:08,559
some kind of secure communication then

00:33:06,399 --> 00:33:12,399
that's because

00:33:08,559 --> 00:33:15,120
that's why we have uh ipsec links

00:33:12,399 --> 00:33:16,000
um yeah then we uh deployment is with

00:33:15,120 --> 00:33:19,120
mix-ups

00:33:16,000 --> 00:33:22,000
uh elastic box storage

00:33:19,120 --> 00:33:23,279
uh and then we have separated production

00:33:22,000 --> 00:33:26,960
and development namespace

00:33:23,279 --> 00:33:28,799
and here is a just high level overview

00:33:26,960 --> 00:33:32,000
how it looks like

00:33:28,799 --> 00:33:34,559
um so a couple of minions uh

00:33:32,000 --> 00:33:35,919
connected and then we have amazon amazon

00:33:34,559 --> 00:33:38,480
load balancer

00:33:35,919 --> 00:33:39,760
that slow balancing the traffic to or to

00:33:38,480 --> 00:33:43,519
these servers and

00:33:39,760 --> 00:33:46,559
open v switch overlay networking

00:33:43,519 --> 00:33:49,039
uh connecting all these instances uh

00:33:46,559 --> 00:33:51,440
maybe just a bit about monitoring we use

00:33:49,039 --> 00:33:54,720
collector for metric segregation

00:33:51,440 --> 00:33:56,000
inflexible for matrix storage grafana

00:33:54,720 --> 00:33:59,760
dashboard

00:33:56,000 --> 00:34:04,399
dashboard for metrics visualization

00:33:59,760 --> 00:34:06,000
bassoon for alerting app as it says

00:34:04,399 --> 00:34:08,320
it's actually we are currently using

00:34:06,000 --> 00:34:11,599
bassoon for alerting because

00:34:08,320 --> 00:34:13,200
uh there is i haven't found any better

00:34:11,599 --> 00:34:16,159
component but

00:34:13,200 --> 00:34:18,000
grafana will get in an extra least

00:34:16,159 --> 00:34:19,599
support for alerting so this would be

00:34:18,000 --> 00:34:21,839
really nice because then you

00:34:19,599 --> 00:34:24,240
we just have to run influx double

00:34:21,839 --> 00:34:27,760
grafana and some a

00:34:24,240 --> 00:34:31,599
service like collector that that

00:34:27,760 --> 00:34:31,599
collects the locks and

00:34:32,079 --> 00:34:38,639
that would be it um configuration

00:34:36,240 --> 00:34:39,359
actually i will not show how to deploy a

00:34:38,639 --> 00:34:42,399
multi

00:34:39,359 --> 00:34:45,520
um how to deploy cluster now but

00:34:42,399 --> 00:34:47,839
actually i have opens i have

00:34:45,520 --> 00:34:48,800
available set of profiles so you can

00:34:47,839 --> 00:34:52,079
include this

00:34:48,800 --> 00:34:52,800
into your nexus configuration and i have

00:34:52,079 --> 00:34:56,480
something like

00:34:52,800 --> 00:34:58,960
profiles dot kubernetes dot enable true

00:34:56,480 --> 00:35:00,800
and for example profiles dot open we

00:34:58,960 --> 00:35:04,480
switch enable true and it will

00:35:00,800 --> 00:35:07,040
um and with a bit of options you

00:35:04,480 --> 00:35:09,200
or you pretty simple configural system

00:35:07,040 --> 00:35:13,040
why i don't want to use bear

00:35:09,200 --> 00:35:15,760
on nexus config because um i reuse this

00:35:13,040 --> 00:35:17,760
um this configuration in in different

00:35:15,760 --> 00:35:21,839
deployments so

00:35:17,760 --> 00:35:25,599
and i don't want to duplicate my code so

00:35:21,839 --> 00:35:28,839
i have a valid set of profiles um

00:35:25,599 --> 00:35:31,280
that i can reuse in different

00:35:28,839 --> 00:35:32,160
deployments but of course and it's still

00:35:31,280 --> 00:35:36,800
a better

00:35:32,160 --> 00:35:39,839
documentation so

00:35:36,800 --> 00:35:45,040
that that's about it

00:35:39,839 --> 00:35:45,040
um i think it's already time right

00:35:45,200 --> 00:35:59,839
for questions thank you

00:36:08,880 --> 00:36:16,000
um so so you do

00:36:12,720 --> 00:36:19,680
at which point when you deploy to

00:36:16,000 --> 00:36:20,160
um when you build images docker images

00:36:19,680 --> 00:36:23,280
right

00:36:20,160 --> 00:36:24,079
yeah but yeah when you build docker

00:36:23,280 --> 00:36:27,760
images

00:36:24,079 --> 00:36:30,560
um you insert you include the whole

00:36:27,760 --> 00:36:31,280
closure uh inside the image so they can

00:36:30,560 --> 00:36:34,320
be

00:36:31,280 --> 00:36:37,839
moved around yeah currently but

00:36:34,320 --> 00:36:38,800
but we are working on on having

00:36:37,839 --> 00:36:41,680
distributed

00:36:38,800 --> 00:36:42,560
like next storage which is mounted and

00:36:41,680 --> 00:36:46,320
across yeah that

00:36:42,560 --> 00:36:49,440
that's an idea but we are not there yet

00:36:46,320 --> 00:36:52,240
but yeah that's that's the idea and this

00:36:49,440 --> 00:36:55,040
would be really awesome man

00:36:52,240 --> 00:36:55,520
okay i just don't for me it's like

00:36:55,040 --> 00:36:57,760
really

00:36:55,520 --> 00:36:59,599
you really need a big scale to uh

00:36:57,760 --> 00:37:01,440
benefit from all this big setup like you

00:36:59,599 --> 00:37:04,800
need to really have a good problem

00:37:01,440 --> 00:37:08,560
to solve this to have this big setup

00:37:04,800 --> 00:37:12,160
i mean just uh i mean for us

00:37:08,560 --> 00:37:12,160
it's easier because

00:37:12,320 --> 00:37:18,640
what's the size we are running around 10

00:37:15,520 --> 00:37:22,560
amazon instances around

00:37:18,640 --> 00:37:24,800
20 micro services replicated

00:37:22,560 --> 00:37:26,640
and then we also have like support

00:37:24,800 --> 00:37:30,000
services like gitlab

00:37:26,640 --> 00:37:30,000
like sentry like

00:37:30,880 --> 00:37:38,400
and graffana elasticsearch

00:37:34,960 --> 00:37:41,520
a lot of stuff so and actually if

00:37:38,400 --> 00:37:43,359
if i would have to deploy all this by i

00:37:41,520 --> 00:37:46,240
actually for example gitlab

00:37:43,359 --> 00:37:50,480
is just deployed with with image

00:37:46,240 --> 00:37:53,359
available on docker hub because

00:37:50,480 --> 00:37:53,920
because this was much easier quicker way

00:37:53,359 --> 00:37:56,079
so

00:37:53,920 --> 00:37:57,920
it this setup actually enables you to

00:37:56,079 --> 00:38:00,960
run nick

00:37:57,920 --> 00:38:04,000
nick services and also the other

00:38:00,960 --> 00:38:07,280
and and it enables us to

00:38:04,000 --> 00:38:10,640
later scale or replace it with a full

00:38:07,280 --> 00:38:10,640
nik setup so

00:38:13,520 --> 00:38:17,760
i'm just curious on that topic with the

00:38:15,839 --> 00:38:18,240
copying the closures into the other

00:38:17,760 --> 00:38:20,400
containers

00:38:18,240 --> 00:38:21,760
how big you know are you seeing your

00:38:20,400 --> 00:38:23,280
your containers

00:38:21,760 --> 00:38:24,800
being like you know for your nginx

00:38:23,280 --> 00:38:28,560
container for example

00:38:24,800 --> 00:38:32,160
oh nginx um i don't know how

00:38:28,560 --> 00:38:35,599
how big is it it's uh it's it's

00:38:32,160 --> 00:38:38,640
it's an exclosure size plus

00:38:35,599 --> 00:38:42,720
a few 10 megabytes maybe so it's it's

00:38:38,640 --> 00:38:45,680
it's not it's not a big container uh

00:38:42,720 --> 00:38:47,680
the bigger problems are other services

00:38:45,680 --> 00:38:48,720
for example we have a lot of node.js

00:38:47,680 --> 00:38:51,920
packages

00:38:48,720 --> 00:38:53,920
that could be really big in size so

00:38:51,920 --> 00:38:55,839
if they have a lot of dependencies this

00:38:53,920 --> 00:38:57,520
becomes has that ever been

00:38:55,839 --> 00:39:00,240
a problem in actuality or is it just

00:38:57,520 --> 00:39:03,280
kind of a um

00:39:00,240 --> 00:39:06,400
actually we had uh uh

00:39:03,280 --> 00:39:09,839
we had problems with storage uh because

00:39:06,400 --> 00:39:12,960
uh uh because when we updated

00:39:09,839 --> 00:39:16,400
it we uh

00:39:12,960 --> 00:39:19,440
if we yeah if you updated it

00:39:16,400 --> 00:39:20,800
and for example especially for node

00:39:19,440 --> 00:39:24,000
packages

00:39:20,800 --> 00:39:25,280
uh if you updated the docker docker file

00:39:24,000 --> 00:39:29,119
docker description file

00:39:25,280 --> 00:39:31,359
and you update the version it will

00:39:29,119 --> 00:39:33,359
rebuild the whole image with all

00:39:31,359 --> 00:39:34,240
dependencies and it will be a different

00:39:33,359 --> 00:39:36,960
hash

00:39:34,240 --> 00:39:38,960
and then you you have a lot of if you

00:39:36,960 --> 00:39:41,599
have a lot of updates

00:39:38,960 --> 00:39:43,200
it will just fill the disk space so now

00:39:41,599 --> 00:39:45,200
we actually have a garbage collector

00:39:43,200 --> 00:39:48,720
that runs every day and cleans the

00:39:45,200 --> 00:39:51,680
all docker images so it is a problem in

00:39:48,720 --> 00:39:52,000
like distributed storage with onix would

00:39:51,680 --> 00:39:57,839
be

00:39:52,000 --> 00:39:57,839
a really nice solution here

00:40:12,000 --> 00:40:16,240
can you tell a little bit more about how

00:40:14,000 --> 00:40:18,960
the vpn works or the

00:40:16,240 --> 00:40:20,160
about open fee switch the how open we

00:40:18,960 --> 00:40:23,119
switch between

00:40:20,160 --> 00:40:25,760
amazon and head snare and stuff oh so

00:40:23,119 --> 00:40:29,040
openly switches

00:40:25,760 --> 00:40:32,560
virtualized a switch that uh

00:40:29,040 --> 00:40:34,880
it's integrated uh i mean

00:40:32,560 --> 00:40:36,079
some other it's integrated in linux

00:40:34,880 --> 00:40:38,240
kernel

00:40:36,079 --> 00:40:40,720
so what it actually provides is to

00:40:38,240 --> 00:40:44,560
actually to simply create

00:40:40,720 --> 00:40:47,520
uh uh virtualized networking

00:40:44,560 --> 00:40:48,319
but so we could say software-defined

00:40:47,520 --> 00:40:50,560
networking

00:40:48,319 --> 00:40:51,440
between machines we are not using all

00:40:50,560 --> 00:40:54,800
the features

00:40:51,440 --> 00:40:56,480
of it but it provided us with actually

00:40:54,800 --> 00:40:59,040
not so easy setup of

00:40:56,480 --> 00:41:00,240
uh encrypted tunnels we could also

00:40:59,040 --> 00:41:04,000
probably use

00:41:00,240 --> 00:41:07,119
just jury tunnels so it's like

00:41:04,000 --> 00:41:08,880
and uh ipsec integrated directly in

00:41:07,119 --> 00:41:11,040
linux but

00:41:08,880 --> 00:41:12,880
i actually decided to use openwe switch

00:41:11,040 --> 00:41:16,720
because it

00:41:12,880 --> 00:41:16,720
kind of uh uh

00:41:16,880 --> 00:41:20,480
it has better support for our routing we

00:41:19,599 --> 00:41:23,520
could do

00:41:20,480 --> 00:41:23,920
firewalling in some sense with it so we

00:41:23,520 --> 00:41:26,240
can

00:41:23,920 --> 00:41:28,160
actually limit communication between

00:41:26,240 --> 00:41:32,839
different containers

00:41:28,160 --> 00:41:35,839
uh in a cluster so in that sense openly

00:41:32,839 --> 00:41:35,839
switch

00:41:43,920 --> 00:41:47,520
okay and the configuration between the

00:41:45,760 --> 00:41:50,079
different servers

00:41:47,520 --> 00:41:51,839
is that manual or currently yeah

00:41:50,079 --> 00:41:54,640
currently currently we have

00:41:51,839 --> 00:41:57,200
we deploy uh the configuration it's

00:41:54,640 --> 00:42:00,480
static it's generated by

00:41:57,200 --> 00:42:02,640
by nixops so when i deploy it and if i

00:42:00,480 --> 00:42:04,720
add another server actually it

00:42:02,640 --> 00:42:08,000
reconfigures or

00:42:04,720 --> 00:42:09,760
all all of all the other servers to

00:42:08,000 --> 00:42:11,359
provide this mesh networking between

00:42:09,760 --> 00:42:13,839
machines okay cool

00:42:11,359 --> 00:42:16,160
so we need a better solution to actually

00:42:13,839 --> 00:42:17,839
be able to spin up servers just without

00:42:16,160 --> 00:42:20,240
mix-ups

00:42:17,839 --> 00:42:20,240
because

00:42:28,640 --> 00:42:31,839

YouTube URL: https://www.youtube.com/watch?v=1UTO9Sf4GPQ


