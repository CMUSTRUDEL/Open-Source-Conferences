Title: LoneStarRuby Conf 2013 - Asynchronous Workers to the Resque
Publication date: 2020-01-28
Playlist: Lone Star Ruby Conf 2013
Description: 
	By Dave Kapp 

While Ruby is a terrific language, it doesn't offer a lot of ways to deal with asynchronous tasks using the default libraries. Thankfully, the community has come up with several great options for bringing asynchronicity to your applications. Resque is one of the forerunners of this, and it offers a lot of functionality and flexibility with an easily approachable API. Here, we'll go over several techniques for utilizing asynchronous workers to benefit your projects.

We'll start off with a review of how asynchronous processing works, and then we'll delve into three different things you can use Resque for: speeding up your applications by processing slow operations on the side, performing sequential updates with pipelining, and performing periodic maintenance tasks. We'll go over example code for how to handle these different situations and ideas for how to integrate them with existing applications.

While the examples will be given using Resque, the ideas and patterns discussed will be applicable to other worker queues, such as delayed_job and Sidekiq.

Help us caption & translate this video!

http://amara.org/v/FG8l/
Captions: 
	00:00:15,670 --> 00:00:22,070
all right hello everyone my name is

00:00:18,500 --> 00:00:24,279
David cap I am a cat video aficionado

00:00:22,070 --> 00:00:28,130
who moonlights as a software developer I

00:00:24,279 --> 00:00:30,039
work for cosh X labs which is a company

00:00:28,130 --> 00:00:32,840
based out of Charlottesville Virginia I

00:00:30,039 --> 00:00:34,820
used to work in the boulder colorado

00:00:32,840 --> 00:00:37,010
office of the company i moved to austin

00:00:34,820 --> 00:00:38,690
about a year ago and so i'm the only

00:00:37,010 --> 00:00:41,390
person from the company currently in

00:00:38,690 --> 00:00:42,680
austin having been in austin for about

00:00:41,390 --> 00:00:44,330
one year I've been here longer than

00:00:42,680 --> 00:00:49,550
two-thirds of the population which I'm

00:00:44,330 --> 00:00:50,870
very happy about say i really enjoy the

00:00:49,550 --> 00:00:54,410
tech scene year so i'm happy to be a

00:00:50,870 --> 00:00:56,210
part of it and i gave a talk on an

00:00:54,410 --> 00:00:58,910
introduction to asynchronous workers at

00:00:56,210 --> 00:01:00,530
railsconf this year and they were kind

00:00:58,910 --> 00:01:02,870
enough to invite me to give a follow-up

00:01:00,530 --> 00:01:04,990
talk on some patterns of asynchronous

00:01:02,870 --> 00:01:07,399
worker use in a little bit of details on

00:01:04,990 --> 00:01:09,770
some ways to deal with the concurrency

00:01:07,399 --> 00:01:11,149
problems that can come up and so that is

00:01:09,770 --> 00:01:13,250
what I'm going to speak about today I

00:01:11,149 --> 00:01:14,960
have a reasonably large amount of

00:01:13,250 --> 00:01:17,030
material and I will try and watch the

00:01:14,960 --> 00:01:20,090
time as closely as I can to allow for

00:01:17,030 --> 00:01:22,430
some questions but concurrent processing

00:01:20,090 --> 00:01:23,780
and parallel processing our large fields

00:01:22,430 --> 00:01:26,630
and it's going to be difficult for me to

00:01:23,780 --> 00:01:28,280
cover a whole lot of material in half an

00:01:26,630 --> 00:01:32,810
hour but I hope to cover as much as I

00:01:28,280 --> 00:01:36,290
possibly can so asynchronous workers to

00:01:32,810 --> 00:01:37,759
the rescue parallelism patterns so I

00:01:36,290 --> 00:01:39,259
have some good news in case you haven't

00:01:37,759 --> 00:01:41,390
heard it you might have heard that Ruby

00:01:39,259 --> 00:01:43,670
2 point 0 has come out which is great

00:01:41,390 --> 00:01:45,680
and I'm sure that many of you are

00:01:43,670 --> 00:01:47,060
extremely happy about this I know I was

00:01:45,680 --> 00:01:49,850
very happy because there are some great

00:01:47,060 --> 00:01:51,439
improvements in Ruby too however there's

00:01:49,850 --> 00:01:53,600
some of you whose dreams were not

00:01:51,439 --> 00:01:55,100
fulfilled by Ruby 2 point 0 because

00:01:53,600 --> 00:01:57,200
there is still a global interpreter lock

00:01:55,100 --> 00:01:58,460
and those people might have been a

00:01:57,200 --> 00:02:00,229
little bit disciplined in the release

00:01:58,460 --> 00:02:02,240
but it doesn't sound like the gill is

00:02:00,229 --> 00:02:03,439
going to be going away anytime soon it's

00:02:02,240 --> 00:02:05,719
something that we're going to have to

00:02:03,439 --> 00:02:09,019
deal with an MRI I'm if you're on JRuby

00:02:05,719 --> 00:02:10,700
or the latest builds of Rubinius this is

00:02:09,019 --> 00:02:12,769
a different case but an MRI it's still

00:02:10,700 --> 00:02:14,299
around and I would like to encourage

00:02:12,769 --> 00:02:16,519
everyone to calm down you can see the

00:02:14,299 --> 00:02:19,160
mass panic that ensued in the room when

00:02:16,519 --> 00:02:20,480
I mention that fact and there the truth

00:02:19,160 --> 00:02:22,160
is there are still options for

00:02:20,480 --> 00:02:25,880
parallelism and Ruby even when you're on

00:02:22,160 --> 00:02:27,199
MRI and it's also true that some

00:02:25,880 --> 00:02:28,220
traditional parallel programming

00:02:27,199 --> 00:02:30,590
techniques don't real

00:02:28,220 --> 00:02:32,720
I work well with Ruby you may or may not

00:02:30,590 --> 00:02:34,490
be familiar with the way the MRI works

00:02:32,720 --> 00:02:37,220
or what the global interpreter lock is

00:02:34,490 --> 00:02:39,230
the Gil global interpreter lock is

00:02:37,220 --> 00:02:41,780
something that prevents more than one

00:02:39,230 --> 00:02:44,420
thread within a single MRI process from

00:02:41,780 --> 00:02:46,970
running code at the same time that is

00:02:44,420 --> 00:02:49,190
ruby has true native threads now but it

00:02:46,970 --> 00:02:52,340
cannot actually execute more than one of

00:02:49,190 --> 00:02:54,140
them at once Python has the same setup

00:02:52,340 --> 00:02:58,310
many languages have it it's not

00:02:54,140 --> 00:03:00,620
something unique to Ruby and when you're

00:02:58,310 --> 00:03:02,150
doing an HTTP request response oriented

00:03:00,620 --> 00:03:04,760
system which i'm guessing many of you

00:03:02,150 --> 00:03:08,360
are rails is the thing that has brought

00:03:04,760 --> 00:03:11,209
commercial fame and fortune to ruby when

00:03:08,360 --> 00:03:12,830
you're doing dealing with that a lot of

00:03:11,209 --> 00:03:14,990
what you're doing probably does have

00:03:12,830 --> 00:03:16,940
some form of parallelism in the fact

00:03:14,990 --> 00:03:18,980
that you're running multiple processes

00:03:16,940 --> 00:03:20,780
on your servers I don't know too many

00:03:18,980 --> 00:03:23,300
people who are in production only run in

00:03:20,780 --> 00:03:26,830
a single instance of passenger or puma

00:03:23,300 --> 00:03:30,080
or unicorn or rainbows or what have you

00:03:26,830 --> 00:03:31,580
so the basic idea of parallel processing

00:03:30,080 --> 00:03:33,620
if you're not familiar with it is that

00:03:31,580 --> 00:03:34,850
you have a big problem problem that's so

00:03:33,620 --> 00:03:36,920
big you don't want to do it all at once

00:03:34,850 --> 00:03:39,110
so you take that problem you break it

00:03:36,920 --> 00:03:41,090
into small pieces you work on each of

00:03:39,110 --> 00:03:43,670
those pieces separately and then after

00:03:41,090 --> 00:03:44,959
you've taken those individual pieces you

00:03:43,670 --> 00:03:47,480
put them back together and you either

00:03:44,959 --> 00:03:50,209
construct or reconstruct that solution

00:03:47,480 --> 00:03:51,800
depending on your point of view it's

00:03:50,209 --> 00:03:52,940
really like solving a puzzle you have

00:03:51,800 --> 00:03:54,769
all these different pieces that

00:03:52,940 --> 00:03:56,269
represent that represent an aggregate

00:03:54,769 --> 00:03:59,450
solution you have to get it back into

00:03:56,269 --> 00:04:01,340
one there's really nothing this Ruby

00:03:59,450 --> 00:04:02,840
specific about that idea parallel

00:04:01,340 --> 00:04:04,430
processing has been around much longer

00:04:02,840 --> 00:04:06,380
than the Ruby language itself and

00:04:04,430 --> 00:04:08,180
there's more than one way to approach

00:04:06,380 --> 00:04:10,820
parallel ISM in pretty much every

00:04:08,180 --> 00:04:12,620
language some languages have language

00:04:10,820 --> 00:04:17,000
level features to support it other

00:04:12,620 --> 00:04:18,530
languages do not and here the approach

00:04:17,000 --> 00:04:20,330
that we're going to be discussing

00:04:18,530 --> 00:04:22,100
asynchronous workers is an approach that

00:04:20,330 --> 00:04:26,600
really does work very nicely with Ruby

00:04:22,100 --> 00:04:29,660
multiple flavors of Ruby so asynchronous

00:04:26,600 --> 00:04:31,940
workers have many ways that they can be

00:04:29,660 --> 00:04:33,800
used they're more of a tool that can be

00:04:31,940 --> 00:04:35,570
applied in different ways to different

00:04:33,800 --> 00:04:37,280
situations I'd like to talk about three

00:04:35,570 --> 00:04:39,349
main techniques or patterns of using

00:04:37,280 --> 00:04:41,930
them and those will be isolating slow

00:04:39,349 --> 00:04:46,460
activities pipeline to processing

00:04:41,930 --> 00:04:47,960
and periodic maintenance tasks and I

00:04:46,460 --> 00:04:49,340
would also like to mention an aside if

00:04:47,960 --> 00:04:51,110
you're not familiar with asynchronous

00:04:49,340 --> 00:04:53,240
workers or why you might care about them

00:04:51,110 --> 00:04:55,070
there's a few reasons whether a good

00:04:53,240 --> 00:04:57,500
approach to this sort of problem in with

00:04:55,070 --> 00:04:59,660
Ruby and that is they're very flexible

00:04:57,500 --> 00:05:00,979
there's a lot of different ways that can

00:04:59,660 --> 00:05:02,870
be used and they offer you a lot of

00:05:00,979 --> 00:05:04,580
choices on the way you want to apply

00:05:02,870 --> 00:05:07,580
their processing techniques to a given

00:05:04,580 --> 00:05:09,199
problem there are several Ruby libraries

00:05:07,580 --> 00:05:11,660
on which I'll mention my name in just a

00:05:09,199 --> 00:05:13,789
moment that are very mature and they

00:05:11,660 --> 00:05:16,070
have got a lot of battle testing and

00:05:13,789 --> 00:05:18,560
even the most recent of them sidekick is

00:05:16,070 --> 00:05:19,789
quite stable so you have a choice of

00:05:18,560 --> 00:05:23,780
many different things that you could

00:05:19,789 --> 00:05:25,460
work with they do not rely on threads or

00:05:23,780 --> 00:05:28,220
fibers or the global interpreter lock

00:05:25,460 --> 00:05:31,070
being there or not being there so that

00:05:28,220 --> 00:05:33,289
is they work with MRI they work with

00:05:31,070 --> 00:05:34,699
JRuby they overthrew Ben eous and there

00:05:33,289 --> 00:05:36,620
are a few other Ruby libraries out there

00:05:34,699 --> 00:05:39,919
but odds are you're not actually using

00:05:36,620 --> 00:05:41,570
them in production they are relatively

00:05:39,919 --> 00:05:42,979
easy to work with and the reason I like

00:05:41,570 --> 00:05:44,630
them so much is because you can actually

00:05:42,979 --> 00:05:46,840
use them to avoid a lot of the

00:05:44,630 --> 00:05:50,000
traditional concurrency problems

00:05:46,840 --> 00:05:51,830
concurrency is hard and when I can get

00:05:50,000 --> 00:05:53,599
the benefits of parallel processing and

00:05:51,830 --> 00:05:54,979
plug my ears and say la la la none of

00:05:53,599 --> 00:05:58,729
these other problems exist it makes my

00:05:54,979 --> 00:06:01,430
life easier and you can think of them as

00:05:58,729 --> 00:06:03,500
a primitive to compose complex solutions

00:06:01,430 --> 00:06:06,860
and that goes in hand with the flexible

00:06:03,500 --> 00:06:08,570
part you can use them in many ways now

00:06:06,860 --> 00:06:10,699
that might be a bit of a controversial

00:06:08,570 --> 00:06:11,870
statement you have parallel processing

00:06:10,699 --> 00:06:13,909
in which you don't have to do with

00:06:11,870 --> 00:06:16,220
concurrency issues doesn't that sound

00:06:13,909 --> 00:06:19,699
implausibly good and the truth is yes it

00:06:16,220 --> 00:06:22,009
does you can't rely on them to magically

00:06:19,699 --> 00:06:24,289
solve your problems however you can use

00:06:22,009 --> 00:06:26,530
them in a manner that will allow you to

00:06:24,289 --> 00:06:31,940
ignore many of the traditional problems

00:06:26,530 --> 00:06:33,830
and with all these libraries you run

00:06:31,940 --> 00:06:36,919
into different situations and different

00:06:33,830 --> 00:06:41,690
choices but the patterns of use apply to

00:06:36,919 --> 00:06:44,090
all of them so upfront before we start

00:06:41,690 --> 00:06:46,280
talking about the different patterns I'd

00:06:44,090 --> 00:06:49,039
like to just mention to best practices

00:06:46,280 --> 00:06:51,110
that will save you a lot of sanity and a

00:06:49,039 --> 00:06:52,849
lot of swearing and these are in my

00:06:51,110 --> 00:06:54,349
opinion the two best things you can do

00:06:52,849 --> 00:06:56,919
with asynchronous workers to avoid

00:06:54,349 --> 00:06:56,919
concurrency

00:06:57,039 --> 00:07:02,599
number one is a concept called shared

00:07:00,830 --> 00:07:05,330
nothing and I believe I stole this

00:07:02,599 --> 00:07:07,249
terminology from closure in which they

00:07:05,330 --> 00:07:09,889
like to use the term the idea of shared

00:07:07,249 --> 00:07:12,289
nothing is that you do not actually have

00:07:09,889 --> 00:07:14,769
anything in terms of state or in terms

00:07:12,289 --> 00:07:18,319
of objects that are shared across things

00:07:14,769 --> 00:07:20,539
so even if you are working with the same

00:07:18,319 --> 00:07:23,330
domain models or the same database

00:07:20,539 --> 00:07:24,619
back-end you do not share the specific

00:07:23,330 --> 00:07:26,949
things you're working on across

00:07:24,619 --> 00:07:32,959
asynchronous workers across threads

00:07:26,949 --> 00:07:34,729
anything like that them yes the less

00:07:32,959 --> 00:07:36,409
that you can share between these things

00:07:34,729 --> 00:07:38,089
the better off you'll be and that is

00:07:36,409 --> 00:07:39,319
because the less you are sharing the

00:07:38,089 --> 00:07:42,499
less you have to worry about these

00:07:39,319 --> 00:07:44,719
concurrency problems and next is having

00:07:42,499 --> 00:07:46,429
your jobs be ad impotent I've also heard

00:07:44,719 --> 00:07:48,469
this pronounced item potent if anyone

00:07:46,429 --> 00:07:50,149
can provide me with strong evidence one

00:07:48,469 --> 00:07:51,349
of these pronunciations is correct that

00:07:50,149 --> 00:07:55,339
would be great i can't actually

00:07:51,349 --> 00:07:58,519
determine that and i would like to give

00:07:55,339 --> 00:08:00,169
in addendum on that that is there are

00:07:58,519 --> 00:08:01,550
things that you can't do this to if

00:08:00,169 --> 00:08:04,699
you're not familiar with the idea of

00:08:01,550 --> 00:08:07,009
being idempotent that is that you have

00:08:04,699 --> 00:08:09,919
something that even if it is repeated

00:08:07,009 --> 00:08:12,110
you will not change your state the most

00:08:09,919 --> 00:08:14,149
common example of this is using an ATM

00:08:12,110 --> 00:08:16,490
you want something to be an idempotent

00:08:14,149 --> 00:08:18,139
transaction there because if you have to

00:08:16,490 --> 00:08:20,539
repeat something that is the initial

00:08:18,139 --> 00:08:22,639
application fails and has to be played

00:08:20,539 --> 00:08:24,139
back from a log the person's account

00:08:22,639 --> 00:08:26,959
does not end up with a different amount

00:08:24,139 --> 00:08:28,789
of money this doesn't really apply to

00:08:26,959 --> 00:08:30,889
all situations and there are cases where

00:08:28,789 --> 00:08:32,060
you can't do that I'm a simple example

00:08:30,889 --> 00:08:35,060
is when you deal with things based on

00:08:32,060 --> 00:08:37,099
time if you have a function such as time

00:08:35,060 --> 00:08:39,019
now and you call that in multiple places

00:08:37,099 --> 00:08:40,849
it's not going to return the same thing

00:08:39,019 --> 00:08:42,050
unless you're using time cup and

00:08:40,849 --> 00:08:44,720
production in which case you've also

00:08:42,050 --> 00:08:46,490
probably got some other problems so

00:08:44,720 --> 00:08:47,930
something simply can't be made item

00:08:46,490 --> 00:08:49,430
potent and if you're working in a

00:08:47,930 --> 00:08:50,779
language like Haskell you would have to

00:08:49,430 --> 00:08:52,100
use monads to work around that issue

00:08:50,779 --> 00:08:53,600
thankfully I don't have to do that in

00:08:52,100 --> 00:08:55,370
Ruby and Ruby you just have to keep in

00:08:53,600 --> 00:08:56,810
mind that you are going to be working

00:08:55,370 --> 00:09:00,350
with something that's not item potent

00:08:56,810 --> 00:09:02,240
and again some things may seem item

00:09:00,350 --> 00:09:03,620
potent and it's difficult to come to an

00:09:02,240 --> 00:09:05,870
actual consensus because it's not

00:09:03,620 --> 00:09:08,240
necessarily a scientific term when we're

00:09:05,870 --> 00:09:09,020
dealing with business applications when

00:09:08,240 --> 00:09:11,030
your deal with Matt

00:09:09,020 --> 00:09:12,950
addicts it is a separate thing things

00:09:11,030 --> 00:09:16,040
can easily be proven to be idempotent or

00:09:12,950 --> 00:09:20,170
not however when you're dealing with an

00:09:16,040 --> 00:09:23,240
application it often is difficult to say

00:09:20,170 --> 00:09:26,030
so my suggestion for is even if you

00:09:23,240 --> 00:09:28,070
can't get true item potency aim for

00:09:26,030 --> 00:09:30,080
understood failure that is you know

00:09:28,070 --> 00:09:33,050
exactly what will happen if something

00:09:30,080 --> 00:09:35,390
does fail and minimal impact if repeated

00:09:33,050 --> 00:09:36,650
so you want to try and get the benefits

00:09:35,390 --> 00:09:40,070
of item potency even if you don't have a

00:09:36,650 --> 00:09:42,040
true idempotent transaction there's this

00:09:40,070 --> 00:09:44,180
concept of referential transparency

00:09:42,040 --> 00:09:45,470
which is a great term because it makes

00:09:44,180 --> 00:09:48,470
you sound really intelligent when you

00:09:45,470 --> 00:09:49,760
say it and what it means in it's a term

00:09:48,470 --> 00:09:53,030
that comes from functional programming

00:09:49,760 --> 00:09:55,370
it means the output of a function will

00:09:53,030 --> 00:09:58,070
always be the same given the same

00:09:55,370 --> 00:10:00,620
parameters if you have a function called

00:09:58,070 --> 00:10:02,780
add to and it adds to to the number you

00:10:00,620 --> 00:10:04,480
pass in you can very easily prove that

00:10:02,780 --> 00:10:06,980
that has a referential transparency

00:10:04,480 --> 00:10:09,380
given the same number it will always

00:10:06,980 --> 00:10:11,480
return the same value this is something

00:10:09,380 --> 00:10:13,130
to strive for because again when you're

00:10:11,480 --> 00:10:15,650
dealing with business applications it

00:10:13,130 --> 00:10:17,510
may not actually be possible and I'm not

00:10:15,650 --> 00:10:19,730
really a fan of the term business logic

00:10:17,510 --> 00:10:21,680
or business application I'm just using

00:10:19,730 --> 00:10:23,480
it as a general term for something that

00:10:21,680 --> 00:10:28,790
is going to be doing practical rather

00:10:23,480 --> 00:10:30,980
than purely mathematical work you can

00:10:28,790 --> 00:10:33,890
apply this idea to asynchronous workers

00:10:30,980 --> 00:10:35,840
so I would like to call that referential

00:10:33,890 --> 00:10:37,430
II transparent workers which might sound

00:10:35,840 --> 00:10:39,860
like a bit of a mouthful but what I mean

00:10:37,430 --> 00:10:42,790
with that is you should aim to have

00:10:39,860 --> 00:10:45,080
workers that when the job is executed

00:10:42,790 --> 00:10:47,710
you know that it's going to produce the

00:10:45,080 --> 00:10:50,090
same result given the same input and

00:10:47,710 --> 00:10:52,250
that will make the behavior of your

00:10:50,090 --> 00:10:53,870
asynchronous jobs more consistent and

00:10:52,250 --> 00:10:56,810
more composable and more easily

00:10:53,870 --> 00:10:58,840
understandable so yes let's go back to

00:10:56,810 --> 00:11:00,860
the whole idea of asynchronous workers

00:10:58,840 --> 00:11:02,000
I'd like to define them just a little

00:11:00,860 --> 00:11:04,420
bit more in case you're not familiar

00:11:02,000 --> 00:11:07,190
with the term and asynchronous worker is

00:11:04,420 --> 00:11:10,370
something that is a separate process

00:11:07,190 --> 00:11:12,290
from the rest of your application since

00:11:10,370 --> 00:11:14,030
I'm going to be giving some examples

00:11:12,290 --> 00:11:15,590
using rails because that composes the

00:11:14,030 --> 00:11:17,750
majority of the work that a lot of

00:11:15,590 --> 00:11:20,120
people do but the same ideas apply to

00:11:17,750 --> 00:11:21,830
using other servers if you're on Sinatra

00:11:20,120 --> 00:11:22,610
or one of the others or if you're doing

00:11:21,830 --> 00:11:26,540
an application that

00:11:22,610 --> 00:11:28,220
not web-based regardless an asynchronous

00:11:26,540 --> 00:11:31,519
worker is separate from the rest of your

00:11:28,220 --> 00:11:34,730
application it is something that reads

00:11:31,519 --> 00:11:37,670
data from a specified place and it

00:11:34,730 --> 00:11:39,709
processes it in some way and it will

00:11:37,670 --> 00:11:43,640
periodically pull this data source to

00:11:39,709 --> 00:11:45,829
see if there is more to do it may or may

00:11:43,640 --> 00:11:47,269
not be actually pulling sometimes it'll

00:11:45,829 --> 00:11:49,880
get notifications in a different manner

00:11:47,269 --> 00:11:53,079
but it is generally pulling rather than

00:11:49,880 --> 00:11:56,660
getting events from the OS I the OS

00:11:53,079 --> 00:11:58,790
there are three main libraries for

00:11:56,660 --> 00:12:00,440
asynchronous workers in Ruby they are

00:11:58,790 --> 00:12:03,110
rescue which is the one the examples

00:12:00,440 --> 00:12:05,990
here are going to be in sidekick which

00:12:03,110 --> 00:12:07,640
was originally made to be API compatible

00:12:05,990 --> 00:12:09,950
with rescue but it uses a different

00:12:07,640 --> 00:12:12,560
model for managing multiple jobs at the

00:12:09,950 --> 00:12:14,839
same time and delayed job which is one

00:12:12,560 --> 00:12:18,320
that instead of using Redis as the data

00:12:14,839 --> 00:12:20,360
back end uses an SQL database I would

00:12:18,320 --> 00:12:22,120
encourage you to pick the one that is

00:12:20,360 --> 00:12:24,290
the best for your project there's no

00:12:22,120 --> 00:12:25,760
guaranteed statement that this is the

00:12:24,290 --> 00:12:28,279
right thing that you should be using and

00:12:25,760 --> 00:12:29,540
the others are wrong I wish I could tell

00:12:28,279 --> 00:12:32,570
you that one is always better than the

00:12:29,540 --> 00:12:34,100
others but it's not that simple one

00:12:32,570 --> 00:12:35,390
thing that may influence your decision

00:12:34,100 --> 00:12:37,790
greatly is if you have to have things

00:12:35,390 --> 00:12:39,410
run on windows I believe the only one of

00:12:37,790 --> 00:12:43,029
these that can run on windows is delayed

00:12:39,410 --> 00:12:46,490
job I would may be wrong on that but

00:12:43,029 --> 00:12:48,620
that may influence your decision so

00:12:46,490 --> 00:12:50,390
again I am going to give examples with

00:12:48,620 --> 00:12:52,339
rescue but please do give some thought

00:12:50,390 --> 00:12:54,589
don't simply pick up rescue and say this

00:12:52,339 --> 00:12:57,709
is the one because i have given the

00:12:54,589 --> 00:12:59,930
examples using it you may have heard

00:12:57,709 --> 00:13:03,230
someone use the term asynchronous worker

00:12:59,930 --> 00:13:04,490
queue and that is not necessarily

00:13:03,230 --> 00:13:08,269
indicative of how they're going to

00:13:04,490 --> 00:13:10,220
behave it's simply that on a conceptual

00:13:08,269 --> 00:13:12,470
level they operate as though they are

00:13:10,220 --> 00:13:17,480
reading from a data queue the back end

00:13:12,470 --> 00:13:18,860
may or may not actually be a queue you

00:13:17,480 --> 00:13:21,920
simply can think of it as a place where

00:13:18,860 --> 00:13:25,430
the jobs are in q2 and will be dq'd from

00:13:21,920 --> 00:13:27,110
when their data is read and here's a

00:13:25,430 --> 00:13:28,640
friendly warning just in case you're

00:13:27,110 --> 00:13:30,529
thinking about using JRuby for an

00:13:28,640 --> 00:13:32,209
upcoming project and you're thinking

00:13:30,529 --> 00:13:33,740
that you're going to use sidekick and

00:13:32,209 --> 00:13:35,839
you have the JVM and you can sidestep

00:13:33,740 --> 00:13:36,230
the global interpreter lock so you can

00:13:35,839 --> 00:13:37,910
do also

00:13:36,230 --> 00:13:40,490
sorts of neat stuff inside your worker

00:13:37,910 --> 00:13:43,550
processes I will recommend you read this

00:13:40,490 --> 00:13:46,610
as an article called Ruby core classes

00:13:43,550 --> 00:13:49,280
aren't thread safe it will save you a

00:13:46,610 --> 00:13:50,720
lot of frustration and I will make these

00:13:49,280 --> 00:13:52,160
slides available so that you can

00:13:50,720 --> 00:13:54,680
actually click the link instead of just

00:13:52,160 --> 00:13:56,720
staring at it uh-huh it is an excellent

00:13:54,680 --> 00:13:58,460
article and I would highly recommend you

00:13:56,720 --> 00:14:01,730
familiarize yourself with the contents

00:13:58,460 --> 00:14:04,190
of it if you are using JRuby so let's go

00:14:01,730 --> 00:14:05,720
on to the first of the three patterns

00:14:04,190 --> 00:14:07,370
we're going to discuss and that is how

00:14:05,720 --> 00:14:09,320
to banish slow things so they do not

00:14:07,370 --> 00:14:11,630
bother you anymore or at least banish

00:14:09,320 --> 00:14:12,800
them into an asynchronous worker job so

00:14:11,630 --> 00:14:16,520
that they will not bother your main

00:14:12,800 --> 00:14:19,040
application applications sometimes have

00:14:16,520 --> 00:14:21,080
to do things that are slow this is

00:14:19,040 --> 00:14:23,000
sometimes due to the necessity of the

00:14:21,080 --> 00:14:26,210
complexity of the calculations you're

00:14:23,000 --> 00:14:29,360
doing or it may in many cases for us be

00:14:26,210 --> 00:14:31,460
a slow API call you have to make if you

00:14:29,360 --> 00:14:33,800
have an API called it takes 15 seconds

00:14:31,460 --> 00:14:35,720
no amount of algorithmic improvements on

00:14:33,800 --> 00:14:37,840
your side will actually change the fact

00:14:35,720 --> 00:14:40,940
that the other server is still slow and

00:14:37,840 --> 00:14:43,040
I bet if you asked users of your

00:14:40,940 --> 00:14:44,630
application if they enjoy clicking on

00:14:43,040 --> 00:14:46,280
things and having to wait 15 plus

00:14:44,630 --> 00:14:47,690
seconds for a response you will

00:14:46,280 --> 00:14:50,990
overwhelmingly find that they are not

00:14:47,690 --> 00:14:53,390
interested in that lady so even if you

00:14:50,990 --> 00:14:55,880
try and apply changes to make the rest

00:14:53,390 --> 00:14:57,800
of the things they're faster you're only

00:14:55,880 --> 00:14:59,360
incrementally increasing the speed and

00:14:57,800 --> 00:15:02,360
not really dealing if the true problem

00:14:59,360 --> 00:15:04,790
what you need to do is deal with it a

00:15:02,360 --> 00:15:08,030
different way that is HTTP request time

00:15:04,790 --> 00:15:10,790
is different something that is slow for

00:15:08,030 --> 00:15:13,280
an HTTP request response cycle is

00:15:10,790 --> 00:15:15,470
different than something to be slow were

00:15:13,280 --> 00:15:18,200
you doing some sort of giant batch data

00:15:15,470 --> 00:15:19,760
processing job on a mainframe if you

00:15:18,200 --> 00:15:22,460
have an HTTP request that takes it a

00:15:19,760 --> 00:15:24,320
minute that's really just as bad as a 15

00:15:22,460 --> 00:15:26,060
minute one your users aren't going to

00:15:24,320 --> 00:15:27,410
put up with it and most browsers aren't

00:15:26,060 --> 00:15:29,900
really your allow you to actually wait

00:15:27,410 --> 00:15:31,460
that long so you need to do is change

00:15:29,900 --> 00:15:33,440
the architecture of your application a

00:15:31,460 --> 00:15:35,090
little bit you need to take that thing

00:15:33,440 --> 00:15:37,970
that's really slow and take it out of

00:15:35,090 --> 00:15:39,860
the request response cycle the same idea

00:15:37,970 --> 00:15:42,830
here applies to doing things such as

00:15:39,860 --> 00:15:44,390
drawing graphics on an event loop if you

00:15:42,830 --> 00:15:45,860
do any iOS development you may be

00:15:44,390 --> 00:15:47,930
familiar with how you're no longer you

00:15:45,860 --> 00:15:49,139
are not supposed to do drawing to the

00:15:47,930 --> 00:15:50,429
screen on the main

00:15:49,139 --> 00:15:52,559
that loop and that is so you're not

00:15:50,429 --> 00:15:55,290
holding up everything else that applies

00:15:52,559 --> 00:15:56,549
to the rails request response loop where

00:15:55,290 --> 00:15:58,290
you don't want to hold up everything

00:15:56,549 --> 00:16:02,279
because you're taking a long time to

00:15:58,290 --> 00:16:03,749
process a single HTTP response so you're

00:16:02,279 --> 00:16:04,949
probably wondering released I hope

00:16:03,749 --> 00:16:06,689
you're wondering how does an

00:16:04,949 --> 00:16:10,709
asynchronous worker actually help me

00:16:06,689 --> 00:16:13,499
deal with this slow stuff what you are

00:16:10,709 --> 00:16:15,779
doing is asynchronous call to something

00:16:13,499 --> 00:16:18,480
that is slow that means you cannot move

00:16:15,779 --> 00:16:20,369
forward until it is done what you want

00:16:18,480 --> 00:16:22,589
is this to be asynchronous you want it

00:16:20,369 --> 00:16:24,149
to start that is you want the processing

00:16:22,589 --> 00:16:26,699
to actually begin but you want to keep

00:16:24,149 --> 00:16:29,160
going on without it and by doing so

00:16:26,699 --> 00:16:31,709
achieve a form of parallel processing in

00:16:29,160 --> 00:16:33,359
which your application will still have

00:16:31,709 --> 00:16:36,299
the other work done but it is not being

00:16:33,359 --> 00:16:38,879
held up so what we want out of

00:16:36,299 --> 00:16:40,790
asynchronous workers is the ability to

00:16:38,879 --> 00:16:43,139
asynchronously process slow things

00:16:40,790 --> 00:16:45,839
preferably in parallel with our main

00:16:43,139 --> 00:16:49,559
program so we want the slow things to

00:16:45,839 --> 00:16:51,989
not slow us down especially the HTTP

00:16:49,559 --> 00:16:53,549
request handling which is what most of

00:16:51,989 --> 00:16:56,040
us are probably doing to bring in money

00:16:53,549 --> 00:17:01,559
and I'm willing to bet most of us like

00:16:56,040 --> 00:17:03,809
money so asynchronous workers to recap

00:17:01,559 --> 00:17:07,139
what I said we have our proverbial dump

00:17:03,809 --> 00:17:09,480
truck and a proverbial slow thing we're

00:17:07,139 --> 00:17:12,899
going to load it on there and have it

00:17:09,480 --> 00:17:14,549
brought elsewhere for processing I think

00:17:12,899 --> 00:17:18,600
this picture nicely captures all of

00:17:14,549 --> 00:17:20,579
these proverbial things at once now I've

00:17:18,600 --> 00:17:22,169
explained it a moment ago but the

00:17:20,579 --> 00:17:24,480
general answer is why do we care about

00:17:22,169 --> 00:17:27,419
isolating slow things because we want

00:17:24,480 --> 00:17:29,610
our application to feel responsive even

00:17:27,419 --> 00:17:31,679
if the actual processing is still taking

00:17:29,610 --> 00:17:33,630
a long time if your application feels

00:17:31,679 --> 00:17:37,139
responsive that's generally what the

00:17:33,630 --> 00:17:39,450
user cares about so some good things to

00:17:37,139 --> 00:17:42,120
have your workers do call external API

00:17:39,450 --> 00:17:44,789
is a special to really slow ones perform

00:17:42,120 --> 00:17:47,190
numerical crunching generate documents

00:17:44,789 --> 00:17:50,730
your user might want manipulate images

00:17:47,190 --> 00:17:53,039
or video send emails this is one where

00:17:50,730 --> 00:17:54,840
even though generally sending an email

00:17:53,039 --> 00:17:57,059
is a relatively quick operation if

00:17:54,840 --> 00:17:59,639
you're using a third-party service for

00:17:57,059 --> 00:18:02,039
it we use sendgrid quite frequently

00:17:59,639 --> 00:18:03,030
cigarette is generally really fast and

00:18:02,039 --> 00:18:05,850
if you do the synchronous

00:18:03,030 --> 00:18:07,380
it's not a problem but if they have some

00:18:05,850 --> 00:18:09,510
sort of server outage and they're down

00:18:07,380 --> 00:18:11,730
to five percent of their servers for a

00:18:09,510 --> 00:18:13,350
little while your entire application can

00:18:11,730 --> 00:18:15,090
get held up because of it if you're

00:18:13,350 --> 00:18:17,550
doing it asynchronously you don't have

00:18:15,090 --> 00:18:19,110
to worry about that and payment

00:18:17,550 --> 00:18:22,140
processing which can sometimes be quite

00:18:19,110 --> 00:18:23,550
slow and geolocation which again can

00:18:22,140 --> 00:18:25,830
also be quite so depending on what's

00:18:23,550 --> 00:18:28,020
available to the machine all of these

00:18:25,830 --> 00:18:30,360
things are not required immediately upon

00:18:28,020 --> 00:18:32,130
response that's what makes them good

00:18:30,360 --> 00:18:35,280
candidates from being processed in an

00:18:32,130 --> 00:18:37,020
asynchronous worker let's give some code

00:18:35,280 --> 00:18:40,770
examples so that you can see this in

00:18:37,020 --> 00:18:44,370
action a worker class looks something

00:18:40,770 --> 00:18:47,820
like this if you look at it this is a

00:18:44,370 --> 00:18:49,350
worker for rescue depending on which you

00:18:47,820 --> 00:18:50,880
choose if you're in delayed job or

00:18:49,350 --> 00:18:53,040
sidekick it looks slightly different but

00:18:50,880 --> 00:18:56,670
in general they look like this it is a

00:18:53,040 --> 00:19:00,450
class in rescue they have the cue set as

00:18:56,670 --> 00:19:02,700
a class instance variable and that does

00:19:00,450 --> 00:19:06,780
not have to be unique although it often

00:19:02,700 --> 00:19:09,060
is and a method named perform that is a

00:19:06,780 --> 00:19:10,680
class method the fact that is a class

00:19:09,060 --> 00:19:13,140
method is important and the fact that

00:19:10,680 --> 00:19:15,770
his name perform is important you pass

00:19:13,140 --> 00:19:17,910
it some arguments and it does some stuff

00:19:15,770 --> 00:19:19,560
don't worry too much about the details

00:19:17,910 --> 00:19:21,950
of what stuff it is and please don't try

00:19:19,560 --> 00:19:24,960
and write down the entire code example

00:19:21,950 --> 00:19:27,330
some things to notice from there again

00:19:24,960 --> 00:19:30,270
the @q in the class you do need to tell

00:19:27,330 --> 00:19:32,310
it where to write this stuff it perform

00:19:30,270 --> 00:19:35,100
a class method it receives the arguments

00:19:32,310 --> 00:19:37,290
that are in cute along with it which

00:19:35,100 --> 00:19:39,390
means that you do need one class per job

00:19:37,290 --> 00:19:40,500
type that's not a big deal in fact

00:19:39,390 --> 00:19:42,300
that's good because it means you have

00:19:40,500 --> 00:19:47,220
lots of things to handle specific small

00:19:42,300 --> 00:19:48,600
pieces of work and a slight aside you

00:19:47,220 --> 00:19:50,580
may be wondering where you put them in a

00:19:48,600 --> 00:19:52,290
rails project I usually put them in the

00:19:50,580 --> 00:19:54,270
lib some people like to put it in models

00:19:52,290 --> 00:19:57,240
some people put it elsewhere what's

00:19:54,270 --> 00:19:59,790
important is not where it is put but

00:19:57,240 --> 00:20:01,110
that your team is consistent and you

00:19:59,790 --> 00:20:02,820
might have also noticed those using

00:20:01,110 --> 00:20:08,490
rails inside something that is not a

00:20:02,820 --> 00:20:10,350
rails server that is correct you can use

00:20:08,490 --> 00:20:12,660
rails stuff inside of your asynchronous

00:20:10,350 --> 00:20:15,000
workers you do need to configure this

00:20:12,660 --> 00:20:16,530
but it's very simple to do so and you

00:20:15,000 --> 00:20:16,890
have the option of leaving it out if you

00:20:16,530 --> 00:20:18,480
want your

00:20:16,890 --> 00:20:21,510
a sickness workers to start faster

00:20:18,480 --> 00:20:22,920
although to be honest every time I see

00:20:21,510 --> 00:20:26,040
someone do this in an application they

00:20:22,920 --> 00:20:27,570
load it it is generally worth it because

00:20:26,040 --> 00:20:29,310
it gives you complete access to your

00:20:27,570 --> 00:20:30,690
active record models and the rest of

00:20:29,310 --> 00:20:32,820
your domain things from rails from

00:20:30,690 --> 00:20:34,080
within the worker but you can leave it

00:20:32,820 --> 00:20:36,630
out if you're sure you don't need it and

00:20:34,080 --> 00:20:39,450
you want the faster startup time to load

00:20:36,630 --> 00:20:42,990
rails you simply create a rescue Drake

00:20:39,450 --> 00:20:45,890
over in lib tasks and you make rescue

00:20:42,990 --> 00:20:48,420
setup depend on environment and that

00:20:45,890 --> 00:20:50,160
means that you will now have rails

00:20:48,420 --> 00:20:55,470
loaded on all of your asynchronous

00:20:50,160 --> 00:20:57,900
workers to call the worker please take a

00:20:55,470 --> 00:21:00,840
look inside the create method at the

00:20:57,900 --> 00:21:03,930
line after if at user dot save you call

00:21:00,840 --> 00:21:06,000
rescue dot and cue the class name and

00:21:03,930 --> 00:21:07,830
the arguments in this case we're only

00:21:06,000 --> 00:21:11,010
passing one argument that you may pass

00:21:07,830 --> 00:21:13,350
multiple and notice how down in the else

00:21:11,010 --> 00:21:18,570
clause we are in queuing a different

00:21:13,350 --> 00:21:20,100
type of asynchronous worker job it's

00:21:18,570 --> 00:21:21,840
true we're leaving out a lot of details

00:21:20,100 --> 00:21:24,450
here you know there's not much logging

00:21:21,840 --> 00:21:25,560
there's not much a formatting done what

00:21:24,450 --> 00:21:26,940
I really want to emphasize here is

00:21:25,560 --> 00:21:29,520
simply the fact you're calling rescue

00:21:26,940 --> 00:21:31,350
dotting queue so for things to notice

00:21:29,520 --> 00:21:33,780
you simply call a rescue dog EQ class

00:21:31,350 --> 00:21:35,460
followed by arguments you will naturally

00:21:33,780 --> 00:21:38,550
not type a rescue if you're using

00:21:35,460 --> 00:21:41,190
something else and whatever args you in

00:21:38,550 --> 00:21:43,200
queue or seal as is JSON don't pass

00:21:41,190 --> 00:21:45,210
arbitrary objects if you try and pass

00:21:43,200 --> 00:21:47,330
active record objects as is to the

00:21:45,210 --> 00:21:51,750
serializer will get upset at you

00:21:47,330 --> 00:21:53,580
serialize simple arbitrary values if you

00:21:51,750 --> 00:21:57,600
need to access something out of the

00:21:53,580 --> 00:22:00,030
database pass the ID or pass a JSON hash

00:21:57,600 --> 00:22:01,770
that represents all the information you

00:22:00,030 --> 00:22:05,970
need about the object that would

00:22:01,770 --> 00:22:07,710
actually be preferable so you've done

00:22:05,970 --> 00:22:09,030
this congratulations your work your job

00:22:07,710 --> 00:22:11,370
will now be processed separate from

00:22:09,030 --> 00:22:14,310
rails or separate from the rest of your

00:22:11,370 --> 00:22:15,960
application if you're not on rounds the

00:22:14,310 --> 00:22:17,400
problem now is of course you've just

00:22:15,960 --> 00:22:19,470
sent back the user something without

00:22:17,400 --> 00:22:24,150
that data being processed it's not done

00:22:19,470 --> 00:22:27,060
yet so you need to get that data back

00:22:24,150 --> 00:22:29,220
there's two main ways to do this first

00:22:27,060 --> 00:22:30,680
is the data simply on another page I

00:22:29,220 --> 00:22:32,330
like to call this the check back

00:22:30,680 --> 00:22:33,680
later approached you simply tell the

00:22:32,330 --> 00:22:35,540
user if you come here at a later time

00:22:33,680 --> 00:22:36,830
we'll have what you're asking for this

00:22:35,540 --> 00:22:38,240
is generally more useful for something

00:22:36,830 --> 00:22:39,650
that's going to take a while to run and

00:22:38,240 --> 00:22:41,420
you say come here to get your financial

00:22:39,650 --> 00:22:44,420
report it'll be done in about 10 minutes

00:22:41,420 --> 00:22:47,600
or you can asynchronously load the data

00:22:44,420 --> 00:22:49,190
via JavaScript you can set up something

00:22:47,600 --> 00:22:50,750
that's a little bit fancier than polling

00:22:49,190 --> 00:22:52,520
but in most cases polling works just

00:22:50,750 --> 00:22:54,320
fine for this purpose and you'll

00:22:52,520 --> 00:22:59,060
probably display some sort of indication

00:22:54,320 --> 00:23:00,590
to the user that it is being loaded you

00:22:59,060 --> 00:23:03,650
do need to know where the data is going

00:23:00,590 --> 00:23:07,190
to be determine this ahead of time using

00:23:03,650 --> 00:23:09,500
your routes or you can generate a hash

00:23:07,190 --> 00:23:11,330
and look that up that would be along

00:23:09,500 --> 00:23:13,160
with the response you pass along some

00:23:11,330 --> 00:23:15,500
sort of hash code that you generated and

00:23:13,160 --> 00:23:17,240
it knows where to go to go and find

00:23:15,500 --> 00:23:20,870
information about whatever object was

00:23:17,240 --> 00:23:22,340
associated with that hash users do get a

00:23:20,870 --> 00:23:24,800
noid of pages that are full of too many

00:23:22,340 --> 00:23:26,240
loading wheels if they go to a page and

00:23:24,800 --> 00:23:27,710
there's ten of the little spinning gray

00:23:26,240 --> 00:23:29,390
circles they're not going to be thrilled

00:23:27,710 --> 00:23:31,760
especially if they're on a mobile device

00:23:29,390 --> 00:23:33,410
on a mobile device having that much

00:23:31,760 --> 00:23:36,200
asynchronous loading going on can be

00:23:33,410 --> 00:23:38,810
really annoying so use this technique

00:23:36,200 --> 00:23:40,250
judiciously don't ignore it but

00:23:38,810 --> 00:23:43,880
overdoing it will generally make the

00:23:40,250 --> 00:23:46,040
user experience quite poor and of course

00:23:43,880 --> 00:23:48,500
I mentioned that there are concerns you

00:23:46,040 --> 00:23:50,570
have to deal with in terms of using your

00:23:48,500 --> 00:23:53,360
data and encountering synchronicity

00:23:50,570 --> 00:23:55,910
problems be careful with mutable state

00:23:53,360 --> 00:23:59,870
the usual thing you will run into is

00:23:55,910 --> 00:24:01,520
something called a race condition this

00:23:59,870 --> 00:24:03,470
is what happens when you are when you

00:24:01,520 --> 00:24:05,840
have two things modifying the same data

00:24:03,470 --> 00:24:07,760
at the same time and if you have your

00:24:05,840 --> 00:24:10,340
asynchronous workers modifying data in

00:24:07,760 --> 00:24:11,990
your back-end probably your SQL database

00:24:10,340 --> 00:24:14,060
but it could be another form of database

00:24:11,990 --> 00:24:15,680
you were going to run into race

00:24:14,060 --> 00:24:19,070
conditions and strange things are going

00:24:15,680 --> 00:24:20,660
to happen so you need to be careful the

00:24:19,070 --> 00:24:23,180
especially wary when you might have the

00:24:20,660 --> 00:24:26,750
same object or the same data in multiple

00:24:23,180 --> 00:24:28,850
workers at the same time if you're using

00:24:26,750 --> 00:24:31,580
the state in the database that might be

00:24:28,850 --> 00:24:33,410
read by multiple workers especially if

00:24:31,580 --> 00:24:35,570
it might be modified by multiple workers

00:24:33,410 --> 00:24:37,610
you probably want to adjust your

00:24:35,570 --> 00:24:39,650
workflow so that you do not have the

00:24:37,610 --> 00:24:42,380
possibility of having multiple things

00:24:39,650 --> 00:24:44,570
doing this at the same time eliminating

00:24:42,380 --> 00:24:46,580
the possibility by rewriting

00:24:44,570 --> 00:24:48,529
the order in which processing is done is

00:24:46,580 --> 00:24:51,070
generally going to be a lot easier than

00:24:48,529 --> 00:24:53,450
trying to set up a lock of some sort so

00:24:51,070 --> 00:24:56,600
as I said you do need to be careful of

00:24:53,450 --> 00:24:58,190
these situations otherwise you're going

00:24:56,600 --> 00:24:59,630
to run into some problems and you're

00:24:58,190 --> 00:25:02,509
going to encounter very strange data

00:24:59,630 --> 00:25:04,669
issues I'd like to go over the four

00:25:02,509 --> 00:25:06,740
rules of concurrency from the JRuby wiki

00:25:04,669 --> 00:25:09,529
I think they're very helpful rule number

00:25:06,740 --> 00:25:11,090
one is don't do it congratulations you

00:25:09,529 --> 00:25:13,549
can now go back and say parallelism does

00:25:11,090 --> 00:25:15,679
not need to be done you got your money's

00:25:13,549 --> 00:25:16,850
worth out of this conference they're

00:25:15,679 --> 00:25:18,830
probably not going to take that as an

00:25:16,850 --> 00:25:21,799
argument so number two is if you must do

00:25:18,830 --> 00:25:23,750
this don't share data across threads 4G

00:25:21,799 --> 00:25:26,600
Ruby here they say threads you can read

00:25:23,750 --> 00:25:28,190
that is asynchronous workers if you must

00:25:26,600 --> 00:25:29,990
share data across threads or

00:25:28,190 --> 00:25:32,240
asynchronous workers don't share mutable

00:25:29,990 --> 00:25:34,669
data and if you must share mutable data

00:25:32,240 --> 00:25:39,679
across asynchronous workers synchronize

00:25:34,669 --> 00:25:42,080
access to it so what should you do the

00:25:39,679 --> 00:25:45,200
best choices I said is simply don't do

00:25:42,080 --> 00:25:48,740
it as they said don't do it but since

00:25:45,200 --> 00:25:51,679
you might have to if you do need a

00:25:48,740 --> 00:25:53,149
specific state at a given point or you

00:25:51,679 --> 00:25:55,730
have a mutable object there are

00:25:53,149 --> 00:25:58,190
generally two ways to deal with it the

00:25:55,730 --> 00:26:01,730
first is using a lock you'll often hear

00:25:58,190 --> 00:26:03,700
this referred to as a mutex this is

00:26:01,730 --> 00:26:06,620
often database level using a database

00:26:03,700 --> 00:26:08,659
transaction because a mutex lock is

00:26:06,620 --> 00:26:10,519
generally within one process and your

00:26:08,659 --> 00:26:13,759
asynchronous workers are each a separate

00:26:10,519 --> 00:26:15,980
process it is possible to have a system

00:26:13,759 --> 00:26:17,389
level lock in which you have a single

00:26:15,980 --> 00:26:19,730
mutex lock that is shared across

00:26:17,389 --> 00:26:24,320
multiple processes this is very

00:26:19,730 --> 00:26:26,720
error-prone try to avoid that as it is

00:26:24,320 --> 00:26:28,539
very easy to mess up however using

00:26:26,720 --> 00:26:32,629
database transactions is generally very

00:26:28,539 --> 00:26:34,460
straightforward you can look up the ways

00:26:32,629 --> 00:26:36,529
in which active record provides access

00:26:34,460 --> 00:26:37,700
to it or you can look up the ways in

00:26:36,529 --> 00:26:39,620
which you can do it manually if you're

00:26:37,700 --> 00:26:42,799
doing a approach other than using active

00:26:39,620 --> 00:26:45,710
record the other choice is to make a

00:26:42,799 --> 00:26:49,429
copy of the state and do the processing

00:26:45,710 --> 00:26:51,289
on that if you've heard about the way

00:26:49,429 --> 00:26:53,690
closure handles things or you've heard

00:26:51,289 --> 00:26:55,580
the term copy-on-write well copy and

00:26:53,690 --> 00:26:57,920
write is different I apologize the way

00:26:55,580 --> 00:27:00,020
closure often handles mutate

00:26:57,920 --> 00:27:02,450
is that anything that mutates an object

00:27:00,020 --> 00:27:03,980
returns a copy that has been changed it

00:27:02,450 --> 00:27:06,980
doesn't know it never actually returns

00:27:03,980 --> 00:27:08,840
the original object you can do that in

00:27:06,980 --> 00:27:11,170
Ruby it just has to be something you are

00:27:08,840 --> 00:27:13,520
manually making sure you are enforcing

00:27:11,170 --> 00:27:17,360
Ruby is not going to enforce it for you

00:27:13,520 --> 00:27:19,280
if you make a copy of the state and do

00:27:17,360 --> 00:27:20,780
the processing on that you don't have to

00:27:19,280 --> 00:27:22,760
worry about the data getting modified

00:27:20,780 --> 00:27:25,040
from underneath you and if you're using

00:27:22,760 --> 00:27:27,350
rescue or sidekick you have read us as

00:27:25,040 --> 00:27:29,540
your data back end and Redis is a great

00:27:27,350 --> 00:27:31,460
place to write temporary values that is

00:27:29,540 --> 00:27:33,080
you're going to take your object the

00:27:31,460 --> 00:27:35,600
state of it at the time that you need

00:27:33,080 --> 00:27:37,790
this information processed about it copy

00:27:35,600 --> 00:27:39,490
that information out and then work with

00:27:37,790 --> 00:27:41,810
the copy for the rest of the flow and

00:27:39,490 --> 00:27:43,760
that way you are not going to be

00:27:41,810 --> 00:27:44,960
modifying the original data just make

00:27:43,760 --> 00:27:50,750
sure you don't write back to the

00:27:44,960 --> 00:27:52,580
database so the process of making a copy

00:27:50,750 --> 00:27:56,510
of the state and working with that is

00:27:52,580 --> 00:27:59,600
very similar to making sending

00:27:56,510 --> 00:28:01,130
parameters to a method call and when you

00:27:59,600 --> 00:28:03,710
in cure work or job you're going to

00:28:01,130 --> 00:28:05,870
write the parameters out to something

00:28:03,710 --> 00:28:08,480
which is a copy since it's going to

00:28:05,870 --> 00:28:11,360
Redis which sounds a lot like pipelining

00:28:08,480 --> 00:28:13,250
which is my shameless segue into the

00:28:11,360 --> 00:28:16,190
second technique which is pipelining

00:28:13,250 --> 00:28:19,490
pipelining is a general term for doing

00:28:16,190 --> 00:28:24,740
data manipulation in a specified step by

00:28:19,490 --> 00:28:26,840
step sequence so pipelining since an

00:28:24,740 --> 00:28:28,640
asynchronous job doesn't inherently bog

00:28:26,840 --> 00:28:31,180
anything down in your application it's

00:28:28,640 --> 00:28:34,360
tempting to make it do way too much i

00:28:31,180 --> 00:28:37,250
encourage you to resist that temptation

00:28:34,360 --> 00:28:38,660
this is an example of a very bad way to

00:28:37,250 --> 00:28:40,640
write something that I have seen many

00:28:38,660 --> 00:28:42,170
times when working with asynchronous

00:28:40,640 --> 00:28:43,250
workers and I am guilty of writing

00:28:42,170 --> 00:28:46,550
things like this on more than one

00:28:43,250 --> 00:28:48,320
occasion if you look at it in general

00:28:46,550 --> 00:28:51,080
you'll see that's doing far too much it

00:28:48,320 --> 00:28:53,600
is trying to do a whole lot of different

00:28:51,080 --> 00:28:54,800
things using Twitter and different

00:28:53,600 --> 00:28:57,140
followers for them and different

00:28:54,800 --> 00:29:01,130
messages for them there's too much going

00:28:57,140 --> 00:29:02,840
on in this single worker I consider this

00:29:01,130 --> 00:29:04,540
a code smell having a single and

00:29:02,840 --> 00:29:07,190
synchronous process doing too much is

00:29:04,540 --> 00:29:09,620
having a god worker you probably heard

00:29:07,190 --> 00:29:11,929
the term God object this is a God worker

00:29:09,620 --> 00:29:15,610
it is doing far more

00:29:11,929 --> 00:29:18,320
than it needs to when something breaks

00:29:15,610 --> 00:29:20,559
such as here this is shattered glass a

00:29:18,320 --> 00:29:23,840
few people told me it looks like sugar

00:29:20,559 --> 00:29:26,330
when something breaks you have no idea

00:29:23,840 --> 00:29:28,940
what just happened let's say you've got

00:29:26,330 --> 00:29:31,220
an exception in here somewhere somewhere

00:29:28,940 --> 00:29:33,169
in the middle maybe somewhere near the

00:29:31,220 --> 00:29:36,940
end it would be very difficult to figure

00:29:33,169 --> 00:29:39,080
out at what stage things went wrong and

00:29:36,940 --> 00:29:41,450
had you been doing the data and

00:29:39,080 --> 00:29:44,299
well-defined small chunks of work it

00:29:41,450 --> 00:29:46,070
would be much easier pipelining is

00:29:44,299 --> 00:29:50,919
sequencing you're processing a series of

00:29:46,070 --> 00:29:53,419
stages and the term of course comes from

00:29:50,919 --> 00:29:57,200
pipelines in which multiple segments are

00:29:53,419 --> 00:29:58,850
connected together and it is simply

00:29:57,200 --> 00:30:01,220
taking that and divining it into a

00:29:58,850 --> 00:30:03,980
series of small operations rather than

00:30:01,220 --> 00:30:07,580
one giant operation why should you

00:30:03,980 --> 00:30:09,320
bother it's focused you know exactly

00:30:07,580 --> 00:30:10,970
what each stage is doing rather than

00:30:09,320 --> 00:30:13,820
having to look at this giant blob of

00:30:10,970 --> 00:30:14,929
work it's adjustable and by this I mean

00:30:13,820 --> 00:30:17,600
in terms of the amount of things

00:30:14,929 --> 00:30:19,100
performing that step if you have ten

00:30:17,600 --> 00:30:20,899
steps and you discover that your

00:30:19,100 --> 00:30:22,970
application is bottlenecking on step

00:30:20,899 --> 00:30:25,700
three you can create more workers that

00:30:22,970 --> 00:30:28,159
are simply processing step three jobs if

00:30:25,700 --> 00:30:30,769
everything was just one giant job you

00:30:28,159 --> 00:30:31,879
cannot do that in many cases you won't

00:30:30,769 --> 00:30:33,799
need this because you won't be

00:30:31,879 --> 00:30:36,440
bottlenecking somewhere but if you is

00:30:33,799 --> 00:30:39,740
happening it's very handy to have it's

00:30:36,440 --> 00:30:42,019
much more testable it's much much easier

00:30:39,740 --> 00:30:45,440
to test one small step there rather than

00:30:42,019 --> 00:30:46,820
Mach out nine methods to test one and i

00:30:45,440 --> 00:30:50,269
encourage you to test what your workers

00:30:46,820 --> 00:30:51,860
are doing because having a synchronous

00:30:50,269 --> 00:30:53,179
workers doing work is not going to be

00:30:51,860 --> 00:30:56,110
much clearer if you haven't actually

00:30:53,179 --> 00:30:58,279
thoroughly tested what they are doing

00:30:56,110 --> 00:31:00,019
you might have noticed that if you

00:30:58,279 --> 00:31:03,049
divide or if you think about the way

00:31:00,019 --> 00:31:05,360
you're going to be setting things up for

00:31:03,049 --> 00:31:07,490
multi stage pipeline processing each

00:31:05,360 --> 00:31:09,289
step is going to be receiving the exact

00:31:07,490 --> 00:31:11,299
parameters it needs to work on which

00:31:09,289 --> 00:31:13,190
greatly resembles dependency injection

00:31:11,299 --> 00:31:16,820
style systems which are much more

00:31:13,190 --> 00:31:18,799
testable and it is traceable to me this

00:31:16,820 --> 00:31:20,899
is the most valuable thing when

00:31:18,799 --> 00:31:23,330
something goes wrong you will know why

00:31:20,899 --> 00:31:25,210
or you at least know where and that can

00:31:23,330 --> 00:31:28,460
let you find out why

00:31:25,210 --> 00:31:31,730
so here's step one broken out into a

00:31:28,460 --> 00:31:34,429
single process you get a user you find

00:31:31,730 --> 00:31:38,600
the followers for that user and ewan q

00:31:34,429 --> 00:31:40,669
the next step with the new data it's

00:31:38,600 --> 00:31:44,390
that simple this is stage one of your

00:31:40,669 --> 00:31:46,190
data pipeline your step two it is the

00:31:44,390 --> 00:31:48,380
Twitter messages finder you receive the

00:31:46,190 --> 00:31:51,110
arguments from the first stage do the

00:31:48,380 --> 00:31:56,059
next piece of work and then you in queue

00:31:51,110 --> 00:31:57,559
the subsequent one it's that simple and

00:31:56,059 --> 00:31:59,240
you might be wondering does that is it

00:31:57,559 --> 00:32:01,970
really any better like is this really

00:31:59,240 --> 00:32:03,919
worth the effort and it is worth the

00:32:01,970 --> 00:32:06,830
effort it is definitely worth splitting

00:32:03,919 --> 00:32:09,139
things up like this as I said all other

00:32:06,830 --> 00:32:12,460
benefits aside being able to concisely

00:32:09,139 --> 00:32:14,510
and accurately find errors is invaluable

00:32:12,460 --> 00:32:17,779
nothing is more frustrating than an

00:32:14,510 --> 00:32:20,389
error that you can't track down and to

00:32:17,779 --> 00:32:22,220
me that alone mixed data pipeline mean

00:32:20,389 --> 00:32:26,090
worthwhile I think the rest of the

00:32:22,220 --> 00:32:28,370
benefits are excellent as well some side

00:32:26,090 --> 00:32:30,440
notes about this if you're wondering

00:32:28,370 --> 00:32:34,159
where to save temporary data between

00:32:30,440 --> 00:32:36,470
stages saving it to read SD is fine

00:32:34,159 --> 00:32:40,760
passing it as parameters is fine writing

00:32:36,470 --> 00:32:43,490
it elsewhere is fine if you need to do

00:32:40,760 --> 00:32:45,919
things based on a time window do not

00:32:43,490 --> 00:32:49,130
expect your processes to be run at a

00:32:45,919 --> 00:32:51,080
certain time instead pass along the

00:32:49,130 --> 00:32:53,389
specific time window at which you want

00:32:51,080 --> 00:32:54,980
the processing to be done explicitly

00:32:53,389 --> 00:32:56,750
passing as a parameter is much better

00:32:54,980 --> 00:33:00,919
than saying this job should get

00:32:56,750 --> 00:33:03,440
processed around 6pm today and when you

00:33:00,919 --> 00:33:06,260
have a lot of worker types managing

00:33:03,440 --> 00:33:07,700
failed jobs can be a little tricky and I

00:33:06,260 --> 00:33:09,230
will admit this is one of the areas

00:33:07,700 --> 00:33:11,570
where most of the libraries are a little

00:33:09,230 --> 00:33:13,490
lacking look up the documentation for

00:33:11,570 --> 00:33:16,279
how to handle failed jobs depending on

00:33:13,490 --> 00:33:17,690
which library you're using but this is

00:33:16,279 --> 00:33:20,090
something that you often have to create

00:33:17,690 --> 00:33:23,269
some support on your own to work with in

00:33:20,090 --> 00:33:25,429
your own application and the last piece

00:33:23,269 --> 00:33:27,440
of information or let my last piece of

00:33:25,429 --> 00:33:30,049
advice here is using a good log

00:33:27,440 --> 00:33:32,090
aggregator will make this all much much

00:33:30,049 --> 00:33:34,520
easier if you have all of the

00:33:32,090 --> 00:33:37,520
information for dozens of workers go

00:33:34,520 --> 00:33:38,300
into a single log sequential log file it

00:33:37,520 --> 00:33:40,790
can be very

00:33:38,300 --> 00:33:41,870
difficult to read through so really

00:33:40,790 --> 00:33:43,880
think about getting a good log

00:33:41,870 --> 00:33:45,290
aggregator it will save you a lot of

00:33:43,880 --> 00:33:46,820
time and it will make getting

00:33:45,290 --> 00:33:50,600
information about what's happening much

00:33:46,820 --> 00:33:51,920
much easier if you have really specific

00:33:50,600 --> 00:33:53,630
needs or you don't want to pay for one

00:33:51,920 --> 00:33:55,460
making a long degra Gator isn't too

00:33:53,630 --> 00:33:57,290
difficult but I think if you look at the

00:33:55,460 --> 00:34:01,360
availability of other options and the

00:33:57,290 --> 00:34:03,710
pricing of them it's not prohibitive

00:34:01,360 --> 00:34:06,410
save yourself some headaches use a good

00:34:03,710 --> 00:34:07,940
log aggregator start one go get an

00:34:06,410 --> 00:34:10,880
open-source one pay for one of the

00:34:07,940 --> 00:34:12,350
services it's worth it let's talk a

00:34:10,880 --> 00:34:13,520
little bit about logging but I'm going

00:34:12,350 --> 00:34:15,950
to go through this pretty quick because

00:34:13,520 --> 00:34:18,650
we are a little time constrained rescue

00:34:15,950 --> 00:34:21,830
has a configurable logger it defaults to

00:34:18,650 --> 00:34:23,840
standard out you can write to the rails

00:34:21,830 --> 00:34:25,100
logs I recommend not doing that because

00:34:23,840 --> 00:34:26,720
you've got a lot more information than

00:34:25,100 --> 00:34:28,640
you actually need about the state of the

00:34:26,720 --> 00:34:30,920
worker itself being written there

00:34:28,640 --> 00:34:33,050
instead of what's processing you can

00:34:30,920 --> 00:34:34,790
adjust how verbose it is using the

00:34:33,050 --> 00:34:37,160
environmental variables for both and V

00:34:34,790 --> 00:34:38,570
verbose keep in mind that logging can be

00:34:37,160 --> 00:34:42,560
buffered if you're writing to the file

00:34:38,570 --> 00:34:45,110
system and rescue 2 point 0 which is not

00:34:42,560 --> 00:34:47,870
ready for production you yet is still in

00:34:45,110 --> 00:34:54,980
development changes the way that is set

00:34:47,870 --> 00:34:57,380
up and the logger is only in 124 on if

00:34:54,980 --> 00:34:58,670
you try and configure rescue lager and

00:34:57,380 --> 00:34:59,870
it's raising an error because there's no

00:34:58,670 --> 00:35:01,310
idea what you're talking about you're on

00:34:59,870 --> 00:35:05,180
an older version in that case just

00:35:01,310 --> 00:35:06,710
redirect from standard out let's talk

00:35:05,180 --> 00:35:12,740
about the last pattern real quick

00:35:06,710 --> 00:35:14,570
periodic maintenance tasks rescue and

00:35:12,740 --> 00:35:16,370
friends are usually called primarily

00:35:14,570 --> 00:35:18,170
from within an application and there's

00:35:16,370 --> 00:35:21,110
another convenient use for them which is

00:35:18,170 --> 00:35:23,270
taking care of periodic tasks this is

00:35:21,110 --> 00:35:26,900
useful when you have anything that needs

00:35:23,270 --> 00:35:28,460
to be done based on periodic pneus or on

00:35:26,900 --> 00:35:30,380
certain times of day or on certain user

00:35:28,460 --> 00:35:32,060
input you need to run a data collation

00:35:30,380 --> 00:35:33,830
job you need to fetch fresh data for

00:35:32,060 --> 00:35:35,030
mode API you need to write a report of

00:35:33,830 --> 00:35:38,030
the state of the business whatever

00:35:35,030 --> 00:35:40,490
simple way to do this create a worker

00:35:38,030 --> 00:35:44,930
that will do the work make a rake task

00:35:40,490 --> 00:35:48,230
that will enculer to run the rake task

00:35:44,930 --> 00:35:49,520
that's it if you need a bunch of things

00:35:48,230 --> 00:35:52,190
and queued together there's a slight

00:35:49,520 --> 00:35:55,190
variation on it you create the worker

00:35:52,190 --> 00:35:56,869
which is the processing job you make a

00:35:55,190 --> 00:35:59,150
rake test that will find all the things

00:35:56,869 --> 00:36:00,650
that need the processing and then use

00:35:59,150 --> 00:36:03,920
the scheduler to run it and it will link

00:36:00,650 --> 00:36:05,510
you all of them if you need a really

00:36:03,920 --> 00:36:08,630
large number of things and cute together

00:36:05,510 --> 00:36:10,280
I think you might be trying to do big

00:36:08,630 --> 00:36:11,839
data and I'm going to use the scare

00:36:10,280 --> 00:36:14,119
quotes around that processing using the

00:36:11,839 --> 00:36:16,550
system not really designed for it but

00:36:14,119 --> 00:36:19,430
what you could do create a worker that

00:36:16,550 --> 00:36:21,950
will do the work on a single job create

00:36:19,430 --> 00:36:23,890
another job that finds the things that

00:36:21,950 --> 00:36:27,079
need to have this data processed on them

00:36:23,890 --> 00:36:29,270
the in queue anjaan make a rake test

00:36:27,079 --> 00:36:31,130
that will divide things up and find what

00:36:29,270 --> 00:36:34,400
needs to have the acuity ob's in queued

00:36:31,130 --> 00:36:37,280
and use a scheduled to run it what's a

00:36:34,400 --> 00:36:38,810
good scheduler cron works fine and if

00:36:37,280 --> 00:36:40,280
you don't like Crohn's syntax there's a

00:36:38,810 --> 00:36:41,900
gem called whenever which gives you

00:36:40,280 --> 00:36:44,630
really nice access to things like this

00:36:41,900 --> 00:36:47,480
every three hours every one day every

00:36:44,630 --> 00:36:49,130
hour etc I apologize if I'm going too

00:36:47,480 --> 00:36:50,300
fast but we are a little constrained for

00:36:49,130 --> 00:36:52,430
time because it started a couple minutes

00:36:50,300 --> 00:36:54,589
late friendly reminder if you're on a

00:36:52,430 --> 00:36:57,260
cloud host that does not give you access

00:36:54,589 --> 00:36:59,270
to cron you can't use whatever however

00:36:57,260 --> 00:37:01,130
they generally offer you some sort of

00:36:59,270 --> 00:37:04,160
service that is a substitute that you

00:37:01,130 --> 00:37:06,410
can use to in queue these jobs if you

00:37:04,160 --> 00:37:09,200
need to run something later but not at a

00:37:06,410 --> 00:37:10,880
periodic set time there was something

00:37:09,200 --> 00:37:12,530
called rescue scheduler which is really

00:37:10,880 --> 00:37:15,260
nice but it's looking for a new

00:37:12,530 --> 00:37:17,480
maintainer if you want to become the new

00:37:15,260 --> 00:37:19,609
maintainer people will love you it's

00:37:17,480 --> 00:37:21,740
always nice to be loved if you have an

00:37:19,609 --> 00:37:23,960
existing project that uses a version

00:37:21,740 --> 00:37:26,150
that is compatible with it it does work

00:37:23,960 --> 00:37:28,400
fine it's just got some issues now and

00:37:26,150 --> 00:37:29,569
going forward it's future is a little

00:37:28,400 --> 00:37:33,440
uncertain until it finds a new

00:37:29,569 --> 00:37:35,720
maintainer and I'm going to skip that I

00:37:33,440 --> 00:37:37,130
apologize so the three things we talked

00:37:35,720 --> 00:37:38,839
about our isolating slow activities

00:37:37,130 --> 00:37:40,760
pipeline processing and periodic

00:37:38,839 --> 00:37:43,579
maintenance tasks they all work very

00:37:40,760 --> 00:37:46,940
well together concurrency is hard don't

00:37:43,579 --> 00:37:48,920
feel bad if you get it wrong try to keep

00:37:46,940 --> 00:37:52,220
things in order with shared nothing and

00:37:48,920 --> 00:37:55,339
item potent transactions for rules of

00:37:52,220 --> 00:37:57,260
concurrency remember only do it when you

00:37:55,339 --> 00:37:58,579
actually will get real benefit from it

00:37:57,260 --> 00:38:02,359
don't do it simply because you want to

00:37:58,579 --> 00:38:04,460
feel smart remember that if you take a

00:38:02,359 --> 00:38:05,250
consistent and careful approach it will

00:38:04,460 --> 00:38:08,820
help you

00:38:05,250 --> 00:38:11,640
and is it worth the effort to do this I

00:38:08,820 --> 00:38:15,210
say yes it is feel free to disagree if

00:38:11,640 --> 00:38:16,470
you like I would love to take questions

00:38:15,210 --> 00:38:18,090
in the hallway but I don't think we have

00:38:16,470 --> 00:38:20,190
time to do it in here or if you want to

00:38:18,090 --> 00:38:22,410
tweet them at me my name is David cap

00:38:20,190 --> 00:38:23,880
I'm a happy mr. Dave on Twitter and I

00:38:22,410 --> 00:38:25,950
will put up the slides but I couldn't

00:38:23,880 --> 00:38:27,390
get Wi-Fi to work so i will tweet the

00:38:25,950 --> 00:38:30,710
thing later and i'll be on my github

00:38:27,390 --> 00:38:30,710

YouTube URL: https://www.youtube.com/watch?v=1zMcGagg_M8


