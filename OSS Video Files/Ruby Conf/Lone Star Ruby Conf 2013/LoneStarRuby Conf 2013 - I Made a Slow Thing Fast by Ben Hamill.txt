Title: LoneStarRuby Conf 2013 - I Made a Slow Thing Fast by Ben Hamill
Publication date: 2020-01-28
Playlist: Lone Star Ruby Conf 2013
Description: 
	The talk is a narrative retelling of how I took an application that needed to communicate with a slow external API and improved the user's experience in terms of speed. I'll talk about the situation that we started with, and then retell the story of measurement, and improvement and measurement and improvement.

I'll talk about perftools.rb, improving the perception of speed without having to actually make your code faster, MRI's Threads (when they're a good fit, and how and why we used them), a few strategies for managing threads, and a few other related topics. None of these topics will be discussed in great depth; the format is intended to be a retelling of the project, so I'll limit my discussion to the scope of how it applied to this specific project.

The talk will probably be of most interest to people who have little real-world experience with MRI's Threads and/or making users feel like an application is responding quickly. My hope is that showing these things in the context of a real project can help solidify understanding of topics that are often covered in contrived or theoretical examples (I know it did for me: I was totally new to a lot of this stuff when I started the project).

Help us caption & translate this video!

http://amara.org/v/FG8o/
Captions: 
	00:00:14,840 --> 00:00:24,540
so hi I'm Ben hamla my Twitter website

00:00:20,250 --> 00:00:27,330
and my email address ok at a company

00:00:24,540 --> 00:00:28,830
called return path we're the global

00:00:27,330 --> 00:00:31,050
leader and email intelligence which is

00:00:28,830 --> 00:00:32,940
cutting mouthful but suffice it to say

00:00:31,050 --> 00:00:35,280
we spend a lot of time to make email

00:00:32,940 --> 00:00:38,430
more awesome and specifically our

00:00:35,280 --> 00:00:42,390
Confederate called context I 0 which is

00:00:38,430 --> 00:00:45,780
an HTTP API or email you may have talked

00:00:42,390 --> 00:00:48,720
to Tony at our sponsor booth and I just

00:00:45,780 --> 00:00:50,100
want to drop in here we're hiring if you

00:00:48,720 --> 00:00:53,239
want to talk to me about that after this

00:00:50,100 --> 00:00:58,019
or talk to Tony that would be happy so

00:00:53,239 --> 00:01:01,710
until you aster you today about my first

00:00:58,019 --> 00:01:04,170
foray into thinking about measuring and

00:01:01,710 --> 00:01:07,049
doing anything about performance in Ruby

00:01:04,170 --> 00:01:11,040
and like the users experience with

00:01:07,049 --> 00:01:12,299
performance before this though the

00:01:11,040 --> 00:01:14,450
project that I'm going to tell you about

00:01:12,299 --> 00:01:17,280
I was kind of intimidated about it and

00:01:14,450 --> 00:01:20,580
it wasn't as bad as I thought so I hope

00:01:17,280 --> 00:01:23,100
to convey that not as bad feeling to all

00:01:20,580 --> 00:01:24,660
of you so even talk about three things

00:01:23,100 --> 00:01:26,820
first I'm going to talk about sort of

00:01:24,660 --> 00:01:29,180
the state of the code base when I

00:01:26,820 --> 00:01:31,500
started then I'm going to tell you how

00:01:29,180 --> 00:01:34,020
some tricks that I discovered to sort of

00:01:31,500 --> 00:01:35,880
fake out speed and not actually make it

00:01:34,020 --> 00:01:43,020
any faster and then we will talk about

00:01:35,880 --> 00:01:45,570
achieving real speed yeah so the API

00:01:43,020 --> 00:01:48,230
mentioned in the previous slide will

00:01:45,570 --> 00:01:51,480
remain anonymous throughout this

00:01:48,230 --> 00:01:54,030
presentation partly because I want to

00:01:51,480 --> 00:01:58,200
protect the identity of the innocent

00:01:54,030 --> 00:02:00,270
that's not my API that's say but also

00:01:58,200 --> 00:02:04,200
because it has to do with a project that

00:02:00,270 --> 00:02:06,360
we're not ready to announce yet but we

00:02:04,200 --> 00:02:09,840
will say some things about the API which

00:02:06,360 --> 00:02:12,599
must not be made first of all it's all

00:02:09,840 --> 00:02:17,310
xml all the time which is super awesome

00:02:12,599 --> 00:02:18,530
um so that you're making HTTP requests

00:02:17,310 --> 00:02:20,270
at this thing with

00:02:18,530 --> 00:02:23,150
bodies and getting back responses with

00:02:20,270 --> 00:02:26,510
XML in them and there are two kinds of

00:02:23,150 --> 00:02:29,480
entities that the Pythia external API

00:02:26,510 --> 00:02:32,890
knows about there are documents which

00:02:29,480 --> 00:02:36,950
have like a body largely of text and

00:02:32,890 --> 00:02:44,660
mean a set of changes and the changes

00:02:36,950 --> 00:02:46,550
are like add dawid mattify so when

00:02:44,660 --> 00:02:49,040
someone leaves a document to you further

00:02:46,550 --> 00:02:52,310
you get a change when they have received

00:02:49,040 --> 00:02:54,560
a new fountain in their account that's

00:02:52,310 --> 00:02:58,400
add and if they delete a document that's

00:02:54,560 --> 00:03:00,320
a delete clearly so do the change that

00:02:58,400 --> 00:03:02,360
was very data light though and if you

00:03:00,320 --> 00:03:05,120
want to know details you put you have to

00:03:02,360 --> 00:03:07,790
fetch the document itself so the way

00:03:05,120 --> 00:03:09,709
that my app works we perform what we

00:03:07,790 --> 00:03:12,830
call sink which is to say we synchronize

00:03:09,709 --> 00:03:17,600
our understanding of the account in

00:03:12,830 --> 00:03:21,080
foreign API with what is true on their

00:03:17,600 --> 00:03:22,880
server so this is their API alright so

00:03:21,080 --> 00:03:26,989
we make a request and we get this change

00:03:22,880 --> 00:03:29,060
document down I mean for a given wine or

00:03:26,989 --> 00:03:31,100
given command in the change document we

00:03:29,060 --> 00:03:34,640
fetch the body of the message do some

00:03:31,100 --> 00:03:36,980
analysis on it and we do that for every

00:03:34,640 --> 00:03:40,850
line and the change document for however

00:03:36,980 --> 00:03:44,540
many there are I mean once we've done

00:03:40,850 --> 00:03:47,090
that we can like stamp the timestamp and

00:03:44,540 --> 00:03:51,650
do some post processing and be done with

00:03:47,090 --> 00:03:55,010
our sink so here's where we would come

00:03:51,650 --> 00:03:56,780
to sort of the problem right so then the

00:03:55,010 --> 00:04:00,350
sinks that I do is storing this data

00:03:56,780 --> 00:04:02,799
then there's an iphone app that team

00:04:00,350 --> 00:04:05,870
members working on it uses this data a

00:04:02,799 --> 00:04:08,180
new user downloads the app and signs up

00:04:05,870 --> 00:04:11,060
for it it triggers a sink and then posed

00:04:08,180 --> 00:04:12,799
for the post-processing results and when

00:04:11,060 --> 00:04:15,049
I find something interesting it like

00:04:12,799 --> 00:04:17,030
updates to show the user the interesting

00:04:15,049 --> 00:04:18,769
thing and interesting here is like

00:04:17,030 --> 00:04:20,180
determined by bayesian classifier but

00:04:18,769 --> 00:04:21,870
starting beside the point for our

00:04:20,180 --> 00:04:23,729
purposes just know that it

00:04:21,870 --> 00:04:26,850
time after the sink is done to determine

00:04:23,729 --> 00:04:30,229
whether something was interesting and

00:04:26,850 --> 00:04:34,169
the problem was that the time between

00:04:30,229 --> 00:04:36,360
finishing sign up and step 3 was too

00:04:34,169 --> 00:04:38,280
long and I don't know what you guys but

00:04:36,360 --> 00:04:41,550
when I'm trying out a new iphone up I'm

00:04:38,280 --> 00:04:43,919
like oh is this thing you know click on

00:04:41,550 --> 00:04:46,199
Fame sure you know here's my credentials

00:04:43,919 --> 00:04:47,790
and looking at a spinner now if it takes

00:04:46,199 --> 00:04:50,760
longer than about five seconds to go

00:04:47,790 --> 00:04:55,190
from this to this and this is the face

00:04:50,760 --> 00:04:59,400
of like bad user experience yeah so

00:04:55,190 --> 00:05:03,660
avoid like wage I'm style and screaming

00:04:59,400 --> 00:05:07,680
babies and you know achieved a better

00:05:03,660 --> 00:05:11,820
user experience so the first question to

00:05:07,680 --> 00:05:13,199
ask is what what is actually slow like

00:05:11,820 --> 00:05:17,100
we know the whole thing is slow but

00:05:13,199 --> 00:05:20,280
what's the slow part and we had an

00:05:17,100 --> 00:05:21,780
intuition that it was something external

00:05:20,280 --> 00:05:23,850
Chris goes like Mike Mike oh it's not

00:05:21,780 --> 00:05:27,870
slow right you've never written so code

00:05:23,850 --> 00:05:32,729
me right but your intuition can be one

00:05:27,870 --> 00:05:34,320
and it would be abysmal to guess what is

00:05:32,729 --> 00:05:36,550
slow spend a week refactoring and

00:05:34,320 --> 00:05:39,280
optimizing it deployed and then have

00:05:36,550 --> 00:05:42,430
at on how fast your thing actually runs

00:05:39,280 --> 00:05:45,130
so you have to measure things to

00:05:42,430 --> 00:05:47,230
actually answer this question so this

00:05:45,130 --> 00:05:48,700
was our intuition with some other

00:05:47,230 --> 00:05:52,000
external stuff that we're using you know

00:05:48,700 --> 00:05:55,330
who being the API that's to not to be

00:05:52,000 --> 00:05:57,580
named you know you could be using too

00:05:55,330 --> 00:06:00,760
much RAM if going down the system or you

00:05:57,580 --> 00:06:03,250
know pegging your processor etc so learn

00:06:00,760 --> 00:06:06,130
about some tools to find out the first

00:06:03,250 --> 00:06:09,640
of their just called top it's a command

00:06:06,130 --> 00:06:11,560
line tool from linux and this output is

00:06:09,640 --> 00:06:13,120
actually taken from my laptop while I

00:06:11,560 --> 00:06:15,880
was making the slides I didn't capture

00:06:13,120 --> 00:06:19,390
it while it was actually running it so I

00:06:15,880 --> 00:06:21,850
deployed to my sync process to an alpha

00:06:19,390 --> 00:06:23,020
server when I man ran top there's kind

00:06:21,850 --> 00:06:26,140
of a lot of output so I'm going to

00:06:23,020 --> 00:06:30,130
highlight the sort of major important

00:06:26,140 --> 00:06:34,300
things so this bit here this this whole

00:06:30,130 --> 00:06:37,480
line is in kilobytes of memory and so

00:06:34,300 --> 00:06:39,670
this number here is the amount of food

00:06:37,480 --> 00:06:41,200
and when you have if it is low you're

00:06:39,670 --> 00:06:45,490
using a lot of ram and if it is high

00:06:41,200 --> 00:06:49,000
you're not on case this number was

00:06:45,490 --> 00:06:54,100
plenty high so okay we're not ran down

00:06:49,000 --> 00:06:55,090
that's good news I guess and the next

00:06:54,100 --> 00:07:00,250
important thing that when going

00:06:55,090 --> 00:07:02,200
attention to here is this column so each

00:07:00,250 --> 00:07:05,050
of these lines is a process running a

00:07:02,200 --> 00:07:07,960
machine and um like one of these lines

00:07:05,050 --> 00:07:09,970
will be in your process that represents

00:07:07,960 --> 00:07:12,910
the code you wrote or in my case the

00:07:09,970 --> 00:07:16,720
code I wrote and this one is the person

00:07:12,910 --> 00:07:18,940
oh its CPU that it's using it will total

00:07:16,720 --> 00:07:21,160
one hundred percent times negative cores

00:07:18,940 --> 00:07:22,540
in machine so if you have four cores it

00:07:21,160 --> 00:07:24,010
might total four hundred percent

00:07:22,540 --> 00:07:26,710
assuming you're pegging the whole thing

00:07:24,010 --> 00:07:28,630
its more common that it will be

00:07:26,710 --> 00:07:30,160
like one process will be pegging women

00:07:28,630 --> 00:07:31,900
of your physical cores and other things

00:07:30,160 --> 00:07:35,140
are still getting scheduled because you

00:07:31,900 --> 00:07:38,320
have other processors available but

00:07:35,140 --> 00:07:41,110
again in our case these numbers were

00:07:38,320 --> 00:07:42,400
relatively low like I could see my movie

00:07:41,110 --> 00:07:44,770
process I'm here taking up some

00:07:42,400 --> 00:07:48,900
resources but it was not an unreasonable

00:07:44,770 --> 00:07:52,690
amount so that wasn't the bottleneck

00:07:48,900 --> 00:07:54,040
okay so that's top not show next to

00:07:52,690 --> 00:07:57,690
learn about his eyes that you can read

00:07:54,040 --> 00:08:00,610
is perfectly right it's good so ask that

00:07:57,690 --> 00:08:02,050
as a kind of a lot of output and I put

00:08:00,610 --> 00:08:04,090
this here because I'm gonna refer to the

00:08:02,050 --> 00:08:06,850
elec general shape of it but what is in

00:08:04,090 --> 00:08:09,130
here on the command the first business

00:08:06,850 --> 00:08:11,620
here is just my prompt but if command is

00:08:09,130 --> 00:08:16,030
iostat and then I fed at the options x +

00:08:11,620 --> 00:08:17,560
k x is for extra columns and the k is to

00:08:16,030 --> 00:08:19,120
put things in kilobytes per second

00:08:17,560 --> 00:08:23,980
because it's easier to understand as a

00:08:19,120 --> 00:08:27,880
human included two arguments the first

00:08:23,980 --> 00:08:30,400
is the number of seconds per bucket and

00:08:27,880 --> 00:08:33,310
the second is the number of buckets and

00:08:30,400 --> 00:08:36,970
like the general shape of the output

00:08:33,310 --> 00:08:39,070
about that each grouping of lines is a

00:08:36,970 --> 00:08:41,620
bucket so like it shows you the data it

00:08:39,070 --> 00:08:43,660
waits five seconds and then it shows you

00:08:41,620 --> 00:08:45,910
the data from that five seconds net

00:08:43,660 --> 00:08:49,000
weight and it shows you the third bucket

00:08:45,910 --> 00:08:51,160
what it's showing data about is the

00:08:49,000 --> 00:08:53,020
amount of disk reads and writes that

00:08:51,160 --> 00:08:56,860
your system is doing so you can use it

00:08:53,020 --> 00:09:02,200
to measure how I'm like waiting on Io

00:08:56,860 --> 00:09:04,450
your program is so this is the like the

00:09:02,200 --> 00:09:08,080
first thing to look at here and i try to

00:09:04,450 --> 00:09:10,810
zoom in so this is this percent

00:09:08,080 --> 00:09:12,250
until here goes up to 100 and if it's a

00:09:10,810 --> 00:09:14,530
hundred you're spending a lot of time

00:09:12,250 --> 00:09:16,450
waiting on disk reading right if it is

00:09:14,530 --> 00:09:22,000
below 1 like here you're not spending

00:09:16,450 --> 00:09:26,980
very much time so these two tools can

00:09:22,000 --> 00:09:29,350
help you confirm or eliminate ram cpu

00:09:26,980 --> 00:09:31,870
usage and disk reads and writes in our

00:09:29,350 --> 00:09:36,270
case the none of those were the options

00:09:31,870 --> 00:09:38,530
so I was beginning to suspect you know

00:09:36,270 --> 00:09:40,830
something on the network something

00:09:38,530 --> 00:09:44,620
across the network was slowing me down

00:09:40,830 --> 00:09:49,830
so I turned to a third tool called proof

00:09:44,620 --> 00:09:52,600
tools Darby it's a real gem and it's a

00:09:49,830 --> 00:09:56,260
like a real implementation of a sea tool

00:09:52,600 --> 00:09:58,270
called / fuels so this this example code

00:09:56,260 --> 00:10:02,020
is going pretty much right from Louie

00:09:58,270 --> 00:10:03,850
and I did effectively this I went on to

00:10:02,020 --> 00:10:08,020
the Alpha store i opened up my niche

00:10:03,850 --> 00:10:10,690
script and I required the gym you start

00:10:08,020 --> 00:10:13,480
the CPU profiler and feed it a file do I

00:10:10,690 --> 00:10:15,070
to do it over your work is and then you

00:10:13,480 --> 00:10:17,110
tell the profiler stopping it like

00:10:15,070 --> 00:10:19,390
closes the file in my case I actually

00:10:17,110 --> 00:10:21,580
put a stop in another thread that's

00:10:19,390 --> 00:10:22,630
waited five minutes and then stop so I

00:10:21,580 --> 00:10:27,370
get a five minute sample without

00:10:22,630 --> 00:10:30,670
knocking over the whole process after

00:10:27,370 --> 00:10:32,980
you've collected all the data you can

00:10:30,670 --> 00:10:34,900
generate output this output actually is

00:10:32,980 --> 00:10:37,240
from the alpha server while I was doing

00:10:34,900 --> 00:10:40,300
the project I saved to put in a comment

00:10:37,240 --> 00:10:42,490
in a ticket so you're going to keep

00:10:40,300 --> 00:10:48,930
track text and you feed at you what's

00:10:42,490 --> 00:10:52,000
taking so long file I mean this calm so

00:10:48,930 --> 00:10:55,110
the way that the Tool Works is at

00:10:52,000 --> 00:10:58,860
regular intervals attacks after the EVM

00:10:55,110 --> 00:11:01,650
what what method are you running man

00:10:58,860 --> 00:11:03,090
and it just keeps a list and like how

00:11:01,650 --> 00:11:06,810
many times the responses were which

00:11:03,090 --> 00:11:08,310
methods so then you run people off you

00:11:06,810 --> 00:11:10,020
can use it to generate different kinds

00:11:08,310 --> 00:11:13,200
of output that the text was sufficient

00:11:10,020 --> 00:11:16,230
for my case it basically just advocates

00:11:13,200 --> 00:11:18,140
it up and tells you so this column is

00:11:16,230 --> 00:11:21,120
the percentage of times that a given

00:11:18,140 --> 00:11:23,670
method was the answer to what are you

00:11:21,120 --> 00:11:27,330
doing right now so the first time you

00:11:23,670 --> 00:11:29,340
can see is IO select which are the

00:11:27,330 --> 00:11:31,230
second then there's TCP socket

00:11:29,340 --> 00:11:34,290
initialize an i/o right all of this is

00:11:31,230 --> 00:11:38,550
like network related stuff in particular

00:11:34,290 --> 00:11:41,400
Iowa select which is 71.6 percent of the

00:11:38,550 --> 00:11:45,810
time it's like not quite three quarters

00:11:41,400 --> 00:11:48,900
that's kind of absurd right I'll select

00:11:45,810 --> 00:11:52,500
is was basically my sync process waiting

00:11:48,900 --> 00:11:55,620
to hear back from an HTTP request so

00:11:52,500 --> 00:11:58,140
that's spectacular we're not actually

00:11:55,620 --> 00:11:59,100
doing processing that's taking the time

00:11:58,140 --> 00:12:02,190
we're just waiting to hear back from

00:11:59,100 --> 00:12:04,920
somebody else so I did a failure

00:12:02,190 --> 00:12:07,290
investigation like cutting pieces of the

00:12:04,920 --> 00:12:09,900
codebase out and doing external calls

00:12:07,290 --> 00:12:11,580
and what I determined was that a round

00:12:09,900 --> 00:12:15,450
trip to fetch the body of the document

00:12:11,580 --> 00:12:16,620
took about half a second and at the

00:12:15,450 --> 00:12:18,840
number of documents that we were

00:12:16,620 --> 00:12:20,520
generally working with as at least that

00:12:18,840 --> 00:12:22,740
we were testing with it ended up being a

00:12:20,520 --> 00:12:28,050
lot of second so I added up that we were

00:12:22,740 --> 00:12:29,790
just spending like hanging out and that

00:12:28,050 --> 00:12:36,420
was by far the slowest external will

00:12:29,790 --> 00:12:37,620
call we were making so wait so we've

00:12:36,420 --> 00:12:41,190
been talking about the applications

00:12:37,620 --> 00:12:42,690
performance and I expect about three

00:12:41,190 --> 00:12:44,400
days into it at this juncture and I kind

00:12:42,690 --> 00:12:46,920
of was like moving to think about my

00:12:44,400 --> 00:12:49,200
performance because of course like

00:12:46,920 --> 00:12:50,790
developer time is valuable and there's

00:12:49,200 --> 00:12:52,290
an opportunity cost and we choose to do

00:12:50,790 --> 00:12:55,830
one thing you're not doing something

00:12:52,290 --> 00:12:58,200
else and I like heard about these things

00:12:55,830 --> 00:13:00,240
called threads and that like you can do

00:12:58,200 --> 00:13:00,800
stuff in parallel and we faster but I

00:13:00,240 --> 00:13:03,589
know

00:13:00,800 --> 00:13:06,380
about it was like maybe I would take

00:13:03,589 --> 00:13:09,410
like a week to do like lamb and then do

00:13:06,380 --> 00:13:11,000
something with it um but I kind of

00:13:09,410 --> 00:13:16,959
wondered if there's something that I can

00:13:11,000 --> 00:13:21,050
do today you know that would be maybe

00:13:16,959 --> 00:13:23,269
good enough you know so I kind of took a

00:13:21,050 --> 00:13:25,310
step back and started thinking what is

00:13:23,269 --> 00:13:27,140
actually important here you know it

00:13:25,310 --> 00:13:28,579
usually doesn't know when a sink started

00:13:27,140 --> 00:13:30,920
and when it and didn't even know what

00:13:28,579 --> 00:13:32,300
the hell a sink is they know that press

00:13:30,920 --> 00:13:37,120
the button and they're looking at a

00:13:32,300 --> 00:13:39,380
spinner which sort of implies that the

00:13:37,120 --> 00:13:40,940
answer to this question like what it

00:13:39,380 --> 00:13:42,829
actually matters is that the app gives

00:13:40,940 --> 00:13:44,000
feedback to the user if they're licking

00:13:42,829 --> 00:13:46,029
is something that doesn't appear to be

00:13:44,000 --> 00:13:49,670
doing anything that feel like it is slow

00:13:46,029 --> 00:13:52,130
but if it if it changes in some way that

00:13:49,670 --> 00:13:53,930
that feel like it's working right so I

00:13:52,130 --> 00:13:56,870
say they look for ways that I could make

00:13:53,930 --> 00:14:01,870
users feel like the app is this even if

00:13:56,870 --> 00:14:06,440
the app was actually like this so I

00:14:01,870 --> 00:14:10,310
devised three simple strategies to sort

00:14:06,440 --> 00:14:16,370
of fake out speed to like give users

00:14:10,310 --> 00:14:18,589
feedback earlier so we change document

00:14:16,370 --> 00:14:20,930
when it comes down the like list of

00:14:18,589 --> 00:14:24,079
commands to do comes down in financial

00:14:20,930 --> 00:14:27,320
the order but people in general another

00:14:24,079 --> 00:14:29,149
case specifically today in yesterday's

00:14:27,320 --> 00:14:31,339
way more interesting than three weeks

00:14:29,149 --> 00:14:33,649
ago and last month so we would parsing

00:14:31,339 --> 00:14:36,950
this XML document and sticking it away I

00:14:33,649 --> 00:14:40,070
maybe we'll just added dot reverse smell

00:14:36,950 --> 00:14:42,350
change and it just put the more

00:14:40,070 --> 00:14:47,500
interesting stuff to be processed first

00:14:42,350 --> 00:14:50,120
in the huge list I also then like

00:14:47,500 --> 00:14:52,029
realized there are three kinds of

00:14:50,120 --> 00:14:55,699
changes but in the case of it delete

00:14:52,029 --> 00:14:57,110
that documents not there there's movie

00:14:55,699 --> 00:15:00,890
can just spend half a second to get a

00:14:57,110 --> 00:15:03,080
404 so don't make a call and updates are

00:15:00,890 --> 00:15:05,600
metadata only like if you move

00:15:03,080 --> 00:15:07,610
folder to another that's reflected in

00:15:05,600 --> 00:15:11,960
the update command so you don't mean to

00:15:07,610 --> 00:15:15,170
fetch the big documents body memories

00:15:11,960 --> 00:15:17,480
and spend half a second only add do we

00:15:15,170 --> 00:15:18,530
actually need the document buddy so that

00:15:17,480 --> 00:15:19,760
we can send it to the bayesian

00:15:18,530 --> 00:15:22,700
classifier to find out if it's

00:15:19,760 --> 00:15:24,860
interesting so that's like two out of

00:15:22,700 --> 00:15:27,170
three cases that I didn't have to make

00:15:24,860 --> 00:15:30,250
the call it's not doing much faster it's

00:15:27,170 --> 00:15:35,090
just doing less of it and then the third

00:15:30,250 --> 00:15:38,410
is a persistent HTTP connection so i was

00:15:35,090 --> 00:15:42,050
using faraday which is a gem that

00:15:38,410 --> 00:15:45,200
presents a limb foam api for dealing

00:15:42,050 --> 00:15:47,750
with HTTP requests i mean you can switch

00:15:45,200 --> 00:15:50,090
out the sort of back end of it they call

00:15:47,750 --> 00:15:52,460
it an adapter for how it actually makes

00:15:50,090 --> 00:15:55,010
us so out of the box it uses net HTTP

00:15:52,460 --> 00:15:57,920
from the standard library and i already

00:15:55,010 --> 00:16:01,430
had a faraday config block that was

00:15:57,920 --> 00:16:04,490
doing other configuration so i installed

00:16:01,430 --> 00:16:07,940
the gym net HTTP persistent added the

00:16:04,490 --> 00:16:09,740
one line and it uses it what the net

00:16:07,940 --> 00:16:12,790
HTTP persistent does is we make a

00:16:09,740 --> 00:16:15,080
request to a house to hold on to that

00:16:12,790 --> 00:16:16,790
connection for a little while so that if

00:16:15,080 --> 00:16:20,660
you make a request to the same host it

00:16:16,790 --> 00:16:22,580
reuses the connection so it saves on

00:16:20,660 --> 00:16:31,010
setup and teardown time and just kind of

00:16:22,580 --> 00:16:36,260
handles it for you so my three simple

00:16:31,010 --> 00:16:39,770
acts well if fixes i should say this is

00:16:36,260 --> 00:16:42,320
the time for various benchmarks before I

00:16:39,770 --> 00:16:43,970
made my three changes the way that I got

00:16:42,320 --> 00:16:48,080
this i sat down next to the iOS

00:16:43,970 --> 00:16:50,690
developer and he when his the app in the

00:16:48,080 --> 00:16:53,050
test thing on his computer and they SAT

00:16:50,690 --> 00:16:57,040
with my phone and like hit the stopwatch

00:16:53,050 --> 00:16:59,170
so it's super scientific but the

00:16:57,040 --> 00:17:01,690
feedback is the time

00:16:59,170 --> 00:17:04,809
and like finishing sign up to having the

00:17:01,690 --> 00:17:06,490
app show some change the total sync time

00:17:04,809 --> 00:17:08,829
is like the time that this my sync

00:17:06,490 --> 00:17:10,329
process had seen the last document and

00:17:08,829 --> 00:17:12,459
then you can see three minutes later

00:17:10,329 --> 00:17:14,169
that's the last time that the bayesian

00:17:12,459 --> 00:17:15,880
class of like the time at which the

00:17:14,169 --> 00:17:19,630
bayesian classifier had seen the last

00:17:15,880 --> 00:17:24,250
message so i made three changes I mean

00:17:19,630 --> 00:17:26,799
times went like this be like 15 minutes

00:17:24,250 --> 00:17:29,080
to two and a half minutes I felt so good

00:17:26,799 --> 00:17:31,330
I was like I am a best programmer I'm

00:17:29,080 --> 00:17:36,040
pretty sure that's all net HTTP

00:17:31,330 --> 00:17:37,540
persistent no but largely so a little

00:17:36,040 --> 00:17:39,880
bit about this like a cut the feedback

00:17:37,540 --> 00:17:41,290
time in half I was like awesome so I

00:17:39,880 --> 00:17:44,110
took it to the product on me and I was

00:17:41,290 --> 00:17:46,840
like look it's like twice as fast now

00:17:44,110 --> 00:17:48,429
it's it's it's way better and it only

00:17:46,840 --> 00:17:50,410
took a day didn't take that week I was

00:17:48,429 --> 00:17:53,799
talking about you know he's like that's

00:17:50,410 --> 00:18:02,080
that's really great then but hmm that's

00:17:53,799 --> 00:18:05,919
like half a minute right it's bad but

00:18:02,080 --> 00:18:08,650
it's still not not good enough so

00:18:05,919 --> 00:18:10,390
clearly ship that but then I went back

00:18:08,650 --> 00:18:13,450
to the drawing board and started to

00:18:10,390 --> 00:18:16,990
learn about actual speed so now we're

00:18:13,450 --> 00:18:18,250
going to talk about threads and before

00:18:16,990 --> 00:18:19,270
you talk about threads I need to talk

00:18:18,250 --> 00:18:24,520
about something called the global

00:18:19,270 --> 00:18:26,650
interpreter lock or the GI oh so you if

00:18:24,520 --> 00:18:28,480
you have two threads which are trying to

00:18:26,650 --> 00:18:31,780
which need the interpreter to execute

00:18:28,480 --> 00:18:33,669
whatever they're doing and one of them

00:18:31,780 --> 00:18:36,669
will have the attention of the

00:18:33,669 --> 00:18:39,549
interpreter serve to be doing it Stefan

00:18:36,669 --> 00:18:41,830
has a a global lack so your other thread

00:18:39,549 --> 00:18:44,049
has to wait until it is done with the

00:18:41,830 --> 00:18:45,730
interpreter then it can run there like

00:18:44,049 --> 00:18:47,860
practical fallout is if you have

00:18:45,730 --> 00:18:50,230
something that takes a minute and you

00:18:47,860 --> 00:18:51,880
can do it 10 times doing it in a row

00:18:50,230 --> 00:18:54,610
takes 10 minutes you might think oh I'll

00:18:51,880 --> 00:18:57,760
do 10 threads I'll do it all in parallel

00:18:54,610 --> 00:18:59,350
and it will take one minute but if what

00:18:57,760 --> 00:19:00,280
you're doing means the interpreter it

00:18:59,350 --> 00:19:02,560
means it 14

00:19:00,280 --> 00:19:04,750
we'll have no lock and do whatever it's

00:19:02,560 --> 00:19:06,460
going to do and then it's done and it

00:19:04,750 --> 00:19:09,610
will unlock and somebody else will grab

00:19:06,460 --> 00:19:11,200
it and it will do in an unlock so you

00:19:09,610 --> 00:19:12,790
have 10 beds but you still end up

00:19:11,200 --> 00:19:17,190
running your 10 things in sequence and

00:19:12,790 --> 00:19:21,070
it still takes 10 minutes yeah note I

00:19:17,190 --> 00:19:22,570
said if it needs the attention of the

00:19:21,070 --> 00:19:24,550
interpreter to do whatever it's doing

00:19:22,570 --> 00:19:28,030
which kind of implies that some stuff

00:19:24,550 --> 00:19:30,670
doesn't need the interpreter so what's

00:19:28,030 --> 00:19:32,770
parallel what's not things that are not

00:19:30,670 --> 00:19:34,930
parallel which need the interpreter is

00:19:32,770 --> 00:19:38,410
like mucking out the things in memory

00:19:34,930 --> 00:19:41,230
like reversing away or doing math or

00:19:38,410 --> 00:19:43,480
most methods that you will call on most

00:19:41,230 --> 00:19:46,870
objects that you run into the things

00:19:43,480 --> 00:19:50,950
that all parallel are basically anything

00:19:46,870 --> 00:19:53,620
the needs that will use a system call so

00:19:50,950 --> 00:19:55,650
if you mean from the file system call if

00:19:53,620 --> 00:19:58,840
you sleep for 10 seconds system call

00:19:55,650 --> 00:20:01,030
notably for me if you do I own select

00:19:58,840 --> 00:20:02,860
system call because it's using the

00:20:01,030 --> 00:20:06,730
system's talk to the networking hardware

00:20:02,860 --> 00:20:08,950
which is talking through whatever so for

00:20:06,730 --> 00:20:12,790
our case because we identified that as

00:20:08,950 --> 00:20:16,540
the bottleneck see we these threads were

00:20:12,790 --> 00:20:20,290
actually really great way to get some

00:20:16,540 --> 00:20:21,970
speed no this is a serious Pacific

00:20:20,290 --> 00:20:27,010
jovian other implementations of

00:20:21,970 --> 00:20:29,880
different parallelization stories so

00:20:27,010 --> 00:20:32,620
okay if you don't you're threading them

00:20:29,880 --> 00:20:35,530
you canna you have to manage them so the

00:20:32,620 --> 00:20:37,540
real reason why those three changes were

00:20:35,530 --> 00:20:39,310
so easy is because they're really below

00:20:37,540 --> 00:20:40,930
footprint but when you start managing

00:20:39,310 --> 00:20:43,270
threads you're necessarily introducing

00:20:40,930 --> 00:20:49,990
more codes double codes more lines of

00:20:43,270 --> 00:20:52,330
code so they're in my thinking is

00:20:49,990 --> 00:20:54,390
basically two ways to manage threads

00:20:52,330 --> 00:20:57,580
when we're dealing with a group of figs

00:20:54,390 --> 00:21:00,610
you generally call them a pool so there

00:20:57,580 --> 00:21:02,830
are temporary fed pools and say

00:21:00,610 --> 00:21:05,140
persistent threat pools so this is kind

00:21:02,830 --> 00:21:07,300
of an example implementation of a

00:21:05,140 --> 00:21:08,790
temporary thread pool if you imagine

00:21:07,300 --> 00:21:11,670
like work items is

00:21:08,790 --> 00:21:14,790
way of say AB commands or something and

00:21:11,670 --> 00:21:16,260
my example and whenever you want to

00:21:14,790 --> 00:21:18,360
process them and called uber can you

00:21:16,260 --> 00:21:20,310
feed in the array right so with a

00:21:18,360 --> 00:21:22,260
temporary fed fool you would create an

00:21:20,310 --> 00:21:23,580
empty array for each will got him you

00:21:22,260 --> 00:21:25,980
spin up the new thread that's gonna

00:21:23,580 --> 00:21:31,080
process it whatever that means for your

00:21:25,980 --> 00:21:34,830
business I mean the next last line there

00:21:31,080 --> 00:21:37,620
you can see I'm doing this pulled on

00:21:34,830 --> 00:21:40,860
each join business so when thread a

00:21:37,620 --> 00:21:43,530
calls a joint on the thread be it means

00:21:40,860 --> 00:21:45,930
that thread a will wait for thread be to

00:21:43,530 --> 00:21:49,110
be done before it continues so in this

00:21:45,930 --> 00:21:51,300
case the third that is executing this

00:21:49,110 --> 00:21:53,040
method who wait for all the threads that

00:21:51,300 --> 00:21:55,830
had just spun up to finish before this

00:21:53,040 --> 00:21:58,350
method returns before do work returns

00:21:55,830 --> 00:22:01,260
right so that every time you have a

00:21:58,350 --> 00:22:02,970
group of work items that we want to do

00:22:01,260 --> 00:22:04,470
if we're spinning up a bunch of threads

00:22:02,970 --> 00:22:05,880
waiting for the finish and spinning and

00:22:04,470 --> 00:22:07,140
down and then we have more stuff to do

00:22:05,880 --> 00:22:10,050
we spit up a bunch of threads and we

00:22:07,140 --> 00:22:12,090
spin them down which is great because

00:22:10,050 --> 00:22:15,270
like the bookkeeping is super easy you

00:22:12,090 --> 00:22:16,710
have to like manage them really but

00:22:15,270 --> 00:22:20,370
there's some overhead with spinning up

00:22:16,710 --> 00:22:23,100
threads and hanging down and also for

00:22:20,370 --> 00:22:26,310
our case specifically net HTTP

00:22:23,100 --> 00:22:28,740
persistent keeps its handle on a

00:22:26,310 --> 00:22:31,110
connection it does it on a thread by

00:22:28,740 --> 00:22:32,520
thread basis so if we were spinning up

00:22:31,110 --> 00:22:34,530
dogs and spinning down we'd be

00:22:32,520 --> 00:22:35,940
completely throwing away all the benefit

00:22:34,530 --> 00:22:47,100
we got from holding under those

00:22:35,940 --> 00:22:49,700
connections so persistent fed pools the

00:22:47,100 --> 00:22:54,000
downside of persistent a pool is that

00:22:49,700 --> 00:22:56,340
you have to manage it a lot more and the

00:22:54,000 --> 00:22:59,430
upside is that thread pool hangs out and

00:22:56,340 --> 00:23:00,870
you send stuff to it and it stays for

00:22:59,430 --> 00:23:03,030
the life of the review process so

00:23:00,870 --> 00:23:06,270
there's you me several slide

00:23:03,030 --> 00:23:09,900
code here and I will welcome walk

00:23:06,270 --> 00:23:12,810
through them so the first few lines here

00:23:09,900 --> 00:23:14,730
we're sticking q objects into some

00:23:12,810 --> 00:23:17,750
global variables that's basically a

00:23:14,730 --> 00:23:21,480
shortcut for like the sake of concise

00:23:17,750 --> 00:23:24,390
examples on the slides but they need to

00:23:21,480 --> 00:23:26,880
be available to the threads that are

00:23:24,390 --> 00:23:29,250
doing the work and the thread that is

00:23:26,880 --> 00:23:33,360
giving work to those threads so this was

00:23:29,250 --> 00:23:36,300
a reasonable shortcut q you can think of

00:23:33,360 --> 00:23:39,270
sort of like an away except it's all

00:23:36,300 --> 00:23:42,590
push and pop and the reason that you use

00:23:39,270 --> 00:23:45,810
it when you're doing threads is that the

00:23:42,590 --> 00:23:48,270
pushes and pops are tonic so two threads

00:23:45,810 --> 00:23:50,160
are trying to pop from the same queue

00:23:48,270 --> 00:23:53,370
they were not running to each other and

00:23:50,160 --> 00:23:55,950
like pop the same value when going and

00:23:53,370 --> 00:23:58,680
get a thing and the other one will lose

00:23:55,950 --> 00:24:00,360
and get the next thing this is really

00:23:58,680 --> 00:24:03,330
important so that you can avoid like

00:24:00,360 --> 00:24:05,460
race conditions so okay well there to

00:24:03,330 --> 00:24:07,860
choose of these are going to be like we

00:24:05,460 --> 00:24:10,230
can put an output to our work threads

00:24:07,860 --> 00:24:15,330
right items go in and whatever the

00:24:10,230 --> 00:24:17,190
results are coming out I mean so then

00:24:15,330 --> 00:24:19,230
hundred times I'm gonna spin up a bunch

00:24:17,190 --> 00:24:23,100
thread its pinnacle thread and put it in

00:24:19,230 --> 00:24:28,560
this array well hundred there happen to

00:24:23,100 --> 00:24:31,230
be 0 so I had to do some experimentation

00:24:28,560 --> 00:24:34,350
with my code to find the right number of

00:24:31,230 --> 00:24:37,110
threads to spin up there's basically you

00:24:34,350 --> 00:24:39,150
will find the point most likely we're

00:24:37,110 --> 00:24:42,630
adding more threads does not add more

00:24:39,150 --> 00:24:45,810
performance and so we want like if you

00:24:42,630 --> 00:24:49,470
are doing this to experiment to find

00:24:45,810 --> 00:24:52,260
what that is for the environment gonna

00:24:49,470 --> 00:24:54,180
be pointing to so anyway how many times

00:24:52,260 --> 00:24:56,910
will spin up a thread and an image red

00:24:54,180 --> 00:25:00,420
co-worker dotwork loop we'll look at

00:24:56,910 --> 00:25:02,520
that implementation in a second so that

00:25:00,420 --> 00:25:05,100
basically sets up our thread pool which

00:25:02,520 --> 00:25:09,389
knows how to process our work then do

00:25:05,100 --> 00:25:11,969
work will pass our work items in and

00:25:09,389 --> 00:25:13,950
the the idea here is we can call do it

00:25:11,969 --> 00:25:17,219
with my work items as many times as with

00:25:13,950 --> 00:25:18,719
them they're probably in a loop in our

00:25:17,219 --> 00:25:22,709
case we were pulling the work from like

00:25:18,719 --> 00:25:25,109
our load queuing system and it will we

00:25:22,709 --> 00:25:26,729
lose the same hundred threads I'm going

00:25:25,109 --> 00:25:31,049
to have commented out pool about each

00:25:26,729 --> 00:25:33,329
join here because the whole idea here is

00:25:31,049 --> 00:25:36,989
that this drug tool is alive for the

00:25:33,329 --> 00:25:39,089
wife of the way we process so you don't

00:25:36,989 --> 00:25:42,419
need to have this thread waiting and

00:25:39,089 --> 00:25:44,279
join how those threads like you want

00:25:42,419 --> 00:25:47,669
those threads there until it will be

00:25:44,279 --> 00:25:51,749
quits and when movies quitting it will

00:25:47,669 --> 00:25:54,149
manage this all on its own so what would

00:25:51,749 --> 00:25:56,190
it work this is sort of the complicated

00:25:54,149 --> 00:26:00,479
pneus so they're good at keeping

00:25:56,190 --> 00:26:02,489
complicated pneus that go back yeah so

00:26:00,479 --> 00:26:07,559
here's workbook which is actually two

00:26:02,489 --> 00:26:11,909
slides here but so the rule like the

00:26:07,559 --> 00:26:14,489
actual work part as it were is the first

00:26:11,909 --> 00:26:16,950
balut line inside the loop so we call

00:26:14,489 --> 00:26:19,769
this method it basically a loop and it's

00:26:16,950 --> 00:26:23,279
looking for work items on work items in

00:26:19,769 --> 00:26:25,589
popping mouth passing the process well

00:26:23,279 --> 00:26:30,029
Everett earnings it's pushing them into

00:26:25,589 --> 00:26:31,889
the results q so that's why I meant

00:26:30,029 --> 00:26:36,419
earlier when I said that they were like

00:26:31,889 --> 00:26:40,619
the input and output to our kids so that

00:26:36,419 --> 00:26:43,440
like that's how your yeah your these

00:26:40,619 --> 00:26:47,489
threads actually do the work yes this is

00:26:43,440 --> 00:26:50,999
sort of book you penis here so when you

00:26:47,489 --> 00:26:53,700
try to pop them and a queue and there's

00:26:50,999 --> 00:26:57,119
nothing in it it raises thread error

00:26:53,700 --> 00:26:58,979
it's not like thread clone clone q empty

00:26:57,119 --> 00:27:02,869
area or anything helpful like that it's

00:26:58,979 --> 00:27:02,869
just thread error so

00:27:02,960 --> 00:27:06,919
you have to plan for this eventuality

00:27:04,309 --> 00:27:09,799
unless you can guarantee that there's

00:27:06,919 --> 00:27:13,309
always something in your queue in our

00:27:09,799 --> 00:27:16,039
case this was expected because the

00:27:13,309 --> 00:27:19,520
worker may or may not have a sink at any

00:27:16,039 --> 00:27:22,429
given instant and we just went into like

00:27:19,520 --> 00:27:25,070
oh there's nothing in cool look again so

00:27:22,429 --> 00:27:26,779
we just you know we try there it goes

00:27:25,070 --> 00:27:30,490
back to the top of the work with method

00:27:26,779 --> 00:27:33,230
enters the loop and tries to pop again

00:27:30,490 --> 00:27:35,169
that's like exceptions is flow control

00:27:33,230 --> 00:27:40,000
but that's the way Q is implemented and

00:27:35,169 --> 00:27:42,919
it's a tenacious I have to deal with so

00:27:40,000 --> 00:27:45,770
the other thing that's my slide

00:27:42,919 --> 00:27:50,570
transition to scroll down the other

00:27:45,770 --> 00:27:52,399
thing is because we begs to be alive as

00:27:50,570 --> 00:27:56,090
long as the Ruby process they give me

00:27:52,399 --> 00:27:57,320
bulletproof so here in rescuing standard

00:27:56,090 --> 00:27:59,390
error because if anything goes wrong

00:27:57,320 --> 00:28:05,240
when I'm trying to process for whatever

00:27:59,390 --> 00:28:07,940
um I walk it I want to know about it but

00:28:05,240 --> 00:28:12,770
I don't want that exception to kill this

00:28:07,940 --> 00:28:15,020
thread so I log it and in this case I'm

00:28:12,770 --> 00:28:17,360
sticking the symbol error in the results

00:28:15,020 --> 00:28:21,860
Q so that I like communicate something

00:28:17,360 --> 00:28:23,659
that well I mean we try note retry does

00:28:21,860 --> 00:28:26,840
not mean we try the work that just raise

00:28:23,659 --> 00:28:28,010
an exception that that work just got

00:28:26,840 --> 00:28:29,809
dropped on the floor because this is

00:28:28,010 --> 00:28:32,390
kind of a naive implementation in our

00:28:29,809 --> 00:28:37,789
case that was fine in many cases you

00:28:32,390 --> 00:28:39,770
want to do something about that or you

00:28:37,789 --> 00:28:42,559
know you may need to store it and we try

00:28:39,770 --> 00:28:44,179
it again in five minutes or whatever so

00:28:42,559 --> 00:28:45,940
we tried just goes back to the top of

00:28:44,179 --> 00:28:48,679
this method and starts the loop again

00:28:45,940 --> 00:28:51,799
you know probably to pop another work

00:28:48,679 --> 00:28:54,590
item and actually process it so let's go

00:28:51,799 --> 00:28:56,960
back to this code that called this right

00:28:54,590 --> 00:28:59,149
so all that stuff we just talked about

00:28:56,960 --> 00:29:03,340
is happening in each other hundred

00:28:59,149 --> 00:29:06,040
threads there's there's still nothing

00:29:03,340 --> 00:29:08,050
item sku so like at this point movies

00:29:06,040 --> 00:29:10,150
executing of this lines there's a

00:29:08,050 --> 00:29:14,140
hundred fills fiddling pop nothing pop

00:29:10,150 --> 00:29:16,150
nothing pop nothing hit do work so last

00:29:14,140 --> 00:29:19,630
time do it was like the whole thing with

00:29:16,150 --> 00:29:25,570
our temporary thread pool now jus work

00:29:19,630 --> 00:29:27,820
is pretty simple so we pass in array of

00:29:25,570 --> 00:29:30,760
stuff we iterate and each one we just

00:29:27,820 --> 00:29:32,710
put it in work items in queue and it

00:29:30,760 --> 00:29:36,190
will get handled by our persistent pool

00:29:32,710 --> 00:29:37,600
I mean I have a cop-out comment do

00:29:36,190 --> 00:29:41,550
something interesting with work item

00:29:37,600 --> 00:29:44,170
results so in our case I needed to know

00:29:41,550 --> 00:29:46,180
that all the items I had queued to be

00:29:44,170 --> 00:29:47,950
worked on had finished so I counted the

00:29:46,180 --> 00:29:49,840
items as I put them in and then I

00:29:47,950 --> 00:29:51,970
counted the items as they came out and

00:29:49,840 --> 00:29:54,790
when those numbers were the same I could

00:29:51,970 --> 00:30:00,190
make the timestamp and trigger some post

00:29:54,790 --> 00:30:01,720
processing stuff so that was why it was

00:30:00,190 --> 00:30:03,550
important for me to stick this error

00:30:01,720 --> 00:30:05,080
symbol in the case of an exception so

00:30:03,550 --> 00:30:07,000
that there would be ni dont account

00:30:05,080 --> 00:30:12,450
instead of having this just wait on

00:30:07,000 --> 00:30:17,020
stuff that was never going to return so

00:30:12,450 --> 00:30:20,530
I wanted to go forward okay so

00:30:17,020 --> 00:30:23,140
everybody's you move aside so then the

00:30:20,530 --> 00:30:25,210
times after nine three simple changes

00:30:23,140 --> 00:30:27,190
then I took my it ended up being about a

00:30:25,210 --> 00:30:30,070
week to learn about threads and

00:30:27,190 --> 00:30:35,260
implement persistent thread pooling and

00:30:30,070 --> 00:30:37,750
the times did this so like two and a

00:30:35,260 --> 00:30:40,210
half went to a minute felt really good

00:30:37,750 --> 00:30:41,950
about that 17 seconds still kind of

00:30:40,210 --> 00:30:45,920
running in like looking at your phone

00:30:41,950 --> 00:30:48,590
time but it's important to you

00:30:45,920 --> 00:30:50,960
doing performance stuff like there's

00:30:48,590 --> 00:30:56,090
almost always something you can do to

00:30:50,960 --> 00:30:57,560
make your code faster but but just stop

00:30:56,090 --> 00:31:00,280
somewhere so you have to make a

00:30:57,560 --> 00:31:02,570
determination of what is fast enough and

00:31:00,280 --> 00:31:04,370
our determination was for the time

00:31:02,570 --> 00:31:06,890
investment this is fast enough for now

00:31:04,370 --> 00:31:09,980
and if we like we have some other

00:31:06,890 --> 00:31:11,420
priority stuff that we need to get to

00:31:09,980 --> 00:31:13,490
and make Schafer back and try to make it

00:31:11,420 --> 00:31:18,710
even faster like we have some other

00:31:13,490 --> 00:31:22,160
ideas to try so yeah one minute to 17

00:31:18,710 --> 00:31:26,360
seconds very good about that so I've

00:31:22,160 --> 00:31:28,790
kind of had a lot all at once so let's

00:31:26,360 --> 00:31:32,150
kind of go back and review and then

00:31:28,790 --> 00:31:33,560
we'll do questions so first step you're

00:31:32,150 --> 00:31:35,450
worried about foments something takes

00:31:33,560 --> 00:31:38,780
too long first is to figure out what is

00:31:35,450 --> 00:31:40,820
actually taking too long and top iostat

00:31:38,780 --> 00:31:44,180
proof tools dot RB are your friends for

00:31:40,820 --> 00:31:47,780
that the second question to ask is can I

00:31:44,180 --> 00:31:50,240
pretend you know can you give these your

00:31:47,780 --> 00:31:52,850
feedback earlier or like in our case

00:31:50,240 --> 00:31:56,240
reverse so it's something can you

00:31:52,850 --> 00:31:58,940
distract the user so people talk about

00:31:56,240 --> 00:32:00,860
putting mirrors in elevator lobbies and

00:31:58,940 --> 00:32:02,750
even though the elevator does not come

00:32:00,860 --> 00:32:05,300
faster people feel like it doesn't take

00:32:02,750 --> 00:32:07,160
as long so like if you show the user a

00:32:05,300 --> 00:32:11,930
tutorial level waiting they're not like

00:32:07,160 --> 00:32:14,630
just waiting by running right then you

00:32:11,930 --> 00:32:18,920
know if that's not going to cut it you

00:32:14,630 --> 00:32:20,360
can go to threads remember in MLA you

00:32:18,920 --> 00:32:23,810
have to deal with the global interpreter

00:32:20,360 --> 00:32:28,190
lock which means you can paralyze I oboe

00:32:23,810 --> 00:32:30,530
and other things I low and Eugene your

00:32:28,190 --> 00:32:35,120
threads their blood pools there's two

00:32:30,530 --> 00:32:39,520
kinds temporary and persistent so I'm

00:32:35,120 --> 00:32:39,520

YouTube URL: https://www.youtube.com/watch?v=oKQBgNebEOI


