Title: LA RubyConf 2010 - Everything you ever wanted to know about threads...
Publication date: 2020-01-29
Playlist: LA RubyConf 2010
Description: 
	Everything you ever wanted to know about threads and fibers but were afraid to ask by: Joe Damato and Aman Gupta
Captions: 
	00:07:45,979 --> 00:07:49,050
etrust if you use it on the command line

00:07:47,970 --> 00:07:52,590
it's sort of like a wrapper around

00:07:49,050 --> 00:07:55,760
dtrace it doesn't give as fine grain

00:07:52,590 --> 00:08:00,200
output but it's useful

00:07:55,760 --> 00:08:02,390
um alright so let's estrace Ruby what

00:08:00,200 --> 00:08:07,460
happens when you guys trace Ruby you get

00:08:02,390 --> 00:08:09,050
this ah so you know what's the sig feety

00:08:07,460 --> 00:08:11,600
alarm they just come up like crazy all

00:08:09,050 --> 00:08:14,300
over the place what does that mean so it

00:08:11,600 --> 00:08:16,610
turns out that Ruby uses a system called

00:08:14,300 --> 00:08:18,470
called set I timer and signals to

00:08:16,610 --> 00:08:19,490
schedule green threads and this only

00:08:18,470 --> 00:08:21,200
happens in the case where you're not

00:08:19,490 --> 00:08:23,600
building Ruby with enable pthread which

00:08:21,200 --> 00:08:24,710
we'll get into a little bit but the

00:08:23,600 --> 00:08:27,500
first time a new trick us right is

00:08:24,710 --> 00:08:29,360
graded in Ruby Ruby calls set I timer to

00:08:27,500 --> 00:08:31,520
create a timer and it tells the colonel

00:08:29,360 --> 00:08:33,050
hey every 10 milliseconds send me a sick

00:08:31,520 --> 00:08:35,870
VT alarm I want to know what's going on

00:08:33,050 --> 00:08:38,150
and then one really gets that signal it

00:08:35,870 --> 00:08:39,560
fires a handler cold catch timer so the

00:08:38,150 --> 00:08:43,160
second call down there positive signal

00:08:39,560 --> 00:08:44,120
is attaching that handler that signal so

00:08:43,160 --> 00:08:46,010
let's take a look at the code in the

00:08:44,120 --> 00:08:50,620
Ruby VM sort of an abbreviated version

00:08:46,010 --> 00:08:53,510
of what's going on you can see here that

00:08:50,620 --> 00:08:54,680
you have your RV thread start 0 function

00:08:53,510 --> 00:08:56,690
over there on the right that's called

00:08:54,680 --> 00:08:59,030
every time a new thread is started the

00:08:56,690 --> 00:09:00,500
first time you start a thread it'll flip

00:08:59,030 --> 00:09:02,380
the flag thread in it saying hey we

00:09:00,500 --> 00:09:04,490
started the timer they're good to go

00:09:02,380 --> 00:09:06,680
POSIX signal right there is attaching

00:09:04,490 --> 00:09:11,750
the catch timer handler function to the

00:09:06,680 --> 00:09:13,730
e to the signal and RV's red star timer

00:09:11,750 --> 00:09:16,580
is calling set timer down there saying

00:09:13,730 --> 00:09:18,110
hey our handler set up we want to get

00:09:16,580 --> 00:09:20,570
signals every 10 milliseconds so we can

00:09:18,110 --> 00:09:21,890
time stuff so if you guys trace Ruby you

00:09:20,570 --> 00:09:23,810
can actually see this happen you attach

00:09:21,890 --> 00:09:25,160
estrace you see a call said I timer you

00:09:23,810 --> 00:09:27,680
see the sick VT alarms come in

00:09:25,160 --> 00:09:29,880
everything's cool but the big problem

00:09:27,680 --> 00:09:31,530
here is that

00:09:29,880 --> 00:09:33,450
so the big problem is that when you

00:09:31,530 --> 00:09:34,950
start a one thread even after all your

00:09:33,450 --> 00:09:36,540
threads die the timer still happens

00:09:34,950 --> 00:09:39,900
every 10 milliseconds interrupting all

00:09:36,540 --> 00:09:41,070
your code which is bad and if you guys

00:09:39,900 --> 00:09:42,960
trace your Ruby code you may say hey

00:09:41,070 --> 00:09:46,410
like I'm not using threads so you know

00:09:42,960 --> 00:09:49,230
what's the deal well net HTTP use this

00:09:46,410 --> 00:09:51,840
time out and Nessen feel so use timeout

00:09:49,230 --> 00:09:54,030
and timeout is built on threads and so

00:09:51,840 --> 00:09:55,530
once you spawn a single thread this time

00:09:54,030 --> 00:09:57,090
out the timer that's eating your

00:09:55,530 --> 00:09:58,940
reprocess like I said before we'll

00:09:57,090 --> 00:10:05,550
continue interrupting your Ruby process

00:09:58,940 --> 00:10:08,460
forever which is bad so we wrote a patch

00:10:05,550 --> 00:10:09,780
the Ruby VM stop the threat timer it's

00:10:08,460 --> 00:10:11,730
pretty simple this check basically says

00:10:09,780 --> 00:10:13,170
hey if I'm the last thread turn off the

00:10:11,730 --> 00:10:14,910
thread timer stop interrupting my Ruby

00:10:13,170 --> 00:10:17,220
process I want to be able to run code

00:10:14,910 --> 00:10:19,610
you attach ashtrays you can see the

00:10:17,220 --> 00:10:22,020
timer starts some threads were spawned

00:10:19,610 --> 00:10:26,640
alarms came in and taemin was turned off

00:10:22,020 --> 00:10:28,380
um so this is actually a pretty big win

00:10:26,640 --> 00:10:30,000
our code started running faster we'd

00:10:28,380 --> 00:10:31,350
have to worry about stuff so the next

00:10:30,000 --> 00:10:33,030
big performance improve we did on the

00:10:31,350 --> 00:10:35,640
threading implication was hey we use

00:10:33,030 --> 00:10:38,190
debian debian servers in production we s

00:10:35,640 --> 00:10:39,570
traced our rear process because we were

00:10:38,190 --> 00:10:43,170
like oh wow this review process is

00:10:39,570 --> 00:10:45,780
really really slow what's the deal um so

00:10:43,170 --> 00:10:47,430
we catch ashtrays we saw all these calls

00:10:45,780 --> 00:10:49,110
to sig proc masks were like okay let's

00:10:47,430 --> 00:10:52,650
get a count of how many of these how

00:10:49,110 --> 00:10:55,380
many calls or it looks like a lot we're

00:10:52,650 --> 00:10:56,910
going to edge trace and there's three

00:10:55,380 --> 00:11:00,990
and a half million calls to fig proc

00:10:56,910 --> 00:11:05,400
math in about 100 seconds which is a

00:11:00,990 --> 00:11:06,300
large number of system goals so what's

00:11:05,400 --> 00:11:09,030
the deal with that like why is that

00:11:06,300 --> 00:11:10,890
happening well it turns out that when

00:11:09,030 --> 00:11:12,660
you enable pthread what it's actually

00:11:10,890 --> 00:11:14,250
what the Ruby VM is actually doing sort

00:11:12,660 --> 00:11:15,570
of a little bit confusing a lot of

00:11:14,250 --> 00:11:17,370
people think that when you pass an able

00:11:15,570 --> 00:11:18,480
pthread to configure when you build Ruby

00:11:17,370 --> 00:11:21,090
18 that you're telling groovy to use

00:11:18,480 --> 00:11:22,620
native threads that's not the case when

00:11:21,090 --> 00:11:24,660
you pass an able p threaded saying hey

00:11:22,620 --> 00:11:26,700
use a native fed on the system to do the

00:11:24,660 --> 00:11:30,840
timing for the green thread

00:11:26,700 --> 00:11:32,220
implementation and so it's also enabling

00:11:30,840 --> 00:11:34,950
p throw is also useful for compatibility

00:11:32,220 --> 00:11:37,320
with like ruby TK and other stuff that

00:11:34,950 --> 00:11:38,580
uses native threading but if you just

00:11:37,320 --> 00:11:40,320
look at a diff of what happens when you

00:11:38,580 --> 00:11:42,060
enable pthread you get these other

00:11:40,320 --> 00:11:45,930
defines that pop up and then those

00:11:42,060 --> 00:11:48,210
defines create your timer thread if

00:11:45,930 --> 00:11:50,850
you're using enable pthread and there's

00:11:48,210 --> 00:11:53,870
other funds go on to which we'll talk

00:11:50,850 --> 00:11:53,870
about what that means right now

00:11:53,940 --> 00:11:58,690
so it turns out that if you look at the

00:11:57,160 --> 00:12:01,030
bottom to define their its enabling get

00:11:58,690 --> 00:12:02,320
context and set context so what are

00:12:01,030 --> 00:12:08,560
those functions what they mean or they

00:12:02,320 --> 00:12:10,810
do what's the deal so get complex asset

00:12:08,560 --> 00:12:13,210
context are part of a system in the

00:12:10,810 --> 00:12:14,680
kernel called view context and it turns

00:12:13,210 --> 00:12:17,050
out that Ruby can either use set jump

00:12:14,680 --> 00:12:18,880
and long jump or set context and get

00:12:17,050 --> 00:12:21,610
contacts in the threading implementation

00:12:18,880 --> 00:12:24,340
and for exception handling on and so

00:12:21,610 --> 00:12:25,990
what they do is set context your

00:12:24,340 --> 00:12:27,490
contacts and set jump long jump family

00:12:25,990 --> 00:12:29,650
they save and restore the current cpu

00:12:27,490 --> 00:12:31,180
state so you can save state execute some

00:12:29,650 --> 00:12:34,090
code something bad happens restore and

00:12:31,180 --> 00:12:35,980
go back to root for so set jump and long

00:12:34,090 --> 00:12:38,680
jump do similar things to get contacts

00:12:35,980 --> 00:12:39,550
and set context except that you contacts

00:12:38,680 --> 00:12:41,260
is sort of a more advanced version

00:12:39,550 --> 00:12:43,060
allows you to modify the internal state

00:12:41,260 --> 00:12:44,920
the downside is though is that these two

00:12:43,060 --> 00:12:47,740
functions save and restore the signal

00:12:44,920 --> 00:12:49,510
mask and hence call sig proc mask which

00:12:47,740 --> 00:12:51,430
is why we're hitting three and a half

00:12:49,510 --> 00:12:53,980
million of these calls every time we run

00:12:51,430 --> 00:12:55,510
Ruby for a short amount of time so it's

00:12:53,980 --> 00:12:58,540
pretty simple patch to fix this guy I

00:12:55,510 --> 00:13:00,430
just patched you fit your script tell it

00:12:58,540 --> 00:13:02,470
enabled new flag called disable you

00:13:00,430 --> 00:13:03,970
contacts so this does that says hey I

00:13:02,470 --> 00:13:08,320
want the timer thread but I don't want

00:13:03,970 --> 00:13:09,790
you to call sig sig proc mask so with

00:13:08,320 --> 00:13:11,380
this patch you can next race again all

00:13:09,790 --> 00:13:14,740
the sick proc mask calls are gone and

00:13:11,380 --> 00:13:17,250
Ruby's now thirty percent faster which

00:13:14,740 --> 00:13:17,250
is pretty sick

00:13:18,160 --> 00:13:24,380
cool so I maintain the event machine gem

00:13:21,800 --> 00:13:37,040
and there was a long-standing problem

00:13:24,380 --> 00:13:39,140
that so there was a long-standing

00:13:37,040 --> 00:13:42,890
problem in the event machine gem where

00:13:39,140 --> 00:13:44,750
if you used mm machine withypol and with

00:13:42,890 --> 00:13:49,340
threads in the Ruby VM everything would

00:13:44,750 --> 00:13:52,340
basically be unusually slow so I decided

00:13:49,340 --> 00:13:54,590
I need to take a look at this and this

00:13:52,340 --> 00:13:57,520
was especially a problem because we were

00:13:54,590 --> 00:13:57,520
using thin and

00:13:57,580 --> 00:14:03,660
somewhere in our code using that HP

00:14:00,040 --> 00:14:06,430
which would enable this timer thread or

00:14:03,660 --> 00:14:08,110
it would start the timer signals coming

00:14:06,430 --> 00:14:11,620
in and everything was sort of grind to a

00:14:08,110 --> 00:14:14,200
halt so I knew I had to profile it so i

00:14:11,620 --> 00:14:19,240
started out basically building a simple

00:14:14,200 --> 00:14:21,430
group review a repro case basically so

00:14:19,240 --> 00:14:23,830
in a man-machine amad machine basically

00:14:21,430 --> 00:14:26,230
handled network I oh and it allocates

00:14:23,830 --> 00:14:28,710
big buffers on sack to copy incoming

00:14:26,230 --> 00:14:31,800
data and

00:14:28,710 --> 00:14:34,140
passes at de Ruby so I wrote a simple C

00:14:31,800 --> 00:14:36,690
extension that basically called the c

00:14:34,140 --> 00:14:38,970
function which allocates a large buffer

00:14:36,690 --> 00:14:40,560
on the stack and then after al cayman

00:14:38,970 --> 00:14:42,870
that buffer goes back and groovy and

00:14:40,560 --> 00:14:45,540
basically excuse a bunch of Ruby code

00:14:42,870 --> 00:14:47,280
and does a lot of threading and so I

00:14:45,540 --> 00:14:49,110
started running this through profiler

00:14:47,280 --> 00:14:52,620
and we decided to use google / tools

00:14:49,110 --> 00:14:54,360
which is basically the profiler that

00:14:52,620 --> 00:14:56,970
Google uses internally it's really cool

00:14:54,360 --> 00:14:58,650
it works really well so the way you use

00:14:56,970 --> 00:15:01,350
this is you can you can download it

00:14:58,650 --> 00:15:02,820
compile it the way you use it is it

00:15:01,350 --> 00:15:05,100
fills the shared library that you can

00:15:02,820 --> 00:15:08,460
either link to your application or

00:15:05,100 --> 00:15:10,530
preload so on Linux you can set LD

00:15:08,460 --> 00:15:12,510
preload or on OSX there's an equivalent

00:15:10,530 --> 00:15:15,120
and basically once you set this

00:15:12,510 --> 00:15:17,220
environment variable any binaries you

00:15:15,120 --> 00:15:19,170
launch will first load this library

00:15:17,220 --> 00:15:21,570
before doing anything else so once

00:15:19,170 --> 00:15:24,750
you've loaded this library all you have

00:15:21,570 --> 00:15:26,970
to do is set a environment variable

00:15:24,750 --> 00:15:29,580
called CPU profile and point that at a

00:15:26,970 --> 00:15:31,020
file name and once the binary finishes

00:15:29,580 --> 00:15:33,630
running is going to dump out a whole

00:15:31,020 --> 00:15:34,800
bunch of statistics to that file once

00:15:33,630 --> 00:15:36,570
you've created that file all you have to

00:15:34,800 --> 00:15:39,570
do is run this perl script they bundle

00:15:36,570 --> 00:15:41,550
fault p prof on that and it gives you a

00:15:39,570 --> 00:15:44,070
bunch of output so the cool thing about

00:15:41,550 --> 00:15:45,630
this profilers not only does have ruiz

00:15:44,070 --> 00:15:48,750
full text output you can create these

00:15:45,630 --> 00:15:50,040
really nice graphs ah and you can just

00:15:48,750 --> 00:15:52,570
look at this graph and tell right away

00:15:50,040 --> 00:15:55,100
what's taking most amount of time

00:15:52,570 --> 00:15:57,050
so I ran this on the event machine

00:15:55,100 --> 00:15:59,779
threading problem and I got back

00:15:57,050 --> 00:16:01,430
something like this and there were some

00:15:59,779 --> 00:16:03,800
candidates that made sense deadly

00:16:01,430 --> 00:16:06,200
thread-safe contacts to restore contacts

00:16:03,800 --> 00:16:09,230
but it turned out they were all calling

00:16:06,200 --> 00:16:11,899
mem copy and this was really surprising

00:16:09,230 --> 00:16:13,850
I didn't really believe it at first so I

00:16:11,899 --> 00:16:16,370
was like this can't be true like mem

00:16:13,850 --> 00:16:17,839
copy was taking that long so I decided

00:16:16,370 --> 00:16:19,370
to try yet another tool and try to

00:16:17,839 --> 00:16:22,250
confirm that this was actually happening

00:16:19,370 --> 00:16:24,770
ah so this other tools call el traits

00:16:22,250 --> 00:16:27,950
it's very similar to estres but it

00:16:24,770 --> 00:16:30,260
traces library calls instead of system

00:16:27,950 --> 00:16:33,830
calls and the syntax is almost exactly

00:16:30,260 --> 00:16:35,089
the same so you can run this again with

00:16:33,830 --> 00:16:39,130
dash C which is sort of gives you a

00:16:35,089 --> 00:16:41,360
summary and sure enough mem copy is the

00:16:39,130 --> 00:16:43,880
first one on there and taking a large

00:16:41,360 --> 00:16:47,450
amount of time again you can run it in

00:16:43,880 --> 00:16:48,620
detailed mode and see get a little bit

00:16:47,450 --> 00:16:51,740
more information about what's going on

00:16:48,620 --> 00:16:53,690
in this case sick VT alarm right after

00:16:51,740 --> 00:16:56,240
62 alarm there were two calls to mem

00:16:53,690 --> 00:16:58,449
copy happening and all these calls were

00:16:56,240 --> 00:17:01,209
act adding up

00:16:58,449 --> 00:17:04,360
so we know it is definitely calling mem

00:17:01,209 --> 00:17:05,829
copy but the question was what is it

00:17:04,360 --> 00:17:07,269
copying and why is it coffee so much

00:17:05,829 --> 00:17:10,299
stuff like what it's what exactly is

00:17:07,269 --> 00:17:11,949
going on so we know it's getting called

00:17:10,299 --> 00:17:13,389
from threats tape context and restore

00:17:11,949 --> 00:17:17,319
context we can pull up the C code for

00:17:13,389 --> 00:17:19,240
that and sort of walk through it so the

00:17:17,319 --> 00:17:21,370
first thing that safe context does is

00:17:19,240 --> 00:17:23,429
call set jump which we talked about and

00:17:21,370 --> 00:17:26,139
we know that that saves CPU stayed away

00:17:23,429 --> 00:17:28,120
then after that it's calling the mem

00:17:26,139 --> 00:17:31,149
copy that's where the mem copy is and it

00:17:28,120 --> 00:17:33,399
looks like it's accessing the thread

00:17:31,149 --> 00:17:38,409
stack pointer and sack position and

00:17:33,399 --> 00:17:40,529
copying something so it turns out it's

00:17:38,409 --> 00:17:42,399
actually copying the entire stack

00:17:40,529 --> 00:17:43,870
associated with that thread so all the

00:17:42,399 --> 00:17:46,149
stack frames in that thread or getting

00:17:43,870 --> 00:17:48,220
copied away and then the third thing it

00:17:46,149 --> 00:17:51,730
does is save a whole bunch of VM

00:17:48,220 --> 00:17:54,279
Global's that basically tell the vmware

00:17:51,730 --> 00:17:56,830
it is a way into the thread structure

00:17:54,279 --> 00:17:58,059
and increase or context it basically

00:17:56,830 --> 00:18:00,039
does the same thing in the opposite

00:17:58,059 --> 00:18:02,799
order so it restores all those goals

00:18:00,039 --> 00:18:05,289
then in mem copy is this the stack back

00:18:02,799 --> 00:18:08,029
and then at long jumps to where the CPU

00:18:05,289 --> 00:18:10,519
had saved state

00:18:08,029 --> 00:18:12,979
so we sort of have an idea of what's

00:18:10,519 --> 00:18:15,169
going on it's actually copying stacks to

00:18:12,979 --> 00:18:19,779
the heap but what what exactly does that

00:18:15,169 --> 00:18:19,779
mean just going to explain

00:18:26,460 --> 00:18:30,039
alright so before we keep going is

00:18:28,690 --> 00:18:33,600
anybody is everybody cool there may have

00:18:30,039 --> 00:18:33,600
any questions we're at so far

00:18:34,299 --> 00:18:43,340
what's up all right all right word um so

00:18:39,620 --> 00:18:45,559
stacks versus heaps ah so all right so

00:18:43,340 --> 00:18:48,350
stacks what's the deal storage for local

00:18:45,559 --> 00:18:50,179
variables those variables are only valid

00:18:48,350 --> 00:18:52,940
well the stack frame is on the stack and

00:18:50,179 --> 00:18:54,559
as your call functions a function calls

00:18:52,940 --> 00:18:56,149
push metadata onto the stack to keep

00:18:54,559 --> 00:18:57,769
track of where you were called from

00:18:56,149 --> 00:19:00,950
we're going to go through a diagram in a

00:18:57,769 --> 00:19:02,360
second i also have you keep storage

00:19:00,950 --> 00:19:04,730
variables that persist across function

00:19:02,360 --> 00:19:07,429
calls and it's typically managed by your

00:19:04,730 --> 00:19:10,340
malc implementation so live c or t seem

00:19:07,429 --> 00:19:11,779
a lot or wherever you use so you have

00:19:10,340 --> 00:19:14,960
this function one right here that you're

00:19:11,779 --> 00:19:17,389
calling function want allocates a void

00:19:14,960 --> 00:19:19,460
pointer called data let's just assume

00:19:17,389 --> 00:19:22,940
around 32 bit so those four bytes live

00:19:19,460 --> 00:19:24,529
on the stack he calls funk too so that

00:19:22,940 --> 00:19:26,029
pushes some metadata onto the stack to

00:19:24,529 --> 00:19:27,590
say hey we're calling this function so

00:19:26,029 --> 00:19:33,409
when you're done you have to go back to

00:19:27,590 --> 00:19:35,869
funk one so long to is allocating HHR

00:19:33,409 --> 00:19:37,129
star string the storage for that pointer

00:19:35,869 --> 00:19:38,869
the pointer itself is stored on the

00:19:37,129 --> 00:19:40,309
stack the four bytes but the call to

00:19:38,869 --> 00:19:42,769
malloc right there is going to put 10

00:19:40,309 --> 00:19:45,080
bytes on the heap plus metadata needed

00:19:42,769 --> 00:19:46,179
by the malakin volant a shin and then

00:19:45,080 --> 00:19:48,679
he's going to call function three

00:19:46,179 --> 00:19:50,690
function three is allocating a buffer on

00:19:48,679 --> 00:19:52,549
the stack think hold buffer eight boys

00:19:50,690 --> 00:19:54,990
go there on the stack once function

00:19:52,549 --> 00:19:56,970
returns

00:19:54,990 --> 00:19:59,130
those eight bytes are gone and it's no

00:19:56,970 --> 00:20:03,110
longer valid and so that's sort of the

00:19:59,130 --> 00:20:05,550
deal basic gist of stacks versus heaps

00:20:03,110 --> 00:20:07,320
so we're mem copy the thread stacks what

00:20:05,550 --> 00:20:09,270
does that mean at a high level so at a

00:20:07,320 --> 00:20:10,890
high level you have your it's kind of

00:20:09,270 --> 00:20:13,620
cut off but you have your Ruby process

00:20:10,890 --> 00:20:16,500
executing and over here on the left you

00:20:13,620 --> 00:20:17,670
have your current program stack and then

00:20:16,500 --> 00:20:19,140
these are the other thread stacks and

00:20:17,670 --> 00:20:21,030
your review process that are saved on

00:20:19,140 --> 00:20:23,820
the keep waiting for when it's their

00:20:21,030 --> 00:20:25,020
turn to run so when a timer comes in our

00:20:23,820 --> 00:20:28,830
the scheduler decides it's your turn to

00:20:25,020 --> 00:20:31,590
run it copies the entire current program

00:20:28,830 --> 00:20:34,140
stack onto the heap to save the state

00:20:31,590 --> 00:20:36,570
and then it copies the next guy to run

00:20:34,140 --> 00:20:40,740
from the heat on to the current program

00:20:36,570 --> 00:20:42,120
stack over itself um so you know this is

00:20:40,740 --> 00:20:43,260
interesting like we'll figure out what's

00:20:42,120 --> 00:20:44,340
going on but you know first may be

00:20:43,260 --> 00:20:48,570
interesting to find out what's actually

00:20:44,340 --> 00:20:50,880
on these threats tax so we use gdb to

00:20:48,570 --> 00:20:52,710
figure out what the deal is going to go

00:20:50,880 --> 00:20:54,720
through a girly quick gtb overview for

00:20:52,710 --> 00:20:55,920
anybody's not used it before if you're

00:20:54,720 --> 00:20:57,720
going to experiment make sure to build

00:20:55,920 --> 00:21:00,750
gdb make sure to build your app with

00:20:57,720 --> 00:21:04,530
dash gdb and 0 0 otherwise you have to

00:21:00,750 --> 00:21:06,679
read a lot of assembly arm so gb

00:21:04,530 --> 00:21:09,440
walkthrough not too not too intense

00:21:06,679 --> 00:21:12,090
you're going GV pass in your program

00:21:09,440 --> 00:21:14,370
let's start it up there it is okay you

00:21:12,090 --> 00:21:15,960
can put a breakpoint on a function so in

00:21:14,370 --> 00:21:17,580
this case this program just calculates

00:21:15,960 --> 00:21:20,510
the average of two numbers so we set a

00:21:17,580 --> 00:21:20,510
breakpoint on average

00:21:20,800 --> 00:21:25,330
we say hey keep running gdb hits the

00:21:23,650 --> 00:21:27,610
break point freezes the program it says

00:21:25,330 --> 00:21:29,200
you know I just called average here are

00:21:27,610 --> 00:21:32,080
the two arguments this is a line of code

00:21:29,200 --> 00:21:34,540
I'm on and see you know what do you want

00:21:32,080 --> 00:21:36,460
to do so I said okay give me a back

00:21:34,540 --> 00:21:38,080
trace that'll show me okay I'm in the

00:21:36,460 --> 00:21:40,030
function average average was called from

00:21:38,080 --> 00:21:42,120
Maine sort of that idea of a stack that

00:21:40,030 --> 00:21:44,890
we just talked about a couple slides ago

00:21:42,120 --> 00:21:46,270
and you can ask you to be too so yeah

00:21:44,890 --> 00:21:48,040
that's the function stack so you can

00:21:46,270 --> 00:21:49,360
actually DB to give you to help you walk

00:21:48,040 --> 00:21:51,430
through the C code line by line so you

00:21:49,360 --> 00:21:53,320
can type s and press enter and then gdp

00:21:51,430 --> 00:21:55,750
will execute one line of c code and then

00:21:53,320 --> 00:21:57,910
let you do something else you can output

00:21:55,750 --> 00:21:59,920
local variables by just running p then

00:21:57,910 --> 00:22:00,970
the variable name so gdp has lots of

00:21:59,920 --> 00:22:03,070
stuff is just sort of a quick overview

00:22:00,970 --> 00:22:05,770
of some of the useful features you guys

00:22:03,070 --> 00:22:08,140
should definitely check it out all right

00:22:05,770 --> 00:22:10,180
so what's on the Ruby stack so we attach

00:22:08,140 --> 00:22:12,820
DVD Ruby we hit back chorizo want to see

00:22:10,180 --> 00:22:15,520
what's going on and this is just a small

00:22:12,820 --> 00:22:19,330
snippet of the entire stack trace it's

00:22:15,520 --> 00:22:21,160
pretty massive as you can see all C

00:22:19,330 --> 00:22:24,330
programs including Ruby have a main

00:22:21,160 --> 00:22:24,330
function mains all the way down here

00:22:24,450 --> 00:22:30,900
main immediately calls Ruby run which

00:22:26,940 --> 00:22:32,160
starts the Ruby vm and then we can see

00:22:30,900 --> 00:22:33,330
up here like other fragments from our

00:22:32,160 --> 00:22:35,280
Ruby code like I'm sure you guys have

00:22:33,330 --> 00:22:37,560
used you know things in numeric like if

00:22:35,280 --> 00:22:39,570
you say 5,000 times and then pass a

00:22:37,560 --> 00:22:44,040
block that actually calls the c function

00:22:39,570 --> 00:22:45,920
in due time and then into dou x ends up

00:22:44,040 --> 00:22:48,270
calling like right above that RB yield

00:22:45,920 --> 00:22:49,980
to yield to the block that was passed in

00:22:48,270 --> 00:22:52,650
so sort of fat like the inner workings

00:22:49,980 --> 00:22:55,290
of the vm go down and if you notice

00:22:52,650 --> 00:22:58,470
there's lots of calls in the stack frame

00:22:55,290 --> 00:23:01,140
and the stack trace to RB eval turns out

00:22:58,470 --> 00:23:03,000
that RV eval evaluates code in your ruby

00:23:01,140 --> 00:23:05,280
program and RV eval calls itself

00:23:03,000 --> 00:23:07,770
recursively throughout the execution

00:23:05,280 --> 00:23:10,260
time of your program and that's sort of

00:23:07,770 --> 00:23:11,520
important so we want to see like sort of

00:23:10,260 --> 00:23:12,690
you know how bigger these stack frames

00:23:11,520 --> 00:23:13,980
what's the story like you know we're

00:23:12,690 --> 00:23:15,120
seeing mem copy we're seeing a lot of

00:23:13,980 --> 00:23:18,600
stuff being copied like let's get an

00:23:15,120 --> 00:23:19,800
idea of how big were talking so this is

00:23:18,600 --> 00:23:21,720
kind of like a little bit of magic right

00:23:19,800 --> 00:23:23,280
here but basically what's going on is

00:23:21,720 --> 00:23:25,620
I'm saying I'm in gdb and I'm saying yo

00:23:23,280 --> 00:23:26,970
G be where I'm at right now I want to

00:23:25,620 --> 00:23:29,460
get the base pointer for the current

00:23:26,970 --> 00:23:31,770
stack frame and i want to subtract from

00:23:29,460 --> 00:23:34,190
it the bottom of the stack ESP these are

00:23:31,770 --> 00:23:38,700
just two cpu registers so give this

00:23:34,190 --> 00:23:43,260
pronounce out 968 bites so each RB eval

00:23:38,700 --> 00:23:45,570
stack frame is almost one kilobyte which

00:23:43,260 --> 00:23:48,090
is you know a large amount of space to

00:23:45,570 --> 00:23:49,590
be copying back and forth and if you

00:23:48,090 --> 00:23:51,450
want to get the entire distance of the

00:23:49,590 --> 00:23:54,030
stack like the entire rubyprogram stack

00:23:51,450 --> 00:23:56,880
right now ruby has a internal valuable

00:23:54,030 --> 00:23:58,230
or BGC stack start you can subtract the

00:23:56,880 --> 00:24:00,690
current bottom of the stack from that

00:23:58,230 --> 00:24:04,740
and say oh look the Ruby stack is you

00:24:00,690 --> 00:24:07,080
know 10k will get mem copy back and

00:24:04,740 --> 00:24:10,650
forth so you know if you have 50 method

00:24:07,080 --> 00:24:12,930
calls each with 1k each with 1k stack

00:24:10,650 --> 00:24:15,180
frames you end up with a 50k stack it

00:24:12,930 --> 00:24:16,560
turns out that in rails you can have

00:24:15,180 --> 00:24:18,480
several hundred method calls for a

00:24:16,560 --> 00:24:19,710
single request so we're talking about a

00:24:18,480 --> 00:24:20,790
shitload of data that's getting copied

00:24:19,710 --> 00:24:22,540
back and forth every time and threats

00:24:20,790 --> 00:24:26,890
wishes

00:24:22,540 --> 00:24:34,830
what's up man yeah nineteen sixty eight

00:24:26,890 --> 00:24:37,090
bytes for a single stack frame ah so

00:24:34,830 --> 00:24:38,350
typically like you only you don't have

00:24:37,090 --> 00:24:41,050
that much space like I would say like

00:24:38,350 --> 00:24:44,050
anywhere on the orders of you know 256

00:24:41,050 --> 00:24:47,590
256 bytes is like pushing it on the high

00:24:44,050 --> 00:24:48,850
end so the thing is that it shouldn't

00:24:47,590 --> 00:24:49,780
actually matter what you have on the

00:24:48,850 --> 00:24:53,380
stack it's just that the threading

00:24:49,780 --> 00:24:54,520
implementation is broken so it does so

00:24:53,380 --> 00:24:55,930
we're going to get into like how you fix

00:24:54,520 --> 00:25:00,660
that and like how it stops being a

00:24:55,930 --> 00:25:03,760
problem like very shortly alright so

00:25:00,660 --> 00:25:05,860
quick recap when we got to so far out of

00:25:03,760 --> 00:25:07,990
the threads and Ruby work each thread

00:25:05,860 --> 00:25:09,460
has its own execution context you say

00:25:07,990 --> 00:25:11,230
the cpu registers and you restore them

00:25:09,460 --> 00:25:14,080
with set jump and long jump you have a

00:25:11,230 --> 00:25:15,520
copy of the vm Global's and a copy of

00:25:14,080 --> 00:25:17,560
the stack that's made by calling them

00:25:15,520 --> 00:25:20,380
coffee we switch between the threat of

00:25:17,560 --> 00:25:22,360
switches between threads by executing

00:25:20,380 --> 00:25:25,240
until you get a signal from the colonel

00:25:22,360 --> 00:25:26,770
it saves the context calls scheduled to

00:25:25,240 --> 00:25:28,710
pick the next guy and then restores that

00:25:26,770 --> 00:25:31,120
that guy's contacts and he starts going

00:25:28,710 --> 00:25:32,590
and between these two phases there's two

00:25:31,120 --> 00:25:36,760
calls to bem cop you won't call to save

00:25:32,590 --> 00:25:38,020
one call to restore but you know your

00:25:36,760 --> 00:25:39,280
pain in just beginning the talk you're

00:25:38,020 --> 00:25:40,390
saying hey yeah like you just said it

00:25:39,280 --> 00:25:41,380
beginning that the whole point of green

00:25:40,390 --> 00:25:44,200
that is that they're supposed to be fast

00:25:41,380 --> 00:25:45,160
and cheap at the sacrifice of SMP you

00:25:44,200 --> 00:25:48,400
don't get multi-core but they're

00:25:45,160 --> 00:25:50,410
supposed to be fast um but you know that

00:25:48,400 --> 00:25:51,790
much copying that we're seeing with all

00:25:50,410 --> 00:25:55,480
these traces and the code we just looked

00:25:51,790 --> 00:25:57,400
at is neither fast nor cheap um so how

00:25:55,480 --> 00:26:00,250
do we fix this problem well we can fix

00:25:57,400 --> 00:26:03,490
the problem by just not copying stuff a

00:26:00,250 --> 00:26:06,370
stack is just to read it in memory so

00:26:03,490 --> 00:26:08,980
when we just point the CPU at a region

00:26:06,370 --> 00:26:10,330
of memory that lives on the heap and

00:26:08,980 --> 00:26:12,040
then we want to switch to a new thread

00:26:10,330 --> 00:26:15,520
we just swap in a new register context

00:26:12,040 --> 00:26:17,140
on the cpu and we just do no copy so it

00:26:15,520 --> 00:26:19,000
turns out that's what we can do we wrote

00:26:17,140 --> 00:26:20,710
it back to do that this is sort of a

00:26:19,000 --> 00:26:22,930
really really brief overview of these

00:26:20,710 --> 00:26:24,190
the important like a few lines that went

00:26:22,930 --> 00:26:25,030
into the patch there's lots of other

00:26:24,190 --> 00:26:27,070
stuff that has to go on behind the

00:26:25,030 --> 00:26:28,630
scenes too but I'll just sort of a quick

00:26:27,070 --> 00:26:31,720
walkthrough of the zero copy threading

00:26:28,630 --> 00:26:34,340
passion how it works so when you call RV

00:26:31,720 --> 00:26:37,400
thread start 0

00:26:34,340 --> 00:26:40,850
we allocate a thread stack by calling em

00:26:37,400 --> 00:26:42,710
map and then when it's time to switch

00:26:40,850 --> 00:26:44,390
into that threat to execute there's just

00:26:42,710 --> 00:26:46,460
a little tiny trampoline of inline

00:26:44,390 --> 00:26:48,110
assembly this inline assembly is just

00:26:46,460 --> 00:26:53,659
going to swap the stack pointer out

00:26:48,110 --> 00:26:54,799
manually to switch to the other guy and

00:26:53,659 --> 00:26:57,230
so at a high level how does that

00:26:54,799 --> 00:26:58,940
actually work it's not that crazy like

00:26:57,230 --> 00:27:00,529
you have your current executing thread

00:26:58,940 --> 00:27:01,610
over there on the left that's your

00:27:00,529 --> 00:27:03,440
current program you have these other

00:27:01,610 --> 00:27:04,789
guys that live out on the heap when a

00:27:03,440 --> 00:27:07,399
signal comes in and it's time to switch

00:27:04,789 --> 00:27:09,679
you don't copy you just run that little

00:27:07,399 --> 00:27:11,210
piece of inline assembly to swap the to

00:27:09,679 --> 00:27:12,770
swap the stack pointer to the guy who

00:27:11,210 --> 00:27:14,659
lives on the heap and you just keep

00:27:12,770 --> 00:27:15,770
executing next time I signal comes in

00:27:14,659 --> 00:27:17,450
you do the same thing you've run that

00:27:15,770 --> 00:27:19,039
little piece of assembly swap to the

00:27:17,450 --> 00:27:20,360
next guy that's on the heat you've now

00:27:19,039 --> 00:27:22,970
eliminated all the copies that we're

00:27:20,360 --> 00:27:23,899
going on in threading implantation you

00:27:22,970 --> 00:27:26,960
know what does that mean in terms of a

00:27:23,899 --> 00:27:28,279
benchmark so luckily there's people who

00:27:26,960 --> 00:27:30,380
like to benchmark things so we stole a

00:27:28,279 --> 00:27:32,809
benchmark from computer language

00:27:30,380 --> 00:27:35,029
benchmark game there's a benchmark all

00:27:32,809 --> 00:27:36,529
the thread ring benchmark and to

00:27:35,029 --> 00:27:39,830
illustrate this sort of the speed boost

00:27:36,529 --> 00:27:41,510
by this zero thread copy patch we

00:27:39,830 --> 00:27:43,760
decided to do was we're going to grow

00:27:41,510 --> 00:27:45,169
the stacks a little bit and then context

00:27:43,760 --> 00:27:47,990
switch just to show like how intense

00:27:45,169 --> 00:27:49,669
this change actually is so we wrote a

00:27:47,990 --> 00:27:51,620
little function called grow stack grow

00:27:49,669 --> 00:27:54,140
snack calls itself recursively until

00:27:51,620 --> 00:27:56,559
it's called itself 20 times and it

00:27:54,140 --> 00:27:58,929
yields to the block that was passed in

00:27:56,559 --> 00:28:02,740
ah the actual benchmark looks kind of

00:27:58,929 --> 00:28:04,600
like this it's creating 500 threads we

00:28:02,740 --> 00:28:07,090
increase the thread stack size in each

00:28:04,600 --> 00:28:09,399
thread the threads all Pauls when they

00:28:07,090 --> 00:28:12,100
first get entered into and when they

00:28:09,399 --> 00:28:13,419
resume they decrement one from the

00:28:12,100 --> 00:28:15,249
number and as you can see number all the

00:28:13,419 --> 00:28:18,580
way at the top is set to something large

00:28:15,249 --> 00:28:19,990
value like 50 million and so what this

00:28:18,580 --> 00:28:21,549
is actually doing this is just basically

00:28:19,990 --> 00:28:23,710
getting a bunch of threads together each

00:28:21,549 --> 00:28:25,809
thread is subtracting 1 from the total

00:28:23,710 --> 00:28:27,159
amount and then dq'ing itself laying the

00:28:25,809 --> 00:28:28,899
next guy run so we're really

00:28:27,159 --> 00:28:30,429
benchmarking is the cost of context

00:28:28,899 --> 00:28:31,720
switching between lots of threads as

00:28:30,429 --> 00:28:35,320
they all work together decrement this

00:28:31,720 --> 00:28:38,619
link shared object silly results we

00:28:35,320 --> 00:28:43,299
passed in 50 million on Ruby 186

00:28:38,619 --> 00:28:45,009
standard no patches I take 7400 seconds

00:28:43,299 --> 00:28:48,279
I'm saudia under second that's about 2

00:28:45,009 --> 00:28:52,679
hours and change Ruby 186 with our

00:28:48,279 --> 00:28:57,779
thread fix takes about 13 minutes

00:28:52,679 --> 00:29:00,200
um so we're pretty happy what's up you

00:28:57,779 --> 00:29:00,200
have question

00:29:07,250 --> 00:29:12,020
yeah so that's actually we're gonna talk

00:29:09,260 --> 00:29:15,440
about GC we're talking again later about

00:29:12,020 --> 00:29:19,000
GC so there's like a entire separate

00:29:15,440 --> 00:29:19,000
talk to answer your question Yosh

00:29:25,170 --> 00:29:30,120
sure sure

00:29:34,559 --> 00:29:38,220
sure so so the way so the way it sex

00:29:36,690 --> 00:29:40,620
inflated right now in the linux kernel

00:29:38,220 --> 00:29:42,779
for processes there's two models there's

00:29:40,620 --> 00:29:44,100
one model where if you fall off the end

00:29:42,779 --> 00:29:45,509
of your stack that causes a page fault

00:29:44,100 --> 00:29:47,789
the colonel sees that and maps more

00:29:45,509 --> 00:29:49,470
memory in to grow your stack but that's

00:29:47,789 --> 00:29:50,970
sort of the older model of processes in

00:29:49,470 --> 00:29:52,350
the linux kernel the current model

00:29:50,970 --> 00:29:55,740
processing lumens kernel is to basically

00:29:52,350 --> 00:29:57,330
set a system-wide value with sis comp

00:29:55,740 --> 00:29:59,490
that's just called our limit stack and

00:29:57,330 --> 00:30:01,320
that's commonly set at eight Meg's so

00:29:59,490 --> 00:30:03,870
the system on 32-bit system instead of

00:30:01,320 --> 00:30:05,610
eight Meg's so the operating system will

00:30:03,870 --> 00:30:07,019
just say in advance like like hey you're

00:30:05,610 --> 00:30:08,820
only going to get eight Meg's to execute

00:30:07,019 --> 00:30:10,019
and then once you fall off that you're

00:30:08,820 --> 00:30:11,909
screwed and the program gets killed

00:30:10,019 --> 00:30:13,049
that's just like a problem in general

00:30:11,909 --> 00:30:14,909
right like you don't have infinite space

00:30:13,049 --> 00:30:17,399
you want to jump in and it's just going

00:30:14,909 --> 00:30:19,070
to say yeah we decided just to go with

00:30:17,399 --> 00:30:21,779
the easiest solution and we added a

00:30:19,070 --> 00:30:23,279
thread got sack size and so at the

00:30:21,779 --> 00:30:26,399
beginning of a program you can set how

00:30:23,279 --> 00:30:28,679
big you want your stacks to be yeah and

00:30:26,399 --> 00:30:30,679
we decided we brainstormed about a

00:30:28,679 --> 00:30:32,820
couple solutions to growing stockist

00:30:30,679 --> 00:30:36,139
growing the stacks automatically would

00:30:32,820 --> 00:30:36,139
decided it wasn't worth it in the end

00:30:36,930 --> 00:30:40,860
cool so sort of like you know we fix

00:30:39,450 --> 00:30:43,140
this thing as fast as cool everybody's

00:30:40,860 --> 00:30:46,110
happy like what's next well RV thread

00:30:43,140 --> 00:30:47,370
schedule sucks um thread switching might

00:30:46,110 --> 00:30:49,590
be fast but the scheduler is still

00:30:47,370 --> 00:30:51,210
pretty bad um this is kind of like a

00:30:49,590 --> 00:30:53,010
little bit a cleaned up version of what

00:30:51,210 --> 00:30:54,450
it looks like so it's basically just

00:30:53,010 --> 00:30:56,700
iterating through the entire thread list

00:30:54,450 --> 00:30:59,790
over and over and over again um you know

00:30:56,700 --> 00:31:00,960
five plus times maybe more um so

00:30:59,790 --> 00:31:02,340
complexity theory will say that

00:31:00,960 --> 00:31:05,070
constants don't matter they just drop

00:31:02,340 --> 00:31:08,250
out but if you have tens of thousands of

00:31:05,070 --> 00:31:09,750
green threads ah you know going au vin

00:31:08,250 --> 00:31:12,930
over these things several times can

00:31:09,750 --> 00:31:14,730
definitely add up so what's next what we

00:31:12,930 --> 00:31:17,940
do now how do we fix this well we could

00:31:14,730 --> 00:31:19,860
rewrite the scheduler um but that's too

00:31:17,940 --> 00:31:22,260
much work so we just get rid of the

00:31:19,860 --> 00:31:26,220
scheduler and now we've come full circle

00:31:22,260 --> 00:31:29,010
we're back around at fibers so we're

00:31:26,220 --> 00:31:30,870
back wearing the fibers API to MRI to

00:31:29,010 --> 00:31:33,300
use the fast threading patch we just

00:31:30,870 --> 00:31:34,920
described so behind the scenes you just

00:31:33,300 --> 00:31:36,720
way it works you just create a thread

00:31:34,920 --> 00:31:38,880
you don't add it to the schedule list

00:31:36,720 --> 00:31:43,440
and then you schedule the thread

00:31:38,880 --> 00:31:44,250
manually with yield and resume hopefully

00:31:43,440 --> 00:31:45,810
at this point you're asking yourself

00:31:44,250 --> 00:31:49,680
like all like where can I get all its

00:31:45,810 --> 00:31:52,380
awesome stuff you get on github I have

00:31:49,680 --> 00:31:53,370
two branches that has the heaps tax

00:31:52,380 --> 00:31:55,920
thing that we just talked about this

00:31:53,370 --> 00:31:59,130
your copy thing and Amon has a branch

00:31:55,920 --> 00:32:00,480
that has some fiber stuff in it if you

00:31:59,130 --> 00:32:01,830
don't like applying patches or building

00:32:00,480 --> 00:32:04,740
cell phone github you can use Ruby

00:32:01,830 --> 00:32:07,470
enterprise edition re is based on 187

00:32:04,740 --> 00:32:10,350
it's free it's open source it has our

00:32:07,470 --> 00:32:13,020
thread timer fix our zero copy threading

00:32:10,350 --> 00:32:14,940
patch can be enabled with flag and it

00:32:13,020 --> 00:32:17,400
also includes some patches from the NBA

00:32:14,940 --> 00:32:21,150
a patch that which help reduce the stack

00:32:17,400 --> 00:32:22,920
frame size of important reef unction so

00:32:21,150 --> 00:32:24,000
REE is actually really fast and we're

00:32:22,920 --> 00:32:26,070
going to talk about it again later in

00:32:24,000 --> 00:32:28,580
the GC talk but you can get it there

00:32:26,070 --> 00:32:32,280
Ruby Enterprise Edition com

00:32:28,580 --> 00:32:34,290
and that's it so questions and you can

00:32:32,280 --> 00:32:36,890
grab us on Twitter the internet

00:32:34,290 --> 00:32:36,890
elsewhere

00:32:37,280 --> 00:32:40,670
yeah sure dude

00:32:51,710 --> 00:32:55,830
so 1.9 like we said at the beginning 1.9

00:32:54,990 --> 00:32:57,659
uses a different threading

00:32:55,830 --> 00:33:00,600
implementation so these patches don't

00:32:57,659 --> 00:33:02,669
wouldn't apply to 1.9 and as far as

00:33:00,600 --> 00:33:05,340
getting this stuff backward to 18 the

00:33:02,669 --> 00:33:06,659
answer right now is no ah and so the

00:33:05,340 --> 00:33:07,919
reason why this will never be in 18

00:33:06,659 --> 00:33:10,320
mainlined it's sort of several reasons

00:33:07,919 --> 00:33:13,529
one of which is that our code is

00:33:10,320 --> 00:33:17,399
platform-specific we only support 32-bit

00:33:13,529 --> 00:33:19,110
and 64-bit x86 and x64 platforms I

00:33:17,399 --> 00:33:21,360
brewery supports lots of other people

00:33:19,110 --> 00:33:24,149
like you know the human 68k and all

00:33:21,360 --> 00:33:25,169
kinds of like weird CPUs and so I don't

00:33:24,149 --> 00:33:26,370
know rube easily know a lot about

00:33:25,169 --> 00:33:27,899
portability and stuff which you know

00:33:26,370 --> 00:33:29,250
we're just not going to write

00:33:27,899 --> 00:33:31,139
instructions for all the stress of sweep

00:33:29,250 --> 00:33:33,570
we've submitted some the event is

00:33:31,139 --> 00:33:36,299
actually the initial timer patch that we

00:33:33,570 --> 00:33:38,490
talked about that stops the timer once

00:33:36,299 --> 00:33:41,820
the thread dies was recently accepted

00:33:38,490 --> 00:33:44,250
and is inflated 27

00:33:41,820 --> 00:33:45,900
oh and the other hand might have said

00:33:44,250 --> 00:33:48,150
we're very specific in this life we were

00:33:45,900 --> 00:33:48,999
able to get them in REE because our he

00:33:48,150 --> 00:33:51,959
is

00:33:48,999 --> 00:33:51,959
if we met for

00:33:57,910 --> 00:34:00,900
ruby is elven language

00:34:01,370 --> 00:34:05,260
and inline assembly like me added

00:34:10,830 --> 00:34:15,580
so it depends like a it opens up like a

00:34:14,020 --> 00:34:17,649
huge philosophical argument right

00:34:15,580 --> 00:34:18,850
because it's like you know what do you

00:34:17,649 --> 00:34:19,750
what kinds of you know what type of

00:34:18,850 --> 00:34:21,370
throating are you doing are you I Oh

00:34:19,750 --> 00:34:22,480
bound are you CPU bound and then what do

00:34:21,370 --> 00:34:24,460
you care about and just sort of like

00:34:22,480 --> 00:34:25,840
lots of trade-offs in both directions so

00:34:24,460 --> 00:34:27,610
I don't think there's like you know one

00:34:25,840 --> 00:34:28,929
or answer like yes it's better like the

00:34:27,610 --> 00:34:30,550
three inflation is better here it's

00:34:28,929 --> 00:34:32,020
worse there or whatever I mean they both

00:34:30,550 --> 00:34:34,300
have their pros and cons it's just

00:34:32,020 --> 00:34:36,370
trade-offs I mean if you ran in French

00:34:34,300 --> 00:34:39,210
being benchmark on 19 it would be

00:34:36,370 --> 00:34:39,210
comparable

00:34:41,530 --> 00:34:45,470
and that's just because since you're

00:34:43,630 --> 00:34:47,310
using kernel threads and Carla table

00:34:45,470 --> 00:34:50,900
do this the old magic

00:34:47,310 --> 00:34:50,900
in the colonel and you know

00:34:53,450 --> 00:34:59,090
any other questions

00:34:56,720 --> 00:35:00,050
yeah yeah so the slides I won't have to

00:34:59,090 --> 00:35:02,330
clean them up a bit because of all the

00:35:00,050 --> 00:35:04,430
transitions so hope you had tonight or

00:35:02,330 --> 00:35:07,460
tomorrow and output it to PDF then

00:35:04,430 --> 00:35:10,099
they'll be on time to bleed calm on my

00:35:07,460 --> 00:35:11,090
blog or on Twitter but yell supple

00:35:10,099 --> 00:35:12,440
definitely be available in so we have a

00:35:11,090 --> 00:35:14,270
you know whole minutes to clean it up

00:35:12,440 --> 00:35:19,220
these flights are actually pretty dope

00:35:14,270 --> 00:35:21,440
if you go too far back yeah I'll tweet

00:35:19,220 --> 00:35:23,710
something on all hashtag it and you guys

00:35:21,440 --> 00:35:23,710
will be fine

00:35:41,140 --> 00:35:46,190
yeah so the logic is that you don't have

00:35:44,210 --> 00:35:47,360
to write platform specific code because

00:35:46,190 --> 00:35:48,800
different platforms the stacks are

00:35:47,360 --> 00:35:50,030
different directions and so if you just

00:35:48,800 --> 00:35:51,980
say hey we're not going to write code

00:35:50,030 --> 00:35:53,450
free CPU will just copy them it makes it

00:35:51,980 --> 00:35:55,460
a lot easier and you can support things

00:35:53,450 --> 00:35:56,540
like continuations so our zero copy

00:35:55,460 --> 00:35:59,090
thread patch actually breaks

00:35:56,540 --> 00:36:05,740
continuations you can fix them but I

00:35:59,090 --> 00:36:08,180
don't care about attenuations so so I

00:36:05,740 --> 00:36:10,610
want to take this it's like it's like

00:36:08,180 --> 00:36:11,810
you execute you save state you can store

00:36:10,610 --> 00:36:15,140
that state away and you can resume it

00:36:11,810 --> 00:36:17,690
later it's sort of like a better fiber

00:36:15,140 --> 00:36:19,900
Vidya you can save table full time jump

00:36:17,690 --> 00:36:19,900
back

00:36:20,760 --> 00:36:25,130
and if five or six we saved and resume

00:36:28,369 --> 00:36:32,019
and last for applications

00:36:33,950 --> 00:36:37,070
sup man

00:36:40,140 --> 00:36:45,180
yeah they were never really well

00:36:41,700 --> 00:36:49,040
supported 180 feet

00:36:45,180 --> 00:36:49,040
and I think in 19 you there

00:36:50,020 --> 00:36:53,440
yeah more

00:36:57,390 --> 00:37:04,110
cool well next listing guys and I'll

00:37:01,090 --> 00:37:04,110

YouTube URL: https://www.youtube.com/watch?v=sbOaxfCJB3A


