Title: Ensuring High Performance for Your Ruby App by Kowsik Guruswamy
Publication date: 2020-01-28
Playlist: Aloha RubyConf 2012
Description: 
	Help us caption & translate this video!

http://amara.org/v/FGff/
Captions: 
	00:00:14,680 --> 00:00:19,010
hey guys probably one of the last

00:00:17,360 --> 00:00:22,460
presentations you know jet lag hitting

00:00:19,010 --> 00:00:23,630
us I'm bound to fall asleep so just wake

00:00:22,460 --> 00:00:24,740
me up with questions i love the

00:00:23,630 --> 00:00:26,770
questions so we don't have to wait till

00:00:24,740 --> 00:00:29,119
the end so if i if you see myself not

00:00:26,770 --> 00:00:30,800
usually a talk very fast so if you see

00:00:29,119 --> 00:00:32,000
myself slow down a little bit just going

00:00:30,800 --> 00:00:36,200
to give me a nudge and stand up and ask

00:00:32,000 --> 00:00:37,730
questions so keep it's going so just a

00:00:36,200 --> 00:00:40,040
really really quick quick thing intro

00:00:37,730 --> 00:00:41,239
about myself CTO for new dynamics is a

00:00:40,040 --> 00:00:43,610
company that i started some years ago

00:00:41,239 --> 00:00:45,429
and we got acquired in april and now I'm

00:00:43,610 --> 00:00:49,059
CTO for blitz so blitz cannot lives on

00:00:45,429 --> 00:00:51,769
I've been a rubios students about 2006

00:00:49,059 --> 00:00:53,629
my lot of people actually get introduced

00:00:51,769 --> 00:00:55,329
to Ruby through rails mine was exactly

00:00:53,629 --> 00:00:58,579
the opposite so we actually built

00:00:55,329 --> 00:01:01,969
250,000 250,000 a line of coke

00:00:58,579 --> 00:01:03,440
commercial non web app application and

00:01:01,969 --> 00:01:04,820
Ruby and I'll go through a little bit

00:01:03,440 --> 00:01:07,340
about what we did and why performance

00:01:04,820 --> 00:01:09,620
was pretty important for us so me

00:01:07,340 --> 00:01:12,440
dynamics when I started you know anybody

00:01:09,620 --> 00:01:14,150
know what fuzziness alright so I'll go

00:01:12,440 --> 00:01:15,470
through just one slight alright so it

00:01:14,150 --> 00:01:18,020
was essentially we put the commercial

00:01:15,470 --> 00:01:19,310
fuzzer on steroids and before I talk

00:01:18,020 --> 00:01:21,290
about what fuzzing is our very first

00:01:19,310 --> 00:01:23,660
version was in C++ you know y'all keep

00:01:21,290 --> 00:01:26,060
say right so it was it was pretty hard

00:01:23,660 --> 00:01:27,680
to maintain and so we started moving

00:01:26,060 --> 00:01:29,570
some of the stuff over to Ruby and

00:01:27,680 --> 00:01:32,360
trying to put some Ruby you know

00:01:29,570 --> 00:01:33,530
lipstick on the C++ big and kind of

00:01:32,360 --> 00:01:35,480
struggle through a little bit and then

00:01:33,530 --> 00:01:37,370
the third version we pretty much switch

00:01:35,480 --> 00:01:38,390
almost completed Ruby and then we have

00:01:37,370 --> 00:01:40,910
to do a bunch of stuff would see

00:01:38,390 --> 00:01:42,830
extensions to kind of optimize that so

00:01:40,910 --> 00:01:44,480
for those of you that don't know what

00:01:42,830 --> 00:01:47,300
fuzzing is anybody familiar with this

00:01:44,480 --> 00:01:49,550
one was a github rails vulnerability

00:01:47,300 --> 00:01:51,590
it's not a mint be a put down on github

00:01:49,550 --> 00:01:53,930
I love github we actually use github for

00:01:51,590 --> 00:01:55,490
bliss but essentially this was a sequel

00:01:53,930 --> 00:01:56,690
injection vulnerability so you could

00:01:55,490 --> 00:01:58,400
essentially take over and do math

00:01:56,690 --> 00:02:00,050
assignment with rails and take over

00:01:58,400 --> 00:02:02,870
other people's SSH keys and all of that

00:02:00,050 --> 00:02:04,850
fun stuff right so that's kind of what

00:02:02,870 --> 00:02:07,610
we did we essentially did something

00:02:04,850 --> 00:02:09,019
called hacker development which you know

00:02:07,610 --> 00:02:10,789
if you have a restful api you may be

00:02:09,019 --> 00:02:12,530
using rack or you know whatever else it

00:02:10,789 --> 00:02:15,260
is we could take your restful api and

00:02:12,530 --> 00:02:17,510
very methodically generate tons and tons

00:02:15,260 --> 00:02:19,640
of automatic unit tests that essentially

00:02:17,510 --> 00:02:20,810
are all triggered around either crashing

00:02:19,640 --> 00:02:23,239
the ruby up generating as many

00:02:20,810 --> 00:02:24,890
exceptions as we possibly can input

00:02:23,239 --> 00:02:26,630
tampering you know things actually

00:02:24,890 --> 00:02:28,850
missing things that are overflowing

00:02:26,630 --> 00:02:30,290
things that look like email that are not

00:02:28,850 --> 00:02:32,330
supposed to be like email so we would

00:02:30,290 --> 00:02:34,610
just automatically generate all these

00:02:32,330 --> 00:02:36,470
thousands of test cases and so the whole

00:02:34,610 --> 00:02:39,590
idea was you can incorporate security

00:02:36,470 --> 00:02:41,000
testing and vulnerability testing into

00:02:39,590 --> 00:02:42,950
your development process instead of

00:02:41,000 --> 00:02:44,090
running an audit you know once a year so

00:02:42,950 --> 00:02:46,700
that's kind of the company that I built

00:02:44,090 --> 00:02:48,400
and and so because we were generating

00:02:46,700 --> 00:02:50,690
these tens of thousands of test cases

00:02:48,400 --> 00:02:52,820
you know these things tend to run for

00:02:50,690 --> 00:02:55,010
3-4 hours because it was very exhaustive

00:02:52,820 --> 00:02:56,810
and methodical right so we want it and

00:02:55,010 --> 00:02:58,580
we love Ruby and I'll tell you why in a

00:02:56,810 --> 00:03:00,230
second and so we wanted to make this

00:02:58,580 --> 00:03:02,540
thing go faster because we couldn't wait

00:03:00,230 --> 00:03:05,810
around for you know 36 hours 4000 test

00:03:02,540 --> 00:03:07,730
cases to run so we did a lot of stuff in

00:03:05,810 --> 00:03:09,470
order to break pretty much everything it

00:03:07,730 --> 00:03:11,600
was a lot of fun you know we broke

00:03:09,470 --> 00:03:14,180
printers it didn't matter what protocol

00:03:11,600 --> 00:03:15,860
that spoke we broke printers little fans

00:03:14,180 --> 00:03:17,840
and minecraft you know in mines that

00:03:15,860 --> 00:03:19,790
it's called SCADA if you familiar with

00:03:17,840 --> 00:03:21,260
that space in a rails application Python

00:03:19,790 --> 00:03:22,820
it didn't matter we broke everything and

00:03:21,260 --> 00:03:25,010
found a lot of problems with it that's

00:03:22,820 --> 00:03:26,390
kind of the product that we sold so the

00:03:25,010 --> 00:03:28,730
speed of execution was actually super

00:03:26,390 --> 00:03:30,440
super important for us okay anybody

00:03:28,730 --> 00:03:35,150
still think I'm yawning or slowing down

00:03:30,440 --> 00:03:36,860
okay cool so we love Ruby because after

00:03:35,150 --> 00:03:38,240
going to c and c++ and all of that stuff

00:03:36,860 --> 00:03:39,860
right so it was very very clean and

00:03:38,240 --> 00:03:41,990
beautiful we love that as the language

00:03:39,860 --> 00:03:43,550
but also it was a beautiful boat on the

00:03:41,990 --> 00:03:45,950
outside as well as the inside so when

00:03:43,550 --> 00:03:47,780
you write see inside of ruby it actually

00:03:45,950 --> 00:03:50,060
felt like a writing you know writing

00:03:47,780 --> 00:03:52,190
Ruby so a lot of the methods that you're

00:03:50,060 --> 00:03:55,010
using internally were very similar to

00:03:52,190 --> 00:03:56,360
how you would use it outside okay and so

00:03:55,010 --> 00:03:58,910
extensions as we talked about it's

00:03:56,360 --> 00:04:00,350
almost like writing ruby and so 192 is a

00:03:58,910 --> 00:04:01,580
little bit more complex because of the

00:04:00,350 --> 00:04:04,100
whole virtual machine infrastructure

00:04:01,580 --> 00:04:07,459
that it's there but 197 is almost pure

00:04:04,100 --> 00:04:09,260
okay so since this is a talk about

00:04:07,459 --> 00:04:10,850
performance and performance is this huge

00:04:09,260 --> 00:04:12,350
subject right you can kind of pick up

00:04:10,850 --> 00:04:14,690
any one of these pieces and you can talk

00:04:12,350 --> 00:04:16,190
about it all day long so just a quick

00:04:14,690 --> 00:04:18,260
note on languages all right i mean

00:04:16,190 --> 00:04:20,390
people say no Jo is fast or rails is

00:04:18,260 --> 00:04:22,070
slow or Python is okay and I mean

00:04:20,390 --> 00:04:23,630
languages by themselves or just abstract

00:04:22,070 --> 00:04:25,280
it's like saying English as faster than

00:04:23,630 --> 00:04:28,010
German or something like that right it

00:04:25,280 --> 00:04:29,450
just doesn't make sense so but when it

00:04:28,010 --> 00:04:31,370
comes to programming languages you know

00:04:29,450 --> 00:04:32,810
interpret the interpreter has a lot of

00:04:31,370 --> 00:04:34,400
trade-offs it makes well there is method

00:04:32,810 --> 00:04:36,440
caching or caching all the regular

00:04:34,400 --> 00:04:39,009
expressions or things like that that

00:04:36,440 --> 00:04:40,210
matters a lot and so you kind of have to

00:04:39,009 --> 00:04:42,129
a little bit about optimization and

00:04:40,210 --> 00:04:43,559
gotchas and actually throughout the day

00:04:42,129 --> 00:04:45,819
there was a lot of really really great

00:04:43,559 --> 00:04:47,110
great presentations and performance

00:04:45,819 --> 00:04:49,149
actually higher Erin opened up the

00:04:47,110 --> 00:04:50,499
keynote with talking about rails 4 and

00:04:49,149 --> 00:04:53,559
threading and concurrency which I will

00:04:50,499 --> 00:04:55,089
touch upon a little bit more but in my

00:04:53,559 --> 00:04:56,710
mind just after you know working with

00:04:55,089 --> 00:04:58,389
Ruby and all of this stuff for you know

00:04:56,710 --> 00:05:00,490
many number of years I think it actually

00:04:58,389 --> 00:05:05,889
comes down to Big O anybody know what

00:05:00,490 --> 00:05:07,330
big O's is all right cool so so big oh

00:05:05,889 --> 00:05:09,399
you've probably seen this you know in

00:05:07,330 --> 00:05:11,680
computer science classes you know they

00:05:09,399 --> 00:05:13,839
talk about one order of log in order an

00:05:11,680 --> 00:05:15,909
order of N squared etc but essentially

00:05:13,839 --> 00:05:18,129
it tells you what the speed of execution

00:05:15,909 --> 00:05:20,020
is or how much memory something is going

00:05:18,129 --> 00:05:21,879
to stick is in the very abstract way of

00:05:20,020 --> 00:05:23,559
describing it okay I mean a lot of times

00:05:21,879 --> 00:05:24,849
when you encounter a performance problem

00:05:23,559 --> 00:05:26,860
it's one of those things that makes you

00:05:24,849 --> 00:05:28,210
go ah you know and then you cannot dig

00:05:26,860 --> 00:05:30,219
deep into it you know it's usually an

00:05:28,210 --> 00:05:33,189
order of you no problem with either

00:05:30,219 --> 00:05:36,849
choice of poor data structures or it's

00:05:33,189 --> 00:05:38,259
wrong choice of algorithms and a lot of

00:05:36,849 --> 00:05:40,270
times your scab by speed of light day

00:05:38,259 --> 00:05:42,550
which means latency right you just can't

00:05:40,270 --> 00:05:43,719
push things fast enough if your data

00:05:42,550 --> 00:05:45,279
centers in Germany and all your

00:05:43,719 --> 00:05:46,749
customers in u.s. you know you just

00:05:45,279 --> 00:05:48,580
can't push back it's fast a novel crop

00:05:46,749 --> 00:05:51,129
across the globe so it's kind of limited

00:05:48,580 --> 00:05:52,959
by the speed of light and most people

00:05:51,129 --> 00:05:55,120
and say in our rails are slow it's like

00:05:52,959 --> 00:05:56,559
don't and also usually dig deep and find

00:05:55,120 --> 00:05:58,029
out that it's really the way you're

00:05:56,559 --> 00:06:01,419
using it I think just the last two

00:05:58,029 --> 00:06:04,300
condos two presentations ago I think Ben

00:06:01,419 --> 00:06:07,899
I think I'm i think it was Ben he had he

00:06:04,300 --> 00:06:08,860
had this date range that includes I

00:06:07,899 --> 00:06:11,319
don't have everybody paid attention

00:06:08,860 --> 00:06:13,629
right includes versus cover so big

00:06:11,319 --> 00:06:15,939
difference right so date that date range

00:06:13,629 --> 00:06:17,589
includes essentially expands Ruby to go

00:06:15,939 --> 00:06:19,419
through every single element and as a

00:06:17,589 --> 00:06:21,669
comparison check so that's order of n

00:06:19,419 --> 00:06:23,139
that means if you've got 300 years in it

00:06:21,669 --> 00:06:24,459
it's going to go through every second of

00:06:23,139 --> 00:06:27,639
every day of every year to scan through

00:06:24,459 --> 00:06:28,959
the whole thing versus cover with the ?

00:06:27,639 --> 00:06:30,699
that meant that essentially checks the

00:06:28,959 --> 00:06:32,439
you know outer bound the inner bound on

00:06:30,699 --> 00:06:33,969
the outer bound and that's ofone

00:06:32,439 --> 00:06:36,580
regardless of the size of the date range

00:06:33,969 --> 00:06:38,830
so so the complexity order of complexity

00:06:36,580 --> 00:06:40,569
is a pretty cool metric of tracking down

00:06:38,830 --> 00:06:45,610
which whether your stuff is going slow

00:06:40,569 --> 00:06:47,139
or fast etc ok so in terms of you know

00:06:45,610 --> 00:06:49,659
if you want to plot the plot the

00:06:47,139 --> 00:06:50,949
complexity it's a pretty nice way to

00:06:49,659 --> 00:06:51,550
actually look at it so the yellow line

00:06:50,949 --> 00:06:53,380
is

00:06:51,550 --> 00:06:55,240
one this actually means that so the

00:06:53,380 --> 00:06:56,650
bottom line is you know the data set

00:06:55,240 --> 00:06:58,720
size right so it could be millions of

00:06:56,650 --> 00:07:01,210
entries in a database or you're holding

00:06:58,720 --> 00:07:02,350
thousands of entries and red is maybe

00:07:01,210 --> 00:07:03,970
your active record sequel query

00:07:02,350 --> 00:07:05,920
essentially gave you back 10,000

00:07:03,970 --> 00:07:07,360
elements so really the order of one

00:07:05,920 --> 00:07:09,490
tells you that regardless of the data

00:07:07,360 --> 00:07:12,160
size the time to access a particular

00:07:09,490 --> 00:07:14,470
element is the same okay in terms of

00:07:12,160 --> 00:07:16,090
data structures so log in essentially is

00:07:14,470 --> 00:07:18,490
pretty nice that's the little blue line

00:07:16,090 --> 00:07:21,790
at the bottom basically says you know it

00:07:18,490 --> 00:07:22,990
kind of grows in a logarithmic way that

00:07:21,790 --> 00:07:24,580
means you can have a million entries in

00:07:22,990 --> 00:07:26,170
there so it's still not going to be as

00:07:24,580 --> 00:07:28,900
you know super slow and that's a good

00:07:26,170 --> 00:07:30,580
thing purple line you're starting to get

00:07:28,900 --> 00:07:32,290
into the word situations now purple line

00:07:30,580 --> 00:07:34,570
is the more the number of entries the

00:07:32,290 --> 00:07:36,190
linear the performance degradation got

00:07:34,570 --> 00:07:37,690
thousand entries your algorithm runs fat

00:07:36,190 --> 00:07:39,640
reasonably okay when it gets to a

00:07:37,690 --> 00:07:41,950
million is closed down by that order and

00:07:39,640 --> 00:07:43,450
that's terrible and the o n squared you

00:07:41,950 --> 00:07:45,190
don't even want to go there that's

00:07:43,450 --> 00:07:46,450
that's the nightmare of all right so you

00:07:45,190 --> 00:07:48,760
want to make sure that you don't go

00:07:46,450 --> 00:07:50,800
there because very very quickly things

00:07:48,760 --> 00:07:52,540
get completely out of whack and your

00:07:50,800 --> 00:07:54,640
entire program just comes crashing down

00:07:52,540 --> 00:07:56,170
things get really slow and sluggish and

00:07:54,640 --> 00:07:57,820
so I'm going to so the way I'm going to

00:07:56,170 --> 00:07:59,890
talk about performance is instead of

00:07:57,820 --> 00:08:01,690
kind of talking about very abstract in a

00:07:59,890 --> 00:08:03,010
way so I'm gonna use some of the parts

00:08:01,690 --> 00:08:04,300
the part that I'm working on as a way to

00:08:03,010 --> 00:08:06,880
actually convey some of the concepts

00:08:04,300 --> 00:08:08,080
like concurrency and threading and hit

00:08:06,880 --> 00:08:09,880
rate and stuff like that that you've

00:08:08,080 --> 00:08:11,350
heard throughout the day so hopefully

00:08:09,880 --> 00:08:13,620
it's a slightly different way of

00:08:11,350 --> 00:08:15,580
presenting it but you know I find that

00:08:13,620 --> 00:08:17,470
thinking about abstractly it's really

00:08:15,580 --> 00:08:19,300
hard for me so if i can use specific

00:08:17,470 --> 00:08:22,720
concrete examples then it you know it's

00:08:19,300 --> 00:08:24,310
much better all right so we'll talk with

00:08:22,720 --> 00:08:25,960
very little things okay so this was just

00:08:24,310 --> 00:08:29,560
a really simple example of the power of

00:08:25,960 --> 00:08:31,360
the big o notation so a while back i did

00:08:29,560 --> 00:08:33,070
this gem install t i saw this on twitter

00:08:31,360 --> 00:08:35,230
somebody actually had a twitter client i

00:08:33,070 --> 00:08:38,200
was very cool so I just a gem install t

00:08:35,230 --> 00:08:39,730
and i just typed t you know enter and it

00:08:38,200 --> 00:08:41,680
was one point three four seconds before

00:08:39,730 --> 00:08:43,990
i got a prong displaying the usage of

00:08:41,680 --> 00:08:45,520
this program I'm like you know that's

00:08:43,990 --> 00:08:47,500
wrong I mean one point three seven

00:08:45,520 --> 00:08:50,140
seconds for a program to just display

00:08:47,500 --> 00:08:54,070
usage that doesn't sound right okay so

00:08:50,140 --> 00:08:55,900
let's dig a little bit deeper so you

00:08:54,070 --> 00:08:57,670
load up binti and then you find that in

00:08:55,900 --> 00:08:59,260
line for I basically said you know just

00:08:57,670 --> 00:09:01,060
print out the loaded feature size which

00:08:59,260 --> 00:09:02,980
is the number of files you've required

00:09:01,060 --> 00:09:05,200
inside Ruby that that thing keeps track

00:09:02,980 --> 00:09:08,200
of it ok and then exit one so you

00:09:05,200 --> 00:09:09,970
again now it's 433 so really the number

00:09:08,200 --> 00:09:13,000
of dependencies that this program had

00:09:09,970 --> 00:09:16,630
was 433 other files that was requiring

00:09:13,000 --> 00:09:19,120
okay that's still not if you think about

00:09:16,630 --> 00:09:20,860
it right it's just an array it's 433

00:09:19,120 --> 00:09:22,960
elements and you should be able to scan

00:09:20,860 --> 00:09:23,890
that pretty quickly too really not a big

00:09:22,960 --> 00:09:25,210
deal we're not talking about million

00:09:23,890 --> 00:09:28,390
will be filed at your including or

00:09:25,210 --> 00:09:30,130
requiring so now you find out what the

00:09:28,390 --> 00:09:32,710
class of this loaded feature thing is

00:09:30,130 --> 00:09:34,780
turns out it was an array ok so now red

00:09:32,710 --> 00:09:38,590
flash start going on right so what's

00:09:34,780 --> 00:09:40,900
actually happening is so inside the load

00:09:38,590 --> 00:09:42,610
see inside the interpreter so if you

00:09:40,900 --> 00:09:44,410
look at what actually happens when you

00:09:42,610 --> 00:09:45,730
do a require and require a ruby file

00:09:44,410 --> 00:09:47,290
whether it's a Ruby gems or whatever

00:09:45,730 --> 00:09:49,420
else it is they let require active

00:09:47,290 --> 00:09:50,740
record so there's this little loop here

00:09:49,420 --> 00:09:52,150
and you know for those of you that don't

00:09:50,740 --> 00:09:53,770
understand see that's all right it's a

00:09:52,150 --> 00:09:56,740
pretty simple loop that basically says I

00:09:53,770 --> 00:09:58,690
equals 0 I is then less than the array

00:09:56,740 --> 00:10:00,580
length ok of all the files that you've

00:09:58,690 --> 00:10:02,170
included and then for each one of them

00:10:00,580 --> 00:10:04,630
it basically goes in there and compares

00:10:02,170 --> 00:10:05,650
you know whatever you're loading against

00:10:04,630 --> 00:10:09,160
all the elements that have already

00:10:05,650 --> 00:10:13,960
loaded ok now who knows which Big O that

00:10:09,160 --> 00:10:15,130
falls under ok so let's simulate to find

00:10:13,960 --> 00:10:17,020
out what the graph looks like all right

00:10:15,130 --> 00:10:18,520
so I just randomly started adding stuff

00:10:17,020 --> 00:10:20,290
and allotted features and I just calling

00:10:18,520 --> 00:10:22,600
kept calling require over and over again

00:10:20,290 --> 00:10:26,680
and a little test harness so the graph

00:10:22,600 --> 00:10:29,320
looks like this which is what come on

00:10:26,680 --> 00:10:30,880
you guys I'm falling asleep not you all

00:10:29,320 --> 00:10:32,980
right N squared all right so since N

00:10:30,880 --> 00:10:34,540
squared because for every require your

00:10:32,980 --> 00:10:36,040
scanning all the other things that have

00:10:34,540 --> 00:10:37,540
already been required so every new

00:10:36,040 --> 00:10:39,400
element that does all the other element

00:10:37,540 --> 00:10:41,620
over and over and over and over again so

00:10:39,400 --> 00:10:45,430
how does this affect in real world you

00:10:41,620 --> 00:10:49,030
know so dem install rails create a new

00:10:45,430 --> 00:10:51,280
app load config-router RB and print that

00:10:49,030 --> 00:10:54,940
load of feature sizes 784 so out of the

00:10:51,280 --> 00:10:58,060
blue a rails app has 784 you know

00:10:54,940 --> 00:10:59,560
dependencies ok so really the point of

00:10:58,060 --> 00:11:01,060
this exercise is performance is

00:10:59,560 --> 00:11:02,860
everything from small to everything from

00:11:01,060 --> 00:11:04,450
big you can I have to worry about or at

00:11:02,860 --> 00:11:07,300
least think about what the big o is so

00:11:04,450 --> 00:11:09,370
it really this manifests itself in the

00:11:07,300 --> 00:11:10,720
startup time of rails that's really what

00:11:09,370 --> 00:11:12,460
it is I think in the last conversation

00:11:10,720 --> 00:11:14,140
last presentation we're talking about

00:11:12,460 --> 00:11:15,940
how jruby takes forever to load the

00:11:14,140 --> 00:11:17,040
first time is doing a cold start it's

00:11:15,940 --> 00:11:19,079
loading everything

00:11:17,040 --> 00:11:20,699
possible and compiling a jit and all of

00:11:19,079 --> 00:11:22,769
that stuff right so that essentially

00:11:20,699 --> 00:11:24,959
manifest itself in low dat load time so

00:11:22,769 --> 00:11:27,139
as you start just reusing lots of these

00:11:24,959 --> 00:11:29,459
gems and just requiring everything else

00:11:27,139 --> 00:11:30,899
it's kinda like the same as chrome space

00:11:29,459 --> 00:11:32,670
speed you know if you can look at it it

00:11:30,899 --> 00:11:34,290
basically tells you don't use this CSS

00:11:32,670 --> 00:11:36,240
rule is never used in other pages might

00:11:34,290 --> 00:11:37,589
want to prune it kind of stuff same

00:11:36,240 --> 00:11:38,970
thing kind of watch it dependencies so

00:11:37,589 --> 00:11:40,589
if you're not using any particular gem

00:11:38,970 --> 00:11:42,829
it's better to prune it because that's

00:11:40,589 --> 00:11:46,790
going to improve your load startup time

00:11:42,829 --> 00:11:49,709
all right so far so good medium things

00:11:46,790 --> 00:11:53,310
I'm a huge fan of Fineman so you can

00:11:49,709 --> 00:11:54,569
kind of see where that's going well very

00:11:53,310 --> 00:11:56,160
cool control about blood co it's not

00:11:54,569 --> 00:11:59,579
meant to be a huge plug but for the how

00:11:56,160 --> 00:12:02,310
many of you know what blitz is cool so

00:11:59,579 --> 00:12:03,870
so built when I build blitz is basically

00:12:02,310 --> 00:12:05,670
it's a it's a distributed app or load

00:12:03,870 --> 00:12:07,380
testing that's what we do so very very

00:12:05,670 --> 00:12:09,110
high level i'll put the sit bones on

00:12:07,380 --> 00:12:11,220
slideshare so you can take a look at it

00:12:09,110 --> 00:12:12,690
very very high level you can basically

00:12:11,220 --> 00:12:14,519
say look I've got this rails app on

00:12:12,690 --> 00:12:16,860
Heroku engine yard pass whatever on your

00:12:14,519 --> 00:12:18,810
own ec2 and you can say send me 10,000

00:12:16,860 --> 00:12:20,160
virtual users from Singapore and we

00:12:18,810 --> 00:12:21,449
basically tell you here's kind of what

00:12:20,160 --> 00:12:23,819
the response time look like here's the

00:12:21,449 --> 00:12:25,440
hit rate looks like and then we also can

00:12:23,819 --> 00:12:27,420
overlay New Relic and copyright metrics

00:12:25,440 --> 00:12:28,920
and top of it so you can find out when

00:12:27,420 --> 00:12:30,269
there are 10,000 users on my website

00:12:28,920 --> 00:12:31,649
here's kind of what my database

00:12:30,269 --> 00:12:33,300
performance looks like that's what we do

00:12:31,649 --> 00:12:37,350
that's what I work on is the part that I

00:12:33,300 --> 00:12:38,490
work on okay so you know here's a really

00:12:37,350 --> 00:12:40,139
simple grab that connect demonstrate

00:12:38,490 --> 00:12:42,060
what's going on this is New Relic data

00:12:40,139 --> 00:12:43,410
and so the grey line the little

00:12:42,060 --> 00:12:45,209
stepladder is the number of concurrent

00:12:43,410 --> 00:12:47,610
users that we're sending against your

00:12:45,209 --> 00:12:49,860
app you can see the response time grabs

00:12:47,610 --> 00:12:51,630
in yellow and the blue line is basically

00:12:49,860 --> 00:12:53,790
a CP usage that New Relic is reporting

00:12:51,630 --> 00:12:54,959
all overlaid on top okay so it's a

00:12:53,790 --> 00:12:56,690
pretty simple am but it's a pretty

00:12:54,959 --> 00:12:58,949
powerful way to constantly incorporate

00:12:56,690 --> 00:13:01,920
performance measure the performance of

00:12:58,949 --> 00:13:04,139
your app and an ongoing basis and the

00:13:01,920 --> 00:13:05,730
plug okay so let me just talk about

00:13:04,139 --> 00:13:06,959
glitz experience what we went through in

00:13:05,730 --> 00:13:09,089
terms of performance right so you

00:13:06,959 --> 00:13:10,889
figured that you know as a performance

00:13:09,089 --> 00:13:12,720
testing part i we're going to be immune

00:13:10,889 --> 00:13:14,430
from all of this stuff to a wrong answer

00:13:12,720 --> 00:13:15,870
so we're gonna have to went through a

00:13:14,430 --> 00:13:17,639
bunch of different lessons along the way

00:13:15,870 --> 00:13:20,279
as we built this product so the very

00:13:17,639 --> 00:13:21,990
first one you know we use CouchDB so

00:13:20,279 --> 00:13:23,459
there was no Redis yet and so I pretty

00:13:21,990 --> 00:13:26,399
much every request would go against

00:13:23,459 --> 00:13:28,470
CouchDB and and the front end is

00:13:26,399 --> 00:13:29,760
actually just a Sinatra app because we

00:13:28,470 --> 00:13:30,840
don't want to for whatever reason we're

00:13:29,760 --> 00:13:33,360
using CouchDB end

00:13:30,840 --> 00:13:36,390
to be burdened by the orem mapping so we

00:13:33,360 --> 00:13:40,800
went with Sinatra and so the very first

00:13:36,390 --> 00:13:45,360
one we had before filter question it's

00:13:40,800 --> 00:13:46,590
almost so the the before filter look

00:13:45,360 --> 00:13:49,140
pretty much like this it basically says

00:13:46,590 --> 00:13:51,030
CouchDB get going such an ID right we

00:13:49,140 --> 00:13:52,980
forgot one thing but all the static

00:13:51,030 --> 00:13:54,720
assets were also being loaded as part of

00:13:52,980 --> 00:13:57,150
the page loads so couchdb was just

00:13:54,720 --> 00:13:59,520
getting hammered with just thousands of

00:13:57,150 --> 00:14:01,290
requests right because every every CSS

00:13:59,520 --> 00:14:03,600
would go through this before filter so

00:14:01,290 --> 00:14:05,580
again this was a simple example of 0 n

00:14:03,600 --> 00:14:06,840
where in the given page if you have n

00:14:05,580 --> 00:14:08,610
number of assets that was translated

00:14:06,840 --> 00:14:11,220
into n number of requests back to couch

00:14:08,610 --> 00:14:13,380
TV and so that was one of those moments

00:14:11,220 --> 00:14:18,120
right so again couple comes back to Big

00:14:13,380 --> 00:14:19,620
O known on a little bit so the first

00:14:18,120 --> 00:14:21,000
architecture so the way kind of the way

00:14:19,620 --> 00:14:22,410
I you know we set up the Blitz was

00:14:21,000 --> 00:14:24,420
there's a Sinatra layer and then there

00:14:22,410 --> 00:14:25,710
was couch TV and then there was all

00:14:24,420 --> 00:14:26,820
these regional what we call engines

00:14:25,710 --> 00:14:28,560
these the little traffic generation

00:14:26,820 --> 00:14:30,840
engines that are sitting in all aw

00:14:28,560 --> 00:14:32,790
regions and it would all do something

00:14:30,840 --> 00:14:34,680
called changes feed on CouchDB which is

00:14:32,790 --> 00:14:36,120
a way for the CouchDB to tell you that

00:14:34,680 --> 00:14:38,640
there's a new document or it's been

00:14:36,120 --> 00:14:40,650
modified right this is a classic case of

00:14:38,640 --> 00:14:42,750
self distributed denial of service so

00:14:40,650 --> 00:14:44,430
what was happening was when you say hey

00:14:42,750 --> 00:14:46,200
I want 10,000 users from Singapore

00:14:44,430 --> 00:14:48,210
against my website so let's say there's

00:14:46,200 --> 00:14:50,550
20 engines in Singapore they would all

00:14:48,210 --> 00:14:52,800
be waiting on you know the changes fee

00:14:50,550 --> 00:14:54,270
and one of them would all of them wake

00:14:52,800 --> 00:14:56,130
up and they would go and try and write

00:14:54,270 --> 00:14:58,170
that document inside CouchDB so every

00:14:56,130 --> 00:15:00,630
front end web request was actually

00:14:58,170 --> 00:15:02,580
getting translated into 20 or 40 or 60

00:15:00,630 --> 00:15:04,500
different HTTP requests back to CouchDB

00:15:02,580 --> 00:15:06,270
so this was like a massive distributor

00:15:04,500 --> 00:15:08,010
dinala service against her own system

00:15:06,270 --> 00:15:09,480
every time we did this so we thought it

00:15:08,010 --> 00:15:11,040
was all cool right Oh change of speed

00:15:09,480 --> 00:15:13,680
it's got to be cool but turns out it

00:15:11,040 --> 00:15:17,340
sucked so we have to go back and figure

00:15:13,680 --> 00:15:20,460
out how to fix it and and so the fix was

00:15:17,340 --> 00:15:22,200
essentially switch to red is ok so we

00:15:20,460 --> 00:15:23,910
now use red is for all the queuing

00:15:22,200 --> 00:15:25,890
everything is in memory until there's a

00:15:23,910 --> 00:15:28,080
delayed worker actually rescued job that

00:15:25,890 --> 00:15:29,280
eventually takes the test that are

00:15:28,080 --> 00:15:31,410
actually done and then moves them to

00:15:29,280 --> 00:15:33,390
CouchDB for persistence and we didn't

00:15:31,410 --> 00:15:36,060
use rescue for test scheduling for a

00:15:33,390 --> 00:15:38,820
number of reasons first one was back

00:15:36,060 --> 00:15:40,770
when we first started using we actually

00:15:38,820 --> 00:15:43,710
have multiple workers per ec2 instance

00:15:40,770 --> 00:15:44,449
and it kind of varies dynamically with

00:15:43,710 --> 00:15:46,069
her with the rest

00:15:44,449 --> 00:15:47,959
you can have to statically declare that

00:15:46,069 --> 00:15:49,429
you want X number of workers per

00:15:47,959 --> 00:15:51,679
physical machine so we wanted that

00:15:49,429 --> 00:15:53,600
elasticity and the second one was maybe

00:15:51,679 --> 00:15:56,029
because Redis didn't have it we use this

00:15:53,600 --> 00:15:58,549
command and read his call it's kind of

00:15:56,029 --> 00:16:00,589
arcane but it's blocking right pop left

00:15:58,549 --> 00:16:02,660
push ok it's almost like long polling

00:16:00,589 --> 00:16:04,369
that's really what it is so every agent

00:16:02,660 --> 00:16:05,809
every engine that we have would connect

00:16:04,369 --> 00:16:07,970
up the red isn't kind of wait for five

00:16:05,809 --> 00:16:09,559
seconds and wait to see when there's a

00:16:07,970 --> 00:16:11,809
new job or not and if it's not it'll

00:16:09,559 --> 00:16:13,399
come back again and try to connect so

00:16:11,809 --> 00:16:15,679
rescue at that time was actually doing

00:16:13,399 --> 00:16:17,480
every five second polling which is a not

00:16:15,679 --> 00:16:20,149
as efficient so we kind of built our own

00:16:17,480 --> 00:16:21,649
at that time i'll talk about Redis and

00:16:20,149 --> 00:16:23,989
how that plays into bigger a little bit

00:16:21,649 --> 00:16:25,669
later and so this turned out to be

00:16:23,989 --> 00:16:27,649
amazing for us because it dropped the UI

00:16:25,669 --> 00:16:29,359
response time from about 7 50

00:16:27,649 --> 00:16:31,519
milliseconds to less than 20

00:16:29,359 --> 00:16:33,439
milliseconds so that was a pretty huge

00:16:31,519 --> 00:16:38,600
performance benefit for us by moving to

00:16:33,439 --> 00:16:44,290
Redis question come on guys somebody

00:16:38,600 --> 00:16:48,980
asked me what my name is anybody jet lag

00:16:44,290 --> 00:16:50,629
all right so bigger things so this one

00:16:48,980 --> 00:16:53,119
is gets things got getting a little bit

00:16:50,629 --> 00:16:54,139
interesting so the jruby presentation

00:16:53,119 --> 00:16:55,579
right before me you know they were

00:16:54,139 --> 00:16:56,809
talking about GC hiccups so I figured

00:16:55,579 --> 00:16:58,579
I'll kind of show you actually what a GC

00:16:56,809 --> 00:17:00,079
hiccup hiccup looks like I've got this

00:16:58,579 --> 00:17:03,139
little project on github is called vroom

00:17:00,079 --> 00:17:06,500
and it's deployed on Heroku and I've got

00:17:03,139 --> 00:17:07,970
two routes / GC which essentially what i

00:17:06,500 --> 00:17:10,100
did was it if you look at the source

00:17:07,970 --> 00:17:12,079
code i disable garbage collection and

00:17:10,100 --> 00:17:13,939
then every time there's a request new

00:17:12,079 --> 00:17:15,949
request coming to the / GC route every

00:17:13,939 --> 00:17:17,659
10 seconds later it basically manually

00:17:15,949 --> 00:17:19,279
runs a full GC just to kind of

00:17:17,659 --> 00:17:21,589
exaggerated and kind of show you what's

00:17:19,279 --> 00:17:25,939
going on ok so let's see what this looks

00:17:21,589 --> 00:17:27,669
like so amusing blitz make sure that the

00:17:25,939 --> 00:17:29,960
Heroku app is actually up and running

00:17:27,669 --> 00:17:31,940
because they idle the Dinos up for a

00:17:29,960 --> 00:17:33,440
while so here's kind of what we're going

00:17:31,940 --> 00:17:36,110
to do so I'm going to start looking at

00:17:33,440 --> 00:17:37,820
the GC count which basically uses object

00:17:36,110 --> 00:17:39,320
space has a method called count objects

00:17:37,820 --> 00:17:41,059
which essentially categorized as the

00:17:39,320 --> 00:17:42,980
object type and number of objects that

00:17:41,059 --> 00:17:44,149
are inside Ruby interpreter so this is

00:17:42,980 --> 00:17:45,529
just going to showing you what the total

00:17:44,149 --> 00:17:47,350
number of objects are and the different

00:17:45,529 --> 00:17:49,820
types of objects okay this is a simple

00:17:47,350 --> 00:17:52,279
half we're just doing a matter tag and

00:17:49,820 --> 00:17:54,529
refreshing okay so nothing nothing crazy

00:17:52,279 --> 00:17:56,909
here and so here all we're going to do

00:17:54,529 --> 00:17:58,950
is we're going to go from 1 to 100

00:17:56,909 --> 00:18:00,149
current users in 60 seconds okay and

00:17:58,950 --> 00:18:02,849
we're going to hit that rat which is as

00:18:00,149 --> 00:18:05,179
you can see you / GC and let's see what

00:18:02,849 --> 00:18:05,179
happens

00:18:08,800 --> 00:18:12,310
okay so what you're seeing here is

00:18:10,780 --> 00:18:14,470
basically you seeing the response time

00:18:12,310 --> 00:18:15,970
and at the bottom you're seeing sort of

00:18:14,470 --> 00:18:18,330
the hit rate how many per second I'll

00:18:15,970 --> 00:18:20,590
clarify what these two things are and

00:18:18,330 --> 00:18:22,870
you can see starting to see some time

00:18:20,590 --> 00:18:26,260
outs and if you look at this we went

00:18:22,870 --> 00:18:28,210
from 100 objects in memory to about half

00:18:26,260 --> 00:18:29,590
a million objects and when the GC

00:18:28,210 --> 00:18:30,760
actually kicks in that's going to drop a

00:18:29,590 --> 00:18:35,290
little bit and then it's going to kick

00:18:30,760 --> 00:18:37,570
back again ok so these little hiccups

00:18:35,290 --> 00:18:38,920
that you see here is essentially though

00:18:37,570 --> 00:18:40,450
so that that's when the GC is actively

00:18:38,920 --> 00:18:42,490
running so when the GC is running

00:18:40,450 --> 00:18:44,080
because it's a single VM its GC is

00:18:42,490 --> 00:18:46,360
running on the same thread process as

00:18:44,080 --> 00:18:47,740
the primary Sinatra Iraq application

00:18:46,360 --> 00:18:49,810
everything basically comes to a stop

00:18:47,740 --> 00:18:52,300
well GC is all you know all the garbage

00:18:49,810 --> 00:18:53,500
collection happens once it the Ruby

00:18:52,300 --> 00:18:55,420
interpreter gets a breather then

00:18:53,500 --> 00:18:56,620
everything comes back alive again see

00:18:55,420 --> 00:18:58,380
that big hiccup right there that's

00:18:56,620 --> 00:19:01,300
basically what I'm talking about ok and

00:18:58,380 --> 00:19:02,440
so if you look at this object again you

00:19:01,300 --> 00:19:07,360
can kind of see that it's going up and

00:19:02,440 --> 00:19:10,990
down so why does this matter when you

00:19:07,360 --> 00:19:13,180
see ok so why does it matter because

00:19:10,990 --> 00:19:16,120
this was actually captured from one of

00:19:13,180 --> 00:19:17,380
our customers running a rails app they

00:19:16,120 --> 00:19:18,730
were just look I think they had an N

00:19:17,380 --> 00:19:20,320
plus one query issue or something like

00:19:18,730 --> 00:19:21,790
that and using active record and they

00:19:20,320 --> 00:19:23,920
were just loading objects like there's

00:19:21,790 --> 00:19:25,270
no tomorrow so once you start hitting

00:19:23,920 --> 00:19:28,210
the app in a big way everything would

00:19:25,270 --> 00:19:29,710
just go off just stop and huge spikes in

00:19:28,210 --> 00:19:31,990
response time while garbage collector is

00:19:29,710 --> 00:19:33,610
busy just doing stuff what is doing and

00:19:31,990 --> 00:19:35,230
then would come back up so object

00:19:33,610 --> 00:19:36,910
creation in it doesn't matter what

00:19:35,230 --> 00:19:38,260
programming language you use object you

00:19:36,910 --> 00:19:39,820
know object creation the less number of

00:19:38,260 --> 00:19:41,860
objects you have it's a better thing

00:19:39,820 --> 00:19:44,110
just less things to worry about and

00:19:41,860 --> 00:19:45,190
that's probably oh one because you're

00:19:44,110 --> 00:19:47,020
going to have to touch every single

00:19:45,190 --> 00:19:49,870
object during the update cycle to figure

00:19:47,020 --> 00:19:53,950
out which ones to read so GC hiccups or

00:19:49,870 --> 00:19:57,010
a real problem ok so questions on that

00:19:53,950 --> 00:19:58,570
one all right so you can kind of see

00:19:57,010 --> 00:20:04,230
that big hiccup right there and also

00:19:58,570 --> 00:20:04,230
your hit rate taking a dive ok all right

00:20:04,740 --> 00:20:08,880
so I've talked to many people about

00:20:07,170 --> 00:20:10,800
concurrency versus hit rape and there's

00:20:08,880 --> 00:20:12,059
always some confusion about it so

00:20:10,800 --> 00:20:14,670
hopefully I can do a little bit of

00:20:12,059 --> 00:20:16,470
clarification on that so hit rate when

00:20:14,670 --> 00:20:17,880
you when you talked when people post it

00:20:16,470 --> 00:20:19,770
on hacker news or whatever else it is

00:20:17,880 --> 00:20:22,050
you know my website can take this many

00:20:19,770 --> 00:20:23,190
hits per month you know so hit rate is

00:20:22,050 --> 00:20:26,490
basically the number of requests per

00:20:23,190 --> 00:20:27,720
second your website or web app can

00:20:26,490 --> 00:20:30,570
handle what the rails or not doesn't

00:20:27,720 --> 00:20:32,940
matter okay and it's not the same as the

00:20:30,570 --> 00:20:34,559
average response time and it's a pretty

00:20:32,940 --> 00:20:36,059
important distinction because a lot of

00:20:34,559 --> 00:20:38,990
time people tend to bundle those two

00:20:36,059 --> 00:20:42,360
things together okay so that's hit rape

00:20:38,990 --> 00:20:43,770
concurrency which kind of sorta has some

00:20:42,360 --> 00:20:46,590
implications to hit right and I'll show

00:20:43,770 --> 00:20:48,300
you how it's typically when you run you

00:20:46,590 --> 00:20:51,510
know when there are thousand users on

00:20:48,300 --> 00:20:53,460
your website and you go to you know on

00:20:51,510 --> 00:20:55,110
on you easy to instance a line or two

00:20:53,460 --> 00:20:58,140
whatever else it is any type list open

00:20:55,110 --> 00:20:59,940
files else off minus n minus T whatever

00:20:58,140 --> 00:21:02,160
he basically shows you all the number of

00:20:59,940 --> 00:21:03,540
sockets open that's concurrency that's

00:21:02,160 --> 00:21:06,870
basically how many people there are at

00:21:03,540 --> 00:21:09,000
any given time on your application it's

00:21:06,870 --> 00:21:10,500
also known as the simultaneous users so

00:21:09,000 --> 00:21:12,390
when you define it that way what you

00:21:10,500 --> 00:21:15,150
realize is if you if you use a single

00:21:12,390 --> 00:21:19,140
threaded Sinatra application it has a

00:21:15,150 --> 00:21:21,030
concurrency of one okay it because Ruby

00:21:19,140 --> 00:21:22,950
there is no I mean you can use threads

00:21:21,030 --> 00:21:24,990
I'm just talking about vanilla Sinatra

00:21:22,950 --> 00:21:27,240
no threading no external processes no

00:21:24,990 --> 00:21:29,100
rails for no real spy stuff just vanilla

00:21:27,240 --> 00:21:32,850
you know even if you use web break or

00:21:29,100 --> 00:21:35,160
then you've got Sinatra running you can

00:21:32,850 --> 00:21:36,690
only handle one request in its thread on

00:21:35,160 --> 00:21:38,790
process so effectively it has a

00:21:36,690 --> 00:21:42,090
concurrency of one so let's see what it

00:21:38,790 --> 00:21:44,429
actually means okay so I've got this

00:21:42,090 --> 00:21:45,540
other route called sink okay you access

00:21:44,429 --> 00:21:47,490
that you can give it a parameter called

00:21:45,540 --> 00:21:49,260
delay which is in milliseconds and

00:21:47,490 --> 00:21:51,090
there's basically a sleep statement so

00:21:49,260 --> 00:21:53,010
you can see it gets sync it basically

00:21:51,090 --> 00:21:55,410
has a delay it sleeps for that many

00:21:53,010 --> 00:21:58,080
number of seconds and then returns a

00:21:55,410 --> 00:22:00,300
value okay so because it sleeps one

00:21:58,080 --> 00:22:02,730
second you expect a hit parade of about

00:22:00,300 --> 00:22:04,679
one per second okay regardless of the

00:22:02,730 --> 00:22:07,590
number of users and the average response

00:22:04,679 --> 00:22:10,110
time of one second let's try that so

00:22:07,590 --> 00:22:12,780
let's just try a very very simple

00:22:10,110 --> 00:22:14,820
request and it basically comes back and

00:22:12,780 --> 00:22:15,929
says about one second you know there's

00:22:14,820 --> 00:22:17,080
some margin of error that it's not

00:22:15,929 --> 00:22:18,670
exactly right right so

00:22:17,080 --> 00:22:20,770
because we're coming from Virginia

00:22:18,670 --> 00:22:23,290
Heroku is also in Virginia data center

00:22:20,770 --> 00:22:25,300
or latency whatever okay so now let's

00:22:23,290 --> 00:22:28,510
run it's really really simple load test

00:22:25,300 --> 00:22:30,040
1 21 and 60 basically we just have one

00:22:28,510 --> 00:22:32,200
user so the effect that we're simulating

00:22:30,040 --> 00:22:34,300
here is somebody with the browser

00:22:32,200 --> 00:22:36,370
essentially holding apple are the whole

00:22:34,300 --> 00:22:38,140
time okay so they're not letting it go

00:22:36,370 --> 00:22:39,430
so one user goes to the website load to

00:22:38,140 --> 00:22:40,840
the page comes back as soon as it

00:22:39,430 --> 00:22:42,250
finishes goes again comes back goes

00:22:40,840 --> 00:22:44,470
again comes back for about 60 seconds

00:22:42,250 --> 00:22:48,300
just one user so when you try this

00:22:44,470 --> 00:22:48,300
against this app let's see what happens

00:22:55,980 --> 00:22:59,250
wireless issues

00:23:01,910 --> 00:23:04,840
lock up

00:23:08,790 --> 00:23:16,490
anybody check for us is active does

00:23:14,220 --> 00:23:16,490
anything

00:23:19,110 --> 00:23:23,030
it's just this window that loved up

00:23:39,720 --> 00:23:48,320
alright so let's try this again and

00:23:45,240 --> 00:23:48,320
let's hope it works

00:23:52,220 --> 00:23:58,429
and hung again all right so we'll keep

00:23:55,010 --> 00:23:59,720
going and see what happens so typically

00:23:58,429 --> 00:24:01,250
what happens is when you do again one

00:23:59,720 --> 00:24:06,169
user everything's going to be all right

00:24:01,250 --> 00:24:08,000
right just one one second hit in a one

00:24:06,169 --> 00:24:10,789
per second hit rate and the average

00:24:08,000 --> 00:24:12,710
response time of one second okay so what

00:24:10,789 --> 00:24:14,059
happens if you increase concurrency so

00:24:12,710 --> 00:24:15,710
when you typically increase concurrency

00:24:14,059 --> 00:24:17,720
you can only fit one per second and

00:24:15,710 --> 00:24:18,919
there's only one user a lot on your

00:24:17,720 --> 00:24:21,140
website so typically only slight

00:24:18,919 --> 00:24:22,520
increase in concurrency what the user

00:24:21,140 --> 00:24:24,470
actually ends up experiencing is

00:24:22,520 --> 00:24:25,730
timeouts and errors that's what happens

00:24:24,470 --> 00:24:26,809
right so a lot of people say that you

00:24:25,730 --> 00:24:28,850
know that's why you know WordPress

00:24:26,809 --> 00:24:30,289
caching is a big deal or cashing in side

00:24:28,850 --> 00:24:31,789
rails is a big deal because what are you

00:24:30,289 --> 00:24:33,080
trying to effectively do is you're

00:24:31,789 --> 00:24:35,120
trying to return the data back to the

00:24:33,080 --> 00:24:37,039
user as fast as you can so your response

00:24:35,120 --> 00:24:38,240
time is really short and so that it can

00:24:37,039 --> 00:24:40,880
try to accommodate as many users as

00:24:38,240 --> 00:24:42,080
possible okay so one last try if it

00:24:40,880 --> 00:24:44,110
doesn't work I'm going to give this one

00:24:42,080 --> 00:24:44,110
up

00:25:00,419 --> 00:25:05,039
okay so essentially what we're doing is

00:25:02,129 --> 00:25:06,389
I put 100 in there if this locks up then

00:25:05,039 --> 00:25:11,009
I'm stopping the demo I'm not sure

00:25:06,389 --> 00:25:13,649
what's going on okay so so the next one

00:25:11,009 --> 00:25:15,359
is it's an interesting one just a

00:25:13,649 --> 00:25:17,669
variation so we're using asynchronous

00:25:15,359 --> 00:25:19,529
Sinatra and what you use this event

00:25:17,669 --> 00:25:21,600
machine underneath it and so we have

00:25:19,529 --> 00:25:23,730
this route called a sink which is very

00:25:21,600 --> 00:25:25,799
similar to the sink except instead of

00:25:23,730 --> 00:25:28,919
returning the response right away you're

00:25:25,799 --> 00:25:30,389
now telling event machine to sleep you

00:25:28,919 --> 00:25:31,710
know to wake you up it's almost like a

00:25:30,389 --> 00:25:33,659
node.js callback is really what you're

00:25:31,710 --> 00:25:35,820
trying to do right basically saying wake

00:25:33,659 --> 00:25:38,789
me up in a second and then return the

00:25:35,820 --> 00:25:41,070
body with that with that element so this

00:25:38,789 --> 00:25:42,389
method itself when you executed if you

00:25:41,070 --> 00:25:45,299
look at sort of the how the method

00:25:42,389 --> 00:25:46,799
execute this will return right away but

00:25:45,299 --> 00:25:49,559
the HTTP connection is still pending

00:25:46,799 --> 00:25:51,330
it's kind of waiting and so one second

00:25:49,559 --> 00:25:52,799
later event machine wakes up and invokes

00:25:51,330 --> 00:25:55,649
this callback and then you return back

00:25:52,799 --> 00:25:58,830
to the socket is actively open so each

00:25:55,649 --> 00:26:00,720
request still takes one second okay but

00:25:58,830 --> 00:26:02,580
what you gain is concurrency because

00:26:00,720 --> 00:26:05,279
you're multiplexing it's the same thing

00:26:02,580 --> 00:26:06,929
as a load balancer or a Heroku dinos or

00:26:05,279 --> 00:26:08,669
you know whatever terminology that you

00:26:06,929 --> 00:26:11,249
use is if you have a load balancer with

00:26:08,669 --> 00:26:13,409
100 nodes in it if each node takes about

00:26:11,249 --> 00:26:15,239
a second to respond back because it's

00:26:13,409 --> 00:26:17,039
learning this really complex page but

00:26:15,239 --> 00:26:18,090
you still get a concurrency of 100 even

00:26:17,039 --> 00:26:20,580
though the average response time is

00:26:18,090 --> 00:26:21,989
about a second does that make sense yeah

00:26:20,580 --> 00:26:25,440
so that's really what we're trying to do

00:26:21,989 --> 00:26:27,720
here all right so a connection pool is

00:26:25,440 --> 00:26:29,460
another interesting one again you can

00:26:27,720 --> 00:26:30,960
look at the code it's it's a pretty easy

00:26:29,460 --> 00:26:32,009
I just it's like a fake connection pool

00:26:30,960 --> 00:26:33,389
I don't really have a real database

00:26:32,009 --> 00:26:35,210
there but it kind of uses them in

00:26:33,389 --> 00:26:37,499
machines to create congestion and

00:26:35,210 --> 00:26:39,059
connection pool the idea is you know you

00:26:37,499 --> 00:26:40,559
maybe have a post course database but

00:26:39,059 --> 00:26:41,850
the connection pool of 50 okay that

00:26:40,559 --> 00:26:43,320
basically means at any given time you

00:26:41,850 --> 00:26:45,690
have 50 connections back up to the

00:26:43,320 --> 00:26:48,600
postcards that's all you can handle now

00:26:45,690 --> 00:26:49,919
up to 50 concurrency you're not going to

00:26:48,600 --> 00:26:51,659
experience any problem because

00:26:49,919 --> 00:26:53,580
everything is going to be okay there's

00:26:51,659 --> 00:26:55,350
hundreds 50 users coming in I've got 50

00:26:53,580 --> 00:26:56,700
50 pool 50 connections in the connection

00:26:55,350 --> 00:26:58,379
pool you're going to route all the

00:26:56,700 --> 00:27:00,139
traffic through postgres and do some

00:26:58,379 --> 00:27:03,029
complex database queries and return back

00:27:00,139 --> 00:27:04,350
now once the concurrency goes up that's

00:27:03,029 --> 00:27:05,609
when all hell breaks loose that's

00:27:04,350 --> 00:27:07,679
basically like an eight-lane highway

00:27:05,609 --> 00:27:09,450
merging into a one lane okay so you've

00:27:07,679 --> 00:27:11,249
got a hundred concurrent users coming in

00:27:09,450 --> 00:27:12,110
they've got a connection full of 50

00:27:11,249 --> 00:27:14,240
you're gonna have to fit

00:27:12,110 --> 00:27:16,820
somehow but you can't fit them so what

00:27:14,240 --> 00:27:18,530
happens you got to back them up right so

00:27:16,820 --> 00:27:19,940
things start backing up so what happens

00:27:18,530 --> 00:27:21,500
is if the concurrency goes up this

00:27:19,940 --> 00:27:23,179
happens when you get sloshed on it or

00:27:21,500 --> 00:27:24,860
when you get a hacker news or Twitter or

00:27:23,179 --> 00:27:27,140
whatever else it is it's basically this

00:27:24,860 --> 00:27:28,580
huge flux of people coming in your

00:27:27,140 --> 00:27:30,590
connection pool is probably tiny and

00:27:28,580 --> 00:27:32,420
everybody starts getting longer and

00:27:30,590 --> 00:27:34,490
longer and longer and longer usually

00:27:32,420 --> 00:27:36,080
ending up in timeouts and all hit all

00:27:34,490 --> 00:27:37,610
failed to hail whale I mean that whole

00:27:36,080 --> 00:27:41,240
thing all right so that's what you see

00:27:37,610 --> 00:27:44,150
in terms of the connection poles one

00:27:41,240 --> 00:27:47,950
last try on this demo otherwise I want

00:27:44,150 --> 00:27:47,950
to throw this out okay so

00:27:59,110 --> 00:28:03,520
okay it's going now so in the case of

00:28:02,410 --> 00:28:04,450
connection pool you actually start

00:28:03,520 --> 00:28:07,870
seeing what's happening so you're

00:28:04,450 --> 00:28:09,940
starting to see the timeout okay because

00:28:07,870 --> 00:28:11,860
as we ramp up the user the connection

00:28:09,940 --> 00:28:13,360
pool size as I mentioned it's kind of

00:28:11,860 --> 00:28:16,570
you know it's mocked but the connection

00:28:13,360 --> 00:28:17,980
pool is about size of 10 and that's all

00:28:16,570 --> 00:28:19,150
failed you know all hail that fail whale

00:28:17,980 --> 00:28:20,559
nothing is going through because

00:28:19,150 --> 00:28:23,500
everybody's timing out if we're just

00:28:20,559 --> 00:28:25,270
trying to jam as much as we can and we

00:28:23,500 --> 00:28:26,679
can't do anything about it so it's a

00:28:25,270 --> 00:28:28,000
pretty interesting way of actually

00:28:26,679 --> 00:28:30,880
looking at the connection pool problem

00:28:28,000 --> 00:28:33,010
now the challenge is this most people

00:28:30,880 --> 00:28:34,630
when they do a simple ping check against

00:28:33,010 --> 00:28:35,860
their side and claim like in a like 200

00:28:34,630 --> 00:28:37,690
millisecond response time this is

00:28:35,860 --> 00:28:40,480
amazing life at my site is just super

00:28:37,690 --> 00:28:42,010
hot wait till the concurrency starts

00:28:40,480 --> 00:28:43,510
increasing past the pool size that's

00:28:42,010 --> 00:28:45,370
when this manifests itself so at very

00:28:43,510 --> 00:28:47,260
low pings you're never going to see this

00:28:45,370 --> 00:28:48,760
problem but once the number of users

00:28:47,260 --> 00:28:54,250
starts creeping up that's when you see

00:28:48,760 --> 00:28:55,540
this huge problem okay all right so like

00:28:54,250 --> 00:28:57,820
I said you know we use riddles quite a

00:28:55,540 --> 00:28:59,830
bit in bliss and for a number of things

00:28:57,820 --> 00:29:01,299
you know we use for registration so when

00:28:59,830 --> 00:29:02,980
every time we ought to scale the total

00:29:01,299 --> 00:29:04,150
number of agents in the system they risk

00:29:02,980 --> 00:29:05,500
we come and register with various so

00:29:04,150 --> 00:29:07,360
it's almost like an IRC channel where

00:29:05,500 --> 00:29:09,340
these things come and go we use it as a

00:29:07,360 --> 00:29:11,380
right through cash we use it for job

00:29:09,340 --> 00:29:13,870
scheduling for actually the test

00:29:11,380 --> 00:29:15,400
scheduling we also use rescue for things

00:29:13,870 --> 00:29:18,250
like sending emails and whatever else it

00:29:15,400 --> 00:29:21,790
is for API throttling but here's the key

00:29:18,250 --> 00:29:23,890
thing red is it's actually a distributed

00:29:21,790 --> 00:29:26,290
dictionary with a beautiful protocol and

00:29:23,890 --> 00:29:28,360
built on top of it okay it's it's this

00:29:26,290 --> 00:29:30,490
the ultimate manifestation of you know

00:29:28,360 --> 00:29:31,419
Big O and if you go to register you and

00:29:30,490 --> 00:29:32,890
you look at all the different commands

00:29:31,419 --> 00:29:35,080
and what it can do you'll see big ol

00:29:32,890 --> 00:29:37,720
everywhere and that's for a reason right

00:29:35,080 --> 00:29:39,669
because if you have a data structure

00:29:37,720 --> 00:29:41,950
like a linked list or an array or a hash

00:29:39,669 --> 00:29:44,380
table or sets or solid sets they're all

00:29:41,950 --> 00:29:46,150
just ultimately you know book examples

00:29:44,380 --> 00:29:47,590
of you know different data structures

00:29:46,150 --> 00:29:49,510
implemented except where this does it in

00:29:47,590 --> 00:29:51,580
memory over a network end of the day

00:29:49,510 --> 00:29:53,080
it's no different from using Ruby hashes

00:29:51,580 --> 00:29:57,120
etc it's just you now have a server

00:29:53,080 --> 00:29:59,049
that's keeping all the data with it so

00:29:57,120 --> 00:30:02,799
so the thing that you got to watch out

00:29:59,049 --> 00:30:05,380
for is this if you have a list of things

00:30:02,799 --> 00:30:07,570
and red eyes so finding the index of a

00:30:05,380 --> 00:30:09,070
particular element or inserting an

00:30:07,570 --> 00:30:11,320
element at a certain point inside the

00:30:09,070 --> 00:30:12,390
list or removing an element these are

00:30:11,320 --> 00:30:14,010
all em

00:30:12,390 --> 00:30:15,750
if you've got a million entries inside

00:30:14,010 --> 00:30:17,580
where this as a linked list watch out

00:30:15,750 --> 00:30:18,540
for these things so that's going to come

00:30:17,580 --> 00:30:19,980
back and bite you and you're gonna

00:30:18,540 --> 00:30:22,350
complain or you know it might say oh

00:30:19,980 --> 00:30:23,610
rails are slow which is the default way

00:30:22,350 --> 00:30:25,140
to talk about these problems anyway so

00:30:23,610 --> 00:30:26,850
you're gonna have to dig dig deeper a

00:30:25,140 --> 00:30:29,100
little bit and then you find out that

00:30:26,850 --> 00:30:32,220
you know here's a problem same thing

00:30:29,100 --> 00:30:34,620
with sets so sets by default you know

00:30:32,220 --> 00:30:36,930
it's the way various implements is it's

00:30:34,620 --> 00:30:39,870
something called a it's a form of a

00:30:36,930 --> 00:30:41,430
linked list but they actually have an

00:30:39,870 --> 00:30:44,370
interesting implementation there it's

00:30:41,430 --> 00:30:46,050
all log in but when you take two sits

00:30:44,370 --> 00:30:49,140
and it's two sets and you try to do a

00:30:46,050 --> 00:30:51,510
difference or you do a union at that

00:30:49,140 --> 00:30:52,710
point it all becomes 0 n ok so you can

00:30:51,510 --> 00:30:54,240
have to watch shots that means you're

00:30:52,710 --> 00:30:55,680
taking two sets of million entries and

00:30:54,240 --> 00:30:57,180
you turn into an intersection somebody

00:30:55,680 --> 00:30:59,160
has to do the work all right it's not

00:30:57,180 --> 00:31:00,870
all out of magic so and so you're gonna

00:30:59,160 --> 00:31:01,920
have to watch out for that same thing

00:31:00,870 --> 00:31:04,230
with sets you know some of the other

00:31:01,920 --> 00:31:06,510
operation like intersection intersection

00:31:04,230 --> 00:31:08,370
you know that's 0 n times m that means

00:31:06,510 --> 00:31:10,290
if you've got a set of n elements got

00:31:08,370 --> 00:31:12,480
another set of M elements you try to do

00:31:10,290 --> 00:31:14,760
intersection that's order of n times m

00:31:12,480 --> 00:31:17,550
so remember that girl exponential curve

00:31:14,760 --> 00:31:19,260
that goes up that's what happens ok so

00:31:17,550 --> 00:31:25,710
that's definitely gonna have to watch

00:31:19,260 --> 00:31:27,420
out for it all right so so I'm kind of

00:31:25,710 --> 00:31:28,620
wrapping up cuz i guess i skipped over a

00:31:27,420 --> 00:31:30,840
bunch or something or maybe I'm just

00:31:28,620 --> 00:31:33,330
slowing down too much jet lag so

00:31:30,840 --> 00:31:34,230
probably my last slide I'm happy to take

00:31:33,330 --> 00:31:35,730
questions after that but really

00:31:34,230 --> 00:31:37,830
performance is really just a fun sport

00:31:35,730 --> 00:31:39,690
once you start digging in their Ruby or

00:31:37,830 --> 00:31:42,540
not it's definitely a fun sport because

00:31:39,690 --> 00:31:44,250
usually it boils down to like I said

00:31:42,540 --> 00:31:46,110
data structures and algorithms you know

00:31:44,250 --> 00:31:47,700
so when we were doing blitz and early

00:31:46,110 --> 00:31:49,500
days of blitz you know we had a customer

00:31:47,700 --> 00:31:51,420
that was running geospatial queries on

00:31:49,500 --> 00:31:52,710
their database and you've probably seen

00:31:51,420 --> 00:31:54,990
this in production to you know they have

00:31:52,710 --> 00:31:56,790
yet you know it was a it was an iphone

00:31:54,990 --> 00:31:58,050
sending some kind of restful query with

00:31:56,790 --> 00:31:59,130
the latter lat and long and they were

00:31:58,050 --> 00:32:01,650
trying to look it up the care that heat

00:31:59,130 --> 00:32:03,660
map really cool app iphone app and so

00:32:01,650 --> 00:32:05,970
they had index the X column they index

00:32:03,660 --> 00:32:08,550
the y column but they had not index X&Y

00:32:05,970 --> 00:32:10,200
together so now what happens to is if

00:32:08,550 --> 00:32:11,310
they got a million entries million users

00:32:10,200 --> 00:32:13,680
all in there trying to generate a heat

00:32:11,310 --> 00:32:15,390
map when we ran blitz against it would

00:32:13,680 --> 00:32:17,940
essentially the database would just get

00:32:15,390 --> 00:32:19,740
pegged sip utilization on them on the

00:32:17,940 --> 00:32:21,630
middle tier the web server peachy you

00:32:19,740 --> 00:32:22,950
know it's all awesome looks great but

00:32:21,630 --> 00:32:25,020
the database was just getting hammered

00:32:22,950 --> 00:32:26,100
so you start digging in there

00:32:25,020 --> 00:32:28,290
start like returning a lot of load

00:32:26,100 --> 00:32:29,520
either right so and then we start

00:32:28,290 --> 00:32:31,980
digging into it we found an index

00:32:29,520 --> 00:32:34,410
problem guess what older that is that's

00:32:31,980 --> 00:32:36,870
a linear right because now you don't

00:32:34,410 --> 00:32:38,910
have an index nice log inquiries on the

00:32:36,870 --> 00:32:40,440
x and y column together because x and y

00:32:38,910 --> 00:32:41,880
we're indexed separately the database

00:32:40,440 --> 00:32:43,620
was essentially do in linear lookups

00:32:41,880 --> 00:32:46,440
trying to find a geospatial queries so

00:32:43,620 --> 00:32:48,090
million users even one use are trying to

00:32:46,440 --> 00:32:49,500
access the Jews spatial query all of a

00:32:48,090 --> 00:32:51,510
sudden the database would come crashing

00:32:49,500 --> 00:32:53,580
down so performance is definitely a lot

00:32:51,510 --> 00:32:55,020
of fun again just takes a little bit of

00:32:53,580 --> 00:32:56,420
you know experience and kind of poking

00:32:55,020 --> 00:32:58,800
around to figure out what's going on and

00:32:56,420 --> 00:33:01,920
bottom line is it's not always rails

00:32:58,800 --> 00:33:04,020
okay so that was the end of my

00:33:01,920 --> 00:33:05,270
conversation I mean my my talk so happy

00:33:04,020 --> 00:33:07,850
to take any questions if you have it

00:33:05,270 --> 00:33:10,850
otherwise it's time to go hit the beach

00:33:07,850 --> 00:33:10,850
thank

00:33:23,200 --> 00:33:25,260

YouTube URL: https://www.youtube.com/watch?v=MBUUmTK3YDc


