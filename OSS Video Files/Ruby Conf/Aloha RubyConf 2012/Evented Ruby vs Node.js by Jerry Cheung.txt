Title: Evented Ruby vs Node.js by Jerry Cheung
Publication date: 2020-01-28
Playlist: Aloha RubyConf 2012
Description: 
	Help us caption & translate this video!

http://amara.org/v/FGgT/
Captions: 
	00:00:14,690 --> 00:00:22,500
talk i'm gonna give as a vented Ruby

00:00:18,240 --> 00:00:25,140
versus nodejs first a little bit about

00:00:22,500 --> 00:00:28,050
myself my name is jerry i work at github

00:00:25,140 --> 00:00:30,630
on the enterprise team I primarily work

00:00:28,050 --> 00:00:33,329
in Ruby and JavaScript but in the last

00:00:30,630 --> 00:00:35,399
year I've been playing what invented

00:00:33,329 --> 00:00:37,770
programming a bit and I kind of wanted

00:00:35,399 --> 00:00:40,530
to share some of the things I've come

00:00:37,770 --> 00:00:47,000
across and how you can use it in your

00:00:40,530 --> 00:00:49,830
own projects before I go into the talk

00:00:47,000 --> 00:00:51,300
here's kind of the things I keep in the

00:00:49,830 --> 00:00:54,510
back of my head whenever I think about

00:00:51,300 --> 00:00:56,310
performance problems I think whenever we

00:00:54,510 --> 00:00:59,220
optimize for performance it should

00:00:56,310 --> 00:01:03,060
always be something that helps our

00:00:59,220 --> 00:01:05,360
end-users a lot of the times we go after

00:01:03,060 --> 00:01:08,610
these kind of micro optimizations where

00:01:05,360 --> 00:01:10,470
it's very cool technically but really

00:01:08,610 --> 00:01:12,659
it's not worth the level of effort that

00:01:10,470 --> 00:01:14,070
you have to put in so it's important to

00:01:12,659 --> 00:01:18,329
kind of figure out the lowest hanging

00:01:14,070 --> 00:01:22,649
fruit as far as performance problems

00:01:18,329 --> 00:01:24,569
goes in your project and to that end you

00:01:22,649 --> 00:01:26,329
really want to make sustainable changes

00:01:24,569 --> 00:01:28,889
in your projects changes that are

00:01:26,329 --> 00:01:31,469
relatively straightforward to make but

00:01:28,889 --> 00:01:32,939
easy to maintain in the long run you

00:01:31,469 --> 00:01:35,939
don't want to come back six months later

00:01:32,939 --> 00:01:39,420
and be like I have no idea why I did

00:01:35,939 --> 00:01:44,369
this it's all broken now was it really

00:01:39,420 --> 00:01:46,770
worth it so an overview of what I'm

00:01:44,369 --> 00:01:49,319
going to cover a lot of invented stuff

00:01:46,770 --> 00:01:51,840
I'll give a brief intro to what a vented

00:01:49,319 --> 00:01:54,659
programming is at a very high level and

00:01:51,840 --> 00:01:56,880
then cover how that applies to

00:01:54,659 --> 00:02:00,749
server-side programming and specifically

00:01:56,880 --> 00:02:02,459
to the web then I'll go over some of the

00:02:00,749 --> 00:02:04,889
similarities and differences of doing a

00:02:02,459 --> 00:02:07,499
vented programming in JavaScript versus

00:02:04,889 --> 00:02:09,590
doing it in Ruby and what some of the

00:02:07,499 --> 00:02:12,270
pros and cons are for each of those

00:02:09,590 --> 00:02:15,450
after that I'll talk about how you can

00:02:12,270 --> 00:02:18,090
apply a vented programming techniques to

00:02:15,450 --> 00:02:21,269
your existing application either within

00:02:18,090 --> 00:02:22,830
your rails app or writing specific

00:02:21,269 --> 00:02:27,480
features to run alongside

00:02:22,830 --> 00:02:30,600
web app so a vented program what is it

00:02:27,480 --> 00:02:32,880
all it is is registering functioning

00:02:30,600 --> 00:02:34,920
callbacks for events that we care about

00:02:32,880 --> 00:02:37,590
so we already do this every day when

00:02:34,920 --> 00:02:39,420
we're doing client side JavaScript this

00:02:37,590 --> 00:02:42,210
snippet of code is just saying whenever

00:02:39,420 --> 00:02:48,240
there's a click on the Dom we should

00:02:42,210 --> 00:02:50,640
change the text color to red and that

00:02:48,240 --> 00:02:52,470
little code snippet is an example of the

00:02:50,640 --> 00:02:56,010
reactor pattern so what the reactor

00:02:52,470 --> 00:02:57,930
pattern is it's you have a system called

00:02:56,010 --> 00:03:00,090
the reactor that's responsible for

00:02:57,930 --> 00:03:04,080
listening to the events that are

00:03:00,090 --> 00:03:07,110
triggered and in our case the reactor is

00:03:04,080 --> 00:03:08,940
a browser for example when it notices

00:03:07,110 --> 00:03:11,010
there's a click event or a drag a bit it

00:03:08,940 --> 00:03:16,200
delivers those events to any callbacks

00:03:11,010 --> 00:03:19,740
you register certain domains naturally

00:03:16,200 --> 00:03:22,110
lend themselves to this evented reactor

00:03:19,740 --> 00:03:24,600
pattern when we're talking about things

00:03:22,110 --> 00:03:26,640
like UI events keyboard mouse and touch

00:03:24,600 --> 00:03:28,050
there's no way for us to kind of

00:03:26,640 --> 00:03:30,660
anticipate when those are going to

00:03:28,050 --> 00:03:33,269
happen so obviously you have to define

00:03:30,660 --> 00:03:35,640
the handlers for those and register them

00:03:33,269 --> 00:03:37,320
at the beginning your program so when

00:03:35,640 --> 00:03:40,500
these events do happen you know what to

00:03:37,320 --> 00:03:43,769
do and the nice thing about these

00:03:40,500 --> 00:03:46,950
reusable reactors it's that it saves us

00:03:43,769 --> 00:03:50,250
a lot of time in plumbing if we didn't

00:03:46,950 --> 00:03:52,800
have these then suddenly we spend all of

00:03:50,250 --> 00:03:56,519
our time writing mouse detection instead

00:03:52,800 --> 00:03:59,489
of building useful things but the thing

00:03:56,519 --> 00:04:02,220
to keep in mind is that even though it

00:03:59,489 --> 00:04:05,000
makes it's very intuitive to have UI

00:04:02,220 --> 00:04:08,489
events you can really define events for

00:04:05,000 --> 00:04:11,850
arbitrary things so another event might

00:04:08,489 --> 00:04:14,970
be when the wireless becomes available

00:04:11,850 --> 00:04:19,200
or when there's data available on the

00:04:14,970 --> 00:04:22,260
disk for reading from the node.js site

00:04:19,200 --> 00:04:27,800
we see that nodejs uses an event-driven

00:04:22,260 --> 00:04:29,760
non-blocking i/o model and it kind of

00:04:27,800 --> 00:04:31,289
overlaps with some of the terms we're

00:04:29,760 --> 00:04:32,740
talking about but what does it actually

00:04:31,289 --> 00:04:36,880
mean

00:04:32,740 --> 00:04:39,130
in a server-side context so unlike the

00:04:36,880 --> 00:04:41,889
browser example you can think of node as

00:04:39,130 --> 00:04:44,139
a general-purpose reactor so instead of

00:04:41,889 --> 00:04:47,500
dealing with mouse clicks and events you

00:04:44,139 --> 00:04:51,240
can have it as a reactor to deliver

00:04:47,500 --> 00:04:55,240
arbitrary events that you care about and

00:04:51,240 --> 00:04:57,910
as far as blocking i/o goes I love this

00:04:55,240 --> 00:05:00,910
quote an image from Christian

00:04:57,910 --> 00:05:02,710
foreign-eeze he says if Ram was an f-18

00:05:00,910 --> 00:05:06,580
Hornet with a max speed of 1200 miles an

00:05:02,710 --> 00:05:09,400
hour then disk access speed is a banana

00:05:06,580 --> 00:05:12,069
slug with the top speed of 7,000 over

00:05:09,400 --> 00:05:15,819
mile per hour and intuitively I think we

00:05:12,069 --> 00:05:17,560
all have a sense for this that CPU is

00:05:15,819 --> 00:05:19,090
going to be faster than memory memory is

00:05:17,560 --> 00:05:22,720
going to be faster than deerskin disk

00:05:19,090 --> 00:05:25,930
faster than network access but the thing

00:05:22,720 --> 00:05:28,090
to keep in mind is whenever we whenever

00:05:25,930 --> 00:05:30,639
there isn't data available for the CPU

00:05:28,090 --> 00:05:37,000
to process on then we have to idle the

00:05:30,639 --> 00:05:38,860
CPU and wait for that so the operating

00:05:37,000 --> 00:05:41,770
system and hardware caches basically

00:05:38,860 --> 00:05:46,300
hides this from us when we say filed

00:05:41,770 --> 00:05:48,460
that read file that text it works like

00:05:46,300 --> 00:05:52,000
we would expect but under the hood the

00:05:48,460 --> 00:05:58,889
CPU might be idling and you're wasting

00:05:52,000 --> 00:06:02,680
processing basically luckily for us the

00:05:58,889 --> 00:06:05,139
seat the OS is smart enough to basically

00:06:02,680 --> 00:06:08,319
switch between different processes when

00:06:05,139 --> 00:06:12,400
it notices that it's one cpu is it busy

00:06:08,319 --> 00:06:16,569
so the reason why when we load up a song

00:06:12,400 --> 00:06:18,610
on iTunes it doesn't cause the rest of

00:06:16,569 --> 00:06:20,650
our system to kind of grind to a halt

00:06:18,610 --> 00:06:22,830
you can still do stuff in your browser

00:06:20,650 --> 00:06:27,069
and your rails process will keep running

00:06:22,830 --> 00:06:30,210
and it's really nice because even though

00:06:27,069 --> 00:06:34,270
this might not be the most optimal way

00:06:30,210 --> 00:06:40,090
it's really simple this process

00:06:34,270 --> 00:06:41,860
concurrency so what nodejs gives us is

00:06:40,090 --> 00:06:43,990
it optimizes the iowa step one step

00:06:41,860 --> 00:06:45,689
further by pushing some of the

00:06:43,990 --> 00:06:47,489
responsibility into the apple

00:06:45,689 --> 00:06:49,469
tation layer so rather than having just

00:06:47,489 --> 00:06:51,929
the operating systems which between

00:06:49,469 --> 00:06:54,419
processes now you have a reactor in the

00:06:51,929 --> 00:06:56,579
node process and whenever there's i/o

00:06:54,419 --> 00:07:02,129
callbacks it's able to switch between

00:06:56,579 --> 00:07:04,399
tasks internally so up until now we're

00:07:02,129 --> 00:07:07,649
talking about a vented programming but

00:07:04,399 --> 00:07:09,389
why should we care about this for web

00:07:07,649 --> 00:07:12,809
apps especially since we already have

00:07:09,389 --> 00:07:15,360
process concurrency well the reason we

00:07:12,809 --> 00:07:17,669
should care is because we are still

00:07:15,360 --> 00:07:21,809
doing a lot of blocking io all over the

00:07:17,669 --> 00:07:23,999
place and I really enjoyed errands talk

00:07:21,809 --> 00:07:26,519
about how the direction we're going to

00:07:23,999 --> 00:07:29,369
go in the future for kind of slimming

00:07:26,519 --> 00:07:34,949
this down and taking advantage of more

00:07:29,369 --> 00:07:36,089
of our resources so a few examples of

00:07:34,949 --> 00:07:38,909
things that we're going to run into

00:07:36,089 --> 00:07:41,269
every day is we're definitely going to

00:07:38,909 --> 00:07:44,069
touch a database we're going to hit

00:07:41,269 --> 00:07:46,469
external api's and that's going to be a

00:07:44,069 --> 00:07:48,989
very slow blocking coil and even things

00:07:46,469 --> 00:07:50,639
like when you resize an image when you

00:07:48,989 --> 00:07:53,339
shell out to a different process you're

00:07:50,639 --> 00:07:56,009
basically waiting for the contents of

00:07:53,339 --> 00:08:00,539
that process to finish before you can

00:07:56,009 --> 00:08:03,119
get back to processing so if we were

00:08:00,539 --> 00:08:05,789
writing a little controller to save

00:08:03,119 --> 00:08:08,279
tweets for example in the first line

00:08:05,789 --> 00:08:10,110
we're creating a new tweet object then

00:08:08,279 --> 00:08:12,899
we might want to shorten any links in

00:08:10,110 --> 00:08:15,239
the text and then we want to save the

00:08:12,899 --> 00:08:17,879
tweet to a database so even in just

00:08:15,239 --> 00:08:20,789
these three lines we're going out to the

00:08:17,879 --> 00:08:25,979
network and we're also touching the file

00:08:20,789 --> 00:08:27,989
system and when when we are blocking on

00:08:25,979 --> 00:08:31,529
Io what happens is from the CPUs

00:08:27,989 --> 00:08:33,809
perspective is we can't handle more than

00:08:31,529 --> 00:08:36,300
one incoming request at a time we have

00:08:33,809 --> 00:08:38,459
to finish the first request before we

00:08:36,300 --> 00:08:43,889
can start handling another incoming user

00:08:38,459 --> 00:08:46,829
and the way we get around this right now

00:08:43,889 --> 00:08:48,809
today in rails is we spool up multiple

00:08:46,829 --> 00:08:52,259
rails processes and each of those

00:08:48,809 --> 00:08:54,959
handles one user at a time it's simple

00:08:52,259 --> 00:08:57,980
it's nice it works but it chews through

00:08:54,959 --> 00:08:57,980
a lot of memory

00:08:58,520 --> 00:09:04,470
if we rewrote that same little bit of

00:09:01,590 --> 00:09:06,690
code in node what we do is change all of

00:09:04,470 --> 00:09:10,110
the blocking calls into function

00:09:06,690 --> 00:09:13,170
callbacks so instead of calling

00:09:10,110 --> 00:09:15,690
shortened links and save directly we

00:09:13,170 --> 00:09:18,930
basically say here is what you should do

00:09:15,690 --> 00:09:20,900
when you finish so shorten my links when

00:09:18,930 --> 00:09:23,370
that's done call this function callback

00:09:20,900 --> 00:09:25,310
save my tweet to the database when

00:09:23,370 --> 00:09:29,010
that's done call the function call bank

00:09:25,310 --> 00:09:32,070
and when we draw out what the

00:09:29,010 --> 00:09:34,170
concurrency looks like here when we

00:09:32,070 --> 00:09:36,360
start node we're already running in a

00:09:34,170 --> 00:09:40,350
reactor so that's the first line on the

00:09:36,360 --> 00:09:42,150
top and when the first request comes in

00:09:40,350 --> 00:09:44,160
we start doing some processing but

00:09:42,150 --> 00:09:46,200
because all we're doing is registering

00:09:44,160 --> 00:09:49,130
callbacks we finish really quickly and

00:09:46,200 --> 00:09:55,050
give control right back to the reactor

00:09:49,130 --> 00:09:57,390
so that as soon as that first red line

00:09:55,050 --> 00:10:00,690
is happening which is the blocking i/o

00:09:57,390 --> 00:10:04,950
from the first request the reactor

00:10:00,690 --> 00:10:08,400
thread is what has control so it's able

00:10:04,950 --> 00:10:12,420
to start another request while the CPU

00:10:08,400 --> 00:10:15,150
isn't doing anything at some point later

00:10:12,420 --> 00:10:19,050
the i/o finishes for the first request

00:10:15,150 --> 00:10:22,050
so we invoke the callback and same with

00:10:19,050 --> 00:10:24,630
the last request notice that even though

00:10:22,050 --> 00:10:27,210
we're able to start new requests when

00:10:24,630 --> 00:10:29,730
blocking iOS going on only one thing is

00:10:27,210 --> 00:10:34,220
going on at a time so we don't have to

00:10:29,730 --> 00:10:37,530
worry about race conditions and deadlox

00:10:34,220 --> 00:10:41,310
we're just switching between these tasks

00:10:37,530 --> 00:10:43,770
when the cpu isn't doing anything so

00:10:41,310 --> 00:10:46,320
with node because the reactor can switch

00:10:43,770 --> 00:10:51,150
between requests internally each reactor

00:10:46,320 --> 00:10:53,190
can process more requests and the nice

00:10:51,150 --> 00:10:55,020
thing is if one of the node processes

00:10:53,190 --> 00:10:56,820
become saturated you can still get

00:10:55,020 --> 00:11:03,360
process concurrency by spooling up

00:10:56,820 --> 00:11:06,060
another node process but the important

00:11:03,360 --> 00:11:07,500
thing to keep in mind is there's a

00:11:06,060 --> 00:11:10,020
distinction between latency and

00:11:07,500 --> 00:11:10,579
concurrency so even though the node

00:11:10,020 --> 00:11:12,739
process

00:11:10,579 --> 00:11:15,439
can handle more requests in that one

00:11:12,739 --> 00:11:17,569
process for the same amount of memory if

00:11:15,439 --> 00:11:20,389
it was just one incoming request for

00:11:17,569 --> 00:11:22,699
Ruby and one incoming request for

00:11:20,389 --> 00:11:24,559
JavaScript it's going to take the same

00:11:22,699 --> 00:11:26,660
amount of time for it to finish

00:11:24,559 --> 00:11:30,259
processing so if you have a really slow

00:11:26,660 --> 00:11:32,029
request it's better to optimize the

00:11:30,259 --> 00:11:35,379
response latency because that's what

00:11:32,029 --> 00:11:35,379
your users are actually going to notice

00:11:37,059 --> 00:11:44,809
and the trade-off for on the node side

00:11:42,170 --> 00:11:47,360
of things is that suddenly when we look

00:11:44,809 --> 00:11:49,670
at this code the application code is

00:11:47,360 --> 00:11:52,129
aware of walking I oh so our domain

00:11:49,670 --> 00:11:55,129
model is tweets but somehow we're

00:11:52,129 --> 00:11:58,489
thinking about blocking io because we

00:11:55,129 --> 00:12:01,670
need to and coming from Ruby that's

00:11:58,489 --> 00:12:04,129
especially hard to swallow because we're

00:12:01,670 --> 00:12:07,040
so used to really maintainable really

00:12:04,129 --> 00:12:13,910
readable code but now we have to kind of

00:12:07,040 --> 00:12:15,410
deal with this callback spaghetti so now

00:12:13,910 --> 00:12:17,929
we know that node can give us better

00:12:15,410 --> 00:12:22,129
concurrency on the backend the rails but

00:12:17,929 --> 00:12:24,739
the caveat is that kind of ugly Colbeck

00:12:22,129 --> 00:12:26,959
soup we saw in the last slide so the

00:12:24,739 --> 00:12:29,360
question we want to ask is can we get

00:12:26,959 --> 00:12:32,089
some of the same benefits with Ruby but

00:12:29,360 --> 00:12:34,129
without the drawbacks so Ruby is

00:12:32,089 --> 00:12:36,529
definitely capable of evented

00:12:34,129 --> 00:12:40,220
programming and it's also a

00:12:36,529 --> 00:12:42,019
general-purpose language so typically

00:12:40,220 --> 00:12:43,879
when we're writing Ruby for the most

00:12:42,019 --> 00:12:47,389
part we're writing it procedurally so

00:12:43,879 --> 00:12:48,919
each line execute after the next and

00:12:47,389 --> 00:12:53,209
it's very intuitive for us to think

00:12:48,919 --> 00:12:56,329
about but it also allows us to do nodes

00:12:53,209 --> 00:12:59,329
of vintage style and if we wanted to if

00:12:56,329 --> 00:13:02,989
the problem fits then we can also do

00:12:59,329 --> 00:13:05,179
parallel computing with Reds and the

00:13:02,989 --> 00:13:08,989
nice thing but also the main drawback is

00:13:05,179 --> 00:13:13,309
you can mix and match these paradigms so

00:13:08,989 --> 00:13:17,439
we'll we'll see that in a few slides so

00:13:13,309 --> 00:13:20,059
in order to get us going with

00:13:17,439 --> 00:13:23,089
registering for events the first thing

00:13:20,059 --> 00:13:27,379
we need is a reactor so unlike node

00:13:23,089 --> 00:13:29,149
because we can do procedural and

00:13:27,379 --> 00:13:30,740
invented programming side by side you

00:13:29,149 --> 00:13:36,139
have to explicitly start your own

00:13:30,740 --> 00:13:38,209
reactor and in Rubio reactors it's just

00:13:36,139 --> 00:13:42,139
a gem and there's multiple choices out

00:13:38,209 --> 00:13:44,689
there but a vet machine is the most

00:13:42,139 --> 00:13:46,939
widely used and the way you start a

00:13:44,689 --> 00:13:48,889
reactor is you call a.m. run and you

00:13:46,939 --> 00:13:51,470
pass it a block everything inside that

00:13:48,889 --> 00:13:56,059
block is going to be running inside the

00:13:51,470 --> 00:13:58,069
reactor you can manually start the

00:13:56,059 --> 00:14:02,680
reactor but if you use one of these app

00:13:58,069 --> 00:14:05,540
servers that are reactor aware then you

00:14:02,680 --> 00:14:07,639
already have a reactor running for all

00:14:05,540 --> 00:14:09,589
of your application code so if you use

00:14:07,639 --> 00:14:11,480
thin than everything in your rails

00:14:09,589 --> 00:14:17,029
process is already running within a

00:14:11,480 --> 00:14:20,959
reactor so once we have the reactor

00:14:17,029 --> 00:14:22,790
running we need to subscribe for events

00:14:20,959 --> 00:14:26,180
that we care about so in order for our

00:14:22,790 --> 00:14:29,360
reactor to have something to do I put up

00:14:26,180 --> 00:14:34,189
this example which is fetching a web

00:14:29,360 --> 00:14:36,019
page and what's what's happening here is

00:14:34,189 --> 00:14:37,850
first you build a request object and

00:14:36,019 --> 00:14:44,480
then you register a callback for when

00:14:37,850 --> 00:14:48,399
that request is finished unfortunately

00:14:44,480 --> 00:14:51,370
this this ruby version looks a lot like

00:14:48,399 --> 00:14:53,899
the node code I put up earlier because

00:14:51,370 --> 00:14:57,259
here even though we're just trying to

00:14:53,899 --> 00:15:01,579
fetch a web page we're still handling

00:14:57,259 --> 00:15:04,519
blocking i/o by ourselves and the

00:15:01,579 --> 00:15:06,139
problem I see with a vented code is it

00:15:04,519 --> 00:15:07,550
doesn't really matter what language or

00:15:06,139 --> 00:15:09,439
framework you're using you're always

00:15:07,550 --> 00:15:13,999
going to have to kind of deal with this

00:15:09,439 --> 00:15:15,439
callback inverted control pattern and I

00:15:13,999 --> 00:15:18,050
think this is actually worse than the

00:15:15,439 --> 00:15:21,520
node version because now you're writing

00:15:18,050 --> 00:15:25,420
Ruby but it doesn't look like Ruby any

00:15:21,520 --> 00:15:30,700
it's valid syntax but where it's not

00:15:25,420 --> 00:15:33,250
natural feeling so what we really want

00:15:30,700 --> 00:15:37,390
to have is we want to get back to a

00:15:33,250 --> 00:15:40,210
procedural style syntax but have the

00:15:37,390 --> 00:15:42,940
executing code run in an event in

00:15:40,210 --> 00:15:45,070
fashion under the hood so ideally this

00:15:42,940 --> 00:15:46,960
is what we'd want the code to look like

00:15:45,070 --> 00:15:50,020
and even if you didn't know what Faraday

00:15:46,960 --> 00:15:52,390
does as a library you can kind of guess

00:15:50,020 --> 00:15:54,760
what this does right we're fetching a

00:15:52,390 --> 00:15:58,180
page and the result is going to be saved

00:15:54,760 --> 00:16:02,020
in the response the nice thing is Ruby

00:15:58,180 --> 00:16:06,580
lets us hide blocking i/o and related

00:16:02,020 --> 00:16:09,160
call backs into library code so Faraday

00:16:06,580 --> 00:16:11,770
gives you the option to kind of switch

00:16:09,160 --> 00:16:13,930
out adapters for how you actually do the

00:16:11,770 --> 00:16:17,080
page fetches and if you just switch it

00:16:13,930 --> 00:16:21,010
to the event machine synchrony adapter

00:16:17,080 --> 00:16:23,020
then suddenly it hides all the system

00:16:21,010 --> 00:16:25,270
event callbacks until the library so

00:16:23,020 --> 00:16:26,980
even though when you do the page fetch

00:16:25,270 --> 00:16:29,620
it's going to run in that event at

00:16:26,980 --> 00:16:32,070
fashion when you're coding at the

00:16:29,620 --> 00:16:36,300
application layer it's going to be this

00:16:32,070 --> 00:16:39,870
intuitive style that you're used to and

00:16:36,300 --> 00:16:43,210
the way this is actually done is we use

00:16:39,870 --> 00:16:45,340
Ruby fibers and fibers are primitives

00:16:43,210 --> 00:16:48,190
for implementing lightweight cooperative

00:16:45,340 --> 00:16:50,710
concurrency so basically that means you

00:16:48,190 --> 00:16:52,750
can create code blocks get that can be

00:16:50,710 --> 00:16:54,430
paused and resumed at like threads but

00:16:52,750 --> 00:16:56,500
the main difference is they are

00:16:54,430 --> 00:17:02,620
preempted and the scheduling has to be

00:16:56,500 --> 00:17:04,810
done by the programmer so if I burr is

00:17:02,620 --> 00:17:07,510
acro routine which means they we have to

00:17:04,810 --> 00:17:09,339
manually control which fiber is running

00:17:07,510 --> 00:17:12,040
only one fiber is running at a time but

00:17:09,339 --> 00:17:15,810
we basically have to pause when we

00:17:12,040 --> 00:17:15,810
expect walking iona happen

00:17:18,089 --> 00:17:23,459
so we start the first request when we

00:17:21,689 --> 00:17:27,059
know there's going to be blocking IL we

00:17:23,459 --> 00:17:31,590
pause the request and yield the control

00:17:27,059 --> 00:17:33,690
back to the reactor and when when data

00:17:31,590 --> 00:17:37,950
is ready to actually finish the request

00:17:33,690 --> 00:17:40,740
then we resumed the request fiber so

00:17:37,950 --> 00:17:42,510
this still kind of sucks because you

00:17:40,740 --> 00:17:44,390
know it's the same thing we've been

00:17:42,510 --> 00:17:47,360
talking about this whole time we're

00:17:44,390 --> 00:17:51,600
human beings are just not good at

00:17:47,360 --> 00:17:53,549
scheduling as an opera system or a

00:17:51,600 --> 00:17:55,710
computer is so at some point we're going

00:17:53,549 --> 00:18:03,840
to screw up and we're going to forget to

00:17:55,710 --> 00:18:06,270
yield control back so we have a reactor

00:18:03,840 --> 00:18:08,220
in one fiber but we still need to have

00:18:06,270 --> 00:18:09,720
requests in their own fiber so we can

00:18:08,220 --> 00:18:12,299
kind of do the switching back and forth

00:18:09,720 --> 00:18:14,220
and the nice thing is that web requests

00:18:12,299 --> 00:18:24,929
are naturally independent of one another

00:18:14,220 --> 00:18:27,380
right so lost my place here so to wrap

00:18:24,929 --> 00:18:29,970
each request in its own fiber there's a

00:18:27,380 --> 00:18:32,130
rack middleware out there called rack

00:18:29,970 --> 00:18:34,890
fiber pool and because rails is rack

00:18:32,130 --> 00:18:38,130
it's really easy to configure your stack

00:18:34,890 --> 00:18:40,500
to do this you just basically add it to

00:18:38,130 --> 00:18:42,480
the top of the middleware stack and if

00:18:40,500 --> 00:18:45,270
you're using any other web frameworks

00:18:42,480 --> 00:18:49,020
like Sinatra grape you can also use the

00:18:45,270 --> 00:18:51,149
same gym so so far what we've done is

00:18:49,020 --> 00:18:54,240
we've chosen a reactor for our app

00:18:51,149 --> 00:18:56,610
server we've wrapped each request in its

00:18:54,240 --> 00:18:59,100
own fiber and we haven't changed any of

00:18:56,610 --> 00:19:00,899
our application code if you benchmark

00:18:59,100 --> 00:19:02,130
your app at this point you're going to

00:19:00,899 --> 00:19:03,750
be really disappointed because

00:19:02,130 --> 00:19:07,610
everything's still going to suck and be

00:19:03,750 --> 00:19:10,980
slow and the reason for that is because

00:19:07,610 --> 00:19:13,320
the Ruby ecosystem wasn't written with

00:19:10,980 --> 00:19:14,880
invented in mind all of your application

00:19:13,320 --> 00:19:19,020
code is going to be blocking all the

00:19:14,880 --> 00:19:22,380
time so the reactor is going to come in

00:19:19,020 --> 00:19:24,210
start the first request but as soon as

00:19:22,380 --> 00:19:25,649
there's a blocking library it's not

00:19:24,210 --> 00:19:27,539
going to yield so the reactor can't

00:19:25,649 --> 00:19:29,370
actually do anything when the second

00:19:27,539 --> 00:19:30,429
request comes in because it's already

00:19:29,370 --> 00:19:34,200
blocked

00:19:30,429 --> 00:19:37,029
so basically what we're looking at is

00:19:34,200 --> 00:19:38,860
the same process concurrency as before

00:19:37,029 --> 00:19:40,990
but really that's that's okay because

00:19:38,860 --> 00:19:43,269
we're not we're not doing any worse than

00:19:40,990 --> 00:19:44,950
when we started right so we're still

00:19:43,269 --> 00:19:46,869
using process concurrency each of these

00:19:44,950 --> 00:19:50,499
roles processes is still handling one

00:19:46,869 --> 00:19:52,570
request per process and we can only do

00:19:50,499 --> 00:19:54,909
better from there so some of the

00:19:52,570 --> 00:19:57,879
starting points of where to start

00:19:54,909 --> 00:20:01,690
unblocking you a reactor is to take a

00:19:57,879 --> 00:20:06,669
look at your data stores external HTTP

00:20:01,690 --> 00:20:09,309
calls and system calls for data stores a

00:20:06,669 --> 00:20:12,700
lot of the drivers for these data stores

00:20:09,309 --> 00:20:16,029
will either support event machine out of

00:20:12,700 --> 00:20:18,340
the box and you just have to configure

00:20:16,029 --> 00:20:23,200
it or there'll be special adapters

00:20:18,340 --> 00:20:25,679
available for them for HTTP you can use

00:20:23,200 --> 00:20:28,720
Faraday there's a built-in adapter and

00:20:25,679 --> 00:20:31,990
for system calls event machine comes

00:20:28,720 --> 00:20:34,389
bundled with its own version of kernel

00:20:31,990 --> 00:20:37,720
that p open that's non blocking and if

00:20:34,389 --> 00:20:39,999
you really can't rewrite a chunk of code

00:20:37,720 --> 00:20:42,460
to be a vented then what you can do is

00:20:39,999 --> 00:20:45,549
call am defer and what this will do is

00:20:42,460 --> 00:20:47,889
kick off another thread run the block in

00:20:45,549 --> 00:20:49,779
a separate thread and when that returns

00:20:47,889 --> 00:20:54,490
feed the results back into your main

00:20:49,779 --> 00:20:56,529
reactor loop so after we've tweaked our

00:20:54,490 --> 00:20:58,869
libraries to be reactor where we're

00:20:56,529 --> 00:21:00,279
getting an execution pattern that's much

00:20:58,869 --> 00:21:08,259
more similar to what we're seeing in

00:21:00,279 --> 00:21:14,169
noon so why and when should you use Ruby

00:21:08,259 --> 00:21:15,999
if if you do spend some time trying to

00:21:14,169 --> 00:21:18,580
add a vented io2 you're real zap you'll

00:21:15,999 --> 00:21:22,509
see some clear benefits right you can

00:21:18,580 --> 00:21:24,549
reuse your existing code the performance

00:21:22,509 --> 00:21:26,820
won't be worse than when you started you

00:21:24,549 --> 00:21:29,820
can keep that same pretty Ruby

00:21:26,820 --> 00:21:32,710
readability that we all appreciate and

00:21:29,820 --> 00:21:34,990
it's also multi-paradigm so you can kind

00:21:32,710 --> 00:21:36,879
of pick and choose what things you want

00:21:34,990 --> 00:21:42,580
to optimize with what style of

00:21:36,879 --> 00:21:44,769
programming why should you use node the

00:21:42,580 --> 00:21:48,129
nice thing with known I think the single

00:21:44,769 --> 00:21:50,049
biggest win is because everything is in

00:21:48,129 --> 00:21:52,149
this event at paradigm everything is

00:21:50,049 --> 00:21:54,730
very consistent so every library you go

00:21:52,149 --> 00:21:57,879
out and find is just going to work right

00:21:54,730 --> 00:21:59,259
it's going to be aware that it has to

00:21:57,879 --> 00:22:00,490
register callbacks whenever there's

00:21:59,259 --> 00:22:03,100
blocking io because there's no

00:22:00,490 --> 00:22:05,230
alternative and the community is much

00:22:03,100 --> 00:22:07,149
better than the Rubio vented community

00:22:05,230 --> 00:22:09,460
at this point so if you have a question

00:22:07,149 --> 00:22:14,740
or get stuck you're much more likely to

00:22:09,460 --> 00:22:19,090
get help so while it's straightforward

00:22:14,740 --> 00:22:21,309
to write a utility script doing a vented

00:22:19,090 --> 00:22:23,350
i/o in either Ruby or JavaScript it's

00:22:21,309 --> 00:22:26,559
much harder so you kind of go and

00:22:23,350 --> 00:22:28,929
rewrite your app in another form

00:22:26,559 --> 00:22:31,419
American language so please don't do

00:22:28,929 --> 00:22:33,480
that whether you're already on Rails and

00:22:31,419 --> 00:22:36,460
you want to switch to something else or

00:22:33,480 --> 00:22:41,289
on JavaScript and switching rails it's

00:22:36,460 --> 00:22:42,940
just a bad idea just don't do it but for

00:22:41,289 --> 00:22:46,210
certain things you can still write

00:22:42,940 --> 00:22:48,669
specific features that fits this

00:22:46,210 --> 00:22:51,879
invented paradigm so you can write one

00:22:48,669 --> 00:22:54,279
feature and have it either run alongside

00:22:51,879 --> 00:23:00,340
your real system and just route requests

00:22:54,279 --> 00:23:05,259
between them or yeah so I'll give an

00:23:00,340 --> 00:23:07,509
example of that guy so on github all of

00:23:05,259 --> 00:23:10,149
our dot-com pages are going to be

00:23:07,509 --> 00:23:13,029
rendered through rails so we're not

00:23:10,149 --> 00:23:15,940
we're not enjoying the benefits of a

00:23:13,029 --> 00:23:18,009
vented programming but at the same time

00:23:15,940 --> 00:23:19,960
that as long as the site feels fast

00:23:18,009 --> 00:23:23,970
that's all you should really care about

00:23:19,960 --> 00:23:27,429
and whenever you see this zip button

00:23:23,970 --> 00:23:30,070
when you download a zip archive of a git

00:23:27,429 --> 00:23:33,940
repository that's actually a known

00:23:30,070 --> 00:23:36,460
process that handles that so the node

00:23:33,940 --> 00:23:39,580
process is living alongside of the rails

00:23:36,460 --> 00:23:41,919
process and whenever it sees this

00:23:39,580 --> 00:23:44,440
request we're out the user to have the

00:23:41,919 --> 00:23:49,080
node process generate the zip archive on

00:23:44,440 --> 00:23:49,080
life and send it out

00:23:49,950 --> 00:23:56,020
so wrapping up a bit vented programming

00:23:54,220 --> 00:23:57,850
is going to be tricky in any language

00:23:56,020 --> 00:24:00,160
you choose it really is in a matter of

00:23:57,850 --> 00:24:03,820
choosing between reviewed or JavaScript

00:24:00,160 --> 00:24:06,160
you should try to aim a vented

00:24:03,820 --> 00:24:11,020
programming for the types of problems

00:24:06,160 --> 00:24:15,190
where it makes sense it also doesn't

00:24:11,020 --> 00:24:17,740
make your requests magically faster so I

00:24:15,190 --> 00:24:19,480
think it's more important to make sure

00:24:17,740 --> 00:24:21,700
that your response times are reasonable

00:24:19,480 --> 00:24:29,820
before you even try to dabble in this

00:24:21,700 --> 00:24:33,190
and finally I think for the trade-off in

00:24:29,820 --> 00:24:35,740
maintenance and readability I think even

00:24:33,190 --> 00:24:39,760
if you use a vented programming you

00:24:35,740 --> 00:24:41,590
should hide the i/o logic with libraries

00:24:39,760 --> 00:24:44,380
that actually deal with IO you should

00:24:41,590 --> 00:24:47,560
never pollute your domain and business

00:24:44,380 --> 00:24:51,070
logic with these callbacks about what

00:24:47,560 --> 00:24:53,050
your database is doing so if you take

00:24:51,070 --> 00:24:54,910
some time and start tinkering with some

00:24:53,050 --> 00:24:56,860
of these concepts in a separate branch

00:24:54,910 --> 00:24:59,860
then you can kind of benchmark and

00:24:56,860 --> 00:25:02,470
benchmark your app and kind of see which

00:24:59,860 --> 00:25:05,880
changes are worthwhile and which changes

00:25:02,470 --> 00:25:09,840
are just more hassle than they're worth

00:25:05,880 --> 00:25:09,840
cool thanks

00:25:17,630 --> 00:25:28,230
questions one of the things you said was

00:25:23,220 --> 00:25:30,450
to hide the vented pneus of the

00:25:28,230 --> 00:25:33,120
programming in libraries and you

00:25:30,450 --> 00:25:35,820
mentioned Faraday example doesn't that

00:25:33,120 --> 00:25:40,170
mean though that you can only juggle

00:25:35,820 --> 00:25:41,550
like events like blocking IO against one

00:25:40,170 --> 00:25:43,440
another that is if you have a whole

00:25:41,550 --> 00:25:45,840
bunch of HTTP in the tweet example you

00:25:43,440 --> 00:25:47,580
can have seven tweet Network requests

00:25:45,840 --> 00:25:49,050
that you can't juggle those against the

00:25:47,580 --> 00:25:50,490
disk requests right because those aren't

00:25:49,050 --> 00:25:55,620
going to be the same underlying

00:25:50,490 --> 00:26:00,600
mechanism so the question is if if you

00:25:55,620 --> 00:26:03,560
juggle HTTP events suddenly you're tied

00:26:00,600 --> 00:26:07,680
to just dealing with HTTP events right

00:26:03,560 --> 00:26:09,630
really the the main thing you need to

00:26:07,680 --> 00:26:12,000
optimize and look out for is to make

00:26:09,630 --> 00:26:13,860
sure you don't block the reactor so as

00:26:12,000 --> 00:26:16,850
long as the reactor is not blocked it

00:26:13,860 --> 00:26:21,270
can dispatch on arbitrary events so if

00:26:16,850 --> 00:26:24,060
your database adapter is event is

00:26:21,270 --> 00:26:28,350
reactor aware and your HTTP library is

00:26:24,060 --> 00:26:30,690
reactor aware whenever you know if your

00:26:28,350 --> 00:26:33,180
HTTP call is busy but there's an

00:26:30,690 --> 00:26:37,520
incoming DB request that can be executed

00:26:33,180 --> 00:26:37,520
while the first fiber is busy

00:26:45,670 --> 00:26:48,480
entire application

00:26:49,660 --> 00:26:54,000
are there any project review

00:26:55,320 --> 00:26:58,250
the big match

00:26:59,540 --> 00:27:05,420
so I don't I don't quite follow the

00:27:02,670 --> 00:27:10,710
question does using then give you

00:27:05,420 --> 00:27:13,440
advantages so the thing with using any

00:27:10,710 --> 00:27:15,720
of these technologies is even if you

00:27:13,440 --> 00:27:18,180
have the reactor and you start it up

00:27:15,720 --> 00:27:20,630
it's going to handle one request at a

00:27:18,180 --> 00:27:26,520
time because all of your code is a

00:27:20,630 --> 00:27:29,850
reactor aware so you never yield control

00:27:26,520 --> 00:27:32,910
back up too thin back to the reactor for

00:27:29,850 --> 00:27:35,730
it to do something else so the nice

00:27:32,910 --> 00:27:37,440
thing is you you basically get to pick

00:27:35,730 --> 00:27:39,510
and choose where you want to optimize

00:27:37,440 --> 00:27:41,400
things so if you notice there's a big

00:27:39,510 --> 00:27:45,440
chunk blocking here then you can

00:27:41,400 --> 00:27:45,440
optimize just that one chunk of code

00:27:50,690 --> 00:27:54,140
alright thanks guys

00:28:07,220 --> 00:28:09,280

YouTube URL: https://www.youtube.com/watch?v=hNfURUailz0


