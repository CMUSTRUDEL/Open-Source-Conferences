Title: Garden City Ruby 2014 - Lessons Learnt Building India's E-Commerce Supply Chain in Ruby
Publication date: 2020-01-24
Playlist: Garden City Ruby 2014
Description: 
	By Yogi Kulkarni

In 2012 Flipkart's supply chain system was re-built as a service oriented architecture with Ruby at its core.

This talk will cover our experiences designing, building and scaling a mission-critical Ruby-based system where data integrity and performance is vital.

Dealing with cross-service transaction integrity
JRuby - the good, bad & ugly
Coordinating gem upgrades across multiple services
Performance tuning to get predictable response times - taming queries, external calls, GC, locks
Monitoring & profiling production systems
Ruby app servers: Trinidad vs Passenger vs Unicorn
Challenges in ramping up teams on Ruby
etc
Captions: 
	00:00:29,140 --> 00:00:29,145
This talk is about a specific project that we did at Flipkart

00:00:29,145 --> 00:00:33,705
so just to give people, foreigners here, a bit of context of Flipkart 

00:00:33,760 --> 00:00:35,760
it's sort of like the Amazon of India

00:00:35,760 --> 00:00:41,140
and they are, right now, the largest e-commerce store in India

00:00:41,140 --> 00:00:46,820
we, so yeah, let me keep the numbers for later

00:00:46,820 --> 00:00:52,500
so, in 2011 around about in December

00:00:52,500 --> 00:00:57,000
there was the, we had a kind of a moment where

00:00:57,000 --> 00:00:59,820
we realized that our supply chain was not going to be able to scale

00:00:59,820 --> 00:01:01,940
we were having very, very serious problems

00:01:01,940 --> 00:01:04,780
with actually having things, with things,

00:01:04,780 --> 00:01:05,960
actually building new features

00:01:05,960 --> 00:01:07,160
it was going very slow

00:01:07,160 --> 00:01:11,540
the number of requests hitting our website

00:01:11,540 --> 00:01:14,200
were just going through the roof and

00:01:14,200 --> 00:01:15,320
and we were not able to keep up

00:01:15,320 --> 00:01:17,400
so at that point there was a

00:01:17,400 --> 00:01:19,660
so let me just actually talk about what the system looked like

00:01:19,660 --> 00:01:24,760
so, this was Version 2 of the supply chain at Flipkart

00:01:24,760 --> 00:01:28,640
Version 1 which was kind of written in 2007

00:01:28,640 --> 00:01:32,120
was written by our founder, Sachin and Binny themselves in PHP

00:01:32,120 --> 00:01:36,980
so this was Version 2, which was written in about 2010

00:01:36,980 --> 00:01:40,720
it was Open Source ERP system called Opentaps

00:01:40,720 --> 00:01:43,480
which we had extended extensively

00:01:43,480 --> 00:01:46,920
it was basically a single monolithic application

00:01:46,920 --> 00:01:52,320
it had all these modules for the management, warehousing, so on and so forth

00:01:52,320 --> 00:01:55,180
and they all came out of a single JVM

00:01:55,180 --> 00:01:56,440
connected to a single database

00:01:56,440 --> 00:01:59,720
and that was just horrible

00:01:59,720 --> 00:02:00,340
right

00:02:00,340 --> 00:02:01,340
the problem was that

00:02:01,340 --> 00:02:03,540
each module as we were extending it

00:02:03,540 --> 00:02:05,680
the developers didn't actually bother

00:02:05,680 --> 00:02:07,220
to kind of think about

00:02:07,220 --> 00:02:09,000
should we be accessing this data

00:02:09,000 --> 00:02:10,860
this table, should we be querying it or not

00:02:10,860 --> 00:02:13,740
they would just go and make joins across tables

00:02:13,740 --> 00:02:15,600
just to solve the problem, get the feature out, right

00:02:15,600 --> 00:02:16,660
you're probably familiar with that

00:02:16,660 --> 00:02:19,580
so horrible coupling

00:02:19,580 --> 00:02:22,400
and we spent about a month trying to see if we can

00:02:22,400 --> 00:02:24,660
call up (??) each piece from the system

00:02:24,660 --> 00:02:26,180
and kind of start breaking out services

00:02:26,180 --> 00:02:27,920
and we couldn't do it, it was just impossible

00:02:27,920 --> 00:02:31,620
so, at that point we took a hard, hard decision that

00:02:31,620 --> 00:02:32,860
you know, let's actually rewrite

00:02:32,860 --> 00:02:35,680
and this was something which was completely against

00:02:35,680 --> 00:02:39,180
my past work's philosophy of, you know, let's re-factor incrementally

00:02:39,180 --> 00:02:41,960
and go slowly and let's have the system running and then

00:02:41,960 --> 00:02:44,600
kind of migrate, but we took the score

00:02:44,600 --> 00:02:49,020
and in two-thousand-and, I think it was 2011, in December

00:02:49,020 --> 00:02:54,200
we started the project where, so this was sort of a 

00:02:54,200 --> 00:02:55,620
bet the company project for Flipkart

00:02:55,620 --> 00:02:58,320
it was so critical at that point that

00:02:58,320 --> 00:03:02,380
Sachin, he was the founder, actually came and sat with the team

00:03:02,380 --> 00:03:05,880
so we basically called up a team of initially ten people and then

00:03:05,880 --> 00:03:07,640
that increased to about thirty developers

00:03:07,640 --> 00:03:09,920
and he moved us, moved that team out

00:03:09,920 --> 00:03:13,440
to a separate office which was basically a house

00:03:13,440 --> 00:03:15,900
in Banglore, which was the place where Flipkart was born

00:03:15,900 --> 00:03:19,760
and that was, got turned into a skunk (??) works start-up project within Flipkart

00:03:19,760 --> 00:03:22,800
where this team worked, and complete isolation

00:03:22,800 --> 00:03:24,440
no interviews, no meetings, nothing

00:03:24,440 --> 00:03:27,700
this team was only here to build out this system in seven months

00:03:27,700 --> 00:03:29,920
because the next milestone was the Diwali

00:03:29,920 --> 00:03:35,040
so the Diwali is the time when we do the most sales in the year

00:03:35,040 --> 00:03:37,780
and that was in October of 2012

00:03:37,780 --> 00:03:40,260
so we had about seven months to replace

00:03:40,260 --> 00:03:41,820
an entire supply chain system

00:03:41,820 --> 00:03:45,840
with a new system built from grounds up

00:03:45,840 --> 00:03:47,960
get it in production, make sure it's working

00:03:47,960 --> 00:03:51,220
and it's scaling right. So get to, probably do it by August

00:03:51,220 --> 00:03:53,460
and give ourselves time till August to kind of do that

00:03:53,460 --> 00:03:59,340
so yeah, we start up on this project and

00:03:59,340 --> 00:04:04,260
the idea was to break up each of these modules into

00:04:04,260 --> 00:04:06,480
services and I think Chad's talk

00:04:06,480 --> 00:04:11,080
really set up the context beautifully for this talk

00:04:11,080 --> 00:04:15,920
because a lot of the ideas and though processes that he mentioned is stuff that 

00:04:15,920 --> 00:04:20,820
we tried to kind of work on and kind of implement in the system

00:04:20,820 --> 00:04:25,560
so, some of the things he wanted to do was

00:04:25,560 --> 00:04:28,840
I think it was nice because

00:04:28,840 --> 00:04:32,940
it's all small pieces loosely joined which I came across around that time

00:04:32,940 --> 00:04:36,660
I think that beautifully summarizes what we want to get to, right

00:04:36,660 --> 00:04:39,980
each service doing one small thing. So you break down

00:04:39,980 --> 00:04:41,960
the warehouse module into a separate service

00:04:41,960 --> 00:04:43,080
order management into a separate service

00:04:43,080 --> 00:04:44,960
accounting and so on and so forth

00:04:44,960 --> 00:04:48,320
we didn't want to go down micro-services architecture way

00:04:48,320 --> 00:04:51,000
I'd worked with Fred George earlier and

00:04:51,000 --> 00:04:54,880
I'd gone down, I'd seen some of the down sides

00:04:54,880 --> 00:04:57,360
of it and I didn't actually have a clear idea of

00:04:57,360 --> 00:05:00,520
how to work around those downsides at that point in time

00:05:00,520 --> 00:05:03,400
so I was kind of wary about micro-services at that point

00:05:03,400 --> 00:05:05,460
and I would love to actually hear other peoples' thoughts

00:05:05,460 --> 00:05:06,460
on how that's working out

00:05:06,460 --> 00:05:10,060
but anyway, so we all took on our separate services

00:05:10,060 --> 00:05:12,380
each doing one thing and doing one thing well

00:05:12,380 --> 00:05:16,280
and each service would have its own database

00:05:16,280 --> 00:05:18,860
and nobody could access it except the service, right

00:05:18,860 --> 00:05:21,860
you could just access it through an HTTP JSON API

00:05:21,860 --> 00:05:24,900
and you will never touch my data, right

00:05:24,900 --> 00:05:26,140
my private parts are private

00:05:26,140 --> 00:05:29,140
so this is what we ended up with

00:05:29,140 --> 00:05:34,160
probably not going to read the thing so I'm gonna read it out to you

00:05:34,160 --> 00:05:36,460
so we end up with about twenty-five services

00:05:36,460 --> 00:05:38,420
this is a sub-set of the services we actually built

00:05:38,420 --> 00:05:42,060
you have all the management service

00:05:42,060 --> 00:05:43,880
then the fulfillment orchestration service

00:05:43,880 --> 00:05:45,680
which talks to warehousing service

00:05:45,680 --> 00:05:48,640
and fulfillment, which in turn talks to supplier

00:05:48,640 --> 00:05:51,720
and the whole logistics subsystems 

00:05:51,720 --> 00:05:56,240
and you have accounting services, document services, and then you have a bunch of

00:05:56,240 --> 00:05:59,600
infrastructure services including this piece at the bottom

00:05:59,600 --> 00:06:02,220
which was a messaging system that we ended up building

00:06:02,220 --> 00:06:05,820
called Resbus, which I talk a little bit about

00:06:05,820 --> 00:06:10,180
which kind of addressed the problem of cross-service transaction integrity

00:06:10,180 --> 00:06:15,040
so in this picture the Ruby services were basic- so

00:06:15,040 --> 00:06:17,260
each service, for example, the order management service

00:06:17,260 --> 00:06:21,720
the blue pieces were written in Padrino or Sinatra

00:06:21,720 --> 00:06:34,740
 

00:06:34,900 --> 00:06:37,100
so these are written in Padrino and

00:06:37,100 --> 00:06:38,900
they added in JRuby when we went live

00:06:38,900 --> 00:06:41,400
we eventually migrated those to MRI

00:06:41,400 --> 00:06:43,040
but, and I'm going to be clear about why

00:06:43,040 --> 00:06:46,360
so these were the Padrino services

00:06:46,360 --> 00:06:51,380
and then the UI pieces where required were written in Ruby on Rails

00:06:51,380 --> 00:06:52,060
running on MRI

00:06:52,060 --> 00:06:55,360
we also had some infrastructure services running on Ruby

00:06:55,360 --> 00:06:57,160
for example the single sign-on service was

00:06:57,160 --> 00:06:59,460
used CAS and used RubyCAS

00:06:59,460 --> 00:07:04,280
we built our role-based access system again in Ruby

00:07:04,280 --> 00:07:07,680
and a bunch of other pieces, right

00:07:07,680 --> 00:07:11,820
so essentially we went from monolithic single system

00:07:11,820 --> 00:07:16,240
to twenty-five services, right, and this was a massive change

00:07:16,240 --> 00:07:20,120
and this, so each, there were total about seven teams

00:07:20,120 --> 00:07:24,000
which worked on this project, owning one or two services

00:07:24,000 --> 00:07:28,700
each team had between four and six developers

00:07:28,700 --> 00:07:36,460
yeah, so that's to just set the context, about where we were

00:07:36,460 --> 00:07:46,380
so, when we started the project in two thousand and, early 2011, we were doing about

00:07:46,380 --> 00:07:52,180
the system was doing, the old system was doing about 20,000 orders a day. 30,000 shipments a day.

00:07:52,180 --> 00:07:56,520
roughly around that order, and this new system has now survived 

00:07:56,520 --> 00:08:02,500
two Diwali workloads, which includes the latest Diwali which was in 2013

00:08:02,500 --> 00:08:06,620
we did, I think 100,000 orders and 150,000 shipments

00:08:06,620 --> 00:08:09,100
and it's working pretty well

00:08:09,100 --> 00:08:14,500
so, at the time when we were making this decision

00:08:14,500 --> 00:08:16,420
we were kind of selecting the technology stack

00:08:16,420 --> 00:08:19,220
and we, the big question was, you know, what tech stack to use

00:08:19,220 --> 00:08:22,400
so Flipkart traditionally had a lot

00:08:22,400 --> 00:08:26,820
so we, Opentabs given the Java stack

00:08:26,820 --> 00:08:30,400
so most developers were very, very comfortable with Java

00:08:30,400 --> 00:08:33,040
so the thought of actually introducing a new language

00:08:33,040 --> 00:08:35,860
a new ecosystem, was, people were kind of wary about that

00:08:35,860 --> 00:08:37,880
also there were concerns about performance

00:08:37,880 --> 00:08:41,860
but, I knew from my experience in the past that

00:08:41,860 --> 00:08:47,780
performance is not a language issue

00:08:47,780 --> 00:08:52,060
it's an architecture design issue fundamentally, right

00:08:52,060 --> 00:08:53,920
and there are differences in technologies and languages

00:08:53,920 --> 00:08:55,520
and I talk a little bit more about that in detail

00:08:55,520 --> 00:08:59,220
but performance I'm not too worried about

00:08:59,220 --> 00:09:01,460
so why Ruby then?

00:09:01,460 --> 00:09:09,960
so there's a, the obvious reason is speed of development, right

00:09:09,960 --> 00:09:13,940
we had a short, a very, very tight deadline to detail the entire system

00:09:13,940 --> 00:09:17,320
system in seven months we wanted to move fast, right 

00:09:17,320 --> 00:09:21,100
so that's obviously one benefit. The other reason was

00:09:21,100 --> 00:09:26,100
I think this idea of small pieces loosely joined is really powerful

00:09:26,100 --> 00:09:29,880
small code bases are inherently easier to debug, right

00:09:29,880 --> 00:09:32,740
like even if you have the best tools and you have a large Java system

00:09:32,740 --> 00:09:35,500
it's hard to work, even with great profilers,

00:09:35,600 --> 00:09:39,520
great modeling tools, it's still hard when you are dealing

00:09:39,520 --> 00:09:41,440
with 100,000 line code base

00:09:41,440 --> 00:09:44,660
you, it's just far more complex than dealing with

00:09:44,660 --> 00:09:47,120
something that is maybe 10,000 lines

00:09:47,120 --> 00:09:48,360
or maybe 5,000 lines of code right

00:09:48,360 --> 00:09:50,100
and that code compression that Ruby allows

00:09:50,100 --> 00:09:56,560
is actually really powerful. Also I think in the Ruby world

00:09:56,560 --> 00:10:00,040
Ruby's secret weapon is not Rails

00:10:00,040 --> 00:10:03,040
I think to me, Ruby's secret weapon is ActiveRecord

00:10:03,040 --> 00:10:05,420
especially for business applications

00:10:05,420 --> 00:10:09,600
there's, I just love it as a new item tool

00:10:09,600 --> 00:10:13,680
and it has its problems, especially in the enterprise space when

00:10:13,680 --> 00:10:18,740
you are dealing with fairly complex logic. We, we'll have cases where

00:10:18,740 --> 00:10:21,480
so because it lacks what's called an identity map

00:10:21,480 --> 00:10:24,100
you can have situations where if you're not traversing from

00:10:24,100 --> 00:10:26,620
parent to object, to a child object, and back

00:10:26,620 --> 00:10:28,960
to the parent object, you end up with two references to the

00:10:28,960 --> 00:10:32,600
two instances of the parent object, right, and that's kind of bad

00:10:32,600 --> 00:10:36,420
tools like Hibernate in the Java world actually solve this beautifully

00:10:36,420 --> 00:10:41,980
so yeah, so it has its glitches. But still, as a tool to write business applications

00:10:41,980 --> 00:10:43,920
I think there's, it's fairly amazing.

00:10:43,920 --> 00:10:47,580
So we want to use the power of ActiveRecord, we want to have small systems,

00:10:47,580 --> 00:10:51,740
which is why we built our services, back-end services which were the HTTP JSON ones

00:10:51,740 --> 00:10:53,840
only in Sinatra

00:10:53,840 --> 00:10:56,080
so Padrino was just a pin wrapped around it

00:10:56,080 --> 00:11:00,420
so it's Sinatra talking to its own database

00:11:05,200 --> 00:11:11,000
OK, so I'm gonna kind of try and focus a lot more on the lessons learned

00:11:11,000 --> 00:11:13,580
so I'm kind of going to be jumping topics a bit 

00:11:13,580 --> 00:11:16,080
and it might be a bit of discontinuity so, please excuse that

00:11:16,080 --> 00:11:20,360
but I want to kind of get the real key insights that we had on the project out

00:11:20,360 --> 00:11:23,480
than worry about a kind of a consistent flow

00:11:23,480 --> 00:11:29,700
So JRuby, right. Let me start it off good.

00:11:29,700 --> 00:11:35,860
so JRuby is incredible. It's an amazing piece of technology, great community

00:11:35,860 --> 00:11:40,940
you get the power of the JVM which is just amazing

00:11:40,940 --> 00:11:43,120
and specifically within the JVM what you want is

00:11:43,120 --> 00:11:46,260
its garbage collector and the just-in-time compilation

00:11:46,260 --> 00:11:48,900
very cohesive. Those two are just amazing

00:11:48,900 --> 00:11:53,180
I'll share some numbers about how those two things actually make a difference

00:11:53,180 --> 00:11:56,280
but that's a good part of JRuby, right

00:11:56,280 --> 00:12:01,440
amazing ecosystem - you get all the tools that are in the Java work just work

00:12:01,440 --> 00:12:07,640
not just work, but they work OK with, in JRuby context

00:12:07,640 --> 00:12:11,820
but still you get a lot of tools like this that can be used, et cetera

00:12:14,440 --> 00:12:17,540
The bad. So what's bad about JRuby?

00:12:17,540 --> 00:12:21,580
one thing that gets talked about a lot is its slow start-up time

00:12:21,580 --> 00:12:24,240
and it is a massive, massive issue

00:12:24,240 --> 00:12:32,540
typically, when you're kind of coding, particularly when you're testing, you want

00:12:32,540 --> 00:12:37,120
to have a very quick cycle of going from test to code to test

00:12:37,120 --> 00:12:40,960
and back and forth, but that's hard to do with JRuby

00:12:40,960 --> 00:12:42,460
and there are other things you can do

00:12:42,480 --> 00:12:44,120
you can use things like ??

00:12:44,120 --> 00:12:46,220
is almost like using Nailgun, for example, or Spork

00:12:46,220 --> 00:12:49,760
connect the ?? up to the VM, and then connect it and run tests against it

00:12:49,760 --> 00:12:53,600
so all that is fine but it's still very sluggish to work with, right

00:12:53,600 --> 00:12:58,880
so you end up having to do a to kind of jump through hoops to work around that problem

00:12:58,880 --> 00:13:03,800
For example, we ended up writing. So all our development was in CRuby.

00:13:03,800 --> 00:13:12,020
So tests run very fast, specs run fast, scripts run fast. But you deploy to JRuby.

00:13:12,020 --> 00:13:16,040
But even then, even for CI and for deployment, you end up isolating

00:13:16,040 --> 00:13:19,300
the kind of scripts which were launched in CRuby.

00:13:19,300 --> 00:13:23,460
But they would in turn just launch JRuby just for the pieces which actually required JRuby.

00:13:23,460 --> 00:13:27,680
So you had to kind of do a bunch of these things. Just kind of not great.

00:13:30,580 --> 00:13:33,860
So, but all this you could kind of live with, right.

00:13:33,860 --> 00:13:38,540
There's one thing about JRuby which surprisingly isn't talked about so much,

00:13:38,540 --> 00:13:43,300
which I think is fundamentally a deal-breaker, and that's its thread safety.

00:13:43,300 --> 00:13:46,440
It's actually. It's not actually a JRuby problem.

00:13:46,440 --> 00:13:53,260
I just think the Ruby world is just not ready to work on a truly multi-threaded Ruby interpreter.

00:13:53,260 --> 00:14:00,740
Right, which is without a global interpreter lock and is manifested in horrible, horrible bugs for us.

00:14:00,740 --> 00:14:05,200
So, when you start working at scale, you know you're getting tons of requests in the system,

00:14:05,200 --> 00:14:09,120
so these problems typically don't manifest when you're running a small service,

00:14:09,120 --> 00:14:11,460
and, you know, JRuby works fine for that. All good.

00:14:11,460 --> 00:14:17,780
But you will run into cases where some library was not written with thread safety in mind

00:14:17,780 --> 00:14:22,240
and that will just kill you, and it is virtually impossible to debug.

00:14:22,240 --> 00:14:29,540
So beefiest problems with Padrino, where the actual app wouldn't get initialized,

00:14:29,540 --> 00:14:34,680
and it was just horrible figuring it out, and the problem turned out to be something

00:14:34,680 --> 00:14:42,140
in HTTP router, which is a gem used for actual route creation,

00:14:42,140 --> 00:14:44,660
and there's no fix for that.

00:14:44,660 --> 00:14:47,340
It's been over a year and a half and it's still not been fixed.

00:14:47,340 --> 00:14:50,280
We actually put in a patch to Padrino to actually work around,

00:14:50,280 --> 00:14:54,060
so we created a rack filter, which kind of hand-holds the initializing process

00:14:54,060 --> 00:14:55,840
and initializes each VM correctly.

00:14:55,840 --> 00:14:59,300
It was just horrible, horrible, horrible code. So that's one.

00:14:59,300 --> 00:15:02,180
HTTPR is one example

00:15:06,600 --> 00:15:08,140
Sadly was, we were ActiveRecord, right.

00:15:08,140 --> 00:15:14,560
We were on 3.1.x, so ActiveRecord has got concurrency, has got concept issues,

00:15:14,560 --> 00:15:17,800
and they don't show up again on, in normal situations,

00:15:17,800 --> 00:15:22,800
they show up at scale, at high load. The connection pool

00:15:22,800 --> 00:15:25,780
is actually not thread safe, so we had situations where the same

00:15:25,780 --> 00:15:29,940
connection was being returned to two different, to two different threads, and 

00:15:29,940 --> 00:15:33,500
they would end up just messing up the data base or the transaction.

00:15:33,500 --> 00:15:36,200
So essentially what would happen was the transaction would commit

00:15:36,200 --> 00:15:42,040
the, but the service would say, OK, 200, all OK, committed, and you would go back

00:15:42,040 --> 00:15:44,540
and see there's no data in the database because the transaction never committed.

00:15:44,540 --> 00:15:47,960
The connection was basically rolled back at some point and nobody knew anything about it.

00:15:47,960 --> 00:15:50,820
No framework. ActiveRecord didn't know anything about it.

00:15:50,820 --> 00:15:52,320
Padrino didn't know anything about it.

00:15:52,320 --> 00:15:54,740
So this was horrible and we couldn't figure out.

00:15:54,740 --> 00:15:59,360
We tried patching. We've actually patched ActiveRecord quite a bit, but we couldn't

00:15:59,360 --> 00:16:06,920
get that to work. So we actually went live with the JRuby in September of 2012.

00:16:06,920 --> 00:16:10,420
And I think in three months, after kind of struggling with these issues,

00:16:10,420 --> 00:16:15,740
we kind of threw a call to move back to CRuby, and that was a kind of sad moment

00:16:15,740 --> 00:16:17,140
because I really, really loved JRuby, 

00:16:17,140 --> 00:16:22,240
and there are great stories of people using it in production.

00:16:22,240 --> 00:16:24,700
Not too many, but yes, there are.

00:16:24,700 --> 00:16:28,220
And its potential is there, but the problem is the libraries,

00:16:28,220 --> 00:16:32,000
and developers are still not in that Java mindset.

00:16:32,000 --> 00:16:33,600
Surprisingly the Java world does this very well.

00:16:33,600 --> 00:16:36,520
They're kind of constantly thinking about thread safety, but the Ruby world

00:16:36,520 --> 00:16:41,220
is still not part of that. They'll probably get there soon, yeah.

00:16:41,220 --> 00:16:45,560
So we moved to CRuby and that sorted out a lot of performance issues,

00:16:45,560 --> 00:16:48,260
rather, thread-safety issues.

00:16:52,460 --> 00:16:54,980
I'll talk about the performance parts actually. I'll draw a comparison.

00:16:57,980 --> 00:17:00,000
Yeah, also, besides performance, I'm guessing you're saying.

00:17:00,000 --> 00:17:01,600
But that wasn't too much of an issue.

00:17:04,840 --> 00:17:08,480
OK, so I mentioned this briefly, I'll just touch on it.

00:17:08,480 --> 00:17:13,780
So what's a problem here. Right. So when you have a bunch of services

00:17:13,780 --> 00:17:16,680
like this, right, when you have a single monolithic application,

00:17:16,680 --> 00:17:22,240
you can start at, you have a request which comes and kind of touches multiple databases

00:17:22,240 --> 00:17:26,100
or the management warehouse, and you can run that, all those database changes

00:17:26,100 --> 00:17:29,120
in a single transaction, right. It commits or doesn't commit.

00:17:29,120 --> 00:17:31,280
Everyone's happy. All beautiful.

00:17:31,280 --> 00:17:35,360
The moment you go to something like this, that doesn't work, right.

00:17:35,360 --> 00:17:41,920
Suppose you have a transaction which, say, called create order, which kind of enters the

00:17:41,920 --> 00:17:45,360
create order request, which comes through the order management system.

00:17:48,160 --> 00:17:52,540
It basically makes the call to approve that order, the fulfillment orchestrator, 

00:17:52,540 --> 00:17:59,320
and the, as part of the fulfillment, the orchestrator basically tells the warehouse service

00:17:59,320 --> 00:18:05,020
that they're all, they don't have the stuff in stock. So I'm gonna actually order it for you.

00:18:05,020 --> 00:18:07,280
So he tells the procurement service to go on, order this item,

00:18:07,280 --> 00:18:10,900
but he also has to tell warehouse that, OK, expect this item.

00:18:10,900 --> 00:18:12,740
I'm ordering it for you. Expect it, right.

00:18:12,740 --> 00:18:16,340
Now, those two things, which is placing the order with the supplier and 

00:18:16,340 --> 00:18:19,880
expect the order, has to happen kind of automatically, right.

00:18:19,880 --> 00:18:25,040
Has to happen automatically, along with the commit of the approval.

00:18:25,040 --> 00:18:28,120
OK. It got approved and I've told this guy to procure it

00:18:28,120 --> 00:18:29,280
and I've told warehouse to expect it, right.

00:18:29,280 --> 00:18:31,940
These two things have to happen at one time.

00:18:31,940 --> 00:18:34,680
Now this is a really, really hard problem to solve, and it's.

00:18:37,120 --> 00:18:42,940
So, the way you solve that, typically, is to, in the enterprise world, is to use

00:18:42,940 --> 00:18:48,620
the stored transaction call data. So most of the JTE servers, for example, do that. 

00:18:48,620 --> 00:18:54,320
They actually have, they kind of implement the two-phase commit,

00:18:54,320 --> 00:19:00,900
and you can actually have a database, two databases, take part in a single transaction or two phases, right.

00:19:00,900 --> 00:19:02,100
So that's one way to do it.

00:19:02,100 --> 00:19:05,620
The problem with that is that completely breaks service isolation.

00:19:05,620 --> 00:19:09,860
Like, now I've got a distributed transaction coordinator which is going to be sitting ??

00:19:09,860 --> 00:19:14,540
and coordinating transactions between this database and that guy, and

00:19:14,540 --> 00:19:17,640
if you remember the original principle, right, I don't want to expose my database. Right?

00:19:17,640 --> 00:19:19,020
I want to expose my service.

00:19:19,060 --> 00:19:21,020
So it kind of breaks service and translation very badly,

00:19:21,020 --> 00:19:23,640
and that's not the least of the problems, right.

00:19:23,640 --> 00:19:27,980
The bigger problem is that it degrades, before, it's basically

00:19:27,980 --> 00:19:32,820
a way to ensure system doesn't scale, because, sorry,

00:19:34,200 --> 00:19:38,080
when you have a transaction spanning multiple systems, essentially 

00:19:38,080 --> 00:19:41,780
what's happening is happening under the hood for each database.

00:19:41,780 --> 00:19:44,600
The resource packages requiring some locks on some rows in the table

00:19:44,600 --> 00:19:48,140
and those are now held for a much longer time, because you're going to go through

00:19:48,140 --> 00:19:49,020
two passes through it, right.

00:19:49,020 --> 00:19:52,660
So essentially you end up holding locks on database rows for much longer,

00:19:52,660 --> 00:19:56,640
which increases contention and reduces book problems, right.

00:19:56,640 --> 00:20:00,180
So then how do you solve this problem, right?

00:20:00,180 --> 00:20:03,100
So the way you solve it. So the other option is to actually go

00:20:03,100 --> 00:20:08,380
in for something like, use messaging. You actually send messages to other services.

00:20:08,380 --> 00:20:15,720
And the push to the message queue and the right database has to happen as one transaction, right.

00:20:15,720 --> 00:20:16,720
So that's another option.

00:20:16,720 --> 00:20:20,300
But, again, you need a distributed transaction coordinator to kind of manage

00:20:20,300 --> 00:20:26,600
the two-phase commit coming between the message queue and the database.

00:20:26,600 --> 00:20:30,480
So what we end up doing is views-

00:20:30,480 --> 00:20:34,000
Are you serious? Ten minutes? All right.

00:20:40,980 --> 00:20:43,920
So yeah. So we ended up creating a service called Resbus,

00:20:43,920 --> 00:20:46,740
which kind of, essentially does local transactions

00:20:46,740 --> 00:20:50,840
and asynchronous relayer of messages to actually call upon

00:20:50,840 --> 00:20:54,380
and I can talk offline about that in more detail, if anybody's interested.

00:20:56,340 --> 00:21:01,360
So what we learned there though was this, the power of HTTP as integration glue

00:21:01,360 --> 00:21:03,540
was just underestimated, right.

00:21:03,540 --> 00:21:09,200
We end up creating, using, messaging systems and use databases, and

00:21:09,200 --> 00:21:10,800
why do you need that?

00:21:10,800 --> 00:21:14,740
Why can't messaging be exposed as a HTTP inquiry?

00:21:14,740 --> 00:21:20,320
We did that, and actually that had amazing side-effects to viewer architecture.

00:21:20,320 --> 00:21:23,520
And, yeah, I can't spend too much time on that.

00:21:25,060 --> 00:21:26,160
So performance.

00:21:28,860 --> 00:21:31,980
So Ruby's performance is often talked about as being sluggish.

00:21:31,980 --> 00:21:36,880
So let's kind of get an intuition for how good or bad that is.

00:21:36,880 --> 00:21:39,480
Let me ask you a question.

00:21:39,480 --> 00:21:49,120
If you had a Hello World Sinatra route, right, and you were to pound it with requests,

00:21:49,120 --> 00:21:50,660
say, using Apache Bench or something,

00:21:50,660 --> 00:21:53,100
what kind of response times can you expect?

00:21:53,100 --> 00:21:59,360
It's just a Hello World, so just a get slash hello_world, and just says Hello World and returns. That's it, right

00:22:00,160 --> 00:22:01,780
Some guesses of how long that would take.

00:22:04,640 --> 00:22:13,340
Five milliseconds? Yeah. So that's roughly, it takes about a millisecond at the 95th percentile.

00:22:13,340 --> 00:22:18,160
But it takes nine to twelve milliseconds at the 99th percentile,

00:22:18,160 --> 00:22:20,020
and the max is around fourteen, right.

00:22:21,380 --> 00:22:23,380
If you run the same thing in JRuby,

00:22:23,380 --> 00:22:31,860
it will take about two milliseconds at the 95th percentile, and 99th would be about five milliseconds,

00:22:31,860 --> 00:22:33,980
and max also is actually about five milliseconds.

00:22:33,980 --> 00:22:35,600
So it's actually very, very tightly bound.

00:22:35,600 --> 00:22:38,660
That's the beauty of JRuby, right, because its GC is so good,

00:22:38,660 --> 00:22:43,380
and the zip compilation is so good that it's able to clearly optimize pieces of code

00:22:43,380 --> 00:22:45,040
to give you very, very stable response times

00:22:45,040 --> 00:22:47,220
but they're actually worse than MRI.

00:22:47,220 --> 00:22:51,240
So the bench marks that talk about JRuby being faster,

00:22:51,240 --> 00:22:52,380
I've never been able to reproduce those.

00:22:52,380 --> 00:22:56,020
So anyway, that's the, an intuition about-

00:22:56,020 --> 00:22:59,120
So we also actually ended up getting much higher support,

00:22:59,120 --> 00:23:04,880
so, that same Hello World server will do about 700 requests per second, 

00:23:04,880 --> 00:23:09,740
versus the JRuby one will take about 550 to 580.

00:23:12,040 --> 00:23:17,060
However, if you had a tomcat servlet doing Hello World,

00:23:17,060 --> 00:23:20,280
how long do you think that would take? Thirty?

00:23:21,600 --> 00:23:25,280
Yeah, it would be roughly in the fifty microseconds, it's about twenty times,

00:23:25,280 --> 00:23:26,820
twenty to forty times faster.

00:23:26,820 --> 00:23:30,920
So that's one of the big arguments that was made against, you know, using Ruby.

00:23:30,920 --> 00:23:32,140
Why should you use Ruby? It's so slow.

00:23:32,140 --> 00:23:36,040
But the point is this, it's still perfectly fine, and that is because

00:23:36,040 --> 00:23:39,560
most business applications are not CPU-bonred, they're IO-boned,

00:23:39,560 --> 00:23:43,460
They're basically all just waiting for some horribly slow query to return, right, 

00:23:43,460 --> 00:23:47,140
and it takes the same time waiting in Java or in Ruby.

00:23:47,140 --> 00:23:53,200
So that's why actually IO in managing, IO is the most important thing,

00:23:53,200 --> 00:23:59,060
and that includes things like database calls, calls to external services, yeah,

00:23:59,060 --> 00:24:04,380
kind of optimizing that is the first priority of, for tuning Ruby apps.

00:24:11,920 --> 00:24:17,760
So, given this, we wanted to make sure that all our services were kind of behaving well.

00:24:17,760 --> 00:24:24,720
So we actually built a tool called drac metrics, which basically is a rack filter

00:24:24,720 --> 00:24:29,080
which will send the request cycle. And you can actually add plug-ins to monitor

00:24:29,080 --> 00:24:33,080
different parts of the application. So we had plug-ins for Sinatra's routes, 

00:24:33,080 --> 00:24:35,220
so you can get inquiry into request time.

00:24:35,220 --> 00:24:39,960
We had plug-ins which ca go to ActiveRecord, and calculated the time for each query,

00:24:39,960 --> 00:24:44,000
and we, it hooked into desk client and thrift clients

00:24:44,000 --> 00:24:48,320
to basically instrument the time taken for all our outgoing calls.

00:24:48,320 --> 00:24:52,200
So the result was it would- oh, look, you can't read it very well.

00:24:52,200 --> 00:24:56,800
But essentially you'd see, you could go to any service and ask for its metrics.

00:24:56,800 --> 00:24:58,740
I'll tell you all the routes that were defined.

00:25:02,100 --> 00:25:05,240
All routes and how much total time was spent in them,

00:25:05,240 --> 00:25:07,580
the total count, we have average time, min, max, et cetera.

00:25:07,580 --> 00:25:11,180
And within each route, if you expanded it, it will tell you the

00:25:11,180 --> 00:25:15,520
five slowest requests for that route.

00:25:15,520 --> 00:25:19,180
So, for example, for this inventory post, inventory call, 

00:25:19,180 --> 00:25:21,720
there's a caller that tells you how much DB time was spent,

00:25:21,720 --> 00:25:28,260
how many rest calls, how much rest calls was split between different parts of the code,

00:25:28,260 --> 00:25:30,860
and it'll give you a list of all the external calls

00:25:30,860 --> 00:25:32,860
and database queries made, right.

00:25:32,860 --> 00:25:35,940
So with this, you could immediately find out that you're doing something stupid like

00:25:35,940 --> 00:25:40,460
an N plus one query, or the call to external system is actually slow, and that kind of optimized

00:25:40,460 --> 00:25:48,340
you have a check list for kind of figuring out what you want to attack first, right.

00:25:48,340 --> 00:25:51,540
So we'd use this, figure out the slow points, optimize that first.

00:25:52,100 --> 00:25:58,440
So, we also had an extensive monitoring through StatsD and Graphite.

00:25:58,440 --> 00:26:02,980
So Graphite allows you to kind of just push points to it

00:26:02,980 --> 00:26:08,060
and it gives you a time series view of the data, and we've got, again,

00:26:08,060 --> 00:26:14,600
as Chad was saying, like metrics from business down to tech metrics, including CPU and

00:26:14,600 --> 00:26:17,540
capacity and request response times, number of requests.

00:26:17,540 --> 00:26:22,700
So with this we also built a loading framework, which basically models Graphite,

00:26:22,700 --> 00:26:27,080
and you can define, OK, if this threshold is breached for this metric, then send me

00:26:27,080 --> 00:26:31,360
a mailer SNS. So with these three pieces, we had the modeling in place

00:26:31,360 --> 00:26:33,840
to kind of keep a check on our systems.

00:26:40,680 --> 00:26:44,020
Right. So how do you tune that,

00:26:44,020 --> 00:26:47,400
once you kind of figure out the problems that are typically there?

00:26:48,100 --> 00:26:49,340
It's actually fairly straightforward.

00:26:49,340 --> 00:26:54,460
If it's IO, fix the IO problem. If it's N plus one query, remove it, do an eager join. Simple stuff.

00:26:54,460 --> 00:27:01,000
If it's a bad query, run MySQL Explain or whatever query plan or tool you have for a database.

00:27:01,000 --> 00:27:07,920
You get the query plan, figure out what the optimal join struct join sequence is, and actually fix the query.

00:27:10,460 --> 00:27:13,860
For external cause, we actually end up putting in very aggresstive time-outs,

00:27:13,860 --> 00:27:19,780
so that you don't have a thread or a process just waiting forever for somebody else to respond, right.

00:27:19,780 --> 00:27:24,120
It, because that has very bad effects on capacity of the entire cluster.

00:27:24,120 --> 00:27:25,800
Because, for example, if you have a slow-

00:27:25,800 --> 00:27:28,300
If you have a service that is calling another service,

00:27:28,300 --> 00:27:30,200
and that service is running slow,

00:27:30,200 --> 00:27:33,420
you can end up completely freezing this calling service

00:27:33,420 --> 00:27:36,860
because all the processes are just waiting for this guy to respond, right.

00:27:42,280 --> 00:27:46,640
So once these two are, these two kind of things are fixed,

00:27:46,640 --> 00:27:50,360
then it's important to look at GC itself.

00:27:50,360 --> 00:27:53,800
Now, Ruby's default GC settings are actually very conservative,

00:27:53,800 --> 00:27:57,800
and you typically see, initially, just after restart,

00:27:57,800 --> 00:28:01,040
response times are kind of slow and they kind of get faster,

00:28:01,040 --> 00:28:05,220
they can work pretty fast, but there's still a lag.

00:28:05,220 --> 00:28:10,640
So there are ways to kind of improve the default heap size

00:28:10,640 --> 00:28:13,020
and the allocation rate and percentage and all that stuff.

00:28:13,020 --> 00:28:17,820
I've got a reference to that in the, at the end, but I think that, that's something which we did

00:28:17,820 --> 00:28:20,800
and that immediately improved our response times.

00:28:25,740 --> 00:28:28,680
So this still doesn't address our problem, right.

00:28:28,680 --> 00:28:31,800
There are still cases where GC is still a problem.

00:28:31,800 --> 00:28:34,960
For example, there will be queries which just load a ton of data,

00:28:34,960 --> 00:28:39,240
say, for example, reporting queries. And those are tricky.

00:28:39,240 --> 00:28:43,540
So, for those, what we end up doing is just carving out a separate cluster

00:28:43,540 --> 00:28:48,160
this earmark tool, two nodes in a cluster for the recording queries,

00:28:48,160 --> 00:28:56,140
build a separate virtual IP, a separate rip, and point all those requests to those, to those servers.

00:28:59,180 --> 00:29:02,420
Even if that doesn't fix the problem with GC,

00:29:02,420 --> 00:29:04,100
then you've got to go down to profiling.

00:29:04,100 --> 00:29:09,680
So for profiling we end up using both tools. Again, a URL link to it at the end,

00:29:09,680 --> 00:29:12,020
which is a great, great tool.

00:29:12,020 --> 00:29:17,720
It's, there are rack filters which can kind of mod the request, of, 

00:29:17,720 --> 00:29:22,000
hook into the request cycle and actually give you a graph of the call-chains,

00:29:22,000 --> 00:29:24,980
along with how much time was being spent in each section.

00:29:24,980 --> 00:29:27,120
That's great. And that'll tell you exactly how much time

00:29:27,120 --> 00:29:28,780
is spent in GC or some section of code.

00:29:28,780 --> 00:29:34,040
So that's your final, final kind of hammer

00:29:34,040 --> 00:29:36,380
you can use to address performance issues.

00:29:38,580 --> 00:29:42,600
We also ended up clinging quite a bit with changing app source.

00:29:42,600 --> 00:29:49,380
So we moved from Trinidad in the JRuby world, time, to an MRI view, passenger first,

00:29:49,380 --> 00:29:50,960
and now we have been on Unicorn.

00:29:53,540 --> 00:29:58,320
And Unicorn particularly has a plug-in called the out-of-band GC, 

00:29:58,320 --> 00:30:01,540
which basically runs GC on that.

00:30:01,540 --> 00:30:07,220
It basically disabled GC for that particular interpreter and runs GC after the request cycle ends.

00:30:07,220 --> 00:30:13,180
Right. So all your response, none of your requests actually see bad response times

00:30:13,180 --> 00:30:15,580
due to GC. So that works beautifully, actually.

00:30:15,580 --> 00:30:17,440
So really nice plug-in.

00:30:17,440 --> 00:30:21,620
There's also a plug-in called WorkerKiller, which can kind kill a worker

00:30:21,620 --> 00:30:25,640
at the process of the memory threshold. So we use all these.

00:30:30,200 --> 00:30:34,920
OK. So another problem we faced, which was, we now have

00:30:34,920 --> 00:30:39,300
twenty-four, twenty-five services running on Sinatra and Padrino apps.

00:30:39,300 --> 00:30:46,080
And there was a bunch of Ruby gems that we were using

00:30:46,080 --> 00:30:47,800
which were the core platform gems which had to be shared.

00:30:47,800 --> 00:30:50,360
And each team worked independently,

00:30:50,360 --> 00:30:53,560
so it ended up becoming a problem for the platform team

00:30:53,560 --> 00:30:56,520
to kind of go and chase around people, say, OK, create this gem

00:30:56,520 --> 00:30:57,520
or there's gonna be problems.

00:30:57,520 --> 00:30:58,960
And that was a big issue.

00:30:59,880 --> 00:31:05,620
So, what we ended up doing was creating a patched version of Bundler

00:31:05,620 --> 00:31:09,560
which essentially allows you to annotate each, your gem file,

00:31:09,560 --> 00:31:16,320
each gem line with a auto-updated code true flag,

00:31:16,320 --> 00:31:19,720
and then Bundler basically will, when you run Bundle install, it will 

00:31:19,720 --> 00:31:24,960
basically check if there's a new version of that same gem in the repo, and actually

00:31:24,960 --> 00:31:27,180
resolves dependencies and actually install.

00:31:27,180 --> 00:31:31,900
So the nice thing with this was, it works in the dev's environment.

00:31:31,900 --> 00:31:33,500
It's not something that happens automatically in the background.

00:31:33,500 --> 00:31:37,600
You're weighing it, kind of messing around platform gems, and it happens

00:31:37,600 --> 00:31:43,500
frequently enough that, you know, everybody, the entire ecosystem kind of moves together

00:31:43,500 --> 00:31:45,580
and upgrades the services quickly.

00:31:48,960 --> 00:31:53,280
OK, so - can I take five minutes? No?

00:31:53,920 --> 00:31:54,920
All right, I'm.

00:31:55,940 --> 00:31:56,940
OK, I'll rush through. So OK.

00:31:56,940 --> 00:31:58,140
Team dynamics.

00:31:59,320 --> 00:32:04,840
So, we started with a Java team, and we kind of just threw them

00:32:04,840 --> 00:32:07,740
into the deep end into Ruby.

00:32:07,740 --> 00:32:12,940
And we just had had about two or three Ruby devs, so it took, on average, I think,

00:32:12,940 --> 00:32:16,580
people about three to four months to start writing idiomatic Ruby,

00:32:16,580 --> 00:32:17,880
and that was a big challenge.

00:32:17,880 --> 00:32:20,280
So we did a bunch of things to kind of address those problems

00:32:20,280 --> 00:32:24,940
including kind of having consultants to bear with the people on the team

00:32:24,940 --> 00:32:27,280
having one expert per team, et cetera.

00:32:30,780 --> 00:32:33,860
OK, I'll skip to. All right. 

00:32:33,860 --> 00:32:41,340
So one of the things that we noticed, or, happened was that 

00:32:43,460 --> 00:32:45,820
because Ruby's such a dynamic language

00:32:45,820 --> 00:32:48,500
you can write such, such code so quickly

00:32:48,500 --> 00:32:49,960
and so compactly 

00:32:49,960 --> 00:32:55,680
sometimes it tends to, design tends to be taken for granted

00:32:55,680 --> 00:32:57,300
I don't know if it's automatic or not

00:32:57,300 --> 00:32:59,320
it will, it tends to be taken for granted

00:32:59,320 --> 00:33:02,080
like people don't, just don't think, like OK there's a feature

00:33:02,080 --> 00:33:07,020
then we decided quickly, it was not, yeah, let's not try to set it on them then

00:33:09,360 --> 00:33:12,060
but I think this is a really big problem

00:33:12,060 --> 00:33:15,340
because you end up, or rather you need to actually ask

00:33:15,340 --> 00:33:16,960
very deep questions about the domain

00:33:16,960 --> 00:33:20,520
and we actually got caught in this problem

00:33:20,520 --> 00:33:22,560
a couple of times where we actually ended up creating

00:33:22,560 --> 00:33:24,840
small custom solutions to specific problems 

00:33:24,840 --> 00:33:26,760
instead of asking deep questions about it

00:33:26,760 --> 00:33:28,860
what is this domain, what is this problem really about

00:33:28,860 --> 00:33:30,360
what is warehousing, for example, really about

00:33:30,360 --> 00:33:32,860
it's not about check lists and foot lists

00:33:32,860 --> 00:33:35,040
it's about goods movement and material movement

00:33:35,040 --> 00:33:37,460
and how do we model that as a first class concept right

00:33:37,460 --> 00:33:43,720
and, I wonder if Ruby being a dynamic powerful language

00:33:43,720 --> 00:33:45,080
actually cultivated that

00:33:45,160 --> 00:33:48,880
that's more of, a question for me

00:33:51,040 --> 00:33:52,540
OK, yeah, questions

00:33:52,540 --> 00:33:55,820
The slides, so there is a bunch of references at the end.

00:33:57,500 --> 00:33:59,200
V.O.: Sorry, Yogi. No questions.

00:33:59,200 --> 00:34:03,400
Y.K.: All right no questions. Thank you guys.

00:34:03,400 --> 00:34:04,980

YouTube URL: https://www.youtube.com/watch?v=FXg2n7Uf4DY


