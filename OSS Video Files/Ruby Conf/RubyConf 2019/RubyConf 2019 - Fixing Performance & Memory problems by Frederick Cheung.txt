Title: RubyConf 2019 - Fixing Performance & Memory problems by Frederick Cheung
Publication date: 2019-12-03
Playlist: RubyConf 2019
Description: 
	RubyConf 2019 - Fixing Performance & Memory problems by Frederick Cheung

Performance problems got you down? Do memory leaks strike fear in your heart?


In this session I'll share two real world stories of how you can solve performance problems and plug memory leaks. You'll learn how to use tools such as ruby-prof and stackprof, interpret their output and gain extra insight into how your code is performing.



When dealing with memory leaks, the biggest challenge can be finding them. You'll learn how to use rbtrace and ObjectSpace to identify what objects are being leaked and by which code, so that you can approach leaks with confidence.

#confreaks #rubyconf2019
Captions: 
	00:00:04,190 --> 00:00:14,860
[Music]

00:00:09,910 --> 00:00:16,960
i Prats i work for a company called

00:00:14,860 --> 00:00:18,160
recipe we do a bunch of stuff but one of

00:00:16,960 --> 00:00:21,160
our big things is clothing

00:00:18,160 --> 00:00:22,599
recommendation engines and today i want

00:00:21,160 --> 00:00:24,849
to tell you about two problems that we'd

00:00:22,599 --> 00:00:26,380
had two stories around these problems

00:00:24,849 --> 00:00:30,099
like a performance problem memory

00:00:26,380 --> 00:00:33,460
problem and what we did about them so

00:00:30,099 --> 00:00:35,230
this is not about 24 au a not anymore

00:00:33,460 --> 00:00:38,110
and this is about a real-time

00:00:35,230 --> 00:00:39,790
recommender system so if you build

00:00:38,110 --> 00:00:41,559
recommendation systems you very often

00:00:39,790 --> 00:00:43,150
have this kind of gap you have your

00:00:41,559 --> 00:00:45,670
batch predictions this is the most

00:00:43,150 --> 00:00:47,440
accurate algorithm you can run but it

00:00:45,670 --> 00:00:49,920
takes a long time to run might take i

00:00:47,440 --> 00:00:52,630
know 12 to 24 hours or something to run

00:00:49,920 --> 00:00:55,000
and you can only really run on all of

00:00:52,630 --> 00:00:56,740
your users data at one time so it's

00:00:55,000 --> 00:00:58,350
great for accuracy but not at all good

00:00:56,740 --> 00:01:00,640
responding to what's actually happening

00:00:58,350 --> 00:01:02,680
then you have your real time recommender

00:01:00,640 --> 00:01:04,479
which is kind of you know responds in

00:01:02,680 --> 00:01:06,220
real time to individual events as they

00:01:04,479 --> 00:01:08,590
come in you know clicks interactions

00:01:06,220 --> 00:01:09,850
purchase and so on and you get some

00:01:08,590 --> 00:01:11,770
things a bit more approximate though it

00:01:09,850 --> 00:01:13,439
is changing literally every second in

00:01:11,770 --> 00:01:15,579
response to every single possible event

00:01:13,439 --> 00:01:18,270
and obviously we're greedy and we want

00:01:15,579 --> 00:01:21,579
both of these things so you combine them

00:01:18,270 --> 00:01:22,780
and this is like not a new idea so we

00:01:21,579 --> 00:01:27,249
thought that sounds good we should do

00:01:22,780 --> 00:01:31,299
that how we did so what went wrong well

00:01:27,249 --> 00:01:33,280
it was fine until we deployed it you

00:01:31,299 --> 00:01:36,999
know there's the PR looked looked good I

00:01:33,280 --> 00:01:38,770
thought you know I approved it you know

00:01:36,999 --> 00:01:41,079
worked by in our staging environments we

00:01:38,770 --> 00:01:43,060
also have these kind of these evaluation

00:01:41,079 --> 00:01:44,289
tests so we've kind of predict was the

00:01:43,060 --> 00:01:46,569
improvement and accuracy that we're

00:01:44,289 --> 00:01:48,789
going to get on real data those numbers

00:01:46,569 --> 00:01:50,439
are really good and actually for the

00:01:48,789 --> 00:01:52,990
first 12 hours after we deployed it it

00:01:50,439 --> 00:01:54,819
was really good as well then I ran that

00:01:52,990 --> 00:01:56,649
evening kind of this thing happened so

00:01:54,819 --> 00:01:59,170
that blue line which starts kicking up

00:01:56,649 --> 00:02:01,569
about 7:00 p.m. that's the number of

00:01:59,170 --> 00:02:04,319
jobs in a queue or the backlog of jobs

00:02:01,569 --> 00:02:07,599
nuke Ãºnica goes up to that 10,000 jobs

00:02:04,319 --> 00:02:09,220
the red line is the number of instances

00:02:07,599 --> 00:02:11,200
that are processing their queue so we're

00:02:09,220 --> 00:02:14,260
kind of adding new instances and it's

00:02:11,200 --> 00:02:15,849
not really doing anything it does

00:02:14,260 --> 00:02:17,380
eventually come back down once of 11:00

00:02:15,849 --> 00:02:18,940
p.m. that's not us rolling back the

00:02:17,380 --> 00:02:21,810
change or fixing anything that's just

00:02:18,940 --> 00:02:21,810
another users going to sleep

00:02:22,170 --> 00:02:24,300
so yeah we got a real-time

00:02:23,010 --> 00:02:26,030
recommendation system we're like a

00:02:24,300 --> 00:02:30,090
two-hour buffer in the middle of it

00:02:26,030 --> 00:02:32,370
which is not great I will say however

00:02:30,090 --> 00:02:33,780
that it did actually kind of work out in

00:02:32,370 --> 00:02:35,490
the sense that we had a real-time

00:02:33,780 --> 00:02:37,110
recommender system whose failure mode

00:02:35,490 --> 00:02:38,670
was a non real-time recommender system

00:02:37,110 --> 00:02:40,260
and like the users didn't know we'd roll

00:02:38,670 --> 00:02:42,240
this out that morning so they didn't

00:02:40,260 --> 00:02:43,620
actually notice anything so in terms of

00:02:42,240 --> 00:02:47,280
our ESL a isn't someone we're all good

00:02:43,620 --> 00:02:50,100
I'm so yeah everyone loves keys I'm

00:02:47,280 --> 00:02:51,180
obviously we - you want to fix this so

00:02:50,100 --> 00:02:52,860
next morning kind of pulled up a

00:02:51,180 --> 00:02:54,209
monitoring see well what is the job that

00:02:52,860 --> 00:02:56,850
is doing this so obviously I've got a

00:02:54,209 --> 00:02:58,530
pretty good idea it's this job which is

00:02:56,850 --> 00:03:00,300
pretty much the last step in a previous

00:02:58,530 --> 00:03:03,540
slides we get our batch predictions that

00:03:00,300 --> 00:03:04,739
we've computed overnight we have an API

00:03:03,540 --> 00:03:06,780
that we can call to get the real-time

00:03:04,739 --> 00:03:08,489
predictions for a user and we combine

00:03:06,780 --> 00:03:10,769
that data we sterilized in a specific

00:03:08,489 --> 00:03:11,519
formats and then put into another data

00:03:10,769 --> 00:03:13,950
store

00:03:11,519 --> 00:03:16,110
and this way any one of these steps

00:03:13,950 --> 00:03:19,530
could be could be the slow step or all

00:03:16,110 --> 00:03:21,120
of them for unlucky um so we dug a bit

00:03:19,530 --> 00:03:22,980
more time on the shrink so this is a

00:03:21,120 --> 00:03:24,959
screenshot from app signal like they're

00:03:22,980 --> 00:03:27,209
really tiny bits I've kind of circled

00:03:24,959 --> 00:03:29,280
anarres those are all the API calls the

00:03:27,209 --> 00:03:31,320
data stores and so on so you know that

00:03:29,280 --> 00:03:33,360
clearly another problem but there's this

00:03:31,320 --> 00:03:36,120
really big step here which is like no 90

00:03:33,360 --> 00:03:38,100
95 % of it and that is the serialized

00:03:36,120 --> 00:03:39,600
step which I actually didn't really

00:03:38,100 --> 00:03:42,480
think would be a problem but clearly it

00:03:39,600 --> 00:03:44,850
was and that's handled by this this

00:03:42,480 --> 00:03:46,230
class here which is conceptually called

00:03:44,850 --> 00:03:47,790
school Maps concept free it's just a

00:03:46,230 --> 00:03:49,920
wrapper around a hash where the keys are

00:03:47,790 --> 00:03:52,280
the IDS of the items and the values are

00:03:49,920 --> 00:03:55,079
how recommended are those items for you

00:03:52,280 --> 00:03:56,190
and from the point of view of this this

00:03:55,079 --> 00:03:58,019
job the men and the point is this

00:03:56,190 --> 00:04:00,269
serialize method where we take the data

00:03:58,019 --> 00:04:02,340
turn into an integer array array of

00:04:00,269 --> 00:04:05,640
integers and pack it in a specific

00:04:02,340 --> 00:04:07,730
format and this is just iterating using

00:04:05,640 --> 00:04:09,810
flat map over the scores

00:04:07,730 --> 00:04:11,760
what would we doing is we're taking the

00:04:09,810 --> 00:04:13,920
key value pairs and we're scaling the

00:04:11,760 --> 00:04:15,209
values so that no matter what the source

00:04:13,920 --> 00:04:17,640
data looks like the value is always

00:04:15,209 --> 00:04:18,630
between 1 and thousands and that just

00:04:17,640 --> 00:04:19,440
makes things easier to deal with

00:04:18,630 --> 00:04:21,539
afterwards

00:04:19,440 --> 00:04:22,740
this and this is the scale factor where

00:04:21,539 --> 00:04:25,229
we just take the biggest value and

00:04:22,740 --> 00:04:27,360
divide it through I'm sorry look at this

00:04:25,229 --> 00:04:30,479
I thought oh this seems legit

00:04:27,360 --> 00:04:32,849
clearly it wasn't so need something a

00:04:30,479 --> 00:04:35,129
little bit more refined than that and we

00:04:32,849 --> 00:04:37,979
started using Ruby froth um

00:04:35,129 --> 00:04:39,689
profiler and what that means is that it

00:04:37,979 --> 00:04:42,119
records the behavior code know who is

00:04:39,689 --> 00:04:44,399
calling what and when and then it uses

00:04:42,119 --> 00:04:46,619
that to produce a bunch of reports where

00:04:44,399 --> 00:04:47,789
your credit spending time and it's not

00:04:46,619 --> 00:04:49,830
something you kind of run preemptively

00:04:47,789 --> 00:04:51,209
it's more something is slow someone's

00:04:49,830 --> 00:04:54,119
shouting at you and I need to understand

00:04:51,209 --> 00:04:56,159
why so here's my rubyprof sort of

00:04:54,119 --> 00:04:57,779
benchmark script if you will I load

00:04:56,159 --> 00:05:01,249
reproof so just that gem you can install

00:04:57,779 --> 00:05:03,089
I load some example data and sometimes

00:05:01,249 --> 00:05:04,819
generating the right input that will

00:05:03,089 --> 00:05:07,229
cool the problems like half the battle

00:05:04,819 --> 00:05:09,330
but in this case is fine just literally

00:05:07,229 --> 00:05:12,209
five hundred key value pair randomly

00:05:09,330 --> 00:05:13,529
generated hash was playing where we

00:05:12,209 --> 00:05:15,389
propped up profiles like the actual

00:05:13,529 --> 00:05:18,269
profile a bit of it so everything that's

00:05:15,389 --> 00:05:19,499
in that block gets measured and then

00:05:18,269 --> 00:05:21,209
once you've got that data error will be

00:05:19,499 --> 00:05:23,789
proof you need to display in some way

00:05:21,209 --> 00:05:25,649
that is readable to you plus well this

00:05:23,789 --> 00:05:27,659
code here does and there's a bunch of

00:05:25,649 --> 00:05:29,729
output classes that come a ruby frolf I

00:05:27,659 --> 00:05:31,319
quite like this HTML based ones but

00:05:29,729 --> 00:05:32,969
they're bunch of other ones and there

00:05:31,319 --> 00:05:34,889
are some that produce output that is I

00:05:32,969 --> 00:05:37,169
mean readable by other tools and you can

00:05:34,889 --> 00:05:39,809
make your own classes as well so I read

00:05:37,169 --> 00:05:42,300
all that and you get kind of this kind

00:05:39,809 --> 00:05:44,579
of wall of information which kind of

00:05:42,300 --> 00:05:47,550
ratio of mental code on slides he

00:05:44,579 --> 00:05:50,039
reminded impose it's scary

00:05:47,550 --> 00:05:53,129
let's have a have a closer look at it so

00:05:50,039 --> 00:05:55,319
each row in this table is one method the

00:05:53,129 --> 00:05:56,459
one the top is this was not really a

00:05:55,319 --> 00:05:59,059
method it's the block that you could

00:05:56,459 --> 00:06:01,319
pass a route to group up the profile

00:05:59,059 --> 00:06:02,669
it's got a bunch of information there so

00:06:01,319 --> 00:06:06,300
color on the Left you've got some timing

00:06:02,669 --> 00:06:07,800
information so how much time does it

00:06:06,300 --> 00:06:10,050
take to run this med as a proportion of

00:06:07,800 --> 00:06:11,669
the total runtime so but this top level

00:06:10,050 --> 00:06:15,059
one is kind of total it's a hundred

00:06:11,669 --> 00:06:17,550
percent kind of by definition the next

00:06:15,059 --> 00:06:19,379
attribute itself and what that is saying

00:06:17,550 --> 00:06:20,579
well yes you spend a home assignment I'm

00:06:19,379 --> 00:06:22,469
wearing this method but did you actually

00:06:20,579 --> 00:06:24,990
spend much of time running others up

00:06:22,469 --> 00:06:27,059
inside that other methods which are else

00:06:24,990 --> 00:06:29,099
were on this table and here Leon says

00:06:27,059 --> 00:06:30,389
yes and this method basically did

00:06:29,099 --> 00:06:33,269
nothing else other than call some other

00:06:30,389 --> 00:06:35,099
stuff and obviously you have that timing

00:06:33,269 --> 00:06:37,469
information is no numbers of seconds

00:06:35,099 --> 00:06:39,539
rather than percentages and on the right

00:06:37,469 --> 00:06:40,979
you have some cool sack information so

00:06:39,539 --> 00:06:42,749
this method all these other two methods

00:06:40,979 --> 00:06:45,089
and I call them once and I was the only

00:06:42,749 --> 00:06:47,009
time that's meant to be called so that's

00:06:45,089 --> 00:06:49,110
you saw didn't you tell me anything yet

00:06:47,009 --> 00:06:51,210
if I look at the next couple of row

00:06:49,110 --> 00:06:53,490
that kind of the same that the total

00:06:51,210 --> 00:06:56,939
time is nearest I met 100 percent the

00:06:53,490 --> 00:06:58,680
self time is basically zero this is

00:06:56,939 --> 00:07:00,270
pretty common you often have a good few

00:06:58,680 --> 00:07:01,319
layers that kind of wrapper code before

00:07:00,270 --> 00:07:03,389
you get through to where the time is

00:07:01,319 --> 00:07:05,219
actually being spent so what I normally

00:07:03,389 --> 00:07:07,199
do is I scroll down the table till the

00:07:05,219 --> 00:07:08,810
first thing I find which has a self time

00:07:07,199 --> 00:07:10,979
that's of non-trivial

00:07:08,810 --> 00:07:13,889
which in this case happens to be the

00:07:10,979 --> 00:07:15,750
each method I Larry see you I can see

00:07:13,889 --> 00:07:18,419
that each to be called by a numeral max

00:07:15,750 --> 00:07:20,129
by I like I see is calling calling the

00:07:18,419 --> 00:07:23,280
ABS method quarter of a million times

00:07:20,129 --> 00:07:25,349
which seems somewhat excessive given you

00:07:23,280 --> 00:07:27,750
know I tell you my input was the 500 key

00:07:25,349 --> 00:07:29,430
value pair hash and these all these

00:07:27,750 --> 00:07:31,139
method names are hyperlink so I can

00:07:29,430 --> 00:07:38,669
click on those things to see the same

00:07:31,139 --> 00:07:39,750
information and pull that method they

00:07:38,669 --> 00:07:41,340
clearly I'm not saying something wrong

00:07:39,750 --> 00:07:43,050
with you know standard library so what I

00:07:41,340 --> 00:07:44,819
need to do and I go back up the call

00:07:43,050 --> 00:07:46,969
stack until I find some my code and you

00:07:44,819 --> 00:07:50,490
know why is according this in this way

00:07:46,969 --> 00:07:51,870
so click around a bit and we get to the

00:07:50,490 --> 00:07:54,360
scale factor method it's been called

00:07:51,870 --> 00:07:56,669
there's 98 percent for the runtime of my

00:07:54,360 --> 00:07:59,219
code and it's the thing that's calling

00:07:56,669 --> 00:08:02,550
max by which is then calling coming out

00:07:59,219 --> 00:08:04,949
kind of pull hole called chain so have a

00:08:02,550 --> 00:08:06,360
look have a look at their method I mean

00:08:04,949 --> 00:08:09,029
a first thing in the kind of pops out

00:08:06,360 --> 00:08:11,819
this method takes no arguments the

00:08:09,029 --> 00:08:13,680
scores hash is not one that we mutate so

00:08:11,819 --> 00:08:16,259
it's gonna return the same thing every

00:08:13,680 --> 00:08:17,610
single time so this we could just

00:08:16,259 --> 00:08:18,900
memorize this but then terms of

00:08:17,610 --> 00:08:22,259
understanding why is it taking so long

00:08:18,900 --> 00:08:24,300
well you got your your hash scores how

00:08:22,259 --> 00:08:25,949
Michael Valley's on it that returns me

00:08:24,300 --> 00:08:28,039
an array of values then I use max base

00:08:25,949 --> 00:08:30,300
that iterates through all the values

00:08:28,039 --> 00:08:32,699
calling ABS on each one so I get the

00:08:30,300 --> 00:08:35,699
biggest one by absolute value and so

00:08:32,699 --> 00:08:37,589
that block gets called if I got a an

00:08:35,699 --> 00:08:39,479
input of size n it gets called N squared

00:08:37,589 --> 00:08:43,919
times and there N squared is always like

00:08:39,479 --> 00:08:45,839
bad bad day so if I memorize it then

00:08:43,919 --> 00:08:47,790
it's still going to call scale factor

00:08:45,839 --> 00:08:50,070
487 times but then you're gonna iterate

00:08:47,790 --> 00:08:52,649
through that array once so I should be

00:08:50,070 --> 00:08:56,070
getting rid of 300 million calls to end

00:08:52,649 --> 00:08:58,500
up abs and yeah I did several hundred

00:08:56,070 --> 00:08:59,850
times faster um so you might say well

00:08:58,500 --> 00:09:01,529
this is great being able to see this

00:08:59,850 --> 00:09:02,370
information why did I have just had this

00:09:01,529 --> 00:09:04,020
running permanently

00:09:02,370 --> 00:09:05,339
so whenever I'm curious about something

00:09:04,020 --> 00:09:08,520
I can click on like monitoring and seal

00:09:05,339 --> 00:09:11,580
this data and basically it will be the

00:09:08,520 --> 00:09:13,230
slow stuff down will be from 1.0 scan I

00:09:11,580 --> 00:09:15,960
ready to be recently is better than the

00:09:13,230 --> 00:09:18,180
older versions it's still kind of three

00:09:15,960 --> 00:09:19,800
to four times slower maybe two and a

00:09:18,180 --> 00:09:21,990
half times if you're lucky so it's not

00:09:19,800 --> 00:09:25,320
something you can rerun constantly and

00:09:21,990 --> 00:09:26,760
it's also generating a lot of data and

00:09:25,320 --> 00:09:28,980
kind of a corollary of that is it it

00:09:26,760 --> 00:09:30,300
distorts things because it's making a

00:09:28,980 --> 00:09:32,370
ruby code three or four times slower

00:09:30,300 --> 00:09:34,470
it's not mating making your database

00:09:32,370 --> 00:09:36,330
queries or your API calls all over your

00:09:34,470 --> 00:09:38,430
file i/o any slower so it's going to

00:09:36,330 --> 00:09:41,940
exaggerate the importance of your Ruby

00:09:38,430 --> 00:09:44,130
code but you know maybe you're still

00:09:41,940 --> 00:09:46,589
kind of greedy and you're like well if I

00:09:44,130 --> 00:09:48,570
get some of this insight insight without

00:09:46,589 --> 00:09:50,880
this performance penalty and without

00:09:48,570 --> 00:09:52,800
this kind of distortion and you can

00:09:50,880 --> 00:09:55,290
using a thing called a sampling profiler

00:09:52,800 --> 00:09:58,170
and basically the the reason why

00:09:55,290 --> 00:09:59,910
rubyprof is has this big overhead is

00:09:58,170 --> 00:10:01,860
because it's a very exact is every

00:09:59,910 --> 00:10:04,200
single method call it's saying running

00:10:01,860 --> 00:10:06,089
down who call this and keeping track of

00:10:04,200 --> 00:10:08,459
that so you know a lot of method calls

00:10:06,089 --> 00:10:10,050
happening in a ruby program and that's

00:10:08,459 --> 00:10:12,870
overhead it's paying on every single one

00:10:10,050 --> 00:10:15,150
of those on the other side the sampling

00:10:12,870 --> 00:10:17,279
profiler is approximate and what it's

00:10:15,150 --> 00:10:19,560
doing is them as your program runs maybe

00:10:17,279 --> 00:10:21,360
once every hundred of a second it will

00:10:19,560 --> 00:10:22,709
pause your program and just grab what is

00:10:21,360 --> 00:10:24,660
the current method actually grab the

00:10:22,709 --> 00:10:26,010
whole call stack but actually simplify

00:10:24,660 --> 00:10:27,750
and say grabs the name of the current

00:10:26,010 --> 00:10:28,800
method and that's all it has to do and

00:10:27,750 --> 00:10:31,230
then you can let your program resume

00:10:28,800 --> 00:10:33,870
running and then nobody gets the end

00:10:31,230 --> 00:10:36,660
will say well how which methods that I

00:10:33,870 --> 00:10:38,790
see and how often and what's going to

00:10:36,660 --> 00:10:40,110
say is that if I saw scale factor as the

00:10:38,790 --> 00:10:42,330
running method and ninety-five percent

00:10:40,110 --> 00:10:44,220
of the time and I'm going to say scale

00:10:42,330 --> 00:10:46,200
factor to 95 percent of the run time I

00:10:44,220 --> 00:10:47,730
mean the cool thing about this is that

00:10:46,200 --> 00:10:52,380
you can trade off accuracy versus

00:10:47,730 --> 00:10:53,730
overhead so maybe I want to run once

00:10:52,380 --> 00:10:55,050
every millisecond I was everyone'd of a

00:10:53,730 --> 00:10:58,070
second it's a bit more overhead a bit

00:10:55,050 --> 00:11:01,050
more precision but you have that control

00:10:58,070 --> 00:11:01,980
there is a good something profiler for

00:11:01,050 --> 00:11:04,680
rubies called stackprof

00:11:01,980 --> 00:11:06,930
by Ammon Gupta pretty straightforward to

00:11:04,680 --> 00:11:08,850
use you knock off that run and these are

00:11:06,930 --> 00:11:12,240
basically the default options and then

00:11:08,850 --> 00:11:15,480
was ever in the block gets measured the

00:11:12,240 --> 00:11:17,280
default output looks like this

00:11:15,480 --> 00:11:19,380
so it's obviously much less output then

00:11:17,280 --> 00:11:21,240
you go out a rubyprof I mean there are

00:11:19,380 --> 00:11:24,030
other options in you can do flame grass

00:11:21,240 --> 00:11:26,700
and stuff but it's still a much less

00:11:24,030 --> 00:11:30,540
than regrowth but that said I mean it

00:11:26,700 --> 00:11:32,130
has picked out the culprit if anything

00:11:30,540 --> 00:11:35,580
slightly easier than really proper this

00:11:32,130 --> 00:11:36,780
less information to look at um I tell it

00:11:35,580 --> 00:11:40,290
had less overhead so I thought I should

00:11:36,780 --> 00:11:40,920
probably you know justify that so I took

00:11:40,290 --> 00:11:43,260
her

00:11:40,920 --> 00:11:44,940
I took my codes I wrote a little script

00:11:43,260 --> 00:11:47,600
I ran it so I think a hundred times the

00:11:44,940 --> 00:11:51,330
loop I'm just on its own took six

00:11:47,600 --> 00:11:53,640
seconds and change around brown rubyprof

00:11:51,330 --> 00:11:55,710
though no instrumentation I ran rubyprof

00:11:53,640 --> 00:11:58,740
on this same benchmarking script out of

00:11:55,710 --> 00:11:59,820
27 seconds that's for for a bit times

00:11:58,740 --> 00:12:02,130
this kind of like a worst case for

00:11:59,820 --> 00:12:03,510
reproof and then I ran it through

00:12:02,130 --> 00:12:06,570
stackprof from the default settings

00:12:03,510 --> 00:12:07,920
which is once every milliseconds and

00:12:06,570 --> 00:12:09,930
maybe there's some overhead there's

00:12:07,920 --> 00:12:12,720
probably measurement error so it's

00:12:09,930 --> 00:12:14,760
basically no overhead for my use case

00:12:12,720 --> 00:12:16,620
which is really cool so you can run this

00:12:14,760 --> 00:12:18,390
in production if you want there's even

00:12:16,620 --> 00:12:20,160
the correct middleware and in stackprof

00:12:18,390 --> 00:12:22,860
so you could hook this into web

00:12:20,160 --> 00:12:26,250
applications so just to kind of

00:12:22,860 --> 00:12:28,200
summarize on my performance problem now

00:12:26,250 --> 00:12:29,550
used monitoring people venting at you

00:12:28,200 --> 00:12:32,700
and Twitter you know that's how you can

00:12:29,550 --> 00:12:34,170
detect problems you know they're

00:12:32,700 --> 00:12:36,060
carbon-based neural nets they're very

00:12:34,170 --> 00:12:38,100
sophisticated

00:12:36,060 --> 00:12:39,720
you know stackprof can actually help you

00:12:38,100 --> 00:12:42,510
can drill that down in production if you

00:12:39,720 --> 00:12:43,890
need to I would then recommend a kind of

00:12:42,510 --> 00:12:45,360
extracting into a small benchmark

00:12:43,890 --> 00:12:46,590
something you can really iterate on

00:12:45,360 --> 00:12:48,150
really quickly you know make a change

00:12:46,590 --> 00:12:50,180
run it in two seconds later add the

00:12:48,150 --> 00:12:52,320
answer have I made it slower or faster

00:12:50,180 --> 00:12:53,910
and if you still need help and yeah

00:12:52,320 --> 00:12:56,190
usually proclick I've dig into that a

00:12:53,910 --> 00:12:59,670
bit more and hopefully the next step is

00:12:56,190 --> 00:13:02,820
profit so the next thing I want to talk

00:12:59,670 --> 00:13:06,060
about is memory I remember being a new

00:13:02,820 --> 00:13:09,390
Ruby developer coming from C and yes

00:13:06,060 --> 00:13:10,890
this is amazing for many reasons one of

00:13:09,390 --> 00:13:12,060
them being well I don't have to worry

00:13:10,890 --> 00:13:14,070
about memory anymore this is great

00:13:12,060 --> 00:13:16,500
garbage collection takes care of memory

00:13:14,070 --> 00:13:18,330
yeah Ruby core team takes care of the

00:13:16,500 --> 00:13:21,120
garbage collector and I can just worry

00:13:18,330 --> 00:13:23,220
about my application I mean is certainly

00:13:21,120 --> 00:13:25,320
true that the core team spends a lot of

00:13:23,220 --> 00:13:27,600
time on memory in the garbage collection

00:13:25,320 --> 00:13:28,900
and so on and these are just some of the

00:13:27,600 --> 00:13:30,610
improvements

00:13:28,900 --> 00:13:31,750
they've added over the past couple years

00:13:30,610 --> 00:13:32,770
you know value even naming like they're

00:13:31,750 --> 00:13:36,100
just the general performance

00:13:32,770 --> 00:13:37,480
improvements but pretty soon and I'm

00:13:36,100 --> 00:13:40,120
sorry for anyone who's still in this

00:13:37,480 --> 00:13:42,580
honeymoon period yeah you still have to

00:13:40,120 --> 00:13:44,110
worry about memory so you know if you

00:13:42,580 --> 00:13:46,620
learn a massive file into memory in one

00:13:44,110 --> 00:13:48,490
go that's going to ruin your day if your

00:13:46,620 --> 00:13:49,810
application has a very large kind of

00:13:48,490 --> 00:13:51,550
base footprint we'll use a lot of memory

00:13:49,810 --> 00:13:53,620
then that's probably an impact your

00:13:51,550 --> 00:13:54,760
hosting costs or your runtime is

00:13:53,620 --> 00:13:56,980
produced a lot of time garbage

00:13:54,760 --> 00:13:58,870
collecting I don't really want to talk

00:13:56,980 --> 00:14:00,040
about that kind of memory problem in

00:13:58,870 --> 00:14:02,050
many ways that's just a performance

00:14:00,040 --> 00:14:04,210
problem but the metrics that are being

00:14:02,050 --> 00:14:06,240
time elapsed is amount of memory

00:14:04,210 --> 00:14:08,350
allocated or number of allocations

00:14:06,240 --> 00:14:10,510
rubyprof has in a measurement mode where

00:14:08,350 --> 00:14:11,860
we'll do exactly that and I know the you

00:14:10,510 --> 00:14:14,380
know the monitoring system I use app

00:14:11,860 --> 00:14:15,960
signal it will tell me how many memory

00:14:14,380 --> 00:14:18,400
allocations happen on each request

00:14:15,960 --> 00:14:19,720
instead I want to talk about an error I

00:14:18,400 --> 00:14:21,670
got through from our monitoring system

00:14:19,720 --> 00:14:24,880
you know they've got paged to me one day

00:14:21,670 --> 00:14:27,190
no memory error which I'd seen come out

00:14:24,880 --> 00:14:29,410
the rails console in IRB many times but

00:14:27,190 --> 00:14:30,190
never in a page I guess because if

00:14:29,410 --> 00:14:32,320
you're out of memory it's quite

00:14:30,190 --> 00:14:33,880
difficult to contact our motor to

00:14:32,320 --> 00:14:36,610
trigger a page someone has happened

00:14:33,880 --> 00:14:38,920
halfway around the world so that's quite

00:14:36,610 --> 00:14:43,060
curious it was kind of 10:00 in the

00:14:38,920 --> 00:14:47,290
morning wasn't a busy time for us to

00:14:43,060 --> 00:14:48,760
start looking into our monitoring and

00:14:47,290 --> 00:14:51,490
when you look at the kind of lifetime

00:14:48,760 --> 00:14:53,560
usage of a other process you're kind of

00:14:51,490 --> 00:14:55,750
hoping or something a bit like this it

00:14:53,560 --> 00:14:58,900
starts out growing quite quickly as

00:14:55,750 --> 00:15:01,810
stuff gets loaded as needed it ramps up

00:14:58,900 --> 00:15:02,920
then it kind of entry stabilizes and

00:15:01,810 --> 00:15:04,150
instead we were saying something

00:15:02,920 --> 00:15:05,740
especially like this there's kind of

00:15:04,150 --> 00:15:07,209
growing steadily steadily steadily and

00:15:05,740 --> 00:15:10,660
there's you know there's no clear end in

00:15:07,209 --> 00:15:13,600
sight let me show the memory leak a bit

00:15:10,660 --> 00:15:15,880
big font because it's scary

00:15:13,600 --> 00:15:17,290
and you might feel betrayed as a new

00:15:15,880 --> 00:15:19,720
rubia to a memory leak you know how can

00:15:17,290 --> 00:15:21,880
this happen why is the garbage collector

00:15:19,720 --> 00:15:23,589
not doing his job

00:15:21,880 --> 00:15:26,950
once couple days they come from

00:15:23,589 --> 00:15:30,640
so obviously native extensions so C code

00:15:26,950 --> 00:15:32,170
doesn't play by the rules that's a whole

00:15:30,640 --> 00:15:34,779
different talk how to track down leaks

00:15:32,170 --> 00:15:36,640
in C extensions but that can definitely

00:15:34,779 --> 00:15:38,500
happen I mean and a couple of C

00:15:36,640 --> 00:15:41,800
extensions have been notorious over the

00:15:38,500 --> 00:15:42,160
years for leaking memory but the rest of

00:15:41,800 --> 00:15:44,290
the

00:15:42,160 --> 00:15:45,790
if you have a memory leak in Ruby it's

00:15:44,290 --> 00:15:48,190
because Ruby thinks that you are still

00:15:45,790 --> 00:15:50,860
using that memory you may think you're

00:15:48,190 --> 00:15:53,040
not using it but Ruby does so that's

00:15:50,860 --> 00:15:54,759
often some very long-lived objects

00:15:53,040 --> 00:15:56,440
caches that I've got out of control

00:15:54,759 --> 00:15:59,050
global variables if you're still using

00:15:56,440 --> 00:16:01,149
those and they often boil down to not

00:15:59,050 --> 00:16:03,639
understanding life cycle these objects

00:16:01,149 --> 00:16:06,250
you think it's a short-lived object but

00:16:03,639 --> 00:16:08,410
it's not I've got an example here of the

00:16:06,250 --> 00:16:10,360
memory leak that I wrote once um so this

00:16:08,410 --> 00:16:12,970
is a rack middleware I copied this

00:16:10,360 --> 00:16:15,699
method from a rails controller a dumb

00:16:12,970 --> 00:16:18,339
thing to do as it turned out so no rails

00:16:15,699 --> 00:16:19,690
control a rails controller rails create

00:16:18,339 --> 00:16:22,750
a new instance for every single request

00:16:19,690 --> 00:16:24,759
so the controller object lives for mine

00:16:22,750 --> 00:16:27,160
over 100 milliseconds so this little at

00:16:24,759 --> 00:16:28,329
things cache it'll happen to be two or

00:16:27,160 --> 00:16:29,649
three things in it and then after a

00:16:28,329 --> 00:16:31,930
hundred milliseconds the controller

00:16:29,649 --> 00:16:34,389
object gets destroyed and this goes with

00:16:31,930 --> 00:16:35,860
it a rack middleware is very different a

00:16:34,389 --> 00:16:37,839
rack middleware lasts for the entire

00:16:35,860 --> 00:16:38,889
lifetime of your application so this

00:16:37,839 --> 00:16:40,120
thing just grows and grows and grows

00:16:38,889 --> 00:16:42,759
until it's got a hole that database

00:16:40,120 --> 00:16:44,079
table still in the instance variable and

00:16:42,759 --> 00:16:47,019
probably all the associated objects as

00:16:44,079 --> 00:16:50,889
well and yeah in-memory databases are

00:16:47,019 --> 00:16:53,560
great but don't build them like this so

00:16:50,889 --> 00:16:54,250
yeah misunderstanding the lifecycle of

00:16:53,560 --> 00:16:57,310
your objects

00:16:54,250 --> 00:16:58,680
I said leaks were scary I think there's

00:16:57,310 --> 00:17:00,939
a couple of reasons

00:16:58,680 --> 00:17:02,889
first I think they're a global problem

00:17:00,939 --> 00:17:04,929
like there is all of the complicated

00:17:02,889 --> 00:17:07,240
behavior application that's kind of

00:17:04,929 --> 00:17:08,199
drilled down to one number and it

00:17:07,240 --> 00:17:09,459
doesn't really give you any clues on

00:17:08,199 --> 00:17:11,650
where to start

00:17:09,459 --> 00:17:12,970
it's not like a user saying yeah I'm you

00:17:11,650 --> 00:17:14,679
know your app is really slow when I

00:17:12,970 --> 00:17:15,850
press this button you know they're you

00:17:14,679 --> 00:17:17,140
know where to start or we get a

00:17:15,850 --> 00:17:18,549
performance alert if you're monitoring

00:17:17,140 --> 00:17:20,230
saying this endpoint is slow and you

00:17:18,549 --> 00:17:22,480
again you know where to start with a

00:17:20,230 --> 00:17:25,630
memory leak it's just I don't know from

00:17:22,480 --> 00:17:28,630
this leaking second thing is memory

00:17:25,630 --> 00:17:31,120
usage is quite complicated and noisy the

00:17:28,630 --> 00:17:33,610
patterns are our memory usage are very

00:17:31,120 --> 00:17:35,470
complicated that's actually a very good

00:17:33,610 --> 00:17:39,570
blog post recently by British Neiman

00:17:35,470 --> 00:17:39,570
kind of digging into that I Richard

00:17:39,880 --> 00:17:43,070
so you got this very complicated

00:17:41,690 --> 00:17:44,360
behavior and you're trying to pull out

00:17:43,070 --> 00:17:45,559
this very small amount of signal you

00:17:44,360 --> 00:17:47,559
know you've got an application that's

00:17:45,559 --> 00:17:50,000
making I know tens of thousands of

00:17:47,559 --> 00:17:53,920
medications per request and there's like

00:17:50,000 --> 00:17:53,920
one of them or two of them bad

00:17:54,160 --> 00:17:58,700
so yeah ask complicated oh yeah and

00:17:57,200 --> 00:18:00,530
obviously dependency is very easy to

00:17:58,700 --> 00:18:03,590
update a gem put in something new and

00:18:00,530 --> 00:18:05,390
there's a leak in there so if you get

00:18:03,590 --> 00:18:08,450
back to my problem I've got my leaking

00:18:05,390 --> 00:18:10,250
rails application so the modern training

00:18:08,450 --> 00:18:12,740
and someone can tell me where the leak

00:18:10,250 --> 00:18:14,390
is coming from straightaway but my first

00:18:12,740 --> 00:18:16,610
hope was well maybe is this a really new

00:18:14,390 --> 00:18:18,530
leak you know maybe if I'm really lucky

00:18:16,610 --> 00:18:19,820
since the last deploy and then they'll

00:18:18,530 --> 00:18:22,820
just have a very small amount of code

00:18:19,820 --> 00:18:24,800
toward it unfortunately the answer was

00:18:22,820 --> 00:18:26,210
at least a year it's at least a year

00:18:24,800 --> 00:18:28,970
because we had one year's worth of

00:18:26,210 --> 00:18:30,470
monitoring data so you might be thinking

00:18:28,970 --> 00:18:32,600
well how do we not notice this for a

00:18:30,470 --> 00:18:35,630
year which is you know maybe not the

00:18:32,600 --> 00:18:37,910
best well it's either a very slow leak

00:18:35,630 --> 00:18:39,650
or very rarely was taking about two

00:18:37,910 --> 00:18:41,450
weeks to exhaust memory on the instances

00:18:39,650 --> 00:18:44,360
that we're using and that's doing about

00:18:41,450 --> 00:18:46,429
three million requests a day so you're a

00:18:44,360 --> 00:18:48,770
very gradual and because it's two weeks

00:18:46,429 --> 00:18:50,870
and we deploy more often that I mean

00:18:48,770 --> 00:18:52,250
substantially more often than that and

00:18:50,870 --> 00:18:53,870
even if we're not deploying we're

00:18:52,250 --> 00:18:55,520
starting up new instances to deal with

00:18:53,870 --> 00:18:57,860
load or stopping them and so on

00:18:55,520 --> 00:18:59,270
and so it's very rare for the app for an

00:18:57,860 --> 00:19:02,660
individual process to be running along

00:18:59,270 --> 00:19:04,730
an upper to be a problem and if it did

00:19:02,660 --> 00:19:05,780
become a problem an instance fails put

00:19:04,730 --> 00:19:08,300
it around the memory then it gets

00:19:05,780 --> 00:19:10,580
automatically retired and replaced you

00:19:08,300 --> 00:19:10,970
know we just say hey WS what do they

00:19:10,580 --> 00:19:15,140
know

00:19:10,970 --> 00:19:18,440
yeah so I reliable phone of T it was us

00:19:15,140 --> 00:19:25,160
so yeah we start your apps all the time

00:19:18,440 --> 00:19:27,260
thank you pick over to my talk I mean

00:19:25,160 --> 00:19:29,150
all seriousness I mean like the whole

00:19:27,260 --> 00:19:31,420
like Lenny crash thing is actually quite

00:19:29,150 --> 00:19:35,270
a sound idea again that is another talk

00:19:31,420 --> 00:19:37,190
and I wanted fix this leak the problem I

00:19:35,270 --> 00:19:41,360
had is I could not reproduce it so I

00:19:37,190 --> 00:19:43,280
spent a day or two trying as I try do

00:19:41,360 --> 00:19:44,840
different end points in the app I tried

00:19:43,280 --> 00:19:48,290
all kinds of tools that do generate

00:19:44,840 --> 00:19:50,030
synthetic load but wasn't getting

00:19:48,290 --> 00:19:51,830
anywhere like you know whenever I did it

00:19:50,030 --> 00:19:54,820
seemed like it was not leaking or maybe

00:19:51,830 --> 00:20:00,770
was leaking so slow I couldn't

00:19:54,820 --> 00:20:01,880
so what could be happening well maybe

00:20:00,770 --> 00:20:03,500
I'm not just picking the right end point

00:20:01,880 --> 00:20:05,150
like I don't know whether this is a

00:20:03,500 --> 00:20:06,800
common problem or very rare problem

00:20:05,150 --> 00:20:07,370
maybe it's some weird end point there

00:20:06,800 --> 00:20:08,840
gets here

00:20:07,370 --> 00:20:10,160
you know once a day if you need

00:20:08,840 --> 00:20:12,770
something very specific and that's where

00:20:10,160 --> 00:20:14,570
that he's coming from maybe it's a usage

00:20:12,770 --> 00:20:16,940
pattern thing like maybe there's a race

00:20:14,570 --> 00:20:18,620
condition in a cash somewhere and the

00:20:16,940 --> 00:20:20,930
only way you leak is use that race

00:20:18,620 --> 00:20:23,360
condition and whatever I'm doing locally

00:20:20,930 --> 00:20:25,130
it's not doing that or just you know

00:20:23,360 --> 00:20:27,350
weird environmental differences that

00:20:25,130 --> 00:20:29,090
stuff happens so having kind of

00:20:27,350 --> 00:20:31,330
exhausted what I could do in serve our

00:20:29,090 --> 00:20:33,590
development and staging environments

00:20:31,330 --> 00:20:35,060
debugging your production sounds like

00:20:33,590 --> 00:20:36,470
like a really bad thing that was like

00:20:35,060 --> 00:20:39,140
lock the doors so no one can see that

00:20:36,470 --> 00:20:40,610
we're talking about it but you know if

00:20:39,140 --> 00:20:42,850
you need that insight from production

00:20:40,610 --> 00:20:45,020
sometimes you go do what you got to do

00:20:42,850 --> 00:20:46,640
and to be clear I'm not talking about

00:20:45,020 --> 00:20:48,080
you know old school I'm gonna open up a

00:20:46,640 --> 00:20:50,600
text editor on the server and start

00:20:48,080 --> 00:20:51,250
editing files and you know like in the

00:20:50,600 --> 00:20:56,360
good old days

00:20:51,250 --> 00:20:57,860
I did PHP once I was talking about you

00:20:56,360 --> 00:21:01,970
know instrumenting my code in production

00:20:57,860 --> 00:21:05,080
to get some extra data and the two tools

00:21:01,970 --> 00:21:07,340
I kind of used first is our beat race

00:21:05,080 --> 00:21:08,680
which I see another tool by a man group

00:21:07,340 --> 00:21:11,270
toad the stackprof

00:21:08,680 --> 00:21:12,980
it kind of builds itself as s trace for

00:21:11,270 --> 00:21:14,690
Ruby and what that means is that you can

00:21:12,980 --> 00:21:15,560
connect to a Ruby process and get a lot

00:21:14,690 --> 00:21:18,470
of insight out of it

00:21:15,560 --> 00:21:19,820
um so you can count method calls and

00:21:18,470 --> 00:21:20,960
garbage collections and there's all kind

00:21:19,820 --> 00:21:23,210
of options kind of filtering down that

00:21:20,960 --> 00:21:24,770
firehose something measurable I'm you

00:21:23,210 --> 00:21:27,230
can go back traces which is really cool

00:21:24,770 --> 00:21:29,150
so say you've got a reprocess that stuck

00:21:27,230 --> 00:21:30,740
it at a hundred percent CPU or when

00:21:29,150 --> 00:21:32,480
we're stuck at zero percent CPU or like

00:21:30,740 --> 00:21:34,070
what is this code doing well you know

00:21:32,480 --> 00:21:35,210
get a back trace you'll see what the

00:21:34,070 --> 00:21:36,650
call stack will look like and all your

00:21:35,210 --> 00:21:39,560
threads and hopefully you can see where

00:21:36,650 --> 00:21:41,090
that time was going and actually but the

00:21:39,560 --> 00:21:42,530
other thing you can do which what I was

00:21:41,090 --> 00:21:45,530
actually Singapore is you can inject

00:21:42,530 --> 00:21:48,470
poverty ruby into a process it was quite

00:21:45,530 --> 00:21:50,090
cool and the thing I wanted to inject is

00:21:48,470 --> 00:21:52,760
to think will trace object allocations

00:21:50,090 --> 00:21:54,560
which is part of object space in the

00:21:52,760 --> 00:21:56,480
Ruby standard library and what that does

00:21:54,560 --> 00:21:57,950
is it records details but every single

00:21:56,480 --> 00:21:59,900
memory allocation that happens in your

00:21:57,950 --> 00:22:03,050
system and you can dump all that data

00:21:59,900 --> 00:22:04,550
right it does come with this warning in

00:22:03,050 --> 00:22:06,410
the documentation

00:22:04,550 --> 00:22:07,170
note that this feature introduces a huge

00:22:06,410 --> 00:22:10,320
performance

00:22:07,170 --> 00:22:11,580
and the huge memory consumption which

00:22:10,320 --> 00:22:13,080
kind of makes sense you know that is

00:22:11,580 --> 00:22:14,760
every single allocation we like really

00:22:13,080 --> 00:22:16,530
profit every single method call was

00:22:14,760 --> 00:22:19,770
incurring overhead and that was every

00:22:16,530 --> 00:22:21,900
single allocation so my plan was

00:22:19,770 --> 00:22:23,940
well maybe is bad if you just have this

00:22:21,900 --> 00:22:27,030
everywhere but if I run this just on you

00:22:23,940 --> 00:22:29,550
know one of our ec2 instances and I only

00:22:27,030 --> 00:22:31,170
I'll be priced and on a single process

00:22:29,550 --> 00:22:32,790
on the instance that's probably only

00:22:31,170 --> 00:22:36,390
know single digit percentages of our

00:22:32,790 --> 00:22:38,040
requests so it's probably fine and you

00:22:36,390 --> 00:22:41,430
know I won't do it like on Black Friday

00:22:38,040 --> 00:22:44,400
or something so yeah do that you know

00:22:41,430 --> 00:22:45,690
this is the danger zone and then I just

00:22:44,400 --> 00:22:47,460
runs for a couple of minutes yeah a heap

00:22:45,690 --> 00:22:50,760
dump and then analyze that heap dump

00:22:47,460 --> 00:22:54,090
offline and yeah and then hopefully you

00:22:50,760 --> 00:22:55,850
profit so you can have this like

00:22:54,090 --> 00:22:58,620
incantation with our we traced to run it

00:22:55,850 --> 00:23:01,740
kind of the meat where I'm doing it at

00:22:58,620 --> 00:23:03,000
Ramon traced object allocation start let

00:23:01,740 --> 00:23:04,230
them running for go for a couple of

00:23:03,000 --> 00:23:06,120
minutes and then trace already

00:23:04,230 --> 00:23:08,570
allocations stopped so that it stops

00:23:06,120 --> 00:23:15,330
consuming all the memory and everything

00:23:08,570 --> 00:23:17,430
and then just dump that to a file I did

00:23:15,330 --> 00:23:19,230
this a couple of minutes a few hundred

00:23:17,430 --> 00:23:21,750
megabytes of output so you might be

00:23:19,230 --> 00:23:24,000
wondering we know what is an ape dump in

00:23:21,750 --> 00:23:25,800
a way it's quite simple it's one JSON

00:23:24,000 --> 00:23:28,410
object for every single object that's

00:23:25,800 --> 00:23:30,060
the live in your application and they

00:23:28,410 --> 00:23:31,830
look a bit like this so you start off

00:23:30,060 --> 00:23:34,500
with an address this is just where in

00:23:31,830 --> 00:23:36,450
memory was this object I mean get a load

00:23:34,500 --> 00:23:38,490
of type information so this is not type

00:23:36,450 --> 00:23:41,220
as in your class name it's look at those

00:23:38,490 --> 00:23:42,450
so the internal sea types that it

00:23:41,220 --> 00:23:46,320
doesn't have the missing like object

00:23:42,450 --> 00:23:48,240
string array and so on so 99% of the

00:23:46,320 --> 00:23:50,610
time it is an if is something from your

00:23:48,240 --> 00:23:52,560
codes just going to be object you do

00:23:50,610 --> 00:23:54,870
have a pointer to the class subject for

00:23:52,560 --> 00:23:56,280
this clip for this object um so you

00:23:54,870 --> 00:23:57,450
could go look at your heap dump for that

00:23:56,280 --> 00:23:59,520
address and see what it is

00:23:57,450 --> 00:24:00,840
quite often you don't need to because

00:23:59,520 --> 00:24:03,480
the next bit of information is where

00:24:00,840 --> 00:24:05,670
does was this memory allocated so in

00:24:03,480 --> 00:24:08,190
this case it's a ID document of

00:24:05,670 --> 00:24:10,140
some sort you get a generation which is

00:24:08,190 --> 00:24:11,370
very useful so every time garbage

00:24:10,140 --> 00:24:13,440
collection runs the generation

00:24:11,370 --> 00:24:16,590
increments by 1 so this is effectively

00:24:13,440 --> 00:24:17,820
tell me when was memory allocated you

00:24:16,590 --> 00:24:19,200
get some information about the footprint

00:24:17,820 --> 00:24:20,550
of the app so it's got three instance

00:24:19,200 --> 00:24:22,890
variables

00:24:20,550 --> 00:24:24,690
mm sighs like kind of approximate it

00:24:22,890 --> 00:24:26,910
works for some things and not for others

00:24:24,690 --> 00:24:28,410
so take that with Peter's thoughts if

00:24:26,910 --> 00:24:28,800
you see 40 is probably I'll tell you the

00:24:28,410 --> 00:24:30,720
whole truth

00:24:28,800 --> 00:24:33,390
that's kind the default size for a ruby

00:24:30,720 --> 00:24:34,770
object in memory it's 40 bytes and it's

00:24:33,390 --> 00:24:37,680
like any Ruby on the Apple to you which

00:24:34,770 --> 00:24:40,710
is a lot smaller reference says that's

00:24:37,680 --> 00:24:42,420
any object is holding on to so say you

00:24:40,710 --> 00:24:44,760
had an array then you'd see all the

00:24:42,420 --> 00:24:46,860
contents of the area there then you get

00:24:44,760 --> 00:24:49,530
some flag data in this case WB and

00:24:46,860 --> 00:24:52,110
protect WB protected is to do with the

00:24:49,530 --> 00:24:54,510
incremental garbage collection um so

00:24:52,110 --> 00:24:56,430
this is great is very detailed but

00:24:54,510 --> 00:24:59,550
there's like literally a million of

00:24:56,430 --> 00:25:00,660
these in this file so just going to you

00:24:59,550 --> 00:25:03,450
know where you want to start it's far

00:25:00,660 --> 00:25:05,250
too much detail so you want to get an

00:25:03,450 --> 00:25:07,830
address that's out of that and I use the

00:25:05,250 --> 00:25:09,690
gem called he P also by Richards Neiman

00:25:07,830 --> 00:25:13,620
you still there he hasn't left so it's

00:25:09,690 --> 00:25:15,000
good so took first thing I thought well

00:25:13,620 --> 00:25:17,610
what does it look like if I have an

00:25:15,000 --> 00:25:19,590
application that's not leaking so I give

00:25:17,610 --> 00:25:22,050
it my heap dump to file it grinds away

00:25:19,590 --> 00:25:24,750
for a couple of seconds the first thing

00:25:22,050 --> 00:25:27,240
you see is a generation nil this is

00:25:24,750 --> 00:25:29,730
basically all the data for allocations

00:25:27,240 --> 00:25:31,620
that happen before I turned on occasion

00:25:29,730 --> 00:25:33,090
tracing so this is like the line share

00:25:31,620 --> 00:25:37,830
the start of my app these have allocated

00:25:33,090 --> 00:25:39,930
for $475,000 X and the memory is 0 again

00:25:37,830 --> 00:25:42,510
because the tracing wasn't on at that

00:25:39,930 --> 00:25:44,430
point first these are the first few

00:25:42,510 --> 00:25:45,390
generations after I turn on tracing so

00:25:44,430 --> 00:25:47,100
there's a small amount of memory

00:25:45,390 --> 00:25:48,980
something allocated and it's still being

00:25:47,100 --> 00:25:52,410
used much later on which is kind of ok

00:25:48,980 --> 00:25:54,420
um and then there's 2000 something

00:25:52,410 --> 00:25:57,030
generations for which we have no memory

00:25:54,420 --> 00:25:58,530
retained this is what you want you know

00:25:57,030 --> 00:26:00,660
there was a memory it got used it got

00:25:58,530 --> 00:26:02,550
released that's fine and there is a

00:26:00,660 --> 00:26:04,230
small amount memory memory being used by

00:26:02,550 --> 00:26:06,690
the most recent generations that's what

00:26:04,230 --> 00:26:09,270
my code is currently working on so you

00:26:06,690 --> 00:26:11,820
know this is this is what you want so

00:26:09,270 --> 00:26:13,470
then I ran it on my bad dump so the

00:26:11,820 --> 00:26:15,180
first bit is kind of the same I've got

00:26:13,470 --> 00:26:16,890
these memory memory being allocated

00:26:15,180 --> 00:26:18,810
earlier on the application startup and

00:26:16,890 --> 00:26:22,110
which is still there but then I never

00:26:18,810 --> 00:26:23,640
get this gap you know these generations

00:26:22,110 --> 00:26:26,010
they've all retained and they're ten

00:26:23,640 --> 00:26:31,620
objects these ones they will retain ten

00:26:26,010 --> 00:26:33,620
objects and just forever and ever so I

00:26:31,620 --> 00:26:35,350
picked one of these at random

00:26:33,620 --> 00:26:37,370
have a look you know what's in there

00:26:35,350 --> 00:26:39,380
first thing you get is you get some

00:26:37,370 --> 00:26:41,090
information about what you mean leak so

00:26:39,380 --> 00:26:43,430
I've leaked this amount of memory and

00:26:41,090 --> 00:26:45,470
this is aware was allocated from the

00:26:43,430 --> 00:26:48,200
side you'd normally get the full pass by

00:26:45,470 --> 00:26:50,210
a truncated than the other slide so I

00:26:48,200 --> 00:26:52,610
went into the rails code base to see

00:26:50,210 --> 00:26:55,760
what this code does and it's to do with

00:26:52,610 --> 00:26:57,230
the template compiling and the next

00:26:55,760 --> 00:26:59,750
thing you get is you get the actual

00:26:57,230 --> 00:27:01,250
values that were leaked and this really

00:26:59,750 --> 00:27:03,380
cool was for the first time I actually

00:27:01,250 --> 00:27:05,180
know which bit of the app is leaking

00:27:03,380 --> 00:27:07,520
because I know I recognized those view

00:27:05,180 --> 00:27:10,070
names and I know what code it is and

00:27:07,520 --> 00:27:11,720
there's this little little outfit

00:27:10,070 --> 00:27:15,320
displayed that we embed in partner sites

00:27:11,720 --> 00:27:16,640
through an iframe then I was accuracy

00:27:15,320 --> 00:27:18,800
was anything else I went back to the

00:27:16,640 --> 00:27:21,530
actual heap dump file and when I found

00:27:18,800 --> 00:27:23,360
this thing all these objects say

00:27:21,530 --> 00:27:26,000
uncollectible true they're probably why

00:27:23,360 --> 00:27:27,230
they're not being collected but you know

00:27:26,000 --> 00:27:31,160
doesn't really actually help me that

00:27:27,230 --> 00:27:33,830
much so yeah two questions really why

00:27:31,160 --> 00:27:35,300
are there so many of them I don't have

00:27:33,830 --> 00:27:37,760
an infinite number of templates in my

00:27:35,300 --> 00:27:40,340
app I'm listener so there shouldn't be

00:27:37,760 --> 00:27:42,740
an unexhausted will supply of than being

00:27:40,340 --> 00:27:46,430
leaked over and yeah why is the method

00:27:42,740 --> 00:27:48,170
name and a collectible some of you you

00:27:46,430 --> 00:27:49,520
know may remember that a couple years

00:27:48,170 --> 00:27:51,050
ago you did have be really careful with

00:27:49,520 --> 00:27:52,880
symbols and no method name that

00:27:51,050 --> 00:27:54,290
eventually get any symbols because

00:27:52,880 --> 00:27:56,090
symbols couldn't be collected and so if

00:27:54,290 --> 00:27:58,220
you created symbols from user input say

00:27:56,090 --> 00:28:00,500
then you were opening yourself to two

00:27:58,220 --> 00:28:02,330
memory leaks but one of the changes in

00:28:00,500 --> 00:28:05,540
Ruby 2.2 was symbols can be garbage

00:28:02,330 --> 00:28:07,450
collected there was actually some small

00:28:05,540 --> 00:28:10,520
prints terms and conditions may apply

00:28:07,450 --> 00:28:12,070
especially rights not affected there are

00:28:10,520 --> 00:28:14,870
two kinds of symbols

00:28:12,070 --> 00:28:16,460
so there are mortal symbols so if you

00:28:14,870 --> 00:28:19,220
were a food or two same you get a mortal

00:28:16,460 --> 00:28:21,740
symbol but mortal boogers they can die

00:28:19,220 --> 00:28:23,780
they can be collected and you get

00:28:21,740 --> 00:28:25,310
immortal symbols and these are basically

00:28:23,780 --> 00:28:27,410
come out at sea level references to

00:28:25,310 --> 00:28:29,030
stuff kind of oh can a rule of thumb for

00:28:27,410 --> 00:28:31,070
garbage collection improvements in Ruby

00:28:29,030 --> 00:28:32,270
it's always the sea level stuff that

00:28:31,070 --> 00:28:35,600
makes everything horrible and

00:28:32,270 --> 00:28:38,150
complicated and symbol garbage

00:28:35,600 --> 00:28:39,770
collection was no no exception I mean

00:28:38,150 --> 00:28:42,560
yes it turns out if you define a method

00:28:39,770 --> 00:28:44,600
you get in a modal symbol so that

00:28:42,560 --> 00:28:46,610
answers why these things can't be

00:28:44,600 --> 00:28:48,200
collected it still doesn't answer

00:28:46,610 --> 00:28:50,030
why there are so many of them I mean

00:28:48,200 --> 00:28:51,800
there is supposed to be template caching

00:28:50,030 --> 00:28:54,380
and I was looking at the code that said

00:28:51,800 --> 00:28:55,730
it was cashing these templates the first

00:28:54,380 --> 00:28:57,020
thing I checked was without actually

00:28:55,730 --> 00:28:58,990
running in production with development

00:28:57,020 --> 00:29:02,270
settings which is you know easily done

00:28:58,990 --> 00:29:04,340
but no it was actually running as it

00:29:02,270 --> 00:29:05,690
should be so I kind of dug into the

00:29:04,340 --> 00:29:09,260
rails credible a little bit who

00:29:05,690 --> 00:29:11,870
understand was remind myself or how she

00:29:09,260 --> 00:29:13,700
works um every template gets compiled to

00:29:11,870 --> 00:29:15,140
a methods um every time it does that he

00:29:13,700 --> 00:29:17,060
ended it the same template it generates

00:29:15,140 --> 00:29:18,590
a random name for it what the prefix is

00:29:17,060 --> 00:29:22,670
constant but the suffix there's numbers

00:29:18,590 --> 00:29:24,320
at the end are random so rails will

00:29:22,670 --> 00:29:27,040
search multiple folders for your views

00:29:24,320 --> 00:29:29,210
this is called the view search path and

00:29:27,040 --> 00:29:31,760
conceptually it's an array of strings

00:29:29,210 --> 00:29:33,260
you know the path that it looks for in

00:29:31,760 --> 00:29:37,280
practice there are these objects called

00:29:33,260 --> 00:29:38,450
resolvers before we'd looked into this I

00:29:37,280 --> 00:29:40,280
kind of imagined the template cache

00:29:38,450 --> 00:29:42,710
which is a one great big hash of I don't

00:29:40,280 --> 00:29:45,800
know paths to methods something like

00:29:42,710 --> 00:29:48,200
that actually the cache is live inside

00:29:45,800 --> 00:29:49,670
the resolvers so if you have three paths

00:29:48,200 --> 00:29:52,520
you have three resolvers and three

00:29:49,670 --> 00:29:54,560
caches when you say to Rails pre-render

00:29:52,520 --> 00:29:56,840
me this view it goes through each

00:29:54,560 --> 00:29:58,130
revolver saying please you know gave me

00:29:56,840 --> 00:30:00,230
this template and the resolver will

00:29:58,130 --> 00:30:01,670
either return a compiled template loaded

00:30:00,230 --> 00:30:04,430
from disk will say you know I don't have

00:30:01,670 --> 00:30:07,070
this view I was there got me interested

00:30:04,430 --> 00:30:09,890
in view paths I started searching around

00:30:07,070 --> 00:30:11,720
and I found this code I'm as a bit of

00:30:09,890 --> 00:30:15,110
history here so this is the before

00:30:11,720 --> 00:30:16,640
action filter thing originally this

00:30:15,110 --> 00:30:19,220
iframe that we built for our retailers

00:30:16,640 --> 00:30:21,290
got embedded into their desktop site and

00:30:19,220 --> 00:30:23,750
then one day they come along and they

00:30:21,290 --> 00:30:27,290
want to go mobile first you know it's

00:30:23,750 --> 00:30:28,400
like a couple years ago but what they

00:30:27,290 --> 00:30:30,470
wanted to do they want to run their own

00:30:28,400 --> 00:30:31,910
site and the new site in parallel so

00:30:30,470 --> 00:30:35,030
they could you know maybe test stuff and

00:30:31,910 --> 00:30:36,170
gradually colorist they said you know we

00:30:35,030 --> 00:30:38,300
need to run these two things in parallel

00:30:36,170 --> 00:30:40,070
we said that's fine we'll give you this

00:30:38,300 --> 00:30:41,960
query parameter if you pass it then

00:30:40,070 --> 00:30:43,820
we'll run at the mobile version if not

00:30:41,960 --> 00:30:45,740
we'll render the old desktop version and

00:30:43,820 --> 00:30:47,450
the way we did it is we kept exactly the

00:30:45,740 --> 00:30:50,390
same using control sorry the exact same

00:30:47,450 --> 00:30:51,770
controllers in everything and some views

00:30:50,390 --> 00:30:54,260
didn't need any changes some views

00:30:51,770 --> 00:30:55,760
didn't need some changes and we had we

00:30:54,260 --> 00:30:59,610
prepared this view path which had these

00:30:55,760 --> 00:31:02,519
kind of view overrides for mobile

00:30:59,610 --> 00:31:03,960
and so that allows us to just change out

00:31:02,519 --> 00:31:07,289
the base of views that needed needed

00:31:03,960 --> 00:31:08,789
changing so what that looks like in can

00:31:07,289 --> 00:31:10,710
real life is your app starts up you had

00:31:08,789 --> 00:31:12,749
these resolvers so my app maybe just has

00:31:10,710 --> 00:31:15,299
to search path like some view some

00:31:12,749 --> 00:31:19,259
device some views from my app the app

00:31:15,299 --> 00:31:22,289
starts and all the caches are empty my

00:31:19,259 --> 00:31:24,600
app starts getting requests and you know

00:31:22,289 --> 00:31:26,159
fairly quickly these template all the

00:31:24,600 --> 00:31:28,710
templates that I actually use often are

00:31:26,159 --> 00:31:31,409
cached then I get a request for this

00:31:28,710 --> 00:31:33,299
mobile variant so you know I've got my

00:31:31,409 --> 00:31:35,399
prepend view path it as this new

00:31:33,299 --> 00:31:36,239
resolver all the states new so it's

00:31:35,399 --> 00:31:38,879
empty

00:31:36,239 --> 00:31:40,499
it renders like it's two templates so

00:31:38,879 --> 00:31:43,049
this is like okay this is cool

00:31:40,499 --> 00:31:45,480
everything's cached but that prepend

00:31:43,049 --> 00:31:47,220
view path was in a before action an

00:31:45,480 --> 00:31:49,109
innocence method so there only applies

00:31:47,220 --> 00:31:52,379
to that controller so at the end the

00:31:49,109 --> 00:31:54,480
request gets thrown away so when the

00:31:52,379 --> 00:31:58,019
next request comes in start from scratch

00:31:54,480 --> 00:31:59,249
again and so tender caching was working

00:31:58,019 --> 00:32:03,090
but with a new empty cache and every

00:31:59,249 --> 00:32:04,649
request this isn't it not the best which

00:32:03,090 --> 00:32:06,899
color balls down to a life cycle

00:32:04,649 --> 00:32:08,789
misunderstanding again

00:32:06,899 --> 00:32:10,859
lucky for us is ready to be simple you

00:32:08,789 --> 00:32:12,899
know this happened several we noticed

00:32:10,859 --> 00:32:14,249
this so long after we've done the

00:32:12,899 --> 00:32:16,879
switchover that we could just delete all

00:32:14,249 --> 00:32:19,559
the old use whether you can deal with it

00:32:16,879 --> 00:32:21,299
otherwise so before we deployed this

00:32:19,559 --> 00:32:23,309
change this is what I remember she was

00:32:21,299 --> 00:32:27,080
kind of looking like in an off be

00:32:23,309 --> 00:32:30,239
deployed a just flat we were happy just

00:32:27,080 --> 00:32:32,669
kind of summarize I think I said don't

00:32:30,239 --> 00:32:35,159
be afraid of production like there is a

00:32:32,669 --> 00:32:36,989
lot of useful insights in there and you

00:32:35,159 --> 00:32:40,529
care there are ways of experimenting

00:32:36,989 --> 00:32:42,629
relatively safely there heap dumps are

00:32:40,529 --> 00:32:44,369
the bomb I mean they are has so much

00:32:42,629 --> 00:32:47,730
detail to how your application is using

00:32:44,369 --> 00:32:49,559
memory I think the last tip pay

00:32:47,730 --> 00:32:51,869
attention to objects life cycles you

00:32:49,559 --> 00:32:53,609
know don't assume that this thing you

00:32:51,869 --> 00:32:54,779
think is very short-lived is actually

00:32:53,609 --> 00:32:55,919
very short-lived you know that instant

00:32:54,779 --> 00:32:58,230
vary with it oh it's an instance

00:32:55,919 --> 00:33:00,090
variable that's fine if the object is an

00:32:58,230 --> 00:33:03,989
instance of here's like a class

00:33:00,090 --> 00:33:05,580
nothing will live forever and yeah thank

00:33:03,989 --> 00:33:11,910
you very much

00:33:05,580 --> 00:33:11,910
[Applause]

00:33:12,780 --> 00:33:22,060

YouTube URL: https://www.youtube.com/watch?v=UCJsjr8ksDc


