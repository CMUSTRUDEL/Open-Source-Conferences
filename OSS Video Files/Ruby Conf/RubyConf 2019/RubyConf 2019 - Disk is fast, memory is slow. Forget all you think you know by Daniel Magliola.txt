Title: RubyConf 2019 - Disk is fast, memory is slow. Forget all you think you know by Daniel Magliola
Publication date: 2019-12-03
Playlist: RubyConf 2019
Description: 
	RubyConf 2019 - Disk is fast, memory is slow. Forget all you think you know by Daniel Magliola

Adding metrics to your code should effectively have no impact on performance.


When we were recently tasked with doing that in multi-process Ruby servers, we ran into an interesting challenge: could we aggregate our numbers across processes without blowing our target of just one microsecond of overhead?



The months of work that followed had us looking into C extensions, segfault dumps, memory maps, syscall timings, and pretty much everything we could think of to try and achieve our objective.



In the process, we found some very counter-intuitive performance results that I'd like to share with you.

#confreaks #rubyconf2019
Captions: 
	00:00:04,190 --> 00:00:10,269
[Music]

00:00:12,139 --> 00:00:17,460
like many developers I love working on

00:00:15,210 --> 00:00:18,150
code performance getting deep into a

00:00:17,460 --> 00:00:21,660
problem

00:00:18,150 --> 00:00:23,869
measuring profiling tweaking squeezing

00:00:21,660 --> 00:00:26,849
out every last drop of truth for my code

00:00:23,869 --> 00:00:29,820
I'm a rails back-end developer I don't

00:00:26,849 --> 00:00:31,560
get to do that very often last year I

00:00:29,820 --> 00:00:33,899
worked on this project where performance

00:00:31,560 --> 00:00:37,079
was key and working on that project I

00:00:33,899 --> 00:00:40,110
learned some interesting lessons this is

00:00:37,079 --> 00:00:42,390
to talk about assumptions first of all

00:00:40,110 --> 00:00:44,040
though hi my name is Daniel and I work

00:00:42,390 --> 00:00:46,530
for go careless we are a payments

00:00:44,040 --> 00:00:48,120
company based in London UK as you

00:00:46,530 --> 00:00:48,540
probably noticed I'm not originally from

00:00:48,120 --> 00:00:50,640
London

00:00:48,540 --> 00:00:54,000
I come from Argentina so in case you're

00:00:50,640 --> 00:00:55,200
wondering that's the accent now before I

00:00:54,000 --> 00:00:56,430
get into the interesting part of this

00:00:55,200 --> 00:00:57,870
talk I need to give you a little

00:00:56,430 --> 00:01:00,600
background on the problem we were trying

00:00:57,870 --> 00:01:02,850
to solve co-catalyst is a bank to bank

00:01:00,600 --> 00:01:04,500
payments company which basically means

00:01:02,850 --> 00:01:06,600
we're sort of an API on top of the

00:01:04,500 --> 00:01:08,250
banking system when you're a payments

00:01:06,600 --> 00:01:10,140
company your customers expect you to

00:01:08,250 --> 00:01:11,970
always be available just like they

00:01:10,140 --> 00:01:14,790
expect the electricity to always work so

00:01:11,970 --> 00:01:17,010
for us app time is critical and that

00:01:14,790 --> 00:01:18,390
means among other things that having

00:01:17,010 --> 00:01:21,180
good metrics for our apps is critical

00:01:18,390 --> 00:01:22,979
and this is where a project came in one

00:01:21,180 --> 00:01:25,470
of the main tools we use for this is a

00:01:22,979 --> 00:01:27,870
metric server called Prometheus now will

00:01:25,470 --> 00:01:29,600
not Prometheus but we have a pretty big

00:01:27,870 --> 00:01:32,400
issue trying to use a word movie

00:01:29,600 --> 00:01:34,260
prometheus basically keeps a history of

00:01:32,400 --> 00:01:36,240
all what all of your metrics have looked

00:01:34,260 --> 00:01:38,460
like over time and to get those numbers

00:01:36,240 --> 00:01:40,770
it will periodically hit your app asking

00:01:38,460 --> 00:01:42,119
for them so in order to have metrics

00:01:40,770 --> 00:01:44,070
you're gonna have your web server that's

00:01:42,119 --> 00:01:45,810
running your app and in addition is

00:01:44,070 --> 00:01:48,450
keeping a bunch of counters in it say

00:01:45,810 --> 00:01:50,369
how many HTTP requests it serve how long

00:01:48,450 --> 00:01:53,100
they took how many payments you took in

00:01:50,369 --> 00:01:54,720
different currencies Prometheus will hit

00:01:53,100 --> 00:01:55,680
your app every few seconds asking for

00:01:54,720 --> 00:01:57,150
those numbers and you reply with

00:01:55,680 --> 00:02:00,540
something that looks a little bit like

00:01:57,150 --> 00:02:02,610
this now Prometheus also has libraries

00:02:00,540 --> 00:02:04,290
that help you do this these libraries

00:02:02,610 --> 00:02:05,880
allow you to declare your counters and

00:02:04,290 --> 00:02:07,920
set their values and then when you get

00:02:05,880 --> 00:02:10,140
scraped it automatically generates this

00:02:07,920 --> 00:02:11,819
output and this one for all major server

00:02:10,140 --> 00:02:13,890
languages this one for Ruby

00:02:11,819 --> 00:02:14,849
sorry should forego one for Java and of

00:02:13,890 --> 00:02:17,430
course is one for Ruby

00:02:14,849 --> 00:02:21,269
and for most languages the story ends

00:02:17,430 --> 00:02:23,549
there however in Ruby land and by the

00:02:21,269 --> 00:02:23,800
way also in Python land the story is a

00:02:23,549 --> 00:02:25,960
little

00:02:23,800 --> 00:02:29,020
bit trickier because Ruby and Python

00:02:25,960 --> 00:02:31,210
have a global interpreter lock or kill

00:02:29,020 --> 00:02:32,640
which doesn't let you run your code in

00:02:31,210 --> 00:02:35,410
multiple threads at the same time

00:02:32,640 --> 00:02:37,090
because of this our web servers tend to

00:02:35,410 --> 00:02:39,790
not be multi-threaded because that

00:02:37,090 --> 00:02:41,560
doesn't scale very well instead in Ruby

00:02:39,790 --> 00:02:44,560
we tend to use separate processes

00:02:41,560 --> 00:02:46,180
processes don't share memory and this

00:02:44,560 --> 00:02:48,190
ends up solving the same problem that

00:02:46,180 --> 00:02:49,390
the Gil is trying to solve and everyone

00:02:48,190 --> 00:02:51,970
can happily run in parallel

00:02:49,390 --> 00:02:53,890
ignoring each other in the web world we

00:02:51,970 --> 00:02:56,590
call this a prefix server and is how

00:02:53,890 --> 00:02:58,360
unicron works when Unicode starts it

00:02:56,590 --> 00:03:00,340
will load your app and then it Forks

00:02:58,360 --> 00:03:02,770
itself into a master Orchestrator

00:03:00,340 --> 00:03:04,210
process that's listening to requests and

00:03:02,770 --> 00:03:06,340
a bunch of workers that are actually

00:03:04,210 --> 00:03:08,800
working on them when a request comes in

00:03:06,340 --> 00:03:10,660
the master process will pick a client to

00:03:08,800 --> 00:03:12,550
work on it and then take the response

00:03:10,660 --> 00:03:15,280
and send it back to the to the to the

00:03:12,550 --> 00:03:17,230
client the system works great it scales

00:03:15,280 --> 00:03:19,030
really well across scores and is how the

00:03:17,230 --> 00:03:21,880
majority of Ruby web apps are running in

00:03:19,030 --> 00:03:23,260
production however for the primitives

00:03:21,880 --> 00:03:25,330
use case this is a bit of a problem

00:03:23,260 --> 00:03:27,250
because now that we have multiple

00:03:25,330 --> 00:03:29,530
processes and they don't share memory

00:03:27,250 --> 00:03:32,260
which was a whole point each process now

00:03:29,530 --> 00:03:34,660
has their own internal counters when

00:03:32,260 --> 00:03:37,300
prometheus hits you and ask for the all

00:03:34,660 --> 00:03:39,459
of your numbers each the worker that

00:03:37,300 --> 00:03:42,130
works on that process on that request

00:03:39,459 --> 00:03:43,330
will basically report its numbers but

00:03:42,130 --> 00:03:44,920
this is never what you want because this

00:03:43,330 --> 00:03:47,230
is a partial view of the system what you

00:03:44,920 --> 00:03:50,080
want is the view of everything added

00:03:47,230 --> 00:03:51,730
together however because the processes

00:03:50,080 --> 00:03:53,380
don't share memory there's no easy way

00:03:51,730 --> 00:03:54,730
for any process to see the numbers in

00:03:53,380 --> 00:03:57,190
the other processes to be able to add

00:03:54,730 --> 00:03:59,110
them which is by design and it's the

00:03:57,190 --> 00:04:00,940
main reason we use multiple processes we

00:03:59,110 --> 00:04:02,890
want that isolation but for the

00:04:00,940 --> 00:04:05,260
Prometheus case this is a problem so

00:04:02,890 --> 00:04:06,520
since the majority of Ruby web

00:04:05,260 --> 00:04:08,800
applications are running in peripheral

00:04:06,520 --> 00:04:10,420
servers and since the Prometheus library

00:04:08,800 --> 00:04:12,970
doesn't have a solution for that cross

00:04:10,420 --> 00:04:14,860
process validation basically everyone

00:04:12,970 --> 00:04:16,600
that's using Ruby in production and one

00:04:14,860 --> 00:04:18,880
matrix with Prometheus can have them and

00:04:16,600 --> 00:04:20,950
we also had this problem we were using

00:04:18,880 --> 00:04:23,280
Prometheus we want a matrix for our main

00:04:20,950 --> 00:04:26,290
monolith which is Ruby and we couldn't

00:04:23,280 --> 00:04:29,020
and it wasn't just us this has been the

00:04:26,290 --> 00:04:32,410
case for quite a lot of people for quite

00:04:29,020 --> 00:04:33,910
a while and also this ruby library had a

00:04:32,410 --> 00:04:35,710
bunch of other problems he was one of

00:04:33,910 --> 00:04:37,100
the first libraries to be made so it's

00:04:35,710 --> 00:04:38,390
made before the community

00:04:37,100 --> 00:04:40,430
figure out what the best practices were

00:04:38,390 --> 00:04:44,450
for these counters and so it had a bunch

00:04:40,430 --> 00:04:46,280
of other stuff problems now there were

00:04:44,450 --> 00:04:48,830
some workarounds most notably kid lab

00:04:46,280 --> 00:04:50,720
worked this official library and they

00:04:48,830 --> 00:04:52,100
had a multi-process solution but it

00:04:50,720 --> 00:04:53,900
wasn't getting merged back into the main

00:04:52,100 --> 00:04:56,120
repo and it also shared all of these

00:04:53,900 --> 00:04:57,530
issues with best practices so we didn't

00:04:56,120 --> 00:04:59,900
want to use that and we didn't want to

00:04:57,530 --> 00:05:01,160
make yet another fort so instead we got

00:04:59,900 --> 00:05:02,930
in touch with a maintainer roughly

00:05:01,160 --> 00:05:04,520
agreed on a plan of action and we

00:05:02,930 --> 00:05:06,920
decided we would do pretty much every

00:05:04,520 --> 00:05:08,990
write solving all of these issues but

00:05:06,920 --> 00:05:11,360
there was one more thing to consider the

00:05:08,990 --> 00:05:12,590
prometheus maintainer z' really really

00:05:11,360 --> 00:05:15,080
care about performance for these

00:05:12,590 --> 00:05:16,310
libraries because instrumentation should

00:05:15,080 --> 00:05:17,390
be free for your app if you're gonna

00:05:16,310 --> 00:05:18,950
have your counters and you want to

00:05:17,390 --> 00:05:20,630
increment one of those in a tight loop

00:05:18,950 --> 00:05:23,090
you should be able to do that and not

00:05:20,630 --> 00:05:26,060
even notice it and buried in that long

00:05:23,090 --> 00:05:28,100
thread from that 2015 ticket we had a

00:05:26,060 --> 00:05:29,870
target now I've changed names to protect

00:05:28,100 --> 00:05:30,860
the innocent but one of the main main

00:05:29,870 --> 00:05:33,170
Taymor's basically said that

00:05:30,860 --> 00:05:35,660
incrementing a counter should take less

00:05:33,170 --> 00:05:37,550
than a microsecond why a microsecond I

00:05:35,660 --> 00:05:38,690
don't know but that was his target and

00:05:37,550 --> 00:05:41,000
if I wanted to get this thing merged

00:05:38,690 --> 00:05:42,260
we're gonna have to get there now

00:05:41,000 --> 00:05:44,210
another maintainer of this chain

00:05:42,260 --> 00:05:46,520
basically like yeah you're not gonna be

00:05:44,210 --> 00:05:47,840
able to do that in Ruby the first guy

00:05:46,520 --> 00:05:51,020
very recently responds like I mean

00:05:47,840 --> 00:05:52,790
surely Ruby can't be that slow which is

00:05:51,020 --> 00:05:54,860
leads to one of my favorite answers ever

00:05:52,790 --> 00:05:58,730
I guess there's a reason people like

00:05:54,860 --> 00:06:00,260
Ronnie see extensions right so whatever

00:05:58,730 --> 00:06:02,090
we did to solve this problem it had to

00:06:00,260 --> 00:06:04,310
be fast we had an actual target and

00:06:02,090 --> 00:06:05,720
there was one more thing that the

00:06:04,310 --> 00:06:08,030
maintainer zan asked all agree that we

00:06:05,720 --> 00:06:10,070
wanted to do in the library we have

00:06:08,030 --> 00:06:11,990
these metrics classes which is were used

00:06:10,070 --> 00:06:13,900
to declare counters and they store the

00:06:11,990 --> 00:06:16,160
value in an instance variable like this

00:06:13,900 --> 00:06:17,660
we want to change this so that these

00:06:16,160 --> 00:06:19,460
numbers would actually be stored

00:06:17,660 --> 00:06:20,810
somewhere else somewhere separate we

00:06:19,460 --> 00:06:22,640
were to have stores that would be

00:06:20,810 --> 00:06:24,050
interchangeable and keep all of the

00:06:22,640 --> 00:06:25,790
numbers there so we go from something

00:06:24,050 --> 00:06:28,190
like this to something a bit more like

00:06:25,790 --> 00:06:29,810
that and the reason for that is that

00:06:28,190 --> 00:06:31,310
different projects would have different

00:06:29,810 --> 00:06:32,870
needs some people will be running in a

00:06:31,310 --> 00:06:34,300
single thread a single process and

00:06:32,870 --> 00:06:36,680
really really care about performance

00:06:34,300 --> 00:06:38,150
whereas some other people would have a

00:06:36,680 --> 00:06:39,350
web app in multiple processes and

00:06:38,150 --> 00:06:41,630
they're hitting a database over the

00:06:39,350 --> 00:06:44,150
network so who cares about microseconds

00:06:41,630 --> 00:06:46,460
at that point having these

00:06:44,150 --> 00:06:48,440
interchangeable stores gave our users

00:06:46,460 --> 00:06:50,590
better options but also it made our

00:06:48,440 --> 00:06:52,450
lives much much easier because the

00:06:50,590 --> 00:06:54,130
about this problem was that the project

00:06:52,450 --> 00:06:56,020
was sharing these numbers across

00:06:54,130 --> 00:06:57,880
processes right having these

00:06:56,020 --> 00:06:59,440
interchangeable stores meant it was very

00:06:57,880 --> 00:07:01,390
easy to just make a little experiment

00:06:59,440 --> 00:07:02,860
put it up there and measure it and we

00:07:01,390 --> 00:07:04,660
wouldn't have to touch anything else in

00:07:02,860 --> 00:07:07,390
the rest of the code which was a really

00:07:04,660 --> 00:07:09,280
good pattern for experimentation so to

00:07:07,390 --> 00:07:11,110
recap we knew what we had to do we were

00:07:09,280 --> 00:07:12,820
going to rewrite this gem so that it

00:07:11,110 --> 00:07:15,280
would support prefix servers you would

00:07:12,820 --> 00:07:17,110
have obstructed storage of numbers it

00:07:15,280 --> 00:07:19,330
would follow all of the best the current

00:07:17,110 --> 00:07:22,000
best practices and it was going to be

00:07:19,330 --> 00:07:23,680
fast and this is what we were at we're

00:07:22,000 --> 00:07:25,480
not needed to figure out how we were

00:07:23,680 --> 00:07:27,490
going to do this in a way that actually

00:07:25,480 --> 00:07:30,360
allowed us to share those numbers but

00:07:27,490 --> 00:07:34,060
staying under that performance budget

00:07:30,360 --> 00:07:36,370
now to store our numbers we use hashes

00:07:34,060 --> 00:07:38,650
instead of integers for reasons that

00:07:36,370 --> 00:07:40,000
will make more sense later but for now

00:07:38,650 --> 00:07:42,220
what this means is that when I say

00:07:40,000 --> 00:07:43,840
increment the counter what I'm talking

00:07:42,220 --> 00:07:46,690
about in practice is reading and writing

00:07:43,840 --> 00:07:48,580
a value in a hash and I couldn't do this

00:07:46,690 --> 00:07:51,940
exchange they say that could or couldn't

00:07:48,580 --> 00:07:53,560
be done in a microsecond now I don't

00:07:51,940 --> 00:07:54,970
know about you but if you had asked me

00:07:53,560 --> 00:07:57,340
whether this was possible before this

00:07:54,970 --> 00:08:01,480
project my answer would have pretty much

00:07:57,340 --> 00:08:04,090
been a because I have no intuition of

00:08:01,480 --> 00:08:05,980
what performance at this level here one

00:08:04,090 --> 00:08:07,720
guy's implying that Ruby is very slow

00:08:05,980 --> 00:08:09,340
the other one is saying like surely

00:08:07,720 --> 00:08:11,920
writing to hashes is faster than that

00:08:09,340 --> 00:08:13,540
but this is such a tiny scale compared

00:08:11,920 --> 00:08:15,700
to my usual experience that I have no

00:08:13,540 --> 00:08:17,830
idea which one is right what I mean by

00:08:15,700 --> 00:08:20,500
that is my entire Ruby experience for

00:08:17,830 --> 00:08:22,720
the last decade is writing the back end

00:08:20,500 --> 00:08:24,160
of a web app right so I'm used to a

00:08:22,720 --> 00:08:26,170
world of performance that looks a little

00:08:24,160 --> 00:08:28,660
bit like this let's imagine that that's

00:08:26,170 --> 00:08:31,120
a second that's a thousand squares one

00:08:28,660 --> 00:08:32,950
millisecond each as a web programmer

00:08:31,120 --> 00:08:34,630
this is how I see the world

00:08:32,950 --> 00:08:36,790
there's nothing smaller than a

00:08:34,630 --> 00:08:38,530
millisecond for me right so I'm running

00:08:36,790 --> 00:08:40,570
my web app and a request comes in and

00:08:38,530 --> 00:08:42,340
there's a couple of milliseconds taken

00:08:40,570 --> 00:08:43,780
by Unicron rack rails I don't even know

00:08:42,340 --> 00:08:46,900
but before it even hits my code I'd lost

00:08:43,780 --> 00:08:48,430
oh shoot there's a user ID in session so

00:08:46,900 --> 00:08:51,070
we're gonna hit the database to load

00:08:48,430 --> 00:08:53,320
that user it's a will index table so it

00:08:51,070 --> 00:08:55,420
takes just a millisecond the page were

00:08:53,320 --> 00:08:57,400
loading is actually a list of the orders

00:08:55,420 --> 00:08:59,170
for this user so we're gonna hit the

00:08:57,400 --> 00:09:01,090
database to load those orders and we're

00:08:59,170 --> 00:09:03,490
gonna hit it again to load the items for

00:09:01,090 --> 00:09:04,360
those orders then we're gonna hit it a

00:09:03,490 --> 00:09:05,579
bunch more because we

00:09:04,360 --> 00:09:10,180
n plus one that we didn't know about

00:09:05,579 --> 00:09:11,740
oops we check a couple of feature flags

00:09:10,180 --> 00:09:12,940
in gravis which is super fast but it's

00:09:11,740 --> 00:09:14,709
still at the other end of the network

00:09:12,940 --> 00:09:15,160
cable so it's another millisecond

00:09:14,709 --> 00:09:17,079
moralism

00:09:15,160 --> 00:09:18,670
and then we take all of this information

00:09:17,079 --> 00:09:21,399
I would render the view which is quite

00:09:18,670 --> 00:09:24,670
large so it takes a while so that's what

00:09:21,399 --> 00:09:27,040
60 70 milliseconds this is recent

00:09:24,670 --> 00:09:28,839
overweight wave up in rails like this

00:09:27,040 --> 00:09:30,579
isn't a good day and a bad day maybe

00:09:28,839 --> 00:09:33,970
more than that like that but who's

00:09:30,579 --> 00:09:35,709
counting right now this is basically my

00:09:33,970 --> 00:09:38,079
daily life as a rails developer

00:09:35,709 --> 00:09:39,220
this is where my intuition works this is

00:09:38,079 --> 00:09:41,470
where if I need to care about

00:09:39,220 --> 00:09:43,269
performance I know where to look and I

00:09:41,470 --> 00:09:45,519
know roughly how long things take so I

00:09:43,269 --> 00:09:47,260
know where to focus for all the

00:09:45,519 --> 00:09:49,019
developers though this is very different

00:09:47,260 --> 00:09:52,360
for example if you're a game developer

00:09:49,019 --> 00:09:54,640
you live and die in 16 millisecond

00:09:52,360 --> 00:09:56,860
buckets if your game is going to run at

00:09:54,640 --> 00:09:59,320
60 frames per second you have 16

00:09:56,860 --> 00:10:01,600
milliseconds per frame non-negotiable

00:09:59,320 --> 00:10:03,790
no 16 milliseconds you need to process

00:10:01,600 --> 00:10:05,529
your inputs run your physics collision

00:10:03,790 --> 00:10:07,450
detection all of your game logic some

00:10:05,529 --> 00:10:08,589
pretty particle systems and then you

00:10:07,450 --> 00:10:11,260
need to take all of our render a

00:10:08,589 --> 00:10:13,360
beautiful frame and if you miss the 16

00:10:11,260 --> 00:10:14,740
millisecond bolt you skip the frame your

00:10:13,360 --> 00:10:16,660
game stopped us a little bit and then

00:10:14,740 --> 00:10:19,089
thousands of hungry gamers will shout at

00:10:16,660 --> 00:10:23,290
you on Twitter so it's a real little

00:10:19,089 --> 00:10:24,519
terrifying for me how strict that is and

00:10:23,290 --> 00:10:26,500
you feel the high frequency traders

00:10:24,519 --> 00:10:29,019
you're dying of laughter right now like

00:10:26,500 --> 00:10:31,269
16 milliseconds is an unthinkable luxury

00:10:29,019 --> 00:10:32,769
if you take just one entire millisecond

00:10:31,269 --> 00:10:34,959
you're dead in the water you can't even

00:10:32,769 --> 00:10:36,519
play this game so the point I'm trying

00:10:34,959 --> 00:10:38,050
to make here is that what's fast and

00:10:36,519 --> 00:10:40,540
whoa slow it's really really very

00:10:38,050 --> 00:10:43,360
relative to what you do it some people

00:10:40,540 --> 00:10:45,370
are over here trying to get memory to be

00:10:43,360 --> 00:10:47,079
in big chunks all together so the CPU

00:10:45,370 --> 00:10:50,079
caches are full and they shave some

00:10:47,079 --> 00:10:51,760
nanoseconds where I'm overhearing

00:10:50,079 --> 00:10:54,100
milliseconds land trying to maybe not

00:10:51,760 --> 00:10:56,320
hit the database so much right like the

00:10:54,100 --> 00:10:58,449
difference in scale is so large it's

00:10:56,320 --> 00:11:00,160
insane and so this is something

00:10:58,449 --> 00:11:02,350
important to keep in mind when talking

00:11:00,160 --> 00:11:04,750
about performance some things that to me

00:11:02,350 --> 00:11:07,720
as a ruby developer are amazingly fast

00:11:04,750 --> 00:11:09,250
somebody writing drivers inside a kernel

00:11:07,720 --> 00:11:11,860
they can't even think of using them

00:11:09,250 --> 00:11:14,440
because of how slow they are for them so

00:11:11,860 --> 00:11:15,970
try to keep in mind when somebody says

00:11:14,440 --> 00:11:17,980
that something is fast or something is

00:11:15,970 --> 00:11:20,350
low nice literally mean

00:11:17,980 --> 00:11:22,060
inglis without a context but we don't

00:11:20,350 --> 00:11:23,950
think about it that way we just go with

00:11:22,060 --> 00:11:26,430
this is fast and that is low and we

00:11:23,950 --> 00:11:28,360
internalize it as if it meant something

00:11:26,430 --> 00:11:30,820
now let's go back to our original

00:11:28,360 --> 00:11:33,010
question can we do this in a microsecond

00:11:30,820 --> 00:11:35,380
well as I said I'm used to these sorts

00:11:33,010 --> 00:11:37,930
of timings right for most of my work

00:11:35,380 --> 00:11:40,180
life time exists in many second boxes I

00:11:37,930 --> 00:11:42,670
cannot care about anything smaller than

00:11:40,180 --> 00:11:44,200
this I have bigger fish to fry so if you

00:11:42,670 --> 00:11:46,930
ask me can we increment a hash in a

00:11:44,200 --> 00:11:48,610
microsecond and microsecond is not much

00:11:46,930 --> 00:11:52,150
in case you can't see that it's that

00:11:48,610 --> 00:11:52,570
tiny red door over there so I have no

00:11:52,150 --> 00:11:56,710
idea

00:11:52,570 --> 00:11:58,510
I live in milliseconds land right but we

00:11:56,710 --> 00:12:01,260
have two opposite opinions here surely

00:11:58,510 --> 00:12:04,330
at least we can figure out who was right

00:12:01,260 --> 00:12:06,790
but the interesting thing is they both

00:12:04,330 --> 00:12:08,230
kind of work let's go measure and see

00:12:06,790 --> 00:12:09,940
what we find the first problem you're

00:12:08,230 --> 00:12:12,250
gonna have is that even measuring this

00:12:09,940 --> 00:12:13,390
isn't that straightforward the normal

00:12:12,250 --> 00:12:15,910
way you would do this is with

00:12:13,390 --> 00:12:17,620
benchmarked IPs basically you give it a

00:12:15,910 --> 00:12:19,390
bunch of ways of doing the same thing it

00:12:17,620 --> 00:12:21,430
will do them repeatedly and tell you how

00:12:19,390 --> 00:12:23,380
many iterations per second it got and so

00:12:21,430 --> 00:12:24,880
you can tell which one is faster the

00:12:23,380 --> 00:12:27,580
problem is when the thing you're

00:12:24,880 --> 00:12:29,590
measuring is so tiny the measuring

00:12:27,580 --> 00:12:31,990
mechanism itself is a significant

00:12:29,590 --> 00:12:33,010
portion of your Ranta the method still

00:12:31,990 --> 00:12:34,660
works when you're comparing different

00:12:33,010 --> 00:12:36,280
things because the overhead is more or

00:12:34,660 --> 00:12:37,930
less constant so you will know which one

00:12:36,280 --> 00:12:39,580
is faster but it's not gonna help you

00:12:37,930 --> 00:12:42,820
answer the question how long does it

00:12:39,580 --> 00:12:44,380
take to do X when X is this tiny for

00:12:42,820 --> 00:12:46,270
example of what I mean if I run this in

00:12:44,380 --> 00:12:48,970
my laptop it gives me about 1/2

00:12:46,270 --> 00:12:51,730
microseconds for increment a hash which

00:12:48,970 --> 00:12:53,410
is great but it's a lie because here's

00:12:51,730 --> 00:12:55,870
the thing for each iteration I need to

00:12:53,410 --> 00:12:57,550
run a block and Cooling a block is

00:12:55,870 --> 00:12:59,080
really fast in Ruby but compared to

00:12:57,550 --> 00:13:01,510
other things like incrementing a hash

00:12:59,080 --> 00:13:03,610
it's still a significant chunk of how

00:13:01,510 --> 00:13:05,380
much time you're spending if you do this

00:13:03,610 --> 00:13:07,090
for example and not use a block now

00:13:05,380 --> 00:13:08,920
you're twice as fast which is closer to

00:13:07,090 --> 00:13:10,720
the truth and if you can want to get

00:13:08,920 --> 00:13:13,000
even faster you can remove the thing

00:13:10,720 --> 00:13:14,440
you're measuring time the loop itself so

00:13:13,000 --> 00:13:16,540
you can see how much time you're wasting

00:13:14,440 --> 00:13:18,910
subtract the two and we get something

00:13:16,540 --> 00:13:20,950
like this which is you can do this about

00:13:18,910 --> 00:13:23,490
12 times in a microsecond which is

00:13:20,950 --> 00:13:25,930
awesome this is well within a budget and

00:13:23,490 --> 00:13:28,600
that's it right I mean we have our

00:13:25,930 --> 00:13:30,280
answer first guy was correct Ruby isn't

00:13:28,600 --> 00:13:31,769
that slow you can totally do this in

00:13:30,280 --> 00:13:35,730
less than a microsecond

00:13:31,769 --> 00:13:38,890
except it's not that simple in our case

00:13:35,730 --> 00:13:40,300
if we take a step back for a second I'm

00:13:38,890 --> 00:13:43,269
talking about storing these numbers in

00:13:40,300 --> 00:13:45,610
hashes why why will you see hashes

00:13:43,269 --> 00:13:46,990
instead of integers well the reason is

00:13:45,610 --> 00:13:48,640
when you have metrics you don't want to

00:13:46,990 --> 00:13:51,940
have one number you want to have more

00:13:48,640 --> 00:13:53,470
granularity than that and so for example

00:13:51,940 --> 00:13:54,940
if you have payments you don't want to

00:13:53,470 --> 00:13:56,170
just know how many payments you took you

00:13:54,940 --> 00:13:59,110
want to know how many in each currency

00:13:56,170 --> 00:14:01,149
right so we have this concept of labels

00:13:59,110 --> 00:14:02,860
we have this key value pairs that we

00:14:01,149 --> 00:14:04,360
call labels and the way we do this

00:14:02,860 --> 00:14:06,880
internally is we store all of our

00:14:04,360 --> 00:14:10,810
numbers in hashes whose key is also a

00:14:06,880 --> 00:14:13,180
hash and the reason these matters for

00:14:10,810 --> 00:14:14,410
our performance is basically way caches

00:14:13,180 --> 00:14:16,269
work like when you're getting something

00:14:14,410 --> 00:14:18,370
from a hash you need to take your key

00:14:16,269 --> 00:14:19,630
find which pocket it folds in and then

00:14:18,370 --> 00:14:20,980
compare the key with all the other

00:14:19,630 --> 00:14:22,620
interests in this in those in that

00:14:20,980 --> 00:14:25,120
bucket until you find the one you want

00:14:22,620 --> 00:14:26,470
when your case a constant you're

00:14:25,120 --> 00:14:29,440
comparing constants with constants it's

00:14:26,470 --> 00:14:31,000
pretty fast if your key is a hash now

00:14:29,440 --> 00:14:32,050
that you found the bucket you need to

00:14:31,000 --> 00:14:34,870
compare the hash with all the other

00:14:32,050 --> 00:14:37,570
hashes which is much slower now how slow

00:14:34,870 --> 00:14:39,310
depends on how big those hashes are so

00:14:37,570 --> 00:14:41,829
for example if you have a metric with

00:14:39,310 --> 00:14:45,910
three labels that's going to be 60 times

00:14:41,829 --> 00:14:47,470
slower which is terrible for us now how

00:14:45,910 --> 00:14:49,149
about a best-case scenario now your

00:14:47,470 --> 00:14:51,760
metrics in theory most of them should

00:14:49,149 --> 00:14:54,430
have no labels so if we try and use an

00:14:51,760 --> 00:14:55,990
empty hash as a key that's a little

00:14:54,430 --> 00:14:58,329
under a microsecond which is within

00:14:55,990 --> 00:15:00,250
budget but we're getting quite close and

00:14:58,329 --> 00:15:00,940
we're just incrementing a hash here in

00:15:00,250 --> 00:15:02,649
real life

00:15:00,940 --> 00:15:04,000
we need to validate those labels we need

00:15:02,649 --> 00:15:05,410
to do some processing on them and

00:15:04,000 --> 00:15:07,390
wondering whether it's safe we put a

00:15:05,410 --> 00:15:09,339
mutex around this to make it for thread

00:15:07,390 --> 00:15:11,589
safe and now we're at about a

00:15:09,339 --> 00:15:16,029
microsecond and a half and we blew our

00:15:11,589 --> 00:15:17,350
target so turns out for our case guy

00:15:16,029 --> 00:15:19,899
number two was right in the end we

00:15:17,350 --> 00:15:22,600
cannot do this in a microsecond but what

00:15:19,899 --> 00:15:24,850
I find interesting is not really which

00:15:22,600 --> 00:15:27,100
one was right what I find interesting is

00:15:24,850 --> 00:15:28,570
that I just expected this to be an easy

00:15:27,100 --> 00:15:31,209
answer right I wonder one of these two

00:15:28,570 --> 00:15:34,690
guys to win but there's no winners

00:15:31,209 --> 00:15:35,680
reality is Moneo answer that and this is

00:15:34,690 --> 00:15:37,630
what I'm talking about what I'm saying

00:15:35,680 --> 00:15:39,399
that fast and slow are meaningless we

00:15:37,630 --> 00:15:41,430
are a context it's it's always more

00:15:39,399 --> 00:15:45,220
nuance than that when you look into it

00:15:41,430 --> 00:15:46,180
bottom line we cannot hit the target or

00:15:45,220 --> 00:15:48,340
your country's in less than a

00:15:46,180 --> 00:15:49,870
microsecond we are already past it and

00:15:48,340 --> 00:15:52,000
we're still in a single process now we

00:15:49,870 --> 00:15:53,380
can optimize this code a little bit but

00:15:52,000 --> 00:15:54,820
doing anything that's gonna solve our

00:15:53,380 --> 00:15:56,530
multi-process problem in less than a

00:15:54,820 --> 00:16:00,520
microsecond is definitely not gonna

00:15:56,530 --> 00:16:02,110
happen but we decided to not throw the

00:16:00,520 --> 00:16:05,320
baby out with the bathwater right like

00:16:02,110 --> 00:16:07,000
we can't hit a target but we can try and

00:16:05,320 --> 00:16:09,070
follow the spirit of it which is the

00:16:07,000 --> 00:16:10,720
instrumentation should be free so we

00:16:09,070 --> 00:16:12,940
want to make this as fast as humanly

00:16:10,720 --> 00:16:14,380
possible and because this is going to

00:16:12,940 --> 00:16:16,180
impact lots of projects for lots of

00:16:14,380 --> 00:16:18,250
companies it's actually really worth

00:16:16,180 --> 00:16:19,720
investing a lot of time in making this

00:16:18,250 --> 00:16:23,410
as fast as we can even if you can hit

00:16:19,720 --> 00:16:25,780
the microsecond now at this point we

00:16:23,410 --> 00:16:28,090
have a basic baseline of times we have a

00:16:25,780 --> 00:16:31,300
beautifully refactor code base that lets

00:16:28,090 --> 00:16:33,130
me experiment very quickly so how do we

00:16:31,300 --> 00:16:35,080
solve this problem well we experiment a

00:16:33,130 --> 00:16:36,130
lot I mean we have made it really cheap

00:16:35,080 --> 00:16:37,900
for ourselves to try different

00:16:36,130 --> 00:16:39,160
strategies so we started trying pretty

00:16:37,900 --> 00:16:41,260
much everything we could think of and

00:16:39,160 --> 00:16:44,710
I'd like to walk you through four of

00:16:41,260 --> 00:16:46,570
these experiments that we did first up

00:16:44,710 --> 00:16:48,850
let's make this real easy for ourselves

00:16:46,570 --> 00:16:51,310
buuck has this really unusual data

00:16:48,850 --> 00:16:54,040
structure called AP store basically it's

00:16:51,310 --> 00:16:55,870
a hash backed by a file on disk every

00:16:54,040 --> 00:16:57,310
time you write a value to this hash the

00:16:55,870 --> 00:16:57,700
whole thing gets serialize then put into

00:16:57,310 --> 00:17:00,190
a file

00:16:57,700 --> 00:17:01,390
every time you read a value the file

00:17:00,190 --> 00:17:04,000
gets read again and you get that value

00:17:01,390 --> 00:17:05,410
and there's a look around that file so

00:17:04,000 --> 00:17:07,180
you can actually do this from multiple

00:17:05,410 --> 00:17:08,920
processes at the same time all competing

00:17:07,180 --> 00:17:13,300
for the same file everybody sees the

00:17:08,920 --> 00:17:15,430
latest data and it's safe now pistols

00:17:13,300 --> 00:17:17,199
are used almost exactly like a hash they

00:17:15,430 --> 00:17:19,060
have this idea of transactions which

00:17:17,199 --> 00:17:20,770
basically allows you to set several

00:17:19,060 --> 00:17:22,839
values all at once without having to hit

00:17:20,770 --> 00:17:24,670
the disk for each one and you basically

00:17:22,839 --> 00:17:27,130
just wrap your accesses in one of those

00:17:24,670 --> 00:17:29,620
and you're done and if you think about

00:17:27,130 --> 00:17:31,690
it this is exactly what we need right I

00:17:29,620 --> 00:17:32,050
mean we have this global hash shared by

00:17:31,690 --> 00:17:34,900
everyone

00:17:32,050 --> 00:17:37,420
all processes see all of the data we're

00:17:34,900 --> 00:17:41,950
done the only extra requirement we had

00:17:37,420 --> 00:17:43,660
is is it fast and P stores are no very

00:17:41,950 --> 00:17:48,970
fast this is this is not gonna work for

00:17:43,660 --> 00:17:51,000
us but this thing one step back what are

00:17:48,970 --> 00:17:53,140
we trying to do here well basically

00:17:51,000 --> 00:17:54,730
we're trying to have a chunk of memory

00:17:53,140 --> 00:17:58,590
that is shared between all the different

00:17:54,730 --> 00:17:59,850
processes right as a complete aside

00:17:58,590 --> 00:18:01,470
one of the great things of working at my

00:17:59,850 --> 00:18:02,370
company is the amazing people and

00:18:01,470 --> 00:18:04,440
surround equipment

00:18:02,370 --> 00:18:08,909
now granted some of those people are

00:18:04,440 --> 00:18:12,450
trolls but the trolls sometimes have

00:18:08,909 --> 00:18:14,190
good ideas I mean secret life was

00:18:12,450 --> 00:18:15,990
probably not gonna be the best way to do

00:18:14,190 --> 00:18:17,730
this but he got me thinking you know

00:18:15,990 --> 00:18:20,370
it's a great way of having a chunk of

00:18:17,730 --> 00:18:21,870
memory shared between processes I mean

00:18:20,370 --> 00:18:23,600
it's my favorite tune in the whole wide

00:18:21,870 --> 00:18:26,279
world it's my good old friend red is

00:18:23,600 --> 00:18:28,260
real this is basically a chunk of memory

00:18:26,279 --> 00:18:30,659
running in a process outside your app

00:18:28,260 --> 00:18:32,490
all of your worker processes can read

00:18:30,659 --> 00:18:34,950
and write from it and we all know it's

00:18:32,490 --> 00:18:36,179
super fast right so this sounds perfect

00:18:34,950 --> 00:18:36,720
this sounds exactly like we need like

00:18:36,179 --> 00:18:38,909
what we need

00:18:36,720 --> 00:18:41,669
I'm actually the Prometheus library for

00:18:38,909 --> 00:18:44,669
PHP uses readies for exactly the same

00:18:41,669 --> 00:18:46,350
reason so that was promising so everyone

00:18:44,669 --> 00:18:48,059
Apple you store the user Asus back-end I

00:18:46,350 --> 00:18:50,580
was super excited because I knew this

00:18:48,059 --> 00:18:55,470
was gonna be the solution I fired on by

00:18:50,580 --> 00:18:58,620
benchmarks and it's it was very

00:18:55,470 --> 00:19:01,799
disappointing it's it's actually slower

00:18:58,620 --> 00:19:05,460
than marshaling an entire hash into disk

00:19:01,799 --> 00:19:07,169
every time I was really sad when this

00:19:05,460 --> 00:19:11,610
happened because I really thought I had

00:19:07,169 --> 00:19:13,470
it but mainly how how can it be this low

00:19:11,610 --> 00:19:16,649
I mean isn't really supposed to be super

00:19:13,470 --> 00:19:17,940
fast now if you stop and think about it

00:19:16,649 --> 00:19:19,190
for a second it kind of makes sense like

00:19:17,940 --> 00:19:21,659
you took to Reddit over the network

00:19:19,190 --> 00:19:23,070
granted is localhost but still every

00:19:21,659 --> 00:19:24,480
time you talk to it you need to make a

00:19:23,070 --> 00:19:26,309
packet put into a socket send it over

00:19:24,480 --> 00:19:27,630
already states that opens it up parses

00:19:26,309 --> 00:19:29,700
your command runs it makes a response

00:19:27,630 --> 00:19:32,760
packets okay did this a lot going on

00:19:29,700 --> 00:19:35,549
right right this is really fast for a

00:19:32,760 --> 00:19:37,110
database it normally lives in its own

00:19:35,549 --> 00:19:39,750
server you talk to it over the network

00:19:37,110 --> 00:19:41,669
and those 60 microseconds we just saw

00:19:39,750 --> 00:19:44,820
that basically nothing compared to the

00:19:41,669 --> 00:19:47,250
network round-trip so it's really fast

00:19:44,820 --> 00:19:49,260
compared to other databases are in the

00:19:47,250 --> 00:19:51,179
network but compared to something is

00:19:49,260 --> 00:19:53,909
happening in your own machine in your

00:19:51,179 --> 00:19:58,140
own process like writing a tiny file you

00:19:53,909 --> 00:20:01,110
never had a chance really so so I keep

00:19:58,140 --> 00:20:06,390
saying fast and slow without context or

00:20:01,110 --> 00:20:08,130
meaningless now at this point I had no

00:20:06,390 --> 00:20:10,409
choice but to face the giant elephant in

00:20:08,130 --> 00:20:12,370
the room the consensus from pretty much

00:20:10,409 --> 00:20:14,020
everyone on how to solve the

00:20:12,370 --> 00:20:16,750
multi-process issue was that we should

00:20:14,020 --> 00:20:18,450
use memory maps for this this is for

00:20:16,750 --> 00:20:20,620
example with the Python library does but

00:20:18,450 --> 00:20:22,809
through our oldest project I was trying

00:20:20,620 --> 00:20:24,790
really hard to avoid them I really

00:20:22,809 --> 00:20:27,010
wanted to find a different answer and if

00:20:24,790 --> 00:20:28,930
I'm being honest the reason I was

00:20:27,010 --> 00:20:31,120
avoiding them is that I was basically

00:20:28,930 --> 00:20:32,890
afraid of them like I didn't know what a

00:20:31,120 --> 00:20:35,050
memory map was before this project I

00:20:32,890 --> 00:20:37,270
hadn't even heard of him I didn't know

00:20:35,050 --> 00:20:38,830
how to use them if you try to read up on

00:20:37,270 --> 00:20:41,770
them it's not really clear what they are

00:20:38,830 --> 00:20:43,210
what they're for how you use them the

00:20:41,770 --> 00:20:45,280
rest thing you have is this the camel

00:20:43,210 --> 00:20:47,530
documents and they're super useful in

00:20:45,280 --> 00:20:49,960
the description of the details of how

00:20:47,530 --> 00:20:52,000
each flag works but if you don't know

00:20:49,960 --> 00:20:54,610
what this thing even is this is not a

00:20:52,000 --> 00:20:56,110
very good primer and I also saw some

00:20:54,610 --> 00:20:58,240
code examples that left me even more

00:20:56,110 --> 00:21:00,490
confused like it looked like the way to

00:20:58,240 --> 00:21:04,860
get this shared chunk of memory was a

00:21:00,490 --> 00:21:09,790
file path in /tmp I mean that makes no

00:21:04,860 --> 00:21:12,040
no use files right now just how the

00:21:09,790 --> 00:21:13,990
reason also confused is that it maps are

00:21:12,040 --> 00:21:16,720
one of the most basic fundamental

00:21:13,990 --> 00:21:18,490
building blocks of the kernel this is

00:21:16,720 --> 00:21:20,650
not a thing to share memory between

00:21:18,490 --> 00:21:23,170
processes this is a massive Swiss Army

00:21:20,650 --> 00:21:25,390
knife that you used to do all sorts of

00:21:23,170 --> 00:21:26,650
basic memory stuff and the problem with

00:21:25,390 --> 00:21:28,660
the docs is that they have really good

00:21:26,650 --> 00:21:29,679
descriptions of each of the tools but

00:21:28,660 --> 00:21:32,500
there's nothing that's going to give you

00:21:29,679 --> 00:21:34,360
the big picture but it is out there is

00:21:32,500 --> 00:21:36,840
one of these tools that is what we want

00:21:34,360 --> 00:21:38,800
is the shared memory mapped file

00:21:36,840 --> 00:21:41,200
basically the way this works is a

00:21:38,800 --> 00:21:43,360
process opens a file and it maps it to

00:21:41,200 --> 00:21:45,220
some place in memory if you read that

00:21:43,360 --> 00:21:46,660
page in memory you get the contents of a

00:21:45,220 --> 00:21:50,290
file if you write to a page in memory

00:21:46,660 --> 00:21:51,730
the file magically gets updated at some

00:21:50,290 --> 00:21:54,160
point later whenever the camera feels

00:21:51,730 --> 00:21:56,830
like it but here comes the magic if a

00:21:54,160 --> 00:21:59,230
second process Maps the same file saying

00:21:56,830 --> 00:22:00,850
that it wants to share it both processes

00:21:59,230 --> 00:22:03,490
get assigned the same exact page in

00:22:00,850 --> 00:22:05,320
memory so if one of these processes

00:22:03,490 --> 00:22:07,300
writes for a page in memory the file

00:22:05,320 --> 00:22:08,710
eventually gets updated but you don't

00:22:07,300 --> 00:22:11,679
care about that we're talking about that

00:22:08,710 --> 00:22:13,270
about is that the other process can now

00:22:11,679 --> 00:22:17,260
read that page in memory and immediately

00:22:13,270 --> 00:22:18,280
get the new data which is magic and the

00:22:17,260 --> 00:22:20,440
other thing you care about is that

00:22:18,280 --> 00:22:22,210
there's a file but you're not really

00:22:20,440 --> 00:22:24,100
writing directly to it you're writing to

00:22:22,210 --> 00:22:26,060
memory which is as fast as writing to

00:22:24,100 --> 00:22:28,670
memory instead of being a slowest

00:22:26,060 --> 00:22:31,250
and this is actually famously one of the

00:22:28,670 --> 00:22:33,530
fastest ways to do inter process

00:22:31,250 --> 00:22:37,460
communication so I can see why everyone

00:22:33,530 --> 00:22:39,530
was suggesting to use this now a small

00:22:37,460 --> 00:22:42,020
slight problem in map

00:22:39,530 --> 00:22:45,170
it's a Cisco do you all know how you

00:22:42,020 --> 00:22:47,450
call a Cisco from Ruby you don't you do

00:22:45,170 --> 00:22:49,970
it from C now granted this this thing

00:22:47,450 --> 00:22:55,010
which has the most hilarious line I've

00:22:49,970 --> 00:22:56,990
ever seen in official documentation it's

00:22:55,010 --> 00:22:58,640
not particularly useful for this and

00:22:56,990 --> 00:23:01,100
also let's say you manage to actually

00:22:58,640 --> 00:23:03,050
call a map with this now you have a

00:23:01,100 --> 00:23:05,690
chunk of raw memory that is yours and a

00:23:03,050 --> 00:23:06,920
row pointed to it now what how you're

00:23:05,690 --> 00:23:09,470
gonna read and write that from Ruby

00:23:06,920 --> 00:23:11,240
right so we're gonna need some sort of

00:23:09,470 --> 00:23:14,930
wrapper to use this and it has to be

00:23:11,240 --> 00:23:19,010
written in C or something similar and I

00:23:14,930 --> 00:23:20,480
don't write C I can barely read it and I

00:23:19,010 --> 00:23:22,940
should certainly know be trusted to

00:23:20,480 --> 00:23:24,950
write some C code that's dealing with a

00:23:22,940 --> 00:23:26,990
Cisco that I don't understand and it's

00:23:24,950 --> 00:23:28,370
doing some magic memory voodoo that

00:23:26,990 --> 00:23:29,750
we're running production early in my

00:23:28,370 --> 00:23:31,610
company when a bunch of holiday

00:23:29,750 --> 00:23:35,330
companies this is not going to happen

00:23:31,610 --> 00:23:37,460
right but fortunately we have this gem

00:23:35,330 --> 00:23:39,590
which was originally made by a gentleman

00:23:37,460 --> 00:23:41,120
called give a coup but if you look at

00:23:39,590 --> 00:23:43,880
the repo these days you're gonna see a

00:23:41,120 --> 00:23:49,700
load of this face now that

00:23:43,880 --> 00:23:52,040
that is a face I trust like this guy

00:23:49,700 --> 00:23:53,990
knows C and he's normally found doing

00:23:52,040 --> 00:23:56,750
magic memory voodoo this is definitely

00:23:53,990 --> 00:23:58,790
good news now in case you will recognize

00:23:56,750 --> 00:24:01,040
that it's our own pattern so he goes on

00:23:58,790 --> 00:24:03,290
the internet by tender love and he's one

00:24:01,040 --> 00:24:04,670
of the main one of the coal room ain't a

00:24:03,290 --> 00:24:05,660
nurse and you should what she stopped

00:24:04,670 --> 00:24:07,970
tomorrow because it's very really

00:24:05,660 --> 00:24:11,180
interesting but going back to arcades

00:24:07,970 --> 00:24:13,940
how do we end up with this thing well

00:24:11,180 --> 00:24:16,070
you basically make a file you initialize

00:24:13,940 --> 00:24:18,830
it to a certain size say one megabyte

00:24:16,070 --> 00:24:21,860
and then you init this M map thing and I

00:24:18,830 --> 00:24:24,580
have this M variable which behaves sort

00:24:21,860 --> 00:24:27,560
of kind of like a byte array so

00:24:24,580 --> 00:24:30,470
importantly it is not a ruby array the

00:24:27,560 --> 00:24:32,300
emmab gem is doing a bunch of magic to

00:24:30,470 --> 00:24:35,060
map between the actual memory and things

00:24:32,300 --> 00:24:36,710
that look like ruby but it does behave

00:24:35,060 --> 00:24:38,870
like an array so you can just pretend

00:24:36,710 --> 00:24:39,980
this one and if you have a bunch of

00:24:38,870 --> 00:24:41,690
bytes to write

00:24:39,980 --> 00:24:45,230
you just set a range on the array and

00:24:41,690 --> 00:24:46,850
I'll do it now the tricky bit is telling

00:24:45,230 --> 00:24:49,010
the stuff you want to ride in two bytes

00:24:46,850 --> 00:24:50,600
and to do that you have these methods

00:24:49,010 --> 00:24:52,940
called pack and unpack which will turn

00:24:50,600 --> 00:24:55,910
your Ruby stuff into bytes and then back

00:24:52,940 --> 00:24:58,550
into Ruby stuff again now if you've

00:24:55,910 --> 00:25:00,200
never heard of pack and unpack don't

00:24:58,550 --> 00:25:01,910
don't look them up just keep that

00:25:00,200 --> 00:25:06,740
innocence it's really nice to not have

00:25:01,910 --> 00:25:08,810
to know about this but in our case we

00:25:06,740 --> 00:25:11,120
had to and so we have a float and we

00:25:08,810 --> 00:25:14,420
want to write it into this M thing so we

00:25:11,120 --> 00:25:16,250
pack it into eight bytes which is a

00:25:14,420 --> 00:25:17,660
bigger flow rate and then we set those

00:25:16,250 --> 00:25:20,630
positions in the array and we're done

00:25:17,660 --> 00:25:21,710
which is amazing and like for all the

00:25:20,630 --> 00:25:23,450
other stores we need to figure out

00:25:21,710 --> 00:25:26,810
whether this is going to be fast enough

00:25:23,450 --> 00:25:28,430
right now to recap a little bit what we

00:25:26,810 --> 00:25:29,960
had so far we had a hash with no

00:25:28,430 --> 00:25:32,120
synchronization which ended up being a

00:25:29,960 --> 00:25:33,530
little under a microsecond we have the

00:25:32,120 --> 00:25:35,060
same thing but we look around it for

00:25:33,530 --> 00:25:36,710
multi-threaded applications which is

00:25:35,060 --> 00:25:39,170
about a microsecond a half and we have

00:25:36,710 --> 00:25:40,640
the only reasonable solution so far for

00:25:39,170 --> 00:25:42,530
the multi process problem which is the P

00:25:40,640 --> 00:25:45,620
store which is a terrible 35

00:25:42,530 --> 00:25:48,680
microseconds in maps which I really

00:25:45,620 --> 00:25:52,910
really don't want to use actually quite

00:25:48,680 --> 00:25:57,260
fast which I'm gonna have to use these

00:25:52,910 --> 00:25:59,870
and at the point again it looks like

00:25:57,260 --> 00:26:02,000
with that right and I thought that too

00:25:59,870 --> 00:26:04,430
but in addition to having a script that

00:26:02,000 --> 00:26:06,980
benchmarks these things and times them I

00:26:04,430 --> 00:26:09,470
have another script to stress tested

00:26:06,980 --> 00:26:11,090
basically this script will do terrible

00:26:09,470 --> 00:26:12,260
things to these stores just just to make

00:26:11,090 --> 00:26:13,850
sure that we're safe you'll have a

00:26:12,260 --> 00:26:15,020
ridiculously large number of metrics

00:26:13,850 --> 00:26:16,580
which ridiculously large number of

00:26:15,020 --> 00:26:18,410
labels and you'll be hitting it from

00:26:16,580 --> 00:26:19,520
many threads and many processes all at

00:26:18,410 --> 00:26:21,380
the same time competing for the same

00:26:19,520 --> 00:26:23,840
file you know just hammering it to make

00:26:21,380 --> 00:26:28,010
sure it's solid and as soon as I run the

00:26:23,840 --> 00:26:29,360
script on the end map store now raise

00:26:28,010 --> 00:26:32,600
your hand if you've ever seen one of

00:26:29,360 --> 00:26:34,700
these in Ruby that was your fault right

00:26:32,600 --> 00:26:37,460
I have two hands and one is actually

00:26:34,700 --> 00:26:38,990
turned along like that's the point

00:26:37,460 --> 00:26:40,910
you're not supposed to see one of these

00:26:38,990 --> 00:26:43,010
this is the famous seg fault or

00:26:40,910 --> 00:26:45,020
segmentation fault or I think

00:26:43,010 --> 00:26:47,210
technically is the scarier little sister

00:26:45,020 --> 00:26:48,620
which is the sake bus but it's basically

00:26:47,210 --> 00:26:52,060
the kernel telling you you've messed up

00:26:48,620 --> 00:26:53,330
real bad and I don't know about you but

00:26:52,060 --> 00:26:55,370
what my

00:26:53,330 --> 00:26:57,380
favorite thing about how high-level

00:26:55,370 --> 00:26:59,840
languages is that I don't have to deal

00:26:57,380 --> 00:27:00,920
with this like I don't I don't have to

00:26:59,840 --> 00:27:02,300
deal with this I don't know how to do

00:27:00,920 --> 00:27:04,760
with this I don't know where to start

00:27:02,300 --> 00:27:06,040
this is precisely why on the C so I

00:27:04,760 --> 00:27:08,840
don't have to think about these things

00:27:06,040 --> 00:27:10,670
but I asked around and apparently this

00:27:08,840 --> 00:27:12,230
looks like garbage collector related

00:27:10,670 --> 00:27:14,090
like something was freed and then he got

00:27:12,230 --> 00:27:18,470
cleaned up and then I was still using it

00:27:14,090 --> 00:27:21,110
and the ball is what do I do with that

00:27:18,470 --> 00:27:22,730
as far as I knew I wasn't freeing or not

00:27:21,110 --> 00:27:24,410
free in anything I was just using this

00:27:22,730 --> 00:27:26,240
gem that gives you this thing that looks

00:27:24,410 --> 00:27:29,720
like an array I'm gonna have a sec Fault

00:27:26,240 --> 00:27:31,760
in my face and this is precisely why I

00:27:29,720 --> 00:27:33,500
was trying to avoid the memory map right

00:27:31,760 --> 00:27:38,600
I was worried about this exact thing

00:27:33,500 --> 00:27:39,980
happening and now it happens and given

00:27:38,600 --> 00:27:42,080
that this was a gem written by

00:27:39,980 --> 00:27:44,210
tenderlove and I was being used by me

00:27:42,080 --> 00:27:45,890
this was most likely not about in the

00:27:44,210 --> 00:27:49,100
gym I was almost certainly using it

00:27:45,890 --> 00:27:50,810
wrong but this is a fairly obscure gem

00:27:49,100 --> 00:27:53,150
there's not that many people trying to

00:27:50,810 --> 00:27:55,010
do em maps in Ruby there's nothing about

00:27:53,150 --> 00:27:57,380
in Stack Overflow I haven't found anyone

00:27:55,010 --> 00:28:00,340
actually using it so it's kind of hard

00:27:57,380 --> 00:28:02,960
to figure out what I'm doing wrong now

00:28:00,340 --> 00:28:05,420
experimenting randomly I basically

00:28:02,960 --> 00:28:08,030
figured out that this was related to

00:28:05,420 --> 00:28:10,640
some code that I have to resize their

00:28:08,030 --> 00:28:14,090
Maps if that initial one megabyte wasn't

00:28:10,640 --> 00:28:16,880
enough so if that code run afterwards I

00:28:14,090 --> 00:28:19,130
would get a second but not immediately a

00:28:16,880 --> 00:28:22,130
while later which kind of points to a

00:28:19,130 --> 00:28:24,560
garbage collector right so that's great

00:28:22,130 --> 00:28:26,680
we have no idea why this happens but at

00:28:24,560 --> 00:28:29,630
least I can reproduce it reliably and

00:28:26,680 --> 00:28:30,920
like always with these problems if you

00:28:29,630 --> 00:28:33,530
want to solve it you basically try

00:28:30,920 --> 00:28:35,030
random stuff until something sticks now

00:28:33,530 --> 00:28:36,860
it took a while because I had no idea

00:28:35,030 --> 00:28:38,510
what I was doing but I actually made the

00:28:36,860 --> 00:28:40,130
SEC full stop it was this elaborate

00:28:38,510 --> 00:28:40,430
dance of flashing the file closing the

00:28:40,130 --> 00:28:41,810
file

00:28:40,430 --> 00:28:42,830
reopening it just to resize it and

00:28:41,810 --> 00:28:48,530
posting it again then open it again a

00:28:42,830 --> 00:28:51,110
mapping again and a sec host stop now if

00:28:48,530 --> 00:28:53,480
you have a problem you don't understand

00:28:51,110 --> 00:28:54,890
the problem you try random stuff until

00:28:53,480 --> 00:28:56,810
the problem doesn't happen anymore but

00:28:54,890 --> 00:28:59,930
you don't know why was happening or why

00:28:56,810 --> 00:29:01,010
it stopped how confident are you that

00:28:59,930 --> 00:29:03,320
that's not gonna happen again in

00:29:01,010 --> 00:29:04,880
production in some random server and

00:29:03,320 --> 00:29:06,710
some random company's mission-critical

00:29:04,880 --> 00:29:09,620
app right I

00:29:06,710 --> 00:29:11,779
I really wasn't I did not like this one

00:29:09,620 --> 00:29:13,730
bit and in addition to that there are

00:29:11,779 --> 00:29:15,919
other downsides of using this nmap gem

00:29:13,730 --> 00:29:17,659
because it's a see extension dependency

00:29:15,919 --> 00:29:20,659
these are the ones that get compiled

00:29:17,659 --> 00:29:22,159
when you stole the gem they for example

00:29:20,659 --> 00:29:24,289
they don't work on JRuby at least not

00:29:22,159 --> 00:29:26,390
directly and we do want to support JRuby

00:29:24,289 --> 00:29:27,980
and they're also tricky like most of you

00:29:26,390 --> 00:29:29,510
probably had trouble installing nokogiri

00:29:27,980 --> 00:29:32,899
at some point in your life right like

00:29:29,510 --> 00:29:35,090
see extensions can be a pain but most

00:29:32,899 --> 00:29:39,169
importantly it may be kind of sec

00:29:35,090 --> 00:29:42,549
faulted which is like no ideal so it was

00:29:39,169 --> 00:29:44,630
fast but we wanted to keep looking and

00:29:42,549 --> 00:29:46,760
of all the interesting things we found

00:29:44,630 --> 00:29:49,220
in this project this last experiment was

00:29:46,760 --> 00:29:51,399
by far the most surprising with the

00:29:49,220 --> 00:29:54,140
memory maps we were working with a file

00:29:51,399 --> 00:29:56,299
doing the kind of things that you do

00:29:54,140 --> 00:29:58,870
with a file we were just doing it in

00:29:56,299 --> 00:30:01,010
memory which is faster than normal files

00:29:58,870 --> 00:30:04,909
but what happens if we ditch the air

00:30:01,010 --> 00:30:06,289
maps and we just do this to a file from

00:30:04,909 --> 00:30:07,610
the code perspective pretty much the

00:30:06,289 --> 00:30:09,380
only difference is instead of setting a

00:30:07,610 --> 00:30:12,529
range in a thing that's pretending to be

00:30:09,380 --> 00:30:14,809
an array you just call it a couple of

00:30:12,529 --> 00:30:17,210
the file functions to jump around and to

00:30:14,809 --> 00:30:19,130
write an interesting various you're

00:30:17,210 --> 00:30:21,380
doing the minimum around possible you're

00:30:19,130 --> 00:30:23,450
not marshal dumping an entire hash into

00:30:21,380 --> 00:30:25,640
a file you're just doing one jump and

00:30:23,450 --> 00:30:28,279
then writing eight bytes it's pretty

00:30:25,640 --> 00:30:30,289
efficient that's pretty much the whole

00:30:28,279 --> 00:30:32,179
change I mean we have no air maps we

00:30:30,289 --> 00:30:33,919
have no see we have no sexual there's

00:30:32,179 --> 00:30:36,740
nothing fancy it's just plain old boring

00:30:33,919 --> 00:30:40,789
Ruby running bytes to plain old boring

00:30:36,740 --> 00:30:42,230
files and slow hard ways but as usual

00:30:40,789 --> 00:30:44,870
with these solutions we need to be fast

00:30:42,230 --> 00:30:47,330
than this I mean how slow was going pace

00:30:44,870 --> 00:30:50,000
going to be right and before I tell you

00:30:47,330 --> 00:30:52,960
I want you to visualize how slow disks

00:30:50,000 --> 00:30:55,190
are I mean we use Redis and memcache the

00:30:52,960 --> 00:30:56,990
famously because they're in RAM and not

00:30:55,190 --> 00:30:58,970
on disk right we used run drives in

00:30:56,990 --> 00:31:00,169
temper phase so we can work with

00:30:58,970 --> 00:31:02,149
something that looks like files but not

00:31:00,169 --> 00:31:05,179
how to use the disk because there's low

00:31:02,149 --> 00:31:07,159
we give our databases can do enormous

00:31:05,179 --> 00:31:08,600
amounts of ram so you can keep

00:31:07,159 --> 00:31:11,750
everything there and know how to touch

00:31:08,600 --> 00:31:13,399
the disks because they're so slow so how

00:31:11,750 --> 00:31:15,260
slow was this solution based on disks

00:31:13,399 --> 00:31:18,740
well if you remember the EM maps were

00:31:15,260 --> 00:31:20,190
about six microseconds files on actual

00:31:18,740 --> 00:31:23,470
hard drive

00:31:20,190 --> 00:31:25,480
ix I mean considering how slow I

00:31:23,470 --> 00:31:27,370
expected this to be this completely blew

00:31:25,480 --> 00:31:30,460
my mind if you compare this to memory

00:31:27,370 --> 00:31:31,440
maps we have no external dependencies no

00:31:30,460 --> 00:31:34,510
risky C code

00:31:31,440 --> 00:31:36,250
definitely no seg faults it's compatible

00:31:34,510 --> 00:31:39,940
with all editions of Ruby like Jade will

00:31:36,250 --> 00:31:41,620
be it's 100% understandable by any Ruby

00:31:39,940 --> 00:31:43,180
wherever and most importantly there's

00:31:41,620 --> 00:31:46,870
nothing in that code that keeps me up at

00:31:43,180 --> 00:31:48,640
night all of this which is three extra

00:31:46,870 --> 00:31:50,770
microseconds this was a complete

00:31:48,640 --> 00:31:53,770
no-brainer and that's pretty much it I

00:31:50,770 --> 00:31:55,750
mean we ended up picking discs as our in

00:31:53,770 --> 00:31:58,240
solution because he was fast enough and

00:31:55,750 --> 00:32:00,490
we think of this trade-off is more than

00:31:58,240 --> 00:32:04,300
worth it for the peace of mind that the

00:32:00,490 --> 00:32:07,450
dissolution brings us and this this is

00:32:04,300 --> 00:32:09,010
what this talk should end I mean we saw

00:32:07,450 --> 00:32:10,000
the problem with a fast elegant solution

00:32:09,010 --> 00:32:11,620
we got our code merged

00:32:10,000 --> 00:32:13,660
well now maintenance of the gem which is

00:32:11,620 --> 00:32:18,070
pretty nice and now people can use

00:32:13,660 --> 00:32:21,100
prometheus in Ruby right happy times but

00:32:18,070 --> 00:32:24,550
this this is a funny result isn't it I

00:32:21,100 --> 00:32:26,530
mean memory is supposed to be orders of

00:32:24,550 --> 00:32:28,750
magnitude faster than these thousands of

00:32:26,530 --> 00:32:32,100
times faster and I'm telling you is like

00:32:28,750 --> 00:32:35,020
what 30% faster and what's going on here

00:32:32,100 --> 00:32:36,250
well as I've been saying it's always

00:32:35,020 --> 00:32:37,600
more new yours than that

00:32:36,250 --> 00:32:39,640
now first of all writing to memory

00:32:37,600 --> 00:32:42,220
should take nanoseconds no microseconds

00:32:39,640 --> 00:32:44,320
and what's happening there is that the

00:32:42,220 --> 00:32:46,060
thing I have is not an actual array be a

00:32:44,320 --> 00:32:47,500
map gem is actually doing a bunch of

00:32:46,060 --> 00:32:48,640
magic to map from one thing to the other

00:32:47,500 --> 00:32:51,190
and it has to synchronize between

00:32:48,640 --> 00:32:53,680
processes it takes a while but more

00:32:51,190 --> 00:32:55,060
importantly if you are at all used to

00:32:53,680 --> 00:32:57,340
performance numbers you've only

00:32:55,060 --> 00:32:58,570
important hard drives you're probably

00:32:57,340 --> 00:33:02,790
looking at this number with a lot of

00:32:58,570 --> 00:33:05,110
suspicion right now you'd be right

00:33:02,790 --> 00:33:06,760
because what's happening here is that

00:33:05,110 --> 00:33:09,040
I'm basically cheating

00:33:06,760 --> 00:33:12,400
it's a fetch it it works for my use case

00:33:09,040 --> 00:33:17,200
but I'm still cheating you see actually

00:33:12,400 --> 00:33:18,460
putting stuff on a disk is slow but this

00:33:17,200 --> 00:33:20,230
is not what happens when you're a prize

00:33:18,460 --> 00:33:22,330
to disk at least not on a modern

00:33:20,230 --> 00:33:24,070
operating system when you tell the OS

00:33:22,330 --> 00:33:25,990
that you want to write to disk the u.s.

00:33:24,070 --> 00:33:27,340
takes note of that and I'm saying yeah

00:33:25,990 --> 00:33:29,410
all right I'll get around to that at

00:33:27,340 --> 00:33:31,480
some point but it doesn't actually write

00:33:29,410 --> 00:33:33,790
to this right they're like do it later

00:33:31,480 --> 00:33:35,800
at leisure whenever it's

00:33:33,790 --> 00:33:37,450
and normally this is a problem for you

00:33:35,800 --> 00:33:39,730
if you're a database and somebody sends

00:33:37,450 --> 00:33:41,590
you data would you trust this dude to

00:33:39,730 --> 00:33:43,180
actually do it later I mean of course

00:33:41,590 --> 00:33:45,190
not because when somebody trips on your

00:33:43,180 --> 00:33:47,680
power cable and the OS haven't finished

00:33:45,190 --> 00:33:49,450
chilling you lost data which the

00:33:47,680 --> 00:33:52,480
database world is generally known as you

00:33:49,450 --> 00:33:54,070
know good so you have to have sync which

00:33:52,480 --> 00:33:55,690
is literally telling like hey those

00:33:54,070 --> 00:33:58,210
things I told you to do do it now oh

00:33:55,690 --> 00:34:01,030
wait and that is low because you

00:33:58,210 --> 00:34:04,450
actually write into the disk if your

00:34:01,030 --> 00:34:06,040
database sadly you're gonna have to pay

00:34:04,450 --> 00:34:07,830
that price because you really care about

00:34:06,040 --> 00:34:11,080
your date that data that you're writing

00:34:07,830 --> 00:34:13,480
but I'm just storing metrics for this

00:34:11,080 --> 00:34:16,000
particular run of my app if my app gets

00:34:13,480 --> 00:34:17,980
killed yeah I mean probably few says the

00:34:16,000 --> 00:34:20,470
number so far next run of my app I'm

00:34:17,980 --> 00:34:21,940
starting fresh from zero I don't care if

00:34:20,470 --> 00:34:24,310
that data stays I only care about this

00:34:21,940 --> 00:34:25,660
data while my app is running so that the

00:34:24,310 --> 00:34:27,400
processes can see each other's numbers

00:34:25,660 --> 00:34:29,710
but once I'm dead I'm dead

00:34:27,400 --> 00:34:31,600
whatever I'm starting over anyway which

00:34:29,710 --> 00:34:34,030
means I don't have to wait for the data

00:34:31,600 --> 00:34:36,760
to actually get committed to disk and

00:34:34,030 --> 00:34:39,220
now it's not slow anymore because when

00:34:36,760 --> 00:34:40,570
I'm writing to disk I'm really just

00:34:39,220 --> 00:34:42,040
writing to that bit of memory where the

00:34:40,570 --> 00:34:45,000
OS makes a list of the things that is

00:34:42,040 --> 00:34:47,260
going to write to disk which is cheating

00:34:45,000 --> 00:34:49,570
but it doesn't mean you can do it it

00:34:47,260 --> 00:34:51,160
just means I have this very unusual use

00:34:49,570 --> 00:34:53,680
case where I can get away with

00:34:51,160 --> 00:34:57,690
pretending to use disks without actually

00:34:53,680 --> 00:34:57,690
having to pay the price for doing it so

00:34:58,110 --> 00:35:06,300
it's memory fast a disk slow well as

00:35:02,980 --> 00:35:10,600
I've been saying depends on the context

00:35:06,300 --> 00:35:12,820
so we've covered a lot of weirdly

00:35:10,600 --> 00:35:14,920
specific ground all over the place right

00:35:12,820 --> 00:35:18,550
now but what is the point of me being

00:35:14,920 --> 00:35:20,470
here what am I trying to say does this

00:35:18,550 --> 00:35:21,820
age-old saying when it comes to

00:35:20,470 --> 00:35:24,400
performance optimization you've probably

00:35:21,820 --> 00:35:26,020
heard it measure before you optimize

00:35:24,400 --> 00:35:27,520
because the thing that you think is low

00:35:26,020 --> 00:35:30,580
is probably not the thing that is

00:35:27,520 --> 00:35:32,890
actually slow and we'll notice know this

00:35:30,580 --> 00:35:34,120
and when I was trying to figure out

00:35:32,890 --> 00:35:35,230
where my code was spending time I

00:35:34,120 --> 00:35:36,850
definitely measure then I definitely

00:35:35,230 --> 00:35:39,330
found some prices there were different

00:35:36,850 --> 00:35:41,740
cases where my expectations were wrong

00:35:39,330 --> 00:35:43,780
you know might be explicit they were

00:35:41,740 --> 00:35:46,829
right but what I found in this project

00:35:43,780 --> 00:35:48,819
is that that's not enough

00:35:46,829 --> 00:35:50,680
now as I said at the beginning this is

00:35:48,819 --> 00:35:53,380
not to talk about memory or disk or

00:35:50,680 --> 00:35:56,140
microseconds files or hashes this is a

00:35:53,380 --> 00:35:57,700
talk about assumptions when we decided

00:35:56,140 --> 00:35:59,289
with the solutions to a performance

00:35:57,700 --> 00:36:02,079
problem where we need to do something

00:35:59,289 --> 00:36:05,109
really fast was to put stuff on a disk

00:36:02,079 --> 00:36:07,059
else I was shocked I was completely

00:36:05,109 --> 00:36:08,470
stunned and the reason I was shocked is

00:36:07,059 --> 00:36:10,839
that like everybody else

00:36:08,470 --> 00:36:12,549
I knew that disks are really slow in

00:36:10,839 --> 00:36:14,349
fact if you had told me before this

00:36:12,549 --> 00:36:17,039
project that Marshall dumping an entire

00:36:14,349 --> 00:36:19,869
hash into a file would be twice as slow

00:36:17,039 --> 00:36:21,849
sorry twice as fast as hitting a local

00:36:19,869 --> 00:36:23,109
who's ready server I would have laughed

00:36:21,849 --> 00:36:26,019
so hard I would have needed a medical

00:36:23,109 --> 00:36:28,779
attention because I just knew that just

00:36:26,019 --> 00:36:31,059
not true right but here's the problem

00:36:28,779 --> 00:36:32,619
with these things we all know the

00:36:31,059 --> 00:36:34,660
normally very simple they're very

00:36:32,619 --> 00:36:36,180
memorable they have to be if they're

00:36:34,660 --> 00:36:39,250
going to spread and stay in our heads

00:36:36,180 --> 00:36:40,839
ruby is slow we can possibly be that

00:36:39,250 --> 00:36:42,970
slow surely you can write read and write

00:36:40,839 --> 00:36:46,720
a hash in another microsecond right

00:36:42,970 --> 00:36:48,250
can you yeah can we know we're doing

00:36:46,720 --> 00:36:51,460
something weird with them for good

00:36:48,250 --> 00:36:53,829
reasons and it's low memory is fast this

00:36:51,460 --> 00:36:56,799
case no race is fast because it doesn't

00:36:53,829 --> 00:36:58,960
use disk now is it fast yeah for

00:36:56,799 --> 00:37:03,250
database it's really fast is it faster

00:36:58,960 --> 00:37:05,140
than disk depends the point is that

00:37:03,250 --> 00:37:07,900
there's a lot of new ones around this

00:37:05,140 --> 00:37:09,549
simple truth and it gets lost in the

00:37:07,900 --> 00:37:11,500
process if you look at them up close

00:37:09,549 --> 00:37:14,170
these questions aren't simple they don't

00:37:11,500 --> 00:37:16,029
have straightforward simple answers and

00:37:14,170 --> 00:37:17,589
everyone that believes them hasn't

00:37:16,029 --> 00:37:19,450
actually checked them in the context of

00:37:17,589 --> 00:37:21,730
their own problem I mean of course no we

00:37:19,450 --> 00:37:23,140
already know that true but the reason

00:37:21,730 --> 00:37:25,150
that the problem is that having these

00:37:23,140 --> 00:37:27,160
things we all know is going to make you

00:37:25,150 --> 00:37:28,480
blind to potential solutions that you

00:37:27,160 --> 00:37:31,450
could otherwise see if you didn't have

00:37:28,480 --> 00:37:33,609
this knowledge I take this project for

00:37:31,450 --> 00:37:36,549
example it's not like at the beginning

00:37:33,609 --> 00:37:38,529
we all got together we discussed it and

00:37:36,549 --> 00:37:40,569
we explicitly explicitly discard the

00:37:38,529 --> 00:37:42,910
disks because we thought there would be

00:37:40,569 --> 00:37:44,410
too slow we didn't even consider it

00:37:42,910 --> 00:37:46,750
didn't even cross our minds because

00:37:44,410 --> 00:37:50,079
implicitly we all knew that it will work

00:37:46,750 --> 00:37:52,299
now I'll undergone this by pure luck I

00:37:50,079 --> 00:37:55,269
happen to notice that the memory maps

00:37:52,299 --> 00:37:56,559
were opening a file anyway and it'd be

00:37:55,269 --> 00:37:58,480
easy to make them do the same thing

00:37:56,559 --> 00:37:59,260
without the memory maps and so I tried

00:37:58,480 --> 00:38:02,260
it

00:37:59,260 --> 00:38:04,000
but I didn't try it because I thought it

00:38:02,260 --> 00:38:06,310
would be an actual potential solution I

00:38:04,000 --> 00:38:08,350
turned it out of pure curiosity I knew

00:38:06,310 --> 00:38:09,820
it wasn't going to work I just wanted to

00:38:08,350 --> 00:38:14,710
see how much ridiculously slow where it

00:38:09,820 --> 00:38:16,480
would be and if I hadn't to this day I

00:38:14,710 --> 00:38:17,950
wouldn't sleep well wondering when that

00:38:16,480 --> 00:38:22,240
SEC fold was going to hit someone in

00:38:17,950 --> 00:38:23,740
production so what I'm trying to say is

00:38:22,240 --> 00:38:26,650
when you're trying to solve a problem

00:38:23,740 --> 00:38:28,119
and figuring out how to approach it try

00:38:26,650 --> 00:38:28,720
to be aware of that filter in the back

00:38:28,119 --> 00:38:30,670
of your mind

00:38:28,720 --> 00:38:32,890
that's discarding options because you

00:38:30,670 --> 00:38:35,590
know they wouldn't work try and pause

00:38:32,890 --> 00:38:36,730
and look at those options like why do

00:38:35,590 --> 00:38:38,590
you think they wouldn't work are you

00:38:36,730 --> 00:38:40,060
sure that's actually true can you do a

00:38:38,590 --> 00:38:42,430
little experiment can you measure things

00:38:40,060 --> 00:38:44,590
because there may just be a really

00:38:42,430 --> 00:38:46,800
straightforward solution that you're

00:38:44,590 --> 00:38:51,740
missing because it wouldn't work

00:38:46,800 --> 00:38:57,200
sometimes it does thank you

00:38:51,740 --> 00:39:04,689
[Applause]

00:38:57,200 --> 00:39:04,689
[Music]

00:39:07,099 --> 00:39:09,160

YouTube URL: https://www.youtube.com/watch?v=crbyeyPS7HE


