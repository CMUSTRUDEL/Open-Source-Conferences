Title: Ruby Conf 2013 - The tricky truth about parallel execution and modern hardware
Publication date: 2020-01-27
Playlist: RubyConf 2013
Description: 
	By Dirkjan Bussink

Concurrency and parallelism in Ruby are more and more important in the future. Machines will be multi-core and parallelization is often the way these days to speed things up.

At a hardware level, this parallel world is not always a nice and simple place to live. As Ruby implementations get faster and hardware more parallel, these details will matter for you as a Ruby developer too.

Want to know about the pitfalls are of double check locking? No idea what out of order execution means? How CPU cache effects can lead to obscure crashes? What this thing called a memory barrier is? How false sharing can cause performance issues?

Come listen if you want to know about nitty gritty details that can affect your Ruby application in the future.

Help us caption & translate this video!

http://amara.org/v/FG4y/
Captions: 
	00:00:16,000 --> 00:00:19,700
DIRKJAN BUSSINK: Hello everybody. I'm gonna pronounce my own name

00:00:19,749 --> 00:00:21,650
so everybody knows how to pronounce it.

00:00:21,650 --> 00:00:25,759
It's always a challenge. It's Dirkjan Bussink.

00:00:25,759 --> 00:00:28,439
I'm used to all kinds of different butchered forms of it,

00:00:28,439 --> 00:00:31,759
so don't worry about it if you want to ask questions later.

00:00:31,759 --> 00:00:34,500
So what I want to talk to you, today,

00:00:34,500 --> 00:00:38,219
is about -- I call it a tricky truth

00:00:38,219 --> 00:00:41,230
about parallel execution in modern hardware. It's a bit

00:00:41,230 --> 00:00:43,109
of a broad term, term -- and I'm gonna

00:00:43,109 --> 00:00:47,570
talk about all kinds of behavior that might seem

00:00:47,570 --> 00:00:53,100
crazy but are, can be interesting and actually matter

00:00:53,100 --> 00:00:54,879
even to Ruby these days.

00:00:54,879 --> 00:00:57,829
So it's a bit of a journey, for me.

00:00:57,829 --> 00:01:00,999
It's been a thing that I've touched upon for

00:01:00,999 --> 00:01:03,589
at least the last few years in, in, sometimes

00:01:03,589 --> 00:01:08,070
less, sometimes more, and even today, today, like even

00:01:08,070 --> 00:01:11,030
looking into stuff for this presentation, there was still

00:01:11,030 --> 00:01:15,030
things that only then I understood better and, and,

00:01:15,030 --> 00:01:17,770
and actually correct, so. I'm not gonna tell this

00:01:17,770 --> 00:01:20,330
is easy and you should all understand everything and

00:01:20,330 --> 00:01:23,910
all the nuances after this talk.

00:01:23,910 --> 00:01:27,250
It's something that, you know, takes time and, and,

00:01:27,250 --> 00:01:30,120
and is something that you should be interested in.

00:01:30,120 --> 00:01:33,430
So I want to start the journey with actually

00:01:33,430 --> 00:01:35,920
a, a step across the way, which was a

00:01:35,920 --> 00:01:38,570
GitHub commit I made, I think it was two

00:01:38,570 --> 00:01:41,660
years ago. According to the screen shot at least,

00:01:41,660 --> 00:01:44,550
it was. And it was actually a commit to

00:01:44,550 --> 00:01:47,490
Rubinius, and it was something that actually- it only,

00:01:47,490 --> 00:01:49,550
if you look at it, it's a three-line comment

00:01:49,550 --> 00:01:52,050
and it actually only changes one line.

00:01:52,050 --> 00:01:54,470
And this talk is a bit of the story

00:01:54,470 --> 00:01:57,710
about how I came to this case, add this

00:01:57,710 --> 00:02:01,540
one line, in this specific example.

00:02:01,540 --> 00:02:05,330
So one of the things I want to talk

00:02:05,330 --> 00:02:10,190
about first is a very basic concept. It's called

00:02:10,190 --> 00:02:15,110
causality. Basically things happen in a certain order, in

00:02:15,110 --> 00:02:18,420
this case, in your computer. So let's -- I'm,

00:02:18,420 --> 00:02:22,370
I'm -- let's talk about, you know, reasonably trivial

00:02:22,370 --> 00:02:24,810
code, where basically we say OK, we have a

00:02:24,810 --> 00:02:26,620
number and we have a string and we have

00:02:26,620 --> 00:02:29,370
a variable a and b and we just set

00:02:29,370 --> 00:02:29,870
them.

00:02:29,870 --> 00:02:32,480
You know, so far, so good. So far it's,

00:02:32,480 --> 00:02:35,950
it's pretty straightforward. But we're gonna make it a

00:02:35,950 --> 00:02:38,200
little bit more complex. We're gonna add some stuff

00:02:38,200 --> 00:02:43,700
to the mix, and that is parallelism, concurrency. So

00:02:43,700 --> 00:02:45,180
we're gonna change it a little bit. We now

00:02:45,180 --> 00:02:47,880
make a and b a shared variable.

00:02:47,880 --> 00:02:51,450
So everybody knows shared mutable state is bad. This

00:02:51,450 --> 00:02:55,200
talk will hopefully, you have a little bit better

00:02:55,200 --> 00:02:57,760
of an idea of what all, except for the

00:02:57,760 --> 00:03:00,980
standard problems of shared mutable state, what other concerns

00:03:00,980 --> 00:03:02,180
are with it.

00:03:02,180 --> 00:03:06,350
So, but, nevertheless, we're just using mutable state, because

00:03:06,350 --> 00:03:07,850
we got a problem that we want to solve

00:03:07,850 --> 00:03:11,319
this way. So what we do is we change,

00:03:11,319 --> 00:03:13,790
we initialize and, first these variables, then we change

00:03:13,790 --> 00:03:16,950
them. And we use them in another CPU or

00:03:16,950 --> 00:03:18,730
thread, in this case.

00:03:18,730 --> 00:03:21,400
The question is, what can happen here? What are

00:03:21,400 --> 00:03:26,040
possible orders in which you might see things? So

00:03:26,040 --> 00:03:31,080
first there's this. We first initialize a and b.

00:03:31,080 --> 00:03:34,290
Then we copy the values to x and y.

00:03:34,290 --> 00:03:36,349
And at the end, x is the empty string

00:03:36,349 --> 00:03:38,970
and y is, in this case, 1. Note that

00:03:38,970 --> 00:03:41,120
actually swapped the order.

00:03:41,120 --> 00:03:43,140
In the second case, where we first load b

00:03:43,140 --> 00:03:46,540
and then load a.

00:03:46,540 --> 00:03:50,670
So another way this could happen is you first

00:03:50,670 --> 00:03:54,590
copy these values, this code gets run first, and

00:03:54,590 --> 00:03:56,620
then we end up running the other two examples.

00:03:56,620 --> 00:03:58,810
And at the end, x and y are both

00:03:58,810 --> 00:03:59,830
zero.

00:03:59,830 --> 00:04:04,319
There's, of course, more possibilities. There's this one. It

00:04:04,319 --> 00:04:08,459
actually says x, x is zero and y is

00:04:08,459 --> 00:04:11,739
one at the end. As you might have noticed

00:04:11,739 --> 00:04:16,000
so far, this is three possibilities. You can change

00:04:16,000 --> 00:04:18,799
them in a different orders and all this kind

00:04:18,799 --> 00:04:21,249
of stuff, but there's only actually these, these three

00:04:21,249 --> 00:04:24,300
options that should come out of it if you

00:04:24,300 --> 00:04:27,110
reason about this in a logical sense.

00:04:27,110 --> 00:04:30,020
But the question is, is that really what can

00:04:30,020 --> 00:04:36,330
happen on your computer? And there's actually cases how

00:04:36,330 --> 00:04:41,289
this can end up not being in a right

00:04:41,289 --> 00:04:43,779
order, and actually x ending up being an empty

00:04:43,779 --> 00:04:47,120
string and y being an, ending up zero.

00:04:47,120 --> 00:04:51,279
And the question is, what happens? I didn't copy

00:04:51,279 --> 00:04:54,409
this -- no, I did, but, it's actually purposefully

00:04:54,409 --> 00:04:56,580
dutch word. It's the only Dutch slide I have

00:04:56,580 --> 00:04:59,349
in my presentation. Because this is exactly the expression

00:04:59,349 --> 00:05:01,719
that we would say in Dutch. Wat?

00:05:01,719 --> 00:05:04,339
It actually sounds almost the same.

00:05:04,339 --> 00:05:06,479
So why, why is this happening? Like, what can

00:05:06,479 --> 00:05:08,559
do this? What can cause this stuff in your

00:05:08,559 --> 00:05:10,349
code. Well, there's a, there's a few things that

00:05:10,349 --> 00:05:12,389
can cause this. The first one I want to

00:05:12,389 --> 00:05:16,009
talk about are compiler optimizations.

00:05:16,009 --> 00:05:19,990
So, if you imagine this code not, it could

00:05:19,990 --> 00:05:23,210
be Ruby, it could be, you know, C, Java

00:05:23,210 --> 00:05:26,569
-- whatever. The same principles apply. So there might

00:05:26,569 --> 00:05:29,059
be something that actually works in optimizing your code,

00:05:29,059 --> 00:05:32,110
so just, it doesn't, it doesn't just, you know,

00:05:32,110 --> 00:05:34,830
emit this direct code and run that at a

00:05:34,830 --> 00:05:37,339
low-level in assembly on your machine.

00:05:37,339 --> 00:05:39,080
So it could be, you know, C compile, it

00:05:39,080 --> 00:05:40,999
could be a just-in-time compile. It, it could be

00:05:40,999 --> 00:05:41,449
anything.

00:05:41,449 --> 00:05:44,089
And, and one of the things to think about

00:05:44,089 --> 00:05:47,689
is, you know we have these, these two statements.

00:05:47,689 --> 00:05:52,479
And the question is, how different is this from

00:05:52,479 --> 00:05:57,219
doing this? You know, does this matter? Does this

00:05:57,219 --> 00:06:01,069
have an effect that is different on your system?

00:06:01,069 --> 00:06:03,759
And that actually all comes down to the, to

00:06:03,759 --> 00:06:06,589
the perception of what is this, what is the

00:06:06,589 --> 00:06:10,360
same, like, what is equal? And a lot of

00:06:10,360 --> 00:06:14,069
systems define what is equal in the sense of,

00:06:14,069 --> 00:06:17,119
what is equal for just the single thread of

00:06:17,119 --> 00:06:20,949
execution? So in that context, this is perfectly fine.

00:06:20,949 --> 00:06:23,080
You can swap these and it doesn't make the

00:06:23,080 --> 00:06:26,979
meaning of your program in any way different.

00:06:26,979 --> 00:06:31,129
But actually, it doesn't work anymore if you consider

00:06:31,129 --> 00:06:34,430
this in a concurrent scenario. Because what then happens

00:06:34,430 --> 00:06:37,599
is we see, hey, we suddenly run this in

00:06:37,599 --> 00:06:40,419
a different order, and we get this example of

00:06:40,419 --> 00:06:43,460
x being an empty string and y being zero,

00:06:43,460 --> 00:06:46,150
even though, if we look at our code and

00:06:46,150 --> 00:06:48,699
reason about it in the order that we see

00:06:48,699 --> 00:06:52,499
things, this is not what is supposed to happen.

00:06:52,499 --> 00:06:55,089
So that's one example. So that's, that's one cause

00:06:55,089 --> 00:06:57,110
of what can cause these problems and that's, in

00:06:57,110 --> 00:06:59,599
this case, your compiler.

00:06:59,599 --> 00:07:02,029
But, of course your compiler is not the only

00:07:02,029 --> 00:07:04,809
thing that can do that, because that will be,

00:07:04,809 --> 00:07:09,069
you know, too simple. There's another principle here that

00:07:09,069 --> 00:07:12,649
could have an effect on this. And I say

00:07:12,649 --> 00:07:15,899
could because it depends on a lot of factors.

00:07:15,899 --> 00:07:19,180
For example, let's think about, like, the machine you

00:07:19,180 --> 00:07:21,210
have, I think a lot of people have in

00:07:21,210 --> 00:07:25,860
front of them. Usually they're intel systems, laptop still

00:07:25,860 --> 00:07:29,270
these days, so what does the intel manual say

00:07:29,270 --> 00:07:33,379
about, you know, memory and running code and, and

00:07:33,379 --> 00:07:34,770
stuff like that.

00:07:34,770 --> 00:07:37,580
So actually, intel is actually pretty nice. It's, it's

00:07:37,580 --> 00:07:41,059
fairly conservative. It doesn't do things that you might

00:07:41,059 --> 00:07:44,830
find confusing. But it does say one thing, and

00:07:44,830 --> 00:07:48,550
that is that loads may be reordered with earlier

00:07:48,550 --> 00:07:52,289
stores to different locations. And that's from the intel

00:07:52,289 --> 00:07:56,770
64 and ia32 architecture developer manual called 338. It's

00:07:56,770 --> 00:07:57,669
a long term.

00:07:57,669 --> 00:07:59,869
But, but what, what does it mean?

00:07:59,869 --> 00:08:02,039
Well what it means is that, if we look

00:08:02,039 --> 00:08:06,439
at code like in a more assembly style of,

00:08:06,439 --> 00:08:09,559
of those examples we had, that we, we now

00:08:09,559 --> 00:08:11,779
define this here as a load and a store

00:08:11,779 --> 00:08:15,659
operation. X and y can be other memory locations,

00:08:15,659 --> 00:08:18,679
and be registered, but that's not, it's all about

00:08:18,679 --> 00:08:21,330
the a's and the b's here.

00:08:21,330 --> 00:08:23,429
So what we see here is that, OK, we

00:08:23,429 --> 00:08:27,369
can load a and load b and store them.

00:08:27,369 --> 00:08:30,860
And this is, still has the same examples. And

00:08:30,860 --> 00:08:34,289
if you look at that common, like that line

00:08:34,289 --> 00:08:37,209
from the manual we just saw, there's not really

00:08:37,209 --> 00:08:39,930
a way. Because the only thing the manual allows

00:08:39,930 --> 00:08:44,860
is that we could swap instructions that store and

00:08:44,860 --> 00:08:47,680
load, like only a store and load that actually

00:08:47,680 --> 00:08:49,410
use a different location.

00:08:49,410 --> 00:08:51,860
So if you want to go back to having

00:08:51,860 --> 00:08:56,130
this example where we can end up with x

00:08:56,130 --> 00:08:58,990
being an empty string and y being zero, there's

00:08:58,990 --> 00:09:02,050
not really a way to do that here, because-

00:09:02,050 --> 00:09:05,940
Well, we can see, actually in all cases, we

00:09:05,940 --> 00:09:08,149
see that there's a load and a store in,

00:09:08,149 --> 00:09:11,269
in like the left lower corner that actually talk

00:09:11,269 --> 00:09:14,069
about the same memory location. But we cannot swap

00:09:14,069 --> 00:09:16,259
them around.

00:09:16,259 --> 00:09:22,430
But of course not all architectures are created equal.

00:09:22,430 --> 00:09:25,500
This is where it gets interesting, and that is

00:09:25,500 --> 00:09:28,519
that, like I said, x86 -- the thing you

00:09:28,519 --> 00:09:30,389
have in your laptop -- it's fairly straight. It

00:09:30,389 --> 00:09:32,680
doesn't do a lot of things that could be

00:09:32,680 --> 00:09:35,579
confusing. But if you compare it to what you

00:09:35,579 --> 00:09:37,920
have in your phone these days, which is like

00:09:37,920 --> 00:09:41,350
ARMv7 architecture or newer even, I think they're working

00:09:41,350 --> 00:09:45,100
on, like version 8 with 64 bit support, was

00:09:45,100 --> 00:09:46,519
like the new iPhone has that -- all that

00:09:46,519 --> 00:09:48,120
kind of stuff.

00:09:48,120 --> 00:09:54,240
And even ARM these days has multi-core systems. So

00:09:54,240 --> 00:09:57,610
on ARM, actually, it is allowed, that we re-order

00:09:57,610 --> 00:09:59,839
the loads on each other, so we can swap

00:09:59,839 --> 00:10:03,690
loads or we can swap stores and loads or

00:10:03,690 --> 00:10:05,410
stores in stores.

00:10:05,410 --> 00:10:07,379
So if you look at that, you can see,

00:10:07,379 --> 00:10:11,240
you can actually create a new example by swapping

00:10:11,240 --> 00:10:15,490
some instructions and actually causing the same problem we

00:10:15,490 --> 00:10:18,709
had before. So this is something that can happen

00:10:18,709 --> 00:10:23,529
on your phone, or your tablet, or your whatever.

00:10:23,529 --> 00:10:27,079
So, so, the question is why. Why, why do

00:10:27,079 --> 00:10:30,190
CPUs do this? Well, there's a few things that

00:10:30,190 --> 00:10:34,500
are going on. One of the things is that

00:10:34,500 --> 00:10:37,399
this is something they do for efficiency, so they

00:10:37,399 --> 00:10:40,170
can, you know, some operations might be slower, some

00:10:40,170 --> 00:10:42,269
of them might take longer, and one of the

00:10:42,269 --> 00:10:45,709
things that the instruction can store, for example, is

00:10:45,709 --> 00:10:46,610
CPU cache.

00:10:46,610 --> 00:10:50,670
So we all know that if you have something

00:10:50,670 --> 00:10:54,259
that is slow, and in this case, memory, memory

00:10:54,259 --> 00:10:57,220
is slow. You know, if you look at Morris-law

00:10:57,220 --> 00:11:01,930
and you look at the paths we had, CPUs

00:11:01,930 --> 00:11:04,990
and memory were, were much more on par. But

00:11:04,990 --> 00:11:08,100
the speed at which CPUs got fast or when

00:11:08,100 --> 00:11:11,199
-- it went a lot faster than, than memory,

00:11:11,199 --> 00:11:11,720
so.

00:11:11,720 --> 00:11:14,110
The disparity between the speed of your CPU and

00:11:14,110 --> 00:11:17,120
the speed of memory has only become wider and

00:11:17,120 --> 00:11:20,600
bigger and bigger over the last years. So how

00:11:20,600 --> 00:11:22,490
slow is memory?

00:11:22,490 --> 00:11:24,790
Well we all know that if you have slow,

00:11:24,790 --> 00:11:27,550
something slow that, you know, you got to add

00:11:27,550 --> 00:11:30,610
a cache. That's the thing we do as, as

00:11:30,610 --> 00:11:32,269
developers. If you're a web developer, your web page

00:11:32,269 --> 00:11:35,829
slow, you'll end up adding caches. Your CPU is

00:11:35,829 --> 00:11:37,589
slow, you look at adding caches.

00:11:37,589 --> 00:11:39,639
So what kind of caches do we have. In

00:11:39,639 --> 00:11:45,410
this case I'm talking about the, the Vintel core

00:11:45,410 --> 00:11:50,740
dual architecture. Basically this based on a reasonable, reasonably

00:11:50,740 --> 00:11:55,209
recent intel CPU. So we have very descriptive names,

00:11:55,209 --> 00:11:58,220
of course, cause we have different levels of cache.

00:11:58,220 --> 00:12:01,519
Level one is like really close to your CPU.

00:12:01,519 --> 00:12:05,100
It's very expensive memory. It's not very big. And

00:12:05,100 --> 00:12:07,500
it's pretty fast. So if there's a memory value

00:12:07,500 --> 00:12:10,410
that's there, we can get it and just four

00:12:10,410 --> 00:12:14,699
memory, four CPU cycles, which is reasonably fast. If

00:12:14,699 --> 00:12:16,790
it's in level 2, it's a bit slower, but

00:12:16,790 --> 00:12:20,560
it's bigger. So we still have that. It takes

00:12:20,560 --> 00:12:24,129
ten cycles. L3 is even slower. It depends a

00:12:24,129 --> 00:12:27,310
bit on, because L3 is usually shared between CPU

00:12:27,310 --> 00:12:29,029
cores, so.

00:12:29,029 --> 00:12:31,600
They're different timings depending on which CPU core actually

00:12:31,600 --> 00:12:35,870
manages that piece of the cache. So, and, and

00:12:35,870 --> 00:12:38,759
actually RAM is really slow. It's like hundreds of

00:12:38,759 --> 00:12:42,379
cycles and, and, and usually it's even measured in

00:12:42,379 --> 00:12:45,920
actual time, because they don't actually always match up

00:12:45,920 --> 00:12:48,550
with your CPU, because they have different timings and

00:12:48,550 --> 00:12:49,189
stuff.

00:12:49,189 --> 00:12:53,829
But, like I said, caching, caching is hard. So

00:12:53,829 --> 00:12:55,379
we have to do all these tricks to keep

00:12:55,379 --> 00:12:57,569
this stuff in sync, and if you look back

00:12:57,569 --> 00:13:01,089
at these timings, this could be a way you

00:13:01,089 --> 00:13:04,290
say, OK, so, if your CPU has something that

00:13:04,290 --> 00:13:06,439
we have a load of two memory locations and

00:13:06,439 --> 00:13:09,939
one load is already available in our cache, and

00:13:09,939 --> 00:13:12,920
the other load is, is still, still further away

00:13:12,920 --> 00:13:15,379
in another cache or a memory, we might want

00:13:15,379 --> 00:13:19,110
to start running the load that's far away first,

00:13:19,110 --> 00:13:22,160
so we don't waste CPU cycles on waiting for

00:13:22,160 --> 00:13:23,449
that slow load later.

00:13:23,449 --> 00:13:26,500
So we might run stuff in a different order.

00:13:26,500 --> 00:13:28,879
That is actually one of the reasons that this

00:13:28,879 --> 00:13:31,740
stuff could be happening. But like I said, caching

00:13:31,740 --> 00:13:32,779
is hard.

00:13:32,779 --> 00:13:36,230
So one way we implement this is in, in

00:13:36,230 --> 00:13:40,399
the, or not -- we, that's a bit presumptuous.

00:13:40,399 --> 00:13:42,730
I'm not smart enough, I know. I don't feel

00:13:42,730 --> 00:13:46,569
smart enough to work on this kind of stuff.

00:13:46,569 --> 00:13:48,910
But actually not designing CPUs that's not my thing.

00:13:48,910 --> 00:13:51,589
I would love it if I could, but...

00:13:51,589 --> 00:13:52,620
So one of the things we use is a

00:13:52,620 --> 00:13:54,829
store buffer. It's actually a very small place in

00:13:54,829 --> 00:13:57,810
your CPU where we actually store intermediate values you

00:13:57,810 --> 00:14:01,139
might use up later. So I'm giving you another

00:14:01,139 --> 00:14:03,749
example. This example is actually slightly different from the

00:14:03,749 --> 00:14:07,730
one we saw before, but it shows that even

00:14:07,730 --> 00:14:11,639
on your laptop, you can have issues with running

00:14:11,639 --> 00:14:14,360
code on your system and getting and seeing very

00:14:14,360 --> 00:14:16,089
weird results.

00:14:16,089 --> 00:14:18,240
So one of the things is, here we say,

00:14:18,240 --> 00:14:21,779
OK, we have a is one, and we set

00:14:21,779 --> 00:14:23,009
b to a string, and in the end the

00:14:23,009 --> 00:14:25,160
question is, what comes out?

00:14:25,160 --> 00:14:28,410
So here we have, again, x is y, x

00:14:28,410 --> 00:14:32,189
is zero and y is one.

00:14:32,189 --> 00:14:34,120
And we have another example where we do it,

00:14:34,120 --> 00:14:35,600
of course, in a different order, and we get

00:14:35,600 --> 00:14:37,420
the empty string and zero.

00:14:37,420 --> 00:14:40,569
So then there's the case where we intermix them,

00:14:40,569 --> 00:14:42,499
you can intermix in all these different orders, it

00:14:42,499 --> 00:14:45,350
doesn't really matter much, you'll always usually get, get

00:14:45,350 --> 00:14:47,920
an order like this. But if you think back

00:14:47,920 --> 00:14:51,850
about what did the intel manual with a long

00:14:51,850 --> 00:14:54,069
name say?

00:14:54,069 --> 00:14:57,959
It said that we can actually reorder loads and

00:14:57,959 --> 00:15:01,370
stores. So if you go back to this slide,

00:15:01,370 --> 00:15:04,509
you can see, OK, so what can we do

00:15:04,509 --> 00:15:06,899
here? We might, we're allowed to reorder stores and

00:15:06,899 --> 00:15:10,550
loads. Let's do that. So we now say we

00:15:10,550 --> 00:15:13,379
do the loads first, before we do the stores.

00:15:13,379 --> 00:15:15,680
And it means we have x is zero and

00:15:15,680 --> 00:15:19,129
y is zero. Which is not a very intuitive

00:15:19,129 --> 00:15:21,819
answer that your machine might be giving if it's

00:15:21,819 --> 00:15:24,499
running this code in your CPU.

00:15:24,499 --> 00:15:28,009
So of course we have a problem now. But

00:15:28,009 --> 00:15:32,809
what would a problem be without fixing it?

00:15:32,809 --> 00:15:36,670
So there's actually a fairly straightforward way to fix

00:15:36,670 --> 00:15:40,540
this, and that's a concept called memory barriers, and

00:15:40,540 --> 00:15:43,930
basically what memory barriers say is that we have

00:15:43,930 --> 00:15:46,980
your CPU has a specific instruction that says, I

00:15:46,980 --> 00:15:49,649
want to make sure that this happens in the

00:15:49,649 --> 00:15:51,439
way, in the order that I want it to

00:15:51,439 --> 00:15:55,100
happen. So how does the memory barrier look like?

00:15:55,100 --> 00:15:58,050
Well, a lot of languages, like, you know, this

00:15:58,050 --> 00:16:00,639
is, this is low-level concern so we might need

00:16:00,639 --> 00:16:05,120
C, but, well, C actually doesn't have this. There

00:16:05,120 --> 00:16:08,699
are built in constructs in, in, in C and

00:16:08,699 --> 00:16:10,910
compilers that could do, but there's no, like, native

00:16:10,910 --> 00:16:12,730
thing in C that actually has this.

00:16:12,730 --> 00:16:15,199
C doesn't even tell, C doesn't even say anything

00:16:15,199 --> 00:16:18,579
about the semantics and stuff. So you end up

00:16:18,579 --> 00:16:22,740
doing stuff like this -- inline assembly and trying

00:16:22,740 --> 00:16:27,309
to solve this problem. Well, not really elegant, if

00:16:27,309 --> 00:16:29,290
you're a Ruby programmer, that's not the thing.

00:16:29,290 --> 00:16:31,430
You know, we all know what Matz, Matz talked

00:16:31,430 --> 00:16:35,290
about, about the hardware abstraction, and not wanting to

00:16:35,290 --> 00:16:37,790
think about -- well, this is actually an area

00:16:37,790 --> 00:16:40,959
where, in some cases, you might have to think

00:16:40,959 --> 00:16:41,980
about it.

00:16:41,980 --> 00:16:46,379
So there is, there's three versions. Basically sfence, it

00:16:46,379 --> 00:16:50,259
says don't reorder stuff with, well s stands for

00:16:50,259 --> 00:16:52,550
stores. I guess everybody knows what the l stands

00:16:52,550 --> 00:16:54,910
for then, it stands for loads. So don't reorder

00:16:54,910 --> 00:16:57,870
loads around it. And mfence is basically both. So

00:16:57,870 --> 00:17:01,990
the mfence says, OK, we're not reordering anything, any

00:17:01,990 --> 00:17:04,350
code that happens before this with any code after

00:17:04,350 --> 00:17:07,100
this.

00:17:07,100 --> 00:17:08,510
So I've been talking about this stuff, and it

00:17:08,510 --> 00:17:13,540
may look like a very, you know, artificial problems,

00:17:13,540 --> 00:17:16,310
constructed problems that are not a real problem in

00:17:16,310 --> 00:17:20,070
actual real-world code that is out there. And that's

00:17:20,070 --> 00:17:24,510
actually not true. There's actually a pretty-often used pattern

00:17:24,510 --> 00:17:30,180
that is broken in sometimes all these subtle ways

00:17:30,180 --> 00:17:32,530
that can be very complicated.

00:17:32,530 --> 00:17:35,840
And that's double check locking.

00:17:35,840 --> 00:17:40,080
So double check locking, basically, builds on the idea

00:17:40,080 --> 00:17:42,660
that you have something in your system that is

00:17:42,660 --> 00:17:46,580
expensive to make. Like, you know, people know the

00:17:46,580 --> 00:17:49,910
singleton? Pattern. It's not usually a very good pattern.

00:17:49,910 --> 00:17:51,390
But maybe there are places where you have an

00:17:51,390 --> 00:17:52,830
object in your system, and you don't want to

00:17:52,830 --> 00:17:55,830
build an expensive object every time, because you might

00:17:55,830 --> 00:17:57,470
need it -- I know, I don't know, like

00:17:57,470 --> 00:17:59,680
a hundred times in your Rails requests, and you

00:17:59,680 --> 00:18:01,950
don't want to build that expensive object a hundred

00:18:01,950 --> 00:18:03,260
times.

00:18:03,260 --> 00:18:06,300
But, so you think about it, and you say,

00:18:06,300 --> 00:18:08,300
OK, it means I, you know, I have a

00:18:08,300 --> 00:18:10,100
system that runs concurrently, so I have to think

00:18:10,100 --> 00:18:12,860
about mutual exclusions. So I'll put a lock around

00:18:12,860 --> 00:18:16,820
it. But that means that, even if you're construction,

00:18:16,820 --> 00:18:19,670
like, your, your object is very expensive, you still

00:18:19,670 --> 00:18:21,240
have a lock around it. And a lock is

00:18:21,240 --> 00:18:24,210
actually not always that cheap, either. So you have

00:18:24,210 --> 00:18:26,710
to think about, OK, oh, let's remove this lock.

00:18:26,710 --> 00:18:28,450
So you end up with code that looks something

00:18:28,450 --> 00:18:31,460
like this.

00:18:31,460 --> 00:18:34,280
So we store it. We have a mutex, so

00:18:34,280 --> 00:18:38,040
we can do the synchronization part. We initialize it,

00:18:38,040 --> 00:18:43,240
and we do this.

00:18:43,240 --> 00:18:45,880
So I don't know. The thing is, we'd say,

00:18:45,880 --> 00:18:47,280
OK, we have an instance, and if we don't

00:18:47,280 --> 00:18:49,920
have it, we do a lock. And if we

00:18:49,920 --> 00:18:53,260
still don't have it, we make a new object.

00:18:53,260 --> 00:18:55,390
You can now see where the name double check

00:18:55,390 --> 00:18:58,640
comes from, because you see the same unless check

00:18:58,640 --> 00:19:00,690
twice. This is actually why I wrote it like

00:19:00,690 --> 00:19:02,690
this and not with a or or is because

00:19:02,690 --> 00:19:06,030
this, this is a little bit more explicit.

00:19:06,030 --> 00:19:07,840
And the reason for that is that if you

00:19:07,840 --> 00:19:10,150
think about it, if two threads are running at

00:19:10,150 --> 00:19:12,870
the same time, both think, hey, the object is

00:19:12,870 --> 00:19:16,270
not initialized that, yet, they both try to grab

00:19:16,270 --> 00:19:18,750
the lock. Only one of them succeeds, and if

00:19:18,750 --> 00:19:22,970
that object succeeds, it would see, it would build

00:19:22,970 --> 00:19:26,070
the object, and then unlock and return it.

00:19:26,070 --> 00:19:27,870
And the other thread sees oh, this code is

00:19:27,870 --> 00:19:30,530
now unlocked. And I was waiting for it so

00:19:30,530 --> 00:19:33,010
I can run this code. But if it would

00:19:33,010 --> 00:19:35,990
not check again, if some other thread had run

00:19:35,990 --> 00:19:38,280
it and initialized the object, it would run, initialize

00:19:38,280 --> 00:19:39,380
the object again.

00:19:39,380 --> 00:19:41,940
And we would build it twice. That might not

00:19:41,940 --> 00:19:44,080
be a problem. It might be a problem. But

00:19:44,080 --> 00:19:45,570
it's something in this case we don't want to

00:19:45,570 --> 00:19:48,280
happen.

00:19:48,280 --> 00:19:51,460
There is a thing that is actually -- this

00:19:51,460 --> 00:19:55,180
is the, this solves this problem. There's actually something

00:19:55,180 --> 00:19:58,800
far more subtle going on here, that you might

00:19:58,800 --> 00:20:02,630
not think about. And that is, if you remember

00:20:02,630 --> 00:20:05,550
what we just talked about, is that things might

00:20:05,550 --> 00:20:08,780
happen not in the order that you think they

00:20:08,780 --> 00:20:09,590
are.

00:20:09,590 --> 00:20:13,340
And in this case, maybe the compiler, or CPU

00:20:13,340 --> 00:20:16,380
you're running this on, tries to optimize something for

00:20:16,380 --> 00:20:19,450
you. And what it does, it actually ends up

00:20:19,450 --> 00:20:25,680
creating, it's perfectly valid in that sense to say,

00:20:25,680 --> 00:20:30,310
OK, we are building a new instance. And you

00:20:30,310 --> 00:20:33,110
might ask why did I put that constructor up

00:20:33,110 --> 00:20:36,360
there? And that's actually not just for fun.

00:20:36,360 --> 00:20:39,520
Cause what might happen is that, because this stuff

00:20:39,520 --> 00:20:42,510
runs out of order, it might even say, OK,

00:20:42,510 --> 00:20:48,880
I already, in, assigned this variable to instance. But

00:20:48,880 --> 00:20:52,140
I'll finish up the constructor later. So it actually

00:20:52,140 --> 00:20:55,490
might happen that the other thread already sees that,

00:20:55,490 --> 00:21:00,040
hey, instance is there, so I'm going to initialize

00:21:00,040 --> 00:21:00,470
it.

00:21:00,470 --> 00:21:03,320
But it also sees that bar is still nil.

00:21:03,320 --> 00:21:06,310
And it might crash or throw an exception or

00:21:06,310 --> 00:21:09,740
whatever. So what we have to do is find

00:21:09,740 --> 00:21:14,170
some way to explicitly synchronize this. If you run

00:21:14,170 --> 00:21:17,620
on x(86), it's good enough to insert, in this

00:21:17,620 --> 00:21:21,980
case, compiler barrier, which means that it's a way,

00:21:21,980 --> 00:21:25,490
it's safe to say, a right. We have our,

00:21:25,490 --> 00:21:28,950
our compiler is not allowed to reorder this, because

00:21:28,950 --> 00:21:32,220
it would happen if we reorder stores, and if

00:21:32,220 --> 00:21:33,910
you remember, x is, it doesn't do that.

00:21:33,910 --> 00:21:35,940
But if you're on an ARM system, that's not

00:21:35,940 --> 00:21:40,160
enough. You actually have to do, like, CPU instructions

00:21:40,160 --> 00:21:43,430
to do this correctly. If you'll look, I think

00:21:43,430 --> 00:21:45,860
if you Google for like, double check locking, like

00:21:45,860 --> 00:21:48,630
Google will auto suggest, like, double check locking is

00:21:48,630 --> 00:21:53,340
broken in programming language x or y. Because a

00:21:53,340 --> 00:21:58,240
lot of languages don't provide explicit mechanisms that allow

00:21:58,240 --> 00:22:00,210
you to handle this stuff.

00:22:00,210 --> 00:22:02,260
So how does this all matter to Ruby? Because

00:22:02,260 --> 00:22:05,020
you all, people always say, like, Ruby is, is,

00:22:05,020 --> 00:22:06,940
you know, this is not the stuff we want

00:22:06,940 --> 00:22:10,530
to worry about in Ruby. And, for that, I

00:22:10,530 --> 00:22:13,630
have, I have a little other example.

00:22:13,630 --> 00:22:18,470
And it goes back, it's called false sharing, and

00:22:18,470 --> 00:22:21,230
it goes back to the CPU cache problem that

00:22:21,230 --> 00:22:24,370
we talked about before, the performance of the CPU

00:22:24,370 --> 00:22:27,880
cache. So, imagine we're now doing something different. We

00:22:27,880 --> 00:22:30,450
have some concurrent data structure, for example, that we're

00:22:30,450 --> 00:22:33,740
using, and we're, and we're doing things with. And

00:22:33,740 --> 00:22:37,250
we have this magnificent foo class that we need,

00:22:37,250 --> 00:22:39,970
and it has just a single attribute -- this

00:22:39,970 --> 00:22:40,380
case a.

00:22:40,380 --> 00:22:44,370
And we have two threads that are actually modifying

00:22:44,370 --> 00:22:47,710
this. We don't really care about that they actually

00:22:47,710 --> 00:22:50,190
have, to like, interleave this, or what. It's just

00:22:50,190 --> 00:22:52,660
that we run this stuff in two different threads

00:22:52,660 --> 00:22:54,860
on our system, and it runs on two CPUs

00:22:54,860 --> 00:22:59,570
or cores or whatever. Usually cores, cause that's what

00:22:59,570 --> 00:23:02,030
I, what usually ends up happening.

00:23:02,030 --> 00:23:03,840
So, what will we see here is actually we

00:23:03,840 --> 00:23:07,040
change the same value in memory. So if you

00:23:07,040 --> 00:23:14,040
think about this diagram again, we're actually changing a

00:23:14,430 --> 00:23:18,490
shared variable between two, on the same object in

00:23:18,490 --> 00:23:20,340
the same place of memory.

00:23:20,340 --> 00:23:22,400
So what happens here is that the CPU needs

00:23:22,400 --> 00:23:26,080
to synchronize that, because if one core changes it,

00:23:26,080 --> 00:23:28,230
it needs to notify the other that it needs

00:23:28,230 --> 00:23:30,520
to flush its stash and update the value because

00:23:30,520 --> 00:23:32,210
it just changed it. And there's a lot of

00:23:32,210 --> 00:23:35,570
chatter going on about that stuff, because, well, that's,

00:23:35,570 --> 00:23:38,640
that's the downside of caching. You have to keep

00:23:38,640 --> 00:23:39,980
it all in sync.

00:23:39,980 --> 00:23:41,420
And it has to go at least to the

00:23:41,420 --> 00:23:44,220
level three cache, because that's usually where it ends

00:23:44,220 --> 00:23:48,720
up sharing data between different CPU cores. So if

00:23:48,720 --> 00:23:50,980
you see, look at this, and if like, at

00:23:50,980 --> 00:23:54,060
least ten times slower to use that memory address.

00:23:54,060 --> 00:23:56,650
So it, in total this benchmark is not ten

00:23:56,650 --> 00:23:59,600
times slower, but somewhat less, because there's other code

00:23:59,600 --> 00:24:02,710
running, but I have the numbers later, but this

00:24:02,710 --> 00:24:05,740
is like, four times slower, if you compare this

00:24:05,740 --> 00:24:08,970
to just, to just running the single thread compared

00:24:08,970 --> 00:24:12,200
to running two threads are doing this.

00:24:12,200 --> 00:24:14,870
But we're smart. We have a way to solve

00:24:14,870 --> 00:24:18,840
this, because we think of a new data structure,

00:24:18,840 --> 00:24:21,530
and that allows us to use two different variables

00:24:21,530 --> 00:24:24,230
that are not the same. And they're not the

00:24:24,230 --> 00:24:27,480
same. We don't need to keep the cache synchronized,

00:24:27,480 --> 00:24:30,440
so we don't suffer from this problem.

00:24:30,440 --> 00:24:32,470
So this case, we have the value one and

00:24:32,470 --> 00:24:35,160
the value of value a and b, and the

00:24:35,160 --> 00:24:36,890
one thread we modify a and the other one

00:24:36,890 --> 00:24:41,590
we modify b. And we benchmark this again. And

00:24:41,590 --> 00:24:44,820
what do we see? This is just as slow

00:24:44,820 --> 00:24:48,140
as the previous example. It's just as slow as

00:24:48,140 --> 00:24:51,160
the case where we're writing both a's.

00:24:51,160 --> 00:24:53,700
And the question is why. Why is it happening?

00:24:53,700 --> 00:24:57,580
And that comes down to a principle that's called

00:24:57,580 --> 00:25:01,490
cache lines, because your CPU doesn't work with caches

00:25:01,490 --> 00:25:04,650
of just a single memory location. Now, in, in

00:25:04,650 --> 00:25:08,240
Ruby, everything is an object and in this case

00:25:08,240 --> 00:25:10,920
everything here is, even this number is a reference

00:25:10,920 --> 00:25:12,960
so it's, it's, on a 64 bit system it's

00:25:12,960 --> 00:25:15,670
an eight byte value.

00:25:15,670 --> 00:25:18,530
We constantly store an eight byte value. But this

00:25:18,530 --> 00:25:23,790
cache line is on this x(86) machine is 64

00:25:23,790 --> 00:25:26,960
bytes. So it means we have, we always synchronize

00:25:26,960 --> 00:25:32,640
the cache in a pair of 8 consecutive entries.

00:25:32,640 --> 00:25:34,330
So what happens is that even though we modify

00:25:34,330 --> 00:25:37,620
different variables, there's a pretty good chance that they're

00:25:37,620 --> 00:25:39,770
in the same cache line. And we actually end

00:25:39,770 --> 00:25:42,230
up trashing the system in exactly the same way

00:25:42,230 --> 00:25:45,600
as modifying only variable a.

00:25:45,600 --> 00:25:48,840
But of course, for this, we have a solution.

00:25:48,840 --> 00:25:52,970
Because we just add more properties, you know. Let's

00:25:52,970 --> 00:25:57,040
do, let's do k, that's probably not on the

00:25:57,040 --> 00:26:00,230
same cache line as a. And actually, if you

00:26:00,230 --> 00:26:05,480
run this, it actually is as fast as it

00:26:05,480 --> 00:26:07,130
was before.

00:26:07,130 --> 00:26:10,160
And this is actually, like, a bench, like, I

00:26:10,160 --> 00:26:14,180
run this on, on, Rubinius, because mostly because it

00:26:14,180 --> 00:26:18,960
actually creates object layouts for this that actually are

00:26:18,960 --> 00:26:21,880
consecutive in memory. So if you run this benchmark,

00:26:21,880 --> 00:26:24,090
this is pure Ruby code, these are the numbers

00:26:24,090 --> 00:26:27,990
I get. They might be different on different runs,

00:26:27,990 --> 00:26:30,170
because it might end up in different memory locations.

00:26:30,170 --> 00:26:33,320
But this is the kind of idea of what

00:26:33,320 --> 00:26:35,630
is happening here, and what can happen, and what

00:26:35,630 --> 00:26:42,060
this confusion can cause. So, again, Ruby.

00:26:42,060 --> 00:26:45,500
It's all just Ruby. And also the other examples

00:26:45,500 --> 00:26:49,150
that I showed are actually something that is a

00:26:49,150 --> 00:26:51,850
problem in, in, in what Ruby is currently defined

00:26:51,850 --> 00:26:54,700
as. So it, it, it, it puts, it asks

00:26:54,700 --> 00:26:57,600
the question, like, what is thread-safe code?

00:26:57,600 --> 00:26:59,960
So I was in, in Paris a few weeks

00:26:59,960 --> 00:27:03,460
ago at a conference, and Emily, who also gave

00:27:03,460 --> 00:27:06,620
the previous talk, talked a bit about threading there,

00:27:06,620 --> 00:27:09,750
and she said, there's no such thing as thread-safe

00:27:09,750 --> 00:27:14,260
Ruby code. And I have to agree with that.

00:27:14,260 --> 00:27:18,270
Basically because the only way currently we define thread

00:27:18,270 --> 00:27:23,910
safety is basically, oh, this might work on Rubinius,

00:27:23,910 --> 00:27:26,110
or this might work on Jruby, oh this works

00:27:26,110 --> 00:27:27,400
on MRI.

00:27:27,400 --> 00:27:29,070
So it only is define in that context. There

00:27:29,070 --> 00:27:32,910
is no definition of what it is in Ruby.

00:27:32,910 --> 00:27:35,110
So what does it mean for the, for the

00:27:35,110 --> 00:27:39,190
future, and then actually, I would, I was, I

00:27:39,190 --> 00:27:41,750
immediately have to think of that when I heard

00:27:41,750 --> 00:27:44,560
Matz talk this morning is that I don't think

00:27:44,560 --> 00:27:47,470
we should follow the ostrich strategy. So I don't

00:27:47,470 --> 00:27:50,410
think this is a problem we should ignore.

00:27:50,410 --> 00:27:53,040
I think the garbage collectors, as he called it,

00:27:53,040 --> 00:27:57,910
of this, should think about this, and think about

00:27:57,910 --> 00:28:00,170
how do we solve, or not solve, but how

00:28:00,170 --> 00:28:03,880
do we define semantics, how do we define what

00:28:03,880 --> 00:28:06,120
is, what is it that, that Ruby developers can

00:28:06,120 --> 00:28:09,900
expect from Ruby? You know, is there Ruby optimizat-

00:28:09,900 --> 00:28:14,420
like, is Ruby git, is it allowed to reorder

00:28:14,420 --> 00:28:16,870
statements? Or is it not?

00:28:16,870 --> 00:28:19,410
You know. May it change order of initializations for

00:28:19,410 --> 00:28:21,840
optimization purposes or not?

00:28:21,840 --> 00:28:24,780
What, what level, in what level do we want

00:28:24,780 --> 00:28:29,600
to abstract our, our machine, you know? Are the

00:28:29,600 --> 00:28:32,590
things, the, the concerns that I talked about, about

00:28:32,590 --> 00:28:36,320
your CPU reordering things, are those things that semantics

00:28:36,320 --> 00:28:38,590
that end up in Ruby, or do we say,

00:28:38,590 --> 00:28:41,350
no that's not something that should be allowed?

00:28:41,350 --> 00:28:43,360
And those are the things are questions to think

00:28:43,360 --> 00:28:47,160
about, because it matters a lot for, in this

00:28:47,160 --> 00:28:51,130
case, alternative implementations, actually, to think about that. So

00:28:51,130 --> 00:28:54,830
that, that thing is called memory model, basically. It's

00:28:54,830 --> 00:28:58,900
a umbrella term for a lot of those aspects

00:28:58,900 --> 00:29:03,040
of what is the Ruby language allowed to do

00:29:03,040 --> 00:29:04,920
and what is the Ruby, or, sorry, what is

00:29:04,920 --> 00:29:07,460
the Ruby implementation allowed to do and what is

00:29:07,460 --> 00:29:09,730
it not allowed to do?

00:29:09,730 --> 00:29:11,620
So I had, there has been some discussion about

00:29:11,620 --> 00:29:15,820
this. It also means we need better APIs with

00:29:15,820 --> 00:29:19,120
new things and supports to do this, because we

00:29:19,120 --> 00:29:21,970
want to be able to build libraries that, as

00:29:21,970 --> 00:29:25,430
a Ruby developer, you could just pick up and

00:29:25,430 --> 00:29:27,040
use. If you don't want to be that garbage

00:29:27,040 --> 00:29:29,670
collector, you just want to say I need a

00:29:29,670 --> 00:29:31,110
thread-safe cache.

00:29:31,110 --> 00:29:33,700
And there already are APIs, there are gems that

00:29:33,700 --> 00:29:36,520
provide that, but I think it would be nice

00:29:36,520 --> 00:29:39,330
to see that in Ruby and defined as a,

00:29:39,330 --> 00:29:41,560
as a functionality in Ruby.

00:29:41,560 --> 00:29:46,440
So, so bringing back this commit of, of, of

00:29:46,440 --> 00:29:50,270
two years ago, I don't know, it's. I don't

00:29:50,270 --> 00:29:53,190
-- maybe it's not very readable, but down at

00:29:53,190 --> 00:29:56,810
the bottom you see, we're actually updating it, globally

00:29:56,810 --> 00:29:59,880
shared cache object with a new entry. So actually

00:29:59,880 --> 00:30:04,510
the fix was something where we needed to synchronize,

00:30:04,510 --> 00:30:08,440
because otherwise, another threat would see a half-finished cache

00:30:08,440 --> 00:30:11,380
entry, and it would just crash.

00:30:11,380 --> 00:30:13,380
And it's one of those bugs where you're looking

00:30:13,380 --> 00:30:15,780
at code and staring at it and just running

00:30:15,780 --> 00:30:19,710
it and once every while it crashes, and you're

00:30:19,710 --> 00:30:22,220
scratching your head. Because the moment you're down in

00:30:22,220 --> 00:30:25,040
your debugger, everything looks fine, because a few tenths

00:30:25,040 --> 00:30:27,540
of seconds have passed, a few seconds are an

00:30:27,540 --> 00:30:30,810
eternity for a CPU. It has already flushed everything

00:30:30,810 --> 00:30:34,270
and synchronized everything back up. And you're like, why

00:30:34,270 --> 00:30:36,480
did this happen?

00:30:36,480 --> 00:30:39,570
So this is the story a bit about how

00:30:39,570 --> 00:30:44,870
I went through this, the things I've learned, and

00:30:44,870 --> 00:30:46,810
I think it's important for the room and Ruby

00:30:46,810 --> 00:30:49,770
community to think about what is the level of

00:30:49,770 --> 00:30:53,530
learning and what are the things here we want

00:30:53,530 --> 00:30:57,040
to solve for Rubyists, and what are the things

00:30:57,040 --> 00:30:58,770
we don't want to solve.

00:30:58,770 --> 00:31:00,790

YouTube URL: https://www.youtube.com/watch?v=763KOr7LU9Y


