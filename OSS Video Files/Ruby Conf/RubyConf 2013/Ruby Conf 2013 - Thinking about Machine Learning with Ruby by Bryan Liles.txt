Title: Ruby Conf 2013 - Thinking about Machine Learning with Ruby by Bryan Liles
Publication date: 2020-01-27
Playlist: RubyConf 2013
Description: 
	Not sure where to cluster or where to classify? Have you seen a linear regression lately? Every wanted to take a look into machine learning? Curious to what problems you can solve? Using Ruby to become familiar with machine learning and data-mining techniques is great way to get acclimated before diving in with both feet.

Help us caption & translate this video!

http://amara.org/v/FG4x/
Captions: 
	00:00:16,000 --> 00:00:19,500
BRYAN LILES: So, hello. Welcome. I'm Professor Liles.

00:00:19,580 --> 00:00:22,150
You can address me as Professor Liles.

00:00:22,150 --> 00:00:26,529
And this is CD-612 - A Data Mining Exploration.

00:00:26,529 --> 00:00:32,529
Get out here. There we go. And the objectives

00:00:32,529 --> 00:00:35,280
here, and because I'm a professor at a accredited

00:00:35,280 --> 00:00:38,320
university, I'm just gonna read the slides. We're gonna

00:00:38,320 --> 00:00:41,850
explore the facets of machine learning. We're gonna have

00:00:41,850 --> 00:00:44,120
a data scientist check list. We're gonna also talk

00:00:44,120 --> 00:00:47,640
about the practical applications of converse inductive integrals in

00:00:47,640 --> 00:00:49,100
the context of epsilon.

00:00:49,100 --> 00:00:50,750
This is real exciting stuff here.

00:00:50,750 --> 00:00:54,860
There's some prerequisites for this class. Basic understanding of

00:00:54,860 --> 00:00:57,020
statistics. You have to know statistics to do machine

00:00:57,020 --> 00:01:00,760
learning. And data mining. You need to know linear

00:01:00,760 --> 00:01:01,850
algebra. You need to know a little bit of

00:01:01,850 --> 00:01:04,059
calculus. And you also need to have the ability

00:01:04,059 --> 00:01:07,710
to embiggen factorials in a cromulent fashion.

00:01:07,710 --> 00:01:11,930
So let's start off with the review of stuff

00:01:11,930 --> 00:01:14,700
you should know.

00:01:14,700 --> 00:01:17,020
Anyone know what this is? And I feel bad,

00:01:17,020 --> 00:01:18,770
because I gave this, I gave this talk a

00:01:18,770 --> 00:01:20,680
little while ago, and let me - let me

00:01:20,680 --> 00:01:22,290
actually profess this. This is actually supposed to be

00:01:22,290 --> 00:01:25,150
Jeff Prudner's spot. I work with Gus in the

00:01:25,150 --> 00:01:28,369
thunderbolt labs, and he got sick. With some third

00:01:28,369 --> 00:01:30,460
world disease. And we thought it would be best

00:01:30,460 --> 00:01:33,360
if he just not show up.

00:01:33,360 --> 00:01:36,750
We like Guston. We wish Guston the best. And

00:01:36,750 --> 00:01:40,170
I'm stepping in just to help him out. Go

00:01:40,170 --> 00:01:41,280
through the labs.

00:01:41,280 --> 00:01:43,070
So does anyone know what this is, right here,

00:01:43,070 --> 00:01:45,310
besides math?

00:01:45,310 --> 00:01:46,869
By the time I'm done with this talk, you

00:01:46,869 --> 00:01:51,470
will know what this is. Yeah. Math sucks.

00:01:51,470 --> 00:01:55,659
So let's talk about something else. Let's talk about

00:01:55,659 --> 00:01:58,920
some background. This is an introduction to machine learning.

00:01:58,920 --> 00:02:01,560
Machine learning is one of those really overloaded topics

00:02:01,560 --> 00:02:04,640
that I prefer to not use that word. So

00:02:04,640 --> 00:02:07,439
let's not talk about introduction to machine learning.

00:02:07,439 --> 00:02:10,489
Let's talk about an introduction to data mining. Because,

00:02:10,489 --> 00:02:13,129
you know what, statisticians have been data mining for

00:02:13,129 --> 00:02:17,670
the past forty years. This talk is depth versus

00:02:17,670 --> 00:02:20,340
breadth. I'm not gonna go in deep. I'm just

00:02:20,340 --> 00:02:23,000
gonna slide across the top. I think it's better

00:02:23,000 --> 00:02:26,480
for all of us if I do that.

00:02:26,480 --> 00:02:29,390
Let's talk about machine learning or data mining. What

00:02:29,390 --> 00:02:30,879
can we do with this kind of, with this

00:02:30,879 --> 00:02:33,920
kind of technology? Everyone in here has problems that

00:02:33,920 --> 00:02:37,610
can be solved with data mining. I was talking

00:02:37,610 --> 00:02:40,300
to a gentleman earlier from DigitalOcean and he kept

00:02:40,300 --> 00:02:42,489
me, and he was thinking, oh yeah, machine learning.

00:02:42,489 --> 00:02:45,599
I want to be able to detect abuse.

00:02:45,599 --> 00:02:49,310
You can actually have applications of classification to detect

00:02:49,310 --> 00:02:51,580
abuse. What you can do is you can have

00:02:51,580 --> 00:02:54,000
your logs come through, and you can actually start

00:02:54,000 --> 00:02:57,879
classifying your logs as good traffic or bad traffic.

00:02:57,879 --> 00:03:01,319
You see this stuff all the time. Spam assassin

00:03:01,319 --> 00:03:04,360
came out - I think in the 90s.

00:03:04,360 --> 00:03:06,659
This is an application machine learning. You have spam,

00:03:06,659 --> 00:03:08,680
you have ham. So these are the kind of

00:03:08,680 --> 00:03:10,590
problems you can have. And, and I've written things

00:03:10,590 --> 00:03:14,300
in the security context where we were detecting anomalies

00:03:14,300 --> 00:03:16,830
and I didn't know it was machine learning at

00:03:16,830 --> 00:03:19,340
the time because, you know, I learned everything, I

00:03:19,340 --> 00:03:21,060
got a internet degree - that's about what I

00:03:21,060 --> 00:03:24,489
have. So I learned it all off of wikipedia.

00:03:24,489 --> 00:03:25,849
I don't know it was machine learning, but come

00:03:25,849 --> 00:03:27,569
to find out these are kind of things we're

00:03:27,569 --> 00:03:29,799
gonna talk about in machine learning. One thing I

00:03:29,799 --> 00:03:31,220
need to tell you about is I'm gonna, I

00:03:31,220 --> 00:03:34,170
might use these words supervised versus unsupervised in machine

00:03:34,170 --> 00:03:36,060
learning. This is very simple.

00:03:36,060 --> 00:03:38,069
You'll see people talk about, this is an unsupervised

00:03:38,069 --> 00:03:42,250
algorithm. This is a supervised algorithm. This is very

00:03:42,250 --> 00:03:44,730
simple. In machine learning, you can train, you can

00:03:44,730 --> 00:03:48,269
train these models your algorithms with data. There is

00:03:48,269 --> 00:03:51,159
supervised. Or you can have a model that can

00:03:51,159 --> 00:03:55,409
actually gain inference just by applying the data. That's

00:03:55,409 --> 00:03:56,140
unsupervised.

00:03:56,140 --> 00:03:57,599
Simple, simple.

00:03:57,599 --> 00:04:01,280
I work at Thunderbolt Labs. They're pretty awesome. You

00:04:01,280 --> 00:04:04,810
guys should at least go to our website. Actually,

00:04:04,810 --> 00:04:08,349
yeah, go to our website, because yeah, our website's,

00:04:08,349 --> 00:04:10,560
I'm pretty proud of it because-

00:04:10,560 --> 00:04:16,709
Let's see here, where are we? All right. Ah,

00:04:16,709 --> 00:04:20,829
someone put my face on it.

00:04:20,829 --> 00:04:27,120
So yeah. Anything with my face on it has

00:04:27,120 --> 00:04:29,970
got to be awesome. I'm bryanl on Twitter, and

00:04:29,970 --> 00:04:32,530
the standard disclaimer is I do not represent Thunderbolt

00:04:32,530 --> 00:04:34,750
Labs. Except for I do.

00:04:34,750 --> 00:04:39,830
I do use bold, vulgar words. I'm never misogynistic

00:04:39,830 --> 00:04:41,900
or anything like that, but I might offend you.

00:04:41,900 --> 00:04:46,919
So follow with me with, just, be careful.

00:04:46,919 --> 00:04:51,500
And Thunderbolt Labs here, @thunderboltlabs. Follow us. We Tweet

00:04:51,500 --> 00:04:54,990
there sometimes. Here's a really cool thing. And this

00:04:54,990 --> 00:04:56,759
is me getting on my soapbox and stepping on

00:04:56,759 --> 00:04:58,340
machine learning for just a couple seconds.

00:04:58,340 --> 00:05:00,800
You see at the bottom of RubyConf's website, we

00:05:00,800 --> 00:05:02,770
are actually sponsoring as a gold sponsor at RubyConf

00:05:02,770 --> 00:05:05,470
this year. And I'll tell you the reason why.

00:05:05,470 --> 00:05:07,720
I've been - this is my eighth RubyConf. I

00:05:07,720 --> 00:05:09,840
am not an old-timer, which is crazy. I've been

00:05:09,840 --> 00:05:11,300
coming to RubyConf for eight years and I'm not

00:05:11,300 --> 00:05:13,520
an old-timer. Never once have I, as a black

00:05:13,520 --> 00:05:18,850
guy, felt intimidated by anyone at any talk at

00:05:18,850 --> 00:05:21,070
any time. So any one saying that RubyConf isn't

00:05:21,070 --> 00:05:24,210
diverse is out of their mind. So off my

00:05:24,210 --> 00:05:25,220
soap box.

00:05:25,220 --> 00:05:30,410
And let's move on.

00:05:30,410 --> 00:05:33,539
So let's talk about required knowledge for machine learning.

00:05:33,539 --> 00:05:35,220
There's a couple things you're gonna need to know.

00:05:35,220 --> 00:05:37,930
You are gonna have to know math. I've presented

00:05:37,930 --> 00:05:40,300
that equation earlier, which was actually an equation for

00:05:40,300 --> 00:05:44,270
k-means clustering. Actually really simple when I explain it

00:05:44,270 --> 00:05:45,389
to you.

00:05:45,389 --> 00:05:46,720
You will have to know math. You will have

00:05:46,720 --> 00:05:47,910
to know a little bit of Calculus. You will

00:05:47,910 --> 00:05:49,400
have to know a little bit of algebra. You

00:05:49,400 --> 00:05:51,430
might have to dive into statistics. You will need

00:05:51,430 --> 00:05:53,789
to know these things. But guess what? There is

00:05:53,789 --> 00:05:56,250
easy ways to learn this kind of stuff.

00:05:56,250 --> 00:05:58,800
You will have to read papers. And I'm, I'm

00:05:58,800 --> 00:06:01,000
not a fan of papers because I- I went

00:06:01,000 --> 00:06:03,580
to ClojureConf last year, and every talk was like,

00:06:03,580 --> 00:06:08,550
so I read this paper. Whoa! I mean this

00:06:08,550 --> 00:06:09,800
is a good paper right here. This is a

00:06:09,800 --> 00:06:13,389
paper on transactional memory. This is STM. This is

00:06:13,389 --> 00:06:16,139
one of the tenants of Clojure. And it's actually

00:06:16,139 --> 00:06:18,039
pretty famous - it's actually pretty crafty. Cause look

00:06:18,039 --> 00:06:20,210
at it. Look at the authors. They're like, wow,

00:06:20,210 --> 00:06:22,319
we're not even gonna put two emails on here.

00:06:22,319 --> 00:06:26,389
We're gonna put them in little curly brackets.

00:06:26,389 --> 00:06:27,960
You will have to read papers. But you know

00:06:27,960 --> 00:06:29,580
what, there's nothing wrong. A little tech in your

00:06:29,580 --> 00:06:32,210
life never hurt anyone.

00:06:32,210 --> 00:06:34,669
You're gonna have to have persistence. This is the

00:06:34,669 --> 00:06:39,009
interesting science. There are different facets of machine learning,

00:06:39,009 --> 00:06:40,199
and depending on who you talk to - you

00:06:40,199 --> 00:06:42,770
could talk to a statistician, versus more of an

00:06:42,770 --> 00:06:46,009
applied math, math, an applied mathematician, you're gonna get

00:06:46,009 --> 00:06:47,830
different answers about what machine learning is.

00:06:47,830 --> 00:06:49,919
You're just got to be very persistent in the

00:06:49,919 --> 00:06:53,389
whole entire topic. Because, guess what? This is hard.

00:06:53,389 --> 00:06:55,330
So let's get started.

00:06:55,330 --> 00:06:58,090
And today I'm going to introduce three topics. Regression,

00:06:58,090 --> 00:07:01,949
classification, and clustering. These are three of the bigger

00:07:01,949 --> 00:07:04,139
tenants of machine learning, and you can solve all

00:07:04,139 --> 00:07:05,860
the problems. I'm here to solve all your problems

00:07:05,860 --> 00:07:07,199
today.

00:07:07,199 --> 00:07:10,169
So let's talk about regression.

00:07:10,169 --> 00:07:12,139
Yes.

00:07:12,139 --> 00:07:14,870
So does anyone know what regression is? Besides black

00:07:14,870 --> 00:07:17,669
guy in the back? Anyone else? Anyone else? You

00:07:17,669 --> 00:07:20,199
guys know what regression is?

00:07:20,199 --> 00:07:22,310
Regression is a weird word to me. Cause, you

00:07:22,310 --> 00:07:23,789
know what, I take, I take the base of

00:07:23,789 --> 00:07:27,729
this word, regress, and, and regressions really are not

00:07:27,729 --> 00:07:30,810
regressing. Regressions are really just trying to figure out,

00:07:30,810 --> 00:07:33,020
you're trying to predict the value of something given

00:07:33,020 --> 00:07:33,590
some data.

00:07:33,590 --> 00:07:36,650
A good example of, of regression would be, you

00:07:36,650 --> 00:07:39,349
have a list of data of housing prices, of

00:07:39,349 --> 00:07:40,990
houses being sold, and you know that the house

00:07:40,990 --> 00:07:44,680
for $100,000 had 1,000 square feet and two bedrooms

00:07:44,680 --> 00:07:47,870
and the house had, that sold for $150,000 had

00:07:47,870 --> 00:07:51,690
1,500 feet and three bedrooms. And you have many,

00:07:51,690 --> 00:07:53,060
many samples of this.

00:07:53,060 --> 00:07:54,440
So what you can actually do is you can

00:07:54,440 --> 00:07:57,660
take this data and you can actually somewhat accurately

00:07:57,660 --> 00:08:01,979
predict price based on common criteria.

00:08:01,979 --> 00:08:03,970
But the, we're gonna focus on linear regression. And

00:08:03,970 --> 00:08:06,470
what linear regression is, is basically we're just going

00:08:06,470 --> 00:08:10,229
to have it move laterally.

00:08:10,229 --> 00:08:11,620
So let's talk about this. Does anyone know what

00:08:11,620 --> 00:08:13,449
that at the top is? What that equation is

00:08:13,449 --> 00:08:15,169
at the top?

00:08:15,169 --> 00:08:19,190
It's the slop of a line, yes. And actually

00:08:19,190 --> 00:08:20,449
here's a problem that I have, and I have,

00:08:20,449 --> 00:08:23,020
I have a huge problem with mathematics in general.

00:08:23,020 --> 00:08:26,470
When you are taught this in middle school, I

00:08:26,470 --> 00:08:29,449
think you learn one slope formula in middle school,

00:08:29,449 --> 00:08:30,919
you were not taught anything that looks like this.

00:08:30,919 --> 00:08:33,310
You were taught something that looks more like y

00:08:33,310 --> 00:08:36,240
equals mx plus b. And they have y equals

00:08:36,240 --> 00:08:38,469
alpha plus beta x. Come on. This is the

00:08:38,469 --> 00:08:39,690
problem I have with mathematics.

00:08:39,690 --> 00:08:41,610
Depending on the branch of mathematics you're in, they

00:08:41,610 --> 00:08:44,550
will actually use different symbols for the same thing.

00:08:44,550 --> 00:08:47,640
Talk about persistence. Just gotta bare with these guys.

00:08:47,640 --> 00:08:50,410
And for doing regressions, all you're going to do

00:08:50,410 --> 00:08:54,640
is solve this equation. Come on - this is

00:08:54,640 --> 00:08:57,350
simple. You're just, you're minimizing the functioning tube of

00:08:57,350 --> 00:09:00,120
a and b, or alpha, beta, where the functioning

00:09:00,120 --> 00:09:05,339
two alpha, beta equals e squigly e with another

00:09:05,339 --> 00:09:09,700
kind of e with a hat. It has a

00:09:09,700 --> 00:09:12,560
hat. Why does it have a hat?

00:09:12,560 --> 00:09:15,140
All right. This is funny.

00:09:15,140 --> 00:09:17,950
Really all you're trying to do is, is this.

00:09:17,950 --> 00:09:19,709
So talk about the line slope formula. You have

00:09:19,709 --> 00:09:21,730
y equals mx plus b, and then I just

00:09:21,730 --> 00:09:24,519
go through the permutations to get to y equals

00:09:24,519 --> 00:09:29,880
beta of chai plus alpha.

00:09:29,880 --> 00:09:32,399
Really all you're doing, is you're drawing a line.

00:09:32,399 --> 00:09:34,029
And what you're going to do in this line,

00:09:34,029 --> 00:09:35,410
and I'll show you in a second.

00:09:35,410 --> 00:09:37,310
First you're gonna take this data, and actually this

00:09:37,310 --> 00:09:39,769
data right here is - I, I, I just

00:09:39,769 --> 00:09:42,820
went for linear, I looked, looked on the internet.

00:09:42,820 --> 00:09:48,080
I used Google for linear regression data sets. And

00:09:48,080 --> 00:09:50,170
I come across this cool one of the size

00:09:50,170 --> 00:09:53,740
of brain, the body weight, versus the size of

00:09:53,740 --> 00:09:55,830
a brain. And I plotted. Because that's what you

00:09:55,830 --> 00:09:56,870
do. You plot stuff.

00:09:56,870 --> 00:09:58,680
I'm just use gonna plot here [00:09:58]. This is

00:09:58,680 --> 00:10:00,279
not Ruby. Sorry there's no Ruby yet in this

00:10:00,279 --> 00:10:03,190
talk. But I, I just plotted this data. And

00:10:03,190 --> 00:10:05,660
this is a very interesting data set, because it

00:10:05,660 --> 00:10:07,320
says that it was, it says that it was

00:10:07,320 --> 00:10:11,640
a real data set, but I don't know. Because

00:10:11,640 --> 00:10:13,660
if you look over here, I mean. I got

00:10:13,660 --> 00:10:15,380
a big brain. I'm not gonna lie. I'm a

00:10:15,380 --> 00:10:18,200
smart dude. But jees.

00:10:18,200 --> 00:10:20,709
I want to meet this person right here.

00:10:20,709 --> 00:10:24,760
In a linear regression, well all you're trying to

00:10:24,760 --> 00:10:27,350
do is find, is trying to draw a line

00:10:27,350 --> 00:10:29,990
that actually goes through the middle of all this

00:10:29,990 --> 00:10:32,360
data. And it's like, well, we can infer that

00:10:32,360 --> 00:10:34,970
pretty easily as humans because we're, we're linear regression

00:10:34,970 --> 00:10:36,070
monsters.

00:10:36,070 --> 00:10:39,110
But how do you do that mathemet- or algorithmically?

00:10:39,110 --> 00:10:40,410
So what you're trying to do is you're trying

00:10:40,410 --> 00:10:42,279
to calculate something called the error, and what this,

00:10:42,279 --> 00:10:44,940
what that is is the error is the distance

00:10:44,940 --> 00:10:47,640
between a point and a line. Remember before when

00:10:47,640 --> 00:10:49,730
we were, that minimizing function?

00:10:49,730 --> 00:10:51,910
You're just trying to find a line that minimizes

00:10:51,910 --> 00:10:55,470
the distance between this and this for all the

00:10:55,470 --> 00:10:58,300
points on here. This is not the right answer.

00:10:58,300 --> 00:11:00,769
And just to simplify that a little bit more,

00:11:00,769 --> 00:11:03,100
this is all you're doing. You're just basically trying

00:11:03,100 --> 00:11:05,079
to find the line that is between the middle

00:11:05,079 --> 00:11:06,430
of all those points. And we can do it

00:11:06,430 --> 00:11:07,160
with math.

00:11:07,160 --> 00:11:10,089
But better yet, we can do it with Ruby.

00:11:10,089 --> 00:11:11,620
And I put code slides in so I could

00:11:11,620 --> 00:11:13,839
actually remember to go to my code. So let

00:11:13,839 --> 00:11:16,390
me hide this bad boy. And there's that pretty

00:11:16,390 --> 00:11:17,200
guy again.

00:11:17,200 --> 00:11:19,240
AUDIENCE: [whistles, cat-calls]

00:11:19,240 --> 00:11:24,070
B.L.: You know what, I like this jacket. There

00:11:24,070 --> 00:11:27,899
we go. We'll just mirror to this place of

00:11:27,899 --> 00:11:29,820
getting, little difficult for me to look backwards.

00:11:29,820 --> 00:11:32,320
So you know what happens is, I had never

00:11:32,320 --> 00:11:36,130
given this talk with mavericks. And Mavericks would get

00:11:36,130 --> 00:11:39,890
you - it's nice but it'll get you.

00:11:39,890 --> 00:11:42,779
So we're talking about regression. So what I've done

00:11:42,779 --> 00:11:45,010
here is I've provided some examples, and we will

00:11:45,010 --> 00:11:47,839
look- let's look at the Ruby code. No, actually,

00:11:47,839 --> 00:11:49,589
let's look at the, the new pot code first,

00:11:49,589 --> 00:11:52,220
[00:11:50] because this is new pot conf, right. Let's

00:11:52,220 --> 00:11:55,800
look at some gnew plot.

00:11:55,800 --> 00:11:58,360
So I'm using vem this week. If you know

00:11:58,360 --> 00:12:03,180
me I actually, I use a lot of editors.

00:12:03,180 --> 00:12:06,240
And I know this is a Confreaks talk, and

00:12:06,240 --> 00:12:09,389
there's sometimes some, some like clipping on the sides,

00:12:09,389 --> 00:12:12,529
so what I'm going to do is move this

00:12:12,529 --> 00:12:16,329
slightly over so we can see everything.

00:12:16,329 --> 00:12:19,209
So. So let's look at this regression. So what

00:12:19,209 --> 00:12:21,700
it is, is I've written some, some gnew plat

00:12:21,700 --> 00:12:24,370
code, and really all I'm doing is making a

00:12:24,370 --> 00:12:28,070
ping called brain dot ping, and I'm taking, I've

00:12:28,070 --> 00:12:30,380
just setting the x labels and the y labels

00:12:30,380 --> 00:12:32,430
and I'm setting in a grid and I'm plotting

00:12:32,430 --> 00:12:34,320
the second and third columns of this brain dot

00:12:34,320 --> 00:12:35,329
csv.

00:12:35,329 --> 00:12:37,350
Simple, simple.

00:12:37,350 --> 00:12:40,570
So when I run this gnew plot, and this

00:12:40,570 --> 00:12:42,579
is how you run gnew plot stuff, you don't

00:12:42,579 --> 00:12:46,540
even need to type that crap in. And I

00:12:46,540 --> 00:12:48,940
did it, and it ran really fast cause it's

00:12:48,940 --> 00:12:51,029
not Ruby - I'm just kidding.

00:12:51,029 --> 00:12:53,769
And I plot, I type plotted that. So let's

00:12:53,769 --> 00:12:56,170
go one step further. If I want to actually

00:12:56,170 --> 00:12:58,260
- let's, let's see if we can do this

00:12:58,260 --> 00:13:02,170
in Ruby. So, so if we look in this

00:13:02,170 --> 00:13:06,860
regression dot rb - there we go. This is

00:13:06,860 --> 00:13:10,339
actually the code for doing regressions in, in Ruby.

00:13:10,339 --> 00:13:13,260
And what you'll notice here is that we have

00:13:13,260 --> 00:13:15,839
this y-intercept, and we have this slope that mx

00:13:15,839 --> 00:13:18,570
and the b part. And we're just calculating those.

00:13:18,570 --> 00:13:21,220
I actually was gonna write this code, but I

00:13:21,220 --> 00:13:24,079
just searched for simple linear regression in Ruby and

00:13:24,079 --> 00:13:26,170
there was a gist for it. So guess what?

00:13:26,170 --> 00:13:29,870
Our wall - here's your credit.

00:13:29,870 --> 00:13:32,730
Why write code that's already been written? So all

00:13:32,730 --> 00:13:34,750
it does, it does the same thing, and at

00:13:34,750 --> 00:13:37,690
the end, I like to call this train Ruby,

00:13:37,690 --> 00:13:40,380
because you'll notice that I usually start in classes

00:13:40,380 --> 00:13:42,839
and I end in just a mess. And the

00:13:42,839 --> 00:13:44,519
reason why is because I wrote this on a

00:13:44,519 --> 00:13:47,459
train and I was like, typing and then I

00:13:47,459 --> 00:13:50,310
start looking out the window and got distracted. Yeah.

00:13:50,310 --> 00:13:51,940
AUDIENCE: Ruby in Rails.

00:13:51,940 --> 00:13:54,389
B.L.: Yeah, this is my, yeah. So this is

00:13:54,389 --> 00:13:56,589
actually, this file is not too bad. There's only

00:13:56,589 --> 00:13:58,630
like ten lines at the bottom that are kind

00:13:58,630 --> 00:14:04,800
of crazy. So we'll run this. Regression one dot

00:14:04,800 --> 00:14:05,170
rb.

00:14:05,170 --> 00:14:07,320
And really what we're looking for are this, if

00:14:07,320 --> 00:14:08,880
you want to plot the line you just need

00:14:08,880 --> 00:14:10,250
the slope and the y-intercept. So we have this

00:14:10,250 --> 00:14:12,680
number six point six four and six point six

00:14:12,680 --> 00:14:14,769
seven. Can someone remember those numbers for me please?

00:14:14,769 --> 00:14:17,440
Cause I'm gonna ask for them in a second.

00:14:17,440 --> 00:14:21,019
And then what we'll do is, because, what we'll

00:14:21,019 --> 00:14:24,940
do, the last thing we'll do, is we'll actually

00:14:24,940 --> 00:14:27,130
look in the second regression text file that I

00:14:27,130 --> 00:14:29,019
have here. This is more of the new plot

00:14:29,019 --> 00:14:33,209
code. And what it's actually doing is, gnew plot

00:14:33,209 --> 00:14:36,209
has linear regression built in. So we'll just use

00:14:36,209 --> 00:14:39,380
theirs. And what their- and all I'm doing is

00:14:39,380 --> 00:14:41,790
instead of writing tests, the message is just, I'm

00:14:41,790 --> 00:14:44,740
using gnew plot to actually figure out, or tell

00:14:44,740 --> 00:14:46,750
me if I have the right answer.

00:14:46,750 --> 00:14:47,820
So if we look at the bottom of this

00:14:47,820 --> 00:14:50,160
file, we have an m and a b, right

00:14:50,160 --> 00:14:51,779
here. And gnew plot does a whole bunch of

00:14:51,779 --> 00:14:54,490
the craziest things too, but, we actually told it

00:14:54,490 --> 00:14:54,949
to fit the data.

00:14:54,949 --> 00:14:56,610
And you'll notice the number here is six point

00:14:56,610 --> 00:14:59,850
six two and six point eight eight. Close to

00:14:59,850 --> 00:15:01,699
our numbers. I mean our numbers could have been

00:15:01,699 --> 00:15:03,399
better. These numbers are actually a lot better because

00:15:03,399 --> 00:15:06,970
gnew plot actually goes through and figures out if,

00:15:06,970 --> 00:15:08,779
first if the data's linear, and also it gives

00:15:08,779 --> 00:15:11,360
you error numbers. So this is actually the real

00:15:11,360 --> 00:15:13,269
answer, but our Ruby code is pretty close.

00:15:13,269 --> 00:15:17,480
And that brings me to a little point here.

00:15:17,480 --> 00:15:18,550
You will not do a lot of machine learning

00:15:18,550 --> 00:15:22,500
in Ruby. But because group Ruby is so approachable,

00:15:22,500 --> 00:15:24,380
and so easy to use, Ruby is a great

00:15:24,380 --> 00:15:26,540
learning, language to learn how to do machine learning

00:15:26,540 --> 00:15:28,269
before we get to go plot some more later.

00:15:28,269 --> 00:15:30,410
So just to show you one more thing, we'll

00:15:30,410 --> 00:15:36,329
plot the output of our, we'll plot the outputs

00:15:36,329 --> 00:15:39,889
of our files here, and. OK.

00:15:39,889 --> 00:15:45,560
And we'll open brain regression and there's our, that's

00:15:45,560 --> 00:15:47,800
our file. This is from gnew plot. And we'll

00:15:47,800 --> 00:15:54,800
open brain_regression_ruby. And there you go. They look similar.

00:15:55,139 --> 00:15:56,529
Actually we'll put them right next to each other

00:15:56,529 --> 00:16:00,519
so you can inspect for yourself. Simple linear regression

00:16:00,519 --> 00:16:02,810
in Ruby. This code will be on GitHub, or

00:16:02,810 --> 00:16:04,240
actually is on GitHub. You probably can find it

00:16:04,240 --> 00:16:07,259
now if you're, you know, I'm BryanL. But you'll

00:16:07,259 --> 00:16:09,649
notice that these are the same.

00:16:09,649 --> 00:16:12,120
And one's with Ruby and one's with, and one's

00:16:12,120 --> 00:16:14,709
with gnew plot. And this is how simply, and

00:16:14,709 --> 00:16:16,690
you'll notice if we go back to our file

00:16:16,690 --> 00:16:22,649
here, linear regression one dot ruby.

00:16:22,649 --> 00:16:27,389
It's not many lines. Actually it's, it's like forty-seven

00:16:27,389 --> 00:16:31,449
lines. Let's say it's forty-two lines. It's forty-two lines.

00:16:31,449 --> 00:16:35,070
So that's regression. And when I, what I've basically

00:16:35,070 --> 00:16:38,259
shown you is that it's easy in Ruby to

00:16:38,259 --> 00:16:40,740
plot lines and, because you can plot lines you

00:16:40,740 --> 00:16:42,519
can do simple linear regression.

00:16:42,519 --> 00:16:44,940
Let's talk about classification next. And before we talk

00:16:44,940 --> 00:16:47,269
about classification, I want to show you something here.

00:16:47,269 --> 00:16:50,509
I'll go to my web-browser - that guy, keeps

00:16:50,509 --> 00:16:51,959
on coming back.

00:16:51,959 --> 00:16:55,130
I want to show you something. There we go.

00:16:55,130 --> 00:16:57,070
Let's make this a little bit smaller. My computer's

00:16:57,070 --> 00:17:00,600
pretty smart. I, I wrote this Sinatra app called

00:17:00,600 --> 00:17:04,169
the number game, and I'll, and I'll reload it

00:17:04,169 --> 00:17:06,169
a couple times so you can see what's going

00:17:06,169 --> 00:17:13,169
on. So here's once. Here's again. And so what's

00:17:13,829 --> 00:17:16,100
happening here is there's a dataset called the inthis

00:17:16,100 --> 00:17:18,679
dataset, and all it is is a collection of

00:17:18,679 --> 00:17:21,610
60,000 hand-written numbers. And what I did was I

00:17:21,610 --> 00:17:24,169
wrote a simple app to actually go through and

00:17:24,169 --> 00:17:25,189
recognize numbers.

00:17:25,189 --> 00:17:28,350
Simple application on machine learning. This is what you

00:17:28,350 --> 00:17:32,750
call classification. We are classifying these bit, these pixels

00:17:32,750 --> 00:17:35,910
as a number. And, you notice that for most

00:17:35,910 --> 00:17:41,530
part, I believe that this classifier is sixty-five percent,

00:17:41,530 --> 00:17:45,750
maybe seventy-five percent correct. I don't really remember.

00:17:45,750 --> 00:17:48,280
So how do we do stuff like this? Well

00:17:48,280 --> 00:17:51,470
first of all, with classification, let's just go back

00:17:51,470 --> 00:17:52,750
to my slides.

00:17:52,750 --> 00:17:56,590
How do we classify? Well, a classification, classification's actually

00:17:56,590 --> 00:17:59,110
really simple. We're basically doing the same thing we're

00:17:59,110 --> 00:18:03,049
doing in regression, but we have way more dimensions.

00:18:03,049 --> 00:18:06,210
So in that, in that other file here we

00:18:06,210 --> 00:18:08,510
have an image, and this image I do know

00:18:08,510 --> 00:18:10,260
is 28 by 28.

00:18:10,260 --> 00:18:12,840
And I gave this talk before, I asked somebody,

00:18:12,840 --> 00:18:18,169
does anyone know what 28 by 28 is? 28

00:18:18,169 --> 00:18:20,010
times 28?

00:18:20,010 --> 00:18:22,570
When I was in Boston, someone yelled the answer

00:18:22,570 --> 00:18:25,260
out before I finished typing it. He must have

00:18:25,260 --> 00:18:26,210
a special mind.

00:18:26,210 --> 00:18:30,000
But it's, so, this, this particular file has 784

00:18:30,000 --> 00:18:35,700
pixels. So, that we have 784 pix- 784 features

00:18:35,700 --> 00:18:37,880
that we can classify this document against. And really

00:18:37,880 --> 00:18:40,570
what we're doing is we're, in memory, just drawing

00:18:40,570 --> 00:18:43,270
a line and trying to find out, we're just

00:18:43,270 --> 00:18:45,919
predicting, basically, what our image is.

00:18:45,919 --> 00:18:49,370
So without further ado, this is RubyConf. Let's see

00:18:49,370 --> 00:18:50,750
some code.

00:18:50,750 --> 00:18:54,900
Let's see, classification.

00:18:54,900 --> 00:18:57,990
So what I have here, I'm actually gonna run

00:18:57,990 --> 00:18:59,400
- I wrote this classifier. I'll run it real

00:18:59,400 --> 00:19:01,020
quick and then I'll show you what's in there.

00:19:01,020 --> 00:19:02,919
SO what it's doing is I have sixty thousand

00:19:02,919 --> 00:19:05,080
images that are twenty eight by twenty eight, and

00:19:05,080 --> 00:19:06,950
I have sixty thousand labels, and that's the reason

00:19:06,950 --> 00:19:09,190
I know is I'm right or- that's what I

00:19:09,190 --> 00:19:09,880
know what it is.

00:19:09,880 --> 00:19:12,330
Because it, the data is labeled.

00:19:12,330 --> 00:19:13,320
What I'm doing right now is I'm running a

00:19:13,320 --> 00:19:15,440
trainer on it. And in this case, I'm using

00:19:15,440 --> 00:19:18,190
something called support, support vector machines. I find this

00:19:18,190 --> 00:19:20,020
easier to use it and then tell you what

00:19:20,020 --> 00:19:22,200
it is. So really what I'm doing here, is

00:19:22,200 --> 00:19:25,720
I'm classifying this data using a support vector machine.

00:19:25,720 --> 00:19:28,250
And then I'm predicting the data. So I have

00:19:28,250 --> 00:19:30,860
a sixty thousand dollar- or, sixty thousand, a sixty

00:19:30,860 --> 00:19:34,289
thousand count training set convert - this is supervised

00:19:34,289 --> 00:19:40,660
learning. And I have a ten thousand count test

00:19:40,660 --> 00:19:42,510
set. And what it's doing now is it's actually

00:19:42,510 --> 00:19:47,120
going through and seeing how accurate the classifier was.

00:19:47,120 --> 00:19:49,480
And what we find here is that I'm only

00:19:49,480 --> 00:19:51,080
about sixty-five percent accurate.

00:19:51,080 --> 00:19:53,010
And, and the reason why is because you would

00:19:53,010 --> 00:19:54,910
actually, I would actually have to go through, if

00:19:54,910 --> 00:19:57,160
I can actually train all sixty thousand of those

00:19:57,160 --> 00:19:59,630
things, and Ruby, because of my global interpreter block,

00:19:59,630 --> 00:20:02,400
I only have one core of usage. So I

00:20:02,400 --> 00:20:04,419
actually tried to do it - I stopped three

00:20:04,419 --> 00:20:06,490
days cause it was just so slow, cause it

00:20:06,490 --> 00:20:08,059
was just using one core.

00:20:08,059 --> 00:20:12,990
Really, but what it's doing is actually, is going

00:20:12,990 --> 00:20:15,530
through and it's saying, this is the name. The

00:20:15,530 --> 00:20:18,059
computer says, OK. I know that. This is a

00:20:18,059 --> 00:20:20,250
four. OH, that's a nice four. I know that.

00:20:20,250 --> 00:20:22,309
This is the four. And then they're all looking

00:20:22,309 --> 00:20:23,760
different. And when I go back through with the

00:20:23,760 --> 00:20:26,400
test set, all I'm doing is going, then, is

00:20:26,400 --> 00:20:28,039
saying well I think this is, and I think

00:20:28,039 --> 00:20:29,100
this is.

00:20:29,100 --> 00:20:32,780
So let's look at some more train Ruby. So

00:20:32,780 --> 00:20:35,090
this is, and I'll show you a good example

00:20:35,090 --> 00:20:37,440
of this. I was really into this code when

00:20:37,440 --> 00:20:38,909
I was starting and what I - I'll just

00:20:38,909 --> 00:20:40,250
go through and I'll talk about it. I have

00:20:40,250 --> 00:20:41,980
a data set, and then I have this loader

00:20:41,980 --> 00:20:44,390
which actually just loads the data from the files.

00:20:44,390 --> 00:20:46,890
The files, it's a binary format and it's called

00:20:46,890 --> 00:20:49,419
gsub, so ignore all this.

00:20:49,419 --> 00:20:50,530
And then what I do is I load the

00:20:50,530 --> 00:20:52,470
labels, and the labels are along with the file

00:20:52,470 --> 00:20:54,580
and it basically says this blob of data is

00:20:54,580 --> 00:20:57,169
a four, this blob of data is a five.

00:20:57,169 --> 00:20:59,280
And then I start looking out the window on

00:20:59,280 --> 00:21:02,030
the train.

00:21:02,030 --> 00:21:04,049
So really what I've done here is, so the

00:21:04,049 --> 00:21:06,140
line at the top is I'm, I'm basically setting

00:21:06,140 --> 00:21:08,900
a timer and I'm loading the data and then

00:21:08,900 --> 00:21:11,510
I'm, I'm actually going through and I'm using something

00:21:11,510 --> 00:21:13,710
called libsvm, which I'll talk about in a second.

00:21:13,710 --> 00:21:16,350
And I'm classifying all the data. This is a

00:21:16,350 --> 00:21:19,740
really, really important lesson. If anyone in here is

00:21:19,740 --> 00:21:24,559
writing machine learning algorithms, you don't belong here. You

00:21:24,559 --> 00:21:28,270
belong doing something very important. We have to, you,

00:21:28,270 --> 00:21:30,260
in machine learning you will stand on the back

00:21:30,260 --> 00:21:32,690
of giants. You will not write machine learning code.

00:21:32,690 --> 00:21:35,120
You will use things like shark and spark.

00:21:35,120 --> 00:21:37,130
Or you will use mahout, or you will use

00:21:37,130 --> 00:21:39,500
libsvm, or you will use ar4r, but you will

00:21:39,500 --> 00:21:41,850
not write this code. And I'm, what I'm doing

00:21:41,850 --> 00:21:43,590
today is I'm trying to introduce that to you

00:21:43,590 --> 00:21:45,530
so that you can see how easy it is

00:21:45,530 --> 00:21:49,770
to write something like this.

00:21:49,770 --> 00:21:52,240
This took me about twenty minutes to write. Really

00:21:52,240 --> 00:21:54,610
it's just a Sinatra app. Not even, it's not

00:21:54,610 --> 00:21:56,850
even a Rails app. It's a Sinatra app. And

00:21:56,850 --> 00:21:58,990
it just throws an image up and, and that's

00:21:58,990 --> 00:22:01,179
it.

00:22:01,179 --> 00:22:05,280
I'm pretty proud of this. I'm sorry.

00:22:05,280 --> 00:22:10,130
So moving on. So we talked about, we, we're

00:22:10,130 --> 00:22:12,340
talked about - what we did here is linear

00:22:12,340 --> 00:22:15,600
classification. And we use a support vector machine, and

00:22:15,600 --> 00:22:17,460
there was code. I jumped ahead.

00:22:17,460 --> 00:22:19,990
And there's also something called classification with the decision

00:22:19,990 --> 00:22:22,289
tree, and I was gonna talk about this, but

00:22:22,289 --> 00:22:24,429
I was looking through RubyConf talks last year -

00:22:24,429 --> 00:22:26,690
I actually don't go to the talks at RubyConf

00:22:26,690 --> 00:22:27,929
for some reason. But I saw, I actually watched

00:22:27,929 --> 00:22:30,860
this whole talk. This guy, Chris Nelson did a

00:22:30,860 --> 00:22:33,140
talk in Denver at this same conference last year,

00:22:33,140 --> 00:22:34,820
and this is actually a pretty good talk on

00:22:34,820 --> 00:22:37,549
decision trees. He goes to forty minutes on one

00:22:37,549 --> 00:22:39,010
topic, and it's pretty good.

00:22:39,010 --> 00:22:41,970
So basically decision trees are this. You basically learn

00:22:41,970 --> 00:22:45,600
how to divide your data into else clauses. And

00:22:45,600 --> 00:22:46,970
you do it as a tree, and you just

00:22:46,970 --> 00:22:49,360
go down until you get more and more specific.

00:22:49,360 --> 00:22:51,169
You'll find that there's actually software out there that

00:22:51,169 --> 00:22:56,179
builds huge nested trees and that's how they're doing

00:22:56,179 --> 00:22:57,350
their classifications.

00:22:57,350 --> 00:23:01,330
So here, let's talk about clustering. What can we

00:23:01,330 --> 00:23:03,240
use clustering for? Well we can use it to

00:23:03,240 --> 00:23:06,390
group documents. Group like documents. We can use it

00:23:06,390 --> 00:23:08,840
to detect plagiarism.

00:23:08,840 --> 00:23:10,820
This is actually a new part of the talk.

00:23:10,820 --> 00:23:16,250
And I wanted to do some live coding. So

00:23:16,250 --> 00:23:20,440
what I'm going to do here is go backwards

00:23:20,440 --> 00:23:24,780
in my Pry session and there's something called Jacquard's

00:23:24,780 --> 00:23:27,020
constant, or coefficient.

00:23:27,020 --> 00:23:28,710
And what it does is it allows you to

00:23:28,710 --> 00:23:32,049
take a set of data and classify it again

00:23:32,049 --> 00:23:34,059
- or, or compare it against another set of

00:23:34,059 --> 00:23:36,830
data. And basically what we can do with this

00:23:36,830 --> 00:23:38,809
is we can actually do- build a tool that

00:23:38,809 --> 00:23:40,750
can detect plagiarism. And let me show you how

00:23:40,750 --> 00:23:41,870
easy this is.

00:23:41,870 --> 00:23:44,370
Start require Jacquard, and what I went and did

00:23:44,370 --> 00:23:48,000
on the internet is I went and search for

00:23:48,000 --> 00:23:50,860
some text. So what I'm going to do here

00:23:50,860 --> 00:23:52,900
is I'm gonna cut and paste this text on

00:23:52,900 --> 00:23:56,210
this web paste, plagiarize it, and I'm going to

00:23:56,210 --> 00:23:57,970
put it in a variable. And then what I'm

00:23:57,970 --> 00:24:00,059
going to do is make a variable called a

00:24:00,059 --> 00:24:01,169
chunk.

00:24:01,169 --> 00:24:04,580
This is another little quibble I have about Ruby.

00:24:04,580 --> 00:24:05,860
So you have a two, you do a whole

00:24:05,860 --> 00:24:08,850
bunch of underscore case, you can't tell me that

00:24:08,850 --> 00:24:11,840
doesn't look better than this - I'm sorry. I

00:24:11,840 --> 00:24:13,929
like this better. Maybe I, I must have done

00:24:13,929 --> 00:24:15,559
Java and Scala too much.

00:24:15,559 --> 00:24:17,470
But, so what we're going to do is we're

00:24:17,470 --> 00:24:19,870
gonna chunk up that a, so we can do

00:24:19,870 --> 00:24:23,090
a dot split and we can do like this.

00:24:23,090 --> 00:24:29,309
This is what we'll call poor man's nlp. And

00:24:29,309 --> 00:24:33,169
now we have an array with, with our data

00:24:33,169 --> 00:24:35,230
in it. And what we'll do now is we'll

00:24:35,230 --> 00:24:38,600
cop- we'll go down here in another example and

00:24:38,600 --> 00:24:42,350
we'll copy, this is supposedly plagiarized text. So we'll

00:24:42,350 --> 00:24:44,720
just go b equals this - I'll consider it

00:24:44,720 --> 00:24:48,440
a function to do this. I did not.

00:24:48,440 --> 00:24:51,390
And this is live. We're on tv here. So.

00:24:51,390 --> 00:24:53,980
We'll do it all at one time. So now

00:24:53,980 --> 00:24:56,669
we have this. And now for c, I'm just

00:24:56,669 --> 00:25:03,669
gonna say- that's my new paper. So we have

00:25:05,210 --> 00:25:07,720
a, b, c, and we gotta chunk up c

00:25:07,720 --> 00:25:14,720
too into- so, so now what we're going to

00:25:16,870 --> 00:25:19,250
do is, I have to go back here.

00:25:19,250 --> 00:25:25,640
There we go. Is we're going to find which

00:25:25,640 --> 00:25:32,640
two papers match each other. Oh. This is live

00:25:33,510 --> 00:25:38,289
coding, and I'm not cheating this time.

00:25:38,289 --> 00:25:41,299
Thank you.

00:25:41,299 --> 00:25:47,700
Now see this is a group effort.

00:25:47,700 --> 00:25:50,970
There we go. All right. So what it did

00:25:50,970 --> 00:25:54,169
is it, it actually returned the whole entire array.

00:25:54,169 --> 00:25:56,080
But if I go through this code and, cause

00:25:56,080 --> 00:25:58,440
I'm in Pry, you'll notice that it returns two

00:25:58,440 --> 00:26:01,110
arrays, and the two arrays are the, is the,

00:26:01,110 --> 00:26:03,529
is the original copy and the plagiarized copy. Notice

00:26:03,529 --> 00:26:06,039
that my copy, it's saying that these two documents

00:26:06,039 --> 00:26:10,200
are similar. And what we can also do here,

00:26:10,200 --> 00:26:11,029
and I'll move this to the top in a

00:26:11,029 --> 00:26:11,409
second-

00:26:11,409 --> 00:26:13,610
Yes, sir.

00:26:13,610 --> 00:26:16,919
AUDIENCE: indecipherable - 00:26:17

00:26:16,919 --> 00:26:22,340
B.L.: Oh, sorry about that. So we'll, we'll, we'll,

00:26:22,340 --> 00:26:25,880
we'll to the com- coefficients, and this is Jacquard's

00:26:25,880 --> 00:26:31,020
coefficient, we'll generate coefficients for, so notice these numbers

00:26:31,020 --> 00:26:35,070
are point o one five and, and if we

00:26:35,070 --> 00:26:38,720
go and see, you notice that this number is

00:26:38,720 --> 00:26:41,120
a lot lower - point oh one. What we

00:26:41,120 --> 00:26:43,159
can do with Jacquard's coefficient is we can actually

00:26:43,159 --> 00:26:46,270
compare documents based on how similar these numbers are.

00:26:46,270 --> 00:26:50,850
Once again, simple plagiarism detection. We call it classification

00:26:50,850 --> 00:26:52,470
in machine learning. Yes sir.

00:26:52,470 --> 00:26:53,760
AUDIENCE: indecipherable - 00:26:53

00:26:53,760 --> 00:26:56,039
B.L.: Man, I don't know.

00:26:56,039 --> 00:26:59,770
I actually, I do know, but I'm not gonna

00:26:59,770 --> 00:27:03,580
tell you. Go look on Wikipedia. But, no, we

00:27:03,580 --> 00:27:05,919
can talk about it in a second. I mean

00:27:05,919 --> 00:27:08,700
after this talk.

00:27:08,700 --> 00:27:11,309
So the next thing is kmeans clustering, and this

00:27:11,309 --> 00:27:13,200
is the fancy topic that, that formula that I

00:27:13,200 --> 00:27:15,720
showed you earlier was k-means clustering. And what you

00:27:15,720 --> 00:27:18,090
can do with k-means clustering is something neat. So

00:27:18,090 --> 00:27:20,830
imagine that you have a scatter plot of data.

00:27:20,830 --> 00:27:23,490
And I have a scatter plot of data.

00:27:23,490 --> 00:27:26,070
Uh-oh. Uh-oh.

00:27:26,070 --> 00:27:33,070
I'm having technical difficulties. All right, I mean like

00:27:34,270 --> 00:27:39,570
seriously. Keynote thirteen crash going-

00:27:39,570 --> 00:27:44,559
All right, so we'll reload keynote.

00:27:44,559 --> 00:27:49,220
Mhmm. So imagine we have some dots. And pretend

00:27:49,220 --> 00:27:53,980
these dots right here are star-filled maps. So pictures,

00:27:53,980 --> 00:27:56,870
you know, two-dimensional pictures of distant galaxies. And we

00:27:56,870 --> 00:27:59,250
want to take those galaxies, and we want to

00:27:59,250 --> 00:28:01,529
cluster them into groups, because we're gonna say that

00:28:01,529 --> 00:28:04,350
the despars that are in post group are a

00:28:04,350 --> 00:28:07,039
galaxy. So this is not Ruby, this is actually

00:28:07,039 --> 00:28:08,000
Javascript.

00:28:08,000 --> 00:28:09,929
but so let me show you this. I'm gonna

00:28:09,929 --> 00:28:11,750
show you what the computer can do. So I'm

00:28:11,750 --> 00:28:14,450
gonna reload this page, and you're gonna notice that

00:28:14,450 --> 00:28:17,370
the, the, the colors are a little bit off,

00:28:17,370 --> 00:28:24,179
but just wait a second here.

00:28:24,179 --> 00:28:28,750
There you go. Did you see that? So what

00:28:28,750 --> 00:28:30,789
I've done here is, and you're gonna like, Bryan

00:28:30,789 --> 00:28:32,399
what'd you do? So what I've done here is,

00:28:32,399 --> 00:28:34,299
you see these bigger dots? These bigger dots are

00:28:34,299 --> 00:28:36,600
called centraler in k-means plus three. And what I've

00:28:36,600 --> 00:28:38,850
done, doing, is I've put them on the screen

00:28:38,850 --> 00:28:42,260
randomly. And what I've done is I colored the,

00:28:42,260 --> 00:28:45,659
the little dots based on the closest big dot,

00:28:45,659 --> 00:28:47,390
and then what I do is I move the

00:28:47,390 --> 00:28:50,710
big dot to the center of all the, all

00:28:50,710 --> 00:28:53,559
the similar colored dots.

00:28:53,559 --> 00:28:54,909
And then I do it again. And then I

00:28:54,909 --> 00:28:57,149
do it again. Then I do it again. Until

00:28:57,149 --> 00:28:59,690
it stops moving. And then when it stops moving

00:28:59,690 --> 00:29:02,480
I've detected things that are similar. So you'll notice

00:29:02,480 --> 00:29:06,309
that down here in the bottom corner here that

00:29:06,309 --> 00:29:07,750
we can detect with our eyes that this is

00:29:07,750 --> 00:29:09,820
a different group, and we can detect with our

00:29:09,820 --> 00:29:12,460
eyes that this is a different group. With k-means

00:29:12,460 --> 00:29:14,409
clustering, you actually - usually what they'll do is

00:29:14,409 --> 00:29:16,850
they'll run it hundreds, if not thousands of times,

00:29:16,850 --> 00:29:21,340
and they'll actually generate a good sample here.

00:29:21,340 --> 00:29:23,059
Yup.

00:29:23,059 --> 00:29:25,110
We'll generate a good sample here and what we'll

00:29:25,110 --> 00:29:26,880
be able to do is use averages over time

00:29:26,880 --> 00:29:29,940
to actually determine what the probability of a group,

00:29:29,940 --> 00:29:32,559
of a, a little dot being in a group

00:29:32,559 --> 00:29:34,029
with a big dot.

00:29:34,029 --> 00:29:39,440
So, let's see something here. So let's go up.

00:29:39,440 --> 00:29:45,070
And we're talking about clustering. And let's just get

00:29:45,070 --> 00:29:45,669
k-means.

00:29:45,669 --> 00:29:49,830
This app is actually not, this is actually a

00:29:49,830 --> 00:29:53,600
j, a ds, a d3 app.

00:29:53,600 --> 00:29:54,789
I'm not gonna talk about the code. I just

00:29:54,789 --> 00:29:57,470
want to show you how much code it is,

00:29:57,470 --> 00:30:00,830
and this is why we use Ruby, cause, come

00:30:00,830 --> 00:30:02,260
on. Yup.

00:30:02,260 --> 00:30:04,390
Come on. Yup.

00:30:04,390 --> 00:30:09,039
Come on. Yup. Right. We're almost there - wait,

00:30:09,039 --> 00:30:10,730
wait, wait, wait, wait.

00:30:10,730 --> 00:30:12,429
Yup. OK we're there.

00:30:12,429 --> 00:30:15,260
So the reason I show that is because this

00:30:15,260 --> 00:30:17,159
brings me into a new topic. And like I

00:30:17,159 --> 00:30:21,830
said, I'm not - oh, my gosh. It did

00:30:21,830 --> 00:30:22,669
crash.

00:30:22,669 --> 00:30:24,429
I'm not here to show you how to do

00:30:24,429 --> 00:30:26,370
machine learning. I'm trying to show you what machine

00:30:26,370 --> 00:30:30,740
learning is. And practical applications of machine learning. So

00:30:30,740 --> 00:30:35,700
I have nine minutes and forty-four seconds, and let's...

00:30:35,700 --> 00:30:38,070
go... to here.

00:30:38,070 --> 00:30:41,960
So let's talk about doing machine learning in Ruby.

00:30:41,960 --> 00:30:47,169
God. There. There is a practice called AI4R. You

00:30:47,169 --> 00:30:49,529
could gem install AI4R right now. It implements a

00:30:49,529 --> 00:30:54,299
lot of things that I was talking about earlier.

00:30:54,299 --> 00:30:57,330
Here's a picture of their web page. There's something

00:30:57,330 --> 00:31:00,519
called, there's a project called SciRuby out there, and

00:31:00,519 --> 00:31:02,320
it is a lot of scientific stuff. So a

00:31:02,320 --> 00:31:04,940
lot of linear algebra things that you would need

00:31:04,940 --> 00:31:06,380
for machine learning.

00:31:06,380 --> 00:31:08,880
But the problem with SciRuby is that it's more

00:31:08,880 --> 00:31:10,880
like a science experiment and it doesn't have the

00:31:10,880 --> 00:31:13,630
funding it needs to be complete. So people are

00:31:13,630 --> 00:31:17,720
using it but there's much better things out there.

00:31:17,720 --> 00:31:22,409
You can use JRuby and Mahout. Apache Mahout is

00:31:22,409 --> 00:31:24,590
actually one of the defacto machine learning packages out

00:31:24,590 --> 00:31:26,149
there, but it's written in, on, in Java on

00:31:26,149 --> 00:31:28,730
the JVM. If you use JRuby you can actually

00:31:28,730 --> 00:31:30,679
get pretty easy access to it.

00:31:30,679 --> 00:31:33,179
And because it's so popular, someone wrote a JRuby

00:31:33,179 --> 00:31:36,190
Mahout plugin, but you can tell that they were

00:31:36,190 --> 00:31:38,710
really interested in it, because the last time they

00:31:38,710 --> 00:31:41,190
looked at it was eleven months ago.

00:31:41,190 --> 00:31:44,679
So. What I'm gonna do now is I'm gonna

00:31:44,679 --> 00:31:48,570
rail on Ruby for just a second. I love

00:31:48,570 --> 00:31:51,580
Ruby. I write Ruby every day in some fashion

00:31:51,580 --> 00:31:53,580
or another, and I use it for a lot.

00:31:53,580 --> 00:31:56,740
But Ruby is not good for machine learning because

00:31:56,740 --> 00:31:58,600
Ruby is not fast when it comes to math.

00:31:58,600 --> 00:32:01,049
The project and some of the things inside of

00:32:01,049 --> 00:32:03,159
there were kind of, are trying to fix it,

00:32:03,159 --> 00:32:05,919
but the problem is, even getting to that stage

00:32:05,919 --> 00:32:08,200
of installing this stuff is hard. Cause to install

00:32:08,200 --> 00:32:10,519
SciRuby you need an install called Atlas.

00:32:10,519 --> 00:32:13,500
Which is damn near impossible if you have a

00:32:13,500 --> 00:32:14,240
Mac.

00:32:14,240 --> 00:32:15,960
We also don't have easy plotting in Ruby. You

00:32:15,960 --> 00:32:17,830
notice that I used gnew plot and d3 for

00:32:17,830 --> 00:32:21,350
all my, my, my plotting examples. There is a

00:32:21,350 --> 00:32:23,200
Ruby gnew plot gem out there, and you can

00:32:23,200 --> 00:32:26,250
use it. But Ruby does not have great native

00:32:26,250 --> 00:32:30,399
plotting stuff like map plot let in Python.

00:32:30,399 --> 00:32:33,600
There is no integrated environment. Ruby has py- I

00:32:33,600 --> 00:32:36,429
mean, IRB, and you, I was using Pry earlier.

00:32:36,429 --> 00:32:38,360
But there's not a great, there's not like a

00:32:38,360 --> 00:32:42,519
Math lab or a Mathematica, or NI Python for

00:32:42,519 --> 00:32:45,960
Ruby. We really do need this.

00:32:45,960 --> 00:32:48,860
And also, I want to be able to do

00:32:48,860 --> 00:32:50,669
what I need to do as a scientist. I

00:32:50,669 --> 00:32:51,880
want to be like a scientist. As a scientist,

00:32:51,880 --> 00:32:54,929
I don't want to be a programmer. Ruby just

00:32:54,929 --> 00:32:57,690
still does not have the maturity in the idioms

00:32:57,690 --> 00:33:00,840
to allow scientists to be scientists. This is why

00:33:00,840 --> 00:33:03,690
all the scientists either use snap plot or they

00:33:03,690 --> 00:33:08,340
use, not math plot, mount lab or they use

00:33:08,340 --> 00:33:11,370
Python. Because it allows them to still be scientists

00:33:11,370 --> 00:33:13,309
while letting them get stuff done.

00:33:13,309 --> 00:33:16,419
So I don't want to rail on Ruby. What

00:33:16,419 --> 00:33:17,000
do you want to do if you want to

00:33:17,000 --> 00:33:19,289
learn more? Because really I cannot give you guys

00:33:19,289 --> 00:33:22,000
an advance talk. I could actually talk on one

00:33:22,000 --> 00:33:25,409
subject, like, classifiers, for this whole entire time. But

00:33:25,409 --> 00:33:27,169
if you, I want you to learn linear algebra.

00:33:27,169 --> 00:33:28,419
And you know I've probably said this three times

00:33:28,419 --> 00:33:30,899
already. You need to learn linear algebra. It's not

00:33:30,899 --> 00:33:32,860
hard. There's a coursera class on it - it's

00:33:32,860 --> 00:33:33,880
actually, it's not hard.

00:33:33,880 --> 00:33:36,779
You need to learn calculus. You notice I had

00:33:36,779 --> 00:33:38,870
a minimizing function earlier. You need to learn how

00:33:38,870 --> 00:33:40,899
to minimize. You need to know some kind of

00:33:40,899 --> 00:33:42,740
statistics. My friend Randall in the back will tell

00:33:42,740 --> 00:33:45,070
you that you need to know statistics just in

00:33:45,070 --> 00:33:45,590
general.

00:33:45,590 --> 00:33:47,399
But you need to learn some statistics. You at

00:33:47,399 --> 00:33:50,070
least need to know how mean, min, max work,

00:33:50,070 --> 00:33:52,700
how standard deviation works, and a few things around

00:33:52,700 --> 00:33:54,289
there.

00:33:54,289 --> 00:33:58,269
There's a coursera class on machine learning from the

00:33:58,269 --> 00:34:01,559
guy at Standford. I would say watch it. It's

00:34:01,559 --> 00:34:03,620
kind of dry. But at least it'll give you

00:34:03,620 --> 00:34:05,919
some of the, it'll give you some of the

00:34:05,919 --> 00:34:09,040
things you need to know. My partner in the

00:34:09,040 --> 00:34:11,349
back, Randall, has actually written a great blog post

00:34:11,349 --> 00:34:13,750
on getting into machine learning that he's gonna post.

00:34:13,750 --> 00:34:16,109
He has to now because I just said it

00:34:16,109 --> 00:34:17,089
in public.

00:34:17,089 --> 00:34:19,339
And another thing you want to do is use

00:34:19,339 --> 00:34:21,740
Wikipedia. I tell you what. I gotta show you

00:34:21,740 --> 00:34:23,589
this. Five minutes. We'll show you this.

00:34:23,589 --> 00:34:27,599
So Wikipedia is amazing. Anything you want to know,

00:34:27,599 --> 00:34:31,659
some smart dude or lady has written it on

00:34:31,659 --> 00:34:33,210
Wikipedia. So if you want to look up support

00:34:33,210 --> 00:34:40,210
vector machine, yes.

00:34:40,790 --> 00:34:43,480
There it is.

00:34:43,480 --> 00:34:46,929
Some nice person has written how it works. If

00:34:46,929 --> 00:34:51,849
you want to look up, k-means clustering, some smart

00:34:51,849 --> 00:34:56,070
person has, has written how it all works. You

00:34:56,070 --> 00:34:58,710
need to- Wikipedia is better than any textbook, I'm

00:34:58,710 --> 00:34:59,550
not lying.

00:34:59,550 --> 00:35:01,250
You also need to read this book by Peter

00:35:01,250 --> 00:35:02,900
Flach. There's a lot of books on machine learning

00:35:02,900 --> 00:35:04,970
out there, and this one's hard to buy on

00:35:04,970 --> 00:35:06,550
Amazon and it might be, like, I don't know

00:35:06,550 --> 00:35:09,890
how much it is. Maybe it's fifty, sixty bucks.

00:35:09,890 --> 00:35:12,030
There's not many books that will say are great.

00:35:12,030 --> 00:35:16,390
The first chapter of this book is probably the

00:35:16,390 --> 00:35:19,320
best reference on machine learning out there.

00:35:19,320 --> 00:35:20,390
And I'll, I'll wait for a second so you

00:35:20,390 --> 00:35:23,440
guys can take this in. This first chapter of

00:35:23,440 --> 00:35:25,240
this book by Peter Flach is the best thing

00:35:25,240 --> 00:35:27,270
I've seen on machine learning.

00:35:27,270 --> 00:35:28,450
But if you want to get serious, I want

00:35:28,450 --> 00:35:31,369
you to find a data set, find another language,

00:35:31,369 --> 00:35:33,359
unfortunately. If you're really serious about this you're not

00:35:33,359 --> 00:35:35,859
gonna be doing any Ruby. Then you'll want to

00:35:35,859 --> 00:35:37,359
do the dot dot dot dance, and then maybe

00:35:37,359 --> 00:35:38,160
you'll profit.

00:35:38,160 --> 00:35:40,170
But I'll tell you what. We haven't even scratched

00:35:40,170 --> 00:35:44,220
the surface. Sidekiq, which is, Sidekiq learn which is,

00:35:44,220 --> 00:35:47,680
in Python land, actually has this huge chart of

00:35:47,680 --> 00:35:49,050
all the things you can do in machine learning,

00:35:49,050 --> 00:35:51,660
we only talked about three things on this list,

00:35:51,660 --> 00:35:53,760
and look at all these little circles and lines.

00:35:53,760 --> 00:35:55,070
There's so much more you could talk about in

00:35:55,070 --> 00:35:57,010
machine learning.

00:35:57,010 --> 00:35:58,890
I want you to go look at BigML. It's

00:35:58,890 --> 00:36:01,500
actually a great machine learning platform, and it's a

00:36:01,500 --> 00:36:05,220
lot of tutorials on there. And Dundas. This is

00:36:05,220 --> 00:36:07,829
this website. Their blog has interesting every once in

00:36:07,829 --> 00:36:11,000
awhile. Kaggle has contests, data sets, and an interesting

00:36:11,000 --> 00:36:11,710
blog.

00:36:11,710 --> 00:36:14,119
You might want to go look in Python land.

00:36:14,119 --> 00:36:18,780
NumPy, SciPy, ScikitLearn and MapPlotlib are godsends. And on

00:36:18,780 --> 00:36:21,810
Python look at Apache Mahout. And there's a newcomer

00:36:21,810 --> 00:36:23,690
on the block - I'm just throwing things out

00:36:23,690 --> 00:36:28,550
there for future reference. Shark with Spark. PredicitionIO -

00:36:28,550 --> 00:36:31,380
this is a newcomer. It does prediction tools. It's

00:36:31,380 --> 00:36:33,460
actually pretty neat. I got a data set in

00:36:33,460 --> 00:36:36,930
there and I was not unimpressed.

00:36:36,930 --> 00:36:38,440
But the cool thing about it is that it's

00:36:38,440 --> 00:36:41,270
only building on, on technologies we already have. I

00:36:41,270 --> 00:36:43,260
mean it's not a new thing. It is using

00:36:43,260 --> 00:36:45,270
Padu. It is using Mahout.

00:36:45,270 --> 00:36:50,079
Here's some slides. Here's where the, the code for

00:36:50,079 --> 00:36:52,140
this talk is, if you're really into that kind

00:36:52,140 --> 00:36:53,770
of stuff. No one really loves this stuff, so

00:36:53,770 --> 00:36:56,390
I'll put it up there for posterity.

00:36:56,390 --> 00:36:57,770
But I want to show you something with the

00:36:57,770 --> 00:37:00,390
last couple minutes I have here.

00:37:00,390 --> 00:37:02,670
So this is what Ruby needs. If, If I

00:37:02,670 --> 00:37:05,089
were to walk around to everyone and say, you

00:37:05,089 --> 00:37:07,020
know what, I can tell you what Ruby needs.

00:37:07,020 --> 00:37:10,150
Ruby needs IPython. Has anyone here seen IPython?

00:37:10,150 --> 00:37:14,390
All right, I'm about to blow your guys's minds.

00:37:14,390 --> 00:37:19,140
So IPython is basically Pry on a webpage. And

00:37:19,140 --> 00:37:24,150
because I'm so awesome, I'm just gonna type in

00:37:24,150 --> 00:37:26,000
some Python.

00:37:26,000 --> 00:37:30,500
I'm just kidding.

00:37:30,500 --> 00:37:37,500
I'm not gonna do that.

00:37:37,990 --> 00:37:42,310
So one plus one equals two. You're actually writing

00:37:42,310 --> 00:37:44,790
Python in your web browser here. This is, this

00:37:44,790 --> 00:37:49,119
is a transformational tool. We could actually do this

00:37:49,119 --> 00:37:51,400
better, and I'm not saying that we should just

00:37:51,400 --> 00:37:53,720
go steal this, but you know what, rack got

00:37:53,720 --> 00:37:56,630
us really, really far. And you nice guys know

00:37:56,630 --> 00:38:00,970
where Rack came from, right? From Python.

00:38:00,970 --> 00:38:03,660
Another thing I want to look at, and this'll

00:38:03,660 --> 00:38:07,589
be the last thing, is - oh actually, you

00:38:07,589 --> 00:38:10,300
know what, I'm done.

00:38:10,300 --> 00:38:14,420

YouTube URL: https://www.youtube.com/watch?v=cxqjgq4VhgY


