Title: Ruby Conf 2013 - Test Driven Neural Networks with Ruby by Matthew Kirk
Publication date: 2020-01-27
Playlist: RubyConf 2013
Description: 
	Neural networks are an excellent way of mapping past observations to a functional model. Many researchers have been able to build tools to recognize handwriting, or even jaundice detection.

While Neural Networks are powerful they still are somewhat of a mystery to many. This talk aims to explain neural networks in a test driven way. We'll write tests first and go through how to build a neural network to determine what language a sentence is.

By the end of this talk you'll know how to build neural networks with tests!

Help us caption & translate this video!

http://amara.org/v/FG57/
Captions: 
	00:00:16,000 --> 00:00:21,000
MATTHEW KIRK: Hi. My name is Matt Kirk. Hello!

00:00:21,439 --> 00:00:26,359
Hi everybody. My name is Matt Kirk. And I

00:00:26,359 --> 00:00:31,800
want to know, who remembers email before Gmail? All

00:00:31,800 --> 00:00:36,640
right. Now who remembers the massive amount of spam

00:00:36,640 --> 00:00:38,980
that we used to get every single day in

00:00:38,980 --> 00:00:41,850
our inbox? Still do.

00:00:41,850 --> 00:00:45,210
I know that when I switched from having an

00:00:45,210 --> 00:00:48,870
excite account to having Gmail, it was like entering

00:00:48,870 --> 00:00:50,800
the garden of Eden of all inboxes, because I

00:00:50,800 --> 00:00:53,940
no longer had to spend my time deleting all

00:00:53,940 --> 00:01:00,720
of those ridiculous adds for pharmaceuticals and solicitations for

00:01:00,720 --> 00:01:02,710
Nigerian money.

00:01:02,710 --> 00:01:06,210
I could focus on sending emails to people that

00:01:06,210 --> 00:01:08,030
were important, and I no longer had to spend

00:01:08,030 --> 00:01:13,479
my time actually filtering out spam myself. Now, who

00:01:13,479 --> 00:01:19,329
remembers mix tapes? All right. My kind of audience.

00:01:19,329 --> 00:01:21,509
I know that when I was a kid, I

00:01:21,509 --> 00:01:24,249
used to listen to a couple radio stations up

00:01:24,249 --> 00:01:27,640
in Seattle, where I'm from. And my favorite radio

00:01:27,640 --> 00:01:31,799
stations, I'd always have a cassette ready, because there

00:01:31,799 --> 00:01:34,280
might be that song that I really want on

00:01:34,280 --> 00:01:37,450
a tape. And, of course, as soon as it

00:01:37,450 --> 00:01:39,490
got to that song, it would play the intro

00:01:39,490 --> 00:01:41,829
and then I'd hit record as fast as I

00:01:41,829 --> 00:01:44,299
can, and about twelve hours later I'd have this

00:01:44,299 --> 00:01:48,659
mediocre mix tape. That was pretty good but it

00:01:48,659 --> 00:01:50,819
wasn't really that great.

00:01:50,819 --> 00:01:52,219
No longer do I have to do that. Now

00:01:52,219 --> 00:01:54,729
I can just load up my iPhone, type in

00:01:54,729 --> 00:01:58,569
favorite artist into Pandora and go for a run.

00:01:58,569 --> 00:02:01,340
It's amazing that I don't have to spend twelve

00:02:01,340 --> 00:02:04,369
hours making a playlist. I don't have to spend

00:02:04,369 --> 00:02:06,389
any of this time.

00:02:06,389 --> 00:02:11,650
Now, Pandora and Gmail, or spam filtering getting better.

00:02:11,650 --> 00:02:14,379
They both have one thing in common, and that

00:02:14,379 --> 00:02:17,810
is they're both using data to solve a problem

00:02:17,810 --> 00:02:21,400
to make our lives much easier.

00:02:21,400 --> 00:02:23,620
And today I am here to issue every single

00:02:23,620 --> 00:02:26,209
one of you a challenge, and that is to

00:02:26,209 --> 00:02:31,180
use data to solve problems. Somewhere in this audience,

00:02:31,180 --> 00:02:33,310
there is somebody who will make the next Pandora,

00:02:33,310 --> 00:02:39,470
or will make a spam filter that somewhat works.

00:02:39,470 --> 00:02:42,819
I think that this community is extremely smart, and

00:02:42,819 --> 00:02:46,829
can do it. Can really utilize data, because there

00:02:46,829 --> 00:02:49,370
is a massive opportunity in front of us right

00:02:49,370 --> 00:02:52,819
now. We can get data everywhere from temperatures to

00:02:52,819 --> 00:02:56,120
Kim Kardashian's Tweets to everything in between. We have

00:02:56,120 --> 00:03:01,230
data. We have data's being created from Rails, you

00:03:01,230 --> 00:03:02,510
name it.

00:03:02,510 --> 00:03:07,010
But, of course, this is a RubyConf, and Ruby

00:03:07,010 --> 00:03:11,409
really isn't the big data language. A lot of

00:03:11,409 --> 00:03:15,510
people, unfortunately, think that, when I talked about machine

00:03:15,510 --> 00:03:18,860
learning, big data, data science, whatever you want to

00:03:18,860 --> 00:03:22,099
call it, we're talking about Java and Python and

00:03:22,099 --> 00:03:24,480
R and Julia and Clojure and MatLab and the

00:03:24,480 --> 00:03:25,459
list goes on.

00:03:25,459 --> 00:03:31,590
But Ruby doesn't do that. Ruby has tools too.

00:03:31,590 --> 00:03:35,090
We have tools. Whether it be JRuby tying into

00:03:35,090 --> 00:03:37,689
Mahout, or using some of the C libraries in

00:03:37,689 --> 00:03:42,099
MRI. We have Ruby tools. We have tools as

00:03:42,099 --> 00:03:46,250
well. We can approach machine learning problems, data problems,

00:03:46,250 --> 00:03:51,069
like everybody else.

00:03:51,069 --> 00:03:57,939
But unfortunately, data science, big data, machine learning, optimization,

00:03:57,939 --> 00:04:01,689
bio-informatics, you name it, is a big freaking mess.

00:04:01,689 --> 00:04:04,480
It is a confusing ball of mud in everybody's

00:04:04,480 --> 00:04:08,599
mind because nobody really knows what even to call

00:04:08,599 --> 00:04:11,609
this form of study. If you were to go

00:04:11,609 --> 00:04:15,140
and find an academic paper and start reading through

00:04:15,140 --> 00:04:17,949
it, most likely by the end of it, you

00:04:17,949 --> 00:04:20,720
would be more confused than when you started reading

00:04:20,720 --> 00:04:23,100
it.

00:04:23,100 --> 00:04:24,690
It's like this poor little guy who doesn't have

00:04:24,690 --> 00:04:30,449
a freaking clue what's going on. Data science? That's

00:04:30,449 --> 00:04:34,130
a form of science. Hasn't had Newton or Einstein

00:04:34,130 --> 00:04:37,360
to come and unify everything in this elegant theory.

00:04:37,360 --> 00:04:41,970
It is an extremely nascent field, whereby it's extremely

00:04:41,970 --> 00:04:45,970
immature and confusing.

00:04:45,970 --> 00:04:47,970
On top of that, Ruby was not ever created

00:04:47,970 --> 00:04:51,500
to be about complex mathematics, linear algebra or anything

00:04:51,500 --> 00:04:55,650
like that. Matz, the creator of Ruby, created the

00:04:55,650 --> 00:04:59,220
language for everybody here, including me. He made it

00:04:59,220 --> 00:05:03,199
for our joy, happiness, to make us happier, so

00:05:03,199 --> 00:05:05,210
that we didn't have to worry about boilerplate.

00:05:05,210 --> 00:05:07,400
And I'm sure a lot of you can attest

00:05:07,400 --> 00:05:13,560
that mathematics was not created for our happiness.

00:05:13,560 --> 00:05:17,120
But that can actually be a strong point in

00:05:17,120 --> 00:05:21,560
Ruby as well. Ruby was made for our happiness.

00:05:21,560 --> 00:05:24,460
It's expressive, it's easy to read. When you write

00:05:24,460 --> 00:05:27,370
Ruby in the right way, it's almost like writing

00:05:27,370 --> 00:05:32,889
pseudo-code. So if we're able to solve these data-type

00:05:32,889 --> 00:05:36,590
problems in Ruby, we could share it with other

00:05:36,590 --> 00:05:43,400
people and teach more how to approach these problems.

00:05:43,400 --> 00:05:48,340
Today, I'm going to teach you how to approach

00:05:48,340 --> 00:05:52,240
one simple problem. By the end of this, you

00:05:52,240 --> 00:05:55,319
won't know nearly enough, when it comes to machine

00:05:55,319 --> 00:05:57,139
learning. You will not come out of here with

00:05:57,139 --> 00:06:02,569
a Ph.D. in advanced mathematics. But, I hope to

00:06:02,569 --> 00:06:05,759
encourage you to search and to learn more about

00:06:05,759 --> 00:06:08,560
this field, because it is extremely useful for what

00:06:08,560 --> 00:06:10,860
we do.

00:06:10,860 --> 00:06:14,150
Today we're gonna go through what feed forward neural

00:06:14,150 --> 00:06:17,139
networks are. We're going to have one example, which

00:06:17,139 --> 00:06:21,759
is classifying strings to languages. We're going to do

00:06:21,759 --> 00:06:25,960
it in a test-driven fashion, which is kind of

00:06:25,960 --> 00:06:27,940
a different way of thinking about it. And then

00:06:27,940 --> 00:06:29,440
at the very end, just to prove that I'm

00:06:29,440 --> 00:06:35,169
not making things up, we'll actually have a demonstration.

00:06:35,169 --> 00:06:38,360
So who knows what a neural network is?

00:06:38,360 --> 00:06:42,729
OK. Who knows how they work?

00:06:42,729 --> 00:06:46,410
All right.

00:06:46,410 --> 00:06:49,729
Neural networks, to me, is the best example of

00:06:49,729 --> 00:06:52,949
machine learning, because it's kind of a magical sledgehammer,

00:06:52,949 --> 00:06:57,830
whereby we can hammer in functional relationships of previous

00:06:57,830 --> 00:07:01,949
data. It works really well, if we have data

00:07:01,949 --> 00:07:04,370
that we can model, and we think that there's

00:07:04,370 --> 00:07:07,960
a functional relationship there. But, for the most part,

00:07:07,960 --> 00:07:13,099
it is kind of a confusing algorithm, and, I

00:07:13,099 --> 00:07:14,430
hope, by the end of this section, you'll at

00:07:14,430 --> 00:07:17,250
least have a better idea of how they're built.

00:07:17,250 --> 00:07:20,780
Definitely won't be very deep, but hopefully you'll just

00:07:20,780 --> 00:07:23,300
know a little bit more about how these neural

00:07:23,300 --> 00:07:24,569
networks actually work.

00:07:24,569 --> 00:07:28,590
In the graphical format, it looks something like this,

00:07:28,590 --> 00:07:32,280
for the most part. Neural networks are broken down

00:07:32,280 --> 00:07:38,659
into four pieces. There's three layers, and then neurons.

00:07:38,659 --> 00:07:43,099
So, the layers, going through them one by one,

00:07:43,099 --> 00:07:46,699
we have an input layer. Input layer is actually

00:07:46,699 --> 00:07:49,729
probably one of the easiest things to understand. Really,

00:07:49,729 --> 00:07:52,490
it is just what we're inputting into this particular

00:07:52,490 --> 00:07:58,009
model that we want to model a functional relationship.

00:07:58,009 --> 00:08:00,210
Now the thing here to stress is that, for

00:08:00,210 --> 00:08:02,990
the most part, when we're talking about neural networks,

00:08:02,990 --> 00:08:08,580
we're talking about data between zero and one. So

00:08:08,580 --> 00:08:13,189
that can be anything normalized between zero and one.

00:08:13,189 --> 00:08:17,169
So input is simple. It's just what you're inputting

00:08:17,169 --> 00:08:19,180
into this particular model.

00:08:19,180 --> 00:08:22,259
Now that's not where most people get tripped up.

00:08:22,259 --> 00:08:24,199
Instead they get tripped up on this idea of

00:08:24,199 --> 00:08:27,939
the hidden layer. And this is where I got

00:08:27,939 --> 00:08:30,580
really confused when I first learned about a neural

00:08:30,580 --> 00:08:32,300
network.

00:08:32,300 --> 00:08:35,969
I understand that input and output is input and

00:08:35,969 --> 00:08:39,919
output. But the hidden layer is like this private

00:08:39,919 --> 00:08:42,560
method that we have no control over and can't

00:08:42,560 --> 00:08:48,440
really observe. The hidden layer is just an added

00:08:48,440 --> 00:08:51,779
complexity to the model, so that we can model

00:08:51,779 --> 00:08:54,649
even more complex functions.

00:08:54,649 --> 00:08:58,160
Unfortunately, we can't really observe what's going on in

00:08:58,160 --> 00:09:01,100
there, because it is really just like a private

00:09:01,100 --> 00:09:04,320
method of this function. It's out of our scope,

00:09:04,320 --> 00:09:06,060
and for the most part, we just treat it

00:09:06,060 --> 00:09:07,890
like a black box.

00:09:07,890 --> 00:09:11,519
I'll get back to how these things actually get

00:09:11,519 --> 00:09:14,970
computed a little bit later, but let's first talk

00:09:14,970 --> 00:09:17,269
about neurons.

00:09:17,269 --> 00:09:20,490
How many neurons actually should go into this is

00:09:20,490 --> 00:09:25,680
a very open question. When you look at this

00:09:25,680 --> 00:09:29,529
particular graph, we know that we're inputting a certain

00:09:29,529 --> 00:09:31,360
amount of data, and we want to output a

00:09:31,360 --> 00:09:33,860
certain amount of data. But when it comes to

00:09:33,860 --> 00:09:37,050
the hidden neurons, how many neurons do you want

00:09:37,050 --> 00:09:39,290
in that layer?

00:09:39,290 --> 00:09:42,190
Now you could put as many or as little

00:09:42,190 --> 00:09:46,050
as you want in there. It's up to you.

00:09:46,050 --> 00:09:48,709
But there's a heuristic which is to use two-thirds

00:09:48,709 --> 00:09:52,010
times the input layer plus the output count. That's

00:09:52,010 --> 00:09:53,070
just a good way to start.

00:09:53,070 --> 00:09:56,640
It doesn't really matter. The only thing to stress

00:09:56,640 --> 00:10:00,029
here is that these neural networks, in a feedforward

00:10:00,029 --> 00:10:03,130
context, which is what we're talking about, more or

00:10:03,130 --> 00:10:05,899
less, does a really good job of aggregating data

00:10:05,899 --> 00:10:07,670
together. So as you can see, it goes from

00:10:07,670 --> 00:10:11,490
three to two to one.

00:10:11,490 --> 00:10:15,510
Lastly, we have the output layer, which is just

00:10:15,510 --> 00:10:22,510
where the data comes out of this massive function.

00:10:23,200 --> 00:10:25,990
Let's talk about the neurons.

00:10:25,990 --> 00:10:28,910
Neurons, as you know, are in every single one

00:10:28,910 --> 00:10:31,170
of us, in our brain. We have a neural

00:10:31,170 --> 00:10:35,180
network of sort. And it takes input, a bunch

00:10:35,180 --> 00:10:38,000
of input, and then it sends outputs to other

00:10:38,000 --> 00:10:41,610
neurons, which then sends more output to other neurons.

00:10:41,610 --> 00:10:45,389
When we're talking about an artificial context, though, it's

00:10:45,389 --> 00:10:48,910
a very specific idea, which is, we're taking two

00:10:48,910 --> 00:10:52,630
inputs, in this case x1 and x2, and then

00:10:52,630 --> 00:10:58,290
we're weighting them together. The idea here is that

00:10:58,290 --> 00:11:03,709
we really only want one output in this neuron.

00:11:03,709 --> 00:11:07,829
And we just want it to be weighted based

00:11:07,829 --> 00:11:12,149
off of minimizing the error of the entire network.

00:11:12,149 --> 00:11:14,110
On top of that, we also want it to

00:11:14,110 --> 00:11:19,529
be between zero and one. Now, this is really

00:11:19,529 --> 00:11:21,790
confusing, so let me explain it in a different

00:11:21,790 --> 00:11:22,970
way.

00:11:22,970 --> 00:11:24,850
How many of you have ever run into digital

00:11:24,850 --> 00:11:29,959
logic before? All right, so most everybody here probably

00:11:29,959 --> 00:11:32,339
knows what digital logic is, because you use ands

00:11:32,339 --> 00:11:35,680
and ors in Ruby code all the time. Digital

00:11:35,680 --> 00:11:40,019
logic is where, basically, you say zero is false

00:11:40,019 --> 00:11:42,540
and one is true. So when you have something

00:11:42,540 --> 00:11:45,240
like the and gate, the only time it will

00:11:45,240 --> 00:11:48,829
be one is if they're both one. So it's

00:11:48,829 --> 00:11:51,889
true and true equals true.

00:11:51,889 --> 00:11:53,149
Simple enough.

00:11:53,149 --> 00:11:58,180
This neuron, like a digital logic gate, is more

00:11:58,180 --> 00:12:02,920
like fuzzy logic. So instead of being zero or

00:12:02,920 --> 00:12:06,010
one, it's really just kind of a range between

00:12:06,010 --> 00:12:11,010
zero and one. So, for instance, instead of being

00:12:11,010 --> 00:12:14,940
true, it could be seventy-five percent true.

00:12:14,940 --> 00:12:19,760
Now this is a really powerful idea, because instead

00:12:19,760 --> 00:12:21,899
of having to make sure that everything is true

00:12:21,899 --> 00:12:24,550
or false, we can have an inclination towards an

00:12:24,550 --> 00:12:28,630
answer, and that's what really makes neural networks powerful.

00:12:28,630 --> 00:12:30,540
We get close to a solution, but we don't

00:12:30,540 --> 00:12:34,350
actually find the exact solution.

00:12:34,350 --> 00:12:37,079
And originally when neural networks were first come up

00:12:37,079 --> 00:12:39,620
with, that's what they were doing, is looking at

00:12:39,620 --> 00:12:43,860
something called threshold logic, which is around this idea

00:12:43,860 --> 00:12:46,389
of taking a lot of input and determining whether

00:12:46,389 --> 00:12:48,740
things were true or false.

00:12:48,740 --> 00:12:51,870
Now, if you noticed back on this slide, I

00:12:51,870 --> 00:12:56,870
had this random function that wraps everything. This f.

00:12:56,870 --> 00:12:58,930
There's a special name for that, and what it's

00:12:58,930 --> 00:13:03,320
called is the activation function. Now I'm sure everybody

00:13:03,320 --> 00:13:06,160
up here knows these, right.

00:13:06,160 --> 00:13:12,170
Obviously not. OK. So, activation function serves one purpose

00:13:12,170 --> 00:13:15,260
and that is to normalize everything between zero and

00:13:15,260 --> 00:13:19,579
one. So if, for instance, the weighted sum outputs

00:13:19,579 --> 00:13:23,149
ninety-five, then it would be towards one, but it

00:13:23,149 --> 00:13:26,120
wouldn't actually be one.

00:13:26,120 --> 00:13:31,519
Activation functions take many different forms. Sigmoidal and Elliot

00:13:31,519 --> 00:13:34,690
is really just the learning curve. So, if you

00:13:34,690 --> 00:13:36,740
have learned something, most likely, you know about the

00:13:36,740 --> 00:13:40,519
learning curve, where you struggle for awhile, it goes

00:13:40,519 --> 00:13:43,269
up really fast, and then you kind of plateau

00:13:43,269 --> 00:13:47,670
at the top. So that's Sigmoid and Elliot.

00:13:47,670 --> 00:13:51,610
Second, we have Gaussian, which really is just a

00:13:51,610 --> 00:13:53,630
fancy term for the bell curve, which looks like

00:13:53,630 --> 00:13:55,220
a big hump in the - or like a

00:13:55,220 --> 00:13:59,899
hill. Linear - line. Threshold is just yes or

00:13:59,899 --> 00:14:05,079
no. And cosine is, obviously, cosine and sine.

00:14:05,079 --> 00:14:07,350
The really important thing here is that, since we're

00:14:07,350 --> 00:14:11,660
looking for a fuzzy logic answer, we need to

00:14:11,660 --> 00:14:16,440
make sure that everything is normalized between zero and

00:14:16,440 --> 00:14:17,420
one.

00:14:17,420 --> 00:14:19,579
Now, I don't think that you're gonna be able

00:14:19,579 --> 00:14:22,079
to see this, because I pulled this somewhere off

00:14:22,079 --> 00:14:25,070
of Google images and it's hard to see, but

00:14:25,070 --> 00:14:28,050
I will be posting all of this, resources at

00:14:28,050 --> 00:14:29,720
the end so you can check it out. This

00:14:29,720 --> 00:14:31,820
is just a graph of all of the activation

00:14:31,820 --> 00:14:35,889
function so that you can see it.

00:14:35,889 --> 00:14:39,620
Now, the last thing we need to talk about

00:14:39,620 --> 00:14:42,269
in terms of feed forward neural networks is this

00:14:42,269 --> 00:14:45,040
idea of a training algorithm, and that's where machine

00:14:45,040 --> 00:14:48,170
learning really comes into play. Now if you think

00:14:48,170 --> 00:14:51,339
about it, looking back on the neuron slide, there

00:14:51,339 --> 00:14:55,420
was this weighted sum. But how exactly does it

00:14:55,420 --> 00:14:55,980
weight?

00:14:55,980 --> 00:15:00,100
It could be completely arbitrary. Should it be fifty-fifty

00:15:00,100 --> 00:15:06,170
or seventy-five twenty-five? It's a completely arbitrary idea. And

00:15:06,170 --> 00:15:10,630
what the training algorithm does, effectively, is illustrate it

00:15:10,630 --> 00:15:12,829
in this little slide that I put together, including

00:15:12,829 --> 00:15:16,980
the little AOL guy.

00:15:16,980 --> 00:15:19,320
So imagine that you're the AOL guy standing at

00:15:19,320 --> 00:15:23,690
the top of a mountain, and for some reason,

00:15:23,690 --> 00:15:26,149
it's super dark outside, it's foggy, you have a

00:15:26,149 --> 00:15:27,930
tree in front of you with the club on

00:15:27,930 --> 00:15:30,259
the top. And you want to get to the

00:15:30,259 --> 00:15:34,459
bottom of the valley where your base camp is.

00:15:34,459 --> 00:15:38,000
Now intuitively, in terms of how I would do

00:15:38,000 --> 00:15:40,589
it, I would say, OK, it's really freaking dark,

00:15:40,589 --> 00:15:42,860
but, it looks like the hill is going down

00:15:42,860 --> 00:15:46,740
that direction, and I start walking that direction until

00:15:46,740 --> 00:15:48,519
I notice the hill start goes back up.

00:15:48,519 --> 00:15:51,800
Now, then I would say, OK, I need to

00:15:51,800 --> 00:15:55,360
backtrack and maybe I'll try a different direction. And

00:15:55,360 --> 00:15:59,519
that's effectively what these training algorithms do. They're just

00:15:59,519 --> 00:16:02,790
trying to find the minimum error. So they're trying

00:16:02,790 --> 00:16:06,190
to find the set of weights that minimizes the

00:16:06,190 --> 00:16:08,980
error of the entire model.

00:16:08,980 --> 00:16:12,759
And they do that step-wise. So they look for

00:16:12,759 --> 00:16:16,660
the steepest descent. So we're looking for how to

00:16:16,660 --> 00:16:21,130
get down to the bottom of the valley. This

00:16:21,130 --> 00:16:22,720
is just the tip of the iceberg when it

00:16:22,720 --> 00:16:26,220
comes to neural networks, and to be honest, it's

00:16:26,220 --> 00:16:27,949
a lot to take in in a very short

00:16:27,949 --> 00:16:31,569
period of time, so I recommend everybody look more

00:16:31,569 --> 00:16:34,329
into this, into neural networks.

00:16:34,329 --> 00:16:40,139
There's all kinds of variants, including cyclical, RBF neural

00:16:40,139 --> 00:16:43,529
networks. The list goes on and on. But hopefully

00:16:43,529 --> 00:16:46,470
this explains enough so that we can approach a

00:16:46,470 --> 00:16:51,430
problem of some use.

00:16:51,430 --> 00:16:56,529
Who's seen this before? Anybody know what it is?

00:16:56,529 --> 00:17:01,170
Wow, you guys are really loud.

00:17:01,170 --> 00:17:06,280
OK, thank you. Google translate. So if you're a,

00:17:06,280 --> 00:17:08,880
if you're a student of a foreign language, most

00:17:08,880 --> 00:17:11,510
likely you've gone to Google translate or any of

00:17:11,510 --> 00:17:14,780
the other ones. But one day, I was kind

00:17:14,780 --> 00:17:17,630
of surprised by being able to type in a

00:17:17,630 --> 00:17:19,430
word, and it would say, would you like to

00:17:19,430 --> 00:17:22,430
translate this from German or, whatever you're trying to

00:17:22,430 --> 00:17:24,850
translate - Finnish, whatever.

00:17:24,850 --> 00:17:27,100
And when I looked at it, I'm saying, wow,

00:17:27,100 --> 00:17:29,540
Google is really smart. They must know things that

00:17:29,540 --> 00:17:33,590
I don't know, because they can read my mind.

00:17:33,590 --> 00:17:35,410
And I thought to myself, OK, how would you

00:17:35,410 --> 00:17:39,160
actually approach building something like this?

00:17:39,160 --> 00:17:43,950
Now, the programmer in me would say, OK, this

00:17:43,950 --> 00:17:46,160
is just a simple dictionary lookup, for the most

00:17:46,160 --> 00:17:49,310
part. We could probably get every word in the

00:17:49,310 --> 00:17:53,050
entire world, put it into this enormous hash, and

00:17:53,050 --> 00:17:56,230
then look things up one by one.

00:17:56,230 --> 00:17:57,850
Until I thought about it for a second. I'm

00:17:57,850 --> 00:18:00,920
saying, OK, there's probably twelve thousand words, more or

00:18:00,920 --> 00:18:05,170
less, for each language, across maybe a few hundred

00:18:05,170 --> 00:18:08,690
languages. That would get pretty big pretty fast, and,

00:18:08,690 --> 00:18:10,260
for the most part, I don't care if it's

00:18:10,260 --> 00:18:12,080
perfect or not.

00:18:12,080 --> 00:18:15,150
On top of that, if you're into German, they

00:18:15,150 --> 00:18:20,120
have really big, complex, compound words that probably wouldn't

00:18:20,120 --> 00:18:26,100
be found by the particular implementation. So we really

00:18:26,100 --> 00:18:32,730
need to take a different pers- different approach.

00:18:32,730 --> 00:18:37,830
That approach of solving specifically something like this, where

00:18:37,830 --> 00:18:43,290
we want to classify English, German, Polish, Swedish, Finnish,

00:18:43,290 --> 00:18:46,220
Norwegian. Now, I just picked these languages out of

00:18:46,220 --> 00:18:49,370
hat because that's what I want to specify. I

00:18:49,370 --> 00:18:52,630
think it would be great if we could actually

00:18:52,630 --> 00:18:56,750
make a Scandinavian German language classifier, because they kind

00:18:56,750 --> 00:19:02,670
of look similar sometimes.

00:19:02,670 --> 00:19:03,940
The way that I would do this is I'd

00:19:03,940 --> 00:19:09,750
probably pull some data down first. And, all politics

00:19:09,750 --> 00:19:12,750
and religion aside, probably one of the most translated

00:19:12,750 --> 00:19:15,430
books in the world would be the Bible, so

00:19:15,430 --> 00:19:17,210
I just figured I would go out and find

00:19:17,210 --> 00:19:20,070
a bunch of text from the Bible in many

00:19:20,070 --> 00:19:23,040
different languages, pull that down, and if we have

00:19:23,040 --> 00:19:29,660
the data, we can do something with it, right?

00:19:29,660 --> 00:19:32,510
Well, this is where things get a little bit

00:19:32,510 --> 00:19:38,190
more complicated, because, language, as many of you know,

00:19:38,190 --> 00:19:42,690
can be extracted in many different ways. Now, a

00:19:42,690 --> 00:19:45,320
computer really doesn't care about what the language looks

00:19:45,320 --> 00:19:49,740
like. They care about how you're modeling that language.

00:19:49,740 --> 00:19:51,850
And if we have all of this text from

00:19:51,850 --> 00:19:54,620
the Bible in many different languages, we could extract

00:19:54,620 --> 00:19:57,230
it in many different ways. We could pull out

00:19:57,230 --> 00:20:03,540
stems, words, character counts, or we could do frequency

00:20:03,540 --> 00:20:05,010
of characters.

00:20:05,010 --> 00:20:08,630
And this is where something struck me right away,

00:20:08,630 --> 00:20:14,730
because I remember, from grammar or something, that e

00:20:14,730 --> 00:20:17,550
was the most frequent letter in the English language.

00:20:17,550 --> 00:20:19,370
So I said, OK, that would be great if

00:20:19,370 --> 00:20:21,680
I could just pull out the frequencies of these

00:20:21,680 --> 00:20:27,340
letters and somehow model that into a classifier.

00:20:27,340 --> 00:20:31,130
Doing a little bit more research, I decided to

00:20:31,130 --> 00:20:34,280
graph this out, and what this is is showing

00:20:34,280 --> 00:20:40,210
the character distribution alphabetized for these six different languages.

00:20:40,210 --> 00:20:44,190
So, as you can see, Finnish has a lot

00:20:44,190 --> 00:20:47,660
of a's in it. English has a lot of

00:20:47,660 --> 00:20:50,330
e's. So I'm just pulling that out of my

00:20:50,330 --> 00:20:51,290
head, but.

00:20:51,290 --> 00:20:53,670
As you can see though, there's something here. There

00:20:53,670 --> 00:20:57,130
is somewhat of a relationship and there's somewhat of

00:20:57,130 --> 00:21:01,150
a characteristic to each one of these languages. And

00:21:01,150 --> 00:21:03,750
that was really intriguing to me, and exciting, because

00:21:03,750 --> 00:21:07,530
if there's something, then we could probably use a

00:21:07,530 --> 00:21:11,400
neural net, right.

00:21:11,400 --> 00:21:17,290
Now, taking a step back, who remembers the scientific

00:21:17,290 --> 00:21:23,140
method from seventh grade science class? All right. I

00:21:23,140 --> 00:21:26,060
remember in seventh grade I learned the scientific method,

00:21:26,060 --> 00:21:29,930
and it was hypothesize, test that hypothesis, and based

00:21:29,930 --> 00:21:31,460
off of that answer, you feed that into a

00:21:31,460 --> 00:21:33,710
new hypothesis, which then you do the same thing

00:21:33,710 --> 00:21:37,430
over and over again until finally you have a

00:21:37,430 --> 00:21:41,160
theory of sorts.

00:21:41,160 --> 00:21:43,740
I've always thought that test-driven development is just a

00:21:43,740 --> 00:21:47,570
subset of the scientific method. You write a test,

00:21:47,570 --> 00:21:51,030
you test it, you make, you see what comes

00:21:51,030 --> 00:21:52,750
out of that, and based off of that feedback

00:21:52,750 --> 00:21:57,270
loop over time you get to a theoretically sound

00:21:57,270 --> 00:21:59,340
code base, so to speak.

00:21:59,340 --> 00:22:02,360
Now wouldn't it be great if we could actually

00:22:02,360 --> 00:22:07,390
approach this particular problem of mapping strings to language

00:22:07,390 --> 00:22:10,600
in a test-driven fashion so that we're actually writing

00:22:10,600 --> 00:22:14,530
down our assumptions first, and then running the test

00:22:14,530 --> 00:22:16,870
so that we can use that feedback to actually

00:22:16,870 --> 00:22:21,230
tune something like a neural network, or anything.

00:22:21,230 --> 00:22:25,840
And so I'm going to explain to you how

00:22:25,840 --> 00:22:28,240
I go about doing that. And it's a little

00:22:28,240 --> 00:22:30,010
bit different than probably what you're used to. I

00:22:30,010 --> 00:22:31,270
think a lot of us are used to this

00:22:31,270 --> 00:22:34,650
idea of unit testing, whereby you make sure that

00:22:34,650 --> 00:22:39,240
a class returns the same string every single time.

00:22:39,240 --> 00:22:42,060
Instead, this is a little bit more fuzzy, but

00:22:42,060 --> 00:22:47,290
it's still writing down your assumptions in code.

00:22:47,290 --> 00:22:50,360
Now the first thing, it's really important when testing

00:22:50,360 --> 00:22:53,240
something like this, is making sure that integration points

00:22:53,240 --> 00:22:56,480
are well-tested. So if any of you have ever

00:22:56,480 --> 00:22:59,500
read working effectively with like, you'll see code most

00:22:59,500 --> 00:23:02,460
likely, you've heard of seam testing, which is making

00:23:02,460 --> 00:23:05,660
sure that the seams between one piece of code

00:23:05,660 --> 00:23:07,400
and something that's more or less out of your

00:23:07,400 --> 00:23:10,250
control, is well-tested.

00:23:10,250 --> 00:23:13,230
Now, machine learning algorithms are pretty much out of

00:23:13,230 --> 00:23:17,180
our control. We don't have any real power over

00:23:17,180 --> 00:23:20,020
what goes on inside of the training algorithm, because

00:23:20,020 --> 00:23:23,100
that's just an algorithm that somebody else has built

00:23:23,100 --> 00:23:27,000
before us. So what we have power over, though,

00:23:27,000 --> 00:23:30,840
is what we give to the neural network.

00:23:30,840 --> 00:23:33,460
And so in this case, I'm using really generic

00:23:33,460 --> 00:23:36,720
terms for my classes, which is a bad thing,

00:23:36,720 --> 00:23:41,030
but I just made a language class, which takes

00:23:41,030 --> 00:23:46,200
in a bunch of text and a language. And

00:23:46,200 --> 00:23:48,500
I wanted to test these three things, which is

00:23:48,500 --> 00:23:52,130
making sure that it has the proper characters. I

00:23:52,130 --> 00:23:54,810
used keys because I think of everything as a

00:23:54,810 --> 00:23:56,800
hash, but, making sure that it has the proper

00:23:56,800 --> 00:23:59,800
keys for everything.

00:23:59,800 --> 00:24:02,060
On top of that, I also wanted to ensure

00:24:02,060 --> 00:24:04,830
that the data itself summed up to one. So

00:24:04,830 --> 00:24:06,740
I was wanting to make sure that it's a

00:24:06,740 --> 00:24:10,630
percentage of total, as opposed to just anywhere between

00:24:10,630 --> 00:24:13,130
zero and one, because that's how I wanted to

00:24:13,130 --> 00:24:15,140
model it.

00:24:15,140 --> 00:24:17,020
On top of that, I wanted to make sure

00:24:17,020 --> 00:24:19,910
that we had a unique character set. So this

00:24:19,910 --> 00:24:22,150
comes in a little bit more important when I

00:24:22,150 --> 00:24:27,760
explain the code, but, it's important that we don't

00:24:27,760 --> 00:24:31,130
care about sensitivity and cases. We just want everything

00:24:31,130 --> 00:24:32,590
to be - yeah.

00:24:32,590 --> 00:24:36,010
QUESTION: (indecipherable -- 00:24:36)

00:24:36,010 --> 00:24:38,280
M.K.: Sure.

00:24:38,280 --> 00:24:42,520
So the vectors in this particular context, assuming that

00:24:42,520 --> 00:24:47,170
you have a bunch of - so I've downloaded

00:24:47,170 --> 00:24:51,390
a bunch of Bible data, so to speak, and

00:24:51,390 --> 00:24:53,520
in that, there's a bunch of versus, which are

00:24:53,520 --> 00:24:57,560
sentences and paragraphs. The vector is really just a

00:24:57,560 --> 00:25:02,130
frequency distribution of each sentence.

00:25:02,130 --> 00:25:05,150
So each sentence, going through one by one, I

00:25:05,150 --> 00:25:08,270
wanted to make sure that the data was well-defined

00:25:08,270 --> 00:25:15,270
for that particular sentence. Does that make sense? Great.

00:25:17,720 --> 00:25:21,590
Now, we can test what data goes in and

00:25:21,590 --> 00:25:24,630
make sure that our data is always well-formed, but

00:25:24,630 --> 00:25:27,500
really the most important test when we're testing things

00:25:27,500 --> 00:25:31,300
is how it performs. And for that, we have

00:25:31,300 --> 00:25:34,250
something called cross-validation.

00:25:34,250 --> 00:25:35,680
Now if any of you who have ever looked

00:25:35,680 --> 00:25:41,010
into neural nets, you've probably heard of, learned that

00:25:41,010 --> 00:25:43,570
there is an error rate inside of the neural

00:25:43,570 --> 00:25:46,170
net. So there's this basic idea that this neural

00:25:46,170 --> 00:25:48,460
net has an error rate of five percent or

00:25:48,460 --> 00:25:50,620
whatever.

00:25:50,620 --> 00:25:55,860
Now, we could rely on that. But I feel

00:25:55,860 --> 00:25:58,720
that it's actually more powerful to split your data

00:25:58,720 --> 00:26:01,980
into two pieces. One of them being a training

00:26:01,980 --> 00:26:04,960
piece and the other one being a validation piece.

00:26:04,960 --> 00:26:08,360
And the real important distinction there is that, with

00:26:08,360 --> 00:26:11,520
the validation piece, we can validate against new data

00:26:11,520 --> 00:26:13,420
as it comes in, to make sure that our

00:26:13,420 --> 00:26:17,810
model is still performing as we expect it to.

00:26:17,810 --> 00:26:21,010
So, cross-validation is really just this generic term of

00:26:21,010 --> 00:26:25,420
splitting your data into multiple pieces and modeling it

00:26:25,420 --> 00:26:29,380
against the train, the trained model. And the last

00:26:29,380 --> 00:26:32,300
thing that we really need to test is Ockham's

00:26:32,300 --> 00:26:33,370
Razor.

00:26:33,370 --> 00:26:38,780
And this sounds completely out of context, but hang

00:26:38,780 --> 00:26:43,110
with me for a second. Neural networks take steps.

00:26:43,110 --> 00:26:47,570
So each training algorithm is an iteration, over and

00:26:47,570 --> 00:26:51,510
over and over again. If those iterations go on

00:26:51,510 --> 00:26:56,270
for millions of billions of times, most likely what

00:26:56,270 --> 00:27:01,020
we're trying to model is not working very well.

00:27:01,020 --> 00:27:02,590
So the thing to think about here is that

00:27:02,590 --> 00:27:06,000
Ockham's Razors is all about simplicity being the best

00:27:06,000 --> 00:27:10,310
answer if you can find the simple answer. So

00:27:10,310 --> 00:27:12,080
with neural nets, we want to make sure that

00:27:12,080 --> 00:27:15,940
our model doesn't take a really long time to

00:27:15,940 --> 00:27:19,770
train, because if it does, most likely it's not

00:27:19,770 --> 00:27:22,050
seeing the patterns, or there is no pattern to

00:27:22,050 --> 00:27:24,020
begin with.

00:27:24,020 --> 00:27:26,070
So while you can't explicitly test for this, this

00:27:26,070 --> 00:27:27,750
is something to keep in the back of your

00:27:27,750 --> 00:27:32,140
mind as kind of a cognitive test, I suppose.

00:27:32,140 --> 00:27:35,970
You will know when your neural network all of

00:27:35,970 --> 00:27:40,120
a sudden doesn't work because it takes all of,

00:27:40,120 --> 00:27:45,750
a really long time to run.

00:27:45,750 --> 00:27:47,790
That's a lot to take in.

00:27:47,790 --> 00:27:51,710
And I'm really excited that all of you are

00:27:51,710 --> 00:27:54,680
sticking with me on this, because neural networks can

00:27:54,680 --> 00:27:58,040
be a lot in the very beginning. But I

00:27:58,040 --> 00:28:00,860
think this will be actually a lot more exciting,

00:28:00,860 --> 00:28:06,370
because I personally learn in terms of application. And

00:28:06,370 --> 00:28:07,980
at the end of this talk, I'm going to

00:28:07,980 --> 00:28:12,170
post a link, which you guys can go and

00:28:12,170 --> 00:28:13,860
get all of the resources to this.

00:28:13,860 --> 00:28:17,130
I recommend that you download the GitHub repository, you

00:28:17,130 --> 00:28:20,210
play around with it and actually learn how it,

00:28:20,210 --> 00:28:23,200
how it works, because really we all learn through

00:28:23,200 --> 00:28:26,520
application.

00:28:26,520 --> 00:28:29,440
So let's go through this one by one.

00:28:29,440 --> 00:28:31,820
I'm going to start this test because it takes

00:28:31,820 --> 00:28:33,440
twenty seconds or so and I don't want to

00:28:33,440 --> 00:28:36,520
sit here waiting for it to run. So this

00:28:36,520 --> 00:28:39,340
is just running my, my unit test that, or

00:28:39,340 --> 00:28:41,130
not really unit tests, but my test suite that

00:28:41,130 --> 00:28:44,750
I've defined up on the previous slides.

00:28:44,750 --> 00:28:47,930
And let's load this up so that you can

00:28:47,930 --> 00:28:50,920
see that I have two tests in here. One

00:28:50,920 --> 00:28:53,990
of them being a language test, which is just

00:28:53,990 --> 00:28:56,340
the seam test, and the other one being the

00:28:56,340 --> 00:29:00,540
cross-validation test. Now when I was personally writing the

00:29:00,540 --> 00:29:03,880
language test, I was getting a little annoyed because

00:29:03,880 --> 00:29:05,800
I'm thinking, wow, this is a lot of boilerplate.

00:29:05,800 --> 00:29:08,370
This is kind of silly that I'm making sure

00:29:08,370 --> 00:29:12,990
that what I'm writing is correct until I found

00:29:12,990 --> 00:29:15,600
a really nasty bug that tripped me up for

00:29:15,600 --> 00:29:19,750
a little bit of time. And that was, UTF8

00:29:19,750 --> 00:29:24,390
characters in Ruby is really hard to work with.

00:29:24,390 --> 00:29:29,870
Splitting on spaces or downcasing things that have umlauts

00:29:29,870 --> 00:29:32,920
over them is a tricky prospect, and I was

00:29:32,920 --> 00:29:36,510
finding things like, oh, space is a character that

00:29:36,510 --> 00:29:38,720
we want to model in our model, which is

00:29:38,720 --> 00:29:42,040
not true. That happened to just be the UTF8

00:29:42,040 --> 00:29:45,170
character of space.

00:29:45,170 --> 00:29:49,770
So after writing these tests, I came in here

00:29:49,770 --> 00:29:53,620
and I explicitly put this translate - can everybody

00:29:53,620 --> 00:29:55,730
see this, by the way? Should I make it

00:29:55,730 --> 00:29:58,300
a little bi- OK, great.

00:29:58,300 --> 00:30:00,170
So I had to explicitly translate some of these

00:30:00,170 --> 00:30:02,860
special characters like a circle, which is Swedish, and

00:30:02,860 --> 00:30:09,010
the German characters, which is really enlightening, especially since

00:30:09,010 --> 00:30:10,580
I was- I wanted to make sure that my

00:30:10,580 --> 00:30:13,870
data was well-formed, and the test actually told me

00:30:13,870 --> 00:30:16,890
right away that something was wrong.

00:30:16,890 --> 00:30:19,000
As opposed to learning about it after I've put

00:30:19,000 --> 00:30:23,390
all the effort into training the neural network.

00:30:23,390 --> 00:30:27,240
So that's the seam test in a nutshell.

00:30:27,240 --> 00:30:30,820
Cross-validation is actually mostly just setting up the two

00:30:30,820 --> 00:30:33,820
different neural nets, which one of them is the

00:30:33,820 --> 00:30:38,010
Matthew verses from the book and the ax verses.

00:30:38,010 --> 00:30:41,550
And down here I'm going through each language, English,

00:30:41,550 --> 00:30:44,670
German, Finnish, Norwegian, Polish, Swedish. And testing to make

00:30:44,670 --> 00:30:46,510
sure that it has an error rate of strictly

00:30:46,510 --> 00:30:49,150
less than five percent.

00:30:49,150 --> 00:30:53,490
I just arbitrarily picked five percent because five out

00:30:53,490 --> 00:30:56,600
of a hundred times of errors is OK with

00:30:56,600 --> 00:30:59,460
me. I don't really care that much.

00:30:59,460 --> 00:31:03,720
This test really just trains a network and validates

00:31:03,720 --> 00:31:08,620
against known quantities. Now let's go back and take

00:31:08,620 --> 00:31:11,050
a look and see if this still runs.

00:31:11,050 --> 00:31:13,210
As you can see here, there's a bunch of

00:31:13,210 --> 00:31:15,630
output, and this is from the gem that I

00:31:15,630 --> 00:31:19,300
was using called RubyFan. It was just a artificial

00:31:19,300 --> 00:31:23,310
network gem off the shelf. I didn't really do

00:31:23,310 --> 00:31:25,900
anything with it. This is a bunch of output

00:31:25,900 --> 00:31:31,530
from that. It actually runs and it's correct.

00:31:31,530 --> 00:31:33,550
Now the thing that's interesting here, though, is that

00:31:33,550 --> 00:31:36,850
when we build neural networks, a lot of the

00:31:36,850 --> 00:31:39,340
times there's things that you can tweak. You can

00:31:39,340 --> 00:31:42,940
try new things, and in this case, I did.

00:31:42,940 --> 00:31:46,140
So this network class, you can try to set

00:31:46,140 --> 00:31:49,960
error rates at many different levels, and since I

00:31:49,960 --> 00:31:52,610
had an automated test, I could explicitly test to

00:31:52,610 --> 00:31:54,300
make sure that it was strictly less than five

00:31:54,300 --> 00:31:59,380
percent. So I found that point zero zero five

00:31:59,380 --> 00:32:02,220
worked. So I just went with that.

00:32:02,220 --> 00:32:04,080
On top of that, I decided to use the

00:32:04,080 --> 00:32:07,280
fancier activation function, the Elliot function just because I

00:32:07,280 --> 00:32:09,860
felt like it. The important thing here to realize

00:32:09,860 --> 00:32:12,800
though is that I can change or experiment with

00:32:12,800 --> 00:32:16,220
many different things and if I try something that

00:32:16,220 --> 00:32:19,470
breaks the entire thing, I will know it breaks.

00:32:19,470 --> 00:32:21,320
And that's huge.

00:32:21,320 --> 00:32:24,990
Now, of course, we're not gonna go through every

00:32:24,990 --> 00:32:27,040
line of code one by one, so I wanted

00:32:27,040 --> 00:32:29,410
to show you what this looks like in a

00:32:29,410 --> 00:32:33,850
little Sinatra app, where you can basically come in

00:32:33,850 --> 00:32:40,850
here and type in random words.

00:32:41,080 --> 00:32:44,700
Or we can - I don't know Swedish, so

00:32:44,700 --> 00:32:50,820
I don't know what this says, but. Mileage may

00:32:50,820 --> 00:32:51,880
very.

00:32:51,880 --> 00:32:54,760
It, it will show up as red if it's

00:32:54,760 --> 00:32:56,820
mis-classified. And I've been playing with this for awhile

00:32:56,820 --> 00:33:01,660
and it, it does mis-classify once in awhile. This

00:33:01,660 --> 00:33:08,660
is Polish now. Oh boy, that's long. Norwegian. OK.

00:33:08,670 --> 00:33:11,790
I don't see mis-classification.

00:33:11,790 --> 00:33:16,260
Well, you get the picture. And for a little

00:33:16,260 --> 00:33:17,440
bit of fun I wanted to throw in just

00:33:17,440 --> 00:33:19,790
one little thing, and that is I really like

00:33:19,790 --> 00:33:22,230
the Swedish chef because he's hilarious on the Muppets

00:33:22,230 --> 00:33:25,160
and I was wondering what language he spoke.

00:33:25,160 --> 00:33:31,470
So, well, OK. So "No masken?" is Swedish. This,

00:33:31,470 --> 00:33:37,010
I don't even know what this says. Jaaa!! This

00:33:37,010 --> 00:33:44,010
is Polish obviously. No match. It says, okee dokee

00:33:46,420 --> 00:33:48,900
is Norwegian.

00:33:48,900 --> 00:33:52,420
Now, one thing to realize here though is that

00:33:52,420 --> 00:33:57,540
it does break down with smaller sample-sizes. So if

00:33:57,540 --> 00:34:01,390
you put in something like blam it will be

00:34:01,390 --> 00:34:07,660
Swedish, or l-a-m-o is Finnish supposedly.

00:34:07,660 --> 00:34:09,110
Now the thing to realize is that we are

00:34:09,110 --> 00:34:12,740
kind of looking at the average, so it will

00:34:12,740 --> 00:34:15,520
generally get better as you add more characters to

00:34:15,520 --> 00:34:19,010
it, but that is OK with me because, for

00:34:19,010 --> 00:34:21,310
the most part, that is how these classifiers work.

00:34:21,310 --> 00:34:22,850
So the more data that you give to it

00:34:22,850 --> 00:34:24,740
the better it becomes.

00:34:24,740 --> 00:34:26,300
But as you can see just using some of

00:34:26,300 --> 00:34:32,330
these random - it's, it does really extremely well

00:34:32,330 --> 00:34:39,310
just based off of character frequencies.

00:34:39,310 --> 00:34:43,520
OK.

00:34:43,520 --> 00:34:45,850
So there is the link that I recommend everybody

00:34:45,850 --> 00:34:49,659
go to. It's modulus seven dot com slash rubyconf.

00:34:49,659 --> 00:34:52,510
There's a bunch of different links on there. Some

00:34:52,510 --> 00:34:58,160
free data resources. There's a, there's actually a really

00:34:58,160 --> 00:35:00,660
good paper on there if you have an afternoon

00:35:00,660 --> 00:35:02,700
and you really want to delve into something, there's

00:35:02,700 --> 00:35:05,980
a paper written by Scott Falman, who, by the

00:35:05,980 --> 00:35:10,300
way, invented the emoticon.

00:35:10,300 --> 00:35:13,110
He also came up with the quick prop algorithm,

00:35:13,110 --> 00:35:17,490
which you saw earlier, and it's a really well-written

00:35:17,490 --> 00:35:20,040
piece that will explain some of the more deep

00:35:20,040 --> 00:35:23,740
mathematics behind feed forward neural networks.

00:35:23,740 --> 00:35:26,790
Also, to plug myself a little bit, there is

00:35:26,790 --> 00:35:29,910
a link up there to sign up for a

00:35:29,910 --> 00:35:34,900
email list. I'm writing a book about test-driven machine

00:35:34,900 --> 00:35:37,480
learning. It's called Thoughtful Machine Learning. It will be

00:35:37,480 --> 00:35:41,850
out in 2014. So if you want more information,

00:35:41,850 --> 00:35:43,960
it would be great if you signed up so

00:35:43,960 --> 00:35:46,380
that I can send you emails. That's hopefully not

00:35:46,380 --> 00:35:47,790
spam.

00:35:47,790 --> 00:35:51,260
I promise it won't be spam.

00:35:51,260 --> 00:35:53,280
Also, you can Tweet at me. You can come

00:35:53,280 --> 00:35:55,050
up and talk to me as much as you

00:35:55,050 --> 00:35:59,560
like. I will be here until tomorrow.

00:35:59,560 --> 00:36:00,790
But I want to leave you with this notion

00:36:00,790 --> 00:36:06,150
that this is not the beginning. I firmly believe

00:36:06,150 --> 00:36:09,050
that in this community we have an amazing amount

00:36:09,050 --> 00:36:11,550
of talent and people who will be able to

00:36:11,550 --> 00:36:14,910
make the next Pandora or the next Gmail. And

00:36:14,910 --> 00:36:17,050
I personally believe that the way that we're going

00:36:17,050 --> 00:36:19,190
to be able to do that is through utilizing

00:36:19,190 --> 00:36:19,970
data.

00:36:19,970 --> 00:36:23,240
Because data really is the next frontier when it

00:36:23,240 --> 00:36:26,430
comes to programming. And as you can see, just

00:36:26,430 --> 00:36:30,550
using a neural network to map really, just, simple

00:36:30,550 --> 00:36:34,680
text to languages is really powerful. It's also extremely

00:36:34,680 --> 00:36:37,890
fast. If you noticed, I was just typing things

00:36:37,890 --> 00:36:40,360
in and it was making a request every single

00:36:40,360 --> 00:36:43,550
time. It's extremely fast.

00:36:43,550 --> 00:36:47,710
So learning these techniques will make everybody here better.

00:36:47,710 --> 00:36:49,680
So I really challenge you to go out there,

00:36:49,680 --> 00:36:54,480
learn more about data analysis, and just learn more.

00:36:54,480 --> 00:36:57,000

YouTube URL: https://www.youtube.com/watch?v=ppf8m-3uXvU


