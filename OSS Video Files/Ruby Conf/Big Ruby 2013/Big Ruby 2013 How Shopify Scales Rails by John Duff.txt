Title: Big Ruby 2013 How Shopify Scales Rails by John Duff
Publication date: 2020-01-28
Playlist: Big Ruby 2013
Description: 
	Tobi Lutke wrote the first line of code for Shopify nearly 10 years ago to power his own Snowboard shop. Two years later Shopify launched to the public on a single webserver using Rails 0.13.1. Today Shopify powers over 40k online stores and processes up to half a million product sales per day across the platform. Over 30 people actively work on Shopify which makes it the longest developed and likely largest Rails code base out there.

This is the story of how Shopify has evolved to handle its immense growth over the years. This is what getting big is all about: evolving to meet the needs of your customers. You don't start out with a system and infrastructure that can handle a billion dollar in GMV. You evolve to it. You evolve by adding caching layers, hardware, queuing systems and splitting your application to services.

This is the story of how we have tackled the various scaling pain points that Shopify has hit and what we have done to surpass them, what we are doing to go even further.

Help us caption & translate this video!

http://amara.org/v/FGdU/
Captions: 
	00:00:18,710 --> 00:00:23,070
yeah my talk is about how Shopify scales

00:00:22,289 --> 00:00:27,000
rails

00:00:23,070 --> 00:00:29,699
so first up just what is Shopify I

00:00:27,000 --> 00:00:32,790
already had someone confuse us forever

00:00:29,699 --> 00:00:35,100
Spotify so we're not Spotify we're

00:00:32,790 --> 00:00:36,899
Shopify so we do hosted online

00:00:35,100 --> 00:00:38,820
e-commerce we make it really easy for

00:00:36,899 --> 00:00:43,079
just about anyone to set up an online

00:00:38,820 --> 00:00:45,120
store and get started with that so I

00:00:43,079 --> 00:00:48,360
grabbed a couple pictures of our office

00:00:45,120 --> 00:00:51,210
so we're really trying to to make it

00:00:48,360 --> 00:00:53,850
we're based up in Ottawa Canada so we've

00:00:51,210 --> 00:00:54,750
made our office like really fun like

00:00:53,850 --> 00:00:57,870
pulled a lot of really interesting

00:00:54,750 --> 00:01:00,809
things from different offices in Silicon

00:00:57,870 --> 00:01:03,629
Valley and it's a really amazing really

00:01:00,809 --> 00:01:05,129
cool place to work so I like to share

00:01:03,629 --> 00:01:06,840
that with everyone because it's a really

00:01:05,129 --> 00:01:08,610
cool place even though we're up in

00:01:06,840 --> 00:01:10,080
Canada and it's like really cold all the

00:01:08,610 --> 00:01:16,229
time this this kind of makes it

00:01:10,080 --> 00:01:19,740
worthwhile anyways like into into the

00:01:16,229 --> 00:01:24,780
talk so I'd like just share like kind of

00:01:19,740 --> 00:01:29,189
our stack what we run on so we're

00:01:24,780 --> 00:01:32,250
running Ruby 193 patch level 327 rails

00:01:29,189 --> 00:01:36,930
3-2 we just like made the big bump from

00:01:32,250 --> 00:01:40,350
rails 3 to rails 3 to Monday so that was

00:01:36,930 --> 00:01:44,369
pretty crazy we use a pro Kona flavor of

00:01:40,350 --> 00:01:46,049
MySQL 55 so proponent builds of MySQL

00:01:44,369 --> 00:01:48,600
that we use they had a lot of

00:01:46,049 --> 00:01:50,790
instrumentation and performance patches

00:01:48,600 --> 00:01:53,610
so we use that and then we're running on

00:01:50,790 --> 00:01:55,740
unicorn memcache and we have Redis in

00:01:53,610 --> 00:02:00,540
the stack so that's kind of the main

00:01:55,740 --> 00:02:01,380
moving parts to Shopify so it kind of

00:02:00,540 --> 00:02:03,659
looks like this

00:02:01,380 --> 00:02:07,170
you know nginx and unicorn in front of

00:02:03,659 --> 00:02:10,410
rails and Ruby holding everything up we

00:02:07,170 --> 00:02:12,480
have 33 app servers eleven hundred and

00:02:10,410 --> 00:02:15,959
seventy-two unicorn workers

00:02:12,480 --> 00:02:18,360
five job servers and 307 job workers so

00:02:15,959 --> 00:02:21,799
lots of stuff processing lots of stuff

00:02:18,360 --> 00:02:25,349
happening at once which is pretty cool

00:02:21,799 --> 00:02:28,409
so this is kind of what a little piece

00:02:25,349 --> 00:02:31,019
of the cluster looks like we have

00:02:28,409 --> 00:02:33,989
firewall load balancer we have our App

00:02:31,019 --> 00:02:37,340
servers which are then replicated across

00:02:33,989 --> 00:02:40,290
we have search and Redis job servers

00:02:37,340 --> 00:02:43,890
pretty standard set up and we can scale

00:02:40,290 --> 00:02:48,810
all these pieces horizontally which is

00:02:43,890 --> 00:02:51,420
pretty great just an idea of the amount

00:02:48,810 --> 00:02:53,970
of code in the Shopify project itself so

00:02:51,420 --> 00:02:56,129
we have a bunch of like projects around

00:02:53,970 --> 00:02:59,420
Shopify itself so these stats are just

00:02:56,129 --> 00:03:02,160
for the Shopify core product itself so

00:02:59,420 --> 00:03:05,160
55,000 lines of application code 80

00:03:02,160 --> 00:03:08,609
lounge lines of test code 211

00:03:05,160 --> 00:03:10,470
controllers 468 models so there's a lot

00:03:08,609 --> 00:03:15,599
of code in there and there's a lot of

00:03:10,470 --> 00:03:18,269
stuff going on lots of Ruby so what's

00:03:15,599 --> 00:03:21,780
our current scale like what kind of how

00:03:18,269 --> 00:03:25,410
much are we doing and what does that

00:03:21,780 --> 00:03:27,810
look like so last year we processed

00:03:25,410 --> 00:03:30,030
nine point nine million orders on behalf

00:03:27,810 --> 00:03:33,480
of our merchants and this works out to

00:03:30,030 --> 00:03:36,780
be an order every 3.2 seconds so that

00:03:33,480 --> 00:03:40,019
was pretty amazing last year on cyber

00:03:36,780 --> 00:03:42,480
monday we process 2008 sales per minute

00:03:40,019 --> 00:03:45,060
so cyber monday is traditionally our

00:03:42,480 --> 00:03:47,069
busiest time of year so we were doing

00:03:45,060 --> 00:03:50,130
2008 sales per minute which is pretty

00:03:47,069 --> 00:03:53,730
crazy one really amazing thing about

00:03:50,130 --> 00:03:56,489
this is in about a month or two this is

00:03:53,730 --> 00:03:59,010
like our regular transaction rate and

00:03:56,489 --> 00:04:00,959
next year it'll be double so it's really

00:03:59,010 --> 00:04:02,970
amazing just like how fast things are

00:04:00,959 --> 00:04:06,780
growing and how fast we're needing the

00:04:02,970 --> 00:04:09,690
scale and deal with this stuff so we've

00:04:06,780 --> 00:04:12,629
run out about 50,000 requests per minute

00:04:09,690 --> 00:04:15,150
on a regular day and we keep it pretty

00:04:12,629 --> 00:04:18,329
steady at about 45 millisecond response

00:04:15,150 --> 00:04:20,310
time so lots of requests and we're

00:04:18,329 --> 00:04:24,510
serving them really fast to make our

00:04:20,310 --> 00:04:26,330
users happy which is really cool last

00:04:24,510 --> 00:04:29,700
year we served about three

00:04:26,330 --> 00:04:33,030
3.3 billion requests so this is just

00:04:29,700 --> 00:04:34,710
Shopify itself and all the CDN and all

00:04:33,030 --> 00:04:36,690
the image requests but just the core

00:04:34,710 --> 00:04:39,990
application we serve thirteen point

00:04:36,690 --> 00:04:45,870
three billion requests which is a

00:04:39,990 --> 00:04:49,800
shitload of requests so before I get

00:04:45,870 --> 00:04:51,660
into it too much more I really think

00:04:49,800 --> 00:04:53,610
it's important for us to look at like

00:04:51,660 --> 00:04:56,310
where we came from and like what

00:04:53,610 --> 00:04:58,800
happened in the past I find like myself

00:04:56,310 --> 00:05:00,780
included our generation of developers we

00:04:58,800 --> 00:05:02,610
really like to look at the new things

00:05:00,780 --> 00:05:04,350
the new technologies that are coming out

00:05:02,610 --> 00:05:06,240
but it's really important to look at

00:05:04,350 --> 00:05:08,310
what's happened in the past to get like

00:05:06,240 --> 00:05:09,690
an idea of what what's been done and

00:05:08,310 --> 00:05:12,660
what's been solved and how it's been

00:05:09,690 --> 00:05:17,400
solved so this is just a look at the

00:05:12,660 --> 00:05:20,130
history of Shopify so the first line of

00:05:17,400 --> 00:05:24,270
code to Shopify was written in 2004 by

00:05:20,130 --> 00:05:27,240
Toby and like a coffee shop somewhere we

00:05:24,270 --> 00:05:29,669
released the first version in 2005 it's

00:05:27,240 --> 00:05:32,400
been the same codebase since that

00:05:29,669 --> 00:05:33,930
initial line of code was written if I

00:05:32,400 --> 00:05:35,580
tried hard enough I could probably find

00:05:33,930 --> 00:05:38,160
those first couple of lines of code in

00:05:35,580 --> 00:05:40,800
there in the history so that's nine

00:05:38,160 --> 00:05:44,280
years of rails upgrades improvements and

00:05:40,800 --> 00:05:47,370
changes on the same codebase I'm not a

00:05:44,280 --> 00:05:48,960
hundred percent sure but at this point

00:05:47,370 --> 00:05:50,640
I'd say we're like one of the longest

00:05:48,960 --> 00:05:53,790
running rails applications out there

00:05:50,640 --> 00:05:56,870
seeing as the Basecamp last release I

00:05:53,790 --> 00:05:59,310
believe they rewrote most of it so

00:05:56,870 --> 00:06:03,720
longest-running rails app as far as I

00:05:59,310 --> 00:06:06,990
know which is really cool so looking

00:06:03,720 --> 00:06:10,800
back at the stats for when Shopify was

00:06:06,990 --> 00:06:11,640
released in 2005 they had 6,000 lines of

00:06:10,800 --> 00:06:14,520
code

00:06:11,640 --> 00:06:16,610
there was a lot less test code a lot

00:06:14,520 --> 00:06:19,410
less controllers and a lot less models

00:06:16,610 --> 00:06:21,390
so over this time we've grown

00:06:19,410 --> 00:06:26,400
substantially and had to deal with all

00:06:21,390 --> 00:06:30,030
that growth and this is what the stack

00:06:26,400 --> 00:06:31,979
probably looked like at that time so I

00:06:30,030 --> 00:06:33,750
had to I dug through the first couple

00:06:31,979 --> 00:06:35,729
commits and just looking at some

00:06:33,750 --> 00:06:39,030
timelines to figure this out but we were

00:06:35,729 --> 00:06:39,810
probably running on Ruby 182 we were for

00:06:39,030 --> 00:06:42,510
sure using it

00:06:39,810 --> 00:06:45,720
version of rails before 100 we were we

00:06:42,510 --> 00:06:48,780
were tracking the master for a long time

00:06:45,720 --> 00:06:50,820
we were probably on MySQL 4.1 we're

00:06:48,780 --> 00:06:53,280
using light instead of unicorn and

00:06:50,820 --> 00:06:56,460
memcache was already in the mix right

00:06:53,280 --> 00:06:57,690
from the get-go some interesting things

00:06:56,460 --> 00:06:59,970
to think about if you're a rails

00:06:57,690 --> 00:07:03,150
developer like I kind of went through

00:06:59,970 --> 00:07:05,730
what wasn't in rails at this time so

00:07:03,150 --> 00:07:08,700
like you don't have any rjs you don't

00:07:05,730 --> 00:07:10,710
have any response - there's no like

00:07:08,700 --> 00:07:13,620
respond with response to those like

00:07:10,710 --> 00:07:16,440
deprecated for respond with there's no

00:07:13,620 --> 00:07:20,389
like nested includes for either loading

00:07:16,440 --> 00:07:24,500
polymorphic associations Capistrano rest

00:07:20,389 --> 00:07:27,540
resources scopes gem files thread safety

00:07:24,500 --> 00:07:30,389
rack none of these things existed when

00:07:27,540 --> 00:07:32,850
we first released Shopify so it's really

00:07:30,389 --> 00:07:35,820
amazing and we've come to upgrade and

00:07:32,850 --> 00:07:38,040
like depend on all these new things over

00:07:35,820 --> 00:07:43,290
time so it's really cool looking back at

00:07:38,040 --> 00:07:46,470
where we came from so into the meat of

00:07:43,290 --> 00:07:48,180
it know the system so to me the most

00:07:46,470 --> 00:07:50,490
important part of scaling your

00:07:48,180 --> 00:07:53,340
application you really need to know what

00:07:50,490 --> 00:07:55,680
it's about so there isn't really any

00:07:53,340 --> 00:07:57,240
magical formula to scaling it's knowing

00:07:55,680 --> 00:08:00,030
the characteristics of your particular

00:07:57,240 --> 00:08:02,550
system and changing or removing the

00:08:00,030 --> 00:08:03,630
constraints it imposes and your

00:08:02,550 --> 00:08:05,600
constraints are going to be very

00:08:03,630 --> 00:08:07,890
different than the constraints we've had

00:08:05,600 --> 00:08:09,990
our constraints are based on an

00:08:07,890 --> 00:08:12,389
e-commerce platform where we have an

00:08:09,990 --> 00:08:14,250
admin and a storefront the storefront is

00:08:12,389 --> 00:08:18,479
used by the customers to make purchases

00:08:14,250 --> 00:08:20,490
and the administrator of the shop the

00:08:18,479 --> 00:08:22,590
storefront is the most important part of

00:08:20,490 --> 00:08:23,850
the system because we want transactions

00:08:22,590 --> 00:08:26,610
to happen so that's where we're gonna

00:08:23,850 --> 00:08:28,350
optimize things and knowing this is like

00:08:26,610 --> 00:08:29,729
a big part of the battle because you

00:08:28,350 --> 00:08:31,860
need to know where to start for your

00:08:29,729 --> 00:08:33,839
optimizations if we want to if we

00:08:31,860 --> 00:08:35,550
started optimizing the admin we'd be

00:08:33,839 --> 00:08:40,229
wasting our time because that's not the

00:08:35,550 --> 00:08:43,440
most important part of the system so one

00:08:40,229 --> 00:08:44,159
request one process so we're using

00:08:43,440 --> 00:08:46,080
unicorn

00:08:44,159 --> 00:08:48,540
so maybe you have it set up we have one

00:08:46,080 --> 00:08:50,670
request and it's handled by one process

00:08:48,540 --> 00:08:53,190
this isn't necessarily true for all

00:08:50,670 --> 00:08:53,750
applications but I believe most rails

00:08:53,190 --> 00:08:56,629
apps

00:08:53,750 --> 00:08:59,029
our setup in this way you might be using

00:08:56,629 --> 00:09:01,250
a threaded web server and might not be

00:08:59,029 --> 00:09:03,769
the case but most of us are in this

00:09:01,250 --> 00:09:06,470
situation and knowing this fact is

00:09:03,769 --> 00:09:09,170
really important for us to know how to

00:09:06,470 --> 00:09:11,269
scale because now we know that this is

00:09:09,170 --> 00:09:13,730
the situation we're in we have a process

00:09:11,269 --> 00:09:15,560
and it's handling or a request and if we

00:09:13,730 --> 00:09:18,050
want to make these faster we add

00:09:15,560 --> 00:09:23,870
processes or we make the individual

00:09:18,050 --> 00:09:26,300
processes themselves faster so I

00:09:23,870 --> 00:09:29,480
mentioned our rpm or request per minute

00:09:26,300 --> 00:09:31,459
earlier so this is kind of a formula for

00:09:29,480 --> 00:09:34,490
actually this is wrong it's not a 1 it's

00:09:31,459 --> 00:09:39,250
a 60 but it's requests per minute is

00:09:34,490 --> 00:09:43,850
workers times 60 over the response time

00:09:39,250 --> 00:09:45,769
so I was using the numbers from that I

00:09:43,850 --> 00:09:48,589
had on the previous slide and we can

00:09:45,769 --> 00:09:51,769
calculate the potential rpm for Shopify

00:09:48,589 --> 00:09:55,250
using the number of workers and the

00:09:51,769 --> 00:09:58,699
response time that we have so if we use

00:09:55,250 --> 00:10:01,370
that we can come up with a potential rpm

00:09:58,699 --> 00:10:03,230
of close to a million and the key here

00:10:01,370 --> 00:10:05,389
is it's a potential because there's a

00:10:03,230 --> 00:10:09,170
lot of other factors that are involved

00:10:05,389 --> 00:10:11,629
when when handling the requests but this

00:10:09,170 --> 00:10:14,779
gives us kind of an idea of the pieces

00:10:11,629 --> 00:10:16,939
that we can move around to help to scale

00:10:14,779 --> 00:10:21,680
and help to improve how much we can

00:10:16,939 --> 00:10:24,050
process so the two main knobs that we

00:10:21,680 --> 00:10:26,360
have to dial are increasing the number

00:10:24,050 --> 00:10:29,569
of workers or decreasing response time

00:10:26,360 --> 00:10:31,610
so increasing the number of workers is

00:10:29,569 --> 00:10:34,819
pretty easy we add boxes we can add more

00:10:31,610 --> 00:10:36,680
processes that's not a big deal what

00:10:34,819 --> 00:10:39,819
gets tricky and where the interesting

00:10:36,680 --> 00:10:43,579
work lies is decreasing a response time

00:10:39,819 --> 00:10:45,559
and knowing that these are the things

00:10:43,579 --> 00:10:47,149
that you have to work with is really

00:10:45,559 --> 00:10:53,089
important when you're trying to scale a

00:10:47,149 --> 00:10:55,100
system so if we want to increase

00:10:53,089 --> 00:10:57,410
response time the things we want to do

00:10:55,100 --> 00:10:59,870
is avoid Network calls during the

00:10:57,410 --> 00:11:01,730
requests so anything that's happening

00:10:59,870 --> 00:11:04,699
during the request we want to cut them

00:11:01,730 --> 00:11:06,439
out if possible if we have unavoidable

00:11:04,699 --> 00:11:07,130
Network calls like calls to memcache

00:11:06,439 --> 00:11:09,380
called the route

00:11:07,130 --> 00:11:11,840
whatever they are we can try and speed

00:11:09,380 --> 00:11:14,840
those up in whatever ways we can by

00:11:11,840 --> 00:11:18,530
using faster libraries or dropping down

00:11:14,840 --> 00:11:20,510
to C code if we need to in Shopify's

00:11:18,530 --> 00:11:21,950
case the storefront and the checkout are

00:11:20,510 --> 00:11:24,770
the most important things so these are

00:11:21,950 --> 00:11:26,480
the things that we focus on initially

00:11:24,770 --> 00:11:27,980
when trying to speed up Shopify because

00:11:26,480 --> 00:11:30,200
these are the parts that are getting hit

00:11:27,980 --> 00:11:32,780
by the most users and knowing that this

00:11:30,200 --> 00:11:35,410
is the most important part makes it

00:11:32,780 --> 00:11:39,020
easier to figure out what you need to do

00:11:35,410 --> 00:11:41,660
we also have this interesting sort of

00:11:39,020 --> 00:11:43,310
aspect to our system called the chive

00:11:41,660 --> 00:11:46,430
does everyone know what the chivor e is

00:11:43,310 --> 00:11:48,980
so through there s funny website and

00:11:46,430 --> 00:11:52,430
they sell sell t-shirts and stuff online

00:11:48,980 --> 00:11:54,530
but they do flash sales and so this is

00:11:52,430 --> 00:11:56,720
an interesting aspect to our system that

00:11:54,530 --> 00:12:00,680
has come up in the last year or so is

00:11:56,720 --> 00:12:02,630
having to handle these flash sales so to

00:12:00,680 --> 00:12:05,660
just give you an idea of what this looks

00:12:02,630 --> 00:12:10,300
like this is a new relic graph of a

00:12:05,660 --> 00:12:12,860
chive that happened today at 11 o'clock

00:12:10,300 --> 00:12:15,770
so the numbers there may be a little bit

00:12:12,860 --> 00:12:19,670
blurry but you can see the regular rpm

00:12:15,770 --> 00:12:26,660
is around 55 K and then we spiked up in

00:12:19,670 --> 00:12:28,400
about 10 minutes to 200 K and then that

00:12:26,660 --> 00:12:31,490
lasts for about 10 minutes and then

00:12:28,400 --> 00:12:33,830
drops down so knowing the fact that we

00:12:31,490 --> 00:12:39,110
have to handle this we can't just like

00:12:33,830 --> 00:12:41,630
deal with scaling at the 50 or 75 K rpm

00:12:39,110 --> 00:12:44,180
we need to be able to absorb these huge

00:12:41,630 --> 00:12:45,710
spikes in traffic which makes it really

00:12:44,180 --> 00:12:47,720
tricky and we have to have all this

00:12:45,710 --> 00:12:51,290
Headroom to be able to absorb these

00:12:47,720 --> 00:12:53,360
things and sometimes they're nice of a

00:12:51,290 --> 00:12:55,310
enough to let us know when these splash

00:12:53,360 --> 00:12:58,190
sales are happening a lot of time we

00:12:55,310 --> 00:12:59,840
don't know and as we add more customers

00:12:58,190 --> 00:13:02,450
doing these things because flash sales

00:12:59,840 --> 00:13:03,740
are really popular it's hard to predict

00:13:02,450 --> 00:13:05,060
when these are going to happen so we

00:13:03,740 --> 00:13:10,940
just need to be able to handle these

00:13:05,060 --> 00:13:12,680
sort of spikes in our system so one of

00:13:10,940 --> 00:13:16,790
the big things is just measuring

00:13:12,680 --> 00:13:18,950
everything you can get your hands on so

00:13:16,790 --> 00:13:20,570
knowing how fast things are moving

00:13:18,950 --> 00:13:22,280
within the system

00:13:20,570 --> 00:13:24,080
looking at the parts that are most

00:13:22,280 --> 00:13:28,130
important and measuring those things is

00:13:24,080 --> 00:13:30,440
really important so we use a few tools

00:13:28,130 --> 00:13:32,060
New Relic a lot of people have mentioned

00:13:30,440 --> 00:13:34,610
it I think most people use New Relic

00:13:32,060 --> 00:13:35,840
it's one of the most amazing tools to be

00:13:34,610 --> 00:13:38,360
able to get insight into what's

00:13:35,840 --> 00:13:40,670
happening with your application we also

00:13:38,360 --> 00:13:43,220
use a tool called Splunk which is a log

00:13:40,670 --> 00:13:43,970
analyzer so we throw all our log files

00:13:43,220 --> 00:13:47,120
at Splunk

00:13:43,970 --> 00:13:49,670
and it lets us query them build graphs

00:13:47,120 --> 00:13:51,710
and reports and give us a lot of

00:13:49,670 --> 00:13:54,590
historical insight into what our system

00:13:51,710 --> 00:13:56,930
is doing and that's really amazing new

00:13:54,590 --> 00:13:59,180
stats D in a very similar manner so we

00:13:56,930 --> 00:14:02,210
are able to record different statistics

00:13:59,180 --> 00:14:05,930
that New Relic can't give us and cacti

00:14:02,210 --> 00:14:08,210
is similar but for MySQL so we use that

00:14:05,930 --> 00:14:09,620
to record historical statistics and

00:14:08,210 --> 00:14:11,660
generate graphs and be able to see

00:14:09,620 --> 00:14:14,180
what's been going on in the past and how

00:14:11,660 --> 00:14:16,520
we've been changing the system and how

00:14:14,180 --> 00:14:19,220
that's been improving or degrading

00:14:16,520 --> 00:14:21,200
performance over time we've also

00:14:19,220 --> 00:14:24,220
developed this tool in house called

00:14:21,200 --> 00:14:27,440
Conan and we use this to actually test

00:14:24,220 --> 00:14:29,270
the production system under load so

00:14:27,440 --> 00:14:31,820
Conan is a tool that's been developed

00:14:29,270 --> 00:14:33,890
it's still internal but at some point

00:14:31,820 --> 00:14:35,980
we'd like to open source it but it lets

00:14:33,890 --> 00:14:38,660
us throw huge amounts of traffic in

00:14:35,980 --> 00:14:42,530
somewhat realistic traffic patterns at

00:14:38,660 --> 00:14:44,810
the production system so we segregated

00:14:42,530 --> 00:14:47,510
an app server and we're able to pull it

00:14:44,810 --> 00:14:49,700
out of the main rotation and we can

00:14:47,510 --> 00:14:51,860
point particular shops at the app server

00:14:49,700 --> 00:14:53,990
and then we can use Conan to drive

00:14:51,860 --> 00:14:56,000
traffic to that app server and this way

00:14:53,990 --> 00:14:59,420
we can test the changes and see how they

00:14:56,000 --> 00:15:01,970
perform under load collect data and see

00:14:59,420 --> 00:15:04,120
where our bottlenecks are so it's really

00:15:01,970 --> 00:15:06,980
it's a really great tool and it's really

00:15:04,120 --> 00:15:09,680
important to test your system your

00:15:06,980 --> 00:15:10,790
production system under load to see how

00:15:09,680 --> 00:15:12,500
it's going to behave because you're

00:15:10,790 --> 00:15:18,290
never going to get the same sort of gist

00:15:12,500 --> 00:15:20,060
statistics when running in dev so just

00:15:18,290 --> 00:15:22,000
to show you some of the information we

00:15:20,060 --> 00:15:24,620
get from New Relic I think most people

00:15:22,000 --> 00:15:27,020
use New Relic so it gives you like an

00:15:24,620 --> 00:15:29,570
idea of the the web traffic memcache

00:15:27,020 --> 00:15:31,310
database Ruby and where all the time

00:15:29,570 --> 00:15:34,000
spent and you get to see your throughput

00:15:31,310 --> 00:15:34,000
over time

00:15:34,010 --> 00:15:39,200
this is just a little example of what we

00:15:36,200 --> 00:15:42,740
get from Splunk so this is it's not very

00:15:39,200 --> 00:15:45,140
clear but this is a graph showing HTTP

00:15:42,740 --> 00:15:49,610
response codes over time so with this

00:15:45,140 --> 00:15:51,700
we're able to set up alerts so if 500

00:15:49,610 --> 00:15:54,350
codes start to spike this is a good

00:15:51,700 --> 00:15:56,270
indicator that something's wrong so as

00:15:54,350 --> 00:15:59,210
long as it's all like 200 300

00:15:56,270 --> 00:16:01,370
everything's good but Splunk gives us

00:15:59,210 --> 00:16:02,960
this real-time sort of log analysis to

00:16:01,370 --> 00:16:06,620
be able to see what's going on right now

00:16:02,960 --> 00:16:10,430
and we can react to those whatever is

00:16:06,620 --> 00:16:12,200
happening we've also started putting

00:16:10,430 --> 00:16:14,810
stats in front of the teams so we've

00:16:12,200 --> 00:16:16,400
built this these dashboards we have an

00:16:14,810 --> 00:16:18,530
open source framework called dashing

00:16:16,400 --> 00:16:21,680
that lets you build these really great

00:16:18,530 --> 00:16:23,840
dashboards with information so we have

00:16:21,680 --> 00:16:25,490
them spread all over the office and put

00:16:23,840 --> 00:16:27,350
them in front of the teams and these are

00:16:25,490 --> 00:16:30,250
really great motivators to tell people

00:16:27,350 --> 00:16:33,890
where we need to focus our efforts and

00:16:30,250 --> 00:16:36,050
what needs to be improved so we spent a

00:16:33,890 --> 00:16:37,940
lot of time on Shopify core and the

00:16:36,050 --> 00:16:40,750
store front so we've got like requests

00:16:37,940 --> 00:16:44,540
down to 51 milliseconds which is amazing

00:16:40,750 --> 00:16:46,790
but as you can see the Shopify API 300

00:16:44,540 --> 00:16:48,710
milliseconds is kind of terrible so

00:16:46,790 --> 00:16:50,690
that's where we need to like be focusing

00:16:48,710 --> 00:16:53,030
our efforts now and knowing where you

00:16:50,690 --> 00:16:55,970
need to focus the effort is like half

00:16:53,030 --> 00:16:59,500
the battle another really interesting

00:16:55,970 --> 00:17:03,170
thing we did is we literally printed out

00:16:59,500 --> 00:17:06,589
everything from storefront requests on

00:17:03,170 --> 00:17:08,660
paper and all the database calls all the

00:17:06,589 --> 00:17:11,300
memcache hits everything that was

00:17:08,660 --> 00:17:12,740
happening so we did this before cyber

00:17:11,300 --> 00:17:14,959
monday this year where we were doing a

00:17:12,740 --> 00:17:16,880
big performance push and this was really

00:17:14,959 --> 00:17:18,290
great like just putting a real enemy in

00:17:16,880 --> 00:17:20,600
front of the team so that we had

00:17:18,290 --> 00:17:22,699
something to attack so we could go up

00:17:20,600 --> 00:17:25,370
and literally like cross things off as

00:17:22,699 --> 00:17:27,650
we fix them and just basically go

00:17:25,370 --> 00:17:30,170
through and slash all the requests down

00:17:27,650 --> 00:17:32,030
and cut out whatever we could so putting

00:17:30,170 --> 00:17:36,350
information in front of the team is

00:17:32,030 --> 00:17:38,180
super important so now that we're

00:17:36,350 --> 00:17:41,120
measuring things now that we know what

00:17:38,180 --> 00:17:43,970
we need to do what are some things that

00:17:41,120 --> 00:17:46,400
we can do to improve the performance and

00:17:43,970 --> 00:17:47,960
help us scale so caching is one of the

00:17:46,400 --> 00:17:51,140
big things

00:17:47,960 --> 00:17:53,179
so we have a gem called cacheable so

00:17:51,140 --> 00:17:59,660
this is controller billet based page

00:17:53,179 --> 00:18:02,750
caching and it's memcache backed so it's

00:17:59,660 --> 00:18:04,850
up on a public repo so people can use it

00:18:02,750 --> 00:18:07,160
which is pretty cool one of the neat

00:18:04,850 --> 00:18:09,290
things with it is we serve up the gzip

00:18:07,160 --> 00:18:11,900
content to the browser if it supports it

00:18:09,290 --> 00:18:14,540
and we also store the content gzipped

00:18:11,900 --> 00:18:16,850
into memcache so storing it in memcache

00:18:14,540 --> 00:18:18,679
gzip is really handy because it'll

00:18:16,850 --> 00:18:21,169
increase the response time when talking

00:18:18,679 --> 00:18:23,900
to memcache and then serving up the

00:18:21,169 --> 00:18:25,460
content gzipped when we can just cuts

00:18:23,900 --> 00:18:27,280
down the amount of work we need to do so

00:18:25,460 --> 00:18:29,900
we don't need to deflate it every time

00:18:27,280 --> 00:18:32,510
so one of the interesting things with

00:18:29,900 --> 00:18:35,750
cacheable is it uses this idea of

00:18:32,510 --> 00:18:38,809
generate generalization 'l generally a

00:18:35,750 --> 00:18:42,380
tional caching so this means each cache

00:18:38,809 --> 00:18:45,290
key is a generation and it changes over

00:18:42,380 --> 00:18:49,130
time when the data changes so in rails

00:18:45,290 --> 00:18:51,350
this is as simple as using like an

00:18:49,130 --> 00:18:53,840
updated @ timestamp so when the data

00:18:51,350 --> 00:18:55,580
changes the cache key changes and you'll

00:18:53,840 --> 00:18:58,700
get a cache miss and load the new data

00:18:55,580 --> 00:19:01,520
and push it into memcache when the next

00:18:58,700 --> 00:19:03,679
request comes in if no nothing has

00:19:01,520 --> 00:19:07,790
updated it you'll get a cache hit and

00:19:03,679 --> 00:19:10,100
serve it from the cache and this doesn't

00:19:07,790 --> 00:19:13,100
have an explicit expiry on the cache so

00:19:10,100 --> 00:19:15,770
the cache Keys changes and the data just

00:19:13,100 --> 00:19:19,780
falls off the end of the cache as it

00:19:15,770 --> 00:19:19,780
doesn't isn't used anymore

00:19:20,169 --> 00:19:25,549
so this is a little bit of code showing

00:19:23,030 --> 00:19:27,049
how you can use cacheable in in your

00:19:25,549 --> 00:19:29,240
application so this is just your

00:19:27,049 --> 00:19:33,140
controller and you have a response cache

00:19:29,240 --> 00:19:35,690
block and you just define what the key

00:19:33,140 --> 00:19:37,730
is based on so in Shopify we actually

00:19:35,690 --> 00:19:39,669
have a version on our shop since

00:19:37,730 --> 00:19:42,110
everything's kind of keyed off the shop

00:19:39,669 --> 00:19:44,030
when things change we increment the

00:19:42,110 --> 00:19:48,650
version of the shop and that busts the

00:19:44,030 --> 00:19:51,440
cache for us and there's another piece

00:19:48,650 --> 00:19:53,570
to it which includes a middleware so if

00:19:51,440 --> 00:19:55,520
there is a cache hit it won't even hit

00:19:53,570 --> 00:19:56,750
the controller stack so it's nice and

00:19:55,520 --> 00:20:01,330
fast it'll serve it I would have

00:19:56,750 --> 00:20:01,330
memcache really quickly which is great

00:20:02,880 --> 00:20:07,960
so another thing we started doing

00:20:05,049 --> 00:20:11,380
recently with cashable is started

00:20:07,960 --> 00:20:15,309
cashing 404s so errors are like

00:20:11,380 --> 00:20:16,900
unexpected and 404s happen and it's not

00:20:15,309 --> 00:20:19,539
really the first thing you think of to

00:20:16,900 --> 00:20:22,570
speed up but when people are typing

00:20:19,539 --> 00:20:24,669
things in randomly or trying URLs

00:20:22,570 --> 00:20:28,120
randomly we get a lot of four fours on

00:20:24,669 --> 00:20:32,400
Shopify so caching those four or four

00:20:28,120 --> 00:20:37,210
pages actually was pretty huge for us

00:20:32,400 --> 00:20:39,549
so you can see the the red line is the

00:20:37,210 --> 00:20:42,970
cache misses and you can see when we

00:20:39,549 --> 00:20:45,549
started caching four or fours that

00:20:42,970 --> 00:20:48,090
dropped drastically and we had a lot

00:20:45,549 --> 00:20:50,230
more cache hits which is the blue line

00:20:48,090 --> 00:20:51,970
so we saw a lot of performance

00:20:50,230 --> 00:20:54,159
improvements once we started doing this

00:20:51,970 --> 00:20:56,020
and just looking at our traffic patterns

00:20:54,159 --> 00:20:58,210
we were able to determine that like

00:20:56,020 --> 00:21:01,510
we're having a lot of four fours and

00:20:58,210 --> 00:21:05,110
this was a pretty easy win to add some

00:21:01,510 --> 00:21:08,169
caching too so another really

00:21:05,110 --> 00:21:11,590
interesting tool that we built in-house

00:21:08,169 --> 00:21:15,400
is identity cache so this is actually

00:21:11,590 --> 00:21:18,429
really similar to that what Brian was

00:21:15,400 --> 00:21:20,320
talking about record cache or something

00:21:18,429 --> 00:21:24,820
like that so this is a memcache bat

00:21:20,320 --> 00:21:28,390
backed model caching and this was

00:21:24,820 --> 00:21:30,490
written a few years ago by Toby and kind

00:21:28,390 --> 00:21:32,830
of went unnoticed in Shopify for a while

00:21:30,490 --> 00:21:35,080
and then as we were really trying to

00:21:32,830 --> 00:21:36,970
improve import performance we started

00:21:35,080 --> 00:21:39,820
using identity cache all over the place

00:21:36,970 --> 00:21:41,230
to cache as many models as we can in

00:21:39,820 --> 00:21:45,820
memcache so we don't need to hit the

00:21:41,230 --> 00:21:48,700
database as often so this lets us cache

00:21:45,820 --> 00:21:50,500
full model objects and in memcache we

00:21:48,700 --> 00:21:54,159
can include associated objects in the

00:21:50,500 --> 00:21:55,870
cache we can embed them with the parent

00:21:54,159 --> 00:21:57,700
object so you can load the parent object

00:21:55,870 --> 00:21:59,919
and you get all the associated objects

00:21:57,700 --> 00:22:02,350
back which is really great

00:21:59,919 --> 00:22:05,250
we made this an opt-in caching strategy

00:22:02,350 --> 00:22:07,870
so you need to you need to say which

00:22:05,250 --> 00:22:10,000
models and which associations need to be

00:22:07,870 --> 00:22:12,280
cached and you also need to opt in to

00:22:10,000 --> 00:22:13,660
using the cache because there's certain

00:22:12,280 --> 00:22:15,970
points when you want

00:22:13,660 --> 00:22:18,870
the fresh data and certain points when

00:22:15,970 --> 00:22:23,140
you can live with cash data

00:22:18,870 --> 00:22:25,360
this also has explicit expiry but we've

00:22:23,140 --> 00:22:27,700
made it automatic by hooking into after

00:22:25,360 --> 00:22:29,920
commit so you don't need to you don't

00:22:27,700 --> 00:22:32,470
need to worry about it itself this is

00:22:29,920 --> 00:22:34,360
still internal as well but I've been

00:22:32,470 --> 00:22:37,600
working last couple days as a on

00:22:34,360 --> 00:22:39,130
extracting data as a gem so hopefully

00:22:37,600 --> 00:22:43,480
people can start using it themselves

00:22:39,130 --> 00:22:45,730
soon so a little bit of code showing how

00:22:43,480 --> 00:22:48,100
you can use it you just need to include

00:22:45,730 --> 00:22:51,460
identity cache and then you specify the

00:22:48,100 --> 00:22:52,810
index for the model itself and then you

00:22:51,460 --> 00:22:56,260
can say that it's caching the

00:22:52,810 --> 00:22:58,870
associations and the embed true tells it

00:22:56,260 --> 00:23:02,080
we want to embed the associated images

00:22:58,870 --> 00:23:04,210
with the product itself and then it just

00:23:02,080 --> 00:23:05,980
adds a couple methods to the product so

00:23:04,210 --> 00:23:08,110
that you can fetch it by the shop ID and

00:23:05,980 --> 00:23:10,330
ID and then when you get that product

00:23:08,110 --> 00:23:12,280
out of the cache it already includes the

00:23:10,330 --> 00:23:15,280
images so you can call fetch images and

00:23:12,280 --> 00:23:17,230
you won't hit the you won't hit memcache

00:23:15,280 --> 00:23:22,450
and you won't hit the DB either it'll

00:23:17,230 --> 00:23:24,940
already be there for you so this is just

00:23:22,450 --> 00:23:29,680
an example of where we added memcache or

00:23:24,940 --> 00:23:31,300
identity cache to one of our models so

00:23:29,680 --> 00:23:33,100
we can see that the average call time is

00:23:31,300 --> 00:23:35,440
really high and three pluto is really

00:23:33,100 --> 00:23:37,690
high and then at that particular point

00:23:35,440 --> 00:23:41,410
is when we deployed the change to

00:23:37,690 --> 00:23:43,900
identity cache links and there was a

00:23:41,410 --> 00:23:46,090
huge drop because we're now serving most

00:23:43,900 --> 00:23:48,520
of them out of the cache and not having

00:23:46,090 --> 00:23:50,770
to hit the database for them so we've

00:23:48,520 --> 00:23:52,510
had a lot of really big wins by adding

00:23:50,770 --> 00:23:57,610
identity cache and storing more things

00:23:52,510 --> 00:24:00,670
into memcache which is really great so

00:23:57,610 --> 00:24:02,860
get into my process the easiest way to

00:24:00,670 --> 00:24:05,260
speed up a process is just kick things

00:24:02,860 --> 00:24:06,640
out of it so you can speed up what's in

00:24:05,260 --> 00:24:08,740
there or you can just throw it right out

00:24:06,640 --> 00:24:11,260
of the process so the process doesn't

00:24:08,740 --> 00:24:13,870
need to do the work and it can move on

00:24:11,260 --> 00:24:16,450
and do other things so one of the ways

00:24:13,870 --> 00:24:20,200
to do this delay job so this is

00:24:16,450 --> 00:24:25,660
something Toby wrote back in 2010 or

00:24:20,200 --> 00:24:26,940
2009 and so delayed jobs is just a job

00:24:25,660 --> 00:24:29,220
server

00:24:26,940 --> 00:24:31,800
and you store the jobs in the DB you run

00:24:29,220 --> 00:24:34,110
another worker that pulls the DB and

00:24:31,800 --> 00:24:36,810
processes job it's pretty

00:24:34,110 --> 00:24:39,870
straightforward pretty easy to use it's

00:24:36,810 --> 00:24:42,780
on github collective idea has been

00:24:39,870 --> 00:24:44,360
maintaining it lately so that's what we

00:24:42,780 --> 00:24:48,680
started with

00:24:44,360 --> 00:24:53,580
back in 2010 2009 when it was introduced

00:24:48,680 --> 00:24:57,890
we moved to rescue which is Redis backed

00:24:53,580 --> 00:25:00,960
so the big reason to move to rescue was

00:24:57,890 --> 00:25:02,580
we no longer had as much DB convention

00:25:00,960 --> 00:25:05,430
so if you go back to one of my earliest

00:25:02,580 --> 00:25:07,710
earlier slides I said we have about 300

00:25:05,430 --> 00:25:09,630
job workers so if all those job workers

00:25:07,710 --> 00:25:11,400
are hitting the jobs table pulling

00:25:09,630 --> 00:25:13,350
constantly we're gonna have a lot of

00:25:11,400 --> 00:25:15,420
contention on that table and it was

00:25:13,350 --> 00:25:17,360
causing trouble as we wanted to grow the

00:25:15,420 --> 00:25:19,380
number of job servers and workers

00:25:17,360 --> 00:25:23,670
because we have a lot of jobs to work

00:25:19,380 --> 00:25:26,070
off so just removing that bottleneck and

00:25:23,670 --> 00:25:28,170
moving things to Redis helped us a lot

00:25:26,070 --> 00:25:30,960
so we no longer had the DB contention

00:25:28,170 --> 00:25:33,060
there's also a fact with Shopify that we

00:25:30,960 --> 00:25:37,020
just do a lot of rights to the database

00:25:33,060 --> 00:25:38,670
a lot of things change often as things

00:25:37,020 --> 00:25:41,100
are being purchased as products are

00:25:38,670 --> 00:25:42,780
being added as orders are being created

00:25:41,100 --> 00:25:44,610
so we need to write all that to the

00:25:42,780 --> 00:25:46,110
database so whatever we can do to

00:25:44,610 --> 00:25:49,800
offload things from the database is

00:25:46,110 --> 00:25:51,810
gonna be a big win it's also faster

00:25:49,800 --> 00:25:54,600
because rest Redis is really good at

00:25:51,810 --> 00:25:57,570
just pushing data into it so we're able

00:25:54,600 --> 00:26:00,060
to do 300 jobs per second versus 120

00:25:57,570 --> 00:26:01,710
jobs per second and there's also some

00:26:00,060 --> 00:26:04,020
nice extensions that we've been able to

00:26:01,710 --> 00:26:07,170
take use of such as exponential back-off

00:26:04,020 --> 00:26:09,780
some locking plugins and status plugins

00:26:07,170 --> 00:26:16,650
which just make using jobs a lot more

00:26:09,780 --> 00:26:20,190
easier and a lot more flexible so what

00:26:16,650 --> 00:26:21,870
we use rescue for or yeah these are some

00:26:20,190 --> 00:26:24,240
of the types of jobs that we have for

00:26:21,870 --> 00:26:27,420
rescue so we send emails we process

00:26:24,240 --> 00:26:31,140
payments we do geolocation import/export

00:26:27,420 --> 00:26:32,670
for our indexing on search and I went

00:26:31,140 --> 00:26:35,580
through and like grabbed for all the

00:26:32,670 --> 00:26:38,520
jobs and there's 86 other ones so we use

00:26:35,580 --> 00:26:40,500
jobs for just about everything we can so

00:26:38,520 --> 00:26:42,690
we can offload the work out

00:26:40,500 --> 00:26:47,130
the main process that's handling the

00:26:42,690 --> 00:26:49,440
request for the user so just an example

00:26:47,130 --> 00:26:51,990
of some of the improvements we saw so

00:26:49,440 --> 00:26:54,300
this is what we saw when we started back

00:26:51,990 --> 00:26:57,210
rounding payments so one of the things

00:26:54,300 --> 00:26:59,670
with processing payments is majority of

00:26:57,210 --> 00:27:02,460
the time it's handled by HTTP calls and

00:26:59,670 --> 00:27:04,500
the payment processors they're usually

00:27:02,460 --> 00:27:06,450
backed by banks which aren't very fast

00:27:04,500 --> 00:27:10,170
and so there's a lot of fluctuation in

00:27:06,450 --> 00:27:12,390
the response times and it can be very

00:27:10,170 --> 00:27:15,240
slow so moving these into a background

00:27:12,390 --> 00:27:18,840
job cut the response times in half which

00:27:15,240 --> 00:27:20,880
was really great and it also normalized

00:27:18,840 --> 00:27:23,130
the data a little bit or the response

00:27:20,880 --> 00:27:25,260
time a little bit so we had more regular

00:27:23,130 --> 00:27:27,360
traffic patterns because we weren't

00:27:25,260 --> 00:27:31,740
getting as many variations in the

00:27:27,360 --> 00:27:33,360
requests of the payment gateways so just

00:27:31,740 --> 00:27:35,700
a little example of how you can use

00:27:33,360 --> 00:27:38,310
rescue it's pretty straightforward I

00:27:35,700 --> 00:27:41,040
think most people know how rescue works

00:27:38,310 --> 00:27:42,780
you just define a job and then you can

00:27:41,040 --> 00:27:45,120
push that job with the data it needs

00:27:42,780 --> 00:27:47,490
onto the queue you have workers running

00:27:45,120 --> 00:27:49,410
and one of the workers will pick up the

00:27:47,490 --> 00:27:51,360
job initialize the class and pass the

00:27:49,410 --> 00:27:52,710
parameters and work it off really

00:27:51,360 --> 00:27:57,960
straightforward really easy to add to

00:27:52,710 --> 00:28:00,540
your app to help you scale things up one

00:27:57,960 --> 00:28:02,700
added benefit to adding rescue is we had

00:28:00,540 --> 00:28:05,010
Redis available to us so initially we

00:28:02,700 --> 00:28:06,980
just had Redis for rescue but we've

00:28:05,010 --> 00:28:09,120
started using it for a lot more things

00:28:06,980 --> 00:28:12,480
so one of the big things is the

00:28:09,120 --> 00:28:14,730
inventory reservation system so we use

00:28:12,480 --> 00:28:17,880
Redis and the Lewis scripting available

00:28:14,730 --> 00:28:20,280
to make really fast reservations on

00:28:17,880 --> 00:28:21,750
inventory which is really important

00:28:20,280 --> 00:28:24,630
during the checkout process and one of

00:28:21,750 --> 00:28:27,150
the most heavily hit things during a

00:28:24,630 --> 00:28:30,510
flash sale we also store our sessions

00:28:27,150 --> 00:28:33,000
theme uploads we do some API throttling

00:28:30,510 --> 00:28:35,990
and we use it for this thing called

00:28:33,000 --> 00:28:41,100
sequence column so we can just increment

00:28:35,990 --> 00:28:42,780
columns scoped to a particular store so

00:28:41,100 --> 00:28:44,730
this used to be data based back and

00:28:42,780 --> 00:28:48,180
again we ripped it out of the database

00:28:44,730 --> 00:28:50,610
and started using Redis for it because

00:28:48,180 --> 00:28:53,350
Redis is really good for these types of

00:28:50,610 --> 00:28:57,039
increments

00:28:53,350 --> 00:28:59,350
so in Shopify's case all roads lead to

00:28:57,039 --> 00:29:01,899
mysql at some point at some point we're

00:28:59,350 --> 00:29:04,269
gonna be writing data to mysql so

00:29:01,899 --> 00:29:07,120
whatever we can do to speed up mysql and

00:29:04,269 --> 00:29:11,740
speed up how it can handle the requests

00:29:07,120 --> 00:29:14,460
is going to be a big win so the type of

00:29:11,740 --> 00:29:17,559
hardware we run our MySQL servers on

00:29:14,460 --> 00:29:21,730
they have a lot of cores they're filled

00:29:17,559 --> 00:29:23,590
with SSDs we have a lot of RAM and this

00:29:21,730 --> 00:29:27,309
allows us to keep the full working set

00:29:23,590 --> 00:29:31,000
in memory so our DB is about four

00:29:27,309 --> 00:29:32,379
hundred and fifty gigs and with 256 gigs

00:29:31,000 --> 00:29:35,080
of ram we're able to keep the main

00:29:32,379 --> 00:29:38,259
working set into memory and keeping it

00:29:35,080 --> 00:29:42,370
in memory we were able to see about a 10

00:29:38,259 --> 00:29:44,740
to 15 times improvement in speed because

00:29:42,370 --> 00:29:48,340
it doesn't need to read from the disks

00:29:44,740 --> 00:29:51,159
and there's no IO holding it back so if

00:29:48,340 --> 00:29:53,919
you can it's really great to keep all

00:29:51,159 --> 00:29:58,600
your working set in memory if possible

00:29:53,919 --> 00:30:00,070
and ramps cheap so it's easy to do so we

00:29:58,600 --> 00:30:03,850
also started doing a whole bunch of

00:30:00,070 --> 00:30:07,000
query optimization so we use peak PT

00:30:03,850 --> 00:30:09,129
query digest which is a Percona tool so

00:30:07,000 --> 00:30:10,690
we use the pre Kona version of MySQL so

00:30:09,129 --> 00:30:12,519
they add a lot of instrumentation had a

00:30:10,690 --> 00:30:14,919
lot of tooling and this is one of the

00:30:12,519 --> 00:30:17,919
tools you have available to you to look

00:30:14,919 --> 00:30:22,779
at the queries and see how they're

00:30:17,919 --> 00:30:25,330
performing and try and optimize them one

00:30:22,779 --> 00:30:28,419
important thing is to avoid queries that

00:30:25,330 --> 00:30:31,509
generate temp tables so this happens

00:30:28,419 --> 00:30:36,460
really easily with group bys and order

00:30:31,509 --> 00:30:38,710
bys that use different columns and if

00:30:36,460 --> 00:30:42,549
you have most your working set in memory

00:30:38,710 --> 00:30:44,500
and you do this on very large tables you

00:30:42,549 --> 00:30:47,259
can very easily start writing to disk

00:30:44,500 --> 00:30:49,090
which will lose all those benefits of

00:30:47,259 --> 00:30:52,750
keeping the working set in memory so you

00:30:49,090 --> 00:30:55,000
really want to avoid that we also just

00:30:52,750 --> 00:30:57,519
really focus on adding the right indexes

00:30:55,000 --> 00:31:00,370
and forcing in and ignoring indexes in

00:30:57,519 --> 00:31:02,950
some cases so in Shopify's case the

00:31:00,370 --> 00:31:05,440
orders table is kind of the key to most

00:31:02,950 --> 00:31:06,970
of the system so it's used in a lot of

00:31:05,440 --> 00:31:08,919
different places and we have

00:31:06,970 --> 00:31:11,289
a lot of indexes on it and this means

00:31:08,919 --> 00:31:13,419
MySQL sometimes can make the wrong

00:31:11,289 --> 00:31:18,130
decision about when at which index to

00:31:13,419 --> 00:31:20,770
use so we need to coax it and tell it

00:31:18,130 --> 00:31:23,110
which indexes to use in some cases and

00:31:20,770 --> 00:31:28,299
in some plate cases tell it to ignore

00:31:23,110 --> 00:31:30,520
indexes so it'll do the right thing we

00:31:28,299 --> 00:31:33,720
also did a lot of MySQL tuning recently

00:31:30,520 --> 00:31:36,909
so I picked out a few of the sort of

00:31:33,720 --> 00:31:38,919
variables that we tuned recently that

00:31:36,909 --> 00:31:41,640
were kind of interesting so one of them

00:31:38,919 --> 00:31:44,890
was that you know DB stats on metadata

00:31:41,640 --> 00:31:47,770
so in a rails app a lot of times when

00:31:44,890 --> 00:31:49,419
it's requesting data it's gonna do and

00:31:47,770 --> 00:31:52,210
explain on the tables to see what

00:31:49,419 --> 00:31:53,950
columns are there so this explain does a

00:31:52,210 --> 00:31:56,980
bunch of extra stats and a bunch of

00:31:53,950 --> 00:31:59,320
other sampling of data most of the time

00:31:56,980 --> 00:32:01,929
which is just extra work that we don't

00:31:59,320 --> 00:32:03,309
need to do so by disabling this we were

00:32:01,929 --> 00:32:05,890
able to cut out that work that it's

00:32:03,309 --> 00:32:09,730
doing and make my school respond that

00:32:05,890 --> 00:32:11,679
much faster we also increase the table

00:32:09,730 --> 00:32:13,659
open cache so since we have a lot of

00:32:11,679 --> 00:32:15,760
CPUs we're able to have a lot of threads

00:32:13,659 --> 00:32:17,919
running and increasing the number of

00:32:15,760 --> 00:32:22,360
tables open lets those threads work

00:32:17,919 --> 00:32:25,240
harder one key when you're starting to

00:32:22,360 --> 00:32:26,559
increase connections or table open

00:32:25,240 --> 00:32:28,630
caches you really need to make sure

00:32:26,559 --> 00:32:30,190
they're in sync so if you increase the

00:32:28,630 --> 00:32:32,590
number of connections and don't increase

00:32:30,190 --> 00:32:34,419
the number of table open caches or don't

00:32:32,590 --> 00:32:35,760
increase the file descriptors you're

00:32:34,419 --> 00:32:38,020
going to run into those limits instead

00:32:35,760 --> 00:32:39,580
so you really need to watch out what

00:32:38,020 --> 00:32:42,010
you're increasing and making sure

00:32:39,580 --> 00:32:45,130
they're all in sync when they're related

00:32:42,010 --> 00:32:47,590
to each other another thing we did was

00:32:45,130 --> 00:32:50,530
replace the G Lib memory allocator with

00:32:47,590 --> 00:32:52,210
TC malloc so MySQL has a bit of a

00:32:50,530 --> 00:32:54,720
half-dozen different memory allocators

00:32:52,210 --> 00:32:56,549
you can use with various performance

00:32:54,720 --> 00:32:59,200
indicators

00:32:56,549 --> 00:33:01,960
so in Shopify's case since we're very

00:32:59,200 --> 00:33:04,210
right heavy and we have a lot of threads

00:33:01,960 --> 00:33:06,880
interacting with the database we found

00:33:04,210 --> 00:33:08,860
that TC malloc gave us a good amount of

00:33:06,880 --> 00:33:11,020
performance increase so we switched to

00:33:08,860 --> 00:33:13,600
that but you should really look at your

00:33:11,020 --> 00:33:15,690
own system and see which memory

00:33:13,600 --> 00:33:18,789
allocators make sense for you

00:33:15,690 --> 00:33:21,160
another thing we changed was the nodb

00:33:18,789 --> 00:33:23,860
auto increment lock mode

00:33:21,160 --> 00:33:25,660
so this is really important for tables

00:33:23,860 --> 00:33:27,520
that have autoincrement columns which

00:33:25,660 --> 00:33:31,570
most rails apps do you have the auto

00:33:27,520 --> 00:33:41,020
increment primary key so what this does

00:33:31,570 --> 00:33:43,840
is sorry so it optimizes inserts into

00:33:41,020 --> 00:33:45,910
tables with Auto increment and makes it

00:33:43,840 --> 00:33:48,970
more scalable and performant on those

00:33:45,910 --> 00:33:51,100
types of tables the drawback is it may

00:33:48,970 --> 00:33:53,170
degrade performance when using it with

00:33:51,100 --> 00:33:55,180
bulk inserts so this isn't really

00:33:53,170 --> 00:33:58,230
something that we need to deal with so

00:33:55,180 --> 00:34:03,520
we made this switch to optimize for the

00:33:58,230 --> 00:34:06,190
regular inserts into these tables so

00:34:03,520 --> 00:34:08,890
another interesting thing with the DB

00:34:06,190 --> 00:34:11,950
and rails in particular is after commit

00:34:08,890 --> 00:34:14,380
Hux so these are really cool because it

00:34:11,950 --> 00:34:16,419
gives up the transaction and lets it

00:34:14,380 --> 00:34:17,679
work on something else

00:34:16,419 --> 00:34:20,380
because you don't want to hold the

00:34:17,679 --> 00:34:22,390
transaction open for too long because

00:34:20,380 --> 00:34:24,190
you'll have a limited number of undo

00:34:22,390 --> 00:34:27,190
slots in the database which are held

00:34:24,190 --> 00:34:29,050
open per transaction so if you can give

00:34:27,190 --> 00:34:32,169
up the transaction and let something

00:34:29,050 --> 00:34:34,240
else do work and do different do your

00:34:32,169 --> 00:34:35,919
work in another transaction after commit

00:34:34,240 --> 00:34:41,290
you're able to speed up the overall

00:34:35,919 --> 00:34:43,390
request so the way after commit works is

00:34:41,290 --> 00:34:45,820
it fires after the transaction has been

00:34:43,390 --> 00:34:47,560
committed another added benefit is you

00:34:45,820 --> 00:34:49,810
know the data is in the database which

00:34:47,560 --> 00:34:53,970
is really great so we use this for our

00:34:49,810 --> 00:34:56,320
web hooks which we fire to API clients

00:34:53,970 --> 00:34:57,940
so this way we know the data has

00:34:56,320 --> 00:35:00,190
actually been persisted we were running

00:34:57,940 --> 00:35:02,560
into issues with stale data and having

00:35:00,190 --> 00:35:04,480
these happen in after commit meant that

00:35:02,560 --> 00:35:06,850
the data was in the database and it was

00:35:04,480 --> 00:35:07,300
we knew it was there so that's really

00:35:06,850 --> 00:35:10,200
good

00:35:07,300 --> 00:35:12,880
cache expiry so this is a great place to

00:35:10,200 --> 00:35:14,860
expire your caches because you know the

00:35:12,880 --> 00:35:17,740
data has been persisted you know what's

00:35:14,860 --> 00:35:20,440
there and it's also a good place to

00:35:17,740 --> 00:35:22,270
update associated objects so when we

00:35:20,440 --> 00:35:24,340
have orders created we want to update

00:35:22,270 --> 00:35:26,920
our customer objects with the totals

00:35:24,340 --> 00:35:28,930
that they've spent so we do that and

00:35:26,920 --> 00:35:31,570
after commit so we can commit the order

00:35:28,930 --> 00:35:34,450
transaction and then we just create a

00:35:31,570 --> 00:35:35,980
new transaction for the customer

00:35:34,450 --> 00:35:40,930
and we can commit that on its own as

00:35:35,980 --> 00:35:44,020
well so a little code sample of after

00:35:40,930 --> 00:35:46,180
commit one key thing with after commit

00:35:44,020 --> 00:35:47,950
is the object you're given has the

00:35:46,180 --> 00:35:49,480
changes blown away already because it's

00:35:47,950 --> 00:35:52,210
being committed to the database it's

00:35:49,480 --> 00:35:53,109
already been persisted so we often use

00:35:52,210 --> 00:35:56,530
after commit

00:35:53,109 --> 00:35:58,390
hand-in-hand with after save so we'll

00:35:56,530 --> 00:36:01,150
check the changes and see if we need to

00:35:58,390 --> 00:36:03,609
do some work we can set a flag and then

00:36:01,150 --> 00:36:06,280
in after commit we can check that flag

00:36:03,609 --> 00:36:09,040
and do the work that we need to do so

00:36:06,280 --> 00:36:10,060
again it's pretty easy to use but just

00:36:09,040 --> 00:36:11,920
the fact that you're dealing with

00:36:10,060 --> 00:36:15,670
multiple transactions makes it a little

00:36:11,920 --> 00:36:17,790
bit more confusing but well worth the

00:36:15,670 --> 00:36:17,790
effort

00:36:18,240 --> 00:36:24,010
so another point I wanted to touch on is

00:36:20,770 --> 00:36:28,060
services so I found Brian gave a really

00:36:24,010 --> 00:36:29,560
great talk on on services and I can't

00:36:28,060 --> 00:36:33,400
really add much more to what he was

00:36:29,560 --> 00:36:35,740
saying Adam and Brian both they talked

00:36:33,400 --> 00:36:38,410
about not pulling out services until you

00:36:35,740 --> 00:36:40,690
really need to I can't reiterate that

00:36:38,410 --> 00:36:43,720
enough you really don't want to extract

00:36:40,690 --> 00:36:46,510
services when you don't need to because

00:36:43,720 --> 00:36:48,910
it does make your system more complex so

00:36:46,510 --> 00:36:51,099
you want to wait and split them out as

00:36:48,910 --> 00:36:54,430
standalone services as it becomes

00:36:51,099 --> 00:36:57,359
necessary one of the big benefits is

00:36:54,430 --> 00:36:59,319
that they can be independently scaled

00:36:57,359 --> 00:37:02,349
one of the things that was talked about

00:36:59,319 --> 00:37:05,200
a lot is just how do you know what and

00:37:02,349 --> 00:37:06,880
when to split out services so one of the

00:37:05,200 --> 00:37:10,599
things that I was kind of thinking about

00:37:06,880 --> 00:37:12,819
after Brian's talk was when you have to

00:37:10,599 --> 00:37:14,589
start segmenting your metrics to get any

00:37:12,819 --> 00:37:16,869
meaning out of it that might be a good

00:37:14,589 --> 00:37:19,690
indicator that you need to split out a

00:37:16,869 --> 00:37:22,329
service so I'm just going to talk about

00:37:19,690 --> 00:37:26,230
one of the services we split out which

00:37:22,329 --> 00:37:31,240
is called imagery so imagery handles

00:37:26,230 --> 00:37:33,520
dynamics resizing of images and so what

00:37:31,240 --> 00:37:35,500
we were seeing is we used to have

00:37:33,520 --> 00:37:38,410
Shopify the application serving all the

00:37:35,500 --> 00:37:41,140
images and dynamically resizing them at

00:37:38,410 --> 00:37:42,910
some point it became obvious that like

00:37:41,140 --> 00:37:45,069
those requests were kind of

00:37:42,910 --> 00:37:47,109
overshadowing the other application

00:37:45,069 --> 00:37:48,070
requests so it was hard to actually

00:37:47,109 --> 00:37:51,520
determine

00:37:48,070 --> 00:37:53,140
much meaning from the overall data that

00:37:51,520 --> 00:37:54,730
we were seeing so that was a good

00:37:53,140 --> 00:37:57,030
indicator that it was time to move

00:37:54,730 --> 00:37:59,980
imagery out Dharma to its own service

00:37:57,030 --> 00:38:02,440
handling image processing is also like a

00:37:59,980 --> 00:38:06,670
pretty good sort of stand-alone thing

00:38:02,440 --> 00:38:08,380
that we can do so we split it out onto

00:38:06,670 --> 00:38:11,170
its own service and we can scale it

00:38:08,380 --> 00:38:14,460
independently and deal with any sort of

00:38:11,170 --> 00:38:17,340
scaling issues on its own so the way

00:38:14,460 --> 00:38:20,760
imagery kind of talks to Shopify is

00:38:17,340 --> 00:38:23,770
Shopify will push the assets into s3 and

00:38:20,760 --> 00:38:27,870
all the image requests will go through

00:38:23,770 --> 00:38:30,850
the CDN and hit the Amazon elby's

00:38:27,870 --> 00:38:33,340
which take that HTV crackit to the

00:38:30,850 --> 00:38:35,410
traffic to the front-end instances which

00:38:33,340 --> 00:38:38,530
are made up of some HD a proxy and

00:38:35,410 --> 00:38:41,200
varnish caches so these machines are

00:38:38,530 --> 00:38:44,710
really really RAM heavy because they're

00:38:41,200 --> 00:38:47,290
big caches and so if there's no cache

00:38:44,710 --> 00:38:50,500
hits it'll send the request to imagery

00:38:47,290 --> 00:38:53,290
and imagery will do the processing of

00:38:50,500 --> 00:38:56,590
the images and send it back through the

00:38:53,290 --> 00:38:58,380
stack and it'll be cached so one really

00:38:56,590 --> 00:39:01,120
great thing with this architecture is

00:38:58,380 --> 00:39:03,280
for one we're able to scale imagery

00:39:01,120 --> 00:39:04,750
servers on their own they're all in the

00:39:03,280 --> 00:39:06,850
cloud so we're able to increase and

00:39:04,750 --> 00:39:09,730
decrease them on their own which is

00:39:06,850 --> 00:39:13,330
really great because storefront requests

00:39:09,730 --> 00:39:15,340
happen kind of sporadically and we don't

00:39:13,330 --> 00:39:16,710
know exactly when a whole bunch of image

00:39:15,340 --> 00:39:19,300
requests are going to be coming in

00:39:16,710 --> 00:39:21,100
another good thing is by splitting up

00:39:19,300 --> 00:39:23,800
the front-end instances and the backend

00:39:21,100 --> 00:39:25,630
instances we can optimize the hardware

00:39:23,800 --> 00:39:27,880
for the specific jobs they're doing

00:39:25,630 --> 00:39:29,740
so those front-end instances are really

00:39:27,880 --> 00:39:33,670
Ram heavies because they're big caches

00:39:29,740 --> 00:39:34,720
and the back-end instances are CPU heavy

00:39:33,670 --> 00:39:37,150
because they're doing image processing

00:39:34,720 --> 00:39:39,670
and so we can scale each of these

00:39:37,150 --> 00:39:41,980
horizontally as needed which is really

00:39:39,670 --> 00:39:43,690
great and I find this is a really good

00:39:41,980 --> 00:39:45,940
definition of a service because it

00:39:43,690 --> 00:39:50,260
stands on its own there's very limited

00:39:45,940 --> 00:39:52,690
points of interaction and you want to be

00:39:50,260 --> 00:39:53,920
able to scale it independently so if you

00:39:52,690 --> 00:39:55,480
have things like that in your system

00:39:53,920 --> 00:39:58,030
they're probably good things to split

00:39:55,480 --> 00:40:00,520
out but you really want to watch out and

00:39:58,030 --> 00:40:01,990
not split out things unnecessarily

00:40:00,520 --> 00:40:04,030
because you're gonna increase the

00:40:01,990 --> 00:40:05,980
overall complexity of your system and

00:40:04,030 --> 00:40:10,810
it'll be harder to maintain and harder

00:40:05,980 --> 00:40:12,730
to understand so kind of the key things

00:40:10,810 --> 00:40:15,580
that I was hoping you would get from

00:40:12,730 --> 00:40:18,040
this is just to adapt and evolve as

00:40:15,580 --> 00:40:20,650
needed and to use the data and knowledge

00:40:18,040 --> 00:40:22,780
of the system to drive your decisions so

00:40:20,650 --> 00:40:25,630
everything we've done in Shopify we've

00:40:22,780 --> 00:40:28,300
done as the data is dictated as things

00:40:25,630 --> 00:40:31,450
have changed as we've grown we've never

00:40:28,300 --> 00:40:33,310
prematurely optimized anything it's as

00:40:31,450 --> 00:40:34,810
it becomes necessary as it becomes

00:40:33,310 --> 00:40:37,270
apparent that things should stand on a

00:40:34,810 --> 00:40:38,320
loan stand on their own that's what we

00:40:37,270 --> 00:40:42,430
do

00:40:38,320 --> 00:40:45,930
so hopefully that's will help you with

00:40:42,430 --> 00:40:45,930
scaling your own applications

00:41:01,970 --> 00:41:04,030

YouTube URL: https://www.youtube.com/watch?v=j347oSSuNHA


