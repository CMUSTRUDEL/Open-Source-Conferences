Title: Async Iterators: A New Future for Streams - Stephen Belanger
Publication date: 2020-05-11
Playlist: Node + JS Interactive 2019
Description: 
	Async Iterators: A New Future for Streams - Stephen Belanger
Speakers: Stephen Belanger
Async iterators make stream processing much easier than using Node.js core streams. Let's investigate a few common use cases and analyze the performance profile.
Captions: 
	00:00:00,030 --> 00:00:07,290
gonna talk about async iterators and so

00:00:03,149 --> 00:00:11,849
how can change stream streaming systems

00:00:07,290 --> 00:00:17,539
in the future so about me I'm Stephen

00:00:11,849 --> 00:00:20,880
hello I'm on github and Twitter and

00:00:17,539 --> 00:00:23,850
we're gonna talk about some things the

00:00:20,880 --> 00:00:26,099
intro some of you might have seen Mateos

00:00:23,850 --> 00:00:28,199
talked earlier so you've already maybe

00:00:26,099 --> 00:00:29,970
seen a bit of intro to isn't Gatorade

00:00:28,199 --> 00:00:33,540
here so I won't it's been too much time

00:00:29,970 --> 00:00:35,489
on that one also gonna show off some use

00:00:33,540 --> 00:00:38,879
cases some like more complicated use

00:00:35,489 --> 00:00:40,559
cases for hits and get writers talk

00:00:38,879 --> 00:00:46,579
about a bit of the pitfalls of using

00:00:40,559 --> 00:00:50,120
them and do a little performance demo so

00:00:46,579 --> 00:00:55,710
whatever is a sink it writers its

00:00:50,120 --> 00:00:57,750
matches the async function system and

00:00:55,710 --> 00:01:00,570
the generator function system into one

00:00:57,750 --> 00:01:04,409
thing special signature you above the

00:01:00,570 --> 00:01:05,970
async symbol and the asterisks it's you

00:01:04,409 --> 00:01:10,200
can weight stuff and you can yield stuff

00:01:05,970 --> 00:01:15,119
and just returns an iterator that you

00:01:10,200 --> 00:01:20,670
can do for weight loop over and it's

00:01:15,119 --> 00:01:22,799
also internally an interface that just

00:01:20,670 --> 00:01:28,710
promise like promise returning next

00:01:22,799 --> 00:01:31,650
function that resolves to object with a

00:01:28,710 --> 00:01:32,729
value and a flag indicating whether it's

00:01:31,650 --> 00:01:37,979
done or not

00:01:32,729 --> 00:01:40,159
and objects that have this async

00:01:37,979 --> 00:01:43,409
iterator assembled at async iterator

00:01:40,159 --> 00:01:45,210
function that returns an iterator can be

00:01:43,409 --> 00:01:49,619
consumed by far up like for our weight

00:01:45,210 --> 00:01:56,310
of loops so get to the get to the

00:01:49,619 --> 00:02:02,159
examples so streams are actually async

00:01:56,310 --> 00:02:04,729
iterators so it you can just take a any

00:02:02,159 --> 00:02:06,990
creek read stream and just for awaits

00:02:04,729 --> 00:02:09,840
over it like right now this already

00:02:06,990 --> 00:02:13,210
works so just go and do it

00:02:09,840 --> 00:02:15,550
so with that like you can do

00:02:13,210 --> 00:02:17,560
a simple can cats dream type thing too

00:02:15,550 --> 00:02:19,810
like this like there's a bunch of

00:02:17,560 --> 00:02:24,130
modules any in the user land right now

00:02:19,810 --> 00:02:27,070
to do like stream can cat that are like

00:02:24,130 --> 00:02:33,090
five times the length of this to do the

00:02:27,070 --> 00:02:33,090
same thing so it makes things easier and

00:02:33,930 --> 00:02:39,700
the you can also do stream

00:02:36,130 --> 00:02:43,420
transformations I'm going to be soon

00:02:39,700 --> 00:02:45,300
working on a pull request that's in node

00:02:43,420 --> 00:02:47,530
core there's a function called pipeline

00:02:45,300 --> 00:02:50,800
which you might see later in the

00:02:47,530 --> 00:02:54,130
presentation that replaces the like

00:02:50,800 --> 00:02:55,900
stream pipe you just call pipeline it

00:02:54,130 --> 00:03:00,190
looks basically the same as this he's

00:02:55,900 --> 00:03:03,820
giving a bunch of streams the this is my

00:03:00,190 --> 00:03:09,010
my own user land thing using async

00:03:03,820 --> 00:03:12,120
iterator pipe which it takes just any

00:03:09,010 --> 00:03:17,820
stream the same as like pipeline does

00:03:12,120 --> 00:03:22,170
and transform streams but it also takes

00:03:17,820 --> 00:03:25,960
but it can also take the async generator

00:03:22,170 --> 00:03:29,650
functions in place of a stream which

00:03:25,960 --> 00:03:31,630
just looks like that so it's it's just a

00:03:29,650 --> 00:03:35,620
function that receives another iterable

00:03:31,630 --> 00:03:38,050
and produces the new one so this

00:03:35,620 --> 00:03:39,940
interval can be like an existing stream

00:03:38,050 --> 00:03:42,490
or another one of these and you can just

00:03:39,940 --> 00:03:46,030
chain all these together the the nice

00:03:42,490 --> 00:03:49,030
thing about a sync generator functions

00:03:46,030 --> 00:03:51,130
is that you can actually just like call

00:03:49,030 --> 00:03:53,140
like you call these nested and pass the

00:03:51,130 --> 00:03:55,510
values into each other and that's

00:03:53,140 --> 00:03:58,650
basically what this pipe model does when

00:03:55,510 --> 00:03:58,650
it sees that it's not a stream

00:04:02,130 --> 00:04:07,200
and so we're gonna show something a

00:04:04,110 --> 00:04:10,110
little more complex this time because

00:04:07,200 --> 00:04:11,760
the this other one is just upper casing

00:04:10,110 --> 00:04:17,130
a stream that doesn't really do anything

00:04:11,760 --> 00:04:20,310
too notable so let's try parsing a CSV

00:04:17,130 --> 00:04:26,070
file and converting that to a new line

00:04:20,310 --> 00:04:28,080
delimited JSON so we have a CSV file we

00:04:26,070 --> 00:04:35,520
just do a quick read stream on that and

00:04:28,080 --> 00:04:39,600
then have to do lines split so we want

00:04:35,520 --> 00:04:42,240
to start with an empty buffer and just

00:04:39,600 --> 00:04:46,560
as we receive chunks from the read

00:04:42,240 --> 00:04:47,880
stream append those trunks to an

00:04:46,560 --> 00:04:50,940
intermediate buffer that we're working

00:04:47,880 --> 00:04:55,200
with and continuously watch that until

00:04:50,940 --> 00:05:00,480
we see a newline character which is just

00:04:55,200 --> 00:05:02,700
looking for the that the like character

00:05:00,480 --> 00:05:07,680
code for it instead of the string so I

00:05:02,700 --> 00:05:10,230
don't have to stringify this and it it's

00:05:07,680 --> 00:05:14,480
just looping looping over as long as

00:05:10,230 --> 00:05:16,770
there is a new line in here then it will

00:05:14,480 --> 00:05:19,800
slice up to the point of that new line

00:05:16,770 --> 00:05:22,740
and yield that chunk and then move the

00:05:19,800 --> 00:05:26,340
pointer like resetting that buffer and

00:05:22,740 --> 00:05:27,900
so this will just keep like loop until I

00:05:26,340 --> 00:05:29,250
have a new line and then omit that loop

00:05:27,900 --> 00:05:31,320
until I have another new line and hit

00:05:29,250 --> 00:05:35,040
that and just keep doing that and then

00:05:31,320 --> 00:05:36,600
eventually you might have no new line

00:05:35,040 --> 00:05:40,070
terminator at the end of the file so

00:05:36,600 --> 00:05:42,540
just yield if there's anything left and

00:05:40,070 --> 00:05:44,130
now that we've splitted into lines we

00:05:42,540 --> 00:05:50,720
need to do something with those lines

00:05:44,130 --> 00:05:53,070
which is trans translate that as CSV so

00:05:50,720 --> 00:05:53,610
the first line in CSV is just the

00:05:53,070 --> 00:05:56,010
keenen's

00:05:53,610 --> 00:05:59,130
so we can loop over each line and just

00:05:56,010 --> 00:06:02,880
split the first line into an array of

00:05:59,130 --> 00:06:05,940
the keys and then the next for every

00:06:02,880 --> 00:06:10,380
subsequent line the position in the

00:06:05,940 --> 00:06:13,919
array maps to the key position in the

00:06:10,380 --> 00:06:15,710
key list so we just make a data object

00:06:13,919 --> 00:06:20,070
out of that and then you

00:06:15,710 --> 00:06:24,900
and then to JSON is just json stringify

00:06:20,070 --> 00:06:26,039
so it's pretty easy to do and so now we

00:06:24,900 --> 00:06:27,740
can pass that standard outs we've

00:06:26,039 --> 00:06:32,280
managed to do this like fairly

00:06:27,740 --> 00:06:34,020
complicated task of like taking CSV file

00:06:32,280 --> 00:06:36,389
and converting that to new lot new line

00:06:34,020 --> 00:06:38,880
to learn the JSON in like 50 lines of

00:06:36,389 --> 00:06:44,550
code which with streams this would be a

00:06:38,880 --> 00:06:46,500
bunch more complicated and so that pipe

00:06:44,550 --> 00:06:50,910
module is actually just this like that's

00:06:46,500 --> 00:06:52,560
the entire module it has this for

00:06:50,910 --> 00:06:55,139
handling streams which as I've said

00:06:52,560 --> 00:06:57,360
before a stream is just an interval so

00:06:55,139 --> 00:07:01,860
you can just iterate over things and

00:06:57,360 --> 00:07:05,130
that this handles a stream a lot like if

00:07:01,860 --> 00:07:07,110
it's targeting a stream then you can

00:07:05,130 --> 00:07:09,690
just iterate over the iterable source

00:07:07,110 --> 00:07:12,750
whether it's a stream or not and just

00:07:09,690 --> 00:07:16,380
write into the stream and and when

00:07:12,750 --> 00:07:19,560
you're done the loop and then if it's

00:07:16,380 --> 00:07:21,870
function it you can just hand it the

00:07:19,560 --> 00:07:26,669
source directly just create this like

00:07:21,870 --> 00:07:28,740
nested call thing and then all we have

00:07:26,669 --> 00:07:32,430
to do is just detect whether something

00:07:28,740 --> 00:07:36,199
is a stream and pick which size of logic

00:07:32,430 --> 00:07:39,270
we want to do and then you can just do a

00:07:36,199 --> 00:07:41,039
reduce all the targets so you have like

00:07:39,270 --> 00:07:43,680
two in the pipeline the first thing is

00:07:41,039 --> 00:07:45,720
the source and then you're just like

00:07:43,680 --> 00:07:47,820
connecting each thing in the pipeline to

00:07:45,720 --> 00:07:54,199
the next thing so you just have each

00:07:47,820 --> 00:08:01,099
target gets reduced into the source so

00:07:54,199 --> 00:08:04,560
another cool example is at HTTP servers

00:08:01,099 --> 00:08:07,500
so typically you'll have like an HTTP

00:08:04,560 --> 00:08:11,159
app that's you have like HTTP create

00:08:07,500 --> 00:08:15,060
server with like a like handler to

00:08:11,159 --> 00:08:19,199
receive each I get each request that

00:08:15,060 --> 00:08:21,870
comes in but instead you can use HTTP

00:08:19,199 --> 00:08:24,120
iterator and just do create server

00:08:21,870 --> 00:08:25,500
without giving a callback and you can

00:08:24,120 --> 00:08:28,350
actually do that normally in a like

00:08:25,500 --> 00:08:29,580
attach a like on response event instead

00:08:28,350 --> 00:08:32,760
that's actually what it's just doing in

00:08:29,580 --> 00:08:34,349
turn internally but this module will

00:08:32,760 --> 00:08:36,960
actually do that internally and convert

00:08:34,349 --> 00:08:40,080
that into an async iterator so you can

00:08:36,960 --> 00:08:43,110
just for await over requests and there's

00:08:40,080 --> 00:08:45,510
some kind of neat things you can do with

00:08:43,110 --> 00:08:47,820
this sort of pattern like pushing all of

00:08:45,510 --> 00:08:49,350
this into a queue and then like awaiting

00:08:47,820 --> 00:08:51,330
if you have like too many concurrent

00:08:49,350 --> 00:08:53,100
connections or something like you you

00:08:51,330 --> 00:08:55,020
might want to throttle or things like

00:08:53,100 --> 00:08:56,400
that so you can like push stuff into a

00:08:55,020 --> 00:08:59,970
queue and handle it elsewhere

00:08:56,400 --> 00:09:01,980
instead of like handling it all in this

00:08:59,970 --> 00:09:06,630
callback gives you a little bit of extra

00:09:01,980 --> 00:09:10,260
controls and so this is the entirety of

00:09:06,630 --> 00:09:13,650
HTTP iterator module called channel

00:09:10,260 --> 00:09:17,280
surfer which provides go like channels

00:09:13,650 --> 00:09:20,130
so you create a channel and listens to

00:09:17,280 --> 00:09:22,890
as I said the server on requests event

00:09:20,130 --> 00:09:26,430
and just passes the request in response

00:09:22,890 --> 00:09:31,580
in to this channel and then closes the

00:09:26,430 --> 00:09:31,580
channel when the server closes that's it

00:09:31,880 --> 00:09:42,990
so we'll get into more complex example

00:09:38,550 --> 00:09:46,680
now so a lot of like api's will have

00:09:42,990 --> 00:09:48,930
like a pageant ated api and they might

00:09:46,680 --> 00:09:51,540
like have their pages like nested and

00:09:48,930 --> 00:09:53,190
things and it can be kind of awkward if

00:09:51,540 --> 00:09:56,250
you're like trying to deal with

00:09:53,190 --> 00:09:58,290
something like that if you want to like

00:09:56,250 --> 00:10:01,200
interact with like every record in a

00:09:58,290 --> 00:10:02,610
system or something like that then you

00:10:01,200 --> 00:10:04,290
have to like build a whole bunch of

00:10:02,610 --> 00:10:06,870
logic on top of logic on top of other

00:10:04,290 --> 00:10:09,390
logic that just makes it complicated to

00:10:06,870 --> 00:10:13,620
interact with they have something like

00:10:09,390 --> 00:10:15,990
that so but let's just consider like

00:10:13,620 --> 00:10:18,830
with load page just pretend this is like

00:10:15,990 --> 00:10:24,150
fetching from the network or something

00:10:18,830 --> 00:10:28,260
it gets a page by the page number so we

00:10:24,150 --> 00:10:30,450
can convert that that's a page number of

00:10:28,260 --> 00:10:35,030
getting function into a nascent Gatorade

00:10:30,450 --> 00:10:39,839
or pretty easily by just having this and

00:10:35,030 --> 00:10:42,060
as long as load page returns a like

00:10:39,839 --> 00:10:45,480
truth e value then

00:10:42,060 --> 00:10:49,410
it will keep going in the while loop and

00:10:45,480 --> 00:10:57,270
yielding pages so whenever it hits a

00:10:49,410 --> 00:10:59,820
empty page than it starts so but each of

00:10:57,270 --> 00:11:01,980
each of these pages looks like this it's

00:10:59,820 --> 00:11:04,500
it doesn't give us the items it gives us

00:11:01,980 --> 00:11:10,290
the page what we want is actually like a

00:11:04,500 --> 00:11:12,180
list of items so we can just convert one

00:11:10,290 --> 00:11:14,460
iterator into another a diretor but just

00:11:12,180 --> 00:11:16,830
wrapping the pages iterator in one that

00:11:14,460 --> 00:11:19,560
loops over each page that it receives

00:11:16,830 --> 00:11:25,170
from that and omits each item from each

00:11:19,560 --> 00:11:27,300
of those pages and so we can reduce this

00:11:25,170 --> 00:11:30,180
like what would normally be a fairly

00:11:27,300 --> 00:11:32,550
complicated system of interacting with

00:11:30,180 --> 00:11:34,830
this like whole paginate 'add api and

00:11:32,550 --> 00:11:36,680
just turning that into a narrator that

00:11:34,830 --> 00:11:39,840
we can just loop over every item and

00:11:36,680 --> 00:11:42,000
like stop when we want to stop or just

00:11:39,840 --> 00:11:45,090
loop over everything as if it's just

00:11:42,000 --> 00:11:52,770
like a single iterable thing which is

00:11:45,090 --> 00:11:59,130
pretty nice and then another interesting

00:11:52,770 --> 00:12:02,220
application is batching you you you you

00:11:59,130 --> 00:12:04,050
might have like a giant sequence of

00:12:02,220 --> 00:12:06,990
things you want to break up into like

00:12:04,050 --> 00:12:08,010
groups of like process ten items at a

00:12:06,990 --> 00:12:11,880
time or something like that

00:12:08,010 --> 00:12:13,740
so here we have infinite sequence of

00:12:11,880 --> 00:12:16,140
numbers this will just keep looping

00:12:13,740 --> 00:12:23,010
forever every like ten milliseconds

00:12:16,140 --> 00:12:25,650
it'll give you the next number so we for

00:12:23,010 --> 00:12:28,350
batching we want to be able to take like

00:12:25,650 --> 00:12:31,740
a certain number of items out of the

00:12:28,350 --> 00:12:40,550
iterator and process each of those like

00:12:31,740 --> 00:12:43,410
in that batch so that there's some

00:12:40,550 --> 00:12:45,780
interesting stuff in here that's a we're

00:12:43,410 --> 00:12:47,880
using the like iterator next function

00:12:45,780 --> 00:12:50,880
instead of like a 408 loop here and then

00:12:47,880 --> 00:12:52,900
like breaking at so after like n

00:12:50,880 --> 00:12:57,279
iterations and the

00:12:52,900 --> 00:13:00,160
the reason for that is that for like for

00:12:57,279 --> 00:13:03,510
weight of willfully consume an iterator

00:13:00,160 --> 00:13:07,960
even if you try to break out of it

00:13:03,510 --> 00:13:10,720
so if you try to like hand to the same

00:13:07,960 --> 00:13:11,680
iterator and do like take and items out

00:13:10,720 --> 00:13:13,570
of it and then like oh wait for that and

00:13:11,680 --> 00:13:16,180
then take another n items out of that if

00:13:13,570 --> 00:13:21,390
you consume the whole iterator then it's

00:13:16,180 --> 00:13:25,930
gone so yeah that's what's doing the

00:13:21,390 --> 00:13:29,980
while loop and the weight iterator next

00:13:25,930 --> 00:13:32,260
and when you're interacting with the

00:13:29,980 --> 00:13:36,130
underlying iterator interface you have

00:13:32,260 --> 00:13:39,820
to check the like dumb flag and yield

00:13:36,130 --> 00:13:47,560
the value not like yield the OP the

00:13:39,820 --> 00:13:49,089
object so that this might look a little

00:13:47,560 --> 00:13:51,430
bit familiar because this is actually

00:13:49,089 --> 00:13:52,960
effectively the same thing as the stream

00:13:51,430 --> 00:13:56,800
can cap that I showed you earlier it

00:13:52,960 --> 00:13:58,050
just doesn't deal buffer can cat so this

00:13:56,800 --> 00:14:01,089
is interesting in that like you can

00:13:58,050 --> 00:14:03,010
actually like abstract away the whole

00:14:01,089 --> 00:14:04,540
like stream can cat thing entirely like

00:14:03,010 --> 00:14:06,130
don't even have a module that does that

00:14:04,540 --> 00:14:07,690
just have a module that turns it into an

00:14:06,130 --> 00:14:11,100
array and then hand that into the buffer

00:14:07,690 --> 00:14:13,870
can cat function and it works the same

00:14:11,100 --> 00:14:19,480
so you can make this more generic things

00:14:13,870 --> 00:14:21,820
it's just easier so now that we have

00:14:19,480 --> 00:14:25,779
those pieces in place we can make the

00:14:21,820 --> 00:14:28,060
batch function so it just takes an

00:14:25,779 --> 00:14:34,150
iterator and it takes a page size and it

00:14:28,060 --> 00:14:36,310
will take a page of that size out of

00:14:34,150 --> 00:14:39,850
that iterator convert that to an array

00:14:36,310 --> 00:14:44,370
and then as long as there's items to be

00:14:39,850 --> 00:14:48,580
yielded then it'll just yield that page

00:14:44,370 --> 00:14:52,060
so we can do something like if we have

00:14:48,580 --> 00:14:54,790
infinite number of infinite sequence of

00:14:52,060 --> 00:14:59,170
numbers we can like take batches of that

00:14:54,790 --> 00:15:00,529
and some the batches or I think things

00:14:59,170 --> 00:15:03,089
like that

00:15:00,529 --> 00:15:05,250
but that there are some interesting

00:15:03,089 --> 00:15:07,310
pitfalls to consider with async

00:15:05,250 --> 00:15:10,110
iterators though

00:15:07,310 --> 00:15:14,730
so I've already mentioned this one which

00:15:10,110 --> 00:15:17,930
is like for a weight of loop fully

00:15:14,730 --> 00:15:22,850
consumes and they were iterator there's

00:15:17,930 --> 00:15:27,060
some other interesting ones as well a

00:15:22,850 --> 00:15:30,839
really weird one to wrap your brain

00:15:27,060 --> 00:15:33,570
around is that micro tasks are higher

00:15:30,839 --> 00:15:38,430
priority than everything else in the

00:15:33,570 --> 00:15:41,910
like event loop so what what this means

00:15:38,430 --> 00:15:46,290
in practice is that's you can you can do

00:15:41,910 --> 00:15:50,959
some things like in here we have we have

00:15:46,290 --> 00:15:54,899
this function that we want it to just

00:15:50,959 --> 00:15:58,829
infinitely loop over and like await some

00:15:54,899 --> 00:16:01,620
task and we have this timeout here that

00:15:58,829 --> 00:16:03,889
just sets a flag to tell it yeah like

00:16:01,620 --> 00:16:07,470
what when when it reaches this timeout

00:16:03,889 --> 00:16:11,459
just like set the flag to stop running

00:16:07,470 --> 00:16:17,100
the loop so do you think this works no

00:16:11,459 --> 00:16:19,800
it does not because there's a weird

00:16:17,100 --> 00:16:24,110
thing in basing a weight that you can

00:16:19,800 --> 00:16:28,949
actually await an on promise and it's

00:16:24,110 --> 00:16:31,829
just we'll wait a wait like it'll yield

00:16:28,949 --> 00:16:33,990
the value it's like you can just do like

00:16:31,829 --> 00:16:37,319
a weight one and it'll give you one and

00:16:33,990 --> 00:16:38,850
it won't actually defer well it it will

00:16:37,319 --> 00:16:42,750
defer to the micro task queue but it

00:16:38,850 --> 00:16:45,410
will be immediately resolved and that is

00:16:42,750 --> 00:16:53,279
a that particular property is a problem

00:16:45,410 --> 00:16:55,500
in that the micro task queue little bit

00:16:53,279 --> 00:16:58,740
basically the the queues in node like

00:16:55,500 --> 00:17:01,709
will step down to the next that the next

00:16:58,740 --> 00:17:05,910
tier when the current tier has M has

00:17:01,709 --> 00:17:08,669
drained so if the micro task queue every

00:17:05,910 --> 00:17:10,199
every time it has a tick adds another

00:17:08,669 --> 00:17:12,059
task to the micro task queue it'll just

00:17:10,199 --> 00:17:13,110
keep cycling through the micro task

00:17:12,059 --> 00:17:14,160
queue forever and will never actually

00:17:13,110 --> 00:17:17,910
reach anything else

00:17:14,160 --> 00:17:21,589
so the set timeouts will actually never

00:17:17,910 --> 00:17:27,690
get reached because it's a lower

00:17:21,589 --> 00:17:31,530
priority queue so it's a little bit of a

00:17:27,690 --> 00:17:34,950
weight issue but just realize that micro

00:17:31,530 --> 00:17:43,080
tasks your higher priority and you might

00:17:34,950 --> 00:17:47,010
have to debug that and the that this was

00:17:43,080 --> 00:17:52,950
kind of connected to that if any of you

00:17:47,010 --> 00:17:55,380
remember the salgo issue and the DS algo

00:17:52,950 --> 00:17:58,050
module that came out of that in like

00:17:55,380 --> 00:17:59,640
early days of know those like lots of

00:17:58,050 --> 00:18:03,180
people would like write eight async

00:17:59,640 --> 00:18:04,380
stuff that like was sometimes async like

00:18:03,180 --> 00:18:06,870
you might have a function that like

00:18:04,380 --> 00:18:08,970
might do like an FS read file or

00:18:06,870 --> 00:18:10,260
something but it might cache that data

00:18:08,970 --> 00:18:12,570
and then like the next time you call the

00:18:10,260 --> 00:18:13,410
function it has that stored in memory so

00:18:12,570 --> 00:18:15,450
it's just gonna like it call the

00:18:13,410 --> 00:18:16,800
callback immediately but it call like it

00:18:15,450 --> 00:18:19,140
is sometimes call it in the same tick

00:18:16,800 --> 00:18:22,500
instead of the next tick so like you'd

00:18:19,140 --> 00:18:26,010
have like like logically your code would

00:18:22,500 --> 00:18:28,320
like call this async thing and then you

00:18:26,010 --> 00:18:31,500
might have something below it that that

00:18:28,320 --> 00:18:33,330
that would like on the first run that

00:18:31,500 --> 00:18:35,820
would happen first and then the callback

00:18:33,330 --> 00:18:38,010
would happen but then that would switch

00:18:35,820 --> 00:18:39,420
around because it was calling the

00:18:38,010 --> 00:18:42,210
callback in the same tick and it just

00:18:39,420 --> 00:18:44,940
like makes your code super confusing and

00:18:42,210 --> 00:18:48,420
non non deterministic so the desal go

00:18:44,940 --> 00:18:52,020
module was created to ensure that things

00:18:48,420 --> 00:18:56,610
are always async and this is basically

00:18:52,020 --> 00:18:57,450
the equivalent in async iterators we

00:18:56,610 --> 00:19:02,910
have to do this again

00:18:57,450 --> 00:19:06,690
apparently so you just wait another

00:19:02,910 --> 00:19:12,570
promise that's differs to set immediate

00:19:06,690 --> 00:19:16,530
which is at the bottom of the the like

00:19:12,570 --> 00:19:18,570
tiers of queue priorities so that this

00:19:16,530 --> 00:19:22,340
will say like once everything else is

00:19:18,570 --> 00:19:22,340
done then jump back to this again

00:19:23,980 --> 00:19:36,440
so oh I also have a bit of performance

00:19:29,330 --> 00:19:40,100
demo so I had there's been a lot of

00:19:36,440 --> 00:19:42,770
people have kind of avoided isn't Gator

00:19:40,100 --> 00:19:45,110
writers and like related to that

00:19:42,770 --> 00:19:47,900
promises because of the myth that

00:19:45,110 --> 00:19:51,230
promises are slow which at one point had

00:19:47,900 --> 00:19:52,280
some truth to it but there's been a huge

00:19:51,230 --> 00:19:54,320
amount of effort that's gone into

00:19:52,280 --> 00:19:57,250
optimizing promises over the last

00:19:54,320 --> 00:20:01,429
several years that's they're actually

00:19:57,250 --> 00:20:05,960
quite performant at this point so I'm

00:20:01,429 --> 00:20:09,940
gonna show the show a little demo so

00:20:05,960 --> 00:20:09,940
I'll just show you the code for it

00:20:17,130 --> 00:20:25,570
so on the left side we have how to

00:20:22,870 --> 00:20:27,910
implement the just upper casing stream

00:20:25,570 --> 00:20:36,460
and on the right side we have the

00:20:27,910 --> 00:20:39,460
equivalent code in async iterator so the

00:20:36,460 --> 00:20:47,190
this just will take a infinite stream of

00:20:39,460 --> 00:20:47,190
stuff and upper case it let's see oops

00:20:53,010 --> 00:20:56,160
to work

00:21:19,440 --> 00:21:22,890
now what

00:21:24,140 --> 00:21:32,310
why is my node modules missing that's

00:21:27,360 --> 00:21:34,370
not good I was to install that in the

00:21:32,310 --> 00:21:39,780
background and install for a minute

00:21:34,370 --> 00:21:42,090
all right try to I think it's all cached

00:21:39,780 --> 00:21:44,300
locally so it should work without a

00:21:42,090 --> 00:21:44,300
connection

00:21:53,040 --> 00:22:01,290
the results walk through the code yeah

00:21:57,780 --> 00:22:03,840
so that the stream version just you you

00:22:01,290 --> 00:22:07,790
push the like uppercase and and then do

00:22:03,840 --> 00:22:12,690
the set immediate because you need to be

00:22:07,790 --> 00:22:14,310
responsible async participant and this

00:22:12,690 --> 00:22:18,470
is doing effectively the same thing

00:22:14,310 --> 00:22:18,470
because of dues algo reasons

00:22:26,970 --> 00:22:32,000
that's it still doesn't want to work

00:22:36,730 --> 00:22:46,640
okay the demo doesn't seem to wanna run

00:22:39,980 --> 00:22:55,990
right now but I'll show off my coat then

00:22:46,640 --> 00:22:59,950
instead so this is the CSV to JSON was

00:22:55,990 --> 00:23:02,900
optimized slightly from the other one

00:22:59,950 --> 00:23:14,240
does the line splitting and CSV parsing

00:23:02,900 --> 00:23:18,020
all in one and yeah yeah it has some

00:23:14,240 --> 00:23:26,270
helpers to handle the converting the

00:23:18,020 --> 00:23:27,650
keys and stuff well but the the I was

00:23:26,270 --> 00:23:31,790
kind of hoping to show the demo but it

00:23:27,650 --> 00:23:36,380
doesn't run around so that I I did some

00:23:31,790 --> 00:23:39,770
performance testing basically and the

00:23:36,380 --> 00:23:43,309
like went when when running the upper

00:23:39,770 --> 00:23:48,020
case like the opera casing demo it's

00:23:43,309 --> 00:23:49,280
fairly naive code so it's not gonna have

00:23:48,020 --> 00:23:51,770
any significant performance difference

00:23:49,280 --> 00:23:53,320
but the CSV to JSON has like a little

00:23:51,770 --> 00:23:56,360
more meat to it there's a little more

00:23:53,320 --> 00:24:02,870
stuff there that's it's like more

00:23:56,360 --> 00:24:06,309
real-world kind of demo and the the code

00:24:02,870 --> 00:24:11,260
from the async iterator actually is

00:24:06,309 --> 00:24:17,750
about 15% faster than streams are and

00:24:11,260 --> 00:24:20,440
about 40% less memory usage so you can

00:24:17,750 --> 00:24:23,390
actually use async iterators now and

00:24:20,440 --> 00:24:25,640
gets like as good or better performance

00:24:23,390 --> 00:24:27,910
than streams if you'd know how to use

00:24:25,640 --> 00:24:27,910
them properly

00:24:30,620 --> 00:24:39,860
that's basically the end of that so go

00:24:36,679 --> 00:24:40,790
forth nice and get right sorry sorry my

00:24:39,860 --> 00:24:44,460
demo didn't work

00:24:40,790 --> 00:24:44,460

YouTube URL: https://www.youtube.com/watch?v=Q8N1xBXn0uY


