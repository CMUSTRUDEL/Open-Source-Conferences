Title: Application Modernization with Camel JavaScript and OpenShift - Ip Sam & Wuxin Zeng, Red Hat
Publication date: 2021-05-31
Playlist: OpenJS World 2021 - Development
Description: 
	Application Modernization with Camel JavaScript and OpenShift - Ip Sam & Wuxin Zeng, Red Hat

Apache Camel has been used widely for messaging queue integration and notification. The light way and simple Camel coding structure make it a good choice for developers. The Camel technology is used widely during application modernization. Camel also integrates very well with OpenShift forthe CI / CD pipeline and the deployment process. In this presentation, we will go over the architecture of Camel, and how Camel can be used with JavaScript and deployed to OpenShift. We will walk through a few example of application modernization and review the performance gain using Camel Javascript with OpenShift.

Join the speaker for live Q&A on Slack: Wednesday, June 2 from 16:20 - 16:40 PDT / 01:20 - 01:40 CEST, channel - #openjs_world-development
Captions: 
	00:00:00,000 --> 00:00:05,440
hi everyone our talk is on application

00:00:02,760 --> 00:00:08,960
modernization with camo javascript

00:00:05,440 --> 00:00:12,160
and openshift my name is washing zhang

00:00:08,960 --> 00:00:15,280
i am an associate consultant at raha and

00:00:12,160 --> 00:00:16,080
my co-pilot of my presentation is eep

00:00:15,280 --> 00:00:19,119
sam

00:00:16,080 --> 00:00:21,520
who is an architect of

00:00:19,119 --> 00:00:21,520
a hat

00:00:25,199 --> 00:00:31,599
so application modernization there are

00:00:28,480 --> 00:00:34,399
five parts to application modernization

00:00:31,599 --> 00:00:36,960
for service endpoint we migrate web

00:00:34,399 --> 00:00:41,280
services to apis

00:00:36,960 --> 00:00:43,680
for architecture migration modernization

00:00:41,280 --> 00:00:45,840
we want to break down monolith into

00:00:43,680 --> 00:00:48,160
standalone microservices

00:00:45,840 --> 00:00:50,480
because they are easier to maintain and

00:00:48,160 --> 00:00:52,800
to share the code

00:00:50,480 --> 00:00:53,760
to modernize development process we want

00:00:52,800 --> 00:00:56,800
to modernize

00:00:53,760 --> 00:00:58,000
waterfall approach to ci cd so then you

00:00:56,800 --> 00:01:02,640
can release on a daily

00:00:58,000 --> 00:01:04,799
basis like actual transformation

00:01:02,640 --> 00:01:06,320
and for deployment we'll want to

00:01:04,799 --> 00:01:09,600
modernize virtual machine

00:01:06,320 --> 00:01:12,159
on-prem to containerize images

00:01:09,600 --> 00:01:15,760
and lastly for infrastructure we want to

00:01:12,159 --> 00:01:15,760
move data center to cloud

00:01:17,439 --> 00:01:22,799
integration points before on the left

00:01:20,640 --> 00:01:26,240
hand side

00:01:22,799 --> 00:01:29,439
we have a big cluster

00:01:26,240 --> 00:01:31,920
of dependencies it's hard to cut out a

00:01:29,439 --> 00:01:33,920
piece of the application to modernize

00:01:31,920 --> 00:01:35,040
because in order to modernize an

00:01:33,920 --> 00:01:36,479
application

00:01:35,040 --> 00:01:38,400
you also need to identify the

00:01:36,479 --> 00:01:39,520
dependencies to modernize at the same

00:01:38,400 --> 00:01:43,040
time

00:01:39,520 --> 00:01:45,840
and now we have this

00:01:43,040 --> 00:01:47,040
graph on the right hand side that shows

00:01:45,840 --> 00:01:49,600
once you have

00:01:47,040 --> 00:01:50,240
an application to modernize you can

00:01:49,600 --> 00:01:53,280
create

00:01:50,240 --> 00:01:54,960
clusters of dependencies meaning we are

00:01:53,280 --> 00:01:57,119
breaking down the dependencies into

00:01:54,960 --> 00:01:59,680
smaller multiple clusters

00:01:57,119 --> 00:02:01,759
so instead of having one giant cluster

00:01:59,680 --> 00:02:05,040
depending on each other

00:02:01,759 --> 00:02:09,840
we have small clusters of dependencies

00:02:05,040 --> 00:02:09,840
and doing so we can maintain low risks

00:02:10,160 --> 00:02:15,760
so camo what is apache camel

00:02:13,280 --> 00:02:18,080
apache canal is an upstream project that

00:02:15,760 --> 00:02:22,160
we use for integration technology

00:02:18,080 --> 00:02:24,560
arahat apache camo is java based based

00:02:22,160 --> 00:02:26,000
on enterprise integration patterns

00:02:24,560 --> 00:02:28,239
apache camo started

00:02:26,000 --> 00:02:31,280
its life as an implementation of the

00:02:28,239 --> 00:02:33,760
enterprise integration patterns book

00:02:31,280 --> 00:02:36,000
it comes with 300 components out of the

00:02:33,760 --> 00:02:38,720
box you can use

00:02:36,000 --> 00:02:39,280
integration can range from simple timer

00:02:38,720 --> 00:02:42,319
to log

00:02:39,280 --> 00:02:43,280
dummy examples to complex processing

00:02:42,319 --> 00:02:46,879
workflows

00:02:43,280 --> 00:02:49,840
connecting several external systems

00:02:46,879 --> 00:02:51,120
kml has built-in data transformation

00:02:49,840 --> 00:02:54,879
intuitive routing

00:02:51,120 --> 00:02:54,879
and provides native rest support

00:02:58,239 --> 00:03:02,560
integration patterns as developers we

00:03:01,440 --> 00:03:05,040
know that

00:03:02,560 --> 00:03:06,640
the module applications is deconstructed

00:03:05,040 --> 00:03:09,440
into smaller pieces

00:03:06,640 --> 00:03:10,480
the more you need um better

00:03:09,440 --> 00:03:12,400
communication

00:03:10,480 --> 00:03:14,239
patterns for managing all the inherent

00:03:12,400 --> 00:03:16,560
complexity

00:03:14,239 --> 00:03:19,519
pmo has been shaped around enterprise

00:03:16,560 --> 00:03:23,760
integration patterns simpsons inception

00:03:19,519 --> 00:03:23,760
and developers have created a

00:03:27,760 --> 00:03:32,560
dsl that often maps patterns in a

00:03:30,159 --> 00:03:34,640
one-to-one relationship

00:03:32,560 --> 00:03:35,760
these patterns are agnostic of

00:03:34,640 --> 00:03:38,640
programming language

00:03:35,760 --> 00:03:40,080
platform architecture and provide a

00:03:38,640 --> 00:03:42,799
universal language

00:03:40,080 --> 00:03:44,640
notation and fundamental messaging and

00:03:42,799 --> 00:03:47,120
integration

00:03:44,640 --> 00:03:48,319
kml continues to evolve and adding new

00:03:47,120 --> 00:03:50,799
patterns

00:03:48,319 --> 00:03:52,159
from service oriented architecture

00:03:50,799 --> 00:03:56,159
microservices

00:03:52,159 --> 00:03:56,159
cloud native and serverless

00:03:56,319 --> 00:04:00,080
camo has become a journal pattern-based

00:03:58,480 --> 00:04:03,280
integration framework

00:04:00,080 --> 00:04:05,519
suitable for multiple architecture

00:04:03,280 --> 00:04:08,000
i am not exaggerating if i state that

00:04:05,519 --> 00:04:10,080
camo dsl is the language of

00:04:08,000 --> 00:04:11,200
enterprise enterprise integration

00:04:10,080 --> 00:04:12,959
pattern

00:04:11,200 --> 00:04:14,879
it's a language that expresses better

00:04:12,959 --> 00:04:17,519
than most of the patterns

00:04:14,879 --> 00:04:18,799
that were present in the original book

00:04:17,519 --> 00:04:20,639
of integration

00:04:18,799 --> 00:04:24,080
with other patterns that have been added

00:04:20,639 --> 00:04:25,919
by the community during all these years

00:04:24,080 --> 00:04:28,639
and the community keeps adding patterns

00:04:25,919 --> 00:04:32,160
and new components in every release

00:04:28,639 --> 00:04:33,919
in this slide you can see that we have a

00:04:32,160 --> 00:04:35,680
split orders pattern

00:04:33,919 --> 00:04:38,479
that splits the order from a larger

00:04:35,680 --> 00:04:43,840
order and have each item be sent to

00:04:38,479 --> 00:04:43,840
either electronics or other areas

00:04:44,320 --> 00:04:47,440
apache camo is a powerful integration

00:04:46,639 --> 00:04:49,040
library

00:04:47,440 --> 00:04:51,040
that provides lots of integration

00:04:49,040 --> 00:04:53,040
connectors

00:04:51,040 --> 00:04:56,080
as you can see there are hundreds of

00:04:53,040 --> 00:04:59,759
java libraries that used camo connectors

00:04:56,080 --> 00:05:03,360
using this camo and point notations

00:04:59,759 --> 00:05:05,680
these uris are also universal

00:05:03,360 --> 00:05:06,880
here are more examples of camo camo

00:05:05,680 --> 00:05:08,720
components

00:05:06,880 --> 00:05:12,080
you can google camo components and you

00:05:08,720 --> 00:05:12,080
will find a lot of them

00:05:12,400 --> 00:05:17,520
camera routes so like i said before

00:05:15,440 --> 00:05:18,639
kml has multiple domain specific

00:05:17,520 --> 00:05:22,080
language for

00:05:18,639 --> 00:05:26,080
dsl it supports xml java

00:05:22,080 --> 00:05:28,960
groovy kotlin and of course javascript

00:05:26,080 --> 00:05:29,440
there are good reasons to use both java

00:05:28,960 --> 00:05:33,600
and

00:05:29,440 --> 00:05:36,080
xml dsl camo route expresses the

00:05:33,600 --> 00:05:37,919
enterprise integration patterns

00:05:36,080 --> 00:05:39,120
it gets the developers into thinking in

00:05:37,919 --> 00:05:42,479
terms of

00:05:39,120 --> 00:05:45,360
pipes and filters for instance

00:05:42,479 --> 00:05:46,000
the dsl is a technicality that will not

00:05:45,360 --> 00:05:48,639
impact

00:05:46,000 --> 00:05:49,759
the success of project you can even mix

00:05:48,639 --> 00:05:52,639
and match

00:05:49,759 --> 00:05:53,440
so in this slide you see that this is a

00:05:52,639 --> 00:05:56,800
one-to-one

00:05:53,440 --> 00:05:58,000
integration between a file and a jms

00:05:56,800 --> 00:06:00,319
queue

00:05:58,000 --> 00:06:01,600
around time it does not matter for camo

00:06:00,319 --> 00:06:06,479
whether you write it in

00:06:01,600 --> 00:06:09,840
xml or java

00:06:06,479 --> 00:06:10,880
so more examples here from a file called

00:06:09,840 --> 00:06:13,360
inbox

00:06:10,880 --> 00:06:14,800
we split the body based on its line for

00:06:13,360 --> 00:06:17,680
each of the lines

00:06:14,800 --> 00:06:19,199
we turn it into a custom xml and for

00:06:17,680 --> 00:06:22,319
each of the xmls

00:06:19,199 --> 00:06:26,080
we send it to an active mq called

00:06:22,319 --> 00:06:27,680
activemq called line integrations are

00:06:26,080 --> 00:06:30,080
great for connecting systems

00:06:27,680 --> 00:06:33,199
data transformations as well as creating

00:06:30,080 --> 00:06:33,199
new micro services

00:06:33,360 --> 00:06:40,080
rest dsl camel also offers a rest

00:06:37,120 --> 00:06:40,319
styled dsl which can be used with java

00:06:40,080 --> 00:06:43,759
or

00:06:40,319 --> 00:06:45,840
xml the point here is for end users to

00:06:43,759 --> 00:06:49,280
define rest services

00:06:45,840 --> 00:06:53,440
using a rest style with verbs like get

00:06:49,280 --> 00:06:56,800
post delete and etc the rest dsl

00:06:53,440 --> 00:07:00,479
supports the xml dsl using either spring

00:06:56,800 --> 00:07:04,319
or blueprint here to define

00:07:00,479 --> 00:07:06,880
a state path we can set the base path

00:07:04,319 --> 00:07:07,599
in rest say and then provide the uri

00:07:06,880 --> 00:07:11,680
template

00:07:07,599 --> 00:07:14,080
in the verbs it also accepts data format

00:07:11,680 --> 00:07:14,080
setting

00:07:14,880 --> 00:07:21,680
okay let's talk about camo javascript

00:07:19,440 --> 00:07:22,800
in this sample we use javascript

00:07:21,680 --> 00:07:25,759
function to create

00:07:22,800 --> 00:07:27,199
and predicate in a message filter the

00:07:25,759 --> 00:07:30,160
message filter is

00:07:27,199 --> 00:07:31,599
enterprise integration pattern it allows

00:07:30,160 --> 00:07:34,800
you to filter the messages

00:07:31,599 --> 00:07:35,759
obviously for example if the predicate

00:07:34,800 --> 00:07:39,520
is true

00:07:35,759 --> 00:07:42,160
the message will be routed from qa to qb

00:07:39,520 --> 00:07:43,120
this route path routes exchanges from an

00:07:42,160 --> 00:07:46,800
user

00:07:43,120 --> 00:07:50,479
to a special queue we can write this

00:07:46,800 --> 00:07:50,479
in spring dsl as well

00:07:50,960 --> 00:07:55,840
here's another example of camo

00:07:53,120 --> 00:07:55,840
javascript

00:07:56,639 --> 00:08:00,319
as you can see the integration written

00:07:59,280 --> 00:08:03,520
in javascript

00:08:00,319 --> 00:08:06,960
is very similar to a java one

00:08:03,520 --> 00:08:09,199
here from the timer tick process the

00:08:06,960 --> 00:08:13,360
function that prints hello camo k

00:08:09,199 --> 00:08:16,000
to log info to run it you just have to

00:08:13,360 --> 00:08:18,400
execute camera run and the name of the

00:08:16,000 --> 00:08:18,400
file

00:08:19,919 --> 00:08:23,280
for javascript integrations qmlk does

00:08:22,800 --> 00:08:26,479
not yet

00:08:23,280 --> 00:08:27,919
have an enhanced dsl that you can access

00:08:26,479 --> 00:08:31,399
to some global bounded

00:08:27,919 --> 00:08:32,719
objects in this sample we're using

00:08:31,399 --> 00:08:35,440
contacts.get

00:08:32,719 --> 00:08:35,919
component of the previous log component

00:08:35,440 --> 00:08:38,000
and use

00:08:35,919 --> 00:08:41,839
exchange formatter property to do

00:08:38,000 --> 00:08:41,839
something like this

00:08:43,519 --> 00:08:47,040
camo script contacts

00:08:47,080 --> 00:08:51,920
jsr223 lets you use the power and

00:08:49,600 --> 00:08:52,720
flexibility of scripting languages like

00:08:51,920 --> 00:08:56,080
ruby

00:08:52,720 --> 00:08:58,000
groovy and python on the java platform

00:08:56,080 --> 00:09:00,160
kml supports a number of scripting

00:08:58,000 --> 00:09:01,040
languages which are used to create an

00:09:00,160 --> 00:09:04,080
expression

00:09:01,040 --> 00:09:07,519
or predicate via jsr 223

00:09:04,080 --> 00:09:10,399
which is a standard part of java 6.

00:09:07,519 --> 00:09:11,519
javascript context is extremely useful

00:09:10,399 --> 00:09:14,160
when you need to

00:09:11,519 --> 00:09:15,920
invoke some logic there are now in java

00:09:14,160 --> 00:09:19,920
code such as javascript

00:09:15,920 --> 00:09:19,920
gui or any other languages

00:09:20,560 --> 00:09:25,040
properties is the attribute of camel

00:09:22,800 --> 00:09:29,519
script contacts

00:09:25,040 --> 00:09:31,120
as you can see here before camo 2.6 2.9

00:09:29,519 --> 00:09:33,040
if you need to use the properties

00:09:31,120 --> 00:09:34,880
component from a script to look up

00:09:33,040 --> 00:09:38,480
property placeholders

00:09:34,880 --> 00:09:41,600
it is a bit cumbersome to do so however

00:09:38,480 --> 00:09:42,959
since camel 2.9 you can now use the

00:09:41,600 --> 00:09:47,040
properties function

00:09:42,959 --> 00:09:49,600
and this in the example is much simpler

00:09:47,040 --> 00:09:50,880
here in this example function with the

00:09:49,600 --> 00:09:52,480
resolve method

00:09:50,880 --> 00:09:56,399
makes it easier to use chemical

00:09:52,480 --> 00:09:56,399
properties component from scripts

00:09:56,880 --> 00:10:01,040
you can also load scripts from external

00:09:59,120 --> 00:10:03,200
resources

00:10:01,040 --> 00:10:04,720
you can do so by referring to external

00:10:03,200 --> 00:10:07,600
script files

00:10:04,720 --> 00:10:08,880
for example to lay a groovy script from

00:10:07,600 --> 00:10:11,440
the class path

00:10:08,880 --> 00:10:12,240
you need to prefix the value with

00:10:11,440 --> 00:10:18,320
resource

00:10:12,240 --> 00:10:19,839
as shown panel dependencies to use

00:10:18,320 --> 00:10:20,480
scripting languages in your camera

00:10:19,839 --> 00:10:22,240
routes

00:10:20,480 --> 00:10:23,839
you'll need to add a dependency on

00:10:22,240 --> 00:10:27,839
camera script which

00:10:23,839 --> 00:10:30,560
integrates the jsr 223 scripting engine

00:10:27,839 --> 00:10:34,399
here if you use maven you could just add

00:10:30,560 --> 00:10:36,240
the following to your palm.xml file

00:10:34,399 --> 00:10:38,079
substituting the version number for the

00:10:36,240 --> 00:10:39,519
latest and greatest release

00:10:38,079 --> 00:10:42,480
and you can see the download page for

00:10:39,519 --> 00:10:42,480
the latest versions

00:10:43,200 --> 00:10:47,519
so with the introduction of camo and how

00:10:45,600 --> 00:10:51,120
camo supports javascript

00:10:47,519 --> 00:10:54,720
let's talk about camel k klok is a deep

00:10:51,120 --> 00:10:58,160
kubernetes integration for camel camel k

00:10:54,720 --> 00:11:00,399
runs natively in the cloud on openshift

00:10:58,160 --> 00:11:01,440
kmlk is designed for serverless and

00:11:00,399 --> 00:11:04,399
microservice

00:11:01,440 --> 00:11:06,160
tech architectures for those who are not

00:11:04,399 --> 00:11:08,800
familiar with camo k

00:11:06,160 --> 00:11:09,600
camo k is the sub project of apache

00:11:08,800 --> 00:11:11,200
camel

00:11:09,600 --> 00:11:13,040
with the target of building a

00:11:11,200 --> 00:11:14,320
lightweight runtime for running

00:11:13,040 --> 00:11:16,720
integration code

00:11:14,320 --> 00:11:20,720
directly on cloud platforms like

00:11:16,720 --> 00:11:20,720
kubernetes and raha openshift

00:11:21,120 --> 00:11:28,079
so we learned that qmo is a swiss knife

00:11:24,880 --> 00:11:30,560
of integration kmlk is

00:11:28,079 --> 00:11:32,480
for serverless camo for kubernetes and

00:11:30,560 --> 00:11:35,440
native

00:11:32,480 --> 00:11:37,760
and we also have camo corcus which runs

00:11:35,440 --> 00:11:38,959
on top of quarkus and enables developers

00:11:37,760 --> 00:11:42,000
to write small

00:11:38,959 --> 00:11:45,360
fast java applications we also have

00:11:42,000 --> 00:11:48,320
camo carafe camo spring boot

00:11:45,360 --> 00:11:52,240
and camo kafka connectors these are all

00:11:48,320 --> 00:11:52,240
the apache camo 3 projects

00:11:55,360 --> 00:12:01,920
so apache camel k configuration

00:11:58,639 --> 00:12:04,320
in order to run kmlk um you'll need

00:12:01,920 --> 00:12:06,320
access to a kubernetes or openshift

00:12:04,320 --> 00:12:08,880
environment

00:12:06,320 --> 00:12:10,959
however chemok works best when is run

00:12:08,880 --> 00:12:13,680
natively on k native

00:12:10,959 --> 00:12:14,720
k native is a simple pre-built component

00:12:13,680 --> 00:12:18,800
to publish

00:12:14,720 --> 00:12:18,800
and subscribe from the event mesh

00:12:18,959 --> 00:12:22,399
let's take a look at the performance of

00:12:20,720 --> 00:12:24,399
camo k

00:12:22,399 --> 00:12:26,959
chemo k runtime provides significant

00:12:24,399 --> 00:12:29,279
performance optimizations

00:12:26,959 --> 00:12:30,240
this graph is shows the performance of

00:12:29,279 --> 00:12:32,320
camel k

00:12:30,240 --> 00:12:34,560
without utilizing k native and

00:12:32,320 --> 00:12:37,040
serverless technologies

00:12:34,560 --> 00:12:38,240
compared to binary source to image

00:12:37,040 --> 00:12:41,040
deployment

00:12:38,240 --> 00:12:42,560
kmlk has lower deploy and reach the

00:12:41,040 --> 00:12:45,600
redeploy time

00:12:42,560 --> 00:12:47,279
if the binary runs remotely it is even

00:12:45,600 --> 00:12:50,320
slower

00:12:47,279 --> 00:12:53,839
notice that the redeploy with camel k

00:12:50,320 --> 00:12:53,839
is almost instantaneous

00:12:54,639 --> 00:12:59,920
so how does kmlk work well developers

00:12:58,480 --> 00:13:02,320
just want to deal with the business

00:12:59,920 --> 00:13:04,560
logic and not deal with the runtimes and

00:13:02,320 --> 00:13:06,720
all they want to integrate systems and

00:13:04,560 --> 00:13:08,959
become serverless

00:13:06,720 --> 00:13:10,800
what they can do is to write camera

00:13:08,959 --> 00:13:13,200
routes in a single file

00:13:10,800 --> 00:13:15,440
for example here we have a camera route

00:13:13,200 --> 00:13:17,200
written in xml

00:13:15,440 --> 00:13:19,120
and how does it work with openshift and

00:13:17,200 --> 00:13:21,600
kubernetes piece

00:13:19,120 --> 00:13:24,320
well at this point with camo k you only

00:13:21,600 --> 00:13:28,000
have an integration file

00:13:24,320 --> 00:13:30,320
this file is

00:13:28,000 --> 00:13:31,680
says from some sort of timer every

00:13:30,320 --> 00:13:34,160
second

00:13:31,680 --> 00:13:36,639
route id set a header and send it and

00:13:34,160 --> 00:13:36,639
log it

00:13:36,800 --> 00:13:41,360
so once we have a cluster prepared and

00:13:39,440 --> 00:13:42,000
the operator installed in the current

00:13:41,360 --> 00:13:45,279
name

00:13:42,000 --> 00:13:48,560
namespace then we can say camel run

00:13:45,279 --> 00:13:50,480
with a k kmlk comes with a command line

00:13:48,560 --> 00:13:53,519
tool called camera with a k

00:13:50,480 --> 00:13:56,399
so camo run and you can do camera run

00:13:53,519 --> 00:13:57,680
and then the name of the file the cli

00:13:56,399 --> 00:14:00,000
can automate the text

00:13:57,680 --> 00:14:01,600
on the developer's machine such as

00:14:00,000 --> 00:14:03,279
observing code changes

00:14:01,600 --> 00:14:05,440
streaming those to the kubernetes

00:14:03,279 --> 00:14:08,639
cluster printing the logs

00:14:05,440 --> 00:14:10,800
from the running pods and etc

00:14:08,639 --> 00:14:12,959
note that you don't have to specify any

00:14:10,800 --> 00:14:14,360
dependency specification

00:14:12,959 --> 00:14:16,560
in the folder that you wrote your

00:14:14,360 --> 00:14:18,880
integration.guv file

00:14:16,560 --> 00:14:20,079
because kmlk will figure that out for

00:14:18,880 --> 00:14:22,639
you and then

00:14:20,079 --> 00:14:26,000
inject it during the build so all you'll

00:14:22,639 --> 00:14:28,480
need to do is just write the application

00:14:26,000 --> 00:14:29,680
in this case the camel binary will push

00:14:28,480 --> 00:14:31,519
it to the cluster

00:14:29,680 --> 00:14:33,440
and the operator will do all the tedious

00:14:31,519 --> 00:14:36,480
footwork for you

00:14:33,440 --> 00:14:37,920
at first at your first the first time

00:14:36,480 --> 00:14:40,880
you run your application

00:14:37,920 --> 00:14:42,320
it might take up to two minutes to start

00:14:40,880 --> 00:14:44,399
since it needs to pull and build the

00:14:42,320 --> 00:14:46,399
image for the first time

00:14:44,399 --> 00:14:47,519
but the next bill will only take a few

00:14:46,399 --> 00:14:49,600
seconds

00:14:47,519 --> 00:14:53,680
once it started you can find the pod

00:14:49,600 --> 00:14:55,440
running this application on openshift

00:14:53,680 --> 00:14:57,600
here is what the pod looks like on the

00:14:55,440 --> 00:15:00,079
openshift console

00:14:57,600 --> 00:15:02,720
the pile runs in the cluster this can

00:15:00,079 --> 00:15:03,760
also be done with openshift ci tools as

00:15:02,720 --> 00:15:06,240
well

00:15:03,760 --> 00:15:07,839
once logged into the openshift cluster

00:15:06,240 --> 00:15:09,360
the kmlk cli

00:15:07,839 --> 00:15:11,600
will then use that to run the

00:15:09,360 --> 00:15:14,480
integration on the openshift cluster

00:15:11,600 --> 00:15:16,160
in this project and deploy it from here

00:15:14,480 --> 00:15:19,199
so next let's talk about how to

00:15:16,160 --> 00:15:21,600
deploy javascript on openshift

00:15:19,199 --> 00:15:24,480
so the deployment for openshift is based

00:15:21,600 --> 00:15:26,959
on containerized images

00:15:24,480 --> 00:15:29,920
so the first step is to identify and

00:15:26,959 --> 00:15:32,639
find the base image for your javascript

00:15:29,920 --> 00:15:33,360
application you could find it from the

00:15:32,639 --> 00:15:37,920
docker hub

00:15:33,360 --> 00:15:40,160
or quay.io or gcr.io

00:15:37,920 --> 00:15:41,199
right so so the image needs to match

00:15:40,160 --> 00:15:44,480
your specific

00:15:41,199 --> 00:15:45,279
javascript version and once you have the

00:15:44,480 --> 00:15:46,880
image

00:15:45,279 --> 00:15:48,560
you could start working on your docker

00:15:46,880 --> 00:15:50,560
file um

00:15:48,560 --> 00:15:53,920
and and then with the docker file you

00:15:50,560 --> 00:15:55,440
could do the docker command to build the

00:15:53,920 --> 00:15:58,320
application image

00:15:55,440 --> 00:15:59,040
basically this is a s2i process that

00:15:58,320 --> 00:16:02,000
will

00:15:59,040 --> 00:16:03,920
merge your code from your git repository

00:16:02,000 --> 00:16:06,639
with the base image

00:16:03,920 --> 00:16:09,199
that generate a new application image

00:16:06,639 --> 00:16:11,920
for deployment

00:16:09,199 --> 00:16:12,639
so this is the high level architecture

00:16:11,920 --> 00:16:16,720
of

00:16:12,639 --> 00:16:20,399
how the deployment work with the camo

00:16:16,720 --> 00:16:22,320
camo k application on your on the left

00:16:20,399 --> 00:16:25,360
side on the box you have your

00:16:22,320 --> 00:16:27,440
local machine your dev environment you

00:16:25,360 --> 00:16:29,759
have your ide

00:16:27,440 --> 00:16:32,399
and once your coding is completed you do

00:16:29,759 --> 00:16:36,480
the use the camo cli

00:16:32,399 --> 00:16:40,160
command to uh execute

00:16:36,480 --> 00:16:42,160
uh the the program what it does is it

00:16:40,160 --> 00:16:45,440
does do a live update

00:16:42,160 --> 00:16:47,279
to um to basically trigger and send an

00:16:45,440 --> 00:16:48,399
update to the cloud on the right-hand

00:16:47,279 --> 00:16:50,399
side

00:16:48,399 --> 00:16:52,320
it will trigger a notification to the

00:16:50,399 --> 00:16:55,680
camel k operator

00:16:52,320 --> 00:16:56,800
in open shift the the operator will get

00:16:55,680 --> 00:16:59,920
notified

00:16:56,800 --> 00:17:00,560
and then deploy the latest change to the

00:16:59,920 --> 00:17:02,639
port

00:17:00,560 --> 00:17:04,959
based on the integration definition

00:17:02,639 --> 00:17:08,640
otherwise the surface architecture is

00:17:04,959 --> 00:17:10,720
autonomous it's loosely coupled right

00:17:08,640 --> 00:17:14,480
in the modern days people have talked

00:17:10,720 --> 00:17:16,319
more about micro services

00:17:14,480 --> 00:17:18,319
the idea is that we want to make the

00:17:16,319 --> 00:17:19,679
microservices single cup a single

00:17:18,319 --> 00:17:23,120
responsibility

00:17:19,679 --> 00:17:27,280
single purpose stainless right all these

00:17:23,120 --> 00:17:30,000
specific application programs they will

00:17:27,280 --> 00:17:32,400
be moved away from the micro services

00:17:30,000 --> 00:17:34,799
and kept in some sort of persistent

00:17:32,400 --> 00:17:37,120
volume claim or databases

00:17:34,799 --> 00:17:38,559
right each microservice is independently

00:17:37,120 --> 00:17:40,880
scalable

00:17:38,559 --> 00:17:42,480
and they could also be independently

00:17:40,880 --> 00:17:44,080
automated

00:17:42,480 --> 00:17:46,000
and then on the far right-hand side we

00:17:44,080 --> 00:17:49,840
have surface-less architecture

00:17:46,000 --> 00:17:53,840
right surface is based on single action

00:17:49,840 --> 00:17:56,480
right and this is also temporary

00:17:53,840 --> 00:17:57,919
so when we talk about camo k native

00:17:56,480 --> 00:18:02,000
profile

00:17:57,919 --> 00:18:04,799
um so this is an example of a workflow

00:18:02,000 --> 00:18:05,679
on the left hand side you have some sort

00:18:04,799 --> 00:18:09,200
of um

00:18:05,679 --> 00:18:12,799
you know chemo definition um

00:18:09,200 --> 00:18:14,080
you see from um from the form attribute

00:18:12,799 --> 00:18:17,039
you see that this is

00:18:14,080 --> 00:18:18,240
getting the information from the native

00:18:17,039 --> 00:18:20,320
channel

00:18:18,240 --> 00:18:22,160
and then the two attributes saying that

00:18:20,320 --> 00:18:23,280
it gets an information from k native

00:18:22,160 --> 00:18:26,320
channel

00:18:23,280 --> 00:18:27,200
and send the information to the specific

00:18:26,320 --> 00:18:32,000
http

00:18:27,200 --> 00:18:36,080
my host api path this is a very simple

00:18:32,000 --> 00:18:39,120
camo definition you put this into

00:18:36,080 --> 00:18:41,440
a mo file right

00:18:39,120 --> 00:18:42,400
this mo file has an integration as a

00:18:41,440 --> 00:18:46,440
kind

00:18:42,400 --> 00:18:50,320
right the api version is using

00:18:46,440 --> 00:18:52,320
chemo.apache.org version one alpha

00:18:50,320 --> 00:18:53,760
and this is an example of a yamgo file

00:18:52,320 --> 00:18:57,039
for deployment

00:18:53,760 --> 00:18:57,760
in openshift right so once you set up

00:18:57,039 --> 00:19:00,559
the

00:18:57,760 --> 00:19:03,360
ymo file all you need to do is to pass

00:19:00,559 --> 00:19:06,400
this along to the chemok operator

00:19:03,360 --> 00:19:08,559
when the chemical operator got notified

00:19:06,400 --> 00:19:10,080
the operator will look at the file and

00:19:08,559 --> 00:19:13,120
make a decision

00:19:10,080 --> 00:19:13,520
is it a k native profile right if this

00:19:13,120 --> 00:19:16,480
is

00:19:13,520 --> 00:19:17,760
yes this is a k native profile then it

00:19:16,480 --> 00:19:21,120
will generate a new

00:19:17,760 --> 00:19:23,760
emo file set the kind to surface

00:19:21,120 --> 00:19:25,039
and then use that new file for

00:19:23,760 --> 00:19:28,400
deployment

00:19:25,039 --> 00:19:30,240
right if this is not a k native profile

00:19:28,400 --> 00:19:31,600
right in this case this is just a

00:19:30,240 --> 00:19:34,160
deployment object

00:19:31,600 --> 00:19:35,360
right then it will generate the new

00:19:34,160 --> 00:19:38,640
deployment

00:19:35,360 --> 00:19:41,200
kind mo file based on the information

00:19:38,640 --> 00:19:43,200
and use that for deployment yeah so this

00:19:41,200 --> 00:19:44,799
is a high level

00:19:43,200 --> 00:19:46,960
architecture of how the chemical

00:19:44,799 --> 00:19:50,080
operator would work

00:19:46,960 --> 00:19:51,840
surface and k native

00:19:50,080 --> 00:19:53,600
so now it's really important to

00:19:51,840 --> 00:19:55,520
understand how we could apply k natives

00:19:53,600 --> 00:19:58,320
to surface less

00:19:55,520 --> 00:20:00,480
surface is basically is an execution

00:19:58,320 --> 00:20:01,520
model where the code is executed by a

00:20:00,480 --> 00:20:03,919
dynamically

00:20:01,520 --> 00:20:05,360
allocated resources when you have the

00:20:03,919 --> 00:20:07,440
core available

00:20:05,360 --> 00:20:08,960
trigger notification and the resources

00:20:07,440 --> 00:20:11,360
got spin up

00:20:08,960 --> 00:20:12,240
to execute a specific piece of code

00:20:11,360 --> 00:20:14,559
right

00:20:12,240 --> 00:20:16,559
serverless remove the need of

00:20:14,559 --> 00:20:19,200
traditional

00:20:16,559 --> 00:20:21,039
deployment model right you know the

00:20:19,200 --> 00:20:22,960
traditional ways you always need to have

00:20:21,039 --> 00:20:25,440
some sort of server component

00:20:22,960 --> 00:20:26,159
that will deploy to handle the specific

00:20:25,440 --> 00:20:28,799
deployment

00:20:26,159 --> 00:20:30,720
but serverless talk away that concept

00:20:28,799 --> 00:20:34,000
right everything is on demand

00:20:30,720 --> 00:20:36,799
right k native is an open

00:20:34,000 --> 00:20:38,559
source kubernetes based platform to help

00:20:36,799 --> 00:20:41,679
you deploy and manage

00:20:38,559 --> 00:20:44,640
serverless workflow so

00:20:41,679 --> 00:20:45,440
between um when you talk about k native

00:20:44,640 --> 00:20:48,000
we need to

00:20:45,440 --> 00:20:49,360
define the different component the

00:20:48,000 --> 00:20:51,760
building blocks

00:20:49,360 --> 00:20:52,799
of k native right for the surface

00:20:51,760 --> 00:20:55,280
application

00:20:52,799 --> 00:20:56,960
so k native contain two pieces uh

00:20:55,280 --> 00:20:59,840
serving and eventing

00:20:56,960 --> 00:21:01,280
right serving is based on your surface

00:20:59,840 --> 00:21:03,360
object

00:21:01,280 --> 00:21:05,600
you could scale to zero when i don't

00:21:03,360 --> 00:21:07,600
need you to to use the surface

00:21:05,600 --> 00:21:09,120
right or it could scale up to as many

00:21:07,600 --> 00:21:11,840
instances as it need

00:21:09,120 --> 00:21:12,720
when when you have a peak at the traffic

00:21:11,840 --> 00:21:16,000
right

00:21:12,720 --> 00:21:17,840
and and this is the service model is a

00:21:16,000 --> 00:21:20,559
request driven dev uh compute

00:21:17,840 --> 00:21:22,000
uh model when i need it i will ask for

00:21:20,559 --> 00:21:23,200
it and when i don't need it i will scale

00:21:22,000 --> 00:21:25,760
to zero

00:21:23,200 --> 00:21:26,240
eventing is based on the event binding

00:21:25,760 --> 00:21:28,559
right

00:21:26,240 --> 00:21:29,360
when you have a specific event come in

00:21:28,559 --> 00:21:31,200
right

00:21:29,360 --> 00:21:33,039
uh usually a lot of time is coming from

00:21:31,200 --> 00:21:35,120
a messaging queue like

00:21:33,039 --> 00:21:36,559
the kill come in and say hey you know we

00:21:35,120 --> 00:21:39,120
need to

00:21:36,559 --> 00:21:40,640
do this specific operation right when

00:21:39,120 --> 00:21:43,840
that event comes in

00:21:40,640 --> 00:21:44,720
k native will spin up the resources

00:21:43,840 --> 00:21:47,440
required

00:21:44,720 --> 00:21:48,080
to do the computation for the events

00:21:47,440 --> 00:21:49,919
right

00:21:48,080 --> 00:21:52,559
so each building block is a crop

00:21:49,919 --> 00:21:55,600
operation right with a controller

00:21:52,559 --> 00:21:58,960
and that manage the life cycle

00:21:55,600 --> 00:22:02,799
so in k native serving for example

00:21:58,960 --> 00:22:04,799
we have a camo script coming in

00:22:02,799 --> 00:22:06,960
where it's doing a rest call doing a

00:22:04,799 --> 00:22:09,520
post to a specific path

00:22:06,960 --> 00:22:10,559
and then you have two y2 system one to

00:22:09,520 --> 00:22:13,440
system two

00:22:10,559 --> 00:22:13,840
so basically in in when this script

00:22:13,440 --> 00:22:16,480
comes

00:22:13,840 --> 00:22:18,320
in you'll create a kubernetes namespace

00:22:16,480 --> 00:22:21,520
inside the namespace you have the

00:22:18,320 --> 00:22:24,559
um the k native surface that will spin

00:22:21,520 --> 00:22:26,559
up right there's no container if no one

00:22:24,559 --> 00:22:29,120
is using it right so so this is all

00:22:26,559 --> 00:22:32,000
on demand right server let's also help

00:22:29,120 --> 00:22:34,559
you reduce the operational cost

00:22:32,000 --> 00:22:36,240
right much faster deployment to the

00:22:34,559 --> 00:22:38,320
market

00:22:36,240 --> 00:22:40,559
uh it helps you reduce packaging

00:22:38,320 --> 00:22:42,640
deployment complexity

00:22:40,559 --> 00:22:45,520
and then at the end right is a flexible

00:22:42,640 --> 00:22:47,919
scalable on-demand solution

00:22:45,520 --> 00:22:49,200
and you can see this chart on the left

00:22:47,919 --> 00:22:51,840
on the right right

00:22:49,200 --> 00:22:54,159
the left side shows a traditional i.t

00:22:51,840 --> 00:22:56,880
organization

00:22:54,159 --> 00:22:58,880
how much they were overpaying right

00:22:56,880 --> 00:23:00,240
majority of the time on the yellow line

00:22:58,880 --> 00:23:02,240
right

00:23:00,240 --> 00:23:03,760
your demand is on the red line but you

00:23:02,240 --> 00:23:06,640
were you need to

00:23:03,760 --> 00:23:08,640
basically have a 20 30 margin to make

00:23:06,640 --> 00:23:10,480
sure that you cover the demand

00:23:08,640 --> 00:23:12,240
when there's a peak on the day of

00:23:10,480 --> 00:23:13,840
thanksgiving right

00:23:12,240 --> 00:23:15,520
you are not able to meet the demand

00:23:13,840 --> 00:23:16,640
right so this is a this is a traditional

00:23:15,520 --> 00:23:19,039
problem of

00:23:16,640 --> 00:23:20,880
predicting the usages and and

00:23:19,039 --> 00:23:22,640
computational resources that

00:23:20,880 --> 00:23:24,559
a lot of itb departments were having

00:23:22,640 --> 00:23:28,080
difficulty um

00:23:24,559 --> 00:23:29,200
camo k stay between um microservices and

00:23:28,080 --> 00:23:31,840
surferless

00:23:29,200 --> 00:23:33,360
right underneath that you have corkers

00:23:31,840 --> 00:23:35,200
right quarkus it's also an important

00:23:33,360 --> 00:23:36,640
component

00:23:35,200 --> 00:23:38,400
that is also kind of between

00:23:36,640 --> 00:23:41,520
microservices and serverless

00:23:38,400 --> 00:23:43,840
and k-native is completely surface right

00:23:41,520 --> 00:23:45,120
um and then you have streaming am q

00:23:43,840 --> 00:23:48,400
messaging q

00:23:45,120 --> 00:23:50,880
those are working you know could be both

00:23:48,400 --> 00:23:53,279
microservices and serverless and then

00:23:50,880 --> 00:23:56,640
underneath that we have open shift

00:23:53,279 --> 00:23:58,240
so the event driven computation is

00:23:56,640 --> 00:24:01,679
happening between the

00:23:58,240 --> 00:24:02,720
messaging queue k-native camo and

00:24:01,679 --> 00:24:05,840
qualcas

00:24:02,720 --> 00:24:07,440
for microservices we want to ensure that

00:24:05,840 --> 00:24:11,120
the services are

00:24:07,440 --> 00:24:13,760
have granularity and security

00:24:11,120 --> 00:24:15,840
for distributed integration right we

00:24:13,760 --> 00:24:18,960
want to be able to

00:24:15,840 --> 00:24:19,919
set up different containers when right

00:24:18,960 --> 00:24:22,320
when we discover

00:24:19,919 --> 00:24:23,360
services available the container got

00:24:22,320 --> 00:24:25,120
spin up

00:24:23,360 --> 00:24:27,600
right and then at the same time you have

00:24:25,120 --> 00:24:29,760
container that coming on

00:24:27,600 --> 00:24:31,200
on the other side of the picture where

00:24:29,760 --> 00:24:33,600
um you need to

00:24:31,200 --> 00:24:34,960
track the api transaction management

00:24:33,600 --> 00:24:37,679
using saga

00:24:34,960 --> 00:24:38,559
right um and then you can see why this

00:24:37,679 --> 00:24:40,480
container

00:24:38,559 --> 00:24:42,000
uh application architecture could get

00:24:40,480 --> 00:24:43,520
very complicated because you have you

00:24:42,000 --> 00:24:44,159
could have container in different size

00:24:43,520 --> 00:24:46,480
of the

00:24:44,159 --> 00:24:47,600
architecture diagram and then at the end

00:24:46,480 --> 00:24:49,039
right they all

00:24:47,600 --> 00:24:51,039
need to communicate to some sort of

00:24:49,039 --> 00:24:51,919
centralized databases on the right-hand

00:24:51,039 --> 00:24:55,440
side

00:24:51,919 --> 00:24:57,600
um so so when this type of distribution

00:24:55,440 --> 00:25:00,400
application comes in right so what are

00:24:57,600 --> 00:25:02,960
the best practices to handle this right

00:25:00,400 --> 00:25:04,159
yeah so here we talk about a saga

00:25:02,960 --> 00:25:07,440
pattern that we use

00:25:04,159 --> 00:25:09,520
um heavily for application modernization

00:25:07,440 --> 00:25:10,640
right uh the cycle pattern work like

00:25:09,520 --> 00:25:12,720
this right you have

00:25:10,640 --> 00:25:14,000
multiple surface surfaces you have

00:25:12,720 --> 00:25:16,640
surface one surface two

00:25:14,000 --> 00:25:18,159
service three and service four right

00:25:16,640 --> 00:25:21,200
each surface has its own

00:25:18,159 --> 00:25:24,880
uh compensation uh object

00:25:21,200 --> 00:25:26,000
associated with the with the surface

00:25:24,880 --> 00:25:28,320
so what happened is when you have

00:25:26,000 --> 00:25:31,200
surface one making a call

00:25:28,320 --> 00:25:32,240
to surface two right and then as one

00:25:31,200 --> 00:25:34,000
surface two

00:25:32,240 --> 00:25:35,360
make the call back to surface one and

00:25:34,000 --> 00:25:36,880
then you need to make the call to

00:25:35,360 --> 00:25:40,000
surface three

00:25:36,880 --> 00:25:42,799
and then come back right each each step

00:25:40,000 --> 00:25:44,159
the compensation um object will get

00:25:42,799 --> 00:25:47,120
notified right

00:25:44,159 --> 00:25:47,840
in that situation uh it could um

00:25:47,120 --> 00:25:50,240
basically

00:25:47,840 --> 00:25:51,360
hand um based on the request and

00:25:50,240 --> 00:25:52,880
response

00:25:51,360 --> 00:25:55,520
uh you could make a decision right

00:25:52,880 --> 00:25:57,120
should it continue making call

00:25:55,520 --> 00:25:58,960
in the orchestration surface

00:25:57,120 --> 00:26:02,080
orchestration or

00:25:58,960 --> 00:26:03,679
should it go back return the return the

00:26:02,080 --> 00:26:06,320
call back to the caller

00:26:03,679 --> 00:26:08,480
and do something else right so this is a

00:26:06,320 --> 00:26:09,840
very useful saga pattern that

00:26:08,480 --> 00:26:12,400
that can help handle surface

00:26:09,840 --> 00:26:13,279
orchestration you can see we can uh set

00:26:12,400 --> 00:26:15,679
up a

00:26:13,279 --> 00:26:16,480
set of uh integration point between the

00:26:15,679 --> 00:26:18,960
saga

00:26:16,480 --> 00:26:19,520
and the camo right and and the first

00:26:18,960 --> 00:26:22,000
saga

00:26:19,520 --> 00:26:23,440
is basically saying that i i'm making a

00:26:22,000 --> 00:26:26,720
population

00:26:23,440 --> 00:26:29,039
um to towards uh to the to

00:26:26,720 --> 00:26:29,919
to the south to the uh make to make the

00:26:29,039 --> 00:26:32,480
service call

00:26:29,919 --> 00:26:33,279
and this is a mandatory uh uh

00:26:32,480 --> 00:26:36,320
propagation

00:26:33,279 --> 00:26:39,279
right and then in the compensation model

00:26:36,320 --> 00:26:41,600
um you can say direct cancel booking

00:26:39,279 --> 00:26:43,919
right so this is my compensation model

00:26:41,600 --> 00:26:44,720
and then two right specify where this is

00:26:43,919 --> 00:26:48,240
coming to

00:26:44,720 --> 00:26:50,720
this come to a specific sql database and

00:26:48,240 --> 00:26:51,360
it is doing a insert into the flight

00:26:50,720 --> 00:26:54,720
table

00:26:51,360 --> 00:26:56,720
with the specific value right so

00:26:54,720 --> 00:26:57,760
you you can see your saga can be set up

00:26:56,720 --> 00:27:01,279
in a way that it

00:26:57,760 --> 00:27:04,480
you know in a camo camo format where

00:27:01,279 --> 00:27:07,279
you can um uh you know specify the

00:27:04,480 --> 00:27:08,480
the the source the destination the

00:27:07,279 --> 00:27:11,039
condition

00:27:08,480 --> 00:27:11,919
right and and what to do to handle

00:27:11,039 --> 00:27:14,880
specific

00:27:11,919 --> 00:27:16,799
uh accept exception right uh so the

00:27:14,880 --> 00:27:18,640
lower section of the saga is the same

00:27:16,799 --> 00:27:21,520
thing as well we set up the header

00:27:18,640 --> 00:27:23,760
this is http header is a post and then

00:27:21,520 --> 00:27:27,760
you're posting the two requests to

00:27:23,760 --> 00:27:28,559
http endpoint so for the source to image

00:27:27,760 --> 00:27:30,799
deployment

00:27:28,559 --> 00:27:33,760
right you usually get the record from

00:27:30,799 --> 00:27:36,480
the git repository

00:27:33,760 --> 00:27:37,600
and then from there we as soon as the

00:27:36,480 --> 00:27:41,039
coca push we

00:27:37,600 --> 00:27:43,279
push to the port uh we we

00:27:41,039 --> 00:27:44,799
merge the code with the basic image and

00:27:43,279 --> 00:27:47,600
generate an application

00:27:44,799 --> 00:27:49,600
image for deployment so the

00:27:47,600 --> 00:27:50,960
configuration injection is a common

00:27:49,600 --> 00:27:54,960
pattern where

00:27:50,960 --> 00:27:57,360
we can inject the specific

00:27:54,960 --> 00:27:58,159
configuration during the deployment so

00:27:57,360 --> 00:28:00,399
for example

00:27:58,159 --> 00:28:02,320
in openshift we have the config map

00:28:00,399 --> 00:28:04,000
configmap is an object that whole key

00:28:02,320 --> 00:28:07,120
value pairs

00:28:04,000 --> 00:28:08,320
so when we deploy the application for

00:28:07,120 --> 00:28:09,760
application one

00:28:08,320 --> 00:28:12,080
it pulled the information from the

00:28:09,760 --> 00:28:13,919
config map

00:28:12,080 --> 00:28:15,279
and used that information for deployment

00:28:13,919 --> 00:28:18,080
for application one

00:28:15,279 --> 00:28:20,559
and similarly application two followed

00:28:18,080 --> 00:28:23,919
to follow the same design pattern

00:28:20,559 --> 00:28:26,159
um openshift operator uh contains

00:28:23,919 --> 00:28:27,760
uh an example of the red hat open shift

00:28:26,159 --> 00:28:31,279
surface

00:28:27,760 --> 00:28:32,480
and once surface is click on you can go

00:28:31,279 --> 00:28:34,480
here and

00:28:32,480 --> 00:28:36,320
specify if you want to do a basic

00:28:34,480 --> 00:28:38,559
install

00:28:36,320 --> 00:28:39,600
if you want you can specify specific

00:28:38,559 --> 00:28:41,760
version

00:28:39,600 --> 00:28:43,039
like for example i want to do a version

00:28:41,760 --> 00:28:45,200
4.6

00:28:43,039 --> 00:28:46,240
for the operator for the openshift

00:28:45,200 --> 00:28:49,120
surface

00:28:46,240 --> 00:28:51,120
once it's installed you can see that the

00:28:49,120 --> 00:28:52,159
the install operator is in your screen

00:28:51,120 --> 00:28:54,720
here

00:28:52,159 --> 00:28:56,320
in conclusion camo k is a lightweight

00:28:54,720 --> 00:28:59,679
integration framework

00:28:56,320 --> 00:29:02,799
that one natively on openshift chemok

00:28:59,679 --> 00:29:05,440
is also designed for serverless and

00:29:02,799 --> 00:29:08,880
microservices architecture

00:29:05,440 --> 00:29:12,480
the k native ad component for deploying

00:29:08,880 --> 00:29:15,679
running managing surface cloud native

00:29:12,480 --> 00:29:18,159
application in openshift the serverless

00:29:15,679 --> 00:29:20,320
cloud computing model

00:29:18,159 --> 00:29:21,679
uh lead to an increase in developer

00:29:20,320 --> 00:29:24,799
productivity

00:29:21,679 --> 00:29:29,120
reliability in the cloud deployment and

00:29:24,799 --> 00:29:32,720
reduce operational cost camel k

00:29:29,120 --> 00:29:33,919
and k native provide a fast and scalable

00:29:32,720 --> 00:29:36,960
solution for

00:29:33,919 --> 00:29:39,120
application modernization architecture

00:29:36,960 --> 00:29:41,440
and camo integrate integra with

00:29:39,120 --> 00:29:44,320
different technology different languages

00:29:41,440 --> 00:29:46,159
with reliable results sean we are coming

00:29:44,320 --> 00:29:48,240
from red hat consultant

00:29:46,159 --> 00:29:50,559
team if you guys have any specific

00:29:48,240 --> 00:29:54,640
question please reach out to

00:29:50,559 --> 00:29:54,640

YouTube URL: https://www.youtube.com/watch?v=iM1LiceeyHk


