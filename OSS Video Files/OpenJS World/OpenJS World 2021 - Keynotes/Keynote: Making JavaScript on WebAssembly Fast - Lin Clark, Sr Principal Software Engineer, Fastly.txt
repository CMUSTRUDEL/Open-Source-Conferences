Title: Keynote: Making JavaScript on WebAssembly Fast - Lin Clark, Sr Principal Software Engineer, Fastly
Publication date: 2021-06-01
Playlist: OpenJS World 2021 - Keynotes
Description: 
	Keynote: Making JavaScript on WebAssembly Fast - Lin Clark, Senior Principal Software Engineer, Fastly

JavaScript in the browser runs many times faster than it did two decades ago. And that happened because the browser vendors spent that time working on intensive performance optimizations in their JavaScript engines.

Because of this optimization work, JavaScript is now running in many places besides the browser. But there are still some environments where the JS engines can’t apply those optimizations in the right way to make things fast.

We’re working to solve this, beginning a whole new wave of JavaScript optimization work. We’re improving JavaScript performance for entirely different environments, where different rules apply. And this is possible because of WebAssembly. In this talk, I'll explain how this all works and what's coming next.
Captions: 
	00:00:02,320 --> 00:00:07,359
hi i'm lynn clark

00:00:04,080 --> 00:00:08,080
and i make code cartoons i also work at

00:00:07,359 --> 00:00:09,599
fastly

00:00:08,080 --> 00:00:11,360
which is doing a ton of cool things with

00:00:09,599 --> 00:00:13,040
webassembly to make better edge compute

00:00:11,360 --> 00:00:14,559
possible

00:00:13,040 --> 00:00:17,199
and i'm a co-founder of the bytecode

00:00:14,559 --> 00:00:19,279
alliance we're working on tools for a

00:00:17,199 --> 00:00:22,000
webassembly ecosystem that extends

00:00:19,279 --> 00:00:23,680
beyond the browser and is one of those

00:00:22,000 --> 00:00:26,080
tools that i wanted to talk to you about

00:00:23,680 --> 00:00:26,080
today

00:00:26,640 --> 00:00:30,000
javascript was first created to run in

00:00:28,800 --> 00:00:31,679
the browser so that people

00:00:30,000 --> 00:00:34,160
could add a little bit of interactivity

00:00:31,679 --> 00:00:35,840
to their web pages

00:00:34,160 --> 00:00:37,520
no one would have guessed that 20 years

00:00:35,840 --> 00:00:38,960
later people will be using javascript to

00:00:37,520 --> 00:00:41,200
build all sorts of

00:00:38,960 --> 00:00:42,800
big complex applications to run in your

00:00:41,200 --> 00:00:44,640
browser

00:00:42,800 --> 00:00:46,320
what made this possible is that

00:00:44,640 --> 00:00:48,640
javascript in the browser

00:00:46,320 --> 00:00:50,399
runs a lot faster than it did two

00:00:48,640 --> 00:00:52,480
decades ago

00:00:50,399 --> 00:00:54,719
and that happened because the browser

00:00:52,480 --> 00:00:56,320
vendors spent that time working on

00:00:54,719 --> 00:00:58,640
some pretty intense intensive

00:00:56,320 --> 00:01:00,879
performance optimizations

00:00:58,640 --> 00:01:03,600
now this started with the introduction

00:01:00,879 --> 00:01:05,360
of just-in-time compilers around 2008

00:01:03,600 --> 00:01:07,520
and the browsers have built on top of

00:01:05,360 --> 00:01:09,520
that continuing these optimization

00:01:07,520 --> 00:01:11,439
efforts

00:01:09,520 --> 00:01:13,200
now we're starting work on optimizing

00:01:11,439 --> 00:01:15,040
javascript performance

00:01:13,200 --> 00:01:17,920
for an entirely different set of

00:01:15,040 --> 00:01:19,200
environments where different rules apply

00:01:17,920 --> 00:01:22,320
and this is possible because of

00:01:19,200 --> 00:01:23,759
webassembly so today i want to explain

00:01:22,320 --> 00:01:25,680
what it is about webassembly that

00:01:23,759 --> 00:01:28,560
enables this but first

00:01:25,680 --> 00:01:30,320
i want to give you a heads up this talk

00:01:28,560 --> 00:01:32,799
is structured a bit differently

00:01:30,320 --> 00:01:35,680
than speaking experts would tell me i

00:01:32,799 --> 00:01:37,439
should be structuring this presentation

00:01:35,680 --> 00:01:39,520
i'm going to start with telling you how

00:01:37,439 --> 00:01:41,360
we're making this work at all

00:01:39,520 --> 00:01:42,560
and once you've heard that you might not

00:01:41,360 --> 00:01:44,079
be on board

00:01:42,560 --> 00:01:46,079
you might think that this is a pretty

00:01:44,079 --> 00:01:48,799
ridiculous idea

00:01:46,079 --> 00:01:50,320
so that's why i'm going to explain why

00:01:48,799 --> 00:01:52,159
i'm going to explain why you would

00:01:50,320 --> 00:01:53,680
actually want to do this

00:01:52,159 --> 00:01:55,439
and then once you're bought in and i

00:01:53,680 --> 00:01:57,600
know you'll be bought in

00:01:55,439 --> 00:01:59,360
then i'm going to come back and explain

00:01:57,600 --> 00:02:00,880
exactly how it is that we're making this

00:01:59,360 --> 00:02:02,960
fast

00:02:00,880 --> 00:02:04,079
so let's get started with how we're

00:02:02,960 --> 00:02:08,319
running javascript

00:02:04,079 --> 00:02:09,759
inside a webassembly engine whenever

00:02:08,319 --> 00:02:12,560
you're running javascript

00:02:09,759 --> 00:02:13,680
the js code needs to be executed as

00:02:12,560 --> 00:02:16,800
machine code

00:02:13,680 --> 00:02:19,440
in one way or another now this is done

00:02:16,800 --> 00:02:20,720
by the js engine using a variety of

00:02:19,440 --> 00:02:23,920
different techniques

00:02:20,720 --> 00:02:25,680
from interpreters and gig compilers

00:02:23,920 --> 00:02:27,120
and i explained this all in more detail

00:02:25,680 --> 00:02:30,000
in my first set of

00:02:27,120 --> 00:02:31,440
articles about webassembly back in 2017

00:02:30,000 --> 00:02:32,800
so if you want to understand more about

00:02:31,440 --> 00:02:37,040
how this works you can go back

00:02:32,800 --> 00:02:39,840
and read those articles

00:02:37,040 --> 00:02:42,239
running this javascript code is really

00:02:39,840 --> 00:02:43,440
quite easy in environments like the web

00:02:42,239 --> 00:02:46,080
where you know that you're going to have

00:02:43,440 --> 00:02:48,319
a javascript engine available

00:02:46,080 --> 00:02:49,360
but what if your target platform doesn't

00:02:48,319 --> 00:02:52,000
have a javascript

00:02:49,360 --> 00:02:54,640
engine then you need to deploy your

00:02:52,000 --> 00:02:56,480
javascript engine with your code

00:02:54,640 --> 00:02:58,080
and so that's what we need to do to

00:02:56,480 --> 00:02:59,599
bring javascript to these different

00:02:58,080 --> 00:03:03,120
environments

00:02:59,599 --> 00:03:05,200
so how do we do this well we deploy the

00:03:03,120 --> 00:03:06,239
javascript engine as a webassembly

00:03:05,200 --> 00:03:07,840
module

00:03:06,239 --> 00:03:10,480
and that makes it portable across a

00:03:07,840 --> 00:03:12,720
bunch of different machine architectures

00:03:10,480 --> 00:03:14,239
and with wazzy we can make it portable

00:03:12,720 --> 00:03:16,720
across a bunch of different operating

00:03:14,239 --> 00:03:18,239
systems as well

00:03:16,720 --> 00:03:20,080
this means that the whole javascript

00:03:18,239 --> 00:03:21,519
environment is bundled up into

00:03:20,080 --> 00:03:24,000
the webassembly module and once you

00:03:21,519 --> 00:03:27,200
deploy it all you need to do

00:03:24,000 --> 00:03:30,560
is feed in the javascript code and that

00:03:27,200 --> 00:03:32,640
javascript engine will run that code

00:03:30,560 --> 00:03:34,319
now instead of working directly on the

00:03:32,640 --> 00:03:36,480
machine's memory like it would for

00:03:34,319 --> 00:03:38,480
a browser the javascript engine puts

00:03:36,480 --> 00:03:40,080
everything from bytecode to the garbage

00:03:38,480 --> 00:03:41,519
collected objects that the bytecode

00:03:40,080 --> 00:03:44,840
works on

00:03:41,519 --> 00:03:46,720
into the webassembly memory's linear

00:03:44,840 --> 00:03:48,640
memory

00:03:46,720 --> 00:03:50,720
for our js engine we went with spider

00:03:48,640 --> 00:03:52,720
monkey and that's the js engine that

00:03:50,720 --> 00:03:54,560
firefox uses

00:03:52,720 --> 00:03:56,720
it's one of the industrial strength

00:03:54,560 --> 00:03:58,560
javascript virtual machines

00:03:56,720 --> 00:03:59,760
because it's been battle tested in the

00:03:58,560 --> 00:04:01,519
browser

00:03:59,760 --> 00:04:02,879
and this kind of battle testing and

00:04:01,519 --> 00:04:03,760
investment in security is really

00:04:02,879 --> 00:04:05,519
important

00:04:03,760 --> 00:04:07,200
when you're running untrusted code or

00:04:05,519 --> 00:04:11,280
running code that processes

00:04:07,200 --> 00:04:13,599
untrusted input spydermonkey also uses a

00:04:11,280 --> 00:04:14,799
technique called precise stack scanning

00:04:13,599 --> 00:04:15,599
which is important for some of the

00:04:14,799 --> 00:04:17,359
optimizations

00:04:15,599 --> 00:04:19,600
i'll be describing a bit later in the

00:04:17,359 --> 00:04:19,600
talk

00:04:19,919 --> 00:04:23,759
so far there's nothing revolutionary

00:04:21,759 --> 00:04:25,199
about the approach that i've described

00:04:23,759 --> 00:04:27,680
people have already been running

00:04:25,199 --> 00:04:30,960
javascript inside of webassembly

00:04:27,680 --> 00:04:34,000
like this for a number of years

00:04:30,960 --> 00:04:35,680
the problem is that it's slow

00:04:34,000 --> 00:04:37,280
webassembly doesn't allow you to

00:04:35,680 --> 00:04:39,360
dynamically generate

00:04:37,280 --> 00:04:41,360
new machine code and run it from within

00:04:39,360 --> 00:04:43,120
pure webassembly code

00:04:41,360 --> 00:04:45,919
so this means that you can't use the jet

00:04:43,120 --> 00:04:47,840
you can only use the interpreter

00:04:45,919 --> 00:04:50,240
now given this constraint you might be

00:04:47,840 --> 00:04:52,960
asking why

00:04:50,240 --> 00:04:54,639
since jits are how the browsers made js

00:04:52,960 --> 00:04:56,960
code run fast

00:04:54,639 --> 00:04:58,880
and since you can't jit compile inside

00:04:56,960 --> 00:05:03,280
of a webassembly module

00:04:58,880 --> 00:05:06,160
this just doesn't make sense but what if

00:05:03,280 --> 00:05:07,120
even given these constraints we could

00:05:06,160 --> 00:05:10,479
actually make

00:05:07,120 --> 00:05:12,720
this javascript run fast let's look at a

00:05:10,479 --> 00:05:16,479
couple of use cases where a fast version

00:05:12,720 --> 00:05:16,479
of this approach could be really useful

00:05:16,639 --> 00:05:20,320
there are some places where you can't

00:05:18,240 --> 00:05:23,680
use a just-in-time compiler

00:05:20,320 --> 00:05:26,800
due to security concerns so for example

00:05:23,680 --> 00:05:28,720
ios devices or some smart tvs and gaming

00:05:26,800 --> 00:05:31,520
consoles

00:05:28,720 --> 00:05:33,280
on these platforms you have to use an

00:05:31,520 --> 00:05:34,960
interpreter

00:05:33,280 --> 00:05:37,039
but the kinds of applications that you

00:05:34,960 --> 00:05:38,960
run on these platforms are long running

00:05:37,039 --> 00:05:40,479
and they require lots of code

00:05:38,960 --> 00:05:42,160
and those are exactly the kinds of

00:05:40,479 --> 00:05:43,440
conditions where historically you

00:05:42,160 --> 00:05:45,280
wouldn't want to use an interpreter

00:05:43,440 --> 00:05:47,520
because of how much it slows down your

00:05:45,280 --> 00:05:49,840
execution

00:05:47,520 --> 00:05:50,960
if we can make our approach fast then

00:05:49,840 --> 00:05:52,880
these developers

00:05:50,960 --> 00:05:54,560
could use javascript on gitless

00:05:52,880 --> 00:05:57,360
platforms without taking a massive

00:05:54,560 --> 00:05:59,759
performance hit

00:05:57,360 --> 00:06:01,280
now there are other places where using a

00:05:59,759 --> 00:06:05,759
jit isn't a problem

00:06:01,280 --> 00:06:07,680
but where startup times are prohibitive

00:06:05,759 --> 00:06:09,759
so an example of this is in serverless

00:06:07,680 --> 00:06:11,199
functions and this plays into that cold

00:06:09,759 --> 00:06:14,160
start latency problem that you might

00:06:11,199 --> 00:06:16,240
have heard people talking about

00:06:14,160 --> 00:06:18,160
even if you're using the most paired

00:06:16,240 --> 00:06:20,000
down javascript environment

00:06:18,160 --> 00:06:21,840
which is an isolate that just starts up

00:06:20,000 --> 00:06:23,520
a bare javascript engine

00:06:21,840 --> 00:06:26,479
you're looking at about five

00:06:23,520 --> 00:06:28,639
milliseconds of startup latency

00:06:26,479 --> 00:06:29,680
now there are some ways to hide this

00:06:28,639 --> 00:06:32,000
startup latency

00:06:29,680 --> 00:06:33,840
for an incoming request but it's getting

00:06:32,000 --> 00:06:35,840
harder to hide as connection times are

00:06:33,840 --> 00:06:38,000
being optimized in the network layer

00:06:35,840 --> 00:06:39,840
with proposals such as quick

00:06:38,000 --> 00:06:41,759
and it's also harder to hide when you're

00:06:39,840 --> 00:06:44,000
chaining different serverless functions

00:06:41,759 --> 00:06:46,479
together

00:06:44,000 --> 00:06:47,840
but more than this platforms that use

00:06:46,479 --> 00:06:48,720
these kinds of techniques to hide

00:06:47,840 --> 00:06:50,960
latency

00:06:48,720 --> 00:06:52,479
also often reuse instances between

00:06:50,960 --> 00:06:54,639
requests

00:06:52,479 --> 00:06:56,400
and in some cases this means that global

00:06:54,639 --> 00:06:58,560
state can be observed between

00:06:56,400 --> 00:07:00,560
different requests which can be a

00:06:58,560 --> 00:07:02,400
security issue

00:07:00,560 --> 00:07:03,759
and because of this cold start problem

00:07:02,400 --> 00:07:06,240
developers also

00:07:03,759 --> 00:07:08,319
often don't follow best practices they

00:07:06,240 --> 00:07:10,080
stuff a lot of functions into one

00:07:08,319 --> 00:07:11,840
serverless deployment

00:07:10,080 --> 00:07:14,880
so this results in another security

00:07:11,840 --> 00:07:16,960
issue which is a larger blast radius

00:07:14,880 --> 00:07:19,039
if one part of the serverless deployment

00:07:16,960 --> 00:07:22,160
is exploited the attacker has access to

00:07:19,039 --> 00:07:24,160
everything in that deployment

00:07:22,160 --> 00:07:26,639
but if we can get javascript startup

00:07:24,160 --> 00:07:28,560
times low enough in these contexts

00:07:26,639 --> 00:07:30,479
then we wouldn't need to hide startup

00:07:28,560 --> 00:07:33,599
times with any tricks we could just

00:07:30,479 --> 00:07:35,520
start up an instance in microseconds

00:07:33,599 --> 00:07:36,720
with this we can provide a new instance

00:07:35,520 --> 00:07:38,400
for each request

00:07:36,720 --> 00:07:40,319
which means that there's no state lying

00:07:38,400 --> 00:07:41,919
around between requests

00:07:40,319 --> 00:07:44,560
and because the instances are so

00:07:41,919 --> 00:07:45,680
lightweight developers could feel free

00:07:44,560 --> 00:07:48,560
to break up their code

00:07:45,680 --> 00:07:50,240
into fine-grained pieces and this would

00:07:48,560 --> 00:07:54,080
bring their blast radius down to a

00:07:50,240 --> 00:07:54,080
minimum for any single piece of code

00:07:54,240 --> 00:07:58,879
so for these use cases there's a big

00:07:56,479 --> 00:08:00,479
benefit to making javascript on wasm

00:07:58,879 --> 00:08:03,919
fast

00:08:00,479 --> 00:08:05,440
but how can we do that in order to

00:08:03,919 --> 00:08:06,879
answer that question

00:08:05,440 --> 00:08:10,400
we need to understand where the

00:08:06,879 --> 00:08:11,840
javascript engine spends its time

00:08:10,400 --> 00:08:13,440
we can break down the work that a

00:08:11,840 --> 00:08:17,280
javascript engine has to do

00:08:13,440 --> 00:08:20,479
into two different parts

00:08:17,280 --> 00:08:23,919
initialization and runtime

00:08:20,479 --> 00:08:25,840
i think of the js engine as a contractor

00:08:23,919 --> 00:08:27,360
this contractor is retained to complete

00:08:25,840 --> 00:08:29,120
a job and that job is

00:08:27,360 --> 00:08:31,919
running the javascript code and getting

00:08:29,120 --> 00:08:33,760
to a final result

00:08:31,919 --> 00:08:35,200
before this contractor can actually

00:08:33,760 --> 00:08:36,719
start running the project though it

00:08:35,200 --> 00:08:38,240
needs to do a little bit of preliminary

00:08:36,719 --> 00:08:40,159
work

00:08:38,240 --> 00:08:42,080
this initialization phase includes

00:08:40,159 --> 00:08:45,440
everything that only needs to happen

00:08:42,080 --> 00:08:47,200
once at the very start of the project

00:08:45,440 --> 00:08:49,440
so one part of this is application

00:08:47,200 --> 00:08:51,120
initialization for any project

00:08:49,440 --> 00:08:54,000
the contractor needs to take a look at

00:08:51,120 --> 00:08:55,760
the work that the client wants it to do

00:08:54,000 --> 00:08:57,839
and then set up the resources that it

00:08:55,760 --> 00:08:59,440
needs in order to complete that job

00:08:57,839 --> 00:09:00,880
so for example the contractor reads

00:08:59,440 --> 00:09:02,480
through the project briefing and other

00:09:00,880 --> 00:09:03,920
supporting documents

00:09:02,480 --> 00:09:05,760
and turns them into something that it

00:09:03,920 --> 00:09:07,440
can work with

00:09:05,760 --> 00:09:09,200
so this might be something like setting

00:09:07,440 --> 00:09:10,720
up the project management system with

00:09:09,200 --> 00:09:13,279
all of the documents stored and

00:09:10,720 --> 00:09:16,959
organized and breaking things into tasks

00:09:13,279 --> 00:09:19,279
that go into the task management system

00:09:16,959 --> 00:09:21,120
in the case of the js engine this work

00:09:19,279 --> 00:09:22,880
looks more like reading through the top

00:09:21,120 --> 00:09:24,640
level of source code and parsing

00:09:22,880 --> 00:09:26,560
functions into bytecode

00:09:24,640 --> 00:09:28,320
or allocating memory for the variables

00:09:26,560 --> 00:09:31,120
that are declared and setting values

00:09:28,320 --> 00:09:33,200
where they're already defined

00:09:31,120 --> 00:09:34,480
so that's application initialization but

00:09:33,200 --> 00:09:37,519
in some cases there's also

00:09:34,480 --> 00:09:39,600
engine initialization and you see this

00:09:37,519 --> 00:09:42,000
in contexts like serverless

00:09:39,600 --> 00:09:43,440
the js engine itself needs to be started

00:09:42,000 --> 00:09:45,440
up in the first place

00:09:43,440 --> 00:09:48,320
and built-in functions need to be added

00:09:45,440 --> 00:09:48,320
to the environment

00:09:48,560 --> 00:09:51,600
i think of this like setting up the

00:09:50,240 --> 00:09:53,440
office itself

00:09:51,600 --> 00:09:55,120
doing things like assembling the ikea

00:09:53,440 --> 00:09:57,279
chairs and tables

00:09:55,120 --> 00:09:59,440
and everything else in the environment

00:09:57,279 --> 00:10:02,240
before starting the work

00:09:59,440 --> 00:10:04,000
now this can take considerable time and

00:10:02,240 --> 00:10:04,560
that's part of what can make the cold

00:10:04,000 --> 00:10:08,640
start

00:10:04,560 --> 00:10:08,640
such an issue for serverless use cases

00:10:08,720 --> 00:10:13,680
once the initialization phase is done

00:10:11,200 --> 00:10:16,399
the js engine can start its work

00:10:13,680 --> 00:10:17,839
this work of running the code and the

00:10:16,399 --> 00:10:19,040
speed of this part of the work is called

00:10:17,839 --> 00:10:20,800
throughput

00:10:19,040 --> 00:10:22,640
and this throughput is affected by lots

00:10:20,800 --> 00:10:25,120
of different variables so for example

00:10:22,640 --> 00:10:26,959
which language features are being used

00:10:25,120 --> 00:10:29,600
whether the code behaves predictably

00:10:26,959 --> 00:10:31,680
from the js engine's point of view

00:10:29,600 --> 00:10:33,680
what sorts of data structures are used

00:10:31,680 --> 00:10:35,760
and whether or not the code runs long

00:10:33,680 --> 00:10:38,880
enough to benefit from the js engine's

00:10:35,760 --> 00:10:38,880
optimizing compiler

00:10:38,959 --> 00:10:43,279
so these are the two phases where the js

00:10:41,279 --> 00:10:47,839
engine spends its time

00:10:43,279 --> 00:10:47,839
initialization and runtime

00:10:49,920 --> 00:10:53,200
now how can we make the work in these

00:10:52,399 --> 00:10:55,600
two phases

00:10:53,200 --> 00:10:58,240
go faster let's start with

00:10:55,600 --> 00:11:01,360
initialization can we make that fast

00:10:58,240 --> 00:11:03,760
and spoiler alert yes we can

00:11:01,360 --> 00:11:05,680
we used a tool called wiser for this and

00:11:03,760 --> 00:11:07,279
i'll explain how that works in a minute

00:11:05,680 --> 00:11:09,360
but first i want to show you some of the

00:11:07,279 --> 00:11:11,200
results that we saw

00:11:09,360 --> 00:11:13,440
we tested with a small markdown

00:11:11,200 --> 00:11:15,519
application and using wiser

00:11:13,440 --> 00:11:17,680
we were able to make startup time six

00:11:15,519 --> 00:11:20,320
times faster

00:11:17,680 --> 00:11:21,279
if we look in more depth at this case

00:11:20,320 --> 00:11:23,600
about 80

00:11:21,279 --> 00:11:25,680
of this was spent on engine

00:11:23,600 --> 00:11:27,600
initialization

00:11:25,680 --> 00:11:29,519
and the remaining 20 was spent on

00:11:27,600 --> 00:11:31,040
application initialization

00:11:29,519 --> 00:11:33,279
and part of that is because this

00:11:31,040 --> 00:11:35,200
markdown render is a very small and

00:11:33,279 --> 00:11:37,519
simple application

00:11:35,200 --> 00:11:39,600
as apps get larger and more complex

00:11:37,519 --> 00:11:42,480
application initialization time

00:11:39,600 --> 00:11:44,560
just takes longer so we would see even

00:11:42,480 --> 00:11:48,160
larger comparative speed ups

00:11:44,560 --> 00:11:50,560
for real world applications

00:11:48,160 --> 00:11:53,279
now we get this fast startup using a

00:11:50,560 --> 00:11:55,519
technique called snapshotting

00:11:53,279 --> 00:11:56,880
before the code is deployed as part of

00:11:55,519 --> 00:11:58,560
the build step

00:11:56,880 --> 00:11:59,920
we run the javascript code using the

00:11:58,560 --> 00:12:02,720
javascript engine to the

00:11:59,920 --> 00:12:04,720
end of the initialization phase and at

00:12:02,720 --> 00:12:06,000
this point the js engine has parsed all

00:12:04,720 --> 00:12:09,120
of the js bytecode

00:12:06,000 --> 00:12:11,440
or js and turned it into bytecode

00:12:09,120 --> 00:12:12,720
which the js engine module stores in the

00:12:11,440 --> 00:12:14,480
linear memory

00:12:12,720 --> 00:12:16,320
and the engine also does a lot of memory

00:12:14,480 --> 00:12:18,320
allocation and initialization in this

00:12:16,320 --> 00:12:20,160
phase

00:12:18,320 --> 00:12:21,760
because this linear memory is so

00:12:20,160 --> 00:12:23,440
self-contained

00:12:21,760 --> 00:12:25,440
once all the values have been filled in

00:12:23,440 --> 00:12:26,720
we can just take that memory and attach

00:12:25,440 --> 00:12:30,160
it as a data section

00:12:26,720 --> 00:12:32,560
to a wasm module when the js

00:12:30,160 --> 00:12:33,200
engine module is instantiated it has

00:12:32,560 --> 00:12:36,320
access

00:12:33,200 --> 00:12:38,160
to all of the data in the data section

00:12:36,320 --> 00:12:40,480
whenever the engine needs a bit of that

00:12:38,160 --> 00:12:43,279
memory it can copy the section or rather

00:12:40,480 --> 00:12:45,839
the memory page that it needs into its

00:12:43,279 --> 00:12:48,000
own linear memory

00:12:45,839 --> 00:12:50,639
with this the js engine doesn't have to

00:12:48,000 --> 00:12:53,440
do any setup when it starts up

00:12:50,639 --> 00:12:56,800
all of this is pre-initialized ready and

00:12:53,440 --> 00:12:56,800
waiting for it to start its work

00:12:56,880 --> 00:13:00,639
currently we attach the data section to

00:12:58,880 --> 00:13:02,880
the same module as the js

00:13:00,639 --> 00:13:04,959
engine but in the future once

00:13:02,880 --> 00:13:06,800
webassembly module linking is in place

00:13:04,959 --> 00:13:08,880
we'll be able to ship the data section

00:13:06,800 --> 00:13:10,560
as a separate module

00:13:08,880 --> 00:13:12,160
so this provides a really clean

00:13:10,560 --> 00:13:14,240
separation and allows the js

00:13:12,160 --> 00:13:17,920
engine module to be reused across a

00:13:14,240 --> 00:13:20,160
bunch of different js applications

00:13:17,920 --> 00:13:22,240
the js engine module only contains the

00:13:20,160 --> 00:13:24,320
code for the engine

00:13:22,240 --> 00:13:26,079
that means that once it's compiled that

00:13:24,320 --> 00:13:27,920
code can be effectively cached

00:13:26,079 --> 00:13:29,600
and reused between lots of different

00:13:27,920 --> 00:13:31,839
instances

00:13:29,600 --> 00:13:33,120
now on the other hand the application

00:13:31,839 --> 00:13:35,839
specific module

00:13:33,120 --> 00:13:37,440
contains no webassembly code it only

00:13:35,839 --> 00:13:39,279
contains the linear memory

00:13:37,440 --> 00:13:40,959
which in turn contains the javascript

00:13:39,279 --> 00:13:42,720
vice bytecode

00:13:40,959 --> 00:13:45,600
along with all of the rest of the js

00:13:42,720 --> 00:13:47,680
engine state that was initialized

00:13:45,600 --> 00:13:49,519
this makes it really easy to move this

00:13:47,680 --> 00:13:52,000
memory around and send it wherever it

00:13:49,519 --> 00:13:53,920
needs to go

00:13:52,000 --> 00:13:55,519
it's kind of like the j ascension

00:13:53,920 --> 00:13:57,199
contractor doesn't need to set up its

00:13:55,519 --> 00:13:59,120
own office at all it just gets this

00:13:57,199 --> 00:14:00,800
travel case shipped to it

00:13:59,120 --> 00:14:02,639
and that travel case has the whole

00:14:00,800 --> 00:14:03,600
office with everything in it all set up

00:14:02,639 --> 00:14:06,639
and ready to go

00:14:03,600 --> 00:14:08,720
for the js engine to just get to work

00:14:06,639 --> 00:14:10,959
and the coolest thing about this is that

00:14:08,720 --> 00:14:12,320
it doesn't rely on anything that's js

00:14:10,959 --> 00:14:14,800
dependent

00:14:12,320 --> 00:14:16,800
it's just using an existing property of

00:14:14,800 --> 00:14:18,880
webassembly itself

00:14:16,800 --> 00:14:21,600
so you could use the same technique with

00:14:18,880 --> 00:14:24,720
languages like python or ruby or lua

00:14:21,600 --> 00:14:24,720
and other runtimes too

00:14:25,040 --> 00:14:30,240
so with this approach we can get to this

00:14:27,760 --> 00:14:33,120
super fast startup time

00:14:30,240 --> 00:14:34,880
but what about throughput well for some

00:14:33,120 --> 00:14:36,480
use cases the throughput is actually not

00:14:34,880 --> 00:14:38,639
too bad

00:14:36,480 --> 00:14:40,079
if you have a very short running piece

00:14:38,639 --> 00:14:41,279
of javascript it wouldn't go through the

00:14:40,079 --> 00:14:42,480
jit anyways

00:14:41,279 --> 00:14:44,320
it would stay in the interpreter the

00:14:42,480 --> 00:14:45,920
whole time so in that case

00:14:44,320 --> 00:14:47,680
the throughput would be about the same

00:14:45,920 --> 00:14:50,079
as in the browser

00:14:47,680 --> 00:14:51,920
and so this will have finished before a

00:14:50,079 --> 00:14:53,600
traditional javascript engine would have

00:14:51,920 --> 00:14:54,399
finished initialization in the case

00:14:53,600 --> 00:14:57,440
where you need to do

00:14:54,399 --> 00:14:59,519
engine initialization but for

00:14:57,440 --> 00:15:01,839
longer running javascript it doesn't

00:14:59,519 --> 00:15:03,040
take all that long before the jit starts

00:15:01,839 --> 00:15:04,720
kicking in

00:15:03,040 --> 00:15:08,399
and once this happens the throughput

00:15:04,720 --> 00:15:10,720
difference does become pretty obvious

00:15:08,399 --> 00:15:12,240
now as i said before it's not possible

00:15:10,720 --> 00:15:16,399
to jit compile code within

00:15:12,240 --> 00:15:18,320
a pure webassembly module at the moment

00:15:16,399 --> 00:15:20,320
but it turns out that we can apply some

00:15:18,320 --> 00:15:21,920
of the same thinking that comes with

00:15:20,320 --> 00:15:25,760
just in time compilation

00:15:21,920 --> 00:15:27,760
to and ahead of time compilation model

00:15:25,760 --> 00:15:29,920
so one optimizing technique that jits

00:15:27,760 --> 00:15:30,560
use is inline caching which i also

00:15:29,920 --> 00:15:34,000
explained

00:15:30,560 --> 00:15:35,600
in my first series about webassembly

00:15:34,000 --> 00:15:38,079
when the same bit of code gets

00:15:35,600 --> 00:15:39,839
interpreted over and over and over again

00:15:38,079 --> 00:15:41,680
the engine decides to store its

00:15:39,839 --> 00:15:44,399
translation for that bit of code

00:15:41,680 --> 00:15:47,120
to reuse next time and this stored

00:15:44,399 --> 00:15:48,800
translation is called the stub

00:15:47,120 --> 00:15:50,639
now these stubs are chained together

00:15:48,800 --> 00:15:52,880
into a linked list

00:15:50,639 --> 00:15:55,519
and they're based on what types are used

00:15:52,880 --> 00:15:57,040
for that particular invocation

00:15:55,519 --> 00:15:58,480
the next time that the code is run the

00:15:57,040 --> 00:15:58,800
engine will check through this list to

00:15:58,480 --> 00:15:59,920
see

00:15:58,800 --> 00:16:01,839
whether or not it actually has a

00:15:59,920 --> 00:16:04,800
translation that

00:16:01,839 --> 00:16:08,079
is available for those types and if so

00:16:04,800 --> 00:16:10,639
it'll just reuse this dub

00:16:08,079 --> 00:16:12,000
because ice subs are commonly used in

00:16:10,639 --> 00:16:13,519
jets

00:16:12,000 --> 00:16:16,079
people think of them as being very

00:16:13,519 --> 00:16:18,000
dynamic and specific to each program but

00:16:16,079 --> 00:16:21,440
it turns out that they can be applied

00:16:18,000 --> 00:16:23,519
in an aot context too

00:16:21,440 --> 00:16:25,680
even before we see the javascript code

00:16:23,519 --> 00:16:27,680
we already know a lot of the ic stubs

00:16:25,680 --> 00:16:30,160
that we're going to need to use

00:16:27,680 --> 00:16:32,000
and to generate and that's because there

00:16:30,160 --> 00:16:34,320
are some patterns in javascript that

00:16:32,000 --> 00:16:36,480
just get used a whole lot

00:16:34,320 --> 00:16:38,720
a good example of this is accessing

00:16:36,480 --> 00:16:40,720
properties on objects

00:16:38,720 --> 00:16:42,720
this happens a lot in javascript code

00:16:40,720 --> 00:16:44,320
and it can be sped up by using an ic

00:16:42,720 --> 00:16:46,320
stub

00:16:44,320 --> 00:16:47,440
for objects that have a certain shape or

00:16:46,320 --> 00:16:49,199
hidden class

00:16:47,440 --> 00:16:51,600
that is where the properties are laid

00:16:49,199 --> 00:16:54,000
out in the same order

00:16:51,600 --> 00:16:55,920
when you get a particular property from

00:16:54,000 --> 00:16:58,399
those objects that property will always

00:16:55,920 --> 00:17:00,320
be at the same offset

00:16:58,399 --> 00:17:01,839
now traditionally this kind of ic stub

00:17:00,320 --> 00:17:04,880
in the jet would hard code

00:17:01,839 --> 00:17:07,919
two values the pointer to the shape

00:17:04,880 --> 00:17:09,439
and the offset of the property that

00:17:07,919 --> 00:17:10,880
requires information that we don't have

00:17:09,439 --> 00:17:13,439
ahead of time

00:17:10,880 --> 00:17:14,959
but what we can do is parameterize the

00:17:13,439 --> 00:17:16,720
ic stub

00:17:14,959 --> 00:17:18,799
so we can treat the shape and the

00:17:16,720 --> 00:17:19,280
property offset as variables that get

00:17:18,799 --> 00:17:23,120
passed

00:17:19,280 --> 00:17:24,880
in for the stub and this way we create a

00:17:23,120 --> 00:17:25,679
single stub that loads values from

00:17:24,880 --> 00:17:27,280
memory

00:17:25,679 --> 00:17:29,120
and then use that same stub code

00:17:27,280 --> 00:17:31,200
everywhere we can just

00:17:29,120 --> 00:17:33,919
bake all of the stubs for these common

00:17:31,200 --> 00:17:35,039
patterns into the aot compiled module

00:17:33,919 --> 00:17:38,640
regardless

00:17:35,039 --> 00:17:40,160
of what the javascript is actually doing

00:17:38,640 --> 00:17:42,400
and we discovered that with just a

00:17:40,160 --> 00:17:43,280
couple of kilobytes of ic stubs we can

00:17:42,400 --> 00:17:46,320
cover the vast

00:17:43,280 --> 00:17:48,480
majority of all js code for example with

00:17:46,320 --> 00:17:50,000
two kilobytes of ic stubs we can cover

00:17:48,480 --> 00:17:52,640
95 percent

00:17:50,000 --> 00:17:53,440
of the javascript in google's octane

00:17:52,640 --> 00:17:55,520
benchmark

00:17:53,440 --> 00:17:57,360
and from preliminary tests that percent

00:17:55,520 --> 00:18:00,799
percentage seems to hold up

00:17:57,360 --> 00:18:02,720
for general web browsing as well

00:18:00,799 --> 00:18:06,240
now this is just one example of a

00:18:02,720 --> 00:18:08,160
potential optimization that we can make

00:18:06,240 --> 00:18:10,400
right now we're in the same kind of

00:18:08,160 --> 00:18:11,039
position that the browser js engines

00:18:10,400 --> 00:18:13,200
were in

00:18:11,039 --> 00:18:14,080
in the early days when they were first

00:18:13,200 --> 00:18:16,160
experimenting

00:18:14,080 --> 00:18:17,600
with just-in-time compilers in the first

00:18:16,160 --> 00:18:19,679
place

00:18:17,600 --> 00:18:21,520
we still have a lot of work to do to

00:18:19,679 --> 00:18:22,000
find the clever shortcuts that we can

00:18:21,520 --> 00:18:24,400
use

00:18:22,000 --> 00:18:26,000
in this context but we're excited to be

00:18:24,400 --> 00:18:28,799
starting that work and excited for the

00:18:26,000 --> 00:18:30,799
changes to come

00:18:28,799 --> 00:18:31,840
if you're excited like we are about this

00:18:30,799 --> 00:18:33,360
and want to contribute to the

00:18:31,840 --> 00:18:35,200
optimization efforts

00:18:33,360 --> 00:18:37,440
or if you want to try to make this work

00:18:35,200 --> 00:18:38,240
for another language like python or ruby

00:18:37,440 --> 00:18:40,480
or lua

00:18:38,240 --> 00:18:42,320
we'd be happy to hear from you you can

00:18:40,480 --> 00:18:45,120
find us on the messaging platform

00:18:42,320 --> 00:18:47,600
zulip and feel free to post there if you

00:18:45,120 --> 00:18:49,440
want to ask for more info

00:18:47,600 --> 00:18:51,120
you can also find links to the projects

00:18:49,440 --> 00:18:52,720
that i mentioned in my recently

00:18:51,120 --> 00:18:54,880
published blog post on the bytecode

00:18:52,720 --> 00:18:56,400
alliance blog

00:18:54,880 --> 00:18:58,320
i want to say thank you to the

00:18:56,400 --> 00:18:59,120
organizers for inviting me to speak here

00:18:58,320 --> 00:19:03,200
today

00:18:59,120 --> 00:19:03,200

YouTube URL: https://www.youtube.com/watch?v=MvAU752MqW4


