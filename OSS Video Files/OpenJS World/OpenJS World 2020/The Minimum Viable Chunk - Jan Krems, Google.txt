Title: The Minimum Viable Chunk - Jan Krems, Google
Publication date: 2020-06-17
Playlist: OpenJS World 2020
Description: 
	
Captions: 
	00:00:00,000 --> 00:00:05,160
back in the old days when jQuery had

00:00:03,149 --> 00:00:08,099
just taken the web development world by

00:00:05,160 --> 00:00:10,260
storm most developers had a very clear

00:00:08,099 --> 00:00:12,990
idea of what a good build process for

00:00:10,260 --> 00:00:14,700
the web looked like an application had a

00:00:12,990 --> 00:00:15,179
list of scripts to be included on the

00:00:14,700 --> 00:00:17,550
page

00:00:15,179 --> 00:00:19,770
they all got concatenated into one big

00:00:17,550 --> 00:00:23,070
bundle and aesthetic script tag in the

00:00:19,770 --> 00:00:25,460
HTML pointed to the latest version but

00:00:23,070 --> 00:00:28,769
over time user expectations changed

00:00:25,460 --> 00:00:31,019
websites were expected to do more and at

00:00:28,769 --> 00:00:33,300
the same time they were still expected

00:00:31,019 --> 00:00:36,149
to load fast even on slow mobile

00:00:33,300 --> 00:00:38,280
connections lately everybody seemed to

00:00:36,149 --> 00:00:40,559
agree that the answer is to split the

00:00:38,280 --> 00:00:43,980
big bundles of the past into smaller and

00:00:40,559 --> 00:00:46,710
smaller chunks but is smaller always

00:00:43,980 --> 00:00:49,170
better is there a limit to how small we

00:00:46,710 --> 00:00:53,360
can go is there such a thing as a

00:00:49,170 --> 00:00:53,360
Minimum Viable Schock

00:00:54,580 --> 00:01:00,770
hello everyone my name is young some

00:00:58,460 --> 00:01:03,290
facts about myself I'm an occasional

00:01:00,770 --> 00:01:05,330
collaborator on no tricks inside of code

00:01:03,290 --> 00:01:07,970
core I'm working on better support for

00:01:05,330 --> 00:01:10,010
ears modules I'm gainfully employed as a

00:01:07,970 --> 00:01:12,020
software engineer at Google and if you

00:01:10,010 --> 00:01:16,070
want to find me on twitter my handle is

00:01:12,020 --> 00:01:19,040
at Yan cramps before we get started two

00:01:16,070 --> 00:01:21,110
disclaimers first there is some

00:01:19,040 --> 00:01:23,390
practical advice in this talk but it is

00:01:21,110 --> 00:01:25,670
not a step-by-step instruction for the

00:01:23,390 --> 00:01:27,530
perfect weapon setup if that is what

00:01:25,670 --> 00:01:29,030
you're looking for I'll be linking a

00:01:27,530 --> 00:01:31,790
pretty good guide at the end of this

00:01:29,030 --> 00:01:33,950
talk and secondly these are not the

00:01:31,790 --> 00:01:37,690
opinions of my employer and with that

00:01:33,950 --> 00:01:37,690
out of the way let's jump in

00:01:38,740 --> 00:01:44,590
since this is about finding a minimum

00:01:41,619 --> 00:01:47,500
viable chunk let's quickly recap what a

00:01:44,590 --> 00:01:50,229
chunk is for that purpose he is a very

00:01:47,500 --> 00:01:52,810
crude illustration of building a web app

00:01:50,229 --> 00:01:54,310
the build process collects all the

00:01:52,810 --> 00:01:56,740
source files that belong to the

00:01:54,310 --> 00:01:58,600
application analyzes them and then

00:01:56,740 --> 00:02:01,030
distributes the code across a number of

00:01:58,600 --> 00:02:03,549
output files and be called each one of

00:02:01,030 --> 00:02:05,590
those output files a chunk because it

00:02:03,549 --> 00:02:07,810
contains a chunk of the application code

00:02:05,590 --> 00:02:09,550
let's stick with this illustration a

00:02:07,810 --> 00:02:12,160
little longer though because you might

00:02:09,550 --> 00:02:14,739
have noticed something interesting if we

00:02:12,160 --> 00:02:18,100
remove the colors the left side and the

00:02:14,739 --> 00:02:19,780
right side are eerily similar it does

00:02:18,100 --> 00:02:21,459
look like we are taking code that has

00:02:19,780 --> 00:02:24,340
already been split up into nice

00:02:21,459 --> 00:02:26,519
individual units combined it just to

00:02:24,340 --> 00:02:29,140
then spit it up again into various files

00:02:26,519 --> 00:02:31,269
we could make our lives a lot easier if

00:02:29,140 --> 00:02:33,910
we kept the separation already present

00:02:31,269 --> 00:02:37,120
in the source files why is that not our

00:02:33,910 --> 00:02:39,580
minimum viable chunk to answer that

00:02:37,120 --> 00:02:44,040
question properly we'll have to look at

00:02:39,580 --> 00:02:44,040
what makes a set of output chunks viable

00:02:45,470 --> 00:02:51,780
what makes a set of Chung's viable

00:02:49,310 --> 00:02:55,880
fortunately the answer is simple and

00:02:51,780 --> 00:02:58,890
it's my two favorite words it depends I

00:02:55,880 --> 00:03:01,920
know it's not a very satisfying answer

00:02:58,890 --> 00:03:05,040
and I think we can do better on what

00:03:01,920 --> 00:03:06,660
does it depend we could look at how the

00:03:05,040 --> 00:03:09,540
way the code is split into chunks

00:03:06,660 --> 00:03:10,950
effects user experience there are many

00:03:09,540 --> 00:03:13,530
different factors that influence the

00:03:10,950 --> 00:03:16,290
final experience but here I want to

00:03:13,530 --> 00:03:18,330
focus on three each of them is directly

00:03:16,290 --> 00:03:20,550
affected by the way we decide to bundle

00:03:18,330 --> 00:03:22,800
the app and each of them could lead to

00:03:20,550 --> 00:03:25,320
an unacceptable user experience if we

00:03:22,800 --> 00:03:27,900
ignore it the three are download

00:03:25,320 --> 00:03:30,630
efficiency cache hit rate and code

00:03:27,900 --> 00:03:32,489
execution time the download efficiency

00:03:30,630 --> 00:03:35,010
determines the time it takes to transfer

00:03:32,489 --> 00:03:36,690
the application to the user's browser or

00:03:35,010 --> 00:03:38,190
at the very least the parts of the

00:03:36,690 --> 00:03:41,100
application that the user needs right

00:03:38,190 --> 00:03:42,989
now if this is too slow the user may not

00:03:41,100 --> 00:03:46,019
stick around long enough for anything

00:03:42,989 --> 00:03:48,150
else to matter but no matter how fast

00:03:46,019 --> 00:03:50,489
the download is we don't want the user

00:03:48,150 --> 00:03:52,799
to load everything from scratch if we

00:03:50,489 --> 00:03:55,140
can help it to provide a great user

00:03:52,799 --> 00:03:58,019
experience we want to serve responses

00:03:55,140 --> 00:04:00,180
from cache as often as possible this

00:03:58,019 --> 00:04:03,079
will determine if our app is fast enough

00:04:00,180 --> 00:04:06,209
on average not just in the worst case

00:04:03,079 --> 00:04:08,730
after the code has been loaded it still

00:04:06,209 --> 00:04:11,640
needs to run it doesn't really help the

00:04:08,730 --> 00:04:14,760
user if the code loads super quickly but

00:04:11,640 --> 00:04:17,039
then takes too long to execute this part

00:04:14,760 --> 00:04:19,680
is even relevant when all code came from

00:04:17,039 --> 00:04:22,380
the cache it's all about how quickly we

00:04:19,680 --> 00:04:25,169
are done running it and there are two

00:04:22,380 --> 00:04:28,110
aspects to this on one hand we need

00:04:25,169 --> 00:04:30,030
access to all relevant code if we only

00:04:28,110 --> 00:04:32,880
discover that we need additional code

00:04:30,030 --> 00:04:35,100
halfway through execution it will count

00:04:32,880 --> 00:04:36,810
against the execution time on the other

00:04:35,100 --> 00:04:38,880
hand we really don't want to

00:04:36,810 --> 00:04:41,930
accidentally run code that's not needed

00:04:38,880 --> 00:04:44,640
right now that will cause delays as well

00:04:41,930 --> 00:04:47,430
download efficiency cache hit rate and

00:04:44,640 --> 00:04:51,060
code execution time are at least to some

00:04:47,430 --> 00:04:53,060
degree mutually exclusive fun fact this

00:04:51,060 --> 00:04:55,680
kind of diagram is called a ternary plot

00:04:53,060 --> 00:04:59,009
which I learned while making the slide

00:04:55,680 --> 00:05:01,409
the point is we can't fully optimize

00:04:59,009 --> 00:05:03,869
for one of them without sacrificing

00:05:01,409 --> 00:05:05,639
something about the others if we are

00:05:03,869 --> 00:05:08,189
somewhere in the middle of this triangle

00:05:05,639 --> 00:05:10,710
and we want to move closer and closer to

00:05:08,189 --> 00:05:12,960
the download' corner eventually we'll

00:05:10,710 --> 00:05:15,300
have to move away from both execution

00:05:12,960 --> 00:05:18,599
and cache it's what does that mean in

00:05:15,300 --> 00:05:20,819
practice let's ignore execution and just

00:05:18,599 --> 00:05:23,610
look at down load efficiency and cache

00:05:20,819 --> 00:05:25,589
it's if we are focused on getting more

00:05:23,610 --> 00:05:27,869
cache it's we might come to the

00:05:25,589 --> 00:05:31,229
conclusion that smaller chunks are

00:05:27,869 --> 00:05:34,229
always better we'd start with a chunk of

00:05:31,229 --> 00:05:36,539
any size we'd see that it changed

00:05:34,229 --> 00:05:38,520
towards the end of the chunk invalidates

00:05:36,539 --> 00:05:41,909
the cache for the rest of the chunk and

00:05:38,520 --> 00:05:44,249
so we'd split it up as long as there's

00:05:41,909 --> 00:05:47,610
any way to split chunks into smaller

00:05:44,249 --> 00:05:50,550
pieces we would have to continue at the

00:05:47,610 --> 00:05:53,699
end we'd have the perfect cache hit rate

00:05:50,550 --> 00:05:56,309
every tiny section of code get its very

00:05:53,699 --> 00:05:58,680
own chunk cache independently from the

00:05:56,309 --> 00:06:00,599
rest of the program but what happens

00:05:58,680 --> 00:06:03,599
when we don't hit the cache what

00:06:00,599 --> 00:06:06,089
happened to our download efficiency it

00:06:03,599 --> 00:06:09,509
got real bad and one reason is

00:06:06,089 --> 00:06:11,520
compression we usually don't send the

00:06:09,509 --> 00:06:13,589
actual file contents of the network

00:06:11,520 --> 00:06:16,469
especially for text files like

00:06:13,589 --> 00:06:19,139
JavaScript code what we sent instead is

00:06:16,469 --> 00:06:21,360
a compressed version the principle idea

00:06:19,139 --> 00:06:23,519
is to try to find patterns in the input

00:06:21,360 --> 00:06:26,069
to reduce the size of the output and

00:06:23,519 --> 00:06:28,949
that is a problem as the inputs get

00:06:26,069 --> 00:06:31,289
smaller and smaller if an input contains

00:06:28,949 --> 00:06:33,599
ten function declarations there is an

00:06:31,289 --> 00:06:36,389
obvious pattern that can be used if it's

00:06:33,599 --> 00:06:38,849
a single function not so much which

00:06:36,389 --> 00:06:41,339
means the same amount of code split up

00:06:38,849 --> 00:06:43,620
into many small chunks will need to

00:06:41,339 --> 00:06:46,050
transfer more bytes over the network

00:06:43,620 --> 00:06:48,269
each of the chunks will be harder to

00:06:46,050 --> 00:06:50,219
compress individually than when they

00:06:48,269 --> 00:06:53,099
were still part of the same response and

00:06:50,219 --> 00:06:55,499
so eventually we get to the point where

00:06:53,099 --> 00:06:57,360
we have to make a choice do we keep

00:06:55,499 --> 00:07:00,029
splitting chunks to get higher and

00:06:57,360 --> 00:07:02,219
higher cache hit rates or with the

00:07:00,029 --> 00:07:05,550
download efficiency become unacceptable

00:07:02,219 --> 00:07:09,149
if we do a viable solution would have to

00:07:05,550 --> 00:07:11,159
fall somewhere in between we can repeat

00:07:09,149 --> 00:07:12,620
this exercise with the next edge of the

00:07:11,159 --> 00:07:15,199
triangle the line

00:07:12,620 --> 00:07:17,870
between cash its and execution let's

00:07:15,199 --> 00:07:20,060
take this example we have two snippets

00:07:17,870 --> 00:07:23,840
of application code on the left side a

00:07:20,060 --> 00:07:26,150
and on the right side B we'll assume

00:07:23,840 --> 00:07:29,720
that each one gets loaded on a different

00:07:26,150 --> 00:07:32,540
page because they both reuse the same

00:07:29,720 --> 00:07:33,290
logic we put that shared code into its

00:07:32,540 --> 00:07:38,000
own chunk

00:07:33,290 --> 00:07:40,760
C whenever a or B is loaded C will be

00:07:38,000 --> 00:07:44,389
loaded as well let's check how we're

00:07:40,760 --> 00:07:46,940
doing on cache its and execution things

00:07:44,389 --> 00:07:49,820
are looking good for caches if anything

00:07:46,940 --> 00:07:51,770
changes in one of the three chunks only

00:07:49,820 --> 00:07:54,680
that one chunk gets invalidated in the

00:07:51,770 --> 00:07:57,050
cache and actually no issue from an

00:07:54,680 --> 00:07:59,720
execution point of view either whether

00:07:57,050 --> 00:08:02,180
we run a with a common chunk or B with a

00:07:59,720 --> 00:08:04,639
common chunk we're only running the code

00:08:02,180 --> 00:08:06,530
that's necessary and even if we have

00:08:04,639 --> 00:08:08,000
client-side routing and both of them

00:08:06,530 --> 00:08:10,880
eventually run in the same window

00:08:08,000 --> 00:08:14,300
there's no line of code executed twice

00:08:10,880 --> 00:08:16,880
or unnecessarily but the structure of

00:08:14,300 --> 00:08:18,860
the code may change over time and that

00:08:16,880 --> 00:08:22,099
is where it gets tricky let's make a

00:08:18,860 --> 00:08:24,680
small change a removes one of the two

00:08:22,099 --> 00:08:27,919
imports now we are faced with a

00:08:24,680 --> 00:08:30,560
conundrum we didn't change B or any of

00:08:27,919 --> 00:08:32,959
its dependencies if we're interested in

00:08:30,560 --> 00:08:36,440
cash it's we would want to preserve the

00:08:32,959 --> 00:08:39,080
cache of B and of C neither of them has

00:08:36,440 --> 00:08:41,750
changed after all but wearing our

00:08:39,080 --> 00:08:44,180
execution time head we don't want to run

00:08:41,750 --> 00:08:46,910
code that's not necessary and if C

00:08:44,180 --> 00:08:51,410
doesn't change then whenever we load a

00:08:46,910 --> 00:08:54,560
we will run code that isn't necessary so

00:08:51,410 --> 00:08:56,240
we have to choose again do we change or

00:08:54,560 --> 00:08:58,430
restructure the common chunk so it

00:08:56,240 --> 00:09:01,190
always reflects the latest state of what

00:08:58,430 --> 00:09:04,010
is actually shared or do we need more

00:09:01,190 --> 00:09:05,870
cash it's there's an inherent friction

00:09:04,010 --> 00:09:08,180
here between allowing global

00:09:05,870 --> 00:09:10,459
optimizations for fast execution on one

00:09:08,180 --> 00:09:13,160
side and stable chunks that stick around

00:09:10,459 --> 00:09:15,560
in the cache on the other if you kept

00:09:13,160 --> 00:09:17,660
track there's one more edge we haven't

00:09:15,560 --> 00:09:20,510
talked about and that is the one between

00:09:17,660 --> 00:09:23,660
execution and download at first glance

00:09:20,510 --> 00:09:25,560
they may seem like the same thing if we

00:09:23,660 --> 00:09:28,740
download more code we

00:09:25,560 --> 00:09:31,050
execute more code intuitively they're

00:09:28,740 --> 00:09:34,260
the same but it's not always as

00:09:31,050 --> 00:09:36,690
one-to-one relationship sometimes it can

00:09:34,260 --> 00:09:40,100
take downloading more code to execute

00:09:36,690 --> 00:09:42,600
less code let's take these two modules

00:09:40,100 --> 00:09:45,270
entry is an entry point into the

00:09:42,600 --> 00:09:48,750
application and sometimes that entry

00:09:45,270 --> 00:09:52,050
point imports em but it is only known at

00:09:48,750 --> 00:09:54,300
runtime if it will import em or not in

00:09:52,050 --> 00:09:56,250
real code this could be because it

00:09:54,300 --> 00:09:58,350
depends on certain browser features or

00:09:56,250 --> 00:10:00,960
because it depends on data that was

00:09:58,350 --> 00:10:03,870
loaded from an API for this example

00:10:00,960 --> 00:10:06,210
we'll say it's random and to clarify

00:10:03,870 --> 00:10:07,650
this example assumes that using dynamic

00:10:06,210 --> 00:10:10,529
import isn't good enough

00:10:07,650 --> 00:10:12,210
in the cases where we need em we can't

00:10:10,529 --> 00:10:14,580
wait for another round trip to get it

00:10:12,210 --> 00:10:17,520
it's a crucial part of the initial user

00:10:14,580 --> 00:10:19,560
experience our build process assigned

00:10:17,520 --> 00:10:21,420
both of these files to the same chunk

00:10:19,560 --> 00:10:24,150
and because we wanted to have the

00:10:21,420 --> 00:10:25,950
fastest possible download we decided to

00:10:24,150 --> 00:10:28,529
use a technique called scope hoisting

00:10:25,950 --> 00:10:31,320
both modules are merged into one

00:10:28,529 --> 00:10:33,270
combined module we saved all the bytes

00:10:31,320 --> 00:10:35,640
from setting exports properties and

00:10:33,270 --> 00:10:38,030
calling require and it certainly looks

00:10:35,640 --> 00:10:40,890
like execution should be cheaper as well

00:10:38,030 --> 00:10:43,650
but in this particular case we

00:10:40,890 --> 00:10:46,470
introduced a problem before we merge the

00:10:43,650 --> 00:10:49,290
two modules calculate value was only

00:10:46,470 --> 00:10:52,470
executed when the value was actually

00:10:49,290 --> 00:10:55,410
needed now we're always running it if

00:10:52,470 --> 00:10:58,310
that function is expensive we just make

00:10:55,410 --> 00:11:00,900
the average execution time a lot worse a

00:10:58,310 --> 00:11:02,520
practical example would be top level

00:11:00,900 --> 00:11:05,220
code that builds a complex data

00:11:02,520 --> 00:11:07,680
structure think a big static JSX

00:11:05,220 --> 00:11:10,200
fragment that get rightfully moved out

00:11:07,680 --> 00:11:13,110
of a components render function if we

00:11:10,200 --> 00:11:15,500
needed a lower execution time we might

00:11:13,110 --> 00:11:18,750
want to preserve the module boundaries

00:11:15,500 --> 00:11:20,700
this is a lot more code to download but

00:11:18,750 --> 00:11:23,480
because we are running the module body

00:11:20,700 --> 00:11:27,740
of M only when it's actually needed on

00:11:23,480 --> 00:11:32,010
average it will execute more quickly now

00:11:27,740 --> 00:11:34,320
this was very situational usually scope

00:11:32,010 --> 00:11:36,920
hoisting reduces the download size and

00:11:34,320 --> 00:11:38,800
also leads to faster execution times

00:11:36,920 --> 00:11:40,570
also in

00:11:38,800 --> 00:11:43,750
example we were talking about running

00:11:40,570 --> 00:11:45,760
the entire modular body of em lazily but

00:11:43,750 --> 00:11:48,399
the same idea applies to any kind of

00:11:45,760 --> 00:11:50,529
lazy value for every lazy value

00:11:48,399 --> 00:11:53,410
additional code has to be shipped to

00:11:50,529 --> 00:11:55,950
handle the lazy calculation but if the

00:11:53,410 --> 00:11:59,110
value is needed or until it is needed

00:11:55,950 --> 00:12:01,329
execution can wrap up more quickly what

00:11:59,110 --> 00:12:04,720
did all of this tell us about what's

00:12:01,329 --> 00:12:06,970
viable we've seen that having more

00:12:04,720 --> 00:12:09,700
fine-grained chunks can mean that the

00:12:06,970 --> 00:12:11,470
download becomes too inefficient we've

00:12:09,700 --> 00:12:13,510
seen that maintaining high cache hit

00:12:11,470 --> 00:12:16,089
rates may prevent us from adding

00:12:13,510 --> 00:12:18,279
important global optimizations and we've

00:12:16,089 --> 00:12:21,160
seen that sometimes we need to download

00:12:18,279 --> 00:12:25,060
more code to ensure execution is fast

00:12:21,160 --> 00:12:26,890
enough so any viable solution we'll have

00:12:25,060 --> 00:12:30,190
to make some trade-offs between those

00:12:26,890 --> 00:12:32,620
extremes with that we are ready to draw

00:12:30,190 --> 00:12:34,540
some conclusions we know what a chunk is

00:12:32,620 --> 00:12:37,839
we know what makes a set of chunks

00:12:34,540 --> 00:12:40,829
viable so how small can we go without

00:12:37,839 --> 00:12:40,829
running into issues

00:12:41,840 --> 00:12:47,280
let's start with a throwback to our

00:12:44,430 --> 00:12:49,200
definition of chunk we saw source files

00:12:47,280 --> 00:12:51,780
on the left and chunk files on the right

00:12:49,200 --> 00:12:54,120
and it seemed awfully convenient to use

00:12:51,780 --> 00:12:57,540
the existing source 5 honorees as our

00:12:54,120 --> 00:13:00,450
chunks in development doing just that

00:12:57,540 --> 00:13:03,300
can be absolutely viable if you're using

00:13:00,450 --> 00:13:05,100
es modules you can try it out today you

00:13:03,300 --> 00:13:07,650
might have already heard about snowpack

00:13:05,100 --> 00:13:10,020
or def server both of those tools

00:13:07,650 --> 00:13:12,750
effectively treat your source files as

00:13:10,020 --> 00:13:14,970
chunks so there's no need to run an

00:13:12,750 --> 00:13:17,640
extensive build process and in

00:13:14,970 --> 00:13:19,770
development build speed is often more

00:13:17,640 --> 00:13:22,410
important than a realistic user

00:13:19,770 --> 00:13:25,170
experience if we want a minimum chunk

00:13:22,410 --> 00:13:27,420
that's viable for end-users we have to

00:13:25,170 --> 00:13:30,540
take one more look at the triangle it

00:13:27,420 --> 00:13:33,690
turns out the triangle is actually a

00:13:30,540 --> 00:13:35,880
pyramid in the earlier slide one of the

00:13:33,690 --> 00:13:37,770
corners just wasn't quite visible you

00:13:35,880 --> 00:13:39,660
might say there was some hidden

00:13:37,770 --> 00:13:42,120
complexity I'm so sorry

00:13:39,660 --> 00:13:44,310
this new corner represents how concerned

00:13:42,120 --> 00:13:46,800
we are about introducing more complexity

00:13:44,310 --> 00:13:48,300
into our system if we want to get the

00:13:46,800 --> 00:13:50,340
smallest chunks that are viable in

00:13:48,300 --> 00:13:52,830
production we'll have to accept some

00:13:50,340 --> 00:13:55,740
additional complexity but it starts with

00:13:52,830 --> 00:13:58,530
small changes this is an example of a

00:13:55,740 --> 00:14:00,510
manifest or digest file it's a fire that

00:13:58,530 --> 00:14:02,400
lists all entry points into the

00:14:00,510 --> 00:14:04,260
application and maps them to a

00:14:02,400 --> 00:14:06,930
fingerprinted file to be loaded in

00:14:04,260 --> 00:14:09,390
production in this case there's also an

00:14:06,930 --> 00:14:12,030
explicitly listed common chunk that will

00:14:09,390 --> 00:14:14,640
be loaded for all entry points so on the

00:14:12,030 --> 00:14:16,560
home page there be two script tags one

00:14:14,640 --> 00:14:19,050
for the common chunk and one for the

00:14:16,560 --> 00:14:21,330
home page chunk the problem is there's

00:14:19,050 --> 00:14:23,730
only two ways to deal with code that is

00:14:21,330 --> 00:14:25,710
needed for multiple entry points either

00:14:23,730 --> 00:14:28,320
it has to be put into the common chunk

00:14:25,710 --> 00:14:30,440
or the same code has to be duplicated

00:14:28,320 --> 00:14:33,270
for each entry point that needs it a

00:14:30,440 --> 00:14:34,530
huge improvement is to remove the

00:14:33,270 --> 00:14:37,260
assumption that there's a one-to-one

00:14:34,530 --> 00:14:39,390
relationship between an entry point into

00:14:37,260 --> 00:14:42,630
production chunk this can be done

00:14:39,390 --> 00:14:45,660
incrementally step 1 add square brackets

00:14:42,630 --> 00:14:48,690
step to move the common chunk into each

00:14:45,660 --> 00:14:51,300
entry point this is also where we remove

00:14:48,690 --> 00:14:53,460
the hard-coded two script tags and use a

00:14:51,300 --> 00:14:55,110
loop instead step 3

00:14:53,460 --> 00:14:57,329
time to cash in

00:14:55,110 --> 00:15:00,029
now we can update the buildconfig to

00:14:57,329 --> 00:15:02,190
create more granular chunks for webpack

00:15:00,029 --> 00:15:04,740
this could mean setting split chunks to

00:15:02,190 --> 00:15:06,990
all I have some good news at this point

00:15:04,740 --> 00:15:10,019
for users of frameworks like next jazz

00:15:06,990 --> 00:15:13,050
or Gatsby all of this may already be

00:15:10,019 --> 00:15:15,390
taken care of for you it may seem like a

00:15:13,050 --> 00:15:17,670
small change but when next Jes and

00:15:15,390 --> 00:15:19,740
Gatsby roll this out many larger

00:15:17,670 --> 00:15:23,339
websites saw that total JavaScript size

00:15:19,740 --> 00:15:24,870
dropped by 20 to 30 percent so far we

00:15:23,339 --> 00:15:28,620
haven't touched the application code

00:15:24,870 --> 00:15:30,630
itself but what if we did we can go one

00:15:28,620 --> 00:15:32,820
step further on the complexity scale and

00:15:30,630 --> 00:15:35,579
design our application for progressive

00:15:32,820 --> 00:15:37,740
fetching many applications already use

00:15:35,579 --> 00:15:39,990
route level code splitting which is a

00:15:37,740 --> 00:15:42,779
basic form of progressive fetching it

00:15:39,990 --> 00:15:44,790
groups similar pages together and builds

00:15:42,779 --> 00:15:47,760
a special entry point to be used when

00:15:44,790 --> 00:15:50,459
loading that kind of page this works

00:15:47,760 --> 00:15:53,610
well as long as all pages of the type

00:15:50,459 --> 00:15:55,680
are very similar but when the pages are

00:15:53,610 --> 00:15:58,440
assemble dynamically using a variety of

00:15:55,680 --> 00:16:00,570
components it isn't quite optimal

00:15:58,440 --> 00:16:03,180
anymore maybe there's a form that is

00:16:00,570 --> 00:16:05,640
only visible to Lockton users maybe

00:16:03,180 --> 00:16:07,620
there's an optional video player maybe

00:16:05,640 --> 00:16:10,350
the page has a common section that's

00:16:07,620 --> 00:16:12,660
below the fold progressive fetching

00:16:10,350 --> 00:16:14,670
means designing our page in a way that

00:16:12,660 --> 00:16:17,010
loads the code we need as early as

00:16:14,670 --> 00:16:20,070
possible but only the code we actually

00:16:17,010 --> 00:16:22,050
need in this case we may want the

00:16:20,070 --> 00:16:25,140
initial page to reference the form code

00:16:22,050 --> 00:16:26,699
but only if the user is locked in and we

00:16:25,140 --> 00:16:28,500
don't want to load the code for the

00:16:26,699 --> 00:16:30,750
comment section until we run out of

00:16:28,500 --> 00:16:33,329
other things to load or until the user

00:16:30,750 --> 00:16:35,399
actively Scrolls down doing this

00:16:33,329 --> 00:16:37,290
requires actively designing the

00:16:35,399 --> 00:16:39,350
application to allow for this kind of

00:16:37,290 --> 00:16:42,000
fine-grained control of the load owner

00:16:39,350 --> 00:16:44,610
adding dynamic import calls is a start

00:16:42,000 --> 00:16:47,160
but to prevent waterfall behavior and

00:16:44,610 --> 00:16:49,560
unnecessary delays it's likely not

00:16:47,160 --> 00:16:52,170
sufficient without that kind of

00:16:49,560 --> 00:16:54,480
architectural change will quickly run

00:16:52,170 --> 00:16:57,089
out of meaningful chunks to create but

00:16:54,480 --> 00:16:59,160
let's say we did all that we have all

00:16:57,089 --> 00:17:02,250
these small chunks in our application

00:16:59,160 --> 00:17:04,589
can leverage them effectively if we stop

00:17:02,250 --> 00:17:07,589
here downloading the resources for our

00:17:04,589 --> 00:17:08,689
website may be highly inefficient unless

00:17:07,589 --> 00:17:10,850
we get very lucky

00:17:08,689 --> 00:17:13,069
caching and also ignore first-time

00:17:10,850 --> 00:17:16,730
visitors we need to deal with a download

00:17:13,069 --> 00:17:18,769
site somehow we touch the build we touch

00:17:16,730 --> 00:17:20,990
the application code time to take a

00:17:18,769 --> 00:17:23,809
closer look at how we are serving chunks

00:17:20,990 --> 00:17:26,029
the simplest solution is that we serve

00:17:23,809 --> 00:17:29,029
each chunk as a static file from a CDN

00:17:26,029 --> 00:17:32,000
there's one script tag per chunk one

00:17:29,029 --> 00:17:34,750
HTTP request per trunk and one HTTP

00:17:32,000 --> 00:17:37,190
response per chunk as we covered before

00:17:34,750 --> 00:17:39,379
transferring each of these small files

00:17:37,190 --> 00:17:42,169
on its own isn't the most efficient way

00:17:39,379 --> 00:17:44,929
to download the contents enter dynamic

00:17:42,169 --> 00:17:47,240
bundling in its most basic form the idea

00:17:44,929 --> 00:17:49,820
is quite simple instead of serving each

00:17:47,240 --> 00:17:51,500
file individually there's one HTTP

00:17:49,820 --> 00:17:53,809
endpoint that accepts the IDS of

00:17:51,500 --> 00:17:56,019
multiple chunks and all of the chunks

00:17:53,809 --> 00:17:58,759
are then sent back in one response

00:17:56,019 --> 00:18:01,129
Congrats we just reinvented the big

00:17:58,759 --> 00:18:03,740
bundle we started with but not quite

00:18:01,129 --> 00:18:06,049
since the bundled response only contains

00:18:03,740 --> 00:18:08,210
the chunks the client asked for we are

00:18:06,049 --> 00:18:10,970
not over fetching code we are doing well

00:18:08,210 --> 00:18:12,169
on the execution side and with a way we

00:18:10,970 --> 00:18:14,059
are combining the chunks

00:18:12,169 --> 00:18:16,789
it's about as efficient to download as

00:18:14,059 --> 00:18:19,549
we can make it but we did sacrifice our

00:18:16,789 --> 00:18:22,340
cache hit rate one way to make up for it

00:18:19,549 --> 00:18:24,679
is to use a serviceworker as long as the

00:18:22,340 --> 00:18:27,080
serviceworker understands how this HTTP

00:18:24,679 --> 00:18:29,299
endpoint works it can compare the list

00:18:27,080 --> 00:18:31,730
of the chunk IDs in the request against

00:18:29,299 --> 00:18:35,090
the cache and then only request the

00:18:31,730 --> 00:18:36,320
chunks that aren't cached yet and once

00:18:35,090 --> 00:18:38,419
it gets the response back from the

00:18:36,320 --> 00:18:40,399
server it can extract the chunk contents

00:18:38,419 --> 00:18:42,679
and cache them individually in the

00:18:40,399 --> 00:18:44,840
future we may also be able to use web

00:18:42,679 --> 00:18:46,669
bundles for this purpose with that in

00:18:44,840 --> 00:18:48,590
place we have a solution that runs

00:18:46,669 --> 00:18:50,629
exactly the code that is absolutely

00:18:48,590 --> 00:18:53,299
necessary downloads what it needs

00:18:50,629 --> 00:18:56,480
efficiently and can achieve a high cache

00:18:53,299 --> 00:18:59,629
hit rate and that may be the minimum

00:18:56,480 --> 00:19:01,850
viable chunk thank you for watching I

00:18:59,629 --> 00:19:04,399
hope you enjoyed this exploration of

00:19:01,850 --> 00:19:06,289
taking code splitting to the extreme as

00:19:04,399 --> 00:19:08,870
promised here is the link to the guide

00:19:06,289 --> 00:19:10,700
on setting up granular chunks and if I

00:19:08,870 --> 00:19:12,710
made you at all curious about dynamic

00:19:10,700 --> 00:19:14,570
bundling the folks from Netflix gave

00:19:12,710 --> 00:19:16,909
some great talks and how they use

00:19:14,570 --> 00:19:19,490
dynamic bundling to run a be experiments

00:19:16,909 --> 00:19:22,520
at scale also my Twitter handle again

00:19:19,490 --> 00:19:24,680
just in case if you want to chat about

00:19:22,520 --> 00:19:26,540
Jia's modules or novel ways to bundle

00:19:24,680 --> 00:19:27,200
web apps that might be the best way to

00:19:26,540 --> 00:19:29,950
reach me

00:19:27,200 --> 00:19:29,950

YouTube URL: https://www.youtube.com/watch?v=ImjzA7EMI6I


