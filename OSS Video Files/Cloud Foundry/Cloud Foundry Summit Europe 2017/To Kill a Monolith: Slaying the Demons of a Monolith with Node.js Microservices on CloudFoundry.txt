Title: To Kill a Monolith: Slaying the Demons of a Monolith with Node.js Microservices on CloudFoundry
Publication date: 2017-10-18
Playlist: Cloud Foundry Summit Europe 2017
Description: 
	To Kill a Monolith: Slaying the Demons of a Monolith with Node.js Microservices on CloudFoundry - Tony Erwin, IBM

The Bluemix UI (which runs on CloudFoundry) is the front-end to Bluemix, IBMâ€™s open cloud hosting platform. The original implementation as a single-page, monolithic Java web app brought with it many demons, such as poor performance, lack of scalability, inability to push small updates, and difficulty for other teams to contribute code. Over the last 2 years, the team has been on a mission to slay these demons by embracing cloud native principles and splitting the monolith into smaller Node.js microservices. The effort to migrate to a more modern and scalable architecture has paid large dividends, but has also left behind a few battle scars from wrestling with the added complexity cloud native can bring. The team had to tackle problems in a wide variety of areas, including: large-scale deployments, continuous integration, monitoring, problem determination, high availability, and security. Tony Erwin will discuss the advantages of microservice architectures, ways that Node.js has increased developer productivity, approaches to phasing microservices into a live product, and real-life lessons learned in the deployment and management of Node.js microservices across multiple CloudFoundry environments. His war stories will prepare you to wage your own battles against monoliths everywhere -- happy slaying!

About Tony Erwin
Tony Erwin is a Senior Software Engineer at IBM and currently the Lead Architect for the IBM Bluemix UI. He's been with IBM for 18 years and has extensive full-stack experience building UIs using a wide variety of technologies. Current interests include cloud, Node.js, microservices, reliability, and performance. In addition, he's a semi-regular blogger on Bluemix and CloudFoundry-related topics.
Captions: 
	00:00:00,329 --> 00:00:04,890
good morning I'm Tony Erwin I guess I

00:00:03,870 --> 00:00:06,930
was giving a little bit of an intro

00:00:04,890 --> 00:00:09,269
earlier but I'm going to I'm the lead

00:00:06,930 --> 00:00:10,920
architect for the bluemix UI and I'm

00:00:09,269 --> 00:00:15,330
going to talk about Archer teams journey

00:00:10,920 --> 00:00:19,740
from monolith to microservices during

00:00:15,330 --> 00:00:21,500
this half hour we'll talk a little bit

00:00:19,740 --> 00:00:25,019
about the origins of the bluemix you I

00:00:21,500 --> 00:00:27,410
will talk about some of the problems we

00:00:25,019 --> 00:00:29,939
had with our original monolithic

00:00:27,410 --> 00:00:32,969
implementation we'll talk about how

00:00:29,939 --> 00:00:36,660
microservices helped deal with some of

00:00:32,969 --> 00:00:40,170
these demons I guess and then some new

00:00:36,660 --> 00:00:41,489
problems that occurred with with our

00:00:40,170 --> 00:00:43,469
microservice architecture there's

00:00:41,489 --> 00:00:45,570
already some mention of added complexity

00:00:43,469 --> 00:00:50,010
and famous when you go to my cursor

00:00:45,570 --> 00:00:52,320
versus the bluemix UI serves as the

00:00:50,010 --> 00:00:55,050
front-end to bluemix which is ibm's open

00:00:52,320 --> 00:00:57,989
cloud offering which features cloud

00:00:55,050 --> 00:01:01,230
foundry as a big part of that that lets

00:00:57,989 --> 00:01:04,400
users create and manage pipe foundry

00:01:01,230 --> 00:01:08,400
resources containers virtual servers

00:01:04,400 --> 00:01:10,680
accounts billing usage etc it runs on

00:01:08,400 --> 00:01:13,500
top of the bluemix pass layer which is

00:01:10,680 --> 00:01:17,310
cloud foundry it started as a single

00:01:13,500 --> 00:01:20,580
page application if the attempt to

00:01:17,310 --> 00:01:23,759
provide a desktop like experience in the

00:01:20,580 --> 00:01:26,729
browser so it's loading all HTML in one

00:01:23,759 --> 00:01:30,840
page using javascript and manipulate the

00:01:26,729 --> 00:01:32,430
dom and all that that the stack was kind

00:01:30,840 --> 00:01:34,829
of the state of the art at least in IBM

00:01:32,430 --> 00:01:37,340
we were using the dojo framework on the

00:01:34,829 --> 00:01:40,290
front end so you know dojo front-end

00:01:37,340 --> 00:01:42,720
single Java server back in at least in

00:01:40,290 --> 00:01:45,079
IBM at the time you know three or four

00:01:42,720 --> 00:01:47,939
years ago was kind of the common stack

00:01:45,079 --> 00:01:49,500
but we kind of quickly figured out that

00:01:47,939 --> 00:01:54,210
it's not really where we wanted to go

00:01:49,500 --> 00:01:57,240
for the our cloud environment this is

00:01:54,210 --> 00:02:02,119
just you know a few random pages from

00:01:57,240 --> 00:02:02,119
the bluemix UI so it's a fairly big

00:02:02,450 --> 00:02:04,770
application with a lot of different

00:02:04,079 --> 00:02:06,110
pages

00:02:04,770 --> 00:02:09,950
[Music]

00:02:06,110 --> 00:02:11,840
and this is just a a very simple picture

00:02:09,950 --> 00:02:14,480
of of our original monolithic

00:02:11,840 --> 00:02:17,450
architecture basically at the top the

00:02:14,480 --> 00:02:19,940
bluemix you live which is but the client

00:02:17,450 --> 00:02:22,370
in this case which is the browser just

00:02:19,940 --> 00:02:24,200
some different components we had like

00:02:22,370 --> 00:02:26,420
the home page and the catalog and

00:02:24,200 --> 00:02:29,210
dashboard really just kind of showing

00:02:26,420 --> 00:02:31,400
all that logic was at least the UI logic

00:02:29,210 --> 00:02:34,130
was pretty much loaded onto the front

00:02:31,400 --> 00:02:38,060
end the back end running in Cloud

00:02:34,130 --> 00:02:42,260
Foundry was the single Java server and

00:02:38,060 --> 00:02:43,760
then we that the monolith the Java

00:02:42,260 --> 00:02:47,470
monolith would talk to the various back

00:02:43,760 --> 00:02:53,720
in the EPI is a cloud foundry of UA a

00:02:47,470 --> 00:02:56,000
building authentication etc so so this

00:02:53,720 --> 00:03:01,180
led to several problems one was

00:02:56,000 --> 00:03:03,260
performance there Doug does a very large

00:03:01,180 --> 00:03:06,220
JavaScript framework so it was kind of

00:03:03,260 --> 00:03:09,950
floating this heavyweight JavaScript

00:03:06,220 --> 00:03:11,420
kind of led to some bottlenecks since it

00:03:09,950 --> 00:03:13,549
was a single page application as well

00:03:11,420 --> 00:03:16,280
there was really no data we included

00:03:13,549 --> 00:03:21,200
from the server in the initial payload

00:03:16,280 --> 00:03:22,790
so it was all Ajax requests which you

00:03:21,200 --> 00:03:25,060
know just again kind of bogged things

00:03:22,790 --> 00:03:25,060
down

00:03:25,690 --> 00:03:29,180
there's also difficult to integrate code

00:03:27,950 --> 00:03:32,510
from other teams and this will be a

00:03:29,180 --> 00:03:35,330
theme as I get deeper into the to the

00:03:32,510 --> 00:03:37,340
top but we wanted to make a flexible

00:03:35,330 --> 00:03:39,620
framework because you know to IBM you

00:03:37,340 --> 00:03:42,260
know I've got my core team but there's

00:03:39,620 --> 00:03:44,840
you know like 20 other teams that ones

00:03:42,260 --> 00:03:48,950
who also kind of be part of this console

00:03:44,840 --> 00:03:52,220
framework and asking everyone to somehow

00:03:48,950 --> 00:03:53,989
write a dojo plugin to get into what was

00:03:52,220 --> 00:03:58,130
their mano that the gap really wasn't

00:03:53,989 --> 00:04:00,769
practical you know some of this you know

00:03:58,130 --> 00:04:03,799
if you dealt with micro services you

00:04:00,769 --> 00:04:05,780
already know but uh with a monolith you

00:04:03,799 --> 00:04:07,940
know when you have an update you have to

00:04:05,780 --> 00:04:09,170
push the whole thing as opposed to being

00:04:07,940 --> 00:04:13,519
able to push a smaller part of the

00:04:09,170 --> 00:04:16,250
system so that was an issue poor SEO so

00:04:13,519 --> 00:04:20,570
search engine optimization was pulled

00:04:16,250 --> 00:04:23,900
because as I mentioned the HTML payload

00:04:20,570 --> 00:04:28,100
really didn't include any searchable

00:04:23,900 --> 00:04:29,150
data and the last point there not know

00:04:28,100 --> 00:04:32,900
how many people in the room have ever

00:04:29,150 --> 00:04:34,640
used dojo but uh at the time we had some

00:04:32,900 --> 00:04:38,240
new hires come in and they had wanted

00:04:34,640 --> 00:04:39,410
nothing to do with it so rightfully so

00:04:38,240 --> 00:04:45,940
wanted to move to a little bit more

00:04:39,410 --> 00:04:48,590
modern lighter weight infrastructure so

00:04:45,940 --> 00:04:52,250
so we decided to go to my cursor verses

00:04:48,590 --> 00:04:54,440
and these are some of the advantages or

00:04:52,250 --> 00:04:55,700
things we thought would help us deal

00:04:54,440 --> 00:04:59,660
with some of the problems with our

00:04:55,700 --> 00:05:01,070
monolith you know what one issue we had

00:04:59,660 --> 00:05:03,830
is that we were a live production

00:05:01,070 --> 00:05:06,890
product we wanted to totally reaaargh

00:05:03,830 --> 00:05:08,780
detect it to microservices but obviously

00:05:06,890 --> 00:05:11,330
that takes time especially when you've

00:05:08,780 --> 00:05:15,830
got pressures to continue to that new

00:05:11,330 --> 00:05:17,330
function as well so we went down the

00:05:15,830 --> 00:05:19,190
path that we could slowly break this

00:05:17,330 --> 00:05:22,910
monolith down into Mike your services

00:05:19,190 --> 00:05:26,060
kind of you know continue down this path

00:05:22,910 --> 00:05:28,780
of a lighter weight stack but but

00:05:26,060 --> 00:05:31,100
keeping you have the core monolith

00:05:28,780 --> 00:05:36,020
monolithic aspect of the product alive

00:05:31,100 --> 00:05:37,640
as we broke things apart the we tried to

00:05:36,020 --> 00:05:41,810
go for smaller services that are

00:05:37,640 --> 00:05:46,820
optimized for speed and page size so we

00:05:41,810 --> 00:05:49,220
went with lighter UI frameworks you know

00:05:46,820 --> 00:05:51,860
and services that were focused on you

00:05:49,220 --> 00:05:56,240
know a smaller subset of things than the

00:05:51,860 --> 00:05:58,760
monolith as a whole micro services also

00:05:56,240 --> 00:06:00,320
help increase developer productivity

00:05:58,760 --> 00:06:01,700
there's less chance of breaking other

00:06:00,320 --> 00:06:06,860
parts of the product because you can

00:06:01,700 --> 00:06:09,530
deploy individual micro services loosely

00:06:06,860 --> 00:06:10,400
coupled services can't deploy at their

00:06:09,530 --> 00:06:12,770
own schedule

00:06:10,400 --> 00:06:14,000
so the so I kind of alluded to this

00:06:12,770 --> 00:06:17,330
before that we have all these other

00:06:14,000 --> 00:06:20,330
teams that want to plug in they don't

00:06:17,330 --> 00:06:24,640
want to wait for one big push they want

00:06:20,330 --> 00:06:24,640
to update as they have changes

00:06:25,030 --> 00:06:29,780
microservices have a

00:06:27,800 --> 00:06:31,400
this little bit fuzzy okay not really

00:06:29,780 --> 00:06:34,310
microservices that allowed us to improve

00:06:31,400 --> 00:06:36,889
our SEO but just as part of this reorder

00:06:34,310 --> 00:06:39,680
we you know we started doing more

00:06:36,889 --> 00:06:42,949
server-side templating including some

00:06:39,680 --> 00:06:45,699
more content in the page in individual

00:06:42,949 --> 00:06:50,569
pages rather than having one big

00:06:45,699 --> 00:06:52,370
monolithic single page app so this you

00:06:50,569 --> 00:06:57,370
know had more content than the Google

00:06:52,370 --> 00:07:00,129
and other search engines could crawl and

00:06:57,370 --> 00:07:03,979
I'll get into this a little bit deeper

00:07:00,129 --> 00:07:06,229
shortly as well but we wanted you know

00:07:03,979 --> 00:07:08,659
as the core team worked and we had other

00:07:06,229 --> 00:07:10,490
teams plugging in we wanted to make it

00:07:08,659 --> 00:07:13,129
look like it was all part of one product

00:07:10,490 --> 00:07:15,440
so we used some micro service

00:07:13,129 --> 00:07:19,539
composition so we could all share some

00:07:15,440 --> 00:07:25,389
common UI elements and things like that

00:07:19,539 --> 00:07:27,740
so this diagram basically shows our our

00:07:25,389 --> 00:07:30,080
micro service pattern our typical

00:07:27,740 --> 00:07:34,069
UI micro service is going to be

00:07:30,080 --> 00:07:37,190
implemented this way again we have the

00:07:34,069 --> 00:07:40,909
bluemix UI client at the top you know

00:07:37,190 --> 00:07:44,509
where all the HTML CSS JavaScript is you

00:07:40,909 --> 00:07:48,169
know the JavaScript maybe vanilla could

00:07:44,509 --> 00:07:50,779
be polymer react angular we've been kind

00:07:48,169 --> 00:07:57,139
of focusing on react more often than not

00:07:50,779 --> 00:07:59,389
within our product the I always forget

00:07:57,139 --> 00:08:02,750
to talk about the proxy piece of this

00:07:59,389 --> 00:08:04,669
the Prophet gray box there the prophecy

00:08:02,750 --> 00:08:07,250
is really what makes the micro service

00:08:04,669 --> 00:08:09,469
system come together because as a

00:08:07,250 --> 00:08:12,469
request for a particular path come in

00:08:09,469 --> 00:08:17,419
the proxy decides what Mike reservist to

00:08:12,469 --> 00:08:19,990
send the request to so this nodejs micro

00:08:17,419 --> 00:08:22,849
service in the middle of the green box

00:08:19,990 --> 00:08:24,199
might be the catalog our catalog micro

00:08:22,849 --> 00:08:26,750
service for example someone slash

00:08:24,199 --> 00:08:30,830
catalog comes in the request is

00:08:26,750 --> 00:08:33,199
forwarded on to this micro service so as

00:08:30,830 --> 00:08:36,349
I alluded to all of our new micro

00:08:33,199 --> 00:08:38,100
services are in no js' we're using dust

00:08:36,349 --> 00:08:43,890
js4 server side

00:08:38,100 --> 00:08:46,440
templating the UI microservice needs to

00:08:43,890 --> 00:08:49,860
call our common header micro service

00:08:46,440 --> 00:08:53,250
which this was alluded to before it

00:08:49,860 --> 00:08:55,470
provides an API to get the the header at

00:08:53,250 --> 00:08:59,940
the top of the page so that all pages

00:08:55,470 --> 00:09:02,880
can at least share that piece and these

00:08:59,940 --> 00:09:06,120
micro services may also call other API

00:09:02,880 --> 00:09:10,950
micro services or and certainly the

00:09:06,120 --> 00:09:15,360
various back-end API s we're also using

00:09:10,950 --> 00:09:17,820
the Redis for shared session storage so

00:09:15,360 --> 00:09:19,920
so you authenticate and then these UI

00:09:17,820 --> 00:09:25,650
micro services can grab tokens out of

00:09:19,920 --> 00:09:29,750
the session and this is a visual

00:09:25,650 --> 00:09:33,090
depiction of of how we compose the pages

00:09:29,750 --> 00:09:35,730
so the green box is just a micro service

00:09:33,090 --> 00:09:38,400
it does invoke common and you see the

00:09:35,730 --> 00:09:41,580
strip at the top is basically what we

00:09:38,400 --> 00:09:44,910
call the header so with the server-side

00:09:41,580 --> 00:09:49,050
templating the Micra service can take

00:09:44,910 --> 00:09:52,260
that HTML snippet put it into the its

00:09:49,050 --> 00:09:54,300
overall HTML payload and serve that and

00:09:52,260 --> 00:09:56,520
then you've got a header with user

00:09:54,300 --> 00:09:59,040
information and as well as whatever

00:09:56,520 --> 00:10:02,150
content the page wants to provide

00:09:59,040 --> 00:10:02,150
[Music]

00:10:03,220 --> 00:10:09,190
so this this whole process for us

00:10:07,420 --> 00:10:11,500
started a couple years ago really and

00:10:09,190 --> 00:10:13,470
where we feel like we're and I'll show

00:10:11,500 --> 00:10:18,220
more kind of the stages of our

00:10:13,470 --> 00:10:20,710
progression but we're pretty much where

00:10:18,220 --> 00:10:23,320
we want to be still not you know quite

00:10:20,710 --> 00:10:26,230
you never quite yet everything exactly

00:10:23,320 --> 00:10:28,900
the way you want it to be but uh so back

00:10:26,230 --> 00:10:31,540
in February of 2015 was the first

00:10:28,900 --> 00:10:34,090
release we had that had any microt

00:10:31,540 --> 00:10:35,980
services at all and as I mentioned

00:10:34,090 --> 00:10:39,010
before we wanted to start you know kind

00:10:35,980 --> 00:10:42,550
of slowly we started with home and

00:10:39,010 --> 00:10:45,760
solutions were kind of two smaller

00:10:42,550 --> 00:10:47,770
pieces of the monolith we thought well

00:10:45,760 --> 00:10:51,010
let's just make those micro services to

00:10:47,770 --> 00:10:52,960
start with so you can kind of see so

00:10:51,010 --> 00:10:55,240
those those Ernie boxes moved out at the

00:10:52,960 --> 00:10:59,560
top became micro services on the back

00:10:55,240 --> 00:11:03,040
end the java the bluemix UI server which

00:10:59,560 --> 00:11:05,050
is our job app still running there we've

00:11:03,040 --> 00:11:07,900
got the proxy which i mentioned which is

00:11:05,050 --> 00:11:10,180
routing requests to the various apps as

00:11:07,900 --> 00:11:16,030
needed it's all been all deployed to

00:11:10,180 --> 00:11:17,770
Cloud Foundry the this I was at a

00:11:16,030 --> 00:11:21,370
conference in Shanghai a couple weeks

00:11:17,770 --> 00:11:23,950
ago too and you know it that was more of

00:11:21,370 --> 00:11:25,720
an academic conference so folks are very

00:11:23,950 --> 00:11:29,680
interested in research around how you

00:11:25,720 --> 00:11:34,000
break a monolith down into maestra

00:11:29,680 --> 00:11:37,300
services and you know my view is this

00:11:34,000 --> 00:11:40,420
more of a black art than a science at

00:11:37,300 --> 00:11:43,210
this point we you know we started with a

00:11:40,420 --> 00:11:44,980
couple smaller components and slowly you

00:11:43,210 --> 00:11:48,070
know things that seemed to logically

00:11:44,980 --> 00:11:49,630
kind of go together you know but but

00:11:48,070 --> 00:11:51,930
some of the the academics of the

00:11:49,630 --> 00:11:55,360
conference were like well is there a

00:11:51,930 --> 00:11:57,730
could you assign a score to cure

00:11:55,360 --> 00:12:02,170
architecture and you have to rate how

00:11:57,730 --> 00:12:04,600
good it is no one had an answer to that

00:12:02,170 --> 00:12:06,520
at that conference I think that's a very

00:12:04,600 --> 00:12:08,860
difficult thing you know media is in the

00:12:06,520 --> 00:12:10,300
eye of the beholder I think and in some

00:12:08,860 --> 00:12:13,180
of these micro service

00:12:10,300 --> 00:12:14,830
downs so that you know as you know

00:12:13,180 --> 00:12:22,080
there's lots of different ways to slice

00:12:14,830 --> 00:12:25,540
and dice phase 2 was about a year later

00:12:22,080 --> 00:12:28,570
and you know I'd say 90% of our

00:12:25,540 --> 00:12:31,150
migration was done at that time the

00:12:28,570 --> 00:12:35,140
account stuff was still kind of mostly

00:12:31,150 --> 00:12:38,650
on the client side you see a lot more

00:12:35,140 --> 00:12:41,890
green boxes mess that UI logic move down

00:12:38,650 --> 00:12:43,900
into separate micro services our Java

00:12:41,890 --> 00:12:46,000
server is still there but it's doing

00:12:43,900 --> 00:12:48,970
less and less it's just by this point

00:12:46,000 --> 00:12:54,880
it's just serving some api's that we

00:12:48,970 --> 00:12:57,040
hadn't yet ported to node and our end

00:12:54,880 --> 00:12:59,380
goal is you know to get rid of the Java

00:12:57,040 --> 00:13:03,520
server we do technically still have it

00:12:59,380 --> 00:13:06,670
there we would like to you know just 14

00:13:03,520 --> 00:13:08,500
consistency to be all on nodejs so

00:13:06,670 --> 00:13:11,050
that's something we still want to get

00:13:08,500 --> 00:13:14,530
rid of but but we're essentially at this

00:13:11,050 --> 00:13:20,190
point now except for some remnants of

00:13:14,530 --> 00:13:20,190
the Java server laying around I

00:13:20,340 --> 00:13:27,850
mentioned via plugins and other teams

00:13:23,860 --> 00:13:29,380
wanting to be able to you know plugin be

00:13:27,850 --> 00:13:32,440
part of the console and deploy on their

00:13:29,380 --> 00:13:34,570
own schedule and that this diagram is

00:13:32,440 --> 00:13:36,940
intended to show that so we talked about

00:13:34,570 --> 00:13:40,080
how the proxy routes request to our

00:13:36,940 --> 00:13:44,800
individual micro services other teams

00:13:40,080 --> 00:13:50,170
here the yellow boxes on the I guess

00:13:44,800 --> 00:13:53,590
that's my left or whatever like so we

00:13:50,170 --> 00:13:59,110
have that like Watson IOT open whisk

00:13:53,590 --> 00:14:01,900
various components that other teams own

00:13:59,110 --> 00:14:04,710
you know it's like slash Watson would

00:14:01,900 --> 00:14:07,570
route all requests to the Watson

00:14:04,710 --> 00:14:09,700
endpoint that they've provided now that

00:14:07,570 --> 00:14:12,330
may be a microcircuits on its own right

00:14:09,700 --> 00:14:17,680
or maybe a proxy to other micro services

00:14:12,330 --> 00:14:20,470
we really don't care we've got about 25

00:14:17,680 --> 00:14:22,260
I think core mind your services or so

00:14:20,470 --> 00:14:24,120
and with all of our

00:14:22,260 --> 00:14:25,560
you know I think I I guess this lights

00:14:24,120 --> 00:14:28,650
us 15 teams I think we'd probably

00:14:25,560 --> 00:14:30,990
actually closer to 20 now teams that

00:14:28,650 --> 00:14:34,530
have plugged in within IBM to this

00:14:30,990 --> 00:14:36,960
infrastructure and you know they they

00:14:34,530 --> 00:14:38,850
all may have you know a handful of micro

00:14:36,960 --> 00:14:40,920
services so so you know it's a very

00:14:38,850 --> 00:14:44,460
loosely coupled system you know maybe a

00:14:40,920 --> 00:14:50,880
hundred micro services when you add up

00:14:44,460 --> 00:14:53,700
all the teams involved so when you move

00:14:50,880 --> 00:14:55,470
the micro services you know I guess the

00:14:53,700 --> 00:14:58,350
saying is there's no free lunch right so

00:14:55,470 --> 00:15:00,330
there's always you know you sometimes

00:14:58,350 --> 00:15:02,490
you trade one set of problems for it for

00:15:00,330 --> 00:15:05,910
another I mean it has been a good move

00:15:02,490 --> 00:15:10,260
for us but you know it does bring some

00:15:05,910 --> 00:15:12,900
added cost so there's more moving parts

00:15:10,260 --> 00:15:15,720
you know I mentioned we have 25 30 micro

00:15:12,900 --> 00:15:18,600
services plus all the plugins so there's

00:15:15,720 --> 00:15:20,750
more moving parts more complexity the

00:15:18,600 --> 00:15:23,070
build pipeline becomes all the more

00:15:20,750 --> 00:15:25,110
important you know to be able to

00:15:23,070 --> 00:15:29,430
orchestrate deploying that many micro

00:15:25,110 --> 00:15:31,410
services federated status monitoring I

00:15:29,430 --> 00:15:35,460
have another slide that will go into

00:15:31,410 --> 00:15:37,020
that in more detail but I think this was

00:15:35,460 --> 00:15:39,510
something we really underestimated when

00:15:37,020 --> 00:15:41,430
we started how important it is when you

00:15:39,510 --> 00:15:43,320
have micro services you know all these

00:15:41,430 --> 00:15:45,660
loosely couple things be able to monitor

00:15:43,320 --> 00:15:47,720
you know problem comes at 2 a.m.

00:15:45,660 --> 00:15:49,650
how do you figure out what went wrong

00:15:47,720 --> 00:15:52,740
you know or if you have a performance

00:15:49,650 --> 00:15:56,040
bottleneck how do you figure out what

00:15:52,740 --> 00:15:58,880
component is causing that issue so we've

00:15:56,040 --> 00:16:01,350
we've invested a fair amount into

00:15:58,880 --> 00:16:06,240
monitoring and we'll talk a little bit

00:16:01,350 --> 00:16:08,940
more about that briefly the granularity

00:16:06,240 --> 00:16:14,040
of micro services versus memory

00:16:08,940 --> 00:16:16,620
allocation so as I I mentioned there's

00:16:14,040 --> 00:16:19,140
more art than science I think when

00:16:16,620 --> 00:16:22,490
you're breaking down a monolith into

00:16:19,140 --> 00:16:25,370
micro services but when you're deploying

00:16:22,490 --> 00:16:27,900
you have one consideration though we

00:16:25,370 --> 00:16:29,730
I've heard people coined the term nano

00:16:27,900 --> 00:16:31,830
services we did not want to get to the

00:16:29,730 --> 00:16:34,080
point where we've got you know a

00:16:31,830 --> 00:16:36,530
thousand different micro services

00:16:34,080 --> 00:16:39,900
you know so we've got more than 25 to 30

00:16:36,530 --> 00:16:43,200
but if you look at like in Cloud Foundry

00:16:39,900 --> 00:16:46,680
as you know you have to allocate memory

00:16:43,200 --> 00:16:51,000
for instance up front so we did notice a

00:16:46,680 --> 00:16:53,670
significant increase in memory usage by

00:16:51,000 --> 00:16:56,580
doing this so so our java app our single

00:16:53,670 --> 00:16:58,290
job app was you know three instances of

00:16:56,580 --> 00:17:01,470
two gigabytes apiece so we were using

00:16:58,290 --> 00:17:05,970
roughly six gigabytes allocated to those

00:17:01,470 --> 00:17:08,520
java instances with our micro-service

00:17:05,970 --> 00:17:12,300
system you know this was some math I did

00:17:08,520 --> 00:17:16,050
when we had like 27 apps about 95

00:17:12,300 --> 00:17:19,380
instances even if those are you know 512

00:17:16,050 --> 00:17:22,500
to a gigabyte apiece you know that adds

00:17:19,380 --> 00:17:24,890
up to you know fifty five and a half

00:17:22,500 --> 00:17:32,190
gigabytes so that's you know far more

00:17:24,890 --> 00:17:35,040
memory than than the monolith took there

00:17:32,190 --> 00:17:37,830
were some issues just trying to we

00:17:35,040 --> 00:17:40,290
needed to keep that monolith running so

00:17:37,830 --> 00:17:41,970
we had some issues just you know trying

00:17:40,290 --> 00:17:44,760
to have some seamless navigation between

00:17:41,970 --> 00:17:50,550
the single page app and the individual

00:17:44,760 --> 00:17:51,900
pages blue/green deployments there's you

00:17:50,550 --> 00:17:52,560
know doing a Bluegreen deployment in

00:17:51,900 --> 00:17:55,350
Cloud Foundry

00:17:52,560 --> 00:17:59,400
is easy you know with one app when you

00:17:55,350 --> 00:18:01,140
have 30 what do you do we ended up doing

00:17:59,400 --> 00:18:04,020
a Bluegreen deployment at the proxy

00:18:01,140 --> 00:18:06,810
layer so we deploy you know one set of

00:18:04,020 --> 00:18:10,640
30 micro services and another set and we

00:18:06,810 --> 00:18:10,640
would do blue green at the proxy layer

00:18:10,700 --> 00:18:18,090
promoting uniformity and consistency

00:18:13,530 --> 00:18:20,100
that this is you know if something keeps

00:18:18,090 --> 00:18:22,890
me up at night sometimes this is it at

00:18:20,100 --> 00:18:24,570
IBM we want you know these individual

00:18:22,890 --> 00:18:26,220
teams to be able to plug in and have

00:18:24,570 --> 00:18:29,790
freedom to deploy your own schedules and

00:18:26,220 --> 00:18:32,280
everything but if you want to try to I

00:18:29,790 --> 00:18:35,310
have a product with a consistent UI

00:18:32,280 --> 00:18:37,740
experience you know what what sort of

00:18:35,310 --> 00:18:39,920
policing do you put in place and quality

00:18:37,740 --> 00:18:41,539
standards when you've got other teams

00:18:39,920 --> 00:18:43,729
plugging and I

00:18:41,539 --> 00:18:46,100
not sure we've totally nailed that one

00:18:43,729 --> 00:18:50,529
down yet but that is a concern in our

00:18:46,100 --> 00:18:55,580
case and geo load balancing and failover

00:18:50,529 --> 00:18:57,590
not really required to do micro services

00:18:55,580 --> 00:18:59,899
but you know we have invested all the

00:18:57,590 --> 00:19:03,049
time and I have another slide dedicated

00:18:59,899 --> 00:19:04,940
to this shortly but we you know invested

00:19:03,049 --> 00:19:07,639
all the time and trying to get a che and

00:19:04,940 --> 00:19:09,440
resiliency for our micro service system

00:19:07,639 --> 00:19:11,359
but you know then if you're running in

00:19:09,440 --> 00:19:14,149
just one data center that data center

00:19:11,359 --> 00:19:17,090
goes down there's not much you can do so

00:19:14,149 --> 00:19:18,590
so we did undertake some efforts to be

00:19:17,090 --> 00:19:22,450
able to load balance between different

00:19:18,590 --> 00:19:22,450
Cloud Foundry deployments

00:19:23,090 --> 00:19:29,629
so I mentioned monitoring just a little

00:19:26,599 --> 00:19:31,009
bit more detail here lots of things can

00:19:29,629 --> 00:19:33,320
go wrong when you've got this too many

00:19:31,009 --> 00:19:35,479
micro services and you know they're all

00:19:33,320 --> 00:19:38,840
talking to various back-end API is that

00:19:35,479 --> 00:19:40,609
can have problems Cloud Foundry can have

00:19:38,840 --> 00:19:42,739
problems there can be networking issues

00:19:40,609 --> 00:19:47,029
you know how do you figure out what's

00:19:42,739 --> 00:19:50,779
wrong so we did build a monitoring

00:19:47,029 --> 00:19:52,220
system you know some needed metrics or

00:19:50,779 --> 00:19:55,220
metrics that have helped us along the

00:19:52,220 --> 00:19:58,639
way so so for all of our micro services

00:19:55,220 --> 00:20:01,309
we have all inbound and outbound HTTP

00:19:58,639 --> 00:20:05,599
requests so with response times and

00:20:01,309 --> 00:20:08,479
error codes and we've got we all we pop

00:20:05,599 --> 00:20:10,629
it into kevanna it's a little example

00:20:08,479 --> 00:20:13,129
graph on that chart at the bottom and

00:20:10,629 --> 00:20:15,229
you know when you start seeing various

00:20:13,129 --> 00:20:17,720
components returning a bunch of 500

00:20:15,229 --> 00:20:22,220
errors just as an example you know you

00:20:17,720 --> 00:20:24,200
might see a big bump in red and red

00:20:22,220 --> 00:20:25,970
would indicate 500 errors here there's

00:20:24,200 --> 00:20:28,849
not a lot of red here but if if you see

00:20:25,970 --> 00:20:30,950
a big red bump you know there's probably

00:20:28,849 --> 00:20:34,399
a problem

00:20:30,950 --> 00:20:37,549
we also cared about memory usage and CPU

00:20:34,399 --> 00:20:39,889
usage and uptime for every micro service

00:20:37,549 --> 00:20:42,049
so you know we keep track of app trashes

00:20:39,889 --> 00:20:44,659
all those kinds of things so if your app

00:20:42,049 --> 00:20:48,649
is crashing your quality of service is

00:20:44,659 --> 00:20:50,809
probably going to be impacted you know

00:20:48,649 --> 00:20:52,940
general health of ourselves and our

00:20:50,809 --> 00:20:56,720
dependencies as I

00:20:52,940 --> 00:21:00,500
for as an example we've used Redis for

00:20:56,720 --> 00:21:02,150
shared session storage so we do want to

00:21:00,500 --> 00:21:06,680
so one of the things we do is keep track

00:21:02,150 --> 00:21:07,850
of how healthy our Redis system is if

00:21:06,680 --> 00:21:11,120
that starts to have the issues that's

00:21:07,850 --> 00:21:14,180
something we need to resolve quickly and

00:21:11,120 --> 00:21:17,570
aside from kind of the real monitoring

00:21:14,180 --> 00:21:20,930
of real data we do also run some site

00:21:17,570 --> 00:21:23,330
speed IO we site speed iota to generate

00:21:20,930 --> 00:21:28,970
some synthetic page loads so we can look

00:21:23,330 --> 00:21:31,850
at front-end performance as well the

00:21:28,970 --> 00:21:35,480
this slide I alluded to the global

00:21:31,850 --> 00:21:37,880
console that we have before or that we

00:21:35,480 --> 00:21:40,670
just recently released and we used to

00:21:37,880 --> 00:21:44,540
have so we deploy in four we have four

00:21:40,670 --> 00:21:46,400
public cloud foundry deployments in at

00:21:44,540 --> 00:21:49,060
IBM as part of bluemix

00:21:46,400 --> 00:21:52,940
it's a Dallas London Sydney and

00:21:49,060 --> 00:21:55,400
Frankfurt we used to have individual

00:21:52,940 --> 00:21:59,090
URLs for each of those regions these are

00:21:55,400 --> 00:22:02,630
very separate deployments we with the

00:21:59,090 --> 00:22:07,250
global console as we called it we have

00:22:02,630 --> 00:22:09,320
one URL now console bluemix.net we do

00:22:07,250 --> 00:22:11,450
have a region selector so if you wanted

00:22:09,320 --> 00:22:14,360
to create pod foundry apps in Frankfurt

00:22:11,450 --> 00:22:16,880
or Sydney we still have a switcher for

00:22:14,360 --> 00:22:19,670
that but instead of doing a whole page

00:22:16,880 --> 00:22:24,770
reload with a newbie URL it's more of a

00:22:19,670 --> 00:22:26,570
filter in place so we use you know I

00:22:24,770 --> 00:22:29,450
haven't really talked about Akamai but

00:22:26,570 --> 00:22:31,790
but Akamai we use Akamai here in our

00:22:29,450 --> 00:22:33,440
picture but the important part for load

00:22:31,790 --> 00:22:36,440
balancing is that it does a DNS lookup

00:22:33,440 --> 00:22:38,360
against a dying load balancer which

00:22:36,440 --> 00:22:41,990
basically has all the IP addresses of

00:22:38,360 --> 00:22:47,090
our different table foundry deployments

00:22:41,990 --> 00:22:48,680
and so it's going to return the one the

00:22:47,090 --> 00:22:51,680
IP address for the deployment that is

00:22:48,680 --> 00:22:55,130
closest to you geographically so if I'm

00:22:51,680 --> 00:22:57,290
in Sydney hopefully I would get the UI

00:22:55,130 --> 00:22:59,420
serve from the Sydney data center rather

00:22:57,290 --> 00:23:01,539
than the u.s. data center so that that's

00:22:59,420 --> 00:23:03,429
an improvement in performance

00:23:01,539 --> 00:23:05,799
right there but the other thing is it

00:23:03,429 --> 00:23:10,059
looks for it returns to the nearest

00:23:05,799 --> 00:23:11,769
healthy data center so if sitting you

00:23:10,059 --> 00:23:13,869
know you're in Sydney you would normally

00:23:11,769 --> 00:23:16,029
go to the Sydney data center if that

00:23:13,869 --> 00:23:17,859
data center goes down you would be

00:23:16,029 --> 00:23:21,340
routed to the next closest one which may

00:23:17,859 --> 00:23:23,549
be you know Frankfurt say so you you

00:23:21,340 --> 00:23:26,619
don't notice any interruption in service

00:23:23,549 --> 00:23:32,889
and we can go figure out what's wrong in

00:23:26,619 --> 00:23:34,659
Austin Greg's not Austin Australia yeah

00:23:32,889 --> 00:23:36,879
and that's basically that so the odds of

00:23:34,659 --> 00:23:39,700
all of four regions being down at once

00:23:36,879 --> 00:23:44,080
are pretty rare compared to certainly

00:23:39,700 --> 00:23:48,849
two one one region being down and that

00:23:44,080 --> 00:23:54,070
kind of brings us to the end any I think

00:23:48,849 --> 00:23:56,369
we've got time for questions yeah yeah

00:23:54,070 --> 00:23:56,369
there's two

00:24:28,430 --> 00:24:33,560
that's a good question I don't know that

00:24:30,650 --> 00:24:35,720
we've been I think we'd probably have

00:24:33,560 --> 00:24:38,960
built up some tactical debt in terms of

00:24:35,720 --> 00:24:43,670
some dead code you know being in the

00:24:38,960 --> 00:24:46,670
java piece I think in some cases as we

00:24:43,670 --> 00:24:49,820
sort of ported things we were probably

00:24:46,670 --> 00:24:53,720
better about deleting that code than

00:24:49,820 --> 00:24:55,670
other times so this is going to be a you

00:24:53,720 --> 00:24:58,340
know we do have a goal as I mentioned to

00:24:55,670 --> 00:25:00,050
knock out that Java server eventually so

00:24:58,340 --> 00:25:02,510
I think we will have a little bit of a

00:25:00,050 --> 00:25:05,060
challenge just to you know we'll be able

00:25:02,510 --> 00:25:07,490
to see what what what API calls we make

00:25:05,060 --> 00:25:11,240
into it so we'll know you know what's

00:25:07,490 --> 00:25:13,160
still being used but measuring sort of

00:25:11,240 --> 00:25:14,600
according exercise there'll be pieces of

00:25:13,160 --> 00:25:16,310
Java code that we don't want to pour it

00:25:14,600 --> 00:25:17,750
at this point because they're not maybe

00:25:16,310 --> 00:25:21,110
they're already been ported or no longer

00:25:17,750 --> 00:25:27,550
used so I don't know if that answers

00:25:21,110 --> 00:25:27,550
your question yeah it's

00:25:34,650 --> 00:25:40,590
the proxy that you mentioned what does

00:25:37,020 --> 00:25:43,560
that exactly do over just routing to a

00:25:40,590 --> 00:25:45,360
certain URL in your internal really

00:25:43,560 --> 00:25:49,140
nothing else we tried to keep that layer

00:25:45,360 --> 00:25:51,510
very it's actually note JSI happen Cloud

00:25:49,140 --> 00:25:53,550
Foundry we probably will be moving to

00:25:51,510 --> 00:25:55,560
engine acts but there's really no

00:25:53,550 --> 00:25:58,890
intelligence other than looking at the

00:25:55,560 --> 00:26:01,530
the host or the path and rounding to the

00:25:58,890 --> 00:26:03,120
sort of right micro-service so so why am

00:26:01,530 --> 00:26:06,510
I don't you use the routing option in

00:26:03,120 --> 00:26:09,720
foundry well I think we started this

00:26:06,510 --> 00:26:16,320
before that was even an option so it's

00:26:09,720 --> 00:26:19,170
probably one of the big reasons yeah so

00:26:16,320 --> 00:26:20,100
I've heard arguments that you guys need

00:26:19,170 --> 00:26:22,950
to be monoliths

00:26:20,100 --> 00:26:25,050
because you want to guarantee a seamless

00:26:22,950 --> 00:26:28,980
user experience between the different UI

00:26:25,050 --> 00:26:31,860
components how did your UI design

00:26:28,980 --> 00:26:34,890
process change as you split up your UI

00:26:31,860 --> 00:26:37,500
into really separate micro-services I

00:26:34,890 --> 00:26:39,900
don't think are you from a user

00:26:37,500 --> 00:26:42,660
experience design perspective I don't

00:26:39,900 --> 00:26:45,090
think it changed a whole lot I mean we

00:26:42,660 --> 00:26:47,460
do have more times where you click on a

00:26:45,090 --> 00:26:49,680
button and you get a full page reload as

00:26:47,460 --> 00:26:53,040
opposed to just you know some some Dom

00:26:49,680 --> 00:26:56,370
updates occurring but I don't think that

00:26:53,040 --> 00:27:00,300
really impacted our design approach that

00:26:56,370 --> 00:27:02,670
much now it does you know there there

00:27:00,300 --> 00:27:07,740
are cases where you know the UI

00:27:02,670 --> 00:27:10,080
designers will I guess you know propose

00:27:07,740 --> 00:27:12,750
something that doesn't necessarily fit

00:27:10,080 --> 00:27:16,680
real well with our you know with just

00:27:12,750 --> 00:27:19,560
how our code is broken up so that makes

00:27:16,680 --> 00:27:23,160
me a challenge but but I guess I thought

00:27:19,560 --> 00:27:24,900
well you know let's let's not make it an

00:27:23,160 --> 00:27:26,880
architectural decision that we had made

00:27:24,900 --> 00:27:29,580
at one point in fact our user experience

00:27:26,880 --> 00:27:31,350
too much so if there's some Swizzle and

00:27:29,580 --> 00:27:32,580
we need to do or extension points or

00:27:31,350 --> 00:27:35,220
whatever to make some of those things

00:27:32,580 --> 00:27:37,370
happen then I then we need to be open to

00:27:35,220 --> 00:27:37,370
that

00:27:44,670 --> 00:27:50,630
[Music]

00:27:46,720 --> 00:27:54,020
human you mentioned that you do

00:27:50,630 --> 00:27:56,030
Bluegreen deployments via the proxy so

00:27:54,020 --> 00:27:58,220
you are deploying all of your micro

00:27:56,030 --> 00:27:59,440
services Bluegreen even if you only

00:27:58,220 --> 00:28:01,970
changed one right

00:27:59,440 --> 00:28:06,140
that's right that's very very astute

00:28:01,970 --> 00:28:09,050
observation so that is where we've taken

00:28:06,140 --> 00:28:12,650
some steps to improve that so we we do

00:28:09,050 --> 00:28:15,860
have the ability to swap in individual

00:28:12,650 --> 00:28:19,960
micro services but it's not as good as

00:28:15,860 --> 00:28:22,070
it could be yeah yeah so that's a yeah

00:28:19,960 --> 00:28:25,250
that's a shortcoming we have because

00:28:22,070 --> 00:28:27,860
yeah we I think we've gotten smarter

00:28:25,250 --> 00:28:29,320
about at least being able to update the

00:28:27,860 --> 00:28:32,210
proxy config

00:28:29,320 --> 00:28:33,830
deployment to point at a new new version

00:28:32,210 --> 00:28:35,510
of a micro service and then so we may

00:28:33,830 --> 00:28:37,820
still be doing a Bluegreen deployment at

00:28:35,510 --> 00:28:43,010
the proxy but we haven't actually

00:28:37,820 --> 00:28:45,710
deployed all new apps to do them how

00:28:43,010 --> 00:28:49,130
many times do you deploy how many times

00:28:45,710 --> 00:28:51,500
yeah we're yeah I wouldn't say we're

00:28:49,130 --> 00:28:54,080
yeah I know some people like to deploy

00:28:51,500 --> 00:28:58,550
multiple times a day we're more maybe a

00:28:54,080 --> 00:28:59,960
couple times a week typically I guess

00:28:58,550 --> 00:29:01,520
there's a few reasons for that one is

00:28:59,960 --> 00:29:04,490
that just when you're making UI updates

00:29:01,520 --> 00:29:05,990
you usually do need some you know we

00:29:04,490 --> 00:29:07,010
have automated tests and stuff but

00:29:05,990 --> 00:29:09,830
sometimes you still kind of need that

00:29:07,010 --> 00:29:11,750
visual inspection to make sure nothing

00:29:09,830 --> 00:29:13,310
looks too askew so there's there's some

00:29:11,750 --> 00:29:17,200
testing overhead and stuff when you're

00:29:13,310 --> 00:29:17,200
doing you eyes thank you

00:29:22,940 --> 00:29:27,379
the wrinkles way back there I can barely

00:29:24,950 --> 00:29:29,149
see see yep hi there

00:29:27,379 --> 00:29:30,710
so am obviously the individual teams

00:29:29,149 --> 00:29:32,720
will have responsibility for tests in

00:29:30,710 --> 00:29:34,190
their own micro-services but in terms of

00:29:32,720 --> 00:29:35,599
the product as a whole where's that

00:29:34,190 --> 00:29:38,269
responsibility lie and what are the

00:29:35,599 --> 00:29:40,609
challenges would you experienced I'm

00:29:38,269 --> 00:29:42,080
sorry I test and test terms of testing

00:29:40,609 --> 00:29:44,479
yeah in terms of testing the whole

00:29:42,080 --> 00:29:46,249
product as a whole and I mean individual

00:29:44,479 --> 00:29:48,529
teams will have responsibility for their

00:29:46,249 --> 00:29:50,659
own pieces but who owns the overall pace

00:29:48,529 --> 00:29:52,549
right yeah and that that's a real

00:29:50,659 --> 00:29:54,679
challenge I mean so so I mentioned that

00:29:52,549 --> 00:29:57,109
we have automated tests so each micro

00:29:54,679 --> 00:29:59,960
service owner is certainly responsible

00:29:57,109 --> 00:30:03,080
for having a nice automated set of unit

00:29:59,960 --> 00:30:05,090
tests it's it's a little bit more

00:30:03,080 --> 00:30:08,450
challenging when you then want to make

00:30:05,090 --> 00:30:11,570
tests in dan flows and we do have some

00:30:08,450 --> 00:30:13,220
automated testing around that you know

00:30:11,570 --> 00:30:15,649
testing the you know if you transition

00:30:13,220 --> 00:30:16,909
from one you are a page with you know

00:30:15,649 --> 00:30:18,859
serve from one micro service

00:30:16,909 --> 00:30:21,259
transitioning to another I mean we do

00:30:18,859 --> 00:30:22,789
have some tests around that but that's

00:30:21,259 --> 00:30:25,220
those are typically stored you know

00:30:22,789 --> 00:30:26,979
separately from the micro services and I

00:30:25,220 --> 00:30:32,289
think we still need to do a better job

00:30:26,979 --> 00:30:35,659
there we have a couple QA folks that

00:30:32,289 --> 00:30:40,389
would love it if we required a little

00:30:35,659 --> 00:30:40,389
bit less manual testing than we do today

00:30:41,950 --> 00:30:48,499
hi my question was you compared the Java

00:30:45,830 --> 00:30:51,200
memory footprint and the micro services

00:30:48,499 --> 00:30:53,450
footprint is that around the same

00:30:51,200 --> 00:30:55,429
functionality included in these two

00:30:53,450 --> 00:30:57,830
types or was there also functionality

00:30:55,429 --> 00:31:00,470
wise a difference now that functionality

00:30:57,830 --> 00:31:03,559
was I mean we probably added some new

00:31:00,470 --> 00:31:07,929
function but but by and large it was you

00:31:03,559 --> 00:31:07,929
know equivalent functionality okay

00:31:13,850 --> 00:31:16,690
you're getting a workout

00:31:17,630 --> 00:31:23,540
my question is you showed the different

00:31:19,970 --> 00:31:25,790
data centers of the installation how did

00:31:23,540 --> 00:31:28,370
you manage to synchronize the state

00:31:25,790 --> 00:31:31,010
between between the data in the data

00:31:28,370 --> 00:31:33,440
centers that that's a very good question

00:31:31,010 --> 00:31:38,210
so our UI code doesn't really store a

00:31:33,440 --> 00:31:40,730
lot of state the you know we really rely

00:31:38,210 --> 00:31:42,050
on back into API so it's just as example

00:31:40,730 --> 00:31:45,020
you know the UI will allow you to create

00:31:42,050 --> 00:31:48,560
a Cloud Foundry application that stage

00:31:45,020 --> 00:31:50,660
is maintained in the Cloud Foundry you

00:31:48,560 --> 00:31:54,020
know by the API controller right and all

00:31:50,660 --> 00:31:58,940
that's backend the the one thing we do

00:31:54,020 --> 00:32:00,590
store is like the the user token in the

00:31:58,940 --> 00:32:03,590
raddest session so if we do do a

00:32:00,590 --> 00:32:05,720
failover we do have to do a quick

00:32:03,590 --> 00:32:07,430
refresh we've got some cookies and

00:32:05,720 --> 00:32:09,890
things so we can do a quick refresh of

00:32:07,430 --> 00:32:13,550
the token and we end up our register

00:32:09,890 --> 00:32:15,470
points or separate so okay so when you

00:32:13,550 --> 00:32:18,170
register read this it's use for that in

00:32:15,470 --> 00:32:20,150
the backend exactly so we so we don't

00:32:18,170 --> 00:32:22,430
necessarily copy everything from aratus

00:32:20,150 --> 00:32:23,900
here to arrest us there but but since we

00:32:22,430 --> 00:32:25,760
don't store very much in there to start

00:32:23,900 --> 00:32:27,500
with you know we just get the new token

00:32:25,760 --> 00:32:28,870
and put it in the Ravis when you're

00:32:27,500 --> 00:32:30,610
failover appears

00:32:28,870 --> 00:32:33,780
Thanks

00:32:30,610 --> 00:32:33,780
[Music]

00:32:37,360 --> 00:32:43,569
[Music]

00:32:40,529 --> 00:32:45,519
monolith yeah they tend to have an

00:32:43,569 --> 00:32:47,259
exciting internal structure as well

00:32:45,519 --> 00:32:49,719
right there might be some layering going

00:32:47,259 --> 00:32:52,359
on and stuff like that so in your case

00:32:49,719 --> 00:32:56,529
the decomposition that it just pulled

00:32:52,359 --> 00:32:58,659
into clean top-to-bottom slices or was

00:32:56,529 --> 00:33:01,209
there also some sort of downstream

00:32:58,659 --> 00:33:04,359
services happening and if so how did you

00:33:01,209 --> 00:33:07,719
how did you cope with that yeah it's a

00:33:04,359 --> 00:33:09,009
good question they I mean I think it you

00:33:07,719 --> 00:33:10,509
know because you know it shows the

00:33:09,009 --> 00:33:14,139
street shot earlier of the different

00:33:10,509 --> 00:33:16,599
kind of sections of our UI and typically

00:33:14,139 --> 00:33:17,949
the api's and things provided by her so

00:33:16,599 --> 00:33:19,959
our monolith didn't really provide a

00:33:17,949 --> 00:33:22,859
whole lot of UI it just it kind of

00:33:19,959 --> 00:33:25,689
served you know all the JavaScript HTML

00:33:22,859 --> 00:33:30,069
and you know we had to make back-end API

00:33:25,689 --> 00:33:32,349
calls so so the Java server ended up

00:33:30,069 --> 00:33:36,789
becoming just an API server now some of

00:33:32,349 --> 00:33:39,339
the API is tended to be kind of you know

00:33:36,789 --> 00:33:40,989
so an API for Cloud Foundry yeah that

00:33:39,339 --> 00:33:43,029
was doing some v founded manipulation

00:33:40,989 --> 00:33:46,539
like for creating apps was probably only

00:33:43,029 --> 00:33:48,609
used by our catalog nitrous service so

00:33:46,539 --> 00:33:52,269
we so we did sort of look at the various

00:33:48,609 --> 00:33:54,969
pieces of the UI catalog dashboard

00:33:52,269 --> 00:33:56,979
accounts and billing and and those were

00:33:54,969 --> 00:34:00,519
roughly you know some of the pieces in

00:33:56,979 --> 00:34:02,349
our in our monolithic code as well so I

00:34:00,519 --> 00:34:05,109
guess you know that that was somewhat

00:34:02,349 --> 00:34:07,539
natural um I can't say we went and

00:34:05,109 --> 00:34:10,809
looked at the you know the class

00:34:07,539 --> 00:34:15,159
hierarchy of our java app and and used

00:34:10,809 --> 00:34:16,629
that to sort of drive you know the Micra

00:34:15,159 --> 00:34:20,799
services we broke down that they were

00:34:16,629 --> 00:34:23,379
probably bigger components than then you

00:34:20,799 --> 00:34:26,710
know individual you know java classes

00:34:23,379 --> 00:34:29,849
and things like that I don't know if

00:34:26,710 --> 00:34:29,849
that answers the question but

00:34:31,830 --> 00:34:37,149
then thanks Tony

00:34:33,909 --> 00:34:39,879
couch are good questions and we ran out

00:34:37,149 --> 00:34:41,550
of chance okay we have to switch out all

00:34:39,879 --> 00:34:43,859
right thank you

00:34:41,550 --> 00:34:43,859

YouTube URL: https://www.youtube.com/watch?v=oAo1rB6tQRc


