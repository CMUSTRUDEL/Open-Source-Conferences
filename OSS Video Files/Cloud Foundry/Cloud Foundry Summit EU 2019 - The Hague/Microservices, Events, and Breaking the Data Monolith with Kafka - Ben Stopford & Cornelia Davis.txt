Title: Microservices, Events, and Breaking the Data Monolith with Kafka - Ben Stopford & Cornelia Davis
Publication date: 2019-09-13
Playlist: Cloud Foundry Summit EU 2019 - The Hague
Description: 
	Microservices, Events, and Breaking the Data Monolith with Kafka - Ben Stopford, Confluent & Cornelia Davis, Pivotal 

One of the trickiest problems with microservices is dealing with data as it becomes spread across many different bounded contexts. An event architecture and event-streaming platform like Kafka provide a respite to this problem. Event-first thinking has a plethora of other advantages too, pulling in concepts from event sourcing, stream processing, and domain-driven design. 
  In this talk, you will learn the following: Transform the data monolith to microservices. Manage bounded contexts for data fields that overlap  Use event architectures that apply streaming technologies like Kafka to address the challenges of distributed data 

For more info: https://www.cloudfoundry.org/
Captions: 
	00:00:00,539 --> 00:00:06,240
so thank you everyone for joining us

00:00:02,399 --> 00:00:10,170
this afternoon my name is Cornelio Davis

00:00:06,240 --> 00:00:11,759
I work for pivotal and I'll tell you a

00:00:10,170 --> 00:00:14,309
little bit more about myself in just a

00:00:11,759 --> 00:00:16,230
moment and I'm here with my industry

00:00:14,309 --> 00:00:17,730
colleague Ben Stopford who works for

00:00:16,230 --> 00:00:20,670
confluent and I'll let him introduce

00:00:17,730 --> 00:00:22,590
himself in just a moment as well to give

00:00:20,670 --> 00:00:24,029
you a little bit about my background

00:00:22,590 --> 00:00:26,070
I have been with pivitol since the

00:00:24,029 --> 00:00:28,740
pivotal spin-off I have been in the EMC

00:00:26,070 --> 00:00:30,240
family of companies now for 20 years and

00:00:28,740 --> 00:00:32,430
you might have heard that pivotal is

00:00:30,240 --> 00:00:35,250
getting purchased it looks like it's

00:00:32,430 --> 00:00:38,879
gonna get purchased by VMware so more of

00:00:35,250 --> 00:00:41,040
the Dell family so been there for a long

00:00:38,879 --> 00:00:44,280
time have been working in web

00:00:41,040 --> 00:00:46,500
architectures for 15 or more years I

00:00:44,280 --> 00:00:49,680
have been working in cloud native and

00:00:46,500 --> 00:00:51,210
cloud foundry in particular for longer

00:00:49,680 --> 00:00:53,280
than pivotal has been existent in

00:00:51,210 --> 00:00:54,750
existence I came from the EMC side of

00:00:53,280 --> 00:00:56,610
the house where I worked in the CTO

00:00:54,750 --> 00:00:58,649
office doing architecture and emerging

00:00:56,610 --> 00:01:01,680
tech and started working on Cloud

00:00:58,649 --> 00:01:04,140
Foundry back then the other thing is

00:01:01,680 --> 00:01:06,869
that I recently published a book the

00:01:04,140 --> 00:01:09,119
book finally published I wrote it took

00:01:06,869 --> 00:01:10,890
me three years to write it published at

00:01:09,119 --> 00:01:13,409
the end of May

00:01:10,890 --> 00:01:16,229
and so there's that and you might have

00:01:13,409 --> 00:01:18,509
noticed that I am wearing a t-shirt with

00:01:16,229 --> 00:01:21,270
the cover of my book Thank You Manning

00:01:18,509 --> 00:01:23,670
for the t-shirt and I will turn around

00:01:21,270 --> 00:01:26,880
there's a discount code on the slides

00:01:23,670 --> 00:01:31,229
that you'll find but there's also a 50%

00:01:26,880 --> 00:01:32,880
discount code off the t-shirt so you can

00:01:31,229 --> 00:01:34,350
come find me afterward I'm gonna wear my

00:01:32,880 --> 00:01:36,840
t-shirt for the next couple of days

00:01:34,350 --> 00:01:38,820
Manning really likes that so I will hand

00:01:36,840 --> 00:01:41,570
it over to Ben and he can introduce

00:01:38,820 --> 00:01:44,399
himself you've got the next slide there

00:01:41,570 --> 00:01:47,399
sure thanks Canadia and yes it my name

00:01:44,399 --> 00:01:49,229
is best of it I work it confluent anyone

00:01:47,399 --> 00:01:53,880
heard of confluent it doesn't make

00:01:49,229 --> 00:01:55,799
wiki's as good so yeah we're the company

00:01:53,880 --> 00:01:58,110
if you haven't heard of it we we sit

00:01:55,799 --> 00:02:00,479
behind a patchy Kafka which is a stream

00:01:58,110 --> 00:02:03,689
processing framework event streaming

00:02:00,479 --> 00:02:05,969
platform yes I yeah I working office of

00:02:03,689 --> 00:02:07,079
the CTO I used to work on Kafka the

00:02:05,969 --> 00:02:09,300
messaging system I use to work on

00:02:07,079 --> 00:02:10,920
caprica wrote the latest version of the

00:02:09,300 --> 00:02:13,290
replication protocol a few a few other

00:02:10,920 --> 00:02:15,150
things and watching a bunch of other

00:02:13,290 --> 00:02:17,550
companies mostly in Europe thought works

00:02:15,150 --> 00:02:22,200
a few enterprise companies in one year

00:02:17,550 --> 00:02:24,599
Lucy's looking at data I'll take that

00:02:22,200 --> 00:02:28,200
you keep that cuz I have the love

00:02:24,599 --> 00:02:30,000
lavalier okay so um oh and this is the

00:02:28,200 --> 00:02:33,569
book of course that Ben has written as

00:02:30,000 --> 00:02:35,550
well so um brought the the the picture

00:02:33,569 --> 00:02:38,430
up there so where we're gonna go today

00:02:35,550 --> 00:02:39,780
in the next 25 minutes or so is we're

00:02:38,430 --> 00:02:41,790
gonna talk a little bit about the

00:02:39,780 --> 00:02:43,560
goodness of micro services we'll also

00:02:41,790 --> 00:02:46,379
talk about some of the challenges

00:02:43,560 --> 00:02:48,000
because those challenges set the stage

00:02:46,379 --> 00:02:50,580
for what we're going to talk about here

00:02:48,000 --> 00:02:52,080
with Kafka today so it's when we start

00:02:50,580 --> 00:02:54,480
to look at those challenges that we can

00:02:52,080 --> 00:02:56,790
really understand the value that Kafka

00:02:54,480 --> 00:02:59,810
can bring to the micro services based

00:02:56,790 --> 00:03:03,659
applications that you all know and love

00:02:59,810 --> 00:03:05,849
and are deploying on onto Cloud Foundry

00:03:03,659 --> 00:03:07,800
and that's really where that how event

00:03:05,849 --> 00:03:10,140
driven approaches help and because we're

00:03:07,800 --> 00:03:13,709
here at the Cloud Foundry summit it's

00:03:10,140 --> 00:03:15,060
also super relevant to you on okay given

00:03:13,709 --> 00:03:16,500
all of those patterns

00:03:15,060 --> 00:03:18,720
we're going to talk about these things

00:03:16,500 --> 00:03:21,720
more in a kind of pattern oriented way

00:03:18,720 --> 00:03:25,019
then how can you get your hands on this

00:03:21,720 --> 00:03:28,830
stuff to actually start using it in your

00:03:25,019 --> 00:03:30,989
Cloud Foundry based environments so the

00:03:28,830 --> 00:03:33,209
first thing that I'll start with is I am

00:03:30,989 --> 00:03:35,220
NOT going to belabor this point we all

00:03:33,209 --> 00:03:37,349
know that micro services are good it's

00:03:35,220 --> 00:03:39,540
about loose coupling loosely coupling

00:03:37,349 --> 00:03:42,989
teams loosely coupling pieces of

00:03:39,540 --> 00:03:44,849
software all of those things but we also

00:03:42,989 --> 00:03:47,220
know that when we start to break apart

00:03:44,849 --> 00:03:49,680
what used to be monoliths into these

00:03:47,220 --> 00:03:52,260
micro services now we have what I in

00:03:49,680 --> 00:03:55,349
what I call in the book cloud native

00:03:52,260 --> 00:03:57,629
architectures are highly distributed and

00:03:55,349 --> 00:03:58,739
constantly changing so some those are

00:03:57,629 --> 00:04:00,930
some of the things that we'll deal with

00:03:58,739 --> 00:04:03,810
so as soon as we have this highly

00:04:00,930 --> 00:04:06,000
distributed environment we inherit a

00:04:03,810 --> 00:04:08,189
whole bunch of other problems that

00:04:06,000 --> 00:04:11,220
didn't exist when we ran things as

00:04:08,189 --> 00:04:14,580
monoliths and this is one of the more

00:04:11,220 --> 00:04:17,880
famous you know headline blog posts here

00:04:14,580 --> 00:04:20,549
that say okay when you take on those

00:04:17,880 --> 00:04:23,280
micro services you take on all of these

00:04:20,549 --> 00:04:25,410
other responsibilities and you need to

00:04:23,280 --> 00:04:27,150
be you know so tall to ride the ride

00:04:25,410 --> 00:04:30,960
and so you need to deal with some of

00:04:27,150 --> 00:04:33,450
those things so for example what we have

00:04:30,960 --> 00:04:36,120
here is not my slide it's a picture from

00:04:33,450 --> 00:04:39,210
a presentation that has been done by

00:04:36,120 --> 00:04:41,360
scott mansfield from netflix and what we

00:04:39,210 --> 00:04:44,760
have here on the left hand side is

00:04:41,360 --> 00:04:47,730
homepage request comes in and what you

00:04:44,760 --> 00:04:50,610
see is the cascading requests that go

00:04:47,730 --> 00:04:53,220
down to downstream micro-services it

00:04:50,610 --> 00:04:57,870
goes down to hundreds of micro-services

00:04:53,220 --> 00:05:00,270
in that entire tree now let's assume for

00:04:57,870 --> 00:05:03,450
a moment that each one of the nodes each

00:05:00,270 --> 00:05:05,880
one of the microservices has about five

00:05:03,450 --> 00:05:10,170
nines of availability that is it's

00:05:05,880 --> 00:05:13,380
available 99.999% of the time that's

00:05:10,170 --> 00:05:15,690
pretty good now I'm gonna make a super

00:05:13,380 --> 00:05:19,770
simplifying assumption and say let's

00:05:15,690 --> 00:05:25,350
also assume that the network is reliable

00:05:19,770 --> 00:05:26,420
so the network is always there yeah

00:05:25,350 --> 00:05:29,520
right

00:05:26,420 --> 00:05:31,680
well even with that simplifying

00:05:29,520 --> 00:05:34,260
assumption which we know is not the case

00:05:31,680 --> 00:05:36,450
by the time we get down to the home page

00:05:34,260 --> 00:05:37,290
request we've lost two nines of

00:05:36,450 --> 00:05:43,170
availability

00:05:37,290 --> 00:05:46,650
we've gone from 99.999 to 99.9 and that

00:05:43,170 --> 00:05:48,570
starts counting as real money so that's

00:05:46,650 --> 00:05:51,900
just an example of some of the problems

00:05:48,570 --> 00:05:55,140
that micro services bring in so how do

00:05:51,900 --> 00:05:57,300
we try to add a level of resilience to

00:05:55,140 --> 00:05:59,130
these micro service based architectures

00:05:57,300 --> 00:06:01,200
well that's what I wrote the book about

00:05:59,130 --> 00:06:02,700
that's what cloud cloud native patterns

00:06:01,200 --> 00:06:06,410
is about is all of these different

00:06:02,700 --> 00:06:10,700
patterns that we put in place to try to

00:06:06,410 --> 00:06:13,710
take you know to account for and and

00:06:10,700 --> 00:06:17,250
adapt to these things like network

00:06:13,710 --> 00:06:20,160
outages so for example retries is one

00:06:17,250 --> 00:06:22,410
when you are browsing the web as a human

00:06:20,160 --> 00:06:24,510
and you click on a link and the page

00:06:22,410 --> 00:06:27,870
doesn't render do you give up and go to

00:06:24,510 --> 00:06:30,240
a different page maybe I hear somebody

00:06:27,870 --> 00:06:33,330
say yep but most of the time you hit

00:06:30,240 --> 00:06:36,090
refresh first right you're doing a retry

00:06:33,330 --> 00:06:38,070
what we implement retries within the

00:06:36,090 --> 00:06:40,500
architecture as well so that if the

00:06:38,070 --> 00:06:42,810
client doesn't hear back we're gonna do

00:06:40,500 --> 00:06:44,160
a retry but then we have to deal with

00:06:42,810 --> 00:06:47,490
things like timeouts

00:06:44,160 --> 00:06:49,350
how long do I wait how impatient am I as

00:06:47,490 --> 00:06:51,600
a client before I hit the retry button

00:06:49,350 --> 00:06:54,450
and there's all sorts of things

00:06:51,600 --> 00:06:57,210
now take that same picture and add a

00:06:54,450 --> 00:06:59,910
level of scale and now we've got

00:06:57,210 --> 00:07:02,970
multiple clients and they're all doing

00:06:59,910 --> 00:07:05,100
retries which end up with down at the

00:07:02,970 --> 00:07:08,460
service end is you could end up with a

00:07:05,100 --> 00:07:11,400
retry storm and in fact the force first

00:07:08,460 --> 00:07:14,400
four words in my book are it's not

00:07:11,400 --> 00:07:16,710
Amazon's fault and I go on and talk

00:07:14,400 --> 00:07:19,740
about an Amazon outage that they had

00:07:16,710 --> 00:07:23,100
that essentially was a retry storm in an

00:07:19,740 --> 00:07:26,040
inadvertent retry storm so we do things

00:07:23,100 --> 00:07:27,960
like we add circuit breakers so that the

00:07:26,040 --> 00:07:31,740
service itself doesn't get overloaded

00:07:27,960 --> 00:07:35,490
with retry storms another pattern that

00:07:31,740 --> 00:07:37,830
we use to adapt to this the these

00:07:35,490 --> 00:07:41,100
challenges with distributed systems as

00:07:37,830 --> 00:07:43,260
we stick caches in place so when I make

00:07:41,100 --> 00:07:45,330
a downstream request when I do get a

00:07:43,260 --> 00:07:48,660
successful response I'm gonna save that

00:07:45,330 --> 00:07:51,120
result just in case the next time I ask

00:07:48,660 --> 00:07:54,270
I don't get back a response maybe I can

00:07:51,120 --> 00:07:57,020
use that cache data instead well as

00:07:54,270 --> 00:07:59,880
usual you inherit some challenges Oh

00:07:57,020 --> 00:08:02,100
didn't talk about those as usual you

00:07:59,880 --> 00:08:05,910
inherit some challenges which are things

00:08:02,100 --> 00:08:08,420
like how fresh is the cache how do I

00:08:05,910 --> 00:08:11,700
know when the cache needs to be updated

00:08:08,420 --> 00:08:14,700
so those are a set of things but there's

00:08:11,700 --> 00:08:16,770
actually even more when it comes to that

00:08:14,700 --> 00:08:19,080
so what we did when we went from

00:08:16,770 --> 00:08:23,690
monoliths to micro services is we have

00:08:19,080 --> 00:08:23,690
all these loosely coupled pieces right

00:08:24,110 --> 00:08:29,670
not so much because a lot of times we

00:08:28,320 --> 00:08:31,410
have all these loosely coupled

00:08:29,670 --> 00:08:33,930
components that are all tied to the same

00:08:31,410 --> 00:08:37,680
monolithic database so it's just an

00:08:33,930 --> 00:08:39,840
illusion of loose coupling so the way

00:08:37,680 --> 00:08:42,000
that we've started to talk about this in

00:08:39,840 --> 00:08:44,190
the industry so we said okay well then

00:08:42,000 --> 00:08:48,420
each micro service gets its own storage

00:08:44,190 --> 00:08:49,980
it gets its own database but now you

00:08:48,420 --> 00:08:51,330
have a whole nother set of problems

00:08:49,980 --> 00:08:54,210
which are

00:08:51,330 --> 00:08:56,730
where's the source of truth how do i

00:08:54,210 --> 00:08:58,230
reconcile if that database so that in

00:08:56,730 --> 00:09:01,230
the upper right-hand corner has a

00:08:58,230 --> 00:09:03,180
customer record and a customer email how

00:09:01,230 --> 00:09:04,980
do i reconcile that with the customer

00:09:03,180 --> 00:09:07,620
email that's down here in the lower left

00:09:04,980 --> 00:09:11,190
hand corner so these are all of the

00:09:07,620 --> 00:09:13,620
different types of challenges and it

00:09:11,190 --> 00:09:17,810
turns out that there are some key

00:09:13,620 --> 00:09:21,390
patterns that come to the rescue of cash

00:09:17,810 --> 00:09:23,040
freshness of monolithic databases and

00:09:21,390 --> 00:09:25,410
that's where I'd like to hand things

00:09:23,040 --> 00:09:28,800
over to my colleague to talk about some

00:09:25,410 --> 00:09:31,470
of those patterns now by the way when we

00:09:28,800 --> 00:09:34,650
talked about that Netflix case we

00:09:31,470 --> 00:09:37,500
assumed something most micro-service

00:09:34,650 --> 00:09:40,770
architectures assume a request response

00:09:37,500 --> 00:09:43,620
style that is a request comes in to a

00:09:40,770 --> 00:09:46,590
root of a whole bunch of cascading

00:09:43,620 --> 00:09:49,260
requests going down and then we get back

00:09:46,590 --> 00:09:52,860
those responses and return the response

00:09:49,260 --> 00:09:55,410
to the user what I'm going to suggest to

00:09:52,860 --> 00:09:57,450
you is that you need to start thinking

00:09:55,410 --> 00:10:00,060
about going instead of from the root out

00:09:57,450 --> 00:10:04,710
to leaves think about going from the

00:10:00,060 --> 00:10:06,780
leaves to the root hmm that's kind of

00:10:04,710 --> 00:10:12,060
different and that's what my colleague

00:10:06,780 --> 00:10:15,690
is going to talk about thank you I could

00:10:12,060 --> 00:10:18,500
have been embarrassing yes I really like

00:10:15,690 --> 00:10:20,760
this this analogy which it Cornelia uses

00:10:18,500 --> 00:10:22,890
it's a really good one I really like

00:10:20,760 --> 00:10:25,860
this idea of like all your microscopes

00:10:22,890 --> 00:10:28,830
is a leaves and you can either sit at

00:10:25,860 --> 00:10:31,230
the Routan and like come on them or pull

00:10:28,830 --> 00:10:33,120
data from them or alternatively you can

00:10:31,230 --> 00:10:33,540
let the leaves like that data flow to

00:10:33,120 --> 00:10:35,310
you

00:10:33,540 --> 00:10:37,110
and that's what we're a venn streaming

00:10:35,310 --> 00:10:38,640
comes in and actually in most big

00:10:37,110 --> 00:10:41,120
systems I see you want to use both of

00:10:38,640 --> 00:10:43,530
these for different different use cases

00:10:41,120 --> 00:10:45,810
so we'll talk a little bit about some of

00:10:43,530 --> 00:10:47,070
those patterns but just to kind of get

00:10:45,810 --> 00:10:49,500
started let's look at the most familiar

00:10:47,070 --> 00:10:51,500
one which is the request response while

00:10:49,500 --> 00:10:54,000
you guys all be familiar with this so I

00:10:51,500 --> 00:10:56,190
can use this little example this is one

00:10:54,000 --> 00:10:58,710
of Cornelia's examples with this little

00:10:56,190 --> 00:11:02,010
abundant sunshine website this is just

00:10:58,710 --> 00:11:04,329
like a little social network and you've

00:11:02,010 --> 00:11:07,300
got like a user you have

00:11:04,329 --> 00:11:09,670
various different you can befriend other

00:11:07,300 --> 00:11:11,769
users you can like post things write

00:11:09,670 --> 00:11:13,420
little blog posts and when the web page

00:11:11,769 --> 00:11:15,429
comes up for the first time it has a

00:11:13,420 --> 00:11:17,019
nice little timeline so very much like

00:11:15,429 --> 00:11:18,339
Twitter or Facebook or one of these

00:11:17,019 --> 00:11:19,300
things you get like a timeline that

00:11:18,339 --> 00:11:20,730
tells you what other people are doing

00:11:19,300 --> 00:11:24,339
what other than other people are posting

00:11:20,730 --> 00:11:27,579
so if we build a system like that from a

00:11:24,339 --> 00:11:29,679
request response paradigm we cannot make

00:11:27,579 --> 00:11:31,089
a request to this homepage service and

00:11:29,679 --> 00:11:32,860
then that might call out to the friend

00:11:31,089 --> 00:11:34,420
service and look up who your friends are

00:11:32,860 --> 00:11:36,369
alright so we might have like some

00:11:34,420 --> 00:11:38,559
database tables for users and who

00:11:36,369 --> 00:11:42,910
follows you and then that return back

00:11:38,559 --> 00:11:44,649
like yeah who friends out and then you

00:11:42,910 --> 00:11:47,019
might make a request passing your

00:11:44,649 --> 00:11:48,939
friends to the blog post service this is

00:11:47,019 --> 00:11:51,100
gonna work out what all the most recent

00:11:48,939 --> 00:11:52,300
blog posts are from your various friends

00:11:51,100 --> 00:11:54,069
that can send that back to the home page

00:11:52,300 --> 00:11:55,360
service and then you can construct the

00:11:54,069 --> 00:11:57,879
timeline and display it back on the

00:11:55,360 --> 00:12:00,579
screen that's pretty intuitive right

00:11:57,879 --> 00:12:02,079
everyone should understand that and then

00:12:00,579 --> 00:12:03,429
as Cornelia said we would probably add a

00:12:02,079 --> 00:12:04,540
bit of caching right because we don't

00:12:03,429 --> 00:12:07,929
want to do these requests all the time

00:12:04,540 --> 00:12:09,249
people tend to like ef5 a lot or keep

00:12:07,929 --> 00:12:10,779
refreshing there at their home page so

00:12:09,249 --> 00:12:12,249
we had a bit of caching in to do that

00:12:10,779 --> 00:12:13,749
and there are some problems associated

00:12:12,249 --> 00:12:18,129
that with that which we talked about

00:12:13,749 --> 00:12:20,079
earlier Oh Cornelia did so let's try

00:12:18,129 --> 00:12:21,009
looking at the Avenger front approach so

00:12:20,079 --> 00:12:21,970
with the event driven approach you

00:12:21,009 --> 00:12:23,470
actually need another piece of

00:12:21,970 --> 00:12:24,490
infrastructure you need something like

00:12:23,470 --> 00:12:25,809
half code it doesnäôt you have to be

00:12:24,490 --> 00:12:27,699
careful it could be any message broke

00:12:25,809 --> 00:12:30,910
upper calf get has some quite useful

00:12:27,699 --> 00:12:32,259
properties as it can support like very

00:12:30,910 --> 00:12:34,869
high scale so you can actually run like

00:12:32,259 --> 00:12:36,549
a massive installations with hundreds of

00:12:34,869 --> 00:12:38,799
machines doing very high throughput use

00:12:36,549 --> 00:12:40,329
cases like you're solving data from

00:12:38,799 --> 00:12:41,709
mobile phones and things like that or

00:12:40,329 --> 00:12:44,290
you can use it for like a very small use

00:12:41,709 --> 00:12:45,999
cases it can store data which is a she

00:12:44,290 --> 00:12:47,980
very unusual and it's actually like a

00:12:45,999 --> 00:12:50,110
storage system as well as a messaging

00:12:47,980 --> 00:12:51,910
system so there are clusters out there

00:12:50,110 --> 00:12:53,740
with hundreds of terabytes of data in a

00:12:51,910 --> 00:12:56,110
single topic so very different to the

00:12:53,740 --> 00:12:58,209
messaging systems or the sort of came

00:12:56,110 --> 00:13:00,579
before it and I had some other things

00:12:58,209 --> 00:13:02,410
like the ability to replay these

00:13:00,579 --> 00:13:04,059
messages and then advanced features like

00:13:02,410 --> 00:13:05,589
stream processing which will we're just

00:13:04,059 --> 00:13:07,540
going to touch on today but not too much

00:13:05,589 --> 00:13:10,869
so the core point here is that I can

00:13:07,540 --> 00:13:12,040
take a service and I can instead of

00:13:10,869 --> 00:13:13,720
calling out to another service I'm

00:13:12,040 --> 00:13:14,919
actually just gonna publish an event an

00:13:13,720 --> 00:13:17,649
event it's just something that happened

00:13:14,919 --> 00:13:19,720
so for example I might publish

00:13:17,649 --> 00:13:21,040
new blog post and that would be sent as

00:13:19,720 --> 00:13:23,079
a message to a topic of interest

00:13:21,040 --> 00:13:25,029
something you're interested in and

00:13:23,079 --> 00:13:26,800
somebody else can subscribe to somebody

00:13:25,029 --> 00:13:28,480
something like blog posts and another

00:13:26,800 --> 00:13:30,819
micro-service can literally just choose

00:13:28,480 --> 00:13:32,740
whether or not it wants to subscribe to

00:13:30,819 --> 00:13:35,230
that stream of events this is actually a

00:13:32,740 --> 00:13:36,699
bit like a female like publish/subscribe

00:13:35,230 --> 00:13:38,980
very like a so group email address

00:13:36,699 --> 00:13:40,300
publishing some into this like topic

00:13:38,980 --> 00:13:41,589
which is like a group email address

00:13:40,300 --> 00:13:42,819
different people can decide whether or

00:13:41,589 --> 00:13:45,220
not they wanna listen to that

00:13:42,819 --> 00:13:46,869
information or not but also the data

00:13:45,220 --> 00:13:49,899
stored and we'll come back to why that's

00:13:46,869 --> 00:13:52,779
important later so if we put that into

00:13:49,899 --> 00:13:54,369
our little example our friend service

00:13:52,779 --> 00:13:57,040
ensnares actually gonna start publishing

00:13:54,369 --> 00:13:58,149
events so every time you like add a new

00:13:57,040 --> 00:13:59,800
friend you're gonna get a new friend

00:13:58,149 --> 00:14:02,050
event that's gonna get published to the

00:13:59,800 --> 00:14:03,970
friendships topic likewise whenever you

00:14:02,050 --> 00:14:05,889
create a new blog post there's to me

00:14:03,970 --> 00:14:08,379
another event so we emitted by this

00:14:05,889 --> 00:14:11,110
service into Kafka on the blog post

00:14:08,379 --> 00:14:13,029
topic and different services can

00:14:11,110 --> 00:14:14,860
subscribe to these streams of events and

00:14:13,029 --> 00:14:18,309
get and find out about what's happening

00:14:14,860 --> 00:14:20,889
right now so what does this mean for our

00:14:18,309 --> 00:14:23,860
little example so we have this homepage

00:14:20,889 --> 00:14:26,829
service and previously we had like a

00:14:23,860 --> 00:14:28,959
little cash for cash requests now we're

00:14:26,829 --> 00:14:30,040
gonna change that into what we tend to

00:14:28,959 --> 00:14:31,720
call a materialized view there's not

00:14:30,040 --> 00:14:33,069
actually a great name for this so we

00:14:31,720 --> 00:14:34,749
tend to use the term materialized view

00:14:33,069 --> 00:14:36,819
and what that really means is we're

00:14:34,749 --> 00:14:37,809
going to take these events which are

00:14:36,819 --> 00:14:40,480
flying through this sort of data

00:14:37,809 --> 00:14:42,459
background and we're gonna subscribe to

00:14:40,480 --> 00:14:44,980
them take the bits we're interested in

00:14:42,459 --> 00:14:46,120
and effectively store them in a way

00:14:44,980 --> 00:14:49,029
that's going to make them kind of read

00:14:46,120 --> 00:14:51,910
optimized so in this case the home page

00:14:49,029 --> 00:14:53,800
service is gonna filter these events out

00:14:51,910 --> 00:14:56,410
and create a little data model which

00:14:53,800 --> 00:14:57,429
exactly matches this timeline and this

00:14:56,410 --> 00:14:59,110
is actually a very efficient way of

00:14:57,429 --> 00:15:02,499
doing this so this is a bit like a cache

00:14:59,110 --> 00:15:04,509
but instead of expiring is constantly

00:15:02,499 --> 00:15:06,009
being updated with events which have

00:15:04,509 --> 00:15:07,660
phoned through the system so it's always

00:15:06,009 --> 00:15:09,459
up to date there's no like less you know

00:15:07,660 --> 00:15:12,399
conservative expiry it's just like a a

00:15:09,459 --> 00:15:14,980
replica a continuous query of the

00:15:12,399 --> 00:15:17,709
information which is coming out of these

00:15:14,980 --> 00:15:19,569
other services so now we can do this

00:15:17,709 --> 00:15:21,429
serve very quickly in fact this is kind

00:15:19,569 --> 00:15:22,899
of have Twitter works its Timeline

00:15:21,429 --> 00:15:26,410
feature does this for performance

00:15:22,899 --> 00:15:28,569
reasons so that said the core of

00:15:26,410 --> 00:15:30,029
event-driven programming was certainly

00:15:28,569 --> 00:15:31,760
it's a pattern which is called event

00:15:30,029 --> 00:15:33,320
carried state transfer

00:15:31,760 --> 00:15:35,779
that's what Martin Fowler called it many

00:15:33,320 --> 00:15:38,019
years ago but it also relates to another

00:15:35,779 --> 00:15:40,519
pattern who's heard of event sourcing a

00:15:38,019 --> 00:15:43,820
few of you okay so this is like a

00:15:40,519 --> 00:15:45,380
another way of modeling data in a system

00:15:43,820 --> 00:15:47,510
and it's a bit different

00:15:45,380 --> 00:15:49,790
also from like the traditional way of

00:15:47,510 --> 00:15:53,029
doing things so if you apply a vent

00:15:49,790 --> 00:15:54,740
sourcing again it's just a pattern then

00:15:53,029 --> 00:15:57,680
the main things you make events your

00:15:54,740 --> 00:16:00,170
data model so those events which are

00:15:57,680 --> 00:16:02,540
being sent out from very different

00:16:00,170 --> 00:16:04,430
services which actually representing

00:16:02,540 --> 00:16:05,930
real world facts they're literally just

00:16:04,430 --> 00:16:07,160
what's happening in the real world like

00:16:05,930 --> 00:16:08,510
somebody for befriend someone else

00:16:07,160 --> 00:16:10,699
somebody creates a blog post etc etc

00:16:08,510 --> 00:16:13,970
these real world facts we're gonna use

00:16:10,699 --> 00:16:16,490
those facts as our data model so why is

00:16:13,970 --> 00:16:17,959
that a bit different well to see why

00:16:16,490 --> 00:16:19,160
it's different we have to take like a

00:16:17,959 --> 00:16:20,510
trivial example this is one of the

00:16:19,160 --> 00:16:23,360
common ones that's used it sir think

00:16:20,510 --> 00:16:24,649
about a a shopping cart so maybe like

00:16:23,360 --> 00:16:25,880
you're buying something from Amazon or

00:16:24,649 --> 00:16:27,050
whatever and you have like a lot of

00:16:25,880 --> 00:16:28,790
shopping cart and you're like building

00:16:27,050 --> 00:16:31,130
it up with with the things that you want

00:16:28,790 --> 00:16:34,790
to buy so Bob here has got like a pair

00:16:31,130 --> 00:16:36,170
of trousers a jumper and hat and we have

00:16:34,790 --> 00:16:37,550
a lot of maybe a little database table

00:16:36,170 --> 00:16:39,529
in a crud model where we're gonna

00:16:37,550 --> 00:16:42,170
increment how many things he's got in

00:16:39,529 --> 00:16:43,370
his shopping basket and that's fine

00:16:42,170 --> 00:16:47,240
there's nothing wrong with that that all

00:16:43,370 --> 00:16:48,529
works but if we use events as the data

00:16:47,240 --> 00:16:50,930
model we get something slightly

00:16:48,529 --> 00:16:53,120
different so in the event based data

00:16:50,930 --> 00:16:55,190
model we'd actually follow exactly what

00:16:53,120 --> 00:16:56,839
happened in the real world so what

00:16:55,190 --> 00:16:59,240
actually happened was Bob added two

00:16:56,839 --> 00:17:00,800
pairs of trousers he then added a jumper

00:16:59,240 --> 00:17:02,720
he then removed a pair of trousers

00:17:00,800 --> 00:17:04,819
because he realized he didn't want to

00:17:02,720 --> 00:17:06,470
buy two pairs of trousers I then added a

00:17:04,819 --> 00:17:09,260
hat and then he checked out so that's at

00:17:06,470 --> 00:17:11,900
the events actually map the user journey

00:17:09,260 --> 00:17:12,470
and this is important because the events

00:17:11,900 --> 00:17:14,929
are truthful

00:17:12,470 --> 00:17:16,059
they represent exactly what happens in

00:17:14,929 --> 00:17:18,610
the real world

00:17:16,059 --> 00:17:21,169
whereas this view is a little bit lossy

00:17:18,610 --> 00:17:24,410
so event sourcing is about storing data

00:17:21,169 --> 00:17:26,480
as events in the knowledge you can

00:17:24,410 --> 00:17:28,250
always transfer them back and get this

00:17:26,480 --> 00:17:29,450
view right you can always derive this

00:17:28,250 --> 00:17:30,820
one from this one but not the other way

00:17:29,450 --> 00:17:34,580
around

00:17:30,820 --> 00:17:38,410
so if we go back to a little example our

00:17:34,580 --> 00:17:42,409
materialized view is really a

00:17:38,410 --> 00:17:44,510
representation of these events and it's

00:17:42,409 --> 00:17:44,950
a projection Africa's got that it'll

00:17:44,510 --> 00:17:46,150
have set

00:17:44,950 --> 00:17:47,410
to be the source of truth it's truthful

00:17:46,150 --> 00:17:48,820
because it's capturing exactly what

00:17:47,410 --> 00:17:50,260
happened in the real world and we're

00:17:48,820 --> 00:17:52,450
doing the projection inside this boot

00:17:50,260 --> 00:17:54,250
materialized you simply so that we can

00:17:52,450 --> 00:17:55,720
do the thing that we need to do inside

00:17:54,250 --> 00:17:59,710
the home page service which is displayed

00:17:55,720 --> 00:18:02,500
this timeline and this is a actually yep

00:17:59,710 --> 00:18:04,390
this pattern is a session called CQRS

00:18:02,500 --> 00:18:07,150
come on query responsibility segregation

00:18:04,390 --> 00:18:09,540
which is a bit of a mouthful and it's

00:18:07,150 --> 00:18:13,090
just like a variant of events or thing

00:18:09,540 --> 00:18:16,360
so because CAF can be used as a storage

00:18:13,090 --> 00:18:21,250
system we can actually store the events

00:18:16,360 --> 00:18:23,560
in Kafka for as long as we want and we

00:18:21,250 --> 00:18:25,300
can define our view that projection it

00:18:23,560 --> 00:18:27,490
turns the event based view into the view

00:18:25,300 --> 00:18:30,310
which suits our service inside our

00:18:27,490 --> 00:18:33,940
service and then we can query this read

00:18:30,310 --> 00:18:35,830
optimize view so this is like a bad read

00:18:33,940 --> 00:18:38,260
optimize cache and this could actually

00:18:35,830 --> 00:18:40,600
be a database it could be a hash map in

00:18:38,260 --> 00:18:44,770
memory it could be something like Redis

00:18:40,600 --> 00:18:45,910
like to see easiest Redis but yeah there

00:18:44,770 --> 00:18:49,210
are lots of there are lots of options

00:18:45,910 --> 00:18:51,190
the kilt the core point is that inside

00:18:49,210 --> 00:18:52,630
this view would tend to be read

00:18:51,190 --> 00:18:54,280
optimized or at least something that

00:18:52,630 --> 00:19:01,990
very much suits the way that we want to

00:18:54,280 --> 00:19:05,440
read data so yes the events are stored

00:19:01,990 --> 00:19:09,730
yeah stored inside its Kafka inside

00:19:05,440 --> 00:19:13,330
Kafka we derive or maybe read arrive the

00:19:09,730 --> 00:19:15,550
view from those stored event streams so

00:19:13,330 --> 00:19:17,320
if we store the later in Kafka we can

00:19:15,550 --> 00:19:18,820
throw this view away but let's say it's

00:19:17,320 --> 00:19:21,760
just a hash map in memory or maybe like

00:19:18,820 --> 00:19:23,470
a a cache and we derive it from scratch

00:19:21,760 --> 00:19:25,810
that's kind of interesting because if we

00:19:23,470 --> 00:19:27,670
change our data model we can then it's

00:19:25,810 --> 00:19:31,060
very easy for us to just reemployed a

00:19:27,670 --> 00:19:32,680
new data model from the underlying like

00:19:31,060 --> 00:19:36,910
extreme events because that's what

00:19:32,680 --> 00:19:39,070
actually happened in the real world so

00:19:36,910 --> 00:19:41,650
the reason this becomes interesting is

00:19:39,070 --> 00:19:44,830
that we can then start apply the - to

00:19:41,650 --> 00:19:46,510
whole microservice ecosystems and the

00:19:44,830 --> 00:19:48,130
reason the pattern works quite well is

00:19:46,510 --> 00:19:49,840
because different microservices tend to

00:19:48,130 --> 00:19:52,060
want to do different things with data so

00:19:49,840 --> 00:19:53,260
the homepage right it just wants to

00:19:52,060 --> 00:19:55,290
create a timeline that's all he wants to

00:19:53,260 --> 00:19:58,750
do it doesn't care about maybe like old

00:19:55,290 --> 00:20:00,610
posts and it doesn't care too much about

00:19:58,750 --> 00:20:02,800
information about the user particularly

00:20:00,610 --> 00:20:04,180
it just wants to display posts but we

00:20:02,800 --> 00:20:07,510
might have liked another service which

00:20:04,180 --> 00:20:09,910
is maybe of Opera optimizing the sales

00:20:07,510 --> 00:20:11,770
conversion rate that might be very

00:20:09,910 --> 00:20:13,660
interested in more data or we might have

00:20:11,770 --> 00:20:15,310
set a recommendation system and which we

00:20:13,660 --> 00:20:17,860
wants to recommend you different types

00:20:15,310 --> 00:20:19,210
of posts these are all going to have

00:20:17,860 --> 00:20:21,010
like different data models but they're

00:20:19,210 --> 00:20:24,310
always going to go back to that

00:20:21,010 --> 00:20:27,910
underlying core set of of truthful

00:20:24,310 --> 00:20:28,270
events so just to kind of summarize this

00:20:27,910 --> 00:20:30,370
bit

00:20:28,270 --> 00:20:33,640
there are really two patterns going on

00:20:30,370 --> 00:20:35,530
here the first pattern is the event

00:20:33,640 --> 00:20:38,290
source architecture and that's where

00:20:35,530 --> 00:20:41,860
we're retaining our events in Kafka and

00:20:38,290 --> 00:20:44,860
we're using those events that store of

00:20:41,860 --> 00:20:46,870
events to redriver view maybe when the

00:20:44,860 --> 00:20:51,280
application starts up maybe just

00:20:46,870 --> 00:20:53,950
periodically or maybe yeah really any

00:20:51,280 --> 00:20:55,330
frequency we want and then there's the

00:20:53,950 --> 00:20:56,440
event-driven architecture the venturi of

00:20:55,330 --> 00:20:58,480
an architecture we don't need to store

00:20:56,440 --> 00:21:00,040
the data right we can just say actually

00:20:58,480 --> 00:21:01,750
we're gonna put our data in a database

00:21:00,040 --> 00:21:03,790
inside each micro-service and we're just

00:21:01,750 --> 00:21:06,730
going to use the stream of events to

00:21:03,790 --> 00:21:10,870
keep it up-to-date both patterns are

00:21:06,730 --> 00:21:13,050
equally valid so finally I just gonna

00:21:10,870 --> 00:21:17,020
talk a little bit about event streaming

00:21:13,050 --> 00:21:19,810
so if we take those examples we can

00:21:17,020 --> 00:21:21,340
actually extend the same kind of

00:21:19,810 --> 00:21:23,530
concepts of having different

00:21:21,340 --> 00:21:25,120
microservices set around our

00:21:23,530 --> 00:21:27,370
architecture with different views

00:21:25,120 --> 00:21:30,070
different views on the same underlying

00:21:27,370 --> 00:21:33,790
fact and we can represent this in a

00:21:30,070 --> 00:21:37,300
stream processor and we often do this

00:21:33,790 --> 00:21:38,740
for kind of offline activities that you

00:21:37,300 --> 00:21:41,080
know we want to where we want things to

00:21:38,740 --> 00:21:43,150
react in real time so one process to

00:21:41,080 --> 00:21:46,060
happen continuously this is less

00:21:43,150 --> 00:21:46,690
commonly used for user interfaces so

00:21:46,060 --> 00:21:48,600
let's say we have a recommendation

00:21:46,690 --> 00:21:52,270
service the recommendation service

00:21:48,600 --> 00:21:53,080
actually wants to tell you what you

00:21:52,270 --> 00:21:56,170
might want to read next

00:21:53,080 --> 00:21:59,110
so we'd make this contextual right so

00:21:56,170 --> 00:22:01,930
let's say you're browsing the absolutely

00:21:59,110 --> 00:22:03,670
sunshine website you look at various

00:22:01,930 --> 00:22:07,300
different posts and we might have a

00:22:03,670 --> 00:22:09,280
stream of a click stream of pageviews so

00:22:07,300 --> 00:22:12,280
we might look at like the the previous

00:22:09,280 --> 00:22:15,250
three posts that you've looked it

00:22:12,280 --> 00:22:17,080
you've read let's say the last three

00:22:15,250 --> 00:22:19,300
poster on Cloud Foundry well maybe you

00:22:17,080 --> 00:22:20,770
want to recommend you some some other

00:22:19,300 --> 00:22:23,170
Cloud Foundry poster maybe you want to

00:22:20,770 --> 00:22:25,390
recommend you a posts which your friends

00:22:23,170 --> 00:22:27,730
have really liked and they spent time

00:22:25,390 --> 00:22:28,630
reading they were on the same subject so

00:22:27,730 --> 00:22:30,580
we might have like a little machine

00:22:28,630 --> 00:22:33,100
learning algorithm which allows us to

00:22:30,580 --> 00:22:35,080
sort of drive that and we take in three

00:22:33,100 --> 00:22:36,550
streams of events page views which would

00:22:35,080 --> 00:22:39,730
be like what people are doing and we'll

00:22:36,550 --> 00:22:42,100
see the friendships and the blog posts

00:22:39,730 --> 00:22:43,480
event streams and the interesting thing

00:22:42,100 --> 00:22:44,650
about using about doing this in a

00:22:43,480 --> 00:22:46,660
streaming ways we can use something like

00:22:44,650 --> 00:22:49,750
cathica for streams or alternative case

00:22:46,660 --> 00:22:53,580
equal to wrap up the concept of events

00:22:49,750 --> 00:22:55,360
that happen in real time and tables and

00:22:53,580 --> 00:22:59,410
process them as they're sort of

00:22:55,360 --> 00:23:00,820
continuously evolving program and the

00:22:59,410 --> 00:23:03,820
CAF extreme is just a library you can

00:23:00,820 --> 00:23:06,580
you can use it standalone and you can

00:23:03,820 --> 00:23:07,720
use it inside spring it allows you gives

00:23:06,580 --> 00:23:10,560
you tools for joining built on a

00:23:07,720 --> 00:23:13,120
stretcher event streams tables and also

00:23:10,560 --> 00:23:17,710
summarizing streams so that you have

00:23:13,120 --> 00:23:21,190
like you can take a yes summarize

00:23:17,710 --> 00:23:22,630
something into some page views may be

00:23:21,190 --> 00:23:25,720
into like views per hour or something

00:23:22,630 --> 00:23:27,640
like that so that's how you can kind of

00:23:25,720 --> 00:23:29,620
build a recommendation system very very

00:23:27,640 --> 00:23:31,210
simply and then you push the result back

00:23:29,620 --> 00:23:33,850
into another topic which might be used

00:23:31,210 --> 00:23:35,860
by another microservice such a little

00:23:33,850 --> 00:23:38,470
bit on event streaming and I'm gonna

00:23:35,860 --> 00:23:47,110
hand back over to Cornelia to finish up

00:23:38,470 --> 00:23:49,180
okay all right so to sum it up first of

00:23:47,110 --> 00:23:51,580
all I have to say that I love the

00:23:49,180 --> 00:23:53,260
distinction of excuse me those three

00:23:51,580 --> 00:23:53,560
different patterns that Ben just talked

00:23:53,260 --> 00:23:57,070
about

00:23:53,560 --> 00:23:58,930
there's the event-driven which just that

00:23:57,070 --> 00:24:01,480
that is very similar to messaging

00:23:58,930 --> 00:24:03,850
there's the event sourcing which is now

00:24:01,480 --> 00:24:06,730
the event stream or the events are

00:24:03,850 --> 00:24:08,890
themselves a source of truth and then

00:24:06,730 --> 00:24:10,780
there's the streaming which is okay now

00:24:08,890 --> 00:24:13,570
that I've got this whole series of

00:24:10,780 --> 00:24:16,660
events can I process when that Windows

00:24:13,570 --> 00:24:19,720
of that those three patterns are just so

00:24:16,660 --> 00:24:22,000
incredibly powerful when we do things

00:24:19,720 --> 00:24:24,670
like turn this whole thing on its head

00:24:22,000 --> 00:24:25,630
instead of going root to leaf go leaf to

00:24:24,670 --> 00:24:29,170
root though

00:24:25,630 --> 00:24:31,360
three key key patterns for that so to

00:24:29,170 --> 00:24:33,430
sum it up the interesting thing is that

00:24:31,360 --> 00:24:35,230
we can take a look at this evolution of

00:24:33,430 --> 00:24:36,520
different architectures you know we used

00:24:35,230 --> 00:24:40,210
to have this monolithic architecture

00:24:36,520 --> 00:24:43,210
where we had all of the app logic in one

00:24:40,210 --> 00:24:45,280
big piece tied to a database then we

00:24:43,210 --> 00:24:47,440
started to break that up that was the

00:24:45,280 --> 00:24:50,370
picture I showed you earlier single

00:24:47,440 --> 00:24:53,860
database a whole bunch of seemingly

00:24:50,370 --> 00:24:55,690
autonomous components then we started to

00:24:53,860 --> 00:24:58,570
say well actually let's break up the

00:24:55,690 --> 00:25:01,360
data tier but as soon as we broke up the

00:24:58,570 --> 00:25:05,200
data tier we needed to address what we

00:25:01,360 --> 00:25:07,630
do in terms of logically having one body

00:25:05,200 --> 00:25:09,700
of data but actually breaking that up

00:25:07,630 --> 00:25:12,130
into several components and that's where

00:25:09,700 --> 00:25:15,190
the Kafka and the patterns that Ben

00:25:12,130 --> 00:25:17,890
talked about come in now if we take that

00:25:15,190 --> 00:25:19,510
picture and we say how does that

00:25:17,890 --> 00:25:21,910
actually work in the Cloud Foundry

00:25:19,510 --> 00:25:25,000
setting this is pretty high-level and

00:25:21,910 --> 00:25:28,210
abstract so I'm going to click to get to

00:25:25,000 --> 00:25:31,840
the next level of detail which is in

00:25:28,210 --> 00:25:33,880
fact it is the applications not the

00:25:31,840 --> 00:25:36,010
databases themselves not the local

00:25:33,880 --> 00:25:40,330
databases but the applications that are

00:25:36,010 --> 00:25:43,720
connecting to Kafka what do we call that

00:25:40,330 --> 00:25:46,300
Kafka in the Cloud Foundry setting it's

00:25:43,720 --> 00:25:50,290
a service right it's a service that we

00:25:46,300 --> 00:25:53,260
bind to so here we have the service the

00:25:50,290 --> 00:25:55,690
Kafka service itself and then we also

00:25:53,260 --> 00:25:59,200
have to deal with how do we do those

00:25:55,690 --> 00:26:01,980
bindings so what we want to tell you

00:25:59,200 --> 00:26:04,240
about is a couple of very concrete

00:26:01,980 --> 00:26:08,470
components that are available to you

00:26:04,240 --> 00:26:11,140
today albeit some of them not quite GA

00:26:08,470 --> 00:26:13,330
one of them I believe is coming GA in

00:26:11,140 --> 00:26:16,450
the spring one platform in in just a few

00:26:13,330 --> 00:26:18,250
weeks we want to tell you about those so

00:26:16,450 --> 00:26:21,130
first all have been talked about the

00:26:18,250 --> 00:26:23,920
first of those which is how can you

00:26:21,130 --> 00:26:26,460
actually get the Kafka service itself

00:26:23,920 --> 00:26:30,310
running in a cloud foundry environment

00:26:26,460 --> 00:26:33,430
yeah sure so there's a nice little tool

00:26:30,310 --> 00:26:35,320
it's called confluent operator and this

00:26:33,430 --> 00:26:39,190
basically automates the process of

00:26:35,320 --> 00:26:40,990
managing Kafka for you inside kubernetes

00:26:39,190 --> 00:26:43,450
so you can also make Afghans who keep a

00:26:40,990 --> 00:26:45,010
connect schema registry which like hold

00:26:43,450 --> 00:26:47,260
schemas case equal which is stream

00:26:45,010 --> 00:26:48,970
processor and replicator which basically

00:26:47,260 --> 00:26:52,540
ties different Kaffee clusters together

00:26:48,970 --> 00:26:54,340
and the operator itself has a bunch of

00:26:52,540 --> 00:26:56,710
features obviously it helps you with a

00:26:54,340 --> 00:27:00,160
whole pom deployment but actually most

00:26:56,710 --> 00:27:01,150
of the smart really in keeping the thing

00:27:00,160 --> 00:27:03,550
running so let's say you want to do

00:27:01,150 --> 00:27:04,750
something like a of rolling bounce right

00:27:03,550 --> 00:27:06,610
so you want to be able restart your

00:27:04,750 --> 00:27:08,890
cluster in a way where it's always on

00:27:06,610 --> 00:27:10,270
it's able to do operations like the Hat

00:27:08,890 --> 00:27:12,130
knowing that you're not going to lose

00:27:10,270 --> 00:27:14,380
any data or sacrifice ordering

00:27:12,130 --> 00:27:15,610
guarantees that that kind of thing so

00:27:14,380 --> 00:27:18,550
you can do that other things like a

00:27:15,610 --> 00:27:20,200
scale install and install all these all

00:27:18,550 --> 00:27:23,290
these kind of things and you can

00:27:20,200 --> 00:27:26,290
download it there excellent thank you

00:27:23,290 --> 00:27:28,030
and then the other half of that picture

00:27:26,290 --> 00:27:30,400
that previous picture was in the

00:27:28,030 --> 00:27:32,500
bindings so if you're deploying your

00:27:30,400 --> 00:27:34,990
applications onto Cloud Foundry you want

00:27:32,500 --> 00:27:36,730
to be able to bind now if you notice

00:27:34,990 --> 00:27:39,490
what been talked about was he talked

00:27:36,730 --> 00:27:42,010
about the actual running of that service

00:27:39,490 --> 00:27:44,710
so how you can instantiate it how you

00:27:42,010 --> 00:27:47,800
can do day2 operations all running on

00:27:44,710 --> 00:27:50,890
top of kubernetes but what is it that we

00:27:47,800 --> 00:27:53,620
need to be able to bind a service broker

00:27:50,890 --> 00:27:56,410
right so there's a service broker that's

00:27:53,620 --> 00:27:59,260
coming out called the container service

00:27:56,410 --> 00:28:02,230
manager that's what the Chaos Sun stands

00:27:59,260 --> 00:28:04,900
for and what that is is it's developed

00:28:02,230 --> 00:28:08,170
by pivotal and what it allows you to do

00:28:04,900 --> 00:28:11,880
is it allows you to bring operators like

00:28:08,170 --> 00:28:15,310
the confluent operator that deploy

00:28:11,880 --> 00:28:18,310
services on top of kubernetes and it

00:28:15,310 --> 00:28:21,070
allows you to register those things

00:28:18,310 --> 00:28:23,650
inside of your Cloud Foundry services

00:28:21,070 --> 00:28:25,660
catalog so here's a picture of what that

00:28:23,650 --> 00:28:27,520
looks like I won't go through it in

00:28:25,660 --> 00:28:31,180
detail but what you can see here

00:28:27,520 --> 00:28:33,910
basically is that the platform team who

00:28:31,180 --> 00:28:37,150
we call Alana here is going to be able

00:28:33,910 --> 00:28:39,760
to install the confluent operator first

00:28:37,150 --> 00:28:41,290
of all they're installing kisum then

00:28:39,760 --> 00:28:45,040
they're installing the confluent

00:28:41,290 --> 00:28:47,860
operator into that broker that has the

00:28:45,040 --> 00:28:50,050
effect of making that available as a

00:28:47,860 --> 00:28:52,600
marketplace offering in cloud foundry

00:28:50,050 --> 00:28:55,720
where cody can just do a CF

00:28:52,600 --> 00:28:58,899
create service that CF create service

00:28:55,720 --> 00:29:01,450
will then result in having the operator

00:28:58,899 --> 00:29:03,460
get deployed onto the kubernetes

00:29:01,450 --> 00:29:07,299
environment of your choice we've shown a

00:29:03,460 --> 00:29:09,490
couple here PKS as well as gke and then

00:29:07,299 --> 00:29:11,590
the service is available for you to bind

00:29:09,490 --> 00:29:14,440
to to apply those patterns of

00:29:11,590 --> 00:29:18,909
event-driven or event sourcing or event

00:29:14,440 --> 00:29:21,909
streaming so that wraps up the picture

00:29:18,909 --> 00:29:24,700
and unbelievably I have 40 seconds left

00:29:21,909 --> 00:29:28,779
or we have 40 seconds left so I think we

00:29:24,700 --> 00:29:32,759
have time for maybe one question any

00:29:28,779 --> 00:29:32,759
questions on that yes

00:29:52,520 --> 00:29:57,900
and say yes a really good question

00:29:55,170 --> 00:30:01,920
actually say yeah I mean the questions

00:29:57,900 --> 00:30:04,470
really like how in event streaming and

00:30:01,920 --> 00:30:05,700
an event-driven how what is your source

00:30:04,470 --> 00:30:07,950
of truth like how do you not have this a

00:30:05,700 --> 00:30:10,440
data divergence problem and actually

00:30:07,950 --> 00:30:11,760
event streaming and the event sourcing

00:30:10,440 --> 00:30:13,380
are actually pretty closely linked so

00:30:11,760 --> 00:30:16,050
offense human tends to use event

00:30:13,380 --> 00:30:18,180
sourcing just implicitly it just turns

00:30:16,050 --> 00:30:21,390
out it evolved that way in a different

00:30:18,180 --> 00:30:22,740
field basically but yeah the main thing

00:30:21,390 --> 00:30:26,370
is this you actually still have one

00:30:22,740 --> 00:30:29,580
source of truth in in in all of those

00:30:26,370 --> 00:30:30,690
patterns the typical event-driven

00:30:29,580 --> 00:30:32,700
pattern which has been around for a long

00:30:30,690 --> 00:30:34,710
time it doesn't actually really address

00:30:32,700 --> 00:30:37,560
it in the same way it doesn't give you

00:30:34,710 --> 00:30:38,910
that much more it decouples but you

00:30:37,560 --> 00:30:41,010
actually have like still have like many

00:30:38,910 --> 00:30:41,400
different copies of your data around the

00:30:41,010 --> 00:30:44,430
place

00:30:41,400 --> 00:30:46,020
the main thing which both the event

00:30:44,430 --> 00:30:48,690
sourcing and the event streaming

00:30:46,020 --> 00:30:51,870
patterns do is they keep you closer to

00:30:48,690 --> 00:30:53,910
that source of truth because you tend to

00:30:51,870 --> 00:30:56,100
write your code in a way that your data

00:30:53,910 --> 00:30:58,200
your copy the copy that's inside your

00:30:56,100 --> 00:31:01,590
micro service it can always be read

00:30:58,200 --> 00:31:03,030
arrived from the that source of truth

00:31:01,590 --> 00:31:04,830
it's not the same thing because it's it

00:31:03,030 --> 00:31:06,900
you're keeping yourself one step away

00:31:04,830 --> 00:31:08,730
from it but your work you're always able

00:31:06,900 --> 00:31:09,840
to read write derive so it's actually

00:31:08,730 --> 00:31:11,250
very similar to the way you did kind of

00:31:09,840 --> 00:31:12,690
like infrastructure as code it's pretty

00:31:11,250 --> 00:31:14,460
much like a it's more like sort of the

00:31:12,690 --> 00:31:16,830
same kind of principle of saying well

00:31:14,460 --> 00:31:18,990
actually I've got this data it's as

00:31:16,830 --> 00:31:20,760
events and I have some code which turns

00:31:18,990 --> 00:31:22,470
that data into the data that I actually

00:31:20,760 --> 00:31:23,820
use and for data that comes from other

00:31:22,470 --> 00:31:25,920
services that kind of declarative

00:31:23,820 --> 00:31:27,600
approach how I'm gonna represent this

00:31:25,920 --> 00:31:29,970
this source of sort of source of truth

00:31:27,600 --> 00:31:31,590
data but in my own micro service and

00:31:29,970 --> 00:31:33,630
that's kind of what makes it work so

00:31:31,590 --> 00:31:35,370
it's kind of like a balance yep

00:31:33,630 --> 00:31:39,390
and I'll add to that that the short

00:31:35,370 --> 00:31:41,100
answer is it's not easy and what we've

00:31:39,390 --> 00:31:43,380
done over the course the last 20 30

00:31:41,100 --> 00:31:48,750
years is if you if you've heard terms

00:31:43,380 --> 00:31:50,130
like master data management those types

00:31:48,750 --> 00:31:51,950
of things those are the approaches that

00:31:50,130 --> 00:31:55,380
we use before and it's extraordinarily

00:31:51,950 --> 00:31:58,290
complex because you do have to decide

00:31:55,380 --> 00:31:59,730
where is my source of truth and then you

00:31:58,290 --> 00:32:01,230
also have to deal with the other

00:31:59,730 --> 00:32:03,779
complexity that comes in

00:32:01,230 --> 00:32:05,960
is that if I want to write to one of my

00:32:03,779 --> 00:32:07,649
local databases how do i do

00:32:05,960 --> 00:32:10,409
synchronization in multiple directions

00:32:07,649 --> 00:32:13,049
so the answer is it's super hard and

00:32:10,409 --> 00:32:15,059
it's very brittle and it's not agile at

00:32:13,049 --> 00:32:18,360
all and which is why we're moving into

00:32:15,059 --> 00:32:20,580
event sourcing type of patterns so I

00:32:18,360 --> 00:32:23,760
think with that we have to close up and

00:32:20,580 --> 00:32:25,649
I am Ben is leaving this afternoon so if

00:32:23,760 --> 00:32:27,960
you want to snag him sometime this

00:32:25,649 --> 00:32:30,480
afternoon would be good I'm around at

00:32:27,960 --> 00:32:31,950
the conference through tomorrow so if

00:32:30,480 --> 00:32:33,840
you have any questions you can certainly

00:32:31,950 --> 00:32:35,669
find me in the hallways and happy to

00:32:33,840 --> 00:32:36,830
have more chats so thanks so much for

00:32:35,669 --> 00:32:38,100
your attention

00:32:36,830 --> 00:32:42,090
thanks again

00:32:38,100 --> 00:32:42,090

YouTube URL: https://www.youtube.com/watch?v=OqN6x_vNsds


