Title: Seeing the Forest for the Trees: An Operator’s Guide to Observability of CF with... Todd Persen
Publication date: 2019-09-13
Playlist: Cloud Foundry Summit EU 2019 - The Hague
Description: 
	Seeing the Forest for the Trees: An Operator’s Guide to Observability of CF with Metric Store - Todd Persen, Pivotal 

In this talk, Todd will introduce a recently-released component of CF called Metric Store and discuss how it is becoming an invaluable tool to cut through the noise of streaming, ephemeral metrics. Instead of simply pulling metrics out of Loggregator with a nozzle, Metric Store will provide operators with the ability to analyze long-living metrics about platform health and performance, while also offering a richer interaction with developers as they build and deploy new applications. 

For more info: https://www.cloudfoundry.org/
Captions: 
	00:00:00,060 --> 00:00:06,060
hi everybody thank you for coming my

00:00:03,330 --> 00:00:08,580
name is Todd Pearson I work with the

00:00:06,060 --> 00:00:10,860
data observability team at pivotal out

00:00:08,580 --> 00:00:13,290
of Denver and this is a talk about

00:00:10,860 --> 00:00:14,519
observability using the metric start

00:00:13,290 --> 00:00:18,720
product they've been working on for the

00:00:14,519 --> 00:00:21,270
last year so so a little bit of an

00:00:18,720 --> 00:00:22,260
overview about the talk so we kind of

00:00:21,270 --> 00:00:25,439
wanted to talk about the concept of

00:00:22,260 --> 00:00:26,820
observability what it is why it matters

00:00:25,439 --> 00:00:28,920
and just kind of how to think about it

00:00:26,820 --> 00:00:30,720
within a cloud foundry deployment in

00:00:28,920 --> 00:00:33,420
particular and then talk to you a little

00:00:30,720 --> 00:00:34,950
bit about metrics tour itself why we

00:00:33,420 --> 00:00:37,340
built it what it's good for and how it

00:00:34,950 --> 00:00:39,870
can be useful with cloud foundry and

00:00:37,340 --> 00:00:41,670
then just kind of wanted to talk in

00:00:39,870 --> 00:00:43,379
general about what makes metric store

00:00:41,670 --> 00:00:46,530
special and why it makes observability

00:00:43,379 --> 00:00:49,079
easier than other products other other

00:00:46,530 --> 00:00:50,640
data storage and observability tools and

00:00:49,079 --> 00:00:53,460
just kind of go over some examples of

00:00:50,640 --> 00:00:54,960
things you can do with metric store kind

00:00:53,460 --> 00:00:58,379
of give you a sense of what what it

00:00:54,960 --> 00:01:00,960
makes easier so first of all what is

00:00:58,379 --> 00:01:02,760
observability so there's a quote from

00:01:00,960 --> 00:01:04,860
Peter Drucker who was a business

00:01:02,760 --> 00:01:06,090
management consultant and he said if you

00:01:04,860 --> 00:01:08,250
can't measure it you can't improve it

00:01:06,090 --> 00:01:09,360
and that's kind of been changed around

00:01:08,250 --> 00:01:11,880
in a lot of different ways but in

00:01:09,360 --> 00:01:13,560
general the idea behind that quote is

00:01:11,880 --> 00:01:14,729
that if you don't know what your system

00:01:13,560 --> 00:01:16,470
is actually doing if you don't have some

00:01:14,729 --> 00:01:18,570
sort of concrete metrics about how it's

00:01:16,470 --> 00:01:20,009
performing or what it is that you want

00:01:18,570 --> 00:01:21,930
it to be doing there's no way that you

00:01:20,009 --> 00:01:22,520
can make it any better or know how bad

00:01:21,930 --> 00:01:25,860
it is

00:01:22,520 --> 00:01:28,979
so observability is kind of this larger

00:01:25,860 --> 00:01:30,329
concept now it includes monitoring and

00:01:28,979 --> 00:01:31,890
alerting it's sort of been evolving a

00:01:30,329 --> 00:01:35,220
lot recently but it's basically just

00:01:31,890 --> 00:01:37,250
instrumenting the systems services and

00:01:35,220 --> 00:01:39,479
applications that you're running and

00:01:37,250 --> 00:01:42,119
sometimes it includes visualization it

00:01:39,479 --> 00:01:43,590
can be graphs it can be charts gauges

00:01:42,119 --> 00:01:46,049
whatever it is that you need to be able

00:01:43,590 --> 00:01:47,899
to actually see how your system is

00:01:46,049 --> 00:01:51,270
performing but collecting those metrics

00:01:47,899 --> 00:01:53,250
visualizing them alerting on them but

00:01:51,270 --> 00:01:55,409
giving you insight into your system so

00:01:53,250 --> 00:01:56,850
that you can really understand how it's

00:01:55,409 --> 00:01:58,950
doing how well is it doing how is it

00:01:56,850 --> 00:02:00,780
performing compared to how you want it

00:01:58,950 --> 00:02:04,320
to be performing and one tool that's

00:02:00,780 --> 00:02:07,049
kind of come up more recently is the

00:02:04,320 --> 00:02:09,450
concept of SL OS and SLI so those are

00:02:07,049 --> 00:02:11,489
service level objectives and service

00:02:09,450 --> 00:02:13,770
level indicators so it's giving you a

00:02:11,489 --> 00:02:16,140
way of saying here are the goals that I

00:02:13,770 --> 00:02:18,060
want to hit those are the objectives and

00:02:16,140 --> 00:02:20,550
here are the actual metrics that I'm

00:02:18,060 --> 00:02:22,110
reporting that tell me how close I am to

00:02:20,550 --> 00:02:23,820
those goals or am i exceeding those

00:02:22,110 --> 00:02:27,380
goals and we'll talk about those a

00:02:23,820 --> 00:02:30,600
little bit and kind of what they are so

00:02:27,380 --> 00:02:32,010
from the the Google SR ebook so the site

00:02:30,600 --> 00:02:34,410
reliability engineering book that Google

00:02:32,010 --> 00:02:35,850
put out a few years ago it's actually a

00:02:34,410 --> 00:02:37,620
great book it's open source if you want

00:02:35,850 --> 00:02:38,640
to go read it it's all online but they

00:02:37,620 --> 00:02:41,600
talk about a lot of these different

00:02:38,640 --> 00:02:44,060
concepts in pretty pretty good detail

00:02:41,600 --> 00:02:47,850
but they kind of came up with this one

00:02:44,060 --> 00:02:49,560
set of things to monitor called the four

00:02:47,850 --> 00:02:51,030
golden signals so kind of the the key

00:02:49,560 --> 00:02:54,710
things that you want to look at in any

00:02:51,030 --> 00:02:58,950
and any system and there are some older

00:02:54,710 --> 00:03:02,040
kind of groupings of of metrics one is

00:02:58,950 --> 00:03:04,230
called read looking at rate like rate of

00:03:02,040 --> 00:03:06,180
throughput errors and duration and the

00:03:04,230 --> 00:03:07,740
other one is used which is utilization

00:03:06,180 --> 00:03:10,350
saturation errors but these are kind of

00:03:07,740 --> 00:03:11,850
like groupings of things that you want

00:03:10,350 --> 00:03:15,150
to keep in mind together to sort of give

00:03:11,850 --> 00:03:17,280
you an aggregate view into your system

00:03:15,150 --> 00:03:18,870
but Google is kind of taken it made it a

00:03:17,280 --> 00:03:21,840
little bit more generic and included

00:03:18,870 --> 00:03:23,970
these four things so latency would

00:03:21,840 --> 00:03:26,400
ideally be if you have something like an

00:03:23,970 --> 00:03:28,230
endpoint or a service how long is it

00:03:26,400 --> 00:03:31,110
taking to respond to requests or

00:03:28,230 --> 00:03:34,170
returned data to a user traffic how much

00:03:31,110 --> 00:03:37,140
how much like actual user level

00:03:34,170 --> 00:03:38,430
throughput is it servicing errors so

00:03:37,140 --> 00:03:40,110
like the rate of errors how frequently

00:03:38,430 --> 00:03:42,480
are they're occurring how many per unit

00:03:40,110 --> 00:03:44,370
time and then saturation how close for

00:03:42,480 --> 00:03:48,110
your service is getting to be fully

00:03:44,370 --> 00:03:51,660
utilized do they need to be scaled up

00:03:48,110 --> 00:03:53,820
and then so taking those four golden

00:03:51,660 --> 00:03:56,670
signals I think that was one last thing

00:03:53,820 --> 00:03:57,840
on this other slide yeah so there's

00:03:56,670 --> 00:03:59,010
there's a whole chapter on this in the

00:03:57,840 --> 00:04:00,870
SRT book so if you want to look at these

00:03:59,010 --> 00:04:03,510
in more detail they go into them a bunch

00:04:00,870 --> 00:04:06,660
more so check that out so kind of

00:04:03,510 --> 00:04:07,950
looking at SL is what what is a good SLI

00:04:06,660 --> 00:04:08,880
if you're looking at these four golden

00:04:07,950 --> 00:04:11,520
signals and you want to actually use

00:04:08,880 --> 00:04:15,450
them to sort of talk about your system

00:04:11,520 --> 00:04:17,730
so a good SLI as an indicator should be

00:04:15,450 --> 00:04:19,650
something that's relatively opaque to

00:04:17,730 --> 00:04:21,979
the system so it should be like a user

00:04:19,650 --> 00:04:23,669
user doesn't know what any of your

00:04:21,979 --> 00:04:25,710
microservices are doing under the hood

00:04:23,669 --> 00:04:28,139
they just use it and know how it should

00:04:25,710 --> 00:04:30,330
be actually be returning data that

00:04:28,139 --> 00:04:32,069
so you want your you want your metrics

00:04:30,330 --> 00:04:34,409
to sort of resemble an end user

00:04:32,069 --> 00:04:36,719
experience so don't try and use any like

00:04:34,409 --> 00:04:38,699
funky internal state of your system you

00:04:36,719 --> 00:04:41,340
want to actually be measuring something

00:04:38,699 --> 00:04:42,870
the way that a user would see it and you

00:04:41,340 --> 00:04:44,969
want you want those metrics to be

00:04:42,870 --> 00:04:47,550
specific as well it should be something

00:04:44,969 --> 00:04:50,310
that's a relatively concrete value so

00:04:47,550 --> 00:04:52,409
don't don't measure it in a unit or a

00:04:50,310 --> 00:04:57,150
term that a user wouldn't be familiar

00:04:52,409 --> 00:04:58,949
with and then kind of making sure that

00:04:57,150 --> 00:05:00,689
that these SL has actually represent a

00:04:58,949 --> 00:05:02,009
real user value so if it's not something

00:05:00,689 --> 00:05:03,960
that your user is gonna care about if

00:05:02,009 --> 00:05:05,310
it's not something actually impact how

00:05:03,960 --> 00:05:07,319
they use your system or the value they

00:05:05,310 --> 00:05:09,120
get out of your system you might be

00:05:07,319 --> 00:05:12,509
coming up with an indicator that's more

00:05:09,120 --> 00:05:14,250
focused on developers or an operator and

00:05:12,509 --> 00:05:16,259
sometimes those internal metrics can be

00:05:14,250 --> 00:05:18,569
useful but in general if it's not

00:05:16,259 --> 00:05:21,300
something that actually impacts a user

00:05:18,569 --> 00:05:23,129
it's not something that you should maybe

00:05:21,300 --> 00:05:24,449
be considering to make into an SLI that

00:05:23,129 --> 00:05:26,840
chucks you want to make part of your

00:05:24,449 --> 00:05:29,099
larger observability platform and then

00:05:26,840 --> 00:05:30,689
finally SLI should be architecture

00:05:29,099 --> 00:05:33,779
agnostic so this kind of goes back to

00:05:30,689 --> 00:05:35,759
the previous points as well it shouldn't

00:05:33,779 --> 00:05:37,740
really matter how your systems are

00:05:35,759 --> 00:05:38,250
implemented or what tools are what stack

00:05:37,740 --> 00:05:41,879
you're using

00:05:38,250 --> 00:05:44,099
it should be facing into the system

00:05:41,879 --> 00:05:47,669
looking at it as a user so try to figure

00:05:44,099 --> 00:05:48,990
out measuring things that would still be

00:05:47,669 --> 00:05:52,379
valid even if you changed out the

00:05:48,990 --> 00:05:53,370
implementation underneath and then on

00:05:52,379 --> 00:05:55,770
the other side of it what makes a good

00:05:53,370 --> 00:05:59,189
SLO so what is something that you

00:05:55,770 --> 00:06:01,199
actually want to make that objective

00:05:59,189 --> 00:06:04,439
that you kind of agree on with users so

00:06:01,199 --> 00:06:07,620
in a way the the SLI is a thing that you

00:06:04,439 --> 00:06:10,439
can measure and the SLO the objective is

00:06:07,620 --> 00:06:12,569
is more like a contract so if you have

00:06:10,439 --> 00:06:14,490
operators on one side and users on the

00:06:12,569 --> 00:06:16,729
other what is the actual objective

00:06:14,490 --> 00:06:19,500
target that you want to hit so if it's

00:06:16,729 --> 00:06:22,020
like an error rate is it you know half a

00:06:19,500 --> 00:06:24,270
percent or something that really is it

00:06:22,020 --> 00:06:25,229
like a number of errors per hour or

00:06:24,270 --> 00:06:27,300
something like that so what is the

00:06:25,229 --> 00:06:30,259
actual contract that you want to make

00:06:27,300 --> 00:06:35,069
that your goal as an operator is to hit

00:06:30,259 --> 00:06:36,779
or exceed so for SL OS they should

00:06:35,069 --> 00:06:39,360
represent some sort of business value so

00:06:36,779 --> 00:06:41,520
if we're talking about error rates you

00:06:39,360 --> 00:06:43,139
know if your error rates start to climb

00:06:41,520 --> 00:06:44,550
it's probably gonna impact business

00:06:43,139 --> 00:06:46,410
values so it should be something that

00:06:44,550 --> 00:06:49,379
keeping those under a certain threshold

00:06:46,410 --> 00:06:52,530
should be valuable to the to the company

00:06:49,379 --> 00:06:55,110
to the users in some tangible way it

00:06:52,530 --> 00:06:56,370
should be relatively defensible if if

00:06:55,110 --> 00:06:58,349
somebody comes to you and says I want

00:06:56,370 --> 00:06:59,940
this endpoint to return in under ten

00:06:58,349 --> 00:07:02,460
milliseconds well it should be a reason

00:06:59,940 --> 00:07:03,720
for it there should be some some need

00:07:02,460 --> 00:07:06,120
for it to be where it's set up

00:07:03,720 --> 00:07:07,860
there's no reason and looking for five

00:07:06,120 --> 00:07:11,129
9s or six 9s or something like that of

00:07:07,860 --> 00:07:13,880
reliability if it's if the cost of doing

00:07:11,129 --> 00:07:17,069
so exceeds the value of actually

00:07:13,880 --> 00:07:19,259
implementing it and then finally the

00:07:17,069 --> 00:07:21,389
other side of it is once again the SLO

00:07:19,259 --> 00:07:22,770
should again represent user value it

00:07:21,389 --> 00:07:25,710
should be something that makes the user

00:07:22,770 --> 00:07:27,539
experience of your your platform your

00:07:25,710 --> 00:07:30,960
app whatever it should be something

00:07:27,539 --> 00:07:32,880
that's actually valuable to them so kind

00:07:30,960 --> 00:07:34,860
of the way that this this frames here if

00:07:32,880 --> 00:07:36,030
you meet an SLO your users should be

00:07:34,860 --> 00:07:38,430
happy so that should be kind of the

00:07:36,030 --> 00:07:40,860
underlying goal you you find the sls

00:07:38,430 --> 00:07:43,530
that you can measure and you set s ollas

00:07:40,860 --> 00:07:48,150
in order to to meet that sort of

00:07:43,530 --> 00:07:50,069
Happiness threshold for users okay so

00:07:48,150 --> 00:07:51,030
that's observability in general but

00:07:50,069 --> 00:07:53,789
let's talk a little bit about metrics

00:07:51,030 --> 00:07:55,370
tor so what is it so I don't know if

00:07:53,789 --> 00:07:57,719
anyone in the room has actually used

00:07:55,370 --> 00:07:59,580
metrics tour yet it's relatively new we

00:07:57,719 --> 00:08:02,159
open sourced it earlier this year and

00:07:59,580 --> 00:08:04,680
been contributing to it ever since but

00:08:02,159 --> 00:08:06,900
it's basically it started out as a

00:08:04,680 --> 00:08:12,930
project called log cache which is now a

00:08:06,900 --> 00:08:14,909
part of CFD but as we started using log

00:08:12,930 --> 00:08:16,440
cache more and getting more services

00:08:14,909 --> 00:08:18,060
using it getting user feedback from it

00:08:16,440 --> 00:08:20,240
we realized that the in-memory cache

00:08:18,060 --> 00:08:23,340
duration of log cache all does a store

00:08:20,240 --> 00:08:24,539
envelopes from the firehose in memory as

00:08:23,340 --> 00:08:27,090
people start using it is that this is

00:08:24,539 --> 00:08:28,349
great but the memory limitation is kind

00:08:27,090 --> 00:08:30,479
of a problem because I would like to

00:08:28,349 --> 00:08:32,039
have you know more than a day or two of

00:08:30,479 --> 00:08:34,620
data like ideally I'd like to have

00:08:32,039 --> 00:08:36,180
several weeks of data and you know it'd

00:08:34,620 --> 00:08:38,250
also be nice if it didn't go away every

00:08:36,180 --> 00:08:39,510
time I restarted my log cache instances

00:08:38,250 --> 00:08:41,190
so as we started talking about it we

00:08:39,510 --> 00:08:44,880
realized that we kind of needed to

00:08:41,190 --> 00:08:46,800
approach the implementation differently

00:08:44,880 --> 00:08:49,529
so what we did is took took log cache

00:08:46,800 --> 00:08:51,720
and instead of it all being in memory we

00:08:49,529 --> 00:08:53,579
actually use an on disk time series

00:08:51,720 --> 00:08:55,170
database storage engine so actually

00:08:53,579 --> 00:08:57,060
write all of the envelope

00:08:55,170 --> 00:08:58,860
to disk now and kind of built a new

00:08:57,060 --> 00:09:00,990
project around that storage interface

00:08:58,860 --> 00:09:02,519
and that is what turned into metric

00:09:00,990 --> 00:09:03,990
storage so at this point the code bases

00:09:02,519 --> 00:09:07,589
are pretty different but it originally

00:09:03,990 --> 00:09:09,180
started as just a fork of law cache but

00:09:07,589 --> 00:09:11,279
the goal was rather than it just being

00:09:09,180 --> 00:09:12,690
like any arbitrary times through your

00:09:11,279 --> 00:09:14,730
database we built it to work

00:09:12,690 --> 00:09:18,720
specifically with Cloud Foundry in terms

00:09:14,730 --> 00:09:20,970
of ingress authentication it's basically

00:09:18,720 --> 00:09:22,170
a just a drop-in time series database

00:09:20,970 --> 00:09:24,149
for Cloud Foundry and I'll talk about

00:09:22,170 --> 00:09:25,620
how that differs from other things as

00:09:24,149 --> 00:09:27,990
well in just a minute

00:09:25,620 --> 00:09:32,100
by default it gives you six weeks of

00:09:27,990 --> 00:09:34,440
storage retention and we actually we

00:09:32,100 --> 00:09:36,480
shard the data in days so essentially as

00:09:34,440 --> 00:09:38,579
data expires we can just delete the

00:09:36,480 --> 00:09:41,010
oldest day so you get 42 days of storage

00:09:38,579 --> 00:09:42,990
by default that's user configurable if

00:09:41,010 --> 00:09:45,930
you don't have a lot of volume on your

00:09:42,990 --> 00:09:47,639
foundation you can scale that up but

00:09:45,930 --> 00:09:49,860
ideally you know six weeks is pretty

00:09:47,639 --> 00:09:51,240
comfortable for most people but you

00:09:49,860 --> 00:09:52,949
could easily you could potentially go to

00:09:51,240 --> 00:09:56,519
yours if you have the disk storage for

00:09:52,949 --> 00:09:59,190
it so it connects directly to the the

00:09:56,519 --> 00:10:02,579
RLP the reverse log proxy of the logger

00:09:59,190 --> 00:10:03,990
Gator firehose and we have a component

00:10:02,579 --> 00:10:05,100
called the nozzle that just ingests met

00:10:03,990 --> 00:10:06,779
everything that comes in everything

00:10:05,100 --> 00:10:08,760
that's a gauge timer a counter metric

00:10:06,779 --> 00:10:10,470
just gets pulled in we don't do anything

00:10:08,760 --> 00:10:12,170
special with logs because there's

00:10:10,470 --> 00:10:14,550
there's way too much variability there

00:10:12,170 --> 00:10:16,410
so it basically pulls everything in

00:10:14,550 --> 00:10:18,420
without without any filtering and

00:10:16,410 --> 00:10:20,370
processes it and stores it internally

00:10:18,420 --> 00:10:21,630
and then on the query side we have

00:10:20,370 --> 00:10:24,120
started doing this a little bit with log

00:10:21,630 --> 00:10:27,120
cache originally log cache had its own

00:10:24,120 --> 00:10:29,220
proprietary endpoint for queries but we

00:10:27,120 --> 00:10:31,260
actually took the entire Prometheus

00:10:29,220 --> 00:10:33,000
query engine just dropped it right in

00:10:31,260 --> 00:10:35,430
and kind of connected that to our

00:10:33,000 --> 00:10:37,740
storage engine so metrics are actually

00:10:35,430 --> 00:10:39,449
now has like a full prompt ql query

00:10:37,740 --> 00:10:41,459
engine that you can use as well the one

00:10:39,449 --> 00:10:44,850
that we had added to log cache was only

00:10:41,459 --> 00:10:46,589
supported a subset of the queries so

00:10:44,850 --> 00:10:48,839
essentially now we've just taken the the

00:10:46,589 --> 00:10:50,459
query side prometheus

00:10:48,839 --> 00:10:52,740
some stuff from log cache that made it

00:10:50,459 --> 00:10:54,180
easy to run a Cloud Foundry and a new

00:10:52,740 --> 00:10:57,120
storage engine and put them all together

00:10:54,180 --> 00:10:59,339
so basically you can get the best pieces

00:10:57,120 --> 00:11:01,670
of prom ql with the persistent store

00:10:59,339 --> 00:11:04,500
that works natively with Cloud Foundry

00:11:01,670 --> 00:11:05,339
okay so quickly you know why not use

00:11:04,500 --> 00:11:06,930
some of the other things that are out

00:11:05,339 --> 00:11:08,700
there where this is definitely not the

00:11:06,930 --> 00:11:09,870
first time series database

00:11:08,700 --> 00:11:12,120
and there are lots of other things in

00:11:09,870 --> 00:11:13,710
the ecosystem that people ask about so

00:11:12,120 --> 00:11:15,960
why not use Prometheus so for me this is

00:11:13,710 --> 00:11:18,180
great for a lot of use cases but by

00:11:15,960 --> 00:11:19,860
default it wants to scrape end points it

00:11:18,180 --> 00:11:20,940
wants to have a lot of metrics end

00:11:19,860 --> 00:11:22,650
points that it goes out and collects

00:11:20,940 --> 00:11:24,180
data from those have to be configured

00:11:22,650 --> 00:11:27,000
and those have to be available and right

00:11:24,180 --> 00:11:28,590
now that's not the way that the

00:11:27,000 --> 00:11:30,420
ecosystem inside of cloud foundry works

00:11:28,590 --> 00:11:32,520
it's something that we're moving towards

00:11:30,420 --> 00:11:34,980
in newer versions of logger Gator but

00:11:32,520 --> 00:11:36,330
right now it's just not available so

00:11:34,980 --> 00:11:37,650
you'd have to do a lot of work to

00:11:36,330 --> 00:11:39,510
implement that and make it work and they

00:11:37,650 --> 00:11:40,530
could go out and scrape and there are

00:11:39,510 --> 00:11:42,780
still some things coming through the

00:11:40,530 --> 00:11:45,600
fire hose that have a resolution that's

00:11:42,780 --> 00:11:47,580
lower than 10 seconds so right now

00:11:45,600 --> 00:11:48,900
Prometheus by default would just scrape

00:11:47,580 --> 00:11:50,970
everything every 10 seconds so that's

00:11:48,900 --> 00:11:51,960
how quickly to get your data stuff

00:11:50,970 --> 00:11:54,410
coming to the fire house still has a

00:11:51,960 --> 00:11:57,180
very like event-based

00:11:54,410 --> 00:11:58,950
design right now so you know six to

00:11:57,180 --> 00:12:00,990
twelve months from now maybe for me this

00:11:58,950 --> 00:12:03,180
would be a just as good of a drop-in

00:12:00,990 --> 00:12:04,680
choice but for now metrics or gives you

00:12:03,180 --> 00:12:06,570
the ability to work with the way that

00:12:04,680 --> 00:12:07,800
things are currently designed and give

00:12:06,570 --> 00:12:11,100
you the storage that you would get with

00:12:07,800 --> 00:12:12,600
something like prometheus in Flex TV so

00:12:11,100 --> 00:12:14,670
I mentioned we're using the in Flex DB

00:12:12,600 --> 00:12:16,410
storage engine but once again in Flex DV

00:12:14,670 --> 00:12:19,320
has its own ingestion format its own

00:12:16,410 --> 00:12:20,370
query language and it's it's not

00:12:19,320 --> 00:12:22,710
necessarily something that's very easy

00:12:20,370 --> 00:12:24,960
to get up and running on Cloud Foundry

00:12:22,710 --> 00:12:27,210
by itself it's totally possible and

00:12:24,960 --> 00:12:28,470
there are Bosch deployments for it you

00:12:27,210 --> 00:12:29,760
could get some decent experience but in

00:12:28,470 --> 00:12:31,860
general we were going for with metrics

00:12:29,760 --> 00:12:34,110
tor was making it as easy as possible to

00:12:31,860 --> 00:12:35,360
just add a component that works out of

00:12:34,110 --> 00:12:37,500
the box and doesn't require anything

00:12:35,360 --> 00:12:40,500
special to get all the metrics in and

00:12:37,500 --> 00:12:43,230
then data dog and there are other SAS

00:12:40,500 --> 00:12:45,840
services as well are actually a great

00:12:43,230 --> 00:12:47,370
way to get insight into some systems but

00:12:45,840 --> 00:12:49,830
the problem is that you you still have

00:12:47,370 --> 00:12:51,000
to add you know some sort of library or

00:12:49,830 --> 00:12:53,550
component that's going to push stuff the

00:12:51,000 --> 00:12:54,810
data dog and if I don't know if I'm sure

00:12:53,550 --> 00:12:56,790
other people in the room have used data

00:12:54,810 --> 00:12:59,250
dog at some scale it gets really

00:12:56,790 --> 00:13:00,660
expensive and it's easy to kind of get

00:12:59,250 --> 00:13:02,880
hooked and just be like I will use data

00:13:00,660 --> 00:13:04,410
dog for now it's fine and then you

00:13:02,880 --> 00:13:05,970
realize your your bill is just growing

00:13:04,410 --> 00:13:08,160
and growing growing they're doing well

00:13:05,970 --> 00:13:09,600
as a result as a company but it's it's

00:13:08,160 --> 00:13:11,160
kind of you go down this road where you

00:13:09,600 --> 00:13:13,230
become entirely dependent on another

00:13:11,160 --> 00:13:14,340
service and it kind of puts you further

00:13:13,230 --> 00:13:16,590
away from being able to get

00:13:14,340 --> 00:13:19,560
observability in your own your own

00:13:16,590 --> 00:13:21,000
system so and then any other time series

00:13:19,560 --> 00:13:22,560
database the stories basically going to

00:13:21,000 --> 00:13:23,970
be the same there are lots of things out

00:13:22,560 --> 00:13:25,829
the story is always changing but in

00:13:23,970 --> 00:13:27,180
general like I sort of metric so we want

00:13:25,829 --> 00:13:29,069
to make it as easy as possible to just

00:13:27,180 --> 00:13:33,629
drop it in and get some get some easy

00:13:29,069 --> 00:13:35,699
success so on the visualization side I'm

00:13:33,629 --> 00:13:38,939
just gonna plug Ravana pretty

00:13:35,699 --> 00:13:41,459
aggressively it's probably what almost

00:13:38,939 --> 00:13:42,959
everyone out there is already using but

00:13:41,459 --> 00:13:45,269
if you haven't used it before you're not

00:13:42,959 --> 00:13:47,360
sure what it is it's basically an

00:13:45,269 --> 00:13:49,110
open-source tool for you know building

00:13:47,360 --> 00:13:50,579
visualization dashboards you can

00:13:49,110 --> 00:13:52,740
configure a ton of stuff now it's also

00:13:50,579 --> 00:13:53,999
got some built-in alerting as of recent

00:13:52,740 --> 00:13:55,499
versions you can do data exploration

00:13:53,999 --> 00:13:58,230
kind of look at the data that's actually

00:13:55,499 --> 00:13:59,249
in there before you build graphs and it

00:13:58,230 --> 00:14:01,529
actually it's been around

00:13:59,249 --> 00:14:03,089
I don't probably five or six years and

00:14:01,529 --> 00:14:05,519
before that was actually it started out

00:14:03,089 --> 00:14:08,069
as a tool called Cabana that was part of

00:14:05,519 --> 00:14:10,800
elastic search so it's kind of been

00:14:08,069 --> 00:14:12,930
modified over time and is now

00:14:10,800 --> 00:14:14,189
essentially as good as you could

00:14:12,930 --> 00:14:16,350
possibly get in a data visualization

00:14:14,189 --> 00:14:18,389
tool and it's all open source they have

00:14:16,350 --> 00:14:19,829
some closed source offerings for for

00:14:18,389 --> 00:14:21,959
like organization management things like

00:14:19,829 --> 00:14:24,899
that but what you get for free with the

00:14:21,959 --> 00:14:26,220
open source tool is pretty fantastic it

00:14:24,899 --> 00:14:27,589
also lets you connect to other data

00:14:26,220 --> 00:14:29,970
sources so if you have other things like

00:14:27,589 --> 00:14:31,439
elastic search or in Flex DB or

00:14:29,970 --> 00:14:33,259
Prometheus you can kind of get all three

00:14:31,439 --> 00:14:35,790
data sources in one place which lets you

00:14:33,259 --> 00:14:38,490
build dashboards from from multiple

00:14:35,790 --> 00:14:40,889
sources and then one of the nice thing

00:14:38,490 --> 00:14:42,629
is there's an open ID plugin that'll use

00:14:40,889 --> 00:14:45,149
OAuth with you AAA so you can actually

00:14:42,629 --> 00:14:46,740
get some authentication built in with

00:14:45,149 --> 00:14:48,449
Cloud Foundry and metric store and

00:14:46,740 --> 00:14:51,360
you'll have to do anything crazy there's

00:14:48,449 --> 00:14:52,980
still some limitations to how you can

00:14:51,360 --> 00:14:54,600
manage data sources as part of the open

00:14:52,980 --> 00:14:55,920
source version but in general it works

00:14:54,600 --> 00:14:59,129
pretty well out of the box and you can

00:14:55,920 --> 00:15:00,480
just hook it up and get up and running

00:14:59,129 --> 00:15:02,339
and we've got a blog post that we put

00:15:00,480 --> 00:15:04,379
out a little while ago about this if you

00:15:02,339 --> 00:15:05,759
just I think if you look for you know

00:15:04,379 --> 00:15:07,500
pivotal metric store

00:15:05,759 --> 00:15:09,059
Griffen a-- it'll probably come up but

00:15:07,500 --> 00:15:12,720
kind of walks you through the steps of

00:15:09,059 --> 00:15:14,870
getting that set up and you know just as

00:15:12,720 --> 00:15:17,910
an example this is kind of a generic

00:15:14,870 --> 00:15:19,439
observability type dashboard so it's got

00:15:17,910 --> 00:15:21,779
some gauges up at the top so you can

00:15:19,439 --> 00:15:24,290
kind of see over a period of time how

00:15:21,779 --> 00:15:27,300
many logins or signups this system had

00:15:24,290 --> 00:15:29,129
memory utilization how the logins have

00:15:27,300 --> 00:15:30,870
changed over time so you see kind of in

00:15:29,129 --> 00:15:32,129
that second row of graphs there are some

00:15:30,870 --> 00:15:36,370
dips there so that might be something

00:15:32,129 --> 00:15:38,680
that there's you know an an SLO on where

00:15:36,370 --> 00:15:40,600
if Loggins dropped for a certain period

00:15:38,680 --> 00:15:41,830
of time that there is an alert and that

00:15:40,600 --> 00:15:43,450
somebody might go take a look at that

00:15:41,830 --> 00:15:46,090
but otherwise if it stays within a

00:15:43,450 --> 00:15:48,190
certain threshold everything's fine and

00:15:46,090 --> 00:15:50,500
this is kind of what you what you might

00:15:48,190 --> 00:15:52,960
expect to sees you start building out in

00:15:50,500 --> 00:15:55,390
observability dashboard kind of adding

00:15:52,960 --> 00:15:57,279
your own metrics that you really care

00:15:55,390 --> 00:16:02,260
about as you start to define your SOS an

00:15:57,279 --> 00:16:06,279
SOS so I kind of wanted to talk a little

00:16:02,260 --> 00:16:07,089
bit about prom QL which is because as I

00:16:06,279 --> 00:16:08,560
said we kind of took the whole

00:16:07,089 --> 00:16:10,510
Prometheus query engine so prom QL is

00:16:08,560 --> 00:16:11,830
the language that we've adopted just

00:16:10,510 --> 00:16:13,480
because it's so ubiquitous within the

00:16:11,830 --> 00:16:15,670
Prometheus ecosystem which is now

00:16:13,480 --> 00:16:17,080
becoming more a part of kubernetes

00:16:15,670 --> 00:16:19,920
deployments and things as well so people

00:16:17,080 --> 00:16:23,470
are generally pretty familiar with it so

00:16:19,920 --> 00:16:26,290
if you wanted to you could write your

00:16:23,470 --> 00:16:28,270
own queries against about against metric

00:16:26,290 --> 00:16:30,160
storage is using prom QL like you would

00:16:28,270 --> 00:16:31,420
with Prometheus or you could use a tool

00:16:30,160 --> 00:16:33,640
like Ravana and kind of build your

00:16:31,420 --> 00:16:35,290
queries there but this is the form that

00:16:33,640 --> 00:16:37,960
they're gonna take so it's essentially

00:16:35,290 --> 00:16:40,150
you have you're gonna have a metric name

00:16:37,960 --> 00:16:42,339
so in this case the first one it's CPU

00:16:40,150 --> 00:16:44,380
so that's just like a metric that is

00:16:42,339 --> 00:16:46,150
emitted that tells you what the CPU

00:16:44,380 --> 00:16:48,220
utilization is for a particular instance

00:16:46,150 --> 00:16:50,740
and then you can give it a set of

00:16:48,220 --> 00:16:53,680
filters so in this case we're filtering

00:16:50,740 --> 00:16:56,350
on the source ID of dopler so if you run

00:16:53,680 --> 00:16:57,700
this query this first style of query is

00:16:56,350 --> 00:17:01,240
called an instant query so it will give

00:16:57,700 --> 00:17:03,220
you the most recent value by default and

00:17:01,240 --> 00:17:04,929
it just gives you one it doesn't give

00:17:03,220 --> 00:17:07,780
you a range of times it just gives you

00:17:04,929 --> 00:17:08,920
now and you can move that to a previous

00:17:07,780 --> 00:17:10,780
point of time if you want to see what it

00:17:08,920 --> 00:17:12,010
was then but in general these instant

00:17:10,780 --> 00:17:13,329
queries are kind of what you would

00:17:12,010 --> 00:17:15,040
expect to see if you're getting like a

00:17:13,329 --> 00:17:17,079
gauge like if you go back to this

00:17:15,040 --> 00:17:18,790
previous screen a graph on alike those

00:17:17,079 --> 00:17:19,929
top ones all your all you're looking at

00:17:18,790 --> 00:17:24,520
is like what are the current number of

00:17:19,929 --> 00:17:26,380
logins and now so 174 or 273 so those

00:17:24,520 --> 00:17:28,840
type of queries will just give you an

00:17:26,380 --> 00:17:30,280
immediate results range queries on the

00:17:28,840 --> 00:17:33,280
other hand are kind of the other style

00:17:30,280 --> 00:17:35,440
of promise QL queries where if you give

00:17:33,280 --> 00:17:37,840
it a time range it will allow you to get

00:17:35,440 --> 00:17:40,420
a series of points and that's something

00:17:37,840 --> 00:17:42,429
that you would graph or do some other

00:17:40,420 --> 00:17:44,920
aggregation on but in general range

00:17:42,429 --> 00:17:46,780
queries you provide a time range and

00:17:44,920 --> 00:17:49,390
then this thing that's bolded here in

00:17:46,780 --> 00:17:49,970
brackets that's so that would tell it to

00:17:49,390 --> 00:17:51,919
give you

00:17:49,970 --> 00:17:53,360
five minute buckets so basically we give

00:17:51,919 --> 00:17:55,580
you points spaced five minutes apart

00:17:53,360 --> 00:17:58,490
over a given time range that you could

00:17:55,580 --> 00:18:00,860
graph or do other other processing on

00:17:58,490 --> 00:18:02,659
but in general those are kind of the two

00:18:00,860 --> 00:18:05,659
forms as you start working with with

00:18:02,659 --> 00:18:07,190
queries inside of pramukh ul and then as

00:18:05,659 --> 00:18:10,159
I mentioned on this last bullet point

00:18:07,190 --> 00:18:12,620
there are lots of other functions built

00:18:10,159 --> 00:18:15,140
into prom QL that you can use to try and

00:18:12,620 --> 00:18:16,700
do more analysis whether it's averaging

00:18:15,140 --> 00:18:19,179
or things like that

00:18:16,700 --> 00:18:21,530
and I'll look at a couple examples now

00:18:19,179 --> 00:18:24,020
so we've been doing a lot of playing

00:18:21,530 --> 00:18:25,580
around with metrics or internally and as

00:18:24,020 --> 00:18:26,750
we started talking to some customers and

00:18:25,580 --> 00:18:28,100
trying to see how they wanted to use it

00:18:26,750 --> 00:18:30,440
what kind of data they wanted to get out

00:18:28,100 --> 00:18:32,750
of it one thing that we got asked

00:18:30,440 --> 00:18:34,070
several times is well how can I see what

00:18:32,750 --> 00:18:37,250
applications are using the most

00:18:34,070 --> 00:18:39,200
resources you know I don't have any idea

00:18:37,250 --> 00:18:42,650
how to figure that out and some people

00:18:39,200 --> 00:18:43,640
have you know like interns going through

00:18:42,650 --> 00:18:44,690
and like scraping data and putting

00:18:43,640 --> 00:18:46,549
gather spreadsheets and try to figure

00:18:44,690 --> 00:18:47,659
out like pull all this data together to

00:18:46,549 --> 00:18:49,100
figure it out but really all this

00:18:47,659 --> 00:18:50,929
information comes through the firehose

00:18:49,100 --> 00:18:53,240
like we have a ton of information from

00:18:50,929 --> 00:18:56,390
Diego that we can put together in a

00:18:53,240 --> 00:18:58,340
query and figure out you know who's

00:18:56,390 --> 00:19:00,230
actually using how like how many AIS are

00:18:58,340 --> 00:19:02,390
my apps using so in this case so there's

00:19:00,230 --> 00:19:05,390
this is using a function called top K

00:19:02,390 --> 00:19:06,710
which will give you the top you know K

00:19:05,390 --> 00:19:10,120
results so in this case we're looking

00:19:06,710 --> 00:19:12,799
for the top five and then it will take

00:19:10,120 --> 00:19:15,080
sort descending so it's going to look at

00:19:12,799 --> 00:19:17,570
the count of the number of CPU metrics

00:19:15,080 --> 00:19:19,039
coming out and then it's going to sort

00:19:17,570 --> 00:19:21,559
them in descending order so it's going

00:19:19,039 --> 00:19:23,720
to have highest to lowest and then this

00:19:21,559 --> 00:19:26,270
bottom line here is telling it to group

00:19:23,720 --> 00:19:28,970
them by organization space and app name

00:19:26,270 --> 00:19:30,950
so that'll actually give you a per org

00:19:28,970 --> 00:19:32,360
space and app it will actually break it

00:19:30,950 --> 00:19:35,000
down so that they're all bundled in that

00:19:32,360 --> 00:19:36,710
way so for each app you'll you'll get

00:19:35,000 --> 00:19:38,179
who you it's going to do the grouping

00:19:36,710 --> 00:19:40,789
first and then it'll do the top on it so

00:19:38,179 --> 00:19:44,419
it's gonna take all the CPU metrics

00:19:40,789 --> 00:19:46,130
count them sort them by app and then

00:19:44,419 --> 00:19:48,169
it'll give you the top five so when you

00:19:46,130 --> 00:19:49,520
run this query it's gonna be a huge JSON

00:19:48,169 --> 00:19:52,130
thing out if you look at it and grifone

00:19:49,520 --> 00:19:54,980
I'd be much nicer to look at but this

00:19:52,130 --> 00:19:56,330
will actually give you that list of AIS

00:19:54,980 --> 00:19:58,280
and you can look at that you could graph

00:19:56,330 --> 00:20:01,070
it over time you could look for you know

00:19:58,280 --> 00:20:03,650
an app that's spiked suddenly or one

00:20:01,070 --> 00:20:05,780
that's dropped and this

00:20:03,650 --> 00:20:07,970
could be something where you know you

00:20:05,780 --> 00:20:09,500
could set an SLI our SLO on it could be

00:20:07,970 --> 00:20:11,060
something that you just have an alert

00:20:09,500 --> 00:20:13,430
condition on if you suddenly see that

00:20:11,060 --> 00:20:15,830
application is using way more resources

00:20:13,430 --> 00:20:17,030
than it should be but this is just one

00:20:15,830 --> 00:20:18,650
example of the kind of data that you

00:20:17,030 --> 00:20:20,270
could pull out a metric store that you

00:20:18,650 --> 00:20:21,440
actually get without having to do any

00:20:20,270 --> 00:20:23,240
work because we're just taking all the

00:20:21,440 --> 00:20:24,890
data from the firehose and pulling it in

00:20:23,240 --> 00:20:29,180
and giving you the ability to run

00:20:24,890 --> 00:20:32,300
queries on it okay and then a second

00:20:29,180 --> 00:20:35,900
example is if you want to look across

00:20:32,300 --> 00:20:38,900
all the Diego cells and see how much

00:20:35,900 --> 00:20:41,090
unused memory you have so this would be

00:20:38,900 --> 00:20:43,250
you know allocated and running instances

00:20:41,090 --> 00:20:44,990
that are just not being used so this

00:20:43,250 --> 00:20:46,430
one's a little bit hairier just because

00:20:44,990 --> 00:20:48,260
we're doing some some math so we're

00:20:46,430 --> 00:20:51,590
actually looking at the memory quota

00:20:48,260 --> 00:20:52,940
metric and then because of the way that

00:20:51,590 --> 00:20:54,770
the because of the way we're getting

00:20:52,940 --> 00:20:56,480
some of this data out instead of it

00:20:54,770 --> 00:21:00,080
being sourced it's coming out as

00:20:56,480 --> 00:21:01,250
exported job but this is saying look at

00:21:00,080 --> 00:21:04,460
the memory quota for all the Diego cells

00:21:01,250 --> 00:21:05,960
and then subtract the memory so in this

00:21:04,460 --> 00:21:08,720
case the memory metric is just memory

00:21:05,960 --> 00:21:11,360
you to utilize same thing with CPU it's

00:21:08,720 --> 00:21:12,770
assuming that it's the utilization so

00:21:11,360 --> 00:21:16,190
we're taking the quota and subtracting

00:21:12,770 --> 00:21:17,840
utilization and that gives you the

00:21:16,190 --> 00:21:19,700
amount and bytes so then we're just

00:21:17,840 --> 00:21:21,380
doing some quick math here to give us

00:21:19,700 --> 00:21:23,720
gigabytes so that's easier to look at

00:21:21,380 --> 00:21:25,760
but ideally you can run this across your

00:21:23,720 --> 00:21:27,230
entire foundation and see how

00:21:25,760 --> 00:21:28,520
over-allocated you are so how many more

00:21:27,230 --> 00:21:31,730
resources have you allocated than you're

00:21:28,520 --> 00:21:33,710
actually using so for some customers and

00:21:31,730 --> 00:21:35,780
some users of Cloud Foundry you want to

00:21:33,710 --> 00:21:37,280
be able to do this periodically or just

00:21:35,780 --> 00:21:39,080
have this be something that is a target

00:21:37,280 --> 00:21:42,620
to make sure that you're you know always

00:21:39,080 --> 00:21:44,530
using maybe 70% or 80% of your memory so

00:21:42,620 --> 00:21:47,870
you can tell if you need to scale up

00:21:44,530 --> 00:21:49,700
before before there's a problem but also

00:21:47,870 --> 00:21:51,860
not be wasting money in the mean time

00:21:49,700 --> 00:21:53,240
and once again this is stuff that just

00:21:51,860 --> 00:21:55,280
kind of exists automatically it's in the

00:21:53,240 --> 00:21:56,330
firehose metric store is going to store

00:21:55,280 --> 00:21:59,960
it and give you the ability to actually

00:21:56,330 --> 00:22:01,220
run run queries against it so a lot of a

00:21:59,960 --> 00:22:02,480
lot of the work here is just figuring

00:22:01,220 --> 00:22:06,440
out what's the information that you want

00:22:02,480 --> 00:22:08,990
to actually be alerting on and then kind

00:22:06,440 --> 00:22:12,200
of going into the little bit more detail

00:22:08,990 --> 00:22:13,280
about prom QL so once again as I said

00:22:12,200 --> 00:22:15,430
reason to permeate these query engine

00:22:13,280 --> 00:22:17,090
directly we're actually now also using

00:22:15,430 --> 00:22:18,770
the API

00:22:17,090 --> 00:22:21,590
so everything basically prometheus

00:22:18,770 --> 00:22:23,300
exposes where we're exposing as well but

00:22:21,590 --> 00:22:25,190
these are the primary end points for

00:22:23,300 --> 00:22:27,260
actually running your queries and kind

00:22:25,190 --> 00:22:28,880
of like looking at the data that that is

00:22:27,260 --> 00:22:30,470
available so those first two end points

00:22:28,880 --> 00:22:31,970
are the ones I discussed already and the

00:22:30,470 --> 00:22:34,730
two different kinds of queries instant

00:22:31,970 --> 00:22:36,950
queries and range queries there's an API

00:22:34,730 --> 00:22:38,450
endpoint that lets you actually find out

00:22:36,950 --> 00:22:39,920
what series exists over you doing some

00:22:38,450 --> 00:22:41,570
exploration in Ravana it's probably

00:22:39,920 --> 00:22:43,430
using this under the hood but you can

00:22:41,570 --> 00:22:47,270
pass some some labels and find out what

00:22:43,430 --> 00:22:49,160
series match those labels you can get a

00:22:47,270 --> 00:22:50,900
list of all the the label name so if

00:22:49,160 --> 00:22:52,580
you're looking at the sort of the tags

00:22:50,900 --> 00:22:53,810
so if you go back to these prom ql

00:22:52,580 --> 00:22:55,880
queries

00:22:53,810 --> 00:22:58,220
we've got like job equals diego cell

00:22:55,880 --> 00:22:59,870
that's a label export a job equals diego

00:22:58,220 --> 00:23:01,850
cell those are those are labels so you

00:22:59,870 --> 00:23:03,110
can kind of do some exploration and say

00:23:01,850 --> 00:23:04,520
like oh well what are the what are the

00:23:03,110 --> 00:23:07,160
things that my data is tagged with so

00:23:04,520 --> 00:23:09,200
that I can actually learn about those in

00:23:07,160 --> 00:23:10,340
filter then filter them down and once

00:23:09,200 --> 00:23:12,560
again if you're in grief on a-- and you

00:23:10,340 --> 00:23:13,790
do kind of an autocomplete as you're

00:23:12,560 --> 00:23:15,200
starting to fill in these labels these

00:23:13,790 --> 00:23:16,400
are the endpoints that would be using

00:23:15,200 --> 00:23:19,430
under the hood to kind of like get that

00:23:16,400 --> 00:23:21,830
data and then the last one is label

00:23:19,430 --> 00:23:23,750
values which you give it a label name

00:23:21,830 --> 00:23:25,910
such as export a job it would give you a

00:23:23,750 --> 00:23:28,550
list of all the possible values and I

00:23:25,910 --> 00:23:31,280
put asterisks next to these last two

00:23:28,550 --> 00:23:34,160
because we made one slight change in

00:23:31,280 --> 00:23:35,180
metric store there's some of the stuff

00:23:34,160 --> 00:23:37,040
that comes through the firehose that's

00:23:35,180 --> 00:23:40,040
really noisy in terms of labels so

00:23:37,040 --> 00:23:42,230
things like request request URI user

00:23:40,040 --> 00:23:43,340
agent things like that they're they're

00:23:42,230 --> 00:23:45,530
probably five or six things that come

00:23:43,340 --> 00:23:47,600
through and the the values that come

00:23:45,530 --> 00:23:48,710
through are just they're not anything

00:23:47,600 --> 00:23:51,440
you would ever filter on because they're

00:23:48,710 --> 00:23:53,870
so they're so noisy and sometimes you

00:23:51,440 --> 00:23:54,920
know the URIs or it can be twenty

00:23:53,870 --> 00:23:55,970
thousand characters and like that if

00:23:54,920 --> 00:23:58,880
it's just got a bunch of query

00:23:55,970 --> 00:24:02,060
parameters so we decided to make those

00:23:58,880 --> 00:24:04,520
non indexed for for memory usage

00:24:02,060 --> 00:24:05,810
purposes and just because it would it

00:24:04,520 --> 00:24:07,280
would potentially cause problems with

00:24:05,810 --> 00:24:08,450
visualization tools if you tried to list

00:24:07,280 --> 00:24:10,880
some of these things in an autocomplete

00:24:08,450 --> 00:24:12,470
so those are the only things you won't

00:24:10,880 --> 00:24:14,330
see in the label names and label values

00:24:12,470 --> 00:24:17,390
endpoints and I think it was it was a

00:24:14,330 --> 00:24:18,800
good usability choice that has ended up

00:24:17,390 --> 00:24:20,330
working out well but they're still

00:24:18,800 --> 00:24:22,370
stored there so if you did do a query

00:24:20,330 --> 00:24:23,960
for one of those things like request URI

00:24:22,370 --> 00:24:25,670
you could still get the data back you

00:24:23,960 --> 00:24:28,400
just won't be able to see it and part of

00:24:25,670 --> 00:24:29,900
the label names and values endpoints for

00:24:28,400 --> 00:24:32,390
autocomplete

00:24:29,900 --> 00:24:33,860
and then there's a ton of really good

00:24:32,390 --> 00:24:35,090
Prometheus documentation if you want to

00:24:33,860 --> 00:24:36,530
go look at it more it kind of talks

00:24:35,090 --> 00:24:39,770
about how these API endpoints work what

00:24:36,530 --> 00:24:42,020
the data formats are but if you if you

00:24:39,770 --> 00:24:44,559
just do prompt QL API there's a pretty

00:24:42,020 --> 00:24:50,210
good set of documentation out there and

00:24:44,559 --> 00:24:51,890
then kind of to recap so the big thing

00:24:50,210 --> 00:24:53,240
that that metric story gives you is the

00:24:51,890 --> 00:24:55,250
ability to take all this data that

00:24:53,240 --> 00:24:57,710
already exists in the firehose and pull

00:24:55,250 --> 00:25:00,200
it in and make it available to you

00:24:57,710 --> 00:25:02,540
through the prom with ul API so now if

00:25:00,200 --> 00:25:05,540
you use metric store you have an easy

00:25:02,540 --> 00:25:08,510
way to have access to that data run

00:25:05,540 --> 00:25:10,429
arbitrary arbitrary queries on it work

00:25:08,510 --> 00:25:13,190
with your teams internally and

00:25:10,429 --> 00:25:14,929
externally to define slis and SL O's and

00:25:13,190 --> 00:25:17,390
figure out okay now that I've got all

00:25:14,929 --> 00:25:18,530
this data what do I want to do with it

00:25:17,390 --> 00:25:22,640
what are the things that my users care

00:25:18,530 --> 00:25:25,070
about and what is what is like a set of

00:25:22,640 --> 00:25:27,670
initial s lis and SLO is that we can we

00:25:25,070 --> 00:25:29,929
can start to put in place and figure out

00:25:27,670 --> 00:25:31,700
how we're using the system how its

00:25:29,929 --> 00:25:35,720
performing and that gives you the

00:25:31,700 --> 00:25:37,309
ability to to improve and then being

00:25:35,720 --> 00:25:38,570
able to settle on a tool like graph on

00:25:37,309 --> 00:25:40,400
ax whatever it is that you end up using

00:25:38,570 --> 00:25:42,559
but have something that makes it easy

00:25:40,400 --> 00:25:45,020
for you to see how you're doing with

00:25:42,559 --> 00:25:46,970
those with those goals that you start to

00:25:45,020 --> 00:25:48,410
define and how the data is doing it kind

00:25:46,970 --> 00:25:49,520
of gives you and the rest of your team

00:25:48,410 --> 00:25:51,620
the ability to look at the stuff

00:25:49,520 --> 00:25:53,120
overtime and say like oh we deployed

00:25:51,620 --> 00:25:54,920
something and all this changed like

00:25:53,120 --> 00:25:56,929
let's go back and look in look into it

00:25:54,920 --> 00:25:58,370
now and metrics tour since it stores

00:25:56,929 --> 00:26:01,460
everything for a long period of time

00:25:58,370 --> 00:26:04,580
lets you have that for free basically

00:26:01,460 --> 00:26:07,760
and then as you as you start to set

00:26:04,580 --> 00:26:08,840
these SLS and SL O's up you can decide

00:26:07,760 --> 00:26:10,490
oh we thought this thing was really

00:26:08,840 --> 00:26:11,900
important but it turns out nobody cares

00:26:10,490 --> 00:26:14,750
about it so you can start to retire some

00:26:11,900 --> 00:26:16,910
of those those SL O's those objectives

00:26:14,750 --> 00:26:18,590
if you realize that you know maybe

00:26:16,910 --> 00:26:21,890
nobody cares when this thing actually

00:26:18,590 --> 00:26:23,690
drops below 80% and you can you can kind

00:26:21,890 --> 00:26:24,740
of come up with a tighter set of things

00:26:23,690 --> 00:26:26,179
and that's one of the things when you

00:26:24,740 --> 00:26:29,270
start to use other tools and you're not

00:26:26,179 --> 00:26:31,040
defining defining your actual objectives

00:26:29,270 --> 00:26:32,570
you can just end up with dashboard after

00:26:31,040 --> 00:26:34,880
dashboard of metrics that people don't

00:26:32,570 --> 00:26:36,110
care about so a good process here is to

00:26:34,880 --> 00:26:38,450
kind of review them periodically and

00:26:36,110 --> 00:26:40,490
just say oh hey you know these actually

00:26:38,450 --> 00:26:41,690
aren't serving us very well let's either

00:26:40,490 --> 00:26:42,610
come up with some new ones or just get

00:26:41,690 --> 00:26:45,279
rid of them

00:26:42,610 --> 00:26:49,570
and try to keep keep our observability

00:26:45,279 --> 00:26:50,200
scope as tight as possible and I think

00:26:49,570 --> 00:27:02,919
that's it

00:26:50,200 --> 00:27:04,330
questions yeah yeah you can so it you

00:27:02,919 --> 00:27:06,610
actually will just set it up as a

00:27:04,330 --> 00:27:09,220
Prometheus back-end and as I was saying

00:27:06,610 --> 00:27:13,080
there's a there's an OAuth plugin for

00:27:09,220 --> 00:27:14,950
Griffin oh right sorry the mic so the

00:27:13,080 --> 00:27:18,789
and I took down already

00:27:14,950 --> 00:27:20,919
the so I think the question was since it

00:27:18,789 --> 00:27:22,480
supports a prompt qlp I can we just use

00:27:20,919 --> 00:27:24,639
it directly as a back under Griffin the

00:27:22,480 --> 00:27:26,769
answer is yes you just set it up as a

00:27:24,639 --> 00:27:28,240
Prometheus back-end and you can use the

00:27:26,769 --> 00:27:29,620
the open ID plug-in that I was talking

00:27:28,240 --> 00:27:31,240
about in Griffin I said when you

00:27:29,620 --> 00:27:33,730
configure Griffin ax you can just set

00:27:31,240 --> 00:27:34,990
that that up as a kind of a UA plug-in

00:27:33,730 --> 00:27:36,960
and pointed at your UA a and that'll

00:27:34,990 --> 00:27:39,250
give you some authentication for free

00:27:36,960 --> 00:27:47,919
but yeah it just just treat it like a

00:27:39,250 --> 00:27:51,600
prom ql backend so how do you configure

00:27:47,919 --> 00:27:58,389
computation like there's a certain

00:27:51,600 --> 00:27:59,110
decreases its threshold and so so you're

00:27:58,389 --> 00:28:01,840
asking like how do you actually

00:27:59,110 --> 00:28:04,330
configure the alerts so in this case so

00:28:01,840 --> 00:28:06,279
Griffin ax has some basic alerting

00:28:04,330 --> 00:28:07,510
capability so in that case they're

00:28:06,279 --> 00:28:08,679
they're kind of two ways you can run for

00:28:07,510 --> 00:28:10,299
Fano ones just kind of like as a

00:28:08,679 --> 00:28:11,889
client-side application you can also run

00:28:10,299 --> 00:28:13,480
it as like a server-side so it's running

00:28:11,889 --> 00:28:16,029
all the time and you can configure

00:28:13,480 --> 00:28:18,039
alerts within Griffin ax and give it you

00:28:16,029 --> 00:28:20,080
can configure those those metrics that

00:28:18,039 --> 00:28:21,190
you're looking for and how it's gonna

00:28:20,080 --> 00:28:22,779
get triggered then at that point you

00:28:21,190 --> 00:28:24,070
need to figure out is it going to send

00:28:22,779 --> 00:28:25,750
it alert to slack or is it going to send

00:28:24,070 --> 00:28:27,190
something to Page or duty so that's kind

00:28:25,750 --> 00:28:29,080
of dependent on how you're the rest of

00:28:27,190 --> 00:28:31,269
your team wants to configure their their

00:28:29,080 --> 00:28:33,639
whole alerting and paging stack which is

00:28:31,269 --> 00:28:35,470
a completely it's a much bigger

00:28:33,639 --> 00:28:38,740
conversation how you want to actually

00:28:35,470 --> 00:28:40,690
get reported on those things but I would

00:28:38,740 --> 00:28:42,519
say try using Griffin alerting initially

00:28:40,690 --> 00:28:44,529
and then there are other tools that you

00:28:42,519 --> 00:28:46,210
could configure so I know like our some

00:28:44,529 --> 00:28:48,010
of our teams at pivotal do use data dog

00:28:46,210 --> 00:28:49,870
for that so we'll actually push alerts

00:28:48,010 --> 00:28:52,240
the data dog for the things that we

00:28:49,870 --> 00:28:53,770
really want to see and then set alerts

00:28:52,240 --> 00:28:55,360
there and that that goes to page or duty

00:28:53,770 --> 00:28:57,539
and then that alerts the rest of the

00:28:55,360 --> 00:28:57,539
team

00:29:02,140 --> 00:29:08,570
so we used Riemann which collects a

00:29:05,600 --> 00:29:10,040
matrix from the firehose so there is a

00:29:08,570 --> 00:29:11,780
closed script right I think you might be

00:29:10,040 --> 00:29:14,240
aware of it so you write a closer script

00:29:11,780 --> 00:29:15,830
even before it goes to the influx TV it

00:29:14,240 --> 00:29:18,110
sends the alert whenever it reaches a

00:29:15,830 --> 00:29:20,960
certain threshold so it does matrix door

00:29:18,110 --> 00:29:22,940
has so many mechanism on that because I

00:29:20,960 --> 00:29:24,500
don't have to create any other time the

00:29:22,940 --> 00:29:26,210
graph on a transport I just write a

00:29:24,500 --> 00:29:26,930
write down the closest cream for

00:29:26,210 --> 00:29:29,180
symmetric

00:29:26,930 --> 00:29:30,980
I got using the syntax yep so whenever

00:29:29,180 --> 00:29:33,410
it reaches some threshold because

00:29:30,980 --> 00:29:35,570
directly getting from the Pyro's and it

00:29:33,410 --> 00:29:37,790
always checks before it insert into the

00:29:35,570 --> 00:29:39,530
in flag stable yeah so the moment it

00:29:37,790 --> 00:29:42,020
reaches its threshold it immediately

00:29:39,530 --> 00:29:44,270
sends a lot so yeah edit email anything

00:29:42,020 --> 00:29:46,340
yeah yes yeah you so you can basically

00:29:44,270 --> 00:29:48,380
just use the prom qle API directly and

00:29:46,340 --> 00:29:49,910
you can query those metrics and you

00:29:48,380 --> 00:29:51,890
probably want to use that instant query

00:29:49,910 --> 00:29:53,120
end point the first one because that'll

00:29:51,890 --> 00:29:55,190
just give you the current value so

00:29:53,120 --> 00:29:57,050
anytime that script runs to get that

00:29:55,190 --> 00:29:59,660
value then you can just have a compare

00:29:57,050 --> 00:30:01,820
to a threshold and one other thing that

00:29:59,660 --> 00:30:03,380
I didn't mention in this talk and should

00:30:01,820 --> 00:30:05,270
have is that we've been doing some work

00:30:03,380 --> 00:30:06,740
there's another Prometheus component

00:30:05,270 --> 00:30:08,030
called alert manager which you can

00:30:06,740 --> 00:30:09,800
configure so that's we've actually been

00:30:08,030 --> 00:30:12,950
working on adding support for that and I

00:30:09,800 --> 00:30:14,720
think it may have actually landed off

00:30:12,950 --> 00:30:15,770
that check but keep an eye on that as

00:30:14,720 --> 00:30:17,690
well because that's something we're

00:30:15,770 --> 00:30:21,410
working on so you'll be able to

00:30:17,690 --> 00:30:23,210
configure metrics store to run some of

00:30:21,410 --> 00:30:25,220
those alert queries internally and that

00:30:23,210 --> 00:30:27,500
can push to an alert manager process

00:30:25,220 --> 00:30:28,730
which you can have configured as well so

00:30:27,500 --> 00:30:29,900
we don't have we don't have a lot of

00:30:28,730 --> 00:30:31,100
documentation on it yet but that's

00:30:29,900 --> 00:30:32,750
something we're working towards since we

00:30:31,100 --> 00:30:34,310
have so much compatibility with

00:30:32,750 --> 00:30:36,350
Prometheus we're able to do some of that

00:30:34,310 --> 00:30:38,300
stuff so configuration might be a little

00:30:36,350 --> 00:30:39,620
bit weird right now because Prometheus

00:30:38,300 --> 00:30:42,350
just takes like a static yeah mole to

00:30:39,620 --> 00:30:43,310
configure that stuff but within the next

00:30:42,350 --> 00:30:45,290
I would say within the next few weeks

00:30:43,310 --> 00:30:46,700
that should be in master and we'll

00:30:45,290 --> 00:30:48,500
probably cut a release a metric store as

00:30:46,700 --> 00:30:50,720
well that has that and talk a little bit

00:30:48,500 --> 00:30:52,220
more about that but definitely view have

00:30:50,720 --> 00:30:55,900
questions about that as well feel free

00:30:52,220 --> 00:30:55,900
to to talk to me after

00:30:58,870 --> 00:31:06,140
just thanks it's very good since I would

00:31:03,100 --> 00:31:11,420
waiting for that since long the matrix

00:31:06,140 --> 00:31:14,030
was a long waiting feature you can get

00:31:11,420 --> 00:31:16,760
it from firehose but you get into some

00:31:14,030 --> 00:31:19,580
many security issues right yeah if you

00:31:16,760 --> 00:31:22,100
want to get hole to F exporter fire hose

00:31:19,580 --> 00:31:23,840
exactly yep that's but now I have a

00:31:22,100 --> 00:31:26,120
question to this metric tanks is it's

00:31:23,840 --> 00:31:29,000
still one deployment you can deploy it

00:31:26,120 --> 00:31:32,270
per org so you can somehow say ok get me

00:31:29,000 --> 00:31:33,860
only metrics which are for this org so

00:31:32,270 --> 00:31:36,290
right now it'll connect and just get

00:31:33,860 --> 00:31:39,530
everything and then as you query it so

00:31:36,290 --> 00:31:41,570
it'll it uses UA a to do authentication

00:31:39,530 --> 00:31:43,940
and it does copy for some authorization

00:31:41,570 --> 00:31:45,500
so they'll use Cloud Controller to

00:31:43,940 --> 00:31:47,840
figure out what you're allowed to see so

00:31:45,500 --> 00:31:49,700
right now it just pulls one one set of

00:31:47,840 --> 00:31:52,610
metrics for the entire foundation and

00:31:49,700 --> 00:31:54,710
then per user as you authenticate with

00:31:52,610 --> 00:31:56,960
it it will let you see what you're

00:31:54,710 --> 00:31:58,520
allowed to see oh that's cool

00:31:56,960 --> 00:31:59,450
yeah and that's that's some we're still

00:31:58,520 --> 00:32:01,910
working on somewhere that's it but

00:31:59,450 --> 00:32:03,770
admins can see everything if you have a

00:32:01,910 --> 00:32:06,230
certain scope so you can see everything

00:32:03,770 --> 00:32:07,970
and then you know other users will be

00:32:06,230 --> 00:32:11,090
filtered based on what they're allowed

00:32:07,970 --> 00:32:13,010
to see so we we may do some work to try

00:32:11,090 --> 00:32:14,840
and make it easier to limit that but for

00:32:13,010 --> 00:32:17,420
now that's worked pretty well for us to

00:32:14,840 --> 00:32:19,730
just let people kind of use UA and Cloud

00:32:17,420 --> 00:32:21,170
Controller to kind of limit access and

00:32:19,730 --> 00:32:22,340
that I'm doing another talk right after

00:32:21,170 --> 00:32:24,230
this one that kind of talks a little bit

00:32:22,340 --> 00:32:25,460
more about the internals and I kind of

00:32:24,230 --> 00:32:27,050
go over some of the components and

00:32:25,460 --> 00:32:28,640
there's a thing that sits in front of

00:32:27,050 --> 00:32:31,540
metrics are called the auth proxy and

00:32:28,640 --> 00:32:34,580
that actually limits who can see what

00:32:31,540 --> 00:32:36,620
Thanks I'm I assumed no sensitive

00:32:34,580 --> 00:32:40,990
information just matrix just Patrick's

00:32:36,620 --> 00:32:40,990
yep okay thanks yeah no problem

00:32:50,190 --> 00:32:57,750
all right thank you everybody

00:32:52,350 --> 00:32:57,750

YouTube URL: https://www.youtube.com/watch?v=K6SIDbuY4BU


