Title: A Journey to the Center of the Cloud Foundry - Alex Ley & Ed King, Pivotal
Publication date: 2016-05-29
Playlist: Cloud Foundry Summit Santa Clara 2016
Description: 
	Come join us for a journey to the center of the Cloud Foundry! 

Ever wondered what happens once you hit return on a `cf push`? What is a Diego? Does Loggregator bite? Are CAPIâ€™s really as cute as they look? 

Alex & Ed will take you on a whistlestop tour of the major components and workflows in Cloud Foundry in this exciting adventure. 

Buckle up for this low budget production!

Ed King
Software Engineer, Pivotal
Ed has been working with Cloud Foundry and BOSH for several years now. He is currently working at Pivotal as an engineer on the Garden team. At last year's Cloud Foundry Summit, Ed presented "Cloud Foundry Logging & Metrics", a companion talk to a well-received series of blog posts he wrote under the same name. He has also co-delivered the BOSH training course at events in the past.

Alex Ley
Pivotal
Product Manager
London
Alex Ley works on the Cloud Foundry platform at Pivotal as a Product Manager. He is primarily focused on bringing data services to the Pivotal Cloud Foundry platform such as Redis, RabbitMQ and Cassandra. Alex has a passion for Cloud Foundry and the way we build software. Previously Alex has given talks at "muCon - The Microservices Conference 2015", "Continuous Lifecycle Conference 2016" , "London PaaS Meetup 2015", "Pivotal Open Lunch & Learn 2016".
Captions: 
	00:00:00,740 --> 00:00:09,650
deep below the surface of the cloud

00:00:05,090 --> 00:00:12,590
there is a hidden world of our

00:00:09,650 --> 00:00:19,939
applications one without fear of vendor

00:00:12,590 --> 00:00:25,780
local cabbies roam freely lager gaiters

00:00:19,939 --> 00:00:25,780
lurk a DA consistory

00:00:26,360 --> 00:00:29,990
this is the journey to the center of the

00:00:29,330 --> 00:00:32,219
cloud

00:00:29,990 --> 00:00:36,980
sound three

00:00:32,219 --> 00:00:36,980
prepare yourself as a team

00:00:37,570 --> 00:00:41,580
into the deepest darkness

00:00:44,350 --> 00:00:57,070
please do not feed them so yeah thank

00:00:56,109 --> 00:00:59,559
you very much for joining us this

00:00:57,070 --> 00:01:01,780
morning so my name is Alex Leigh

00:00:59,559 --> 00:01:03,309
I'm a product manager for pivotal in

00:01:01,780 --> 00:01:06,759
London I'm gonna be one of the guys on

00:01:03,309 --> 00:01:10,210
your journey and I met King I work on

00:01:06,759 --> 00:01:12,130
the garden team also in London so just

00:01:10,210 --> 00:01:13,539
to set expectations that was our entire

00:01:12,130 --> 00:01:16,869
production budget for this talk

00:01:13,539 --> 00:01:19,899
completely gone so you know stay if you

00:01:16,869 --> 00:01:21,909
want to so this all started when we

00:01:19,899 --> 00:01:24,280
found this map we're in the National

00:01:21,909 --> 00:01:25,690
History Museum in London and we were

00:01:24,280 --> 00:01:27,759
just going through some old books and it

00:01:25,690 --> 00:01:29,890
turned out we found a map that takes you

00:01:27,759 --> 00:01:31,440
right around the Cloud Foundry going

00:01:29,890 --> 00:01:33,369
through the center of the Cloud Foundry

00:01:31,440 --> 00:01:35,470
so you can see that we're gonna be

00:01:33,369 --> 00:01:37,869
starting up in the top left at the CLI

00:01:35,470 --> 00:01:39,819
Beach and then we're going to be going

00:01:37,869 --> 00:01:42,459
past the UAA through the cloud

00:01:39,819 --> 00:01:44,560
controller across the CC bridge we're

00:01:42,459 --> 00:01:47,020
gonna check out Diego Island here

00:01:44,560 --> 00:01:48,880
there's a nice garden there we're gonna

00:01:47,020 --> 00:01:49,869
check also look at the root alligator

00:01:48,880 --> 00:01:53,200
and the blobstore

00:01:49,869 --> 00:01:55,630
now take us right back to the beach so

00:01:53,200 --> 00:01:58,270
the start of our journey we're going to

00:01:55,630 --> 00:02:04,420
be using the CLI so what's the end line

00:01:58,270 --> 00:02:07,060
interface so this is a primary way that

00:02:04,420 --> 00:02:08,470
you interact with Cloud Foundry and so

00:02:07,060 --> 00:02:11,019
has the commands for both users and

00:02:08,470 --> 00:02:14,079
operators and we're gonna use this to

00:02:11,019 --> 00:02:15,700
guide our journey and so you can see

00:02:14,079 --> 00:02:17,859
here that the CLI has a plug-in

00:02:15,700 --> 00:02:19,870
interface as well so you can extend the

00:02:17,859 --> 00:02:22,030
CLI with plugins there's quite a good

00:02:19,870 --> 00:02:25,000
marketplace for these with community and

00:02:22,030 --> 00:02:28,150
Cloud Foundry repositories so what do we

00:02:25,000 --> 00:02:29,859
first need to do on our journey we first

00:02:28,150 --> 00:02:32,680
need to log in and authenticate with the

00:02:29,859 --> 00:02:34,030
system and so you're going to see a lot

00:02:32,680 --> 00:02:36,730
of this from our talk we'll be jumping

00:02:34,030 --> 00:02:38,320
up to the CLI to see what the user would

00:02:36,730 --> 00:02:40,989
be seen as we're going through our

00:02:38,320 --> 00:02:42,760
journey and so you can see here that we

00:02:40,989 --> 00:02:44,500
need to target our selected platform and

00:02:42,760 --> 00:02:46,989
here we're just going to pivot all's

00:02:44,500 --> 00:02:48,459
public cloud foundry and then you need

00:02:46,989 --> 00:02:50,350
to authenticate so there's two ways you

00:02:48,459 --> 00:02:54,160
can do this the username and password as

00:02:50,350 --> 00:02:55,650
usual or you can use SSO so we do this

00:02:54,160 --> 00:03:01,110
to a component

00:02:55,650 --> 00:03:04,079
I could use the authentication user

00:03:01,110 --> 00:03:06,120
account an authentication service and so

00:03:04,079 --> 00:03:07,709
this is the primary authentication

00:03:06,120 --> 00:03:10,829
system you'll see used across most cloud

00:03:07,709 --> 00:03:12,959
boundaries and the CLI receives the UA

00:03:10,829 --> 00:03:13,920
information from the from a component

00:03:12,959 --> 00:03:15,569
with the cloud controller which we're

00:03:13,920 --> 00:03:17,689
gonna take a look at next

00:03:15,569 --> 00:03:21,480
and this performs kind of an OAuth dance

00:03:17,689 --> 00:03:25,439
and so it's based on a auth - and it can

00:03:21,480 --> 00:03:27,139
back onto LDAP SC I am and open ID and

00:03:25,439 --> 00:03:29,519
this is actually built as a spring MVC

00:03:27,139 --> 00:03:31,620
scalable web app it's one of the only

00:03:29,519 --> 00:03:35,010
Java components left in Cloud Foundry at

00:03:31,620 --> 00:03:36,359
the moment quite rare so so let's just

00:03:35,010 --> 00:03:38,190
take a look at this workflow it's quite

00:03:36,359 --> 00:03:39,569
straightforward so we'll send a login

00:03:38,190 --> 00:03:42,569
request from the CLI to the cloud

00:03:39,569 --> 00:03:44,519
controller we get back the UA details of

00:03:42,569 --> 00:03:46,470
where to authenticate against then we

00:03:44,519 --> 00:03:50,180
can send an authorization request to the

00:03:46,470 --> 00:03:52,560
UA a and we get back an access token

00:03:50,180 --> 00:03:54,269
right so now we're authenticated we

00:03:52,560 --> 00:03:57,120
really need an application so we're

00:03:54,269 --> 00:03:59,310
going to be using a spring music example

00:03:57,120 --> 00:04:02,040
app and so you can see here it's a

00:03:59,310 --> 00:04:03,840
groovy application we specify a manifest

00:04:02,040 --> 00:04:05,310
it's pretty straightforward and say

00:04:03,840 --> 00:04:08,190
we're gonna be using this to guide us

00:04:05,310 --> 00:04:10,319
through our journey so let's take a look

00:04:08,190 --> 00:04:12,060
we want to have a manifest to describe

00:04:10,319 --> 00:04:13,949
what the application needs to look like

00:04:12,060 --> 00:04:15,510
when it's running in Cloud Foundry so

00:04:13,949 --> 00:04:17,519
you can see we give a name we give it

00:04:15,510 --> 00:04:19,560
how much memory we need and we also

00:04:17,519 --> 00:04:21,510
specify how many instances we want

00:04:19,560 --> 00:04:22,979
running so in this case we're saying we

00:04:21,510 --> 00:04:25,020
want three instances of our app running

00:04:22,979 --> 00:04:26,460
and we're using this feature as well to

00:04:25,020 --> 00:04:28,500
have a random route so that we avoid

00:04:26,460 --> 00:04:30,090
like collisions because we need a way to

00:04:28,500 --> 00:04:31,710
access our application and so this is

00:04:30,090 --> 00:04:36,990
going to our Cloud Foundry to find a

00:04:31,710 --> 00:04:38,610
unique name to run our app as so now we

00:04:36,990 --> 00:04:41,130
need to get ready to push this into

00:04:38,610 --> 00:04:42,599
Cloud Foundry so as most people I guess

00:04:41,130 --> 00:04:46,470
everyone here must have run CF push

00:04:42,599 --> 00:04:48,090
right yeah good okay so you're very

00:04:46,470 --> 00:04:49,740
familiar with this command and so what

00:04:48,090 --> 00:04:51,900
we're going to be doing is when we run

00:04:49,740 --> 00:04:54,300
CF push it creates a record in the cloud

00:04:51,900 --> 00:04:56,310
controller database and the cloud

00:04:54,300 --> 00:04:58,020
controller will then keep track of your

00:04:56,310 --> 00:05:00,960
application and record this is the

00:04:58,020 --> 00:05:03,389
desired state so let's take a look back

00:05:00,960 --> 00:05:05,550
at the map so you can see we've gone

00:05:03,389 --> 00:05:07,560
through through got past the UA a we're

00:05:05,550 --> 00:05:08,990
onto a cloud controller which is on

00:05:07,560 --> 00:05:11,300
Kathy land

00:05:08,990 --> 00:05:13,430
and so let's take a look at a bit more

00:05:11,300 --> 00:05:19,460
detail about the cloud controller cloud

00:05:13,430 --> 00:05:20,900
controller so this component is the core

00:05:19,460 --> 00:05:24,020
entry point and it provides a set of

00:05:20,900 --> 00:05:27,290
restful api s these api's are used by

00:05:24,020 --> 00:05:29,180
app developers and operators and it's

00:05:27,290 --> 00:05:30,980
really a huge amount of endpoints you

00:05:29,180 --> 00:05:34,670
can see that's going under a big rewrite

00:05:30,980 --> 00:05:36,320
at the moment going to a v3 API the

00:05:34,670 --> 00:05:38,990
cloud controller also interfaces with

00:05:36,320 --> 00:05:43,850
your external services and it uses a

00:05:38,990 --> 00:05:46,550
broker API specification to do this so

00:05:43,850 --> 00:05:49,220
right next we need to get a way to

00:05:46,550 --> 00:05:51,470
access the application so we need a

00:05:49,220 --> 00:05:53,270
route so you can see here that you know

00:05:51,470 --> 00:05:57,230
Cloud Foundry is generated a nicely

00:05:53,270 --> 00:06:00,380
named random route and so how does your

00:05:57,230 --> 00:06:03,770
application then get messages to it so

00:06:00,380 --> 00:06:05,330
we use a routine release this routine

00:06:03,770 --> 00:06:08,690
release contains a collection components

00:06:05,330 --> 00:06:11,300
you can see here we've got a go Rooter

00:06:08,690 --> 00:06:14,210
and a TCP Rooter so this supports HTTP

00:06:11,300 --> 00:06:16,340
and TCP routing and you can see on the

00:06:14,210 --> 00:06:18,110
right hand side we've got the route

00:06:16,340 --> 00:06:20,990
emitters and these will be sending

00:06:18,110 --> 00:06:26,330
information to the rooters to make make

00:06:20,990 --> 00:06:30,380
them aware of your application ok so

00:06:26,330 --> 00:06:32,240
this component is uses it's like it

00:06:30,380 --> 00:06:35,900
offers HTTP routine for Cloud Foundry

00:06:32,240 --> 00:06:37,370
effectively and it uses a component you

00:06:35,900 --> 00:06:40,670
can see in the middle called Nats to

00:06:37,370 --> 00:06:43,040
advertise its availability and so

00:06:40,670 --> 00:06:45,140
consumers have to put messages onto Nats

00:06:43,040 --> 00:06:47,810
to register with the go Rooter

00:06:45,140 --> 00:06:49,130
periodically otherwise the go Rooter

00:06:47,810 --> 00:06:51,860
will prune it from its routing tables

00:06:49,130 --> 00:06:53,870
and then you know assume that your

00:06:51,860 --> 00:06:55,760
application is offline and this stops

00:06:53,870 --> 00:06:56,720
people from getting you know you know

00:06:55,760 --> 00:06:59,150
errors when trying to reach your

00:06:56,720 --> 00:07:03,230
application and it uses simple

00:06:59,150 --> 00:07:06,050
round-robin load balancing so next up

00:07:03,230 --> 00:07:08,390
we've got the TCP Rooter so this is you

00:07:06,050 --> 00:07:10,460
know for TCP based apps you've given a

00:07:08,390 --> 00:07:12,530
reserved port and route on a shared

00:07:10,460 --> 00:07:17,000
domain you can see that actually uses

00:07:12,530 --> 00:07:18,980
haitch a proxy inside and so this offers

00:07:17,000 --> 00:07:21,290
us a way to kind of move away from the

00:07:18,980 --> 00:07:22,639
Nats message bus and move towards a

00:07:21,290 --> 00:07:25,189
routing API

00:07:22,639 --> 00:07:28,099
so the rooty api is currently an

00:07:25,189 --> 00:07:30,439
experimental stage and you can check it

00:07:28,099 --> 00:07:32,689
out there's lots of good Doc's on the on

00:07:30,439 --> 00:07:35,990
the repo as well but this uses the

00:07:32,689 --> 00:07:37,939
publish/subscribe model but over HTTP so

00:07:35,990 --> 00:07:40,009
this allows us yeah like I said to move

00:07:37,939 --> 00:07:41,990
away from that but works in the same way

00:07:40,009 --> 00:07:45,199
where stale routes are pruned from the

00:07:41,990 --> 00:07:47,270
routing tables and so you can get

00:07:45,199 --> 00:07:49,279
started really easily by using this RTR

00:07:47,270 --> 00:07:54,560
client you can see the link there at the

00:07:49,279 --> 00:07:55,759
bottom so now we have our you know kind

00:07:54,560 --> 00:07:59,120
of application registered with Cloud

00:07:55,759 --> 00:08:02,330
Foundry we've got our route but next we

00:07:59,120 --> 00:08:03,740
need to upload the files right so you

00:08:02,330 --> 00:08:06,229
can see here that we're uploading all of

00:08:03,740 --> 00:08:07,819
the files in the directory and we're

00:08:06,229 --> 00:08:09,710
going to be passing these through to the

00:08:07,819 --> 00:08:10,909
cloud controller so the cloud controller

00:08:09,710 --> 00:08:13,580
obviously needs somewhere to store these

00:08:10,909 --> 00:08:15,529
files so in Cloud Foundry you know we

00:08:13,580 --> 00:08:18,800
normally attach a blob store dare you

00:08:15,529 --> 00:08:23,419
enter the mob store Caverns

00:08:18,800 --> 00:08:25,639
so yeah this effectively is where we

00:08:23,419 --> 00:08:27,169
store all of your application files and

00:08:25,639 --> 00:08:30,460
so it has three main concepts you've got

00:08:27,169 --> 00:08:32,630
resources app packages and droplets

00:08:30,460 --> 00:08:34,610
resources the files they're uploaded to

00:08:32,630 --> 00:08:37,459
the cloud controller and we track a

00:08:34,610 --> 00:08:39,349
unique sha you then have app packages

00:08:37,459 --> 00:08:42,260
and these are unstaged files that

00:08:39,349 --> 00:08:44,449
represent an application and finally you

00:08:42,260 --> 00:08:46,940
have droplets and this is a result of

00:08:44,449 --> 00:08:48,230
taking all of those files and getting

00:08:46,940 --> 00:08:50,510
them running ready to run on Cloud

00:08:48,230 --> 00:08:52,760
Foundry and so you might have seen a

00:08:50,510 --> 00:08:54,550
talk yesterday about the bit service and

00:08:52,760 --> 00:08:57,589
so this is underway to kind of extract

00:08:54,550 --> 00:09:01,670
the blobstore logic from the cloud

00:08:57,589 --> 00:09:03,890
controller so let's take a look at what

00:09:01,670 --> 00:09:05,899
the kind of workflow is for uploading an

00:09:03,890 --> 00:09:08,300
app so you can see to start with from

00:09:05,899 --> 00:09:10,190
the CLI we will send a resource map

00:09:08,300 --> 00:09:12,019
request to the cloud controller this

00:09:10,190 --> 00:09:14,240
will then go to the blob store and check

00:09:12,019 --> 00:09:15,589
for this unique chars so what you're

00:09:14,240 --> 00:09:17,300
saying is you're sending a list of all

00:09:15,589 --> 00:09:21,199
the shards for your files and you get

00:09:17,300 --> 00:09:23,149
back your matches and then based on the

00:09:21,199 --> 00:09:25,760
difference you're going to be uploading

00:09:23,149 --> 00:09:28,610
the changes or new files to cloud

00:09:25,760 --> 00:09:31,660
controller and this puts it into the

00:09:28,610 --> 00:09:31,660
blob store so it's quite straightforward

00:09:31,959 --> 00:09:36,259
so next up we need to start looking at

00:09:34,970 --> 00:09:37,519
how we're going to get our application

00:09:36,259 --> 00:09:39,499
because we've just pushed the raw source

00:09:37,519 --> 00:09:40,819
code and so we need a ways to turn this

00:09:39,499 --> 00:09:42,979
into something that runs in Cloud

00:09:40,819 --> 00:09:45,529
Foundry and so you can see here from the

00:09:42,979 --> 00:09:47,509
CL ice perspective you'll be seeing an

00:09:45,529 --> 00:09:49,879
output of this bill PACs downloading

00:09:47,509 --> 00:09:51,649
bill PACs downloading bill PACs and so

00:09:49,879 --> 00:09:53,779
what is this you might think so this is

00:09:51,649 --> 00:09:55,339
how we take your application code and

00:09:53,779 --> 00:09:59,419
build it into something that can run on

00:09:55,339 --> 00:10:00,799
the platform so you can see here bill

00:09:59,419 --> 00:10:03,289
packs really allow you to have a

00:10:00,799 --> 00:10:05,629
repeatable process for compiling and

00:10:03,289 --> 00:10:07,009
running your code on Cloud Foundry it

00:10:05,629 --> 00:10:09,139
means the platform can worry about the

00:10:07,009 --> 00:10:10,729
operational concerns especially on the

00:10:09,139 --> 00:10:13,549
underlying operating system and you just

00:10:10,729 --> 00:10:15,279
get to focus on your code so again we

00:10:13,549 --> 00:10:17,749
have a three step process for bill PACs

00:10:15,279 --> 00:10:20,389
to start with you have the detect phase

00:10:17,749 --> 00:10:22,759
so Cloud Foundry will run every bill

00:10:20,389 --> 00:10:25,039
PACs detects script until it finds a

00:10:22,759 --> 00:10:26,929
match when it's found a matching bill

00:10:25,039 --> 00:10:28,549
PAC it will then go through a compile

00:10:26,929 --> 00:10:30,529
phase where it grabs your dependencies

00:10:28,549 --> 00:10:32,749
compiles them into an artifact and then

00:10:30,529 --> 00:10:34,970
the release phase is when it gets it

00:10:32,749 --> 00:10:38,419
ready to be extracted into a droplet

00:10:34,970 --> 00:10:40,609
which we're going to a bit more later so

00:10:38,419 --> 00:10:42,559
here's an example of how we've you know

00:10:40,609 --> 00:10:44,329
running a Java app and so you can see

00:10:42,559 --> 00:10:45,649
that we pushed has been detected as Java

00:10:44,329 --> 00:10:47,809
and then we've downloaded the

00:10:45,649 --> 00:10:51,459
dependencies and packaged it up ready

00:10:47,809 --> 00:10:51,459
for extraction to run on Cloud Foundry

00:10:53,289 --> 00:10:59,059
all right thank you very much Alex okay

00:10:56,959 --> 00:11:02,959
so let's just briefly recap our journey

00:10:59,059 --> 00:11:05,389
so far so far we have created an app we

00:11:02,959 --> 00:11:07,160
have created a route for that app and

00:11:05,389 --> 00:11:10,129
we've also uploaded all of the source

00:11:07,160 --> 00:11:12,619
code into Cloud Foundry so what happens

00:11:10,129 --> 00:11:14,689
next well in order to answer that

00:11:12,619 --> 00:11:16,549
question let's just take a step back and

00:11:14,689 --> 00:11:18,439
think about exactly what it is that

00:11:16,549 --> 00:11:20,679
Cloud Foundry is going to do when it

00:11:18,439 --> 00:11:23,299
receives our application pushes and

00:11:20,679 --> 00:11:25,429
really Cloud Foundry has two key

00:11:23,299 --> 00:11:27,230
responsibilities the first

00:11:25,429 --> 00:11:29,509
responsibility is to take our

00:11:27,230 --> 00:11:32,629
application source code and compile that

00:11:29,509 --> 00:11:34,809
down into some artifacts that can then

00:11:32,629 --> 00:11:37,179
be scheduled to run on the platform and

00:11:34,809 --> 00:11:40,279
that's exactly the second responsibility

00:11:37,179 --> 00:11:42,619
we need to take the output of that build

00:11:40,279 --> 00:11:44,809
compile process and actually schedule it

00:11:42,619 --> 00:11:47,989
to run and ensure that it continues to

00:11:44,809 --> 00:11:49,730
run until we tell it to stop and then of

00:11:47,989 --> 00:11:51,829
course there are also all of the

00:11:49,730 --> 00:11:55,970
traversable responsibilities such as

00:11:51,829 --> 00:11:59,230
logging metrics etc etc so what exactly

00:11:55,970 --> 00:12:01,880
does this look like inside Cloud Foundry

00:11:59,230 --> 00:12:05,180
well the first process that compile

00:12:01,880 --> 00:12:08,089
process is known as staging and staging

00:12:05,180 --> 00:12:11,540
looks like this first of all we take our

00:12:08,089 --> 00:12:13,970
application source code we then combine

00:12:11,540 --> 00:12:15,620
that together with a build pack which as

00:12:13,970 --> 00:12:17,630
Alex said provides the runtime

00:12:15,620 --> 00:12:21,079
dependencies and we compile that

00:12:17,630 --> 00:12:22,699
together into some artifacts but in

00:12:21,079 --> 00:12:24,589
order to actually do this we need to

00:12:22,699 --> 00:12:26,810
have somewhere to actually run that

00:12:24,589 --> 00:12:29,120
compile step we need to have a root

00:12:26,810 --> 00:12:32,000
filesystem or or an operating system and

00:12:29,120 --> 00:12:36,470
in Cloud Foundry terminology this root

00:12:32,000 --> 00:12:37,910
filesystem is known as a stack and every

00:12:36,470 --> 00:12:40,279
deployment of Cloud Foundry will come

00:12:37,910 --> 00:12:42,740
with a default stack typically this

00:12:40,279 --> 00:12:44,209
tends to be a bun too but it could just

00:12:42,740 --> 00:12:48,500
as easily it would be something else as

00:12:44,209 --> 00:12:51,620
well and so what happens is we create a

00:12:48,500 --> 00:12:54,230
container using that stack that default

00:12:51,620 --> 00:12:57,769
stack as the root filesystem for this

00:12:54,230 --> 00:12:59,660
process once we've got these three

00:12:57,769 --> 00:13:04,069
components together we then run the

00:12:59,660 --> 00:13:06,560
compile step and we output a droplet so

00:13:04,069 --> 00:13:08,630
this is the immutable artifact that we

00:13:06,560 --> 00:13:11,420
can actually scheduled to run on our

00:13:08,630 --> 00:13:14,959
Cloud Foundry platform so what does that

00:13:11,420 --> 00:13:16,730
actually look like well next up we

00:13:14,959 --> 00:13:18,860
create ourselves another container and

00:13:16,730 --> 00:13:20,690
this container is based on the exact

00:13:18,860 --> 00:13:22,760
same stack that we use to actually

00:13:20,690 --> 00:13:24,620
compile the artifact in the first place

00:13:22,760 --> 00:13:25,940
this is how we can guarantee that it's

00:13:24,620 --> 00:13:28,790
going to run successfully and how it has

00:13:25,940 --> 00:13:30,889
all of its dependencies available so we

00:13:28,790 --> 00:13:33,319
create a new container and we simply

00:13:30,889 --> 00:13:36,319
copy the droplet into the container and

00:13:33,319 --> 00:13:37,880
we say start start running and this is

00:13:36,319 --> 00:13:40,120
really really nice because we've got a

00:13:37,880 --> 00:13:42,860
very very clear separation here between

00:13:40,120 --> 00:13:44,810
the developers who are responsible for

00:13:42,860 --> 00:13:46,850
creating the source code and the droplet

00:13:44,810 --> 00:13:48,889
and the operators who are responsible

00:13:46,850 --> 00:13:51,980
for the underlying file system it's a

00:13:48,889 --> 00:13:53,510
very clear contract and this approach to

00:13:51,980 --> 00:13:55,250
running your applications is really nice

00:13:53,510 --> 00:13:59,930
because it means that things like

00:13:55,250 --> 00:14:01,959
scaling is also very very easy here is a

00:13:59,930 --> 00:14:03,740
typical scale command in cloud foundry

00:14:01,959 --> 00:14:06,950
the - either

00:14:03,740 --> 00:14:09,470
scale it up to eight instances what does

00:14:06,950 --> 00:14:14,510
this look like well rather than creating

00:14:09,470 --> 00:14:16,580
one container we create eight and then

00:14:14,510 --> 00:14:19,640
all we need to do is copy our droplet on

00:14:16,580 --> 00:14:22,460
to each of those containers and tell

00:14:19,640 --> 00:14:24,350
them all to start very very nice and

00:14:22,460 --> 00:14:26,170
simple model there and I think that's

00:14:24,350 --> 00:14:29,570
one of the reasons the Cloud Foundry is

00:14:26,170 --> 00:14:33,890
really excelling at this nd running the

00:14:29,570 --> 00:14:35,630
applications here okay so we've got an

00:14:33,890 --> 00:14:36,860
idea of what exactly Cloud Foundry is

00:14:35,630 --> 00:14:39,250
trying to do when we push our

00:14:36,860 --> 00:14:41,990
applications how exactly does it do this

00:14:39,250 --> 00:14:44,150
and in order to answer that we are going

00:14:41,990 --> 00:14:50,120
to need to cross over the CC bridge and

00:14:44,150 --> 00:14:51,560
into Diego Island Oh hail Diego just

00:14:50,120 --> 00:14:54,560
making sure you're all still awake and

00:14:51,560 --> 00:14:56,450
sir okay so what is Diego

00:14:54,560 --> 00:14:58,130
well Diego is the component of cloud

00:14:56,450 --> 00:15:01,790
foundry that actually provides that

00:14:58,130 --> 00:15:04,640
staging and runtime support at its core

00:15:01,790 --> 00:15:07,490
Diego is a scheduler and it's able to

00:15:04,640 --> 00:15:09,740
schedule two types of workload tasks and

00:15:07,490 --> 00:15:11,660
LR peas and I'm going to touch on those

00:15:09,740 --> 00:15:13,820
in just a moment but one of the other

00:15:11,660 --> 00:15:15,820
features Diego provides is it can take

00:15:13,820 --> 00:15:19,130
all of the incoming workload and

00:15:15,820 --> 00:15:25,370
optimally distribute it across a cluster

00:15:19,130 --> 00:15:27,110
of cell components so a Diego task this

00:15:25,370 --> 00:15:30,410
is a workload that is guaranteed to be

00:15:27,110 --> 00:15:32,720
run at most once so this is perfectly

00:15:30,410 --> 00:15:34,520
suited to the staging process as we only

00:15:32,720 --> 00:15:38,080
really ever want that to happen once or

00:15:34,520 --> 00:15:40,220
at least once per push of your code

00:15:38,080 --> 00:15:44,720
another example there might be a one-off

00:15:40,220 --> 00:15:47,030
database migration for example a Diego

00:15:44,720 --> 00:15:49,460
lrp on the other hand these stand for

00:15:47,030 --> 00:15:50,840
long-running processes and this is what

00:15:49,460 --> 00:15:54,020
your applications are actually going to

00:15:50,840 --> 00:15:57,770
end up running as with under indeed in

00:15:54,020 --> 00:16:00,320
the Diego cluster so Diego provides some

00:15:57,770 --> 00:16:02,960
additional features here it is able to

00:16:00,320 --> 00:16:05,060
distribute the lrp instances across your

00:16:02,960 --> 00:16:07,280
cluster of cells and this is nice

00:16:05,060 --> 00:16:09,830
because it means if we lose one of the

00:16:07,280 --> 00:16:12,110
cells for whatever reason perhaps the

00:16:09,830 --> 00:16:14,570
virtual machine crashes or all goes away

00:16:12,110 --> 00:16:17,340
and your application can still continue

00:16:14,570 --> 00:16:20,240
to run as other instances of the

00:16:17,340 --> 00:16:22,680
P will be distributed to other cells and

00:16:20,240 --> 00:16:25,830
it also provides us with some fairly

00:16:22,680 --> 00:16:28,110
nice fairly nice health checking so if

00:16:25,830 --> 00:16:29,970
your application instance crashes for

00:16:28,110 --> 00:16:30,800
whatever reason perhaps it runs out of

00:16:29,970 --> 00:16:32,730
memory

00:16:30,800 --> 00:16:39,330
delia can't detect that and

00:16:32,730 --> 00:16:40,920
automatically restart it ok so we now

00:16:39,330 --> 00:16:44,700
know what staging is and we know what

00:16:40,920 --> 00:16:48,960
Diego is how exactly does Diego stage

00:16:44,700 --> 00:16:50,940
our applications well first off the

00:16:48,960 --> 00:16:53,340
cloud controller sends a request into

00:16:50,940 --> 00:16:55,920
the stage' and the stage' sits there

00:16:53,340 --> 00:16:59,700
listens for these requests and converts

00:16:55,920 --> 00:17:03,900
them into a Diego task in this case it's

00:16:59,700 --> 00:17:05,580
going to be a staging task it then sends

00:17:03,900 --> 00:17:08,460
that off to a component called the BBS

00:17:05,580 --> 00:17:11,160
the BBS stands for the bulletin board

00:17:08,460 --> 00:17:13,110
service and this is really Diego's cool

00:17:11,160 --> 00:17:16,950
Orchestrator and sort of the central

00:17:13,110 --> 00:17:19,650
data store of our cluster so the BBS

00:17:16,950 --> 00:17:22,770
receives this staging task and it

00:17:19,650 --> 00:17:27,090
persists it to its database this

00:17:22,770 --> 00:17:29,040
currently backed by at CD so at this

00:17:27,090 --> 00:17:31,830
point Diego knows that there is a

00:17:29,040 --> 00:17:35,070
staging task that it needs to work that

00:17:31,830 --> 00:17:37,740
it needs to perform but it doesn't know

00:17:35,070 --> 00:17:39,060
where it can actually perform that so we

00:17:37,740 --> 00:17:41,220
have an entire cluster of cells

00:17:39,060 --> 00:17:42,810
available to us at the moment any one of

00:17:41,220 --> 00:17:45,930
which might be suitable for running this

00:17:42,810 --> 00:17:49,400
workload how do we determine which cells

00:17:45,930 --> 00:17:53,850
ascend it to well in order to solve this

00:17:49,400 --> 00:17:55,470
Diego kicks off an auction process so

00:17:53,850 --> 00:18:00,260
the BBS will go and send out a request

00:17:55,470 --> 00:18:02,910
to the auctioneer and the auctioneer is

00:18:00,260 --> 00:18:05,640
in constant communication with the

00:18:02,910 --> 00:18:07,410
cluster of cells via a component called

00:18:05,640 --> 00:18:10,980
the rep which I think is the

00:18:07,410 --> 00:18:12,840
representative of this cell and so the

00:18:10,980 --> 00:18:15,450
auctioneer says okay we have this

00:18:12,840 --> 00:18:18,270
staging task one of you needs to go and

00:18:15,450 --> 00:18:23,010
perform it and it asks all of the cells

00:18:18,270 --> 00:18:25,080
to make a bid on that workload and the

00:18:23,010 --> 00:18:27,960
one with the highest bid is then

00:18:25,080 --> 00:18:30,360
assigned that that that workload

00:18:27,960 --> 00:18:33,119
so once we've decided the BBS sends off

00:18:30,360 --> 00:18:36,749
the request to the appropriate cell at

00:18:33,119 --> 00:18:39,360
which point the executor will create us

00:18:36,749 --> 00:18:42,289
a garden container and then this is

00:18:39,360 --> 00:18:44,369
where the actual process gets executed

00:18:42,289 --> 00:18:46,919
and I'm going to talk a little bit about

00:18:44,369 --> 00:18:49,169
garden in just a moment

00:18:46,919 --> 00:18:52,019
but also worth mentioning here that the

00:18:49,169 --> 00:18:54,149
executor will also be streaming the

00:18:52,019 --> 00:18:57,210
standard out and the standard error of

00:18:54,149 --> 00:18:59,399
that process into a component called

00:18:57,210 --> 00:19:04,830
Metron which alex is going to talk about

00:18:59,399 --> 00:19:06,929
in just a moment as well okay so at this

00:19:04,830 --> 00:19:09,179
point the staging task is now complete

00:19:06,929 --> 00:19:11,490
and as I mentioned earlier the output of

00:19:09,179 --> 00:19:13,710
that process is the droplet

00:19:11,490 --> 00:19:15,929
so we now need to take that droplet and

00:19:13,710 --> 00:19:19,200
put it back in the cloud controller so

00:19:15,929 --> 00:19:21,090
that we can schedule it to run and this

00:19:19,200 --> 00:19:23,970
is fairly simple the executor simply

00:19:21,090 --> 00:19:26,460
sends off a request to the CC uploader

00:19:23,970 --> 00:19:31,529
which is responsible for mediating that

00:19:26,460 --> 00:19:33,509
upload great so that's responsibility

00:19:31,529 --> 00:19:35,340
number one done we have now completed

00:19:33,509 --> 00:19:37,350
the staging process and we have this

00:19:35,340 --> 00:19:41,149
droplet which we want to schedule to run

00:19:37,350 --> 00:19:43,679
in our cluster how do we do that

00:19:41,149 --> 00:19:47,940
well there is another component here

00:19:43,679 --> 00:19:50,100
called NSYNC and NSYNC sits there

00:19:47,940 --> 00:19:53,610
listening for the desired app requests

00:19:50,100 --> 00:19:56,070
and it will convert those into El RPS

00:19:53,610 --> 00:19:59,039
which will it will then send off to the

00:19:56,070 --> 00:20:01,169
BBS so obviously we don't want our apps

00:19:59,039 --> 00:20:03,269
to run as a task because we want them to

00:20:01,169 --> 00:20:06,720
continue running until we tell them to

00:20:03,269 --> 00:20:08,759
stop and then again the a very similar

00:20:06,720 --> 00:20:11,299
process happens where the BBS persists

00:20:08,759 --> 00:20:13,259
it to the database kicks off an auction

00:20:11,299 --> 00:20:15,749
finds the cells it's actually going to

00:20:13,259 --> 00:20:19,490
run those that that application on

00:20:15,749 --> 00:20:19,490
streams or the logs off to met from

00:20:19,999 --> 00:20:24,869
another component worth mentioning here

00:20:22,139 --> 00:20:27,029
is the TPS and this is responsible for

00:20:24,869 --> 00:20:29,330
providing the Cloud Controller with

00:20:27,029 --> 00:20:33,480
information about the currently running

00:20:29,330 --> 00:20:35,659
LRP instances and it will also be

00:20:33,480 --> 00:20:38,100
monitoring activity for any crashes and

00:20:35,659 --> 00:20:40,550
reporting that information back to the

00:20:38,100 --> 00:20:42,840
Cloud Controller

00:20:40,550 --> 00:20:46,380
finally here there's one last component

00:20:42,840 --> 00:20:48,840
the converger and the converter is

00:20:46,380 --> 00:20:52,410
responsible for ensuring that everything

00:20:48,840 --> 00:20:54,090
becomes eventually consistent and it

00:20:52,410 --> 00:20:57,960
will take action to ensure that that is

00:20:54,090 --> 00:21:00,480
the case so for example if it detects

00:20:57,960 --> 00:21:02,790
that one of our lrp instances is missing

00:21:00,480 --> 00:21:05,040
it can go and kick off another auction

00:21:02,790 --> 00:21:05,580
to ensure that we bring that back into

00:21:05,040 --> 00:21:08,850
focus

00:21:05,580 --> 00:21:15,090
so that the desired State it's always

00:21:08,850 --> 00:21:17,070
equal to the actual state all right

00:21:15,090 --> 00:21:19,140
perfect so hopefully now I've described

00:21:17,070 --> 00:21:21,360
both of those processes the staging and

00:21:19,140 --> 00:21:24,030
the running and showing you how that

00:21:21,360 --> 00:21:25,260
actually works inside Diego there's one

00:21:24,030 --> 00:21:28,800
other component that I'd like to talk

00:21:25,260 --> 00:21:30,630
about and that is garden so full

00:21:28,800 --> 00:21:32,610
disclosure I do work on the garden team

00:21:30,630 --> 00:21:35,220
so I'm going to be speaking very

00:21:32,610 --> 00:21:38,160
favorably about it but I think with good

00:21:35,220 --> 00:21:41,520
reason let let me show you why welcome

00:21:38,160 --> 00:21:46,410
to the garden that's the last one I

00:21:41,520 --> 00:21:49,110
promise okay so garden garden is plowed

00:21:46,410 --> 00:21:50,850
Foundry's container technology and the

00:21:49,110 --> 00:21:52,620
first question people tend to ask with

00:21:50,850 --> 00:21:55,980
regards to containers and Cloud Foundry

00:21:52,620 --> 00:21:57,930
is can I run my docker image in cloud

00:21:55,980 --> 00:22:01,890
foundry and the answer is yes absolutely

00:21:57,930 --> 00:22:03,840
you can but as well as that garden

00:22:01,890 --> 00:22:08,820
allows us to run the build pack based

00:22:03,840 --> 00:22:11,190
applications as I've just described so

00:22:08,820 --> 00:22:13,880
what exactly does garden look like well

00:22:11,190 --> 00:22:17,370
at the top level we have the garden API

00:22:13,880 --> 00:22:19,680
and the API provides the functions such

00:22:17,370 --> 00:22:23,520
as create container destroy container

00:22:19,680 --> 00:22:26,480
etc etc and that API is implemented by

00:22:23,520 --> 00:22:30,200
multiple and pluggable backends and

00:22:26,480 --> 00:22:35,550
there are currently three main backends

00:22:30,200 --> 00:22:37,980
let's take a look at those the first one

00:22:35,550 --> 00:22:41,100
is garden Linux as the name suggests

00:22:37,980 --> 00:22:45,000
this is the Linux implementation of the

00:22:41,100 --> 00:22:47,400
garden API and this was essentially a

00:22:45,000 --> 00:22:49,740
rewrite of the warden container

00:22:47,400 --> 00:22:52,230
technology which which was induced in

00:22:49,740 --> 00:22:53,460
previous versions of Cloud Foundry prior

00:22:52,230 --> 00:22:54,720
to Diego

00:22:53,460 --> 00:22:57,750
and that's actually where the name

00:22:54,720 --> 00:23:00,540
garden sort of originated as we rewrote

00:22:57,750 --> 00:23:02,490
warden in go and then it was go warden

00:23:00,540 --> 00:23:05,760
which kind of sounds like garden

00:23:02,490 --> 00:23:07,740
I guess anyway this is what's currently

00:23:05,760 --> 00:23:11,130
running in most production plant factory

00:23:07,740 --> 00:23:13,440
deployments next up we have garden

00:23:11,130 --> 00:23:16,590
windows so this brings a long net and

00:23:13,440 --> 00:23:19,700
windows support into Cloud Foundry but

00:23:16,590 --> 00:23:24,630
perhaps most excitingly of all we have

00:23:19,700 --> 00:23:26,430
garden run see what is run sea run sea

00:23:24,630 --> 00:23:30,180
is a project that's being worked on by

00:23:26,430 --> 00:23:32,280
the open container initiative so the

00:23:30,180 --> 00:23:34,620
open container initiative is a body who

00:23:32,280 --> 00:23:36,690
are looking at defining standards around

00:23:34,620 --> 00:23:41,940
containers and this is really really

00:23:36,690 --> 00:23:44,190
exciting for a number of reasons so

00:23:41,940 --> 00:23:46,260
first on it means that the containers

00:23:44,190 --> 00:23:48,120
running inside Cloud Foundry are going

00:23:46,260 --> 00:23:50,820
to be running according to standards set

00:23:48,120 --> 00:23:53,070
by some independent body the body is

00:23:50,820 --> 00:23:54,690
part of the Linux Foundation and so

00:23:53,070 --> 00:23:57,540
that's that's fairly nice we have those

00:23:54,690 --> 00:23:59,340
standards there it also means that the

00:23:57,540 --> 00:24:01,470
containers running on Cloud Foundry will

00:23:59,340 --> 00:24:04,890
be using the exact same code base as

00:24:01,470 --> 00:24:06,390
containers running with docker and this

00:24:04,890 --> 00:24:08,040
is great because it means that things

00:24:06,390 --> 00:24:11,430
like compatibility is going to be much

00:24:08,040 --> 00:24:14,220
better and also with a lot more eyes on

00:24:11,430 --> 00:24:15,540
the codebase things like security issues

00:24:14,220 --> 00:24:19,170
are going to surface somewhat too quick

00:24:15,540 --> 00:24:21,840
surface much quicker and be easier to

00:24:19,170 --> 00:24:24,630
fix as well and so this is nearly ready

00:24:21,840 --> 00:24:27,780
I think it's currently going through the

00:24:24,630 --> 00:24:31,560
Diego CI pipelines hopefully we will be

00:24:27,780 --> 00:24:33,330
able to ship it fairly soon and once we

00:24:31,560 --> 00:24:35,610
do this is going to replace garden Linux

00:24:33,330 --> 00:24:38,210
as sort of the default back-end for

00:24:35,610 --> 00:24:38,210
cloud foundry

00:24:41,000 --> 00:24:46,200
okay so we've seen now our application

00:24:43,800 --> 00:24:47,580
is running in Cloud Foundry and so from

00:24:46,200 --> 00:24:49,890
the outside we need to access the

00:24:47,580 --> 00:24:52,560
application so let's take a look at the

00:24:49,890 --> 00:24:54,840
workflow here so we first send a request

00:24:52,560 --> 00:24:55,860
in and that will hit end up hitting the

00:24:54,840 --> 00:24:58,140
go Rooter

00:24:55,860 --> 00:25:00,750
while the go Rooter is working out what

00:24:58,140 --> 00:25:02,460
to do is continually being updated by

00:25:00,750 --> 00:25:04,380
the route emitter of where to find that

00:25:02,460 --> 00:25:07,680
application so you can see here we've

00:25:04,380 --> 00:25:09,210
got two Diego cells and then so the

00:25:07,680 --> 00:25:11,490
Rooter needs to know where to forward

00:25:09,210 --> 00:25:12,570
this request onto so once it gets the

00:25:11,490 --> 00:25:15,630
information from the root emitter

00:25:12,570 --> 00:25:16,980
continually it will be looking to

00:25:15,630 --> 00:25:18,600
forward this request first you know the

00:25:16,980 --> 00:25:22,080
first request will go to cell 1 the

00:25:18,600 --> 00:25:23,340
second request you go to cell 2 so this

00:25:22,080 --> 00:25:27,660
is just a nice straightforward workflow

00:25:23,340 --> 00:25:29,970
very similar for TCP routing as well so

00:25:27,660 --> 00:25:31,170
also my apps running but we won't really

00:25:29,970 --> 00:25:32,880
see what's happening because Cloud

00:25:31,170 --> 00:25:34,710
Foundry can be a bit of a black box you

00:25:32,880 --> 00:25:35,970
know you've just pushed a code and now

00:25:34,710 --> 00:25:38,040
you've got your app running in the

00:25:35,970 --> 00:25:40,710
container you know deep nested inside

00:25:38,040 --> 00:25:44,160
Diego so to do this from the outside we

00:25:40,710 --> 00:25:46,830
can use CF locks so you can see here

00:25:44,160 --> 00:25:48,780
we've issued a logs command and we're

00:25:46,830 --> 00:25:50,670
connected and tailing any logs that get

00:25:48,780 --> 00:25:52,800
emitted from our application so this is

00:25:50,670 --> 00:25:54,900
awesome you get a stream you know almost

00:25:52,800 --> 00:25:56,400
like a live stream of information coming

00:25:54,900 --> 00:25:59,310
from your app really useful for

00:25:56,400 --> 00:26:00,840
debugging and so what how is this you

00:25:59,310 --> 00:26:02,670
know being achieved so ed mentioned

00:26:00,840 --> 00:26:06,150
earlier we have a component called labra

00:26:02,670 --> 00:26:07,860
Gator and this is comprised of two main

00:26:06,150 --> 00:26:09,960
concepts so we've got dopplers and

00:26:07,860 --> 00:26:11,490
dopplers are there for collecting all of

00:26:09,960 --> 00:26:13,380
this information and then we have the

00:26:11,490 --> 00:26:15,150
traffic controller which is used to push

00:26:13,380 --> 00:26:17,940
this information so there's a few

00:26:15,150 --> 00:26:19,020
concepts in here that we might have seen

00:26:17,940 --> 00:26:20,460
throughout the presentation so the

00:26:19,020 --> 00:26:23,370
sources in this case will be your

00:26:20,460 --> 00:26:25,260
application the Metron agents are what

00:26:23,370 --> 00:26:27,870
is going to be connecting to dopler and

00:26:25,260 --> 00:26:30,180
you know sending your logs and metrics

00:26:27,870 --> 00:26:32,820
and events you then have the traffic

00:26:30,180 --> 00:26:34,680
controller which kind of collects this

00:26:32,820 --> 00:26:37,050
information and produces what's called a

00:26:34,680 --> 00:26:39,360
fire hose this fire hose can then be

00:26:37,050 --> 00:26:40,650
connected to and it's a massive

00:26:39,360 --> 00:26:42,420
information that's coming out of Cloud

00:26:40,650 --> 00:26:44,130
Foundry and so this is with one of the

00:26:42,420 --> 00:26:45,750
components it's under the most stress in

00:26:44,130 --> 00:26:47,100
the system because you can imagine you

00:26:45,750 --> 00:26:49,740
have thousands of applications running

00:26:47,100 --> 00:26:52,050
loads of system components all emitting

00:26:49,740 --> 00:26:54,000
information to this you know one

00:26:52,050 --> 00:26:54,240
component set and so you can you know

00:26:54,000 --> 00:26:55,410
see

00:26:54,240 --> 00:26:59,429
this has some real scalability

00:26:55,410 --> 00:27:02,550
challenges so let's take a look at you

00:26:59,429 --> 00:27:04,770
know how do we collect these logs so you

00:27:02,550 --> 00:27:06,630
have the Diego cells running the Metron

00:27:04,770 --> 00:27:09,630
agents you know so you could be emitting

00:27:06,630 --> 00:27:11,760
out logs or metrics metrics are normally

00:27:09,630 --> 00:27:13,860
from the system components these are

00:27:11,760 --> 00:27:15,660
then collected and pushed into traffic

00:27:13,860 --> 00:27:20,040
controller and then traffic controller

00:27:15,660 --> 00:27:21,480
creates the fires so now from the CLI

00:27:20,040 --> 00:27:22,470
how do we see these logs right because

00:27:21,480 --> 00:27:24,240
the logs are flow through the system

00:27:22,470 --> 00:27:27,630
into the and they ended up a traffic

00:27:24,240 --> 00:27:30,240
controller so we send a request for the

00:27:27,630 --> 00:27:31,770
application details and we get back you

00:27:30,240 --> 00:27:34,140
know everything we need to be able to

00:27:31,770 --> 00:27:35,429
connect to the traffic controller so we

00:27:34,140 --> 00:27:37,170
send off a request to the traffic

00:27:35,429 --> 00:27:38,760
controller which is using WebSockets

00:27:37,170 --> 00:27:40,830
so you can see here we head up an

00:27:38,760 --> 00:27:43,500
endpoint that's like slash tail and then

00:27:40,830 --> 00:27:45,120
you pass your out good and then so you

00:27:43,500 --> 00:27:50,520
establish a WebSocket connection and

00:27:45,120 --> 00:27:51,660
then you get back at blocks ok so that

00:27:50,520 --> 00:27:53,580
kind of concludes our journey

00:27:51,660 --> 00:27:56,010
we're just recapping it we've touched on

00:27:53,580 --> 00:27:58,040
you a a cloud controller we visited

00:27:56,010 --> 00:28:00,150
Kathy land across the sea sea bridge

00:27:58,040 --> 00:28:03,420
kind of looked at the staging and

00:28:00,150 --> 00:28:05,760
running processes in Cloud Foundry had a

00:28:03,420 --> 00:28:07,260
walk through the garden and then we came

00:28:05,760 --> 00:28:11,610
back out looking at the router and

00:28:07,260 --> 00:28:14,050
logger Gator so yes thanks for joining

00:28:11,610 --> 00:28:21,190
us yeah yes

00:28:14,050 --> 00:28:21,190

YouTube URL: https://www.youtube.com/watch?v=LRILQFBW4U0


