Title: What We Learned From Deploying 7000 Cloud Foundry Foundations Per Month - Rowan Jacobs, VMware
Publication date: 2020-06-14
Playlist: Cloud Foundry Summit NA 2020 - Virtual
Description: 
	What We Learned From Deploying 7000 Cloud Foundry Foundations Per Month - Rowan Jacobs, VMware 

For more info: https://www.cloudfoundry.org/ 

The Cloud Foundry Toolsmiths team at VMware deploys up to 7,000 Cloud Foundry foundations a month for internal testing for VMware and open source Cloud Foundry R&D teams. Here's what we've learned about observability, reliability, repeatable deployments, and keeping our Concourse happy.
Captions: 
	00:00:00,030 --> 00:00:07,470
welcome I'm Rowan Jacobs I am a cloud

00:00:03,899 --> 00:00:09,030
foundry engineer at VMware and today

00:00:07,470 --> 00:00:11,969
we're gonna talk about what we learned

00:00:09,030 --> 00:00:15,030
from deploying 7005 foundry foundations

00:00:11,969 --> 00:00:17,970
for a month I work on the CF tool

00:00:15,030 --> 00:00:19,859
Smith's team and we provide pre-made pre

00:00:17,970 --> 00:00:23,100
deployed cloud foundry foundations for

00:00:19,859 --> 00:00:25,350
other vmware teams and we deploy up to

00:00:23,100 --> 00:00:26,340
7,000 of them per month there are

00:00:25,350 --> 00:00:28,650
several different kinds of foundations

00:00:26,340 --> 00:00:31,109
we deploy including open source CF

00:00:28,650 --> 00:00:33,290
deployment on DCP proprietary tansu

00:00:31,109 --> 00:00:36,630
application service on GC p or vSphere

00:00:33,290 --> 00:00:38,610
proprietary PKS environments on G say p

00:00:36,630 --> 00:00:41,430
or p sphere and we're currently working

00:00:38,610 --> 00:00:44,190
on deploying open source CF for capes on

00:00:41,430 --> 00:00:46,170
AWS these environments are deployed in

00:00:44,190 --> 00:00:48,360
pools that are ready for users to just

00:00:46,170 --> 00:00:51,390
claim already pre-built environments out

00:00:48,360 --> 00:00:52,949
of the pool so most of our users are

00:00:51,390 --> 00:00:54,750
component teams and they need to test

00:00:52,949 --> 00:00:55,460
new versions of their releases on live

00:00:54,750 --> 00:00:57,870
foundations

00:00:55,460 --> 00:00:59,579
unfortunately deploying CF for VMs can

00:00:57,870 --> 00:01:02,309
take a really long time it can take up

00:00:59,579 --> 00:01:04,379
to two hours this leads to slow feedback

00:01:02,309 --> 00:01:07,290
cycles its leads to unhappy developers

00:01:04,379 --> 00:01:08,820
so by having a pool of environments that

00:01:07,290 --> 00:01:12,570
they can just claim in their pipelines

00:01:08,820 --> 00:01:14,430
we save time we allow fast feedback if a

00:01:12,570 --> 00:01:16,229
team needs to debug something they can

00:01:14,430 --> 00:01:18,750
just pick an environment out of the pool

00:01:16,229 --> 00:01:21,930
and overall the teams we work with are

00:01:18,750 --> 00:01:24,150
really happy with what we provide so how

00:01:21,930 --> 00:01:25,680
do we do this we have a ruby app which

00:01:24,150 --> 00:01:27,810
uses Concours pipelines to deploy

00:01:25,680 --> 00:01:30,180
foundations this app is deployed to an

00:01:27,810 --> 00:01:32,130
on-prem CF foundation and we treat that

00:01:30,180 --> 00:01:34,110
foundation like a pet we upgrade at

00:01:32,130 --> 00:01:35,759
every quarter if something goes wrong we

00:01:34,110 --> 00:01:37,380
debug it but the environments that we

00:01:35,759 --> 00:01:39,119
deploy for our customers are treated

00:01:37,380 --> 00:01:40,829
more like cattle if an environment has

00:01:39,119 --> 00:01:42,479
problems teams can just pick another one

00:01:40,829 --> 00:01:44,369
out of the pool if our deployment

00:01:42,479 --> 00:01:45,810
pipeline has issues we frequently just

00:01:44,369 --> 00:01:47,729
destroy the environment instead of

00:01:45,810 --> 00:01:48,930
debugging the pipeline it's important

00:01:47,729 --> 00:01:50,250
for us to keep an eye on recurring

00:01:48,930 --> 00:01:52,049
issues though that might affect multiple

00:01:50,250 --> 00:01:54,149
pipelines so their deployments can

00:01:52,049 --> 00:01:56,100
become more reliable but if it's a

00:01:54,149 --> 00:01:59,280
sporadic a rare issue it's not really

00:01:56,100 --> 00:02:00,540
worthwhile for us to be back so this is

00:01:59,280 --> 00:02:02,130
what our conference looks like when our

00:02:00,540 --> 00:02:03,210
pools are filling we have multiple

00:02:02,130 --> 00:02:04,680
different pools for different kinds of

00:02:03,210 --> 00:02:06,479
environments for instance proprietary

00:02:04,680 --> 00:02:07,860
where soap and source and on the

00:02:06,479 --> 00:02:09,479
proprietary side because we have

00:02:07,860 --> 00:02:12,209
long-term support we have different

00:02:09,479 --> 00:02:13,800
versions of that the support contract

00:02:12,209 --> 00:02:16,350
for tanzy application service is

00:02:13,800 --> 00:02:18,390
and - - so we support the latest version

00:02:16,350 --> 00:02:21,600
and also the two previous versions after

00:02:18,390 --> 00:02:24,030
that but we allow users to also deploy

00:02:21,600 --> 00:02:27,660
private tools into their own GCP

00:02:24,030 --> 00:02:31,560
projects using their own resources we

00:02:27,660 --> 00:02:34,020
manage those pools but the user actually

00:02:31,560 --> 00:02:36,690
provides their own GCP resources for it

00:02:34,020 --> 00:02:38,190
so for those pools we allow users to

00:02:36,690 --> 00:02:41,870
deploy versions that are pretty old

00:02:38,190 --> 00:02:45,030
including going as back as far as to six

00:02:41,870 --> 00:02:47,010
our app monitors the number of unclaimed

00:02:45,030 --> 00:02:48,990
environments every pool and each pool

00:02:47,010 --> 00:02:51,000
basically has a desired minimum

00:02:48,990 --> 00:02:53,430
unclaimed number of environments and if

00:02:51,000 --> 00:02:55,470
we go below that threshold then we start

00:02:53,430 --> 00:02:58,170
deploying environments and then our

00:02:55,470 --> 00:03:01,470
pipeline starts looking like this our

00:02:58,170 --> 00:03:03,210
desired minimum unclaimed is set to a

00:03:01,470 --> 00:03:06,360
very low value usually one or two

00:03:03,210 --> 00:03:08,940
sometimes zero during weekends so at the

00:03:06,360 --> 00:03:10,950
end of the week Friday afternoon at 6

00:03:08,940 --> 00:03:14,550
p.m. Pacific time all the tools will

00:03:10,950 --> 00:03:17,190
start draining so that we save resources

00:03:14,550 --> 00:03:18,690
so the average lifespan of an unclaimed

00:03:17,190 --> 00:03:21,630
environment in the pool is about a week

00:03:18,690 --> 00:03:24,120
for pools for environments that do get

00:03:21,630 --> 00:03:26,430
claimed from the pool they last 24 hours

00:03:24,120 --> 00:03:28,080
unless users renew them 24 hours is

00:03:26,430 --> 00:03:30,540
usually long enough for a pipeline to do

00:03:28,080 --> 00:03:32,550
whatever it wants but if users are

00:03:30,540 --> 00:03:33,989
trying to debug something maybe a

00:03:32,550 --> 00:03:37,860
customer has an issue and they want to

00:03:33,989 --> 00:03:41,430
run a new version of their release on a

00:03:37,860 --> 00:03:42,660
very specific version of tasks then they

00:03:41,430 --> 00:03:44,010
might want it to stick around for a

00:03:42,660 --> 00:03:45,630
little while longer and not

00:03:44,010 --> 00:03:47,459
automatically get reaped after 24 hours

00:03:45,630 --> 00:03:51,480
so we provide an option for them to

00:03:47,459 --> 00:03:53,580
renew the environment all of this pool

00:03:51,480 --> 00:03:56,100
filling and draining is automatically

00:03:53,580 --> 00:03:58,860
scheduled by the app we do have the

00:03:56,100 --> 00:04:01,950
ability to change the desired minimum

00:03:58,860 --> 00:04:03,060
unclaimed number or to monitor the pools

00:04:01,950 --> 00:04:05,580
to request the creation of new

00:04:03,060 --> 00:04:08,040
environments but we don't typically have

00:04:05,580 --> 00:04:13,590
to do this because the app mostly does

00:04:08,040 --> 00:04:17,430
it all itself so here is what it looks

00:04:13,590 --> 00:04:19,530
like for deploying a cf deployments open

00:04:17,430 --> 00:04:22,260
source environment it looks pretty

00:04:19,530 --> 00:04:24,750
similar to the way that component team

00:04:22,260 --> 00:04:26,430
would deploy this environment we use a

00:04:24,750 --> 00:04:27,540
couple different open-source tools we

00:04:26,430 --> 00:04:29,790
use Bosch bootloader it

00:04:27,540 --> 00:04:32,130
a bubble and CF deployment conquers

00:04:29,790 --> 00:04:34,320
tasks aka CF Dakota which is built by

00:04:32,130 --> 00:04:36,570
DCF release integration team we use

00:04:34,320 --> 00:04:39,360
those to deploy our CF deployment

00:04:36,570 --> 00:04:41,670
environments when you use bubble it

00:04:39,360 --> 00:04:43,350
stores all the information about the

00:04:41,670 --> 00:04:44,730
resources created in terraform and the

00:04:43,350 --> 00:04:47,340
boss director it's created in the jump

00:04:44,730 --> 00:04:50,330
box all in a large folder called the

00:04:47,340 --> 00:04:52,050
bubble state and this folder is

00:04:50,330 --> 00:04:53,730
represented by this bubble state

00:04:52,050 --> 00:04:55,950
resource you see in the pipeline it's

00:04:53,730 --> 00:04:57,690
actually pretty big because storing the

00:04:55,950 --> 00:04:59,970
terraform information also in those

00:04:57,690 --> 00:05:02,880
storing terraform plug-ins and the turbo

00:04:59,970 --> 00:05:05,250
plug-ins take up several megabytes so we

00:05:02,880 --> 00:05:08,430
don't want to necessarily pass around

00:05:05,250 --> 00:05:11,430
this really bulky large file and send it

00:05:08,430 --> 00:05:13,140
directly to our users also you can't use

00:05:11,430 --> 00:05:17,220
most of the functions of bubble without

00:05:13,140 --> 00:05:19,800
a DCP service account key or equivalent

00:05:17,220 --> 00:05:21,540
Aya's credentials and because we deploy

00:05:19,800 --> 00:05:23,760
all these pools of environments on our

00:05:21,540 --> 00:05:26,850
own GCP projects we don't want to be

00:05:23,760 --> 00:05:31,590
going out and handing that to any random

00:05:26,850 --> 00:05:33,360
user so we don't want to give users our

00:05:31,590 --> 00:05:36,480
bubble State because it would basically

00:05:33,360 --> 00:05:38,430
be useless to them for proprietary Cloud

00:05:36,480 --> 00:05:39,960
Foundry environments our standard is to

00:05:38,430 --> 00:05:42,600
provide what we call a metadata file

00:05:39,960 --> 00:05:44,130
which is just some simple JSON that

00:05:42,600 --> 00:05:47,580
contains the admin controls for the

00:05:44,130 --> 00:05:50,790
environment some information about the

00:05:47,580 --> 00:05:53,160
ops manager VM how to SSH on to it SSH

00:05:50,790 --> 00:05:54,810
keys for that and the relevant terraform

00:05:53,160 --> 00:05:56,940
outputs representing the networking

00:05:54,810 --> 00:05:58,380
setup for the foundation so we wanted to

00:05:56,940 --> 00:06:00,990
provide users with something similar

00:05:58,380 --> 00:06:03,900
like similar to that for our open source

00:06:00,990 --> 00:06:05,580
environments instead of this bulky tar

00:06:03,900 --> 00:06:07,560
ball that they can't even use properly

00:06:05,580 --> 00:06:09,510
so we needed to make changes to both

00:06:07,560 --> 00:06:12,060
bubble and safe Dakota in order to

00:06:09,510 --> 00:06:13,560
enable this we changed bubble so that

00:06:12,060 --> 00:06:16,880
the bubble printf command which you use

00:06:13,560 --> 00:06:19,500
to target the Boche director can take a

00:06:16,880 --> 00:06:21,360
metadata file as input instead of just

00:06:19,500 --> 00:06:23,610
taking the bubble state and it can use

00:06:21,360 --> 00:06:25,350
that what the bubble printed command

00:06:23,610 --> 00:06:28,770
does is it prints out a bunch of

00:06:25,350 --> 00:06:30,630
environment variables that tell you how

00:06:28,770 --> 00:06:32,730
to target your boss director so now you

00:06:30,630 --> 00:06:34,470
can target your boss director with just

00:06:32,730 --> 00:06:39,030
H volts offense metadata file in

00:06:34,470 --> 00:06:40,590
addition to a bulky bubble state we also

00:06:39,030 --> 00:06:41,460
change the F Dakota so that it can use

00:06:40,590 --> 00:06:44,550
the metadata

00:06:41,460 --> 00:06:47,220
to target the CF environment for other

00:06:44,550 --> 00:06:49,710
CF Dakota tasks like running Cloud

00:06:47,220 --> 00:06:51,330
Foundry acceptance tests or cats most

00:06:49,710 --> 00:06:52,830
component teams are gonna want to run

00:06:51,330 --> 00:06:54,600
cats somewhere in their pipeline and

00:06:52,830 --> 00:06:56,490
they frequently use the CF Dakota test

00:06:54,600 --> 00:06:58,980
for that instead of writing their own

00:06:56,490 --> 00:07:00,360
conquers tasks from scratch so since

00:06:58,980 --> 00:07:02,730
most users want to do that in our

00:07:00,360 --> 00:07:05,250
pipelines we in their pipelines we

00:07:02,730 --> 00:07:07,920
change CF Dakota in order to allow them

00:07:05,250 --> 00:07:11,640
to do that so we've got all these

00:07:07,920 --> 00:07:13,980
environments we have these complex

00:07:11,640 --> 00:07:15,570
pipelines this one is fairly simple but

00:07:13,980 --> 00:07:17,970
the ones for proprietary tabs are a lot

00:07:15,570 --> 00:07:19,770
longer and more complicated how do we

00:07:17,970 --> 00:07:23,040
manage all these environments how do we

00:07:19,770 --> 00:07:24,720
monitor them well we mostly monitor the

00:07:23,040 --> 00:07:27,840
health of the app itself and health the

00:07:24,720 --> 00:07:29,730
pools as a whole our target reliability

00:07:27,840 --> 00:07:31,950
for deployments and tear downs is two

00:07:29,730 --> 00:07:37,170
and a half nines and we typically reach

00:07:31,950 --> 00:07:39,810
that wait you can see an example here at

00:07:37,170 --> 00:07:42,030
the top is an example of what our wave

00:07:39,810 --> 00:07:45,120
front dashboard looks like it shows us

00:07:42,030 --> 00:07:48,810
that our environments endpoints are all

00:07:45,120 --> 00:07:50,400
healthy and that our pools are full of

00:07:48,810 --> 00:07:54,600
unclaimed environments and that there

00:07:50,400 --> 00:07:57,540
are no environments in an error State we

00:07:54,600 --> 00:08:00,600
often have to adjust the headroom for

00:07:57,540 --> 00:08:03,180
the pools too to accommodate either

00:08:00,600 --> 00:08:05,400
increased or decreased demand so

00:08:03,180 --> 00:08:06,990
frequently if there's a release about to

00:08:05,400 --> 00:08:10,410
come out there might be a surge of

00:08:06,990 --> 00:08:13,140
increased demand where users are trying

00:08:10,410 --> 00:08:15,210
to claim environments for the latest

00:08:13,140 --> 00:08:16,530
version because maybe a new beta came

00:08:15,210 --> 00:08:18,810
out or a new release candidate and

00:08:16,530 --> 00:08:21,240
everybody wants to test that version so

00:08:18,810 --> 00:08:23,190
we might actually have to increase the

00:08:21,240 --> 00:08:24,600
Headroom so that users can actually

00:08:23,190 --> 00:08:27,300
claim environments out of the pools

00:08:24,600 --> 00:08:29,280
because that doesn't really do that much

00:08:27,300 --> 00:08:32,970
good if there's not an environment ready

00:08:29,280 --> 00:08:34,380
for you to claim so that's one thing

00:08:32,970 --> 00:08:37,230
that we have to do another thing is

00:08:34,380 --> 00:08:39,600
we've got this monitoring for errors in

00:08:37,230 --> 00:08:41,100
environments and we want to keep the

00:08:39,600 --> 00:08:43,800
number of errors in our deploy is fairly

00:08:41,100 --> 00:08:45,570
low we've taken a lot of reliability

00:08:43,800 --> 00:08:49,320
measures in order to do that which

00:08:45,570 --> 00:08:50,310
include retrying concourse tasks when

00:08:49,320 --> 00:08:52,200
they fail but one of the more

00:08:50,310 --> 00:08:54,210
interesting ones is that when there are

00:08:52,200 --> 00:08:55,290
more than five failing the plates we

00:08:54,210 --> 00:08:57,360
automatically

00:08:55,290 --> 00:08:58,860
that and we suspend new environment

00:08:57,360 --> 00:09:00,810
creation and we suspend all the

00:08:58,860 --> 00:09:02,880
pipelines as well this has allowed us to

00:09:00,810 --> 00:09:07,829
detect and accommodate for things like

00:09:02,880 --> 00:09:11,399
GCP failures or because we use AWS route

00:09:07,829 --> 00:09:13,139
53 for DNS for our app and system

00:09:11,399 --> 00:09:15,600
domains for these environments it

00:09:13,139 --> 00:09:18,209
protects us from AWS route 53 failures

00:09:15,600 --> 00:09:20,370
or from networking problems affecting

00:09:18,209 --> 00:09:22,980
the on creme foundation that hosts the

00:09:20,370 --> 00:09:24,990
app when deploys are suspended the app

00:09:22,980 --> 00:09:26,220
creates canary pipelines every 30

00:09:24,990 --> 00:09:30,060
minutes we try to create a new

00:09:26,220 --> 00:09:32,730
environment and if that succeeds then we

00:09:30,060 --> 00:09:35,430
resume service on the app we're also

00:09:32,730 --> 00:09:37,290
exploring using observability tools like

00:09:35,430 --> 00:09:38,790
honeycomb to explore the types of errors

00:09:37,290 --> 00:09:41,370
we get during deployments and tear downs

00:09:38,790 --> 00:09:43,139
so that we're not just sort of playing

00:09:41,370 --> 00:09:44,850
whack-a-mole and every time we see an

00:09:43,139 --> 00:09:48,389
issue we have a more kind of

00:09:44,850 --> 00:09:50,639
sophisticated analysis of how often that

00:09:48,389 --> 00:09:51,839
issue is occurring and what the

00:09:50,639 --> 00:09:54,959
different kinds of errors were getting

00:09:51,839 --> 00:09:57,000
are so the bottom screenshot here is a

00:09:54,959 --> 00:09:59,579
screenshot from honeycomb and it shows

00:09:57,000 --> 00:10:02,819
the success rate of our let's encrypt

00:09:59,579 --> 00:10:04,319
search requests part of our part of the

00:10:02,819 --> 00:10:07,800
service that we provide users for our

00:10:04,319 --> 00:10:11,399
environments is real actual trusted SSL

00:10:07,800 --> 00:10:13,260
certs from let's encrypt and so we have

00:10:11,399 --> 00:10:15,389
to make a lot of let's insert let's

00:10:13,260 --> 00:10:18,449
encrypt cert requests in our pipelines

00:10:15,389 --> 00:10:20,339
in order to get all of these certs thing

00:10:18,449 --> 00:10:23,040
is let's encrypt has rate-limiting and

00:10:20,339 --> 00:10:24,750
when we first started this service we

00:10:23,040 --> 00:10:26,610
were getting rate limited a lot and we

00:10:24,750 --> 00:10:29,819
were producing a lot of environments

00:10:26,610 --> 00:10:34,199
without valid certs as a result so we

00:10:29,819 --> 00:10:36,149
decided to provide all the errors that

00:10:34,199 --> 00:10:38,519
we were getting from let's encrypt into

00:10:36,149 --> 00:10:40,230
a honeycomb data set and analyzed it and

00:10:38,519 --> 00:10:43,380
we found out that rate limiting was the

00:10:40,230 --> 00:10:45,389
problem in particular if you request

00:10:43,380 --> 00:10:48,360
search for the same domain more than

00:10:45,389 --> 00:10:52,380
five times a week let's encrypt will not

00:10:48,360 --> 00:10:54,329
allow you to request another one and we

00:10:52,380 --> 00:10:57,810
have a large pool of environment names

00:10:54,329 --> 00:11:01,829
that we select from for our pools but we

00:10:57,810 --> 00:11:04,050
didn't have any way to prevent the same

00:11:01,829 --> 00:11:07,380
name from getting chosen more than five

00:11:04,050 --> 00:11:08,890
times a week so instead of selecting

00:11:07,380 --> 00:11:11,800
randomly from the pool

00:11:08,890 --> 00:11:14,860
we decided to select the least recently

00:11:11,800 --> 00:11:16,899
used environment name and that has cut

00:11:14,860 --> 00:11:21,029
our error rate for let's encrypt cert

00:11:16,899 --> 00:11:23,800
requests down from about 95 down to

00:11:21,029 --> 00:11:28,300
sorry it's it's raised our success rate

00:11:23,800 --> 00:11:30,820
from 95 up to about 99 percent so that's

00:11:28,300 --> 00:11:31,899
been really helpful for us we're hoping

00:11:30,820 --> 00:11:34,870
to incorporate some of these

00:11:31,899 --> 00:11:37,300
observability tools into the rest of our

00:11:34,870 --> 00:11:41,649
pipelines so that we can have even more

00:11:37,300 --> 00:11:44,230
reliable deployments especially as going

00:11:41,649 --> 00:11:45,940
forward we're going to have four or five

00:11:44,230 --> 00:11:48,339
different kinds of environments that

00:11:45,940 --> 00:11:49,959
we're deploying we have you know PKS

00:11:48,339 --> 00:11:51,730
proprietary Tad's

00:11:49,959 --> 00:11:53,980
open source CF deployment open source

00:11:51,730 --> 00:11:56,440
Atia perc aids proprietary tabs for

00:11:53,980 --> 00:11:58,660
Kate's and we want to make sure that

00:11:56,440 --> 00:12:03,399
we're giving users reliable environments

00:11:58,660 --> 00:12:05,290
for all of them so that is our adventure

00:12:03,399 --> 00:12:08,770
that's basically where we're at right

00:12:05,290 --> 00:12:13,200
now with deploying massive fleets of

00:12:08,770 --> 00:12:16,740
environments hope you enjoy the talk and

00:12:13,200 --> 00:12:16,740

YouTube URL: https://www.youtube.com/watch?v=eDzZI3ADs0E


