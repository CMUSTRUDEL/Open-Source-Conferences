Title: How Cloud Foundry Integrates Kubernetes into Open Source Projects
Publication date: 2018-12-13
Playlist: How Cloud Foundry Integrates Kubernetes into Open Source Projects
Description: 
	Interested to learn how Cloud Foundry projects are integrating Kubernetes into their technology? Chip Childers, CTO of Cloud Foundry Foundation, walks you through three projects: Cloud Foundry Container Runtime (CFCR), CF Containerization and Eirini. All three projects integrate Kubernetes into the Cloud Foundry platform in different ways, meeting DevOps teamsâ€™ need for the simple, agile and flexible delivery of software packaged into containers.
Captions: 
	00:00:00,060 --> 00:00:04,740
[Music]

00:00:02,030 --> 00:00:06,420
hi I'm chip CTO of the clock founders

00:00:04,740 --> 00:00:07,859
Foundation recently we've been spending

00:00:06,420 --> 00:00:09,900
a lot of time as a community talking

00:00:07,859 --> 00:00:11,610
about lots of really interesting

00:00:09,900 --> 00:00:14,219
projects that are integrating kubernetes

00:00:11,610 --> 00:00:15,990
into the Cloud Foundry family of open

00:00:14,219 --> 00:00:19,020
source efforts and so today I wanted to

00:00:15,990 --> 00:00:20,730
help clarify how three of them work so

00:00:19,020 --> 00:00:22,949
the first project is the Cloud Foundry

00:00:20,730 --> 00:00:25,050
container runtime this is a project that

00:00:22,949 --> 00:00:26,820
pivotal and Google started initially

00:00:25,050 --> 00:00:28,890
together they called it Kubo back then

00:00:26,820 --> 00:00:30,150
vmware quickly got involved and since

00:00:28,890 --> 00:00:32,759
then it joined the cloud foundry

00:00:30,150 --> 00:00:33,899
Foundation as a incubating project the

00:00:32,759 --> 00:00:35,899
whole goal of the class foundry

00:00:33,899 --> 00:00:39,329
container runtime is to make deploying

00:00:35,899 --> 00:00:42,629
managing and upgrading kubernetes easy

00:00:39,329 --> 00:00:44,940
on any cloud it does that by using live

00:00:42,629 --> 00:00:47,219
memory Bosh in order to deploy on to

00:00:44,940 --> 00:00:49,230
virtually any infrastructure Bosh has

00:00:47,219 --> 00:00:50,719
the ability to communicate with public

00:00:49,230 --> 00:00:53,280
clouds private infrastructure

00:00:50,719 --> 00:00:55,469
environments virtualization platforms

00:00:53,280 --> 00:00:57,420
open stores infrastructures of service

00:00:55,469 --> 00:00:59,820
systems and it can ask for whatever it

00:00:57,420 --> 00:01:02,579
needs in terms of virtual machines the

00:00:59,820 --> 00:01:04,949
storage necessary to support them the

00:01:02,579 --> 00:01:06,540
networking configuration and so the Bosh

00:01:04,949 --> 00:01:08,490
director is able to ask this

00:01:06,540 --> 00:01:11,340
infrastructure where these clouds were

00:01:08,490 --> 00:01:13,560
as many virtual machines as it needs it

00:01:11,340 --> 00:01:15,509
installs a small agent on each one of

00:01:13,560 --> 00:01:18,540
those machines and that agent lets it

00:01:15,509 --> 00:01:20,820
give that machine jobs to do so for

00:01:18,540 --> 00:01:23,610
example Bosh director to the make

00:01:20,820 --> 00:01:25,860
kubernetes work will deploy its V

00:01:23,610 --> 00:01:28,170
cluster the community's master nodes and

00:01:25,860 --> 00:01:29,670
then the rest of the pool of nodes that

00:01:28,170 --> 00:01:31,409
are gonna host the containers that

00:01:29,670 --> 00:01:32,850
kubernetes is responsible for scheduling

00:01:31,409 --> 00:01:34,920
the other thing that's very important

00:01:32,850 --> 00:01:37,500
about this dual scheduling layer where

00:01:34,920 --> 00:01:40,170
kubernetes is responsible for scheduling

00:01:37,500 --> 00:01:42,360
containers and Bosh is responsible for

00:01:40,170 --> 00:01:44,880
scheduling jobs on to virtual machines

00:01:42,360 --> 00:01:47,850
which is in fact kubernetes nodes is

00:01:44,880 --> 00:01:51,360
that what happens when a node disappears

00:01:47,850 --> 00:01:53,450
well kubernetes will redistribute all of

00:01:51,360 --> 00:01:55,590
the containers that it's responsible for

00:01:53,450 --> 00:01:57,869
but with the Cloud Foundry container

00:01:55,590 --> 00:02:00,210
runtime Bosh is able to ask the

00:01:57,869 --> 00:02:02,040
infrastructure for a new VM and rejoin

00:02:00,210 --> 00:02:03,090
it to the cluster adding the capacity

00:02:02,040 --> 00:02:05,640
that was lost back

00:02:03,090 --> 00:02:08,670
it also can take advantage of the logic

00:02:05,640 --> 00:02:11,730
that Bosh is able to achieve for zero

00:02:08,670 --> 00:02:13,470
downtime upgrades or rolling upgrades of

00:02:11,730 --> 00:02:15,540
Hooven Eddie's platform within the

00:02:13,470 --> 00:02:17,549
public clouds all right next up CF

00:02:15,540 --> 00:02:19,650
containerization in a very very

00:02:17,549 --> 00:02:22,080
simplistic way of looking at it is going

00:02:19,650 --> 00:02:24,629
from the release manifests that are

00:02:22,080 --> 00:02:27,959
typically used by Bosch to deploy

00:02:24,629 --> 00:02:30,720
software into docker images and home

00:02:27,959 --> 00:02:32,459
charts for deployment into kubernetes it

00:02:30,720 --> 00:02:36,090
does that by using a process called

00:02:32,459 --> 00:02:38,120
fizzle and this fizzle codebase is what

00:02:36,090 --> 00:02:41,040
takes this Bosch release manifest

00:02:38,120 --> 00:02:42,659
creates a docker image runs the same

00:02:41,040 --> 00:02:44,549
logic that Bosch would typically run

00:02:42,659 --> 00:02:46,920
within a virtual machine to pull in the

00:02:44,549 --> 00:02:49,560
software that needs to be packaged and

00:02:46,920 --> 00:02:51,299
then it puts it together using a helms

00:02:49,560 --> 00:02:53,700
art that is then used to deploy

00:02:51,299 --> 00:02:55,620
kubernetes now what's important about

00:02:53,700 --> 00:02:58,739
the CF containerization effort is that

00:02:55,620 --> 00:03:00,390
while that's a general-purpose idea it's

00:02:58,739 --> 00:03:02,670
specifically trying to get the Cloud

00:03:00,390 --> 00:03:04,530
Foundry application runtime it's the

00:03:02,670 --> 00:03:06,480
traditional platform as-a-service

00:03:04,530 --> 00:03:08,250
that everybody thinks of when you think

00:03:06,480 --> 00:03:10,709
of Cloud Foundry it's trying to package

00:03:08,250 --> 00:03:13,410
that whole system into docker images

00:03:10,709 --> 00:03:15,629
using home charts to deploy it on top of

00:03:13,410 --> 00:03:18,120
a kubernetes cluster all right now the

00:03:15,629 --> 00:03:20,489
third project this one's called a Rini

00:03:18,120 --> 00:03:22,079
this is when we tear inside the Cloud

00:03:20,489 --> 00:03:24,510
Foundry application runtime again that

00:03:22,079 --> 00:03:28,079
that pa's part of the Cloud Foundry

00:03:24,510 --> 00:03:30,120
technology stack and so inside that has

00:03:28,079 --> 00:03:32,669
part of the Cloud Foundry stack we have

00:03:30,120 --> 00:03:34,769
lots of different smaller projects we

00:03:32,669 --> 00:03:38,220
have the Cloud Controller API or the

00:03:34,769 --> 00:03:40,680
happy project we have routing which is

00:03:38,220 --> 00:03:43,049
how end-users talk to applications

00:03:40,680 --> 00:03:45,329
deployed in the CF environment we have

00:03:43,049 --> 00:03:47,250
Identity Management through UA a logging

00:03:45,329 --> 00:03:49,919
and all of the other projects that make

00:03:47,250 --> 00:03:52,049
that a hundred app runtime project what

00:03:49,919 --> 00:03:55,500
now what the arena project is focused on

00:03:52,049 --> 00:03:58,079
doing is providing an option for the

00:03:55,500 --> 00:03:59,669
Diego container scheduler a Diego

00:03:58,079 --> 00:04:01,889
container schedule is one that was built

00:03:59,669 --> 00:04:04,799
by our community it's purpose-built to

00:04:01,889 --> 00:04:06,239
support the app runtime but kubernetes

00:04:04,799 --> 00:04:08,310
has reached the point of maturity where

00:04:06,239 --> 00:04:11,310
there are some use cases that it can

00:04:08,310 --> 00:04:14,370
solve and ireenie is all about giving us

00:04:11,310 --> 00:04:16,979
choice between Diego and kubernetes as

00:04:14,370 --> 00:04:20,609
the underlying infrastructure that the

00:04:16,979 --> 00:04:21,719
app containers are run on so those are

00:04:20,609 --> 00:04:25,290
the three projects that I wanted to

00:04:21,719 --> 00:04:27,180
share with you they actually seem like

00:04:25,290 --> 00:04:28,740
they all do the same thing or do similar

00:04:27,180 --> 00:04:30,450
things when you hear about the initial

00:04:28,740 --> 00:04:32,580
right it's kubernetes and the Cloud

00:04:30,450 --> 00:04:34,530
Foundry community is coming together but

00:04:32,580 --> 00:04:36,300
as you can see there are different ways

00:04:34,530 --> 00:04:37,560
that kubernetes can be integrated into

00:04:36,300 --> 00:04:39,990
the Cloud Foundry

00:04:37,560 --> 00:04:42,450
technologists staff and each one has a

00:04:39,990 --> 00:04:43,890
different potential use case but what's

00:04:42,450 --> 00:04:46,860
more interesting is the potential

00:04:43,890 --> 00:04:48,990
combination of these as our ecosystem

00:04:46,860 --> 00:04:51,090
the end users the customers and

00:04:48,990 --> 00:04:52,380
importantly the vendors look at the

00:04:51,090 --> 00:04:54,300
different ways they want to use these

00:04:52,380 --> 00:04:56,220
technologies they may find that a

00:04:54,300 --> 00:04:58,650
combination of all three will be very

00:04:56,220 --> 00:05:00,630
interesting so I can imagine using a

00:04:58,650 --> 00:05:03,720
Cloud Foundry container runtime process

00:05:00,630 --> 00:05:06,120
as a way to deploy and manage kubernetes

00:05:03,720 --> 00:05:08,610
with Bosch taking responsibility for

00:05:06,120 --> 00:05:10,170
working with the underlying clouds we

00:05:08,610 --> 00:05:12,570
could then further imagine that we're

00:05:10,170 --> 00:05:14,430
using CF containerization to take just

00:05:12,570 --> 00:05:17,700
the part of the application runtime

00:05:14,430 --> 00:05:20,310
that's needed to create the developer

00:05:17,700 --> 00:05:22,380
experience package it into dr. images

00:05:20,310 --> 00:05:24,540
including a helmet arc for deployment

00:05:22,380 --> 00:05:26,640
and push it on top of that same

00:05:24,540 --> 00:05:29,070
kubernetes cluster but to contain a

00:05:26,640 --> 00:05:31,050
runtime project deployed for us so the

00:05:29,070 --> 00:05:33,720
combination of CF containerization and

00:05:31,050 --> 00:05:36,570
arena collapses the cloud memory

00:05:33,720 --> 00:05:39,210
application runtime into a kubernetes

00:05:36,570 --> 00:05:41,190
integrated developer experience and we

00:05:39,210 --> 00:05:43,920
use the power of Bosch to deploy that

00:05:41,190 --> 00:05:44,770
uber Nettie's cluster on to any cloud or

00:05:43,920 --> 00:05:53,840
any infrastructure

00:05:44,770 --> 00:05:55,900
[Music]

00:05:53,840 --> 00:05:55,900

YouTube URL: https://www.youtube.com/watch?v=CwAmh8MdWCg


