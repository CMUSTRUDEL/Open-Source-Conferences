Title: Performance of a VM vs. Containerized Cloud Foundry
Publication date: 2018-10-10
Playlist: Cloud Foundry Summit Europe 2018
Description: 
	Performance of a VM vs. Containerized Cloud Foundry - Vlad Iovanov & Jeff Hobbs, SUSE

One of the most asked questions about the new containerized Cloud Foundry is how it compares to a VM-based installation in terms of performance.

In this talk we will discuss the architecture design for containerization of CF, going beyond making containers to make it Kubernetes aware. We will compare a "Kubernetes-native" Cloud Foundry against a "traditional" BOSH OpenStack VM-based installation. Weâ€™ll present numbers to compare how these perform in operation.

The presenter will show the techniques used in these experiments and discuss the comparison between the two styles of deploying Cloud Foundry.

We'll explain our testing methodology and go through the results.

This will include installation/upgrade duration, application start-up and scaling duration, application latency and routing performance.

https://cfseu18.sched.com/event/FRyi/performance-of-a-vm-vs-containerized-cloud-foundry-vlad-iovanov-jeff-hobbs-suse
Captions: 
	00:00:00,030 --> 00:00:06,299
yeah well welcome everyone thanks for

00:00:03,389 --> 00:00:08,849
joining this afternoon we're gonna talk

00:00:06,299 --> 00:00:10,500
about the performance of VM versus

00:00:08,849 --> 00:00:12,900
containerized cloud foundry

00:00:10,500 --> 00:00:17,460
I'm Jeff Hobbs director of engineering

00:00:12,900 --> 00:00:24,320
at Sousa and Vlad is one of our system

00:00:17,460 --> 00:00:28,109
architects okay so what are we comparing

00:00:24,320 --> 00:00:33,030
we're looking at Ace to two standard

00:00:28,109 --> 00:00:38,730
installations of CF deployment what one

00:00:33,030 --> 00:00:42,149
is the CF deployment of Bosh on GC P so

00:00:38,730 --> 00:00:44,160
Google compute platform the VM based one

00:00:42,149 --> 00:00:46,379
and then there is the standard Hjelm

00:00:44,160 --> 00:00:48,090
installation of Sousa Cloud Foundry

00:00:46,379 --> 00:00:52,739
which is the containerized cloud foundry

00:00:48,090 --> 00:00:54,739
on google kubernetes so you're really

00:00:52,739 --> 00:00:59,039
looking at the the boss and the boss

00:00:54,739 --> 00:01:05,430
Bosh and v I'll approach word I'll try

00:00:59,039 --> 00:01:07,530
and mix together too many times so what

00:01:05,430 --> 00:01:09,930
are we doing what's our goal we're

00:01:07,530 --> 00:01:12,270
really trying to validate obviously

00:01:09,930 --> 00:01:13,799
there was the you might have seen a lot

00:01:12,270 --> 00:01:16,619
of talks about container rising cloud

00:01:13,799 --> 00:01:18,630
foundry and there's all the presumptions

00:01:16,619 --> 00:01:20,790
that hey everything from the user

00:01:18,630 --> 00:01:21,900
experience doesn't change at all and and

00:01:20,790 --> 00:01:24,630
then it's all going to be great from the

00:01:21,900 --> 00:01:26,820
operator experience but there's a lot of

00:01:24,630 --> 00:01:29,240
non-functional requirements in software

00:01:26,820 --> 00:01:33,060
one of those big important ones is

00:01:29,240 --> 00:01:35,040
performance did it does did it get a lot

00:01:33,060 --> 00:01:36,990
worse did it actually get a lot better

00:01:35,040 --> 00:01:40,860
did it get a little better what's going

00:01:36,990 --> 00:01:43,049
on so we're not really looking at a

00:01:40,860 --> 00:01:46,860
better worse but just to make sure that

00:01:43,049 --> 00:01:47,430
there weren't any critical flaws and you

00:01:46,860 --> 00:01:49,409
know because we've gone through

00:01:47,430 --> 00:01:50,850
exercises like this before and realized

00:01:49,409 --> 00:01:52,590
you know oops

00:01:50,850 --> 00:01:56,399
oh we've added two or three hops in here

00:01:52,590 --> 00:01:57,840
and and that makes things worse so it is

00:01:56,399 --> 00:02:00,320
it is addressing one of those

00:01:57,840 --> 00:02:04,110
non-functional requirements and software

00:02:00,320 --> 00:02:09,500
the next is what can we improve what

00:02:04,110 --> 00:02:09,500
learnings can we take away from this and

00:02:09,739 --> 00:02:13,709
so will to go into the methodology and

00:02:13,140 --> 00:02:15,900
here I'll

00:02:13,709 --> 00:02:17,849
pass off to Vlad and we'll he'll talk

00:02:15,900 --> 00:02:21,689
exactly what the environments were and

00:02:17,849 --> 00:02:24,390
the tests that were run all right okay

00:02:21,689 --> 00:02:27,120
so first about the environments we had

00:02:24,390 --> 00:02:29,879
to VM based environments and to

00:02:27,120 --> 00:02:32,780
container environments we're gonna split

00:02:29,879 --> 00:02:35,700
these up into minimal and heavy

00:02:32,780 --> 00:02:39,420
environments I'm going to explain

00:02:35,700 --> 00:02:41,909
exactly how much they cost how many CPUs

00:02:39,420 --> 00:02:44,670
they had and so on so we wanted to see

00:02:41,909 --> 00:02:47,519
okay if we take the minimal Bosch

00:02:44,670 --> 00:02:49,950
deployment as referenced by CF

00:02:47,519 --> 00:02:52,470
deployment what can we get out of that

00:02:49,950 --> 00:02:54,989
if we deploy something at the same cost

00:02:52,470 --> 00:02:59,069
in the container world what do we get

00:02:54,989 --> 00:03:02,579
out of that so this is how a minimal

00:02:59,069 --> 00:03:05,340
environment would look like for for

00:03:02,579 --> 00:03:08,340
Bosch let's say so we have three VM

00:03:05,340 --> 00:03:12,989
flavors for a Bosch deployment you need

00:03:08,340 --> 00:03:16,889
tiny VMs one CPU one memory 3.7 75 gigs

00:03:12,989 --> 00:03:19,400
of memory small with two two CPUs and

00:03:16,889 --> 00:03:22,560
small high memory with four CPUs and

00:03:19,400 --> 00:03:25,919
respective memory this is the cost for

00:03:22,560 --> 00:03:27,810
each of those types of VMs and in total

00:03:25,919 --> 00:03:30,889
for the minimal deployment that you can

00:03:27,810 --> 00:03:33,659
currently do with CF deployment on GCP

00:03:30,889 --> 00:03:36,569
you reach an estimated cost of about

00:03:33,659 --> 00:03:39,900
seven hundred and eighty dollars per

00:03:36,569 --> 00:03:43,109
month you get twenty two CPUs out of it

00:03:39,900 --> 00:03:45,989
and 93.5 kicks a memory so that's one of

00:03:43,109 --> 00:03:46,769
the environments its counterpart in the

00:03:45,989 --> 00:03:51,500
Fissel world

00:03:46,769 --> 00:03:53,849
so in gke you can provision nodes that

00:03:51,500 --> 00:04:00,560
become the workers of your kubernetes

00:03:53,849 --> 00:04:02,819
cluster we used the small flavor and

00:04:00,560 --> 00:04:06,629
because it's a homogeneous environment

00:04:02,819 --> 00:04:10,019
we just have one type of VM in our in

00:04:06,629 --> 00:04:12,449
our cluster we tried to estimate so that

00:04:10,019 --> 00:04:16,130
we get roughly the same cost but so for

00:04:12,449 --> 00:04:19,829
our environment we are a bit below

00:04:16,130 --> 00:04:21,239
there's a small hiccup here I think we

00:04:19,829 --> 00:04:24,300
should have used the small high memory

00:04:21,239 --> 00:04:26,470
that have given us a better match with

00:04:24,300 --> 00:04:28,420
the CPU and memory care

00:04:26,470 --> 00:04:30,640
we cannot take a hit so the continued

00:04:28,420 --> 00:04:33,340
containerized approach takes a bit of a

00:04:30,640 --> 00:04:36,190
performance hit here because it has less

00:04:33,340 --> 00:04:40,890
memory and less CPU at roughly the same

00:04:36,190 --> 00:04:44,620
cost so anyway this is the minimum and

00:04:40,890 --> 00:04:48,130
then we have the heavy one so we wanted

00:04:44,620 --> 00:04:50,320
to push the the minimal environments to

00:04:48,130 --> 00:04:53,590
the brain where they couldn't accept

00:04:50,320 --> 00:04:55,480
more applications and then after running

00:04:53,590 --> 00:04:59,380
those tests and see how it performs

00:04:55,480 --> 00:05:00,970
let's just create more space and then

00:04:59,380 --> 00:05:02,800
see what happens when everything is ok

00:05:00,970 --> 00:05:06,610
and well and when we don't run out of

00:05:02,800 --> 00:05:09,100
resources so in this case you

00:05:06,610 --> 00:05:13,300
essentially add five more cells to the

00:05:09,100 --> 00:05:16,630
Boche deployment which means for more

00:05:13,300 --> 00:05:20,200
small high memories so you get a ton

00:05:16,630 --> 00:05:23,470
more memory you also add some routers

00:05:20,200 --> 00:05:26,970
and some api's so you end up with a much

00:05:23,470 --> 00:05:32,020
beefier system it'll cost you around

00:05:26,970 --> 00:05:36,370
$1,500 a month but it'll it'll it'll set

00:05:32,020 --> 00:05:37,390
more applications again for the Fissel

00:05:36,370 --> 00:05:39,790
based environment so for the

00:05:37,390 --> 00:05:44,370
containerized one there's a modulus

00:05:39,790 --> 00:05:48,160
environment we use 19 small vm types

00:05:44,370 --> 00:05:50,740
that gives you 142 gigs of ram and 38

00:05:48,160 --> 00:05:53,140
cpus again should I use small high

00:05:50,740 --> 00:05:56,070
memory we would have gotten around the

00:05:53,140 --> 00:05:59,500
same cost but a much better

00:05:56,070 --> 00:06:03,100
approximation with memory so this is

00:05:59,500 --> 00:06:05,140
what we're running on is it just a you

00:06:03,100 --> 00:06:07,330
know clarify what we were doing here was

00:06:05,140 --> 00:06:10,750
trying to create cost equivalent systems

00:06:07,330 --> 00:06:13,590
and then see any cost equivalency what

00:06:10,750 --> 00:06:17,890
kind of performance we were getting

00:06:13,590 --> 00:06:19,510
there is as well you know we could be

00:06:17,890 --> 00:06:21,700
pushing and doing all the small high

00:06:19,510 --> 00:06:24,520
memory the it would look a little

00:06:21,700 --> 00:06:26,140
different but we're not targeting that

00:06:24,520 --> 00:06:28,360
we have a couple of slides at the end

00:06:26,140 --> 00:06:32,599
for if you did want to do that what your

00:06:28,360 --> 00:06:36,770
result might be yeah so what do we get

00:06:32,599 --> 00:06:39,559
oh one more thing how did the tests look

00:06:36,770 --> 00:06:41,020
like so we use the locus framework it's

00:06:39,559 --> 00:06:44,360
a python-based framework for writing

00:06:41,020 --> 00:06:47,779
agents that do things and then it'll

00:06:44,360 --> 00:06:51,439
measure how how the requests happen and

00:06:47,779 --> 00:06:55,069
you'll get reports at the end our agents

00:06:51,439 --> 00:06:56,599
that do Cloud Foundry things can can

00:06:55,069 --> 00:06:59,240
perform these types of actions they can

00:06:56,599 --> 00:07:01,759
push the Dora application they can make

00:06:59,240 --> 00:07:04,069
requests to random applications so they

00:07:01,759 --> 00:07:05,240
look at the available applications that

00:07:04,069 --> 00:07:07,699
have been deployed they try to make a

00:07:05,240 --> 00:07:10,580
request see if that succeeds or not they

00:07:07,699 --> 00:07:12,889
can delete a random application they can

00:07:10,580 --> 00:07:16,729
also call the stress endpoint of of an

00:07:12,889 --> 00:07:18,409
app so the Dora application if you're

00:07:16,729 --> 00:07:20,869
familiar with it in the clouds on your

00:07:18,409 --> 00:07:22,580
acceptance tests there's this Dora

00:07:20,869 --> 00:07:25,610
application that has a bunch of

00:07:22,580 --> 00:07:27,979
endpoints that you can use to trigger a

00:07:25,610 --> 00:07:31,009
behavior one of those is a stress

00:07:27,979 --> 00:07:37,909
behavior which essentially would start

00:07:31,009 --> 00:07:40,369
eating CPU and make IO make intensive IO

00:07:37,909 --> 00:07:43,209
IO calls essentially acting like like a

00:07:40,369 --> 00:07:46,849
bad app like a like a bad agent like

00:07:43,209 --> 00:07:50,059
either a bad application or a malicious

00:07:46,849 --> 00:07:52,309
agent so sometimes these tests will

00:07:50,059 --> 00:07:54,589
actually call the stress system the

00:07:52,309 --> 00:07:57,979
stress endpoint simulating a bad agent

00:07:54,589 --> 00:08:00,169
in the in the cloud and then listing

00:07:57,979 --> 00:08:02,089
applications the numbers that you see in

00:08:00,169 --> 00:08:06,319
parentheses are the weight of that

00:08:02,089 --> 00:08:08,209
action so it's 50 times more likely to

00:08:06,319 --> 00:08:11,209
make a request to an app than it is to

00:08:08,209 --> 00:08:13,099
push in app so we run 20 of these agents

00:08:11,209 --> 00:08:15,379
across five hours and and see what

00:08:13,099 --> 00:08:17,689
happens and of course it's much less

00:08:15,379 --> 00:08:19,789
likely to delete an app because we want

00:08:17,689 --> 00:08:22,969
to build up we don't want to keep

00:08:19,789 --> 00:08:24,740
churning and and not reaching the limit

00:08:22,969 --> 00:08:27,289
of our cluster we actually want to push

00:08:24,740 --> 00:08:32,149
it to the brink and of course it's much

00:08:27,289 --> 00:08:34,759
less likely to actually get a bad actor

00:08:32,149 --> 00:08:37,159
but that happens as well so when one

00:08:34,759 --> 00:08:41,599
once that happens essentially you kind

00:08:37,159 --> 00:08:43,190
of one of your CP uses is is running a

00:08:41,599 --> 00:08:49,880
hundred percent on

00:08:43,190 --> 00:08:53,339
on whatever that stress test does okay

00:08:49,880 --> 00:08:54,360
so results we're going to go through

00:08:53,339 --> 00:08:57,000
some charts and I'm going to try to

00:08:54,360 --> 00:08:59,120
explain what they mean and what we what

00:08:57,000 --> 00:09:02,820
we were trying to learn from them

00:08:59,120 --> 00:09:05,880
so first pushing applications in the

00:09:02,820 --> 00:09:10,470
minimal environment success versus

00:09:05,880 --> 00:09:13,110
failure so in the green here we have how

00:09:10,470 --> 00:09:16,430
many apps were successfully pushed by

00:09:13,110 --> 00:09:19,350
the Fissel environment with blue we see

00:09:16,430 --> 00:09:22,649
the Bosch how many successful apps were

00:09:19,350 --> 00:09:25,709
pushed using the barcia environment red

00:09:22,649 --> 00:09:28,829
is failure for box and the orange is

00:09:25,709 --> 00:09:31,680
failure for for vessel what you want to

00:09:28,829 --> 00:09:36,390
see when you have sufficient space is

00:09:31,680 --> 00:09:39,959
that failures are zero or nil you'll see

00:09:36,390 --> 00:09:41,640
that in the large in the heavy tests we

00:09:39,959 --> 00:09:44,820
never reach the capacity of that cloud

00:09:41,640 --> 00:09:48,029
so these will be zero you never want to

00:09:44,820 --> 00:09:50,730
see errors here so what do we see how

00:09:48,029 --> 00:09:53,010
can you interpret this well using the

00:09:50,730 --> 00:09:57,149
same amount of money it was like 700

00:09:53,010 --> 00:10:00,540
bucks we can push many more apps in the

00:09:57,149 --> 00:10:03,510
Fissel based deployment so it'll take

00:10:00,540 --> 00:10:06,270
more applications because you can pack

00:10:03,510 --> 00:10:09,329
more in given that it's a homogeneous

00:10:06,270 --> 00:10:11,130
environment and you run cells on on each

00:10:09,329 --> 00:10:13,950
of the each of the nodes that make up

00:10:11,130 --> 00:10:15,870
your cluster and obviously there are

00:10:13,950 --> 00:10:18,420
fewer errors because you reach capacity

00:10:15,870 --> 00:10:20,760
later so you pushed more and more

00:10:18,420 --> 00:10:25,910
applications and you reach capacity

00:10:20,760 --> 00:10:25,910
later and yep

00:10:26,250 --> 00:10:31,620
pushing application duration so how long

00:10:29,790 --> 00:10:34,500
does it take to push an app on each of

00:10:31,620 --> 00:10:37,860
these environments you don't want to see

00:10:34,500 --> 00:10:40,620
a large difference here in here we do

00:10:37,860 --> 00:10:43,040
see that the Box one on average takes a

00:10:40,620 --> 00:10:47,160
bit longer for the minimal environment

00:10:43,040 --> 00:10:50,579
and it goes up as the cluster runs out

00:10:47,160 --> 00:10:52,800
of resources and we see it for the

00:10:50,579 --> 00:10:54,300
fissile one it also runs our resources

00:10:52,800 --> 00:10:58,930
and

00:10:54,300 --> 00:11:01,029
kind of levels off here but the

00:10:58,930 --> 00:11:04,270
difference is not that large so you see

00:11:01,029 --> 00:11:07,870
the here the we have 50 seconds here and

00:11:04,270 --> 00:11:10,839
55 seconds here so not not that big of a

00:11:07,870 --> 00:11:14,350
difference and then application requests

00:11:10,839 --> 00:11:17,650
how long does it take to send a request

00:11:14,350 --> 00:11:22,410
to to the application and get a response

00:11:17,650 --> 00:11:22,410
back and here it's it's very similar

00:11:22,920 --> 00:11:28,839
yeah here is very similar there's little

00:11:26,230 --> 00:11:33,040
difference the fissile one is a bit

00:11:28,839 --> 00:11:35,710
faster I I don't know exactly why in

00:11:33,040 --> 00:11:38,040
this case it's a bit faster it's maybe

00:11:35,710 --> 00:11:43,480
something that we should investigate and

00:11:38,040 --> 00:11:46,180
maybe the CF deployment topology can

00:11:43,480 --> 00:11:47,890
change a bit or maybe we can we have the

00:11:46,180 --> 00:11:49,570
suppositions that GK is just operating

00:11:47,890 --> 00:11:52,589
straight bare metal so you're just

00:11:49,570 --> 00:11:55,660
taking one layer virtualization out and

00:11:52,589 --> 00:11:57,400
getting a little advantage okay so these

00:11:55,660 --> 00:11:59,410
were the charts for the minimal

00:11:57,400 --> 00:12:01,120
deployment but what we can learn from it

00:11:59,410 --> 00:12:02,470
is there is no real difference when it

00:12:01,120 --> 00:12:04,420
comes to application requests so the

00:12:02,470 --> 00:12:06,220
networking part seems to be the same

00:12:04,420 --> 00:12:09,400
you're not taking it hit by doing

00:12:06,220 --> 00:12:11,680
containers and containers you do get a

00:12:09,400 --> 00:12:15,790
benefit of application density you can

00:12:11,680 --> 00:12:17,440
push more into and get more out of your

00:12:15,790 --> 00:12:21,790
cluster so for the same amount of money

00:12:17,440 --> 00:12:24,130
you could run more applications okay so

00:12:21,790 --> 00:12:26,950
this is the heavy environment in this

00:12:24,130 --> 00:12:29,080
case we have much more space the cluster

00:12:26,950 --> 00:12:32,040
doesn't run out of resources you can you

00:12:29,080 --> 00:12:35,529
can push many more apps so everything is

00:12:32,040 --> 00:12:38,980
is running okay in this case we see that

00:12:35,529 --> 00:12:41,860
the Bosch VM based one was able to push

00:12:38,980 --> 00:12:44,170
a few more applications than then the

00:12:41,860 --> 00:12:46,330
fissile based one there are no errors

00:12:44,170 --> 00:12:48,700
for any of these which is great so you

00:12:46,330 --> 00:12:53,440
can keep pushing apps they're both

00:12:48,700 --> 00:12:56,290
stable they they both allow the

00:12:53,440 --> 00:13:00,510
developer to to run their applications

00:12:56,290 --> 00:13:00,510
without without error so that's great

00:13:00,840 --> 00:13:06,750
how long does it take to push a nap so

00:13:03,180 --> 00:13:10,020
here we see that you want this number to

00:13:06,750 --> 00:13:14,550
be lower in the case of Bosch when we

00:13:10,020 --> 00:13:17,750
added resources the time to push went

00:13:14,550 --> 00:13:20,310
went down a lot and the average dropped

00:13:17,750 --> 00:13:24,990
for fissile it kind of stayed this the

00:13:20,310 --> 00:13:27,780
same as the as the minimal test we think

00:13:24,990 --> 00:13:30,450
that this is because of our Dell tax the

00:13:27,780 --> 00:13:35,220
bill tax we ship we shipped with SCF

00:13:30,450 --> 00:13:38,880
have bits for more stacks we have

00:13:35,220 --> 00:13:40,920
openSUSE 42 and Slee so the build packs

00:13:38,880 --> 00:13:44,340
are bigger so they might generate more

00:13:40,920 --> 00:13:46,620
traffic so it might take longer to to

00:13:44,340 --> 00:13:48,180
push these applications it could also be

00:13:46,620 --> 00:13:52,820
that we're not doing as much caching

00:13:48,180 --> 00:13:55,620
because we have on line build packs so

00:13:52,820 --> 00:13:57,330
it's probably some sort of one of these

00:13:55,620 --> 00:14:01,740
so it's something that we learned and

00:13:57,330 --> 00:14:03,600
we're gonna take a look at so this also

00:14:01,740 --> 00:14:06,420
makes sense because if we push

00:14:03,600 --> 00:14:09,270
applications a bit slower it makes sense

00:14:06,420 --> 00:14:11,550
that Bosch Gates gains an advantage here

00:14:09,270 --> 00:14:15,300
in how many applications you can push

00:14:11,550 --> 00:14:19,530
inside five hours so bit of advantage

00:14:15,300 --> 00:14:22,590
there and finally the application

00:14:19,530 --> 00:14:25,220
request duration this one is basically

00:14:22,590 --> 00:14:28,080
the same you can't see any difference

00:14:25,220 --> 00:14:30,960
for Boston Pizza which is great I mean

00:14:28,080 --> 00:14:33,180
at the end I think this one is what we

00:14:30,960 --> 00:14:34,710
were mostly scared about so once you

00:14:33,180 --> 00:14:38,750
push your application you're not gonna

00:14:34,710 --> 00:14:41,730
push one app every 10 seconds forever

00:14:38,750 --> 00:14:44,310
but you are gonna get requests a lot of

00:14:41,730 --> 00:14:46,680
requests for your applications and this

00:14:44,310 --> 00:14:48,420
is what matters that we don't see

00:14:46,680 --> 00:14:52,590
discrepancies here and the fact that we

00:14:48,420 --> 00:14:55,200
run with oh and by the way the fissile

00:14:52,590 --> 00:14:58,470
deployment with helm was done with load

00:14:55,200 --> 00:15:01,770
balancers and the VM based one was done

00:14:58,470 --> 00:15:04,470
with load balancers as well on GK so as

00:15:01,770 --> 00:15:07,350
you probably know in kubernetes we also

00:15:04,470 --> 00:15:09,680
have services there's an extra network

00:15:07,350 --> 00:15:11,570
that's that's available there

00:15:09,680 --> 00:15:15,560
we were of course everyone's afraid that

00:15:11,570 --> 00:15:22,520
that might make us lose some time but we

00:15:15,560 --> 00:15:26,930
don't so that's great okay so we learned

00:15:22,520 --> 00:15:28,520
that we don't seem to have made any huge

00:15:26,930 --> 00:15:30,950
errors when containerized cloud foundry

00:15:28,520 --> 00:15:34,070
we are after all running the exact same

00:15:30,950 --> 00:15:36,080
bits that's why we're we're certified by

00:15:34,070 --> 00:15:38,029
the foundation so the exact same bits

00:15:36,080 --> 00:15:41,330
that are running in VMs are running in

00:15:38,029 --> 00:15:43,550
containers as well the infrastructure

00:15:41,330 --> 00:15:49,190
that kubernetes has doesn't slow down

00:15:43,550 --> 00:15:53,230
application requests we do have to learn

00:15:49,190 --> 00:15:56,000
about these differences I think the VM

00:15:53,230 --> 00:15:57,890
team so that CF deployment team could

00:15:56,000 --> 00:16:01,610
take a look at these maybe and think

00:15:57,890 --> 00:16:04,820
about how how to reduce that initial

00:16:01,610 --> 00:16:08,959
footprint that Bosch VMs that a VM

00:16:04,820 --> 00:16:11,540
deployment brings because there's

00:16:08,959 --> 00:16:14,839
there's so many resources lost when you

00:16:11,540 --> 00:16:18,500
just start with 15 VMs now you spend a

00:16:14,839 --> 00:16:21,860
lot of money and you can't push a lot of

00:16:18,500 --> 00:16:25,940
apps really and of course we can look at

00:16:21,860 --> 00:16:30,650
those as the reason why push takes a bit

00:16:25,940 --> 00:16:32,630
longer with this out so so what's next

00:16:30,650 --> 00:16:35,089
for these we want to add more test

00:16:32,630 --> 00:16:38,390
scenarios like finding applications

00:16:35,089 --> 00:16:42,380
using services that using applications

00:16:38,390 --> 00:16:44,209
that use services things like that we

00:16:42,380 --> 00:16:46,820
want to add these performance tests as

00:16:44,209 --> 00:16:49,670
part of our pipeline so when we release

00:16:46,820 --> 00:16:53,450
SCF we run into a whole battery of tests

00:16:49,670 --> 00:16:56,360
including cats brats we have our own set

00:16:53,450 --> 00:16:58,490
of acceptance tests we want to add these

00:16:56,360 --> 00:17:02,029
performance tests and grab a snapshot of

00:16:58,490 --> 00:17:03,560
the data each time we release then of

00:17:02,029 --> 00:17:07,600
course we want to investigate all these

00:17:03,560 --> 00:17:07,600
tiny discrepancies that we saw

00:17:10,990 --> 00:17:16,089
you've probably heard a lot about

00:17:12,539 --> 00:17:18,939
containerization and ireenie so for

00:17:16,089 --> 00:17:20,610
continues ation with regard to

00:17:18,939 --> 00:17:24,339
performance you have to think about

00:17:20,610 --> 00:17:28,960
adoption of CF deployment we want to be

00:17:24,339 --> 00:17:30,760
able to deploy our our cloud our

00:17:28,960 --> 00:17:33,940
containerized cloud foundry the same way

00:17:30,760 --> 00:17:37,120
that the vm based one is deployed have

00:17:33,940 --> 00:17:39,789
the same composition of roles be able to

00:17:37,120 --> 00:17:42,070
manage to manage it using a cube

00:17:39,789 --> 00:17:45,429
operator which means we won't have

00:17:42,070 --> 00:17:48,159
Monnett anymore will will further reduce

00:17:45,429 --> 00:17:51,010
the amount of things that run in order

00:17:48,159 --> 00:17:53,620
to have a CF deployment so the footprint

00:17:51,010 --> 00:17:54,640
that will have will be even smaller if

00:17:53,620 --> 00:17:57,490
one of the aspects of the

00:17:54,640 --> 00:17:59,100
containerization is is again we are

00:17:57,490 --> 00:18:01,779
seeking to have a certified

00:17:59,100 --> 00:18:03,760
implementation there are some

00:18:01,779 --> 00:18:05,980
limitations in that in the

00:18:03,760 --> 00:18:08,860
containerization or going beyond

00:18:05,980 --> 00:18:10,690
containerization cuba fication and this

00:18:08,860 --> 00:18:13,809
is part of the ongoing conversation that

00:18:10,690 --> 00:18:15,490
we're having in terms of well if we're

00:18:13,809 --> 00:18:18,520
not thinking only in terms of VMs

00:18:15,490 --> 00:18:23,140
anymore how else could we refactor and

00:18:18,520 --> 00:18:25,000
gain further efficiencies the operators

00:18:23,140 --> 00:18:35,320
a big piece of that and an even bigger

00:18:25,000 --> 00:18:39,330
piece is Irene so competing with the AI

00:18:35,320 --> 00:18:41,830
with Jules and Jules and Irene above but

00:18:39,330 --> 00:18:45,580
OneNote so all of these numbers are done

00:18:41,830 --> 00:18:47,830
again as we mentioned with Diego and the

00:18:45,580 --> 00:18:51,700
container and container approach Irene E

00:18:47,830 --> 00:18:55,090
is pure CF push to cuban kubernetes

00:18:51,700 --> 00:18:58,659
scheduling so you remove diego remove

00:18:55,090 --> 00:19:01,360
all of the extra stuff that diego adds

00:18:58,659 --> 00:19:03,070
and rely purely on kubernetes for your

00:19:01,360 --> 00:19:06,640
scheduling it would go right into a

00:19:03,070 --> 00:19:08,980
namespace next to your your other apps

00:19:06,640 --> 00:19:11,289
this also would improve a general

00:19:08,980 --> 00:19:13,390
efficiency you don't have to worry about

00:19:11,289 --> 00:19:15,309
how many Diego's do I have you're really

00:19:13,390 --> 00:19:17,950
only thinking at the platform layer of

00:19:15,309 --> 00:19:20,919
how much space is my kubernetes platform

00:19:17,950 --> 00:19:22,620
have I wanted to add one more thing to

00:19:20,919 --> 00:19:24,870
this aspect

00:19:22,620 --> 00:19:27,630
we do have some control now of how we

00:19:24,870 --> 00:19:30,809
optimize the topology when you deploy to

00:19:27,630 --> 00:19:33,120
kubernetes a good example is anti

00:19:30,809 --> 00:19:35,640
infinity rules between routers and in

00:19:33,120 --> 00:19:37,680
cells we noticed that if they would be

00:19:35,640 --> 00:19:39,330
co-located so if the same kubernetes

00:19:37,680 --> 00:19:41,490
node were to run your router and

00:19:39,330 --> 00:19:44,190
yourself performance would drop

00:19:41,490 --> 00:19:47,220
drastically because the router needs a

00:19:44,190 --> 00:19:49,650
lot of CPU and your app might compete

00:19:47,220 --> 00:19:51,809
with that and then it just gets slowed

00:19:49,650 --> 00:19:53,490
down a lot but we can do that but with

00:19:51,809 --> 00:19:55,320
the cube operator we might get even

00:19:53,490 --> 00:19:57,570
better at it and we might be able to

00:19:55,320 --> 00:20:00,330
share that knowledge with with CF

00:19:57,570 --> 00:20:04,650
deployment so that's that's gonna be

00:20:00,330 --> 00:20:07,920
pretty great okay so for Jeff's request

00:20:04,650 --> 00:20:11,910
we have a bonus around the slides what

00:20:07,920 --> 00:20:15,090
if you wanted to run the minimal minimal

00:20:11,910 --> 00:20:19,170
SCF so we looked at the minimal Bosch it

00:20:15,090 --> 00:20:22,020
takes 15 VMs or something but what if I

00:20:19,170 --> 00:20:23,910
wanted to run a very small footprint of

00:20:22,020 --> 00:20:26,040
a CF what does that look like and how

00:20:23,910 --> 00:20:30,059
does that compare to the minimum Bosch

00:20:26,040 --> 00:20:33,929
so what we usually do when we deploy a

00:20:30,059 --> 00:20:39,150
CF minimally is we have around 20 gigs

00:20:33,929 --> 00:20:42,840
of ram so that means 3 small small VMs

00:20:39,150 --> 00:20:45,480
here you get about 22 gigs of memory and

00:20:42,840 --> 00:20:49,020
it has a cost of two hundred forty-seven

00:20:45,480 --> 00:20:51,270
dollars a month approximately so what

00:20:49,020 --> 00:20:55,429
does that bring you so again we see the

00:20:51,270 --> 00:20:59,130
chart success versus failure for apps

00:20:55,429 --> 00:21:01,590
you see that Bosch does allow more

00:20:59,130 --> 00:21:04,800
applications in but remember it's also

00:21:01,590 --> 00:21:08,160
three times as expensive and we have

00:21:04,800 --> 00:21:11,059
successes for Fissel so you can push

00:21:08,160 --> 00:21:16,260
about 80 I think it was 83 applications

00:21:11,059 --> 00:21:19,650
each door optics is set to use the 256

00:21:16,260 --> 00:21:24,600
Meg's of memory so in this case you can

00:21:19,650 --> 00:21:27,450
run 83 and Bars can run 120 but you paid

00:21:24,600 --> 00:21:30,059
a lot more for the box one so it kind of

00:21:27,450 --> 00:21:33,540
turns out that you would be paying six

00:21:30,059 --> 00:21:34,960
bucks an app in the Bosch case and about

00:21:33,540 --> 00:21:37,360
three bucks an app for

00:21:34,960 --> 00:21:39,669
for the Fissel case of course if you

00:21:37,360 --> 00:21:44,049
pack all of your applications into the

00:21:39,669 --> 00:21:48,340
smallest environment possible again

00:21:44,049 --> 00:21:52,990
average duration fissile gets warm and

00:21:48,340 --> 00:21:55,480
the kind of it's similar you get like an

00:21:52,990 --> 00:21:57,730
average of 80 seconds to push an

00:21:55,480 --> 00:22:01,270
application with the fissile one versus

00:21:57,730 --> 00:22:05,350
about 60 50 60 seconds for the Box one

00:22:01,270 --> 00:22:07,659
and again the application request is

00:22:05,350 --> 00:22:09,640
virtually the same there there's almost

00:22:07,659 --> 00:22:10,230
no difference if someone takes just a

00:22:09,640 --> 00:22:12,280
bit longer

00:22:10,230 --> 00:22:16,059
because we run in such a more

00:22:12,280 --> 00:22:18,220
constrained environment but yeah you can

00:22:16,059 --> 00:22:21,580
get started more quickly and this is a

00:22:18,220 --> 00:22:24,220
much affordable number I think if you

00:22:21,580 --> 00:22:24,490
look at it to get started with this you

00:22:24,220 --> 00:22:27,640
have the

00:22:24,490 --> 00:22:29,830
witta C of deployment and another thing

00:22:27,640 --> 00:22:32,080
that we're taking away from all these

00:22:29,830 --> 00:22:34,000
tests you saw that we're using it's

00:22:32,080 --> 00:22:35,140
actually most easy to set up in a

00:22:34,000 --> 00:22:38,470
criminai his environment to use a

00:22:35,140 --> 00:22:41,919
homogenous we chosen small we didn't

00:22:38,470 --> 00:22:43,750
choose small high memory we think we

00:22:41,919 --> 00:22:47,200
didn't test but we think that that

00:22:43,750 --> 00:22:49,600
wouldn't give us a the proper V CPU to

00:22:47,200 --> 00:22:52,419
memory ratio or rather there'd be too

00:22:49,600 --> 00:22:54,429
few you got up a ton of memory maybe you

00:22:52,419 --> 00:22:58,090
we would actually like to test that and

00:22:54,429 --> 00:23:00,190
see what the real impact is you know all

00:22:58,090 --> 00:23:02,230
this part is that we we do this and then

00:23:00,190 --> 00:23:05,650
recommend reference architectures we've

00:23:02,230 --> 00:23:09,340
been recommending kind of about this you

00:23:05,650 --> 00:23:10,120
know one before ratio and to move to

00:23:09,340 --> 00:23:12,400
something different

00:23:10,120 --> 00:23:13,630
we'd have to see what the real impact is

00:23:12,400 --> 00:23:15,700
so that's another takeaway for us

00:23:13,630 --> 00:23:17,770
because if you did that you know we

00:23:15,700 --> 00:23:20,890
could have had just one small high

00:23:17,770 --> 00:23:24,250
memory I could have cut another 33% off

00:23:20,890 --> 00:23:27,130
of this cost but I'm not quite sure what

00:23:24,250 --> 00:23:28,630
the the app duration and now I have to

00:23:27,130 --> 00:23:31,299
approve another couple thousand dollars

00:23:28,630 --> 00:23:34,990
worth of time online for flag to figure

00:23:31,299 --> 00:23:38,460
this out yeah I think a bottom line is

00:23:34,990 --> 00:23:40,480
that it were ever worried that

00:23:38,460 --> 00:23:43,000
containerized approach was not as stable

00:23:40,480 --> 00:23:45,820
or is not not as performant you don't

00:23:43,000 --> 00:23:48,460
have to worry it turns out it is it's

00:23:45,820 --> 00:23:55,540
stable it'll save you money

00:23:48,460 --> 00:24:08,950
yeah we think it's a good choice that's

00:23:55,540 --> 00:24:10,750
it take some questions I guess I'm a

00:24:08,950 --> 00:24:12,520
good observation so does that mean that

00:24:10,750 --> 00:24:15,670
containers over containers over

00:24:12,520 --> 00:24:18,520
containers doesn't matter we there was a

00:24:15,670 --> 00:24:20,440
lot of question about that you know one

00:24:18,520 --> 00:24:22,000
you're adding in some extra with just

00:24:20,440 --> 00:24:23,470
kubernetes itself ingress controllers

00:24:22,000 --> 00:24:28,480
and all this and then container in

00:24:23,470 --> 00:24:31,930
container on the backend and the answer

00:24:28,480 --> 00:24:34,330
is no no I think so you are sharing the

00:24:31,930 --> 00:24:35,830
kernel it's not like you're running VMs

00:24:34,330 --> 00:24:38,020
and VMs that would be a terrible idea

00:24:35,830 --> 00:24:40,060
but with containers in containers you

00:24:38,020 --> 00:24:43,740
are using the same kernel of the host

00:24:40,060 --> 00:24:45,250
now if you were doing some math

00:24:43,740 --> 00:24:47,560
calculations I don't know you're

00:24:45,250 --> 00:24:48,730
computing PI for some reason you might

00:24:47,560 --> 00:24:51,310
find that there's a difference there

00:24:48,730 --> 00:24:52,930
maybe but that's not the correct test

00:24:51,310 --> 00:24:55,030
for this level yeah

00:24:52,930 --> 00:24:56,950
so for our purposes for a web

00:24:55,030 --> 00:24:58,870
application I don't think it matters and

00:24:56,950 --> 00:25:02,200
to have different workloads to try

00:24:58,870 --> 00:25:06,940
instead of just door oh yeah definitely

00:25:02,200 --> 00:25:09,520
okay and more frameworks so Dora is Ruby

00:25:06,940 --> 00:25:11,530
by the way but we want to push different

00:25:09,520 --> 00:25:17,200
apps too and exercise all of the bill

00:25:11,530 --> 00:25:21,910
packs yeah any questions I can't beat if

00:25:17,200 --> 00:25:24,270
there's any question no questions I have

00:25:21,910 --> 00:25:27,790
a question too but yeah go for it

00:25:24,270 --> 00:25:40,000
so was the Bosh deployment using online

00:25:27,790 --> 00:25:43,480
bill packs as well no default is okay is

00:25:40,000 --> 00:25:46,210
more for my scientific perspective I

00:25:43,480 --> 00:25:48,940
mean I I know you brushed up on it

00:25:46,210 --> 00:25:50,500
methodology and everything the key

00:25:48,940 --> 00:25:52,780
question is can somebody else reproduce

00:25:50,500 --> 00:25:54,550
this oh you have enough information that

00:25:52,780 --> 00:25:57,760
people can go and try it and of course

00:25:54,550 --> 00:25:58,809
try it on GC g ke and or different other

00:25:57,760 --> 00:26:01,360
places i go

00:25:58,809 --> 00:26:03,249
was have a docker image pointed to a

00:26:01,360 --> 00:26:06,190
glove on your cluster and then it spits

00:26:03,249 --> 00:26:08,710
out these charts for you so that's I'm

00:26:06,190 --> 00:26:10,629
almost there here almost there so it's

00:26:08,710 --> 00:26:12,429
gonna be open source and you'll just be

00:26:10,629 --> 00:26:14,889
able to run the image appointed and

00:26:12,429 --> 00:26:21,789
it'll spit out these these charts for

00:26:14,889 --> 00:26:24,519
you thank you no questions okay go run

00:26:21,789 --> 00:26:26,889
your Cloud Foundry on containers it

00:26:24,519 --> 00:26:27,309
seems like oh if you do that's not a

00:26:26,889 --> 00:26:31,440
problem

00:26:27,309 --> 00:26:37,680
Thank You Vlad and Geoff appreciate it

00:26:31,440 --> 00:26:37,680

YouTube URL: https://www.youtube.com/watch?v=YJKbbuxmt0U


