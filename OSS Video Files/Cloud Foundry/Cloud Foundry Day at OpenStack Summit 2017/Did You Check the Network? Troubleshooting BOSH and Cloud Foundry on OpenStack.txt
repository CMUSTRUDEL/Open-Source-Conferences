Title: Did You Check the Network? Troubleshooting BOSH and Cloud Foundry on OpenStack
Publication date: 2017-05-16
Playlist: Cloud Foundry Day at OpenStack Summit 2017
Description: 
	The goal of any PaaS is to abstract away the underlying hardware or software infrastructure. "Here is my application, I don't care how you deploy it, just get it done!" But your target infrastructure will have its own nuances. This is certainly true for OpenStack. Having deployed and automated BOSH and Cloud Foundry hundreds of times, over several versions of OpenStack, we at Stark & Wayne have had the opportunity to see many of the edge cases, and constant sources of implementation pain that oc
Captions: 
	00:00:05,450 --> 00:00:10,139
check alright I guess this thing's on hi

00:00:09,180 --> 00:00:12,240
everybody

00:00:10,139 --> 00:00:13,800
I tried to hide all the way up here in

00:00:12,240 --> 00:00:15,450
the corner and it seems a bunch of you

00:00:13,800 --> 00:00:16,699
found me anyways so I guess I have to

00:00:15,450 --> 00:00:20,550
give a talk

00:00:16,699 --> 00:00:22,769
so I'm bill Chapman and I am a cloud

00:00:20,550 --> 00:00:25,550
architect and Technical Account Manager

00:00:22,769 --> 00:00:29,069
at Stark and Wayne I've been deploying

00:00:25,550 --> 00:00:30,839
maintaining and troubleshooting

00:00:29,069 --> 00:00:33,200
platforms and services on top of

00:00:30,839 --> 00:00:35,340
OpenStack for a couple of years now

00:00:33,200 --> 00:00:38,790
primarily Cloud Foundry and Bosch

00:00:35,340 --> 00:00:41,700
related services I came to this space by

00:00:38,790 --> 00:00:43,530
way of application development I was in

00:00:41,700 --> 00:00:48,510
application architect looking for a

00:00:43,530 --> 00:00:50,310
better way to scale my applications and

00:00:48,510 --> 00:00:52,940
as I said I work for Stark and Wayne and

00:00:50,310 --> 00:00:55,320
Stark and Wayne is a multidisciplinary

00:00:52,940 --> 00:00:58,770
operations team we've got folks from the

00:00:55,320 --> 00:01:00,480
application space DevOps infrastructure

00:00:58,770 --> 00:01:02,250
and we all come together on the layer in

00:01:00,480 --> 00:01:07,980
between the infrastructure and the

00:01:02,250 --> 00:01:10,470
application where our PA's libs Cloud

00:01:07,980 --> 00:01:13,050
Foundry and Bosh are a core component of

00:01:10,470 --> 00:01:16,350
what we do every day and yes as far as

00:01:13,050 --> 00:01:21,320
anyone is concerned Batman and Iron Man

00:01:16,350 --> 00:01:23,520
are our founders so this is OpenStack I

00:01:21,320 --> 00:01:26,220
don't think that I need to explain

00:01:23,520 --> 00:01:29,250
OpenStack and I would need the entire

00:01:26,220 --> 00:01:31,350
conference to do so but the reason I put

00:01:29,250 --> 00:01:34,440
this slide in is so that we can take a

00:01:31,350 --> 00:01:36,510
second to look at OpenStack for what it

00:01:34,440 --> 00:01:40,250
is it's a very complex distributed

00:01:36,510 --> 00:01:42,659
system errors can occur anywhere and

00:01:40,250 --> 00:01:48,030
they can bubble up to places you don't

00:01:42,659 --> 00:01:52,290
expect them in other systems and this is

00:01:48,030 --> 00:01:53,850
Cloud Foundry exact this is what Cloud

00:01:52,290 --> 00:01:58,020
Foundry looks like today along with a

00:01:53,850 --> 00:02:00,240
reference resource list there cloud

00:01:58,020 --> 00:02:06,570
foundry is also a very complex

00:02:00,240 --> 00:02:09,060
distributed system and this is bash

00:02:06,570 --> 00:02:11,360
which is a distributed system to

00:02:09,060 --> 00:02:14,069
distribute distributed systems no I'm

00:02:11,360 --> 00:02:15,420
Bosh's bash allows you to deploy

00:02:14,069 --> 00:02:17,640
distributed systems

00:02:15,420 --> 00:02:21,270
and Cloud Foundry of course is deployed

00:02:17,640 --> 00:02:22,800
via Bosch there are some situations like

00:02:21,270 --> 00:02:24,930
with pivotal cloud foundry where Bosch

00:02:22,800 --> 00:02:26,849
is mostly abstracted away behind their

00:02:24,930 --> 00:02:29,280
operations manager but it's still there

00:02:26,849 --> 00:02:31,110
you still have access to it so any

00:02:29,280 --> 00:02:33,239
discussion about troubleshooting cloud

00:02:31,110 --> 00:02:35,400
foundry at least on a high level like

00:02:33,239 --> 00:02:37,350
this talk is today is primarily going to

00:02:35,400 --> 00:02:41,550
be a discussion about troubleshooting

00:02:37,350 --> 00:02:46,500
Bosch if Bosch is doing its job then you

00:02:41,550 --> 00:02:49,080
should then Cloud Foundry in OpenStack

00:02:46,500 --> 00:02:51,540
really shouldn't interact as much and

00:02:49,080 --> 00:02:53,970
this is your brain on all of that this

00:02:51,540 --> 00:02:55,830
is what cramming a whole bunch of

00:02:53,970 --> 00:02:58,709
distributed systems together looks like

00:02:55,830 --> 00:03:02,610
and as I mentioned I came to this space

00:02:58,709 --> 00:03:04,819
by way of app development so I went from

00:03:02,610 --> 00:03:08,100
something that looks like this in

00:03:04,819 --> 00:03:11,250
general to something that looks like

00:03:08,100 --> 00:03:15,750
this and I'm starting to question my

00:03:11,250 --> 00:03:19,920
life choices but fortunately I found a

00:03:15,750 --> 00:03:21,840
lot of places to get help if you get

00:03:19,920 --> 00:03:24,570
getting involved in the Cloud Foundry

00:03:21,840 --> 00:03:26,280
community is one of the first steps

00:03:24,570 --> 00:03:29,519
towards troubleshooting your environment

00:03:26,280 --> 00:03:31,530
I spent a lot of time on the forums when

00:03:29,519 --> 00:03:33,359
I was first trying to find my way

00:03:31,530 --> 00:03:35,910
through my first Cloud Foundry

00:03:33,359 --> 00:03:37,709
deployments especially on OpenStack and

00:03:35,910 --> 00:03:39,900
you would be amazed how many people in

00:03:37,709 --> 00:03:43,350
the Cloud Foundry community have

00:03:39,900 --> 00:03:45,900
phenomenal experience and deep knowledge

00:03:43,350 --> 00:03:49,609
of OpenStack we have some people in the

00:03:45,900 --> 00:03:49,609
audience today who have that knowledge

00:03:49,640 --> 00:03:56,340
but wait there's more

00:03:52,170 --> 00:03:58,560
if you sign up today I'll throw in over

00:03:56,340 --> 00:04:00,450
80 other non-trivial services and

00:03:58,560 --> 00:04:03,350
systems that you can deploy via Bosch a

00:04:00,450 --> 00:04:10,400
whole lot of this talk also applies to

00:04:03,350 --> 00:04:14,670
the ecosystem of Basra Lisa's a quick

00:04:10,400 --> 00:04:16,979
sidenote I'm going to go through a lot

00:04:14,670 --> 00:04:18,690
of examples and some of them are no

00:04:16,979 --> 00:04:22,650
longer relevant on edge versions of

00:04:18,690 --> 00:04:24,419
Bosch Cloud Foundry and OpenStack but

00:04:22,650 --> 00:04:26,340
very rarely do we encounter an

00:04:24,419 --> 00:04:28,420
organization that is on the latest

00:04:26,340 --> 00:04:30,420
version of these systems

00:04:28,420 --> 00:04:35,890
you should note that I think Bosch is

00:04:30,420 --> 00:04:40,300
actively tested on lmn Liberty Mitaka

00:04:35,890 --> 00:04:42,280
and Newton right now but many of the

00:04:40,300 --> 00:04:45,870
stacks we work on are already older than

00:04:42,280 --> 00:04:49,480
that so talking about troubleshooting

00:04:45,870 --> 00:04:51,010
this platform on it really needs to be

00:04:49,480 --> 00:04:54,880
geared towards what's happening in the

00:04:51,010 --> 00:04:57,040
wild Cloud Foundry and OpenStack have

00:04:54,880 --> 00:05:00,280
very aggressive release schedules for

00:04:57,040 --> 00:05:01,990
projects of their size so I considered

00:05:00,280 --> 00:05:04,630
prune pruning this talk to only edge

00:05:01,990 --> 00:05:06,130
related issues but it turned out that I

00:05:04,630 --> 00:05:11,920
wouldn't be getting a good cross-section

00:05:06,130 --> 00:05:13,090
of what you might encounter next I'm

00:05:11,920 --> 00:05:15,840
going to go through a bunch of basic

00:05:13,090 --> 00:05:19,750
problem classes that you might

00:05:15,840 --> 00:05:21,760
experience and some errors a lot of

00:05:19,750 --> 00:05:23,620
times those errors are going to be not

00:05:21,760 --> 00:05:25,840
necessarily intuitive that's why I'm

00:05:23,620 --> 00:05:28,300
pointing them out and some of them may

00:05:25,840 --> 00:05:30,190
seem obvious but I've got these from my

00:05:28,300 --> 00:05:32,050
notes from the notes of colleagues and

00:05:30,190 --> 00:05:34,060
from the notes of some of the folks I've

00:05:32,050 --> 00:05:35,770
worked with in the community and every

00:05:34,060 --> 00:05:37,600
one of them has caused someone to go to

00:05:35,770 --> 00:05:41,680
others for help or to lose a day or two

00:05:37,600 --> 00:05:44,110
of progress true to the talk title we'll

00:05:41,680 --> 00:05:47,530
start out with networking this

00:05:44,110 --> 00:05:49,090
represents the basic collection of

00:05:47,530 --> 00:05:51,100
networks and subnets that you would need

00:05:49,090 --> 00:05:53,650
for just to get bought just to get Bosch

00:05:51,100 --> 00:05:54,970
off the ground in general though in

00:05:53,650 --> 00:05:57,000
production obviously you're probably

00:05:54,970 --> 00:06:01,180
going to have a much more complicated

00:05:57,000 --> 00:06:05,380
scenario but the bottom line here is to

00:06:01,180 --> 00:06:09,910
always make sure that the networks

00:06:05,380 --> 00:06:12,310
available in your OpenStack map onto

00:06:09,910 --> 00:06:14,620
your the topology that's shown in your

00:06:12,310 --> 00:06:17,919
manifest this is just kind of we're just

00:06:14,620 --> 00:06:21,550
getting started but this is a typical

00:06:17,919 --> 00:06:23,230
area you might get and you should get

00:06:21,550 --> 00:06:24,940
used to it you should make friends with

00:06:23,230 --> 00:06:26,650
it you're going to spend a lot of time

00:06:24,940 --> 00:06:29,110
together you're trying to date Cloud

00:06:26,650 --> 00:06:34,120
Foundry but this is the annoying friend

00:06:29,110 --> 00:06:36,520
that keeps tagging along but I say that

00:06:34,120 --> 00:06:39,340
this is related to networking but you

00:06:36,520 --> 00:06:41,260
also might run into this error if

00:06:39,340 --> 00:06:44,950
there's issues bringing up of

00:06:41,260 --> 00:06:46,900
em and in that case that's not

00:06:44,950 --> 00:06:48,250
necessarily related to networking and

00:06:46,900 --> 00:06:49,420
that's where it gets messy because you

00:06:48,250 --> 00:06:51,340
look at this and you think oh that must

00:06:49,420 --> 00:06:53,440
be network related so now we got to talk

00:06:51,340 --> 00:06:56,290
about how do you figure out where the

00:06:53,440 --> 00:07:00,250
problem is and that's where we learn to

00:06:56,290 --> 00:07:03,220
love our logs and Bosch has its own logs

00:07:00,250 --> 00:07:05,770
and sometimes you'll get distracted by

00:07:03,220 --> 00:07:09,280
them because Bosch only knows about

00:07:05,770 --> 00:07:11,950
Bosch the CPI is aware of the underlying

00:07:09,280 --> 00:07:15,340
infrastructure in this case the

00:07:11,950 --> 00:07:17,800
OpenStack CPI but as errors flow up from

00:07:15,340 --> 00:07:20,950
OpenStack the Aya's layer through the

00:07:17,800 --> 00:07:24,670
CPI into Bosch very rarely does it end

00:07:20,950 --> 00:07:26,920
up giving you the smoking gun right it's

00:07:24,670 --> 00:07:28,360
not always going to make sense it's not

00:07:26,920 --> 00:07:29,860
always going to be obvious so log

00:07:28,360 --> 00:07:34,810
tracing is going to be a skill on its

00:07:29,860 --> 00:07:38,620
own so you need to be aware of the

00:07:34,810 --> 00:07:42,280
primary ways to get at the logs I find

00:07:38,620 --> 00:07:45,580
that I spend a lot of time in the

00:07:42,280 --> 00:07:53,260
OpenStack logs you know generally very

00:07:45,580 --> 00:07:55,030
log OpenStack component but over time

00:07:53,260 --> 00:07:56,590
I've spent less and less time there I

00:07:55,030 --> 00:07:58,770
think the community has really come

00:07:56,590 --> 00:08:01,210
together and made the CPI a lot better

00:07:58,770 --> 00:08:05,050
some like I said some of these examples

00:08:01,210 --> 00:08:08,680
are going to be a little bit dated for

00:08:05,050 --> 00:08:11,380
edge versions of some software the most

00:08:08,680 --> 00:08:14,130
important thing to consider is that you

00:08:11,380 --> 00:08:18,940
need to have a good understanding of

00:08:14,130 --> 00:08:21,670
OpenStack and Bosch networking if you

00:08:18,940 --> 00:08:24,310
have three hours before you have to go

00:08:21,670 --> 00:08:27,160
stand up Cloud Foundry and the only

00:08:24,310 --> 00:08:29,530
thing you have time to do is read

00:08:27,160 --> 00:08:32,440
through some of the docs on OpenStack

00:08:29,530 --> 00:08:35,410
networking you can't go wrong it'll save

00:08:32,440 --> 00:08:37,960
you a great amount of headache later and

00:08:35,410 --> 00:08:38,890
I have a link up here for one of the

00:08:37,960 --> 00:08:47,590
troubleshooting guides that are

00:08:38,890 --> 00:08:48,970
available bosch debugging this obviously

00:08:47,590 --> 00:08:51,820
is another skill you need to spend some

00:08:48,970 --> 00:08:54,300
time on what I'm really excited about is

00:08:51,820 --> 00:08:57,330
this last example the

00:08:54,300 --> 00:08:59,459
to CLI allows you to follow the logs for

00:08:57,330 --> 00:09:06,140
a particular job which can be pretty

00:08:59,459 --> 00:09:08,700
useful but again this really isn't about

00:09:06,140 --> 00:09:10,769
the details of Bosch it's just that

00:09:08,700 --> 00:09:12,630
before you go into a Cloud Foundry

00:09:10,769 --> 00:09:14,760
deployment make sure you understand the

00:09:12,630 --> 00:09:16,769
Bosch CLI make sure you have at least a

00:09:14,760 --> 00:09:21,410
cursory knowledge of OpenStack

00:09:16,769 --> 00:09:24,450
networking and make sure you understand

00:09:21,410 --> 00:09:29,850
what the manifests role is in your Bosch

00:09:24,450 --> 00:09:32,180
deployment sometimes you'll use bespoke

00:09:29,850 --> 00:09:34,200
systems that are you're editing your

00:09:32,180 --> 00:09:36,779
manifest piecemeal and you won't

00:09:34,200 --> 00:09:38,700
necessarily understand that the manifest

00:09:36,779 --> 00:09:40,860
is everything that makes your deployment

00:09:38,700 --> 00:09:43,320
your deployment if there is something

00:09:40,860 --> 00:09:46,740
wrong in your deployment and it's not

00:09:43,320 --> 00:09:48,390
OpenStack it's probably something in

00:09:46,740 --> 00:09:49,890
your manifest and if you go to the

00:09:48,390 --> 00:09:50,910
community I mentioned before for help

00:09:49,890 --> 00:09:52,320
the first thing they're going to do is

00:09:50,910 --> 00:09:54,000
ask you can you show me what your

00:09:52,320 --> 00:09:57,690
manifest looks like you'll see some

00:09:54,000 --> 00:10:02,810
examples later where this comes into

00:09:57,690 --> 00:10:05,579
play I threw this in here because it's a

00:10:02,810 --> 00:10:08,820
diagram we like to use when people come

00:10:05,579 --> 00:10:13,529
to ask for help try to classify which

00:10:08,820 --> 00:10:14,760
vert vert is vertex the problem lies in

00:10:13,529 --> 00:10:16,709
on this triangle because you've got

00:10:14,760 --> 00:10:19,290
OpenStack that has to speak to your

00:10:16,709 --> 00:10:20,459
virtual machines we've got Bosch the

00:10:19,290 --> 00:10:22,290
director that has to speak to your

00:10:20,459 --> 00:10:24,779
virtual machines and you've got Bosch

00:10:22,290 --> 00:10:26,670
that needs to speak to OpenStack and the

00:10:24,779 --> 00:10:30,450
problem can lie on any one of these

00:10:26,670 --> 00:10:31,950
vertex and what's interesting is Bosch

00:10:30,450 --> 00:10:33,959
has its own view of the world

00:10:31,950 --> 00:10:35,760
OpenStack has its own view of the world

00:10:33,959 --> 00:10:37,649
and it's really helpful to understand

00:10:35,760 --> 00:10:40,170
that because sometimes some of the

00:10:37,649 --> 00:10:41,910
errors we're going to go through it's

00:10:40,170 --> 00:10:43,740
just a matter of Bosh's view of the

00:10:41,910 --> 00:10:45,060
world not syncing with openstax view of

00:10:43,740 --> 00:10:46,860
the world so you go to look at your

00:10:45,060 --> 00:10:48,240
manifest and your manifest says oh this

00:10:46,860 --> 00:10:51,870
is right then you go to look at

00:10:48,240 --> 00:10:53,550
OpenStack and OpenStack seems to imply

00:10:51,870 --> 00:10:55,769
something's right but it turns out that

00:10:53,550 --> 00:10:57,839
there's an error somewhere else where it

00:10:55,769 --> 00:11:00,000
thinks the VM was down and it can't

00:10:57,839 --> 00:11:01,860
release a port and it gets pretty

00:11:00,000 --> 00:11:02,970
interesting so if you're coming to the

00:11:01,860 --> 00:11:05,100
community for help

00:11:02,970 --> 00:11:06,720
spend some time trying to figure out if

00:11:05,100 --> 00:11:08,190
the problem is between OpenStack and the

00:11:06,720 --> 00:11:10,560
VMS bosh and the VM

00:11:08,190 --> 00:11:11,910
openstack and the bosch director and

00:11:10,560 --> 00:11:15,930
hopefully some of these examples will

00:11:11,910 --> 00:11:18,090
help now let's get to what are probably

00:11:15,930 --> 00:11:20,220
way too many examples in too little time

00:11:18,090 --> 00:11:21,690
try to get them through them quickly I

00:11:20,220 --> 00:11:25,110
know we probably want to go to lunch

00:11:21,690 --> 00:11:28,250
right so you will probably face some of

00:11:25,110 --> 00:11:31,530
these issues start out with key pairs

00:11:28,250 --> 00:11:32,610
Bosh must be provided with the key pair

00:11:31,530 --> 00:11:35,220
that you can use to communicate with

00:11:32,610 --> 00:11:37,380
instances without a valid key your

00:11:35,220 --> 00:11:39,870
deployments will fail this is a pretty

00:11:37,380 --> 00:11:41,790
nice class of error because it usually

00:11:39,870 --> 00:11:45,060
is spelled right out for you it'll say

00:11:41,790 --> 00:11:49,140
missing private key but sometimes it's

00:11:45,060 --> 00:11:51,930
not in this case if you're using

00:11:49,140 --> 00:11:54,390
OpenStack OpenStack liberty or Mitaka

00:11:51,930 --> 00:11:56,340
you can't use their SSH key generator

00:11:54,390 --> 00:12:00,780
you have to generate one manually so

00:11:56,340 --> 00:12:02,760
even if you tell the the API to generate

00:12:00,780 --> 00:12:06,510
that for you it doesn't matter it will

00:12:02,760 --> 00:12:07,380
not can actually can you use the API to

00:12:06,510 --> 00:12:09,140
generate a key

00:12:07,380 --> 00:12:11,700
I haven't yes you can of course you can

00:12:09,140 --> 00:12:13,860
it will break it will not work but

00:12:11,700 --> 00:12:16,500
you'll look in OpenStack and OpenStack

00:12:13,860 --> 00:12:18,600
will say hey yes this this is here it

00:12:16,500 --> 00:12:21,750
worked and then you'll go to try to run

00:12:18,600 --> 00:12:26,640
Bosh deploy and it'll fail this is a

00:12:21,750 --> 00:12:29,070
case of a bug that's actually in Liberty

00:12:26,640 --> 00:12:32,670
and Mitaka so it doesn't fall into the

00:12:29,070 --> 00:12:35,930
base class of error and a lot of

00:12:32,670 --> 00:12:38,670
validation might not even catch this

00:12:35,930 --> 00:12:42,210
another thing to keep in mind is VM

00:12:38,670 --> 00:12:43,590
Communication Bosh requires that the

00:12:42,210 --> 00:12:48,210
virtual machines have to be able to

00:12:43,590 --> 00:12:49,920
communicate with one another I think

00:12:48,210 --> 00:12:51,240
we've seen this error before this one's

00:12:49,920 --> 00:12:53,100
going to come out a lot I told you it's

00:12:51,240 --> 00:12:55,500
that annoying friend that wants to tag

00:12:53,100 --> 00:12:59,160
along on your dates it's not going to go

00:12:55,500 --> 00:13:02,250
away this one here is a typical error

00:12:59,160 --> 00:13:04,470
you might get if you have blocked

00:13:02,250 --> 00:13:08,250
network connectivity between the agent

00:13:04,470 --> 00:13:10,110
and the Bosh director but then again

00:13:08,250 --> 00:13:12,750
it's also typical for a whole nother

00:13:10,110 --> 00:13:15,000
class of problems and we're going to see

00:13:12,750 --> 00:13:19,560
a pattern here and that pattern is that

00:13:15,000 --> 00:13:22,019
the Bosh with the error that Bosh spits

00:13:19,560 --> 00:13:24,029
out is going to point to an

00:13:22,019 --> 00:13:25,889
higher class of problems and sometimes

00:13:24,029 --> 00:13:27,480
that might mean you have to go look in

00:13:25,889 --> 00:13:28,920
the Nova logs and sometimes it might

00:13:27,480 --> 00:13:31,860
mean you have to go look in the neutron

00:13:28,920 --> 00:13:35,429
logs we'll talk a little bit about how

00:13:31,860 --> 00:13:37,920
to mitigate that later security group

00:13:35,429 --> 00:13:41,959
rules the boss security group is the

00:13:37,920 --> 00:13:46,290
security group that Bosh's that Bosch

00:13:41,959 --> 00:13:48,389
VMs will be deployed within and this

00:13:46,290 --> 00:13:51,360
right here is the reference list of

00:13:48,389 --> 00:13:55,529
security group rules it's the minimum

00:13:51,360 --> 00:13:56,480
set that you need to make Bosch do its

00:13:55,529 --> 00:13:59,459
thing

00:13:56,480 --> 00:14:02,160
it's not necessarily production you

00:13:59,459 --> 00:14:04,589
wouldn't use this in production and it's

00:14:02,160 --> 00:14:07,079
definitely not the most secure but what

00:14:04,589 --> 00:14:08,610
I've seen happen far too many times you

00:14:07,079 --> 00:14:12,540
have problems with security groups and

00:14:08,610 --> 00:14:13,949
then you do this I've seen this happen a

00:14:12,540 --> 00:14:16,170
lot especially when you're fighting with

00:14:13,949 --> 00:14:17,819
third-party SDNS you know many a young

00:14:16,170 --> 00:14:21,179
adventurer has lost a battle with

00:14:17,819 --> 00:14:25,739
Neutron I've done this myself this is

00:14:21,179 --> 00:14:29,309
actually from a open stack that's

00:14:25,739 --> 00:14:30,689
running on my home lab it's a short fix

00:14:29,309 --> 00:14:35,549
but you'll feel dirty about it in the

00:14:30,689 --> 00:14:36,079
morning don't do it seriously oh no not

00:14:35,549 --> 00:14:40,249
again

00:14:36,079 --> 00:14:40,249
this error is going to pop up again

00:14:40,970 --> 00:14:49,199
security group rules default flavors so

00:14:44,999 --> 00:14:50,819
this one's interesting again some type

00:14:49,199 --> 00:14:51,990
of validation will probably check to

00:14:50,819 --> 00:14:53,970
make sure you have all your default

00:14:51,990 --> 00:14:56,160
flavors but a lot of people don't put a

00:14:53,970 --> 00:15:00,740
lot of thought into it because when you

00:14:56,160 --> 00:15:03,089
go to gesundheit sir when you go to the

00:15:00,740 --> 00:15:06,509
documentation pivotal or from us and

00:15:03,089 --> 00:15:08,160
Stark and Wayne it'll give you this list

00:15:06,509 --> 00:15:11,220
and it'll say put these in make sure

00:15:08,160 --> 00:15:12,809
open SEC has these available but you

00:15:11,220 --> 00:15:15,899
really need to make some consideration

00:15:12,809 --> 00:15:17,879
about what your use case is for Cloud

00:15:15,899 --> 00:15:20,869
Foundry often these flavors will not be

00:15:17,879 --> 00:15:24,540
sufficient for what you're trying to do

00:15:20,869 --> 00:15:27,360
when I mentioned this to my colleagues

00:15:24,540 --> 00:15:30,119
the responses ranged from really you

00:15:27,360 --> 00:15:32,459
have problems with flavors to yeah yeah

00:15:30,119 --> 00:15:34,740
that bit me so you know when it's a

00:15:32,459 --> 00:15:35,939
problem it's really a problem it really

00:15:34,740 --> 00:15:39,239
depends what you're going to do

00:15:35,939 --> 00:15:44,999
with it and I this this is a fun example

00:15:39,239 --> 00:15:47,099
for me because I was looking for an

00:15:44,999 --> 00:15:49,499
example from the past I remembered

00:15:47,099 --> 00:15:51,749
having issues with flavours so it made

00:15:49,499 --> 00:15:53,609
it into the talk and I'm trying to find

00:15:51,749 --> 00:15:55,349
an error for the slide and I couldn't

00:15:53,609 --> 00:15:56,879
make it I couldn't get the failure that

00:15:55,349 --> 00:15:58,559
I had remembered so I went looking and I

00:15:56,879 --> 00:16:00,569
found this and I thought this is great

00:15:58,559 --> 00:16:02,939
somebody else had the same problem I did

00:16:00,569 --> 00:16:05,279
and five minutes into reading through

00:16:02,939 --> 00:16:09,509
the slide I said no I had that problem

00:16:05,279 --> 00:16:12,509
this is me it happens way too often this

00:16:09,509 --> 00:16:15,299
error happened because the manifest had

00:16:12,509 --> 00:16:16,529
a vSphere specific directive in it and

00:16:15,299 --> 00:16:19,339
it was just skipping all of the

00:16:16,529 --> 00:16:19,339
OpenStack stuff

00:16:21,439 --> 00:16:25,979
quota issues are also common especially

00:16:23,970 --> 00:16:27,119
the first time you deploy things and

00:16:25,979 --> 00:16:29,099
especially if you have a large

00:16:27,119 --> 00:16:32,249
production deployment in your

00:16:29,099 --> 00:16:37,859
organization or your your tenant doesn't

00:16:32,249 --> 00:16:40,409
have the resources it needs big thing

00:16:37,859 --> 00:16:43,529
here is to consider Diego which is

00:16:40,409 --> 00:16:45,059
probably by far going to be your largest

00:16:43,529 --> 00:16:49,409
consumer of resources because that's

00:16:45,059 --> 00:16:50,849
where your applications run and when you

00:16:49,409 --> 00:16:54,029
think about your quotas you're going to

00:16:50,849 --> 00:16:56,999
come back to your a minimum deployment

00:16:54,029 --> 00:16:59,519
and I use PCF because this is what

00:16:56,999 --> 00:17:03,839
pivotal documents as the minimum amount

00:16:59,519 --> 00:17:06,329
of resources that you need to run a PCF

00:17:03,839 --> 00:17:07,949
deployment so it should become pretty

00:17:06,329 --> 00:17:12,629
clear that quotas are a big deal

00:17:07,949 --> 00:17:15,089
and then you end up doing this which

00:17:12,629 --> 00:17:16,470
which is probably also a bad idea but if

00:17:15,089 --> 00:17:19,379
you happen to have admin rights to your

00:17:16,470 --> 00:17:24,389
tenant you might be tempted

00:17:19,379 --> 00:17:29,190
you probably shouldn't another error

00:17:24,389 --> 00:17:31,980
that falls into the quota class in this

00:17:29,190 --> 00:17:35,070
case Bosh was trying to provision a new

00:17:31,980 --> 00:17:37,409
VM and they didn't have the quota for it

00:17:35,070 --> 00:17:40,080
you get VM creation failed this is the

00:17:37,409 --> 00:17:41,370
second class of error the timeout

00:17:40,080 --> 00:17:41,820
pinging one we've seen three times

00:17:41,370 --> 00:17:44,190
already

00:17:41,820 --> 00:17:46,049
VM creation fail you are also going to

00:17:44,190 --> 00:17:49,080
see all the time and again the pattern

00:17:46,049 --> 00:17:51,000
here should be that you shouldn't get

00:17:49,080 --> 00:17:52,890
too caught up in the air

00:17:51,000 --> 00:17:54,440
you need to dig deeper because the

00:17:52,890 --> 00:17:57,620
errors aren't necessarily going to

00:17:54,440 --> 00:18:00,950
explain the problem to you

00:17:57,620 --> 00:18:07,020
OpenStack ap is this one is another one

00:18:00,950 --> 00:18:10,950
to to think about in this case you need

00:18:07,020 --> 00:18:12,840
to know that Bosch needs to be able to

00:18:10,950 --> 00:18:14,669
talk to compute he needs to be able to

00:18:12,840 --> 00:18:16,620
talk to identity it needs to be talked

00:18:14,669 --> 00:18:17,789
to be able to talk to image storage and

00:18:16,620 --> 00:18:23,220
optionally needs to be talked to

00:18:17,789 --> 00:18:24,960
networking here's an issue you get if

00:18:23,220 --> 00:18:26,610
your API is unavailable what's

00:18:24,960 --> 00:18:28,890
interesting about this is this error

00:18:26,610 --> 00:18:31,580
happened because there was an upgrade to

00:18:28,890 --> 00:18:35,220
a newer version of the OpenStack CPI

00:18:31,580 --> 00:18:36,600
everything worked fine on version 27 a

00:18:35,220 --> 00:18:39,030
ton version 28 OpenStack networking

00:18:36,600 --> 00:18:43,830
became the default and all of a sudden

00:18:39,030 --> 00:18:47,450
we're in a situation where this client

00:18:43,830 --> 00:18:51,360
wasn't using OpenStack networking so

00:18:47,450 --> 00:18:52,860
this problem arose and it was it worked

00:18:51,360 --> 00:18:59,580
fine yesterday which ends up being

00:18:52,860 --> 00:19:01,860
difficult stem cell issues sometimes you

00:18:59,580 --> 00:19:03,960
have problem with stem cells and usually

00:19:01,860 --> 00:19:06,480
it's pretty straightforward because

00:19:03,960 --> 00:19:07,980
it'll bosch will just yell at you you

00:19:06,480 --> 00:19:11,520
didn't uh you know smishing stem cell

00:19:07,980 --> 00:19:15,210
but sometimes you get a problem that the

00:19:11,520 --> 00:19:17,190
stem cells missing but bosch will think

00:19:15,210 --> 00:19:19,020
that the stem cells there so you try to

00:19:17,190 --> 00:19:21,600
upload the image and you can't this

00:19:19,020 --> 00:19:26,400
usually means that somebody deleted the

00:19:21,600 --> 00:19:28,409
stem cell on you in your OpenStack again

00:19:26,400 --> 00:19:30,210
all of these examples are examples in

00:19:28,409 --> 00:19:32,700
the real world from notes that's it's

00:19:30,210 --> 00:19:38,309
just a cross section that I believe most

00:19:32,700 --> 00:19:42,679
folks will encounter image provisioning

00:19:38,309 --> 00:19:45,720
you need to be aware how OpenStack

00:19:42,679 --> 00:19:48,059
applies things like your SSH keys to

00:19:45,720 --> 00:19:51,240
your stem cells when they come up right

00:19:48,059 --> 00:19:54,000
well the stem cell uses the metadata

00:19:51,240 --> 00:19:56,309
service so you can check to make sure

00:19:54,000 --> 00:19:58,200
that an image can hit the metadata

00:19:56,309 --> 00:19:59,909
service by doing something like this and

00:19:58,200 --> 00:20:02,399
in this case that's the output you

00:19:59,909 --> 00:20:03,550
should receive if you don't then there's

00:20:02,399 --> 00:20:06,640
a problem

00:20:03,550 --> 00:20:08,950
and then we get this error again four

00:20:06,640 --> 00:20:13,390
times four dates four best friends

00:20:08,950 --> 00:20:14,440
tagging alone in this case if you're

00:20:13,390 --> 00:20:15,640
having problems with the metadata

00:20:14,440 --> 00:20:18,790
service you're not going to be able to

00:20:15,640 --> 00:20:21,460
ssh into any of your VMs you're also

00:20:18,790 --> 00:20:23,170
going to have issues bosch is going to

00:20:21,460 --> 00:20:24,310
bring the vm up just fine but then it's

00:20:23,170 --> 00:20:29,110
not gonna be able to communicate with it

00:20:24,310 --> 00:20:32,140
necessarily so also remember that bosch

00:20:29,110 --> 00:20:34,090
stores stem cells in glance or an image

00:20:32,140 --> 00:20:35,260
service in general so you're going to

00:20:34,090 --> 00:20:40,210
want to check the amount of disk space

00:20:35,260 --> 00:20:44,610
you have available things like that rate

00:20:40,210 --> 00:20:47,890
limiting this one's also fun because

00:20:44,610 --> 00:20:50,440
bosch throws hundreds of calls against

00:20:47,890 --> 00:20:53,860
your OpenStack API and if Nova has

00:20:50,440 --> 00:20:57,690
rate-limiting set to low you're going to

00:20:53,860 --> 00:21:02,680
get an error like this which is actually

00:20:57,690 --> 00:21:05,260
not very intuitive because that doesn't

00:21:02,680 --> 00:21:07,930
say anything about I'm making too many

00:21:05,260 --> 00:21:11,170
requests I think in newer versions of

00:21:07,930 --> 00:21:12,460
the CPI this may be cleaned up but this

00:21:11,170 --> 00:21:14,640
was the error we were getting at the

00:21:12,460 --> 00:21:14,640
time

00:21:19,280 --> 00:21:26,300
so if stem cells are actually just

00:21:22,820 --> 00:21:28,190
machine images we need to check the

00:21:26,300 --> 00:21:29,750
amount of disk space that's being used

00:21:28,190 --> 00:21:31,580
for glance if you're having trouble

00:21:29,750 --> 00:21:33,980
uploading stem cells make sure you

00:21:31,580 --> 00:21:37,130
haven't run out of space I've moved on

00:21:33,980 --> 00:21:40,660
now I've got a bunch of just some

00:21:37,130 --> 00:21:44,780
housekeeping things that will go through

00:21:40,660 --> 00:21:47,030
VM performance I've found that actually

00:21:44,780 --> 00:21:49,430
we've found that sometimes you'll have

00:21:47,030 --> 00:21:51,560
problems with the performance of large

00:21:49,430 --> 00:21:53,330
distributed systems on top of OpenStack

00:21:51,560 --> 00:21:55,630
and you have to take care to figure out

00:21:53,330 --> 00:21:59,120
what type of emulation mode you're using

00:21:55,630 --> 00:22:01,730
in this case usually send it setting

00:21:59,120 --> 00:22:03,650
your CPU CPU mode to host pass-through

00:22:01,730 --> 00:22:06,380
will actually alleviate the problem but

00:22:03,650 --> 00:22:07,790
it's really not something you should do

00:22:06,380 --> 00:22:11,150
without understanding what's going on

00:22:07,790 --> 00:22:14,120
under the hood it's probably a decision

00:22:11,150 --> 00:22:15,440
for your admin team to make but this is

00:22:14,120 --> 00:22:18,320
something you can point them at if

00:22:15,440 --> 00:22:21,680
you're having issues also I like to be

00:22:18,320 --> 00:22:23,480
aware of the default CPU allocation

00:22:21,680 --> 00:22:27,200
ratio and the overcommit ratio for

00:22:23,480 --> 00:22:28,370
memory because you sometimes you want to

00:22:27,200 --> 00:22:30,440
double check those things if you're

00:22:28,370 --> 00:22:31,760
having performance issues because if you

00:22:30,440 --> 00:22:33,230
didn't stand up the stack you don't

00:22:31,760 --> 00:22:35,360
necessarily know what's going on under

00:22:33,230 --> 00:22:37,000
the hood chances are you're not going to

00:22:35,360 --> 00:22:39,350
have that access but you could at least

00:22:37,000 --> 00:22:42,340
say hey I'd like you to check this for

00:22:39,350 --> 00:22:42,340
me and let me know what's going on

00:22:44,110 --> 00:22:51,800
network performance is another

00:22:46,130 --> 00:22:54,470
interesting class of problem Jan

00:22:51,800 --> 00:22:57,200
mentioned MTU issues earlier there's a

00:22:54,470 --> 00:23:00,340
you can you can make changes to your

00:22:57,200 --> 00:23:03,830
manifest you can update MTU settings in

00:23:00,340 --> 00:23:06,110
in Nova is a bit of a dark art to that

00:23:03,830 --> 00:23:09,800
but another networking performance issue

00:23:06,110 --> 00:23:13,330
that isn't always apparent is that

00:23:09,800 --> 00:23:15,970
Neutron itself can be a bottleneck

00:23:13,330 --> 00:23:18,470
there's ways to get around this

00:23:15,970 --> 00:23:22,610
distributed virtual routing for example

00:23:18,470 --> 00:23:26,800
where the let the level 3 agent is

00:23:22,610 --> 00:23:26,800
distributed across to the compute nodes

00:23:26,890 --> 00:23:33,230
but the first time this had come up I

00:23:31,090 --> 00:23:36,450
actually hadn't expected

00:23:33,230 --> 00:23:38,160
you can you can distribute your you can

00:23:36,450 --> 00:23:40,170
add more neutron nodes or you can use a

00:23:38,160 --> 00:23:42,360
third-party Sdn provider as well to try

00:23:40,170 --> 00:23:46,380
to get around this but when you consider

00:23:42,360 --> 00:23:48,180
that a typical large enterprise

00:23:46,380 --> 00:23:53,400
production Cloud Foundry might have

00:23:48,180 --> 00:23:56,190
hundreds of well say 110 Diego cells you

00:23:53,400 --> 00:24:02,900
know you want to make sure that you're

00:23:56,190 --> 00:24:02,900
scaling that traffic proxy issues also

00:24:02,930 --> 00:24:09,570
they're not necessarily OpenStack

00:24:07,020 --> 00:24:16,620
specific but the reason they're here is

00:24:09,570 --> 00:24:18,180
because I find that a lot of the clients

00:24:16,620 --> 00:24:21,240
we've dealt with that are using

00:24:18,180 --> 00:24:24,030
OpenStack are also using some type of

00:24:21,240 --> 00:24:25,710
internal OpenStack right there's it's

00:24:24,030 --> 00:24:29,130
more likely that an OpenStack is to be

00:24:25,710 --> 00:24:30,870
going to behind a corporate firewall and

00:24:29,130 --> 00:24:33,140
you're going to come run into some

00:24:30,870 --> 00:24:35,700
pretty interesting issues with this

00:24:33,140 --> 00:24:38,000
because some of the build packs

00:24:35,700 --> 00:24:40,200
interestingly this is the first issue

00:24:38,000 --> 00:24:43,320
that is Cloud Foundry specific

00:24:40,200 --> 00:24:45,300
everything else has been about Bosh but

00:24:43,320 --> 00:24:49,050
some of the build packs actually need to

00:24:45,300 --> 00:24:51,420
go grab stuff from github so sometimes

00:24:49,050 --> 00:24:52,770
you have to actually specify the proxy

00:24:51,420 --> 00:24:55,110
in your app excuse me in your

00:24:52,770 --> 00:24:58,770
application manifest there's also some

00:24:55,110 --> 00:25:03,240
problems with the UA a where the UA a

00:24:58,770 --> 00:25:05,910
controller will not recognize the proxy

00:25:03,240 --> 00:25:08,310
flag and if you have another flag so

00:25:05,910 --> 00:25:11,010
there's a HTTP proxy flag and then proxy

00:25:08,310 --> 00:25:13,590
and the no proxy flag I think well

00:25:11,010 --> 00:25:15,420
there's two flags and they don't the

00:25:13,590 --> 00:25:16,770
hierarchy of them isn't set right so you

00:25:15,420 --> 00:25:18,930
might have one flag set and think

00:25:16,770 --> 00:25:20,070
everything should work and then you

00:25:18,930 --> 00:25:20,580
can't get any access to the outside

00:25:20,070 --> 00:25:24,260
world

00:25:20,580 --> 00:25:27,300
so you need to be aware of proxy issues

00:25:24,260 --> 00:25:29,220
cinder I don't actually have anything

00:25:27,300 --> 00:25:30,600
about cinder right now but cinder if

00:25:29,220 --> 00:25:33,180
you're not aware of it is the OpenStack

00:25:30,600 --> 00:25:36,720
dating app it allows you to swipe left

00:25:33,180 --> 00:25:44,010
for reliable block storage come on

00:25:36,720 --> 00:25:46,290
really actually no I do have an example

00:25:44,010 --> 00:25:49,190
for cinder

00:25:46,290 --> 00:25:51,800
sometimes a Bosch deployment will break

00:25:49,190 --> 00:25:54,630
because a host computer host goes down

00:25:51,800 --> 00:25:59,340
Bosch will try to resurrect that VM the

00:25:54,630 --> 00:26:01,530
VMS will become unresponsive and but

00:25:59,340 --> 00:26:03,930
because the the VM relied on a host

00:26:01,530 --> 00:26:06,000
that's no longer available q node went

00:26:03,930 --> 00:26:09,180
down so this means that the VM is

00:26:06,000 --> 00:26:11,340
attached this could mean that the VMS

00:26:09,180 --> 00:26:13,680
were attached to cinder volley the the

00:26:11,340 --> 00:26:18,270
cinder volumes aren't resurrecting

00:26:13,680 --> 00:26:20,580
properly because it is stuck in the

00:26:18,270 --> 00:26:29,850
attached state to a VM that no longer

00:26:20,580 --> 00:26:31,410
exists so this is a we've come full

00:26:29,850 --> 00:26:33,240
circle we're back to my first cloud

00:26:31,410 --> 00:26:37,290
foundry so we went backwards in time

00:26:33,240 --> 00:26:39,480
just now newer errors two errors in the

00:26:37,290 --> 00:26:44,060
beginning and this one is relevant

00:26:39,480 --> 00:26:48,750
because it was one of my first battles

00:26:44,060 --> 00:26:51,290
with bosch on OpenStack and as you'll

00:26:48,750 --> 00:26:58,290
see we've seen this error twice already

00:26:51,290 --> 00:27:00,630
and this error in this case I had

00:26:58,290 --> 00:27:02,580
assumed that OpenStack must be working

00:27:00,630 --> 00:27:04,230
correctly because this is one of my

00:27:02,580 --> 00:27:05,670
first experience with Zoet with

00:27:04,230 --> 00:27:07,170
OpenStack and it's this huge project

00:27:05,670 --> 00:27:09,090
it's got all the support I met all these

00:27:07,170 --> 00:27:10,800
great people thinking okay so openstax

00:27:09,090 --> 00:27:14,300
working is this must be a problem with

00:27:10,800 --> 00:27:16,410
Bosch so after a day or so of

00:27:14,300 --> 00:27:20,160
troubleshooting I finally found my way

00:27:16,410 --> 00:27:24,030
to the Nova logs and it turned out that

00:27:20,160 --> 00:27:27,540
there was a bug in Nova that was not

00:27:24,030 --> 00:27:30,330
allowing IP addresses to be manually

00:27:27,540 --> 00:27:33,870
assigned to new instances as they were

00:27:30,330 --> 00:27:36,000
brought up so I figured this out I

00:27:33,870 --> 00:27:37,470
patched it then I did some googling and

00:27:36,000 --> 00:27:41,460
I found that there was actually actually

00:27:37,470 --> 00:27:44,250
an open issue for it and it's

00:27:41,460 --> 00:27:45,750
interesting because we've now seen three

00:27:44,250 --> 00:27:47,580
or four errors that all have the same

00:27:45,750 --> 00:27:50,250
error in bosch three or four situations

00:27:47,580 --> 00:27:53,730
that have all have the same VM create

00:27:50,250 --> 00:28:00,120
failed a bunch to have the same unable

00:27:53,730 --> 00:28:02,610
to ping and the point of all of that

00:28:00,120 --> 00:28:04,440
was it was when I was looking through my

00:28:02,610 --> 00:28:06,390
notes it was pretty fascinating that I

00:28:04,440 --> 00:28:07,799
didn't expect to keep seeing the same

00:28:06,390 --> 00:28:11,429
errors over and over again

00:28:07,799 --> 00:28:20,400
and it really is all about needing to go

00:28:11,429 --> 00:28:22,860
dig deeper this is my last example and I

00:28:20,400 --> 00:28:27,029
can thank Sean Kerry at pivotal for this

00:28:22,860 --> 00:28:30,029
one so in this case the Bosch deploys

00:28:27,029 --> 00:28:31,559
were failing instances were getting

00:28:30,029 --> 00:28:36,120
created but the director couldn't talk

00:28:31,559 --> 00:28:40,679
to the agent and it turned out that

00:28:36,120 --> 00:28:43,679
there was Neutron was timing out trying

00:28:40,679 --> 00:28:47,370
to create trying to release the IP

00:28:43,679 --> 00:28:51,059
address from an orphaned instance and it

00:28:47,370 --> 00:28:54,059
was taking it was disallowing those

00:28:51,059 --> 00:28:57,570
agents from having an IP address

00:28:54,059 --> 00:29:05,210
assigned and what I like about this one

00:28:57,570 --> 00:29:08,279
is is it's it's really indicative of the

00:29:05,210 --> 00:29:10,890
general case of problems that we see in

00:29:08,279 --> 00:29:13,399
the wild so to speak and it's that

00:29:10,890 --> 00:29:16,679
there's no way to prep for this one

00:29:13,399 --> 00:29:18,240
except really understanding OpenStack

00:29:16,679 --> 00:29:20,490
networking which was my point from the

00:29:18,240 --> 00:29:23,190
beginning all of these examples that

00:29:20,490 --> 00:29:24,720
preceded it all seem to fall into nice

00:29:23,190 --> 00:29:26,279
neat classes but then I show you an

00:29:24,720 --> 00:29:28,230
error message that doesn't fall into the

00:29:26,279 --> 00:29:30,299
class that it might be and then this is

00:29:28,230 --> 00:29:33,720
another one that kind of hits that point

00:29:30,299 --> 00:29:34,620
forward and the reason I wanted to share

00:29:33,720 --> 00:29:37,789
this is because this was a really

00:29:34,620 --> 00:29:40,020
painful one for them they had a lot of

00:29:37,789 --> 00:29:41,309
people who know their way around working

00:29:40,020 --> 00:29:42,570
on and it took a couple days to figure

00:29:41,309 --> 00:29:49,169
out and it turned out to be something

00:29:42,570 --> 00:29:52,730
fairly silly so tools for the discerning

00:29:49,169 --> 00:29:52,730
operator there's there's a lot of

00:29:54,559 --> 00:30:02,130
available packages out there that can

00:29:57,270 --> 00:30:03,419
help here and I find that any list of

00:30:02,130 --> 00:30:05,460
them would probably take a whole nother

00:30:03,419 --> 00:30:08,220
talk to say but these are ones that we

00:30:05,460 --> 00:30:10,010
use a lot at Stark and Wayne or at least

00:30:08,220 --> 00:30:12,270
I use for some of the things I do

00:30:10,010 --> 00:30:14,210
libvirt you should get to know libvirt

00:30:12,270 --> 00:30:15,710
libvirt of course is

00:30:14,210 --> 00:30:18,020
takes a lot of the pain about out of

00:30:15,710 --> 00:30:20,540
troubleshooting virtual host based

00:30:18,020 --> 00:30:23,150
issues for example we've had instance

00:30:20,540 --> 00:30:25,340
migrations fail an open second or trying

00:30:23,150 --> 00:30:27,800
to move things around and you can use

00:30:25,340 --> 00:30:29,270
verse to get an idea of what the

00:30:27,800 --> 00:30:30,680
hypervisor thinks the world looks like

00:30:29,270 --> 00:30:36,350
and you can see what Bosch thinks the

00:30:30,680 --> 00:30:38,900
world looks like CF sizing tool this one

00:30:36,350 --> 00:30:41,900
is surprisingly useful you can pick your

00:30:38,900 --> 00:30:45,560
your I as you can say what size

00:30:41,900 --> 00:30:47,480
deployment you want you and it will spit

00:30:45,560 --> 00:30:52,370
out this is what you need these are the

00:30:47,480 --> 00:30:55,100
flavors you need this is the this is how

00:30:52,370 --> 00:30:56,570
your flavors should be sized if you even

00:30:55,100 --> 00:31:00,190
use the AWS one I tell you how much

00:30:56,570 --> 00:31:02,900
it'll cost and this is nice because if

00:31:00,190 --> 00:31:04,790
you do this before you go down the path

00:31:02,900 --> 00:31:07,370
of deploying Cloud Foundry you can at

00:31:04,790 --> 00:31:08,990
least get an idea of how you're going to

00:31:07,370 --> 00:31:11,450
size those quotas how you're going to

00:31:08,990 --> 00:31:13,340
size the flavors that you're going to

00:31:11,450 --> 00:31:16,790
use what kind of quotas you need to give

00:31:13,340 --> 00:31:17,030
- I just said quotas twice we'll skip

00:31:16,790 --> 00:31:20,980
that

00:31:17,030 --> 00:31:24,290
okay so codex this one's interesting and

00:31:20,980 --> 00:31:26,560
my colleague Xiu Zhao is actually going

00:31:24,290 --> 00:31:31,100
to speak a little bit about this later

00:31:26,560 --> 00:31:33,980
codex is a a workbook that Stark and

00:31:31,100 --> 00:31:36,620
Wayne has been putting together and it

00:31:33,980 --> 00:31:40,700
is all of our best practices for

00:31:36,620 --> 00:31:42,800
deploying on the is lay layers that we

00:31:40,700 --> 00:31:44,990
have worked with our clients and it's a

00:31:42,800 --> 00:31:48,290
living document so as we come up with

00:31:44,990 --> 00:31:50,390
new techniques for things we we added in

00:31:48,290 --> 00:31:52,550
here so that anybody that wants to see

00:31:50,390 --> 00:31:54,680
how we are doing things can come here

00:31:52,550 --> 00:31:58,640
often our clients were approached us and

00:31:54,680 --> 00:32:01,310
say we want you to do what codex says it

00:31:58,640 --> 00:32:03,710
is a little different than other

00:32:01,310 --> 00:32:05,840
companies I think because this is the

00:32:03,710 --> 00:32:10,310
way we do it but it has become our

00:32:05,840 --> 00:32:13,850
internal best practices and then Jen

00:32:10,310 --> 00:32:17,060
talked about this at length there's a CF

00:32:13,850 --> 00:32:20,150
validation tool that the community

00:32:17,060 --> 00:32:22,840
supports that actually will cover a

00:32:20,150 --> 00:32:25,550
whole lot of the errors we've seen today

00:32:22,840 --> 00:32:28,010
at least they'll cover the error classes

00:32:25,550 --> 00:32:29,240
I tried to throw in errors that might

00:32:28,010 --> 00:32:31,370
not necessarily get caught by the

00:32:29,240 --> 00:32:33,020
validation tool at the very least it

00:32:31,370 --> 00:32:34,550
won't catch them all if you're not

00:32:33,020 --> 00:32:39,310
running the validation and pipeline

00:32:34,550 --> 00:32:42,290
regularly for example it can tell you if

00:32:39,310 --> 00:32:44,450
the security groups can be created it

00:32:42,290 --> 00:32:46,240
can tell you if they exist right now but

00:32:44,450 --> 00:32:48,470
if you're not running your validation

00:32:46,240 --> 00:32:50,000
regularly you don't know what the state

00:32:48,470 --> 00:32:54,470
of the world is or if it's still valid

00:32:50,000 --> 00:32:56,930
tomorrow this should go without saying

00:32:54,470 --> 00:32:59,600
but script all your automation terraform

00:32:56,930 --> 00:33:02,140
is one way our codex documentation uses

00:32:59,600 --> 00:33:05,800
terraform and we already have terraform

00:33:02,140 --> 00:33:11,210
scripting that will stand up our

00:33:05,800 --> 00:33:13,190
reference OpenStack the first time i

00:33:11,210 --> 00:33:17,030
reaiiy the first time I set up open sac

00:33:13,190 --> 00:33:18,650
it was a hundred or so lines of Python

00:33:17,030 --> 00:33:20,720
and that actually is really friendly too

00:33:18,650 --> 00:33:24,530
I mean being that it integrates so well

00:33:20,720 --> 00:33:27,290
with with the OpenStack API bas UI is

00:33:24,530 --> 00:33:29,030
another helpful tool and bas UI is a

00:33:27,290 --> 00:33:30,380
relatively new project that Stark and

00:33:29,030 --> 00:33:34,970
Wayne is added to the cloud finder

00:33:30,380 --> 00:33:37,970
community and it gives you a nice view

00:33:34,970 --> 00:33:39,950
of your Bosch world it lets you you can

00:33:37,970 --> 00:33:42,020
SSH into your boss you can see logs

00:33:39,950 --> 00:33:43,310
we're going to update it for Bosch too

00:33:42,020 --> 00:33:47,030
so that it has some of the features that

00:33:43,310 --> 00:33:50,600
Bosch tus CPI or sorry CLI will support

00:33:47,030 --> 00:33:57,680
and finally if this isn't readily

00:33:50,600 --> 00:33:59,630
apparent ship your logs if you've got 30

00:33:57,680 --> 00:34:02,120
compute nodes and every one of them has

00:33:59,630 --> 00:34:04,100
its own copy of its of what's going on

00:34:02,120 --> 00:34:05,750
it's view of Nova I mean some

00:34:04,100 --> 00:34:07,700
distributions actually I hope most

00:34:05,750 --> 00:34:10,340
distributions now actually do some type

00:34:07,700 --> 00:34:12,879
of forwarding to a controller node but

00:34:10,340 --> 00:34:15,110
if you're standing up your own bespoke

00:34:12,879 --> 00:34:17,240
OpenStack I've come into situations

00:34:15,110 --> 00:34:19,190
often where there's nothing happening

00:34:17,240 --> 00:34:20,870
with the logs out of the gate this

00:34:19,190 --> 00:34:23,179
should be the first thing you do it

00:34:20,870 --> 00:34:25,970
should be pretty clear from what I've

00:34:23,179 --> 00:34:28,760
talked about today that you need access

00:34:25,970 --> 00:34:31,220
to those open stack logs most of the

00:34:28,760 --> 00:34:36,679
errors we've talked about you I showed

00:34:31,220 --> 00:34:39,320
you what Bosch has said this is the

00:34:36,679 --> 00:34:41,750
problem and I did have lots of slides

00:34:39,320 --> 00:34:44,690
that also said this is what Oh

00:34:41,750 --> 00:34:46,520
stack says and it turned out I just

00:34:44,690 --> 00:34:48,290
didn't have the time to really discuss

00:34:46,520 --> 00:34:51,679
all of them so I thought it would be

00:34:48,290 --> 00:34:54,350
easier to make the point that you really

00:34:51,679 --> 00:34:57,320
have to dig a little deeper and that's

00:34:54,350 --> 00:34:58,700
why we get to this point this here is a

00:34:57,320 --> 00:35:01,520
project from Stark and Wayne called

00:34:58,700 --> 00:35:04,520
sawmill and sawmill is pretty useful

00:35:01,520 --> 00:35:07,910
because it's basically tail - F for

00:35:04,520 --> 00:35:10,790
distributed systems so you can't really

00:35:07,910 --> 00:35:12,950
you're not getting any log retention but

00:35:10,790 --> 00:35:15,590
you can see exactly what's going on

00:35:12,950 --> 00:35:18,340
right now make the error happen and get

00:35:15,590 --> 00:35:18,340
it in front of your face

00:35:21,980 --> 00:35:27,200
a few people contributed to my talk and

00:35:25,130 --> 00:35:29,960
some of their examples are in here and I

00:35:27,200 --> 00:35:32,600
wanted to thank them James Hunt Jeremy

00:35:29,960 --> 00:35:34,490
Budnick Sean Kerry Craig boo check and

00:35:32,600 --> 00:35:41,710
then my wife for putting up with me in

00:35:34,490 --> 00:35:41,710
general and that's all I have today

00:35:49,330 --> 00:35:56,300
there's a couple of minutes but it is

00:35:51,800 --> 00:36:02,920
also lunchtime sorry so if anybody had

00:35:56,300 --> 00:36:02,920
any questions other all right

00:36:04,290 --> 00:36:15,630
oh sure sure sure yep Jan can answer

00:36:13,410 --> 00:36:24,900
that one the what what OpenStack

00:36:15,630 --> 00:36:26,190
versions is the validator support okay

00:36:24,900 --> 00:36:36,600
yes I actually mentioned that that's

00:36:26,190 --> 00:36:39,980
right yep excellent all right enjoy

00:36:36,600 --> 00:36:39,980

YouTube URL: https://www.youtube.com/watch?v=GLWos28qpwY


