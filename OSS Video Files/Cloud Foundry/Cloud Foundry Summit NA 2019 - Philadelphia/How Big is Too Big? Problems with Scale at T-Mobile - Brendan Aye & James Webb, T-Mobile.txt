Title: How Big is Too Big? Problems with Scale at T-Mobile - Brendan Aye & James Webb, T-Mobile
Publication date: 2019-04-11
Playlist: Cloud Foundry Summit NA 2019 - Philadelphia
Description: 
	How Big is Too Big? Problems with Scale at T-Mobile - Brendan Aye & James Webb, T-Mobile

Over the last three years, T-Mobile has leaned in heavily on Cloud Foundry and the boost it brought to developer productivity. As the platform popularity "hockey-sticked", so did problems with operating large foundations.

Through it all, we struggled to find answers to two important questions:
How big is too big for a foundation?
How many foundations is too many?

Without clear answers, we stumbled in to the limit for both for our environment. Running entirely on-premise, hardware constraints underpinned most of the problems faced, as well as the possible solutions. We'll walk through some of the issues that came up in our larger foundations and what we did about them.

About Brendan Aye
Cloud Foundry Platform Architect, T-Mobile
Brendan Aye is the Principal Cloud Foundry architect at T-Mobile, where he has been working with Cloud Foundry for four years.

About James Webb
Member of Technical Staff, Platform Architecture, T-Mobile
Technical leader with 20+ years of infrastructure background currently focused on bringing on-premise Cloud Foundry & Kubernetes goodness to the enterprise.

https://www.cloudfoundry.org/
Captions: 
	00:00:00,000 --> 00:00:04,259
hi my name is Brendan a this is James

00:00:01,920 --> 00:00:05,279
Webb we are the platform engineering

00:00:04,259 --> 00:00:07,890
team from t-mobile

00:00:05,279 --> 00:00:09,710
we started ourselves about just about

00:00:07,890 --> 00:00:12,420
three years ago or so with cloud foundry

00:00:09,710 --> 00:00:16,379
at this point we've now grown to around

00:00:12,420 --> 00:00:18,900
25 people across both paths for cloud

00:00:16,379 --> 00:00:20,760
foundry as well as PKS we have a common

00:00:18,900 --> 00:00:22,800
Intel team that deals with monitoring

00:00:20,760 --> 00:00:24,689
and logging over the top as well as a

00:00:22,800 --> 00:00:26,640
common team that is designed for

00:00:24,689 --> 00:00:28,170
customer success they help teams on

00:00:26,640 --> 00:00:30,599
board make sure they run properly follow

00:00:28,170 --> 00:00:32,189
best practices things like that so a

00:00:30,599 --> 00:00:34,320
pretty varied background that's very

00:00:32,189 --> 00:00:36,090
hard to find people who already know you

00:00:34,320 --> 00:00:38,100
know cloud foundry or kubernetes who are

00:00:36,090 --> 00:00:39,570
not actively employed so we found a lot

00:00:38,100 --> 00:00:41,670
of people that are you know X UNIX

00:00:39,570 --> 00:00:43,020
admins software developers things like

00:00:41,670 --> 00:00:44,969
that and I really looked for the right

00:00:43,020 --> 00:00:47,399
mindset in those people and instead

00:00:44,969 --> 00:00:50,520
train them up to you know kind of fit

00:00:47,399 --> 00:00:52,770
the mold we're looking for so in terms

00:00:50,520 --> 00:00:55,020
of what we manage really looking at

00:00:52,770 --> 00:00:57,449
typical cloud foundry or you know

00:00:55,020 --> 00:00:58,530
pickles I mean apples application

00:00:57,449 --> 00:01:00,239
service at this point they keep on

00:00:58,530 --> 00:01:01,530
changing names on us as well as

00:01:00,239 --> 00:01:02,940
kubernetes and we are going to breeze

00:01:01,530 --> 00:01:03,989
through these slides pretty quickly we

00:01:02,940 --> 00:01:05,970
assume it's going to be some questions

00:01:03,989 --> 00:01:08,010
that answer so some of this content will

00:01:05,970 --> 00:01:09,360
just be going through fairly quickly we

00:01:08,010 --> 00:01:11,100
also have some ayahs that we deal with

00:01:09,360 --> 00:01:13,500
for our customers we have some guys that

00:01:11,100 --> 00:01:14,700
need to run services that are not part

00:01:13,500 --> 00:01:17,130
of the platform itself so we boss

00:01:14,700 --> 00:01:21,450
deploys and rabbitmq a lot of Concours

00:01:17,130 --> 00:01:22,979
jump boxes things of that nature in

00:01:21,450 --> 00:01:25,439
terms of where we were versus where we

00:01:22,979 --> 00:01:27,090
are now it used to take us seven months

00:01:25,439 --> 00:01:29,009
and 72 steps to get new code to

00:01:27,090 --> 00:01:31,530
production if you think about how slowly

00:01:29,009 --> 00:01:33,689
that is moving for you know something

00:01:31,530 --> 00:01:35,430
when our CEO or if someone else in the

00:01:33,689 --> 00:01:37,049
business wants to get some feature added

00:01:35,430 --> 00:01:38,189
some kind of new promotion or launch

00:01:37,049 --> 00:01:40,079
team we have to scale up for major

00:01:38,189 --> 00:01:42,570
events like iPhone launch or for Black

00:01:40,079 --> 00:01:44,579
Friday that is just a crippling speed to

00:01:42,570 --> 00:01:46,170
move at so we've been able to change

00:01:44,579 --> 00:01:48,060
that around we can now deploy same-day

00:01:46,170 --> 00:01:49,020
from dead test production we have some

00:01:48,060 --> 00:01:50,490
of the guys in this room who are

00:01:49,020 --> 00:01:52,530
involved in that process as well who

00:01:50,490 --> 00:01:54,450
could speak to the benefit they've seen

00:01:52,530 --> 00:01:56,130
in their own teams a big part of that

00:01:54,450 --> 00:01:57,899
also you know moving towards cloud

00:01:56,130 --> 00:01:59,549
native micro services and trying to

00:01:57,899 --> 00:02:01,500
optimize these things for the scale to

00:01:59,549 --> 00:02:03,840
running at has led these apps to run a

00:02:01,500 --> 00:02:05,270
lot faster so on average we've seen 40

00:02:03,840 --> 00:02:07,829
to 50 percent application response time

00:02:05,270 --> 00:02:09,390
and a lot more reliable applications as

00:02:07,829 --> 00:02:10,800
well they break you know maybe three

00:02:09,390 --> 00:02:12,330
percent less frequently and we can fix

00:02:10,800 --> 00:02:13,530
them much faster when they do

00:02:12,330 --> 00:02:16,830
due to the very narrow

00:02:13,530 --> 00:02:18,090
with them so all in all you know a lot

00:02:16,830 --> 00:02:19,830
more changes happening a lot more

00:02:18,090 --> 00:02:20,819
frequently apps are running faster

00:02:19,830 --> 00:02:22,440
they're breaking less frequently and

00:02:20,819 --> 00:02:23,550
they're they're being fixed a lot more

00:02:22,440 --> 00:02:24,750
quickly

00:02:23,550 --> 00:02:27,930
you know when they when they are

00:02:24,750 --> 00:02:29,310
breaking beyond that we have some

00:02:27,930 --> 00:02:31,650
applications that used to use around

00:02:29,310 --> 00:02:32,940
2000 physical servers due to the

00:02:31,650 --> 00:02:35,100
consolidation have done here they now

00:02:32,940 --> 00:02:36,540
run on less than 150 physical servers

00:02:35,100 --> 00:02:39,300
along with the whole suite of other

00:02:36,540 --> 00:02:40,350
applications so incredible density that

00:02:39,300 --> 00:02:43,560
were able to achieve through this

00:02:40,350 --> 00:02:45,239
platform and through containerization so

00:02:43,560 --> 00:02:46,890
throughout this whole process you know

00:02:45,239 --> 00:02:47,459
we asked kind of two questions of the

00:02:46,890 --> 00:02:49,140
broader community

00:02:47,459 --> 00:02:51,090
how big is too big for a single

00:02:49,140 --> 00:02:52,980
foundation and how many foundations is

00:02:51,090 --> 00:02:54,690
too many and everyone kind of has

00:02:52,980 --> 00:02:56,450
different answers you know we've been

00:02:54,690 --> 00:02:59,340
pointed to some case studies showing

00:02:56,450 --> 00:03:01,410
Diego and BBS scheduling of 200 thousand

00:02:59,340 --> 00:03:02,880
containers and sure that's great but

00:03:01,410 --> 00:03:04,080
what about logging what about monitoring

00:03:02,880 --> 00:03:05,760
what about metrics what about the fire

00:03:04,080 --> 00:03:07,769
hose and those aren't really the concern

00:03:05,760 --> 00:03:09,390
there other enterprises say we don't

00:03:07,769 --> 00:03:10,920
worry about logging some enterprises say

00:03:09,390 --> 00:03:12,750
customers are on their own for

00:03:10,920 --> 00:03:14,610
monitoring really a lot of different

00:03:12,750 --> 00:03:16,319
options all across the board but we

00:03:14,610 --> 00:03:18,810
couldn't get a good answer to these two

00:03:16,319 --> 00:03:21,420
questions so we kind of start to find

00:03:18,810 --> 00:03:24,420
them answer ourselves star largest

00:03:21,420 --> 00:03:27,209
foundation 16,000 apps these are not all

00:03:24,420 --> 00:03:29,910
running which is why we only have 9500 a

00:03:27,209 --> 00:03:33,269
is so 16,000 apps in the cloud

00:03:29,910 --> 00:03:35,940
controller maybe half a runny or so 365

00:03:33,269 --> 00:03:38,160
orgs and 2,200 spaces which is just

00:03:35,940 --> 00:03:39,570
insane to us there there are some

00:03:38,160 --> 00:03:41,970
services that you know page through all

00:03:39,570 --> 00:03:44,579
the spaces and it takes forever 3,200

00:03:41,970 --> 00:03:46,890
users only around 500 those are monthly

00:03:44,579 --> 00:03:48,560
active users so it's not you know 3,000

00:03:46,890 --> 00:03:51,570
developers longer than every single day

00:03:48,560 --> 00:03:54,209
eighty seven hundred and forty three

00:03:51,570 --> 00:03:56,670
thousand seven hundred bindings that is

00:03:54,209 --> 00:03:58,320
just a lot of services a lot of these

00:03:56,670 --> 00:04:00,090
are syslog services that almost every

00:03:58,320 --> 00:04:01,890
app uses as you can see we have eleven

00:04:00,090 --> 00:04:03,690
hundred seven thousand six log drains a

00:04:01,890 --> 00:04:05,549
lot of app dynamics a lot of spring

00:04:03,690 --> 00:04:08,100
cloud services including config server

00:04:05,549 --> 00:04:09,630
service registry circuit breaker you

00:04:08,100 --> 00:04:12,390
know just you name it we've got it

00:04:09,630 --> 00:04:14,820
running we've got a lot of stuff in this

00:04:12,390 --> 00:04:16,500
foundation the recent update did not go

00:04:14,820 --> 00:04:16,890
all that well which we'll get to in a

00:04:16,500 --> 00:04:20,160
minute

00:04:16,890 --> 00:04:21,450
so at vertical scale we found some

00:04:20,160 --> 00:04:22,919
limits we found what does not work that

00:04:21,450 --> 00:04:24,390
well we'll talk about some of the

00:04:22,919 --> 00:04:25,830
problems we've actually seen that showed

00:04:24,390 --> 00:04:28,139
us this is too large

00:04:25,830 --> 00:04:29,669
so just kind of general issues and I

00:04:28,139 --> 00:04:30,840
apologize view of sunglasses you want to

00:04:29,669 --> 00:04:33,659
block out all the magenta we've got a

00:04:30,840 --> 00:04:36,599
lot of that coming up so general issues

00:04:33,659 --> 00:04:38,699
we find that we have some TCP buffers

00:04:36,599 --> 00:04:40,169
overflowing from our Diego cells that

00:04:38,699 --> 00:04:42,000
are doing round-trip traffic back to our

00:04:40,169 --> 00:04:43,250
foundation there's kind of some bizarre

00:04:42,000 --> 00:04:45,210
problems where we get you know

00:04:43,250 --> 00:04:48,000
occasionally a few percent packet loss

00:04:45,210 --> 00:04:49,740
that leads to some disconnected active

00:04:48,000 --> 00:04:51,120
sessions some SSL handshake failures

00:04:49,740 --> 00:04:52,500
things like that just some really

00:04:51,120 --> 00:04:53,729
strange stuff we see only in our large

00:04:52,500 --> 00:04:55,620
foundations that we don't see at our

00:04:53,729 --> 00:04:58,889
small ones and had not quite been able

00:04:55,620 --> 00:05:00,930
to pinpoint that fire hose nozzles in

00:04:58,889 --> 00:05:03,599
our large foundations disconnect every

00:05:00,930 --> 00:05:05,580
minute or two maybe regardless of the

00:05:03,599 --> 00:05:07,500
scale we cannot keep them running we

00:05:05,580 --> 00:05:09,120
still use them but we have kind of some

00:05:07,500 --> 00:05:11,370
sparse and not always very accurate

00:05:09,120 --> 00:05:12,690
metrics and then beyond that you know

00:05:11,370 --> 00:05:14,729
just some occasional errors where we'll

00:05:12,690 --> 00:05:16,500
get issues pushing applications whether

00:05:14,729 --> 00:05:18,569
it's going to blobstore talking to BBS

00:05:16,500 --> 00:05:19,740
something else like that that we just it

00:05:18,569 --> 00:05:21,659
makes it difficult for us to have

00:05:19,740 --> 00:05:24,210
synthetic transactions running like a

00:05:21,659 --> 00:05:28,169
smoke test for spring cloud services or

00:05:24,210 --> 00:05:30,029
for you know general has run time where

00:05:28,169 --> 00:05:31,199
we have a hard time saying is this an

00:05:30,029 --> 00:05:32,580
actual failure that's going to impact

00:05:31,199 --> 00:05:34,440
customers or is it just something that

00:05:32,580 --> 00:05:36,289
if we retry will work without a problem

00:05:34,440 --> 00:05:39,870
so it's made it difficult for us to

00:05:36,289 --> 00:05:41,460
troubleshoot some problems at times one

00:05:39,870 --> 00:05:43,080
of the big ones we've seen this is an

00:05:41,460 --> 00:05:44,400
example of an upgrade that's running so

00:05:43,080 --> 00:05:47,849
here you can see preparing the manifest

00:05:44,400 --> 00:05:49,680
and then it goes compile packages which

00:05:47,849 --> 00:05:50,819
it does not have to do and then 45

00:05:49,680 --> 00:05:53,190
minutes later it finishes with no

00:05:50,819 --> 00:05:54,360
changes just sits there - and through

00:05:53,190 --> 00:05:56,039
deciding what's going to change you

00:05:54,360 --> 00:05:58,979
realizes nothing's gonna change after 45

00:05:56,039 --> 00:06:00,419
minutes and moves on so that's not a

00:05:58,979 --> 00:06:01,800
huge problem to have upgrade to take a

00:06:00,419 --> 00:06:03,449
while and nothing happens but when

00:06:01,800 --> 00:06:04,979
something fails and then we have to

00:06:03,449 --> 00:06:06,779
again start the upgrade again and wait

00:06:04,979 --> 00:06:08,099
we put something that's the wrong change

00:06:06,779 --> 00:06:09,449
and we have to go through and change

00:06:08,099 --> 00:06:11,610
that again and wait for all this wait

00:06:09,449 --> 00:06:12,779
time it gets pretty brutal that to sit

00:06:11,610 --> 00:06:14,400
there and just wait it wait for it to

00:06:12,779 --> 00:06:16,469
chew through and turn around and do

00:06:14,400 --> 00:06:18,210
almost nothing at all so we don't like

00:06:16,469 --> 00:06:20,490
that much we've got these slow upgrades

00:06:18,210 --> 00:06:22,259
where it can take sometimes 60 to 90

00:06:20,490 --> 00:06:24,479
minutes for ops and a boss to even start

00:06:22,259 --> 00:06:26,310
doing the work beyond that we got a new

00:06:24,479 --> 00:06:28,860
stem cell or a new major past version

00:06:26,310 --> 00:06:30,750
and it can take 18 to 24 hours to repave

00:06:28,860 --> 00:06:33,150
our whole oral platform this is all

00:06:30,750 --> 00:06:34,620
running on premise it's not AWS so we

00:06:33,150 --> 00:06:35,729
have you know underlying infrastructure

00:06:34,620 --> 00:06:38,099
that could be causing some of these

00:06:35,729 --> 00:06:38,650
issues but really just a very long time

00:06:38,099 --> 00:06:40,720
for upgrade

00:06:38,650 --> 00:06:42,880
and then we start adding in some of the

00:06:40,720 --> 00:06:45,699
on-demand services pivotal cloud cash or

00:06:42,880 --> 00:06:49,030
on-demand rabbin queue Redis my sequel

00:06:45,699 --> 00:06:51,100
it gets to one of those jobs and it may

00:06:49,030 --> 00:06:52,300
take a minute may take an hour may take

00:06:51,100 --> 00:06:54,250
10 hours to go through all these

00:06:52,300 --> 00:06:55,960
instances really an unknown amount of

00:06:54,250 --> 00:06:57,690
time and we can't control the order of

00:06:55,960 --> 00:07:01,000
those or the timing at which they happen

00:06:57,690 --> 00:07:03,400
so we're not crazy about that now the

00:07:01,000 --> 00:07:04,780
big problem is blast radius we have a

00:07:03,400 --> 00:07:06,669
number of production foundations we've

00:07:04,780 --> 00:07:07,990
got more or less five or six foundations

00:07:06,669 --> 00:07:10,780
in the same network context for

00:07:07,990 --> 00:07:12,190
production however we started out with

00:07:10,780 --> 00:07:14,139
one of these before we scaled out to

00:07:12,190 --> 00:07:15,760
more and team still like that foundation

00:07:14,139 --> 00:07:17,350
they know it by name they love it they

00:07:15,760 --> 00:07:20,680
want to run all the stuff there as a

00:07:17,350 --> 00:07:23,229
result it handles 70% of our traffic we

00:07:20,680 --> 00:07:25,600
had an issue about probably nine months

00:07:23,229 --> 00:07:26,949
ago that led to a 15 minute outage where

00:07:25,600 --> 00:07:29,110
no traffic was getting to the foundation

00:07:26,949 --> 00:07:30,310
the impact was so large that our CEO is

00:07:29,110 --> 00:07:32,080
aware of it and wanted to make sure it

00:07:30,310 --> 00:07:33,580
did not happen again so kind of shows

00:07:32,080 --> 00:07:35,620
you the importance of this one single

00:07:33,580 --> 00:07:40,690
foundation that we just cannot allow to

00:07:35,620 --> 00:07:43,060
happen the Cloud Foundry API as I

00:07:40,690 --> 00:07:44,919
mentioned we've got 16,000 apps 43,000

00:07:43,060 --> 00:07:47,110
service bindings this stuff takes a long

00:07:44,919 --> 00:07:48,669
time to page through when logs or

00:07:47,110 --> 00:07:50,410
metrics come out the platform they are

00:07:48,669 --> 00:07:51,789
associated with a good not by the app

00:07:50,410 --> 00:07:53,830
name or the org Bamber space name

00:07:51,789 --> 00:07:55,030
guittar is not good is not very useful

00:07:53,830 --> 00:07:57,130
to most people and so we have to

00:07:55,030 --> 00:07:58,150
correlate this information to correlate

00:07:57,130 --> 00:07:59,889
it we have to look at all up in Cloud

00:07:58,150 --> 00:08:02,200
Foundry API and we have to make sure we

00:07:59,889 --> 00:08:02,710
keep that stuff up to date and keeping

00:08:02,200 --> 00:08:05,169
it up to date

00:08:02,710 --> 00:08:07,780
every few minutes with that many Records

00:08:05,169 --> 00:08:10,000
is pretty significant trying things like

00:08:07,780 --> 00:08:11,229
the bug Prometheus CF exporter we

00:08:10,000 --> 00:08:12,340
actually hit a limit with open file

00:08:11,229 --> 00:08:15,729
handles because it was doing this

00:08:12,340 --> 00:08:17,560
massive unconstrained you know parallel

00:08:15,729 --> 00:08:20,080
lookup of all these objects so we had to

00:08:17,560 --> 00:08:21,970
submit an issue to them to you know have

00:08:20,080 --> 00:08:24,400
a size weight group and said that does

00:08:21,970 --> 00:08:26,199
not just spin up you know three or four

00:08:24,400 --> 00:08:30,280
thousand threads all at once or go

00:08:26,199 --> 00:08:32,050
routines rather the latency we

00:08:30,280 --> 00:08:34,390
occasionally have issues where we're

00:08:32,050 --> 00:08:36,459
doing some cache refreshes for some of

00:08:34,390 --> 00:08:38,529
our downstream systems we might see

00:08:36,459 --> 00:08:40,209
latency or 3 to 6 seconds or so and as

00:08:38,529 --> 00:08:41,380
an end user when you do a CF log and

00:08:40,209 --> 00:08:43,599
then it goes to pull up your list of

00:08:41,380 --> 00:08:46,000
orgs and it takes 6 seconds like that

00:08:43,599 --> 00:08:47,860
that sucks it just feels slow again for

00:08:46,000 --> 00:08:49,510
the spaces waiting more time for that

00:08:47,860 --> 00:08:50,779
looking up your services your apps all

00:08:49,510 --> 00:08:53,920
these things take time

00:08:50,779 --> 00:08:56,389
and it's a very bad customer perception

00:08:53,920 --> 00:08:58,069
logging is one of our favorite and least

00:08:56,389 --> 00:08:59,740
favorite things to talk about as I

00:08:58,069 --> 00:09:02,480
mentioned we have 11,000 syslog grains

00:08:59,740 --> 00:09:05,810
for production we produce around 4.5

00:09:02,480 --> 00:09:08,300
billion log messages per day we lose

00:09:05,810 --> 00:09:09,920
around 5 to 10 percent of those the

00:09:08,300 --> 00:09:11,959
sustained rate that we have not been

00:09:09,920 --> 00:09:13,490
able to improve upon yet and then we

00:09:11,959 --> 00:09:15,529
have some customers one in particular

00:09:13,490 --> 00:09:17,209
that logs out 300 million messages in

00:09:15,529 --> 00:09:19,430
about 10 or 15 minutes every night for

00:09:17,209 --> 00:09:21,259
some big batch job and that's basically

00:09:19,430 --> 00:09:24,079
one instance logging out all those logs

00:09:21,259 --> 00:09:25,249
we drop 70 or 80% of those logs and

00:09:24,079 --> 00:09:25,459
there's not a whole lot we can do about

00:09:25,249 --> 00:09:27,050
that

00:09:25,459 --> 00:09:28,910
so we try to work with these customers

00:09:27,050 --> 00:09:31,370
try to improve things but in general

00:09:28,910 --> 00:09:34,459
we've scaled log Gator as largest logger

00:09:31,370 --> 00:09:37,220
team since we should scale it $40 20 TCS

00:09:34,459 --> 00:09:40,129
40 syslog adapters and it still is not

00:09:37,220 --> 00:09:41,870
big enough and there's not much you can

00:09:40,129 --> 00:09:43,279
do about at this point so you know

00:09:41,870 --> 00:09:45,170
there's not much we can do about this

00:09:43,279 --> 00:09:46,279
vertical scale problem beyond just

00:09:45,170 --> 00:09:48,829
saying that you're gonna lose some

00:09:46,279 --> 00:09:49,999
percentage of logs log less use use log

00:09:48,829 --> 00:09:52,759
data less than it will probably be

00:09:49,999 --> 00:09:54,499
better overall so a lot of problems with

00:09:52,759 --> 00:09:55,730
vertical scaling the best solution to

00:09:54,499 --> 00:09:57,860
vertical scaling challenges is

00:09:55,730 --> 00:09:59,360
horizontal scaling so many smaller

00:09:57,860 --> 00:10:01,579
foundations instead of a few very large

00:09:59,360 --> 00:10:02,240
foundations so instead of challenges

00:10:01,579 --> 00:10:03,740
that comes with that

00:10:02,240 --> 00:10:12,529
so James will talk through some of those

00:10:03,740 --> 00:10:14,209
issues I want to add to what Brendan

00:10:12,529 --> 00:10:16,430
just said so it's interesting it's it's

00:10:14,209 --> 00:10:18,079
it's just a varied experience through

00:10:16,430 --> 00:10:19,490
the day for the for those foundations

00:10:18,079 --> 00:10:20,689
for our large vertical foundations and

00:10:19,490 --> 00:10:21,889
we're not happy about it right we know

00:10:20,689 --> 00:10:23,449
it's not the right thing to do and we're

00:10:21,889 --> 00:10:25,519
working really hard to fix it it's just

00:10:23,449 --> 00:10:29,089
it's and we have a persistent sense of

00:10:25,519 --> 00:10:30,620
dread about making changes and and how

00:10:29,089 --> 00:10:33,500
things impact our customers and work

00:10:30,620 --> 00:10:36,610
there a couple of key contributors right

00:10:33,500 --> 00:10:36,610
down here we're gonna help us fix that

00:10:36,720 --> 00:10:39,960
the horizontal scale so horizontal scale

00:10:38,610 --> 00:10:41,070
bring his own set of problems right his

00:10:39,960 --> 00:10:42,570
web we're hoping what we're gonna do is

00:10:41,070 --> 00:10:43,770
we're gonna we're gonna make life better

00:10:42,570 --> 00:10:46,770
for our customers but we're gonna take

00:10:43,770 --> 00:10:48,360
on a lot of complexity ourselves and one

00:10:46,770 --> 00:10:50,460
of the main things is just like how do

00:10:48,360 --> 00:10:52,710
you how do you do automation across so

00:10:50,460 --> 00:10:54,990
many foundations how do you there's a

00:10:52,710 --> 00:10:57,030
lot of objects PCF automations complex

00:10:54,990 --> 00:10:59,010
it's it's fantastic but it takes a lot

00:10:57,030 --> 00:10:59,970
of automation just to get PCF automation

00:10:59,010 --> 00:11:01,890
working so that's one of the things

00:10:59,970 --> 00:11:05,720
we're looking for is how do we automate

00:11:01,890 --> 00:11:10,830
our automation the first thing we do is

00:11:05,720 --> 00:11:13,290
deploy PCF automation with with Josh and

00:11:10,830 --> 00:11:16,890
Concours that's its own set that's its

00:11:13,290 --> 00:11:18,690
own set of things and tooling to

00:11:16,890 --> 00:11:19,950
maintain we need to make sure that

00:11:18,690 --> 00:11:20,940
configs are standard across large

00:11:19,950 --> 00:11:22,740
foundations we didn't make sure our

00:11:20,940 --> 00:11:24,360
config management is solid if it doesn't

00:11:22,740 --> 00:11:25,530
one suite once we start automating

00:11:24,360 --> 00:11:28,560
things and pushing things to production

00:11:25,530 --> 00:11:30,300
we can have a severe impact and this is

00:11:28,560 --> 00:11:31,410
happening before so we need to make sure

00:11:30,300 --> 00:11:33,270
that we're doing the right thing with

00:11:31,410 --> 00:11:35,430
config management we need to everything

00:11:33,270 --> 00:11:37,080
to be CDC I we have to dog food what we

00:11:35,430 --> 00:11:38,370
what we tell our customers to do which

00:11:37,080 --> 00:11:39,840
is everything you do do with automation

00:11:38,370 --> 00:11:41,160
everything you do do with continuous

00:11:39,840 --> 00:11:44,280
integration can use development we need

00:11:41,160 --> 00:11:45,690
to do the same thing the horizontal

00:11:44,280 --> 00:11:48,270
scale which requires a lot of tooling

00:11:45,690 --> 00:11:49,980
right there's it's it's we have a lot of

00:11:48,270 --> 00:11:51,750
sidecar infrastructure to maintain and

00:11:49,980 --> 00:11:54,030
again that's just a lot of complexity to

00:11:51,750 --> 00:11:57,150
manage we have 15 site carwash instances

00:11:54,030 --> 00:11:58,860
and that numbers growing daily we we had

00:11:57,150 --> 00:11:59,940
centralized concourse centralized Boston

00:11:58,860 --> 00:12:01,320
what we found as we hit the same

00:11:59,940 --> 00:12:02,850
problems with scale in those that were

00:12:01,320 --> 00:12:05,070
repeating in our foundations so now

00:12:02,850 --> 00:12:06,600
pretty much every hardware region get to

00:12:05,070 --> 00:12:08,370
don't concours its own Vash sidecar

00:12:06,600 --> 00:12:10,950
every foundation is gonna get sewn

00:12:08,370 --> 00:12:12,690
concourse right so again we run into a

00:12:10,950 --> 00:12:14,820
management problem of how do we automate

00:12:12,690 --> 00:12:17,010
all that we have a lot of other tools

00:12:14,820 --> 00:12:21,380
there's over there we love Bosch we love

00:12:17,010 --> 00:12:21,380
concours I like the concourse is on fire

00:12:22,190 --> 00:12:27,000
but I think we have to maintain current

00:12:25,380 --> 00:12:28,680
state for all for all this automation

00:12:27,000 --> 00:12:30,630
tooling we have to keep it patched we

00:12:28,680 --> 00:12:32,550
have to keep upgraded monitored backed

00:12:30,630 --> 00:12:34,230
up all right it's a lot of complexity so

00:12:32,550 --> 00:12:36,270
essentially we're taking the complexity

00:12:34,230 --> 00:12:37,830
for managing ops man by clicking around

00:12:36,270 --> 00:12:39,430
the GUI and we're pushing it one that

00:12:37,830 --> 00:12:45,940
work and

00:12:39,430 --> 00:12:47,290
it's hard so that's the issues with us

00:12:45,940 --> 00:12:48,580
now we talk about the issues that were

00:12:47,290 --> 00:12:50,020
that we're giving to our customers by

00:12:48,580 --> 00:12:51,760
scaling out of foundations so teams

00:12:50,020 --> 00:12:53,910
running their applications and multiple

00:12:51,760 --> 00:12:56,830
foundations is problem very problematic

00:12:53,910 --> 00:12:58,570
they we don't have a good deal load

00:12:56,830 --> 00:13:00,610
balancing solution yet we have something

00:12:58,570 --> 00:13:03,460
we've worked on and we're rolling it out

00:13:00,610 --> 00:13:05,410
early stages but for a customer move

00:13:03,460 --> 00:13:06,760
from one foundation to another they've

00:13:05,410 --> 00:13:08,890
got to notify all their upstream

00:13:06,760 --> 00:13:11,710
customers of changes and in some cases

00:13:08,890 --> 00:13:14,050
that might be 10,000 carrots that have a

00:13:11,710 --> 00:13:16,270
that have a bookmark to link to our

00:13:14,050 --> 00:13:17,980
primary foundation so it's not as easy

00:13:16,270 --> 00:13:19,090
as telling the customer just move and

00:13:17,980 --> 00:13:22,840
when are you gonna be done next week

00:13:19,090 --> 00:13:24,400
they can't they can't do it I will talk

00:13:22,840 --> 00:13:26,680
about the juice a little bit so we've

00:13:24,400 --> 00:13:28,270
tried to solve this problem with a DSL B

00:13:26,680 --> 00:13:30,210
we've created up we've created a service

00:13:28,270 --> 00:13:33,610
broker with the open service broker that

00:13:30,210 --> 00:13:35,350
basically you can register which which

00:13:33,610 --> 00:13:37,240
apps you want to be geo load-balanced

00:13:35,350 --> 00:13:38,620
and then when you bind your you you

00:13:37,240 --> 00:13:40,780
create the service behind the service to

00:13:38,620 --> 00:13:43,210
your app and then when you create a geo

00:13:40,780 --> 00:13:44,620
route and bind it to that app as long as

00:13:43,210 --> 00:13:46,480
the health check passes you'll start

00:13:44,620 --> 00:13:48,910
routing traffic to that application so

00:13:46,480 --> 00:13:50,620
it's DNS at that point it's DNS load

00:13:48,910 --> 00:13:51,790
balancing seems to be working pretty

00:13:50,620 --> 00:13:53,230
well we're hoping this is going to gets

00:13:51,790 --> 00:13:54,520
out of our mind we're also really

00:13:53,230 --> 00:13:55,990
interested in working with pivotal to

00:13:54,520 --> 00:13:57,100
try and figure out the service mesh to

00:13:55,990 --> 00:14:00,130
solve these problems and we can just

00:13:57,100 --> 00:14:03,040
eliminate our own solutions and that's

00:14:00,130 --> 00:14:05,770
pretty much all begun we figured this

00:14:03,040 --> 00:14:07,480
was going to be a we were looking for

00:14:05,770 --> 00:14:08,770
questions for and feedback from folks in

00:14:07,480 --> 00:14:10,540
the room because this is a pretty

00:14:08,770 --> 00:14:15,250
interesting topic to get feedback on

00:14:10,540 --> 00:14:17,110
live so we've chatted with a couple of

00:14:15,250 --> 00:14:19,030
customers customer advisory session on

00:14:17,110 --> 00:14:20,560
Monday along with PCF user group and

00:14:19,030 --> 00:14:23,200
found that we're definitely not unique

00:14:20,560 --> 00:14:26,380
in these issues our friends that you

00:14:23,200 --> 00:14:27,520
know a PMC have you know six times our

00:14:26,380 --> 00:14:29,230
foundations and they're managed in a

00:14:27,520 --> 00:14:31,150
horizontal scale and our different ways

00:14:29,230 --> 00:14:32,650
than we are some other customers a

00:14:31,150 --> 00:14:34,570
similar science vertical scale and have

00:14:32,650 --> 00:14:35,860
similar issues that we have so we want

00:14:34,570 --> 00:14:37,900
to open it up for questions and answers

00:14:35,860 --> 00:14:40,000
here we also set up a channel on the

00:14:37,900 --> 00:14:41,400
cloud primary slack running at scale so

00:14:40,000 --> 00:14:44,170
hopefully continuing this conversation

00:14:41,400 --> 00:14:45,310
beyond just the conference but having

00:14:44,170 --> 00:14:47,530
some of the large customers they're able

00:14:45,310 --> 00:14:48,510
to join up and start talking about some

00:14:47,530 --> 00:14:50,259
of these issues that we've been

00:14:48,510 --> 00:14:51,669
experiencing and we

00:14:50,259 --> 00:15:03,100
hopefully find some common solutions or

00:14:51,669 --> 00:15:05,519
patterns at least to mitigate them any

00:15:03,100 --> 00:15:05,519
questions

00:15:06,959 --> 00:15:22,989
we ran way too short for the global low

00:15:16,359 --> 00:15:25,179
bouncer service is that yeah so we have

00:15:22,989 --> 00:15:27,639
f5g is this thing on

00:15:25,179 --> 00:15:30,789
we have f5 GTM setup that we have a

00:15:27,639 --> 00:15:32,410
separate DNS zone delegated to those so

00:15:30,789 --> 00:15:34,389
when customers say see if create service

00:15:32,410 --> 00:15:38,410
my GS lb it goes out there and

00:15:34,389 --> 00:15:40,539
configures a wide IP on that f v g TM so

00:15:38,410 --> 00:15:44,079
when a customer says I need to get to my

00:15:40,539 --> 00:15:46,929
app dot geo dot T - mobile comm that

00:15:44,079 --> 00:15:48,669
lookup itself goes to the g TM the g TM

00:15:46,929 --> 00:15:51,100
says I know that this app is configured

00:15:48,669 --> 00:15:52,209
in these four PCF foundations and so it

00:15:51,100 --> 00:15:53,619
figures out which of those are healthy

00:15:52,209 --> 00:15:55,179
and which when it can route traffic to

00:15:53,619 --> 00:15:58,119
and returns back one of those IP

00:15:55,179 --> 00:15:59,949
addresses for the DNS lookup that's

00:15:58,119 --> 00:16:01,809
effectively how DNS load balancing works

00:15:59,949 --> 00:16:03,249
so it's just been the automation we put

00:16:01,809 --> 00:16:11,949
in place in front of that that's made it

00:16:03,249 --> 00:16:12,110
work along with the OSB one right back

00:16:11,949 --> 00:16:15,269
there

00:16:12,110 --> 00:16:15,269
[Music]

00:16:22,190 --> 00:16:27,200
so you were talking of kind of the

00:16:25,940 --> 00:16:31,160
different ways that companies are

00:16:27,200 --> 00:16:33,200
handling you know the instances at scale

00:16:31,160 --> 00:16:35,420
like for example going to multiple

00:16:33,200 --> 00:16:37,310
foundations and whatever would you say

00:16:35,420 --> 00:16:39,740
and that's something that I think we've

00:16:37,310 --> 00:16:40,220
done to try and address that what have

00:16:39,740 --> 00:16:42,110
had it

00:16:40,220 --> 00:16:44,480
the struggle is getting people to

00:16:42,110 --> 00:16:48,140
actually move to those yes you describe

00:16:44,480 --> 00:16:50,060
that very well how are you guys handling

00:16:48,140 --> 00:16:52,070
that you know as you all important

00:16:50,060 --> 00:16:54,380
applications are you having to think

00:16:52,070 --> 00:16:55,790
about okay you're a small facial you let

00:16:54,380 --> 00:16:57,769
go in this posture and you're a bigger

00:16:55,790 --> 00:16:59,209
finisher good another posture or or how

00:16:57,769 --> 00:17:01,910
are you kind of addressing that problem

00:16:59,209 --> 00:17:03,740
sure for production we have CF

00:17:01,910 --> 00:17:06,110
management setup that PCI vests put

00:17:03,740 --> 00:17:07,669
together so anytime a customer wants to

00:17:06,110 --> 00:17:10,040
be on boarded to a production foundation

00:17:07,669 --> 00:17:12,110
they get the same the same orgs and same

00:17:10,040 --> 00:17:14,240
spaces and same quota across all

00:17:12,110 --> 00:17:15,500
production foundations so from the very

00:17:14,240 --> 00:17:17,900
start they can push strap to all these

00:17:15,500 --> 00:17:19,429
places at once we have dashboards we

00:17:17,900 --> 00:17:21,140
expose to customers that show the

00:17:19,429 --> 00:17:23,030
current utilization and the available

00:17:21,140 --> 00:17:24,350
free space in the foundations themselves

00:17:23,030 --> 00:17:25,939
so they can kind of make their own

00:17:24,350 --> 00:17:27,439
decisions in terms of you know what

00:17:25,939 --> 00:17:29,179
version is this at how much space is

00:17:27,439 --> 00:17:31,250
available how much am i deploying and

00:17:29,179 --> 00:17:32,480
where should that go we tell all of our

00:17:31,250 --> 00:17:34,760
customers you should deploy to multiple

00:17:32,480 --> 00:17:36,860
we have you know two regions of hardware

00:17:34,760 --> 00:17:38,540
and our primary dc4 foundations across

00:17:36,860 --> 00:17:40,730
that and so we say you should leave at

00:17:38,540 --> 00:17:42,530
least two of these run three instances

00:17:40,730 --> 00:17:44,270
of your app in each of these foundations

00:17:42,530 --> 00:17:45,770
and distribute load across all them at

00:17:44,270 --> 00:17:48,169
the same time that way you can tolerate

00:17:45,770 --> 00:17:49,549
failure of an AZ of an entire region of

00:17:48,169 --> 00:17:52,309
a whole PCF foundation without your

00:17:49,549 --> 00:17:54,080
application being impacted itself not

00:17:52,309 --> 00:17:55,760
all customers do the right thing so

00:17:54,080 --> 00:17:58,309
we're working with our with some of our

00:17:55,760 --> 00:17:59,900
teams now directly saying we've noticed

00:17:58,309 --> 00:18:01,820
your application is not running in both

00:17:59,900 --> 00:18:04,700
places or is not running in more than

00:18:01,820 --> 00:18:05,750
one place rather so are there barriers

00:18:04,700 --> 00:18:06,860
that are keeping you from doing this

00:18:05,750 --> 00:18:08,840
when can you make it happen

00:18:06,860 --> 00:18:10,669
making sure that our leadership and

00:18:08,840 --> 00:18:12,290
their leadership knows that this is the

00:18:10,669 --> 00:18:13,549
state they're currently in and if we

00:18:12,290 --> 00:18:16,330
have issues that will likely impact

00:18:13,549 --> 00:18:16,330
their application

00:18:18,730 --> 00:18:21,730
or more foundations we're gonna have

00:18:20,080 --> 00:18:22,869
issues where we we're trying to figure

00:18:21,730 --> 00:18:24,669
out what the right approach for that is

00:18:22,869 --> 00:18:26,080
right if we have we have 15 foundations

00:18:24,669 --> 00:18:28,539
do we really want everyone peanut butter

00:18:26,080 --> 00:18:30,159
across all 15 where do we start putting

00:18:28,539 --> 00:18:32,799
together groups of foundations and say

00:18:30,159 --> 00:18:34,899
you deployed a foundation set ABC right

00:18:32,799 --> 00:18:36,399
so it's kind of we're figuring out what

00:18:34,899 --> 00:18:38,529
that transition looks like in work we

00:18:36,399 --> 00:18:40,210
have some limitations because Harbert

00:18:38,529 --> 00:18:41,320
are I mean other just life cycle events

00:18:40,210 --> 00:18:43,779
that are coming in or hope we're gonna

00:18:41,320 --> 00:18:48,700
be able to to do it right but it's it's

00:18:43,779 --> 00:18:55,749
gonna be very challenging couple right

00:18:48,700 --> 00:18:57,279
there you mentioned a CI CD for long

00:18:55,749 --> 00:19:01,119
oops man

00:18:57,279 --> 00:19:03,639
configuration guru please elaborate a

00:19:01,119 --> 00:19:06,249
little bit out of these now question is

00:19:03,639 --> 00:19:09,460
you also mention automation your PSA of

00:19:06,249 --> 00:19:12,669
automation yes sure very pairs what did

00:19:09,460 --> 00:19:14,769
we do to achieve that Thanks sure

00:19:12,669 --> 00:19:16,299
so you want to talk about it's just it's

00:19:14,769 --> 00:19:18,009
a work in progress right right now so

00:19:16,299 --> 00:19:19,330
right now we manual the click on course

00:19:18,009 --> 00:19:21,159
and then automation on top of that but

00:19:19,330 --> 00:19:22,480
we have another team that's sub team

00:19:21,159 --> 00:19:24,159
that's looking at how do we

00:19:22,480 --> 00:19:25,749
automatically deploy Concours and then

00:19:24,159 --> 00:19:27,940
how do we how do we prioritize

00:19:25,749 --> 00:19:30,220
everything so that we can set up that

00:19:27,940 --> 00:19:32,590
set up DC fanimation to then deploy a

00:19:30,220 --> 00:19:36,489
foundation in terms of config management

00:19:32,590 --> 00:19:38,769
for a a particular foundation it's all

00:19:36,489 --> 00:19:41,049
just kind of get ops model to where we

00:19:38,769 --> 00:19:44,669
up we update repos and then rather run

00:19:41,049 --> 00:19:47,859
the automation we weave

00:19:44,669 --> 00:19:50,830
we're very diligent now about making

00:19:47,859 --> 00:19:53,080
sure we don't push bad things too or we

00:19:50,830 --> 00:19:54,909
don't change too much with the given

00:19:53,080 --> 00:19:58,179
push so we do some you know

00:19:54,909 --> 00:20:00,159
configuration drift analysis between

00:19:58,179 --> 00:20:01,330
what it was and what we're going to and

00:20:00,159 --> 00:20:04,149
we're very careful about what we push

00:20:01,330 --> 00:20:06,100
and gaining confident confidence in

00:20:04,149 --> 00:20:07,869
making that and much more just just push

00:20:06,100 --> 00:20:09,879
button automate it we'd like to get to

00:20:07,869 --> 00:20:11,440
the point where you know something goes

00:20:09,879 --> 00:20:12,909
to piff net it goes to our staging

00:20:11,440 --> 00:20:14,649
foundations runs for a couple of days

00:20:12,909 --> 00:20:15,190
you know and then our automation will

00:20:14,649 --> 00:20:16,390
start

00:20:15,190 --> 00:20:19,810
rolling that through all the

00:20:16,390 --> 00:20:21,420
Foundation's not there yet but so we

00:20:19,810 --> 00:20:25,750
know we need to do automation automation

00:20:21,420 --> 00:20:27,160
not solved yet we're hoping the

00:20:25,750 --> 00:20:29,890
community really kind of sees the same

00:20:27,160 --> 00:20:32,400
need and starts working on those

00:20:29,890 --> 00:20:32,400
problems as well

00:20:34,850 --> 00:20:41,220
great presentation by do I thank you

00:20:37,549 --> 00:20:44,809
I've seen other places especially the

00:20:41,220 --> 00:20:47,700
more inexperienced development teams

00:20:44,809 --> 00:20:51,960
first basically the blame is on the

00:20:47,700 --> 00:20:55,980
platform it's on the platform team to

00:20:51,960 --> 00:20:58,110
prove them wrong and that works kind of

00:20:55,980 --> 00:21:00,630
okay in smaller environments I don't

00:20:58,110 --> 00:21:02,190
assume let's kill you guys running yeah

00:21:00,630 --> 00:21:03,350
that doesn't work anymore so how do you

00:21:02,190 --> 00:21:05,039
have that kind of communication

00:21:03,350 --> 00:21:07,919
especially when things are not perfect

00:21:05,039 --> 00:21:11,399
between the plot the product you guys

00:21:07,919 --> 00:21:12,929
provide on I wish I could say Timur was

00:21:11,399 --> 00:21:15,870
unique and that never happens to us but

00:21:12,929 --> 00:21:17,100
we are just like everyone else you speed

00:21:15,870 --> 00:21:18,929
blowing the network team now you blame

00:21:17,100 --> 00:21:21,299
the VMware team then it became the

00:21:18,929 --> 00:21:24,179
platform team instead so to a large

00:21:21,299 --> 00:21:26,190
extent we try to communicate status of

00:21:24,179 --> 00:21:27,809
our platforms as best as we can we run

00:21:26,190 --> 00:21:29,370
synthetic transactions smoke tests

00:21:27,809 --> 00:21:31,440
against our services and against the

00:21:29,370 --> 00:21:33,149
foundations themselves so when somebody

00:21:31,440 --> 00:21:35,399
says app pushes aren't working please

00:21:33,149 --> 00:21:37,740
fix it we can say well your app push

00:21:35,399 --> 00:21:39,899
isn't working our app pushes our what's

00:21:37,740 --> 00:21:41,309
different between these things and for

00:21:39,899 --> 00:21:44,250
the most part we've gotten our customers

00:21:41,309 --> 00:21:45,720
to understand that if there's a platform

00:21:44,250 --> 00:21:47,460
problem we'll probably know about it

00:21:45,720 --> 00:21:48,960
before they do and we'll be you know

00:21:47,460 --> 00:21:51,090
raising flags and letting everyone know

00:21:48,960 --> 00:21:52,860
as we bring the alarms if they're seeing

00:21:51,090 --> 00:21:53,340
an issue it's more than likely on their

00:21:52,860 --> 00:21:55,740
side

00:21:53,340 --> 00:21:57,419
we'll help where we can but our job is

00:21:55,740 --> 00:21:59,549
not to debug their application

00:21:57,419 --> 00:22:02,159
so we'll you know investigate things to

00:21:59,549 --> 00:22:05,130
a certain extent but we're a small team

00:22:02,159 --> 00:22:07,230
we can stay a small team by not fixing

00:22:05,130 --> 00:22:08,429
every customer problem so as best as we

00:22:07,230 --> 00:22:10,049
can we'll help customers that they're

00:22:08,429 --> 00:22:11,340
not willing to help themselves then

00:22:10,049 --> 00:22:12,720
we'll have a communication with their

00:22:11,340 --> 00:22:14,580
management saying you know we've seen

00:22:12,720 --> 00:22:15,990
four times in the last two weeks that

00:22:14,580 --> 00:22:17,100
your team hasn't done basic

00:22:15,990 --> 00:22:18,539
troubleshooting like looking at their

00:22:17,100 --> 00:22:20,760
own app logs or trying to investigate

00:22:18,539 --> 00:22:22,830
their own problems and we level set with

00:22:20,760 --> 00:22:24,000
them and say you know this is not the

00:22:22,830 --> 00:22:26,220
kind of environment where you can depend

00:22:24,000 --> 00:22:27,870
entirely on us to fix your stuff we're a

00:22:26,220 --> 00:22:29,820
shared partnership and we want to help

00:22:27,870 --> 00:22:31,850
you but you have to help yourselves as

00:22:29,820 --> 00:22:31,850
well

00:22:32,679 --> 00:22:37,029
as great as possible and I feel like

00:22:33,789 --> 00:22:38,889
we've earned the trust of our user base

00:22:37,029 --> 00:22:41,470
and that helps a lot right so we go out

00:22:38,889 --> 00:22:42,549
of our way to make sure that that we if

00:22:41,470 --> 00:22:43,899
there's a platform problem we're

00:22:42,549 --> 00:22:45,610
completely transparent about it and when

00:22:43,899 --> 00:22:48,249
there's not and when users have issues

00:22:45,610 --> 00:22:51,549
we share those issues and try to keep a

00:22:48,249 --> 00:22:54,039
flame free environment and just look

00:22:51,549 --> 00:22:55,779
forward that way right so it's it's also

00:22:54,039 --> 00:22:57,129
great leadership support right the

00:22:55,779 --> 00:23:00,190
lovely the leaders believe in the

00:22:57,129 --> 00:23:01,629
platform and trust that we're trying to

00:23:00,190 --> 00:23:03,669
do the right things and when we when we

00:23:01,629 --> 00:23:05,289
communicate up this was a platform issue

00:23:03,669 --> 00:23:09,149
right we have a lot of a lot of

00:23:05,289 --> 00:23:09,149
credibility with them awesome thinking

00:23:11,730 --> 00:23:26,639
hey guys great talk thank you have a

00:23:14,429 --> 00:23:29,490
question yeah yeah we do not have to

00:23:26,639 --> 00:23:31,350
manager on infrastructure we we had the

00:23:29,490 --> 00:23:33,570
infrastructure dedicated to us we work

00:23:31,350 --> 00:23:36,120
with our VMware team to architech what

00:23:33,570 --> 00:23:38,130
that looks like from a computer and from

00:23:36,120 --> 00:23:40,440
a storage perspective and then they

00:23:38,130 --> 00:23:43,230
deploy vSphere for us dedicated to our

00:23:40,440 --> 00:23:45,690
team but everything above the Aya's

00:23:43,230 --> 00:23:47,639
layer is our concern everything vSphere

00:23:45,690 --> 00:23:49,110
and below is their concern and so we say

00:23:47,639 --> 00:23:50,789
we want to be able provision of VM and

00:23:49,110 --> 00:23:52,500
no it will be done and not have to worry

00:23:50,789 --> 00:23:53,700
about any of the underlying stuff and

00:23:52,500 --> 00:23:55,169
that makes it much easier

00:23:53,700 --> 00:23:57,179
however we occasionally will find

00:23:55,169 --> 00:23:58,350
problems that the infrastructure of

00:23:57,179 --> 00:24:00,510
Eastfield level that we can say hey can

00:23:58,350 --> 00:24:01,529
you take a look at this it doesn't look

00:24:00,510 --> 00:24:04,950
quite right and they'll give us feedback

00:24:01,529 --> 00:24:07,139
on if that is true or not in terms of

00:24:04,950 --> 00:24:09,419
the size of our ops team we have both a

00:24:07,139 --> 00:24:12,000
PKS team like a core PKS team as well as

00:24:09,419 --> 00:24:15,029
a core pass team and they're both around

00:24:12,000 --> 00:24:16,590
six or seven people and they have a

00:24:15,029 --> 00:24:18,899
shared team around four or five people

00:24:16,590 --> 00:24:20,580
that is designed to deal with logging

00:24:18,899 --> 00:24:24,269
and monitoring across both of those

00:24:20,580 --> 00:24:26,039
platforms so and with a customer team

00:24:24,269 --> 00:24:28,169
that's for I think four or five people

00:24:26,039 --> 00:24:29,490
or so that really is when a customer

00:24:28,169 --> 00:24:30,899
says I'm having issues I can't get this

00:24:29,490 --> 00:24:32,850
to work or hey I new to your platform

00:24:30,899 --> 00:24:34,710
how do I make this work they sit with

00:24:32,850 --> 00:24:36,750
them they explain them explain things to

00:24:34,710 --> 00:24:38,789
them they will do training or onboarding

00:24:36,750 --> 00:24:40,620
if needed and they're the ones that make

00:24:38,789 --> 00:24:42,240
sure that they're successful and that if

00:24:40,620 --> 00:24:44,220
they're going to have issues we know

00:24:42,240 --> 00:24:45,330
about those long before they've grumbled

00:24:44,220 --> 00:24:46,980
to their management and said this stuff

00:24:45,330 --> 00:24:53,490
doesn't work at all I don't want to use

00:24:46,980 --> 00:24:55,470
it yeah but probably 20 tech people then

00:24:53,490 --> 00:24:57,980
you know three managers a senior manager

00:24:55,470 --> 00:24:57,980
a product owner

00:25:01,869 --> 00:25:23,869
yes that's yeah kubernetes at PKS also

00:25:05,149 --> 00:25:26,899
running on Bosh yes yeah I'd say of the

00:25:23,869 --> 00:25:29,690
4.5 billion per day probably 95% of

00:25:26,899 --> 00:25:31,100
those are not necessary logs we work as

00:25:29,690 --> 00:25:33,350
best as we can with our teams to cut

00:25:31,100 --> 00:25:36,019
those numbers down but for example we'll

00:25:33,350 --> 00:25:37,519
see teams that don't escape line breaks

00:25:36,019 --> 00:25:39,499
in a JSON body they all gout

00:25:37,519 --> 00:25:41,149
so in Splunk we'll see you know all the

00:25:39,499 --> 00:25:43,940
log metadata with just a single curly

00:25:41,149 --> 00:25:46,090
brace or maybe just a blank line we had

00:25:43,940 --> 00:25:48,710
a team recently where we found they were

00:25:46,090 --> 00:25:50,659
escaping with the backslash almost every

00:25:48,710 --> 00:25:52,429
single quote in a JSON body which was

00:25:50,659 --> 00:25:53,869
over a thousand of them per message they

00:25:52,429 --> 00:25:56,600
put out so thousand bytes just for back

00:25:53,869 --> 00:25:57,710
slashes and a message they put out we

00:25:56,600 --> 00:25:59,480
have teams that do transaction

00:25:57,710 --> 00:26:00,889
reconciliation where they say I need to

00:25:59,480 --> 00:26:02,929
be able to find every transaction in

00:26:00,889 --> 00:26:05,509
Splunk that I have done and we say

00:26:02,929 --> 00:26:06,919
you're losing you know 5 or 10% of those

00:26:05,509 --> 00:26:08,359
so it's not accurate and they say well

00:26:06,919 --> 00:26:10,730
we still have to do what the business

00:26:08,359 --> 00:26:12,080
tells us to we also have teams that have

00:26:10,730 --> 00:26:13,879
debug or trace logging turned on in

00:26:12,080 --> 00:26:16,549
production and we find those and tell

00:26:13,879 --> 00:26:18,649
them not to as much as we can we try to

00:26:16,549 --> 00:26:20,629
identify these things we have reports in

00:26:18,649 --> 00:26:22,369
Splunk now that kind of show our top

00:26:20,629 --> 00:26:24,950
producers and we're gonna use that as a

00:26:22,369 --> 00:26:26,539
wall of shame to say you know here's

00:26:24,950 --> 00:26:27,950
who's logging if you're sending out 3 2

00:26:26,539 --> 00:26:30,409
million logs in 15 minutes

00:26:27,950 --> 00:26:31,669
it probably is not that useful we have

00:26:30,409 --> 00:26:34,399
some guys here that might be on that

00:26:31,669 --> 00:26:35,840
wall at some point so but we'll see what

00:26:34,399 --> 00:26:39,049
happens and see if it works or not it's

00:26:35,840 --> 00:26:40,279
worked well for overall usage and memory

00:26:39,049 --> 00:26:41,509
consumption for the platform so

00:26:40,279 --> 00:26:43,519
hopefully it does similar for logging

00:26:41,509 --> 00:26:45,049
but we do know that's a bit more of a

00:26:43,519 --> 00:26:47,119
change to the application potentially if

00:26:45,049 --> 00:26:48,230
they're you know having to change the

00:26:47,119 --> 00:26:52,549
way the application is logging at a

00:26:48,230 --> 00:26:53,600
fundamental level we've got a few

00:26:52,549 --> 00:26:56,239
minutes left want to make sure I plug

00:26:53,600 --> 00:26:58,549
the KS engineering talk we have 4:35

00:26:56,239 --> 00:27:00,379
p.m. we've got some cool stuff cooking

00:26:58,549 --> 00:27:01,759
up their hour-long demo session you'll

00:27:00,379 --> 00:27:04,399
be able to see all about how it works

00:27:01,759 --> 00:27:06,230
the expansions are made forecast toolkit

00:27:04,399 --> 00:27:09,220
and turbulence that we're able to do

00:27:06,230 --> 00:27:12,039
some pretty cool stuff in the past level

00:27:09,220 --> 00:27:14,229
any other final questions

00:27:12,039 --> 00:27:15,999
quickly are you all leveraging selective

00:27:14,229 --> 00:27:17,859
deploys in ops manager and so have you

00:27:15,999 --> 00:27:20,710
built any automation around that we are

00:27:17,859 --> 00:27:22,149
not yet we just got the PCF 2.3 we have

00:27:20,710 --> 00:27:24,249
been on 2.0 and majority of our

00:27:22,149 --> 00:27:27,759
foundations so we're kind of blitzing

00:27:24,249 --> 00:27:29,200
through from - dota 2 dot 3.8 so going

00:27:27,759 --> 00:27:30,369
forward we do plan on using those

00:27:29,200 --> 00:27:32,889
heavily because that is a big thing that

00:27:30,369 --> 00:27:35,619
makes our deploys go so much more slowly

00:27:32,889 --> 00:27:37,450
that 45 minutes of doing nothing we

00:27:35,619 --> 00:27:39,909
could skip that entirely and just move

00:27:37,450 --> 00:27:44,739
straight to the stuff we care about yeah

00:27:39,909 --> 00:27:59,200
one more question up here sure she wants

00:27:44,739 --> 00:28:00,700
down the recording probably yeah there's

00:27:59,200 --> 00:28:02,590
definitely some features we don't want

00:28:00,700 --> 00:28:04,869
people to use example this would be

00:28:02,590 --> 00:28:06,309
volume services where we think that you

00:28:04,869 --> 00:28:07,899
know proliferation of NFS mounts is

00:28:06,309 --> 00:28:10,029
going to be bad for us to manage overall

00:28:07,899 --> 00:28:11,889
so we look at features like that and

00:28:10,029 --> 00:28:13,690
don't advertise those features for any

00:28:11,889 --> 00:28:15,249
new given major or minor past version

00:28:13,690 --> 00:28:16,840
we'll look at the features that are

00:28:15,249 --> 00:28:18,580
listed there see what we think is the

00:28:16,840 --> 00:28:20,139
most useful to our customers or the

00:28:18,580 --> 00:28:22,059
biggest pain points people have had and

00:28:20,139 --> 00:28:24,519
we'll communicate that to our channel in

00:28:22,059 --> 00:28:25,869
slack you know maybe six weeks before we

00:28:24,519 --> 00:28:27,190
ever do upgrades and say we have these

00:28:25,869 --> 00:28:29,019
planned here's the new stuff it brings

00:28:27,190 --> 00:28:30,759
you here's the new features you'll be

00:28:29,019 --> 00:28:31,960
able to get and then as soon as you have

00:28:30,759 --> 00:28:34,269
a foundation and ready that can take

00:28:31,960 --> 00:28:35,919
customers will say hey we've upgraded to

00:28:34,269 --> 00:28:37,179
this version over here you can start

00:28:35,919 --> 00:28:38,559
playing around with stuff again here's

00:28:37,179 --> 00:28:40,690
the key features we think that'll be

00:28:38,559 --> 00:28:44,139
interesting to you and can start telling

00:28:40,690 --> 00:28:45,820
people about those for the most part we

00:28:44,139 --> 00:28:47,649
are pretty selective with the things

00:28:45,820 --> 00:28:49,389
that we enable like container container

00:28:47,649 --> 00:28:50,200
networking we just recently enabled that

00:28:49,389 --> 00:28:52,179
even though we've had it for a few

00:28:50,200 --> 00:28:53,859
versions just making sure we're gonna be

00:28:52,179 --> 00:28:55,029
able to tolerate that well that it's not

00:28:53,859 --> 00:28:57,460
going to impact our cloud control

00:28:55,029 --> 00:28:58,899
database for example that we have the

00:28:57,460 --> 00:29:00,369
right overlay network set up so it's not

00:28:58,899 --> 00:29:02,049
going to you know we're not going to run

00:29:00,369 --> 00:29:05,710
out of virtual IP addresses on there

00:29:02,049 --> 00:29:07,989
which we did previously so yeah a bit of

00:29:05,710 --> 00:29:09,759
a slow rollout overall but we try to

00:29:07,989 --> 00:29:12,909
make sure that we release things that we

00:29:09,759 --> 00:29:14,710
want to release and if customers are

00:29:12,909 --> 00:29:16,299
asking for things we're not going to

00:29:14,710 --> 00:29:17,440
release we're pretty emphatic that this

00:29:16,299 --> 00:29:19,690
is not something we're going to support

00:29:17,440 --> 00:29:22,239
it will never be turned on until we see

00:29:19,690 --> 00:29:24,960
some changes made to it so you know

00:29:22,239 --> 00:29:24,960
please stop asking

00:29:28,100 --> 00:29:35,880
last question sure can you talk more

00:29:33,450 --> 00:29:39,720
about your process for deploying

00:29:35,880 --> 00:29:41,190
upgrades out to the platform itself not

00:29:39,720 --> 00:29:44,010
necessarily on the communication side

00:29:41,190 --> 00:29:45,480
but like do you so test and you

00:29:44,010 --> 00:29:52,910
mentioned like 70% of the traffic and

00:29:45,480 --> 00:29:52,910
one foundation so that one comes last

00:29:54,500 --> 00:29:59,190
appointment as well what kind of leaks

00:29:56,400 --> 00:30:01,620
start in one region just like follow

00:29:59,190 --> 00:30:03,030
this on over half a day and right did

00:30:01,620 --> 00:30:06,120
somebody from the first region screams

00:30:03,030 --> 00:30:07,650
already enough yeah so we have a number

00:30:06,120 --> 00:30:09,750
of staging foundations pretty much one

00:30:07,650 --> 00:30:11,100
in every borough region that we have so

00:30:09,750 --> 00:30:12,870
we'll usually deploy their first leave

00:30:11,100 --> 00:30:14,580
it running for usually a few weeks or so

00:30:12,870 --> 00:30:15,900
we play around with stuff leave our

00:30:14,580 --> 00:30:17,610
smoke tests running it just kind of sits

00:30:15,900 --> 00:30:19,740
around this is usually for minor minor

00:30:17,610 --> 00:30:22,290
versions not for patch patch versions

00:30:19,740 --> 00:30:24,930
were a lot quicker about potentially oh

00:30:22,290 --> 00:30:27,690
yeah it's not always that long sometimes

00:30:24,930 --> 00:30:29,640
it'll be days what's that oh no a

00:30:27,690 --> 00:30:30,990
critical CBE that's generally gonna be a

00:30:29,640 --> 00:30:32,730
patch release anyway so we can push that

00:30:30,990 --> 00:30:33,900
out pretty quickly a stem cell update

00:30:32,730 --> 00:30:35,630
we're not gonna let it soak for weeks it

00:30:33,900 --> 00:30:42,030
might be one or two days at the most

00:30:35,630 --> 00:30:44,700
depending on severity of a CVD no

00:30:42,030 --> 00:30:45,660
they're not yeah it's exactly internal

00:30:44,700 --> 00:30:47,100
stage and it's just for us before

00:30:45,660 --> 00:30:50,340
anything we push the production goes

00:30:47,100 --> 00:30:51,870
through staging first once we get once

00:30:50,340 --> 00:30:53,160
we think things look pretty okay there

00:30:51,870 --> 00:30:55,020
we'll push it out to the non production

00:30:53,160 --> 00:30:57,180
foundations which is all the ones that

00:30:55,020 --> 00:31:02,670
are the users are using for their own

00:30:57,180 --> 00:31:04,170
non production we normally will normally

00:31:02,670 --> 00:31:05,340
do one or two non production foundations

00:31:04,170 --> 00:31:07,530
at a time and then we'll roll through

00:31:05,340 --> 00:31:08,910
after those are totally done we'll start

00:31:07,530 --> 00:31:11,160
the production foundations after those

00:31:08,910 --> 00:31:12,990
non production are complete and we'll do

00:31:11,160 --> 00:31:15,420
you know depending on regions we might

00:31:12,990 --> 00:31:17,250
do one of the two foundations in a given

00:31:15,420 --> 00:31:19,740
region at the same time across several

00:31:17,250 --> 00:31:21,240
regions just to get things moving more

00:31:19,740 --> 00:31:23,040
quickly because if it would them all you

00:31:21,240 --> 00:31:26,340
know in serial would take a very long

00:31:23,040 --> 00:31:27,750
time so we're still working on improving

00:31:26,340 --> 00:31:29,370
that right now it still takes way too

00:31:27,750 --> 00:31:31,530
long to push these changes out and so

00:31:29,370 --> 00:31:32,910
figuring out which level of changes we

00:31:31,530 --> 00:31:34,620
can push at the same time which

00:31:32,910 --> 00:31:36,780
foundations are the most critical and

00:31:34,620 --> 00:31:38,419
really you know we think like that one

00:31:36,780 --> 00:31:39,980
with 70% of our traffic

00:31:38,419 --> 00:31:41,419
we're actually decided we're going to

00:31:39,980 --> 00:31:42,679
end of life that foundation and say it's

00:31:41,419 --> 00:31:44,870
going away quarter three of this year

00:31:42,679 --> 00:31:45,950
here's your new foundations please move

00:31:44,870 --> 00:31:47,090
to those because we're not going to

00:31:45,950 --> 00:31:49,639
support this one after this period of

00:31:47,090 --> 00:31:51,139
time it's just it's not safe anymore for

00:31:49,639 --> 00:31:53,269
us to upgrade that we had some non

00:31:51,139 --> 00:32:18,529
production upgrades with that the one

00:31:53,269 --> 00:32:20,059
largest foundation we saw no impact like

00:32:18,529 --> 00:32:21,590
our current upgrade process it's kind of

00:32:20,059 --> 00:32:23,809
all hands on deck and somebody's

00:32:21,590 --> 00:32:28,129
somebody's pretty much up 24 by 7 want

00:32:23,809 --> 00:32:30,230
some slack and watch you know it's

00:32:28,129 --> 00:32:32,149
pretty right now just cuz we're moving

00:32:30,230 --> 00:32:34,279
from we're trying to move as we can to

00:32:32,149 --> 00:32:39,200
get caught up to n minus one and then

00:32:34,279 --> 00:32:40,669
our lives should get a lot better yeah

00:32:39,200 --> 00:32:42,230
and as we move to more more smaller

00:32:40,669 --> 00:32:44,210
foundations the impact of any one of

00:32:42,230 --> 00:32:45,769
those going down as much less so we can

00:32:44,210 --> 00:32:48,710
be more tolerant of risk in a given

00:32:45,769 --> 00:32:49,450
foundation thank you all please shave

00:32:48,710 --> 00:32:50,820
your time

00:32:49,450 --> 00:32:54,490
[Applause]

00:32:50,820 --> 00:32:54,490

YouTube URL: https://www.youtube.com/watch?v=XwYRg-HkfVA


