Title: #testedAF: Test All the Things (Not Just Your Units) - Bryon Kroger & Quynh Tran
Publication date: 2019-04-11
Playlist: Cloud Foundry Summit NA 2019 - Philadelphia
Description: 
	#testedAF: Test All the Things (Not Just Your Units) - Bryon Kroger, United States Air Force & Quynh Tran, Raytheon

The United States Air Force’s Kessel Run has made headlines for the incredible fuel savings from the tanker planner application and for taking their deployment frequency from 5 years to 1 week. What often goes unstated is that they are also building applications where failure carries life and death consequences and, as such, the larger organization they are part of takes testing very seriously. Not only that, they spend even more time on upfront planning than is seen in even the worst offending commercial enterprises. And talking to real end users? Forget about it, they have an active mission to support! Breaking through those barriers took a lot more than just a robust suite of unit tests.

Pivotal Cloud Foundry is key in that it provided the Air Force the platform they needed to ignore all the things below the value line and focus on expanding their testing practice to meet the demands of their enterprise: testing assumptions around building the right thing, building the thing right, and was the right thing built. Find out how Kessel Run established the means to go fast forever, continuously delivering business value their users LOVE by testing all the things!

About Bryon Kroger
Air Force Captain Bryon Kroger is Founder and COO at Kessel Run, where he leads operations for an enterprise-scale software lab running a worldwide cloud platform and 22 customer-facing products. Bryon scaled operations from $25M to $190M annually and reduced average new product initial launch from 8.2 years to 124 days, lead time from 2.5 years to 92 hours, and deployment frequency from bi-annually to weekly.

About Quynh Tran
Quynh is a Raytheon Software Engineer and 
Kessel Run’s Engineering Practice Lead where 
she is responsible for creating a continuous learning environment for 50-100+ engineers and growing a community of software engineering practice. She is currently in the Raytheon Leadership Development Program, class of 2019. She has been featured on Raytheon’s internal and external website for being a change agent in empowering professional women in STEM careers and leading adoption of DevOps methodologies and technologies within Raytheon.

https://www.cloudfoundry.org/
Captions: 
	00:00:00,030 --> 00:00:03,659
all right everybody my name is Quinn

00:00:01,650 --> 00:00:05,700
Tran I am a Raytheon software engineer

00:00:03,659 --> 00:00:08,519
and I'm also like a someone's engineer

00:00:05,700 --> 00:00:11,519
practically and I'm Brian founder and

00:00:08,519 --> 00:00:12,990
CEO of Kessel run by the way if you have

00:00:11,519 --> 00:00:15,330
nice things to tweet about this talk

00:00:12,990 --> 00:00:17,789
it's at BJ Kroger if you have unkind of

00:00:15,330 --> 00:00:19,830
things to tweet it's at US Army Kessel

00:00:17,789 --> 00:00:21,210
run is a disruptive government program

00:00:19,830 --> 00:00:23,369
that is transforming the way that the

00:00:21,210 --> 00:00:25,590
Air Force builds and deliver software we

00:00:23,369 --> 00:00:27,480
started with a single legacy system and

00:00:25,590 --> 00:00:29,279
now our portfolio has grown

00:00:27,480 --> 00:00:31,679
substantially as we demonstrated results

00:00:29,279 --> 00:00:34,710
like reducing initial product launch to

00:00:31,679 --> 00:00:36,239
120 days on average with average weekly

00:00:34,710 --> 00:00:38,760
deployment frequency on every team

00:00:36,239 --> 00:00:40,590
thereafter so getting there was quite a

00:00:38,760 --> 00:00:42,300
journey and a very important part of

00:00:40,590 --> 00:00:43,559
that journey is testing so today we're

00:00:42,300 --> 00:00:46,980
going to talk about how to test all of

00:00:43,559 --> 00:00:48,930
the things not just your units and as we

00:00:46,980 --> 00:00:50,129
reflect on all of the practices and

00:00:48,930 --> 00:00:52,770
lessons that we've learned along the way

00:00:50,129 --> 00:00:55,440
a central theme out of our successes is

00:00:52,770 --> 00:00:56,940
test now this won't be a technical deep

00:00:55,440 --> 00:00:58,590
dive into advanced testing

00:00:56,940 --> 00:01:00,890
implementations those aren't actually

00:00:58,590 --> 00:01:03,989
what broke us through the QA barriers

00:01:00,890 --> 00:01:05,220
they were important but what is equally

00:01:03,989 --> 00:01:07,740
important is actually the conversation

00:01:05,220 --> 00:01:09,000
shift and that's what got us through so

00:01:07,740 --> 00:01:10,650
the purpose of this talk is to change

00:01:09,000 --> 00:01:12,900
how we think about and communicate about

00:01:10,650 --> 00:01:15,090
testing in relation to all the things

00:01:12,900 --> 00:01:16,409
that you're hopefully already doing and

00:01:15,090 --> 00:01:18,509
this will help you better align with

00:01:16,409 --> 00:01:21,030
stakeholders as they might be resisting

00:01:18,509 --> 00:01:22,799
the idea of continuous delivery so as I

00:01:21,030 --> 00:01:24,270
mentioned testing is everywhere in every

00:01:22,799 --> 00:01:27,000
aspect of our practice whether you're a

00:01:24,270 --> 00:01:28,350
PM designer engineer and so any moment

00:01:27,000 --> 00:01:30,990
we're thinking about creating a product

00:01:28,350 --> 00:01:32,250
or writing user stories - implementing

00:01:30,990 --> 00:01:33,990
the story - pushing through production

00:01:32,250 --> 00:01:36,270
we're always need to have that mindset

00:01:33,990 --> 00:01:37,619
of testing and so as we're children I

00:01:36,270 --> 00:01:39,900
take you to the journey from pre build

00:01:37,619 --> 00:01:41,189
to post build we're also going to share

00:01:39,900 --> 00:01:42,600
you some of the meta concepts things

00:01:41,189 --> 00:01:45,360
that we're thinking about moving to the

00:01:42,600 --> 00:01:47,399
next step so anytime you're engaging

00:01:45,360 --> 00:01:49,409
stakeholders it's a really great idea to

00:01:47,399 --> 00:01:51,210
start with a set of mutual agreements

00:01:49,409 --> 00:01:53,579
and here's some that I recommend for the

00:01:51,210 --> 00:01:55,079
test conversation first our priority is

00:01:53,579 --> 00:01:56,790
to satisfy the user with early and

00:01:55,079 --> 00:01:59,969
continuous delivery of value test

00:01:56,790 --> 00:02:01,530
doesn't exist for tests sake it exists

00:01:59,969 --> 00:02:04,409
to enable an outcome in a safe and

00:02:01,530 --> 00:02:06,240
sustainable way and so as we think about

00:02:04,409 --> 00:02:07,940
how we could improve these outcomes we

00:02:06,240 --> 00:02:11,160
have to compare outcomes to outcomes

00:02:07,940 --> 00:02:12,930
talking about people's intent especially

00:02:11,160 --> 00:02:13,990
you know if it's maligned or unrealized

00:02:12,930 --> 00:02:16,360
intent

00:02:13,990 --> 00:02:18,070
those things are off the table it's also

00:02:16,360 --> 00:02:20,980
important that we realize security

00:02:18,070 --> 00:02:22,720
quality and risk are all relative so

00:02:20,980 --> 00:02:24,520
there's no such thing as quality assured

00:02:22,720 --> 00:02:26,980
only quality improved our quality

00:02:24,520 --> 00:02:28,260
decreased and finally it's important to

00:02:26,980 --> 00:02:30,700
remember that quality and performance

00:02:28,260 --> 00:02:33,370
aren't the only risks to operations

00:02:30,700 --> 00:02:35,550
delay is its own operational risk and we

00:02:33,370 --> 00:02:38,380
need to balance it against the other two

00:02:35,550 --> 00:02:40,480
stated another way speed reduces risk

00:02:38,380 --> 00:02:42,730
you need to be able to dodge 21 punches

00:02:40,480 --> 00:02:44,350
in 10 seconds if you saw Abby's keynote

00:02:42,730 --> 00:02:45,790
yesterday she said it's time to drop the

00:02:44,350 --> 00:02:48,730
butterfly analogy because digital

00:02:45,790 --> 00:02:51,460
transformation isn't magic she said it

00:02:48,730 --> 00:02:53,260
takes mastery and I love that Muhammad

00:02:51,460 --> 00:02:55,210
Ali was also a master of his craft

00:02:53,260 --> 00:02:56,560
I love the Rapids analogy I really do

00:02:55,210 --> 00:02:57,850
but my experience with digital

00:02:56,560 --> 00:03:00,130
transformation has looked a lot more

00:02:57,850 --> 00:03:01,450
like a 12 round boxing match maybe that

00:03:00,130 --> 00:03:03,760
means I'm doing it wrong I'm not sure

00:03:01,450 --> 00:03:05,830
but regardless I'm not ready to throw

00:03:03,760 --> 00:03:07,360
out the butterflies just yet I'd rather

00:03:05,830 --> 00:03:09,580
take that analogy and apply it to the

00:03:07,360 --> 00:03:12,280
boxing ring as Muhammad Ali Lisa DevOps

00:03:09,580 --> 00:03:14,920
like a butterfly test like a beat how's

00:03:12,280 --> 00:03:17,680
that for a punch line yeah that is so

00:03:14,920 --> 00:03:19,720
bad anyways it's easy to imagine that

00:03:17,680 --> 00:03:21,220
your opponent in the ring is actually

00:03:19,720 --> 00:03:22,900
the other right the other guy the other

00:03:21,220 --> 00:03:24,850
gal the ones that don't get it the ones

00:03:22,900 --> 00:03:26,050
that resist your change the ones that

00:03:24,850 --> 00:03:28,270
you have to navigate to get anything

00:03:26,050 --> 00:03:30,040
done in reality your opponent in the

00:03:28,270 --> 00:03:32,140
ring is actually your own collection of

00:03:30,040 --> 00:03:34,270
assumptions they hit you where it hurts

00:03:32,140 --> 00:03:36,340
when you least expect it they're the

00:03:34,270 --> 00:03:38,080
things that you have to destroy it's not

00:03:36,340 --> 00:03:40,960
enough to just turn your caterpillar IT

00:03:38,080 --> 00:03:43,209
shop into a magical butterfly you really

00:03:40,960 --> 00:03:44,590
need to focus in sooner or later you

00:03:43,209 --> 00:03:46,930
have to knock out your assumptions if

00:03:44,590 --> 00:03:48,700
you want to win the market that means to

00:03:46,930 --> 00:03:50,110
us that you have to be tested AF and

00:03:48,700 --> 00:03:52,600
that's why we want to test all the

00:03:50,110 --> 00:03:55,330
things especially our assumptions all

00:03:52,600 --> 00:03:58,180
the time and so when we mean all the

00:03:55,330 --> 00:03:59,560
time we mean that we test every time we

00:03:58,180 --> 00:04:01,570
build a new feature every time we

00:03:59,560 --> 00:04:02,920
implement something and push it into

00:04:01,570 --> 00:04:05,590
production so we always want to make

00:04:02,920 --> 00:04:06,970
sure we're always testing daily as often

00:04:05,590 --> 00:04:09,070
as we can running our test Suites for

00:04:06,970 --> 00:04:10,510
instance and also testing in production

00:04:09,070 --> 00:04:12,430
to get that feedback as often as

00:04:10,510 --> 00:04:13,810
possible so when we say we're testing

00:04:12,430 --> 00:04:15,550
all the time we're never really done

00:04:13,810 --> 00:04:17,290
right as long as we continue to deliver

00:04:15,550 --> 00:04:19,780
our product into production contains

00:04:17,290 --> 00:04:22,419
delivery we're not done we're just gonna

00:04:19,780 --> 00:04:24,070
keep going and so I love the saying when

00:04:22,419 --> 00:04:26,200
we say good engineer's meet the

00:04:24,070 --> 00:04:26,740
requirements great engineers question a

00:04:26,200 --> 00:04:28,180
requirement

00:04:26,740 --> 00:04:30,280
right so as we go back to this theme

00:04:28,180 --> 00:04:32,139
again everybody needs to be thinking

00:04:30,280 --> 00:04:34,090
about how do we test our assumptions and

00:04:32,139 --> 00:04:35,800
so as software requirements are always

00:04:34,090 --> 00:04:37,389
changing we can't afford to wait until

00:04:35,800 --> 00:04:39,190
later to find out that our requirements

00:04:37,389 --> 00:04:42,069
is outdated or it's irrelevant right

00:04:39,190 --> 00:04:43,569
after we build a product and so we want

00:04:42,069 --> 00:04:45,610
to adopt this mindset of testing or

00:04:43,569 --> 00:04:47,800
assumptions often validating and

00:04:45,610 --> 00:04:49,000
learning from these so that right before

00:04:47,800 --> 00:04:51,550
even when we start building these

00:04:49,000 --> 00:04:53,710
products right absolutely there's

00:04:51,550 --> 00:04:55,569
nothing as useless as being really good

00:04:53,710 --> 00:04:57,460
at building the wrong things and the

00:04:55,569 --> 00:04:59,229
requirements that we often get in

00:04:57,460 --> 00:05:00,849
waterfall or for those of you that are

00:04:59,229 --> 00:05:02,919
really advanced at waterfall water scrum

00:05:00,849 --> 00:05:04,780
fall they're really just assumptions

00:05:02,919 --> 00:05:06,039
about value and priority and those are

00:05:04,780 --> 00:05:08,590
the first things that actually need to

00:05:06,039 --> 00:05:09,940
be tested a great contrast of how

00:05:08,590 --> 00:05:12,009
important it is to test your riskiest

00:05:09,940 --> 00:05:14,979
assumptions before you start building is

00:05:12,009 --> 00:05:16,210
Zappos versus web and so in Zappos the

00:05:14,979 --> 00:05:18,280
founder had this great idea to sell

00:05:16,210 --> 00:05:19,539
shoes online riskiest assumption believe

00:05:18,280 --> 00:05:22,419
it or not back then was would people

00:05:19,539 --> 00:05:24,069
actually buy shoes online and so he went

00:05:22,419 --> 00:05:26,380
into a local shoe mart photographed

00:05:24,069 --> 00:05:27,639
shoes put them online customers sold

00:05:26,380 --> 00:05:29,080
them he went back to the shoe store

00:05:27,639 --> 00:05:30,849
bought them put them in the mail and

00:05:29,080 --> 00:05:32,680
sent them to the customer customer never

00:05:30,849 --> 00:05:34,870
knew the difference and he was able to

00:05:32,680 --> 00:05:36,400
evaluate his business model using a kind

00:05:34,870 --> 00:05:38,380
of Wizard of Oz you know don't look

00:05:36,400 --> 00:05:40,780
behind the curtain and ended up with a

00:05:38,380 --> 00:05:43,690
really successful business web then on

00:05:40,780 --> 00:05:45,820
the other hand peak of dot-com madness

00:05:43,690 --> 00:05:48,699
they went out got tons of investments

00:05:45,820 --> 00:05:51,820
they built out a full set of warehouses

00:05:48,699 --> 00:05:53,889
a full fleet of vans they had a full

00:05:51,820 --> 00:05:55,180
product offering just like very robust

00:05:53,889 --> 00:05:57,370
up front without doing a lot of the

00:05:55,180 --> 00:05:59,680
initial validation work and no surprise

00:05:57,370 --> 00:06:02,590
here shortly after launching they went

00:05:59,680 --> 00:06:04,240
bankrupt now people will say there's a

00:06:02,590 --> 00:06:05,770
lot of reasons why they didn't succeed

00:06:04,240 --> 00:06:07,479
but I think you can trace all of them

00:06:05,770 --> 00:06:09,009
back to not validating the riskiest

00:06:07,479 --> 00:06:12,039
assumptions before they started building

00:06:09,009 --> 00:06:13,270
out their product so prior to building

00:06:12,039 --> 00:06:14,849
anything we do a lot of activities like

00:06:13,270 --> 00:06:16,990
a fence storming discovery and framing

00:06:14,849 --> 00:06:18,250
inception just so that we understand our

00:06:16,990 --> 00:06:19,960
problem space and where we're going

00:06:18,250 --> 00:06:21,789
right so that allows us to lay out our

00:06:19,960 --> 00:06:23,199
assumption ahead of time so as we're

00:06:21,789 --> 00:06:25,030
implementing building it and getting

00:06:23,199 --> 00:06:26,530
these feedbacks we validate whether

00:06:25,030 --> 00:06:28,719
these assumptions are true or not and

00:06:26,530 --> 00:06:30,219
then so in any of these roles right we

00:06:28,719 --> 00:06:30,819
need to have that test mindset that we

00:06:30,219 --> 00:06:33,190
mentioned earlier

00:06:30,819 --> 00:06:34,419
and so like 4:00 p.m. right there always

00:06:33,190 --> 00:06:35,800
have to be thinking about what's the

00:06:34,419 --> 00:06:38,790
next valuable thing that we're building

00:06:35,800 --> 00:06:40,530
so that it meets the business needs

00:06:38,790 --> 00:06:42,120
and then so for the product designs

00:06:40,530 --> 00:06:43,890
right we're always thinking about how do

00:06:42,120 --> 00:06:45,870
we what is the next level thing that

00:06:43,890 --> 00:06:47,670
we're building for our user are we

00:06:45,870 --> 00:06:49,980
possibly is this feature that we're

00:06:47,670 --> 00:06:51,450
building help change the users behavior

00:06:49,980 --> 00:06:53,220
in a right way that we're looking for

00:06:51,450 --> 00:06:54,930
and then finally for the engineers we're

00:06:53,220 --> 00:06:56,520
thinking is this feasible right as we're

00:06:54,930 --> 00:06:57,180
implementing these stories does this

00:06:56,520 --> 00:06:58,800
make sense

00:06:57,180 --> 00:07:03,690
can we actually accomplish this and can

00:06:58,800 --> 00:07:06,390
we actually ship it to production and so

00:07:03,690 --> 00:07:07,830
when it comes to building these products

00:07:06,390 --> 00:07:09,600
there's always going to be risk and we

00:07:07,830 --> 00:07:11,130
think about how do we build by down risk

00:07:09,600 --> 00:07:13,770
how do we address these risks early on

00:07:11,130 --> 00:07:15,750
and make decisions with all these

00:07:13,770 --> 00:07:18,240
information that we learned so we I

00:07:15,750 --> 00:07:19,290
guess around we practice lean and so

00:07:18,240 --> 00:07:21,510
we're always trying to constantly

00:07:19,290 --> 00:07:23,100
testing our riskiest assumptions seeking

00:07:21,510 --> 00:07:25,530
those feedbacks and constantly learning

00:07:23,100 --> 00:07:27,120
and validating so that way with all the

00:07:25,530 --> 00:07:30,420
learnings we have that helps us decide

00:07:27,120 --> 00:07:32,160
whether we should pivot or persevere and

00:07:30,420 --> 00:07:34,230
perhaps more than anyone else on the

00:07:32,160 --> 00:07:36,330
team a good designer has to make the

00:07:34,230 --> 00:07:38,100
riskiest assumptions of all so if you

00:07:36,330 --> 00:07:40,140
want to avoid building faster horses

00:07:38,100 --> 00:07:43,050
right user driven design that Henry Ford

00:07:40,140 --> 00:07:44,790
cautions against and instead synthesized

00:07:43,050 --> 00:07:46,230
pains and deliver solutions that nobody

00:07:44,790 --> 00:07:48,060
could have ever imagined the truly

00:07:46,230 --> 00:07:49,500
innovative solutions you're really gonna

00:07:48,060 --> 00:07:51,180
have to push the boundaries on making

00:07:49,500 --> 00:07:53,340
assumptions about what your users need

00:07:51,180 --> 00:07:55,020
versus what they want so it follows that

00:07:53,340 --> 00:07:56,810
designers as much as anyone on the team

00:07:55,020 --> 00:07:59,730
if not more really need to validate

00:07:56,810 --> 00:08:01,920
their assumptions before coders code it

00:07:59,730 --> 00:08:03,690
and so there's a lot of ways to do this

00:08:01,920 --> 00:08:05,670
you're probably doing a lot of these

00:08:03,690 --> 00:08:07,110
things but you probably aren't taking

00:08:05,670 --> 00:08:09,600
credit for them as tests that reduce

00:08:07,110 --> 00:08:11,250
risk and improve quality so of course we

00:08:09,600 --> 00:08:12,480
don't get final validation until we put

00:08:11,250 --> 00:08:14,310
things in the hands of users in

00:08:12,480 --> 00:08:16,380
production and a real live environment

00:08:14,310 --> 00:08:17,880
but there's a lot of things that we can

00:08:16,380 --> 00:08:20,580
do along the way to buy down our risk

00:08:17,880 --> 00:08:23,430
and so maybe it starts with an interview

00:08:20,580 --> 00:08:26,040
then hand-drawn sketches mock-ups

00:08:23,430 --> 00:08:27,510
wireframes maybe finally ending in a

00:08:26,040 --> 00:08:29,760
clickable prototype like you see in the

00:08:27,510 --> 00:08:32,160
top left that we hosted in envision and

00:08:29,760 --> 00:08:34,380
the user then says wow this isn't what I

00:08:32,160 --> 00:08:35,820
was expecting at all but I love it so

00:08:34,380 --> 00:08:38,550
now it's finally time to start thinking

00:08:35,820 --> 00:08:39,900
about how we might build the thing and

00:08:38,550 --> 00:08:41,430
so in engineering we're also thinking

00:08:39,900 --> 00:08:43,410
about that as well right building things

00:08:41,430 --> 00:08:45,060
are easy because engineers we can do

00:08:43,410 --> 00:08:46,800
anything right but building the thing

00:08:45,060 --> 00:08:48,600
right is hard especially when it comes

00:08:46,800 --> 00:08:50,550
to like designing the architecture it

00:08:48,600 --> 00:08:51,990
takes time and so as a result we should

00:08:50,550 --> 00:08:54,899
also take a lean approach

00:08:51,990 --> 00:08:56,640
how we implement as we like for instance

00:08:54,899 --> 00:08:58,290
as we're growing our architecture we're

00:08:56,640 --> 00:09:00,750
evolving to the way that we want to be

00:08:58,290 --> 00:09:02,399
and so as we're implementing something

00:09:00,750 --> 00:09:04,260
that might be technically challenged we

00:09:02,399 --> 00:09:06,240
also need to give feedback to our PM's

00:09:04,260 --> 00:09:08,700
and designers to show that hey you know

00:09:06,240 --> 00:09:09,959
I know this is exactly what you want but

00:09:08,700 --> 00:09:11,250
there's alternative solutions that we

00:09:09,959 --> 00:09:13,980
can implement to reduce that risk

00:09:11,250 --> 00:09:16,200
technically and then work together to

00:09:13,980 --> 00:09:18,480
achieve that same outcome and so the

00:09:16,200 --> 00:09:20,640
another way the engineers reduce risk is

00:09:18,480 --> 00:09:22,050
doing spikes writing stories where we

00:09:20,640 --> 00:09:24,240
explore certain technologies or

00:09:22,050 --> 00:09:26,580
different practices before we introduce

00:09:24,240 --> 00:09:29,220
them into your codebase and those are

00:09:26,580 --> 00:09:31,110
opportunities that we can learn more pay

00:09:29,220 --> 00:09:34,350
that time to learn about the challenges

00:09:31,110 --> 00:09:35,940
the risk but also in addition we look at

00:09:34,350 --> 00:09:37,800
tech debts right duck does tech debts

00:09:35,940 --> 00:09:39,360
are also risks as well and we always

00:09:37,800 --> 00:09:43,290
want to keep an eye on that and pay them

00:09:39,360 --> 00:09:46,770
off as often as we can and so now we're

00:09:43,290 --> 00:09:49,920
entering to the test build phase at

00:09:46,770 --> 00:09:53,010
castle run we practice XP we do pairing

00:09:49,920 --> 00:09:54,990
we do TDD we also do CI CD as well to

00:09:53,010 --> 00:09:57,000
allow us to go fast so we're pairing

00:09:54,990 --> 00:09:58,529
right it allows us to build a thing

00:09:57,000 --> 00:10:00,120
right meaning as you're pairing with

00:09:58,529 --> 00:10:02,310
another engineer we're always constantly

00:10:00,120 --> 00:10:04,050
making sure we're focusing on completing

00:10:02,310 --> 00:10:07,380
that story and delivering the right

00:10:04,050 --> 00:10:10,230
thing incorporating equality as long as

00:10:07,380 --> 00:10:12,230
as well as sharing context and help

00:10:10,230 --> 00:10:15,329
catch bugs as early as possible in

00:10:12,230 --> 00:10:18,570
addition with TDD right we are building

00:10:15,329 --> 00:10:20,790
high quality into our product so when we

00:10:18,570 --> 00:10:24,000
talk about writing test first we talked

00:10:20,790 --> 00:10:24,390
about like addressing being able to go

00:10:24,000 --> 00:10:26,790
fast

00:10:24,390 --> 00:10:28,350
forever rate being out speed is reducing

00:10:26,790 --> 00:10:30,540
risk so in order for us to go fast

00:10:28,350 --> 00:10:31,740
forever we need clean code and clean

00:10:30,540 --> 00:10:33,600
code is not something that's easy to

00:10:31,740 --> 00:10:35,760
come by right it takes time to invest to

00:10:33,600 --> 00:10:37,649
care for our code in addition to care

00:10:35,760 --> 00:10:39,540
for our tests in order to even do that

00:10:37,649 --> 00:10:40,890
right we're constantly refactoring like

00:10:39,540 --> 00:10:43,350
I mentioned earlier we're evolving our

00:10:40,890 --> 00:10:45,000
architecture we're cleaning up our code

00:10:43,350 --> 00:10:47,310
we are refactoring by making sure we

00:10:45,000 --> 00:10:48,839
don't change our behaviors and so to do

00:10:47,310 --> 00:10:50,640
all that we need confidence and

00:10:48,839 --> 00:10:52,290
confidence comes from having those tests

00:10:50,640 --> 00:10:54,360
and not just any tests

00:10:52,290 --> 00:10:56,670
it's test-driven development taking the

00:10:54,360 --> 00:10:58,920
approach where we care about thinking

00:10:56,670 --> 00:11:00,329
about all the behaviors that we want to

00:10:58,920 --> 00:11:02,640
achieve what success should look like

00:11:00,329 --> 00:11:04,230
before we even implement and when we

00:11:02,640 --> 00:11:04,840
implement we think about what is the

00:11:04,230 --> 00:11:06,970
simplest thing I

00:11:04,840 --> 00:11:08,830
can do to get this test to pass and so

00:11:06,970 --> 00:11:13,510
in that sense we're reducing waste as

00:11:08,830 --> 00:11:16,270
well and now a lot of times rate as

00:11:13,510 --> 00:11:17,950
we're growing our test code base test

00:11:16,270 --> 00:11:19,210
and code base we're growing our test

00:11:17,950 --> 00:11:20,950
strategies and figuring out what it

00:11:19,210 --> 00:11:24,040
should look like and if you flip that

00:11:20,950 --> 00:11:25,900
test pyramid upside down it can be seen

00:11:24,040 --> 00:11:28,090
as a filter so in the bottom right we

00:11:25,900 --> 00:11:29,860
see all these unit tests they're cheap

00:11:28,090 --> 00:11:32,110
they're fast you can think of them as

00:11:29,860 --> 00:11:34,270
like a very coarse grain filter to catch

00:11:32,110 --> 00:11:35,950
all the bugs that can be reproducible

00:11:34,270 --> 00:11:38,710
right and so when you catch those bugs

00:11:35,950 --> 00:11:41,350
you can add another test to help catch

00:11:38,710 --> 00:11:42,670
that bug in the future and as you go

00:11:41,350 --> 00:11:45,160
down the filter right there's

00:11:42,670 --> 00:11:46,150
integration there's end to end tests and

00:11:45,160 --> 00:11:48,160
the end right

00:11:46,150 --> 00:11:49,630
all those the ones that are actually

00:11:48,160 --> 00:11:51,340
made it through the bugs I've made it to

00:11:49,630 --> 00:11:53,830
production or the ones that needs to be

00:11:51,340 --> 00:11:55,120
needs a human to catch that it's not

00:11:53,830 --> 00:11:57,790
something we can automate the test to

00:11:55,120 --> 00:11:59,830
capture it but it's really great if we

00:11:57,790 --> 00:12:02,950
be more intent --fill about like how we

00:11:59,830 --> 00:12:04,360
build this test strategy and so that it

00:12:02,950 --> 00:12:07,240
will do the work for us in capturing

00:12:04,360 --> 00:12:09,130
bugs early on so I mentioned outcomes

00:12:07,240 --> 00:12:10,180
earlier the outcomes of building a

00:12:09,130 --> 00:12:12,310
really efficient funnel are

00:12:10,180 --> 00:12:13,930
extraordinary but it's important to note

00:12:12,310 --> 00:12:15,820
that we shouldn't make villains out of

00:12:13,930 --> 00:12:17,110
the people that exist in the legacy

00:12:15,820 --> 00:12:19,060
system the legacy way of doing business

00:12:17,110 --> 00:12:20,800
what they do today is actually very

00:12:19,060 --> 00:12:23,050
appropriate given the environment that

00:12:20,800 --> 00:12:25,030
they live in and I should also point out

00:12:23,050 --> 00:12:27,640
that in our case they've gone to great

00:12:25,030 --> 00:12:29,800
lengths to make their process more agile

00:12:27,640 --> 00:12:31,000
it used to actually be a one big event

00:12:29,800 --> 00:12:32,890
every couple years and now they're

00:12:31,000 --> 00:12:34,270
testing quarterly and my hats off to

00:12:32,890 --> 00:12:36,130
them for doing that it also is a huge

00:12:34,270 --> 00:12:38,200
boon to us as we look to integrate with

00:12:36,130 --> 00:12:40,750
the legacy system it gives us the

00:12:38,200 --> 00:12:42,340
ability to put changes into their

00:12:40,750 --> 00:12:44,080
backlog as well that we need for

00:12:42,340 --> 00:12:46,090
integration and get them into production

00:12:44,080 --> 00:12:49,120
much more quickly so hats off to them

00:12:46,090 --> 00:12:51,010
but in the legacy system we don't have a

00:12:49,120 --> 00:12:53,110
lot of automated tests there are

00:12:51,010 --> 00:12:55,360
systemic reasons for that most of which

00:12:53,110 --> 00:12:57,550
extend well beyond our program offices

00:12:55,360 --> 00:13:00,520
and the people that test within them but

00:12:57,550 --> 00:13:02,980
the result is that the system for the

00:13:00,520 --> 00:13:04,840
most part has humans as the filter we

00:13:02,980 --> 00:13:06,670
have humans catching regressions which

00:13:04,840 --> 00:13:09,070
is a terribly inefficient use of human

00:13:06,670 --> 00:13:11,620
capital right and fun facts as we

00:13:09,070 --> 00:13:14,350
started since August 2017 we've grown

00:13:11,620 --> 00:13:16,720
from one team to 18 product teams and so

00:13:14,350 --> 00:13:18,580
up until now we've used and run our test

00:13:16,720 --> 00:13:20,350
Suites across 18 teams

00:13:18,580 --> 00:13:22,300
at least thirty three thousand times

00:13:20,350 --> 00:13:24,010
that's that's huge right so an average

00:13:22,300 --> 00:13:26,110
we're committing our code and running

00:13:24,010 --> 00:13:28,420
our test Suites at least twice a day per

00:13:26,110 --> 00:13:30,100
team yeah and so my goal at Kessel run

00:13:28,420 --> 00:13:33,459
was to change that environment that QA

00:13:30,100 --> 00:13:34,720
exists in and we wanted to do that so

00:13:33,459 --> 00:13:36,160
that we can actually change the way we

00:13:34,720 --> 00:13:39,250
test because scaling the thing on the

00:13:36,160 --> 00:13:41,050
left is very costly scaling humans is

00:13:39,250 --> 00:13:43,329
expensive it also comes at a cost of

00:13:41,050 --> 00:13:44,529
quality so humans aren't nearly as

00:13:43,329 --> 00:13:47,019
efficient at catching things like

00:13:44,529 --> 00:13:49,000
regressions also there's an epidural

00:13:47,019 --> 00:13:51,070
delays in the left that present really

00:13:49,000 --> 00:13:53,200
long feedback loops that increase our

00:13:51,070 --> 00:13:55,240
risk and also present high opportunity

00:13:53,200 --> 00:13:57,700
cost when it comes to getting our

00:13:55,240 --> 00:13:59,380
product to the market too late or doing

00:13:57,700 --> 00:14:01,450
so with too many assumptions so as we

00:13:59,380 --> 00:14:03,070
replace the legacy system with the new

00:14:01,450 --> 00:14:05,350
my hopes that we can take those same

00:14:03,070 --> 00:14:07,420
humans and their context and domain

00:14:05,350 --> 00:14:09,880
expertise and use it in new and in

00:14:07,420 --> 00:14:11,560
unique ways for instance exploratory

00:14:09,880 --> 00:14:13,269
testing is still a thing Quinn mentioned

00:14:11,560 --> 00:14:15,970
some things still get through the filter

00:14:13,269 --> 00:14:17,829
and maybe we could debate if you can

00:14:15,970 --> 00:14:19,720
catch them technically or not with

00:14:17,829 --> 00:14:21,730
automation but regardless the cost of

00:14:19,720 --> 00:14:23,709
doing so in an automated way starts to

00:14:21,730 --> 00:14:25,600
grow exponentially and actually humans

00:14:23,709 --> 00:14:26,860
become the more efficient ones when you

00:14:25,600 --> 00:14:29,290
reach the bottom of the funnel if you've

00:14:26,860 --> 00:14:30,820
built the funnel correctly so let's take

00:14:29,290 --> 00:14:32,860
those same people and still have them do

00:14:30,820 --> 00:14:35,200
quarterly events just like they do today

00:14:32,860 --> 00:14:37,329
but instead of it being a gateway to

00:14:35,200 --> 00:14:39,190
production that stops us if the test

00:14:37,329 --> 00:14:42,070
doesn't go well it just instead becomes

00:14:39,190 --> 00:14:44,350
one more feedback mechanism that informs

00:14:42,070 --> 00:14:46,750
our backlog and also sometimes the

00:14:44,350 --> 00:14:48,760
balanced team as I've shown here doesn't

00:14:46,750 --> 00:14:50,649
actually overlap so we always draw it

00:14:48,760 --> 00:14:52,690
that way but it's usually never true the

00:14:50,649 --> 00:14:54,220
overlap is often very unequal based on

00:14:52,690 --> 00:14:55,990
the backgrounds of the people that exist

00:14:54,220 --> 00:14:57,970
on the team and so sometimes you have an

00:14:55,990 --> 00:14:59,230
inexperienced team or a team that's in a

00:14:57,970 --> 00:15:01,120
new domain and doesn't have a lot of

00:14:59,230 --> 00:15:02,440
domain knowledge and these gaps start to

00:15:01,120 --> 00:15:04,089
emerge and that's when it's actually

00:15:02,440 --> 00:15:06,220
appropriate to take an exploratory

00:15:04,089 --> 00:15:07,990
tester and embed them on the team to

00:15:06,220 --> 00:15:10,959
fill in a lot of those context gaps and

00:15:07,990 --> 00:15:12,339
so you want to do that actually during

00:15:10,959 --> 00:15:13,899
the build phase too because you can

00:15:12,339 --> 00:15:15,370
identify assumptions and bugs that would

00:15:13,899 --> 00:15:18,040
otherwise be missed by the balanced team

00:15:15,370 --> 00:15:19,630
I call these unknown unknowns and when

00:15:18,040 --> 00:15:21,010
you when you see that your team is being

00:15:19,630 --> 00:15:23,290
slowed down by things you didn't

00:15:21,010 --> 00:15:25,060
anticipate unknown unknowns and every

00:15:23,290 --> 00:15:27,850
effort you make to try to identify those

00:15:25,060 --> 00:15:29,350
things beforehand is failing it's a good

00:15:27,850 --> 00:15:30,710
indication that your team lacks

00:15:29,350 --> 00:15:32,630
experience or context

00:15:30,710 --> 00:15:34,430
this domain and that you should bring in

00:15:32,630 --> 00:15:37,940
an exploratory tester and establish an

00:15:34,430 --> 00:15:39,830
exploratory charter all right besides

00:15:37,940 --> 00:15:42,350
just automating test Suites right we

00:15:39,830 --> 00:15:44,390
also want to make sure we are Auto right

00:15:42,350 --> 00:15:47,770
automating like the way we do coke ollie

00:15:44,390 --> 00:15:50,420
scans security scans testing our code

00:15:47,770 --> 00:15:52,460
every time we commit and so as we're

00:15:50,420 --> 00:15:54,710
continuously integrating we are sure and

00:15:52,460 --> 00:15:56,090
feel confident that our code is in a

00:15:54,710 --> 00:15:58,550
good state and if there's thought right

00:15:56,090 --> 00:16:00,350
we can always roll back and so all these

00:15:58,550 --> 00:16:02,300
automations allow us to get feedback

00:16:00,350 --> 00:16:04,520
very quickly as soon as we commit our

00:16:02,300 --> 00:16:05,960
code into the pipeline we get feedback

00:16:04,520 --> 00:16:08,420
whether we're missing something or

00:16:05,960 --> 00:16:10,250
whether we don't have quality or we

00:16:08,420 --> 00:16:11,750
caused a test to fail so that feedback

00:16:10,250 --> 00:16:13,930
is really effective because we can

00:16:11,750 --> 00:16:16,970
address it on as early as possible and

00:16:13,930 --> 00:16:21,200
then also with this right it gives us

00:16:16,970 --> 00:16:23,990
the freedom to ship at any time so what

00:16:21,200 --> 00:16:26,600
happens after we finish building yeah so

00:16:23,990 --> 00:16:28,400
as developers complete their stories PMS

00:16:26,600 --> 00:16:29,900
go through the acceptance criteria to

00:16:28,400 --> 00:16:32,060
test whether or not the implementation

00:16:29,900 --> 00:16:34,220
is really doing what we as a team agreed

00:16:32,060 --> 00:16:37,490
to from the start it's also a really

00:16:34,220 --> 00:16:38,960
great way to naturally enforce CI the CI

00:16:37,490 --> 00:16:41,720
that Quinn described so many

00:16:38,960 --> 00:16:43,130
organizations throw out the term and say

00:16:41,720 --> 00:16:45,290
they're doing continuous integration but

00:16:43,130 --> 00:16:46,850
if you actually measure and look they'll

00:16:45,290 --> 00:16:48,830
have very long-lived feature branches

00:16:46,850 --> 00:16:50,990
it's very common and it's a hard thing

00:16:48,830 --> 00:16:53,240
to combat without being very directive

00:16:50,990 --> 00:16:54,590
which usually isn't the kind of culture

00:16:53,240 --> 00:16:56,450
that we want in an engineering

00:16:54,590 --> 00:16:57,830
organization so this is a great way if

00:16:56,450 --> 00:17:00,500
you're struggling to do trunk based

00:16:57,830 --> 00:17:01,790
development what our offer up is make it

00:17:00,500 --> 00:17:04,339
such that you can only get credit for

00:17:01,790 --> 00:17:05,750
your work by just checking it into the

00:17:04,339 --> 00:17:07,130
acceptance environment and you can only

00:17:05,750 --> 00:17:09,950
get to the acceptance environment by

00:17:07,130 --> 00:17:11,720
merging into main branch so once a PM

00:17:09,950 --> 00:17:13,730
accepts a story though then we get to

00:17:11,720 --> 00:17:15,260
see if the users agree for us we

00:17:13,730 --> 00:17:17,240
actually do this at a small scale before

00:17:15,260 --> 00:17:18,650
we push out to production once we

00:17:17,240 --> 00:17:20,180
release the software into production

00:17:18,650 --> 00:17:22,010
those when we really get to test all of

00:17:20,180 --> 00:17:24,410
our assumptions I did we build the right

00:17:22,010 --> 00:17:25,820
thing did we build it right does it

00:17:24,410 --> 00:17:27,040
actually produce the business value

00:17:25,820 --> 00:17:29,180
sometimes the business value

00:17:27,040 --> 00:17:31,370
conversation gets lost in empathy for

00:17:29,180 --> 00:17:33,620
users but ultimately we do want to make

00:17:31,370 --> 00:17:35,570
sure that users find our software joyful

00:17:33,620 --> 00:17:38,210
to use and this is the ultimate test but

00:17:35,570 --> 00:17:39,920
there's a couple other things we can

00:17:38,210 --> 00:17:41,510
achieve the outcomes of reduced risk and

00:17:39,920 --> 00:17:44,240
sustainability and other ways with this

00:17:41,510 --> 00:17:46,429
so as we iterative really add

00:17:44,240 --> 00:17:49,250
we release we're actually training our

00:17:46,429 --> 00:17:50,750
users in small increments and for us in

00:17:49,250 --> 00:17:53,480
the business context the domain that we

00:17:50,750 --> 00:17:54,590
exist in our users are employees of the

00:17:53,480 --> 00:17:56,900
business that we're working for its

00:17:54,590 --> 00:17:59,809
internal IT and so training is a huge

00:17:56,900 --> 00:18:01,820
risk for people in large-scale change so

00:17:59,809 --> 00:18:04,400
for new and existing users the barrier

00:18:01,820 --> 00:18:06,230
to entry is much lower and then as we

00:18:04,400 --> 00:18:08,690
create change we can do it intentionally

00:18:06,230 --> 00:18:10,700
and create ease of use that caters to

00:18:08,690 --> 00:18:12,080
the users workflow so it's much easier

00:18:10,700 --> 00:18:13,580
for them to adopt and then the other

00:18:12,080 --> 00:18:15,890
thing that is kind of a follow-on to

00:18:13,580 --> 00:18:18,500
that is you'll often get large-scale

00:18:15,890 --> 00:18:20,420
rejection from users when you're trying

00:18:18,500 --> 00:18:21,890
to influence or change user behavior and

00:18:20,420 --> 00:18:25,220
you try and do it in too big of a batch

00:18:21,890 --> 00:18:28,130
and so part of our task is not only to

00:18:25,220 --> 00:18:29,420
automate the air operations center but

00:18:28,130 --> 00:18:30,710
also to change some of the business

00:18:29,420 --> 00:18:31,850
processes that have been around for a

00:18:30,710 --> 00:18:33,740
really long time and they're quite

00:18:31,850 --> 00:18:35,750
inefficient and so doing that in a large

00:18:33,740 --> 00:18:37,850
batches is really difficult and going

00:18:35,750 --> 00:18:40,730
iteratively allows us to influence their

00:18:37,850 --> 00:18:42,410
behavior over time all right so what

00:18:40,730 --> 00:18:45,760
happens one made it through and how do

00:18:42,410 --> 00:18:49,070
we prevent that from happening again so

00:18:45,760 --> 00:18:51,650
so in this case our organization is gain

00:18:49,070 --> 00:18:53,900
mature right we have a mix of new and

00:18:51,650 --> 00:18:54,410
maturing teams application teams and for

00:18:53,900 --> 00:18:56,270
new ones

00:18:54,410 --> 00:18:58,429
they really care a lot about delivering

00:18:56,270 --> 00:19:00,559
features into production as fast as

00:18:58,429 --> 00:19:02,690
possible but for mature app teams they

00:19:00,559 --> 00:19:04,100
start to care a lot more about liability

00:19:02,690 --> 00:19:06,260
and how fast can we respond to

00:19:04,100 --> 00:19:07,790
production issues and so like we're

00:19:06,260 --> 00:19:09,980
getting into a practice of monitoring

00:19:07,790 --> 00:19:12,320
driven development or MDD it's very

00:19:09,980 --> 00:19:14,690
similar to TDD right where TDD gives you

00:19:12,320 --> 00:19:16,100
feedback on your code designed MDD gives

00:19:14,690 --> 00:19:17,870
you feedback on your application

00:19:16,100 --> 00:19:19,760
business logic so in this sense

00:19:17,870 --> 00:19:21,290
monitoring and testing are very closely

00:19:19,760 --> 00:19:23,059
related because you're monitoring your

00:19:21,290 --> 00:19:24,230
application to test whether that

00:19:23,059 --> 00:19:27,410
application has fulfilled that

00:19:24,230 --> 00:19:28,760
requirement in production and so when

00:19:27,410 --> 00:19:31,000
they don't meet that requirement right

00:19:28,760 --> 00:19:34,550
you want to take note to be noticed and

00:19:31,000 --> 00:19:35,390
get notified and take action on how can

00:19:34,550 --> 00:19:36,800
we fix that

00:19:35,390 --> 00:19:38,240
whether it's automated or you know

00:19:36,800 --> 00:19:39,890
figure out the next step to do that and

00:19:38,240 --> 00:19:41,750
so the movement I like testing

00:19:39,890 --> 00:19:43,630
monitoring towards the earliest

00:19:41,750 --> 00:19:47,600
definition of the face and production

00:19:43,630 --> 00:19:49,580
lifecycle is also called a shift left so

00:19:47,600 --> 00:19:52,100
in this case for us right a lot of

00:19:49,580 --> 00:19:53,960
factors determine our influence our

00:19:52,100 --> 00:19:56,749
performance key indicators such as

00:19:53,960 --> 00:19:58,889
production failures production bugs

00:19:56,749 --> 00:20:00,989
performance issues so as your

00:19:58,889 --> 00:20:02,999
organization I decide what metrics that

00:20:00,989 --> 00:20:05,309
you care most about that's what you will

00:20:02,999 --> 00:20:07,799
then focus on and then work with

00:20:05,309 --> 00:20:09,389
application and platform operations team

00:20:07,799 --> 00:20:13,350
to ensure that we actually are meeting

00:20:09,389 --> 00:20:14,879
our metrics so Kessel run exists to

00:20:13,350 --> 00:20:16,619
build a product for the air operations

00:20:14,879 --> 00:20:17,940
center that I mentioned but we

00:20:16,619 --> 00:20:20,100
understand at the end of the day our

00:20:17,940 --> 00:20:21,840
product is a system of systems not just

00:20:20,100 --> 00:20:24,210
a collection of individual applications

00:20:21,840 --> 00:20:26,940
and we didn't nail this one out of the

00:20:24,210 --> 00:20:29,070
gate at all at this time we have 20

00:20:26,940 --> 00:20:30,720
applications and I would say they're

00:20:29,070 --> 00:20:32,340
only loosely integrated at this point

00:20:30,720 --> 00:20:33,659
and our next challenge is figuring out

00:20:32,340 --> 00:20:35,940
how to put these applications together

00:20:33,659 --> 00:20:37,289
to form a cohesive system and we learned

00:20:35,940 --> 00:20:39,090
the hard way that in order to do that

00:20:37,289 --> 00:20:41,399
successfully we've had to really think

00:20:39,090 --> 00:20:43,830
about how our organization is structured

00:20:41,399 --> 00:20:46,320
testing some of the assumptions we might

00:20:43,830 --> 00:20:48,869
have about organization as it relates to

00:20:46,320 --> 00:20:50,609
implementation or Conway's law Conway's

00:20:48,869 --> 00:20:55,109
law tells us that organization structure

00:20:50,609 --> 00:20:57,809
is important it is often reflected in

00:20:55,109 --> 00:20:59,489
our systems architecture and so a really

00:20:57,809 --> 00:21:00,840
important thing that we did is we

00:20:59,489 --> 00:21:03,149
employed the inverse Conway maneuver

00:21:00,840 --> 00:21:05,309
where we restructured our organization

00:21:03,149 --> 00:21:07,169
to achieve some of the architectural

00:21:05,309 --> 00:21:09,570
outcomes that we wanted to see so we

00:21:07,169 --> 00:21:11,369
divided up our organization into three

00:21:09,570 --> 00:21:12,929
portfolios which are our bounded

00:21:11,369 --> 00:21:15,929
contexts within this particular domain

00:21:12,929 --> 00:21:17,700
and as our product teams are growing we

00:21:15,929 --> 00:21:19,799
have portfolio teams influencing and

00:21:17,700 --> 00:21:21,539
aligning the teams under the same vision

00:21:19,799 --> 00:21:23,639
while still giving them the autonomy

00:21:21,539 --> 00:21:25,409
they need to serve their specific users

00:21:23,639 --> 00:21:27,239
which is really important and we're

00:21:25,409 --> 00:21:29,249
advocating for balanced teams at every

00:21:27,239 --> 00:21:30,899
level because we understand that we also

00:21:29,249 --> 00:21:34,590
have different sets of users at every

00:21:30,899 --> 00:21:36,059
level in side of this business and so we

00:21:34,590 --> 00:21:37,409
have to make sure that our balanced

00:21:36,059 --> 00:21:39,059
teams can address their needs so at

00:21:37,409 --> 00:21:40,950
every level we have to be sure that we

00:21:39,059 --> 00:21:42,419
have a backlog of stories right we want

00:21:40,950 --> 00:21:43,980
to use the same process that we use at

00:21:42,419 --> 00:21:46,289
the lower level that represent the

00:21:43,980 --> 00:21:48,450
integration aspect between applications

00:21:46,289 --> 00:21:50,100
between portfolios and ultimately at the

00:21:48,450 --> 00:21:51,929
system level so Quinn brought the

00:21:50,100 --> 00:21:54,450
practice of capability stories into our

00:21:51,929 --> 00:21:55,950
organization to help with that yeah so

00:21:54,450 --> 00:21:57,059
when it comes to building a system we

00:21:55,950 --> 00:21:59,309
should think about in lean right

00:21:57,059 --> 00:22:01,109
building a system should be no different

00:21:59,309 --> 00:22:02,700
than how you build apps so in this case

00:22:01,109 --> 00:22:04,529
we take it to another level where

00:22:02,700 --> 00:22:06,570
capability stories represent like units

00:22:04,529 --> 00:22:08,429
of integration or a slicin system that

00:22:06,570 --> 00:22:09,990
we're trying to build and so example of

00:22:08,429 --> 00:22:12,120
a capability story is something like

00:22:09,990 --> 00:22:14,190
given I have some targets when the

00:22:12,120 --> 00:22:16,710
targets are in the approved list in

00:22:14,190 --> 00:22:18,570
application 1 then I see asset snap to

00:22:16,710 --> 00:22:20,279
approve targets application 2 so these

00:22:18,570 --> 00:22:22,020
are like 2 applications I would have

00:22:20,279 --> 00:22:23,610
otherwise be independent right they're

00:22:22,020 --> 00:22:25,770
not talking to each other and so the

00:22:23,610 --> 00:22:27,470
capability stories tells teams that hey

00:22:25,770 --> 00:22:29,970
this is a behavior I want you guys to

00:22:27,470 --> 00:22:31,529
observe right and come together and

00:22:29,970 --> 00:22:33,990
figure out how do you create this

00:22:31,529 --> 00:22:35,279
implementation integration and that's so

00:22:33,990 --> 00:22:36,809
the other thing we talk about is a

00:22:35,279 --> 00:22:38,429
challenge day it's an opportunity for

00:22:36,809 --> 00:22:39,929
applications team to come together and

00:22:38,429 --> 00:22:41,700
share their vision where they're going

00:22:39,929 --> 00:22:44,820
in addition to their integration

00:22:41,700 --> 00:22:46,470
accomplishments so when we only had a

00:22:44,820 --> 00:22:48,270
few product teams business leadership

00:22:46,470 --> 00:22:51,240
was able to maintain broad and deep

00:22:48,270 --> 00:22:53,190
context on every team that we had but as

00:22:51,240 --> 00:22:54,840
we grew the context started to drift and

00:22:53,190 --> 00:22:57,240
we came up with the idea of context

00:22:54,840 --> 00:22:59,850
anchors not to be confused with middle

00:22:57,240 --> 00:23:01,140
management they comprised a balanced

00:22:59,850 --> 00:23:03,450
team of their own at the portfolio level

00:23:01,140 --> 00:23:04,740
for a group of five or so product teams

00:23:03,450 --> 00:23:06,029
and it kind of varies based on the

00:23:04,740 --> 00:23:07,559
bounded context that we're looking at

00:23:06,029 --> 00:23:08,970
but we took some patterns from

00:23:07,559 --> 00:23:11,130
commercial organizations and applied

00:23:08,970 --> 00:23:12,779
them to our context positions like

00:23:11,130 --> 00:23:14,909
associate director engineering lead

00:23:12,779 --> 00:23:17,490
technical strategy lead and product lead

00:23:14,909 --> 00:23:19,620
one of their stated goals is to override

00:23:17,490 --> 00:23:21,659
team prioritization as infrequently as

00:23:19,620 --> 00:23:23,580
possible so queen kind of hinted at this

00:23:21,659 --> 00:23:26,970
but a great way to get product alignment

00:23:23,580 --> 00:23:28,230
without being too rigid or using a

00:23:26,970 --> 00:23:30,210
command-and-control style of

00:23:28,230 --> 00:23:31,909
requirements process is by writing the

00:23:30,210 --> 00:23:34,440
capability stories that Quinn described

00:23:31,909 --> 00:23:36,029
all right so here's like a little

00:23:34,440 --> 00:23:37,409
demonstration what we mean right so

00:23:36,029 --> 00:23:39,630
assuming we have like these five

00:23:37,409 --> 00:23:42,330
different independently apps that are

00:23:39,630 --> 00:23:44,250
running each capability stories kind of

00:23:42,330 --> 00:23:45,390
encourages those two teams to kind of

00:23:44,250 --> 00:23:46,500
work together and say hey here's the

00:23:45,390 --> 00:23:47,720
integration I want you to go first

00:23:46,500 --> 00:23:50,490
because that's really important to us

00:23:47,720 --> 00:23:52,080
and as we kind of integrate to each one

00:23:50,490 --> 00:23:53,640
of these capability stories we're

00:23:52,080 --> 00:23:55,080
constantly making those connections and

00:23:53,640 --> 00:23:56,700
eventually we'll iterate to the point

00:23:55,080 --> 00:23:59,580
where we have a system with the desire

00:23:56,700 --> 00:24:01,380
capabilities we're looking for and so

00:23:59,580 --> 00:24:03,450
these are the things that we want to

00:24:01,380 --> 00:24:05,039
talk about the desire benefits the

00:24:03,450 --> 00:24:06,630
capabilities are meant to align teams

00:24:05,039 --> 00:24:08,399
together toward a common goal right

00:24:06,630 --> 00:24:10,919
we're creating these opportunities for

00:24:08,399 --> 00:24:12,600
teams who are co-located to come

00:24:10,919 --> 00:24:13,890
together and talk about hey you know

00:24:12,600 --> 00:24:15,240
this is the integration that we need to

00:24:13,890 --> 00:24:18,029
do it's really important for all of us

00:24:15,240 --> 00:24:19,529
and in addition right every time we

00:24:18,029 --> 00:24:21,120
complete these capability stories that

00:24:19,529 --> 00:24:23,370
means we can deliver this capability out

00:24:21,120 --> 00:24:25,320
to production right

00:24:23,370 --> 00:24:27,090
and then also the challenge day it gives

00:24:25,320 --> 00:24:28,230
all teams a sense of urgency there's a

00:24:27,090 --> 00:24:31,830
due date there's something that I need

00:24:28,230 --> 00:24:33,120
to show right in addition it creates the

00:24:31,830 --> 00:24:35,190
idea is we want to create a safe space

00:24:33,120 --> 00:24:36,630
so that when teams are demoing this in

00:24:35,190 --> 00:24:38,040
our development space

00:24:36,630 --> 00:24:40,350
it's a opportunity for them to fail

00:24:38,040 --> 00:24:42,750
right to learn as often as they can as

00:24:40,350 --> 00:24:44,040
they iterate through this prior to going

00:24:42,750 --> 00:24:46,290
to production we don't want to learn

00:24:44,040 --> 00:24:47,940
that lesson in production so that's an

00:24:46,290 --> 00:24:50,220
opportunity there shortening the

00:24:47,940 --> 00:24:51,510
feedback loop and then finally right on

00:24:50,220 --> 00:24:54,570
these challenge days we kind of know

00:24:51,510 --> 00:24:56,070
where we are every step away so that are

00:24:54,570 --> 00:24:58,559
we making progress toward building that

00:24:56,070 --> 00:25:00,780
system we're looking for so to wrap it

00:24:58,559 --> 00:25:02,429
up remember that your opponent in

00:25:00,780 --> 00:25:04,410
digital transformation boxing ring is

00:25:02,429 --> 00:25:06,360
actually yourself in the collection of

00:25:04,410 --> 00:25:07,920
assumptions that you have so to be the

00:25:06,360 --> 00:25:10,559
greatest of all time to be the Muhammad

00:25:07,920 --> 00:25:11,730
Ali is to be tested AF which means you

00:25:10,559 --> 00:25:13,380
really have to test all the things

00:25:11,730 --> 00:25:15,450
including your assumptions all the time

00:25:13,380 --> 00:25:17,040
test your assumptions before you start

00:25:15,450 --> 00:25:18,809
building while you're building when you

00:25:17,040 --> 00:25:20,850
complete building and after you ship you

00:25:18,809 --> 00:25:22,620
should always be validating and don't be

00:25:20,850 --> 00:25:24,300
fooled by randomness into believing in

00:25:22,620 --> 00:25:25,290
your own myth right it's something that

00:25:24,300 --> 00:25:27,510
gets people all the time

00:25:25,290 --> 00:25:29,429
black swuan farming is the only way to

00:25:27,510 --> 00:25:31,380
gain and maintain a position in today's

00:25:29,429 --> 00:25:33,210
market and you need to optimize

00:25:31,380 --> 00:25:35,429
everything you do then for being wrong

00:25:33,210 --> 00:25:37,620
and to win against your false

00:25:35,429 --> 00:25:39,600
assumptions against your wrongness you

00:25:37,620 --> 00:25:41,940
need to DevOps like a butterfly and test

00:25:39,600 --> 00:25:43,770
like a bee so thank you everyone we're

00:25:41,940 --> 00:25:45,950
hiring check us out at castle runoff by

00:25:43,770 --> 00:25:45,950
mail

00:26:11,340 --> 00:26:16,180
yeah so you thought you asked about like

00:26:13,660 --> 00:26:17,620
how do we are we actually doing TDD from

00:26:16,180 --> 00:26:19,480
the start or if we're not right we're

00:26:17,620 --> 00:26:21,790
dealing with legacy applications how do

00:26:19,480 --> 00:26:23,050
we introduce that in for a lot of our

00:26:21,790 --> 00:26:24,970
applications right now we start at

00:26:23,050 --> 00:26:27,130
Greenfield so they're all brand new and

00:26:24,970 --> 00:26:29,380
with our engagement with pivotal pivots

00:26:27,130 --> 00:26:31,090
we actually do the practice TD from the

00:26:29,380 --> 00:26:32,800
beginning so we're always making sure

00:26:31,090 --> 00:26:34,330
that we have this test suite and giving

00:26:32,800 --> 00:26:37,270
us that confidence to deliver as often

00:26:34,330 --> 00:26:40,120
as we can so in answering your questions

00:26:37,270 --> 00:26:42,250
we do use TDD everyday and we have done

00:26:40,120 --> 00:26:44,920
some legacy re platforms and in those

00:26:42,250 --> 00:26:47,590
engagements we employ domain-driven

00:26:44,920 --> 00:26:49,750
design to section off portions of the

00:26:47,590 --> 00:26:51,160
code base that will then treat if there

00:26:49,750 --> 00:26:52,900
is low test coverage we'll treat those

00:26:51,160 --> 00:26:54,430
as black boxes and employ testing as

00:26:52,900 --> 00:26:56,110
much testing as we can around it to buy

00:26:54,430 --> 00:26:57,640
down our risk but ultimately you're

00:26:56,110 --> 00:26:59,380
still dealing with a fair amount of risk

00:26:57,640 --> 00:27:01,030
when you do that and so you wanna be

00:26:59,380 --> 00:27:02,440
very deliberate about what sections of

00:27:01,030 --> 00:27:04,510
your code you know we talked about the

00:27:02,440 --> 00:27:06,250
strangler pattern and people sometimes I

00:27:04,510 --> 00:27:08,110
think assume it's just magic and you

00:27:06,250 --> 00:27:09,880
just deploy all the things and then all

00:27:08,110 --> 00:27:11,020
of a sudden you're strangled but you

00:27:09,880 --> 00:27:12,430
have to be really deliberate about which

00:27:11,020 --> 00:27:14,080
things you choose to strangle otherwise

00:27:12,430 --> 00:27:15,520
you especially if it's a production

00:27:14,080 --> 00:27:18,240
system you're introducing a lot of risk

00:27:15,520 --> 00:27:18,240
if you don't do that correctly

00:27:24,720 --> 00:27:29,890
yeah so we what technologies tackle

00:27:27,700 --> 00:27:31,870
we're using four CI CD we are currently

00:27:29,890 --> 00:27:44,470
using concourse as a way for us to

00:27:31,870 --> 00:27:47,650
continuously you know deliver yeah so

00:27:44,470 --> 00:27:49,750
for test suites for a genuine test we

00:27:47,650 --> 00:27:51,820
use Java so Java libraries test

00:27:49,750 --> 00:27:54,040
libraries for genuine test a lot of

00:27:51,820 --> 00:27:55,270
teams use Cypress they also use

00:27:54,040 --> 00:27:56,440
puppeteer so depending on different

00:27:55,270 --> 00:27:58,480
teams they're exploring different

00:27:56,440 --> 00:28:00,310
technologies I'm like how they can this

00:27:58,480 --> 00:28:01,630
and then over time right well the will

00:28:00,310 --> 00:28:04,750
come out with best practices on which

00:28:01,630 --> 00:28:06,550
test tools are best for us so we're

00:28:04,750 --> 00:28:08,320
still exploring at this time and also

00:28:06,550 --> 00:28:08,950
it's important to throw security in

00:28:08,320 --> 00:28:10,510
there as well

00:28:08,950 --> 00:28:12,790
I think sometimes we separate that as a

00:28:10,510 --> 00:28:16,380
separate kind of testing but we're also

00:28:12,790 --> 00:28:19,390
running like sonar cube fortify wasp oh

00:28:16,380 --> 00:28:20,530
my gosh a whole bunch it just depends on

00:28:19,390 --> 00:28:22,630
the team in the language they're using

00:28:20,530 --> 00:28:41,110
obviously and then we didn't mention but

00:28:22,630 --> 00:28:42,910
journeys yeah we employed journeys is so

00:28:41,110 --> 00:28:45,340
you're asking whenever certain things

00:28:42,910 --> 00:28:46,210
fail in the jobs in the pipeline do we

00:28:45,340 --> 00:28:49,660
skip it

00:28:46,210 --> 00:28:52,750
the answer is no the reason is that we

00:28:49,660 --> 00:28:54,670
have monitors in our workspace so if

00:28:52,750 --> 00:28:56,530
it's red it's already telling everybody

00:28:54,670 --> 00:28:58,300
around that we're we failed something

00:28:56,530 --> 00:29:00,640
right and you can't really sneak by it

00:28:58,300 --> 00:29:02,680
it's particularly our p.m. so are very

00:29:00,640 --> 00:29:04,480
you know noticing that pipeline right

00:29:02,680 --> 00:29:06,040
there they're not gonna let us like

00:29:04,480 --> 00:29:07,660
sneak through and like say hey you know

00:29:06,040 --> 00:29:09,850
let's release and then figure out what

00:29:07,660 --> 00:29:11,890
the how to solve this laughter it's not

00:29:09,850 --> 00:29:13,870
the most responsible thing to do and a

00:29:11,890 --> 00:29:15,640
couple more notes on that two things

00:29:13,870 --> 00:29:17,740
that are really helpful there one our

00:29:15,640 --> 00:29:20,140
release pipeline is owned by an

00:29:17,740 --> 00:29:21,670
independent team so all application

00:29:20,140 --> 00:29:23,140
teams have their own dev pipeline and

00:29:21,670 --> 00:29:24,880
they're free to do whatever they want in

00:29:23,140 --> 00:29:26,590
it but the release pipeline is managed

00:29:24,880 --> 00:29:30,220
by a separate entity and it's enforced

00:29:26,590 --> 00:29:31,570
ruthlessly as is the secure the security

00:29:30,220 --> 00:29:33,550
jobs are actually managed by our

00:29:31,570 --> 00:29:35,770
security Assessors so we had a lot of

00:29:33,550 --> 00:29:39,130
luck here I say luck it was a really

00:29:35,770 --> 00:29:40,570
great strategy in giving our security

00:29:39,130 --> 00:29:42,250
sisters an unprecedented level of

00:29:40,570 --> 00:29:44,020
visibility like most of them would only

00:29:42,250 --> 00:29:45,850
ever see receive stacks of paper about

00:29:44,020 --> 00:29:47,980
what our security scans and findings

00:29:45,850 --> 00:29:50,050
were and now we they have full access to

00:29:47,980 --> 00:29:52,930
our git repository to our pivotal

00:29:50,050 --> 00:29:54,700
tracker to all of the security scans

00:29:52,930 --> 00:29:56,650
software they own our fortify rule sets

00:29:54,700 --> 00:29:58,690
and then they own the pipeline

00:29:56,650 --> 00:29:59,920
ultimately so if you don't pass the

00:29:58,690 --> 00:30:01,720
release pipeline in the security

00:29:59,920 --> 00:30:04,000
pipeline you can't deploy to prod and

00:30:01,720 --> 00:30:05,380
then the next question would probably be

00:30:04,000 --> 00:30:06,730
well couldn't people just fake their

00:30:05,380 --> 00:30:08,380
test because that's actually not that

00:30:06,730 --> 00:30:10,000
hard to do it at the unit test level

00:30:08,380 --> 00:30:12,760
especially and pairing is your friend

00:30:10,000 --> 00:30:14,110
here we rotate pairs every day so if you

00:30:12,760 --> 00:30:15,580
wanted to fake your tests you'd have to

00:30:14,110 --> 00:30:18,670
convince probably everybody on your team

00:30:15,580 --> 00:30:20,020
to do that and so in addition we're not

00:30:18,670 --> 00:30:21,430
like any other commercial companies

00:30:20,020 --> 00:30:23,170
right in order for us to push our

00:30:21,430 --> 00:30:25,390
application to production we need to

00:30:23,170 --> 00:30:27,520
have that continuous ATO so meaning

00:30:25,390 --> 00:30:28,750
right we do pairing we do TDD but we

00:30:27,520 --> 00:30:30,970
also have to make sure we address all

00:30:28,750 --> 00:30:32,650
the security vulnerabilities before we

00:30:30,970 --> 00:30:34,300
push otherwise we're violating that and

00:30:32,650 --> 00:30:36,340
we can't get into production and we're

00:30:34,300 --> 00:30:38,020
really bad about acronyms ATO is

00:30:36,340 --> 00:30:39,490
authority to operate you so there's

00:30:38,020 --> 00:30:40,960
nothing in the DoD called authority to

00:30:39,490 --> 00:30:41,799
operate and you cannot push to our

00:30:40,960 --> 00:30:48,299
production environment

00:30:41,799 --> 00:30:50,110
about it anymore

00:30:48,299 --> 00:30:51,010
all right well thank you everyone

00:30:50,110 --> 00:30:56,180
appreciate your time

00:30:51,010 --> 00:30:56,180

YouTube URL: https://www.youtube.com/watch?v=d1SKDqpIYpA


