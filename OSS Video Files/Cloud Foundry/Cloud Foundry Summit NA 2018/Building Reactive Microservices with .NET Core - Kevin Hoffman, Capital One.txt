Title: Building Reactive Microservices with .NET Core - Kevin Hoffman, Capital One
Publication date: 2018-04-21
Playlist: Cloud Foundry Summit NA 2018
Description: 
	Building Reactive Microservices with .NET Core - Kevin Hoffman, Capital One

 This session is all about building reactive services in .NET Core. Kevin Hoffman explains how to deal with distributed transactions by designing around them with techniques like Event Sourcing, CQRS, and embracing eventual consistency. He will walk through a suite of services built with ASP.NET Core to illustrate these patterns, including consuming and publishing Kafka events, using Entity Framework Core to materialize views in Postgres, and more.
Captions: 
	00:00:00,240 --> 00:00:14,639
this is reactive microservices with.net

00:00:04,350 --> 00:00:15,240
core my background is in distributed

00:00:14,639 --> 00:00:18,240
systems

00:00:15,240 --> 00:00:20,730
I wrote a a free book called beyond the

00:00:18,240 --> 00:00:24,660
12 factor app on building cloud native

00:00:20,730 --> 00:00:28,260
apps I've also written a couple of books

00:00:24,660 --> 00:00:32,070
on net most recently is the micro

00:00:28,260 --> 00:00:34,260
services with asp.net core wrote a book

00:00:32,070 --> 00:00:35,760
on go and if you're into that sort of

00:00:34,260 --> 00:00:43,260
thing I also wrote a couple of fantasy

00:00:35,760 --> 00:00:44,640
books so what I want to do today is try

00:00:43,260 --> 00:00:48,270
and figure out how to cram this all into

00:00:44,640 --> 00:00:50,460
half an hour but mostly since every

00:00:48,270 --> 00:00:52,680
micro service presentation is mandated

00:00:50,460 --> 00:00:55,320
by law to have a custom definition of

00:00:52,680 --> 00:00:57,719
what is that microservice I'll have my

00:00:55,320 --> 00:01:00,510
own and I'll talk about distributed

00:00:57,719 --> 00:01:03,899
transactions in the cloud micro services

00:01:00,510 --> 00:01:07,860
world and talk about how we can try and

00:01:03,899 --> 00:01:10,470
work around some of the limitations that

00:01:07,860 --> 00:01:16,409
we get from moving from monoliths to

00:01:10,470 --> 00:01:18,770
micro services and I have what was a

00:01:16,409 --> 00:01:21,060
fully buzzword compliant demo

00:01:18,770 --> 00:01:25,680
unfortunately the Kafka buzzword is

00:01:21,060 --> 00:01:27,689
broken I ran an update this morning and

00:01:25,680 --> 00:01:33,360
that's obviously not what you're

00:01:27,689 --> 00:01:37,860
supposed to do before demo so the first

00:01:33,360 --> 00:01:41,299
question this is a trick question just

00:01:37,860 --> 00:01:43,140
letting you know is this a micro service

00:01:41,299 --> 00:01:45,900
new

00:01:43,140 --> 00:01:49,000
[Laughter]

00:01:45,900 --> 00:01:52,119
this is a protocol handler it's a facade

00:01:49,000 --> 00:01:54,759
this is something that responds to an

00:01:52,119 --> 00:01:55,860
end point the microservice is what's

00:01:54,759 --> 00:01:59,909
inside

00:01:55,860 --> 00:02:03,310
and so the my definition starts with

00:01:59,909 --> 00:02:07,979
some micro services are restful not all

00:02:03,310 --> 00:02:12,550
arrests of all services are micro and

00:02:07,979 --> 00:02:16,569
when building micro services most of us

00:02:12,550 --> 00:02:20,940
tend to start with the idea that we

00:02:16,569 --> 00:02:24,069
build from the rest endpoint in word and

00:02:20,940 --> 00:02:26,170
it's been my experience that doing that

00:02:24,069 --> 00:02:30,550
tends to cause more problems than it's

00:02:26,170 --> 00:02:33,400
worth and so I wanted to describe the

00:02:30,550 --> 00:02:35,380
micro services onion and on the inside

00:02:33,400 --> 00:02:38,170
of this is the service which is your

00:02:35,380 --> 00:02:39,819
real business logic and then we have

00:02:38,170 --> 00:02:44,040
some of the non-functional requirements

00:02:39,819 --> 00:02:47,519
like logging metrics monitoring security

00:02:44,040 --> 00:02:50,500
the protocol handler which I just showed

00:02:47,519 --> 00:02:53,110
and a bunch of other things like storage

00:02:50,500 --> 00:02:54,519
discovery tracing a lot of the things

00:02:53,110 --> 00:02:57,579
that we're talking about at the summit

00:02:54,519 --> 00:03:00,340
here these are all things that are

00:02:57,579 --> 00:03:02,739
important but we should not have to

00:03:00,340 --> 00:03:08,980
write code for them and these things

00:03:02,739 --> 00:03:12,780
aren't in our service so as promised my

00:03:08,980 --> 00:03:16,180
custom definition of a micro service is

00:03:12,780 --> 00:03:17,709
that it is a unit of functionality that

00:03:16,180 --> 00:03:21,640
here's to the single responsibility

00:03:17,709 --> 00:03:23,920
principle asks nothing of its host

00:03:21,640 --> 00:03:26,350
there's an asterisk there because there

00:03:23,920 --> 00:03:27,910
are some basic requirements like being

00:03:26,350 --> 00:03:30,180
able to be deployed into container and

00:03:27,910 --> 00:03:30,180
so on

00:03:31,900 --> 00:03:37,620
like I said we have a whole bunch of

00:03:33,930 --> 00:03:40,780
things that we have to worry about but

00:03:37,620 --> 00:03:44,170
these are not things that that I want in

00:03:40,780 --> 00:03:47,909
my code or I don't want them to affect

00:03:44,170 --> 00:03:50,890
the the core of my my business logic so

00:03:47,909 --> 00:03:53,739
we need to do service discovery there's

00:03:50,890 --> 00:03:57,549
a bunch of demos this week on doing

00:03:53,739 --> 00:04:00,489
steel-toe you can also use council DNS

00:03:57,549 --> 00:04:03,129
other things we all have to monitor our

00:04:00,489 --> 00:04:05,970
services they need security

00:04:03,129 --> 00:04:09,370
we need to interact with our services

00:04:05,970 --> 00:04:13,599
most of us do it with HTTP or arrests

00:04:09,370 --> 00:04:15,430
but I'm going to show using G RPC we

00:04:13,599 --> 00:04:17,919
need configuration we need to be able to

00:04:15,430 --> 00:04:19,539
do zero downtime deployment fault

00:04:17,919 --> 00:04:22,780
tolerance all of that stuff that our

00:04:19,539 --> 00:04:28,690
platform provides that our service code

00:04:22,780 --> 00:04:31,539
should not care about again focus on

00:04:28,690 --> 00:04:36,370
coding your service and not the

00:04:31,539 --> 00:04:38,800
non-functional requirements and you know

00:04:36,370 --> 00:04:45,550
stand on the the shoulders of giants if

00:04:38,800 --> 00:04:47,320
your core business is not building all

00:04:45,550 --> 00:04:49,570
of these non-functional requirements

00:04:47,320 --> 00:04:53,220
then you shouldn't be spending the

00:04:49,570 --> 00:04:53,220
majority every time writing that code

00:04:55,590 --> 00:05:01,750
and since we are at CF summit cloud

00:04:59,830 --> 00:05:03,340
platforms are designed to do these

00:05:01,750 --> 00:05:04,990
things for you whether you use in

00:05:03,340 --> 00:05:08,500
kubernetes or Cloud Foundry or a

00:05:04,990 --> 00:05:10,389
combination of both they're designed to

00:05:08,500 --> 00:05:12,789
run and host your service so you should

00:05:10,389 --> 00:05:18,580
be able to take advantage of those those

00:05:12,789 --> 00:05:21,460
features I think the biggest key point

00:05:18,580 --> 00:05:24,550
here is that if your core business logic

00:05:21,460 --> 00:05:26,080
and your core service is faulty none of

00:05:24,550 --> 00:05:27,639
the things that your cloud platform

00:05:26,080 --> 00:05:28,180
provides is going to be able to fix that

00:05:27,639 --> 00:05:30,370
for you

00:05:28,180 --> 00:05:32,199
so if you have to choose where to spend

00:05:30,370 --> 00:05:35,639
your effort spending it on the inside of

00:05:32,199 --> 00:05:35,639
your service is the best place to go

00:05:37,760 --> 00:05:42,390
like I said we should be spending our

00:05:40,290 --> 00:05:50,010
time worrying about our service and not

00:05:42,390 --> 00:05:55,020
the can you hear that is that okay I

00:05:50,010 --> 00:06:00,810
just yeah that's that's what it sounds

00:05:55,020 --> 00:06:03,390
like when your code is is bad okay one

00:06:00,810 --> 00:06:05,190
of the other things that people do in

00:06:03,390 --> 00:06:07,380
order to take care of some of the

00:06:05,190 --> 00:06:10,140
non-functional requirements or offload

00:06:07,380 --> 00:06:15,240
the platform functionality out of their

00:06:10,140 --> 00:06:17,700
service is sidecars so we can create or

00:06:15,240 --> 00:06:19,650
reuse containers that are designed to

00:06:17,700 --> 00:06:22,310
take care of these things and just

00:06:19,650 --> 00:06:25,310
deploy them alongside our app and again

00:06:22,310 --> 00:06:29,640
not have to worry about it

00:06:25,310 --> 00:06:32,070
so now that I've got my custom fully

00:06:29,640 --> 00:06:33,150
debatable definition of micro service

00:06:32,070 --> 00:06:37,110
out there I want to talk about

00:06:33,150 --> 00:06:39,240
distributed transactions in a classic

00:06:37,110 --> 00:06:42,180
distributed transaction I get a request

00:06:39,240 --> 00:06:44,490
in to my monolith and my monolith then

00:06:42,180 --> 00:06:46,800
creates can create an order it then

00:06:44,490 --> 00:06:49,350
reduces the inventory that I have on

00:06:46,800 --> 00:06:53,610
hand and then updates some ledger and

00:06:49,350 --> 00:06:55,560
this happens transactionally and if it

00:06:53,610 --> 00:06:58,800
fails in any one of these steps it rolls

00:06:55,560 --> 00:07:00,960
back and everything's great but since I

00:06:58,800 --> 00:07:02,760
no longer have a monolith I'm cloud

00:07:00,960 --> 00:07:05,280
native and I'm building micro services

00:07:02,760 --> 00:07:08,550
the way people tell me I'm supposed to

00:07:05,280 --> 00:07:10,350
because micro services are the thing I

00:07:08,550 --> 00:07:14,160
don't have access to distributed

00:07:10,350 --> 00:07:16,350
transactions so what do i do I

00:07:14,160 --> 00:07:23,910
distribute my failure across micro

00:07:16,350 --> 00:07:26,190
services and I try and do the same

00:07:23,910 --> 00:07:32,160
transaction across three different

00:07:26,190 --> 00:07:35,340
services and as the slide says this is a

00:07:32,160 --> 00:07:40,650
pretty guaranteed way to fail and the

00:07:35,340 --> 00:07:42,840
problem here is I'm taking a tightly

00:07:40,650 --> 00:07:44,400
controlled transaction and trying to

00:07:42,840 --> 00:07:47,820
distribute it where I have no control

00:07:44,400 --> 00:07:50,190
and in a micro services world if one of

00:07:47,820 --> 00:07:54,510
these fails I don't have

00:07:50,190 --> 00:07:58,380
compensation so I have two choices

00:07:54,510 --> 00:08:00,330
I can either build in a whole bunch of

00:07:58,380 --> 00:08:03,600
complicated code to compensate for

00:08:00,330 --> 00:08:07,290
transaction failure or I can not do

00:08:03,600 --> 00:08:10,440
distributed transactions at all and it's

00:08:07,290 --> 00:08:13,050
my strongly held opinion that we should

00:08:10,440 --> 00:08:17,310
not do distributed transactions at all

00:08:13,050 --> 00:08:21,540
there's a better way so that better way

00:08:17,310 --> 00:08:24,810
is immutable events and concept called

00:08:21,540 --> 00:08:27,510
shared nothing at the bottom here

00:08:24,810 --> 00:08:30,330
there's a link to probably one of the

00:08:27,510 --> 00:08:32,219
best papers I've ever read by Pat

00:08:30,330 --> 00:08:35,820
Helen's on it's called life beyond

00:08:32,219 --> 00:08:39,690
distributed transactions the idea here

00:08:35,820 --> 00:08:42,030
is instead of giving my system

00:08:39,690 --> 00:08:45,420
imperatives do this do that and if this

00:08:42,030 --> 00:08:49,290
fails undo this my system reacts to

00:08:45,420 --> 00:08:53,610
events so I might have an order accepted

00:08:49,290 --> 00:08:56,820
event and then I'll have inventory

00:08:53,610 --> 00:09:01,220
reserved events and the ledger might

00:08:56,820 --> 00:09:05,700
also see an order accepted event and

00:09:01,220 --> 00:09:11,130
then when my product is shipped I get

00:09:05,700 --> 00:09:13,200
inventory shipped events and if I cancel

00:09:11,130 --> 00:09:16,620
an order there's an order canceled event

00:09:13,200 --> 00:09:18,630
I release the inventory from the

00:09:16,620 --> 00:09:21,900
previously held order and then there the

00:09:18,630 --> 00:09:24,990
ledger sees in order to canceled event I

00:09:21,900 --> 00:09:26,970
have in this diagram here I've got an

00:09:24,990 --> 00:09:29,700
order service inventory service on the

00:09:26,970 --> 00:09:33,920
ledger service but there's no

00:09:29,700 --> 00:09:36,780
transaction I can still model the

00:09:33,920 --> 00:09:38,850
real-time flow events through my system

00:09:36,780 --> 00:09:43,260
and I can still compensate for failure

00:09:38,850 --> 00:09:51,110
but I'm doing it by treating the events

00:09:43,260 --> 00:09:51,110
in my system as immutable facts so

00:09:51,710 --> 00:09:58,790
what this brings up is I now have this

00:09:55,100 --> 00:10:00,830
list of facts that are things that have

00:09:58,790 --> 00:10:03,740
occurred in the past in my system so

00:10:00,830 --> 00:10:06,770
I've got an order created a couple of

00:10:03,740 --> 00:10:13,010
inventory reserved facts order cancelled

00:10:06,770 --> 00:10:16,550
and so on and facts will eventually

00:10:13,010 --> 00:10:18,950
produce States so rather than having

00:10:16,550 --> 00:10:21,380
services that maintain their own state

00:10:18,950 --> 00:10:25,940
I have stateless services and I'm

00:10:21,380 --> 00:10:27,650
calculating my state based on the list

00:10:25,940 --> 00:10:31,700
of facts or events that have occurred in

00:10:27,650 --> 00:10:33,830
the system so rather than having a

00:10:31,700 --> 00:10:35,960
transaction that rolls itself back as

00:10:33,830 --> 00:10:38,990
part of a distributed transaction system

00:10:35,960 --> 00:10:42,170
if there's a failure the failure is an

00:10:38,990 --> 00:10:43,760
event and so I can see when that failure

00:10:42,170 --> 00:10:47,990
happened and I can deal with it

00:10:43,760 --> 00:10:49,880
accordingly so the other philosophy that

00:10:47,990 --> 00:10:51,500
I have here is that being right five

00:10:49,880 --> 00:10:55,780
seconds from now is better than being

00:10:51,500 --> 00:11:00,020
wrong right now and that leads into

00:10:55,780 --> 00:11:04,430
eventual consistency the sample

00:11:00,020 --> 00:11:05,960
application that I have that is somewhat

00:11:04,430 --> 00:11:12,170
demo level today

00:11:05,960 --> 00:11:17,480
is a it's a distributed system with a

00:11:12,170 --> 00:11:20,510
couple of micro services that is

00:11:17,480 --> 00:11:22,820
designed to model an online store and it

00:11:20,510 --> 00:11:27,860
has an order service an inventory

00:11:22,820 --> 00:11:34,310
service and a couple other components to

00:11:27,860 --> 00:11:38,060
it basically it is a event sourcing and

00:11:34,310 --> 00:11:40,940
CQRS demo so there's no distributed

00:11:38,060 --> 00:11:44,690
transactions everything is dealt with in

00:11:40,940 --> 00:11:48,200
terms of commands that come into my

00:11:44,690 --> 00:11:52,990
services and the state is calculated

00:11:48,200 --> 00:11:52,990
based on aggregating the events

00:11:53,589 --> 00:12:01,459
there's a durable message broker here is

00:11:58,190 --> 00:12:10,970
apparently non-durable if you run a PT

00:12:01,459 --> 00:12:17,149
update on Linux the day of your demo so

00:12:10,970 --> 00:12:23,600
I want to take a quick look through some

00:12:17,149 --> 00:12:28,130
of the code the first is I have an

00:12:23,600 --> 00:12:33,440
inventory service and let's see if I

00:12:28,130 --> 00:12:36,920
gotta find the stupid file here this

00:12:33,440 --> 00:12:42,170
inventory service is AG RPC service it's

00:12:36,920 --> 00:12:46,160
not an asp.net core service by show of

00:12:42,170 --> 00:12:47,600
hands who's familiar with G RPC okay

00:12:46,160 --> 00:12:49,610
that's much more than yesterday

00:12:47,600 --> 00:12:52,300
maybe because some of you people were in

00:12:49,610 --> 00:12:52,300
the demo yesterday

00:12:52,370 --> 00:13:03,649
G RPC is a a RPC protocol with a binary

00:13:00,850 --> 00:13:08,899
serialization format on the wire and it

00:13:03,649 --> 00:13:10,760
runs on top of HTTP two and one of the

00:13:08,899 --> 00:13:13,269
reasons there's a number of reasons why

00:13:10,760 --> 00:13:17,540
I'm using it but most of it is because

00:13:13,269 --> 00:13:19,430
this is my service definition and this

00:13:17,540 --> 00:13:24,019
definition can generate code it can

00:13:19,430 --> 00:13:25,519
generate documentation and one of the

00:13:24,019 --> 00:13:26,089
other benefits that I talked about

00:13:25,519 --> 00:13:28,760
yesterday

00:13:26,089 --> 00:13:30,589
is I get bi-directional straining on

00:13:28,760 --> 00:13:35,120
this service so I can send and receive

00:13:30,589 --> 00:13:36,740
data at the same time and the

00:13:35,120 --> 00:13:42,440
implementation of the service is fairly

00:13:36,740 --> 00:13:43,910
simple you just implement the abstract

00:13:42,440 --> 00:13:47,089
base class that you get from the code

00:13:43,910 --> 00:13:50,440
generator and you just handle the

00:13:47,089 --> 00:13:50,440
request and response patterns

00:13:51,590 --> 00:14:01,460
so just a quick demo one of the other

00:13:59,510 --> 00:14:03,470
things that I get from gr PC is the

00:14:01,460 --> 00:14:05,900
ability to interrogate the services that

00:14:03,470 --> 00:14:07,880
I'm running so you can see that I've got

00:14:05,900 --> 00:14:14,170
my inventory management service running

00:14:07,880 --> 00:14:18,020
as well as reflection and I can also

00:14:14,170 --> 00:14:20,360
invoke the G RPC service directly from

00:14:18,020 --> 00:14:22,490
the command line even though you know

00:14:20,360 --> 00:14:24,790
I'm not using curl or postman or

00:14:22,490 --> 00:14:27,680
whatever but you know one of the

00:14:24,790 --> 00:14:30,460
whenever I talk to people about using gr

00:14:27,680 --> 00:14:33,110
PC versus rest the big complaint is I

00:14:30,460 --> 00:14:36,200
don't have access to postman I can't

00:14:33,110 --> 00:14:38,720
query my service but if you use

00:14:36,200 --> 00:14:40,490
reflection than any tool written in any

00:14:38,720 --> 00:14:45,200
language can interrogate your service

00:14:40,490 --> 00:14:48,190
and invoke all the methods and who is

00:14:45,200 --> 00:14:55,190
familiar with the JQ command-line tool

00:14:48,190 --> 00:14:57,080
okay so a couple JQ lets me take the

00:14:55,190 --> 00:15:01,160
ugly spam that I just got from my

00:14:57,080 --> 00:15:04,130
service and format it so that it's it's

00:15:01,160 --> 00:15:06,589
legible in addition to being legible I

00:15:04,130 --> 00:15:09,470
can also run queries through JQ so I can

00:15:06,589 --> 00:15:09,800
filter my results I can order them and

00:15:09,470 --> 00:15:13,100
so on

00:15:09,800 --> 00:15:17,180
so all of the query power that I get

00:15:13,100 --> 00:15:23,360
from postman I also get from ERP curl in

00:15:17,180 --> 00:15:26,300
the command line and again like I said I

00:15:23,360 --> 00:15:30,170
only had a half hour and this is usually

00:15:26,300 --> 00:15:33,230
an hour long session with a pretty

00:15:30,170 --> 00:15:34,910
in-depth demo so what I wanted to do is

00:15:33,230 --> 00:15:41,830
try and get through the slides so that I

00:15:34,910 --> 00:15:45,350
could get to Q&A and looks like I

00:15:41,830 --> 00:15:49,310
okay so the architecture for the

00:15:45,350 --> 00:15:52,959
application is there's a restful api

00:15:49,310 --> 00:15:56,390
gateway at the front that an application

00:15:52,959 --> 00:15:59,060
that doesn't speak g RPC can consume I

00:15:56,390 --> 00:16:03,530
can either write that API myself or I

00:15:59,060 --> 00:16:05,030
can use a standard G RPC essentially a

00:16:03,530 --> 00:16:07,880
reverse proxy that

00:16:05,030 --> 00:16:11,240
converts my G RPC methods into a restful

00:16:07,880 --> 00:16:13,670
interface I have my command service to

00:16:11,240 --> 00:16:16,040
create new orders which submits them to

00:16:13,670 --> 00:16:19,520
Kafka let's just pretend you saw that

00:16:16,040 --> 00:16:22,280
part of the demo and then the order

00:16:19,520 --> 00:16:27,140
management service is responsible for

00:16:22,280 --> 00:16:29,720
listening to events and inventory and

00:16:27,140 --> 00:16:31,640
ledger allow me to query the state based

00:16:29,720 --> 00:16:37,910
on the aggregate of the events in my

00:16:31,640 --> 00:16:39,620
system though like I said don't worry

00:16:37,910 --> 00:16:41,300
about all the code it's all sitting in

00:16:39,620 --> 00:16:50,180
github you can download it and run it

00:16:41,300 --> 00:16:52,970
all so like I said earlier not all micro

00:16:50,180 --> 00:16:57,250
services are restful JSON services I

00:16:52,970 --> 00:17:00,170
think we can get some benefit from

00:16:57,250 --> 00:17:02,150
trying to decide upfront whether we want

00:17:00,170 --> 00:17:07,550
to use rest or something a little more

00:17:02,150 --> 00:17:10,100
powerful or a little more flexible by

00:17:07,550 --> 00:17:12,610
modeling the entities and the flow

00:17:10,100 --> 00:17:17,020
through our system as immutable

00:17:12,610 --> 00:17:19,910
distributed activities we can get a

00:17:17,020 --> 00:17:22,460
simple set of code to solve a complex

00:17:19,910 --> 00:17:30,740
problem without having to use explicit

00:17:22,460 --> 00:17:34,190
distributed transactions a lot of times

00:17:30,740 --> 00:17:35,900
in event sourcing you'll see a whole

00:17:34,190 --> 00:17:39,130
bunch of complicated strategies for

00:17:35,900 --> 00:17:41,630
doing materialized views where you're

00:17:39,130 --> 00:17:45,890
taking your events and then producing

00:17:41,630 --> 00:17:49,340
some sort of cache of the state what I

00:17:45,890 --> 00:17:52,100
found is that's a layer of complexity we

00:17:49,340 --> 00:17:54,650
don't always need so I I'll build the

00:17:52,100 --> 00:17:58,550
system first and then based on the

00:17:54,650 --> 00:18:00,110
actual usage of the system by monitoring

00:17:58,550 --> 00:18:01,910
and getting real metrics then I can

00:18:00,110 --> 00:18:05,680
decide which parts of the system would

00:18:01,910 --> 00:18:05,680
benefit from materialized views

00:18:09,650 --> 00:18:13,960
you know container as your workloads

00:18:11,090 --> 00:18:13,960
that's pretty much a given

00:18:17,170 --> 00:18:24,530
and then finally microservices is a is a

00:18:21,260 --> 00:18:26,960
pattern not just a framework or a

00:18:24,530 --> 00:18:29,990
library so a lot of people a lot of the

00:18:26,960 --> 00:18:34,580
java folks will equate micro-services

00:18:29,990 --> 00:18:35,960
with spring boot and it's not really the

00:18:34,580 --> 00:18:37,670
faculty analogy we should be making

00:18:35,960 --> 00:18:39,430
spring boot is an implementation that

00:18:37,670 --> 00:18:42,260
allows you to build micro-services

00:18:39,430 --> 00:18:44,120
dotnet core allows you to build micro

00:18:42,260 --> 00:18:45,830
services and there are libraries in

00:18:44,120 --> 00:18:49,040
there that give you some functionality

00:18:45,830 --> 00:18:51,470
that you need but a micro service is a

00:18:49,040 --> 00:18:52,880
concept in a pattern and we should try

00:18:51,470 --> 00:18:58,190
and decoupled that from the

00:18:52,880 --> 00:19:00,950
implementation I tried very hard to get

00:18:58,190 --> 00:19:05,930
a logo for the sample application and I

00:19:00,950 --> 00:19:10,700
still haven't found a good one so okay

00:19:05,930 --> 00:19:13,730
so what I'd like to open it for

00:19:10,700 --> 00:19:16,460
questions and we've got a few minutes

00:19:13,730 --> 00:19:18,440
but if there is a specific aspect of the

00:19:16,460 --> 00:19:21,500
code you want me to go through or show

00:19:18,440 --> 00:19:28,940
or the architecture please feel free to

00:19:21,500 --> 00:19:32,260
ask and I'll go through that no

00:19:28,940 --> 00:19:32,260
questions okay yeah

00:19:35,470 --> 00:19:42,080
yeah so the the event store that I have

00:19:38,930 --> 00:19:45,470
or the the event broker that I was using

00:19:42,080 --> 00:19:48,650
for the demo is Kafka I would have been

00:19:45,470 --> 00:19:50,810
able to demo creating an order and

00:19:48,650 --> 00:19:53,750
watching it go through Kafka but as I

00:19:50,810 --> 00:19:55,460
said I ran a software update this

00:19:53,750 --> 00:19:58,270
morning and that was obviously a

00:19:55,460 --> 00:19:58,270
terrible idea

00:20:01,270 --> 00:20:06,730
any other questions yeah

00:20:29,880 --> 00:20:37,929
yeah so in in a situation where if the

00:20:34,750 --> 00:20:40,450
transaction itself starts and finishes

00:20:37,929 --> 00:20:43,690
all within the same bounded context of a

00:20:40,450 --> 00:20:47,470
single service then you probably don't

00:20:43,690 --> 00:20:50,049
need to try and expand that out into an

00:20:47,470 --> 00:20:54,309
event sourcing type thing but as soon as

00:20:50,049 --> 00:20:58,390
a transaction needs to span across

00:20:54,309 --> 00:21:01,000
bounded contexts the the knee-jerk

00:20:58,390 --> 00:21:03,880
reaction is to have two services talk to

00:21:01,000 --> 00:21:05,559
the same database so that they can cheat

00:21:03,880 --> 00:21:09,850
and peek into the status of that

00:21:05,559 --> 00:21:10,240
transaction that's obviously a terrible

00:21:09,850 --> 00:21:14,440
idea

00:21:10,240 --> 00:21:16,059
but when you do that then instead of

00:21:14,440 --> 00:21:18,490
trying to figure out well how can I take

00:21:16,059 --> 00:21:22,600
the transaction that I used to have and

00:21:18,490 --> 00:21:24,279
model that as micro services you know

00:21:22,600 --> 00:21:27,399
take a step up higher and figure out

00:21:24,279 --> 00:21:29,440
what the event flow looks like in the

00:21:27,399 --> 00:21:32,289
system that generated the original

00:21:29,440 --> 00:21:35,350
transaction and then that set of events

00:21:32,289 --> 00:21:37,210
can become the immutable activities that

00:21:35,350 --> 00:21:39,760
you're in your system and like I said

00:21:37,210 --> 00:21:47,830
the one of the important parts is being

00:21:39,760 --> 00:21:50,370
able to model failure as an event any

00:21:47,830 --> 00:21:50,370
other questions

00:21:51,220 --> 00:21:57,610
like I said the all the code is in the

00:21:53,770 --> 00:22:02,080
github repo here this all works on net

00:21:57,610 --> 00:22:04,059
200 I've tried it on two one and I

00:22:02,080 --> 00:22:08,950
didn't have any compilation problems so

00:22:04,059 --> 00:22:12,010
you should be good to go there and if

00:22:08,950 --> 00:22:14,799
your system is not my laptop you should

00:22:12,010 --> 00:22:20,590
have no problem with the kafka part of

00:22:14,799 --> 00:22:22,980
it all right well thanks for coming

00:22:20,590 --> 00:22:22,980

YouTube URL: https://www.youtube.com/watch?v=bGdar01KNzg


