Title: Consumerization of Healthcare on Cloud Foundry - Kaiser Permanente’s Experiences on Cloud Foundry
Publication date: 2018-04-21
Playlist: Cloud Foundry Summit NA 2018
Description: 
	Consumerization of Healthcare on Cloud Foundry - Kaiser Permanente’s Experiences on Cloud Foundry Platform - Surya V Duggirala, IBM & Alex Rubin, Kaiser Permanente

A leader in healthcare, Kaiser Permanente has many applications in production on Cloud Foundry platform. In this session, we will share some lessons learned in the areas of performance, scalability, resiliency, monitoring etc., This session will focus on a large consumer facing application which is used daily by millions of KP members and how it is moving toward microservices running on Cloud Foundry. In this session, we will also share our experiences comparing a set of services deployed on Cloud Foundry and Kubernetes.

About Surya V Duggirala
Surya Duggirala is IBM STSM responsible for Architecture and Performance Engineering of IBM Watson and Cloud Platform. He directs a globally distributed team and chairs IBM Cloud performance engineering Guild. He also works closely with various Open Technology Communities and jointly leads various industry Workgroups on Performance and Optimization with other Cloud Providers in the industry. His special interests include designing microservices applications using scripting and cognitive technologies targeted for cloud. As a Global Technical Ambassador (GTA), he works with many customers, partners and ISVs across the world on cloud, application integration, performance and architecture. He has over 20 years of experience in various fields of the computer industry including application architecture and performance. 

About Alex Rubin
Alex Rubin is a Principal Cloud Architect responsible for Digital applications across different lines of business in Kaiser Permanente.
Captions: 
	00:00:00,030 --> 00:00:03,959
so our talk is going to be about

00:00:01,350 --> 00:00:05,670
consumerization of health care and what

00:00:03,959 --> 00:00:08,429
we're doing at Kaiser Permanente and

00:00:05,670 --> 00:00:09,990
Cloud Foundry and we'll talk a little

00:00:08,429 --> 00:00:11,820
bit about some problems as well but

00:00:09,990 --> 00:00:14,610
first we'll do the quick round of

00:00:11,820 --> 00:00:17,160
introductions here so sorry echo for a

00:00:14,610 --> 00:00:21,449
grafter noon my name is Surya the girl I

00:00:17,160 --> 00:00:25,230
am from IBM as jsm for one cloud

00:00:21,449 --> 00:00:27,269
architecture with me Alex Alex Rubin I'm

00:00:25,230 --> 00:00:30,390
a principal architect at Kaiser

00:00:27,269 --> 00:00:32,009
Permanente and part of my daily duties

00:00:30,390 --> 00:00:35,670
is to work with different teams across

00:00:32,009 --> 00:00:36,809
across KP to talk to them about the

00:00:35,670 --> 00:00:38,399
capabilities that we have on the

00:00:36,809 --> 00:00:40,320
platform the services that we have on

00:00:38,399 --> 00:00:42,270
the platform how to utilize those

00:00:40,320 --> 00:00:45,690
services best practices around micro

00:00:42,270 --> 00:00:47,520
service application design and then also

00:00:45,690 --> 00:00:48,899
to kind of learn a little bit as the

00:00:47,520 --> 00:00:52,020
teams are progressing as they're taking

00:00:48,899 --> 00:00:53,940
their applications from you know POC all

00:00:52,020 --> 00:00:56,969
the way through the development and go

00:00:53,940 --> 00:00:58,710
into production to learn kind of where

00:00:56,969 --> 00:01:01,199
they stumble what are some of the issues

00:00:58,710 --> 00:01:03,030
so we can augment best practices and we

00:01:01,199 --> 00:01:05,309
can look for tools and capabilities that

00:01:03,030 --> 00:01:07,020
will address some of those areas so then

00:01:05,309 --> 00:01:08,729
we'll you know we'll take all of that

00:01:07,020 --> 00:01:11,430
knowledge and we'll wrap it back up and

00:01:08,729 --> 00:01:15,390
give it to teams to help them run better

00:01:11,430 --> 00:01:16,770
and faster yeah with that today we're

00:01:15,390 --> 00:01:19,409
going to talk about healthcare in

00:01:16,770 --> 00:01:21,600
general how Cloud Foundry is being used

00:01:19,409 --> 00:01:24,750
in healthcare industry and why you need

00:01:21,600 --> 00:01:28,500
cloud in healthcare and we'll talk about

00:01:24,750 --> 00:01:32,250
as Lex mentioned the KB's experiences

00:01:28,500 --> 00:01:35,189
running on Cloud Foundry what exactly

00:01:32,250 --> 00:01:38,729
worked well what didn't work pretty well

00:01:35,189 --> 00:01:42,840
with you know Rx application or many

00:01:38,729 --> 00:01:45,750
healthcare applications so then we will

00:01:42,840 --> 00:01:47,729
talk about what we did to make these

00:01:45,750 --> 00:01:50,670
applications perform better scale better

00:01:47,729 --> 00:01:52,799
and then work better and of course we

00:01:50,670 --> 00:01:55,500
still have a few other things that are

00:01:52,799 --> 00:01:57,180
open items for the community so we're

00:01:55,500 --> 00:02:00,420
going to talk about some of those things

00:01:57,180 --> 00:02:05,340
and that's how we're going to spend the

00:02:00,420 --> 00:02:08,119
next 30 minutes here so healthcare and

00:02:05,340 --> 00:02:12,209
cloud right as some of you may have seen

00:02:08,119 --> 00:02:13,470
I was talking about banking on cloud

00:02:12,209 --> 00:02:16,920
foundry

00:02:13,470 --> 00:02:19,860
now how about healthcare industry so you

00:02:16,920 --> 00:02:22,800
can see there are multiple issues with

00:02:19,860 --> 00:02:25,709
the healthcare application healthcare

00:02:22,800 --> 00:02:27,660
industry applications the cloud is

00:02:25,709 --> 00:02:30,959
actually trying to solve for instance

00:02:27,660 --> 00:02:34,200
cost is one of the considerations for

00:02:30,959 --> 00:02:35,490
some of the reasons why in healthcare

00:02:34,200 --> 00:02:37,910
applications our actual health care

00:02:35,490 --> 00:02:40,980
industry is actually looking at cloud

00:02:37,910 --> 00:02:43,020
that's not all that's one of the factors

00:02:40,980 --> 00:02:46,110
but you can look at the digital

00:02:43,020 --> 00:02:49,320
disruption and and the multi speed IT

00:02:46,110 --> 00:02:52,650
because the the speed at which you can

00:02:49,320 --> 00:02:55,230
actually deliver the latest features and

00:02:52,650 --> 00:02:57,930
the requirements that the consumers are

00:02:55,230 --> 00:02:59,850
actually looking for that's the second

00:02:57,930 --> 00:03:02,489
one and of course the third is the

00:02:59,850 --> 00:03:06,019
agility and embracing the kind of

00:03:02,489 --> 00:03:10,440
different business models so I've let

00:03:06,019 --> 00:03:14,030
Alex talk about the reasons why KP chose

00:03:10,440 --> 00:03:22,170
to go to cloud and select Cloud Foundry

00:03:14,030 --> 00:03:23,610
Alex thanks all right so Kaiser

00:03:22,170 --> 00:03:24,750
Permanente is digital journey so I'll

00:03:23,610 --> 00:03:27,000
spend a little bit of time talking about

00:03:24,750 --> 00:03:28,560
kind of where we are where we started

00:03:27,000 --> 00:03:31,500
and where we're going and some of the

00:03:28,560 --> 00:03:33,540
problems that we've had so first of all

00:03:31,500 --> 00:03:36,480
can I get a show of hands who knows what

00:03:33,540 --> 00:03:39,570
kinds of Permanente is anybody know ok

00:03:36,480 --> 00:03:40,769
pretty good ok great so for those folks

00:03:39,570 --> 00:03:42,720
who may not be aware of Kaiser

00:03:40,769 --> 00:03:44,280
Permanente is one of the you know top

00:03:42,720 --> 00:03:46,890
ten largest integrated health care

00:03:44,280 --> 00:03:51,540
providers in the United States we

00:03:46,890 --> 00:03:53,280
operate 39 hospitals we have over 670

00:03:51,540 --> 00:03:57,060
different medical offices and all

00:03:53,280 --> 00:04:00,239
patient facilities and 200,000 plus

00:03:57,060 --> 00:04:02,250
employees in the family and eleven point

00:04:00,239 --> 00:04:04,470
eight million members altogether so lots

00:04:02,250 --> 00:04:06,870
of lots of members that were serving and

00:04:04,470 --> 00:04:09,600
a pretty big company we've been around

00:04:06,870 --> 00:04:11,250
for 70 plus years so there's legacy

00:04:09,600 --> 00:04:12,540
applications as well as the new micro

00:04:11,250 --> 00:04:15,209
service applications that we'll talk

00:04:12,540 --> 00:04:17,760
about here but one of the key things for

00:04:15,209 --> 00:04:20,359
us is kind of this whole idea that as

00:04:17,760 --> 00:04:24,220
you know folks as consumers as

00:04:20,359 --> 00:04:26,680
individuals we like to be engaged with

00:04:24,220 --> 00:04:28,660
in different ways right so there's many

00:04:26,680 --> 00:04:29,950
different things that we prefer we

00:04:28,660 --> 00:04:32,470
prefer to be connected via different

00:04:29,950 --> 00:04:36,280
devices so maybe communicating via cell

00:04:32,470 --> 00:04:39,010
phones or social media you know we have

00:04:36,280 --> 00:04:43,810
all of the IOT devices around too so for

00:04:39,010 --> 00:04:45,850
folks who may be looking at after

00:04:43,810 --> 00:04:48,010
hospital stays how do you improve the

00:04:45,850 --> 00:04:49,420
overall quality right you may be you

00:04:48,010 --> 00:04:52,450
know deciding that it's better for you

00:04:49,420 --> 00:04:53,590
to recover at home and consequently that

00:04:52,450 --> 00:04:55,330
also happens to be a cheaper alternative

00:04:53,590 --> 00:04:59,140
right then for you to stay in the

00:04:55,330 --> 00:05:01,540
hospital you know taking care of some of

00:04:59,140 --> 00:05:03,580
the chronic conditions it's also better

00:05:01,540 --> 00:05:06,660
done you know if you have devices that

00:05:03,580 --> 00:05:09,190
are helping you manage those conditions

00:05:06,660 --> 00:05:10,900
so there's lots of opportunities right

00:05:09,190 --> 00:05:13,450
and and even for things like you know

00:05:10,900 --> 00:05:16,150
farmers markets in the community and

00:05:13,450 --> 00:05:19,840
being able to go in know where to go for

00:05:16,150 --> 00:05:21,970
farmers market or you know being able to

00:05:19,840 --> 00:05:24,850
connect to your doctor in the way that's

00:05:21,970 --> 00:05:26,260
easier for you and maybe that doesn't

00:05:24,850 --> 00:05:27,910
include going to the hospital maybe it

00:05:26,260 --> 00:05:30,310
includes doing an electronic visit and

00:05:27,910 --> 00:05:32,080
just seeing a doctor over video chat and

00:05:30,310 --> 00:05:33,880
and asking questions

00:05:32,080 --> 00:05:35,740
you know that's prefer all of these are

00:05:33,880 --> 00:05:36,910
preferred ways right for us but they're

00:05:35,740 --> 00:05:38,710
also in the end making healthcare

00:05:36,910 --> 00:05:40,690
cheaper for everyone right because if

00:05:38,710 --> 00:05:44,980
you don't show up in the hospital things

00:05:40,690 --> 00:05:46,390
just get a lot simpler so with that in

00:05:44,980 --> 00:05:48,970
mind in order for us to build all kinds

00:05:46,390 --> 00:05:50,740
of experiences and applications that

00:05:48,970 --> 00:05:53,320
enable you to connect in all these

00:05:50,740 --> 00:05:54,970
different ways and give you a value as

00:05:53,320 --> 00:05:57,370
members and as employees in all these

00:05:54,970 --> 00:05:59,530
different ways we need to create a

00:05:57,370 --> 00:06:01,480
digital platform digital foundation

00:05:59,530 --> 00:06:02,740
where we can start building some of

00:06:01,480 --> 00:06:04,300
these components and we can start

00:06:02,740 --> 00:06:05,890
delivering some of that some of that

00:06:04,300 --> 00:06:08,500
value right we don't want to be

00:06:05,890 --> 00:06:10,150
rebuilding continuously the same

00:06:08,500 --> 00:06:12,460
capabilities we want to innovate and

00:06:10,150 --> 00:06:14,470
that means that you have to have a layer

00:06:12,460 --> 00:06:16,870
which you can use to kind of allow

00:06:14,470 --> 00:06:18,430
developers to very quickly deploy

00:06:16,870 --> 00:06:20,980
applications to utilize different

00:06:18,430 --> 00:06:22,690
services so you know fail-fast kind of

00:06:20,980 --> 00:06:24,190
mentality right so you you want to

00:06:22,690 --> 00:06:26,530
create an app you want to use a sequel

00:06:24,190 --> 00:06:28,120
DB well you tried it you know maybe you

00:06:26,530 --> 00:06:29,410
got some feedback from users you have to

00:06:28,120 --> 00:06:32,229
change your data model so now you're

00:06:29,410 --> 00:06:33,910
gonna go and use a no sequel DB how can

00:06:32,229 --> 00:06:35,410
we do that very quickly I just want to

00:06:33,910 --> 00:06:37,550
be able to spin it up and go right I

00:06:35,410 --> 00:06:38,960
don't want to have to wait for you know

00:06:37,550 --> 00:06:41,420
few weeks to stand up one of those

00:06:38,960 --> 00:06:43,070
databases and then try to haggle around

00:06:41,420 --> 00:06:44,660
who's gonna maintain that database and

00:06:43,070 --> 00:06:46,040
upgrade those servers etcetera etcetera

00:06:44,660 --> 00:06:47,810
alright so from a cost perspective

00:06:46,040 --> 00:06:50,570
that's very expensive and gets very

00:06:47,810 --> 00:06:52,910
laborious so what we wanted is we wanted

00:06:50,570 --> 00:06:54,710
a platform where we can really leverage

00:06:52,910 --> 00:06:56,210
all of these capabilities not just from

00:06:54,710 --> 00:06:59,630
the runtime perspective but also from a

00:06:56,210 --> 00:07:01,760
service perspective and we picked IBM

00:06:59,630 --> 00:07:05,030
cloud IBM dedicated cloud as the

00:07:01,760 --> 00:07:06,770
platform for us and and so we've we've

00:07:05,030 --> 00:07:08,210
adopted that and over the last few years

00:07:06,770 --> 00:07:09,890
we've been kind of developing and

00:07:08,210 --> 00:07:11,240
integrating all the different

00:07:09,890 --> 00:07:16,760
capabilities so that we can deliver

00:07:11,240 --> 00:07:18,320
value so just providing a platform is

00:07:16,760 --> 00:07:20,420
not enough though right as I mentioned

00:07:18,320 --> 00:07:21,920
we're over 70 years old and that implies

00:07:20,420 --> 00:07:23,570
that we do have a lot of systems of

00:07:21,920 --> 00:07:26,050
record and a lot of you know cots

00:07:23,570 --> 00:07:28,100
products as any large enterprise right

00:07:26,050 --> 00:07:31,460
nothing ever really goes away it just

00:07:28,100 --> 00:07:33,170
gets you know added to and so you know

00:07:31,460 --> 00:07:34,970
in order to provide and deliver value to

00:07:33,170 --> 00:07:37,280
the our members we have to be contextual

00:07:34,970 --> 00:07:38,840
and we really have to know and some of

00:07:37,280 --> 00:07:42,290
the background in history around how

00:07:38,840 --> 00:07:44,660
some of these things have developed and

00:07:42,290 --> 00:07:46,520
so we need to be able to access back-end

00:07:44,660 --> 00:07:47,870
systems of record which also means then

00:07:46,520 --> 00:07:50,360
that we have to tie everything together

00:07:47,870 --> 00:07:52,250
and we can't just look at you know a

00:07:50,360 --> 00:07:54,200
brand new application greenfield in a

00:07:52,250 --> 00:07:55,730
cloud you you develop and that's it and

00:07:54,200 --> 00:07:57,970
it runs in isolation it means you have

00:07:55,730 --> 00:07:59,810
to have you know the integration

00:07:57,970 --> 00:08:01,070
full-fledged integration with your

00:07:59,810 --> 00:08:02,780
systems of record and you have to be

00:08:01,070 --> 00:08:04,460
able to track transactions you have to

00:08:02,780 --> 00:08:07,070
be able to look at logs holistically you

00:08:04,460 --> 00:08:09,560
have to be able to you know set up see

00:08:07,070 --> 00:08:11,210
ICD pipelines for your deployments and

00:08:09,560 --> 00:08:13,160
also think about how the versions play

00:08:11,210 --> 00:08:15,890
together and integration happens so

00:08:13,160 --> 00:08:17,270
there's a lot going on in in in really

00:08:15,890 --> 00:08:22,180
operationalizing something like this

00:08:17,270 --> 00:08:26,180
right so once we were able to integrate

00:08:22,180 --> 00:08:28,400
cloud cloud foundry and in this case IBM

00:08:26,180 --> 00:08:29,750
cloud into our enterprise a little bit

00:08:28,400 --> 00:08:31,850
better we were more comfortable running

00:08:29,750 --> 00:08:33,140
different applications on it we started

00:08:31,850 --> 00:08:36,200
out with just doing workforce

00:08:33,140 --> 00:08:37,880
applications and then now we're you know

00:08:36,200 --> 00:08:40,970
looking at more complex applications

00:08:37,880 --> 00:08:45,230
which are member facing and so as part

00:08:40,970 --> 00:08:47,480
of that we have a kp.org which is one of

00:08:45,230 --> 00:08:49,400
our premier ways that members can

00:08:47,480 --> 00:08:51,410
connect with us it's a premier member

00:08:49,400 --> 00:08:53,540
facing site millions of users come

00:08:51,410 --> 00:08:55,610
to decide day in and day out to do all

00:08:53,540 --> 00:08:58,009
kinds of different things from you know

00:08:55,610 --> 00:08:59,690
scheduling an appointment sending a

00:08:58,009 --> 00:09:01,370
message to your doctor refilling your

00:08:59,690 --> 00:09:04,100
prescriptions you know all kinds of

00:09:01,370 --> 00:09:05,360
capabilities right and what we wanted to

00:09:04,100 --> 00:09:07,129
do is you know originally this

00:09:05,360 --> 00:09:09,980
application was a monolithic app that

00:09:07,129 --> 00:09:11,329
was running on was and what we wanted to

00:09:09,980 --> 00:09:14,120
do is we wanted to refactor this

00:09:11,329 --> 00:09:17,180
application and take it into micro

00:09:14,120 --> 00:09:19,310
service world and be able to you know

00:09:17,180 --> 00:09:21,829
provide better and better experiences to

00:09:19,310 --> 00:09:23,329
our users allow teams to decouple from

00:09:21,829 --> 00:09:25,970
each other and really run fast

00:09:23,329 --> 00:09:27,769
owning different aspects of this and and

00:09:25,970 --> 00:09:29,420
be able to be able to integrate together

00:09:27,769 --> 00:09:32,360
in the end to provide kind of a holistic

00:09:29,420 --> 00:09:34,250
experience right so as part of that what

00:09:32,360 --> 00:09:36,379
we started doing is we started kind of

00:09:34,250 --> 00:09:37,910
building out these capabilities and

00:09:36,379 --> 00:09:39,860
brought in integration to the enterprise

00:09:37,910 --> 00:09:42,800
so kind of what you see here is at the

00:09:39,860 --> 00:09:45,079
top is kind of what users do and what

00:09:42,800 --> 00:09:47,920
their experience is and in this box here

00:09:45,079 --> 00:09:51,439
you see that we have KP data centers and

00:09:47,920 --> 00:09:53,240
this is the IBM cloud and you can see

00:09:51,439 --> 00:09:55,759
basically some of the micro services

00:09:53,240 --> 00:09:57,589
that are running in IBM cloud so at the

00:09:55,759 --> 00:09:59,839
high level you basically have a user the

00:09:57,589 --> 00:10:02,209
user might you know authenticate against

00:09:59,839 --> 00:10:03,920
some on Prem system then they get it was

00:10:02,209 --> 00:10:06,649
kind of like a welcome screen they can

00:10:03,920 --> 00:10:08,240
decide where to proceed from there so

00:10:06,649 --> 00:10:09,649
they may select let's say pharmacy

00:10:08,240 --> 00:10:13,040
application or some other application

00:10:09,649 --> 00:10:16,069
and you know they will get static

00:10:13,040 --> 00:10:19,519
contents or from am we're using a.m. for

00:10:16,069 --> 00:10:21,259
our content management system and then

00:10:19,519 --> 00:10:22,910
the dynamic content which would come

00:10:21,259 --> 00:10:26,449
from the micro services that are sitting

00:10:22,910 --> 00:10:27,740
over here in IBM cloud and what

00:10:26,449 --> 00:10:29,870
typically happens is there will be a

00:10:27,740 --> 00:10:31,730
request that goes into a micro services

00:10:29,870 --> 00:10:35,000
tier here and that micro services tier

00:10:31,730 --> 00:10:36,920
will be comprised of maybe a Gateway

00:10:35,000 --> 00:10:38,569
written in node.js and we'll have some

00:10:36,920 --> 00:10:42,139
business micro services written in Java

00:10:38,569 --> 00:10:44,029
so it's polyglot and you some of these

00:10:42,139 --> 00:10:46,339
will actually send requests to the

00:10:44,029 --> 00:10:48,110
back-end systems of record now maybe to

00:10:46,339 --> 00:10:50,089
electronic medical record or to other

00:10:48,110 --> 00:10:52,040
systems of record to be able to fetch

00:10:50,089 --> 00:10:53,709
the data and provide you with relevant

00:10:52,040 --> 00:10:55,730
information that you really care about

00:10:53,709 --> 00:10:58,399
and then those requests will be

00:10:55,730 --> 00:11:00,019
processed here and then sent back we're

00:10:58,399 --> 00:11:02,269
also using a bunch of different services

00:11:00,019 --> 00:11:04,279
so this just shows you a few but you

00:11:02,269 --> 00:11:05,329
know in addition to that we have object

00:11:04,279 --> 00:11:08,360
storage

00:11:05,329 --> 00:11:09,649
vacations Postgres a whole bunch of

00:11:08,360 --> 00:11:14,029
other ones right so this is just an

00:11:09,649 --> 00:11:15,499
example with a few and and so then you

00:11:14,029 --> 00:11:17,660
can build out these these complex

00:11:15,499 --> 00:11:20,299
systems now when you have something like

00:11:17,660 --> 00:11:22,339
this it kind of looks easy on the slide

00:11:20,299 --> 00:11:23,839
right not a lot of components but it's a

00:11:22,339 --> 00:11:26,389
simplified slide there's there's a lot

00:11:23,839 --> 00:11:27,949
to it and you really do have to start

00:11:26,389 --> 00:11:29,480
thinking about you know how are we gonna

00:11:27,949 --> 00:11:31,189
have different teams running and

00:11:29,480 --> 00:11:33,139
building out you know all these

00:11:31,189 --> 00:11:34,429
different capabilities how is this all

00:11:33,139 --> 00:11:38,209
going to fit together how is the

00:11:34,429 --> 00:11:39,799
platform going to hold up you know how

00:11:38,209 --> 00:11:40,939
is the performance going to be right so

00:11:39,799 --> 00:11:44,689
you want to optimize a lot of these

00:11:40,939 --> 00:11:45,649
things so next step of what I'm gonna do

00:11:44,689 --> 00:11:47,449
is I'm going to talk about a few

00:11:45,649 --> 00:11:48,920
challenges that we've hit all along the

00:11:47,449 --> 00:11:52,459
way right not everything was absolutely

00:11:48,920 --> 00:11:55,369
perfect all times and some of these

00:11:52,459 --> 00:11:57,110
challenges were interesting so and then

00:11:55,369 --> 00:11:59,179
what I'll do is I'll pass over to Surya

00:11:57,110 --> 00:12:00,860
to talk about some of the kind of

00:11:59,179 --> 00:12:01,879
lessons learned and best practices and

00:12:00,860 --> 00:12:03,860
you know kind of how we're working

00:12:01,879 --> 00:12:05,629
together to address this and also where

00:12:03,860 --> 00:12:09,259
the community can can help us with some

00:12:05,629 --> 00:12:11,480
of these issues so one of the one of the

00:12:09,259 --> 00:12:13,999
things that we had an interesting

00:12:11,480 --> 00:12:16,220
problem with is multi-tenancy so

00:12:13,999 --> 00:12:18,139
basically we have multiple cloud foundry

00:12:16,220 --> 00:12:20,360
environments that we're running in and

00:12:18,139 --> 00:12:22,189
one of our environments is a dev

00:12:20,360 --> 00:12:25,489
environment where lots of people are

00:12:22,189 --> 00:12:27,439
deploying code and so what happened is

00:12:25,489 --> 00:12:28,970
you know we have some projects as I

00:12:27,439 --> 00:12:30,949
mentioned early on they're like in POC

00:12:28,970 --> 00:12:33,169
stage so they'll just do sandbox they'll

00:12:30,949 --> 00:12:35,059
deploy from their laptop you know

00:12:33,169 --> 00:12:36,410
they'll push some sample apps or do

00:12:35,059 --> 00:12:38,179
something to protect people's used to

00:12:36,410 --> 00:12:40,910
see if certain frameworks run and how

00:12:38,179 --> 00:12:42,259
fast they run etc we'll have other teams

00:12:40,910 --> 00:12:44,600
that are going to be going through a

00:12:42,259 --> 00:12:46,759
standard you know pipeline from dev to

00:12:44,600 --> 00:12:48,379
q8 uet etc right so you might have

00:12:46,759 --> 00:12:50,629
somebody running standard set of tests

00:12:48,379 --> 00:12:52,160
and QA or et just checking the

00:12:50,629 --> 00:12:53,209
functionality and you'll have other

00:12:52,160 --> 00:12:54,439
teams that are going to be running

00:12:53,209 --> 00:12:55,819
performance testing and they're just

00:12:54,439 --> 00:12:57,709
going to be pushing their apps to try to

00:12:55,819 --> 00:12:59,419
see hey how much can I squeeze out of

00:12:57,709 --> 00:13:01,160
this app in terms of transactions am i

00:12:59,419 --> 00:13:03,110
fine you know where do I need to go

00:13:01,160 --> 00:13:04,730
patch or what do I need to go optimize

00:13:03,110 --> 00:13:06,980
in terms of my application capabilities

00:13:04,730 --> 00:13:10,910
and how fast they run right and so what

00:13:06,980 --> 00:13:12,980
we found is at one point in in that

00:13:10,910 --> 00:13:15,470
environment we saw like this behavior

00:13:12,980 --> 00:13:17,449
where in this kind of shows you IBM

00:13:15,470 --> 00:13:19,040
cloud dashboard that kind of gives you a

00:13:17,449 --> 00:13:21,170
highlight of what your resource

00:13:19,040 --> 00:13:22,820
the doing in the high level and you can

00:13:21,170 --> 00:13:24,139
see there's a bunch of Giga cells here

00:13:22,820 --> 00:13:25,759
and you can see that a bunch of these

00:13:24,139 --> 00:13:28,399
Diego cells are kind of pegged at like a

00:13:25,759 --> 00:13:30,470
hundred percent CPU and they were a bit

00:13:28,399 --> 00:13:32,660
like literally like most of them in the

00:13:30,470 --> 00:13:34,250
environment where peg did 100% CPU so

00:13:32,660 --> 00:13:36,470
that was a little bit problematic and

00:13:34,250 --> 00:13:38,449
you can see kind of all the behavior in

00:13:36,470 --> 00:13:41,630
the platform here showing kind of the

00:13:38,449 --> 00:13:44,389
this bad behavior so that was that was

00:13:41,630 --> 00:13:46,040
kind of fun and we'll talk a little bit

00:13:44,389 --> 00:13:48,819
later in the talk of kind of what

00:13:46,040 --> 00:13:51,230
happened and how we address some of this

00:13:48,819 --> 00:13:56,630
suffice it to say we should care about

00:13:51,230 --> 00:13:58,009
CPU at this stage the other problem we

00:13:56,630 --> 00:14:00,050
had is as I mentioned performance

00:13:58,009 --> 00:14:01,730
testing we wanted to make sure that you

00:14:00,050 --> 00:14:03,079
know our developers are able to deploy

00:14:01,730 --> 00:14:04,819
quickly and that you know they're

00:14:03,079 --> 00:14:05,899
getting good results on the platform so

00:14:04,819 --> 00:14:09,889
what we've done is we've build out some

00:14:05,899 --> 00:14:11,720
some very simple sample application the

00:14:09,889 --> 00:14:13,459
idea behind the app is that you know I

00:14:11,720 --> 00:14:15,860
have a data center and I have some

00:14:13,459 --> 00:14:18,290
service being a big made available in a

00:14:15,860 --> 00:14:20,000
data center I have a Java Liberty in

00:14:18,290 --> 00:14:22,430
this case app which is going to make

00:14:20,000 --> 00:14:23,930
requests to the data center and then I

00:14:22,430 --> 00:14:25,190
have a node app which is going to talk

00:14:23,930 --> 00:14:28,490
to the Java app which is gonna make

00:14:25,190 --> 00:14:30,290
requests from the data center and all we

00:14:28,490 --> 00:14:32,149
are doing here is we're just connecting

00:14:30,290 --> 00:14:34,220
jmeter to that and saying okay let me

00:14:32,149 --> 00:14:36,170
just get some static content right and

00:14:34,220 --> 00:14:37,639
have have that content come from here

00:14:36,170 --> 00:14:40,160
and it's just gonna pull it you know

00:14:37,639 --> 00:14:41,540
with a bunch of calls here and today a

00:14:40,160 --> 00:14:43,459
bunch of these calls are going through

00:14:41,540 --> 00:14:44,990
the go router right so if you if you

00:14:43,459 --> 00:14:47,000
think about Cloud Foundry and from the

00:14:44,990 --> 00:14:48,560
architecture point of view you know this

00:14:47,000 --> 00:14:50,839
connection to this will be going to the

00:14:48,560 --> 00:14:52,730
go router and this connection here will

00:14:50,839 --> 00:14:53,959
be going to our on-prem and this

00:14:52,730 --> 00:14:56,149
connection also goes through the go

00:14:53,959 --> 00:14:59,720
router right so there's a bunch of

00:14:56,149 --> 00:15:01,519
connection hops so one of the things we

00:14:59,720 --> 00:15:03,380
found is you know for this particular

00:15:01,519 --> 00:15:06,410
case we picked a pretty good back-end

00:15:03,380 --> 00:15:08,000
system and there was you know going at

00:15:06,410 --> 00:15:09,439
about 100 millisecond response time so

00:15:08,000 --> 00:15:12,019
things were looking pretty good there

00:15:09,439 --> 00:15:13,250
and believe it not all of our systems

00:15:12,019 --> 00:15:15,709
are able to give you a hundred

00:15:13,250 --> 00:15:17,389
millisecond response times we do have

00:15:15,709 --> 00:15:19,399
some legacy systems and those systems

00:15:17,389 --> 00:15:21,079
can take quite a while to respond but we

00:15:19,399 --> 00:15:23,449
wanted to keep things simple in this

00:15:21,079 --> 00:15:25,610
particular use case and not actually you

00:15:23,449 --> 00:15:27,829
know show some of that data and not

00:15:25,610 --> 00:15:30,800
worry about caching and and all of that

00:15:27,829 --> 00:15:32,840
good stuff so we just simplified it and

00:15:30,800 --> 00:15:34,580
then we're so measuring

00:15:32,840 --> 00:15:37,340
from Java app directly going to the back

00:15:34,580 --> 00:15:40,220
end you can see the spread of five to

00:15:37,340 --> 00:15:41,900
eight hundred milliseconds now as you go

00:15:40,220 --> 00:15:43,850
up to the node.js level you have no

00:15:41,900 --> 00:15:45,290
making requests to Java which then goes

00:15:43,850 --> 00:15:47,060
back to the backend and comes all the

00:15:45,290 --> 00:15:50,990
way back now you're looking at five to

00:15:47,060 --> 00:15:52,250
seven seconds that's pretty bad so and

00:15:50,990 --> 00:15:54,230
that's a pretty simple app right so we

00:15:52,250 --> 00:15:56,120
said okay well yeah definitely there's

00:15:54,230 --> 00:15:56,540
something wrong here so where's the

00:15:56,120 --> 00:15:58,670
problem

00:15:56,540 --> 00:16:01,880
right is it the hardware is it the

00:15:58,670 --> 00:16:04,880
network platform code like what happened

00:16:01,880 --> 00:16:07,070
and we did not of course you know we did

00:16:04,880 --> 00:16:08,480
not want this type of behavior once they

00:16:07,070 --> 00:16:11,720
have a more complex app right things

00:16:08,480 --> 00:16:13,430
become very very difficult to manage so

00:16:11,720 --> 00:16:15,980
what we've done is we've worked with IBM

00:16:13,430 --> 00:16:18,710
we kind of pulled together a more

00:16:15,980 --> 00:16:21,230
representative use case and we provided

00:16:18,710 --> 00:16:23,750
that use case to IBM and they've been

00:16:21,230 --> 00:16:25,910
looking at it and running some tests and

00:16:23,750 --> 00:16:27,320
running tweaks etc and we've been

00:16:25,910 --> 00:16:30,170
working hand-in-hand on some of the best

00:16:27,320 --> 00:16:32,810
practices around this as well so this is

00:16:30,170 --> 00:16:34,490
where I will pass the baton to Surya to

00:16:32,810 --> 00:16:38,710
talk about some of the solutions and

00:16:34,490 --> 00:16:43,040
best practices thank you Alex

00:16:38,710 --> 00:16:45,170
so as Alex mentioned we have this

00:16:43,040 --> 00:16:49,250
healthcare application and we have some

00:16:45,170 --> 00:16:51,710
challenges I can classify them as three

00:16:49,250 --> 00:16:54,620
different things one is the application

00:16:51,710 --> 00:16:56,540
specific issue like as Alex mentioned

00:16:54,620 --> 00:16:59,540
we're trying to actually go from a

00:16:56,540 --> 00:17:03,770
traditional Java EE application to a

00:16:59,540 --> 00:17:05,840
more cloud native BFF applications so do

00:17:03,770 --> 00:17:08,450
we have any lessons learned from that

00:17:05,840 --> 00:17:10,940
point and then the second point is about

00:17:08,450 --> 00:17:14,209
the platform itself Cloud Foundry itself

00:17:10,940 --> 00:17:17,420
as we are trying to scale do we have any

00:17:14,209 --> 00:17:21,860
kind of inherent issues within the cloud

00:17:17,420 --> 00:17:24,230
foundry or do we have any issues in the

00:17:21,860 --> 00:17:28,430
cloud platform where we have multiple

00:17:24,230 --> 00:17:31,190
different layers right so what we did we

00:17:28,430 --> 00:17:33,290
took a representative application like

00:17:31,190 --> 00:17:35,720
the BFF back and for front-end pattern

00:17:33,290 --> 00:17:39,770
because most of the applications that

00:17:35,720 --> 00:17:41,240
Cape uses are based on the BFF you can

00:17:39,770 --> 00:17:43,280
see we have two different types like you

00:17:41,240 --> 00:17:44,270
know a two layer two tier and three tier

00:17:43,280 --> 00:17:46,160
like you know the node application

00:17:44,270 --> 00:17:50,150
calling a Java API which in

00:17:46,160 --> 00:17:51,770
turn calls the SOR systems of record so

00:17:50,150 --> 00:17:56,990
you can see that there are two different

00:17:51,770 --> 00:17:58,370
types so the different network issues

00:17:56,990 --> 00:18:00,590
that we have within the thing so

00:17:58,370 --> 00:18:02,870
basically we wanted to see whether we

00:18:00,590 --> 00:18:04,850
have any latency issues if at all those

00:18:02,870 --> 00:18:07,160
latency issues are actually coming from

00:18:04,850 --> 00:18:11,210
where and then we also saw some long

00:18:07,160 --> 00:18:14,420
tail latencies also with this so let me

00:18:11,210 --> 00:18:17,450
start with the application first from a

00:18:14,420 --> 00:18:19,880
BFF point of view what we identified is

00:18:17,450 --> 00:18:22,670
actually a lot of these recommendations

00:18:19,880 --> 00:18:24,650
are applicable for not only just for a

00:18:22,670 --> 00:18:25,730
healthcare for any other industry as

00:18:24,650 --> 00:18:28,880
well

00:18:25,730 --> 00:18:31,760
so from a when you look at the backend

00:18:28,880 --> 00:18:35,870
services because as Alex mentioned we

00:18:31,760 --> 00:18:37,430
have the systems of record where these

00:18:35,870 --> 00:18:41,390
applications are actually accessing the

00:18:37,430 --> 00:18:44,540
backend so when we are designing these

00:18:41,390 --> 00:18:46,280
applications we need to take care of the

00:18:44,540 --> 00:18:48,170
backend service latency because some of

00:18:46,280 --> 00:18:51,500
the cloud applications when you have

00:18:48,170 --> 00:18:53,510
very high back-end service latency then

00:18:51,500 --> 00:18:55,670
some of the runtimes will misbehave so

00:18:53,510 --> 00:18:59,000
you need to tweak and tune the runtimes

00:18:55,670 --> 00:19:03,020
that is one of the things and then when

00:18:59,000 --> 00:19:05,510
we talk about micro services again the

00:19:03,020 --> 00:19:08,360
main value proposition of micro service

00:19:05,510 --> 00:19:11,960
is the z-axis scalability so we need to

00:19:08,360 --> 00:19:14,840
make sure that you know we are finding

00:19:11,960 --> 00:19:17,660
the knee of the curve and actually your

00:19:14,840 --> 00:19:20,180
scaling and we are sizing it such a way

00:19:17,660 --> 00:19:24,170
that you know we have those things built

00:19:20,180 --> 00:19:26,540
into your application right and then a

00:19:24,170 --> 00:19:28,490
topology also so then we went into the

00:19:26,540 --> 00:19:30,350
Cloud Foundry itself from a best

00:19:28,490 --> 00:19:33,790
practice perspective Cloud Foundry as

00:19:30,350 --> 00:19:35,990
you can see we need to make sure that

00:19:33,790 --> 00:19:38,350
Cloud Foundry when you're using go

00:19:35,990 --> 00:19:40,520
router right you know we we have to

00:19:38,350 --> 00:19:43,250
because every call let's say you have

00:19:40,520 --> 00:19:45,740
BFF node calling Java API another

00:19:43,250 --> 00:19:47,600
calling the second Java API all these

00:19:45,740 --> 00:19:49,160
calls will go back all the way to the

00:19:47,600 --> 00:19:51,050
firewall and then get into the data

00:19:49,160 --> 00:19:53,000
power and then gets into go router and

00:19:51,050 --> 00:19:56,060
then get into the second instance so

00:19:53,000 --> 00:19:59,670
there are lots of network

00:19:56,060 --> 00:20:02,040
multiple hops that these applications

00:19:59,670 --> 00:20:04,260
these transactions will go through so

00:20:02,040 --> 00:20:07,410
those are some of the inherent design

00:20:04,260 --> 00:20:09,420
issues but there are certain things that

00:20:07,410 --> 00:20:10,880
we have within Cloud Foundry like the

00:20:09,420 --> 00:20:14,210
new features that we're actually driving

00:20:10,880 --> 00:20:18,330
for instance the gorod or keep alive

00:20:14,210 --> 00:20:21,780
so starting 253 we have a keepalive

00:20:18,330 --> 00:20:23,460
upstream upstream

00:20:21,780 --> 00:20:27,000
channel keep alive is enabled for go

00:20:23,460 --> 00:20:28,860
router we need to use that and why we

00:20:27,000 --> 00:20:30,990
need to use that and what exactly it

00:20:28,860 --> 00:20:33,240
will solve I'll show some data there and

00:20:30,990 --> 00:20:36,270
then container to container like if you

00:20:33,240 --> 00:20:38,310
want to avoid all these kinds of Network

00:20:36,270 --> 00:20:40,380
hops there is a new feature called

00:20:38,310 --> 00:20:44,910
container to container networking with

00:20:40,380 --> 00:20:48,000
the CNI plugin where an application in

00:20:44,910 --> 00:20:50,070
turn can call another service without

00:20:48,000 --> 00:20:52,080
going back all the way to the firewall

00:20:50,070 --> 00:20:53,880
and getting into those things so that

00:20:52,080 --> 00:20:57,540
will help and then another thing like

00:20:53,880 --> 00:20:59,730
Alex mentioned about okay see I'm almost

00:20:57,540 --> 00:21:01,680
saturating my you know Diego sells

00:20:59,730 --> 00:21:03,180
almost everything is saturating what

00:21:01,680 --> 00:21:05,400
exactly is happening there are two

00:21:03,180 --> 00:21:07,830
things that are happening there one is

00:21:05,400 --> 00:21:10,500
the the test environment the second one

00:21:07,830 --> 00:21:12,600
is the production environment the test

00:21:10,500 --> 00:21:16,050
environment is actually more impacted

00:21:12,600 --> 00:21:18,240
because there is constant you know

00:21:16,050 --> 00:21:21,180
pushes that are happening there so each

00:21:18,240 --> 00:21:24,060
time you do a CF push if it is java

00:21:21,180 --> 00:21:27,330
application you will see a significant

00:21:24,060 --> 00:21:29,130
spike because the amount of droplet the

00:21:27,330 --> 00:21:31,980
bigger the droplet size the bigger the

00:21:29,130 --> 00:21:33,750
spike is going to be so those are some

00:21:31,980 --> 00:21:36,630
of the things and we have a new feature

00:21:33,750 --> 00:21:40,020
in cloud foundry that is just just in

00:21:36,630 --> 00:21:42,450
279 I think it's a result it's there in

00:21:40,020 --> 00:21:44,820
OCI that's called OC a layered file

00:21:42,450 --> 00:21:49,500
system basically the the bill pack

00:21:44,820 --> 00:21:51,540
mechanism now uses a layered file system

00:21:49,500 --> 00:21:53,850
like docker rather than a flat file

00:21:51,540 --> 00:21:57,030
system so that will actually reduce

00:21:53,850 --> 00:22:00,690
these CPU spikes so things like that and

00:21:57,030 --> 00:22:04,020
you you need to look into and then there

00:22:00,690 --> 00:22:07,050
are other things like the algorithm the

00:22:04,020 --> 00:22:07,790
C group algorithm how when you push an

00:22:07,050 --> 00:22:09,740
app

00:22:07,790 --> 00:22:11,630
the algorithm doesn't take into

00:22:09,740 --> 00:22:14,840
consideration whether that particular

00:22:11,630 --> 00:22:17,540
cell has enough CPU left because it's

00:22:14,840 --> 00:22:20,390
the algorithm is based on the memory so

00:22:17,540 --> 00:22:22,690
that also will have an impact because

00:22:20,390 --> 00:22:25,280
the your cell is completely full

00:22:22,690 --> 00:22:27,560
saturated from a CPU perspective but

00:22:25,280 --> 00:22:29,870
still the push will go to that cell and

00:22:27,560 --> 00:22:32,450
then that staging may fail and some of

00:22:29,870 --> 00:22:36,110
those things we need to take into

00:22:32,450 --> 00:22:39,890
consideration so you can see here and

00:22:36,110 --> 00:22:43,430
then another major issue that we saw was

00:22:39,890 --> 00:22:45,680
the long tail latency we saw certain

00:22:43,430 --> 00:22:47,480
certain transactions like you know if

00:22:45,680 --> 00:22:49,460
you go 98th percentile to 99th

00:22:47,480 --> 00:22:53,600
percentile they're almost like Kennex

00:22:49,460 --> 00:22:57,230
difference which is really bad for micro

00:22:53,600 --> 00:23:00,530
services so resolving the long tail

00:22:57,230 --> 00:23:02,870
latencies is a really tough one but you

00:23:00,530 --> 00:23:05,390
know we identified that to be the good

00:23:02,870 --> 00:23:07,790
order keep alive once you enable that

00:23:05,390 --> 00:23:10,130
then we resolve we could resolve the

00:23:07,790 --> 00:23:13,730
long tail latency so I suggest all of

00:23:10,130 --> 00:23:16,640
you to take advantage of that to

00:23:13,730 --> 00:23:19,460
eliminate the long tail latency and you

00:23:16,640 --> 00:23:22,610
can clearly see the difference on the on

00:23:19,460 --> 00:23:24,890
the left-hand side you can see that that

00:23:22,610 --> 00:23:26,600
is without go router on the right-hand

00:23:24,890 --> 00:23:29,270
side you can see with go router the

00:23:26,600 --> 00:23:34,690
difference in the latency just by

00:23:29,270 --> 00:23:38,720
enabling the go router keep alive there

00:23:34,690 --> 00:23:43,070
this is with the BFF application after

00:23:38,720 --> 00:23:44,930
enabling the the keeper lives for go

00:23:43,070 --> 00:23:46,820
router you can clearly see the

00:23:44,930 --> 00:23:51,890
difference between the 98 and 99

00:23:46,820 --> 00:23:54,020
percentile is much lower there another

00:23:51,890 --> 00:23:56,600
thing that we found is the front door

00:23:54,020 --> 00:23:58,460
like because you have a front door that

00:23:56,600 --> 00:24:00,170
you know like the data power and other

00:23:58,460 --> 00:24:04,040
things that we have in front of the

00:24:00,170 --> 00:24:06,350
browser if those front door areas those

00:24:04,040 --> 00:24:08,360
layers are not tuned right like for

00:24:06,350 --> 00:24:10,580
instance data power is not tuned then

00:24:08,360 --> 00:24:13,070
you can clearly see the significant jump

00:24:10,580 --> 00:24:15,140
in the latency on the right hand side

00:24:13,070 --> 00:24:18,320
you can see that the one that

00:24:15,140 --> 00:24:19,630
misconfigured front door how much it's

00:24:18,320 --> 00:24:21,910
impacting

00:24:19,630 --> 00:24:26,919
the the overall latency of their up

00:24:21,910 --> 00:24:30,730
microservices and this is what Alex was

00:24:26,919 --> 00:24:34,270
talking about the spikes what we did we

00:24:30,730 --> 00:24:37,539
did a temporary fix and a and a

00:24:34,270 --> 00:24:39,640
long-term fix temporary fixes we have

00:24:37,539 --> 00:24:42,490
doubled the capacity we went from four V

00:24:39,640 --> 00:24:45,429
CPUs to eight V CPUs in a Cell so that

00:24:42,490 --> 00:24:47,530
you don't need to actually you won't be

00:24:45,429 --> 00:24:50,140
saturating and then you will have enough

00:24:47,530 --> 00:24:53,380
room Headroom so that you can actually

00:24:50,140 --> 00:24:57,760
get the pushes going through fine

00:24:53,380 --> 00:25:01,419
without any staging issues of course the

00:24:57,760 --> 00:25:06,809
the long-term fix is the OCI so which

00:25:01,419 --> 00:25:10,090
will tone that CPU spikes down right and

00:25:06,809 --> 00:25:13,840
after applying all that we can actually

00:25:10,090 --> 00:25:15,390
clearly see that now we have the the

00:25:13,840 --> 00:25:17,980
healthcare micro service application

00:25:15,390 --> 00:25:20,590
performing and scaling and as you can

00:25:17,980 --> 00:25:23,740
clearly see the knee of the curve that's

00:25:20,590 --> 00:25:24,880
where one single instance of this micro

00:25:23,740 --> 00:25:27,159
service application is actually hitting

00:25:24,880 --> 00:25:28,630
beyond that of course the only thing

00:25:27,159 --> 00:25:34,299
that'll increase is the latencies you

00:25:28,630 --> 00:25:36,370
get to scale horizontally so these are

00:25:34,299 --> 00:25:39,880
some of the lessons learned and I will

00:25:36,370 --> 00:25:43,289
let Alex talk about some of the pain

00:25:39,880 --> 00:25:46,090
points that are from the Cloud Foundry

00:25:43,289 --> 00:25:50,320
fabric itself right that you have

00:25:46,090 --> 00:25:52,000
identified yeah thanks so one of the

00:25:50,320 --> 00:25:53,980
things we learned is that I mean doing

00:25:52,000 --> 00:25:56,260
active monitoring for things like CPU

00:25:53,980 --> 00:25:57,940
Association is a good idea and if you're

00:25:56,260 --> 00:25:59,620
working in the managed environment you

00:25:57,940 --> 00:26:01,600
may not have a lot of visibility into

00:25:59,620 --> 00:26:03,460
those things so you have to work with

00:26:01,600 --> 00:26:05,830
your provider to understand how are you

00:26:03,460 --> 00:26:08,140
gonna manage that right so they may have

00:26:05,830 --> 00:26:09,700
a view into virtual machines and how

00:26:08,140 --> 00:26:11,500
they're running you may not have access

00:26:09,700 --> 00:26:13,059
to that level and if you don't have

00:26:11,500 --> 00:26:15,520
access to that level then you better be

00:26:13,059 --> 00:26:17,530
talking to them about okay great how do

00:26:15,520 --> 00:26:20,320
I you know how do I get to that level

00:26:17,530 --> 00:26:22,240
how do how am I going to know when I get

00:26:20,320 --> 00:26:24,280
to that barrier right so we've developed

00:26:22,240 --> 00:26:25,900
some code some scripts and we have some

00:26:24,280 --> 00:26:28,690
dashboards that now we're tracking how

00:26:25,900 --> 00:26:30,640
our applications behave so we're trying

00:26:28,690 --> 00:26:32,590
to you know proactively look at those

00:26:30,640 --> 00:26:34,570
those things and then carefully analyze

00:26:32,590 --> 00:26:36,130
what's happening

00:26:34,570 --> 00:26:37,600
the other thing we found is that it's

00:26:36,130 --> 00:26:41,380
interesting because teams will optimize

00:26:37,600 --> 00:26:43,450
for areas where you set quotas so if you

00:26:41,380 --> 00:26:45,039
tell your team hey you guys were being

00:26:43,450 --> 00:26:47,289
charged by memory and we have to

00:26:45,039 --> 00:26:49,360
optimize the memory and if you know you

00:26:47,289 --> 00:26:50,710
know Cloud Foundry a lot of quotas you

00:26:49,360 --> 00:26:52,029
can set based on memory there's not a

00:26:50,710 --> 00:26:54,429
lot you can do based on network

00:26:52,029 --> 00:26:56,620
throughput or based on CPU utilization

00:26:54,429 --> 00:26:59,260
so what you find is you find clever

00:26:56,620 --> 00:27:01,600
developers who say well ok if I have to

00:26:59,260 --> 00:27:03,850
make a trade-off between being more CPU

00:27:01,600 --> 00:27:06,760
intensive and lower memory versus being

00:27:03,850 --> 00:27:10,210
less CPU intensive and higher memory

00:27:06,760 --> 00:27:12,460
guess where I'm gonna go so they're

00:27:10,210 --> 00:27:14,230
making these decisions and in the end

00:27:12,460 --> 00:27:15,669
that only makes the problem worse right

00:27:14,230 --> 00:27:19,080
so if you're not tracking it it just

00:27:15,669 --> 00:27:20,919
gets worse the other thing is the

00:27:19,080 --> 00:27:22,270
performance testing becomes an

00:27:20,919 --> 00:27:24,250
interesting problem and ministering

00:27:22,270 --> 00:27:26,950
challenge because what happens is your

00:27:24,250 --> 00:27:29,770
teams basically can run performance

00:27:26,950 --> 00:27:31,149
tests one day and you know from from the

00:27:29,770 --> 00:27:33,309
point of view of cgroups

00:27:31,149 --> 00:27:35,710
it will allow you to spike right for

00:27:33,309 --> 00:27:37,510
your CPU to spike and you can actually

00:27:35,710 --> 00:27:39,370
if you are happen to be on the Diego

00:27:37,510 --> 00:27:41,559
cell which is not very busy you can use

00:27:39,370 --> 00:27:44,080
up more CPU on a Diego cell for a

00:27:41,559 --> 00:27:46,990
particular application now what happens

00:27:44,080 --> 00:27:48,700
if you get on a busy Diego cell then you

00:27:46,990 --> 00:27:50,230
only get whatever CPU shares are

00:27:48,700 --> 00:27:51,279
available for your application based on

00:27:50,230 --> 00:27:54,340
the amount of memory that is allocated

00:27:51,279 --> 00:27:56,500
right and so one of the challenges we've

00:27:54,340 --> 00:27:58,690
seen is you know depending on where your

00:27:56,500 --> 00:28:00,700
application lends and where a specific

00:27:58,690 --> 00:28:02,260
application instance lends your

00:28:00,700 --> 00:28:03,970
performance testing may show some

00:28:02,260 --> 00:28:06,130
different results right in some cases

00:28:03,970 --> 00:28:08,140
you may think everything is great in

00:28:06,130 --> 00:28:10,299
other cases you may think things aren't

00:28:08,140 --> 00:28:12,159
so great right so you have to be careful

00:28:10,299 --> 00:28:13,779
about that and keep that in mind that

00:28:12,159 --> 00:28:18,070
there's some consistency here that you

00:28:13,779 --> 00:28:20,309
need to worry about and a few other

00:28:18,070 --> 00:28:22,270
things in terms of support for workload

00:28:20,309 --> 00:28:23,950
rebalancing so those are the things that

00:28:22,270 --> 00:28:25,000
we would you know appreciate folks to

00:28:23,950 --> 00:28:27,940
weigh in from the community perspective

00:28:25,000 --> 00:28:29,140
and support for CPU quotas so I think

00:28:27,940 --> 00:28:31,419
you know a lot of talk in this

00:28:29,140 --> 00:28:33,520
conference about kubernetes and you know

00:28:31,419 --> 00:28:36,460
how kubernetes will potentially you know

00:28:33,520 --> 00:28:39,010
work with Cloud Foundry and maybe in the

00:28:36,460 --> 00:28:41,140
future be part of you know just run time

00:28:39,010 --> 00:28:42,549
for Cloud Foundry I think those are all

00:28:41,140 --> 00:28:44,080
interesting conversations for us because

00:28:42,549 --> 00:28:45,429
you know we want to make sure that we

00:28:44,080 --> 00:28:47,049
understand

00:28:45,429 --> 00:28:49,120
you know and can control some of the

00:28:47,049 --> 00:28:50,890
additional capabilities that some of

00:28:49,120 --> 00:28:52,360
these additional resources that you know

00:28:50,890 --> 00:28:57,580
kubernetes may be able to provide us

00:28:52,360 --> 00:29:00,790
with knobs to control better so yeah

00:28:57,580 --> 00:29:05,049
with that there is one more session I

00:29:00,790 --> 00:29:10,750
have tomorrow like around 3:45 that

00:29:05,049 --> 00:29:12,850
talks about how you compare Cloud

00:29:10,750 --> 00:29:15,610
Foundry with kubernetes and also I think

00:29:12,850 --> 00:29:18,340
dawn from IBM already announced about

00:29:15,610 --> 00:29:21,010
the CFE the IBM cloud foundry enterprise

00:29:18,340 --> 00:29:23,980
environment so you will actually get to

00:29:21,010 --> 00:29:25,870
see some of the data from the CFE and

00:29:23,980 --> 00:29:30,760
also we'll talk about a little bit on

00:29:25,870 --> 00:29:32,320
honesty oh and how is tio can be

00:29:30,760 --> 00:29:34,540
supported on Cloud Foundry what's the

00:29:32,320 --> 00:29:38,830
future and all that we have a talk

00:29:34,540 --> 00:29:41,100
tomorrow at 3:45 so with that any any

00:29:38,830 --> 00:29:41,100
questions

00:29:56,710 --> 00:30:01,820
what do they

00:29:59,030 --> 00:30:04,730
monitoring okay the question is what did

00:30:01,820 --> 00:30:07,160
we use for monitoring that's a great

00:30:04,730 --> 00:30:10,730
question so we're using for monitoring

00:30:07,160 --> 00:30:13,460
we're using dynaTrace so we've kind of

00:30:10,730 --> 00:30:15,250
we have a lot of flexibility into what

00:30:13,460 --> 00:30:17,660
we can look into with dynaTrace so

00:30:15,250 --> 00:30:23,630
that's kind of our product of choice

00:30:17,660 --> 00:30:26,810
right now yeah one is the dynaTrace but

00:30:23,630 --> 00:30:28,940
also I think you have some custom yeah

00:30:26,810 --> 00:30:30,290
yeah of course there's also some custom

00:30:28,940 --> 00:30:31,640
scripts basically that we've written as

00:30:30,290 --> 00:30:33,710
I mentioned so basically some of this

00:30:31,640 --> 00:30:35,720
stuff because it's a platform so we may

00:30:33,710 --> 00:30:37,700
not be able to install like agents on

00:30:35,720 --> 00:30:39,920
the VMS to actually get some of the data

00:30:37,700 --> 00:30:42,350
so what we end up doing is writing some

00:30:39,920 --> 00:30:45,260
scripts against api's and pulling the

00:30:42,350 --> 00:30:46,940
data from that way and basically then

00:30:45,260 --> 00:30:48,590
dumping that data into a store and then

00:30:46,940 --> 00:30:50,330
doing some other lytx with dashboards on

00:30:48,590 --> 00:30:52,180
top of that so that that's the other

00:30:50,330 --> 00:31:01,900
that's the other way to integrate and

00:30:52,180 --> 00:31:01,900

YouTube URL: https://www.youtube.com/watch?v=L6lwGXw3OKc


