Title: Bring-Your-Own Service Mesh to Cloud Foundry - Andy Paine, EngineerBetter
Publication date: 2020-10-22
Playlist: Cloud Foundry Summit Europe 2020
Description: 
	Bring-Your-Own Service Mesh to Cloud Foundry - Andy Paine, EngineerBetter

Andy Paine will demonstrate how he used some advanced Cloud Foundry features including container-to-container networking, sidecars and metadata to deploy Hashicorp Consul as just a normal SpaceDeveloper. This will involve deploying the Consul control plane in a way that allows it run automatic leadership elections as well as deploying applications with the Consul + Envoy sidecars that register applications into the service mesh.
Captions: 
	00:00:00,000 --> 00:00:03,600
everyone i'm andy i work for engineer

00:00:02,159 --> 00:00:05,120
better for those of you don't know we're

00:00:03,600 --> 00:00:07,279
a small cloud consultancy

00:00:05,120 --> 00:00:10,400
based in london uh i'm sure a lot of you

00:00:07,279 --> 00:00:11,840
know dj our mustache ceo

00:00:10,400 --> 00:00:13,759
so today i'm going to give you a brief

00:00:11,840 --> 00:00:14,240
overview on how i deployed a service

00:00:13,759 --> 00:00:16,800
mesh

00:00:14,240 --> 00:00:17,920
on top of cloud foundry uh we'll explore

00:00:16,800 --> 00:00:19,520
some of the interesting bits of getting

00:00:17,920 --> 00:00:21,600
it running so that

00:00:19,520 --> 00:00:23,519
we can see all the features that we use

00:00:21,600 --> 00:00:24,640
to make it possible and so even if you

00:00:23,519 --> 00:00:25,760
don't need a service mesh hopefully

00:00:24,640 --> 00:00:27,359
you'll be able to take something away

00:00:25,760 --> 00:00:29,199
that might help you run applications

00:00:27,359 --> 00:00:31,279
better or using some new

00:00:29,199 --> 00:00:32,559
bits and bobs from the cloud foundry uh

00:00:31,279 --> 00:00:34,399
all the code samples

00:00:32,559 --> 00:00:35,440
can be found in the github repo here so

00:00:34,399 --> 00:00:36,320
if anyone wants to give this a go

00:00:35,440 --> 00:00:38,079
themselves or

00:00:36,320 --> 00:00:40,480
have any reference you can uh check it

00:00:38,079 --> 00:00:41,840
out over there

00:00:40,480 --> 00:00:43,760
so first and foremost let's lay out the

00:00:41,840 --> 00:00:46,399
goals of what we're trying to achieve

00:00:43,760 --> 00:00:47,680
so we can assess how well we're doing so

00:00:46,399 --> 00:00:49,520
first and foremost we want our apps to

00:00:47,680 --> 00:00:50,960
communicate within the platform

00:00:49,520 --> 00:00:52,559
across platform service mesh would be

00:00:50,960 --> 00:00:55,360
cool but i think it's probably

00:00:52,559 --> 00:00:56,079
a strong walk before we can run secondly

00:00:55,360 --> 00:00:57,199
we want to

00:00:56,079 --> 00:00:58,719
simplify the network from an

00:00:57,199 --> 00:01:00,239
application's perspective ideally this

00:00:58,719 --> 00:01:01,440
means not having to configure our app to

00:01:00,239 --> 00:01:04,879
know about protocols

00:01:01,440 --> 00:01:05,439
ports or dns we'll also be able to

00:01:04,879 --> 00:01:07,040
secure

00:01:05,439 --> 00:01:08,560
network traffic between applications as

00:01:07,040 --> 00:01:09,200
part of this many cloud foundry

00:01:08,560 --> 00:01:10,799
foundations

00:01:09,200 --> 00:01:12,080
are multi-talented and we may not

00:01:10,799 --> 00:01:13,600
completely trust the network over which

00:01:12,080 --> 00:01:15,759
we're communicating so

00:01:13,600 --> 00:01:17,520
if we can lock things down that's ideal

00:01:15,759 --> 00:01:18,720
uh we're modern software developers so

00:01:17,520 --> 00:01:19,600
we want everything to be in source

00:01:18,720 --> 00:01:20,799
control so all

00:01:19,600 --> 00:01:23,520
configuration will be written down and

00:01:20,799 --> 00:01:25,840
applied as automatically as possible

00:01:23,520 --> 00:01:27,119
um and we will also not require any

00:01:25,840 --> 00:01:28,720
elevator permissions as i said we'll

00:01:27,119 --> 00:01:30,400
just be normal space developers as we do

00:01:28,720 --> 00:01:32,799
this

00:01:30,400 --> 00:01:34,320
um lastly and probably most importantly

00:01:32,799 --> 00:01:35,680
we're trying to show off some cool

00:01:34,320 --> 00:01:36,960
features of cloud foundry especially

00:01:35,680 --> 00:01:38,320
some of the newer ones

00:01:36,960 --> 00:01:40,240
that you may not have used before or may

00:01:38,320 --> 00:01:40,560
not realize and so that we can all enjoy

00:01:40,240 --> 00:01:42,159
the

00:01:40,560 --> 00:01:44,399
full benefits of this platform that we

00:01:42,159 --> 00:01:44,399
use

00:01:45,600 --> 00:01:48,799
also just to set a couple of extra

00:01:46,960 --> 00:01:50,240
boundaries given we only have 20 minutes

00:01:48,799 --> 00:01:51,520
we won't be doing a production ready

00:01:50,240 --> 00:01:53,520
deployment and we're not going to do a

00:01:51,520 --> 00:01:56,399
big deep dive into how console

00:01:53,520 --> 00:01:58,159
works um we'll just be kind of seeing

00:01:56,399 --> 00:02:00,479
how the features of cloud foundry helped

00:01:58,159 --> 00:02:00,479
us out

00:02:01,439 --> 00:02:04,799
right so to demonstrate service mesh

00:02:03,520 --> 00:02:05,840
features you kind of need some micro

00:02:04,799 --> 00:02:07,360
services

00:02:05,840 --> 00:02:09,119
i recently bought bosch release for

00:02:07,360 --> 00:02:10,959
jaeger which is an open source

00:02:09,119 --> 00:02:12,640
distributed tracing system

00:02:10,959 --> 00:02:15,200
and as part of testing that bosch

00:02:12,640 --> 00:02:16,720
release i use the hot rod micro services

00:02:15,200 --> 00:02:17,599
which are set for microservices that

00:02:16,720 --> 00:02:18,720
communicate with each other in a

00:02:17,599 --> 00:02:20,239
reasonably simple way

00:02:18,720 --> 00:02:22,080
which is for demonstrating how jaeger

00:02:20,239 --> 00:02:24,239
works but we can use them to show off

00:02:22,080 --> 00:02:25,599
some of the features of our service mesh

00:02:24,239 --> 00:02:27,760
and to really drive home the point about

00:02:25,599 --> 00:02:29,360
the service mesh work normally you can't

00:02:27,760 --> 00:02:29,840
actually deploy hot rod to cloud foundry

00:02:29,360 --> 00:02:31,280
is

00:02:29,840 --> 00:02:32,400
four separate applications as they

00:02:31,280 --> 00:02:33,840
expect them all to be running on the

00:02:32,400 --> 00:02:37,760
same host

00:02:33,840 --> 00:02:39,440
but i think we can fix that

00:02:37,760 --> 00:02:40,959
so the first step in setting up service

00:02:39,440 --> 00:02:42,319
measures choosing your software

00:02:40,959 --> 00:02:43,440
uh if you ask most people these days of

00:02:42,319 --> 00:02:45,200
service mesh they would use they'd

00:02:43,440 --> 00:02:46,319
probably say istio

00:02:45,200 --> 00:02:47,760
i think those people have probably never

00:02:46,319 --> 00:02:49,840
tried deploying istio outside of

00:02:47,760 --> 00:02:51,920
kubernetes

00:02:49,840 --> 00:02:53,440
from hashicore is an alternative service

00:02:51,920 --> 00:02:55,760
measure defines itself as a solution for

00:02:53,440 --> 00:02:57,519
service networking across any cloud

00:02:55,760 --> 00:02:59,360
and it's comprised of simple and easy to

00:02:57,519 --> 00:03:00,879
use components and it comes with a nice

00:02:59,360 --> 00:03:03,599
ui that's quite good for showing off in

00:03:00,879 --> 00:03:05,040
blog posts and conference talks

00:03:03,599 --> 00:03:06,239
so we're going to make a slight amount

00:03:05,040 --> 00:03:10,000
of their product and see if we can do

00:03:06,239 --> 00:03:10,000
this across any cloud foundry instead

00:03:10,560 --> 00:03:14,640
so the basics of getting console running

00:03:12,480 --> 00:03:14,959
are that we need a control plane which

00:03:14,640 --> 00:03:17,120
is

00:03:14,959 --> 00:03:18,480
three or more console agents running in

00:03:17,120 --> 00:03:19,599
server mode

00:03:18,480 --> 00:03:22,000
which can install the state and the

00:03:19,599 --> 00:03:23,519
configuration of our mesh uh control

00:03:22,000 --> 00:03:24,959
plane also serves a nice ui for

00:03:23,519 --> 00:03:26,720
visualizing what's going on and checking

00:03:24,959 --> 00:03:28,640
the status of everything

00:03:26,720 --> 00:03:32,000
um the other piece is the puzzle the

00:03:28,640 --> 00:03:33,760
console agents and the envoy proxies

00:03:32,000 --> 00:03:35,120
which run as side cars to other

00:03:33,760 --> 00:03:36,560
applications that are part of the

00:03:35,120 --> 00:03:37,760
service mesh

00:03:36,560 --> 00:03:40,319
we'll see a bit more about this as we

00:03:37,760 --> 00:03:40,319
build it up

00:03:40,879 --> 00:03:44,159
so step one is deploying the control

00:03:42,640 --> 00:03:44,959
plane as i said this is just running the

00:03:44,159 --> 00:03:46,799
console agent

00:03:44,959 --> 00:03:48,640
in a special mode which uses this dash

00:03:46,799 --> 00:03:50,239
server flag

00:03:48,640 --> 00:03:51,920
the console agent is just a simple

00:03:50,239 --> 00:03:54,159
binary so we can just use the binary

00:03:51,920 --> 00:03:56,080
build pack to get this running

00:03:54,159 --> 00:03:57,680
and then we just add a bunch of command

00:03:56,080 --> 00:04:00,159
line flags which tell us to run

00:03:57,680 --> 00:04:02,080
a ui add a server we add a health check

00:04:00,159 --> 00:04:04,400
for the ui endpoint and we run three

00:04:02,080 --> 00:04:06,080
instances as discussed before

00:04:04,400 --> 00:04:08,159
so so far so normal other than this

00:04:06,080 --> 00:04:12,239
quite complicated um

00:04:08,159 --> 00:04:13,920
app command but there are these weird

00:04:12,239 --> 00:04:14,720
bits in here these app store internal

00:04:13,920 --> 00:04:18,079
references

00:04:14,720 --> 00:04:19,680
so so what are all these about so

00:04:18,079 --> 00:04:21,280
that brings us on to our first cool

00:04:19,680 --> 00:04:24,400
cloud foundry feature which is

00:04:21,280 --> 00:04:25,600
container to container networking um so

00:04:24,400 --> 00:04:27,440
this is sometimes known as internal

00:04:25,600 --> 00:04:28,639
networking and it basically exploits the

00:04:27,440 --> 00:04:30,720
silk cni

00:04:28,639 --> 00:04:32,240
to allow applications running on diego

00:04:30,720 --> 00:04:33,440
cells to communicate with one another

00:04:32,240 --> 00:04:35,600
directly

00:04:33,440 --> 00:04:37,040
so by default traffic is not allowed

00:04:35,600 --> 00:04:39,199
between applications

00:04:37,040 --> 00:04:40,720
but we can create network policies using

00:04:39,199 --> 00:04:43,520
the cfcli

00:04:40,720 --> 00:04:44,880
to allow either tcp or udp traffic to

00:04:43,520 --> 00:04:48,560
flow directly from one application

00:04:44,880 --> 00:04:48,560
container to one application container

00:04:48,880 --> 00:04:51,759
so historically if you had two

00:04:50,479 --> 00:04:53,120
applications running on the same

00:04:51,759 --> 00:04:54,080
foundation and you wanted them to talk

00:04:53,120 --> 00:04:57,919
to one another

00:04:54,080 --> 00:05:00,160
you had to go out via the go router and

00:04:57,919 --> 00:05:01,120
use the public route uh the go retro is

00:05:00,160 --> 00:05:03,680
a great bit of kit

00:05:01,120 --> 00:05:04,639
but this is limited to http and https

00:05:03,680 --> 00:05:06,800
which may not fit

00:05:04,639 --> 00:05:08,080
all workloads and that coupled with the

00:05:06,800 --> 00:05:09,360
fact that you're having to go in

00:05:08,080 --> 00:05:10,639
completely through the front door which

00:05:09,360 --> 00:05:11,840
may involve going all the way out of the

00:05:10,639 --> 00:05:13,520
internet and back in

00:05:11,840 --> 00:05:14,880
maybe with our load balancers or other

00:05:13,520 --> 00:05:16,160
networking middleware

00:05:14,880 --> 00:05:18,479
and this is quite a lot of network

00:05:16,160 --> 00:05:19,600
connections as well as like making it so

00:05:18,479 --> 00:05:21,919
that our traffic has to leave the

00:05:19,600 --> 00:05:23,280
platform just to come back in

00:05:21,919 --> 00:05:24,720
so to contain the container networking

00:05:23,280 --> 00:05:26,479
allows us to go directly from an app

00:05:24,720 --> 00:05:27,919
instance on a diego cell

00:05:26,479 --> 00:05:29,600
to another app instance without using

00:05:27,919 --> 00:05:30,960
the go router and

00:05:29,600 --> 00:05:34,800
this can happen over any protocol you

00:05:30,960 --> 00:05:34,800
like since these are just tcp or udp

00:05:36,840 --> 00:05:40,400
connections the other

00:05:38,800 --> 00:05:43,039
key component here with getting this all

00:05:40,400 --> 00:05:44,400
working is the app store internal domain

00:05:43,039 --> 00:05:46,400
the container's container networking

00:05:44,400 --> 00:05:47,919
allows us to talk to other applications

00:05:46,400 --> 00:05:48,960
but how do we find out how to address

00:05:47,919 --> 00:05:50,400
them

00:05:48,960 --> 00:05:51,759
the absolute internal domain allows us

00:05:50,400 --> 00:05:53,440
to be discovered by other applications

00:05:51,759 --> 00:05:55,280
running on the platform by binding to a

00:05:53,440 --> 00:05:56,639
root in this magic domain

00:05:55,280 --> 00:05:58,080
cloud foundry will then automatically

00:05:56,639 --> 00:05:58,720
track all the running application

00:05:58,080 --> 00:06:00,720
instances

00:05:58,720 --> 00:06:02,000
and update the dns for this domain which

00:06:00,720 --> 00:06:02,880
provides a simple method of service

00:06:02,000 --> 00:06:04,400
discovery

00:06:02,880 --> 00:06:05,680
i say simple it's actually quite a bit

00:06:04,400 --> 00:06:06,240
more complicated i really recommend

00:06:05,680 --> 00:06:08,240
going to see

00:06:06,240 --> 00:06:09,600
toby's talk after this one about how

00:06:08,240 --> 00:06:11,039
cloud foundry goes bang if you want to

00:06:09,600 --> 00:06:12,720
know a bit more about how this system

00:06:11,039 --> 00:06:14,400
works

00:06:12,720 --> 00:06:15,919
another feature that we can use of this

00:06:14,400 --> 00:06:18,639
is that if we need to address a

00:06:15,919 --> 00:06:19,600
specific application instance we can

00:06:18,639 --> 00:06:22,880
prefix the

00:06:19,600 --> 00:06:24,080
hostname with the index of that instance

00:06:22,880 --> 00:06:26,400
which we'll see in these a little bit

00:06:24,080 --> 00:06:26,400
later

00:06:26,560 --> 00:06:30,000
so as we discussed we have the console

00:06:28,000 --> 00:06:31,759
control plane which is three plus

00:06:30,000 --> 00:06:35,199
console agents running a service

00:06:31,759 --> 00:06:36,960
server mode and then we can use tcp and

00:06:35,199 --> 00:06:39,680
udp to access one another for

00:06:36,960 --> 00:06:40,720
meshing and using the gossip protocol to

00:06:39,680 --> 00:06:43,360
identify

00:06:40,720 --> 00:06:44,639
each other and sync configuration and to

00:06:43,360 --> 00:06:45,440
do this we need to be able to uniquely

00:06:44,639 --> 00:06:49,680
identify

00:06:45,440 --> 00:06:51,280
each instance so tcp and udb connections

00:06:49,680 --> 00:06:53,360
we can achieve with containers container

00:06:51,280 --> 00:06:55,360
networking

00:06:53,360 --> 00:06:57,280
and uniquely identifying each instance

00:06:55,360 --> 00:06:58,000
we can use the apps.internal domain and

00:06:57,280 --> 00:07:00,160
that

00:06:58,000 --> 00:07:03,039
index prefix that we talked about so

00:07:00,160 --> 00:07:05,360
this looks like a pretty good candidate

00:07:03,039 --> 00:07:06,960
so as you can see we add another route

00:07:05,360 --> 00:07:07,680
which is on the app's internal domain

00:07:06,960 --> 00:07:10,319
here

00:07:07,680 --> 00:07:12,479
and then we use index based access to

00:07:10,319 --> 00:07:14,840
uniquely identify each of them when we

00:07:12,479 --> 00:07:16,560
tell the agent which other servers to

00:07:14,840 --> 00:07:17,919
join

00:07:16,560 --> 00:07:19,039
what we can't see here is that we also

00:07:17,919 --> 00:07:20,319
have to create some network policies

00:07:19,039 --> 00:07:22,400
that allow communication between the

00:07:20,319 --> 00:07:23,280
console server instances on both tcp and

00:07:22,400 --> 00:07:24,479
udp

00:07:23,280 --> 00:07:25,759
unfortunately we can't do this through

00:07:24,479 --> 00:07:28,080
the manifest at the moment there's no

00:07:25,759 --> 00:07:32,000
declarative way to achieve this

00:07:28,080 --> 00:07:32,000
so just trust me that i did that

00:07:32,720 --> 00:07:36,319
uh so if we see if push the manifest and

00:07:34,880 --> 00:07:37,840
we browse the poly route we're met with

00:07:36,319 --> 00:07:38,960
this screen which shows three healthy

00:07:37,840 --> 00:07:41,199
server instances

00:07:38,960 --> 00:07:42,800
and a star indicating that successfully

00:07:41,199 --> 00:07:45,919
elected a leader

00:07:42,800 --> 00:07:46,720
uh which is all nice and good so stage

00:07:45,919 --> 00:07:48,400
one is complete

00:07:46,720 --> 00:07:49,840
we have our control plane so now we can

00:07:48,400 --> 00:07:52,400
start building our mesh around this

00:07:49,840 --> 00:07:52,400
control plane

00:07:52,560 --> 00:07:56,720
so to build a mesh we need to register

00:07:54,879 --> 00:07:58,000
applications within it

00:07:56,720 --> 00:07:59,919
the way we register application is that

00:07:58,000 --> 00:08:01,440
we run these two sidecar processes

00:07:59,919 --> 00:08:03,280
within the same container

00:08:01,440 --> 00:08:04,319
uh one of these is the console agent

00:08:03,280 --> 00:08:05,599
which is configured to sync

00:08:04,319 --> 00:08:07,360
configuration down from the control

00:08:05,599 --> 00:08:09,680
plane and keep that all up to date

00:08:07,360 --> 00:08:11,680
and we also deploy an envoy process

00:08:09,680 --> 00:08:14,000
managed by console

00:08:11,680 --> 00:08:15,520
envoy is a highly configurable proxy

00:08:14,000 --> 00:08:16,879
it's the same one istio uses you may

00:08:15,520 --> 00:08:18,560
have heard of it through that

00:08:16,879 --> 00:08:20,160
and it can sync configuration via the

00:08:18,560 --> 00:08:22,400
local agent to make sure it stays up to

00:08:20,160 --> 00:08:22,400
date

00:08:24,720 --> 00:08:27,599
so here is an example manifesto

00:08:26,639 --> 00:08:28,960
deploying one of those hot rod

00:08:27,599 --> 00:08:30,160
microscopes we talked about the front

00:08:28,960 --> 00:08:31,840
end of the situation

00:08:30,160 --> 00:08:33,279
uh there's quite a lot of unpack in this

00:08:31,840 --> 00:08:35,200
situation so

00:08:33,279 --> 00:08:38,159
let's just focus on one particular yama

00:08:35,200 --> 00:08:40,000
key which is this sidecars key

00:08:38,159 --> 00:08:41,919
so this is cool feature number two that

00:08:40,000 --> 00:08:43,760
we'll get on to which is that

00:08:41,919 --> 00:08:46,160
applications can now define side cars in

00:08:43,760 --> 00:08:47,600
cloud foundry sidecars are an extra set

00:08:46,160 --> 00:08:49,360
of processors that run in the same

00:08:47,600 --> 00:08:50,720
container as an application

00:08:49,360 --> 00:08:52,240
their ads consume a fixed share of the

00:08:50,720 --> 00:08:53,600
application memory and can be configured

00:08:52,240 --> 00:08:54,080
either through the manifest as we're

00:08:53,600 --> 00:08:57,519
doing

00:08:54,080 --> 00:08:58,640
or by a dedicated sidecar build pack

00:08:57,519 --> 00:09:00,399
critically all this means that they

00:08:58,640 --> 00:09:02,320
share a file system and process space

00:09:00,399 --> 00:09:04,720
and for our use case most importantly

00:09:02,320 --> 00:09:06,000
they share a network space so they can

00:09:04,720 --> 00:09:09,839
bind to the same

00:09:06,000 --> 00:09:09,839
network interface as the application

00:09:12,240 --> 00:09:16,080
so here we can see the sidecars defined

00:09:14,480 --> 00:09:18,320
for the hot rod front end so we have the

00:09:16,080 --> 00:09:20,800
console agent

00:09:18,320 --> 00:09:22,160
and you can see we are joining it to the

00:09:20,800 --> 00:09:24,080
control plane that we defined in the

00:09:22,160 --> 00:09:26,320
previous steps

00:09:24,080 --> 00:09:28,240
and then we also get console to start

00:09:26,320 --> 00:09:29,680
this envoy proxy up for us

00:09:28,240 --> 00:09:31,680
there's a little five second sleep in

00:09:29,680 --> 00:09:32,959
there due to a race condition about the

00:09:31,680 --> 00:09:35,040
console agent having to be running

00:09:32,959 --> 00:09:38,320
before we start envoy but

00:09:35,040 --> 00:09:40,240
other than that all fairly normal uh

00:09:38,320 --> 00:09:42,720
the last kind of big interesting thing

00:09:40,240 --> 00:09:45,360
here is the config directory

00:09:42,720 --> 00:09:46,959
so what's going on in here so i'm not

00:09:45,360 --> 00:09:48,959
going to do a hugely deep dive into

00:09:46,959 --> 00:09:50,640
configuration for console but this is

00:09:48,959 --> 00:09:52,160
effectively what that configuration

00:09:50,640 --> 00:09:55,279
looks like for an application

00:09:52,160 --> 00:09:57,920
we define which service this represents

00:09:55,279 --> 00:09:59,680
and then we add any upstream services

00:09:57,920 --> 00:10:00,320
which we want to create proxies for and

00:09:59,680 --> 00:10:03,440
we

00:10:00,320 --> 00:10:06,720
these bind to a local port

00:10:03,440 --> 00:10:07,600
one per proxy and that allows us to

00:10:06,720 --> 00:10:10,959
communicate with

00:10:07,600 --> 00:10:10,959
other services in the mesh

00:10:11,839 --> 00:10:15,279
so if we set everything up right and we

00:10:13,440 --> 00:10:16,560
push all of those four applications the

00:10:15,279 --> 00:10:18,959
front end customer

00:10:16,560 --> 00:10:20,320
driver and root we should be able to see

00:10:18,959 --> 00:10:21,279
all four microservices registered in the

00:10:20,320 --> 00:10:23,600
service mesh

00:10:21,279 --> 00:10:25,200
and they all look healthy which is good

00:10:23,600 --> 00:10:28,079
uh if we do a bit of a

00:10:25,200 --> 00:10:28,480
deeper dig into one of them we find uh

00:10:28,079 --> 00:10:29,920
the

00:10:28,480 --> 00:10:31,279
hot rod front end and we can see that

00:10:29,920 --> 00:10:32,880
those three upstreams that we defined

00:10:31,279 --> 00:10:33,760
before those are all running those

00:10:32,880 --> 00:10:37,760
proxies on

00:10:33,760 --> 00:10:37,760
8081 82 and 83.

00:10:38,959 --> 00:10:42,399
so earlier we saw this diagram of the

00:10:40,880 --> 00:10:43,839
two options that we have by default

00:10:42,399 --> 00:10:47,120
cloud foundry for communicating

00:10:43,839 --> 00:10:49,440
between applications and what we've done

00:10:47,120 --> 00:10:53,920
is we've augmented that by adding

00:10:49,440 --> 00:10:55,760
the envoy components managed by console

00:10:53,920 --> 00:10:57,200
so we can see that the consolidations

00:10:55,760 --> 00:10:58,320
are syncing data down from the console

00:10:57,200 --> 00:10:59,920
servers

00:10:58,320 --> 00:11:02,320
and the invoice sidecars are being

00:10:59,920 --> 00:11:05,440
configured by those agents

00:11:02,320 --> 00:11:07,200
um traffic between services passes via

00:11:05,440 --> 00:11:09,760
both envoy site cars

00:11:07,200 --> 00:11:11,120
um and so earlier you may recall me

00:11:09,760 --> 00:11:12,560
saying you couldn't normally deploy hot

00:11:11,120 --> 00:11:14,000
rod to cloud foundries expect all the

00:11:12,560 --> 00:11:16,320
services to be on the same host

00:11:14,000 --> 00:11:18,480
but now can we see we can see how

00:11:16,320 --> 00:11:20,480
console has helped us get it working

00:11:18,480 --> 00:11:21,839
as the console proxy is on the same host

00:11:20,480 --> 00:11:23,519
as each service then from the

00:11:21,839 --> 00:11:24,720
front-end's perspective it looks like

00:11:23,519 --> 00:11:25,680
the back-end services are running

00:11:24,720 --> 00:11:27,440
locally

00:11:25,680 --> 00:11:28,560
with console and envoy quietly handling

00:11:27,440 --> 00:11:29,920
all the hard network bits in the

00:11:28,560 --> 00:11:31,920
background

00:11:29,920 --> 00:11:33,440
and as an added bonus the communication

00:11:31,920 --> 00:11:35,120
between these envoy proxies is actually

00:11:33,440 --> 00:11:36,480
secured by mutual tls

00:11:35,120 --> 00:11:38,160
meaning everything is encrypted without

00:11:36,480 --> 00:11:42,079
the applications even needing to know

00:11:38,160 --> 00:11:44,240
about how to do encryption

00:11:42,079 --> 00:11:45,600
so everything should work in theory but

00:11:44,240 --> 00:11:47,200
if we try to actually order a right

00:11:45,600 --> 00:11:49,200
through hot rod we find that it just

00:11:47,200 --> 00:11:51,040
hangs on dispatching a car

00:11:49,200 --> 00:11:53,360
uh this is because of the cloud foundry

00:11:51,040 --> 00:11:54,880
denied by default network policy

00:11:53,360 --> 00:11:56,399
so our sidecar proxies can't actually

00:11:54,880 --> 00:11:57,920
communicate with one another

00:11:56,399 --> 00:11:59,600
without us creating some specific

00:11:57,920 --> 00:12:01,120
network policies

00:11:59,600 --> 00:12:03,440
but in a service mesh of many

00:12:01,120 --> 00:12:05,279
applications we need to ensure that

00:12:03,440 --> 00:12:06,240
network policies exist between all of

00:12:05,279 --> 00:12:09,360
them

00:12:06,240 --> 00:12:10,959
so how do we do that well

00:12:09,360 --> 00:12:11,920
that leads us on to the third feature

00:12:10,959 --> 00:12:12,959
that i want to talk about which is

00:12:11,920 --> 00:12:15,040
metadata

00:12:12,959 --> 00:12:16,959
so most objects in cloud foundry can

00:12:15,040 --> 00:12:18,480
have metadata associated with them

00:12:16,959 --> 00:12:19,680
kubernetes users i'm sure are fairly

00:12:18,480 --> 00:12:21,279
familiar with the idea of labels and

00:12:19,680 --> 00:12:22,320
annotations but

00:12:21,279 --> 00:12:24,240
you may not have known that you can

00:12:22,320 --> 00:12:26,399
apply these to apps spaces and orgs

00:12:24,240 --> 00:12:27,920
amongst other things in cloud foundry

00:12:26,399 --> 00:12:29,519
and we can use this to mark specific

00:12:27,920 --> 00:12:31,120
environments timestamps certain

00:12:29,519 --> 00:12:33,760
operations or add commit hashes to

00:12:31,120 --> 00:12:33,760
pushed apps

00:12:34,800 --> 00:12:39,360
we can use in this situation a label to

00:12:37,839 --> 00:12:41,600
mark all of the applications that should

00:12:39,360 --> 00:12:42,880
be part of the service mesh

00:12:41,600 --> 00:12:44,639
and this then allows us to write some

00:12:42,880 --> 00:12:46,320
scripts which

00:12:44,639 --> 00:12:47,760
fetch all of the applications within the

00:12:46,320 --> 00:12:50,000
service mesh

00:12:47,760 --> 00:12:51,440
and then we use this handy ruby

00:12:50,000 --> 00:12:52,000
permutation function to ensure that

00:12:51,440 --> 00:12:54,079
there's a network

00:12:52,000 --> 00:12:56,240
policy that exists between every pair of

00:12:54,079 --> 00:12:59,519
services in the mesh

00:12:56,240 --> 00:12:59,519
for all permutations of it

00:13:00,079 --> 00:13:03,200
so now if we go back to hot rod after

00:13:01,519 --> 00:13:04,320
running that script and try ordering

00:13:03,200 --> 00:13:04,800
something we confirm that everything is

00:13:04,320 --> 00:13:08,079
working

00:13:04,800 --> 00:13:09,839
as it should so we have a front-end

00:13:08,079 --> 00:13:11,839
microservice talking to all of its three

00:13:09,839 --> 00:13:13,760
back-end microservices

00:13:11,839 --> 00:13:16,160
using envoy proxies deployed and managed

00:13:13,760 --> 00:13:18,160
by console

00:13:16,160 --> 00:13:20,079
if we quickly revisit our goals we can

00:13:18,160 --> 00:13:22,560
show that we've met all of the criteria

00:13:20,079 --> 00:13:24,079
by communicating within the platform not

00:13:22,560 --> 00:13:25,600
requiring applications to know a lot

00:13:24,079 --> 00:13:28,160
about network topology

00:13:25,600 --> 00:13:30,320
uh all of our traffic is now secured and

00:13:28,160 --> 00:13:32,639
we're using declarative json and

00:13:30,320 --> 00:13:34,000
hash core configuration languages files

00:13:32,639 --> 00:13:36,240
to manage everything

00:13:34,000 --> 00:13:39,839
and we don't require any permissions

00:13:36,240 --> 00:13:39,839
more than a normal space developer

00:13:40,480 --> 00:13:43,600
so thanks for coming everyone uh i know

00:13:42,480 --> 00:13:45,600
that was a bit of a

00:13:43,600 --> 00:13:46,639
quick blast but i'll be around now for

00:13:45,600 --> 00:13:47,920
questions or

00:13:46,639 --> 00:13:49,199
feel free to reach out to me during the

00:13:47,920 --> 00:13:51,360
rest of summer or in the cloud foundry

00:13:49,199 --> 00:13:55,120
slack if you'd like to discuss more

00:13:51,360 --> 00:13:58,480
thanks hello everyone

00:13:55,120 --> 00:14:00,560
i see there's one question in the uh

00:13:58,480 --> 00:14:02,000
chat on the main session so i'll answer

00:14:00,560 --> 00:14:04,240
that first um

00:14:02,000 --> 00:14:05,920
says are there any limitations to the

00:14:04,240 --> 00:14:07,600
number of go routers needed to implement

00:14:05,920 --> 00:14:08,959
the envoy proxy

00:14:07,600 --> 00:14:10,560
uh so one of the really nice things

00:14:08,959 --> 00:14:12,639
about this is that actually the go

00:14:10,560 --> 00:14:16,240
reachers aren't

00:14:12,639 --> 00:14:17,519
really involved and there's still uh the

00:14:16,240 --> 00:14:19,199
core component for doing ingress into

00:14:17,519 --> 00:14:19,920
the cluster so accessing the front end

00:14:19,199 --> 00:14:21,839
for example

00:14:19,920 --> 00:14:23,279
but all service to service communication

00:14:21,839 --> 00:14:26,000
actually travels just over

00:14:23,279 --> 00:14:27,839
silk which is just a cni so all it's

00:14:26,000 --> 00:14:30,560
doing is configuring some network

00:14:27,839 --> 00:14:31,199
policies and ip tables rules so there's

00:14:30,560 --> 00:14:34,399
actually no

00:14:31,199 --> 00:14:36,240
extra networking components

00:14:34,399 --> 00:14:37,760
like a go router the envoy proxies are

00:14:36,240 --> 00:14:39,839
the limit of it so you don't need to

00:14:37,760 --> 00:14:42,959
scale your go routers at all

00:14:39,839 --> 00:14:44,320
in fact if you currently using the go

00:14:42,959 --> 00:14:46,000
router to do service to service

00:14:44,320 --> 00:14:48,000
communication you could probably

00:14:46,000 --> 00:14:50,480
remove a lot of that traffic by using an

00:14:48,000 --> 00:14:51,760
internal networking based system

00:14:50,480 --> 00:14:54,560
so it may even allow you to drop the

00:14:51,760 --> 00:14:57,720
number of go routers

00:14:54,560 --> 00:14:58,880
um and as i say it supports other

00:14:57,720 --> 00:15:02,079
non-http

00:14:58,880 --> 00:15:03,920
protocols so it's got some other

00:15:02,079 --> 00:15:06,160
benefits to skipping the characters as

00:15:03,920 --> 00:15:06,160
well

00:15:06,480 --> 00:15:08,880
i hope that's answered your question

00:15:07,519 --> 00:15:13,839
please let me know if you'd like any

00:15:08,880 --> 00:15:15,360
more clarification

00:15:13,839 --> 00:15:17,519
i haven't got any more other questions

00:15:15,360 --> 00:15:20,880
at the moment so

00:15:17,519 --> 00:15:27,839
if people want to send some over or

00:15:20,880 --> 00:15:27,839
stick them in the chat then feel free

00:15:36,800 --> 00:15:41,040
ah will there be a blog post excellent

00:15:38,639 --> 00:15:41,600
question um so this is actually already

00:15:41,040 --> 00:15:43,839
uh

00:15:41,600 --> 00:15:45,199
up i blogged about this a while back on

00:15:43,839 --> 00:15:46,959
the engineer better blog

00:15:45,199 --> 00:15:49,120
i'll put a link actually in the chat so

00:15:46,959 --> 00:15:50,880
that everyone can

00:15:49,120 --> 00:15:52,480
find it this is basically uh something

00:15:50,880 --> 00:15:55,839
that i i thought about

00:15:52,480 --> 00:15:57,279
as a due to going to a talk at the last

00:15:55,839 --> 00:15:59,120
summit the n a summit

00:15:57,279 --> 00:16:00,720
and jonathan matthews who's a friend of

00:15:59,120 --> 00:16:02,880
engineer better

00:16:00,720 --> 00:16:04,399
kind of uh said something that piqued my

00:16:02,880 --> 00:16:06,079
interest about using non-transparent

00:16:04,399 --> 00:16:06,800
proxies to build a service mesh and so

00:16:06,079 --> 00:16:09,680
uh

00:16:06,800 --> 00:16:10,320
one day on a bench friday i uh played

00:16:09,680 --> 00:16:12,399
around

00:16:10,320 --> 00:16:14,000
with console and then wrote this blog

00:16:12,399 --> 00:16:16,160
about it and i thought i'd give a talk

00:16:14,000 --> 00:16:18,320
at this summit so that people could

00:16:16,160 --> 00:16:21,279
maybe get a bit more of a visual basis

00:16:18,320 --> 00:16:23,440
but in that blog post is a github

00:16:21,279 --> 00:16:25,120
link as well that should have all of the

00:16:23,440 --> 00:16:26,000
examples and all of the code that was

00:16:25,120 --> 00:16:27,279
needed to do this

00:16:26,000 --> 00:16:29,519
obviously i wouldn't recommend running

00:16:27,279 --> 00:16:31,440
in production in its current format but

00:16:29,519 --> 00:16:34,000
it should show you what you need to do

00:16:31,440 --> 00:16:36,240
and let you play around

00:16:34,000 --> 00:16:38,160
it's a dedicated repo so if people want

00:16:36,240 --> 00:16:40,240
to ask any questions or play with things

00:16:38,160 --> 00:16:41,680
then feel free to raise issues on there

00:16:40,240 --> 00:16:43,279
or as i say you can always reach out to

00:16:41,680 --> 00:16:47,199
me on cloud foundry slack and

00:16:43,279 --> 00:16:49,440
i'm normally around so uh yeah

00:16:47,199 --> 00:16:51,279
20 minutes is quite short so if you want

00:16:49,440 --> 00:17:05,839
a bit more time to play with it then

00:16:51,279 --> 00:17:05,839
feel free

00:17:09,600 --> 00:17:12,640
i'll get a question

00:17:17,839 --> 00:17:21,919
so uh i'm not sure if i i answered that

00:17:20,160 --> 00:17:23,360
at the beginning of this uh breakout

00:17:21,919 --> 00:17:26,959
session but i'm not sure if people had

00:17:23,360 --> 00:17:30,400
transferred over yet um so the answer to

00:17:26,959 --> 00:17:31,760
do you need more go routers is no

00:17:30,400 --> 00:17:33,760
none of the communication between

00:17:31,760 --> 00:17:36,160
service to service acts

00:17:33,760 --> 00:17:37,760
via the go routers in fact the envoys

00:17:36,160 --> 00:17:38,080
are the limit of the like networking

00:17:37,760 --> 00:17:40,240
like

00:17:38,080 --> 00:17:42,720
infrastructure needed there's there's

00:17:40,240 --> 00:17:44,960
the silk cni which does some things with

00:17:42,720 --> 00:17:46,000
ip tables and like network policies but

00:17:44,960 --> 00:17:48,160
that's

00:17:46,000 --> 00:17:49,360
that's all part of um like the

00:17:48,160 --> 00:17:50,559
infrastructure itself you don't need an

00:17:49,360 --> 00:17:52,960
extra component you don't need to run a

00:17:50,559 --> 00:17:54,480
thing that's any in your processes

00:17:52,960 --> 00:17:55,760
in fact you could arguably scale down

00:17:54,480 --> 00:17:56,720
the number of go routers as well as

00:17:55,760 --> 00:17:58,799
saying

00:17:56,720 --> 00:18:00,559
as if you're currently doing out to out

00:17:58,799 --> 00:18:01,520
communication via the go routers via the

00:18:00,559 --> 00:18:03,360
public routes

00:18:01,520 --> 00:18:05,039
by switching to an internal networking

00:18:03,360 --> 00:18:06,400
model you could actually save some

00:18:05,039 --> 00:18:07,440
traffic going through the go routers it

00:18:06,400 --> 00:18:09,200
doesn't need to

00:18:07,440 --> 00:18:11,840
and as i say opens you out to being able

00:18:09,200 --> 00:18:14,960
to do other tcp based protocols like

00:18:11,840 --> 00:18:16,559
grpc or you can do udp-based protocols

00:18:14,960 --> 00:18:18,400
i've used it for things like statsd in

00:18:16,559 --> 00:18:19,440
the past which is udp-based metrics

00:18:18,400 --> 00:18:21,760
protocol

00:18:19,440 --> 00:18:24,960
which can't go via the go routers due to

00:18:21,760 --> 00:18:24,960
it being all udp-based

00:18:25,120 --> 00:18:30,880
and as i say like any tcp as well

00:18:27,440 --> 00:18:30,880
without using the tcp router

00:18:34,480 --> 00:18:37,600
it's all right i don't know if anyone

00:18:36,160 --> 00:18:43,360
else was here so i just

00:18:37,600 --> 00:18:46,240
know how i'm repeating it

00:18:43,360 --> 00:18:48,240
all right got about a minute left so uh

00:18:46,240 --> 00:18:51,600
any last questions or uh

00:18:48,240 --> 00:18:53,360
we'll stop for i think stretch and uh

00:18:51,600 --> 00:18:57,840
back exercises and things something like

00:18:53,360 --> 00:18:57,840
that on the schedule

00:19:22,000 --> 00:19:29,360
is a good boss um

00:19:25,760 --> 00:19:32,000
yeah generally um as long as he's not

00:19:29,360 --> 00:19:32,000
writing code

00:19:35,760 --> 00:19:39,840
he'll agree with me on that one i hope

00:19:44,400 --> 00:19:50,240
oh pickle for sure yeah

00:19:47,840 --> 00:19:53,840
i love fermented food so definitely

00:19:50,240 --> 00:19:53,840
pickle over jam

00:19:58,240 --> 00:20:02,240
cool i feel like we've moved a bit away

00:20:00,160 --> 00:20:04,400
from uh service meshes so

00:20:02,240 --> 00:20:05,440
i'm gonna i'm gonna end that there

00:20:04,400 --> 00:20:06,880
thanks for coming everyone

00:20:05,440 --> 00:20:09,120
as i say if anyone wants to reach out

00:20:06,880 --> 00:20:10,000
either through the summit platform or

00:20:09,120 --> 00:20:12,159
via

00:20:10,000 --> 00:20:13,440
cloud foundry slack feel free or github

00:20:12,159 --> 00:20:17,760
issues

00:20:13,440 --> 00:20:17,760

YouTube URL: https://www.youtube.com/watch?v=JaVPz867BxE


