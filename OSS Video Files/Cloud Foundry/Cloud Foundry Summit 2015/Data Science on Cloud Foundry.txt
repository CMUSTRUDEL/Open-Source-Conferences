Title: Data Science on Cloud Foundry
Publication date: 2015-05-12
Playlist: Cloud Foundry Summit 2015
Description: 
	Data Science on Cloud Foundry - 07 Ian Huston, Alexander Kagoshima 720p
Captions: 
	00:00:00,530 --> 00:00:05,910
okay I think that's the last few

00:00:03,659 --> 00:00:09,330
stragglers coming in there so maybe

00:00:05,910 --> 00:00:11,759
we'll get started and my name is in

00:00:09,330 --> 00:00:14,040
Houston and along with Alex kagoshima

00:00:11,759 --> 00:00:16,470
here and we're going to talk about data

00:00:14,040 --> 00:00:18,210
science on side foundry and and

00:00:16,470 --> 00:00:20,760
something Andrew clay Schafer said in

00:00:18,210 --> 00:00:22,439
his talk this afternoon really resonated

00:00:20,760 --> 00:00:25,080
with me about we're trying to build a

00:00:22,439 --> 00:00:26,849
and a community of practice and I think

00:00:25,080 --> 00:00:28,769
that's really what we're doing here as

00:00:26,849 --> 00:00:30,990
well so we're gonna talk a little bit

00:00:28,769 --> 00:00:33,480
about how we think about doing data

00:00:30,990 --> 00:00:36,719
science on on CF but we'd also really

00:00:33,480 --> 00:00:38,129
like to hear any input from you what

00:00:36,719 --> 00:00:40,230
you've done what you've tried who I

00:00:38,129 --> 00:00:42,840
worked what hasn't worked and we'll talk

00:00:40,230 --> 00:00:47,219
a little bit about how you can maybe get

00:00:42,840 --> 00:00:49,980
involved later so first of all who are

00:00:47,219 --> 00:00:51,840
we we're both at working as data

00:00:49,980 --> 00:00:53,670
scientists at pivotal labs which is the

00:00:51,840 --> 00:00:55,829
agile software development arm of

00:00:53,670 --> 00:00:58,020
pivotal and we both actually work in

00:00:55,829 --> 00:00:59,969
Europe alex and berlin myself in london

00:00:58,020 --> 00:01:02,660
and we've been using cloud foundry for

00:00:59,969 --> 00:01:04,739
the last few years - and delivered

00:01:02,660 --> 00:01:07,290
data-driven applications for our

00:01:04,739 --> 00:01:08,760
customers and that what we really do

00:01:07,290 --> 00:01:11,210
with our customers is we try and work

00:01:08,760 --> 00:01:13,409
with them to get value out of their data

00:01:11,210 --> 00:01:15,420
maybe we just have a quick show of hands

00:01:13,409 --> 00:01:19,290
who here would identify themselves as a

00:01:15,420 --> 00:01:21,240
data scientist okay we've got a few so

00:01:19,290 --> 00:01:23,909
it's not maybe as rare as maybe I

00:01:21,240 --> 00:01:26,400
thought and who works with data

00:01:23,909 --> 00:01:29,070
scientists or you know provide services

00:01:26,400 --> 00:01:30,810
or operations for data scientists okay

00:01:29,070 --> 00:01:33,780
so a lot a lot more hands that going up

00:01:30,810 --> 00:01:35,040
and who doesn't know or has heard the

00:01:33,780 --> 00:01:37,950
buzzword but doesn't really know what a

00:01:35,040 --> 00:01:40,200
data scientist is and wonders why I keep

00:01:37,950 --> 00:01:41,640
putting those words together anyone do

00:01:40,200 --> 00:01:43,040
you all know what data science is okay

00:01:41,640 --> 00:01:47,369
that's great

00:01:43,040 --> 00:01:49,049
really brief recap then maybe is to

00:01:47,369 --> 00:01:50,280
understand you know what is a data

00:01:49,049 --> 00:01:53,490
scientist and what is part of their job

00:01:50,280 --> 00:01:56,100
and so this Venn diagram is famously

00:01:53,490 --> 00:01:58,110
created by Drew Conway and kind of shows

00:01:56,100 --> 00:02:00,149
the mix of skills you need to have to be

00:01:58,110 --> 00:02:01,860
a data scientist so you need programming

00:02:00,149 --> 00:02:03,810
skills definitely you're hacking coding

00:02:01,860 --> 00:02:05,610
skills and but you also need quite a lot

00:02:03,810 --> 00:02:07,799
of maths and statistical knowledge and

00:02:05,610 --> 00:02:09,810
then to actually apply that to a problem

00:02:07,799 --> 00:02:12,030
you need to main knowledge in one area

00:02:09,810 --> 00:02:13,860
and when you get there the intersection

00:02:12,030 --> 00:02:16,470
of all these three you get data science

00:02:13,860 --> 00:02:18,750
a data scientist may be a different way

00:02:16,470 --> 00:02:21,420
of saying it is this quote from Josh

00:02:18,750 --> 00:02:22,860
wills says that a data scientist is a

00:02:21,420 --> 00:02:24,750
person who's better at statistics than a

00:02:22,860 --> 00:02:26,940
software engineer and better at software

00:02:24,750 --> 00:02:29,160
engineering than a statistician and the

00:02:26,940 --> 00:02:31,410
point about this is that you know we're

00:02:29,160 --> 00:02:33,450
not really software engineers we don't

00:02:31,410 --> 00:02:36,240
have computer science backgrounds in the

00:02:33,450 --> 00:02:38,400
main light either a physics research

00:02:36,240 --> 00:02:39,510
background and some of the machine

00:02:38,400 --> 00:02:40,950
learning backgrounds but we didn't

00:02:39,510 --> 00:02:44,370
really go through a traditional software

00:02:40,950 --> 00:02:45,930
engineering and education and I think

00:02:44,370 --> 00:02:47,970
what that means is that something like

00:02:45,930 --> 00:02:50,480
something platform like Cloud Foundry is

00:02:47,970 --> 00:02:53,430
actually really ideal for us because and

00:02:50,480 --> 00:02:55,920
we are the people who really don't want

00:02:53,430 --> 00:02:58,280
to get bogged down in you know setting

00:02:55,920 --> 00:03:01,260
up and configuring servers and

00:02:58,280 --> 00:03:02,700
maintaining and doing operations on them

00:03:01,260 --> 00:03:04,530
because really we were trying to get as

00:03:02,700 --> 00:03:07,830
quickly to business value by

00:03:04,530 --> 00:03:11,280
understanding data and providing and

00:03:07,830 --> 00:03:13,650
some insights so you know where software

00:03:11,280 --> 00:03:15,750
developers in the past had to and stand

00:03:13,650 --> 00:03:17,520
up servers themselves and provision and

00:03:15,750 --> 00:03:19,200
do those kind of things and the data

00:03:17,520 --> 00:03:21,630
scientist that is really not my core

00:03:19,200 --> 00:03:24,120
skill my core competency so I want to be

00:03:21,630 --> 00:03:25,920
out actually doing science tasks I don't

00:03:24,120 --> 00:03:29,070
really want to be doing that so that's

00:03:25,920 --> 00:03:32,880
why clay foundry is kind of interesting

00:03:29,070 --> 00:03:34,620
for us briefly though what are the type

00:03:32,880 --> 00:03:36,420
of projects that we actually work on and

00:03:34,620 --> 00:03:37,620
well they're a wide variety of them

00:03:36,420 --> 00:03:40,680
here's three sort of simple

00:03:37,620 --> 00:03:42,000
straightforward examples and for example

00:03:40,680 --> 00:03:44,040
you could be an insurance company that

00:03:42,000 --> 00:03:45,840
wants to understand the risk you have

00:03:44,040 --> 00:03:47,070
insurable risks buildings and different

00:03:45,840 --> 00:03:49,380
places and maybe you want to understand

00:03:47,070 --> 00:03:51,420
how natural disasters like earthquakes

00:03:49,380 --> 00:03:53,519
are flooding and will affect those

00:03:51,420 --> 00:03:55,950
buildings so how much money would you

00:03:53,519 --> 00:03:58,290
lose if you know a particular country or

00:03:55,950 --> 00:03:59,519
particular region flooded and so we have

00:03:58,290 --> 00:04:03,209
a client who's trying to do this and

00:03:59,519 --> 00:04:06,480
they're trying to run large-scale very

00:04:03,209 --> 00:04:08,220
computationally intensive tasks and and

00:04:06,480 --> 00:04:09,630
what we're trying to do is trying to

00:04:08,220 --> 00:04:12,420
help them to run that in a parallel way

00:04:09,630 --> 00:04:15,239
maybe use in database systems and go

00:04:12,420 --> 00:04:18,479
from running you know maybe being able

00:04:15,239 --> 00:04:20,609
to run one or ten of these statistical

00:04:18,479 --> 00:04:22,229
procedures to being able to run thousand

00:04:20,609 --> 00:04:24,630
or 10,000 of them to get a better

00:04:22,229 --> 00:04:26,820
understanding and better insight and in

00:04:24,630 --> 00:04:29,520
effect reduce the risk

00:04:26,820 --> 00:04:31,440
they have we've heard a lot today about

00:04:29,520 --> 00:04:33,120
the Internet of Things or the industrial

00:04:31,440 --> 00:04:34,830
Internet and predictive maintenance

00:04:33,120 --> 00:04:38,370
would come under that sort of heading

00:04:34,830 --> 00:04:40,530
and this is where we have you some some

00:04:38,370 --> 00:04:42,540
mechanical thing may be hard drives or

00:04:40,530 --> 00:04:43,890
maybe it's an oil drilling platform and

00:04:42,540 --> 00:04:46,560
you're trying to predict when it'll fail

00:04:43,890 --> 00:04:49,470
because and the cost of having that

00:04:46,560 --> 00:04:52,770
system out of production is very high so

00:04:49,470 --> 00:04:54,660
I've heard people have systems with a

00:04:52,770 --> 00:04:57,150
cost of hundreds of thousands of dollars

00:04:54,660 --> 00:04:59,220
if it's out for one hour or you know one

00:04:57,150 --> 00:05:01,110
day and if we can predict when those

00:04:59,220 --> 00:05:03,510
ideas might happen we'll be able to

00:05:01,110 --> 00:05:05,310
either repair them in advance or send

00:05:03,510 --> 00:05:06,660
the right spare parts that need to be

00:05:05,310 --> 00:05:08,760
there or maybe take them out of

00:05:06,660 --> 00:05:10,860
production and put something else in its

00:05:08,760 --> 00:05:12,630
place in time that we don't actually get

00:05:10,860 --> 00:05:14,730
that downtime so we do that with a

00:05:12,630 --> 00:05:16,740
mixture of you know large scale machine

00:05:14,730 --> 00:05:18,870
learning processes understanding the

00:05:16,740 --> 00:05:21,480
live data feeds that are coming in from

00:05:18,870 --> 00:05:24,180
those industrial internet applications

00:05:21,480 --> 00:05:27,510
and trying to predict and then take

00:05:24,180 --> 00:05:28,800
action because of that and then the

00:05:27,510 --> 00:05:31,560
third one here is understanding your

00:05:28,800 --> 00:05:33,840
customer so lots of enterprises and

00:05:31,560 --> 00:05:35,220
large companies have siloed data where

00:05:33,840 --> 00:05:37,050
they understand a little bit about their

00:05:35,220 --> 00:05:38,400
customer over here and another little

00:05:37,050 --> 00:05:39,900
bit over here but these never talk to

00:05:38,400 --> 00:05:41,880
each other so trying to bring those

00:05:39,900 --> 00:05:43,290
together trying to understand your

00:05:41,880 --> 00:05:44,790
customer from a holistic point of view

00:05:43,290 --> 00:05:47,940
and then being able to provide better

00:05:44,790 --> 00:05:50,370
services better better customer and

00:05:47,940 --> 00:05:51,750
experience because of that and that's

00:05:50,370 --> 00:05:53,210
quite a lot of what we do but there's a

00:05:51,750 --> 00:05:56,130
lot of other things for example like

00:05:53,210 --> 00:06:00,900
trying to reduce fraud in banking or

00:05:56,130 --> 00:06:04,770
trying to predict the destination of you

00:06:00,900 --> 00:06:06,030
know your journey in a car and we do a

00:06:04,770 --> 00:06:08,430
lot of these different things and we

00:06:06,030 --> 00:06:10,020
want to be able to provide the services

00:06:08,430 --> 00:06:11,850
we do the data science services in a

00:06:10,020 --> 00:06:16,290
quick and easy way and get to those data

00:06:11,850 --> 00:06:18,480
driven apps so what does the data

00:06:16,290 --> 00:06:20,760
scientist really need out of a platform

00:06:18,480 --> 00:06:23,250
or what sort of infrastructure do they

00:06:20,760 --> 00:06:25,050
need to do their work really I think it

00:06:23,250 --> 00:06:27,660
boils down to three things we need

00:06:25,050 --> 00:06:30,480
somewhere to store data and some easy

00:06:27,660 --> 00:06:31,950
way to capture that data so for example

00:06:30,480 --> 00:06:34,290
in the internet of things that you know

00:06:31,950 --> 00:06:36,180
wide variety of different types of data

00:06:34,290 --> 00:06:38,370
coming in from different devices we need

00:06:36,180 --> 00:06:39,800
a way to be able to channel that data

00:06:38,370 --> 00:06:41,659
somewhere and be able to store it

00:06:39,800 --> 00:06:43,340
long term and be able to access that

00:06:41,659 --> 00:06:45,080
easily as well and not have it in

00:06:43,340 --> 00:06:47,210
long-term storage which is very hard to

00:06:45,080 --> 00:06:48,770
get at and for example I'm working with

00:06:47,210 --> 00:06:50,419
a client at the moment and we've you

00:06:48,770 --> 00:06:52,610
know tried to do a data extract very

00:06:50,419 --> 00:06:55,220
small relatively small size of data like

00:06:52,610 --> 00:06:57,139
it fit in my free Dropbox account but it

00:06:55,220 --> 00:06:58,909
took you know over 24 hours to get that

00:06:57,139 --> 00:07:00,889
extract out that was 24 hours we

00:06:58,909 --> 00:07:03,889
couldn't work on the data so we need

00:07:00,889 --> 00:07:06,530
somewhere easy to put data and access it

00:07:03,889 --> 00:07:09,710
we need somewhere where we can do

00:07:06,530 --> 00:07:12,590
large-scale intensive computations so

00:07:09,710 --> 00:07:14,960
running at scale with distributed

00:07:12,590 --> 00:07:17,479
computation systems like Apache spark or

00:07:14,960 --> 00:07:20,629
on top of Hadoop MapReduce paradigm that

00:07:17,479 --> 00:07:21,949
kind of thing but finally and this is

00:07:20,629 --> 00:07:25,030
where I really get to value we need to

00:07:21,949 --> 00:07:27,650
be able to deliver results whether that

00:07:25,030 --> 00:07:30,409
purely just as you know a list of

00:07:27,650 --> 00:07:32,990
results on a web website or it's a data

00:07:30,409 --> 00:07:35,629
data API where someone can go accesses

00:07:32,990 --> 00:07:36,680
and get and predictions for different

00:07:35,629 --> 00:07:39,289
things and alex is going to talk a

00:07:36,680 --> 00:07:42,379
little bit about that where it might be

00:07:39,289 --> 00:07:43,580
simply an interactive sort of data

00:07:42,379 --> 00:07:44,840
visualization where you're able to

00:07:43,580 --> 00:07:47,389
explore the data and see what the

00:07:44,840 --> 00:07:49,430
consequences are so we need all three of

00:07:47,389 --> 00:07:50,840
these things and I'm going to talk about

00:07:49,430 --> 00:07:53,870
the first one then alex is going to talk

00:07:50,840 --> 00:07:56,900
about the next two so I think the first

00:07:53,870 --> 00:07:58,550
of these is the data storage the how do

00:07:56,900 --> 00:08:00,590
we get data in and how do we keep it

00:07:58,550 --> 00:08:02,990
somewhere and in Cloud Foundry terms

00:08:00,590 --> 00:08:07,550
platform terms these are data services

00:08:02,990 --> 00:08:10,190
so we want an an easy way to get access

00:08:07,550 --> 00:08:12,830
to these services without me having to

00:08:10,190 --> 00:08:14,930
go and download you know Redis myself

00:08:12,830 --> 00:08:16,729
and install it and try and tune it on an

00:08:14,930 --> 00:08:18,710
easy way to get a key value store and

00:08:16,729 --> 00:08:20,690
just push things towards it and I also

00:08:18,710 --> 00:08:22,250
want and to be able to build an

00:08:20,690 --> 00:08:24,830
application that can actually feed that

00:08:22,250 --> 00:08:26,599
relatively easily as well so instead of

00:08:24,830 --> 00:08:28,069
just getting you know someone delivering

00:08:26,599 --> 00:08:30,560
me a hard drive and I have to load it up

00:08:28,069 --> 00:08:33,229
somewhere with the Internet of Things

00:08:30,560 --> 00:08:35,360
and other and you know online real-time

00:08:33,229 --> 00:08:37,219
streaming data we're going to get these

00:08:35,360 --> 00:08:38,329
streams of data in and we're going to

00:08:37,219 --> 00:08:42,320
need to be able to do something with it

00:08:38,329 --> 00:08:44,449
quickly so there's kind of a natural way

00:08:42,320 --> 00:08:46,190
of doing this in CF with data services

00:08:44,449 --> 00:08:48,440
so you can have you know your managed

00:08:46,190 --> 00:08:49,670
service and you know there's lots of

00:08:48,440 --> 00:08:51,709
examples now and I think we've heard a

00:08:49,670 --> 00:08:53,250
lot about these today and we'll tomorrow

00:08:51,709 --> 00:08:56,250
but even you know thing

00:08:53,250 --> 00:08:58,650
like highly available my sequel or Redis

00:08:56,250 --> 00:09:00,000
or even a rabbit message queue we want

00:08:58,650 --> 00:09:01,680
to be able to create them easily and we

00:09:00,000 --> 00:09:04,530
want to be able to bind our applications

00:09:01,680 --> 00:09:06,480
to them as well but you know lots of

00:09:04,530 --> 00:09:08,130
people have dedicated standalone big

00:09:06,480 --> 00:09:09,450
data infrastructure you know they might

00:09:08,130 --> 00:09:11,340
have their own Hadoop installation

00:09:09,450 --> 00:09:13,680
something like an Apache spark cluster

00:09:11,340 --> 00:09:15,870
or whatever else and user provides

00:09:13,680 --> 00:09:17,250
usually provided services allow you to

00:09:15,870 --> 00:09:19,560
connect to those really quickly and

00:09:17,250 --> 00:09:21,210
easily and enable you to use your

00:09:19,560 --> 00:09:23,190
existing infrastructure without having

00:09:21,210 --> 00:09:24,450
to manage it through Cloud Foundry now

00:09:23,190 --> 00:09:26,310
you may want to get to the point where

00:09:24,450 --> 00:09:29,550
you manage it and provision it using

00:09:26,310 --> 00:09:31,350
something like Bosh but using user

00:09:29,550 --> 00:09:34,950
provided services for now gets you to

00:09:31,350 --> 00:09:36,990
you know meet that distributed data

00:09:34,950 --> 00:09:40,980
requirement today if your service isn't

00:09:36,990 --> 00:09:43,260
managed by CFO at the moment and one

00:09:40,980 --> 00:09:44,850
good way of thinking about this is the

00:09:43,260 --> 00:09:47,460
ease with which you can switch from a

00:09:44,850 --> 00:09:49,950
test data store to a real live

00:09:47,460 --> 00:09:51,390
production data store and you know a

00:09:49,950 --> 00:09:53,580
sort of traditional way of doing this in

00:09:51,390 --> 00:09:55,260
data science might you might have to

00:09:53,580 --> 00:09:56,790
actually go and edit your files and

00:09:55,260 --> 00:09:59,130
change the way the data flow happens

00:09:56,790 --> 00:10:01,950
here we can just bind to a different

00:09:59,130 --> 00:10:05,310
service so I can have one app push to cf

00:10:01,950 --> 00:10:07,470
that it's bound to my test postgrads

00:10:05,310 --> 00:10:09,150
instance and then I push another app but

00:10:07,470 --> 00:10:11,220
I bind that to my production instance

00:10:09,150 --> 00:10:13,140
alright switch between the two sub

00:10:11,220 --> 00:10:17,190
provides a really easy way of going from

00:10:13,140 --> 00:10:18,660
one to the other so that was the data

00:10:17,190 --> 00:10:20,130
services part Alex you're going to talk

00:10:18,660 --> 00:10:23,190
a little bit about the computation and

00:10:20,130 --> 00:10:27,510
the delivery of results sure thanks

00:10:23,190 --> 00:10:32,400
again so I'm going to talk a little bit

00:10:27,510 --> 00:10:33,960
about the compute part so on the one

00:10:32,400 --> 00:10:37,440
hand I'm going to explain a little bit

00:10:33,960 --> 00:10:39,240
what are the typical challenges when we

00:10:37,440 --> 00:10:43,680
work on actual customer projects with

00:10:39,240 --> 00:10:47,130
this and so the concept of a little

00:10:43,680 --> 00:10:51,150
prototype we developed but first of all

00:10:47,130 --> 00:10:53,970
so as data scientists what we usually do

00:10:51,150 --> 00:10:56,280
in our work is we obviously we implement

00:10:53,970 --> 00:10:57,720
code so some people they have this image

00:10:56,280 --> 00:11:01,770
that we stand in front of a whiteboard

00:10:57,720 --> 00:11:03,660
with a lab code and then code stuff and

00:11:01,770 --> 00:11:06,360
C or something like that that's not how

00:11:03,660 --> 00:11:07,200
it is so what we use mainly is Python

00:11:06,360 --> 00:11:09,510
and

00:11:07,200 --> 00:11:12,720
so these are two fairly high-level

00:11:09,510 --> 00:11:14,310
languages and the reason we use them is

00:11:12,720 --> 00:11:16,950
because they have really really good

00:11:14,310 --> 00:11:18,690
library support for a lot of machine

00:11:16,950 --> 00:11:22,529
learning algorithms so these are really

00:11:18,690 --> 00:11:26,820
our favorite tools so when Ian and I

00:11:22,529 --> 00:11:29,250
started out working working on cloud

00:11:26,820 --> 00:11:33,270
foundry the first thing we found is

00:11:29,250 --> 00:11:36,900
there's no our boot pack and the Python

00:11:33,270 --> 00:11:39,990
build pack which was there is kind of mm

00:11:36,900 --> 00:11:41,760
let's say it doesn't really have a lot

00:11:39,990 --> 00:11:44,550
of the libraries out of the box that we

00:11:41,760 --> 00:11:48,420
usually need so what Ian did is he used

00:11:44,550 --> 00:11:51,720
the Anaconda Python distribution by

00:11:48,420 --> 00:11:53,160
continuum i/o and built his own belt

00:11:51,720 --> 00:11:55,380
pack out of it and if we use that

00:11:53,160 --> 00:11:58,170
there's a lot of stuff like scikit-learn

00:11:55,380 --> 00:11:59,850
for example which is a machine learning

00:11:58,170 --> 00:12:03,770
library and we can use that out of the

00:11:59,850 --> 00:12:06,630
box so that was that was very handy I

00:12:03,770 --> 00:12:09,630
used a lot of our especially in

00:12:06,630 --> 00:12:11,610
university so I'm a bigger guy so what I

00:12:09,630 --> 00:12:15,060
did is I created the build pack for R

00:12:11,610 --> 00:12:18,510
which was kind of challenging but at

00:12:15,060 --> 00:12:21,570
some point I got it done so these two

00:12:18,510 --> 00:12:23,370
things were really really helpful and

00:12:21,570 --> 00:12:24,959
really essential before we actually

00:12:23,370 --> 00:12:27,120
could anything could do anything on

00:12:24,959 --> 00:12:31,070
Cloud Foundry right so first thing first

00:12:27,120 --> 00:12:31,070
we had the build packs which was good

00:12:31,130 --> 00:12:39,750
so let's let's take a look at at our

00:12:36,540 --> 00:12:41,700
usual work so Ian already mentioned

00:12:39,750 --> 00:12:44,190
briefly what we do is we work as kind of

00:12:41,700 --> 00:12:46,980
consultants for customers of the pivotal

00:12:44,190 --> 00:12:49,940
big data suite and what we do there is

00:12:46,980 --> 00:12:52,860
we kind of try to get some meaningful

00:12:49,940 --> 00:12:56,630
valuable information out of big big data

00:12:52,860 --> 00:12:59,100
sets so the way this happens in practice

00:12:56,630 --> 00:13:00,990
so we work with a lot of enterprise

00:12:59,100 --> 00:13:03,750
customers so you see these siloed data

00:13:00,990 --> 00:13:06,600
and siloed systems at the customer and

00:13:03,750 --> 00:13:08,400
then what we do is we get a big data

00:13:06,600 --> 00:13:09,779
extract and put all of this and some

00:13:08,400 --> 00:13:13,290
kind of distributors a Big Data Platform

00:13:09,779 --> 00:13:15,630
which is nowadays usually HDFS and then

00:13:13,290 --> 00:13:17,940
we work on top of it with spark or

00:13:15,630 --> 00:13:19,020
something else it could also be green

00:13:17,940 --> 00:13:21,630
plum

00:13:19,020 --> 00:13:24,990
some that's an MPP relational database

00:13:21,630 --> 00:13:28,170
and once we have it there

00:13:24,990 --> 00:13:31,980
we are happy data scientists we can see

00:13:28,170 --> 00:13:35,190
all the data with with great speed so we

00:13:31,980 --> 00:13:36,930
don't need to so we don't need to go

00:13:35,190 --> 00:13:38,520
through long running extract processes

00:13:36,930 --> 00:13:41,040
because these already took place

00:13:38,520 --> 00:13:43,650
so we already pushed everything over

00:13:41,040 --> 00:13:46,620
there and what we do over there is we

00:13:43,650 --> 00:13:49,260
develop the actual models so we think

00:13:46,620 --> 00:13:52,560
about how can we for example let's say

00:13:49,260 --> 00:13:56,280
for a specific specific customer predict

00:13:52,560 --> 00:13:58,650
his lifetime value for example we use

00:13:56,280 --> 00:14:00,960
different statistical models machine

00:13:58,650 --> 00:14:03,030
learning models that we train there so

00:14:00,960 --> 00:14:04,380
we show a lot of data to that particular

00:14:03,030 --> 00:14:07,080
algorithm and then that algorithm

00:14:04,380 --> 00:14:10,140
somehow learns how valuable our customer

00:14:07,080 --> 00:14:12,500
is so everything happens over there but

00:14:10,140 --> 00:14:16,500
the big problem is actually how do we

00:14:12,500 --> 00:14:18,210
push this model back here because the

00:14:16,500 --> 00:14:20,610
the business they actually need the

00:14:18,210 --> 00:14:22,500
prediction here in their legacy system

00:14:20,610 --> 00:14:25,620
landscape right so that's that's

00:14:22,500 --> 00:14:27,030
actually kind of a big issue that we

00:14:25,620 --> 00:14:32,970
face in a lot of our customer

00:14:27,030 --> 00:14:35,340
engagements very often after we created

00:14:32,970 --> 00:14:36,690
a really fancy model we created a really

00:14:35,340 --> 00:14:38,910
great algorithm and then we show a

00:14:36,690 --> 00:14:41,520
PowerPoint but then the model kind of

00:14:38,910 --> 00:14:44,370
dies in the PowerPoint is what we say so

00:14:41,520 --> 00:14:46,050
nothing and not a lot happens so this is

00:14:44,370 --> 00:14:49,380
kind of the issue that we that we have

00:14:46,050 --> 00:14:51,600
and we were looking at some ideas on how

00:14:49,380 --> 00:14:56,910
to solve that with Cloud Foundry which

00:14:51,600 --> 00:14:59,010
leads to roughly two thoughts on how you

00:14:56,910 --> 00:15:00,870
can actually do data science on Cloud

00:14:59,010 --> 00:15:03,960
Foundry so this is just a very rough

00:15:00,870 --> 00:15:07,260
idea on how we think about this a lot of

00:15:03,960 --> 00:15:09,990
different variants to it but essentially

00:15:07,260 --> 00:15:12,960
so what you can do let's start here on

00:15:09,990 --> 00:15:15,050
the right side what you can do is keep

00:15:12,960 --> 00:15:17,760
using your Big Data Platform

00:15:15,050 --> 00:15:19,860
which is good because there's a lot of

00:15:17,760 --> 00:15:21,960
libraries there you can use SPARC and

00:15:19,860 --> 00:15:24,930
you can do the computation on the data

00:15:21,960 --> 00:15:26,700
in place which is very good and you kind

00:15:24,930 --> 00:15:29,460
of use Cloud Foundry mainly as a

00:15:26,700 --> 00:15:31,650
visualization thing so once you have

00:15:29,460 --> 00:15:32,579
some aggregated results you you are able

00:15:31,650 --> 00:15:34,529
to

00:15:32,579 --> 00:15:38,279
to show it to your customer in a web app

00:15:34,529 --> 00:15:42,029
that you deploy on Cloud Foundry which

00:15:38,279 --> 00:15:43,980
is good the other approach is that you

00:15:42,029 --> 00:15:46,170
actually somehow try to leverage the

00:15:43,980 --> 00:15:49,499
compute power that's available in Cloud

00:15:46,170 --> 00:15:51,569
Foundry and use the big data store just

00:15:49,499 --> 00:15:55,139
for storage so you don't do any

00:15:51,569 --> 00:15:57,119
computation in there yeah so these are

00:15:55,139 --> 00:15:59,910
the two different approaches there's

00:15:57,119 --> 00:16:01,860
also some variance to it let's say you

00:15:59,910 --> 00:16:03,269
don't want to store the data for some

00:16:01,860 --> 00:16:05,549
reason and you can just leave that out

00:16:03,269 --> 00:16:07,379
and just do some online learning

00:16:05,549 --> 00:16:08,910
computations up there so there's

00:16:07,379 --> 00:16:13,230
different variances but these are the

00:16:08,910 --> 00:16:16,009
two rough ideas how you could do it so

00:16:13,230 --> 00:16:20,579
what we did is we created this prototype

00:16:16,009 --> 00:16:23,369
of a prediction API we call it so what

00:16:20,579 --> 00:16:26,549
we want to do with it is basically have

00:16:23,369 --> 00:16:30,089
a better way of actually interfacing

00:16:26,549 --> 00:16:34,199
with other software so this is actually

00:16:30,089 --> 00:16:37,290
deployed at des on CF CF EPS dot IO when

00:16:34,199 --> 00:16:39,119
you go on there you just get the readme

00:16:37,290 --> 00:16:41,759
landing page basically which tells you

00:16:39,119 --> 00:16:44,100
how you can send Jason there to to do

00:16:41,759 --> 00:16:46,169
stuff with the API and if you're in the

00:16:44,100 --> 00:16:49,499
pivotal organization on github you can

00:16:46,169 --> 00:16:51,389
actually get the code here so what does

00:16:49,499 --> 00:16:53,850
this do so basically you have this REST

00:16:51,389 --> 00:16:56,399
API endpoint and you can send it a

00:16:53,850 --> 00:16:58,439
request that says hey create your model

00:16:56,399 --> 00:17:02,850
which then creates a model in the

00:16:58,439 --> 00:17:05,399
backend that model then is able to

00:17:02,850 --> 00:17:08,970
ingest data so you send the data as a

00:17:05,399 --> 00:17:10,860
JSON blob as well and it's kicking of

00:17:08,970 --> 00:17:12,419
some periodic retraining so in machine

00:17:10,860 --> 00:17:14,339
learning there's this notion of training

00:17:12,419 --> 00:17:15,720
you show the model a lot of data and

00:17:14,339 --> 00:17:20,100
then the model gets smarter and smarter

00:17:15,720 --> 00:17:22,289
about the data so this this framework is

00:17:20,100 --> 00:17:25,319
actually able to do some periodic

00:17:22,289 --> 00:17:29,159
retraining saves everything in Redis for

00:17:25,319 --> 00:17:32,309
now which you can bind really easily on

00:17:29,159 --> 00:17:35,100
Cloud Foundry and then you can also kind

00:17:32,309 --> 00:17:38,070
of send scoring requests to this API so

00:17:35,100 --> 00:17:39,899
you tell it you you let it know about a

00:17:38,070 --> 00:17:41,610
data point for example all the

00:17:39,899 --> 00:17:44,880
transactions of a customer and then the

00:17:41,610 --> 00:17:46,140
model gives you a prediction back on how

00:17:44,880 --> 00:17:49,200
valuable that customers

00:17:46,140 --> 00:17:54,059
for example so this is kind of the the

00:17:49,200 --> 00:17:56,700
API idea that we have and on how we can

00:17:54,059 --> 00:18:00,630
actually leverage Cloud Foundry for data

00:17:56,700 --> 00:18:04,679
science we created this kind of

00:18:00,630 --> 00:18:06,420
interface which which means you

00:18:04,679 --> 00:18:08,670
basically if you want to create a model

00:18:06,420 --> 00:18:11,040
in that kind of framework you have to

00:18:08,670 --> 00:18:12,480
implement this class interface which

00:18:11,040 --> 00:18:14,309
means you need to have a trained

00:18:12,480 --> 00:18:16,170
function a score function and get

00:18:14,309 --> 00:18:18,990
parameters function and this is all done

00:18:16,170 --> 00:18:20,669
in Python oh and by the way this is

00:18:18,990 --> 00:18:24,870
using Ian's Python build pack I

00:18:20,669 --> 00:18:26,910
mentioned previously so what have some

00:18:24,870 --> 00:18:29,730
data-driven applications that we did

00:18:26,910 --> 00:18:32,520
what are some examples on our work so

00:18:29,730 --> 00:18:34,770
one thing which is really cool which Ian

00:18:32,520 --> 00:18:39,540
created is this Transport for London

00:18:34,770 --> 00:18:42,960
demo um so what this does is it creates

00:18:39,540 --> 00:18:45,990
a live feed of all the disruptions on

00:18:42,960 --> 00:18:47,850
London streets and then you can see the

00:18:45,990 --> 00:18:51,030
current disruptions that are happening

00:18:47,850 --> 00:18:53,820
but what it also does is it gives you a

00:18:51,030 --> 00:18:56,010
prediction on how long these disruptions

00:18:53,820 --> 00:18:58,260
are going to last and that is based on

00:18:56,010 --> 00:19:03,270
historical data so we we scrape this

00:18:58,260 --> 00:19:05,549
data feed store it show it show the life

00:19:03,270 --> 00:19:06,960
status put some predictions in there and

00:19:05,549 --> 00:19:09,900
the model also gets periodically

00:19:06,960 --> 00:19:11,669
retrained on the historical data and you

00:19:09,900 --> 00:19:12,780
can you can access it right there I

00:19:11,669 --> 00:19:14,970
think it's first say this is like the

00:19:12,780 --> 00:19:17,370
simplest possible way of using a phone

00:19:14,970 --> 00:19:21,870
yeah yes so this is a website this is

00:19:17,370 --> 00:19:27,179
basically the right approach did you see

00:19:21,870 --> 00:19:31,590
here another thing that I created with

00:19:27,179 --> 00:19:34,350
my our build pack is and we call it

00:19:31,590 --> 00:19:39,270
insurance demo so it's basically an

00:19:34,350 --> 00:19:41,730
insurance data set and this this app

00:19:39,270 --> 00:19:45,660
basically allows you to to explore the

00:19:41,730 --> 00:19:48,929
data a little bit and the the goal here

00:19:45,660 --> 00:19:50,960
is to find valuable new customers and

00:19:48,929 --> 00:19:55,290
what you can do in this app is try to

00:19:50,960 --> 00:19:57,690
create some rules manually but also it

00:19:55,290 --> 00:19:59,640
lets you just train a model that picks

00:19:57,690 --> 00:20:01,650
out these customers for you and

00:19:59,640 --> 00:20:04,320
you can compare the performance of your

00:20:01,650 --> 00:20:08,160
manual rules and the model and the model

00:20:04,320 --> 00:20:09,720
is usually a lot better now that's an

00:20:08,160 --> 00:20:12,150
example of the second one where the

00:20:09,720 --> 00:20:15,810
computation is actually happening in the

00:20:12,150 --> 00:20:17,400
cloud foundry itself and so it's not

00:20:15,810 --> 00:20:19,950
happening on the big data platform

00:20:17,400 --> 00:20:21,600
yes so the it's possible in this case

00:20:19,950 --> 00:20:23,820
because the data set is really small

00:20:21,600 --> 00:20:28,140
it's like a megabyte or something like

00:20:23,820 --> 00:20:30,510
that okay so these are two examples on

00:20:28,140 --> 00:20:32,550
data driven applications with it with

00:20:30,510 --> 00:20:35,550
that I'm going to hand it over to Ian

00:20:32,550 --> 00:20:37,410
again yeah I think you know these are

00:20:35,550 --> 00:20:39,510
two public examples you've done quite a

00:20:37,410 --> 00:20:40,890
lot of customer work as well where we've

00:20:39,510 --> 00:20:42,780
used these ideas and we've gone a bit

00:20:40,890 --> 00:20:43,920
further in those but what we really want

00:20:42,780 --> 00:20:45,950
to hear is about the rest of the

00:20:43,920 --> 00:20:49,140
community and what they're doing it I'm

00:20:45,950 --> 00:20:51,000
already gone down to the G booth and

00:20:49,140 --> 00:20:52,470
heard a little bit about predicts and

00:20:51,000 --> 00:20:53,940
but I'm sure there's a lot of other

00:20:52,470 --> 00:20:55,620
examples in the community of people

00:20:53,940 --> 00:20:58,200
right where people are using Cloud

00:20:55,620 --> 00:21:01,500
Foundry to not only just display results

00:20:58,200 --> 00:21:03,990
but maybe provide data api's and provide

00:21:01,500 --> 00:21:05,520
you know understand some of the sort of

00:21:03,990 --> 00:21:07,290
issues we're talking about so we'd be

00:21:05,520 --> 00:21:09,690
really happy to hear anything that

00:21:07,290 --> 00:21:11,250
anyone has to say about that and we said

00:21:09,690 --> 00:21:13,830
if this Web site is a place where you

00:21:11,250 --> 00:21:16,380
can like just show examples of how to do

00:21:13,830 --> 00:21:17,880
these kind of things and you can send us

00:21:16,380 --> 00:21:19,290
something on our Twitter account but

00:21:17,880 --> 00:21:21,600
also we'd be happy to hear right now if

00:21:19,290 --> 00:21:25,340
anyone's doing any of this or if you

00:21:21,600 --> 00:21:25,340
have any other questions as well so

00:21:26,000 --> 00:21:35,040
questions okay and what well I think it

00:21:32,280 --> 00:21:37,500
depends on hi I'm the if you're setting

00:21:35,040 --> 00:21:39,300
it up internally on your your own CF

00:21:37,500 --> 00:21:42,420
instance you just have to provision it

00:21:39,300 --> 00:21:44,370
as you will I'm the say on PWS which is

00:21:42,420 --> 00:21:47,640
the pivotal web services and that's

00:21:44,370 --> 00:21:49,440
cloud provided Redis so you keep paying

00:21:47,640 --> 00:21:53,430
for higher and higher levels higher

00:21:49,440 --> 00:21:56,130
higher tiers of service but you know I

00:21:53,430 --> 00:21:58,200
think it goes up for quite a far way at

00:21:56,130 --> 00:22:01,470
the moment I mean Redis isn't really

00:21:58,200 --> 00:22:05,550
made for the storage of really large

00:22:01,470 --> 00:22:10,110
amounts it's in memory so it's features

00:22:05,550 --> 00:22:12,360
that it's quick but I mean for for this

00:22:10,110 --> 00:22:13,380
prediction API architecture that I

00:22:12,360 --> 00:22:15,750
showed

00:22:13,380 --> 00:22:17,580
this is mainly we think of it as kind of

00:22:15,750 --> 00:22:20,070
a prototype proof-of-concept type of

00:22:17,580 --> 00:22:21,690
thing that we eventually also want to

00:22:20,070 --> 00:22:24,630
hook up to something like spark for

00:22:21,690 --> 00:22:30,750
example so we can also do batch training

00:22:24,630 --> 00:22:33,630
on really large data sets so that's good

00:22:30,750 --> 00:22:36,360
that's a good question so in the example

00:22:33,630 --> 00:22:39,810
Alex showed the ingest is just again

00:22:36,360 --> 00:22:42,450
REST API that you can and send data to

00:22:39,810 --> 00:22:44,190
for example we've you've helped build

00:22:42,450 --> 00:22:47,070
this connected car demo which is

00:22:44,190 --> 00:22:49,350
streaming data live back from a car like

00:22:47,070 --> 00:22:52,590
a widget stuck into your car and it just

00:22:49,350 --> 00:22:55,410
hits a HTTP endpoint and that's provided

00:22:52,590 --> 00:22:57,600
by a CF app and then the CF app knows

00:22:55,410 --> 00:23:00,090
you've sent some data to me

00:22:57,600 --> 00:23:01,500
I'll go store it and I'll run my you

00:23:00,090 --> 00:23:10,620
know machine learning on run my scoring

00:23:01,500 --> 00:23:13,350
on top of that yeah yeah exactly so you

00:23:10,620 --> 00:23:15,990
know there's basically you know there

00:23:13,350 --> 00:23:18,870
was a talk earlier about how CF right

00:23:15,990 --> 00:23:21,690
now uses HTTP as the transport but there

00:23:18,870 --> 00:23:25,020
might there is moves to use also use TCP

00:23:21,690 --> 00:23:27,180
because that allows you to move to use

00:23:25,020 --> 00:23:29,340
other things I aim kewpie and other ways

00:23:27,180 --> 00:23:30,660
of getting data in because you know the

00:23:29,340 --> 00:23:33,090
Internet of Things runs on a lot of

00:23:30,660 --> 00:23:36,410
different protocols not just I think

00:23:33,090 --> 00:23:36,410
there was some more questions yeah

00:23:48,530 --> 00:23:56,640
you know I mean one thing you could

00:23:52,890 --> 00:23:59,850
think about this so I'm actually using

00:23:56,640 --> 00:24:03,200
spark and some customer projects now and

00:23:59,850 --> 00:24:05,370
I'm using PI spark and since the

00:24:03,200 --> 00:24:08,070
prototype that we wrote it's written in

00:24:05,370 --> 00:24:11,940
pison you could actually easily

00:24:08,070 --> 00:24:13,710
integrate PI spark with some spark

00:24:11,940 --> 00:24:16,110
back-end that you have running somewhere

00:24:13,710 --> 00:24:18,390
so I think you know right now you're

00:24:16,110 --> 00:24:20,820
using a spark instance that's separate

00:24:18,390 --> 00:24:22,440
you know it's on your standalone Big

00:24:20,820 --> 00:24:24,810
Data hardware a big data infrastructure

00:24:22,440 --> 00:24:26,610
where I'd like to get to and I don't

00:24:24,810 --> 00:24:28,020
know you know what sort of timescales

00:24:26,610 --> 00:24:30,300
Israel I'd like to be able to provision

00:24:28,020 --> 00:24:32,760
a spark cluster the same way as I

00:24:30,300 --> 00:24:36,240
provision today I confusion a Cassandra

00:24:32,760 --> 00:24:37,770
cluster in PCF so like you know I can do

00:24:36,240 --> 00:24:40,620
that all through Cloud Foundry maybe

00:24:37,770 --> 00:24:42,810
Bosh's provisioning spark and I can just

00:24:40,620 --> 00:24:45,090
bind to that so that would be the ideal

00:24:42,810 --> 00:24:47,520
thing for me like I don't want to yeah

00:24:45,090 --> 00:24:49,380
you know I want the minimum amount of

00:24:47,520 --> 00:24:51,390
fuss for me to get access to something

00:24:49,380 --> 00:24:52,950
so it's the difference you know we heard

00:24:51,390 --> 00:24:55,350
Android cliche we talked about a bit

00:24:52,950 --> 00:24:57,120
about know the old days of provisioning

00:24:55,350 --> 00:24:58,740
a web application is you go and request

00:24:57,120 --> 00:25:00,330
a server and it takes three months and

00:24:58,740 --> 00:25:02,520
then someone has to set it up that's

00:25:00,330 --> 00:25:05,130
kind of still the same for big data

00:25:02,520 --> 00:25:07,290
infrastructure today and in many ways

00:25:05,130 --> 00:25:10,460
especially for on-premises it's

00:25:07,290 --> 00:25:13,290
sometimes even longer than three months

00:25:10,460 --> 00:25:15,810
so but you know you can imagine people

00:25:13,290 --> 00:25:18,030
obviously spin up AWS and you have SPARC

00:25:15,810 --> 00:25:20,580
living on there but it you know we also

00:25:18,030 --> 00:25:22,680
have you know large bits of kit being

00:25:20,580 --> 00:25:27,090
moved around so if you make it easier

00:25:22,680 --> 00:25:28,860
for people to to start and get to get to

00:25:27,090 --> 00:25:30,920
starch their data science work as

00:25:28,860 --> 00:25:33,270
quickly as possible and then that's

00:25:30,920 --> 00:25:35,910
provisioning and through cf4 Bosch will

00:25:33,270 --> 00:25:38,060
be the way I'd see that going christen

00:25:35,910 --> 00:25:38,060
there

00:26:01,570 --> 00:26:05,360
that's a good question I think you know

00:26:04,010 --> 00:26:07,790
I don't think I have a hard and fast

00:26:05,360 --> 00:26:10,520
rule I think yeah the way everything's

00:26:07,790 --> 00:26:13,580
going is to be more distributed rather

00:26:10,520 --> 00:26:15,830
than you know one single and large VM

00:26:13,580 --> 00:26:18,710
set obviously there are some overheads

00:26:15,830 --> 00:26:21,320
but you have people running large scale

00:26:18,710 --> 00:26:23,840
machine learning systems purely on top

00:26:21,320 --> 00:26:26,870
of AWS with all this sort of overhead

00:26:23,840 --> 00:26:29,450
that that entails and you know they you

00:26:26,870 --> 00:26:31,730
know someone like Netflix is able to run

00:26:29,450 --> 00:26:33,710
their machine learning pipeline purely

00:26:31,730 --> 00:26:35,780
on on that infrastructure without having

00:26:33,710 --> 00:26:38,270
to go down to bare metal and at any

00:26:35,780 --> 00:26:39,350
points so it's definitely doable and you

00:26:38,270 --> 00:26:41,210
probably have to be a little bit clever

00:26:39,350 --> 00:26:43,220
about it because you're not you know

00:26:41,210 --> 00:26:44,360
getting a hundred percent of the speed

00:26:43,220 --> 00:26:46,520
that you weren't in bare metal but

00:26:44,360 --> 00:26:48,320
you're what you're gaining is the ease

00:26:46,520 --> 00:26:49,190
to provision and the ease of getting

00:26:48,320 --> 00:26:51,440
started

00:26:49,190 --> 00:26:52,850
whereas on bare metal you know you have

00:26:51,440 --> 00:27:04,840
to then be responsible for maintaining

00:26:52,850 --> 00:27:04,840
all of that yeah yeah

00:27:22,570 --> 00:27:33,380
yes that I would say there's no general

00:27:30,920 --> 00:27:35,480
rule of thumb that you can apply here I

00:27:33,380 --> 00:27:38,090
mean it also highly depends on the use

00:27:35,480 --> 00:27:40,700
case that you have so I would say in

00:27:38,090 --> 00:27:42,410
general if you follow that traditional

00:27:40,700 --> 00:27:44,510
approach where you have one big data

00:27:42,410 --> 00:27:46,100
extract and you put that somewhere then

00:27:44,510 --> 00:27:48,080
I would definitely do that

00:27:46,100 --> 00:27:50,090
on top of spark so not inside of Cloud

00:27:48,080 --> 00:27:54,980
Foundry but somewhere where I have the

00:27:50,090 --> 00:27:56,240
storage and the compute together yeah

00:27:54,980 --> 00:27:57,770
yeah yeah

00:27:56,240 --> 00:28:00,470
if the data is streaming in there maybe

00:27:57,770 --> 00:28:02,330
it's a if if the data is streaming in

00:28:00,470 --> 00:28:03,740
then it might make sense to deploy some

00:28:02,330 --> 00:28:05,720
online learning on Cloud Foundry

00:28:03,740 --> 00:28:07,880
directly and I think the other thing to

00:28:05,720 --> 00:28:10,520
think about is you know Cloud Foundry

00:28:07,880 --> 00:28:12,920
installations may be originally set up

00:28:10,520 --> 00:28:15,470
for web applications which don't needs

00:28:12,920 --> 00:28:17,030
large volumes of round compared to maybe

00:28:15,470 --> 00:28:19,160
some machine learning applications so

00:28:17,030 --> 00:28:21,580
for example on on the hosted versions it

00:28:19,160 --> 00:28:23,900
tends to be like a two gig ram limit and

00:28:21,580 --> 00:28:26,630
but you know really I'd want you know a

00:28:23,900 --> 00:28:30,380
lot more memory for if I was to do this

00:28:26,630 --> 00:28:32,630
you know honor as a CF app inside the CF

00:28:30,380 --> 00:28:36,140
installation so maybe what you get is

00:28:32,630 --> 00:28:39,020
you know resource pools that have much

00:28:36,140 --> 00:28:40,370
better I think this is going to be part

00:28:39,020 --> 00:28:42,950
of Diego if I'm not wrong someone

00:28:40,370 --> 00:28:44,540
correct me here and you assign resource

00:28:42,950 --> 00:28:46,370
pools that have a lot better

00:28:44,540 --> 00:28:49,520
infrastructure for you know a big data

00:28:46,370 --> 00:28:52,100
computation and let your pick those when

00:28:49,520 --> 00:28:53,470
it needs to so I think that's you know

00:28:52,100 --> 00:28:57,580
it's about how much you give the

00:28:53,470 --> 00:28:59,690
application each time any more questions

00:28:57,580 --> 00:29:04,749
okay thank you very very much

00:28:59,690 --> 00:29:04,749

YouTube URL: https://www.youtube.com/watch?v=n95hCVvuPKQ


