Title: Monitoring Cloud Foundry Infrastructure and Applications with Stackdriver and BigQuery
Publication date: 2017-06-22
Playlist: Cloud Foundry Summit Silicon Valley 2017
Description: 
	Monitoring Cloud Foundry Infrastructure and Applications with Stackdriver and BigQuery [I] - Jeff Johnson, Google    

Create a single pane of glass for your Cloud Foundry deployment, search through application logs, and be alerted on errors with Stackdriver Logging and Monitoring. This talk will look at the open source Stackdriver Nozzle developed by Google and Pivotal and walk through useful features for operators and developers alike including the ability to stream logs into Stackdriver.

Jeff Johnson
Jeff is a Software Engineer at Google who is giving developers super powers by integrating the tools that run Google with open source Cloud Foundry. He has worked closely with the excellent engineers at Pivotal on the stackdriver-tools BOSH release to integrate Google's Logging, Monitoring, Tracing, and Debugging with Cloud Foundry. Today he is working with Pivotal on bringing Kubernetes' container orchestration strengths to complement Cloud Foundry applications. Check out the Pivotal Cloud Foundry on Google Cloud Platform web series for a hint of what's to come.
Captions: 
	00:00:00,770 --> 00:00:05,400
all right good afternoon everybody my

00:00:03,060 --> 00:00:07,290
name is Jeff Johnson I'm a software

00:00:05,400 --> 00:00:09,120
engineer at Google I work on the Cloud

00:00:07,290 --> 00:00:11,690
Foundry team with a lot of the folks

00:00:09,120 --> 00:00:13,469
who've been speaking in this room today

00:00:11,690 --> 00:00:15,870
I'm going to talk to you today about

00:00:13,469 --> 00:00:18,840
stackdriver and what it means for Cloud

00:00:15,870 --> 00:00:19,619
Foundry we're gonna show you how you can

00:00:18,840 --> 00:00:22,260
use stackdriver

00:00:19,619 --> 00:00:24,570
to monitor alert on Cloud Foundry and

00:00:22,260 --> 00:00:29,820
use bigquery to do some analytics with

00:00:24,570 --> 00:00:32,579
that data so stackdriver is the suite of

00:00:29,820 --> 00:00:36,840
monitoring logging and diagnostics tools

00:00:32,579 --> 00:00:38,460
for GCP and AWS with stackdriver you get

00:00:36,840 --> 00:00:41,010
a lot of the things you expect you know

00:00:38,460 --> 00:00:43,230
you get logs you get the tools you

00:00:41,010 --> 00:00:45,300
expect the the dashboards we support

00:00:43,230 --> 00:00:48,210
your favorite you know languages but

00:00:45,300 --> 00:00:49,170
there's some awesome in there the

00:00:48,210 --> 00:00:51,210
awesome are some things I'm going to

00:00:49,170 --> 00:00:53,449
show you like doing an Al's like

00:00:51,210 --> 00:00:55,649
streaming data live in a big query

00:00:53,449 --> 00:00:57,300
debugging your production app which has

00:00:55,649 --> 00:01:00,449
been shown today so I won't go into that

00:00:57,300 --> 00:01:03,090
and the fact that it's a Google scale

00:01:00,449 --> 00:01:04,439
product it's an API you write to in the

00:01:03,090 --> 00:01:06,450
cloud you don't need to worry about

00:01:04,439 --> 00:01:08,280
scaling up that pipeline and you don't

00:01:06,450 --> 00:01:10,890
need to worry about doing some nations

00:01:08,280 --> 00:01:14,610
of data and all that sorts of stuff it

00:01:10,890 --> 00:01:18,420
was released into GA GCP next 2016 so

00:01:14,610 --> 00:01:20,150
it's been out there for a bit but how do

00:01:18,420 --> 00:01:23,810
we integrate it with Cloud Foundry I

00:01:20,150 --> 00:01:25,830
think that's we say we have a cool piece

00:01:23,810 --> 00:01:27,570
we want to stick it together with this

00:01:25,830 --> 00:01:28,560
other cool thing we like that's not

00:01:27,570 --> 00:01:30,240
really the right approach we want to

00:01:28,560 --> 00:01:32,520
take let's think about sort of the

00:01:30,240 --> 00:01:35,340
motivation behind this I think there's

00:01:32,520 --> 00:01:37,829
two personas to think about you've got a

00:01:35,340 --> 00:01:40,020
developer the developer has applications

00:01:37,829 --> 00:01:42,210
that they need to monitor they want to

00:01:40,020 --> 00:01:45,060
be alerted on and dive into issues

00:01:42,210 --> 00:01:47,460
quickly you've got the operator who's

00:01:45,060 --> 00:01:49,380
got a much broader set of issues who

00:01:47,460 --> 00:01:51,060
isn't really concerned necessarily with

00:01:49,380 --> 00:01:53,780
specific applications but really

00:01:51,060 --> 00:01:56,340
concerned about the health of the system

00:01:53,780 --> 00:01:58,710
so that operator needs a single pane of

00:01:56,340 --> 00:02:00,060
glass and they need alerting as well but

00:01:58,710 --> 00:02:03,469
they need to be able to just add a

00:02:00,060 --> 00:02:03,469
glance make sure things are ok

00:02:04,759 --> 00:02:09,239
stackdriver tools is the Bosch release

00:02:07,200 --> 00:02:12,030
that we developed in conjunction with

00:02:09,239 --> 00:02:14,489
pivotal stack driver tools is in the

00:02:12,030 --> 00:02:17,610
Cloud Foundry community and is available

00:02:14,489 --> 00:02:20,220
today what we provide insect revver

00:02:17,610 --> 00:02:23,069
tools is both his first application

00:02:20,220 --> 00:02:25,230
monitoring this is taking data logs and

00:02:23,069 --> 00:02:29,760
metrics from Cloud Foundry slogra Gator

00:02:25,230 --> 00:02:31,730
and adjusting them into stack driver the

00:02:29,760 --> 00:02:34,170
other piece that gives you is the

00:02:31,730 --> 00:02:35,970
infrastructure and virtual machine level

00:02:34,170 --> 00:02:38,340
monitoring so there's two separate

00:02:35,970 --> 00:02:41,190
agents that stackdriver provides one is

00:02:38,340 --> 00:02:43,230
to collect logs which is through fluent

00:02:41,190 --> 00:02:45,330
D and the other is to collect metrics

00:02:43,230 --> 00:02:46,680
things that the hypervisor can't really

00:02:45,330 --> 00:02:49,560
find on its own that you need active

00:02:46,680 --> 00:02:51,120
monitoring for it was released into

00:02:49,560 --> 00:02:54,810
general availability in the spring of

00:02:51,120 --> 00:03:00,120
2017 and the nozzle portion of it is

00:02:54,810 --> 00:03:03,540
available today on pivot as a tile so

00:03:00,120 --> 00:03:05,040
let's look at what a what what all these

00:03:03,540 --> 00:03:08,519
three pieces sort of look like in

00:03:05,040 --> 00:03:11,909
practice so this box here of course is a

00:03:08,519 --> 00:03:13,530
virtual machine and that machine happens

00:03:11,909 --> 00:03:16,409
to be a Diego cell runs some

00:03:13,530 --> 00:03:18,269
applications that kind of thing on that

00:03:16,409 --> 00:03:20,370
machine we're gonna co-locate two jobs

00:03:18,269 --> 00:03:22,709
that's the stack driver agent that's

00:03:20,370 --> 00:03:24,260
metrics and Google fluent D which is

00:03:22,709 --> 00:03:26,489
logging

00:03:24,260 --> 00:03:29,069
having those agents on the machine and

00:03:26,489 --> 00:03:30,930
giving them some credentials lets them

00:03:29,069 --> 00:03:34,459
write directly to stack driver so each

00:03:30,930 --> 00:03:34,459
one streams directly to that endpoint

00:03:34,489 --> 00:03:38,450
now since we have a Diego cell we have

00:03:37,080 --> 00:03:40,950
application logs

00:03:38,450 --> 00:03:42,390
those application logs come from the

00:03:40,950 --> 00:03:44,159
application and are collected by the

00:03:42,390 --> 00:03:46,980
Metron agent running on that machine and

00:03:44,159 --> 00:03:48,959
go through the logger gator now there

00:03:46,980 --> 00:03:50,970
are people potential in this room who

00:03:48,959 --> 00:03:54,150
have written the logger Gator so I'm not

00:03:50,970 --> 00:03:55,799
gonna go into depth about it but I have

00:03:54,150 --> 00:03:57,420
represented it as this alligator who

00:03:55,799 --> 00:03:59,879
will go ahead and spit the logs out to

00:03:57,420 --> 00:04:02,730
our stack driver nozzle so we have two

00:03:59,879 --> 00:04:06,620
instances in this case but you shard all

00:04:02,730 --> 00:04:06,620
your logs across a pool of these nozzles

00:04:08,450 --> 00:04:12,650
so now we'll be the tricky part

00:04:30,169 --> 00:04:36,710
if - excuse me I was gonna try to do

00:04:32,599 --> 00:04:38,749
this on my laptop my normal laptop but

00:04:36,710 --> 00:04:41,479
is a Linux machine as soon as I plugged

00:04:38,749 --> 00:04:42,710
it in it crashed so we've made a quick

00:04:41,479 --> 00:04:45,439
change I'm gonna figure out how to use

00:04:42,710 --> 00:04:46,879
this Mac so I have this cloud foundry

00:04:45,439 --> 00:04:49,069
application on the right a left hand

00:04:46,879 --> 00:04:52,189
side it's not very interesting it logs

00:04:49,069 --> 00:04:59,629
out to standard error standard out I'm

00:04:52,189 --> 00:05:01,870
gonna pull up stack driver logging few

00:04:59,629 --> 00:05:01,870
ticks

00:05:05,450 --> 00:05:08,830
there's Michael abscess

00:05:13,479 --> 00:05:16,509
and I'm gonna start streaming lakhs from

00:05:15,909 --> 00:05:19,659
stackdriver

00:05:16,509 --> 00:05:22,900
so this Cloud Foundry deployment I have

00:05:19,659 --> 00:05:25,360
right now is three actual three separate

00:05:22,900 --> 00:05:28,270
cloud foundries in a single GCP project

00:05:25,360 --> 00:05:29,439
that's sort of around the world and I'll

00:05:28,270 --> 00:05:32,650
talk a little bit more about that in my

00:05:29,439 --> 00:05:34,210
next spanner talk but what we have here

00:05:32,650 --> 00:05:35,620
is a lot of data coming in and these are

00:05:34,210 --> 00:05:37,749
logs right now just from the logger

00:05:35,620 --> 00:05:41,800
Gator so I'm gonna go ahead and generate

00:05:37,749 --> 00:05:42,939
just a random air which you can see some

00:05:41,800 --> 00:05:45,150
other application is doing that right

00:05:42,939 --> 00:05:45,150
now

00:05:53,700 --> 00:05:59,820
okay there's our air stackdriver does

00:05:57,840 --> 00:06:01,680
structured logging so it's structured

00:05:59,820 --> 00:06:03,210
logging means is we're not just talking

00:06:01,680 --> 00:06:05,460
about lines in a log file we have

00:06:03,210 --> 00:06:09,210
additional context about the log so if

00:06:05,460 --> 00:06:11,160
we expand these labels we can see all

00:06:09,210 --> 00:06:13,440
the context about the application that

00:06:11,160 --> 00:06:16,320
this log came from so this came from my

00:06:13,440 --> 00:06:19,440
logger app we've got application ID all

00:06:16,320 --> 00:06:21,840
the stuff you'd expect and it also has a

00:06:19,440 --> 00:06:25,770
JSON payload now the log message doesn't

00:06:21,840 --> 00:06:27,240
have much more in the payload but every

00:06:25,770 --> 00:06:29,010
cloud foundry metric everything that

00:06:27,240 --> 00:06:32,160
comes through the logger Gator we retain

00:06:29,010 --> 00:06:33,990
all the fields so you can do structured

00:06:32,160 --> 00:06:36,270
queries so I'm going to do a really

00:06:33,990 --> 00:06:39,770
simple structured query and just look at

00:06:36,270 --> 00:06:39,770
the events for my application

00:06:48,540 --> 00:06:53,250
so now have a stream of just things that

00:06:50,640 --> 00:07:00,330
have happened for my application we can

00:06:53,250 --> 00:07:01,770
see here it was deployed earlier and we

00:07:00,330 --> 00:07:04,920
can stream just the same way we did with

00:07:01,770 --> 00:07:06,630
with the data before so this is awesome

00:07:04,920 --> 00:07:08,490
for sort of at a glance looking at

00:07:06,630 --> 00:07:09,470
digging into issues and looking at

00:07:08,490 --> 00:07:13,110
things that are happening now

00:07:09,470 --> 00:07:14,850
stackdriver does a 30-day retention so

00:07:13,110 --> 00:07:17,520
if you have if you're writing to

00:07:14,850 --> 00:07:19,770
stackdriver in 30 days your data starts

00:07:17,520 --> 00:07:21,930
to fall off you can choose to export

00:07:19,770 --> 00:07:23,460
that data and you exported data by

00:07:21,930 --> 00:07:27,120
creating a query just like I did here

00:07:23,460 --> 00:07:28,710
that query could just be everything you

00:07:27,120 --> 00:07:33,900
create that query and export it to a

00:07:28,710 --> 00:07:36,840
source sink sink I've chosen bigquery so

00:07:33,900 --> 00:07:39,290
I'm gonna look at bigquery in my GCP

00:07:36,840 --> 00:07:39,290
project

00:08:11,650 --> 00:08:15,740
so here's the table that represents all

00:08:14,030 --> 00:08:17,990
the data coming from stackdriver

00:08:15,740 --> 00:08:21,740
my query like I said is just give me all

00:08:17,990 --> 00:08:23,840
the lager Gator events just to show how

00:08:21,740 --> 00:08:26,360
quickly the streams let's go ahead and

00:08:23,840 --> 00:08:28,850
create a query to do a new search for a

00:08:26,360 --> 00:08:31,820
log message and see hopefully that it

00:08:28,850 --> 00:08:59,660
appears right as we create it so let me

00:08:31,820 --> 00:09:02,150
just set this mic down for a sec alright

00:08:59,660 --> 00:09:04,280
so that is there immediately that goes

00:09:02,150 --> 00:09:05,750
from your application into Metron into

00:09:04,280 --> 00:09:07,490
the logger gator and just into

00:09:05,750 --> 00:09:10,430
stackdriver and is available immediately

00:09:07,490 --> 00:09:13,310
in bigquery what's awesome about this is

00:09:10,430 --> 00:09:14,510
you can start to build up an analytics

00:09:13,310 --> 00:09:17,210
pipeline without having to necessarily

00:09:14,510 --> 00:09:19,580
worry about at each stage of the each

00:09:17,210 --> 00:09:20,930
stage how do I break this data down even

00:09:19,580 --> 00:09:22,670
more and more and more and start doing

00:09:20,930 --> 00:09:24,410
those averages and worry a little bit

00:09:22,670 --> 00:09:28,040
more about just what do you want to find

00:09:24,410 --> 00:09:30,140
out so a simple a little more complex

00:09:28,040 --> 00:09:32,570
query that I will definitely put the mic

00:09:30,140 --> 00:09:34,600
down for again is okay we've got all

00:09:32,570 --> 00:09:37,370
this information from the logger Gator

00:09:34,600 --> 00:09:38,030
one of those bits of information is from

00:09:37,370 --> 00:09:39,890
the go router

00:09:38,030 --> 00:09:41,480
so the go router is at the front end of

00:09:39,890 --> 00:09:43,880
our Cloud Foundry and it's going to

00:09:41,480 --> 00:09:47,210
receive every single event and log

00:09:43,880 --> 00:09:50,990
accordingly so what we can do is look at

00:09:47,210 --> 00:09:53,240
the payload that it gives us and we can

00:09:50,990 --> 00:09:53,840
try to figure out okay who's hitting our

00:09:53,240 --> 00:09:55,250
Cloud Foundry

00:09:53,840 --> 00:09:58,780
let's get an assessment of the user

00:09:55,250 --> 00:09:58,780
agents that are coming at us

00:10:00,700 --> 00:10:03,739
[Music]

00:10:58,680 --> 00:11:04,750
all right now this is not a cloud

00:11:02,500 --> 00:11:06,399
foundry that is very public but you can

00:11:04,750 --> 00:11:08,860
see we've been getting scanned by all

00:11:06,399 --> 00:11:11,890
sorts of bots here's our stack driver

00:11:08,860 --> 00:11:13,870
monitoring thing here's an RC e we can

00:11:11,890 --> 00:11:15,310
see how frequently they are and it was

00:11:13,870 --> 00:11:17,800
pretty straightforward to build that

00:11:15,310 --> 00:11:18,970
query it's just simple sequel but what's

00:11:17,800 --> 00:11:22,470
incredible about it is that it is

00:11:18,970 --> 00:11:25,779
real-time so we did that query it took

00:11:22,470 --> 00:11:27,580
1.7 seconds not not too long and we were

00:11:25,779 --> 00:11:36,490
able to we can refresh that and just get

00:11:27,580 --> 00:11:41,920
constantly up-to-date data you're still

00:11:36,490 --> 00:11:44,020
going so another thing stackdriver

00:11:41,920 --> 00:11:46,660
logging allows us to do we already have

00:11:44,020 --> 00:11:49,120
this query concept we'll get any query

00:11:46,660 --> 00:11:52,540
based on you know arbitrary metadata or

00:11:49,120 --> 00:11:54,370
whatever we want to see we can take that

00:11:52,540 --> 00:11:57,070
query and start to create metrics with

00:11:54,370 --> 00:11:59,470
that information so logs and metrics are

00:11:57,070 --> 00:12:01,899
in a ways a bit different metrics are

00:11:59,470 --> 00:12:03,850
about counts they're about values where

00:12:01,899 --> 00:12:05,890
logs are more often just an event

00:12:03,850 --> 00:12:08,440
something has occurred but we can use

00:12:05,890 --> 00:12:10,740
these this query to create metrics from

00:12:08,440 --> 00:12:10,740
logs

00:12:18,880 --> 00:12:22,480
so let's change this query instead of

00:12:20,769 --> 00:12:25,259
all the Lux for my app let's look at all

00:12:22,480 --> 00:12:25,259
the errors from my app

00:12:56,300 --> 00:12:59,850
so now that I've built up that metric

00:12:58,710 --> 00:13:03,510
I'm going to go ahead and just generate

00:12:59,850 --> 00:13:07,040
some more airs so something happens very

00:13:03,510 --> 00:13:07,040
interesting application as you can see

00:13:07,760 --> 00:13:12,320
as I go into stock driver monitoring

00:13:25,620 --> 00:13:31,620
so stackdriver monitoring is the home of

00:13:27,990 --> 00:13:33,360
metrics so it gives you access to the

00:13:31,620 --> 00:13:35,040
metrics that you've explicitly created

00:13:33,360 --> 00:13:35,520
those are custom metrics from Cloud

00:13:35,040 --> 00:13:37,590
Foundry

00:13:35,520 --> 00:13:38,850
those are log metrics like we just

00:13:37,590 --> 00:13:41,190
created and we'll try to check out in a

00:13:38,850 --> 00:13:43,200
minute here and those are also GCP

00:13:41,190 --> 00:13:45,000
services so you can see it's gone ahead

00:13:43,200 --> 00:13:48,390
and created a chart for me on my pub/sub

00:13:45,000 --> 00:13:50,520
on responded to messages that's because

00:13:48,390 --> 00:13:52,830
I created a pub sub topic for

00:13:50,520 --> 00:13:54,690
stackdriver for the nozzle and I have

00:13:52,830 --> 00:13:58,250
nothing to subscribe to it so I should

00:13:54,690 --> 00:14:02,280
probably delete that after this talk but

00:13:58,250 --> 00:14:07,470
let's go ahead and create a create a

00:14:02,280 --> 00:14:08,880
metric for what we just saw oh let's try

00:14:07,470 --> 00:14:11,120
to do it through this Explorer this will

00:14:08,880 --> 00:14:11,120
be interesting

00:14:59,420 --> 00:15:04,240
so that metric is not ready but here's

00:15:01,610 --> 00:15:04,240
one I created earlier

00:15:18,010 --> 00:15:25,630
all right so that's demo no stackdriver

00:15:23,740 --> 00:15:28,060
metrics we've got all of our lager Gator

00:15:25,630 --> 00:15:30,370
information coming in so we are taking

00:15:28,060 --> 00:15:31,690
those container metrics we're taking

00:15:30,370 --> 00:15:33,040
counter metrics all these things coming

00:15:31,690 --> 00:15:35,290
out of various pieces of Cloud Foundry

00:15:33,040 --> 00:15:40,150
and we're ingesting that that means we

00:15:35,290 --> 00:15:41,230
can start to build out dashboards so

00:15:40,150 --> 00:15:46,690
here's the dashboard I built for my

00:15:41,230 --> 00:15:49,450
cloud foundry we've got the CPU

00:15:46,690 --> 00:15:51,820
percentage per hour Diego cell we've got

00:15:49,450 --> 00:15:53,380
a lot of Diego cells but what stock

00:15:51,820 --> 00:15:54,910
drive allows you to do in this view is

00:15:53,380 --> 00:15:57,070
we can start to start doing averages

00:15:54,910 --> 00:15:58,870
99th percentile means things like that

00:15:57,070 --> 00:16:01,420
so I've gone ahead and done that with my

00:15:58,870 --> 00:16:03,010
go router latency I've got three go

00:16:01,420 --> 00:16:05,800
routers in this deployment just one in

00:16:03,010 --> 00:16:08,020
each one so I really just am worried

00:16:05,800 --> 00:16:09,970
about well what's the 95th percentile on

00:16:08,020 --> 00:16:11,740
that and there's all sorts of ways to

00:16:09,970 --> 00:16:20,980
look at this but it's pretty easy to

00:16:11,740 --> 00:16:23,440
slice and dice these metrics here are

00:16:20,980 --> 00:16:25,270
generated by the stack driver agent so I

00:16:23,440 --> 00:16:26,770
just picked two and tossed them in here

00:16:25,270 --> 00:16:29,800
but there are certain things that a

00:16:26,770 --> 00:16:31,480
hypervisor can't really know about the

00:16:29,800 --> 00:16:32,650
operating system and it needs to have

00:16:31,480 --> 00:16:35,650
about the running operating system it

00:16:32,650 --> 00:16:37,780
needs to have something there sitting

00:16:35,650 --> 00:16:38,830
alongside doing you know deeper asks to

00:16:37,780 --> 00:16:40,990
the kernel what's going on

00:16:38,830 --> 00:16:42,250
checking the state of things so what you

00:16:40,990 --> 00:16:44,920
can do with this information is start to

00:16:42,250 --> 00:16:46,240
drill down and see you know what is the

00:16:44,920 --> 00:16:47,910
VM that is starting to run out of memory

00:16:46,240 --> 00:16:51,250
those sorts of those sorts of views

00:16:47,910 --> 00:16:53,200
that's great that's that's a view but

00:16:51,250 --> 00:16:55,090
with this information you often really

00:16:53,200 --> 00:16:57,460
want to be told when to look so it's

00:16:55,090 --> 00:16:59,020
awesome if you have a huge screen on the

00:16:57,460 --> 00:17:02,200
wall that has this very attractive

00:16:59,020 --> 00:17:04,510
dashboard but probably I need to be

00:17:02,200 --> 00:17:06,250
paged probably I need an email or

00:17:04,510 --> 00:17:14,380
something when when things go wrong and

00:17:06,250 --> 00:17:16,510
you're able to do that with alerting so

00:17:14,380 --> 00:17:19,030
here's a policy I created and this is

00:17:16,510 --> 00:17:21,280
just based on that Diego metric that I

00:17:19,030 --> 00:17:23,620
had in the in the last pane and it says

00:17:21,280 --> 00:17:25,540
if my disk space goes under 10 gigs go

00:17:23,620 --> 00:17:27,640
ahead and send me an email nothing crazy

00:17:25,540 --> 00:17:30,670
but one thing stackdriver does that I

00:17:27,640 --> 00:17:31,900
really like is it has both incidents it

00:17:30,670 --> 00:17:33,550
can create an incident

00:17:31,900 --> 00:17:35,470
that needs to be resolved or responded

00:17:33,550 --> 00:17:38,710
to and it can also send a little help

00:17:35,470 --> 00:17:40,240
message alongside so if you have sort of

00:17:38,710 --> 00:17:40,690
a culture of we're not just gonna create

00:17:40,240 --> 00:17:42,700
alerts

00:17:40,690 --> 00:17:45,850
those alerts are actionable alerts that

00:17:42,700 --> 00:17:46,690
say this is a problem here are some ways

00:17:45,850 --> 00:17:48,970
to get started

00:17:46,690 --> 00:17:51,100
maybe not here's a solution this one has

00:17:48,970 --> 00:17:52,660
provided a great solution you can see

00:17:51,100 --> 00:17:54,850
that which is to download a few more

00:17:52,660 --> 00:17:56,920
hard drives that is possible in a lot of

00:17:54,850 --> 00:18:02,740
ways in the cloud but maybe not the most

00:17:56,920 --> 00:18:04,900
useful advice the last thing I want to

00:18:02,740 --> 00:18:12,690
show you here is the uptime checks

00:18:04,900 --> 00:18:15,040
feature so I mentioned I have a multi

00:18:12,690 --> 00:18:17,560
region Cloud Foundry a global Cloud

00:18:15,040 --> 00:18:20,020
Foundry what I'm able to do is define a

00:18:17,560 --> 00:18:22,030
simple URL endpoint like you'd expect

00:18:20,020 --> 00:18:25,060
from uptime monitoring and stackdriver

00:18:22,030 --> 00:18:27,700
we'll check it out and periodically pool

00:18:25,060 --> 00:18:30,070
from it at the frequency I want and give

00:18:27,700 --> 00:18:32,040
me metrics based on how if it's healthy

00:18:30,070 --> 00:18:34,630
or not and what's where the latency is

00:18:32,040 --> 00:18:37,090
you can just like anything create alerts

00:18:34,630 --> 00:18:43,480
be notified hook that up with what you

00:18:37,090 --> 00:18:47,230
need to hook up to so with that I'd like

00:18:43,480 --> 00:18:48,790
to go to any questions anyone has but

00:18:47,230 --> 00:18:50,970
mostly thank you all for checking this

00:18:48,790 --> 00:18:50,970
out

00:18:51,230 --> 00:18:57,219
[Applause]

00:19:01,350 --> 00:19:05,080
so feel free to stand up you have any

00:19:03,429 --> 00:19:32,259
questions or just hang around I'm gonna

00:19:05,080 --> 00:19:34,899
be in here for the next talk for the VM

00:19:32,259 --> 00:19:37,029
itself even without the agents we do

00:19:34,899 --> 00:19:41,440
provide a set of metrics at each VM

00:19:37,029 --> 00:19:45,879
about various utilization so I believe

00:19:41,440 --> 00:19:47,889
we can do CPU usage and a few others but

00:19:45,879 --> 00:19:51,309
we also provide metrics for a lot of our

00:19:47,889 --> 00:19:55,840
services so our load balancing services

00:19:51,309 --> 00:19:57,429
have some metrics and are things like

00:19:55,840 --> 00:20:00,129
spanner you could build a dashboard for

00:19:57,429 --> 00:20:02,619
those services so this is definitely the

00:20:00,129 --> 00:20:06,039
place where if you have a GCP project

00:20:02,619 --> 00:20:09,940
we'd expect to do our eye as reporting

00:20:06,039 --> 00:20:12,309
in here you can build reports

00:20:09,940 --> 00:20:15,249
stackdriver has a pretty robust API I

00:20:12,309 --> 00:20:17,499
know because I wrote the nozzle that you

00:20:15,249 --> 00:20:19,059
can pull stuff out of so if you want to

00:20:17,499 --> 00:20:21,639
pull that into another system it is

00:20:19,059 --> 00:20:24,330
available and able to to sort of

00:20:21,639 --> 00:20:24,330
integrate with that stuff

00:21:00,170 --> 00:21:05,550
so that is an excellent question so the

00:21:02,880 --> 00:21:07,980
question around essentially is there a

00:21:05,550 --> 00:21:10,650
way to stamp out dashboards let's say I

00:21:07,980 --> 00:21:12,600
have one I even have an application that

00:21:10,650 --> 00:21:15,420
we have a set application dashboard and

00:21:12,600 --> 00:21:17,910
we want to launch that with every PCF

00:21:15,420 --> 00:21:20,700
app that we push but the overall health

00:21:17,910 --> 00:21:24,350
is just the same same sort of need I

00:21:20,700 --> 00:21:26,340
tell you I hear it I hear that ask

00:21:24,350 --> 00:21:29,490
that's all I can say about it right now

00:21:26,340 --> 00:22:05,160
but today there is that is not capable

00:21:29,490 --> 00:22:09,870
that is an excellent question

00:22:05,160 --> 00:22:11,430
the first the easiest way to do that

00:22:09,870 --> 00:22:13,200
today would be to say to have a

00:22:11,430 --> 00:22:15,870
centralized account and then do

00:22:13,200 --> 00:22:17,220
reporting out from that but that doesn't

00:22:15,870 --> 00:22:19,020
get you stackdriver monitoring that

00:22:17,220 --> 00:22:20,850
gives you stackdriver logging it's easy

00:22:19,020 --> 00:22:22,710
to create those queries and say ok for

00:22:20,850 --> 00:22:25,260
this logging application I'm going to

00:22:22,710 --> 00:22:26,670
dump this into a specific bucket or

00:22:25,260 --> 00:22:28,260
specific bigquery that I give these

00:22:26,670 --> 00:22:30,420
folks permissions to having that

00:22:28,260 --> 00:22:32,100
centralized spot I don't know how to do

00:22:30,420 --> 00:22:34,850
that with monitoring but I'd be happy to

00:22:32,100 --> 00:22:34,850
follow up about that

00:22:42,009 --> 00:22:45,979
yeah as opposed to having the the

00:22:44,899 --> 00:22:50,320
monitoring console you do enough for

00:22:45,979 --> 00:22:50,320
logs okay cool

00:22:58,240 --> 00:23:18,790
oh yeah what's up so under the hood for

00:23:16,450 --> 00:23:22,170
the the host minor agent we're using

00:23:18,790 --> 00:23:24,790
collect D so collect D does allow you to

00:23:22,170 --> 00:23:26,410
include some plugins for a lot of puppet

00:23:24,790 --> 00:23:28,960
popular open source projects things like

00:23:26,410 --> 00:23:31,410
nginx if you are hosting something like

00:23:28,960 --> 00:23:34,179
that you can expand that configuration

00:23:31,410 --> 00:23:37,330
what we're doing with this is the base

00:23:34,179 --> 00:23:39,400
set and we are also doing what Cloud

00:23:37,330 --> 00:23:46,720
Foundry is logging so we aren't really

00:23:39,400 --> 00:23:51,130
doing instrumentation beyond that that's

00:23:46,720 --> 00:23:52,840
right I don't know enough about

00:23:51,130 --> 00:23:53,970
stackdriver trace to tell you what if

00:23:52,840 --> 00:23:58,090
that's what that is

00:23:53,970 --> 00:24:14,710
but I don't believe we have a full APM

00:23:58,090 --> 00:24:16,270
product yeah so I think the way today to

00:24:14,710 --> 00:24:17,710
handle that they're all going to come to

00:24:16,270 --> 00:24:20,080
a central account or whatever count you

00:24:17,710 --> 00:24:21,820
specify the way today to do that would

00:24:20,080 --> 00:24:24,850
be to create those exports and

00:24:21,820 --> 00:24:27,370
permission based on the the sync that

00:24:24,850 --> 00:24:32,320
you're sending that data to so you could

00:24:27,370 --> 00:24:34,179
flow into bigquery or pub/sub and with

00:24:32,320 --> 00:24:35,350
your data going to those specific syncs

00:24:34,179 --> 00:24:37,720
you can do your permissioning at that

00:24:35,350 --> 00:24:41,530
level but there isn't really a way to

00:24:37,720 --> 00:24:43,570
say okay give this I am user this sort

00:24:41,530 --> 00:24:45,780
of slice of log view that does not exist

00:24:43,570 --> 00:24:45,780
today

00:24:53,660 --> 00:24:56,420
well who everybody is any other

00:24:55,160 --> 00:24:58,670
questions I'm going to be hanging around

00:24:56,420 --> 00:25:01,180
I'll be here all week so thank you all

00:24:58,670 --> 00:25:01,180
for joining me

00:25:02,020 --> 00:25:04,750

YouTube URL: https://www.youtube.com/watch?v=OaMKHbpo5CY


