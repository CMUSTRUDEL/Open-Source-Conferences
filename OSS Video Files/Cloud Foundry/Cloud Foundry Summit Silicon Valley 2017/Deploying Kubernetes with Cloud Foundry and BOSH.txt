Title: Deploying Kubernetes with Cloud Foundry and BOSH
Publication date: 2017-06-21
Playlist: Cloud Foundry Summit Silicon Valley 2017
Description: 
	Deploying Kubernetes with Cloud Foundry and BOSH [I] - Jeff Johnson and Meaghan Kjelland, Google    

In this talk, Meaghan and Jeff will show you how to run and manage Kubernetes with Cloud Foundry and BOSH. This is made possible by a joint collaboration between Pivotal and Google on an open source BOSH release of Kubernetes. We’ll go over the architecture, deployment, and value of the platforms alongside one another.

Meaghan Kjelland
Meaghan is a Software Engineer at Google taking the steam out of proprietary software by building the future in open source. She is currently working with Pivotal to make Kubernetes' container orchestration strengths complement Cloud Foundry applications.

Jeff Johnson
Jeff is a Software Engineer at Google who is giving developers super powers by integrating the tools that run Google with open source Cloud Foundry. He has worked closely with the excellent engineers at Pivotal on the stackdriver-tools BOSH release to integrate Google's Logging, Monitoring, Tracing, and Debugging with Cloud Foundry. Today he is working with Pivotal on bringing Kubernetes' container orchestration strengths to complement Cloud Foundry applications. Check out the Pivotal Cloud Foundry on Google Cloud Platform web series for a hint of what's to come.
Captions: 
	00:00:00,030 --> 00:00:05,339
so my name is Konstantin Simonov I'm the

00:00:03,629 --> 00:00:07,379
principal software engineer at pivotal

00:00:05,339 --> 00:00:09,900
and today me and my colleagues from

00:00:07,379 --> 00:00:14,099
Google Jeff Johnson and Megan challenge

00:00:09,900 --> 00:00:17,369
will talk about Kubo so what are we

00:00:14,099 --> 00:00:23,400
gonna talk about first I will give a

00:00:17,369 --> 00:00:25,260
brief introduction to Bosch well well

00:00:23,400 --> 00:00:27,029
some of you may know what Bosch is

00:00:25,260 --> 00:00:30,119
something you might be interested in

00:00:27,029 --> 00:00:32,550
what problems it's canceled for us then

00:00:30,119 --> 00:00:35,550
Jeff will talk quickly about kubernetes

00:00:32,550 --> 00:00:38,340
and explains what problems that solves

00:00:35,550 --> 00:00:40,950
and how it could be useful to our family

00:00:38,340 --> 00:00:44,100
community and then Meghan will explain

00:00:40,950 --> 00:00:47,370
how Kubo brings both of them together to

00:00:44,100 --> 00:00:51,860
our mutual benefit then we'll give you a

00:00:47,370 --> 00:00:55,079
demo of how Kubo handles vm failures

00:00:51,860 --> 00:00:56,219
with an example application and how does

00:00:55,079 --> 00:00:59,640
that propagate throughout the whole

00:00:56,219 --> 00:01:01,469
stack and while we're doing this there

00:00:59,640 --> 00:01:05,189
will be some time waiting so we'll

00:01:01,469 --> 00:01:06,780
discuss the project roadmap and then

00:01:05,189 --> 00:01:12,500
we'll tell you how to contribute to the

00:01:06,780 --> 00:01:15,299
project so let's kick off in modern day

00:01:12,500 --> 00:01:16,860
developers use different technologies to

00:01:15,299 --> 00:01:18,810
deliver the functionality they're

00:01:16,860 --> 00:01:21,060
working on these could be anywhere

00:01:18,810 --> 00:01:22,710
between functional systems that are

00:01:21,060 --> 00:01:26,100
event-driven they're micro services

00:01:22,710 --> 00:01:28,140
these could be more complicated app

00:01:26,100 --> 00:01:31,560
centric systems that we all know and

00:01:28,140 --> 00:01:34,860
love and we use 12 factor apps in

00:01:31,560 --> 00:01:37,770
foundry those could be more complicated

00:01:34,860 --> 00:01:41,100
stateful applications for example

00:01:37,770 --> 00:01:44,130
something that can be run on docker var

00:01:41,100 --> 00:01:47,340
kubernetes or even data services like

00:01:44,130 --> 00:01:51,329
database management systems and the like

00:01:47,340 --> 00:01:52,710
so all of them are handled by are

00:01:51,329 --> 00:01:55,380
running on top of some sort of

00:01:52,710 --> 00:01:57,180
infrastructure and when it comes to

00:01:55,380 --> 00:02:00,180
connecting them together and then

00:01:57,180 --> 00:02:02,969
maintaining that that sometimes well

00:02:00,180 --> 00:02:04,290
almost always we'll shoot the

00:02:02,969 --> 00:02:07,350
operational cost through the roof

00:02:04,290 --> 00:02:09,539
because either you'll be left with

00:02:07,350 --> 00:02:12,170
unpatched versions of different

00:02:09,539 --> 00:02:14,870
environments because all of them

00:02:12,170 --> 00:02:16,910
running on different systems you have to

00:02:14,870 --> 00:02:19,580
be patched through you have to manage

00:02:16,910 --> 00:02:21,590
the credentials when the applications

00:02:19,580 --> 00:02:24,740
are talking to each other and all of

00:02:21,590 --> 00:02:26,720
that will grow and grow exponentially

00:02:24,740 --> 00:02:31,490
with the number of systems that you have

00:02:26,720 --> 00:02:33,370
to handle so what do you do well our

00:02:31,490 --> 00:02:38,390
family has been using Bosch quite a lot

00:02:33,370 --> 00:02:41,660
for a long time to manage all all of

00:02:38,390 --> 00:02:44,470
that it is used to create all the

00:02:41,660 --> 00:02:47,500
virtual machines that a foundry runs on

00:02:44,470 --> 00:02:51,980
make sure that they're up and running

00:02:47,500 --> 00:02:55,600
enable scaling updating and now with the

00:02:51,980 --> 00:02:58,910
new credit hub product also can manage

00:02:55,600 --> 00:03:03,850
storing and rotating your credentials

00:02:58,910 --> 00:03:06,170
and secrets securely and automatically

00:03:03,850 --> 00:03:09,920
so what is borscht it's an automated

00:03:06,170 --> 00:03:12,290
cloud agnostic platform it's based it

00:03:09,920 --> 00:03:14,269
was inspired by Google's board system

00:03:12,290 --> 00:03:19,040
which is a cluster manager that runs at

00:03:14,269 --> 00:03:21,260
tremendous scales and handles hundreds

00:03:19,040 --> 00:03:24,110
of thousands of clusters in the Google

00:03:21,260 --> 00:03:26,720
infrastructure it's an open-source tool

00:03:24,110 --> 00:03:31,090
chain for lease engineering deployment

00:03:26,720 --> 00:03:33,799
and lifecycle that is managing your

00:03:31,090 --> 00:03:37,220
infrastructure for you as I have

00:03:33,799 --> 00:03:39,860
explained before so without further ado

00:03:37,220 --> 00:03:43,690
I'm heading over to Jeff to talk about

00:03:39,860 --> 00:03:48,980
kubernetes Thank You Constantine yes

00:03:43,690 --> 00:03:50,989
okay so what is kubernetes if you've

00:03:48,980 --> 00:03:53,570
been on hacker news before you've seen

00:03:50,989 --> 00:03:56,120
the ships wheel there's a lot of talk

00:03:53,570 --> 00:03:58,790
about it but if you land on kubernetes

00:03:56,120 --> 00:04:02,780
io you'll get a pretty dense but

00:03:58,790 --> 00:04:05,750
comprehensive explanation kubernetes is

00:04:02,780 --> 00:04:07,730
all about deploying scaling and managing

00:04:05,750 --> 00:04:09,380
containerized applications you think

00:04:07,730 --> 00:04:11,750
about a containerized application I like

00:04:09,380 --> 00:04:13,280
to think of it as just a binary blob and

00:04:11,750 --> 00:04:18,919
some metadata that you can run in a

00:04:13,280 --> 00:04:20,780
pretty you know reproducible way but you

00:04:18,919 --> 00:04:22,370
don't just have a container there's not

00:04:20,780 --> 00:04:25,650
just a single instance there's not just

00:04:22,370 --> 00:04:27,270
a single service it's a whole network of

00:04:25,650 --> 00:04:29,130
interacting pieces that work together

00:04:27,270 --> 00:04:31,830
and they have a lot of these problems

00:04:29,130 --> 00:04:34,229
around how do you access them manage

00:04:31,830 --> 00:04:39,360
them update them kubernetes is all about

00:04:34,229 --> 00:04:40,560
that orchestration and management where

00:04:39,360 --> 00:04:42,990
you would use this to some like

00:04:40,560 --> 00:04:44,850
kubernetes varies quite a bit but there

00:04:42,990 --> 00:04:47,070
are a few ones that really stand out an

00:04:44,850 --> 00:04:49,199
excellent use case are commercial

00:04:47,070 --> 00:04:51,870
off-the-shelf applications so let's say

00:04:49,199 --> 00:04:53,550
you have this C++ program with a whole

00:04:51,870 --> 00:04:55,169
long tail list of these binary

00:04:53,550 --> 00:04:57,000
dependencies well it's sticking that in

00:04:55,169 --> 00:04:59,970
a container as a much more convenient

00:04:57,000 --> 00:05:01,979
way to run that and run it reproducibly

00:04:59,970 --> 00:05:05,940
if you can just pull it off a docker hub

00:05:01,979 --> 00:05:07,680
very easy way to get the software some

00:05:05,940 --> 00:05:09,690
apps have very specific hardware

00:05:07,680 --> 00:05:13,500
scheduling and networking requirements

00:05:09,690 --> 00:05:16,470
so a CF push would not suffice if I need

00:05:13,500 --> 00:05:19,500
to say this is today I need to say that

00:05:16,470 --> 00:05:21,419
my machine needs 10 GPUs and it better

00:05:19,500 --> 00:05:24,030
not run on a same machine as this other

00:05:21,419 --> 00:05:27,660
little node so these little very special

00:05:24,030 --> 00:05:29,010
applications and the last bit is when

00:05:27,660 --> 00:05:31,380
we're talking about data services with

00:05:29,010 --> 00:05:33,270
persistence this is sort of an evolving

00:05:31,380 --> 00:05:37,410
area in kubernetes but we'll show you

00:05:33,270 --> 00:05:39,479
how you could do that today so this is a

00:05:37,410 --> 00:05:41,300
bit of an eye chart and I apologize not

00:05:39,479 --> 00:05:43,919
like a graphic designer

00:05:41,300 --> 00:05:45,240
but here's a few core concepts of

00:05:43,919 --> 00:05:46,800
kubernetes that we're gonna look at just

00:05:45,240 --> 00:05:48,840
to get some of the terminology and sort

00:05:46,800 --> 00:05:50,400
of understand how kubernetes talks about

00:05:48,840 --> 00:05:52,260
these containers and connects them

00:05:50,400 --> 00:05:55,620
together so if you look at the bottom

00:05:52,260 --> 00:05:57,800
row we have three pots going across the

00:05:55,620 --> 00:06:01,380
pod is a set of running containers so

00:05:57,800 --> 00:06:03,180
our pods here is an image cockroach TB

00:06:01,380 --> 00:06:07,169
it's just an image from docker hub and

00:06:03,180 --> 00:06:09,840
it has got some metadata on it so app

00:06:07,169 --> 00:06:13,699
equals cockroach DB just arbitrary key

00:06:09,840 --> 00:06:16,470
value now with those three running pods

00:06:13,699 --> 00:06:18,539
above them we have a service the service

00:06:16,470 --> 00:06:20,940
is how we're going to expose these

00:06:18,539 --> 00:06:23,520
applications so the service gets a name

00:06:20,940 --> 00:06:27,330
and it gets the selector the selector is

00:06:23,520 --> 00:06:29,400
the same as our DB coincidence and it's

00:06:27,330 --> 00:06:31,620
got a name what this allows us to do is

00:06:29,400 --> 00:06:33,990
dial it within the cluster get dns

00:06:31,620 --> 00:06:36,750
resolution and route traffic directly to

00:06:33,990 --> 00:06:39,130
a healthy pod so if we go up a tier

00:06:36,750 --> 00:06:41,560
we've got our front end

00:06:39,130 --> 00:06:43,870
which just think of it as a stateless

00:06:41,560 --> 00:06:47,020
app that's able to access it over the

00:06:43,870 --> 00:06:49,960
container network access those those

00:06:47,020 --> 00:06:51,640
services in our case we use flannel but

00:06:49,960 --> 00:06:54,640
you can use anything here kubernetes is

00:06:51,640 --> 00:06:56,650
not that opinionated about it one more

00:06:54,640 --> 00:06:58,750
layer above our guestbook pods which is

00:06:56,650 --> 00:07:01,150
just like the one below is a service

00:06:58,750 --> 00:07:03,850
with a node port now kubernetes is a lot

00:07:01,150 --> 00:07:05,950
of ways to expose services externally to

00:07:03,850 --> 00:07:07,990
the cluster and we're not gonna go in a

00:07:05,950 --> 00:07:11,320
lot of detail about that but node port

00:07:07,990 --> 00:07:13,120
is one that says ok if you hit any VM on

00:07:11,320 --> 00:07:16,450
this port I will route you to this

00:07:13,120 --> 00:07:21,100
service somehow you're gonna do ingress

00:07:16,450 --> 00:07:22,960
into there and you've got a service now

00:07:21,100 --> 00:07:25,330
in this is this is how sort of the

00:07:22,960 --> 00:07:27,940
concepts play together but in practice

00:07:25,330 --> 00:07:30,160
kubernetes is just a collection of you

00:07:27,940 --> 00:07:33,550
know running user space applications so

00:07:30,160 --> 00:07:35,650
if you look on the on the far left we've

00:07:33,550 --> 00:07:38,170
got our control plane the control plane

00:07:35,650 --> 00:07:40,630
it has a master node that master node

00:07:38,170 --> 00:07:42,580
runs an API interface as well as a

00:07:40,630 --> 00:07:44,950
scheduler which decides where it's going

00:07:42,580 --> 00:07:47,410
to run the work and that's all stateless

00:07:44,950 --> 00:07:50,320
and connects to a database which uses at

00:07:47,410 --> 00:07:54,010
CD which stores all the actual state for

00:07:50,320 --> 00:07:55,630
the cluster we then have a set of

00:07:54,010 --> 00:07:57,130
workers who actually do something in the

00:07:55,630 --> 00:08:00,370
cluster they're actually running your

00:07:57,130 --> 00:08:01,900
work and they also run a few services on

00:08:00,370 --> 00:08:04,690
there like The Container overlay Network

00:08:01,900 --> 00:08:08,980
flannel and cube proxy to help set up

00:08:04,690 --> 00:08:11,020
some IP tables rules somehow that gets

00:08:08,980 --> 00:08:14,410
to the internet and folks can consume

00:08:11,020 --> 00:08:16,480
your kubernetes services so that's sort

00:08:14,410 --> 00:08:17,860
of the whirlwind tour of kubernetes I'm

00:08:16,480 --> 00:08:19,420
gonna pass off to Megan who's going to

00:08:17,860 --> 00:08:24,820
talk about how I can combine bosh and

00:08:19,420 --> 00:08:26,050
kubernetes Thanks so if you google Kubo

00:08:24,820 --> 00:08:27,700
you'll actually get this movie called

00:08:26,050 --> 00:08:30,280
Kubo and the two strings have any of you

00:08:27,700 --> 00:08:31,510
guys seen that well if you came here to

00:08:30,280 --> 00:08:35,320
hear about that we're not talking about

00:08:31,510 --> 00:08:36,580
that so I'm sorry we named it that

00:08:35,320 --> 00:08:38,560
actually not after the movie

00:08:36,580 --> 00:08:41,890
surprisingly but after kubernetes on

00:08:38,560 --> 00:08:44,229
Bosh it's shortened so we said already a

00:08:41,890 --> 00:08:46,360
Bosh is based on Google's Borg system

00:08:44,229 --> 00:08:48,580
which is our internal cluster manager

00:08:46,360 --> 00:08:50,339
and you might also know that kubernetes

00:08:48,580 --> 00:08:52,170
is based on the same

00:08:50,339 --> 00:08:54,450
but in a different way so kubernetes

00:08:52,170 --> 00:08:56,610
does management of containers clusters

00:08:54,450 --> 00:08:58,620
of containers and more Bosh does

00:08:56,610 --> 00:09:00,750
management of vm's and clusters of VMs

00:08:58,620 --> 00:09:02,339
so they're actually very complementary

00:09:00,750 --> 00:09:04,019
systems in my opinion because they're

00:09:02,339 --> 00:09:06,240
based on the same underlying board

00:09:04,019 --> 00:09:07,800
system and this is a project that we've

00:09:06,240 --> 00:09:10,709
been working on Google and pivotal

00:09:07,800 --> 00:09:12,360
together for about six months the reason

00:09:10,709 --> 00:09:14,399
we started this project is that we've

00:09:12,360 --> 00:09:16,440
kind of found that kubernetes has some

00:09:14,399 --> 00:09:21,300
unsolved problems since it's meant to be

00:09:16,440 --> 00:09:23,040
a manager of containers not VMs we don't

00:09:21,300 --> 00:09:25,260
have some things like for example health

00:09:23,040 --> 00:09:26,850
checking and healing of VMs themselves

00:09:25,260 --> 00:09:28,920
so those kubernetes nodes if they go

00:09:26,850 --> 00:09:30,570
down kubernetes will reschedule the pods

00:09:28,920 --> 00:09:33,779
on to other nodes but they won't bring

00:09:30,570 --> 00:09:35,490
back the nodes themselves also in terms

00:09:33,779 --> 00:09:37,560
of a che there's no support out of the

00:09:35,490 --> 00:09:41,279
box for multiple master nodes or at CD

00:09:37,560 --> 00:09:43,529
nodes and then scaling so if we want to

00:09:41,279 --> 00:09:44,640
add additional nodes to our cluster we'd

00:09:43,529 --> 00:09:46,470
like a way to be able to do that in

00:09:44,640 --> 00:09:48,329
kubernetes isn't providing that today

00:09:46,470 --> 00:09:50,430
and then upgrade so that's both

00:09:48,329 --> 00:09:52,140
upgrading the kubernetes software you're

00:09:50,430 --> 00:09:54,300
running and also upgrading your

00:09:52,140 --> 00:09:56,010
operating system so if there's for

00:09:54,300 --> 00:09:58,500
example another heartbleed bug you'll

00:09:56,010 --> 00:10:00,240
need to update to an o'the stable

00:09:58,500 --> 00:10:01,410
version of the operating system for your

00:10:00,240 --> 00:10:05,339
cluster and you'd like to be able to do

00:10:01,410 --> 00:10:06,750
that without taking the cluster down and

00:10:05,339 --> 00:10:08,310
you might have noticed that those are

00:10:06,750 --> 00:10:11,610
the exact problems that we earlier said

00:10:08,310 --> 00:10:13,769
Bosch solves so Kubo is meant to solve

00:10:11,610 --> 00:10:16,199
those problems using Bosch so we're our

00:10:13,769 --> 00:10:17,790
goal is to give you a uniform way to

00:10:16,199 --> 00:10:20,040
deploy and manage your kubernetes

00:10:17,790 --> 00:10:22,440
clusters and we do that with Bosch and

00:10:20,040 --> 00:10:25,860
since Bosch works on any cloud Kubo

00:10:22,440 --> 00:10:27,600
should also work on any cloud how do we

00:10:25,860 --> 00:10:29,279
do that we kind of break it up into two

00:10:27,600 --> 00:10:32,760
things so day 1 activities would be

00:10:29,279 --> 00:10:34,890
deploying a cluster we have a repo with

00:10:32,760 --> 00:10:36,360
deployment scripts and documentation on

00:10:34,890 --> 00:10:38,490
how you could deploy a cluster using a

00:10:36,360 --> 00:10:40,290
Bosch director and then we're working on

00:10:38,490 --> 00:10:42,540
integrating that with cloud foundry

00:10:40,290 --> 00:10:45,630
so you could type like CF create service

00:10:42,540 --> 00:10:47,850
kubernetes to get kubernetes cluster up

00:10:45,630 --> 00:10:49,529
and running and then in terms of day 2

00:10:47,850 --> 00:10:51,570
activities for the most part we just

00:10:49,529 --> 00:10:53,610
rely on Bosch to do that for us we're

00:10:51,570 --> 00:10:56,310
testing it and making sure any kinks are

00:10:53,610 --> 00:10:58,020
kind of worked out but Bosch does the

00:10:56,310 --> 00:11:01,319
self-healing of VMs and monitoring by

00:10:58,020 --> 00:11:02,200
the Bosch agent elastic scaling for

00:11:01,319 --> 00:11:04,030
clusters rolling

00:11:02,200 --> 00:11:06,520
upgrades so we're continuously updating

00:11:04,030 --> 00:11:08,620
kubernetes version to later versions

00:11:06,520 --> 00:11:10,180
we're on the latest major version right

00:11:08,620 --> 00:11:12,970
now and we're working on updating to the

00:11:10,180 --> 00:11:15,010
latest minor version and then high

00:11:12,970 --> 00:11:16,450
availability and we will be working on

00:11:15,010 --> 00:11:19,770
multi zone support so you could have a

00:11:16,450 --> 00:11:19,770
cluster that spans multiple zones

00:11:20,100 --> 00:11:24,400
Kubo OSS is the joint project we've been

00:11:22,690 --> 00:11:26,200
working on Google and pivotal together

00:11:24,400 --> 00:11:29,790
we kind of have two different tracks of

00:11:26,200 --> 00:11:32,140
work one would be the pure open source

00:11:29,790 --> 00:11:34,690
solution so that has no dependency on

00:11:32,140 --> 00:11:36,960
Cloud Foundry you deploy a kubernetes

00:11:34,690 --> 00:11:38,860
cluster using Bosch and then you just

00:11:36,960 --> 00:11:40,150
interact with it the same way that you'd

00:11:38,860 --> 00:11:42,970
interact with any kubernetes cluster

00:11:40,150 --> 00:11:44,470
using cube control but we also have

00:11:42,970 --> 00:11:47,110
another tract of work to integrate this

00:11:44,470 --> 00:11:48,850
with pivotal Cloud Foundry so we do

00:11:47,110 --> 00:11:51,340
things like share a routing layer with

00:11:48,850 --> 00:11:55,600
Cloud Foundry and hopefully integrate

00:11:51,340 --> 00:12:02,020
support through the CFC Li now it's time

00:11:55,600 --> 00:12:03,340
for a demo so we have a cluster already

00:12:02,020 --> 00:12:04,690
deployed it takes about 20 minutes to

00:12:03,340 --> 00:12:07,600
deploy and we don't have that much time

00:12:04,690 --> 00:12:10,390
so we've deployed a cluster that has two

00:12:07,600 --> 00:12:14,110
master nodes three worker nodes and

00:12:10,390 --> 00:12:16,510
three at CD nodes and the first thing

00:12:14,110 --> 00:12:19,390
that we'll do is look at the nodes that

00:12:16,510 --> 00:12:21,130
kubernetes is aware of right now and

00:12:19,390 --> 00:12:23,470
we'll do that using

00:12:21,130 --> 00:12:25,360
cube control so we have three worker

00:12:23,470 --> 00:12:28,210
nodes as you can see and then let's look

00:12:25,360 --> 00:12:29,710
at the VMS bosch is managing and we'll

00:12:28,210 --> 00:12:33,250
just look at the workers since that's

00:12:29,710 --> 00:12:34,750
what we're demoing right now so you can

00:12:33,250 --> 00:12:36,820
see the IP addresses of the nodes are

00:12:34,750 --> 00:12:39,940
the same so these are the exact same

00:12:36,820 --> 00:12:43,000
notes and now we will deploy an

00:12:39,940 --> 00:12:46,180
application to kubernetes which is a

00:12:43,000 --> 00:12:50,160
cockroach TV you'll have to excuse us if

00:12:46,180 --> 00:12:57,690
it's a little buggy it's a cockroach

00:12:50,160 --> 00:12:57,690
thank you oh can you make it bigger

00:12:59,560 --> 00:13:03,700
like the font yeah

00:13:14,520 --> 00:13:24,720
okay so let's deploy our database

00:13:17,430 --> 00:13:27,450
application to kubernetes oh and yeah

00:13:24,720 --> 00:13:29,399
we're gonna watch the pods that are

00:13:27,450 --> 00:13:32,370
created on kubernetes okay so we're

00:13:29,399 --> 00:13:34,050
creating a cockroach TV pod we're gonna

00:13:32,370 --> 00:13:40,830
create three but they get created

00:13:34,050 --> 00:13:42,510
sequentially and the reason we're

00:13:40,830 --> 00:13:44,070
deploying this to kubernetes is because

00:13:42,510 --> 00:13:46,110
cloud foundry doesn't support cockroach

00:13:44,070 --> 00:13:49,320
TV but we want to use that for our

00:13:46,110 --> 00:13:51,300
applications so we're going to use the

00:13:49,320 --> 00:13:53,459
two together and we're gonna deploy a

00:13:51,300 --> 00:13:58,050
front-end application to Cloud Foundry

00:13:53,459 --> 00:14:00,089
in just a minute okay one of our pods

00:13:58,050 --> 00:14:02,810
was created so that's good now we're

00:14:00,089 --> 00:14:02,810
creating the second one

00:14:11,240 --> 00:14:16,100
once all the pods are created we'll also

00:14:12,740 --> 00:14:19,400
run a script to create a database within

00:14:16,100 --> 00:14:21,910
those pods and table on this database in

00:14:19,400 --> 00:14:21,910
the database

00:14:28,930 --> 00:14:32,339
it takes a second

00:14:34,240 --> 00:14:36,869
yay

00:14:44,300 --> 00:14:50,120
cool so now we can create our database

00:14:46,130 --> 00:14:52,580
and the table and then we will push our

00:14:50,120 --> 00:14:57,170
Cloud Foundry app that uses cockroach

00:14:52,580 --> 00:15:01,070
db2 cloud foundry and what this

00:14:57,170 --> 00:15:02,870
application is it is the kubernetes

00:15:01,070 --> 00:15:04,100
guestbook application so this if you've

00:15:02,870 --> 00:15:07,190
used kubernetes you've probably seen

00:15:04,100 --> 00:15:10,160
this all it is is a store for text that

00:15:07,190 --> 00:15:11,390
you type into a guestbook and the reason

00:15:10,160 --> 00:15:12,680
we're deploying the front-end to Cloud

00:15:11,390 --> 00:15:13,850
Foundry is because we think it's a good

00:15:12,680 --> 00:15:17,060
candidate for a Cloud Foundry

00:15:13,850 --> 00:15:19,460
application but the like I said the

00:15:17,060 --> 00:15:21,260
cockroach DB is not supported so we need

00:15:19,460 --> 00:15:23,960
some way to deploy that if we want to

00:15:21,260 --> 00:15:25,250
use it we kind of think of this as they

00:15:23,960 --> 00:15:26,840
can be complimentary so you could deploy

00:15:25,250 --> 00:15:28,820
part of your app to Cloud Foundry part

00:15:26,840 --> 00:15:30,680
of it to kubernetes but if you're

00:15:28,820 --> 00:15:32,360
migrating to cloud foundry you might

00:15:30,680 --> 00:15:34,730
have applications that have dependencies

00:15:32,360 --> 00:15:36,470
that are hard to move so you can use

00:15:34,730 --> 00:15:38,990
this as kind of a stopgap solution if

00:15:36,470 --> 00:15:40,940
you want or you can use it as a full

00:15:38,990 --> 00:15:42,500
solution if you have a dependency that

00:15:40,940 --> 00:15:44,860
really needs to be run somewhere like

00:15:42,500 --> 00:15:44,860
kubernetes

00:16:04,399 --> 00:16:09,910
takes a couple of minutes everything in

00:16:08,329 --> 00:16:12,259
this demo takes a couple of minutes oh

00:16:09,910 --> 00:16:14,720
okay there we go now let's look at our

00:16:12,259 --> 00:16:15,889
application we're gonna pull up two

00:16:14,720 --> 00:16:19,579
windows just so you can see the

00:16:15,889 --> 00:16:23,149
persistence oh that's an old deployment

00:16:19,579 --> 00:16:24,620
over there cool so now if we store

00:16:23,149 --> 00:16:29,120
something in the guestbook

00:16:24,620 --> 00:16:32,629
it should be stored in the database and

00:16:29,120 --> 00:16:36,079
we can see it is we can write something

00:16:32,629 --> 00:16:37,249
else Darth Vader was also there they're

00:16:36,079 --> 00:16:43,879
not writing much about what they thought

00:16:37,249 --> 00:16:44,720
but that's okay cool so now let's see

00:16:43,879 --> 00:16:46,670
what happens

00:16:44,720 --> 00:16:51,079
how these two systems play together if

00:16:46,670 --> 00:16:52,939
we delete one of our worker nodes so

00:16:51,079 --> 00:16:54,889
we'll run a watch on the Boche CLI

00:16:52,939 --> 00:16:57,199
command to see the V ends it's managing

00:16:54,889 --> 00:16:58,970
so we can see how Bosch is dealing with

00:16:57,199 --> 00:17:01,939
this failure and we're already running

00:16:58,970 --> 00:17:03,350
the watch on get pods down here so we

00:17:01,939 --> 00:17:08,209
can see how kubernetes deals with the

00:17:03,350 --> 00:17:11,899
failure and will delete one of the nodes

00:17:08,209 --> 00:17:17,209
that has the dashboard running on it and

00:17:11,899 --> 00:17:20,620
one of our cockroach TV pods we have to

00:17:17,209 --> 00:17:20,620
get the name of it from this so

00:17:26,480 --> 00:17:30,980
the vans aren't named very easily but

00:17:29,289 --> 00:17:32,360
usually they don't need to be I don't

00:17:30,980 --> 00:17:36,460
think people are usually deleting their

00:17:32,360 --> 00:17:39,289
VMs on purpose but we do it a lot cool

00:17:36,460 --> 00:17:42,080
so this is going to take about two and a

00:17:39,289 --> 00:17:43,760
half minutes to delete Google has really

00:17:42,080 --> 00:17:45,529
fast beyond boot times but not really

00:17:43,760 --> 00:17:47,240
fast via I'm delete times which is

00:17:45,529 --> 00:17:49,039
probably the place that you want to

00:17:47,240 --> 00:17:52,090
optimize but depends on what you're

00:17:49,039 --> 00:17:55,250
doing I guess not in this demo but

00:17:52,090 --> 00:17:58,070
that's okay so let's talk about what's

00:17:55,250 --> 00:17:59,480
happening here well it's deleting so

00:17:58,070 --> 00:18:01,370
this is a current state of our cluster

00:17:59,480 --> 00:18:04,010
we have two masters but you can ignore

00:18:01,370 --> 00:18:06,380
that part we have three workers and the

00:18:04,010 --> 00:18:09,110
green tiny boxes hopefully you can see

00:18:06,380 --> 00:18:10,549
our our cockroach DB pods and then I

00:18:09,110 --> 00:18:13,240
just put this purple pod in here to

00:18:10,549 --> 00:18:17,269
represent the kubernetes dashboard and

00:18:13,240 --> 00:18:19,730
right now we are blowing up that worker

00:18:17,269 --> 00:18:21,919
node so we're gonna end up in this state

00:18:19,730 --> 00:18:24,380
which is not where we want to be we have

00:18:21,919 --> 00:18:30,590
two replicas of our cockroach DB and

00:18:24,380 --> 00:18:32,750
only zero of our dashboard so what will

00:18:30,590 --> 00:18:33,850
happen is kubernetes will notice that

00:18:32,750 --> 00:18:36,350
those pods are gone

00:18:33,850 --> 00:18:39,049
so it'll reschedule the dashboard onto

00:18:36,350 --> 00:18:42,320
another node which is great we asked the

00:18:39,049 --> 00:18:44,450
cockroach TV pods to all be on different

00:18:42,320 --> 00:18:46,600
nodes so it won't reschedule that one

00:18:44,450 --> 00:18:48,970
it'll just be mad for a little while and

00:18:46,600 --> 00:18:51,860
then our boss director will activate

00:18:48,970 --> 00:18:53,450
it'll notice that the VM is gone because

00:18:51,860 --> 00:18:56,480
it can't contact the agent that it's

00:18:53,450 --> 00:18:57,769
running on that VM then it'll wait a

00:18:56,480 --> 00:18:59,539
couple minutes to see if it's gonna come

00:18:57,769 --> 00:19:01,789
back on its own well I think it waits

00:18:59,539 --> 00:19:04,279
like 30 seconds I believe that's a

00:19:01,789 --> 00:19:06,289
setting in Bosch though and then it'll

00:19:04,279 --> 00:19:07,940
start creating the VM like I said it

00:19:06,289 --> 00:19:10,070
takes about 30 seconds to create a VM

00:19:07,940 --> 00:19:11,779
then it takes a couple more seconds to

00:19:10,070 --> 00:19:14,330
install the Bosch agent on the VM and

00:19:11,779 --> 00:19:16,549
then it has to run all of the jobs like

00:19:14,330 --> 00:19:17,990
the queue proxy and cubelet on that VM

00:19:16,549 --> 00:19:21,740
to make it part of our kubernetes

00:19:17,990 --> 00:19:23,299
cluster again once the note is that

00:19:21,740 --> 00:19:25,250
kubernetes will notice that it's there

00:19:23,299 --> 00:19:27,380
and it'll be like yay I can schedule

00:19:25,250 --> 00:19:28,429
that pod again and it will and then

00:19:27,380 --> 00:19:30,289
we'll be back in the state we were in

00:19:28,429 --> 00:19:31,580
before our dashboard will probably stay

00:19:30,289 --> 00:19:33,740
on the other node because it doesn't

00:19:31,580 --> 00:19:37,460
matter where it's running but we'll be

00:19:33,740 --> 00:19:38,539
in a happy state again so while we're

00:19:37,460 --> 00:19:40,190
continuing to wait do you want to talk

00:19:38,539 --> 00:19:44,490
about the product roadmap for a bit

00:19:40,190 --> 00:19:46,460
yes thanks Megan so while we're waiting

00:19:44,490 --> 00:19:48,480
for something to happen

00:19:46,460 --> 00:19:51,360
Washington Burnett is both notice that

00:19:48,480 --> 00:19:53,700
actually a machine is gone I can briefly

00:19:51,360 --> 00:19:57,179
talk you through the road map what's at

00:19:53,700 --> 00:20:00,780
the top of our backlog right now and I

00:19:57,179 --> 00:20:04,650
will be pointing out the when something

00:20:00,780 --> 00:20:08,100
fails as you can see now the VM that

00:20:04,650 --> 00:20:11,220
we've killed is now not recognized any

00:20:08,100 --> 00:20:12,990
longer by Bosch has a running vm so it's

00:20:11,220 --> 00:20:15,450
now suspecting that something went wrong

00:20:12,990 --> 00:20:17,520
it will disappear in about 20 seconds

00:20:15,450 --> 00:20:20,040
and a new one will boot in another 20

00:20:17,520 --> 00:20:22,940
seconds in the meantime I can tell you

00:20:20,040 --> 00:20:28,950
about the networking that we have

00:20:22,940 --> 00:20:30,690
planned so many before you start if you

00:20:28,950 --> 00:20:33,480
notice the cockroach TV pod is now

00:20:30,690 --> 00:20:34,679
unknown by kubernetes and if we could

00:20:33,480 --> 00:20:37,350
see the rest of this you'd see that the

00:20:34,679 --> 00:20:40,440
dashboard was recreated on a different

00:20:37,350 --> 00:20:45,690
node also G cloud has finally reported

00:20:40,440 --> 00:20:48,059
that it has deleted the VM yes okay so

00:20:45,690 --> 00:20:49,830
networking most of the Kubo clients

00:20:48,059 --> 00:20:51,600
would be really interested in exposing

00:20:49,830 --> 00:20:54,030
the applications they are deploying to

00:20:51,600 --> 00:20:57,390
kubernetes to outside of the kubernetes

00:20:54,030 --> 00:21:01,080
cluster at the moment we have two ways

00:20:57,390 --> 00:21:03,270
of exposing that one is through the CF

00:21:01,080 --> 00:21:06,530
routers another is through I allude

00:21:03,270 --> 00:21:08,850
bouncers the thing is they both have

00:21:06,530 --> 00:21:13,620
shortcomings and both needs to be

00:21:08,850 --> 00:21:15,240
further developed and yeah now our note

00:21:13,620 --> 00:21:17,760
is missing from box so that means Bosch

00:21:15,240 --> 00:21:23,040
is currently creating a new VM to be

00:21:17,760 --> 00:21:26,580
that worker node great next up is high

00:21:23,040 --> 00:21:28,350
availability which is which should be

00:21:26,580 --> 00:21:29,910
relying on the Bosch functionality but

00:21:28,350 --> 00:21:33,059
it's really need to be thoroughly tested

00:21:29,910 --> 00:21:35,940
we have a few experimental multi AZ

00:21:33,059 --> 00:21:38,370
deployments that seem to be working but

00:21:35,940 --> 00:21:41,370
we need to do more thorough testing on

00:21:38,370 --> 00:21:44,370
that so the the VM has came back up

00:21:41,370 --> 00:21:47,030
again and it's waiting for the agent to

00:21:44,370 --> 00:21:49,380
be installed in order to be running

00:21:47,030 --> 00:21:50,320
before it could be recognized by

00:21:49,380 --> 00:21:52,929
kubernetes

00:21:50,320 --> 00:21:54,309
oh it is running yeah so now it's

00:21:52,929 --> 00:21:55,929
running but it's installing all of those

00:21:54,309 --> 00:22:01,090
kubernetes jobs on it so that it becomes

00:21:55,929 --> 00:22:02,950
a true worker node so the next feature

00:22:01,090 --> 00:22:06,009
that is really in high demand is

00:22:02,950 --> 00:22:09,669
persistence because in most cases when

00:22:06,009 --> 00:22:11,350
people want to when people use Cloud

00:22:09,669 --> 00:22:14,320
Foundry and they want to have kubernetes

00:22:11,350 --> 00:22:16,809
is in many cases because they want to

00:22:14,320 --> 00:22:20,799
have stateless a stateful applications

00:22:16,809 --> 00:22:23,139
so they need persistence the kubernetes

00:22:20,799 --> 00:22:25,750
is handling the persistence through the

00:22:23,139 --> 00:22:28,059
platform but kubu has to be able to

00:22:25,750 --> 00:22:32,799
configure it properly in order to for it

00:22:28,059 --> 00:22:35,200
to be reliable core migration to the

00:22:32,799 --> 00:22:39,129
latest core components the kubernetes

00:22:35,200 --> 00:22:42,580
here it has a very fast upgrade update

00:22:39,129 --> 00:22:44,889
cycle so version one sticks came out two

00:22:42,580 --> 00:22:46,779
months ago version one seven will

00:22:44,889 --> 00:22:49,720
probably come out in about a month or so

00:22:46,779 --> 00:22:51,669
and there are a lot of differences

00:22:49,720 --> 00:22:54,759
between those versions so we need to

00:22:51,669 --> 00:22:57,879
stay on top of the track currently we

00:22:54,759 --> 00:22:59,139
don't support rolling upgrades but it's

00:22:57,879 --> 00:23:03,399
something we're really looking forward

00:22:59,139 --> 00:23:05,710
to it looks like our VM is now up and

00:23:03,399 --> 00:23:07,659
running and we have a cockroach TV pod

00:23:05,710 --> 00:23:09,009
that is initializing it takes a few

00:23:07,659 --> 00:23:10,210
minutes to initialize so I think we

00:23:09,009 --> 00:23:12,399
should just switch back to the slides

00:23:10,210 --> 00:23:16,230
but we are now back in the state that

00:23:12,399 --> 00:23:16,230
we'd like to be in because of Bosch

00:23:19,419 --> 00:23:26,829
and the last feature that is also very

00:23:23,799 --> 00:23:29,349
important is multi is so Bosch does

00:23:26,829 --> 00:23:31,899
support multiple houses which is really

00:23:29,349 --> 00:23:33,579
great but we also need to have some of

00:23:31,899 --> 00:23:36,399
our custom configuration in order to

00:23:33,579 --> 00:23:39,029
enable terminators to run that so this

00:23:36,399 --> 00:23:42,879
is really tied to persistence as well

00:23:39,029 --> 00:23:45,099
and as you may have seen yesterday

00:23:42,879 --> 00:23:46,989
Kubo was recently accepted into the

00:23:45,099 --> 00:23:54,129
Cloud Foundry foundation we're

00:23:46,989 --> 00:23:56,320
celebrating and this cat is really so we

00:23:54,129 --> 00:23:57,729
have here links to our repo but we're

00:23:56,320 --> 00:23:59,019
about to change them to Cloud Foundry

00:23:57,729 --> 00:24:00,339
incubator

00:23:59,019 --> 00:24:01,959
I believe these links will still work

00:24:00,339 --> 00:24:04,299
but if they don't work then just slap it

00:24:01,959 --> 00:24:06,459
to Cloud Foundry incubator this is our

00:24:04,299 --> 00:24:08,049
the Kubo deployment that's our helper

00:24:06,459 --> 00:24:09,519
scripts and Doc's that we have so if

00:24:08,049 --> 00:24:11,829
you're interested in deploying a

00:24:09,519 --> 00:24:13,570
kubernetes cluster using Bosch that's a

00:24:11,829 --> 00:24:15,339
really good place to start if you're

00:24:13,570 --> 00:24:18,009
really good at Bosch you could just go

00:24:15,339 --> 00:24:21,579
directly to our Bosch release at Kubo

00:24:18,009 --> 00:24:22,719
release I don't I wouldn't recommend it

00:24:21,579 --> 00:24:24,429
because it's hard to configure a

00:24:22,719 --> 00:24:26,409
manifest but and we have one already

00:24:24,429 --> 00:24:27,789
configured in Kubo deployment but if

00:24:26,409 --> 00:24:29,859
you're really adventurous you could do

00:24:27,789 --> 00:24:34,450
that and we also have a slack channel

00:24:29,859 --> 00:24:36,519
that I have a link to here Thanks

00:24:34,450 --> 00:24:39,450
I think we have a few minutes left for

00:24:36,519 --> 00:24:39,450
questions if anyone has questions

00:24:41,290 --> 00:24:51,370
all right your name and Association very

00:24:47,720 --> 00:24:55,630
quickly Sarah Gadon mother Kim Comcast

00:24:51,370 --> 00:25:00,200
question about about persistency and

00:24:55,630 --> 00:25:03,080
volume management last time I checked

00:25:00,200 --> 00:25:07,330
you we're focusing on a cluster right is

00:25:03,080 --> 00:25:09,370
there plan to have it more pluggable

00:25:07,330 --> 00:25:12,790
specifically for installations inside

00:25:09,370 --> 00:25:15,500
data centers not in a not in a cloud

00:25:12,790 --> 00:25:18,110
something like a scale AO and other

00:25:15,500 --> 00:25:21,470
backends to use so at the moment we're

00:25:18,110 --> 00:25:25,460
focusing on native volumes that are

00:25:21,470 --> 00:25:27,620
provided by the iOS platforms and we're

00:25:25,460 --> 00:25:28,040
not focusing on other solutions right

00:25:27,620 --> 00:25:30,800
now

00:25:28,040 --> 00:25:38,030
so it might even though it might be in

00:25:30,800 --> 00:25:43,340
the pipeline but it's for later what

00:25:38,030 --> 00:25:45,290
question of kubernetes are you can you

00:25:43,340 --> 00:25:47,810
speak up please can you hear me louder

00:25:45,290 --> 00:25:50,000
okay what version of Cloud Foundry are

00:25:47,810 --> 00:25:53,120
sorry the company is allowing you to

00:25:50,000 --> 00:25:58,970
apply through CF and there was two

00:25:53,120 --> 00:26:02,120
statements you made okay can everybody

00:25:58,970 --> 00:26:04,550
hear my question was like what version

00:26:02,120 --> 00:26:06,980
of kubernetes were you allowing to

00:26:04,550 --> 00:26:09,050
deploy through CF at this time because

00:26:06,980 --> 00:26:10,850
you made a two statement you can add

00:26:09,050 --> 00:26:14,060
scale mashers you can add scale easily

00:26:10,850 --> 00:26:16,970
that is totally wrong I mean to say the

00:26:14,060 --> 00:26:19,040
version 162 allows that way to a scale

00:26:16,970 --> 00:26:22,130
masters in multiple notes and then you

00:26:19,040 --> 00:26:25,970
can also scale etcd the the quorum into

00:26:22,130 --> 00:26:30,470
multiple nodes are multiple measures so

00:26:25,970 --> 00:26:33,670
if you question the version of at the

00:26:30,470 --> 00:26:36,260
moment of kubernetes I think is one six

00:26:33,670 --> 00:26:40,810
one six one is the current version of

00:26:36,260 --> 00:26:40,810
kubernetes but we're planning to update

00:26:41,710 --> 00:26:46,210
okay additional questions yes

00:26:51,389 --> 00:27:02,799
so auto-scaling

00:26:53,169 --> 00:27:04,749
and you are Shandra fun to update the

00:27:02,799 --> 00:27:06,369
bosch manifest with an additional number

00:27:04,749 --> 00:27:08,710
and then bosch will kind of do a diff of

00:27:06,369 --> 00:27:11,200
what you want and what you have and

00:27:08,710 --> 00:27:15,509
scale that way we haven't talked about

00:27:11,200 --> 00:27:15,509
auto scaling but that would be cool yeah

00:27:21,029 --> 00:27:24,029
yeah

00:27:24,860 --> 00:27:33,260
you can do it for me automatically

00:27:30,610 --> 00:27:35,960
automated that also like our

00:27:33,260 --> 00:27:38,540
prioritization process is a lot based on

00:27:35,960 --> 00:27:39,620
what people are asking for so I mean the

00:27:38,540 --> 00:27:42,140
fact that you're asking that means we

00:27:39,620 --> 00:27:46,250
should probably talk about it you have a

00:27:42,140 --> 00:27:49,160
couple of more questions so one here hi

00:27:46,250 --> 00:27:51,440
guys from Accenture I think this is

00:27:49,160 --> 00:27:53,240
great and solves a really big problem

00:27:51,440 --> 00:27:58,150
but I have two questions

00:27:53,240 --> 00:28:00,470
how do you keep it from falling behind

00:27:58,150 --> 00:28:03,440
from like kubernetes as you mentioned

00:28:00,470 --> 00:28:09,620
it's a fast pace and the second part is

00:28:03,440 --> 00:28:11,570
how do you prevent it from like exposing

00:28:09,620 --> 00:28:13,370
like limited set of features like you

00:28:11,570 --> 00:28:14,900
mentioned like there's a persistence

00:28:13,370 --> 00:28:16,760
that's still not there and other things

00:28:14,900 --> 00:28:19,730
so I think those two problems would

00:28:16,760 --> 00:28:22,490
continue so what is like overall

00:28:19,730 --> 00:28:27,770
strategy to you know make this kind of

00:28:22,490 --> 00:28:29,000
like a default way of yeah I mean since

00:28:27,770 --> 00:28:31,520
we're in a pre-alpha state right now

00:28:29,000 --> 00:28:33,230
we're obviously missing some things in

00:28:31,520 --> 00:28:34,820
terms of keeping kubernetes up-to-date

00:28:33,230 --> 00:28:36,799
right now we're just manually updating

00:28:34,820 --> 00:28:38,299
the binaries but I think it'd be cool if

00:28:36,799 --> 00:28:40,040
we could do like an automatic system

00:28:38,299 --> 00:28:42,290
that do that like a pipeline Concours

00:28:40,040 --> 00:28:43,780
pipeline or something which I think

00:28:42,290 --> 00:28:45,710
we've started talking about a little bit

00:28:43,780 --> 00:28:47,150
so I don't think you could do that for

00:28:45,710 --> 00:28:50,330
major versions maybe but at least for

00:28:47,150 --> 00:28:56,480
minor versions and then your second

00:28:50,330 --> 00:28:57,770
question was oh yeah right so I think

00:28:56,480 --> 00:28:59,480
the thing we're missing in kubernetes

00:28:57,770 --> 00:29:01,820
right now is that we don't have these

00:28:59,480 --> 00:29:03,830
like cloud provider packages so it can't

00:29:01,820 --> 00:29:05,390
provision cloud resources right now but

00:29:03,830 --> 00:29:07,370
we're actively working on that like this

00:29:05,390 --> 00:29:09,020
week so hopefully once we have that in

00:29:07,370 --> 00:29:10,730
place we'll be able to provision things

00:29:09,020 --> 00:29:14,120
like load balancers or the persistent

00:29:10,730 --> 00:29:16,250
volumes one last question you did okay

00:29:14,120 --> 00:29:17,419
Jeff has to go the constant Tina and I

00:29:16,250 --> 00:29:21,140
are gonna stick around after if you have

00:29:17,419 --> 00:29:23,870
questions too so quick question so there

00:29:21,140 --> 00:29:25,820
is Bosh which I'm really a big fan and

00:29:23,870 --> 00:29:29,540
then there is infra Creek and there is

00:29:25,820 --> 00:29:33,760
also cops so my question is is that mean

00:29:29,540 --> 00:29:36,910
that cops is done is gone and like

00:29:33,760 --> 00:29:38,730
can you explain please oh do you think

00:29:36,910 --> 00:29:41,140
cots coffee

00:29:38,730 --> 00:29:44,800
k-o-k UPS like the way you actually

00:29:41,140 --> 00:29:46,210
install the big difference oh not

00:29:44,800 --> 00:29:47,680
necessarily I mean some people I think

00:29:46,210 --> 00:29:49,390
are using kubernetes in different ways

00:29:47,680 --> 00:29:51,640
this is really more for like production

00:29:49,390 --> 00:29:54,130
workloads I think and things that really

00:29:51,640 --> 00:29:55,960
need something to manage kubernetes I

00:29:54,130 --> 00:29:58,290
don't know that every use case requires

00:29:55,960 --> 00:29:58,290
that

00:30:01,470 --> 00:30:05,589
[Music]

00:30:02,040 --> 00:30:05,589

YouTube URL: https://www.youtube.com/watch?v=uOFW_0J9q70


