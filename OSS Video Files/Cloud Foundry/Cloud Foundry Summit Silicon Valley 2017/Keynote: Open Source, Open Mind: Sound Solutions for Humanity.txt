Title: Keynote: Open Source, Open Mind: Sound Solutions for Humanity
Publication date: 2017-06-21
Playlist: Cloud Foundry Summit Silicon Valley 2017
Description: 
	Keynote: Open Source, Open Mind: Sound Solutions for Humanity - Kyla A. McMullen, PhD, Assistant Professor, University of Florida    

Undoubtedly, there is a strong connection between open source contribution and academia: collaboration across multiple groups, open access to information, and quality over quantity. Dr. McMullen will discuss how the SoundPadLab at the University of Florida uses open source to create novel solutions to many societal challenges. Come hear about how open source projects are being implemented in academic and human contexts.

Kyla A. McMullen, PhD
University of Florida
Assistant Professor
Dr. Kyla McMullen earned her Bachelor of Science in Computer Science from the University of Maryland, Baltimore County (UMBC), where she was also a Meyerhoff Scholar. She earned her Masters and Ph.D. degrees in Computer Science and Engineering from the University of Michigan (2007-2012). While earning her Ph.D. she was also a faculty member at Wayne State University in Detroit, Michigan. At Wayne State University she taught computer literacy courses to over 2,000 students. Professor McMullen is the first underrepresented woman to earn a Ph.D. in Computer Science and Engineering from the University of Michigan. She is currently a tenure-track faculty member at the University of Floridaâ€™s Computer & Information Sciences & Engineering Department. Dr. McMullen has a personal commitment to encouraging women and minorities to pursue careers in computing and other STEM fields. She is the creator of "Beautiful, Black, and Brainy" and "Brilliant is the New Black", which showcase hundreds of exceptional young African Americans who excel in STEM fields and don't fit the typical "scientist" stereotype. 

Dr. McMullen is the leader of the SoundPAD Laboratory at the University of Florida, which focuses on the Perception, Application, and Development of 3D audio in various contexts. Current projects include (1) psychoacoustic analysis of the quality of customized head-related transfer functions, (2) using 3D audio to sonify positional data for situational awareness, (3) using virtual spatial audio to augment assistive technology for persons with visual impairments, (4) discovering critical interface design techniques for developing virtual auditory environments, and (5) using 3D audio to increase immersion and realness in virtual and augmented reality.
Captions: 
	00:00:00,030 --> 00:00:04,950
good afternoon guys hear me all right

00:00:02,790 --> 00:00:06,899
there we go it's so good to see you all

00:00:04,950 --> 00:00:10,050
here I did not know Beyonce was the

00:00:06,899 --> 00:00:12,269
theme but I'm so excited about it so as

00:00:10,050 --> 00:00:15,120
Kim mentioned I'm going to talk to you

00:00:12,269 --> 00:00:17,369
today about open source open mind so I'm

00:00:15,120 --> 00:00:19,590
faculty at University of Florida I'm an

00:00:17,369 --> 00:00:22,050
assistant professor there and I run the

00:00:19,590 --> 00:00:24,990
sound pad lab and this is where the

00:00:22,050 --> 00:00:27,330
sound thing comes in so open source open

00:00:24,990 --> 00:00:29,220
mind we use open source software to

00:00:27,330 --> 00:00:32,279
create a lot of our research projects

00:00:29,220 --> 00:00:33,960
and then open mine is the second half of

00:00:32,279 --> 00:00:36,180
the presentation where we're going to

00:00:33,960 --> 00:00:38,070
talk about how when we're creating these

00:00:36,180 --> 00:00:40,260
open source projects and contributing

00:00:38,070 --> 00:00:44,010
suit them how we can think about them

00:00:40,260 --> 00:00:46,320
from an inclusive design perspective all

00:00:44,010 --> 00:00:48,480
right so what do I work on I said

00:00:46,320 --> 00:00:50,520
computer science but more specifically

00:00:48,480 --> 00:00:53,910
we work on a very specific application

00:00:50,520 --> 00:00:56,460
of sounds and computer interfaces called

00:00:53,910 --> 00:00:58,770
3d sounds so typically when you think of

00:00:56,460 --> 00:01:00,480
3d you typically think of the picture

00:00:58,770 --> 00:01:02,820
here on the left where you put on a

00:01:00,480 --> 00:01:06,840
headset and then you're automatically in

00:01:02,820 --> 00:01:09,990
a virtual world so visually you guys got

00:01:06,840 --> 00:01:13,049
it you know what 3d visually is but what

00:01:09,990 --> 00:01:15,030
in the world is 3d sound luckily I am

00:01:13,049 --> 00:01:18,000
going to tell you so how many of you

00:01:15,030 --> 00:01:21,390
have used unity or unreal any of those

00:01:18,000 --> 00:01:24,299
engines ok a few of you so if you've

00:01:21,390 --> 00:01:26,580
noticed as of late there is a check box

00:01:24,299 --> 00:01:28,829
that you can check that says hey do you

00:01:26,580 --> 00:01:30,689
want to turn on that 3d audio spatial

00:01:28,829 --> 00:01:32,400
Iser I know it's especially in unity I

00:01:30,689 --> 00:01:35,310
know you're wondering what in the world

00:01:32,400 --> 00:01:39,090
is that I'm so glad you asked

00:01:35,310 --> 00:01:42,780
nobody asks but I'm glad you asked me we

00:01:39,090 --> 00:01:44,970
think of 3d visually there are two

00:01:42,780 --> 00:01:46,770
different pictures that are given to

00:01:44,970 --> 00:01:48,329
your eyes so as you see the picture on

00:01:46,770 --> 00:01:50,340
the left there's two different pictures

00:01:48,329 --> 00:01:52,320
and your brain combines them and it

00:01:50,340 --> 00:01:54,210
gives you the sense of depth and of

00:01:52,320 --> 00:01:56,640
space so we do the same sort of

00:01:54,210 --> 00:01:58,770
techniques with 3d audio where we give

00:01:56,640 --> 00:02:00,390
two different sounds to your ears and

00:01:58,770 --> 00:02:02,579
when your brain combines them it's

00:02:00,390 --> 00:02:04,829
perceived as being coming from like a

00:02:02,579 --> 00:02:07,860
specific location in space I know you

00:02:04,829 --> 00:02:11,940
are thinking what kind of crazy magic is

00:02:07,860 --> 00:02:13,940
that so this is made possible by the use

00:02:11,940 --> 00:02:17,600
of pet related transfer phone

00:02:13,940 --> 00:02:19,340
or HR ts so I'm pretty sure almost

00:02:17,600 --> 00:02:19,580
nobody in the room knows what these are

00:02:19,340 --> 00:02:22,550
about

00:02:19,580 --> 00:02:24,140
but just from a general perspective

00:02:22,550 --> 00:02:26,570
hair-related transfer functions

00:02:24,140 --> 00:02:28,430
basically describe the acoustic

00:02:26,570 --> 00:02:31,250
transformation of sound in the

00:02:28,430 --> 00:02:33,800
environment to your ear so the way that

00:02:31,250 --> 00:02:35,900
we can measure them is imagine that we

00:02:33,800 --> 00:02:38,450
have our friend up here on the Left

00:02:35,900 --> 00:02:39,710
sitting inside of an anechoic chamber so

00:02:38,450 --> 00:02:41,810
sitting in a room that has no

00:02:39,710 --> 00:02:44,480
reflections and there's two microphones

00:02:41,810 --> 00:02:46,910
inside of their ears so if you can see

00:02:44,480 --> 00:02:49,310
their speakers all around this person so

00:02:46,910 --> 00:02:51,770
a sound displayed impulse response

00:02:49,310 --> 00:02:53,420
actually in a certain direction so then

00:02:51,770 --> 00:02:55,550
we can record all of these impulse

00:02:53,420 --> 00:02:57,650
responses so if you look up you can see

00:02:55,550 --> 00:03:00,020
the left ear gets the signal the right

00:02:57,650 --> 00:03:03,560
air gets the signal in this example here

00:03:00,020 --> 00:03:03,920
the left ear is the closest ear to the

00:03:03,560 --> 00:03:06,890
sound

00:03:03,920 --> 00:03:09,320
so the has a higher amplitude and then

00:03:06,890 --> 00:03:12,370
the right ear is the farthest ear so the

00:03:09,320 --> 00:03:14,630
right ear actually has a slight delay

00:03:12,370 --> 00:03:16,220
receiving the sound so we can take this

00:03:14,630 --> 00:03:19,340
amplitude difference or sorry this

00:03:16,220 --> 00:03:20,959
volume difference this time delay and

00:03:19,340 --> 00:03:23,150
then some head shadowing because of the

00:03:20,959 --> 00:03:25,340
head combine those all together and

00:03:23,150 --> 00:03:28,220
create a filter such that we can take

00:03:25,340 --> 00:03:30,470
any sound source and convolve it with

00:03:28,220 --> 00:03:32,660
that impulse response and then it sounds

00:03:30,470 --> 00:03:35,690
like the sound is coming from anywhere

00:03:32,660 --> 00:03:37,850
in space around you so by doing this we

00:03:35,690 --> 00:03:39,860
have a bunch of different head related

00:03:37,850 --> 00:03:41,900
transfer functions for all different

00:03:39,860 --> 00:03:44,390
locations in space so it allows us to

00:03:41,900 --> 00:03:47,030
use sound treated as though it's a

00:03:44,390 --> 00:03:49,880
signal and manipulate it using DSP or

00:03:47,030 --> 00:03:52,250
digital signal processing so emulate how

00:03:49,880 --> 00:03:55,370
sound actually travels in space so we

00:03:52,250 --> 00:03:58,010
can take in a mono or a single channel

00:03:55,370 --> 00:03:59,330
sound source and then split it into one

00:03:58,010 --> 00:04:01,700
for the left ear one for the right ear

00:03:59,330 --> 00:04:03,950
and then impose a delay on the farther

00:04:01,700 --> 00:04:05,630
side and then actually filter it don't

00:04:03,950 --> 00:04:07,970
worry this is not on the test I promise

00:04:05,630 --> 00:04:10,640
and then filter it and so when a person

00:04:07,970 --> 00:04:13,550
hears that over headphones it actually

00:04:10,640 --> 00:04:17,120
sounds like it's coming from a location

00:04:13,550 --> 00:04:19,970
in space so you guys are not excited

00:04:17,120 --> 00:04:21,709
enough about this you're not excited but

00:04:19,970 --> 00:04:24,950
you know what I was prepared for it I

00:04:21,709 --> 00:04:26,210
was prepared for it I was prepared

00:04:24,950 --> 00:04:27,500
because you know sometimes

00:04:26,210 --> 00:04:30,050
you know you need a little bit of

00:04:27,500 --> 00:04:32,539
convincing of why being able to put a

00:04:30,050 --> 00:04:35,060
sound anywhere in space should be

00:04:32,539 --> 00:04:38,389
something of interest to you so in my

00:04:35,060 --> 00:04:40,190
lab we use this technology combined with

00:04:38,389 --> 00:04:42,530
open source software and cloud software

00:04:40,190 --> 00:04:45,080
services to make solutions for a wide

00:04:42,530 --> 00:04:48,319
variety of populations but before I talk

00:04:45,080 --> 00:04:52,550
about any of those projects I have to

00:04:48,319 --> 00:04:55,300
think my minions I mean my lab group so

00:04:52,550 --> 00:04:57,620
these are the folks that I work with and

00:04:55,300 --> 00:04:59,389
without a lot of them a lot of this

00:04:57,620 --> 00:05:02,180
wouldn't be possible these are grad

00:04:59,389 --> 00:05:04,190
students undergrad master students and

00:05:02,180 --> 00:05:06,410
I'll also show you some work from

00:05:04,190 --> 00:05:08,870
students that are in my 3d audio special

00:05:06,410 --> 00:05:10,880
topics course so actually I wanted to go

00:05:08,870 --> 00:05:12,380
back for a second so our group is kind

00:05:10,880 --> 00:05:14,259
of like the Avengers I like to think

00:05:12,380 --> 00:05:17,210
like everybody has their own specific

00:05:14,259 --> 00:05:19,729
little like specialties and skills and

00:05:17,210 --> 00:05:21,650
then in this picture Ben has on green so

00:05:19,729 --> 00:05:24,020
he's like the Hulk so yeah this is our

00:05:21,650 --> 00:05:27,020
Avengers picture everybody is special in

00:05:24,020 --> 00:05:29,180
their own unique way love it so these

00:05:27,020 --> 00:05:31,490
are a few of the open-source software

00:05:29,180 --> 00:05:35,389
packages that we use in the lab with

00:05:31,490 --> 00:05:38,810
varying degrees of openness so one

00:05:35,389 --> 00:05:41,210
project is literally called beep boop

00:05:38,810 --> 00:05:43,699
blip Adeeb up and just pause for a

00:05:41,210 --> 00:05:45,979
second this is one of the reasons you

00:05:43,699 --> 00:05:48,440
don't give the students free rein to

00:05:45,979 --> 00:05:51,560
name the projects anything that they

00:05:48,440 --> 00:05:55,400
want to but this one I call it quadric

00:05:51,560 --> 00:05:58,159
will be but it is beep blip a debug but

00:05:55,400 --> 00:06:00,380
the take-home point is here imagine that

00:05:58,159 --> 00:06:02,539
you are not even imagining just a quick

00:06:00,380 --> 00:06:05,750
show of hands how many of you ride a

00:06:02,539 --> 00:06:08,210
motorcycle have a motorcycle all 10 of

00:06:05,750 --> 00:06:09,979
you Wow so I can't believe that this

00:06:08,210 --> 00:06:12,320
room full of computer scientists we

00:06:09,979 --> 00:06:16,130
don't have more bikers really really I'm

00:06:12,320 --> 00:06:19,430
joking I can imagine it anyways imagine

00:06:16,130 --> 00:06:22,190
if you are in a room sorry if you are a

00:06:19,430 --> 00:06:23,449
biker and you need to change lanes so

00:06:22,190 --> 00:06:25,460
this is actually a quick little

00:06:23,449 --> 00:06:27,259
depiction out of the biker training

00:06:25,460 --> 00:06:29,300
manual where you have to do a head check

00:06:27,259 --> 00:06:31,250
where you literally turn your head and

00:06:29,300 --> 00:06:33,050
look before you change lanes but guess

00:06:31,250 --> 00:06:35,469
what you're taking your eyes off the

00:06:33,050 --> 00:06:38,150
road in front of you so in order to

00:06:35,469 --> 00:06:39,919
combat that eyes off the road problem

00:06:38,150 --> 00:06:43,280
that could lead to potential danger

00:06:39,919 --> 00:06:46,219
we've created using Python and dudu to

00:06:43,280 --> 00:06:49,819
open-source pieces an actual prototype

00:06:46,219 --> 00:06:52,729
that allows you to put sensors inside a

00:06:49,819 --> 00:06:55,759
provider's helmet and it can sense the

00:06:52,729 --> 00:06:59,240
proximity of incoming cars so you can

00:06:55,759 --> 00:07:00,919
actually hear them as sounds in 3d space

00:06:59,240 --> 00:07:02,719
I remember that 3d audio thing we can

00:07:00,919 --> 00:07:04,939
put sounds anywhere around you well you

00:07:02,719 --> 00:07:06,580
can ride a bicycle and have or ride a

00:07:04,939 --> 00:07:09,349
motorcycle and have things coming from

00:07:06,580 --> 00:07:11,090
anywhere around you and you can perceive

00:07:09,349 --> 00:07:15,349
them without having to turn your head so

00:07:11,090 --> 00:07:17,120
this 360-degree awareness and in order

00:07:15,349 --> 00:07:19,610
to make sure that the motorcycle is this

00:07:17,120 --> 00:07:22,400
safe and we're not just clouding their

00:07:19,610 --> 00:07:24,439
whole their ears with all sorts of

00:07:22,400 --> 00:07:26,000
sounds we can deliver it over bone

00:07:24,439 --> 00:07:28,520
phones we have wireless phone phones

00:07:26,000 --> 00:07:30,949
that connect to that you do so that bone

00:07:28,520 --> 00:07:32,810
phones actually conduct sound to your

00:07:30,949 --> 00:07:35,120
ears without being on your ears they

00:07:32,810 --> 00:07:37,879
said on this this bone right here so

00:07:35,120 --> 00:07:39,589
that's one project another project is a

00:07:37,879 --> 00:07:42,110
little bit similar except in the

00:07:39,589 --> 00:07:44,300
aviation domain so this is called plane

00:07:42,110 --> 00:07:47,330
sense and we use an open source project

00:07:44,300 --> 00:07:51,050
called Stratus and Stratus is an open

00:07:47,330 --> 00:07:53,960
source aviation it's actually just

00:07:51,050 --> 00:07:56,990
traffic and weather but we just use the

00:07:53,960 --> 00:07:58,969
traffic portion of it so allow pilots to

00:07:56,990 --> 00:08:01,399
not have to actually look down at their

00:07:58,969 --> 00:08:04,430
instrumentation as much to figure out

00:08:01,399 --> 00:08:07,520
the proximity of other aircraft pilots

00:08:04,430 --> 00:08:10,250
can hear sounds in 3d space that relate

00:08:07,520 --> 00:08:12,139
to the proximity of other aircraft so

00:08:10,250 --> 00:08:13,939
here we've increased their situational

00:08:12,139 --> 00:08:15,319
awareness without overloading their

00:08:13,939 --> 00:08:17,659
visual channel so if any of you've ever

00:08:15,319 --> 00:08:19,849
seen a cockpit there are a thousand

00:08:17,659 --> 00:08:21,710
different panels and gauges why add

00:08:19,849 --> 00:08:23,839
another one for them to look at where

00:08:21,710 --> 00:08:25,490
you can utilize the ears and show them

00:08:23,839 --> 00:08:27,560
where things are so this is another

00:08:25,490 --> 00:08:31,310
open-source technology that we're using

00:08:27,560 --> 00:08:33,019
in this domain so this one isn't saving

00:08:31,310 --> 00:08:36,320
anybody's life this one's more of a fun

00:08:33,019 --> 00:08:38,870
one it's called 3d eight and it uses

00:08:36,320 --> 00:08:42,110
pidgin anybody ever seen pidgin before

00:08:38,870 --> 00:08:44,810
maybe a few of you okay cool so we

00:08:42,110 --> 00:08:47,029
hacked up pigeon and pigeons a messaging

00:08:44,810 --> 00:08:48,980
client and it operates with a bunch of

00:08:47,029 --> 00:08:51,890
different some multiple multi platform

00:08:48,980 --> 00:08:52,600
instant messaging protocol so imagine

00:08:51,890 --> 00:08:54,639
that

00:08:52,600 --> 00:08:57,009
you want to receive your instant

00:08:54,639 --> 00:08:59,050
messages but you don't want to

00:08:57,009 --> 00:09:01,089
constantly look up and see okay who

00:08:59,050 --> 00:09:03,250
delivered this message how important is

00:09:01,089 --> 00:09:05,500
this so you can create settings here to

00:09:03,250 --> 00:09:07,750
say all right if I receive a message

00:09:05,500 --> 00:09:10,240
from my boss I want it to come in 3d

00:09:07,750 --> 00:09:12,490
space really close to me but if it's

00:09:10,240 --> 00:09:14,230
build down the hallway and Bill just

00:09:12,490 --> 00:09:17,079
wants to talk about the Cavaliers nobody

00:09:14,230 --> 00:09:19,240
was here about the Cavaliers so if it's

00:09:17,079 --> 00:09:20,980
just bill and you can say okay I can

00:09:19,240 --> 00:09:22,630
come from a farther away location

00:09:20,980 --> 00:09:25,449
perhaps even the trash can so it's a way

00:09:22,630 --> 00:09:28,089
to just customize the way to customize

00:09:25,449 --> 00:09:29,980
your whole instant messaging listening

00:09:28,089 --> 00:09:32,380
experience so that you don't have to

00:09:29,980 --> 00:09:34,329
always pop out of whatever you're doing

00:09:32,380 --> 00:09:36,579
to determine if it's from someone who's

00:09:34,329 --> 00:09:38,680
important or not the actual location the

00:09:36,579 --> 00:09:39,790
sound comes from can tell you whether or

00:09:38,680 --> 00:09:43,029
not it's something you should pay

00:09:39,790 --> 00:09:45,970
attention to in this next one it's not

00:09:43,029 --> 00:09:47,470
exactly a 3d audio project but I still

00:09:45,970 --> 00:09:50,980
think it's cool

00:09:47,470 --> 00:09:53,350
we were we were approached by a PC

00:09:50,980 --> 00:09:55,930
company that I can't name yet but we

00:09:53,350 --> 00:09:58,980
were approached to use BCI if anyone

00:09:55,930 --> 00:10:02,259
heard of BCI brain computer interfaces

00:09:58,980 --> 00:10:03,009
nobody ok few of you a few of you so for

00:10:02,259 --> 00:10:05,410
the rest of the room

00:10:03,009 --> 00:10:07,449
BCI or brain computer interfaces are

00:10:05,410 --> 00:10:10,060
these sensors and they typically come as

00:10:07,449 --> 00:10:12,279
these commercial off-the-shelf sort of

00:10:10,060 --> 00:10:14,050
like headsets and they have lots of

00:10:12,279 --> 00:10:17,410
sensors on them you can actually read

00:10:14,050 --> 00:10:20,860
brainwave data with them so using these

00:10:17,410 --> 00:10:23,050
you can basically train a machine to

00:10:20,860 --> 00:10:25,630
recognize different patterns of data so

00:10:23,050 --> 00:10:27,639
we map these different commands that the

00:10:25,630 --> 00:10:31,000
brain is giving to commit to key

00:10:27,639 --> 00:10:33,069
commands such that for this project the

00:10:31,000 --> 00:10:36,220
company we're working with has a person

00:10:33,069 --> 00:10:38,410
who they were previously a heavy-metal

00:10:36,220 --> 00:10:40,269
drummer and they are currently an

00:10:38,410 --> 00:10:42,279
amputee and we'd like to restore his

00:10:40,269 --> 00:10:43,870
ability to play the drums again so we've

00:10:42,279 --> 00:10:47,230
created sort of like a MIDI trigger

00:10:43,870 --> 00:10:48,939
using this BCI headset but using juice

00:10:47,230 --> 00:10:52,420
which is another open-source

00:10:48,939 --> 00:10:54,639
cross-platform audio application to

00:10:52,420 --> 00:10:56,050
facilitate a lot of this so as you can

00:10:54,639 --> 00:10:57,610
see we're using open-source the state of

00:10:56,050 --> 00:11:01,449
the world right so we're creating this

00:10:57,610 --> 00:11:03,610
customized solution for that project and

00:11:01,449 --> 00:11:05,860
this is a picture of this has actually

00:11:03,610 --> 00:11:07,810
been again using um

00:11:05,860 --> 00:11:10,029
the first models that we use we actually

00:11:07,810 --> 00:11:12,310
didn't end up using this device but this

00:11:10,029 --> 00:11:14,019
is one of the concepts behind it where a

00:11:12,310 --> 00:11:16,120
person is literally sitting in front of

00:11:14,019 --> 00:11:17,829
the computer with this device on and

00:11:16,120 --> 00:11:20,079
we're literally just changing the face

00:11:17,829 --> 00:11:21,490
of an emoji to see if we can like you

00:11:20,079 --> 00:11:24,880
know just get it to change this is one

00:11:21,490 --> 00:11:26,500
of the early phases alright and the last

00:11:24,880 --> 00:11:28,600
project I'll tell you about that we're

00:11:26,500 --> 00:11:30,850
working on is called sensing the

00:11:28,600 --> 00:11:33,190
museum's so if you were a person who's

00:11:30,850 --> 00:11:35,410
visually impaired and you went to visit

00:11:33,190 --> 00:11:37,120
a museum it would be a pretty boring

00:11:35,410 --> 00:11:39,100
experience why because everything's on

00:11:37,120 --> 00:11:40,510
the walls it's visual let me see if I

00:11:39,100 --> 00:11:43,630
already boring in the first place right

00:11:40,510 --> 00:11:45,220
so if you can't see anything but it's

00:11:43,630 --> 00:11:48,040
extra for I'm checking these hands are

00:11:45,220 --> 00:11:49,720
fun but if you're visually impaired

00:11:48,040 --> 00:11:51,910
there isn't much that's accessible to

00:11:49,720 --> 00:11:54,550
you so we're collaborating with the

00:11:51,910 --> 00:11:56,410
museum science program at the University

00:11:54,550 --> 00:11:58,570
of Florida to create a very accessible

00:11:56,410 --> 00:12:01,329
museum experience where we have an

00:11:58,570 --> 00:12:03,279
indoor localization system such that if

00:12:01,329 --> 00:12:05,829
you are standing anywhere in the room

00:12:03,279 --> 00:12:07,510
you can hear a sound coming from the

00:12:05,829 --> 00:12:09,550
locations of all the different exhibits

00:12:07,510 --> 00:12:11,620
so you can interact with those you can

00:12:09,550 --> 00:12:13,329
choose it's a Panama Canal exhibit for

00:12:11,620 --> 00:12:15,130
the first one so you can say okay do I

00:12:13,329 --> 00:12:18,279
want to hear an oral history I can walk

00:12:15,130 --> 00:12:20,110
over here so I want to hear about some

00:12:18,279 --> 00:12:22,690
sports so you can walk around and

00:12:20,110 --> 00:12:26,860
personalize your whole experience so

00:12:22,690 --> 00:12:28,810
this is this is basically a way to make

00:12:26,860 --> 00:12:30,790
the museum more accessible for a

00:12:28,810 --> 00:12:33,220
population that people generally don't

00:12:30,790 --> 00:12:35,470
think about with when designing museums

00:12:33,220 --> 00:12:38,290
so as you can see we have a lot going on

00:12:35,470 --> 00:12:40,240
in my lap in my lab but when you take a

00:12:38,290 --> 00:12:42,550
step back when you're designing software

00:12:40,240 --> 00:12:44,709
for all of us you have to reflect and

00:12:42,550 --> 00:12:48,449
think about population that you're

00:12:44,709 --> 00:12:52,240
actually designing for so this is the

00:12:48,449 --> 00:12:54,670
transition into solutions for Humanity

00:12:52,240 --> 00:12:57,310
this portion so this is making a case

00:12:54,670 --> 00:12:59,350
for inclusive design so this means

00:12:57,310 --> 00:13:01,510
inclusive design is when you design a

00:12:59,350 --> 00:13:03,850
software or a piece of product thinking

00:13:01,510 --> 00:13:08,140
about everyone who could potentially use

00:13:03,850 --> 00:13:09,459
it and not just the general case so some

00:13:08,140 --> 00:13:11,350
of these lives may or may not have been

00:13:09,459 --> 00:13:13,839
stolen with or without permission of my

00:13:11,350 --> 00:13:15,880
friend Nancy to yarn from uber but we

00:13:13,839 --> 00:13:19,209
shall move along so we can all agree

00:13:15,880 --> 00:13:21,879
that we all design software and there

00:13:19,209 --> 00:13:24,129
some terrible interfaces out there some

00:13:21,879 --> 00:13:26,470
of us are guilty of creating them and if

00:13:24,129 --> 00:13:27,040
you're not convinced then I can show you

00:13:26,470 --> 00:13:30,189
this

00:13:27,040 --> 00:13:32,410
so all right everyone's seen one of

00:13:30,189 --> 00:13:35,199
these you go in you pay for your items

00:13:32,410 --> 00:13:39,749
but what button are you supposed to

00:13:35,199 --> 00:13:39,749
press to complete the credit transaction

00:13:40,649 --> 00:13:48,160
so someone said the green one so yeah it

00:13:44,649 --> 00:13:50,769
says okay so usually green means yes

00:13:48,160 --> 00:13:52,720
confirmation okay it actually says enter

00:13:50,769 --> 00:13:54,610
in yes on it but nothing really says

00:13:52,720 --> 00:13:56,740
okay but then we could think all right

00:13:54,610 --> 00:13:59,860
let's press this middle button here

00:13:56,740 --> 00:14:02,079
because there's a arrow pointing to be

00:13:59,860 --> 00:14:04,240
okay perhaps that's the answer or maybe

00:14:02,079 --> 00:14:05,679
even the button that says credit because

00:14:04,240 --> 00:14:08,619
we're trying to do a credit transaction

00:14:05,679 --> 00:14:12,189
so as you can see here there are some

00:14:08,619 --> 00:14:14,709
real ambiguities in this interface so we

00:14:12,189 --> 00:14:16,420
can all agree that interfaces can be

00:14:14,709 --> 00:14:19,779
designed a bit better

00:14:16,420 --> 00:14:22,480
in the same vein of design things that

00:14:19,779 --> 00:14:24,549
are poorly designed seen that put out an

00:14:22,480 --> 00:14:26,799
article saying that women generally

00:14:24,549 --> 00:14:29,980
prefer Apple products and gentlemen

00:14:26,799 --> 00:14:32,019
preferred Samsung and if you were to

00:14:29,980 --> 00:14:34,629
just physically look at both of the

00:14:32,019 --> 00:14:36,759
products you would see that with the

00:14:34,629 --> 00:14:38,379
Samsung compete of interfaces with the

00:14:36,759 --> 00:14:40,389
phones you can't put them in your

00:14:38,379 --> 00:14:42,490
pockets so it could be actually a

00:14:40,389 --> 00:14:45,009
preference because of being able to

00:14:42,490 --> 00:14:47,769
actually take it with you versus even

00:14:45,009 --> 00:14:50,499
being able to being a preferred object

00:14:47,769 --> 00:14:53,069
so this article says well the iPhone 6

00:14:50,499 --> 00:14:55,869
fit in your pocket if you were dude yep

00:14:53,069 --> 00:14:58,149
everybody else know so we have to think

00:14:55,869 --> 00:15:01,480
about a whole population when we're

00:14:58,149 --> 00:15:03,249
creating these things and also about the

00:15:01,480 --> 00:15:08,379
whole population things that are colored

00:15:03,249 --> 00:15:14,049
nude so nude is not one color yellowish

00:15:08,379 --> 00:15:15,939
looking bra is not nude and calling them

00:15:14,049 --> 00:15:18,670
sheer and new kind of sends the message

00:15:15,939 --> 00:15:20,920
that anything that doesn't fit into this

00:15:18,670 --> 00:15:22,449
it's just outside of the norm and that

00:15:20,920 --> 00:15:24,069
it's super weird so we need to design

00:15:22,449 --> 00:15:25,360
things that think about everybody it

00:15:24,069 --> 00:15:27,639
wasn't until like the last five years

00:15:25,360 --> 00:15:30,220
that you can even get pandas in

00:15:27,639 --> 00:15:32,499
different colors than the generic flesh

00:15:30,220 --> 00:15:35,859
tone color so hopefully

00:15:32,499 --> 00:15:38,019
making the case for inclusive design to

00:15:35,859 --> 00:15:40,389
you guys but in case I'm not

00:15:38,019 --> 00:15:42,699
I'm sorry Cory I have to bring this out

00:15:40,389 --> 00:15:44,859
let's look at Microsoft's pride and joy

00:15:42,699 --> 00:15:48,969
from I think maybe last year the year

00:15:44,859 --> 00:15:50,049
before you guys know who T is okay some

00:15:48,969 --> 00:15:53,379
of you do know who you know where I'm

00:15:50,049 --> 00:15:55,989
going with this all right so today was

00:15:53,379 --> 00:15:58,629
an artificial agent it was a Twitter bot

00:15:55,989 --> 00:16:00,879
and this was an experiment in AI and

00:15:58,629 --> 00:16:02,799
machine learning and the bot was

00:16:00,879 --> 00:16:05,019
supposed to communicate with Millennials

00:16:02,799 --> 00:16:07,709
and they thought it'd be a good idea for

00:16:05,019 --> 00:16:10,359
Tay to use Twitter to learn how to talk

00:16:07,709 --> 00:16:15,699
so you guys already laughing see you're

00:16:10,359 --> 00:16:18,609
new so now after about 24 hours Tay

00:16:15,699 --> 00:16:23,169
learn some crazy things like this

00:16:18,609 --> 00:16:26,439
colorful language here so inclusive

00:16:23,169 --> 00:16:28,689
design is always needed they learn how

00:16:26,439 --> 00:16:32,229
to just be the most vile person on the

00:16:28,689 --> 00:16:34,209
planet so hey was actually tested it for

00:16:32,229 --> 00:16:36,249
two years before they released it in the

00:16:34,209 --> 00:16:38,229
States but the problem it was tested in

00:16:36,249 --> 00:16:39,970
China they don't have free speech you

00:16:38,229 --> 00:16:41,470
know a lot of the speech is centered so

00:16:39,970 --> 00:16:43,209
of course it work there you know people

00:16:41,470 --> 00:16:45,699
couldn't say crazy stuff this America

00:16:43,209 --> 00:16:48,789
we're crazy they should know we should

00:16:45,699 --> 00:16:51,129
know so it was very well intentioned but

00:16:48,789 --> 00:16:52,869
inclusive design having someone there to

00:16:51,129 --> 00:16:54,939
say hey guess what Twitter is not a good

00:16:52,869 --> 00:16:56,559
place for all people it would have just

00:16:54,939 --> 00:16:58,689
you know rain this thing in put some

00:16:56,559 --> 00:17:00,099
filters in to say hey we don't need

00:16:58,689 --> 00:17:03,009
someone to learn how to talk from

00:17:00,099 --> 00:17:04,750
Twitter the next is the next point is

00:17:03,009 --> 00:17:07,299
that inclusion for one group does not

00:17:04,750 --> 00:17:09,129
have to mean exclusion for another so

00:17:07,299 --> 00:17:11,679
everyone can be excluded for example

00:17:09,129 --> 00:17:13,360
there are no baby changing stations in

00:17:11,679 --> 00:17:15,970
the men's restroom so here's a picture

00:17:13,360 --> 00:17:17,500
of a man trying to change a baby on the

00:17:15,970 --> 00:17:20,019
floor of the men's restroom because

00:17:17,500 --> 00:17:22,329
until lately a lot of men's restrooms

00:17:20,019 --> 00:17:23,589
did not have changing tables so you have

00:17:22,329 --> 00:17:26,199
when you're designing things you have to

00:17:23,589 --> 00:17:29,470
think of everyone who will use it not

00:17:26,199 --> 00:17:31,869
just the usual use case and so if you

00:17:29,470 --> 00:17:33,519
ignore a lot of these a lot of these

00:17:31,869 --> 00:17:35,799
inclusive design practices you actually

00:17:33,519 --> 00:17:38,049
get into a lot of ethical issues so

00:17:35,799 --> 00:17:40,299
there was a snapchat filter that was

00:17:38,049 --> 00:17:41,350
created I want to say almost a year ago

00:17:40,299 --> 00:17:42,250
or something that was clearly

00:17:41,350 --> 00:17:44,950
yellow-faced

00:17:42,250 --> 00:17:45,740
so these are some things that if you do

00:17:44,950 --> 00:17:47,480
not have any

00:17:45,740 --> 00:17:49,610
person of color in the room to let you

00:17:47,480 --> 00:17:52,820
know this is not a good idea then you

00:17:49,610 --> 00:17:55,460
can get into some real issues and so the

00:17:52,820 --> 00:17:58,280
second the second image here is actually

00:17:55,460 --> 00:18:01,670
a picture and this picture is the

00:17:58,280 --> 00:18:07,280
algorithm for a hand soap dispenser and

00:18:01,670 --> 00:18:15,140
we can play the video all right so watch

00:18:07,280 --> 00:18:26,500
this black in that's it

00:18:15,140 --> 00:18:26,500
Larry go black and nothing Larry go

00:18:27,370 --> 00:18:36,260
racist you love sinks now I wouldn't say

00:18:34,760 --> 00:18:38,179
that I want to go that far to say that

00:18:36,260 --> 00:18:39,980
the sink is racist but when you're

00:18:38,179 --> 00:18:42,530
creating the algorithms for these

00:18:39,980 --> 00:18:45,950
sensors to detect if a hand is very to

00:18:42,530 --> 00:18:48,080
consider all hues of hands and not just

00:18:45,950 --> 00:18:51,679
the one that represents the majority of

00:18:48,080 --> 00:18:53,179
the people in the room so the take home

00:18:51,679 --> 00:18:54,980
point here is that you need to diversify

00:18:53,179 --> 00:18:58,040
the data that you train your

00:18:54,980 --> 00:19:00,920
applications on so that it can accept a

00:18:58,040 --> 00:19:04,190
wide variety of input so in case you

00:19:00,920 --> 00:19:05,809
were asleep this entire time then here

00:19:04,190 --> 00:19:08,000
are a few take-home points I'm not

00:19:05,809 --> 00:19:10,520
asking you guys to become diversity

00:19:08,000 --> 00:19:12,679
experts or anything like that but just

00:19:10,520 --> 00:19:14,780
think about these four things the first

00:19:12,679 --> 00:19:17,480
one when you're creating software that

00:19:14,780 --> 00:19:20,059
you expect to impact a wide variety of

00:19:17,480 --> 00:19:22,820
people make sure you include a wide

00:19:20,059 --> 00:19:24,800
variety of people in the design process

00:19:22,820 --> 00:19:26,600
ask them how this would work and if you

00:19:24,800 --> 00:19:29,150
don't have access to those populations

00:19:26,600 --> 00:19:30,800
just imagine what you're doing from the

00:19:29,150 --> 00:19:32,600
perspective of someone that's much

00:19:30,800 --> 00:19:34,460
different than you I know we're very

00:19:32,600 --> 00:19:36,260
selfish we're American we're taught to

00:19:34,460 --> 00:19:38,000
think about ourselves but just just turn

00:19:36,260 --> 00:19:39,710
your brain for half a second and think

00:19:38,000 --> 00:19:43,100
about somebody who is much much

00:19:39,710 --> 00:19:45,200
different than you and then also if you

00:19:43,100 --> 00:19:47,570
are creating a system try to get rid of

00:19:45,200 --> 00:19:49,280
any assumptions any generalized

00:19:47,570 --> 00:19:51,890
assumptions that your system might make

00:19:49,280 --> 00:19:53,990
about how a person would use it so

00:19:51,890 --> 00:19:56,990
anything that has to do with gender size

00:19:53,990 --> 00:19:59,150
ability experience think about the wide

00:19:56,990 --> 00:20:02,270
spectrum and then last

00:19:59,150 --> 00:20:05,030
if you are creating algorithms one way

00:20:02,270 --> 00:20:07,070
to avoid bias in these algorithms is to

00:20:05,030 --> 00:20:08,960
make sure that you diversify your

00:20:07,070 --> 00:20:13,690
training data make sure your training

00:20:08,960 --> 00:20:13,690
based on a wide spectrum of data points

00:20:13,900 --> 00:20:17,400
all right well thank you guys so much it

00:20:16,640 --> 00:20:22,329
has been a pleasure

00:20:17,400 --> 00:20:22,329

YouTube URL: https://www.youtube.com/watch?v=7Et-3yflWAQ


