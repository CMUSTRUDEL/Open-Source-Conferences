Title: MountainWest RubyConf 2014 - Five machine learning techniques that....
Publication date: 2020-01-24
Playlist: MWRC 2014
Description: 
	Five machine learning techniques that you can use in your Ruby apps today By Benjamin Curtis

Machine learning is everywhere these days. Features like search, voice recognition, recommendations - they've become so common that people have started to expect them. They're starting to expect the apps we build to be smarter.
Ten years ago, machine learning and data mining techniques were only available to the people dedicated enough to dig through the math. Now that's not the case.
The most common machine learning techniques are well known. Standard approaches have been developed. And, fortunately for us, many of these are available as ruby gems. Some are even easy to implement yourself.
In this presentation we'll cover five important machine learning techniques that can be used in a wide range of applications. It will be a wide and shallow introduction, for Rubyists, not mathematicians - we'll have plenty of simple code examples.
By the end of the presentation, you won't be an expert, but you'll know about a class of tools you may not have realized were available.

Help us caption & translate this video!

http://amara.org/v/FG2G/
Captions: 
	00:00:24,829 --> 00:00:31,079
all right good morning everybody it is a

00:00:28,500 --> 00:00:32,879
pleasure to be here with you this has

00:00:31,079 --> 00:00:34,469
been a fantastic conference I want to

00:00:32,879 --> 00:00:37,079
thank all the presenters that have gone

00:00:34,469 --> 00:00:39,420
on before and of course Mike who's done

00:00:37,079 --> 00:00:43,530
a great job when it's all together I am

00:00:39,420 --> 00:00:44,940
Ben Curtis I am from Seattle ish I'm

00:00:43,530 --> 00:00:46,140
actually I actually live in Kirkland and

00:00:44,940 --> 00:00:48,989
that doesn't matter to anybody who's

00:00:46,140 --> 00:00:50,070
outside of Seattle but but if you do

00:00:48,989 --> 00:00:52,440
live in Seattle and I say I'm from

00:00:50,070 --> 00:00:55,890
Seattle then I that's totally false so

00:00:52,440 --> 00:00:58,379
have to be clear about that I am one of

00:00:55,890 --> 00:01:00,719
the cofounders of honey badger geo with

00:00:58,379 --> 00:01:02,010
star horn and Joshua wood and if you

00:01:00,719 --> 00:01:03,780
don't know about honey badger you really

00:01:02,010 --> 00:01:06,270
should so go check it out that's an

00:01:03,780 --> 00:01:08,280
awesome service for Ruby developers and

00:01:06,270 --> 00:01:12,270
you can find me at Stimpy on the

00:01:08,280 --> 00:01:13,740
interwebs and I'm excited to be talking

00:01:12,270 --> 00:01:16,830
about this topic about machine learning

00:01:13,740 --> 00:01:18,390
techniques it's been fun to put together

00:01:16,830 --> 00:01:19,770
this material and I hope that we can

00:01:18,390 --> 00:01:22,440
spend a few productive minutes together

00:01:19,770 --> 00:01:24,570
talking about it I will apologize if you

00:01:22,440 --> 00:01:29,399
are a machine learning expert because I

00:01:24,570 --> 00:01:31,200
am not but I do enjoy this this topic

00:01:29,399 --> 00:01:32,880
and I hope that I won't offend you by

00:01:31,200 --> 00:01:35,159
the things that I say that are wrong you

00:01:32,880 --> 00:01:37,860
can correct me later and if I mislead

00:01:35,159 --> 00:01:38,790
interview you I apologize sincerely so

00:01:37,860 --> 00:01:44,040
we're going to learn about machine

00:01:38,790 --> 00:01:45,570
learning it's kind of a big topic so I'm

00:01:44,040 --> 00:01:47,579
not going to talk about all of it and

00:01:45,570 --> 00:01:49,380
I'm not going to talk very deeply about

00:01:47,579 --> 00:01:50,009
it but I want to talk about it from the

00:01:49,380 --> 00:01:53,310
approach of

00:01:50,009 --> 00:01:54,509
I'm a ruby developer and I want to know

00:01:53,310 --> 00:01:57,149
what this machine learn thing is about

00:01:54,509 --> 00:01:59,189
so I can see how I might use it in my

00:01:57,149 --> 00:02:00,630
applications so that's that's the intent

00:01:59,189 --> 00:02:01,829
if that's not interesting to you you can

00:02:00,630 --> 00:02:06,600
go and do something else for half an

00:02:01,829 --> 00:02:08,670
hour there is a lot of info out there so

00:02:06,600 --> 00:02:11,310
once you start learning you can just

00:02:08,670 --> 00:02:13,500
keep going and going and going and going

00:02:11,310 --> 00:02:15,030
so if you feel intrigued by the things

00:02:13,500 --> 00:02:16,560
you learn here you can definitely hit up

00:02:15,030 --> 00:02:19,680
Wikipedia and bunch of other resources

00:02:16,560 --> 00:02:21,810
to find out more but the main thing that

00:02:19,680 --> 00:02:23,940
I want to do today is I want to

00:02:21,810 --> 00:02:26,700
introduce you to a couple of the secret

00:02:23,940 --> 00:02:28,410
past phrases and key words that you'll

00:02:26,700 --> 00:02:30,480
need to be able to actually have a

00:02:28,410 --> 00:02:31,470
productive line of research into machine

00:02:30,480 --> 00:02:31,919
learning if you want to learn more about

00:02:31,470 --> 00:02:33,419
it

00:02:31,919 --> 00:02:33,930
the thing about machine learning is it

00:02:33,419 --> 00:02:36,510
seems like this

00:02:33,930 --> 00:02:39,659
big black mysterious thing that you

00:02:36,510 --> 00:02:41,489
don't know anything about and once you

00:02:39,659 --> 00:02:43,109
know a few key words then you can kind

00:02:41,489 --> 00:02:44,280
of get your foot in the door and go from

00:02:43,109 --> 00:02:47,129
there so we're going to talk about what

00:02:44,280 --> 00:02:49,230
some of those few key words are and that

00:02:47,129 --> 00:02:51,269
will help you on your journey to finding

00:02:49,230 --> 00:02:56,310
the right pattern or algorithm to help

00:02:51,269 --> 00:02:58,019
you and your quest so the other topic

00:02:56,310 --> 00:02:59,849
the other title that this talk could be

00:02:58,019 --> 00:03:01,829
is making sense of a bunch of data and

00:02:59,849 --> 00:03:04,349
that's really all machine learning is to

00:03:01,829 --> 00:03:06,900
me from my viewpoint it's helping me

00:03:04,349 --> 00:03:08,310
deal with the the gobs and gobs of data

00:03:06,900 --> 00:03:10,769
that I've coming in and making some

00:03:08,310 --> 00:03:16,439
smart decisions about it or learning

00:03:10,769 --> 00:03:18,030
some interesting things from it before I

00:03:16,439 --> 00:03:19,829
get dive into the talk though I want to

00:03:18,030 --> 00:03:21,030
have a course of warm up joke and I

00:03:19,829 --> 00:03:22,739
haven't seen any so far in the

00:03:21,030 --> 00:03:25,730
presentations so I'm glad I can be the

00:03:22,739 --> 00:03:25,730
first and here it is

00:03:30,069 --> 00:03:35,810
I love that joke it's awesome I was I

00:03:33,799 --> 00:03:36,860
was showing that with my family over

00:03:35,810 --> 00:03:40,879
dinner the other night and I had to

00:03:36,860 --> 00:03:43,159
explain what TCP and UDP were and I love

00:03:40,879 --> 00:03:47,540
my kids they're great they humor me and

00:03:43,159 --> 00:03:49,099
it was okay before we get into machine

00:03:47,540 --> 00:03:50,269
learning and what you can do with all

00:03:49,099 --> 00:03:53,409
the fun data that you're going to have

00:03:50,269 --> 00:03:56,349
you got to have some fun data and so

00:03:53,409 --> 00:03:59,569
logging is important there's a great

00:03:56,349 --> 00:04:02,989
blog post written by a fella by the name

00:03:59,569 --> 00:04:04,430
Jake reps works at LinkedIn and he this

00:04:02,989 --> 00:04:06,530
is from December and he talks about

00:04:04,430 --> 00:04:08,599
setting up a logging infrastructure

00:04:06,530 --> 00:04:11,650
inside your business to capture all the

00:04:08,599 --> 00:04:13,730
information that you have he did this at

00:04:11,650 --> 00:04:15,379
LinkedIn so you can imagine that that's

00:04:13,730 --> 00:04:16,880
kind of a big job but he talks about why

00:04:15,379 --> 00:04:19,459
logging is so important and it's not

00:04:16,880 --> 00:04:20,870
just about you know storing strings to

00:04:19,459 --> 00:04:22,070
text files that someone might grep

00:04:20,870 --> 00:04:24,229
through later because there's a problem

00:04:22,070 --> 00:04:26,180
that's that's maybe like your first

00:04:24,229 --> 00:04:28,039
order of logging but we think a little

00:04:26,180 --> 00:04:30,259
more abstract than that think about all

00:04:28,039 --> 00:04:32,599
the data that comes into your enterprise

00:04:30,259 --> 00:04:35,990
into your application it passes through

00:04:32,599 --> 00:04:37,190
it and what is happening to all that

00:04:35,990 --> 00:04:38,810
data you're just throwing it away

00:04:37,190 --> 00:04:41,780
because you're not tracking it or are

00:04:38,810 --> 00:04:44,389
you finding some way to systematically

00:04:41,780 --> 00:04:47,060
log it and so you can analyze it later

00:04:44,389 --> 00:04:49,250
and that's that's kind of the the first

00:04:47,060 --> 00:04:51,530
I guess a step 0 of machine learning is

00:04:49,250 --> 00:04:55,099
is first having a bunch of data to learn

00:04:51,530 --> 00:04:58,400
with sometimes we forget that when we're

00:04:55,099 --> 00:05:01,130
dealing with data the win can be as

00:04:58,400 --> 00:05:02,599
important as the what especially when we

00:05:01,130 --> 00:05:05,030
talk about recommendation systems and

00:05:02,599 --> 00:05:06,650
freshness the win of things happening is

00:05:05,030 --> 00:05:08,990
it can be very critical and if you don't

00:05:06,650 --> 00:05:12,050
log then you don't know when things

00:05:08,990 --> 00:05:14,210
happened so to help you in your logging

00:05:12,050 --> 00:05:16,370
endeavors here are a few products that

00:05:14,210 --> 00:05:18,650
you might look into to get started on

00:05:16,370 --> 00:05:20,900
having a way to log all the things that

00:05:18,650 --> 00:05:22,729
are happening in your environment I am

00:05:20,900 --> 00:05:25,280
most familiar with log stash which works

00:05:22,729 --> 00:05:28,250
well with elastic search and Cabana for

00:05:25,280 --> 00:05:29,240
visualization but these other systems

00:05:28,250 --> 00:05:32,810
are great too

00:05:29,240 --> 00:05:34,970
Amazon would happily let you use their

00:05:32,810 --> 00:05:37,700
system if you feel like paying them for

00:05:34,970 --> 00:05:40,400
that but all of these are great Apache

00:05:37,700 --> 00:05:41,479
Kafka was written by Jake reps who talks

00:05:40,400 --> 00:05:43,610
about logging so

00:05:41,479 --> 00:05:45,080
it's a pretty intense thing and of

00:05:43,610 --> 00:05:48,979
course with any Apache project there's a

00:05:45,080 --> 00:05:54,039
lot of stuff to go along with it so take

00:05:48,979 --> 00:05:57,830
your pick okay so let's talk about

00:05:54,039 --> 00:06:00,559
clustering we have a lot of data we want

00:05:57,830 --> 00:06:05,770
to make some sense out of this data so

00:06:00,559 --> 00:06:08,419
let's make it into smaller piles of data

00:06:05,770 --> 00:06:09,680
machine learning is a lot about sifting

00:06:08,419 --> 00:06:11,180
through all this data that you have and

00:06:09,680 --> 00:06:12,439
and breaking it up into parts that you

00:06:11,180 --> 00:06:18,589
can actually understand something about

00:06:12,439 --> 00:06:21,490
that data the taking the clustering

00:06:18,589 --> 00:06:23,569
approach says okay let me analyze

00:06:21,490 --> 00:06:28,069
everything and see if I can start

00:06:23,569 --> 00:06:29,629
looking for patterns the principal thing

00:06:28,069 --> 00:06:30,860
that you'll find algorithm that you'll

00:06:29,629 --> 00:06:33,139
find when you start think about

00:06:30,860 --> 00:06:34,550
clustering is k-means clustering now we

00:06:33,139 --> 00:06:38,060
were introduced yesterday to what K is

00:06:34,550 --> 00:06:40,099
and you might know what a mean is that's

00:06:38,060 --> 00:06:42,199
just simply an average and so we take

00:06:40,099 --> 00:06:46,370
averages of things and we're putting

00:06:42,199 --> 00:06:48,439
them into K buckets alright so a k-means

00:06:46,370 --> 00:06:50,300
clustering just say okay given a bunch

00:06:48,439 --> 00:06:52,789
of points and usually we're talking

00:06:50,300 --> 00:06:54,319
about Cartesian points it's not limited

00:06:52,789 --> 00:06:55,930
to just that but typically talking about

00:06:54,319 --> 00:06:58,189
anything you can graph on an XY plane

00:06:55,930 --> 00:07:01,189
given a whole bunch of these things

00:06:58,189 --> 00:07:03,229
let's cluster them so that we can

00:07:01,189 --> 00:07:07,279
identify which ones are similar and

00:07:03,229 --> 00:07:09,589
which ones are dissimilar this is very

00:07:07,279 --> 00:07:10,779
useful in mapping applications obviously

00:07:09,589 --> 00:07:12,770
and we'll talk about that in a minute

00:07:10,779 --> 00:07:14,959
but basically we want to take n

00:07:12,770 --> 00:07:19,180
observations and divide them into K

00:07:14,959 --> 00:07:24,319
clusters and the k-means clustering has

00:07:19,180 --> 00:07:26,509
one significant drawback and that is you

00:07:24,319 --> 00:07:27,889
have to decide what K is but that's what

00:07:26,509 --> 00:07:30,020
is the shortcut that actually makes it

00:07:27,889 --> 00:07:31,219
work pretty well so if you don't have

00:07:30,020 --> 00:07:37,729
any problems deciding what the K is

00:07:31,219 --> 00:07:39,469
k-means clustering is a great thing in

00:07:37,729 --> 00:07:41,870
the terms of machine learning this is a

00:07:39,469 --> 00:07:43,490
k-means clustering all clustering

00:07:41,870 --> 00:07:45,319
techniques are kind of a what's called

00:07:43,490 --> 00:07:47,029
unsupervised learning we're letting the

00:07:45,319 --> 00:07:49,279
computer decide what it wants to do with

00:07:47,029 --> 00:07:52,099
the data without giving it much or any

00:07:49,279 --> 00:07:54,330
guidance so let's have a demo here's my

00:07:52,099 --> 00:07:56,280
demo courtesy of Wikipedia

00:07:54,330 --> 00:07:57,990
if you go through the Kapiti page you

00:07:56,280 --> 00:08:00,180
can see this fantastic demo but here's

00:07:57,990 --> 00:08:02,430
how canings works we have a series of

00:08:00,180 --> 00:08:04,470
points here so these are all points in

00:08:02,430 --> 00:08:07,889
our data and we're going to say we want

00:08:04,470 --> 00:08:09,840
a K of three and given this set of data

00:08:07,889 --> 00:08:11,159
let's pick three points at random this

00:08:09,840 --> 00:08:12,990
is actually one of the initialization

00:08:11,159 --> 00:08:15,360
method you can use but it's a good one

00:08:12,990 --> 00:08:17,099
and given those random three points in

00:08:15,360 --> 00:08:19,879
our data let's say those are our

00:08:17,099 --> 00:08:22,680
clusters that we're going to start with

00:08:19,879 --> 00:08:24,870
once we've identified our centroids we

00:08:22,680 --> 00:08:26,490
now need to look and decide which of our

00:08:24,870 --> 00:08:28,169
other data points are close to the

00:08:26,490 --> 00:08:30,629
centroids we do that by taking the

00:08:28,169 --> 00:08:33,209
average of the X wide distance to those

00:08:30,629 --> 00:08:35,279
centroids and on the first pass we say

00:08:33,209 --> 00:08:37,700
oh okay looks like that talk 1 is near

00:08:35,279 --> 00:08:40,800
the top centroid and so on and so forth

00:08:37,700 --> 00:08:44,870
once we have identified these this

00:08:40,800 --> 00:08:47,310
initial set then we move the centroids

00:08:44,870 --> 00:08:49,490
to a position that is at the center of

00:08:47,310 --> 00:08:52,410
that set

00:08:49,490 --> 00:08:54,690
we now repeat that process it may say ok

00:08:52,410 --> 00:08:56,730
now which points are nearest to the

00:08:54,690 --> 00:08:59,670
centroids and as we go through that

00:08:56,730 --> 00:09:01,320
process we find that these are our

00:08:59,670 --> 00:09:03,990
clusters it's a pretty straightforward

00:09:01,320 --> 00:09:07,320
process and you can do this visually if

00:09:03,990 --> 00:09:10,110
you have a small data set it takes not

00:09:07,320 --> 00:09:13,800
too long and comparatively speaking and

00:09:10,110 --> 00:09:15,480
it works pretty well it basically you

00:09:13,800 --> 00:09:17,209
know you're done when the points stop

00:09:15,480 --> 00:09:19,890
moving

00:09:17,209 --> 00:09:21,540
here's the canonical example let's say

00:09:19,890 --> 00:09:23,430
we are building an application where we

00:09:21,540 --> 00:09:26,730
want to point a bunt a plot a bunch of

00:09:23,430 --> 00:09:28,380
points on a map this is a screenshot

00:09:26,730 --> 00:09:31,250
from Zillow and they want to point a

00:09:28,380 --> 00:09:34,290
plot up watch a bunch of houses on a map

00:09:31,250 --> 00:09:37,199
the problem comes when we want to zoom

00:09:34,290 --> 00:09:39,270
out so a naive implementation of a map

00:09:37,199 --> 00:09:40,709
would say ok I'll show you all the

00:09:39,270 --> 00:09:41,550
points that are in the map area and then

00:09:40,709 --> 00:09:44,579
all of a sudden

00:09:41,550 --> 00:09:47,430
yeah that's not helpful at all what you

00:09:44,579 --> 00:09:49,320
do you cluster so instead of showing 500

00:09:47,430 --> 00:09:51,750
points or 5,000 points you cluster those

00:09:49,320 --> 00:09:53,459
500 or 5,000 points into five or six

00:09:51,750 --> 00:09:55,050
clusters and then you show the clusters

00:09:53,459 --> 00:09:57,540
with the counts and then of course

00:09:55,050 --> 00:09:59,279
you've seen this you click on a cluster

00:09:57,540 --> 00:10:02,520
you dive in and you see the exploded

00:09:59,279 --> 00:10:04,980
view this is pretty straightforward

00:10:02,520 --> 00:10:07,410
and it works really well there's

00:10:04,980 --> 00:10:08,190
actually a client-side more than one but

00:10:07,410 --> 00:10:10,350
there's a

00:10:08,190 --> 00:10:11,520
you might find markerclusterer when you

00:10:10,350 --> 00:10:13,620
go looking for this sort of thing if you

00:10:11,520 --> 00:10:15,840
need to plot a bunch of spots on a map

00:10:13,620 --> 00:10:17,970
and that works on the client side which

00:10:15,840 --> 00:10:20,160
is great if you only have a few hundred

00:10:17,970 --> 00:10:22,950
reserved points but if you have a few

00:10:20,160 --> 00:10:25,260
more then you need to do some clustering

00:10:22,950 --> 00:10:27,750
on the server side and so you can use

00:10:25,260 --> 00:10:29,940
some Ruby so these slides that look like

00:10:27,750 --> 00:10:32,250
this have the github repository of the

00:10:29,940 --> 00:10:35,040
title and the example code from the

00:10:32,250 --> 00:10:36,510
repository on the code part so none of

00:10:35,040 --> 00:10:37,950
this code is mine all this code is the

00:10:36,510 --> 00:10:39,540
original authors so thank you very much

00:10:37,950 --> 00:10:42,030
original authors for making this easier

00:10:39,540 --> 00:10:43,110
for me but look at the k-means Jim if

00:10:42,030 --> 00:10:45,870
you look interested in doing some

00:10:43,110 --> 00:10:47,640
clustering and here's pretty

00:10:45,870 --> 00:10:49,680
straightforward our first set of data

00:10:47,640 --> 00:10:52,440
there we have a bunch of points on our

00:10:49,680 --> 00:10:55,590
on our plane and we shove all these

00:10:52,440 --> 00:10:57,360
points into a new object and we tell

00:10:55,590 --> 00:10:58,770
them how many centroids we want to have

00:10:57,360 --> 00:11:01,770
or how many clusters we want to have and

00:10:58,770 --> 00:11:07,230
then it gives us the same sets of points

00:11:01,770 --> 00:11:09,690
broken up into those clusters pretty

00:11:07,230 --> 00:11:12,720
easy if you have a whole lot of points

00:11:09,690 --> 00:11:15,330
this can get kind of slow so this is a

00:11:12,720 --> 00:11:16,740
good opportunity for using some of the

00:11:15,330 --> 00:11:18,690
seed that you learned yesterday and

00:11:16,740 --> 00:11:21,060
putting this out into a seed library and

00:11:18,690 --> 00:11:23,460
calling it that way my co-founder star

00:11:21,060 --> 00:11:25,260
and nine we worked at alpha space comm a

00:11:23,460 --> 00:11:26,940
while back and this is exactly what we

00:11:25,260 --> 00:11:29,400
did we had to do a lot of clustering of

00:11:26,940 --> 00:11:37,290
points he wrote some C code and it was

00:11:29,400 --> 00:11:39,930
great so after we talked about a bunch

00:11:37,290 --> 00:11:42,300
of data and we've maybe clustered it so

00:11:39,930 --> 00:11:44,310
that we can identify it better let's

00:11:42,300 --> 00:11:46,250
actually take some action on some of our

00:11:44,310 --> 00:11:49,350
data and this is where we get into

00:11:46,250 --> 00:11:50,820
what's called supervised learning in the

00:11:49,350 --> 00:11:53,040
machine learning world and that just

00:11:50,820 --> 00:11:55,170
means that we're going to give the

00:11:53,040 --> 00:11:57,839
computer some hints about how it should

00:11:55,170 --> 00:11:59,250
treat the data and the first kind of

00:11:57,839 --> 00:12:04,160
supervised learning we want to talk

00:11:59,250 --> 00:12:06,180
about is decision trees Ilya is

00:12:04,160 --> 00:12:07,589
fantastic if you have if you're not

00:12:06,180 --> 00:12:10,080
familiar with Ilya you should definitely

00:12:07,589 --> 00:12:12,839
check out his blog at egg veto he is

00:12:10,080 --> 00:12:14,610
just a genius I guess and he has written

00:12:12,839 --> 00:12:16,770
a bunch of code and decision tree is one

00:12:14,610 --> 00:12:19,350
of the things that he's written a

00:12:16,770 --> 00:12:21,450
decision tree is pretty simple can be

00:12:19,350 --> 00:12:21,900
pretty simple it looks a lot like a case

00:12:21,450 --> 00:12:24,660
statement

00:12:21,900 --> 00:12:27,510
and basically we say you know what we we

00:12:24,660 --> 00:12:28,790
know that the the ranges of things that

00:12:27,510 --> 00:12:31,710
we're dealing with in this case

00:12:28,790 --> 00:12:33,330
temperature observations we know that

00:12:31,710 --> 00:12:35,940
certain temperatures have certain

00:12:33,330 --> 00:12:37,650
classifications healthy or sick and so

00:12:35,940 --> 00:12:39,420
we just teach the computer okay here are

00:12:37,650 --> 00:12:41,820
the classifications that we know about

00:12:39,420 --> 00:12:44,160
please just look at all the data and you

00:12:41,820 --> 00:12:45,930
tell me what each one should be

00:12:44,160 --> 00:12:48,300
classified as based on this rule set

00:12:45,930 --> 00:12:49,800
that I gave you it's pretty straight

00:12:48,300 --> 00:12:51,150
forward but you'd be surprised at how

00:12:49,800 --> 00:12:55,170
much you can actually do with this sort

00:12:51,150 --> 00:12:56,820
of thing for example you can have the

00:12:55,170 --> 00:12:58,860
computer write you an article that shows

00:12:56,820 --> 00:13:00,300
up in the setting of those times so on

00:12:58,860 --> 00:13:02,630
Monday you may be aware there is an

00:13:00,300 --> 00:13:05,010
earthquake and the in California and

00:13:02,630 --> 00:13:06,930
within 20 minutes of the earthquake

00:13:05,010 --> 00:13:08,640
happening this article was published at

00:13:06,930 --> 00:13:10,290
the LA Times and you'll notice that

00:13:08,640 --> 00:13:12,450
bolded line down the bottom that

00:13:10,290 --> 00:13:15,030
highlighting is mine that says

00:13:12,450 --> 00:13:16,980
acknowledges that yes this article was

00:13:15,030 --> 00:13:19,350
actually written by a machine with some

00:13:16,980 --> 00:13:20,940
guidance when the author so this guy is

00:13:19,350 --> 00:13:22,970
brilliant you know he says hey I can

00:13:20,940 --> 00:13:26,940
make the computer do my work for me and

00:13:22,970 --> 00:13:28,830
I can have it write my article this is

00:13:26,940 --> 00:13:29,970
the same if you were reading TechCrunch

00:13:28,830 --> 00:13:32,160
this week this is the same earthquake

00:13:29,970 --> 00:13:34,140
that caused the newscaster to dive under

00:13:32,160 --> 00:13:36,690
the desk because it's kind of check it

00:13:34,140 --> 00:13:38,010
out it's kind of fun but you'll notice

00:13:36,690 --> 00:13:39,450
in this article there are some places

00:13:38,010 --> 00:13:41,070
where a decision tree could have been

00:13:39,450 --> 00:13:43,500
used I don't know exactly how he did

00:13:41,070 --> 00:13:46,830
this but like the first sentence a

00:13:43,500 --> 00:13:48,420
shallow magnitude 2.7 earthquake how do

00:13:46,830 --> 00:13:50,100
we know it's shallow that could be a

00:13:48,420 --> 00:13:51,780
decision tree right whatever the

00:13:50,100 --> 00:13:53,850
magnitude is they say it's shallow or

00:13:51,780 --> 00:13:57,120
it's not or that with a depth of it was

00:13:53,850 --> 00:13:59,580
or not it was four miles from Westwood

00:13:57,120 --> 00:14:01,770
ok that's obviously some computation

00:13:59,580 --> 00:14:06,420
there happening with some Great Circle

00:14:01,770 --> 00:14:08,580
distance hit a large swath well it's a

00:14:06,420 --> 00:14:10,200
large swath ok well if it's if the range

00:14:08,580 --> 00:14:11,730
is greater than 50 miles or is felt

00:14:10,200 --> 00:14:13,080
that's a large swath or if it's less

00:14:11,730 --> 00:14:15,240
than 10 miles man that was it you know

00:14:13,080 --> 00:14:17,190
very localized anyway you can see that

00:14:15,240 --> 00:14:19,320
you can use a decision tree to put in a

00:14:17,190 --> 00:14:22,620
bunch of text and I find this incredibly

00:14:19,320 --> 00:14:24,480
useful as a web application person by

00:14:22,620 --> 00:14:27,750
saying hey I can look at my users data

00:14:24,480 --> 00:14:28,920
and I can say if you know this threshold

00:14:27,750 --> 00:14:30,570
is under here and I could send this kind

00:14:28,920 --> 00:14:31,950
of email versus that kind of email or in

00:14:30,570 --> 00:14:33,960
that email but this kind of content

00:14:31,950 --> 00:14:35,120
versus that kind of content so it's

00:14:33,960 --> 00:14:38,000
pretty easy to see how this

00:14:35,120 --> 00:14:42,550
be useful to customizing content and

00:14:38,000 --> 00:14:42,550
making a better experience for users so

00:14:45,100 --> 00:14:50,360
what decision trees are great but

00:14:47,990 --> 00:14:52,850
they're pretty simple so we want to get

00:14:50,360 --> 00:14:56,750
up to the next level and that would be

00:14:52,850 --> 00:14:59,360
classifying I love munchkin I play with

00:14:56,750 --> 00:15:00,560
my kids so I throw it in there you might

00:14:59,360 --> 00:15:04,910
recognize that from the instruction

00:15:00,560 --> 00:15:06,290
instructions in munchkin classifiers

00:15:04,910 --> 00:15:10,520
you're probably already familiar with

00:15:06,290 --> 00:15:12,320
some you've probably gotten spam so you

00:15:10,520 --> 00:15:14,690
are familiar with Bayesian classifiers

00:15:12,320 --> 00:15:18,140
so a lot of spam filters are built upon

00:15:14,690 --> 00:15:23,000
a Bayesian classifiers it's just a way

00:15:18,140 --> 00:15:25,610
to say what is this blob of text is it

00:15:23,000 --> 00:15:27,230
this or is it that and again this is

00:15:25,610 --> 00:15:30,440
supervised learning so we are training

00:15:27,230 --> 00:15:32,540
the Machine this is that and this is

00:15:30,440 --> 00:15:34,460
something else and so we talk about

00:15:32,540 --> 00:15:36,170
having a corpus of data and Aaron talked

00:15:34,460 --> 00:15:38,690
about yesterday where he had his corpus

00:15:36,170 --> 00:15:41,330
of images and so we train the machine

00:15:38,690 --> 00:15:43,220
this is spam it's a spam this is bad

00:15:41,330 --> 00:15:45,860
this is bad this is not spam this is fan

00:15:43,220 --> 00:15:47,240
it's a spam spam and then over time the

00:15:45,860 --> 00:15:49,970
machines like oh I get it

00:15:47,240 --> 00:15:51,050
this is spam right and so we train it

00:15:49,970 --> 00:15:55,700
over time and they get better as you

00:15:51,050 --> 00:15:57,680
give them more a corpus we call this you

00:15:55,700 --> 00:15:59,450
may have seen the naive Bayes new filter

00:15:57,680 --> 00:16:00,800
it's naive because it just makes some

00:15:59,450 --> 00:16:03,440
assumptions that make the calculations

00:16:00,800 --> 00:16:05,120
easier you can dive into that you can

00:16:03,440 --> 00:16:06,770
use Bayesian classifiers for sentiment

00:16:05,120 --> 00:16:08,150
analysis let's say I don't know if

00:16:06,770 --> 00:16:09,440
you've ever checked out the reviews on

00:16:08,150 --> 00:16:11,330
Amazon but you may have noticed that

00:16:09,440 --> 00:16:13,520
some are positive and some are negative

00:16:11,330 --> 00:16:14,959
and it might actually give you the thing

00:16:13,520 --> 00:16:17,000
it says here the most positive reviews

00:16:14,959 --> 00:16:18,500
and here are most negative reviews well

00:16:17,000 --> 00:16:20,720
you can use Bayesian classifiers to

00:16:18,500 --> 00:16:22,700
decide if a review is positive or as

00:16:20,720 --> 00:16:24,410
negative based on the words are being

00:16:22,700 --> 00:16:26,630
used like I hated this product okay

00:16:24,410 --> 00:16:28,160
that's probably negative or I love this

00:16:26,630 --> 00:16:29,990
product it made me rich you know it's

00:16:28,160 --> 00:16:33,500
probably a positive review and so you

00:16:29,990 --> 00:16:34,839
can classify things like that here's an

00:16:33,500 --> 00:16:38,089
example with a classifier

00:16:34,839 --> 00:16:40,220
it's pretty straightforward you say what

00:16:38,089 --> 00:16:42,020
your classifications are in this case

00:16:40,220 --> 00:16:44,600
something is interesting or it's not

00:16:42,020 --> 00:16:47,060
interesting and then here's my corpus

00:16:44,600 --> 00:16:48,680
computer this is interesting here's some

00:16:47,060 --> 00:16:50,960
other stuff that's not interesting

00:16:48,680 --> 00:16:53,060
now some point later I can say okay

00:16:50,960 --> 00:17:00,350
here's some unidentified text tell me if

00:16:53,060 --> 00:17:01,850
it's interesting or not if you want to

00:17:00,350 --> 00:17:04,490
go up a little bit from there there's

00:17:01,850 --> 00:17:08,089
another algorithm called latent semantic

00:17:04,490 --> 00:17:10,339
indexing and this or latent semantic

00:17:08,089 --> 00:17:12,079
analysis if you prefer and this

00:17:10,339 --> 00:17:14,420
particular algorithm is actually

00:17:12,079 --> 00:17:16,730
patented which is awesome

00:17:14,420 --> 00:17:19,520
and in fact it can be used and has been

00:17:16,730 --> 00:17:22,850
used to discover prior art for patents

00:17:19,520 --> 00:17:25,280
and surprise surprise basically what we

00:17:22,850 --> 00:17:27,709
do here is we throw a bunch of text at

00:17:25,280 --> 00:17:30,920
the classifier and it looks at the text

00:17:27,709 --> 00:17:33,740
and we say okay this is about something

00:17:30,920 --> 00:17:36,080
or this is about something else and what

00:17:33,740 --> 00:17:37,520
it can do using the power of math and

00:17:36,080 --> 00:17:40,340
vectors which we learned about earlier

00:17:37,520 --> 00:17:42,440
it says okay this section of text has

00:17:40,340 --> 00:17:44,120
these kinds of words in it and this

00:17:42,440 --> 00:17:46,309
block of text has these words in it and

00:17:44,120 --> 00:17:48,080
based on the co-occurrence of those

00:17:46,309 --> 00:17:49,640
words and these two documents these two

00:17:48,080 --> 00:17:51,920
documents are similar or they're

00:17:49,640 --> 00:17:54,080
dissimilar it doesn't know what these

00:17:51,920 --> 00:17:55,790
documents mean per se doesn't understand

00:17:54,080 --> 00:17:57,320
like in human does but it can say okay

00:17:55,790 --> 00:17:59,690
all these documents here about

00:17:57,320 --> 00:18:05,390
amazon.com and all these documents over

00:17:59,690 --> 00:18:07,070
here about Amazon the river okay and

00:18:05,390 --> 00:18:08,809
postgrads there's an example of this ts

00:18:07,070 --> 00:18:10,910
vector if you're interested in fuzzy

00:18:08,809 --> 00:18:12,770
search that does this sort of thing

00:18:10,910 --> 00:18:14,720
but in the Ruby land we have again the

00:18:12,770 --> 00:18:16,100
classifier Jim if you scroll down

00:18:14,720 --> 00:18:19,250
they'll get have a page a little bit you

00:18:16,100 --> 00:18:21,470
get down to the LSI part and we just

00:18:19,250 --> 00:18:23,450
have a bunch of documents that we're

00:18:21,470 --> 00:18:25,100
sending to the classifier and these

00:18:23,450 --> 00:18:27,260
documents have a bunch of text in them

00:18:25,100 --> 00:18:28,429
and we identify we tell it again

00:18:27,260 --> 00:18:30,530
supervised learning so we tell the

00:18:28,429 --> 00:18:33,940
Machine this is about dogs or this is

00:18:30,530 --> 00:18:36,320
about cats or birds and then we say okay

00:18:33,940 --> 00:18:38,660
this finer lated thing that's where I

00:18:36,320 --> 00:18:40,550
was talking about it knows the documents

00:18:38,660 --> 00:18:42,320
are similar based on the content in them

00:18:40,550 --> 00:18:43,700
doesn't nobody mean necessarily but it

00:18:42,320 --> 00:18:46,580
knows they are similar so you can say

00:18:43,700 --> 00:18:49,370
okay given this new text can you find me

00:18:46,580 --> 00:18:51,740
some similar things to it like a prior

00:18:49,370 --> 00:18:53,240
patent search for example or you can

00:18:51,740 --> 00:18:55,160
also ask the classifier okay here's some

00:18:53,240 --> 00:18:56,480
new text based on the classifications

00:18:55,160 --> 00:18:58,580
I've given you before can you tell me

00:18:56,480 --> 00:19:01,750
what you think it's more like as I'm

00:18:58,580 --> 00:19:01,750
more like a dog or someone like a cat

00:19:03,640 --> 00:19:08,000
okay so once we have a bunch of

00:19:06,440 --> 00:19:09,560
classifications once we've taught the

00:19:08,000 --> 00:19:12,050
machine or to a thing or two about our

00:19:09,560 --> 00:19:14,210
domain now we can start asking it

00:19:12,050 --> 00:19:16,130
questions to give us more insight into a

00:19:14,210 --> 00:19:18,800
data that we have we can ask it to

00:19:16,130 --> 00:19:20,360
recommend things and this is a lot of

00:19:18,800 --> 00:19:23,540
time where people love to go when they

00:19:20,360 --> 00:19:24,770
talk about machine learning you may have

00:19:23,540 --> 00:19:27,580
seen some recommendations on some

00:19:24,770 --> 00:19:30,680
popular shopping sites like Amazon and

00:19:27,580 --> 00:19:31,940
the thing that's fun about interacting

00:19:30,680 --> 00:19:33,140
with websites that are having

00:19:31,940 --> 00:19:35,660
recommendation systems built into them

00:19:33,140 --> 00:19:38,930
is that we as customers are classifying

00:19:35,660 --> 00:19:41,420
ourselves right I'm buying this book on

00:19:38,930 --> 00:19:43,430
Python or I'm looking at this this movie

00:19:41,420 --> 00:19:46,070
or whatever I'm buying some buying some

00:19:43,430 --> 00:19:47,690
garden supplies and so I'm adding all

00:19:46,070 --> 00:19:48,140
these data points that classify Here I

00:19:47,690 --> 00:19:49,790
am

00:19:48,140 --> 00:19:51,890
and then Amazon can look at these data

00:19:49,790 --> 00:19:53,030
points and say oh well based on what

00:19:51,890 --> 00:19:54,320
you're shopping for which you looked at

00:19:53,030 --> 00:19:56,210
or what your friends have bought or

00:19:54,320 --> 00:19:57,650
whatever they use I can recommend these

00:19:56,210 --> 00:20:00,530
things which are nowhere similar to you

00:19:57,650 --> 00:20:03,020
or which have been liked or or similar

00:20:00,530 --> 00:20:04,370
to other people who are like you so the

00:20:03,020 --> 00:20:06,200
next time you're buying stuff you can

00:20:04,370 --> 00:20:13,340
think I'm classifying I'm doing machine

00:20:06,200 --> 00:20:16,280
learning one algorithm is the jacquard

00:20:13,340 --> 00:20:18,860
index so this is kind of a fun one this

00:20:16,280 --> 00:20:22,610
is where it takes you look at discrete

00:20:18,860 --> 00:20:25,280
discrete sets of data and it says how

00:20:22,610 --> 00:20:28,880
similar or different are these sets of

00:20:25,280 --> 00:20:30,980
data and it looks at the unions and the

00:20:28,880 --> 00:20:34,640
intersections of these sets of data in

00:20:30,980 --> 00:20:42,080
the site how similar they are it you

00:20:34,640 --> 00:20:45,650
know sounds similar to the LSI basically

00:20:42,080 --> 00:20:49,130
it says given you know if I'll just look

00:20:45,650 --> 00:20:51,230
at good given a few arrays this is the

00:20:49,130 --> 00:20:53,060
exact card one of the gems you can use

00:20:51,230 --> 00:20:55,520
given a few arrays which ones are like

00:20:53,060 --> 00:20:58,580
the others now we can see that you know

00:20:55,520 --> 00:21:00,470
user a likes genes and likes blue user B

00:20:58,580 --> 00:21:02,390
likes genes like apples likes red so

00:21:00,470 --> 00:21:05,570
they're not terribly similar because the

00:21:02,390 --> 00:21:07,040
union of those two arrays combined with

00:21:05,570 --> 00:21:09,830
the size of those two arrays is not a

00:21:07,040 --> 00:21:11,690
great ratio but if you look at user C he

00:21:09,830 --> 00:21:13,430
likes apples and he likes red if you

00:21:11,690 --> 00:21:14,750
compare B and C you're like oh you know

00:21:13,430 --> 00:21:18,020
what B and C have a big

00:21:14,750 --> 00:21:19,640
and also that Union is as big you know

00:21:18,020 --> 00:21:21,799
is very similar to the total size this

00:21:19,640 --> 00:21:22,970
set so these guys are pretty similar and

00:21:21,799 --> 00:21:25,370
the jacquard will tell you the

00:21:22,970 --> 00:21:29,030
coefficient of the similarity so you can

00:21:25,370 --> 00:21:30,559
say okay given a new set of likes how

00:21:29,030 --> 00:21:33,590
similar to someone else who's already in

00:21:30,559 --> 00:21:35,090
the system the the k-means library that

00:21:33,590 --> 00:21:36,799
we talked about at the beginning can

00:21:35,090 --> 00:21:39,350
also use the jacquard index as one of

00:21:36,799 --> 00:21:40,940
its calculations so again remember means

00:21:39,350 --> 00:21:43,070
it's only talking about averages so XY

00:21:40,940 --> 00:21:44,299
is one way but Jaccard coefficient is

00:21:43,070 --> 00:21:47,870
another number that it can use as a

00:21:44,299 --> 00:21:49,400
measure for clustering people so you can

00:21:47,870 --> 00:21:52,419
cluster thing people based on

00:21:49,400 --> 00:21:56,450
preferences which is kind of fun

00:21:52,419 --> 00:21:58,190
this library also I'm sorry and there's

00:21:56,450 --> 00:21:59,630
also a postgrads extension for this

00:21:58,190 --> 00:22:00,890
called PG similarity so you can

00:21:59,630 --> 00:22:02,570
calculate this stuff in the database

00:22:00,890 --> 00:22:03,830
like Aaron was talking about yesterday

00:22:02,570 --> 00:22:06,440
with the function that did the hamming

00:22:03,830 --> 00:22:08,059
distance in sequel light that particular

00:22:06,440 --> 00:22:09,710
puzzle essentially has your card has

00:22:08,059 --> 00:22:11,630
Hamming and so if you're doing a lot of

00:22:09,710 --> 00:22:12,770
computations over a lot of data putting

00:22:11,630 --> 00:22:19,520
a database can help your performance

00:22:12,770 --> 00:22:23,030
quite a bit there's another useful gem

00:22:19,520 --> 00:22:25,370
called recommendable which takes these

00:22:23,030 --> 00:22:28,850
concepts especially jacquard and says

00:22:25,370 --> 00:22:32,510
okay let's let a user like something so

00:22:28,850 --> 00:22:34,280
I'd say I'm doing a movie site and I

00:22:32,510 --> 00:22:35,990
want my users to like movies and after

00:22:34,280 --> 00:22:36,620
they like a certain set of movies then I

00:22:35,990 --> 00:22:38,390
should be able to give them

00:22:36,620 --> 00:22:41,470
recommendations on what movies they

00:22:38,390 --> 00:22:44,299
might like that they haven't seen yet so

00:22:41,470 --> 00:22:48,380
if I you know like movie a and I like

00:22:44,299 --> 00:22:50,390
movie B then C then I know that Alice

00:22:48,380 --> 00:22:53,210
has also liked movie like movie a and

00:22:50,390 --> 00:22:56,030
movie B and she's also like movie C well

00:22:53,210 --> 00:22:58,039
then there's some reasonable assumption

00:22:56,030 --> 00:22:59,870
that I might also like maybe see because

00:22:58,039 --> 00:23:01,880
our likes are similar so the

00:22:59,870 --> 00:23:04,190
recommendation system can say then you

00:23:01,880 --> 00:23:06,190
should check out maybe C because other

00:23:04,190 --> 00:23:08,750
people who are like you have liked it

00:23:06,190 --> 00:23:11,270
this recommend well Jim is pretty cool

00:23:08,750 --> 00:23:12,650
if you're familiar with Redis you might

00:23:11,270 --> 00:23:14,150
be thinking hey that'd be a great place

00:23:12,650 --> 00:23:15,919
to put stuff because it deal with sets

00:23:14,150 --> 00:23:18,260
all the time and in fact this Jim you

00:23:15,919 --> 00:23:22,159
just read it Redis to store those sets

00:23:18,260 --> 00:23:24,260
so it's pretty quick and it's it's you

00:23:22,159 --> 00:23:26,539
can also this gem is neat also because

00:23:24,260 --> 00:23:28,039
it has an idea of the nearest neighbor

00:23:26,539 --> 00:23:28,550
which you've done if you've done much

00:23:28,039 --> 00:23:31,010
plotting

00:23:28,550 --> 00:23:32,720
is can tell you how something how

00:23:31,010 --> 00:23:33,980
relevant something is or not and so you

00:23:32,720 --> 00:23:35,990
can actually limit it to a certain

00:23:33,980 --> 00:23:38,360
number of people so you help refine the

00:23:35,990 --> 00:23:40,970
recommendations that's all kind of fun

00:23:38,360 --> 00:23:43,430
stuff like that but if you check out

00:23:40,970 --> 00:23:45,320
that gym there's a blog post that this

00:23:43,430 --> 00:23:47,540
author has written that goes along with

00:23:45,320 --> 00:23:51,590
it that talks about in great length and

00:23:47,540 --> 00:23:53,270
it's it's good read if you're really

00:23:51,590 --> 00:23:54,980
interested in recommendation engines and

00:23:53,270 --> 00:23:57,620
especially if you're doing e-commerce

00:23:54,980 --> 00:23:59,540
like things you should definitely check

00:23:57,620 --> 00:24:01,760
out this ebook by O'Reilly called

00:23:59,540 --> 00:24:03,170
practical machine learning it is a free

00:24:01,760 --> 00:24:04,400
resource all you have to do is give up

00:24:03,170 --> 00:24:05,380
your email address so they can be

00:24:04,400 --> 00:24:08,360
marketed out for the rest of eternity

00:24:05,380 --> 00:24:09,980
but once you've done that you get access

00:24:08,360 --> 00:24:13,250
to this great book and it talks about

00:24:09,980 --> 00:24:16,610
using Apache mahout and Apache Solr and

00:24:13,250 --> 00:24:18,640
the approach this OTO takes is I I find

00:24:16,610 --> 00:24:22,250
really intriguing

00:24:18,640 --> 00:24:24,740
if you classify people based on their

00:24:22,250 --> 00:24:26,540
likes so let's say that you got three

00:24:24,740 --> 00:24:26,990
shoppers right and here's an example I

00:24:26,540 --> 00:24:29,330
use in the book

00:24:26,990 --> 00:24:32,720
you've got Alice and you got Bob and you

00:24:29,330 --> 00:24:36,560
got Charles and Alice likes apples and

00:24:32,720 --> 00:24:40,520
Alice likes puppies and Alice likes

00:24:36,560 --> 00:24:44,930
ponies got ponies in there Charles

00:24:40,520 --> 00:24:47,750
he likes ponies too and bicycles and Bob

00:24:44,930 --> 00:24:50,540
he likes apples and ponies they all like

00:24:47,750 --> 00:24:52,640
ponies so what can we recommend to Bob

00:24:50,540 --> 00:24:54,790
based on the recommendations that other

00:24:52,640 --> 00:24:59,800
other likes that are in the system well

00:24:54,790 --> 00:25:01,820
ponies what someone give the answer

00:24:59,800 --> 00:25:03,350
ponies make no sense because everybody

00:25:01,820 --> 00:25:05,030
likes ponies so we're not going to

00:25:03,350 --> 00:25:07,220
recommend to Bob that he likes ponies

00:25:05,030 --> 00:25:09,590
everyone next ponies but we know that

00:25:07,220 --> 00:25:12,350
Alice has liked apples and puppies and

00:25:09,590 --> 00:25:14,690
Bob has chosen to like puppies and so

00:25:12,350 --> 00:25:16,280
you might also like apples so that's the

00:25:14,690 --> 00:25:18,170
example they use in the book and they

00:25:16,280 --> 00:25:20,360
talk about how Apache ma Hut has

00:25:18,170 --> 00:25:22,340
algorithms built into it that allow you

00:25:20,360 --> 00:25:24,680
to feed all this kind of data into it

00:25:22,340 --> 00:25:26,420
and then it can do similarities it can

00:25:24,680 --> 00:25:28,850
look at co-occurrences and they can say

00:25:26,420 --> 00:25:30,470
oh and it can ignore those Universal

00:25:28,850 --> 00:25:32,680
ones like ponies and then they can tell

00:25:30,470 --> 00:25:35,780
you by the way you should recommend

00:25:32,680 --> 00:25:37,730
puppies to someone who likes apples and

00:25:35,780 --> 00:25:38,930
then he talks in the book about using

00:25:37,730 --> 00:25:40,640
those recommendations and putting them

00:25:38,930 --> 00:25:42,000
into solar which i think is really neat

00:25:40,640 --> 00:25:44,040
so then if you have

00:25:42,000 --> 00:25:46,170
sucks if you have the Apple product you

00:25:44,040 --> 00:25:47,750
can say in solar here's a list of

00:25:46,170 --> 00:25:49,830
related products like puppies and

00:25:47,750 --> 00:25:52,020
conversely for puppies and apples if you

00:25:49,830 --> 00:25:53,670
want and so it makes it really easy then

00:25:52,020 --> 00:25:57,180
to have a searchable index that you can

00:25:53,670 --> 00:25:59,190
use to look up like products or like

00:25:57,180 --> 00:26:00,780
documents or whatever you can use their

00:25:59,190 --> 00:26:03,420
imagination to come up with interesting

00:26:00,780 --> 00:26:11,580
things but I thought that was a thing

00:26:03,420 --> 00:26:14,120
approach and that is all I have so I

00:26:11,580 --> 00:26:14,120

YouTube URL: https://www.youtube.com/watch?v=crziu7dk6Vw


