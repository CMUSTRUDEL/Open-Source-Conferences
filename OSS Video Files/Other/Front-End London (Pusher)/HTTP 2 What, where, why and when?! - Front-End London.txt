Title: HTTP 2 What, where, why and when?! - Front-End London
Publication date: 2016-09-14
Playlist: Front-End London
Description: 
	The onset of HTTP/2 is upon us. Now over 75% of your users browsers support the low-latency transfer protocol, yet adoption has been slow.

What does this really mean for us as frontend developers? How can we utilise H2’s features to deliver fast experiences? Have our best practices become anti-patterns? What is the tooling landscape like and will we need to change our existing build systems?

Over the course of this talk, Patrick will use new research and real-world examples from the Financial Times to put our minds at easy and – most importantly – get you excited about a future with HTTP/2.

▼ Speaker ▼

Patrick Hamann (https://twitter.com/patrickhamann)

▼ Event ▼

This talk was part of Front-End London in August

▼ Transcript ▼

Coming soon...

▼ Video by Pusher ▼

Pusher is a hosted service with APIs, developer tools and open source libraries that greatly simplify integrating real-time functionality into web and mobile applications.

Pusher will automatically scale when required, removing all the pain of setting up and maintaining a secure, real-time infrastructure.

Pusher is already trusted to do so by thousands of developers and companies like GitHub, MailChimp, the Financial Times, Buffer and many more.

Getting started takes just a few seconds: simply go to https://pusher.com and create a free account. Happy hacking!

▼ More from Pusher ▼

Subscribe to Pusher: https://www.youtube.com/c/pusherrealtime?sub_confirmation=1
Front-End London playlist: https://www.youtube.com/playlist?list=PL8xuokhAnn4pZ6tAyFobOcUrLI2MNKZbU
Captions: 
	00:00:07,309 --> 00:00:11,130
having it's already my name's Patrick

00:00:09,480 --> 00:00:13,349
come in you can catch me there on

00:00:11,130 --> 00:00:15,929
Twitter at Patrick Hammond I'm always up

00:00:13,349 --> 00:00:17,609
for a rant about performance or chat and

00:00:15,929 --> 00:00:19,310
come and grab me in the power BAFTA

00:00:17,609 --> 00:00:23,400
words if you not on Twitter anything

00:00:19,310 --> 00:00:24,750
please please talk it's good to talk you

00:00:23,400 --> 00:00:26,160
haven't guessed it already I live and

00:00:24,750 --> 00:00:28,230
work here in London at the Financial

00:00:26,160 --> 00:00:30,630
Times we are the world's leading news

00:00:28,230 --> 00:00:33,329
organization for Business and Economic

00:00:30,630 --> 00:00:35,730
Affairs we're amongst other things I'm

00:00:33,329 --> 00:00:39,210
helping to rebuild the next generation

00:00:35,730 --> 00:00:41,430
of ft.com we're redefining how the FT

00:00:39,210 --> 00:00:43,530
delivers news creating an immersive and

00:00:41,430 --> 00:00:45,600
personalized news experience for our

00:00:43,530 --> 00:00:47,610
users but one of the core remix when

00:00:45,600 --> 00:00:49,230
we've been building this product is that

00:00:47,610 --> 00:00:51,510
we know we wanted to make it extremely

00:00:49,230 --> 00:00:53,850
fast we've done a lot of research and

00:00:51,510 --> 00:00:56,280
know that could speed correlate directly

00:00:53,850 --> 00:00:57,899
with engagement of our users and

00:00:56,280 --> 00:01:00,809
therefore people coming back to our site

00:00:57,899 --> 00:01:02,850
reading Newton more news subscribing

00:01:00,809 --> 00:01:05,489
more giving us more money and paying my

00:01:02,850 --> 00:01:07,619
wages but I'm not actually here today to

00:01:05,489 --> 00:01:09,360
talk about the product development of

00:01:07,619 --> 00:01:10,920
that I'd love to be able to talk to that

00:01:09,360 --> 00:01:12,780
but I'm here to talk to you about how

00:01:10,920 --> 00:01:14,970
we're making it as fast as possible and

00:01:12,780 --> 00:01:17,159
more specifically one of the underlying

00:01:14,970 --> 00:01:19,979
technologies that we're using to deliver

00:01:17,159 --> 00:01:22,920
the news as fast as possible so

00:01:19,979 --> 00:01:24,479
hopefully this may look slightly

00:01:22,920 --> 00:01:26,640
familiar to many of you in the room

00:01:24,479 --> 00:01:28,680
especially if you're a developer since

00:01:26,640 --> 00:01:30,930
their inception web pages have been

00:01:28,680 --> 00:01:33,450
delivered over the same way over the

00:01:30,930 --> 00:01:36,180
network over the same way for tens and

00:01:33,450 --> 00:01:39,180
tens of years we have tcp/ip at the

00:01:36,180 --> 00:01:41,369
bottom HTTP at the top when we use the

00:01:39,180 --> 00:01:43,500
transfer protocol to deliver our HTML

00:01:41,369 --> 00:01:45,570
CSS and JavaScript that form the web

00:01:43,500 --> 00:01:48,180
pages that you build on a daily basis

00:01:45,570 --> 00:01:49,890
and your users interact with and as

00:01:48,180 --> 00:01:52,860
application design ISM developers we've

00:01:49,890 --> 00:01:54,630
rarely had to understand even how the

00:01:52,860 --> 00:01:56,640
bottom half of this stack fits together

00:01:54,630 --> 00:01:59,490
and how it communicates with the top

00:01:56,640 --> 00:02:02,310
layer and by analyze that's remained the

00:01:59,490 --> 00:02:04,140
same for about 20 years now but this is

00:02:02,310 --> 00:02:06,090
beginning to change and it's quite an

00:02:04,140 --> 00:02:09,209
exciting time because of that and that's

00:02:06,090 --> 00:02:11,819
again what I'm here to talk to you today

00:02:09,209 --> 00:02:13,920
for the first time in nearly over 20

00:02:11,819 --> 00:02:16,109
years we now have a new version of the

00:02:13,920 --> 00:02:18,629
underlying transfer protocol of the

00:02:16,109 --> 00:02:22,079
Internet the protocol that all our

00:02:18,629 --> 00:02:24,870
websites use to deliver their assets and

00:02:22,079 --> 00:02:27,209
the simplicity I think of the HTTP

00:02:24,870 --> 00:02:29,579
protocol hasn't has the reason why it's

00:02:27,209 --> 00:02:31,620
been so long right it was actually from

00:02:29,579 --> 00:02:33,719
its initial design from tins berners-lee

00:02:31,620 --> 00:02:35,639
in his colleagues at CERN such a well

00:02:33,719 --> 00:02:37,109
designed specification that it didn't

00:02:35,639 --> 00:02:39,079
really need to change that smile it

00:02:37,109 --> 00:02:42,989
actually lasted us so well we now have

00:02:39,079 --> 00:02:44,879
fridges watches even cars that

00:02:42,989 --> 00:02:46,709
communicate with each other and the

00:02:44,879 --> 00:02:48,150
servers around the world using this

00:02:46,709 --> 00:02:49,829
transfer protocol you might find that a

00:02:48,150 --> 00:02:51,540
bit scary that cars are talking it to

00:02:49,829 --> 00:02:55,650
each other over HP but I think it's an

00:02:51,540 --> 00:02:57,870
amazing testament to to the protocol and

00:02:55,650 --> 00:03:01,650
why it's actually survived so long but

00:02:57,870 --> 00:03:03,780
as things get older you know most things

00:03:01,650 --> 00:03:06,599
start to sign show some signs of stress

00:03:03,780 --> 00:03:09,739
and to meet these new challenges the web

00:03:06,599 --> 00:03:12,569
of 1991 is very different to the web of

00:03:09,739 --> 00:03:14,609
2016 and so to meet these new challenges

00:03:12,569 --> 00:03:17,190
it's starting to show some signs of

00:03:14,609 --> 00:03:19,739
stress and so that's why in 2012 the

00:03:17,190 --> 00:03:22,949
HTTP biz which is a working group part

00:03:19,739 --> 00:03:25,949
of the IETF announced the new initiative

00:03:22,949 --> 00:03:28,169
to create HTTP 2 it's taken until now -

00:03:25,949 --> 00:03:30,299
last year for that working draft to

00:03:28,169 --> 00:03:32,819
climb out and be finalized and that's

00:03:30,299 --> 00:03:37,199
why exciting literally last year we have

00:03:32,819 --> 00:03:38,759
a new point - version of the underlying

00:03:37,199 --> 00:03:40,319
transfer protocol of the internet and

00:03:38,759 --> 00:03:42,389
this is very much of the back of the

00:03:40,319 --> 00:03:44,280
work that Mike bleachy and colleagues at

00:03:42,389 --> 00:03:45,449
Google did in the Speedy draft might

00:03:44,280 --> 00:03:48,659
talk about a little bit about that later

00:03:45,449 --> 00:03:51,090
ever time so that's what I'm going to

00:03:48,659 --> 00:03:52,379
cover today is the why the what the

00:03:51,090 --> 00:03:54,479
where in the web why do you need to know

00:03:52,379 --> 00:03:57,030
about HTTP how does it work underneath

00:03:54,479 --> 00:04:01,409
and what why you should know about that

00:03:57,030 --> 00:04:03,180
to help you with your daily basis but

00:04:01,409 --> 00:04:05,009
most of you are probably asking and I

00:04:03,180 --> 00:04:08,069
definitely ask myself this as well and

00:04:05,009 --> 00:04:10,169
why do we did we need a new version

00:04:08,069 --> 00:04:12,209
right I'm still building websites every

00:04:10,169 --> 00:04:14,340
single day delivering them they're

00:04:12,209 --> 00:04:17,430
working our users loving them coming

00:04:14,340 --> 00:04:19,169
back why do we need this and it's quite

00:04:17,430 --> 00:04:20,729
common and quite right for you to ask

00:04:19,169 --> 00:04:23,430
that but I have to let you into a little

00:04:20,729 --> 00:04:26,729
secret that we're all trapped in the

00:04:23,430 --> 00:04:29,539
lolled sense of funk security that our

00:04:26,729 --> 00:04:33,210
websites are in fact using the network

00:04:29,539 --> 00:04:35,039
extremely inefficiently and why is this

00:04:33,210 --> 00:04:37,139
hopefully the next sections going to

00:04:35,039 --> 00:04:41,009
explain that I mentioned earlier that

00:04:37,139 --> 00:04:43,800
the web of 95 this is ft.com Tech in 95

00:04:41,009 --> 00:04:45,690
is very different to the web of today

00:04:43,800 --> 00:04:48,150
our users expecting a much more

00:04:45,690 --> 00:04:51,560
immersive experiences hundreds of

00:04:48,150 --> 00:04:54,180
resources different mediums images video

00:04:51,560 --> 00:04:56,669
interactions but all of this is coming

00:04:54,180 --> 00:04:59,009
at a cost when we deliver it down the

00:04:56,669 --> 00:05:00,810
network to our users as you can see it's

00:04:59,009 --> 00:05:02,520
very very different that is literally

00:05:00,810 --> 00:05:04,680
just text on a white they didn't have

00:05:02,520 --> 00:05:06,419
CSS then this is all just tables and it

00:05:04,680 --> 00:05:09,599
was probably one single file probably

00:05:06,419 --> 00:05:11,520
two at most and it's completely

00:05:09,599 --> 00:05:14,610
different to what our users are

00:05:11,520 --> 00:05:16,410
expecting we have to hire hundreds of

00:05:14,610 --> 00:05:19,039
people to be able to deliver this now

00:05:16,410 --> 00:05:21,449
and live up with the rest of the

00:05:19,039 --> 00:05:24,660
competition that we have in the world

00:05:21,449 --> 00:05:27,720
and so our average web pages are now

00:05:24,660 --> 00:05:30,720
making over 80 requests per page and

00:05:27,720 --> 00:05:35,370
that is just that's not it that's the

00:05:30,720 --> 00:05:37,710
95th percentile is more like 300 plus we

00:05:35,370 --> 00:05:39,780
are at the peak of a website obesity

00:05:37,710 --> 00:05:43,770
crisis and the trend as you can see here

00:05:39,780 --> 00:05:49,800
is not stopping anytime soon let me just

00:05:43,770 --> 00:05:52,620
let that settle in 80 requests HP 1 and

00:05:49,800 --> 00:05:54,479
1.1 simply was not designed to cater for

00:05:52,620 --> 00:05:57,509
this sheer amount of requests going down

00:05:54,479 --> 00:05:59,669
the pipe like this is probably just 1 or

00:05:57,509 --> 00:06:01,650
5 the first website that Tim berners-lee

00:05:59,669 --> 00:06:03,330
ever made was a single document and it

00:06:01,650 --> 00:06:07,320
was linking to another one that was it

00:06:03,330 --> 00:06:09,060
just one request so whilst we've seen a

00:06:07,320 --> 00:06:11,370
great increase in the available

00:06:09,060 --> 00:06:13,199
bandwidth that people have over the last

00:06:11,370 --> 00:06:14,849
few years a lot of us here we're very

00:06:13,199 --> 00:06:16,830
privileged to live in London we have

00:06:14,849 --> 00:06:18,900
things like Virgin Media that have cable

00:06:16,830 --> 00:06:21,090
going into our houses that have now

00:06:18,900 --> 00:06:24,030
something ridiculous like 200 megabits a

00:06:21,090 --> 00:06:26,909
second pipe going into your own living

00:06:24,030 --> 00:06:29,729
room yet we haven't seen the same

00:06:26,909 --> 00:06:31,469
benefits and improvements in latency now

00:06:29,729 --> 00:06:33,240
what is latency so latency is

00:06:31,469 --> 00:06:35,580
essentially can be boiled down to the

00:06:33,240 --> 00:06:36,960
time it takes from a request to go from

00:06:35,580 --> 00:06:38,340
your mobile phone

00:06:36,960 --> 00:06:40,770
the way to the server and back again the

00:06:38,340 --> 00:06:42,960
round-trip time and mobile networks by

00:06:40,770 --> 00:06:45,030
their pure nature and very highly latent

00:06:42,960 --> 00:06:46,919
things you are a rat if Mobile's in the

00:06:45,030 --> 00:06:48,419
name right you are mobile you're walking

00:06:46,919 --> 00:06:51,419
around it's going to take a long time

00:06:48,419 --> 00:06:53,759
and when's Dougal were building we're

00:06:51,419 --> 00:06:55,349
experimenting with speedy Mike bleachy

00:06:53,759 --> 00:06:57,690
and it's a great article down here that

00:06:55,349 --> 00:07:00,180
slides will be online later they found

00:06:57,690 --> 00:07:01,889
that whilst you increased at the speed

00:07:00,180 --> 00:07:03,990
of bandwidth it plateaued there was a

00:07:01,889 --> 00:07:06,569
threshold where that had no no longer

00:07:03,990 --> 00:07:09,870
had any more impact on your page load

00:07:06,569 --> 00:07:11,849
time whereas there was for every 20

00:07:09,870 --> 00:07:14,580
millisecond improvement in latency there

00:07:11,849 --> 00:07:16,710
was a near linear improvement with the

00:07:14,580 --> 00:07:17,970
page load time of your website and there

00:07:16,710 --> 00:07:19,860
are many good reasons for this you know

00:07:17,970 --> 00:07:21,919
as we've seen it's 80 requests the

00:07:19,860 --> 00:07:24,180
average page is composed of many small

00:07:21,919 --> 00:07:26,160
resources which require many connections

00:07:24,180 --> 00:07:28,620
many TCP connections each with their own

00:07:26,160 --> 00:07:30,479
overheads and the performance of each

00:07:28,620 --> 00:07:35,819
one this is very very closely tied to

00:07:30,479 --> 00:07:38,970
your round-trip time hb1 the data was

00:07:35,819 --> 00:07:40,470
defined as an ASCII character stream of

00:07:38,970 --> 00:07:42,210
text so you can actually see it it's

00:07:40,470 --> 00:07:44,849
just it's English this the text that you

00:07:42,210 --> 00:07:47,460
can go by its ASCII so because of this

00:07:44,849 --> 00:07:49,500
we must send and receive the requests in

00:07:47,460 --> 00:07:51,900
exactly the same order that we sent them

00:07:49,500 --> 00:07:53,460
so we have to when we send a request for

00:07:51,900 --> 00:07:55,860
image 1 we have to wait for the server

00:07:53,460 --> 00:07:58,650
to respond of that data so we can

00:07:55,860 --> 00:08:01,139
allocate the data to that request in the

00:07:58,650 --> 00:08:03,949
browser until we can send the next one

00:08:01,139 --> 00:08:06,419
on a single TCP connection and this

00:08:03,949 --> 00:08:09,719
phenomenon is known as head of line

00:08:06,419 --> 00:08:11,400
blocking this could be analogy like this

00:08:09,719 --> 00:08:13,650
is you could be in a bank you have two

00:08:11,400 --> 00:08:16,469
people in front of you waiting for the

00:08:13,650 --> 00:08:18,599
cashier you are blocked by them and

00:08:16,469 --> 00:08:21,090
however long it may take to process them

00:08:18,599 --> 00:08:23,250
at the cashier until you can go and we

00:08:21,090 --> 00:08:26,070
have exactly the same problem with TCP

00:08:23,250 --> 00:08:26,520
connections because the data is ASCII we

00:08:26,070 --> 00:08:28,469
can't

00:08:26,520 --> 00:08:30,000
interleave it because the things might

00:08:28,469 --> 00:08:32,099
get mixed up the cashier might get

00:08:30,000 --> 00:08:33,630
confused so we have to wait for that

00:08:32,099 --> 00:08:36,060
response before we can send the next

00:08:33,630 --> 00:08:38,729
response now this is a fundamental flaw

00:08:36,060 --> 00:08:41,459
well some would say in the design of HP

00:08:38,729 --> 00:08:43,890
one and most importantly why we have a

00:08:41,459 --> 00:08:46,740
ripple of effects so to get around this

00:08:43,890 --> 00:08:48,600
issue browsers started to open more than

00:08:46,740 --> 00:08:51,360
one TCP connection for the same host

00:08:48,600 --> 00:08:53,160
it's like okay I can't I can't send a

00:08:51,360 --> 00:08:54,810
request in this TCP connection so I'm

00:08:53,160 --> 00:08:56,940
gonna have to open another one so we

00:08:54,810 --> 00:08:59,310
started off by opening two and then that

00:08:56,940 --> 00:09:01,260
wasn't enough so now the specification

00:08:59,310 --> 00:09:04,980
says that we're allowed to have six open

00:09:01,260 --> 00:09:06,870
TCP connections to the same host name to

00:09:04,980 --> 00:09:09,029
overcome the head-of-line blocking but

00:09:06,870 --> 00:09:11,550
this comes at a great cost to our users

00:09:09,029 --> 00:09:12,990
right each connection incurs a full TCP

00:09:11,550 --> 00:09:14,519
handshake if you've ever seen me talk

00:09:12,990 --> 00:09:16,350
before I've explained in depth about

00:09:14,519 --> 00:09:17,700
that but on your UK average 3G

00:09:16,350 --> 00:09:19,950
connection that could be up to a

00:09:17,700 --> 00:09:23,040
thousand milliseconds just to open the

00:09:19,950 --> 00:09:24,600
TCP connection and the connection then

00:09:23,040 --> 00:09:26,339
we if you're over secure network that

00:09:24,600 --> 00:09:29,160
may add the TLS handshake as well and

00:09:26,339 --> 00:09:31,079
then each connection competes with the

00:09:29,160 --> 00:09:33,740
underlying network resources that

00:09:31,079 --> 00:09:36,000
bandwidth and thus causing potential

00:09:33,740 --> 00:09:39,029
congestion on the underlying network

00:09:36,000 --> 00:09:40,500
link and that wasn't enough right so we

00:09:39,029 --> 00:09:42,420
stopped at 6:00 we're like no but I need

00:09:40,500 --> 00:09:43,950
I need to optimize this as much as

00:09:42,420 --> 00:09:46,350
possible so we started to create hacks

00:09:43,950 --> 00:09:48,480
and anti-patterns to overcome

00:09:46,350 --> 00:09:50,610
head-of-line blocking so one of which is

00:09:48,480 --> 00:09:52,829
concatenation i've heard all the cool

00:09:50,610 --> 00:09:54,480
kids today like to use react angular

00:09:52,829 --> 00:09:57,920
jquery bootstrap and mootools

00:09:54,480 --> 00:09:59,820
all in the same application in fact

00:09:57,920 --> 00:10:02,070
except just talking about my dear friend

00:09:59,820 --> 00:10:03,420
oli is actually using an architect like

00:10:02,070 --> 00:10:03,839
that at the moment he's no longer my

00:10:03,420 --> 00:10:09,149
friend

00:10:03,839 --> 00:10:10,890
and so why create t have the overhead of

00:10:09,149 --> 00:10:13,110
creating five connections when I can

00:10:10,890 --> 00:10:15,329
concatenate that into a single file and

00:10:13,110 --> 00:10:17,130
therefore I only need to open one TCP

00:10:15,329 --> 00:10:18,870
connection for this and this is great

00:10:17,130 --> 00:10:20,970
and I still do this to a daily basis

00:10:18,870 --> 00:10:22,140
most of you will have build processes

00:10:20,970 --> 00:10:24,329
that can catenate in these files

00:10:22,140 --> 00:10:26,730
together but this comes at a cost right

00:10:24,329 --> 00:10:29,010
that's more CPU and memory overhead for

00:10:26,730 --> 00:10:30,990
your low powered mobile device to

00:10:29,010 --> 00:10:33,240
download and parcel that even if they

00:10:30,990 --> 00:10:33,990
only need to actually execute two lines

00:10:33,240 --> 00:10:36,209
of mootools

00:10:33,990 --> 00:10:38,370
you've just incurred the user from

00:10:36,209 --> 00:10:40,140
downloading all of those bikes and if I

00:10:38,370 --> 00:10:42,480
change a single line even let's add a

00:10:40,140 --> 00:10:44,250
semicolon to a line and then

00:10:42,480 --> 00:10:46,199
invalidating all of those bikes even

00:10:44,250 --> 00:10:48,360
though I only change one bike in that

00:10:46,199 --> 00:10:50,430
file I'm forcing the down the user to

00:10:48,360 --> 00:10:51,870
download images actually came first

00:10:50,430 --> 00:10:53,760
before this and images were the main

00:10:51,870 --> 00:10:57,269
reason why we actually started opening

00:10:53,760 --> 00:10:58,829
more connections because in Kannada

00:10:57,269 --> 00:11:00,449
early noughties they were the main

00:10:58,829 --> 00:11:02,310
medium that we were throwing loads more

00:11:00,449 --> 00:11:04,589
at and so we started to borrow ideas

00:11:02,310 --> 00:11:04,950
from gaming developers in the 80s and we

00:11:04,589 --> 00:11:07,890
started

00:11:04,950 --> 00:11:11,400
sprite image together so rather than

00:11:07,890 --> 00:11:13,890
having a 200 HTTP requests over probably

00:11:11,400 --> 00:11:16,260
six TCP connections I can concatenate

00:11:13,890 --> 00:11:18,360
that into one sprite into one but the

00:11:16,260 --> 00:11:21,000
problem here is I probably only need to

00:11:18,360 --> 00:11:23,580
use one image on my page and so I've

00:11:21,000 --> 00:11:25,500
just forced the user to download 200

00:11:23,580 --> 00:11:28,170
pixels maybe even 2 megabytes of data

00:11:25,500 --> 00:11:29,880
when all I wanted to just display that

00:11:28,170 --> 00:11:31,830
one image and again the invalidation

00:11:29,880 --> 00:11:33,720
problems here is I changed my designer

00:11:31,830 --> 00:11:35,790
decides that this devil actually needs

00:11:33,720 --> 00:11:38,100
to be green we've just forced the user

00:11:35,790 --> 00:11:40,080
to redownload all of those images not

00:11:38,100 --> 00:11:43,710
benefiting of having a cache at all on

00:11:40,080 --> 00:11:45,810
the user's device and then we decided

00:11:43,710 --> 00:11:48,060
that 6 hosts wasn't even enough right

00:11:45,810 --> 00:11:49,860
and so we started to shard our TCP

00:11:48,060 --> 00:11:52,800
connections so here this is literally

00:11:49,860 --> 00:11:56,340
taken from Flickr a month ago this is C

00:11:52,800 --> 00:11:58,680
1 C 2 C 3 C 4 at static Flickr host com

00:11:56,340 --> 00:12:00,510
this is actually all residing back to

00:11:58,680 --> 00:12:02,610
probably the same IP address or the same

00:12:00,510 --> 00:12:04,680
server even and this is called domain

00:12:02,610 --> 00:12:06,690
sharding so this is tricking the browser

00:12:04,680 --> 00:12:08,430
to thinking that these images are

00:12:06,690 --> 00:12:10,800
actually on different hosts so it will

00:12:08,430 --> 00:12:13,920
open up another 6 connections so Flickr

00:12:10,800 --> 00:12:16,110
is probably actually got 24 open TCP

00:12:13,920 --> 00:12:18,660
connections right now and this is coming

00:12:16,110 --> 00:12:19,920
out a cost and by creating those

00:12:18,660 --> 00:12:22,500
additional TCP connections we're

00:12:19,920 --> 00:12:26,430
actually completely flooding the

00:12:22,500 --> 00:12:27,660
underlying TC network and Etsy I should

00:12:26,430 --> 00:12:29,550
have had a link to them Etsy have done

00:12:27,660 --> 00:12:31,470
some amazing research here as to the

00:12:29,550 --> 00:12:34,890
threshold point at which you actually

00:12:31,470 --> 00:12:37,500
start to cause performance issues rather

00:12:34,890 --> 00:12:40,140
than gain them by - domain sharding and

00:12:37,500 --> 00:12:42,120
finally we started to realize that

00:12:40,140 --> 00:12:45,090
actually let's not create a TCP

00:12:42,120 --> 00:12:47,490
connection at all and let's inline that

00:12:45,090 --> 00:12:49,890
resource into our document so we can

00:12:47,490 --> 00:12:52,230
send it down in the initial one and it's

00:12:49,890 --> 00:12:54,810
quite ironic because I've sat in this

00:12:52,230 --> 00:12:56,550
exact place talking about why this is

00:12:54,810 --> 00:12:59,100
such a great idea probably about 2 years

00:12:56,550 --> 00:13:01,380
ago and has been an evangelist of this

00:12:59,100 --> 00:13:04,770
and I'm now realizing that it's probably

00:13:01,380 --> 00:13:06,150
a very bad I did because when you base64

00:13:04,770 --> 00:13:08,310
encode an image for instance you're

00:13:06,150 --> 00:13:11,520
actually increasing the size of that

00:13:08,310 --> 00:13:14,070
image by 33% so you're actually forcing

00:13:11,520 --> 00:13:15,840
that user to download more and again low

00:13:14,070 --> 00:13:17,760
powered devices are going to have a very

00:13:15,840 --> 00:13:18,720
hard time and lots of memory going to be

00:13:17,760 --> 00:13:20,850
consumed too

00:13:18,720 --> 00:13:23,939
convert this back to its native format

00:13:20,850 --> 00:13:26,970
hopefully you've learnt and why latency

00:13:23,939 --> 00:13:28,860
matters it's all about latency where

00:13:26,970 --> 00:13:30,810
latency occurs what head-of-line

00:13:28,860 --> 00:13:33,449
blocking is the front most fundamental

00:13:30,810 --> 00:13:35,399
problem with h1 and the hacks and

00:13:33,449 --> 00:13:38,699
antipatterns that we created because of

00:13:35,399 --> 00:13:41,250
head-of-line blocking so now that we

00:13:38,699 --> 00:13:43,319
know that how can let's have a look at

00:13:41,250 --> 00:13:45,360
Hector 2 to see how it's overcome these

00:13:43,319 --> 00:13:48,029
problems in what specific bits of the

00:13:45,360 --> 00:13:50,519
design of the specification have made it

00:13:48,029 --> 00:13:52,680
so brilliant and so to start with I

00:13:50,519 --> 00:13:54,750
thought this is quite good this is taken

00:13:52,680 --> 00:13:56,639
from a great books very simple so online

00:13:54,750 --> 00:13:59,870
free open source book called h2

00:13:56,639 --> 00:14:02,459
explained by Daniel Steinberg he is the

00:13:59,870 --> 00:14:05,220
one of the maintainer of curl and he

00:14:02,459 --> 00:14:08,569
works at networking team at Mozilla and

00:14:05,220 --> 00:14:12,569
he was explained the problems or the

00:14:08,569 --> 00:14:15,240
manifests as essentially that the HTTP

00:14:12,569 --> 00:14:16,829
biz hat working group had the remit and

00:14:15,240 --> 00:14:18,300
the requirements they had when they were

00:14:16,829 --> 00:14:19,949
building the specification and that was

00:14:18,300 --> 00:14:22,769
obviously to be less sensitive to

00:14:19,949 --> 00:14:24,620
latency fix the pipelining and head of

00:14:22,769 --> 00:14:27,120
line blocking problems that we just saw

00:14:24,620 --> 00:14:28,379
eliminate the need to increase the

00:14:27,120 --> 00:14:30,329
number of connections and they're all

00:14:28,379 --> 00:14:32,490
those anti patterns to each host and

00:14:30,329 --> 00:14:35,399
this is really important to keep all

00:14:32,490 --> 00:14:37,949
existing interfaces your eye formats and

00:14:35,399 --> 00:14:40,139
schemes I can't stress this enough when

00:14:37,949 --> 00:14:41,879
we're designing a new version of the

00:14:40,139 --> 00:14:45,930
spec it would have been great ok you

00:14:41,879 --> 00:14:48,779
know those periods inside URLs like

00:14:45,930 --> 00:14:50,850
dub-dub-dub dot ft.com I don't like them

00:14:48,779 --> 00:14:53,129
I want to turn that into like a tilde

00:14:50,850 --> 00:14:54,990
dub-dub-dub tilde ft we would have

00:14:53,129 --> 00:14:57,209
broken the internet right so we can't

00:14:54,990 --> 00:14:59,850
change the scheme the semantics the

00:14:57,209 --> 00:15:01,800
methods that we use that most restful

00:14:59,850 --> 00:15:05,009
api is talk to each other we couldn't

00:15:01,800 --> 00:15:07,470
change um most importantly it had to be

00:15:05,009 --> 00:15:09,389
made within the ITF PageSpeed working

00:15:07,470 --> 00:15:11,550
group Google laid some amazing

00:15:09,389 --> 00:15:13,620
foundations with the speedy research but

00:15:11,550 --> 00:15:15,540
it was for them and it was in a

00:15:13,620 --> 00:15:18,059
controlled environment we wanted like

00:15:15,540 --> 00:15:19,529
most good website Ephesians to be

00:15:18,059 --> 00:15:22,620
developed in the open and let other

00:15:19,529 --> 00:15:26,610
people add to and ultimately make it

00:15:22,620 --> 00:15:28,800
better so to do this they've outlined

00:15:26,610 --> 00:15:30,389
what I think are the six core features

00:15:28,800 --> 00:15:32,690
that make up page 2 which is

00:15:30,389 --> 00:15:35,110
multiplexing a binary data

00:15:32,690 --> 00:15:38,360
format prioritization header compression

00:15:35,110 --> 00:15:40,310
flow control and server push and for

00:15:38,360 --> 00:15:41,810
this it because this is front in London

00:15:40,310 --> 00:15:43,280
for front-end developers I think the

00:15:41,810 --> 00:15:45,830
most important things to understand a

00:15:43,280 --> 00:15:48,650
multiplexing prioritization and server

00:15:45,830 --> 00:15:52,160
resource pushing at the heart of all of

00:15:48,650 --> 00:15:54,470
h2 our streams streams essentially a

00:15:52,160 --> 00:15:58,760
virtual channel with inside the TTP

00:15:54,470 --> 00:16:01,280
connection there only which carry

00:15:58,760 --> 00:16:03,590
bi-directional messages so their streams

00:16:01,280 --> 00:16:05,570
are virtual they don't really exist they

00:16:03,590 --> 00:16:07,490
can contain messages which are complete

00:16:05,570 --> 00:16:10,520
sequences of frames and messages are the

00:16:07,490 --> 00:16:13,100
things that most closely map to a HTTP 1

00:16:10,520 --> 00:16:14,690
request or response and then you have

00:16:13,100 --> 00:16:17,330
frames the building blocks of it all

00:16:14,690 --> 00:16:20,180
frames are the data payloads in their

00:16:17,330 --> 00:16:22,580
binary and so we have frames frames make

00:16:20,180 --> 00:16:25,460
up messages messages are transformed

00:16:22,580 --> 00:16:28,520
within streams and a connection can have

00:16:25,460 --> 00:16:30,980
multiple streams as I said this is the

00:16:28,520 --> 00:16:33,650
building block which is a frame each

00:16:30,980 --> 00:16:36,470
frame has a type such as I am a header

00:16:33,650 --> 00:16:40,010
frame or I am a data frame or I am a

00:16:36,470 --> 00:16:42,500
push frame all frames share an common

00:16:40,010 --> 00:16:44,450
nine byte header field which is this so

00:16:42,500 --> 00:16:46,400
regardless of the frame type they'll all

00:16:44,450 --> 00:16:47,570
have this same header field and the

00:16:46,400 --> 00:16:50,300
header fields really important because

00:16:47,570 --> 00:16:52,760
it declares its type obviously saying

00:16:50,300 --> 00:16:54,260
I'm a data frame its length in bytes

00:16:52,760 --> 00:16:58,130
because remember I said it's a binary

00:16:54,260 --> 00:16:59,900
format and the stream it belongs to

00:16:58,130 --> 00:17:02,950
so a stream identifier and maybe it's

00:16:59,900 --> 00:17:05,839
priority which lives inside the flags

00:17:02,950 --> 00:17:10,130
and so the date within the frame is

00:17:05,839 --> 00:17:11,870
actually represented as binary and and

00:17:10,130 --> 00:17:14,360
this is really important because it

00:17:11,870 --> 00:17:17,900
allows a frame to declare its length say

00:17:14,360 --> 00:17:21,020
I am 20 bytes long and this is the

00:17:17,900 --> 00:17:22,880
reason why we no longer have to open TCP

00:17:21,020 --> 00:17:25,520
get more TCP connections because that

00:17:22,880 --> 00:17:28,130
means that I can interleave frames on

00:17:25,520 --> 00:17:30,320
the same connection if the cloud the

00:17:28,130 --> 00:17:32,570
client say the browser is consuming that

00:17:30,320 --> 00:17:34,970
connection and it doesn't care about say

00:17:32,570 --> 00:17:36,590
stream for it looks at the length of

00:17:34,970 --> 00:17:38,270
this and it can just skip forward that

00:17:36,590 --> 00:17:40,130
many bytes in the buffer and not care

00:17:38,270 --> 00:17:42,080
about them and it can interleave frames

00:17:40,130 --> 00:17:44,120
put them in their own buffers and we

00:17:42,080 --> 00:17:45,620
stitch them back on the other side this

00:17:44,120 --> 00:17:46,400
is the most fundamental piece of

00:17:45,620 --> 00:17:49,490
information about

00:17:46,400 --> 00:17:51,560
a ch2 this is what allows it to overcome

00:17:49,490 --> 00:17:54,950
the latency problems by interleaving

00:17:51,560 --> 00:17:57,230
binary denta frames on the wire the only

00:17:54,950 --> 00:18:00,140
downside to it being binary is that we

00:17:57,230 --> 00:18:02,420
can no longer inspect HTTP requests or

00:18:00,140 --> 00:18:04,100
responses on the wire so you getting

00:18:02,420 --> 00:18:06,200
used to being out in your dev tools to

00:18:04,100 --> 00:18:06,800
be able to see the text of the raw

00:18:06,200 --> 00:18:08,810
response

00:18:06,800 --> 00:18:10,130
unfortunately that is going but there's

00:18:08,810 --> 00:18:11,000
some ways to get around that I'll

00:18:10,130 --> 00:18:13,580
explain later

00:18:11,000 --> 00:18:16,580
so here we can see how closely it maps

00:18:13,580 --> 00:18:18,740
from an h1 request to h2 so we'll have

00:18:16,580 --> 00:18:20,540
the header area and HTTP one that

00:18:18,740 --> 00:18:22,430
probably will make up a couple of dead

00:18:20,540 --> 00:18:24,200
of frames and then the payload which

00:18:22,430 --> 00:18:26,840
will probably make up a couple of data

00:18:24,200 --> 00:18:30,350
frames so all communication is now

00:18:26,840 --> 00:18:33,320
performed on a single TCP connection and

00:18:30,350 --> 00:18:35,480
this is why it's so so much improvement

00:18:33,320 --> 00:18:37,840
over latency and here we can see two

00:18:35,480 --> 00:18:40,460
frames interleaved with each other

00:18:37,840 --> 00:18:42,230
different streams on the single

00:18:40,460 --> 00:18:44,840
connections whilst this is going on

00:18:42,230 --> 00:18:47,510
I can send head of frames requests for

00:18:44,840 --> 00:18:51,520
stream 6 and c5 whilst I'm still getting

00:18:47,510 --> 00:18:54,620
data streams to team 3 between 4 and

00:18:51,520 --> 00:18:56,960
this is true bi-directional multiplexing

00:18:54,620 --> 00:19:00,520
happening right here this animation is

00:18:56,960 --> 00:19:00,520
also extremely long sorry

00:19:00,540 --> 00:19:09,040
let's just wait for it to go cool so

00:19:06,880 --> 00:19:10,960
over the years because of the

00:19:09,040 --> 00:19:15,070
inefficiencies of h1 browsers have had

00:19:10,960 --> 00:19:17,770
to overcome and create their own

00:19:15,070 --> 00:19:19,420
optimizations of how they optimize the

00:19:17,770 --> 00:19:21,660
requests that they send whilst they're

00:19:19,420 --> 00:19:23,590
rendering a page and they do this by

00:19:21,660 --> 00:19:25,900
resource prior a critical resource

00:19:23,590 --> 00:19:28,000
prioritization most browsers will have

00:19:25,900 --> 00:19:30,400
this baked into them and so as your

00:19:28,000 --> 00:19:33,730
browser pauses the HTML document it will

00:19:30,400 --> 00:19:35,290
find the resources and when it finds the

00:19:33,730 --> 00:19:37,300
resources it's going to push these into

00:19:35,290 --> 00:19:40,090
a queue essentially before it actually

00:19:37,300 --> 00:19:41,560
sends them off on the network now most

00:19:40,090 --> 00:19:44,740
browsers are clever enough that even if

00:19:41,560 --> 00:19:46,630
they found image one first before they

00:19:44,740 --> 00:19:49,180
found main dot CSS in the ordering of

00:19:46,630 --> 00:19:51,670
the source they'll prioritize the CSS

00:19:49,180 --> 00:19:53,290
file higher because they know they need

00:19:51,670 --> 00:19:55,210
that to be able to paint to the screen

00:19:53,290 --> 00:19:57,640
so actually what they're doing here is

00:19:55,210 --> 00:19:59,950
they're creating artificial latency that

00:19:57,640 --> 00:20:01,690
they're purposefully delaying the

00:19:59,950 --> 00:20:03,670
request even though they sent it and I

00:20:01,690 --> 00:20:04,930
kept on going on about how latency is so

00:20:03,670 --> 00:20:08,890
important and they're actually on

00:20:04,930 --> 00:20:11,650
purpose creating prioritization here now

00:20:08,890 --> 00:20:13,270
with h2 because it doesn't matter the

00:20:11,650 --> 00:20:14,620
order that we send them in and we - on a

00:20:13,270 --> 00:20:17,080
single connection I can just fire off

00:20:14,620 --> 00:20:19,240
the request as I find them which is

00:20:17,080 --> 00:20:20,950
amazing so we've already reduced that

00:20:19,240 --> 00:20:24,100
artificial latency that results

00:20:20,950 --> 00:20:25,720
prioritization incurs but the eagle-eyed

00:20:24,100 --> 00:20:28,270
in the audience will see though ok but

00:20:25,720 --> 00:20:30,010
what if I did still send image one first

00:20:28,270 --> 00:20:33,670
doesn't that mean that I'm going to get

00:20:30,010 --> 00:20:35,950
image one back first as well um and so

00:20:33,670 --> 00:20:39,040
so obviously it's faster but this is

00:20:35,950 --> 00:20:40,540
where h2 dependency tree weighting and

00:20:39,040 --> 00:20:42,160
prioritization comes in and this is

00:20:40,540 --> 00:20:45,070
actually part of the specification so

00:20:42,160 --> 00:20:48,340
now as the browser is finding those

00:20:45,070 --> 00:20:52,090
files it will apply a weighting number

00:20:48,340 --> 00:20:55,120
which starts off with 16 this base64 and

00:20:52,090 --> 00:20:56,980
then it can increment that and so here

00:20:55,120 --> 00:20:59,320
we concede that main dot CSS has got the

00:20:56,980 --> 00:21:02,230
highest weight and inside main dot CSS

00:20:59,320 --> 00:21:05,800
when we got it back we found icon lit

00:21:02,230 --> 00:21:08,080
CSS and so even if this is passing like

00:21:05,800 --> 00:21:10,120
we've only got half of it we can tell

00:21:08,080 --> 00:21:12,040
via a dependency tree that this is

00:21:10,120 --> 00:21:13,420
linked to this so you shouldn't send me

00:21:12,040 --> 00:21:15,640
any frames for that until I

00:21:13,420 --> 00:21:17,650
got all the frames for that and what's

00:21:15,640 --> 00:21:20,200
even more clever about this is that it's

00:21:17,650 --> 00:21:22,570
truly dynamic so if you imagine that we

00:21:20,200 --> 00:21:24,250
have a tab for google.com open and

00:21:22,570 --> 00:21:26,380
there's a h2 connection for that the

00:21:24,250 --> 00:21:29,740
user opens another tab for google.com

00:21:26,380 --> 00:21:31,300
and focuses on that tab firstly the

00:21:29,740 --> 00:21:33,400
great thing about h2 is we can we can

00:21:31,300 --> 00:21:35,650
share the same connection but suddenly

00:21:33,400 --> 00:21:37,240
all the resources for that tab become

00:21:35,650 --> 00:21:39,550
much more important than the ones that

00:21:37,240 --> 00:21:42,100
still might be on the wire here so in

00:21:39,550 --> 00:21:44,890
real time we can change the stream

00:21:42,100 --> 00:21:47,140
weighting via frames and tell the server

00:21:44,890 --> 00:21:49,060
actually now these ones have become much

00:21:47,140 --> 00:21:50,800
more important another use case you

00:21:49,060 --> 00:21:52,630
could imagine even on your website a

00:21:50,800 --> 00:21:54,610
user hovers over a button they click on

00:21:52,630 --> 00:21:56,380
the button that opens up a carousel and

00:21:54,610 --> 00:21:59,050
the carousel is a big hero image

00:21:56,380 --> 00:22:00,550
suddenly that hero image its priority

00:21:59,050 --> 00:22:02,230
becomes much more important than any

00:22:00,550 --> 00:22:04,720
other data and we can communicate to

00:22:02,230 --> 00:22:07,540
this to the server via prioritization

00:22:04,720 --> 00:22:09,340
this is extremely extremely important no

00:22:07,540 --> 00:22:12,250
longer do we have to try and trick the

00:22:09,340 --> 00:22:14,770
browser and hide resources from the pre

00:22:12,250 --> 00:22:19,110
parser because we can actually get there

00:22:14,770 --> 00:22:22,900
the browser to do this work for us um in

00:22:19,110 --> 00:22:25,480
introducing HP 1.1 so 0.9 didn't have it

00:22:22,900 --> 00:22:28,810
we allowed us to start adding metadata

00:22:25,480 --> 00:22:30,910
to our requests and responses and via

00:22:28,810 --> 00:22:33,040
headers and we started to have a wealth

00:22:30,910 --> 00:22:35,440
of metadata and because HTTP is

00:22:33,040 --> 00:22:37,420
stateless there is no state maintained

00:22:35,440 --> 00:22:39,850
unfortunately we have to send this data

00:22:37,420 --> 00:22:41,740
especially things like cookies on every

00:22:39,850 --> 00:22:43,600
single request even if the servers

00:22:41,740 --> 00:22:46,300
already seen that cookie and this is

00:22:43,600 --> 00:22:48,700
exactly how login systems authentication

00:22:46,300 --> 00:22:51,190
works on on most log on most websites

00:22:48,700 --> 00:22:53,140
and so I have to always send this cookie

00:22:51,190 --> 00:22:55,630
and so to address this in the h2

00:22:53,140 --> 00:22:57,870
specification they invented hate pack

00:22:55,630 --> 00:23:01,720
which is a compression algorithm

00:22:57,870 --> 00:23:03,790
specifically designed for HTTP now there

00:23:01,720 --> 00:23:05,710
could be a whole talk just about hates

00:23:03,790 --> 00:23:07,570
pack and because it's really really

00:23:05,710 --> 00:23:09,700
intelligent but I've just explained to

00:23:07,570 --> 00:23:11,710
you basically how the basics work so the

00:23:09,700 --> 00:23:14,590
first thing is that the client and the

00:23:11,710 --> 00:23:16,360
server maintain a static lookup table so

00:23:14,590 --> 00:23:17,770
just like a database table on either

00:23:16,360 --> 00:23:19,930
side of the connection on the client in

00:23:17,770 --> 00:23:22,660
the server and in the specification

00:23:19,930 --> 00:23:24,760
there is detailed the most commonly

00:23:22,660 --> 00:23:26,980
occurring key value pair rings for

00:23:24,760 --> 00:23:29,650
headers and the assigned a

00:23:26,980 --> 00:23:32,350
ID number and so whenever you need to

00:23:29,650 --> 00:23:34,210
send that value you actually don't need

00:23:32,350 --> 00:23:36,220
to send the key or the value at all you

00:23:34,210 --> 00:23:37,870
just send the ID because the server will

00:23:36,220 --> 00:23:40,630
know exactly that but the really

00:23:37,870 --> 00:23:42,730
intelligent bit is for the duration of

00:23:40,630 --> 00:23:44,440
that h2 connection for that single

00:23:42,730 --> 00:23:47,020
connection both the client and the

00:23:44,440 --> 00:23:49,510
server maintain a dynamic lookup table

00:23:47,020 --> 00:23:51,700
so the first time I send this cookie

00:23:49,510 --> 00:23:54,760
header on the on the server it will be

00:23:51,700 --> 00:23:57,340
assigned a key of 64 the next time I

00:23:54,760 --> 00:24:00,190
want to send that same thing I only need

00:23:57,340 --> 00:24:01,870
to send the key of 64 along with those

00:24:00,190 --> 00:24:03,820
because the server's already seen this

00:24:01,870 --> 00:24:06,100
now the problem here is this is actually

00:24:03,820 --> 00:24:07,330
maintaining state between a client and a

00:24:06,100 --> 00:24:09,309
server and that's why things like see

00:24:07,330 --> 00:24:11,500
the ends have had quite a lot of trouble

00:24:09,309 --> 00:24:13,540
with implementing h2 and then to send a

00:24:11,500 --> 00:24:15,490
new one I just send that and it will get

00:24:13,540 --> 00:24:17,169
assigned that and then all of this data

00:24:15,490 --> 00:24:19,480
is then Huffman encoded which is the

00:24:17,169 --> 00:24:21,460
same algorithm that the compression

00:24:19,480 --> 00:24:23,320
algorithm that gzip uses to reduce that

00:24:21,460 --> 00:24:25,660
footprint even more it's incredibly

00:24:23,320 --> 00:24:27,040
incredibly intelligent please if you're

00:24:25,660 --> 00:24:29,250
interested in to that kind of thing go

00:24:27,040 --> 00:24:31,840
and check out the H pack spec and

00:24:29,250 --> 00:24:33,790
finally before moving on the final

00:24:31,840 --> 00:24:37,240
feature I want it to discuss about h2 is

00:24:33,790 --> 00:24:40,660
server-side resource fishing as we saw

00:24:37,240 --> 00:24:43,330
earlier I have to send a HT HTML request

00:24:40,660 --> 00:24:46,210
my get request to my index file wait for

00:24:43,330 --> 00:24:48,160
the server to process that I then get

00:24:46,210 --> 00:24:50,320
that back I start pausing the document I

00:24:48,160 --> 00:24:54,160
find the CSS file and then I send a

00:24:50,320 --> 00:24:55,900
request for that now that's extremely

00:24:54,160 --> 00:24:57,400
inefficient because I've had to wait for

00:24:55,900 --> 00:24:58,809
the server to process that even though

00:24:57,400 --> 00:25:02,230
as application designers and developers

00:24:58,809 --> 00:25:04,090
we know that the next thing that the

00:25:02,230 --> 00:25:06,640
browser is going to request because of

00:25:04,090 --> 00:25:09,220
resource privatization is main CSS and I

00:25:06,640 --> 00:25:10,809
always know that when index dot HTML is

00:25:09,220 --> 00:25:12,580
request the next thing they're going to

00:25:10,809 --> 00:25:14,440
request is that so what if we could

00:25:12,580 --> 00:25:17,200
Intel into intelligent Lee tell the

00:25:14,440 --> 00:25:19,750
client that so with h2 I make that

00:25:17,200 --> 00:25:22,660
request whilst I'm processing that may

00:25:19,750 --> 00:25:24,790
be that dynamic file I can push the the

00:25:22,660 --> 00:25:27,160
resource the data for that main that CSS

00:25:24,790 --> 00:25:29,530
file even before the clients even got

00:25:27,160 --> 00:25:30,970
any of the index file and before it

00:25:29,530 --> 00:25:33,400
would normally pause and find it so

00:25:30,970 --> 00:25:34,780
we've dramatically reduced the latency

00:25:33,400 --> 00:25:36,790
that it might take for that normal

00:25:34,780 --> 00:25:38,020
round-trip now the eagle-eyed and the

00:25:36,790 --> 00:25:39,669
audience would notice that the push

00:25:38,020 --> 00:25:40,540
promise frame so this is a new frame

00:25:39,669 --> 00:25:42,310
type just like

00:25:40,540 --> 00:25:45,280
the header and data frame the post

00:25:42,310 --> 00:25:48,160
promise frame must be spent sent as part

00:25:45,280 --> 00:25:50,890
the specification before any data frame

00:25:48,160 --> 00:25:52,330
of the initial resource and why is this

00:25:50,890 --> 00:25:54,370
because you might get into a race

00:25:52,330 --> 00:25:57,040
condition that if I had sent the data

00:25:54,370 --> 00:25:58,780
frame first the client might be so fast

00:25:57,040 --> 00:26:01,060
that it would then find the CSS file and

00:25:58,780 --> 00:26:03,070
then you're actually sending more of the

00:26:01,060 --> 00:26:05,200
bytes too many bytes as possible so as

00:26:03,070 --> 00:26:07,210
part the spec push promised frame must

00:26:05,200 --> 00:26:11,080
be sent first before any data frames

00:26:07,210 --> 00:26:12,190
with that file now the even more keen in

00:26:11,080 --> 00:26:15,640
the audience would have noticed that

00:26:12,190 --> 00:26:18,310
what if the client already had that main

00:26:15,640 --> 00:26:20,500
dot CSS file in its cache so we now have

00:26:18,310 --> 00:26:22,480
a new frame type called reset stream so

00:26:20,500 --> 00:26:24,190
this is the client saying nope okay

00:26:22,480 --> 00:26:25,570
thanks for that I don't need any of the

00:26:24,190 --> 00:26:27,760
data frames for that stream because I

00:26:25,570 --> 00:26:30,460
already have it in my cache so that's

00:26:27,760 --> 00:26:32,020
even more efficient and we can use reset

00:26:30,460 --> 00:26:35,800
stream quite a lot if say for instance

00:26:32,020 --> 00:26:37,720
the cache headers are already still not

00:26:35,800 --> 00:26:39,940
there not stale then you could reset

00:26:37,720 --> 00:26:41,830
may-maybe Ajax requests during the

00:26:39,940 --> 00:26:44,440
connections lifetime and this is

00:26:41,830 --> 00:26:46,810
incredibly powerful contrast that so

00:26:44,440 --> 00:26:50,020
much this is truly bi-directional

00:26:46,810 --> 00:26:51,510
multiplexing of 82 connections in full

00:26:50,020 --> 00:26:55,810
effect right here

00:26:51,510 --> 00:26:58,810
so we've learnt the building blocks of

00:26:55,810 --> 00:27:01,390
h2 which are streams and frames and

00:26:58,810 --> 00:27:04,120
binary data late data framing resource

00:27:01,390 --> 00:27:07,050
prioritization header compression via H

00:27:04,120 --> 00:27:10,540
pack and server-side resource pushing

00:27:07,050 --> 00:27:11,950
now hopefully that wasn't too much

00:27:10,540 --> 00:27:14,500
information for you to take in and I

00:27:11,950 --> 00:27:17,470
promise you that was the the most techy

00:27:14,500 --> 00:27:20,170
crazy bit of it all of this talk but the

00:27:17,470 --> 00:27:22,240
more I I've what I personally feel about

00:27:20,170 --> 00:27:23,890
this that the more I've learnt whilst

00:27:22,240 --> 00:27:26,140
working with h2 and reading the specs

00:27:23,890 --> 00:27:27,670
the more I've become to be amazed by its

00:27:26,140 --> 00:27:30,280
design and it is truly incredible

00:27:27,670 --> 00:27:31,300
compared to h1 and they've done some

00:27:30,280 --> 00:27:33,220
amazing work here and I've only

00:27:31,300 --> 00:27:35,800
literally just skimmed the surface in

00:27:33,220 --> 00:27:38,500
it's a very large specification but I do

00:27:35,800 --> 00:27:40,570
urge you to go in and have a check and

00:27:38,500 --> 00:27:42,220
read it a bit more but hopefully I've

00:27:40,570 --> 00:27:44,860
given you enough there to take home and

00:27:42,220 --> 00:27:45,790
apply to your day to day work so the

00:27:44,860 --> 00:27:47,470
most processed thing I'm going to show

00:27:45,790 --> 00:27:49,900
you today is the current browser support

00:27:47,470 --> 00:27:53,110
landscape we've got a global average of

00:27:49,900 --> 00:27:53,710
17 here in the UK we've actually got 77

00:27:53,110 --> 00:27:55,419
which is

00:27:53,710 --> 00:27:58,179
amazing Safari finally jumped on the

00:27:55,419 --> 00:28:00,100
bandwagon at nine and that brought up

00:27:58,179 --> 00:28:01,929
the stats massively and this is this

00:28:00,100 --> 00:28:03,159
alone was enough for us at the FT to

00:28:01,929 --> 00:28:06,399
know that this it was worthwhile

00:28:03,159 --> 00:28:09,240
investing in our interests who here is

00:28:06,399 --> 00:28:13,270
using has deployed h2 into production

00:28:09,240 --> 00:28:15,520
one person great and two awesome

00:28:13,270 --> 00:28:18,370
that's good to see but you know that's

00:28:15,520 --> 00:28:21,309
hopefully why I'm here to try and trying

00:28:18,370 --> 00:28:24,630
to to get you all to on the bandwagon a

00:28:21,309 --> 00:28:27,299
much debated issue feature of h2 was its

00:28:24,630 --> 00:28:30,520
requirement for TLS that you have to

00:28:27,299 --> 00:28:32,409
serve be serving a website over HTTP and

00:28:30,520 --> 00:28:33,909
probably that might be a reason why most

00:28:32,409 --> 00:28:35,380
of you in the audience aren't using it

00:28:33,909 --> 00:28:36,760
yet and the original speedy

00:28:35,380 --> 00:28:38,919
specification it actually was a

00:28:36,760 --> 00:28:41,169
requirement but they dropped that in the

00:28:38,919 --> 00:28:43,149
H Spears working group and it no longer

00:28:41,169 --> 00:28:45,760
is but and so it's got they've got a lot

00:28:43,149 --> 00:28:47,289
of stick for that and I actually agree

00:28:45,760 --> 00:28:48,580
with them one because I think we should

00:28:47,289 --> 00:28:51,580
be making the world a more secure place

00:28:48,580 --> 00:28:53,860
but to in the speedy experiments they

00:28:51,580 --> 00:28:55,690
found that many of the old middle boxes

00:28:53,860 --> 00:28:57,340
and proxies so the intent the Internet's

00:28:55,690 --> 00:28:59,799
actually made up of lots of cables and

00:28:57,340 --> 00:29:03,070
boxes in they get eaten by sharks under

00:28:59,799 --> 00:29:05,350
the ground under the sea and if those

00:29:03,070 --> 00:29:06,850
proxies didn't understand the packets

00:29:05,350 --> 00:29:08,559
that they were routing they would drop

00:29:06,850 --> 00:29:10,419
them so in the speedy experiments they

00:29:08,559 --> 00:29:12,970
saw between ten and fifteen packet loss

00:29:10,419 --> 00:29:14,710
for all connections and that's why they

00:29:12,970 --> 00:29:17,409
enforced here less is by correctly

00:29:14,710 --> 00:29:19,270
secure tunnel you're ensuring that there

00:29:17,409 --> 00:29:22,179
are no middle boxes can be inspecting

00:29:19,270 --> 00:29:24,970
the packets who hears heard of let's

00:29:22,179 --> 00:29:27,220
encrypt awesome that's great

00:29:24,970 --> 00:29:29,679
and so you have no reason for your site

00:29:27,220 --> 00:29:32,770
not to be delivered over HTTPS now where

00:29:29,679 --> 00:29:34,330
there is a free open typical 480 that

00:29:32,770 --> 00:29:36,490
makes it so easy for issuing and

00:29:34,330 --> 00:29:37,779
reassigning certs ilio be really good if

00:29:36,490 --> 00:29:39,549
you get someone to come and talk about

00:29:37,779 --> 00:29:41,830
let's encrypt because I think more

00:29:39,549 --> 00:29:44,110
people need to know about it so once

00:29:41,830 --> 00:29:46,390
you've got Taylor set up you start

00:29:44,110 --> 00:29:49,149
observing your own traffic this when we

00:29:46,390 --> 00:29:51,100
start a directory it's obviously gonna a

00:29:49,149 --> 00:29:52,240
lot more was what our stats were like I

00:29:51,100 --> 00:29:54,100
said we started to talk to our

00:29:52,240 --> 00:29:57,070
stakeholders explaining the benefits of

00:29:54,100 --> 00:30:00,880
HTTPS and h2 and what might happen to

00:29:57,070 --> 00:30:02,320
those other users the server support is

00:30:00,880 --> 00:30:04,090
looking really good

00:30:02,320 --> 00:30:06,429
most of you probably serve your websites

00:30:04,090 --> 00:30:07,240
using nginx or Apache they both support

00:30:06,429 --> 00:30:09,130
it now

00:30:07,240 --> 00:30:10,960
this is actually about to change I need

00:30:09,130 --> 00:30:13,360
to update that jetty if you're using

00:30:10,960 --> 00:30:15,299
Java when I is for Windows the support

00:30:13,360 --> 00:30:17,770
is all there for the actual servers

00:30:15,299 --> 00:30:19,299
sadly the CDN landscapes not looking

00:30:17,770 --> 00:30:23,260
that great but it's getting better

00:30:19,299 --> 00:30:25,029
Akamai supports it CloudFlare no no sign

00:30:23,260 --> 00:30:26,169
from Aida West cloud front yet fastly

00:30:25,029 --> 00:30:27,520
I've done it they've actually got the

00:30:26,169 --> 00:30:29,649
best implementation at the moment and

00:30:27,520 --> 00:30:32,440
I'm not being paid to say that even

00:30:29,649 --> 00:30:34,510
though I am a customer there it's just

00:30:32,440 --> 00:30:37,059
that they've chosen the best h2 server

00:30:34,510 --> 00:30:40,240
something called h2o putting Akamai's

00:30:37,059 --> 00:30:42,100
just about to release push but I heard

00:30:40,240 --> 00:30:45,130
we all like to deploy our software in

00:30:42,100 --> 00:30:51,159
the cloud these days then it white rains

00:30:45,130 --> 00:30:53,320
a lot up there well the service

00:30:51,159 --> 00:30:54,789
providers their internal networking

00:30:53,320 --> 00:30:56,169
stats are very bad Google App Engine and

00:30:54,789 --> 00:30:56,890
the only people that have native support

00:30:56,169 --> 00:30:59,230
for it

00:30:56,890 --> 00:31:01,779
AWS have not mentioned anything on there

00:30:59,230 --> 00:31:03,220
a lbiza because Heroku is on a duress

00:31:01,779 --> 00:31:06,130
we're not going to see anything there

00:31:03,220 --> 00:31:07,720
anytime soon I don't think um so that's

00:31:06,130 --> 00:31:09,190
great you've upgraded your server

00:31:07,720 --> 00:31:09,789
software maybe for some of you that's as

00:31:09,190 --> 00:31:12,880
simple as that

00:31:09,789 --> 00:31:14,529
how can I start using this and their

00:31:12,880 --> 00:31:16,690
approach that we first took at the FT is

00:31:14,529 --> 00:31:18,610
- it's probably easier you probably

00:31:16,690 --> 00:31:20,380
already serve your static assets your

00:31:18,610 --> 00:31:22,480
images of your CSS of something else

00:31:20,380 --> 00:31:24,909
other than your application server so

00:31:22,480 --> 00:31:26,529
why not just put a CDN or a proxy in

00:31:24,909 --> 00:31:27,730
front of those and you don't need to

00:31:26,529 --> 00:31:29,500
worry about that because that's going to

00:31:27,730 --> 00:31:34,270
probably take a lot longer to upgrade

00:31:29,500 --> 00:31:36,640
your origin or stick a proxy in front of

00:31:34,270 --> 00:31:38,500
your origin that can speak h2 this is I

00:31:36,640 --> 00:31:40,270
know a lot of businesses have going for

00:31:38,500 --> 00:31:41,860
this approach this is in fact how fastly

00:31:40,270 --> 00:31:43,450
did it as part of their CDN work and

00:31:41,860 --> 00:31:45,970
then finally hopefully in a couple of

00:31:43,450 --> 00:31:48,580
years we can just everything all of our

00:31:45,970 --> 00:31:51,279
servers will be speaking at natively so

00:31:48,580 --> 00:31:53,260
once your h2 capable it's time to start

00:31:51,279 --> 00:31:55,510
considering how you're going to optimize

00:31:53,260 --> 00:31:58,149
your resources and on what you want to

00:31:55,510 --> 00:32:00,070
push so here's your typical critical

00:31:58,149 --> 00:32:02,830
rendering path we have to request the

00:32:00,070 --> 00:32:04,899
HTML file we then pass it we get the CSS

00:32:02,830 --> 00:32:06,370
we have to block wait for that then we

00:32:04,899 --> 00:32:08,289
get our fonts we have to block waiting

00:32:06,370 --> 00:32:10,539
for that so obviously to me the most

00:32:08,289 --> 00:32:12,610
important things should that you should

00:32:10,539 --> 00:32:15,100
be pushing are your critical resources

00:32:12,610 --> 00:32:17,350
and look already the impact that has on

00:32:15,100 --> 00:32:19,020
the timeline the amount of latency that

00:32:17,350 --> 00:32:21,160
we can be reducing

00:32:19,020 --> 00:32:24,640
there's been a lot of debate within the

00:32:21,160 --> 00:32:27,700
w3c of how as developers we declare the

00:32:24,640 --> 00:32:29,440
resources that we want to push so the

00:32:27,700 --> 00:32:31,570
most common way of doing this now is via

00:32:29,440 --> 00:32:34,060
the link header and using the rel

00:32:31,570 --> 00:32:36,340
preload attribute so this is me saying

00:32:34,060 --> 00:32:39,490
that style dot CSS I want you to push

00:32:36,340 --> 00:32:41,890
this and Apache nginx and h2o all taken

00:32:39,490 --> 00:32:44,290
this as their implementation of pushing

00:32:41,890 --> 00:32:46,300
resources you can also do that by an

00:32:44,290 --> 00:32:48,040
element but that's probably far too late

00:32:46,300 --> 00:32:51,220
the client would have already found that

00:32:48,040 --> 00:32:53,770
so you should do it as a header myself

00:32:51,220 --> 00:32:57,610
and people like your voice actually who

00:32:53,770 --> 00:32:59,560
he wrote preload think that actually we

00:32:57,610 --> 00:33:00,970
need our own semantics because the

00:32:59,560 --> 00:33:03,370
semantics are preload are slightly

00:33:00,970 --> 00:33:05,460
different to what you want to push so

00:33:03,370 --> 00:33:09,610
we're pushing for a rel push

00:33:05,460 --> 00:33:11,290
specification mmm so now you you've got

00:33:09,610 --> 00:33:13,810
it working you want to start seeing if

00:33:11,290 --> 00:33:15,520
it's actually doing what it's won the

00:33:13,810 --> 00:33:18,370
web page test which is the toolbox of

00:33:15,520 --> 00:33:19,690
most performance engineers now has

00:33:18,370 --> 00:33:21,310
native support for it you can see

00:33:19,690 --> 00:33:23,590
multiplex connections within the

00:33:21,310 --> 00:33:25,600
connection view you can also for the

00:33:23,590 --> 00:33:28,810
Firefox agents on web page test you can

00:33:25,600 --> 00:33:30,820
see pushed resources it took me about

00:33:28,810 --> 00:33:33,790
three months to realize that in chrome

00:33:30,820 --> 00:33:35,280
you have to right-click and enable with

00:33:33,790 --> 00:33:37,480
the protocol and the network panel

00:33:35,280 --> 00:33:39,070
literally took me three months and

00:33:37,480 --> 00:33:40,570
that's the only way in chrome that you

00:33:39,070 --> 00:33:42,400
can tell whether or not a connection is

00:33:40,570 --> 00:33:44,980
so here you can see our serving our

00:33:42,400 --> 00:33:47,020
document over h1 all the resources over

00:33:44,980 --> 00:33:48,700
h2 Firefox

00:33:47,020 --> 00:33:49,510
put it where I would have thought it

00:33:48,700 --> 00:33:52,420
would have been in the network

00:33:49,510 --> 00:33:53,770
connection in the headers and I

00:33:52,420 --> 00:33:55,930
mentioned earlier because it's binding

00:33:53,770 --> 00:33:58,720
which for a binary framing we can't we

00:33:55,930 --> 00:34:01,090
can no longer expect the actual response

00:33:58,720 --> 00:34:02,800
body and so unfortunately we're going to

00:34:01,090 --> 00:34:04,480
have to start becoming more friends with

00:34:02,800 --> 00:34:05,920
tools like why sharks as front-end

00:34:04,480 --> 00:34:08,230
developers and I this is quite scary

00:34:05,920 --> 00:34:10,030
when I say this to a lot of people I was

00:34:08,230 --> 00:34:12,130
as well this is a really good blog post

00:34:10,030 --> 00:34:15,610
explaining how to set up wireshark

00:34:12,130 --> 00:34:17,050
properly and use the TLS encryption but

00:34:15,610 --> 00:34:19,600
this is great here you can see header

00:34:17,050 --> 00:34:21,850
frames on the wire and actually the data

00:34:19,600 --> 00:34:24,190
of that so it's decrypted the binary and

00:34:21,850 --> 00:34:26,320
the TLS certificate and now I can

00:34:24,190 --> 00:34:28,240
actually see the data so the only way to

00:34:26,320 --> 00:34:30,370
do that in dev tools at the moment is in

00:34:28,240 --> 00:34:32,710
chrome they have in chrome net internals

00:34:30,370 --> 00:34:34,899
you can actually inspect the

00:34:32,710 --> 00:34:36,550
ht2 session and here the headers and it

00:34:34,899 --> 00:34:37,899
needs a lot of work especially as more

00:34:36,550 --> 00:34:40,720
people are going to start to having to

00:34:37,899 --> 00:34:44,470
use net internals they it needs so much

00:34:40,720 --> 00:34:45,609
love and if you've implemented h2 and

00:34:44,470 --> 00:34:47,560
you want to know how much of the

00:34:45,609 --> 00:34:49,000
specification your server or CDN is

00:34:47,560 --> 00:34:51,609
living up to it there's a really good

00:34:49,000 --> 00:34:54,070
test suite h2 spec on github that you

00:34:51,609 --> 00:34:56,649
can run against your deployment and see

00:34:54,070 --> 00:35:00,670
whether or not good and how much of the

00:34:56,649 --> 00:35:01,990
spec you've implemented so far I'm sorry

00:35:00,670 --> 00:35:04,060
for the whirlwind tour at the end there

00:35:01,990 --> 00:35:07,210
I've already run over time I told Lily

00:35:04,060 --> 00:35:09,190
I'd only be 30 minutes I'm already 35 so

00:35:07,210 --> 00:35:12,180
hopefully in that section you've learnt

00:35:09,190 --> 00:35:13,750
the browser support the TLS requirement

00:35:12,180 --> 00:35:15,550
considerations when you're thinking

00:35:13,750 --> 00:35:17,650
about choosing your h2 server what you

00:35:15,550 --> 00:35:20,260
should be pushing how you can push it

00:35:17,650 --> 00:35:24,609
and the torque current tooling landscape

00:35:20,260 --> 00:35:27,580
around it so to end with I just whilst

00:35:24,609 --> 00:35:29,349
HTTP here is here a lot of you aren't

00:35:27,580 --> 00:35:30,970
using it yet but there's already some

00:35:29,349 --> 00:35:32,530
problems with it there I think that

00:35:30,970 --> 00:35:35,770
people are starting to iron out and it's

00:35:32,530 --> 00:35:38,109
only by us trying and feeding back to

00:35:35,770 --> 00:35:40,109
the working group into the browser

00:35:38,109 --> 00:35:42,040
vendors will this become better and so

00:35:40,109 --> 00:35:43,930
one of the biggest problems that you

00:35:42,040 --> 00:35:45,490
might have noticed with push is that

00:35:43,930 --> 00:35:48,250
there's it still can be extremely

00:35:45,490 --> 00:35:50,050
efficient that I'm sending resources

00:35:48,250 --> 00:35:51,700
down to the browser even though it might

00:35:50,050 --> 00:35:56,140
actually already be in the browser's

00:35:51,700 --> 00:35:59,020
cache so what is his name I've forgotten

00:35:56,140 --> 00:36:01,330
it's yeah yeah Kenji who wrote h2o

00:35:59,020 --> 00:36:02,710
server has come up with the cash digest

00:36:01,330 --> 00:36:04,930
specification and this is going to be a

00:36:02,710 --> 00:36:07,540
new frame type and this is a way of the

00:36:04,930 --> 00:36:09,820
client communicating to the server what

00:36:07,540 --> 00:36:11,740
resources it hat already has in the

00:36:09,820 --> 00:36:14,470
cache for that host name and that's

00:36:11,740 --> 00:36:17,080
extremely powerful not just for h2 think

00:36:14,470 --> 00:36:19,630
about how CDNs can use this it's amazing

00:36:17,080 --> 00:36:21,369
so it basically used an algorithm to

00:36:19,630 --> 00:36:23,619
compress down all of those values into a

00:36:21,369 --> 00:36:25,960
single digest and sends that up in a

00:36:23,619 --> 00:36:28,960
single frame on the h2 connection it's

00:36:25,960 --> 00:36:31,030
very powerful and I talked a lot about

00:36:28,960 --> 00:36:33,089
head-of-line blocking earlier and whilst

00:36:31,030 --> 00:36:35,680
we've eliminated head-of-line blocking

00:36:33,089 --> 00:36:37,690
we've only done that at the at the

00:36:35,680 --> 00:36:40,300
request layer actually all we've done is

00:36:37,690 --> 00:36:44,050
pushed down the inefficiencies to the

00:36:40,300 --> 00:36:45,360
TCP layer and so a lot of deployments

00:36:44,050 --> 00:36:47,040
especially

00:36:45,360 --> 00:36:48,840
friends of mine at fastly actually don't

00:36:47,040 --> 00:36:51,030
like h2 because all they've done is

00:36:48,840 --> 00:36:53,910
pushed the problem lower down the stack

00:36:51,030 --> 00:36:55,890
and so Google thought of already

00:36:53,910 --> 00:36:58,650
realized this many years ago and have

00:36:55,890 --> 00:37:01,290
moved on and they have now opened the

00:36:58,650 --> 00:37:03,690
specification for quick which is h2 on

00:37:01,290 --> 00:37:05,880
top of a UDP connection not a TCP

00:37:03,690 --> 00:37:07,950
connection so when you're browsing on

00:37:05,880 --> 00:37:10,020
google.com today and many of the Google

00:37:07,950 --> 00:37:12,180
properties you're already not using

00:37:10,020 --> 00:37:15,870
speedy or h2 you'll be on a quick

00:37:12,180 --> 00:37:17,070
connection and it took four years as I

00:37:15,870 --> 00:37:19,680
said to show that the history line at

00:37:17,070 --> 00:37:21,570
the beginning for h2 to become so I'll

00:37:19,680 --> 00:37:24,330
probably be back in about four or five

00:37:21,570 --> 00:37:28,830
years to talk about quick and why it's

00:37:24,330 --> 00:37:30,180
so great um so ultimately its new

00:37:28,830 --> 00:37:31,680
there's a lot of answer question

00:37:30,180 --> 00:37:33,570
unanswered questions when should we

00:37:31,680 --> 00:37:34,830
start the optimizing assets what's best

00:37:33,570 --> 00:37:36,660
to push how is this going to play your

00:37:34,830 --> 00:37:38,880
service workers and how does it affect

00:37:36,660 --> 00:37:40,140
my website and so leave on that note I

00:37:38,880 --> 00:37:43,080
just wanted to share some of the

00:37:40,140 --> 00:37:44,760
findings that we've had at the FT and I

00:37:43,080 --> 00:37:46,710
think by only us talking and people

00:37:44,760 --> 00:37:49,440
sharing and people writing blog posts do

00:37:46,710 --> 00:37:51,240
does the web evolved so we ran a split

00:37:49,440 --> 00:37:54,780
test when we first deploy it takes to be

00:37:51,240 --> 00:37:58,260
two and we so on mobile tablet desktop

00:37:54,780 --> 00:38:00,210
and compared the 95th percent of the

00:37:58,260 --> 00:38:01,590
page load event and you'll see that

00:38:00,210 --> 00:38:03,390
actually it doesn't have that much of an

00:38:01,590 --> 00:38:06,120
impact on desktop but it has a dramatic

00:38:03,390 --> 00:38:07,950
impact on mobile by nearly five seconds

00:38:06,120 --> 00:38:11,190
and I think this is amazing because it

00:38:07,950 --> 00:38:13,260
proves that it truly was designed to

00:38:11,190 --> 00:38:14,640
battle latency and that is the problem

00:38:13,260 --> 00:38:17,880
that we have a mobile we don't have

00:38:14,640 --> 00:38:19,680
latency process on desktop so then we

00:38:17,880 --> 00:38:21,390
measured the round-trip time to the time

00:38:19,680 --> 00:38:24,600
it takes for all of these average

00:38:21,390 --> 00:38:26,550
connections and you can see that the the

00:38:24,600 --> 00:38:31,650
greater the round-trip time the better

00:38:26,550 --> 00:38:33,630
the impact h2 had on the overall load

00:38:31,650 --> 00:38:36,660
event and h1 got slower and slower and

00:38:33,630 --> 00:38:38,310
slower and finally this is actually

00:38:36,660 --> 00:38:40,260
where desktop did which we've started

00:38:38,310 --> 00:38:42,360
some experiments with push and you can

00:38:40,260 --> 00:38:44,340
see here that we shaved a thousand

00:38:42,360 --> 00:38:48,090
milliseconds of our start render by

00:38:44,340 --> 00:38:49,530
pushing CSS files and I've been working

00:38:48,090 --> 00:38:51,300
in performance a quite a long time now

00:38:49,530 --> 00:38:53,100
and I've never had a single technique

00:38:51,300 --> 00:38:56,160
that's been able to cut that amount of

00:38:53,100 --> 00:38:58,599
time off so it's it's incredible go and

00:38:56,160 --> 00:39:01,029
use it common check to me afterwards

00:38:58,599 --> 00:39:01,869
I'm so sorry I've won over thank you

00:39:01,029 --> 00:39:05,979
very much

00:39:01,869 --> 00:39:08,859
oh that's more the performance basic

00:39:05,979 --> 00:39:10,690
still matter right a slow website on h1

00:39:08,859 --> 00:39:12,190
is still going to be a slow website on

00:39:10,690 --> 00:39:14,140
h2 you need to think about the

00:39:12,190 --> 00:39:16,239
performance basics optimize your first

00:39:14,140 --> 00:39:18,400
render compress minify optimize reduce

00:39:16,239 --> 00:39:20,710
DNS lookups you see the ends to reduce

00:39:18,400 --> 00:39:22,479
your latency and come to london web

00:39:20,710 --> 00:39:25,630
purse we host it at the FT I'm a host

00:39:22,479 --> 00:39:27,279
sorry I had to plug that if you want to

00:39:25,630 --> 00:39:29,229
find out more about performance technic

00:39:27,279 --> 00:39:33,029
techniques come to that thank you very

00:39:29,229 --> 00:39:33,029

YouTube URL: https://www.youtube.com/watch?v=krmBaPUuhyM


