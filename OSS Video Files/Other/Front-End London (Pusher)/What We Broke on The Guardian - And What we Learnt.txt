Title: What We Broke on The Guardian - And What we Learnt
Publication date: 2018-01-31
Playlist: Front-End London
Description: 
	Pusher is a hosted service with APIs, developer tools and open source libraries that greatly simplify integrating real-time functionality into web and mobile applications. 

Pusher will automatically scale when required, removing all the pain of setting up and maintaining a secure, real-time infrastructure. 

Pusher is already trusted to do so by thousands of developers and companies like GitHub, MailChimp, the Financial Times, Buffer and many more. 

Getting started takes just a few seconds: simply go to pusher.com and create a free account. Happy hacking!
Captions: 
	00:00:00,089 --> 00:00:03,629
okay so we're gonna start with the show

00:00:02,250 --> 00:00:06,210
of hands I'm going to move out here so I

00:00:03,629 --> 00:00:11,150
can see who has broken something on

00:00:06,210 --> 00:00:13,380
production all right most of you maybe

00:00:11,150 --> 00:00:14,700
those of you that didn't put up your

00:00:13,380 --> 00:00:16,740
hands you forgot about the time that you

00:00:14,700 --> 00:00:18,720
took all the servers off the load

00:00:16,740 --> 00:00:20,640
balancer at once you know but I've been

00:00:18,720 --> 00:00:23,070
there have been there or you touched

00:00:20,640 --> 00:00:27,180
something in the footer and it broke

00:00:23,070 --> 00:00:28,529
some something in the header breaking

00:00:27,180 --> 00:00:31,920
stuff is a natural part of the

00:00:28,529 --> 00:00:34,680
development process often innovation

00:00:31,920 --> 00:00:38,460
comes from that failure and autonomy and

00:00:34,680 --> 00:00:39,899
speed out way weeks of QA process so a

00:00:38,460 --> 00:00:41,399
bit about me I'm Gareth I'm an

00:00:39,899 --> 00:00:43,800
engineering manager at the Guardian and

00:00:41,399 --> 00:00:46,110
these are mine and my colleagues

00:00:43,800 --> 00:00:48,120
experiences about what we broke on the

00:00:46,110 --> 00:00:51,120
Guardian comm and what we learnt from

00:00:48,120 --> 00:00:57,809
that so does anyone not know what the

00:00:51,120 --> 00:00:59,640
Guardian is no cool gave it we were

00:00:57,809 --> 00:01:01,440
established in 1821 we met one of the

00:00:59,640 --> 00:01:04,110
main British newspapers you know that we

00:01:01,440 --> 00:01:06,110
broke Edward Snowden Panama papers we

00:01:04,110 --> 00:01:08,909
have about 10 million page views a day

00:01:06,110 --> 00:01:11,250
and we have three main editions that UK

00:01:08,909 --> 00:01:13,220
the Australian and US editions and then

00:01:11,250 --> 00:01:15,420
we have an international Edition as well

00:01:13,220 --> 00:01:17,759
but some of you may know that the ground

00:01:15,420 --> 00:01:19,650
yard has a history of making errors but

00:01:17,759 --> 00:01:22,380
to wet your whistles here a few of the

00:01:19,650 --> 00:01:25,799
examples of some faux pars that we've

00:01:22,380 --> 00:01:27,960
we've seen so we had a new developer it

00:01:25,799 --> 00:01:30,479
it can't come in and he asked us you

00:01:27,960 --> 00:01:32,610
know how do I test my changes and he was

00:01:30,479 --> 00:01:34,740
told just publish an article and

00:01:32,610 --> 00:01:37,290
composer the content management system

00:01:34,740 --> 00:01:39,210
said ok all right so he went ahead and

00:01:37,290 --> 00:01:41,540
he did that but was failed to mention

00:01:39,210 --> 00:01:43,770
was to use the test environment

00:01:41,540 --> 00:01:46,439
unfortunately there's now an article in

00:01:43,770 --> 00:01:48,950
the poke with this screenshot of an

00:01:46,439 --> 00:01:53,080
apple news article that he published

00:01:48,950 --> 00:01:55,750
I've obviously taken his name off

00:01:53,080 --> 00:01:58,690
they said delete this stuff and in his

00:01:55,750 --> 00:02:00,940
name so this could have been caught with

00:01:58,690 --> 00:02:03,820
a bit better communication make sure you

00:02:00,940 --> 00:02:05,290
test it on the code environment in this

00:02:03,820 --> 00:02:07,960
next example we were getting some

00:02:05,290 --> 00:02:10,450
complaints from users they were opening

00:02:07,960 --> 00:02:13,990
new tabs like this and they're

00:02:10,450 --> 00:02:15,970
immediately closing so we're going

00:02:13,990 --> 00:02:18,400
through a conversion of a lot of our

00:02:15,970 --> 00:02:19,800
code base to es6 and one of our modules

00:02:18,400 --> 00:02:23,590
had gone through that conversion and

00:02:19,800 --> 00:02:26,140
unfortunately this was the fix literally

00:02:23,590 --> 00:02:28,300
the JavaScript this so you know this was

00:02:26,140 --> 00:02:30,340
accidentally bubbling up too close to

00:02:28,300 --> 00:02:32,860
the window and immediately closing any

00:02:30,340 --> 00:02:34,030
windows that are opened this could have

00:02:32,860 --> 00:02:37,390
been caught with a bit of linting

00:02:34,030 --> 00:02:40,450
probably finally we had this file some

00:02:37,390 --> 00:02:43,600
of you probably recognize it it's it was

00:02:40,450 --> 00:02:45,580
thought that it was documentation so

00:02:43,600 --> 00:02:49,120
what this actually is a browser list

00:02:45,580 --> 00:02:52,600
file it's used for configuration for

00:02:49,120 --> 00:02:54,880
autoprefixer it was assumed it was

00:02:52,600 --> 00:02:57,250
documentation we had this documentation

00:02:54,880 --> 00:02:59,220
elsewhere the browser browsers that we

00:02:57,250 --> 00:03:01,060
supported so the file was deleted

00:02:59,220 --> 00:03:03,580
unfortunately it meant the Flex box

00:03:01,060 --> 00:03:08,110
wasn't prefixed anymore and the home

00:03:03,580 --> 00:03:10,180
page went a little bit long so we said

00:03:08,110 --> 00:03:11,590
you know make config look like config

00:03:10,180 --> 00:03:14,500
maybe add a comment at the top of the

00:03:11,590 --> 00:03:16,750
page comments are communication to your

00:03:14,500 --> 00:03:18,340
future developers most of us will

00:03:16,750 --> 00:03:20,739
recognize this quite move fast and break

00:03:18,340 --> 00:03:22,510
things so the Guardian has a development

00:03:20,739 --> 00:03:24,280
process and a deployment pipeline like

00:03:22,510 --> 00:03:26,709
many others we build and we test locally

00:03:24,280 --> 00:03:28,989
and we have pre push hooks for linting

00:03:26,709 --> 00:03:31,870
and javascript tests so when we're ready

00:03:28,989 --> 00:03:34,360
we open small as possible PRS those

00:03:31,870 --> 00:03:36,580
people requests building team city and

00:03:34,360 --> 00:03:38,890
they run Scala and Java Script unit

00:03:36,580 --> 00:03:40,900
tests and then we require one approval

00:03:38,890 --> 00:03:43,570
from the team to merge and team city

00:03:40,900 --> 00:03:44,920
builds master we use our homegrown

00:03:43,570 --> 00:03:47,110
deployment tool riff-raff to

00:03:44,920 --> 00:03:50,140
continuously deploy to an AWS

00:03:47,110 --> 00:03:53,500
infrastructure with fastly CDN and AWS

00:03:50,140 --> 00:03:55,750
cloud watch logs watching our back door

00:03:53,500 --> 00:03:58,180
to door with 14 minutes from merge to

00:03:55,750 --> 00:04:00,130
production and then once we're live we

00:03:58,180 --> 00:04:01,930
can watch those error rates and the and

00:04:00,130 --> 00:04:05,260
any alerts and we can dig into the logs

00:04:01,930 --> 00:04:06,880
if we need but just important just as

00:04:05,260 --> 00:04:08,800
important maybe even more so

00:04:06,880 --> 00:04:10,420
is that we're able to roll back to a

00:04:08,800 --> 00:04:12,820
previous version in three and a half

00:04:10,420 --> 00:04:14,800
minutes so the important thing to

00:04:12,820 --> 00:04:16,720
understand here is that every developer

00:04:14,800 --> 00:04:18,580
is responsible for merging and deploying

00:04:16,720 --> 00:04:20,200
their code and they're responsible for

00:04:18,580 --> 00:04:21,910
watching it out to production and

00:04:20,200 --> 00:04:25,410
they're responsible for checking that it

00:04:21,910 --> 00:04:27,730
works as expected on the live site I

00:04:25,410 --> 00:04:29,380
believe that there are four main pillars

00:04:27,730 --> 00:04:31,630
of working in a stable and resilient

00:04:29,380 --> 00:04:33,460
continuous deployment environment while

00:04:31,630 --> 00:04:36,310
making sure that we break things early

00:04:33,460 --> 00:04:38,500
and we break them rarely so these

00:04:36,310 --> 00:04:42,250
pillars are pre merged monitoring and

00:04:38,500 --> 00:04:45,040
testing post deploy monitoring making

00:04:42,250 --> 00:04:49,210
smart unreliable tools and last but

00:04:45,040 --> 00:04:52,030
certainly not least communication so

00:04:49,210 --> 00:04:54,250
another hands up moment as everyone here

00:04:52,030 --> 00:04:55,960
you know does everyone have a hundred

00:04:54,250 --> 00:04:59,260
percent code coverage in their unit test

00:04:55,960 --> 00:05:00,940
sounds up if you've got that right we

00:04:59,260 --> 00:05:02,620
all double-check our changes locally

00:05:00,940 --> 00:05:04,750
before merging we have total confidence

00:05:02,620 --> 00:05:06,570
in every line of code that we write but

00:05:04,750 --> 00:05:08,920
you know sometimes things slip through

00:05:06,570 --> 00:05:11,640
this one of my own mistakes

00:05:08,920 --> 00:05:13,960
I was busy adding some documentation

00:05:11,640 --> 00:05:16,180
decided to add a to-do at the top of our

00:05:13,960 --> 00:05:18,610
code base it was a simple enough task

00:05:16,180 --> 00:05:22,380
work in a command pushed documentation

00:05:18,610 --> 00:05:25,150
and no code changes no worries

00:05:22,380 --> 00:05:26,920
unfortunately it turns out that HTML

00:05:25,150 --> 00:05:28,420
comments are different - scarlet

00:05:26,920 --> 00:05:29,860
comments and we ended up with this

00:05:28,420 --> 00:05:32,950
beauty at the top of all of our amp

00:05:29,860 --> 00:05:34,990
pages it was a simple mistake with

00:05:32,950 --> 00:05:36,610
slightly embarrassing consequences and

00:05:34,990 --> 00:05:38,500
the most perceptive of you will have

00:05:36,610 --> 00:05:40,810
noticed this isn't even an HTML coming

00:05:38,500 --> 00:05:43,480
and I was pairing on this documentation

00:05:40,810 --> 00:05:44,800
with another developer things slip

00:05:43,480 --> 00:05:48,130
through it happens to the best of us

00:05:44,800 --> 00:05:49,750
this is on flow dog with a nice to do

00:05:48,130 --> 00:05:52,720
alert

00:05:49,750 --> 00:05:54,919
what did we learn from our mistakes oh

00:05:52,720 --> 00:05:57,949
well we learnt that we should probably

00:05:54,919 --> 00:05:59,599
check the smallest of changes but with

00:05:57,949 --> 00:06:01,610
the site the size of the Guardian and

00:05:59,599 --> 00:06:03,229
how do we have the confidence that we've

00:06:01,610 --> 00:06:07,210
not made a change that affects our

00:06:03,229 --> 00:06:09,889
multiple page templates or our platforms

00:06:07,210 --> 00:06:11,599
so we build rapport requests branches as

00:06:09,889 --> 00:06:14,000
I mentioned before and we run our tests

00:06:11,599 --> 00:06:15,770
before we merge but how about we deploy

00:06:14,000 --> 00:06:18,919
each of those bills so we can do more

00:06:15,770 --> 00:06:21,020
exciting testing well exactly what one

00:06:18,919 --> 00:06:23,120
of our developers did all of our pull

00:06:21,020 --> 00:06:25,550
requests been up of an instance of our

00:06:23,120 --> 00:06:28,639
environment in AWS and they deploy in a

00:06:25,550 --> 00:06:30,139
build of the branch to that instance so

00:06:28,639 --> 00:06:33,139
what exactly is this allowed us to do

00:06:30,139 --> 00:06:35,389
well instead of a manual visual check of

00:06:33,139 --> 00:06:37,490
all of our page templates we're able to

00:06:35,389 --> 00:06:39,050
take automatic screenshots of the full

00:06:37,490 --> 00:06:41,990
request branch like this at different

00:06:39,050 --> 00:06:43,639
responsive breakpoints it's not perfect

00:06:41,990 --> 00:06:45,889
we've been burnt by visual regression

00:06:43,639 --> 00:06:47,449
testing being too noisy before but we'd

00:06:45,889 --> 00:06:49,129
like to look at services like site

00:06:47,449 --> 00:06:51,979
effect and maybe test individual

00:06:49,129 --> 00:06:54,680
components in this way you can also run

00:06:51,979 --> 00:06:56,659
this on localhost so developers can test

00:06:54,680 --> 00:06:58,370
these screenshots before they even push

00:06:56,659 --> 00:07:01,940
up to github

00:06:58,370 --> 00:07:03,740
I mean environment spun up from branches

00:07:01,940 --> 00:07:06,169
also allows us to run other monitoring

00:07:03,740 --> 00:07:07,849
such as this page rate tool to make sure

00:07:06,169 --> 00:07:10,849
we haven't busted any page rate limits

00:07:07,849 --> 00:07:12,770
on our selection of pages you can also

00:07:10,849 --> 00:07:13,699
check for simple acts of accessibility

00:07:12,770 --> 00:07:18,590
mishaps

00:07:13,699 --> 00:07:20,300
we run pally and these PR environments

00:07:18,590 --> 00:07:23,060
have opened up opportunities for real

00:07:20,300 --> 00:07:24,949
browser testing this is closer to

00:07:23,060 --> 00:07:26,870
testing what the user sees and it's

00:07:24,949 --> 00:07:29,599
closer to measuring symptoms and not

00:07:26,870 --> 00:07:30,139
causes which brings me on to my next

00:07:29,599 --> 00:07:33,409
point

00:07:30,139 --> 00:07:35,840
methodology of measuring symptoms and

00:07:33,409 --> 00:07:38,389
not causes is how we approach monitoring

00:07:35,840 --> 00:07:40,490
in our production environments this

00:07:38,389 --> 00:07:42,319
paper by Rob arishok a site reliability

00:07:40,490 --> 00:07:42,979
engineer at Google states that when

00:07:42,319 --> 00:07:44,539
alerting

00:07:42,979 --> 00:07:47,300
we should include cause baits

00:07:44,539 --> 00:07:48,949
information in symptoms based pages or

00:07:47,300 --> 00:07:51,860
on dashboards but we should avoid

00:07:48,949 --> 00:07:52,759
directly alerting on the causes so what

00:07:51,860 --> 00:07:55,490
exactly does that mean

00:07:52,759 --> 00:07:57,500
well users don't care about causes of

00:07:55,490 --> 00:08:00,169
problems like databases being down or

00:07:57,500 --> 00:08:02,960
data being dropped or endpoints being

00:08:00,169 --> 00:08:03,529
inaccessible what they do care about is

00:08:02,960 --> 00:08:05,659
error pay

00:08:03,529 --> 00:08:07,399
ages they care about slowness in their

00:08:05,659 --> 00:08:09,289
pages they care about pages that never

00:08:07,399 --> 00:08:11,149
return they care that when they make

00:08:09,289 --> 00:08:13,669
changes to their data that they see the

00:08:11,149 --> 00:08:15,889
updated data and they care that the

00:08:13,669 --> 00:08:19,309
features that they expect to be working

00:08:15,889 --> 00:08:21,289
are actually working the citizens based

00:08:19,309 --> 00:08:23,959
metrics are reflected in our dashboards

00:08:21,289 --> 00:08:25,519
if an alert is fired will offer often

00:08:23,959 --> 00:08:27,619
make our dashboards the first point of

00:08:25,519 --> 00:08:30,199
cool here we can see for each

00:08:27,619 --> 00:08:31,969
application enough in our front-end calm

00:08:30,199 --> 00:08:35,180
environment that the error response

00:08:31,969 --> 00:08:37,550
rates we can see latency successful

00:08:35,180 --> 00:08:40,430
requests and more and then from these

00:08:37,550 --> 00:08:43,099
dashboards on the calm side we know

00:08:40,430 --> 00:08:46,009
which application we need to go to next

00:08:43,099 --> 00:08:48,319
and which service for example if the

00:08:46,009 --> 00:08:51,139
article application is playing up then

00:08:48,319 --> 00:08:52,519
we check our content API if discussion

00:08:51,139 --> 00:08:54,649
is showing problems then we'll just

00:08:52,519 --> 00:08:56,839
check the discussion API dashboard and

00:08:54,649 --> 00:08:58,519
if fronts are showing issues then we can

00:08:56,839 --> 00:09:01,220
head over to the front sight API

00:08:58,519 --> 00:09:03,350
dashboard each service has similar

00:09:01,220 --> 00:09:05,649
metric dashboards to in aid our initial

00:09:03,350 --> 00:09:08,149
investigation

00:09:05,649 --> 00:09:09,829
so in general deployment as I mentioned

00:09:08,149 --> 00:09:11,689
before we ask that our developers follow

00:09:09,829 --> 00:09:14,029
their change out to production and then

00:09:11,689 --> 00:09:15,439
they check it on the live site to ensure

00:09:14,029 --> 00:09:17,089
that a developer remembers to check

00:09:15,439 --> 00:09:19,220
their changes we use an open-source tool

00:09:17,089 --> 00:09:21,949
built by garden developer Roberto called

00:09:19,220 --> 00:09:23,990
Prout's this will comment on a PR if a

00:09:21,949 --> 00:09:25,430
change is slow to go out and then it

00:09:23,990 --> 00:09:28,370
will comment again when that change is

00:09:25,430 --> 00:09:30,199
landed in life the pro comment has a

00:09:28,370 --> 00:09:32,389
reminder to check the change on the live

00:09:30,199 --> 00:09:35,839
site and a link to our dashboard in

00:09:32,389 --> 00:09:37,279
Cabana some of you may know Cabana but

00:09:35,839 --> 00:09:39,170
it's a tool that ingests the logs of

00:09:37,279 --> 00:09:41,059
your applications your CDN and anywhere

00:09:39,170 --> 00:09:42,740
else that you can look from and it can

00:09:41,059 --> 00:09:44,089
create metrics and dashboards to enable

00:09:42,740 --> 00:09:46,189
the charting of about just about

00:09:44,089 --> 00:09:48,230
anything that you give it a deploy

00:09:46,189 --> 00:09:52,550
dashboard here shows engine engineers

00:09:48,230 --> 00:09:54,470
the 200 the error rates the latency and

00:09:52,550 --> 00:09:57,230
it stands as a sanity check that nothing

00:09:54,470 --> 00:09:58,850
major is fallen over in deployment but

00:09:57,230 --> 00:10:01,429
the front-end experience is important

00:09:58,850 --> 00:10:03,920
too because our users experience relies

00:10:01,429 --> 00:10:05,679
on how our site performs it's important

00:10:03,920 --> 00:10:07,999
for us to track the front-end metrics

00:10:05,679 --> 00:10:10,639
things like load times or time to

00:10:07,999 --> 00:10:12,170
interactive we need to make sure that a

00:10:10,639 --> 00:10:14,300
deployment hasn't caused a major issue

00:10:12,170 --> 00:10:16,850
and that our site doesn't decrease in

00:10:14,300 --> 00:10:18,739
performance over time

00:10:16,850 --> 00:10:20,329
we use a service called speed care if

00:10:18,739 --> 00:10:21,970
you've probably heard of this as well is

00:10:20,329 --> 00:10:24,259
a tool for measuring browser performance

00:10:21,970 --> 00:10:26,509
metrics built on top of web page test

00:10:24,259 --> 00:10:28,729
and it runs a test periodically after

00:10:26,509 --> 00:10:30,410
every deployment if we've broken our

00:10:28,729 --> 00:10:32,539
budgets for metrics such as time to

00:10:30,410 --> 00:10:34,939
first paint or start render or visually

00:10:32,539 --> 00:10:38,059
complete then we're alerted in slack in

00:10:34,939 --> 00:10:40,970
our slack channel to a problem we also

00:10:38,059 --> 00:10:43,819
use Galilee Google Analytics here for

00:10:40,970 --> 00:10:46,220
performance events and real music for

00:10:43,819 --> 00:10:48,379
real user monitoring we can aggregate

00:10:46,220 --> 00:10:49,970
the page load times and custom metrics

00:10:48,379 --> 00:10:51,679
such as when our JavaScript bundles are

00:10:49,970 --> 00:10:54,289
requested and how long they take to

00:10:51,679 --> 00:10:56,089
parse from real users this allows us to

00:10:54,289 --> 00:10:58,039
monitor the changes and drill down into

00:10:56,089 --> 00:11:03,709
particular browsers or devices to

00:10:58,039 --> 00:11:07,069
investigate bottlenecks so there's every

00:11:03,709 --> 00:11:09,589
developer knows undefined in JavaScript

00:11:07,069 --> 00:11:12,019
it'll take down your application you'll

00:11:09,589 --> 00:11:14,389
not care about you or your users one bit

00:11:12,019 --> 00:11:15,799
but Guardian developers learned early on

00:11:14,389 --> 00:11:18,379
to make sure that their JavaScript with

00:11:15,799 --> 00:11:19,910
sandbox we wrap our modules and our

00:11:18,379 --> 00:11:22,429
bootstraps and exception caching

00:11:19,910 --> 00:11:24,049
wrappers but if we do something wrong it

00:11:22,429 --> 00:11:26,569
only takes out the functionality of that

00:11:24,049 --> 00:11:28,429
specific module we catch all our

00:11:26,569 --> 00:11:30,439
exceptions and we report them to century

00:11:28,429 --> 00:11:32,389
century is a tool that aggregates and

00:11:30,439 --> 00:11:33,859
reports JavaScript errors and it gives

00:11:32,389 --> 00:11:35,659
us another avenue of real user

00:11:33,859 --> 00:11:38,929
monitoring but from the point of view of

00:11:35,659 --> 00:11:40,939
things going wrong with our recent

00:11:38,929 --> 00:11:42,799
version of the codebase es6 we also

00:11:40,939 --> 00:11:45,289
integrated flow into our environment

00:11:42,799 --> 00:11:47,239
this gives us a level of type safety and

00:11:45,289 --> 00:11:49,399
hopefully removes many of the undefined

00:11:47,239 --> 00:11:53,809
in other JavaScript errors that we often

00:11:49,399 --> 00:11:55,609
saw in a century finally our editorial

00:11:53,809 --> 00:11:58,039
tools team has a separate type of QA

00:11:55,609 --> 00:12:00,199
monitoring with a tool they called prod

00:11:58,039 --> 00:12:02,899
Mon that's short for production

00:12:00,199 --> 00:12:05,239
monitoring it's a synthetic monitoring

00:12:02,899 --> 00:12:07,039
application that uses webdriver under

00:12:05,239 --> 00:12:08,989
the hood and you can read more about

00:12:07,039 --> 00:12:11,329
this type of monitoring here but ensure

00:12:08,989 --> 00:12:13,519
it's designed to test each stage of a

00:12:11,329 --> 00:12:16,759
user flow and doesn't progress into

00:12:13,519 --> 00:12:19,279
until the previous step is passed so for

00:12:16,759 --> 00:12:21,139
example a specific flow is the creation

00:12:19,279 --> 00:12:22,850
and publication of an article and

00:12:21,139 --> 00:12:25,069
composer our content management system

00:12:22,850 --> 00:12:27,230
it tests that the article has appeared

00:12:25,069 --> 00:12:29,659
in our content API and then that the

00:12:27,230 --> 00:12:30,470
article appears on the live site the

00:12:29,659 --> 00:12:31,970
articles then take

00:12:30,470 --> 00:12:35,270
came down and is tested that is not

00:12:31,970 --> 00:12:37,160
available each step again this type of

00:12:35,270 --> 00:12:39,290
monitoring works great for Ida toriel

00:12:37,160 --> 00:12:41,180
tools and it's a great approach to

00:12:39,290 --> 00:12:43,790
running periodic tests on production

00:12:41,180 --> 00:12:46,100
both in our user flows and in the tools

00:12:43,790 --> 00:12:48,470
that we build it also works well for

00:12:46,100 --> 00:12:50,090
testing the tasks that users don't often

00:12:48,470 --> 00:12:52,400
use to make sure that they continue

00:12:50,090 --> 00:12:54,290
working so that when you really need

00:12:52,400 --> 00:12:55,670
them in that critical moment you'll know

00:12:54,290 --> 00:12:58,970
that they'll perform their job as

00:12:55,670 --> 00:13:02,440
expected which leads us onto our next

00:12:58,970 --> 00:13:05,480
point making sure that your tooling is

00:13:02,440 --> 00:13:07,760
resilient and reliable is paramount to

00:13:05,480 --> 00:13:09,800
stability in your platform especially

00:13:07,760 --> 00:13:11,870
when those tools have the ability to be

00:13:09,800 --> 00:13:16,160
more damaging than a user expects them

00:13:11,870 --> 00:13:17,870
to be so story time in March last year

00:13:16,160 --> 00:13:19,700
we had a bad deploy things went wrong

00:13:17,870 --> 00:13:21,560
and we serve five hundreds from origin

00:13:19,700 --> 00:13:24,140
servers sounds like an end of world

00:13:21,560 --> 00:13:26,570
scenario but thankfully not because our

00:13:24,140 --> 00:13:28,970
CDN is set up to serve stale pages from

00:13:26,570 --> 00:13:33,770
the CDN cache if the origin servers are

00:13:28,970 --> 00:13:35,390
erroring this is a lesson in itself it's

00:13:33,770 --> 00:13:37,640
often saved us against our own and

00:13:35,390 --> 00:13:39,230
author and third party poly origins is a

00:13:37,640 --> 00:13:40,940
good pattern to give you a safety net

00:13:39,230 --> 00:13:43,790
when something breaks and sometime to

00:13:40,940 --> 00:13:46,010
fix it but this lesson is really about

00:13:43,790 --> 00:13:47,720
reliable tooling and a tool that our

00:13:46,010 --> 00:13:50,660
central production team often use is

00:13:47,720 --> 00:13:52,910
this cache clear tool you might be able

00:13:50,660 --> 00:13:55,790
to see where I'm going here this cache

00:13:52,910 --> 00:13:58,640
clear tool removes the page from the CDN

00:13:55,790 --> 00:14:00,740
cache unfortunately because our home

00:13:58,640 --> 00:14:03,170
page was failing to update thanks to

00:14:00,740 --> 00:14:06,170
serving stale it was avoiding showing

00:14:03,170 --> 00:14:08,330
users a 500 error but it deemed that

00:14:06,170 --> 00:14:10,850
there was a cache issue the cache issue

00:14:08,330 --> 00:14:12,710
suddenly became this 500 issue when the

00:14:10,850 --> 00:14:15,380
stale homepage was cleared from the CDN

00:14:12,710 --> 00:14:17,750
cache our tools that were very reliable

00:14:15,380 --> 00:14:19,610
in clearing the cache were to dutiful in

00:14:17,750 --> 00:14:22,630
that job and they undermined that

00:14:19,610 --> 00:14:24,920
reliability by failing at a crucial time

00:14:22,630 --> 00:14:27,470
this taught us the value of making sure

00:14:24,920 --> 00:14:29,840
that our tools not only do that 99% of

00:14:27,470 --> 00:14:33,200
the time job but remembering that they

00:14:29,840 --> 00:14:34,760
have a 1% critical situation well we

00:14:33,200 --> 00:14:37,940
like to build checks into our tools to

00:14:34,760 --> 00:14:39,620
avoid destructive behavior the cache

00:14:37,940 --> 00:14:41,630
clear tool for example will now hit the

00:14:39,620 --> 00:14:43,190
origin servers and it'll only allow

00:14:41,630 --> 00:14:46,490
clearing the page

00:14:43,190 --> 00:14:50,509
from the cache if it receives us 200

00:14:46,490 --> 00:14:53,120
from the CDN but how else could that

00:14:50,509 --> 00:14:55,129
cache clear to have been avoided well a

00:14:53,120 --> 00:14:56,600
message in slack from the developers

00:14:55,129 --> 00:14:58,040
looking at the issue or our central

00:14:56,600 --> 00:15:00,920
production team would have saved us the

00:14:58,040 --> 00:15:02,449
panic of showing 500 start users you can

00:15:00,920 --> 00:15:04,040
have the smartest tools in the world but

00:15:02,449 --> 00:15:05,569
if you don't coordinate when things go

00:15:04,040 --> 00:15:07,490
wrong or when you're going to make a

00:15:05,569 --> 00:15:09,170
significant change or even when you're

00:15:07,490 --> 00:15:10,970
just fiddling with a testing environment

00:15:09,170 --> 00:15:13,970
then the likelihood of breaking things

00:15:10,970 --> 00:15:16,160
is significantly increased the

00:15:13,970 --> 00:15:18,439
communication needs work there needs to

00:15:16,160 --> 00:15:21,110
be an open honest no blame culture where

00:15:18,439 --> 00:15:22,910
people feel psychologically safe they

00:15:21,110 --> 00:15:25,040
can admit to their mistakes freely and

00:15:22,910 --> 00:15:26,720
they can talk about what why that

00:15:25,040 --> 00:15:29,360
happened without fear of repercussions

00:15:26,720 --> 00:15:31,459
our central production on our user help

00:15:29,360 --> 00:15:33,800
team sit nearby to us and we have open

00:15:31,459 --> 00:15:35,149
invite demos within the pipeline work so

00:15:33,800 --> 00:15:37,189
they can see what's coming up and be

00:15:35,149 --> 00:15:38,899
prepared for it when there's a problem

00:15:37,189 --> 00:15:41,480
we head over and we talk face to face

00:15:38,899 --> 00:15:43,759
with them it's important to never under

00:15:41,480 --> 00:15:47,329
message underestimate the power of email

00:15:43,759 --> 00:15:50,449
to skew meaning some of you might have

00:15:47,329 --> 00:15:52,579
might remember the gate lab issue it's a

00:15:50,449 --> 00:15:54,170
it's a great example of open honest

00:15:52,579 --> 00:15:57,350
communication when things are going

00:15:54,170 --> 00:15:59,180
wrong really really wrong so a developer

00:15:57,350 --> 00:16:01,370
accidentally removed most of their data

00:15:59,180 --> 00:16:04,759
from the production database they lost

00:16:01,370 --> 00:16:06,680
about 5,000 comments and 5,000 projects

00:16:04,759 --> 00:16:08,389
issues but the way they handled

00:16:06,680 --> 00:16:11,209
themselves was a great example of good

00:16:08,389 --> 00:16:12,920
communication a fear of their developers

00:16:11,209 --> 00:16:14,509
jumped in to this public live stream to

00:16:12,920 --> 00:16:16,189
discuss the problem and they had a

00:16:14,509 --> 00:16:18,699
completely public Google Doc with the

00:16:16,189 --> 00:16:21,319
time of events with what they had tried

00:16:18,699 --> 00:16:23,509
the community reacted so positively

00:16:21,319 --> 00:16:25,100
people are using their tool and seeing

00:16:23,509 --> 00:16:27,829
the problems were sending love and hugs

00:16:25,100 --> 00:16:31,040
esteem especially to team member one who

00:16:27,829 --> 00:16:32,449
is the deleter of the database it really

00:16:31,040 --> 00:16:36,309
showed how people appreciate

00:16:32,449 --> 00:16:39,019
transparency when things are going wrong

00:16:36,309 --> 00:16:40,639
so I've talked a bit about communication

00:16:39,019 --> 00:16:42,470
before code goes out the door and a

00:16:40,639 --> 00:16:44,809
little bit about when things are going

00:16:42,470 --> 00:16:47,420
wrong but what about after an incident

00:16:44,809 --> 00:16:49,189
has been resolved after all those are

00:16:47,420 --> 00:16:51,920
the times when we can really learn what

00:16:49,189 --> 00:16:53,839
went wrong and why the Guardian we have

00:16:51,920 --> 00:16:56,300
post-mortems a day after an incident or

00:16:53,839 --> 00:16:57,080
in certain respects these are open

00:16:56,300 --> 00:16:58,400
invite with Mandy

00:16:57,080 --> 00:17:00,530
three attendants from the teams that

00:16:58,400 --> 00:17:03,130
maintain the system and the engineers

00:17:00,530 --> 00:17:05,240
that were on call or resolve the issue

00:17:03,130 --> 00:17:06,860
these are the true what on why

00:17:05,240 --> 00:17:08,839
environment they're free of

00:17:06,860 --> 00:17:10,850
finger-pointing no arguing and they're

00:17:08,839 --> 00:17:12,950
laser focused on finding remediation

00:17:10,850 --> 00:17:16,040
tasks to shore up the tools and systems

00:17:12,950 --> 00:17:17,360
that didn't work as expected so they

00:17:16,040 --> 00:17:19,220
provide a short description of what

00:17:17,360 --> 00:17:21,500
happened and they pulled together a

00:17:19,220 --> 00:17:23,180
timeline of events things like when did

00:17:21,500 --> 00:17:25,670
the support devs get called when did the

00:17:23,180 --> 00:17:27,800
monitoring notify the teams when were

00:17:25,670 --> 00:17:31,370
communications sent to affected users or

00:17:27,800 --> 00:17:33,080
status is updated next we talk about the

00:17:31,370 --> 00:17:35,690
questions that were raised things like

00:17:33,080 --> 00:17:38,360
why didn't an alarm go off why doesn't a

00:17:35,690 --> 00:17:40,070
set section have unit test coverage why

00:17:38,360 --> 00:17:42,380
isn't something protected by the cache

00:17:40,070 --> 00:17:43,730
these questions are designed to tease

00:17:42,380 --> 00:17:47,270
out the bullet points for the next

00:17:43,730 --> 00:17:50,000
section the actions the actions will

00:17:47,270 --> 00:17:51,560
offer often vary from investigations to

00:17:50,000 --> 00:17:53,570
answer the previous kept questions

00:17:51,560 --> 00:17:55,520
things like adding health checks or

00:17:53,570 --> 00:17:58,490
alarms to systems and checking that all

00:17:55,520 --> 00:17:59,930
the similar sections are covered we

00:17:58,490 --> 00:18:03,950
might add log in to make it easier to

00:17:59,930 --> 00:18:05,360
debug in the future and we all also want

00:18:03,950 --> 00:18:08,180
to make sure that systems are more

00:18:05,360 --> 00:18:10,010
robust by adding things like exception

00:18:08,180 --> 00:18:13,040
caching or providing full backs of

00:18:10,010 --> 00:18:15,520
failover ease these incident

00:18:13,040 --> 00:18:18,440
retrospectives create a virtuous cycle

00:18:15,520 --> 00:18:20,900
each post mortem teaches us how to build

00:18:18,440 --> 00:18:22,820
more robust resilient systems that

00:18:20,900 --> 00:18:27,680
filter into the next product or feature

00:18:22,820 --> 00:18:30,020
that we build so it can feel like a

00:18:27,680 --> 00:18:31,460
disaster when things are going wrong but

00:18:30,020 --> 00:18:34,670
the majority of these issues they go

00:18:31,460 --> 00:18:37,460
unnoticed by users by ensuring that we

00:18:34,670 --> 00:18:39,920
have robust pre-emerge monitoring post

00:18:37,460 --> 00:18:41,630
deploy monitoring and alerting robust

00:18:39,920 --> 00:18:43,970
tools and excellent communication

00:18:41,630 --> 00:18:47,450
between our teams we can ensure that

00:18:43,970 --> 00:18:49,520
when things do go wrong we know and we

00:18:47,450 --> 00:18:53,270
can fix them before our readers notice a

00:18:49,520 --> 00:18:55,640
problem each thing that breaks improves

00:18:53,270 --> 00:18:58,850
the robustness of our tools processes

00:18:55,640 --> 00:19:00,800
and infrastructure all in all we're

00:18:58,850 --> 00:19:02,600
moving forward we're building the tools

00:19:00,800 --> 00:19:04,280
the checks the processes and the

00:19:02,600 --> 00:19:06,740
communications so that we can follow

00:19:04,280 --> 00:19:08,030
Facebook's new mantra it's not quite as

00:19:06,740 --> 00:19:10,279
catchy but it's certainly a better

00:19:08,030 --> 00:19:12,649
strategy for building websites in a crap

00:19:10,279 --> 00:19:17,690
patience the move fast with strong and

00:19:12,649 --> 00:19:19,550
stable infrastructure there you go

00:19:17,690 --> 00:19:26,930
any questions thank you very much

00:19:19,550 --> 00:19:26,930

YouTube URL: https://www.youtube.com/watch?v=dwlRKmjWOzE


