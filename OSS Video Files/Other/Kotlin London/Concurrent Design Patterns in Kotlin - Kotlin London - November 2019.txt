Title: Concurrent Design Patterns in Kotlin - Kotlin London - November 2019
Publication date: 2019-11-24
Playlist: Kotlin London
Description: 
	Alexey Soshin - Design patterns with Kotlin

Get familiar with half a dozen concurrent design patterns 
Discuss how concurrency is solved in other languages 
Convince you that concurrency in Kotlin is awesome

Parallelism is "doing many things at the same time" 
Concurrency is "doing something, while you wait for something 
else" 
Our brains are not parallel, but they are concurrent 
We're switching between different tasks, creating an illusion 
that we doing more than one thing at the same time 

_

About Pusher Sessions:

We're bringing the meetup to you. With Sessions, you can watch recordings of top-notch talks from developer meetups -- wherever and whenever you want.

Meetups are a great way to learn from our peers and to keep up with the latest trends and technologies. As developers ourselves, we at Pusher wanted to bring this great content to more people... So we built Sessions. On Sessions, you can watch talks that interest you and subscribe to be notified when new content gets added.

If you run a meetup and want to get involved, kindly get in touch.

_

About Pusher:

Pusher is a hosted service with APIs, developer tools and open source libraries that greatly simplify integrating real-time functionality into web and mobile applications. 

Pusher will automatically scale when required, removing all the pain of setting up and maintaining a secure, real-time infrastructure. 

Pusher is already trusted to do so by thousands of developers and companies like GitHub, MailChimp, the Financial Times, Buffer and many more. 

Getting started takes just a few seconds: simply go to pusher.com and create a free account. Happy hacking!
Captions: 
	00:00:00,030 --> 00:00:05,069
yeah so hello everyone my name is Alexis

00:00:03,000 --> 00:00:08,790
ocean hey can you hear me well at the

00:00:05,069 --> 00:00:12,540
back yep perfect and this is concurrent

00:00:08,790 --> 00:00:15,450
design patterns in Kotlin talk so a

00:00:12,540 --> 00:00:18,449
little bit about me I'm currently a

00:00:15,450 --> 00:00:22,320
staff engineer at deliver Oh former a

00:00:18,449 --> 00:00:25,380
Software Architect at yet and I'm also

00:00:22,320 --> 00:00:28,140
author of hands-on design patterns with

00:00:25,380 --> 00:00:33,660
codename book I know this name of a book

00:00:28,140 --> 00:00:36,870
is a bit mouthful but yeah so goals of

00:00:33,660 --> 00:00:39,540
this talk first of all get familiar with

00:00:36,870 --> 00:00:44,719
half a dozen of concurrent design but

00:00:39,540 --> 00:00:48,930
patterns and then discuss a bit how

00:00:44,719 --> 00:00:53,520
concurrency is solved in some other

00:00:48,930 --> 00:00:58,590
language languages and convince you that

00:00:53,520 --> 00:01:02,550
concurrency in Catalan is awesome a bit

00:00:58,590 --> 00:01:07,439
of an intro so when I first started

00:01:02,550 --> 00:01:11,310
those talks about two years ago and it

00:01:07,439 --> 00:01:14,610
they were received pretty well and but

00:01:11,310 --> 00:01:19,020
back then most of the people that came

00:01:14,610 --> 00:01:22,979
to conferences and meetups where Java

00:01:19,020 --> 00:01:26,759
developers and then when I showed them

00:01:22,979 --> 00:01:30,470
something like this so instead of this

00:01:26,759 --> 00:01:34,049
for this is the implementation of a

00:01:30,470 --> 00:01:38,189
singleton in Java you could have

00:01:34,049 --> 00:01:40,759
something like this they were like oh

00:01:38,189 --> 00:01:43,320
that's a really nice language

00:01:40,759 --> 00:01:45,960
and unless of course there were some

00:01:43,320 --> 00:01:48,119
scarlet developers that came to my talks

00:01:45,960 --> 00:01:50,579
and then they would like shout at me

00:01:48,119 --> 00:01:53,159
yeah darsky invented that like ten years

00:01:50,579 --> 00:01:56,040
ago you just stole that from us and

00:01:53,159 --> 00:01:59,159
stuff like that yeah any Scala

00:01:56,040 --> 00:02:04,409
developers here okay because scale

00:01:59,159 --> 00:02:08,369
developers are a bit of fun killer for

00:02:04,409 --> 00:02:11,970
Kotlin meetups we already had that yeah

00:02:08,369 --> 00:02:13,380
so yeah but nowadays when like when I

00:02:11,970 --> 00:02:15,270
show you

00:02:13,380 --> 00:02:17,400
objects in built on it's obvious because

00:02:15,270 --> 00:02:20,700
probably most of you are coding

00:02:17,400 --> 00:02:22,260
developers and by the way are there is

00:02:20,700 --> 00:02:26,210
there somebody that's not caught in

00:02:22,260 --> 00:02:29,900
developer because then I know okay so a

00:02:26,210 --> 00:02:34,440
few because all of my examples will be

00:02:29,900 --> 00:02:36,750
given in Kotlin I just need to

00:02:34,440 --> 00:02:37,190
understand how deep I need to explain

00:02:36,750 --> 00:02:41,190
that

00:02:37,190 --> 00:02:44,010
so no cheap tricks for me anymore and I

00:02:41,190 --> 00:02:47,970
need to not to discuss something more

00:02:44,010 --> 00:02:51,090
advanced and then what will what I

00:02:47,970 --> 00:02:53,550
decided is that let's discuss something

00:02:51,090 --> 00:02:56,370
less obvious like concurrent design

00:02:53,550 --> 00:02:59,820
patterns instead of the regular one the

00:02:56,370 --> 00:03:01,800
classical ones but is there such a thing

00:02:59,820 --> 00:03:04,200
because there's this book probably

00:03:01,800 --> 00:03:06,540
you're familiar with it at least from

00:03:04,200 --> 00:03:08,130
the outside and there was no such thing

00:03:06,540 --> 00:03:09,900
in this book as concurrent design

00:03:08,130 --> 00:03:14,760
patterns so probably it doesn't exist

00:03:09,900 --> 00:03:17,520
right and so there are a few things you

00:03:14,760 --> 00:03:19,440
need to know about this book and maybe

00:03:17,520 --> 00:03:22,530
you know them maybe or not it was

00:03:19,440 --> 00:03:27,000
written in 92 and that's the only

00:03:22,530 --> 00:03:29,400
edition of this book and if you seen

00:03:27,000 --> 00:03:32,550
examples from this book written in C++

00:03:29,400 --> 00:03:34,170
or in Java that's not from this book

00:03:32,550 --> 00:03:36,720
actually that's somebody else written

00:03:34,170 --> 00:03:41,430
them because this book is in C++ and

00:03:36,720 --> 00:03:42,230
Smalltalk and yeah I read that and it

00:03:41,430 --> 00:03:46,320
wasn't fun

00:03:42,230 --> 00:03:48,450
and this book obviously doesn't contain

00:03:46,320 --> 00:03:50,340
all the design patterns in the world so

00:03:48,450 --> 00:03:52,170
we'll discuss a few darts not in this

00:03:50,340 --> 00:03:55,350
book but still design patterns

00:03:52,170 --> 00:03:59,160
concurrent design patterns so why do I

00:03:55,350 --> 00:04:02,790
speak about concurrency first it's a hot

00:03:59,160 --> 00:04:04,920
topic in the past ten years and the main

00:04:02,790 --> 00:04:08,600
reason for that is that we're reaching

00:04:04,920 --> 00:04:12,540
the limit of how fast our CPUs can get

00:04:08,600 --> 00:04:14,610
and so we try to add more course and

00:04:12,540 --> 00:04:17,070
meaning more parallelism but there's

00:04:14,610 --> 00:04:20,299
also a limit for that and our solution

00:04:17,070 --> 00:04:23,100
for this is actually concurrency so

00:04:20,299 --> 00:04:25,150
concurrency is a way to optimize our

00:04:23,100 --> 00:04:29,800
resources

00:04:25,150 --> 00:04:33,570
and unlike some other problems

00:04:29,800 --> 00:04:36,160
concurrency is hard to visualize and in

00:04:33,570 --> 00:04:39,340
usual design patterns we have but nice

00:04:36,160 --> 00:04:42,310
um else if um else can be nice and here

00:04:39,340 --> 00:04:46,810
we don't have them so much but I'll try

00:04:42,310 --> 00:04:49,830
to visualize them anyway and a few words

00:04:46,810 --> 00:04:52,630
about concurrency versus parallelism so

00:04:49,830 --> 00:04:54,400
parallelism is doing many things at the

00:04:52,630 --> 00:04:56,800
same time so I'm speaking you're

00:04:54,400 --> 00:04:59,970
listening we're two separate entities

00:04:56,800 --> 00:05:03,910
and we were doing things in parallel and

00:04:59,970 --> 00:05:08,440
concurrency is doing something while you

00:05:03,910 --> 00:05:12,130
wait for something else so for example

00:05:08,440 --> 00:05:15,820
our brains are not parallel but they are

00:05:12,130 --> 00:05:18,160
concurrent and we were switching between

00:05:15,820 --> 00:05:22,000
different tasks creating the illusion

00:05:18,160 --> 00:05:24,160
that we doing a few things at the same

00:05:22,000 --> 00:05:27,580
time but we're actually not it's only an

00:05:24,160 --> 00:05:30,160
illusion and one example is driving and

00:05:27,580 --> 00:05:31,419
speaking over the phone so you're not

00:05:30,160 --> 00:05:34,900
actually doing two things at the same

00:05:31,419 --> 00:05:37,440
time and what I want you to take from

00:05:34,900 --> 00:05:41,770
this is concurrency is an illusion

00:05:37,440 --> 00:05:46,180
so let's actually start a bit the design

00:05:41,770 --> 00:05:47,740
patterns and first one if most of you

00:05:46,180 --> 00:05:50,979
are calling developers you'll probably

00:05:47,740 --> 00:05:54,070
are familiar with the a sinc function

00:05:50,979 --> 00:05:58,449
and the question is is this a design

00:05:54,070 --> 00:05:59,949
pattern so if you worked with cortland

00:05:58,449 --> 00:06:03,310
and co-routines you're familiar with

00:05:59,949 --> 00:06:05,639
that and it goes like this for example

00:06:03,310 --> 00:06:08,440
usually you'll have by function and

00:06:05,639 --> 00:06:12,010
inside we invoke the I think function

00:06:08,440 --> 00:06:14,340
and we wrapped some some synchronous

00:06:12,010 --> 00:06:16,630
code so in this example probably it's

00:06:14,340 --> 00:06:19,840
spring or something because it's called

00:06:16,630 --> 00:06:22,570
service and some somewhere else in the

00:06:19,840 --> 00:06:29,620
code you invoke this synchronous

00:06:22,570 --> 00:06:32,289
function then to await so if it's a

00:06:29,620 --> 00:06:34,120
design pattern it's quite easy to guess

00:06:32,289 --> 00:06:36,760
that this is a design pattern because

00:06:34,120 --> 00:06:38,439
that's the name of my talk and what's

00:06:36,760 --> 00:06:46,149
its name

00:06:38,439 --> 00:06:48,669
and anybody want to guess so Kirtland

00:06:46,149 --> 00:06:51,909
compiler actually and cotton ID actually

00:06:48,669 --> 00:06:55,959
give us a hint and if we look at the

00:06:51,909 --> 00:06:59,800
signature we see that I think actually

00:06:55,959 --> 00:07:02,319
returns us something called deferred and

00:06:59,800 --> 00:07:07,839
yeah this design pattern that I think

00:07:02,319 --> 00:07:10,599
implements called deferred value and in

00:07:07,839 --> 00:07:12,610
other languages it's also called future

00:07:10,599 --> 00:07:14,679
or promise there they are all

00:07:12,610 --> 00:07:19,149
implemented the same design pattern the

00:07:14,679 --> 00:07:24,099
deferred value and any JavaScript

00:07:19,149 --> 00:07:26,289
developers in the room so I not not once

00:07:24,099 --> 00:07:28,419
I heard that from JavaScript developers

00:07:26,289 --> 00:07:31,089
that design patterns are obsolete only

00:07:28,419 --> 00:07:33,039
Java developers need them and there are

00:07:31,089 --> 00:07:35,709
no design patterns in JavaScript and

00:07:33,039 --> 00:07:39,369
we're doing fine so there are design

00:07:35,709 --> 00:07:42,099
patterns in JavaScript and URI we're

00:07:39,369 --> 00:07:44,379
using them every day maybe in some cases

00:07:42,099 --> 00:07:51,729
we just don't know that they are design

00:07:44,379 --> 00:07:55,179
patterns and the question is now is it

00:07:51,729 --> 00:07:57,849
related though to any classical design

00:07:55,179 --> 00:08:02,619
pattern any design pattern out of the

00:07:57,849 --> 00:08:05,229
Gang of Four book if we look at the

00:08:02,619 --> 00:08:11,169
beautiful ASCII art in the job

00:08:05,229 --> 00:08:13,179
documentation will see this and somebody

00:08:11,169 --> 00:08:16,059
in jetbrains worked very hard to

00:08:13,179 --> 00:08:21,629
generate this diagram probably or maybe

00:08:16,059 --> 00:08:25,869
he just generated it and it's a state so

00:08:21,629 --> 00:08:29,199
job deferred deferred in Kotlin inherits

00:08:25,869 --> 00:08:32,259
from a job and every job is actually a

00:08:29,199 --> 00:08:36,039
state machine so it's it implements

00:08:32,259 --> 00:08:39,219
state design pattern and the interesting

00:08:36,039 --> 00:08:43,089
part it's actually implements it twice

00:08:39,219 --> 00:08:45,160
so once it implements it for itself so

00:08:43,089 --> 00:08:48,069
every job is a state machine with

00:08:45,160 --> 00:08:50,620
specified States and then when you write

00:08:48,069 --> 00:08:52,130
a core routine and the Kotlin compiler

00:08:50,620 --> 00:08:55,820
breaks you

00:08:52,130 --> 00:08:57,830
or cold into pieces and creates another

00:08:55,820 --> 00:09:00,350
state machine which is a dynamic state

00:08:57,830 --> 00:09:02,360
machines for you code specifically so

00:09:00,350 --> 00:09:05,780
it's an interesting implementation

00:09:02,360 --> 00:09:08,060
okay to our next design pattern so

00:09:05,780 --> 00:09:10,160
co-routines make everything better and

00:09:08,060 --> 00:09:14,150
let's take a look at the following code

00:09:10,160 --> 00:09:16,520
so that's the reason I asked if there

00:09:14,150 --> 00:09:19,760
are there are many people that are not

00:09:16,520 --> 00:09:23,180
familiar with Kotlin because I wrote

00:09:19,760 --> 00:09:26,720
that it's obvious maybe if you never

00:09:23,180 --> 00:09:29,810
seen code units obviously not this code

00:09:26,720 --> 00:09:33,980
prints numbers between zero and 100

00:09:29,810 --> 00:09:36,440
thousand and two we launched it in a

00:09:33,980 --> 00:09:39,740
main function we have the run blocking

00:09:36,440 --> 00:09:43,340
so it won't exit early and for other

00:09:39,740 --> 00:09:45,770
reasons then we generate 100,000 numbers

00:09:43,340 --> 00:09:50,150
and for each number willow check Co

00:09:45,770 --> 00:09:52,940
routine and since coroutine as you know

00:09:50,150 --> 00:09:58,250
are concurrent we will see those numbers

00:09:52,940 --> 00:10:03,170
in random order semi random and yeah so

00:09:58,250 --> 00:10:05,330
let's try to switch to my IntelliJ you

00:10:03,170 --> 00:10:13,510
don't need to see the actual code like

00:10:05,330 --> 00:10:18,020
it's exactly the same and I learn on it

00:10:13,510 --> 00:10:20,960
so if you look at the output the numbers

00:10:18,020 --> 00:10:24,620
are not random at all and that's really

00:10:20,960 --> 00:10:27,980
weird but if it wasn't weird I probably

00:10:24,620 --> 00:10:33,080
wouldn't show it in my talk and there is

00:10:27,980 --> 00:10:38,750
a reason they are all ordered and not in

00:10:33,080 --> 00:10:41,780
semi random order because if we look if

00:10:38,750 --> 00:10:46,900
we dig deeper inside the code we'll see

00:10:41,780 --> 00:10:50,780
this and there is actually an event loop

00:10:46,900 --> 00:10:54,140
there since we run this code from the

00:10:50,780 --> 00:10:57,200
main thread and induced run blocking run

00:10:54,140 --> 00:11:00,940
blocking creates an event loop and the

00:10:57,200 --> 00:11:05,910
event loop uses on a single thread and

00:11:00,940 --> 00:11:09,060
this this was popular

00:11:05,910 --> 00:11:11,580
raised by a JavaScript and the reason

00:11:09,060 --> 00:11:13,890
it's so popular is that when you have a

00:11:11,580 --> 00:11:16,440
single thread you have less concurrency

00:11:13,890 --> 00:11:20,820
problems one thread no concurrency and

00:11:16,440 --> 00:11:25,200
sometimes that's good and the another

00:11:20,820 --> 00:11:28,320
interesting part is that if we dig even

00:11:25,200 --> 00:11:33,300
deeper you actually can see I created

00:11:28,320 --> 00:11:35,220
there 100,000 co-routines and you can

00:11:33,300 --> 00:11:37,980
see them all in the queue so they are

00:11:35,220 --> 00:11:41,760
all waiting to be executed sequentially

00:11:37,980 --> 00:11:45,090
and back to design patterns event loop

00:11:41,760 --> 00:11:50,100
is actually a design pattern and its

00:11:45,090 --> 00:11:53,670
official name is reactor as I said it's

00:11:50,100 --> 00:11:55,980
it uses a single thread meaning no

00:11:53,670 --> 00:12:00,840
concurrency issues which is sometimes

00:11:55,980 --> 00:12:04,140
good but the reason is if something

00:12:00,840 --> 00:12:06,810
blocks the thread and the world stops so

00:12:04,140 --> 00:12:09,900
I decided not to show that because it's

00:12:06,810 --> 00:12:13,590
a bit boring like we won't see numbers

00:12:09,900 --> 00:12:17,180
for some time and it's also pretty

00:12:13,590 --> 00:12:20,610
obvious at this point I would say and

00:12:17,180 --> 00:12:24,740
but yeah that's one of the problems with

00:12:20,610 --> 00:12:29,850
event loop design pattern and not GS

00:12:24,740 --> 00:12:32,550
runtime uses this model so we discussed

00:12:29,850 --> 00:12:34,920
two of them deferred value and now they

00:12:32,550 --> 00:12:38,900
react Oh what about this code I'm not

00:12:34,920 --> 00:12:42,860
sure how well can you see it but it's

00:12:38,900 --> 00:12:47,010
exactly the same code where I changed

00:12:42,860 --> 00:12:51,920
only one line which says now that my

00:12:47,010 --> 00:12:53,430
launch will use dispatchers default and

00:12:51,920 --> 00:12:58,250
what do I say

00:12:53,430 --> 00:12:58,250
is it the same design pattern or not

00:13:04,739 --> 00:13:10,899
and if I run it again

00:13:07,329 --> 00:13:14,709
I should see the numbers are I didn't

00:13:10,899 --> 00:13:17,019
run the correct one I think yeah let's

00:13:14,709 --> 00:13:21,660
see again it should should be random at

00:13:17,019 --> 00:13:25,319
this time at least yeah that's better

00:13:21,660 --> 00:13:30,660
so now the numbers are still pretty

00:13:25,319 --> 00:13:30,660
pretty ordered that's not what I wanted

00:13:30,959 --> 00:13:38,290
but but but yeah they should be more

00:13:34,269 --> 00:13:43,779
mixed at least and the reason is and

00:13:38,290 --> 00:13:46,809
that the dispatchers implement another

00:13:43,779 --> 00:13:48,850
design pattern and that's the part where

00:13:46,809 --> 00:13:53,889
I try to visualize what's actually

00:13:48,850 --> 00:13:57,459
happening when you launch 100,000 on in

00:13:53,889 --> 00:14:08,069
my case 1000 co-routines on a default

00:13:57,459 --> 00:14:12,399
dispatcher yeah so what happens here and

00:14:08,069 --> 00:14:15,790
on my laptop I have eight course so we

00:14:12,399 --> 00:14:21,239
have actually each column is a single

00:14:15,790 --> 00:14:25,869
thread and the green lines you see are

00:14:21,239 --> 00:14:30,669
the accordions that I launched so we'll

00:14:25,869 --> 00:14:32,529
run it again and you launch them in a

00:14:30,669 --> 00:14:34,980
loop as you've seen it's exactly the

00:14:32,529 --> 00:14:38,639
same code and but notice a few

00:14:34,980 --> 00:14:41,829
interesting things first they are not

00:14:38,639 --> 00:14:44,139
distributed evenly so some threads get

00:14:41,829 --> 00:14:50,259
more recordings to execute some threads

00:14:44,139 --> 00:14:53,679
get less and another part is that even

00:14:50,259 --> 00:14:56,439
though some threads get more tasks to

00:14:53,679 --> 00:15:00,519
execute they may finish before others

00:14:56,439 --> 00:15:03,009
with less fuss so it's distributed in

00:15:00,519 --> 00:15:05,259
pretty random order even though I have

00:15:03,009 --> 00:15:09,669
the same amount of work for each core

00:15:05,259 --> 00:15:12,129
routine and as you may have guessed from

00:15:09,669 --> 00:15:14,590
the name of the file that I executed now

00:15:12,129 --> 00:15:19,030
it's called multi

00:15:14,590 --> 00:15:23,020
reactor design pattern it I think it was

00:15:19,030 --> 00:15:25,950
coined about ten years ago by vertex

00:15:23,020 --> 00:15:31,030
framework which is a Java framework and

00:15:25,950 --> 00:15:34,360
this the inventor of vertex which was

00:15:31,030 --> 00:15:36,490
which is a British guiding folks and he

00:15:34,360 --> 00:15:42,970
looked at node.js at that time it was

00:15:36,490 --> 00:15:45,580
two 2000-2010 ten and he said to himself

00:15:42,970 --> 00:15:48,700
wait but not jess is actually an event

00:15:45,580 --> 00:15:51,490
loop written in C++ I can do the same in

00:15:48,700 --> 00:15:54,220
Java and I can do and I could use more

00:15:51,490 --> 00:15:56,230
threads and it would be even better so

00:15:54,220 --> 00:15:59,890
that's how he went at the a multi

00:15:56,230 --> 00:16:03,730
reactor design pattern and its benefit

00:15:59,890 --> 00:16:06,460
it uses all the available CPU cores so

00:16:03,730 --> 00:16:07,990
as you've seen I had eight CPU cores so

00:16:06,460 --> 00:16:12,310
my coroutines

00:16:07,990 --> 00:16:13,870
spray are spread evenly IRA spread

00:16:12,310 --> 00:16:18,190
across all course but they're they are

00:16:13,870 --> 00:16:20,560
not spread evenly and go language uses

00:16:18,190 --> 00:16:22,540
this model for go routines so if you

00:16:20,560 --> 00:16:25,930
heard about go routines and go they are

00:16:22,540 --> 00:16:30,100
just go routines and very similar to

00:16:25,930 --> 00:16:32,020
what Cortland does and a bit more help

00:16:30,100 --> 00:16:34,150
from the compiler because they have only

00:16:32,020 --> 00:16:41,950
one concurrency model so they could

00:16:34,150 --> 00:16:45,310
optimize it a bit more ok so let's see

00:16:41,950 --> 00:16:47,770
another example as I said I'm from

00:16:45,310 --> 00:16:50,980
delivery so everything will be around

00:16:47,770 --> 00:16:54,300
deliveries and drivers and stuff let's

00:16:50,980 --> 00:16:59,770
see we want to fetch the profile of our

00:16:54,300 --> 00:17:02,740
driver so we have this data class with a

00:16:59,770 --> 00:17:09,490
picture some of his favorites and

00:17:02,740 --> 00:17:14,200
friends and then we fetch the fetch some

00:17:09,490 --> 00:17:16,720
elements and the problem is if I run

00:17:14,200 --> 00:17:20,140
this code let's say this is written in

00:17:16,720 --> 00:17:22,660
Ruby and each endpoint is 100

00:17:20,140 --> 00:17:26,709
milliseconds 200 milliseconds and 300

00:17:22,660 --> 00:17:27,760
milliseconds respectively if I ran this

00:17:26,709 --> 00:17:30,279
code

00:17:27,760 --> 00:17:32,590
it will take me 600 milliseconds and

00:17:30,279 --> 00:17:34,419
that's the same like if I use if I go

00:17:32,590 --> 00:17:38,950
back a few years ago and would use

00:17:34,419 --> 00:17:43,510
spring MVC or something like that so

00:17:38,950 --> 00:17:48,399
what we do in Kotlin we usually wrap all

00:17:43,510 --> 00:17:52,570
those functions in a sink blocks we use

00:17:48,399 --> 00:17:56,440
basically the same data class and then

00:17:52,570 --> 00:18:01,480
you use a weight so you have this data

00:17:56,440 --> 00:18:04,049
class underneath and you use a weight

00:18:01,480 --> 00:18:06,700
away to wait on all the elements and

00:18:04,049 --> 00:18:09,940
hopefully it will be more more

00:18:06,700 --> 00:18:13,029
concurrent and faster so did this

00:18:09,940 --> 00:18:15,700
example we'll take half of the time and

00:18:13,029 --> 00:18:18,639
my usual question is is this a design

00:18:15,700 --> 00:18:23,559
pattern because it looks quite naive i I

00:18:18,639 --> 00:18:26,740
would say but yes it is it's called a

00:18:23,559 --> 00:18:30,610
barrier and it makes sure that

00:18:26,740 --> 00:18:35,350
co-routines can proceed only when they

00:18:30,610 --> 00:18:39,250
all reach the same point so if we go

00:18:35,350 --> 00:18:42,519
back the point when we return the object

00:18:39,250 --> 00:18:46,389
is the point where all the other

00:18:42,519 --> 00:18:49,269
goroutines can accordions can proceed so

00:18:46,389 --> 00:18:51,940
sometimes here it's an object that you

00:18:49,269 --> 00:18:54,610
would have created anyway like this

00:18:51,940 --> 00:18:57,970
function obviously returns the profile

00:18:54,610 --> 00:19:00,519
but in some other cases you may have

00:18:57,970 --> 00:19:03,450
created this data class only for the

00:19:00,519 --> 00:19:04,929
purpose of synchronizing all of your

00:19:03,450 --> 00:19:11,080
core routines

00:19:04,929 --> 00:19:15,309
now some more examples let's say I have

00:19:11,080 --> 00:19:21,250
a web page low cats and I would like to

00:19:15,309 --> 00:19:24,549
fetch all the images from it so what do

00:19:21,250 --> 00:19:26,139
you do you start with you decide to do

00:19:24,549 --> 00:19:28,620
that in Kotlin so you do something like

00:19:26,139 --> 00:19:33,970
this you have this produce function and

00:19:28,620 --> 00:19:39,159
which creates as co-routine and binds it

00:19:33,970 --> 00:19:41,440
to a channel so we return scrapp gets an

00:19:39,159 --> 00:19:43,419
URL and returns err

00:19:41,440 --> 00:19:46,090
if channel let's say it's channel

00:19:43,419 --> 00:19:49,809
strings and then inside the core it in

00:19:46,090 --> 00:19:52,240
your fetch HTML you parse it so you'll

00:19:49,809 --> 00:19:55,659
get all the links from it and then you

00:19:52,240 --> 00:20:00,970
start sending the links over the channel

00:19:55,659 --> 00:20:04,690
for somebody else to consume and what

00:20:00,970 --> 00:20:06,879
what design pattern is this so you

00:20:04,690 --> 00:20:11,289
probably wrote something like like this

00:20:06,879 --> 00:20:18,759
if you use coding and it's actually

00:20:11,289 --> 00:20:20,889
called ecto it has two goals to

00:20:18,759 --> 00:20:23,100
encapsulate concurrency on one hand so

00:20:20,889 --> 00:20:27,039
that's what co-routine does in our case

00:20:23,100 --> 00:20:30,279
and it communicates using message queues

00:20:27,039 --> 00:20:36,190
so our channel is a message queue in

00:20:30,279 --> 00:20:38,259
this case in some languages and some

00:20:36,190 --> 00:20:42,490
documentation you may see that message

00:20:38,259 --> 00:20:46,210
queues are called mailboxes and often

00:20:42,490 --> 00:20:48,519
you'll have two mailboxes characters so

00:20:46,210 --> 00:20:49,629
one for incoming messages and one for

00:20:48,519 --> 00:20:51,820
outgoing messages

00:20:49,629 --> 00:20:55,659
but it's not mandatory as long as you

00:20:51,820 --> 00:20:57,789
have some kind of core routine and at

00:20:55,659 --> 00:21:02,559
least one channel you implemented an

00:20:57,789 --> 00:21:09,730
actor this model was popularized by

00:21:02,559 --> 00:21:14,139
Airlink in 90's and also akka framework

00:21:09,730 --> 00:21:17,340
from muscala uses this model and it's

00:21:14,139 --> 00:21:21,429
pretty successful so the accompanying

00:21:17,340 --> 00:21:26,080
function to produce is actually called

00:21:21,429 --> 00:21:28,450
actor and I think about a month or two

00:21:26,080 --> 00:21:30,610
ago there was a discussion on Kotlin

00:21:28,450 --> 00:21:33,669
forums about whether it should be called

00:21:30,610 --> 00:21:37,629
an actor because it's if it's an actor

00:21:33,669 --> 00:21:40,600
it's very lightweight actor but Roman

00:21:37,629 --> 00:21:43,120
Eleazar of say yeah probably it's still

00:21:40,600 --> 00:21:47,980
an actor okay let's continue with our

00:21:43,120 --> 00:21:50,619
example and so we produce these images

00:21:47,980 --> 00:21:53,080
and those links we send them over the

00:21:50,619 --> 00:21:55,180
channel what do we do next

00:21:53,080 --> 00:21:57,790
so we

00:21:55,180 --> 00:22:00,790
like we could of course download them

00:21:57,790 --> 00:22:03,040
why one by one but hey we are not in

00:22:00,790 --> 00:22:06,700
Ruby to do that right we can we have

00:22:03,040 --> 00:22:10,920
coffee at least so we would like to

00:22:06,700 --> 00:22:15,010
spawn a few downloaders instead of one

00:22:10,920 --> 00:22:17,800
and then each download or gets the same

00:22:15,010 --> 00:22:21,490
channel actually it could be done a bit

00:22:17,800 --> 00:22:23,680
simpler now I I did it because in the

00:22:21,490 --> 00:22:26,020
real code it's a bit more complicated he

00:22:23,680 --> 00:22:28,770
has two channels but in this example it

00:22:26,020 --> 00:22:31,900
is only inbound channel and then we

00:22:28,770 --> 00:22:34,930
start each downloader each downloader

00:22:31,900 --> 00:22:37,750
waits on the channel and if you have

00:22:34,930 --> 00:22:41,680
like eight CPUs we can launch eight

00:22:37,750 --> 00:22:44,770
downloaders for example only one of the

00:22:41,680 --> 00:22:47,500
download or C wins every time so message

00:22:44,770 --> 00:22:53,260
arrives to only one and then it starts

00:22:47,500 --> 00:22:58,680
downloading the image so it's called the

00:22:53,260 --> 00:23:01,330
fan-out when I distribute this work now

00:22:58,680 --> 00:23:04,090
when have single channel and I

00:23:01,330 --> 00:23:04,870
distribute work I've crossed a few

00:23:04,090 --> 00:23:11,620
actors

00:23:04,870 --> 00:23:14,530
it's a fan-out and it has two main

00:23:11,620 --> 00:23:18,460
benefits when a one is it's very

00:23:14,530 --> 00:23:20,980
scalable so as I said if I have eight

00:23:18,460 --> 00:23:24,970
CPUs I can create eight actors so maybe

00:23:20,980 --> 00:23:27,070
I decide to create 16 or if for some

00:23:24,970 --> 00:23:29,500
reason I want to reduce the load I can

00:23:27,070 --> 00:23:33,160
just reduce the amount of factors and it

00:23:29,500 --> 00:23:37,570
will all be done in run time we're

00:23:33,160 --> 00:23:41,380
continuing so we got those links we

00:23:37,570 --> 00:23:43,420
download the images and now we need to

00:23:41,380 --> 00:23:46,750
store them to disk so of course we can

00:23:43,420 --> 00:23:49,780
decide that each of our download there's

00:23:46,750 --> 00:23:52,930
also or can write to this technically

00:23:49,780 --> 00:23:55,030
it's possible but it's not really a

00:23:52,930 --> 00:23:59,020
clean code it's not really a good

00:23:55,030 --> 00:24:02,410
separation of concerns so it would be

00:23:59,020 --> 00:24:05,500
more effective if one will have only one

00:24:02,410 --> 00:24:08,430
or only a few of them and that would

00:24:05,500 --> 00:24:11,430
write to disk so what do we do

00:24:08,430 --> 00:24:14,910
we create this time we can use actually

00:24:11,430 --> 00:24:17,160
the actor function now which receives

00:24:14,910 --> 00:24:19,370
some kind of messages so in this case it

00:24:17,160 --> 00:24:24,540
doesn't make sense to send anonymous

00:24:19,370 --> 00:24:27,360
bytes arrays so we'll send some that

00:24:24,540 --> 00:24:30,780
data class with byte array and its name

00:24:27,360 --> 00:24:35,190
and it will just wait on a channel and

00:24:30,780 --> 00:24:37,880
gather all the results so we'll go back

00:24:35,190 --> 00:24:37,880
to our code

00:24:51,520 --> 00:24:59,360
yeah

00:24:53,980 --> 00:25:02,870
and that's what it looks like so I must

00:24:59,360 --> 00:25:05,409
say that when I showed you the multi

00:25:02,870 --> 00:25:09,470
reactor design pattern I cheated a bit I

00:25:05,409 --> 00:25:12,399
recorded the results ahead of time and

00:25:09,470 --> 00:25:13,610
then I just visualized them in

00:25:12,399 --> 00:25:17,679
JavaScript

00:25:13,610 --> 00:25:20,149
this actually runs in real time so I'm

00:25:17,679 --> 00:25:24,529
pretty scared because it may get stuck

00:25:20,149 --> 00:25:27,220
and what happens here is all the code I

00:25:24,529 --> 00:25:31,490
showed you about the downloaders and

00:25:27,220 --> 00:25:33,950
other actors it actually runs now and

00:25:31,490 --> 00:25:38,870
each time I send a message over a

00:25:33,950 --> 00:25:42,860
channel and i duplicate it and I send it

00:25:38,870 --> 00:25:45,320
over a WebSocket to UI so this is all

00:25:42,860 --> 00:25:47,840
happens in real time and we have the

00:25:45,320 --> 00:25:50,330
HTML feature that fetches all the links

00:25:47,840 --> 00:25:53,720
and then because I have eight CPU so I

00:25:50,330 --> 00:25:57,320
decided to create eight image features

00:25:53,720 --> 00:26:00,740
downloaders and then they are sending

00:25:57,320 --> 00:26:04,700
their results they downloaded images to

00:26:00,740 --> 00:26:08,360
a single image saver you can see the

00:26:04,700 --> 00:26:10,640
counts you can see that downloaded in

00:26:08,360 --> 00:26:14,120
getting the links and distributing them

00:26:10,640 --> 00:26:16,130
is very fast actually I had to slow it

00:26:14,120 --> 00:26:20,210
down because otherwise it would finish

00:26:16,130 --> 00:26:24,169
in a few seconds and and downloading the

00:26:20,210 --> 00:26:28,700
images was of course much much slower so

00:26:24,169 --> 00:26:31,760
yeah I try to visualize that and from

00:26:28,700 --> 00:26:35,870
here you also can see where the names

00:26:31,760 --> 00:26:40,130
are coming from because this is fan-out

00:26:35,870 --> 00:26:44,779
and the lower part is actually Fanning

00:26:40,130 --> 00:26:47,750
so we have spreading and gathering again

00:26:44,779 --> 00:26:51,799
and so in concurrent design patterns

00:26:47,750 --> 00:26:54,320
it's called fan infant out in other

00:26:51,799 --> 00:26:54,830
places you may hear of that as Map

00:26:54,320 --> 00:26:58,149
Reduce

00:26:54,830 --> 00:27:01,789
or divide and conquer it's all the same

00:26:58,149 --> 00:27:04,460
principle so we've seen what it looks

00:27:01,789 --> 00:27:06,070
like and as I said it's called the fan

00:27:04,460 --> 00:27:08,560
in design pattern

00:27:06,070 --> 00:27:12,790
allows together results from multiple

00:27:08,560 --> 00:27:15,550
sources and its advantage is that it

00:27:12,790 --> 00:27:19,360
decoupled from producers so if we can

00:27:15,550 --> 00:27:23,880
add more actors or reduce the number of

00:27:19,360 --> 00:27:26,650
vectors in the fan-out design pattern

00:27:23,880 --> 00:27:29,500
softening also supports that I could

00:27:26,650 --> 00:27:35,110
have only two producers and it will

00:27:29,500 --> 00:27:43,450
still work and now my animation is a bit

00:27:35,110 --> 00:27:50,460
wrong I'll go back to it and because it

00:27:43,450 --> 00:27:53,380
may seem that I have sixteen channels

00:27:50,460 --> 00:27:55,540
eight incoming channels and eight

00:27:53,380 --> 00:27:58,930
outgoing channels and that's not the

00:27:55,540 --> 00:28:09,070
case I actually have only two so let's

00:27:58,930 --> 00:28:13,800
try to see that yeah and that's what it

00:28:09,070 --> 00:28:18,070
actually looks like so I have one

00:28:13,800 --> 00:28:21,160
channel to send send those links and I

00:28:18,070 --> 00:28:25,600
have another channel to communicate with

00:28:21,160 --> 00:28:28,300
the image saver and again you can see

00:28:25,600 --> 00:28:33,580
the times that downloading the images

00:28:28,300 --> 00:28:36,430
take takes much more time although those

00:28:33,580 --> 00:28:43,660
examples are available so you can run in

00:28:36,430 --> 00:28:46,540
them later okay so to summarize design

00:28:43,660 --> 00:28:49,300
patterns are everywhere even though you

00:28:46,540 --> 00:28:52,290
may be not aware of them and they are

00:28:49,300 --> 00:28:57,130
not limited to the again before book

00:28:52,290 --> 00:29:00,780
different programming languages use

00:28:57,130 --> 00:29:03,330
different concurrency models but the

00:29:00,780 --> 00:29:06,280
awesome part of Cortland that it

00:29:03,330 --> 00:29:08,620
incorporates different concurrency

00:29:06,280 --> 00:29:11,950
models in the same language so we've

00:29:08,620 --> 00:29:15,340
seen event loop we've seen multi reactor

00:29:11,950 --> 00:29:18,160
we've seen actors and it's all in the

00:29:15,340 --> 00:29:18,680
same language it's flexible enough so

00:29:18,160 --> 00:29:22,580
you

00:29:18,680 --> 00:29:26,780
choose what's the best tool for for your

00:29:22,580 --> 00:29:29,000
case a bit of references so if you're

00:29:26,780 --> 00:29:32,930
interested in classical design patterns

00:29:29,000 --> 00:29:35,390
those are two great books like let's put

00:29:32,930 --> 00:29:36,950
it like that design patterns the classic

00:29:35,390 --> 00:29:39,950
one it's pretty hard to read nowadays

00:29:36,950 --> 00:29:40,460
ahead first design patterns is totally

00:29:39,950 --> 00:29:44,150
awesome

00:29:40,460 --> 00:29:46,040
there's also my book it has one or two

00:29:44,150 --> 00:29:48,590
chapters about specifically concurrent

00:29:46,040 --> 00:29:52,330
design patterns and coding so thank you

00:29:48,590 --> 00:29:54,830
very much that's the link to the

00:29:52,330 --> 00:29:58,400
concurrency examples which you can run

00:29:54,830 --> 00:30:01,930
and now I must say that Cortland code is

00:29:58,400 --> 00:30:04,940
pretty good don't look too much into

00:30:01,930 --> 00:30:08,690
javascript code because it's vanilla

00:30:04,940 --> 00:30:12,140
JavaScript and I'm not very proficient

00:30:08,690 --> 00:30:14,330
JavaScript developer and if you like to

00:30:12,140 --> 00:30:18,950
keep a touch there is my Twitter link

00:30:14,330 --> 00:30:20,980
Stack Overflow and the github so thank

00:30:18,950 --> 00:30:23,450
you very much if you have any question

00:30:20,980 --> 00:30:25,440
questions just feel free to catch me

00:30:23,450 --> 00:30:29,309
later thank you

00:30:25,440 --> 00:30:29,309

YouTube URL: https://www.youtube.com/watch?v=IN6mNxTW47w


