Title: GRCon19 - AI and SDR: Software Meets Hardware Again... by Manuel Uhm
Publication date: 2019-11-05
Playlist: GRCon 2019
Description: 
	AI and SDR: Software Meets Hardware Again... by Manuel Uhm, Jason Vidmar

Over the course of the last 30 years, SDR has become the de facto industry standard for the implementation of waveforms for communications, both military and commercial. During that time, the desire for waveforms to be fully realized in software running on general purpose processors (GPPs) had to be tempered against size, weight and power (SWaP) restrictions that required compute intensive portions of the waveform software to be run on hardware such as field programmable gate arrays (FPGAs) or hardened IP accelerators.

More recently, artificial intelligence (AI) and Machine Learning (ML) have come to the forefront of research efforts worldwide. Led by the development of open source ML frameworks, such as TensorFlow and PyTorch, there is again a desire for AI/ML algorithms to be fully realized in software which has to be balanced against SWaP restrictions, particularly for inference at the edge. Is the fate of AI/ML to follow the course of SDR technology development in combining both software and hardware development to get to market?

Fortunately, there have been technology advancements in both the semiconductor and tools industry which will greatly influence the answer to this question. In this presentation, we will discuss a new category of heterogeneous processor, the Adaptive Compute Acceleration Platform (ACAP), and the supporting tools which will make hardware far more accessible to software developers and AI/data scientists, for both AI/ML processing, as well as increasingly compute intensive communication needs, such as anti-jam, MIMO and adaptive beam forming.
Captions: 
	00:00:14,809 --> 00:00:19,279
okay so my name is Manuel um I'm

00:00:17,360 --> 00:00:21,400
director of silicon marketing at SCI

00:00:19,279 --> 00:00:24,020
links which means that I have

00:00:21,400 --> 00:00:26,270
responsibility for all silicon and Silex

00:00:24,020 --> 00:00:27,680
I'm also chair of the board of directors

00:00:26,270 --> 00:00:29,300
of the wireless innovation forum which

00:00:27,680 --> 00:00:31,430
some of you may remember is the SDR

00:00:29,300 --> 00:00:34,100
forum so I've been involved in SDR for a

00:00:31,430 --> 00:00:36,440
long time and my partner in crime mister

00:00:34,100 --> 00:00:38,690
Jason vidmar who is our senior System

00:00:36,440 --> 00:00:41,360
Architect for millicom SATCOM and

00:00:38,690 --> 00:00:42,320
machine learning that's Alex so today

00:00:41,360 --> 00:00:45,170
we're going to talk a little bit about

00:00:42,320 --> 00:00:46,789
AI and software-defined radio I think

00:00:45,170 --> 00:00:49,030
most people recognize that the years are

00:00:46,789 --> 00:00:51,679
these are trends that are converging and

00:00:49,030 --> 00:00:54,379
what we find interesting is the

00:00:51,679 --> 00:00:58,280
evolution of SDR over multiple decades

00:00:54,379 --> 00:00:59,870
now followed a track that has a lot of

00:00:58,280 --> 00:01:01,850
parallels that were seen with artificial

00:00:59,870 --> 00:01:04,159
intelligence and processing for

00:01:01,850 --> 00:01:05,659
artificial intelligence and specifically

00:01:04,159 --> 00:01:08,300
where I talk about software meets

00:01:05,659 --> 00:01:10,490
Hardware again you know the goal way

00:01:08,300 --> 00:01:12,260
back in the day of the JT RS program I'm

00:01:10,490 --> 00:01:14,180
going to even preach a TRS with programs

00:01:12,260 --> 00:01:17,510
like Speak Easy was to have your

00:01:14,180 --> 00:01:19,640
waveform run on a CD yes a CD remember

00:01:17,510 --> 00:01:21,619
those and just be able to run on a

00:01:19,640 --> 00:01:23,680
general-purpose processor everything's

00:01:21,619 --> 00:01:26,840
good all software and then of course

00:01:23,680 --> 00:01:28,990
reality struck and it wasn't possible to

00:01:26,840 --> 00:01:30,920
do that within the size weight and power

00:01:28,990 --> 00:01:33,619
restrictions that you have within a

00:01:30,920 --> 00:01:35,840
typical tactical radio and so you need

00:01:33,619 --> 00:01:39,439
it too tightly couple software with

00:01:35,840 --> 00:01:42,409
hardware through devices like FPGAs well

00:01:39,439 --> 00:01:45,799
with AI we're seeing a pretty similar

00:01:42,409 --> 00:01:48,020
trend where you know ideally yes you can

00:01:45,799 --> 00:01:49,700
just take your tensor flows and put them

00:01:48,020 --> 00:01:51,530
into a general-purpose processor and

00:01:49,700 --> 00:01:53,960
you're off to the races but again I

00:01:51,530 --> 00:01:55,729
think we see from a compute density

00:01:53,960 --> 00:01:58,399
perspective a lot of the same challenges

00:01:55,729 --> 00:02:00,560
and so we certainly believe that

00:01:58,399 --> 00:02:03,320
software tightly coupled with hardware

00:02:00,560 --> 00:02:07,429
is also going to be the trend for

00:02:03,320 --> 00:02:08,990
actually applying AI in the field so

00:02:07,429 --> 00:02:11,510
going back to SDR and talking a little

00:02:08,990 --> 00:02:13,820
bit about the history so SDR essentially

00:02:11,510 --> 00:02:15,290
is a de-facto standard today it's in

00:02:13,820 --> 00:02:17,570
every handset in the world it's in

00:02:15,290 --> 00:02:19,910
pretty much every radio that you see

00:02:17,570 --> 00:02:22,460
these days and you know we've gone

00:02:19,910 --> 00:02:24,019
through successive generations and so it

00:02:22,460 --> 00:02:26,989
started way back in the day where you

00:02:24,019 --> 00:02:27,960
had CBN systems electronic warfare

00:02:26,989 --> 00:02:30,360
systems

00:02:27,960 --> 00:02:32,100
like safety systems all using some type

00:02:30,360 --> 00:02:34,530
of software-defined radio and in this

00:02:32,100 --> 00:02:36,090
case I'm using the definition that the

00:02:34,530 --> 00:02:38,430
wireless innovation forum uses which is

00:02:36,090 --> 00:02:40,980
a radio in which some are all of the

00:02:38,430 --> 00:02:44,130
physical air is programmable okay so by

00:02:40,980 --> 00:02:46,850
that definition all these radios were

00:02:44,130 --> 00:02:50,310
software-defined radio then Along Came

00:02:46,850 --> 00:02:52,080
Jay TRS with a tactical radio market

00:02:50,310 --> 00:02:54,720
which created kind of this huge

00:02:52,080 --> 00:02:57,360
disturbance and benefited really from

00:02:54,720 --> 00:03:00,030
two main semiconductor trends one was

00:02:57,360 --> 00:03:04,440
use of FPGAs for signal processing and

00:03:00,030 --> 00:03:07,130
also the availability of affordable RFI

00:03:04,440 --> 00:03:09,360
C's that had the type of dynamic range

00:03:07,130 --> 00:03:11,660
that was required for our

00:03:09,360 --> 00:03:14,970
software-defined radios for the military

00:03:11,660 --> 00:03:16,920
so from there technology continued to

00:03:14,970 --> 00:03:18,780
evolve of course from a processing

00:03:16,920 --> 00:03:21,780
perspective there was a lot of benefit

00:03:18,780 --> 00:03:25,500
from Moore's law and so continue to ride

00:03:21,780 --> 00:03:28,200
that trend and with 4G again you see

00:03:25,500 --> 00:03:30,840
this situation where every base station

00:03:28,200 --> 00:03:34,260
and every handset was a software-defined

00:03:30,840 --> 00:03:37,410
radio and so that evolution continued

00:03:34,260 --> 00:03:39,120
now we're seeing it with 5g and the

00:03:37,410 --> 00:03:40,620
trend now is towards even more

00:03:39,120 --> 00:03:42,270
integration so analog and digital

00:03:40,620 --> 00:03:45,480
integration through products like

00:03:42,270 --> 00:03:47,550
silences RF SOC is one example but

00:03:45,480 --> 00:03:48,870
there's many other examples where again

00:03:47,550 --> 00:03:51,630
the goal is bringing things together

00:03:48,870 --> 00:03:53,850
very tightly have it smaller size weight

00:03:51,630 --> 00:03:56,630
and power and be more efficient from a

00:03:53,850 --> 00:03:56,630
processing perspective

00:03:57,350 --> 00:04:03,090
okay so ai has been kind of a newer

00:04:00,840 --> 00:04:06,210
domain in terms of the evolution but as

00:04:03,090 --> 00:04:08,850
we all know it's growing and increasing

00:04:06,210 --> 00:04:11,550
exponentially and so there's a lot of

00:04:08,850 --> 00:04:13,470
evolution happening very quickly now and

00:04:11,550 --> 00:04:15,180
again we've seen this trend move from

00:04:13,470 --> 00:04:17,070
artificial intelligence to machine

00:04:15,180 --> 00:04:20,790
learning now it's all about deep

00:04:17,070 --> 00:04:22,350
learning moving from CNN's to DNS but

00:04:20,790 --> 00:04:24,960
from a technology perspective on the

00:04:22,350 --> 00:04:28,830
semiconductor side again definitely

00:04:24,960 --> 00:04:30,780
seems to benefits from Moore's law GPUs

00:04:28,830 --> 00:04:33,600
have certainly had a large role to play

00:04:30,780 --> 00:04:36,240
here because again throwing tensors at a

00:04:33,600 --> 00:04:38,340
GPP hasn't practically been the answer

00:04:36,240 --> 00:04:42,130
for getting AI out into the field and

00:04:38,340 --> 00:04:44,920
deployed certainly FPGAs also have had

00:04:42,130 --> 00:04:46,750
and definitely Asics you've seen Asics

00:04:44,920 --> 00:04:50,200
from companies like Google with GPUs

00:04:46,750 --> 00:04:53,110
there's many startups now have a I

00:04:50,200 --> 00:04:55,600
focused semiconductor devices and so

00:04:53,110 --> 00:04:57,130
Asics are coming back into play there

00:04:55,600 --> 00:04:58,660
may be a large enough market in the end

00:04:57,130 --> 00:05:04,720
for artificial intelligence for there to

00:04:58,660 --> 00:05:06,160
be ASIC based solutions so a lot of

00:05:04,720 --> 00:05:08,410
similar trends that we're seeing here

00:05:06,160 --> 00:05:10,900
and of course really gets interesting is

00:05:08,410 --> 00:05:13,090
the fact that these are converging right

00:05:10,900 --> 00:05:15,490
so now you have a situation where

00:05:13,090 --> 00:05:18,160
software defined radio compute density

00:05:15,490 --> 00:05:22,210
was scaley and beyond what Gbps could do

00:05:18,160 --> 00:05:24,190
an AI with the same problem and now

00:05:22,210 --> 00:05:27,030
you're combining them which makes for an

00:05:24,190 --> 00:05:30,100
even worse problem as you know and so

00:05:27,030 --> 00:05:32,890
really we're having this convergence

00:05:30,100 --> 00:05:34,840
from an SDR and AI payload and it

00:05:32,890 --> 00:05:37,660
started with cognitive radio and when I

00:05:34,840 --> 00:05:39,340
say cognitive radio I'm referring to the

00:05:37,660 --> 00:05:41,980
way that Joe Mottola originally coined

00:05:39,340 --> 00:05:44,050
the term which was a radio that actually

00:05:41,980 --> 00:05:46,510
had some form of cognition that could

00:05:44,050 --> 00:05:48,700
actually identify scenarios like okay

00:05:46,510 --> 00:05:50,890
the warfighter is getting bombed send a

00:05:48,700 --> 00:05:53,620
distress signal right or call in a

00:05:50,890 --> 00:05:55,570
strike that not the sort of lesser term

00:05:53,620 --> 00:05:58,180
which is kind of become more commonplace

00:05:55,570 --> 00:06:00,010
which is a frequency agile radio so

00:05:58,180 --> 00:06:02,590
really a radio with some form of

00:06:00,010 --> 00:06:04,510
cognition it could also have adaptive

00:06:02,590 --> 00:06:06,370
characteristics on the wave form where

00:06:04,510 --> 00:06:08,740
again it's adapting dynamically it's not

00:06:06,370 --> 00:06:10,540
doing it because a human is changing

00:06:08,740 --> 00:06:12,910
some type of setting it could also be

00:06:10,540 --> 00:06:14,320
doing interference mitigation so

00:06:12,910 --> 00:06:16,240
cognitive radio is pretty well

00:06:14,320 --> 00:06:18,880
established from a technology and a

00:06:16,240 --> 00:06:21,850
payload perspective so go you know why

00:06:18,880 --> 00:06:25,330
not call it to radar right so having

00:06:21,850 --> 00:06:26,800
radars that have pulse or you know pulse

00:06:25,330 --> 00:06:29,290
frequencies that are repetitive at

00:06:26,800 --> 00:06:32,650
different dynamics dynamically different

00:06:29,290 --> 00:06:35,830
times different waveforms being able to

00:06:32,650 --> 00:06:38,320
be more stealth right so cognitive radar

00:06:35,830 --> 00:06:41,680
is also something that's starting to

00:06:38,320 --> 00:06:44,590
become more commonplace so now you have

00:06:41,680 --> 00:06:46,210
this plethora of data right that you

00:06:44,590 --> 00:06:47,380
generated through all these cognitive

00:06:46,210 --> 00:06:50,200
radios through all these cognitive

00:06:47,380 --> 00:06:52,690
radars well you need to turn that data

00:06:50,200 --> 00:06:55,510
and information right into intelligence

00:06:52,690 --> 00:06:57,640
and so how about cognitive secant

00:06:55,510 --> 00:06:59,770
right I mean the human ability to

00:06:57,640 --> 00:07:02,230
process that amount of data is extremely

00:06:59,770 --> 00:07:05,020
limited and so the demand there is now

00:07:02,230 --> 00:07:06,960
for cognitive SIGINT systems and these

00:07:05,020 --> 00:07:09,160
sigit systems are doing things like

00:07:06,960 --> 00:07:11,230
detection and classification of unknown

00:07:09,160 --> 00:07:14,500
signals is just one fairly simple

00:07:11,230 --> 00:07:16,540
example well now you have all this

00:07:14,500 --> 00:07:18,670
information what do you do with the

00:07:16,540 --> 00:07:21,580
information right so you have to turn

00:07:18,670 --> 00:07:24,310
that information into action and so now

00:07:21,580 --> 00:07:26,410
you need cognitive UW systems right and

00:07:24,310 --> 00:07:28,930
these W systems may be doing jamming

00:07:26,410 --> 00:07:30,760
they may be doing anti jamming in the RF

00:07:28,930 --> 00:07:33,100
domain there's many different things

00:07:30,760 --> 00:07:35,140
which they could do but again the goal

00:07:33,100 --> 00:07:38,190
is to have a system which has some level

00:07:35,140 --> 00:07:41,920
of cognition some level of AI

00:07:38,190 --> 00:07:43,780
implementation and capability and I

00:07:41,920 --> 00:07:46,690
think overall the goal is really to have

00:07:43,780 --> 00:07:49,090
what in the defense space I think folks

00:07:46,690 --> 00:07:53,410
would call a multi mission situationally

00:07:49,090 --> 00:07:56,980
aware payload okay so a payload that's

00:07:53,410 --> 00:07:59,470
capable of doing radar radio signals

00:07:56,980 --> 00:08:01,600
intelligence electronic warfare be aware

00:07:59,470 --> 00:08:03,940
of the situation and act accordingly and

00:08:01,600 --> 00:08:05,340
to do this you're going to need SDR and

00:08:03,940 --> 00:08:08,980
AI technology

00:08:05,340 --> 00:08:11,770
okay that's great so let's come back to

00:08:08,980 --> 00:08:13,210
the processor problem right so I talked

00:08:11,770 --> 00:08:14,560
a little bit earlier about Moore's Law

00:08:13,210 --> 00:08:16,540
most people are familiar with Moore's

00:08:14,560 --> 00:08:19,440
law there's plenty of other laws in the

00:08:16,540 --> 00:08:22,260
semiconductor world if you combine

00:08:19,440 --> 00:08:26,230
Dennard scaling with Moore's law

00:08:22,260 --> 00:08:30,550
basically the in what you get is a

00:08:26,230 --> 00:08:33,760
doubling in performance per watt every

00:08:30,550 --> 00:08:36,580
two years now it's generally agreed upon

00:08:33,760 --> 00:08:39,250
in the semiconductor industry that we

00:08:36,580 --> 00:08:42,340
reached the end of this probably about a

00:08:39,250 --> 00:08:44,350
decade ago there are other laws that

00:08:42,340 --> 00:08:46,690
have kicked in like AM dolls law

00:08:44,350 --> 00:08:49,060
so having multi-core going

00:08:46,690 --> 00:08:51,310
multi-threading but the issue there is

00:08:49,060 --> 00:08:54,100
am das law states that performance

00:08:51,310 --> 00:08:56,110
doesn't scale linearly right and so you

00:08:54,100 --> 00:08:59,380
can't just throw more cores the problem

00:08:56,110 --> 00:09:03,280
eventually you saturate and you just run

00:08:59,380 --> 00:09:06,700
out of juice so we've made pretty

00:09:03,280 --> 00:09:07,820
incredible gains and customers consumers

00:09:06,700 --> 00:09:10,160
have expected

00:09:07,820 --> 00:09:11,960
this and unfortunately we're at this

00:09:10,160 --> 00:09:14,000
point now with processor and subbing

00:09:11,960 --> 00:09:16,040
conductor technology where that's just

00:09:14,000 --> 00:09:18,470
not good enough you can't just rely on

00:09:16,040 --> 00:09:20,810
Moore's law to solve the problem

00:09:18,470 --> 00:09:23,090
especially problem as tough as software

00:09:20,810 --> 00:09:28,220
compute performance and AI compute

00:09:23,090 --> 00:09:29,930
performance together so moving forward

00:09:28,220 --> 00:09:31,790
in the industry that has been talked

00:09:29,930 --> 00:09:33,680
about domain-specific architectures

00:09:31,790 --> 00:09:35,000
because by no means does the

00:09:33,680 --> 00:09:37,070
semiconductor industry throwing in the

00:09:35,000 --> 00:09:38,510
towel of course there's new things so

00:09:37,070 --> 00:09:40,670
what are these new things what are these

00:09:38,510 --> 00:09:42,500
domain-specific architectures and how do

00:09:40,670 --> 00:09:44,600
they impact how one would design the

00:09:42,500 --> 00:09:49,250
processor for a software-defined radio

00:09:44,600 --> 00:09:52,070
and an AI intelligent radio so if you

00:09:49,250 --> 00:09:54,050
look at the landscape today again

00:09:52,070 --> 00:09:56,150
general-purpose processors are not going

00:09:54,050 --> 00:09:59,180
anywhere they span a plethora of

00:09:56,150 --> 00:10:01,910
applications they're applicable in a

00:09:59,180 --> 00:10:04,940
wide variety of scenarios if not almost

00:10:01,910 --> 00:10:08,080
all scenarios but they're limited on the

00:10:04,940 --> 00:10:09,980
performance and performance per watt a

00:10:08,080 --> 00:10:12,560
six and a SSPs

00:10:09,980 --> 00:10:15,220
this is interesting because there was a

00:10:12,560 --> 00:10:17,320
lot of talk actually over successive

00:10:15,220 --> 00:10:20,510
generations of semiconductor technology

00:10:17,320 --> 00:10:21,410
that okay it's too expensive to do a six

00:10:20,510 --> 00:10:23,990
and a SSPs

00:10:21,410 --> 00:10:25,790
and for the most part I'd say that's

00:10:23,990 --> 00:10:28,760
been true we've seen design starts

00:10:25,790 --> 00:10:30,830
slowed down significantly but actually

00:10:28,760 --> 00:10:33,650
recently they've actually started up

00:10:30,830 --> 00:10:34,490
again despite the cost of doing a six

00:10:33,650 --> 00:10:37,040
and a SSPs

00:10:34,490 --> 00:10:39,410
and part of that is again this evolution

00:10:37,040 --> 00:10:41,840
to trying to achieve artificial

00:10:39,410 --> 00:10:44,090
intelligent type processors which

00:10:41,840 --> 00:10:45,710
require something different so for

00:10:44,090 --> 00:10:48,650
markets with enough volume it's a big

00:10:45,710 --> 00:10:50,660
bet but Asics and Asus peas certainly I

00:10:48,650 --> 00:10:52,850
don't expect to go away anytime soon and

00:10:50,660 --> 00:10:54,560
if you look at your handset that's gonna

00:10:52,850 --> 00:10:58,580
be the typical solution that we're gonna

00:10:54,560 --> 00:11:01,520
see now FPGA is kind of fill that gap

00:10:58,580 --> 00:11:04,580
right in the middle there where you need

00:11:01,520 --> 00:11:05,870
something that's more compute dense has

00:11:04,580 --> 00:11:09,350
more performance than a general-purpose

00:11:05,870 --> 00:11:11,570
processor but has more flexibility more

00:11:09,350 --> 00:11:12,770
ability to differentiate and evolve than

00:11:11,570 --> 00:11:14,420
an ASIC or an ASSP

00:11:12,770 --> 00:11:17,960
it's a trade-off because it's never

00:11:14,420 --> 00:11:20,390
going to be as powerful or as low cost

00:11:17,960 --> 00:11:21,410
as an ASIC or a SSP when you talk about

00:11:20,390 --> 00:11:26,619
per unit

00:11:21,410 --> 00:11:29,149
price so if that's where we are today

00:11:26,619 --> 00:11:32,599
domain-specific architectures we see is

00:11:29,149 --> 00:11:35,089
fitting somewhere around here where you

00:11:32,599 --> 00:11:37,759
have something that silence has called

00:11:35,089 --> 00:11:39,349
an a cap adaptive compute acceleration

00:11:37,759 --> 00:11:41,059
platform and I'll go into the details of

00:11:39,349 --> 00:11:43,339
that in a minute but it's a

00:11:41,059 --> 00:11:45,109
domain-specific architecture which means

00:11:43,339 --> 00:11:47,059
we specifically done things in the

00:11:45,109 --> 00:11:52,179
silicon targeted towards specific

00:11:47,059 --> 00:11:56,229
domains which means it's in some ways

00:11:52,179 --> 00:11:58,729
less general-purpose than a general FPGA

00:11:56,229 --> 00:12:00,289
okay so then why is it seemed to be more

00:11:58,729 --> 00:12:02,029
applicable because the way we've

00:12:00,289 --> 00:12:04,309
implemented it through heterogeneous

00:12:02,029 --> 00:12:06,949
processing actually means you can scale

00:12:04,309 --> 00:12:09,229
it to multiple different domains and as

00:12:06,949 --> 00:12:12,399
folks know SDR and AI technology are

00:12:09,229 --> 00:12:14,899
broadly applicable to many markets and

00:12:12,399 --> 00:12:17,899
it allows that increase in performance

00:12:14,899 --> 00:12:18,829
and performance per power that customers

00:12:17,899 --> 00:12:21,439
are used to getting

00:12:18,829 --> 00:12:23,979
even though Moore's law has basically

00:12:21,439 --> 00:12:26,239
come to an end

00:12:23,979 --> 00:12:28,429
okay so I'm going to talk quickly

00:12:26,239 --> 00:12:32,779
through adaptive compute acceleration

00:12:28,429 --> 00:12:37,939
platform there's one here so these

00:12:32,779 --> 00:12:39,889
devices are real and I'll just quickly

00:12:37,939 --> 00:12:42,379
go through it by going through the names

00:12:39,889 --> 00:12:44,299
so why did we call it an a cap well

00:12:42,379 --> 00:12:46,669
adaptive I think that speaks for itself

00:12:44,299 --> 00:12:49,309
multiple workloads it's kind of what

00:12:46,669 --> 00:12:51,859
Xilinx is known for with previous

00:12:49,309 --> 00:12:54,229
generations of FPGAs so again with an a

00:12:51,859 --> 00:12:57,949
cap we're still benefiting from that

00:12:54,229 --> 00:13:00,559
adaptive nature compute acceleration

00:12:57,949 --> 00:13:03,409
okay heterogeneous processing it's clear

00:13:00,559 --> 00:13:06,919
one processor type isn't gonna win you

00:13:03,409 --> 00:13:09,619
can't just use FPGA fabric you can't

00:13:06,919 --> 00:13:11,600
just use a GPU and you can't just use a

00:13:09,619 --> 00:13:15,229
GPP all for a variety of different

00:13:11,600 --> 00:13:18,649
reasons and so the goal here for us has

00:13:15,229 --> 00:13:20,869
been to combine the best of all those

00:13:18,649 --> 00:13:22,549
different processor types to address as

00:13:20,869 --> 00:13:24,289
wide a set of markets as possible

00:13:22,549 --> 00:13:27,709
including SDR and artificial

00:13:24,289 --> 00:13:30,979
intelligence so we have our based scaler

00:13:27,709 --> 00:13:33,319
engines general-purpose processors we

00:13:30,979 --> 00:13:34,730
have our fabric or logic which are what

00:13:33,319 --> 00:13:37,070
we call adaptable engines

00:13:34,730 --> 00:13:41,090
and intelligent engines which are

00:13:37,070 --> 00:13:43,490
vector-based v li w processors and the

00:13:41,090 --> 00:13:46,640
DSP blocks from previous generations of

00:13:43,490 --> 00:13:48,110
FPGAs but i'll spend the most time

00:13:46,640 --> 00:13:50,540
talking about platform because actually

00:13:48,110 --> 00:13:54,470
this is what really distinguishes an a

00:13:50,540 --> 00:13:56,450
cap because everything else here is also

00:13:54,470 --> 00:13:58,190
applicable to have PGA's so what's the

00:13:56,450 --> 00:14:00,980
difference what makes an a cap and a cap

00:13:58,190 --> 00:14:02,750
it's really in the platform and the

00:14:00,980 --> 00:14:04,370
first thing I'll point out is having

00:14:02,750 --> 00:14:06,740
this software programmable silicon

00:14:04,370 --> 00:14:08,480
infrastructure okay so many of you may

00:14:06,740 --> 00:14:11,390
realize that we have something called a

00:14:08,480 --> 00:14:12,830
network on chip in this device something

00:14:11,390 --> 00:14:15,920
we've not ever had before

00:14:12,830 --> 00:14:18,020
and when I started in this role in Silex

00:14:15,920 --> 00:14:19,580
I kind of said okay that's cute we have

00:14:18,020 --> 00:14:23,120
a network on chip well so does every

00:14:19,580 --> 00:14:24,860
ASIC and ASSP in the world well when I

00:14:23,120 --> 00:14:27,650
dug more into it I started to realize

00:14:24,860 --> 00:14:29,840
okay what we've done is actually very

00:14:27,650 --> 00:14:32,870
unique and very novel because if you

00:14:29,840 --> 00:14:35,930
look at a SSPs and a6 they have a very

00:14:32,870 --> 00:14:40,970
defined data flow with very defined bit

00:14:35,930 --> 00:14:43,460
widths data rates throughputs well FPGAs

00:14:40,970 --> 00:14:45,050
in previous generations and a caps have

00:14:43,460 --> 00:14:47,090
to have flexibility they have to be able

00:14:45,050 --> 00:14:48,890
to change bit wits they have to be able

00:14:47,090 --> 00:14:50,570
to support different Layton sees they

00:14:48,890 --> 00:14:54,470
have to be able to be deterministic and

00:14:50,570 --> 00:14:55,910
so you can't just have a preset network

00:14:54,470 --> 00:14:58,460
on a chip you actually have to have a

00:14:55,910 --> 00:14:59,660
programmable network on a chip and so

00:14:58,460 --> 00:15:02,120
that's what we've done where you can

00:14:59,660 --> 00:15:04,670
change and specify bit widths those can

00:15:02,120 --> 00:15:06,590
change as the algorithm changes or as

00:15:04,670 --> 00:15:09,620
you have different algorithms you can

00:15:06,590 --> 00:15:13,450
specify constraints around latency you

00:15:09,620 --> 00:15:15,260
can have quality results and specify

00:15:13,450 --> 00:15:18,440
basically algorithms that would be

00:15:15,260 --> 00:15:20,240
deterministic so this is definitely

00:15:18,440 --> 00:15:22,070
something unique it's hardened

00:15:20,240 --> 00:15:25,010
infrastructure and yet it's programmable

00:15:22,070 --> 00:15:26,330
and that's part of how we get the

00:15:25,010 --> 00:15:28,300
reduction in power consumption the

00:15:26,330 --> 00:15:30,590
increase in performance per watt and

00:15:28,300 --> 00:15:32,150
then from a software perspective because

00:15:30,590 --> 00:15:33,950
it's not enough to have a good processor

00:15:32,150 --> 00:15:36,830
right you have to be able to program it

00:15:33,950 --> 00:15:39,830
you need development tools and really

00:15:36,830 --> 00:15:42,290
for the first time this is a platform

00:15:39,830 --> 00:15:44,360
that we've targeted where a software

00:15:42,290 --> 00:15:46,580
developer could actually develop without

00:15:44,360 --> 00:15:48,470
having to touch RTL without any view

00:15:46,580 --> 00:15:51,589
dealer verilock knowledge at all

00:15:48,470 --> 00:15:55,459
and that's again very different than

00:15:51,589 --> 00:15:58,370
before part of the other thing that

00:15:55,459 --> 00:15:59,690
we're focusing on with a cap is to do

00:15:58,370 --> 00:16:02,000
what we call accelerating the whole

00:15:59,690 --> 00:16:03,889
application so it's not just good enough

00:16:02,000 --> 00:16:05,540
to have these AI engines okay we have

00:16:03,889 --> 00:16:07,459
these AI engines what are those well

00:16:05,540 --> 00:16:09,199
Jason's going to talk more about them

00:16:07,459 --> 00:16:11,329
but you know they're essentially doing

00:16:09,199 --> 00:16:13,160
things like linear algebra matrix math

00:16:11,329 --> 00:16:15,319
things that are commonly used in AI

00:16:13,160 --> 00:16:17,269
inferencing algorithms as well as things

00:16:15,319 --> 00:16:20,389
like beamforming and other types of 5g

00:16:17,269 --> 00:16:23,029
processing but in order to make that

00:16:20,389 --> 00:16:25,370
work you have to have memory hierarchies

00:16:23,029 --> 00:16:28,880
you have to have IO so you don't have

00:16:25,370 --> 00:16:32,259
any bottlenecks in the system and so

00:16:28,880 --> 00:16:34,940
we've put in place all that hierarchy

00:16:32,259 --> 00:16:37,940
all this network on chip all this

00:16:34,940 --> 00:16:40,040
connectivity all sio to ensure that from

00:16:37,940 --> 00:16:42,529
a system level you can bring in all the

00:16:40,040 --> 00:16:46,389
data do all the processing you need and

00:16:42,529 --> 00:16:48,410
then make decisions and in this case

00:16:46,389 --> 00:16:49,730
targeting things like a tactical egg

00:16:48,410 --> 00:16:50,779
system where you might have to do

00:16:49,730 --> 00:16:52,639
adaptive beamforming

00:16:50,779 --> 00:16:59,360
or you might have to do anti jamming

00:16:52,639 --> 00:17:02,529
tactical networking etc okay so really

00:16:59,360 --> 00:17:06,740
quickly I talked about software before

00:17:02,529 --> 00:17:09,350
really the goal here is to be able to

00:17:06,740 --> 00:17:11,179
have a different set of tools that

00:17:09,350 --> 00:17:13,549
appeal to different types of developers

00:17:11,179 --> 00:17:17,480
and not force developers to all have to

00:17:13,549 --> 00:17:19,909
know VHDL or Verilog lavato is always

00:17:17,480 --> 00:17:22,850
there for those who do understand VHDL

00:17:19,909 --> 00:17:24,650
and Verilog but for those embedded

00:17:22,850 --> 00:17:26,990
developers that are used to doing things

00:17:24,650 --> 00:17:30,440
like using SDS OC in programming and see

00:17:26,990 --> 00:17:32,809
using avato HLS for example there's an

00:17:30,440 --> 00:17:34,909
internal codename tool called Scout that

00:17:32,809 --> 00:17:37,970
will actually be announced in October at

00:17:34,909 --> 00:17:42,200
silence Developer Forum and that allows

00:17:37,970 --> 00:17:44,510
folks to use tea and other os's drivers

00:17:42,200 --> 00:17:46,850
that they're used to and then at the

00:17:44,510 --> 00:17:49,790
framework level we have another tool

00:17:46,850 --> 00:17:51,500
which will allow folks to basically take

00:17:49,790 --> 00:17:53,870
tools like tensorflow

00:17:51,500 --> 00:17:58,159
or pi torch and actually implement those

00:17:53,870 --> 00:17:59,390
algorithms on their platform and so if

00:17:58,159 --> 00:18:01,620
we come back to our multi mission

00:17:59,390 --> 00:18:04,169
situationally aware UAV payload

00:18:01,620 --> 00:18:06,840
we're looking at this type of scenario

00:18:04,169 --> 00:18:08,700
where our goal is to again provide as

00:18:06,840 --> 00:18:11,610
much of the platform as much of the

00:18:08,700 --> 00:18:14,850
solution real-time operating systems but

00:18:11,610 --> 00:18:17,610
also support AI through tools that AI

00:18:14,850 --> 00:18:19,590
developers are familiar with and allow

00:18:17,610 --> 00:18:23,210
our customers to focus on the

00:18:19,590 --> 00:18:25,830
applications the comms radar SIGINT ndw

00:18:23,210 --> 00:18:27,900
and very quickly before I hand over to

00:18:25,830 --> 00:18:31,890
Jason I did quickly want to flash up

00:18:27,900 --> 00:18:34,409
this slide the two series that we've

00:18:31,890 --> 00:18:37,049
announced with versal so far our AI core

00:18:34,409 --> 00:18:38,490
and prime obviously AI core is the one

00:18:37,049 --> 00:18:40,440
that we're focusing more on today

00:18:38,490 --> 00:18:42,779
because it has the AI engines in them

00:18:40,440 --> 00:18:45,390
but you will notice going forward in

00:18:42,779 --> 00:18:47,700
fact in November we will launch AI edge

00:18:45,390 --> 00:18:49,380
which will be of interest to a number of

00:18:47,700 --> 00:18:50,490
folks in the room because that's going

00:18:49,380 --> 00:18:52,890
to be where we're focusing on

00:18:50,490 --> 00:18:55,320
performance per watt ai core is really

00:18:52,890 --> 00:18:59,970
around compute in the data center edge

00:18:55,320 --> 00:19:01,950
will be AI at the edge and that AI RF

00:18:59,970 --> 00:19:04,049
for those of you familiar with RF sock

00:19:01,950 --> 00:19:06,090
there will actually be a next generation

00:19:04,049 --> 00:19:09,029
of that of course and that will be found

00:19:06,090 --> 00:19:12,919
with the versatile AI RF series and with

00:19:09,029 --> 00:19:12,919
that I will hand off to Jason

00:19:13,750 --> 00:19:19,470
[Applause]

00:19:16,820 --> 00:19:21,779
perfect thanks Manuel pleasure to be

00:19:19,470 --> 00:19:24,240
back working with Manuel again at Xilinx

00:19:21,779 --> 00:19:25,679
and pleasure to be here at the Kinney

00:19:24,240 --> 00:19:27,090
radio conference thank you to the

00:19:25,679 --> 00:19:29,580
conference organizers thank you to all

00:19:27,090 --> 00:19:30,960
the attendees you know just great to

00:19:29,580 --> 00:19:32,520
have a chance to speak with you today

00:19:30,960 --> 00:19:34,799
I've been a longtime lurker of the

00:19:32,520 --> 00:19:36,149
conference glad to finally be here so as

00:19:34,799 --> 00:19:37,830
Manuel mentioned I'm a system

00:19:36,149 --> 00:19:40,230
architected Xilinx on our aerospace and

00:19:37,830 --> 00:19:41,789
defense team and I wanted to you know

00:19:40,230 --> 00:19:43,770
key off of Manuel's introduction and

00:19:41,789 --> 00:19:45,870
talk a little bit about all right I

00:19:43,770 --> 00:19:48,570
wanted to talk about really just trying

00:19:45,870 --> 00:19:51,240
to quantify to an extent some of the

00:19:48,570 --> 00:19:52,860
problems that we're facing on the front

00:19:51,240 --> 00:19:54,450
of advanced software-defined radio and I

00:19:52,860 --> 00:19:56,789
realized that that term itself is a bit

00:19:54,450 --> 00:19:58,890
ambiguous I'll try to help define that I

00:19:56,789 --> 00:20:00,929
really want to focus more on advanced

00:19:58,890 --> 00:20:01,860
software defined radio requirements I'm

00:20:00,929 --> 00:20:04,770
going to go ahead and build some of this

00:20:01,860 --> 00:20:07,350
out just in the interest of time really

00:20:04,770 --> 00:20:09,480
from a wireless physical access layer

00:20:07,350 --> 00:20:11,370
perspective you know how do we handle

00:20:09,480 --> 00:20:13,020
that problem so that we can enable a

00:20:11,370 --> 00:20:14,070
whole bunch of interesting SDR

00:20:13,020 --> 00:20:15,090
applications that run on top of

00:20:14,070 --> 00:20:16,590
platforms

00:20:15,090 --> 00:20:19,320
and if you look at a couple of trend

00:20:16,590 --> 00:20:20,820
lines in few in a few very prominent

00:20:19,320 --> 00:20:22,140
categories here you know there's

00:20:20,820 --> 00:20:23,700
multiple ways to break this down but

00:20:22,140 --> 00:20:26,100
it's interesting to focus on here what's

00:20:23,700 --> 00:20:28,289
going on in terms of requirements and

00:20:26,100 --> 00:20:30,240
demand for more capacity from our

00:20:28,289 --> 00:20:32,760
software-defined radio systems for more

00:20:30,240 --> 00:20:34,890
autonomy from our SDR systems and then

00:20:32,760 --> 00:20:37,770
also for more resiliency from our SDR

00:20:34,890 --> 00:20:39,440
systems and you know capacity I think

00:20:37,770 --> 00:20:42,390
you know 5g is kind of the poster child

00:20:39,440 --> 00:20:43,650
example to look to when it comes to

00:20:42,390 --> 00:20:47,159
quantifying hey what's the difference

00:20:43,650 --> 00:20:49,320
between 4G capabilities and 5g and ETA e

00:20:47,159 --> 00:20:51,690
TR I was you know put out this graphic

00:20:49,320 --> 00:20:53,429
they published this a few years ago at a

00:20:51,690 --> 00:20:54,929
5g working group and it just really

00:20:53,429 --> 00:20:56,909
compared metrics and a number of

00:20:54,929 --> 00:20:59,130
different parameters related to overall

00:20:56,909 --> 00:21:00,809
SDR performance and a few things that

00:20:59,130 --> 00:21:04,110
jump out or you know peak data rates for

00:21:00,809 --> 00:21:07,049
5g 20x increase over 4G to 20 gigabits

00:21:04,110 --> 00:21:09,679
per second a total area traffic capacity

00:21:07,049 --> 00:21:12,630
increase of two orders of magnitude 100x

00:21:09,679 --> 00:21:15,620
latency improvement 10x down to one

00:21:12,630 --> 00:21:17,549
millisecond latency in these systems you

00:21:15,620 --> 00:21:19,980
hardware platforms are required to

00:21:17,549 --> 00:21:21,510
realize this from an autonomy

00:21:19,980 --> 00:21:23,490
perspective you could kind of fit in the

00:21:21,510 --> 00:21:25,350
word cognitive radio up there that's

00:21:23,490 --> 00:21:27,120
kind of the end goal from an SDR system

00:21:25,350 --> 00:21:28,440
and I think we've come to realize out of

00:21:27,120 --> 00:21:29,820
this community in particular there's

00:21:28,440 --> 00:21:31,679
been a lot of great work published on

00:21:29,820 --> 00:21:33,809
how deep learning it's not only

00:21:31,679 --> 00:21:36,600
revolutionized revolutionising fields

00:21:33,809 --> 00:21:39,450
such as image classification what about

00:21:36,600 --> 00:21:41,370
RF classification and I think if we

00:21:39,450 --> 00:21:43,770
looked at this is not inference specific

00:21:41,370 --> 00:21:45,929
but it gives us a hint as to the growth

00:21:43,770 --> 00:21:47,070
in compute complexity for neural

00:21:45,929 --> 00:21:48,900
networks and deep learning neural

00:21:47,070 --> 00:21:52,740
networks this is a comparison put out by

00:21:48,900 --> 00:21:54,179
open AI comparing alex net in 2012 from

00:21:52,740 --> 00:21:58,440
a total computational workload

00:21:54,179 --> 00:22:01,140
perspective to alphago zero put out just

00:21:58,440 --> 00:22:05,039
in 2018 it's it's a total increase in

00:22:01,140 --> 00:22:07,710
petaflop days of 300,000 X it's 5 order

00:22:05,039 --> 00:22:09,299
of magnitude increase at 6 years Moore's

00:22:07,710 --> 00:22:11,340
law alone would be about a tax increase

00:22:09,299 --> 00:22:13,559
that same time so we know that's not

00:22:11,340 --> 00:22:16,890
going to get us there and then I think a

00:22:13,559 --> 00:22:19,169
more difficult element to quantify

00:22:16,890 --> 00:22:20,610
precisely would be the resiliency side

00:22:19,169 --> 00:22:22,710
of things certainly from a defense

00:22:20,610 --> 00:22:25,409
perspective our critical communication

00:22:22,710 --> 00:22:27,059
systems are having to operate in a

00:22:25,409 --> 00:22:28,360
highly contested environment a highly

00:22:27,059 --> 00:22:30,610
contested spectrum not just

00:22:28,360 --> 00:22:32,110
congested but contested so the

00:22:30,610 --> 00:22:33,130
adversarial capabilities that are out

00:22:32,110 --> 00:22:35,890
there just was standard off-the-shelf

00:22:33,130 --> 00:22:37,450
hardware are very prominent so you know

00:22:35,890 --> 00:22:39,910
how can we from a signal processing

00:22:37,450 --> 00:22:41,470
perspective enable more resiliency in

00:22:39,910 --> 00:22:42,850
our critical communication systems and

00:22:41,470 --> 00:22:44,320
what sort of compute costs does that

00:22:42,850 --> 00:22:47,740
have those are the sorts of things that

00:22:44,320 --> 00:22:49,270
we're interested in solving I'm gonna do

00:22:47,740 --> 00:22:51,010
some build outs here so the dramatic

00:22:49,270 --> 00:22:53,049
effect is a little bit lessened but I

00:22:51,010 --> 00:22:55,299
want to be conscious at the time so

00:22:53,049 --> 00:22:57,040
enabling technologies there's more than

00:22:55,299 --> 00:23:00,580
just a few but I certainly would point

00:22:57,040 --> 00:23:03,280
to the prominence in the rise of direct

00:23:00,580 --> 00:23:04,929
RF or high F sampling data converters

00:23:03,280 --> 00:23:07,299
you know that's giving us access to

00:23:04,929 --> 00:23:09,429
millimeter wave spectrum of wide range

00:23:07,299 --> 00:23:12,640
of companies able to field and produce

00:23:09,429 --> 00:23:14,679
this this technology going along with

00:23:12,640 --> 00:23:16,750
that array antennas phased array

00:23:14,679 --> 00:23:18,700
antennas and then taking a look at just

00:23:16,750 --> 00:23:19,720
some of the advances that we've had for

00:23:18,700 --> 00:23:21,549
deep learning and the compute

00:23:19,720 --> 00:23:23,590
optimizations associated with that

00:23:21,549 --> 00:23:24,700
the thing about millimeter wave is it's

00:23:23,590 --> 00:23:27,190
great that we're able to access

00:23:24,700 --> 00:23:28,960
millimeter wave now frequencies

00:23:27,190 --> 00:23:30,610
certainly we get some benefit of

00:23:28,960 --> 00:23:32,919
increased bandwidth but we still have to

00:23:30,610 --> 00:23:34,960
observe physics the physics say that

00:23:32,919 --> 00:23:36,730
with shorter wavelengths for the same

00:23:34,960 --> 00:23:39,220
amount of power we have less range right

00:23:36,730 --> 00:23:41,710
so effects of the environment become

00:23:39,220 --> 00:23:43,330
more prominent at millimeter wave you

00:23:41,710 --> 00:23:45,880
know foliage penetration building

00:23:43,330 --> 00:23:48,220
penetration multipath effects are

00:23:45,880 --> 00:23:50,020
prominent so the range that we have has

00:23:48,220 --> 00:23:51,490
to be considered and this is leading to

00:23:50,020 --> 00:23:53,860
a lot of innovation in the antenna side

00:23:51,490 --> 00:23:56,169
of things we're seeing you know

00:23:53,860 --> 00:23:58,450
prominent implementation of phased array

00:23:56,169 --> 00:24:00,730
systems at the base stations but it's

00:23:58,450 --> 00:24:03,460
it's good for more than just commercial

00:24:00,730 --> 00:24:06,130
comms it's also good for interference

00:24:03,460 --> 00:24:07,540
mitigation against bad actors anti-jam

00:24:06,130 --> 00:24:09,669
systems so that picture in the lower

00:24:07,540 --> 00:24:12,179
right hand corner that's kind of some

00:24:09,669 --> 00:24:13,750
images on of noeleen represent a

00:24:12,179 --> 00:24:15,820
representations on a controlled

00:24:13,750 --> 00:24:17,169
reception pattern or a antenna and I'll

00:24:15,820 --> 00:24:20,080
talk a little bit about the compute cost

00:24:17,169 --> 00:24:21,910
for that but lower left-hand corner if

00:24:20,080 --> 00:24:23,440
we're trying to get a sense of compute

00:24:21,910 --> 00:24:25,059
you know everyone kind of wants to

00:24:23,440 --> 00:24:27,220
classify their cats and dogs you know

00:24:25,059 --> 00:24:29,919
that's two three years ago sort of

00:24:27,220 --> 00:24:31,510
results but out of this community in

00:24:29,919 --> 00:24:33,340
particular there's been some interesting

00:24:31,510 --> 00:24:35,260
advances for RF classification

00:24:33,340 --> 00:24:37,330
particularly modulation classification

00:24:35,260 --> 00:24:39,370
what's the compute cost for that and how

00:24:37,330 --> 00:24:41,830
do we build that into a system that is

00:24:39,370 --> 00:24:42,220
more spectrally aware so I thought I

00:24:41,830 --> 00:24:44,320
draw

00:24:42,220 --> 00:24:47,260
some comparisons here do a quick time

00:24:44,320 --> 00:24:49,179
check between space-time adapted

00:24:47,260 --> 00:24:51,549
processing techniques that are needed

00:24:49,179 --> 00:24:52,270
for applications like adaptive

00:24:51,549 --> 00:24:55,110
beamforming

00:24:52,270 --> 00:24:57,730
and nulling and deep learning

00:24:55,110 --> 00:24:59,860
applications are they similar are they

00:24:57,730 --> 00:25:01,690
different and what can we kind of take

00:24:59,860 --> 00:25:03,100
away from that so this is actually a

00:25:01,690 --> 00:25:05,409
picture I'll admit this is from 12 years

00:25:03,100 --> 00:25:06,909
ago this picture made by Xilinx we've

00:25:05,409 --> 00:25:08,650
been doing adaptive beamforming for a

00:25:06,909 --> 00:25:10,090
long time what's different now is you're

00:25:08,650 --> 00:25:13,330
starting to see this capability filled

00:25:10,090 --> 00:25:14,830
it into comm systems on a wide scale so

00:25:13,330 --> 00:25:17,559
the whole notion here is that if you

00:25:14,830 --> 00:25:19,840
have not just a single antenna element

00:25:17,559 --> 00:25:22,330
in an array of antenna elements you can

00:25:19,840 --> 00:25:24,340
exploit the spatial diversity in a

00:25:22,330 --> 00:25:26,100
manner that you can detect the direction

00:25:24,340 --> 00:25:29,500
of arrival between a signal of interest

00:25:26,100 --> 00:25:32,080
as long as your your jammer is not in

00:25:29,500 --> 00:25:33,789
the same location as the signal you want

00:25:32,080 --> 00:25:35,590
to identify you can use that to

00:25:33,789 --> 00:25:37,780
discriminate and ultimately increase

00:25:35,590 --> 00:25:40,179
gain along a path of interest and cancel

00:25:37,780 --> 00:25:42,850
out gain the long and interferers paths

00:25:40,179 --> 00:25:46,659
and the process for for doing this

00:25:42,850 --> 00:25:47,890
involves if it's a linear problem which

00:25:46,659 --> 00:25:49,809
depending on the antenna technology

00:25:47,890 --> 00:25:51,850
there's some considerations here but

00:25:49,809 --> 00:25:54,309
involves a lot of deep linear algebra

00:25:51,850 --> 00:25:56,429
compute the process for solving for an

00:25:54,309 --> 00:25:58,750
optimal set of weights that might

00:25:56,429 --> 00:26:02,049
maximize the gain of a signal of

00:25:58,750 --> 00:26:04,330
interest is kind of summarized below

00:26:02,049 --> 00:26:05,559
here in this wiener equation but

00:26:04,330 --> 00:26:07,960
essentially what you're doing is you're

00:26:05,559 --> 00:26:10,210
taking a covariance you're estimating

00:26:07,960 --> 00:26:11,980
the covariance matrix for that antenna

00:26:10,210 --> 00:26:13,630
array that's a vector cross product and

00:26:11,980 --> 00:26:15,280
then you're needing to invert that

00:26:13,630 --> 00:26:17,260
matrix and multiply it times the

00:26:15,280 --> 00:26:18,970
steering vector so the whole process of

00:26:17,260 --> 00:26:20,860
doing that matrix inversion is very

00:26:18,970 --> 00:26:22,570
compute intensive you know depth off

00:26:20,860 --> 00:26:24,460
your favorite numerical methods textbook

00:26:22,570 --> 00:26:25,809
there's many many different solutions

00:26:24,460 --> 00:26:27,850
this class of problem and well study

00:26:25,809 --> 00:26:30,490
through years often in FPGAs we're

00:26:27,850 --> 00:26:32,980
looking at matrix decompositions QR

00:26:30,490 --> 00:26:35,260
decomposition Zaleski decompositions as

00:26:32,980 --> 00:26:37,480
we factor this matrix generally these

00:26:35,260 --> 00:26:39,669
are it's a complex value problem it

00:26:37,480 --> 00:26:41,470
wants to have higher precision if the

00:26:39,669 --> 00:26:43,570
array size is large you know single

00:26:41,470 --> 00:26:45,460
precision floating point for instance

00:26:43,570 --> 00:26:47,799
and we're looking at anywhere from you

00:26:45,460 --> 00:26:50,049
know thousands of floating operations of

00:26:47,799 --> 00:26:52,840
floating point operations to mega flops

00:26:50,049 --> 00:26:54,850
per decomposition so an actual real-time

00:26:52,840 --> 00:26:56,020
system might be looking at gigaflops to

00:26:54,850 --> 00:26:58,660
perform this

00:26:56,020 --> 00:27:00,460
optimal weight vector estimation kind of

00:26:58,660 --> 00:27:01,630
comparing and contrasting this will what

00:27:00,460 --> 00:27:03,310
about deep learning and particularly

00:27:01,630 --> 00:27:07,120
deep learning with convolutional neural

00:27:03,310 --> 00:27:08,740
networks well also at the heart of this

00:27:07,120 --> 00:27:10,360
problem kind of the bounty and compute

00:27:08,740 --> 00:27:12,190
problem ends up being that convolution

00:27:10,360 --> 00:27:14,320
operation this is naturally something

00:27:12,190 --> 00:27:16,390
that has cubic compute complexity but

00:27:14,320 --> 00:27:18,190
there's you know there's a number of

00:27:16,390 --> 00:27:19,780
factors involved I can lessen that but

00:27:18,190 --> 00:27:22,120
ultimately you have a 2d matrix

00:27:19,780 --> 00:27:25,150
multiplied happening here so if you look

00:27:22,120 --> 00:27:27,430
at a network like a resonant 50 that is

00:27:25,150 --> 00:27:31,600
a network that has a compute cost of

00:27:27,430 --> 00:27:33,070
seven point six billion operations so

00:27:31,600 --> 00:27:34,270
depending on how fast you can compute

00:27:33,070 --> 00:27:35,800
that controllers your latency through

00:27:34,270 --> 00:27:37,660
that network so these are different

00:27:35,800 --> 00:27:38,980
problems in terms of precision but

00:27:37,660 --> 00:27:42,880
they're similar in overall compute

00:27:38,980 --> 00:27:44,380
density so you know it's I links if

00:27:42,880 --> 00:27:46,120
we're considering or we're looking at

00:27:44,380 --> 00:27:48,070
being able to design hardware platform

00:27:46,120 --> 00:27:51,370
that's capable of addressed in these two

00:27:48,070 --> 00:27:52,810
vastly different areas of SDR I think

00:27:51,370 --> 00:27:54,190
that previous exercise is very

00:27:52,810 --> 00:27:55,330
instructive because first of all it lets

00:27:54,190 --> 00:27:57,870
us know that we really need to be able

00:27:55,330 --> 00:28:00,550
to support a wide range of precision and

00:27:57,870 --> 00:28:02,710
in the AI engine that's present in the a

00:28:00,550 --> 00:28:04,930
cap architecture we do have a mixed

00:28:02,710 --> 00:28:07,000
precision wide range of precision

00:28:04,930 --> 00:28:09,520
selection available so everything from

00:28:07,000 --> 00:28:11,470
real data pipe data types from

00:28:09,520 --> 00:28:14,230
floating-point precision to real on the

00:28:11,470 --> 00:28:16,030
left hand side to complex native support

00:28:14,230 --> 00:28:18,850
for complex data types very important

00:28:16,030 --> 00:28:21,070
for RF signal processing and this is

00:28:18,850 --> 00:28:22,990
applicable not just the RF but a wide

00:28:21,070 --> 00:28:24,760
range of digital signal processing

00:28:22,990 --> 00:28:26,020
applications so really how do we design

00:28:24,760 --> 00:28:28,030
an architecture that can accelerate

00:28:26,020 --> 00:28:32,980
these sorts of linear algebraic

00:28:28,030 --> 00:28:35,920
operations and then kind of taking it

00:28:32,980 --> 00:28:37,570
now more toward the processor itself so

00:28:35,920 --> 00:28:39,880
again speaking to kind of the design

00:28:37,570 --> 00:28:42,580
motivations for the AI engine processor

00:28:39,880 --> 00:28:44,650
that's implemented in a cap will

00:28:42,580 --> 00:28:46,600
actually construct kind of a multi

00:28:44,650 --> 00:28:48,370
processor unit here so we definitely

00:28:46,600 --> 00:28:49,990
want to have some sort of scalar

00:28:48,370 --> 00:28:51,850
processing capability coupled here

00:28:49,990 --> 00:28:53,050
there's more than just vector operations

00:28:51,850 --> 00:28:55,060
that we need to do with these sorts of

00:28:53,050 --> 00:28:56,830
SDR related tasks but we definitely need

00:28:55,060 --> 00:28:58,810
a vector unit both floating point and

00:28:56,830 --> 00:29:00,550
fixed point we need a memory interface

00:28:58,810 --> 00:29:02,980
and we like to be able to stream data at

00:29:00,550 --> 00:29:05,950
low latency into and out of this but the

00:29:02,980 --> 00:29:07,900
design of this class of processor we

00:29:05,950 --> 00:29:09,120
obviously get parallelism we can exploit

00:29:07,900 --> 00:29:10,710
in the data itself

00:29:09,120 --> 00:29:12,780
you know look at your favorite textbook

00:29:10,710 --> 00:29:15,690
for an F IR filter get rid of the for

00:29:12,780 --> 00:29:17,610
loop replace it with vector multiply or

00:29:15,690 --> 00:29:19,590
a convolution replace it with a matrix

00:29:17,610 --> 00:29:22,350
multiply there's data parallelism that

00:29:19,590 --> 00:29:24,450
we can exploit with the vectorization of

00:29:22,350 --> 00:29:26,160
a processor such as this but also we get

00:29:24,450 --> 00:29:28,230
instruction parallelism this is a very

00:29:26,160 --> 00:29:30,080
large instruction word processor we can

00:29:28,230 --> 00:29:31,850
do multiple operations in parallel

00:29:30,080 --> 00:29:34,440
simultaneously and the left-hand side

00:29:31,850 --> 00:29:39,720
shows the individual operations that can

00:29:34,440 --> 00:29:41,250
be done in one clock cycle couple more

00:29:39,720 --> 00:29:42,930
slides that wrap this up so the concept

00:29:41,250 --> 00:29:46,800
here is this hasn't done an island will

00:29:42,930 --> 00:29:48,990
actually create this vector aware ki

00:29:46,800 --> 00:29:50,910
engine processor and will couple this

00:29:48,990 --> 00:29:53,070
together with a non-blocking high speed

00:29:50,910 --> 00:29:55,110
interconnect this is an ACCI

00:29:53,070 --> 00:29:57,170
interconnect switch fabric and that's

00:29:55,110 --> 00:30:00,210
also further coupled than to direct

00:29:57,170 --> 00:30:03,450
attached memory both local and neighbor

00:30:00,210 --> 00:30:06,480
memory direct-attached that further is

00:30:03,450 --> 00:30:08,160
combined into an array whose size will

00:30:06,480 --> 00:30:09,300
vary based on the size and the

00:30:08,160 --> 00:30:10,770
capability of the device right this

00:30:09,300 --> 00:30:12,690
could vary anywhere from tens of these

00:30:10,770 --> 00:30:15,000
to hundreds of these in the largest

00:30:12,690 --> 00:30:17,220
device and then we ultimately want to be

00:30:15,000 --> 00:30:18,720
able to couple this sort of vector

00:30:17,220 --> 00:30:21,030
processing array with other

00:30:18,720 --> 00:30:22,500
heterogeneous capabilities on a platform

00:30:21,030 --> 00:30:24,480
so for instance if we're doing RF

00:30:22,500 --> 00:30:27,030
processing can we get those high-speed

00:30:24,480 --> 00:30:29,490
RF samples in from either our chip or an

00:30:27,030 --> 00:30:31,290
on ship direct RF data converter into

00:30:29,490 --> 00:30:33,450
the programmable logic fabric and then

00:30:31,290 --> 00:30:36,990
ultimately efficiently into the I engine

00:30:33,450 --> 00:30:38,220
array so I mean aside from signal

00:30:36,990 --> 00:30:39,320
processing we could also think about

00:30:38,220 --> 00:30:42,210
well how do we utilize this capability

00:30:39,320 --> 00:30:44,190
for machine learning inference how can

00:30:42,210 --> 00:30:45,630
it be optimized in similar fashion in

00:30:44,190 --> 00:30:49,230
this case we like to think about the ki

00:30:45,630 --> 00:30:51,300
engines as being a vehicle for an

00:30:49,230 --> 00:30:53,490
overlay to be provided on top of the

00:30:51,300 --> 00:30:56,280
engine array that optimizes that array

00:30:53,490 --> 00:30:58,440
for specific precision type and a

00:30:56,280 --> 00:30:59,790
specific workload type and in this case

00:30:58,440 --> 00:31:04,170
we actually will use the programmable

00:30:59,790 --> 00:31:06,150
logic fabric as a very tensor aware low

00:31:04,170 --> 00:31:08,430
latency cache system so we don't have to

00:31:06,150 --> 00:31:11,400
go to external DRAM to fetch weights and

00:31:08,430 --> 00:31:13,770
activations at a very rapid pace we have

00:31:11,400 --> 00:31:15,390
enough depth and on chip SRAM where we

00:31:13,770 --> 00:31:17,310
can store those in a very deep on chip

00:31:15,390 --> 00:31:18,900
low latency buffer and have that

00:31:17,310 --> 00:31:22,170
optimize and feed data into the AI

00:31:18,900 --> 00:31:22,710
engine ai engines also optimize for this

00:31:22,170 --> 00:31:25,500
sort of

00:31:22,710 --> 00:31:28,230
cade Streamy operation that is often

00:31:25,500 --> 00:31:32,340
seen when you share weights between the

00:31:28,230 --> 00:31:33,630
same input finally wrapping up here in a

00:31:32,340 --> 00:31:35,010
couple of slides what we have looked at

00:31:33,630 --> 00:31:36,899
is just a wide range of signal

00:31:35,010 --> 00:31:39,419
processing problems and machine learning

00:31:36,899 --> 00:31:41,610
problems and how vectorizable they are

00:31:39,419 --> 00:31:43,559
and you know as you might suspect they

00:31:41,610 --> 00:31:45,210
are highly vectorizable these are some

00:31:43,559 --> 00:31:47,909
of the efficiency calculations we have

00:31:45,210 --> 00:31:52,080
for various operations such as machine

00:31:47,909 --> 00:31:53,669
learning convolutions FFTs and digital

00:31:52,080 --> 00:31:56,370
pre-distortion algorithm being

00:31:53,669 --> 00:31:58,529
implemented on the AI engine so you can

00:31:56,370 --> 00:32:00,600
see very high utilization the whole idea

00:31:58,529 --> 00:32:03,570
is we always want to be doing compute if

00:32:00,600 --> 00:32:05,399
we can while we're fetching data we

00:32:03,570 --> 00:32:08,490
don't want to have any stalls and that's

00:32:05,399 --> 00:32:10,080
what the efficiency applies here so it's

00:32:08,490 --> 00:32:12,090
very novel locket architecture in terms

00:32:10,080 --> 00:32:14,760
of it's a low latency streaming vector

00:32:12,090 --> 00:32:16,169
processor so hopefully that gives you a

00:32:14,760 --> 00:32:17,970
sense of some of the motivations as

00:32:16,169 --> 00:32:19,950
Manuel mentioned opening we definitely

00:32:17,970 --> 00:32:21,419
see a convergence and more and more

00:32:19,950 --> 00:32:23,340
compute being driven out to the edge of

00:32:21,419 --> 00:32:25,529
our systems and needing to be fielded in

00:32:23,340 --> 00:32:27,899
a power efficient manner in our radio

00:32:25,529 --> 00:32:29,059
architectures and in that sense we're

00:32:27,899 --> 00:32:31,590
really seeing a convergence between

00:32:29,059 --> 00:32:33,299
demands for artificial intelligence and

00:32:31,590 --> 00:32:36,929
machine learning and what we

00:32:33,299 --> 00:32:38,580
historically seen for SDR you know the

00:32:36,929 --> 00:32:41,610
world the SDR world's driving for more

00:32:38,580 --> 00:32:43,049
capacity autonomy and resiliency we know

00:32:41,610 --> 00:32:46,140
that Moore's law is out of steam even if

00:32:43,049 --> 00:32:47,789
it was at full steam the 2x gain every

00:32:46,140 --> 00:32:49,789
two years isn't it isn't enough we

00:32:47,789 --> 00:32:52,140
really need architectural innovation and

00:32:49,789 --> 00:32:55,440
adaptive compute acceleration platforms

00:32:52,140 --> 00:32:56,789
are our response to this new reality so

00:32:55,440 --> 00:32:58,169
again the picture is a little bit of a

00:32:56,789 --> 00:32:59,970
blown-up picture of what Manuel has in

00:32:58,169 --> 00:33:00,899
his pocket I'm not sure if what he has

00:32:59,970 --> 00:33:04,200
in the pocket is electric

00:33:00,899 --> 00:33:06,450
electrostatically alive still but feel

00:33:04,200 --> 00:33:08,280
free to stop by and take a peek thank

00:33:06,450 --> 00:33:10,340
you for your time

00:33:08,280 --> 00:33:10,340

YouTube URL: https://www.youtube.com/watch?v=PNjF8O0wZEY


