Title: Birmingham on Rails 2020 - Postgres at any Scale by Craig Kerstiens
Publication date: 2020-02-19
Playlist: Birmingham on Rails 2020
Description: 
	Birmingham on Rails 2020 - Postgres at any Scale by Craig Kerstiens
Captions: 
	00:00:03,310 --> 00:00:06,460
[Music]

00:00:10,550 --> 00:00:15,210
[Music]

00:00:12,070 --> 00:00:15,210
[Applause]

00:00:17,330 --> 00:00:23,220
hi everyone so we're gonna talk a little

00:00:20,850 --> 00:00:24,960
bit about Postgres today here really

00:00:23,220 --> 00:00:31,489
quick show of hands who already uses

00:00:24,960 --> 00:00:33,510
Postgres awesome who does not know one

00:00:31,489 --> 00:00:37,260
alright if you're too shy we can chat

00:00:33,510 --> 00:00:42,300
afterwards happy to convince you anyone

00:00:37,260 --> 00:00:44,160
who said this so I take the exact

00:00:42,300 --> 00:00:46,890
opposite of this philosophy this is from

00:00:44,160 --> 00:00:50,250
DHH the database I think it was actually

00:00:46,890 --> 00:00:51,329
it's just a dumb hashing this guy we'll

00:00:50,250 --> 00:00:52,410
get into it a little bit of why I think

00:00:51,329 --> 00:00:54,660
like you should know a little bit by

00:00:52,410 --> 00:00:56,699
your database even I'm here on a DBA to

00:00:54,660 --> 00:00:58,500
work better with it how to deal with

00:00:56,699 --> 00:01:00,120
hidden handle it at really any scale

00:00:58,500 --> 00:01:02,480
without having to go you know back to

00:01:00,120 --> 00:01:05,519
school take a bunch of database courses

00:01:02,480 --> 00:01:07,799
really this is the like 101 with a lot

00:01:05,519 --> 00:01:11,159
of links and references to to treat it a

00:01:07,799 --> 00:01:13,470
little bit better so first a little bit

00:01:11,159 --> 00:01:15,960
about me I was one of the first product

00:01:13,470 --> 00:01:18,390
managers at Roku spent about five and a

00:01:15,960 --> 00:01:22,110
half years there primarily built and ran

00:01:18,390 --> 00:01:24,240
Heroku Postgres we ran around 1.5

00:01:22,110 --> 00:01:26,729
million Postgres databases across the

00:01:24,240 --> 00:01:27,960
team of about eight of us so I think a

00:01:26,729 --> 00:01:31,020
pretty good ratio of database to

00:01:27,960 --> 00:01:33,079
engineer rated product for site is data

00:01:31,020 --> 00:01:35,400
I'll talk a little bit more about situs

00:01:33,079 --> 00:01:37,409
later but the short is we turned

00:01:35,400 --> 00:01:39,390
Postgres into a distributed started

00:01:37,409 --> 00:01:42,720
database and it's transparent to your

00:01:39,390 --> 00:01:46,500
application we were at Clara right out a

00:01:42,720 --> 00:01:48,479
year ago so now I'm at Microsoft if you

00:01:46,500 --> 00:01:50,369
like Post Crescent wanna learn a little

00:01:48,479 --> 00:01:52,290
bit more about it I create a newsletter

00:01:50,369 --> 00:01:54,210
Postgres weekly it's pretty highly

00:01:52,290 --> 00:01:56,670
curated sounds like Ruby weekly and

00:01:54,210 --> 00:01:59,219
others that it's not a hundred things

00:01:56,670 --> 00:02:01,409
it's like here's the top 10 15 20 things

00:01:59,219 --> 00:02:06,450
really targeted for like an application

00:02:01,409 --> 00:02:08,459
develop or not the DBA Krab so I think

00:02:06,450 --> 00:02:10,709
this is you know representative of the

00:02:08,459 --> 00:02:12,210
show of hands in the room I think

00:02:10,709 --> 00:02:15,510
everyone's hand went up

00:02:12,210 --> 00:02:17,940
Postgres is more popular than ever it's

00:02:15,510 --> 00:02:21,570
kind of the largest open-source database

00:02:17,940 --> 00:02:23,400
I think growing in popularity if you

00:02:21,570 --> 00:02:25,230
look at like hacker news who's hiring I

00:02:23,400 --> 00:02:27,240
don't know if you counted as a barometer

00:02:25,230 --> 00:02:28,620
of success or not but like who's hiring

00:02:27,240 --> 00:02:32,250
Postgres ranks number one among

00:02:28,620 --> 00:02:35,520
databases it's really well-loved really

00:02:32,250 --> 00:02:38,370
well-liked as a relational database now

00:02:35,520 --> 00:02:43,470
first this is a really fun excerpt from

00:02:38,370 --> 00:02:46,590
the Postgres mailing list from 2006 Tom

00:02:43,470 --> 00:02:47,160
Lane anyone know who he is with any

00:02:46,590 --> 00:02:51,420
hands

00:02:47,160 --> 00:02:53,880
so Tom Lane helped create TIF he was on

00:02:51,420 --> 00:02:56,820
the board for creating the spec for JPEG

00:02:53,880 --> 00:03:00,600
co-authored with JPEG Co wrote the spec

00:02:56,820 --> 00:03:02,370
for PNG then co-authored with PNG then

00:03:00,600 --> 00:03:03,930
he said I'm kind of tired of images I'm

00:03:02,370 --> 00:03:05,730
gonna go work with this database thing

00:03:03,930 --> 00:03:08,130
and he's been working with Postgres for

00:03:05,730 --> 00:03:10,470
about the last 15 to 20 years he is the

00:03:08,130 --> 00:03:12,300
primary contributor to much of Postgres

00:03:10,470 --> 00:03:16,670
I think if you look in top open source

00:03:12,300 --> 00:03:19,500
contributors he's in the top five or so

00:03:16,670 --> 00:03:22,290
this was him 14 years ago on the mailing

00:03:19,500 --> 00:03:23,790
list coming back from a conference and

00:03:22,290 --> 00:03:24,780
now it's pretty well regarded is that

00:03:23,790 --> 00:03:27,840
you know this is the biggest mistake

00:03:24,780 --> 00:03:30,120
post-crisis ever made was its name it's

00:03:27,840 --> 00:03:34,140
not post gray sequel it's not Postgres

00:03:30,120 --> 00:03:38,340
sequel just ignore the sequel part like

00:03:34,140 --> 00:03:39,720
Postgres PostgreSQL is fine post press

00:03:38,340 --> 00:03:43,050
is perfectly acceptable just go with

00:03:39,720 --> 00:03:45,420
post press it's still painful to this

00:03:43,050 --> 00:03:46,620
day and I I'm kind of thinking about

00:03:45,420 --> 00:03:48,480
starting a campaign with all the core

00:03:46,620 --> 00:03:50,400
developers calling it post gray to annoy

00:03:48,480 --> 00:03:54,630
them until they go and change it don't

00:03:50,400 --> 00:03:56,430
think it's kind of having them so if

00:03:54,630 --> 00:03:58,020
you're new to Postgres or someone asked

00:03:56,430 --> 00:04:02,610
you why do you like it

00:03:58,020 --> 00:04:04,350
to me this is the TLDR I think a lot of

00:04:02,610 --> 00:04:05,970
you know engineers we jump onto a

00:04:04,350 --> 00:04:07,950
bandwagon oh it's cool of course I'm

00:04:05,970 --> 00:04:10,260
using it I mean if you ask why we maybe

00:04:07,950 --> 00:04:13,080
actually can't give a good answer it's a

00:04:10,260 --> 00:04:15,180
really really feature-rich database I

00:04:13,080 --> 00:04:17,570
looking like data types or something

00:04:15,180 --> 00:04:19,470
good I'm actually really excited about

00:04:17,570 --> 00:04:21,120
you wouldn't think that that's something

00:04:19,470 --> 00:04:23,570
that jumps out is in terms of a database

00:04:21,120 --> 00:04:25,770
but it's real useful and powerful

00:04:23,570 --> 00:04:27,389
transactional DDL so if you're running

00:04:25,770 --> 00:04:28,919
migration and it fails you can actually

00:04:27,389 --> 00:04:33,090
roll it back and not have it kind of be

00:04:28,919 --> 00:04:34,889
mid migration foreign data wrappers you

00:04:33,090 --> 00:04:36,990
can connect from inside Postgres to

00:04:34,889 --> 00:04:40,800
another database in query directly so if

00:04:36,990 --> 00:04:42,930
you have stuff in Redis or and you

00:04:40,800 --> 00:04:44,789
just want to interact with in Postgres

00:04:42,930 --> 00:04:48,000
you can query directly to those other

00:04:44,789 --> 00:04:50,580
databases listen notify is pub/sub

00:04:48,000 --> 00:04:52,650
directly inside your database so a lot

00:04:50,580 --> 00:04:54,539
of these things on the list if I'm not

00:04:52,650 --> 00:04:56,009
going to cover all of you in the talk if

00:04:54,539 --> 00:04:57,509
you're curious about any of them have to

00:04:56,009 --> 00:04:59,310
be chat afterwards or go look them up

00:04:57,509 --> 00:05:03,419
all of these really really awesome

00:04:59,310 --> 00:05:06,870
features so first just a little bit of a

00:05:03,419 --> 00:05:08,610
background on Postgres it's unique as

00:05:06,870 --> 00:05:10,319
open-source and I would actually say

00:05:08,610 --> 00:05:12,210
it's probably unique is an open-source

00:05:10,319 --> 00:05:14,789
database I think we actually see you

00:05:12,210 --> 00:05:17,669
know within rails like there is no owner

00:05:14,789 --> 00:05:19,979
necessarily of rails it's a very liberal

00:05:17,669 --> 00:05:23,130
license which is rare for databases you

00:05:19,979 --> 00:05:24,599
can take it modify and resell it this

00:05:23,130 --> 00:05:26,669
happens a lot you look at things like

00:05:24,599 --> 00:05:28,199
greenplum redshift aster data and as

00:05:26,669 --> 00:05:30,240
heesu we're all originally post grassed

00:05:28,199 --> 00:05:32,550
they took it they changed it now it's

00:05:30,240 --> 00:05:34,319
got some slight Simplot of Postgres down

00:05:32,550 --> 00:05:38,669
in there doesn't look much like post

00:05:34,319 --> 00:05:40,530
press anymore but a lot of popularity in

00:05:38,669 --> 00:05:42,840
academia because you can go and create a

00:05:40,530 --> 00:05:46,289
PhD project on it ship it change it do

00:05:42,840 --> 00:05:49,199
whatever with it the community's

00:05:46,289 --> 00:05:49,979
interesting there's a core team that's

00:05:49,199 --> 00:05:52,949
kind of like a steering committee

00:05:49,979 --> 00:05:54,990
there's a committer which is actually

00:05:52,949 --> 00:05:57,599
only about 40 people that have a

00:05:54,990 --> 00:05:59,550
commitment to Postgres this is actually

00:05:57,599 --> 00:06:03,870
doubled over the last three years or so

00:05:59,550 --> 00:06:05,520
so it was even smaller there's major

00:06:03,870 --> 00:06:06,870
contributors minor contributors so you

00:06:05,520 --> 00:06:11,880
can actually contribute a lot to

00:06:06,870 --> 00:06:15,240
Postgres without getting a commitment in

00:06:11,880 --> 00:06:16,650
terms of mailing lists like Postgres

00:06:15,240 --> 00:06:19,590
everything happens on the mailing list

00:06:16,650 --> 00:06:22,650
with a patch there's no central like git

00:06:19,590 --> 00:06:24,539
repo pull request type model it happens

00:06:22,650 --> 00:06:27,840
like it has happened for the past 20

00:06:24,539 --> 00:06:30,240
years if you want to learn a little more

00:06:27,840 --> 00:06:31,710
on post pass the PG sequel users mailing

00:06:30,240 --> 00:06:33,990
list is a pretty good one to go and

00:06:31,710 --> 00:06:36,659
learn things if you want to fall asleep

00:06:33,990 --> 00:06:39,009
at night the PDC core hackers list is

00:06:36,659 --> 00:06:40,419
the place to go

00:06:39,009 --> 00:06:41,979
if you want to get deep into Postgres

00:06:40,419 --> 00:06:45,879
like it's where they talking about deep

00:06:41,979 --> 00:06:46,960
kernel things it's fascinating and I

00:06:45,879 --> 00:06:48,999
don't understand half of what they

00:06:46,960 --> 00:06:50,199
discuss on there but if you want to

00:06:48,999 --> 00:06:56,529
level up it's a great place to go and

00:06:50,199 --> 00:06:57,999
subscribe so post-crisis pretty regular

00:06:56,529 --> 00:07:01,360
with the yearly release you'll see that

00:06:57,999 --> 00:07:02,649
every fall it used to be there was a 9.2

00:07:01,360 --> 00:07:05,770
was a major release and I got four was

00:07:02,649 --> 00:07:07,659
the major release nine five six usually

00:07:05,770 --> 00:07:09,399
there's one more key feature now we've

00:07:07,659 --> 00:07:11,349
shifted the numbering scheme so that

00:07:09,399 --> 00:07:14,199
major releases are a whole number no

00:07:11,349 --> 00:07:16,199
point so ten eleven twelve or all the

00:07:14,199 --> 00:07:18,759
equivalent of the nine dot something

00:07:16,199 --> 00:07:21,639
minor versions are released with

00:07:18,759 --> 00:07:23,050
security fixes patches usually about

00:07:21,639 --> 00:07:26,199
once a month sometimes it's every two

00:07:23,050 --> 00:07:30,009
months usually there's a marquee feature

00:07:26,199 --> 00:07:32,349
for 9.2 it was JSON we kind of cheated

00:07:30,009 --> 00:07:35,229
there like we said hey we're a JSON

00:07:32,349 --> 00:07:37,839
database and we did JSON validation and

00:07:35,229 --> 00:07:39,879
put it into a text field everyone was

00:07:37,839 --> 00:07:43,569
really excited about that for a while

00:07:39,879 --> 00:07:45,339
then we got JSON be in 9.4 B stands for

00:07:43,569 --> 00:07:47,370
binary one of my colleagues says it

00:07:45,339 --> 00:07:50,709
stands for better I prefer that version

00:07:47,370 --> 00:07:52,300
that's a full binary representation on

00:07:50,709 --> 00:07:57,039
disk where you can query directly into

00:07:52,300 --> 00:07:57,999
an index it really really powerful all

00:07:57,039 --> 00:08:02,219
right so let me go a little bit more

00:07:57,999 --> 00:08:02,219
into like the features and why Postgres

00:08:02,370 --> 00:08:07,479
so data types I've mentioned to me this

00:08:05,889 --> 00:08:09,490
is one that stands out is really unique

00:08:07,479 --> 00:08:12,069
I think stands apart from other

00:08:09,490 --> 00:08:13,930
databases Postgres keys are very liberal

00:08:12,069 --> 00:08:17,529
approach to new data types there's

00:08:13,930 --> 00:08:18,490
around 180 type support it a lot of the

00:08:17,529 --> 00:08:20,050
easy if you're using it in your

00:08:18,490 --> 00:08:21,189
application there's a really fun case

00:08:20,050 --> 00:08:22,959
that you should go ahead and use it

00:08:21,189 --> 00:08:24,309
directly within your database I think of

00:08:22,959 --> 00:08:26,589
something like arrays if you've got a

00:08:24,309 --> 00:08:28,509
raise in your application why actually

00:08:26,589 --> 00:08:29,439
join that to some table when you're

00:08:28,509 --> 00:08:32,219
actually making things more expensive

00:08:29,439 --> 00:08:35,050
why not just put that into an array

00:08:32,219 --> 00:08:38,860
categories tags really useful for those

00:08:35,050 --> 00:08:40,209
kind of data types JSON JSON B I

00:08:38,860 --> 00:08:43,000
mentioned those both really really

00:08:40,209 --> 00:08:45,430
useful you usually want JSON B if you're

00:08:43,000 --> 00:08:48,300
doing anything with JSON if you're just

00:08:45,430 --> 00:08:50,620
actually capturing a bunch of like API

00:08:48,300 --> 00:08:51,760
you know log data that come in

00:08:50,620 --> 00:08:53,620
you want to preserve the whitespace

00:08:51,760 --> 00:08:55,210
preserve the format you're not going to

00:08:53,620 --> 00:08:57,580
query Ghana that much Jason's really

00:08:55,210 --> 00:09:01,510
useful it's not as much overhead really

00:08:57,580 --> 00:09:02,290
really fast time-stamped easy really

00:09:01,510 --> 00:09:05,430
useful

00:09:02,290 --> 00:09:07,540
who likes working with time zones

00:09:05,430 --> 00:09:10,180
Postgres takes care of a lot of that

00:09:07,540 --> 00:09:11,350
heavy lifting so being able to get it

00:09:10,180 --> 00:09:15,400
back something in a local time zone

00:09:11,350 --> 00:09:16,810
automatic ly to kind of shift time zones

00:09:15,400 --> 00:09:19,050
that sort of thing time stamped easy

00:09:16,810 --> 00:09:22,990
really really really useful data type

00:09:19,050 --> 00:09:24,100
I'm missing a few on here UUID handy if

00:09:22,990 --> 00:09:26,200
you're using them your app put them

00:09:24,100 --> 00:09:28,180
directly in your database range' types

00:09:26,200 --> 00:09:30,070
if you're doing anything again back to

00:09:28,180 --> 00:09:32,020
times like time apparently is really

00:09:30,070 --> 00:09:33,190
hard to work with if you're building a

00:09:32,020 --> 00:09:35,890
calendar application if you've ever

00:09:33,190 --> 00:09:38,020
built one it's really painful range

00:09:35,890 --> 00:09:39,820
types have a from na to directly in the

00:09:38,020 --> 00:09:41,920
data type so you can have constraints

00:09:39,820 --> 00:09:44,110
like we can't have more than 100 people

00:09:41,920 --> 00:09:46,240
in this class at this time so you can

00:09:44,110 --> 00:09:47,920
have a constraint that says you know you

00:09:46,240 --> 00:09:49,270
can't have classes that overlap and you

00:09:47,920 --> 00:09:51,339
can't have more than this many students

00:09:49,270 --> 00:09:56,200
in this kind of bucket right here really

00:09:51,339 --> 00:09:58,810
really useful it's really feature-rich

00:09:56,200 --> 00:10:00,459
in terms of its equal support common

00:09:58,810 --> 00:10:04,300
table expressions also kind of known as

00:10:00,459 --> 00:10:07,180
swift causes who likes writing sequel

00:10:04,300 --> 00:10:08,740
quick show of hands there's a few hands

00:10:07,180 --> 00:10:12,790
who are like some reading sequel someone

00:10:08,740 --> 00:10:14,920
else wrote I think I saw one person

00:10:12,790 --> 00:10:18,630
there we should talk after there's

00:10:14,920 --> 00:10:21,760
something probably wrong with you its

00:10:18,630 --> 00:10:26,050
sequel is a very powerful language it is

00:10:21,760 --> 00:10:27,790
not the most elegant language CTS are

00:10:26,050 --> 00:10:29,800
really really really nice for making

00:10:27,790 --> 00:10:31,720
readable sequel I promise you would be

00:10:29,800 --> 00:10:33,580
going write a 200 line query that you

00:10:31,720 --> 00:10:35,260
could parse and follow so you look like

00:10:33,580 --> 00:10:36,520
those of you that's lived for that

00:10:35,260 --> 00:10:37,720
period of the query so you can have

00:10:36,520 --> 00:10:39,940
these building blocks that build on each

00:10:37,720 --> 00:10:42,670
other make it really really really easy

00:10:39,940 --> 00:10:45,160
to follow you can also you know comment

00:10:42,670 --> 00:10:48,640
the sequel in line as well really really

00:10:45,160 --> 00:10:49,779
simply with CTS window functions if

00:10:48,640 --> 00:10:51,370
you're doing things where you want to

00:10:49,779 --> 00:10:54,339
like settle order things like find a

00:10:51,370 --> 00:10:57,430
rank based on some category really

00:10:54,339 --> 00:10:58,990
useful functions there's hundreds and

00:10:57,430 --> 00:11:00,490
hundreds of functions if you're trying

00:10:58,990 --> 00:11:01,959
to do something to manipulate your data

00:11:00,490 --> 00:11:02,480
like find out what day of the week it is

00:11:01,959 --> 00:11:05,420
or

00:11:02,480 --> 00:11:07,010
ship things by one our really really

00:11:05,420 --> 00:11:08,300
useful that you can go and just probably

00:11:07,010 --> 00:11:14,269
have a function to do this sort of thing

00:11:08,300 --> 00:11:16,459
already in Postgres so indexing if

00:11:14,269 --> 00:11:18,230
you're like me so I actually about

00:11:16,459 --> 00:11:20,240
miners yes but I don't have a major in

00:11:18,230 --> 00:11:22,610
CS I don't work on the internals of

00:11:20,240 --> 00:11:24,920
databases every day I go to the docks

00:11:22,610 --> 00:11:26,570
when I want to add an index and I and I

00:11:24,920 --> 00:11:30,949
have no idea what's going on with all of

00:11:26,570 --> 00:11:32,690
these this super simplified version so a

00:11:30,949 --> 00:11:35,660
b-tree is usually what you want when you

00:11:32,690 --> 00:11:37,459
say create index b-tree indexes worth

00:11:35,660 --> 00:11:40,630
couldn't be created if you learned about

00:11:37,459 --> 00:11:43,130
an index and cs it was probably this

00:11:40,630 --> 00:11:45,170
then what happens with in Postgres with

00:11:43,130 --> 00:11:48,529
almost every major release now we get a

00:11:45,170 --> 00:11:50,649
new index type there's a group within

00:11:48,529 --> 00:11:52,730
the the community known as the Russians

00:11:50,649 --> 00:11:55,130
one of them is a professor of

00:11:52,730 --> 00:11:57,110
astrophysics at the University of Moscow

00:11:55,130 --> 00:12:01,010
and excellent Postgres for fun we have

00:11:57,110 --> 00:12:02,510
very different definitions of fun but he

00:12:01,010 --> 00:12:04,130
will go and read some papers say this

00:12:02,510 --> 00:12:06,230
can be really useful for this specific

00:12:04,130 --> 00:12:08,839
data type or this specific data

00:12:06,230 --> 00:12:10,339
structure or when you have this

00:12:08,839 --> 00:12:11,660
distribution of data this is really

00:12:10,339 --> 00:12:13,699
useful and will give us a 10x

00:12:11,660 --> 00:12:16,250
improvement for the first couple years

00:12:13,699 --> 00:12:18,680
everyone's like okay great sure we have

00:12:16,250 --> 00:12:19,850
indexes we're not worried about it he

00:12:18,680 --> 00:12:21,589
kind of went off three months later

00:12:19,850 --> 00:12:22,850
showed up with a prototype with numbers

00:12:21,589 --> 00:12:26,510
and it's like oh this actually works

00:12:22,850 --> 00:12:27,920
really cool now really sure what we kind

00:12:26,510 --> 00:12:29,060
of expect them like yeah this is crazy

00:12:27,920 --> 00:12:31,430
but it's kind of work and we're gonna

00:12:29,060 --> 00:12:34,579
see in the next release so we've got a

00:12:31,430 --> 00:12:36,410
Jin really useful if you're working with

00:12:34,579 --> 00:12:38,329
JSON B arrays you can think of it as

00:12:36,410 --> 00:12:42,440
having you know multiple values within a

00:12:38,329 --> 00:12:44,449
single column so you're packing and a

00:12:42,440 --> 00:12:48,319
bunch of values JSON keys and values

00:12:44,449 --> 00:12:49,940
directly in really useful just really

00:12:48,319 --> 00:12:51,470
useful simplified way is full text

00:12:49,940 --> 00:12:53,240
search geospatial you can think of it

00:12:51,470 --> 00:12:54,769
when you've got values within a row that

00:12:53,240 --> 00:12:56,510
might overlap other rows so if you think

00:12:54,769 --> 00:12:58,069
you've got a sentence there's part of

00:12:56,510 --> 00:12:59,089
this sentence that applies you know here

00:12:58,069 --> 00:13:00,829
and you've got another row that as

00:12:59,089 --> 00:13:03,230
another sentence part of that sentence

00:13:00,829 --> 00:13:04,790
could overlap or pulley got polygons

00:13:03,230 --> 00:13:06,199
where you got points anyone apply and

00:13:04,790 --> 00:13:12,829
hey does it overlap with and this wanted

00:13:06,199 --> 00:13:14,269
out SP just I asked every core developer

00:13:12,829 --> 00:13:15,709
every time I see them what it's good for

00:13:14,269 --> 00:13:16,460
and they literally just say thought

00:13:15,709 --> 00:13:18,920
numbers

00:13:16,460 --> 00:13:20,570
so that's all I know oh really large

00:13:18,920 --> 00:13:22,070
data sets the kind of naturally cluster

00:13:20,570 --> 00:13:23,630
together I've asked for another

00:13:22,070 --> 00:13:25,010
practical use of them and they'd get to

00:13:23,630 --> 00:13:26,270
come up with one so for now if you're

00:13:25,010 --> 00:13:30,170
dealing with phone numbers you probably

00:13:26,270 --> 00:13:31,820
want to SP just and then Bren block

00:13:30,170 --> 00:13:33,290
range index it's really useful for

00:13:31,820 --> 00:13:34,970
really really large tables I'm talking

00:13:33,290 --> 00:13:36,250
billions and billions of rows and things

00:13:34,970 --> 00:13:38,720
that are naturally clustered together

00:13:36,250 --> 00:13:40,460
most of the time you just want a tree

00:13:38,720 --> 00:13:41,750
sometimes you want gin and just if

00:13:40,460 --> 00:13:43,160
you're doing things with like JSON

00:13:41,750 --> 00:13:47,450
arrays

00:13:43,160 --> 00:13:50,510
geospatial stuff all right so a few

00:13:47,450 --> 00:13:53,840
people like writing a sequel who likes

00:13:50,510 --> 00:13:56,750
writing procedural sequel no one in that

00:13:53,840 --> 00:13:58,940
one so it's really powerful but there's

00:13:56,750 --> 00:14:01,100
another option with in Postgres PL v8

00:13:58,940 --> 00:14:02,710
which is the full v8 JavaScript engine

00:14:01,100 --> 00:14:04,880
and that it directly was in Postgres

00:14:02,710 --> 00:14:07,310
really powerful so I can go now and

00:14:04,880 --> 00:14:09,950
write you know procedural Java scripts

00:14:07,310 --> 00:14:11,210
do whatever I want I have a friend that

00:14:09,950 --> 00:14:12,560
jokes about creating like a two-tier

00:14:11,210 --> 00:14:13,640
application so he can just execute all

00:14:12,560 --> 00:14:15,950
the JavaScript directly in the database

00:14:13,640 --> 00:14:18,110
just figured out how to have to get

00:14:15,950 --> 00:14:20,420
Postgres to respond to web calls that

00:14:18,110 --> 00:14:21,770
hasn't happened yet but really useful we

00:14:20,420 --> 00:14:24,110
need to be more advanced things and you

00:14:21,770 --> 00:14:28,580
want a slightly better language than

00:14:24,110 --> 00:14:32,210
than procedural sequel and then

00:14:28,580 --> 00:14:34,130
extensions so more and more post fest to

00:14:32,210 --> 00:14:35,450
me is becoming a data platform like it

00:14:34,130 --> 00:14:37,850
used to maybe like a relational database

00:14:35,450 --> 00:14:40,730
in a very very strict thing and those

00:14:37,850 --> 00:14:43,070
bounds are kind of changing Postgres

00:14:40,730 --> 00:14:44,570
moves really slow and stable but

00:14:43,070 --> 00:14:46,880
post-crisis unique and it has this

00:14:44,570 --> 00:14:48,890
extension framework so you can have

00:14:46,880 --> 00:14:50,960
low-level hooks that change the behavior

00:14:48,890 --> 00:14:53,330
of Postgres so you can write your data

00:14:50,960 --> 00:14:56,750
types you can write new indexes you can

00:14:53,330 --> 00:14:58,520
write things that will take your data

00:14:56,750 --> 00:15:01,840
and just write it to deb null so you can

00:14:58,520 --> 00:15:04,250
write a run a really fast benchmark

00:15:01,840 --> 00:15:05,570
these are really low-level hooks that

00:15:04,250 --> 00:15:08,090
allow it to completely change what

00:15:05,570 --> 00:15:11,150
Postgres does one of the biggest ones

00:15:08,090 --> 00:15:13,940
suppose GIS so post GIS has its own huge

00:15:11,150 --> 00:15:16,520
ecosystem community of its own it's a

00:15:13,940 --> 00:15:18,110
massive extension host GIS is regarded

00:15:16,520 --> 00:15:20,480
as like the advanced open source

00:15:18,110 --> 00:15:22,130
geospatial database and it all basically

00:15:20,480 --> 00:15:25,130
goes and hooks into Postgres and extends

00:15:22,130 --> 00:15:27,500
it with new datatypes new functions all

00:15:25,130 --> 00:15:29,120
sorts of things you want time series

00:15:27,500 --> 00:15:30,050
there are some multiple time series

00:15:29,120 --> 00:15:32,600
extinctions

00:15:30,050 --> 00:15:34,400
if you want to migrate from Oracle over

00:15:32,600 --> 00:15:35,960
to Postgres there's an extension that

00:15:34,400 --> 00:15:38,480
will basically help with all that

00:15:35,960 --> 00:15:40,430
compatibility so really really powerful

00:15:38,480 --> 00:15:42,380
ability to go and change what Postgres

00:15:40,430 --> 00:15:44,630
does and extend it without us having to

00:15:42,380 --> 00:15:48,050
wait for you know a new release within

00:15:44,630 --> 00:15:49,730
the core to date there's about 100

00:15:48,050 --> 00:15:51,290
extensions or so new ones show up kind

00:15:49,730 --> 00:15:52,430
of every week if you're looking to do

00:15:51,290 --> 00:15:54,290
something that you think Postgres can't

00:15:52,430 --> 00:16:05,090
do take a look at the extensions that

00:15:54,290 --> 00:16:07,820
exist work so a couple of pro tips if

00:16:05,090 --> 00:16:11,330
you use a terminal PC cool is really

00:16:07,820 --> 00:16:14,810
really good I'm a big fan of it how many

00:16:11,330 --> 00:16:16,220
of you have like a bash RC setup okay

00:16:14,810 --> 00:16:19,310
most hands how many of you have a PC

00:16:16,220 --> 00:16:22,910
quality setup we're drinking together

00:16:19,310 --> 00:16:24,830
thereafter good making out so P sequel

00:16:22,910 --> 00:16:26,930
is really really powerful and awesome

00:16:24,830 --> 00:16:29,540
you can do things like Bosch class-ix

00:16:26,930 --> 00:16:31,370
Auto which will Auto format your text

00:16:29,540 --> 00:16:32,720
based on the width of your screen so if

00:16:31,370 --> 00:16:35,450
it was gonna wrap it's actually to go

00:16:32,720 --> 00:16:37,490
split those lines up one by one by one

00:16:35,450 --> 00:16:39,440
backslash timing will automatically turn

00:16:37,490 --> 00:16:41,150
on the timing for every query to tell

00:16:39,440 --> 00:16:43,580
you how long it ran really useful I

00:16:41,150 --> 00:16:45,980
actually had mine set up that will

00:16:43,580 --> 00:16:48,650
record the history of every query I run

00:16:45,980 --> 00:16:50,420
against the database so if you've ever

00:16:48,650 --> 00:16:52,250
had someone come to you and say hey can

00:16:50,420 --> 00:16:55,160
you give me a report of you know how

00:16:52,250 --> 00:16:58,160
many user signups we had last month from

00:16:55,160 --> 00:17:00,500
from Birmingham I you know hop in and I

00:16:58,160 --> 00:17:02,390
write this query sim in the report great

00:17:00,500 --> 00:17:03,590
and they come back six months later and

00:17:02,390 --> 00:17:04,850
say hey you remember that report that

00:17:03,590 --> 00:17:06,770
you ran for me six months ago that was

00:17:04,850 --> 00:17:09,470
really really useful I have no idea what

00:17:06,770 --> 00:17:11,120
they're talking about because I saved

00:17:09,470 --> 00:17:13,010
the history and it's saved in a file

00:17:11,120 --> 00:17:15,100
that matches the database thing I just

00:17:13,010 --> 00:17:17,240
have to reconnect to the database

00:17:15,100 --> 00:17:18,380
control-r and search back through my

00:17:17,240 --> 00:17:19,850
history start typing and I'll

00:17:18,380 --> 00:17:22,070
automatically populate with that query

00:17:19,850 --> 00:17:23,959
so I never lose a query against any

00:17:22,070 --> 00:17:26,720
database I'm connected to really really

00:17:23,959 --> 00:17:28,280
really handy and it's all sort of my

00:17:26,720 --> 00:17:29,690
piece equal RC so I don't have to do

00:17:28,280 --> 00:17:31,910
anything extra it's just automatically

00:17:29,690 --> 00:17:34,340
there if there's really common queries

00:17:31,910 --> 00:17:35,660
that you write you can name them so if

00:17:34,340 --> 00:17:37,490
you've got a hundred line sequel query

00:17:35,660 --> 00:17:39,630
you can actually name it and then just

00:17:37,490 --> 00:17:41,280
execute the name of that

00:17:39,630 --> 00:17:43,800
how you name it and it'll run that query

00:17:41,280 --> 00:17:46,770
for you really useful if you're not a CI

00:17:43,800 --> 00:17:49,050
person as your data studio I recommend

00:17:46,770 --> 00:17:54,990
is you know kind of evolving improving

00:17:49,050 --> 00:17:57,950
more GUI interface or Postgres anyone

00:17:54,990 --> 00:18:00,300
here not convinced I'm using Postgres

00:17:57,950 --> 00:18:02,400
alright hopefully it's a good case for

00:18:00,300 --> 00:18:03,990
it if you need more reading or need to

00:18:02,400 --> 00:18:07,740
commit someone else there's a couple of

00:18:03,990 --> 00:18:09,540
articles but this talk was really about

00:18:07,740 --> 00:18:10,890
Postgres anything scale so I actually

00:18:09,540 --> 00:18:12,420
just cover and kind of think of a bunch

00:18:10,890 --> 00:18:13,920
of things that you care about was really

00:18:12,420 --> 00:18:15,990
really small data and I say small data

00:18:13,920 --> 00:18:17,670
less than 10 gigabytes if you've got a

00:18:15,990 --> 00:18:19,620
database that's smaller than that

00:18:17,670 --> 00:18:21,240
Postgres is pretty much gonna handle it

00:18:19,620 --> 00:18:23,250
you don't have to do anything special or

00:18:21,240 --> 00:18:26,340
extra you want to leverage your data

00:18:23,250 --> 00:18:28,080
types do this early go ahead and start

00:18:26,340 --> 00:18:31,860
using arrays and the timestamp data

00:18:28,080 --> 00:18:34,770
types JSON B start putting indexes in

00:18:31,860 --> 00:18:37,980
place gradually back up things get a

00:18:34,770 --> 00:18:39,540
backup strategy going test it if you

00:18:37,980 --> 00:18:40,830
haven't tested your backup in the last

00:18:39,540 --> 00:18:42,540
six months

00:18:40,830 --> 00:18:44,820
I'll bet good money it's not gonna work

00:18:42,540 --> 00:18:46,290
I don't know if everyone saw the they

00:18:44,820 --> 00:18:48,150
get lab incident that was I think about

00:18:46,290 --> 00:18:49,980
a year or two ago now where they

00:18:48,150 --> 00:18:53,220
supposedly had five different mechanisms

00:18:49,980 --> 00:18:55,620
for backups and none of them work but

00:18:53,220 --> 00:18:57,630
they were down for hours lost data

00:18:55,620 --> 00:18:59,100
it was painful if you haven't tested

00:18:57,630 --> 00:19:01,350
your backups in the last month please

00:18:59,100 --> 00:19:03,630
just go home and do that see if it works

00:19:01,350 --> 00:19:05,160
I mean then spend some time getting your

00:19:03,630 --> 00:19:06,930
environment right go ahead and set up

00:19:05,160 --> 00:19:09,900
here PC core so you save your useful

00:19:06,930 --> 00:19:11,940
queries send up your history now and

00:19:09,900 --> 00:19:13,470
it's a lot easier than when you know

00:19:11,940 --> 00:19:14,850
you're in a crisis and triaging

00:19:13,470 --> 00:19:20,820
something that it's already set up for

00:19:14,850 --> 00:19:22,350
you all right so let's go into a little

00:19:20,820 --> 00:19:24,690
bit more medium scale so you've got an

00:19:22,350 --> 00:19:26,340
application you've had some success I'm

00:19:24,690 --> 00:19:29,190
gonna say this about you know 10 gigs

00:19:26,340 --> 00:19:30,780
200 gigs a few hundred gigs you can even

00:19:29,190 --> 00:19:35,040
say this is maybe up to the terabyte

00:19:30,780 --> 00:19:36,240
scale so here you're gonna sort of want

00:19:35,040 --> 00:19:37,680
to hear a little bit more about

00:19:36,240 --> 00:19:39,000
performance there's gonna be some key

00:19:37,680 --> 00:19:41,580
metrics you're gonna pay attention to

00:19:39,000 --> 00:19:44,270
you I do this on a weekly monthly basis

00:19:41,580 --> 00:19:46,200
or when things get slow here we come in

00:19:44,270 --> 00:19:49,410
the first thing you don't wanna pay

00:19:46,200 --> 00:19:51,390
attention to is your cache hit ratio I'm

00:19:49,410 --> 00:19:53,750
really excited for DuckTales back with

00:19:51,390 --> 00:19:53,750
my kids

00:19:55,180 --> 00:20:01,100
so this really quick cryptic query is

00:19:59,300 --> 00:20:02,480
just gonna give you back a really simple

00:20:01,100 --> 00:20:04,640
number and this can I show you the

00:20:02,480 --> 00:20:07,250
amount of times that your queries were

00:20:04,640 --> 00:20:10,070
served from cache rememory versus going

00:20:07,250 --> 00:20:12,890
to disk what you're gonna want here is

00:20:10,070 --> 00:20:15,680
to see 99% or higher if you're less than

00:20:12,890 --> 00:20:17,990
99% like those queries when you're at

00:20:15,680 --> 00:20:20,390
99% are often gonna come to me a 1/2

00:20:17,990 --> 00:20:23,060
millisecond kind of time frame as soon

00:20:20,390 --> 00:20:24,500
as it goes from like 99% to like 98

00:20:23,060 --> 00:20:26,630
you're gonna fall off a cliff and you're

00:20:24,500 --> 00:20:27,920
gonna see ten fifteen hundred

00:20:26,630 --> 00:20:30,620
millisecond kind of time for your

00:20:27,920 --> 00:20:32,210
queries anytime I talk to a database

00:20:30,620 --> 00:20:34,250
this is the first thing I'm gonna check

00:20:32,210 --> 00:20:37,220
and say you know what's my cache a ratio

00:20:34,250 --> 00:20:38,510
look like if it's too small you guys

00:20:37,220 --> 00:20:39,980
want to do some indexing or you want to

00:20:38,510 --> 00:20:41,510
go get a bigger database just go get a

00:20:39,980 --> 00:20:45,770
bigger one it's the easiest thing to do

00:20:41,510 --> 00:20:49,130
in terms of scaling databases a little

00:20:45,770 --> 00:20:51,470
more nuance is your index hit ratio so

00:20:49,130 --> 00:20:53,270
when you issue a query by default

00:20:51,470 --> 00:20:56,630
Postgres is gonna scan every single row

00:20:53,270 --> 00:20:58,640
in that query what you want to do is if

00:20:56,630 --> 00:21:00,980
you've got you know hundreds of

00:20:58,640 --> 00:21:02,540
thousands millions billions of records

00:21:00,980 --> 00:21:04,070
you don't want to scan every single

00:21:02,540 --> 00:21:05,990
record that's gonna take a while so you

00:21:04,070 --> 00:21:09,020
want to do is start to leverage indexes

00:21:05,990 --> 00:21:10,970
for your popular popular queries this is

00:21:09,020 --> 00:21:12,890
going to give you a list of all the

00:21:10,970 --> 00:21:14,630
tables in your database the number of

00:21:12,890 --> 00:21:17,870
rows and the amount of time you use in

00:21:14,630 --> 00:21:20,090
index really really useful to come in

00:21:17,870 --> 00:21:22,910
and say okay am i appropriately indexing

00:21:20,090 --> 00:21:28,430
things do I need to go in and change

00:21:22,910 --> 00:21:32,510
some things etc and then unused indexes

00:21:28,430 --> 00:21:34,730
so I just for fun tweeted a query

00:21:32,510 --> 00:21:37,070
because I could fit it into 140

00:21:34,730 --> 00:21:40,520
characters that would generate sequel to

00:21:37,070 --> 00:21:43,370
create an index on every column on every

00:21:40,520 --> 00:21:46,340
table in your database don't actually do

00:21:43,370 --> 00:21:48,080
that like yes every query will be fast

00:21:46,340 --> 00:21:52,280
but you're gonna be able to insert like

00:21:48,080 --> 00:21:53,810
one record per second but you can't be

00:21:52,280 --> 00:21:55,370
pretty liberal with indexing like if

00:21:53,810 --> 00:21:57,440
something slow go ahead and add an index

00:21:55,370 --> 00:21:59,600
but it's useful to come through where we

00:21:57,440 --> 00:22:02,570
so often every month to three months and

00:21:59,600 --> 00:22:04,279
get rid of ones that aren't being used

00:22:02,570 --> 00:22:05,690
and Postgres actually is really good at

00:22:04,279 --> 00:22:08,000
about keeping track of all these things

00:22:05,690 --> 00:22:11,029
like which indexes are used which ones

00:22:08,000 --> 00:22:13,220
aren't how many blocks are dirtied all

00:22:11,029 --> 00:22:14,480
these sort of things so you can come

00:22:13,220 --> 00:22:16,279
through here and actually see that hey

00:22:14,480 --> 00:22:17,840
we've got this index that has not been

00:22:16,279 --> 00:22:19,940
used in the last six months and just

00:22:17,840 --> 00:22:21,049
drop it really really useful so you can

00:22:19,940 --> 00:22:27,289
get some performance back on the right

00:22:21,049 --> 00:22:29,509
side so some rough guidelines any new

00:22:27,289 --> 00:22:31,759
database your cash flow ratio keep it

00:22:29,509 --> 00:22:33,440
above 99% as soon as this drops below

00:22:31,759 --> 00:22:37,340
that it's time to go get a bigger

00:22:33,440 --> 00:22:38,690
database index hit ratio this one varies

00:22:37,340 --> 00:22:42,230
based on the size of the table a little

00:22:38,690 --> 00:22:44,330
bit near your workload pattern generally

00:22:42,230 --> 00:22:47,090
I would say 95 percent or higher on you

00:22:44,330 --> 00:22:48,289
know any sizable table 10,000 rows is a

00:22:47,090 --> 00:22:51,019
decent record could be a hundred

00:22:48,289 --> 00:22:52,639
thousand tables that are maybe a hundred

00:22:51,019 --> 00:23:02,019
records you don't need a great index

00:22:52,639 --> 00:23:02,019
Arenas necessarily alright connections

00:23:02,710 --> 00:23:08,539
connections in Postgres are a bit of a

00:23:05,090 --> 00:23:10,100
sore spot overall every time you go and

00:23:08,539 --> 00:23:11,840
grab a new connection to your database

00:23:10,100 --> 00:23:14,269
like you there's TLS negotiation

00:23:11,840 --> 00:23:15,799
Postgres isn't perfect in this like the

00:23:14,269 --> 00:23:17,360
time to grab a new connection I would

00:23:15,799 --> 00:23:20,629
estimate it about 50 milliseconds it

00:23:17,360 --> 00:23:22,549
could be less it could be more so what

00:23:20,629 --> 00:23:25,129
typically happens is you know you set up

00:23:22,549 --> 00:23:26,690
a pool with an active record and it's

00:23:25,129 --> 00:23:27,889
gonna have a bunch of connections for

00:23:26,690 --> 00:23:30,529
you and your request comes in it says

00:23:27,889 --> 00:23:34,190
here's one from the pool now this is a

00:23:30,529 --> 00:23:35,389
bit of a problem because when you active

00:23:34,190 --> 00:23:38,750
record goes and grabs a pool

00:23:35,389 --> 00:23:40,549
automatically if it's you know 5 10

00:23:38,750 --> 00:23:43,159
connections for kind of each web server

00:23:40,549 --> 00:23:46,490
you're running that's a lot of wasted

00:23:43,159 --> 00:23:47,779
resources every connection even if it's

00:23:46,490 --> 00:23:51,080
running query or not consumes resources

00:23:47,779 --> 00:23:52,460
it consumes about SIMEX of memory and

00:23:51,080 --> 00:23:54,019
then when you get to hundreds and

00:23:52,460 --> 00:23:56,240
hundreds there's various lock contention

00:23:54,019 --> 00:23:59,059
and that's where thing going on under

00:23:56,240 --> 00:24:00,980
the covers idle connections in Postgres

00:23:59,059 --> 00:24:02,539
are basically just bad and wasted and

00:24:00,980 --> 00:24:04,940
you don't want them if you don't have to

00:24:02,539 --> 00:24:06,649
have them but we want fast connection so

00:24:04,940 --> 00:24:10,399
we you know turn on their application

00:24:06,649 --> 00:24:12,679
side connection pooling here at PG

00:24:10,399 --> 00:24:14,340
bouncer is really an ideal thing to to

00:24:12,679 --> 00:24:16,830
add to the stack

00:24:14,340 --> 00:24:18,930
what PG bouncer is gonna do is take all

00:24:16,830 --> 00:24:20,340
of those idle connections and just make

00:24:18,930 --> 00:24:21,990
them disappear it's gonna have its own

00:24:20,340 --> 00:24:23,250
pool but it's not gonna pass things

00:24:21,990 --> 00:24:25,560
through until you start to run a query

00:24:23,250 --> 00:24:26,580
automatically so if you're running a

00:24:25,560 --> 00:24:27,780
production application it would

00:24:26,580 --> 00:24:30,270
definitely recommend this if you have

00:24:27,780 --> 00:24:31,740
any sizable workload I've talked to

00:24:30,270 --> 00:24:33,450
people before they said you know hey I

00:24:31,740 --> 00:24:35,670
need 3,000 connections through my

00:24:33,450 --> 00:24:38,370
database can you raise the limit from

00:24:35,670 --> 00:24:39,540
1500 and I'm like do you really need

00:24:38,370 --> 00:24:42,540
that many like that's a really really

00:24:39,540 --> 00:24:44,790
big production application yeah yeah we

00:24:42,540 --> 00:24:46,530
have this many active to our database we

00:24:44,790 --> 00:24:48,120
hopped him and ran a query and there

00:24:46,530 --> 00:24:51,600
were 13 active connections on the

00:24:48,120 --> 00:24:53,070
database so several thousand idle doing

00:24:51,600 --> 00:24:56,850
absolutely nothing just wasting

00:24:53,070 --> 00:24:58,680
resources so they kind of get an idea

00:24:56,850 --> 00:25:00,570
right like PG bouncer is gonna sit right

00:24:58,680 --> 00:25:01,620
there between your database and all of

00:25:00,570 --> 00:25:03,450
your different rail servers

00:25:01,620 --> 00:25:05,670
you're gonna connect to it just like you

00:25:03,450 --> 00:25:07,080
into the database PG bouncers basically

00:25:05,670 --> 00:25:08,550
gonna wait for that query to start if

00:25:07,080 --> 00:25:10,350
it's a transaction it's gonna hold it

00:25:08,550 --> 00:25:12,270
all all the way through begin until you

00:25:10,350 --> 00:25:15,210
commit it's a really quick query it's

00:25:12,270 --> 00:25:16,260
just gonna pass it right on through it's

00:25:15,210 --> 00:25:17,700
gonna make everything much much

00:25:16,260 --> 00:25:19,830
healthier so if you run into connection

00:25:17,700 --> 00:25:21,480
issues at all or if you had you know 100

00:25:19,830 --> 00:25:22,680
connections are hired and you're not

00:25:21,480 --> 00:25:28,590
running PG bouncer would highly

00:25:22,680 --> 00:25:30,510
recommend it and that's mostly it for

00:25:28,590 --> 00:25:32,340
this for the medium scale like add some

00:25:30,510 --> 00:25:35,280
indexes watch your cache the ratio and

00:25:32,340 --> 00:25:37,700
things slow down add more memory it's a

00:25:35,280 --> 00:25:40,830
pretty good in robust database if you're

00:25:37,700 --> 00:25:42,210
looking to optimize specific queries PG

00:25:40,830 --> 00:25:44,850
stat statements is a really really

00:25:42,210 --> 00:25:47,280
useful tool as well PG set statements

00:25:44,850 --> 00:25:49,110
will show you every query that's ever

00:25:47,280 --> 00:25:51,390
been run against your database

00:25:49,110 --> 00:25:53,490
how many times it was run and then how

00:25:51,390 --> 00:25:54,780
long it took an average and in total so

00:25:53,490 --> 00:25:56,550
you can go and find like really really

00:25:54,780 --> 00:26:00,780
bad a fingers there so another really

00:25:56,550 --> 00:26:04,530
useful tool for that medium scale as you

00:26:00,780 --> 00:26:05,760
get a little bit larger you're gonna

00:26:04,530 --> 00:26:07,320
want to shift your backup strategy a

00:26:05,760 --> 00:26:10,290
little bit most people are just gonna do

00:26:07,320 --> 00:26:11,910
a PG dump once a day this is a logical

00:26:10,290 --> 00:26:13,230
back though it's really useful for

00:26:11,910 --> 00:26:15,120
pulling something from you know

00:26:13,230 --> 00:26:17,820
production down to staging or to your

00:26:15,120 --> 00:26:20,120
local machine it's basically like sequel

00:26:17,820 --> 00:26:22,140
and more or less raw inserted statements

00:26:20,120 --> 00:26:24,330
now it does have some load on the

00:26:22,140 --> 00:26:25,890
database so you know when you run this

00:26:24,330 --> 00:26:27,220
you're gonna run it at night when it's

00:26:25,890 --> 00:26:29,740
off peak so you

00:26:27,220 --> 00:26:32,380
there's not a huge performance hit it's

00:26:29,740 --> 00:26:34,450
really good for less than 50 gigs it

00:26:32,380 --> 00:26:36,190
will not work at a terabyte it might

00:26:34,450 --> 00:26:38,440
work at 100 gigs it might work to 200

00:26:36,190 --> 00:26:40,180
gigs there you're gonna want to ship to

00:26:38,440 --> 00:26:41,740
a physical back home here want to use

00:26:40,180 --> 00:26:43,180
something like PG backrest or Rolly

00:26:41,740 --> 00:26:44,920
there's a bunch of tools it's a little

00:26:43,180 --> 00:26:46,930
more overhead to set up which is why I

00:26:44,920 --> 00:26:49,810
say like you don't necessarily mean it

00:26:46,930 --> 00:26:51,640
right away when you're 10 gigs when

00:26:49,810 --> 00:26:53,110
you're at 50 100 gigs really really

00:26:51,640 --> 00:26:55,660
useful to shift your backup strategies

00:26:53,110 --> 00:26:57,130
to start to use physical backups this is

00:26:55,660 --> 00:26:59,940
gonna be the physical bytes on disk and

00:26:57,130 --> 00:27:03,040
then stream the Postgres right ahead log

00:26:59,940 --> 00:27:07,930
to something like an s3 or as your blob

00:27:03,040 --> 00:27:09,820
store that you can then replay it and so

00:27:07,930 --> 00:27:12,310
I mentioned this at be you know smaller

00:27:09,820 --> 00:27:14,620
scale middle scale applies of large

00:27:12,310 --> 00:27:17,650
scale like if things are slow add more

00:27:14,620 --> 00:27:21,510
cache if your cache hit ratio falls

00:27:17,650 --> 00:27:23,890
below that 99% go get a bigger instance

00:27:21,510 --> 00:27:28,480
it's the easiest thing to do for scaling

00:27:23,890 --> 00:27:30,460
a database now at some point you can

00:27:28,480 --> 00:27:33,310
only go so large like there's only a

00:27:30,460 --> 00:27:35,680
instance so big they do keep getting

00:27:33,310 --> 00:27:36,880
bigger and bigger and bigger but at some

00:27:35,680 --> 00:27:40,450
point you're gonna have to start to say

00:27:36,880 --> 00:27:42,280
you know breakout theta one option is

00:27:40,450 --> 00:27:45,730
deleting data for most businesses that's

00:27:42,280 --> 00:27:47,920
usually not a great option so here what

00:27:45,730 --> 00:27:49,630
you can do the quickest easiest thing is

00:27:47,920 --> 00:27:52,120
to start to spit out some reads to a

00:27:49,630 --> 00:27:55,210
read replica if you have things that are

00:27:52,120 --> 00:27:56,890
like business reporting or analytics

00:27:55,210 --> 00:27:58,000
those are great against to reread

00:27:56,890 --> 00:28:02,520
replicas because they're not competing

00:27:58,000 --> 00:28:04,870
for the same workload pulling out

00:28:02,520 --> 00:28:06,940
usually a really really large database

00:28:04,870 --> 00:28:09,910
there's one table and it's either called

00:28:06,940 --> 00:28:11,320
blogs events or messages like if you

00:28:09,910 --> 00:28:12,820
have one of these tables in your

00:28:11,320 --> 00:28:15,040
database it's probably the largest one

00:28:12,820 --> 00:28:16,630
and the bad offender that may not need

00:28:15,040 --> 00:28:18,070
to go in there with all the rest of your

00:28:16,630 --> 00:28:21,340
application data you can pull that one

00:28:18,070 --> 00:28:23,410
out then you can start to you know split

00:28:21,340 --> 00:28:27,430
things up or when a really large scales

00:28:23,410 --> 00:28:29,200
chart so shorting in the most simplest

00:28:27,430 --> 00:28:32,490
terms is just splitting your database up

00:28:29,200 --> 00:28:35,830
into smaller bits smaller tinier parts

00:28:32,490 --> 00:28:36,850
Gail wants me to cite it a little bit so

00:28:35,830 --> 00:28:38,530
cytus is an extent

00:28:36,850 --> 00:28:41,140
in pure open-source you can drop it in

00:28:38,530 --> 00:28:43,210
and it's gonna turn a bunch of different

00:28:41,140 --> 00:28:46,210
Postgres databases turn them into a

00:28:43,210 --> 00:28:47,230
distributed set up if your application

00:28:46,210 --> 00:28:48,700
they still looks like a single node

00:28:47,230 --> 00:28:50,520
database so you don't have to go

00:28:48,700 --> 00:28:53,680
rewriting a bunch of application logic

00:28:50,520 --> 00:28:54,820
so if you had like you know a Vince team

00:28:53,680 --> 00:28:56,170
when we were just put this up it would

00:28:54,820 --> 00:28:58,270
create like in the Vince underscore one

00:28:56,170 --> 00:29:00,900
two bits underscore two three spread

00:28:58,270 --> 00:29:02,920
these out across multiple physical notes

00:29:00,900 --> 00:29:05,440
when you query you're just gonna create

00:29:02,920 --> 00:29:07,180
events just like normal so shorting is

00:29:05,440 --> 00:29:08,260
just the process of splitting this out

00:29:07,180 --> 00:29:10,870
usually you've got to build some

00:29:08,260 --> 00:29:12,190
application logic to handle this site is

00:29:10,870 --> 00:29:17,950
do one extension that just handles it

00:29:12,190 --> 00:29:19,450
for you so here what's gonna happen and

00:29:17,950 --> 00:29:21,340
whether you're using citation or

00:29:19,450 --> 00:29:23,380
something else you're gonna want to hash

00:29:21,340 --> 00:29:25,660
your data upfront so you're gonna want

00:29:23,380 --> 00:29:29,350
to give undefined a number of shards say

00:29:25,660 --> 00:29:30,670
like 128 shards is a decent number your

00:29:29,350 --> 00:29:31,780
lines and find these buckets ahead of

00:29:30,670 --> 00:29:33,640
time you're not gonna be wanting to go

00:29:31,780 --> 00:29:35,290
and I create new ones every single day I

00:29:33,640 --> 00:29:36,580
see a lot of people that start with

00:29:35,290 --> 00:29:39,280
sharding and say okay I'm gonna put my

00:29:36,580 --> 00:29:41,140
first 10 customers on this box and I put

00:29:39,280 --> 00:29:43,060
my next 10 customers on another box and

00:29:41,140 --> 00:29:46,120
my next in the problem with that

00:29:43,060 --> 00:29:47,920
is your first 10 or your the ones with

00:29:46,120 --> 00:29:51,910
the most data the most valuable your

00:29:47,920 --> 00:29:53,290
your long-term customers so you got new

00:29:51,910 --> 00:29:54,550
customers coming in that have no data

00:29:53,290 --> 00:29:57,640
and you've got this one really really

00:29:54,550 --> 00:30:00,070
large instance still so better to

00:29:57,640 --> 00:30:02,020
actually hash every user ID that comes

00:30:00,070 --> 00:30:04,030
in and put them in buckets so you're

00:30:02,020 --> 00:30:07,300
gonna divide up the the hash space of

00:30:04,030 --> 00:30:10,570
whatever you create and split that up so

00:30:07,300 --> 00:30:12,550
that by default customer 1 2 3 4 all in

00:30:10,570 --> 00:30:13,960
different spots already now these are

00:30:12,550 --> 00:30:16,870
just tables under the covers so you're

00:30:13,960 --> 00:30:18,910
gonna create a lot of shards and one

00:30:16,870 --> 00:30:21,130
important note is a shard is not equal

00:30:18,910 --> 00:30:22,540
to it note a lot of people I see like oh

00:30:21,130 --> 00:30:24,400
I'm going to create two shards because I

00:30:22,540 --> 00:30:26,140
have two nodes

00:30:24,400 --> 00:30:28,510
George will end up being a table with in

00:30:26,140 --> 00:30:30,250
Postgres so you're gonna have like 128

00:30:28,510 --> 00:30:31,210
shards or hundred 28 table so you're

00:30:30,250 --> 00:30:34,470
just flip these across to different

00:30:31,210 --> 00:30:37,690
nodes so you have 64 on one 64 any other

00:30:34,470 --> 00:30:39,880
why this is helpful and important is

00:30:37,690 --> 00:30:40,960
when you outgrow those two notes that

00:30:39,880 --> 00:30:43,090
you have you're gonna go and add two

00:30:40,960 --> 00:30:46,060
more nodes and it's really easy to copy

00:30:43,090 --> 00:30:48,160
32 tables from one node over to the

00:30:46,060 --> 00:30:49,789
other than it is to go and copy data out

00:30:48,160 --> 00:30:51,229
of a table and break that up

00:30:49,789 --> 00:30:53,600
so you're gonna have a bunch of smaller

00:30:51,229 --> 00:30:55,129
tables already and then you're just

00:30:53,600 --> 00:30:57,529
gonna route them accordingly so as it

00:30:55,129 --> 00:31:04,299
comes in what's the hash ID of this user

00:30:57,529 --> 00:31:06,919
that goes to node3 send them there now

00:31:04,299 --> 00:31:09,470
scaling relational databases is hard

00:31:06,919 --> 00:31:13,460
you've got a bunch of relations and

00:31:09,470 --> 00:31:16,129
models you've got a bunch of joins like

00:31:13,460 --> 00:31:18,259
if you're a CRM you've got leads and

00:31:16,129 --> 00:31:21,919
accounts and opportunities and all these

00:31:18,259 --> 00:31:25,009
join and interact how you know aggregate

00:31:21,919 --> 00:31:25,869
from one section to the other how do you

00:31:25,009 --> 00:31:27,919
make sure something is completely

00:31:25,869 --> 00:31:31,419
transactional when you're going from one

00:31:27,919 --> 00:31:31,419
node to another in a distributed system

00:31:31,720 --> 00:31:36,289
so all this is actually to be made a lot

00:31:33,979 --> 00:31:37,669
easier by colocation so what you're

00:31:36,289 --> 00:31:40,220
going to want to do is define some

00:31:37,669 --> 00:31:43,460
really high level sharky that everything

00:31:40,220 --> 00:31:45,919
can start on for a lot of like if you're

00:31:43,460 --> 00:31:48,139
a SAS multi-tenant kind of application

00:31:45,919 --> 00:31:49,940
it's probably like customer ID or tenant

00:31:48,139 --> 00:31:51,289
ID really really common you're gonna

00:31:49,940 --> 00:31:53,239
want to actually put this on every

00:31:51,289 --> 00:31:55,909
single one of your tables and group them

00:31:53,239 --> 00:31:58,519
together so if I've got like a you know

00:31:55,909 --> 00:31:59,960
customer ID I put that on every table

00:31:58,519 --> 00:32:01,309
all of these tables are gonna live

00:31:59,960 --> 00:32:02,479
together so I've got customer ID and

00:32:01,309 --> 00:32:04,729
then I got you know the leads and

00:32:02,479 --> 00:32:06,889
accounts and opportunities all for

00:32:04,729 --> 00:32:08,450
customer one all those are gonna have

00:32:06,889 --> 00:32:10,519
the same resulting hash value because

00:32:08,450 --> 00:32:12,019
customer ID is one and so I'm going to

00:32:10,519 --> 00:32:14,239
start all those tables together inchoate

00:32:12,019 --> 00:32:16,039
locate them so I've got all the

00:32:14,239 --> 00:32:18,200
resulting hash ranges of this together

00:32:16,039 --> 00:32:20,450
which means I can actually join them

00:32:18,200 --> 00:32:22,609
again which I couldn't in a easily

00:32:20,450 --> 00:32:25,220
distributed fashion so all those are

00:32:22,609 --> 00:32:26,809
split up I've got a hundred drain shards

00:32:25,220 --> 00:32:29,869
of each of my leads my talents my

00:32:26,809 --> 00:32:33,259
opportunities tables together now for

00:32:29,869 --> 00:32:36,229
things that you can't necessarily shard

00:32:33,259 --> 00:32:37,970
and split up what you don't wanna do is

00:32:36,229 --> 00:32:39,019
create like a reference table and here

00:32:37,970 --> 00:32:40,789
you're gonna do a two-phase commit

00:32:39,019 --> 00:32:43,159
across all of these this is really

00:32:40,789 --> 00:32:45,259
common for like a categories if you have

00:32:43,159 --> 00:32:47,720
something like a you know state mapping

00:32:45,259 --> 00:32:48,979
or zip code something like that really

00:32:47,720 --> 00:32:51,649
really useful and you're just gonna want

00:32:48,979 --> 00:32:53,299
to have this typically be less than a

00:32:51,649 --> 00:32:55,279
hundred thousand records definitely less

00:32:53,299 --> 00:32:56,389
than a million because every time you

00:32:55,279 --> 00:32:57,710
write this data you're gonna have to

00:32:56,389 --> 00:33:00,259
write it to every single node and make

00:32:57,710 --> 00:33:02,049
sure it's a proper two-phase commit

00:33:00,259 --> 00:33:04,029
transaction

00:33:02,049 --> 00:33:05,830
but then you can join these things so

00:33:04,029 --> 00:33:08,380
even if something there is that there

00:33:05,830 --> 00:33:09,820
the table that you can't shard you can

00:33:08,380 --> 00:33:15,429
actually distribute it across all nodes

00:33:09,820 --> 00:33:18,279
and join now with charting you really

00:33:15,429 --> 00:33:19,750
don't want to do it until you have to so

00:33:18,279 --> 00:33:21,610
I would say you know look for things

00:33:19,750 --> 00:33:23,649
that are killing your cash head ratio

00:33:21,610 --> 00:33:27,070
like n plus 1 queries and consuming

00:33:23,649 --> 00:33:29,200
resources when you're really maxed out

00:33:27,070 --> 00:33:30,909
and your cash your at the largest

00:33:29,200 --> 00:33:33,039
instance your cash head ratio is low

00:33:30,909 --> 00:33:34,929
look at offloading things to a read

00:33:33,039 --> 00:33:37,330
replica for like the VI the analytics

00:33:34,929 --> 00:33:40,270
things that can have some latency don't

00:33:37,330 --> 00:33:42,880
have to be real-time can lag by an hour

00:33:40,270 --> 00:33:46,390
a few minutes that sort of thing that'll

00:33:42,880 --> 00:33:48,640
give you more runway when you do need to

00:33:46,390 --> 00:33:50,260
shard I talk to a bunch of people that

00:33:48,640 --> 00:33:52,179
you know tried to shard 10 years ago and

00:33:50,260 --> 00:33:55,600
five years ago I think the landscape has

00:33:52,179 --> 00:33:56,770
changed a lot if you tried to do with 10

00:33:55,600 --> 00:34:00,010
years ago you probably still have

00:33:56,770 --> 00:34:02,440
nightmares from it but then there's now

00:34:00,010 --> 00:34:04,690
use cases like Instagram which started

00:34:02,440 --> 00:34:05,710
when they were 8 employees and manage

00:34:04,690 --> 00:34:07,690
your pretty successfully they got a

00:34:05,710 --> 00:34:09,669
number it talks about it look at the

00:34:07,690 --> 00:34:14,950
guides and resources out there it's not

00:34:09,669 --> 00:34:19,030
as people as it used to be yeah all

00:34:14,950 --> 00:34:21,520
right so really quick recap small medium

00:34:19,030 --> 00:34:25,599
sized databases watch your cache a ratio

00:34:21,520 --> 00:34:27,190
number one use indexes I'm use the right

00:34:25,599 --> 00:34:30,070
indexes like that primers should give

00:34:27,190 --> 00:34:32,169
you a pretty good guide add a hundred

00:34:30,070 --> 00:34:36,099
connections or more I would highly

00:34:32,169 --> 00:34:37,720
recommend putting PG bouncer in place is

00:34:36,099 --> 00:34:42,639
anyone here using PG bouncer in

00:34:37,720 --> 00:34:43,990
production a few hands okay it's if

00:34:42,639 --> 00:34:45,909
connections have ever been a pain for

00:34:43,990 --> 00:34:48,520
8.4 you may be worth going back and

00:34:45,909 --> 00:34:49,599
looking at and please test your backups

00:34:48,520 --> 00:34:51,790
if you don't have a backup that you

00:34:49,599 --> 00:34:53,050
tested in the past few months you

00:34:51,790 --> 00:34:56,409
probably don't have a backup that'll

00:34:53,050 --> 00:34:58,950
work and that'll buy you into for larger

00:34:56,409 --> 00:35:01,359
scale modify your backup strategy

00:34:58,950 --> 00:35:03,940
identify the right shorty model this is

00:35:01,359 --> 00:35:06,130
actually good to do early like adding a

00:35:03,940 --> 00:35:08,500
customer ID onto every column every

00:35:06,130 --> 00:35:10,570
table if you've got like a multi-tenant

00:35:08,500 --> 00:35:11,770
app could be good to do when you're

00:35:10,570 --> 00:35:13,240
small so then you don't have to go in

00:35:11,770 --> 00:35:14,869
back so that later you don't have to

00:35:13,240 --> 00:35:17,720
char it but then when the time

00:35:14,869 --> 00:35:19,339
you're ready for it and then identify a

00:35:17,720 --> 00:35:20,839
collocation strategy that kind of work

00:35:19,339 --> 00:35:22,250
so you can maintain all the

00:35:20,839 --> 00:35:24,740
transactional consistency joins

00:35:22,250 --> 00:35:27,260
reporting all of that and then still do

00:35:24,740 --> 00:35:30,130
everything you did earlier on and that's

00:35:27,260 --> 00:35:30,130
it thank you

00:35:31,340 --> 00:35:34,499

YouTube URL: https://www.youtube.com/watch?v=rXPtXkYU134


