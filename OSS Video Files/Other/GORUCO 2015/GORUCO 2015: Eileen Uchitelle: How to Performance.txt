Title: GORUCO 2015: Eileen Uchitelle: How to Performance
Publication date: 2020-01-23
Playlist: GORUCO 2015
Description: 
	@eileencodes

Understanding performance output can feel like reading tea leaves. It makes sense to a few people, but many of us are left in the dark; overwhelmed and frustrated by the data. On top of that there are a ton of performance tools to choose from; StackProf, RubyProf, AllocationTracer. Where do you even start? While working on speeding up integration tests in Rails source, I learned that the key to improving the performance of Ruby code is having a baseline, not relying on one profiler and understanding the advantages and limitations of your tools. By utilizing these methods, integration tests are now 3 times faster than they were in Rails 4.2.0, with more improvements being made every day. In this talk we will not only look at how to read performance output, but when and how to use the right profilers for the job. We'll discuss a variety of methods and techniques for benchmarking and profiling so you can get the most out of any performance tool.

 Talk given at GORUCO 2015: http://goruco.com
Captions: 
	00:00:13,410 --> 00:00:19,900
today we're gonna talk about how to

00:00:15,840 --> 00:00:21,700
performance this hog is going to focus

00:00:19,900 --> 00:00:23,800
on tools and techniques to help speed up

00:00:21,700 --> 00:00:25,900
your Ruby code the things we're going to

00:00:23,800 --> 00:00:27,520
talk about today came out of work I did

00:00:25,900 --> 00:00:32,110
with Aaron Patterson to make integration

00:00:27,520 --> 00:00:33,309
tests faster in rails I'm Eileen you

00:00:32,110 --> 00:00:35,670
should tell and I'm a programmer at

00:00:33,309 --> 00:00:38,469
Basecamp formerly known as 37signals

00:00:35,670 --> 00:00:40,300
I'm also on the rails commuters team

00:00:38,469 --> 00:00:43,149
which means I can I'm allowed to push

00:00:40,300 --> 00:00:44,649
directly a master on rails I'm not in

00:00:43,149 --> 00:00:45,850
core which apparently means I'm not

00:00:44,649 --> 00:00:50,290
allowed to tweet from the rails Twitter

00:00:45,850 --> 00:00:53,530
account you can find me anywhere online

00:00:50,290 --> 00:00:55,540
at Eileen codes this is my dog Aria

00:00:53,530 --> 00:01:00,370
she's of course named after Arya Stark

00:00:55,540 --> 00:01:02,500
from Game of Thrones she has her own

00:01:00,370 --> 00:01:03,550
Twitter account at Aria dog and would

00:01:02,500 --> 00:01:05,560
love it if you followed her

00:01:03,550 --> 00:01:10,840
you should be warned though she loves to

00:01:05,560 --> 00:01:12,579
talk about poop I'm from upstate New

00:01:10,840 --> 00:01:14,200
York from a city called Kingston it's

00:01:12,579 --> 00:01:16,689
about two hours north of New York City

00:01:14,200 --> 00:01:19,600
it was the first capital of New York

00:01:16,689 --> 00:01:20,920
State in 1777 but then the British

00:01:19,600 --> 00:01:22,689
burned it down twice and we moved to

00:01:20,920 --> 00:01:26,409
Albany because we can't be trusted with

00:01:22,689 --> 00:01:28,170
it it's a wonderfully walkable city with

00:01:26,409 --> 00:01:30,639
near some of the best hiking in New York

00:01:28,170 --> 00:01:33,459
you can experience some of that hiking

00:01:30,639 --> 00:01:35,499
paired with inspiring technical talks if

00:01:33,459 --> 00:01:38,350
you come to the new Catskills comp on

00:01:35,499 --> 00:01:40,990
October 23rd to 25th it's going to be a

00:01:38,350 --> 00:01:45,219
wonderful weekend full of inspiration

00:01:40,990 --> 00:01:46,840
and learning in the Catskills I'm super

00:01:45,219 --> 00:01:48,310
happy he's speaking at Heroku this year

00:01:46,840 --> 00:01:49,840
because this was the first Ruby

00:01:48,310 --> 00:01:53,049
conference that I ever attended back in

00:01:49,840 --> 00:01:55,920
2012 I like the new logo a lot better

00:01:53,049 --> 00:01:55,920
it's more appropriate

00:01:57,540 --> 00:02:02,140
I'm not gonna go into details with those

00:01:59,979 --> 00:02:06,030
of you here in 2012 will understand why

00:02:02,140 --> 00:02:06,030
I can't wear the t-shirt from this year

00:02:06,600 --> 00:02:09,340
so you all remember I said I worked at

00:02:08,740 --> 00:02:11,709
base camp

00:02:09,340 --> 00:02:13,150
well DHH knows that performance is one

00:02:11,709 --> 00:02:14,650
of my favorite things which is why I'm

00:02:13,150 --> 00:02:18,310
on the performance and infrastructure

00:02:14,650 --> 00:02:21,490
team at base camp back in January David

00:02:18,310 --> 00:02:24,520
said to me hey I like fast things like

00:02:21,490 --> 00:02:27,910
race cars and I really hate it when

00:02:24,520 --> 00:02:29,500
things are slow I want to move base

00:02:27,910 --> 00:02:31,540
camps controller tests to integration

00:02:29,500 --> 00:02:33,670
tests but right now there are 20 to 40%

00:02:31,540 --> 00:02:36,489
slower than than controller tests and

00:02:33,670 --> 00:02:37,660
that's really just not going to do can

00:02:36,489 --> 00:02:39,700
you see what you can do about speeding

00:02:37,660 --> 00:02:42,970
up integration test and Rails so there

00:02:39,700 --> 00:02:43,330
as fast as race cars of course I said

00:02:42,970 --> 00:02:47,250
yes

00:02:43,330 --> 00:02:51,610
because this was a good opportunity to

00:02:47,250 --> 00:02:53,410
improve Rails for everyone if we're

00:02:51,610 --> 00:02:56,950
going to improve performance what's the

00:02:53,410 --> 00:02:59,110
first thing that we need to do we need

00:02:56,950 --> 00:03:00,790
to have a baseline this gives you

00:02:59,110 --> 00:03:02,019
something to measure against so that you

00:03:00,790 --> 00:03:03,760
know you're actually improving speed

00:03:02,019 --> 00:03:07,120
rather than just thinking or hoping you

00:03:03,760 --> 00:03:08,650
are so you get a good baseline I decided

00:03:07,120 --> 00:03:10,360
it would be a lot easier to not change

00:03:08,650 --> 00:03:12,250
base camp score code and build

00:03:10,360 --> 00:03:14,680
application specifically for testing

00:03:12,250 --> 00:03:15,250
this building a new application has many

00:03:14,680 --> 00:03:17,709
benefits

00:03:15,250 --> 00:03:19,840
one it's on github so you all can see

00:03:17,709 --> 00:03:22,480
all of the scripts that I wrote to test

00:03:19,840 --> 00:03:23,860
this and two it removes anything that

00:03:22,480 --> 00:03:26,500
can be getting in the way of helping me

00:03:23,860 --> 00:03:28,410
get build that base line like other gems

00:03:26,500 --> 00:03:30,970
and weird stuff

00:03:28,410 --> 00:03:32,890
of course HelloWorld examples aren't

00:03:30,970 --> 00:03:34,360
going to show or all of the slowdown is

00:03:32,890 --> 00:03:36,010
but you need to start with the bare

00:03:34,360 --> 00:03:38,200
minimum and build up from there so that

00:03:36,010 --> 00:03:40,200
you are not changing things that are not

00:03:38,200 --> 00:03:42,100
the real problem

00:03:40,200 --> 00:03:44,320
controller tests and integration tests

00:03:42,100 --> 00:03:45,940
don't look that different both define a

00:03:44,320 --> 00:03:48,130
test to processor out and assert

00:03:45,940 --> 00:03:50,799
something about that response here the

00:03:48,130 --> 00:03:52,810
index tests for both are getting the

00:03:50,799 --> 00:03:55,810
index route and asserting the response

00:03:52,810 --> 00:03:57,880
was a success to build a baseline I

00:03:55,810 --> 00:04:00,220
started Ruby to15 and rails force UO

00:03:57,880 --> 00:04:02,260
because that's what Basecamp was using

00:04:00,220 --> 00:04:04,090
at the time I wanted to be sure that

00:04:02,260 --> 00:04:05,020
integration tests were slow in isolation

00:04:04,090 --> 00:04:08,380
using the same

00:04:05,020 --> 00:04:10,030
knowledge base camp first I double-check

00:04:08,380 --> 00:04:11,440
that David's assertion that integration

00:04:10,030 --> 00:04:12,990
tests were twenty to forty percent

00:04:11,440 --> 00:04:15,070
slower was true

00:04:12,990 --> 00:04:16,810
David was basing this off the time they

00:04:15,070 --> 00:04:18,100
took to execute so I first looked at

00:04:16,810 --> 00:04:20,440
that knowing that it wasn't going to be

00:04:18,100 --> 00:04:21,400
my real baseline I ran it the single

00:04:20,440 --> 00:04:22,870
controller test that we looked at

00:04:21,400 --> 00:04:26,140
earlier and found that it took one point

00:04:22,870 --> 00:04:27,520
six to five seconds of real time I then

00:04:26,140 --> 00:04:29,230
around the corresponding integration

00:04:27,520 --> 00:04:32,050
tests and it took two point one two zero

00:04:29,230 --> 00:04:33,430
seconds of real time that calculated two

00:04:32,050 --> 00:04:34,510
integration tests being about twenty

00:04:33,430 --> 00:04:37,360
three percent slower than controller

00:04:34,510 --> 00:04:38,950
tests that's actually a huge difference

00:04:37,360 --> 00:04:41,140
and if you were gonna run your entire

00:04:38,950 --> 00:04:44,380
test we got integration tests that would

00:04:41,140 --> 00:04:46,180
take a lot longer I then decided to read

00:04:44,380 --> 00:04:49,510
run each of those tests five more times

00:04:46,180 --> 00:04:51,400
and got some interesting results they

00:04:49,510 --> 00:04:52,540
varied a lot and after a few runs

00:04:51,400 --> 00:04:54,190
appeared there was no difference between

00:04:52,540 --> 00:04:56,140
controller tests and integration tests

00:04:54,190 --> 00:04:58,570
and I knew this to be completely false

00:04:56,140 --> 00:05:00,490
and it pointed to the fact that time is

00:04:58,570 --> 00:05:02,040
not a good baseline for the type of

00:05:00,490 --> 00:05:04,450
performance work that needs to be done

00:05:02,040 --> 00:05:06,130
this is because using time only runs one

00:05:04,450 --> 00:05:08,170
iteration there are a lot of factors at

00:05:06,130 --> 00:05:10,810
play like garbage collection caching

00:05:08,170 --> 00:05:12,280
memory to use time we'd have to

00:05:10,810 --> 00:05:14,140
calculate the average of all the runs

00:05:12,280 --> 00:05:16,720
and figure out how many runs got a good

00:05:14,140 --> 00:05:18,760
average time was not a good baseline for

00:05:16,720 --> 00:05:20,530
me because it would be varied a lot and

00:05:18,760 --> 00:05:24,160
would require a lot more work to prove

00:05:20,530 --> 00:05:25,800
that I made it faster so if time isn't a

00:05:24,160 --> 00:05:28,270
good baseline how do we get a baseline

00:05:25,800 --> 00:05:30,460
we can that we can't start improving our

00:05:28,270 --> 00:05:31,930
code without one a good gem for

00:05:30,460 --> 00:05:33,940
benchmarking your Ruby code is benchmark

00:05:31,930 --> 00:05:36,040
a piece it was written by Evan Phoenix

00:05:33,940 --> 00:05:38,670
and the gem measures the number of times

00:05:36,040 --> 00:05:42,580
per second so the specified code can run

00:05:38,670 --> 00:05:44,620
in one that means the more iterations

00:05:42,580 --> 00:05:46,090
the faster your code it completely takes

00:05:44,620 --> 00:05:48,070
the guesswork out of figuring out how

00:05:46,090 --> 00:05:50,500
many runs you need to do to get a good

00:05:48,070 --> 00:05:53,380
average it also provides this percent of

00:05:50,500 --> 00:05:55,000
standard deviation so that you know how

00:05:53,380 --> 00:05:57,669
spread out your results are from that

00:05:55,000 --> 00:05:59,200
average benchmark Aquis allow you to

00:05:57,669 --> 00:06:01,950
focus on the results rather than the

00:05:59,200 --> 00:06:04,630
data points when benchmarking your code

00:06:01,950 --> 00:06:06,190
here's an example of the benchmark a key

00:06:04,630 --> 00:06:08,650
script I used to measure the difference

00:06:06,190 --> 00:06:11,380
between iteration and controller tests

00:06:08,650 --> 00:06:13,390
first we define the controller test it's

00:06:11,380 --> 00:06:15,550
a simple gap and we assert the response

00:06:13,390 --> 00:06:17,770
was a success then we do the same for

00:06:15,550 --> 00:06:18,579
the integration test get the index route

00:06:17,770 --> 00:06:22,519
and assert the risk

00:06:18,579 --> 00:06:25,189
success then we invoke the benchmark

00:06:22,519 --> 00:06:26,989
ipys gym inside the benchmark block we

00:06:25,189 --> 00:06:29,299
were at court report on each of the

00:06:26,989 --> 00:06:30,919
tests using mini test run one method we

00:06:29,299 --> 00:06:32,509
can call each of the tests individually

00:06:30,919 --> 00:06:33,859
and label them integration of functional

00:06:32,509 --> 00:06:36,649
tests so that they're easy to recognize

00:06:33,859 --> 00:06:38,959
after the run then we use the benchmark

00:06:36,649 --> 00:06:41,299
bang benchmark apiece compare bang

00:06:38,959 --> 00:06:42,979
method and to compare the number of

00:06:41,299 --> 00:06:44,719
times slower integration tests are then

00:06:42,979 --> 00:06:47,649
the controller tests this method is

00:06:44,719 --> 00:06:50,089
great because it doesn't matter for you

00:06:47,649 --> 00:06:52,989
we can then run this like any other test

00:06:50,089 --> 00:06:56,029
and it tells us that we were able to run

00:06:52,989 --> 00:06:57,859
393 iterations per iteration of

00:06:56,029 --> 00:06:59,989
integration tests per second you ever

00:06:57,859 --> 00:07:01,609
take 8% in comparison we were able to

00:06:59,989 --> 00:07:03,589
run nine hundred and twenty controller

00:07:01,609 --> 00:07:05,509
tests in one second you ever take seven

00:07:03,589 --> 00:07:07,009
percent the data shows that integration

00:07:05,509 --> 00:07:09,889
tests were two point four three four

00:07:07,009 --> 00:07:11,359
times slower than controller tests is a

00:07:09,889 --> 00:07:12,799
huge difference and is definitely not

00:07:11,359 --> 00:07:16,219
going to be noticeable when you're

00:07:12,799 --> 00:07:17,779
running an entire husky now that I had

00:07:16,219 --> 00:07:19,009
proved the integration tests were in

00:07:17,779 --> 00:07:20,959
fact definitely slower than controller

00:07:19,009 --> 00:07:22,639
tests and it had nothing to do

00:07:20,959 --> 00:07:24,679
specifically with base camps code I

00:07:22,639 --> 00:07:26,719
needed to double check that it was still

00:07:24,679 --> 00:07:28,959
true on rails master and the latest Ruby

00:07:26,719 --> 00:07:30,919
which at the time was Ruby to 200

00:07:28,959 --> 00:07:32,509
improve is to speed are being made all

00:07:30,919 --> 00:07:34,249
the time so it's a really good idea to

00:07:32,509 --> 00:07:35,869
be sure that it's still a problem on the

00:07:34,249 --> 00:07:37,129
latest versions because you don't want

00:07:35,869 --> 00:07:40,039
to be redoing work that someone has

00:07:37,129 --> 00:07:41,869
already done so I ran the same benchmark

00:07:40,039 --> 00:07:44,719
script with Ruby - - oh I'm not rails

00:07:41,869 --> 00:07:46,759
master and they were about the same a

00:07:44,719 --> 00:07:48,949
little bit slower but nothing to be

00:07:46,759 --> 00:07:50,269
concerned about if you check the

00:07:48,949 --> 00:07:52,609
iterations they're basically the same

00:07:50,269 --> 00:07:54,649
and have a slightly higher standard % of

00:07:52,609 --> 00:07:56,269
standard deviation with Ruby choo choooo

00:07:54,649 --> 00:07:59,569
and rails master integration test for

00:07:56,269 --> 00:08:01,159
2.5 3 times slower here the integration

00:07:59,569 --> 00:08:03,799
tester and paint and controller tests

00:08:01,159 --> 00:08:04,969
are in black we can we can compare why

00:08:03,799 --> 00:08:07,429
don't we compare the difference between

00:08:04,969 --> 00:08:09,859
rails 4 2 and master they're pretty

00:08:07,429 --> 00:08:11,419
close in a number of iterations but the

00:08:09,859 --> 00:08:14,599
newest Ruby and rails closed a tad

00:08:11,419 --> 00:08:17,569
slower for integration tests we are now

00:08:14,599 --> 00:08:19,750
getting on rails master denied 395

00:08:17,569 --> 00:08:21,870
variations in one second and not

00:08:19,750 --> 00:08:24,070
our 98 iterations of controller tests

00:08:21,870 --> 00:08:25,510
this demonstrates how much slower

00:08:24,070 --> 00:08:26,830
integration tests are than controller

00:08:25,510 --> 00:08:30,220
tests we weren't seeing this when we

00:08:26,830 --> 00:08:32,110
were using time as a baseline so now we

00:08:30,220 --> 00:08:34,360
have a solid baseline and we can start

00:08:32,110 --> 00:08:35,950
improving our code having this benchmark

00:08:34,360 --> 00:08:37,840
script means that we can be confident

00:08:35,950 --> 00:08:41,469
that we've improved the speed of our

00:08:37,840 --> 00:08:43,180
code and prove it to others the next

00:08:41,469 --> 00:08:45,610
step is to find what is slowing down our

00:08:43,180 --> 00:08:48,970
code we can't just go changing things

00:08:45,610 --> 00:08:51,240
without knowing what is actually slow so

00:08:48,970 --> 00:08:54,390
the first gem I used to profile our code

00:08:51,240 --> 00:08:57,430
the integration test was Ruby problem

00:08:54,390 --> 00:08:59,620
rubyprof requires Ruby 193 or higher and

00:08:57,430 --> 00:09:02,710
it's faster than other reprofiling cuz

00:08:59,620 --> 00:09:04,240
it's a C extension reproof is long has

00:09:02,710 --> 00:09:05,890
been around a lot longer than the other

00:09:04,240 --> 00:09:08,890
profilers first being released eight

00:09:05,890 --> 00:09:10,540
years ago the first script I wrote to

00:09:08,890 --> 00:09:12,700
profile the integration test and find

00:09:10,540 --> 00:09:14,560
where the slowdowns in rails were was

00:09:12,700 --> 00:09:16,690
this one to write this I follow along

00:09:14,560 --> 00:09:20,260
with the first rubyprof example on

00:09:16,690 --> 00:09:21,580
github first I set a set of the

00:09:20,260 --> 00:09:23,590
documents integration tests so I could

00:09:21,580 --> 00:09:26,170
specifically profile the integration

00:09:23,590 --> 00:09:27,940
test stuff here I'm using the Ruby prop

00:09:26,170 --> 00:09:29,830
API to run the index tests in a block

00:09:27,940 --> 00:09:32,890
this this will capture the integration

00:09:29,830 --> 00:09:35,350
test stack trace and finally I set the

00:09:32,890 --> 00:09:38,500
printer to the default printer which is

00:09:35,350 --> 00:09:40,120
flat and output to standard out and then

00:09:38,500 --> 00:09:42,270
when you run the Ruby prep in this

00:09:40,120 --> 00:09:44,410
terminal it returns following output

00:09:42,270 --> 00:09:46,720
read prop has given us quite a bit

00:09:44,410 --> 00:09:48,010
information here I don't know about you

00:09:46,720 --> 00:09:50,259
but when I first saw this I was pretty

00:09:48,010 --> 00:09:54,669
confused

00:09:50,259 --> 00:09:56,739
I wasn't really even sure what I was

00:09:54,669 --> 00:09:58,179
looking at and had no idea how to use

00:09:56,739 --> 00:10:00,399
this she'll actually speed anything up

00:09:58,179 --> 00:10:02,229
or figure out what was going on it was

00:10:00,399 --> 00:10:05,859
felt like it was a secret code telling

00:10:02,229 --> 00:10:08,259
me where Ruby's flow this was so let's

00:10:05,859 --> 00:10:10,059
break down what we're looking at first

00:10:08,259 --> 00:10:11,889
we have the percent tot of time spent in

00:10:10,059 --> 00:10:13,720
this method this is calculated from time

00:10:11,889 --> 00:10:15,939
spent in the method divided by total

00:10:13,720 --> 00:10:19,329
time then we have the total time spent

00:10:15,939 --> 00:10:20,649
in this method and its children now we

00:10:19,329 --> 00:10:22,989
have the total time spent in this

00:10:20,649 --> 00:10:25,479
particular method then we have the wait

00:10:22,989 --> 00:10:27,850
time spent in this method the time spent

00:10:25,479 --> 00:10:30,249
those methods children the number of

00:10:27,850 --> 00:10:32,459
times his method was called and finally

00:10:30,249 --> 00:10:34,209
the method name that was called

00:10:32,459 --> 00:10:36,069
unfortunately even after breaking this

00:10:34,209 --> 00:10:38,879
down I wasn't entirely sure what to do

00:10:36,069 --> 00:10:40,779
with this it was really overwhelming I

00:10:38,879 --> 00:10:42,009
started reading the documentation more

00:10:40,779 --> 00:10:44,649
closely and playing with available

00:10:42,009 --> 00:10:46,239
options and Printers first I found an

00:10:44,649 --> 00:10:48,189
each other printer called graph HTML

00:10:46,239 --> 00:10:50,019
printer there are no screenshots of how

00:10:48,189 --> 00:10:51,369
these work so you have to do a lot of

00:10:50,019 --> 00:10:53,039
trial and error to figure out what's

00:10:51,369 --> 00:10:55,029
good what's data that you can understand

00:10:53,039 --> 00:10:57,009
instead of printing a standard out I

00:10:55,029 --> 00:10:59,819
printed to a specified file which is

00:10:57,009 --> 00:11:01,839
HTML and you open it in the browser and

00:10:59,819 --> 00:11:02,859
it's a little bit more readable but I

00:11:01,839 --> 00:11:05,319
still haven't no idea what this is

00:11:02,859 --> 00:11:06,910
saying at first glance it almost seems

00:11:05,319 --> 00:11:07,539
like global team method is your problem

00:11:06,910 --> 00:11:09,069
because you're spending a hundred

00:11:07,539 --> 00:11:10,359
percent of your time there that's

00:11:09,069 --> 00:11:12,429
definitely not the case and the next

00:11:10,359 --> 00:11:13,929
printer will show you why a better way

00:11:12,429 --> 00:11:15,819
to demonstrate the time spent let's use

00:11:13,929 --> 00:11:17,829
the call stack printer this is by far

00:11:15,819 --> 00:11:20,439
the easiest output to understand it

00:11:17,829 --> 00:11:22,809
creates a visual type display of your

00:11:20,439 --> 00:11:24,939
stop and where your code is spending the

00:11:22,809 --> 00:11:26,259
most time well you want to focus on are

00:11:24,939 --> 00:11:29,529
the parts of the stack that are not part

00:11:26,259 --> 00:11:31,329
of the main straight cascade so if you

00:11:29,529 --> 00:11:33,669
look closer at the top part where you

00:11:31,329 --> 00:11:35,559
have that straight line you can see that

00:11:33,669 --> 00:11:37,779
a hundred percent in global no method is

00:11:35,559 --> 00:11:39,279
just the first method call so you're

00:11:37,779 --> 00:11:41,169
always going to spend a hundred percent

00:11:39,279 --> 00:11:42,970
of your time in the top and the

00:11:41,169 --> 00:11:44,799
beginning of your stuff so what you want

00:11:42,970 --> 00:11:46,959
to do need to focus on if you use this

00:11:44,799 --> 00:11:49,119
is the ones that are not part of the

00:11:46,959 --> 00:11:51,039
main stack and actually are jutting out

00:11:49,119 --> 00:11:52,720
farther so if we look closer at this one

00:11:51,039 --> 00:11:54,069
we can see that we're spending 12.5 six

00:11:52,720 --> 00:11:56,529
percent of our time and actually just

00:11:54,069 --> 00:11:57,850
budget runner reset and this could

00:11:56,529 --> 00:12:01,029
potentially be a good place to start

00:11:57,850 --> 00:12:03,040
looking for problems in your code so a

00:12:01,029 --> 00:12:05,230
root crop is really great for showing

00:12:03,040 --> 00:12:07,060
the big picture but at the same time the

00:12:05,230 --> 00:12:08,260
data can feel incredibly overwhelming

00:12:07,060 --> 00:12:10,120
and frustrating if you're not familiar

00:12:08,260 --> 00:12:11,680
with how to use it there are a lot of

00:12:10,120 --> 00:12:15,160
options that come with every prop so

00:12:11,680 --> 00:12:16,630
it's worth trying them out overall we

00:12:15,160 --> 00:12:18,310
promise most useful for finding the

00:12:16,630 --> 00:12:19,930
differences between the code stocks for

00:12:18,310 --> 00:12:22,240
integration tests and controller tests

00:12:19,930 --> 00:12:32,550
but in the end we didn't use it to

00:12:22,240 --> 00:12:35,760
improve the speed of the code all right

00:12:32,550 --> 00:12:35,760
not yet

00:12:36,050 --> 00:12:40,249
once I had these results I posted to the

00:12:38,809 --> 00:12:41,059
rels proud to come base camp about my

00:12:40,249 --> 00:12:43,279
findings

00:12:41,059 --> 00:12:45,290
I was hoping members of the rails core

00:12:43,279 --> 00:12:47,329
team can give you some insight into the

00:12:45,290 --> 00:12:48,800
data I had collected I got a lot of

00:12:47,329 --> 00:12:50,300
feedback in this point iearnt Patterson

00:12:48,800 --> 00:12:51,769
chimes in and says hey that sounds like

00:12:50,300 --> 00:12:55,040
a really great idea for my rails comp

00:12:51,769 --> 00:13:06,019
talk let's work on this together so I

00:12:55,040 --> 00:13:11,239
can use your code in my slides I wish I

00:13:06,019 --> 00:13:12,920
hadn't ruined that one the first tool

00:13:11,239 --> 00:13:15,920
that Aaron introduced me to was that

00:13:12,920 --> 00:13:18,230
crop stack crop is written by ami Gupta

00:13:15,920 --> 00:13:19,999
and is a ruby profiler like Ruby prop

00:13:18,230 --> 00:13:21,589
but it takes a sampling of the call

00:13:19,999 --> 00:13:24,009
stack so you can focus on the biggest

00:13:21,589 --> 00:13:26,410
problems and slow down to your code

00:13:24,009 --> 00:13:29,029
let's take a look at how to set this up

00:13:26,410 --> 00:13:31,939
here's an example of the stack crop code

00:13:29,029 --> 00:13:32,989
we used again we add the integration

00:13:31,939 --> 00:13:36,649
test code like we did in the previous

00:13:32,989 --> 00:13:38,089
examples then we call stack profit and

00:13:36,649 --> 00:13:40,309
set a file for it to output to you

00:13:38,089 --> 00:13:42,110
inside the block you run mini tests 3000

00:13:40,309 --> 00:13:45,920
times we run it so many times so we can

00:13:42,110 --> 00:13:47,209
get a real sample of our Ruby code we

00:13:45,920 --> 00:13:49,100
can't run this like we did before and

00:13:47,209 --> 00:13:51,290
since it's outputting to a file we just

00:13:49,100 --> 00:13:52,850
need to open that file that we specified

00:13:51,290 --> 00:13:55,429
in the script you can do that with

00:13:52,850 --> 00:14:00,429
sacrify type doing stack rock - - text

00:13:55,429 --> 00:14:03,079
and pat tech path to the file dump file

00:14:00,429 --> 00:14:05,420
this will show you the sample profile of

00:14:03,079 --> 00:14:06,740
your Ruby code and it seems kind of

00:14:05,420 --> 00:14:08,779
confusing at first it's similar to what

00:14:06,740 --> 00:14:11,209
we learned in Ruby prop section but the

00:14:08,779 --> 00:14:13,730
stack is sorted by time spent in each

00:14:11,209 --> 00:14:17,569
frame let's take a look at would each

00:14:13,730 --> 00:14:18,919
column represents the first column is

00:14:17,569 --> 00:14:21,350
the total number of samples where this

00:14:18,919 --> 00:14:23,240
print was in the stack next is the

00:14:21,350 --> 00:14:25,519
percent of time all samples spent in

00:14:23,240 --> 00:14:27,410
this frame then stack cross shows the

00:14:25,519 --> 00:14:30,829
number of samples where this was the

00:14:27,410 --> 00:14:32,449
topmost frame then we have time have the

00:14:30,829 --> 00:14:35,299
percent of time where this method was

00:14:32,449 --> 00:14:37,869
the topmost frame and lastly it shows

00:14:35,299 --> 00:14:40,369
the method that was called in this frame

00:14:37,869 --> 00:14:42,290
stack crop output is sorted by most time

00:14:40,369 --> 00:14:43,519
spent at the top so we can focus on the

00:14:42,290 --> 00:14:45,079
top line where it says we're spending

00:14:43,519 --> 00:14:46,470
fifty three percent of our time a mini

00:14:45,079 --> 00:14:48,930
test run a bowl on signal

00:14:46,470 --> 00:14:50,330
and those of you who saw Aaron girls

00:14:48,930 --> 00:14:52,260
can't talk me where I'm going with this

00:14:50,330 --> 00:14:54,480
let's take a look at the on signal

00:14:52,260 --> 00:14:57,180
method and basically this method is just

00:14:54,480 --> 00:14:58,740
yielding so the so if the integration

00:14:57,180 --> 00:15:00,600
tests really are spending fifty three

00:14:58,740 --> 00:15:02,220
fifty three percent of our time in on

00:15:00,600 --> 00:15:06,320
signal we can just delete all the code

00:15:02,220 --> 00:15:09,120
and just make the method only yield

00:15:06,320 --> 00:15:11,130
there's no way that only a yield would

00:15:09,120 --> 00:15:13,440
be the source of slowness in our code so

00:15:11,130 --> 00:15:15,540
we can run stack drop again ma test on

00:15:13,440 --> 00:15:17,280
signal is no longer in our stack and the

00:15:15,540 --> 00:15:19,410
newest slowest code is search for file

00:15:17,280 --> 00:15:24,230
at fourteen point seven percent so we're

00:15:19,410 --> 00:15:26,780
done this is mini tests problem now so

00:15:24,230 --> 00:15:29,270
let's open an issue grab a beer and go

00:15:26,780 --> 00:15:31,160
work on something else Oh what we forgot

00:15:29,270 --> 00:15:33,680
to do something super super important

00:15:31,160 --> 00:15:35,050
when you're doing performance you need

00:15:33,680 --> 00:15:37,430
to follow the number-one rule of

00:15:35,050 --> 00:15:40,540
verifying that you improve performance

00:15:37,430 --> 00:15:43,670
I call it ABB always be benchmarking

00:15:40,540 --> 00:15:45,110
every time you change something to

00:15:43,670 --> 00:15:46,790
improve performance you have to

00:15:45,110 --> 00:15:48,650
benchmark your code otherwise you have

00:15:46,790 --> 00:15:50,540
no idea that you're making it faster and

00:15:48,650 --> 00:15:57,020
it's just like having unicorns run

00:15:50,540 --> 00:15:58,550
around they're not real just to be sure

00:15:57,020 --> 00:16:00,350
let's run that benchmark script again

00:15:58,550 --> 00:16:01,880
with the change that we made to you on

00:16:00,350 --> 00:16:03,230
signal and mini test we should see a

00:16:01,880 --> 00:16:04,760
massive improvement now that we are not

00:16:03,230 --> 00:16:06,800
spending 53 percent of our time in mini

00:16:04,760 --> 00:16:12,200
test and we run this again we can see

00:16:06,800 --> 00:16:14,210
that we are still at 2.5 3 times slower

00:16:12,200 --> 00:16:17,660
which is exactly the same and it hasn't

00:16:14,210 --> 00:16:19,130
improved at all at this time I was

00:16:17,660 --> 00:16:21,850
pairing remotely with iron and he was

00:16:19,130 --> 00:16:21,850
pretty upset too

00:16:23,940 --> 00:16:28,420
he said it was impossible and then there

00:16:26,889 --> 00:16:30,700
was no way that this could be happening

00:16:28,420 --> 00:16:31,839
and he was right after a little bit of

00:16:30,700 --> 00:16:34,029
research and consulting the creator

00:16:31,839 --> 00:16:36,519
stock prof he found that there was a bug

00:16:34,029 --> 00:16:38,170
in OS X that causes CPU time to be

00:16:36,519 --> 00:16:41,490
completely 100 percent inaccurate and

00:16:38,170 --> 00:16:41,490
not correctly profile the code

00:16:41,670 --> 00:16:46,149
this is something to remember if you

00:16:43,720 --> 00:16:48,310
stock proper any profiler that defaults

00:16:46,149 --> 00:16:51,160
to CPU time Linux does not have this

00:16:48,310 --> 00:16:54,040
issue so you're pretty you CPU time with

00:16:51,160 --> 00:16:55,690
stack rock on that OS we can simply

00:16:54,040 --> 00:16:57,610
resolve this by using wall time instead

00:16:55,690 --> 00:17:00,100
so if we change our the mode in our

00:16:57,610 --> 00:17:01,810
stack cross script from CPU to wall time

00:17:00,100 --> 00:17:03,910
we get accurate results that tell us

00:17:01,810 --> 00:17:05,110
where the real problems are and that

00:17:03,910 --> 00:17:06,670
problem wasn't in mini test

00:17:05,110 --> 00:17:09,220
it's not even represented on our stack a

00:17:06,670 --> 00:17:10,839
tall stack rothman wall time actually

00:17:09,220 --> 00:17:13,449
pointed to a regression in the delegate

00:17:10,839 --> 00:17:15,549
method that we were spending 28.3% of

00:17:13,449 --> 00:17:17,319
our time there and Aaron changed the

00:17:15,549 --> 00:17:19,449
delegate methods in route set to be just

00:17:17,319 --> 00:17:21,309
ran out and if we're on the stack crop

00:17:19,449 --> 00:17:23,439
again we can see that module delegate is

00:17:21,309 --> 00:17:27,100
no longer in the list and the slowest

00:17:23,439 --> 00:17:28,480
example we have now is 4% and if we

00:17:27,100 --> 00:17:30,910
follow our number one rule of always we

00:17:28,480 --> 00:17:33,010
but always be benchmarking we run the

00:17:30,910 --> 00:17:34,780
benchmark script again and integration

00:17:33,010 --> 00:17:36,940
test went for being 2.5 3 times slower

00:17:34,780 --> 00:17:39,309
at 1.4 times slower and that's a huge

00:17:36,940 --> 00:17:40,720
improvement here we can see that we

00:17:39,309 --> 00:17:42,429
actually lost some iterations in the

00:17:40,720 --> 00:17:43,809
controller test after this change but

00:17:42,429 --> 00:17:45,970
the integration tests have gained back

00:17:43,809 --> 00:17:48,010
200 more iterate 200 more iterations in

00:17:45,970 --> 00:17:49,510
a second so we're definitely starting to

00:17:48,010 --> 00:17:51,370
see you some improvement in integration

00:17:49,510 --> 00:17:55,120
test speed and closing the gap between

00:17:51,370 --> 00:17:56,799
the two stack coffee is really great for

00:17:55,120 --> 00:18:00,160
helping point out slowdowns in your code

00:17:56,799 --> 00:18:02,530
that quickly would slow down so quickly

00:18:00,160 --> 00:18:04,240
because it sorts by the slowest profile

00:18:02,530 --> 00:18:06,820
rather than having to search through all

00:18:04,240 --> 00:18:08,380
of the information at once but an issue

00:18:06,820 --> 00:18:09,910
that we did have a stack crop was there

00:18:08,380 --> 00:18:11,500
was really a hard to pinpoint problems

00:18:09,910 --> 00:18:13,840
when methods were dynamically created or

00:18:11,500 --> 00:18:16,360
modules were anonymous one such method

00:18:13,840 --> 00:18:17,650
was you're all helpers and we found that

00:18:16,360 --> 00:18:19,270
was creating a net we found that URL

00:18:17,650 --> 00:18:21,490
helpers was creating an extra anonymous

00:18:19,270 --> 00:18:22,750
module I looked back in the game history

00:18:21,490 --> 00:18:24,130
and found that this method you used to

00:18:22,750 --> 00:18:26,950
be member wise so I just added the cash

00:18:24,130 --> 00:18:28,480
back the diff is much larger than this

00:18:26,950 --> 00:18:30,040
but you get the idea you're all helpers

00:18:28,480 --> 00:18:31,480
is now cached and we should see awesome

00:18:30,040 --> 00:18:33,970
speed improvements and everyone will be

00:18:31,480 --> 00:18:35,650
happy after caching the URL helpers you

00:18:33,970 --> 00:18:38,110
run the benchmark script again and it

00:18:35,650 --> 00:18:40,419
was a minor improvement they went from

00:18:38,110 --> 00:18:43,870
being 1.4 times slower to 1.3 6 times

00:18:40,419 --> 00:18:45,540
slower and saw an improvement in the

00:18:43,870 --> 00:18:47,890
controller test as well

00:18:45,540 --> 00:18:49,240
but I reported out that there's a better

00:18:47,890 --> 00:18:51,160
way to fix this besides cashing your El

00:18:49,240 --> 00:18:52,510
helpers when it's working when working

00:18:51,160 --> 00:18:54,330
with performance is really easy to think

00:18:52,510 --> 00:18:56,440
that you should cash all the things

00:18:54,330 --> 00:18:58,929
because caching is going to fix all your

00:18:56,440 --> 00:19:01,420
problems somehow but it's actually kind

00:18:58,929 --> 00:19:03,010
of dangerous captioning comes with a

00:19:01,420 --> 00:19:04,450
cost and if you're able to speed up your

00:19:03,010 --> 00:19:07,690
code without caching it you should

00:19:04,450 --> 00:19:08,950
absolutely do that first the problem was

00:19:07,690 --> 00:19:10,690
that URL helpers was being called when

00:19:08,950 --> 00:19:12,220
it wasn't necessary the integration

00:19:10,690 --> 00:19:13,870
tests didn't always need URL helpers

00:19:12,220 --> 00:19:14,740
when they were being called an initial

00:19:13,870 --> 00:19:17,170
mm-hmm

00:19:14,740 --> 00:19:18,250
initialized so the better path is to

00:19:17,170 --> 00:19:20,230
move them to where they are needed

00:19:18,250 --> 00:19:22,300
rather than caching it the dip is a

00:19:20,230 --> 00:19:23,890
large but if we look closer we can see

00:19:22,300 --> 00:19:26,110
this change is taking URL helpers

00:19:23,890 --> 00:19:28,540
include from the integration session

00:19:26,110 --> 00:19:30,580
initialize and you only be called when

00:19:28,540 --> 00:19:32,170
the session is reset now that we have

00:19:30,580 --> 00:19:33,880
done this we need to remember to follow

00:19:32,170 --> 00:19:35,530
our number one rule always be

00:19:33,880 --> 00:19:37,660
benchmarking so if you run the script

00:19:35,530 --> 00:19:39,250
again we can see that we have improved

00:19:37,660 --> 00:19:41,170
the test even more from when we catch

00:19:39,250 --> 00:19:43,210
them we capture all helpers we were at

00:19:41,170 --> 00:19:44,860
one point three six times slower but

00:19:43,210 --> 00:19:46,240
after this change we are at one point

00:19:44,860 --> 00:19:48,970
twelve times slower than controller

00:19:46,240 --> 00:19:50,290
tests chart makes it clear that we've

00:19:48,970 --> 00:19:51,820
gained a lot of iterations on

00:19:50,290 --> 00:19:55,870
integration tests and gain back the ones

00:19:51,820 --> 00:19:57,309
that we lost on controller tests stack

00:19:55,870 --> 00:19:59,110
drop is great for helping us find the

00:19:57,309 --> 00:20:00,640
largest problems in our rail source that

00:19:59,110 --> 00:20:02,470
were causing the slow to slow downs in

00:20:00,640 --> 00:20:03,940
the integration tests of course you made

00:20:02,470 --> 00:20:05,950
a lot more improvements that I didn't

00:20:03,940 --> 00:20:07,210
demonstrate today but we were starting

00:20:05,950 --> 00:20:10,090
to get to the point where we were making

00:20:07,210 --> 00:20:13,540
my perturbance to performance was just

00:20:10,090 --> 00:20:15,160
super tedious one thing that we noticed

00:20:13,540 --> 00:20:16,450
after removing the largest culprits was

00:20:15,160 --> 00:20:18,340
that we were spending a lot of time in

00:20:16,450 --> 00:20:20,980
garbage collection eleven point thirteen

00:20:18,340 --> 00:20:22,120
percent this is because we were creating

00:20:20,980 --> 00:20:24,460
a lot of objects that need to be garbage

00:20:22,120 --> 00:20:27,309
collected to figure out why we returned

00:20:24,460 --> 00:20:28,809
to a location tracer a location tracer

00:20:27,309 --> 00:20:30,970
was written by Kikuchi and is a tool for

00:20:28,809 --> 00:20:32,890
finding many how many objects are being

00:20:30,970 --> 00:20:35,710
allocated by Ruby and where they are in

00:20:32,890 --> 00:20:37,330
your code allocation tracer focuses on a

00:20:35,710 --> 00:20:38,650
specific problem your Ruby code and

00:20:37,330 --> 00:20:43,120
helps narrow down unnecessary

00:20:38,650 --> 00:20:44,590
allocations of objects here's an example

00:20:43,120 --> 00:20:46,150
of the allocation tracer script we used

00:20:44,590 --> 00:20:48,760
to track allocations in integration

00:20:46,150 --> 00:20:51,010
tests to use allocation tracer we needed

00:20:48,760 --> 00:20:51,810
to include object space then we define

00:20:51,010 --> 00:20:56,670
the index

00:20:51,810 --> 00:20:58,590
test as we've done in past scores we

00:20:56,670 --> 00:21:00,540
then stead of allocation tracer and call

00:20:58,590 --> 00:21:02,460
path line and type this allows us to

00:21:00,540 --> 00:21:05,880
define the information we want from a

00:21:02,460 --> 00:21:08,070
location tracers output then we assign

00:21:05,880 --> 00:21:10,680
the trace to a result again we run the

00:21:08,070 --> 00:21:12,650
test 3000 mini tests for 3000 times to

00:21:10,680 --> 00:21:15,990
get accurate example of allocations

00:21:12,650 --> 00:21:17,880
finally we sort the results by counts so

00:21:15,990 --> 00:21:19,680
that we have the highest ones reversed

00:21:17,880 --> 00:21:21,120
puts the highest counts at the top and

00:21:19,680 --> 00:21:23,130
then we return just the first five

00:21:21,120 --> 00:21:24,450
because we don't need all the allocated

00:21:23,130 --> 00:21:26,940
objects just the top five biggest

00:21:24,450 --> 00:21:27,870
offenders let me run the allocation

00:21:26,940 --> 00:21:29,730
trace your script like we've done with

00:21:27,870 --> 00:21:31,020
past scripts and then I'll put is a

00:21:29,730 --> 00:21:32,130
little bit confusing at first but once

00:21:31,020 --> 00:21:33,300
you get the hang of the data you're

00:21:32,130 --> 00:21:35,550
looking at and know what you're looking

00:21:33,300 --> 00:21:37,110
for it makes a lot of sense this shows

00:21:35,550 --> 00:21:39,780
us the past of the file that allocated

00:21:37,110 --> 00:21:42,270
the object then we have the line number

00:21:39,780 --> 00:21:43,680
where the objects were allocated next is

00:21:42,270 --> 00:21:46,880
the type of object that was allocated

00:21:43,680 --> 00:21:49,380
this can be a string a hash struct array

00:21:46,880 --> 00:21:51,600
the next array gives us the total count

00:21:49,380 --> 00:21:54,090
of objects created this is really the

00:21:51,600 --> 00:21:55,620
number that we care about the old count

00:21:54,090 --> 00:21:57,180
of objects which were which are objects

00:21:55,620 --> 00:22:00,570
that haven't been a garbage collector

00:21:57,180 --> 00:22:02,880
yet the total age of objects the minimum

00:22:00,570 --> 00:22:05,330
age of objects the maximum age of

00:22:02,880 --> 00:22:07,050
objects and the total memory size

00:22:05,330 --> 00:22:08,910
specifically we found that a lot of

00:22:07,050 --> 00:22:10,680
object allocation problems were in rack

00:22:08,910 --> 00:22:12,030
and not rails at least the top by

00:22:10,680 --> 00:22:14,550
biggest offenders for the time that we

00:22:12,030 --> 00:22:16,050
ran this script one of the ways in which

00:22:14,550 --> 00:22:18,060
we reduce time spent in garbage

00:22:16,050 --> 00:22:20,070
collection Iraq was to reduce the number

00:22:18,060 --> 00:22:21,920
of strings being created a simple way to

00:22:20,070 --> 00:22:23,790
do this is to freeze certain strings

00:22:21,920 --> 00:22:25,710
after each of these improvements you

00:22:23,790 --> 00:22:27,450
could check our allocations now here we

00:22:25,710 --> 00:22:29,640
don't need to be benchmarking because

00:22:27,450 --> 00:22:31,950
we're not specifically trying to improve

00:22:29,640 --> 00:22:34,410
speed but rather reduce time and garbage

00:22:31,950 --> 00:22:37,170
collection which should eventually speed

00:22:34,410 --> 00:22:39,420
up the code because GC is expensive in

00:22:37,170 --> 00:22:41,310
this run we can see that Rell's has

00:22:39,420 --> 00:22:43,530
replaced three of the rack allocations

00:22:41,310 --> 00:22:45,870
in our top five this is from changes

00:22:43,530 --> 00:22:47,310
mostly where refers strings the reason

00:22:45,870 --> 00:22:49,230
we froze the strings is because when you

00:22:47,310 --> 00:22:50,700
assign a string key to a hash the string

00:22:49,230 --> 00:22:52,770
is copied which creates more objects

00:22:50,700 --> 00:22:54,630
freezing prevents this but makes the

00:22:52,770 --> 00:22:57,150
string immutable now before you declare

00:22:54,630 --> 00:22:59,240
that winter is coming and that you need

00:22:57,150 --> 00:23:01,820
to freeze all the strings

00:22:59,240 --> 00:23:04,100
you must absolutely first prove that

00:23:01,820 --> 00:23:05,840
shrinking allocations are a problem you

00:23:04,100 --> 00:23:07,340
don't want to prematurely optimize this

00:23:05,840 --> 00:23:07,970
code because you're making the strings

00:23:07,340 --> 00:23:10,280
immutable

00:23:07,970 --> 00:23:11,660
it's an odd note is if this isn't

00:23:10,280 --> 00:23:13,220
necessary if it's not slowing down your

00:23:11,660 --> 00:23:15,410
code and dangerous if the string ever

00:23:13,220 --> 00:23:17,480
needs to change this should only be done

00:23:15,410 --> 00:23:18,950
if it's absolutely necessary so I hope

00:23:17,480 --> 00:23:20,510
we don't see any of you send the giant

00:23:18,950 --> 00:23:24,730
flaw request to Rails freezing all the

00:23:20,510 --> 00:23:24,730
strings telle saying I told you to do it

00:23:24,820 --> 00:23:28,790
you absolutely must first prove that the

00:23:27,380 --> 00:23:32,210
string is a bottleneck before freezing

00:23:28,790 --> 00:23:33,410
it a location tracer was a great tool

00:23:32,210 --> 00:23:35,990
for finding where objects for being

00:23:33,410 --> 00:23:37,910
unnecessary allocated in rails and where

00:23:35,990 --> 00:23:39,830
GC was wasting our time we unfortunately

00:23:37,910 --> 00:23:41,240
didn't see much improvement from this

00:23:39,830 --> 00:23:43,250
but it's also because there are micro

00:23:41,240 --> 00:23:45,340
improvements which can be very tedious

00:23:43,250 --> 00:23:47,660
and get boring after a while

00:23:45,340 --> 00:23:49,100
Connect integration tester wherever you

00:23:47,660 --> 00:23:50,630
start it that's it before we started to

00:23:49,100 --> 00:23:52,670
where we ended up we're almost faster

00:23:50,630 --> 00:23:54,429
than the original controller tests we

00:23:52,670 --> 00:23:56,780
close that gap quite a bit

00:23:54,429 --> 00:23:58,580
originally we can only run 393

00:23:56,780 --> 00:24:00,740
iterations of integration tests now we

00:23:58,580 --> 00:24:02,210
current 828 variations of integration

00:24:00,740 --> 00:24:03,650
tests it's a huge difference in

00:24:02,210 --> 00:24:05,150
calculation with the integration test

00:24:03,650 --> 00:24:06,800
being almost three times faster in

00:24:05,150 --> 00:24:09,830
current routes and they were in rails 4

00:24:06,800 --> 00:24:11,120
- in fact most of these changes didn't

00:24:09,830 --> 00:24:12,710
actually alter the behavior of the code

00:24:11,120 --> 00:24:15,140
so they're available in the newest rails

00:24:12,710 --> 00:24:18,800
4 - so you don't have to wait for rails

00:24:15,140 --> 00:24:21,440
5 to get these improvements I hope this

00:24:18,800 --> 00:24:24,860
helps you better understand how to use

00:24:21,440 --> 00:24:26,179
performance tools be sure you know the

00:24:24,860 --> 00:24:28,070
advantages and disadvantages and the

00:24:26,179 --> 00:24:29,570
tools that you're using you need to

00:24:28,070 --> 00:24:31,820
understand the limitations so you don't

00:24:29,570 --> 00:24:34,100
end up frustrated with your tools no

00:24:31,820 --> 00:24:36,260
tools can do everything so be sure to

00:24:34,100 --> 00:24:37,760
use multiple tools we were only able to

00:24:36,260 --> 00:24:40,010
speed up integration tests because we

00:24:37,760 --> 00:24:41,960
combined benchmark AP's rubyprof stack

00:24:40,010 --> 00:24:44,330
for off an allocation tracer and of

00:24:41,960 --> 00:24:45,320
course always be benchmarking it will

00:24:44,330 --> 00:24:47,270
help you be confident that you're

00:24:45,320 --> 00:24:50,179
actually speeding up your code rep and

00:24:47,270 --> 00:24:53,900
able to defend it it may even help you

00:24:50,179 --> 00:24:55,940
find a bug in your profiler if you do

00:24:53,900 --> 00:24:57,320
ever end up setting a pull request to

00:24:55,940 --> 00:24:58,730
Rails or any other project that's

00:24:57,320 --> 00:25:00,080
improves performance make sure you

00:24:58,730 --> 00:25:02,030
include those benchmark IDs in your

00:25:00,080 --> 00:25:02,660
commit message I want to say thank you

00:25:02,030 --> 00:25:05,000
to a few people

00:25:02,660 --> 00:25:06,669
thanks to iearn for helping me with this

00:25:05,000 --> 00:25:08,929
work

00:25:06,669 --> 00:25:10,249
there I know there was some concern that

00:25:08,929 --> 00:25:11,779
he was serious when he said that he

00:25:10,249 --> 00:25:14,859
stole my code for his rails comp talk

00:25:11,779 --> 00:25:17,749
but it was a joint effort I promise

00:25:14,859 --> 00:25:19,369
and thank you to all the gem creators of

00:25:17,749 --> 00:25:20,929
the gems that we used and thanks to the

00:25:19,369 --> 00:25:24,220
Roku for having me speak here today and

00:25:20,929 --> 00:25:24,220
thank you to all of you for listening

00:25:40,880 --> 00:25:42,940

YouTube URL: https://www.youtube.com/watch?v=oT74HLvDo_A


