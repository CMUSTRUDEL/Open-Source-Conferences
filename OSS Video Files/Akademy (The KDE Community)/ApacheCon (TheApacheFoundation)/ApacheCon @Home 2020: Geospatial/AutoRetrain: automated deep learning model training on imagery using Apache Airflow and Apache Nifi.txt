Title: AutoRetrain: automated deep learning model training on imagery using Apache Airflow and Apache Nifi
Publication date: 2020-10-22
Playlist: ApacheCon @Home 2020: Geospatial
Description: 
	AutoRetrain: automated deep learning model training on imagery using Apache Airflow and Apache Nifi.-
Carlos Caceres

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

The ability to automate model training is a complex subject that has recently received much attention in the deep learning community. Multiple workflow management systems have also begun gaining traction, and are necessary in order to orchestrate the necessary steps to make auto-retraining feasible. This work tackles model automation by making use of two such technologies: Apache Airflow and Apache Nifi. Since both fields of automatic model training and the overarching field of AutoML are broad and complex, this work seeks to show the utility of AutoML approaches on object detection in overhead imagery by a simple approach: integrating cycles of model retraining as data becomes available over time. Not only does this approach match the reality of data acquisition, it also seeks to leverage information as it becomes available and in so doing, reduces the time lag from acquiring new data to extracting useful intelligence. This work tackles a few problems practitioners often encounter when involved in long-term, deep learning projects. Questions include: 1). when to start a new round of training, 2). how to minimize the time complexity of training a deep learning network, and 3). how to tackle the problem of selection bias, which occurs when training sets contain uneven probability across classes. The third and most complex question originates from the uneven distribution that may be present in the data. This bias occurs for a variety of reasons, low sampling opportunities chief among them. Selection bias and other forms of dataset bias are only a part of the learning problem as learning through back propagation also allows the model to ignore uncertainty in its predictions. Instead, certain scenarios have been helped by other techniques, such as curriculum learning, active-bias learning, and hard example mining that focus training on easy, uncertain, and hard examples respectively. Retraining as described consists of training cycles, where each cycle contains the whole data science pipeline â€“ from data gathering, data preparation, to training, and scoring. In order to automate this process for a production system, it is first necessary to establish a reliable method to orchestrate the execution of individual pieces of the pipeline. To this end, this work experimented with Apache Nifi and Apache Airflow, two popular data flow management tools. By combining them with a tracking tool such as Mlflow, both Apache Nifi and Apache Airflow become extremely useful in managing retraining flows in a way that allows for reliable reproducibility.

Carlos Caceres:
MAXAR
Cloud Computing for Gov & Milsatcom Applications from satellite data.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,080 --> 00:00:27,760
this is

00:00:24,640 --> 00:00:30,000
uh our next uh talk in the geospatial

00:00:27,760 --> 00:00:33,200
track we're pleased to have carlos

00:00:30,000 --> 00:00:34,000
from maxar uh and continue kind of the

00:00:33,200 --> 00:00:35,760
machine learning

00:00:34,000 --> 00:00:38,239
and using apache tools on machine

00:00:35,760 --> 00:00:40,000
learning on big imagery maxar's got some

00:00:38,239 --> 00:00:43,520
you know big imagery so

00:00:40,000 --> 00:00:46,239
carlos please give us your

00:00:43,520 --> 00:00:47,680
talk yeah great uh thanks a lot for that

00:00:46,239 --> 00:00:49,520
uh so

00:00:47,680 --> 00:00:50,719
good uh good morning good afternoon i

00:00:49,520 --> 00:00:51,760
know whatever the time might be where

00:00:50,719 --> 00:00:53,520
you are

00:00:51,760 --> 00:00:54,879
thanks for having me my name is carlos

00:00:53,520 --> 00:00:58,160
castros

00:00:54,879 --> 00:01:00,079
i'm a data scientist at matsar where

00:00:58,160 --> 00:01:02,160
we're working with uh deep learning

00:01:00,079 --> 00:01:04,320
solutions to you know big

00:01:02,160 --> 00:01:05,439
big data in terms of uh satellite

00:01:04,320 --> 00:01:06,479
imagery

00:01:05,439 --> 00:01:08,560
in this presentation i'm gonna be

00:01:06,479 --> 00:01:10,320
talking a little bit about

00:01:08,560 --> 00:01:12,320
um some of the initial work that we've

00:01:10,320 --> 00:01:14,479
been doing in terms of

00:01:12,320 --> 00:01:16,240
doing outreach training so basically

00:01:14,479 --> 00:01:18,960
training models but also

00:01:16,240 --> 00:01:20,240
how to incorporate feedback and how to

00:01:18,960 --> 00:01:23,200
incorporate

00:01:20,240 --> 00:01:24,880
in ingest data through time right out of

00:01:23,200 --> 00:01:25,439
this in another amazing way by using

00:01:24,880 --> 00:01:29,040
some of the

00:01:25,439 --> 00:01:31,840
battery tools so um first let's

00:01:29,040 --> 00:01:34,320
go through like the agenda very fast and

00:01:31,840 --> 00:01:38,079
some of the objectives of this talk

00:01:34,320 --> 00:01:39,439
so we're gonna first look at a very

00:01:38,079 --> 00:01:41,920
quick

00:01:39,439 --> 00:01:43,040
two-slide introduction into image-based

00:01:41,920 --> 00:01:44,560
deep learning

00:01:43,040 --> 00:01:46,399
and specifically thinking about some of

00:01:44,560 --> 00:01:48,079
the challenges with deep learning and

00:01:46,399 --> 00:01:49,600
asset applies to satellite imagery

00:01:48,079 --> 00:01:52,159
specifically

00:01:49,600 --> 00:01:54,000
from then we're going to look at uh how

00:01:52,159 --> 00:01:56,240
these challenges take us to the

00:01:54,000 --> 00:01:58,719
motivation for this work specifically

00:01:56,240 --> 00:02:00,640
and uh the tests that we've done in

00:01:58,719 --> 00:02:02,640
order to kind of um

00:02:00,640 --> 00:02:04,960
piece out how reliable these approaches

00:02:02,640 --> 00:02:06,960
are in terms of

00:02:04,960 --> 00:02:08,239
improving performance and satellite

00:02:06,960 --> 00:02:10,720
imagery object

00:02:08,239 --> 00:02:11,680
detection right right where the task is

00:02:10,720 --> 00:02:15,120
that we want to

00:02:11,680 --> 00:02:17,599
we want to be as as correct as possible

00:02:15,120 --> 00:02:20,560
we want to have the best performance

00:02:17,599 --> 00:02:21,680
from then we're going to take another

00:02:20,560 --> 00:02:25,280
turn and look at

00:02:21,680 --> 00:02:28,800
automation methods that uh are used

00:02:25,280 --> 00:02:31,040
by by my team and in the last few months

00:02:28,800 --> 00:02:32,959
in order to try to

00:02:31,040 --> 00:02:34,160
do make as much of this automated as

00:02:32,959 --> 00:02:36,959
possible right because

00:02:34,160 --> 00:02:37,840
as you will see the pipelines that end

00:02:36,959 --> 00:02:40,080
up happening

00:02:37,840 --> 00:02:41,760
uh can be complex and they can be very

00:02:40,080 --> 00:02:43,760
time consuming so you want to do as much

00:02:41,760 --> 00:02:47,040
of it in a hands-off approach

00:02:43,760 --> 00:02:48,800
uh as possible right uh so

00:02:47,040 --> 00:02:50,160
i guess again it's just like framework

00:02:48,800 --> 00:02:52,160
for them it's half an hour

00:02:50,160 --> 00:02:54,879
so we're going to start out by looking

00:02:52,160 --> 00:02:58,879
at an initial approach to

00:02:54,879 --> 00:03:02,480
uh retraining of models and how

00:02:58,879 --> 00:03:04,400
these approaches get us some improvement

00:03:02,480 --> 00:03:06,239
in terms of performance and then we're

00:03:04,400 --> 00:03:08,879
going to look at

00:03:06,239 --> 00:03:09,519
the framework but in which we might do

00:03:08,879 --> 00:03:12,640
this

00:03:09,519 --> 00:03:15,120
and this framework should be able to

00:03:12,640 --> 00:03:16,159
um this framework should be able to

00:03:15,120 --> 00:03:18,560
support

00:03:16,159 --> 00:03:20,480
not only automation but also being able

00:03:18,560 --> 00:03:21,840
to track performance over time right so

00:03:20,480 --> 00:03:23,519
if we are training models

00:03:21,840 --> 00:03:26,159
continuously and improving on those

00:03:23,519 --> 00:03:28,799
models we want to be able to

00:03:26,159 --> 00:03:29,920
uh support tracking of the performance

00:03:28,799 --> 00:03:32,400
and the parameters

00:03:29,920 --> 00:03:33,840
and all the aspects that went into all

00:03:32,400 --> 00:03:35,280
the parameters and aspects and hyper

00:03:33,840 --> 00:03:35,920
parameters that went into a specific

00:03:35,280 --> 00:03:38,560
model

00:03:35,920 --> 00:03:39,840
so that down the road somewhere if uh we

00:03:38,560 --> 00:03:42,080
have a detection if we have

00:03:39,840 --> 00:03:43,360
some results that are of interest we can

00:03:42,080 --> 00:03:46,239
always go back and

00:03:43,360 --> 00:03:47,440
figure out the piece of information

00:03:46,239 --> 00:03:50,799
right that went into

00:03:47,440 --> 00:03:53,920
into making that possible okay so

00:03:50,799 --> 00:03:55,760
diving uh head on into

00:03:53,920 --> 00:03:57,519
image-based deep learning right that's a

00:03:55,760 --> 00:04:00,879
quick introduction

00:03:57,519 --> 00:04:02,799
um as you all might know or may not know

00:04:00,879 --> 00:04:05,439
uh image-based deep learning has been

00:04:02,799 --> 00:04:07,519
you know a revolution since maybe

00:04:05,439 --> 00:04:10,239
the early 2010s doesn't offer around

00:04:07,519 --> 00:04:13,760
there with the image the competition

00:04:10,239 --> 00:04:15,439
um image-based deep learning has

00:04:13,760 --> 00:04:17,359
exploded it's been used in a lot of

00:04:15,439 --> 00:04:18,320
different fields or a lot of different

00:04:17,359 --> 00:04:21,040
problems

00:04:18,320 --> 00:04:22,320
uh some of the obvious problems to use

00:04:21,040 --> 00:04:23,919
the user for are

00:04:22,320 --> 00:04:25,919
cases of classification right so for

00:04:23,919 --> 00:04:27,440
instance an image an image such as this

00:04:25,919 --> 00:04:29,440
that you have here

00:04:27,440 --> 00:04:31,040
you might ask the question of well is

00:04:29,440 --> 00:04:34,639
this an image of a

00:04:31,040 --> 00:04:36,240
you know a bird or a cat or a dog um

00:04:34,639 --> 00:04:37,759
then moving on to the object detection

00:04:36,240 --> 00:04:40,960
realm now you're talking about

00:04:37,759 --> 00:04:42,080
localization problems right can i find

00:04:40,960 --> 00:04:45,120
the thing that i'm interested

00:04:42,080 --> 00:04:47,440
in in an image and given that i found it

00:04:45,120 --> 00:04:49,440
can i perhaps count how many of them are

00:04:47,440 --> 00:04:51,919
there in other person right

00:04:49,440 --> 00:04:52,880
uh in the segmentation realm of object

00:04:51,919 --> 00:04:55,199
detection

00:04:52,880 --> 00:04:56,320
you're looking at segmenting whole

00:04:55,199 --> 00:04:59,440
instances of tasks

00:04:56,320 --> 00:05:00,720
of objects so given an image you know

00:04:59,440 --> 00:05:03,600
can i

00:05:00,720 --> 00:05:05,919
extract out the the person or the or the

00:05:03,600 --> 00:05:08,479
car or

00:05:05,919 --> 00:05:10,240
whatever other object you might have now

00:05:08,479 --> 00:05:12,000
in order to do this uh

00:05:10,240 --> 00:05:13,919
since in the last few years right since

00:05:12,000 --> 00:05:15,120
this revolution has started

00:05:13,919 --> 00:05:16,960
there's been a lot of models that have

00:05:15,120 --> 00:05:19,280
been developed like the yellow type

00:05:16,960 --> 00:05:22,840
models ssds and retinas right

00:05:19,280 --> 00:05:24,000
these models perform um their tasks very

00:05:22,840 --> 00:05:26,880
well

00:05:24,000 --> 00:05:28,400
um now when i say model right thinking

00:05:26,880 --> 00:05:31,039
uh taking a quick step back

00:05:28,400 --> 00:05:32,400
when i say model there's nothing you

00:05:31,039 --> 00:05:35,680
know magical going on here

00:05:32,400 --> 00:05:36,080
uh black deep learning models are often

00:05:35,680 --> 00:05:38,560
thought

00:05:36,080 --> 00:05:40,000
to be black boxes but in reality there

00:05:38,560 --> 00:05:42,639
is just a collection of

00:05:40,000 --> 00:05:43,039
matrix operations over over an image

00:05:42,639 --> 00:05:46,720
right

00:05:43,039 --> 00:05:49,280
or the ultimate uh or the ultimate goal

00:05:46,720 --> 00:05:51,280
is to try to extract out some

00:05:49,280 --> 00:05:53,039
some contents information around pixels

00:05:51,280 --> 00:05:55,520
and from then

00:05:53,039 --> 00:05:56,800
make some decision about what is what is

00:05:55,520 --> 00:05:57,840
the thing that you're looking at in this

00:05:56,800 --> 00:06:01,600
image right kind of like

00:05:57,840 --> 00:06:04,319
a person would do about trying to train

00:06:01,600 --> 00:06:05,360
uh an algorithm to do that now when i

00:06:04,319 --> 00:06:08,160
say train

00:06:05,360 --> 00:06:08,880
that is basically done by feeding these

00:06:08,160 --> 00:06:11,840
models

00:06:08,880 --> 00:06:12,160
uh air input right off your input image

00:06:11,840 --> 00:06:14,240
the

00:06:12,160 --> 00:06:15,199
image that you might be looking at and

00:06:14,240 --> 00:06:17,600
some labels

00:06:15,199 --> 00:06:18,560
in the case of classification uh the

00:06:17,600 --> 00:06:21,919
labels might be

00:06:18,560 --> 00:06:23,199
you know is it a like a cat dog bird

00:06:21,919 --> 00:06:26,080
kind of label just

00:06:23,199 --> 00:06:27,360
class names in the sense of object

00:06:26,080 --> 00:06:29,360
detection

00:06:27,360 --> 00:06:32,080
you might get labels that are you know

00:06:29,360 --> 00:06:34,960
series of numbers that correspond to

00:06:32,080 --> 00:06:37,759
coordinates which you know show a bots

00:06:34,960 --> 00:06:40,000
in segmentation the labels might be

00:06:37,759 --> 00:06:42,479
uh now you're talking about a mask where

00:06:40,000 --> 00:06:45,680
each pixel has a probability of

00:06:42,479 --> 00:06:48,080
being a certain class or not

00:06:45,680 --> 00:06:49,759
and as i mentioned these models tend to

00:06:48,080 --> 00:06:53,039
perform very well right over

00:06:49,759 --> 00:06:54,720
natural scenes and natural scenes being

00:06:53,039 --> 00:06:57,120
our normal point of view right they're

00:06:54,720 --> 00:07:00,560
looking horizontally into the horizon

00:06:57,120 --> 00:07:02,080
um classes that that we're familiar with

00:07:00,560 --> 00:07:05,840
every day like people cars

00:07:02,080 --> 00:07:08,240
animals they perform very well in this

00:07:05,840 --> 00:07:10,720
in these kinds of images

00:07:08,240 --> 00:07:12,080
which of course has led to these kinds

00:07:10,720 --> 00:07:14,080
of models being used in

00:07:12,080 --> 00:07:15,440
many other realms one of them being

00:07:14,080 --> 00:07:17,280
satellite imagery

00:07:15,440 --> 00:07:19,039
now moving into the satellite image

00:07:17,280 --> 00:07:20,400
realm you can

00:07:19,039 --> 00:07:22,960
ask the same kinds of questions you

00:07:20,400 --> 00:07:24,560
might ask uh in the classification sense

00:07:22,960 --> 00:07:26,720
right like if i look at that

00:07:24,560 --> 00:07:28,960
at a piece of an image like the one here

00:07:26,720 --> 00:07:30,639
in the in the lower left

00:07:28,960 --> 00:07:33,360
what are what am i looking at what are

00:07:30,639 --> 00:07:35,039
the pixels representing is this

00:07:33,360 --> 00:07:36,400
uh what is the land use basically right

00:07:35,039 --> 00:07:39,599
is this some

00:07:36,400 --> 00:07:43,599
grassy area or is this uh maybe a

00:07:39,599 --> 00:07:47,199
city or is this some roads

00:07:43,599 --> 00:07:49,680
likewise in the object detection realm

00:07:47,199 --> 00:07:51,120
you are looking at can i extract that

00:07:49,680 --> 00:07:52,720
whole instance or something so

00:07:51,120 --> 00:07:54,000
maybe you're looking for cars right

00:07:52,720 --> 00:07:55,680
maybe you're trying to count how many

00:07:54,000 --> 00:07:58,080
cars you are in the roads

00:07:55,680 --> 00:08:00,319
uh versus specifically matzer has

00:07:58,080 --> 00:08:03,039
recently done some tasks where

00:08:00,319 --> 00:08:04,560
we're trying to count cars uh

00:08:03,039 --> 00:08:05,840
specifically in this time of coverage in

00:08:04,560 --> 00:08:08,879
order to see

00:08:05,840 --> 00:08:10,400
how people are um how people are here

00:08:08,879 --> 00:08:11,520
into the you know the stay-at-home

00:08:10,400 --> 00:08:13,440
orders that

00:08:11,520 --> 00:08:15,919
don't go out if unless you need to kind

00:08:13,440 --> 00:08:18,560
of uh can the mandates

00:08:15,919 --> 00:08:20,639
um these subject detection models are

00:08:18,560 --> 00:08:23,599
very handy in that right by

00:08:20,639 --> 00:08:23,919
doing car counting over public areas you

00:08:23,599 --> 00:08:25,919
can

00:08:23,919 --> 00:08:27,039
start to answer some of these questions

00:08:25,919 --> 00:08:28,479
uh

00:08:27,039 --> 00:08:30,960
you can also ask some indication

00:08:28,479 --> 00:08:34,159
question based on satellite imagery

00:08:30,960 --> 00:08:35,919
given um given an image maybe

00:08:34,159 --> 00:08:38,479
you want to extract out all the roads

00:08:35,919 --> 00:08:41,839
right or all the railroads

00:08:38,479 --> 00:08:45,440
this might be done in order to write uh

00:08:41,839 --> 00:08:47,519
update your maps on a continual basis

00:08:45,440 --> 00:08:48,959
um now having moved into this realm

00:08:47,519 --> 00:08:51,200
though everything isn't

00:08:48,959 --> 00:08:52,320
um doesn't just work right off right off

00:08:51,200 --> 00:08:54,800
the bots right

00:08:52,320 --> 00:08:55,600
uh we have some challenges some issues

00:08:54,800 --> 00:08:58,800
with this

00:08:55,600 --> 00:08:59,920
transition versus one um there's

00:08:58,800 --> 00:09:00,480
definitely a different point of view

00:08:59,920 --> 00:09:01,920
right

00:09:00,480 --> 00:09:04,240
uh as it's shown in the picture right

00:09:01,920 --> 00:09:06,800
here uh cars

00:09:04,240 --> 00:09:07,360
boats airplanes they look very different

00:09:06,800 --> 00:09:11,279
from

00:09:07,360 --> 00:09:14,720
from up high now of course you can just

00:09:11,279 --> 00:09:17,839
take this to this in a lot of images

00:09:14,720 --> 00:09:19,600
since since this is not the

00:09:17,839 --> 00:09:21,600
everyday data this is not the data that

00:09:19,600 --> 00:09:23,600
perhaps universities

00:09:21,600 --> 00:09:25,279
uh used for a lot of their challenges

00:09:23,600 --> 00:09:26,959
and a lot of their research

00:09:25,279 --> 00:09:28,480
it requires a lot of time to go through

00:09:26,959 --> 00:09:32,000
and type the data right

00:09:28,480 --> 00:09:34,720
not only that but the all of a sudden

00:09:32,000 --> 00:09:37,120
you your orientation of your objects

00:09:34,720 --> 00:09:39,279
cannot take any form

00:09:37,120 --> 00:09:40,240
uh also the scale of objects right is

00:09:39,279 --> 00:09:42,000
way different

00:09:40,240 --> 00:09:44,560
now you're looking at very small objects

00:09:42,000 --> 00:09:46,640
in very large images as opposed to

00:09:44,560 --> 00:09:47,839
the images of cars here for instance

00:09:46,640 --> 00:09:51,360
where the car

00:09:47,839 --> 00:09:53,360
takes in a big chunk of the image

00:09:51,360 --> 00:09:54,959
uh so not only that but there's there's

00:09:53,360 --> 00:09:57,760
many more challenges right

00:09:54,959 --> 00:09:58,720
uh speaking farther against the

00:09:57,760 --> 00:10:01,839
challenge of

00:09:58,720 --> 00:10:03,600
scale and size of the objects when you

00:10:01,839 --> 00:10:06,399
move from natural scenes and

00:10:03,600 --> 00:10:07,839
to overhead imagery uh there's also an

00:10:06,399 --> 00:10:09,760
image of a

00:10:07,839 --> 00:10:12,399
problem of the scale of the objects

00:10:09,760 --> 00:10:15,040
right that are much more buried

00:10:12,399 --> 00:10:16,720
for instance you might you guys might be

00:10:15,040 --> 00:10:18,640
familiar with the model yellow

00:10:16,720 --> 00:10:20,640
you only look once it's very popular

00:10:18,640 --> 00:10:22,079
nowadays and it's able to detect the

00:10:20,640 --> 00:10:23,040
number of different objects within the

00:10:22,079 --> 00:10:24,480
single model

00:10:23,040 --> 00:10:26,800
so you run a single model and you can

00:10:24,480 --> 00:10:29,360
enable you're able to get

00:10:26,800 --> 00:10:30,160
detections over many different classes

00:10:29,360 --> 00:10:33,040
in

00:10:30,160 --> 00:10:33,440
this natural scenes however moving into

00:10:33,040 --> 00:10:36,560
the

00:10:33,440 --> 00:10:38,240
overhead realm these techniques don't

00:10:36,560 --> 00:10:39,200
really work as well because now you're

00:10:38,240 --> 00:10:41,040
dealing with

00:10:39,200 --> 00:10:43,200
objects of interest that are very very

00:10:41,040 --> 00:10:45,600
in size right a car for instance in an

00:10:43,200 --> 00:10:49,440
overhead image might only be

00:10:45,600 --> 00:10:53,040
a dozen pixels in width and length right

00:10:49,440 --> 00:10:55,920
um whereas uh the

00:10:53,040 --> 00:10:56,320
the stadium of example here might be

00:10:55,920 --> 00:10:58,800
much

00:10:56,320 --> 00:11:00,320
is much much larger than that right so

00:10:58,800 --> 00:11:04,399
the models struggle to

00:11:00,320 --> 00:11:06,880
find objects of such different scale

00:11:04,399 --> 00:11:08,800
uh likewise you also deal with problems

00:11:06,880 --> 00:11:11,040
of data set bias

00:11:08,800 --> 00:11:11,839
right and these are these are problems

00:11:11,040 --> 00:11:15,920
inherent to

00:11:11,839 --> 00:11:17,360
related any machine learning task where

00:11:15,920 --> 00:11:20,560
data's involved

00:11:17,360 --> 00:11:22,640
but it shows up specifically in

00:11:20,560 --> 00:11:24,240
uh object education inside other imagery

00:11:22,640 --> 00:11:26,640
because

00:11:24,240 --> 00:11:28,079
when you're doing tagging of objects

00:11:26,640 --> 00:11:29,440
because it's very expensive it's very

00:11:28,079 --> 00:11:31,200
hard to tag

00:11:29,440 --> 00:11:32,720
over the whole distribution of your data

00:11:31,200 --> 00:11:35,839
that you are interested in

00:11:32,720 --> 00:11:37,279
imagine for instance tagging um an

00:11:35,839 --> 00:11:40,880
object of interest in

00:11:37,279 --> 00:11:43,760
in a warm climate rather words

00:11:40,880 --> 00:11:44,320
lots of trees lots of trees and uh maybe

00:11:43,760 --> 00:11:46,800
not much

00:11:44,320 --> 00:11:48,079
now and then trying to deploy that model

00:11:46,800 --> 00:11:51,120
in an area where

00:11:48,079 --> 00:11:53,760
perhaps it's not a lot or perhaps uh

00:11:51,120 --> 00:11:55,040
it's a desert scene so the underlying

00:11:53,760 --> 00:11:56,000
distribution of your data is now

00:11:55,040 --> 00:11:58,800
different

00:11:56,000 --> 00:12:00,480
and the so the base assumption that your

00:11:58,800 --> 00:12:01,839
model is

00:12:00,480 --> 00:12:03,600
that your base that your model is going

00:12:01,839 --> 00:12:06,800
to perform well in this new

00:12:03,600 --> 00:12:09,120
in this new region kind of falls apart

00:12:06,800 --> 00:12:10,399
and so it becomes another attacking

00:12:09,120 --> 00:12:10,959
problem right now you have to go and

00:12:10,399 --> 00:12:14,160
attack

00:12:10,959 --> 00:12:16,560
instances in those areas uh

00:12:14,160 --> 00:12:18,079
not to mention that dataset bias can

00:12:16,560 --> 00:12:19,200
also come just from the fact that

00:12:18,079 --> 00:12:20,880
you might have low sampling

00:12:19,200 --> 00:12:22,560
opportunities right let's say you didn't

00:12:20,880 --> 00:12:24,800
want to go and tag

00:12:22,560 --> 00:12:26,079
cars in the desert region well perhaps

00:12:24,800 --> 00:12:28,079
there aren't that many

00:12:26,079 --> 00:12:29,279
uh cars that drive through those areas

00:12:28,079 --> 00:12:32,399
so just the

00:12:29,279 --> 00:12:34,240
sampling opportunities are decreased uh

00:12:32,399 --> 00:12:35,760
and even taking a step back right

00:12:34,240 --> 00:12:38,000
from from the model training

00:12:35,760 --> 00:12:40,079
specifically um

00:12:38,000 --> 00:12:41,279
in looking at the larger life cycle of

00:12:40,079 --> 00:12:43,519
deep learning right

00:12:41,279 --> 00:12:44,480
we are also facing with we're also faced

00:12:43,519 --> 00:12:46,959
with uh

00:12:44,480 --> 00:12:48,880
an engineering problem given that

00:12:46,959 --> 00:12:50,000
training the model is only one piece of

00:12:48,880 --> 00:12:51,760
it

00:12:50,000 --> 00:12:53,120
uh if we look at the other parts of the

00:12:51,760 --> 00:12:56,399
pipeline for instance

00:12:53,120 --> 00:12:59,040
getting the uh um

00:12:56,399 --> 00:12:59,440
making it putting it into a form that is

00:12:59,040 --> 00:13:01,519
uh

00:12:59,440 --> 00:13:03,120
can be adjusted by the model through an

00:13:01,519 --> 00:13:05,839
inference in nbn

00:13:03,120 --> 00:13:07,760
and like exploring these models doing

00:13:05,839 --> 00:13:10,800
this continuously over many different

00:13:07,760 --> 00:13:11,440
object types in many different regions

00:13:10,800 --> 00:13:13,279
can be

00:13:11,440 --> 00:13:15,120
quite an engineering problem especially

00:13:13,279 --> 00:13:17,040
when you consider that

00:13:15,120 --> 00:13:20,079
these models are not at all meant to

00:13:17,040 --> 00:13:22,639
take in large swaths of images right uh

00:13:20,079 --> 00:13:24,560
saturday images can be you know can be

00:13:22,639 --> 00:13:26,800
very large in the

00:13:24,560 --> 00:13:28,560
in the realm of gigabytes whereas these

00:13:26,800 --> 00:13:30,959
models are more meant to take in

00:13:28,560 --> 00:13:32,000
a small chunks of images right in the

00:13:30,959 --> 00:13:35,360
scale of

00:13:32,000 --> 00:13:37,120
uh hundreds of pixels so

00:13:35,360 --> 00:13:39,199
being able to do this reliably right

00:13:37,120 --> 00:13:42,480
where you can

00:13:39,199 --> 00:13:42,959
take an image ship it into a way that

00:13:42,480 --> 00:13:45,120
can be

00:13:42,959 --> 00:13:46,639
adjustable a model in order to train and

00:13:45,120 --> 00:13:48,800
then in the back end

00:13:46,639 --> 00:13:50,240
uh cut it up again so that it can be

00:13:48,800 --> 00:13:51,839
inferenced by the model

00:13:50,240 --> 00:13:53,680
but not only that right because

00:13:51,839 --> 00:13:56,000
inferencing will give you

00:13:53,680 --> 00:13:57,360
results in pixel space which then need

00:13:56,000 --> 00:13:58,320
to be converted into geospatial

00:13:57,360 --> 00:14:00,560
coordinates

00:13:58,320 --> 00:14:02,720
and then ultimately we appended together

00:14:00,560 --> 00:14:04,160
in order to have a full result set for

00:14:02,720 --> 00:14:06,399
any given image

00:14:04,160 --> 00:14:07,600
uh this all creates quite an engineering

00:14:06,399 --> 00:14:09,920
challenge right

00:14:07,600 --> 00:14:11,519
i guess luckily mata has been doing this

00:14:09,920 --> 00:14:13,839
for a number of years so

00:14:11,519 --> 00:14:15,040
they have a pretty complete set of tools

00:14:13,839 --> 00:14:16,399
and there are deep cores are the tools

00:14:15,040 --> 00:14:18,959
that

00:14:16,399 --> 00:14:20,560
do a lot of this and make at least this

00:14:18,959 --> 00:14:22,800
part of the processing a lot easier way

00:14:20,560 --> 00:14:22,800
but

00:14:22,959 --> 00:14:25,920
but that's not to say that the problem

00:14:24,320 --> 00:14:27,839
isn't isn't there it's impressive and

00:14:25,920 --> 00:14:30,399
doesn't require a lot of

00:14:27,839 --> 00:14:31,839
um a lot of a lot of thought to go into

00:14:30,399 --> 00:14:33,519
it

00:14:31,839 --> 00:14:35,440
so having looked at some of these

00:14:33,519 --> 00:14:37,199
motivations and some of these challenges

00:14:35,440 --> 00:14:39,279
um the motivation for this particular

00:14:37,199 --> 00:14:41,519
work is to try to value

00:14:39,279 --> 00:14:44,480
alleviate some of these issues and

00:14:41,519 --> 00:14:46,800
especially alleviate decisions as you

00:14:44,480 --> 00:14:48,720
continuously try to integrate new data

00:14:46,800 --> 00:14:51,199
into the process

00:14:48,720 --> 00:14:52,480
so first of all we want to be we want to

00:14:51,199 --> 00:14:54,079
position ourselves right in a place

00:14:52,480 --> 00:14:55,360
where we can use the latest state of the

00:14:54,079 --> 00:14:56,959
art

00:14:55,360 --> 00:14:58,959
now this is the center they are both in

00:14:56,959 --> 00:15:01,600
terms of the research

00:14:58,959 --> 00:15:03,920
and in terms of tools as far as the

00:15:01,600 --> 00:15:06,160
research goes right there's

00:15:03,920 --> 00:15:07,600
many many groups all over the world

00:15:06,160 --> 00:15:10,000
working on this

00:15:07,600 --> 00:15:11,279
object deduction problems doing things

00:15:10,000 --> 00:15:13,360
like

00:15:11,279 --> 00:15:15,279
active learning methods hyper grammar

00:15:13,360 --> 00:15:16,000
tuning methods neural architecture

00:15:15,279 --> 00:15:17,920
search

00:15:16,000 --> 00:15:19,279
methods all trying to improve

00:15:17,920 --> 00:15:22,320
performance over

00:15:19,279 --> 00:15:24,399
um of a given model right uh in the

00:15:22,320 --> 00:15:27,040
terms of tools

00:15:24,399 --> 00:15:28,720
um there's many there's many companies

00:15:27,040 --> 00:15:29,519
and organizations putting out tools for

00:15:28,720 --> 00:15:31,839
automation

00:15:29,519 --> 00:15:34,079
putting out tools that allow abstraction

00:15:31,839 --> 00:15:37,360
of the details of

00:15:34,079 --> 00:15:39,680
um of training particular models right

00:15:37,360 --> 00:15:42,399
allowing the user to be able to

00:15:39,680 --> 00:15:44,079
concentrate on the tougher problems

00:15:42,399 --> 00:15:46,160
specifically this for instance that we

00:15:44,079 --> 00:15:47,759
are interested in right if if we can

00:15:46,160 --> 00:15:50,000
come up with some automation methods to

00:15:47,759 --> 00:15:53,199
allow non-machine learning and experts

00:15:50,000 --> 00:15:54,240
to tackle some of these easier object

00:15:53,199 --> 00:15:56,639
detection test

00:15:54,240 --> 00:15:58,160
then perhaps we all allow the the

00:15:56,639 --> 00:15:59,600
machine learning networks

00:15:58,160 --> 00:16:01,120
in our ranks to tackle some of these

00:15:59,600 --> 00:16:02,560
more problems that have been plaguing us

00:16:01,120 --> 00:16:05,600
right

00:16:02,560 --> 00:16:06,959
uh so our second motivation given that

00:16:05,600 --> 00:16:08,480
we're trying to be as efficient as

00:16:06,959 --> 00:16:10,720
possible in terms of

00:16:08,480 --> 00:16:11,920
um using the state of the art research

00:16:10,720 --> 00:16:14,160
motivation is

00:16:11,920 --> 00:16:15,680
then to start tackling just the

00:16:14,160 --> 00:16:16,880
staggering amount of data that is out

00:16:15,680 --> 00:16:21,120
there right

00:16:16,880 --> 00:16:22,959
um for instance they take a satellite

00:16:21,120 --> 00:16:24,639
i met one of the metro satellites right

00:16:22,959 --> 00:16:26,800
which can collect over

00:16:24,639 --> 00:16:27,839
uh three million square kilometers of

00:16:26,800 --> 00:16:30,320
both images

00:16:27,839 --> 00:16:31,199
every single day uh so to put this into

00:16:30,320 --> 00:16:33,680
context

00:16:31,199 --> 00:16:35,680
that's basically emission the whole of

00:16:33,680 --> 00:16:36,639
the united states every three to four

00:16:35,680 --> 00:16:38,399
days

00:16:36,639 --> 00:16:39,839
now that is that's a lot of images right

00:16:38,399 --> 00:16:42,000
and if you're trying to do

00:16:39,839 --> 00:16:43,120
for instance car counting over such a

00:16:42,000 --> 00:16:45,519
big area

00:16:43,120 --> 00:16:47,279
um you're gonna need a lot of resources

00:16:45,519 --> 00:16:49,920
and you're gonna need a lot of

00:16:47,279 --> 00:16:51,600
uh thought into how geo engineering

00:16:49,920 --> 00:16:53,519
engineer the pipeline you know to do

00:16:51,600 --> 00:16:55,600
this effectively

00:16:53,519 --> 00:16:57,440
uh not only that right but these

00:16:55,600 --> 00:16:58,720
satellites earth observation satellites

00:16:57,440 --> 00:17:02,399
specifically

00:16:58,720 --> 00:17:03,759
uh continue to go up and they living

00:17:02,399 --> 00:17:05,280
that's the plot here shows right there's

00:17:03,759 --> 00:17:06,400
plans for more and more to go up in the

00:17:05,280 --> 00:17:09,120
next few years

00:17:06,400 --> 00:17:10,480
so the amount of data that is available

00:17:09,120 --> 00:17:12,799
and that

00:17:10,480 --> 00:17:14,559
we should be able to use in order to

00:17:12,799 --> 00:17:15,120
give the best results to our customer in

00:17:14,559 --> 00:17:16,880
order to

00:17:15,120 --> 00:17:18,720
create the best models it's only gonna

00:17:16,880 --> 00:17:21,039
keep increasing

00:17:18,720 --> 00:17:22,079
it's also important to realize

00:17:21,039 --> 00:17:24,959
specifically

00:17:22,079 --> 00:17:26,480
in the realm of retraining of models and

00:17:24,959 --> 00:17:29,039
automating the

00:17:26,480 --> 00:17:30,960
the feedback process that this new data

00:17:29,039 --> 00:17:31,360
doesn't only come from external sources

00:17:30,960 --> 00:17:34,480
right

00:17:31,360 --> 00:17:37,200
doesn't only come from external images

00:17:34,480 --> 00:17:38,880
but instead uh the models themselves the

00:17:37,200 --> 00:17:42,000
models that we've already built

00:17:38,880 --> 00:17:43,520
can give us also new uh new information

00:17:42,000 --> 00:17:45,440
that we can incorporate

00:17:43,520 --> 00:17:48,080
for instance say you have a model and

00:17:45,440 --> 00:17:51,120
you use to test over some area

00:17:48,080 --> 00:17:53,200
the the correct and

00:17:51,120 --> 00:17:55,520
mistaken predictions of that model can

00:17:53,200 --> 00:17:57,039
be used as new data to fit into the next

00:17:55,520 --> 00:17:59,200
generations of the model

00:17:57,039 --> 00:18:00,720
right and it is through this approach

00:17:59,200 --> 00:18:01,679
that we are starting that we're trying

00:18:00,720 --> 00:18:03,280
to tackle

00:18:01,679 --> 00:18:04,960
some of these active learning methods

00:18:03,280 --> 00:18:06,559
and also tackle

00:18:04,960 --> 00:18:08,240
the biases within the models that we've

00:18:06,559 --> 00:18:09,600
already created right in order to try to

00:18:08,240 --> 00:18:12,320
improve them

00:18:09,600 --> 00:18:13,120
and uh be able to use them more broadly

00:18:12,320 --> 00:18:16,320
in

00:18:13,120 --> 00:18:16,320
different regions around the world

00:18:16,400 --> 00:18:20,720
so um the test the the approach that we

00:18:19,919 --> 00:18:23,360
are kind of taking

00:18:20,720 --> 00:18:24,320
in order to to try to do this retraining

00:18:23,360 --> 00:18:27,760
retraining process

00:18:24,320 --> 00:18:31,440
is as follows um

00:18:27,760 --> 00:18:34,799
we want to take a model and

00:18:31,440 --> 00:18:36,240
um let me take a step back so there's

00:18:34,799 --> 00:18:38,960
lots of approaches that you might be

00:18:36,240 --> 00:18:40,799
that you might use to do this uh

00:18:38,960 --> 00:18:42,480
retraining roml

00:18:40,799 --> 00:18:44,480
there's a you know these are hot words

00:18:42,480 --> 00:18:45,760
out there right now

00:18:44,480 --> 00:18:47,679
one thing you may do for instance is

00:18:45,760 --> 00:18:50,880
curriculum learning right where

00:18:47,679 --> 00:18:52,400
you basically take uh you basically take

00:18:50,880 --> 00:18:53,760
the examples at any given time that you

00:18:52,400 --> 00:18:56,160
might fit into your model

00:18:53,760 --> 00:18:57,600
and you sort them you you link it by

00:18:56,160 --> 00:18:59,600
easiest to hardest

00:18:57,600 --> 00:19:00,880
right the idea being that a model much

00:18:59,600 --> 00:19:03,679
like a person

00:19:00,880 --> 00:19:04,799
should learn uh on a curricular in a

00:19:03,679 --> 00:19:08,160
curriculum of

00:19:04,799 --> 00:19:10,400
easiest to hardest um or you may do the

00:19:08,160 --> 00:19:12,880
exact opposite right and do

00:19:10,400 --> 00:19:14,400
online hard sample mining where now

00:19:12,880 --> 00:19:16,240
you're trying to fit your model

00:19:14,400 --> 00:19:18,160
the hardest that samples at any given

00:19:16,240 --> 00:19:21,120
time the idea being that

00:19:18,160 --> 00:19:22,799
if your model learns to learn by seeing

00:19:21,120 --> 00:19:25,120
as examples more and more

00:19:22,799 --> 00:19:26,880
then it will get better at those and

00:19:25,120 --> 00:19:29,360
since it's getting better the hard cases

00:19:26,880 --> 00:19:30,240
should also be better in these cases

00:19:29,360 --> 00:19:31,600
right

00:19:30,240 --> 00:19:33,440
so there's a number of other approaches

00:19:31,600 --> 00:19:34,880
but ultimately

00:19:33,440 --> 00:19:36,480
the issue with these approaches is that

00:19:34,880 --> 00:19:39,360
they try to

00:19:36,480 --> 00:19:41,440
improve a single model a single model

00:19:39,360 --> 00:19:43,600
through its training process

00:19:41,440 --> 00:19:44,720
and while the these approaches perform a

00:19:43,600 --> 00:19:46,640
great in that

00:19:44,720 --> 00:19:49,520
kind of definition that is not our

00:19:46,640 --> 00:19:51,360
definition um

00:19:49,520 --> 00:19:53,520
of retraining right we want to be able

00:19:51,360 --> 00:19:56,559
to train models but also incorporate

00:19:53,520 --> 00:19:59,280
this new data that we that you know that

00:19:56,559 --> 00:20:00,320
is provided by these images every single

00:19:59,280 --> 00:20:04,000
day

00:20:00,320 --> 00:20:07,120
so instead of using those approaches we

00:20:04,000 --> 00:20:10,000
look at doing um a method of

00:20:07,120 --> 00:20:12,080
hard sample mining over the whole over

00:20:10,000 --> 00:20:15,039
the whole pipeline of the model

00:20:12,080 --> 00:20:16,559
so from the data collection to the

00:20:15,039 --> 00:20:18,400
training and the testing

00:20:16,559 --> 00:20:19,679
we do the whole pipeline then at the

00:20:18,400 --> 00:20:22,000
very end

00:20:19,679 --> 00:20:23,200
we use the inference results from the

00:20:22,000 --> 00:20:24,880
current model

00:20:23,200 --> 00:20:27,679
in order to get some of this thick back

00:20:24,880 --> 00:20:29,760
feedback information that we then

00:20:27,679 --> 00:20:31,200
look back and aggregate with new

00:20:29,760 --> 00:20:34,480
information coming in

00:20:31,200 --> 00:20:37,520
um this might be new images thread or

00:20:34,480 --> 00:20:39,600
new annotations from uh from

00:20:37,520 --> 00:20:40,880
tigers we will aggregate all this

00:20:39,600 --> 00:20:43,760
information and feed it

00:20:40,880 --> 00:20:45,360
into this next generation of training we

00:20:43,760 --> 00:20:48,240
iterate over this

00:20:45,360 --> 00:20:50,000
uh process of fitting in these this uh

00:20:48,240 --> 00:20:50,640
mistake annotations like like you see

00:20:50,000 --> 00:20:54,320
here in the

00:20:50,640 --> 00:20:55,919
in the image we do this in loops as

00:20:54,320 --> 00:20:57,600
for as long as it takes right as long as

00:20:55,919 --> 00:20:59,840
it takes either to meet some

00:20:57,600 --> 00:21:00,640
performance criteria or as long as it

00:20:59,840 --> 00:21:03,200
takes for the

00:21:00,640 --> 00:21:06,320
model performance to converge to some

00:21:03,200 --> 00:21:09,360
some steady state level

00:21:06,320 --> 00:21:10,320
um so so far we have tested this

00:21:09,360 --> 00:21:13,440
approach with uh

00:21:10,320 --> 00:21:15,760
two frameworks and two models

00:21:13,440 --> 00:21:16,480
uh two model architectures the first one

00:21:15,760 --> 00:21:18,960
is

00:21:16,480 --> 00:21:20,240
the technet used through algorithmic

00:21:18,960 --> 00:21:21,840
caffeine just through the digits

00:21:20,240 --> 00:21:24,080
interface from nvidia

00:21:21,840 --> 00:21:25,280
now we started with this model type

00:21:24,080 --> 00:21:27,679
because

00:21:25,280 --> 00:21:29,039
at least when used through the nvidia

00:21:27,679 --> 00:21:31,200
pictures interface

00:21:29,039 --> 00:21:32,720
it's very easy to use uh it doesn't

00:21:31,200 --> 00:21:35,280
require a lot of setup

00:21:32,720 --> 00:21:36,960
and it's surprisingly good it's

00:21:35,280 --> 00:21:39,919
personally good

00:21:36,960 --> 00:21:40,480
for how easy it is to use right however

00:21:39,919 --> 00:21:43,600
the

00:21:40,480 --> 00:21:46,559
architecture doesn't come without its uh

00:21:43,600 --> 00:21:48,960
limitations so again specifically using

00:21:46,559 --> 00:21:51,200
the model through the digits interface

00:21:48,960 --> 00:21:53,520
there's a lot of restrictions right on

00:21:51,200 --> 00:21:55,360
uh custom using custom generators or

00:21:53,520 --> 00:21:58,000
using

00:21:55,360 --> 00:21:59,440
custom contacts classes or maybe or even

00:21:58,000 --> 00:22:01,039
using class weights

00:21:59,440 --> 00:22:02,720
it is some of these things that would

00:22:01,039 --> 00:22:06,640
make it possible to do things like

00:22:02,720 --> 00:22:07,919
curriculum learning and active feedback

00:22:06,640 --> 00:22:09,200
right some of that some of these

00:22:07,919 --> 00:22:11,600
techniques that might tackle this

00:22:09,200 --> 00:22:13,520
dataset bias

00:22:11,600 --> 00:22:15,919
uh on the other hand so we also have

00:22:13,520 --> 00:22:19,440
tested this with

00:22:15,919 --> 00:22:22,720
a yolo type architecture brilliant keras

00:22:19,440 --> 00:22:24,159
uh being around cares there's a lot more

00:22:22,720 --> 00:22:26,159
there's a lot more options there's a lot

00:22:24,159 --> 00:22:29,280
more things that are feasible

00:22:26,159 --> 00:22:31,919
and and doable with these models right

00:22:29,280 --> 00:22:33,600
for instance you can do the curriculum

00:22:31,919 --> 00:22:34,720
style approaches by just feeding your

00:22:33,600 --> 00:22:38,799
model

00:22:34,720 --> 00:22:40,400
the right uh instances the right

00:22:38,799 --> 00:22:42,640
the right chips at the right time

00:22:40,400 --> 00:22:46,240
through again a custom generator

00:22:42,640 --> 00:22:48,000
or you might do even fancier more uh

00:22:46,240 --> 00:22:50,000
newer approaches right like hyper

00:22:48,000 --> 00:22:52,880
programmer tuning or neural architecture

00:22:50,000 --> 00:22:54,720
search but now like over every training

00:22:52,880 --> 00:22:56,640
over every training

00:22:54,720 --> 00:22:58,559
round you might be looking at for the

00:22:56,640 --> 00:23:00,000
best architecture right to prune all the

00:22:58,559 --> 00:23:02,799
things that are necessary and

00:23:00,000 --> 00:23:05,919
really look for the most efficient model

00:23:02,799 --> 00:23:05,919
given your current data

00:23:06,080 --> 00:23:09,919
so in fact so many things are possible

00:23:08,080 --> 00:23:12,159
right with keras and

00:23:09,919 --> 00:23:14,320
even you're now looking at uh some

00:23:12,159 --> 00:23:17,120
python style models right

00:23:14,320 --> 00:23:17,840
that the each there should becomes the

00:23:17,120 --> 00:23:20,720
opposite of

00:23:17,840 --> 00:23:22,320
of in a detective case where so many

00:23:20,720 --> 00:23:23,840
things are possible that

00:23:22,320 --> 00:23:25,360
it really becomes important to have a

00:23:23,840 --> 00:23:27,840
good understanding

00:23:25,360 --> 00:23:29,760
of what the state of the art is and what

00:23:27,840 --> 00:23:32,320
the best approaches are out there right

00:23:29,760 --> 00:23:33,200
especially if uh like in our problem

00:23:32,320 --> 00:23:34,960
right there's

00:23:33,200 --> 00:23:37,280
like i said lots of data lots of objects

00:23:34,960 --> 00:23:40,400
that we're interested in

00:23:37,280 --> 00:23:42,320
if you want to use the best

00:23:40,400 --> 00:23:44,320
techniques to find the best optimal

00:23:42,320 --> 00:23:47,679
performance for every model

00:23:44,320 --> 00:23:50,000
the options are almost unlimited so

00:23:47,679 --> 00:23:52,640
given the real-world limitations of

00:23:50,000 --> 00:23:56,080
resources and time

00:23:52,640 --> 00:23:58,640
it is necessary when looking at

00:23:56,080 --> 00:24:00,159
these uh frameworks right these learning

00:23:58,640 --> 00:24:00,880
frameworks that allow for a lot more

00:24:00,159 --> 00:24:04,080
control it's

00:24:00,880 --> 00:24:06,080
necessary to keep in mind what the best

00:24:04,080 --> 00:24:09,120
is in order to be able to

00:24:06,080 --> 00:24:09,600
uh guide yourself better and only uh you

00:24:09,120 --> 00:24:12,799
know and

00:24:09,600 --> 00:24:14,320
basically don't burn out your resources

00:24:12,799 --> 00:24:16,000
so hey carlos you've got about 10

00:24:14,320 --> 00:24:18,159
minutes left in the session

00:24:16,000 --> 00:24:19,760
and so i want to leave some time for q

00:24:18,159 --> 00:24:21,919
and a that'd be great but

00:24:19,760 --> 00:24:23,840
your choice yeah just let you know thank

00:24:21,919 --> 00:24:25,760
you thank you

00:24:23,840 --> 00:24:27,279
uh i'm taking a little longer than i

00:24:25,760 --> 00:24:28,240
meant to i'll speed up through the rest

00:24:27,279 --> 00:24:29,840
of this

00:24:28,240 --> 00:24:32,720
uh so looking at some of the results

00:24:29,840 --> 00:24:34,320
here for instance for cafe

00:24:32,720 --> 00:24:35,919
right we tested the approach that i was

00:24:34,320 --> 00:24:36,960
just talking about where we train the

00:24:35,919 --> 00:24:39,840
model

00:24:36,960 --> 00:24:39,840
and then use it to

00:24:40,480 --> 00:24:44,799
use it to inference over some images

00:24:42,159 --> 00:24:47,120
from then we get some feedback

00:24:44,799 --> 00:24:50,320
the feedback is fed into uh the next

00:24:47,120 --> 00:24:50,320
generation of the model

00:24:50,640 --> 00:24:54,240
that generation also has a similar model

00:24:52,799 --> 00:24:55,760
that we take as the controller which

00:24:54,240 --> 00:24:58,159
doesn't get any feedback

00:24:55,760 --> 00:24:59,039
now the hypothesis is that by looking at

00:24:58,159 --> 00:25:02,080
this

00:24:59,039 --> 00:25:04,559
uh feedback the augmented model is going

00:25:02,080 --> 00:25:06,559
to be able to outperform the control one

00:25:04,559 --> 00:25:08,159
and the results seem to show that right

00:25:06,559 --> 00:25:11,520
so looking at these plots

00:25:08,159 --> 00:25:14,720
they show that percent difference

00:25:11,520 --> 00:25:17,440
uh from the feedback model to the

00:25:14,720 --> 00:25:19,279
to the uh control model so looking at

00:25:17,440 --> 00:25:21,840
the lower range of the ad statuses

00:25:19,279 --> 00:25:23,200
we see that as you add low number of

00:25:21,840 --> 00:25:24,720
annotations

00:25:23,200 --> 00:25:26,240
right the models perform up almost

00:25:24,720 --> 00:25:27,919
equally that's given by the

00:25:26,240 --> 00:25:30,080
almost equal variation in the positive

00:25:27,919 --> 00:25:31,679
and negative directions

00:25:30,080 --> 00:25:33,120
and that makes sense right because your

00:25:31,679 --> 00:25:34,080
models are basically getting the same

00:25:33,120 --> 00:25:35,679
data set

00:25:34,080 --> 00:25:37,279
however as you start increasing the

00:25:35,679 --> 00:25:40,720
number of mistakes

00:25:37,279 --> 00:25:43,919
the augmented model outperforms the

00:25:40,720 --> 00:25:47,120
control model pre uh pretty extensively

00:25:43,919 --> 00:25:49,039
so this is again just showing that our

00:25:47,120 --> 00:25:50,480
simple feedback approach actually does

00:25:49,039 --> 00:25:52,159
gain us something right

00:25:50,480 --> 00:25:54,080
the same thing can be said for this java

00:25:52,159 --> 00:25:56,799
architecture where here

00:25:54,080 --> 00:25:58,000
um a colleague directors were basically

00:25:56,799 --> 00:25:59,760
she added

00:25:58,000 --> 00:26:01,279
uh empty ships right directed

00:25:59,760 --> 00:26:03,520
internships uh

00:26:01,279 --> 00:26:05,039
guided at where the previous model had

00:26:03,520 --> 00:26:06,480
uh had stumbled

00:26:05,039 --> 00:26:08,720
and by adding different different

00:26:06,480 --> 00:26:11,279
amounts of these empty chips to the

00:26:08,720 --> 00:26:11,760
data set her performance increase

00:26:11,279 --> 00:26:15,200
through

00:26:11,760 --> 00:26:18,640
this different iterations right

00:26:15,200 --> 00:26:21,279
so uh having shown having seen that

00:26:18,640 --> 00:26:22,720
uh this kind of approach of automated

00:26:21,279 --> 00:26:24,480
loops of retraining can help us

00:26:22,720 --> 00:26:26,799
let's go ahead and talk about uh some

00:26:24,480 --> 00:26:28,159
automation real fast down

00:26:26,799 --> 00:26:30,799
so we looked at two different approaches

00:26:28,159 --> 00:26:33,840
to do this right nifi and airflow

00:26:30,799 --> 00:26:35,120
uh they're both different tools uh for

00:26:33,840 --> 00:26:37,760
different purposes but

00:26:35,120 --> 00:26:40,240
ultimately they kind of they kind of

00:26:37,760 --> 00:26:42,320
intersected in their ability to like

00:26:40,240 --> 00:26:45,919
uh process tasks you know as these

00:26:42,320 --> 00:26:47,520
stacks flow from one state into another

00:26:45,919 --> 00:26:49,039
uh which is exactly what we're doing

00:26:47,520 --> 00:26:50,000
right when we're kind of testing this

00:26:49,039 --> 00:26:53,360
pipeline of

00:26:50,000 --> 00:26:53,919
of flows from getting data all the way

00:26:53,360 --> 00:26:56,720
to

00:26:53,919 --> 00:26:57,679
inferences and scoring now that's only

00:26:56,720 --> 00:27:00,000
important right to

00:26:57,679 --> 00:27:01,440
to consider that neither knifeline nor

00:27:00,000 --> 00:27:03,840
airflow have any built-in

00:27:01,440 --> 00:27:05,039
knowledge about data science pipeline or

00:27:03,840 --> 00:27:07,440
deep learning

00:27:05,039 --> 00:27:09,120
so it's necessary to stack these tools

00:27:07,440 --> 00:27:10,559
on top of

00:27:09,120 --> 00:27:12,720
another tool that has some knowledge

00:27:10,559 --> 00:27:13,279
about this in our case we use this

00:27:12,720 --> 00:27:16,320
built-in

00:27:13,279 --> 00:27:17,679
library called spar which

00:27:16,320 --> 00:27:19,679
you know has a lot of the stuff built

00:27:17,679 --> 00:27:22,880
into it

00:27:19,679 --> 00:27:24,799
so looking at knife real fast um

00:27:22,880 --> 00:27:26,240
knife is a very common tool it's a very

00:27:24,799 --> 00:27:27,679
popular tool right for data flow

00:27:26,240 --> 00:27:30,480
management

00:27:27,679 --> 00:27:30,799
it strengthens in looking at live flows

00:27:30,480 --> 00:27:32,799
right

00:27:30,799 --> 00:27:34,640
so in the terms of further retraining

00:27:32,799 --> 00:27:37,440
and automating the

00:27:34,640 --> 00:27:38,000
deep learning pipeline it's extremely

00:27:37,440 --> 00:27:41,200
helpful

00:27:38,000 --> 00:27:41,840
in the sense of giving a model can we

00:27:41,200 --> 00:27:44,159
ingest

00:27:41,840 --> 00:27:44,960
data can we just data to be inferenced

00:27:44,159 --> 00:27:48,000
over

00:27:44,960 --> 00:27:49,440
and use it to maybe do

00:27:48,000 --> 00:27:52,640
some of this inferencing but also

00:27:49,440 --> 00:27:55,200
notifications right uh not only that but

00:27:52,640 --> 00:27:57,039
by using the data provenance tools that

00:27:55,200 --> 00:27:58,880
are built into nifi

00:27:57,039 --> 00:28:00,960
you know we can when we do get a

00:27:58,880 --> 00:28:02,960
prediction we can have some

00:28:00,960 --> 00:28:04,960
reliability and some confidence that

00:28:02,960 --> 00:28:08,880
we're able to we'll be able to track

00:28:04,960 --> 00:28:10,799
back and look at our um at every aspect

00:28:08,880 --> 00:28:12,960
of the pipeline of the flow that touch

00:28:10,799 --> 00:28:14,559
the data and have some have a better

00:28:12,960 --> 00:28:18,080
sense have some better context for

00:28:14,559 --> 00:28:20,240
for that detection right um

00:28:18,080 --> 00:28:22,480
so even though it fits a lot better in

00:28:20,240 --> 00:28:24,960
that kind of inference pipeline

00:28:22,480 --> 00:28:25,919
if you wanted to do uh training and that

00:28:24,960 --> 00:28:27,760
i found

00:28:25,919 --> 00:28:29,440
that this simple flow tends to work for

00:28:27,760 --> 00:28:32,240
instance here

00:28:29,440 --> 00:28:32,720
knife is acting as a like a manager tool

00:28:32,240 --> 00:28:34,880
right

00:28:32,720 --> 00:28:36,720
taking in this dag taking in these flows

00:28:34,880 --> 00:28:38,559
which uh these raw files which are

00:28:36,720 --> 00:28:40,399
basically defining

00:28:38,559 --> 00:28:42,399
each part of the pipeline again right

00:28:40,399 --> 00:28:45,120
like for instance that flow here

00:28:42,399 --> 00:28:45,600
uh the full file here defines an

00:28:45,120 --> 00:28:49,679
inference

00:28:45,600 --> 00:28:53,039
job and knife is right in this flow file

00:28:49,679 --> 00:28:54,399
into the underlying library again the

00:28:53,039 --> 00:28:56,159
library that we're building the house in

00:28:54,399 --> 00:28:57,520
order to have it

00:28:56,159 --> 00:28:59,840
you know check for dependencies and

00:28:57,520 --> 00:29:01,760
actually run the job in a dockerized

00:28:59,840 --> 00:29:04,799
container

00:29:01,760 --> 00:29:06,480
under five minutes um

00:29:04,799 --> 00:29:08,640
so given the time i think i'll escape a

00:29:06,480 --> 00:29:12,399
couple of these guys um

00:29:08,640 --> 00:29:14,159
so uh let's search real quick to airflow

00:29:12,399 --> 00:29:16,240
airflow is a somewhat different tool

00:29:14,159 --> 00:29:19,279
than the nifi

00:29:16,240 --> 00:29:23,200
uh in it the user predefines a dag

00:29:19,279 --> 00:29:26,480
right uh directed basically graph

00:29:23,200 --> 00:29:30,159
and uh runs over at some cadence

00:29:26,480 --> 00:29:30,880
um unlike knife airflow i think would

00:29:30,159 --> 00:29:33,679
much better

00:29:30,880 --> 00:29:34,480
fit operating over data that has already

00:29:33,679 --> 00:29:38,240
reached

00:29:34,480 --> 00:29:39,919
a central location so

00:29:38,240 --> 00:29:41,360
in the case of photo retraining we might

00:29:39,919 --> 00:29:42,320
do something like this right where we

00:29:41,360 --> 00:29:44,159
have a deck

00:29:42,320 --> 00:29:45,760
defined to run at some cadence in this

00:29:44,159 --> 00:29:47,760
case daily but

00:29:45,760 --> 00:29:49,039
if you like you could do it weekly or

00:29:47,760 --> 00:29:50,640
bi-weekly or every

00:29:49,039 --> 00:29:52,240
every every month depending on your

00:29:50,640 --> 00:29:54,159
resources um

00:29:52,240 --> 00:29:55,360
and the doc might run through the whole

00:29:54,159 --> 00:29:58,159
learning process

00:29:55,360 --> 00:29:58,960
from getting data all the way to uh

00:29:58,159 --> 00:30:01,840
joining the model

00:29:58,960 --> 00:30:03,279
inferencing and then doing some feedback

00:30:01,840 --> 00:30:05,279
and again you might have

00:30:03,279 --> 00:30:08,159
uh different branches of this dac in

00:30:05,279 --> 00:30:09,919
order to you know test different uh

00:30:08,159 --> 00:30:12,320
hypothesis different hyper parameters

00:30:09,919 --> 00:30:14,559
different pre-processing functions

00:30:12,320 --> 00:30:15,440
at the end of every one of these rounds

00:30:14,559 --> 00:30:18,720
you might get

00:30:15,440 --> 00:30:20,480
the best model for for any given uh

00:30:18,720 --> 00:30:23,120
round right and of course you can extend

00:30:20,480 --> 00:30:26,880
this even farther given resources

00:30:23,120 --> 00:30:28,880
um you can use this uh this kind of

00:30:26,880 --> 00:30:32,000
simple pipeline to scale over different

00:30:28,880 --> 00:30:33,840
objects so for instance in this case we

00:30:32,000 --> 00:30:35,200
have different dacs over different

00:30:33,840 --> 00:30:36,480
object types of different model

00:30:35,200 --> 00:30:38,880
architectures

00:30:36,480 --> 00:30:39,840
and you can toggle in each one on and

00:30:38,880 --> 00:30:43,840
off uh

00:30:39,840 --> 00:30:45,360
independently i think i'll skip this

00:30:43,840 --> 00:30:47,440
something that's used that we found very

00:30:45,360 --> 00:30:49,840
useful is that the ability to test

00:30:47,440 --> 00:30:51,279
that specific task specifically allow

00:30:49,840 --> 00:30:51,919
you to do things like this right award

00:30:51,279 --> 00:30:55,120
this is

00:30:51,919 --> 00:30:57,120
the timeline of the whole flow uh

00:30:55,120 --> 00:30:58,799
of a retraining round and for instance

00:30:57,120 --> 00:31:02,399
here it allows us to see that

00:30:58,799 --> 00:31:03,840
our second round of training um

00:31:02,399 --> 00:31:05,120
took about twice as long as the first

00:31:03,840 --> 00:31:06,320
round of training right which is

00:31:05,120 --> 00:31:09,840
expected

00:31:06,320 --> 00:31:12,159
so uh in summer you know we've uh

00:31:09,840 --> 00:31:15,120
we've done a lot of automation here but

00:31:12,159 --> 00:31:15,120
yeah i'll get it there

00:31:15,360 --> 00:31:19,440
excellent carlos uh yeah uh if there's

00:31:18,320 --> 00:31:22,559
some questions

00:31:19,440 --> 00:31:24,880
in chat that'd be great um

00:31:22,559 --> 00:31:27,919
i don't see me immediately we've got

00:31:24,880 --> 00:31:30,320
about a minute or so to go

00:31:27,919 --> 00:31:31,760
um yeah and if you want to reach out to

00:31:30,320 --> 00:31:34,159
me inside kind

00:31:31,760 --> 00:31:36,480
or i'll post my email in the chat if

00:31:34,159 --> 00:31:38,559
anybody has any questions afterwards

00:31:36,480 --> 00:31:39,760
that'd be cool yeah go ahead and do that

00:31:38,559 --> 00:31:42,080
pretty quick because we're about ready

00:31:39,760 --> 00:31:46,960
to shut the session down there is also

00:31:42,080 --> 00:31:48,320
a an apache con slack channel um

00:31:46,960 --> 00:31:50,240
folks can join there you can put it

00:31:48,320 --> 00:31:52,080
there there's a geospatial

00:31:50,240 --> 00:31:53,760
um is it a channel i forgot what the sub

00:31:52,080 --> 00:31:55,279
parts maybe it's a geospatial channel

00:31:53,760 --> 00:31:58,480
and the apache gone

00:31:55,279 --> 00:32:00,799
overall uh so um there is a question

00:31:58,480 --> 00:32:02,000
are you regularly using one or the other

00:32:00,799 --> 00:32:05,919
now airflow or

00:32:02,000 --> 00:32:07,600
nifi or both which and when

00:32:05,919 --> 00:32:10,399
yeah so we're using both at the moment

00:32:07,600 --> 00:32:10,960
uh as i mentioned we're using knife more

00:32:10,399 --> 00:32:13,200
for

00:32:10,960 --> 00:32:14,960
kind of the inference pipeline where you

00:32:13,200 --> 00:32:16,559
know it's reaching out to endpoints for

00:32:14,960 --> 00:32:17,919
for images and it's reaching out to

00:32:16,559 --> 00:32:19,360
endpoints where people might drop in

00:32:17,919 --> 00:32:22,399
images that they're interested in

00:32:19,360 --> 00:32:24,080
inferencing over and those are getting

00:32:22,399 --> 00:32:26,159
um passed through the model and then

00:32:24,080 --> 00:32:28,000
notifications are being sent out to

00:32:26,159 --> 00:32:30,080
to different customers and we'll use an

00:32:28,000 --> 00:32:32,399
airflow to manage more of the training

00:32:30,080 --> 00:32:33,919
the training rounds uh where which is

00:32:32,399 --> 00:32:35,200
updated in the database and they

00:32:33,919 --> 00:32:37,679
mentioned it in some

00:32:35,200 --> 00:32:39,360
repository and uh we want to train them

00:32:37,679 --> 00:32:41,919
in some cadence right like

00:32:39,360 --> 00:32:43,360
every few days train uh car detector

00:32:41,919 --> 00:32:45,840
again every few days train the airplane

00:32:43,360 --> 00:32:45,840
detector

00:32:46,000 --> 00:32:49,600
cool well let's leave it there again

00:32:48,159 --> 00:32:51,760
carlos thank you very much

00:32:49,600 --> 00:32:53,679
a lot of creative ideas and uh let's

00:32:51,760 --> 00:32:55,360
keep the conversation going

00:32:53,679 --> 00:32:57,279
uh we'll now switch over to another

00:32:55,360 --> 00:32:59,600
channel so click on sessions

00:32:57,279 --> 00:33:01,039
and go join the next section in the

00:32:59,600 --> 00:33:11,840
geospatial try

00:33:01,039 --> 00:33:11,840
thanks a lot

00:33:14,480 --> 00:33:16,559

YouTube URL: https://www.youtube.com/watch?v=C_9lAPFpYh4


