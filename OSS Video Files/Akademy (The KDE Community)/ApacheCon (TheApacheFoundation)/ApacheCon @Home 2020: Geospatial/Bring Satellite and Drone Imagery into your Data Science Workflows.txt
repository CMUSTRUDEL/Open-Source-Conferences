Title: Bring Satellite and Drone Imagery into your Data Science Workflows
Publication date: 2020-10-22
Playlist: ApacheCon @Home 2020: Geospatial
Description: 
	Bring Satellite and Drone Imagery into your Data Science Workflows
Jason Brown

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Overhead imagery from satellites and drones have entered the mainstream of how we explore, understand, and tell stories about our world. They are undeniable and arresting descriptions of cultural events, environmental disasters, economic shifts, and more. Data scientists recognize that their value goes far beyond anecdotal storytelling. It is unstructured data full of distinctive patterns in a high dimensional space. With machine learning, we can extract structured data from the vast set of imagery available. RasterFrames extends Apache Spark SQL with a strong Python API to enable processing of satellite, drone, and other spatial image data. This talk will discuss the fundamentals ideas to make sense of this imagery data. We will discuss how RasterFrames custom DataSource exploits convergent trends in how public and private providers publish images. Through deep Spark SQL integration, RasterFrames lets users consider imagery and other location-aware data sets in their existing data pipelines. RasterFrames builds on Apache licensed tech stack, fully supports Spark ML and interoperates smoothly with scikit-learn, TensorFlow, Keras, and PyTorch. To crystallize these ideas, we will discuss a practical data science case study using overhead imagery in PySpark.

Jason is a Senior Data Scientist at Astraea, Inc. applying machine learning to Earth-observing data to provide actionable insights to clients' and partners' challenges. He brings a background in mathematical modeling and statistics together with an appreciation for data visualization, geography, and software development.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,720 --> 00:00:29,760
you got two minutes left

00:00:25,920 --> 00:00:32,399
okay great uh all right let's uh

00:00:29,760 --> 00:00:33,920
let's begin as jim said i'm a senior

00:00:32,399 --> 00:00:36,320
data scientist at estrella

00:00:33,920 --> 00:00:37,520
if you've not heard of us uh that's

00:00:36,320 --> 00:00:40,879
that's okay

00:00:37,520 --> 00:00:41,280
you will uh we're um a platform as a

00:00:40,879 --> 00:00:42,800
server

00:00:41,280 --> 00:00:44,800
software as a service company and we're

00:00:42,800 --> 00:00:50,320
focused around

00:00:44,800 --> 00:00:53,440
creating uh like platforms for

00:00:50,320 --> 00:00:56,559
organizations people to discover

00:00:53,440 --> 00:00:58,719
uh consume and analyze uh earth

00:00:56,559 --> 00:01:00,480
observation imagery so

00:00:58,719 --> 00:01:02,079
satellite and drone imagery overhead

00:01:00,480 --> 00:01:04,799
imagery um

00:01:02,079 --> 00:01:05,199
all of those all of those terms uh to me

00:01:04,799 --> 00:01:08,320
mean

00:01:05,199 --> 00:01:09,600
pretty much the same thing uh and at the

00:01:08,320 --> 00:01:12,159
core of our

00:01:09,600 --> 00:01:13,119
sort of analytics platform as a service

00:01:12,159 --> 00:01:17,119
offering

00:01:13,119 --> 00:01:19,360
uh is apache spark and uh

00:01:17,119 --> 00:01:22,159
built on top of apache spark we have

00:01:19,360 --> 00:01:25,600
created a library called raster frames

00:01:22,159 --> 00:01:29,280
uh as as jim mentioned in the last uh

00:01:25,600 --> 00:01:32,400
jam session uh about geospatial

00:01:29,280 --> 00:01:34,960
so uh i will uh

00:01:32,400 --> 00:01:36,159
i'll um assume that because this is the

00:01:34,960 --> 00:01:38,240
geospatial track

00:01:36,159 --> 00:01:40,720
most of people here are gonna be

00:01:38,240 --> 00:01:43,040
familiar with a lot of the terms of art

00:01:40,720 --> 00:01:45,200
kind of buzzwords that i use if not

00:01:43,040 --> 00:01:47,759
shout in the questions and i'll try to

00:01:45,200 --> 00:01:50,000
try to clarify and connect the dots i

00:01:47,759 --> 00:01:51,759
also kind of assume that since i had

00:01:50,000 --> 00:01:54,159
you know data science in the title of my

00:01:51,759 --> 00:01:57,759
talk that a lot of folks here or

00:01:54,159 --> 00:02:02,000
maybe work as a data scientist or work

00:01:57,759 --> 00:02:04,479
as like a machine learning engineer or

00:02:02,000 --> 00:02:05,119
or a software developer on a team that

00:02:04,479 --> 00:02:09,599
has

00:02:05,119 --> 00:02:12,160
those kinds of people as their users or

00:02:09,599 --> 00:02:14,000
as part of the as part of the you know

00:02:12,160 --> 00:02:19,120
solution that they deliver

00:02:14,000 --> 00:02:22,480
um so uh i i'll uh i'll i'll first

00:02:19,120 --> 00:02:25,360
uh zoom out and i gave a similar talk uh

00:02:22,480 --> 00:02:26,800
to that i gave a similar talk earlier i

00:02:25,360 --> 00:02:27,280
had some thoughts prepared and then i

00:02:26,800 --> 00:02:30,480
saw this

00:02:27,280 --> 00:02:33,920
i saw a a blog post from andrew

00:02:30,480 --> 00:02:36,720
king of stanford university who's uh

00:02:33,920 --> 00:02:37,760
you know fairly influential in uh the

00:02:36,720 --> 00:02:41,360
deep learning

00:02:37,760 --> 00:02:42,959
community and he uh he outlined that

00:02:41,360 --> 00:02:44,640
i'll bring this all back together i

00:02:42,959 --> 00:02:48,319
promise he outlined three

00:02:44,640 --> 00:02:51,599
important factors uh in how advanced

00:02:48,319 --> 00:02:52,959
how advancements in in ai come about

00:02:51,599 --> 00:02:55,519
like he kind of gave some

00:02:52,959 --> 00:02:57,440
uh you know amusing anecdotes of things

00:02:55,519 --> 00:02:59,680
that he thought were really cool

00:02:57,440 --> 00:03:02,239
but never panned out and and in his

00:02:59,680 --> 00:03:04,000
reflection as to why that happened he

00:03:02,239 --> 00:03:05,599
points to these three factors

00:03:04,000 --> 00:03:08,640
computational scaling

00:03:05,599 --> 00:03:09,680
so that's things like uh going from

00:03:08,640 --> 00:03:12,879
training

00:03:09,680 --> 00:03:16,640
uh models on just the cpu

00:03:12,879 --> 00:03:20,080
to training on gpu or training on

00:03:16,640 --> 00:03:22,159
lots of gpus working together um

00:03:20,080 --> 00:03:23,360
data scaling being able to have access

00:03:22,159 --> 00:03:26,080
to

00:03:23,360 --> 00:03:27,599
more and more training data and so as

00:03:26,080 --> 00:03:30,080
you see

00:03:27,599 --> 00:03:32,080
again that distinction between

00:03:30,080 --> 00:03:33,040
traditional machine learning and deep

00:03:32,080 --> 00:03:36,159
learning

00:03:33,040 --> 00:03:39,280
is also marked by

00:03:36,159 --> 00:03:43,040
orders of magnitude more data

00:03:39,280 --> 00:03:43,040
being brought into the model training

00:03:43,360 --> 00:03:46,959
those two i think most people are pretty

00:03:45,120 --> 00:03:49,040
comfortable with right

00:03:46,959 --> 00:03:50,959
he also he also outlined this idea of

00:03:49,040 --> 00:03:54,319
algorithmic improvements

00:03:50,959 --> 00:03:56,000
which i don't take that statement

00:03:54,319 --> 00:03:57,920
that he made as being like oh we

00:03:56,000 --> 00:04:00,080
achieved a point two percent

00:03:57,920 --> 00:04:00,959
uh improvement in the state of the art

00:04:00,080 --> 00:04:04,239
of this

00:04:00,959 --> 00:04:05,200
metric uh in this um machine learning

00:04:04,239 --> 00:04:08,879
task

00:04:05,200 --> 00:04:12,159
um it's rather much broader he's saying

00:04:08,879 --> 00:04:14,000
does the ev does the data does the

00:04:12,159 --> 00:04:16,639
corpus of data still have

00:04:14,000 --> 00:04:17,680
a significant amount of information that

00:04:16,639 --> 00:04:20,639
current

00:04:17,680 --> 00:04:22,400
art doesn't extract so it's not really

00:04:20,639 --> 00:04:25,120
asking like are you getting

00:04:22,400 --> 00:04:25,919
two tenths of a percent better it's like

00:04:25,120 --> 00:04:30,479
what is

00:04:25,919 --> 00:04:33,600
uh what's the information in the data

00:04:30,479 --> 00:04:34,320
um what's that kind of defines like a

00:04:33,600 --> 00:04:37,600
ceiling

00:04:34,320 --> 00:04:39,440
perhaps on on performance um

00:04:37,600 --> 00:04:40,720
and you see that uh you see that

00:04:39,440 --> 00:04:43,600
argument with

00:04:40,720 --> 00:04:45,440
um in certain computer vision problems

00:04:43,600 --> 00:04:48,240
where it's like hey we're you know this

00:04:45,440 --> 00:04:48,720
algorithm is now it is now achieving

00:04:48,240 --> 00:04:50,720
better

00:04:48,720 --> 00:04:52,000
than human performance like that's kind

00:04:50,720 --> 00:04:55,840
of a that's

00:04:52,000 --> 00:04:57,840
that's a way to kind of think about that

00:04:55,840 --> 00:04:59,120
so bringing it back into geospatial how

00:04:57,840 --> 00:05:02,160
does this work right

00:04:59,120 --> 00:05:03,360
we know uh i we haven't actually shown

00:05:02,160 --> 00:05:06,160
you any obligatory

00:05:03,360 --> 00:05:07,039
earth observation pictures but we we

00:05:06,160 --> 00:05:10,800
know that

00:05:07,039 --> 00:05:12,479
uh like this satellite uh

00:05:10,800 --> 00:05:14,560
you know commercial mosaic in your like

00:05:12,479 --> 00:05:17,280
google maps or bing maps

00:05:14,560 --> 00:05:18,720
has a lot of information in it right and

00:05:17,280 --> 00:05:21,680
this is an example this gif

00:05:18,720 --> 00:05:23,199
is an example of uh you know some

00:05:21,680 --> 00:05:25,840
someone who's stuck at home

00:05:23,199 --> 00:05:28,240
during quarantine is mapping this uh

00:05:25,840 --> 00:05:30,080
this village in canada on openstreetmap

00:05:28,240 --> 00:05:31,280
so openstreetmap is really a powerful

00:05:30,080 --> 00:05:35,520
expression of

00:05:31,280 --> 00:05:39,840
how um you know how

00:05:35,520 --> 00:05:43,120
openly available overhead imagery data

00:05:39,840 --> 00:05:45,840
contains a great deal of information

00:05:43,120 --> 00:05:47,600
right but i kind of want to bring the

00:05:45,840 --> 00:05:49,360
aperture a little higher than just like

00:05:47,600 --> 00:05:51,840
cartographic things that's important

00:05:49,360 --> 00:05:52,880
work and there's a lot that's been done

00:05:51,840 --> 00:05:55,759
uh towards that

00:05:52,880 --> 00:05:56,479
in things like space net which is hey

00:05:55,759 --> 00:05:58,560
let's

00:05:56,479 --> 00:06:00,319
take these images and extract the roads

00:05:58,560 --> 00:06:02,319
extract the buildings extract

00:06:00,319 --> 00:06:03,759
certain relationships uh between like

00:06:02,319 --> 00:06:07,440
physical features

00:06:03,759 --> 00:06:08,880
um but there's uh there's more

00:06:07,440 --> 00:06:11,280
you know kind of arguing that there's

00:06:08,880 --> 00:06:13,199
there's more uh information that we

00:06:11,280 --> 00:06:15,520
aren't yet extracting which is just

00:06:13,199 --> 00:06:20,479
promising and now my

00:06:15,520 --> 00:06:22,240
now my computer is freezing up

00:06:20,479 --> 00:06:24,160
jim can you give me a shout out if you

00:06:22,240 --> 00:06:26,880
can hear me i can hear you fine

00:06:24,160 --> 00:06:28,000
uh yeah you're still looks like you

00:06:26,880 --> 00:06:31,199
still got an open street map

00:06:28,000 --> 00:06:31,840
uh slide yep correct i got that i got

00:06:31,199 --> 00:06:33,680
the apple

00:06:31,840 --> 00:06:36,720
wheel of doom as it's trying to go to

00:06:33,680 --> 00:06:36,720
the next page here

00:06:37,039 --> 00:06:43,840
oh dear well

00:06:40,319 --> 00:06:47,440
uh we can just talk about everything

00:06:43,840 --> 00:06:50,400
and uh paint pictures i i got it

00:06:47,440 --> 00:06:53,120
we're gonna we'll just jump right into

00:06:50,400 --> 00:06:53,120
the code demo

00:06:53,759 --> 00:06:59,840
just kidding uh

00:06:57,120 --> 00:07:01,599
okay i'll try and get get things back on

00:06:59,840 --> 00:07:03,680
the road here and if not i think i have

00:07:01,599 --> 00:07:07,680
a pdf that i could

00:07:03,680 --> 00:07:07,680
that i can rip off of probably

00:07:08,880 --> 00:07:12,400
sorry team this is the the fun of doing

00:07:10,960 --> 00:07:17,120
this live i'm really glad that we're

00:07:12,400 --> 00:07:18,000
doing this right here we go see we

00:07:17,120 --> 00:07:21,280
didn't we

00:07:18,000 --> 00:07:23,919
that this a small a small side

00:07:21,280 --> 00:07:25,759
side track so looking at um extracting

00:07:23,919 --> 00:07:29,440
imagery from this kind of like

00:07:25,759 --> 00:07:31,680
nice uh you know like

00:07:29,440 --> 00:07:33,039
commercial mosaics of overhead imagery

00:07:31,680 --> 00:07:33,840
right that's that's kind of the bread

00:07:33,039 --> 00:07:35,759
and butter of how

00:07:33,840 --> 00:07:37,520
open street map gets populated but

00:07:35,759 --> 00:07:37,919
there's a lot more and so i'm gonna go a

00:07:37,520 --> 00:07:41,199
through

00:07:37,919 --> 00:07:43,520
z until the end of uh apache con

00:07:41,199 --> 00:07:44,720
uh start with the a's right so

00:07:43,520 --> 00:07:47,680
archaeology

00:07:44,720 --> 00:07:50,000
um this uh this is a screen grab from a

00:07:47,680 --> 00:07:52,319
ted talk by uh sarah parchak who's a

00:07:50,000 --> 00:07:53,759
an archaeology anthropology professor

00:07:52,319 --> 00:07:55,680
and she has this open

00:07:53,759 --> 00:07:57,120
uh she's this pardon me like crowd

00:07:55,680 --> 00:07:58,960
sourcing platform

00:07:57,120 --> 00:08:01,280
where people can go in and and look at

00:07:58,960 --> 00:08:01,759
these uh wonderful images that somehow

00:08:01,280 --> 00:08:04,800
she's

00:08:01,759 --> 00:08:06,000
gotten max or to give give her of areas

00:08:04,800 --> 00:08:09,520
that might contain

00:08:06,000 --> 00:08:10,879
uh archaeological uh sites of interest

00:08:09,520 --> 00:08:14,080
so they found this

00:08:10,879 --> 00:08:15,120
set of structures uh that was that was

00:08:14,080 --> 00:08:18,160
up until that point

00:08:15,120 --> 00:08:21,680
not yet discovered uh in or

00:08:18,160 --> 00:08:23,759
known to known to archaeology right um

00:08:21,680 --> 00:08:25,599
so that's that's kind of that's kind of

00:08:23,759 --> 00:08:27,759
cool and that's an example of like

00:08:25,599 --> 00:08:29,120
a human being applied to the task in a

00:08:27,759 --> 00:08:30,560
way that was

00:08:29,120 --> 00:08:32,320
that you were finally able to like

00:08:30,560 --> 00:08:34,399
extract that information this

00:08:32,320 --> 00:08:35,519
whatever the site is has probably been

00:08:34,399 --> 00:08:37,919
imaged by

00:08:35,519 --> 00:08:38,719
landsat mission like many many hundreds

00:08:37,919 --> 00:08:41,599
of times

00:08:38,719 --> 00:08:42,240
but only in only uh until now has been

00:08:41,599 --> 00:08:44,640
sort of

00:08:42,240 --> 00:08:45,680
surfaced uh as as something that was

00:08:44,640 --> 00:08:47,760
that's like

00:08:45,680 --> 00:08:48,720
take known for knowing for what it is

00:08:47,760 --> 00:08:52,480
right

00:08:48,720 --> 00:08:53,040
um another more uh sort of traditional

00:08:52,480 --> 00:08:55,760
science

00:08:53,040 --> 00:08:57,440
example of like information in the data

00:08:55,760 --> 00:08:59,440
from atmospheric science

00:08:57,440 --> 00:09:00,560
i credit here nasa and issa my

00:08:59,440 --> 00:09:02,880
understanding is

00:09:00,560 --> 00:09:04,720
his european space agency flies flies

00:09:02,880 --> 00:09:08,480
the mission nice sentinel 5p

00:09:04,720 --> 00:09:08,880
mission and nasa did the data processing

00:09:08,480 --> 00:09:11,200
to

00:09:08,880 --> 00:09:12,160
um to get us to get us this very

00:09:11,200 --> 00:09:15,600
interesting map

00:09:12,160 --> 00:09:17,360
of year over year change in uh nitrogen

00:09:15,600 --> 00:09:21,120
dioxide pollution so it's in

00:09:17,360 --> 00:09:24,480
sentinel 5p is not really a it's not

00:09:21,120 --> 00:09:24,959
it's not a traditional like camera in

00:09:24,480 --> 00:09:27,600
space

00:09:24,959 --> 00:09:29,120
it's measuring concentrations of of

00:09:27,600 --> 00:09:31,760
pollutants in the atmosphere

00:09:29,120 --> 00:09:32,320
and you can see this is in in wuhan

00:09:31,760 --> 00:09:35,760
china

00:09:32,320 --> 00:09:38,399
and in 2020 around the um

00:09:35,760 --> 00:09:39,519
lunar new year there was there was uh

00:09:38,399 --> 00:09:42,080
you know this

00:09:39,519 --> 00:09:42,800
very stark decrease as opposed to an

00:09:42,080 --> 00:09:45,839
increase

00:09:42,800 --> 00:09:47,760
in uh in pollution

00:09:45,839 --> 00:09:49,120
uh around that around the time of the

00:09:47,760 --> 00:09:51,120
lunar new year so

00:09:49,120 --> 00:09:53,279
um and that's like one example that

00:09:51,120 --> 00:09:54,959
probably was real

00:09:53,279 --> 00:09:56,640
i respect this it was probably really

00:09:54,959 --> 00:09:58,959
hard to generate

00:09:56,640 --> 00:10:00,240
the data and create this uh create this

00:09:58,959 --> 00:10:02,800
product right here

00:10:00,240 --> 00:10:04,560
um but it goes to show and that's you

00:10:02,800 --> 00:10:07,040
know that satellite is still flying

00:10:04,560 --> 00:10:09,680
uh it goes to show that um there's

00:10:07,040 --> 00:10:12,480
there's information to be extracted

00:10:09,680 --> 00:10:13,680
uh from from that data that's that's

00:10:12,480 --> 00:10:15,760
still being collected

00:10:13,680 --> 00:10:17,600
so this is all like good news for ai and

00:10:15,760 --> 00:10:18,000
there's there's more good news right the

00:10:17,600 --> 00:10:22,079
data

00:10:18,000 --> 00:10:25,519
scale is is large um

00:10:22,079 --> 00:10:26,800
at australia we have some i

00:10:25,519 --> 00:10:28,720
can't remember the exact way we have

00:10:26,800 --> 00:10:30,480
some like very uh

00:10:28,720 --> 00:10:33,440
we have some very large number of like

00:10:30,480 --> 00:10:36,320
terabytes of petabytes of

00:10:33,440 --> 00:10:39,040
imagery data that um we don't actually

00:10:36,320 --> 00:10:43,360
own all of it or whatever but we

00:10:39,040 --> 00:10:46,000
have have made available through our um

00:10:43,360 --> 00:10:47,040
through our catalog service which i'll

00:10:46,000 --> 00:10:51,040
talk about a little bit

00:10:47,040 --> 00:10:52,880
uh later in the in the code demo um

00:10:51,040 --> 00:10:54,560
and that kind of points to things right

00:10:52,880 --> 00:10:56,320
like a point like i showed you that

00:10:54,560 --> 00:10:58,000
uh sentinel imagery there's there's a

00:10:56,320 --> 00:11:01,279
there's really strong open

00:10:58,000 --> 00:11:04,399
data access policies for the for

00:11:01,279 --> 00:11:06,000
you know u.s and european uh satellite

00:11:04,399 --> 00:11:07,440
missions and that's kind of catching on

00:11:06,000 --> 00:11:10,560
around the world

00:11:07,440 --> 00:11:11,839
there's also private um like private

00:11:10,560 --> 00:11:13,680
satellite

00:11:11,839 --> 00:11:15,440
operators that you know it's not open

00:11:13,680 --> 00:11:17,519
you have to pay but

00:11:15,440 --> 00:11:19,120
but there's there's uh there's a lot of

00:11:17,519 --> 00:11:22,079
data available

00:11:19,120 --> 00:11:23,200
um and and around a lot of the open data

00:11:22,079 --> 00:11:26,320
policies that says hey

00:11:23,200 --> 00:11:28,000
you know this we we as a government or

00:11:26,320 --> 00:11:29,839
we as a

00:11:28,000 --> 00:11:32,399
group of states intends to make this

00:11:29,839 --> 00:11:34,399
data available for a really long time

00:11:32,399 --> 00:11:36,399
uh for the benefit of you know everyone

00:11:34,399 --> 00:11:39,920
on the planet that we're imaging

00:11:36,399 --> 00:11:42,240
right and there's also

00:11:39,920 --> 00:11:43,440
been a lot of work around open standards

00:11:42,240 --> 00:11:46,160
for

00:11:43,440 --> 00:11:47,120
how you publish that data how you access

00:11:46,160 --> 00:11:50,320
that data

00:11:47,120 --> 00:11:52,720
um and and that's all kind of on the

00:11:50,320 --> 00:11:55,600
back of this like really long standing

00:11:52,720 --> 00:11:56,000
uh and systematic collection of the data

00:11:55,600 --> 00:11:57,600
um

00:11:56,000 --> 00:11:59,760
which is which is really kind of

00:11:57,600 --> 00:12:01,279
exciting from a data scale thing and

00:11:59,760 --> 00:12:03,279
we'll kind of borrow just

00:12:01,279 --> 00:12:04,959
in a word like the you know the cloud

00:12:03,279 --> 00:12:05,680
enables us to compute at the kind of

00:12:04,959 --> 00:12:08,800
scale that

00:12:05,680 --> 00:12:11,519
that we want to compute at right um and

00:12:08,800 --> 00:12:11,920
and so our hypothesis we finally come to

00:12:11,519 --> 00:12:14,160
it is

00:12:11,920 --> 00:12:15,760
to advance like those algorithmic

00:12:14,160 --> 00:12:20,000
improvements to really like push

00:12:15,760 --> 00:12:22,800
the envelope in in ai um

00:12:20,000 --> 00:12:23,360
you know it's like we we got to get this

00:12:22,800 --> 00:12:25,680
data

00:12:23,360 --> 00:12:27,519
right now that we kind of it's it's

00:12:25,680 --> 00:12:29,920
legally available it's

00:12:27,519 --> 00:12:31,360
accessible um it's in the cloud where

00:12:29,920 --> 00:12:31,920
the computer is that's great so now we

00:12:31,360 --> 00:12:33,600
just now

00:12:31,920 --> 00:12:35,600
all we need is to like get those ai

00:12:33,600 --> 00:12:37,279
practitioners like working on it

00:12:35,600 --> 00:12:39,440
um and that's where it comes to that's

00:12:37,279 --> 00:12:42,880
where it comes to tooling right

00:12:39,440 --> 00:12:46,000
um and kind of one of the main uh

00:12:42,880 --> 00:12:46,639
thing that i'll focus on right uh right

00:12:46,000 --> 00:12:48,880
now and there

00:12:46,639 --> 00:12:49,760
it's obviously more complex and this is

00:12:48,880 --> 00:12:52,959
uh is g

00:12:49,760 --> 00:12:55,279
doll it's kind of like de facto industry

00:12:52,959 --> 00:12:59,680
standard a lot a lot of um

00:12:55,279 --> 00:13:01,680
a lot of penetration into um

00:12:59,680 --> 00:13:03,519
like a lot of other projects and a lot

00:13:01,680 --> 00:13:05,920
of other efforts um

00:13:03,519 --> 00:13:07,279
and it is an abstraction layer right so

00:13:05,920 --> 00:13:09,680
as a data scientist

00:13:07,279 --> 00:13:11,040
i want to work in gdals like c library

00:13:09,680 --> 00:13:14,000
about as much as i want to work in

00:13:11,040 --> 00:13:15,279
tensorflow c library which is not at all

00:13:14,000 --> 00:13:17,120
there are some like higher level

00:13:15,279 --> 00:13:19,040
programs there's some library

00:13:17,120 --> 00:13:20,399
like libraries like resteria which is

00:13:19,040 --> 00:13:22,880
really really good

00:13:20,399 --> 00:13:23,920
um and i i kind of make the claim that

00:13:22,880 --> 00:13:26,399
that's those

00:13:23,920 --> 00:13:28,240
that's necessary but not sufficient for

00:13:26,399 --> 00:13:30,240
doing data science you have to have that

00:13:28,240 --> 00:13:31,920
abstraction layer like i don't

00:13:30,240 --> 00:13:34,160
i'm i don't want to have to worry if

00:13:31,920 --> 00:13:37,680
this file is a in a

00:13:34,160 --> 00:13:40,560
netcat format or a geotiff or a

00:13:37,680 --> 00:13:42,480
mrf file that abstraction layer is

00:13:40,560 --> 00:13:43,040
necessary i need that but it's not

00:13:42,480 --> 00:13:46,560
enough

00:13:43,040 --> 00:13:49,519
um so that's where we come to uh

00:13:46,560 --> 00:13:51,120
to raster frames uh and we kind of asked

00:13:49,519 --> 00:13:54,399
two questions

00:13:51,120 --> 00:13:56,240
um to get to the like you know to

00:13:54,399 --> 00:13:57,839
to kind of light up that origin story

00:13:56,240 --> 00:14:00,639
one is like what is

00:13:57,839 --> 00:14:02,320
what is actually special about this this

00:14:00,639 --> 00:14:04,720
overhead imagery data

00:14:02,320 --> 00:14:06,399
and what can we do to kind of overcome

00:14:04,720 --> 00:14:09,839
the things that make it special

00:14:06,399 --> 00:14:12,800
um without doing any violence to the

00:14:09,839 --> 00:14:14,000
the value value of the data but also

00:14:12,800 --> 00:14:17,040
bring it into

00:14:14,000 --> 00:14:18,079
uh general purpose tool because like in

00:14:17,040 --> 00:14:20,639
our

00:14:18,079 --> 00:14:21,600
you know in my worldview anyways like

00:14:20,639 --> 00:14:24,240
data scientists

00:14:21,600 --> 00:14:25,600
ml practitioners are to some degree like

00:14:24,240 --> 00:14:27,519
generalists

00:14:25,600 --> 00:14:29,440
right like i think they get specialized

00:14:27,519 --> 00:14:31,839
as they you know dig into their

00:14:29,440 --> 00:14:33,120
thing but like they are often come from

00:14:31,839 --> 00:14:36,240
a generalist

00:14:33,120 --> 00:14:39,839
kind of background um so

00:14:36,240 --> 00:14:43,279
they tend to not be geographers right um

00:14:39,839 --> 00:14:46,320
so i'll go through this quite quickly um

00:14:43,279 --> 00:14:48,240
in terms of of overhead image data

00:14:46,320 --> 00:14:49,680
but um from the perspective again of a

00:14:48,240 --> 00:14:52,320
data scientist it's like

00:14:49,680 --> 00:14:54,000
an image is a multi-dimensional array

00:14:52,320 --> 00:14:56,000
it's a 3d tensor

00:14:54,000 --> 00:14:57,519
um that has height and width and a

00:14:56,000 --> 00:14:59,040
number of channels it's usually one

00:14:57,519 --> 00:15:01,360
three or four channels

00:14:59,040 --> 00:15:03,120
and it's usually like about a megapixel

00:15:01,360 --> 00:15:04,000
it's like maybe a thousand by a thousand

00:15:03,120 --> 00:15:06,959
pixels is

00:15:04,000 --> 00:15:07,680
kind of like a typical image that you'll

00:15:06,959 --> 00:15:09,680
come across

00:15:07,680 --> 00:15:10,839
in computer vision and deep deep

00:15:09,680 --> 00:15:14,000
learning

00:15:10,839 --> 00:15:15,839
um on images so

00:15:14,000 --> 00:15:17,839
what's different about overhead imagery

00:15:15,839 --> 00:15:20,399
is that the

00:15:17,839 --> 00:15:21,040
the images that you get in these files

00:15:20,399 --> 00:15:22,720
uh

00:15:21,040 --> 00:15:24,560
tend to be more on the order of like 100

00:15:22,720 --> 00:15:25,279
megapixels they tend to have more on the

00:15:24,560 --> 00:15:28,320
order of

00:15:25,279 --> 00:15:30,959
um you know five or

00:15:28,320 --> 00:15:33,519
12 bands they have these really

00:15:30,959 --> 00:15:36,720
interesting different kinds of encodings

00:15:33,519 --> 00:15:38,560
um that are

00:15:36,720 --> 00:15:42,000
that are not not just the typical like

00:15:38,560 --> 00:15:44,300
okay i'm going to read this png file

00:15:42,000 --> 00:15:45,680
and go on and go along my day

00:15:44,300 --> 00:15:47,440
[Music]

00:15:45,680 --> 00:15:49,600
and and there's a lot less kind of

00:15:47,440 --> 00:15:52,639
standard like

00:15:49,600 --> 00:15:55,120
you you get any kind of normal

00:15:52,639 --> 00:15:56,959
normal any kind of vanilla image file

00:15:55,120 --> 00:15:59,759
and it's red green blue

00:15:56,959 --> 00:16:01,759
but that band ordering is completely

00:15:59,759 --> 00:16:05,040
arbitrary it could be anything

00:16:01,759 --> 00:16:06,639
um in earth observation imagery

00:16:05,040 --> 00:16:08,720
and there's there's some additional

00:16:06,639 --> 00:16:09,839
things on top of it right so there's

00:16:08,720 --> 00:16:11,839
more data

00:16:09,839 --> 00:16:13,759
that we want to keep track of right

00:16:11,839 --> 00:16:17,040
location data is

00:16:13,759 --> 00:16:19,279
is key that allows us to

00:16:17,040 --> 00:16:20,800
gain a lot of context right and so

00:16:19,279 --> 00:16:22,240
that's information that lets us

00:16:20,800 --> 00:16:24,000
reference information

00:16:22,240 --> 00:16:25,600
which i think is key like when you think

00:16:24,000 --> 00:16:28,560
about andrew ing's

00:16:25,600 --> 00:16:30,480
um like algorithmic improvement is there

00:16:28,560 --> 00:16:32,639
information

00:16:30,480 --> 00:16:34,839
in the data that hasn't hasn't yet been

00:16:32,639 --> 00:16:38,240
fully explored

00:16:34,839 --> 00:16:41,759
location in that context and like

00:16:38,240 --> 00:16:42,639
time uh is i think particularly

00:16:41,759 --> 00:16:47,040
important

00:16:42,639 --> 00:16:49,040
um in in looking at this data um

00:16:47,040 --> 00:16:50,320
and uh there's there's a lot of other

00:16:49,040 --> 00:16:51,600
metadata that give you additional

00:16:50,320 --> 00:16:53,920
context like

00:16:51,600 --> 00:16:54,800
you know the mission that it was taken

00:16:53,920 --> 00:16:56,959
by

00:16:54,800 --> 00:16:58,480
when it was taken this sun sensor

00:16:56,959 --> 00:17:00,720
geometry what processing

00:16:58,480 --> 00:17:02,959
has it gone through and so on and so on

00:17:00,720 --> 00:17:06,240
and then there's this totally crazy idea

00:17:02,959 --> 00:17:09,679
of no data that doesn't exist in

00:17:06,240 --> 00:17:12,079
like any like computer

00:17:09,679 --> 00:17:13,919
vision kind of typical application that

00:17:12,079 --> 00:17:15,919
a data scientist would see

00:17:13,919 --> 00:17:17,280
because you never get like a an image

00:17:15,919 --> 00:17:20,000
net image where like

00:17:17,280 --> 00:17:20,799
a third of it is just gone it's just

00:17:20,000 --> 00:17:23,520
like

00:17:20,799 --> 00:17:25,600
sorry the camera malfunction but we you

00:17:23,520 --> 00:17:26,640
know we we kept on going with this

00:17:25,600 --> 00:17:29,679
example

00:17:26,640 --> 00:17:32,080
um because it's it's so rare in the

00:17:29,679 --> 00:17:33,360
um sort of natural perspective

00:17:32,080 --> 00:17:36,880
photography

00:17:33,360 --> 00:17:40,240
uh imaging space um but it's like

00:17:36,880 --> 00:17:40,880
quite common in uh in overhead data so

00:17:40,240 --> 00:17:43,280
anyways we

00:17:40,880 --> 00:17:44,160
finally like wrap our head around like

00:17:43,280 --> 00:17:47,360
those uh

00:17:44,160 --> 00:17:51,120
those differences uh and come to

00:17:47,360 --> 00:17:54,240
raster frames so uh here is on the left

00:17:51,120 --> 00:17:56,880
physical model of what a large

00:17:54,240 --> 00:17:57,440
coverage might look like you have your

00:17:56,880 --> 00:17:59,679
four

00:17:57,440 --> 00:18:01,120
bands stacked up and there could be you

00:17:59,679 --> 00:18:01,840
know some arbitrary number of bands

00:18:01,120 --> 00:18:04,000
stacked up

00:18:01,840 --> 00:18:06,480
you have this large coverage that's like

00:18:04,000 --> 00:18:10,000
you know many thousands of pixels

00:18:06,480 --> 00:18:12,160
um and and uh our

00:18:10,000 --> 00:18:14,799
you know raster frames data frame model

00:18:12,160 --> 00:18:17,360
is on the right um so that's

00:18:14,799 --> 00:18:18,160
that's uh here's here's how that works

00:18:17,360 --> 00:18:20,559
we're gonna take

00:18:18,160 --> 00:18:21,360
that really large coverage and divide it

00:18:20,559 --> 00:18:24,799
up into

00:18:21,360 --> 00:18:28,480
pretty small um areas

00:18:24,799 --> 00:18:31,360
called tiles each tile is maybe 128 or

00:18:28,480 --> 00:18:34,320
256 pixels square

00:18:31,360 --> 00:18:36,640
each tile is also only one channel then

00:18:34,320 --> 00:18:39,840
we're going to take each channel

00:18:36,640 --> 00:18:42,720
uh and put them in a separate column

00:18:39,840 --> 00:18:44,080
of the data frame so you can see that

00:18:42,720 --> 00:18:46,720
like on the far right there

00:18:44,080 --> 00:18:47,440
for there are four channels divided up

00:18:46,720 --> 00:18:50,400
and then

00:18:47,440 --> 00:18:50,960
uh like we've kind of broken this broken

00:18:50,400 --> 00:18:53,520
this uh

00:18:50,960 --> 00:18:54,880
really large coverage down up down along

00:18:53,520 --> 00:18:59,120
the res and then we're

00:18:54,880 --> 00:19:03,120
kind of associating all that metadata um

00:18:59,120 --> 00:19:04,480
that we have for each uh for each row so

00:19:03,120 --> 00:19:06,320
while we're showing like the physical

00:19:04,480 --> 00:19:10,160
model here of like

00:19:06,320 --> 00:19:12,480
one really large image what we what we

00:19:10,160 --> 00:19:15,840
can kind of imply with this is

00:19:12,480 --> 00:19:19,039
lots and lots of um of images

00:19:15,840 --> 00:19:20,799
that all go into the same data frame um

00:19:19,039 --> 00:19:22,000
and this is supposed this is a like wall

00:19:20,799 --> 00:19:23,280
of words so it's supposed to have

00:19:22,000 --> 00:19:26,400
animation in it

00:19:23,280 --> 00:19:28,799
um but there's a couple of uh important

00:19:26,400 --> 00:19:31,440
things that we do i will go through this

00:19:28,799 --> 00:19:32,400
fairly quickly um even though it

00:19:31,440 --> 00:19:35,200
represents a lot of

00:19:32,400 --> 00:19:35,600
hours of people's lives um first we have

00:19:35,200 --> 00:19:38,000
a

00:19:35,600 --> 00:19:39,520
strong python api like kind of try to

00:19:38,000 --> 00:19:43,360
know who our audience is

00:19:39,520 --> 00:19:46,559
um so it's uh it's pretty easy to

00:19:43,360 --> 00:19:48,240
to pip install um if you do need to work

00:19:46,559 --> 00:19:49,200
with gdal there's a little more fuzzing

00:19:48,240 --> 00:19:51,840
to do

00:19:49,200 --> 00:19:54,480
but we'll we'll try to help you with it

00:19:51,840 --> 00:19:57,039
we have a custom data source for us

00:19:54,480 --> 00:19:58,160
spark data frames uh accessible through

00:19:57,039 --> 00:20:00,880
the spark

00:19:58,160 --> 00:20:02,240
session through spark.read.raster i'll

00:20:00,880 --> 00:20:07,280
show that in our little

00:20:02,240 --> 00:20:10,400
demo we define a tile user defined type

00:20:07,280 --> 00:20:12,799
so that gives us a single uh like column

00:20:10,400 --> 00:20:14,640
type that we can use to carry the tensor

00:20:12,799 --> 00:20:16,400
as well as like some of the most

00:20:14,640 --> 00:20:18,000
important pieces of metadata about the

00:20:16,400 --> 00:20:21,440
location

00:20:18,000 --> 00:20:22,720
and when you bring a tile uh into the

00:20:21,440 --> 00:20:25,280
python driver it's

00:20:22,720 --> 00:20:27,280
just it's a thin wrapper around a numpy

00:20:25,280 --> 00:20:30,000
indie array which feels really good

00:20:27,280 --> 00:20:30,320
um as like a python consumer of this of

00:20:30,000 --> 00:20:33,919
this

00:20:30,320 --> 00:20:35,039
uh api uh and there's a whole bunch of

00:20:33,919 --> 00:20:37,679
column functions

00:20:35,039 --> 00:20:38,640
uh that work like on the jvm distributed

00:20:37,679 --> 00:20:41,679
and spark

00:20:38,640 --> 00:20:43,440
to operate on either the location part

00:20:41,679 --> 00:20:47,520
or the tensor part of that

00:20:43,440 --> 00:20:50,159
tile udt um or other kind of related

00:20:47,520 --> 00:20:52,240
objects like we have geometry objects

00:20:50,159 --> 00:20:54,000
and all of our location and geometry

00:20:52,240 --> 00:20:56,640
stuff is thanks to

00:20:54,000 --> 00:20:57,679
geo mesa another location tech project

00:20:56,640 --> 00:21:00,880
and all of our

00:20:57,679 --> 00:21:01,760
tensor stuff is thanks to geotrellus

00:21:00,880 --> 00:21:06,480
which

00:21:01,760 --> 00:21:09,840
is also a location tech project

00:21:06,480 --> 00:21:13,200
right jim anyways um

00:21:09,840 --> 00:21:14,240
and then we have a variety of spark ml

00:21:13,200 --> 00:21:16,480
transformers

00:21:14,240 --> 00:21:17,760
to help us uh do that integration

00:21:16,480 --> 00:21:20,400
between um

00:21:17,760 --> 00:21:22,159
spark sql and spark machine learning

00:21:20,400 --> 00:21:23,840
spark ml for machine learning

00:21:22,159 --> 00:21:26,080
um so that you can work with the this

00:21:23,840 --> 00:21:28,159
tile udt and pipelines

00:21:26,080 --> 00:21:29,440
uh and then we also have an ipython

00:21:28,159 --> 00:21:32,000
module that

00:21:29,440 --> 00:21:34,000
gives some nice functionality for

00:21:32,000 --> 00:21:36,799
visualization and inspection of

00:21:34,000 --> 00:21:38,000
of the tile udt uh and so then i think

00:21:36,799 --> 00:21:41,600
yeah here we go into our

00:21:38,000 --> 00:21:42,400
into our demo um apologies the name of

00:21:41,600 --> 00:21:45,600
the repos

00:21:42,400 --> 00:21:49,520
uh it this

00:21:45,600 --> 00:21:50,480
uh was also presented this code demo at

00:21:49,520 --> 00:21:54,000
um

00:21:50,480 --> 00:21:57,360
at spark a summit but uh here we go um

00:21:54,000 --> 00:22:00,240
so we are going to take a look at uh

00:21:57,360 --> 00:22:01,840
a set of of kaggle data about wildfires

00:22:00,240 --> 00:22:04,559
in california which i understand

00:22:01,840 --> 00:22:05,360
is still relevant even many months after

00:22:04,559 --> 00:22:08,799
sparky

00:22:05,360 --> 00:22:09,919
summit um and uh some land surface

00:22:08,799 --> 00:22:11,200
temperature data from the modis

00:22:09,919 --> 00:22:14,320
satellite mission so like

00:22:11,200 --> 00:22:15,919
uh modis is a really

00:22:14,320 --> 00:22:17,360
kind of awesome satellite mission but

00:22:15,919 --> 00:22:19,440
it's not famous for

00:22:17,360 --> 00:22:20,720
outside of like earth observation people

00:22:19,440 --> 00:22:23,679
because it doesn't

00:22:20,720 --> 00:22:27,280
produce like really detailed uh you know

00:22:23,679 --> 00:22:28,880
pictures that people like to look at

00:22:27,280 --> 00:22:30,559
but it's a it's a very important kind of

00:22:28,880 --> 00:22:34,400
scientific mission

00:22:30,559 --> 00:22:35,919
um so we'll go through and uh i'll skip

00:22:34,400 --> 00:22:37,600
access all of this is on the

00:22:35,919 --> 00:22:39,039
all this is on the github repo if you

00:22:37,600 --> 00:22:41,039
want to study this so we're going to

00:22:39,039 --> 00:22:43,360
read up read our

00:22:41,039 --> 00:22:45,039
kaggle data set and do some basic data

00:22:43,360 --> 00:22:45,760
cleaning we do a little bit of kind of

00:22:45,039 --> 00:22:47,360
cheating

00:22:45,760 --> 00:22:49,600
they give us a point location for the

00:22:47,360 --> 00:22:51,120
fire and an area

00:22:49,600 --> 00:22:52,480
like an acre is burned in the fire so

00:22:51,120 --> 00:22:53,280
we're going to kind of buffer that point

00:22:52,480 --> 00:22:55,600
and say

00:22:53,280 --> 00:22:57,360
well maybe about like this like maybe

00:22:55,600 --> 00:23:01,840
around in this area is

00:22:57,360 --> 00:23:03,200
is where that fire happened um

00:23:01,840 --> 00:23:05,919
i'll leave it as an exercise for the

00:23:03,200 --> 00:23:07,679
reader to figure out like where

00:23:05,919 --> 00:23:08,960
like how we can do an analytic to

00:23:07,679 --> 00:23:10,720
identify the area that

00:23:08,960 --> 00:23:12,000
actually got burned in the fire which is

00:23:10,720 --> 00:23:15,039
totally possible

00:23:12,000 --> 00:23:17,120
uh with satellite data um

00:23:15,039 --> 00:23:18,720
and then so you guys don't have to wait

00:23:17,120 --> 00:23:19,919
uh forever we're gonna filter this down

00:23:18,720 --> 00:23:23,039
to one year of

00:23:19,919 --> 00:23:25,039
of data so then we get into

00:23:23,039 --> 00:23:27,600
some of the proprietary goodies we're in

00:23:25,039 --> 00:23:30,000
uh we're in australia's earth ai

00:23:27,600 --> 00:23:31,600
notebook environment here um i'm going

00:23:30,000 --> 00:23:33,360
to use a few of the just play around

00:23:31,600 --> 00:23:36,799
with a few of the proprietary

00:23:33,360 --> 00:23:39,360
toys in here not to bore you too much

00:23:36,799 --> 00:23:41,200
uh but this builds it's kind of fun

00:23:39,360 --> 00:23:44,640
because this builds on top of

00:23:41,200 --> 00:23:46,559
uh an open standard called stack spatio

00:23:44,640 --> 00:23:47,919
temporal asset catalogs it's a way to

00:23:46,559 --> 00:23:51,120
describe

00:23:47,919 --> 00:23:55,120
uh the location of or like describe

00:23:51,120 --> 00:23:56,720
access to um satellite data drone data

00:23:55,120 --> 00:23:57,840
and this type of thing

00:23:56,720 --> 00:23:59,840
so first i'm going to look in our

00:23:57,840 --> 00:24:01,520
catalog for different for a collect

00:23:59,840 --> 00:24:04,080
any collection that contains the word

00:24:01,520 --> 00:24:08,080
temp what do i have about temp

00:24:04,080 --> 00:24:09,440
uh here's my modis uh mod 11a1

00:24:08,080 --> 00:24:11,520
collection of outland surface

00:24:09,440 --> 00:24:14,640
temperature and emissivity

00:24:11,520 --> 00:24:18,400
um great that's what i wanted

00:24:14,640 --> 00:24:19,279
um and this is uh this is the bands that

00:24:18,400 --> 00:24:22,640
are available the

00:24:19,279 --> 00:24:25,919
um basically you can see their tiffs

00:24:22,640 --> 00:24:26,240
um the different uh bands of data that

00:24:25,919 --> 00:24:28,159
are

00:24:26,240 --> 00:24:30,240
there's a lot most of them are most of

00:24:28,159 --> 00:24:31,600
them many of them are metadata

00:24:30,240 --> 00:24:33,760
uh the one that we're going to work with

00:24:31,600 --> 00:24:34,720
is is the daytime land surface

00:24:33,760 --> 00:24:36,480
temperature

00:24:34,720 --> 00:24:38,640
uh and so this is like aggregate over a

00:24:36,480 --> 00:24:40,240
one kilometer by one kilometer pixel

00:24:38,640 --> 00:24:41,919
just don't know jason you've got about

00:24:40,240 --> 00:24:45,200
10 minutes left okay great

00:24:41,919 --> 00:24:47,120
we're going to make it guys so then i

00:24:45,200 --> 00:24:48,480
then i uh go through and query that

00:24:47,120 --> 00:24:50,640
catalog once for each

00:24:48,480 --> 00:24:51,600
individual fire i'm looking for any

00:24:50,640 --> 00:24:54,720
image

00:24:51,600 --> 00:24:56,640
from this modis uh 11a1

00:24:54,720 --> 00:24:58,320
that is in between the time the fire

00:24:56,640 --> 00:24:59,840
started and the fire was extinguished

00:24:58,320 --> 00:25:02,960
that intersects that kind of

00:24:59,840 --> 00:25:05,200
bubble that i defined

00:25:02,960 --> 00:25:06,400
around the fire and then i'm going to

00:25:05,200 --> 00:25:09,919
finally join that all

00:25:06,400 --> 00:25:11,279
all back up and make this make this data

00:25:09,919 --> 00:25:11,840
frame here's kind of what we're looking

00:25:11,279 --> 00:25:13,520
at

00:25:11,840 --> 00:25:15,520
we have this unique id which is from the

00:25:13,520 --> 00:25:17,520
kaggle fire data set we have a date time

00:25:15,520 --> 00:25:20,400
that's referring to the date

00:25:17,520 --> 00:25:21,440
of the modus image and then i have this

00:25:20,400 --> 00:25:24,640
link to the

00:25:21,440 --> 00:25:28,320
it's not real at this s3 bucket uh

00:25:24,640 --> 00:25:31,840
and um key that tells me where's this

00:25:28,320 --> 00:25:35,200
where's this raster data item um

00:25:31,840 --> 00:25:36,799
at so for each fire i have uh

00:25:35,200 --> 00:25:38,720
and you can see this unique id is

00:25:36,799 --> 00:25:42,240
repeated for each fire i have

00:25:38,720 --> 00:25:46,000
potentially many different uh

00:25:42,240 --> 00:25:46,720
images of of land surface temperature so

00:25:46,000 --> 00:25:49,200
finally i'm gonna

00:25:46,720 --> 00:25:49,760
i'm gonna merge all that stuff together

00:25:49,200 --> 00:25:53,039
and then

00:25:49,760 --> 00:25:54,559
use my spark data frame reader i'm gonna

00:25:53,039 --> 00:25:58,000
pass in the data frame

00:25:54,559 --> 00:25:59,600
and a list of column names and the list

00:25:58,000 --> 00:26:01,600
of column names tells me

00:25:59,600 --> 00:26:03,200
tells the reader okay these are the

00:26:01,600 --> 00:26:06,320
columns that contain

00:26:03,200 --> 00:26:07,679
a uri that references data that you are

00:26:06,320 --> 00:26:10,240
to read

00:26:07,679 --> 00:26:12,559
so here's my schema i get my i get my

00:26:10,240 --> 00:26:14,799
path my original path back and

00:26:12,559 --> 00:26:16,799
and this struct which has the tile udt

00:26:14,799 --> 00:26:19,120
in it along with the location

00:26:16,799 --> 00:26:20,080
and you can see it's pretty simple uh

00:26:19,120 --> 00:26:23,600
this uh

00:26:20,080 --> 00:26:24,400
we have the proj string and um

00:26:23,600 --> 00:26:27,200
obstructive

00:26:24,400 --> 00:26:28,080
affordables telling me where in where in

00:26:27,200 --> 00:26:31,120
that crs

00:26:28,080 --> 00:26:31,600
is is this tile and then all of the rest

00:26:31,120 --> 00:26:34,320
of our

00:26:31,600 --> 00:26:36,320
there's two two main categories here the

00:26:34,320 --> 00:26:38,320
rest of this data is from the kaggle

00:26:36,320 --> 00:26:40,480
data set this kind of camel case stuff

00:26:38,320 --> 00:26:42,320
so there's administrative info there's

00:26:40,480 --> 00:26:43,360
resources used and there's like damage

00:26:42,320 --> 00:26:46,400
cause like

00:26:43,360 --> 00:26:49,039
fatalities uh structures damaged

00:26:46,400 --> 00:26:50,960
um and so on and then there and then the

00:26:49,039 --> 00:26:53,440
kind of bottom half of this is all

00:26:50,960 --> 00:26:54,320
is all of the metadata about the

00:26:53,440 --> 00:26:57,440
satellite

00:26:54,320 --> 00:26:58,880
image that is is paired with that so the

00:26:57,440 --> 00:27:02,159
next thing that i'll do is

00:26:58,880 --> 00:27:05,679
some nice indie geomesa filtering

00:27:02,159 --> 00:27:09,360
so i only want uh i only want to keep

00:27:05,679 --> 00:27:11,679
rows where um that my fire bubble

00:27:09,360 --> 00:27:12,400
like intersects with that geometry of

00:27:11,679 --> 00:27:14,640
the

00:27:12,400 --> 00:27:16,400
of the data um and so because i didn't

00:27:14,640 --> 00:27:18,399
want to punish you guys waiting for this

00:27:16,400 --> 00:27:19,600
uh this should be pretty fast we have it

00:27:18,399 --> 00:27:22,799
cached

00:27:19,600 --> 00:27:25,520
um so i have 625 interest in my

00:27:22,799 --> 00:27:26,320
in my data frame uh and then this is

00:27:25,520 --> 00:27:29,520
kind of our

00:27:26,320 --> 00:27:31,679
this is from this point below i think i

00:27:29,520 --> 00:27:33,840
somewhere in here i have a shortcut

00:27:31,679 --> 00:27:36,080
uh where you can read it yeah from this

00:27:33,840 --> 00:27:39,120
shortcut below everything is all

00:27:36,080 --> 00:27:41,520
it's all open source uh and there's

00:27:39,120 --> 00:27:42,320
there's no proprietary secret sauce in

00:27:41,520 --> 00:27:45,360
here

00:27:42,320 --> 00:27:48,480
um so this is this is all ipython

00:27:45,360 --> 00:27:50,399
uh module within pi roster frames

00:27:48,480 --> 00:27:52,159
that enables this kind of table display

00:27:50,399 --> 00:27:54,880
which is

00:27:52,159 --> 00:27:56,159
i think pretty useful so you can see the

00:27:54,880 --> 00:27:58,960
name of the fire

00:27:56,159 --> 00:28:00,880
a sample of an image location about the

00:27:58,960 --> 00:28:03,440
image the date of that image

00:28:00,880 --> 00:28:04,640
you can kind of see its relationship to

00:28:03,440 --> 00:28:07,520
the um

00:28:04,640 --> 00:28:08,960
to the time interval that the fire

00:28:07,520 --> 00:28:12,080
happened in

00:28:08,960 --> 00:28:14,159
the tile um is

00:28:12,080 --> 00:28:15,520
so there's there it is is a spark sql

00:28:14,159 --> 00:28:18,240
row

00:28:15,520 --> 00:28:19,200
and you can you can dig around in there

00:28:18,240 --> 00:28:21,440
and see okay

00:28:19,200 --> 00:28:22,720
it's uh it's just a thin wrapper over a

00:28:21,440 --> 00:28:25,520
numpy array

00:28:22,720 --> 00:28:27,440
um with some nice uh nice functionality

00:28:25,520 --> 00:28:30,880
to help us get a nice

00:28:27,440 --> 00:28:33,279
a nice wrapper in in ipython um

00:28:30,880 --> 00:28:34,240
like i said we had we have something

00:28:33,279 --> 00:28:36,799
over a hundred

00:28:34,240 --> 00:28:38,480
uh different kind of column functions

00:28:36,799 --> 00:28:41,200
and aggregates defined

00:28:38,480 --> 00:28:41,679
in master frames uh this is this is one

00:28:41,200 --> 00:28:43,200
where we

00:28:41,679 --> 00:28:45,760
we go back to the documentation it says

00:28:43,200 --> 00:28:48,399
okay to get from this digital number to

00:28:45,760 --> 00:28:50,080
kelvin uh that was measured divide by

00:28:48,399 --> 00:28:52,080
50. so we do that

00:28:50,080 --> 00:28:53,520
uh and then we're gonna then we're gonna

00:28:52,080 --> 00:28:56,159
aggregate i'll i'll

00:28:53,520 --> 00:28:58,159
bring your attention to this uh bit here

00:28:56,159 --> 00:28:58,640
raster frame rf ag stats so we're going

00:28:58,159 --> 00:29:01,760
to get

00:28:58,640 --> 00:29:02,480
um we're going to run an aggregate

00:29:01,760 --> 00:29:05,840
statistic

00:29:02,480 --> 00:29:10,720
over all of the cells in the tiles

00:29:05,840 --> 00:29:14,720
and all of the rows in the column

00:29:10,720 --> 00:29:17,360
for the whole data frame grouped by uh

00:29:14,720 --> 00:29:17,840
group by basically distinct fire right

00:29:17,360 --> 00:29:21,200
all this

00:29:17,840 --> 00:29:23,360
is that kaggle like per fire info

00:29:21,200 --> 00:29:24,480
um so we're going to take that series of

00:29:23,360 --> 00:29:28,399
however many it was

00:29:24,480 --> 00:29:31,120
5 or 20 images per fire and

00:29:28,399 --> 00:29:31,520
aggregate that all together and uh we're

00:29:31,120 --> 00:29:33,120
gonna

00:29:31,520 --> 00:29:34,880
we're gonna pull out of that stat

00:29:33,120 --> 00:29:36,720
structure the max and

00:29:34,880 --> 00:29:38,080
some of the other things and then uh and

00:29:36,720 --> 00:29:39,760
then take a peek

00:29:38,080 --> 00:29:41,120
and that will be kind of the end of our

00:29:39,760 --> 00:29:44,159
demo but just kind of

00:29:41,120 --> 00:29:47,279
to show you um

00:29:44,159 --> 00:29:49,679
this uh the intuition here

00:29:47,279 --> 00:29:50,559
is we have this we have this kaggle data

00:29:49,679 --> 00:29:52,080
set which has

00:29:50,559 --> 00:29:54,000
a lot of interesting things about the

00:29:52,080 --> 00:29:56,240
fire and then we have this other free

00:29:54,000 --> 00:29:57,840
data set that gives us physical

00:29:56,240 --> 00:29:59,120
measurements of what was happening to

00:29:57,840 --> 00:30:01,279
the surface of the earth

00:29:59,120 --> 00:30:03,200
while that fire was happening we've now

00:30:01,279 --> 00:30:04,080
been and we're now able to bring that

00:30:03,200 --> 00:30:06,000
together

00:30:04,080 --> 00:30:07,679
so like at the end of the day we didn't

00:30:06,000 --> 00:30:10,960
make a map of anything

00:30:07,679 --> 00:30:14,000
but we did enrich this existing data set

00:30:10,960 --> 00:30:15,760
with um with this with this

00:30:14,000 --> 00:30:18,640
earth observation data so that's just

00:30:15,760 --> 00:30:23,279
kind of like hints at a direction that

00:30:18,640 --> 00:30:26,000
um that this uh that this work can go um

00:30:23,279 --> 00:30:26,640
and there's uh i um the talk before me

00:30:26,000 --> 00:30:28,240
was

00:30:26,640 --> 00:30:30,480
hopefully gonna talk a lot about like

00:30:28,240 --> 00:30:32,799
how you can apply deep learning to

00:30:30,480 --> 00:30:34,320
uh this to earth observation data and

00:30:32,799 --> 00:30:36,000
kind of give you a sense of like how a

00:30:34,320 --> 00:30:39,440
lot of that work is about extracting

00:30:36,000 --> 00:30:41,279
semantic meaning from these images

00:30:39,440 --> 00:30:43,200
um which which was going to be an

00:30:41,279 --> 00:30:44,799
awesome dovetail to this but use your

00:30:43,200 --> 00:30:46,799
use your imagination

00:30:44,799 --> 00:30:48,480
uh and and if you look at things like

00:30:46,799 --> 00:30:48,960
space net you can you can see how that's

00:30:48,480 --> 00:30:50,799
really

00:30:48,960 --> 00:30:52,640
um how that's really true and there's a

00:30:50,799 --> 00:30:54,640
lot of there's a lot more work to be

00:30:52,640 --> 00:30:55,360
done to extract even more information

00:30:54,640 --> 00:30:57,840
out of

00:30:55,360 --> 00:30:59,200
out of the body of data that we have so

00:30:57,840 --> 00:31:00,640
a quick recap

00:30:59,200 --> 00:31:02,000
of raster frames and then i'll do

00:31:00,640 --> 00:31:02,480
questions with whatever time we have

00:31:02,000 --> 00:31:04,799
left

00:31:02,480 --> 00:31:06,960
uh it's on it's under location tech it's

00:31:04,799 --> 00:31:09,039
uh apache2 licensed

00:31:06,960 --> 00:31:10,159
uh with like a a strong commercial

00:31:09,039 --> 00:31:12,799
friendly ip

00:31:10,159 --> 00:31:14,080
governance model um check out the

00:31:12,799 --> 00:31:15,600
website to get started

00:31:14,080 --> 00:31:17,279
you can pip install raster frames if

00:31:15,600 --> 00:31:19,360
you'd like you can try our

00:31:17,279 --> 00:31:21,039
try our notebook product uh i think it's

00:31:19,360 --> 00:31:23,360
free for a week i think i can probably

00:31:21,039 --> 00:31:27,039
give you a coupon code if you

00:31:23,360 --> 00:31:28,480
if you at me on something um

00:31:27,039 --> 00:31:30,640
and get you some extra time and then

00:31:28,480 --> 00:31:31,679
feel free to contribute uh our get our

00:31:30,640 --> 00:31:34,880
channel is kind of the

00:31:31,679 --> 00:31:35,279
main place to come with like hey i'm new

00:31:34,880 --> 00:31:37,600
and

00:31:35,279 --> 00:31:39,039
i have a question um we also have uh

00:31:37,600 --> 00:31:40,480
issue tracking and pull requests on

00:31:39,039 --> 00:31:41,679
github and if you want to contribute you

00:31:40,480 --> 00:31:44,640
can check out our

00:31:41,679 --> 00:31:44,640
contributors guide

00:31:44,720 --> 00:31:49,360
and that's it now go ahead and take your

00:31:46,799 --> 00:31:49,360
questions

00:31:49,760 --> 00:31:55,440
thank you jason uh so yeah

00:31:53,120 --> 00:31:56,399
hey folks cool if folks have any

00:31:55,440 --> 00:31:59,039
questions uh

00:31:56,399 --> 00:32:00,399
feel free to add them in chat uh i'm

00:31:59,039 --> 00:32:02,240
trying to think of

00:32:00,399 --> 00:32:03,760
anything in particular that i'm curious

00:32:02,240 --> 00:32:06,960
about uh because i've

00:32:03,760 --> 00:32:07,760
had a chance to see um raster frame

00:32:06,960 --> 00:32:11,120
several times

00:32:07,760 --> 00:32:12,720
uh as as it's been in development uh

00:32:11,120 --> 00:32:14,720
i definitely liked what you said earlier

00:32:12,720 --> 00:32:16,240
about the uh that

00:32:14,720 --> 00:32:18,240
an abstraction layer like gdal is

00:32:16,240 --> 00:32:21,360
necessary but it doesn't

00:32:18,240 --> 00:32:23,440
um automatically just enable

00:32:21,360 --> 00:32:25,440
uh data science you know you need

00:32:23,440 --> 00:32:28,159
something else and so

00:32:25,440 --> 00:32:28,640
yeah and and spark gives us i kind of

00:32:28,159 --> 00:32:30,240
just

00:32:28,640 --> 00:32:32,320
took it as an assumed like everybody

00:32:30,240 --> 00:32:34,799
here knows all about

00:32:32,320 --> 00:32:35,360
all about spark but smart gives us that

00:32:34,799 --> 00:32:37,600
um

00:32:35,360 --> 00:32:38,960
the ability to take those like kind of

00:32:37,600 --> 00:32:41,600
data reads

00:32:38,960 --> 00:32:42,080
right which is we're mostly doing reads

00:32:41,600 --> 00:32:43,600
uh

00:32:42,080 --> 00:32:45,440
in this in this kind of analysis that

00:32:43,600 --> 00:32:48,480
we're talking about and

00:32:45,440 --> 00:32:51,039
um do that in a way that's distributed

00:32:48,480 --> 00:32:52,559
and and abstracts away a lot of the um

00:32:51,039 --> 00:32:55,039
sort of

00:32:52,559 --> 00:32:56,960
grunt work of thinking about exactly how

00:32:55,039 --> 00:32:58,159
do i set up all my maps and reduces and

00:32:56,960 --> 00:33:02,240
all of my things

00:32:58,159 --> 00:33:05,200
um yeah uh cloud octa uh

00:33:02,240 --> 00:33:06,799
i'm gonna so apologies about your name i

00:33:05,200 --> 00:33:09,279
see in the chat there might be

00:33:06,799 --> 00:33:12,000
a silly question something about code

00:33:09,279 --> 00:33:14,080
geotiff but like cog optimized geotiffs

00:33:12,000 --> 00:33:15,440
uh i assume is what you mean yeah that's

00:33:14,080 --> 00:33:18,320
absolutely

00:33:15,440 --> 00:33:19,760
uh part of the part of the sauce that

00:33:18,320 --> 00:33:23,440
makes this all work

00:33:19,760 --> 00:33:25,679
um we are heavily opinionated towards

00:33:23,440 --> 00:33:27,360
uh cloud optimized geotiffs because it

00:33:25,679 --> 00:33:30,640
does all the things

00:33:27,360 --> 00:33:33,440
in the way that we want to do them in

00:33:30,640 --> 00:33:34,480
master frames to to read out like if you

00:33:33,440 --> 00:33:36,799
saw that

00:33:34,480 --> 00:33:38,880
physical model versus the data model

00:33:36,799 --> 00:33:40,240
we're gonna go we're gonna go drost

00:33:38,880 --> 00:33:43,360
effect again here

00:33:40,240 --> 00:33:45,039
um in this in this uh

00:33:43,360 --> 00:33:47,360
like sort of physical model to data

00:33:45,039 --> 00:33:49,360
model like on the left that physical

00:33:47,360 --> 00:33:52,159
model really is how the data is

00:33:49,360 --> 00:33:52,799
is stored as well as like how you see it

00:33:52,159 --> 00:33:55,039
in the map

00:33:52,799 --> 00:33:58,159
but um so we need these like kind of

00:33:55,039 --> 00:34:00,880
arbitrary range reads of small ranges

00:33:58,159 --> 00:34:02,320
um to make this work so to be able to go

00:34:00,880 --> 00:34:05,039
to

00:34:02,320 --> 00:34:07,279
a bucket in a cloud or an object in a

00:34:05,039 --> 00:34:09,760
cloud store and say give me this rain

00:34:07,279 --> 00:34:11,359
like give me the header and then okay

00:34:09,760 --> 00:34:13,040
now i know what i need give me this

00:34:11,359 --> 00:34:16,399
range of bytes out of it

00:34:13,040 --> 00:34:19,119
and that's my row data um that's that's

00:34:16,399 --> 00:34:20,079
super powerful um that it's absolutely

00:34:19,119 --> 00:34:23,280
uh

00:34:20,079 --> 00:34:27,359
it's absolutely a huge part of what

00:34:23,280 --> 00:34:27,359
makes this practical um

00:34:28,879 --> 00:34:36,079
chunking hdf net cdf and czar

00:34:32,720 --> 00:34:39,280
yeah i that so those i'm familiar with

00:34:36,079 --> 00:34:42,320
uh hdf net cdf and

00:34:39,280 --> 00:34:45,359
the kind of family of things um

00:34:42,320 --> 00:34:49,040
but i'm i'm not as familiar with

00:34:45,359 --> 00:34:52,879
uh like how that would really play

00:34:49,040 --> 00:34:56,480
in um yeah and like that sort of

00:34:52,879 --> 00:34:59,520
parallel distributed uh compute to like

00:34:56,480 --> 00:35:02,320
manage the tasks and all of that stuff i

00:34:59,520 --> 00:35:04,160
i really don't know i can't really speak

00:35:02,320 --> 00:35:06,079
to that

00:35:04,160 --> 00:35:08,000
but yeah b that's a that's a cool

00:35:06,079 --> 00:35:11,200
question and we have

00:35:08,000 --> 00:35:13,200
we have uh theoretically through gdal we

00:35:11,200 --> 00:35:16,880
have the ability to read

00:35:13,200 --> 00:35:18,960
hdf and net cdf files but i'm not

00:35:16,880 --> 00:35:21,599
aware of it being done in there maybe

00:35:18,960 --> 00:35:25,280
there may need to be a little more work

00:35:21,599 --> 00:35:28,079
to get everything like

00:35:25,280 --> 00:35:28,960
tied together just right yeah it and i

00:35:28,079 --> 00:35:31,680
think that's

00:35:28,960 --> 00:35:33,040
um maybe maybe as a closing thing it's

00:35:31,680 --> 00:35:33,839
this is where we're starting to see

00:35:33,040 --> 00:35:36,160
where

00:35:33,839 --> 00:35:37,280
it's good to have the abstraction layer

00:35:36,160 --> 00:35:40,800
things like

00:35:37,280 --> 00:35:42,320
uh cloud optimized geotiffs help us make

00:35:40,800 --> 00:35:44,000
sure that even though we're reaching

00:35:42,320 --> 00:35:45,280
through an abstraction layer we're doing

00:35:44,000 --> 00:35:47,920
that in a way that

00:35:45,280 --> 00:35:48,800
optimizes our reads and so to george's

00:35:47,920 --> 00:35:51,839
point

00:35:48,800 --> 00:35:53,599
uh being able to do that across multiple

00:35:51,839 --> 00:35:56,320
uh different file formats would be

00:35:53,599 --> 00:35:58,240
really interesting

00:35:56,320 --> 00:35:59,760
the next presentation in our track is

00:35:58,240 --> 00:36:01,119
going to be starting uh here in about

00:35:59,760 --> 00:36:02,320
three or four minutes so we should jump

00:36:01,119 --> 00:36:03,920
over to that

00:36:02,320 --> 00:36:06,000
uh there is going to be a birds of a

00:36:03,920 --> 00:36:09,200
feather that will start after

00:36:06,000 --> 00:36:12,160
uh that talk at i believe 4 15

00:36:09,200 --> 00:36:12,960
uh eastern so if you've got more time

00:36:12,160 --> 00:36:16,160
this afternoon

00:36:12,960 --> 00:36:16,720
uh either for you jason or for anyone

00:36:16,160 --> 00:36:19,040
else

00:36:16,720 --> 00:36:19,760
you can come hang out with us there and

00:36:19,040 --> 00:36:22,000
uh

00:36:19,760 --> 00:36:23,119
you can ask george more questions about

00:36:22,000 --> 00:36:26,720
hdf

00:36:23,119 --> 00:36:30,079
and net cdf

00:36:26,720 --> 00:36:30,720
ah thank you thank you jim and i posted

00:36:30,079 --> 00:36:33,280
our um

00:36:30,720 --> 00:36:35,599
our projects getter link in the in the

00:36:33,280 --> 00:36:37,440
chat it's easy it's easy to find

00:36:35,599 --> 00:36:40,560
um and you can if you have a question

00:36:37,440 --> 00:36:42,480
you can get on there and ask

00:36:40,560 --> 00:36:43,920
and yeah we're happy to happy to help

00:36:42,480 --> 00:36:55,839
you out get

00:36:43,920 --> 00:36:55,839
get on your journey doing all this

00:40:03,760 --> 00:40:05,839

YouTube URL: https://www.youtube.com/watch?v=55eqn6eIuoU


