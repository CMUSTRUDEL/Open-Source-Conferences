Title: Enabling geospatial in big data lakes and databases with LocationTech GeoMesa
Publication date: 2020-10-22
Playlist: ApacheCon @Home 2020: Geospatial
Description: 
	Enabling geospatial in big data lakes and databases with LocationTech GeoMesa
James Hughes

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Many of the Apache projects serving the big data space do not come with out of the box support for geospatial data types like points, lines, and polygons. LocationTech GeoMesa has provided add-on support to Apache database projects such as Accumulo, Cassandra, HBase, and Redis crafting spatial and spatio-temporal keys. In addition to distributed databases, GeoMesa has enables spatial storage in many of the popular Apache file format projects such as Arrow, Avro, Orc, and Parquet. This talk will review the basics of big geo data persistence either in a data lake or in a database, and provide an overview of the benefits (and limitations) of each technology.

Jim Hughes applies training in mathematics and computer science to build distributed, scalable system capable of supporting data science and machine learning. He is a core committer for GeoMesa, which leverages HBase, Accumulo and other distributed database systems to provide distributed computation and query capabilities. He is also a committer for the LocationTech projects JTS and SFCurve and serves a mentor for other LocationTech and Eclipse projects. He serves on the LocationTech Project Management Committee and Steering Committee. Through work with LocationTech and OSGeo projects like GeoTools and GeoServer, he works to build end-to-end solutions for big spatio-temporal problems. Jim received his Ph.D. in Mathematics from the University of Virginia for work studying algebraic topology. He enjoys playing outdoors and swing dancing.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:25,760 --> 00:00:30,080
geospatial track

00:00:27,199 --> 00:00:31,199
we've got a special presentation in this

00:00:30,080 --> 00:00:34,559
session

00:00:31,199 --> 00:00:37,760
uh from jim hughes of ccri um

00:00:34,559 --> 00:00:39,520
last year in the geospatial track uh

00:00:37,760 --> 00:00:41,600
jim showed up uh you know he's been

00:00:39,520 --> 00:00:44,640
working in this area for a while

00:00:41,600 --> 00:00:47,280
and came to apachecon last year and and

00:00:44,640 --> 00:00:48,239
uh not only blew us away but also uh you

00:00:47,280 --> 00:00:50,719
know said hey

00:00:48,239 --> 00:00:52,079
i'd like to get involved so uh you know

00:00:50,719 --> 00:00:55,920
kudos to gym

00:00:52,079 --> 00:00:59,039
uh on organizing the track with me

00:00:55,920 --> 00:01:00,160
and uh even more kudos to his work this

00:00:59,039 --> 00:01:03,840
uh

00:01:00,160 --> 00:01:04,720
work on gym mesa and uh uh location tech

00:01:03,840 --> 00:01:07,680
and the like

00:01:04,720 --> 00:01:09,200
and uh if you don't say spatial pulling

00:01:07,680 --> 00:01:10,799
curves somewhere and we're gonna take

00:01:09,200 --> 00:01:14,240
away that topology

00:01:10,799 --> 00:01:16,880
uh doctorate for me buddy so

00:01:14,240 --> 00:01:17,680
thank you uh yeah thanks for thanks for

00:01:16,880 --> 00:01:20,400
the introduction

00:01:17,680 --> 00:01:22,159
um so george and i have been uh the

00:01:20,400 --> 00:01:25,680
organizers for this track for this year

00:01:22,159 --> 00:01:29,360
and uh george has done a lot of the

00:01:25,680 --> 00:01:32,479
heavy lifting and a lot of thanks

00:01:29,360 --> 00:01:35,600
goes to rich and other folks

00:01:32,479 --> 00:01:36,400
who have helped move the whole thing

00:01:35,600 --> 00:01:39,200
online

00:01:36,400 --> 00:01:39,600
uh with a current situation here in 2020

00:01:39,200 --> 00:01:42,720
uh

00:01:39,600 --> 00:01:44,240
so i'm grateful to be able to speak at

00:01:42,720 --> 00:01:45,920
apache con again

00:01:44,240 --> 00:01:47,920
i will talk about space filling curves

00:01:45,920 --> 00:01:50,799
so i do get to keep my

00:01:47,920 --> 00:01:52,240
phd in math um as a little bit of uh

00:01:50,799 --> 00:01:55,439
background about myself

00:01:52,240 --> 00:01:57,920
i work at a company called ccri where

00:01:55,439 --> 00:01:59,600
i'm the director of open source programs

00:01:57,920 --> 00:02:02,159
and for the last eight years i've been

00:01:59,600 --> 00:02:04,640
working on geospatial software that

00:02:02,159 --> 00:02:07,040
lives on the jvm

00:02:04,640 --> 00:02:08,000
some of that work is based on location

00:02:07,040 --> 00:02:10,720
tech geomesa which

00:02:08,000 --> 00:02:12,080
i'll talk about there's a project called

00:02:10,720 --> 00:02:15,599
sf curve

00:02:12,080 --> 00:02:20,000
that we got started a little bit ago

00:02:15,599 --> 00:02:20,000
to be a common place to do some of the

00:02:20,080 --> 00:02:24,640
indexing that we'll talk about later

00:02:22,160 --> 00:02:27,840
i've also been contributing to

00:02:24,640 --> 00:02:29,760
um uh jts uh to help with some of the

00:02:27,840 --> 00:02:32,400
releases and things like that

00:02:29,760 --> 00:02:32,959
uh and uh geotools and geoserver are

00:02:32,400 --> 00:02:35,280
projects

00:02:32,959 --> 00:02:36,239
uh from osgo that i've worked with quite

00:02:35,280 --> 00:02:38,080
a bit

00:02:36,239 --> 00:02:39,440
uh so we're talking about uh big

00:02:38,080 --> 00:02:42,400
geospatial data

00:02:39,440 --> 00:02:44,400
and uh we should clarify what type and

00:02:42,400 --> 00:02:47,360
what volume

00:02:44,400 --> 00:02:48,560
so let's state our problem we want to

00:02:47,360 --> 00:02:51,680
figure out how to handle

00:02:48,560 --> 00:02:54,080
a big geospatial data for a second and

00:02:51,680 --> 00:02:56,080
the first thing we want to do is be

00:02:54,080 --> 00:02:58,640
clear about what sort of data

00:02:56,080 --> 00:03:00,640
we could mean by that when we talk about

00:02:58,640 --> 00:03:02,000
geospatial data

00:03:00,640 --> 00:03:04,400
it can come in about three different

00:03:02,000 --> 00:03:06,720
modalities at least

00:03:04,400 --> 00:03:08,080
as i think about it we could talk about

00:03:06,720 --> 00:03:11,360
vector data which is

00:03:08,080 --> 00:03:14,239
points lines and polygons and

00:03:11,360 --> 00:03:14,720
attributes associated with them from

00:03:14,239 --> 00:03:17,760
there

00:03:14,720 --> 00:03:19,440
we could also have raster data if you

00:03:17,760 --> 00:03:20,879
wanted to be precise about raster data

00:03:19,440 --> 00:03:24,159
you should think of it

00:03:20,879 --> 00:03:27,680
as a grid of data where for every

00:03:24,159 --> 00:03:30,879
little grid cell you have an array of

00:03:27,680 --> 00:03:33,920
values commonly that array of values

00:03:30,879 --> 00:03:36,400
is red green and blue channels and then

00:03:33,920 --> 00:03:39,599
that gives you a pretty picture

00:03:36,400 --> 00:03:42,080
so this can cover imagery uh

00:03:39,599 --> 00:03:43,519
it can cover lots of different things

00:03:42,080 --> 00:03:45,599
that we could gather

00:03:43,519 --> 00:03:47,120
earth observation data or it could just

00:03:45,599 --> 00:03:50,400
be a pretty map that we've

00:03:47,120 --> 00:03:53,280
made from some other data set

00:03:50,400 --> 00:03:54,959
there's also point cloud data which um

00:03:53,280 --> 00:03:57,120
as we've gone from vector data

00:03:54,959 --> 00:03:58,799
through raster data to point cloud data

00:03:57,120 --> 00:04:02,400
point cloud data is definitely the

00:03:58,799 --> 00:04:06,400
heaviest it's the largest in volume um

00:04:02,400 --> 00:04:08,080
and um yeah um

00:04:06,400 --> 00:04:09,760
we're we're talking about vector data

00:04:08,080 --> 00:04:12,640
today um

00:04:09,760 --> 00:04:13,599
so a lot of what we're gonna focus on is

00:04:12,640 --> 00:04:16,320
just

00:04:13,599 --> 00:04:17,680
points lines and polygons i'm going to

00:04:16,320 --> 00:04:20,639
leave the

00:04:17,680 --> 00:04:23,280
other types of data for experts in those

00:04:20,639 --> 00:04:26,000
modalities

00:04:23,280 --> 00:04:28,080
so we should talk about how much data

00:04:26,000 --> 00:04:31,520
you have to have before you've got

00:04:28,080 --> 00:04:33,280
big data um there are two

00:04:31,520 --> 00:04:35,199
data sets that i'm going to say are kind

00:04:33,280 --> 00:04:37,840
of a little bit on the smaller side

00:04:35,199 --> 00:04:38,880
or maybe medium data instead of big data

00:04:37,840 --> 00:04:42,000
um

00:04:38,880 --> 00:04:45,840
but the first one to talk about is gdelt

00:04:42,000 --> 00:04:49,280
it's a database of events that has been

00:04:45,840 --> 00:04:52,479
uh computed by uh performing nlp

00:04:49,280 --> 00:04:56,000
on uh basically just

00:04:52,479 --> 00:05:00,000
worldwide news sources uh for the past

00:04:56,000 --> 00:05:02,400
you know almost 40 years and it's got

00:05:00,000 --> 00:05:03,120
um i didn't check the exact size

00:05:02,400 --> 00:05:07,280
recently but

00:05:03,120 --> 00:05:10,560
200 25 250 million records in it

00:05:07,280 --> 00:05:11,199
um and so everything that's happened

00:05:10,560 --> 00:05:14,800
since

00:05:11,199 --> 00:05:18,160
uh you know uh 1980 till now

00:05:14,800 --> 00:05:21,440
um is is not even a billion events

00:05:18,160 --> 00:05:24,960
um so that's moderately that's

00:05:21,440 --> 00:05:26,720
we're not getting too big um i

00:05:24,960 --> 00:05:29,280
double checked and if we look at

00:05:26,720 --> 00:05:32,320
openstreetmap uh the worldwide

00:05:29,280 --> 00:05:34,240
um coverage of that so

00:05:32,320 --> 00:05:36,639
a second ago g dot was everything that's

00:05:34,240 --> 00:05:39,759
happened uh over the course of history

00:05:36,639 --> 00:05:42,000
or recent history uh osm

00:05:39,759 --> 00:05:44,479
is uh everywhere where we might want to

00:05:42,000 --> 00:05:46,639
go and have some information about it

00:05:44,479 --> 00:05:48,080
uh the entire change set looks like it's

00:05:46,639 --> 00:05:52,479
only a few

00:05:48,080 --> 00:05:54,560
is 140 some odd gigabytes and so

00:05:52,479 --> 00:05:56,160
uh that can fit on a thumb drive so we

00:05:54,560 --> 00:05:59,360
haven't quite hit

00:05:56,160 --> 00:06:00,960
um big where uh we can

00:05:59,360 --> 00:06:02,960
we really need to dig into some of these

00:06:00,960 --> 00:06:07,199
techniques that these top level

00:06:02,960 --> 00:06:10,960
apache projects are going to give us um

00:06:07,199 --> 00:06:11,759
so as a next example where things do get

00:06:10,960 --> 00:06:15,600
much

00:06:11,759 --> 00:06:18,160
larger if we start to talk about um

00:06:15,600 --> 00:06:20,800
data that comes from some sort of sensor

00:06:18,160 --> 00:06:24,080
moving through space and time

00:06:20,800 --> 00:06:27,039
that gets us to quite a bit more data

00:06:24,080 --> 00:06:27,919
some examples of this would be ais or

00:06:27,039 --> 00:06:30,800
adsb

00:06:27,919 --> 00:06:32,000
or mobility data to take each of those

00:06:30,800 --> 00:06:35,440
in turn

00:06:32,000 --> 00:06:38,800
ais is a signal that's broadcast by

00:06:35,440 --> 00:06:42,080
uh all the ships uh that are at sea um

00:06:38,800 --> 00:06:44,240
so there's some regulation that if your

00:06:42,080 --> 00:06:46,160
uh ship is over a certain size you need

00:06:44,240 --> 00:06:49,120
to be broadcasting where you are

00:06:46,160 --> 00:06:49,759
some of it's um to help with collision

00:06:49,120 --> 00:06:53,440
avoidance

00:06:49,759 --> 00:06:57,280
some of it is to um help monitor

00:06:53,440 --> 00:07:00,800
um if vessels are behaving correctly

00:06:57,280 --> 00:07:04,160
uh relative to um international waters

00:07:00,800 --> 00:07:07,360
things like that and respecting those

00:07:04,160 --> 00:07:11,440
zones around fishing or other transport

00:07:07,360 --> 00:07:14,160
similarly for airplanes there's adsv and

00:07:11,440 --> 00:07:15,280
that's also you know used to track see

00:07:14,160 --> 00:07:18,479
where

00:07:15,280 --> 00:07:19,759
airplanes are and our cell phone

00:07:18,479 --> 00:07:21,919
providers

00:07:19,759 --> 00:07:23,120
they can triangulate where most of our

00:07:21,919 --> 00:07:26,639
cell phones are

00:07:23,120 --> 00:07:28,080
that information is used by any of our

00:07:26,639 --> 00:07:31,440
cell phone applications that

00:07:28,080 --> 00:07:34,560
where we clicked accept to say that it

00:07:31,440 --> 00:07:34,560
can track our location

00:07:34,880 --> 00:07:38,960
these sources can produce millions to

00:07:37,440 --> 00:07:42,080
billions of records per day

00:07:38,960 --> 00:07:42,479
so if we're talking about that in terms

00:07:42,080 --> 00:07:44,879
of

00:07:42,479 --> 00:07:46,240
spatial temporal data this is where for

00:07:44,879 --> 00:07:51,199
me big data starts to

00:07:46,240 --> 00:07:52,800
take off so um my daily job is to

00:07:51,199 --> 00:07:54,639
you know address this question how do we

00:07:52,800 --> 00:07:55,280
handle millions to billions of vector

00:07:54,639 --> 00:07:57,280
data

00:07:55,280 --> 00:07:59,280
and it's typically point data that's

00:07:57,280 --> 00:08:02,639
coming in every day

00:07:59,280 --> 00:08:05,120
and so um that's kind of my background

00:08:02,639 --> 00:08:06,479
frame of reference so that you know what

00:08:05,120 --> 00:08:09,520
i'm talking about today

00:08:06,479 --> 00:08:10,639
um i want to introduce geomesa um we're

00:08:09,520 --> 00:08:14,160
going to focus a lot

00:08:10,639 --> 00:08:18,000
on the distributed databases we use

00:08:14,160 --> 00:08:19,919
and the apache file formats that we use

00:08:18,000 --> 00:08:21,440
but as a quick overview about what

00:08:19,919 --> 00:08:23,199
geomesa is

00:08:21,440 --> 00:08:25,039
it's a suite of tools for streaming

00:08:23,199 --> 00:08:28,240
persisting managing and analyzing

00:08:25,039 --> 00:08:29,759
spatial temporal data at scale um

00:08:28,240 --> 00:08:32,080
we are open source through the eclipse

00:08:29,759 --> 00:08:33,839
foundation they've got a

00:08:32,080 --> 00:08:36,000
sub part of that called location tech

00:08:33,839 --> 00:08:38,959
that gms is a part of

00:08:36,000 --> 00:08:40,000
um as we've worked with streaming data

00:08:38,959 --> 00:08:43,200
we've integrated with

00:08:40,000 --> 00:08:44,800
kafka and um there's not much you have

00:08:43,200 --> 00:08:45,920
to open source around what happens in

00:08:44,800 --> 00:08:49,760
storm

00:08:45,920 --> 00:08:52,399
but kafka and storm are great ways to

00:08:49,760 --> 00:08:53,120
stream the data this talk is going to be

00:08:52,399 --> 00:08:55,440
a lot about

00:08:53,120 --> 00:08:57,040
how things work for persistence and so

00:08:55,440 --> 00:08:58,959
uh the top line

00:08:57,040 --> 00:09:00,800
uh we're calling out some of the key

00:08:58,959 --> 00:09:02,640
value databases that we'll

00:09:00,800 --> 00:09:04,800
drill into a little bit more on the

00:09:02,640 --> 00:09:06,640
second row we've got some of the

00:09:04,800 --> 00:09:08,800
uh file formats that we'll dig into a

00:09:06,640 --> 00:09:11,600
little bit more

00:09:08,800 --> 00:09:13,600
for data management we've integrated

00:09:11,600 --> 00:09:16,959
with apache nifi to help

00:09:13,600 --> 00:09:20,480
move data around the enterprise so

00:09:16,959 --> 00:09:22,560
this is a great way to get data into

00:09:20,480 --> 00:09:24,880
a system and then if you do need to send

00:09:22,560 --> 00:09:28,560
it to kafka and then to

00:09:24,880 --> 00:09:31,279
one of your distributed databases nifi

00:09:28,560 --> 00:09:32,240
is a really powerful tool for doing that

00:09:31,279 --> 00:09:36,480
um

00:09:32,240 --> 00:09:39,200
in terms of analysis spark is

00:09:36,480 --> 00:09:40,000
uh you know everyone's favorite uh thing

00:09:39,200 --> 00:09:42,560
to

00:09:40,000 --> 00:09:43,920
go write uh distributed jobs in at this

00:09:42,560 --> 00:09:46,160
point

00:09:43,920 --> 00:09:48,080
geomesa integrates with uh the hadoop

00:09:46,160 --> 00:09:49,600
mapreduce input formats and that lets

00:09:48,080 --> 00:09:53,839
you get spark rdds

00:09:49,600 --> 00:09:56,080
and spark data frames of geospatial data

00:09:53,839 --> 00:09:57,519
once you've got that hooked up you can

00:09:56,080 --> 00:09:59,519
use popular

00:09:57,519 --> 00:10:00,959
notebook technologies to rapidly

00:09:59,519 --> 00:10:04,320
prototype

00:10:00,959 --> 00:10:06,240
analytics and go from there

00:10:04,320 --> 00:10:07,519
if we put this all together we can have

00:10:06,240 --> 00:10:10,800
data streaming in

00:10:07,519 --> 00:10:14,720
uh gmasa has some additional uh etl

00:10:10,800 --> 00:10:17,279
capabilities that help us uh map between

00:10:14,720 --> 00:10:18,240
uh whatever format your data happens to

00:10:17,279 --> 00:10:21,120
be in

00:10:18,240 --> 00:10:22,240
over to some of the ogc standards like

00:10:21,120 --> 00:10:26,160
simple features

00:10:22,240 --> 00:10:28,160
as we stream the data through either

00:10:26,160 --> 00:10:29,360
to kafka so that we can see a live view

00:10:28,160 --> 00:10:32,959
of what's going on

00:10:29,360 --> 00:10:38,240
or into distributed databases

00:10:32,959 --> 00:10:41,120
for later historical retrieval analysis

00:10:38,240 --> 00:10:43,040
um so i said we're going to drill into

00:10:41,120 --> 00:10:45,920
this persistence piece a little bit more

00:10:43,040 --> 00:10:47,279
so we'll kind of take this top line of

00:10:45,920 --> 00:10:49,040
distributed databases

00:10:47,279 --> 00:10:51,680
and then the second line of file formats

00:10:49,040 --> 00:10:51,680
each in turn

00:10:53,760 --> 00:10:58,839
okay so whenever we talk about

00:10:56,160 --> 00:11:02,640
distributed key value stores

00:10:58,839 --> 00:11:03,839
um uh this is a gross oversimplification

00:11:02,640 --> 00:11:07,279
of the databases

00:11:03,839 --> 00:11:08,640
uh on the right um i think of them as an

00:11:07,279 --> 00:11:11,040
encyclopedia

00:11:08,640 --> 00:11:13,760
uh and i i almost always literally think

00:11:11,040 --> 00:11:16,880
of the encyclopedia set i had as a kid

00:11:13,760 --> 00:11:18,320
sitting up on the shelf um if you were

00:11:16,880 --> 00:11:19,440
talking about the computer science

00:11:18,320 --> 00:11:23,040
background here

00:11:19,440 --> 00:11:25,200
uh you have what's called a b plus tree

00:11:23,040 --> 00:11:26,839
and the data at the end of the day is

00:11:25,200 --> 00:11:30,160
actually written into

00:11:26,839 --> 00:11:32,320
uh volumes on disk

00:11:30,160 --> 00:11:33,360
that would be like pulling off volume

00:11:32,320 --> 00:11:35,600
off the shelf

00:11:33,360 --> 00:11:37,600
uh whenever you've got that encyclopedia

00:11:35,600 --> 00:11:38,640
the each volume gets distributed to

00:11:37,600 --> 00:11:42,079
different

00:11:38,640 --> 00:11:43,440
um you know workers in the cloud and

00:11:42,079 --> 00:11:44,880
they're responsible for

00:11:43,440 --> 00:11:47,200
answering questions about their part of

00:11:44,880 --> 00:11:50,480
it um so that's my

00:11:47,200 --> 00:11:50,959
kind of anchor point there um the thing

00:11:50,480 --> 00:11:53,519
that

00:11:50,959 --> 00:11:54,399
we have to overcome is if we have that

00:11:53,519 --> 00:11:56,399
distributed

00:11:54,399 --> 00:11:57,600
uh key value store if we just have the

00:11:56,399 --> 00:12:00,720
same structure that

00:11:57,600 --> 00:12:02,320
our multi-volume dictionary or

00:12:00,720 --> 00:12:04,320
encyclopedia has

00:12:02,320 --> 00:12:06,480
we do need to use uh space flowing

00:12:04,320 --> 00:12:10,399
curves uh to do that

00:12:06,480 --> 00:12:11,440
um so this is my space filling curves in

00:12:10,399 --> 00:12:14,160
one slide

00:12:11,440 --> 00:12:15,760
um just so that i don't wind up spending

00:12:14,160 --> 00:12:18,880
uh the entire talk

00:12:15,760 --> 00:12:20,399
uh going on about it um our goal

00:12:18,880 --> 00:12:22,880
is to come up with a one-dimensional

00:12:20,399 --> 00:12:26,480
index for data that has

00:12:22,880 --> 00:12:27,600
more than one dimension there are a few

00:12:26,480 --> 00:12:29,600
steps

00:12:27,600 --> 00:12:31,279
and it's worth separating them out at

00:12:29,600 --> 00:12:32,560
least in my opinion this has helped me

00:12:31,279 --> 00:12:33,760
think through a lot of it

00:12:32,560 --> 00:12:36,160
the first thing we're going to do is

00:12:33,760 --> 00:12:38,240
we're going to grid up our space

00:12:36,160 --> 00:12:40,000
so we've picked whatever projection

00:12:38,240 --> 00:12:43,040
longitude latitude for the world

00:12:40,000 --> 00:12:45,360
and we've decided um that we're going to

00:12:43,040 --> 00:12:47,519
grid it up in this case we happen to be

00:12:45,360 --> 00:12:50,639
using a very regular

00:12:47,519 --> 00:12:52,720
uh quad tree um but

00:12:50,639 --> 00:12:54,720
if you keep track these steps don't have

00:12:52,720 --> 00:12:57,279
to be done exactly this way

00:12:54,720 --> 00:12:58,639
you could see that you have choices once

00:12:57,279 --> 00:13:00,399
we've got the grid

00:12:58,639 --> 00:13:02,160
we have to figure out an order to put on

00:13:00,399 --> 00:13:04,800
the grid um

00:13:02,160 --> 00:13:06,000
the easiest thing you could possibly do

00:13:04,800 --> 00:13:07,519
and i've actually seen people

00:13:06,000 --> 00:13:09,839
do this on a mailing list where they'll

00:13:07,519 --> 00:13:11,360
say hey once we've got this grid we

00:13:09,839 --> 00:13:13,600
could interleave

00:13:11,360 --> 00:13:14,480
uh the bits about which row and which

00:13:13,600 --> 00:13:16,959
column you're

00:13:14,480 --> 00:13:18,399
uh in in the grid we could interleave

00:13:16,959 --> 00:13:21,680
those

00:13:18,399 --> 00:13:24,800
if you do that you end up with a

00:13:21,680 --> 00:13:26,560
um morton order curve a z order curve uh

00:13:24,800 --> 00:13:28,800
it's also called a geohash

00:13:26,560 --> 00:13:31,120
so the obvious thing that you would do

00:13:28,800 --> 00:13:33,760
if you just said hey i want to

00:13:31,120 --> 00:13:34,959
put my grid cells in order is this there

00:13:33,760 --> 00:13:36,480
are also

00:13:34,959 --> 00:13:38,240
other spatial and curves the hilbert

00:13:36,480 --> 00:13:40,320
curve is another good one

00:13:38,240 --> 00:13:42,160
uh the z-order curve is really quick to

00:13:40,320 --> 00:13:44,959
compute um

00:13:42,160 --> 00:13:45,680
as a little plug for why you want to use

00:13:44,959 --> 00:13:47,920
a library

00:13:45,680 --> 00:13:49,839
even though the implementation is

00:13:47,920 --> 00:13:52,720
literally just interleaving

00:13:49,839 --> 00:13:54,399
uh two bit arrays and uh you know you

00:13:52,720 --> 00:13:57,839
could hand that off to

00:13:54,399 --> 00:13:59,839
a uh you know first year computer

00:13:57,839 --> 00:14:01,600
science student to any programmer

00:13:59,839 --> 00:14:03,680
there are algorithms that you would want

00:14:01,600 --> 00:14:04,320
to have whenever you're going back the

00:14:03,680 --> 00:14:08,240
other way

00:14:04,320 --> 00:14:10,160
to say whenever you need to go from a

00:14:08,240 --> 00:14:11,680
query back to what cells have been

00:14:10,160 --> 00:14:12,959
touched and what ranges that you want to

00:14:11,680 --> 00:14:14,279
work through

00:14:12,959 --> 00:14:16,399
some of that is a little more

00:14:14,279 --> 00:14:19,120
complicated

00:14:16,399 --> 00:14:20,959
anyhow there are some other properties

00:14:19,120 --> 00:14:24,000
that we want

00:14:20,959 --> 00:14:27,760
with our space filling curves around uh

00:14:24,000 --> 00:14:31,760
them nesting that lets us truncate

00:14:27,760 --> 00:14:34,160
our bit string and then be able to

00:14:31,760 --> 00:14:35,920
control how fine grain or how coarse our

00:14:34,160 --> 00:14:37,519
query is

00:14:35,920 --> 00:14:40,160
that also helps with a little bit with

00:14:37,519 --> 00:14:42,320
locality um

00:14:40,160 --> 00:14:44,000
if you've paid attention in math class

00:14:42,320 --> 00:14:47,839
one of the things that they always

00:14:44,000 --> 00:14:49,279
do um if someone comes in uh on monday

00:14:47,839 --> 00:14:50,079
and tells you we're gonna do something

00:14:49,279 --> 00:14:52,720
for

00:14:50,079 --> 00:14:53,519
uh two dimensions they'll usually come

00:14:52,720 --> 00:14:56,160
in

00:14:53,519 --> 00:14:57,120
um you know a week later a month later

00:14:56,160 --> 00:14:58,720
next year and then

00:14:57,120 --> 00:15:00,560
say okay here's how we do it in three

00:14:58,720 --> 00:15:02,560
dimensions or four dimensions

00:15:00,560 --> 00:15:04,560
um all of these things have higher

00:15:02,560 --> 00:15:07,120
dimensional analogs

00:15:04,560 --> 00:15:08,399
one of the things that is really really

00:15:07,120 --> 00:15:10,720
interesting here

00:15:08,399 --> 00:15:12,480
is that as you go to more dimensions you

00:15:10,720 --> 00:15:15,760
can realize that space filling curves

00:15:12,480 --> 00:15:19,120
are effectively uh finite functions

00:15:15,760 --> 00:15:20,959
uh that get composed in certain ways so

00:15:19,120 --> 00:15:23,199
as you have higher dimensions you have

00:15:20,959 --> 00:15:27,120
more choices than just saying

00:15:23,199 --> 00:15:30,240
oh i need to go um i either had to pick

00:15:27,120 --> 00:15:31,519
team z order curve or team hilbert curve

00:15:30,240 --> 00:15:33,279
and ask how those go to higher

00:15:31,519 --> 00:15:34,959
dimensions you have ways that you could

00:15:33,279 --> 00:15:39,519
mix and match as you go

00:15:34,959 --> 00:15:39,519
in higher dimensions uh anyhow

00:15:39,680 --> 00:15:43,120
since we are talking about both

00:15:41,440 --> 00:15:46,480
distributed databases

00:15:43,120 --> 00:15:49,360
and um the file formats

00:15:46,480 --> 00:15:50,720
i want to highlight here that we can

00:15:49,360 --> 00:15:53,759
either use this to

00:15:50,720 --> 00:15:56,240
make uh bit and byte based keys that we

00:15:53,759 --> 00:15:59,519
can use in our distributed databases

00:15:56,240 --> 00:16:00,880
or if we go ahead and come up with a way

00:15:59,519 --> 00:16:03,920
to take our bit strings

00:16:00,880 --> 00:16:06,720
and map them into to do something like

00:16:03,920 --> 00:16:08,320
base64 encode them or pick another

00:16:06,720 --> 00:16:09,839
string representation for them we can

00:16:08,320 --> 00:16:11,759
use those whenever we're partitioning

00:16:09,839 --> 00:16:15,440
files

00:16:11,759 --> 00:16:17,199
okay so that's the quick caveat

00:16:15,440 --> 00:16:18,880
that i wanted to say that's going to

00:16:17,199 --> 00:16:20,639
make clear that this approach can be

00:16:18,880 --> 00:16:22,800
used for either

00:16:20,639 --> 00:16:24,560
so whenever we're query planning if we

00:16:22,800 --> 00:16:28,160
were querying for just the

00:16:24,560 --> 00:16:30,160
gray rectangle our it's going to

00:16:28,160 --> 00:16:31,600
overlap with our underlying grid

00:16:30,160 --> 00:16:35,120
structure

00:16:31,600 --> 00:16:36,000
and this gives us a little bit of slop

00:16:35,120 --> 00:16:38,800
whenever we're talking

00:16:36,000 --> 00:16:40,320
about what data to actually pull back

00:16:38,800 --> 00:16:42,800
there are some options there

00:16:40,320 --> 00:16:43,440
where we can pull back the additional

00:16:42,800 --> 00:16:46,240
data

00:16:43,440 --> 00:16:46,800
and then use something higher up in the

00:16:46,240 --> 00:16:48,560
stack

00:16:46,800 --> 00:16:50,560
to go ahead and forget about those

00:16:48,560 --> 00:16:52,160
points or we can

00:16:50,560 --> 00:16:55,199
apply fine grand filtering if our

00:16:52,160 --> 00:16:58,240
database will allow us to do that

00:16:55,199 --> 00:17:01,360
okay so the score so far

00:16:58,240 --> 00:17:02,240
is there was some really nerdy math that

00:17:01,360 --> 00:17:04,160
we talked about

00:17:02,240 --> 00:17:06,160
that let us put our points lines and

00:17:04,160 --> 00:17:09,439
polygons into

00:17:06,160 --> 00:17:11,199
uh databases uh like acumulo and hbase

00:17:09,439 --> 00:17:14,160
and cassandra and redis

00:17:11,199 --> 00:17:16,319
um one of the things that we can do in

00:17:14,160 --> 00:17:20,079
the case of cumulon hbase

00:17:16,319 --> 00:17:22,640
is things that happen on the server side

00:17:20,079 --> 00:17:24,079
these optimizations we don't have them

00:17:22,640 --> 00:17:26,959
for cassandra or

00:17:24,079 --> 00:17:28,000
redis uh cassandra and redis have a

00:17:26,959 --> 00:17:32,000
little bit

00:17:28,000 --> 00:17:35,360
uh smaller and also harder to work with

00:17:32,000 --> 00:17:38,640
uh options for pushing down work

00:17:35,360 --> 00:17:40,960
to you know the cluster

00:17:38,640 --> 00:17:42,320
but in accumula on hbase we can push

00:17:40,960 --> 00:17:43,280
down some of the work that we're talking

00:17:42,320 --> 00:17:46,400
about

00:17:43,280 --> 00:17:47,440
so accumulo has iterators hbase has

00:17:46,400 --> 00:17:50,559
filters

00:17:47,440 --> 00:17:53,360
and effectively what we can do

00:17:50,559 --> 00:17:54,960
is um if you think about uh your

00:17:53,360 --> 00:17:57,760
functional programming

00:17:54,960 --> 00:17:59,280
um you know that you've uh we've all

00:17:57,760 --> 00:18:01,600
been learning and adopting over the last

00:17:59,280 --> 00:18:04,480
several years with mapreduce

00:18:01,600 --> 00:18:06,880
we can apply a filter and a map step

00:18:04,480 --> 00:18:10,320
over these key value pairs as they're

00:18:06,880 --> 00:18:13,039
being scanned so this lets us apply

00:18:10,320 --> 00:18:15,360
um fine grain spatial filtering if we

00:18:13,039 --> 00:18:20,240
need to do a point in polygon check

00:18:15,360 --> 00:18:22,000
it would also let us go through and

00:18:20,240 --> 00:18:23,440
check something more careful about the

00:18:22,000 --> 00:18:25,600
additional attributes that may be

00:18:23,440 --> 00:18:28,320
associated to the geometry

00:18:25,600 --> 00:18:29,840
as a concrete example i said we might

00:18:28,320 --> 00:18:32,000
talk about ais some

00:18:29,840 --> 00:18:34,720
if we were looking for tankers that were

00:18:32,000 --> 00:18:38,400
in a given region for a time period

00:18:34,720 --> 00:18:41,360
that spatial temporal uh constraint

00:18:38,400 --> 00:18:42,640
can be used against gma's z3 index that

00:18:41,360 --> 00:18:45,840
gives us a chance to

00:18:42,640 --> 00:18:50,320
cut down the amount of data we're asking

00:18:45,840 --> 00:18:52,400
the database to even consider and that

00:18:50,320 --> 00:18:54,000
restriction to various key ranges can be

00:18:52,400 --> 00:18:55,440
applied across whether we're talking

00:18:54,000 --> 00:18:59,280
about

00:18:55,440 --> 00:19:01,440
redis or cassandra as well as um

00:18:59,280 --> 00:19:03,360
accumula on hbase whenever we're talking

00:19:01,440 --> 00:19:04,480
about uh filtering for that particular

00:19:03,360 --> 00:19:07,679
vessel type

00:19:04,480 --> 00:19:09,440
in accumulon hbase we can push that down

00:19:07,679 --> 00:19:11,200
so the good thing about this is this

00:19:09,440 --> 00:19:14,720
cuts down on

00:19:11,200 --> 00:19:16,480
network traffic if there is some

00:19:14,720 --> 00:19:18,400
work to be done to figure out if the

00:19:16,480 --> 00:19:20,720
records

00:19:18,400 --> 00:19:22,160
match our constraint this also

00:19:20,720 --> 00:19:25,679
distributes the work so that's

00:19:22,160 --> 00:19:28,080
uh useful at the same time

00:19:25,679 --> 00:19:28,960
we shouldn't just think of this being a

00:19:28,080 --> 00:19:31,440
filter step

00:19:28,960 --> 00:19:32,240
in terms of our functional programming

00:19:31,440 --> 00:19:34,080
paradigm

00:19:32,240 --> 00:19:35,440
we can also transform the data with a

00:19:34,080 --> 00:19:36,720
map step

00:19:35,440 --> 00:19:39,600
one of the common things you might want

00:19:36,720 --> 00:19:42,960
to do in a projection is

00:19:39,600 --> 00:19:45,200
drop off certain columns and

00:19:42,960 --> 00:19:46,320
we can do that so we can return just the

00:19:45,200 --> 00:19:49,440
subset of columns

00:19:46,320 --> 00:19:50,640
that's needed either to respond to the

00:19:49,440 --> 00:19:54,480
particular request

00:19:50,640 --> 00:19:55,600
or if we're providing a wms request

00:19:54,480 --> 00:19:56,880
where there's going to be a style

00:19:55,600 --> 00:20:00,480
applied

00:19:56,880 --> 00:20:03,760
we can uh subset down

00:20:00,480 --> 00:20:06,240
just what we're looking for there um

00:20:03,760 --> 00:20:07,840
as a like weird little side note if

00:20:06,240 --> 00:20:08,480
you're ever implementing an accumulo

00:20:07,840 --> 00:20:12,159
iterator

00:20:08,480 --> 00:20:13,840
don't change the key uh uh find me later

00:20:12,159 --> 00:20:14,799
if you want to hear a war story about

00:20:13,840 --> 00:20:18,640
that

00:20:14,799 --> 00:20:20,640
um on the server side we've got filters

00:20:18,640 --> 00:20:24,000
that we can

00:20:20,640 --> 00:20:24,880
plug into where we can either do a

00:20:24,000 --> 00:20:28,159
little bit

00:20:24,880 --> 00:20:29,760
of additional filtering around the

00:20:28,159 --> 00:20:33,120
space filling curves that are used for

00:20:29,760 --> 00:20:35,039
the keys or we can apply the geotools

00:20:33,120 --> 00:20:36,400
query language it's called cql we can

00:20:35,039 --> 00:20:38,799
apply that

00:20:36,400 --> 00:20:39,919
uh to pull back exactly the features

00:20:38,799 --> 00:20:43,120
we're talking about

00:20:39,919 --> 00:20:46,640
there's some other specialized ones that

00:20:43,120 --> 00:20:47,039
fit into finer grain maintenance things

00:20:46,640 --> 00:20:50,480
or

00:20:47,039 --> 00:20:50,480
around visibility

00:20:53,520 --> 00:20:56,960
so as we're talking about all this work

00:20:55,679 --> 00:21:00,400
that can be pushed to

00:20:56,960 --> 00:21:02,799
the distributed database um

00:21:00,400 --> 00:21:04,320
we've seen how we're able to filter and

00:21:02,799 --> 00:21:07,440
transform the data a little bit

00:21:04,320 --> 00:21:09,200
we can also do uh a reduce uh

00:21:07,440 --> 00:21:10,720
and that gives us a chance to do

00:21:09,200 --> 00:21:14,080
aggregations

00:21:10,720 --> 00:21:16,320
so we can do both of these together um

00:21:14,080 --> 00:21:17,360
if we do these aggregations this lets us

00:21:16,320 --> 00:21:20,559
calculate uh

00:21:17,360 --> 00:21:23,760
things like heat maps and statistics

00:21:20,559 --> 00:21:26,240
very easily we can also

00:21:23,760 --> 00:21:27,840
create custom data formats uh i won't

00:21:26,240 --> 00:21:31,280
focus on that one as much

00:21:27,840 --> 00:21:32,880
in this particular talk so um

00:21:31,280 --> 00:21:34,960
the cool thing here is everything we're

00:21:32,880 --> 00:21:35,840
talking about uh works in a single pass

00:21:34,960 --> 00:21:39,280
over the data

00:21:35,840 --> 00:21:42,159
and that single pass is distributed um

00:21:39,280 --> 00:21:43,919
again my kind of anchor point for this

00:21:42,159 --> 00:21:45,039
is imagining that we have our

00:21:43,919 --> 00:21:48,240
encyclopedia

00:21:45,039 --> 00:21:50,080
of data we've passed out the volumes to

00:21:48,240 --> 00:21:52,400
uh everyone in the audience and we're

00:21:50,080 --> 00:21:53,440
asking uh each person to look up in

00:21:52,400 --> 00:21:57,440
their volume

00:21:53,440 --> 00:22:00,320
and do some part of the so if we need to

00:21:57,440 --> 00:22:01,600
calculate something like a heat map um

00:22:00,320 --> 00:22:02,400
everyone's going to have to return their

00:22:01,600 --> 00:22:04,000
part of it

00:22:02,400 --> 00:22:05,520
whenever we aggregate the results then

00:22:04,000 --> 00:22:07,600
we'll have to style it

00:22:05,520 --> 00:22:09,120
uh heat maps are cool because if you

00:22:07,600 --> 00:22:10,840
just return all the points you get a

00:22:09,120 --> 00:22:13,440
view that looks like this

00:22:10,840 --> 00:22:15,280
where um it's

00:22:13,440 --> 00:22:16,880
not very clear we're we're somewhere in

00:22:15,280 --> 00:22:19,919
the mediterranean sea

00:22:16,880 --> 00:22:22,559
and we just have a whole bunch of noise

00:22:19,919 --> 00:22:23,360
if we create a heat map we can start to

00:22:22,559 --> 00:22:25,039
see

00:22:23,360 --> 00:22:28,880
uh where there are shipping lanes things

00:22:25,039 --> 00:22:28,880
start to pop out a little bit better

00:22:29,440 --> 00:22:36,240
the way this is implemented we

00:22:32,720 --> 00:22:38,000
we know what size the user's screen is

00:22:36,240 --> 00:22:41,039
where they've made the request

00:22:38,000 --> 00:22:43,440
and we can ask for a grid

00:22:41,039 --> 00:22:44,640
that's that size and we can ask each

00:22:43,440 --> 00:22:46,480
server to

00:22:44,640 --> 00:22:49,360
uh basically for each pixel return

00:22:46,480 --> 00:22:51,840
account at that point a little

00:22:49,360 --> 00:22:52,799
um kernel gaussian something like that

00:22:51,840 --> 00:22:55,760
is applied

00:22:52,799 --> 00:22:58,720
uh to that to smooth it out and you've

00:22:55,760 --> 00:23:00,960
got control over that as well

00:22:58,720 --> 00:23:02,640
all of this means that we don't have to

00:23:00,960 --> 00:23:04,080
ship all that data back to

00:23:02,640 --> 00:23:05,840
geoserver and we don't have to send it

00:23:04,080 --> 00:23:08,880
back to the client so

00:23:05,840 --> 00:23:10,880
that heat map could represent hundreds

00:23:08,880 --> 00:23:12,640
of thousands or millions of points

00:23:10,880 --> 00:23:14,880
and we're just sending back one small

00:23:12,640 --> 00:23:18,159
png

00:23:14,880 --> 00:23:19,039
as another example of this sort of work

00:23:18,159 --> 00:23:22,559
that we can push

00:23:19,039 --> 00:23:24,480
down we can also um

00:23:22,559 --> 00:23:25,760
come up with uh very complicated

00:23:24,480 --> 00:23:29,200
statistical queries

00:23:25,760 --> 00:23:31,760
so doing something easy like um

00:23:29,200 --> 00:23:32,720
counts or minimum maximum values uh

00:23:31,760 --> 00:23:35,679
would be

00:23:32,720 --> 00:23:36,240
pretty quick to think through and we

00:23:35,679 --> 00:23:38,720
would

00:23:36,240 --> 00:23:40,640
get it right um the thing that's

00:23:38,720 --> 00:23:43,919
non-obvious

00:23:40,640 --> 00:23:45,760
is that there are much more complicated

00:23:43,919 --> 00:23:47,440
things like descriptive statistics where

00:23:45,760 --> 00:23:50,480
you can calculate

00:23:47,440 --> 00:23:51,919
not just a mean but also standard

00:23:50,480 --> 00:23:54,799
deviation

00:23:51,919 --> 00:23:56,159
and higher order moments uh like

00:23:54,799 --> 00:23:57,840
skewering kurtosis

00:23:56,159 --> 00:23:59,279
all of that can be calculated in one

00:23:57,840 --> 00:24:01,760
pass

00:23:59,279 --> 00:24:02,799
over the data so that was a really cool

00:24:01,760 --> 00:24:04,320
thing

00:24:02,799 --> 00:24:05,919
as one of my co-workers pointed that out

00:24:04,320 --> 00:24:07,840
to me

00:24:05,919 --> 00:24:10,430
again the big thing that's happening

00:24:07,840 --> 00:24:11,840
here is we're asking each

00:24:10,430 --> 00:24:13,520
[Music]

00:24:11,840 --> 00:24:14,960
server for their particular part of the

00:24:13,520 --> 00:24:16,480
answer

00:24:14,960 --> 00:24:18,000
there's something similar in the spark

00:24:16,480 --> 00:24:21,440
api if you've ever seen

00:24:18,000 --> 00:24:22,880
their user-defined aggregate functions

00:24:21,440 --> 00:24:26,640
you get the same sort of

00:24:22,880 --> 00:24:30,960
capability there okay

00:24:26,640 --> 00:24:35,360
so just before we leave talking about

00:24:30,960 --> 00:24:37,840
our geospatial databases uh i wanted to

00:24:35,360 --> 00:24:39,360
say a moment or two about some of the

00:24:37,840 --> 00:24:41,279
cool things about using them in practice

00:24:39,360 --> 00:24:42,960
hey jim you've got 10 minutes left in

00:24:41,279 --> 00:24:46,000
this session

00:24:42,960 --> 00:24:48,640
probably in the q a if you like great

00:24:46,000 --> 00:24:49,600
okay thank you very much um so for

00:24:48,640 --> 00:24:52,400
geospatial

00:24:49,600 --> 00:24:53,440
uh databases both accumula and hbase can

00:24:52,400 --> 00:24:56,640
use things like

00:24:53,440 --> 00:24:57,840
aws's s3 and azure and google have

00:24:56,640 --> 00:25:00,960
equivalents

00:24:57,840 --> 00:25:05,120
uh this is cheaper than running uh hdfs

00:25:00,960 --> 00:25:07,200
using uh um whatever attached uh storage

00:25:05,120 --> 00:25:10,799
the particular cloud vendor has

00:25:07,200 --> 00:25:14,240
uh gmasa3 has support for um

00:25:10,799 --> 00:25:15,039
accumulo and hbase both their 1x and 2o

00:25:14,240 --> 00:25:16,720
lines

00:25:15,039 --> 00:25:18,880
so that's something a little bit new

00:25:16,720 --> 00:25:22,000
there um

00:25:18,880 --> 00:25:24,400
so let's talk about some of the

00:25:22,000 --> 00:25:26,840
things that we've done with the various

00:25:24,400 --> 00:25:30,720
vector data formats

00:25:26,840 --> 00:25:32,000
so the cool uh things that we have

00:25:30,720 --> 00:25:33,760
uh with some of the formats we're going

00:25:32,000 --> 00:25:34,880
to talk through some of them have

00:25:33,760 --> 00:25:37,760
columnar layouts

00:25:34,880 --> 00:25:38,320
we've got uh one of them avro that is a

00:25:37,760 --> 00:25:41,440
row

00:25:38,320 --> 00:25:44,000
uh format they wind up having

00:25:41,440 --> 00:25:44,720
tools like dictionary encoding and other

00:25:44,000 --> 00:25:47,760
compression

00:25:44,720 --> 00:25:51,039
uh structures uh that help us out

00:25:47,760 --> 00:25:51,600
um and the language interoperability is

00:25:51,039 --> 00:25:54,880
another

00:25:51,600 --> 00:25:57,120
uh cool thing um there is one

00:25:54,880 --> 00:25:58,720
one catch at the minute uh none of the

00:25:57,120 --> 00:26:01,360
types we're talking about

00:25:58,720 --> 00:26:02,559
out of the box have um a way to handle

00:26:01,360 --> 00:26:05,679
any of the vector data

00:26:02,559 --> 00:26:08,000
uh our priority okay so

00:26:05,679 --> 00:26:09,039
i'll skip over talking about row versus

00:26:08,000 --> 00:26:11,760
column layouts

00:26:09,039 --> 00:26:12,720
um that'll be in the slides if folks are

00:26:11,760 --> 00:26:15,919
interested later

00:26:12,720 --> 00:26:17,919
apache arrow is uh avro sorry is the odd

00:26:15,919 --> 00:26:20,400
one out that we're going to talk about

00:26:17,919 --> 00:26:21,440
here for a moment in that it's row based

00:26:20,400 --> 00:26:25,039
um

00:26:21,440 --> 00:26:27,760
this is going to be great for

00:26:25,039 --> 00:26:29,760
handling whenever we need to think of

00:26:27,760 --> 00:26:32,159
our records one off by themselves

00:26:29,760 --> 00:26:34,559
and also having the schema potentially

00:26:32,159 --> 00:26:37,360
embedded in a file

00:26:34,559 --> 00:26:38,159
parkay and orc are going to look fairly

00:26:37,360 --> 00:26:42,159
similar

00:26:38,159 --> 00:26:44,640
uh they are both column based um

00:26:42,159 --> 00:26:46,000
and we get uh some good compression

00:26:44,640 --> 00:26:50,159
things like that

00:26:46,000 --> 00:26:53,840
um yep so a lot of the same things

00:26:50,159 --> 00:26:55,760
are the same there arrow is optimized

00:26:53,840 --> 00:26:56,960
unlike work and parquet arrows optimized

00:26:55,760 --> 00:27:00,400
for in-memory use

00:26:56,960 --> 00:27:03,279
and um yeah

00:27:00,400 --> 00:27:04,159
will uh that's the probably the key

00:27:03,279 --> 00:27:07,600
point to

00:27:04,159 --> 00:27:09,440
say about arrow okay so

00:27:07,600 --> 00:27:10,640
since these don't have native native

00:27:09,440 --> 00:27:14,080
spatial types

00:27:10,640 --> 00:27:16,480
we have uh to figure out how to actually

00:27:14,080 --> 00:27:20,000
encode the geometries

00:27:16,480 --> 00:27:23,039
and um avro since it's

00:27:20,000 --> 00:27:26,000
the one record-based one we do

00:27:23,039 --> 00:27:26,720
we pretty much want to have one field

00:27:26,000 --> 00:27:29,520
there that's

00:27:26,720 --> 00:27:30,399
representing the uh geometry so we'll

00:27:29,520 --> 00:27:32,320
use something like

00:27:30,399 --> 00:27:34,159
a well-known text or well-known binary

00:27:32,320 --> 00:27:37,279
or tiny well-known binary

00:27:34,159 --> 00:27:39,120
for the other formats we're going to

00:27:37,279 --> 00:27:41,520
wind up

00:27:39,120 --> 00:27:44,159
storing our points as a column of x's

00:27:41,520 --> 00:27:48,159
and a column of y's

00:27:44,159 --> 00:27:49,279
and the good thing about that is uh work

00:27:48,159 --> 00:27:52,240
and parquet

00:27:49,279 --> 00:27:53,600
as they write out their uh files in

00:27:52,240 --> 00:27:55,760
multiple chunks

00:27:53,600 --> 00:27:57,600
will actually keep track of statistics

00:27:55,760 --> 00:28:00,720
of that x value and that y value

00:27:57,600 --> 00:28:02,320
so that allows for some modest amount of

00:28:00,720 --> 00:28:04,399
filtering that can happen

00:28:02,320 --> 00:28:06,720
uh for line strings and multipoints you

00:28:04,399 --> 00:28:08,880
can have a column of list of double for

00:28:06,720 --> 00:28:12,240
x's and a list of y for

00:28:08,880 --> 00:28:13,600
um you know a list of uh doubles for the

00:28:12,240 --> 00:28:15,679
y's

00:28:13,600 --> 00:28:17,440
and once you realize you can play that

00:28:15,679 --> 00:28:19,360
game you can

00:28:17,440 --> 00:28:20,480
have a list of lists and a list of list

00:28:19,360 --> 00:28:24,399
of lists to cover

00:28:20,480 --> 00:28:27,360
uh the other types okay

00:28:24,399 --> 00:28:29,120
uh in terms of reading and writing uh

00:28:27,360 --> 00:28:32,559
this slide has some information about

00:28:29,120 --> 00:28:35,120
our um some of the things there

00:28:32,559 --> 00:28:36,320
i'm skipping through some of this a

00:28:35,120 --> 00:28:38,320
little bit quick to get to

00:28:36,320 --> 00:28:40,399
a few of the other things in terms of

00:28:38,320 --> 00:28:42,000
use cases

00:28:40,399 --> 00:28:43,679
i want to drill into a little bit of

00:28:42,000 --> 00:28:46,480
that for avro

00:28:43,679 --> 00:28:47,360
since each message is its own record

00:28:46,480 --> 00:28:49,840
having it wrote

00:28:47,360 --> 00:28:51,600
having it be row based is uh really

00:28:49,840 --> 00:28:54,880
useful

00:28:51,600 --> 00:28:58,159
we've been sending uh avro

00:28:54,880 --> 00:29:00,799
and cryo to kafka topics and

00:28:58,159 --> 00:29:02,799
uh using that with um either storm or

00:29:00,799 --> 00:29:05,840
things like cave streams or

00:29:02,799 --> 00:29:06,960
uh other technologies to uh do some uh

00:29:05,840 --> 00:29:08,559
good things there

00:29:06,960 --> 00:29:10,480
uh we're looking into using confluence

00:29:08,559 --> 00:29:14,240
schema registry to manage the

00:29:10,480 --> 00:29:15,200
avro schemas and we have this kafka data

00:29:14,240 --> 00:29:17,360
store that also

00:29:15,200 --> 00:29:19,440
will read from this topic and keep it in

00:29:17,360 --> 00:29:23,200
memory index of what's going on

00:29:19,440 --> 00:29:26,159
for spark working with organ parquet

00:29:23,200 --> 00:29:26,720
is really great you don't have to have a

00:29:26,159 --> 00:29:30,480
database

00:29:26,720 --> 00:29:33,760
so that's a nice win there

00:29:30,480 --> 00:29:36,799
so that's handy if you

00:29:33,760 --> 00:29:39,919
have if you do have an hbase merging

00:29:36,799 --> 00:29:41,279
some of that data with a longer view

00:29:39,919 --> 00:29:43,600
that's available

00:29:41,279 --> 00:29:45,039
in something like s3 and worker park a

00:29:43,600 --> 00:29:48,799
files is another

00:29:45,039 --> 00:29:51,840
uh powerful thing and

00:29:48,799 --> 00:29:53,200
apache arrow is really handy for

00:29:51,840 --> 00:29:55,679
doing some of the in-memory things that

00:29:53,200 --> 00:29:58,720
we're talking about

00:29:55,679 --> 00:30:02,559
and this is where we've done a fair bit

00:29:58,720 --> 00:30:04,880
in um working with web browsers to be

00:30:02,559 --> 00:30:05,919
able to create histograms and animate

00:30:04,880 --> 00:30:07,520
points

00:30:05,919 --> 00:30:09,120
and do things like that in the browser

00:30:07,520 --> 00:30:11,200
so um

00:30:09,120 --> 00:30:13,039
we can filter through uh what's

00:30:11,200 --> 00:30:14,240
happening in an arrow file pretty

00:30:13,039 --> 00:30:18,000
quickly there

00:30:14,240 --> 00:30:20,000
um i want to say one or two things about

00:30:18,000 --> 00:30:23,039
where some of this goes for using these

00:30:20,000 --> 00:30:23,840
file formats in practice afro since it

00:30:23,039 --> 00:30:26,399
does have

00:30:23,840 --> 00:30:28,880
can have the schema with it is great for

00:30:26,399 --> 00:30:30,720
interchange between systems

00:30:28,880 --> 00:30:32,000
aero is great for your analysis use

00:30:30,720 --> 00:30:35,120
cases where

00:30:32,000 --> 00:30:37,760
you're sharing memory between

00:30:35,120 --> 00:30:39,760
projects or doing uh between languages

00:30:37,760 --> 00:30:42,799
we're doing something in browser

00:30:39,760 --> 00:30:45,520
and work and part a are going to be

00:30:42,799 --> 00:30:46,960
great for this data lake storage use

00:30:45,520 --> 00:30:48,960
case

00:30:46,960 --> 00:30:51,279
i said earlier that your space filling

00:30:48,960 --> 00:30:52,960
curve could generate a string

00:30:51,279 --> 00:30:54,399
just the same way that hive uses

00:30:52,960 --> 00:30:56,399
partitions

00:30:54,399 --> 00:30:57,519
where you might put in information about

00:30:56,399 --> 00:31:00,320
um

00:30:57,519 --> 00:31:02,240
you know the date or other uh column or

00:31:00,320 --> 00:31:02,960
data like that to separate out what's

00:31:02,240 --> 00:31:05,120
happening

00:31:02,960 --> 00:31:06,480
you could use any of your space fling

00:31:05,120 --> 00:31:10,880
curves to generate those same

00:31:06,480 --> 00:31:12,799
sort of strings to represent

00:31:10,880 --> 00:31:13,919
uh where the data is instead of when the

00:31:12,799 --> 00:31:15,760
data is

00:31:13,919 --> 00:31:18,799
there's file and block level information

00:31:15,760 --> 00:31:20,080
in these parquet files and work files

00:31:18,799 --> 00:31:22,000
that can let you do some course

00:31:20,080 --> 00:31:25,120
filtering and

00:31:22,000 --> 00:31:26,480
if you think through that and also think

00:31:25,120 --> 00:31:29,279
through some of the sorting

00:31:26,480 --> 00:31:31,360
you can pick up some additional

00:31:29,279 --> 00:31:32,640
compression benefits

00:31:31,360 --> 00:31:34,720
a lot of the data that we're talking

00:31:32,640 --> 00:31:37,919
about in this in my use cases

00:31:34,720 --> 00:31:40,159
uh that i'm really interested in uh are

00:31:37,919 --> 00:31:41,200
it's it's entity-based data so if you

00:31:40,159 --> 00:31:43,679
group the data

00:31:41,200 --> 00:31:45,760
sort it by a given entity and then sort

00:31:43,679 --> 00:31:48,799
by time with respect to that

00:31:45,760 --> 00:31:50,640
all the data for a particular uh vessel

00:31:48,799 --> 00:31:52,880
or airplane would be together

00:31:50,640 --> 00:31:54,480
and then um there's going to be pretty

00:31:52,880 --> 00:31:56,559
good compression out along a lot of the

00:31:54,480 --> 00:31:59,840
columns since a lot of the metadata for

00:31:56,559 --> 00:32:00,640
a vessel doesn't change um that's what

00:31:59,840 --> 00:32:03,840
i've got

00:32:00,640 --> 00:32:06,320
uh here's all my contact information uh

00:32:03,840 --> 00:32:07,600
geomesa has a getter that we're fairly

00:32:06,320 --> 00:32:09,600
active on

00:32:07,600 --> 00:32:10,799
so feel free to reach out and ask us

00:32:09,600 --> 00:32:14,960
questions there

00:32:10,799 --> 00:32:17,360
uh ccri is pretty much always hiring um

00:32:14,960 --> 00:32:19,279
to do what we do we need everything from

00:32:17,360 --> 00:32:21,519
devops to help us

00:32:19,279 --> 00:32:23,360
deploy things to software engineers to

00:32:21,519 --> 00:32:25,039
help make more of gmasa

00:32:23,360 --> 00:32:26,960
and data scientists to analyze what we

00:32:25,039 --> 00:32:28,399
do with that

00:32:26,960 --> 00:32:30,559
i'll stop and see what questions there

00:32:28,399 --> 00:32:30,559
are

00:32:31,919 --> 00:32:37,519
thanks jen very good got a couple of

00:32:34,720 --> 00:32:39,600
minutes three minutes

00:32:37,519 --> 00:32:41,440
i don't see anything in the chat

00:32:39,600 --> 00:32:43,840
encourage people to put their questions

00:32:41,440 --> 00:32:43,840
in the chat

00:32:43,919 --> 00:32:48,080
now one thing that occurs to me is uh

00:32:46,000 --> 00:32:49,919
the slide it's not just two

00:32:48,080 --> 00:32:51,840
two or so back with respect to kind of

00:32:49,919 --> 00:32:52,480
your summary on the coding format it's

00:32:51,840 --> 00:32:55,039
ad row

00:32:52,480 --> 00:32:56,399
and arrow and uh first of all it was a

00:32:55,039 --> 00:32:57,760
really good summary with respect to

00:32:56,399 --> 00:32:59,840
applications

00:32:57,760 --> 00:33:01,120
and you know your point here being that

00:32:59,840 --> 00:33:04,559
these are not natively

00:33:01,120 --> 00:33:06,240
spatial you need additional definition

00:33:04,559 --> 00:33:08,080
uh i know for example other groups that

00:33:06,240 --> 00:33:12,240
have done spatial definitions

00:33:08,080 --> 00:33:14,799
in um where you know how should we

00:33:12,240 --> 00:33:18,240
i would say standardize uh you know how

00:33:14,799 --> 00:33:21,360
we do spatial and avro hero

00:33:18,240 --> 00:33:21,360
any thoughts about that

00:33:23,120 --> 00:33:30,000
good question um so

00:33:26,799 --> 00:33:33,440
i yeah um

00:33:30,000 --> 00:33:37,360
i think that's tough because um

00:33:33,440 --> 00:33:39,679
i could certainly see um options for

00:33:37,360 --> 00:33:40,880
just the same way that json is separate

00:33:39,679 --> 00:33:44,159
from geojson

00:33:40,880 --> 00:33:46,240
having a uh for any of these having

00:33:44,159 --> 00:33:47,279
uh something that says okay here's how

00:33:46,240 --> 00:33:50,240
we're gonna

00:33:47,279 --> 00:33:50,960
um you know add geo on top of uh one of

00:33:50,240 --> 00:33:54,559
these

00:33:50,960 --> 00:33:58,080
is a great way um so

00:33:54,559 --> 00:34:01,200
yeah i could see that as one approach um

00:33:58,080 --> 00:34:04,000
there have um i feel like

00:34:01,200 --> 00:34:04,840
for some of what we've done um it's been

00:34:04,000 --> 00:34:08,080
good

00:34:04,840 --> 00:34:08,080
to um

00:34:08,879 --> 00:34:12,720
just get an implementation out there and

00:34:11,599 --> 00:34:15,520
think about

00:34:12,720 --> 00:34:17,280
uh and then be able to iterate uh with

00:34:15,520 --> 00:34:18,879
it in a project

00:34:17,280 --> 00:34:21,040
just to see what works and what doesn't

00:34:18,879 --> 00:34:24,960
work

00:34:21,040 --> 00:34:27,520
so um that said uh i've also seen

00:34:24,960 --> 00:34:29,760
conversations where people have you know

00:34:27,520 --> 00:34:32,399
gotten on github and tried to say okay

00:34:29,760 --> 00:34:33,280
you know we're trying to figure out how

00:34:32,399 --> 00:34:35,520
um

00:34:33,280 --> 00:34:36,639
you know uh arrows should be organized

00:34:35,520 --> 00:34:38,720
so that we can come up with a really

00:34:36,639 --> 00:34:42,320
good python library for it

00:34:38,720 --> 00:34:45,359
and um yeah i think it's interesting to

00:34:42,320 --> 00:34:46,839
see how to organize those talks uh omar

00:34:45,359 --> 00:34:48,240
asked

00:34:46,839 --> 00:34:50,159
um gentlemen i'm gonna leave you with

00:34:48,240 --> 00:34:51,679
those questions in the chat you can look

00:34:50,159 --> 00:34:54,079
at those yourselves and discuss them as

00:34:51,679 --> 00:34:57,200
long as you want because i understand

00:34:54,079 --> 00:34:58,720
great okay so omar's got a question yeah

00:34:57,200 --> 00:35:00,079
so george is gonna drop off because our

00:34:58,720 --> 00:35:00,640
next talk in the track is starting in

00:35:00,079 --> 00:35:02,720
five minutes

00:35:00,640 --> 00:35:04,480
omar's got a question about do you store

00:35:02,720 --> 00:35:07,680
the space-fling curve index

00:35:04,480 --> 00:35:10,000
alongside the coordinates um

00:35:07,680 --> 00:35:10,800
the keys are a lot of the keys in the

00:35:10,000 --> 00:35:15,040
gmasa

00:35:10,800 --> 00:35:17,760
tables are you know created using

00:35:15,040 --> 00:35:18,880
that space filling curve uh information

00:35:17,760 --> 00:35:21,200
so

00:35:18,880 --> 00:35:22,320
um we've got metadata to know which

00:35:21,200 --> 00:35:25,280
curve we used

00:35:22,320 --> 00:35:25,839
to generate those bits and bytes and so

00:35:25,280 --> 00:35:28,720
um

00:35:25,839 --> 00:35:30,320
that's you know really what gets uh used

00:35:28,720 --> 00:35:33,680
there so uh

00:35:30,320 --> 00:35:35,359
we don't have to yeah so

00:35:33,680 --> 00:35:37,440
the coordinates are also stored in the

00:35:35,359 --> 00:35:40,640
value so hopefully that

00:35:37,440 --> 00:35:43,839
helps there a little bit and anita asks

00:35:40,640 --> 00:35:45,440
uh if uh if i'm working on any features

00:35:43,839 --> 00:35:47,040
specializing on movement data like the

00:35:45,440 --> 00:35:50,560
vessel tracks you mentioned

00:35:47,040 --> 00:35:52,960
um and uh

00:35:50,560 --> 00:35:54,160
the answer is yes we're always trying to

00:35:52,960 --> 00:35:56,240
uh

00:35:54,160 --> 00:35:57,680
work on things make them a little better

00:35:56,240 --> 00:36:00,079
uh the

00:35:57,680 --> 00:36:00,800
uh answer is also no not as fast as i'd

00:36:00,079 --> 00:36:02,480
like

00:36:00,800 --> 00:36:04,960
um there is a lot of work that could be

00:36:02,480 --> 00:36:06,800
done um george's talk at the beginning

00:36:04,960 --> 00:36:09,760
mentioned the uh moving feature

00:36:06,800 --> 00:36:12,000
uh ogc spec uh that would be a good one

00:36:09,760 --> 00:36:14,160
to implement

00:36:12,000 --> 00:36:17,040
there's also a fair bit that could be

00:36:14,160 --> 00:36:17,040
done just to

00:36:17,200 --> 00:36:22,560
as you ingest point data point

00:36:20,400 --> 00:36:25,040
observation data to generate

00:36:22,560 --> 00:36:26,079
uh higher level aggregations of the data

00:36:25,040 --> 00:36:29,200
and so

00:36:26,079 --> 00:36:31,839
um yeah um

00:36:29,200 --> 00:36:33,359
so anita is also very interested in this

00:36:31,839 --> 00:36:36,800
she's got papers about

00:36:33,359 --> 00:36:39,119
uh mobility data uh feel free to

00:36:36,800 --> 00:36:40,720
anita if you want to to add a link to

00:36:39,119 --> 00:36:43,760
your stuff in here

00:36:40,720 --> 00:36:45,440
um yeah

00:36:43,760 --> 00:36:47,200
yeah that's that's another topic that's

00:36:45,440 --> 00:36:50,400
very interesting to me so

00:36:47,200 --> 00:36:50,400
are there any other questions

00:36:52,560 --> 00:36:58,880
so uh there is a slack channel uh

00:36:56,000 --> 00:36:59,520
for there there's a slide channel for

00:36:58,880 --> 00:37:01,040
the whole

00:36:59,520 --> 00:37:03,440
apache con conference and there's a

00:37:01,040 --> 00:37:06,079
geospatial channel i'll go ahead

00:37:03,440 --> 00:37:07,040
and try to get my slides over there real

00:37:06,079 --> 00:37:09,520
quick

00:37:07,040 --> 00:37:10,400
and other than that uh please join us

00:37:09,520 --> 00:37:12,880
for

00:37:10,400 --> 00:37:13,839
uh the next two talks uh they'll be

00:37:12,880 --> 00:37:18,400
starting

00:37:13,839 --> 00:37:20,880
here in two or three minutes thanks

00:37:18,400 --> 00:37:24,079
um and i'll hang out here for another

00:37:20,880 --> 00:37:24,079
minute and see if there are any other

00:37:34,839 --> 00:37:37,839
questions

00:38:45,839 --> 00:38:47,920

YouTube URL: https://www.youtube.com/watch?v=2bO7ZxiJVN8


