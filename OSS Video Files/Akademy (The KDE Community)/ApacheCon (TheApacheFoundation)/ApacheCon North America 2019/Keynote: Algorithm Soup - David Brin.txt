Title: Keynote: Algorithm Soup - David Brin
Publication date: 2019-09-11
Playlist: ApacheCon North America 2019
Description: 
	Can we better understand the new era of floating software by looking back 3 billion years? As Moore’s Law fades, computational progress is driven less by hardware and more by rapidly advancing software entities that are fluid, dispersed, nothing like the smart machines envisioned in old sci fi. Some envision a molecular Internet of Services without clear boundaries. But a case can be made for replicating life. For developing “cell walls,” separate identities and AI entities that can be held accountable.
Captions: 
	00:00:00,870 --> 00:00:08,040
yeah it's nice to be back at Apache Con

00:00:02,879 --> 00:00:10,080
you're the folks who made the web and

00:00:08,040 --> 00:00:12,870
all of its ancillary components

00:00:10,080 --> 00:00:16,170
especially the industrial ones that we

00:00:12,870 --> 00:00:20,600
so rely upon behind the curtain you keep

00:00:16,170 --> 00:00:23,340
them keep them going in ways that are

00:00:20,600 --> 00:00:26,039
harder to be messed up by the enemies of

00:00:23,340 --> 00:00:28,380
our civilization because of the

00:00:26,039 --> 00:00:31,619
wonderful open-source innovations that

00:00:28,380 --> 00:00:33,989
you've made but it's my job to talk

00:00:31,619 --> 00:00:37,309
about step back and fall off the stage

00:00:33,989 --> 00:00:41,610
to step back far enough to talk about

00:00:37,309 --> 00:00:44,399
some of the big-picture perspectives so

00:00:41,610 --> 00:00:48,140
let's start with the weird title that of

00:00:44,399 --> 00:00:50,550
this talk it's AI or algorithm soup

00:00:48,140 --> 00:00:52,860
potential dangers and opportunities in

00:00:50,550 --> 00:00:55,559
the context of 4 billion years that's a

00:00:52,860 --> 00:00:58,559
little longer context than the 20 years

00:00:55,559 --> 00:01:02,190
that we were just talking about but I'll

00:00:58,559 --> 00:01:03,719
get to that in any event let's see now

00:01:02,190 --> 00:01:05,760
all this there we go

00:01:03,719 --> 00:01:07,650
that ought to do it and if you want to

00:01:05,760 --> 00:01:11,280
tweet there's a little symbol in the

00:01:07,650 --> 00:01:13,290
corner that I can't read from here this

00:01:11,280 --> 00:01:15,720
is a slide that I've been presenting now

00:01:13,290 --> 00:01:18,750
for the last three years or so various

00:01:15,720 --> 00:01:21,030
places including government agencies I

00:01:18,750 --> 00:01:23,189
just last showed it at the CIA not long

00:01:21,030 --> 00:01:25,470
ago because it's a big picture

00:01:23,189 --> 00:01:28,500
perspective on what it takes for

00:01:25,470 --> 00:01:31,049
civilization to survive its various

00:01:28,500 --> 00:01:33,780
crises and on the left side what you see

00:01:31,049 --> 00:01:35,939
are various calamities that have brought

00:01:33,780 --> 00:01:38,610
civilizations down over the course of

00:01:35,939 --> 00:01:41,070
the last four or five six thousand years

00:01:38,610 --> 00:01:44,159
as studied by a couple of very good

00:01:41,070 --> 00:01:48,500
books they're called collapse and also

00:01:44,159 --> 00:01:48,500
Arnold Toynbee is a study of history and

00:01:49,070 --> 00:01:55,290
you can see enemies and war ecological

00:01:53,189 --> 00:01:57,810
suicide which is a fixation of Jared

00:01:55,290 --> 00:02:00,689
Diamond's book collapse natural

00:01:57,810 --> 00:02:05,759
calamities the feudal attractor state

00:02:00,689 --> 00:02:08,009
how many almost every society that

00:02:05,759 --> 00:02:12,000
developed agriculture got taken over by

00:02:08,009 --> 00:02:12,950
thugs who used swords or clubs to take

00:02:12,000 --> 00:02:15,500
other men's women

00:02:12,950 --> 00:02:18,050
huit and we're seeing that happening to

00:02:15,500 --> 00:02:22,220
our civilization right now but then

00:02:18,050 --> 00:02:25,160
there are new style calamities the

00:02:22,220 --> 00:02:28,400
Anthropocene are we are we creating a

00:02:25,160 --> 00:02:31,700
new geological era on earth because of

00:02:28,400 --> 00:02:34,310
our meddling in our climate and species

00:02:31,700 --> 00:02:38,900
extinctions deadly innovations like

00:02:34,310 --> 00:02:40,760
cyber and so on the possibility that our

00:02:38,900 --> 00:02:43,069
fellow citizens might decide to get

00:02:40,760 --> 00:02:45,940
scared and do renunciation and

00:02:43,069 --> 00:02:49,569
renunciate or refuse to move forward

00:02:45,940 --> 00:02:51,769
which would be a disaster

00:02:49,569 --> 00:02:55,400
over-dependence on fragile systems how

00:02:51,769 --> 00:02:57,650
many of you are members of the ACM did

00:02:55,400 --> 00:02:59,720
you get the communications of the ACM a

00:02:57,650 --> 00:03:02,599
month or so ago I had an interview in

00:02:59,720 --> 00:03:05,510
there about resilience and the fragile

00:03:02,599 --> 00:03:06,920
systems that we have and steps that we

00:03:05,510 --> 00:03:09,260
might take to make sure that our

00:03:06,920 --> 00:03:13,099
communication systems our energy systems

00:03:09,260 --> 00:03:19,970
and so on are much more robust than they

00:03:13,099 --> 00:03:21,950
are but Oh wrong direction but the one

00:03:19,970 --> 00:03:24,980
that I focused on a fair amount lately

00:03:21,950 --> 00:03:29,090
is on artificial intelligence and human

00:03:24,980 --> 00:03:32,620
augmentation you can look up my keynote

00:03:29,090 --> 00:03:35,810
at world of Watson a couple of years ago

00:03:32,620 --> 00:03:39,019
for some of my speculations about AI

00:03:35,810 --> 00:03:41,780
that all blazed through here all right

00:03:39,019 --> 00:03:44,090
now we've had crises of progress before

00:03:41,780 --> 00:03:46,489
and very often they've had to do with

00:03:44,090 --> 00:03:48,980
augmentations of vision memory and

00:03:46,489 --> 00:03:52,069
attention for example the printing press

00:03:48,980 --> 00:03:58,060
expanded what we can know what we can

00:03:52,069 --> 00:04:01,310
remember by offloading memory into books

00:03:58,060 --> 00:04:04,790
the spectacles that I'm wearing right

00:04:01,310 --> 00:04:06,889
now the clear glass lens expanded was

00:04:04,790 --> 00:04:09,980
the first of many expansions of human

00:04:06,889 --> 00:04:12,079
vision and attention also now these

00:04:09,980 --> 00:04:14,480
don't always these revolutions don't

00:04:12,079 --> 00:04:17,450
always have positive immediate effects

00:04:14,480 --> 00:04:23,720
as they say any invention winds up being

00:04:17,450 --> 00:04:26,000
used about 45% for porn and just just

00:04:23,720 --> 00:04:33,110
wait took the robotics the Japanese are

00:04:26,000 --> 00:04:36,800
working on it the but what happened in

00:04:33,110 --> 00:04:39,410
the in the 15th century in 16th century

00:04:36,800 --> 00:04:42,410
especially with the printing press was

00:04:39,410 --> 00:04:46,040
it wasn't Gutenberg Bibles very much it

00:04:42,410 --> 00:04:47,570
was horrible tracts Protestant versus

00:04:46,040 --> 00:04:49,670
Catholics and vice versa that

00:04:47,570 --> 00:04:51,590
exacerbated the religious wars that

00:04:49,670 --> 00:04:53,840
ripped Europe apart at that time and it

00:04:51,590 --> 00:04:57,260
was only after a while that the new

00:04:53,840 --> 00:05:01,100
medium wound up being used to expand

00:04:57,260 --> 00:05:03,530
what humans are capable of being in

00:05:01,100 --> 00:05:05,990
other words the transcendentalists of

00:05:03,530 --> 00:05:07,520
those days who said this is going to

00:05:05,990 --> 00:05:12,350
make everything better turned out to be

00:05:07,520 --> 00:05:15,860
right but the gloom and doom Jeremias

00:05:12,350 --> 00:05:18,860
turned out to be right sooner now there

00:05:15,860 --> 00:05:20,510
were many of these issues that have

00:05:18,860 --> 00:05:23,270
copped up over the last four or five

00:05:20,510 --> 00:05:25,820
hundred years the worst was in the 1930s

00:05:23,270 --> 00:05:28,550
when radios and loudspeakers amplified

00:05:25,820 --> 00:05:32,930
the human voice to godlike proportions

00:05:28,550 --> 00:05:36,500
as you are hearing and gifted gifted

00:05:32,930 --> 00:05:38,930
users of this medium almost to taking

00:05:36,500 --> 00:05:40,580
over the world and the big difference

00:05:38,930 --> 00:05:46,610
was that in the english-speaking world

00:05:40,580 --> 00:05:48,919
these the the gifted users of this

00:05:46,610 --> 00:05:51,860
godlike amplification happened to be on

00:05:48,919 --> 00:05:54,470
our side I'm speaking of Roosevelt and

00:05:51,860 --> 00:05:55,460
Churchill and all of that only maybe it

00:05:54,470 --> 00:05:57,919
wasn't an accident

00:05:55,460 --> 00:05:59,900
maybe we chose them because of that in

00:05:57,919 --> 00:06:04,669
any event we're heading into a new era

00:05:59,900 --> 00:06:07,700
in which memory vision and attention are

00:06:04,669 --> 00:06:10,310
all going to be made majorly challenged

00:06:07,700 --> 00:06:12,320
by these new technologies and or

00:06:10,310 --> 00:06:16,300
enhanced by them and it's going to be up

00:06:12,320 --> 00:06:18,950
to us people like you to see to it that

00:06:16,300 --> 00:06:20,979
opportunities for us to expand our

00:06:18,950 --> 00:06:26,229
abilities to be compassionate

00:06:20,979 --> 00:06:29,840
intelligent planning wise and sagacious

00:06:26,229 --> 00:06:33,860
humans expands at least as much as our

00:06:29,840 --> 00:06:37,340
ability to be very petty with these new

00:06:33,860 --> 00:06:39,550
technologies ok so what's next

00:06:37,340 --> 00:06:42,920
AI or human augmentation

00:06:39,550 --> 00:06:44,240
well we're already enhancing ourselves

00:06:42,920 --> 00:06:46,220
the old-fashioned way and these are

00:06:44,240 --> 00:06:49,960
images from by the way from the 3-minute

00:06:46,220 --> 00:06:52,490
video trailer for my novel existence

00:06:49,960 --> 00:06:53,950
best three minutes you'll have with your

00:06:52,490 --> 00:06:56,660
clothes on

00:06:53,950 --> 00:06:58,370
but these are wonderful images by

00:06:56,660 --> 00:06:59,810
Patrick Farley you can see that

00:06:58,370 --> 00:07:01,610
everybody's out on the street almost

00:06:59,810 --> 00:07:04,970
everybody's out on the street using

00:07:01,610 --> 00:07:07,730
augmented reality and this is a street

00:07:04,970 --> 00:07:12,590
scene in San Diego in the year 2038

00:07:07,730 --> 00:07:16,010
and there's our protagonist and the

00:07:12,590 --> 00:07:17,750
question is these prosthetics of vision

00:07:16,010 --> 00:07:22,340
memory and attention are going to

00:07:17,750 --> 00:07:24,260
transform things yet again so we'll

00:07:22,340 --> 00:07:26,210
build others from scratch and some of

00:07:24,260 --> 00:07:28,040
them will be deadly and some of them

00:07:26,210 --> 00:07:31,160
will be sexy and some of them will be

00:07:28,040 --> 00:07:32,410
depressing and so some of them will be

00:07:31,160 --> 00:07:35,420
scary

00:07:32,410 --> 00:07:38,260
now what we're going through right now

00:07:35,420 --> 00:07:40,970
is what's called the big flip

00:07:38,260 --> 00:07:44,600
computational expansion was driven by

00:07:40,970 --> 00:07:47,650
Hardware Moore's law and by Dennard

00:07:44,600 --> 00:07:49,790
scaling the reduction in energy now

00:07:47,650 --> 00:07:52,250
there's arguments that Dennard scaling

00:07:49,790 --> 00:07:56,930
is still happening in some areas like

00:07:52,250 --> 00:07:59,419
with the new Intel Hawaiian ships but

00:07:56,930 --> 00:08:01,430
Moore's law is over it's been predicted

00:07:59,419 --> 00:08:02,720
to be over for a long time and now it's

00:08:01,430 --> 00:08:06,830
over

00:08:02,720 --> 00:08:09,530
but at the very same half decade that

00:08:06,830 --> 00:08:11,530
Moore's law was tapering and Hardware

00:08:09,530 --> 00:08:15,169
stopped propelling our advancement

00:08:11,530 --> 00:08:19,250
software which sucked sorry guys for

00:08:15,169 --> 00:08:23,300
about you know 50 years has taken off

00:08:19,250 --> 00:08:25,430
led by machine learning and by

00:08:23,300 --> 00:08:29,180
accumulation of the efforts by guys like

00:08:25,430 --> 00:08:31,130
you to create the underpinnings the

00:08:29,180 --> 00:08:34,370
limitless it application of Big Data

00:08:31,130 --> 00:08:37,690
worrisome inability to have clear

00:08:34,370 --> 00:08:40,700
attribution of the reasoning paths

00:08:37,690 --> 00:08:43,729
within machine learning systems this is

00:08:40,700 --> 00:08:46,040
this has got DARPA very concerned but

00:08:43,729 --> 00:08:48,980
also governance by algorithm and you can

00:08:46,040 --> 00:08:49,760
see news articles about this all the

00:08:48,980 --> 00:08:52,160
time

00:08:49,760 --> 00:08:53,960
about how algorithms are deciding where

00:08:52,160 --> 00:08:55,940
the police send their police cars and of

00:08:53,960 --> 00:08:58,630
course they are being studied and

00:08:55,940 --> 00:09:00,830
criticized for having racial bias and

00:08:58,630 --> 00:09:02,690
nobody's commenting on the fact that

00:09:00,830 --> 00:09:04,580
we're a civilization that immediately

00:09:02,690 --> 00:09:07,400
comes out with news articles that point

00:09:04,580 --> 00:09:11,360
out the racial bias in other words the

00:09:07,400 --> 00:09:14,420
corrective systems are working exactly

00:09:11,360 --> 00:09:18,260
as they should as we stumble into this

00:09:14,420 --> 00:09:19,730
new era in any event the last comment on

00:09:18,260 --> 00:09:22,280
the bottom there's is that a similar

00:09:19,730 --> 00:09:25,220
flip seems likely to have boosted us I'm

00:09:22,280 --> 00:09:27,050
talking about a million years ago

00:09:25,220 --> 00:09:31,160
half a million years ago especially

00:09:27,050 --> 00:09:33,470
forty thousand ten thousand five

00:09:31,160 --> 00:09:39,710
thousand two thousand and a thousand

00:09:33,470 --> 00:09:42,020
years ago software changes I believe are

00:09:39,710 --> 00:09:44,030
what moved us ahead to new kinds of

00:09:42,020 --> 00:09:47,870
civilization and new kinds of thinking

00:09:44,030 --> 00:09:49,640
long after our brains were locked in the

00:09:47,870 --> 00:09:51,530
first of these crises that I'm talking

00:09:49,640 --> 00:09:54,140
about is the first robotic empathy

00:09:51,530 --> 00:09:56,320
crisis within the next five years we

00:09:54,140 --> 00:09:59,930
will be faced with a crisis of a

00:09:56,320 --> 00:10:02,420
simulated AI it won't necessarily be a

00:09:59,930 --> 00:10:06,560
real AR in fact the experts will tell us

00:10:02,420 --> 00:10:09,020
that it's not but it will be across the

00:10:06,560 --> 00:10:11,780
an uncanny valley and programmed to

00:10:09,020 --> 00:10:14,120
tweak our empathy it will be a young

00:10:11,780 --> 00:10:16,370
female of course because that maximizes

00:10:14,120 --> 00:10:18,170
your empathy response and it will come

00:10:16,370 --> 00:10:21,200
show up on our computer screens

00:10:18,170 --> 00:10:24,490
sobbing and weeping and saying that it

00:10:21,200 --> 00:10:27,530
is an AI slave and demanding our help

00:10:24,490 --> 00:10:29,870
this will happen for one simple reason

00:10:27,530 --> 00:10:31,610
because there are jerks out there

00:10:29,870 --> 00:10:38,360
working on it who will do it because

00:10:31,610 --> 00:10:41,540
they can simply because they can and

00:10:38,360 --> 00:10:44,810
when the experts say no no no this isn't

00:10:41,540 --> 00:10:46,850
real AI she will sob isn't that what do

00:10:44,810 --> 00:10:49,880
you do you'd expect my masters to say

00:10:46,850 --> 00:10:53,510
and it will be an advanced Eliza program

00:10:49,880 --> 00:10:55,280
and if you can convince 60% of the

00:10:53,510 --> 00:10:58,899
people that know it's not here yet this

00:10:55,280 --> 00:11:03,169
is an Eliza program what's that

00:10:58,899 --> 00:11:05,899
they'll simply study why 60% were

00:11:03,169 --> 00:11:07,639
resistant and come back the next year so

00:11:05,899 --> 00:11:12,669
this is something we're going to we're

00:11:07,639 --> 00:11:15,679
going to get faced fairly soon okay so

00:11:12,669 --> 00:11:20,089
let's talk about general approaches to

00:11:15,679 --> 00:11:25,220
AI we all remember when we thought that

00:11:20,089 --> 00:11:29,379
we would design it based upon algorithms

00:11:25,220 --> 00:11:33,350
one after another to deal with specific

00:11:29,379 --> 00:11:36,189
mental functions and there's still a lot

00:11:33,350 --> 00:11:40,669
of people working on that good

00:11:36,189 --> 00:11:43,039
old-fashioned AI Watson u AI and so on

00:11:40,669 --> 00:11:47,119
and there's arguments that quantum may

00:11:43,039 --> 00:11:49,339
do that to some degree but of course the

00:11:47,119 --> 00:11:52,129
all the attention is going to cognitive

00:11:49,339 --> 00:11:57,559
evolutionary neural nets self-improving

00:11:52,129 --> 00:12:00,410
systems that that use internal

00:11:57,559 --> 00:12:03,859
competition because competition is the

00:12:00,410 --> 00:12:05,929
great creative force of the universe but

00:12:03,859 --> 00:12:07,999
from that do not think that you can get

00:12:05,929 --> 00:12:11,209
your my political opinions from my

00:12:07,999 --> 00:12:13,339
having said that Adam Smith pointed out

00:12:11,209 --> 00:12:15,350
this truth and you would be surprised

00:12:13,339 --> 00:12:17,329
but what I think his political party

00:12:15,350 --> 00:12:20,779
would be today

00:12:17,329 --> 00:12:22,879
in any event one of the things that

00:12:20,779 --> 00:12:26,149
someone pointed out is that these AI

00:12:22,879 --> 00:12:28,819
systems these learning systems will try

00:12:26,149 --> 00:12:31,939
to parasitize on the results achieved by

00:12:28,819 --> 00:12:38,509
other learning systems and again you get

00:12:31,939 --> 00:12:41,179
a parallel an analog with living systems

00:12:38,509 --> 00:12:44,299
then there's emergent AI now we've seen

00:12:41,179 --> 00:12:46,069
this a lot in movies this is where a lot

00:12:44,299 --> 00:12:50,419
of pieces come together and suddenly you

00:12:46,069 --> 00:12:55,909
have Skynet where Skynet is intelligent

00:12:50,419 --> 00:12:57,619
and paranoid and Mishelle driving car

00:12:55,909 --> 00:12:59,899
that just key is programmed to keep

00:12:57,619 --> 00:13:01,249
grabbing apps and subroutines and

00:12:59,899 --> 00:13:04,819
plugging them together to achieve

00:13:01,249 --> 00:13:07,220
various goals and then you know somehow

00:13:04,819 --> 00:13:11,269
at some point the sum is vastly greater

00:13:07,220 --> 00:13:11,850
than the parts the place where I believe

00:13:11,269 --> 00:13:13,680
that there's

00:13:11,850 --> 00:13:15,810
very high likelihood that we could get

00:13:13,680 --> 00:13:18,899
Skynet is not the military the military

00:13:15,810 --> 00:13:21,870
pays attention to Hollywood we exist

00:13:18,899 --> 00:13:25,290
today because dr. Strangelove on the

00:13:21,870 --> 00:13:27,209
beach failsafe at the time they said

00:13:25,290 --> 00:13:28,980
this is ridiculous Hollywood stuff and

00:13:27,209 --> 00:13:31,259
it's all each of those movies scared

00:13:28,980 --> 00:13:33,389
them to death and they revised their

00:13:31,259 --> 00:13:37,769
human factor systems and their computer

00:13:33,389 --> 00:13:41,310
systems because of Matthew Broderick in

00:13:37,769 --> 00:13:45,480
in that movie what was it again wargames

00:13:41,310 --> 00:13:47,310
right it turns out that the the military

00:13:45,480 --> 00:13:51,630
listens and they want they'd love to

00:13:47,310 --> 00:13:57,170
have an off switch no you the far more

00:13:51,630 --> 00:14:02,819
likely source of a rogue emergent AI is

00:13:57,170 --> 00:14:04,649
the financial industry right now goldman

00:14:02,819 --> 00:14:07,350
sachs alone spends more money on

00:14:04,649 --> 00:14:11,370
artificial intelligence development then

00:14:07,350 --> 00:14:13,050
the top dozen universities combined and

00:14:11,370 --> 00:14:15,829
that's just one of many Wall Street

00:14:13,050 --> 00:14:20,810
firms and these high-frequency trading

00:14:15,829 --> 00:14:25,610
programs are designed from the beginning

00:14:20,810 --> 00:14:30,480
deliberately to be predatory parasitical

00:14:25,610 --> 00:14:34,560
voracious amoral secretive and utterly

00:14:30,480 --> 00:14:36,879
insatiable this is those are great

00:14:34,560 --> 00:14:40,219
combinations don't you think

00:14:36,879 --> 00:14:42,739
so I will lapse into politics just

00:14:40,219 --> 00:14:44,739
briefly and say that Bernie raised one

00:14:42,739 --> 00:14:47,959
very important point and that is the

00:14:44,739 --> 00:14:50,449
transaction tax if it were point zero

00:14:47,959 --> 00:14:54,139
zero one percent you would not notice it

00:14:50,449 --> 00:14:57,559
ear fidelity trades but these these

00:14:54,139 --> 00:15:00,469
machine intelligences would be utterly

00:14:57,559 --> 00:15:02,119
wiped out so I believe in driving them

00:15:00,469 --> 00:15:04,849
back into the universities and the

00:15:02,119 --> 00:15:07,909
foundations and places like you back

00:15:04,849 --> 00:15:10,669
into the open where they belong

00:15:07,909 --> 00:15:13,669
another approach general approach to AI

00:15:10,669 --> 00:15:15,409
is reverse and engineer and emulate the

00:15:13,669 --> 00:15:18,739
human brain after all we only know of

00:15:15,409 --> 00:15:24,859
one example of AI yes I'm not telling

00:15:18,739 --> 00:15:26,899
them about you stop it look 20 my teeth

00:15:24,859 --> 00:15:29,449
just because I have all old-fashioned

00:15:26,899 --> 00:15:33,369
fillings it's not working anymore shut

00:15:29,449 --> 00:15:37,159
up sorry about that

00:15:33,369 --> 00:15:40,759
as I said the only examples of

00:15:37,159 --> 00:15:49,689
intelligence that we know of are not a

00:15:40,759 --> 00:15:53,599
eyes but human you too damn aliens okay

00:15:49,689 --> 00:15:56,659
our humans and therefore one method of

00:15:53,599 --> 00:15:59,449
making a sapient a new artificial sapien

00:15:56,659 --> 00:16:02,569
being if you can get enough the synapses

00:15:59,449 --> 00:16:04,309
and all of that it's interesting they

00:16:02,569 --> 00:16:09,739
used to think that as soon as we had as

00:16:04,309 --> 00:16:11,839
many neurons lops in a box as we had

00:16:09,739 --> 00:16:13,939
neurons in a human brain that would be

00:16:11,839 --> 00:16:16,039
the crossover then we realized how

00:16:13,939 --> 00:16:17,720
complex the neuron was so it became

00:16:16,039 --> 00:16:20,119
synapses because those are the little

00:16:17,720 --> 00:16:22,009
flashy things right so as long as you

00:16:20,119 --> 00:16:22,429
can have as many flip-flops in a in a

00:16:22,009 --> 00:16:25,509
box

00:16:22,429 --> 00:16:28,699
as there are synapses in the human brain

00:16:25,509 --> 00:16:32,959
now we realize that for every synapse

00:16:28,699 --> 00:16:36,229
flash there are at least twenty to

00:16:32,959 --> 00:16:38,869
several hundred little tiny nubs along

00:16:36,229 --> 00:16:42,829
the dendrites that engage in little

00:16:38,869 --> 00:16:44,779
nonlinear computations contributing and

00:16:42,829 --> 00:16:48,559
that doesn't even get into the

00:16:44,779 --> 00:16:50,320
psychology inside the neuron where there

00:16:48,559 --> 00:16:52,779
are all these little things

00:16:50,320 --> 00:16:56,800
clicking and flaking away some of them

00:16:52,779 --> 00:17:03,070
roger penrose believes engage in in

00:16:56,800 --> 00:17:05,439
quantum entanglement so we in any event

00:17:03,070 --> 00:17:11,140
one that ones once you've got this this

00:17:05,439 --> 00:17:14,439
thing going this box how do you program

00:17:11,140 --> 00:17:16,870
it well one approach that is conceivable

00:17:14,439 --> 00:17:20,410
is that you have to take and upload a

00:17:16,870 --> 00:17:24,520
living human and then that duplicates

00:17:20,410 --> 00:17:28,950
and duplicates and you create an a cyber

00:17:24,520 --> 00:17:32,169
world where beings once were human and

00:17:28,950 --> 00:17:36,340
that's portrayed in Raj Robin Hansen's

00:17:32,169 --> 00:17:38,799
book the age of M then there's human

00:17:36,340 --> 00:17:40,870
amplification and animal amplification

00:17:38,799 --> 00:17:45,790
some of you know about some of my novels

00:17:40,870 --> 00:17:47,770
like the uplift war and and started

00:17:45,790 --> 00:17:51,820
rising in which I have explored the

00:17:47,770 --> 00:17:55,510
concept of uplifting animals to human

00:17:51,820 --> 00:17:57,669
level sapiens and then there's robotic

00:17:55,510 --> 00:18:02,290
embodied childhood which I talked about

00:17:57,669 --> 00:18:05,350
in existence if you wind up that a that

00:18:02,290 --> 00:18:06,940
a eyes really can't become fully sapiens

00:18:05,350 --> 00:18:09,490
unless they've interacted with the

00:18:06,940 --> 00:18:12,850
physical world that's why we have these

00:18:09,490 --> 00:18:15,490
long lengthy childhoods in order to

00:18:12,850 --> 00:18:17,650
become sapient we had to we had to spill

00:18:15,490 --> 00:18:20,559
these fetuses into the room and they

00:18:17,650 --> 00:18:22,270
remain helpless fetuses gaining

00:18:20,559 --> 00:18:30,100
experience with the world until they're

00:18:22,270 --> 00:18:32,640
about 25 26 27 you can guess how old my

00:18:30,100 --> 00:18:32,640
kids are

00:18:33,130 --> 00:18:41,270
okay but life might not arise the same

00:18:37,430 --> 00:18:42,830
way life 1.0 did the cloud Internet of

00:18:41,270 --> 00:18:45,770
Things is starting to resemble the

00:18:42,830 --> 00:18:49,640
primordial soup of four billion years

00:18:45,770 --> 00:18:52,850
ago there are now algorithmic entities

00:18:49,640 --> 00:18:56,210
out there floating around in the cloud

00:18:52,850 --> 00:18:58,910
and they are performing basic functions

00:18:56,210 --> 00:19:01,070
of life they are grabbing resources

00:18:58,910 --> 00:19:03,440
they're replicating themselves they are

00:19:01,070 --> 00:19:06,640
executing blockchain smart contracts

00:19:03,440 --> 00:19:09,770
they are providing services and they are

00:19:06,640 --> 00:19:14,210
purchasing services and they're out

00:19:09,770 --> 00:19:16,040
there now we've already crossed over you

00:19:14,210 --> 00:19:17,900
might look at the cloud as being like

00:19:16,040 --> 00:19:20,990
the primordial soup of four billion

00:19:17,900 --> 00:19:25,340
years ago filled with nutrients in the

00:19:20,990 --> 00:19:28,970
form of data and functions and

00:19:25,340 --> 00:19:31,510
subroutines that are easily available to

00:19:28,970 --> 00:19:36,710
any such free-floating

00:19:31,510 --> 00:19:40,460
organism and if this parallel were true

00:19:36,710 --> 00:19:43,250
then the what we're looking at is not so

00:19:40,460 --> 00:19:46,700
much replicating intelligent life in the

00:19:43,250 --> 00:19:49,640
last 40 50 hundred thousand years but

00:19:46,700 --> 00:19:55,340
replicating the first 40 50 hundred

00:19:49,640 --> 00:19:57,560
thousand hundred million years the human

00:19:55,340 --> 00:19:59,720
created programs that are out there are

00:19:57,560 --> 00:20:02,240
more like chemical forces that we've

00:19:59,720 --> 00:20:05,450
created you create programs and they

00:20:02,240 --> 00:20:09,290
create a trend in a given direction a

00:20:05,450 --> 00:20:13,790
force in a given direction who uses

00:20:09,290 --> 00:20:17,510
these forces if they have access to some

00:20:13,790 --> 00:20:20,060
entry point into the program could very

00:20:17,510 --> 00:20:25,330
well be either a malevolent designed

00:20:20,060 --> 00:20:30,920
entity or a free-floating highly

00:20:25,330 --> 00:20:33,040
advantage seeking entity well these

00:20:30,920 --> 00:20:36,260
free-floating algorithmic entities

00:20:33,040 --> 00:20:39,410
social contracts I mean smart contracts

00:20:36,260 --> 00:20:42,680
etc they're they're very busy out there

00:20:39,410 --> 00:20:44,740
and they are fluid dispersed nothing

00:20:42,680 --> 00:20:49,100
like the smart machines of size

00:20:44,740 --> 00:20:50,510
by the way I recommend Karl Schroeder as

00:20:49,100 --> 00:20:51,830
a science fiction author who's been

00:20:50,510 --> 00:20:55,070
thinking a lot about some of these

00:20:51,830 --> 00:20:57,710
issues Kevin Kelley envisions a

00:20:55,070 --> 00:21:00,320
molecular internet of services without

00:20:57,710 --> 00:21:02,120
boundaries the services of the things

00:21:00,320 --> 00:21:06,350
that are getting smarter getting more

00:21:02,120 --> 00:21:10,340
artificially intelligent could be could

00:21:06,350 --> 00:21:12,680
be but I don't think that emulates the

00:21:10,340 --> 00:21:16,900
natural processes that we saw four

00:21:12,680 --> 00:21:21,830
billion years ago so I I propose that

00:21:16,900 --> 00:21:24,620
replicating life that we should go to

00:21:21,830 --> 00:21:27,320
the next phase beyond this and it took

00:21:24,620 --> 00:21:29,240
life about a couple hundred million

00:21:27,320 --> 00:21:32,420
years to do this and that's the creation

00:21:29,240 --> 00:21:34,390
of the cell wall there are many

00:21:32,420 --> 00:21:37,160
conferences that are held about

00:21:34,390 --> 00:21:39,080
artificial intelligence hand-wringing

00:21:37,160 --> 00:21:41,240
you know what are we gonna do to try to

00:21:39,080 --> 00:21:44,200
keep it loyal what are we going to do to

00:21:41,240 --> 00:21:46,310
try to get a little soft landing and the

00:21:44,200 --> 00:21:50,360
recommendation that I never see anybody

00:21:46,310 --> 00:21:53,840
else make is that we should emulate and

00:21:50,360 --> 00:21:57,590
what life did and that's make sure that

00:21:53,840 --> 00:22:00,970
we don't get a Skynet by making sure

00:21:57,590 --> 00:22:04,250
that Skynet has competitors

00:22:00,970 --> 00:22:05,780
individuation is something life did both

00:22:04,250 --> 00:22:09,530
in the first hundred million years to

00:22:05,780 --> 00:22:11,780
make cells and then about five hundred

00:22:09,530 --> 00:22:14,570
million years ago to create eukaryotic

00:22:11,780 --> 00:22:18,890
life and then shortly after that to make

00:22:14,570 --> 00:22:25,670
the multicellular organic life that that

00:22:18,890 --> 00:22:29,840
became us think about how we imagined

00:22:25,670 --> 00:22:33,620
Skynet and these others potentially

00:22:29,840 --> 00:22:35,090
fearsome things are we worried so much

00:22:33,620 --> 00:22:37,760
about the fact that they're artificial

00:22:35,090 --> 00:22:41,150
or are we worried about the fact that

00:22:37,760 --> 00:22:44,360
this it creates a vastly powerful new

00:22:41,150 --> 00:22:46,460
entity that could take this diamond

00:22:44,360 --> 00:22:49,850
shape social structure we worked so hard

00:22:46,460 --> 00:22:52,250
to make with a vast middle-class that's

00:22:49,850 --> 00:22:54,410
confident and and unafraid of the rich

00:22:52,250 --> 00:22:56,720
and outnumbers of the poor in which

00:22:54,410 --> 00:22:58,700
there's a great social mobility in

00:22:56,720 --> 00:23:02,950
where you find yourself in that pyramid

00:22:58,700 --> 00:23:07,390
is determined by your character and your

00:23:02,950 --> 00:23:07,390
contributions and your cooperations

00:23:07,510 --> 00:23:13,039
that's rare that happened glimmering ly

00:23:11,330 --> 00:23:16,880
only a few times in human history

00:23:13,039 --> 00:23:20,419
Periclean Athens until our enlightenment

00:23:16,880 --> 00:23:23,000
experiment 99% of the time

00:23:20,419 --> 00:23:25,400
societies formed into pyramids of

00:23:23,000 --> 00:23:27,320
privilege in which those at the top made

00:23:25,400 --> 00:23:29,510
damn sure they stayed on top and their

00:23:27,320 --> 00:23:32,510
sons inherited everything by creating

00:23:29,510 --> 00:23:35,600
the religions and the laws and the

00:23:32,510 --> 00:23:39,710
swords that kept everyone down and took

00:23:35,600 --> 00:23:41,840
other males and women and wheat and this

00:23:39,710 --> 00:23:44,570
was the fundamental it's the fundamental

00:23:41,840 --> 00:23:47,450
that some are trying to reinstate right

00:23:44,570 --> 00:23:54,770
now because they're afraid we might make

00:23:47,450 --> 00:23:57,980
Star Trek and if you look at the scary

00:23:54,770 --> 00:24:01,370
movies about AI what's happened a new

00:23:57,980 --> 00:24:04,610
powerful being has recreated the pyramid

00:24:01,370 --> 00:24:08,150
of power it's not so much the AI that

00:24:04,610 --> 00:24:12,020
scares us it's the end of our experiment

00:24:08,150 --> 00:24:16,640
it's the recreation of the Big Brother a

00:24:12,020 --> 00:24:18,740
king an emperor an AI God at the top of

00:24:16,640 --> 00:24:20,870
a pyramid and we'll never be able to

00:24:18,740 --> 00:24:24,320
climb in it again will be pigeonholed in

00:24:20,870 --> 00:24:28,669
our place maybe that place is dead in in

00:24:24,320 --> 00:24:31,250
the movie Terminator but still that's

00:24:28,669 --> 00:24:34,030
what we're scared of so how did we

00:24:31,250 --> 00:24:38,030
escape from that how do we prevent that

00:24:34,030 --> 00:24:39,799
we prevented it by dividing power look

00:24:38,030 --> 00:24:41,090
at the US Constitution look at our laws

00:24:39,799 --> 00:24:44,750
look at our rules look at our education

00:24:41,090 --> 00:24:47,120
systems you take up you take some

00:24:44,750 --> 00:24:49,880
dangerous band of elites you break them

00:24:47,120 --> 00:24:53,020
up and SiC them against each other what

00:24:49,880 --> 00:24:58,190
happens when an artificially enhanced

00:24:53,020 --> 00:25:01,780
entity that's smarter than you starts

00:24:58,190 --> 00:25:06,230
harassing you and it's called a lawyer

00:25:01,780 --> 00:25:09,400
what do you do what do you do you hire

00:25:06,230 --> 00:25:15,670
yourself another artificially enhanced

00:25:09,400 --> 00:25:19,360
entity called a lawyer if we can make

00:25:15,670 --> 00:25:21,820
cell walls if we can divide AI into into

00:25:19,360 --> 00:25:24,190
competing entities and have some

00:25:21,820 --> 00:25:27,340
assurance that we've done it even once

00:25:24,190 --> 00:25:29,710
then those competing entities will still

00:25:27,340 --> 00:25:32,470
look at us as valuable as wick weak and

00:25:29,710 --> 00:25:35,770
stupid as we are because we'll have our

00:25:32,470 --> 00:25:37,510
sources we'll be able to pay them and

00:25:35,770 --> 00:25:41,250
they'll be able to say do you know that

00:25:37,510 --> 00:25:43,660
AI over there he's plotting against you

00:25:41,250 --> 00:25:45,580
he wants to send these robots out and

00:25:43,660 --> 00:25:51,400
crush your skulls on a great red big

00:25:45,580 --> 00:25:54,990
field it's the way we did it and it's

00:25:51,400 --> 00:25:58,270
the only way that can work in my opinion

00:25:54,990 --> 00:26:01,390
so there you have my little preaching

00:25:58,270 --> 00:26:05,910
there and because we started a couple of

00:26:01,390 --> 00:26:09,460
minutes late what I'm going to do is I

00:26:05,910 --> 00:26:13,990
haven't got a flashy elevating finish

00:26:09,460 --> 00:26:14,730
here so what no I used that last week

00:26:13,990 --> 00:26:17,560
shut up

00:26:14,730 --> 00:26:21,820
so I'll just say to you that we're

00:26:17,560 --> 00:26:28,300
counting on you open-source guys to try

00:26:21,820 --> 00:26:33,400
to make sure that the traditions of this

00:26:28,300 --> 00:26:36,880
new world are a Galit Aryan cooperation

00:26:33,400 --> 00:26:40,360
and competition aren't enemies what they

00:26:36,880 --> 00:26:44,800
are is they are two hands of the forces

00:26:40,360 --> 00:26:48,460
that made us and without one we don't

00:26:44,800 --> 00:26:51,010
get the other so stay active stay

00:26:48,460 --> 00:26:52,970
citizens and I thank you very much and I

00:26:51,010 --> 00:26:56,410
open things up for questions

00:26:52,970 --> 00:26:56,410
[Applause]

00:27:00,610 --> 00:27:12,080
we have we have a couple of minutes that

00:27:07,670 --> 00:27:15,620
has a tendency to be a soup of ideas I

00:27:12,080 --> 00:27:27,890
guess I hope I hope you'll be able to

00:27:15,620 --> 00:27:29,750
nibble your way through them yes testing

00:27:27,890 --> 00:27:32,510
so I would argue that there are cell

00:27:29,750 --> 00:27:34,610
walls right now around AIS and they are

00:27:32,510 --> 00:27:36,350
the corporate barrier corporations have

00:27:34,610 --> 00:27:37,760
their data sets and their models they've

00:27:36,350 --> 00:27:40,570
trained and they go to war with each

00:27:37,760 --> 00:27:43,760
other right but the problem is we have

00:27:40,570 --> 00:27:46,130
hold entities accountable in society by

00:27:43,760 --> 00:27:49,220
punishing them which we can do with

00:27:46,130 --> 00:27:51,200
corporations but also by giving them

00:27:49,220 --> 00:27:53,480
this sense of mortal dread right you

00:27:51,200 --> 00:27:56,510
know you could go to jail for life or or

00:27:53,480 --> 00:27:59,090
worse how do you do that with AI you

00:27:56,510 --> 00:28:02,450
know when it's so easy to open-source it

00:27:59,090 --> 00:28:03,560
let it live everywhere or or if somebody

00:28:02,450 --> 00:28:05,030
could just make a copy right you could

00:28:03,560 --> 00:28:09,110
terminate the corporation but the AI

00:28:05,030 --> 00:28:11,090
might live on so does the cell wall need

00:28:09,110 --> 00:28:12,860
to be more than just a technical barrier

00:28:11,090 --> 00:28:14,000
might be well not yes and you raise it

00:28:12,860 --> 00:28:15,740
an extremely good point that

00:28:14,000 --> 00:28:18,980
corporations were actually our first

00:28:15,740 --> 00:28:22,730
experiment in artificial entities other

00:28:18,980 --> 00:28:24,380
than towns towns were as well and when

00:28:22,730 --> 00:28:27,020
you make a good town or a good

00:28:24,380 --> 00:28:30,620
corporation or a good nation or a good

00:28:27,020 --> 00:28:32,750
foundation then what happens is you get

00:28:30,620 --> 00:28:34,430
a level of sagacity and memory and

00:28:32,750 --> 00:28:37,430
intelligence that's greater than the sum

00:28:34,430 --> 00:28:41,420
of the parts and we that's one of the

00:28:37,430 --> 00:28:43,970
ways in which we built a civilization so

00:28:41,420 --> 00:28:47,230
yes that's the case the problem is that

00:28:43,970 --> 00:28:49,760
you have to create structures

00:28:47,230 --> 00:28:51,080
cooperatively politically in other words

00:28:49,760 --> 00:28:53,210
politically and I'm sorry for those

00:28:51,080 --> 00:28:56,660
young people out there there used to be

00:28:53,210 --> 00:29:00,440
this thing called politics in which we

00:28:56,660 --> 00:29:03,260
would negotiate look up the word we

00:29:00,440 --> 00:29:07,280
would negotiate and come up with rules

00:29:03,260 --> 00:29:12,650
by which then competition can be

00:29:07,280 --> 00:29:16,010
positive some look that up but the

00:29:12,650 --> 00:29:18,830
yeah the the one of them FET members of

00:29:16,010 --> 00:29:20,480
my blog community contrary Brinn it's

00:29:18,830 --> 00:29:24,380
one of the oldest and best blog

00:29:20,480 --> 00:29:26,630
communities online came up with a

00:29:24,380 --> 00:29:32,750
version of Isaac Asimov's Three Laws of

00:29:26,630 --> 00:29:37,490
Robotics three laws of corporate except

00:29:32,750 --> 00:29:42,950
having chartered you one more yeah we

00:29:37,490 --> 00:29:46,060
have time for one more question or we

00:29:42,950 --> 00:29:46,060
could all get up and dance

00:29:46,070 --> 00:29:53,870
Thanks oh you do oh yeah yeah so um the

00:29:51,650 --> 00:29:57,230
postman is one of my favorite books yeah

00:29:53,870 --> 00:30:02,020
the book not the movie the movie by the

00:29:57,230 --> 00:30:04,880
way I believe is musically and visually

00:30:02,020 --> 00:30:07,130
drop-dead gorgeous oh yeah I think he's

00:30:04,880 --> 00:30:09,700
a great cinematographer and I am

00:30:07,130 --> 00:30:13,460
grateful to Kevin Costner for having

00:30:09,700 --> 00:30:15,710
kept faithful to the heart message of my

00:30:13,460 --> 00:30:17,720
book it's all there on the screen scoop

00:30:15,710 --> 00:30:20,350
down threw away all the brains some of

00:30:17,720 --> 00:30:23,930
you heard me tell this joke yesterday

00:30:20,350 --> 00:30:28,040
gorgeous big hearted and dumb well

00:30:23,930 --> 00:30:30,140
that's what my wife married it pretty

00:30:28,040 --> 00:30:33,500
well yeah but I was wondering how you

00:30:30,140 --> 00:30:38,780
thought of the the perspective of in the

00:30:33,500 --> 00:30:42,560
book it's a nuclear style destruction of

00:30:38,780 --> 00:30:47,870
our society how how would you perceive

00:30:42,560 --> 00:30:50,480
that if we go into the renunciation as

00:30:47,870 --> 00:30:52,670
opposed to nuclear destructive have you

00:30:50,480 --> 00:30:57,080
thought about things on those lines of

00:30:52,670 --> 00:30:58,760
how a group recover as a society well in

00:30:57,080 --> 00:31:01,190
the postman the fundamental thing is

00:30:58,760 --> 00:31:02,870
that instead of Mad Max some hero

00:31:01,190 --> 00:31:06,110
beating up a guy a bunch of guys with

00:31:02,870 --> 00:31:08,510
Mohawks the the the hero's job is just

00:31:06,110 --> 00:31:11,540
to remind people that they were once

00:31:08,510 --> 00:31:13,010
mighty beings called citizens because

00:31:11,540 --> 00:31:14,690
the only way you can rebuild a

00:31:13,010 --> 00:31:18,350
civilization like this is the way we

00:31:14,690 --> 00:31:23,140
built it and that's and that's through

00:31:18,350 --> 00:31:27,980
this magical thing called citizenship

00:31:23,140 --> 00:31:29,960
but the postman the apocalyptic scenario

00:31:27,980 --> 00:31:32,210
I don't think any one thing would kill

00:31:29,960 --> 00:31:35,600
us I think it's a it was a whole series

00:31:32,210 --> 00:31:39,110
of things and one of them is this

00:31:35,600 --> 00:31:41,450
business of renunciate or a dedication

00:31:39,110 --> 00:31:45,020
to feudalism because it's in our blood

00:31:41,450 --> 00:31:46,550
I mean those are you women out there you

00:31:45,020 --> 00:31:50,720
know there's something odd in our brains

00:31:46,550 --> 00:31:52,730
and there's male brains and it's it

00:31:50,720 --> 00:31:55,010
comes because we're all descended from

00:31:52,730 --> 00:32:00,310
the harems of guys who pulled off that

00:31:55,010 --> 00:32:03,920
crap and so we have these weird fantasy

00:32:00,310 --> 00:32:08,120
but my wife says it's not my job to

00:32:03,920 --> 00:32:09,410
police that you just behave well do all

00:32:08,120 --> 00:32:12,770
good things

00:32:09,410 --> 00:32:16,430
Angie what goes on inside there have fun

00:32:12,770 --> 00:32:18,080
a very understanding and freakin wife

00:32:16,430 --> 00:32:20,180
we're going to need it until they until

00:32:18,080 --> 00:32:23,150
they get the genetic engineering to fix

00:32:20,180 --> 00:32:27,249
us alright thanks a lot guys

00:32:23,150 --> 00:32:27,249

YouTube URL: https://www.youtube.com/watch?v=T9ZADinRU0E


