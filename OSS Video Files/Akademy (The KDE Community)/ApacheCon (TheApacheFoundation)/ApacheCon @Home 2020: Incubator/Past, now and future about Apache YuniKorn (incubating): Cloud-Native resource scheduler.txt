Title: Past, now and future about Apache YuniKorn (incubating): Cloud-Native resource scheduler
Publication date: 2020-10-16
Playlist: ApacheCon @Home 2020: Incubator
Description: 
	Past, now and future about Apache YuniKorn (incubating): Cloud-Native resource scheduler
Wilfred Spiegelenburg Wangda Tan

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Apache YuniKorn (Incubating) is a light-weight, universal resource scheduler for container orchestrator systems. It was created to achieve fine-grained resource sharing for various workloads efficiently on a large scale, multi-tenant, and cloud-native environment. YuniKorn brings a unified, cross-platform, scheduling experience for mixed workloads that consist of stateless batch workloads and stateful services. YuniKorn now supports K8s and can be deployed as a custom K8s scheduler. YuniKorn's architecture design also allows adding different shim-layer and adapt to different ResourceManager implementation including Apache Hadoop YARN, or any other systems. For this talk, we will talk about gaps in resource scheduling in Cloud-Native environment, and how YuniKorn can support running big data applications (like Spark/Flink/Tensorflow, etc.) on K8s. We will talk about existing and upcoming features of YuniKorn (including hierarchical of queues, resource fairness, gang scheduling support, integration with K8s features, quota management, autoscaling, etc.). We will also share how YuniKorn being used in community partners such as Alibaba, Cloudera, Lyft.

Wilfred is a Staff Software Engineer from Cloudera in Australia. Heâ€™s also PMC member of Apache YuniKorn (incubating), Apache Hadoop committer. He has worked on Hadoop for 6 years mainly on YARN, MapReduce, and Spark. Before Cloudera, he has worked for SUN Microsystems and Oracle as part of the Identity Management teams as a developer and consultant for over 10 years. Wilfred started his career as a lecturer at the Amsterdam University of Applied Science; teaching, designing, and implementing multiple IT systems. Wilfred holds a Master's in Decision Support Systems from Sunderland University. Wangda Tan is Sr. Manager of Compute Platform engineering team @ Cloudera, responsible for all engineering efforts related to Kubernetes, Apache Hadoop YARN, Resource Scheduling, and internal container cloud. In the open-source world, he's a member of Apache Software Foundation (ASF), PMC Chair of Apache Submarine project, He is also project management committee (PMC) members of Apache Hadoop, Apache YuniKorn (incubating). Before joining Cloudera, he leads High-performance-computing on Hadoop related work in EMC/Pivotal. Before that, he worked in Alibaba Cloud and participated in the development of a distributed machine learning platform (later became ODPS XLIB).
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:25,519 --> 00:00:27,599
good

00:00:26,010 --> 00:00:30,880
[Music]

00:00:27,599 --> 00:00:34,160
afternoon it is for us based

00:00:30,880 --> 00:00:37,360
people um good

00:00:34,160 --> 00:00:40,960
morning really early for the apec

00:00:37,360 --> 00:00:44,719
time zone and a late evening

00:00:40,960 --> 00:00:48,640
for the emea

00:00:44,719 --> 00:00:51,520
time zone um wilfred spiegelberg

00:00:48,640 --> 00:00:58,160
and wang da on the other side uh talking

00:00:51,520 --> 00:01:00,960
about unicorn

00:00:58,160 --> 00:01:01,440
wanda will take over from this point on

00:01:00,960 --> 00:01:03,920
um

00:01:01,440 --> 00:01:05,840
for the first bit talking about what's

00:01:03,920 --> 00:01:09,280
unicorn and why we

00:01:05,840 --> 00:01:10,240
work uh on unicorn and what's uh what

00:01:09,280 --> 00:01:12,479
what it is

00:01:10,240 --> 00:01:13,760
um then i'll take you through the

00:01:12,479 --> 00:01:17,439
current state

00:01:13,760 --> 00:01:21,280
of the program um the community

00:01:17,439 --> 00:01:24,880
and what we're looking at for the future

00:01:21,280 --> 00:01:28,080
um any questions

00:01:24,880 --> 00:01:28,640
um pop up in the chat we will try to

00:01:28,080 --> 00:01:31,680
monitor

00:01:28,640 --> 00:01:33,200
whoever is not talking uh will probably

00:01:31,680 --> 00:01:38,000
interrupt and we'll see what

00:01:33,200 --> 00:01:41,200
uh what's going on so um

00:01:38,000 --> 00:01:43,759
well now for start with the

00:01:41,200 --> 00:01:44,399
what is unicorn and why yeah sure so

00:01:43,759 --> 00:01:46,640
sense

00:01:44,399 --> 00:01:48,880
sense wilfred so thank you to let's get

00:01:46,640 --> 00:01:50,320
slide

00:01:48,880 --> 00:01:52,799
yeah so you probably will ask this

00:01:50,320 --> 00:01:53,439
question uh why we need another

00:01:52,799 --> 00:01:57,200
scheduler

00:01:53,439 --> 00:01:57,200
right so

00:01:57,920 --> 00:02:01,600
we first need to know what is resource

00:01:59,759 --> 00:02:05,200
scheduler

00:02:01,600 --> 00:02:06,159
so research scheduler by definition is

00:02:05,200 --> 00:02:09,119
to

00:02:06,159 --> 00:02:10,800
assign the machine resources to your

00:02:09,119 --> 00:02:13,440
applications or services

00:02:10,800 --> 00:02:14,879
right assume you have a bunch of

00:02:13,440 --> 00:02:17,360
machines in your

00:02:14,879 --> 00:02:18,319
data center you have one servers in the

00:02:17,360 --> 00:02:22,000
data center

00:02:18,319 --> 00:02:25,360
and you want to run the etl

00:02:22,000 --> 00:02:26,319
workload or using mapreduce or using

00:02:25,360 --> 00:02:29,360
spark

00:02:26,319 --> 00:02:32,800
or you want to run your website

00:02:29,360 --> 00:02:35,519
using apache http 2

00:02:32,800 --> 00:02:36,080
um so yeah so so you have to get

00:02:35,519 --> 00:02:39,920
resources

00:02:36,080 --> 00:02:42,959
from one of your machine and run your

00:02:39,920 --> 00:02:46,000
applications here so

00:02:42,959 --> 00:02:46,800
example of scheduler uh in the hadoop we

00:02:46,000 --> 00:02:49,200
have a

00:02:46,800 --> 00:02:50,000
yarn capacity scheduler and a fair

00:02:49,200 --> 00:02:52,800
scheduler

00:02:50,000 --> 00:02:54,800
and in kubernetes we have default

00:02:52,800 --> 00:02:58,400
scheduler code back to batch

00:02:54,800 --> 00:02:58,400
volcano and other schedulers

00:02:59,200 --> 00:03:02,800
so the reason we want to create another

00:03:02,000 --> 00:03:06,080
scheduler

00:03:02,800 --> 00:03:06,959
is because we see a lot of change of the

00:03:06,080 --> 00:03:09,200
demand

00:03:06,959 --> 00:03:10,640
and we have different focuses of

00:03:09,200 --> 00:03:14,000
different projects

00:03:10,640 --> 00:03:17,040
so for the batch um which

00:03:14,000 --> 00:03:18,800
is applications and

00:03:17,040 --> 00:03:21,280
and the non-running services they have

00:03:18,800 --> 00:03:23,280
lots of different properties

00:03:21,280 --> 00:03:24,959
so for the batch workload they are

00:03:23,280 --> 00:03:28,080
typically running for

00:03:24,959 --> 00:03:31,360
a short to a million period of time

00:03:28,080 --> 00:03:34,640
right from seconds to

00:03:31,360 --> 00:03:36,080
hours that's a most of the batch

00:03:34,640 --> 00:03:38,720
applications wrong

00:03:36,080 --> 00:03:40,159
so for the batch application there was

00:03:38,720 --> 00:03:43,040
they were spinning off

00:03:40,159 --> 00:03:43,840
a large number of copies to to read

00:03:43,040 --> 00:03:46,319
their data

00:03:43,840 --> 00:03:47,920
and try to process the data and try to

00:03:46,319 --> 00:03:50,720
write the data back

00:03:47,920 --> 00:03:51,519
okay and for the uh long running

00:03:50,720 --> 00:03:55,680
services

00:03:51,519 --> 00:03:59,680
compared to that it's much more static

00:03:55,680 --> 00:04:03,280
you are you probably not typically

00:03:59,680 --> 00:04:05,840
an apache http 2 service

00:04:03,280 --> 00:04:06,560
runs for online for a few seconds and

00:04:05,840 --> 00:04:10,159
and and

00:04:06,560 --> 00:04:13,360
and and and and turned it down right

00:04:10,159 --> 00:04:14,319
and this long running services sometimes

00:04:13,360 --> 00:04:16,400
needs to be

00:04:14,319 --> 00:04:19,600
still up and down based on the

00:04:16,400 --> 00:04:23,120
requirement but that will be more

00:04:19,600 --> 00:04:26,000
more predictable right so for the batch

00:04:23,120 --> 00:04:29,759
we need faster scheduling decisions

00:04:26,000 --> 00:04:32,400
and because in our uh from our

00:04:29,759 --> 00:04:34,560
um customers a lot of customers here are

00:04:32,400 --> 00:04:37,919
running spark applications

00:04:34,560 --> 00:04:38,560
and they have lots of um tasks to run

00:04:37,919 --> 00:04:40,240
every day

00:04:38,560 --> 00:04:42,560
every day they probably will run

00:04:40,240 --> 00:04:45,280
hundreds of thousands tasks

00:04:42,560 --> 00:04:46,240
in a medium-sized cluster right if we

00:04:45,280 --> 00:04:48,560
have to wait

00:04:46,240 --> 00:04:49,280
the scheduling decision for very very

00:04:48,560 --> 00:04:52,080
long

00:04:49,280 --> 00:04:54,000
um we will wait forever for this uh

00:04:52,080 --> 00:04:56,880
scheduling decisions

00:04:54,000 --> 00:04:58,320
and also for the batch workload um we

00:04:56,880 --> 00:05:01,919
have a

00:04:58,320 --> 00:05:03,199
more uh um more harder requirement for

00:05:01,919 --> 00:05:06,320
the multi-tenancy

00:05:03,199 --> 00:05:08,080
of resource sharing so even

00:05:06,320 --> 00:05:09,520
you you still need multi-tenancy in a

00:05:08,080 --> 00:05:12,880
service world you

00:05:09,520 --> 00:05:15,280
if if one team run if if there's one

00:05:12,880 --> 00:05:18,000
department hosted some website and

00:05:15,280 --> 00:05:20,080
another department hosts another website

00:05:18,000 --> 00:05:22,479
they will share the resources with each

00:05:20,080 --> 00:05:23,199
other but that kind of sharing will be

00:05:22,479 --> 00:05:26,560
more

00:05:23,199 --> 00:05:28,400
and more um predictable right it's not

00:05:26,560 --> 00:05:30,560
something going to be changed

00:05:28,400 --> 00:05:31,759
every day every hour every minute like

00:05:30,560 --> 00:05:33,759
that

00:05:31,759 --> 00:05:35,600
but when you run batch workloads the

00:05:33,759 --> 00:05:38,800
batch is very bursty

00:05:35,600 --> 00:05:42,080
and for normally a lot of batch workload

00:05:38,800 --> 00:05:44,240
is only run several times a day

00:05:42,080 --> 00:05:45,199
and every time it requires a lot of

00:05:44,240 --> 00:05:47,280
resource

00:05:45,199 --> 00:05:48,720
it's not something will consistently

00:05:47,280 --> 00:05:52,400
need results

00:05:48,720 --> 00:05:55,520
so we need a better way to to

00:05:52,400 --> 00:05:58,639
have the resource quota can be applied

00:05:55,520 --> 00:06:01,360
to the uh to your cluster so people from

00:05:58,639 --> 00:06:02,000
different teams and can share the

00:06:01,360 --> 00:06:04,800
resources

00:06:02,000 --> 00:06:06,000
with each other and applications running

00:06:04,800 --> 00:06:08,400
in the same cluster

00:06:06,000 --> 00:06:10,319
can also share results with each other

00:06:08,400 --> 00:06:13,520
so we also have cloud native

00:06:10,319 --> 00:06:18,080
uh requirements which you want to

00:06:13,520 --> 00:06:20,560
um to run your compute cluster on cloud

00:06:18,080 --> 00:06:21,360
and so this cluster is to scale up and

00:06:20,560 --> 00:06:23,520
down

00:06:21,360 --> 00:06:24,800
and this is on-prem it's a fixed size

00:06:23,520 --> 00:06:26,880
cluster

00:06:24,800 --> 00:06:27,840
so we have researched uh all the

00:06:26,880 --> 00:06:30,960
different

00:06:27,840 --> 00:06:34,800
um schedules in the existing

00:06:30,960 --> 00:06:36,160
existing in industry and we didn't find

00:06:34,800 --> 00:06:39,199
a scheduler can

00:06:36,160 --> 00:06:39,680
face all these needs and at once so

00:06:39,199 --> 00:06:42,720
that's

00:06:39,680 --> 00:06:43,600
why we want to go ahead to create our

00:06:42,720 --> 00:06:49,840
own schedule

00:06:43,600 --> 00:06:49,840
so if we can go to next slide

00:06:52,639 --> 00:06:56,319
so what we need to have so for the

00:06:55,039 --> 00:06:59,199
universal

00:06:56,319 --> 00:07:01,440
scheduler is something we want to build

00:06:59,199 --> 00:07:04,319
we want to have one single scheduler

00:07:01,440 --> 00:07:06,240
to for all the different environment and

00:07:04,319 --> 00:07:09,039
we don't want your application to change

00:07:06,240 --> 00:07:10,400
their code to use the new scheduler it's

00:07:09,039 --> 00:07:13,039
it's not

00:07:10,400 --> 00:07:14,240
easy to ask any people who using spark

00:07:13,039 --> 00:07:16,400
and if they want to

00:07:14,240 --> 00:07:17,599
use a new scheduler they have to change

00:07:16,400 --> 00:07:20,319
their smart code or

00:07:17,599 --> 00:07:20,720
change maybe only a little bit of their

00:07:20,319 --> 00:07:24,000
uh

00:07:20,720 --> 00:07:25,680
their workflow they won't like it

00:07:24,000 --> 00:07:27,039
and we want to unify the user

00:07:25,680 --> 00:07:28,960
experiences so

00:07:27,039 --> 00:07:30,240
basically no matter if you are running

00:07:28,960 --> 00:07:33,360
application

00:07:30,240 --> 00:07:34,880
applications on cloud on frame or if you

00:07:33,360 --> 00:07:37,280
want to deploy

00:07:34,880 --> 00:07:38,639
batch and services in the same cluster

00:07:37,280 --> 00:07:42,080
or if you

00:07:38,639 --> 00:07:44,240
want to making a resource can be

00:07:42,080 --> 00:07:45,360
a resource protocol can be applied in

00:07:44,240 --> 00:07:47,759
different clusters

00:07:45,360 --> 00:07:48,720
you can use a very similar um

00:07:47,759 --> 00:07:52,080
configuration

00:07:48,720 --> 00:07:54,400
to to um to

00:07:52,080 --> 00:07:56,080
configure your resource needs and also

00:07:54,400 --> 00:08:00,160
you can use the same

00:07:56,080 --> 00:08:02,879
ui to monitoring the resource needs

00:08:00,160 --> 00:08:03,680
so we also want to return from scratch

00:08:02,879 --> 00:08:06,080
that is not

00:08:03,680 --> 00:08:06,879
because we like to reinvent them well

00:08:06,080 --> 00:08:10,240
it's because

00:08:06,879 --> 00:08:13,039
um existing schedulers they are actually

00:08:10,240 --> 00:08:14,160
so they are all uh inherent a lot of

00:08:13,039 --> 00:08:16,319
latency

00:08:14,160 --> 00:08:18,240
um demands like er there are lots of

00:08:16,319 --> 00:08:20,240
demands in how the batch should

00:08:18,240 --> 00:08:21,840
share with us with just one with each

00:08:20,240 --> 00:08:23,599
other and in communities

00:08:21,840 --> 00:08:25,520
it will define how the communities

00:08:23,599 --> 00:08:28,319
should share resources with each other

00:08:25,520 --> 00:08:29,919
so we want you starting from scratch and

00:08:28,319 --> 00:08:33,039
we want you starting from the

00:08:29,919 --> 00:08:35,680
the needs on the action needs

00:08:33,039 --> 00:08:36,479
so then we will have a cleaner code base

00:08:35,680 --> 00:08:39,440
to build on

00:08:36,479 --> 00:08:40,800
we don't have to maintain the latency

00:08:39,440 --> 00:08:44,080
steps

00:08:40,800 --> 00:08:44,959
so that's the step please so what is

00:08:44,080 --> 00:08:47,519
unicom

00:08:44,959 --> 00:08:48,399
the unicorn is open source universal

00:08:47,519 --> 00:08:51,040
scheduler

00:08:48,399 --> 00:08:53,920
and y for yarn pay for kubernetes and

00:08:51,040 --> 00:08:53,920
uni for unified

00:08:55,279 --> 00:08:58,880
so at the beginning we started up this

00:08:57,360 --> 00:09:02,000
project within

00:08:58,880 --> 00:09:05,279
caldera as an internal project and

00:09:02,000 --> 00:09:05,680
since january 2019 we have a small team

00:09:05,279 --> 00:09:08,720
with

00:09:05,680 --> 00:09:09,760
scheduling backgrounds and and started

00:09:08,720 --> 00:09:12,480
this effort

00:09:09,760 --> 00:09:13,360
and we open source this under cloudera

00:09:12,480 --> 00:09:16,959
github

00:09:13,360 --> 00:09:19,600
since july 2019 and the

00:09:16,959 --> 00:09:20,000
initial goal for this is to first focus

00:09:19,600 --> 00:09:22,959
on

00:09:20,000 --> 00:09:23,760
kubernetes because running deploy batch

00:09:22,959 --> 00:09:26,480
workflows

00:09:23,760 --> 00:09:28,480
and communities for example deploy spark

00:09:26,480 --> 00:09:29,680
of link alternatives is very demanding

00:09:28,480 --> 00:09:32,880
requirement

00:09:29,680 --> 00:09:36,640
and initially this has to be

00:09:32,880 --> 00:09:37,440
very be cloud native we want to make

00:09:36,640 --> 00:09:39,440
this hand

00:09:37,440 --> 00:09:42,240
compatible with other scaling with all

00:09:39,440 --> 00:09:45,360
these cloud native features

00:09:42,240 --> 00:09:47,680
so for the incubator project we

00:09:45,360 --> 00:09:49,600
entered our patch incubator since

00:09:47,680 --> 00:09:52,800
january 2020

00:09:49,600 --> 00:09:53,600
and we focus on application support

00:09:52,800 --> 00:09:55,040
after that

00:09:53,600 --> 00:09:57,120
we're adding a lot of scheduling

00:09:55,040 --> 00:10:00,399
features uh and also we

00:09:57,120 --> 00:10:03,120
we now support spark flink tensorflow

00:10:00,399 --> 00:10:04,240
and since that and the reason we choose

00:10:03,120 --> 00:10:06,880
incubator is

00:10:04,240 --> 00:10:08,320
apache incubator is really has really

00:10:06,880 --> 00:10:10,480
good governance model

00:10:08,320 --> 00:10:12,320
and we got a lot of help from uh

00:10:10,480 --> 00:10:14,720
incubator pmcs

00:10:12,320 --> 00:10:15,440
and yeah so so so that helped us to grow

00:10:14,720 --> 00:10:18,160
the project

00:10:15,440 --> 00:10:19,200
pretty fast and the top project is

00:10:18,160 --> 00:10:22,160
written in go

00:10:19,200 --> 00:10:22,640
because that's a standard uh language in

00:10:22,160 --> 00:10:25,680
the

00:10:22,640 --> 00:10:27,519
cloud related world yeah i think that's

00:10:25,680 --> 00:10:28,800
all for my slides so wilfred please take

00:10:27,519 --> 00:10:31,600
over

00:10:28,800 --> 00:10:33,040
yeah so let let's go through a bit of

00:10:31,600 --> 00:10:36,240
the the current state

00:10:33,040 --> 00:10:40,160
um like what i said

00:10:36,240 --> 00:10:43,200
um started 2019 uh we're now in uh

00:10:40,160 --> 00:10:46,240
2020 so uh we've we've

00:10:43,200 --> 00:10:49,600
got through some some time

00:10:46,240 --> 00:10:50,160
um we've currently got six github repo

00:10:49,600 --> 00:10:52,000
so

00:10:50,160 --> 00:10:53,839
we we do have a bit of a split between

00:10:52,000 --> 00:10:57,440
the different repos

00:10:53,839 --> 00:11:01,120
um we've got a number of code repos

00:10:57,440 --> 00:11:02,160
the cord the the shim web and scheduler

00:11:01,120 --> 00:11:05,200
interface

00:11:02,160 --> 00:11:05,920
and beside that we run two non-code

00:11:05,200 --> 00:11:08,959
repos

00:11:05,920 --> 00:11:12,560
for our releases um

00:11:08,959 --> 00:11:13,519
and the the website part of the release

00:11:12,560 --> 00:11:16,160
is also

00:11:13,519 --> 00:11:17,519
the the deployment the helm charts and

00:11:16,160 --> 00:11:21,200
things like that

00:11:17,519 --> 00:11:23,920
that we need to provide to make

00:11:21,200 --> 00:11:25,440
deployment work make deployments work in

00:11:23,920 --> 00:11:28,560
a

00:11:25,440 --> 00:11:31,920
code cloud native

00:11:28,560 --> 00:11:35,440
kind of way we've released

00:11:31,920 --> 00:11:40,480
two releases under the apache incubator

00:11:35,440 --> 00:11:44,399
the first one may and the second one

00:11:40,480 --> 00:11:47,600
just recently in august uh 2020.

00:11:44,399 --> 00:11:48,000
so um we'll talk more about the releases

00:11:47,600 --> 00:11:50,639
and the

00:11:48,000 --> 00:11:51,680
in the community during uh the rest of

00:11:50,639 --> 00:11:54,800
the the talk

00:11:51,680 --> 00:11:57,839
when we get there so

00:11:54,800 --> 00:12:01,360
the current architecture of unicorn so

00:11:57,839 --> 00:12:02,399
the design of unicorn was based on the

00:12:01,360 --> 00:12:07,200
fact that

00:12:02,399 --> 00:12:10,320
we could have and um we will have

00:12:07,200 --> 00:12:12,880
different kind of orchestration

00:12:10,320 --> 00:12:12,880
systems

00:12:14,000 --> 00:12:19,440
and different kind of container

00:12:17,839 --> 00:12:22,880
orchestration systems

00:12:19,440 --> 00:12:26,320
over the long run like was said before

00:12:22,880 --> 00:12:27,440
we've started looking at kubernetes and

00:12:26,320 --> 00:12:30,560
the cloud native

00:12:27,440 --> 00:12:34,399
side of things so we currently run with

00:12:30,560 --> 00:12:37,680
one shim as the container organization

00:12:34,399 --> 00:12:41,120
orchestrate the system but

00:12:37,680 --> 00:12:44,160
the future will give us

00:12:41,120 --> 00:12:46,320
more and multiple ships um

00:12:44,160 --> 00:12:47,760
the shim communicates through

00:12:46,320 --> 00:12:50,959
[Music]

00:12:47,760 --> 00:12:54,079
the schedule interface

00:12:50,959 --> 00:12:56,399
with the unicorn core so

00:12:54,079 --> 00:12:58,399
again here we see a number of the the

00:12:56,399 --> 00:13:01,360
repositories that we just talked about

00:12:58,399 --> 00:13:02,560
core scheduler interface and shim

00:13:01,360 --> 00:13:06,399
they're working

00:13:02,560 --> 00:13:09,440
independently so we can make changes and

00:13:06,399 --> 00:13:11,200
add facilities and and functionality in

00:13:09,440 --> 00:13:13,360
the core

00:13:11,200 --> 00:13:14,560
while keeping the shim the the

00:13:13,360 --> 00:13:16,880
integration with

00:13:14,560 --> 00:13:18,839
uh different organization systems the

00:13:16,880 --> 00:13:21,519
same

00:13:18,839 --> 00:13:24,639
um because we've got a

00:13:21,519 --> 00:13:27,920
predefined layer we also allow

00:13:24,639 --> 00:13:31,040
other groups of other teams to

00:13:27,920 --> 00:13:34,880
come in and provide their own

00:13:31,040 --> 00:13:37,040
different shim talking to the core as

00:13:34,880 --> 00:13:37,040
uh

00:13:38,880 --> 00:13:47,279
the current shim the kubernetes

00:13:42,480 --> 00:13:49,440
um supports two kinds of the deployments

00:13:47,279 --> 00:13:50,959
we've got the data centers the on-prem

00:13:49,440 --> 00:13:54,480
uh kind of systems

00:13:50,959 --> 00:14:03,839
and the cloud instances on an aws

00:13:54,480 --> 00:14:03,839
or google cloud or something like that

00:14:05,680 --> 00:14:10,079
as i mentioned earlier by by wanda

00:14:10,560 --> 00:14:15,519
performance is a a point that is

00:14:13,760 --> 00:14:17,279
completely different between

00:14:15,519 --> 00:14:19,760
let's say the kubernetes default

00:14:17,279 --> 00:14:24,079
scheduler and what we would need

00:14:19,760 --> 00:14:27,600
for an application kind of scheduling

00:14:24,079 --> 00:14:28,320
um from a unicorn perspective we looked

00:14:27,600 --> 00:14:31,440
at it and said

00:14:28,320 --> 00:14:33,519
okay we we need

00:14:31,440 --> 00:14:34,560
fast scheduling because we need

00:14:33,519 --> 00:14:38,639
applications

00:14:34,560 --> 00:14:40,880
um application support

00:14:38,639 --> 00:14:42,839
and everyone can compare that to what we

00:14:40,880 --> 00:14:44,480
currently have within the default

00:14:42,839 --> 00:14:47,920
scheduler

00:14:44,480 --> 00:14:51,199
we can see that for the shim and the

00:14:47,920 --> 00:14:54,399
design that we've got with the unicorn

00:14:51,199 --> 00:14:58,399
scheduler that we are far

00:14:54,399 --> 00:15:02,160
better in processing the the parts

00:14:58,399 --> 00:15:06,240
and the the allocations

00:15:02,160 --> 00:15:09,680
um compared to the default scheduler

00:15:06,240 --> 00:15:13,519
so the performance numbers

00:15:09,680 --> 00:15:16,079
um for let's say services and other

00:15:13,519 --> 00:15:18,000
long-running things are not that

00:15:16,079 --> 00:15:20,800
important if a

00:15:18,000 --> 00:15:23,279
web server takes half a second late

00:15:20,800 --> 00:15:25,519
longer to start up

00:15:23,279 --> 00:15:27,920
then that does not really matter because

00:15:25,519 --> 00:15:30,560
it runs for days and days on end

00:15:27,920 --> 00:15:31,199
but if you've got a hundred thousand

00:15:30,560 --> 00:15:34,880
pots

00:15:31,199 --> 00:15:37,839
over a day to start up and

00:15:34,880 --> 00:15:38,480
it takes long to start up every single

00:15:37,839 --> 00:15:41,519
pot

00:15:38,480 --> 00:15:44,800
then that will have a large impact on

00:15:41,519 --> 00:15:49,279
applications running on that cluster

00:15:44,800 --> 00:15:52,720
so in the community

00:15:49,279 --> 00:15:56,160
through alibaba they run some

00:15:52,720 --> 00:15:59,360
testing on the performance and we

00:15:56,160 --> 00:16:03,120
from a unicorn perspective see an

00:15:59,360 --> 00:16:07,120
improvement um of

00:16:03,120 --> 00:16:10,770
depending on how big it is uh 134 so 134

00:16:07,120 --> 00:16:12,079
or 164 compared to the standard

00:16:10,770 --> 00:16:15,279
[Music]

00:16:12,079 --> 00:16:15,279
kubernetes scheduler

00:16:17,519 --> 00:16:26,079
the other part that we bring

00:16:21,120 --> 00:16:29,199
from unicorn is a management web ui

00:16:26,079 --> 00:16:32,720
so like what you can see

00:16:29,199 --> 00:16:33,279
with other schedulers looking at the

00:16:32,720 --> 00:16:36,720
yarn

00:16:33,279 --> 00:16:37,040
or other pieces we need to be able to

00:16:36,720 --> 00:16:41,680
see

00:16:37,040 --> 00:16:45,199
what's happening on the scheduler itself

00:16:41,680 --> 00:16:48,079
and we provide

00:16:45,199 --> 00:16:49,199
different overviews based on

00:16:48,079 --> 00:16:54,000
applications

00:16:49,199 --> 00:16:57,440
cues nodes and the scheduling throughput

00:16:54,000 --> 00:17:01,839
that you can see in in these kinds of

00:16:57,440 --> 00:17:02,320
systems the improvements around the web

00:17:01,839 --> 00:17:05,600
ui

00:17:02,320 --> 00:17:06,559
are coming through so the same

00:17:05,600 --> 00:17:09,280
simplicity

00:17:06,559 --> 00:17:10,480
was there at first just to show what

00:17:09,280 --> 00:17:13,120
what we were doing

00:17:10,480 --> 00:17:13,600
and we putting more and more information

00:17:13,120 --> 00:17:17,280
in this

00:17:13,600 --> 00:17:21,360
ui to allow you to monitor and

00:17:17,280 --> 00:17:21,360
manage your cluster better

00:17:26,720 --> 00:17:34,160
so from a functionality perspective

00:17:30,160 --> 00:17:37,760
currently um unicorn is deployed as a

00:17:34,160 --> 00:17:40,000
simple straightforward one executable

00:17:37,760 --> 00:17:41,039
in which we have combined a chord and a

00:17:40,000 --> 00:17:44,240
shim

00:17:41,039 --> 00:17:45,840
so that's not really the

00:17:44,240 --> 00:17:47,919
the end model that we're gonna go to

00:17:45,840 --> 00:17:50,000
because in the end model we want to be

00:17:47,919 --> 00:17:52,480
able to deploy

00:17:50,000 --> 00:17:54,080
multiple shims or different shims

00:17:52,480 --> 00:17:57,280
against the same core

00:17:54,080 --> 00:18:00,000
now we're not yet there

00:17:57,280 --> 00:18:00,880
currently they're deployed as the core

00:18:00,000 --> 00:18:04,480
with the shim

00:18:00,880 --> 00:18:07,600
as one one x euro

00:18:04,480 --> 00:18:10,640
we're focused currently purely

00:18:07,600 --> 00:18:14,240
on kubernetes for the scheduling

00:18:10,640 --> 00:18:16,559
and in that um

00:18:14,240 --> 00:18:18,720
with the choice we've also said look we

00:18:16,559 --> 00:18:20,640
need to be able to coexist with other

00:18:18,720 --> 00:18:21,919
kubernetes schedules like one that

00:18:20,640 --> 00:18:23,679
mentioned in the

00:18:21,919 --> 00:18:25,840
talk earlier there are a number of

00:18:23,679 --> 00:18:27,679
different schedules um

00:18:25,840 --> 00:18:30,640
every kubernetes cluster comes with the

00:18:27,679 --> 00:18:30,640
default scheduler

00:18:31,200 --> 00:18:36,720
set up and engaged by by default

00:18:34,320 --> 00:18:38,400
but you can also extend that with

00:18:36,720 --> 00:18:41,280
volcano or

00:18:38,400 --> 00:18:42,000
other schedules so from from our

00:18:41,280 --> 00:18:44,320
perspective

00:18:42,000 --> 00:18:45,360
we want to be able to co-exist with our

00:18:44,320 --> 00:18:50,080
schedulers

00:18:45,360 --> 00:18:52,559
and um not interfere with their working

00:18:50,080 --> 00:18:53,200
but only schedule what we need to

00:18:52,559 --> 00:18:56,320
schedule

00:18:53,200 --> 00:18:58,880
on the cluster the

00:18:56,320 --> 00:19:00,400
other focus for us has been working with

00:18:58,880 --> 00:19:03,520
auto scalers

00:19:00,400 --> 00:19:06,559
so making sure that we can grow

00:19:03,520 --> 00:19:10,559
and shrink the cluster as needed and

00:19:06,559 --> 00:19:12,480
that we can deploy and still provide all

00:19:10,559 --> 00:19:15,200
the functionality that we want

00:19:12,480 --> 00:19:16,000
as per normal working with those other

00:19:15,200 --> 00:19:20,160
scales

00:19:16,000 --> 00:19:24,880
um if you look at for instance yarn

00:19:20,160 --> 00:19:26,880
there's far less of a

00:19:24,880 --> 00:19:28,880
focus on working with an auto scaler

00:19:26,880 --> 00:19:31,360
because the yarn cluster is set up

00:19:28,880 --> 00:19:32,160
you've got your nodes it's running on

00:19:31,360 --> 00:19:35,679
prem

00:19:32,160 --> 00:19:37,440
and um there's no change in the number

00:19:35,679 --> 00:19:39,760
of nodes in the cluster everything

00:19:37,440 --> 00:19:41,200
is far more static while if you're

00:19:39,760 --> 00:19:43,200
looking at a cloud

00:19:41,200 --> 00:19:45,679
respect for a cloud perspective we

00:19:43,200 --> 00:19:48,720
deploy far more

00:19:45,679 --> 00:19:52,559
in a cluster that can grow and shrink

00:19:48,720 --> 00:19:55,760
when needed so for us also

00:19:52,559 --> 00:19:59,200
we need to be elastic so cues

00:19:55,760 --> 00:20:00,320
resource qualities all those things that

00:19:59,200 --> 00:20:03,039
we want to manage

00:20:00,320 --> 00:20:04,960
we need to be able to grow and shrink

00:20:03,039 --> 00:20:07,679
based on the number of nodes based on

00:20:04,960 --> 00:20:11,679
what's there based on what's needed

00:20:07,679 --> 00:20:12,880
now unicorn currently allows you to grow

00:20:11,679 --> 00:20:16,640
and shrink the cluster

00:20:12,880 --> 00:20:19,520
the quotas will grow and shrink with it

00:20:16,640 --> 00:20:21,360
where we where we can and where we need

00:20:19,520 --> 00:20:26,720
to

00:20:21,360 --> 00:20:26,720
we also need to be able to manage

00:20:27,200 --> 00:20:33,840
different kinds of setups so yarn

00:20:30,880 --> 00:20:35,840
often runs within a on-prem kind of

00:20:33,840 --> 00:20:39,440
solution

00:20:35,840 --> 00:20:41,280
and does scheduling based on what it's

00:20:39,440 --> 00:20:44,400
got and how many

00:20:41,280 --> 00:20:46,240
things how many nodes how many resources

00:20:44,400 --> 00:20:48,000
it's got available

00:20:46,240 --> 00:20:49,440
you schedule differently when you're

00:20:48,000 --> 00:20:52,880
scheduling in a

00:20:49,440 --> 00:20:53,840
known kind of setup then when you

00:20:52,880 --> 00:20:57,679
compare that to

00:20:53,840 --> 00:21:01,360
a setup that is going

00:20:57,679 --> 00:21:03,919
up and down in resource sizes so

00:21:01,360 --> 00:21:04,559
we've provided configurable sorting

00:21:03,919 --> 00:21:07,200
policies

00:21:04,559 --> 00:21:08,799
to be able to adjust to those kinds of

00:21:07,200 --> 00:21:11,919
setups

00:21:08,799 --> 00:21:15,679
in a cluster that is set up

00:21:11,919 --> 00:21:20,000
in the cloud you might want to

00:21:15,679 --> 00:21:23,520
schedule in a way that you provide

00:21:20,000 --> 00:21:26,320
as much density on a note that you can

00:21:23,520 --> 00:21:26,880
so pack all the things that you can on a

00:21:26,320 --> 00:21:30,240
note

00:21:26,880 --> 00:21:32,000
and not extend your numbers of notes

00:21:30,240 --> 00:21:33,760
too quickly and then scale up the

00:21:32,000 --> 00:21:36,080
cluster but only use

00:21:33,760 --> 00:21:37,520
half of the resources or less of every

00:21:36,080 --> 00:21:39,840
single node

00:21:37,520 --> 00:21:40,960
while if you're working on prim that

00:21:39,840 --> 00:21:43,840
doesn't really matter

00:21:40,960 --> 00:21:44,720
you probably want to spread your load

00:21:43,840 --> 00:21:46,720
out of the

00:21:44,720 --> 00:21:48,480
of the cluster that you've got and make

00:21:46,720 --> 00:21:51,919
sure that everything has got

00:21:48,480 --> 00:21:52,480
as many many resources and as much cpu

00:21:51,919 --> 00:21:55,600
as

00:21:52,480 --> 00:21:58,799
it can so we allow you to

00:21:55,600 --> 00:22:02,159
set that up and configure it

00:21:58,799 --> 00:22:04,320
like you want to and adjust to

00:22:02,159 --> 00:22:06,480
the need of the deployment that you've

00:22:04,320 --> 00:22:06,480
got

00:22:08,559 --> 00:22:11,440
so if we're going to look at the

00:22:10,080 --> 00:22:12,559
functionality we compare the

00:22:11,440 --> 00:22:15,760
functionality what

00:22:12,559 --> 00:22:20,240
is delivered between unicorn and

00:22:15,760 --> 00:22:22,720
for instance the default scheduler then

00:22:20,240 --> 00:22:25,120
we've got scheduling based on

00:22:22,720 --> 00:22:29,039
applications

00:22:25,120 --> 00:22:31,840
and we support that within unicorn

00:22:29,039 --> 00:22:32,320
an application is not really something

00:22:31,840 --> 00:22:36,000
that is

00:22:32,320 --> 00:22:37,760
known um within kubernetes

00:22:36,000 --> 00:22:39,360
world it's not something that the

00:22:37,760 --> 00:22:41,039
kubernetes scheduler

00:22:39,360 --> 00:22:42,640
works with it's scheduled report it

00:22:41,039 --> 00:22:43,679
schedules your request and that's it it

00:22:42,640 --> 00:22:45,840
doesn't look at

00:22:43,679 --> 00:22:47,280
oh the the application is running

00:22:45,840 --> 00:22:50,080
doesn't

00:22:47,280 --> 00:22:51,360
need these resources is it part of this

00:22:50,080 --> 00:22:52,240
application or part of another

00:22:51,360 --> 00:22:55,840
application

00:22:52,240 --> 00:22:58,080
so we've got a first class citizen

00:22:55,840 --> 00:22:58,880
as an application which is far more

00:22:58,080 --> 00:23:03,760
based on

00:22:58,880 --> 00:23:06,960
a batch job kind of way of things

00:23:03,760 --> 00:23:10,480
job ordering the the evil schedule

00:23:06,960 --> 00:23:13,760
just schedules resources while

00:23:10,480 --> 00:23:15,760
unicorn looks at where does where the

00:23:13,760 --> 00:23:16,799
resource belong to where does it come

00:23:15,760 --> 00:23:19,039
from

00:23:16,799 --> 00:23:20,840
how do we make sure that that

00:23:19,039 --> 00:23:24,240
application that job

00:23:20,840 --> 00:23:25,600
is handled according to the policies

00:23:24,240 --> 00:23:28,960
that it's being set up

00:23:25,600 --> 00:23:31,120
so we saw we support different policies

00:23:28,960 --> 00:23:32,320
first thing first out fair sharing of

00:23:31,120 --> 00:23:34,480
the resources

00:23:32,320 --> 00:23:35,840
so nicely shared between all these

00:23:34,480 --> 00:23:39,200
things

00:23:35,840 --> 00:23:42,880
or the statewear sorting

00:23:39,200 --> 00:23:46,480
that you make sure that you only allow

00:23:42,880 --> 00:23:50,159
new applications in a

00:23:46,480 --> 00:23:53,279
limited way into the queue so that you

00:23:50,159 --> 00:23:56,480
do not overrun the cluster and scale up

00:23:53,279 --> 00:23:58,960
need to scale up too quickly

00:23:56,480 --> 00:24:01,919
fine grace gradient resource and

00:23:58,960 --> 00:24:04,900
capacity management

00:24:01,919 --> 00:24:06,240
the default scheduler has got a simple

00:24:04,900 --> 00:24:09,360
[Music]

00:24:06,240 --> 00:24:12,799
on the submit enforcement

00:24:09,360 --> 00:24:15,679
of resource many

00:24:12,799 --> 00:24:16,480
requests and if you don't have the

00:24:15,679 --> 00:24:19,919
resources

00:24:16,480 --> 00:24:22,320
it will deny access to the cluster and

00:24:19,919 --> 00:24:23,440
the client needs to take over and need

00:24:22,320 --> 00:24:26,880
to do all the

00:24:23,440 --> 00:24:28,159
um the handling of resubmitting and

00:24:26,880 --> 00:24:31,360
doing all that kind of stuff

00:24:28,159 --> 00:24:33,440
well on unicorn we queue the request

00:24:31,360 --> 00:24:34,720
we put it in the queue it doesn't take

00:24:33,440 --> 00:24:37,840
any resources

00:24:34,720 --> 00:24:38,880
if it's not running so we don't have to

00:24:37,840 --> 00:24:41,919
enforce anything

00:24:38,880 --> 00:24:45,360
on that point and we

00:24:41,919 --> 00:24:49,279
also allow you to set up

00:24:45,360 --> 00:24:51,600
q systems within unicorn

00:24:49,279 --> 00:24:52,799
which can have their own minimum and

00:24:51,600 --> 00:24:55,600
maximum

00:24:52,799 --> 00:24:56,400
resources set so we allow you to do far

00:24:55,600 --> 00:24:59,360
more than just

00:24:56,400 --> 00:25:02,880
a there's no resources at this point in

00:24:59,360 --> 00:25:05,440
time and we deny you access

00:25:02,880 --> 00:25:06,000
resource fairness between the different

00:25:05,440 --> 00:25:09,760
queues

00:25:06,000 --> 00:25:11,919
or different applications kubernetes

00:25:09,760 --> 00:25:13,279
doesn't look at it it just denies you

00:25:11,919 --> 00:25:16,960
access

00:25:13,279 --> 00:25:18,640
while in unicorn we allow you to share

00:25:16,960 --> 00:25:23,600
resources fairly

00:25:18,640 --> 00:25:26,960
or on a priority basis

00:25:23,600 --> 00:25:29,520
which which is being worked on between

00:25:26,960 --> 00:25:30,000
applications that are within a queue or

00:25:29,520 --> 00:25:31,919
over

00:25:30,000 --> 00:25:33,760
the different queues in the in the

00:25:31,919 --> 00:25:36,960
system

00:25:33,760 --> 00:25:38,080
so we support native workloads big data

00:25:36,960 --> 00:25:41,600
workloads out of

00:25:38,080 --> 00:25:44,000
the box because that's the design that

00:25:41,600 --> 00:25:45,600
unicorn was built on we need to be able

00:25:44,000 --> 00:25:48,559
to

00:25:45,600 --> 00:25:49,440
have applications and then work through

00:25:48,559 --> 00:25:51,679
them

00:25:49,440 --> 00:25:53,760
while the evil schedule just does long

00:25:51,679 --> 00:25:55,600
running services

00:25:53,760 --> 00:25:57,760
and as we've seen in one of the previous

00:25:55,600 --> 00:26:01,200
slides

00:25:57,760 --> 00:26:03,919
unicorn is designed for performance far

00:26:01,200 --> 00:26:05,440
larger throughput that we need to be

00:26:03,919 --> 00:26:09,039
able to support

00:26:05,440 --> 00:26:11,679
compared to the default scheduler

00:26:09,039 --> 00:26:12,480
so let's go and have a look at the

00:26:11,679 --> 00:26:15,760
community

00:26:12,480 --> 00:26:16,240
so like one day we've been open source

00:26:15,760 --> 00:26:19,520
since

00:26:16,240 --> 00:26:24,720
uh july 2019 but that was purely

00:26:19,520 --> 00:26:27,760
a cloudera point and the community

00:26:24,720 --> 00:26:31,120
started working after that um

00:26:27,760 --> 00:26:31,600
and we've got a couple of instances a

00:26:31,120 --> 00:26:35,120
couple of

00:26:31,600 --> 00:26:36,240
examples here from uh other companies

00:26:35,120 --> 00:26:39,679
that run

00:26:36,240 --> 00:26:40,880
unicorn in their uh in their clusters in

00:26:39,679 --> 00:26:44,159
their setups

00:26:40,880 --> 00:26:45,840
um and i think at the moment there's a

00:26:44,159 --> 00:26:50,840
different talk also going on

00:26:45,840 --> 00:26:53,679
around um what we've seen with um

00:26:50,840 --> 00:26:56,880
other kubernetes and

00:26:53,679 --> 00:26:57,840
unicorn scheduling um but the first

00:26:56,880 --> 00:27:01,200
instance

00:26:57,840 --> 00:27:05,120
we've got lyft is a a big community

00:27:01,200 --> 00:27:07,840
user and they used unicorn

00:27:05,120 --> 00:27:09,120
in non-production clusters um they're

00:27:07,840 --> 00:27:12,720
pushing through

00:27:09,120 --> 00:27:12,720
large numbers of jobs and seen

00:27:12,880 --> 00:27:20,720
big increases in their utilization

00:27:16,960 --> 00:27:24,399
and higher request

00:27:20,720 --> 00:27:27,520
hits so the first in first out and fair

00:27:24,399 --> 00:27:30,640
scheduling make sure that the jobs work

00:27:27,520 --> 00:27:33,919
and then flow through better

00:27:30,640 --> 00:27:38,320
within claudia we ship

00:27:33,919 --> 00:27:38,320
uh the public cloud

00:27:39,200 --> 00:27:43,360
product and unicorn does the scheduling

00:27:41,840 --> 00:27:46,559
within the the public

00:27:43,360 --> 00:27:50,159
product that we've got mainly for

00:27:46,559 --> 00:27:53,679
for spark jobs at the moment but

00:27:50,159 --> 00:27:55,360
it also does the the the micro services

00:27:53,679 --> 00:27:58,240
that we need within

00:27:55,360 --> 00:27:59,440
uh the the public cloud offering and it

00:27:58,240 --> 00:28:03,360
schedules them

00:27:59,440 --> 00:28:06,000
in a shared kind of way

00:28:03,360 --> 00:28:06,880
like what we said we can't we can do

00:28:06,000 --> 00:28:10,799
more than just

00:28:06,880 --> 00:28:14,640
the patch jobs or the

00:28:10,799 --> 00:28:17,120
the services with unicorn so

00:28:14,640 --> 00:28:18,640
in that can in that setup we

00:28:17,120 --> 00:28:21,360
specifically focused on

00:28:18,640 --> 00:28:23,360
uh auto scaling and resource management

00:28:21,360 --> 00:28:25,600
and resource quota management

00:28:23,360 --> 00:28:27,440
and then alibaba as the is one of the

00:28:25,600 --> 00:28:30,960
third

00:28:27,440 --> 00:28:33,440
community members they've been running

00:28:30,960 --> 00:28:34,240
mainly focused on the on the performance

00:28:33,440 --> 00:28:35,840
the

00:28:34,240 --> 00:28:37,679
performance figures that we saw a little

00:28:35,840 --> 00:28:41,840
bit earlier on

00:28:37,679 --> 00:28:45,600
um were done in alibaba

00:28:41,840 --> 00:28:48,720
cloud setups and they run with

00:28:45,600 --> 00:28:52,480
pre-production clusters on-premise

00:28:48,720 --> 00:28:54,559
clusters with 100 of 100 load

00:28:52,480 --> 00:28:55,679
they're working on production

00:28:54,559 --> 00:28:58,720
deployments

00:28:55,679 --> 00:29:00,000
and they specifically focused on the

00:28:58,720 --> 00:29:02,880
performance and

00:29:00,000 --> 00:29:04,080
the resource sharing so they made sure

00:29:02,880 --> 00:29:06,559
that

00:29:04,080 --> 00:29:08,640
they've got their queues set up with

00:29:06,559 --> 00:29:11,440
resource fairness between the queues

00:29:08,640 --> 00:29:12,000
and they're running large apache flink

00:29:11,440 --> 00:29:15,200
jobs

00:29:12,000 --> 00:29:18,960
on the on kubernetes and again

00:29:15,200 --> 00:29:22,159
they saw a big gain in

00:29:18,960 --> 00:29:24,799
scheduling performance so jobs

00:29:22,159 --> 00:29:26,240
got scheduled quicker and pushed out and

00:29:24,799 --> 00:29:28,000
then into the clusters

00:29:26,240 --> 00:29:30,399
far far quicker than with the default

00:29:28,000 --> 00:29:30,399
scheduler

00:29:30,720 --> 00:29:37,279
so for our release work um we're trying

00:29:34,399 --> 00:29:38,720
to release about every three months

00:29:37,279 --> 00:29:40,640
through the community

00:29:38,720 --> 00:29:41,760
so we scale your minor release at the

00:29:40,640 --> 00:29:45,120
moment

00:29:41,760 --> 00:29:49,360
we did 0.8 0.9 and

00:29:45,120 --> 00:29:53,360
we're currently working on 0.10

00:29:49,360 --> 00:29:57,360
and the current planning

00:29:53,360 --> 00:30:01,120
is for us to release um 0.10

00:29:57,360 --> 00:30:04,480
late october um early november

00:30:01,120 --> 00:30:08,880
for of this year um

00:30:04,480 --> 00:30:11,760
the planning for 1.0 is is on its way

00:30:08,880 --> 00:30:12,320
um we still want to do a couple of

00:30:11,760 --> 00:30:14,640
things

00:30:12,320 --> 00:30:16,320
before we we get there but we we are

00:30:14,640 --> 00:30:20,559
working towards that

00:30:16,320 --> 00:30:25,120
um and we hope that we can announce a

00:30:20,559 --> 00:30:26,720
1.0 in the not the distant future

00:30:25,120 --> 00:30:28,399
the other thing that we have really

00:30:26,720 --> 00:30:30,960
focused on is growing

00:30:28,399 --> 00:30:32,080
the community so we're seeing more

00:30:30,960 --> 00:30:36,320
interest we're seeing

00:30:32,080 --> 00:30:40,080
interest coming from different uh

00:30:36,320 --> 00:30:44,240
uses we had some

00:30:40,080 --> 00:30:48,000
contribution coming in recently

00:30:44,240 --> 00:30:51,679
from from redhead looking at

00:30:48,000 --> 00:30:55,200
running unicorn on openshift clusters um

00:30:51,679 --> 00:30:57,679
so we we see different

00:30:55,200 --> 00:30:58,480
groups coming in and looking more over

00:30:57,679 --> 00:31:01,039
our shoulder

00:30:58,480 --> 00:31:01,519
starting to work on the on the product

00:31:01,039 --> 00:31:04,320
and

00:31:01,519 --> 00:31:06,720
helping us out over the last couple of

00:31:04,320 --> 00:31:06,720
months

00:31:06,799 --> 00:31:13,840
we've also added two new committers

00:31:09,919 --> 00:31:16,960
to the uh to the group

00:31:13,840 --> 00:31:19,840
like i mentioned earlier uh alibaba was

00:31:16,960 --> 00:31:20,880
really early on they they came with uh

00:31:19,840 --> 00:31:23,360
with the project

00:31:20,880 --> 00:31:24,399
but lyft is one of those new committees

00:31:23,360 --> 00:31:28,320
that we've seen

00:31:24,399 --> 00:31:30,799
coming up um and they gave us a

00:31:28,320 --> 00:31:31,440
large amount of feedback on what we were

00:31:30,799 --> 00:31:36,240
doing

00:31:31,440 --> 00:31:39,360
and how that so

00:31:36,240 --> 00:31:42,559
one of the other community com

00:31:39,360 --> 00:31:46,000
contributed uh bits was

00:31:42,559 --> 00:31:47,919
our website um we

00:31:46,000 --> 00:31:49,919
came out of the world from from from a

00:31:47,919 --> 00:31:52,640
yarn in a submarine and

00:31:49,919 --> 00:31:53,440
things like that so we we leveraged what

00:31:52,640 --> 00:31:56,640
was there

00:31:53,440 --> 00:32:00,960
and uh built our own website

00:31:56,640 --> 00:32:03,840
but from a community contribution

00:32:00,960 --> 00:32:04,799
we we we got a complete new website

00:32:03,840 --> 00:32:08,880
built

00:32:04,799 --> 00:32:12,080
um contributed based on on docusaurus

00:32:08,880 --> 00:32:15,279
a facebook open source project and

00:32:12,080 --> 00:32:18,080
um we're running with that now if

00:32:15,279 --> 00:32:20,640
if you've got questions look at that um

00:32:18,080 --> 00:32:24,159
we we use the website to provide

00:32:20,640 --> 00:32:27,919
us with our version documentation um

00:32:24,159 --> 00:32:28,240
and all the whole build is is automated

00:32:27,919 --> 00:32:31,840
and

00:32:28,240 --> 00:32:35,840
what a large community distribution

00:32:31,840 --> 00:32:39,200
that came out of a completely different

00:32:35,840 --> 00:32:42,640
project is that we

00:32:39,200 --> 00:32:44,799
we do a community sink bi-weekly or

00:32:42,640 --> 00:32:46,480
monthly

00:32:44,799 --> 00:32:47,840
we do it in different time zones and

00:32:46,480 --> 00:32:51,600
languages

00:32:47,840 --> 00:32:54,840
wayway runs

00:32:51,600 --> 00:32:57,919
the chinese language setup

00:32:54,840 --> 00:33:00,000
because we've got a large

00:32:57,919 --> 00:33:01,039
larger group of people also coming in

00:33:00,000 --> 00:33:04,720
from china

00:33:01,039 --> 00:33:07,519
so that hooks again back into what we

00:33:04,720 --> 00:33:08,000
see within apache also is the the rise

00:33:07,519 --> 00:33:09,760
of

00:33:08,000 --> 00:33:12,480
the the eight pack and the different

00:33:09,760 --> 00:33:16,000
time zones so we try to accommodate that

00:33:12,480 --> 00:33:17,279
so we run an english um community sync

00:33:16,000 --> 00:33:21,440
and we run a

00:33:17,279 --> 00:33:24,480
chinese language based community sync

00:33:21,440 --> 00:33:26,159
again get more information on it

00:33:24,480 --> 00:33:28,000
yeah so with it we'll have six minutes

00:33:26,159 --> 00:33:31,760
left i'm sure

00:33:28,000 --> 00:33:33,840
okay yeah so

00:33:31,760 --> 00:33:36,840
what do we do what what's the future

00:33:33,840 --> 00:33:38,240
where are we going uh currently with the

00:33:36,840 --> 00:33:40,640
um

00:33:38,240 --> 00:33:41,440
with setup so the next release like i

00:33:40,640 --> 00:33:44,880
said before

00:33:41,440 --> 00:33:46,480
is uh 0.10 we're looking at core

00:33:44,880 --> 00:33:50,880
scheduling improvements

00:33:46,480 --> 00:33:54,000
we think we can be even faster and

00:33:50,880 --> 00:33:55,919
better at scheduling so we're looking at

00:33:54,000 --> 00:33:59,279
a large change for that

00:33:55,919 --> 00:34:03,039
um we we've seen community

00:33:59,279 --> 00:34:04,799
engagement around the tracing and

00:34:03,039 --> 00:34:06,559
the the logging that we want to

00:34:04,799 --> 00:34:09,520
implement and

00:34:06,559 --> 00:34:09,919
kubernetes is moving along so we want to

00:34:09,520 --> 00:34:13,520
move

00:34:09,919 --> 00:34:17,280
and then see new versions of kubernetes

00:34:13,520 --> 00:34:20,879
support so um 116 is

00:34:17,280 --> 00:34:24,800
in progress other

00:34:20,879 --> 00:34:26,879
improvements is even better support for

00:34:24,800 --> 00:34:30,240
applications

00:34:26,879 --> 00:34:32,320
tracking using the kubernetes crd

00:34:30,240 --> 00:34:35,119
again focused on the on the kubernetes

00:34:32,320 --> 00:34:39,280
side at the moment and

00:34:35,119 --> 00:34:42,560
we want to improve the web ui

00:34:39,280 --> 00:34:45,440
and rest api so that

00:34:42,560 --> 00:34:47,119
we can integrate or we can be managed

00:34:45,440 --> 00:34:50,079
using

00:34:47,119 --> 00:34:51,520
their own tools and then provide

00:34:50,079 --> 00:34:54,800
automated

00:34:51,520 --> 00:34:59,200
information statistics

00:34:54,800 --> 00:34:59,200
or configuration changes

00:35:00,480 --> 00:35:04,720
in the future the mid-term um community

00:35:04,000 --> 00:35:07,520
driven

00:35:04,720 --> 00:35:08,240
um and this is also looking forward

00:35:07,520 --> 00:35:12,000
towards

00:35:08,240 --> 00:35:15,040
um a 1.0 release um but

00:35:12,000 --> 00:35:18,640
there is the push from kubernetes to

00:35:15,040 --> 00:35:20,880
support later versions but again

00:35:18,640 --> 00:35:21,839
that requires us to maybe make some

00:35:20,880 --> 00:35:24,320
changes in our

00:35:21,839 --> 00:35:25,040
api use so that's uh things that we're

00:35:24,320 --> 00:35:29,119
looking at

00:35:25,040 --> 00:35:31,440
for a little bit of a longer term

00:35:29,119 --> 00:35:33,520
other things that have been asked um

00:35:31,440 --> 00:35:36,400
about the preemption

00:35:33,520 --> 00:35:37,839
we do have preemption at the moment but

00:35:36,400 --> 00:35:41,440
there's a phase two

00:35:37,839 --> 00:35:44,560
uh being scheduled for that um other

00:35:41,440 --> 00:35:45,520
questions around gang scheduling better

00:35:44,560 --> 00:35:48,720
support for the

00:35:45,520 --> 00:35:52,560
for for applications and

00:35:48,720 --> 00:35:56,079
i think around spot instances to even do

00:35:52,560 --> 00:35:58,720
cluster scaling better and cheaper

00:35:56,079 --> 00:36:00,960
than what we can do at this point in

00:35:58,720 --> 00:36:00,960
time

00:36:01,200 --> 00:36:07,760
so the the real future um

00:36:04,240 --> 00:36:12,800
maybe a little bit of a longer uh

00:36:07,760 --> 00:36:13,839
work uh planning and that's in 1.0 or

00:36:12,800 --> 00:36:17,119
even later

00:36:13,839 --> 00:36:17,839
is we need to provide a compatibility

00:36:17,119 --> 00:36:21,119
guide

00:36:17,839 --> 00:36:24,640
um and make sure that we

00:36:21,119 --> 00:36:25,280
explain and and document how we can

00:36:24,640 --> 00:36:28,079
write

00:36:25,280 --> 00:36:29,040
and then how you can support multiple

00:36:28,079 --> 00:36:33,599
sims

00:36:29,040 --> 00:36:36,079
and and what what can run against what

00:36:33,599 --> 00:36:36,720
for that we need to simplify build and

00:36:36,079 --> 00:36:40,079
deploy

00:36:36,720 --> 00:36:43,839
instructions um but

00:36:40,079 --> 00:36:46,960
all that come comes later on um

00:36:43,839 --> 00:36:49,040
when we put more

00:36:46,960 --> 00:36:50,160
thought and and more work into

00:36:49,040 --> 00:36:53,200
multi-shim

00:36:50,160 --> 00:36:56,720
uh deployments and then improvements

00:36:53,200 --> 00:37:00,320
um and we still have uh the

00:36:56,720 --> 00:37:03,040
the additional shim around the yarn also

00:37:00,320 --> 00:37:04,079
in the pipeline but that's like we had

00:37:03,040 --> 00:37:09,040
further away

00:37:04,079 --> 00:37:11,599
in the in in the future

00:37:09,040 --> 00:37:13,280
okay and that's it for the the

00:37:11,599 --> 00:37:16,640
presentation at this point

00:37:13,280 --> 00:37:21,040
um if there's food any questions

00:37:16,640 --> 00:37:21,040
hit us up on the uh on the channel

00:37:21,200 --> 00:37:24,160
and um

00:37:25,040 --> 00:37:32,480
if there's no further questions for us

00:37:28,240 --> 00:37:34,400
now and it's quarter past

00:37:32,480 --> 00:37:35,520
says maybe let's wait for a few minutes

00:37:34,400 --> 00:37:37,760
and

00:37:35,520 --> 00:37:39,040
because um type the question will take

00:37:37,760 --> 00:37:41,280
some time

00:37:39,040 --> 00:37:42,800
so let's wait for maybe two minutes

00:37:41,280 --> 00:37:51,040
we'll have two minutes left

00:37:42,800 --> 00:37:53,200
and yeah

00:37:51,040 --> 00:37:54,400
yeah so send suggesting and releasing

00:37:53,200 --> 00:37:59,680
for your support

00:37:54,400 --> 00:38:02,400
of our project thank you

00:37:59,680 --> 00:38:04,480
and and justin is a female australian

00:38:02,400 --> 00:38:18,960
yes it is really early

00:38:04,480 --> 00:38:20,640
for all of us around here

00:38:18,960 --> 00:38:22,160
okay so it seems there's no more

00:38:20,640 --> 00:38:24,720
questions

00:38:22,160 --> 00:38:25,200
so if you have any questions feel free

00:38:24,720 --> 00:38:28,240
to

00:38:25,200 --> 00:38:31,280
drop our email to our dev list

00:38:28,240 --> 00:38:34,640
and or find us in the

00:38:31,280 --> 00:38:36,560
uh in a slight channel or

00:38:34,640 --> 00:38:38,240
yeah so so i think we are pretty easy to

00:38:36,560 --> 00:38:41,440
find and

00:38:38,240 --> 00:38:45,920
please try unicorn and

00:38:41,440 --> 00:38:48,079
let us know if you have any feedbacks

00:38:45,920 --> 00:39:01,839
thank you

00:38:48,079 --> 00:39:01,839
thank you

00:39:10,720 --> 00:39:12,800

YouTube URL: https://www.youtube.com/watch?v=dffRG9U4oBU


