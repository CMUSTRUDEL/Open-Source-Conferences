Title: Building efficient and reliable data lakes with Apache Iceberg
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Big Data (Track 1)
Description: 
	Building efficient and reliable data lakes with Apache Iceberg
Anton Okolnychyi, Vishwanath Lakkundi

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Apache Iceberg is a table format that allows data engineers and data scientists to build reliable and efficient data lakes with features that are normally present only in data warehouses. This talk will be a deep dive into key design principles of Apache Iceberg that enable the following features on top of data lakes: - ACID compliance on top of any object store or distributed file system - Flexible indexing capabilities which boost the performance of highly selective queries - Implicit partitioning using partition transforms - Reliable schema evolution - Time travel and rollback These advanced features let companies substantially simplify their current architectures as well as enable new use cases on top of data lakes.

Anton is a committer and PMC member of Apache Iceberg as well as an Apache Spark contributor at Apple. At Apple, he is working on making data lakes efficient and reliable. Prior to joining Apple, he optimized and extended a proprietary Spark distribution at SAP. Anton holds a Masterâ€™s degree in Computer Science from RWTH Aachen University.
Vishwanath Lakkundi is the engineering lead for the team that focuses on Data Orchestration and Data Lake at Apple. This team is responsible for development of an elastic fully managed Apache Spark as a service, a Data Lake engine based on Apache Iceberg and a data pipelines product based on Apache Airflow. He has been working with Apple since the last seven years focusing on various analytics infrastructure and platform products.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,080 --> 00:00:28,320
all right

00:00:24,720 --> 00:00:33,199
um thanks a lot for joining everybody uh

00:00:28,320 --> 00:00:33,199
let me play this uh

00:00:34,800 --> 00:00:39,360
so uh we're going to be talking about uh

00:00:37,760 --> 00:00:40,879
building efficient and reliable data

00:00:39,360 --> 00:00:43,920
lakes using iceberg

00:00:40,879 --> 00:00:46,000
um a little bit about us hey there my

00:00:43,920 --> 00:00:47,840
name is anton i'm part of hubble cloud

00:00:46,000 --> 00:00:49,280
services and my recent focus is on

00:00:47,840 --> 00:00:52,480
building

00:00:49,280 --> 00:00:56,079
data lakes i'm pmc for apache iceberg

00:00:52,480 --> 00:00:56,079
and apache spark contributor

00:00:57,600 --> 00:01:02,800
thank you uh my name is vishwa i manage

00:01:00,800 --> 00:01:04,879
i'm the engineering manager and lead

00:01:02,800 --> 00:01:06,240
here i manage data orchestration and

00:01:04,879 --> 00:01:09,360
data link

00:01:06,240 --> 00:01:10,720
um in in apple cloud services we are

00:01:09,360 --> 00:01:12,479
part of the data orchestration and data

00:01:10,720 --> 00:01:16,320
lake team here

00:01:12,479 --> 00:01:19,119
as part of a data platform organization

00:01:16,320 --> 00:01:19,840
uh we primarily focus on apache spark

00:01:19,119 --> 00:01:23,040
iceberg

00:01:19,840 --> 00:01:25,759
and airflow uh so that's kind of uh

00:01:23,040 --> 00:01:26,720
that's about us agenda we're going to be

00:01:25,759 --> 00:01:28,799
talking a bit about

00:01:26,720 --> 00:01:30,720
data infrastructure at apple what we've

00:01:28,799 --> 00:01:31,680
been doing uh our efforts towards

00:01:30,720 --> 00:01:33,600
modernization

00:01:31,680 --> 00:01:35,119
of data infrastructure at apple um the

00:01:33,600 --> 00:01:37,439
current status

00:01:35,119 --> 00:01:38,159
uh we did have a chat we did have

00:01:37,439 --> 00:01:41,200
another thought

00:01:38,159 --> 00:01:42,159
just before this at 9 15 where we talked

00:01:41,200 --> 00:01:44,479
about

00:01:42,159 --> 00:01:45,920
um what are the absurds and updates

00:01:44,479 --> 00:01:47,840
related use cases

00:01:45,920 --> 00:01:49,680
uh and the current status of spark and

00:01:47,840 --> 00:01:51,680
iceberg at apple so i won't go

00:01:49,680 --> 00:01:53,119
into that again here but a little bit of

00:01:51,680 --> 00:01:55,439
history and the current status of

00:01:53,119 --> 00:01:57,759
overall data platform

00:01:55,439 --> 00:01:59,119
anton would talk about uh why apache

00:01:57,759 --> 00:02:01,840
iceberg what next

00:01:59,119 --> 00:02:03,520
and and and some key takeaways after

00:02:01,840 --> 00:02:06,960
that

00:02:03,520 --> 00:02:06,960
data infrastructure at apple

00:02:07,040 --> 00:02:13,120
not surprisingly has been built

00:02:10,239 --> 00:02:14,800
on on has been traditionally built on

00:02:13,120 --> 00:02:17,360
hadoop ecosystem for

00:02:14,800 --> 00:02:18,160
a very long time for last earlier we

00:02:17,360 --> 00:02:20,239
have

00:02:18,160 --> 00:02:22,640
modernized the infrastructure here and

00:02:20,239 --> 00:02:24,080
we provide spark as a service iceberg as

00:02:22,640 --> 00:02:25,360
a service and so on i'll come to that

00:02:24,080 --> 00:02:28,480
part of things

00:02:25,360 --> 00:02:30,000
but uh historically a lot of data

00:02:28,480 --> 00:02:32,000
engineering and data science has

00:02:30,000 --> 00:02:34,080
happened on hadoop ecosystem

00:02:32,000 --> 00:02:36,480
we have multiple exabytes of data stored

00:02:34,080 --> 00:02:39,040
on hadoop and hdfs today

00:02:36,480 --> 00:02:41,120
and from a compute perspective we have a

00:02:39,040 --> 00:02:41,840
few million cores worth of compute that

00:02:41,120 --> 00:02:44,879
happens

00:02:41,840 --> 00:02:47,040
on top on top of hadoop

00:02:44,879 --> 00:02:48,480
has been happening for uh for a very

00:02:47,040 --> 00:02:51,760
long time

00:02:48,480 --> 00:02:54,800
um typically how it worked out is

00:02:51,760 --> 00:02:55,280
you you have a team you have a new use

00:02:54,800 --> 00:02:57,120
case

00:02:55,280 --> 00:02:58,959
apple is launching a new product there's

00:02:57,120 --> 00:03:02,400
going to be new data that's going to be

00:02:58,959 --> 00:03:03,760
coming in so team gets a hadoop cluster

00:03:02,400 --> 00:03:05,519
as you can see here this is an example

00:03:03,760 --> 00:03:07,920
hadoop cluster which about with about

00:03:05,519 --> 00:03:10,959
120 petabytes of data here

00:03:07,920 --> 00:03:13,040
um over the period of time you figure

00:03:10,959 --> 00:03:13,680
out that this particular hadoop cluster

00:03:13,040 --> 00:03:15,760
is

00:03:13,680 --> 00:03:16,879
extremely high on compute there is no

00:03:15,760 --> 00:03:19,680
compute resource left

00:03:16,879 --> 00:03:20,720
but very low on storage this is a

00:03:19,680 --> 00:03:22,560
pattern that we see

00:03:20,720 --> 00:03:24,480
over and over again for last several

00:03:22,560 --> 00:03:25,200
years as we have provided spark as a

00:03:24,480 --> 00:03:27,840
service

00:03:25,200 --> 00:03:29,040
on a compute substrate uh one thing we

00:03:27,840 --> 00:03:31,840
have figured out is if you

00:03:29,040 --> 00:03:33,440
get a hadoop cluster the you get some

00:03:31,840 --> 00:03:35,280
amount of storage and compute

00:03:33,440 --> 00:03:37,200
but the compute that you get along

00:03:35,280 --> 00:03:40,000
hadoop cluster is never enough it's

00:03:37,200 --> 00:03:41,040
you usually uh as a term of rule need at

00:03:40,000 --> 00:03:42,799
least three times

00:03:41,040 --> 00:03:44,400
more compute than what you would get in

00:03:42,799 --> 00:03:47,920
a cluster

00:03:44,400 --> 00:03:49,360
so as you can see the it's very high on

00:03:47,920 --> 00:03:51,920
compute utilization

00:03:49,360 --> 00:03:53,439
what do you do the team would get one

00:03:51,920 --> 00:03:57,120
more hadoop cluster

00:03:53,439 --> 00:04:00,159
and you copy the data over using the cp

00:03:57,120 --> 00:04:01,200
and then you do spark jobs or or other

00:04:00,159 --> 00:04:03,040
kind of processing

00:04:01,200 --> 00:04:04,720
on on that hadoop cluster and you copy

00:04:03,040 --> 00:04:06,560
the data back

00:04:04,720 --> 00:04:08,000
over the period of time what happens is

00:04:06,560 --> 00:04:09,760
this gets full

00:04:08,000 --> 00:04:11,519
because there's a lot of data that's

00:04:09,760 --> 00:04:16,000
lying around it's not been

00:04:11,519 --> 00:04:16,000
deleted correctly it's it's

00:04:17,199 --> 00:04:20,239
only a subset of compute mode from the

00:04:18,959 --> 00:04:22,000
first cluster to here

00:04:20,239 --> 00:04:23,520
but it's extremely high on storage

00:04:22,000 --> 00:04:27,199
utilization

00:04:23,520 --> 00:04:29,120
um so obviously you get one more cluster

00:04:27,199 --> 00:04:30,560
you can of course delete it prune it

00:04:29,120 --> 00:04:32,080
there are use cases for which you need

00:04:30,560 --> 00:04:34,160
to probably store the data for long and

00:04:32,080 --> 00:04:35,759
you have stored it for a very long time

00:04:34,160 --> 00:04:37,440
so you get one more hadoop cluster as

00:04:35,759 --> 00:04:39,040
you can see the generation of hadoop

00:04:37,440 --> 00:04:41,199
clusters that we have gotten here

00:04:39,040 --> 00:04:43,120
are slightly bigger and bigger in size

00:04:41,199 --> 00:04:45,199
not extremely large but about 20

00:04:43,120 --> 00:04:48,400
petabytes bigger and bigger here

00:04:45,199 --> 00:04:49,440
so again you copy the data over from the

00:04:48,400 --> 00:04:51,120
other two clusters

00:04:49,440 --> 00:04:53,120
just so you can you can do compute on

00:04:51,120 --> 00:04:55,680
this and copy the data back

00:04:53,120 --> 00:04:56,479
so this kind of proliferation is

00:04:55,680 --> 00:04:59,759
something that

00:04:56,479 --> 00:05:03,120
we have seen for a very very long time

00:04:59,759 --> 00:05:05,680
some obvious disadvantages of this

00:05:03,120 --> 00:05:08,240
are this is extremely high operational

00:05:05,680 --> 00:05:11,520
costs because number of hadoop clusters

00:05:08,240 --> 00:05:13,199
become a lot more and more uh there's

00:05:11,520 --> 00:05:15,520
tremendous amount of wastage of

00:05:13,199 --> 00:05:16,560
resources because you either use compute

00:05:15,520 --> 00:05:19,360
or you use

00:05:16,560 --> 00:05:21,120
storage if it's a compute heavy workload

00:05:19,360 --> 00:05:22,479
if it is a compute heavy use case then

00:05:21,120 --> 00:05:23,520
there's extremely large amount of

00:05:22,479 --> 00:05:25,840
compute that's used

00:05:23,520 --> 00:05:27,360
and storage is hardly used there's

00:05:25,840 --> 00:05:30,160
duplication of data so

00:05:27,360 --> 00:05:31,280
you copy the data over and it's it's

00:05:30,160 --> 00:05:33,360
quite hard to

00:05:31,280 --> 00:05:35,840
delete the data track the data and

00:05:33,360 --> 00:05:39,680
delete it once the usage is over

00:05:35,840 --> 00:05:42,000
use cases like gdpr needs extremely

00:05:39,680 --> 00:05:43,039
high amounts of tooling and

00:05:42,000 --> 00:05:44,880
orchestration

00:05:43,039 --> 00:05:46,080
in order to find out all the data sets

00:05:44,880 --> 00:05:47,600
that have been generated

00:05:46,080 --> 00:05:49,840
slightly different data sets that have

00:05:47,600 --> 00:05:52,800
been generated over the period of time

00:05:49,840 --> 00:05:53,840
in a huge form of hadoop cluster

00:05:52,800 --> 00:05:55,919
clusters

00:05:53,840 --> 00:05:57,600
so it's also very hard to govern because

00:05:55,919 --> 00:05:58,960
every time you copy the data over to the

00:05:57,600 --> 00:06:01,199
new cluster you have to set up

00:05:58,960 --> 00:06:02,960
other authentication authorization make

00:06:01,199 --> 00:06:05,759
sure it's encrypted make sure

00:06:02,960 --> 00:06:07,440
only that part of data set is visible to

00:06:05,759 --> 00:06:09,360
only a subset of users

00:06:07,440 --> 00:06:10,960
uh subset of data scientists and not all

00:06:09,360 --> 00:06:11,680
data is visible to them so it's quite

00:06:10,960 --> 00:06:14,800
hard to

00:06:11,680 --> 00:06:17,199
govern so this is only about data

00:06:14,800 --> 00:06:18,160
engineering and data science and and

00:06:17,199 --> 00:06:20,400
this doesn't

00:06:18,160 --> 00:06:21,680
uh to some extent cover what would

00:06:20,400 --> 00:06:24,479
happen with

00:06:21,680 --> 00:06:25,600
uh ad hoc and sql use cases and and for

00:06:24,479 --> 00:06:27,520
that what you do

00:06:25,600 --> 00:06:29,120
you get a system like teradata or

00:06:27,520 --> 00:06:30,639
vertica or something like that because

00:06:29,120 --> 00:06:33,919
you need extremely

00:06:30,639 --> 00:06:34,639
fast queries back and of course you copy

00:06:33,919 --> 00:06:37,199
data from

00:06:34,639 --> 00:06:38,240
all these clusters onto a system like

00:06:37,199 --> 00:06:39,680
that and then

00:06:38,240 --> 00:06:41,280
and then that becomes a legacy

00:06:39,680 --> 00:06:43,039
monolithic

00:06:41,280 --> 00:06:45,919
monolithic system and it becomes

00:06:43,039 --> 00:06:49,199
extremely hard to manage and upgrade

00:06:45,919 --> 00:06:52,479
a system like that so overall

00:06:49,199 --> 00:06:54,880
this has been the state of um

00:06:52,479 --> 00:06:55,759
of data proliferation at apple when when

00:06:54,880 --> 00:06:59,440
we started off

00:06:55,759 --> 00:07:02,639
uh with data platform uh development

00:06:59,440 --> 00:07:04,000
and over the period of time we have made

00:07:02,639 --> 00:07:05,759
sure that we

00:07:04,000 --> 00:07:08,319
shift some of these based on few core

00:07:05,759 --> 00:07:10,720
principles basically

00:07:08,319 --> 00:07:12,400
one of the first things that we did was

00:07:10,720 --> 00:07:14,240
we made sure that

00:07:12,400 --> 00:07:15,680
this aggregation is one of the main most

00:07:14,240 --> 00:07:17,599
important principle for us

00:07:15,680 --> 00:07:19,039
which means that we would disaggregate

00:07:17,599 --> 00:07:21,440
the storage and compute

00:07:19,039 --> 00:07:22,800
having them together has some benefits

00:07:21,440 --> 00:07:25,520
like locality which

00:07:22,800 --> 00:07:26,720
becomes more and more hard as as data

00:07:25,520 --> 00:07:28,160
proliferates and

00:07:26,720 --> 00:07:30,000
the compute that you need is no longer

00:07:28,160 --> 00:07:33,360
enough on a particular cluster that

00:07:30,000 --> 00:07:35,280
becomes somewhat irrelevant so

00:07:33,360 --> 00:07:36,720
this aggregating storage and compute has

00:07:35,280 --> 00:07:39,840
multiple advantages you can

00:07:36,720 --> 00:07:42,880
expand storage separately

00:07:39,840 --> 00:07:44,800
add more and more distributed file

00:07:42,880 --> 00:07:45,599
systems there and expand compute

00:07:44,800 --> 00:07:48,000
separately

00:07:45,599 --> 00:07:49,360
so that you can add uh compute resources

00:07:48,000 --> 00:07:52,160
separately

00:07:49,360 --> 00:07:52,879
spark for all data engineering purposes

00:07:52,160 --> 00:07:56,479
uh

00:07:52,879 --> 00:07:59,520
today apple uses spark for all batch

00:07:56,479 --> 00:08:00,720
and streaming use cases and and all use

00:07:59,520 --> 00:08:03,120
cases related to

00:08:00,720 --> 00:08:04,160
data engineering so spark for all data

00:08:03,120 --> 00:08:05,840
engineering so and

00:08:04,160 --> 00:08:07,599
and the next step for us was to make

00:08:05,840 --> 00:08:08,960
sure that we resolve we solve the

00:08:07,599 --> 00:08:10,560
we solve some of the use cases that

00:08:08,960 --> 00:08:11,039
terror data vertical and systems like

00:08:10,560 --> 00:08:13,680
that

00:08:11,039 --> 00:08:15,120
support today which is to have one stop

00:08:13,680 --> 00:08:17,919
data lake engine that can

00:08:15,120 --> 00:08:18,800
that can be extremely fast and and

00:08:17,919 --> 00:08:21,919
provide

00:08:18,800 --> 00:08:23,440
um the set of uh requirements provide

00:08:21,919 --> 00:08:24,840
the solution for setup requirements that

00:08:23,440 --> 00:08:28,160
we have

00:08:24,840 --> 00:08:30,720
so just to visually look at what i said

00:08:28,160 --> 00:08:31,520
we would have storage which is either

00:08:30,720 --> 00:08:34,959
hdfs

00:08:31,520 --> 00:08:36,320
or s3 or s3 like object stores which we

00:08:34,959 --> 00:08:38,399
can expand out separately

00:08:36,320 --> 00:08:40,080
then we have a compute substrate that's

00:08:38,399 --> 00:08:43,039
built on top of kubernetes

00:08:40,080 --> 00:08:44,159
a little bit on mesos and which you run

00:08:43,039 --> 00:08:45,839
apache spark

00:08:44,159 --> 00:08:47,200
we've been modernizing from mesos

00:08:45,839 --> 00:08:48,480
infrastructure to kubernetes

00:08:47,200 --> 00:08:50,480
infrastructure as well

00:08:48,480 --> 00:08:52,720
and we have a lot of use cases that run

00:08:50,480 --> 00:08:56,160
on kubernetes infrastructure today

00:08:52,720 --> 00:08:59,440
uh spark is great but um

00:08:56,160 --> 00:08:59,920
what makes spark really smarter and also

00:08:59,440 --> 00:09:02,399
adds

00:08:59,920 --> 00:09:03,120
some of the data lake features that we

00:09:02,399 --> 00:09:06,080
want

00:09:03,120 --> 00:09:06,959
is apache iceberg so we provide spark as

00:09:06,080 --> 00:09:09,040
a service

00:09:06,959 --> 00:09:10,640
and from the perspective of aj iceberg

00:09:09,040 --> 00:09:12,240
we have a project called

00:09:10,640 --> 00:09:13,920
data tables we internally call the

00:09:12,240 --> 00:09:18,080
product called data tables

00:09:13,920 --> 00:09:21,200
and that's that provides the

00:09:18,080 --> 00:09:22,880
abstraction and data lake features

00:09:21,200 --> 00:09:24,959
the other thing that spark is not really

00:09:22,880 --> 00:09:27,920
good at is being able to

00:09:24,959 --> 00:09:28,640
share the same session or being able to

00:09:27,920 --> 00:09:30,880
run

00:09:28,640 --> 00:09:32,080
multiple queries from multiple users at

00:09:30,880 --> 00:09:35,839
the same time

00:09:32,080 --> 00:09:36,399
there are use cases where many of the

00:09:35,839 --> 00:09:39,279
teams

00:09:36,399 --> 00:09:41,680
attempt to run um one notebook or

00:09:39,279 --> 00:09:44,720
multiple notebooks using the same

00:09:41,680 --> 00:09:46,880
spark session and submit jobs or submit

00:09:44,720 --> 00:09:48,640
queries on the same spark session

00:09:46,880 --> 00:09:50,160
and spark has a very rudimentary

00:09:48,640 --> 00:09:51,120
scheduling mechanism because of which it

00:09:50,160 --> 00:09:55,279
cannot scale

00:09:51,120 --> 00:09:58,000
and what you need really here is a solid

00:09:55,279 --> 00:09:58,880
query engine and that's where we provide

00:09:58,000 --> 00:10:01,519
presto

00:09:58,880 --> 00:10:03,760
as a service as well so we have apache

00:10:01,519 --> 00:10:05,680
iceberg we have integrations with spark

00:10:03,760 --> 00:10:09,040
and presto sql internally

00:10:05,680 --> 00:10:10,800
and for multi-multi-user query support

00:10:09,040 --> 00:10:13,680
we use presto which is

00:10:10,800 --> 00:10:14,160
um which is extreme which is exclusively

00:10:13,680 --> 00:10:17,120
for

00:10:14,160 --> 00:10:18,800
queries and spark is a general purpose

00:10:17,120 --> 00:10:19,519
data processing engine where you can do

00:10:18,800 --> 00:10:22,480
injection

00:10:19,519 --> 00:10:23,519
you can do queries you can do a copy of

00:10:22,480 --> 00:10:26,079
data you can do

00:10:23,519 --> 00:10:27,200
you can generate newer data sets and and

00:10:26,079 --> 00:10:30,399
such as well

00:10:27,200 --> 00:10:32,640
on top of it we have a unified

00:10:30,399 --> 00:10:33,519
data science catalog which kind of keeps

00:10:32,640 --> 00:10:35,519
track of

00:10:33,519 --> 00:10:37,040
all the data sets that we generate it

00:10:35,519 --> 00:10:40,079
keeps track of

00:10:37,040 --> 00:10:41,040
which data set is generated from the

00:10:40,079 --> 00:10:42,880
parent data set

00:10:41,040 --> 00:10:44,560
who has access to this particular data

00:10:42,880 --> 00:10:48,399
set which columns

00:10:44,560 --> 00:10:51,519
are are which columns are

00:10:48,399 --> 00:10:52,800
encrypted which columns are accessible

00:10:51,519 --> 00:10:55,120
to a particular user group

00:10:52,800 --> 00:10:58,160
and everything related to that is is

00:10:55,120 --> 00:11:00,000
stored in unified data science catalog

00:10:58,160 --> 00:11:01,360
over that we have built user experience

00:11:00,000 --> 00:11:03,680
in the form of notebooks

00:11:01,360 --> 00:11:04,560
user interfaces we have our own user

00:11:03,680 --> 00:11:07,440
interface

00:11:04,560 --> 00:11:09,680
our users have built their own

00:11:07,440 --> 00:11:11,920
dashboards and other user interfaces

00:11:09,680 --> 00:11:12,720
using our apis that we provide on top of

00:11:11,920 --> 00:11:16,000
this

00:11:12,720 --> 00:11:18,880
so this is how our data infrastructure

00:11:16,000 --> 00:11:20,160
looks at looks at apple currently and

00:11:18,880 --> 00:11:22,320
we've been

00:11:20,160 --> 00:11:23,839
slowly migrating off of hadoop

00:11:22,320 --> 00:11:26,640
infrastructure onto

00:11:23,839 --> 00:11:28,640
this modernized data infrastructure here

00:11:26,640 --> 00:11:30,720
focusing on iceberg here so that we can

00:11:28,640 --> 00:11:34,399
talk a little bit about data leaks

00:11:30,720 --> 00:11:37,519
uh uh the primary primarily we have

00:11:34,399 --> 00:11:39,920
three main requirements like which need

00:11:37,519 --> 00:11:41,920
uh to build data like one we need

00:11:39,920 --> 00:11:44,880
extreme mass basing factories is

00:11:41,920 --> 00:11:46,640
no surprise everybody wants it um we

00:11:44,880 --> 00:11:47,279
tend to use different solutions right

00:11:46,640 --> 00:11:50,399
some

00:11:47,279 --> 00:11:52,160
we we um teradata and vertical

00:11:50,399 --> 00:11:53,920
things like that and slowly there has

00:11:52,160 --> 00:11:56,160
been a migration off of it

00:11:53,920 --> 00:11:57,120
so that there's no window lock in it's

00:11:56,160 --> 00:11:59,839
easier to

00:11:57,120 --> 00:12:01,440
uh upgrade it's it's easier to have one

00:11:59,839 --> 00:12:04,079
copy of data so that you don't have to

00:12:01,440 --> 00:12:05,120
copy data from hdfs onto systems like

00:12:04,079 --> 00:12:08,160
teradata

00:12:05,120 --> 00:12:10,160
um for for sql purposes so you have

00:12:08,160 --> 00:12:12,079
one data set that you can use through

00:12:10,160 --> 00:12:14,240
spark or through presto

00:12:12,079 --> 00:12:17,760
or you can use for data engineering data

00:12:14,240 --> 00:12:20,079
science or for sql add-on sql use cases

00:12:17,760 --> 00:12:21,040
this next one is transactional updates

00:12:20,079 --> 00:12:23,920
um

00:12:21,040 --> 00:12:25,839
one thing that is for sure is we do have

00:12:23,920 --> 00:12:28,959
we have a lot of data at apple

00:12:25,839 --> 00:12:31,040
and and most of this data a large

00:12:28,959 --> 00:12:33,360
part of this data needs to be updated as

00:12:31,040 --> 00:12:35,920
well there are use cases like

00:12:33,360 --> 00:12:37,680
uh sessionization deduplication for

00:12:35,920 --> 00:12:38,000
which we need to go back and update the

00:12:37,680 --> 00:12:42,240
data

00:12:38,000 --> 00:12:44,000
basically there are also scenarios where

00:12:42,240 --> 00:12:46,560
we need delete so we need transactional

00:12:44,000 --> 00:12:50,000
updates and deletes

00:12:46,560 --> 00:12:52,000
and when we looked at

00:12:50,000 --> 00:12:53,440
what problems we have in order to solve

00:12:52,000 --> 00:12:55,680
this there

00:12:53,440 --> 00:12:57,760
there used to be huge amount of data

00:12:55,680 --> 00:12:59,600
engineering jobs and data engineering

00:12:57,760 --> 00:13:02,000
infrastructures that were built on top

00:12:59,600 --> 00:13:04,160
in order to solve the simple problem of

00:13:02,000 --> 00:13:06,560
uh transactional updates and it didn't

00:13:04,160 --> 00:13:08,480
provide any transactionality either

00:13:06,560 --> 00:13:10,160
so transactional update is quite

00:13:08,480 --> 00:13:12,800
important for us we want to be able to

00:13:10,160 --> 00:13:15,120
read data as it gets updated

00:13:12,800 --> 00:13:16,560
and update data in multiple threads and

00:13:15,120 --> 00:13:19,680
that's something that's possible

00:13:16,560 --> 00:13:21,519
today using apache iceberg automatic

00:13:19,680 --> 00:13:24,959
compaction is quite important as well

00:13:21,519 --> 00:13:26,240
um what's if you look at hdfs or if you

00:13:24,959 --> 00:13:28,720
look at s3

00:13:26,240 --> 00:13:31,279
one of the maze most prevalent problems

00:13:28,720 --> 00:13:33,920
is problem with small files

00:13:31,279 --> 00:13:34,560
you get a lot of small files and you you

00:13:33,920 --> 00:13:36,959
try to run

00:13:34,560 --> 00:13:38,079
jobs that uh basically merge them at

00:13:36,959 --> 00:13:40,160
some point in time

00:13:38,079 --> 00:13:41,839
what we do today as part of data tables

00:13:40,160 --> 00:13:43,680
and iceberg project is

00:13:41,839 --> 00:13:45,120
we provide a service that automatically

00:13:43,680 --> 00:13:48,560
compacts the data and

00:13:45,120 --> 00:13:50,720
metadata so um

00:13:48,560 --> 00:13:51,760
users can simply choose to run it on a

00:13:50,720 --> 00:13:53,600
cadence or

00:13:51,760 --> 00:13:54,880
or run it on partitions that are just

00:13:53,600 --> 00:13:56,480
updated uh

00:13:54,880 --> 00:13:58,000
and and not touch rest of the data so

00:13:56,480 --> 00:13:58,560
these are the three main requirements

00:13:58,000 --> 00:14:00,320
that

00:13:58,560 --> 00:14:02,000
we were behind in order to build a data

00:14:00,320 --> 00:14:05,040
link for us

00:14:02,000 --> 00:14:06,160
and and we chose apache iceberg as as

00:14:05,040 --> 00:14:08,880
the software that could

00:14:06,160 --> 00:14:09,600
that could do this um the next section

00:14:08,880 --> 00:14:11,440
of this

00:14:09,600 --> 00:14:13,360
uh presentation is going to be talking

00:14:11,440 --> 00:14:14,839
about why we chose iceberg what are the

00:14:13,360 --> 00:14:17,839
features that are there

00:14:14,839 --> 00:14:17,839
how

00:14:18,240 --> 00:14:22,000
and that's something that i don't would

00:14:19,680 --> 00:14:24,560
cover uh i'll hand this over to anton

00:14:22,000 --> 00:14:24,560
now anton

00:14:25,279 --> 00:14:31,839
thanks wilfred um let me share my screen

00:14:34,160 --> 00:14:37,279
all right so in the next section i will

00:14:36,560 --> 00:14:40,160
cover

00:14:37,279 --> 00:14:41,760
um i will deep dive into iceberg

00:14:40,160 --> 00:14:44,079
features and why i think they are so

00:14:41,760 --> 00:14:45,680
essential for any modern data lake and

00:14:44,079 --> 00:14:47,440
that's the reason why we decided to

00:14:45,680 --> 00:14:48,959
adopt apache icebridge

00:14:47,440 --> 00:14:50,639
and the first point that is really

00:14:48,959 --> 00:14:53,920
important for us is that

00:14:50,639 --> 00:14:56,240
iceberg is an open table format that was

00:14:53,920 --> 00:14:58,480
meant for huge analytical data sets

00:14:56,240 --> 00:15:00,320
and it comes with a clear specification

00:14:58,480 --> 00:15:03,839
and it was designed to be integrated

00:15:00,320 --> 00:15:03,839
into different query engines

00:15:03,920 --> 00:15:07,920
the goal of a table format is to define

00:15:06,000 --> 00:15:08,720
how you should layout individual data

00:15:07,920 --> 00:15:10,720
files

00:15:08,720 --> 00:15:13,440
and bundle them up to have a concept of

00:15:10,720 --> 00:15:15,279
a table and the defacto standard table

00:15:13,440 --> 00:15:17,920
formula that's currently built in query

00:15:15,279 --> 00:15:19,120
engines like spark or presto is the hive

00:15:17,920 --> 00:15:20,880
table format

00:15:19,120 --> 00:15:22,399
it usually means there is a central

00:15:20,880 --> 00:15:23,279
matter through it that tracks a list of

00:15:22,399 --> 00:15:25,120
partitions

00:15:23,279 --> 00:15:26,720
for your table and whenever you need to

00:15:25,120 --> 00:15:28,639
know which files are inside those

00:15:26,720 --> 00:15:30,000
partitions you have to perform the list

00:15:28,639 --> 00:15:32,560
operation

00:15:30,000 --> 00:15:33,920
um this has a number of problems with

00:15:32,560 --> 00:15:36,160
respect to performance

00:15:33,920 --> 00:15:37,920
and correctness and iceberg was designed

00:15:36,160 --> 00:15:41,279
to solve those problems and bring your

00:15:37,920 --> 00:15:43,199
data lakes to the next level

00:15:41,279 --> 00:15:45,440
iceberg also was designed to fit into

00:15:43,199 --> 00:15:48,079
the existing ecosystem

00:15:45,440 --> 00:15:51,519
it has a core library and a proper api

00:15:48,079 --> 00:15:53,360
that multiple query engines can be used

00:15:51,519 --> 00:15:54,959
it supports multiple file formats you

00:15:53,360 --> 00:15:58,560
can you can use either parkia

00:15:54,959 --> 00:15:59,920
arrow or rc it came originally with

00:15:58,560 --> 00:16:02,800
support for spark

00:15:59,920 --> 00:16:04,720
presta and pig and now the community is

00:16:02,800 --> 00:16:07,040
actively working on premiere

00:16:04,720 --> 00:16:09,279
hive and flink integration so there are

00:16:07,040 --> 00:16:10,880
actually something you can try right now

00:16:09,279 --> 00:16:13,120
for proof of concepts with those

00:16:10,880 --> 00:16:13,839
frameworks and i'm really excited by

00:16:13,120 --> 00:16:17,120
that

00:16:13,839 --> 00:16:20,720
um to give a bit of history iceberg war

00:16:17,120 --> 00:16:21,279
was started by netflix um in august 2017

00:16:20,720 --> 00:16:22,959
as

00:16:21,279 --> 00:16:26,240
and from the first day it was an open

00:16:22,959 --> 00:16:28,079
source project in november 2018 it was

00:16:26,240 --> 00:16:29,839
donated to the apache software

00:16:28,079 --> 00:16:30,800
foundation where it became part of the

00:16:29,839 --> 00:16:33,440
incubator

00:16:30,800 --> 00:16:34,800
and in may 2020 we actually radiated

00:16:33,440 --> 00:16:36,880
from this

00:16:34,800 --> 00:16:38,720
from the incubator and one of the

00:16:36,880 --> 00:16:40,639
reasons for the gradation

00:16:38,720 --> 00:16:42,480
is that we have a very strong technical

00:16:40,639 --> 00:16:45,040
community um

00:16:42,480 --> 00:16:45,680
led by people from netflix apple

00:16:45,040 --> 00:16:49,040
linkedin

00:16:45,680 --> 00:16:50,320
adobe um thompson alibaba and many other

00:16:49,040 --> 00:16:52,480
companies so we have

00:16:50,320 --> 00:16:54,480
presto folks in primary folks who

00:16:52,480 --> 00:16:57,040
actually participate in the core design

00:16:54,480 --> 00:16:59,839
decisions here

00:16:57,040 --> 00:17:02,160
and um apart from that we have a lot of

00:16:59,839 --> 00:17:05,199
pmc members in hadoop

00:17:02,160 --> 00:17:08,480
spark flink we have pmc members from

00:17:05,199 --> 00:17:11,280
um uh parque avro

00:17:08,480 --> 00:17:12,799
or c and others as well so it makes it

00:17:11,280 --> 00:17:14,959
really a great place to be

00:17:12,799 --> 00:17:19,039
and the way we handle all the technical

00:17:14,959 --> 00:17:21,520
discussions is also very important

00:17:19,039 --> 00:17:22,079
another important really important point

00:17:21,520 --> 00:17:24,799
for us

00:17:22,079 --> 00:17:26,000
is that iceberg was designed to reduce

00:17:24,799 --> 00:17:28,640
the load on the

00:17:26,000 --> 00:17:29,440
object store distributed file system

00:17:28,640 --> 00:17:32,640
there is

00:17:29,440 --> 00:17:35,120
zero list operation to plan a job

00:17:32,640 --> 00:17:35,679
to commit a new table version or even to

00:17:35,120 --> 00:17:38,320
perform

00:17:35,679 --> 00:17:40,559
most of the table management operations

00:17:38,320 --> 00:17:43,520
such as expiring all snapshots

00:17:40,559 --> 00:17:44,960
and it is hard to overestimate the

00:17:43,520 --> 00:17:47,120
importance of this decision

00:17:44,960 --> 00:17:48,320
if you're running systems like s3 where

00:17:47,120 --> 00:17:51,679
you don't have

00:17:48,320 --> 00:17:54,240
consistent lists and where the listing

00:17:51,679 --> 00:17:56,080
itself can take hours on large tables

00:17:54,240 --> 00:17:58,160
or where you don't have atomic rename

00:17:56,080 --> 00:17:59,520
operation and believe me there are so

00:17:58,160 --> 00:18:01,440
many systems with the same

00:17:59,520 --> 00:18:03,919
characteristics

00:18:01,440 --> 00:18:04,720
that are out there and for us it was

00:18:03,919 --> 00:18:06,320
really

00:18:04,720 --> 00:18:08,720
important that iceberg could solve this

00:18:06,320 --> 00:18:08,720
problem

00:18:10,080 --> 00:18:13,600
because there is no requirement for a

00:18:11,919 --> 00:18:17,840
consistent list operation

00:18:13,600 --> 00:18:20,160
or atomic rename iceberg allows you to

00:18:17,840 --> 00:18:22,160
have full asset compliance on any object

00:18:20,160 --> 00:18:24,559
store distributed file system

00:18:22,160 --> 00:18:26,640
you don't need to run solutions like s3

00:18:24,559 --> 00:18:29,120
required you don't have to keep

00:18:26,640 --> 00:18:30,080
part of your math data in the consistent

00:18:29,120 --> 00:18:33,200
storage

00:18:30,080 --> 00:18:35,440
um you don't have to

00:18:33,200 --> 00:18:37,600
deal about optimizing lists in your

00:18:35,440 --> 00:18:40,000
metadata folder you don't have to reason

00:18:37,600 --> 00:18:42,240
about how to work around

00:18:40,000 --> 00:18:43,200
eventual consistency and many other

00:18:42,240 --> 00:18:46,240
problems that you would

00:18:43,200 --> 00:18:47,440
actually normally have and in addition

00:18:46,240 --> 00:18:50,720
what is really important

00:18:47,440 --> 00:18:53,600
is that um icebreak provide full

00:18:50,720 --> 00:18:56,080
provides full asset compliance uh for

00:18:53,600 --> 00:18:58,880
writes and reads from multiple clusters

00:18:56,080 --> 00:18:59,919
and from multiple query engines so this

00:18:58,880 --> 00:19:03,120
means you can have

00:18:59,919 --> 00:19:04,480
a spark notebook a presto cluster and a

00:19:03,120 --> 00:19:07,280
compaction job

00:19:04,480 --> 00:19:08,960
interacting with the same table reliably

00:19:07,280 --> 00:19:10,240
and i think this is a fundamental

00:19:08,960 --> 00:19:13,039
feature to have

00:19:10,240 --> 00:19:13,919
because right now the ecosystem is very

00:19:13,039 --> 00:19:16,799
diverse

00:19:13,919 --> 00:19:19,120
um this actually enables to you to use

00:19:16,799 --> 00:19:20,000
for example dremeo or presto for ad hoc

00:19:19,120 --> 00:19:22,000
analytics

00:19:20,000 --> 00:19:24,080
fling for data ingestion and then

00:19:22,000 --> 00:19:27,360
sparked with some heavy etl

00:19:24,080 --> 00:19:29,440
or batch processing and as

00:19:27,360 --> 00:19:30,640
you saw earlier we actually kind of

00:19:29,440 --> 00:19:34,720
leverage that

00:19:30,640 --> 00:19:38,160
principle a lot internally

00:19:34,720 --> 00:19:40,480
um icebrick relies on

00:19:38,160 --> 00:19:42,240
optimistic concurrency which means that

00:19:40,480 --> 00:19:43,919
if there are two operations that

00:19:42,240 --> 00:19:46,400
are happening right at the same time

00:19:43,919 --> 00:19:49,120
only one of them will be successful

00:19:46,400 --> 00:19:51,440
the second and second one will retry but

00:19:49,120 --> 00:19:53,280
that retry will be implicit to the user

00:19:51,440 --> 00:19:53,840
and what will be done on the metadata

00:19:53,280 --> 00:19:56,000
level

00:19:53,840 --> 00:19:57,440
and we will reuse all of the work during

00:19:56,000 --> 00:20:00,799
the first unsuccessful

00:19:57,440 --> 00:20:03,200
attempt in most cases um

00:20:00,799 --> 00:20:05,200
and if the second iceberg detects that

00:20:03,200 --> 00:20:06,799
the second commit is not in conflict it

00:20:05,200 --> 00:20:09,919
will be able to commit it

00:20:06,799 --> 00:20:10,880
successfully and the conflict detection

00:20:09,919 --> 00:20:13,120
and revolution

00:20:10,880 --> 00:20:14,720
is done on the file level which is even

00:20:13,120 --> 00:20:16,640
better than partition level

00:20:14,720 --> 00:20:18,960
so that you can modify the same

00:20:16,640 --> 00:20:21,600
partition concurrently and still commit

00:20:18,960 --> 00:20:22,880
those operations

00:20:21,600 --> 00:20:24,960
and the reason for that is because

00:20:22,880 --> 00:20:26,080
either keeps my date of every single

00:20:24,960 --> 00:20:27,840
data file

00:20:26,080 --> 00:20:29,520
and it actually contains min max

00:20:27,840 --> 00:20:32,320
statistics for every file

00:20:29,520 --> 00:20:34,960
in the in the metadata so that it can

00:20:32,320 --> 00:20:38,000
actually resolve those conflicts

00:20:34,960 --> 00:20:38,000
on the final level

00:20:38,880 --> 00:20:43,280
the next feature i want to talk about is

00:20:41,360 --> 00:20:45,120
indexing

00:20:43,280 --> 00:20:46,960
iceberg brings the well-known idea of

00:20:45,120 --> 00:20:48,080
small materialized aggregates to the

00:20:46,960 --> 00:20:50,240
next level

00:20:48,080 --> 00:20:51,360
it processed the minimize statistics for

00:20:50,240 --> 00:20:54,799
your columns

00:20:51,360 --> 00:20:55,679
per file in its own metadata and this

00:20:54,799 --> 00:20:58,799
allows us

00:20:55,679 --> 00:20:59,600
to skip files um without actually

00:20:58,799 --> 00:21:00,880
touching them

00:20:59,600 --> 00:21:03,360
and apparently this boosts the

00:21:00,880 --> 00:21:05,679
performance of highly selective queries

00:21:03,360 --> 00:21:07,360
and the index is also part of the table

00:21:05,679 --> 00:21:09,280
it's updated atomically so you don't

00:21:07,360 --> 00:21:09,600
have to run a separate system for this

00:21:09,280 --> 00:21:11,280
and

00:21:09,600 --> 00:21:14,159
make sure that they are kind of in the

00:21:11,280 --> 00:21:14,159
consistent state

00:21:14,640 --> 00:21:18,080
there's also kind of all of this allows

00:21:16,880 --> 00:21:21,039
us to

00:21:18,080 --> 00:21:23,200
execute highly selective queries even on

00:21:21,039 --> 00:21:24,080
tables with specifies of data in only

00:21:23,200 --> 00:21:27,120
five seconds

00:21:24,080 --> 00:21:28,799
overall time and even more you can

00:21:27,120 --> 00:21:30,880
downgrade your clusters and save on

00:21:28,799 --> 00:21:32,799
resources still kind of keeping the same

00:21:30,880 --> 00:21:37,919
level of performance

00:21:32,799 --> 00:21:40,159
um if you like ignore iceberg for now so

00:21:37,919 --> 00:21:41,039
if you consider traditional workload

00:21:40,159 --> 00:21:43,039
then

00:21:41,039 --> 00:21:44,960
in the worst case you do in the best

00:21:43,039 --> 00:21:46,720
case you do partition training

00:21:44,960 --> 00:21:48,559
and once you know which partitions you

00:21:46,720 --> 00:21:52,320
have to touch you need to basically

00:21:48,559 --> 00:21:54,320
touch every single data file um in that

00:21:52,320 --> 00:21:56,559
in that partition so you create a spark

00:21:54,320 --> 00:21:57,760
task the spark test in the best case

00:21:56,559 --> 00:21:59,440
will

00:21:57,760 --> 00:22:01,039
will read the footer of your parking

00:21:59,440 --> 00:22:04,960
file we'll look at the

00:22:01,039 --> 00:22:07,200
row group metadata information see the

00:22:04,960 --> 00:22:08,400
minmax statistics it will check the

00:22:07,200 --> 00:22:10,880
dictionary page

00:22:08,400 --> 00:22:12,080
and after that it will say that this

00:22:10,880 --> 00:22:14,960
file doesn't actually

00:22:12,080 --> 00:22:16,240
match uh so you will not be processing

00:22:14,960 --> 00:22:18,400
that file even now

00:22:16,240 --> 00:22:19,919
but the most important part is not to

00:22:18,400 --> 00:22:22,080
trigger that extra task

00:22:19,919 --> 00:22:24,400
and not to read that footer to basically

00:22:22,080 --> 00:22:27,280
be able to pre-filter that file

00:22:24,400 --> 00:22:28,159
and on average this has an extra penalty

00:22:27,280 --> 00:22:32,000
of one second

00:22:28,159 --> 00:22:34,640
for false positive for a false

00:22:32,000 --> 00:22:34,640
data file

00:22:36,559 --> 00:22:41,039
um iceberg also supports implicit

00:22:38,640 --> 00:22:43,120
partitioning and today data engineers

00:22:41,039 --> 00:22:44,159
they have to produce physical partition

00:22:43,120 --> 00:22:47,600
values

00:22:44,159 --> 00:22:49,440
and users must be aware of that and they

00:22:47,600 --> 00:22:52,320
must defend them to their queries in

00:22:49,440 --> 00:22:55,919
order to benefit from partition pruning

00:22:52,320 --> 00:22:57,679
and in iceberg

00:22:55,919 --> 00:22:58,960
we have a different approach so in

00:22:57,679 --> 00:23:01,200
iceberg the partitioning

00:22:58,960 --> 00:23:02,720
is the logical transformation based on

00:23:01,200 --> 00:23:04,799
your data column

00:23:02,720 --> 00:23:06,640
and whenever you have predicate on your

00:23:04,799 --> 00:23:08,000
data column you will derive the

00:23:06,640 --> 00:23:09,520
partition value for you

00:23:08,000 --> 00:23:11,360
and we will use that to prune the

00:23:09,520 --> 00:23:13,200
partitions

00:23:11,360 --> 00:23:14,880
so this decoupling from the physical

00:23:13,200 --> 00:23:16,000
representation to the logical

00:23:14,880 --> 00:23:19,039
representation

00:23:16,000 --> 00:23:20,240
actually allows iceberg to have a number

00:23:19,039 --> 00:23:22,080
of benefits

00:23:20,240 --> 00:23:24,080
some some of them for example include

00:23:22,080 --> 00:23:25,520
the ability to evolve the partitioning

00:23:24,080 --> 00:23:27,679
scheme over time

00:23:25,520 --> 00:23:29,360
so for example you may start a table and

00:23:27,679 --> 00:23:31,840
you partition by date

00:23:29,360 --> 00:23:32,480
but up to two years the size of the data

00:23:31,840 --> 00:23:35,600
grows

00:23:32,480 --> 00:23:36,880
and you actually want to consider hourly

00:23:35,600 --> 00:23:39,919
partitions as well

00:23:36,880 --> 00:23:40,720
and you can absolutely find do this in

00:23:39,919 --> 00:23:43,360
iceberg

00:23:40,720 --> 00:23:45,440
and keep the the all data unchanged so

00:23:43,360 --> 00:23:48,480
you don't have to copy this eagerly

00:23:45,440 --> 00:23:51,120
you may choose to do this but

00:23:48,480 --> 00:23:53,279
it's up to you so you can still um keep

00:23:51,120 --> 00:23:55,120
the all data with all partitioning

00:23:53,279 --> 00:23:56,640
and produce new data in the new

00:23:55,120 --> 00:23:59,919
partitioning scheme

00:23:56,640 --> 00:23:59,919
and that will work just fine

00:24:00,880 --> 00:24:05,679
um also iceberg finally solves the

00:24:03,679 --> 00:24:08,880
schema evolution problem

00:24:05,679 --> 00:24:09,440
uh it designs um every column a unique

00:24:08,880 --> 00:24:11,279
id

00:24:09,440 --> 00:24:13,039
and tracks it in the math date and

00:24:11,279 --> 00:24:16,400
different parts of it

00:24:13,039 --> 00:24:19,520
um so you no longer have limitations of

00:24:16,400 --> 00:24:23,200
tracking columns by position or by name

00:24:19,520 --> 00:24:26,559
um so you can safely add drop

00:24:23,200 --> 00:24:26,960
rename reorder columns and and do all

00:24:26,559 --> 00:24:29,520
those

00:24:26,960 --> 00:24:31,520
operations according to the spec and

00:24:29,520 --> 00:24:33,360
what is really really important is that

00:24:31,520 --> 00:24:35,600
you don't have to rewrite the data for

00:24:33,360 --> 00:24:37,760
this and there is no side effects

00:24:35,600 --> 00:24:39,520
so if you delete a column from a table

00:24:37,760 --> 00:24:40,960
and then up to here you add a column

00:24:39,520 --> 00:24:43,600
with the same name

00:24:40,960 --> 00:24:45,520
the all data will not appear again and

00:24:43,600 --> 00:24:47,840
this is again a very important point for

00:24:45,520 --> 00:24:47,840
us

00:24:49,440 --> 00:24:54,400
iceberg supports both streaming and

00:24:52,720 --> 00:24:56,799
batch use cases

00:24:54,400 --> 00:24:57,520
we have the spark structure streaming

00:24:56,799 --> 00:24:59,600
rights

00:24:57,520 --> 00:25:01,679
for more than a year right now so you

00:24:59,600 --> 00:25:03,840
can build n2m

00:25:01,679 --> 00:25:04,799
exactly once pipelines with iceberg as

00:25:03,840 --> 00:25:07,520
the same

00:25:04,799 --> 00:25:09,039
and right now we about to merge the pr

00:25:07,520 --> 00:25:10,880
for replayable source

00:25:09,039 --> 00:25:12,480
which you can use in your structure

00:25:10,880 --> 00:25:15,520
streaming pipeline as well

00:25:12,480 --> 00:25:18,720
this will allow you to build pipelines

00:25:15,520 --> 00:25:22,080
between iceberg tables and spark

00:25:18,720 --> 00:25:24,640
and they again will be exactly one's

00:25:22,080 --> 00:25:24,640
pipelines

00:25:25,520 --> 00:25:29,440
one feature that i really like as a

00:25:27,360 --> 00:25:31,840
developer is that iceberg has a very

00:25:29,440 --> 00:25:35,120
rich support for my data tables

00:25:31,840 --> 00:25:37,200
they allow you to analyze

00:25:35,120 --> 00:25:38,240
the table state to allow every detail

00:25:37,200 --> 00:25:40,240
about the table

00:25:38,240 --> 00:25:42,240
you can see the table history how it

00:25:40,240 --> 00:25:43,120
evolved over time which operations

00:25:42,240 --> 00:25:45,279
happen

00:25:43,120 --> 00:25:46,960
you can see statistics for every commit

00:25:45,279 --> 00:25:50,320
so how many records you change

00:25:46,960 --> 00:25:52,320
how many data files you added um

00:25:50,320 --> 00:25:54,240
you can actually like every time you

00:25:52,320 --> 00:25:55,520
have to debug something or every time i

00:25:54,240 --> 00:25:57,760
have to analyze what the

00:25:55,520 --> 00:26:00,240
table in its optimal state i go to the

00:25:57,760 --> 00:26:02,799
metadata tables and i can pre-compute

00:26:00,240 --> 00:26:05,520
the average size uh the average data

00:26:02,799 --> 00:26:07,520
size per partition the data distribution

00:26:05,520 --> 00:26:08,640
the number of snapshots all of that

00:26:07,520 --> 00:26:11,919
using my

00:26:08,640 --> 00:26:14,960
notebook or spark job and also we use

00:26:11,919 --> 00:26:16,559
those math data tables internally

00:26:14,960 --> 00:26:18,880
for example which partitions were

00:26:16,559 --> 00:26:21,200
modified from a given point in time

00:26:18,880 --> 00:26:22,840
and that way we can actually trigger

00:26:21,200 --> 00:26:25,840
compaction in those partitions

00:26:22,840 --> 00:26:25,840
specifically

00:26:26,559 --> 00:26:31,039
in order to truly benefit from iceberg

00:26:28,720 --> 00:26:33,520
you have to maintain your tables

00:26:31,039 --> 00:26:34,480
and therefore iceberg has connections

00:26:33,520 --> 00:26:37,120
api

00:26:34,480 --> 00:26:37,600
which for now lets you optimize metadata

00:26:37,120 --> 00:26:40,240
and

00:26:37,600 --> 00:26:42,320
do bean packing you also have utilities

00:26:40,240 --> 00:26:43,679
to explore all snapshots and remove

00:26:42,320 --> 00:26:45,520
orphan files

00:26:43,679 --> 00:26:46,960
and we are in the process of building

00:26:45,520 --> 00:26:50,080
sql commands as well

00:26:46,960 --> 00:26:52,960
that will let you execute those actions

00:26:50,080 --> 00:26:55,919
through a sql api which is very useful

00:26:52,960 --> 00:26:57,760
for data engineers as well

00:26:55,919 --> 00:26:59,760
there is a design doc by the way on that

00:26:57,760 --> 00:27:03,440
so just feel free to check the

00:26:59,760 --> 00:27:05,039
community of things um another really

00:27:03,440 --> 00:27:06,559
important point for adoption is the

00:27:05,039 --> 00:27:09,440
migration story

00:27:06,559 --> 00:27:11,440
so it's not okay to just copy over the

00:27:09,440 --> 00:27:14,000
the exabytes of data into something

00:27:11,440 --> 00:27:16,400
something different uh we definitely

00:27:14,000 --> 00:27:19,520
wanted to support migration of existing

00:27:16,400 --> 00:27:21,200
datasets in place and iceberg already

00:27:19,520 --> 00:27:23,760
has utilities for this

00:27:21,200 --> 00:27:24,640
but you have to use a java or scala code

00:27:23,760 --> 00:27:27,200
for that

00:27:24,640 --> 00:27:28,559
um internally we have snapshot and

00:27:27,200 --> 00:27:30,640
migrate commands

00:27:28,559 --> 00:27:32,320
and we are also delivering and

00:27:30,640 --> 00:27:34,640
contributing that to the uh

00:27:32,320 --> 00:27:36,559
upstream in the near future as well

00:27:34,640 --> 00:27:39,360
snapshot allows you to

00:27:36,559 --> 00:27:40,880
create a snapshot of an existing spark

00:27:39,360 --> 00:27:45,200
or hive table

00:27:40,880 --> 00:27:47,279
and create an iceberg table for testing

00:27:45,200 --> 00:27:49,120
so the iceberg table will be created in

00:27:47,279 --> 00:27:51,679
a totally different location

00:27:49,120 --> 00:27:52,640
and you can actually write to that table

00:27:51,679 --> 00:27:55,039
in iceberg

00:27:52,640 --> 00:27:57,200
but the results will not be visible in

00:27:55,039 --> 00:27:57,679
your original table so it gives you a

00:27:57,200 --> 00:28:01,120
safe

00:27:57,679 --> 00:28:03,039
playground to play um with the existing

00:28:01,120 --> 00:28:05,200
data set and once you're done with the

00:28:03,039 --> 00:28:07,200
testing you can actually call my grade

00:28:05,200 --> 00:28:09,919
and this wall this will migrate your

00:28:07,200 --> 00:28:10,480
existing table in place without any etl

00:28:09,919 --> 00:28:12,240
jobs and

00:28:10,480 --> 00:28:14,159
up to that point you can actually

00:28:12,240 --> 00:28:17,840
continue your pipelines but now you have

00:28:14,159 --> 00:28:17,840
to write to iceberg

00:28:18,159 --> 00:28:22,080
so i want to also touch upon some of the

00:28:20,559 --> 00:28:23,520
exciting features that we are working

00:28:22,080 --> 00:28:26,080
right now

00:28:23,520 --> 00:28:27,919
um there is a lot of progress on raw

00:28:26,080 --> 00:28:29,840
level updates and delete so we had a

00:28:27,919 --> 00:28:31,760
separate session early today

00:28:29,840 --> 00:28:34,080
so i definitely encourage you to check

00:28:31,760 --> 00:28:34,880
that out if you missed it there will be

00:28:34,080 --> 00:28:38,159
recording

00:28:34,880 --> 00:28:40,159
and by the quick summary that um

00:28:38,159 --> 00:28:41,840
iceberg will support multiple ways to

00:28:40,159 --> 00:28:43,760
perform updates and deletes

00:28:41,840 --> 00:28:45,679
and this will allow you to cover all

00:28:43,760 --> 00:28:47,919
analytical use cases

00:28:45,679 --> 00:28:49,600
uh we will support copy and write for

00:28:47,919 --> 00:28:52,880
bulk updates and we will support

00:28:49,600 --> 00:28:54,640
margin read um for right heavy use cases

00:28:52,880 --> 00:28:57,120
and merging rate can be either

00:28:54,640 --> 00:29:00,000
positional or equality

00:28:57,120 --> 00:29:01,840
you the the the best flexibility uh you

00:29:00,000 --> 00:29:04,000
can actually have

00:29:01,840 --> 00:29:05,760
and copy and write you've been running

00:29:04,000 --> 00:29:08,320
this internally for a year

00:29:05,760 --> 00:29:10,640
uh merge and read is stolen in progress

00:29:08,320 --> 00:29:13,440
so we've completed most of the

00:29:10,640 --> 00:29:15,200
uh most of the work uh in terms of the

00:29:13,440 --> 00:29:17,200
table format

00:29:15,200 --> 00:29:18,880
what is missing is the part logic spark

00:29:17,200 --> 00:29:21,039
logic and uh

00:29:18,880 --> 00:29:22,080
minor and major compaction so that

00:29:21,039 --> 00:29:26,240
should be available

00:29:22,080 --> 00:29:28,880
till the end of the year

00:29:26,240 --> 00:29:30,159
um also we are working on enhanced data

00:29:28,880 --> 00:29:32,480
compaction in iceberg

00:29:30,159 --> 00:29:34,399
so internally we have different ways to

00:29:32,480 --> 00:29:37,360
apply data compaction

00:29:34,399 --> 00:29:38,640
um the most straightforward way is just

00:29:37,360 --> 00:29:40,720
to perform bean pack

00:29:38,640 --> 00:29:41,919
where you take small files and you write

00:29:40,720 --> 00:29:44,000
bigger files

00:29:41,919 --> 00:29:46,080
but the problem that it doesn't really

00:29:44,000 --> 00:29:46,880
help to restore the distribution of the

00:29:46,080 --> 00:29:50,000
data

00:29:46,880 --> 00:29:54,240
and it doesn't help the min max index in

00:29:50,000 --> 00:29:56,480
iceberg so we have one more option is to

00:29:54,240 --> 00:29:58,000
globally shuffle the records within the

00:29:56,480 --> 00:29:59,760
files you been packed

00:29:58,000 --> 00:30:01,440
that way you kind of slightly restore

00:29:59,760 --> 00:30:03,039
the distribution of the data and then

00:30:01,440 --> 00:30:04,080
you can pre-filter the data more

00:30:03,039 --> 00:30:06,480
efficiently

00:30:04,080 --> 00:30:07,679
which means that your queries will be

00:30:06,480 --> 00:30:09,600
faster

00:30:07,679 --> 00:30:11,039
and then at some points even if you've

00:30:09,600 --> 00:30:13,840
been take a lot of files

00:30:11,039 --> 00:30:17,039
with optional sorting the overall

00:30:13,840 --> 00:30:17,039
distribution of data

00:30:17,200 --> 00:30:21,279
within the partition may not be optimal

00:30:19,200 --> 00:30:22,399
so we also have ways to fully restore

00:30:21,279 --> 00:30:24,320
partitions

00:30:22,399 --> 00:30:25,919
and this gives you kind of a very

00:30:24,320 --> 00:30:28,159
flexible way to address the data

00:30:25,919 --> 00:30:31,360
compaction problem and what is really

00:30:28,159 --> 00:30:34,320
important is that data compaction is

00:30:31,360 --> 00:30:36,480
okay still acid compliant and you can

00:30:34,320 --> 00:30:39,120
run this in the background and

00:30:36,480 --> 00:30:40,880
you don't need to stop your ingestion

00:30:39,120 --> 00:30:43,200
pipelines and and so on

00:30:40,880 --> 00:30:44,159
and we're actually contributing this to

00:30:43,200 --> 00:30:46,480
iceberg as well

00:30:44,159 --> 00:30:48,840
there is a design block so i expect that

00:30:46,480 --> 00:30:51,279
to be available in the nearest future as

00:30:48,840 --> 00:30:53,760
well

00:30:51,279 --> 00:30:54,399
also there are talks about secondary

00:30:53,760 --> 00:30:56,480
indexing

00:30:54,399 --> 00:30:58,640
in iceberg and we wanted to have a

00:30:56,480 --> 00:31:00,080
proper way to build arbitrary secondary

00:30:58,640 --> 00:31:02,240
indexes

00:31:00,080 --> 00:31:04,080
to speed up the execution even more and

00:31:02,240 --> 00:31:05,679
one of such ideas is to have a bloom

00:31:04,080 --> 00:31:07,679
filter profile

00:31:05,679 --> 00:31:09,600
and the important part that you will be

00:31:07,679 --> 00:31:10,960
able to load that bloom filter from the

00:31:09,600 --> 00:31:14,080
metadata

00:31:10,960 --> 00:31:16,320
um and on demand apparently

00:31:14,080 --> 00:31:17,200
and then use it for filtering the data

00:31:16,320 --> 00:31:20,320
without actually

00:31:17,200 --> 00:31:20,320
touching data files

00:31:21,200 --> 00:31:25,440
so with that i would like to finish with

00:31:23,200 --> 00:31:28,559
key takeaways and i'll probably hand

00:31:25,440 --> 00:31:28,559
this over to this one

00:31:31,440 --> 00:31:38,559
before we can hear it sorry

00:31:34,799 --> 00:31:41,039
thanks and on uh i think as a summary um

00:31:38,559 --> 00:31:42,240
successful disaggregation uh needs

00:31:41,039 --> 00:31:44,640
efficient and reliable

00:31:42,240 --> 00:31:46,080
data lakes here um there are a few

00:31:44,640 --> 00:31:48,559
questions that have come about

00:31:46,080 --> 00:31:50,320
uh this aggregation i'll address it when

00:31:48,559 --> 00:31:52,960
we start about questions

00:31:50,320 --> 00:31:54,159
um iceberg enables data lakes with open

00:31:52,960 --> 00:31:55,679
data architecture

00:31:54,159 --> 00:31:57,840
the most important thing here is to make

00:31:55,679 --> 00:32:00,080
sure that we are not window logged in

00:31:57,840 --> 00:32:02,000
uh it uses open data formats like power

00:32:00,080 --> 00:32:03,600
k orc and avro

00:32:02,000 --> 00:32:05,679
it's an open data architecture it's all

00:32:03,600 --> 00:32:07,200
completely open source that people can

00:32:05,679 --> 00:32:09,200
contribute towards

00:32:07,200 --> 00:32:10,399
uh finally fast queries asset

00:32:09,200 --> 00:32:13,600
transaction and

00:32:10,399 --> 00:32:16,240
reliable absurds is what makes it

00:32:13,600 --> 00:32:16,880
really invincible actually so we we went

00:32:16,240 --> 00:32:19,519
with

00:32:16,880 --> 00:32:21,840
three uh main core principles on which

00:32:19,519 --> 00:32:26,000
we are trying to build the data platform

00:32:21,840 --> 00:32:26,000
and all these three things are are

00:32:26,159 --> 00:32:32,960
met by apache iceberg here um

00:32:30,000 --> 00:32:32,960
next slide hand on

00:32:37,039 --> 00:32:40,159
we're also hiring so please check out

00:32:39,039 --> 00:32:41,679
our uh english

00:32:40,159 --> 00:32:43,679
operating opportunities and full-time

00:32:41,679 --> 00:32:46,159
opportunities here we have a slack

00:32:43,679 --> 00:32:47,679
channel as well we'll be in boots to

00:32:46,159 --> 00:32:48,320
answer some of the additional questions

00:32:47,679 --> 00:32:50,080
too

00:32:48,320 --> 00:32:52,159
i think we have a couple of minutes let

00:32:50,080 --> 00:32:52,880
me um take few of the questions here and

00:32:52,159 --> 00:32:56,399
then

00:32:52,880 --> 00:32:58,320
we can um we can end once that's done

00:32:56,399 --> 00:32:59,519
i think the first question here is what

00:32:58,320 --> 00:33:02,559
made you chose

00:32:59,519 --> 00:33:04,799
apache iceberg or delta uh uh

00:33:02,559 --> 00:33:06,240
to begin with there are a lot of reasons

00:33:04,799 --> 00:33:07,840
that we have had

00:33:06,240 --> 00:33:09,600
documentations which which kind of

00:33:07,840 --> 00:33:10,559
compare both these products to begin

00:33:09,600 --> 00:33:13,360
with iceberg

00:33:10,559 --> 00:33:13,919
iceberg slightly predates delta the

00:33:13,360 --> 00:33:15,519
second

00:33:13,919 --> 00:33:17,760
most important aspect at least from my

00:33:15,519 --> 00:33:21,679
perspective is

00:33:17,760 --> 00:33:25,679
delta lake is a part of data bricks

00:33:21,679 --> 00:33:29,039
enterprise edition of spark and

00:33:25,679 --> 00:33:30,480
and and that kind of uh means that

00:33:29,039 --> 00:33:32,399
there won't there are certain features

00:33:30,480 --> 00:33:34,080
that will never be open source

00:33:32,399 --> 00:33:35,760
it may be related to z ordering and some

00:33:34,080 --> 00:33:36,960
of the other features that delta today

00:33:35,760 --> 00:33:39,120
provides

00:33:36,960 --> 00:33:41,200
uh and rightly so because that's how

00:33:39,120 --> 00:33:43,200
data breaks is able to provide an

00:33:41,200 --> 00:33:45,279
enterprise edition which people can buy

00:33:43,200 --> 00:33:46,399
basically so some of these optimizations

00:33:45,279 --> 00:33:48,159
that databricks has

00:33:46,399 --> 00:33:49,519
internally would never be available to

00:33:48,159 --> 00:33:51,360
everybody else

00:33:49,519 --> 00:33:53,360
it's a different model with iceberg

00:33:51,360 --> 00:33:54,880
everything that's that we have today we

00:33:53,360 --> 00:33:57,200
would be first contributing out to

00:33:54,880 --> 00:34:00,080
iceberg it's it's open to everybody

00:33:57,200 --> 00:34:01,600
and um the features like uh

00:34:00,080 --> 00:34:05,039
multi-dimensional clustering

00:34:01,600 --> 00:34:07,039
zrdrink uh and and few others are

00:34:05,039 --> 00:34:09,599
to be available for everybody in iceberg

00:34:07,039 --> 00:34:12,879
so that way it's more open source

00:34:09,599 --> 00:34:14,399
than databricks delta lake so why we

00:34:12,879 --> 00:34:20,399
chose apache iceberg

00:34:14,399 --> 00:34:22,639
it's it's an open data architecture and

00:34:20,399 --> 00:34:23,919
open source for all the features that we

00:34:22,639 --> 00:34:25,280
are currently building

00:34:23,919 --> 00:34:27,200
there are some minor other differences

00:34:25,280 --> 00:34:28,480
like uh delta today doesn't support

00:34:27,200 --> 00:34:30,240
merge on reads

00:34:28,480 --> 00:34:32,839
um we are adding support for merge on

00:34:30,240 --> 00:34:35,679
reads it's only copy and writes

00:34:32,839 --> 00:34:37,760
um that delta supports today

00:34:35,679 --> 00:34:38,960
uh the next question is about hoodie uh

00:34:37,760 --> 00:34:39,280
anton do you want to take the question

00:34:38,960 --> 00:34:41,200
on

00:34:39,280 --> 00:34:42,480
on the differences between apache

00:34:41,200 --> 00:34:44,960
iceberg and hoodie

00:34:42,480 --> 00:34:47,359
right so uh even to add to the delta

00:34:44,960 --> 00:34:49,119
discussion so apart from those of

00:34:47,359 --> 00:34:50,720
like models that which were described

00:34:49,119 --> 00:34:52,720
there are also other technical reasons

00:34:50,720 --> 00:34:54,399
so if you go back to the presentation

00:34:52,720 --> 00:34:56,399
and you want to compare

00:34:54,399 --> 00:34:57,760
whether you can get the same features in

00:34:56,399 --> 00:35:00,800
in other projects that would

00:34:57,760 --> 00:35:02,079
probably be a good uh it will give you a

00:35:00,800 --> 00:35:03,760
good idea about what's

00:35:02,079 --> 00:35:05,359
supported what's not supported so i

00:35:03,760 --> 00:35:07,119
would really encourage you to check out

00:35:05,359 --> 00:35:09,520
each project individually

00:35:07,119 --> 00:35:11,599
compare their design uh see what you can

00:35:09,520 --> 00:35:13,599
do and what's the potential of that

00:35:11,599 --> 00:35:15,599
what's happening there with respect to

00:35:13,599 --> 00:35:17,599
hoodie um i think there are a couple of

00:35:15,599 --> 00:35:20,000
uh problems with hoodie i think not all

00:35:17,599 --> 00:35:22,320
the operations are asset compliant

00:35:20,000 --> 00:35:23,839
and also if you take a look at the merge

00:35:22,320 --> 00:35:25,440
and read implementation

00:35:23,839 --> 00:35:27,359
it is limited to observes by a

00:35:25,440 --> 00:35:30,079
predefined key so you have to know the

00:35:27,359 --> 00:35:32,320
key you are beating by

00:35:30,079 --> 00:35:33,359
in basically at the time of the creation

00:35:32,320 --> 00:35:35,440
of the table

00:35:33,359 --> 00:35:37,359
which is not that flexible and we have a

00:35:35,440 --> 00:35:39,520
separate talk where we describe what are

00:35:37,359 --> 00:35:41,440
the requirements we have for absurds

00:35:39,520 --> 00:35:43,200
and what is the plan to do this in

00:35:41,440 --> 00:35:44,800
iceberg and that kind of

00:35:43,200 --> 00:35:48,079
kind of completes that picture with

00:35:44,800 --> 00:35:48,079
respect to the comparison

00:35:49,680 --> 00:35:53,839
cool i think the next question we have

00:35:52,079 --> 00:35:56,560
is about disaggregation

00:35:53,839 --> 00:35:58,320
what about data locality and its

00:35:56,560 --> 00:36:01,280
potential performance cost and

00:35:58,320 --> 00:36:02,160
uh network costs um i think we have

00:36:01,280 --> 00:36:04,000
addressed this

00:36:02,160 --> 00:36:05,599
uh as part of several talks that we have

00:36:04,000 --> 00:36:08,160
done before

00:36:05,599 --> 00:36:10,560
um we started our journey to provide

00:36:08,160 --> 00:36:14,079
data platform back in 2017.

00:36:10,560 --> 00:36:15,920
uh it became it went live in 2018

00:36:14,079 --> 00:36:17,920
um one of the first things that we did

00:36:15,920 --> 00:36:20,320
at apple was to see

00:36:17,920 --> 00:36:21,839
uh how people are doing analytics how is

00:36:20,320 --> 00:36:23,520
the data engineering being done

00:36:21,839 --> 00:36:26,240
what's the layout of data what data

00:36:23,520 --> 00:36:28,079
formats are are being used uh

00:36:26,240 --> 00:36:30,000
and one thing that became very evident

00:36:28,079 --> 00:36:32,320
was that um

00:36:30,000 --> 00:36:33,359
we we had these huge clusters with about

00:36:32,320 --> 00:36:36,560
1500 to

00:36:33,359 --> 00:36:39,119
2000 node clusters um

00:36:36,560 --> 00:36:40,160
the compute that the placement of

00:36:39,119 --> 00:36:42,480
compute is not

00:36:40,160 --> 00:36:43,839
often on the same data nodes that where

00:36:42,480 --> 00:36:46,320
the data exists

00:36:43,839 --> 00:36:47,280
so locality was somewhat of a myth

00:36:46,320 --> 00:36:49,599
because

00:36:47,280 --> 00:36:51,760
you the network layout simply meant that

00:36:49,599 --> 00:36:53,280
you would go up to 7k switches and then

00:36:51,760 --> 00:36:54,320
back to the compute nodes where the

00:36:53,280 --> 00:36:57,920
compute was

00:36:54,320 --> 00:36:59,680
actually running so as so the

00:36:57,920 --> 00:37:01,839
first thing that you notice in large

00:36:59,680 --> 00:37:05,040
organizations is if there is

00:37:01,839 --> 00:37:05,920
x amount of data the data that you have

00:37:05,040 --> 00:37:09,119
stored on

00:37:05,920 --> 00:37:10,000
on hadoop clusters the compute needs is

00:37:09,119 --> 00:37:12,320
usually

00:37:10,000 --> 00:37:14,560
3x amount of what is available along

00:37:12,320 --> 00:37:16,480
with that storage in that hadoop cluster

00:37:14,560 --> 00:37:18,160
so naturally what you do is you would

00:37:16,480 --> 00:37:20,079
run compute somewhere else or you would

00:37:18,160 --> 00:37:20,640
copy data over to somewhere else and

00:37:20,079 --> 00:37:22,320
then

00:37:20,640 --> 00:37:24,640
run compute on it so that leads to data

00:37:22,320 --> 00:37:25,440
proliferation copying of data means that

00:37:24,640 --> 00:37:27,680
you need

00:37:25,440 --> 00:37:29,760
um data engineering efforts you need

00:37:27,680 --> 00:37:32,400
jobs they could copy data back and forth

00:37:29,760 --> 00:37:34,320
you use the cp like features that makes

00:37:32,400 --> 00:37:35,280
it very very hard to do data governance

00:37:34,320 --> 00:37:38,400
basically

00:37:35,280 --> 00:37:41,040
so as the data grows the compute needs

00:37:38,400 --> 00:37:42,880
simply just explode and it's impossible

00:37:41,040 --> 00:37:44,880
to get data locality even if you're

00:37:42,880 --> 00:37:47,119
using hadoop clusters basically

00:37:44,880 --> 00:37:48,640
with respect to network cost network is

00:37:47,119 --> 00:37:50,079
becoming cheaper and cheaper and the

00:37:48,640 --> 00:37:52,480
networks that we have at apple are

00:37:50,079 --> 00:37:55,040
extremely fast and that allows us to

00:37:52,480 --> 00:37:57,119
basically copy data between these

00:37:55,040 --> 00:37:59,359
different availability zones

00:37:57,119 --> 00:38:01,200
and the last point here is we have to be

00:37:59,359 --> 00:38:03,680
smart about which data that we

00:38:01,200 --> 00:38:04,720
read and there's no smarter software

00:38:03,680 --> 00:38:06,480
than spark

00:38:04,720 --> 00:38:08,320
and apache spark and iceberg to make

00:38:06,480 --> 00:38:09,119
sure that you only touch the data that

00:38:08,320 --> 00:38:11,119
you need

00:38:09,119 --> 00:38:13,119
and don't try to read a lot of data

00:38:11,119 --> 00:38:14,560
while spark only reads

00:38:13,119 --> 00:38:17,040
the partitions and files that it

00:38:14,560 --> 00:38:19,119
actually needs iceberg

00:38:17,040 --> 00:38:20,640
completely nullifies the need for doing

00:38:19,119 --> 00:38:23,520
lists and need for

00:38:20,640 --> 00:38:25,119
having to have any additional indexes so

00:38:23,520 --> 00:38:26,960
both of these together makes it

00:38:25,119 --> 00:38:28,320
extremely possible to have this

00:38:26,960 --> 00:38:30,640
aggregated architecture

00:38:28,320 --> 00:38:32,000
it simply becomes cost prohibitive if

00:38:30,640 --> 00:38:33,599
you were to stand up a

00:38:32,000 --> 00:38:35,280
lot of hadoop clusters otherwise so

00:38:33,599 --> 00:38:38,960
that's how it can basically

00:38:35,280 --> 00:38:41,920
expand out um i think

00:38:38,960 --> 00:38:44,000
there is another question here can you

00:38:41,920 --> 00:38:45,760
expand more on implicit partitioning is

00:38:44,000 --> 00:38:47,520
there some query optimization after

00:38:45,760 --> 00:38:50,000
spark presto etc

00:38:47,520 --> 00:38:51,280
does its optimizations right so i think

00:38:50,000 --> 00:38:54,000
the the answer is

00:38:51,280 --> 00:38:54,720
to fault in this question so uh implicit

00:38:54,000 --> 00:38:57,200
partitioning

00:38:54,720 --> 00:38:58,720
is the same way to achieve partitioning

00:38:57,200 --> 00:39:01,280
printing but in a more

00:38:58,720 --> 00:39:03,280
user-friendly way so with the current

00:39:01,280 --> 00:39:05,359
way of partitioning you have to know

00:39:03,280 --> 00:39:07,200
how the table is partitioned you know

00:39:05,359 --> 00:39:09,520
the actual partition value and

00:39:07,200 --> 00:39:11,839
even in all you clearly actually have to

00:39:09,520 --> 00:39:14,000
append the predicate and that partition

00:39:11,839 --> 00:39:15,920
column in many cases that is an

00:39:14,000 --> 00:39:18,240
artificially produced value

00:39:15,920 --> 00:39:20,000
right and some someone who created the

00:39:18,240 --> 00:39:21,839
table he thought about how the table

00:39:20,000 --> 00:39:22,800
must be partitioned and then produces an

00:39:21,839 --> 00:39:24,720
extra column

00:39:22,800 --> 00:39:26,000
which represents your partition value

00:39:24,720 --> 00:39:29,280
and it somehow

00:39:26,000 --> 00:39:31,280
derives from one of the data columns in

00:39:29,280 --> 00:39:32,400
uh in iceberg it's swinging on the

00:39:31,280 --> 00:39:35,040
difference so iceberg

00:39:32,400 --> 00:39:35,839
itself gives a logical transformation

00:39:35,040 --> 00:39:38,240
from the

00:39:35,839 --> 00:39:39,520
data column to the logic to the

00:39:38,240 --> 00:39:41,359
partition value

00:39:39,520 --> 00:39:43,040
so it actually does not produce that

00:39:41,359 --> 00:39:46,640
physical partition value

00:39:43,040 --> 00:39:46,640
it figures that out when you query

00:39:46,800 --> 00:39:50,480
let's say you have a timestamp uh

00:39:48,960 --> 00:39:53,440
timestamp column

00:39:50,480 --> 00:39:55,040
and you want to partition it by day so

00:39:53,440 --> 00:39:56,640
in spark you would have to create a

00:39:55,040 --> 00:39:59,520
separate column called day

00:39:56,640 --> 00:40:01,359
and then use it as a partition value and

00:39:59,520 --> 00:40:02,800
whenever you query by timestamp you

00:40:01,359 --> 00:40:04,400
would actually have to append an

00:40:02,800 --> 00:40:07,119
additional predicate

00:40:04,400 --> 00:40:07,760
um so you'd have to derive that again

00:40:07,119 --> 00:40:10,079
value

00:40:07,760 --> 00:40:11,280
for for for today and then use that an

00:40:10,079 --> 00:40:13,280
additional predicate

00:40:11,280 --> 00:40:14,880
in iceberg that additional predicate is

00:40:13,280 --> 00:40:17,440
optional so iceberg will

00:40:14,880 --> 00:40:19,680
see that the table is partitioned by day

00:40:17,440 --> 00:40:21,040
you have a predicate on the timestamp i

00:40:19,680 --> 00:40:22,880
will figure out what

00:40:21,040 --> 00:40:24,079
day you have and it will apply that

00:40:22,880 --> 00:40:26,240
logical transformation

00:40:24,079 --> 00:40:28,640
and we'll do implicit partitioning for

00:40:26,240 --> 00:40:31,599
you now apart from that

00:40:28,640 --> 00:40:32,560
um it also has file filtering this is

00:40:31,599 --> 00:40:34,800
using the min max

00:40:32,560 --> 00:40:37,200
statistics that's available in metadata

00:40:34,800 --> 00:40:38,160
so traditionally in spark we can improve

00:40:37,200 --> 00:40:40,000
partitions

00:40:38,160 --> 00:40:41,440
but you cannot prune files within those

00:40:40,000 --> 00:40:42,960
partitions and this is

00:40:41,440 --> 00:40:44,560
something that really allows you to

00:40:42,960 --> 00:40:46,400
scale down your clusters

00:40:44,560 --> 00:40:48,079
and even improve the performance this is

00:40:46,400 --> 00:40:50,240
what vishwa was talking about

00:40:48,079 --> 00:40:54,000
which makes it way more efficient in

00:40:50,240 --> 00:40:54,000
terms of the cost and query times

00:40:55,599 --> 00:41:00,160
thank you um i think we are almost out

00:40:57,839 --> 00:41:03,040
of time uh thanks a lot for joining and

00:41:00,160 --> 00:41:04,400
for all the wonderful questions here uh

00:41:03,040 --> 00:41:05,920
please

00:41:04,400 --> 00:41:07,440
reach out to us there are multiple

00:41:05,920 --> 00:41:09,920
full-time and internship opportunities

00:41:07,440 --> 00:41:12,880
that we have check out iceberg for sure

00:41:09,920 --> 00:41:14,640
um uh raised prs in open source iceberg

00:41:12,880 --> 00:41:15,359
and spark we are big users of both of

00:41:14,640 --> 00:41:18,000
them

00:41:15,359 --> 00:41:19,440
uh we are at our booths as well if you

00:41:18,000 --> 00:41:20,640
have any further questions please join

00:41:19,440 --> 00:41:25,280
us there

00:41:20,640 --> 00:41:25,280
thanks a lot thank you thanks a lot guys

00:41:32,839 --> 00:41:35,839
bye

00:41:37,760 --> 00:41:39,839

YouTube URL: https://www.youtube.com/watch?v=QNmSXMQ-gY4


