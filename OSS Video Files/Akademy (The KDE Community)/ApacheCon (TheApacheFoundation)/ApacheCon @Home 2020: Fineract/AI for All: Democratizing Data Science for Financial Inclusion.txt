Title: AI for All: Democratizing Data Science for Financial Inclusion
Publication date: 2020-10-17
Playlist: ApacheCon @Home 2020: Fineract
Description: 
	AI for All: Democratizing Data Science for Financial Inclusion
Jeremy Engelbrecht, Lalit Mohan, Ed Cable

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

In this session members of the community working group leading artificial intelligence and machine learning will outline the vision and roadmap for leveraging Apache Fineract to democratize data science for financial inclusion. They’ll share case studies highlighting how members of the community are currently pioneering tools for explainable decision making, enhance customer experience, and micro-analytics. The roadmap will lay out how to evolve the Apache Fineract platform to support credit scoring and origination tools, targeted segmentation and predictive product insights, KYC, AML, and accelerated onboarding, fraud detection, chatbots with natural and regional language support, customer churn prediction, and more.

Jeremy Engelbrecht:
Jeremy has 20 years experience in the design of software systems from end to end (SDLC). He has worked for two banks in Southern Africa, First National Bank and Standard bank and also worked for a JSE listed insurance company, Clientele. He was the Solutions Architect for an award-winning European fintech company called Mybucks. He was selected to be the CTO to start the first digital bank in Saudi Arabia. He has co-founded LNDR which is a fintech company that has started the first digital bank in Swaziland and is the chosen fintech company of choice for a large bank in south africa. He is currently completing his MSc in advanced computer science at the University of Liverpool, majoring in Artificial Intelligence with a dissertation based on proving a hypothesis to use DBN(Deep Belief Networks) to do credit scoring using large unstructured datasets.

Lalit Mohan:
Lalit is pursuing his PhD in Computer Science & Engineering at IIIT Hyderabad in the area of Information Retrieval, Software Engineering, ML and NLP. Lalit has been a GSOC mentor at Mifos/Fineract for the last 2 years. Lalit has 23+ Years of IT experience at Infosys, Wells Fargo, IDRBT (India’s central bank - Reserve Bank of India - Technology research institute). He has published papers on Credit risk evaluation using ML Models, Digital Banking, FAQs on Cloud Computing for Banks, API Banking, Open source for Banks and other articles. He is also a member of Banking Industry Architecture Network (BIAN). Some of the key projects executed include a) Treasury Management for World Bank b) Establishment of Indian Banking Community Cloud c) Deployment of Payment Systems in a SaaS model to reduce the capital expenses for cooperative Banks.

Ed Cable:
Ed has been a part of the Mifos project since 2007 in its early days at Grameen Foundation. He oversaw the open source community, connecting its members worldwide with the tools, support, and engagement needed to build and use Mifos. Leading the growth of this burgeoning community, he saw the dedication and persistence of its members and decided to found COSM (now the Mifos Initiative) to unite their efforts and help them collectively fulfill the vision Grameen Foundation set out to achieve. Prior to this, he graduated from the Wharton School at the University of Pennsylvania where he led marketing for the nation’s largest student-run credit union and discovered his passion for technology-driven international development in their budding social entrepreneurship program. When he’s not watching over the Mifos community, he’s tending to another community of sorts, his mini-farmhouse of animals – chickens, bunnies, dogs, goats, cats, birds, and fish.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,880 --> 00:00:27,039
so

00:00:25,439 --> 00:00:28,800
thank you again for giving the

00:00:27,039 --> 00:00:31,599
opportunity

00:00:28,800 --> 00:00:32,320
and i would like to introduce was my

00:00:31,599 --> 00:00:35,040
co-speaker

00:00:32,320 --> 00:00:35,920
jeremy uh he has 20 years plus

00:00:35,040 --> 00:00:39,280
experience

00:00:35,920 --> 00:00:39,840
and uh pretty passionate about machine

00:00:39,280 --> 00:00:42,559
learning

00:00:39,840 --> 00:00:45,039
and deep learning and its applicability

00:00:42,559 --> 00:00:47,280
to the financial services

00:00:45,039 --> 00:00:50,640
in the last three four months i've been

00:00:47,280 --> 00:00:53,760
interacting very closely in the

00:00:50,640 --> 00:00:55,360
ai for me force and standardization of

00:00:53,760 --> 00:00:59,120
the platform so

00:00:55,360 --> 00:00:59,920
i'm quite happy to have him on the as my

00:00:59,120 --> 00:01:02,960
co-speaker

00:00:59,920 --> 00:01:04,000
and uh ed doesn't need any introduction

00:01:02,960 --> 00:01:07,280
right so

00:01:04,000 --> 00:01:12,640
and then it's next me and lalith

00:01:07,280 --> 00:01:17,119
and um jeremy slights have gone

00:01:12,640 --> 00:01:20,080
sorry sure that's fine

00:01:17,119 --> 00:01:21,680
and i'm lalit i'm pursuing my phd in

00:01:20,080 --> 00:01:24,159
domain-specific search engine

00:01:21,680 --> 00:01:26,159
uh after working for about 20 years in

00:01:24,159 --> 00:01:28,560
the industry

00:01:26,159 --> 00:01:30,640
and i suddenly find it privileged to

00:01:28,560 --> 00:01:31,759
work for an open source community and me

00:01:30,640 --> 00:01:34,479
person specific

00:01:31,759 --> 00:01:36,720
because all through my career has been

00:01:34,479 --> 00:01:39,119
in the banking technology

00:01:36,720 --> 00:01:40,560
we move to the next slide jeremy you

00:01:39,119 --> 00:01:42,880
want to talk for the first slide and

00:01:40,560 --> 00:01:44,320
then we go into the subsequent stories

00:01:42,880 --> 00:01:46,079
okay so one of the questions that we

00:01:44,320 --> 00:01:48,799
brought up was why does

00:01:46,079 --> 00:01:50,479
uh data science matter so if you had to

00:01:48,799 --> 00:01:53,600
look at your old brick and mortar

00:01:50,479 --> 00:01:56,159
banks in the old days a lot of

00:01:53,600 --> 00:01:57,600
transaction was happening at the teller

00:01:56,159 --> 00:02:00,159
et cetera et cetera and now with the

00:01:57,600 --> 00:02:02,399
rise of neo banks and

00:02:00,159 --> 00:02:03,200
in the world going to the digital

00:02:02,399 --> 00:02:05,200
paradigm

00:02:03,200 --> 00:02:07,360
we have found that there's a lot more

00:02:05,200 --> 00:02:09,840
data that is accessible

00:02:07,360 --> 00:02:10,800
and in ways of doing banking and

00:02:09,840 --> 00:02:14,160
obviously

00:02:10,800 --> 00:02:16,879
there are new banks and from that

00:02:14,160 --> 00:02:18,640
ai has now as is there's a space that's

00:02:16,879 --> 00:02:22,720
that's been made appearance

00:02:18,640 --> 00:02:24,480
that ai has got has got great potential

00:02:22,720 --> 00:02:26,319
that's the thing that you can use with

00:02:24,480 --> 00:02:28,000
all this data that's the various data

00:02:26,319 --> 00:02:28,879
lakes that we can tap into et cetera et

00:02:28,000 --> 00:02:30,640
cetera

00:02:28,879 --> 00:02:33,200
um just on one of the points the

00:02:30,640 --> 00:02:36,720
analysis experts estimate that ai

00:02:33,200 --> 00:02:38,879
um using this data um

00:02:36,720 --> 00:02:40,160
and making it possible with ai and

00:02:38,879 --> 00:02:43,280
creating various

00:02:40,160 --> 00:02:45,440
um processes um they

00:02:43,280 --> 00:02:47,760
they predict that i will say the banking

00:02:45,440 --> 00:02:48,879
industry roughly one trillion dollars by

00:02:47,760 --> 00:02:50,720
2030.

00:02:48,879 --> 00:02:52,000
and that that is phenomenal if i just

00:02:50,720 --> 00:02:55,200
take south africa

00:02:52,000 --> 00:02:58,319
one of our banks standard bank um going

00:02:55,200 --> 00:03:01,440
to the digital paradigm they actually

00:02:58,319 --> 00:03:04,239
they about 10 000 of the employees

00:03:01,440 --> 00:03:05,120
they they started letting go slowly but

00:03:04,239 --> 00:03:07,280
surely

00:03:05,120 --> 00:03:09,440
and the main reason for that is that a

00:03:07,280 --> 00:03:09,680
lot of the the process of being digits

00:03:09,440 --> 00:03:12,800
are

00:03:09,680 --> 00:03:15,519
digitized and and and by doing that

00:03:12,800 --> 00:03:16,800
and incorporating ai it's made it a lot

00:03:15,519 --> 00:03:18,239
more powerful

00:03:16,800 --> 00:03:21,440
and in saying that if you had to

00:03:18,239 --> 00:03:23,920
consider your customer experience

00:03:21,440 --> 00:03:26,239
in that regard is that your customer

00:03:23,920 --> 00:03:28,640
doesn't need to go to the teller anymore

00:03:26,239 --> 00:03:30,480
they can they term itself driving

00:03:28,640 --> 00:03:31,120
finance so what essentially can happen

00:03:30,480 --> 00:03:34,080
is that

00:03:31,120 --> 00:03:35,280
the clients can go on online they can do

00:03:34,080 --> 00:03:37,280
their banking online

00:03:35,280 --> 00:03:38,480
and and it's it's already happening

00:03:37,280 --> 00:03:41,040
around the world

00:03:38,480 --> 00:03:41,840
but um there's so much more that can be

00:03:41,040 --> 00:03:44,959
done with it

00:03:41,840 --> 00:03:46,159
um and we'll give you a demo later on in

00:03:44,959 --> 00:03:47,680
this regard

00:03:46,159 --> 00:03:50,239
and and not just that and with the rise

00:03:47,680 --> 00:03:53,280
of iot um if you had to take

00:03:50,239 --> 00:03:56,159
in 20 in 2019

00:03:53,280 --> 00:03:59,040
on an average day the world is producing

00:03:56,159 --> 00:03:59,040
2.5

00:03:59,280 --> 00:04:01,840
the

00:04:04,480 --> 00:04:11,920
uh gigabytes um well trigger bites sorry

00:04:07,840 --> 00:04:14,000
and um all that data if you can tap into

00:04:11,920 --> 00:04:15,599
the data there's a lot of data that one

00:04:14,000 --> 00:04:17,359
can use to create more profitable

00:04:15,599 --> 00:04:20,400
business models uh

00:04:17,359 --> 00:04:21,919
that's that's that's that that shows

00:04:20,400 --> 00:04:23,040
that there's a lot more power in there

00:04:21,919 --> 00:04:24,400
to god

00:04:23,040 --> 00:04:25,600
and um for instance i'll give you

00:04:24,400 --> 00:04:26,400
perfect example if you take your

00:04:25,600 --> 00:04:28,800
smartphone

00:04:26,400 --> 00:04:30,560
you've actually from an ai perspective

00:04:28,800 --> 00:04:31,600
um and doing credit scoring if you had

00:04:30,560 --> 00:04:36,000
to take

00:04:31,600 --> 00:04:39,520
a person's sms is the messaging service

00:04:36,000 --> 00:04:42,560
when somebody defaults for example um

00:04:39,520 --> 00:04:43,120
an sms gets sent to the to the customer

00:04:42,560 --> 00:04:45,120
saying

00:04:43,120 --> 00:04:46,960
please don't forget to pay your loan

00:04:45,120 --> 00:04:50,639
you're outstanding one month

00:04:46,960 --> 00:04:53,520
now by using ai to get or

00:04:50,639 --> 00:04:56,080
extrapolating their data and using ai to

00:04:53,520 --> 00:04:58,720
actually work with their data

00:04:56,080 --> 00:05:00,320
you you can create better profitable

00:04:58,720 --> 00:05:00,960
business models in the sense of people

00:05:00,320 --> 00:05:03,120
works

00:05:00,960 --> 00:05:05,280
you can you're created risks you can

00:05:03,120 --> 00:05:08,160
quantify better results in that regard

00:05:05,280 --> 00:05:08,880
etc etc and then on the rpa based

00:05:08,160 --> 00:05:12,560
systems

00:05:08,880 --> 00:05:15,530
um robotic processing automation um

00:05:12,560 --> 00:05:16,639
tasks that people would do your your

00:05:15,530 --> 00:05:19,759
[Music]

00:05:16,639 --> 00:05:22,160
staff members would do on a daily basis

00:05:19,759 --> 00:05:23,120
which is repetitive tasks you can get

00:05:22,160 --> 00:05:24,720
analytics

00:05:23,120 --> 00:05:25,919
that can sort that out for you they can

00:05:24,720 --> 00:05:27,280
do that to you and the thing is they can

00:05:25,919 --> 00:05:29,199
do 24 7.

00:05:27,280 --> 00:05:30,320
so they're very it's very powerful in

00:05:29,199 --> 00:05:33,600
that regard

00:05:30,320 --> 00:05:34,720
um and and and there's no need for you

00:05:33,600 --> 00:05:37,520
an intervention

00:05:34,720 --> 00:05:39,199
so that's pretty much why there's so

00:05:37,520 --> 00:05:40,320
much more that we can say about why data

00:05:39,199 --> 00:05:42,479
science matters but

00:05:40,320 --> 00:05:43,440
those are that is pretty much in a

00:05:42,479 --> 00:05:45,520
nutshell

00:05:43,440 --> 00:05:46,720
from being on trying to achieve

00:05:45,520 --> 00:05:50,880
financial infusion

00:05:46,720 --> 00:05:53,840
using data and and using um data science

00:05:50,880 --> 00:05:53,840
um

00:05:57,520 --> 00:06:00,560
right so

00:06:00,960 --> 00:06:05,520
we thought we'll touch upon some of the

00:06:03,680 --> 00:06:07,440
use cases that have relevance for

00:06:05,520 --> 00:06:11,280
banking

00:06:07,440 --> 00:06:14,479
i know ai data is now the

00:06:11,280 --> 00:06:16,240
new new buzzword or a new paradigm in

00:06:14,479 --> 00:06:18,639
terms of how

00:06:16,240 --> 00:06:20,240
digitization is happening or digital

00:06:18,639 --> 00:06:23,039
transformation is happening across

00:06:20,240 --> 00:06:24,800
organizations when we look at from

00:06:23,039 --> 00:06:27,280
banking perspective

00:06:24,800 --> 00:06:28,880
you could see it i know the front office

00:06:27,280 --> 00:06:31,280
the back office or the mid office

00:06:28,880 --> 00:06:33,600
they're all merging but certainly if you

00:06:31,280 --> 00:06:35,280
look at from a customer perspective

00:06:33,600 --> 00:06:37,520
ai can be used in terms of

00:06:35,280 --> 00:06:38,639
personalization ai can be used as

00:06:37,520 --> 00:06:40,960
advisors

00:06:38,639 --> 00:06:41,919
can be used for authentication or

00:06:40,960 --> 00:06:44,160
authorization

00:06:41,919 --> 00:06:45,840
my face can be used directly for

00:06:44,160 --> 00:06:47,039
recognizing rather than i key in a

00:06:45,840 --> 00:06:50,240
password

00:06:47,039 --> 00:06:51,840
and and uh yeah chatbots uh if you look

00:06:50,240 --> 00:06:54,800
at the mid office where

00:06:51,840 --> 00:06:56,080
we feel a lot of operational efficiency

00:06:54,800 --> 00:06:58,720
would kick in

00:06:56,080 --> 00:06:59,440
uh you could look at doing some risk

00:06:58,720 --> 00:07:01,520
management

00:06:59,440 --> 00:07:03,360
credit scoring which we have done to

00:07:01,520 --> 00:07:04,720
certain extent in the me force

00:07:03,360 --> 00:07:06,880
you could do your bank statement

00:07:04,720 --> 00:07:08,800
analysis you could do

00:07:06,880 --> 00:07:10,000
any of the data analysis on the

00:07:08,800 --> 00:07:13,120
statements

00:07:10,000 --> 00:07:16,720
for banks to process the records faster

00:07:13,120 --> 00:07:19,280
better and more accurate right

00:07:16,720 --> 00:07:21,840
it also suddenly is going to help in

00:07:19,280 --> 00:07:23,280
terms of regulatory compliance

00:07:21,840 --> 00:07:25,520
i know a lot of organizations are

00:07:23,280 --> 00:07:27,199
already taking the path of

00:07:25,520 --> 00:07:30,240
robotic process automation and in the

00:07:27,199 --> 00:07:33,120
recent times if you look at makency

00:07:30,240 --> 00:07:35,120
the organization that i work idrbd in

00:07:33,120 --> 00:07:37,919
collaboration with microsoft

00:07:35,120 --> 00:07:39,039
uh we have done quite a bit in terms of

00:07:37,919 --> 00:07:41,280
evangelizing

00:07:39,039 --> 00:07:43,120
talking about various use cases and an

00:07:41,280 --> 00:07:46,240
approach in terms of adoption of

00:07:43,120 --> 00:07:49,360
ai for banking what

00:07:46,240 --> 00:07:52,080
i listed is only just

00:07:49,360 --> 00:07:52,879
just a scratch on the uh on the entire

00:07:52,080 --> 00:07:54,960
surface of

00:07:52,879 --> 00:07:56,160
what ai can do for banking and financial

00:07:54,960 --> 00:08:01,360
services

00:07:56,160 --> 00:08:01,360
we see a lot more potential next slide

00:08:02,080 --> 00:08:08,960
yeah so with with that as the background

00:08:05,919 --> 00:08:10,960
we started a journey on ai

00:08:08,960 --> 00:08:12,240
in me for us for the last three four

00:08:10,960 --> 00:08:15,680
years now

00:08:12,240 --> 00:08:16,560
uh we made some attempts in terms of

00:08:15,680 --> 00:08:21,440
chatbot

00:08:16,560 --> 00:08:25,599
using an open source nlp we used uh

00:08:21,440 --> 00:08:28,639
ppi for identifying the

00:08:25,599 --> 00:08:30,240
poverty probability index so that

00:08:28,639 --> 00:08:32,479
when when we have to really look at

00:08:30,240 --> 00:08:35,599
financial inclusion uh we probably

00:08:32,479 --> 00:08:37,360
uh have the agent or the uh

00:08:35,599 --> 00:08:39,200
person in the branch goes to that

00:08:37,360 --> 00:08:40,000
location takes some pictures and then it

00:08:39,200 --> 00:08:42,159
does some

00:08:40,000 --> 00:08:44,480
calculation and says yeah this is the

00:08:42,159 --> 00:08:45,839
state where the customer is and probably

00:08:44,480 --> 00:08:48,560
you could do some

00:08:45,839 --> 00:08:50,959
uh product design accordingly or this is

00:08:48,560 --> 00:08:53,040
from financial inclusion perspective

00:08:50,959 --> 00:08:54,240
uh more recently we started working on

00:08:53,040 --> 00:08:57,040
the credit scoring

00:08:54,240 --> 00:08:58,240
i know this is currently a hot topic uh

00:08:57,040 --> 00:09:01,120
when we want to do

00:08:58,240 --> 00:09:01,839
any automation in the lending process uh

00:09:01,120 --> 00:09:03,920
what we did

00:09:01,839 --> 00:09:05,440
is we understand when we started the

00:09:03,920 --> 00:09:07,040
journey on the credit scoring this been

00:09:05,440 --> 00:09:11,120
going on for the last

00:09:07,040 --> 00:09:13,120
two three talks at me first

00:09:11,120 --> 00:09:14,240
when we initially started we realized

00:09:13,120 --> 00:09:16,959
the biggest problem is

00:09:14,240 --> 00:09:18,800
lack of data sets what is available as

00:09:16,959 --> 00:09:20,800
public data sets

00:09:18,800 --> 00:09:22,959
is is not good enough because the way

00:09:20,800 --> 00:09:24,160
that every organization wants to do

00:09:22,959 --> 00:09:27,600
credit scoring

00:09:24,160 --> 00:09:29,760
to a largest extent is is secretive

00:09:27,600 --> 00:09:31,279
or probably their own usp in terms of

00:09:29,760 --> 00:09:32,320
whether they want to give a loan or not

00:09:31,279 --> 00:09:34,880
give a loan

00:09:32,320 --> 00:09:36,000
so we felt one basic need is

00:09:34,880 --> 00:09:39,200
democratization of

00:09:36,000 --> 00:09:40,320
data so that smaller organizations can

00:09:39,200 --> 00:09:44,160
benefit

00:09:40,320 --> 00:09:47,279
second the future sense

00:09:44,160 --> 00:09:50,720
is is also a challenge right

00:09:47,279 --> 00:09:51,680
and we built for the gsoc we actually

00:09:50,720 --> 00:09:54,240
went about

00:09:51,680 --> 00:09:55,839
giving flexibility to the end users to

00:09:54,240 --> 00:09:58,720
create the features

00:09:55,839 --> 00:10:00,640
define some parameters uh so that the

00:09:58,720 --> 00:10:02,320
data transformation the encoding that

00:10:00,640 --> 00:10:04,640
you typically require in terms of

00:10:02,320 --> 00:10:08,160
converting from text to numeric

00:10:04,640 --> 00:10:11,600
can all be automated and requires

00:10:08,160 --> 00:10:13,920
minimal or almost less coding so

00:10:11,600 --> 00:10:14,800
the thoughts that started emerging is

00:10:13,920 --> 00:10:18,480
how do we

00:10:14,800 --> 00:10:20,800
reduce the development time how do we

00:10:18,480 --> 00:10:20,800
um

00:10:21,600 --> 00:10:27,920
that can be used for various use cases

00:10:24,800 --> 00:10:29,839
how do we do some data democratization

00:10:27,920 --> 00:10:31,120
and if you see in these three use cases

00:10:29,839 --> 00:10:34,959
that we build

00:10:31,120 --> 00:10:35,920
we did one for using scalar the python

00:10:34,959 --> 00:10:39,040
libraries

00:10:35,920 --> 00:10:39,600
in one case we used open nlp in another

00:10:39,040 --> 00:10:47,839
case

00:10:39,600 --> 00:10:47,839
we actually went about using google

00:10:50,320 --> 00:11:01,839
okay so uh i'm still breaking

00:10:53,760 --> 00:11:01,839
my audible now we can hear you now

00:11:06,320 --> 00:11:10,079
um so do i need to disconnect something

00:11:09,279 --> 00:11:13,040
or am i good

00:11:10,079 --> 00:11:13,600
here no i can hear you yeah you're good

00:11:13,040 --> 00:11:17,120
wallet

00:11:13,600 --> 00:11:20,320
please continue okay

00:11:17,120 --> 00:11:23,440
thank you um so

00:11:20,320 --> 00:11:26,480
um what we realized is uh

00:11:23,440 --> 00:11:28,560
in this journey we the developers are

00:11:26,480 --> 00:11:30,880
uh from a tactical perspective we

00:11:28,560 --> 00:11:33,200
realize that we used to what is

00:11:30,880 --> 00:11:34,399
most suited at that point in time but

00:11:33,200 --> 00:11:37,440
when we actually have to

00:11:34,399 --> 00:11:40,160
deploy in the production or when we

00:11:37,440 --> 00:11:42,140
develop our ecosystem we look at

00:11:40,160 --> 00:11:43,440
standardizing some of these libraries

00:11:42,140 --> 00:11:46,640
[Music]

00:11:43,440 --> 00:11:47,200
or on the cloud so these were the

00:11:46,640 --> 00:11:51,120
thoughts

00:11:47,200 --> 00:11:51,120
and these thoughts actually helped us

00:11:51,440 --> 00:11:53,680
good

00:11:55,200 --> 00:11:57,839
next slide please

00:12:01,680 --> 00:12:10,320
yeah so these thoughts started

00:12:05,600 --> 00:12:13,440
putting us into some kind of a framework

00:12:10,320 --> 00:12:15,440
working group in my first about a month

00:12:13,440 --> 00:12:19,040
month and a half back

00:12:15,440 --> 00:12:21,760
to see uh see support from the partners

00:12:19,040 --> 00:12:23,839
from the developers in the g-stock

00:12:21,760 --> 00:12:26,000
community

00:12:23,839 --> 00:12:27,600
nobody had any interest in terms of we

00:12:26,000 --> 00:12:30,639
first

00:12:27,600 --> 00:12:33,040
completed the movement what we discussed

00:12:30,639 --> 00:12:33,839
is to see how we can look at some

00:12:33,040 --> 00:12:35,600
platforms

00:12:33,839 --> 00:12:37,519
and if we can draw some boundaries in

00:12:35,600 --> 00:12:40,639
terms of what we could do

00:12:37,519 --> 00:12:43,200
this is our proposal to see if we can

00:12:40,639 --> 00:12:43,200
get some

00:12:43,680 --> 00:12:47,760
machine learning libraries which could

00:12:45,279 --> 00:12:49,200
do some uh whether it is

00:12:47,760 --> 00:12:51,760
whether it is supervised whether it is

00:12:49,200 --> 00:12:52,800
deep learning rather than each of us in

00:12:51,760 --> 00:12:54,079
their own journey so

00:12:52,800 --> 00:12:56,079
at least we know these are machine

00:12:54,079 --> 00:12:59,600
learning models but we all

00:12:56,079 --> 00:13:01,279
ai machine learning is one key part

00:12:59,600 --> 00:13:04,639
but a lot goes in terms of data

00:13:01,279 --> 00:13:04,639
processing how do i

00:13:05,519 --> 00:13:09,760
is very essential to make sure that i

00:13:07,680 --> 00:13:11,760
remove the mouse to the extent that

00:13:09,760 --> 00:13:13,360
we are we get the clean data that the

00:13:11,760 --> 00:13:15,279
model can

00:13:13,360 --> 00:13:16,639
you know data processing similarly

00:13:15,279 --> 00:13:18,720
representing the information in

00:13:16,639 --> 00:13:21,360
knowledge in a graphical format

00:13:18,720 --> 00:13:22,160
can give better reasoning so we started

00:13:21,360 --> 00:13:25,279
drawing this

00:13:22,160 --> 00:13:26,480
strawman in terms of putting use cases

00:13:25,279 --> 00:13:31,200
at the top layer

00:13:26,480 --> 00:13:33,440
then what are the various content from

00:13:31,200 --> 00:13:34,959
constructor text we could get structured

00:13:33,440 --> 00:13:36,560
data which is typically what we would

00:13:34,959 --> 00:13:39,120
have in the relational database

00:13:36,560 --> 00:13:40,160
we could have images which we already

00:13:39,120 --> 00:13:44,320
did in the ppi

00:13:40,160 --> 00:13:46,320
project or the speech right

00:13:44,320 --> 00:13:47,680
we know in some interiors literacy is

00:13:46,320 --> 00:13:49,360
still a challenge and

00:13:47,680 --> 00:13:50,639
speech could be an alternative in terms

00:13:49,360 --> 00:13:52,079
of authentication could be an

00:13:50,639 --> 00:13:53,920
alternative in terms of

00:13:52,079 --> 00:13:55,920
checking balances or even doing some

00:13:53,920 --> 00:13:58,160
transactions so with that

00:13:55,920 --> 00:13:59,360
we started putting a stroman or a

00:13:58,160 --> 00:14:02,320
component diagram

00:13:59,360 --> 00:14:02,880
in terms of how we visualize the uh

00:14:02,320 --> 00:14:06,000
platform

00:14:02,880 --> 00:14:08,240
that we want to standardize so

00:14:06,000 --> 00:14:09,440
with that thought we started putting in

00:14:08,240 --> 00:14:12,560
terms of time-lapse

00:14:09,440 --> 00:14:14,839
timeline what we could do in the next

00:14:12,560 --> 00:14:16,959
one one enough game so that the momentum

00:14:14,839 --> 00:14:18,639
continues and we could deliver something

00:14:16,959 --> 00:14:21,760
for the community

00:14:18,639 --> 00:14:21,760
i request the next slide

00:14:22,560 --> 00:14:28,320
so these are our early

00:14:25,920 --> 00:14:29,920
deadlines and it's important that we put

00:14:28,320 --> 00:14:30,880
some deadlines so that we have some

00:14:29,920 --> 00:14:33,360
targets

00:14:30,880 --> 00:14:35,199
we work towards it and we could probably

00:14:33,360 --> 00:14:37,440
create some motivation among the

00:14:35,199 --> 00:14:38,880
community to seek some more partnerships

00:14:37,440 --> 00:14:42,000
some more support

00:14:38,880 --> 00:14:45,680
uh in driving the initiative

00:14:42,000 --> 00:14:47,839
so we are looking at in the next

00:14:45,680 --> 00:14:49,040
quarter that we at least have a common

00:14:47,839 --> 00:14:49,680
understanding on what are all the

00:14:49,040 --> 00:14:51,920
various

00:14:49,680 --> 00:14:53,920
use cases there are enough reference

00:14:51,920 --> 00:14:55,440
material uh

00:14:53,920 --> 00:14:57,760
but yeah we want to make sure that the

00:14:55,440 --> 00:14:59,440
community has a common understanding on

00:14:57,760 --> 00:15:00,560
uh use cases that we could get out of

00:14:59,440 --> 00:15:02,399
the system

00:15:00,560 --> 00:15:03,680
and then start our journey in terms of

00:15:02,399 --> 00:15:07,040
the platform

00:15:03,680 --> 00:15:08,959
of finalization do we want to use cloud

00:15:07,040 --> 00:15:12,560
if it is cloud whether we leverage

00:15:08,959 --> 00:15:15,600
h2oi or we use azure or we use

00:15:12,560 --> 00:15:17,519
aws or if you multiple what are those

00:15:15,600 --> 00:15:20,959
apis what are those

00:15:17,519 --> 00:15:23,600
uh features that we can push or get

00:15:20,959 --> 00:15:26,240
uh if we want to do it on prem what is

00:15:23,600 --> 00:15:27,440
that library that we could use so that

00:15:26,240 --> 00:15:29,680
we have a

00:15:27,440 --> 00:15:31,279
common understanding again across the

00:15:29,680 --> 00:15:34,079
platform

00:15:31,279 --> 00:15:34,720
the later we want to do the development

00:15:34,079 --> 00:15:36,880
and

00:15:34,720 --> 00:15:38,480
i know it's six months is not sufficient

00:15:36,880 --> 00:15:40,079
but yeah at least six months we could

00:15:38,480 --> 00:15:42,240
start showing some

00:15:40,079 --> 00:15:44,399
a deliverables that way the community

00:15:42,240 --> 00:15:46,639
starts building interest

00:15:44,399 --> 00:15:47,519
and and they don't go about implementing

00:15:46,639 --> 00:15:50,560
it and

00:15:47,519 --> 00:15:53,600
create more awareness

00:15:50,560 --> 00:15:57,279
so i

00:15:53,600 --> 00:15:59,920
i'm almost at the end but i

00:15:57,279 --> 00:16:00,560
wanted to create some excitement and see

00:15:59,920 --> 00:16:02,480
how the

00:16:00,560 --> 00:16:03,920
uh approach or what we are trying to

00:16:02,480 --> 00:16:05,680
take as a direction

00:16:03,920 --> 00:16:06,959
uh we will take questions at the end but

00:16:05,680 --> 00:16:08,959
mean time i request

00:16:06,959 --> 00:16:11,199
jeremy to go to the next slide and then

00:16:08,959 --> 00:16:14,000
take over in terms of the demo

00:16:11,199 --> 00:16:15,600
sure okay so in regards to the slide

00:16:14,000 --> 00:16:17,680
that you're looking at right now this is

00:16:15,600 --> 00:16:20,240
an onboarding process

00:16:17,680 --> 00:16:22,079
and what i'll be showing you is is what

00:16:20,240 --> 00:16:23,440
you see now i'll actually show you in a

00:16:22,079 --> 00:16:25,920
live demo

00:16:23,440 --> 00:16:27,199
where a customer would go online apply

00:16:25,920 --> 00:16:29,040
for a loan

00:16:27,199 --> 00:16:30,959
and we and i'd show you the various

00:16:29,040 --> 00:16:33,199
steps of where the ai comes in

00:16:30,959 --> 00:16:34,639
obviously one of them being fraud and on

00:16:33,199 --> 00:16:37,839
anomaly

00:16:34,639 --> 00:16:40,480
doing your kyc um doing bank statement

00:16:37,839 --> 00:16:41,920
analysis and then at the end obviously

00:16:40,480 --> 00:16:43,680
from a machine machine learning

00:16:41,920 --> 00:16:46,720
perspective um

00:16:43,680 --> 00:16:48,480
then um predict which products would be

00:16:46,720 --> 00:16:50,959
good for that customer

00:16:48,480 --> 00:16:51,759
and that is all based on gathering data

00:16:50,959 --> 00:16:54,160
through these

00:16:51,759 --> 00:16:56,079
through these various steps that you see

00:16:54,160 --> 00:16:59,279
um at the end we

00:16:56,079 --> 00:17:01,279
we have collected 130 attributes which

00:16:59,279 --> 00:17:04,000
we then can make a decision on

00:17:01,279 --> 00:17:05,280
whether the person is good for a loan of

00:17:04,000 --> 00:17:08,799
a certain amount

00:17:05,280 --> 00:17:10,319
and a certain period so just to kick off

00:17:08,799 --> 00:17:19,120
just having a look at that

00:17:10,319 --> 00:17:22,240
i'll then go and i'll start the demo

00:17:19,120 --> 00:17:22,240
okay so just to show you

00:17:22,400 --> 00:17:30,320
i'm going to be using my testing plants

00:17:26,959 --> 00:17:30,960
so as you can see um what we've got this

00:17:30,320 --> 00:17:32,640
is all

00:17:30,960 --> 00:17:34,400
fine erect is a core system that we've

00:17:32,640 --> 00:17:35,120
used and we've obviously enhanced it and

00:17:34,400 --> 00:17:38,320
added

00:17:35,120 --> 00:17:39,520
a lot of ai models and functionality to

00:17:38,320 --> 00:17:41,919
the process

00:17:39,520 --> 00:17:43,520
um which has made it which which which

00:17:41,919 --> 00:17:44,559
is actually taking it to the next level

00:17:43,520 --> 00:17:47,520
in natural

00:17:44,559 --> 00:17:49,200
so just having a look so we call it alec

00:17:47,520 --> 00:17:50,400
and what alec does is it does your bank

00:17:49,200 --> 00:17:52,320
statement analysis

00:17:50,400 --> 00:17:54,160
so just to show you that that we're

00:17:52,320 --> 00:17:55,360
doing this live you can see there's no

00:17:54,160 --> 00:17:58,880
dates here

00:17:55,360 --> 00:18:00,720
um and that data will be produced

00:17:58,880 --> 00:18:03,600
when we do the onboarding process which

00:18:00,720 --> 00:18:03,600
i will show you now

00:18:04,000 --> 00:18:10,480
so this is one of our channels

00:18:07,280 --> 00:18:14,240
of of of the lone lms

00:18:10,480 --> 00:18:16,960
front end in south africa which we've

00:18:14,240 --> 00:18:17,840
plugged onto the finrax core banking

00:18:16,960 --> 00:18:19,679
system

00:18:17,840 --> 00:18:21,760
and incorporated all the other various

00:18:19,679 --> 00:18:22,880
market services so this whole this whole

00:18:21,760 --> 00:18:24,160
infrastructure is

00:18:22,880 --> 00:18:26,320
just to add to it is running on

00:18:24,160 --> 00:18:28,240
kubernetes it's on azure

00:18:26,320 --> 00:18:29,840
kubernetes cluster and it's all digital

00:18:28,240 --> 00:18:32,240
and it's all cloud-based

00:18:29,840 --> 00:18:33,840
um with various market services so i'm

00:18:32,240 --> 00:18:35,679
just going to go through the steps

00:18:33,840 --> 00:18:42,400
so obviously i've already registered so

00:18:35,679 --> 00:18:44,160
i'm just going to use my name

00:18:42,400 --> 00:18:45,919
so one of the things that we do we found

00:18:44,160 --> 00:18:48,559
over time is that we need to

00:18:45,919 --> 00:18:49,520
while we're doing this process we try to

00:18:48,559 --> 00:18:52,320
keep it as

00:18:49,520 --> 00:18:54,480
as minimal as possible so we can

00:18:52,320 --> 00:18:56,080
quantify going through these steps and

00:18:54,480 --> 00:18:58,799
using ai

00:18:56,080 --> 00:18:59,360
then we can disperse a loan within

00:18:58,799 --> 00:19:02,240
between

00:18:59,360 --> 00:19:04,000
seven to fifteen minutes um if you had

00:19:02,240 --> 00:19:06,559
to take as i mentioned in the

00:19:04,000 --> 00:19:09,039
in in the first slide if you had to look

00:19:06,559 --> 00:19:10,799
at your brick and mortar banking

00:19:09,039 --> 00:19:12,720
methodologies it would have probably

00:19:10,799 --> 00:19:13,520
taken you two days because somebody has

00:19:12,720 --> 00:19:16,000
to go do

00:19:13,520 --> 00:19:16,960
a bank statement analysis see that you

00:19:16,000 --> 00:19:19,600
qualify

00:19:16,960 --> 00:19:20,400
do affordability do kyc know your

00:19:19,600 --> 00:19:23,600
customer

00:19:20,400 --> 00:19:26,320
etc etc but we have all encompassed that

00:19:23,600 --> 00:19:27,520
into one process using various ai models

00:19:26,320 --> 00:19:28,720
and techniques

00:19:27,520 --> 00:19:30,320
so i'm just going to go through so

00:19:28,720 --> 00:19:32,640
obviously i've already added my my

00:19:30,320 --> 00:19:35,200
banking details

00:19:32,640 --> 00:19:36,160
i include my employer details and just

00:19:35,200 --> 00:19:37,919
adding on that

00:19:36,160 --> 00:19:39,600
there's various attributes that we've

00:19:37,919 --> 00:19:41,280
asked the client to fill in

00:19:39,600 --> 00:19:42,960
and the reason being for that is that

00:19:41,280 --> 00:19:46,080
when we use these data points

00:19:42,960 --> 00:19:48,480
a perfect example as your employer if

00:19:46,080 --> 00:19:49,679
for example the person is working for a

00:19:48,480 --> 00:19:51,120
government entity

00:19:49,679 --> 00:19:53,840
you know that they were looking for a

00:19:51,120 --> 00:19:56,240
solid environment or corporation

00:19:53,840 --> 00:19:57,520
so they are likely to get paid well very

00:19:56,240 --> 00:19:58,000
likely to get paid at the end of the

00:19:57,520 --> 00:19:59,760
month

00:19:58,000 --> 00:20:02,000
but if it's a if it's an individual

00:19:59,760 --> 00:20:03,679
that's just opened a little company

00:20:02,000 --> 00:20:05,120
and it's a starter you don't know how

00:20:03,679 --> 00:20:06,960
long their company is going to last but

00:20:05,120 --> 00:20:07,840
taking in those attributes into your

00:20:06,960 --> 00:20:10,480
algorithm

00:20:07,840 --> 00:20:12,000
as various data points you've got a lot

00:20:10,480 --> 00:20:13,280
you can do a lot more waiting

00:20:12,000 --> 00:20:15,039
in that regard so i'm just going to

00:20:13,280 --> 00:20:15,760
carry on so you go with me with my

00:20:15,039 --> 00:20:17,120
employer

00:20:15,760 --> 00:20:19,679
so this is where the stuff gets

00:20:17,120 --> 00:20:21,760
interesting so yeah what i do is

00:20:19,679 --> 00:20:23,440
we've actually built in two scenarios

00:20:21,760 --> 00:20:25,120
just just to give you an example we've

00:20:23,440 --> 00:20:27,120
actually plugged in

00:20:25,120 --> 00:20:29,280
to all our major banks here in south

00:20:27,120 --> 00:20:30,799
africa so we can get digital statements

00:20:29,280 --> 00:20:34,320
digital transactions

00:20:30,799 --> 00:20:36,320
directly from the banks and then do um

00:20:34,320 --> 00:20:37,840
on that which alec does bank statement

00:20:36,320 --> 00:20:39,120
analysis or the other step which i'm

00:20:37,840 --> 00:20:42,080
going to show you now

00:20:39,120 --> 00:20:43,360
is that we uh we do we ask the

00:20:42,080 --> 00:20:45,600
individual if they don't want to do that

00:20:43,360 --> 00:20:47,280
they can upload the bank statements

00:20:45,600 --> 00:20:50,320
that they've downloaded from the online

00:20:47,280 --> 00:20:52,640
banking etc and we then do ocr

00:20:50,320 --> 00:20:54,880
off of those those bank statements and

00:20:52,640 --> 00:20:58,799
then we do bank statement analysis on it

00:20:54,880 --> 00:20:58,799
so i'm going to just do the ocr method

00:21:00,159 --> 00:21:03,600
okay so now what it's basically doing in

00:21:01,760 --> 00:21:06,240
the back and then this will take a few

00:21:03,600 --> 00:21:07,520
few seconds is checking bank validation

00:21:06,240 --> 00:21:09,520
so we plugged into

00:21:07,520 --> 00:21:11,360
into a credit bureau that will tell us

00:21:09,520 --> 00:21:12,240
yes the individual has got banking

00:21:11,360 --> 00:21:14,960
details

00:21:12,240 --> 00:21:15,600
um their bank validation account is

00:21:14,960 --> 00:21:18,720
legit

00:21:15,600 --> 00:21:20,320
compares to the id we then do um base

00:21:18,720 --> 00:21:21,919
statements analysis so right now the

00:21:20,320 --> 00:21:24,320
system is doing ocr

00:21:21,919 --> 00:21:25,200
it's extracting the data off of the the

00:21:24,320 --> 00:21:26,720
pdfs

00:21:25,200 --> 00:21:28,400
and it's doing better that's it's using

00:21:26,720 --> 00:21:29,440
alec to do bank statement analysis and

00:21:28,400 --> 00:21:31,919
what do the

00:21:29,440 --> 00:21:32,720
does is that it categorizes the various

00:21:31,919 --> 00:21:35,039
spend

00:21:32,720 --> 00:21:36,559
of an individual it defines your salary

00:21:35,039 --> 00:21:38,000
which days you get paid on but i will

00:21:36,559 --> 00:21:40,000
show you that later on in

00:21:38,000 --> 00:21:41,120
in once once you've completed and then

00:21:40,000 --> 00:21:44,080
once it's done that

00:21:41,120 --> 00:21:44,720
then after the end which you'll see soon

00:21:44,080 --> 00:21:46,880
so

00:21:44,720 --> 00:21:48,080
it will then produce a result saying

00:21:46,880 --> 00:21:50,400
that jeremy's

00:21:48,080 --> 00:21:52,559
is she's good for a loan as you can see

00:21:50,400 --> 00:21:54,000
now so we've actually done a few steps

00:21:52,559 --> 00:21:57,440
there in those few seconds

00:21:54,000 --> 00:22:00,320
we did bank validation we did kyc we did

00:21:57,440 --> 00:22:00,640
credit bureau checks credit check we did

00:22:00,320 --> 00:22:03,520
um

00:22:00,640 --> 00:22:04,880
affordability check and i predicted that

00:22:03,520 --> 00:22:06,400
i would be good for a loan of six

00:22:04,880 --> 00:22:08,559
thousand five hundred rand over three

00:22:06,400 --> 00:22:10,320
months

00:22:08,559 --> 00:22:12,000
so that's quite a lot that you've done

00:22:10,320 --> 00:22:13,120
in literally a few seconds like you had

00:22:12,000 --> 00:22:14,880
to take that

00:22:13,120 --> 00:22:16,960
and you had to use your old banking

00:22:14,880 --> 00:22:19,600
systems it would take you a lot

00:22:16,960 --> 00:22:20,559
lot longer so in doing that you can

00:22:19,600 --> 00:22:22,159
quantify

00:22:20,559 --> 00:22:23,760
your optics cost because you can have a

00:22:22,159 --> 00:22:24,159
reduction on your staff you don't have

00:22:23,760 --> 00:22:25,520
to

00:22:24,159 --> 00:22:28,320
but your soft complement doesn't have to

00:22:25,520 --> 00:22:30,559
be that big um the other thing is that

00:22:28,320 --> 00:22:32,240
you don't have to you can produce better

00:22:30,559 --> 00:22:34,720
results and this also comes back to the

00:22:32,240 --> 00:22:39,039
first slide but it's self-driven banking

00:22:34,720 --> 00:22:41,280
so the customer is is is is experiencing

00:22:39,039 --> 00:22:42,559
his own his own learning process without

00:22:41,280 --> 00:22:44,799
any other individual

00:22:42,559 --> 00:22:46,480
or human being interfering so i'm just

00:22:44,799 --> 00:22:49,280
going to go through this process

00:22:46,480 --> 00:22:52,320
i get a quote i accept the quotes it

00:22:49,280 --> 00:22:54,640
gives me my pre-agreements

00:22:52,320 --> 00:22:57,039
i'm happy with the pre-agreements i then

00:22:54,640 --> 00:23:00,080
accepted it sends me an otp

00:22:57,039 --> 00:23:09,840
um which i will get on my phone my phone

00:23:00,080 --> 00:23:09,840
is on silence

00:23:20,080 --> 00:23:23,840
okay maybe that's wrong

00:23:31,100 --> 00:23:34,170
[Music]

00:23:37,200 --> 00:23:40,799
maybe because it's a demo customer it's

00:23:39,039 --> 00:23:42,320
not going through so nonetheless so what

00:23:40,799 --> 00:23:44,320
it's essentially done is

00:23:42,320 --> 00:23:45,679
is that it's then shown it's it's now

00:23:44,320 --> 00:23:47,600
done so i'm going to go to the back end

00:23:45,679 --> 00:23:50,880
just to show you what it's done

00:23:47,600 --> 00:23:52,240
so let's go back here so if you see now

00:23:50,880 --> 00:23:55,120
initially there wasn't a loan

00:23:52,240 --> 00:23:56,000
in this section um so through those

00:23:55,120 --> 00:23:59,279
processes

00:23:56,000 --> 00:24:03,360
i showed you that we had no data yet

00:23:59,279 --> 00:24:05,200
so from the ai analysis we think that

00:24:03,360 --> 00:24:06,960
looking at my statements which i can

00:24:05,200 --> 00:24:10,000
show you it picked up

00:24:06,960 --> 00:24:12,400
a i used nlp which is natural language

00:24:10,000 --> 00:24:15,760
processing which is a form of ai

00:24:12,400 --> 00:24:18,320
and used that and various algorithms to

00:24:15,760 --> 00:24:22,000
depict office of off my

00:24:18,320 --> 00:24:26,159
scan statements my four-month salary

00:24:22,000 --> 00:24:28,240
my vehicle expenses my fuel expenses

00:24:26,159 --> 00:24:30,480
insurance expenses and you can see it's

00:24:28,240 --> 00:24:32,320
on a monthly basis because obviously

00:24:30,480 --> 00:24:35,039
you pay a premium what's your rental

00:24:32,320 --> 00:24:38,000
expense expenses your cellular expenses

00:24:35,039 --> 00:24:38,720
um and then transfers the transactions

00:24:38,000 --> 00:24:40,320
um

00:24:38,720 --> 00:24:42,159
and there's a whole lot more so your

00:24:40,320 --> 00:24:45,520
medical expenses um

00:24:42,159 --> 00:24:48,559
transfer income so with doing that

00:24:45,520 --> 00:24:51,679
within using ai we have

00:24:48,559 --> 00:24:52,799
taken the call we've taken the what

00:24:51,679 --> 00:24:54,000
somebody would have been

00:24:52,799 --> 00:24:56,559
would have done themselves the

00:24:54,000 --> 00:24:58,159
individual at the bank the ai did within

00:24:56,559 --> 00:25:00,080
literally a few seconds

00:24:58,159 --> 00:25:02,400
and as you can see has categorized the

00:25:00,080 --> 00:25:05,279
spin according to what it picked up

00:25:02,400 --> 00:25:07,039
and then at the top it's then quantified

00:25:05,279 --> 00:25:09,120
a disposable income

00:25:07,039 --> 00:25:10,480
which says okay great um you've got that

00:25:09,120 --> 00:25:14,080
disposable income

00:25:10,480 --> 00:25:16,320
and then you can carry on further with

00:25:14,080 --> 00:25:18,240
the the learning natural gods so that's

00:25:16,320 --> 00:25:21,360
how i came back with the figure saying

00:25:18,240 --> 00:25:24,400
that i qualify for a loan of 6 500

00:25:21,360 --> 00:25:24,400
of so many months

00:25:24,480 --> 00:25:27,200
and just to show you the various

00:25:25,919 --> 00:25:28,480
attributes that we have taken into

00:25:27,200 --> 00:25:30,400
consideration

00:25:28,480 --> 00:25:31,840
is that we plug into the credit bureaus

00:25:30,400 --> 00:25:33,840
as i said in south africa

00:25:31,840 --> 00:25:35,600
so we tend to take all these account

00:25:33,840 --> 00:25:39,840
details we pick this up

00:25:35,600 --> 00:25:42,159
and these are all part of of um

00:25:39,840 --> 00:25:43,279
of the attributes that we consider

00:25:42,159 --> 00:25:46,000
during doing

00:25:43,279 --> 00:25:47,679
doing ir but let's just get back let's

00:25:46,000 --> 00:25:50,880
just take one step back

00:25:47,679 --> 00:25:53,120
regarding the the the the process of

00:25:50,880 --> 00:25:55,919
just doing bank statement analysis

00:25:53,120 --> 00:25:56,480
but the prediction process of it as well

00:25:55,919 --> 00:25:58,400
is that

00:25:56,480 --> 00:26:00,159
it's not as simple as what people tend

00:25:58,400 --> 00:26:03,679
to think is that you take

00:26:00,159 --> 00:26:05,440
two million observations you have 130

00:26:03,679 --> 00:26:06,559
attributes and you've got a target value

00:26:05,440 --> 00:26:08,720
target values

00:26:06,559 --> 00:26:10,159
you then as you know machine learning is

00:26:08,720 --> 00:26:11,520
is

00:26:10,159 --> 00:26:13,440
supervised so it learns from

00:26:11,520 --> 00:26:14,960
pre-previous data

00:26:13,440 --> 00:26:16,240
and but it's not as simple as that when

00:26:14,960 --> 00:26:17,840
it comes to finance you've got to

00:26:16,240 --> 00:26:21,679
consider various things

00:26:17,840 --> 00:26:21,679
you've got to you've got to understand

00:26:22,320 --> 00:26:26,320
your role rates what we mean by roll

00:26:24,320 --> 00:26:28,880
rate if a person defaults on the first

00:26:26,320 --> 00:26:30,159
month do we consider that as default no

00:26:28,880 --> 00:26:32,400
something could have happened they could

00:26:30,159 --> 00:26:33,919
have changed banks do we if the person

00:26:32,400 --> 00:26:35,039
defaults in the second month do we

00:26:33,919 --> 00:26:37,760
consider that

00:26:35,039 --> 00:26:38,159
well maybe maybe not but on the third

00:26:37,760 --> 00:26:39,919
month

00:26:38,159 --> 00:26:41,360
we then should start considering yes

00:26:39,919 --> 00:26:43,039
this is a defaulted person

00:26:41,360 --> 00:26:44,640
but what sometimes happens is that they

00:26:43,039 --> 00:26:46,480
might default on the second month

00:26:44,640 --> 00:26:48,080
but pay on the third month so that is

00:26:46,480 --> 00:26:49,760
where your roll rates you need to work

00:26:48,080 --> 00:26:50,559
out what your roll rate is and vintage

00:26:49,760 --> 00:26:52,880
analysis

00:26:50,559 --> 00:26:53,919
so what vintage analysis is is literally

00:26:52,880 --> 00:26:56,960
taking previous

00:26:53,919 --> 00:26:59,760
months and looking what is your your

00:26:56,960 --> 00:27:01,840
your default rate and your loss rate in

00:26:59,760 --> 00:27:05,120
natural god looking at

00:27:01,840 --> 00:27:06,159
at previous data and and besides that if

00:27:05,120 --> 00:27:09,279
you had to look at

00:27:06,159 --> 00:27:09,600
um the various attributes that you take

00:27:09,279 --> 00:27:11,279
into

00:27:09,600 --> 00:27:12,559
consideration if you look at weights of

00:27:11,279 --> 00:27:13,360
evidence so essentially what weight of

00:27:12,559 --> 00:27:14,799
evidence is

00:27:13,360 --> 00:27:17,120
if you had to look at somebody that's

00:27:14,799 --> 00:27:20,399
got a disease um

00:27:17,120 --> 00:27:23,120
let's take uh cancer um there's

00:27:20,399 --> 00:27:24,480
all flu you've got five attributes um

00:27:23,120 --> 00:27:27,279
you've got a cough

00:27:24,480 --> 00:27:28,320
you've got a runny nose your throat's

00:27:27,279 --> 00:27:30,000
sore

00:27:28,320 --> 00:27:32,080
your chest is tight and you've got a

00:27:30,000 --> 00:27:34,720
headache now

00:27:32,080 --> 00:27:36,799
you could weight those accordingly um to

00:27:34,720 --> 00:27:38,640
predict that you would get a flu

00:27:36,799 --> 00:27:40,000
but they're not all weighted at the same

00:27:38,640 --> 00:27:41,279
time because you could have a headache

00:27:40,000 --> 00:27:42,480
in here that could mean that you haven't

00:27:41,279 --> 00:27:44,159
had enough sleep

00:27:42,480 --> 00:27:45,840
um you haven't had enough water for the

00:27:44,159 --> 00:27:46,720
day so the waiting on that would be very

00:27:45,840 --> 00:27:49,279
minimal

00:27:46,720 --> 00:27:50,720
but if you've got a flu a running nose

00:27:49,279 --> 00:27:53,039
would have higher weighting so your

00:27:50,720 --> 00:27:55,120
weighting evidence and information value

00:27:53,039 --> 00:27:57,200
on a runny nose would be a lot higher

00:27:55,120 --> 00:27:59,520
because if you've got a rain nose

00:27:57,200 --> 00:28:00,480
the chances are good you've got the flu

00:27:59,520 --> 00:28:03,279
and the same with

00:28:00,480 --> 00:28:04,240
um you if your chest is if you you've

00:28:03,279 --> 00:28:06,320
got a cough

00:28:04,240 --> 00:28:07,600
um if you it doesn't necessarily mean

00:28:06,320 --> 00:28:08,880
that you're coughing because you got the

00:28:07,600 --> 00:28:09,520
flu there could be something stuck in

00:28:08,880 --> 00:28:11,200
your throat

00:28:09,520 --> 00:28:13,200
so your weighting will be a lot less in

00:28:11,200 --> 00:28:14,960
that regard so those are the various

00:28:13,200 --> 00:28:17,600
things that we need to consider

00:28:14,960 --> 00:28:19,360
when we incorporate these algorithms and

00:28:17,600 --> 00:28:21,840
use them to predict

00:28:19,360 --> 00:28:22,559
the whether a person has defaulted or

00:28:21,840 --> 00:28:25,760
not

00:28:22,559 --> 00:28:26,799
and um there's a lot of algorithm yeah

00:28:25,760 --> 00:28:28,960
and jeremy i don't want to

00:28:26,799 --> 00:28:30,640
cut your demo short but we're getting

00:28:28,960 --> 00:28:31,600
close we have about five minutes left

00:28:30,640 --> 00:28:33,760
and we do have

00:28:31,600 --> 00:28:36,159
a number of good questions in the chat

00:28:33,760 --> 00:28:37,840
there so hopefully you and wallet could

00:28:36,159 --> 00:28:40,080
start to address those

00:28:37,840 --> 00:28:40,960
so the first one we had was from james

00:28:40,080 --> 00:28:43,360
and he was

00:28:40,960 --> 00:28:44,799
you know mentioning the usage of

00:28:43,360 --> 00:28:46,880
federated machine learning

00:28:44,799 --> 00:28:48,080
algorithms and i think this aligns very

00:28:46,880 --> 00:28:49,279
well with the approaches we were

00:28:48,080 --> 00:28:50,960
proposing

00:28:49,279 --> 00:28:53,760
lawlett so perhaps if you both could

00:28:50,960 --> 00:28:56,880
respond to james's question there

00:28:53,760 --> 00:28:58,399
and then sonker and godfrey had some

00:28:56,880 --> 00:29:00,000
questions as well so we'll try to get to

00:28:58,399 --> 00:29:02,480
all of those

00:29:00,000 --> 00:29:02,480
okay great

00:29:03,039 --> 00:29:06,559
do you want to give the first one go

00:29:05,120 --> 00:29:09,360
yeah yeah

00:29:06,559 --> 00:29:11,200
i'll go ahead so james yeah we have

00:29:09,360 --> 00:29:11,840
taken the federated approach we are not

00:29:11,200 --> 00:29:15,039
saying

00:29:11,840 --> 00:29:16,960
this is the only algorithm and

00:29:15,039 --> 00:29:18,559
when we say federated yeah there would

00:29:16,960 --> 00:29:21,679
be multiple algorithms that

00:29:18,559 --> 00:29:24,559
could come back and make one prediction

00:29:21,679 --> 00:29:26,399
and even for models there will be

00:29:24,559 --> 00:29:27,760
multiple models or multiple machine

00:29:26,399 --> 00:29:28,320
learning algorithms that would be

00:29:27,760 --> 00:29:31,120
available

00:29:28,320 --> 00:29:31,600
in the tool set uh we are not proposing

00:29:31,120 --> 00:29:34,799
a

00:29:31,600 --> 00:29:38,480
model or a algorithm so

00:29:34,799 --> 00:29:40,320
we have taken what we are also doing is

00:29:38,480 --> 00:29:42,159
in the proposed approach we are saying

00:29:40,320 --> 00:29:44,799
not only limiting to

00:29:42,159 --> 00:29:45,679
the on-premises but we would make it

00:29:44,799 --> 00:29:49,360
available as an

00:29:45,679 --> 00:29:51,360
api so if you think that or if the

00:29:49,360 --> 00:29:52,840
community thinks that there is a

00:29:51,360 --> 00:29:55,919
powerful

00:29:52,840 --> 00:29:59,440
uh tool set that's available with

00:29:55,919 --> 00:30:01,279
azure or aws or h2o

00:29:59,440 --> 00:30:02,880
they would have that flexibility to go

00:30:01,279 --> 00:30:05,840
and connect to

00:30:02,880 --> 00:30:05,840
do the modeling or

00:30:07,200 --> 00:30:10,720
that machine learning stuff

00:30:09,360 --> 00:30:14,240
[Music]

00:30:10,720 --> 00:30:14,799
if i can just add on to that james is

00:30:14,240 --> 00:30:18,640
that

00:30:14,799 --> 00:30:20,880
we part of my dissertation was is that

00:30:18,640 --> 00:30:22,080
i used deep learning to do credit

00:30:20,880 --> 00:30:25,039
scoring and

00:30:22,080 --> 00:30:25,440
and just to answer that thing as as as

00:30:25,039 --> 00:30:27,760
things

00:30:25,440 --> 00:30:30,159
tend to progress from a data point of

00:30:27,760 --> 00:30:31,600
view and big data data mining is that

00:30:30,159 --> 00:30:33,520
using iot you've got a lot of

00:30:31,600 --> 00:30:35,440
unstructured data and a lot of your

00:30:33,520 --> 00:30:37,120
algorithms that are being used now for

00:30:35,440 --> 00:30:38,000
credit scoring is your machine learning

00:30:37,120 --> 00:30:40,240
algorithms

00:30:38,000 --> 00:30:42,640
so we are we are starting to test the

00:30:40,240 --> 00:30:44,559
day around using deep neural networks

00:30:42,640 --> 00:30:46,480
to do credit scoring on on other

00:30:44,559 --> 00:30:48,240
structured data that's very dimensional

00:30:46,480 --> 00:30:50,399
in that regard

00:30:48,240 --> 00:30:51,600
because obviously neural networks love

00:30:50,399 --> 00:30:53,919
complex data

00:30:51,600 --> 00:30:55,360
um not your your straight to the

00:30:53,919 --> 00:30:57,440
straightforward

00:30:55,360 --> 00:30:58,640
kind of data that you would get where do

00:30:57,440 --> 00:31:01,120
you love age

00:30:58,640 --> 00:31:02,399
how much is your salary etc um you can

00:31:01,120 --> 00:31:04,399
start tapping into

00:31:02,399 --> 00:31:05,760
social media your digital footprint can

00:31:04,399 --> 00:31:07,760
be very completely very

00:31:05,760 --> 00:31:09,360
powerful natural god just adding on to

00:31:07,760 --> 00:31:12,159
that and then saying

00:31:09,360 --> 00:31:14,640
your question yeah so jeremy i was like

00:31:12,159 --> 00:31:17,440
you're going to tackle those two so

00:31:14,640 --> 00:31:19,279
okay how are you generating the data so

00:31:17,440 --> 00:31:20,720
in south africa we've um

00:31:19,279 --> 00:31:22,720
we've been doing it for a few years

00:31:20,720 --> 00:31:24,559
we've gathered data but just to give an

00:31:22,720 --> 00:31:25,360
idea there's various if you go look on

00:31:24,559 --> 00:31:28,320
ucl

00:31:25,360 --> 00:31:30,399
demo um where they're used for kaggle

00:31:28,320 --> 00:31:32,000
there's various datasets that you can

00:31:30,399 --> 00:31:34,559
get from there and there's dynamic

00:31:32,000 --> 00:31:35,679
data that one can use predominantly a

00:31:34,559 --> 00:31:39,679
person's age

00:31:35,679 --> 00:31:42,320
um where um do you own a home

00:31:39,679 --> 00:31:43,760
um what is your salary what is your

00:31:42,320 --> 00:31:45,840
credit risk

00:31:43,760 --> 00:31:46,960
um do you have children are you married

00:31:45,840 --> 00:31:50,080
are you divorced

00:31:46,960 --> 00:31:50,399
how um you know those various attributes

00:31:50,080 --> 00:31:52,720
those

00:31:50,399 --> 00:31:54,000
are dynamic attributes that one can use

00:31:52,720 --> 00:31:55,679
and that's where this whole

00:31:54,000 --> 00:31:57,360
this whole idea is coming of democ

00:31:55,679 --> 00:32:00,559
democratizing

00:31:57,360 --> 00:32:02,799
ai and data is that we need to

00:32:00,559 --> 00:32:05,039
slowly but surely get all the other data

00:32:02,799 --> 00:32:06,559
forms um to build the ai models

00:32:05,039 --> 00:32:08,240
um going forward and obviously from a

00:32:06,559 --> 00:32:09,279
digital footprint coming back to what

00:32:08,240 --> 00:32:11,760
james asked

00:32:09,279 --> 00:32:13,360
using neural networks using a lot of

00:32:11,760 --> 00:32:15,600
other data

00:32:13,360 --> 00:32:17,440
lakes that one can tap into it's not

00:32:15,600 --> 00:32:21,279
just your normal fundamental

00:32:17,440 --> 00:32:24,559
um personal your kyc process

00:32:21,279 --> 00:32:27,039
what is your id now what is your age

00:32:24,559 --> 00:32:28,559
data that you can use but you need to

00:32:27,039 --> 00:32:30,240
the the thing is that you need a lot of

00:32:28,559 --> 00:32:32,399
data obviously to train your models but

00:32:30,240 --> 00:32:34,399
using deep learning and one example is

00:32:32,399 --> 00:32:36,159
using a deep belief neural network

00:32:34,399 --> 00:32:38,080
which creates which actually uses a

00:32:36,159 --> 00:32:39,919
restricted boltzmann machine

00:32:38,080 --> 00:32:42,159
creates features on its own and then

00:32:39,919 --> 00:32:45,600
uses a free forward um

00:32:42,159 --> 00:32:48,480
neural net after that to go further

00:32:45,600 --> 00:32:48,480
they are for fraud

00:32:49,120 --> 00:32:52,159
yeah so god please they're based in

00:32:50,559 --> 00:32:55,200
south africa as well

00:32:52,159 --> 00:32:56,720
jeremy so not sure if you can speak to

00:32:55,200 --> 00:32:58,960
any of the pushback coming from the

00:32:56,720 --> 00:33:02,080
banks or lessons you've learned so far

00:32:58,960 --> 00:33:04,159
in working with them sure

00:33:02,080 --> 00:33:06,559
um from datasets i'll give you a perfect

00:33:04,159 --> 00:33:07,600
example we we went to saudi arabia last

00:33:06,559 --> 00:33:09,840
year to start

00:33:07,600 --> 00:33:10,960
a digital bank in saudi arabia and that

00:33:09,840 --> 00:33:11,919
was one of the very interesting

00:33:10,960 --> 00:33:13,360
environments

00:33:11,919 --> 00:33:14,880
um because obviously you've got to go

00:33:13,360 --> 00:33:15,919
according to legislation obviously with

00:33:14,880 --> 00:33:17,600
the gdpr

00:33:15,919 --> 00:33:20,000
and south africa we've got the papaya

00:33:17,600 --> 00:33:22,480
act um in

00:33:20,000 --> 00:33:23,120
saudi arabia no data is allowed to give

00:33:22,480 --> 00:33:25,440
the country

00:33:23,120 --> 00:33:26,559
so everything needs to be in country so

00:33:25,440 --> 00:33:28,799
that makes your

00:33:26,559 --> 00:33:30,159
your whole paradigm a lot more

00:33:28,799 --> 00:33:32,240
interesting because

00:33:30,159 --> 00:33:33,360
people are very secretive of data over

00:33:32,240 --> 00:33:36,399
there and and

00:33:33,360 --> 00:33:39,760
and and and rightfully so um

00:33:36,399 --> 00:33:41,519
so that makes it very difficult to

00:33:39,760 --> 00:33:42,960
build ai and models in that regard so

00:33:41,519 --> 00:33:44,960
what we did in that

00:33:42,960 --> 00:33:47,200
in that scenario we went to all the

00:33:44,960 --> 00:33:47,919
credit bureaus in saudi arabia and we

00:33:47,200 --> 00:33:49,919
went and had

00:33:47,919 --> 00:33:51,840
meetings with them and try to find out

00:33:49,919 --> 00:33:54,159
with who we could build up a

00:33:51,840 --> 00:33:54,960
relationship to get data from them past

00:33:54,159 --> 00:33:57,440
data

00:33:54,960 --> 00:33:58,080
to create our ai models going forward

00:33:57,440 --> 00:34:00,640
and

00:33:58,080 --> 00:34:02,799
and a few of them were willing to to to

00:34:00,640 --> 00:34:04,960
uh to accommodate us in that way

00:34:02,799 --> 00:34:06,640
obviously being part of the process and

00:34:04,960 --> 00:34:08,800
us using them as a service

00:34:06,640 --> 00:34:09,679
but that was another avenue of getting

00:34:08,800 --> 00:34:11,599
that data

00:34:09,679 --> 00:34:14,000
and and producing data sets in that

00:34:11,599 --> 00:34:14,000
regard

00:34:14,800 --> 00:34:18,079
and then jeremy i think there's two last

00:34:16,639 --> 00:34:20,000
quick questions and then i think we'll

00:34:18,079 --> 00:34:22,560
wrap up so others can go to the next

00:34:20,000 --> 00:34:25,040
panel but one more question from sankar

00:34:22,560 --> 00:34:26,960
and then not two had a question around

00:34:25,040 --> 00:34:28,800
regulatory perspective on deep learning

00:34:26,960 --> 00:34:30,320
for credit risk

00:34:28,800 --> 00:34:32,639
highs authenticity of the submitted

00:34:30,320 --> 00:34:35,440
documents

00:34:32,639 --> 00:34:36,800
so on our bank statements with our banks

00:34:35,440 --> 00:34:39,679
there's various

00:34:36,800 --> 00:34:41,520
points on the statements that we that we

00:34:39,679 --> 00:34:44,159
know that the statements are

00:34:41,520 --> 00:34:46,399
are valid but besides that we do bank

00:34:44,159 --> 00:34:49,359
validation and i can show you that

00:34:46,399 --> 00:34:51,040
using um if you look at my screen we do

00:34:49,359 --> 00:34:52,639
bank validation at the bottom this is

00:34:51,040 --> 00:34:54,960
what we use in south africa

00:34:52,639 --> 00:34:56,720
so from your bank statements and and

00:34:54,960 --> 00:34:58,480
doing a bank validation

00:34:56,720 --> 00:34:59,920
we then speak to the credit bureau and

00:34:58,480 --> 00:35:01,359
we actually talk to the bank and say is

00:34:59,920 --> 00:35:03,440
this one of your customers

00:35:01,359 --> 00:35:05,520
so obviously you can't smackdown so

00:35:03,440 --> 00:35:09,200
they'll say the account numbers open

00:35:05,520 --> 00:35:11,119
id number match yes initials match no

00:35:09,200 --> 00:35:12,560
could be uh because my name is jeremy

00:35:11,119 --> 00:35:15,920
andrew peter

00:35:12,560 --> 00:35:17,599
i generally just use jp

00:35:15,920 --> 00:35:19,760
name match no maybe because i'm just

00:35:17,599 --> 00:35:22,640
using jeremy so in that regard

00:35:19,760 --> 00:35:24,640
we then quantify an authenticity of data

00:35:22,640 --> 00:35:26,560
we then use this as a benchmark

00:35:24,640 --> 00:35:29,440
and that's part of our affordability or

00:35:26,560 --> 00:35:34,160
our analysis process to quantify if you

00:35:29,440 --> 00:35:37,839
already are and conclude the kyc process

00:35:34,160 --> 00:35:40,160
so uh and if we could just add

00:35:37,839 --> 00:35:42,640
uh one approach we have taken in the

00:35:40,160 --> 00:35:45,520
credit risk rating or credit scoring in

00:35:42,640 --> 00:35:46,240
me first part of the project is we also

00:35:45,520 --> 00:35:49,359
are doing

00:35:46,240 --> 00:35:53,680
rule-based under statistical measure

00:35:49,359 --> 00:35:56,720
so that if with its black box in nature

00:35:53,680 --> 00:35:59,040
comes back and makes some recommendation

00:35:56,720 --> 00:36:00,400
the user of the system can validate what

00:35:59,040 --> 00:36:02,640
is the rule based saying

00:36:00,400 --> 00:36:03,839
and what is the statistical approach

00:36:02,640 --> 00:36:05,680
that's coming out

00:36:03,839 --> 00:36:07,280
that they they have a complete view of

00:36:05,680 --> 00:36:09,760
all the approaches and then make a

00:36:07,280 --> 00:36:09,760
decision

00:36:09,920 --> 00:36:14,320
i know there is a lot of interest that's

00:36:12,000 --> 00:36:16,800
building on explainable ai

00:36:14,320 --> 00:36:18,800
um and there are a lot of constraints

00:36:16,800 --> 00:36:21,920
that are coming out from regulators

00:36:18,800 --> 00:36:24,400
from perspective in terms of using ai

00:36:21,920 --> 00:36:26,880
models that are more explainable so

00:36:24,400 --> 00:36:28,079
uh interestingly in our approach we have

00:36:26,880 --> 00:36:30,720
seen

00:36:28,079 --> 00:36:32,240
the decision tree based models

00:36:30,720 --> 00:36:34,160
performing relatively better

00:36:32,240 --> 00:36:38,560
in in the terms of the data set that we

00:36:34,160 --> 00:36:38,560
have which are certainly explainable

00:36:38,640 --> 00:36:45,280
on which there would be little

00:36:42,079 --> 00:36:47,920
or probably lesser uh pushbacks from the

00:36:45,280 --> 00:36:47,920
regulators

00:36:48,320 --> 00:36:50,880
yes thanks

00:36:52,960 --> 00:36:56,880
sorry oh no go on jeremy no i agree with

00:36:55,839 --> 00:36:59,839
it is that um

00:36:56,880 --> 00:37:01,040
you know we continuously try and use our

00:36:59,839 --> 00:37:02,960
other algorithms to

00:37:01,040 --> 00:37:04,480
to quantify a better approach but one of

00:37:02,960 --> 00:37:05,920
the questions is um

00:37:04,480 --> 00:37:07,280
are you allowed to use deep learning for

00:37:05,920 --> 00:37:08,000
credit risk well you're allowed to use

00:37:07,280 --> 00:37:10,240
any algorithm

00:37:08,000 --> 00:37:12,800
that you want um as long as you can

00:37:10,240 --> 00:37:16,079
quantify using a confusion matrix

00:37:12,800 --> 00:37:16,640
um you those metrics you can produce and

00:37:16,079 --> 00:37:19,920
do

00:37:16,640 --> 00:37:21,520
doing statistical analysis on your

00:37:19,920 --> 00:37:23,119
on the metrics that you produce and you

00:37:21,520 --> 00:37:25,200
can show that to the bank

00:37:23,119 --> 00:37:27,760
that this is this is the scoring and

00:37:25,200 --> 00:37:29,359
also as i let mentioned using explainers

00:37:27,760 --> 00:37:30,800
and they're also showing the waiting on

00:37:29,359 --> 00:37:32,560
the various attributes

00:37:30,800 --> 00:37:34,079
you need to produce that and show the

00:37:32,560 --> 00:37:36,400
banks listen this

00:37:34,079 --> 00:37:37,520
is we this is not just a black box i

00:37:36,400 --> 00:37:39,599
think i don't know if you've heard the

00:37:37,520 --> 00:37:40,960
the theory the black box theory where

00:37:39,599 --> 00:37:42,560
you use a deep you use the neural

00:37:40,960 --> 00:37:43,680
network nobody knows what it's doing but

00:37:42,560 --> 00:37:45,680
it actually does what it

00:37:43,680 --> 00:37:47,440
actually does the job pretty well but

00:37:45,680 --> 00:37:49,760
obviously using explainers as

00:37:47,440 --> 00:37:51,200
mentioned we can we can dive deeper into

00:37:49,760 --> 00:37:52,800
the algorithm and understand what the

00:37:51,200 --> 00:37:55,040
algorithm has actually done

00:37:52,800 --> 00:37:56,000
and hence there's various on a deep from

00:37:55,040 --> 00:37:58,079
a deep learning

00:37:56,000 --> 00:37:59,839
perspective you could use uh there's a

00:37:58,079 --> 00:38:01,200
lot of algorithms in that regard but

00:37:59,839 --> 00:38:01,839
once again going back to what they led

00:38:01,200 --> 00:38:04,240
said

00:38:01,839 --> 00:38:06,240
the decision trees while dragon booster

00:38:04,240 --> 00:38:08,160
decision trees are very powerful in that

00:38:06,240 --> 00:38:10,880
robot

00:38:08,160 --> 00:38:12,160
and so thank you uh jeremy and lalit we

00:38:10,880 --> 00:38:13,920
ran over a little bit but

00:38:12,160 --> 00:38:15,359
we're gonna let the next session get

00:38:13,920 --> 00:38:16,960
started but i think we've got a small

00:38:15,359 --> 00:38:18,160
break after that so that one can run a

00:38:16,960 --> 00:38:20,079
little long too

00:38:18,160 --> 00:38:21,920
but really appreciate all the valuable

00:38:20,079 --> 00:38:23,680
questions that our

00:38:21,920 --> 00:38:25,599
audience brought to the table and we

00:38:23,680 --> 00:38:27,200
really look forward to help drive this

00:38:25,599 --> 00:38:29,599
roadmap for ai for all

00:38:27,200 --> 00:38:31,520
on top of the finrac platform and i

00:38:29,599 --> 00:38:32,800
pasted a link to how you can join the

00:38:31,520 --> 00:38:35,680
working group that we have

00:38:32,800 --> 00:38:37,040
on discourse so looking forward to

00:38:35,680 --> 00:38:38,560
incorporating more the partners and

00:38:37,040 --> 00:38:40,640
volunteers in the community

00:38:38,560 --> 00:38:42,480
who have expertise in ai to join this

00:38:40,640 --> 00:38:44,720
group so look forward to

00:38:42,480 --> 00:38:46,560
folks coming into our next session which

00:38:44,720 --> 00:38:48,560
is going to be on scalability

00:38:46,560 --> 00:38:49,680
and thank you again jeremy and lala

00:38:48,560 --> 00:38:52,400
looking forward to

00:38:49,680 --> 00:38:54,800
working with you in the community take

00:38:52,400 --> 00:38:54,800
care everyone

00:38:56,560 --> 00:39:01,839
cheerio bye bye bye

00:39:21,440 --> 00:39:23,520

YouTube URL: https://www.youtube.com/watch?v=DYceN6-HjpE


