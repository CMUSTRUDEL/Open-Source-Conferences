Title: State of Storage in Cloudstack
Publication date: 2019-09-20
Playlist: ApacheCon 2019, Cloudstack Collaboration Conference
Description: 
	With the increased focus and legislation around data sovereignty requirements, storage solutions play an increasingly important role in cloud infrastructures. We will present an overview of the evolution of storage orchestration in Apache CloudStack, with a focus on managed storage. It will also shed light on some upcoming features and the future direction.
Captions: 
	00:00:04,570 --> 00:00:12,100
so alright so welcome to my talk on the

00:00:08,889 --> 00:00:16,000
state of storage in Cossack not sure how

00:00:12,100 --> 00:00:19,450
good a job Google is doing tens litter

00:00:16,000 --> 00:00:21,220
ating or whatever it is does but some

00:00:19,450 --> 00:00:24,730
entertainment in case you know google

00:00:21,220 --> 00:00:27,369
makes mistakes it's it's late in the

00:00:24,730 --> 00:00:28,960
afternoon so you know people might be a

00:00:27,369 --> 00:00:31,980
bit sleepy I'm gonna try to keep

00:00:28,960 --> 00:00:34,510
thinking keep things brief in high level

00:00:31,980 --> 00:00:36,130
feel free to stop me if you guys have

00:00:34,510 --> 00:00:38,680
questions there's also a link at the top

00:00:36,130 --> 00:00:41,460
if you guys are too shy to stop me you

00:00:38,680 --> 00:00:47,760
can click there and ask questions there

00:00:41,460 --> 00:00:47,760
alright let's get started

00:00:52,170 --> 00:01:08,259
failure too much integration of Google

00:01:00,640 --> 00:01:12,550
things if I turn off some stuff you

00:01:08,259 --> 00:01:17,140
won't have the Google entertainment okay

00:01:12,550 --> 00:01:19,420
now works great so a little bit about me

00:01:17,140 --> 00:01:22,120
my name is SID

00:01:19,420 --> 00:01:24,250
I work at a company both caught up Clawd

00:01:22,120 --> 00:01:26,670
ops is a cloud consulting services

00:01:24,250 --> 00:01:29,890
company based out of Montreal Canada

00:01:26,670 --> 00:01:32,409
I've been involved in cloud stack since

00:01:29,890 --> 00:01:34,750
the beginning of the year and my focus

00:01:32,409 --> 00:01:37,750
has been working on the integration

00:01:34,750 --> 00:01:39,850
between cloud stack and sulfur so

00:01:37,750 --> 00:01:43,510
SolidFire is a storage appliance that's

00:01:39,850 --> 00:01:45,190
built by met up and it's kind of gonna

00:01:43,510 --> 00:01:48,299
be the focus of the talk in terms of

00:01:45,190 --> 00:01:52,990
example since that's what I worked on

00:01:48,299 --> 00:01:54,189
also an avid amateur cyclists wonder if

00:01:52,990 --> 00:01:55,479
there's any cyclists in the audience

00:01:54,189 --> 00:01:58,320
cool

00:01:55,479 --> 00:02:00,400
anyone done the Red Rock Canyon loop oh

00:01:58,320 --> 00:02:03,030
wow yeah I want to I want to check that

00:02:00,400 --> 00:02:07,619
out yeah that's a really nice read

00:02:03,030 --> 00:02:10,539
alright so a little bit about quad ups

00:02:07,619 --> 00:02:12,280
what ups our mission is to help our

00:02:10,539 --> 00:02:15,069
customers own their destinies in the

00:02:12,280 --> 00:02:16,580
cloud we help customers bottom the on

00:02:15,069 --> 00:02:19,700
the cloud consumption as well

00:02:16,580 --> 00:02:23,030
cloud delivery side or not kind of loyal

00:02:19,700 --> 00:02:24,860
to me particular sort of technology the

00:02:23,030 --> 00:02:25,940
cool thing about cloud ops is that we

00:02:24,860 --> 00:02:27,830
love open source and we try to

00:02:25,940 --> 00:02:31,490
incorporate that as much as possible in

00:02:27,830 --> 00:02:34,540
our solutions we work with customers

00:02:31,490 --> 00:02:38,690
across industry verticals so Telkom

00:02:34,540 --> 00:02:41,540
finance healthcare and what we're seeing

00:02:38,690 --> 00:02:42,970
is that more and more people are

00:02:41,540 --> 00:02:46,130
concerned about data sovereignty

00:02:42,970 --> 00:02:49,310
regulations where the data is living is

00:02:46,130 --> 00:02:51,680
important and organizations cannot

00:02:49,310 --> 00:02:53,930
always rely on sort of the public

00:02:51,680 --> 00:02:56,810
hyperscale cloud providers to meet their

00:02:53,930 --> 00:02:58,520
specific requirements so there is an

00:02:56,810 --> 00:03:00,680
there is a demand for having a regional

00:02:58,520 --> 00:03:02,420
cloud and create a regional trust just

00:03:00,680 --> 00:03:07,760
make sure the data stays where they need

00:03:02,420 --> 00:03:12,010
it to be quick overview of the agenda

00:03:07,760 --> 00:03:14,870
for today a little bit about cloud stack

00:03:12,010 --> 00:03:17,120
that deeper into storage and

00:03:14,870 --> 00:03:18,890
specifically managed storage and we'll

00:03:17,120 --> 00:03:23,950
talk about some of the recent changes

00:03:18,890 --> 00:03:26,480
around storage so what is cloud stack

00:03:23,950 --> 00:03:28,310
actually before I get started quick pull

00:03:26,480 --> 00:03:31,130
the audience are there any cloud stack

00:03:28,310 --> 00:03:33,980
newbies in the house anyone new to cloud

00:03:31,130 --> 00:03:36,800
sack oh cool I'll be talking to you guys

00:03:33,980 --> 00:03:38,720
because I'm also I'm also a relatively

00:03:36,800 --> 00:03:40,880
new to cloud stack I've been only

00:03:38,720 --> 00:03:43,760
working on it this year I've gotten a

00:03:40,880 --> 00:03:46,180
lot of help from my colleagues some of

00:03:43,760 --> 00:03:49,220
you might know will Syed classroom

00:03:46,180 --> 00:03:50,840
anyway we have our YouTube audience as

00:03:49,220 --> 00:03:52,730
well so some some people might find the

00:03:50,840 --> 00:03:55,250
intro slides useful I'll try to go over

00:03:52,730 --> 00:04:00,320
them quickly so the veterans don't get

00:03:55,250 --> 00:04:03,709
to work so cloud stack is essentially a

00:04:00,320 --> 00:04:05,390
cloud orchestration engine it supports a

00:04:03,709 --> 00:04:08,770
number of different types of hardware so

00:04:05,390 --> 00:04:12,320
we like to call it hypervisor agnostic

00:04:08,770 --> 00:04:15,200
one of the cool sort of features of

00:04:12,320 --> 00:04:18,859
cloud stack is that it has a relatively

00:04:15,200 --> 00:04:21,640
small deployment so another sort of open

00:04:18,859 --> 00:04:26,930
source software in the same space is

00:04:21,640 --> 00:04:28,930
OpenStack OpenStack kind of is much more

00:04:26,930 --> 00:04:30,630
complicated compared to cloud stack

00:04:28,930 --> 00:04:32,520
there's always the

00:04:30,630 --> 00:04:34,800
ongoing debate between monoliths and

00:04:32,520 --> 00:04:37,290
microservices OpenStack went the way of

00:04:34,800 --> 00:04:38,640
micro services one of the trade-offs you

00:04:37,290 --> 00:04:41,760
make when you build micro services is

00:04:38,640 --> 00:04:44,010
increased operational complexity this

00:04:41,760 --> 00:04:46,230
can be mitigated to certain extent

00:04:44,010 --> 00:04:47,640
through opera to true automation but

00:04:46,230 --> 00:04:50,610
it's still it's still a challenge that

00:04:47,640 --> 00:04:52,350
needs to be overcome so people who

00:04:50,610 --> 00:04:54,540
people tend to realize this I don't know

00:04:52,350 --> 00:04:56,550
if you guys know Kelsey Hightower he's a

00:04:54,540 --> 00:04:59,070
pretty famous kubernetes guy he works

00:04:56,550 --> 00:05:01,140
with the loop out he predicted a couple

00:04:59,070 --> 00:05:02,390
years ago that you know mana think one

00:05:01,140 --> 00:05:04,740
le'ts will be coming back into fashion

00:05:02,390 --> 00:05:08,010
you may be right there mean you might be

00:05:04,740 --> 00:05:10,350
onto something there so if you want to

00:05:08,010 --> 00:05:13,230
build a cloud with cloud stack all you

00:05:10,350 --> 00:05:16,260
need is cloud stack and a hypervisor

00:05:13,230 --> 00:05:19,590
and you have a cloud in real life things

00:05:16,260 --> 00:05:22,380
are bit more complicated so a simple

00:05:19,590 --> 00:05:23,880
deployment would look like something

00:05:22,380 --> 00:05:25,770
like this you'd have a management server

00:05:23,880 --> 00:05:32,390
you'd have cluster hypervisors and you

00:05:25,770 --> 00:05:36,860
have your storage if we zoom into the

00:05:32,390 --> 00:05:36,860
zoom into the management server here oh

00:05:37,760 --> 00:05:44,870
we have everything that's required to

00:05:41,970 --> 00:05:47,760
turn on a cloud built into one place so

00:05:44,870 --> 00:05:52,080
some people consider this easier to

00:05:47,760 --> 00:05:54,570
understand than OpenStack most of the

00:05:52,080 --> 00:05:57,180
functionality of the orchestration

00:05:54,570 --> 00:05:59,370
functionality is centered in the cloud

00:05:57,180 --> 00:06:01,770
stack kernel so the cloud stack kernel

00:05:59,370 --> 00:06:04,920
has concepts associated with the

00:06:01,770 --> 00:06:07,230
resources it needs to orchestrate the

00:06:04,920 --> 00:06:09,540
ability or sort of the way that cloud

00:06:07,230 --> 00:06:12,090
stack is able to orchestrate different

00:06:09,540 --> 00:06:14,790
types of hardware different hypervisors

00:06:12,090 --> 00:06:16,890
different storages and different network

00:06:14,790 --> 00:06:20,580
equipment is through a plug-in

00:06:16,890 --> 00:06:22,470
architecture so in order if you want

00:06:20,580 --> 00:06:24,240
cloud stack to orchestrate a specific

00:06:22,470 --> 00:06:27,300
type of hardware you can write a plug-in

00:06:24,240 --> 00:06:29,730
for it and you might potentially have to

00:06:27,300 --> 00:06:32,250
change other things in cloud stack the

00:06:29,730 --> 00:06:37,250
code base is it's a bit retro as we all

00:06:32,250 --> 00:06:42,990
know so it can be extended to to support

00:06:37,250 --> 00:06:44,039
many things another view of cloud stack

00:06:42,990 --> 00:06:47,069
in action

00:06:44,039 --> 00:06:50,610
well gloss over it for the sake of the

00:06:47,069 --> 00:06:52,199
new cloud stock users on the left we

00:06:50,610 --> 00:06:55,349
have sort of the consumers of the cloud

00:06:52,199 --> 00:06:57,659
stack API so you have your automation

00:06:55,349 --> 00:07:00,089
tools your monitoring your sis admin's

00:06:57,659 --> 00:07:02,580
and even even users if you're exposing

00:07:00,089 --> 00:07:04,800
the portal the users the cloud stack

00:07:02,580 --> 00:07:07,050
management server is backed by sequel

00:07:04,800 --> 00:07:10,740
database this is how it keeps track of

00:07:07,050 --> 00:07:13,319
things that it's orchestrating on the

00:07:10,740 --> 00:07:15,659
right you have you can't really read but

00:07:13,319 --> 00:07:17,759
I meant to show or this is actually a

00:07:15,659 --> 00:07:19,080
whole picture it's meant to show the

00:07:17,759 --> 00:07:22,830
different types of hypervisors that

00:07:19,080 --> 00:07:24,659
support as we go down you have network

00:07:22,830 --> 00:07:25,199
equipment like load balancers and

00:07:24,659 --> 00:07:31,139
firewalls

00:07:25,199 --> 00:07:34,460
and lastly different types of storage so

00:07:31,139 --> 00:07:37,730
you take a picture we can go back

00:07:34,460 --> 00:07:37,730
[Laughter]

00:07:38,689 --> 00:07:44,699
alright so at this point everyone who

00:07:42,869 --> 00:07:47,669
was you know cloud stacks newbies couple

00:07:44,699 --> 00:07:50,399
minutes ago or novice experts let's

00:07:47,669 --> 00:07:52,860
let's talk about storage

00:07:50,399 --> 00:07:56,399
I'll keep things high level you know as

00:07:52,860 --> 00:07:59,309
per my initial promise when it comes to

00:07:56,399 --> 00:08:01,949
storage in cloud stack you have sort of

00:07:59,309 --> 00:08:04,289
two main types of storage primary

00:08:01,949 --> 00:08:06,389
storage and secondary storage primary

00:08:04,289 --> 00:08:07,889
storage is your sort of hot storage

00:08:06,389 --> 00:08:09,509
that's where you put your expensive

00:08:07,889 --> 00:08:11,999
hardware that can have they can do a lot

00:08:09,509 --> 00:08:14,459
of I ops this is what kind of box this

00:08:11,999 --> 00:08:15,360
is mix mix up the disks of your or for

00:08:14,459 --> 00:08:18,180
your BMS that you're running in your

00:08:15,360 --> 00:08:19,729
cloud on the others hat on the other

00:08:18,180 --> 00:08:21,629
side you have secondary storage

00:08:19,729 --> 00:08:24,089
secondary storage is more of a warm

00:08:21,629 --> 00:08:25,680
storage here you want to optimize for

00:08:24,089 --> 00:08:28,439
you know low costs in the large amount

00:08:25,680 --> 00:08:31,620
of space here you store your snapshots

00:08:28,439 --> 00:08:33,269
your templates doesn't have to be as

00:08:31,620 --> 00:08:37,740
high performance and you know can be

00:08:33,269 --> 00:08:41,099
shared across your cluster in a cloud

00:08:37,740 --> 00:08:43,110
stack deployment we have a bunch of

00:08:41,099 --> 00:08:45,149
concepts that most people will be

00:08:43,110 --> 00:08:47,490
familiar with so in your data center

00:08:45,149 --> 00:08:51,240
you'll have different availability zones

00:08:47,490 --> 00:08:53,130
each available is own this was shown

00:08:51,240 --> 00:08:55,230
here is an availability zone each of a

00:08:53,130 --> 00:08:57,300
bit zones composed of a number of

00:08:55,230 --> 00:08:59,640
different pods a pods

00:08:57,300 --> 00:09:03,720
is an accession is essentially a probe

00:08:59,640 --> 00:09:07,260
into Iraq in your pods you have a bunch

00:09:03,720 --> 00:09:08,910
of compute clusters traditionally

00:09:07,260 --> 00:09:12,750
CloudStack you had to attach memory

00:09:08,910 --> 00:09:15,660
storage to your tier compute clusters I

00:09:12,750 --> 00:09:18,360
will see in in following slides how that

00:09:15,660 --> 00:09:20,399
has changed recently on the right you

00:09:18,360 --> 00:09:23,700
have your secondary storage secondary

00:09:20,399 --> 00:09:25,620
storage is shared zone wide and you know

00:09:23,700 --> 00:09:29,300
it doesn't have to be as performant so

00:09:25,620 --> 00:09:34,529
it's easier to distribute across your

00:09:29,300 --> 00:09:37,410
deployment before we get into managed

00:09:34,529 --> 00:09:42,390
storage let's look at a few sort of

00:09:37,410 --> 00:09:46,399
storage deployments well stack has the

00:09:42,390 --> 00:09:50,040
ability to leverage object storage

00:09:46,399 --> 00:09:52,079
object storage is as I guess it's

00:09:50,040 --> 00:09:54,060
popularized by the public cloud so

00:09:52,079 --> 00:09:57,570
hypervisors don't necessarily know how

00:09:54,060 --> 00:10:00,540
to talk HTTP and directly use object

00:09:57,570 --> 00:10:04,529
storage so the way that cloud stack gets

00:10:00,540 --> 00:10:06,540
around this is by implementing or making

00:10:04,529 --> 00:10:10,140
use of a sort of a cache or scratch area

00:10:06,540 --> 00:10:12,600
so in the case where for example you

00:10:10,140 --> 00:10:15,600
want to take a snapshot or your snapshot

00:10:12,600 --> 00:10:17,670
will be stored in your cache area and

00:10:15,600 --> 00:10:25,740
then transferred into your object

00:10:17,670 --> 00:10:27,329
storage using another sort of storage

00:10:25,740 --> 00:10:30,029
deployment that's gaining popularity is

00:10:27,329 --> 00:10:32,790
stuff I know a couple of people in the

00:10:30,029 --> 00:10:38,310
audience see you stuff Simon from ena

00:10:32,790 --> 00:10:40,230
and I forgot his name the cool part

00:10:38,310 --> 00:10:42,480
about Saif is that it runs on commodity

00:10:40,230 --> 00:10:45,360
hardware so you don't have to buy super

00:10:42,480 --> 00:10:48,149
expensive sand to to host your ear

00:10:45,360 --> 00:10:50,699
primary search and it has the ability to

00:10:48,149 --> 00:10:55,380
shrink it girl without service

00:10:50,699 --> 00:10:58,399
interruptions stuff is implemented or

00:10:55,380 --> 00:11:02,100
supported I think only on KPM currently

00:10:58,399 --> 00:11:06,449
Saif can expose both block storage as

00:11:02,100 --> 00:11:08,070
well as object storage ena uses stuff

00:11:06,449 --> 00:11:09,240
extensively they either use it for a

00:11:08,070 --> 00:11:11,190
hundred percent of their promise road

00:11:09,240 --> 00:11:13,230
and eventually will

00:11:11,190 --> 00:11:22,980
using it for their secondary storage

00:11:13,230 --> 00:11:26,280
once so all this to say why manage

00:11:22,980 --> 00:11:29,400
George this is sort of the PSD

00:11:26,280 --> 00:11:31,830
resistance of the of the presentation

00:11:29,400 --> 00:11:37,920
I'm not sure Jeff is happy Jeff is happy

00:11:31,830 --> 00:11:41,430
with my pronunciation so the whole

00:11:37,920 --> 00:11:45,390
concept of managed storage is to sort of

00:11:41,430 --> 00:11:47,550
convey that cloud stack has more

00:11:45,390 --> 00:11:51,480
granular control over over the storage

00:11:47,550 --> 00:11:52,860
that's Venus so the example that that

00:11:51,480 --> 00:11:55,470
can be used to kind of illustrate this

00:11:52,860 --> 00:12:00,900
is the difference between using an NFS

00:11:55,470 --> 00:12:03,120
share and using San for example so in a

00:12:00,900 --> 00:12:06,870
net NFS share what cloud stack sees is

00:12:03,120 --> 00:12:08,610
basically a giant file system it has no

00:12:06,870 --> 00:12:11,280
kind of knowledge of control about the

00:12:08,610 --> 00:12:13,770
underlying Hardware the way that it's

00:12:11,280 --> 00:12:15,770
leveraged or using cloud stack is all of

00:12:13,770 --> 00:12:20,580
your disks or files on your anniversary

00:12:15,770 --> 00:12:24,240
so this in contrast to when you have a

00:12:20,580 --> 00:12:27,360
managed storage or sand solution we'll

00:12:24,240 --> 00:12:30,420
talk about you know the cloud stack

00:12:27,360 --> 00:12:34,590
specifically can leverage sans specific

00:12:30,420 --> 00:12:37,530
features using using plugins so in a SAN

00:12:34,590 --> 00:12:41,120
you have a concept of managed disk or

00:12:37,530 --> 00:12:45,830
logical unit and you can map your

00:12:41,120 --> 00:12:48,570
virtual disks to a unit in your sand and

00:12:45,830 --> 00:12:51,450
most sense that they have features that

00:12:48,570 --> 00:12:52,980
can sort of manage the amount of

00:12:51,450 --> 00:12:59,640
performance you give to each each

00:12:52,980 --> 00:13:04,290
logical unit so these are sort of like

00:12:59,640 --> 00:13:05,550
the benefits of managed storage one

00:13:04,290 --> 00:13:07,950
could argue that you could achieve

00:13:05,550 --> 00:13:09,390
similar results if you have like many

00:13:07,950 --> 00:13:11,040
different denna fests with different

00:13:09,390 --> 00:13:12,350
performance characteristics then you

00:13:11,040 --> 00:13:14,760
plug them into your different clusters

00:13:12,350 --> 00:13:18,420
but this is a lot of operational

00:13:14,760 --> 00:13:20,880
overhead and I guess one of the sort of

00:13:18,420 --> 00:13:23,730
benefits of implementing managed storage

00:13:20,880 --> 00:13:24,960
in cloud stack is to have all of this

00:13:23,730 --> 00:13:31,680
orchestration

00:13:24,960 --> 00:13:34,260
be automated so like we saw from the

00:13:31,680 --> 00:13:36,810
example the things that the features

00:13:34,260 --> 00:13:39,710
that you can leverage from your managed

00:13:36,810 --> 00:13:42,860
storage our storage quality of service

00:13:39,710 --> 00:13:44,880
native steps adding capability

00:13:42,860 --> 00:13:47,220
multi-tenant functionality so for

00:13:44,880 --> 00:13:50,400
example specific access control to

00:13:47,220 --> 00:13:52,650
different areas of the storage we'll get

00:13:50,400 --> 00:13:58,800
into this in a bit more detail in the

00:13:52,650 --> 00:14:02,700
following slides so one of the main sort

00:13:58,800 --> 00:14:04,800
of things that I guess is a problem in a

00:14:02,700 --> 00:14:07,529
lot of clouds is the problem of noisy

00:14:04,800 --> 00:14:10,740
neighbors noisy neighbors

00:14:07,529 --> 00:14:12,420
refers to essentially having one of

00:14:10,740 --> 00:14:15,180
three workloads near clouds being really

00:14:12,420 --> 00:14:17,610
resource since that intensive so in the

00:14:15,180 --> 00:14:19,770
case where you were using NFS or our

00:14:17,610 --> 00:14:22,320
example of one managed storage you have

00:14:19,770 --> 00:14:23,670
no control about how the storage

00:14:22,320 --> 00:14:26,460
performance is distributed among your

00:14:23,670 --> 00:14:29,130
tenants one of the features that you get

00:14:26,460 --> 00:14:32,279
when using managed storage specifically

00:14:29,130 --> 00:14:36,050
qualifier is you can provision IAP spur

00:14:32,279 --> 00:14:41,310
on a per volume basis and even on per

00:14:36,050 --> 00:14:43,830
like group of cluster spaces so you can

00:14:41,310 --> 00:14:45,770
control the amount of sort of storage

00:14:43,830 --> 00:14:49,100
jobs that are allocated to your tenants

00:14:45,770 --> 00:14:52,320
this this is kind of almost expected in

00:14:49,100 --> 00:14:54,510
my users today I guess in the early days

00:14:52,320 --> 00:14:56,310
of cloud you know people otic migrated

00:14:54,510 --> 00:14:57,930
their workload from legacy to the cloud

00:14:56,310 --> 00:14:59,490
and the their database wouldn't work the

00:14:57,930 --> 00:15:02,490
same and they're like ok it's a cloud so

00:14:59,490 --> 00:15:04,709
we have to refactor our application but

00:15:02,490 --> 00:15:08,010
now I think even most public providers

00:15:04,709 --> 00:15:10,709
have sort of guaranteed I ops and this

00:15:08,010 --> 00:15:17,580
is something that can be provided even

00:15:10,709 --> 00:15:20,010
with cloud speed limit so just to dig it

00:15:17,580 --> 00:15:22,560
a bit more in the manage storage there

00:15:20,010 --> 00:15:25,140
are sue to sort of sort of concerns when

00:15:22,560 --> 00:15:27,480
regards to furbishing storage one of

00:15:25,140 --> 00:15:29,730
them is orchestration or the control

00:15:27,480 --> 00:15:33,260
plane so this is the functionality that

00:15:29,730 --> 00:15:35,700
is implemented in the cloud stack or

00:15:33,260 --> 00:15:38,259
this this is concerned with you know

00:15:35,700 --> 00:15:40,869
which storage do I want to use where

00:15:38,259 --> 00:15:43,989
provision 8 how much resources are need

00:15:40,869 --> 00:15:47,229
to I need to get from the storage the

00:15:43,989 --> 00:15:49,449
second part is more to deal with the

00:15:47,229 --> 00:15:51,100
provisioning so this is sort of an

00:15:49,449 --> 00:15:53,049
implementation detail this changes

00:15:51,100 --> 00:15:55,569
depending on your deployment depending

00:15:53,049 --> 00:15:59,249
on what hypervisor you using what

00:15:55,569 --> 00:16:01,929
storage you're using if it's sort of

00:15:59,249 --> 00:16:03,429
storage that requires a temporary store

00:16:01,929 --> 00:16:06,429
for example we saw an example with

00:16:03,429 --> 00:16:08,279
object store earlier whether we need to

00:16:06,429 --> 00:16:10,419
whether we can you know take a snapshot

00:16:08,279 --> 00:16:11,910
without pausing a vm or whether we need

00:16:10,419 --> 00:16:15,039
to pause a vm before taking a snapshot

00:16:11,910 --> 00:16:19,239
all of these sort of our provisioning or

00:16:15,039 --> 00:16:22,329
data plane inserts so this is a

00:16:19,239 --> 00:16:23,859
high-level view of how a storage plug-in

00:16:22,329 --> 00:16:27,100
kind of fills in the gap between these

00:16:23,859 --> 00:16:29,160
two concerns on the left you have the

00:16:27,100 --> 00:16:32,289
orchestration concern which is

00:16:29,160 --> 00:16:35,949
implemented in the cloud stack or it has

00:16:32,289 --> 00:16:37,779
it knows how to orchestrate or the

00:16:35,949 --> 00:16:41,910
concepts of you know volumes templates

00:16:37,779 --> 00:16:44,649
snapshots and migration of volumes and

00:16:41,910 --> 00:16:48,299
provisioning part basically is concerned

00:16:44,649 --> 00:16:52,449
with dealing with specific hardware so

00:16:48,299 --> 00:16:54,399
like if you were to take the example of

00:16:52,449 --> 00:16:56,529
integrating SolidFire with cloud stack

00:16:54,399 --> 00:16:58,329
you would need a storage plug-in that

00:16:56,529 --> 00:17:01,379
would know how to talk to us on fire

00:16:58,329 --> 00:17:05,879
plants know how to attach it to a

00:17:01,379 --> 00:17:08,230
hypervisor and other related sort of

00:17:05,879 --> 00:17:13,230
implementation specific provisioning

00:17:08,230 --> 00:17:16,799
concerns so here's the simple example of

00:17:13,230 --> 00:17:20,169
orchestration so say you have a disk

00:17:16,799 --> 00:17:23,019
somewhere on secondary storage you need

00:17:20,169 --> 00:17:25,209
to create VM from it so the steps that

00:17:23,019 --> 00:17:27,069
you need to follow are you know download

00:17:25,209 --> 00:17:30,549
the template from your object storage

00:17:27,069 --> 00:17:33,700
your primary storage and then your

00:17:30,549 --> 00:17:35,440
provisioning sort of concern is

00:17:33,700 --> 00:17:37,929
separated based on the type of storage

00:17:35,440 --> 00:17:40,059
that you have so if you have a file

00:17:37,929 --> 00:17:43,090
based storage you just download the file

00:17:40,059 --> 00:17:44,740
into your file storage if you have a

00:17:43,090 --> 00:17:46,899
block storage you might have to download

00:17:44,740 --> 00:17:50,710
it into a temporary store and then

00:17:46,899 --> 00:17:52,980
import it into your actual block device

00:17:50,710 --> 00:17:52,980
for me

00:17:53,369 --> 00:17:58,840
all right so so far we've seen sort of

00:17:56,740 --> 00:18:01,450
how storage plugins are leveraged in the

00:17:58,840 --> 00:18:05,200
orchestration process let's dig a bit

00:18:01,450 --> 00:18:06,580
deeper and look at what things that you

00:18:05,200 --> 00:18:15,999
need to implement in order to create a

00:18:06,580 --> 00:18:18,399
storage plugin essentially they're

00:18:15,999 --> 00:18:23,110
listed like the sort of main extension

00:18:18,399 --> 00:18:25,149
points where you would need to that you

00:18:23,110 --> 00:18:27,850
need to implement a nerd have a storage

00:18:25,149 --> 00:18:29,980
plugin the first one is the data store

00:18:27,850 --> 00:18:31,509
provider so this is essentially a way

00:18:29,980 --> 00:18:34,570
for CloudStack to reference this

00:18:31,509 --> 00:18:37,570
particular type of storage the second

00:18:34,570 --> 00:18:40,990
one is data store lifecycle so this is

00:18:37,570 --> 00:18:44,289
the interface that deals with attaching

00:18:40,990 --> 00:18:47,649
and removing particular type of storage

00:18:44,289 --> 00:18:50,320
the next one is data store driver this

00:18:47,649 --> 00:18:54,220
is sort of the meat of your storage

00:18:50,320 --> 00:18:56,619
plugin this has functions like create

00:18:54,220 --> 00:19:00,700
volume delete volume resize volume

00:18:56,619 --> 00:19:04,649
cetera lastly we have the sort of UI

00:19:00,700 --> 00:19:07,269
component so if you have any particular

00:19:04,649 --> 00:19:08,529
need for getting input from the user in

00:19:07,269 --> 00:19:12,159
the provisioning process this can be

00:19:08,529 --> 00:19:14,019
implemented with the UI component now

00:19:12,159 --> 00:19:17,100
you guys should check out the talk given

00:19:14,019 --> 00:19:20,169
by Rove it's from Shay blue and nanorack

00:19:17,100 --> 00:19:22,990
but they're modern iteration of the UI

00:19:20,169 --> 00:19:27,610
which is much easier to extend then the

00:19:22,990 --> 00:19:31,929
sort of retribution we have currently so

00:19:27,610 --> 00:19:33,850
once you have all of these pieces your

00:19:31,929 --> 00:19:36,159
plugin basically is the stone maven

00:19:33,850 --> 00:19:41,259
project it compiled into a needle

00:19:36,159 --> 00:19:44,740
package that you plug into that sack at

00:19:41,259 --> 00:19:47,169
this point I guess hope everyone has a

00:19:44,740 --> 00:19:49,080
high level understanding of how plugins

00:19:47,169 --> 00:19:52,450
are leveraged to implement storage

00:19:49,080 --> 00:19:55,029
orchestration in cloud stack in the next

00:19:52,450 --> 00:19:58,389
bit we're going to look at some of the

00:19:55,029 --> 00:20:03,149
recent changes around storage

00:19:58,389 --> 00:20:03,149
orchestration yeah

00:20:06,500 --> 00:20:13,140
so yeah I kind of lost over that so

00:20:09,780 --> 00:20:14,669
essentially you have storage appliance

00:20:13,140 --> 00:20:17,730
like if you take the example of

00:20:14,669 --> 00:20:19,830
SolidFire it is a physical device which

00:20:17,730 --> 00:20:23,159
has a bunch of drives in it that you

00:20:19,830 --> 00:20:24,990
plug into your cloud so in order to plug

00:20:23,159 --> 00:20:27,720
it into your cloud stack cloud you need

00:20:24,990 --> 00:20:29,580
a storage float which essentially knows

00:20:27,720 --> 00:20:31,789
how to orchestrate the stuff that you're

00:20:29,580 --> 00:20:31,789
doing

00:20:33,140 --> 00:20:42,240
all right so a lot of work has been done

00:20:38,549 --> 00:20:45,809
around managed storage all of this all

00:20:42,240 --> 00:20:48,570
these changes were done by Mike Tao ski

00:20:45,809 --> 00:20:54,049
from SolidFire and collaborating with

00:20:48,570 --> 00:20:56,820
others most of these are related to JVM

00:20:54,049 --> 00:20:58,020
not gonna spend like too much time

00:20:56,820 --> 00:21:00,059
getting into the details of these

00:20:58,020 --> 00:21:03,929
changes so you guys could look them up

00:21:00,059 --> 00:21:05,700
on on github I'll just go over some like

00:21:03,929 --> 00:21:10,049
high-level examples just let you guys

00:21:05,700 --> 00:21:14,010
have an idea of the types of things that

00:21:10,049 --> 00:21:18,179
you know you would do with - Jorge so

00:21:14,010 --> 00:21:20,220
one of the top were things that we kind

00:21:18,179 --> 00:21:22,620
of referenced earlier was that the

00:21:20,220 --> 00:21:25,110
ability to have primary storage at the

00:21:22,620 --> 00:21:28,049
zone level insert the cluster level so

00:21:25,110 --> 00:21:32,130
as we saw previously when when we're

00:21:28,049 --> 00:21:35,250
using NFS we have no sort of concept of

00:21:32,130 --> 00:21:37,770
the underlying implementation of the

00:21:35,250 --> 00:21:40,110
storage however when you're using a

00:21:37,770 --> 00:21:42,179
specific type of sand appliance like

00:21:40,110 --> 00:21:45,600
SolidFire the SolidFire

00:21:42,179 --> 00:21:48,659
API gives that stack more granular

00:21:45,600 --> 00:21:52,679
control over the storage so as a result

00:21:48,659 --> 00:21:54,659
of this using concepts like provisioned

00:21:52,679 --> 00:21:57,270
I ops as well as you know access control

00:21:54,659 --> 00:21:59,850
you're able to share a primary storage

00:21:57,270 --> 00:22:05,400
across different clusters in your

00:21:59,850 --> 00:22:08,580
deployment another issue that people

00:22:05,400 --> 00:22:11,190
face when migrating from you know a

00:22:08,580 --> 00:22:12,899
legacy sort of storage implementation to

00:22:11,190 --> 00:22:15,900
a manotaur implementation is how to

00:22:12,899 --> 00:22:18,870
manage their workload

00:22:15,900 --> 00:22:20,070
we talked quite a bit about how you know

00:22:18,870 --> 00:22:22,380
the storage plug-in helps the

00:22:20,070 --> 00:22:26,400
orchestration this is an example of that

00:22:22,380 --> 00:22:28,790
so the source plug-in can I can now sort

00:22:26,400 --> 00:22:32,059
of help users migrate their workloads

00:22:28,790 --> 00:22:35,580
from their legacy into managed storage

00:22:32,059 --> 00:22:37,440
relatively automated in the previous

00:22:35,580 --> 00:22:39,960
previously this would be a manual manual

00:22:37,440 --> 00:22:42,600
process where you'd have to have like a

00:22:39,960 --> 00:22:46,190
team of you know cloud sis it means

00:22:42,600 --> 00:22:46,190
manually migrating your workloads

00:22:47,540 --> 00:22:53,700
another feature that's kind of

00:22:50,300 --> 00:22:57,030
implemented through managed storage

00:22:53,700 --> 00:22:59,880
plugin is leveraging snapshotting

00:22:57,030 --> 00:23:02,910
capabilities that are implemented in the

00:22:59,880 --> 00:23:06,510
storage of plans so if we kind of take

00:23:02,910 --> 00:23:08,160
the example of k vm k vm natively

00:23:06,510 --> 00:23:10,320
supports snapshotting when you're using

00:23:08,160 --> 00:23:13,380
file based storage and it's and the

00:23:10,320 --> 00:23:15,330
disks are in the queue cow format but

00:23:13,380 --> 00:23:18,179
when you're using managed storage with k

00:23:15,330 --> 00:23:22,080
vm k vm doesn't know how to make the

00:23:18,179 --> 00:23:23,940
managed storage do a snapshot but the

00:23:22,080 --> 00:23:25,559
managed storage knows how to create

00:23:23,940 --> 00:23:29,490
snapshots of the volume set it's

00:23:25,559 --> 00:23:31,100
matching so the way that we can take

00:23:29,490 --> 00:23:33,570
advantage of this is to have cloud stack

00:23:31,100 --> 00:23:36,480
called the api of the managed storage

00:23:33,570 --> 00:23:39,570
and managed storage you know has much

00:23:36,480 --> 00:23:41,850
it's much closer to the to its disks and

00:23:39,570 --> 00:23:44,370
it knows much more about them

00:23:41,850 --> 00:23:46,290
it has specifically SolidFire has many

00:23:44,370 --> 00:23:49,110
capabilities around deduplicating data

00:23:46,290 --> 00:23:50,640
and compression so it's the best way to

00:23:49,110 --> 00:23:51,770
take a snapshot it'll be done in the

00:23:50,640 --> 00:23:53,700
most efficient way if you have your

00:23:51,770 --> 00:23:55,860
storage appliance to the snapshot

00:23:53,700 --> 00:23:59,990
instead of trying to make a copy of the

00:23:55,860 --> 00:23:59,990
volume by just duplicating the disk

00:24:06,140 --> 00:24:12,750
those are like some of these sort of

00:24:09,410 --> 00:24:14,540
high level features that were recently

00:24:12,750 --> 00:24:17,100
implemented or unmanaged storage I

00:24:14,540 --> 00:24:19,920
haven't gone into all of them we can

00:24:17,100 --> 00:24:23,550
talk in more detail later if you guys

00:24:19,920 --> 00:24:26,850
are interested in the other changes the

00:24:23,550 --> 00:24:29,690
next section I'd like to present a few

00:24:26,850 --> 00:24:34,450
issues that were reported

00:24:29,690 --> 00:24:34,450
by customers using managed storage

00:24:35,230 --> 00:24:43,160
let's get those so we had a customer

00:24:39,890 --> 00:24:46,970
report saying that they recently

00:24:43,160 --> 00:24:49,670
switched from using NFS to using so far

00:24:46,970 --> 00:24:52,010
and what they noticed was that when they

00:24:49,670 --> 00:24:54,770
were trying to create a VM the NFS VM

00:24:52,010 --> 00:24:56,150
would spin up in less than a minute and

00:24:54,770 --> 00:24:59,120
when they're trying to create a VM

00:24:56,150 --> 00:25:02,870
backed by a SolidFire it would take

00:24:59,120 --> 00:25:06,200
upwards of five minutes one thing to

00:25:02,870 --> 00:25:08,510
note about this customer is that they

00:25:06,200 --> 00:25:10,910
had a relatively large deployment so

00:25:08,510 --> 00:25:15,890
they had off the order of thousands of

00:25:10,910 --> 00:25:17,990
VMs and they had some automated

00:25:15,890 --> 00:25:21,620
snapshotting mechanisms so they had off

00:25:17,990 --> 00:25:23,810
the order of 10,000 snapshots and we

00:25:21,620 --> 00:25:26,510
kind of had trouble reproducing the

00:25:23,810 --> 00:25:29,990
issue in the lab because you know labs

00:25:26,510 --> 00:25:31,850
don't have that many things in them so

00:25:29,990 --> 00:25:35,690
it was quite quite an interesting

00:25:31,850 --> 00:25:37,150
journey trying to figure out what was

00:25:35,690 --> 00:25:40,670
causing the slowdown

00:25:37,150 --> 00:25:44,210
just to pick refresh for our you know

00:25:40,670 --> 00:25:47,210
cloud stack newbies I just have a

00:25:44,210 --> 00:25:50,840
diagram of how an API call works in

00:25:47,210 --> 00:25:52,610
cloud stack so cloud stack has an

00:25:50,840 --> 00:25:57,310
embedded HTTP server I think we use

00:25:52,610 --> 00:26:01,840
jetty previously it was it was Tomcat so

00:25:57,310 --> 00:26:04,700
your API call goes to your API servlet

00:26:01,840 --> 00:26:08,960
usually the API calls are in the form of

00:26:04,700 --> 00:26:11,020
commands and the API calls of are of two

00:26:08,960 --> 00:26:13,010
types so synchronous and asynchronous

00:26:11,020 --> 00:26:17,210
synchronous calls are usually database

00:26:13,010 --> 00:26:19,160
lookups and asynchronous calls are more

00:26:17,210 --> 00:26:24,290
sort of orchestration type activities

00:26:19,160 --> 00:26:26,000
which take longer so as soon as your

00:26:24,290 --> 00:26:28,820
call goes into cloud stack you get a

00:26:26,000 --> 00:26:30,440
response right away in both cases in one

00:26:28,820 --> 00:26:32,390
case you get back some information in

00:26:30,440 --> 00:26:33,980
the other case stuff happens in the

00:26:32,390 --> 00:26:39,410
background and you sort of wait for the

00:26:33,980 --> 00:26:42,050
result in this picture we see an example

00:26:39,410 --> 00:26:43,100
the command being executed so there's a

00:26:42,050 --> 00:26:44,120
DES pick

00:26:43,100 --> 00:26:47,900
of the colonel which has the

00:26:44,120 --> 00:26:49,910
orchestration logic the sort of

00:26:47,900 --> 00:26:53,950
provisioning specific analogies in the

00:26:49,910 --> 00:26:56,030
plugins and both these in combination

00:26:53,950 --> 00:27:00,110
communicate with the resources being

00:26:56,030 --> 00:27:05,080
managed and orchestrate or you know from

00:27:00,110 --> 00:27:05,080
the commander asked through the API so

00:27:05,620 --> 00:27:11,929
we took a deeper look into the VM

00:27:09,020 --> 00:27:14,929
deployment process I guess one of the

00:27:11,929 --> 00:27:16,640
hints that we had was that it works fine

00:27:14,929 --> 00:27:19,220
on manna-fest doesn't work so fine on

00:27:16,640 --> 00:27:20,809
SolidFire so we tried to look a bit

00:27:19,220 --> 00:27:24,650
deeper into which parts of the

00:27:20,809 --> 00:27:27,169
deployment process need to talk to talk

00:27:24,650 --> 00:27:30,169
to SolidFire so the thing to highlight

00:27:27,169 --> 00:27:34,370
in this picture is the call to allocate

00:27:30,169 --> 00:27:36,559
volumes there's a number of places in

00:27:34,370 --> 00:27:40,610
the sort of deployment process where we

00:27:36,559 --> 00:27:42,559
call the SolidFire driver we had to like

00:27:40,610 --> 00:27:44,960
do a couple of sessions and debug with

00:27:42,559 --> 00:27:48,409
the customer to see where the slowdown

00:27:44,960 --> 00:27:51,470
actually was it turned out that the

00:27:48,409 --> 00:27:55,070
problem was the way in which we computed

00:27:51,470 --> 00:27:56,510
the storage or the total storage that's

00:27:55,070 --> 00:27:59,780
currently being provisioned and storage

00:27:56,510 --> 00:28:02,120
available in the case of NFS this is a

00:27:59,780 --> 00:28:06,049
simple look at how big the file system

00:28:02,120 --> 00:28:08,360
is in the case of SolidFire this is not

00:28:06,049 --> 00:28:12,230
as simple the way that it was

00:28:08,360 --> 00:28:13,400
implemented is we look up to see all of

00:28:12,230 --> 00:28:15,470
the volumes that are being provisioned

00:28:13,400 --> 00:28:17,510
all of the snapshots that are associated

00:28:15,470 --> 00:28:19,100
with them all the templates that are in

00:28:17,510 --> 00:28:22,429
your storage and we add up the space

00:28:19,100 --> 00:28:24,890
used by each of them which which should

00:28:22,429 --> 00:28:27,350
be a simple database lookup but

00:28:24,890 --> 00:28:29,659
unfortunately the way that is

00:28:27,350 --> 00:28:32,270
implemented it resulted in a really

00:28:29,659 --> 00:28:34,210
large number of database queries so for

00:28:32,270 --> 00:28:36,530
some reason they were just squaring each

00:28:34,210 --> 00:28:38,000
volumes are presently each snapshots of

00:28:36,530 --> 00:28:41,390
look separately in each template

00:28:38,000 --> 00:28:44,179
separately so the fix was essentially to

00:28:41,390 --> 00:28:46,460
do a bit of refactor I guess for

00:28:44,179 --> 00:28:49,370
developers it's a fairly standard sort

00:28:46,460 --> 00:28:50,929
of code smell to have like a constant

00:28:49,370 --> 00:28:52,669
number of database calls when you're

00:28:50,929 --> 00:28:54,020
trying to do something instead of you

00:28:52,669 --> 00:28:57,440
know increasing number of data per calls

00:28:54,020 --> 00:28:59,989
as your employment grows in size

00:28:57,440 --> 00:29:02,029
once we sort of just did a single query

00:28:59,989 --> 00:29:04,220
to the database for each type and then

00:29:02,029 --> 00:29:06,499
we added up the storage in memory the

00:29:04,220 --> 00:29:10,659
issue went away we were you know having

00:29:06,499 --> 00:29:10,659
fast provisioning with old manifests and

00:29:11,619 --> 00:29:37,239
another issue that was reported was Sir

00:29:17,470 --> 00:29:40,429
sure yeah yeah you you much did yeah

00:29:37,239 --> 00:29:43,580
yeah I have some sort of not very clear

00:29:40,429 --> 00:29:44,720
descriptions and some of them had to do

00:29:43,580 --> 00:29:46,519
with some refactoring for the

00:29:44,720 --> 00:30:08,029
presentation but hopefully it's clear

00:29:46,519 --> 00:30:10,940
enough so we had this with KBM yeah yeah

00:30:08,029 --> 00:30:16,419
I think we yeah the most examples of

00:30:10,940 --> 00:30:20,769
that have shown are KVM specific so

00:30:16,419 --> 00:30:25,580
another issue that was reported was that

00:30:20,769 --> 00:30:31,450
a customer was not able to start Windows

00:30:25,580 --> 00:30:31,450
VMs with a certain number of ID disks so

00:30:31,809 --> 00:30:39,049
this was sort of like a interesting sort

00:30:35,690 --> 00:30:41,389
of example as well it was working fine

00:30:39,049 --> 00:30:44,359
with NFS not working

00:30:41,389 --> 00:30:47,210
what's all if our similar type of

00:30:44,359 --> 00:30:49,099
investigation was done in terms of

00:30:47,210 --> 00:30:53,269
finding out where in the call flow the

00:30:49,099 --> 00:30:57,950
issue could be in this case it turned

00:30:53,269 --> 00:31:01,639
out the issue was when we when we were

00:30:57,950 --> 00:31:07,580
talking to the KBM agent so a couple of

00:31:01,639 --> 00:31:10,309
sort of covets with with this issue the

00:31:07,580 --> 00:31:12,080
issue is only happening when they used

00:31:10,309 --> 00:31:16,700
when they try to create a VM from an ISO

00:31:12,080 --> 00:31:18,169
template not a regular template so the

00:31:16,700 --> 00:31:20,239
difference between an ISO template and

00:31:18,169 --> 00:31:23,210
the regular template is ISO templates

00:31:20,239 --> 00:31:25,519
are supposed to be hypervisor agnostic

00:31:23,210 --> 00:31:27,950
whereas a regular template is specific

00:31:25,519 --> 00:31:29,899
to a hypervisor so in a regular template

00:31:27,950 --> 00:31:31,099
you can specify which this controller

00:31:29,899 --> 00:31:33,409
you want which network controller you

00:31:31,099 --> 00:31:36,859
want and I suppose you don't have this

00:31:33,409 --> 00:31:38,029
option so the way that the

00:31:36,859 --> 00:31:43,039
implementation gets around the

00:31:38,029 --> 00:31:45,529
difference is in specifically in KBM we

00:31:43,039 --> 00:31:47,989
try to guess the sort of hardware

00:31:45,529 --> 00:31:51,469
associated with an ISO based on the

00:31:47,989 --> 00:31:55,669
operating system string there's a bunch

00:31:51,469 --> 00:31:58,549
of logic in the KVM agent which kind of

00:31:55,669 --> 00:32:01,039
hooks up your huis string and tries to

00:31:58,549 --> 00:32:03,789
determine which controller to use there

00:32:01,039 --> 00:32:08,389
was no option for Windows and it

00:32:03,789 --> 00:32:12,889
defaulted to using ID disk normally it

00:32:08,389 --> 00:32:16,039
would be fine except in KVM and CEM you

00:32:12,889 --> 00:32:17,330
you can only have one ID controller so

00:32:16,039 --> 00:32:20,029
you can only have a limited number of

00:32:17,330 --> 00:32:21,710
disks attached to it so if you go over

00:32:20,029 --> 00:32:33,349
that limit basically your vm

00:32:21,710 --> 00:32:36,099
provisioning I think all right you guys

00:32:33,349 --> 00:32:36,099
had a similar issue

00:32:36,369 --> 00:32:54,190
okay exactly

00:32:49,519 --> 00:32:56,989
so if yeah so if you had the windows PE

00:32:54,190 --> 00:32:59,029
if you had the screen matching Windows

00:32:56,989 --> 00:33:01,159
PB in your OS list and you select the

00:32:59,029 --> 00:33:09,279
bat then you would know what to do and

00:33:01,159 --> 00:33:12,289
you would not use just getting to that

00:33:09,279 --> 00:33:14,570
so there yeah like that was kind of like

00:33:12,289 --> 00:33:18,830
you know stump is as well it turns out

00:33:14,570 --> 00:33:21,340
the KVM agent code is also quite retro

00:33:18,830 --> 00:33:25,899
that's my

00:33:21,340 --> 00:33:28,149
cloud stack things there was those

00:33:25,899 --> 00:33:29,470
basically a specific logic to do

00:33:28,149 --> 00:33:31,779
something different when we were using

00:33:29,470 --> 00:33:34,269
file based storage as opposed to a

00:33:31,779 --> 00:33:36,519
different type of storage so when you

00:33:34,269 --> 00:33:40,179
using file based storage and we didn't

00:33:36,519 --> 00:33:42,249
know how to determine the the disk

00:33:40,179 --> 00:33:44,350
controller or wood logic was that the

00:33:42,249 --> 00:33:46,659
root this could be ID and any additional

00:33:44,350 --> 00:33:47,769
discs would be word i/o so at least your

00:33:46,659 --> 00:33:49,330
VM would come up and then you can

00:33:47,769 --> 00:33:53,710
install the drivers in maker Alberta

00:33:49,330 --> 00:33:56,559
over so what we did was we implemented

00:33:53,710 --> 00:33:59,169
the same sort of heuristic for managed

00:33:56,559 --> 00:34:01,869
storage so if we see a row desk we we

00:33:59,169 --> 00:34:11,050
make the route one ID and then we the

00:34:01,869 --> 00:34:36,369
additional ones which is which is so

00:34:11,050 --> 00:34:38,579
legacy would have everything yeah we

00:34:36,369 --> 00:34:43,750
kind of were too afraid of to bring

00:34:38,579 --> 00:34:55,030
people who don't but yeah something that

00:34:43,750 --> 00:35:07,000
needs to be addressed yeah that was the

00:34:55,030 --> 00:35:09,010
other PR that I that I saw the move yeah

00:35:07,000 --> 00:35:18,490
they will say I was breaking something

00:35:09,010 --> 00:35:20,490
for them yeah all right so hopefully you

00:35:18,490 --> 00:35:23,440
know at this point we're ready to see

00:35:20,490 --> 00:35:27,849
some storage integration automation

00:35:23,440 --> 00:35:30,040
stuff so as is the trend with DevOps we

00:35:27,849 --> 00:35:32,530
want to get feedback faster so that we

00:35:30,040 --> 00:35:34,890
can change things faster and develop

00:35:32,530 --> 00:35:34,890
faster

00:35:35,570 --> 00:35:41,270
one of the sort of requirements that we

00:35:38,300 --> 00:35:42,830
were targeting was to be able to fix

00:35:41,270 --> 00:35:45,950
issues faster when we when we had a

00:35:42,830 --> 00:35:48,920
customer report an issue one of the

00:35:45,950 --> 00:35:50,600
things that was kind of at least a

00:35:48,920 --> 00:35:52,130
challenge for me is to get like an

00:35:50,600 --> 00:35:55,130
environment going that matches the

00:35:52,130 --> 00:35:56,480
customers deployment and I would I would

00:35:55,130 --> 00:35:59,420
it would help a lot if this was

00:35:56,480 --> 00:36:03,410
automated another requirement that we

00:35:59,420 --> 00:36:05,810
had was that we needed to support three

00:36:03,410 --> 00:36:09,590
types of hypervisors the XenServer

00:36:05,810 --> 00:36:11,990
KBM and vmware ideally we'd want to

00:36:09,590 --> 00:36:13,670
deploy these environments on fly do our

00:36:11,990 --> 00:36:17,750
work and then you're a get rid of them

00:36:13,670 --> 00:36:20,990
um so that you know we don't waste too

00:36:17,750 --> 00:36:26,270
many resources on this one of the

00:36:20,990 --> 00:36:29,390
solutions that was in solving this kind

00:36:26,270 --> 00:36:36,190
of issue was trillion trillion is in

00:36:29,390 --> 00:36:38,660
sort of automation what question no

00:36:36,190 --> 00:36:41,480
automation created by the guys our

00:36:38,660 --> 00:36:43,460
friends over at Shea blue um essentially

00:36:41,480 --> 00:36:46,460
it fulfilled requirement of creating

00:36:43,460 --> 00:36:48,680
test environments on on demand it

00:36:46,460 --> 00:36:50,000
leverage VMware because VMware is the I

00:36:48,680 --> 00:36:52,550
think the only one right now that can

00:36:50,000 --> 00:36:56,200
support all the other hypervisors nested

00:36:52,550 --> 00:37:01,610
inside of it and it also proposed a

00:36:56,200 --> 00:37:03,230
mechanism to allocate or to sort of

00:37:01,610 --> 00:37:05,290
manage the networking between the nested

00:37:03,230 --> 00:37:08,210
environment and the parent environment

00:37:05,290 --> 00:37:10,450
which which was which is kind of one of

00:37:08,210 --> 00:37:12,620
the challenges when you when you have

00:37:10,450 --> 00:37:14,960
hypervisors inside of hypervisors and

00:37:12,620 --> 00:37:18,370
you won't have the same or support most

00:37:14,960 --> 00:37:18,370
of the functionality that you had before

00:37:19,060 --> 00:37:28,760
this is a picture of what trillion

00:37:22,760 --> 00:37:33,440
deployment looks like so there are two

00:37:28,760 --> 00:37:35,450
parts here as you can see the two two

00:37:33,440 --> 00:37:38,630
colors the bottom is sort of the

00:37:35,450 --> 00:37:40,960
management side of things it consists of

00:37:38,630 --> 00:37:43,960
a parent clouds tech environment and

00:37:40,960 --> 00:37:48,260
Trillian server so the trillion

00:37:43,960 --> 00:37:50,980
basically talks to the parent and has

00:37:48,260 --> 00:37:55,820
parent create nested cloud stacks that

00:37:50,980 --> 00:37:57,500
you see at the top the network scheme

00:37:55,820 --> 00:38:00,080
that was used to kind of address the

00:37:57,500 --> 00:38:02,990
networking issues was to use a shared

00:38:00,080 --> 00:38:04,400
network so we had to share networks a

00:38:02,990 --> 00:38:07,600
management network and a public network

00:38:04,400 --> 00:38:09,260
and trillion would attract sort of the

00:38:07,600 --> 00:38:11,240
slices of the network that were

00:38:09,260 --> 00:38:19,130
allocated to each of the nested

00:38:11,240 --> 00:38:21,410
environments so these are sort of the

00:38:19,130 --> 00:38:25,430
things that we had to use to set up our

00:38:21,410 --> 00:38:27,860
lab automation we had to VMware house we

00:38:25,430 --> 00:38:30,110
had a recenter that's how it's on stack

00:38:27,860 --> 00:38:31,970
talks to VMware use it talks to be

00:38:30,110 --> 00:38:35,270
centered me Center actually manages the

00:38:31,970 --> 00:38:38,450
VMware hosts we have to manually install

00:38:35,270 --> 00:38:43,880
the parent cloud stack we used an NFS

00:38:38,450 --> 00:38:46,160
spor for harness environments we had to

00:38:43,880 --> 00:38:52,100
publishing the two shared networks and

00:38:46,160 --> 00:38:55,190
we also had to have virtual forms of the

00:38:52,100 --> 00:38:57,920
storages that we were testing against so

00:38:55,190 --> 00:39:03,320
we were supporting SolidFire so we had a

00:38:57,920 --> 00:39:05,960
virtual SolidFire this is just a

00:39:03,320 --> 00:39:08,750
visualization of the previous slide the

00:39:05,960 --> 00:39:14,240
tricky part in getting this to work I

00:39:08,750 --> 00:39:16,130
was networking on the KVM host the

00:39:14,240 --> 00:39:18,680
networking setup is fairly standard it's

00:39:16,130 --> 00:39:21,890
sort of quite well documented in the

00:39:18,680 --> 00:39:24,140
cloud stack you have two internet card

00:39:21,890 --> 00:39:26,630
connecting tier two networks all through

00:39:24,140 --> 00:39:30,920
VMs are have virtual interfaces that are

00:39:26,630 --> 00:39:35,720
connected to Linux bridge if we zoom out

00:39:30,920 --> 00:39:40,640
a bit we have sort of an hour scheme of

00:39:35,720 --> 00:39:42,140
the lab set up so the key there a couple

00:39:40,640 --> 00:39:45,170
of key things that that are needed to

00:39:42,140 --> 00:39:48,230
have this work one of them is to have

00:39:45,170 --> 00:39:51,700
trunk networks trunk networks basically

00:39:48,230 --> 00:39:57,020
passed through all VLANs

00:39:51,700 --> 00:39:58,520
going through them I'm not the best

00:39:57,020 --> 00:40:00,050
person to explain him this never set up

00:39:58,520 --> 00:40:02,090
I had a lot of help in order to set this

00:40:00,050 --> 00:40:05,630
up and I still don't

00:40:02,090 --> 00:40:07,010
they understand it but uh yeah maybe

00:40:05,630 --> 00:40:10,310
I'll try to write a blog post or

00:40:07,010 --> 00:40:15,320
something with you know more more detail

00:40:10,310 --> 00:40:16,370
more granular detail sorry yeah it

00:40:15,320 --> 00:40:22,570
doesn't make any sense

00:40:16,370 --> 00:40:25,010
oh yeah

00:40:22,570 --> 00:40:29,840
cool yeah I can't I'm just I can't even

00:40:25,010 --> 00:40:31,700
describe it it just works somehow and

00:40:29,840 --> 00:40:34,550
yes one of the issues that we had like

00:40:31,700 --> 00:40:36,260
all of this was working basically in the

00:40:34,550 --> 00:40:39,950
last stage of the trillion we bring up

00:40:36,260 --> 00:40:42,110
our zone and once

00:40:39,950 --> 00:40:44,480
well after that basically we need our

00:40:42,110 --> 00:40:47,600
system VMs to talk to our nested

00:40:44,480 --> 00:40:51,590
management server so this part wasn't

00:40:47,600 --> 00:40:52,940
working and the way that we have we made

00:40:51,590 --> 00:40:56,500
it to work I guess the the missing

00:40:52,940 --> 00:40:58,700
functionality that we were missing was I

00:40:56,500 --> 00:40:59,810
was explained to this by networking

00:40:58,700 --> 00:41:03,200
person I don't know if this is a real

00:40:59,810 --> 00:41:05,150
word he said I needed layer two routing

00:41:03,200 --> 00:41:06,380
I've heard of layer 3 switching but

00:41:05,150 --> 00:41:08,360
apparently there's a thing called layer

00:41:06,380 --> 00:41:11,180
2 routing so I needed a way to

00:41:08,360 --> 00:41:13,070
communicate between the two the two

00:41:11,180 --> 00:41:16,160
VLANs though the management and the

00:41:13,070 --> 00:41:19,100
public and our workaround to make this

00:41:16,160 --> 00:41:22,610
work was to enable promiscuous mode in

00:41:19,100 --> 00:41:25,160
VMware so our ProQuest's would propagate

00:41:22,610 --> 00:41:28,250
between the two VLANs and things could

00:41:25,160 --> 00:41:30,860
talk to each other but yeah I'm going to

00:41:28,250 --> 00:41:37,520
talk to Apollo a bit later to get some

00:41:30,860 --> 00:41:44,510
insight okay so yeah more details in the

00:41:37,520 --> 00:41:47,990
next talk and yeah finally we want to

00:41:44,510 --> 00:41:53,930
have Trillian incorporated in some sort

00:41:47,990 --> 00:41:56,090
of um CI pipeline so a typical sort of

00:41:53,930 --> 00:41:59,000
ideal workflow would be whenever there's

00:41:56,090 --> 00:42:00,640
a new change cloud stack your CI

00:41:59,000 --> 00:42:03,080
pipeline would kick off build process

00:42:00,640 --> 00:42:05,990
around the unit test build the packages

00:42:03,080 --> 00:42:07,700
push them off to yum repo and then kick

00:42:05,990 --> 00:42:09,730
off trillion trillion would pick up

00:42:07,700 --> 00:42:12,770
these packages from real Mia procreate

00:42:09,730 --> 00:42:15,500
lab environment once environment is up

00:42:12,770 --> 00:42:15,980
to run some Marvin tests in our case

00:42:15,500 --> 00:42:18,410
specific

00:42:15,980 --> 00:42:20,570
we we want solid fire tests to be run

00:42:18,410 --> 00:42:22,820
once they're done it's gonna send a

00:42:20,570 --> 00:42:25,250
report and attach it to your request or

00:42:22,820 --> 00:42:27,140
merge request so this exists today

00:42:25,250 --> 00:42:30,350
I think shaped blue guys maintain blue

00:42:27,140 --> 00:42:34,540
orangutan this essentially is a similar

00:42:30,350 --> 00:42:36,770
workflow to that I guess I'm like

00:42:34,540 --> 00:42:39,230
feeling a bit idealistic today what

00:42:36,770 --> 00:42:41,690
would be cool to have of maybe a red

00:42:39,230 --> 00:42:44,450
orangutan that you know that someone can

00:42:41,690 --> 00:42:46,790
call if they sorry if they want to run

00:42:44,450 --> 00:42:49,130
solid fire tests made it'd be really

00:42:46,790 --> 00:42:50,810
cool if people could give us a sort of

00:42:49,130 --> 00:42:52,880
way for people to contribute their test

00:42:50,810 --> 00:42:54,290
infrastructure that's specific to theirs

00:42:52,880 --> 00:42:58,100
with the club cloud second deployment

00:42:54,290 --> 00:43:00,170
and you know anyone who wants to change

00:42:58,100 --> 00:43:02,770
use their sort of setup or contribute to

00:43:00,170 --> 00:43:07,570
them you could call their particular

00:43:02,770 --> 00:43:15,730
color of orangutan and have have their

00:43:07,570 --> 00:43:15,730
tests run that way that I think yeah

00:43:16,180 --> 00:44:08,810
okay yeah yeah lots of lots of moving

00:43:46,640 --> 00:44:14,480
pieces for sure yeah that's that's quite

00:44:08,810 --> 00:44:16,730
a challenge yeah yeah I definitely want

00:44:14,480 --> 00:44:20,900
to know about this the scheme that you

00:44:16,730 --> 00:44:25,820
guys have in the works that's that's all

00:44:20,900 --> 00:44:27,830
I have for you guys today I'm open to

00:44:25,820 --> 00:44:29,650
any questions I know I might have lost

00:44:27,830 --> 00:44:31,990
or many details

00:44:29,650 --> 00:44:33,880
like I said at the beginning still

00:44:31,990 --> 00:44:37,480
CloudStack relatively new to CloudStack

00:44:33,880 --> 00:44:41,319
so made of made of light a bit in some

00:44:37,480 --> 00:44:43,079
places but yeah we're all we are

00:44:41,319 --> 00:44:46,329
learning together

00:44:43,079 --> 00:44:47,049
hope hope you guys thank you for your

00:44:46,329 --> 00:44:48,999
time this afternoon

00:44:47,049 --> 00:44:53,109
hope you guys were able to take away for

00:44:48,999 --> 00:44:58,299
something from this talk and yeah if you

00:44:53,109 --> 00:44:59,230
guys have any questions I'm open I don't

00:44:58,299 --> 00:45:17,410
know if there's any questions in the

00:44:59,230 --> 00:45:23,289
Google tool there all right so the one

00:45:17,410 --> 00:45:26,410
that I have working was for 12 I have I

00:45:23,289 --> 00:45:28,410
haven't actually have the whole thing

00:45:26,410 --> 00:45:31,509
run the automation you see for 13 I've

00:45:28,410 --> 00:45:34,269
done a few patches and I've had like a

00:45:31,509 --> 00:45:37,470
partial 4:13 test but not haven't really

00:45:34,269 --> 00:45:37,470
run the whole whole syllabus

00:45:40,410 --> 00:46:08,650
any other questions yes right what is

00:46:05,650 --> 00:46:13,509
your opinion aidid view on what you saw

00:46:08,650 --> 00:46:26,079
do you think the storage subsystem is

00:46:13,509 --> 00:46:30,309
good enough you see any refactoring six

00:46:26,079 --> 00:46:32,670
years ago let me just go back to the

00:46:30,309 --> 00:46:32,670
picture

00:46:40,030 --> 00:46:47,680
and then Mike came up came at all and I

00:46:42,040 --> 00:46:57,090
think he made changes in the but we

00:46:47,680 --> 00:46:57,090
haven't heard a storage person but

00:47:06,090 --> 00:47:13,840
that's a good question I mean I haven't

00:47:10,480 --> 00:47:15,730
like had to develop the storage plug-in

00:47:13,840 --> 00:47:17,650
from scratch so I might not have seen

00:47:15,730 --> 00:47:19,330
you know all the issues that were that

00:47:17,650 --> 00:47:22,410
were there

00:47:19,330 --> 00:47:25,420
I guess my generic sort of answer is

00:47:22,410 --> 00:47:27,490
there's a lot of I think I'm quoting you

00:47:25,420 --> 00:47:29,200
on this there's a lot of technical debt

00:47:27,490 --> 00:47:29,620
in cloud stack that you know needs to be

00:47:29,200 --> 00:47:34,540
addressed

00:47:29,620 --> 00:47:35,650
eventually that said yeah even well like

00:47:34,540 --> 00:47:37,210
you mentioned even while implementing

00:47:35,650 --> 00:47:38,440
the SolidFire plug-in a lot of things

00:47:37,210 --> 00:47:39,990
have to be changed in the court you know

00:47:38,440 --> 00:47:41,560
in order to be able to support

00:47:39,990 --> 00:47:45,040
functionality that we wanted to

00:47:41,560 --> 00:47:49,300
implement in in or take advantage of it

00:47:45,040 --> 00:47:52,030
SolidFire so I guess my kind of

00:47:49,300 --> 00:47:54,360
opinionated way I'm like maybe I'm

00:47:52,030 --> 00:47:59,170
showing my age I'm more of a

00:47:54,360 --> 00:48:00,550
microservices type person I guess in a

00:47:59,170 --> 00:48:02,950
monolith the boundaries between

00:48:00,550 --> 00:48:08,760
different things are less obvious and

00:48:02,950 --> 00:48:11,890
less enforced with less sort of force so

00:48:08,760 --> 00:48:14,890
yeah like the generic answer is lots of

00:48:11,890 --> 00:48:23,110
lots of room for refactoring but you

00:48:14,890 --> 00:48:26,380
know definitely leads more work yes I

00:48:23,110 --> 00:48:30,340
had the side like this yeah they've

00:48:26,380 --> 00:48:32,170
they've done the bit error actually that

00:48:30,340 --> 00:48:35,490
there was another is a recent one the

00:48:32,170 --> 00:48:38,800
Ticketmaster guys are are waiting for

00:48:35,490 --> 00:48:41,350
the sort of Multi multi tenant features

00:48:38,800 --> 00:48:46,300
in the dated her plugin that we use in

00:48:41,350 --> 00:48:48,910
cloud dot CA but yeah I mean I don't

00:48:46,300 --> 00:48:50,710
really have a specific answer because I

00:48:48,910 --> 00:48:52,130
haven't haven't spent enough time like

00:48:50,710 --> 00:49:05,300
developers using

00:48:52,130 --> 00:49:07,940
I think it was yeah I think it was

00:49:05,300 --> 00:49:11,710
definitely sired to who who did like a

00:49:07,940 --> 00:49:11,710
big chunk of the work in that plugin

00:49:12,430 --> 00:49:25,340
yeah yeah yeah um yeah I guess like I

00:49:23,450 --> 00:49:28,490
just like to conclude by saying that you

00:49:25,340 --> 00:49:32,060
know if we have some sort of easy way to

00:49:28,490 --> 00:49:33,770
test changes and if we I guess they've

00:49:32,060 --> 00:49:35,360
been you know much much improvements in

00:49:33,770 --> 00:49:37,100
the way cloud sex developed recently we

00:49:35,360 --> 00:49:39,500
have shorter release cycles

00:49:37,100 --> 00:49:43,490
um as long as we iterate fast enough we

00:49:39,500 --> 00:49:47,420
should be able to coax the architecture

00:49:43,490 --> 00:49:50,150
into a kind of you know more easy to use

00:49:47,420 --> 00:50:11,030
easy to consume and easy to contribute

00:49:50,150 --> 00:50:12,560
to any other questions yeah that's a

00:50:11,030 --> 00:50:16,400
good question I'm not sure if there's

00:50:12,560 --> 00:50:20,210
any official documentation um maybe

00:50:16,400 --> 00:50:21,710
maybe SolidFire Dassault yeah the

00:50:20,210 --> 00:50:26,500
way that I've learned about the features

00:50:21,710 --> 00:50:26,500
is by looking at the pull request yeah

00:50:28,000 --> 00:50:34,120
[Music]

00:50:30,940 --> 00:50:34,120

YouTube URL: https://www.youtube.com/watch?v=YG61yx4Sr8I


