Title: #ACEU19: Chris Baynes – Fast federated SQL with Apache Calcite
Publication date: 2019-10-31
Playlist: ApacheCon Europe 2019 – Berlin
Description: 
	More: https://aceu19.apachecon.com/session/fast-federated-sql-apache-calcite

Modern data landscapes are large and complex. Calcite provides functionality to query across databases and optimizes for effective push-down of filters, aggregations, and joins. This makes it an ideal gateway for SQL access to data. However, for analytical queries that require fast responses, this may not be enough.

During this session we discuss ways to speed up difficult queries and reduce the load on underlying database servers.
Captions: 
	00:00:04,609 --> 00:00:08,760
so just before we get started actually

00:00:07,380 --> 00:00:10,770
I'm curious how many in the audience

00:00:08,760 --> 00:00:14,730
have actually heard of Apache calcite

00:00:10,770 --> 00:00:16,289
like show of hands okay cool so a few

00:00:14,730 --> 00:00:19,560
how many of you actually used it for

00:00:16,289 --> 00:00:22,500
something in production or okay

00:00:19,560 --> 00:00:27,029
definitely less people right cool thanks

00:00:22,500 --> 00:00:30,390
and so I'm Chris I'm CTO and co-founder

00:00:27,029 --> 00:00:34,230
of Conti ammo based here in Berlin also

00:00:30,390 --> 00:00:36,420
an Apache calcite committer and Apache

00:00:34,230 --> 00:00:39,720
calcite is really important for us at

00:00:36,420 --> 00:00:43,010
Conti ammo and I'm here to explain today

00:00:39,720 --> 00:00:45,480
like why that is and what we use it for

00:00:43,010 --> 00:00:49,410
so just a bit of background first of all

00:00:45,480 --> 00:00:52,680
so so Conte amo our aim is to radically

00:00:49,410 --> 00:00:56,460
accelerate data access and we do that by

00:00:52,680 --> 00:00:58,920
having a data catalog which centralizes

00:00:56,460 --> 00:01:03,390
both your data access and data

00:00:58,920 --> 00:01:06,540
governance and on top of that we support

00:01:03,390 --> 00:01:08,670
basically querying and building things

00:01:06,540 --> 00:01:12,270
on top of complex data landscapes with

00:01:08,670 --> 00:01:13,920
virtualization also providing

00:01:12,270 --> 00:01:15,060
materializations to actually make things

00:01:13,920 --> 00:01:17,399
fast in the end because data

00:01:15,060 --> 00:01:21,359
virtualization is not always the fastest

00:01:17,399 --> 00:01:23,640
thing by itself we provide connectors

00:01:21,359 --> 00:01:25,979
for lots of different database types so

00:01:23,640 --> 00:01:29,819
of course relational databases also

00:01:25,979 --> 00:01:34,100
object document databases plus we have

00:01:29,819 --> 00:01:37,100
lots of adapters for different data like

00:01:34,100 --> 00:01:37,100
access

00:01:37,829 --> 00:01:41,700
yeah and so once you've connected your

00:01:40,289 --> 00:01:44,310
data to Conte amo

00:01:41,700 --> 00:01:48,060
you can then modify change the metadata

00:01:44,310 --> 00:01:54,060
inside of it and query it basically as

00:01:48,060 --> 00:01:57,929
if it's as if it's a local catalog yep

00:01:54,060 --> 00:01:59,429
so this is roughly how it looks you

00:01:57,929 --> 00:02:01,859
probably won't be able to make those

00:01:59,429 --> 00:02:04,289
screen shots out too well but basically

00:02:01,859 --> 00:02:06,299
provided a very nice user interface for

00:02:04,289 --> 00:02:09,270
all of this to allow you to query and

00:02:06,299 --> 00:02:13,409
visualize and look at data profiles but

00:02:09,270 --> 00:02:16,620
we also provide lots of ways of

00:02:13,409 --> 00:02:18,400
integrating with visualization and

00:02:16,620 --> 00:02:20,739
exploratory tools out

00:02:18,400 --> 00:02:22,360
so maybe you're using tableau or

00:02:20,739 --> 00:02:24,970
something else like this a different

00:02:22,360 --> 00:02:27,549
tool you can also connect that into our

00:02:24,970 --> 00:02:29,470
hub and view and visualize your data in

00:02:27,549 --> 00:02:35,409
basically any way that anyway is

00:02:29,470 --> 00:02:38,110
suitable for yourself yeah so what am I

00:02:35,409 --> 00:02:41,019
going to talk about today so first I'll

00:02:38,110 --> 00:02:44,049
give a very brief introduction to what

00:02:41,019 --> 00:02:47,829
is Apache calcite what you can use it

00:02:44,049 --> 00:02:49,150
for what are the tools in it and then

00:02:47,829 --> 00:02:50,920
after that I'm basically going to be

00:02:49,150 --> 00:02:52,260
talking about how we use this at Conte

00:02:50,920 --> 00:02:54,849
amo

00:02:52,260 --> 00:02:56,410
so talking about basically calcite as a

00:02:54,849 --> 00:02:59,650
toolbox of different things different

00:02:56,410 --> 00:03:01,060
tools which of those tools have been

00:02:59,650 --> 00:03:04,120
interesting for us in which ones we've

00:03:01,060 --> 00:03:07,810
used then talking a little bit about

00:03:04,120 --> 00:03:10,599
performance of our virtual layer on top

00:03:07,810 --> 00:03:13,150
of single data sources and then moving

00:03:10,599 --> 00:03:15,730
on from single data sources to federated

00:03:13,150 --> 00:03:19,690
queries across multiple data data

00:03:15,730 --> 00:03:21,760
sources across your entire landscape and

00:03:19,690 --> 00:03:23,410
basically the do the problem there is

00:03:21,760 --> 00:03:31,209
trying to make this fast and efficient

00:03:23,410 --> 00:03:33,099
as well so so let's get started so so

00:03:31,209 --> 00:03:35,379
not too many of you and so only a few of

00:03:33,099 --> 00:03:37,150
you have heard of Apache calcite but I'm

00:03:35,379 --> 00:03:39,069
sure if I asked how many people have

00:03:37,150 --> 00:03:42,340
heard of one of these projects here the

00:03:39,069 --> 00:03:47,109
numbers would be much much higher so

00:03:42,340 --> 00:03:49,299
Apache calcite is actually provides some

00:03:47,109 --> 00:03:52,540
tools some features which are heavily

00:03:49,299 --> 00:03:55,470
used by these by these tools here so

00:03:52,540 --> 00:03:58,319
lots of Apache projects actually are

00:03:55,470 --> 00:04:01,810
using Apache calcite under the hood for

00:03:58,319 --> 00:04:04,870
example it's used as the optimizer in

00:04:01,810 --> 00:04:07,959
Apache hive it's used as the parser

00:04:04,870 --> 00:04:11,319
inside Apache drill Apache flink

00:04:07,959 --> 00:04:18,789
uses it for query optimization and query

00:04:11,319 --> 00:04:20,680
parsing and of course at Conti amo we

00:04:18,789 --> 00:04:22,930
also use it for query optimization query

00:04:20,680 --> 00:04:28,120
passing plus the things that I'm going

00:04:22,930 --> 00:04:30,280
to talk about in a second here so does

00:04:28,120 --> 00:04:31,780
anybody know what this what this is what

00:04:30,280 --> 00:04:35,670
this represents

00:04:31,780 --> 00:04:38,680
any ideas anybody seen this before

00:04:35,670 --> 00:04:43,930
no so this is a deconstructed cappuccino

00:04:38,680 --> 00:04:45,550
and the so the relationship to what I'm

00:04:43,930 --> 00:04:48,580
talking about here Apache calcite is

00:04:45,550 --> 00:04:51,490
there was this great talk by by Julien

00:04:48,580 --> 00:04:53,830
Liddell from flat files to deconstructed

00:04:51,490 --> 00:04:56,830
databases where he basically talks about

00:04:53,830 --> 00:04:59,350
the concept that if you're building a

00:04:56,830 --> 00:05:00,700
database these days you don't write

00:04:59,350 --> 00:05:03,610
everything from scratch so you don't

00:05:00,700 --> 00:05:05,710
write your own you know your own sequel

00:05:03,610 --> 00:05:07,360
parser you probably don't want to write

00:05:05,710 --> 00:05:10,000
your own optimizer like these things are

00:05:07,360 --> 00:05:13,300
a lot of work right so what you do is

00:05:10,000 --> 00:05:16,030
you you take a piece from here and there

00:05:13,300 --> 00:05:17,860
and a lot of those pieces for example

00:05:16,030 --> 00:05:19,900
parsing and optimizing that I just

00:05:17,860 --> 00:05:20,920
mentioned plus data source connection

00:05:19,900 --> 00:05:23,740
and lots of other things can actually

00:05:20,920 --> 00:05:26,980
come from calcite so you might write

00:05:23,740 --> 00:05:29,410
some superfast layer to pull the

00:05:26,980 --> 00:05:31,690
information you want from disk from

00:05:29,410 --> 00:05:34,300
filesystem but you don't then want to

00:05:31,690 --> 00:05:37,390
build your own sequel parser as well to

00:05:34,300 --> 00:05:38,980
actually give people in a nice sequel

00:05:37,390 --> 00:05:40,810
interface to your product so you can

00:05:38,980 --> 00:05:47,440
plug in something like Apache calcite to

00:05:40,810 --> 00:05:49,270
help you out with this so patchy calcite

00:05:47,440 --> 00:05:51,430
yeah it's a pluggable framework it's

00:05:49,270 --> 00:05:53,470
basically a collection of tools of

00:05:51,430 --> 00:05:56,380
utilities that you can use however you

00:05:53,470 --> 00:05:58,960
like so what does it have inside of the

00:05:56,380 --> 00:06:01,780
box so as mentioned already it's got a

00:05:58,960 --> 00:06:03,100
query parser in there this is for

00:06:01,780 --> 00:06:04,420
standard sequel

00:06:03,100 --> 00:06:06,550
so the standard sequel is kind of the

00:06:04,420 --> 00:06:10,740
default but there are other ways of

00:06:06,550 --> 00:06:16,420
supporting a wider variety of dialects

00:06:10,740 --> 00:06:18,010
query rewriting materializations has

00:06:16,420 --> 00:06:19,630
kind of built-in materializations that

00:06:18,010 --> 00:06:23,980
it can even also generate in certain

00:06:19,630 --> 00:06:25,390
cases a query optimizer of course has a

00:06:23,980 --> 00:06:26,680
couple of different query optimizers

00:06:25,390 --> 00:06:28,920
inside of calcite one of them is

00:06:26,680 --> 00:06:31,120
rule-based the other one is cost based

00:06:28,920 --> 00:06:32,950
it supports lots of different

00:06:31,120 --> 00:06:36,750
connections for all kinds of JDBC

00:06:32,950 --> 00:06:40,360
adapters and JDBC drivers and and other

00:06:36,750 --> 00:06:42,000
adapters that that may be for data

00:06:40,360 --> 00:06:44,320
sources that don't support sequel

00:06:42,000 --> 00:06:47,420
natively

00:06:44,320 --> 00:06:49,100
has an in-memory execution model which

00:06:47,420 --> 00:06:50,990
basically allows you to do stuff in

00:06:49,100 --> 00:06:56,870
calcite which the underlying databases

00:06:50,990 --> 00:07:01,700
might not support has support for sequel

00:06:56,870 --> 00:07:03,980
streams and many many more things so

00:07:01,700 --> 00:07:05,810
let's take a look at a few of those in a

00:07:03,980 --> 00:07:07,840
little bit more detail and I'll tell you

00:07:05,810 --> 00:07:11,120
basically these things we basically used

00:07:07,840 --> 00:07:15,370
add Conti ammo to to really help us

00:07:11,120 --> 00:07:17,950
build this virtualization layer so

00:07:15,370 --> 00:07:20,180
before I get into that I just want to

00:07:17,950 --> 00:07:22,730
discuss a couple of things about

00:07:20,180 --> 00:07:26,420
terminology and and architecture here

00:07:22,730 --> 00:07:28,940
and so there's a couple of son of the

00:07:26,420 --> 00:07:31,460
names in Cal sites that you won't be

00:07:28,940 --> 00:07:33,710
familiar with but they're fairly easily

00:07:31,460 --> 00:07:35,570
understandable so a sequel node is

00:07:33,710 --> 00:07:37,580
basically what you get after you've

00:07:35,570 --> 00:07:40,310
passed sequel so you get some kind of

00:07:37,580 --> 00:07:41,750
tree right so this sequel tree so it's

00:07:40,310 --> 00:07:45,140
called a sequel node inside of Cal

00:07:41,750 --> 00:07:47,330
States the realm node is similar this is

00:07:45,140 --> 00:07:50,350
basically your query plan though so

00:07:47,330 --> 00:07:54,380
you've gone from passing your sequel to

00:07:50,350 --> 00:07:55,820
to maybe a bunch of optimizations but

00:07:54,380 --> 00:07:59,260
you basically end up with a query plan

00:07:55,820 --> 00:08:02,690
and this is a realm node in calcite and

00:07:59,260 --> 00:08:06,230
then finally there's this concept of a

00:08:02,690 --> 00:08:08,120
program which can be which can be one of

00:08:06,230 --> 00:08:08,540
the optimizers inside of calcite and you

00:08:08,120 --> 00:08:10,190
can

00:08:08,540 --> 00:08:11,660
so either the rule-based one or the

00:08:10,190 --> 00:08:13,610
cost-based one and you can combine those

00:08:11,660 --> 00:08:15,919
however you like or you can just use one

00:08:13,610 --> 00:08:18,830
of them completely up to you it's very

00:08:15,919 --> 00:08:23,330
flexible in the way that it allows you

00:08:18,830 --> 00:08:25,250
to to put those all together and on the

00:08:23,330 --> 00:08:28,820
left-hand side you see this is I mean

00:08:25,250 --> 00:08:31,550
this is the default way of using calcite

00:08:28,820 --> 00:08:32,810
so if you didn't plug anything else in

00:08:31,550 --> 00:08:35,719
there if you don't configure anything

00:08:32,810 --> 00:08:37,160
too too harshly then this is basically

00:08:35,719 --> 00:08:39,500
what you get so you start with sequel at

00:08:37,160 --> 00:08:41,810
the top you go through your parser have

00:08:39,500 --> 00:08:44,960
a sequel node then you go through this

00:08:41,810 --> 00:08:46,250
converter converter layer and you so

00:08:44,960 --> 00:08:49,460
then you basically start to build this

00:08:46,250 --> 00:08:50,900
logical plan a logical realm node then

00:08:49,460 --> 00:08:52,430
you go through a bunch of optimization

00:08:50,900 --> 00:08:54,650
steps which are completely configurable

00:08:52,430 --> 00:08:56,720
you end up with a physical plan and this

00:08:54,650 --> 00:08:57,710
physical plan you can then execute and

00:08:56,720 --> 00:08:59,750
get your data

00:08:57,710 --> 00:09:01,790
with the help of what's called the

00:08:59,750 --> 00:09:06,830
railrunner here which is just which is

00:09:01,790 --> 00:09:08,990
just basically an executor so now let's

00:09:06,830 --> 00:09:10,610
look at some of these tools so start off

00:09:08,990 --> 00:09:13,850
with the with the Babel parser

00:09:10,610 --> 00:09:15,440
so the Babel parser is interesting so by

00:09:13,850 --> 00:09:17,810
default as said the sequel pass to

00:09:15,440 --> 00:09:20,060
accept standard sequel but the Babel

00:09:17,810 --> 00:09:22,810
pastor basically extends that so it can

00:09:20,060 --> 00:09:25,250
support much more than standard sequel

00:09:22,810 --> 00:09:28,220
it avoids making assumptions about

00:09:25,250 --> 00:09:32,570
certain keywords so you can use dates as

00:09:28,220 --> 00:09:34,700
a as a column name for example because

00:09:32,570 --> 00:09:36,890
some some sequel dialects basically

00:09:34,700 --> 00:09:38,720
support this it also handles like

00:09:36,890 --> 00:09:41,180
special syntax like for example the

00:09:38,720 --> 00:09:44,209
Postgres double colon which is used for

00:09:41,180 --> 00:09:46,690
casting so I mean what can you use this

00:09:44,209 --> 00:09:49,339
for so this is basically useful if you

00:09:46,690 --> 00:09:51,260
kind of want to impersonate the database

00:09:49,339 --> 00:09:54,709
server you want to pretend that you're a

00:09:51,260 --> 00:09:56,180
Postgres server or an Oracle server you

00:09:54,709 --> 00:09:58,760
can basically expose an interface that

00:09:56,180 --> 00:10:03,380
says ok we we only accept Postgres

00:09:58,760 --> 00:10:06,589
sequel but using the babel parser quite

00:10:03,380 --> 00:10:08,120
easy to do this well I mean maybe you

00:10:06,589 --> 00:10:09,560
have a you have a client's that's that's

00:10:08,120 --> 00:10:11,060
more familiar with one dialect than

00:10:09,560 --> 00:10:13,430
another they don't want to use standard

00:10:11,060 --> 00:10:16,459
sequel they want to use Postgres sequel

00:10:13,430 --> 00:10:21,620
again then you can basically enable this

00:10:16,459 --> 00:10:24,110
with with the babel parser there are a

00:10:21,620 --> 00:10:25,850
couple of different rewriters in calcite

00:10:24,110 --> 00:10:31,910
which allows you to basically rewrite

00:10:25,850 --> 00:10:34,790
these plans that you have internally in

00:10:31,910 --> 00:10:37,180
calcite it provides you can basically

00:10:34,790 --> 00:10:40,790
use the visitor pattern to do this and

00:10:37,180 --> 00:10:42,260
we're transforming from from one sequel

00:10:40,790 --> 00:10:44,209
node into another sequel node or one

00:10:42,260 --> 00:10:45,500
realm node into another realm note you

00:10:44,209 --> 00:10:48,410
can think of it just basically in terms

00:10:45,500 --> 00:10:52,610
of plan transformation in some way so

00:10:48,410 --> 00:10:54,950
why would you want to do this one one

00:10:52,610 --> 00:10:58,370
use case would be view rewrites so you

00:10:54,950 --> 00:10:59,750
can define a view so selecting staff

00:10:58,370 --> 00:11:02,329
from that view that view has a

00:10:59,750 --> 00:11:03,980
definition and you basically would like

00:11:02,329 --> 00:11:05,450
to rewrite that to select star from the

00:11:03,980 --> 00:11:07,700
definition of the view so you can

00:11:05,450 --> 00:11:10,790
actually do this inside of calset with

00:11:07,700 --> 00:11:11,270
these rewriters and the same for row

00:11:10,790 --> 00:11:16,070
levels

00:11:11,270 --> 00:11:20,390
very similar use case but row-level

00:11:16,070 --> 00:11:21,950
security some it's used in quite a it's

00:11:20,390 --> 00:11:24,170
available in quite a lot of databases

00:11:21,950 --> 00:11:25,850
allows you to say if you've got a sales

00:11:24,170 --> 00:11:28,190
table then you only want to give a

00:11:25,850 --> 00:11:30,650
specific user access to sales from

00:11:28,190 --> 00:11:33,140
Germany so if they do a select star from

00:11:30,650 --> 00:11:34,940
sales it will rewrite that to a select

00:11:33,140 --> 00:11:35,510
star from sales where the country is

00:11:34,940 --> 00:11:39,410
Germany

00:11:35,510 --> 00:11:43,250
so yeah allows you to build these kind

00:11:39,410 --> 00:11:45,110
of things and then we've got a plan

00:11:43,250 --> 00:11:48,080
builder which is called the rel builder

00:11:45,110 --> 00:11:50,870
inside of calcite there are certain use

00:11:48,080 --> 00:11:53,060
cases where you want to go directly to a

00:11:50,870 --> 00:11:54,830
plan you basically don't want to provide

00:11:53,060 --> 00:11:59,120
a sequel interface at all perhaps in

00:11:54,830 --> 00:12:02,420
your specific use case so it replaces

00:11:59,120 --> 00:12:04,250
those those top those top two stages

00:12:02,420 --> 00:12:07,850
with just a rel builder that goes

00:12:04,250 --> 00:12:11,960
directly into a logical plan so you this

00:12:07,850 --> 00:12:14,960
might be useful if your if your query is

00:12:11,960 --> 00:12:17,330
generated by some kind of model and some

00:12:14,960 --> 00:12:20,180
some user interface that's doing a bunch

00:12:17,330 --> 00:12:22,970
of steps to to get to defining a query

00:12:20,180 --> 00:12:25,100
or you just want to you know you want to

00:12:22,970 --> 00:12:26,870
avoid writing sequel by hand you can

00:12:25,100 --> 00:12:28,280
basically use this builder to to do

00:12:26,870 --> 00:12:35,990
something programmatically which is then

00:12:28,280 --> 00:12:39,530
potentially typesafe as well so calcite

00:12:35,990 --> 00:12:43,220
has a has a concept of statistics which

00:12:39,530 --> 00:12:47,990
basically provides data metadata about

00:12:43,220 --> 00:12:51,050
the underlying data source tables by

00:12:47,990 --> 00:12:54,620
default it has a statistics provider

00:12:51,050 --> 00:12:56,870
inside of calcite but by default it also

00:12:54,620 --> 00:12:58,660
says that the number of it assumes that

00:12:56,870 --> 00:13:01,690
the number of rows in every table is 100

00:12:58,660 --> 00:13:06,230
so you know if you if you want to get

00:13:01,690 --> 00:13:08,150
good have a good optimization experience

00:13:06,230 --> 00:13:10,070
and generate a plan which is fast and

00:13:08,150 --> 00:13:12,500
efficient you probably want to plug in

00:13:10,070 --> 00:13:13,730
your own statistics here to make this a

00:13:12,500 --> 00:13:17,480
little bit better so this will

00:13:13,730 --> 00:13:19,280
definitely improve the the cost and the

00:13:17,480 --> 00:13:22,630
weights kind of inside of the optimizer

00:13:19,280 --> 00:13:22,630
to get you a better plan

00:13:23,540 --> 00:13:31,160
so as materializations you can define a

00:13:29,030 --> 00:13:33,140
materialization with sequel inside of

00:13:31,160 --> 00:13:35,360
calcite and then it will automatically

00:13:33,140 --> 00:13:39,680
rewrite crews that come in as they come

00:13:35,360 --> 00:13:41,740
in to use those materializations and so

00:13:39,680 --> 00:13:46,400
a small example here so say you have a

00:13:41,740 --> 00:13:46,960
pageviews pageviews table which is very

00:13:46,400 --> 00:13:49,730
large

00:13:46,960 --> 00:13:53,030
you've got columns in their country and

00:13:49,730 --> 00:13:54,470
city generally you might see a lot of

00:13:53,030 --> 00:13:56,870
queries coming in that are kind of

00:13:54,470 --> 00:13:58,100
saying okay group by group pageviews by

00:13:56,870 --> 00:14:01,340
country and by city

00:13:58,100 --> 00:14:04,670
so let's materialize that so basically

00:14:01,340 --> 00:14:06,440
tell calcite materialise pay troops by

00:14:04,670 --> 00:14:09,230
country and city so it's basically a

00:14:06,440 --> 00:14:13,190
group by sequel query right we put that

00:14:09,230 --> 00:14:19,280
into materialization called pageviews by

00:14:13,190 --> 00:14:22,400
location then query comes in so we're

00:14:19,280 --> 00:14:24,500
selecting from pageviews we're grouping

00:14:22,400 --> 00:14:27,020
by country and city ordering by country

00:14:24,500 --> 00:14:30,980
and getting the counts for each of these

00:14:27,020 --> 00:14:33,050
combinations and now this can of course

00:14:30,980 --> 00:14:34,490
go down to the underlying table to

00:14:33,050 --> 00:14:35,870
pageviews directly but this is going to

00:14:34,490 --> 00:14:36,560
be kind of an inefficient if you have to

00:14:35,870 --> 00:14:38,870
do this every time

00:14:36,560 --> 00:14:40,520
so calcite will see this crew coming in

00:14:38,870 --> 00:14:43,070
and then it will use these rewriters to

00:14:40,520 --> 00:14:50,660
say okay I have this materialization

00:14:43,070 --> 00:14:55,040
I'll use that instead and finally the

00:14:50,660 --> 00:14:56,660
sequel the sequel dialects so the sequel

00:14:55,040 --> 00:14:57,920
dialects are something inside of the

00:14:56,660 --> 00:14:59,540
railrunner kind of inside of the

00:14:57,920 --> 00:15:03,500
execution model before the query hits

00:14:59,540 --> 00:15:06,620
the database and it allows you to

00:15:03,500 --> 00:15:09,890
convert this kind of structure that you

00:15:06,620 --> 00:15:11,240
have into something specific for an

00:15:09,890 --> 00:15:13,760
underlying database so let's say you're

00:15:11,240 --> 00:15:16,490
connected to to a my sequel database my

00:15:13,760 --> 00:15:19,130
sequel has specific dialect that you

00:15:16,490 --> 00:15:20,690
want to try and hit so you want to try

00:15:19,130 --> 00:15:23,570
and modify the query a little bit so

00:15:20,690 --> 00:15:27,010
that it looks right for my sequel and my

00:15:23,570 --> 00:15:29,840
sequel be able to execute that correctly

00:15:27,010 --> 00:15:32,170
inside of calcite they have they have a

00:15:29,840 --> 00:15:35,240
whole bunch of different dialects

00:15:32,170 --> 00:15:37,130
supported I mean of course the main ones

00:15:35,240 --> 00:15:40,490
Oracle my sequel post

00:15:37,130 --> 00:15:43,520
yes hive plus actually lots of others

00:15:40,490 --> 00:15:46,340
and it's actually really easy to

00:15:43,520 --> 00:15:47,810
construct your own dialect and then plug

00:15:46,340 --> 00:15:51,500
it in so you have a new database that

00:15:47,810 --> 00:15:52,880
it's not supported in there then you can

00:15:51,500 --> 00:15:56,000
actually just create something like this

00:15:52,880 --> 00:15:57,620
you just extend the sequel dialect and

00:15:56,000 --> 00:15:59,900
what's really nice is that on this layer

00:15:57,620 --> 00:16:01,700
you can also say things like whether it

00:15:59,900 --> 00:16:04,670
supports nested aggregations whether it

00:16:01,700 --> 00:16:06,710
supports window functions if it doesn't

00:16:04,670 --> 00:16:08,090
support window functions then calcite

00:16:06,710 --> 00:16:10,670
will see this and it will do those

00:16:08,090 --> 00:16:12,880
window functions in memory instead so

00:16:10,670 --> 00:16:15,680
you don't have to you don't have to

00:16:12,880 --> 00:16:22,400
implement everything in your underlying

00:16:15,680 --> 00:16:27,950
database lattices I think I'm just going

00:16:22,400 --> 00:16:29,120
to skip here for now so yeah so the

00:16:27,950 --> 00:16:31,370
conclusion so there are lots of

00:16:29,120 --> 00:16:33,830
different tools these are just the ones

00:16:31,370 --> 00:16:36,380
that we've really used a little bit in

00:16:33,830 --> 00:16:38,360
our company but there's lots of other

00:16:36,380 --> 00:16:42,560
things inside of this calcite toolbox

00:16:38,360 --> 00:16:43,970
that you can use really helpful to kind

00:16:42,560 --> 00:16:47,030
of build these these complex

00:16:43,970 --> 00:16:48,590
applications it's really very flexible

00:16:47,030 --> 00:16:50,090
and they're all kind of pluggable so you

00:16:48,590 --> 00:16:52,070
can choose which ones you want to plug

00:16:50,090 --> 00:16:53,570
in which one's going to use maybe you

00:16:52,070 --> 00:16:57,080
want to modify and tweak a couple of

00:16:53,570 --> 00:16:58,400
them this is also possible but you've

00:16:57,080 --> 00:17:01,880
really got to think about performance

00:16:58,400 --> 00:17:03,350
here and this is you know if you plug

00:17:01,880 --> 00:17:05,300
all of these things in in the wrong way

00:17:03,350 --> 00:17:11,120
you could definitely have some issues

00:17:05,300 --> 00:17:12,410
there so that leads us on nicely to -

00:17:11,120 --> 00:17:18,530
looking at single data source

00:17:12,410 --> 00:17:21,280
performance and so a couple of things

00:17:18,530 --> 00:17:23,480
before we actually look at some numbers

00:17:21,280 --> 00:17:26,750
just to describe what we actually used

00:17:23,480 --> 00:17:29,000
here so you've got to measure right when

00:17:26,750 --> 00:17:31,610
you when you're doing when you're kind

00:17:29,000 --> 00:17:35,630
of seeing whether you improve this

00:17:31,610 --> 00:17:37,100
performance or not so what we used and I

00:17:35,630 --> 00:17:39,380
would definitely recommend that is some

00:17:37,100 --> 00:17:44,140
kind of standard sequel benchmarking

00:17:39,380 --> 00:17:47,540
tool so TPC has a whole bunch of them so

00:17:44,140 --> 00:17:50,970
exactly so TP CH is is the one that we

00:17:47,540 --> 00:17:53,890
used we're also looking into TP CDs

00:17:50,970 --> 00:17:57,150
but tpc is just great for generating

00:17:53,890 --> 00:18:02,380
really kind of complex sequel queries

00:17:57,150 --> 00:18:05,890
that difficult to optimize so TP CH

00:18:02,380 --> 00:18:08,020
itself has 22 queries has a configurable

00:18:05,890 --> 00:18:09,760
data size you can basically choose how

00:18:08,020 --> 00:18:12,160
big you want this data set to be and

00:18:09,760 --> 00:18:14,620
then you can basically generate that for

00:18:12,160 --> 00:18:17,530
the for the data source that you want to

00:18:14,620 --> 00:18:20,100
test against what's important here is

00:18:17,530 --> 00:18:24,160
that we're measuring the overhead here

00:18:20,100 --> 00:18:26,680
so we're just looking at it so we're

00:18:24,160 --> 00:18:28,720
looking at how how much we add on in our

00:18:26,680 --> 00:18:30,810
virtualization layer compared to running

00:18:28,720 --> 00:18:35,650
the query directly against the database

00:18:30,810 --> 00:18:38,230
so things like the configuration of TP

00:18:35,650 --> 00:18:40,150
CH in terms of data size plus the

00:18:38,230 --> 00:18:45,880
hardware that it's running on is not the

00:18:40,150 --> 00:18:47,650
most important thing for us thus I think

00:18:45,880 --> 00:18:50,710
second thing that we found incredibly

00:18:47,650 --> 00:18:52,450
useful is tracing so there's a kind of

00:18:50,710 --> 00:18:55,560
open tracing standard out there and

00:18:52,450 --> 00:18:58,240
there's a there's a few different tools

00:18:55,560 --> 00:19:00,490
Jagr is one of them and it basically

00:18:58,240 --> 00:19:02,440
provides you with this so for one single

00:19:00,490 --> 00:19:04,270
query you can see how that's split up

00:19:02,440 --> 00:19:05,830
where the time is taking this you know

00:19:04,270 --> 00:19:07,720
there's a lot of time taken in the the

00:19:05,830 --> 00:19:09,790
parsing or is it the optimization phase

00:19:07,720 --> 00:19:11,770
you've really got to have some some kind

00:19:09,790 --> 00:19:17,800
of insight there of what's going on so

00:19:11,770 --> 00:19:20,050
this is really invaluable and so I just

00:19:17,800 --> 00:19:23,350
want to so just we'll get into the

00:19:20,050 --> 00:19:25,270
numbers in a second but just briefly

00:19:23,350 --> 00:19:26,950
mention query push down for ask it's

00:19:25,270 --> 00:19:27,790
kind of important to understand what

00:19:26,950 --> 00:19:29,290
that is

00:19:27,790 --> 00:19:32,110
probably a lot of you know what that is

00:19:29,290 --> 00:19:34,600
already but just in case so let's say we

00:19:32,110 --> 00:19:36,100
have a query we're selecting from

00:19:34,600 --> 00:19:37,390
customers we're doing some ordering

00:19:36,100 --> 00:19:41,260
there and then we're just getting a

00:19:37,390 --> 00:19:43,240
limit so if you convert this into a into

00:19:41,260 --> 00:19:45,310
a calcite plan it will look something

00:19:43,240 --> 00:19:48,190
like this the best way to read these

00:19:45,310 --> 00:19:50,290
things by the ways to go bottom-up so

00:19:48,190 --> 00:19:53,470
start at the bottom you're seeing that

00:19:50,290 --> 00:19:56,050
we're scanning on the tables then we're

00:19:53,470 --> 00:19:57,310
just this is the Select part of the

00:19:56,050 --> 00:19:59,290
statement so we're just selecting the

00:19:57,310 --> 00:20:02,590
name and the ID that's a project in

00:19:59,290 --> 00:20:03,700
relational algebra there's this

00:20:02,590 --> 00:20:06,520
converters

00:20:03,700 --> 00:20:08,140
here it's not so important but then

00:20:06,520 --> 00:20:11,410
you'll see that we're doing this sort on

00:20:08,140 --> 00:20:13,000
top on at the very top there which right

00:20:11,410 --> 00:20:14,170
at the end of the sorts you'll see that

00:20:13,000 --> 00:20:17,280
the fetches in there so this is

00:20:14,170 --> 00:20:19,780
basically the limit so the limit of ten

00:20:17,280 --> 00:20:23,110
so this is a this is a perfectly valid

00:20:19,780 --> 00:20:26,620
plan this can be executed and we'll give

00:20:23,110 --> 00:20:28,210
you the results that you expect but you

00:20:26,620 --> 00:20:30,430
can see that the sort and the limit are

00:20:28,210 --> 00:20:32,680
in memory so what this means in calcite

00:20:30,430 --> 00:20:34,390
you see this innumerable prefix here

00:20:32,680 --> 00:20:38,320
this means that this is happening in

00:20:34,390 --> 00:20:41,530
memory in calcite the JDBC stuff where

00:20:38,320 --> 00:20:45,190
so it's clear that we're executing the

00:20:41,530 --> 00:20:47,740
query against the JDBC database so if we

00:20:45,190 --> 00:20:51,760
can basically get all of the computation

00:20:47,740 --> 00:20:53,920
into the JDBC parts then we're probably

00:20:51,760 --> 00:20:57,310
doing much better here this is another

00:20:53,920 --> 00:20:59,200
plan so semantically this is identical

00:20:57,310 --> 00:21:03,370
it's doing the same thing except that

00:20:59,200 --> 00:21:06,640
now you'll see that the sort is a JDBC

00:21:03,370 --> 00:21:08,770
sort and we would call this now a full

00:21:06,640 --> 00:21:11,980
career push down so we have pushed down

00:21:08,770 --> 00:21:16,210
this the sort and the limit into the

00:21:11,980 --> 00:21:17,680
database and our aim is to avoid this

00:21:16,210 --> 00:21:18,790
case here where we're doing lots of

00:21:17,680 --> 00:21:22,570
things in memory because it means that

00:21:18,790 --> 00:21:24,610
we have to pull out a lot more and this

00:21:22,570 --> 00:21:26,530
one is much better because we're relying

00:21:24,610 --> 00:21:27,820
on the kind of the speed the performance

00:21:26,530 --> 00:21:36,220
the optimizer of the underlying

00:21:27,820 --> 00:21:38,500
databases which is good so this is this

00:21:36,220 --> 00:21:40,480
is the basically this is the test we're

00:21:38,500 --> 00:21:41,980
going to run here we're going to we have

00:21:40,480 --> 00:21:43,720
some kind of runner we have an

00:21:41,980 --> 00:21:46,890
underlying database it's a relational

00:21:43,720 --> 00:21:49,420
database and then we have our

00:21:46,890 --> 00:21:51,460
virtualization layer the query engine

00:21:49,420 --> 00:21:54,640
and we're basically going to compare

00:21:51,460 --> 00:21:58,440
these two runs for each of these 22t PCH

00:21:54,640 --> 00:22:00,880
queries and see what the difference is

00:21:58,440 --> 00:22:04,870
we're going to do for benchmarking runs

00:22:00,880 --> 00:22:05,950
in total the first one which is not this

00:22:04,870 --> 00:22:08,590
is basically just to give us our

00:22:05,950 --> 00:22:11,530
baseline this is to run directly against

00:22:08,590 --> 00:22:14,140
the database itself the second one would

00:22:11,530 --> 00:22:15,520
be to run through the query engine but

00:22:14,140 --> 00:22:17,140
just with the defaults that calcite

00:22:15,520 --> 00:22:21,340
provides so now

00:22:17,140 --> 00:22:23,050
some logic there at all the next one

00:22:21,340 --> 00:22:25,830
would be to run through the query engine

00:22:23,050 --> 00:22:28,780
but this time adding some statistics and

00:22:25,830 --> 00:22:30,190
then we'll go for something that's this

00:22:28,780 --> 00:22:32,620
called a multi-phase optimizer that I

00:22:30,190 --> 00:22:34,480
explain a little bit later and we'll

00:22:32,620 --> 00:22:36,400
basically compare these and and see how

00:22:34,480 --> 00:22:39,430
they do so let's start off with our

00:22:36,400 --> 00:22:41,980
baseline first so you can see that the

00:22:39,430 --> 00:22:44,650
22 TPC H crew is running along the

00:22:41,980 --> 00:22:47,220
bottom we've got time running along the

00:22:44,650 --> 00:22:50,710
top so the lower the bars the better

00:22:47,220 --> 00:22:53,800
basically the important thing to

00:22:50,710 --> 00:22:55,330
remember here is that I mean just just

00:22:53,800 --> 00:22:56,950
look at the total time so the total time

00:22:55,330 --> 00:22:58,870
in the top right here forty five point

00:22:56,950 --> 00:23:00,310
five seconds so if you just remember

00:22:58,870 --> 00:23:04,060
this number and then we can kind of see

00:23:00,310 --> 00:23:05,740
how that progresses over time so does

00:23:04,060 --> 00:23:10,060
our first run so we basically go through

00:23:05,740 --> 00:23:13,420
unoptimized so this is purely all the

00:23:10,060 --> 00:23:14,860
defaults in calcite so what it does is

00:23:13,420 --> 00:23:16,660
it generates some queries it generates

00:23:14,860 --> 00:23:20,770
this 22 queries and we can see that the

00:23:16,660 --> 00:23:23,020
total now is 158 seconds so original

00:23:20,770 --> 00:23:27,550
being 45 and a half we've added quite a

00:23:23,020 --> 00:23:29,760
bit of overhead here doesn't look too

00:23:27,550 --> 00:23:29,760
great

00:23:31,210 --> 00:23:35,650
yeah there's that's true yeah I'll

00:23:33,910 --> 00:23:42,820
actually come to that later yeah thanks

00:23:35,650 --> 00:23:45,250
so you see that this is very slow what

00:23:42,820 --> 00:23:48,640
we look at we look at the plans and we

00:23:45,250 --> 00:23:49,780
see how much push down there is there's

00:23:48,640 --> 00:23:51,520
actually very little push down there's

00:23:49,780 --> 00:23:55,660
actually a lot happening in memory here

00:23:51,520 --> 00:23:58,990
and the planning step itself is actually

00:23:55,660 --> 00:24:00,310
consuming a lot of time so you know he

00:23:58,990 --> 00:24:02,260
goes to this planning phase before to

00:24:00,310 --> 00:24:03,670
even execute the query that's taking up

00:24:02,260 --> 00:24:07,210
a significant amount of time of the

00:24:03,670 --> 00:24:08,200
curry itself which is obviously bad so

00:24:07,210 --> 00:24:10,810
the next thing we're going to try is

00:24:08,200 --> 00:24:15,370
plug in some table statistics and see

00:24:10,810 --> 00:24:16,990
how this will improve matters so plug in

00:24:15,370 --> 00:24:19,900
some table statistics here so now we

00:24:16,990 --> 00:24:21,490
have basically accurate accurate numbers

00:24:19,900 --> 00:24:24,910
for the row counts of each of the tables

00:24:21,490 --> 00:24:27,460
inside and you can see so comparing

00:24:24,910 --> 00:24:29,500
against the the no optimization you can

00:24:27,460 --> 00:24:30,700
see that now we are doing a little bit

00:24:29,500 --> 00:24:32,499
better in some cases

00:24:30,700 --> 00:24:35,230
some cases it's about the same some case

00:24:32,499 --> 00:24:37,210
even a little bit worse but generally

00:24:35,230 --> 00:24:38,889
over if you look over time so the total

00:24:37,210 --> 00:24:40,690
hundred and twenty five it's definitely

00:24:38,889 --> 00:24:47,019
come down so it seems that we're going

00:24:40,690 --> 00:24:48,549
in the right direction here again like a

00:24:47,019 --> 00:24:52,929
lot of the work is being done in memory

00:24:48,549 --> 00:24:56,080
in this innumerable layer the the

00:24:52,929 --> 00:24:59,200
planning is still very slow so this is

00:24:56,080 --> 00:25:01,330
one of the traces that we have here you

00:24:59,200 --> 00:25:02,980
can see that the the big bar at the top

00:25:01,330 --> 00:25:05,200
is basically the total query time which

00:25:02,980 --> 00:25:08,559
in this case eleven point one seconds

00:25:05,200 --> 00:25:11,859
and if you notice the so the second

00:25:08,559 --> 00:25:12,909
third bar is the time that it's actually

00:25:11,859 --> 00:25:14,919
taking to do the planning and

00:25:12,909 --> 00:25:17,080
optimization so that's like almost a

00:25:14,919 --> 00:25:19,869
third of the crew which is which is

00:25:17,080 --> 00:25:21,279
pretty bad for for eleven seconds to

00:25:19,869 --> 00:25:23,499
basically be in the planning phase for

00:25:21,279 --> 00:25:28,179
three seconds this is not really what we

00:25:23,499 --> 00:25:32,950
want here so the next thing is planning

00:25:28,179 --> 00:25:36,429
phases so what do we mean by that what

00:25:32,950 --> 00:25:37,899
we want to do is try and split up the

00:25:36,429 --> 00:25:41,499
planning into a couple of different

00:25:37,899 --> 00:25:43,389
steps by default what calcite does is it

00:25:41,499 --> 00:25:48,460
just puts everything through the

00:25:43,389 --> 00:25:51,820
cost-based optimizer which is less than

00:25:48,460 --> 00:25:53,679
ideal we'll see why in a second but if

00:25:51,820 --> 00:25:55,600
we what we want to do is now split this

00:25:53,679 --> 00:26:00,070
up into two phases that we call a logic

00:25:55,600 --> 00:26:02,980
logical and a physical face the logical

00:26:00,070 --> 00:26:06,820
phase we will run through the rule-based

00:26:02,980 --> 00:26:08,889
optimizer which is called heping calcite

00:26:06,820 --> 00:26:12,600
and here we'll basically apply all of

00:26:08,889 --> 00:26:15,129
the logical optimization rules so these

00:26:12,600 --> 00:26:18,100
steps can basically can they can be

00:26:15,129 --> 00:26:22,720
performed without knowing anything about

00:26:18,100 --> 00:26:24,340
the underlying data sources so for

00:26:22,720 --> 00:26:27,220
example you know it's it's always good

00:26:24,340 --> 00:26:30,159
to push a filter into a join like these

00:26:27,220 --> 00:26:33,100
kind of rules like it's kind of always

00:26:30,159 --> 00:26:35,200
good to do them so so this would be our

00:26:33,100 --> 00:26:37,570
logical phase and then the physical

00:26:35,200 --> 00:26:40,419
phase will actually use the cost-based

00:26:37,570 --> 00:26:43,869
optimizer again and we'll apply all of

00:26:40,419 --> 00:26:45,429
these kind of the final physical rules

00:26:43,869 --> 00:26:52,899
and conversions that are needed to

00:26:45,429 --> 00:26:57,039
actually execute the query and yeah so

00:26:52,899 --> 00:26:59,019
now if we look at the numbers see that

00:26:57,039 --> 00:27:02,049
so the Green is the is the new planning

00:26:59,019 --> 00:27:03,789
phases compared to the old ones so the

00:27:02,049 --> 00:27:06,460
the previous best which was table stats

00:27:03,789 --> 00:27:07,809
you can see like massive reduction in

00:27:06,460 --> 00:27:11,379
time now so fifty nine and a half

00:27:07,809 --> 00:27:19,960
seconds which is a big big improvement

00:27:11,379 --> 00:27:21,429
here it's yeah it's a bit more complex

00:27:19,960 --> 00:27:22,809
than that you have to really set up and

00:27:21,429 --> 00:27:29,649
decide how you want the whole planning

00:27:22,809 --> 00:27:31,450
phases to go so yeah exactly so now if

00:27:29,649 --> 00:27:34,509
we if we go back and we look we now

00:27:31,450 --> 00:27:37,629
compare our final planning phases versus

00:27:34,509 --> 00:27:41,830
the original baseline you see that okay

00:27:37,629 --> 00:27:45,099
some queries are slower here a little

00:27:41,830 --> 00:27:47,649
bit but as somebody pointed out earlier

00:27:45,099 --> 00:27:50,080
and in fact it's even more valid in this

00:27:47,649 --> 00:27:52,809
case some they're actually quite a few

00:27:50,080 --> 00:27:54,849
cases where the the query is is faster

00:27:52,809 --> 00:27:57,359
now in the new planning phases than it

00:27:54,849 --> 00:27:57,359
was before

00:27:57,539 --> 00:28:02,710
so generally things are much faster we

00:28:00,970 --> 00:28:04,029
have now we've actually looked at the

00:28:02,710 --> 00:28:05,259
plans and we've analyzed the plans as

00:28:04,029 --> 00:28:06,879
well and we found that actually

00:28:05,259 --> 00:28:08,529
everything is happening in those

00:28:06,879 --> 00:28:11,679
underlying databases we're pushing down

00:28:08,529 --> 00:28:15,720
the full the full plan the full query is

00:28:11,679 --> 00:28:18,669
happening underneath which is great

00:28:15,720 --> 00:28:21,190
which of course means that all of the

00:28:18,669 --> 00:28:23,649
well doesn't of course mean but we have

00:28:21,190 --> 00:28:25,419
looked at the the kind of serialization

00:28:23,649 --> 00:28:27,070
and the parsing and all of these other

00:28:25,419 --> 00:28:29,259
phases that we have in our Alea and

00:28:27,070 --> 00:28:30,879
they're really insignificant compared to

00:28:29,259 --> 00:28:32,499
the actual time the crew is being spent

00:28:30,879 --> 00:28:36,789
in the underlying data source so this is

00:28:32,499 --> 00:28:39,669
good and as mentioned some queries are

00:28:36,789 --> 00:28:41,200
faster than the baseline and this this

00:28:39,669 --> 00:28:44,830
actually surprised us quite a bit

00:28:41,200 --> 00:28:47,980
initially as well but it's an

00:28:44,830 --> 00:28:50,529
interesting fact that basically the the

00:28:47,980 --> 00:28:52,450
TP CH queries that start off they go

00:28:50,529 --> 00:28:54,429
through this parsing and optimization

00:28:52,450 --> 00:28:56,500
phase the crews that end up on the other

00:28:54,429 --> 00:28:59,010
end that have finally executed again

00:28:56,500 --> 00:29:03,370
the database can look very different

00:28:59,010 --> 00:29:05,560
from the initial queries so for example

00:29:03,370 --> 00:29:08,110
there are cases where joins are turned

00:29:05,560 --> 00:29:08,830
into sub selects and sometimes

00:29:08,110 --> 00:29:11,620
vice-versa

00:29:08,830 --> 00:29:13,090
so it's interesting that sometimes we

00:29:11,620 --> 00:29:15,310
come up with a query which is actually

00:29:13,090 --> 00:29:22,720
more optimal for that specific database

00:29:15,310 --> 00:29:26,140
than the original query sir so our goal

00:29:22,720 --> 00:29:30,310
for really for this was to do full query

00:29:26,140 --> 00:29:34,330
push down because it's it's it's really

00:29:30,310 --> 00:29:36,070
difficult actually to so even though we

00:29:34,330 --> 00:29:38,020
have full query push down we can't kind

00:29:36,070 --> 00:29:41,050
of guarantee that we're going to be

00:29:38,020 --> 00:29:42,610
faster than just the raw query itself we

00:29:41,050 --> 00:29:44,350
might be a little bit faster we might be

00:29:42,610 --> 00:29:46,390
a little bit slower depending on the

00:29:44,350 --> 00:29:48,010
query that we generate in the end it's a

00:29:46,390 --> 00:29:51,610
little bit tricky to measure that and it

00:29:48,010 --> 00:29:53,800
also depends very much on the optimizer

00:29:51,610 --> 00:29:55,360
of the underlying data sources as to

00:29:53,800 --> 00:29:59,470
whether we're going to be better or

00:29:55,360 --> 00:30:00,520
worse so but would recommend that so if

00:29:59,470 --> 00:30:02,200
you're trying to do this so that then

00:30:00,520 --> 00:30:06,160
the fastest way to get there to get this

00:30:02,200 --> 00:30:07,840
full query pushdown is to apply almost

00:30:06,160 --> 00:30:12,120
all of the rules into this rule-based

00:30:07,840 --> 00:30:15,070
optimizer first that will give you a

00:30:12,120 --> 00:30:17,650
plan which is a still logical plan

00:30:15,070 --> 00:30:20,770
because you haven't added any you

00:30:17,650 --> 00:30:22,630
haven't added any physical rules but

00:30:20,770 --> 00:30:24,910
then you need to then apply this this

00:30:22,630 --> 00:30:26,760
cost-based optimizer at the end to apply

00:30:24,910 --> 00:30:29,170
those physical rules and conversions and

00:30:26,760 --> 00:30:30,460
then if you're going to use the

00:30:29,170 --> 00:30:35,260
cost-based optimizer though be careful

00:30:30,460 --> 00:30:37,270
adding too many rules it once you the

00:30:35,260 --> 00:30:40,560
cost-based optimizer works basically by

00:30:37,270 --> 00:30:43,420
finding a plan with with the lowest cost

00:30:40,560 --> 00:30:46,450
if you consider things like join

00:30:43,420 --> 00:30:48,070
reordering and different kinds of

00:30:46,450 --> 00:30:49,750
combinations of plans that you can have

00:30:48,070 --> 00:30:54,250
that search space is just absolutely

00:30:49,750 --> 00:30:56,620
massive so try and reduce the number of

00:30:54,250 --> 00:30:58,390
kind of the the size of that space

00:30:56,620 --> 00:31:00,760
before you even start that optimizer

00:30:58,390 --> 00:31:04,690
that's that's basically the rule there

00:31:00,760 --> 00:31:06,640
and yeah and overall just rely on the

00:31:04,690 --> 00:31:10,020
underlying optimizers to do the rest of

00:31:06,640 --> 00:31:10,020
the work to actually execute the query

00:31:10,769 --> 00:31:15,389
so now let's look at the Federated crew

00:31:13,090 --> 00:31:18,129
so related just single data source there

00:31:15,389 --> 00:31:20,379
if we now move on to federated crew so

00:31:18,129 --> 00:31:22,210
what is a federated crew it's a single

00:31:20,379 --> 00:31:25,629
query based on information from multiple

00:31:22,210 --> 00:31:28,149
data sources so you have one sequel

00:31:25,629 --> 00:31:31,570
query you could be joining a table from

00:31:28,149 --> 00:31:37,360
hive table in Postgres and getting some

00:31:31,570 --> 00:31:39,429
kind of results of course this is going

00:31:37,360 --> 00:31:44,049
to be an inefficient in in quite a few

00:31:39,429 --> 00:31:46,179
cases if you have a couple of very large

00:31:44,049 --> 00:31:48,519
tables you wants to try and join these

00:31:46,179 --> 00:31:49,659
in memory then it's going to be

00:31:48,519 --> 00:31:51,279
difficult right because that joint

00:31:49,659 --> 00:31:52,990
actually has to happen in memory there's

00:31:51,279 --> 00:31:55,120
no way we can now push down that join

00:31:52,990 --> 00:31:57,850
your joining from two different data

00:31:55,120 --> 00:32:00,179
sources it's got to be done in memory so

00:31:57,850 --> 00:32:03,309
got to be careful about that

00:32:00,179 --> 00:32:05,379
if your driver has large fetch size so

00:32:03,309 --> 00:32:06,940
you basically before you even do start

00:32:05,379 --> 00:32:08,830
doing any kind of computation you pull

00:32:06,940 --> 00:32:11,919
all of the data into memory first and

00:32:08,830 --> 00:32:13,570
then start iterating through it you've

00:32:11,919 --> 00:32:15,759
already kind of exploded your your

00:32:13,570 --> 00:32:17,649
memory consumption there this could also

00:32:15,759 --> 00:32:21,690
be a problem for single data sources as

00:32:17,649 --> 00:32:24,370
well any kind of aggregations and

00:32:21,690 --> 00:32:27,370
basically anything that happens in

00:32:24,370 --> 00:32:29,710
memory in this in memory layer here and

00:32:27,370 --> 00:32:31,690
when we get to well now that we're

00:32:29,710 --> 00:32:33,309
talking about federated queries this

00:32:31,690 --> 00:32:38,350
could happen a lot more than for single

00:32:33,309 --> 00:32:40,149
data source queries right so in the best

00:32:38,350 --> 00:32:43,240
case this will slow down your entire

00:32:40,149 --> 00:32:47,860
system and in the worst case like

00:32:43,240 --> 00:32:50,500
probably things will just crash so how

00:32:47,860 --> 00:32:53,649
can we solve this problem so really the

00:32:50,500 --> 00:32:57,639
issue here is this in-memory layer that

00:32:53,649 --> 00:32:59,080
we have in calcite and there's there's a

00:32:57,639 --> 00:33:02,049
few ways that we can kind of scale that

00:32:59,080 --> 00:33:05,320
out at Conte amor what we've looked at

00:33:02,049 --> 00:33:10,870
is is using spark as the execution

00:33:05,320 --> 00:33:13,840
engine so I'm sure everybody's heard of

00:33:10,870 --> 00:33:14,950
spark at least so it scales out to lots

00:33:13,840 --> 00:33:16,720
and lots of nodes you can basically

00:33:14,950 --> 00:33:22,210
connect to a spark cluster with dozens

00:33:16,720 --> 00:33:23,560
or more nodes in there can avoid our end

00:33:22,210 --> 00:33:25,870
situations so you

00:33:23,560 --> 00:33:29,860
kind of run out of memory in most cases

00:33:25,870 --> 00:33:31,360
for spark and the other advantage of a

00:33:29,860 --> 00:33:37,870
spark is that it actually does have some

00:33:31,360 --> 00:33:39,670
calcite support as a bonus like spark

00:33:37,870 --> 00:33:41,500
actually gives you a little bit better

00:33:39,670 --> 00:33:43,960
access to data Lakes as well so you can

00:33:41,500 --> 00:33:52,120
query things like park' files out of the

00:33:43,960 --> 00:33:54,610
box I mentioned that has that calcite

00:33:52,120 --> 00:33:56,170
supports spark there's a couple of

00:33:54,610 --> 00:33:59,230
different options available inside of

00:33:56,170 --> 00:34:02,140
calcite itself the first one is the

00:33:59,230 --> 00:34:04,660
spark adapter inside of calcite and what

00:34:02,140 --> 00:34:07,210
this does is it takes this this crude

00:34:04,660 --> 00:34:09,820
plan that we have and turns it into a

00:34:07,210 --> 00:34:14,050
spark plan so does a kind of direct

00:34:09,820 --> 00:34:16,600
translation then it has this plan it

00:34:14,050 --> 00:34:18,880
sends this plan to the cluster executed

00:34:16,600 --> 00:34:20,740
everything works unfortunately we've had

00:34:18,880 --> 00:34:22,990
a little bit of a look into this and

00:34:20,740 --> 00:34:24,460
there's still quite a few things missing

00:34:22,990 --> 00:34:30,240
in that translation that's quite

00:34:24,460 --> 00:34:33,880
difficult to get right the second option

00:34:30,240 --> 00:34:35,980
would be the the spark sequel dialect we

00:34:33,880 --> 00:34:38,820
spoke about these dialects earlier they

00:34:35,980 --> 00:34:41,530
allow you to basically translate into

00:34:38,820 --> 00:34:43,149
into the language of the underlying data

00:34:41,530 --> 00:34:44,710
source so you could basically think of

00:34:43,149 --> 00:34:47,679
spark as a data source almost and

00:34:44,710 --> 00:34:54,550
translate sequel into into the spark

00:34:47,679 --> 00:34:56,140
sequel yeah unfortunately this is we

00:34:54,550 --> 00:34:59,200
have quite a bit of overhead here

00:34:56,140 --> 00:35:01,210
because we're we're sending a query off

00:34:59,200 --> 00:35:02,950
to spark which then needs to be passed

00:35:01,210 --> 00:35:05,260
by spark it needs to be optimized by

00:35:02,950 --> 00:35:06,490
spark which is not great since we've

00:35:05,260 --> 00:35:09,550
already done a lot of that work and now

00:35:06,490 --> 00:35:12,610
we're having it done again plus plus the

00:35:09,550 --> 00:35:14,290
the push downs in spark are actually not

00:35:12,610 --> 00:35:16,960
as great as what you can do in Cal said

00:35:14,290 --> 00:35:22,870
Cal so it has a lot more kind of fine

00:35:16,960 --> 00:35:24,820
grained control over that the the final

00:35:22,870 --> 00:35:26,650
option would be just to say okay then we

00:35:24,820 --> 00:35:28,600
just skip this entire calcite layer and

00:35:26,650 --> 00:35:30,700
we just say that everybody just connects

00:35:28,600 --> 00:35:34,780
then we just have our customers connect

00:35:30,700 --> 00:35:37,270
directly to to spark run spark sequel

00:35:34,780 --> 00:35:38,470
queries but yeah but

00:35:37,270 --> 00:35:40,300
we were kind of missing all of these

00:35:38,470 --> 00:35:44,440
cool features from calcite this nice

00:35:40,300 --> 00:35:47,470
toolbox that we have and again this the

00:35:44,440 --> 00:35:51,510
the push downs in spark are not as not

00:35:47,470 --> 00:35:54,510
as flexible as what we have in calcite

00:35:51,510 --> 00:35:58,300
so we decided to take another approach

00:35:54,510 --> 00:36:00,450
and it combines a little bit of the

00:35:58,300 --> 00:36:04,150
ideas from these from these different

00:36:00,450 --> 00:36:05,680
integrations that exist already so the

00:36:04,150 --> 00:36:09,880
first thing of course generated calcite

00:36:05,680 --> 00:36:12,250
plan that's fair enough then the idea

00:36:09,880 --> 00:36:17,440
would be to identify the pieces inside

00:36:12,250 --> 00:36:19,000
of this plan which which relate to to

00:36:17,440 --> 00:36:22,300
the separate data sources that were

00:36:19,000 --> 00:36:24,370
actually connecting to we will squash

00:36:22,300 --> 00:36:28,210
those individual pieces into what we

00:36:24,370 --> 00:36:30,520
call spark tables for every one of these

00:36:28,210 --> 00:36:34,420
spark tables those then become spike

00:36:30,520 --> 00:36:37,330
data frames and then the rest of the

00:36:34,420 --> 00:36:38,950
plan will just actually convert into we

00:36:37,330 --> 00:36:41,770
know whatever's left will then convert

00:36:38,950 --> 00:36:44,230
into spark sequel which will then be

00:36:41,770 --> 00:36:46,210
executed in the cluster so remember this

00:36:44,230 --> 00:36:47,530
architecture diagram earlier basically

00:36:46,210 --> 00:36:50,710
looks like this so we're using all of

00:36:47,530 --> 00:36:52,870
these features of calcite then right at

00:36:50,710 --> 00:36:54,610
the end we have this physical plan that

00:36:52,870 --> 00:36:56,950
we then adjust and tweak a little bit as

00:36:54,610 --> 00:36:59,380
mentioned here and then the final thing

00:36:56,950 --> 00:37:02,530
gets executed in spark and not in

00:36:59,380 --> 00:37:04,860
calcite so just to give an example of

00:37:02,530 --> 00:37:07,120
how that actually looks in practice here

00:37:04,860 --> 00:37:09,550
so want to join two different tables

00:37:07,120 --> 00:37:12,190
from different data sources so a data

00:37:09,550 --> 00:37:15,670
source X data source Y so X contains our

00:37:12,190 --> 00:37:17,110
sales and Y is our customer data want to

00:37:15,670 --> 00:37:19,180
join those two so the query would look

00:37:17,110 --> 00:37:20,650
something like this right so we're just

00:37:19,180 --> 00:37:23,170
joining those two tables using the

00:37:20,650 --> 00:37:24,910
customer ID and we're adding a filter on

00:37:23,170 --> 00:37:26,860
the customer city saying that we only

00:37:24,910 --> 00:37:30,580
want we're only interested in customers

00:37:26,860 --> 00:37:33,480
from Berlin then adding a limit here at

00:37:30,580 --> 00:37:37,710
the end just to get the first 10 results

00:37:33,480 --> 00:37:40,000
so converting this into a calcite plan

00:37:37,710 --> 00:37:41,770
it looks a little bit long but it's

00:37:40,000 --> 00:37:44,470
fairly readable if again you go from

00:37:41,770 --> 00:37:46,390
from bottom to top you can see the the

00:37:44,470 --> 00:37:49,270
two the two table scans there one for

00:37:46,390 --> 00:37:51,040
customer one for sales and then the one

00:37:49,270 --> 00:37:53,440
for customer you see also has the the

00:37:51,040 --> 00:37:55,810
filter on top for the city and then they

00:37:53,440 --> 00:37:57,700
can those get joined together you'll

00:37:55,810 --> 00:38:00,880
notice that the joint is in memory of

00:37:57,700 --> 00:38:02,110
course because these are two different

00:38:00,880 --> 00:38:04,480
data sources the only way to do that

00:38:02,110 --> 00:38:05,980
joint is in memory and then the limit is

00:38:04,480 --> 00:38:11,380
also in memory because it has to be on

00:38:05,980 --> 00:38:15,430
top of that that final joint so let's

00:38:11,380 --> 00:38:17,410
apply our algorithm our approach here so

00:38:15,430 --> 00:38:19,060
we identify first the pieces from the

00:38:17,410 --> 00:38:21,160
separate data sources so we've got this

00:38:19,060 --> 00:38:25,900
piece here first this is from data

00:38:21,160 --> 00:38:30,910
source X the sales table and we we

00:38:25,900 --> 00:38:32,800
convert this into a into a sequel query

00:38:30,910 --> 00:38:35,440
that can be executed on that data source

00:38:32,800 --> 00:38:39,610
so selecting the customer ID the cell ID

00:38:35,440 --> 00:38:41,620
from from the sales table we do the same

00:38:39,610 --> 00:38:42,790
for this other piece here gives us a

00:38:41,620 --> 00:38:43,840
slightly different query we just

00:38:42,790 --> 00:38:44,950
basically have our we have a where

00:38:43,840 --> 00:38:51,420
clause in there as well

00:38:44,950 --> 00:38:54,430
and yeah and then after we've done that

00:38:51,420 --> 00:38:57,190
we can then take the SPARC sequel

00:38:54,430 --> 00:38:59,740
dialect and transform the rest of the

00:38:57,190 --> 00:39:04,150
query into something that we can be

00:38:59,740 --> 00:39:05,830
actually executed in SPARC so this is

00:39:04,150 --> 00:39:07,990
now how it looks after we've broken it

00:39:05,830 --> 00:39:13,140
down and converted these things into

00:39:07,990 --> 00:39:15,190
SPARC tables well those pre there's some

00:39:13,140 --> 00:39:16,660
queries from the previous slide we've

00:39:15,190 --> 00:39:20,650
actually labeled as well right so you've

00:39:16,660 --> 00:39:24,760
got you've got Table one type t1 t2 for

00:39:20,650 --> 00:39:27,580
those separate SPARC tables and now we

00:39:24,760 --> 00:39:29,470
basically have this this spark spark

00:39:27,580 --> 00:39:32,200
join and a spark limit because this will

00:39:29,470 --> 00:39:34,870
actually be executed in spark so we've

00:39:32,200 --> 00:39:39,280
just done a straight translation from an

00:39:34,870 --> 00:39:41,230
innumerable join which is a calcite

00:39:39,280 --> 00:39:44,140
concept into something that spark would

00:39:41,230 --> 00:39:46,240
understand and then we convert this

00:39:44,140 --> 00:39:47,740
final piece we can also do this using

00:39:46,240 --> 00:39:52,240
calcite actually we can convert this

00:39:47,740 --> 00:39:54,310
final piece into a into a query and then

00:39:52,240 --> 00:39:56,590
convert that query into the spark sequel

00:39:54,310 --> 00:40:00,250
dialect so that ends up with a very

00:39:56,590 --> 00:40:02,860
simple select star from t1 join t2 using

00:40:00,250 --> 00:40:04,450
the customer ID limit 10 and t1 and t2

00:40:02,860 --> 00:40:07,360
are data frames at this

00:40:04,450 --> 00:40:09,010
point and the nice thing is that in

00:40:07,360 --> 00:40:11,440
spark you can actually define these data

00:40:09,010 --> 00:40:14,740
frames with all of this pushed down that

00:40:11,440 --> 00:40:16,450
we've created that we kind of have this

00:40:14,740 --> 00:40:18,190
in this knowledge of about what needs to

00:40:16,450 --> 00:40:24,610
be really pushed down and constructed in

00:40:18,190 --> 00:40:28,030
those data frames so using this approach

00:40:24,610 --> 00:40:31,780
we basically get the full scalability of

00:40:28,030 --> 00:40:34,150
SPARC along with the full push down

00:40:31,780 --> 00:40:36,100
capabilities of calcite plus of course

00:40:34,150 --> 00:40:39,160
we're able to keep this full calcite

00:40:36,100 --> 00:40:40,420
toolbox that we wanted to use we don't

00:40:39,160 --> 00:40:42,580
have any more bottlenecks through this

00:40:40,420 --> 00:40:43,930
in-memory layer because we're now

00:40:42,580 --> 00:40:45,880
actually executing the queries directly

00:40:43,930 --> 00:40:48,130
on SPARC so we don't need to actually

00:40:45,880 --> 00:40:51,490
pull any data through that single load

00:40:48,130 --> 00:40:57,580
net single node layer that we have you

00:40:51,490 --> 00:40:59,530
know virtualization layer anymore and we

00:40:57,580 --> 00:41:02,110
can even use SPARC to persist the

00:40:59,530 --> 00:41:04,420
results so we can tell SPARC to write

00:41:02,110 --> 00:41:10,450
this into an external database or into a

00:41:04,420 --> 00:41:12,010
parka file however we like there and the

00:41:10,450 --> 00:41:13,960
nice thing about this approach is that

00:41:12,010 --> 00:41:18,970
it's relatively generic as well you

00:41:13,960 --> 00:41:21,580
could actually build build one of these

00:41:18,970 --> 00:41:24,970
backends for for a completely different

00:41:21,580 --> 00:41:28,030
query engine execution engine I should

00:41:24,970 --> 00:41:29,950
say so I mean drill flink presto we can

00:41:28,030 --> 00:41:32,050
certainly imagine that we might be able

00:41:29,950 --> 00:41:38,680
to to use those instead and swap those

00:41:32,050 --> 00:41:42,000
out instead of SPARC as well so yep and

00:41:38,680 --> 00:41:44,710
that's that's it actually if you like to

00:41:42,000 --> 00:41:48,340
follow me on Twitter I put the slides up

00:41:44,710 --> 00:41:50,290
there later have a look at what Conti

00:41:48,340 --> 00:41:54,420
AMA are doing on our website and of

00:41:50,290 --> 00:41:56,380
course check out the the Apache calcite

00:41:54,420 --> 00:41:59,800
website as well which has some nice

00:41:56,380 --> 00:42:06,160
documentation on all of this any

00:41:59,800 --> 00:42:09,730
questions what is the in process

00:42:06,160 --> 00:42:14,230
override of a java processing in single

00:42:09,730 --> 00:42:16,180
data source yeah as I said it's it's

00:42:14,230 --> 00:42:18,250
negligible

00:42:16,180 --> 00:42:21,579
so of course it depends if you're

00:42:18,250 --> 00:42:23,920
pulling out millions of rows then you've

00:42:21,579 --> 00:42:26,319
got to be careful there but generally if

00:42:23,920 --> 00:42:28,900
you have full push down you should just

00:42:26,319 --> 00:42:31,599
be able to pull out row by row right so

00:42:28,900 --> 00:42:34,029
you could have a fetch size for example

00:42:31,599 --> 00:42:35,859
in your database of 50 rows so you pull

00:42:34,029 --> 00:42:38,920
out 50 rows and since you're actually

00:42:35,859 --> 00:42:40,539
not doing any computation in that memory

00:42:38,920 --> 00:42:41,859
layer there's actually not really much

00:42:40,539 --> 00:42:43,059
overhead because you're just pulling out

00:42:41,859 --> 00:42:45,190
the rows bases you're putting out the

00:42:43,059 --> 00:42:46,990
results set as long as you can push down

00:42:45,190 --> 00:42:52,450
the full query you shouldn't have too

00:42:46,990 --> 00:42:56,109
many problems there yeah I wanted to go

00:42:52,450 --> 00:42:58,089
back to when you talked about the

00:42:56,109 --> 00:43:01,029
optimization that you did where you

00:42:58,089 --> 00:43:04,359
separated out the planning phase from

00:43:01,029 --> 00:43:05,680
the I forget I'm two phases the logical

00:43:04,359 --> 00:43:07,900
planning on the the physical plan

00:43:05,680 --> 00:43:10,420
exactly yeah and so it seemed like magic

00:43:07,900 --> 00:43:10,839
I don't really understand what happened

00:43:10,420 --> 00:43:12,970
there

00:43:10,839 --> 00:43:15,390
I can you explain a little bit about why

00:43:12,970 --> 00:43:17,920
you got an improvement from doing that

00:43:15,390 --> 00:43:20,890
yeah one of the the biggest reasons is

00:43:17,920 --> 00:43:22,420
that the the cost-based optimizer you've

00:43:20,890 --> 00:43:23,680
you've just got to be careful with like

00:43:22,420 --> 00:43:24,099
you've you've got to know what you're

00:43:23,680 --> 00:43:25,990
doing

00:43:24,099 --> 00:43:28,599
so the cost-based optimizer is basically

00:43:25,990 --> 00:43:30,250
state of the art if you know what you're

00:43:28,599 --> 00:43:31,480
doing you should definitely try and use

00:43:30,250 --> 00:43:33,430
that as much as possible but if you

00:43:31,480 --> 00:43:35,170
don't know exactly what you're doing it

00:43:33,430 --> 00:43:37,359
can take a lot of time to build a plan

00:43:35,170 --> 00:43:39,520
which might not necessarily be the most

00:43:37,359 --> 00:43:42,279
optimal plan that you want in the end so

00:43:39,520 --> 00:43:43,960
you've got to be careful on the other

00:43:42,279 --> 00:43:45,460
hand the the rule based optimizer you

00:43:43,960 --> 00:43:47,380
can just give it tons and tons of rules

00:43:45,460 --> 00:43:49,119
and it will just apply them and keep

00:43:47,380 --> 00:43:50,950
applying the rules until nothing changes

00:43:49,119 --> 00:43:53,380
anymore so the only thing you've got to

00:43:50,950 --> 00:43:54,789
be careful there is cycles so you could

00:43:53,380 --> 00:43:56,380
have a rule changing something in other

00:43:54,789 --> 00:43:59,380
rule changing it back and then you go

00:43:56,380 --> 00:44:02,279
into some kind of infinite loop but yeah

00:43:59,380 --> 00:44:02,279
other than that

00:44:07,329 --> 00:44:13,390
the Scout site has any support for UDF's

00:44:10,700 --> 00:44:14,960
user-defined functions and the like I

00:44:13,390 --> 00:44:17,569
believe it does

00:44:14,960 --> 00:44:19,280
yeah MIT does support UDF's you can

00:44:17,569 --> 00:44:20,000
actually even construct them in calcite

00:44:19,280 --> 00:44:23,059
itself

00:44:20,000 --> 00:44:26,359
and then use them inside of your queries

00:44:23,059 --> 00:44:29,089
you can define a Java function which

00:44:26,359 --> 00:44:30,410
which operates as a UDF and then you can

00:44:29,089 --> 00:44:33,289
execute that in your queries of course

00:44:30,410 --> 00:44:39,079
that will happen in memory but yeah it's

00:44:33,289 --> 00:44:42,289
possible yeah thanks for a nice

00:44:39,079 --> 00:44:44,440
presentation you had to pull out some

00:44:42,289 --> 00:44:47,390
tricks to make this spark calcite

00:44:44,440 --> 00:44:50,390
execution running as I said do you see

00:44:47,390 --> 00:44:53,780
an easy way or reachable way for the

00:44:50,390 --> 00:44:56,119
community to kind of do this in calcite

00:44:53,780 --> 00:44:59,270
sir and others can use it more simply as

00:44:56,119 --> 00:45:02,450
the spark adapters it was intended to be

00:44:59,270 --> 00:45:03,950
I think yeah it's a good question is

00:45:02,450 --> 00:45:08,030
something we've definitely thought a lot

00:45:03,950 --> 00:45:11,000
about right now is it's really built

00:45:08,030 --> 00:45:12,619
into our application and we've thought

00:45:11,000 --> 00:45:15,049
about ways of extracting that and to

00:45:12,619 --> 00:45:16,490
make it nice in calcite so we'll

00:45:15,049 --> 00:45:17,750
definitely continue thinking about that

00:45:16,490 --> 00:45:18,920
and I would really like to actually push

00:45:17,750 --> 00:45:24,400
that back to the community if it's

00:45:18,920 --> 00:45:28,240
possible for sure any other questions

00:45:24,400 --> 00:45:28,240
okay so let's tank

00:45:30,850 --> 00:45:35,429

YouTube URL: https://www.youtube.com/watch?v=4JAOkLKrcYE


