Title: Apache OODT: From the beginning to big data management
Publication date: 2013-10-17
Playlist: Apachecon NA 2013 - day 2
Description: 
	Dan Crichton
ApacheCon NA 2013
Apache In Science
Captions: 
	00:00:00,000 --> 00:00:04,890
um good morning as Chris said I'm Dan

00:00:02,669 --> 00:00:06,359
Crichton just say a initial question how

00:00:04,890 --> 00:00:08,220
many people are kind of part of

00:00:06,359 --> 00:00:11,429
committers now right now an ODT in this

00:00:08,220 --> 00:00:13,620
room we've got a few about by sixth and

00:00:11,429 --> 00:00:16,800
some of you guys might be wondering what

00:00:13,620 --> 00:00:18,390
ott actually means I'll get to it I work

00:00:16,800 --> 00:00:20,820
with a government so often we make

00:00:18,390 --> 00:00:22,680
really terrible acronyms for things so

00:00:20,820 --> 00:00:23,820
it was this is this is the case in point

00:00:22,680 --> 00:00:26,160
where it's something that never got lost

00:00:23,820 --> 00:00:27,869
should probably gotten lost but it

00:00:26,160 --> 00:00:32,460
picked up traction it has been with us

00:00:27,869 --> 00:00:33,450
ever since a little bit in terms of what

00:00:32,460 --> 00:00:35,219
we're going to talk about today I

00:00:33,450 --> 00:00:37,590
thought you know given that this is a

00:00:35,219 --> 00:00:38,850
science track I thought that people

00:00:37,590 --> 00:00:42,300
might be interested in understanding

00:00:38,850 --> 00:00:45,090
some of our challenges we have in space

00:00:42,300 --> 00:00:48,629
data management in working with space

00:00:45,090 --> 00:00:50,730
systems at JPL I was gonna spend some

00:00:48,629 --> 00:00:53,160
time talking about kind of our movement

00:00:50,730 --> 00:00:56,210
towards Big Data kind of what has been

00:00:53,160 --> 00:00:58,680
happening in science that's really

00:00:56,210 --> 00:01:02,070
driving us towards thinking more and

00:00:58,680 --> 00:01:05,250
more about Big Data that really has led

00:01:02,070 --> 00:01:06,810
to the history of OD Chi and why ODT was

00:01:05,250 --> 00:01:08,460
created to begin with we're really

00:01:06,810 --> 00:01:10,860
looking at and thinking about you know

00:01:08,460 --> 00:01:12,270
how do we begin to address big data

00:01:10,860 --> 00:01:15,299
management when it's and what are some

00:01:12,270 --> 00:01:16,950
of the challenges and then I'm going to

00:01:15,299 --> 00:01:18,689
talk about some of the applications and

00:01:16,950 --> 00:01:22,950
I suspect you'll be hearing about these

00:01:18,689 --> 00:01:25,590
next two days today throughout the day I

00:01:22,950 --> 00:01:29,790
think there's several talks that are on

00:01:25,590 --> 00:01:31,439
different aspects of ODT and then kind

00:01:29,790 --> 00:01:35,009
of start thinking about what what about

00:01:31,439 --> 00:01:37,530
going beyond science ODT is addressing a

00:01:35,009 --> 00:01:38,430
lot of challenges in science but we

00:01:37,530 --> 00:01:40,250
believe that there's a lot of

00:01:38,430 --> 00:01:43,340
opportunities to actually think about

00:01:40,250 --> 00:01:46,229
how ODT can be used beyond just science

00:01:43,340 --> 00:01:48,270
it part of my presentation style is you

00:01:46,229 --> 00:01:50,549
know I'm hoping that you guys if you

00:01:48,270 --> 00:01:51,630
have questions you ask questions we can

00:01:50,549 --> 00:01:52,860
certainly do at the end but if you have

00:01:51,630 --> 00:01:54,509
things that we're going through and you

00:01:52,860 --> 00:01:55,590
want to say hey can you clarify this you

00:01:54,509 --> 00:01:57,149
know I think it's a small enough room

00:01:55,590 --> 00:02:00,030
that I'd be happy to take questions to

00:01:57,149 --> 00:02:02,549
as we're going through a little bit

00:02:00,030 --> 00:02:07,890
about me I'm a principal computer

00:02:02,549 --> 00:02:11,039
scientist adjoin JPL in 1995 I spent

00:02:07,890 --> 00:02:12,959
about twenty five years in past 25 years

00:02:11,039 --> 00:02:13,970
it seems like I'm not that old but maybe

00:02:12,959 --> 00:02:16,710
I

00:02:13,970 --> 00:02:18,450
developing software systems wearing

00:02:16,710 --> 00:02:22,320
different hats I've gone all the way

00:02:18,450 --> 00:02:24,330
from being sort of an intern to being a

00:02:22,320 --> 00:02:27,330
software developer engineer to

00:02:24,330 --> 00:02:30,750
architecting and now I feel like I don't

00:02:27,330 --> 00:02:33,180
get to touch code enough but it's one of

00:02:30,750 --> 00:02:36,210
the challenges of kind of going on your

00:02:33,180 --> 00:02:38,640
career I actually wear two hats at JPL I

00:02:36,210 --> 00:02:40,500
exist in two different organizations one

00:02:38,640 --> 00:02:42,600
is overseen how we actually build

00:02:40,500 --> 00:02:46,470
planetary systems the others actually

00:02:42,600 --> 00:02:48,150
earth science and I'm also a 8 what we

00:02:46,470 --> 00:02:50,760
call p I that's a principal investigator

00:02:48,150 --> 00:02:52,980
for actually working and proposing

00:02:50,760 --> 00:02:54,390
working on systems doing research so

00:02:52,980 --> 00:02:55,950
actually work with the National Cancer

00:02:54,390 --> 00:02:57,690
Institute as well so working in

00:02:55,950 --> 00:02:59,880
planetary working on earth and helping

00:02:57,690 --> 00:03:02,250
cancer research actually build Science

00:02:59,880 --> 00:03:03,570
Space Systems so you can see a lot of

00:03:02,250 --> 00:03:04,890
the reason why we're trying to look at

00:03:03,570 --> 00:03:06,600
how do we actually build common

00:03:04,890 --> 00:03:08,880
capabilities across all these systems i

00:03:06,600 --> 00:03:10,680
served in the last couple years on a

00:03:08,880 --> 00:03:12,390
national research council committee on

00:03:10,680 --> 00:03:15,630
massive data that's to be coming out

00:03:12,390 --> 00:03:18,450
pretty soon and kind of my reason I'm

00:03:15,630 --> 00:03:21,840
here to talk first is that I was the

00:03:18,450 --> 00:03:23,070
original pi/4 ODT most of the codes

00:03:21,840 --> 00:03:25,890
probably gone by now and ripped out by

00:03:23,070 --> 00:03:29,010
everybody else but I get picked on

00:03:25,890 --> 00:03:30,959
sometimes but but but you know the the

00:03:29,010 --> 00:03:39,269
start ability T was something that we

00:03:30,959 --> 00:03:42,209
launched in 1998 at JPL so when you look

00:03:39,269 --> 00:03:44,190
at this picture what do you see you see

00:03:42,209 --> 00:03:48,540
on the upper left which we'll talk about

00:03:44,190 --> 00:03:50,730
meant you see our Mars Curiosity this is

00:03:48,540 --> 00:03:53,010
a rover that's sitting on the surface of

00:03:50,730 --> 00:03:55,530
Mars talking to orbiting satellites that

00:03:53,010 --> 00:03:57,450
communicate back to earth this is is you

00:03:55,530 --> 00:03:58,830
know things that take ten minutes of

00:03:57,450 --> 00:04:00,840
light time to actually get that

00:03:58,830 --> 00:04:02,100
communication back to earth so things

00:04:00,840 --> 00:04:05,390
that are definitely remote-sensing

00:04:02,100 --> 00:04:08,430
instruments that are capturing data on

00:04:05,390 --> 00:04:11,130
the upper right you see our earth

00:04:08,430 --> 00:04:13,890
science satellites that orbiting the

00:04:11,130 --> 00:04:15,950
earth again remote sensing the thing on

00:04:13,890 --> 00:04:20,040
the bottom which you might not realize

00:04:15,950 --> 00:04:21,870
see if I can actually show there there's

00:04:20,040 --> 00:04:25,500
a actually a baby in there it's an

00:04:21,870 --> 00:04:26,640
infant that's actually wired and I say

00:04:25,500 --> 00:04:27,150
they're actually taking remote

00:04:26,640 --> 00:04:30,600
observation

00:04:27,150 --> 00:04:33,330
in situations if you will this infant

00:04:30,600 --> 00:04:36,210
for actually measuring and in

00:04:33,330 --> 00:04:37,490
understanding what it is and so there's

00:04:36,210 --> 00:04:39,150
there's actually quite a bit of

00:04:37,490 --> 00:04:42,419
connection between these and why I've

00:04:39,150 --> 00:04:44,250
given talks on ODT but what we've really

00:04:42,419 --> 00:04:47,220
focused on is how do we actually capture

00:04:44,250 --> 00:04:49,199
all this observational data from all

00:04:47,220 --> 00:04:50,850
these experiments you can call this an

00:04:49,199 --> 00:04:55,560
experiment that we're actually do in

00:04:50,850 --> 00:04:57,660
science just to give you a little bit of

00:04:55,560 --> 00:05:00,750
history so so thinking about this what

00:04:57,660 --> 00:05:04,380
is JPL do this well back in the early

00:05:00,750 --> 00:05:06,810
30s 1936 theater von karman who is a

00:05:04,380 --> 00:05:11,720
professor at Caltech began rocket

00:05:06,810 --> 00:05:16,229
testing in in the rio seco that led to

00:05:11,720 --> 00:05:17,760
initially to some missile testing and so

00:05:16,229 --> 00:05:19,830
forth with the army so we were not a

00:05:17,760 --> 00:05:21,419
NASA Center NASA actually didn't start

00:05:19,830 --> 00:05:23,880
till nineteen fifty-nine we're actually

00:05:21,419 --> 00:05:28,620
doing army testing and we were working

00:05:23,880 --> 00:05:30,690
with launching a rockets what what our

00:05:28,620 --> 00:05:33,030
initial director at JPL really began to

00:05:30,690 --> 00:05:35,490
realize is that wasn't it rocket that

00:05:33,030 --> 00:05:39,120
was important it was the payload so we

00:05:35,490 --> 00:05:41,039
switched from really in 1958 with the

00:05:39,120 --> 00:05:42,750
Sputnik era from actually building

00:05:41,039 --> 00:05:45,030
rockets to actually creating the

00:05:42,750 --> 00:05:47,010
payloads that flew on the rockets and

00:05:45,030 --> 00:05:48,300
that became a seminal change for JPL

00:05:47,010 --> 00:05:50,099
because we began to really think about

00:05:48,300 --> 00:05:52,560
how do we actually build the instruments

00:05:50,099 --> 00:05:54,570
we actually care about that's led to

00:05:52,560 --> 00:05:57,120
planetary science that's led to work

00:05:54,570 --> 00:05:59,250
with astrophysics and then to earth

00:05:57,120 --> 00:06:01,800
science as well so we have experience

00:05:59,250 --> 00:06:05,159
and working with all these areas the key

00:06:01,800 --> 00:06:06,659
thing is at JPL were a what we call a FF

00:06:05,159 --> 00:06:08,190
our DC where a federal research

00:06:06,659 --> 00:06:11,940
development center or division of

00:06:08,190 --> 00:06:13,740
Caltech we are we're not not NASA

00:06:11,940 --> 00:06:15,389
employee so we've got the ability to be

00:06:13,740 --> 00:06:17,039
a research lab and actually begin to

00:06:15,389 --> 00:06:19,590
apply what we're doing to other areas

00:06:17,039 --> 00:06:21,570
that if you think about it some of the

00:06:19,590 --> 00:06:23,430
impetus of why we did ODT not only to

00:06:21,570 --> 00:06:25,500
address our areas in physical science

00:06:23,430 --> 00:06:27,449
but how could we actually take what

00:06:25,500 --> 00:06:32,220
we're doing and really address national

00:06:27,449 --> 00:06:34,650
priority hard hard core questions this

00:06:32,220 --> 00:06:38,310
just shows some of the sample JPL

00:06:34,650 --> 00:06:39,779
missions that we have line this is

00:06:38,310 --> 00:06:40,409
already outdated because I don't have

00:06:39,779 --> 00:06:42,149
the

00:06:40,409 --> 00:06:44,749
Mars Curiosity on here but you can see

00:06:42,149 --> 00:06:46,769
that we've got a number of different

00:06:44,749 --> 00:06:48,509
spacecraft are flying in planetary

00:06:46,769 --> 00:06:50,269
science alone we have a hundred and ten

00:06:48,509 --> 00:06:52,800
instruments that are making observations

00:06:50,269 --> 00:06:54,239
in the solar system these are things

00:06:52,800 --> 00:06:57,809
that are actually returning physical

00:06:54,239 --> 00:06:59,399
data so there's quite a bit of a variety

00:06:57,809 --> 00:07:00,839
and when these things major often we

00:06:59,399 --> 00:07:02,699
build instruments that are unique

00:07:00,839 --> 00:07:04,679
they're one of the kind they're built in

00:07:02,699 --> 00:07:06,149
universities and so are some of our

00:07:04,679 --> 00:07:09,809
challenges that you know we can't

00:07:06,149 --> 00:07:11,909
predict in five years what kinds of what

00:07:09,809 --> 00:07:13,139
kinds of science experiments what kinds

00:07:11,909 --> 00:07:15,659
of instruments they're actually going to

00:07:13,139 --> 00:07:18,659
be built and so part of what we need to

00:07:15,659 --> 00:07:20,879
do is have an ever evolving capability

00:07:18,659 --> 00:07:22,529
to be able to capture the data products

00:07:20,879 --> 00:07:26,149
that we call them for these instruments

00:07:22,529 --> 00:07:26,149
and be able to serve those data products

00:07:26,599 --> 00:07:32,309
so you know the latest feat hopefully

00:07:29,429 --> 00:07:34,079
everybody saw it you know who were quite

00:07:32,309 --> 00:07:37,349
proud of this but the latest feat was

00:07:34,079 --> 00:07:41,039
our Mars curiosity which landed on march

00:07:37,349 --> 00:07:44,039
six at gale crater on Mars major event

00:07:41,039 --> 00:07:46,199
at people may have read all the news

00:07:44,039 --> 00:07:47,969
about it or watch the videos or we're

00:07:46,199 --> 00:07:50,369
watching a line like all of us to be

00:07:47,969 --> 00:07:51,869
able to to see what was going on the

00:07:50,369 --> 00:07:55,529
major thing was this this idea of

00:07:51,869 --> 00:07:58,079
actually lowering the the Mars rover and

00:07:55,529 --> 00:07:59,729
then cutting a tether and then flying

00:07:58,079 --> 00:08:01,800
away and that was a what we call a

00:07:59,729 --> 00:08:04,649
skycrane so kind of an amazing and

00:08:01,800 --> 00:08:06,719
engineering feat and and so this this is

00:08:04,649 --> 00:08:08,909
an important part of JPL to be able to

00:08:06,719 --> 00:08:12,599
get things on two planets and sometimes

00:08:08,909 --> 00:08:13,619
we even here unless a JPL that that you

00:08:12,599 --> 00:08:15,659
know once we've gotten there we're done

00:08:13,619 --> 00:08:17,699
well the answer is no once we got there

00:08:15,659 --> 00:08:20,729
the science begins and that's really

00:08:17,699 --> 00:08:22,829
where groups like the ones I'm involved

00:08:20,729 --> 00:08:26,189
in my colleagues here here from JPL and

00:08:22,829 --> 00:08:27,719
other other centers is that that's when

00:08:26,189 --> 00:08:31,169
they think the critical science begins

00:08:27,719 --> 00:08:32,939
and we really begin to take over so when

00:08:31,169 --> 00:08:35,610
we send out at a mission our spacecraft

00:08:32,939 --> 00:08:37,110
mission you know one of the big

00:08:35,610 --> 00:08:39,449
challenges is actually being able to

00:08:37,110 --> 00:08:41,939
communicate back to earth so we've got

00:08:39,449 --> 00:08:46,500
an infrastructure that exists around the

00:08:41,939 --> 00:08:48,779
world that has three major receiving

00:08:46,500 --> 00:08:51,059
centers we call them the NASA Deep Space

00:08:48,779 --> 00:08:52,829
Network these are stations that are at

00:08:51,059 --> 00:08:53,940
three points so that we always have line

00:08:52,829 --> 00:08:56,220
of sight to a space

00:08:53,940 --> 00:08:57,870
craft which is actually out out in the

00:08:56,220 --> 00:09:00,510
solar system that's that's that's

00:08:57,870 --> 00:09:02,520
critical and these things are huge 70

00:09:00,510 --> 00:09:04,350
meter antennas that are locking on to

00:09:02,520 --> 00:09:06,630
spacecraft and able to actually receive

00:09:04,350 --> 00:09:08,010
things that are now at the the edges of

00:09:06,630 --> 00:09:12,240
their solar system that's those are our

00:09:08,010 --> 00:09:15,120
Voyager spacecraft missions just to give

00:09:12,240 --> 00:09:16,980
you some example challenges and then

00:09:15,120 --> 00:09:18,420
I'll get get now and end of the software

00:09:16,980 --> 00:09:21,960
challenges but I think this is really

00:09:18,420 --> 00:09:24,780
fascinating when we landed the Mars

00:09:21,960 --> 00:09:27,540
Curiosity rover we were we were very

00:09:24,780 --> 00:09:29,060
very close we were it within hundreds of

00:09:27,540 --> 00:09:31,920
yards of where we thought we would land

00:09:29,060 --> 00:09:33,180
that that precision of navigation when

00:09:31,920 --> 00:09:36,090
you're when you're traveling millions of

00:09:33,180 --> 00:09:38,310
miles is is an amazing accomplishment so

00:09:36,090 --> 00:09:41,450
this gives us an another example this is

00:09:38,310 --> 00:09:45,090
our spirit rover that we launched in

00:09:41,450 --> 00:09:47,370
2004 in this is analogy often our

00:09:45,090 --> 00:09:50,160
director uses when you actually land on

00:09:47,370 --> 00:09:53,240
Mars the navigation precision is amazing

00:09:50,160 --> 00:09:56,040
it's basically like being able to use a

00:09:53,240 --> 00:09:58,530
play golf you tee off from Earth and

00:09:56,040 --> 00:10:01,500
we're close enough basically to to make

00:09:58,530 --> 00:10:03,690
a birdie if it's a three-part ol so

00:10:01,500 --> 00:10:04,920
we're really really pretty amazing kind

00:10:03,690 --> 00:10:07,980
of accomplishment to actually figure out

00:10:04,920 --> 00:10:09,840
where where you're landing and that is

00:10:07,980 --> 00:10:11,580
with the target that's moving as this

00:10:09,840 --> 00:10:14,070
says it's 60,000 miles per hour so we

00:10:11,580 --> 00:10:15,540
landed curiosity the calculations were

00:10:14,070 --> 00:10:17,100
how do we actually land how to actually

00:10:15,540 --> 00:10:21,300
find a precision way to actually land

00:10:17,100 --> 00:10:23,730
with everything always moving so so

00:10:21,300 --> 00:10:26,610
we've landed and this is where we really

00:10:23,730 --> 00:10:28,650
become part of the picture so software

00:10:26,610 --> 00:10:30,180
plays a critical role certainly the

00:10:28,650 --> 00:10:31,950
flight software plays a critical role in

00:10:30,180 --> 00:10:35,130
what we won't build spacecraft and when

00:10:31,950 --> 00:10:37,890
we launch and so the ground data systems

00:10:35,130 --> 00:10:39,630
but more than that for us in science

00:10:37,890 --> 00:10:41,820
it's the science production and

00:10:39,630 --> 00:10:43,440
processing and science analysis that

00:10:41,820 --> 00:10:45,630
that really be that we really get

00:10:43,440 --> 00:10:48,570
involved in to actually help support the

00:10:45,630 --> 00:10:50,250
community and the worldwide scientists

00:10:48,570 --> 00:10:53,220
and actually being able to use and work

00:10:50,250 --> 00:10:56,820
with the data the data as it comes down

00:10:53,220 --> 00:10:58,800
to earth is its telemetry data it's it's

00:10:56,820 --> 00:11:00,089
a signal we've got to take that signal

00:10:58,800 --> 00:11:01,440
we got to split the signal we've got

00:11:00,089 --> 00:11:03,390
extract out what we would call

00:11:01,440 --> 00:11:04,950
engineering data from that we've got

00:11:03,390 --> 00:11:07,020
extract out the science data from that

00:11:04,950 --> 00:11:07,350
and so we've got to begin to create what

00:11:07,020 --> 00:11:10,860
we call

00:11:07,350 --> 00:11:12,630
all pipelines that allow us to bring the

00:11:10,860 --> 00:11:13,950
data streams in be able to start to

00:11:12,630 --> 00:11:16,350
separate and extract out the science

00:11:13,950 --> 00:11:18,840
data I begin to actually build what we

00:11:16,350 --> 00:11:21,480
call science observations for use by the

00:11:18,840 --> 00:11:23,580
community and that's really the focus of

00:11:21,480 --> 00:11:26,070
what we look at is how do we actually

00:11:23,580 --> 00:11:27,570
once we can we start to get the data how

00:11:26,070 --> 00:11:29,460
do we actually generate these higher

00:11:27,570 --> 00:11:30,990
order data Prague's we call them how do

00:11:29,460 --> 00:11:32,880
we actually start to manage the data

00:11:30,990 --> 00:11:35,490
products and how do we be able to serve

00:11:32,880 --> 00:11:38,670
those to the worldwide community and

00:11:35,490 --> 00:11:40,290
i'll talk about to utilize come up some

00:11:38,670 --> 00:11:44,220
of the challenges which is is just the

00:11:40,290 --> 00:11:46,080
increase of data so as i mentioned you

00:11:44,220 --> 00:11:48,530
know science for us is really i think

00:11:46,080 --> 00:11:52,080
more than ever has become a worldwide

00:11:48,530 --> 00:11:54,090
activity in planetary science until

00:11:52,080 --> 00:11:57,030
about two thousand the US was with was

00:11:54,090 --> 00:11:58,620
virtually the well the only nations i

00:11:57,030 --> 00:12:02,220
was actually flying any kind of

00:11:58,620 --> 00:12:04,170
spacecraft your ISA or the European

00:12:02,220 --> 00:12:06,600
Space Agency has begun and it's part of

00:12:04,170 --> 00:12:10,050
that mix the Indians have flown Sean

00:12:06,600 --> 00:12:12,660
driana and orbiting the moon the Chinese

00:12:10,050 --> 00:12:15,390
are launching spacecraft the Japanese

00:12:12,660 --> 00:12:18,000
were launching spacecraft and so what if

00:12:15,390 --> 00:12:21,540
we look it look at a very very 1980s

00:12:18,000 --> 00:12:23,160
1990s model we could see a see a very

00:12:21,540 --> 00:12:26,450
different picture than we see now which

00:12:23,160 --> 00:12:29,790
is the fact that we've got a worldwide

00:12:26,450 --> 00:12:31,890
observation system really of our of

00:12:29,790 --> 00:12:33,960
what's going on in space both for Earth

00:12:31,890 --> 00:12:36,150
for interplanetary research for

00:12:33,960 --> 00:12:38,370
astrophysics and we've got a community a

00:12:36,150 --> 00:12:39,810
worldwide scientists that really want to

00:12:38,370 --> 00:12:41,040
be able to go they're not concerned with

00:12:39,810 --> 00:12:42,090
where the day is coming from they're

00:12:41,040 --> 00:12:43,230
concerned with once they get the data

00:12:42,090 --> 00:12:45,330
how they actually do research on that

00:12:43,230 --> 00:12:47,750
and so part of our goal is how do we

00:12:45,330 --> 00:12:50,160
start to provide a way to do

00:12:47,750 --> 00:12:51,450
distribution of data from highly

00:12:50,160 --> 00:12:53,700
distributed environments these are

00:12:51,450 --> 00:12:55,530
environments which aware where different

00:12:53,700 --> 00:12:56,940
groups are managing data and you've got

00:12:55,530 --> 00:12:59,460
data that's growing at astronomical

00:12:56,940 --> 00:13:02,520
rates and I'll show that a minute no pun

00:12:59,460 --> 00:13:04,950
intended so we've got systems that are

00:13:02,520 --> 00:13:07,710
very heterogeneous part of the challenge

00:13:04,950 --> 00:13:08,880
that we have in working is we've got

00:13:07,710 --> 00:13:10,710
different groups building different

00:13:08,880 --> 00:13:14,700
systems we want to be able to access the

00:13:10,710 --> 00:13:18,270
data from those systems we've got often

00:13:14,700 --> 00:13:19,650
often a lot of the the the the data are

00:13:18,270 --> 00:13:21,089
built around the instruments themselves

00:13:19,650 --> 00:13:22,620
and so we're looking at how to

00:13:21,089 --> 00:13:24,319
actually make that data useful and

00:13:22,620 --> 00:13:27,540
usable when it cut when it's actually

00:13:24,319 --> 00:13:29,129
developed and how do we over time be

00:13:27,540 --> 00:13:31,949
able to support the instruments which

00:13:29,129 --> 00:13:34,110
might have more capability but not force

00:13:31,949 --> 00:13:38,370
a standard stock kind of structure on

00:13:34,110 --> 00:13:40,680
that data one of the major complaints by

00:13:38,370 --> 00:13:42,930
our science community has been is that

00:13:40,680 --> 00:13:44,370
access traditionally has been been

00:13:42,930 --> 00:13:46,110
difficult I think that's getting better

00:13:44,370 --> 00:13:49,230
I think there's more and more data

00:13:46,110 --> 00:13:51,779
that's being served to the community but

00:13:49,230 --> 00:13:54,620
the question now is becoming is how do

00:13:51,779 --> 00:13:57,209
we move from not only access to data but

00:13:54,620 --> 00:13:59,579
really what we could concerned about in

00:13:57,209 --> 00:14:01,050
terms of big data is analysis that data

00:13:59,579 --> 00:14:02,459
how do we actually begin to extract

00:14:01,050 --> 00:14:04,199
meaning from that data and that's a very

00:14:02,459 --> 00:14:05,730
challenging problem when your data is

00:14:04,199 --> 00:14:07,259
distributed when it's large and

00:14:05,730 --> 00:14:09,660
voluminous when you want to be able to

00:14:07,259 --> 00:14:13,980
figure out how to integrate it from

00:14:09,660 --> 00:14:18,660
multiple places this just shows you a

00:14:13,980 --> 00:14:20,040
picture of planetary science the

00:14:18,660 --> 00:14:23,759
interesting thing about planetary

00:14:20,040 --> 00:14:26,100
science is that we started flying

00:14:23,759 --> 00:14:28,860
missions around nineteen 1960s so

00:14:26,100 --> 00:14:31,439
between 1960 and about two thousand one

00:14:28,860 --> 00:14:33,540
we captured four terabytes of data so it

00:14:31,439 --> 00:14:36,300
tells you in about 40 years that we

00:14:33,540 --> 00:14:38,129
captured four terabytes of data and 2001

00:14:36,300 --> 00:14:40,319
to about 2000 to we captured another

00:14:38,129 --> 00:14:43,319
four terabytes of data so we put a lot

00:14:40,319 --> 00:14:45,990
more capable instruments out in one year

00:14:43,319 --> 00:14:47,220
that began to be able to capture the

00:14:45,990 --> 00:14:48,779
entire collection we'd already captured

00:14:47,220 --> 00:14:51,329
in terms of the archive kalantari

00:14:48,779 --> 00:14:55,769
science and we've seen that grown so

00:14:51,329 --> 00:14:58,470
from 2001 to about now 2012-13 we're a

00:14:55,769 --> 00:15:01,319
half a petabyte so we've grown from four

00:14:58,470 --> 00:15:03,569
terabytes to 500 terabytes in the last

00:15:01,319 --> 00:15:07,579
decade that that growth is going to

00:15:03,569 --> 00:15:11,309
continue on and the data is becoming

00:15:07,579 --> 00:15:12,720
complex to a point that and large enough

00:15:11,309 --> 00:15:14,670
that point that we need to think of

00:15:12,720 --> 00:15:17,160
other paradigms for how we actually give

00:15:14,670 --> 00:15:19,019
the data to our scientists their

00:15:17,160 --> 00:15:20,160
traditional approach is they spin out

00:15:19,019 --> 00:15:23,220
they take their computer they spin up

00:15:20,160 --> 00:15:25,230
IDL or MATLAB or one of their nice it's

00:15:23,220 --> 00:15:26,850
their tools and they download all that

00:15:25,230 --> 00:15:28,559
data but we're beginning to look at ways

00:15:26,850 --> 00:15:33,329
that we need to start to think about

00:15:28,559 --> 00:15:34,950
that differently earth science earth

00:15:33,329 --> 00:15:36,480
science this is just looking at

00:15:34,950 --> 00:15:38,940
what we call level two products these

00:15:36,480 --> 00:15:40,800
are our processed products that we get

00:15:38,940 --> 00:15:43,620
ready to soar grids the earth and things

00:15:40,800 --> 00:15:45,600
like that these are these have grown at

00:15:43,620 --> 00:15:47,280
similar rates where we are in earth

00:15:45,600 --> 00:15:50,160
science looking at at about four

00:15:47,280 --> 00:15:52,590
petabytes of data and so you've seen

00:15:50,160 --> 00:15:56,840
just a massive increase in data that's

00:15:52,590 --> 00:15:59,850
going on there so same challenge

00:15:56,840 --> 00:16:01,200
different discipline and we can keep

00:15:59,850 --> 00:16:02,520
going we can go in astronomy it's the

00:16:01,200 --> 00:16:04,440
same challenge in astronomy and in fact

00:16:02,520 --> 00:16:06,900
astronomy is beginning to think about

00:16:04,440 --> 00:16:08,850
the question about exabytes how do we

00:16:06,900 --> 00:16:11,580
begin to deal with the exabyte range of

00:16:08,850 --> 00:16:13,740
missions where we have data coming down

00:16:11,580 --> 00:16:15,660
the data so massive that we have to

00:16:13,740 --> 00:16:17,580
first to do sampling of the data to

00:16:15,660 --> 00:16:19,650
actually extract out what we think the

00:16:17,580 --> 00:16:21,120
good bits are and then we've got to

00:16:19,650 --> 00:16:22,710
start to create build archives that

00:16:21,120 --> 00:16:24,630
capture them and then a certain field

00:16:22,710 --> 00:16:26,010
services to help analyze them it's a

00:16:24,630 --> 00:16:28,760
very very different approach than what

00:16:26,010 --> 00:16:31,890
we have been doing in the last 30 years

00:16:28,760 --> 00:16:33,210
so moving to this new paradigm as I've

00:16:31,890 --> 00:16:35,270
mentioned you know we've got highly

00:16:33,210 --> 00:16:37,680
distributed multi organizational systems

00:16:35,270 --> 00:16:39,150
systems are moving you know towards

00:16:37,680 --> 00:16:40,680
loosely coupled Federation's and I'll

00:16:39,150 --> 00:16:43,320
show us in a minute and you're going to

00:16:40,680 --> 00:16:45,030
hear some of the the case studies later

00:16:43,320 --> 00:16:47,460
today and tomorrow about the kinds of

00:16:45,030 --> 00:16:49,350
systems that are that we have in science

00:16:47,460 --> 00:16:51,150
where we're building Federation's of

00:16:49,350 --> 00:16:55,050
data archives that need to be able to

00:16:51,150 --> 00:16:57,630
share data sharing up not only data but

00:16:55,050 --> 00:17:00,660
services are becoming more important for

00:16:57,630 --> 00:17:03,660
discovery access and transformation

00:17:00,660 --> 00:17:05,880
rather than downloading a 10 gigabyte

00:17:03,660 --> 00:17:07,890
image what we might want to be able to

00:17:05,880 --> 00:17:09,329
do is download a subset of that image we

00:17:07,890 --> 00:17:10,500
might want to be able to do is transform

00:17:09,329 --> 00:17:11,970
that image we might be I want to be able

00:17:10,500 --> 00:17:14,579
to do other kinds of capabilities and so

00:17:11,970 --> 00:17:16,380
we're seeing cases where we have have

00:17:14,579 --> 00:17:18,870
massive amounts of data where we want to

00:17:16,380 --> 00:17:23,280
push more and more that computation out

00:17:18,870 --> 00:17:24,810
to where the data is located and then we

00:17:23,280 --> 00:17:27,690
want to address some of the challenges

00:17:24,810 --> 00:17:31,290
of what we call complex modeling in just

00:17:27,690 --> 00:17:33,030
interdisciplinary science you know many

00:17:31,290 --> 00:17:35,370
people may think that well you know

00:17:33,030 --> 00:17:37,320
we've got all this data and it's all

00:17:35,370 --> 00:17:41,190
integrated and we can just go off and

00:17:37,320 --> 00:17:43,010
run run sort of interdisciplinary ality

00:17:41,190 --> 00:17:45,740
is that just being able to correlate

00:17:43,010 --> 00:17:47,539
something like like you know temperature

00:17:45,740 --> 00:17:49,700
which is when

00:17:47,539 --> 00:17:51,739
don't stick a thermometer out around the

00:17:49,700 --> 00:17:53,090
earth we actually made radiances and

00:17:51,739 --> 00:17:54,830
then we complete calculate temperature

00:17:53,090 --> 00:17:56,570
but but did we derive it in the same way

00:17:54,830 --> 00:17:58,999
what were the conditions how was the

00:17:56,570 --> 00:18:01,309
calibration of the instrument there's a

00:17:58,999 --> 00:18:04,340
lot of things we're trying to compare

00:18:01,309 --> 00:18:06,470
data becomes a real challenge and so as

00:18:04,340 --> 00:18:09,080
we look at the fact that we can now

00:18:06,470 --> 00:18:10,309
bring all this data online the question

00:18:09,080 --> 00:18:12,769
to do more and more interdisciplinary

00:18:10,309 --> 00:18:14,659
research is one that is becoming more

00:18:12,769 --> 00:18:16,399
important in science so where's your

00:18:14,659 --> 00:18:19,840
changing the way in which we really

00:18:16,399 --> 00:18:19,840
think data analysis has been performed

00:18:20,440 --> 00:18:27,919
so I mentioned the movement towards a

00:18:24,729 --> 00:18:29,239
more of these research networks and this

00:18:27,919 --> 00:18:31,369
will give you an example of some of

00:18:29,239 --> 00:18:33,979
these research networks on the upper

00:18:31,369 --> 00:18:36,499
left you've got the planetary data

00:18:33,979 --> 00:18:39,440
system the planetary data system as I

00:18:36,499 --> 00:18:42,679
mentioned is is archived it's now about

00:18:39,440 --> 00:18:45,559
500 terabytes of data the data is

00:18:42,679 --> 00:18:48,590
distributed across the u.s. organized by

00:18:45,559 --> 00:18:51,529
scientific discipline and that's the

00:18:48,590 --> 00:18:52,849
u.s. we now have Europe that has what

00:18:51,529 --> 00:18:55,489
they call the planetary science archive

00:18:52,849 --> 00:18:57,830
we've got the Indians which is bringing

00:18:55,489 --> 00:18:58,970
on an archive and the Japanese and we're

00:18:57,830 --> 00:19:00,979
trying to integrate all this data

00:18:58,970 --> 00:19:04,399
together and so you've got a distributed

00:19:00,979 --> 00:19:06,320
network that has all these properties of

00:19:04,399 --> 00:19:08,779
willing to be distributed collaborative

00:19:06,320 --> 00:19:10,970
information-centric growing evolving

00:19:08,779 --> 00:19:14,059
heterogeneous so forth in the planetary

00:19:10,970 --> 00:19:17,389
data system when it was funded by by

00:19:14,059 --> 00:19:19,879
nasa in the 80s they they didn't provide

00:19:17,389 --> 00:19:21,049
really any architectural guidance they

00:19:19,879 --> 00:19:22,190
didn't provide them any kind of

00:19:21,049 --> 00:19:24,739
standards in terms of what they had to

00:19:22,190 --> 00:19:27,200
buy and so people just began to capture

00:19:24,739 --> 00:19:28,789
data and so and i'll talk about this a

00:19:27,200 --> 00:19:30,769
few minutes so our first challenge of

00:19:28,789 --> 00:19:32,479
ODT which was planetary sciences how do

00:19:30,769 --> 00:19:34,489
we bring together all this just for data

00:19:32,479 --> 00:19:37,879
that was was built with all this

00:19:34,489 --> 00:19:42,369
heterogeneous technology the N and

00:19:37,879 --> 00:19:44,629
provide it to the community for use

00:19:42,369 --> 00:19:45,950
another one is the earth observation

00:19:44,629 --> 00:19:48,200
which you can't see really well in here

00:19:45,950 --> 00:19:50,570
but again it's the same idea of a

00:19:48,200 --> 00:19:52,460
distributed infrastructure this is

00:19:50,570 --> 00:19:55,220
NASA's implementation I know other

00:19:52,460 --> 00:19:58,039
agencies also have their archives as

00:19:55,220 --> 00:20:01,010
well and so you've got a distributed

00:19:58,039 --> 00:20:03,140
network of data repositories that

00:20:01,010 --> 00:20:05,780
this again organized by scientific

00:20:03,140 --> 00:20:08,600
expertise or discipline and you want to

00:20:05,780 --> 00:20:10,190
provide access to that same thing up

00:20:08,600 --> 00:20:11,390
here in climate research and I know

00:20:10,190 --> 00:20:14,000
there's a talk they'll be talking about

00:20:11,390 --> 00:20:15,650
how sort of this community of

00:20:14,000 --> 00:20:16,970
observations in this community of

00:20:15,650 --> 00:20:19,010
climate models of company camp coming

00:20:16,970 --> 00:20:20,960
together and then we're doing the same

00:20:19,010 --> 00:20:23,360
thing in climate guard starting in

00:20:20,960 --> 00:20:24,530
cancer research so and i'll talk about

00:20:23,360 --> 00:20:27,220
that case study because it's very

00:20:24,530 --> 00:20:29,420
interesting when we first released ODT

00:20:27,220 --> 00:20:32,720
you know that we were looking at the

00:20:29,420 --> 00:20:35,300
idea of software you use going in and

00:20:32,720 --> 00:20:36,830
changing your code and then redeploying

00:20:35,300 --> 00:20:38,930
to me isn't really software we use

00:20:36,830 --> 00:20:40,850
software uses that we wanted to draw the

00:20:38,930 --> 00:20:42,530
line at the right level so that we could

00:20:40,850 --> 00:20:44,870
have the building blocks so we could go

00:20:42,530 --> 00:20:46,730
into planetary we could go into cancer

00:20:44,870 --> 00:20:48,650
research we could cut another deployment

00:20:46,730 --> 00:20:55,880
of ODT and actually just upgrade the

00:20:48,650 --> 00:20:59,930
infrastructures in these systems all

00:20:55,880 --> 00:21:01,550
right and that is the key point we had

00:20:59,930 --> 00:21:04,850
to identify what are the common

00:21:01,550 --> 00:21:08,060
architectural patterns in the systems

00:21:04,850 --> 00:21:09,650
that we can exploit we began to realize

00:21:08,060 --> 00:21:11,090
that there was common things that we

00:21:09,650 --> 00:21:14,360
were doing over and over and over an

00:21:11,090 --> 00:21:16,970
area system and you know while each

00:21:14,360 --> 00:21:18,530
community does have their own standards

00:21:16,970 --> 00:21:22,580
in terms of how to find their data and

00:21:18,530 --> 00:21:24,230
so forth and systems we felt that there

00:21:22,580 --> 00:21:26,480
was a reference architecture underneath

00:21:24,230 --> 00:21:29,420
this that we could begin to find the

00:21:26,480 --> 00:21:31,250
common building blocks and so are our

00:21:29,420 --> 00:21:32,840
approach and I think I heard of the

00:21:31,250 --> 00:21:35,120
business session this morning was that

00:21:32,840 --> 00:21:37,310
you know we we have a we had a lot of

00:21:35,120 --> 00:21:38,810
good solid smart developers that we're

00:21:37,310 --> 00:21:40,580
developing this we weren't looking to

00:21:38,810 --> 00:21:42,410
develop a turnkey capability we're

00:21:40,580 --> 00:21:44,000
looking to build libraries and building

00:21:42,410 --> 00:21:46,520
blocks in a framework that could

00:21:44,000 --> 00:21:47,720
actually be reused and that was one of

00:21:46,520 --> 00:21:49,130
the things that we're really looking for

00:21:47,720 --> 00:21:51,530
is how could we actually bring this to

00:21:49,130 --> 00:21:53,960
bear so that we quickly stand up a data

00:21:51,530 --> 00:21:56,420
system whether it's generation the data

00:21:53,960 --> 00:21:58,670
or archive the data or distribution of

00:21:56,420 --> 00:22:01,250
the data or support analysis the data

00:21:58,670 --> 00:22:05,600
that we could reuse and share across all

00:22:01,250 --> 00:22:08,930
of our our different environments so let

00:22:05,600 --> 00:22:10,700
me talk now about about ODT and you know

00:22:08,930 --> 00:22:14,310
kind of the reason why we are right here

00:22:10,700 --> 00:22:16,380
this morning so ODT is

00:22:14,310 --> 00:22:20,070
open source framework its focus was on

00:22:16,380 --> 00:22:24,450
is on data management it was funded

00:22:20,070 --> 00:22:27,600
originally in nineteen 898 and the the

00:22:24,450 --> 00:22:29,850
problem that we posed to NASA to fund it

00:22:27,600 --> 00:22:32,400
was look at you know you have funded

00:22:29,850 --> 00:22:34,800
construction of all these disparate

00:22:32,400 --> 00:22:37,050
databases and systems you haven't

00:22:34,800 --> 00:22:38,520
constructed haven't funded ways in which

00:22:37,050 --> 00:22:43,740
you could actually start to create

00:22:38,520 --> 00:22:46,320
interoperability at that time the the

00:22:43,740 --> 00:22:48,600
planetary data system which is what was

00:22:46,320 --> 00:22:51,870
one of our targets distributed all of

00:22:48,600 --> 00:22:53,910
their data on cd-rom and they were going

00:22:51,870 --> 00:22:56,580
to DVD on DVD ROM and thought well

00:22:53,910 --> 00:22:57,750
that's that's fine now some of those

00:22:56,580 --> 00:22:59,310
technologies were a little bit head

00:22:57,750 --> 00:23:00,270
saying wait a second yeah I can't say

00:22:59,310 --> 00:23:02,820
this is going to work in five years

00:23:00,270 --> 00:23:04,080
because the data volumes are going to

00:23:02,820 --> 00:23:05,220
increase so much so they thought well

00:23:04,080 --> 00:23:07,680
you know when we have a couple of

00:23:05,220 --> 00:23:10,680
terabytes of data no big deal well I was

00:23:07,680 --> 00:23:12,360
able to show that the the the cost of

00:23:10,680 --> 00:23:14,160
them doing Dave distribution the next

00:23:12,360 --> 00:23:15,480
five years was going to far exceed our

00:23:14,160 --> 00:23:17,400
cost of actually building something like

00:23:15,480 --> 00:23:21,750
ODT to actually link it together and

00:23:17,400 --> 00:23:25,700
that actually flew with NASA we also had

00:23:21,750 --> 00:23:27,840
another case of in space interferometry

00:23:25,700 --> 00:23:30,420
investor physics and we've gotten back

00:23:27,840 --> 00:23:33,270
and Astrid Figgis look again recently to

00:23:30,420 --> 00:23:34,500
help them sort of build a capability so

00:23:33,270 --> 00:23:36,090
as as they were making nightly

00:23:34,500 --> 00:23:37,530
observations their data could be

00:23:36,090 --> 00:23:38,910
captured we could bring the components

00:23:37,530 --> 00:23:42,060
in we could distribute that to the data

00:23:38,910 --> 00:23:43,590
to the community so our first goal was

00:23:42,060 --> 00:23:45,630
starting to build some components for

00:23:43,590 --> 00:23:49,170
ODT and i'll talk about the the

00:23:45,630 --> 00:23:51,180
reference architecture there we made

00:23:49,170 --> 00:23:52,770
enough progress in understanding some of

00:23:51,180 --> 00:23:54,090
these these problems and particularly

00:23:52,770 --> 00:23:56,010
with the planetary data system

00:23:54,090 --> 00:23:57,600
challenges of trying to figure out how

00:23:56,010 --> 00:24:01,140
to get access to these distribute

00:23:57,600 --> 00:24:02,640
repositories that we began working with

00:24:01,140 --> 00:24:04,920
the National Institute of Health in two

00:24:02,640 --> 00:24:07,620
thousand and about two thousand one did

00:24:04,920 --> 00:24:10,620
some prototypes for them and we help

00:24:07,620 --> 00:24:12,600
them begin to look at an area called

00:24:10,620 --> 00:24:14,340
cancer biomarker research which I'll

00:24:12,600 --> 00:24:18,210
talk about and then I think there's a

00:24:14,340 --> 00:24:20,430
talk on it today to tomorrow other areas

00:24:18,210 --> 00:24:22,770
earth science I'll talk about and then a

00:24:20,430 --> 00:24:24,840
medicine as well and I showed you that

00:24:22,770 --> 00:24:26,490
initial picture in the beginning of us

00:24:24,840 --> 00:24:28,050
saying you know what are the differences

00:24:26,490 --> 00:24:31,860
between us being able to observe

00:24:28,050 --> 00:24:34,590
serve something on Mars and us being

00:24:31,860 --> 00:24:37,170
able to observe an infant that's in ICU

00:24:34,590 --> 00:24:39,330
and being able to actually extract and

00:24:37,170 --> 00:24:41,340
make inferences because what my good

00:24:39,330 --> 00:24:44,340
friend at Children's Hospital tells me

00:24:41,340 --> 00:24:46,530
is that our is that that something like

00:24:44,340 --> 00:24:48,000
a baby an infant is an experiment most

00:24:46,530 --> 00:24:49,110
doctors don't think that way but he

00:24:48,000 --> 00:24:50,910
thinks that way and says you know it's

00:24:49,110 --> 00:24:53,040
really a hypothesis that we have in

00:24:50,910 --> 00:24:55,020
terms of a diagnosis and so as we're

00:24:53,040 --> 00:24:57,180
capturing we're measuring we're trying

00:24:55,020 --> 00:24:59,190
to understand its data that that's

00:24:57,180 --> 00:25:02,550
important that leads to us better

00:24:59,190 --> 00:25:04,050
understanding disease and so our whole

00:25:02,550 --> 00:25:06,150
focus is how do we actually capture

00:25:04,050 --> 00:25:08,940
those observations and make that

00:25:06,150 --> 00:25:12,060
available in 2008 we got more involved

00:25:08,940 --> 00:25:14,520
in climate research and we've gotten now

00:25:12,060 --> 00:25:17,490
again more involved thanks to to Chris

00:25:14,520 --> 00:25:19,590
mamon over here in 2010 in the area of

00:25:17,490 --> 00:25:21,300
radio astronomy and understanding some

00:25:19,590 --> 00:25:23,970
of their just daunting big data

00:25:21,300 --> 00:25:25,620
challenges so that the focus for ODT has

00:25:23,970 --> 00:25:27,480
been you know how do we support the

00:25:25,620 --> 00:25:28,980
generation of data and we'll talk about

00:25:27,480 --> 00:25:32,100
that so those are you know we build

00:25:28,980 --> 00:25:33,600
these complex pipelines that have many

00:25:32,100 --> 00:25:35,940
many states that have to be fulfilled as

00:25:33,600 --> 00:25:37,890
we are generating data in rain

00:25:35,940 --> 00:25:40,700
algorithms so that's that's a workflow

00:25:37,890 --> 00:25:42,930
that's understanding and allocating a

00:25:40,700 --> 00:25:46,470
jobs to different computational

00:25:42,930 --> 00:25:49,380
infrastructures and then the ability to

00:25:46,470 --> 00:25:51,420
generate capture that data and then

00:25:49,380 --> 00:25:54,540
transform and distribute to the

00:25:51,420 --> 00:25:57,990
community so we made enough progress

00:25:54,540 --> 00:26:01,620
that in 2003 nasa selected ODT for

00:25:57,990 --> 00:26:07,770
runner-up for NASA soph of the year and

00:26:01,620 --> 00:26:09,720
in 2010 we got Caltech which was which

00:26:07,770 --> 00:26:12,960
really own the IP on it to release the

00:26:09,720 --> 00:26:16,020
IP and move this into the the Apache

00:26:12,960 --> 00:26:18,450
Incubator program and of course became a

00:26:16,020 --> 00:26:20,250
top-level project 2011 so to our

00:26:18,450 --> 00:26:23,690
knowledge because we've done a lot of

00:26:20,250 --> 00:26:27,360
education at NASA about the the value of

00:26:23,690 --> 00:26:29,160
open source this is the first project

00:26:27,360 --> 00:26:33,330
that we know of that that's come out of

00:26:29,160 --> 00:26:36,240
the NASA lab so what was the vision for

00:26:33,330 --> 00:26:38,220
ODT the vision at the time and it really

00:26:36,240 --> 00:26:41,700
hasn't changed but this is the sort of

00:26:38,220 --> 00:26:43,710
the 1998-99 vision was we want to

00:26:41,700 --> 00:26:45,269
a framework for sort of bringing

00:26:43,710 --> 00:26:47,700
processing and bringing together all

00:26:45,269 --> 00:26:49,649
this data the idea was that you know the

00:26:47,700 --> 00:26:52,080
data was distributed it was

00:26:49,649 --> 00:26:54,000
heterogeneous it was we need to be able

00:26:52,080 --> 00:26:56,010
to serve to our community we want to be

00:26:54,000 --> 00:26:57,179
able to analyze it so how do we be able

00:26:56,010 --> 00:26:59,370
to actually start to build the

00:26:57,179 --> 00:27:01,289
components that would support a

00:26:59,370 --> 00:27:04,860
construction of a distributed

00:27:01,289 --> 00:27:06,330
architecture and so we focused on what

00:27:04,860 --> 00:27:08,010
are the discrete components that we

00:27:06,330 --> 00:27:11,510
actually needed for the building blocks

00:27:08,010 --> 00:27:15,029
to construct such systems mm-hmm and

00:27:11,510 --> 00:27:16,529
like any good architects we said what

00:27:15,029 --> 00:27:19,080
are the principles that we'd like to

00:27:16,529 --> 00:27:20,639
adhere to and we wrote a paper on this

00:27:19,080 --> 00:27:22,139
and this is what actually led to us

00:27:20,639 --> 00:27:24,210
getting bug with the NIH because we

00:27:22,139 --> 00:27:28,260
presented us at a national academy of

00:27:24,210 --> 00:27:30,480
science meeting and we listed several

00:27:28,260 --> 00:27:32,220
them the first was that we want to

00:27:30,480 --> 00:27:33,990
separate the technology and the

00:27:32,220 --> 00:27:36,570
information architecture this is

00:27:33,990 --> 00:27:38,789
probably if I would say of anything that

00:27:36,570 --> 00:27:41,850
that ODT did I think this is probably

00:27:38,789 --> 00:27:44,130
one of the one of the the the best

00:27:41,850 --> 00:27:45,899
things that we did and the reason is

00:27:44,130 --> 00:27:49,080
that we wanted to understand how we

00:27:45,899 --> 00:27:52,470
could apply different problems and adapt

00:27:49,080 --> 00:27:54,600
the description of our data over time we

00:27:52,470 --> 00:27:55,679
didn't want to be able to tightly couple

00:27:54,600 --> 00:27:58,919
the definition of our data into our

00:27:55,679 --> 00:28:01,260
software and so the idea is that that

00:27:58,919 --> 00:28:02,940
planetary science has a model a data

00:28:01,260 --> 00:28:05,039
model for how describes its data or

00:28:02,940 --> 00:28:06,649
science has a different data model for

00:28:05,039 --> 00:28:09,929
how it describes its data but

00:28:06,649 --> 00:28:11,250
functionally they do the same thing I do

00:28:09,929 --> 00:28:12,360
very very similar things I have to be

00:28:11,250 --> 00:28:15,450
careful again trollese they do the same

00:28:12,360 --> 00:28:18,630
thing but but they they do very very

00:28:15,450 --> 00:28:21,570
similar things and so the idea that we

00:28:18,630 --> 00:28:23,309
can take evolve our ontology or model or

00:28:21,570 --> 00:28:25,830
information architecture independent of

00:28:23,309 --> 00:28:27,779
our software was really critical for us

00:28:25,830 --> 00:28:30,029
it's something that I think his service

00:28:27,779 --> 00:28:33,000
really well second thing that served as

00:28:30,029 --> 00:28:34,710
well and that was you know we were

00:28:33,000 --> 00:28:37,559
chasing and I have been involved for a

00:28:34,710 --> 00:28:39,480
while in the distributed computing world

00:28:37,559 --> 00:28:42,029
we were chasing what were the right

00:28:39,480 --> 00:28:46,470
frameworks for distributed computing I

00:28:42,029 --> 00:28:50,970
had been involved in things like korba

00:28:46,470 --> 00:28:53,450
and you know Java which you know j2ee

00:28:50,970 --> 00:28:55,049
and all these things and you know the

00:28:53,450 --> 00:28:57,450
impacting for that district

00:28:55,049 --> 00:28:59,850
dce I think was the was one we'd you can

00:28:57,450 --> 00:29:01,860
use and so the idea was that that I

00:28:59,850 --> 00:29:04,739
didn't want to tightly couple our

00:29:01,860 --> 00:29:05,879
software component component that we

00:29:04,739 --> 00:29:08,309
want to distribute into the message

00:29:05,879 --> 00:29:12,059
layer so we abstracted that out in a

00:29:08,309 --> 00:29:13,549
served as well because we we had used

00:29:12,059 --> 00:29:18,539
what we thought was an open source

00:29:13,549 --> 00:29:23,999
Corbett or probably in 1999 2000 2001

00:29:18,539 --> 00:29:25,529
and it turned out that iona purchased in

00:29:23,999 --> 00:29:26,850
bought the company that was putting out

00:29:25,529 --> 00:29:28,559
the open source software that we could

00:29:26,850 --> 00:29:30,119
use and they did change the licensing

00:29:28,559 --> 00:29:32,159
agreements so they called me on the

00:29:30,119 --> 00:29:33,600
phone they said you know we see that you

00:29:32,159 --> 00:29:35,580
downloaded it things like that you know

00:29:33,600 --> 00:29:37,259
and we want to give you a quote they

00:29:35,580 --> 00:29:39,330
gave me a quote for the software they

00:29:37,259 --> 00:29:40,830
want thirty thousand dollars and I said

00:29:39,330 --> 00:29:42,980
well gee were kind of a research project

00:29:40,830 --> 00:29:47,549
three thousand dollars kind of lot to us

00:29:42,980 --> 00:29:49,230
and so we have we had some smart

00:29:47,549 --> 00:29:51,570
developers and we said gee you know we

00:29:49,230 --> 00:29:54,809
had separated out the messaging

00:29:51,570 --> 00:29:59,489
implementation of ODT why don't we just

00:29:54,809 --> 00:30:01,309
swap out korba for Java RMI and we'll do

00:29:59,489 --> 00:30:04,049
that and so we took the messaging

00:30:01,309 --> 00:30:07,049
classes that we actually had an ODT we

00:30:04,049 --> 00:30:09,720
built a new implementation of those in C

00:30:07,049 --> 00:30:12,330
on top of our mi we did over a weekend

00:30:09,720 --> 00:30:15,539
and we swapped out and redeployed to our

00:30:12,330 --> 00:30:17,070
projects and we said goodbye to

00:30:15,539 --> 00:30:20,009
particular that messaging infrastructure

00:30:17,070 --> 00:30:21,690
so that was one things that that we that

00:30:20,009 --> 00:30:25,429
was really I think an important about

00:30:21,690 --> 00:30:28,470
the reference implementation of ODT

00:30:25,429 --> 00:30:30,509
other things as we worked with projects

00:30:28,470 --> 00:30:31,919
one of the in fact we went through

00:30:30,509 --> 00:30:33,749
several reviews where people said gee

00:30:31,919 --> 00:30:35,100
you know you guys are trying to take

00:30:33,749 --> 00:30:37,259
planetary science which is a bunch of

00:30:35,100 --> 00:30:39,629
disjoint repositories and bring it into

00:30:37,259 --> 00:30:41,159
an integrated system you know we don't

00:30:39,629 --> 00:30:44,519
have the funding to go off in and

00:30:41,159 --> 00:30:45,840
rebuild every single center we you know

00:30:44,519 --> 00:30:47,399
we already have things that work st.

00:30:45,840 --> 00:30:50,100
happen to the NIH we already collect our

00:30:47,399 --> 00:30:51,720
data we just want to share it so part of

00:30:50,100 --> 00:30:54,450
what we want to do is be able to

00:30:51,720 --> 00:30:56,159
encapsulate hide the differences be able

00:30:54,450 --> 00:30:59,159
to wrap those and then integrate them

00:30:56,159 --> 00:31:01,499
with a way to link the data together and

00:30:59,159 --> 00:31:05,100
that became a really important selling

00:31:01,499 --> 00:31:06,899
point for ODT now there is that we we

00:31:05,100 --> 00:31:08,100
also felt that things like data system

00:31:06,899 --> 00:31:12,120
location dependences

00:31:08,100 --> 00:31:14,160
Martin are you know our users even even

00:31:12,120 --> 00:31:16,410
those are developing a sore application

00:31:14,160 --> 00:31:18,299
or client level software really don't

00:31:16,410 --> 00:31:19,770
need to know where where the data exists

00:31:18,299 --> 00:31:23,669
they just want to be able to access that

00:31:19,770 --> 00:31:25,890
data retrieve it and and be able to use

00:31:23,669 --> 00:31:27,809
it and so the idea was that a we want to

00:31:25,890 --> 00:31:29,250
be able to have a messaging layer that

00:31:27,809 --> 00:31:31,679
would connect these together I'm going

00:31:29,250 --> 00:31:32,520
to be able to wrap the systems and be we

00:31:31,679 --> 00:31:33,900
didn't care where these things were

00:31:32,520 --> 00:31:36,720
really receiving care of leasing is

00:31:33,900 --> 00:31:40,200
really running so that became a real

00:31:36,720 --> 00:31:42,210
important principle for us and and as we

00:31:40,200 --> 00:31:43,970
went on we had more and more principles

00:31:42,210 --> 00:31:47,610
that really helped us be able to

00:31:43,970 --> 00:31:50,460
describe our systems scale what we were

00:31:47,610 --> 00:31:51,929
trying to put out and deploy and real

00:31:50,460 --> 00:31:54,230
and really be able to support this

00:31:51,929 --> 00:31:59,270
separation if you will of the the

00:31:54,230 --> 00:32:02,429
technology layers itself and the and the

00:31:59,270 --> 00:32:05,100
information architecture the last and

00:32:02,429 --> 00:32:07,860
this kind of links us now to here we are

00:32:05,100 --> 00:32:09,960
in 2013 was that we really wanted to

00:32:07,860 --> 00:32:11,669
leverage open source we really in our

00:32:09,960 --> 00:32:15,740
intention from the very beginning was to

00:32:11,669 --> 00:32:15,740
be able to distribute ODT as open source

00:32:16,340 --> 00:32:26,370
so let me talk a little bit about the

00:32:22,350 --> 00:32:28,980
implementation of ODT so back in when we

00:32:26,370 --> 00:32:30,419
started T it was focused on building a

00:32:28,980 --> 00:32:33,840
set of server components and I'll talk

00:32:30,419 --> 00:32:35,370
about those and they were built as Java

00:32:33,840 --> 00:32:36,570
components so we wanted to be able to

00:32:35,370 --> 00:32:39,390
you know support the Java Virtual

00:32:36,570 --> 00:32:41,190
Machine be able to deploy two different

00:32:39,390 --> 00:32:46,140
you know operating system environments

00:32:41,190 --> 00:32:47,730
and be able to plug these together some

00:32:46,140 --> 00:32:48,870
of our early deployments it's it you

00:32:47,730 --> 00:32:51,090
know as you begin to look at distribute

00:32:48,870 --> 00:32:53,370
systems I'm always amazed at how head of

00:32:51,090 --> 00:32:55,140
genius they are you know within the

00:32:53,370 --> 00:32:58,320
planetary community we've got you know

00:32:55,140 --> 00:32:59,520
windows we have different now kind of

00:32:58,320 --> 00:33:04,049
going away but we had two versions of

00:32:59,520 --> 00:33:06,299
Solaris linux mac OS x and so you have

00:33:04,049 --> 00:33:08,980
this environment where you've got highly

00:33:06,299 --> 00:33:10,909
highly heterogeneous sets of

00:33:08,980 --> 00:33:13,730
implementations and so we need to be

00:33:10,909 --> 00:33:17,480
able to run on those and so Java seems

00:33:13,730 --> 00:33:19,039
like a really good deployment for us we

00:33:17,480 --> 00:33:21,620
want to provide messaging as a plug and

00:33:19,039 --> 00:33:24,049
as I mentioned and so you know we've

00:33:21,620 --> 00:33:26,000
gone through the whole sort of different

00:33:24,049 --> 00:33:30,559
different generations of distributed

00:33:26,000 --> 00:33:33,200
middleware from korba to Java RMI now

00:33:30,559 --> 00:33:34,909
everything is effectively rest based in

00:33:33,200 --> 00:33:36,650
those upgrades I think we just see

00:33:34,909 --> 00:33:40,159
continuing to evolve to stay current

00:33:36,650 --> 00:33:43,070
with the messaging technology so part of

00:33:40,159 --> 00:33:44,929
the OTT principle is you know if things

00:33:43,070 --> 00:33:46,460
already exist we're just going to rescan

00:33:44,929 --> 00:33:48,289
sim top and use them and I'll talk about

00:33:46,460 --> 00:33:51,530
that you know where we plug in and use

00:33:48,289 --> 00:33:52,970
who do if we plug in and use solar and

00:33:51,530 --> 00:33:55,940
you'll hear a lot about that this I

00:33:52,970 --> 00:33:57,650
think the next two days and then we want

00:33:55,940 --> 00:34:01,250
to provide client API is for being able

00:33:57,650 --> 00:34:03,289
to access the services and so over time

00:34:01,250 --> 00:34:05,960
those have really really grown and you

00:34:03,289 --> 00:34:07,250
may see things like Java C++ and then

00:34:05,960 --> 00:34:09,770
all the way over here things like IDL

00:34:07,250 --> 00:34:11,960
because you know for us that's a science

00:34:09,770 --> 00:34:12,919
tool kit it's our scientists use it and

00:34:11,960 --> 00:34:16,159
they want they might want to be able get

00:34:12,919 --> 00:34:18,109
to their science data and so ideal

00:34:16,159 --> 00:34:21,050
becomes a really nice platform for them

00:34:18,109 --> 00:34:25,339
to actually program in I purposely left

00:34:21,050 --> 00:34:27,770
out for travel by the way but we still

00:34:25,339 --> 00:34:29,149
have fortran developers at JPL so and

00:34:27,770 --> 00:34:32,480
and in the science community in general

00:34:29,149 --> 00:34:35,750
so we went to support installation of

00:34:32,480 --> 00:34:37,820
variety of platforms one of my my

00:34:35,750 --> 00:34:40,520
initial thinking on both our deployments

00:34:37,820 --> 00:34:42,220
of planetary and cancer research was I

00:34:40,520 --> 00:34:45,349
sort of expected we put this out there

00:34:42,220 --> 00:34:47,720
and you know we would building services

00:34:45,349 --> 00:34:49,339
and then they would go run with them the

00:34:47,720 --> 00:34:51,169
biggest challenge I think we ran into is

00:34:49,339 --> 00:34:53,050
that a lot of a lot of the efforts

00:34:51,169 --> 00:34:55,099
required probably more higher-end

00:34:53,050 --> 00:34:56,540
software development expertise than a

00:34:55,099 --> 00:34:58,130
lot of the center's work with actually

00:34:56,540 --> 00:34:59,990
had and so that was one of the things

00:34:58,130 --> 00:35:01,580
that we've had to overcome and so

00:34:59,990 --> 00:35:03,680
building things like better installers

00:35:01,580 --> 00:35:07,220
and so forth became really critical for

00:35:03,680 --> 00:35:09,050
us and then as we lift it worked on our

00:35:07,220 --> 00:35:11,359
sort of the data architecture side of

00:35:09,050 --> 00:35:13,070
things in 0 UT we adopted a lot of

00:35:11,359 --> 00:35:15,230
various standards in terms of how we

00:35:13,070 --> 00:35:17,510
describe metadata in terms of how we

00:35:15,230 --> 00:35:19,099
what metadata we use in terms of how we

00:35:17,510 --> 00:35:21,070
build data dictionaries and so forth

00:35:19,099 --> 00:35:25,150
which which has helped keep us in

00:35:21,070 --> 00:35:26,350
think with that community so what are

00:35:25,150 --> 00:35:28,450
the things that we think about in terms

00:35:26,350 --> 00:35:29,830
of our data life cycle and you probably

00:35:28,450 --> 00:35:31,510
think about these things in terms of

00:35:29,830 --> 00:35:34,920
data life cycles for many different

00:35:31,510 --> 00:35:38,050
areas other than science but what we see

00:35:34,920 --> 00:35:40,810
very clearly is for us ingestion of data

00:35:38,050 --> 00:35:43,780
so as data is coming coming in in from

00:35:40,810 --> 00:35:45,580
say a ground station for us we're going

00:35:43,780 --> 00:35:47,820
through the steps of initially

00:35:45,580 --> 00:35:50,230
transforming and validating that data

00:35:47,820 --> 00:35:51,940
and this is an important step hey you

00:35:50,230 --> 00:35:53,350
know does the metadata is met at a

00:35:51,940 --> 00:35:55,810
consistent doesn't meet our standards if

00:35:53,350 --> 00:35:57,250
we get data in with poor metade if

00:35:55,810 --> 00:35:59,470
poorly formed metadata things like that

00:35:57,250 --> 00:36:01,420
and it goes all the way down stream is

00:35:59,470 --> 00:36:02,590
going to make search difficult it's

00:36:01,420 --> 00:36:03,760
going to make usability that data

00:36:02,590 --> 00:36:06,370
difficult because people may not

00:36:03,760 --> 00:36:08,440
understand it if we do content

00:36:06,370 --> 00:36:10,870
validation which we do do we find

00:36:08,440 --> 00:36:13,090
problems and so a lot of what we do in

00:36:10,870 --> 00:36:16,060
the ingestion data is running a set of

00:36:13,090 --> 00:36:19,210
rules so here's a workflow for actually

00:36:16,060 --> 00:36:22,690
being able to the data as part of that

00:36:19,210 --> 00:36:25,360
ingestion process and then you know we

00:36:22,690 --> 00:36:29,560
begin to sort of capture that initial

00:36:25,360 --> 00:36:31,780
set of data and we what we do to scale

00:36:29,560 --> 00:36:32,830
is we separate sort of the catalog so

00:36:31,780 --> 00:36:34,540
this is why our metadata becomes so

00:36:32,830 --> 00:36:38,200
important from the physical storage of

00:36:34,540 --> 00:36:39,880
the data and over time we began to ask

00:36:38,200 --> 00:36:42,370
ourselves is do we really even care

00:36:39,880 --> 00:36:44,230
where that physical stories of the data

00:36:42,370 --> 00:36:45,520
is in regards to the catalog there's no

00:36:44,230 --> 00:36:47,230
reason why we have to centralize those

00:36:45,520 --> 00:36:49,330
we can catalog one place and we can

00:36:47,230 --> 00:36:51,490
describe data which is distributed in

00:36:49,330 --> 00:36:54,130
other places so now we've got data on

00:36:51,490 --> 00:36:56,800
the cloud now we've got data at others

00:36:54,130 --> 00:36:58,750
other centers but we can catalog what

00:36:56,800 --> 00:37:00,840
exists and be able to provide

00:36:58,750 --> 00:37:04,240
descriptions of how to get to that data

00:37:00,840 --> 00:37:06,520
through quantum protocols data

00:37:04,240 --> 00:37:09,220
processing so part of once we've

00:37:06,520 --> 00:37:12,130
ingested in catalog our data card what

00:37:09,220 --> 00:37:14,170
we begin to look look at is you know

00:37:12,130 --> 00:37:15,670
what what's the data that you know how

00:37:14,170 --> 00:37:16,960
do we actually process that data how do

00:37:15,670 --> 00:37:19,930
we actually fire off these workflows and

00:37:16,960 --> 00:37:22,870
so you know we can we can end up writing

00:37:19,930 --> 00:37:26,050
a you know a hundred tasks that will

00:37:22,870 --> 00:37:27,910
fire off as jobs as part of a workflow

00:37:26,050 --> 00:37:29,590
that are all related for how we actually

00:37:27,910 --> 00:37:31,470
handle the data they're coming in these

00:37:29,590 --> 00:37:34,410
things have dependencies these things

00:37:31,470 --> 00:37:36,569
need to be run in certain orders

00:37:34,410 --> 00:37:39,480
these things might might consume

00:37:36,569 --> 00:37:40,530
computational resources so we then need

00:37:39,480 --> 00:37:46,049
to look at how where do we run

00:37:40,530 --> 00:37:48,539
executable art and souls of what ODT is

00:37:46,049 --> 00:37:50,010
now doing and then they'll it's the

00:37:48,539 --> 00:37:52,980
long-term management of the data itself

00:37:50,010 --> 00:37:54,780
as I mission is often distributed the

00:37:52,980 --> 00:37:57,000
other side of the equation is once we've

00:37:54,780 --> 00:37:58,380
got data that's processed captured you

00:37:57,000 --> 00:38:00,839
might be able to distribute that it's

00:37:58,380 --> 00:38:02,220
really the discovery of the data and for

00:38:00,839 --> 00:38:04,319
us there might be multiple posit or ease

00:38:02,220 --> 00:38:06,660
it's the access to the data in the

00:38:04,319 --> 00:38:09,000
transformation and so our goal when we

00:38:06,660 --> 00:38:11,220
set up to build ODT was was trying to

00:38:09,000 --> 00:38:13,200
look at that end and ecosystem if you

00:38:11,220 --> 00:38:16,619
will of capabilities that support this

00:38:13,200 --> 00:38:20,789
life cycle so this shows kind of our

00:38:16,619 --> 00:38:22,799
philosophy oet as well so we exist right

00:38:20,789 --> 00:38:24,059
in the middle so for us a mission or

00:38:22,799 --> 00:38:25,619
project may come along science

00:38:24,059 --> 00:38:27,539
experiment that's going to build a bunch

00:38:25,619 --> 00:38:29,640
of things and you know they end up using

00:38:27,539 --> 00:38:32,039
ODT well our goal is to end up using

00:38:29,640 --> 00:38:33,930
things that aren Ethan as well and build

00:38:32,039 --> 00:38:36,030
out the stack and every one of these are

00:38:33,930 --> 00:38:37,650
hopefully as we identify good

00:38:36,030 --> 00:38:41,730
capabilities up here in the missions

00:38:37,650 --> 00:38:43,859
they will gravitate toward more more

00:38:41,730 --> 00:38:45,180
part of the ODT suite of things and

00:38:43,859 --> 00:38:47,579
we've done that where we've seen

00:38:45,180 --> 00:38:50,160
missions that have added value but the

00:38:47,579 --> 00:38:54,059
idea is that this is a continuing

00:38:50,160 --> 00:38:56,880
evolving capability and as I mentioned

00:38:54,059 --> 00:38:58,490
you know we've got a lot of common

00:38:56,880 --> 00:39:01,160
technologies that we're currently using

00:38:58,490 --> 00:39:04,410
you know certainly using apache tomcat

00:39:01,160 --> 00:39:06,480
and the web services but we're using

00:39:04,410 --> 00:39:09,539
teka for data extraction and we're using

00:39:06,480 --> 00:39:11,220
Hadoop for a lot of computation and so

00:39:09,539 --> 00:39:14,640
these we have become core parts of what

00:39:11,220 --> 00:39:17,010
we're doing so these are the ott

00:39:14,640 --> 00:39:18,359
components that are that we have if you

00:39:17,010 --> 00:39:20,279
hear a lot of discussion you can hear

00:39:18,359 --> 00:39:22,619
about now more more is now our catalog

00:39:20,279 --> 00:39:24,539
of archive services and this is where we

00:39:22,619 --> 00:39:26,579
are running our data management doing

00:39:24,539 --> 00:39:28,619
our workflow i'm able to manage files

00:39:26,579 --> 00:39:31,559
being able to be able to build

00:39:28,619 --> 00:39:34,380
catalogues and so it provides a quite a

00:39:31,559 --> 00:39:36,420
bit of services for how to support that

00:39:34,380 --> 00:39:39,089
whole framework of how we build a system

00:39:36,420 --> 00:39:41,369
in addition we've got other services

00:39:39,089 --> 00:39:43,829
which provide access to existing

00:39:41,369 --> 00:39:45,200
repositories we call grid services we're

00:39:43,829 --> 00:39:47,020
being able to actually be

00:39:45,200 --> 00:39:49,670
to understand what resources exist

00:39:47,020 --> 00:39:52,280
access the data transform that data and

00:39:49,670 --> 00:39:53,780
be able to link it in separating for

00:39:52,280 --> 00:39:56,420
that as I mentioned before is our core

00:39:53,780 --> 00:39:59,330
data models which are things that we use

00:39:56,420 --> 00:40:00,980
to describe the resources and then the

00:39:59,330 --> 00:40:04,850
actual domain science projects as well

00:40:00,980 --> 00:40:07,670
it's also in earth or planetary science

00:40:04,850 --> 00:40:09,410
many of our science or cancer research

00:40:07,670 --> 00:40:11,180
many of our disciplines I already have

00:40:09,410 --> 00:40:15,500
existing models and so the idea was to

00:40:11,180 --> 00:40:18,680
layer those on top of ott this is just

00:40:15,500 --> 00:40:20,750
showing our Kellogg archive service data

00:40:18,680 --> 00:40:22,820
model is very simple the idea is you got

00:40:20,750 --> 00:40:25,640
a product and that product is then

00:40:22,820 --> 00:40:27,590
defined by a product type and it's

00:40:25,640 --> 00:40:29,150
really a keyword value kind of store

00:40:27,590 --> 00:40:32,630
that we're using to construct and

00:40:29,150 --> 00:40:34,460
describe or science data this is just

00:40:32,630 --> 00:40:36,140
showing now the idea of turning

00:40:34,460 --> 00:40:39,950
something like our catalog archive

00:40:36,140 --> 00:40:41,450
service in ODT into a pipeline and so

00:40:39,950 --> 00:40:43,220
what you begin to see over here on the

00:40:41,450 --> 00:40:44,780
far left is he going to see the

00:40:43,220 --> 00:40:48,260
spacecraft files other kinds of files

00:40:44,780 --> 00:40:49,760
chumpy files coming in that's coming

00:40:48,260 --> 00:40:52,100
into our information management

00:40:49,760 --> 00:40:54,020
framework that's sitting on top of OTT

00:40:52,100 --> 00:40:56,960
that's doing all the validation as I

00:40:54,020 --> 00:40:58,610
mentioned it's doing the processing it's

00:40:56,960 --> 00:41:00,920
doing the in fact those are the

00:40:58,610 --> 00:41:02,570
processors and it's doing that then the

00:41:00,920 --> 00:41:04,730
data distribution through some sort user

00:41:02,570 --> 00:41:08,930
interface and so the so when we've gone

00:41:04,730 --> 00:41:11,060
through now we can stand up as a skinny

00:41:08,930 --> 00:41:13,040
data system in a couple weeks which it

00:41:11,060 --> 00:41:16,970
might have taken us a year or more

00:41:13,040 --> 00:41:18,590
before to do that this is probably a

00:41:16,970 --> 00:41:20,000
little hard to read in the room but this

00:41:18,590 --> 00:41:21,380
is just showing an extension of coming

00:41:20,000 --> 00:41:23,270
key things and so you've got product

00:41:21,380 --> 00:41:24,260
delivery going on services there that

00:41:23,270 --> 00:41:26,240
are doing with that you've got file

00:41:24,260 --> 00:41:29,120
management this is a big part of what we

00:41:26,240 --> 00:41:30,740
do in ODT which is a lot of our data

00:41:29,120 --> 00:41:31,700
that comes in our file based data but

00:41:30,740 --> 00:41:34,910
we've got to be able to describe that

00:41:31,700 --> 00:41:37,100
extract data from that and and that's

00:41:34,910 --> 00:41:39,440
linked all directly to our workflow

00:41:37,100 --> 00:41:41,030
management management of the resources

00:41:39,440 --> 00:41:43,970
that we have so if we're going to

00:41:41,030 --> 00:41:45,620
allocate say external plus ters things

00:41:43,970 --> 00:41:47,020
like that we can go off and run those

00:41:45,620 --> 00:41:50,870
and we can run what we call a

00:41:47,020 --> 00:41:54,980
programmable algorithm that would run on

00:41:50,870 --> 00:41:56,600
one of those clusters this is just

00:41:54,980 --> 00:41:58,130
showing the quarry models and 0 UT so

00:41:56,600 --> 00:41:59,069
we've got some stock quarry models in

00:41:58,130 --> 00:42:02,430
addition to the dome

00:41:59,069 --> 00:42:04,380
a model which we use to describe in the

00:42:02,430 --> 00:42:06,809
the data itself that we actually have

00:42:04,380 --> 00:42:08,880
four as resources and so we use a number

00:42:06,809 --> 00:42:11,130
of standards most prominently something

00:42:08,880 --> 00:42:12,269
called I so one 1179 which is a standard

00:42:11,130 --> 00:42:14,400
for how you actually describe

00:42:12,269 --> 00:42:16,440
dictionaries of data and we can use that

00:42:14,400 --> 00:42:18,660
for actually describing the elements in

00:42:16,440 --> 00:42:22,319
linking to that the data that actually

00:42:18,660 --> 00:42:24,269
exists in a distributed system this is

00:42:22,319 --> 00:42:26,249
showing now the other pattern in

00:42:24,269 --> 00:42:28,130
addition to archive in the data this is

00:42:26,249 --> 00:42:30,390
access now to data has been archived and

00:42:28,130 --> 00:42:32,249
so this is what we ended up using in

00:42:30,390 --> 00:42:33,859
planetary science to actually link allow

00:42:32,249 --> 00:42:36,749
repositories together we put out

00:42:33,859 --> 00:42:38,969
products services at all the various

00:42:36,749 --> 00:42:41,279
repositories and profile services which

00:42:38,969 --> 00:42:43,499
less a discover what existed and be be

00:42:41,279 --> 00:42:45,809
able to retrieve that those files and

00:42:43,499 --> 00:42:48,359
then we began right services that said

00:42:45,809 --> 00:42:50,699
hey I'd like to get my file not say in a

00:42:48,359 --> 00:42:54,509
PDS image format but I want to get back

00:42:50,699 --> 00:42:58,099
in a jpeg or gif format and so a lot of

00:42:54,509 --> 00:43:00,539
transformations begin to take shape so

00:42:58,099 --> 00:43:03,479
now moving on to talk about some of our

00:43:00,539 --> 00:43:05,369
applications as I mentioned the NASA

00:43:03,479 --> 00:43:09,089
planetary data system was the first one

00:43:05,369 --> 00:43:11,729
we worked with an ODT and so PDS is got

00:43:09,089 --> 00:43:14,759
eight nodes distributed across the US as

00:43:11,729 --> 00:43:17,670
well as international connections it's

00:43:14,759 --> 00:43:19,859
500 terabytes of data and up until about

00:43:17,670 --> 00:43:21,119
two thousand and one when we got a

00:43:19,859 --> 00:43:22,559
mission that was going to double size

00:43:21,119 --> 00:43:26,329
the archive as I mentioned they were

00:43:22,559 --> 00:43:29,789
distributed on optical media the the

00:43:26,329 --> 00:43:31,109
what we did in tooth in 2001 is went to

00:43:29,789 --> 00:43:32,579
go to them and said look at we've been

00:43:31,109 --> 00:43:34,170
building this framework why don't we

00:43:32,579 --> 00:43:35,670
begin to actually deploy this

00:43:34,170 --> 00:43:37,949
operationally and we were able to

00:43:35,670 --> 00:43:39,989
actually do that 2002 for the art Mars

00:43:37,949 --> 00:43:42,630
Odyssey mission and changed the paradigm

00:43:39,989 --> 00:43:46,680
because science community up to that

00:43:42,630 --> 00:43:51,089
point had no experience and actually

00:43:46,680 --> 00:43:53,549
getting data online the nice thing about

00:43:51,089 --> 00:43:55,440
this imitation too is that we didn't

00:43:53,549 --> 00:43:56,519
change in this software that exists at

00:43:55,440 --> 00:43:58,109
any of the site so we were able to wrap

00:43:56,519 --> 00:44:01,920
it integrate it and distribute the

00:43:58,109 --> 00:44:03,539
repositories so earth science came along

00:44:01,920 --> 00:44:07,349
after planetary science as I mentioned

00:44:03,539 --> 00:44:10,019
and we used ODT early for some mission

00:44:07,349 --> 00:44:12,269
called quick stat CC winds quick sakes

00:44:10,019 --> 00:44:13,200
quit scat sorry antsy ones are actually

00:44:12,269 --> 00:44:17,010
two missions but they were

00:44:13,200 --> 00:44:19,410
it was an integrated project and we were

00:44:17,010 --> 00:44:21,540
able to actually take and remove a lot

00:44:19,410 --> 00:44:22,800
of the sort of proprietary cots based

00:44:21,540 --> 00:44:27,450
software at that point they were they

00:44:22,800 --> 00:44:29,940
were pretty connected to using sybase

00:44:27,450 --> 00:44:31,560
and siamese services he swapped all

00:44:29,940 --> 00:44:34,560
those out and we began to use OD chief

00:44:31,560 --> 00:44:36,510
of that and started to write all these

00:44:34,560 --> 00:44:38,130
workflows and and as I showed you that

00:44:36,510 --> 00:44:39,630
framework the idea is it was really our

00:44:38,130 --> 00:44:43,230
first instantiation where we could show

00:44:39,630 --> 00:44:45,510
a mission that was actually using ODT to

00:44:43,230 --> 00:44:48,510
begin to wrap and execute their

00:44:45,510 --> 00:44:50,730
algorithms at that point all that stuff

00:44:48,510 --> 00:44:54,030
was centralized and it's evolved now for

00:44:50,730 --> 00:44:55,740
future missions ocio our orbiting carbon

00:44:54,030 --> 00:44:57,540
Observatory was our first mission that

00:44:55,740 --> 00:44:59,790
really began to look at this st. okay

00:44:57,540 --> 00:45:01,650
we've done this great architecture how

00:44:59,790 --> 00:45:03,630
do we scale it now and so how do we push

00:45:01,650 --> 00:45:06,270
out the computation how do we push out

00:45:03,630 --> 00:45:08,940
the file and resource management so that

00:45:06,270 --> 00:45:12,060
we could be able to scale it as the size

00:45:08,940 --> 00:45:14,849
of our jobs our computation increased

00:45:12,060 --> 00:45:16,410
and as things like cloud services became

00:45:14,849 --> 00:45:23,310
available we could begin a scale to

00:45:16,410 --> 00:45:24,599
there as well airborne so JPL came along

00:45:23,310 --> 00:45:27,210
and said gee you guys have done this now

00:45:24,599 --> 00:45:29,220
for satellite missions 2011 we've got a

00:45:27,210 --> 00:45:30,599
got a big challenge in airborne missions

00:45:29,220 --> 00:45:32,460
and that is that you know we fly these

00:45:30,599 --> 00:45:34,170
airborne missions these are aircraft

00:45:32,460 --> 00:45:36,359
that fly over and they take source for

00:45:34,170 --> 00:45:38,970
regional localized measurements that the

00:45:36,359 --> 00:45:41,040
data often is not going in any kind of

00:45:38,970 --> 00:45:43,740
instrumented data system that people can

00:45:41,040 --> 00:45:45,300
get access to if if there is data

00:45:43,740 --> 00:45:46,980
processing going on is generally been

00:45:45,300 --> 00:45:49,349
done by PI and local their machine

00:45:46,980 --> 00:45:51,510
things like that and so we took the

00:45:49,349 --> 00:45:52,740
instantiation of ODT and what we have

00:45:51,510 --> 00:45:54,930
our experience of doing the earth

00:45:52,740 --> 00:45:57,930
science and pre quickly stood up a

00:45:54,930 --> 00:45:59,700
capability for airborne missions and we

00:45:57,930 --> 00:46:01,650
applied it to something called the card

00:45:59,700 --> 00:46:03,599
mission and its last a couple years

00:46:01,650 --> 00:46:07,770
which is making carbon observatories

00:46:03,599 --> 00:46:09,390
measurements and right we're able to

00:46:07,770 --> 00:46:13,020
show a substantial savings back sent to

00:46:09,390 --> 00:46:16,440
to JPL NASA for that the other thing

00:46:13,020 --> 00:46:18,540
that we did there is historically JPL

00:46:16,440 --> 00:46:20,460
has procured its own computational

00:46:18,540 --> 00:46:22,589
infrastructures and instead we convinced

00:46:20,460 --> 00:46:23,740
them to go out to Amazon and competing

00:46:22,589 --> 00:46:26,890
on top of

00:46:23,740 --> 00:46:29,140
amazon services and runner out RPGs

00:46:26,890 --> 00:46:31,480
there are algorithms there as part of a

00:46:29,140 --> 00:46:33,550
0 UT and and that's worked well too and

00:46:31,480 --> 00:46:35,710
we could show a substantial cost savings

00:46:33,550 --> 00:46:40,030
of us not having to buy our own hardware

00:46:35,710 --> 00:46:41,890
and provision that so another area we

00:46:40,030 --> 00:46:44,440
got involved in is climate research and

00:46:41,890 --> 00:46:45,880
the question there has been gee we're

00:46:44,440 --> 00:46:48,490
capturing all the satellite observations

00:46:45,880 --> 00:46:50,560
data the climate community has all these

00:46:48,490 --> 00:46:53,110
forecast models how they actually fit

00:46:50,560 --> 00:46:55,720
together are the forecast models valid

00:46:53,110 --> 00:46:57,730
as as forecast models against the

00:46:55,720 --> 00:46:59,650
observations or they only calibrate

00:46:57,730 --> 00:47:01,210
against each other so if you go back and

00:46:59,650 --> 00:47:03,340
look at what's called the international

00:47:01,210 --> 00:47:06,610
panel and climate change they run these

00:47:03,340 --> 00:47:08,920
regular protocols for studying climate

00:47:06,610 --> 00:47:12,000
climate models and using a climate model

00:47:08,920 --> 00:47:14,470
output for actually doing their research

00:47:12,000 --> 00:47:17,050
historically they have calibrated models

00:47:14,470 --> 00:47:19,270
against models what we have done in the

00:47:17,050 --> 00:47:22,420
last couple years is actually be able to

00:47:19,270 --> 00:47:24,610
bring in the the satellite observations

00:47:22,420 --> 00:47:27,250
and compare those against the models

00:47:24,610 --> 00:47:29,440
themselves and we're hoping that that

00:47:27,250 --> 00:47:31,300
will be a new direction validate not

00:47:29,440 --> 00:47:33,100
only flying into these missions but

00:47:31,300 --> 00:47:38,020
actually checking the balls themselves

00:47:33,100 --> 00:47:39,850
for accuracy so one group that we ended

00:47:38,020 --> 00:47:42,190
up working with and thanks to Lucas and

00:47:39,850 --> 00:47:43,420
Queenie who's out here in came to JPL

00:47:42,190 --> 00:47:46,450
after we started this experiment so i

00:47:43,420 --> 00:47:49,540
think it was working is that the the

00:47:46,450 --> 00:47:51,609
whole earth system grid federation is

00:47:49,540 --> 00:47:53,380
sharing models internationally but they

00:47:51,609 --> 00:47:55,840
had no access to the observational data

00:47:53,380 --> 00:47:58,869
and so what we were able to do is bring

00:47:55,840 --> 00:48:00,609
in the observational data bring in the

00:47:58,869 --> 00:48:02,680
technologies from nasa to work with them

00:48:00,609 --> 00:48:04,510
and integrate the technologies that have

00:48:02,680 --> 00:48:05,920
been built as part of their system grid

00:48:04,510 --> 00:48:08,050
framework which is an open source

00:48:05,920 --> 00:48:11,260
framework with what we have been doing

00:48:08,050 --> 00:48:13,000
with with ODT and sharing satellite data

00:48:11,260 --> 00:48:14,260
and so this is that picture which is

00:48:13,000 --> 00:48:16,000
starting to show all the satellite data

00:48:14,260 --> 00:48:17,650
going through a data exchange

00:48:16,000 --> 00:48:19,510
infrastructure Rhino DT called the

00:48:17,650 --> 00:48:22,440
climate data exchange and then sharing

00:48:19,510 --> 00:48:25,119
that with the the wrestling community

00:48:22,440 --> 00:48:28,960
another another example is what we've

00:48:25,119 --> 00:48:30,760
been doing in with lunar and that was

00:48:28,960 --> 00:48:35,390
that there was a big push when asked to

00:48:30,760 --> 00:48:38,100
go back to the moon and so they have

00:48:35,390 --> 00:48:39,450
they developed some capabilities to grab

00:48:38,100 --> 00:48:41,040
all that lunar data and make that

00:48:39,450 --> 00:48:43,770
available and provide some imaging

00:48:41,040 --> 00:48:46,770
capabilities on line that ran the cloud

00:48:43,770 --> 00:48:48,660
that use dodici that ran Hadoop to do

00:48:46,770 --> 00:48:50,010
all its tiling and so we brought that

00:48:48,660 --> 00:48:53,840
infrastructure together to be able to

00:48:50,010 --> 00:48:58,490
actually do sort of on the fly scalable

00:48:53,840 --> 00:49:01,200
image analysis of landing sites in path

00:48:58,490 --> 00:49:03,840
planning and so forth for for lunar

00:49:01,200 --> 00:49:05,640
missions now the one is Radio Astronomy

00:49:03,840 --> 00:49:07,260
as I mentioned the challenge here is

00:49:05,640 --> 00:49:09,030
that that with the Square Kilometre

00:49:07,260 --> 00:49:11,970
Array that are really moving to an

00:49:09,030 --> 00:49:16,440
exabyte scale to capture data we're

00:49:11,970 --> 00:49:19,080
talking about terabytes a second kinds

00:49:16,440 --> 00:49:21,960
of measurements with with large large

00:49:19,080 --> 00:49:24,570
arrays of radio antennas deployed in

00:49:21,960 --> 00:49:26,700
areas like like Africa that will be able

00:49:24,570 --> 00:49:28,980
to actually grab kept all this data it

00:49:26,700 --> 00:49:30,150
is it is a 10 year problem that we right

00:49:28,980 --> 00:49:33,090
now don't know how to solve but it's a

00:49:30,150 --> 00:49:35,400
very interesting one and then what I

00:49:33,090 --> 00:49:37,140
mentioned with biomedical research so

00:49:35,400 --> 00:49:39,480
we're involved we're supporting a

00:49:37,140 --> 00:49:41,250
network of 40 centers they're actually

00:49:39,480 --> 00:49:43,350
doing cancer biomarker research and

00:49:41,250 --> 00:49:46,950
doing things like proteomics genomics

00:49:43,350 --> 00:49:48,840
and other kinds of analysis and so we

00:49:46,950 --> 00:49:51,120
provide ODT to support the capture all

00:49:48,840 --> 00:49:52,920
that data they've got about forty or

00:49:51,120 --> 00:49:55,440
fifty to fifty data sets now captured in

00:49:52,920 --> 00:49:57,240
ODT we link it all together this is a

00:49:55,440 --> 00:49:58,350
picture of that down below where they

00:49:57,240 --> 00:49:59,850
actually have a national infrastructure

00:49:58,350 --> 00:50:01,860
and one of the things we did in addition

00:49:59,850 --> 00:50:03,840
to capturing the data is we put ODT out

00:50:01,860 --> 00:50:05,760
at all the Centers about 15 centers in

00:50:03,840 --> 00:50:08,520
this case to share a lot of their data

00:50:05,760 --> 00:50:10,170
called biospecimen data so not only is

00:50:08,520 --> 00:50:11,700
there data data centralized that we're

00:50:10,170 --> 00:50:14,010
capturing but there's data that exists

00:50:11,700 --> 00:50:15,270
in distributed sense as well that we're

00:50:14,010 --> 00:50:20,310
bringing together into an integrated

00:50:15,270 --> 00:50:21,900
virtual system and then as I mentioned

00:50:20,310 --> 00:50:24,030
medicine so we've been working with

00:50:21,900 --> 00:50:30,750
Children's Hospital Los Angeles for

00:50:24,030 --> 00:50:33,450
about 10 years and in 2009 we actually

00:50:30,750 --> 00:50:35,970
want a challenge grant from the National

00:50:33,450 --> 00:50:38,550
Library of Medicine and we're actually

00:50:35,970 --> 00:50:39,780
able to bring an ODT directly in there

00:50:38,550 --> 00:50:42,870
and help them start to capture their

00:50:39,780 --> 00:50:44,580
data extract the data from medical

00:50:42,870 --> 00:50:47,150
records and start to build a repository

00:50:44,580 --> 00:50:49,460
to actually do science analysis

00:50:47,150 --> 00:50:52,340
and so the idea was to build the data

00:50:49,460 --> 00:50:55,100
data infrastructure as well as this case

00:50:52,340 --> 00:50:56,540
bring in then the the analytical

00:50:55,100 --> 00:50:58,520
computational tools would you see down

00:50:56,540 --> 00:51:00,650
there below and so we built the pipeline

00:50:58,520 --> 00:51:02,750
appear to take go through a series of

00:51:00,650 --> 00:51:05,090
steps where we clean the data improve

00:51:02,750 --> 00:51:06,410
the data we d identify the data and then

00:51:05,090 --> 00:51:08,540
we start to build repositories and

00:51:06,410 --> 00:51:12,950
discrete data sets that could be shared

00:51:08,540 --> 00:51:16,340
with the community so thinking about

00:51:12,950 --> 00:51:18,610
this now OT and beyond beyond science a

00:51:16,340 --> 00:51:21,320
lot of the things I think that we see in

00:51:18,610 --> 00:51:23,330
science or patterns that exist other

00:51:21,320 --> 00:51:25,250
where in other places outside of science

00:51:23,330 --> 00:51:26,810
some of the common challenges how do you

00:51:25,250 --> 00:51:28,490
capture massive data repositories for

00:51:26,810 --> 00:51:31,280
analysis these are challenges that we

00:51:28,490 --> 00:51:32,690
are really interested in working on how

00:51:31,280 --> 00:51:34,250
do you develop methods for processing

00:51:32,690 --> 00:51:36,170
that data how do you run workflows on

00:51:34,250 --> 00:51:37,850
these how do you analyze the data from

00:51:36,170 --> 00:51:39,710
highly distributed data repositories

00:51:37,850 --> 00:51:41,510
we're involved in a lot of efforts that

00:51:39,710 --> 00:51:43,370
are really now focusing on that question

00:51:41,510 --> 00:51:45,980
if how do we actually do data science

00:51:43,370 --> 00:51:47,750
and how we do it in on data that's

00:51:45,980 --> 00:51:50,090
highly distributed as highly

00:51:47,750 --> 00:51:52,070
heterogeneous and in order to effect of

00:51:50,090 --> 00:51:54,470
architectures and ways to do that then

00:51:52,070 --> 00:51:55,970
how do you tie all this data together so

00:51:54,470 --> 00:51:57,530
that you can drive integrated data

00:51:55,970 --> 00:51:58,910
analysis so these are the challenges

00:51:57,530 --> 00:52:01,130
some of the things that we think are

00:51:58,910 --> 00:52:02,690
being addressed in science that we also

00:52:01,130 --> 00:52:04,340
see can really be addressed I think in

00:52:02,690 --> 00:52:05,810
other areas as well how can you take

00:52:04,340 --> 00:52:09,560
something like I would eat oh D T and

00:52:05,810 --> 00:52:10,880
use it to link data together so my

00:52:09,560 --> 00:52:13,430
encouragement to you guys is you know

00:52:10,880 --> 00:52:16,610
get involved in ott you know join the

00:52:13,430 --> 00:52:18,470
mailing lists the you know create

00:52:16,610 --> 00:52:19,520
suggestions if you have use cases send

00:52:18,470 --> 00:52:21,830
them the mailing list would be great to

00:52:19,520 --> 00:52:23,930
see what those are and to be able to

00:52:21,830 --> 00:52:25,280
talk through those and look at how ODT

00:52:23,930 --> 00:52:27,740
can be applied to other areas as well

00:52:25,280 --> 00:52:29,990
because I think our vision as part of

00:52:27,740 --> 00:52:32,420
the ODT community is to look at how do

00:52:29,990 --> 00:52:35,060
we really begin to make this a useful

00:52:32,420 --> 00:52:39,200
data management capability for big data

00:52:35,060 --> 00:52:42,610
management so with that we co DC has a

00:52:39,200 --> 00:52:42,610
linking source and I'll take

00:53:02,260 --> 00:53:09,340
I can see her she's on that side being a

00:53:06,460 --> 00:53:11,650
big trouble so this morning we heard a

00:53:09,340 --> 00:53:14,680
panel about the use of open source

00:53:11,650 --> 00:53:17,800
software in business and here you have

00:53:14,680 --> 00:53:21,070
described ODT as an observational system

00:53:17,800 --> 00:53:24,250
so I'm trying to link that the business

00:53:21,070 --> 00:53:26,050
users of open-source software I know

00:53:24,250 --> 00:53:28,750
they're interested in big data I know

00:53:26,050 --> 00:53:31,150
they have tremendous amounts of diverse

00:53:28,750 --> 00:53:33,400
data so how do i link this notion of an

00:53:31,150 --> 00:53:37,180
observational system into the business

00:53:33,400 --> 00:53:39,580
world so I can relate ODT to it so are

00:53:37,180 --> 00:53:42,000
the domain models that we use in science

00:53:39,580 --> 00:53:45,190
are those ones are optimized for

00:53:42,000 --> 00:53:47,860
observational data if there's a domain

00:53:45,190 --> 00:53:48,940
model for another area where already

00:53:47,860 --> 00:53:52,750
we're in defense and things like which

00:53:48,940 --> 00:53:55,360
are not observational we believe we can

00:53:52,750 --> 00:53:56,590
support that by being able to affect if

00:53:55,360 --> 00:53:58,840
we can effectively describe the data

00:53:56,590 --> 00:54:00,610
itself and i think that's that the key

00:53:58,840 --> 00:54:02,620
key goal is to be able to do that but

00:54:00,610 --> 00:54:04,570
many we think may the patterns of being

00:54:02,620 --> 00:54:07,270
a prostitue data integrate some of the

00:54:04,570 --> 00:54:09,250
technologies that exist for ski for

00:54:07,270 --> 00:54:11,160
viewing computation and provide a

00:54:09,250 --> 00:54:13,150
framework that that whole sort of

00:54:11,160 --> 00:54:15,040
workflow of being will capture the data

00:54:13,150 --> 00:54:16,720
that's something that we think is is

00:54:15,040 --> 00:54:18,520
really applicable to other business

00:54:16,720 --> 00:54:21,340
areas I think the key is starting to

00:54:18,520 --> 00:54:23,560
find models or data data definitions for

00:54:21,340 --> 00:54:25,450
data that is in other areas other than

00:54:23,560 --> 00:54:26,650
science and linking out into ODT and

00:54:25,450 --> 00:54:34,990
that's I think something where are we

00:54:26,650 --> 00:54:36,550
are seeing starting to happen so it's

00:54:34,990 --> 00:54:38,560
actually more like an observation than a

00:54:36,550 --> 00:54:39,760
question but one thing that we haven't

00:54:38,560 --> 00:54:42,640
really done on thinking about all the

00:54:39,760 --> 00:54:44,740
tea and big data we probably want to

00:54:42,640 --> 00:54:46,600
take each single t component and

00:54:44,740 --> 00:54:48,520
actually try to see how it scales to big

00:54:46,600 --> 00:54:49,780
data so just start benchmarking for

00:54:48,520 --> 00:54:51,310
example how many requests with ID

00:54:49,780 --> 00:54:53,320
manager we can actually send per sec on

00:54:51,310 --> 00:54:55,150
how many were closed we can actually run

00:54:53,320 --> 00:54:56,260
and you know stuff like that so there

00:54:55,150 --> 00:54:58,480
will be something that we can actually

00:54:56,260 --> 00:55:00,340
not doing it would be good instrument

00:54:58,480 --> 00:55:02,410
some of this right I am that's right and

00:55:00,340 --> 00:55:03,940
we do we have done some some

00:55:02,410 --> 00:55:05,830
benchmarking studies because we

00:55:03,940 --> 00:55:11,290
concerned about the size of volume

00:55:05,830 --> 00:55:13,060
emissions but you know the we often back

00:55:11,290 --> 00:55:14,560
into figuring out how to solve a problem

00:55:13,060 --> 00:55:21,420
rather systematically

00:55:14,560 --> 00:55:21,420

YouTube URL: https://www.youtube.com/watch?v=oM8mxN8ghxI


