Title: Monitoring Apache Tomcat and the Apache Web Server
Publication date: 2013-10-17
Playlist: Apachecon NA 2013 - day 2
Description: 
	Rainer Jung
ApacheCon NA 2013
A Patchy Web
Captions: 
	00:00:00,659 --> 00:00:05,160
next up we have Reyna young with

00:00:03,000 --> 00:00:08,990
monitoring Apache Tomcat and the Apache

00:00:05,160 --> 00:00:08,990
web server please give them applause

00:00:11,599 --> 00:00:16,619
hello everybody

00:00:13,950 --> 00:00:18,359
yeah the topic is about monitoring and

00:00:16,619 --> 00:00:20,250
the two products are coming from

00:00:18,359 --> 00:00:23,070
different technological worlds one is

00:00:20,250 --> 00:00:26,490
written in C one in Java so the means of

00:00:23,070 --> 00:00:28,500
monitoring differ but the metrics are

00:00:26,490 --> 00:00:29,939
quite similar and I will concentrate on

00:00:28,500 --> 00:00:32,579
the metrics on the data that's available

00:00:29,939 --> 00:00:34,440
not how to actually retrieve the data I

00:00:32,579 --> 00:00:36,480
will say a few words about retrieving

00:00:34,440 --> 00:00:38,460
but more about and what kind of

00:00:36,480 --> 00:00:42,480
information is there and why it could be

00:00:38,460 --> 00:00:45,000
interesting so first of all the agenda I

00:00:42,480 --> 00:00:48,930
give a short motivation what I mean by

00:00:45,000 --> 00:00:51,170
monitoring and why I think more data is

00:00:48,930 --> 00:00:54,570
interesting than typically is collected

00:00:51,170 --> 00:00:54,989
then I will talk a little bit about J

00:00:54,570 --> 00:00:57,840
mix

00:00:54,989 --> 00:01:00,930
JMX but before going into J mix I will

00:00:57,840 --> 00:01:02,850
just let you raise your hands who

00:01:00,930 --> 00:01:04,619
already knows about J makes so probably

00:01:02,850 --> 00:01:08,850
we can skip a part of a bit of it other

00:01:04,619 --> 00:01:11,670
last later and then some short remarks

00:01:08,850 --> 00:01:13,500
and then there's the biggest part is

00:01:11,670 --> 00:01:16,710
about Apache Tomcat which metrics are

00:01:13,500 --> 00:01:18,659
available and then similar metrics for

00:01:16,710 --> 00:01:22,049
the Apache web server and hopefully

00:01:18,659 --> 00:01:24,780
we'll have time for some discussion so

00:01:22,049 --> 00:01:27,259
for the motivation typically the main

00:01:24,780 --> 00:01:32,479
goal of monitoring is failure detection

00:01:27,259 --> 00:01:32,479
red/green statures alarms notification

00:01:32,750 --> 00:01:38,369
unfortunately this only works in for

00:01:36,689 --> 00:01:41,280
very specific components and very

00:01:38,369 --> 00:01:43,740
specific situations we usually do not

00:01:41,280 --> 00:01:45,030
want false positives in the middle of

00:01:43,740 --> 00:01:48,590
the night getting a call because of

00:01:45,030 --> 00:01:52,920
false offer false positive is not nice

00:01:48,590 --> 00:01:57,149
but this goal can only be reached for

00:01:52,920 --> 00:02:01,229
simple things like file system 3 % h CPU

00:01:57,149 --> 00:02:08,280
bc or end-to-end checkable things like

00:02:01,229 --> 00:02:10,950
logins transactions and so on I think

00:02:08,280 --> 00:02:13,390
it's important to collect additional

00:02:10,950 --> 00:02:15,640
metrics even if there is no

00:02:13,390 --> 00:02:18,610
of putting a threshold on them or if

00:02:15,640 --> 00:02:22,410
there's no way of letting letting them

00:02:18,610 --> 00:02:25,480
fire a notification in case of a failure

00:02:22,410 --> 00:02:28,560
such metrics typically should be

00:02:25,480 --> 00:02:31,450
appalled in regular intervals stored

00:02:28,560 --> 00:02:34,600
accumulated over time and visualized in

00:02:31,450 --> 00:02:38,440
advance why do I think it's important

00:02:34,600 --> 00:02:40,450
such metrics are typically used in case

00:02:38,440 --> 00:02:43,390
of problems to analyze the root cause

00:02:40,450 --> 00:02:45,910
after the fact if you do not have any

00:02:43,390 --> 00:02:48,850
data collected in advance then you have

00:02:45,910 --> 00:02:50,680
to wait for the next time the problem

00:02:48,850 --> 00:02:53,680
happens and prepare then to collect data

00:02:50,680 --> 00:02:58,060
so it's a good idea to do it from the

00:02:53,680 --> 00:03:03,970
beginning also many of these data help

00:02:58,060 --> 00:03:06,970
to do a good capacity management so what

00:03:03,970 --> 00:03:09,190
kind of metrics are we looking for I'm

00:03:06,970 --> 00:03:11,170
looking for metrics that give

00:03:09,190 --> 00:03:14,140
information about application load and

00:03:11,170 --> 00:03:15,880
response times about utilization of

00:03:14,140 --> 00:03:20,260
software components like pools and

00:03:15,880 --> 00:03:22,180
caches about utilization of resources in

00:03:20,260 --> 00:03:25,720
the Java case especially about memory

00:03:22,180 --> 00:03:27,730
and garbage collection behavior but I

00:03:25,720 --> 00:03:30,190
will focus in this talk is what's

00:03:27,730 --> 00:03:31,780
readily available in Tomcat and the

00:03:30,190 --> 00:03:35,070
Apache web server so I'm not talking

00:03:31,780 --> 00:03:37,900
about your application specific stuff

00:03:35,070 --> 00:03:43,180
I'm also not talking about log file

00:03:37,900 --> 00:03:46,630
monitoring things that we typically do

00:03:43,180 --> 00:03:48,730
not get from the usual monitoring is

00:03:46,630 --> 00:03:51,190
information whether for instance the

00:03:48,730 --> 00:03:53,079
application is fine but it's waiting for

00:03:51,190 --> 00:03:55,930
another system for a back-end for a

00:03:53,079 --> 00:03:58,780
database but it's waiting to acquire

00:03:55,930 --> 00:04:01,630
locks whether we are looping in code so

00:03:58,780 --> 00:04:05,440
this is these are our types of errors

00:04:01,630 --> 00:04:07,750
that we would not detect with that kind

00:04:05,440 --> 00:04:09,970
of monitoring in the Java world one

00:04:07,750 --> 00:04:13,870
would use three Tom's but that's enough

00:04:09,970 --> 00:04:17,579
material for another talk so let's have

00:04:13,870 --> 00:04:19,450
a short introduction to Jamie to get you

00:04:17,579 --> 00:04:23,700
acquainted with the basic terminology

00:04:19,450 --> 00:04:26,620
give me a hand who knows about JMX

00:04:23,700 --> 00:04:27,080
it's about half of the people so I

00:04:26,620 --> 00:04:28,909
should

00:04:27,080 --> 00:04:31,159
not skip the whole block but but maybe I

00:04:28,909 --> 00:04:33,520
can go through it a little faster the

00:04:31,159 --> 00:04:37,580
slides will be available after the talk

00:04:33,520 --> 00:04:40,039
so JMX java management extensions is a

00:04:37,580 --> 00:04:42,139
standard in the java world it can be

00:04:40,039 --> 00:04:47,689
used to expose internal application

00:04:42,139 --> 00:04:50,240
states to the outside typical such

00:04:47,689 --> 00:04:53,330
states are sizes of pools counters

00:04:50,240 --> 00:04:57,319
request counters error counters also

00:04:53,330 --> 00:04:59,919
configuration settings the data can be a

00:04:57,319 --> 00:05:04,849
list of scalars but it can also be

00:04:59,919 --> 00:05:07,669
structured in nested data structures in

00:05:04,849 --> 00:05:10,120
addition Cham X also supports operations

00:05:07,669 --> 00:05:13,909
for instance resetting statistics or

00:05:10,120 --> 00:05:16,969
changing configuration and it supports

00:05:13,909 --> 00:05:20,240
and sending out notifications I will

00:05:16,969 --> 00:05:23,900
focus on metrics that are available and

00:05:20,240 --> 00:05:27,050
interested in for monitoring the data

00:05:23,900 --> 00:05:30,889
typically is grouped in objects called m

00:05:27,050 --> 00:05:35,330
beans the M always stands for management

00:05:30,889 --> 00:05:37,699
in GM X the M beans have a name the name

00:05:35,330 --> 00:05:40,430
is structured it's called an object name

00:05:37,699 --> 00:05:42,110
and apart from the name they have a list

00:05:40,430 --> 00:05:47,659
of attributes and that's where the data

00:05:42,110 --> 00:05:50,029
sets a simple example is on the lower

00:05:47,659 --> 00:05:53,389
part of the slide there you can see the

00:05:50,029 --> 00:05:56,830
name starts in this case with the term

00:05:53,389 --> 00:06:01,129
Catalina and you might have seen that

00:05:56,830 --> 00:06:02,839
showing up around Tomcat lots of time we

00:06:01,129 --> 00:06:05,240
will later see where this Catalina here

00:06:02,839 --> 00:06:06,919
in the name comes from and then after

00:06:05,240 --> 00:06:08,810
the and this part of the name in front

00:06:06,919 --> 00:06:13,190
of the colon it's called the domain it's

00:06:08,810 --> 00:06:16,909
the major grouping of M beans and then

00:06:13,190 --> 00:06:19,849
we have a list of key equals value pairs

00:06:16,909 --> 00:06:21,740
in this case we have a type thread pool

00:06:19,849 --> 00:06:23,479
we have a name so there could be many

00:06:21,740 --> 00:06:25,969
thread pools and we can distinguish with

00:06:23,479 --> 00:06:28,639
them and below we have a list of

00:06:25,969 --> 00:06:32,029
attributes like current thread count 10

00:06:28,639 --> 00:06:36,830
and so on so that's a basic view of an M

00:06:32,029 --> 00:06:37,190
bean now how do we get access to the M

00:06:36,830 --> 00:06:39,940
beans

00:06:37,190 --> 00:06:41,800
M beans are always registered with

00:06:39,940 --> 00:06:43,810
ambien server that's the registry of

00:06:41,800 --> 00:06:45,610
mbeans and they are registered under

00:06:43,810 --> 00:06:49,270
their name so the object name of the

00:06:45,610 --> 00:06:51,130
ambien is important typically in a

00:06:49,270 --> 00:06:54,280
running JVM there is only one ambien

00:06:51,130 --> 00:06:58,060
server but in some situations there can

00:06:54,280 --> 00:07:02,410
be multiple typically for Tomcat has

00:06:58,060 --> 00:07:05,500
only one ambien server each running Java

00:07:02,410 --> 00:07:10,030
process already contains an ambien

00:07:05,500 --> 00:07:14,470
server and not short list of mbeans we

00:07:10,030 --> 00:07:16,420
will see those mbeans very soon so even

00:07:14,470 --> 00:07:18,550
without having a Tomcat in the Java

00:07:16,420 --> 00:07:20,290
process or having your application there

00:07:18,550 --> 00:07:23,740
is already a couple of mbeans that

00:07:20,290 --> 00:07:26,130
provide interesting data for Tomcat

00:07:23,740 --> 00:07:29,920
there is an additional list of mbeans

00:07:26,130 --> 00:07:33,790
and an application developer could

00:07:29,920 --> 00:07:36,370
easily provide own monitoring

00:07:33,790 --> 00:07:40,150
information via our custom mbeans and

00:07:36,370 --> 00:07:41,800
that's a good thing to do so now

00:07:40,150 --> 00:07:47,890
typically monitoring we want to do

00:07:41,800 --> 00:07:50,169
remote access one way to do it is using

00:07:47,890 --> 00:07:52,630
Java as a client because Java knows how

00:07:50,169 --> 00:07:56,800
to access to a mix gem X over the

00:07:52,630 --> 00:07:58,960
network to enable this one has to use a

00:07:56,800 --> 00:08:01,930
couple of system properties to allow

00:07:58,960 --> 00:08:03,750
remote access I gave the URL where you

00:08:01,930 --> 00:08:06,190
can read about it

00:08:03,750 --> 00:08:08,500
caution if you do it for production

00:08:06,190 --> 00:08:11,230
systems always enable access control

00:08:08,500 --> 00:08:14,260
because as I said gem X does not own or

00:08:11,230 --> 00:08:17,650
does not only provide metrics it also

00:08:14,260 --> 00:08:20,169
allows to call operations so who can

00:08:17,650 --> 00:08:21,820
connect to JMX might be able to do

00:08:20,169 --> 00:08:24,040
things to your running processes that

00:08:21,820 --> 00:08:27,640
you don't want so use access control

00:08:24,040 --> 00:08:29,560
there jmx does have a couple of problems

00:08:27,640 --> 00:08:31,960
with firewalls because it uses dynamic

00:08:29,560 --> 00:08:34,510
ports in the case of Tomcat I gave

00:08:31,960 --> 00:08:36,099
another link there is a workaround where

00:08:34,510 --> 00:08:39,659
you can make sure that only ports are

00:08:36,099 --> 00:08:41,440
used that are open in your firewalls

00:08:39,659 --> 00:08:45,670
okay

00:08:41,440 --> 00:08:48,880
couple of examples there is a well-known

00:08:45,670 --> 00:08:52,089
jmx client that's called a visual VM and

00:08:48,880 --> 00:08:54,160
a visual VM is not about monitoring it's

00:08:52,089 --> 00:08:55,690
an interactive GUI

00:08:54,160 --> 00:08:59,380
so you wouldn't use it in an enterprise

00:08:55,690 --> 00:09:02,050
scale bird it's a nice tool to have a

00:08:59,380 --> 00:09:03,820
first look at which mbeans are there how

00:09:02,050 --> 00:09:06,730
do the data look do I understand the

00:09:03,820 --> 00:09:10,510
data before you start to configuring

00:09:06,730 --> 00:09:14,170
your monitoring system to pull the stuff

00:09:10,510 --> 00:09:18,730
automatically jvzoo VM comes comes with

00:09:14,170 --> 00:09:21,940
the Oracle JDK and I will show a short

00:09:18,730 --> 00:09:24,910
demo just so that you have an idea that

00:09:21,940 --> 00:09:27,910
it's interesting to look at it there is

00:09:24,910 --> 00:09:30,940
lots of gem mix clients I gave one

00:09:27,910 --> 00:09:33,250
totally other different example gem

00:09:30,940 --> 00:09:35,170
x-term it's an interactive shell like

00:09:33,250 --> 00:09:38,050
access to jmx

00:09:35,170 --> 00:09:40,650
and probably all monitoring solutions

00:09:38,050 --> 00:09:44,050
allow integration of JMX

00:09:40,650 --> 00:09:51,790
so let's have a very short look at a

00:09:44,050 --> 00:09:54,880
visual VM I already started it and now

00:09:51,790 --> 00:10:01,660
the question is I will have a I will

00:09:54,880 --> 00:10:07,810
make it bigger in a moment so let me the

00:10:01,660 --> 00:10:09,610
first Java process I will use is doing

00:10:07,810 --> 00:10:12,040
nothing else than just sleeping for five

00:10:09,610 --> 00:10:15,400
minutes and then exiting so that there

00:10:12,040 --> 00:10:27,540
is no application code apart from the

00:10:15,400 --> 00:10:33,250
sleeping in there so I started a class

00:10:27,540 --> 00:10:35,860
sleep and it shows up here and when I

00:10:33,250 --> 00:10:40,800
have to tap open I can make it bigger

00:10:35,860 --> 00:10:40,800
let's see whether that works

00:10:44,820 --> 00:10:54,250
yeah so it is readable yeah okay so what

00:10:50,350 --> 00:10:56,290
we see is that a visual VM attached to

00:10:54,250 --> 00:10:59,470
this running Java process and it shows

00:10:56,290 --> 00:11:01,209
us a view of all the mbeans available

00:10:59,470 --> 00:11:03,250
and they are grouped here by domain

00:11:01,209 --> 00:11:05,440
remember there was this domain part in

00:11:03,250 --> 00:11:08,260
front of the colon which was Catalina in

00:11:05,440 --> 00:11:10,420
the Tomcat case and here we have a few

00:11:08,260 --> 00:11:13,269
names that sound more like basic Java

00:11:10,420 --> 00:11:16,510
stuff most of the mbeans that are there

00:11:13,269 --> 00:11:19,089
always are underneath Java dot Lang and

00:11:16,510 --> 00:11:22,779
we will come back to these mbeans very

00:11:19,089 --> 00:11:26,290
soon I will just give you an impression

00:11:22,779 --> 00:11:28,630
that it's very easy to explore them you

00:11:26,290 --> 00:11:31,269
can open them and then you see the list

00:11:28,630 --> 00:11:33,579
of attributes and you see the values so

00:11:31,269 --> 00:11:37,120
you can go through through this very

00:11:33,579 --> 00:11:39,760
easily and get an idea how this works

00:11:37,120 --> 00:11:41,949
note that the first time you start a

00:11:39,760 --> 00:11:44,800
visual VM it will not show the mbeans

00:11:41,949 --> 00:11:46,690
there is a plug-in concept and the menu

00:11:44,800 --> 00:11:49,209
that says you can activate additional

00:11:46,690 --> 00:11:51,339
plugins and by default one of the

00:11:49,209 --> 00:11:53,769
plugins that's available is for mbeans

00:11:51,339 --> 00:11:55,720
and if you activate it and restart a

00:11:53,769 --> 00:12:05,589
visual vm then it will show you the

00:11:55,720 --> 00:12:12,300
ambient information so oops let's return

00:12:05,589 --> 00:12:15,300
to the normal size and to our

00:12:12,300 --> 00:12:15,300
presentation

00:12:18,170 --> 00:12:26,880
okay so a couple of remarks about gem

00:12:23,089 --> 00:12:30,180
ex-clients the very basic monitoring

00:12:26,880 --> 00:12:33,630
setups often use a simple shell script

00:12:30,180 --> 00:12:36,089
that each time you pull data starts a

00:12:33,630 --> 00:12:38,220
Java process that connects firegem X and

00:12:36,089 --> 00:12:40,769
retrieves the data and that's a no-go

00:12:38,220 --> 00:12:42,720
because that doesn't scale it's much too

00:12:40,769 --> 00:12:46,769
expensive to charge to start a Java

00:12:42,720 --> 00:12:49,670
process each time you pull data so you

00:12:46,769 --> 00:12:52,079
need a kind of persistent jam X client

00:12:49,670 --> 00:12:54,240
there is another way of doing it

00:12:52,079 --> 00:12:58,980
especially because we are now talking

00:12:54,240 --> 00:13:02,399
about Tomcat we could run an agent

00:12:58,980 --> 00:13:04,829
inside Tomcat that has in process access

00:13:02,399 --> 00:13:09,720
to the gem X data and from the outside

00:13:04,829 --> 00:13:11,880
can be contacted via HTTP so then the

00:13:09,720 --> 00:13:14,630
basic technologies we can use on the

00:13:11,880 --> 00:13:18,750
client side are much more flexible and

00:13:14,630 --> 00:13:22,250
all the gem X part of it will be

00:13:18,750 --> 00:13:24,839
contained in the Tomcat Java process

00:13:22,250 --> 00:13:27,180
another solution but I will not go

00:13:24,839 --> 00:13:28,980
in-depth here would be running a proxy

00:13:27,180 --> 00:13:31,170
somewhere so running a persistent Java

00:13:28,980 --> 00:13:34,829
process that could be contacted from the

00:13:31,170 --> 00:13:39,779
client and relays the requests to the

00:13:34,829 --> 00:13:42,029
target JVM so some remarks before we

00:13:39,779 --> 00:13:44,940
actually go through the mbeans that are

00:13:42,029 --> 00:13:47,220
available it's important to take the

00:13:44,940 --> 00:13:49,769
measurement automatically and not simply

00:13:47,220 --> 00:13:51,570
using che visual VM this is only for a

00:13:49,769 --> 00:13:55,290
talk inspection finding out what's

00:13:51,570 --> 00:13:57,990
available typical poly interval for the

00:13:55,290 --> 00:14:02,399
data that I present should be around 1

00:13:57,990 --> 00:14:04,470
minute 1 once per minute in addition to

00:14:02,399 --> 00:14:06,060
appalling and persisting of course we

00:14:04,470 --> 00:14:10,079
need to think about thresholds and I

00:14:06,060 --> 00:14:14,010
tried to add the word threshold to each

00:14:10,079 --> 00:14:18,089
metric where I think thresholds could be

00:14:14,010 --> 00:14:20,490
reasonably set data that you collect

00:14:18,089 --> 00:14:22,860
should be visualized because I'm looking

00:14:20,490 --> 00:14:24,360
at long rows of numbers typically gifts

00:14:22,860 --> 00:14:28,709
don't wouldn't give you the right

00:14:24,360 --> 00:14:30,290
impression what's happening the second

00:14:28,709 --> 00:14:35,310
thing

00:14:30,290 --> 00:14:37,980
often mbeans contain only scalar data

00:14:35,310 --> 00:14:41,790
and that's good because it's easy to

00:14:37,980 --> 00:14:44,010
support for all tools we will soon see

00:14:41,790 --> 00:14:45,600
that some of the platform ambience in

00:14:44,010 --> 00:14:49,860
the JVM some of the ambience that are

00:14:45,600 --> 00:14:51,660
always there use nested data and the

00:14:49,860 --> 00:14:53,970
problem is that you have to make sure

00:14:51,660 --> 00:14:57,360
that your tool chain supports nested

00:14:53,970 --> 00:15:00,000
data in ambience so if your developers

00:14:57,360 --> 00:15:03,529
think about adding ambience to your

00:15:00,000 --> 00:15:06,510
applications themselves they should

00:15:03,529 --> 00:15:08,640
think twice whether the tools you're

00:15:06,510 --> 00:15:14,640
using for monitoring actually support

00:15:08,640 --> 00:15:17,100
the use of structured data mbeans

00:15:14,640 --> 00:15:19,860
unfortunately they typically reflect the

00:15:17,100 --> 00:15:22,529
source code structure so they are

00:15:19,860 --> 00:15:24,450
grouped somehow close to the classes

00:15:22,529 --> 00:15:28,529
they are used in the code this

00:15:24,450 --> 00:15:31,080
granularity is not always optimal and if

00:15:28,529 --> 00:15:34,800
we have many instances of objects and

00:15:31,080 --> 00:15:36,990
often we have many mbeans so this might

00:15:34,800 --> 00:15:41,550
mean that if we want to retrieve the

00:15:36,990 --> 00:15:44,459
data we had to do many polls if we

00:15:41,550 --> 00:15:47,370
retrieve data for one mbean each time

00:15:44,459 --> 00:15:49,890
and we want to get the data from 20 then

00:15:47,370 --> 00:15:51,089
we would have to do 20 polls it would be

00:15:49,890 --> 00:15:53,550
much more efficient if the tool

00:15:51,089 --> 00:15:55,890
supported some bulk operations so

00:15:53,550 --> 00:15:56,550
retrieving data for a given set of

00:15:55,890 --> 00:16:00,750
mbeans

00:15:56,550 --> 00:16:03,930
at once what is typically not clever is

00:16:00,750 --> 00:16:05,520
retrieving all anything from the mbean

00:16:03,930 --> 00:16:08,120
server and then filtering on the

00:16:05,520 --> 00:16:09,870
client-side because that could trigger

00:16:08,120 --> 00:16:11,850
unwanted side-effects

00:16:09,870 --> 00:16:13,380
on the server side for instance if you

00:16:11,850 --> 00:16:16,080
do it with the WebLogic server running

00:16:13,380 --> 00:16:18,110
then every time you do it it will create

00:16:16,080 --> 00:16:23,900
a full stratum of the WebLogic server

00:16:18,110 --> 00:16:29,970
and another thing the data is not always

00:16:23,900 --> 00:16:33,060
in given in a way that is directly

00:16:29,970 --> 00:16:35,160
useful sometimes we have to apply simple

00:16:33,060 --> 00:16:36,839
mathematical operations on the data for

00:16:35,160 --> 00:16:39,810
instance if the data is a counters in

00:16:36,839 --> 00:16:40,770
startup then this is not useful we have

00:16:39,810 --> 00:16:42,390
to

00:16:40,770 --> 00:16:44,399
for instance look at the Delta since

00:16:42,390 --> 00:16:46,860
last time which should be retrieved it

00:16:44,399 --> 00:16:48,410
or at the rates how much did it change

00:16:46,860 --> 00:16:50,850
per second in the last interval

00:16:48,410 --> 00:16:55,290
sometimes we need to do quotients of

00:16:50,850 --> 00:16:59,490
data or even quotients of deltas now

00:16:55,290 --> 00:17:03,660
let's know it's enough of theory let's

00:16:59,490 --> 00:17:08,010
have a look at Tomcat first of all I'm

00:17:03,660 --> 00:17:10,620
not going to use a Java client I'm going

00:17:08,010 --> 00:17:13,770
to use a very simple a way of retrieving

00:17:10,620 --> 00:17:15,780
and presenting the data and this is a

00:17:13,770 --> 00:17:18,030
way that's built-in in Tomcat

00:17:15,780 --> 00:17:19,949
it's a servlet that's part of the Tomcat

00:17:18,030 --> 00:17:23,189
manager web application it's called the

00:17:19,949 --> 00:17:25,140
JMX proxy it's not very powerful but for

00:17:23,189 --> 00:17:29,670
just simply retrieving the data it's not

00:17:25,140 --> 00:17:33,030
that bad actually just to give you

00:17:29,670 --> 00:17:35,760
another option there is a another web

00:17:33,030 --> 00:17:38,280
app called Jolokia that's also available

00:17:35,760 --> 00:17:41,070
for Tomcat and other application servers

00:17:38,280 --> 00:17:44,940
and web containers Jolokia returns the

00:17:41,070 --> 00:17:47,820
data in form of JSON serialization and

00:17:44,940 --> 00:17:49,890
there is a client that there are various

00:17:47,820 --> 00:17:53,670
clients for chalukya providing

00:17:49,890 --> 00:17:56,040
JavaScript API is perl api's and also

00:17:53,670 --> 00:17:58,050
interactive api's so that's another way

00:17:56,040 --> 00:18:02,190
that's not bundled it's also open source

00:17:58,050 --> 00:18:03,240
but it's not part of Tomcat so we start

00:18:02,190 --> 00:18:05,370
with platform mbeans

00:18:03,240 --> 00:18:08,280
these are the ones that are available in

00:18:05,370 --> 00:18:10,260
every JVM not just in Tomcat first

00:18:08,280 --> 00:18:14,730
platform and bean operating system M

00:18:10,260 --> 00:18:17,480
bean I do not show the full data because

00:18:14,730 --> 00:18:20,340
I think I omitted everything that's

00:18:17,480 --> 00:18:23,970
that's totally irrelevant to monitoring

00:18:20,340 --> 00:18:26,040
maybe I will show a little that's not

00:18:23,970 --> 00:18:28,530
really relevant but I tried to omit

00:18:26,040 --> 00:18:30,780
everything that's totally irrelevant so

00:18:28,530 --> 00:18:33,090
from the operating system M bean and the

00:18:30,780 --> 00:18:36,450
number in red it says process CPU time

00:18:33,090 --> 00:18:38,700
it's a pretty huge number that was

00:18:36,450 --> 00:18:42,480
shortly after starting the process

00:18:38,700 --> 00:18:45,200
actually how could it take that much CPU

00:18:42,480 --> 00:18:49,320
time be careful this is in nanoseconds

00:18:45,200 --> 00:18:50,790
okay so if you retrieve a metric think

00:18:49,320 --> 00:18:52,370
twice whether you really know what the

00:18:50,790 --> 00:18:56,870
unit is whether you found

00:18:52,370 --> 00:19:00,140
documentation for it or not this mbean

00:18:56,870 --> 00:19:03,530
provides also system load average it

00:19:00,140 --> 00:19:06,140
provides lots of numbers about the

00:19:03,530 --> 00:19:08,090
process and this is the memory but not

00:19:06,140 --> 00:19:09,590
fine-grained in the Java world is more

00:19:08,090 --> 00:19:11,720
to look from the outside from the

00:19:09,590 --> 00:19:13,610
operating system level and it provides

00:19:11,720 --> 00:19:15,140
access to numbers of open file

00:19:13,610 --> 00:19:21,650
descriptors and maximum open file

00:19:15,140 --> 00:19:23,570
descriptors concerning the process CPU

00:19:21,650 --> 00:19:25,309
time what could we do with the process

00:19:23,570 --> 00:19:28,580
CPU time obviously it's a counter it

00:19:25,309 --> 00:19:31,610
will always go up so per se it's not

00:19:28,580 --> 00:19:34,550
very useful but think what would it be

00:19:31,610 --> 00:19:38,929
if we take the rate change of process

00:19:34,550 --> 00:19:41,179
CPU time overtime CPU time overtime what

00:19:38,929 --> 00:19:43,010
would what would the unit be your CPU

00:19:41,179 --> 00:19:46,040
time would be seconds or milliseconds

00:19:43,010 --> 00:19:48,620
overtime divided by seconds so it has no

00:19:46,040 --> 00:19:52,340
unit it's just a scaler and what is it

00:19:48,620 --> 00:19:54,080
what is it it's the average CPU

00:19:52,340 --> 00:19:56,780
concurrency in the last measurement

00:19:54,080 --> 00:20:00,110
interval so it's roughly how many cores

00:19:56,780 --> 00:20:03,830
were used and that's that's an

00:20:00,110 --> 00:20:06,140
interesting number then we've got the

00:20:03,830 --> 00:20:09,290
system load average and here it's the

00:20:06,140 --> 00:20:13,190
usual 1-minute average that's provided

00:20:09,290 --> 00:20:15,500
by any UNIX type system for instance the

00:20:13,190 --> 00:20:17,450
committed virtual memory size typically

00:20:15,500 --> 00:20:20,200
you only look at the Java internal sizes

00:20:17,450 --> 00:20:23,929
but if you're using Java native parts

00:20:20,200 --> 00:20:26,870
and probably have some memory leaks

00:20:23,929 --> 00:20:30,380
there then you can use this one to track

00:20:26,870 --> 00:20:33,650
whether restart is actually soon needed

00:20:30,380 --> 00:20:37,550
or not and the maximum fighter Script

00:20:33,650 --> 00:20:42,030
account I think many ran into the

00:20:37,550 --> 00:20:44,220
problem that for some reason the

00:20:42,030 --> 00:20:45,510
the limit of the file descriptor count

00:20:44,220 --> 00:20:48,330
was not big enough and you had to

00:20:45,510 --> 00:20:50,400
readjust it there is actually a way of

00:20:48,330 --> 00:20:53,280
tracking how many open file descriptors

00:20:50,400 --> 00:20:57,380
are there so that you can easily get an

00:20:53,280 --> 00:21:02,310
alarm when you approach the limit

00:20:57,380 --> 00:21:04,800
runtime runtime mbean the only more or

00:21:02,310 --> 00:21:08,060
less useful item it has is the uptime so

00:21:04,800 --> 00:21:11,220
you can track when the last restart was

00:21:08,060 --> 00:21:13,560
the threading mbean it gives you

00:21:11,220 --> 00:21:16,740
information about how many threats are

00:21:13,560 --> 00:21:20,280
in your process not only currently it

00:21:16,740 --> 00:21:24,150
also has a peak count and it also shows

00:21:20,280 --> 00:21:27,120
you how many threats have been started

00:21:24,150 --> 00:21:28,620
so again by using the rate you can see

00:21:27,120 --> 00:21:34,980
how many threats per second you were

00:21:28,620 --> 00:21:37,440
starting to mbeans that I think are not

00:21:34,980 --> 00:21:39,180
that interesting I would typically not

00:21:37,440 --> 00:21:41,010
monitor them but it's good to know that

00:21:39,180 --> 00:21:43,680
they are available in case one has a

00:21:41,010 --> 00:21:46,260
very specific problem one of it monitors

00:21:43,680 --> 00:21:48,210
class loading typically it sooner or

00:21:46,260 --> 00:21:51,570
later gets stable so there is no more no

00:21:48,210 --> 00:21:55,020
more interesting stuff to see it's not

00:21:51,570 --> 00:21:57,150
true if you start running dynamic

00:21:55,020 --> 00:21:59,460
languages in the JVM then it might be

00:21:57,150 --> 00:22:01,830
that a lot of classes get generated

00:21:59,460 --> 00:22:03,360
dynamically and you probably might run

00:22:01,830 --> 00:22:05,280
into a problem because there's too much

00:22:03,360 --> 00:22:07,290
class loading activity and then it's

00:22:05,280 --> 00:22:09,690
actually useful that one could monitor

00:22:07,290 --> 00:22:12,120
the activity compilation is about the

00:22:09,690 --> 00:22:19,980
hotspot compiler so the on-the-fly

00:22:12,120 --> 00:22:26,220
compilation of methods into assembler

00:22:19,980 --> 00:22:28,620
code so next one memory this one only

00:22:26,220 --> 00:22:30,930
has heap and non heap memory usage and

00:22:28,620 --> 00:22:32,880
that's not very useful because if you

00:22:30,930 --> 00:22:35,520
know about Java memory and garbage

00:22:32,880 --> 00:22:37,200
collection tuning then you know that you

00:22:35,520 --> 00:22:39,660
cannot look at the memory as one big

00:22:37,200 --> 00:22:41,130
block it's divided in several parts and

00:22:39,660 --> 00:22:43,800
you have to individually control what's

00:22:41,130 --> 00:22:46,830
happening so this one typically I would

00:22:43,800 --> 00:22:49,590
not use but there is a memory pool and

00:22:46,830 --> 00:22:52,470
beam and that this M being is available

00:22:49,590 --> 00:22:54,480
for the individual memory regions so

00:22:52,470 --> 00:22:55,610
again it's not a talked about Java

00:22:54,480 --> 00:22:57,410
memory and garbage collection

00:22:55,610 --> 00:22:59,120
tuning but you might have heard the

00:22:57,410 --> 00:23:01,340
terminology there is an Eden space

00:22:59,120 --> 00:23:03,799
survivor spaces tenured permanent and

00:23:01,340 --> 00:23:06,920
each of those spaces have one memory

00:23:03,799 --> 00:23:09,620
pool M beam and this M beam you can use

00:23:06,920 --> 00:23:13,970
to track the usage and the peak usage

00:23:09,620 --> 00:23:17,780
it also has information about the usage

00:23:13,970 --> 00:23:20,179
after the last garbage collection it's

00:23:17,780 --> 00:23:22,549
the collection usage item the last in

00:23:20,179 --> 00:23:25,820
the list bird for this you would better

00:23:22,549 --> 00:23:30,200
use the next M beam it's the garbage

00:23:25,820 --> 00:23:32,030
collector and beam and typically people

00:23:30,200 --> 00:23:35,230
think are thinking they have one garbage

00:23:32,030 --> 00:23:38,150
collector in their JVM but in most cases

00:23:35,230 --> 00:23:40,520
it's - it's one garbage collector that

00:23:38,150 --> 00:23:42,830
collects Eden and one garbage collector

00:23:40,520 --> 00:23:45,500
that is responsible for the ten-yard

00:23:42,830 --> 00:23:49,250
space so we might have more than one of

00:23:45,500 --> 00:23:51,200
these m beans and they provide

00:23:49,250 --> 00:23:52,760
information about how many garbage

00:23:51,200 --> 00:23:55,780
collections have been happening since

00:23:52,760 --> 00:24:00,980
startup so you can have again the rate

00:23:55,780 --> 00:24:06,290
the accumulated duration that these

00:24:00,980 --> 00:24:08,390
garbage collections took and when the

00:24:06,290 --> 00:24:11,210
last collection started ended and how

00:24:08,390 --> 00:24:13,280
long the last collection took so if you

00:24:11,210 --> 00:24:15,950
run into memory problems there is some

00:24:13,280 --> 00:24:18,200
data readily available there also there

00:24:15,950 --> 00:24:22,040
are two items memory usage before and

00:24:18,200 --> 00:24:26,000
after GC which I will show on the next

00:24:22,040 --> 00:24:28,990
slide those again have one entry per

00:24:26,000 --> 00:24:32,000
memory region and it shows the same

00:24:28,990 --> 00:24:36,880
quadruple of data that we have that we

00:24:32,000 --> 00:24:36,880
had in the memory pool mbeans

00:24:37,360 --> 00:24:42,230
okay that's the platform M beam so just

00:24:40,460 --> 00:24:47,480
to recall this operating system that's

00:24:42,230 --> 00:24:50,630
about CPU complete total process memory

00:24:47,480 --> 00:24:53,690
file descriptors we have lots of

00:24:50,630 --> 00:24:55,760
ambience about memory and garbage

00:24:53,690 --> 00:24:58,100
collection and we have an M been about

00:24:55,760 --> 00:25:00,500
totals right counts that's these are the

00:24:58,100 --> 00:25:04,100
most important ones let's look inside

00:25:00,500 --> 00:25:06,640
Tomcat inside Tomcat the first time

00:25:04,100 --> 00:25:06,640
being that I

00:25:06,669 --> 00:25:13,669
we'll present is the threat Coulomb beam

00:25:09,260 --> 00:25:17,620
so Tomcat has the notion of connectors

00:25:13,669 --> 00:25:19,789
the connectors use thread pools to serve

00:25:17,620 --> 00:25:22,309
requests that come in over connections

00:25:19,789 --> 00:25:24,440
and of course every time you have a pool

00:25:22,309 --> 00:25:26,360
it's important to control whether the

00:25:24,440 --> 00:25:29,059
sizing is good whether this pool is

00:25:26,360 --> 00:25:31,210
exhausted or whether you could shrink it

00:25:29,059 --> 00:25:34,789
actually or where you would need to

00:25:31,210 --> 00:25:37,130
increase it so the thread pool mbean

00:25:34,789 --> 00:25:39,200
provides the information about the

00:25:37,130 --> 00:25:42,110
current size of the thread pool that's

00:25:39,200 --> 00:25:45,140
just right count and it also provides

00:25:42,110 --> 00:25:50,510
the information how many BC threats are

00:25:45,140 --> 00:25:53,270
in there what is busy depends on the

00:25:50,510 --> 00:25:55,070
connector you're using for the old-style

00:25:53,270 --> 00:25:56,990
blocking i/o connector whenever

00:25:55,070 --> 00:25:59,299
connection is connected to Tomcat it

00:25:56,990 --> 00:26:02,059
blocks one thread and this is then a B

00:25:59,299 --> 00:26:04,610
C's thread for the newer NRO and a PR

00:26:02,059 --> 00:26:08,230
connectors as write is only busy when

00:26:04,610 --> 00:26:10,789
it's actually working on a request the

00:26:08,230 --> 00:26:12,799
quotient between the busy threads and

00:26:10,789 --> 00:26:14,899
the max threads would give you the

00:26:12,799 --> 00:26:17,510
thread pool usage in percent how many

00:26:14,899 --> 00:26:21,500
percent of the thread pool are currently

00:26:17,510 --> 00:26:27,440
busy so it's easy to put a threshold on

00:26:21,500 --> 00:26:31,000
there then we've got a global request

00:26:27,440 --> 00:26:35,419
process or the global request processor

00:26:31,000 --> 00:26:37,610
counts requests for the whole of Tomcat

00:26:35,419 --> 00:26:40,419
so any request itself by Tomcat will be

00:26:37,610 --> 00:26:43,250
counted in the request count it also

00:26:40,419 --> 00:26:44,570
accumulates the processing time so with

00:26:43,250 --> 00:26:47,600
the time it took to handle the request

00:26:44,570 --> 00:26:49,880
will be summed up it shows the maximum

00:26:47,600 --> 00:26:52,580
time and also some data about traffic

00:26:49,880 --> 00:26:54,320
going in and going out the request count

00:26:52,580 --> 00:26:57,470
as a counter is not interesting in

00:26:54,320 --> 00:27:00,440
itself but again deriving a raid over

00:26:57,470 --> 00:27:02,419
time gives you the throughput of your

00:27:00,440 --> 00:27:06,980
application how many requests per second

00:27:02,419 --> 00:27:09,830
are being handled and another thing

00:27:06,980 --> 00:27:13,000
there is an error count but of course

00:27:09,830 --> 00:27:16,580
these are only errors that can be

00:27:13,000 --> 00:27:18,350
noticed by Tomcat this is not like my

00:27:16,580 --> 00:27:20,270
user provided a wrong

00:27:18,350 --> 00:27:23,630
a squad during login that's not an error

00:27:20,270 --> 00:27:26,270
in in the sense of Tomcat so you have to

00:27:23,630 --> 00:27:32,179
be careful to overestimate what the

00:27:26,270 --> 00:27:34,610
meaning of error current actually is the

00:27:32,179 --> 00:27:36,380
processing time it's cumulated as I said

00:27:34,610 --> 00:27:39,280
in milliseconds what can we do with it

00:27:36,380 --> 00:27:41,630
if we take the rate we get the average

00:27:39,280 --> 00:27:49,730
processing time of requests in the last

00:27:41,630 --> 00:27:54,350
sample interval if we sorry no again

00:27:49,730 --> 00:27:56,600
again what do we get if we take the rate

00:27:54,350 --> 00:27:58,909
of the processing time again the game is

00:27:56,600 --> 00:28:01,010
what's the unit it's processing time so

00:27:58,909 --> 00:28:03,679
it's seconds divided by seconds it has

00:28:01,010 --> 00:28:07,970
no unit what does it mean it's the

00:28:03,679 --> 00:28:09,980
average concurrency that was in place

00:28:07,970 --> 00:28:12,620
during the last interval so if the

00:28:09,980 --> 00:28:14,570
result is 10 it would mean on average in

00:28:12,620 --> 00:28:17,750
the last minute 10 requests per process

00:28:14,570 --> 00:28:20,480
in parallel what we could also do we

00:28:17,750 --> 00:28:22,159
could do dividing the Delta of the

00:28:20,480 --> 00:28:24,230
processing time by the Delta of the

00:28:22,159 --> 00:28:26,720
request count and this would give us the

00:28:24,230 --> 00:28:29,120
average response time in the last

00:28:26,720 --> 00:28:32,570
interval so this is something that

00:28:29,120 --> 00:28:34,909
people sometimes derive from excess logs

00:28:32,570 --> 00:28:38,360
or things like this bypassing it but you

00:28:34,909 --> 00:28:40,580
could also really very simply do it by

00:28:38,360 --> 00:28:42,289
retrieving some scalars and doing the

00:28:40,580 --> 00:28:47,179
right mathematical operations of course

00:28:42,289 --> 00:28:48,830
this is global this does not this from

00:28:47,179 --> 00:28:51,830
the XS lock you can you can choose the

00:28:48,830 --> 00:28:54,289
URLs that you actually are interested in

00:28:51,830 --> 00:28:59,600
this is putting all the requests in one

00:28:54,289 --> 00:29:01,730
counter so then there is a request

00:28:59,600 --> 00:29:03,890
process or remember this thing was

00:29:01,730 --> 00:29:05,720
called global request process or the

00:29:03,890 --> 00:29:08,720
next one is a request processor it's a

00:29:05,720 --> 00:29:11,570
totally different beast a request

00:29:08,720 --> 00:29:16,190
process a more or less is available

00:29:11,570 --> 00:29:18,970
let's say once per fret and for

00:29:16,190 --> 00:29:21,350
monitoring purposes it probably it's not

00:29:18,970 --> 00:29:24,049
normal monitoring but it's still

00:29:21,350 --> 00:29:26,270
interesting what it shows is whether

00:29:24,049 --> 00:29:28,800
there is a request currently running and

00:29:26,270 --> 00:29:30,990
since and since how long

00:29:28,800 --> 00:29:32,700
so if you're interested in on-the-fly

00:29:30,990 --> 00:29:35,540
detection whether you are whether you

00:29:32,700 --> 00:29:38,190
have long-running requests you can

00:29:35,540 --> 00:29:40,890
retrieve the request processor data and

00:29:38,190 --> 00:29:43,440
if there is a current URI item there

00:29:40,890 --> 00:29:45,120
then it's working on this URI and the

00:29:43,440 --> 00:29:47,520
request processing time will show you

00:29:45,120 --> 00:29:49,500
since what time in milliseconds so if

00:29:47,520 --> 00:29:51,420
this is a big number you know you've got

00:29:49,500 --> 00:29:56,070
a request in the system that takes a

00:29:51,420 --> 00:29:57,690
long time data source if you configure

00:29:56,070 --> 00:30:00,480
your data source

00:29:57,690 --> 00:30:03,900
so let's write a connection pool for a

00:30:00,480 --> 00:30:06,570
database inside Tomcat then Tomcat also

00:30:03,900 --> 00:30:09,150
provides some monitoring data you can

00:30:06,570 --> 00:30:11,220
see the number of active and idle

00:30:09,150 --> 00:30:13,500
connections and the maximum number that

00:30:11,220 --> 00:30:16,140
you allow so by division you can

00:30:13,500 --> 00:30:17,820
retrieve the percentage how many of the

00:30:16,140 --> 00:30:22,770
possible connections are in use

00:30:17,820 --> 00:30:26,430
guarantee so those are more or less

00:30:22,770 --> 00:30:29,430
global Tomcat specific mbeans the next

00:30:26,430 --> 00:30:33,900
round is mbeans that Tomcat provides per

00:30:29,430 --> 00:30:36,660
web app so more fine-grained the first

00:30:33,900 --> 00:30:40,050
of them is called manager and now please

00:30:36,660 --> 00:30:43,140
don't confuse the manager mbean with the

00:30:40,050 --> 00:30:46,320
manager web application the manager web

00:30:43,140 --> 00:30:49,080
application is the tool with which we

00:30:46,320 --> 00:30:53,430
can use to deploy applications to

00:30:49,080 --> 00:30:56,340
retrieve JMX data to have a look at

00:30:53,430 --> 00:30:59,640
status information the manager in beam

00:30:56,340 --> 00:31:02,390
is something very different it provides

00:30:59,640 --> 00:31:05,100
information about session management and

00:31:02,390 --> 00:31:07,590
since each web application has its own

00:31:05,100 --> 00:31:10,560
session management there is one of those

00:31:07,590 --> 00:31:12,420
pervert a passion so this is a dump of

00:31:10,560 --> 00:31:16,340
the manager and beam for the root

00:31:12,420 --> 00:31:19,350
context and it shows us that we've got

00:31:16,340 --> 00:31:22,770
one two three four sessions but not

00:31:19,350 --> 00:31:27,240
currently active created since Tomcat

00:31:22,770 --> 00:31:29,370
start again by taking the rage we can

00:31:27,240 --> 00:31:31,710
get an idea how many seconds how many

00:31:29,370 --> 00:31:35,040
sessions per second we created your in

00:31:31,710 --> 00:31:37,260
the last minute aha that for instance

00:31:35,040 --> 00:31:40,010
depending on how your application bugs

00:31:37,260 --> 00:31:42,020
could be close to your login rate

00:31:40,010 --> 00:31:44,120
and often logins are relatively

00:31:42,020 --> 00:31:46,640
expensive and there is a problem at the

00:31:44,120 --> 00:31:48,410
morning at night whenever at 9:00 when

00:31:46,640 --> 00:31:50,750
everybody comes in that you get a

00:31:48,410 --> 00:31:53,480
performance problem so you can measure

00:31:50,750 --> 00:31:57,260
how many session creations per time you

00:31:53,480 --> 00:31:59,450
have by doing monitoring the same goes

00:31:57,260 --> 00:32:02,480
for the expired sessions this is the

00:31:59,450 --> 00:32:04,760
session distractions it counts log outs

00:32:02,480 --> 00:32:08,120
as well as exploration by idle by

00:32:04,760 --> 00:32:10,160
idleness both are counted in in only one

00:32:08,120 --> 00:32:12,890
counter and active sessions is the

00:32:10,160 --> 00:32:20,540
number of sessions that are currently in

00:32:12,890 --> 00:32:25,000
use what else do we have

00:32:20,540 --> 00:32:27,260
max active will show us the maximum

00:32:25,000 --> 00:32:30,410
concurrent number of sessions that we

00:32:27,260 --> 00:32:32,450
had since restart obviously a maximum is

00:32:30,410 --> 00:32:34,460
not that interested because if we grow

00:32:32,450 --> 00:32:36,880
and grow and grow and grow and it will

00:32:34,460 --> 00:32:39,530
never shrink but there is a way of

00:32:36,880 --> 00:32:41,480
resetting the maximum so if you're

00:32:39,530 --> 00:32:44,750
interested for instance in daily max

00:32:41,480 --> 00:32:47,300
maximum you can reset it at midnight and

00:32:44,750 --> 00:32:50,300
then always have to the current days

00:32:47,300 --> 00:32:53,660
maximum in there rejected and duplicates

00:32:50,300 --> 00:32:55,430
a rejected session is a session that

00:32:53,660 --> 00:32:58,550
could not be created because you

00:32:55,430 --> 00:33:01,550
configured an upper limit on the allowed

00:32:58,550 --> 00:33:04,880
number of sessions and the session that

00:33:01,550 --> 00:33:06,710
should be created was too much and then

00:33:04,880 --> 00:33:10,250
it will be denied and will be counted in

00:33:06,710 --> 00:33:12,200
rejected sessions the applicants is

00:33:10,250 --> 00:33:14,570
typically always zero it would count

00:33:12,200 --> 00:33:16,730
whether a duplicate session ID would be

00:33:14,570 --> 00:33:21,530
generated it would then not be used the

00:33:16,730 --> 00:33:24,560
dublicate ID but we can recount it okay

00:33:21,530 --> 00:33:27,980
then the manager and bin is the only

00:33:24,560 --> 00:33:31,220
ambient that actually provides some rate

00:33:27,980 --> 00:33:35,450
type statistic itself it has the average

00:33:31,220 --> 00:33:41,860
a lifetime and a maxi lifetime and this

00:33:35,450 --> 00:33:45,770
is done by using the last 100 sessions

00:33:41,860 --> 00:33:48,350
that know I'm wrong that's the next page

00:33:45,770 --> 00:33:50,090
sorry sorry session average your

00:33:48,350 --> 00:33:52,160
lifetime and maximum a lifetime our

00:33:50,090 --> 00:33:53,149
statistics over the whole lifetime of

00:33:52,160 --> 00:33:56,629
the

00:33:53,149 --> 00:33:58,429
Tomcat process processing time doesn't

00:33:56,629 --> 00:34:00,649
have to do with request processing time

00:33:58,429 --> 00:34:03,229
until now whenever is a processing time

00:34:00,649 --> 00:34:05,389
it was accumulated time of how long did

00:34:03,229 --> 00:34:07,339
it take to handle requests processing

00:34:05,389 --> 00:34:11,119
time for the manager is how long did it

00:34:07,339 --> 00:34:13,879
took the manager to clear up idle

00:34:11,119 --> 00:34:16,819
sessions usually this is not interesting

00:34:13,879 --> 00:34:19,129
in a small number except when you

00:34:16,819 --> 00:34:22,159
register HTTP session listeners they do

00:34:19,129 --> 00:34:23,510
something complex for instance you need

00:34:22,159 --> 00:34:25,549
to log out from a back-end system

00:34:23,510 --> 00:34:28,609
whenever a session goes away in your web

00:34:25,549 --> 00:34:30,829
application so finally you're doing a

00:34:28,609 --> 00:34:32,569
remote call and this could could be a

00:34:30,829 --> 00:34:35,059
performance problem if you want to track

00:34:32,569 --> 00:34:36,859
how long session exploration takes you

00:34:35,059 --> 00:34:41,510
can use them processing time of the

00:34:36,859 --> 00:34:44,569
manager app manager Amin okay so these

00:34:41,510 --> 00:34:46,520
is the last two are rates that are

00:34:44,569 --> 00:34:49,190
provided by this M being the create and

00:34:46,520 --> 00:34:51,889
the expire rate I usually take it from

00:34:49,190 --> 00:34:54,409
the create and expire counters by doing

00:34:51,889 --> 00:34:57,619
the rates myself if you are not able to

00:34:54,409 --> 00:35:00,619
do that some rates are provided here as

00:34:57,619 --> 00:35:01,880
a built-in feature and they are taken

00:35:00,619 --> 00:35:06,140
from the last one hundred sessions

00:35:01,880 --> 00:35:08,569
created or expired okay neck think neck

00:35:06,140 --> 00:35:11,480
thing servlets so inside a web app we've

00:35:08,569 --> 00:35:15,319
got servlets for each servlet there is

00:35:11,480 --> 00:35:17,750
an M beam and the servlet name is a part

00:35:15,319 --> 00:35:20,359
of the object name of the M beam we can

00:35:17,750 --> 00:35:22,960
see here I took the gem X proxy servlet

00:35:20,359 --> 00:35:25,520
and looked at its own statistics and

00:35:22,960 --> 00:35:27,349
again we can see the request count how

00:35:25,520 --> 00:35:28,880
often was it called we can see the

00:35:27,349 --> 00:35:30,980
accumulated processing time in

00:35:28,880 --> 00:35:33,920
milliseconds from which we can again

00:35:30,980 --> 00:35:36,020
derive the average processing time in

00:35:33,920 --> 00:35:42,589
the last interval the concurrency and so

00:35:36,020 --> 00:35:44,450
on some servlets are notable there is

00:35:42,589 --> 00:35:46,760
always the default servlet it delivers

00:35:44,450 --> 00:35:48,970
static content so also the static

00:35:46,760 --> 00:35:51,349
content activity can be measured by

00:35:48,970 --> 00:35:53,720
simply monitoring the default servlet

00:35:51,349 --> 00:35:55,940
there is another servlet that's called

00:35:53,720 --> 00:35:59,059
JSP servlet that's available for

00:35:55,940 --> 00:36:01,779
delivering jsps so also J's P activity

00:35:59,059 --> 00:36:01,779
can be measured

00:36:02,400 --> 00:36:09,690
then there are a few more numbers about

00:36:05,400 --> 00:36:12,210
jsps we have counters about loaded and

00:36:09,690 --> 00:36:13,380
unloaded and reloaded JSP so if you're

00:36:12,210 --> 00:36:16,890
having on jsps

00:36:13,380 --> 00:36:18,660
and need to track those numbers or if

00:36:16,890 --> 00:36:21,510
you know you run into a problem once a

00:36:18,660 --> 00:36:26,190
certain number of jsps have been reached

00:36:21,510 --> 00:36:28,440
you can monitor this since sometime

00:36:26,190 --> 00:36:31,079
I think Tomcat 7 I think we didn't have

00:36:28,440 --> 00:36:34,770
it in 6 I'm not sure there is a feature

00:36:31,079 --> 00:36:36,930
to unload Jay's piece that haven't been

00:36:34,770 --> 00:36:40,380
used for a long time in case of a

00:36:36,930 --> 00:36:46,529
certain limit of loaded chess pieces

00:36:40,380 --> 00:36:48,900
reached finally there is a 1m beam 4 per

00:36:46,529 --> 00:36:51,960
web app so not per servlet per web app

00:36:48,900 --> 00:36:54,270
again and this only provides the

00:36:51,960 --> 00:36:56,220
processing time and that's a bit strange

00:36:54,270 --> 00:36:58,140
why doesn't it provide a request count

00:36:56,220 --> 00:37:00,690
the next time the mean time and so on

00:36:58,140 --> 00:37:04,609
it's just no mission and since I know

00:37:00,690 --> 00:37:09,140
that is that this is missing last night

00:37:04,609 --> 00:37:11,940
during rich talk I edit the other items

00:37:09,140 --> 00:37:13,670
so the next Tomcat 7 release will also

00:37:11,940 --> 00:37:18,869
have requests count max time mean time

00:37:13,670 --> 00:37:21,859
per web app ok that's a long list but

00:37:18,869 --> 00:37:24,510
basically basically we can track

00:37:21,859 --> 00:37:26,430
activity request counts we can track

00:37:24,510 --> 00:37:28,740
response times we can track sessions

00:37:26,430 --> 00:37:31,890
session creation sessions destruction

00:37:28,740 --> 00:37:36,089
we can track thread pool size that's

00:37:31,890 --> 00:37:41,599
used so that's all of the infrastructure

00:37:36,089 --> 00:37:45,079
that Tomcat itself provides so let's go

00:37:41,599 --> 00:37:47,430
to the web server totally different

00:37:45,079 --> 00:37:49,380
technological world in the sense of

00:37:47,430 --> 00:37:51,930
implementation language but obviously

00:37:49,380 --> 00:37:55,650
it's all about again it's all about HTTP

00:37:51,930 --> 00:37:57,150
requests response time so from the point

00:37:55,650 --> 00:38:01,770
of view of metrics there should be some

00:37:57,150 --> 00:38:06,660
similarities so first question is how do

00:38:01,770 --> 00:38:09,599
we retrieve data and in the tomcat case

00:38:06,660 --> 00:38:12,010
it was clear that we would use to MX the

00:38:09,599 --> 00:38:15,100
question is what you use in

00:38:12,010 --> 00:38:19,060
GDP and one easy way of retrieving data

00:38:15,100 --> 00:38:21,280
is using the server status module and

00:38:19,060 --> 00:38:25,060
rich in the previous talk already showed

00:38:21,280 --> 00:38:27,100
a couple of screenshots that are close

00:38:25,060 --> 00:38:29,710
to what I will be showing but I will go

00:38:27,100 --> 00:38:31,300
more into detail about the data so to

00:38:29,710 --> 00:38:33,850
provide the statue's module that's

00:38:31,300 --> 00:38:36,390
usually always installed with the Apache

00:38:33,850 --> 00:38:39,840
you have to load it and you have to

00:38:36,390 --> 00:38:42,040
provide some URI some location section

00:38:39,840 --> 00:38:44,140
where you set the handler to server

00:38:42,040 --> 00:38:45,640
status which your eye you're choosing

00:38:44,140 --> 00:38:48,460
it's totally up to you it doesn't have

00:38:45,640 --> 00:38:50,550
to be slash server - stretches but

00:38:48,460 --> 00:38:55,120
please make sure that you provide an

00:38:50,550 --> 00:38:59,110
appropriate access control in case data

00:38:55,120 --> 00:39:01,060
that's shown there is not supposed to be

00:38:59,110 --> 00:39:04,270
properly public you will see in a minute

00:39:01,060 --> 00:39:06,670
the kind of data that's there there's

00:39:04,270 --> 00:39:08,680
also another way you could write a

00:39:06,670 --> 00:39:12,160
program that connects to the shared

00:39:08,680 --> 00:39:16,390
memory that's actually used for the data

00:39:12,160 --> 00:39:18,970
that the mod status shows but I will not

00:39:16,390 --> 00:39:21,430
go into deaths for this so the simple

00:39:18,970 --> 00:39:25,240
way is activating the status module and

00:39:21,430 --> 00:39:29,470
retrieving data over HTTP okay so here's

00:39:25,240 --> 00:39:31,630
an example and this is now from the time

00:39:29,470 --> 00:39:36,360
after we did the upgrade and actually

00:39:31,630 --> 00:39:39,550
it's from something like yesterday

00:39:36,360 --> 00:39:43,770
running the latest version of the web

00:39:39,550 --> 00:39:46,900
server this page is rendered in HTML so

00:39:43,770 --> 00:39:49,930
unfortunately one would need to pass the

00:39:46,900 --> 00:39:51,970
data out of the page the data that shown

00:39:49,930 --> 00:39:55,180
is interesting I will go into details

00:39:51,970 --> 00:39:59,790
soon and this view has the most complete

00:39:55,180 --> 00:39:59,790
data but there are other views available

00:39:59,850 --> 00:40:06,300
if we add a query parameter question

00:40:03,220 --> 00:40:09,970
mark Auto then we get a textual view and

00:40:06,300 --> 00:40:11,980
most of the data that's interesting in

00:40:09,970 --> 00:40:14,440
the HTML view is also in the auto view

00:40:11,980 --> 00:40:16,420
probably we should complete it if there

00:40:14,440 --> 00:40:19,270
is something interesting missing

00:40:16,420 --> 00:40:22,000
obviously this auto view is much more

00:40:19,270 --> 00:40:24,570
easier to pass there is no HTML text and

00:40:22,000 --> 00:40:28,230
so on so it's trivial

00:40:24,570 --> 00:40:33,600
to monitor to pass the data out and put

00:40:28,230 --> 00:40:36,960
them into your monitoring system then

00:40:33,600 --> 00:40:39,300
below this part with the numbers there

00:40:36,960 --> 00:40:41,760
is a table tabular view that this

00:40:39,300 --> 00:40:44,550
tabular view would show us what's

00:40:41,760 --> 00:40:47,250
happening on each threat of the opechee

00:40:44,550 --> 00:40:49,770
and typically that's not especially

00:40:47,250 --> 00:40:51,960
interesting for monitoring it could be

00:40:49,770 --> 00:40:54,450
interesting if you're overloaded and you

00:40:51,960 --> 00:40:56,100
wonder which URLs it might be from which

00:40:54,450 --> 00:40:58,710
appears the data comes from but this

00:40:56,100 --> 00:41:00,660
goes more into a more detailed analysis

00:40:58,710 --> 00:41:03,480
of the problem and not collecting

00:41:00,660 --> 00:41:05,940
metrical data that's that has an easy

00:41:03,480 --> 00:41:07,530
structure so the table is there but you

00:41:05,940 --> 00:41:12,380
don't have to pass the table to get

00:41:07,530 --> 00:41:12,380
anything for your regular monitoring

00:41:12,650 --> 00:41:19,800
there is a variant if you add the

00:41:17,400 --> 00:41:24,420
question mark no table then this table

00:41:19,800 --> 00:41:27,000
will be not shown as an HTML table it

00:41:24,420 --> 00:41:29,400
will be that the columns will be given

00:41:27,000 --> 00:41:31,860
by appropriate separators so again it's

00:41:29,400 --> 00:41:35,180
easier to pass but as I said typically

00:41:31,860 --> 00:41:38,100
you don't need it for monitoring so

00:41:35,180 --> 00:41:40,380
actually what part of this information

00:41:38,100 --> 00:41:42,660
is interesting let's start from the

00:41:40,380 --> 00:41:45,270
beginning first of all on the top we've

00:41:42,660 --> 00:41:47,160
got the restart time or the same

00:41:45,270 --> 00:41:50,100
information given in another form the

00:41:47,160 --> 00:41:54,390
server uptime note that graceful

00:41:50,100 --> 00:41:56,820
restarts do not count as restarts then

00:41:54,390 --> 00:41:58,890
the next line gives us the server load

00:41:56,820 --> 00:42:03,060
that's a very recent feature that's only

00:41:58,890 --> 00:42:04,830
available in 244 and it's the same kind

00:42:03,060 --> 00:42:06,690
of data that you would get when running

00:42:04,830 --> 00:42:09,270
the uptime command on the system itself

00:42:06,690 --> 00:42:11,390
it's the normal load command at the run

00:42:09,270 --> 00:42:17,190
queue length into three different

00:42:11,390 --> 00:42:19,260
average intervals then the next thing is

00:42:17,190 --> 00:42:21,090
the total excesses so in the tomcat

00:42:19,260 --> 00:42:23,520
world we would have named it request

00:42:21,090 --> 00:42:25,200
counter or request count here it's total

00:42:23,520 --> 00:42:28,380
excesses it's the number of requests

00:42:25,200 --> 00:42:30,510
handled and we have the total traffic so

00:42:28,380 --> 00:42:32,369
to make something interesting out of it

00:42:30,510 --> 00:42:34,259
we would take the rate

00:42:32,369 --> 00:42:36,240
both so we would get the number of

00:42:34,259 --> 00:42:39,660
requests per second handled in the last

00:42:36,240 --> 00:42:42,420
measurement interval last minute and the

00:42:39,660 --> 00:42:45,990
byte bandwidths are used for the traffic

00:42:42,420 --> 00:42:50,249
if we take the quotient of the del-tones

00:42:45,990 --> 00:42:52,740
we get the average response size during

00:42:50,249 --> 00:42:54,809
the last interval so are we solving big

00:42:52,740 --> 00:43:01,859
content on average currently or are we

00:42:54,809 --> 00:43:04,289
solving small content next thing it

00:43:01,859 --> 00:43:06,210
tells us how many requests are currently

00:43:04,289 --> 00:43:09,210
being process and how many idle worker

00:43:06,210 --> 00:43:10,950
threads workers are available this is

00:43:09,210 --> 00:43:14,249
very similar to the thread pool and

00:43:10,950 --> 00:43:17,130
being in Tomcat the number of threats

00:43:14,249 --> 00:43:21,289
made available for handling requests is

00:43:17,130 --> 00:43:25,259
the most important tuning item so

00:43:21,289 --> 00:43:27,809
measuring how how many of the threads

00:43:25,259 --> 00:43:30,690
are in use is important to find out

00:43:27,809 --> 00:43:32,460
whether you actually have oversized your

00:43:30,690 --> 00:43:36,589
server or whether you might need to

00:43:32,460 --> 00:43:36,589
provide more threats every now and then

00:43:38,150 --> 00:43:44,130
then there is additional data that in my

00:43:41,460 --> 00:43:48,749
opinion is not that useful the CPU usage

00:43:44,130 --> 00:43:50,789
CPU usage is a bit hard because apache

00:43:48,749 --> 00:43:54,869
uses several processes so what does it

00:43:50,789 --> 00:43:58,470
mean that does the statue's module

00:43:54,869 --> 00:44:01,650
provides CPU data if you look there you

00:43:58,470 --> 00:44:03,239
can see there is a U and s that's the

00:44:01,650 --> 00:44:05,579
user and the system time and then there

00:44:03,239 --> 00:44:08,999
is a Cu and the Sears Cu means child

00:44:05,579 --> 00:44:11,940
user and child system and for instance

00:44:08,999 --> 00:44:16,200
the Linux operating system has a

00:44:11,940 --> 00:44:20,190
facility that if a child stops normally

00:44:16,200 --> 00:44:22,980
then it's CPU time user and system CPU

00:44:20,190 --> 00:44:25,739
time is carried over is added to a child

00:44:22,980 --> 00:44:29,369
sorry child user and system CPU time

00:44:25,739 --> 00:44:31,230
field in the parent process that means

00:44:29,369 --> 00:44:35,400
the parent can kind of track the

00:44:31,230 --> 00:44:38,279
cumulated CPU time but only for the

00:44:35,400 --> 00:44:40,460
children that have already stopped not

00:44:38,279 --> 00:44:43,109
for the children that are still running

00:44:40,460 --> 00:44:45,779
yeah and that makes the numbers

00:44:43,109 --> 00:44:47,700
problematic I usually don't get much out

00:44:45,779 --> 00:44:51,160
of

00:44:47,700 --> 00:44:52,960
also the requests per second megabytes

00:44:51,160 --> 00:44:54,910
per second kilobytes per request these

00:44:52,960 --> 00:44:57,760
are longtime statistics since the last

00:44:54,910 --> 00:44:59,200
restart so better use the counters and

00:44:57,760 --> 00:45:01,510
retrieve the numbers for the last

00:44:59,200 --> 00:45:04,150
interval yourself and don't use the long

00:45:01,510 --> 00:45:06,610
time statistics that kind of stabilized

00:45:04,150 --> 00:45:08,620
and even if something happens the

00:45:06,610 --> 00:45:12,670
numbers won't change anymore because of

00:45:08,620 --> 00:45:17,590
statistical reasons okay

00:45:12,670 --> 00:45:19,690
then there is this line with or multiple

00:45:17,590 --> 00:45:22,390
lines with both characters what do they

00:45:19,690 --> 00:45:26,140
mean the characters indicate what our

00:45:22,390 --> 00:45:28,840
and threats are actually doing until now

00:45:26,140 --> 00:45:32,560
we only had total number of busy worker

00:45:28,840 --> 00:45:35,050
threats but what are they doing and by

00:45:32,560 --> 00:45:37,240
counting the characters you can get an

00:45:35,050 --> 00:45:40,710
idea and the most important characters

00:45:37,240 --> 00:45:43,330
are W R K the underscore and the dot and

00:45:40,710 --> 00:45:46,210
don't try to remember what it is the

00:45:43,330 --> 00:45:48,820
seller stretches page contains a list an

00:45:46,210 --> 00:45:52,480
explanation of the keys and I pasted it

00:45:48,820 --> 00:45:54,940
here so our means reading the request so

00:45:52,480 --> 00:45:59,290
the Apache web server has not yet fully

00:45:54,940 --> 00:46:01,630
read the request it's still in the phase

00:45:59,290 --> 00:46:05,250
of reading the request in W means

00:46:01,630 --> 00:46:08,860
working or work working on the request

00:46:05,250 --> 00:46:11,140
that could be the proxy waits for a

00:46:08,860 --> 00:46:13,300
back-end to answer that could be we

00:46:11,140 --> 00:46:15,700
serve a big content and we have a slow

00:46:13,300 --> 00:46:18,540
line to the to the user and it just

00:46:15,700 --> 00:46:22,270
takes a longer time to serve the content

00:46:18,540 --> 00:46:25,600
the K as rich already explained is to

00:46:22,270 --> 00:46:28,720
keep alive statues and the underscore is

00:46:25,600 --> 00:46:31,450
an idle slot the dot means there could

00:46:28,720 --> 00:46:35,280
be a process running that would take up

00:46:31,450 --> 00:46:35,280
these slots but there is none currently

00:46:35,460 --> 00:46:41,170
as rich already explained K was very

00:46:38,590 --> 00:46:43,330
frequently before we had sorry before we

00:46:41,170 --> 00:46:47,820
had the event MPM

00:46:43,330 --> 00:46:51,040
now the K is gone mostly and we can see

00:46:47,820 --> 00:46:52,750
where it went to

00:46:51,040 --> 00:46:55,750
when using the event in p.m. there is

00:46:52,750 --> 00:46:58,630
another table in the same page and this

00:46:55,750 --> 00:47:00,630
table gives us some insight what's

00:46:58,630 --> 00:47:03,460
happening apart from the work of threads

00:47:00,630 --> 00:47:07,030
so the work of threads is the precious

00:47:03,460 --> 00:47:08,680
resource but there is also a lot of

00:47:07,030 --> 00:47:11,410
stuff happening apart from the worker

00:47:08,680 --> 00:47:13,180
threads namely the keepalive connections

00:47:11,410 --> 00:47:17,050
where we are just waiting for data to

00:47:13,180 --> 00:47:18,460
arrive but we are just pulling the

00:47:17,050 --> 00:47:21,520
connections whether there is some data

00:47:18,460 --> 00:47:23,890
or not it could be we want to close a

00:47:21,520 --> 00:47:27,670
connection and need to drain remaining

00:47:23,890 --> 00:47:30,040
data so we wait some time so again is

00:47:27,670 --> 00:47:32,080
this mostly an idle situation although

00:47:30,040 --> 00:47:34,600
there is a connection related it could

00:47:32,080 --> 00:47:37,120
be write completion we are serving

00:47:34,600 --> 00:47:40,150
static content we already read it from

00:47:37,120 --> 00:47:42,490
disk but the client doesn't doesn't take

00:47:40,150 --> 00:47:44,980
it very quickly so we have to block

00:47:42,490 --> 00:47:48,490
every now and then before we can send

00:47:44,980 --> 00:47:50,200
the next chunk all these situations are

00:47:48,490 --> 00:47:53,190
now no longer handled with the worker

00:47:50,200 --> 00:47:56,470
threads but in an asynchronous way and

00:47:53,190 --> 00:47:59,080
to read the little table all the rows

00:47:56,470 --> 00:48:04,930
that start with a with a process number

00:47:59,080 --> 00:48:07,150
process ID are per process statistics

00:48:04,930 --> 00:48:09,640
and finally in the last row we have to

00:48:07,150 --> 00:48:12,040
sum typically for the monitoring we are

00:48:09,640 --> 00:48:13,870
only interested in to sum only once once

00:48:12,040 --> 00:48:16,180
we have a real problem need to analyze

00:48:13,870 --> 00:48:18,490
then we might look into the details but

00:48:16,180 --> 00:48:21,400
let's look at the sum and what are the

00:48:18,490 --> 00:48:23,500
columns the first column tells us just

00:48:21,400 --> 00:48:26,470
how many connections overall we are

00:48:23,500 --> 00:48:28,480
currently holding in the webserver the

00:48:26,470 --> 00:48:30,310
second tells us something about the

00:48:28,480 --> 00:48:33,280
worker threads namely how many are busy

00:48:30,310 --> 00:48:35,200
and how many are idle the third column

00:48:33,280 --> 00:48:37,180
tells us something about the connections

00:48:35,200 --> 00:48:38,710
that they are they are not blocking a

00:48:37,180 --> 00:48:40,660
workers right there in some other

00:48:38,710 --> 00:48:42,910
situation that we can handle much more

00:48:40,660 --> 00:48:44,890
efficiently and there we have the right

00:48:42,910 --> 00:48:48,430
completion keep alive and the closing

00:48:44,890 --> 00:48:50,920
state and how do those sum up typically

00:48:48,430 --> 00:48:52,780
you would have the busy ones plus the

00:48:50,920 --> 00:48:55,559
right completion plus to keep alive plus

00:48:52,780 --> 00:48:57,089
the closing State is the same number

00:48:55,559 --> 00:48:58,619
the total number of connections each

00:48:57,089 --> 00:49:03,119
connection should be in one of those

00:48:58,619 --> 00:49:06,239
states okay

00:49:03,119 --> 00:49:09,449
I would suggest to monitor the threats

00:49:06,239 --> 00:49:13,339
and the async data the other data I

00:49:09,449 --> 00:49:13,339
think is for monitoring not important

00:49:13,369 --> 00:49:20,999
okay that's the end of the talk so we've

00:49:18,749 --> 00:49:23,579
got some time for discussion ah

00:49:20,999 --> 00:49:29,579
I also brought with me some pictures we

00:49:23,579 --> 00:49:31,769
can look at but probably I'd like first

00:49:29,579 --> 00:49:34,140
to check whether we've got questions and

00:49:31,769 --> 00:49:36,150
if we don't have any questions we can

00:49:34,140 --> 00:49:43,670
look at a couple of pictures of

00:49:36,150 --> 00:49:43,670
monitoring data okay so questions

00:49:49,140 --> 00:49:55,070
and I know as a tomcat developer you're

00:49:52,080 --> 00:49:59,070
probably biased but uh what do you

00:49:55,070 --> 00:50:05,250
typically use to monitor Tomcat as an

00:49:59,070 --> 00:50:09,180
interface yeah okay I'm not an

00:50:05,250 --> 00:50:11,310
Operations guy I do consulting so

00:50:09,180 --> 00:50:14,250
typically I do troubleshooting in this

00:50:11,310 --> 00:50:16,320
situation I need to quickly build up

00:50:14,250 --> 00:50:19,410
something that's not meant for a long to

00:50:16,320 --> 00:50:22,020
run for a long time so I cannot come

00:50:19,410 --> 00:50:23,580
with my own big monitoring license

00:50:22,020 --> 00:50:25,110
whatever solution it takes a month

00:50:23,580 --> 00:50:26,430
before it starts running and then we

00:50:25,110 --> 00:50:30,260
have some data and can start analyzing

00:50:26,430 --> 00:50:34,200
so yeah I'm using the manager I'm using

00:50:30,260 --> 00:50:38,190
server status for Apache and then a

00:50:34,200 --> 00:50:41,580
couple of scripts that do HTTP calls

00:50:38,190 --> 00:50:45,120
pass data out write them in CSV files

00:50:41,580 --> 00:50:47,810
and run visualization on them but it's

00:50:45,120 --> 00:50:49,710
it's I'm not especially good in

00:50:47,810 --> 00:50:52,170
suggesting the latest and greatest

00:50:49,710 --> 00:50:54,270
monitoring framework I know a lot about

00:50:52,170 --> 00:50:59,630
the data and what what what they are

00:50:54,270 --> 00:51:04,830
useful for but not about the frameworks

00:50:59,630 --> 00:51:06,690
egor we use Nagios to to monitor using

00:51:04,830 --> 00:51:07,890
the similar setup to how he described

00:51:06,690 --> 00:51:11,610
you didn't sort of put all the pieces

00:51:07,890 --> 00:51:14,460
together but in the tomcat wiki there's

00:51:11,610 --> 00:51:16,710
a perl script that you can use to hey

00:51:14,460 --> 00:51:19,530
there's a perl script you can use to hit

00:51:16,710 --> 00:51:21,090
the JMX proxy it will mutate the

00:51:19,530 --> 00:51:22,650
response into something it's acceptable

00:51:21,090 --> 00:51:24,360
for nagios and we use that all the time

00:51:22,650 --> 00:51:26,790
to sample a bunch of different things

00:51:24,360 --> 00:51:29,190
from any number of JVMs that we have

00:51:26,790 --> 00:51:32,100
running but but it's really important

00:51:29,190 --> 00:51:35,850
that you set proxy because the the very

00:51:32,100 --> 00:51:38,040
basic simple negatives recipes and they

00:51:35,850 --> 00:51:40,860
have this check gem X script script and

00:51:38,040 --> 00:51:43,320
and this is problematic for performance

00:51:40,860 --> 00:51:46,170
reason as I said if you're using gem X

00:51:43,320 --> 00:51:48,240
to connect then don't start a gem X

00:51:46,170 --> 00:51:55,140
client for each pas literation you're

00:51:48,240 --> 00:51:57,150
doing yeah we usually use Jolokia in our

00:51:55,140 --> 00:52:00,750
environments which is quite neat you can

00:51:57,150 --> 00:52:05,010
deploy it in most I haven't had much

00:52:00,750 --> 00:52:08,430
trouble yet in most containers and then

00:52:05,010 --> 00:52:11,930
again with nigel's its own framework it

00:52:08,430 --> 00:52:15,120
also has a shell so you can look at the

00:52:11,930 --> 00:52:17,640
as you've been explaining going through

00:52:15,120 --> 00:52:20,940
the Tomcat mbeans I've been following on

00:52:17,640 --> 00:52:24,600
my own local installation with Tomcat

00:52:20,940 --> 00:52:26,580
from trunk and looking at the at the

00:52:24,600 --> 00:52:29,310
single ambience which is quite nice so

00:52:26,580 --> 00:52:31,050
if you want to explore this is a this is

00:52:29,310 --> 00:52:34,320
a very nice interface I very much

00:52:31,050 --> 00:52:37,680
recommend it I was actually just curious

00:52:34,320 --> 00:52:39,090
with you or other people would have but

00:52:37,680 --> 00:52:41,610
yeah this is this is my personal

00:52:39,090 --> 00:52:45,120
recommendation so hello hello kia as it

00:52:41,610 --> 00:52:47,520
is pronounced it's a chilli is is very

00:52:45,120 --> 00:52:50,250
very very nice and very light so you can

00:52:47,520 --> 00:52:54,830
we just deployed it in every tomcat

00:52:50,250 --> 00:52:57,810
instance and we yeah use it everywhere

00:52:54,830 --> 00:53:03,590
the URL is on on the slides because i

00:52:57,810 --> 00:53:09,650
mention it also no more questions

00:53:03,590 --> 00:53:09,650
no so let's take probably a few minutes

00:53:09,860 --> 00:53:17,030
for some pictures let's see

00:53:23,960 --> 00:53:33,700
I need to find the right window so

00:53:26,839 --> 00:53:33,700
probably here okay

00:53:33,849 --> 00:53:41,480
this is I mean this is nothing very

00:53:37,910 --> 00:53:44,030
astonishing I'm just showing some real

00:53:41,480 --> 00:53:47,300
pictures taken from the monitoring data

00:53:44,030 --> 00:53:49,339
that I suggested those pictures might

00:53:47,300 --> 00:53:53,300
not look like what you expect most

00:53:49,339 --> 00:53:57,380
people use rrd to store the data and to

00:53:53,300 --> 00:53:59,660
produce pictures actually I must say

00:53:57,380 --> 00:54:05,480
personally I'm not a big fan of our Rd

00:53:59,660 --> 00:54:11,080
because our Rd disturbs data Rd only

00:54:05,480 --> 00:54:11,080
works if data comes in in perfect

00:54:11,349 --> 00:54:16,550
distances and what it does is if your

00:54:14,900 --> 00:54:18,830
data comes in a few seconds early you're

00:54:16,550 --> 00:54:22,810
late it interpolates the data it doesn't

00:54:18,830 --> 00:54:25,099
write the data that you gave to Rd it

00:54:22,810 --> 00:54:27,080
interpolates the data to the point in

00:54:25,099 --> 00:54:29,210
time where it expected the data to

00:54:27,080 --> 00:54:31,580
arrive and this interpolated data will

00:54:29,210 --> 00:54:33,650
be used to produce the pictures and this

00:54:31,580 --> 00:54:36,830
is something I do not really like

00:54:33,650 --> 00:54:40,730
because if your metrics change a lot

00:54:36,830 --> 00:54:44,630
over time then this can introduce bigger

00:54:40,730 --> 00:54:48,080
rows so this is just done for instance

00:54:44,630 --> 00:54:49,700
by using new plot and it's a couple of

00:54:48,080 --> 00:54:53,390
pictures the first picture on the Left

00:54:49,700 --> 00:54:59,390
that's from the operating system mbean

00:54:53,390 --> 00:55:05,900
it's the CPU load I see it's not all why

00:54:59,390 --> 00:55:08,800
isn't it all on let's see whether we can

00:55:05,900 --> 00:55:08,800
improve the situation

00:55:15,000 --> 00:55:17,720
okay

00:55:24,369 --> 00:55:32,099
okay those pictures are taking during

00:55:28,469 --> 00:55:37,269
will provide weather based on data

00:55:32,099 --> 00:55:41,339
monitor during stress testing and the

00:55:37,269 --> 00:55:46,059
left is the CPU load it was a four node

00:55:41,339 --> 00:55:47,650
farm and to the right with the yellow

00:55:46,059 --> 00:55:50,140
color that goes to the right

00:55:47,650 --> 00:55:51,579
it's the sum over the whole farm so if

00:55:50,140 --> 00:55:53,079
you've got a farm then the question is

00:55:51,579 --> 00:55:54,670
always are you only looking at the

00:55:53,079 --> 00:55:58,749
individual nodes are you looking at

00:55:54,670 --> 00:56:01,299
Maxima at sums averages and so on so we

00:55:58,749 --> 00:56:03,690
can see that we have a pretty steady CPU

00:56:01,299 --> 00:56:09,640
load the right picture to the right

00:56:03,690 --> 00:56:11,380
that's the the system load and the

00:56:09,640 --> 00:56:13,989
system load would also show whether

00:56:11,380 --> 00:56:15,400
there is some other activity on the

00:56:13,989 --> 00:56:18,690
system that's not coming from our

00:56:15,400 --> 00:56:21,700
process but there are no no special

00:56:18,690 --> 00:56:24,519
peaks here so it's pretty much only

00:56:21,700 --> 00:56:27,549
irises our process running there free

00:56:24,519 --> 00:56:29,499
physical memory this looks a bit strange

00:56:27,549 --> 00:56:31,359
looks like a league and then it gives

00:56:29,499 --> 00:56:33,910
back memory but if you know how

00:56:31,359 --> 00:56:36,309
operating systems use memory typically

00:56:33,910 --> 00:56:38,079
they should not have free memory they

00:56:36,309 --> 00:56:40,989
should use it for file system caching

00:56:38,079 --> 00:56:42,999
for whatever they think they can they

00:56:40,989 --> 00:56:44,529
can make use of the memory but if a

00:56:42,999 --> 00:56:46,239
process needs the memory then they

00:56:44,529 --> 00:56:48,219
should free the filesystem caches or

00:56:46,239 --> 00:56:50,529
whatever they use the memory and give it

00:56:48,219 --> 00:56:54,579
to the process so free physical memory

00:56:50,529 --> 00:56:57,969
is expected to go up and down and to be

00:56:54,579 --> 00:57:02,440
not that high it's only problematic if

00:56:57,969 --> 00:57:05,259
it gets really low and remember this is

00:57:02,440 --> 00:57:07,059
all taken from the JVM mbeans this is

00:57:05,259 --> 00:57:11,529
not taken from any operating system

00:57:07,059 --> 00:57:14,710
based measurement file descriptors so we

00:57:11,529 --> 00:57:17,979
can see that this application had about

00:57:14,710 --> 00:57:22,089
500 and file descriptors open per per

00:57:17,979 --> 00:57:27,809
note there is some variation especially

00:57:22,089 --> 00:57:27,809
in in the part at the end of the run

00:57:28,739 --> 00:57:33,579
garbage collection the more interesting

00:57:31,239 --> 00:57:34,839
picture probably is that one this is the

00:57:33,579 --> 00:57:36,440
garbage collection of the young

00:57:34,839 --> 00:57:40,040
generation

00:57:36,440 --> 00:57:43,580
the one that collects Eden on the left

00:57:40,040 --> 00:57:46,280
hand side we can see which percentage of

00:57:43,580 --> 00:57:49,460
time this garbage collection takes so

00:57:46,280 --> 00:57:51,350
it's about 2.5 or 3% of the time is

00:57:49,460 --> 00:57:56,450
taken by this garbage collection which

00:57:51,350 --> 00:57:58,880
is okay in this special situation on the

00:57:56,450 --> 00:58:02,810
right side we can see how many garbage

00:57:58,880 --> 00:58:05,180
collections per second

00:58:02,810 --> 00:58:06,830
we actually have garbage collections per

00:58:05,180 --> 00:58:10,220
second we shouldn't have many per second

00:58:06,830 --> 00:58:15,020
and actually the metric the scale is

00:58:10,220 --> 00:58:17,150
most dots live on 0.25 so this means we

00:58:15,020 --> 00:58:20,390
have about every 4 seconds a garbage

00:58:17,150 --> 00:58:22,910
collection yeah and if if we look at the

00:58:20,390 --> 00:58:24,890
upper and lower numbers we had between

00:58:22,910 --> 00:58:27,260
every 3 and 5 seconds a garbage

00:58:24,890 --> 00:58:28,880
collection which is not I mean in the

00:58:27,260 --> 00:58:30,950
young space which is not too bad because

00:58:28,880 --> 00:58:32,810
the typical web application a request

00:58:30,950 --> 00:58:35,030
should run half a second a second two

00:58:32,810 --> 00:58:37,670
seconds so all of the request objects

00:58:35,030 --> 00:58:40,520
are most of the request objects are

00:58:37,670 --> 00:58:45,440
typically collectible after a couple of

00:58:40,520 --> 00:58:49,940
seconds so then we have some threat

00:58:45,440 --> 00:58:52,060
numbers here class loading as I said not

00:58:49,940 --> 00:58:55,010
very interesting pretty stable

00:58:52,060 --> 00:58:56,810
compilation time mostly zero because

00:58:55,010 --> 00:59:00,920
after some stabilization there is not

00:58:56,810 --> 00:59:03,710
much compilation going on so only the

00:59:00,920 --> 00:59:05,960
upper images provide interesting data

00:59:03,710 --> 00:59:09,500
these were the platform and beans then

00:59:05,960 --> 00:59:13,070
we have the Tomcat ambience this is Fred

00:59:09,500 --> 00:59:15,890
pool information given in percentage how

00:59:13,070 --> 00:59:17,840
many percent of the thread pool were

00:59:15,890 --> 00:59:19,910
busy and we see that during this test

00:59:17,840 --> 00:59:21,230
run we never exceeded 20 percent and

00:59:19,910 --> 00:59:24,200
most of the time we were around five

00:59:21,230 --> 00:59:26,990
percent ego yes I've got a question

00:59:24,200 --> 00:59:30,980
about the JIT I was told by somebody but

00:59:26,990 --> 00:59:33,860
it was over beer so I am asking it not

00:59:30,980 --> 00:59:39,850
to you that after about ten thousand

00:59:33,860 --> 00:59:42,920
requests the JVM JIT kicks in right and

00:59:39,850 --> 00:59:44,690
optimizes based on the request pattern

00:59:42,920 --> 00:59:47,839
for one and

00:59:44,690 --> 00:59:50,060
or rather re optimizes recompiles based

00:59:47,839 --> 00:59:52,390
on the request pattern and based on what

00:59:50,060 --> 00:59:56,869
machine exactly it's running on is how

00:59:52,390 --> 00:59:59,300
can i cannot tell you much about the

00:59:56,869 --> 01:00:04,010
patterns that you mean that yes

00:59:59,300 --> 01:00:06,200
there is first of all there's a client

01:00:04,010 --> 01:00:09,589
JVM and a server JVM and those two have

01:00:06,200 --> 01:00:11,720
different limits so the client JVM

01:00:09,589 --> 01:00:14,480
optimizes much earlier because it

01:00:11,720 --> 01:00:16,880
expects that the code is not that that

01:00:14,480 --> 01:00:18,859
it's more code that's not running that

01:00:16,880 --> 01:00:21,890
often so it the better pattern is to

01:00:18,859 --> 01:00:23,990
optimize more of it and the server JVM

01:00:21,890 --> 01:00:27,410
waits a longer time before it kicks in

01:00:23,990 --> 01:00:30,140
but those thresholds like 10,000 or so

01:00:27,410 --> 01:00:33,500
they are not really huge because under

01:00:30,140 --> 01:00:38,000
load a local method is often called very

01:00:33,500 --> 01:00:40,550
frequently so it depends on the on which

01:00:38,000 --> 01:00:42,410
JVM you use as as always everything is

01:00:40,550 --> 01:00:44,300
configurable there are hundreds of

01:00:42,410 --> 01:00:51,050
settings but this is typically not

01:00:44,300 --> 01:00:54,050
needed okay we got the thread pool usage

01:00:51,050 --> 01:00:58,130
thread creations this is a session

01:00:54,050 --> 01:00:59,599
picture so we can see that during the

01:00:58,130 --> 01:01:02,270
stress test more and more sessions were

01:00:59,599 --> 01:01:04,400
created until finally the login and

01:01:02,270 --> 01:01:07,930
expiration range stabilized and the

01:01:04,400 --> 01:01:11,810
session not count didn't change anymore

01:01:07,930 --> 01:01:13,970
left side is logins right side is

01:01:11,810 --> 01:01:15,710
explorations and we can see for some

01:01:13,970 --> 01:01:18,020
time logins is higher than explorations

01:01:15,710 --> 01:01:22,190
that mean we build up sessions and then

01:01:18,020 --> 01:01:27,200
it stabilizes request rates per second

01:01:22,190 --> 01:01:30,349
about sixty error rates on the right

01:01:27,200 --> 01:01:33,859
side so represent average duration about

01:01:30,349 --> 01:01:35,990
200 milliseconds and it gets bad during

01:01:33,859 --> 01:01:39,050
the end of the run and that was due to

01:01:35,990 --> 01:01:44,569
some external assisting not responding

01:01:39,050 --> 01:01:47,150
anymore in time and on the right side we

01:01:44,569 --> 01:01:49,040
see the concurrency and the left and the

01:01:47,150 --> 01:01:51,200
right picture look very similar that's

01:01:49,040 --> 01:01:54,560
because the throughput the number of

01:01:51,200 --> 01:01:57,470
requests per second we put in was was

01:01:54,560 --> 01:01:57,960
very stable over time so if the response

01:01:57,470 --> 01:01:59,700
time go

01:01:57,960 --> 01:02:01,650
up the concurrency goes up as well but

01:01:59,700 --> 01:02:03,660
it doesn't have to be like that it could

01:02:01,650 --> 01:02:06,359
be that the number of requests per

01:02:03,660 --> 01:02:10,220
second go up and then the concurrency

01:02:06,359 --> 01:02:13,410
might go up more than proportional

01:02:10,220 --> 01:02:15,630
yeah probably that's that's enough since

01:02:13,410 --> 01:02:20,210
time is over so I thank you for your

01:02:15,630 --> 01:02:20,210

YouTube URL: https://www.youtube.com/watch?v=b2iQ7aohfhM


