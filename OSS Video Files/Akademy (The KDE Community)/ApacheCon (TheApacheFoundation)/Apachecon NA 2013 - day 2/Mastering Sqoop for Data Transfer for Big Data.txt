Title: Mastering Sqoop for Data Transfer for Big Data
Publication date: 2013-10-17
Playlist: Apachecon NA 2013 - day 2
Description: 
	Kathleen Ting, Arvind Prabhakar
ApacheCon NA 2013
Big Data
Captions: 
	00:00:00,500 --> 00:00:06,150
alright so we have our window marker and

00:00:03,600 --> 00:00:10,139
Kathleen ding back on track 5 and

00:00:06,150 --> 00:00:13,530
they're going to talk about school thank

00:00:10,139 --> 00:00:16,139
you Apache scoop was created to

00:00:13,530 --> 00:00:17,699
efficiently transfer bulk data from

00:00:16,139 --> 00:00:20,130
structured data sources external

00:00:17,699 --> 00:00:22,050
structure data sources into hit do

00:00:20,130 --> 00:00:25,350
because databases are not easy

00:00:22,050 --> 00:00:27,240
accessible by Hadoop the popularity of

00:00:25,350 --> 00:00:29,670
scoop at enterprise systems confirms

00:00:27,240 --> 00:00:31,800
that scoop does book transfer admirably

00:00:29,670 --> 00:00:34,590
that said there are certain data

00:00:31,800 --> 00:00:36,030
integration use cases that scoop need to

00:00:34,590 --> 00:00:41,489
address as well as become easier to

00:00:36,030 --> 00:00:44,450
manage and operate who are we are member

00:00:41,489 --> 00:00:49,350
Barker is a patchy scoop committer pmc

00:00:44,450 --> 00:00:52,350
chair and a SF member earlier he gave a

00:00:49,350 --> 00:00:55,199
talk on flume as well he's also an

00:00:52,350 --> 00:00:57,360
engineer manager at Cloudera and i also

00:00:55,199 --> 00:01:00,030
am a scoop committer and pmc member

00:00:57,360 --> 00:01:02,760
earlier i gave a talk on hadoop and i am

00:01:00,030 --> 00:01:11,340
a customer operations engineer manager

00:01:02,760 --> 00:01:14,189
at Cloudera and what is scoop scoop is a

00:01:11,340 --> 00:01:18,060
patchy top level project as of april of

00:01:14,189 --> 00:01:23,009
last year it was originally conceived as

00:01:18,060 --> 00:01:25,170
a scoop to start as a sequel to Hadoop

00:01:23,009 --> 00:01:30,150
hence the name scoop as a sequel to hit

00:01:25,170 --> 00:01:32,610
dupe tool and and it was it was born out

00:01:30,150 --> 00:01:36,600
of the frustration of there not being

00:01:32,610 --> 00:01:41,670
anything readily available to import

00:01:36,600 --> 00:01:45,509
large amounts of data from your external

00:01:41,670 --> 00:01:47,729
data store or such as my sequel Oracle

00:01:45,509 --> 00:01:50,549
etc originally just for my sequel but

00:01:47,729 --> 00:01:52,369
the scope has since expanded there's

00:01:50,549 --> 00:01:56,430
nothing out there that could easily

00:01:52,369 --> 00:01:58,590
export from your your external system

00:01:56,430 --> 00:02:00,600
into a dupe for processing and then once

00:01:58,590 --> 00:02:04,119
you're done with the analysis exporting

00:02:00,600 --> 00:02:06,439
it back out to your data store

00:02:04,119 --> 00:02:09,200
with scoop you can automatically

00:02:06,439 --> 00:02:12,080
populate your tables in HDFS and hive

00:02:09,200 --> 00:02:19,370
and HBase on their command options that

00:02:12,080 --> 00:02:23,989
you can provide to do that so can you

00:02:19,370 --> 00:02:26,000
guys hear me so the rationale behind

00:02:23,989 --> 00:02:29,810
scoop you know part of what Kathleen

00:02:26,000 --> 00:02:31,459
just alluded to goes pretty deep you if

00:02:29,810 --> 00:02:34,370
you if you are going to be running

00:02:31,459 --> 00:02:36,230
analytics jobs in your Hadoop cluster in

00:02:34,370 --> 00:02:40,160
Europe in your pipeline it's important

00:02:36,230 --> 00:02:41,870
that you be able to get data in there to

00:02:40,160 --> 00:02:43,880
begin with and while you know the

00:02:41,870 --> 00:02:45,410
earlier session we talked about flume

00:02:43,880 --> 00:02:47,500
that's one way of getting data in there

00:02:45,410 --> 00:02:49,849
fact the matter is for the most part

00:02:47,500 --> 00:02:52,760
enterprises are heavily nested in

00:02:49,849 --> 00:02:56,150
structured data stores so having a

00:02:52,760 --> 00:02:58,160
system like you know a MapReduce program

00:02:56,150 --> 00:03:01,130
go directly against your production

00:02:58,160 --> 00:03:02,620
databases even though that's doable it's

00:03:01,130 --> 00:03:05,030
probably not the best thing to do

00:03:02,620 --> 00:03:07,220
because you do not want to unleash a

00:03:05,030 --> 00:03:09,769
cluster going against your core business

00:03:07,220 --> 00:03:11,810
critical application databases so whats

00:03:09,769 --> 00:03:13,549
coop does is it takes out that

00:03:11,810 --> 00:03:15,709
information that's bird in your

00:03:13,549 --> 00:03:18,440
relational stores your production

00:03:15,709 --> 00:03:19,880
databases makes it available on HDFS or

00:03:18,440 --> 00:03:24,920
a niche base or wherever you need it to

00:03:19,880 --> 00:03:27,109
be and and effectively decouples your

00:03:24,920 --> 00:03:29,569
Hadoop workload from your other business

00:03:27,109 --> 00:03:31,579
critical production applications so that

00:03:29,569 --> 00:03:34,250
that was the primary motivation of why

00:03:31,579 --> 00:03:36,230
scoop was you know conceived in the

00:03:34,250 --> 00:03:39,530
first place but other than that you know

00:03:36,230 --> 00:03:43,069
at the moment we started exploring this

00:03:39,530 --> 00:03:46,340
use case we figured that there is this

00:03:43,069 --> 00:03:48,799
huge discrepancy between the type

00:03:46,340 --> 00:03:50,810
systems that exist in the databases well

00:03:48,799 --> 00:03:54,079
I mean to be honest there is a huge

00:03:50,810 --> 00:03:58,069
discrepancies within databases but

00:03:54,079 --> 00:03:59,750
there's more so between the combined you

00:03:58,069 --> 00:04:02,349
know structured stores as well as I do

00:03:59,750 --> 00:04:04,700
because Hadoop has been perceived more

00:04:02,349 --> 00:04:06,260
from a different point of view then

00:04:04,700 --> 00:04:09,470
where the structured data stores are

00:04:06,260 --> 00:04:12,110
coming from so another aspect that scoop

00:04:09,470 --> 00:04:14,090
does very well and and and has factored

00:04:12,110 --> 00:04:16,370
into the motivation of sort of expanding

00:04:14,090 --> 00:04:16,670
the scope of scoop and covering is the

00:04:16,370 --> 00:04:18,380
above

00:04:16,670 --> 00:04:21,200
to do data type mapping and conversion

00:04:18,380 --> 00:04:23,180
across these disparate sources and then

00:04:21,200 --> 00:04:25,460
part of this data type you know

00:04:23,180 --> 00:04:28,640
conversion across sources also requires

00:04:25,460 --> 00:04:32,900
the propagation of metadata which is to

00:04:28,640 --> 00:04:35,630
say that hey if you have you know let's

00:04:32,900 --> 00:04:38,630
say our Oracle database that has a

00:04:35,630 --> 00:04:40,820
number of data type in a specific column

00:04:38,630 --> 00:04:43,400
and you would like that number data type

00:04:40,820 --> 00:04:47,270
to be expressed as a different data type

00:04:43,400 --> 00:04:49,490
for then I do if you were to be on your

00:04:47,270 --> 00:04:53,300
own it'll require quite a considerable

00:04:49,490 --> 00:04:55,250
amount of manual labor work in order for

00:04:53,300 --> 00:04:57,380
you to make that happen what scoop does

00:04:55,250 --> 00:04:59,660
is you know you run a command basically

00:04:57,380 --> 00:05:00,890
it understands it has intelligent

00:04:59,660 --> 00:05:03,830
default mappings and you can override

00:05:00,890 --> 00:05:05,920
them populates it into Hadoop whatever

00:05:03,830 --> 00:05:08,960
system on Hadoop that you're running

00:05:05,920 --> 00:05:11,240
maybe creates a table in HYFR unit gets

00:05:08,960 --> 00:05:15,410
that data available for you and all of

00:05:11,240 --> 00:05:16,910
this while utilizing the maximum network

00:05:15,410 --> 00:05:18,680
capacity giving you the ability to

00:05:16,910 --> 00:05:22,250
control when you want to run that load

00:05:18,680 --> 00:05:27,440
and you know in a manner that's really

00:05:22,250 --> 00:05:30,230
high performance as arfin mentioned

00:05:27,440 --> 00:05:33,770
scoop one was conceived as a

00:05:30,230 --> 00:05:37,340
command-line tool and as such there are

00:05:33,770 --> 00:05:41,330
60 or so options that you can pass in as

00:05:37,340 --> 00:05:44,930
command line options for for your scoop

00:05:41,330 --> 00:05:47,720
job so everything from dealing with your

00:05:44,930 --> 00:05:50,120
job data to to dealing with the metadata

00:05:47,720 --> 00:05:52,220
that you need to pass it so it can

00:05:50,120 --> 00:05:54,730
connect successfully to your database so

00:05:52,220 --> 00:06:01,430
such things as your username or password

00:05:54,730 --> 00:06:03,860
the connect URL etc so the workflow of

00:06:01,430 --> 00:06:06,260
scoop one is you start from your client

00:06:03,860 --> 00:06:09,230
you get your command input from the

00:06:06,260 --> 00:06:12,530
pliant which then connects and fetches

00:06:09,230 --> 00:06:16,580
the metadata from the database from

00:06:12,530 --> 00:06:19,700
there scoop will automatically create a

00:06:16,580 --> 00:06:23,420
a map job for you so generate code for

00:06:19,700 --> 00:06:25,640
you and then submit this map job to do

00:06:23,420 --> 00:06:27,400
the data transfer so you don't need to

00:06:25,640 --> 00:06:29,860
to write

00:06:27,400 --> 00:06:32,259
your own map job it attracts us away you

00:06:29,860 --> 00:06:35,229
just provide needed parameter so it can

00:06:32,259 --> 00:06:37,479
connect your database and then it will

00:06:35,229 --> 00:06:44,320
then scoop will then take over generate

00:06:37,479 --> 00:06:45,729
the code transfer your data so do to

00:06:44,320 --> 00:06:49,720
highlight one of the statements Kathleen

00:06:45,729 --> 00:06:51,520
made scoop one had sixty or command line

00:06:49,720 --> 00:06:54,580
options and those are the ones we could

00:06:51,520 --> 00:06:57,190
count you've got to think about this

00:06:54,580 --> 00:07:00,760
because if if a system has 60 command

00:06:57,190 --> 00:07:03,729
line options there's there's something

00:07:00,760 --> 00:07:05,680
out of control their part of the

00:07:03,729 --> 00:07:07,360
rationale of why we needed the 16th of

00:07:05,680 --> 00:07:09,310
online options was because it was being

00:07:07,360 --> 00:07:11,350
rapidly developed for very specific use

00:07:09,310 --> 00:07:12,880
cases this is normal evolution of

00:07:11,350 --> 00:07:15,060
software products you know they they

00:07:12,880 --> 00:07:17,169
tend to expand scope then too

00:07:15,060 --> 00:07:19,570
encompassing more and more use cases and

00:07:17,169 --> 00:07:21,430
then you know sooner or later you have a

00:07:19,570 --> 00:07:24,160
realization that the initial design

00:07:21,430 --> 00:07:26,740
initial assumptions weren't sufficient

00:07:24,160 --> 00:07:29,440
to make a case for incorporating those

00:07:26,740 --> 00:07:30,699
use cases happens all the time so but

00:07:29,440 --> 00:07:32,800
part of the matter is like you know

00:07:30,699 --> 00:07:36,340
there's there is a ceiling where once

00:07:32,800 --> 00:07:38,789
you get to it it just becomes very

00:07:36,340 --> 00:07:41,740
apparent that something needs to change

00:07:38,789 --> 00:07:43,030
apart from apart from you know the fact

00:07:41,740 --> 00:07:45,490
that the options were out of control

00:07:43,030 --> 00:07:47,080
there's a very central theme book skip

00:07:45,490 --> 00:07:50,940
one which is it's entirely based on

00:07:47,080 --> 00:07:53,560
connectors and connectors are these full

00:07:50,940 --> 00:07:55,990
extensions of the scoop framework which

00:07:53,560 --> 00:07:58,330
bring in functionality specific to a

00:07:55,990 --> 00:08:01,720
certain datastore you could have a high

00:07:58,330 --> 00:08:04,979
performance you know we a quest software

00:08:01,720 --> 00:08:07,180
which is now part of Dell Dell of

00:08:04,979 --> 00:08:09,789
high-performance connector for Oracle

00:08:07,180 --> 00:08:13,539
Exadata it's called the aura it's freely

00:08:09,789 --> 00:08:15,010
available it's open source if you go

00:08:13,539 --> 00:08:18,669
look at the code it is by far

00:08:15,010 --> 00:08:20,530
non-trivial not in terms of the level of

00:08:18,669 --> 00:08:22,180
coupling and understanding and

00:08:20,530 --> 00:08:24,280
manipulation and brings on the Oracle

00:08:22,180 --> 00:08:28,990
side but equally important on on the

00:08:24,280 --> 00:08:30,610
scoop side these connectors were the

00:08:28,990 --> 00:08:32,710
extension points that the framework came

00:08:30,610 --> 00:08:36,610
with and we saw development a bunch of

00:08:32,710 --> 00:08:39,070
actors part of part of the shortcomings

00:08:36,610 --> 00:08:42,010
of this framework was if any of those

00:08:39,070 --> 00:08:44,230
options that scoop already supported

00:08:42,010 --> 00:08:45,730
weren't applicable to what these

00:08:44,230 --> 00:08:47,500
connectors were trying to do they'd have

00:08:45,730 --> 00:08:49,270
to you know somehow work their way

00:08:47,500 --> 00:08:52,690
around it and I'm sure Kathleen has a

00:08:49,270 --> 00:08:53,950
little bit more details on that apart

00:08:52,690 --> 00:08:56,200
from that there's there's overlap of

00:08:53,950 --> 00:08:58,240
functionality each connector that

00:08:56,200 --> 00:09:00,010
supports say populating it and HBase

00:08:58,240 --> 00:09:07,440
will have to implement it its own

00:09:00,010 --> 00:09:10,570
version of that as Arvind alluded to and

00:09:07,440 --> 00:09:12,520
as you can tell from what we've said so

00:09:10,570 --> 00:09:14,770
far and I'm sure it photos of you who

00:09:12,520 --> 00:09:17,680
have you scoop these challenges are not

00:09:14,770 --> 00:09:19,870
new the cryptic and contextual

00:09:17,680 --> 00:09:21,820
command-line arguments one example is

00:09:19,870 --> 00:09:24,670
the driver option this is something that

00:09:21,820 --> 00:09:27,870
trips users up on a regular basis when

00:09:24,670 --> 00:09:30,190
you specify the driver option on your

00:09:27,870 --> 00:09:32,140
scoot command line what do you think

00:09:30,190 --> 00:09:33,460
will happen you're going to think well

00:09:32,140 --> 00:09:35,770
I'm going to specify I'm going to take

00:09:33,460 --> 00:09:37,990
the trouble of specifying a driver

00:09:35,770 --> 00:09:39,610
option therefore I'm telling a scoop

00:09:37,990 --> 00:09:42,070
look I want you to use a specialized

00:09:39,610 --> 00:09:44,260
connector right why also would i specify

00:09:42,070 --> 00:09:47,050
a driver option but actually in a very

00:09:44,260 --> 00:09:50,050
non-intuitive fashion if you specify the

00:09:47,050 --> 00:09:53,440
driver option scoop will then use the

00:09:50,050 --> 00:09:55,900
generic driver even if you have the

00:09:53,440 --> 00:09:58,510
specialized character such as or loop

00:09:55,900 --> 00:10:00,760
for Oracle in your library or if you

00:09:58,510 --> 00:10:03,270
have them a teaser connector or the

00:10:00,760 --> 00:10:06,070
doterra data connector in your library

00:10:03,270 --> 00:10:07,390
correctly configured and installed when

00:10:06,070 --> 00:10:10,120
you specify the driver option you're

00:10:07,390 --> 00:10:11,350
actually using the generic JDBC right

00:10:10,120 --> 00:10:13,330
you're not getting the performance

00:10:11,350 --> 00:10:18,370
benefits and the added functionality of

00:10:13,330 --> 00:10:21,400
that specialized connector so you know

00:10:18,370 --> 00:10:23,880
definitely something that is not

00:10:21,400 --> 00:10:28,900
intuitive and a pain point for many

00:10:23,880 --> 00:10:32,350
security concerns scoop is is a great

00:10:28,900 --> 00:10:35,350
tool but it's a great tool that many

00:10:32,350 --> 00:10:37,210
users cannot use currently this is

00:10:35,350 --> 00:10:39,460
primarily people who work for a

00:10:37,210 --> 00:10:42,370
financial services company anyone who

00:10:39,460 --> 00:10:46,329
cares about data confidentiality right

00:10:42,370 --> 00:10:48,009
now your username and your password to

00:10:46,329 --> 00:10:51,759
or external database your Oracle

00:10:48,009 --> 00:10:56,199
database user database it's being openly

00:10:51,759 --> 00:10:58,839
shared it is exposed and as a result you

00:10:56,199 --> 00:11:01,239
know many people are not able to use

00:10:58,839 --> 00:11:03,069
scoop as it is even though it's a very

00:11:01,239 --> 00:11:05,860
functional a very great tool because of

00:11:03,069 --> 00:11:07,959
security concerns the need for all

00:11:05,860 --> 00:11:11,019
clients to know credentials to the

00:11:07,959 --> 00:11:12,790
database that's keeping scoop from being

00:11:11,019 --> 00:11:14,819
more widely adopted currently a scoop

00:11:12,790 --> 00:11:17,649
one from being widely adopted

00:11:14,819 --> 00:11:20,079
furthermore some connectors may support

00:11:17,649 --> 00:11:21,369
a certain data format that others don't

00:11:20,079 --> 00:11:24,989
for instance the direct my sequel

00:11:21,369 --> 00:11:27,279
connector can't support sequence files

00:11:24,989 --> 00:11:29,230
scoop users shouldn't need to concern

00:11:27,279 --> 00:11:30,489
themselves with scoop administrative

00:11:29,230 --> 00:11:33,279
responsibilities and that's something

00:11:30,489 --> 00:11:35,559
right now it's scoop user not only do

00:11:33,279 --> 00:11:38,470
you need to worry about what are 26

00:11:35,559 --> 00:11:41,410
years so options I need to provide there

00:11:38,470 --> 00:11:42,819
there is no currently there's no way to

00:11:41,410 --> 00:11:45,759
know that for instance you know if I'm

00:11:42,819 --> 00:11:47,949
trying to run in in the direct mode I

00:11:45,759 --> 00:11:49,179
can't use columns right if you really

00:11:47,949 --> 00:11:51,009
look in the code you would see a comment

00:11:49,179 --> 00:11:52,749
and you can't do that but you know

00:11:51,009 --> 00:11:56,649
that's that's too much to expect of the

00:11:52,749 --> 00:11:58,689
typical scoop user and and finally as

00:11:56,649 --> 00:12:01,419
arvind mentioned currently the jdbc

00:11:58,689 --> 00:12:03,790
model is enforced which made sense if

00:12:01,419 --> 00:12:07,629
you think about how scoop wasn't

00:12:03,790 --> 00:12:09,669
intended originally to import from my

00:12:07,629 --> 00:12:11,439
sequel in to dupe and export back into

00:12:09,669 --> 00:12:13,629
my sequel it made sense that you would

00:12:11,439 --> 00:12:16,119
have this overriding overarching jdbc

00:12:13,629 --> 00:12:18,399
model doutzen force but now we now have

00:12:16,119 --> 00:12:20,259
not just oracle database connective that

00:12:18,399 --> 00:12:21,669
we also have Netezza and couch base and

00:12:20,259 --> 00:12:24,489
for those of you familiar with couchbase

00:12:21,669 --> 00:12:29,019
there is no there's no concept of a

00:12:24,489 --> 00:12:33,160
table but since scoop is restricted to a

00:12:29,019 --> 00:12:36,850
JDBC vocabulary the couch base connector

00:12:33,160 --> 00:12:38,739
is forced to use the table but since

00:12:36,850 --> 00:12:41,829
there is no concept of the table it

00:12:38,739 --> 00:12:44,559
instead instead overloads the table name

00:12:41,829 --> 00:12:46,509
as a backfill or a dump operation which

00:12:44,559 --> 00:12:49,059
again is not intuitive that you have

00:12:46,509 --> 00:12:52,179
this table option dash table which is

00:12:49,059 --> 00:12:54,610
actually operating disguised as a

00:12:52,179 --> 00:12:57,110
backflow or dump operation and this is a

00:12:54,610 --> 00:13:03,110
direct result of the JDBC model being

00:12:57,110 --> 00:13:05,089
forced so that you know to sum it up

00:13:03,110 --> 00:13:07,579
like you might be wondering like you

00:13:05,089 --> 00:13:09,410
know well how come scoop one have has

00:13:07,579 --> 00:13:11,360
these challenges like why wasn't it

00:13:09,410 --> 00:13:13,430
thought through right from the get-go

00:13:11,360 --> 00:13:15,620
about you know enforcing a specific

00:13:13,430 --> 00:13:17,570
connectivity model you know enforcing a

00:13:15,620 --> 00:13:21,230
specific vocabulary the answer is pretty

00:13:17,570 --> 00:13:25,040
simple it was delap as a hackathon

00:13:21,230 --> 00:13:27,410
project for power users by delivers who

00:13:25,040 --> 00:13:29,180
were pained at the prospect of like

00:13:27,410 --> 00:13:30,680
doing manual dumps from one database

00:13:29,180 --> 00:13:32,779
into Hadoop to be able to run their

00:13:30,680 --> 00:13:35,329
MapReduce jobs so for the longest time

00:13:32,779 --> 00:13:37,910
skip one kind of involved more towards

00:13:35,329 --> 00:13:39,470
catering to the power user who's able to

00:13:37,910 --> 00:13:40,910
navigate their way around and and if

00:13:39,470 --> 00:13:44,240
you're one of those power user probably

00:13:40,910 --> 00:13:47,180
enjoy pain and and that's the reason why

00:13:44,240 --> 00:13:49,550
you know it sustained being applicable

00:13:47,180 --> 00:13:51,709
in the industry for such a long time and

00:13:49,550 --> 00:13:55,670
it continues to fit those those aspects

00:13:51,709 --> 00:13:57,410
even till today but but the very nature

00:13:55,670 --> 00:14:00,440
of the kind of issues that Kathleen

00:13:57,410 --> 00:14:03,949
highlight in the previous slide leads on

00:14:00,440 --> 00:14:06,260
to a much bigger problem which is the

00:14:03,949 --> 00:14:07,670
fact that connectors doing their own

00:14:06,260 --> 00:14:10,459
interpretation of the command line

00:14:07,670 --> 00:14:12,680
options implementing functionality that

00:14:10,459 --> 00:14:17,120
is should ideally be shared but you know

00:14:12,680 --> 00:14:20,420
as a one-off leads to non uniformity and

00:14:17,120 --> 00:14:25,040
an inconsistent user experience that can

00:14:20,420 --> 00:14:28,279
put the brakes on you know all new users

00:14:25,040 --> 00:14:32,500
trying to get familiarized the tool be

00:14:28,279 --> 00:14:35,510
able to use it in production the

00:14:32,500 --> 00:14:37,550
implication of this is there is there is

00:14:35,510 --> 00:14:39,170
a usability aspect coupled with the

00:14:37,550 --> 00:14:42,680
security issues that Kathleen talked

00:14:39,170 --> 00:14:44,870
about and and it makes scoop one as a

00:14:42,680 --> 00:14:47,269
product only accessible to a very small

00:14:44,870 --> 00:14:50,089
subset of users who are able to find

00:14:47,269 --> 00:14:52,699
their way around the space there's

00:14:50,089 --> 00:14:55,100
there's the other angles to this whole

00:14:52,699 --> 00:14:57,860
problem which is from the perspective of

00:14:55,100 --> 00:15:00,110
connector developers now scoop one has

00:14:57,860 --> 00:15:02,290
seen many many connectors developed for

00:15:00,110 --> 00:15:06,170
it from third-party vendors and you know

00:15:02,290 --> 00:15:08,310
database providers and I have personally

00:15:06,170 --> 00:15:09,870
interacted with a bunch of those and

00:15:08,310 --> 00:15:12,450
have guided them to build these

00:15:09,870 --> 00:15:16,890
connectors the one common theme that

00:15:12,450 --> 00:15:19,950
stands out is that most of these vendors

00:15:16,890 --> 00:15:22,980
do not do not quite understand the

00:15:19,950 --> 00:15:24,690
MapReduce model very well they're not

00:15:22,980 --> 00:15:28,529
familiar with the idiosyncrasies that

00:15:24,690 --> 00:15:32,640
Hadoop has and it's a it's a struggle

00:15:28,529 --> 00:15:34,260
for them dune a learn it and be keep up

00:15:32,640 --> 00:15:40,650
with it because that's changing its

00:15:34,260 --> 00:15:43,710
continuously evolving so those all fed

00:15:40,650 --> 00:15:46,260
into you know what we kind of sat down

00:15:43,710 --> 00:15:47,430
together and have had discussion when I

00:15:46,260 --> 00:15:49,830
say sat down together in the Apache

00:15:47,430 --> 00:15:51,390
sense it's on the mailing list and we

00:15:49,830 --> 00:15:53,100
had interesting discussions back and

00:15:51,390 --> 00:15:55,230
forth about what are what are the

00:15:53,100 --> 00:15:57,990
various things we can do to change this

00:15:55,230 --> 00:16:00,690
and and and that's basically ended up

00:15:57,990 --> 00:16:05,250
being sort of the seeding thoughts

00:16:00,690 --> 00:16:09,060
behind scoop do one of the seeding

00:16:05,250 --> 00:16:15,360
thoughts behind scoop two is to change

00:16:09,060 --> 00:16:17,250
up scoop completely scoop one has the

00:16:15,360 --> 00:16:21,300
scoop client scoop to has a

00:16:17,250 --> 00:16:23,250
client-server model and by having this

00:16:21,300 --> 00:16:26,310
client server model scoop to is now a

00:16:23,250 --> 00:16:27,780
service in that you can install once and

00:16:26,310 --> 00:16:31,560
then run everywhere just means that

00:16:27,780 --> 00:16:34,170
connectors can be stored in one place it

00:16:31,560 --> 00:16:35,520
can be configured in one place managed

00:16:34,170 --> 00:16:37,640
by the admin role and run by the

00:16:35,520 --> 00:16:40,290
operator which we'll talk about later

00:16:37,640 --> 00:16:42,780
likewise jdbc drivers are going to be

00:16:40,290 --> 00:16:46,530
one place data base connectivity will

00:16:42,780 --> 00:16:48,180
only be needed on the server so we're we

00:16:46,530 --> 00:16:52,800
have server-side installation and

00:16:48,180 --> 00:16:54,630
configuration and and as a result the

00:16:52,800 --> 00:16:55,980
client interacts directly with the

00:16:54,630 --> 00:16:57,930
server as you can see from this diagram

00:16:55,980 --> 00:16:59,880
it doesn't interact with Hadoop it

00:16:57,930 --> 00:17:02,880
doesn't interact with the database

00:16:59,880 --> 00:17:05,220
directly the server takes care of all of

00:17:02,880 --> 00:17:07,980
that the server has a medicine

00:17:05,220 --> 00:17:11,640
repository where you can store all this

00:17:07,980 --> 00:17:14,640
job information for for security and

00:17:11,640 --> 00:17:16,290
also for you know for ease of use so you

00:17:14,640 --> 00:17:18,240
don't have to you know re-enter your

00:17:16,290 --> 00:17:19,589
connection parameters to your database

00:17:18,240 --> 00:17:20,970
over and over again you will need to

00:17:19,589 --> 00:17:23,490
worry about

00:17:20,970 --> 00:17:25,620
safe right you don't want to give your

00:17:23,490 --> 00:17:28,049
password to your oracle database out to

00:17:25,620 --> 00:17:32,850
everyone right you want that stored

00:17:28,049 --> 00:17:34,980
safely and scoop to address is that you

00:17:32,850 --> 00:17:37,890
know we want to make sure with scoop

00:17:34,980 --> 00:17:39,840
that serialization format conversion and

00:17:37,890 --> 00:17:42,000
hive an HBS integration which we're

00:17:39,840 --> 00:17:43,590
lacking in scoop one you know we want

00:17:42,000 --> 00:17:50,340
these to be uniformly available via the

00:17:43,590 --> 00:17:53,520
scoop to framework so to sum that all up

00:17:50,340 --> 00:17:56,280
you know it all kind of was down to the

00:17:53,520 --> 00:17:58,620
key design goals behind scoop to as an

00:17:56,280 --> 00:18:01,440
implementation and here the three key

00:17:58,620 --> 00:18:03,539
design goals that pretty much drove and

00:18:01,440 --> 00:18:05,250
they're still driving scoop do is far

00:18:03,539 --> 00:18:06,510
from a complete product at the moment we

00:18:05,250 --> 00:18:09,409
just made the first release of knob

00:18:06,510 --> 00:18:11,789
stream happen on December 25th last year

00:18:09,409 --> 00:18:13,890
but you know that said there's there's

00:18:11,789 --> 00:18:16,380
plenty of work to be done all of that is

00:18:13,890 --> 00:18:20,309
guided in part by these three design

00:18:16,380 --> 00:18:22,049
goals that we've set in front of us to

00:18:20,309 --> 00:18:25,169
be able to meet them the first is ease

00:18:22,049 --> 00:18:27,299
of use so we talked about the 60 command

00:18:25,169 --> 00:18:29,159
line options how they can contextually

00:18:27,299 --> 00:18:33,870
behave differently how they can have an

00:18:29,159 --> 00:18:36,510
implied you know effect on your actual

00:18:33,870 --> 00:18:37,980
scoop job which may not be intuitive

00:18:36,510 --> 00:18:40,380
enough so we want to get rid of all of

00:18:37,980 --> 00:18:42,210
that we want to get all of the

00:18:40,380 --> 00:18:45,090
information all regarding the

00:18:42,210 --> 00:18:47,340
functionality that the user is trying to

00:18:45,090 --> 00:18:49,710
achieve right in front of the user in a

00:18:47,340 --> 00:18:51,750
way that is domain-specific doesn't

00:18:49,710 --> 00:18:53,370
necessarily require you know the

00:18:51,750 --> 00:18:56,100
understanding of a JDBC model for

00:18:53,370 --> 00:18:58,440
instance if you which group do are

00:18:56,100 --> 00:19:00,870
trying to import data from a couch based

00:18:58,440 --> 00:19:04,860
database you wouldn't need to specify

00:19:00,870 --> 00:19:06,960
tables anymore that domain specific

00:19:04,860 --> 00:19:09,390
interaction is key to a pleasant user

00:19:06,960 --> 00:19:12,480
experience because let's say you know

00:19:09,390 --> 00:19:16,380
contrasting the scoop one case if I have

00:19:12,480 --> 00:19:20,070
a production system which runs maybe and

00:19:16,380 --> 00:19:22,110
that is a data warehouse it's expected

00:19:20,070 --> 00:19:24,210
that I will I will be familiar with the

00:19:22,110 --> 00:19:25,230
concepts in the teaser it's expected

00:19:24,210 --> 00:19:26,400
that I'll be familiar

00:19:25,230 --> 00:19:28,500
the various options that I need to

00:19:26,400 --> 00:19:32,520
specify in order to get connectivity in

00:19:28,500 --> 00:19:34,320
the data however if the system is a

00:19:32,520 --> 00:19:36,720
uniform system that is using like these

00:19:34,320 --> 00:19:38,820
cryptic options to figure out that that

00:19:36,720 --> 00:19:40,530
functionality it might force you to

00:19:38,820 --> 00:19:43,169
understand other warehousing systems

00:19:40,530 --> 00:19:46,320
like teradata and they may not speak the

00:19:43,169 --> 00:19:48,299
same vocabulary a classic example of

00:19:46,320 --> 00:19:51,270
this is you know the notion of a schema

00:19:48,299 --> 00:19:53,730
is different in different databases they

00:19:51,270 --> 00:19:56,400
they have far-reaching implications with

00:19:53,730 --> 00:19:58,770
respect to how security works in

00:19:56,400 --> 00:20:01,290
databases you know how ownership and

00:19:58,770 --> 00:20:02,970
privileges working databases so scoop do

00:20:01,290 --> 00:20:04,830
tries in addresses a lot of this by

00:20:02,970 --> 00:20:07,080
having ease of use as one of the

00:20:04,830 --> 00:20:11,419
fundamental design goals second thing

00:20:07,080 --> 00:20:15,990
that it does is enable the same level of

00:20:11,419 --> 00:20:18,059
ease for for the connector delivers as

00:20:15,990 --> 00:20:20,160
well so ease of extensibility is also

00:20:18,059 --> 00:20:23,309
very very important one of the things we

00:20:20,160 --> 00:20:25,049
factored end was to create an

00:20:23,309 --> 00:20:27,600
abstraction to create a framework that

00:20:25,049 --> 00:20:31,230
will keep the connector developers

00:20:27,600 --> 00:20:34,440
abstracted from the underlying changes

00:20:31,230 --> 00:20:35,880
in Hadoop so for example that scoop do

00:20:34,440 --> 00:20:39,030
you know one of one of the distributions

00:20:35,880 --> 00:20:43,049
you know that that supports scoop to got

00:20:39,030 --> 00:20:45,660
released yesterday is clutter as CDX 4.2

00:20:43,049 --> 00:20:47,760
distribution in that distribution we

00:20:45,660 --> 00:20:50,520
ship em are one and we also ship Hadoop

00:20:47,760 --> 00:20:53,970
do and scoop will work with either one

00:20:50,520 --> 00:20:57,150
of them and the connector doesn't need

00:20:53,970 --> 00:21:01,049
to be coded for either mr1 or for yarn

00:20:57,150 --> 00:21:04,440
the Hadoop do mr system so a lot of this

00:21:01,049 --> 00:21:05,580
is is going to be a welcome change for

00:21:04,440 --> 00:21:08,580
connector delivers who have always

00:21:05,580 --> 00:21:10,290
complained that you know we want to

00:21:08,580 --> 00:21:12,480
coexist in the Zika system we want to

00:21:10,290 --> 00:21:14,130
enable your enterprise workflows but we

00:21:12,480 --> 00:21:16,500
don't quite understand a lot of these

00:21:14,130 --> 00:21:18,090
idiosyncrasies and details and of course

00:21:16,500 --> 00:21:20,370
the third one is security in separation

00:21:18,090 --> 00:21:24,750
of concerns that Kathleen mentioned

00:21:20,370 --> 00:21:27,600
which we'll talk about a minute what

00:21:24,750 --> 00:21:29,490
happens when you submit a scoop job you

00:21:27,600 --> 00:21:32,880
create a connection and a youth submit a

00:21:29,490 --> 00:21:34,860
job so for those of you who have

00:21:32,880 --> 00:21:37,950
submitted at scoop job you you know that

00:21:34,860 --> 00:21:40,650
out of the 60 or so options you can

00:21:37,950 --> 00:21:43,710
parse those options and it basically two

00:21:40,650 --> 00:21:45,929
distinct categories the the connection

00:21:43,710 --> 00:21:47,850
category and a job category the

00:21:45,929 --> 00:21:50,429
connection category are things like your

00:21:47,850 --> 00:21:53,100
your connect URL your username your

00:21:50,429 --> 00:21:54,150
password to your external data store and

00:21:53,100 --> 00:21:56,040
so that's going to be distinct /

00:21:54,150 --> 00:22:00,500
database and then you have your job

00:21:56,040 --> 00:22:03,270
category things like the table the query

00:22:00,500 --> 00:22:07,799
you know the target dirt those are going

00:22:03,270 --> 00:22:11,190
to be distinct per table you know this

00:22:07,799 --> 00:22:13,710
way when the user makes an explicit

00:22:11,190 --> 00:22:16,110
connector choice it would be less

00:22:13,710 --> 00:22:18,809
error-prone and more predictable with

00:22:16,110 --> 00:22:22,110
with scoop to in that you know no longer

00:22:18,809 --> 00:22:25,020
is it scoop going to guess for you based

00:22:22,110 --> 00:22:27,510
on your connect URL what database you're

00:22:25,020 --> 00:22:29,790
trying to you're trying to connect to

00:22:27,510 --> 00:22:31,860
instead I'm you're going to explicitly

00:22:29,790 --> 00:22:33,510
tell scoop right and that will cut down

00:22:31,860 --> 00:22:36,450
a lot of the errors and make more

00:22:33,510 --> 00:22:38,760
predictable as a result with scoop to

00:22:36,450 --> 00:22:40,260
users they don't need to be aware of the

00:22:38,760 --> 00:22:43,260
functionality of other connectors as

00:22:40,260 --> 00:22:45,120
arvind mentioned for instance as i

00:22:43,260 --> 00:22:47,700
mentioned earlier the couch base users

00:22:45,120 --> 00:22:49,650
won't need to care that other connectors

00:22:47,700 --> 00:22:55,080
use tables right that's going to be an

00:22:49,650 --> 00:22:57,090
on an on relevant fact by having

00:22:55,080 --> 00:22:59,669
connections enabled as first class

00:22:57,090 --> 00:23:02,790
objects which are one encompass

00:22:59,669 --> 00:23:05,370
credentials the user and passwords for

00:23:02,790 --> 00:23:07,020
your external data stores you can create

00:23:05,370 --> 00:23:10,020
these connections once and then use them

00:23:07,020 --> 00:23:12,049
many times for various important export

00:23:10,020 --> 00:23:12,049
jobs

00:23:12,340 --> 00:23:18,230
so your your metadata will be saved in

00:23:16,009 --> 00:23:20,029
the server which houses a metadata

00:23:18,230 --> 00:23:21,409
repository so you don't have the first

00:23:20,029 --> 00:23:25,899
keep typing so you're going to be

00:23:21,409 --> 00:23:31,100
responsible for securing it as a result

00:23:25,899 --> 00:23:33,409
so so this is this is typically yeah you

00:23:31,100 --> 00:23:36,980
know the current implementation this is

00:23:33,409 --> 00:23:38,750
how it works with scoop to and part of

00:23:36,980 --> 00:23:40,159
it will become clear as we step in the

00:23:38,750 --> 00:23:44,809
second part of the session where we will

00:23:40,159 --> 00:23:48,470
actually attempt to demo the key idea

00:23:44,809 --> 00:23:50,809
behind scoop do is that connectors bring

00:23:48,470 --> 00:23:53,149
in the metadata of that they operate

00:23:50,809 --> 00:23:54,980
with and the term metadata gets thrown

00:23:53,149 --> 00:23:57,019
around a lot of different you know

00:23:54,980 --> 00:24:00,620
aspects and a lot of different context I

00:23:57,019 --> 00:24:02,870
want to clarify what it means here let's

00:24:00,620 --> 00:24:04,129
say we're developing a connector so one

00:24:02,870 --> 00:24:06,200
of the connectors that scoop do

00:24:04,129 --> 00:24:07,940
currently ships with is the general jdbc

00:24:06,200 --> 00:24:11,629
connector all the generate jdbc

00:24:07,940 --> 00:24:13,789
connector does is it allows you to to

00:24:11,629 --> 00:24:16,330
take data to move data from any database

00:24:13,789 --> 00:24:18,830
that supports jdbc you know connectivity

00:24:16,330 --> 00:24:21,679
you've got to install the JDBC driver

00:24:18,830 --> 00:24:23,120
somewhere and then you should be able to

00:24:21,679 --> 00:24:24,710
use this connector to create a

00:24:23,120 --> 00:24:27,740
connection to the database and then

00:24:24,710 --> 00:24:29,779
eventually create a job which may be of

00:24:27,740 --> 00:24:34,399
import type or export type using that

00:24:29,779 --> 00:24:36,320
connection so this connector registers

00:24:34,399 --> 00:24:39,649
its metadata with the scoop to server

00:24:36,320 --> 00:24:42,080
and and that metadata wood wooden can

00:24:39,649 --> 00:24:43,820
pass all of the necessary things that

00:24:42,080 --> 00:24:46,340
this connector needs to establish the

00:24:43,820 --> 00:24:48,649
connection so that could mean username

00:24:46,340 --> 00:24:51,409
and password and connect screen jdbc

00:24:48,649 --> 00:24:55,700
parameters and so on so forth so you'd

00:24:51,409 --> 00:24:57,350
be able to specify that save it in the

00:24:55,700 --> 00:24:59,809
metadata repository that scoop server

00:24:57,350 --> 00:25:01,610
maintains and that becomes a connection

00:24:59,809 --> 00:25:03,320
and using you know this first class

00:25:01,610 --> 00:25:05,480
object which was you know previously

00:25:03,320 --> 00:25:08,029
didn't quite exist you could actually

00:25:05,480 --> 00:25:09,919
now create another set of objects the

00:25:08,029 --> 00:25:12,289
job objects which kathleen alluded in

00:25:09,919 --> 00:25:15,169
the previous slide which can all depend

00:25:12,289 --> 00:25:17,320
upon this connection so this neatly dies

00:25:15,169 --> 00:25:21,169
back into the separation of concerns

00:25:17,320 --> 00:25:21,450
there is an that there is clearly in an

00:25:21,169 --> 00:25:24,600
end

00:25:21,450 --> 00:25:27,179
price setting a different role that

00:25:24,600 --> 00:25:29,809
governs credentials and access for

00:25:27,179 --> 00:25:32,130
various security implementation purposes

00:25:29,809 --> 00:25:33,899
so those will be the people those

00:25:32,130 --> 00:25:37,080
administrator's would be the people

00:25:33,899 --> 00:25:39,120
creating connection objects and yet

00:25:37,080 --> 00:25:42,269
there would be operators would be able

00:25:39,120 --> 00:25:44,340
to go in and use these connection

00:25:42,269 --> 00:25:46,049
objects without necessarily knowing what

00:25:44,340 --> 00:25:50,610
other credentials contain with it and

00:25:46,049 --> 00:25:53,130
then be able to modify them use them and

00:25:50,610 --> 00:25:57,419
to create their own jobs for importing

00:25:53,130 --> 00:26:00,000
and exporting so metadata enables

00:25:57,419 --> 00:26:01,559
creating the connections and jobs they

00:26:00,000 --> 00:26:03,419
get stored in the metadata repository

00:26:01,559 --> 00:26:06,059
part of storing them in the metadata

00:26:03,419 --> 00:26:07,289
repository also benefits you know the

00:26:06,059 --> 00:26:08,730
user and that you know once you

00:26:07,289 --> 00:26:10,740
configure a job you don't have to keep

00:26:08,730 --> 00:26:13,590
typing it over and over again you can

00:26:10,740 --> 00:26:17,130
just invoke the job any time but you

00:26:13,590 --> 00:26:20,730
know just a job ID and then you would

00:26:17,130 --> 00:26:23,940
run these jobs when you've appropriate

00:26:20,730 --> 00:26:26,940
times the goal is you know the

00:26:23,940 --> 00:26:28,830
separation of concern neatly dies into

00:26:26,940 --> 00:26:31,309
our projected security implementation

00:26:28,830 --> 00:26:35,070
where we'll be able to restrict access

00:26:31,309 --> 00:26:36,510
to these objects based on different

00:26:35,070 --> 00:26:39,539
roles whether it's an admin role on

00:26:36,510 --> 00:26:41,940
operator role but also going one step

00:26:39,539 --> 00:26:44,220
beyond that be able to set authorization

00:26:41,940 --> 00:26:46,860
and policies on top of these objects so

00:26:44,220 --> 00:26:49,230
for instance an admin can say this

00:26:46,860 --> 00:26:52,769
connection object should not have more

00:26:49,230 --> 00:26:54,630
than four connections which effectively

00:26:52,769 --> 00:26:56,340
translates to throttling the amount of

00:26:54,630 --> 00:26:59,519
load your production database will see

00:26:56,340 --> 00:27:02,220
and that's a very huge requirement in

00:26:59,519 --> 00:27:03,720
most enterprises that are trying to move

00:27:02,220 --> 00:27:05,820
data between production systems and

00:27:03,720 --> 00:27:09,950
their Hydra cluster you wouldn't want

00:27:05,820 --> 00:27:13,470
let's say a you know a malfunctioning

00:27:09,950 --> 00:27:15,960
task tracker our malfunctioning node in

00:27:13,470 --> 00:27:18,210
in your cluster to kick in speculative

00:27:15,960 --> 00:27:18,919
execution have more than n number of

00:27:18,210 --> 00:27:20,749
connections

00:27:18,919 --> 00:27:23,179
add it together against your production

00:27:20,749 --> 00:27:30,230
database so those kind of things become

00:27:23,179 --> 00:27:32,840
feasible with scoop Duke as arvind

00:27:30,230 --> 00:27:35,299
mentioned with scoop too we're going to

00:27:32,840 --> 00:27:38,090
have support for secure access to

00:27:35,299 --> 00:27:39,590
external systems via this role based

00:27:38,090 --> 00:27:41,570
access so we're going to have to Rose

00:27:39,590 --> 00:27:43,909
the administrative role and the operator

00:27:41,570 --> 00:27:46,340
role the administrator is responsible

00:27:43,909 --> 00:27:48,769
for creating editing and deleting these

00:27:46,340 --> 00:27:51,739
first-class connection objects and then

00:27:48,769 --> 00:27:56,769
the operator uses these connections this

00:27:51,739 --> 00:27:56,769
way we prevent misuse and abuse as well

00:27:57,100 --> 00:28:06,289
we we can have these connections

00:28:01,210 --> 00:28:08,960
restricted in scope so if a certain user

00:28:06,289 --> 00:28:11,299
only needs to do an import you can have

00:28:08,960 --> 00:28:13,549
them you can give them an import

00:28:11,299 --> 00:28:15,590
connection object so they only do

00:28:13,549 --> 00:28:17,320
importance and notice that you don't

00:28:15,590 --> 00:28:20,929
need to give them the password anymore

00:28:17,320 --> 00:28:23,389
in order to do an import or if they can

00:28:20,929 --> 00:28:24,950
only do an export then you can give them

00:28:23,389 --> 00:28:34,009
a connection object that only allows

00:28:24,950 --> 00:28:35,840
them to do an export to to the table so

00:28:34,009 --> 00:28:38,480
this is this is more secure because

00:28:35,840 --> 00:28:40,639
you're routing through the scoop server

00:28:38,480 --> 00:28:43,970
rather than opening up access to all

00:28:40,639 --> 00:28:45,529
clients to perform jobs where you

00:28:43,970 --> 00:28:48,350
previously in scoop when we require

00:28:45,529 --> 00:28:50,659
direct access to hai van HBase going for

00:28:48,350 --> 00:28:51,889
we no longer need this direct access and

00:28:50,659 --> 00:28:57,109
therefore it's going to be significantly

00:28:51,889 --> 00:28:58,850
more secure so to wrap it up you know

00:28:57,109 --> 00:29:02,029
but we talked about the design goals we

00:28:58,850 --> 00:29:05,179
talked about the driving ideas here's

00:29:02,029 --> 00:29:07,820
how scoop to address as usability and

00:29:05,179 --> 00:29:10,369
extensibility in a nutshell from a

00:29:07,820 --> 00:29:13,489
usability perspective we've identified

00:29:10,369 --> 00:29:15,559
you know of first class objects which

00:29:13,489 --> 00:29:16,999
matter to our users the connections and

00:29:15,559 --> 00:29:19,039
the jobs that's what they're mostly

00:29:16,999 --> 00:29:22,399
interested in they are cleanly separated

00:29:19,039 --> 00:29:24,350
along responsibility boundaries so their

00:29:22,399 --> 00:29:27,100
separation of concerns which ii very

00:29:24,350 --> 00:29:28,690
very well ties into the role base

00:29:27,100 --> 00:29:32,470
model that we would like to implement on

00:29:28,690 --> 00:29:34,750
top of this product having it metadata

00:29:32,470 --> 00:29:37,510
driven through connectors allows us to

00:29:34,750 --> 00:29:39,580
make these objects very specific to the

00:29:37,510 --> 00:29:41,950
domain in which they operate so if

00:29:39,580 --> 00:29:43,870
you're going against Netezza you will be

00:29:41,950 --> 00:29:45,669
speaking the t's of cavalry if you're

00:29:43,870 --> 00:29:49,510
going against oracle you'd be speaking

00:29:45,669 --> 00:29:51,400
oracle cavalry and so on so forth one of

00:29:49,510 --> 00:29:53,380
the things that Scoob Doo does the

00:29:51,400 --> 00:29:55,809
framework does is it and it requires

00:29:53,380 --> 00:29:57,460
that these connectors write data into

00:29:55,809 --> 00:30:02,080
what is called the intermediate data

00:29:57,460 --> 00:30:03,850
representation which IDF or IDR you

00:30:02,080 --> 00:30:05,710
would find plenty of discussion about

00:30:03,850 --> 00:30:09,460
this on our wiki page and our mailing

00:30:05,710 --> 00:30:13,450
list the basic idea behind this is that

00:30:09,460 --> 00:30:15,490
the connectors have a very well

00:30:13,450 --> 00:30:19,390
specified minimal set of functionality

00:30:15,490 --> 00:30:21,220
that they need to address contrasting it

00:30:19,390 --> 00:30:23,530
with scoop one where the connectors were

00:30:21,220 --> 00:30:27,280
supposed expected to populate the HBase

00:30:23,530 --> 00:30:29,590
or hi that's no longer needed because

00:30:27,280 --> 00:30:32,470
all of that processing folds into the

00:30:29,590 --> 00:30:34,030
downstream functionality so the

00:30:32,470 --> 00:30:36,370
connectors do the data transfer and the

00:30:34,030 --> 00:30:38,710
scoop framework does the rest so much

00:30:36,370 --> 00:30:41,080
more extensible from a connector

00:30:38,710 --> 00:30:43,270
development perspective we expect a lot

00:30:41,080 --> 00:30:46,289
of vendors to jump and help out and pick

00:30:43,270 --> 00:30:48,820
up like implementation of connectors

00:30:46,289 --> 00:30:50,679
definitely their experience is going to

00:30:48,820 --> 00:30:52,630
be much better as to what their

00:30:50,679 --> 00:30:53,980
experience was contrasting with how they

00:30:52,630 --> 00:31:01,590
had the connectors roll out for scoop

00:30:53,980 --> 00:31:01,590
one so with that we will attempt to demo

00:31:13,290 --> 00:31:17,890
so I don't know if you guys know this

00:31:15,400 --> 00:31:21,000
but demos usually don't work so don't

00:31:17,890 --> 00:31:24,419
just just to set the level expectations

00:31:21,000 --> 00:31:24,419
all trying

00:32:00,260 --> 00:32:09,380
alright so this is my vm on which i have

00:32:05,120 --> 00:32:12,720
installed a dupe so i'm actually using

00:32:09,380 --> 00:32:14,760
cloud or as distribution of apache

00:32:12,720 --> 00:32:20,880
hadoop full point do that got released

00:32:14,760 --> 00:32:28,130
on tuesday right off of the of the press

00:32:20,880 --> 00:32:28,130
press fresh off the shelf if I mean fine

00:32:30,800 --> 00:32:38,670
so I've got all my demons running all

00:32:34,170 --> 00:32:40,080
the the data node it's a pseudo

00:32:38,670 --> 00:32:45,390
distributed installation that's running

00:32:40,080 --> 00:32:48,420
solely on this vm if I do can you guys

00:32:45,390 --> 00:32:51,170
read it do you want a bigger font okay

00:32:48,420 --> 00:32:51,170
sorry

00:32:59,640 --> 00:33:02,880
any better

00:33:12,299 --> 00:33:20,140
so these are the hadoop demons that i

00:33:14,950 --> 00:33:33,159
just showed a moment ago so if i look at

00:33:20,140 --> 00:33:36,010
what I have under HDFS so I have you

00:33:33,159 --> 00:33:39,940
know a directory for myself and a

00:33:36,010 --> 00:33:45,490
directly for root and let's see what's

00:33:39,940 --> 00:33:49,210
under root not there's nothing under

00:33:45,490 --> 00:33:51,370
root it sits as an empty directory now

00:33:49,210 --> 00:33:54,700
on this very system i also have

00:33:51,370 --> 00:33:56,679
installed scoop to server and scoop to

00:33:54,700 --> 00:33:58,419
clients the scoop to server ncds

00:33:56,679 --> 00:33:59,889
distribution comes as a package you

00:33:58,419 --> 00:34:01,600
install that package and it configures

00:33:59,889 --> 00:34:02,860
itself there's there's you know some

00:34:01,600 --> 00:34:06,760
configuration you may need to override

00:34:02,860 --> 00:34:08,230
depending upon how you set cdh up but

00:34:06,760 --> 00:34:09,399
I've taken care of all of that I'm not

00:34:08,230 --> 00:34:11,020
going to bore you guys with that detail

00:34:09,399 --> 00:34:14,080
the documentation kind of walks you

00:34:11,020 --> 00:34:18,570
through that so one way by which i can

00:34:14,080 --> 00:34:22,980
make sure that the server is running is

00:34:18,570 --> 00:34:22,980
alright i can get to the bottom bar

00:34:30,580 --> 00:34:33,270
sorry

00:34:47,470 --> 00:34:51,010
no pounds

00:34:59,030 --> 00:35:11,640
so by default the server runs on how

00:35:02,820 --> 00:35:13,110
it's not only kiss oh yeah I think I

00:35:11,640 --> 00:35:15,440
should mirror the display Catlin you're

00:35:13,110 --> 00:35:15,440
a genius

00:35:42,150 --> 00:35:45,390
much better

00:35:46,290 --> 00:35:54,000
okay so there it is I have you know the

00:35:49,950 --> 00:35:57,990
server running this is a dummy page the

00:35:54,000 --> 00:36:00,750
actual scoop logic the the server logic

00:35:57,990 --> 00:36:03,960
sits under the context route called

00:36:00,750 --> 00:36:12,720
scoop and then I can query what version

00:36:03,960 --> 00:36:14,520
it's running by doing this so here I

00:36:12,720 --> 00:36:18,330
have you know I have a protocol to

00:36:14,520 --> 00:36:23,310
region one this is the date and so on so

00:36:18,330 --> 00:36:25,440
forth there is another way of accessing

00:36:23,310 --> 00:36:28,680
this information which is what via the

00:36:25,440 --> 00:36:34,920
scoop client so I can start the scoop

00:36:28,680 --> 00:36:37,350
client by just typing scoop do I can do

00:36:34,920 --> 00:36:39,350
I can associate this plan for the

00:36:37,350 --> 00:36:45,600
specific server i can say set server

00:36:39,350 --> 00:36:52,050
minus minus host localhost and then i

00:36:45,600 --> 00:36:54,030
can do show version all so here it is it

00:36:52,050 --> 00:36:58,380
actually shows me the server version is

00:36:54,030 --> 00:37:00,660
199 dot one cdh 420 and the client

00:36:58,380 --> 00:37:03,030
origin is also one 9901 the reason why

00:37:00,660 --> 00:37:06,570
it's 199 dot one is because we weren't

00:37:03,030 --> 00:37:11,520
ready to call it scoop to yet it's it's

00:37:06,570 --> 00:37:13,700
getting close now as I mentioned what

00:37:11,520 --> 00:37:15,750
the server does is it actually enables

00:37:13,700 --> 00:37:17,610
connectors to register their metadata

00:37:15,750 --> 00:37:19,680
and by default there is one connector

00:37:17,610 --> 00:37:21,660
that ships with scoop server is which is

00:37:19,680 --> 00:37:23,310
the generate jdbc connector so I'm just

00:37:21,660 --> 00:37:28,490
going to query the server using this

00:37:23,310 --> 00:37:28,490
tool to see if that connector is there

00:37:31,230 --> 00:37:43,000
so a bunch of stuff got printed out

00:37:34,440 --> 00:37:44,559
mostly it is all metadata so here was

00:37:43,000 --> 00:37:47,680
the command i tabbed scoop connector

00:37:44,559 --> 00:37:51,490
minus all show show connector minus all

00:37:47,680 --> 00:37:54,309
it says one connector to show and the

00:37:51,490 --> 00:37:57,940
connector with ID one is the generic

00:37:54,309 --> 00:38:00,760
jdbc connector so that's the connector

00:37:57,940 --> 00:38:02,559
we will use i also want to show you guys

00:38:00,760 --> 00:38:06,780
that I don't have any jobs or any

00:38:02,559 --> 00:38:10,030
connection seat at the moment so show

00:38:06,780 --> 00:38:13,780
connection minus minus ball 0

00:38:10,030 --> 00:38:15,670
connections to show show job- what's all

00:38:13,780 --> 00:38:17,799
there are no jobs so the first thing

00:38:15,670 --> 00:38:20,710
I'll do is I'll create a connection and

00:38:17,799 --> 00:38:23,650
this connection will go against a my

00:38:20,710 --> 00:38:26,079
sequel database I for that purpose i

00:38:23,650 --> 00:38:45,520
have the my sequel database up set up

00:38:26,079 --> 00:38:51,400
already let's see so i've got a table

00:38:45,520 --> 00:38:53,950
called intro and it has some data so

00:38:51,400 --> 00:38:57,510
here's the intro table it's it's all all

00:38:53,950 --> 00:38:59,770
the cities of my favorite cities and

00:38:57,510 --> 00:39:03,069
this will be the table will try to move

00:38:59,770 --> 00:39:04,990
into Hadoop true scoop using using the

00:39:03,069 --> 00:39:07,750
scoop to system so the first thing to do

00:39:04,990 --> 00:39:12,190
is to create a connection for this so we

00:39:07,750 --> 00:39:15,250
will do create connection minus minus

00:39:12,190 --> 00:39:17,319
CID that's the short for connector ID

00:39:15,250 --> 00:39:20,230
connections or die two connectors and

00:39:17,319 --> 00:39:25,059
the connector ID is one we just saw the

00:39:20,230 --> 00:39:26,829
generic jdbc connector has the ID one so

00:39:25,059 --> 00:39:31,240
please fill the following values the

00:39:26,829 --> 00:39:34,900
name is demo connection the JDBC driver

00:39:31,240 --> 00:39:37,999
class 4 will be for my sequel com my

00:39:34,900 --> 00:39:41,449
sequel jdbc driver

00:39:37,999 --> 00:39:45,519
and the Kinect string would be jdbc

00:39:41,449 --> 00:39:49,399
colon my SQL colon slash slash local

00:39:45,519 --> 00:39:51,739
host scoop that's that's my database

00:39:49,399 --> 00:39:55,909
name scoop and the user name is scoop

00:39:51,739 --> 00:39:59,929
user and password is password the night

00:39:55,909 --> 00:40:03,889
I've been right we'll find out max

00:39:59,929 --> 00:40:05,779
connections for so now a new connection

00:40:03,889 --> 00:40:09,319
was successfully created with validation

00:40:05,779 --> 00:40:18,259
status fine persist 93 let me see if I

00:40:09,319 --> 00:40:20,089
can update connection all right updating

00:40:18,259 --> 00:40:22,339
connection so this allows me to go edit

00:40:20,089 --> 00:40:25,099
these objects I'm updating demo

00:40:22,339 --> 00:40:27,289
connection the driver classes this the

00:40:25,099 --> 00:40:29,269
Kinect string is this user name this

00:40:27,289 --> 00:40:36,799
password this time I should type it

00:40:29,269 --> 00:40:38,809
right yay max connections for so

00:40:36,799 --> 00:40:40,009
connection was updated successfully now

00:40:38,809 --> 00:40:45,919
the next thing i'll do is i'll create a

00:40:40,009 --> 00:40:47,539
job so create job with connection ID xit

00:40:45,919 --> 00:40:50,869
because you can't use cid so it was

00:40:47,539 --> 00:40:52,789
exciting the connection ID is 3 because

00:40:50,869 --> 00:40:57,649
that's that's the connection we're going

00:40:52,789 --> 00:41:01,779
to be using with this job minus minus

00:40:57,649 --> 00:41:04,669
type import we're trying to import data

00:41:01,779 --> 00:41:07,159
and the import like import and export

00:41:04,669 --> 00:41:08,689
our Hadoop centric so when you say

00:41:07,159 --> 00:41:11,509
importance moving data into Hadoop

00:41:08,689 --> 00:41:15,349
export is moving data out of her do so

00:41:11,509 --> 00:41:18,949
the name is a demo job the table name is

00:41:15,349 --> 00:41:20,329
intro we don't need a sequel query we

00:41:18,949 --> 00:41:24,229
don't need to specify columns or

00:41:20,329 --> 00:41:26,449
partitions or boundaries so there's one

00:41:24,229 --> 00:41:29,029
storage type can available in this

00:41:26,449 --> 00:41:32,059
server which is sdfs so we'll use that

00:41:29,029 --> 00:41:34,729
and we will output our format as ass

00:41:32,059 --> 00:41:39,859
text file and the output directory will

00:41:34,729 --> 00:41:41,779
be user root intro that's for the

00:41:39,859 --> 00:41:44,809
throttling and we don't have to enter

00:41:41,779 --> 00:41:49,599
any values there so we got a new job

00:41:44,809 --> 00:41:51,350
created with ID three so I have my

00:41:49,599 --> 00:41:55,030
Hadoop

00:41:51,350 --> 00:41:55,030
demons running here which we can query

00:41:57,580 --> 00:42:04,280
so that's my local Mr job tracker I'm

00:42:01,970 --> 00:42:13,010
going to launch this job now and hope

00:42:04,280 --> 00:42:16,190
for the best so that's my job ID 3 i'm

00:42:13,010 --> 00:42:20,060
going to submit it and request starting

00:42:16,190 --> 00:42:23,240
of that submission so the status is

00:42:20,060 --> 00:42:27,220
booting i can query the status of this

00:42:23,240 --> 00:42:31,700
job any time I can say submission status

00:42:27,220 --> 00:42:35,600
minus minus J id3 and it says running

00:42:31,700 --> 00:42:38,480
I'll probably see it here yeah there is

00:42:35,600 --> 00:42:42,170
this job ID running this is the same ID

00:42:38,480 --> 00:42:49,010
003 that you see over here so that's the

00:42:42,170 --> 00:42:55,190
external job ID and there you go the job

00:42:49,010 --> 00:43:01,490
actually succeeded remarkable alright so

00:42:55,190 --> 00:43:04,040
to the dub job succeeded and yeah the

00:43:01,490 --> 00:43:05,990
you know there were four mappers the map

00:43:04,040 --> 00:43:08,720
total for that was the number of

00:43:05,990 --> 00:43:15,050
connections that it's found out so we go

00:43:08,720 --> 00:43:19,580
back to our command line to see whether

00:43:15,050 --> 00:43:25,460
the data actually moved so I do fs- LS

00:43:19,580 --> 00:43:27,170
user root now there is a directory

00:43:25,460 --> 00:43:30,890
called intro let's see what's inside the

00:43:27,170 --> 00:43:35,350
intro directory oh there are so many

00:43:30,890 --> 00:43:35,350
files maybe we should try and get them

00:43:43,790 --> 00:43:52,170
that's the data text format done on the

00:43:47,190 --> 00:43:56,000
server side so it actually worked let's

00:43:52,170 --> 00:43:56,000
go back to the presentation

00:44:21,480 --> 00:44:31,680
thanks Arvin for a very successful

00:44:23,220 --> 00:44:34,800
dental the current status of scoop to is

00:44:31,680 --> 00:44:37,220
that we have a first cut out as as

00:44:34,800 --> 00:44:40,380
arvind mentioned it was a Christmas gift

00:44:37,220 --> 00:44:42,770
for all of us in the community bits and

00:44:40,380 --> 00:44:46,140
docks are up at scooped-out Apache org

00:44:42,770 --> 00:44:49,380
scoop to is is the primary focus of the

00:44:46,140 --> 00:44:52,700
the scoop community and we welcome your

00:44:49,380 --> 00:44:57,510
feedback we welcome your suggestions and

00:44:52,700 --> 00:45:02,450
most importantly we need you and want

00:44:57,510 --> 00:45:04,830
you to contribute code Doc's use cases

00:45:02,450 --> 00:45:08,760
you know you name it we wanted this is a

00:45:04,830 --> 00:45:10,740
significant we architecture of scoop for

00:45:08,760 --> 00:45:14,060
to better and it's only going to be

00:45:10,740 --> 00:45:16,950
better if the community can assist I

00:45:14,060 --> 00:45:23,100
think that's the beauty of Apache and I

00:45:16,950 --> 00:45:25,520
look forward to your contributions open

00:45:23,100 --> 00:45:25,520
to questions

00:45:27,060 --> 00:45:33,869
try yeah I wish I can make a question if

00:45:32,109 --> 00:45:36,700
you move to like a client-server model

00:45:33,869 --> 00:45:38,350
so what kind of oil when it comes to

00:45:36,700 --> 00:45:39,550
like stealing whatever would you know

00:45:38,350 --> 00:45:43,600
what will pen bottles there on the

00:45:39,550 --> 00:45:44,859
server side masters wave plans or you

00:45:43,600 --> 00:45:46,470
know what kind of redundancy are you

00:45:44,859 --> 00:45:48,910
going to have is that part of the plan

00:45:46,470 --> 00:45:52,510
or is it already here sure so the

00:45:48,910 --> 00:45:54,640
question is what's the scalability model

00:45:52,510 --> 00:45:57,580
now that scoop is transitioning over

00:45:54,640 --> 00:46:01,150
into the client-server landscape so that

00:45:57,580 --> 00:46:04,119
to answer that question one of that's

00:46:01,150 --> 00:46:06,970
been one of the primary underlying goals

00:46:04,119 --> 00:46:10,300
for the implementation so as a result we

00:46:06,970 --> 00:46:11,980
don't have any state management you know

00:46:10,300 --> 00:46:13,960
it's a completely stateless server all

00:46:11,980 --> 00:46:16,150
of the state is externalized to the

00:46:13,960 --> 00:46:17,859
metadata repository which allows us to

00:46:16,150 --> 00:46:20,350
have multiple instances of scoop server

00:46:17,859 --> 00:46:23,609
if you need to scale out so that's

00:46:20,350 --> 00:46:23,609
basically the model we're falling

00:46:27,840 --> 00:46:32,150
to administrators and operators

00:46:46,249 --> 00:46:52,440
so the question is with the move towards

00:46:49,549 --> 00:46:54,210
the different roles for administrators

00:46:52,440 --> 00:46:57,150
and operators would there be different

00:46:54,210 --> 00:47:11,460
number of connections necessary for

00:46:57,150 --> 00:47:13,170
different users is that did I okay so

00:47:11,460 --> 00:47:14,730
the question is can we have like a fine

00:47:13,170 --> 00:47:16,529
brain access at the administrative level

00:47:14,730 --> 00:47:18,599
four different groups of at this point

00:47:16,529 --> 00:47:20,549
in time it's you know we don't have the

00:47:18,599 --> 00:47:22,650
first cut yet so it could shape up

00:47:20,549 --> 00:47:24,210
either way and I think the best way you

00:47:22,650 --> 00:47:25,559
can drive it towards your specific

00:47:24,210 --> 00:47:27,630
requirements by being active on the

00:47:25,559 --> 00:47:30,359
community mailing list and sending in

00:47:27,630 --> 00:47:31,799
these requirements I think the first cut

00:47:30,359 --> 00:47:34,890
that we will try to implement would be

00:47:31,799 --> 00:47:36,690
fairly straightforward in that there

00:47:34,890 --> 00:47:40,710
would be one admin role and one Operator

00:47:36,690 --> 00:47:42,960
role anymore finer grain segregation

00:47:40,710 --> 00:47:48,710
would probably evolved over a period of

00:47:42,960 --> 00:47:48,710
time you had a question

00:48:01,880 --> 00:48:07,260
so the question is where does the

00:48:05,460 --> 00:48:11,309
administrators username and password

00:48:07,260 --> 00:48:14,430
validated or used or stored so scoop

00:48:11,309 --> 00:48:16,920
would not do user management scoop is

00:48:14,430 --> 00:48:18,869
not in the business for for doing the

00:48:16,920 --> 00:48:21,690
actual security and user management

00:48:18,869 --> 00:48:26,010
aspects of a secure system all of that

00:48:21,690 --> 00:48:27,930
we expect to be part of the homogeneous

00:48:26,010 --> 00:48:29,700
security infrastructure across Hadoop

00:48:27,930 --> 00:48:33,150
related projects which at this point in

00:48:29,700 --> 00:48:35,730
time is Kerberos so we would expect the

00:48:33,150 --> 00:48:36,930
users to use kerberos that would be the

00:48:35,730 --> 00:48:38,940
first cut implementation there's been

00:48:36,930 --> 00:48:42,630
some discussion about it we would expect

00:48:38,940 --> 00:48:44,880
the administrators to sign in using

00:48:42,630 --> 00:48:47,160
their specific credentials using K in it

00:48:44,880 --> 00:48:49,200
or whatever they use and then from that

00:48:47,160 --> 00:48:53,369
point onwards scoop will be able to pick

00:48:49,200 --> 00:48:55,140
up that token and then propagate that so

00:48:53,369 --> 00:48:58,760
it's much much like how scoop one

00:48:55,140 --> 00:48:58,760
enables Kerberos integration today

00:49:00,290 --> 00:49:09,260
the me traitor he can create a conectar

00:49:04,460 --> 00:49:12,310
before operation to use so the connector

00:49:09,260 --> 00:49:15,350
you your demo you put in the

00:49:12,310 --> 00:49:17,810
continuities username and password yes

00:49:15,350 --> 00:49:20,780
so the youth Teddy bee gees username and

00:49:17,810 --> 00:49:23,360
password is going connector yes in the

00:49:20,780 --> 00:49:25,280
connection object so in the demo the

00:49:23,360 --> 00:49:27,620
connection objects toward the username

00:49:25,280 --> 00:49:29,960
and password needed for the JDBC

00:49:27,620 --> 00:49:32,810
connectivity what you didn't see in this

00:49:29,960 --> 00:49:34,190
demo is the fact that that there are two

00:49:32,810 --> 00:49:36,820
separate roles you know because that's

00:49:34,190 --> 00:49:39,440
not implemented yet but the connection

00:49:36,820 --> 00:49:43,280
edits and modifications will be only

00:49:39,440 --> 00:49:45,110
done accessible to admins and the

00:49:43,280 --> 00:49:52,610
operators will only be able to use the

00:49:45,110 --> 00:49:54,620
connections yes the connection object is

00:49:52,610 --> 00:49:57,160
safely kept in the database robot the

00:49:54,620 --> 00:49:57,160
metadata repository

00:50:05,270 --> 00:50:12,690
so the so the question is can scoop be

00:50:09,330 --> 00:50:15,300
used as ETL for regular ingest from

00:50:12,690 --> 00:50:20,600
online databases this is a loaded

00:50:15,300 --> 00:50:20,600
question that the term ETL is fairly

00:50:20,960 --> 00:50:25,890
heavy scoped in terms of you etl means

00:50:24,960 --> 00:50:31,140
different things to different

00:50:25,890 --> 00:50:32,580
enterprises I you know I if you if you

00:50:31,140 --> 00:50:34,290
compare scoop with the system like

00:50:32,580 --> 00:50:37,320
informatica probably not scoop is not

00:50:34,290 --> 00:50:40,920
going to go into that segment of of

00:50:37,320 --> 00:50:43,230
market but there are times when minor

00:50:40,920 --> 00:50:44,970
data modifications are necessary in

00:50:43,230 --> 00:50:46,200
order for making them available for the

00:50:44,970 --> 00:50:48,030
downstream processing I'll give you an

00:50:46,200 --> 00:50:51,000
example and it's always this also

00:50:48,030 --> 00:50:53,790
happens with scoop one people use hive

00:50:51,000 --> 00:50:55,710
people use external databases eventually

00:50:53,790 --> 00:50:59,100
they would like to run queries in their

00:50:55,710 --> 00:51:01,050
hive warehouse these queries require the

00:50:59,100 --> 00:51:03,570
data to be available within hive and

00:51:01,050 --> 00:51:05,490
people would use scoop one due to

00:51:03,570 --> 00:51:09,440
transmit this data from from their

00:51:05,490 --> 00:51:12,900
external data stores into in to hi5

00:51:09,440 --> 00:51:15,690
warehouse the problem is that external

00:51:12,900 --> 00:51:17,670
data stores can deal with things such as

00:51:15,690 --> 00:51:21,030
newline characters happening within

00:51:17,670 --> 00:51:22,830
string data that hive cannot it's a very

00:51:21,030 --> 00:51:24,660
very good example there's a lot of lot

00:51:22,830 --> 00:51:26,640
of users out there who have data that

00:51:24,660 --> 00:51:28,440
has new line characters in it and hive

00:51:26,640 --> 00:51:31,140
will just break because new lines are

00:51:28,440 --> 00:51:34,050
wrecked record terminators for hive no

00:51:31,140 --> 00:51:36,510
matter what if it's text or any data so

00:51:34,050 --> 00:51:39,720
scoop comes with options to filter those

00:51:36,510 --> 00:51:42,030
things out that you can consider as an

00:51:39,720 --> 00:51:43,380
inline transformation and if that's an

00:51:42,030 --> 00:51:47,040
inline transformation you could argue

00:51:43,380 --> 00:51:49,350
that that's effectively etl but that's a

00:51:47,040 --> 00:51:51,990
very I mean that's a negligible aspect

00:51:49,350 --> 00:51:53,700
of ETL that probably doesn't even

00:51:51,990 --> 00:51:56,880
marriage itself being associated with

00:51:53,700 --> 00:51:58,950
ETL it's more like data preparation so

00:51:56,880 --> 00:52:00,810
yes scoop will be doing data preparation

00:51:58,950 --> 00:52:04,350
in order for it to become more

00:52:00,810 --> 00:52:06,630
accessible to downstream systems but not

00:52:04,350 --> 00:52:09,480
quite in that et al manner

00:52:06,630 --> 00:52:11,789
right so just to tag on to what I've

00:52:09,480 --> 00:52:13,920
written was saying this coupe originally

00:52:11,789 --> 00:52:18,690
was meant to be a transfer tool and

00:52:13,920 --> 00:52:20,970
scoop to is going to continue to be for

00:52:18,690 --> 00:52:23,130
transfer purposes but with more of a

00:52:20,970 --> 00:52:24,809
service aspect so what we've discussed

00:52:23,130 --> 00:52:26,400
here today with scoop to and what you

00:52:24,809 --> 00:52:28,890
can play around with with the first cut

00:52:26,400 --> 00:52:30,630
of scoop to is it's going to be easier

00:52:28,890 --> 00:52:32,009
to use it's going to be easier to

00:52:30,630 --> 00:52:35,009
develop connectors on putting more

00:52:32,009 --> 00:52:38,220
secure but at the end of the day scoops

00:52:35,009 --> 00:52:41,220
Charter is to be a transfer tool and so

00:52:38,220 --> 00:52:43,529
as a result that the scope of being etl

00:52:41,220 --> 00:52:46,490
is beyond that's to beyond the scope of

00:52:43,529 --> 00:52:46,490
scoop line s coupe to

00:52:58,020 --> 00:53:04,960
so the question is have there been any

00:53:01,270 --> 00:53:10,630
use cases for doing encryption / data as

00:53:04,960 --> 00:53:12,790
its transferred yes and no yes because

00:53:10,630 --> 00:53:17,050
that people have expressed concerns

00:53:12,790 --> 00:53:18,700
about you know the fact that data that

00:53:17,050 --> 00:53:20,920
is transferred by scoop becomes

00:53:18,700 --> 00:53:22,420
accessible pretty much immediately to

00:53:20,920 --> 00:53:24,550
any processes that are running as a

00:53:22,420 --> 00:53:27,700
scoop you know user whoever's running

00:53:24,550 --> 00:53:29,680
script so things like obfuscation was

00:53:27,700 --> 00:53:31,750
requested in the community there there's

00:53:29,680 --> 00:53:33,040
some male records for that but I don't

00:53:31,750 --> 00:53:36,790
think we have implemented any of that

00:53:33,040 --> 00:53:38,440
yet and again you know as the case with

00:53:36,790 --> 00:53:45,070
any functionality no matter how small or

00:53:38,440 --> 00:53:46,960
big patches are welcome right to detect

00:53:45,070 --> 00:53:53,410
aguilon of what Arvind said there as

00:53:46,960 --> 00:53:55,210
well what what I've noticed with so I'm

00:53:53,410 --> 00:53:59,410
also a scoop touch matter expert at

00:53:55,210 --> 00:54:01,869
Cloudera and most of the scoop issues

00:53:59,410 --> 00:54:03,310
that I've seen regards to security are

00:54:01,869 --> 00:54:08,050
primarily em to your earlier question

00:54:03,310 --> 00:54:11,230
about office gating the password rather

00:54:08,050 --> 00:54:13,089
than the data because it's it seems to

00:54:11,230 --> 00:54:16,000
be that's that's kind of beyond the

00:54:13,089 --> 00:54:18,280
scope of scoop and and you know securing

00:54:16,000 --> 00:54:20,859
the data it's more of new Oracle's worry

00:54:18,280 --> 00:54:23,410
or or you know Hadoop's worry right but

00:54:20,859 --> 00:54:26,320
just making sure that the password is

00:54:23,410 --> 00:54:28,660
safe and that's the number one security

00:54:26,320 --> 00:54:30,820
concern I see mark that's a really great

00:54:28,660 --> 00:54:32,800
use case i look forward to jury you're

00:54:30,820 --> 00:54:35,760
going to file for that but there's not

00:54:32,800 --> 00:54:35,760
something we commonly see

00:54:38,609 --> 00:54:52,079
any more questions you have been in

00:54:46,920 --> 00:54:59,220
reference you have garbage too many jobs

00:54:52,079 --> 00:55:02,609
to run by that time what you just one

00:54:59,220 --> 00:55:05,369
so so the question is if you have a

00:55:02,609 --> 00:55:07,890
million record table or more in a

00:55:05,369 --> 00:55:10,500
database do you have to partition it

00:55:07,890 --> 00:55:13,680
into multiple jobs or not the answer is

00:55:10,500 --> 00:55:15,840
no scoop takes care of that you will be

00:55:13,680 --> 00:55:17,130
able to you know when you even if you

00:55:15,840 --> 00:55:20,280
remember when we were creating the

00:55:17,130 --> 00:55:22,050
connection object there there was the

00:55:20,280 --> 00:55:25,230
number of connections that was specified

00:55:22,050 --> 00:55:27,390
as the maximum and scoop will allow the

00:55:25,230 --> 00:55:29,580
framework will allow the number of

00:55:27,390 --> 00:55:33,170
mappers to expand to that in order to

00:55:29,580 --> 00:55:43,109
paralyze the import of large data sets

00:55:33,170 --> 00:55:45,840
scoop it's a streaming system so and it

00:55:43,109 --> 00:55:48,510
also is a function of what the connector

00:55:45,840 --> 00:55:49,980
does different connectors there there

00:55:48,510 --> 00:55:51,930
are direct connectors that exists for

00:55:49,980 --> 00:55:53,520
scoop one that don't damage it be

00:55:51,930 --> 00:55:55,830
encoded for scoop too but those

00:55:53,520 --> 00:55:57,570
connectors use native utilities that the

00:55:55,830 --> 00:55:59,760
database provides like you know my

00:55:57,570 --> 00:56:01,590
sequel dump for example it's extremely

00:55:59,760 --> 00:56:03,960
fast and very well optimized for the

00:56:01,590 --> 00:56:06,300
internal formats that my sequel uses so

00:56:03,960 --> 00:56:08,160
if you have a shorted instance of like a

00:56:06,300 --> 00:56:11,040
table that spans across you know maybe

00:56:08,160 --> 00:56:13,619
maybe hundred nodes of it which has like

00:56:11,040 --> 00:56:15,869
many millions of rows of data using my

00:56:13,619 --> 00:56:17,760
sequel dump would make sure that of the

00:56:15,869 --> 00:56:19,290
discovery in management and transport of

00:56:17,760 --> 00:56:21,359
the data is done in the most optimal

00:56:19,290 --> 00:56:24,599
manner and scoop will ensure that it's

00:56:21,359 --> 00:56:26,280
it's it's invoking the my sequel dump

00:56:24,599 --> 00:56:28,349
processes in as many notes as you've

00:56:26,280 --> 00:56:30,210
specified it to scale with so

00:56:28,349 --> 00:56:32,220
effectively it's it's it's a self

00:56:30,210 --> 00:56:36,660
managing system for the most part you

00:56:32,220 --> 00:56:41,900
would you can tune it and tweak it right

00:56:36,660 --> 00:56:41,900
so long Londo science um Burt we're done

00:56:42,920 --> 00:56:48,200
we can drink ticket a fine I thank

00:56:45,930 --> 00:56:48,200
everyone

00:56:49,329 --> 00:56:51,390

YouTube URL: https://www.youtube.com/watch?v=irF7MAtDCOY


