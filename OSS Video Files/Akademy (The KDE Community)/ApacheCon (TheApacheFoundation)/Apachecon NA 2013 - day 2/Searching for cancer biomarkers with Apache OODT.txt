Title: Searching for cancer biomarkers with Apache OODT
Publication date: 2013-10-17
Playlist: Apachecon NA 2013 - day 2
Description: 
	Rishi Verma
ApacheCon NA 2013
Apache In Science
Captions: 
	00:00:00,000 --> 00:00:06,930
Chris yeah so hi everybody my name is

00:00:03,629 --> 00:00:09,420
Rishi Verma like Chris mentioned the

00:00:06,930 --> 00:00:12,860
title of my talk today is searching for

00:00:09,420 --> 00:00:15,179
cancer biomarkers with Apache ODT I

00:00:12,860 --> 00:00:17,940
guess just to get a quick assessment how

00:00:15,179 --> 00:00:20,520
many of you here don't have never

00:00:17,940 --> 00:00:24,240
interact with the ODT data processing

00:00:20,520 --> 00:00:26,010
components like workflow or okay so a

00:00:24,240 --> 00:00:28,619
couple of you okay so that's great

00:00:26,010 --> 00:00:32,070
because um yeah the point of this talk

00:00:28,619 --> 00:00:34,590
is twofold so first it's to introduce

00:00:32,070 --> 00:00:37,710
some of the science behind what we're

00:00:34,590 --> 00:00:40,770
doing for a project at JPL called ed RN

00:00:37,710 --> 00:00:42,719
and introduce the science of cancer

00:00:40,770 --> 00:00:45,570
biomarker research and then also to give

00:00:42,719 --> 00:00:47,280
an introduction to the ODT data

00:00:45,570 --> 00:00:49,320
processing technologies like workflow

00:00:47,280 --> 00:00:50,460
warfel manager things like that so if

00:00:49,320 --> 00:00:54,059
you're interested in those this is a

00:00:50,460 --> 00:00:57,930
great place to be so let me go ahead and

00:00:54,059 --> 00:01:00,390
get started so just to be more specific

00:00:57,930 --> 00:01:02,100
about the agenda for today I'm going to

00:01:00,390 --> 00:01:04,619
just quickly start out by just telling

00:01:02,100 --> 00:01:08,310
you who I am just so that you all know

00:01:04,619 --> 00:01:10,320
me and then I'm going to go into more

00:01:08,310 --> 00:01:12,780
in-depth into the science behind the

00:01:10,320 --> 00:01:15,570
project that we're doing and just try to

00:01:12,780 --> 00:01:17,700
give an explanation of how the process

00:01:15,570 --> 00:01:20,729
works and hopefully you'll find that

00:01:17,700 --> 00:01:23,549
interesting then I'll be talking about

00:01:20,729 --> 00:01:25,290
apache ODT data processing components

00:01:23,549 --> 00:01:28,680
specifically or Foe manager resource

00:01:25,290 --> 00:01:29,939
manager so the PCs workflow tools that

00:01:28,680 --> 00:01:34,250
we're using out and I'll talk about that

00:01:29,939 --> 00:01:37,229
means and then finally I'll talk about

00:01:34,250 --> 00:01:41,310
or not finally fourth on the list i'll

00:01:37,229 --> 00:01:44,250
talk about the the how we're applying

00:01:41,310 --> 00:01:46,770
those two aforementioned parts together

00:01:44,250 --> 00:01:49,020
in terms of the science and actual

00:01:46,770 --> 00:01:51,990
components that we're using to solve a

00:01:49,020 --> 00:01:53,939
real science use case and that project

00:01:51,990 --> 00:01:55,979
is called eternal Abkhaz and I'll talk a

00:01:53,939 --> 00:01:58,140
little bit more about that and finally

00:01:55,979 --> 00:02:01,200
the last thing I swear to god I'll fit

00:01:58,140 --> 00:02:03,270
everything in is to give you a quick

00:02:01,200 --> 00:02:05,250
tutorial about how to get started

00:02:03,270 --> 00:02:06,780
yourself if you want to set up a data

00:02:05,250 --> 00:02:10,379
processing system something like what

00:02:06,780 --> 00:02:13,770
we've developed so yeah without further

00:02:10,379 --> 00:02:17,810
ado let me let me go and start it so

00:02:13,770 --> 00:02:21,210
yeah that's me it's my facebook picture

00:02:17,810 --> 00:02:24,320
so let's just me hang on really tightly

00:02:21,210 --> 00:02:27,090
to a fence at sequoia national park

00:02:24,320 --> 00:02:28,890
apart from kind of you know my personal

00:02:27,090 --> 00:02:30,990
interest um I work professionally as a

00:02:28,890 --> 00:02:33,300
software engineer at NASA Jet Propulsion

00:02:30,990 --> 00:02:35,520
Laboratory and a couple of you have

00:02:33,300 --> 00:02:38,130
worked also at Indiana University before

00:02:35,520 --> 00:02:40,050
i start at JPL i'm involved in a couple

00:02:38,130 --> 00:02:42,030
different projects all revolved around

00:02:40,050 --> 00:02:44,340
similar themes but I've been working on

00:02:42,030 --> 00:02:48,300
the Curiosity rover many of you probably

00:02:44,340 --> 00:02:49,590
heard about that cancer research which

00:02:48,300 --> 00:02:53,150
is the project I'm going to be talking

00:02:49,590 --> 00:02:55,890
about today and a couple of their

00:02:53,150 --> 00:02:58,140
scientific application projects were

00:02:55,890 --> 00:03:01,920
we're using data processing data

00:02:58,140 --> 00:03:04,230
management systems to help solve a

00:03:01,920 --> 00:03:06,330
scientific use case or provide data

00:03:04,230 --> 00:03:08,580
analysis support or data management

00:03:06,330 --> 00:03:12,450
support for different missions so a

00:03:08,580 --> 00:03:13,830
couple of those are the co2 virtual

00:03:12,450 --> 00:03:15,690
science data system which is another

00:03:13,830 --> 00:03:18,900
project I work on and then also some

00:03:15,690 --> 00:03:20,400
earthquake modeling applications there's

00:03:18,900 --> 00:03:22,860
a couple of things I'm involved in and

00:03:20,400 --> 00:03:26,040
also work on ODT more recently in the

00:03:22,860 --> 00:03:28,320
last year and a half as a committer and

00:03:26,040 --> 00:03:30,120
on the project management community for

00:03:28,320 --> 00:03:33,000
that so that's a little bit about me so

00:03:30,120 --> 00:03:35,550
that you know who I am let's get into

00:03:33,000 --> 00:03:39,540
more of the heart of the talk which is a

00:03:35,550 --> 00:03:42,780
little bit about the science so the

00:03:39,540 --> 00:03:46,140
project that uh that we're working on at

00:03:42,780 --> 00:03:48,690
JPL is is really focused on a scientific

00:03:46,140 --> 00:03:51,630
use case and it's focused on trying to

00:03:48,690 --> 00:03:53,430
advanced cancer research and cancer like

00:03:51,630 --> 00:03:56,490
many of you know it's a disease that's

00:03:53,430 --> 00:03:59,120
been around for a long time and it's a

00:03:56,490 --> 00:04:02,100
disease that to this day there's no

00:03:59,120 --> 00:04:04,020
single kind of cure treatment that works

00:04:02,100 --> 00:04:06,450
very effectively there are many

00:04:04,020 --> 00:04:08,580
different things people can do but it's

00:04:06,450 --> 00:04:11,880
still very hard problem to solve the

00:04:08,580 --> 00:04:14,700
best that people can do is currently is

00:04:11,880 --> 00:04:17,760
to try to detect cancer at its earliest

00:04:14,700 --> 00:04:20,820
stages and also to try to treat it Atlas

00:04:17,760 --> 00:04:25,290
early stages so with those two ideas in

00:04:20,820 --> 00:04:26,729
mind that's where that's where it

00:04:25,290 --> 00:04:27,300
becomes useful to talk a little bit

00:04:26,729 --> 00:04:29,789
about

00:04:27,300 --> 00:04:32,310
cancer biomarkers which are trying to

00:04:29,789 --> 00:04:33,569
address those two topics so cancer by

00:04:32,310 --> 00:04:35,190
actually before I even talk about cancer

00:04:33,569 --> 00:04:37,409
biomarkers let me just talk about what

00:04:35,190 --> 00:04:39,750
biomarkers are in general just to give

00:04:37,409 --> 00:04:43,740
you an overview so biomarkers are any

00:04:39,750 --> 00:04:45,780
kind of biological entity that indicates

00:04:43,740 --> 00:04:48,389
some kind of processes going on so it's

00:04:45,780 --> 00:04:52,129
really it's pretty general term actually

00:04:48,389 --> 00:04:54,629
but it's it essentially could mean

00:04:52,129 --> 00:04:59,159
protein levels in your blood it could

00:04:54,629 --> 00:05:02,159
mean DNA expression gene expression it

00:04:59,159 --> 00:05:04,229
could be any kind of biological entity

00:05:02,159 --> 00:05:06,360
that indicates something some kind of

00:05:04,229 --> 00:05:08,789
condition and it's used in many

00:05:06,360 --> 00:05:11,400
different types of scientific fields

00:05:08,789 --> 00:05:14,009
where we're using it you know when the

00:05:11,400 --> 00:05:16,699
biological and medical realm it's also

00:05:14,009 --> 00:05:18,659
used I've heard and other types of

00:05:16,699 --> 00:05:20,490
scientific applications including

00:05:18,659 --> 00:05:22,740
geology and you know trying to figure

00:05:20,490 --> 00:05:26,099
out where an organism what type of

00:05:22,740 --> 00:05:27,840
organism exists depending on processes

00:05:26,099 --> 00:05:30,240
that go out and go on inside of a cell

00:05:27,840 --> 00:05:32,840
so there's a lot of different types of

00:05:30,240 --> 00:05:36,150
use cases for biomarkers in general

00:05:32,840 --> 00:05:39,719
cancer biomarkers as we're using them or

00:05:36,150 --> 00:05:43,590
investigate them are useful because

00:05:39,719 --> 00:05:45,900
they're trying to help identify cancer

00:05:43,590 --> 00:05:48,090
like the name suggests at its most

00:05:45,900 --> 00:05:50,610
earliest stages for a different variety

00:05:48,090 --> 00:05:52,889
of cancers so it's it's a very

00:05:50,610 --> 00:05:53,880
interesting area in the last 10-15 years

00:05:52,889 --> 00:05:56,039
or so there's been a lot more

00:05:53,880 --> 00:06:00,180
development and research going into this

00:05:56,039 --> 00:06:02,340
field which makes it an interesting

00:06:00,180 --> 00:06:05,159
field to seaworld on the next 10-15

00:06:02,340 --> 00:06:06,479
years but there's a lot of there's a lot

00:06:05,159 --> 00:06:08,520
of development going into trying to

00:06:06,479 --> 00:06:11,669
detect cancer its early stages using

00:06:08,520 --> 00:06:13,590
biomarkers so some facts about cancer

00:06:11,669 --> 00:06:16,650
biomarkers let me go ahead and start

00:06:13,590 --> 00:06:18,569
with just applications so within the

00:06:16,650 --> 00:06:20,550
cancer biomarker research realm it's

00:06:18,569 --> 00:06:22,319
used for three applications so the first

00:06:20,550 --> 00:06:24,629
is screening which means it's trying to

00:06:22,319 --> 00:06:26,849
identify biomarkers in general doing

00:06:24,629 --> 00:06:28,650
statistical analysis of what x mark is

00:06:26,849 --> 00:06:30,750
available and what their what their

00:06:28,650 --> 00:06:32,639
different applications are what we're

00:06:30,750 --> 00:06:36,409
interested in is on early detection

00:06:32,639 --> 00:06:39,060
which is what that means is basically

00:06:36,409 --> 00:06:40,289
looking for specific types of cancer

00:06:39,060 --> 00:06:42,649
biomarkers and then

00:06:40,289 --> 00:06:45,839
relating them to different types of

00:06:42,649 --> 00:06:49,680
cancers that exist in the human body and

00:06:45,839 --> 00:06:52,649
trying to detect those so before you

00:06:49,680 --> 00:06:54,300
know any kind of physical sign of a

00:06:52,649 --> 00:06:57,599
cancer like a tumor or something has

00:06:54,300 --> 00:06:59,399
developed there's small smaller

00:06:57,599 --> 00:07:01,529
indicators that cancer might be

00:06:59,399 --> 00:07:03,389
developing and those are not visible to

00:07:01,529 --> 00:07:05,580
the naked eye but through different

00:07:03,389 --> 00:07:09,169
types of tests early detection test

00:07:05,580 --> 00:07:12,259
people can try to identify and see if

00:07:09,169 --> 00:07:14,729
cancer may form and some type of patient

00:07:12,259 --> 00:07:16,919
the third application is treatment and

00:07:14,729 --> 00:07:18,689
what that means is like I made sure

00:07:16,919 --> 00:07:21,029
their cancer biomarkers are any kind of

00:07:18,689 --> 00:07:23,550
biological entity used for used for

00:07:21,029 --> 00:07:26,520
different purposes there's actually uses

00:07:23,550 --> 00:07:29,369
for it to treat some kinds of disease

00:07:26,520 --> 00:07:33,330
many common types of Kent cancer

00:07:29,369 --> 00:07:36,569
biomarkers or proteins so they can

00:07:33,330 --> 00:07:39,629
scientists and medical practitioners can

00:07:36,569 --> 00:07:41,279
use biomarkers to try to by increasing

00:07:39,629 --> 00:07:42,689
levels of proteins or decreasing levels

00:07:41,279 --> 00:07:44,519
of proteins that can actually have

00:07:42,689 --> 00:07:46,830
clinical application to try to treat

00:07:44,519 --> 00:07:48,539
different types of diseases so there's

00:07:46,830 --> 00:07:51,300
different applications for cancer

00:07:48,539 --> 00:07:55,639
biomarkers the most common types of

00:07:51,300 --> 00:08:00,269
biomarkers existing today are proteins

00:07:55,639 --> 00:08:02,729
found in blood actually and recent area

00:08:00,269 --> 00:08:06,449
of research I'd say recent in the last

00:08:02,729 --> 00:08:09,360
ten years but a fast-expanding areas

00:08:06,449 --> 00:08:11,869
using genomes and DNA to actually

00:08:09,360 --> 00:08:14,219
identify and see if some type of

00:08:11,869 --> 00:08:16,019
sequence in your DNA might actually be

00:08:14,219 --> 00:08:18,529
leading to different types of cancers

00:08:16,019 --> 00:08:21,389
forming this graph just kind of shows

00:08:18,529 --> 00:08:25,259
what current biomarkers are applicable

00:08:21,389 --> 00:08:27,779
for I think the main point here is just

00:08:25,259 --> 00:08:29,550
in general cancer biomarkers span across

00:08:27,779 --> 00:08:31,529
different types of cancers there's many

00:08:29,550 --> 00:08:33,839
differences between different types of

00:08:31,529 --> 00:08:35,969
cancers it's breast cancer and prostate

00:08:33,839 --> 00:08:38,779
cancer lung cancer things like that but

00:08:35,969 --> 00:08:41,279
right now they spend more across

00:08:38,779 --> 00:08:42,990
different types of cancers and one

00:08:41,279 --> 00:08:46,189
specifically they're ours there are

00:08:42,990 --> 00:08:49,939
cancers that spend specific ones put

00:08:46,189 --> 00:08:53,889
those are the prevalent types right now

00:08:49,939 --> 00:08:58,420
I just want to give a quick example

00:08:53,889 --> 00:09:01,509
of one type of cancer well thank you one

00:08:58,420 --> 00:09:03,609
type of cancer biomarker just to give

00:09:01,509 --> 00:09:06,699
you an idea of what it is what what it

00:09:03,609 --> 00:09:10,559
would be so one example was prostate

00:09:06,699 --> 00:09:13,540
specific antigen PSA which is a type of

00:09:10,559 --> 00:09:16,480
biomarker used to help detect prostate

00:09:13,540 --> 00:09:19,209
cancer and it the way they test for this

00:09:16,480 --> 00:09:23,049
it's usually found in prostate glands or

00:09:19,209 --> 00:09:25,089
fluids and one important point I would

00:09:23,049 --> 00:09:26,589
like to mention though like many cancer

00:09:25,089 --> 00:09:29,499
biomarkers this is still a very

00:09:26,589 --> 00:09:31,359
developing field so clinical

00:09:29,499 --> 00:09:34,149
practitioners don't use this in

00:09:31,359 --> 00:09:38,290
isolation to indicate or try to test

00:09:34,149 --> 00:09:40,299
whether a person has cancer or not they

00:09:38,290 --> 00:09:42,519
use as a part of a suite of different

00:09:40,299 --> 00:09:44,230
tests to help corroborate whether a

00:09:42,519 --> 00:09:45,819
patient might be likely to develop some

00:09:44,230 --> 00:09:47,819
kind of cancer this isn't a you know

00:09:45,819 --> 00:09:49,480
this person has this protein and

00:09:47,819 --> 00:09:50,769
therefore they're going to develop

00:09:49,480 --> 00:09:52,179
cancer in fact everybody has this

00:09:50,769 --> 00:09:54,639
protein it's just different level

00:09:52,179 --> 00:09:56,230
amounts that indicate whether type of

00:09:54,639 --> 00:09:59,860
cancer is going to develop or not so

00:09:56,230 --> 00:10:04,049
it's still developing field and there's

00:09:59,860 --> 00:10:06,339
many different types of use cases that

00:10:04,049 --> 00:10:11,829
one can use this is one at one example

00:10:06,339 --> 00:10:15,040
of a type of cancer biomarker so what I

00:10:11,829 --> 00:10:16,779
want to show is now that i've defined we

00:10:15,040 --> 00:10:18,879
kind of shown you what a cancer

00:10:16,779 --> 00:10:21,549
biomarker is what's the process that

00:10:18,879 --> 00:10:25,029
scientists typically use also from a

00:10:21,549 --> 00:10:29,169
data processing perspective to arrive

00:10:25,029 --> 00:10:31,269
and detect cancer biomarkers and and use

00:10:29,169 --> 00:10:35,019
them in an actual use case so what this

00:10:31,269 --> 00:10:38,199
is is this is basically a a pipeline you

00:10:35,019 --> 00:10:41,709
could say for identifying different

00:10:38,199 --> 00:10:43,720
types of proteins and specifically

00:10:41,709 --> 00:10:45,669
applicable to cancer biomarkers so I

00:10:43,720 --> 00:10:46,749
just want to show go through this and

00:10:45,669 --> 00:10:48,759
just show you what are the step-by-step

00:10:46,749 --> 00:10:51,389
procedures that a scientist would

00:10:48,759 --> 00:10:54,339
typically use to try to find a biomarker

00:10:51,389 --> 00:10:57,459
so first step is to collect sample

00:10:54,339 --> 00:10:58,749
tissue and actually that's all I can say

00:10:57,459 --> 00:11:00,429
about that it's very simple just collect

00:10:58,749 --> 00:11:01,779
this issue and get a hold of a tissue

00:11:00,429 --> 00:11:04,689
sample that's probably a lot harder than

00:11:01,779 --> 00:11:07,600
it I made it sound but that's the first

00:11:04,689 --> 00:11:09,490
step the second step is to basically

00:11:07,600 --> 00:11:11,550
after you've collected the tissue break

00:11:09,490 --> 00:11:13,899
it down into its protein and peptide

00:11:11,550 --> 00:11:16,660
components and people use different

00:11:13,899 --> 00:11:19,420
types of solutions many enzymes that

00:11:16,660 --> 00:11:21,220
have capabilities of breaking down

00:11:19,420 --> 00:11:23,199
tissue samples into its specific

00:11:21,220 --> 00:11:25,180
components and that's that's really the

00:11:23,199 --> 00:11:28,870
second step is to take the tissue break

00:11:25,180 --> 00:11:30,699
it down to something usable the third

00:11:28,870 --> 00:11:32,889
step would be to isolate peptides and

00:11:30,699 --> 00:11:35,079
this is again specific to a protein

00:11:32,889 --> 00:11:36,430
identification but there's different

00:11:35,079 --> 00:11:38,440
types of machines that will do this for

00:11:36,430 --> 00:11:40,000
you so I don't know if you ever remember

00:11:38,440 --> 00:11:42,430
from your physics class and things like

00:11:40,000 --> 00:11:45,750
that but there's tools like you know

00:11:42,430 --> 00:11:49,180
mass spectrometry is a very useful tool

00:11:45,750 --> 00:11:50,680
you can take different fragments of

00:11:49,180 --> 00:11:52,839
molecules and run them through magnetic

00:11:50,680 --> 00:11:54,850
fields and then it'll mass-to-charge

00:11:52,839 --> 00:11:57,430
ratio and all that good stuff will let

00:11:54,850 --> 00:11:59,949
you decide and determine specific

00:11:57,430 --> 00:12:02,649
signatures that tell you what that

00:11:59,949 --> 00:12:03,880
particular fragment is and so using

00:12:02,649 --> 00:12:07,569
those types of techniques you can go

00:12:03,880 --> 00:12:09,660
from peptides to try to specifically

00:12:07,569 --> 00:12:13,209
identify what those peptides are and

00:12:09,660 --> 00:12:15,579
this data is then stored you know on the

00:12:13,209 --> 00:12:17,709
computer and into a database where you

00:12:15,579 --> 00:12:20,350
can try to find specific matchings of

00:12:17,709 --> 00:12:21,639
what what it is what's contained inside

00:12:20,350 --> 00:12:25,720
the tissue samples that you're looking

00:12:21,639 --> 00:12:28,449
for the next step would be to and this

00:12:25,720 --> 00:12:30,519
is one of the key steps is to once

00:12:28,449 --> 00:12:33,509
you've identified the peptides to

00:12:30,519 --> 00:12:37,300
actually run that against a database of

00:12:33,509 --> 00:12:39,130
known toxins so there's many

00:12:37,300 --> 00:12:41,230
organizations out there that contain

00:12:39,130 --> 00:12:44,410
full databases for different organisms

00:12:41,230 --> 00:12:46,420
like human ecoli different organisms for

00:12:44,410 --> 00:12:50,139
what are the known toxins what are the

00:12:46,420 --> 00:12:52,480
known problematic signatures that we're

00:12:50,139 --> 00:12:54,490
looking for and so you you go through

00:12:52,480 --> 00:12:56,500
this process of taking the proteins and

00:12:54,490 --> 00:12:58,870
then trying to match them against what

00:12:56,500 --> 00:13:00,939
you already know to be problematic in

00:12:58,870 --> 00:13:03,100
that particular organism and then you

00:13:00,939 --> 00:13:05,199
give it a score and try to identify what

00:13:03,100 --> 00:13:06,970
you found final step is of course

00:13:05,199 --> 00:13:09,430
generating the reports a lot of data is

00:13:06,970 --> 00:13:10,750
generated through this process so many

00:13:09,430 --> 00:13:12,819
times a lot of the tools some of the

00:13:10,750 --> 00:13:15,730
tools we'll be talking about just

00:13:12,819 --> 00:13:18,699
generate graphical representations and

00:13:15,730 --> 00:13:21,339
reports to let you identify what it is

00:13:18,699 --> 00:13:24,220
you found through this entire process of

00:13:21,339 --> 00:13:27,100
looking at tisch sample and finding out

00:13:24,220 --> 00:13:29,860
what um would biomarkers and proteins

00:13:27,100 --> 00:13:31,480
are identified in that and again like

00:13:29,860 --> 00:13:33,070
many things this is an absolute thing

00:13:31,480 --> 00:13:35,350
these are all problem these are all

00:13:33,070 --> 00:13:37,540
probability estimates that tell you

00:13:35,350 --> 00:13:39,430
whether what the probability is that you

00:13:37,540 --> 00:13:46,600
found a particular type of peptide

00:13:39,430 --> 00:13:49,810
fragment so yeah so so now that I've

00:13:46,600 --> 00:13:54,130
kind of explained a little bit about the

00:13:49,810 --> 00:13:55,779
science behind cancer biomarker research

00:13:54,130 --> 00:13:58,810
and hopefully that gives you a little

00:13:55,779 --> 00:14:00,810
bit of an idea I'd like to talk about a

00:13:58,810 --> 00:14:04,540
little bit more in depth and about

00:14:00,810 --> 00:14:06,699
apache ODT and specifically the data

00:14:04,540 --> 00:14:08,290
processing technologies and I'll talk

00:14:06,699 --> 00:14:10,029
about how that fits in with with the

00:14:08,290 --> 00:14:15,310
science application I talked about

00:14:10,029 --> 00:14:16,810
earlier so so what is Apache ODT I know

00:14:15,310 --> 00:14:18,730
many of you are very very familiar with

00:14:16,810 --> 00:14:20,250
it but for those of you who are or not

00:14:18,730 --> 00:14:25,110
or just interesting a little bit more

00:14:20,250 --> 00:14:27,699
information about it patio DT is

00:14:25,110 --> 00:14:30,240
essentially a data management data

00:14:27,699 --> 00:14:32,680
processing technology it's a set of

00:14:30,240 --> 00:14:34,839
loosely coupled components that work

00:14:32,680 --> 00:14:37,779
well together to solve many different

00:14:34,839 --> 00:14:39,899
types of science use cases for managing

00:14:37,779 --> 00:14:42,550
data and processing data and

00:14:39,899 --> 00:14:46,810
distributing data across a distributed

00:14:42,550 --> 00:14:49,199
network so there's this diagram comes

00:14:46,810 --> 00:14:51,880
from actually from the ODT webpage but

00:14:49,199 --> 00:14:54,490
it does a good example of just kind of

00:14:51,880 --> 00:14:56,920
identifying the core components of ODT

00:14:54,490 --> 00:15:00,519
in terms of three categories and the

00:14:56,920 --> 00:15:03,130
first of those categories is the they

00:15:00,519 --> 00:15:04,600
cut off know it so that the first of

00:15:03,130 --> 00:15:08,079
those categories at the catalog and

00:15:04,600 --> 00:15:14,910
archive service or calves for short so

00:15:08,079 --> 00:15:18,389
Kaz is a subset of a DT that contains

00:15:14,910 --> 00:15:22,690
essentially a whole list of different

00:15:18,389 --> 00:15:25,120
components that focus on like the name

00:15:22,690 --> 00:15:27,310
suggests cataloging and archiving

00:15:25,120 --> 00:15:27,990
products so you have file manager which

00:15:27,310 --> 00:15:30,120
is

00:15:27,990 --> 00:15:32,720
one of the main interfaces for actually

00:15:30,120 --> 00:15:35,790
accessing products and accessing

00:15:32,720 --> 00:15:38,310
metadata about products there's a

00:15:35,790 --> 00:15:42,120
curator which is like the name suggests

00:15:38,310 --> 00:15:45,560
a service which allows you to modify

00:15:42,120 --> 00:15:48,779
metadata and improve it and curate it

00:15:45,560 --> 00:15:52,560
increase the readability and usefulness

00:15:48,779 --> 00:15:54,480
of the metadata catalog and and there's

00:15:52,560 --> 00:15:57,870
also workflow and resource and those all

00:15:54,480 --> 00:16:00,120
work very well together to to solve I

00:15:57,870 --> 00:16:04,200
would say the data management portion of

00:16:00,120 --> 00:16:05,550
ODT and these are all again loosely

00:16:04,200 --> 00:16:08,040
coupled so you could just if you just

00:16:05,550 --> 00:16:10,800
needed to store files in the basic setup

00:16:08,040 --> 00:16:13,320
such as leucine database or or leucine

00:16:10,800 --> 00:16:14,910
catalog or an our dms or something you

00:16:13,320 --> 00:16:18,480
could just use file manager if you

00:16:14,910 --> 00:16:20,209
wanted or if you wanted to you know just

00:16:18,480 --> 00:16:22,080
set up a workflow manager and

00:16:20,209 --> 00:16:23,820
incorporate with another component you

00:16:22,080 --> 00:16:27,720
could just use that so these are loosely

00:16:23,820 --> 00:16:30,570
couple components the next sub category

00:16:27,720 --> 00:16:34,350
is the grid services now this is an area

00:16:30,570 --> 00:16:36,870
where it's kind of it's a very important

00:16:34,350 --> 00:16:40,709
part of ODT it doesn't get too much

00:16:36,870 --> 00:16:44,180
limelight but it it's useful for I would

00:16:40,709 --> 00:16:46,890
say the distribution aspect of

00:16:44,180 --> 00:16:49,140
distribution aspect of ODT which is you

00:16:46,890 --> 00:16:50,640
have products across a network and how

00:16:49,140 --> 00:16:52,800
do you distribute them how do you worry

00:16:50,640 --> 00:16:55,709
for them across this just rewritten

00:16:52,800 --> 00:16:57,870
network and so product and profile

00:16:55,709 --> 00:17:00,470
provide different types of services web

00:16:57,870 --> 00:17:02,880
services to allow you access remotely

00:17:00,470 --> 00:17:07,140
organized data and actually search for

00:17:02,880 --> 00:17:10,679
it and then the final subcomponent just

00:17:07,140 --> 00:17:12,780
utilities and I would say you know just

00:17:10,679 --> 00:17:14,640
expanding that definition of utilities

00:17:12,780 --> 00:17:16,559
there's many other efforts in ODT have

00:17:14,640 --> 00:17:18,630
come up in the most recent years so you

00:17:16,559 --> 00:17:20,910
can almost think of this as a category

00:17:18,630 --> 00:17:25,530
for many other applications including

00:17:20,910 --> 00:17:28,199
web applications including monitoring so

00:17:25,530 --> 00:17:30,690
there's many other kind of small fastest

00:17:28,199 --> 00:17:33,980
ODT that are I would say kind of fit

00:17:30,690 --> 00:17:33,980
into this external category

00:17:35,779 --> 00:17:43,340
so yeah so those are the components of

00:17:41,119 --> 00:17:45,769
ODT now here I've taken the same diagram

00:17:43,340 --> 00:17:48,200
and just kind of specified in terms of

00:17:45,769 --> 00:17:50,629
data processing what are the components

00:17:48,200 --> 00:17:53,119
that are involved in the data processing

00:17:50,629 --> 00:17:56,570
aspect of ODT I would say the two core

00:17:53,119 --> 00:18:01,609
ones are workflow and resource so

00:17:56,570 --> 00:18:06,460
workflow manager is workflow for sure is

00:18:01,609 --> 00:18:09,679
a component that focuses on how do you

00:18:06,460 --> 00:18:12,200
how do you build essentially a pipeline

00:18:09,679 --> 00:18:15,830
of processing so you have different

00:18:12,200 --> 00:18:16,820
types of science algorithms or it

00:18:15,830 --> 00:18:18,409
doesn't even have to be signs but

00:18:16,820 --> 00:18:20,539
different algorithms or different

00:18:18,409 --> 00:18:23,359
programs that you want to execute in

00:18:20,539 --> 00:18:25,519
parallel or in series and workflow

00:18:23,359 --> 00:18:28,759
manager works to build that into like

00:18:25,519 --> 00:18:33,320
the name suggests a workflow resource

00:18:28,759 --> 00:18:35,409
manager is involved with how do you

00:18:33,320 --> 00:18:37,729
actually take those workflows and

00:18:35,409 --> 00:18:39,589
execute them what's what's the

00:18:37,729 --> 00:18:41,239
computational infrastructure like and so

00:18:39,589 --> 00:18:44,899
there's a clear separation between those

00:18:41,239 --> 00:18:46,729
two for a reason so that you can you can

00:18:44,899 --> 00:18:48,889
define workflows in one area and you can

00:18:46,729 --> 00:18:51,559
say how how I want to run those which

00:18:48,889 --> 00:18:53,869
nodes I want to run them in in a second

00:18:51,559 --> 00:18:56,419
facet so those are the two kind of core

00:18:53,869 --> 00:19:00,639
data processing components if there's

00:18:56,419 --> 00:19:05,419
anything you can take away from this I

00:19:00,639 --> 00:19:10,339
want to talk briefly about process

00:19:05,419 --> 00:19:19,849
control system pcs so this diagram pcs

00:19:10,339 --> 00:19:23,989
is it's a system that's used to i would

00:19:19,849 --> 00:19:25,820
say in one way improve just make it

00:19:23,989 --> 00:19:27,769
easier to understand your data

00:19:25,820 --> 00:19:30,619
processing system so it includes tools

00:19:27,769 --> 00:19:34,519
to help monitoring to monitor your data

00:19:30,619 --> 00:19:36,830
processing system and in a way allows

00:19:34,519 --> 00:19:40,099
you to think of these different loosely

00:19:36,830 --> 00:19:41,989
coupled components as components that

00:19:40,099 --> 00:19:44,389
work well together and three of the most

00:19:41,989 --> 00:19:47,269
important three important parts of a

00:19:44,389 --> 00:19:49,170
process control system our file manager

00:19:47,269 --> 00:19:51,330
Wuerffel manager and resource manager

00:19:49,170 --> 00:19:53,490
talk a little bit about the the second

00:19:51,330 --> 00:19:56,490
to but this diagram just kind of shows

00:19:53,490 --> 00:19:57,810
that you know file manager and we're

00:19:56,490 --> 00:20:01,080
file manager resource manager they all

00:19:57,810 --> 00:20:05,250
interact together to help facilitate a

00:20:01,080 --> 00:20:07,260
data processing solution so let's go a

00:20:05,250 --> 00:20:12,870
little bit more into depth into each one

00:20:07,260 --> 00:20:14,610
so file manager is the basic at its core

00:20:12,870 --> 00:20:19,020
it's a leucine catalog lets you just

00:20:14,610 --> 00:20:21,150
query for metadata or query for product

00:20:19,020 --> 00:20:23,580
locations on your file based system and

00:20:21,150 --> 00:20:26,160
that can be extended to you can store

00:20:23,580 --> 00:20:28,380
your data in a database system or you

00:20:26,160 --> 00:20:30,600
can store it in whatever kind of

00:20:28,380 --> 00:20:33,090
endpoint you want but by default it's a

00:20:30,600 --> 00:20:39,300
leucine catalog that allows you to store

00:20:33,090 --> 00:20:42,570
metadata and well so this diagram I

00:20:39,300 --> 00:20:45,150
thought would be useful to show this is

00:20:42,570 --> 00:20:46,230
a diagram I believe Chris madman through

00:20:45,150 --> 00:20:50,730
the stuff so I want to give him credit

00:20:46,230 --> 00:20:53,370
for this this diagram shows the the idea

00:20:50,730 --> 00:20:55,440
of process control system pcs in terms

00:20:53,370 --> 00:20:57,480
of how those three components I was

00:20:55,440 --> 00:20:59,760
talking about in Iraq so file managers

00:20:57,480 --> 00:21:03,270
as highlighted there on the left as you

00:20:59,760 --> 00:21:06,510
can see um it interacts with both the

00:21:03,270 --> 00:21:08,400
workflow manager and with in this case

00:21:06,510 --> 00:21:11,460
you see the crawler so you could think

00:21:08,400 --> 00:21:13,950
of a process control system as you need

00:21:11,460 --> 00:21:15,870
to get ahold of products first and right

00:21:13,950 --> 00:21:17,670
and crawler is actually a component that

00:21:15,870 --> 00:21:19,260
helps with that let's crawl crawls

00:21:17,670 --> 00:21:21,660
directory structures and obtains

00:21:19,260 --> 00:21:24,120
references to products file manager

00:21:21,660 --> 00:21:25,380
stores information about those products

00:21:24,120 --> 00:21:27,090
in terms of metadata where they're

00:21:25,380 --> 00:21:30,270
located what some information about them

00:21:27,090 --> 00:21:32,790
and feeds references to the products or

00:21:30,270 --> 00:21:35,460
metadata about the products to work

00:21:32,790 --> 00:21:38,040
flows which I'll talk about in a second

00:21:35,460 --> 00:21:43,110
so that's kind of the position of file

00:21:38,040 --> 00:21:45,840
manager within the scheme to go into a

00:21:43,110 --> 00:21:49,620
workflow manager let me just zoom in

00:21:45,840 --> 00:21:52,050
there again wharfe measure you could

00:21:49,620 --> 00:21:56,580
think of it representing this giant blob

00:21:52,050 --> 00:21:59,970
here so its role in the process control

00:21:56,580 --> 00:22:00,480
system would be to essentially just wrap

00:21:59,970 --> 00:22:03,059
sign

00:22:00,480 --> 00:22:06,720
algorithms together and create create

00:22:03,059 --> 00:22:09,120
the the overall algorithm of how to

00:22:06,720 --> 00:22:11,910
process data what to do with input data

00:22:09,120 --> 00:22:14,700
and produce an output so here there's a

00:22:11,910 --> 00:22:17,250
term called pge those mentioned a couple

00:22:14,700 --> 00:22:20,549
times pge stands for I believe like

00:22:17,250 --> 00:22:22,950
product Generation X executed I think

00:22:20,549 --> 00:22:25,710
it's a NASA term so some of you might

00:22:22,950 --> 00:22:31,620
not be familiar with that oh yeah okay

00:22:25,710 --> 00:22:34,230
so it is it's a term that essentially

00:22:31,620 --> 00:22:36,960
what it means is create a wrapper for

00:22:34,230 --> 00:22:38,400
some program so pgs let you take

00:22:36,960 --> 00:22:43,020
external programs if it's written in

00:22:38,400 --> 00:22:46,559
Python Java bash you know whatever it

00:22:43,020 --> 00:22:48,570
lets you wrap those programs using an

00:22:46,559 --> 00:22:52,610
XML type of configuration where you can

00:22:48,570 --> 00:22:55,290
say you can specify what metadata to

00:22:52,610 --> 00:22:57,510
handle as input what to do with that

00:22:55,290 --> 00:22:58,890
particular algorithm how to execute and

00:22:57,510 --> 00:23:00,840
what to do with the output it generates

00:22:58,890 --> 00:23:05,070
so you can essentially wrap your

00:23:00,840 --> 00:23:07,830
external programs in pges and define an

00:23:05,070 --> 00:23:09,809
xml-based policy that says how those pgs

00:23:07,830 --> 00:23:12,000
fit together in terms of a workflow or

00:23:09,809 --> 00:23:14,910
sets of workflow is if you if you have a

00:23:12,000 --> 00:23:16,620
parallel system and that's the role of

00:23:14,910 --> 00:23:22,340
the workflow manager and then of course

00:23:16,620 --> 00:23:27,690
it sends off the jobs too don't it done

00:23:22,340 --> 00:23:30,000
resource manager so resource manager its

00:23:27,690 --> 00:23:33,059
role like I mentioned earlier is to be

00:23:30,000 --> 00:23:34,970
in charge of the execution of where you

00:23:33,059 --> 00:23:37,230
want to be running these workflows and

00:23:34,970 --> 00:23:40,169
so you can see here on the Left there's

00:23:37,230 --> 00:23:44,210
a list of computing resources and so

00:23:40,169 --> 00:23:46,260
what that means is you can run your

00:23:44,210 --> 00:23:48,419
specific parts of your workflows on

00:23:46,260 --> 00:23:50,940
different different machines or

00:23:48,419 --> 00:23:52,980
different clusters and so that's the

00:23:50,940 --> 00:23:55,620
resource manager is in charge of the Rex

00:23:52,980 --> 00:23:59,390
ml configuration again determining how

00:23:55,620 --> 00:23:59,390
you want to run your different workflows

00:23:59,660 --> 00:24:05,460
okay so hopefully that was a pretty in

00:24:02,309 --> 00:24:06,929
depth introduction to ODT data

00:24:05,460 --> 00:24:09,330
processing now what I want to do is

00:24:06,929 --> 00:24:11,700
connect those two parts of the talk

00:24:09,330 --> 00:24:14,200
together and talk a little bit about an

00:24:11,700 --> 00:24:16,840
actual use case where we're using ODT

00:24:14,200 --> 00:24:20,340
opponents to solve or not to solve but

00:24:16,840 --> 00:24:23,800
to advanced cancer research and try to

00:24:20,340 --> 00:24:28,420
solve an actual problem that we've been

00:24:23,800 --> 00:24:29,890
facing so before I start with that let

00:24:28,420 --> 00:24:32,220
me just introduce what the project

00:24:29,890 --> 00:24:34,870
overall is it there's a project called

00:24:32,220 --> 00:24:37,120
ed RN early detection research network

00:24:34,870 --> 00:24:39,490
and I think Dan had referenced this in

00:24:37,120 --> 00:24:43,650
earlier talk today but ed RN is an

00:24:39,490 --> 00:24:48,220
organization that is focused on it's a

00:24:43,650 --> 00:24:50,770
subsidiary of NCI or NIH actually

00:24:48,220 --> 00:24:53,950
National Institute of Health but it's in

00:24:50,770 --> 00:24:55,540
charge with advancing what I was talking

00:24:53,950 --> 00:24:57,280
about earlier which is cancer biomarker

00:24:55,540 --> 00:25:00,820
research trying to find clinically

00:24:57,280 --> 00:25:03,630
applicable biomarkers that can be used

00:25:00,820 --> 00:25:07,210
by actual clinicians in the future to

00:25:03,630 --> 00:25:09,040
help detect cancer its early stages so

00:25:07,210 --> 00:25:12,940
that's really the charter mission of the

00:25:09,040 --> 00:25:17,830
EV RN and at JPL we actually manage the

00:25:12,940 --> 00:25:24,460
information information system aspects

00:25:17,830 --> 00:25:27,340
of it so as a sub project within the EDR

00:25:24,460 --> 00:25:32,230
n we've been working recently on a

00:25:27,340 --> 00:25:34,680
project called lab cast which is at its

00:25:32,230 --> 00:25:37,390
essence it's a data management system

00:25:34,680 --> 00:25:38,410
much like what you other projects you've

00:25:37,390 --> 00:25:40,270
heard about today but it's a data

00:25:38,410 --> 00:25:43,030
management system targeted for easier

00:25:40,270 --> 00:25:46,420
and researchers for their experimental

00:25:43,030 --> 00:25:48,460
products so we actually have a data

00:25:46,420 --> 00:25:50,850
management system in place for published

00:25:48,460 --> 00:25:53,770
products already if a researcher

00:25:50,850 --> 00:25:56,440
identifies biomarkers there's some kind

00:25:53,770 --> 00:25:57,820
of finding they publish those results in

00:25:56,440 --> 00:25:59,290
a paper and they want to make the data

00:25:57,820 --> 00:26:00,970
sets available associate with those

00:25:59,290 --> 00:26:03,640
results we have a data management system

00:26:00,970 --> 00:26:06,420
for that lab has is an extension of that

00:26:03,640 --> 00:26:09,160
data management system to focus on

00:26:06,420 --> 00:26:12,520
pre-publication data experimental data

00:26:09,160 --> 00:26:13,450
which researchers find valuable and they

00:26:12,520 --> 00:26:16,660
might want to share with other

00:26:13,450 --> 00:26:18,340
researchers but they currently are

00:26:16,660 --> 00:26:20,020
destroying them in their own facilities

00:26:18,340 --> 00:26:22,720
and transferring them through other

00:26:20,020 --> 00:26:24,610
means so that's the focus of lab cats as

00:26:22,720 --> 00:26:27,230
a data management solution proteomics

00:26:24,610 --> 00:26:29,480
pipeline is a parallel effort

00:26:27,230 --> 00:26:32,260
with lab qez where what we are doing

00:26:29,480 --> 00:26:36,020
essentially is adding on centralized

00:26:32,260 --> 00:26:37,700
dating data processing facilities for

00:26:36,020 --> 00:26:40,640
for lab cats so after users have

00:26:37,700 --> 00:26:43,280
actually uploaded data sets experimental

00:26:40,640 --> 00:26:45,890
data sets the idea of proteomics

00:26:43,280 --> 00:26:49,100
pipeline is to allow them to process

00:26:45,890 --> 00:26:50,510
those data sets and produce analytical

00:26:49,100 --> 00:26:51,950
results that they can share what their

00:26:50,510 --> 00:26:56,120
colleagues or just used for their own

00:26:51,950 --> 00:27:04,090
purposes and of course we're using ODT

00:26:56,120 --> 00:27:06,140
components for that so this this diagram

00:27:04,090 --> 00:27:09,530
might be a little bit complicated but

00:27:06,140 --> 00:27:13,070
just to give an idea what it means this

00:27:09,530 --> 00:27:15,200
this diagram essentially shows what it's

00:27:13,070 --> 00:27:18,700
like a little bit hard to see what it

00:27:15,200 --> 00:27:21,140
shows is what ODT data processing

00:27:18,700 --> 00:27:24,620
components ODT components in general

00:27:21,140 --> 00:27:26,840
we're using on the top versus how we're

00:27:24,620 --> 00:27:28,940
using them in which state of our data

00:27:26,840 --> 00:27:31,640
data management system we're using them

00:27:28,940 --> 00:27:33,679
at so as you can see you know we have a

00:27:31,640 --> 00:27:36,200
specific process that we're using in

00:27:33,679 --> 00:27:38,090
terms of our data management solution

00:27:36,200 --> 00:27:39,830
we're taking first getting ahold the

00:27:38,090 --> 00:27:45,770
projects putting them in our staging

00:27:39,830 --> 00:27:47,480
area archiving them you know then curing

00:27:45,770 --> 00:27:48,980
them processing them and then finally

00:27:47,480 --> 00:27:50,929
disagreeing them and so those are the

00:27:48,980 --> 00:27:53,510
steps in our pipeline then on the top

00:27:50,929 --> 00:27:55,730
you can see we're using file manager

00:27:53,510 --> 00:27:58,070
we're using a workflow manager resource

00:27:55,730 --> 00:27:59,570
manager crawler at different stages to

00:27:58,070 --> 00:28:02,000
perform different functions so that's

00:27:59,570 --> 00:28:03,710
the idea you know again in terms of

00:28:02,000 --> 00:28:05,630
modularity you can use it for you can

00:28:03,710 --> 00:28:09,820
use components for a specific process

00:28:05,630 --> 00:28:09,820
and send data in between

00:28:13,580 --> 00:28:19,910
so so yeah I thought would be useful

00:28:18,620 --> 00:28:22,460
actually just to give you a quick

00:28:19,910 --> 00:28:24,970
demonstration of what lab cats is apart

00:28:22,460 --> 00:28:39,020
from just kind of show the architecture

00:28:24,970 --> 00:28:42,190
so let me do that in a second okay

00:28:39,020 --> 00:28:42,190
hopefully that comes up

00:28:44,440 --> 00:28:52,540
okay so this is um this is the lab casts

00:28:49,780 --> 00:28:54,490
current a user interface and what it

00:28:52,540 --> 00:28:57,730
basically shows is a couple of different

00:28:54,490 --> 00:29:00,340
capabilities and along with that

00:28:57,730 --> 00:29:02,680
back-end or front-end versions of

00:29:00,340 --> 00:29:05,110
back-end ODT components so what you see

00:29:02,680 --> 00:29:07,660
here are this also our test side by the

00:29:05,110 --> 00:29:10,630
way what you see here are available

00:29:07,660 --> 00:29:13,420
datasets that researchers or actually in

00:29:10,630 --> 00:29:16,930
this case me i have uploaded so what you

00:29:13,420 --> 00:29:20,920
can see is basically through and there

00:29:16,930 --> 00:29:22,390
an upload tool we can capture end user

00:29:20,920 --> 00:29:23,890
data from different research

00:29:22,390 --> 00:29:28,030
institutions they fill out this form

00:29:23,890 --> 00:29:29,560
they have different kinds of methods to

00:29:28,030 --> 00:29:31,770
upload the data and once the data has

00:29:29,560 --> 00:29:34,930
actually been transferred to our system

00:29:31,770 --> 00:29:38,680
you see a rendering of a data set and

00:29:34,930 --> 00:29:41,680
one can then view individual products as

00:29:38,680 --> 00:29:45,760
a part of that data set and for example

00:29:41,680 --> 00:29:48,430
down here is our actual raw specimen

00:29:45,760 --> 00:29:51,910
files manage different details of that

00:29:48,430 --> 00:29:53,440
data set and then those are some of the

00:29:51,910 --> 00:29:56,530
basic capabilities were supporting right

00:29:53,440 --> 00:29:58,180
now and as well as I was mentioning the

00:29:56,530 --> 00:30:00,760
purple one of the purposes of lab calves

00:29:58,180 --> 00:30:05,010
is also to get a hold of user data as

00:30:00,760 --> 00:30:07,510
early as possible to try to facilitate

00:30:05,010 --> 00:30:09,160
connecting it with our other data

00:30:07,510 --> 00:30:11,850
management solution which is called eks

00:30:09,160 --> 00:30:15,970
and that's for again publication

00:30:11,850 --> 00:30:17,710
specific data already published data so

00:30:15,970 --> 00:30:21,880
there's different tools we're working on

00:30:17,710 --> 00:30:23,890
to help take experimental data where

00:30:21,880 --> 00:30:27,690
users can basically see a list of their

00:30:23,890 --> 00:30:29,710
laboratory data modify metadata about it

00:30:27,690 --> 00:30:32,080
running through pipelines and then

00:30:29,710 --> 00:30:34,140
finally push it to our final cataloging

00:30:32,080 --> 00:30:37,150
system so this kind of just renders

00:30:34,140 --> 00:30:39,340
gives you a quick glimpse of what the

00:30:37,150 --> 00:30:42,550
user interface looks like but many of

00:30:39,340 --> 00:30:46,510
these components these these data set

00:30:42,550 --> 00:30:48,070
lists are taken from information

00:30:46,510 --> 00:30:50,530
obtained from the file manager along

00:30:48,070 --> 00:30:52,980
with solar and direction has to talk

00:30:50,530 --> 00:30:56,050
about that he'll talk about later but

00:30:52,980 --> 00:30:56,659
there's many the point is Mary OTT and

00:30:56,050 --> 00:30:59,059
there's many

00:30:56,659 --> 00:31:02,359
components pushing and supporting this

00:30:59,059 --> 00:31:14,359
in the back end so that's a quick

00:31:02,359 --> 00:31:16,849
example of that go back to here okay all

00:31:14,359 --> 00:31:18,320
right so how about though yeah I'll talk

00:31:16,849 --> 00:31:19,399
about the proteomics pipeline a little

00:31:18,320 --> 00:31:22,789
bit more in depth now so I was

00:31:19,399 --> 00:31:27,049
mentioning it's a it's a system that

00:31:22,789 --> 00:31:29,389
allows the the centralization of

00:31:27,049 --> 00:31:31,729
analysis so one of the issues that many

00:31:29,389 --> 00:31:33,200
researchers of face and I'm sure this is

00:31:31,729 --> 00:31:36,950
applicable across different disciplines

00:31:33,200 --> 00:31:39,649
is you have input data raw data that you

00:31:36,950 --> 00:31:41,210
want to process and analyze but you have

00:31:39,649 --> 00:31:42,889
your own set of algorithms but there's

00:31:41,210 --> 00:31:45,049
many other researchers out there with

00:31:42,889 --> 00:31:48,710
their different sets of algorithms that

00:31:45,049 --> 00:31:50,809
can also process your data and and a

00:31:48,710 --> 00:31:53,419
good way of doing continuing on your

00:31:50,809 --> 00:31:55,700
research is to try out different

00:31:53,419 --> 00:31:57,289
analysis methods on your same input data

00:31:55,700 --> 00:31:59,299
and compare that to contrast the results

00:31:57,289 --> 00:32:01,999
many times that's difficult to do

00:31:59,299 --> 00:32:04,970
because there's an entire pipeline chain

00:32:01,999 --> 00:32:06,769
of tools that are necessary to download

00:32:04,970 --> 00:32:09,830
install configure on your local system

00:32:06,769 --> 00:32:11,840
to try to get external tools working and

00:32:09,830 --> 00:32:14,029
so if you want to analyze your data on

00:32:11,840 --> 00:32:16,789
using different methods that can be

00:32:14,029 --> 00:32:18,229
really difficult to do if you know if

00:32:16,789 --> 00:32:19,999
you don't have the time to set up all

00:32:18,229 --> 00:32:22,309
these different types of tools on your

00:32:19,999 --> 00:32:23,840
system so lab calves are sorry

00:32:22,309 --> 00:32:26,299
proteomics pipeline is trying to address

00:32:23,840 --> 00:32:28,609
that by centralizing the algorithms and

00:32:26,299 --> 00:32:31,549
in a single place where input data

00:32:28,609 --> 00:32:35,529
products can be processed and one

00:32:31,549 --> 00:32:39,049
example case that we started with is a

00:32:35,529 --> 00:32:40,970
set of tools essentially the form a data

00:32:39,049 --> 00:32:43,700
processing algorithm from the Vanderbilt

00:32:40,970 --> 00:32:45,859
University Medical Center and this is

00:32:43,700 --> 00:32:47,690
basically that pipeline diagram that I

00:32:45,859 --> 00:32:51,950
showed earlier with all the different

00:32:47,690 --> 00:32:54,259
arrows and all that that was essentially

00:32:51,950 --> 00:32:56,629
a representation of this algorithm in a

00:32:54,259 --> 00:32:58,609
way so you have input raw data and you

00:32:56,629 --> 00:33:00,440
have different database database

00:32:58,609 --> 00:33:03,080
information of known talks and things

00:33:00,440 --> 00:33:06,169
like that and you run it through these

00:33:03,080 --> 00:33:09,560
analysis tools where you match your raw

00:33:06,169 --> 00:33:11,660
specimens against those known toxins

00:33:09,560 --> 00:33:13,670
generate results and then archive that

00:33:11,660 --> 00:33:16,190
information to lab cats so this is an

00:33:13,670 --> 00:33:17,900
example of one algorithm one data

00:33:16,190 --> 00:33:22,460
processing solution that we've

00:33:17,900 --> 00:33:23,960
implemented in lab cats now the idea in

00:33:22,460 --> 00:33:27,320
general though is to take this type of

00:33:23,960 --> 00:33:29,240
algorithm and implement it as an actual

00:33:27,320 --> 00:33:32,780
workflow so the way we've been doing

00:33:29,240 --> 00:33:34,900
that is using workflow manager we've

00:33:32,780 --> 00:33:37,340
taken those individual steps and

00:33:34,900 --> 00:33:39,680
represented them as each one of those

00:33:37,340 --> 00:33:41,480
blue boxes represents a workflow task

00:33:39,680 --> 00:33:43,010
and so in our case well ours is just

00:33:41,480 --> 00:33:46,160
sequential there's no parallelization

00:33:43,010 --> 00:33:49,330
but you have individual workflow tasks

00:33:46,160 --> 00:33:53,930
that perform a specific function like

00:33:49,330 --> 00:33:56,120
looking out the looking up information

00:33:53,930 --> 00:33:58,640
about the raw specimens against a

00:33:56,120 --> 00:34:01,640
database of known toxins and then

00:33:58,640 --> 00:34:04,640
passing that on to a program that

00:34:01,640 --> 00:34:08,360
generates reports and analysis reports

00:34:04,640 --> 00:34:09,860
essentially and each one of those tasks

00:34:08,360 --> 00:34:13,010
are represented in XML configuration

00:34:09,860 --> 00:34:14,450
files so this kind of shows how you take

00:34:13,010 --> 00:34:16,370
an algorithm and if you want to actually

00:34:14,450 --> 00:34:19,030
implement this workflow you go through

00:34:16,370 --> 00:34:22,460
these steps in workflow manager to just

00:34:19,030 --> 00:34:25,130
wrap each one as a workflow task or as

00:34:22,460 --> 00:34:27,830
their as an as a PG e-- and connect them

00:34:25,130 --> 00:34:33,890
together and that's basically or your

00:34:27,830 --> 00:34:38,990
workflow oh okay so it's going to give a

00:34:33,890 --> 00:34:42,440
quick demonstration of the pipeline so

00:34:38,990 --> 00:34:44,720
let me just reload this okay so this is

00:34:42,440 --> 00:34:46,130
just a quick example of the idea of

00:34:44,720 --> 00:34:49,580
talking about earlier which is the

00:34:46,130 --> 00:34:51,640
centralization of workflows so the idea

00:34:49,580 --> 00:34:54,230
is after users have uploaded their data

00:34:51,640 --> 00:34:57,560
or their data sets if they want to run

00:34:54,230 --> 00:34:59,420
an analysis algorithm on it one can

00:34:57,560 --> 00:35:02,840
basically select among a series of

00:34:59,420 --> 00:35:04,370
different types of workflows and try to

00:35:02,840 --> 00:35:06,980
analyze their data using each one of

00:35:04,370 --> 00:35:10,660
them so I'm going to select one the use

00:35:06,980 --> 00:35:10,660
case that we have here and select which

00:35:11,380 --> 00:35:16,420
data products I want to run in these are

00:35:13,760 --> 00:35:16,420
all defaults

00:35:17,210 --> 00:35:27,680
let's put my email and if I hit submit

00:35:20,839 --> 00:35:30,440
here okay did something so okay so this

00:35:27,680 --> 00:35:32,660
actually immediately transferred us to a

00:35:30,440 --> 00:35:35,030
page called the workflow monitor which

00:35:32,660 --> 00:35:36,710
is another tool that comes straight out

00:35:35,030 --> 00:35:39,320
of ODT in this case it's been a little

00:35:36,710 --> 00:35:40,730
bit customized but it shows currently

00:35:39,320 --> 00:35:43,010
running workflows that have been

00:35:40,730 --> 00:35:46,130
submitted to the system and so this is

00:35:43,010 --> 00:35:48,920
part of the pcs tool suite which allows

00:35:46,130 --> 00:35:50,839
you to see currently running workflows

00:35:48,920 --> 00:35:53,619
that you've submitted and so in this

00:35:50,839 --> 00:35:56,720
case there's just a quick rendering of

00:35:53,619 --> 00:35:58,490
that's been running for a so this is the

00:35:56,720 --> 00:36:01,280
workflow that we just submitted a few

00:35:58,490 --> 00:36:04,580
seconds ago and it's in if you were to

00:36:01,280 --> 00:36:06,890
basically see which stage it's at you

00:36:04,580 --> 00:36:08,000
can click on the rendering of the

00:36:06,890 --> 00:36:09,800
workflow and you can see there's

00:36:08,000 --> 00:36:12,349
actually quite a few steps to diagram

00:36:09,800 --> 00:36:13,460
showing you as many steps involved each

00:36:12,349 --> 00:36:21,800
of which you can find out more

00:36:13,460 --> 00:36:24,109
information about terms of give it a

00:36:21,800 --> 00:36:26,900
second there you go and so this is kind

00:36:24,109 --> 00:36:29,660
of this is information about each

00:36:26,900 --> 00:36:31,970
workflow task so there's a lot of detail

00:36:29,660 --> 00:36:34,099
I know but this is just kind of to show

00:36:31,970 --> 00:36:36,530
you that all those different pieces are

00:36:34,099 --> 00:36:39,740
kind of connected and they can you get

00:36:36,530 --> 00:36:42,890
information about workflows and workflow

00:36:39,740 --> 00:36:45,530
tasks even from a web app so that shows

00:36:42,890 --> 00:36:48,260
you know submission of different

00:36:45,530 --> 00:36:49,760
workflow tasks and an example of how

00:36:48,260 --> 00:36:50,900
we're actually processing the data and

00:36:49,760 --> 00:36:53,599
by the way I don't think we'll have

00:36:50,900 --> 00:36:55,730
enough time to show the end result of

00:36:53,599 --> 00:36:58,010
this it usually takes about 30-40

00:36:55,730 --> 00:37:02,000
minutes to process but the results of

00:36:58,010 --> 00:37:04,400
that that pipeline process will appear

00:37:02,000 --> 00:37:05,930
as a new data set here and which you can

00:37:04,400 --> 00:37:07,250
use to actually browse and see what

00:37:05,930 --> 00:37:09,500
products you've developed and download

00:37:07,250 --> 00:37:11,000
them and that kind of thing so it is you

00:37:09,500 --> 00:37:12,890
take input products running it through

00:37:11,000 --> 00:37:24,800
the pipeline you can generate new data

00:37:12,890 --> 00:37:28,400
set okay all right so to go on to the

00:37:24,800 --> 00:37:30,680
last portion of the talk I want to talk

00:37:28,400 --> 00:37:33,200
about if if you're interested in in this

00:37:30,680 --> 00:37:35,690
and if you're interested in setting up a

00:37:33,200 --> 00:37:38,240
data processing system on your on your

00:37:35,690 --> 00:37:39,440
own how would you go about this and how

00:37:38,240 --> 00:37:41,839
would you replicate the steps that I

00:37:39,440 --> 00:37:45,830
showed and try to you know address the

00:37:41,839 --> 00:37:49,339
science use case yourself so it in the

00:37:45,830 --> 00:37:52,099
most simplest terms what are the steps

00:37:49,339 --> 00:37:54,650
involved just to recap that that are

00:37:52,099 --> 00:37:56,300
involved in and trying to set up a data

00:37:54,650 --> 00:37:57,650
processing system so the first is

00:37:56,300 --> 00:38:00,530
essentially what you want to do is set

00:37:57,650 --> 00:38:04,339
up the pcs framework so you want to get

00:38:00,530 --> 00:38:05,900
ahold of different ODT components like

00:38:04,339 --> 00:38:09,410
file manager or workflow manager

00:38:05,900 --> 00:38:11,300
resource manager crawler and those are

00:38:09,410 --> 00:38:14,180
kind of the core set of components that

00:38:11,300 --> 00:38:16,820
you'd want to use to to set up your data

00:38:14,180 --> 00:38:18,380
processing system and you download them

00:38:16,820 --> 00:38:22,250
and kind of install them and configure

00:38:18,380 --> 00:38:23,630
them and the next step would be to take

00:38:22,250 --> 00:38:25,280
those components and after you've

00:38:23,630 --> 00:38:28,310
actually installed them configured them

00:38:25,280 --> 00:38:29,839
instead of all your environment

00:38:28,310 --> 00:38:30,890
variables and connected connected the

00:38:29,839 --> 00:38:34,460
dots essentially in terms of

00:38:30,890 --> 00:38:36,800
installation you would take your science

00:38:34,460 --> 00:38:39,109
algorithms and implement that within the

00:38:36,800 --> 00:38:41,240
workflow so take the different steps of

00:38:39,109 --> 00:38:43,460
yourselves science algorithm implement

00:38:41,240 --> 00:38:45,290
that as workflow tasks and connect them

00:38:43,460 --> 00:38:48,320
in whatever type of configuration you

00:38:45,290 --> 00:38:50,810
wanted using pges and then finally the

00:38:48,320 --> 00:38:52,490
step final step would be to you know

00:38:50,810 --> 00:38:54,349
configure user interface to make it

00:38:52,490 --> 00:38:58,130
simpler for a user to to launch

00:38:54,349 --> 00:38:59,930
workflows and to see the results and

00:38:58,130 --> 00:39:01,910
render insults so those are essentially

00:38:59,930 --> 00:39:03,770
the most basic level of the steps

00:39:01,910 --> 00:39:10,070
involved in setting up data processing

00:39:03,770 --> 00:39:11,000
system using ODT I know you might be

00:39:10,070 --> 00:39:13,220
wondering is there an easier method

00:39:11,000 --> 00:39:16,030
because it honestly took me quite a long

00:39:13,220 --> 00:39:18,020
time to get that up and running so there

00:39:16,030 --> 00:39:21,910
there's a lot of work that's been going

00:39:18,020 --> 00:39:25,000
into trying to simplify the process of

00:39:21,910 --> 00:39:28,000
getting up and running as a new user of

00:39:25,000 --> 00:39:28,000
ODT

00:39:28,920 --> 00:39:34,390
and setting up your own data management

00:39:32,230 --> 00:39:37,810
system as a subset of that a data

00:39:34,390 --> 00:39:40,840
processing system so one of the things i

00:39:37,810 --> 00:39:46,180
want to just kind of show is how one

00:39:40,840 --> 00:39:48,730
would how one would get up and running

00:39:46,180 --> 00:39:50,260
using a tool called radix which is i'm

00:39:48,730 --> 00:39:54,280
not sure what that stands for honestly

00:39:50,260 --> 00:39:58,390
but i'm sure something cool but it's

00:39:54,280 --> 00:40:01,660
it's basically at its core what it is is

00:39:58,390 --> 00:40:03,700
a tool that allows you to get up and

00:40:01,660 --> 00:40:05,800
running quickly using a full

00:40:03,700 --> 00:40:08,440
distribution of apache ODT well not a

00:40:05,800 --> 00:40:13,720
full but the core components that i

00:40:08,440 --> 00:40:17,400
mentioned in the pcs system and the idea

00:40:13,720 --> 00:40:19,960
is to steal quote from cameron the ideas

00:40:17,400 --> 00:40:21,880
convention over configuration where you

00:40:19,960 --> 00:40:24,880
want to just get up and running as

00:40:21,880 --> 00:40:26,140
quickly as possible and you don't

00:40:24,880 --> 00:40:27,490
necessarily want to spend the time to

00:40:26,140 --> 00:40:29,200
configure everything yourself and

00:40:27,490 --> 00:40:32,950
customizing your own type of directory

00:40:29,200 --> 00:40:34,180
structure and placement on disk but you

00:40:32,950 --> 00:40:35,560
can just assume a certain type of

00:40:34,180 --> 00:40:41,290
directory structure and just get up and

00:40:35,560 --> 00:40:44,050
running quickly and so in terms of

00:40:41,290 --> 00:40:46,330
details how this works it uses a maven

00:40:44,050 --> 00:40:47,800
archetype where you can use apache maven

00:40:46,330 --> 00:40:49,780
to generate the product directory

00:40:47,800 --> 00:40:52,420
structure use it to build it and it's

00:40:49,780 --> 00:40:59,920
pre configured using preset environment

00:40:52,420 --> 00:41:02,020
variables to get up and running so so

00:40:59,920 --> 00:41:04,750
actually using it it's not a lot of

00:41:02,020 --> 00:41:08,410
steps at all I've used it for other

00:41:04,750 --> 00:41:10,030
projects actually so the first step our

00:41:08,410 --> 00:41:12,700
first portion of this is basically just

00:41:10,030 --> 00:41:13,720
using maven to get ahold of the

00:41:12,700 --> 00:41:16,270
information you need to actually

00:41:13,720 --> 00:41:18,880
generate the project directory structure

00:41:16,270 --> 00:41:21,160
and generate the tarball which is your

00:41:18,880 --> 00:41:24,580
data management system and then of

00:41:21,160 --> 00:41:28,570
course starting it starting the data

00:41:24,580 --> 00:41:31,240
management system so I'm actually going

00:41:28,570 --> 00:41:35,140
to be brave today and try it try that

00:41:31,240 --> 00:41:38,380
out in real time so just to give you an

00:41:35,140 --> 00:41:41,530
idea of how you would do that yourself

00:41:38,380 --> 00:41:43,450
and part of this was demonstrated

00:41:41,530 --> 00:41:45,790
last time in Apache con but there's been

00:41:43,450 --> 00:41:47,440
improvements and a little bit easier

00:41:45,790 --> 00:41:48,910
access in terms of getting this up and

00:41:47,440 --> 00:41:52,840
running so I want to demonstrate that as

00:41:48,910 --> 00:41:55,960
well all right always okay alright so

00:41:52,840 --> 00:41:57,640
the first step is basically oh just to

00:41:55,960 --> 00:42:00,190
prove to you that you know I'm not just

00:41:57,640 --> 00:42:01,600
making stuff up here's what I'm going to

00:42:00,190 --> 00:42:07,240
demo and it's clearly not working it's

00:42:01,600 --> 00:42:12,310
the final actual web app and we're t see

00:42:07,240 --> 00:42:14,140
there's no OT components running so I'm

00:42:12,310 --> 00:42:16,240
also being honest as well as brave

00:42:14,140 --> 00:42:17,590
alright so here's the first seven the

00:42:16,240 --> 00:42:20,650
first step is getting a hold of the

00:42:17,590 --> 00:42:23,950
Apache of sorry getting hold of the

00:42:20,650 --> 00:42:26,470
maven archetype and basically generating

00:42:23,950 --> 00:42:27,820
the project directory where you're going

00:42:26,470 --> 00:42:31,630
to build your data management solution

00:42:27,820 --> 00:42:38,500
so let me go ahead and just press enter

00:42:31,630 --> 00:42:39,580
on that and so what it's doing is well I

00:42:38,500 --> 00:42:42,820
mean what does maven always do just

00:42:39,580 --> 00:42:47,740
download the internet but it's telling

00:42:42,820 --> 00:42:49,420
that and and I'm just going to say yes

00:42:47,740 --> 00:42:51,270
on the default structure so it's

00:42:49,420 --> 00:42:53,080
basically what it's done is it's

00:42:51,270 --> 00:42:56,530
generated the Apache more of an

00:42:53,080 --> 00:43:00,430
archetype and it's generated a directory

00:42:56,530 --> 00:43:02,050
where our basic components are stores if

00:43:00,430 --> 00:43:03,300
you see here that these are the

00:43:02,050 --> 00:43:06,460
components that have been generated

00:43:03,300 --> 00:43:08,970
automatically and pre-configured so what

00:43:06,460 --> 00:43:10,960
I'm going to do now is just build that

00:43:08,970 --> 00:43:12,340
data management solution and that

00:43:10,960 --> 00:43:15,370
includes a couple of different

00:43:12,340 --> 00:43:18,670
components it includes its basic onset

00:43:15,370 --> 00:43:23,110
file manager workflow manager resource

00:43:18,670 --> 00:43:25,630
manager I believe crawler and then some

00:43:23,110 --> 00:43:27,670
other tools like pcs monitor as well as

00:43:25,630 --> 00:43:32,500
a couple of web apps so that allows you

00:43:27,670 --> 00:43:35,560
to essentially get data management

00:43:32,500 --> 00:43:38,680
system pre-built where you can just kind

00:43:35,560 --> 00:43:39,970
of get it viewable to a user and what

00:43:38,680 --> 00:43:44,260
I'm going to demo in a second is

00:43:39,970 --> 00:43:46,050
actually the it also comes

00:43:44,260 --> 00:43:49,020
pre-configured with some operational

00:43:46,050 --> 00:43:53,140
user interfaces that you can use to

00:43:49,020 --> 00:43:55,390
monitor workflows and you can use to

00:43:53,140 --> 00:44:00,279
view and see what comes of

00:43:55,390 --> 00:44:02,920
files are on your what types of products

00:44:00,279 --> 00:44:05,880
are in your file manager catalog so oh

00:44:02,920 --> 00:44:09,130
cool it actually finished alright so

00:44:05,880 --> 00:44:13,750
what I'm going to do now is change into

00:44:09,130 --> 00:44:15,039
the or actually I'm going to create yeah

00:44:13,750 --> 00:44:18,010
I'm going to create a deployment

00:44:15,039 --> 00:44:19,539
directory so what it's what step by just

00:44:18,010 --> 00:44:21,279
accomplished is basically building the

00:44:19,539 --> 00:44:22,750
tarball that is my data management

00:44:21,279 --> 00:44:25,470
solution now what I'm going to do is

00:44:22,750 --> 00:44:28,599
actually deploy that tar ball into a

00:44:25,470 --> 00:44:29,789
predefined deployment directory and so

00:44:28,599 --> 00:44:37,410
I'm just going to on Tarth at

00:44:29,789 --> 00:44:43,119
pre-created tar ball and um CD into that

00:44:37,410 --> 00:44:46,119
and let's I'm just going to start that

00:44:43,119 --> 00:44:48,369
um and ODT start is basically part of

00:44:46,119 --> 00:44:50,740
radix it's just a simplified one step

00:44:48,369 --> 00:44:52,089
tool to let you start many of the

00:44:50,740 --> 00:44:56,650
services involved including the web

00:44:52,089 --> 00:44:59,740
applications so that should have started

00:44:56,650 --> 00:45:02,470
the data management system i'm just

00:44:59,740 --> 00:45:05,920
going to reload that ok so this is a

00:45:02,470 --> 00:45:09,819
snapshot of kind of the front end user

00:45:05,920 --> 00:45:12,549
interface for an operator to just see

00:45:09,819 --> 00:45:14,769
the status of their data management

00:45:12,549 --> 00:45:17,079
system and data processing system so at

00:45:14,769 --> 00:45:21,009
its cord contains again you know file

00:45:17,079 --> 00:45:23,559
manager oops yeah file manager workflow

00:45:21,009 --> 00:45:25,299
manager resource manager some other

00:45:23,559 --> 00:45:28,150
tools but as you can see now there's

00:45:25,299 --> 00:45:30,009
there's this is the file manager catalog

00:45:28,150 --> 00:45:33,099
there's no products this is a fresh

00:45:30,009 --> 00:45:34,809
installation but there would be if i

00:45:33,099 --> 00:45:36,730
ingested some new products into the

00:45:34,809 --> 00:45:39,460
system workflow manager there's

00:45:36,730 --> 00:45:42,250
obviously no workflows installed but you

00:45:39,460 --> 00:45:46,890
would see status of workflows if you had

00:45:42,250 --> 00:45:49,299
actually launched them so that is um

00:45:46,890 --> 00:45:50,349
yeah that's essentially just what you

00:45:49,299 --> 00:45:53,349
can get up and running very quickly

00:45:50,349 --> 00:45:55,420
using it there's a couple of steps the

00:45:53,349 --> 00:45:58,599
next step after you actually get this up

00:45:55,420 --> 00:46:03,839
and running and have your data system

00:45:58,599 --> 00:46:03,839
viewable is too

00:46:06,069 --> 00:46:12,920
the next step would be to customize your

00:46:11,150 --> 00:46:15,140
deployment so this this makes it easy to

00:46:12,920 --> 00:46:17,779
get up and running quickly the next step

00:46:15,140 --> 00:46:19,939
is talk to your scientists talk to your

00:46:17,779 --> 00:46:21,949
use case talk to your customers

00:46:19,939 --> 00:46:23,900
essentially and try to figure out what

00:46:21,949 --> 00:46:26,569
are the algorithms involved in your data

00:46:23,900 --> 00:46:29,239
processing system and identify those in

00:46:26,569 --> 00:46:30,559
two separate workflow tasks and of

00:46:29,239 --> 00:46:32,900
course figure out whether you want you

00:46:30,559 --> 00:46:34,789
for parallels data processing solution

00:46:32,900 --> 00:46:37,459
or cereal that kind of thing and then

00:46:34,789 --> 00:46:40,999
isolate those workflow tasks implement

00:46:37,459 --> 00:46:43,910
them as PHP GES like I mentioned and

00:46:40,999 --> 00:46:45,829
then you have your workflows essentially

00:46:43,910 --> 00:46:48,109
that you want to run next step would be

00:46:45,829 --> 00:46:49,759
in terms of resource management figure

00:46:48,109 --> 00:46:52,219
out what are your machines that you want

00:46:49,759 --> 00:46:54,380
to deploy your workflows on are they

00:46:52,219 --> 00:46:57,529
just a single box are there multiple

00:46:54,380 --> 00:47:00,019
nodes involved as a cloud solution what

00:46:57,529 --> 00:47:03,039
type of deployment strategy in terms of

00:47:00,019 --> 00:47:05,269
how you want to execute your workflows

00:47:03,039 --> 00:47:07,189
determine different determine the

00:47:05,269 --> 00:47:10,130
details of that essentially and then

00:47:07,189 --> 00:47:12,529
finally it be the final set would be in

00:47:10,130 --> 00:47:15,259
archival strategy in terms of how do you

00:47:12,529 --> 00:47:16,459
want to store the projects products that

00:47:15,259 --> 00:47:19,039
are involved in your to inter management

00:47:16,459 --> 00:47:21,619
solution what's the policy like what is

00:47:19,039 --> 00:47:22,939
the metadata like that like in fact this

00:47:21,619 --> 00:47:25,339
is actually out of order i would suggest

00:47:22,939 --> 00:47:27,890
your archival strategy is the first step

00:47:25,339 --> 00:47:29,359
that you want to take in terms of your

00:47:27,890 --> 00:47:31,789
data management system and data

00:47:29,359 --> 00:47:33,380
processing system but those would be the

00:47:31,789 --> 00:47:35,809
next steps after you get up and running

00:47:33,380 --> 00:47:40,309
using radix to to get a data management

00:47:35,809 --> 00:47:43,339
system up and running so that's that's

00:47:40,309 --> 00:47:46,640
my talk thanks a lot um there's some

00:47:43,339 --> 00:47:49,339
just additional contact information I

00:47:46,640 --> 00:47:51,259
just want to you know say thanks to all

00:47:49,339 --> 00:47:53,809
the contributors on the slideshow

00:47:51,259 --> 00:47:57,229
there's many other people involved in

00:47:53,809 --> 00:47:59,329
this project but I just wanted to say

00:47:57,229 --> 00:48:01,189
thanks and if you have any questions

00:47:59,329 --> 00:48:03,000
just let me know be happy to take them

00:48:01,189 --> 00:48:26,910
please

00:48:03,000 --> 00:48:28,470
I thought I loud enough but yeah so I'm

00:48:26,910 --> 00:48:30,300
more curious like you know are you guys

00:48:28,470 --> 00:48:31,800
like working with anything the XML you

00:48:30,300 --> 00:48:33,900
mentioned about the workflow description

00:48:31,800 --> 00:48:36,720
yeah is that based on any standard or is

00:48:33,900 --> 00:48:37,740
it or duty specific there so I guess if

00:48:36,720 --> 00:48:40,170
I understand your question correctly

00:48:37,740 --> 00:48:41,610
you're asking how do you take the

00:48:40,170 --> 00:48:43,890
information from the scientists and

00:48:41,610 --> 00:48:45,630
implemented workflows yeah the graph

00:48:43,890 --> 00:48:47,490
what is a contract between the scientist

00:48:45,630 --> 00:48:49,110
and the oddity system like in when they

00:48:47,490 --> 00:48:52,320
represent their they describe their

00:48:49,110 --> 00:48:54,180
problem yeah so I would say it's right

00:48:52,320 --> 00:48:57,420
now the way the process in which we do

00:48:54,180 --> 00:48:59,340
that is the scientists have an idea of

00:48:57,420 --> 00:49:01,650
what the execution steps are involved

00:48:59,340 --> 00:49:03,990
and they communicate that using just

00:49:01,650 --> 00:49:05,970
simple methods like a slideshow or a

00:49:03,990 --> 00:49:08,610
diagram in that case that diagram is

00:49:05,970 --> 00:49:10,200
actually one of the basis that we use to

00:49:08,610 --> 00:49:12,720
figure out what are the steps involved

00:49:10,200 --> 00:49:15,900
in the workflow we want to implement so

00:49:12,720 --> 00:49:18,150
in terms of a standard procedure it's

00:49:15,900 --> 00:49:20,700
just at this stage it's very basic in

00:49:18,150 --> 00:49:24,840
terms of communicating a different type

00:49:20,700 --> 00:49:28,350
of ortho but the next step in terms of

00:49:24,840 --> 00:49:29,700
once you have that information some of

00:49:28,350 --> 00:49:31,920
the tools that I've talked about you

00:49:29,700 --> 00:49:33,720
have you get input from the scientists

00:49:31,920 --> 00:49:35,460
then you represent it using XML

00:49:33,720 --> 00:49:38,430
configuration in more full measure

00:49:35,460 --> 00:49:41,670
you're easily able to render that using

00:49:38,430 --> 00:49:43,380
some of the tools that um like war film

00:49:41,670 --> 00:49:45,120
on and things like that and that allows

00:49:43,380 --> 00:49:47,910
you to kind of contrast so I would say

00:49:45,120 --> 00:49:50,600
the contract is getting the scientists

00:49:47,910 --> 00:49:52,830
view implement implementing that XML

00:49:50,600 --> 00:49:55,230
generating our own graph and then kind

00:49:52,830 --> 00:49:59,940
of comparing and contrasting the short

00:49:55,230 --> 00:50:02,520
in God the short answer is no it's not

00:49:59,940 --> 00:50:04,920
based on any standard and we looked at a

00:50:02,520 --> 00:50:07,920
bunch of standards and I didn't like

00:50:04,920 --> 00:50:09,870
them because they were bloated and I

00:50:07,920 --> 00:50:11,400
think anyone write anything I'm looked

00:50:09,870 --> 00:50:13,470
at be pal we looked at a whole bunch of

00:50:11,400 --> 00:50:15,840
other things the ODT workflows are

00:50:13,470 --> 00:50:17,930
captured in basic XML

00:50:15,840 --> 00:50:21,810
captures control flow and data flow

00:50:17,930 --> 00:50:23,370
differentiates them by tasks by data

00:50:21,810 --> 00:50:24,630
flow dependencies on those tests and

00:50:23,370 --> 00:50:27,720
then controlled flow dependencies for

00:50:24,630 --> 00:50:30,660
the tasks branch and bounds are captured

00:50:27,720 --> 00:50:32,820
in modern versions of the ODT system

00:50:30,660 --> 00:50:34,710
explicitly prior to that they are

00:50:32,820 --> 00:50:36,210
captured implicitly in the way that

00:50:34,710 --> 00:50:37,860
people constructed like conditional

00:50:36,210 --> 00:50:39,600
workflows or preconditions and things

00:50:37,860 --> 00:50:40,770
like that as well as the fact that the

00:50:39,600 --> 00:50:43,320
workflow manager is an event based

00:50:40,770 --> 00:50:44,820
system and when events come into the

00:50:43,320 --> 00:50:46,410
system you can kick off multiple things

00:50:44,820 --> 00:50:47,970
at once and then you can recombine them

00:50:46,410 --> 00:50:50,340
at the end kind of like the way

00:50:47,970 --> 00:50:52,710
MapReduce works through conditionals you

00:50:50,340 --> 00:50:55,140
know on things but in the later version

00:50:52,710 --> 00:50:57,120
of workflow for ODT that I'll talk about

00:50:55,140 --> 00:50:59,730
tomorrow this stuff is supported

00:50:57,120 --> 00:51:01,950
explicitly but but this is really the

00:50:59,730 --> 00:51:03,240
difference between whether or not so

00:51:01,950 --> 00:51:05,430
what Rishi talked about today was a

00:51:03,240 --> 00:51:07,440
production-oriented workflow scientists

00:51:05,430 --> 00:51:08,880
don't touch what he does most of the

00:51:07,440 --> 00:51:11,580
time because he's running it at scale

00:51:08,880 --> 00:51:13,710
and they just communicated to him the

00:51:11,580 --> 00:51:16,290
way to do it and he set it up but if

00:51:13,710 --> 00:51:18,570
this were an interactive more discovery

00:51:16,290 --> 00:51:20,280
thing that would be more important to us

00:51:18,570 --> 00:51:29,030
and we'd care about that more and this

00:51:20,280 --> 00:51:38,099
yeah go ahead crystal short answer

00:51:29,030 --> 00:51:39,810
Wow anything else my friend Richie I

00:51:38,099 --> 00:51:41,490
think one other thing too is is I think

00:51:39,810 --> 00:51:44,030
the other part of that the answer that

00:51:41,490 --> 00:51:46,560
question is what we've observed the NASA

00:51:44,030 --> 00:51:48,750
science realm what we observed in in the

00:51:46,560 --> 00:51:51,780
NIH science realm are vastly different

00:51:48,750 --> 00:51:54,510
the NASA people are used to writing sort

00:51:51,780 --> 00:51:57,210
of prototype sandbox algorithms that we

00:51:54,510 --> 00:51:59,490
can go integrate the with working with

00:51:57,210 --> 00:52:01,020
NIH guys this is all kind of new ground

00:51:59,490 --> 00:52:03,300
for them and so when we could talk to

00:52:01,020 --> 00:52:04,920
them about Ryan workflows we've got

00:52:03,300 --> 00:52:06,930
explaining the concept of a directed

00:52:04,920 --> 00:52:09,000
graph kind of workflow it's to them and

00:52:06,930 --> 00:52:11,220
that's that's been part of the

00:52:09,000 --> 00:52:12,570
experience so part of this is plowing

00:52:11,220 --> 00:52:14,250
your ground figuring out how do we

00:52:12,570 --> 00:52:16,380
relate we do at NASA till we actually

00:52:14,250 --> 00:52:21,089
relate to NIH and trying to get people

00:52:16,380 --> 00:52:23,910
on the same page yeah yeah so how is the

00:52:21,089 --> 00:52:26,880
resource scheduling happening in our

00:52:23,910 --> 00:52:29,520
duty oh just in general or in this use

00:52:26,880 --> 00:52:33,180
case within like in this use case yeah

00:52:29,520 --> 00:52:34,200
so in terms of our deployment Chris

00:52:33,180 --> 00:52:35,970
mission it's kind of production

00:52:34,200 --> 00:52:40,470
deployment what we're using is basically

00:52:35,970 --> 00:52:42,570
it's two nodes so we have because our

00:52:40,470 --> 00:52:45,270
tool set is essentially composed of

00:52:42,570 --> 00:52:47,820
Windows based tools and platform

00:52:45,270 --> 00:52:50,700
specific tools so we have essentially

00:52:47,820 --> 00:52:52,849
two modes for one windows-based tools

00:52:50,700 --> 00:52:55,470
and one for linux based tools and

00:52:52,849 --> 00:52:57,690
depending on different parts of the

00:52:55,470 --> 00:53:00,150
workflow some tools only working windows

00:52:57,690 --> 00:53:04,410
some only work on linux the workflow

00:53:00,150 --> 00:53:06,780
manager identifies or specifies which

00:53:04,410 --> 00:53:08,940
platform those specific tasks your work

00:53:06,780 --> 00:53:10,950
on and shoots them off to the resource

00:53:08,940 --> 00:53:13,950
manager which sends the job to a

00:53:10,950 --> 00:53:15,839
different machine so yeah basically it's

00:53:13,950 --> 00:53:22,170
it's kind of a single node execution of

00:53:15,839 --> 00:53:27,780
it was third part of BSC what DSC bc o

00:53:22,170 --> 00:53:30,000
business PCSO pcs I would say it's still

00:53:27,780 --> 00:53:34,080
kind of a concept almost coming to

00:53:30,000 --> 00:53:36,599
understand but it's i would say resource

00:53:34,080 --> 00:53:38,910
imagine is manager as part of the pcs

00:53:36,599 --> 00:53:41,730
suite of tools pcs allows you to get

00:53:38,910 --> 00:53:42,540
information about the proper way in

00:53:41,730 --> 00:53:46,050
which your process

00:53:42,540 --> 00:53:48,030
data right so it contains monitoring

00:53:46,050 --> 00:53:51,480
applications and different information

00:53:48,030 --> 00:53:54,480
about how data is kind of going through

00:53:51,480 --> 00:53:57,420
your system resource management is part

00:53:54,480 --> 00:53:59,880
of that picture so it includes tools

00:53:57,420 --> 00:54:02,970
about which nodes are currently active

00:53:59,880 --> 00:54:05,940
which nodes are up and which nodes our

00:54:02,970 --> 00:54:07,650
potential jobs can be sent to but I

00:54:05,940 --> 00:54:11,040
would say it's part of that general

00:54:07,650 --> 00:54:12,660
concept so so pcs is aggregate tools

00:54:11,040 --> 00:54:15,660
that bring together information from

00:54:12,660 --> 00:54:17,100
multiple kaz services or file manage our

00:54:15,660 --> 00:54:19,530
workflow manager so if you wrote a tool

00:54:17,100 --> 00:54:21,360
that combines information from workflow

00:54:19,530 --> 00:54:23,430
and file manager it ends up in the PCs

00:54:21,360 --> 00:54:24,750
package so the two or three major things

00:54:23,430 --> 00:54:26,340
we have in there is Reese you mentioned

00:54:24,750 --> 00:54:27,780
is like a health monitoring service

00:54:26,340 --> 00:54:29,760
which connects to all the different

00:54:27,780 --> 00:54:31,080
services as well as like the crawlers

00:54:29,760 --> 00:54:33,120
and things like that and monitors their

00:54:31,080 --> 00:54:35,310
status and then provides like rest and

00:54:33,120 --> 00:54:37,110
JSON stuff back and then there's one for

00:54:35,310 --> 00:54:39,540
Providence because it's a multi file

00:54:37,110 --> 00:54:42,150
manager workflow manager kind of

00:54:39,540 --> 00:54:43,800
aggregator thingy and so that's pcs the

00:54:42,150 --> 00:54:45,900
answer to your question of Sam is that I

00:54:43,800 --> 00:54:49,500
think the information you're looking for

00:54:45,900 --> 00:54:52,440
is stored in the specification of the

00:54:49,500 --> 00:54:54,210
workflow job so when Rishi curates this

00:54:52,440 --> 00:54:56,280
information about the workflow you know

00:54:54,210 --> 00:54:58,890
task or whatever he puts this should go

00:54:56,280 --> 00:55:00,840
to the particular q that's Linux or this

00:54:58,890 --> 00:55:02,400
should go to the one that's windows and

00:55:00,840 --> 00:55:04,170
then the resource manager despite is

00:55:02,400 --> 00:55:06,720
based on that workflow metadata which

00:55:04,170 --> 00:55:08,640
thats against turned into resource

00:55:06,720 --> 00:55:12,300
manager information which one to task it

00:55:08,640 --> 00:55:14,280
too yeah yeah almost kind of just

00:55:12,300 --> 00:55:16,170
emphasizing that point it it all becomes

00:55:14,280 --> 00:55:17,970
part of the metadata so it's all kind of

00:55:16,170 --> 00:55:20,730
part of this giant chunk of meta de

00:55:17,970 --> 00:55:22,140
that's sent off to these tools and then

00:55:20,730 --> 00:55:23,910
the tools decide what they want to do

00:55:22,140 --> 00:55:26,040
with it but which node you want to run

00:55:23,910 --> 00:55:29,010
or which type of Q you want to run it in

00:55:26,040 --> 00:55:32,790
as part of the metadata for a particular

00:55:29,010 --> 00:55:34,680
workflow task okay if there any other

00:55:32,790 --> 00:55:36,120
questions we can take a more on break so

00:55:34,680 --> 00:55:41,000
it's break right now afterwards

00:55:36,120 --> 00:55:41,000

YouTube URL: https://www.youtube.com/watch?v=bJ_pEjYNZcA


