Title: vMotion and Apache Geode: The impact of live migration of vm'ss on an in-memory data grid
Publication date: 2020-10-15
Playlist: ApacheCon @Home 2020: Geode
Description: 
	vMotion and Apache Geode: Investigating the impact of live migration of virtual machines on an in-memory data grid
Nabarun Nag

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Avoiding downtime during maintenance or unforeseen machine issues is paramount for mission-critical, ready and available systems. To achieve this goal, VMware vSphere vMotion provides the capability for a zero-downtime live migration of virtual machine workloads from one server to another. During the entire duration of migration, all applications continue running and providing access to users. This feature can be also be automated using Dynamic Resource Scheduler which places a virtual machine in an optimal location in the server cluster. Pivotal Cloud Cache is an in-memory key-value store powered by Apache Geode, which is responsible for responding to large volume of concurrent read/write requests without compromising throughput and latency. Pivotal Cloud Cache also serves multiple use cases like event processing, transaction and session state caching, etc. in industries like finance and travel. To evaluate the impact of vMotion migration of virtual machines hosting Cloud Cache servers, we devised experiments where we deploy a Cloud Cache cluster using the Pivotal Platform in VMwareâ€™s Solutions lab. We then continuously migrate the virtual machines using vSphere SDK, while the cluster is under read and write workloads. We measure the impact on latency and throughput and also monitor that no members are being kicked out of the distributed system due to lack of response to heartbeat messages during the migration phase. This paper discusses the experiment design and results in detail.

Nabarun has been a code contributor and PMC member for Apache Geode since 2016, after graduating from University of Wisconsin-Madison. Prior to that, he worked for Samsung Research Institute. In his spare time, he likes to explore Portland's food scene and playing Apex Legends and Overwatch
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,720 --> 00:00:28,640
hello everyone

00:00:25,680 --> 00:00:30,160
uh i'm naver nang and welcome to my talk

00:00:28,640 --> 00:00:34,480
on vmware's v-motion

00:00:30,160 --> 00:00:34,480
and its reaction to apache geode

00:00:34,960 --> 00:00:40,000
a little short introduction about me

00:00:38,000 --> 00:00:41,920
i spent like four years as a geode

00:00:40,000 --> 00:00:44,399
committer and a pmc member

00:00:41,920 --> 00:00:46,480
i currently work as a staff software

00:00:44,399 --> 00:00:48,160
engineer at vmware

00:00:46,480 --> 00:00:50,559
in terms of geode like i've worked

00:00:48,160 --> 00:00:51,039
within gateways leucine and the querying

00:00:50,559 --> 00:00:53,760
engine

00:00:51,039 --> 00:00:56,160
and contributing on those specific areas

00:00:53,760 --> 00:00:56,160
right now

00:00:57,039 --> 00:01:01,280
um the agenda for this talk will be like

00:00:59,359 --> 00:01:03,359
i'll begin with a short introduction

00:01:01,280 --> 00:01:05,600
about apache geode and the topology that

00:01:03,359 --> 00:01:08,080
we'll be using in this experiment

00:01:05,600 --> 00:01:10,479
uh an explanation of all the

00:01:08,080 --> 00:01:11,760
terminologies that exist in the vmware's

00:01:10,479 --> 00:01:14,640
v sphere

00:01:11,760 --> 00:01:17,040
virtualization platform ecosystem and

00:01:14,640 --> 00:01:19,040
then the motivation the lab setup the

00:01:17,040 --> 00:01:20,880
experiments that we conducted

00:01:19,040 --> 00:01:24,479
the observations and the future work

00:01:20,880 --> 00:01:24,479
related to those experiments

00:01:25,360 --> 00:01:29,360
if i had to describe apache dude in one

00:01:27,520 --> 00:01:32,240
line like i would say it's a

00:01:29,360 --> 00:01:34,880
low latency highly concurrent consistent

00:01:32,240 --> 00:01:37,840
in memory data management solution

00:01:34,880 --> 00:01:39,759
two of the major components of the geode

00:01:37,840 --> 00:01:43,520
cluster are the locators and

00:01:39,759 --> 00:01:45,840
the geode servers locators act like

00:01:43,520 --> 00:01:48,000
coordinators in a distributed system

00:01:45,840 --> 00:01:49,360
they manage what members are present in

00:01:48,000 --> 00:01:51,200
the cluster

00:01:49,360 --> 00:01:52,479
also as you can see in this diagram one

00:01:51,200 --> 00:01:54,240
of their primary jobs

00:01:52,479 --> 00:01:56,079
is to allow the client to connect to a

00:01:54,240 --> 00:01:57,600
server like that client requested

00:01:56,079 --> 00:01:58,399
locator hey i want to connect to a

00:01:57,600 --> 00:02:00,320
server

00:01:58,399 --> 00:02:02,320
and the addresses are provided to the

00:02:00,320 --> 00:02:04,799
client by the locator

00:02:02,320 --> 00:02:07,280
geode servers they are like java

00:02:04,799 --> 00:02:09,200
processes which actually store the data

00:02:07,280 --> 00:02:10,800
in the cluster and also they also

00:02:09,200 --> 00:02:13,760
service all the requests

00:02:10,800 --> 00:02:15,680
that comes from the jio clients in this

00:02:13,760 --> 00:02:16,800
diagram you can see the white boxes

00:02:15,680 --> 00:02:20,080
which represents

00:02:16,800 --> 00:02:22,959
java java processes and then

00:02:20,080 --> 00:02:27,120
encapsulating a yellow host machine that

00:02:22,959 --> 00:02:27,120
can be a virtual machine or a bare metal

00:02:28,080 --> 00:02:31,840
uh next i would like to explain couple

00:02:29,760 --> 00:02:33,680
of terminologies associated with the

00:02:31,840 --> 00:02:37,440
vsphere environment

00:02:33,680 --> 00:02:40,560
first is esxi stands for elastic sky

00:02:37,440 --> 00:02:41,680
x integrated it's one of the bare metal

00:02:40,560 --> 00:02:44,800
hypervisors

00:02:41,680 --> 00:02:46,560
created by vmware as a hypervisor one of

00:02:44,800 --> 00:02:47,200
its prime responsibilities is to

00:02:46,560 --> 00:02:49,040
interpret

00:02:47,200 --> 00:02:50,879
all the instructions coming in from the

00:02:49,040 --> 00:02:52,800
virtual machine and send it to the

00:02:50,879 --> 00:02:55,599
operating system

00:02:52,800 --> 00:02:58,000
uh second term is vsphere vsphere is

00:02:55,599 --> 00:03:01,200
like the brains for a data center

00:02:58,000 --> 00:03:03,760
it handles the deployment the management

00:03:01,200 --> 00:03:04,480
administration monitoring handling

00:03:03,760 --> 00:03:06,080
network

00:03:04,480 --> 00:03:08,080
like everything that you can possibly

00:03:06,080 --> 00:03:11,120
handle in a data center can be handled

00:03:08,080 --> 00:03:11,120
through a vsphere client

00:03:13,040 --> 00:03:18,720
one of the important tools that vsphere

00:03:15,920 --> 00:03:20,879
has is a distributed resource scheduler

00:03:18,720 --> 00:03:23,440
like any scheduler in computer science

00:03:20,879 --> 00:03:25,920
world its main job is to manage

00:03:23,440 --> 00:03:27,760
workloads and resources is to assign

00:03:25,920 --> 00:03:30,080
resources to workloads

00:03:27,760 --> 00:03:31,840
in our case the workloads are virtual

00:03:30,080 --> 00:03:34,640
machines and the resources are the

00:03:31,840 --> 00:03:38,239
physical host machines

00:03:34,640 --> 00:03:40,879
so in able to do what drs is able to do

00:03:38,239 --> 00:03:42,959
it needs a tool called vmotion vmotion

00:03:40,879 --> 00:03:45,120
is a technology that allows a virtual

00:03:42,959 --> 00:03:48,319
machine to be migrated from one

00:03:45,120 --> 00:03:50,879
physical host to another without any

00:03:48,319 --> 00:03:50,879
downtime

00:03:52,879 --> 00:03:56,159
so since v motion is a very important

00:03:55,280 --> 00:03:58,400
component

00:03:56,159 --> 00:03:59,519
of our experiment i'd like to explain

00:03:58,400 --> 00:04:02,400
like how it's

00:03:59,519 --> 00:04:02,879
how it migrates one host machine from

00:04:02,400 --> 00:04:05,519
sorry

00:04:02,879 --> 00:04:06,480
one vm from one host machine to another

00:04:05,519 --> 00:04:09,599
so this is done

00:04:06,480 --> 00:04:11,280
within three phases so

00:04:09,599 --> 00:04:12,959
a virtual machine is running in a host

00:04:11,280 --> 00:04:15,200
system so it has its pages

00:04:12,959 --> 00:04:17,120
in the memory of the host machine so in

00:04:15,200 --> 00:04:19,280
phase one it puts tracers

00:04:17,120 --> 00:04:20,959
monitoring all the memory pages of that

00:04:19,280 --> 00:04:23,919
particular virtual machine

00:04:20,959 --> 00:04:25,040
like it monitors if any pages are dirty

00:04:23,919 --> 00:04:27,280
then it moves after

00:04:25,040 --> 00:04:29,280
all the tracers are installed it moves

00:04:27,280 --> 00:04:31,520
to phase two that's called the pre-copy

00:04:29,280 --> 00:04:33,440
phase in which it iteratively copies

00:04:31,520 --> 00:04:35,919
all the memory pages from one machine to

00:04:33,440 --> 00:04:36,720
another while monitoring which pages are

00:04:35,919 --> 00:04:38,800
dirty

00:04:36,720 --> 00:04:40,639
for example in this first diagram in

00:04:38,800 --> 00:04:42,560
iteration one we can see while it was

00:04:40,639 --> 00:04:44,880
copying the first iteration

00:04:42,560 --> 00:04:46,720
two of the pages were dirty so it will

00:04:44,880 --> 00:04:48,240
not copy those pages in the first

00:04:46,720 --> 00:04:49,199
iteration it will go on to second

00:04:48,240 --> 00:04:51,199
iteration

00:04:49,199 --> 00:04:53,680
it will continue multiple iterations

00:04:51,199 --> 00:04:55,520
till all the pages are copied from host

00:04:53,680 --> 00:04:57,600
the source host machine to the

00:04:55,520 --> 00:04:59,360
destination host machine

00:04:57,600 --> 00:05:00,880
then we go to phase three which is

00:04:59,360 --> 00:05:03,120
called the switch over phase

00:05:00,880 --> 00:05:04,320
in which we stop all the workload from

00:05:03,120 --> 00:05:06,560
going into the previous

00:05:04,320 --> 00:05:07,680
virtual machine and we start migrating

00:05:06,560 --> 00:05:09,280
them to the new

00:05:07,680 --> 00:05:12,240
virtual machine which has been started

00:05:09,280 --> 00:05:12,240
on a fresh machine

00:05:13,680 --> 00:05:18,479
now these three phases have different

00:05:16,479 --> 00:05:21,919
impact on a performance

00:05:18,479 --> 00:05:23,440
of a distributed system for example

00:05:21,919 --> 00:05:25,199
in our experiment one of the tiny

00:05:23,440 --> 00:05:25,680
experiments that we did is like we spun

00:05:25,199 --> 00:05:27,680
up two

00:05:25,680 --> 00:05:28,800
geode servers and continuously started

00:05:27,680 --> 00:05:31,280
doing puts on them

00:05:28,800 --> 00:05:33,199
and then we triggered vmotion and we

00:05:31,280 --> 00:05:34,240
wanted to see what's the impact of

00:05:33,199 --> 00:05:37,759
different phases

00:05:34,240 --> 00:05:38,080
on the performance of the geode cluster

00:05:37,759 --> 00:05:40,320
so

00:05:38,080 --> 00:05:41,520
over here we can see when the memory

00:05:40,320 --> 00:05:44,240
tracers were

00:05:41,520 --> 00:05:44,639
uh attached to the machine there was

00:05:44,240 --> 00:05:46,479
this

00:05:44,639 --> 00:05:48,560
drop in performance this is because like

00:05:46,479 --> 00:05:50,320
there's an overhead of bookkeeping like

00:05:48,560 --> 00:05:51,440
we're keeping track of which pages are

00:05:50,320 --> 00:05:54,080
getting dirty

00:05:51,440 --> 00:05:56,240
so this reduces the performance a bit

00:05:54,080 --> 00:05:58,960
and we see a significant drop

00:05:56,240 --> 00:06:00,400
over here this is during pay a phase 3

00:05:58,960 --> 00:06:02,400
in which we shut down the

00:06:00,400 --> 00:06:03,600
original vm and switch over all the

00:06:02,400 --> 00:06:06,160
workload to

00:06:03,600 --> 00:06:08,080
the newly started virtual machine so

00:06:06,160 --> 00:06:10,720
this has the maximum impact on the

00:06:08,080 --> 00:06:10,720
performance

00:06:12,080 --> 00:06:16,080
so over here you can see the

00:06:14,400 --> 00:06:17,600
configurations that we had for our

00:06:16,080 --> 00:06:18,400
physical machines and the virtual

00:06:17,600 --> 00:06:20,560
machines

00:06:18,400 --> 00:06:23,520
and i like to take some time to explain

00:06:20,560 --> 00:06:25,280
like why we wanted to do this uh

00:06:23,520 --> 00:06:27,199
experiment on what's the need for

00:06:25,280 --> 00:06:30,240
vmotion or drs

00:06:27,199 --> 00:06:32,080
so one of the obvious reasoning for free

00:06:30,240 --> 00:06:34,160
motion is like assume you have to do a

00:06:32,080 --> 00:06:36,560
scheduled maintenance on a host machine

00:06:34,160 --> 00:06:37,840
so uv motion all the vms out of that

00:06:36,560 --> 00:06:40,319
physical machine

00:06:37,840 --> 00:06:41,680
shut the vm shut the host machine down

00:06:40,319 --> 00:06:44,240
do your maintenance work

00:06:41,680 --> 00:06:45,280
and bring back all the motion so that's

00:06:44,240 --> 00:06:48,720
manual

00:06:45,280 --> 00:06:51,759
one of the important features of

00:06:48,720 --> 00:06:52,960
automated drs is to have a self-driving

00:06:51,759 --> 00:06:56,160
data center

00:06:52,960 --> 00:06:57,840
so as a drs if the drs is set in

00:06:56,160 --> 00:06:59,599
automated mode it has the entire

00:06:57,840 --> 00:07:01,440
holistic view of

00:06:59,599 --> 00:07:03,599
what resources are available in my data

00:07:01,440 --> 00:07:05,919
center and what workload is coming in

00:07:03,599 --> 00:07:08,400
so you'll continuously try to optimize

00:07:05,919 --> 00:07:10,319
and get the maximum performance out of a

00:07:08,400 --> 00:07:11,440
data center without any human

00:07:10,319 --> 00:07:13,120
intervention

00:07:11,440 --> 00:07:14,720
so this is one of the prime feature that

00:07:13,120 --> 00:07:18,080
vmotion had

00:07:14,720 --> 00:07:19,039
and automated trs so but when initial

00:07:18,080 --> 00:07:21,120
versions of

00:07:19,039 --> 00:07:23,360
vmotion were introduced it had a

00:07:21,120 --> 00:07:25,440
significant impact on the performance

00:07:23,360 --> 00:07:27,840
and that made the virtual machines uh

00:07:25,440 --> 00:07:29,360
unresponsive for a little bit of time

00:07:27,840 --> 00:07:31,759
but we also know in our distributed

00:07:29,360 --> 00:07:33,599
systems we have protocols set up in the

00:07:31,759 --> 00:07:35,759
membership and communication

00:07:33,599 --> 00:07:37,599
layers in which if a member is

00:07:35,759 --> 00:07:39,680
unresponsive for a particular amount of

00:07:37,599 --> 00:07:41,840
time we decide to kick it out of the

00:07:39,680 --> 00:07:43,680
distributed system like how geodes

00:07:41,840 --> 00:07:44,319
membership and communication protocols

00:07:43,680 --> 00:07:46,319
have a

00:07:44,319 --> 00:07:48,800
default value of 15 seconds like if a

00:07:46,319 --> 00:07:50,639
member is not responsive for 15 seconds

00:07:48,800 --> 00:07:52,879
we'll just kick it out of the

00:07:50,639 --> 00:07:54,400
distributed system or the cluster

00:07:52,879 --> 00:07:55,919
but now that has like serious

00:07:54,400 --> 00:07:57,840
implications like if a particular number

00:07:55,919 --> 00:08:00,639
of vms are kicked out it may lead to a

00:07:57,840 --> 00:08:04,080
split brain scenario which can have

00:08:00,639 --> 00:08:06,800
adverse effect on the geode cluster

00:08:04,080 --> 00:08:08,479
so the goal of our experiment was to go

00:08:06,800 --> 00:08:11,360
with the worst case scenario

00:08:08,479 --> 00:08:12,000
and see if our performance returns to

00:08:11,360 --> 00:08:14,319
the stable

00:08:12,000 --> 00:08:16,400
state or if any of the geode members

00:08:14,319 --> 00:08:19,599
were kicked out while the vmotion

00:08:16,400 --> 00:08:19,599
migrations were occurring

00:08:19,840 --> 00:08:23,759
uh here a brief description of the

00:08:22,160 --> 00:08:25,039
workloads that we used for our

00:08:23,759 --> 00:08:27,840
experiment

00:08:25,039 --> 00:08:29,680
for read we went with oql query oql

00:08:27,840 --> 00:08:32,399
stands for object query language which

00:08:29,680 --> 00:08:34,959
is like a nosql language which we use

00:08:32,399 --> 00:08:37,200
to query fields within a java object or

00:08:34,959 --> 00:08:39,279
the entire java object itself

00:08:37,200 --> 00:08:40,560
then we have for write operations we

00:08:39,279 --> 00:08:43,440
started using put all

00:08:40,560 --> 00:08:43,919
put all is like a batch operation like

00:08:43,440 --> 00:08:46,720
it

00:08:43,919 --> 00:08:47,440
chunks a group of write and just sends

00:08:46,720 --> 00:08:50,399
it down

00:08:47,440 --> 00:08:52,720
so for this we did a batch operation of

00:08:50,399 --> 00:08:54,720
thousand portfolio objects

00:08:52,720 --> 00:08:56,959
portfolio objects who are the instances

00:08:54,720 --> 00:08:57,519
of the portfolio class um portfolio if

00:08:56,959 --> 00:09:00,399
people are

00:08:57,519 --> 00:09:02,320
familiar with the patio code base

00:09:00,399 --> 00:09:03,680
portfolio class is the one that is used

00:09:02,320 --> 00:09:06,640
for all our testing

00:09:03,680 --> 00:09:08,720
benchmarking and everything for our

00:09:06,640 --> 00:09:10,160
experiments we filled up the geode

00:09:08,720 --> 00:09:12,480
cluster with 15 gigs

00:09:10,160 --> 00:09:16,000
of data which comes around approximately

00:09:12,480 --> 00:09:16,000
30 gigs with replication

00:09:17,680 --> 00:09:22,000
so how we did the migration so in this

00:09:19,839 --> 00:09:25,120
diagram you can see that every member

00:09:22,000 --> 00:09:27,040
in the cluster undergoes migration so we

00:09:25,120 --> 00:09:28,160
went to the worst case scenario in which

00:09:27,040 --> 00:09:30,399
we continuously

00:09:28,160 --> 00:09:31,279
keep on migrating all the members of the

00:09:30,399 --> 00:09:32,959
cluster one

00:09:31,279 --> 00:09:35,200
after one while the workloads are

00:09:32,959 --> 00:09:36,480
running to see like if geode can survive

00:09:35,200 --> 00:09:38,160
this worst case scenario

00:09:36,480 --> 00:09:40,560
we are sure that it will survive in a

00:09:38,160 --> 00:09:42,800
normal day-to-day operation

00:09:40,560 --> 00:09:45,600
so and how did we trigger this uh

00:09:42,800 --> 00:09:47,680
migration so we used uh vsphere's sdks

00:09:45,600 --> 00:09:48,240
to create an app so once the data was

00:09:47,680 --> 00:09:50,000
filled up

00:09:48,240 --> 00:09:54,080
and we started our experiment we could

00:09:50,000 --> 00:09:54,080
trigger vmotion using this app

00:09:55,760 --> 00:10:00,160
a couple of on the next couple of slides

00:09:57,920 --> 00:10:01,920
will show you our observation on

00:10:00,160 --> 00:10:04,160
different workloads and what was the

00:10:01,920 --> 00:10:06,480
impact on the geode cluster

00:10:04,160 --> 00:10:08,000
so over here in the first uh client

00:10:06,480 --> 00:10:10,560
throughput graph we can see

00:10:08,000 --> 00:10:12,160
that once the client skipped on it so

00:10:10,560 --> 00:10:12,959
first of all this is the experiment

00:10:12,160 --> 00:10:14,880
setup

00:10:12,959 --> 00:10:16,079
in which we had four apps which were

00:10:14,880 --> 00:10:19,120
doing continuous okl

00:10:16,079 --> 00:10:21,040
queries on the jio data grid so

00:10:19,120 --> 00:10:23,040
in the throughput chart we can see that

00:10:21,040 --> 00:10:25,279
when the clients keep on attaching

00:10:23,040 --> 00:10:26,640
and then work so there's a increasing

00:10:25,279 --> 00:10:27,920
number of clients connected to the

00:10:26,640 --> 00:10:28,640
system so there's increase in the

00:10:27,920 --> 00:10:31,279
workload

00:10:28,640 --> 00:10:32,560
and then it attains a steady state and

00:10:31,279 --> 00:10:35,200
then we trigger

00:10:32,560 --> 00:10:36,399
the migration of all the geode members

00:10:35,200 --> 00:10:39,760
present in the grid

00:10:36,399 --> 00:10:41,920
so a total of 28 virtual machine

00:10:39,760 --> 00:10:44,079
migration happen during this

00:10:41,920 --> 00:10:45,279
duration and we see that performance

00:10:44,079 --> 00:10:47,040
drop gets back

00:10:45,279 --> 00:10:48,720
and then immediately returns to a steady

00:10:47,040 --> 00:10:51,120
state once our

00:10:48,720 --> 00:10:53,040
once all the migrations have completed

00:10:51,120 --> 00:10:54,320
we can see a similar behavior in the

00:10:53,040 --> 00:10:55,839
server throughput here

00:10:54,320 --> 00:10:58,640
we see step by step when the four

00:10:55,839 --> 00:11:00,240
clients connected attains a stable state

00:10:58,640 --> 00:11:02,160
undergoes all the vmotion and then

00:11:00,240 --> 00:11:03,920
returns to a stable state

00:11:02,160 --> 00:11:06,000
this was for a read workload and we

00:11:03,920 --> 00:11:08,000
could see similar uh

00:11:06,000 --> 00:11:10,079
observations during our right workload

00:11:08,000 --> 00:11:12,079
we had four apps which were doing right

00:11:10,079 --> 00:11:14,480
operation on our geode grid

00:11:12,079 --> 00:11:16,240
and we can see virtual motion migration

00:11:14,480 --> 00:11:18,240
happening impacting the performance and

00:11:16,240 --> 00:11:22,000
then returning to a steady state

00:11:18,240 --> 00:11:24,000
and same can be seen on the server side

00:11:22,000 --> 00:11:25,920
then we decided to go to different mixed

00:11:24,000 --> 00:11:28,079
workload experiment in which

00:11:25,920 --> 00:11:30,160
we set up two apps to do continuous

00:11:28,079 --> 00:11:32,480
querying which is a read operation

00:11:30,160 --> 00:11:34,720
and two apps to do uh right operation

00:11:32,480 --> 00:11:37,440
and we observe the similar behavior

00:11:34,720 --> 00:11:39,839
in both client uh both clients which are

00:11:37,440 --> 00:11:42,480
doing the read and the right operations

00:11:39,839 --> 00:11:44,720
the motion migration drop in performance

00:11:42,480 --> 00:11:47,200
return back to their normal steady state

00:11:44,720 --> 00:11:49,519
once all the migrations were complete

00:11:47,200 --> 00:11:51,519
so once the migration happens the vms

00:11:49,519 --> 00:11:54,000
maintain their network address

00:11:51,519 --> 00:11:56,079
network name so it is as if the same

00:11:54,000 --> 00:11:58,240
member that's existed before prior to

00:11:56,079 --> 00:12:00,480
the migration

00:11:58,240 --> 00:12:01,440
uh we also scrub through all the logs

00:12:00,480 --> 00:12:04,000
and stats to

00:12:01,440 --> 00:12:05,600
see that to confirm that no members were

00:12:04,000 --> 00:12:08,720
kicked out during this migration

00:12:05,600 --> 00:12:10,720
phase if you look at numbers we can see

00:12:08,720 --> 00:12:14,639
that for read and write workloads there

00:12:10,720 --> 00:12:17,040
were a depth of 39 percent to 45 percent

00:12:14,639 --> 00:12:19,120
and the v motion duration on average

00:12:17,040 --> 00:12:21,040
took 36 seconds this is like all the

00:12:19,120 --> 00:12:22,639
three phases of the motion completed

00:12:21,040 --> 00:12:25,279
within 36 seconds

00:12:22,639 --> 00:12:28,560
and there was a drop of 39 to 45

00:12:25,279 --> 00:12:28,560
depending upon the workload

00:12:29,120 --> 00:12:32,880
now we went to the worst-case scenario

00:12:30,800 --> 00:12:34,480
this is like this will like hardly occur

00:12:32,880 --> 00:12:36,560
in a proper data center

00:12:34,480 --> 00:12:38,399
we went uh we also wanted to see what

00:12:36,560 --> 00:12:40,320
happens in a regular day to day ops like

00:12:38,399 --> 00:12:42,959
if one single server gets a

00:12:40,320 --> 00:12:44,480
free motion migration so over here we

00:12:42,959 --> 00:12:46,399
can see that for a small

00:12:44,480 --> 00:12:48,240
duration there will be dip and return

00:12:46,399 --> 00:12:48,720
back to the steady state immediately

00:12:48,240 --> 00:12:51,440
after

00:12:48,720 --> 00:12:53,519
the migration is completed similar

00:12:51,440 --> 00:12:55,120
observation for write ops with a

00:12:53,519 --> 00:12:57,680
blip and it's back to its normal

00:12:55,120 --> 00:12:57,680
operation

00:12:58,720 --> 00:13:01,920
during our read measurements we could

00:13:00,720 --> 00:13:04,000
see that there were

00:13:01,920 --> 00:13:05,680
like so there were four apps depending

00:13:04,000 --> 00:13:06,160
which client was connected to which

00:13:05,680 --> 00:13:08,639
server

00:13:06,160 --> 00:13:10,320
if it was unlucky enough to be connected

00:13:08,639 --> 00:13:12,320
to the server which

00:13:10,320 --> 00:13:13,839
underwent the free motion migration to

00:13:12,320 --> 00:13:15,760
have a slightly higher dip in

00:13:13,839 --> 00:13:18,399
performance for 10 seconds

00:13:15,760 --> 00:13:19,200
and we can see that dips varied from 18

00:13:18,399 --> 00:13:21,920
percent dip

00:13:19,200 --> 00:13:24,480
to a max of 35 between the four apps

00:13:21,920 --> 00:13:27,279
doing the rate operations

00:13:24,480 --> 00:13:27,680
for uh ride operations we could see a

00:13:27,279 --> 00:13:30,720
dip

00:13:27,680 --> 00:13:34,079
for 15 um to 17.

00:13:30,720 --> 00:13:38,000
sorry 10 minimum to 17 on

00:13:34,079 --> 00:13:39,120
average so what's the conclusion for

00:13:38,000 --> 00:13:40,399
this experiment

00:13:39,120 --> 00:13:42,480
we could confirm that there is a

00:13:40,399 --> 00:13:44,000
temporary drop in performance but it was

00:13:42,480 --> 00:13:45,680
for a short duration

00:13:44,000 --> 00:13:47,360
and we could see that they resumed their

00:13:45,680 --> 00:13:50,720
normal steady state operation

00:13:47,360 --> 00:13:52,399
immediately after

00:13:50,720 --> 00:13:54,800
after the motion migrations have

00:13:52,399 --> 00:13:55,680
completed we also confirmed that during

00:13:54,800 --> 00:13:58,320
this migration

00:13:55,680 --> 00:13:58,880
no members became unresponsive or kicked

00:13:58,320 --> 00:14:01,920
out by

00:13:58,880 --> 00:14:03,040
geodes membership and communication

00:14:01,920 --> 00:14:05,040
protocols

00:14:03,040 --> 00:14:06,160
and we could see an average decrease of

00:14:05,040 --> 00:14:08,000
40 percent

00:14:06,160 --> 00:14:11,120
uh in the throughput during this

00:14:08,000 --> 00:14:11,120
migration duration

00:14:11,360 --> 00:14:16,560
so the future so recently vsphere 7 was

00:14:14,800 --> 00:14:18,720
released and they are re-architecting

00:14:16,560 --> 00:14:20,160
entire vsphere based on the kubernetes

00:14:18,720 --> 00:14:22,160
framework

00:14:20,160 --> 00:14:24,000
so they have implemented more algorithms

00:14:22,160 --> 00:14:26,639
in which when we attach

00:14:24,000 --> 00:14:27,199
the memory tracers the impact on memory

00:14:26,639 --> 00:14:29,839
tracing

00:14:27,199 --> 00:14:32,000
and performance is minimized and also

00:14:29,839 --> 00:14:34,240
saturating the network so that

00:14:32,000 --> 00:14:35,440
the switch over phase is faster and

00:14:34,240 --> 00:14:38,320
there's a shorter

00:14:35,440 --> 00:14:40,480
dip in performance during that time so

00:14:38,320 --> 00:14:43,680
we are also in discussions with creating

00:14:40,480 --> 00:14:46,000
a collaborative system in which vsphere

00:14:43,680 --> 00:14:48,399
informs jio that hey we are about to

00:14:46,000 --> 00:14:50,320
migrate a particular server remember

00:14:48,399 --> 00:14:51,920
and our membership protocol can take

00:14:50,320 --> 00:14:53,760
medication steps like

00:14:51,920 --> 00:14:56,480
not allowing clients to connect to that

00:14:53,760 --> 00:14:58,320
particular step a particular server

00:14:56,480 --> 00:14:59,680
when it's about to undergo the emotion

00:14:58,320 --> 00:15:01,519
migration

00:14:59,680 --> 00:15:03,440
so these are the things that we are

00:15:01,519 --> 00:15:04,959
currently working on and looking forward

00:15:03,440 --> 00:15:07,600
in the future

00:15:04,959 --> 00:15:09,760
so a detail a detailed report has been

00:15:07,600 --> 00:15:10,320
published by vmware which you can find

00:15:09,760 --> 00:15:27,839
at this

00:15:10,320 --> 00:15:27,839
link and i'm ready for some questions

00:15:38,839 --> 00:15:41,839
uh

00:16:05,920 --> 00:16:09,360
all right i guess i'll wait for one

00:16:07,839 --> 00:16:13,440
minute if there's no

00:16:09,360 --> 00:16:13,440
no questions we can finish up the

00:16:20,839 --> 00:16:24,639
session

00:16:22,000 --> 00:16:24,639
you alberto

00:16:35,199 --> 00:16:51,839
all right everyone have a great day

00:16:37,120 --> 00:16:51,839
thank you

00:16:52,399 --> 00:16:54,480

YouTube URL: https://www.youtube.com/watch?v=78SQNJUIRGg


