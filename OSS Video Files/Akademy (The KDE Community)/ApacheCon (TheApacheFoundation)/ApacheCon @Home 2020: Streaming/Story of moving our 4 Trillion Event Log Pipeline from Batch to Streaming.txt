Title: Story of moving our 4 Trillion Event Log Pipeline from Batch to Streaming
Publication date: 2020-10-22
Playlist: ApacheCon @Home 2020: Streaming
Description: 
	Story of moving our 4 Trillion Event Log Pipeline from Batch to Streaming
Lohit VijayaRenu, Zhenzhao Wang, Praveen Killamsetti

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Twitter's LogPipeline handle more than 4Trillion events per day. This complex pipeline has evolved over the years to support Twitter's scale of data. This pipeline is designed to be resilient, support high throughput and use resources efficiently. Because of its legacy architecture, it was still batch pipeline at scale. For some time, our team has been redesigning this to support streaming use cases and have done significant architecture changes for this pipeline In this talk we deep dive into our old architecture, highlight pros and cons of that and describe how we are making changes for it to be more streaming friendly. We talk about various open source projects such as Apache Hadoop, Apache Flume, Apache Tez, Apache Beam and cloud technologies which tie together to form our large scale event LogPipeline.

Lohit VijayaRenu:
Lohit is part of DataPlatform team at Twitter. He concentrates on projects around storage, compute and log pipeline for Twitter scale both on premise and cloud. He has worked at several startups before joining Twitter. He has a Masters degree in Computer Science from Stony Brook University.
Zhenzhao Wang:
Zhenzhao works at Twitter as part of Hadoop and Log Management team. He is currently concentrating on Twitter Log Ingestion Pipeline which scales to handle trillions of events per day. Previously he was a member of DFS(Pangu) team in Alibaba Cloud where he focused on feature for random file access file in Pangu used as storage for Virtual Machines. He has Bachelor's degree from Nankai University and Master's degree from Tsinghua University.
Praveen Killamsetti
Praveen works at Twitter as part of the DataPlatform organization. In his current role, he is working on scaling the log ingestion pipeline to trillions of events in the streaming model and building a data set lifecycle management system for analytical data sets. He has a master degree in computer science from IIT Madras. Before joining Twitter, Praveen worked on building distributed storage systems at Nimble Storage, NetApp and built various products including Synchronous Replication across multiple data centers with automatic failover, Write Optimized KV stores, Dedupe and Compression stack, Efficient Cloning features, Archiving Storage Snapshots to S3 efficiently etc.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:28,000 --> 00:00:31,599
okay

00:00:28,400 --> 00:00:35,040
so should we start um

00:00:31,599 --> 00:00:36,880
uh hi folks uh i'm jin zhao uh today i

00:00:35,040 --> 00:00:40,000
will call presenter with uh praveen

00:00:36,880 --> 00:00:42,079
uh laureate is not here so tell me

00:00:40,000 --> 00:00:43,280
if you want to uh hi folks this is

00:00:42,079 --> 00:00:45,360
praveen kilimanjati

00:00:43,280 --> 00:00:46,879
we are excited to share our work from

00:00:45,360 --> 00:00:49,920
twitter

00:00:46,879 --> 00:00:53,600
go head ginger hi so

00:00:49,920 --> 00:00:55,520
um our trainer uh we have a complex law

00:00:53,600 --> 00:00:58,640
paper plan to handle data

00:00:55,520 --> 00:01:01,680
at twitter scale which is about a 4 3.4

00:00:58,640 --> 00:01:04,640
to 4.1 trillion events per day

00:01:01,680 --> 00:01:05,439
um we had been involving this low

00:01:04,640 --> 00:01:08,240
pipeline

00:01:05,439 --> 00:01:08,720
for over the past years it is designed

00:01:08,240 --> 00:01:12,000
to be

00:01:08,720 --> 00:01:15,759
resilient high scalable and use resource

00:01:12,000 --> 00:01:17,759
efficiently it was it worked pretty well

00:01:15,759 --> 00:01:18,799
however because of the the latest

00:01:17,759 --> 00:01:21,840
architecture

00:01:18,799 --> 00:01:25,040
it is still a batch law pipeline

00:01:21,840 --> 00:01:27,040
pretty much hdfs and check

00:01:25,040 --> 00:01:29,040
so for some time we have been

00:01:27,040 --> 00:01:32,159
redesigning our architecture

00:01:29,040 --> 00:01:35,040
to serve the streaming use cases uh

00:01:32,159 --> 00:01:37,040
better uh we have done lots of changes

00:01:35,040 --> 00:01:40,640
to our architecture

00:01:37,040 --> 00:01:42,799
so today we are going to deep dive into

00:01:40,640 --> 00:01:45,040
our own love love helpline share

00:01:42,799 --> 00:01:48,159
supports and accounts

00:01:45,040 --> 00:01:51,759
um in the meantime we want to describe

00:01:48,159 --> 00:01:54,320
into how the uh our new law plan works

00:01:51,759 --> 00:01:55,759
how it it could serve streaming cases

00:01:54,320 --> 00:01:59,920
better

00:01:55,759 --> 00:02:02,799
so um so to to start

00:01:59,920 --> 00:02:03,280
uh i'd like to like to share the skill

00:02:02,799 --> 00:02:05,200
um

00:02:03,280 --> 00:02:07,200
as i said in the beginning the even

00:02:05,200 --> 00:02:09,840
number is about 3.4

00:02:07,200 --> 00:02:10,879
for the 130 events and the day size

00:02:09,840 --> 00:02:13,599
before compression

00:02:10,879 --> 00:02:14,800
is about the 10 pair price today and

00:02:13,599 --> 00:02:17,920
note that

00:02:14,800 --> 00:02:22,400
um the traffic is still still green

00:02:17,920 --> 00:02:23,920
every year uh it's growing rapidly so if

00:02:22,400 --> 00:02:27,760
we are going to build something

00:02:23,920 --> 00:02:31,120
something uh if it is definitely

00:02:27,760 --> 00:02:31,680
need to be scalable so how is the

00:02:31,120 --> 00:02:35,120
architect

00:02:31,680 --> 00:02:37,920
like um as

00:02:35,120 --> 00:02:39,680
shown in uh just just for some people

00:02:37,920 --> 00:02:40,239
which are not familiar with the log

00:02:39,680 --> 00:02:44,000
injection

00:02:40,239 --> 00:02:47,120
system so by the event here we mean

00:02:44,000 --> 00:02:49,599
um we mean something like

00:02:47,120 --> 00:02:51,519
as clicky infer and like even to the

00:02:49,599 --> 00:02:54,560
like even the infer

00:02:51,519 --> 00:02:55,920
we click them and put them in swift

00:02:54,560 --> 00:02:58,959
format or json

00:02:55,920 --> 00:03:01,840
format or protocol buffer format

00:02:58,959 --> 00:03:04,879
then we send it to our law paper and the

00:03:01,840 --> 00:03:06,800
goal of the law paper is to deliver the

00:03:04,879 --> 00:03:10,560
data to hdfs

00:03:06,800 --> 00:03:14,080
in hourly format so the data is uh

00:03:10,560 --> 00:03:16,239
is organized by uh log categories

00:03:14,080 --> 00:03:18,319
the lock the log category is the

00:03:16,239 --> 00:03:21,519
equivalent the concept of a topic

00:03:18,319 --> 00:03:24,480
in the other systems so

00:03:21,519 --> 00:03:26,159
um after the log pipeline deliver data

00:03:24,480 --> 00:03:28,879
to hdfs

00:03:26,159 --> 00:03:29,599
as shown in the picture uh user might

00:03:28,879 --> 00:03:32,480
want

00:03:29,599 --> 00:03:33,920
access the data from different systems

00:03:32,480 --> 00:03:36,319
by different uh

00:03:33,920 --> 00:03:38,080
analytic tools for example they won't

00:03:36,319 --> 00:03:40,239
see the data

00:03:38,080 --> 00:03:42,000
in production cluster at high class

00:03:40,239 --> 00:03:44,239
record cluster or

00:03:42,000 --> 00:03:46,560
google cloud storage so we have a

00:03:44,239 --> 00:03:49,680
replica service to replicate it

00:03:46,560 --> 00:03:50,400
to um to use a specified cluster then

00:03:49,680 --> 00:03:54,000
user could

00:03:50,400 --> 00:03:56,159
consume it so um

00:03:54,000 --> 00:03:58,799
if we look into our architecture of law

00:03:56,159 --> 00:04:01,840
pipeline it's pretty modularized

00:03:58,799 --> 00:04:03,280
from a high level we could uh it could

00:04:01,840 --> 00:04:07,120
be divided into

00:04:03,280 --> 00:04:10,319
five components so first is a client

00:04:07,120 --> 00:04:12,480
um the class if if

00:04:10,319 --> 00:04:15,040
we want to collect inter from outside of

00:04:12,480 --> 00:04:18,239
the d center like the ios can

00:04:15,040 --> 00:04:21,680
under client they will send the data

00:04:18,239 --> 00:04:24,800
by address for api to our internal

00:04:21,680 --> 00:04:27,680
service first and if the event is

00:04:24,800 --> 00:04:29,280
from an internet service like our

00:04:27,680 --> 00:04:32,880
timeline servers

00:04:29,280 --> 00:04:35,919
uh it will be sent it will be sent

00:04:32,880 --> 00:04:39,520
to the uh to to to our long

00:04:35,919 --> 00:04:40,880
uh client subscribe demon on note

00:04:39,520 --> 00:04:42,800
on every note we have a long

00:04:40,880 --> 00:04:46,400
long-running demon process

00:04:42,800 --> 00:04:49,440
to try to collect the evidence of the

00:04:46,400 --> 00:04:52,960
from the servers in the host

00:04:49,440 --> 00:04:55,600
so um so

00:04:52,960 --> 00:04:58,080
after the continue get the data it will

00:04:55,600 --> 00:05:00,400
send data to our aggregation layer

00:04:58,080 --> 00:05:01,360
we have a band travel servers everyday

00:05:00,400 --> 00:05:04,080
center

00:05:01,360 --> 00:05:04,720
the goal of the aggregator layer is to

00:05:04,080 --> 00:05:07,759
persist

00:05:04,720 --> 00:05:09,360
the data as as soon as possible they

00:05:07,759 --> 00:05:13,199
will write it to hdfs

00:05:09,360 --> 00:05:16,240
because once the data is in each dfs

00:05:13,199 --> 00:05:17,759
it's doable it won't be lost then we

00:05:16,240 --> 00:05:20,320
have another layer

00:05:17,759 --> 00:05:21,520
catalog processing to read the output of

00:05:20,320 --> 00:05:25,280
the

00:05:21,520 --> 00:05:27,919
aggregators and try to do something like

00:05:25,280 --> 00:05:30,080
a clean up of the crappy records

00:05:27,919 --> 00:05:31,120
to format a conversion like convert to

00:05:30,080 --> 00:05:33,360
parquet

00:05:31,120 --> 00:05:34,800
and also do better compression reduce

00:05:33,360 --> 00:05:37,360
small files

00:05:34,800 --> 00:05:38,880
so after the data is processed we will

00:05:37,360 --> 00:05:42,960
write it back to hdfs

00:05:38,880 --> 00:05:44,560
again now the data is already in the

00:05:42,960 --> 00:05:47,360
format the users want

00:05:44,560 --> 00:05:48,000
it is ready to be delivered to users but

00:05:47,360 --> 00:05:50,720
also

00:05:48,000 --> 00:05:52,720
but as shown in the above picture user

00:05:50,720 --> 00:05:53,360
might want to access data from different

00:05:52,720 --> 00:05:56,160
htf

00:05:53,360 --> 00:05:56,960
clusters or gcs so we have a wrapping

00:05:56,160 --> 00:06:01,120
service

00:05:56,960 --> 00:06:05,680
to merge the data from all data centers

00:06:01,120 --> 00:06:09,280
and deliver whole design to users

00:06:05,680 --> 00:06:12,720
the user could use a leverage repressor

00:06:09,280 --> 00:06:16,479
spark to consume it and the last

00:06:12,720 --> 00:06:20,000
component is the even lock management

00:06:16,479 --> 00:06:23,039
so um from high level in the two things

00:06:20,000 --> 00:06:25,199
first is the metadata management uh we

00:06:23,039 --> 00:06:28,160
have some polar category

00:06:25,199 --> 00:06:30,160
or also topic metadata like the owner

00:06:28,160 --> 00:06:32,319
the schema infra

00:06:30,160 --> 00:06:33,840
the second function of the log

00:06:32,319 --> 00:06:36,960
management is uh

00:06:33,840 --> 00:06:40,160
to provide the data discovery

00:06:36,960 --> 00:06:41,520
uh functionality it will record where

00:06:40,160 --> 00:06:44,400
the data is stored

00:06:41,520 --> 00:06:46,000
uh how is the segmented is it based on

00:06:44,400 --> 00:06:49,919
hourly or

00:06:46,000 --> 00:06:51,680
uh or a shorter even shorter period

00:06:49,919 --> 00:06:53,280
and the way it is stopped you know some

00:06:51,680 --> 00:06:57,199
people like that

00:06:53,280 --> 00:06:59,280
so we had been uh running the uh the

00:06:57,199 --> 00:07:00,400
other law pipeline for years we hadn't

00:06:59,280 --> 00:07:04,319
learned a lot from

00:07:00,400 --> 00:07:05,919
it so for example we

00:07:04,319 --> 00:07:08,479
learned that the modulization is a

00:07:05,919 --> 00:07:11,360
component so in architecture we

00:07:08,479 --> 00:07:12,960
keep each component independent and

00:07:11,360 --> 00:07:14,720
plug-able

00:07:12,960 --> 00:07:16,160
we had even you know replace our

00:07:14,720 --> 00:07:20,560
aggregation layer without

00:07:16,160 --> 00:07:23,360
any impact to any users or any servers

00:07:20,560 --> 00:07:25,759
and we make each component the skill

00:07:23,360 --> 00:07:27,680
independently

00:07:25,759 --> 00:07:29,360
they they don't have a deep tie they

00:07:27,680 --> 00:07:33,759
just come they just communicate

00:07:29,360 --> 00:07:37,199
communicated by a simple protocol

00:07:33,759 --> 00:07:39,280
we also learned that in some scenario we

00:07:37,199 --> 00:07:40,560
want to share the resource to improve

00:07:39,280 --> 00:07:43,360
the utilization and the

00:07:40,560 --> 00:07:46,319
resiliency but in the meantime we want

00:07:43,360 --> 00:07:50,240
to we want the result to be isolated

00:07:46,319 --> 00:07:53,280
between here to control the blast radius

00:07:50,240 --> 00:07:55,039
so um what we have done is

00:07:53,280 --> 00:07:56,960
we just divided the traffic into

00:07:55,039 --> 00:07:59,599
different tiers

00:07:56,960 --> 00:08:01,759
inside the tree we share the resource

00:07:59,599 --> 00:08:03,039
but between the tiers we make it totally

00:08:01,759 --> 00:08:06,560
isolated and

00:08:03,039 --> 00:08:09,199
independently for example we skip we

00:08:06,560 --> 00:08:10,800
isolate our test traffic with the

00:08:09,199 --> 00:08:13,919
production traffic

00:08:10,800 --> 00:08:16,400
and uh yeah something like that

00:08:13,919 --> 00:08:18,560
so the next thing i want to highlight is

00:08:16,400 --> 00:08:21,520
the scalability is always a primary

00:08:18,560 --> 00:08:22,560
concern the traffic goes every year and

00:08:21,520 --> 00:08:26,000
the traffic can make

00:08:22,560 --> 00:08:27,680
everything hard like at least to our

00:08:26,000 --> 00:08:30,400
htfs

00:08:27,680 --> 00:08:32,000
nymph node problem the non-laymate the

00:08:30,400 --> 00:08:34,240
small fights problem

00:08:32,000 --> 00:08:36,080
and also because the traffic is too too

00:08:34,240 --> 00:08:38,800
big it also

00:08:36,080 --> 00:08:40,080
you know just uh casting lots of

00:08:38,800 --> 00:08:43,039
pressure to our

00:08:40,080 --> 00:08:45,200
network so we also involved some qs

00:08:43,039 --> 00:08:49,200
mechanism to handle it

00:08:45,200 --> 00:08:54,480
um so another thing we learned is

00:08:49,200 --> 00:08:57,279
like uh that users make mistakes

00:08:54,480 --> 00:08:58,959
it's hard you you couldn't imagine what

00:08:57,279 --> 00:09:00,720
you you couldn't assume you should

00:08:58,959 --> 00:09:03,600
always behave correctly

00:09:00,720 --> 00:09:04,480
it might make you know something

00:09:03,600 --> 00:09:06,640
unexpected

00:09:04,480 --> 00:09:08,720
for example they might make backing

00:09:06,640 --> 00:09:12,720
incompatible schema changes

00:09:08,720 --> 00:09:12,720
which is not accessible for key

00:09:13,279 --> 00:09:16,880
we also learn losing our debug

00:09:15,680 --> 00:09:18,959
debuggability

00:09:16,880 --> 00:09:20,560
and some problems like long-tail problem

00:09:18,959 --> 00:09:22,800
dc field world support

00:09:20,560 --> 00:09:25,360
but because of a time limit i won't go

00:09:22,800 --> 00:09:28,560
too into the details

00:09:25,360 --> 00:09:31,519
um but when we come into the new

00:09:28,560 --> 00:09:31,839
uh law paper plan we definitely want to

00:09:31,519 --> 00:09:36,000
take

00:09:31,839 --> 00:09:39,760
the lessons we learned into uh into it

00:09:36,000 --> 00:09:43,120
so um so for the new law pipeline

00:09:39,760 --> 00:09:45,440
we we are not going we

00:09:43,120 --> 00:09:46,959
we're not going to just totally abandon

00:09:45,440 --> 00:09:50,000
the the batch cases

00:09:46,959 --> 00:09:53,040
or our on-prem environment instead

00:09:50,000 --> 00:09:56,800
we want to build a hybrid environment

00:09:53,040 --> 00:10:00,240
which could uh integrate our on-prem

00:09:56,800 --> 00:10:00,640
clusters on-prem environment seamlessly

00:10:00,240 --> 00:10:04,720
with

00:10:00,640 --> 00:10:06,000
our clouds and we want on-prem parody on

00:10:04,720 --> 00:10:08,240
cloud

00:10:06,000 --> 00:10:09,839
we want uh we wanted the new locker plan

00:10:08,240 --> 00:10:13,200
could could empower

00:10:09,839 --> 00:10:14,160
uh most users to try more streaming user

00:10:13,200 --> 00:10:16,720
cases

00:10:14,160 --> 00:10:18,399
for example the google data flow on

00:10:16,720 --> 00:10:21,760
google cloud

00:10:18,399 --> 00:10:24,399
and a big query in a real-time query

00:10:21,760 --> 00:10:24,880
but in the meantime you know we we also

00:10:24,399 --> 00:10:27,440
want to

00:10:24,880 --> 00:10:29,519
search the batch user case as well like

00:10:27,440 --> 00:10:33,200
people use spark data flow

00:10:29,519 --> 00:10:34,720
and then presto so another goal is about

00:10:33,200 --> 00:10:38,000
scalability you know like

00:10:34,720 --> 00:10:39,920
we mentioned that uh we we want to build

00:10:38,000 --> 00:10:42,399
something which could

00:10:39,920 --> 00:10:43,279
be able to handle the traffic and the

00:10:42,399 --> 00:10:45,839
traffic

00:10:43,279 --> 00:10:48,079
increase over the next years we

00:10:45,839 --> 00:10:51,360
definitely do want to build something

00:10:48,079 --> 00:10:53,360
and to make it do a major change you

00:10:51,360 --> 00:10:55,920
know just next year

00:10:53,360 --> 00:10:59,120
uh the last thing i want to highlight is

00:10:55,920 --> 00:11:00,800
the cognitive and pdp

00:10:59,120 --> 00:11:03,360
in the new law pipeline we want to

00:11:00,800 --> 00:11:06,560
leverage cloud-native technologies

00:11:03,360 --> 00:11:09,600
as much as possible uh

00:11:06,560 --> 00:11:10,079
we we we we're not trying to build the

00:11:09,600 --> 00:11:12,000
same

00:11:10,079 --> 00:11:14,399
everything on our own we want to

00:11:12,000 --> 00:11:17,920
leverage connect technologies

00:11:14,399 --> 00:11:21,279
and you know like the the their security

00:11:17,920 --> 00:11:22,800
features and their their

00:11:21,279 --> 00:11:24,560
streaming community engine like data

00:11:22,800 --> 00:11:27,440
flow um

00:11:24,560 --> 00:11:28,720
the last thing is about pdp so ptp means

00:11:27,440 --> 00:11:32,160
uh here i mean

00:11:28,720 --> 00:11:36,000
probability of protection so i treated

00:11:32,160 --> 00:11:38,320
this is always our top priority um

00:11:36,000 --> 00:11:39,360
when we build a new law pipeline we uh

00:11:38,320 --> 00:11:43,120
the the private

00:11:39,360 --> 00:11:44,800
data protection is our top kingston we

00:11:43,120 --> 00:11:47,600
have done lots of

00:11:44,800 --> 00:11:49,040
lost work to define the permission model

00:11:47,600 --> 00:11:51,040
and limit process

00:11:49,040 --> 00:11:53,279
encryption checksum and something like

00:11:51,040 --> 00:11:53,279
that

00:11:53,360 --> 00:11:58,320
so uh next i will introduce how we build

00:11:57,440 --> 00:12:01,040
a law paper

00:11:58,320 --> 00:12:02,240
in gcp gcp here i mean in google cloud

00:12:01,040 --> 00:12:04,160
platform

00:12:02,240 --> 00:12:05,519
so before we're going to go to the

00:12:04,160 --> 00:12:08,000
architecture i would

00:12:05,519 --> 00:12:09,440
like to share the user cases from a high

00:12:08,000 --> 00:12:12,639
level

00:12:09,440 --> 00:12:15,839
um on the cloud

00:12:12,639 --> 00:12:17,680
users could uh send data from gte this

00:12:15,839 --> 00:12:20,079
is a very common use cases

00:12:17,680 --> 00:12:22,320
but it's possible they are the they

00:12:20,079 --> 00:12:23,920
might also send data from the virtual

00:12:22,320 --> 00:12:25,839
machines

00:12:23,920 --> 00:12:28,240
they also costing data from some

00:12:25,839 --> 00:12:31,839
serverless functions some cognitive

00:12:28,240 --> 00:12:35,360
features like cloud function google ap

00:12:31,839 --> 00:12:38,399
apps engine and from the consumer's

00:12:35,360 --> 00:12:39,200
perspective from high level you know it

00:12:38,399 --> 00:12:42,880
is a

00:12:39,200 --> 00:12:46,160
badge of streaming for better process

00:12:42,880 --> 00:12:49,279
uh we need to deliver the data to

00:12:46,160 --> 00:12:49,839
uh produce uh storage uh on google cloud

00:12:49,279 --> 00:12:53,360
we will use

00:12:49,839 --> 00:12:53,839
gcs we were delivered to gcs the user

00:12:53,360 --> 00:12:57,200
could

00:12:53,839 --> 00:13:01,920
do better processing uh

00:12:57,200 --> 00:13:04,720
by by uh by spark data flow

00:13:01,920 --> 00:13:07,040
or scouting the second user case is

00:13:04,720 --> 00:13:10,800
screen processing

00:13:07,040 --> 00:13:13,600
so for streams processing i guess

00:13:10,800 --> 00:13:15,600
there are many use cases users might

00:13:13,600 --> 00:13:18,079
want to consume the data directly from

00:13:15,600 --> 00:13:19,360
the subscriber storage from the pop-tart

00:13:18,079 --> 00:13:21,040
system

00:13:19,360 --> 00:13:23,760
and also they might want to see their

00:13:21,040 --> 00:13:26,720
data in bigquery in real time

00:13:23,760 --> 00:13:29,519
so for the new law pipeline we we want

00:13:26,720 --> 00:13:29,519
to you know just

00:13:29,839 --> 00:13:34,880
want to solve the cases from both the

00:13:32,160 --> 00:13:39,199
producer side and the consume side

00:13:34,880 --> 00:13:42,560
well so here's architecture we

00:13:39,199 --> 00:13:45,839
figure out um it is also pretty

00:13:42,560 --> 00:13:48,480
modelized uh from high level it is

00:13:45,839 --> 00:13:48,880
you know similar to uh to what we have

00:13:48,480 --> 00:13:52,560
on

00:13:48,880 --> 00:13:55,920
brand so the first layer is about

00:13:52,560 --> 00:13:58,959
the client we provide a unity unified

00:13:55,920 --> 00:14:02,000
kind library which abstracts the backend

00:13:58,959 --> 00:14:04,959
uh difference where we just disguised

00:14:02,000 --> 00:14:07,199
we just uh this uh we just shadow the

00:14:04,959 --> 00:14:09,920
difference between gcp

00:14:07,199 --> 00:14:13,279
and on-prem uh you know scene like

00:14:09,920 --> 00:14:16,320
authentication something like that

00:14:13,279 --> 00:14:17,760
so the unified library on cloud it

00:14:16,320 --> 00:14:20,000
wasn't needed to pop up

00:14:17,760 --> 00:14:21,600
the pub server will be our aggregation

00:14:20,000 --> 00:14:24,079
layer

00:14:21,600 --> 00:14:25,760
we will map every log category to google

00:14:24,079 --> 00:14:28,639
sub topic

00:14:25,760 --> 00:14:29,519
but we will add a lot of rich metadata

00:14:28,639 --> 00:14:32,880
headers

00:14:29,519 --> 00:14:34,639
like the checksum infer the the encoding

00:14:32,880 --> 00:14:36,880
infer

00:14:34,639 --> 00:14:39,040
so once the data in pops up ideally the

00:14:36,880 --> 00:14:41,199
user could write a dataflow java or spar

00:14:39,040 --> 00:14:44,240
job to consume it

00:14:41,199 --> 00:14:47,360
but we noticed that

00:14:44,240 --> 00:14:48,320
uh there are some common use cases you

00:14:47,360 --> 00:14:50,240
know is

00:14:48,320 --> 00:14:52,959
one is like the google cloud storage

00:14:50,240 --> 00:14:55,519
they want to want it there to be

00:14:52,959 --> 00:14:57,360
to do batch processing and another case

00:14:55,519 --> 00:15:00,560
is like users want to see

00:14:57,360 --> 00:15:01,199
their data in bigquery so to better

00:15:00,560 --> 00:15:03,680
solve these

00:15:01,199 --> 00:15:05,600
these cases instead of asking users to

00:15:03,680 --> 00:15:08,800
write their job on their own we

00:15:05,600 --> 00:15:12,160
we we did the job for them we provide

00:15:08,800 --> 00:15:15,279
a manager environment to do such

00:15:12,160 --> 00:15:16,320
things we call these components

00:15:15,279 --> 00:15:18,720
processors

00:15:16,320 --> 00:15:20,560
for example we have the pops up to

00:15:18,720 --> 00:15:23,760
google cloud storage processor

00:15:20,560 --> 00:15:24,399
the google google cloud to to bigquery

00:15:23,760 --> 00:15:28,560
stream

00:15:24,399 --> 00:15:31,920
processors we leverage the data flow to

00:15:28,560 --> 00:15:36,320
google cloud computer engine to do it

00:15:31,920 --> 00:15:38,839
and we the processors is polar category

00:15:36,320 --> 00:15:40,320
and we will have you know thousands of

00:15:38,839 --> 00:15:42,160
processors

00:15:40,320 --> 00:15:43,519
in order to management we need a

00:15:42,160 --> 00:15:46,320
component that this

00:15:43,519 --> 00:15:47,519
is why we come up with the log processor

00:15:46,320 --> 00:15:49,920
schedulers

00:15:47,519 --> 00:15:52,639
it manages this job to schedule it

00:15:49,920 --> 00:15:52,639
schedule it

00:15:53,040 --> 00:15:57,279
and to schedule these jobs uh the law

00:15:55,360 --> 00:16:00,000
process needs some info

00:15:57,279 --> 00:16:00,399
pull up heading for like a schema info

00:16:00,000 --> 00:16:04,079
also

00:16:00,399 --> 00:16:06,959
some meta info like owner so

00:16:04,079 --> 00:16:08,720
so here student store comes it stores

00:16:06,959 --> 00:16:13,199
such infra

00:16:08,720 --> 00:16:15,120
um once the uh on cloud

00:16:13,199 --> 00:16:16,480
we have various destinations you know

00:16:15,120 --> 00:16:19,680
the data cleaning be

00:16:16,480 --> 00:16:22,079
called gcs situated now we are we are

00:16:19,680 --> 00:16:23,600
using screen processors to process the

00:16:22,079 --> 00:16:27,839
data

00:16:23,600 --> 00:16:29,680
but this is just on cloud we also have

00:16:27,839 --> 00:16:33,360
on on-prem components

00:16:29,680 --> 00:16:36,160
so we have a wrapping service to to play

00:16:33,360 --> 00:16:37,040
a lot of destinations to to replicate

00:16:36,160 --> 00:16:39,199
between cloud

00:16:37,040 --> 00:16:40,959
on on-prem and sometimes you know

00:16:39,199 --> 00:16:42,720
sometimes users might want to risk

00:16:40,959 --> 00:16:44,959
their data in bigquery they might want

00:16:42,720 --> 00:16:47,839
to load their data to

00:16:44,959 --> 00:16:48,560
go class sorry to bigquery so this is

00:16:47,839 --> 00:16:51,519
also

00:16:48,560 --> 00:16:52,639
a function uh the rule we hope the

00:16:51,519 --> 00:16:56,240
wrappings of it took

00:16:52,639 --> 00:16:57,120
to play okay so now i had introduced the

00:16:56,240 --> 00:16:59,199
architecture

00:16:57,120 --> 00:17:01,279
from now on i will hand over to my

00:16:59,199 --> 00:17:03,600
colleague barbie he will lead us to

00:17:01,279 --> 00:17:04,880
deep dive into each component and share

00:17:03,600 --> 00:17:07,360
how the big

00:17:04,880 --> 00:17:08,400
picture like when we come by on-prem and

00:17:07,360 --> 00:17:10,720
on cloud

00:17:08,400 --> 00:17:10,720
thanks

00:17:15,360 --> 00:17:20,720
so i mean do you want to take it

00:17:24,799 --> 00:17:27,919
can you see my screen

00:17:30,480 --> 00:17:34,160
hey ginger can you see the screen

00:17:35,600 --> 00:17:41,840
i i can't see your screen now yeah

00:17:39,039 --> 00:17:42,640
okay great uh hi everyone uh thank you

00:17:41,840 --> 00:17:45,120
janja

00:17:42,640 --> 00:17:46,400
for the introduction of the log pipeline

00:17:45,120 --> 00:17:47,600
and high level components of the

00:17:46,400 --> 00:17:50,080
architecture

00:17:47,600 --> 00:17:52,080
i have a bunch of slides to cover uh

00:17:50,080 --> 00:17:55,200
component details of our architecture

00:17:52,080 --> 00:17:57,679
and tell how we do replication uh

00:17:55,200 --> 00:17:58,799
between the sinks in a batch way as well

00:17:57,679 --> 00:18:01,760
as streaming way

00:17:58,799 --> 00:18:02,880
and conclude the talk so let's get into

00:18:01,760 --> 00:18:06,000
the details of the

00:18:02,880 --> 00:18:08,240
how we handle the processors one of the

00:18:06,000 --> 00:18:10,880
components in the

00:18:08,240 --> 00:18:11,840
our log pipeline is the log processors

00:18:10,880 --> 00:18:14,240
where

00:18:11,840 --> 00:18:16,080
we deploy a processor for flow

00:18:14,240 --> 00:18:18,400
essentially per log category

00:18:16,080 --> 00:18:20,000
for sync so let's say if i have a user

00:18:18,400 --> 00:18:23,440
data add impressions

00:18:20,000 --> 00:18:26,080
wants to be delivered to bigquery and

00:18:23,440 --> 00:18:26,720
gcs will maintain two separate log

00:18:26,080 --> 00:18:28,480
processor

00:18:26,720 --> 00:18:29,760
for that particular lock category which

00:18:28,480 --> 00:18:32,320
is add impression

00:18:29,760 --> 00:18:33,039
so that means there is more than one

00:18:32,320 --> 00:18:35,840
processor

00:18:33,039 --> 00:18:37,760
to be deployed for log category and

00:18:35,840 --> 00:18:40,000
there are many such log categories

00:18:37,760 --> 00:18:42,240
uh the log processor duty is to

00:18:40,000 --> 00:18:45,679
essentially deliver the data from

00:18:42,240 --> 00:18:47,360
pub sub to respective things so we have

00:18:45,679 --> 00:18:50,160
two kinds of log processors

00:18:47,360 --> 00:18:50,720
first one is a streaming cost processor

00:18:50,160 --> 00:18:52,640
where

00:18:50,720 --> 00:18:54,000
you read data from pub sub and write it

00:18:52,640 --> 00:18:56,320
to the bigquery

00:18:54,000 --> 00:18:57,039
and the users who want data to be

00:18:56,320 --> 00:18:59,679
available in

00:18:57,039 --> 00:19:00,400
uh in within few seconds is what opt for

00:18:59,679 --> 00:19:02,880
this

00:19:00,400 --> 00:19:04,799
uh as uh ginger man mentioned in the

00:19:02,880 --> 00:19:07,200
initial set of slides we want

00:19:04,799 --> 00:19:08,880
even though we ask users uh even though

00:19:07,200 --> 00:19:11,520
we expect users to provide

00:19:08,880 --> 00:19:12,559
a correct schema and valid records it's

00:19:11,520 --> 00:19:15,679
possible that

00:19:12,559 --> 00:19:17,280
things can be not as expected

00:19:15,679 --> 00:19:19,520
when during the deployment so it's

00:19:17,280 --> 00:19:21,840
possible that you could receive a bad

00:19:19,520 --> 00:19:25,280
record and you don't want to mess up

00:19:21,840 --> 00:19:27,039
your bigquery schema so when we find out

00:19:25,280 --> 00:19:29,280
that

00:19:27,039 --> 00:19:30,160
while transforming the data from pubsub

00:19:29,280 --> 00:19:32,720
to

00:19:30,160 --> 00:19:34,720
bigquery if we find any bad records we

00:19:32,720 --> 00:19:37,039
write them and store them to a

00:19:34,720 --> 00:19:39,600
dead letter table so that if the number

00:19:37,039 --> 00:19:42,080
of such bad records beyond a threshold

00:19:39,600 --> 00:19:44,480
uh we can notify the customer teams and

00:19:42,080 --> 00:19:48,080
uh they can look at the data and then

00:19:44,480 --> 00:19:50,240
um re-ingest it back by modifying them

00:19:48,080 --> 00:19:52,080
and another thing that we the duty of

00:19:50,240 --> 00:19:53,280
the processor is to do end to end check

00:19:52,080 --> 00:19:55,520
some validation

00:19:53,280 --> 00:19:57,200
uh the checksum itself is computed and

00:19:55,520 --> 00:20:00,400
added has a special header

00:19:57,200 --> 00:20:02,240
uh at the at the right hand uh

00:20:00,400 --> 00:20:04,799
at the very first end of receiving the

00:20:02,240 --> 00:20:07,200
uh uh the event from the client

00:20:04,799 --> 00:20:09,600
uh which is where in the client library

00:20:07,200 --> 00:20:12,720
we added checksum as a special header

00:20:09,600 --> 00:20:14,080
just before writing to the sync for

00:20:12,720 --> 00:20:16,720
example either bigquery or

00:20:14,080 --> 00:20:17,760
cloud storage we validate those sections

00:20:16,720 --> 00:20:19,840
and if there is any

00:20:17,760 --> 00:20:21,120
encoding done you decode and finally

00:20:19,840 --> 00:20:24,400
publish it to the

00:20:21,120 --> 00:20:26,960
uh your bigquery table

00:20:24,400 --> 00:20:27,840
and that uh with respect to batch

00:20:26,960 --> 00:20:29,760
processor

00:20:27,840 --> 00:20:30,880
uh we support couple of formats for

00:20:29,760 --> 00:20:32,400
users to choose

00:20:30,880 --> 00:20:34,559
whether it's a row based format or

00:20:32,400 --> 00:20:36,159
column format drift or parquet

00:20:34,559 --> 00:20:37,919
and that is something that user can

00:20:36,159 --> 00:20:39,360
configure at the time of provisioning a

00:20:37,919 --> 00:20:40,960
log category

00:20:39,360 --> 00:20:42,559
they can say i want this data to be

00:20:40,960 --> 00:20:44,880
available in a batch fashion

00:20:42,559 --> 00:20:46,159
with this kind of a format and this

00:20:44,880 --> 00:20:47,360
processor also does take some

00:20:46,159 --> 00:20:49,760
validations

00:20:47,360 --> 00:20:50,960
with respect to batching we also need to

00:20:49,760 --> 00:20:53,919
worry about how we

00:20:50,960 --> 00:20:55,120
maintain the metadata for those for

00:20:53,919 --> 00:20:58,320
those

00:20:55,120 --> 00:21:00,159
batch data for example we aggregate the

00:20:58,320 --> 00:21:02,320
batch data at hourly boundary and

00:21:00,159 --> 00:21:04,799
maintain metadata for every hour

00:21:02,320 --> 00:21:06,720
for a given log category we maintain

00:21:04,799 --> 00:21:08,640
data is available at each log each

00:21:06,720 --> 00:21:10,720
each and every hour so it's possible

00:21:08,640 --> 00:21:12,080
that for a particular hour there is no

00:21:10,720 --> 00:21:14,159
data coming in

00:21:12,080 --> 00:21:16,559
from pub sub at that time we still need

00:21:14,159 --> 00:21:18,880
to create a metadata uh

00:21:16,559 --> 00:21:21,039
equivalence for that hour so to do that

00:21:18,880 --> 00:21:23,280
we had dummy events into the

00:21:21,039 --> 00:21:24,400
uh into the life cycle into the

00:21:23,280 --> 00:21:26,720
processor so that

00:21:24,400 --> 00:21:27,520
you had you still get at least one event

00:21:26,720 --> 00:21:30,799
per hour

00:21:27,520 --> 00:21:32,480
to handle the metadata operations and

00:21:30,799 --> 00:21:35,120
i'll discuss more about replication

00:21:32,480 --> 00:21:37,679
service etcetera and next set of slides

00:21:35,120 --> 00:21:39,120
the next component i want to describe is

00:21:37,679 --> 00:21:40,880
how do we manage the

00:21:39,120 --> 00:21:43,440
log process that i explained in the

00:21:40,880 --> 00:21:45,120
previous slide so you have

00:21:43,440 --> 00:21:46,720
more than one log processor per log

00:21:45,120 --> 00:21:49,200
category and also you have

00:21:46,720 --> 00:21:50,159
many such log categories that users can

00:21:49,200 --> 00:21:53,200
uh

00:21:50,159 --> 00:21:54,720
deploy so what does processor scheduler

00:21:53,200 --> 00:21:56,000
does is that it does essentially does

00:21:54,720 --> 00:21:59,280
the lifecycle management

00:21:56,000 --> 00:22:02,720
of uh these uh log processor jobs

00:21:59,280 --> 00:22:05,360
uh ideally uh i mean set of goals to

00:22:02,720 --> 00:22:07,679
goals for the scheduler is to provide a

00:22:05,360 --> 00:22:09,679
simple knobs for users to configure

00:22:07,679 --> 00:22:12,000
uh so that they can choose whether they

00:22:09,679 --> 00:22:14,720
want data in stream way or batch way

00:22:12,000 --> 00:22:16,159
and what destinations that they want

00:22:14,720 --> 00:22:18,320
this data to be delivered

00:22:16,159 --> 00:22:19,679
and we want this scheduler to be

00:22:18,320 --> 00:22:21,600
extendable uh

00:22:19,679 --> 00:22:23,440
in a way that right now you see one or

00:22:21,600 --> 00:22:26,080
two processors that we support

00:22:23,440 --> 00:22:27,679
but it will in future we plan to add

00:22:26,080 --> 00:22:30,159
incision to druid and other

00:22:27,679 --> 00:22:32,080
other other things at that time we don't

00:22:30,159 --> 00:22:33,679
want to rewrite this layer so

00:22:32,080 --> 00:22:36,159
it's good to have a job abstraction

00:22:33,679 --> 00:22:37,919
layer where we can add more set of jobs

00:22:36,159 --> 00:22:40,960
and scheduler is unaware of

00:22:37,919 --> 00:22:42,720
what kind of job it is running and it it

00:22:40,960 --> 00:22:44,640
essentially

00:22:42,720 --> 00:22:47,840
maintains what jobs are running and if

00:22:44,640 --> 00:22:50,000
any changes are detected

00:22:47,840 --> 00:22:51,200
from the user configuration the event

00:22:50,000 --> 00:22:53,280
controller will detect

00:22:51,200 --> 00:22:54,799
uh any changes that happen to

00:22:53,280 --> 00:22:56,400
configurations and

00:22:54,799 --> 00:22:58,559
if it is a new log category it will

00:22:56,400 --> 00:23:00,320
deploy a new job if it is an existing

00:22:58,559 --> 00:23:00,880
clock category it will pause the current

00:23:00,320 --> 00:23:03,679
one

00:23:00,880 --> 00:23:04,880
stop it uh update the configs and

00:23:03,679 --> 00:23:08,240
redeploy the

00:23:04,880 --> 00:23:10,559
redeploy the new job so

00:23:08,240 --> 00:23:11,679
that's at a high level uh job scheduler

00:23:10,559 --> 00:23:14,480
manages uh

00:23:11,679 --> 00:23:16,080
uh the schedule scheduling operation

00:23:14,480 --> 00:23:18,400
scheduling aspects of the

00:23:16,080 --> 00:23:19,600
log processor and this whole experience

00:23:18,400 --> 00:23:21,919
we want it to be in

00:23:19,600 --> 00:23:23,600
a managed execution format that means it

00:23:21,919 --> 00:23:25,360
should be managed player user doesn't

00:23:23,600 --> 00:23:27,520
need to worry about these jobs

00:23:25,360 --> 00:23:29,039
they all they care about is that i'm i'm

00:23:27,520 --> 00:23:30,799
sending data from my

00:23:29,039 --> 00:23:34,000
twitter services i want data to be

00:23:30,799 --> 00:23:37,520
available in these analytical things or

00:23:34,000 --> 00:23:40,159
bad things and this entire thing should

00:23:37,520 --> 00:23:42,400
be hidden if a particular job is not

00:23:40,159 --> 00:23:45,039
paused or not running we should be able

00:23:42,400 --> 00:23:47,679
to detect uh what's going wrong and then

00:23:45,039 --> 00:23:48,240
act accordingly so we have a metrics in

00:23:47,679 --> 00:23:50,000
this pro

00:23:48,240 --> 00:23:52,240
in the scheduler to detect those events

00:23:50,000 --> 00:23:54,799
and handle them

00:23:52,240 --> 00:23:56,400
and the next component is client library

00:23:54,799 --> 00:23:59,840
uh

00:23:56,400 --> 00:24:03,919
why do we need a client library we have

00:23:59,840 --> 00:24:05,120
a separate set of implementation for uh

00:24:03,919 --> 00:24:06,799
our data center our

00:24:05,120 --> 00:24:08,400
creator data center log pipeline and a

00:24:06,799 --> 00:24:09,360
new set of implementation in cloud

00:24:08,400 --> 00:24:11,279
entertainment

00:24:09,360 --> 00:24:12,400
for the users they shouldn't be worrying

00:24:11,279 --> 00:24:14,559
about how

00:24:12,400 --> 00:24:16,159
uh the data pipeline how logs are

00:24:14,559 --> 00:24:18,559
delivered whether they are describing

00:24:16,159 --> 00:24:20,159
from on-prem or cloud

00:24:18,559 --> 00:24:21,679
the client library provides that

00:24:20,159 --> 00:24:22,799
abstraction to the user so that they

00:24:21,679 --> 00:24:25,200
just need to

00:24:22,799 --> 00:24:27,279
interact with a log pipeline using

00:24:25,200 --> 00:24:29,840
simple apis and they don't need to worry

00:24:27,279 --> 00:24:32,240
about how routing is done and where the

00:24:29,840 --> 00:24:32,880
how the events are traveled and apart

00:24:32,240 --> 00:24:35,039
from that

00:24:32,880 --> 00:24:37,200
client library also provides a good set

00:24:35,039 --> 00:24:38,159
of metrics for the user to so that they

00:24:37,200 --> 00:24:40,320
can

00:24:38,159 --> 00:24:42,880
visualize how many events that they are

00:24:40,320 --> 00:24:44,159
sending across their microservices and

00:24:42,880 --> 00:24:46,000
how many events finally they are

00:24:44,159 --> 00:24:49,039
receiving what is the drop rate and what

00:24:46,000 --> 00:24:51,039
not and uh we do want to

00:24:49,039 --> 00:24:53,679
from the previous learnings we want to

00:24:51,039 --> 00:24:54,720
avoid bad data to be ingested into the

00:24:53,679 --> 00:24:57,200
log pipeline

00:24:54,720 --> 00:24:58,720
uh to achieve that we added a static

00:24:57,200 --> 00:25:00,480
schema validation check so that if

00:24:58,720 --> 00:25:03,600
somebody makes a mistake of

00:25:00,480 --> 00:25:04,799
choosing a wrong schema for a for a

00:25:03,600 --> 00:25:07,120
different clock category

00:25:04,799 --> 00:25:08,640
the compile time assets will take care

00:25:07,120 --> 00:25:09,760
of those the library provides those

00:25:08,640 --> 00:25:11,840
enhancements

00:25:09,760 --> 00:25:14,480
and also this is the layer where we add

00:25:11,840 --> 00:25:17,600
all rich metadata and pluggable headers

00:25:14,480 --> 00:25:19,679
where we uh example you can

00:25:17,600 --> 00:25:21,840
compute checksum type of encryption that

00:25:19,679 --> 00:25:25,279
we are doing type of encoding

00:25:21,840 --> 00:25:27,200
um and any other internal metadata that

00:25:25,279 --> 00:25:28,720
we want to associate we want to have it

00:25:27,200 --> 00:25:30,880
associated with a message

00:25:28,720 --> 00:25:32,960
for example what is the time at which

00:25:30,880 --> 00:25:35,279
the event was actually received to lock

00:25:32,960 --> 00:25:36,799
lock lock pipeline so that we can see

00:25:35,279 --> 00:25:38,559
end to end latency so those kind of

00:25:36,799 --> 00:25:40,960
metadata can be added

00:25:38,559 --> 00:25:42,320
and that metadata itself it's forwarded

00:25:40,960 --> 00:25:43,919
to

00:25:42,320 --> 00:25:46,480
forwarded along with the message

00:25:43,919 --> 00:25:48,960
throughout the log pipeline

00:25:46,480 --> 00:25:51,120
and apart from that uh the another

00:25:48,960 --> 00:25:53,520
component is the state store

00:25:51,120 --> 00:25:55,360
which deals with schema management right

00:25:53,520 --> 00:25:56,000
now we have a rudimentary implementation

00:25:55,360 --> 00:25:59,760
of managing

00:25:56,000 --> 00:26:03,679
schemas where we have a ci job which

00:25:59,760 --> 00:26:05,360
essentially runs regularly to look at

00:26:03,679 --> 00:26:08,000
set of changes that happen in the source

00:26:05,360 --> 00:26:11,279
repo and creates a jar from the schema

00:26:08,000 --> 00:26:12,080
and uploads it to a gcs bucket and where

00:26:11,279 --> 00:26:15,360
the

00:26:12,080 --> 00:26:15,919
data log processors periodically load

00:26:15,360 --> 00:26:18,240
that

00:26:15,919 --> 00:26:21,760
schema every now and then to update

00:26:18,240 --> 00:26:21,760
itself with the new set of schemas

00:26:22,640 --> 00:26:25,840
so then next let's go to the log

00:26:24,559 --> 00:26:28,080
replication so

00:26:25,840 --> 00:26:28,960
as i said uh we have a separate log

00:26:28,080 --> 00:26:31,919
pipeline

00:26:28,960 --> 00:26:32,240
for every data center and uh but for the

00:26:31,919 --> 00:26:34,240
end

00:26:32,240 --> 00:26:35,440
for the end consumer they want the data

00:26:34,240 --> 00:26:37,679
to be aggregated

00:26:35,440 --> 00:26:38,720
for a particular hour boundary across

00:26:37,679 --> 00:26:41,120
all data centers

00:26:38,720 --> 00:26:42,000
take an example of ad impression they

00:26:41,120 --> 00:26:45,760
let's say user

00:26:42,000 --> 00:26:47,760
uh multiple uh the users are using uh

00:26:45,760 --> 00:26:50,240
sending these events from all data

00:26:47,760 --> 00:26:52,400
centers but from the backend jobs to run

00:26:50,240 --> 00:26:54,720
they want the data to be available

00:26:52,400 --> 00:26:55,840
aggregated from all data centers in at

00:26:54,720 --> 00:26:57,919
hourly boundary

00:26:55,840 --> 00:26:59,600
so the purpose of log replication is to

00:26:57,919 --> 00:27:00,320
essentially merge the data which is

00:26:59,600 --> 00:27:02,880
being

00:27:00,320 --> 00:27:03,919
generated at each log pipeline from each

00:27:02,880 --> 00:27:06,400
data center

00:27:03,919 --> 00:27:08,159
and merge it to hourly boundary so this

00:27:06,400 --> 00:27:08,559
is this log replication in this slide

00:27:08,159 --> 00:27:10,080
that

00:27:08,559 --> 00:27:11,760
i'm explaining is a batch log

00:27:10,080 --> 00:27:15,120
replication uh where

00:27:11,760 --> 00:27:16,880
uh we uh as and when the data is

00:27:15,120 --> 00:27:18,399
generated by the log pipeline at each

00:27:16,880 --> 00:27:22,240
data center we

00:27:18,399 --> 00:27:24,080
merge them and generate to hdfs or gcs

00:27:22,240 --> 00:27:25,840
then i have another slide to talk about

00:27:24,080 --> 00:27:30,000
how we do

00:27:25,840 --> 00:27:30,000
the log replication for streaming users

00:27:30,159 --> 00:27:33,760
that's at a high level about log

00:27:31,520 --> 00:27:36,000
replication and let me just give a

00:27:33,760 --> 00:27:39,200
little bit details about how we deploy

00:27:36,000 --> 00:27:41,760
our log pipeline uh so to

00:27:39,200 --> 00:27:43,200
enable better security and better

00:27:41,760 --> 00:27:46,799
chargeback mechanism

00:27:43,200 --> 00:27:47,679
uh we have all the gcp deployments are

00:27:46,799 --> 00:27:50,799
deferred

00:27:47,679 --> 00:27:51,600
are mult are divided into multiple gcp

00:27:50,799 --> 00:27:54,559
projects

00:27:51,600 --> 00:27:56,240
uh inside twitter so what we did is to

00:27:54,559 --> 00:27:58,320
deploy this log pipeline

00:27:56,240 --> 00:27:59,360
for each project independently and we

00:27:58,320 --> 00:28:02,559
manage all those

00:27:59,360 --> 00:28:03,600
deployments but they're contained within

00:28:02,559 --> 00:28:06,960
that project

00:28:03,600 --> 00:28:09,279
so this uh this uh

00:28:06,960 --> 00:28:10,880
uh deployment happens uh like if when

00:28:09,279 --> 00:28:11,679
you configure a new log category which

00:28:10,880 --> 00:28:13,760
particular

00:28:11,679 --> 00:28:15,919
log pipeline has to take care of your

00:28:13,760 --> 00:28:17,919
law category is something provision

00:28:15,919 --> 00:28:19,679
handled at the provisioning time so when

00:28:17,919 --> 00:28:21,679
you provision log category

00:28:19,679 --> 00:28:23,279
we look at the log category and based on

00:28:21,679 --> 00:28:25,679
the service account owner

00:28:23,279 --> 00:28:26,960
you can map the log category to a

00:28:25,679 --> 00:28:29,520
corresponding

00:28:26,960 --> 00:28:30,640
gcp project and once that is done we

00:28:29,520 --> 00:28:34,000
create associated

00:28:30,640 --> 00:28:36,320
gcp resources i'm sorry let me take some

00:28:34,000 --> 00:28:36,320
water

00:28:38,799 --> 00:28:44,000
and yeah we create bunch of gcp

00:28:42,080 --> 00:28:47,039
resources after at the provisioning time

00:28:44,000 --> 00:28:51,039
for example creating pub sub topics and

00:28:47,039 --> 00:28:53,120
uh gcs buckets uh bq data sets and

00:28:51,039 --> 00:28:54,640
creating the schema for those tables

00:28:53,120 --> 00:28:56,480
they're all automatically done at the

00:28:54,640 --> 00:28:58,320
time of provisioning time we use

00:28:56,480 --> 00:29:01,279
terraform uh for this purpose

00:28:58,320 --> 00:29:03,520
uh through our internal uh twitter uh

00:29:01,279 --> 00:29:06,000
service called demigod service

00:29:03,520 --> 00:29:06,559
and also at this is the point in time

00:29:06,000 --> 00:29:08,240
where we

00:29:06,559 --> 00:29:10,159
configure the event routing as well like

00:29:08,240 --> 00:29:12,399
how the data to be delivered from

00:29:10,159 --> 00:29:14,640
a particular application to a particular

00:29:12,399 --> 00:29:17,360
uh sync i'll explain more about routing

00:29:14,640 --> 00:29:19,440
inside of a next set of slides but

00:29:17,360 --> 00:29:21,360
the routing capability is essentially

00:29:19,440 --> 00:29:23,200
taken care of the provisioning time

00:29:21,360 --> 00:29:24,480
and also the access control aspects of

00:29:23,200 --> 00:29:26,399
the log categories

00:29:24,480 --> 00:29:28,159
also done during the provisioning time

00:29:26,399 --> 00:29:30,399
where in general all these log

00:29:28,159 --> 00:29:32,640
categories have right access

00:29:30,399 --> 00:29:33,600
will have a right access only to the log

00:29:32,640 --> 00:29:35,600
processors

00:29:33,600 --> 00:29:38,240
and whereas read access is to be given

00:29:35,600 --> 00:29:42,080
to a service account owners

00:29:38,240 --> 00:29:44,240
the user users of the lock category

00:29:42,080 --> 00:29:45,760
so i that's at a high level about

00:29:44,240 --> 00:29:48,720
individual components of

00:29:45,760 --> 00:29:49,760
log pipeline um i'll just have one more

00:29:48,720 --> 00:29:51,840
slide about

00:29:49,760 --> 00:29:54,000
how we stream data between two data

00:29:51,840 --> 00:29:56,320
centers uh especially

00:29:54,000 --> 00:29:58,720
uh between twitter environment and cloud

00:29:56,320 --> 00:30:02,480
lock pipeline which is in gcp

00:29:58,720 --> 00:30:06,799
so to to solve this problem we need to

00:30:02,480 --> 00:30:06,799
handle uh the two different

00:30:07,279 --> 00:30:10,480
we need to solve two different problems

00:30:08,799 --> 00:30:12,080
first one is how do we do how do we

00:30:10,480 --> 00:30:13,279
handle connectivity between twitter data

00:30:12,080 --> 00:30:14,880
center and gcp

00:30:13,279 --> 00:30:17,120
and the second one is how do we forward

00:30:14,880 --> 00:30:20,000
the events the first one is we have a

00:30:17,120 --> 00:30:21,919
dedicated network bandwidth

00:30:20,000 --> 00:30:23,440
provision between twitter data center

00:30:21,919 --> 00:30:25,279
and gcp uh

00:30:23,440 --> 00:30:26,640
to handle the data in a streaming way

00:30:25,279 --> 00:30:28,640
and batch way

00:30:26,640 --> 00:30:30,640
so we provision a separate network

00:30:28,640 --> 00:30:34,320
bandwidth for the log categories

00:30:30,640 --> 00:30:37,760
and we deploy a flow migration layer

00:30:34,320 --> 00:30:38,640
a with a with a dedicated connectivity

00:30:37,760 --> 00:30:40,640
to gcp

00:30:38,640 --> 00:30:42,080
so if you have an application if we have

00:30:40,640 --> 00:30:44,720
an application that

00:30:42,080 --> 00:30:46,000
is scribing data or publishing data from

00:30:44,720 --> 00:30:48,000
twitter applications

00:30:46,000 --> 00:30:49,520
sitting in twitter data center but the

00:30:48,000 --> 00:30:53,200
data to be available in a

00:30:49,520 --> 00:30:55,360
streaming way to bigquery uh users

00:30:53,200 --> 00:30:56,320
scribe the data as usual they don't

00:30:55,360 --> 00:30:58,480
really know that

00:30:56,320 --> 00:30:59,679
how the routing is happening they go

00:30:58,480 --> 00:31:01,039
through the client library client

00:30:59,679 --> 00:31:02,480
library forwards it to the flow

00:31:01,039 --> 00:31:04,080
aggregation layer

00:31:02,480 --> 00:31:07,200
the flume aggregation layer knows that

00:31:04,080 --> 00:31:10,480
this particular log category has to be

00:31:07,200 --> 00:31:12,240
um written to pub sub uh so

00:31:10,480 --> 00:31:14,320
it will does the routing aspect of

00:31:12,240 --> 00:31:16,480
forwarding those events to pub sub

00:31:14,320 --> 00:31:18,240
while preserving all the headers that

00:31:16,480 --> 00:31:20,799
are added by the client library

00:31:18,240 --> 00:31:22,960
or at the flow aggregation layer so and

00:31:20,799 --> 00:31:24,640
once it is in gcp pub server cloud lock

00:31:22,960 --> 00:31:25,600
pipeline will take care of flashing it

00:31:24,640 --> 00:31:27,360
to

00:31:25,600 --> 00:31:29,760
publishing that data to bigquery or

00:31:27,360 --> 00:31:32,559
cloud storage

00:31:29,760 --> 00:31:32,960
so i have final slide that talks about

00:31:32,559 --> 00:31:35,760
uh

00:31:32,960 --> 00:31:37,039
how these two log pipelines together fit

00:31:35,760 --> 00:31:40,559
inside twitter

00:31:37,039 --> 00:31:42,159
and uh how the data can be routed

00:31:40,559 --> 00:31:43,919
through different workflows there are

00:31:42,159 --> 00:31:46,080
many possibilities of data

00:31:43,919 --> 00:31:47,440
routing but uh before going to the

00:31:46,080 --> 00:31:49,279
routing i want to

00:31:47,440 --> 00:31:51,360
just segregate two log pipelines that we

00:31:49,279 --> 00:31:52,240
have in place all yellow boxes are

00:31:51,360 --> 00:31:53,919
essentially

00:31:52,240 --> 00:31:55,440
uh twitter on-prem data center

00:31:53,919 --> 00:31:58,559
deployments uh that's

00:31:55,440 --> 00:32:01,440
uh that serves both uh

00:31:58,559 --> 00:32:01,760
batch and streaming and the gray box uh

00:32:01,440 --> 00:32:03,919
are

00:32:01,760 --> 00:32:04,799
from gcp environment which are deployed

00:32:03,919 --> 00:32:08,720
which serves both

00:32:04,799 --> 00:32:12,000
uh both streaming and batching workloads

00:32:08,720 --> 00:32:12,799
so uh the possible routing let me

00:32:12,000 --> 00:32:15,120
explain

00:32:12,799 --> 00:32:16,399
couple of cases if user wants to do

00:32:15,120 --> 00:32:20,559
streaming workload

00:32:16,399 --> 00:32:22,480
and the streaming workload can come from

00:32:20,559 --> 00:32:24,000
an application deployed in the gcp

00:32:22,480 --> 00:32:26,720
environment then

00:32:24,000 --> 00:32:28,720
the events are traveling from client

00:32:26,720 --> 00:32:31,760
library to gcp pub sub

00:32:28,720 --> 00:32:32,799
through bigquery uh or if the if the

00:32:31,760 --> 00:32:35,760
application is right

00:32:32,799 --> 00:32:37,519
writing data from a twitter data center

00:32:35,760 --> 00:32:39,200
it goes through client library and flume

00:32:37,519 --> 00:32:40,000
aggregation layer forwards the data to

00:32:39,200 --> 00:32:42,240
pub sub

00:32:40,000 --> 00:32:44,080
and then it goes to the bitcoin if it is

00:32:42,240 --> 00:32:44,880
a batch workflow then again you have two

00:32:44,080 --> 00:32:47,120
choices

00:32:44,880 --> 00:32:47,919
uh if if the application is deployed in

00:32:47,120 --> 00:32:50,640
the cloud

00:32:47,919 --> 00:32:51,279
it goes through client library to pub

00:32:50,640 --> 00:32:54,880
sub

00:32:51,279 --> 00:32:57,919
to gcs uh if the data itself is

00:32:54,880 --> 00:32:59,360
deployed in the on-prem data center then

00:32:57,919 --> 00:33:01,279
the data goes through

00:32:59,360 --> 00:33:03,039
on-prem log pipeline which is a client

00:33:01,279 --> 00:33:05,519
library to

00:33:03,039 --> 00:33:07,679
flow aggregation layer to hdfs and

00:33:05,519 --> 00:33:09,279
between hdfs and gcs

00:33:07,679 --> 00:33:10,960
we have a log replication service to

00:33:09,279 --> 00:33:12,799
copy data continuously

00:33:10,960 --> 00:33:14,640
that's at a high level about possible

00:33:12,799 --> 00:33:18,320
routings and as i mentioned

00:33:14,640 --> 00:33:19,760
all the routing aspects are taken care

00:33:18,320 --> 00:33:21,679
at the time of provisioning a log

00:33:19,760 --> 00:33:24,000
category where user specifies

00:33:21,679 --> 00:33:25,279
this is my log data i am describing from

00:33:24,000 --> 00:33:28,000
these data centers

00:33:25,279 --> 00:33:29,440
i want data to be available in observed

00:33:28,000 --> 00:33:33,679
sorry in

00:33:29,440 --> 00:33:36,960
the gcs hdfs bigquery or two way

00:33:33,679 --> 00:33:38,000
to conclude uh we embrace uh hybrid

00:33:36,960 --> 00:33:40,559
cloud environment

00:33:38,000 --> 00:33:41,120
and provide unified experience to

00:33:40,559 --> 00:33:44,320
publish

00:33:41,120 --> 00:33:45,840
log categories doesn't matter how the

00:33:44,320 --> 00:33:46,559
applications are deployed within the

00:33:45,840 --> 00:33:48,559
twitter

00:33:46,559 --> 00:33:50,240
whether they are deployed at on-prem

00:33:48,559 --> 00:33:52,320
data center or cloud

00:33:50,240 --> 00:33:54,159
they'll see an unified experience with

00:33:52,320 --> 00:33:56,559
respect to using the log pipeline

00:33:54,159 --> 00:33:57,679
and with respect to log pipeline itself

00:33:56,559 --> 00:33:59,840
is a global scale

00:33:57,679 --> 00:34:00,720
log delivery mechanism which does bunch

00:33:59,840 --> 00:34:03,039
of things

00:34:00,720 --> 00:34:04,720
first one is to aggregate data between

00:34:03,039 --> 00:34:07,679
the data centers

00:34:04,720 --> 00:34:08,879
and provide modes of multiple modes of

00:34:07,679 --> 00:34:11,599
delivery which is streaming

00:34:08,879 --> 00:34:13,440
and batching and also support various

00:34:11,599 --> 00:34:16,159
sync options for example

00:34:13,440 --> 00:34:17,280
bigquery or druid or gcs so the user can

00:34:16,159 --> 00:34:20,800
configure them

00:34:17,280 --> 00:34:23,200
all these properties routing and

00:34:20,800 --> 00:34:25,280
type of delivery and type of things are

00:34:23,200 --> 00:34:28,320
configured at the

00:34:25,280 --> 00:34:32,480
provisioning time with that um

00:34:28,320 --> 00:34:32,480
we are happy to take questions on this

00:34:32,839 --> 00:34:35,839
stuff

00:34:51,839 --> 00:34:54,879
i guess people could type their

00:34:53,599 --> 00:35:03,839
questions in the

00:34:54,879 --> 00:35:03,839
channel with jackpots yeah

00:35:18,720 --> 00:35:21,839
yeah i i saw one question any trouble

00:35:21,440 --> 00:35:25,280
with

00:35:21,839 --> 00:35:25,280
getting thrown yes

00:35:25,599 --> 00:35:31,440
um so so first we take

00:35:28,960 --> 00:35:32,720
architecture you know the flumes they

00:35:31,440 --> 00:35:35,839
are independent they don't

00:35:32,720 --> 00:35:38,640
interact with each other and it's a

00:35:35,839 --> 00:35:40,640
it's as expansion just receive data and

00:35:38,640 --> 00:35:43,680
you write to hdfs

00:35:40,640 --> 00:35:46,160
you know so we could scale high ground

00:35:43,680 --> 00:35:47,200
skill you know high ground equally but

00:35:46,160 --> 00:35:49,119
for the film itself

00:35:47,200 --> 00:35:50,560
we did see some problems we see some

00:35:49,119 --> 00:35:54,480
memory issue

00:35:50,560 --> 00:35:57,839
we see some memory uh and some bugs

00:35:54,480 --> 00:36:00,400
like the memory leak bugs so we

00:35:57,839 --> 00:36:01,920
many improvements for example we include

00:36:00,400 --> 00:36:05,839
microbation

00:36:01,920 --> 00:36:09,040
to hdfs inc i guess after that patch

00:36:05,839 --> 00:36:11,520
the permanence had increased uh

00:36:09,040 --> 00:36:12,880
10 times or something like that and we

00:36:11,520 --> 00:36:14,800
also increase uh

00:36:12,880 --> 00:36:16,160
introduce a new memory model called

00:36:14,800 --> 00:36:19,200
memory channel group

00:36:16,160 --> 00:36:19,920
so basically the memory inside the

00:36:19,200 --> 00:36:24,079
channel group

00:36:19,920 --> 00:36:26,400
they could share the the results

00:36:24,079 --> 00:36:28,400
but the basement groups is totally you

00:36:26,400 --> 00:36:31,760
know isolated

00:36:28,400 --> 00:36:34,320
uh from this we could you know greatly

00:36:31,760 --> 00:36:35,440
improve our utilization of memory

00:36:34,320 --> 00:36:38,560
because you know we have

00:36:35,440 --> 00:36:40,960
thousands of um uh uh

00:36:38,560 --> 00:36:40,960
thousands

00:36:43,760 --> 00:36:47,839
categories yeah and we also united some

00:36:47,040 --> 00:36:51,119
features like a

00:36:47,839 --> 00:36:54,400
limited the matches reporter one

00:36:51,119 --> 00:36:56,640
category could take uh

00:36:54,400 --> 00:36:57,680
so this could help us control the bus

00:36:56,640 --> 00:37:00,000
radius

00:36:57,680 --> 00:37:01,280
we also introduced a concept of caller

00:37:00,000 --> 00:37:03,520
aggregate group

00:37:01,280 --> 00:37:06,480
so basically group of the files of small

00:37:03,520 --> 00:37:08,880
files a smaller categories together

00:37:06,480 --> 00:37:10,000
so in this case at least skill we

00:37:08,880 --> 00:37:12,720
wouldn't

00:37:10,000 --> 00:37:13,520
you know cause too many problems to hdfs

00:37:12,720 --> 00:37:16,320
because of

00:37:13,520 --> 00:37:17,040
you know small files from number that we

00:37:16,320 --> 00:37:20,839
also

00:37:17,040 --> 00:37:23,839
done lots of tuning like the flash

00:37:20,839 --> 00:37:25,839
frequency yeah so

00:37:23,839 --> 00:37:27,359
yeah influence we also have a single

00:37:25,839 --> 00:37:29,200
thing to kafka

00:37:27,359 --> 00:37:30,960
and for that we also see some issues

00:37:29,200 --> 00:37:33,920
like a better

00:37:30,960 --> 00:37:35,839
slow partition kafka we also add our own

00:37:33,920 --> 00:37:38,160
partition

00:37:35,839 --> 00:37:40,800
things we have gone through and

00:37:38,160 --> 00:37:40,800
performed

00:37:41,680 --> 00:37:45,119
yeah we we didn't uh cover the flume

00:37:44,240 --> 00:37:48,560
aspects more

00:37:45,119 --> 00:37:50,720
in this talk but uh uh

00:37:48,560 --> 00:37:52,800
apart from uh what ginger mentioned we

00:37:50,720 --> 00:37:55,920
uh even to support the

00:37:52,800 --> 00:38:00,880
streaming to pops up we added our own uh

00:37:55,920 --> 00:38:00,880
pub sub sync for plume as well

00:38:02,839 --> 00:38:05,839
um

00:38:08,320 --> 00:38:14,000
yeah so uh yeah we

00:38:12,000 --> 00:38:15,599
you know um we also did some

00:38:14,000 --> 00:38:18,800
configuration to

00:38:15,599 --> 00:38:22,240
plan our full marketer well like we

00:38:18,800 --> 00:38:22,640
introduced a tear concept you know just

00:38:22,240 --> 00:38:26,079
to make

00:38:22,640 --> 00:38:27,760
the micro hairs look different here

00:38:26,079 --> 00:38:30,000
totally isolated

00:38:27,760 --> 00:38:31,599
but in the thin tier we registered to

00:38:30,000 --> 00:38:34,240
the same zookeeper

00:38:31,599 --> 00:38:34,800
to make it available to other tiers you

00:38:34,240 --> 00:38:38,400
know it's

00:38:34,800 --> 00:38:40,720
um yeah so to summarize you know we

00:38:38,400 --> 00:38:42,400
did a lot we introduced new features the

00:38:40,720 --> 00:38:44,880
attack fixes

00:38:42,400 --> 00:38:48,240
and uh worked together with the overall

00:38:44,880 --> 00:38:51,680
contribution to make it a more scalable

00:38:48,240 --> 00:38:54,880
to make it to be able to handle the

00:38:51,680 --> 00:38:56,960
the data as a trader skill like

00:38:54,880 --> 00:39:01,839
it could be up more than four trillion

00:38:56,960 --> 00:39:01,839
events per day

00:39:14,560 --> 00:39:29,839
so answer questions

00:39:34,880 --> 00:39:41,440
and there is more work going on also

00:39:38,480 --> 00:39:43,040
between the streaming aspect of how we

00:39:41,440 --> 00:39:46,240
stream data between

00:39:43,040 --> 00:39:49,119
kafka and uh pub sub

00:39:46,240 --> 00:39:50,320
there we haven't talked about those

00:39:49,119 --> 00:39:52,720
things but uh

00:39:50,320 --> 00:39:54,560
as janja mentioned that involves a bunch

00:39:52,720 --> 00:39:56,960
of changes in the flow

00:39:54,560 --> 00:39:58,880
about how to provide a lot less delivery

00:39:56,960 --> 00:40:01,359
between kafka to pub sub

00:39:58,880 --> 00:40:03,520
uh which is still in work so we couldn't

00:40:01,359 --> 00:40:05,119
talk about those

00:40:03,520 --> 00:40:07,520
yeah i guess that's a good call yeah

00:40:05,119 --> 00:40:10,000
that's also another important feature

00:40:07,520 --> 00:40:11,599
yeah yeah basically we make a you know

00:40:10,000 --> 00:40:14,400
from a support transaction

00:40:11,599 --> 00:40:15,920
between flaws and channels and things

00:40:14,400 --> 00:40:19,200
but it's uh there's

00:40:15,920 --> 00:40:20,960
you know no you know

00:40:19,200 --> 00:40:23,520
what we have done is you know it is

00:40:20,960 --> 00:40:26,000
possible the data is only in channel not

00:40:23,520 --> 00:40:28,720
in sync and we act back to users

00:40:26,000 --> 00:40:29,920
so we develop a new feature so make sure

00:40:28,720 --> 00:40:33,520
we only act back

00:40:29,920 --> 00:40:35,920
to you to the class only the data is

00:40:33,520 --> 00:40:36,960
is confirmed by the thing you know so

00:40:35,920 --> 00:40:40,240
more likely

00:40:36,960 --> 00:40:43,200
and to the better accounting you know

00:40:40,240 --> 00:40:45,440
something like that and yeah essentially

00:40:43,200 --> 00:40:47,920
providing a transactional guarantee

00:40:45,440 --> 00:40:50,839
while moving data from one streaming

00:40:47,920 --> 00:40:54,880
system to another streaming system

00:40:50,839 --> 00:40:57,359
yeah yeah if people are interested

00:40:54,880 --> 00:40:59,599
you could reach out to us we could tell

00:40:57,359 --> 00:40:59,599
more

00:41:02,000 --> 00:41:07,839
all right i guess the time is uh

00:41:13,839 --> 00:41:22,319
okay so if no question i guess uh

00:41:18,960 --> 00:41:22,880
then we can end the session uh thank you

00:41:22,319 --> 00:41:25,920
all for

00:41:22,880 --> 00:41:28,079
uh joining this session um please reach

00:41:25,920 --> 00:41:35,839
out to us with any questions

00:41:28,079 --> 00:41:35,839
yeah yeah thank you have a good one

00:43:10,839 --> 00:43:13,839
uh

00:43:53,119 --> 00:43:55,200

YouTube URL: https://www.youtube.com/watch?v=jOHWAuGoVp4


