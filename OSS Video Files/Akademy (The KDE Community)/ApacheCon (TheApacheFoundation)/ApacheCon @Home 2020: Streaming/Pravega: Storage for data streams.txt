Title: Pravega: Storage for data streams
Publication date: 2020-10-22
Playlist: ApacheCon @Home 2020: Streaming
Description: 
	Pravega: Storage for data streams
Flavio Junqueira

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

There is no shortage of use cases with elements that continuously generate data: end users posting updates and shopping online; sensors that periodically emit samples; drones that continuously produce aerial video streams; connected cars that generate a combination of videos, images, and telemetry; and server fleets that generate an abundance of telemetry data. One common aspect shared by several of these cases is that the sources of data are machines, and at scale, machines can generate data at extremely high volumes. Machine-generated data creates an important challenge for analytics systems to ingest, store and process such high-volumes of machine-generated data in an efficient and effective manner. Pravega is a software system developed from the ground up to enable applications to ingest and store high-volumes of continuously generated data. Pravega exposes the stream as a core storage primitive, which enables applications continuously generating data to ingest and store such data permanently. Applications that consume stream data from Pravega are able to access the data through the same API, independent of whether it is tailing the stream, reprocessing the stream, or processing historical data. Pravega has some unique features such as the ability of storing an unbounded amount of data per stream, while appending transactionally and scaling according to workload variations. It uses an underlying segment abstraction not only to implement such features, but advanced ones to support stream applications such as state synchronization and key-value tables. In this presentation, we overview Pravega, including its main features and architecture. We show how to use Pravega when building streaming data pipelines along with stream processors such as Apache Flink. We have implemented Pravega connectors for Flink that enable end-to-end exactly-once semantics for data pipelines using Pravega checkpoints and transactions. Pravega is an open-source project, licensed under the Apache License Version 2.0, and hosted on GitHub (https://github.com/pravega/pravega).

Flavio Junqueira is a Senior Distinguished Engineer at Dell. He holds a PhD in computer science from the University of California, San Diego, and he is interested in various aspects of distributed systems, including distributed algorithms, concurrency, and scalability. His recent work at Dell focuses on stream analytics, and specifically, on the development of a novel storage system for streams called Pravega. Before Dell, Flavio held an engineering position with Confluent and research positions with Yahoo! Research and Microsoft Research. Flavio has co-authored a number of scientific publications (over 4,000 citations according to Google Scholar) and an Oâ€™Reilly ZooKeeper book on Apache ZooKeeper. Flavio is an Apache Member and has contributed to projects hosted by the ASF, including Apache ZooKeeper (as PMC and committer), Apache BookKeeper (as PMC and committer), and Apache Kafka.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:27,680 --> 00:00:30,960
all right

00:00:28,960 --> 00:00:32,640
if you if you can hear me can anyone

00:00:30,960 --> 00:00:35,520
confirm that you can hear me just type

00:00:32,640 --> 00:00:35,520
on the chat please

00:00:36,160 --> 00:00:40,160
all right perfect perfect uh thanks a

00:00:38,480 --> 00:00:40,800
lot for bearing with me i was having a

00:00:40,160 --> 00:00:44,079
bit of a

00:00:40,800 --> 00:00:46,320
of computer problems here um i

00:00:44,079 --> 00:00:47,680
am speaking from barcelona spain my name

00:00:46,320 --> 00:00:50,800
is flavio

00:00:47,680 --> 00:00:52,800
uh and i was apache member

00:00:50,800 --> 00:00:54,079
and i consider my home at apache to be

00:00:52,800 --> 00:00:57,280
projects like

00:00:54,079 --> 00:00:59,440
zookeeper and uh and bookkeeper

00:00:57,280 --> 00:01:01,039
but today i i won't be telling you about

00:00:59,440 --> 00:01:02,480
those projects i'll be telling you about

00:01:01,039 --> 00:01:05,680
a different project that uh

00:01:02,480 --> 00:01:08,720
i have been working on called prevega

00:01:05,680 --> 00:01:10,000
provega provides storage for streams and

00:01:08,720 --> 00:01:11,600
we have been developing this for the

00:01:10,000 --> 00:01:14,720
past few years

00:01:11,600 --> 00:01:17,759
i am a senior distinguished engineer

00:01:14,720 --> 00:01:21,119
at dell and my main role

00:01:17,759 --> 00:01:23,840
in uh in apache uh in apache impervega

00:01:21,119 --> 00:01:25,439
is as a as an architect so let me tell

00:01:23,840 --> 00:01:26,240
you a bit about uh the context of

00:01:25,439 --> 00:01:27,680
provegan

00:01:26,240 --> 00:01:30,000
and what it does and what problems it

00:01:27,680 --> 00:01:30,000
solve

00:01:31,920 --> 00:01:36,960
if you think of a lot of data analytics

00:01:34,880 --> 00:01:40,000
scenarios today

00:01:36,960 --> 00:01:42,799
a lot of them have data sources that

00:01:40,000 --> 00:01:44,479
continuously produce data um at least

00:01:42,799 --> 00:01:46,479
some of the data sources if not all of

00:01:44,479 --> 00:01:49,040
the sources

00:01:46,479 --> 00:01:50,320
and that kind of pattern of continuously

00:01:49,040 --> 00:01:53,439
producing data

00:01:50,320 --> 00:01:55,840
maps very naturally to how we think of a

00:01:53,439 --> 00:01:58,560
stream or intuitively how we think of

00:01:55,840 --> 00:01:58,560
data streams

00:01:59,520 --> 00:02:04,240
it's even though it's not a it's not

00:02:02,159 --> 00:02:05,920
restricted when we talk about continuous

00:02:04,240 --> 00:02:08,640
uh data sources even though it's not

00:02:05,920 --> 00:02:09,440
restricted to machines it's important to

00:02:08,640 --> 00:02:12,239
notice that

00:02:09,440 --> 00:02:13,120
in the past in the recent past and and

00:02:12,239 --> 00:02:15,599
today

00:02:13,120 --> 00:02:18,080
we're getting more and more cases where

00:02:15,599 --> 00:02:20,080
the data is machine generated

00:02:18,080 --> 00:02:22,080
as i mentioned we can have end users as

00:02:20,080 --> 00:02:23,920
well producing updates uh

00:02:22,080 --> 00:02:25,599
transactions out of online shopping all

00:02:23,920 --> 00:02:27,599
that kind of stuff

00:02:25,599 --> 00:02:29,520
but machine generated data is becoming

00:02:27,599 --> 00:02:30,160
more and more relevant and we expect to

00:02:29,520 --> 00:02:32,400
have more

00:02:30,160 --> 00:02:34,000
cases like that and so one question that

00:02:32,400 --> 00:02:37,280
we asked ourselves

00:02:34,000 --> 00:02:40,400
and we have set ourselves to to answer

00:02:37,280 --> 00:02:43,920
is what is the role of storage in that

00:02:40,400 --> 00:02:46,720
uh streaming analytics world and prevega

00:02:43,920 --> 00:02:47,519
is precisely about that is a system data

00:02:46,720 --> 00:02:50,959
we have

00:02:47,519 --> 00:02:51,920
imagined for uh applications or

00:02:50,959 --> 00:02:55,280
scenarios

00:02:51,920 --> 00:02:57,840
in which streaming is is um

00:02:55,280 --> 00:03:01,840
is very important maps naturally the way

00:02:57,840 --> 00:03:04,159
that data is generated and processed

00:03:01,840 --> 00:03:05,360
now pravega as i mentioned is storage

00:03:04,159 --> 00:03:07,599
for streaming data

00:03:05,360 --> 00:03:10,640
it provides a number of relevant

00:03:07,599 --> 00:03:14,159
features in the context of streaming

00:03:10,640 --> 00:03:15,200
for example it enables um an unbounded

00:03:14,159 --> 00:03:18,159
amount of data per

00:03:15,200 --> 00:03:18,560
stream and the way should we do this is

00:03:18,159 --> 00:03:20,400
by

00:03:18,560 --> 00:03:22,720
tiering data to horizontally

00:03:20,400 --> 00:03:24,879
horizontally stable storage

00:03:22,720 --> 00:03:26,560
but it's not only about uh unbounded

00:03:24,879 --> 00:03:29,440
amounts of data per stream

00:03:26,560 --> 00:03:30,319
we also make streams elastic so it can

00:03:29,440 --> 00:03:33,040
grow

00:03:30,319 --> 00:03:34,000
and shrink the the parallelism of uh of

00:03:33,040 --> 00:03:36,319
a stream

00:03:34,000 --> 00:03:38,879
uh dynamically depending on the workload

00:03:36,319 --> 00:03:40,879
that is uh that is receiving

00:03:38,879 --> 00:03:42,879
uh on top of all that we make it

00:03:40,879 --> 00:03:44,720
consistent we enable transaction appends

00:03:42,879 --> 00:03:48,000
we track positions of uh

00:03:44,720 --> 00:03:49,680
of of writers to avoid duplication

00:03:48,000 --> 00:03:52,239
missing messages and such

00:03:49,680 --> 00:03:53,439
um we guarantee order on a per-routing

00:03:52,239 --> 00:03:56,959
key basis

00:03:53,439 --> 00:03:58,640
to provide properties that enable

00:03:56,959 --> 00:04:00,799
correctness for applications

00:03:58,640 --> 00:04:02,959
and performance is also key to what we

00:04:00,799 --> 00:04:05,439
do high throughput and low latency

00:04:02,959 --> 00:04:06,239
uh are are are part of our bread and

00:04:05,439 --> 00:04:08,000
butter what we

00:04:06,239 --> 00:04:09,680
try to achieve and in fact i'll show

00:04:08,000 --> 00:04:11,200
some performance numbers later in the in

00:04:09,680 --> 00:04:13,280
the presentation

00:04:11,200 --> 00:04:15,760
so this is a project that has been under

00:04:13,280 --> 00:04:18,880
development since 2016.

00:04:15,760 --> 00:04:20,799
it's part of a of a dell emc product

00:04:18,880 --> 00:04:22,000
a platform product called streaming data

00:04:20,799 --> 00:04:23,840
platform

00:04:22,000 --> 00:04:26,240
but the core of that platform which is

00:04:23,840 --> 00:04:30,000
prevega is entirely open source

00:04:26,240 --> 00:04:33,520
so i i'm showing on screen two um

00:04:30,000 --> 00:04:34,240
um two links one for the main website of

00:04:33,520 --> 00:04:37,280
pravega

00:04:34,240 --> 00:04:39,680
and another for our repository you

00:04:37,280 --> 00:04:40,479
it's been actively developed our all of

00:04:39,680 --> 00:04:42,000
our work

00:04:40,479 --> 00:04:44,479
in provega actually happens on the

00:04:42,000 --> 00:04:47,600
repository so i encourage everyone to go

00:04:44,479 --> 00:04:47,600
and check it out

00:04:49,040 --> 00:04:52,800
in this particular talk i'll be focusing

00:04:50,880 --> 00:04:54,720
on the following first i'll say

00:04:52,800 --> 00:04:56,720
a few more things about streaming data

00:04:54,720 --> 00:04:58,560
to motivate our work then i'll introduce

00:04:56,720 --> 00:04:59,440
provega talk about his concepts

00:04:58,560 --> 00:05:02,479
architecture

00:04:59,440 --> 00:05:04,479
the read and write paths um then i will

00:05:02,479 --> 00:05:07,199
talk about one interesting aspect

00:05:04,479 --> 00:05:08,400
um i i mentioned scaling which i will

00:05:07,199 --> 00:05:10,000
talk more about but

00:05:08,400 --> 00:05:12,000
if you if you think that streams are

00:05:10,000 --> 00:05:14,080
changing dynamically how does

00:05:12,000 --> 00:05:15,280
reading from that stream happen so i'll

00:05:14,080 --> 00:05:17,919
talk about that

00:05:15,280 --> 00:05:19,680
then i'll say um a few things about

00:05:17,919 --> 00:05:21,440
abstractions beyond strings

00:05:19,680 --> 00:05:24,080
so the kinds of abstractions that we can

00:05:21,440 --> 00:05:26,720
build using the the basic construct

00:05:24,080 --> 00:05:27,360
of provega uh then performance then i'll

00:05:26,720 --> 00:05:29,199
wrap up

00:05:27,360 --> 00:05:31,120
so these are the topics i i plan to

00:05:29,199 --> 00:05:34,560
cover during this talk

00:05:31,120 --> 00:05:34,560
so let's go into streaming data

00:05:34,880 --> 00:05:38,560
so this is a very simple model of of key

00:05:37,759 --> 00:05:41,759
components

00:05:38,560 --> 00:05:44,160
of uh of a of a stream

00:05:41,759 --> 00:05:45,600
um of a stream application of course

00:05:44,160 --> 00:05:47,280
this is simplifying a lot

00:05:45,600 --> 00:05:49,039
i don't expect this to represent every

00:05:47,280 --> 00:05:51,199
single aspect that is important

00:05:49,039 --> 00:05:53,039
but it captures the aspects that are

00:05:51,199 --> 00:05:55,199
that are relevant for this discussion

00:05:53,039 --> 00:05:56,800
so it has a data source the data source

00:05:55,199 --> 00:05:58,720
is not a single element if we're talking

00:05:56,800 --> 00:06:01,440
for example about sensors or servers

00:05:58,720 --> 00:06:02,400
there could be multiple of them and they

00:06:01,440 --> 00:06:05,039
are producing

00:06:02,400 --> 00:06:06,240
a parallel flows of events then i have a

00:06:05,039 --> 00:06:07,759
data processor that

00:06:06,240 --> 00:06:09,360
could also have some degree of

00:06:07,759 --> 00:06:12,319
parallelism uh

00:06:09,360 --> 00:06:13,680
or be part of my complex pipeline and

00:06:12,319 --> 00:06:16,880
that's data processor

00:06:13,680 --> 00:06:18,479
is taking those events processing it and

00:06:16,880 --> 00:06:20,880
generating some output some

00:06:18,479 --> 00:06:21,360
visualization them into a database that

00:06:20,880 --> 00:06:23,440
you can

00:06:21,360 --> 00:06:26,400
query against all those are our

00:06:23,440 --> 00:06:26,400
potential options

00:06:26,960 --> 00:06:30,960
concrete examples are sensors that are

00:06:29,039 --> 00:06:33,840
continuously producing sensed values

00:06:30,960 --> 00:06:35,280
uh we we have seen talks uh about

00:06:33,840 --> 00:06:35,759
databases where we have i don't know

00:06:35,280 --> 00:06:38,479
change

00:06:35,759 --> 00:06:39,120
data capture uh event sourcing so

00:06:38,479 --> 00:06:42,160
updates

00:06:39,120 --> 00:06:45,039
out of a database can also constitute a

00:06:42,160 --> 00:06:47,520
a good a good use case where we map

00:06:45,039 --> 00:06:50,400
again all those updates to uh to

00:06:47,520 --> 00:06:50,400
flows of events

00:06:50,560 --> 00:06:53,599
again it's not only about machines it

00:06:51,919 --> 00:06:54,000
could be about end users as well we can

00:06:53,599 --> 00:06:56,560
have

00:06:54,000 --> 00:06:57,599
end users producing updates in a say a

00:06:56,560 --> 00:06:59,520
social network

00:06:57,599 --> 00:07:02,160
or pre-logs if it's against the search

00:06:59,520 --> 00:07:03,120
engine or transactions if if it's online

00:07:02,160 --> 00:07:06,160
shopping

00:07:03,120 --> 00:07:09,360
um one interesting example which which

00:07:06,160 --> 00:07:09,840
um is not really about events is the one

00:07:09,360 --> 00:07:12,720
of

00:07:09,840 --> 00:07:14,160
video streams so i'm adding video

00:07:12,720 --> 00:07:17,120
streams because again that's

00:07:14,160 --> 00:07:18,160
um that's a very important use case

00:07:17,120 --> 00:07:21,599
today

00:07:18,160 --> 00:07:24,160
and those cameras will be producing uh

00:07:21,599 --> 00:07:26,000
data continuously streams of videos

00:07:24,160 --> 00:07:28,400
continuously that could be many of them

00:07:26,000 --> 00:07:29,759
and video analytics is uh is very

00:07:28,400 --> 00:07:32,800
important for

00:07:29,759 --> 00:07:35,919
a vast number of applications

00:07:32,800 --> 00:07:37,599
now in our work uh a few of the things

00:07:35,919 --> 00:07:38,479
that uh that we have observed so let me

00:07:37,599 --> 00:07:41,680
mention then

00:07:38,479 --> 00:07:44,800
them we have seen some scenarios where

00:07:41,680 --> 00:07:46,319
um users are interested in in capturing

00:07:44,800 --> 00:07:49,039
data from drones

00:07:46,319 --> 00:07:50,240
um data like video streams and telemetry

00:07:49,039 --> 00:07:52,160
um

00:07:50,240 --> 00:07:53,840
and that could be for very different

00:07:52,160 --> 00:07:56,560
scenarios from inspecting

00:07:53,840 --> 00:07:58,000
uh cattle health to inspecting airplanes

00:07:56,560 --> 00:08:00,960
between flights

00:07:58,000 --> 00:08:01,599
and they wanted to ingest that data and

00:08:00,960 --> 00:08:04,560
tail

00:08:01,599 --> 00:08:06,319
the data of uh of of those streams but

00:08:04,560 --> 00:08:08,080
at the same time accumulate data so that

00:08:06,319 --> 00:08:11,440
it can be processed

00:08:08,080 --> 00:08:13,120
um later on and so

00:08:11,440 --> 00:08:15,280
they were interested in building a

00:08:13,120 --> 00:08:17,680
unified uh pipeline

00:08:15,280 --> 00:08:18,319
or a unifying workflow in which they

00:08:17,680 --> 00:08:21,520
could both

00:08:18,319 --> 00:08:23,440
process tail and and historical data

00:08:21,520 --> 00:08:25,360
using pretty much the same same

00:08:23,440 --> 00:08:27,520
infrastructure

00:08:25,360 --> 00:08:28,960
and very similarly we have cases with

00:08:27,520 --> 00:08:31,199
inducer iot

00:08:28,960 --> 00:08:32,399
where in a factory floor you have um

00:08:31,199 --> 00:08:34,880
cameras and

00:08:32,399 --> 00:08:36,240
and sensors continuously producing data

00:08:34,880 --> 00:08:38,880
and we also

00:08:36,240 --> 00:08:40,000
here want to capture that data uh tail

00:08:38,880 --> 00:08:42,320
the the the

00:08:40,000 --> 00:08:44,080
stream while processing accumulating and

00:08:42,320 --> 00:08:44,959
performing some historical processing

00:08:44,080 --> 00:08:47,600
over that data

00:08:44,959 --> 00:08:49,200
later on so that's another um general

00:08:47,600 --> 00:08:51,440
use case that we have observed in our

00:08:49,200 --> 00:08:51,440
work

00:08:52,080 --> 00:08:58,399
now going back to um going back to

00:08:55,920 --> 00:09:00,320
the the the the model the simple model

00:08:58,399 --> 00:09:02,240
that i mentioned before

00:09:00,320 --> 00:09:03,760
there are two very important aspects

00:09:02,240 --> 00:09:06,800
that uh that uh

00:09:03,760 --> 00:09:08,800
i want to highlight for this um

00:09:06,800 --> 00:09:10,399
for the simple pipeline uh their

00:09:08,800 --> 00:09:12,320
applications care about

00:09:10,399 --> 00:09:13,519
they're not the only ones but they're

00:09:12,320 --> 00:09:14,560
they are the ones that are important for

00:09:13,519 --> 00:09:16,080
this discussion

00:09:14,560 --> 00:09:18,320
so the first one is a lot of

00:09:16,080 --> 00:09:20,800
applications they they

00:09:18,320 --> 00:09:23,600
one streaming because they want low

00:09:20,800 --> 00:09:26,240
latency between the data being produced

00:09:23,600 --> 00:09:28,000
and the output reflecting the processing

00:09:26,240 --> 00:09:30,640
of data of that data

00:09:28,000 --> 00:09:31,920
so they need that for uh for low latency

00:09:30,640 --> 00:09:34,240
and

00:09:31,920 --> 00:09:36,080
this is of course a model that if

00:09:34,240 --> 00:09:37,440
implemented is reflected in a in a

00:09:36,080 --> 00:09:40,240
distributed system

00:09:37,440 --> 00:09:41,680
and as any other distributed system uh

00:09:40,240 --> 00:09:44,320
components crash

00:09:41,680 --> 00:09:44,959
they disconnect uh we have network

00:09:44,320 --> 00:09:47,680
problems

00:09:44,959 --> 00:09:48,959
so all those are possible so having um a

00:09:47,680 --> 00:09:50,800
reliable path

00:09:48,959 --> 00:09:53,279
that ensures that the data that is

00:09:50,800 --> 00:09:57,279
produced is eventually processed

00:09:53,279 --> 00:09:59,200
is very important now when the data

00:09:57,279 --> 00:10:00,320
or those events catch the data processor

00:09:59,200 --> 00:10:02,720
the data processor

00:10:00,320 --> 00:10:04,399
uh produces an output so takes the

00:10:02,720 --> 00:10:06,720
events produces an output

00:10:04,399 --> 00:10:08,320
um what do we do with the events at that

00:10:06,720 --> 00:10:11,040
point

00:10:08,320 --> 00:10:11,760
so do we throw it away do we keep it

00:10:11,040 --> 00:10:13,519
what do we do

00:10:11,760 --> 00:10:15,760
so a number of applications will choose

00:10:13,519 --> 00:10:17,279
to uh to get rid of it so they have

00:10:15,760 --> 00:10:19,040
process they produce whatever

00:10:17,279 --> 00:10:21,839
output they needed and they are done

00:10:19,040 --> 00:10:23,680
with it but there are many reasons for

00:10:21,839 --> 00:10:25,839
uh for maintaining ek around

00:10:23,680 --> 00:10:27,600
so a few of them would be that you want

00:10:25,839 --> 00:10:29,600
to reprocess data

00:10:27,600 --> 00:10:31,440
you find you found the bug in your in

00:10:29,600 --> 00:10:32,000
your application you wanna you wanna

00:10:31,440 --> 00:10:35,120
roll back

00:10:32,000 --> 00:10:37,360
and reprocess data uh or

00:10:35,120 --> 00:10:38,320
you simply have a job that that cares

00:10:37,360 --> 00:10:41,279
about

00:10:38,320 --> 00:10:42,160
a later state of the data data from six

00:10:41,279 --> 00:10:45,360
months ago

00:10:42,160 --> 00:10:47,360
data from a year ago um and also you are

00:10:45,360 --> 00:10:48,800
deriving data out of that processing so

00:10:47,360 --> 00:10:49,760
you might want to keep the data around

00:10:48,800 --> 00:10:53,200
for lineage

00:10:49,760 --> 00:10:54,800
lineage and auditing purposes

00:10:53,200 --> 00:10:57,200
so those are some reasons for uh for

00:10:54,800 --> 00:10:58,160
keeping it around now one way of doing

00:10:57,200 --> 00:11:00,959
this

00:10:58,160 --> 00:11:02,000
is to fork that output from this stream

00:11:00,959 --> 00:11:05,279
and um

00:11:02,000 --> 00:11:07,519
and uh copy that data on storage

00:11:05,279 --> 00:11:08,560
say on a file system on some object

00:11:07,519 --> 00:11:11,040
store

00:11:08,560 --> 00:11:13,120
um so that's one option but one question

00:11:11,040 --> 00:11:16,160
to ask is

00:11:13,120 --> 00:11:17,760
you know so this part of the flow

00:11:16,160 --> 00:11:19,920
in that part of the flow i'm persisting

00:11:17,760 --> 00:11:20,240
data so why can't we just leave the data

00:11:19,920 --> 00:11:21,920
there

00:11:20,240 --> 00:11:23,839
why can't i just consider that part of

00:11:21,920 --> 00:11:26,160
the path my um

00:11:23,839 --> 00:11:28,720
my storage and that brings me to the

00:11:26,160 --> 00:11:32,480
question of you know storage for streams

00:11:28,720 --> 00:11:35,360
um what have we done about that

00:11:32,480 --> 00:11:37,120
so if we start from traditional storage

00:11:35,360 --> 00:11:40,480
the typical primitives you'll see

00:11:37,120 --> 00:11:43,519
are the files objects blocks

00:11:40,480 --> 00:11:46,560
which um do not capture the right level

00:11:43,519 --> 00:11:48,560
of abstraction that we want for streams

00:11:46,560 --> 00:11:50,399
messaging systems are much closer to

00:11:48,560 --> 00:11:51,600
that so they provide rich semantics with

00:11:50,399 --> 00:11:53,519
respect to messaging

00:11:51,600 --> 00:11:55,200
but part of the problems that it

00:11:53,519 --> 00:11:56,160
provides they typically provide limited

00:11:55,200 --> 00:11:58,000
durability

00:11:56,160 --> 00:12:00,160
because they rely on broker storage for

00:11:58,000 --> 00:12:02,320
that and what we really want

00:12:00,160 --> 00:12:04,800
is the stream as a first class storage

00:12:02,320 --> 00:12:04,800
primitive

00:12:04,959 --> 00:12:08,000
and given the way we we are thinking

00:12:07,360 --> 00:12:10,959
about it

00:12:08,000 --> 00:12:13,040
we strongly believe that uh the the

00:12:10,959 --> 00:12:15,040
continuous data sources that we have

00:12:13,040 --> 00:12:16,720
and the number of applications that have

00:12:15,040 --> 00:12:18,320
them um

00:12:16,720 --> 00:12:20,800
it makes sense for us to make this

00:12:18,320 --> 00:12:23,279
popular just like files have been for uh

00:12:20,800 --> 00:12:25,519
for for many decades

00:12:23,279 --> 00:12:27,120
um but with the streams and the way we

00:12:25,519 --> 00:12:27,920
are generating and processing damage

00:12:27,120 --> 00:12:30,560
today it's just

00:12:27,920 --> 00:12:31,519
much more natural to have uh to have

00:12:30,560 --> 00:12:34,480
streams

00:12:31,519 --> 00:12:35,519
for uh for capturing this data uh we can

00:12:34,480 --> 00:12:38,000
reason about them

00:12:35,519 --> 00:12:39,760
using power lesson uh scaling uh

00:12:38,000 --> 00:12:41,680
transactional rights for consistency and

00:12:39,760 --> 00:12:42,639
files and objects do not abstract those

00:12:41,680 --> 00:12:44,720
away

00:12:42,639 --> 00:12:47,360
of course it's not to say that they are

00:12:44,720 --> 00:12:48,079
not useful in the scenario files and in

00:12:47,360 --> 00:12:49,519
objects

00:12:48,079 --> 00:12:51,760
uh in fact when i talk about the

00:12:49,519 --> 00:12:52,639
architecture we see that we we rely on

00:12:51,760 --> 00:12:55,440
them

00:12:52,639 --> 00:12:56,639
but it is important that what we use to

00:12:55,440 --> 00:12:59,839
build our systems

00:12:56,639 --> 00:13:02,079
is based on uh on on streams

00:12:59,839 --> 00:13:03,680
and in just reasoning about streams

00:13:02,079 --> 00:13:04,240
themselves why i want to keep that as a

00:13:03,680 --> 00:13:06,079
stream

00:13:04,240 --> 00:13:07,279
well streams enable tailing in

00:13:06,079 --> 00:13:10,079
historical processing

00:13:07,279 --> 00:13:10,880
indistinctively so i can move my point

00:13:10,079 --> 00:13:13,120
in the stream

00:13:10,880 --> 00:13:14,079
so that i can tell the stream or process

00:13:13,120 --> 00:13:16,240
historically

00:13:14,079 --> 00:13:17,600
using that same abstraction uh it can

00:13:16,240 --> 00:13:19,360
also be the source of truth for

00:13:17,600 --> 00:13:20,480
materializing different views if i treat

00:13:19,360 --> 00:13:22,639
my stream as a log

00:13:20,480 --> 00:13:25,200
i can generate tables graphs time series

00:13:22,639 --> 00:13:27,200
out of out of that of that data

00:13:25,200 --> 00:13:28,720
so this is um this is at a high level

00:13:27,200 --> 00:13:31,360
what we would like to achieve

00:13:28,720 --> 00:13:31,920
so now let me move move on and talk

00:13:31,360 --> 00:13:35,839
about

00:13:31,920 --> 00:13:39,360
uh prevega so the system that we have um

00:13:35,839 --> 00:13:41,920
we have designed and implemented to

00:13:39,360 --> 00:13:42,959
materialize this this this vision of a

00:13:41,920 --> 00:13:46,160
of uh

00:13:42,959 --> 00:13:46,160
of storage for streams

00:13:47,279 --> 00:13:50,399
so the basic construct that we have in

00:13:49,600 --> 00:13:52,240
prevega

00:13:50,399 --> 00:13:55,120
is a stream segment so the stream

00:13:52,240 --> 00:13:57,360
segment is the storage unit of pravega

00:13:55,120 --> 00:13:58,800
it's in its very essence it's an append

00:13:57,360 --> 00:14:01,279
only sickness of bytes

00:13:58,800 --> 00:14:02,720
um note that it's bytes not events

00:14:01,279 --> 00:14:05,040
messages or records

00:14:02,720 --> 00:14:06,639
uh we do not care about the framing at

00:14:05,040 --> 00:14:09,199
the at the segment level

00:14:06,639 --> 00:14:10,160
and we just simply start the bytes now

00:14:09,199 --> 00:14:13,600
at the api

00:14:10,160 --> 00:14:15,600
when you when you are appending events

00:14:13,600 --> 00:14:17,279
so those events are you know rely on a

00:14:15,600 --> 00:14:19,440
sterilizer to

00:14:17,279 --> 00:14:20,320
transform down dummy two bytes on the

00:14:19,440 --> 00:14:23,120
way in

00:14:20,320 --> 00:14:26,160
and and transform it back to an events

00:14:23,120 --> 00:14:27,760
on the on the way out of the system

00:14:26,160 --> 00:14:30,160
and with these stream segments i can

00:14:27,760 --> 00:14:31,839
provide parallelism i can have a number

00:14:30,160 --> 00:14:35,279
of segments in parallel that the

00:14:31,839 --> 00:14:38,720
the data source can can append to

00:14:35,279 --> 00:14:41,600
and the way to map

00:14:38,720 --> 00:14:43,440
to map requests japan to the segments uh

00:14:41,600 --> 00:14:45,040
can be done via routing key so

00:14:43,440 --> 00:14:46,720
the application provides routing keys so

00:14:45,040 --> 00:14:49,199
that uh so that internally

00:14:46,720 --> 00:14:50,720
provider guarantees that uh the events

00:14:49,199 --> 00:14:52,000
with the same routing here the data with

00:14:50,720 --> 00:14:55,600
the same routing key

00:14:52,000 --> 00:14:57,680
will be uh will be delivered in order

00:14:55,600 --> 00:15:00,079
but very important that degree of

00:14:57,680 --> 00:15:02,240
parallelism is not static in prevega

00:15:00,079 --> 00:15:04,800
so say that i start the stream with with

00:15:02,240 --> 00:15:06,399
two segments s1 and s2

00:15:04,800 --> 00:15:08,880
i can have that degree of parallelism

00:15:06,399 --> 00:15:12,320
changing uh dynamically over time

00:15:08,880 --> 00:15:15,040
so if i if i um if my stream starts

00:15:12,320 --> 00:15:18,399
receiving more loads

00:15:15,040 --> 00:15:20,800
then i i can have a scale up event that

00:15:18,399 --> 00:15:21,760
um seals initial segments and create

00:15:20,800 --> 00:15:24,399
four new segments

00:15:21,760 --> 00:15:25,600
so now my string became i went from a

00:15:24,399 --> 00:15:27,519
two segment stream

00:15:25,600 --> 00:15:28,880
to a four segment string providing more

00:15:27,519 --> 00:15:31,680
parallelism for uh

00:15:28,880 --> 00:15:32,399
for for a pens but it can go further if

00:15:31,680 --> 00:15:35,600
two of those

00:15:32,399 --> 00:15:38,399
if two of those segments um

00:15:35,600 --> 00:15:39,759
that codes then i can seal them and

00:15:38,399 --> 00:15:41,440
transform them into one

00:15:39,759 --> 00:15:43,120
so bringing the string from a four

00:15:41,440 --> 00:15:43,680
segment string into a three segment

00:15:43,120 --> 00:15:46,079
string

00:15:43,680 --> 00:15:48,480
so this kind of dynamics is uh is what

00:15:46,079 --> 00:15:51,040
we expect from uh from a previous string

00:15:48,480 --> 00:15:51,680
and so that he can adapt to workload

00:15:51,040 --> 00:15:55,839
changes

00:15:51,680 --> 00:15:55,839
uh over time

00:15:57,040 --> 00:15:59,839
there are the things we can do with

00:15:58,240 --> 00:16:01,279
stream segments i won't be covered them

00:15:59,839 --> 00:16:04,160
here but i want to mention

00:16:01,279 --> 00:16:06,000
um transactions uh revision streams

00:16:04,160 --> 00:16:07,600
watermarking so those are all features

00:16:06,000 --> 00:16:10,880
that we have implemented

00:16:07,600 --> 00:16:14,000
and they rely on them on

00:16:10,880 --> 00:16:15,600
on stream segments to to implement them

00:16:14,000 --> 00:16:17,759
we rely on stream segments to implement

00:16:15,600 --> 00:16:17,759
them

00:16:18,480 --> 00:16:23,199
let me move to talk to uh to talk about

00:16:20,880 --> 00:16:26,880
the preview architecture

00:16:23,199 --> 00:16:29,680
so in improv vega uh talking about this

00:16:26,880 --> 00:16:30,320
the the event api an application would

00:16:29,680 --> 00:16:32,240
distinguish

00:16:30,320 --> 00:16:34,399
event writers the event writers would

00:16:32,240 --> 00:16:37,360
append events to a prevegan stream

00:16:34,399 --> 00:16:38,560
through produce the bytes that we append

00:16:37,360 --> 00:16:40,480
proviga tracks

00:16:38,560 --> 00:16:42,079
the writer position so that we don't

00:16:40,480 --> 00:16:44,000
miss events and we don't duplicate

00:16:42,079 --> 00:16:46,399
events

00:16:44,000 --> 00:16:47,519
then on the read side we have um event

00:16:46,399 --> 00:16:49,839
reader instances

00:16:47,519 --> 00:16:51,279
we group event readers into what we call

00:16:49,839 --> 00:16:53,759
reader groups

00:16:51,279 --> 00:16:54,880
and the readers in the group will split

00:16:53,759 --> 00:16:58,320
the load of uh

00:16:54,880 --> 00:17:00,000
of segments among them and we do provide

00:16:58,320 --> 00:17:01,519
a bit of growing shrinking data that

00:17:00,000 --> 00:17:05,839
read the group

00:17:01,519 --> 00:17:05,839
according to the application needs

00:17:05,919 --> 00:17:10,240
that reading also happens uh in the

00:17:09,039 --> 00:17:12,000
presence of scaling

00:17:10,240 --> 00:17:13,679
so it respects the predecessor's

00:17:12,000 --> 00:17:16,480
successor relationship

00:17:13,679 --> 00:17:18,240
of segments but we'll talk more about

00:17:16,480 --> 00:17:22,959
that a few slides down

00:17:18,240 --> 00:17:22,959
so hold on to uh to that thought

00:17:23,199 --> 00:17:26,480
provega has two um as your main

00:17:25,839 --> 00:17:28,319
components

00:17:26,480 --> 00:17:30,080
the controller and the segment store so

00:17:28,319 --> 00:17:30,559
the controller manages the stream life

00:17:30,080 --> 00:17:32,799
cycle

00:17:30,559 --> 00:17:33,760
and manages transactions as well the

00:17:32,799 --> 00:17:37,120
segment store

00:17:33,760 --> 00:17:40,080
up doesn't know about streams it's

00:17:37,120 --> 00:17:40,720
um it manages the lifecycle of segments

00:17:40,080 --> 00:17:42,799
and one

00:17:40,720 --> 00:17:45,840
important part of that lifecycle is

00:17:42,799 --> 00:17:48,240
storing the the segment

00:17:45,840 --> 00:17:49,280
the unit of work of the segment store is

00:17:48,240 --> 00:17:51,120
segment containers

00:17:49,280 --> 00:17:52,480
so what we do is we configure a number

00:17:51,120 --> 00:17:55,520
of segment containers to run

00:17:52,480 --> 00:17:56,799
across segment store instances and we

00:17:55,520 --> 00:17:59,679
split the load of

00:17:56,799 --> 00:18:00,240
of segment containers across all the

00:17:59,679 --> 00:18:03,679
segments

00:18:00,240 --> 00:18:06,160
store instances the

00:18:03,679 --> 00:18:07,440
segment store relies on two storage

00:18:06,160 --> 00:18:09,520
dependencies

00:18:07,440 --> 00:18:11,280
one uh the first one being the durable

00:18:09,520 --> 00:18:13,840
log the durable log

00:18:11,280 --> 00:18:15,520
guarantees durability for string data we

00:18:13,840 --> 00:18:18,240
do not return to the application

00:18:15,520 --> 00:18:20,799
before we ensure that it's uh that is

00:18:18,240 --> 00:18:23,360
written to the durable

00:18:20,799 --> 00:18:25,039
and we use a long-term storage

00:18:23,360 --> 00:18:27,840
dependency

00:18:25,039 --> 00:18:29,520
to uh to asynchronously is the right

00:18:27,840 --> 00:18:30,400
data there and that's where we keep data

00:18:29,520 --> 00:18:32,960
long term

00:18:30,400 --> 00:18:34,320
uh that's that's long term so i just

00:18:32,960 --> 00:18:36,960
expect it to be

00:18:34,320 --> 00:18:37,919
uh horizontally scalable and we have

00:18:36,960 --> 00:18:41,360
options for both

00:18:37,919 --> 00:18:42,080
a file and an act for a long term start

00:18:41,360 --> 00:18:46,160
so this is

00:18:42,080 --> 00:18:47,360
configurable uh for for your deployment

00:18:46,160 --> 00:18:48,799
for the journal i think it didn't

00:18:47,360 --> 00:18:50,400
mention that for the journal we are

00:18:48,799 --> 00:18:53,600
relying on today we're planning that

00:18:50,400 --> 00:18:53,600
with apache boot keeper

00:18:54,559 --> 00:18:57,679
an important aspect i want to mention

00:18:56,160 --> 00:19:00,880
about the pravega architecture

00:18:57,679 --> 00:19:04,080
is how we made the stream metadata

00:19:00,880 --> 00:19:05,520
um stable so why do we even care about

00:19:04,080 --> 00:19:08,880
that for for two reasons

00:19:05,520 --> 00:19:12,720
one is that we are aiming at building

00:19:08,880 --> 00:19:14,240
a stable system and as such we need to

00:19:12,720 --> 00:19:16,160
be able to accommodate a large number of

00:19:14,240 --> 00:19:19,200
streams a large number of segments

00:19:16,160 --> 00:19:21,679
and not only that i have talked about

00:19:19,200 --> 00:19:22,480
um streams dynamically changing over

00:19:21,679 --> 00:19:25,679
time

00:19:22,480 --> 00:19:28,960
so the metadata of those streams will

00:19:25,679 --> 00:19:30,640
will evolve and and will grow so for

00:19:28,960 --> 00:19:31,200
example if i need to keep the history of

00:19:30,640 --> 00:19:33,919
segments

00:19:31,200 --> 00:19:34,960
as i add more segments then the history

00:19:33,919 --> 00:19:37,520
will grow

00:19:34,960 --> 00:19:38,640
so we have the needs of uh of making it

00:19:37,520 --> 00:19:42,160
scalable

00:19:38,640 --> 00:19:44,960
and uh we have chosen to eu

00:19:42,160 --> 00:19:46,480
implements um this abstraction of tables

00:19:44,960 --> 00:19:47,360
internally backed by segments that we

00:19:46,480 --> 00:19:50,640
call table

00:19:47,360 --> 00:19:51,440
segments and we store the our stream

00:19:50,640 --> 00:19:54,559
metadata

00:19:51,440 --> 00:19:55,520
there so a table segment is again backed

00:19:54,559 --> 00:19:57,200
by segments

00:19:55,520 --> 00:19:59,280
and it has an index that is built on

00:19:57,200 --> 00:20:00,559
segment attributes so get segment

00:19:59,280 --> 00:20:02,320
attributes are key value pairs

00:20:00,559 --> 00:20:05,280
associated to segments

00:20:02,320 --> 00:20:06,000
that themselves are indexed with a b

00:20:05,280 --> 00:20:08,640
plus c

00:20:06,000 --> 00:20:10,320
structure so we do not store string

00:20:08,640 --> 00:20:13,440
metadata in zookeeper

00:20:10,320 --> 00:20:17,280
uh we do store the metadata of

00:20:13,440 --> 00:20:17,280
of bookkeeper in zookeeper so let's

00:20:17,520 --> 00:20:20,880
store it in zookeeper but our use of

00:20:20,159 --> 00:20:23,840
bookkeeper

00:20:20,880 --> 00:20:26,080
is um is bounded recall that we use that

00:20:23,840 --> 00:20:28,559
for uh for the durable log

00:20:26,080 --> 00:20:29,760
and uh and we flush data to long-term

00:20:28,559 --> 00:20:31,360
storage

00:20:29,760 --> 00:20:33,039
as we flush the data to long-term

00:20:31,360 --> 00:20:35,039
storage the data in

00:20:33,039 --> 00:20:37,600
bookkeeper in the durable log is

00:20:35,039 --> 00:20:41,760
eligible for for truncation so

00:20:37,600 --> 00:20:44,320
again our use of bookkeeper is uh

00:20:41,760 --> 00:20:48,880
is limited so that doesn't it's not a

00:20:44,320 --> 00:20:50,799
problem for us

00:20:48,880 --> 00:20:51,919
but one thing that pro that zookeeper

00:20:50,799 --> 00:20:54,799
does for us uh

00:20:51,919 --> 00:20:55,919
is to is to help us implement some

00:20:54,799 --> 00:20:58,720
coordination tasks

00:20:55,919 --> 00:21:00,480
for example i mentioned that we assign

00:20:58,720 --> 00:21:01,200
segment containers to segment story

00:21:00,480 --> 00:21:03,360
instances

00:21:01,200 --> 00:21:04,400
so that work is done by the controller

00:21:03,360 --> 00:21:07,840
um via

00:21:04,400 --> 00:21:09,360
zookeeper so for example if i have two

00:21:07,840 --> 00:21:10,480
segment store instances and i have six

00:21:09,360 --> 00:21:12,240
containers to assign

00:21:10,480 --> 00:21:14,159
let's say that the the controller has

00:21:12,240 --> 00:21:19,039
chosen the assignment that we see

00:21:14,159 --> 00:21:22,080
um that we see on the slide now later on

00:21:19,039 --> 00:21:22,880
if we use segment store instance then

00:21:22,080 --> 00:21:26,960
the controller

00:21:22,880 --> 00:21:29,760
can um can reshuffle those uh those um

00:21:26,960 --> 00:21:31,440
those segment containers and uh and so

00:21:29,760 --> 00:21:32,400
then it distributes the load of segment

00:21:31,440 --> 00:21:35,440
containers

00:21:32,400 --> 00:21:37,679
to um to uh

00:21:35,440 --> 00:21:39,520
to the segment store instances so that's

00:21:37,679 --> 00:21:42,559
one of the tasks that

00:21:39,520 --> 00:21:42,559
helps us execute

00:21:43,440 --> 00:21:46,880
now let me talk in in a bit more detail

00:21:46,159 --> 00:21:48,799
um

00:21:46,880 --> 00:21:50,880
about the right and in the read paths so

00:21:48,799 --> 00:21:53,919
that we get a a better sense of

00:21:50,880 --> 00:21:55,360
of what the flow is how this and

00:21:53,919 --> 00:21:58,720
how the different components interact

00:21:55,360 --> 00:22:01,760
with each other and the steps

00:21:58,720 --> 00:22:03,200
so when the event stream writer gets a

00:22:01,760 --> 00:22:07,520
right events

00:22:03,200 --> 00:22:10,559
uh call to append an event e

00:22:07,520 --> 00:22:12,400
with a key k

00:22:10,559 --> 00:22:13,840
then he needs to determine which segment

00:22:12,400 --> 00:22:15,120
is going to write you and and perhaps

00:22:13,840 --> 00:22:17,039
even more important needs to determine

00:22:15,120 --> 00:22:18,799
which server to talk to

00:22:17,039 --> 00:22:20,320
so if it doesn't have fresh information

00:22:18,799 --> 00:22:21,280
on segments you will have to talk to the

00:22:20,320 --> 00:22:22,880
controller

00:22:21,280 --> 00:22:24,960
so you'll get current segments from the

00:22:22,880 --> 00:22:26,480
controller the controller will respond

00:22:24,960 --> 00:22:29,919
with segment ranges

00:22:26,480 --> 00:22:33,600
uh segment ranges are they

00:22:29,919 --> 00:22:35,600
they are the mapping of um key ranges

00:22:33,600 --> 00:22:37,360
to segments so the event stream writer

00:22:35,600 --> 00:22:39,440
will determine which segments

00:22:37,360 --> 00:22:41,039
it needs to append to based on the on

00:22:39,440 --> 00:22:43,600
the routing key

00:22:41,039 --> 00:22:44,960
so it will request the controller uh the

00:22:43,600 --> 00:22:46,799
the endpoints

00:22:44,960 --> 00:22:49,440
for uh for that segment so the server

00:22:46,799 --> 00:22:52,960
needs to talk to controller returns that

00:22:49,440 --> 00:22:55,039
so once it has it um then you can talk

00:22:52,960 --> 00:22:56,320
to the server but note that

00:22:55,039 --> 00:22:58,320
it's not the case the event stream

00:22:56,320 --> 00:23:00,880
writer needs to talk to the controller

00:22:58,320 --> 00:23:01,360
every time he needs to do it right so it

00:23:00,880 --> 00:23:03,440
does

00:23:01,360 --> 00:23:05,039
it happens occasionally when he has say

00:23:03,440 --> 00:23:06,000
stale information so for example we have

00:23:05,039 --> 00:23:07,760
the scale events

00:23:06,000 --> 00:23:09,440
we have new segments the event stream

00:23:07,760 --> 00:23:11,039
writer needs to learn uh

00:23:09,440 --> 00:23:12,880
what they are so this is not an

00:23:11,039 --> 00:23:15,679
interaction that happens frequently

00:23:12,880 --> 00:23:17,360
uh for a ride event now when the event

00:23:15,679 --> 00:23:21,039
stream writer determines which server

00:23:17,360 --> 00:23:22,559
to talk to then it sets up a pen

00:23:21,039 --> 00:23:24,720
against a component called the pen

00:23:22,559 --> 00:23:28,000
processor on the server side

00:23:24,720 --> 00:23:30,880
so the pen processor it starts

00:23:28,000 --> 00:23:31,760
that uh that uh that an append block it

00:23:30,880 --> 00:23:34,159
starts in

00:23:31,760 --> 00:23:35,039
an append batch that and then the writer

00:23:34,159 --> 00:23:38,480
starts

00:23:35,039 --> 00:23:41,919
appending blocks of data to that batch

00:23:38,480 --> 00:23:44,000
then at some point it um

00:23:41,919 --> 00:23:45,200
it calls a pen block and which closes

00:23:44,000 --> 00:23:48,320
that batch and

00:23:45,200 --> 00:23:51,760
triggers a call to the segment store to

00:23:48,320 --> 00:23:53,760
append that batch of data so segment

00:23:51,760 --> 00:23:56,960
containers are responsible for

00:23:53,760 --> 00:23:58,880
subsets of of segments and so

00:23:56,960 --> 00:24:00,640
the the segment store will routes that

00:23:58,880 --> 00:24:02,720
append request to the segments to

00:24:00,640 --> 00:24:04,400
the segment container responsible for

00:24:02,720 --> 00:24:06,480
that particular segment

00:24:04,400 --> 00:24:08,720
so the segment container will do a

00:24:06,480 --> 00:24:10,159
second level of aggregation

00:24:08,720 --> 00:24:12,080
on the data so perhaps we have data

00:24:10,159 --> 00:24:13,919
coming from

00:24:12,080 --> 00:24:15,279
from from different clients to that same

00:24:13,919 --> 00:24:18,080
segment container

00:24:15,279 --> 00:24:19,520
and then we'll append it to the durable

00:24:18,080 --> 00:24:22,320
log

00:24:19,520 --> 00:24:23,039
once it gets a response from the durable

00:24:22,320 --> 00:24:25,840
log

00:24:23,039 --> 00:24:27,039
it will in parallel um write the data to

00:24:25,840 --> 00:24:30,159
the cache

00:24:27,039 --> 00:24:31,760
and um and respond to the append

00:24:30,159 --> 00:24:33,760
processor

00:24:31,760 --> 00:24:34,799
so the append processor once it gets

00:24:33,760 --> 00:24:36,559
that it can respond

00:24:34,799 --> 00:24:38,400
to the event stream writer acknowledging

00:24:36,559 --> 00:24:41,600
that the data has been written

00:24:38,400 --> 00:24:42,000
now asynchronously asynchronously will

00:24:41,600 --> 00:24:43,600
write

00:24:42,000 --> 00:24:45,279
data that we take from the cache and

00:24:43,600 --> 00:24:48,960
flash it to uh to

00:24:45,279 --> 00:24:51,039
lts to long term storage at which point

00:24:48,960 --> 00:24:54,880
the that same data in the durable log is

00:24:51,039 --> 00:24:54,880
eligible for uh for truncation

00:24:55,440 --> 00:24:58,960
the read path um is not very different

00:24:58,080 --> 00:25:00,799
um

00:24:58,960 --> 00:25:02,480
it so that if the event stream reader

00:25:00,799 --> 00:25:04,480
doesn't have the segment information it

00:25:02,480 --> 00:25:06,159
has to obtain in a similar way that yes

00:25:04,480 --> 00:25:07,679
it will do a similar interaction with

00:25:06,159 --> 00:25:11,120
the controller together

00:25:07,679 --> 00:25:13,360
to get the end point and uh

00:25:11,120 --> 00:25:14,880
and once it once it has an end point it

00:25:13,360 --> 00:25:16,480
will read segment from the

00:25:14,880 --> 00:25:18,240
from the request processor sme doesn't

00:25:16,480 --> 00:25:19,520
have data to return

00:25:18,240 --> 00:25:21,279
then the request processor will read

00:25:19,520 --> 00:25:22,960
that from the segment store

00:25:21,279 --> 00:25:24,400
if the data is cached then it returns

00:25:22,960 --> 00:25:26,559
from the cache if it's a cache missed

00:25:24,400 --> 00:25:28,480
then you read from long-term storage

00:25:26,559 --> 00:25:30,320
the segment starting returns the data to

00:25:28,480 --> 00:25:33,600
the request processor

00:25:30,320 --> 00:25:35,919
responds to the event stream reader

00:25:33,600 --> 00:25:37,039
and the event stream reader returns an

00:25:35,919 --> 00:25:39,760
event to the

00:25:37,039 --> 00:25:41,840
to the application note that we as we

00:25:39,760 --> 00:25:43,120
assume that this is a this is sequential

00:25:41,840 --> 00:25:45,279
access that the application will be

00:25:43,120 --> 00:25:46,960
reading on may events we read ahead and

00:25:45,279 --> 00:25:48,799
so the block that we are returning

00:25:46,960 --> 00:25:50,000
does not necessarily correspond to a

00:25:48,799 --> 00:25:53,360
single event

00:25:50,000 --> 00:25:54,000
uh in fact if there is enough traffic in

00:25:53,360 --> 00:25:55,840
the segment

00:25:54,000 --> 00:25:57,679
you will be you'll be reading more data

00:25:55,840 --> 00:25:59,440
from uh you'll be reading ahead and

00:25:57,679 --> 00:26:02,320
getting more data from the segment store

00:25:59,440 --> 00:26:02,320
for that segment

00:26:04,960 --> 00:26:08,559
so before i finish the part this part

00:26:06,559 --> 00:26:10,640
about reading right paths um

00:26:08,559 --> 00:26:11,679
a few important comments about them so

00:26:10,640 --> 00:26:14,720
the right path

00:26:11,679 --> 00:26:16,720
uh as we observed is primarily driven

00:26:14,720 --> 00:26:18,480
by the sequential right performance of

00:26:16,720 --> 00:26:20,880
the durable log

00:26:18,480 --> 00:26:21,840
so the performance of a pen into stream

00:26:20,880 --> 00:26:24,400
is essentially is

00:26:21,840 --> 00:26:25,200
is primarily driven by by that durable

00:26:24,400 --> 00:26:27,760
log

00:26:25,200 --> 00:26:29,919
the read path is slightly different so

00:26:27,760 --> 00:26:32,480
it depends on whether we talk about tail

00:26:29,919 --> 00:26:34,240
uh tail data or historical data so for

00:26:32,480 --> 00:26:35,520
tail data we expect it to be served from

00:26:34,240 --> 00:26:37,520
the cache

00:26:35,520 --> 00:26:39,840
now for historical data we expect to be

00:26:37,520 --> 00:26:42,000
reading from from long-term storage so

00:26:39,840 --> 00:26:43,279
the sequential read performance of the

00:26:42,000 --> 00:26:46,000
of the long-term storage

00:26:43,279 --> 00:26:47,440
will determine the the performance of

00:26:46,000 --> 00:26:49,200
reading

00:26:47,440 --> 00:26:50,640
the reason the right and the read paths

00:26:49,200 --> 00:26:54,240
they meet in the cache

00:26:50,640 --> 00:26:57,120
but when we talk about storage ios uh

00:26:54,240 --> 00:26:58,640
reads are separate from from writes

00:26:57,120 --> 00:26:59,840
because of the description i have given

00:26:58,640 --> 00:27:01,279
in the and the different storage

00:26:59,840 --> 00:27:03,440
dependencies that we use

00:27:01,279 --> 00:27:05,200
and and a big part of the of of the

00:27:03,440 --> 00:27:09,440
reason to do that was to reduce

00:27:05,200 --> 00:27:09,440
and random access on access media

00:27:11,679 --> 00:27:15,840
all right so let me um let me quickly

00:27:13,919 --> 00:27:17,520
cover what happens when reading

00:27:15,840 --> 00:27:19,279
with scaling so this is interesting

00:27:17,520 --> 00:27:20,000
because i'm i want to read from a stream

00:27:19,279 --> 00:27:23,039
let's take the same

00:27:20,000 --> 00:27:26,799
example i mentioned before and uh and

00:27:23,039 --> 00:27:27,440
and and um i want to guarantee per key

00:27:26,799 --> 00:27:29,039
order as i'm

00:27:27,440 --> 00:27:31,360
as i'm reading from the from that stream

00:27:29,039 --> 00:27:33,440
so how does it happen

00:27:31,360 --> 00:27:34,559
so let's say i have a uh again same

00:27:33,440 --> 00:27:37,360
stream of the example

00:27:34,559 --> 00:27:40,960
with segments from s1 through s7 and i

00:27:37,360 --> 00:27:42,559
have a reader group with two readers

00:27:40,960 --> 00:27:44,399
initially if i'm using the event stream

00:27:42,559 --> 00:27:45,760
api that's also very important the event

00:27:44,399 --> 00:27:46,080
stream api is the one that guarantees

00:27:45,760 --> 00:27:48,080
this

00:27:46,080 --> 00:27:50,000
in a few slides down i will talk about a

00:27:48,080 --> 00:27:50,480
different api data that doesn't preserve

00:27:50,000 --> 00:27:53,840
that

00:27:50,480 --> 00:27:57,120
order um it with the event stream api

00:27:53,840 --> 00:28:00,559
um only segments s1 and s2

00:27:57,120 --> 00:28:03,120
will be enabled for reading so let's say

00:28:00,559 --> 00:28:05,120
that reader a acquires s1 and reader b

00:28:03,120 --> 00:28:05,520
acquires s2 so at that point the readers

00:28:05,120 --> 00:28:08,880
uh

00:28:05,520 --> 00:28:11,520
are free to go and uh and read events

00:28:08,880 --> 00:28:12,720
so now say that that reader a is done

00:28:11,520 --> 00:28:15,600
reading s1

00:28:12,720 --> 00:28:17,840
so now s3 and s4 become enabled for

00:28:15,600 --> 00:28:17,840
reading

00:28:18,000 --> 00:28:22,399
and now let's say that uh soon after

00:28:20,320 --> 00:28:26,880
reader b is also done reading s2

00:28:22,399 --> 00:28:26,880
and now s5 and s6 are available for read

00:28:27,200 --> 00:28:31,360
let's say that uh that the acquisition

00:28:29,760 --> 00:28:34,559
such that reader acquires

00:28:31,360 --> 00:28:35,760
s3 and s6 and reader b acquires s4 and

00:28:34,559 --> 00:28:38,960
s5

00:28:35,760 --> 00:28:41,200
uh one input one this is a this is a

00:28:38,960 --> 00:28:42,480
this is a valid uh assignment but one

00:28:41,200 --> 00:28:45,679
thing that i want to point out

00:28:42,480 --> 00:28:46,240
is that um the the the ranges of routing

00:28:45,679 --> 00:28:48,399
keys

00:28:46,240 --> 00:28:49,520
are now going to to different going to

00:28:48,399 --> 00:28:51,440
different readers

00:28:49,520 --> 00:28:53,360
so this is important to note because the

00:28:51,440 --> 00:28:56,960
application needs to ensure

00:28:53,360 --> 00:28:58,880
that uh that if if it needs to process

00:28:56,960 --> 00:29:00,320
according to routing key order it needs

00:28:58,880 --> 00:29:03,440
to ensure that uh

00:29:00,320 --> 00:29:06,320
that uh it does it performs some steps

00:29:03,440 --> 00:29:06,640
that uh to guarantee correct processing

00:29:06,320 --> 00:29:08,080
so

00:29:06,640 --> 00:29:09,840
there there's a mechanism that i won't

00:29:08,080 --> 00:29:10,799
have i won't be covering here are called

00:29:09,840 --> 00:29:13,279
checkpoints

00:29:10,799 --> 00:29:15,440
that helps the application um achieve

00:29:13,279 --> 00:29:18,880
that goal

00:29:15,440 --> 00:29:19,120
so okay now let's say that readers a and

00:29:18,880 --> 00:29:22,720
b

00:29:19,120 --> 00:29:26,000
are then reading s3 and s4 now s7

00:29:22,720 --> 00:29:29,120
is enabled uh we have reader b acquiring

00:29:26,000 --> 00:29:29,679
it and this is the the final assignment

00:29:29,120 --> 00:29:32,880
for uh

00:29:29,679 --> 00:29:33,679
for the stream as the stream lies uh

00:29:32,880 --> 00:29:36,320
right now

00:29:33,679 --> 00:29:37,200
so of course i'm using a static snapshot

00:29:36,320 --> 00:29:39,679
of a stream

00:29:37,200 --> 00:29:41,600
for the sake of example but it's not the

00:29:39,679 --> 00:29:43,279
case that uh that the writers cannot be

00:29:41,600 --> 00:29:45,679
writing to the application right so

00:29:43,279 --> 00:29:46,720
this is dynamic there could be even um

00:29:45,679 --> 00:29:48,880
um

00:29:46,720 --> 00:29:51,039
we could even have more scale events

00:29:48,880 --> 00:29:55,840
happening as this as um we have

00:29:51,039 --> 00:29:55,840
writers writing and readers reading

00:29:57,120 --> 00:30:00,799
a different way of reading from the same

00:29:58,640 --> 00:30:03,520
stream is to use the batch api

00:30:00,799 --> 00:30:04,000
so with the batch api we forget about

00:30:03,520 --> 00:30:06,240
order

00:30:04,000 --> 00:30:07,679
and we just give iterators for all

00:30:06,240 --> 00:30:10,399
available segments at a time

00:30:07,679 --> 00:30:12,240
so the application can have um different

00:30:10,399 --> 00:30:14,640
processes just reading from all those

00:30:12,240 --> 00:30:15,600
segments in parallel so different from

00:30:14,640 --> 00:30:18,399
the events

00:30:15,600 --> 00:30:20,159
um from the event api there's no notion

00:30:18,399 --> 00:30:22,159
of continuous reading here so the radius

00:30:20,159 --> 00:30:24,720
bounding is bounded and

00:30:22,159 --> 00:30:25,760
uh and the day traders will go up to uh

00:30:24,720 --> 00:30:27,279
up to that bound

00:30:25,760 --> 00:30:29,120
but they cannot read in parallel from

00:30:27,279 --> 00:30:31,360
the segments and uh

00:30:29,120 --> 00:30:33,120
and again we do not necessarily preserve

00:30:31,360 --> 00:30:34,799
order and this is useful if

00:30:33,120 --> 00:30:36,320
the application doesn't care about order

00:30:34,799 --> 00:30:39,200
if you're trying to perform some

00:30:36,320 --> 00:30:43,520
global counts or just grab over uh all

00:30:39,200 --> 00:30:43,520
events in a in a in a stream for example

00:30:44,320 --> 00:30:47,600
one place where this could be useful is

00:30:46,320 --> 00:30:50,399
if you're familiar with

00:30:47,600 --> 00:30:51,200
presto sql which is a sql engine and

00:30:50,399 --> 00:30:54,480
enables

00:30:51,200 --> 00:30:57,519
um systems to implement connectors

00:30:54,480 --> 00:31:00,960
and process query sql queries

00:30:57,519 --> 00:31:02,480
over external storage systems um so if

00:31:00,960 --> 00:31:04,799
you're familiar with that system

00:31:02,480 --> 00:31:06,399
um we have uh we have actually

00:31:04,799 --> 00:31:09,200
implemented a prototype

00:31:06,399 --> 00:31:11,279
where we we read and process data from a

00:31:09,200 --> 00:31:14,720
prevegan stream

00:31:11,279 --> 00:31:15,120
and uh and we assign the splits which is

00:31:14,720 --> 00:31:18,240
the

00:31:15,120 --> 00:31:21,360
the units of work that uh

00:31:18,240 --> 00:31:22,480
in in um for a connector in presto and

00:31:21,360 --> 00:31:24,399
we map those

00:31:22,480 --> 00:31:26,000
to the segments of a of a stream so

00:31:24,399 --> 00:31:28,240
essentially use the batch api

00:31:26,000 --> 00:31:29,360
to match segments to split which is a

00:31:28,240 --> 00:31:31,200
very natural

00:31:29,360 --> 00:31:32,720
uh match for the kind of processing that

00:31:31,200 --> 00:31:34,159
process sticker does for you

00:31:32,720 --> 00:31:36,000
and one of the interesting things of

00:31:34,159 --> 00:31:37,039
this example which is a sort of a site

00:31:36,000 --> 00:31:39,679
observation is that

00:31:37,039 --> 00:31:40,640
we can even do joins of stream data with

00:31:39,679 --> 00:31:43,840
other things like

00:31:40,640 --> 00:31:44,799
object store data and once we have such

00:31:43,840 --> 00:31:47,279
splits we can

00:31:44,799 --> 00:31:49,279
we cannot give it to pressure tasks and

00:31:47,279 --> 00:31:52,320
have it execute as part of a

00:31:49,279 --> 00:31:52,320
of a sql query

00:31:54,480 --> 00:31:58,640
all right so let me say a few words

00:31:56,320 --> 00:32:02,080
about other abstractions we have built

00:31:58,640 --> 00:32:03,679
on on segments um

00:32:02,080 --> 00:32:04,960
which are not streams i talked a lot

00:32:03,679 --> 00:32:05,600
about streams they are the things we

00:32:04,960 --> 00:32:07,519
have done

00:32:05,600 --> 00:32:09,840
so we have the state synchronizer the

00:32:07,519 --> 00:32:13,039
state synchronizer enables applications

00:32:09,840 --> 00:32:15,840
to uh replicate states and it

00:32:13,039 --> 00:32:17,120
uses as an underlying construct what we

00:32:15,840 --> 00:32:18,559
call revision stream

00:32:17,120 --> 00:32:20,960
which is which is a single segment

00:32:18,559 --> 00:32:23,840
stream which accepts conditional appends

00:32:20,960 --> 00:32:25,440
the condition is on is on the offset the

00:32:23,840 --> 00:32:28,159
state synchronizer manages

00:32:25,440 --> 00:32:30,000
uh generic states that the state is

00:32:28,159 --> 00:32:30,720
defined by the application so we provide

00:32:30,000 --> 00:32:33,039
interfaces

00:32:30,720 --> 00:32:35,039
so that the application can do it and

00:32:33,039 --> 00:32:36,720
the synchronizer takes care of uh

00:32:35,039 --> 00:32:38,640
fetching updates updating the state

00:32:36,720 --> 00:32:40,159
updating conditionally compacting the

00:32:38,640 --> 00:32:42,320
state so that's the api

00:32:40,159 --> 00:32:44,000
it offers and uh and allows the

00:32:42,320 --> 00:32:46,320
application to do that kind of uh

00:32:44,000 --> 00:32:47,039
that kind of synchronization and it can

00:32:46,320 --> 00:32:49,519
do things

00:32:47,039 --> 00:32:50,080
like other systems um zookeeper for

00:32:49,519 --> 00:32:51,840
example

00:32:50,080 --> 00:32:54,320
have done for us in the past like leader

00:32:51,840 --> 00:32:56,960
election membership

00:32:54,320 --> 00:32:58,320
and even uh in in our own case in the

00:32:56,960 --> 00:33:01,600
case of prevega

00:32:58,320 --> 00:33:03,519
manage um the reader group states so we

00:33:01,600 --> 00:33:04,799
also we not only expose that as part of

00:33:03,519 --> 00:33:07,519
the api but we

00:33:04,799 --> 00:33:10,640
use it internally as part of the reader

00:33:07,519 --> 00:33:12,880
group coordination

00:33:10,640 --> 00:33:14,799
another one that i have that we have

00:33:12,880 --> 00:33:17,760
implemented is a key value table

00:33:14,799 --> 00:33:19,919
so we have as part of the api the usual

00:33:17,760 --> 00:33:22,960
suspects like gets put remove and

00:33:19,919 --> 00:33:23,519
iteration over over a table key value

00:33:22,960 --> 00:33:25,919
tables

00:33:23,519 --> 00:33:27,440
are implemented with table segments i

00:33:25,919 --> 00:33:27,919
mentioned table segments when i talked

00:33:27,440 --> 00:33:30,559
about

00:33:27,919 --> 00:33:31,519
stream metadata and table segments are

00:33:30,559 --> 00:33:34,720
again backed by

00:33:31,519 --> 00:33:36,559
uh by by segments so when we defined

00:33:34,720 --> 00:33:38,320
a key value table we determine the

00:33:36,559 --> 00:33:39,760
number of partitions we want for that

00:33:38,320 --> 00:33:41,679
table

00:33:39,760 --> 00:33:45,840
and uh and each one of those partitions

00:33:41,679 --> 00:33:45,840
again will be a table segment

00:33:46,320 --> 00:33:51,200
all right so the last part of the

00:33:47,600 --> 00:33:53,919
presentation is about performance

00:33:51,200 --> 00:33:56,320
so we have conducted uh an extensive

00:33:53,919 --> 00:33:59,840
amount of valuation on the latest

00:33:56,320 --> 00:34:01,519
uh release of provega prevega08

00:33:59,840 --> 00:34:03,039
and i want to show a few of the graphs

00:34:01,519 --> 00:34:05,440
that we have we

00:34:03,039 --> 00:34:07,360
are having we are publishing a blog post

00:34:05,440 --> 00:34:10,560
about it with a lot more detail

00:34:07,360 --> 00:34:13,119
in uh in the next few days so

00:34:10,560 --> 00:34:14,480
stay tuned for that uh so that will give

00:34:13,119 --> 00:34:15,200
a lot more detail that i'm showing here

00:34:14,480 --> 00:34:17,679
so here

00:34:15,200 --> 00:34:19,359
i'm starting with a graph that shows p95

00:34:17,679 --> 00:34:22,720
right latency and

00:34:19,359 --> 00:34:26,480
and events per second so on the

00:34:22,720 --> 00:34:29,599
on the x-axis on both x's we i have

00:34:26,480 --> 00:34:31,760
i have a log scale so bear that in mind

00:34:29,599 --> 00:34:32,960
but one thing the two important messages

00:34:31,760 --> 00:34:36,000
that i want to take from this

00:34:32,960 --> 00:34:36,639
is that um we are achieving over 1

00:34:36,000 --> 00:34:38,879
million

00:34:36,639 --> 00:34:40,399
messages per second with latency under

00:34:38,879 --> 00:34:43,040
10 milliseconds

00:34:40,399 --> 00:34:43,679
and we're doing this for two types of of

00:34:43,040 --> 00:34:46,000
experiments

00:34:43,679 --> 00:34:47,919
one in which i have one segment in a

00:34:46,000 --> 00:34:48,560
string and another that i have a 16

00:34:47,919 --> 00:34:51,200
segments

00:34:48,560 --> 00:34:51,599
so this is one rider and the event size

00:34:51,200 --> 00:34:54,560
of a

00:34:51,599 --> 00:34:54,560
of 100 bytes

00:34:55,440 --> 00:34:59,200
so the situation is not very different

00:34:57,440 --> 00:35:01,920
from entrant latency we can obtain

00:34:59,200 --> 00:35:04,320
high throughput and low latency also

00:35:01,920 --> 00:35:07,359
when looking at end to end

00:35:04,320 --> 00:35:09,200
uh well look at it end trends uh

00:35:07,359 --> 00:35:10,560
it's it's a bit different for detail for

00:35:09,200 --> 00:35:11,920
very high throughputs there's a bit of

00:35:10,560 --> 00:35:13,200
an imbalance between reading

00:35:11,920 --> 00:35:15,280
and in writing and this is something

00:35:13,200 --> 00:35:17,920
that we are currently looking to

00:35:15,280 --> 00:35:19,040
but we are still able to obtain very

00:35:17,920 --> 00:35:22,079
high throughput and uh

00:35:19,040 --> 00:35:22,800
and low latency when um when looking at

00:35:22,079 --> 00:35:26,640
entrance

00:35:22,800 --> 00:35:26,640
um at the end joint path

00:35:28,240 --> 00:35:31,359
another interesting experiment we have

00:35:30,160 --> 00:35:34,880
done is given that

00:35:31,359 --> 00:35:38,000
it's going to prevega um um

00:35:34,880 --> 00:35:40,560
to it's going to prevega to

00:35:38,000 --> 00:35:41,040
process historical data and uh and catch

00:35:40,560 --> 00:35:42,640
up

00:35:41,040 --> 00:35:44,960
we performed an experiment in which we

00:35:42,640 --> 00:35:46,079
have a writer continuously producing 100

00:35:44,960 --> 00:35:49,520
megabytes

00:35:46,079 --> 00:35:52,400
per second and we

00:35:49,520 --> 00:35:55,040
keep readers asleep until we have

00:35:52,400 --> 00:35:56,960
accumulated 100 gigabytes of data

00:35:55,040 --> 00:35:58,320
so at that point we await the readers

00:35:56,960 --> 00:35:59,040
and see if they can catch up with the

00:35:58,320 --> 00:36:01,520
writer

00:35:59,040 --> 00:36:02,880
and the writer keeps writing right so it

00:36:01,520 --> 00:36:05,040
doesn't stop when we

00:36:02,880 --> 00:36:05,920
wake up the readers and we can see that

00:36:05,040 --> 00:36:07,520
aprivega is

00:36:05,920 --> 00:36:10,640
able to provide enough performance that

00:36:07,520 --> 00:36:12,079
the readers can can catch up

00:36:10,640 --> 00:36:14,800
so again very important because

00:36:12,079 --> 00:36:16,640
historical data is very uh is key to our

00:36:14,800 --> 00:36:18,000
very core to uh the features and the

00:36:16,640 --> 00:36:21,119
kind of properties that we want to

00:36:18,000 --> 00:36:21,119
provide to applications

00:36:23,440 --> 00:36:26,880
all right so that's all i wanted to say

00:36:25,040 --> 00:36:27,520
about provega so let me i'm ready to

00:36:26,880 --> 00:36:29,839
wrap up

00:36:27,520 --> 00:36:30,720
um the state of provega preveg is not an

00:36:29,839 --> 00:36:32,880
apache project

00:36:30,720 --> 00:36:34,720
it does use apache projects like apache

00:36:32,880 --> 00:36:37,920
zookeeper and apache boot keeper

00:36:34,720 --> 00:36:40,000
our latest release is zero h0 um

00:36:37,920 --> 00:36:41,520
some of the highlights of the release is

00:36:40,000 --> 00:36:42,320
the the implementation of key value

00:36:41,520 --> 00:36:44,560
tables

00:36:42,320 --> 00:36:46,320
the performance improvements and uh the

00:36:44,560 --> 00:36:47,119
schema registry implementation and

00:36:46,320 --> 00:36:48,720
integration

00:36:47,119 --> 00:36:51,200
which is not really part of project

00:36:48,720 --> 00:36:54,640
itself it's a separate repository

00:36:51,200 --> 00:36:58,640
and uh and uh but we if we are releasing

00:36:54,640 --> 00:36:58,640
alongside with a vega 080

00:36:59,280 --> 00:37:03,520
now to conclude um the vision we have

00:37:02,560 --> 00:37:07,040
set ourselves

00:37:03,520 --> 00:37:07,520
is to implement um is to provide the

00:37:07,040 --> 00:37:09,520
stream

00:37:07,520 --> 00:37:11,200
as a core storage primitive and

00:37:09,520 --> 00:37:13,920
implement a system that achieves

00:37:11,200 --> 00:37:14,960
that vision so as part of that system we

00:37:13,920 --> 00:37:17,839
wanted to provide

00:37:14,960 --> 00:37:18,400
both um both the ability of taking a

00:37:17,839 --> 00:37:20,839
stream

00:37:18,400 --> 00:37:22,160
and starting is processing data

00:37:20,839 --> 00:37:23,920
historically

00:37:22,160 --> 00:37:26,240
it's built on the on the on this

00:37:23,920 --> 00:37:27,760
construct that we call stream segments

00:37:26,240 --> 00:37:29,359
which is very important to enable a

00:37:27,760 --> 00:37:32,720
number of features that i described

00:37:29,359 --> 00:37:34,000
and it's open source um some of the core

00:37:32,720 --> 00:37:36,880
features that i mentioned are stream

00:37:34,000 --> 00:37:39,359
scaling transaction order breeds

00:37:36,880 --> 00:37:41,040
as for the architecture two important

00:37:39,359 --> 00:37:42,960
points i want to highlight is that we

00:37:41,040 --> 00:37:44,000
separate ios in the critical paths of

00:37:42,960 --> 00:37:46,960
reads and writes

00:37:44,000 --> 00:37:47,520
and we make the stream data stable by

00:37:46,960 --> 00:37:50,640
using

00:37:47,520 --> 00:37:52,720
um by using table segments

00:37:50,640 --> 00:37:53,760
as for performance again stay tuned for

00:37:52,720 --> 00:37:55,440
our post

00:37:53,760 --> 00:37:56,800
uh a few highlights of the numbers i

00:37:55,440 --> 00:37:58,000
have shown is that we're able to achieve

00:37:56,800 --> 00:38:01,200
over one million

00:37:58,000 --> 00:38:03,200
um small events per second uh when when

00:38:01,200 --> 00:38:05,119
writing and single digit millisecond

00:38:03,200 --> 00:38:06,880
latency and trends

00:38:05,119 --> 00:38:08,240
i also talked about experiment in which

00:38:06,880 --> 00:38:10,960
we do catch up

00:38:08,240 --> 00:38:12,800
over a backlog of 100 gigabytes while

00:38:10,960 --> 00:38:14,400
ingesting 100 megabytes per second and

00:38:12,800 --> 00:38:16,320
provigo successfully

00:38:14,400 --> 00:38:19,040
uh provided the performance so that

00:38:16,320 --> 00:38:20,320
readers could catch up

00:38:19,040 --> 00:38:21,839
so i'm not sure i have time for

00:38:20,320 --> 00:38:22,480
questions but i won't provide a few

00:38:21,839 --> 00:38:25,119
links

00:38:22,480 --> 00:38:27,119
uh some references about myself email

00:38:25,119 --> 00:38:29,520
twitter linkedin and so on

00:38:27,119 --> 00:38:30,640
uh and then a bunch of websites so the

00:38:29,520 --> 00:38:33,359
provega website

00:38:30,640 --> 00:38:35,359
our blog that encourage everyone to pay

00:38:33,359 --> 00:38:47,839
attention to github and

00:38:35,359 --> 00:38:47,839
our slack all right thank you

00:38:49,839 --> 00:38:53,760
i'm not sure i'm not sure i'm allowed to

00:38:52,160 --> 00:38:54,720
stay around to answer some of these

00:38:53,760 --> 00:38:57,599
questions

00:38:54,720 --> 00:39:01,839
um i'm more than happy to discuss them

00:38:57,599 --> 00:39:01,839
uh them offline

00:39:13,119 --> 00:39:16,480
okay so let's see let's let's try to

00:39:14,800 --> 00:39:19,520
handle um let's see if i can answer some

00:39:16,480 --> 00:39:22,240
of them if people are still around

00:39:19,520 --> 00:39:23,359
um how do you handle situation when

00:39:22,240 --> 00:39:26,480
bookkeeper store

00:39:23,359 --> 00:39:29,760
is out of capacity since lts uh is

00:39:26,480 --> 00:39:31,680
is um is is lower

00:39:29,760 --> 00:39:32,880
yeah so we we do assume that we have

00:39:31,680 --> 00:39:35,040
enough capacity in

00:39:32,880 --> 00:39:35,920
in the durable log because if we cannot

00:39:35,040 --> 00:39:37,680
if we cannot

00:39:35,920 --> 00:39:38,960
append to the durable log then we we

00:39:37,680 --> 00:39:41,760
have to start the pipeline

00:39:38,960 --> 00:39:45,359
we guarantee durability and and so that

00:39:41,760 --> 00:39:45,359
definitely needs that needs to happen

00:39:45,440 --> 00:39:49,760
um how low level does pravega go for

00:39:48,160 --> 00:39:52,079
optimizing read write at the harder

00:39:49,760 --> 00:39:53,839
level for example does this type http

00:39:52,079 --> 00:39:55,359
versus solid make a difference

00:39:53,839 --> 00:39:57,599
uh well of course it makes a difference

00:39:55,359 --> 00:40:00,880
so if you got faster drives

00:39:57,599 --> 00:40:03,520
it will it will be faster but we do uh

00:40:00,880 --> 00:40:04,720
we do tune the pipeline so that we

00:40:03,520 --> 00:40:07,920
accommodate

00:40:04,720 --> 00:40:10,800
the different um the different speeds of

00:40:07,920 --> 00:40:12,000
of the storage that we're using right so

00:40:10,800 --> 00:40:14,079
so for example if the

00:40:12,000 --> 00:40:15,280
lts is lower we will apply back pressure

00:40:14,079 --> 00:40:17,520
and make sure that uh

00:40:15,280 --> 00:40:18,480
that we are not uh we're not appending

00:40:17,520 --> 00:40:21,440
faster than we can

00:40:18,480 --> 00:40:21,440
then we can accommodate

00:40:22,160 --> 00:40:26,079
um next question is prove a topic engine

00:40:24,560 --> 00:40:28,079
with published subscriber clients

00:40:26,079 --> 00:40:29,359
or should i use another framework to

00:40:28,079 --> 00:40:31,680
read writing provega

00:40:29,359 --> 00:40:33,040
if so what can we use to rewrite it yeah

00:40:31,680 --> 00:40:35,280
so um

00:40:33,040 --> 00:40:36,560
you have the stream abstraction and uh

00:40:35,280 --> 00:40:38,400
you create a stream

00:40:36,560 --> 00:40:39,599
and and you appreciate then you read

00:40:38,400 --> 00:40:42,000
from it

00:40:39,599 --> 00:40:43,200
right so it has um we do use the

00:40:42,000 --> 00:40:45,040
terminology that scrolls that you

00:40:43,200 --> 00:40:47,359
storage reads and writes

00:40:45,040 --> 00:40:51,119
but uh but certainly you can use that in

00:40:47,359 --> 00:40:51,119
a pub in a public subscriber man

00:40:51,280 --> 00:40:55,680
so i don't need to go elsewhere um is

00:40:54,079 --> 00:40:56,480
the stream message exactly once or at

00:40:55,680 --> 00:40:58,319
least once

00:40:56,480 --> 00:40:59,680
if exactly one is how how to achieve

00:40:58,319 --> 00:41:03,440
that so we

00:40:59,680 --> 00:41:05,760
provide both transactions and we provide

00:41:03,440 --> 00:41:07,200
um uh summation this will provide a

00:41:05,760 --> 00:41:08,560
mechanism to track the position of

00:41:07,200 --> 00:41:09,839
writers so that in the presence of

00:41:08,560 --> 00:41:12,560
disconnections

00:41:09,839 --> 00:41:13,520
we uh we guarantee that we are not

00:41:12,560 --> 00:41:16,079
duplicating or

00:41:13,520 --> 00:41:17,440
or missing data i have actually given up

00:41:16,079 --> 00:41:20,560
a couple of thoughts

00:41:17,440 --> 00:41:22,880
um specifically about that so

00:41:20,560 --> 00:41:24,640
we can either discuss offline or we can

00:41:22,880 --> 00:41:26,960
perhaps check some of my uh my previous

00:41:24,640 --> 00:41:26,960
talks

00:41:27,520 --> 00:41:31,440
um next question where can i find more

00:41:29,520 --> 00:41:33,599
information about elasticity

00:41:31,440 --> 00:41:34,560
also can you share the slides yeah so

00:41:33,599 --> 00:41:37,280
certainly

00:41:34,560 --> 00:41:39,839
uh i can share these slides uh about

00:41:37,280 --> 00:41:41,119
elasticity on provega i mean we have a

00:41:39,839 --> 00:41:42,720
number of uh i don't know

00:41:41,119 --> 00:41:45,200
we have blog posts to talk about it we

00:41:42,720 --> 00:41:47,680
have documentation on the websites

00:41:45,200 --> 00:41:49,440
uh there are javadocs you know there is

00:41:47,680 --> 00:41:52,160
lack you can interact with us

00:41:49,440 --> 00:41:52,960
and ask questions that if you have any

00:41:52,160 --> 00:41:54,800
so

00:41:52,960 --> 00:41:58,319
go to all those references interact with

00:41:54,800 --> 00:41:58,319
us and we will answer your questions

00:42:01,359 --> 00:42:04,880
what features are looking forward uh the

00:42:03,680 --> 00:42:08,960
most in the

00:42:04,880 --> 00:42:11,440
in the in the future of of provega

00:42:08,960 --> 00:42:13,680
thank you um what features are looking

00:42:11,440 --> 00:42:17,200
forward to the most in the future of uh

00:42:13,680 --> 00:42:17,599
of of provega so we we have been working

00:42:17,200 --> 00:42:19,520
on a

00:42:17,599 --> 00:42:20,880
on a number of uh on a number of things

00:42:19,520 --> 00:42:22,400
one of the features that we have added

00:42:20,880 --> 00:42:26,240
and i didn't mention

00:42:22,400 --> 00:42:28,240
is a simplification of uh of um

00:42:26,240 --> 00:42:30,079
of youtube so that we can accommodate

00:42:28,240 --> 00:42:32,560
more storage bindings for

00:42:30,079 --> 00:42:33,440
for long-term storage so that's one

00:42:32,560 --> 00:42:35,440
thing we're working on

00:42:33,440 --> 00:42:37,680
another thing is different client

00:42:35,440 --> 00:42:39,520
bindings so i didn't mention this but uh

00:42:37,680 --> 00:42:40,720
but um our client right now is we only

00:42:39,520 --> 00:42:42,319
have a java client

00:42:40,720 --> 00:42:44,160
but as we speak we're working on the

00:42:42,319 --> 00:42:44,560
appliance bindings and so we'll have

00:42:44,160 --> 00:42:47,119
more

00:42:44,560 --> 00:42:48,400
more languages that i can you can use so

00:42:47,119 --> 00:42:51,520
we we're looking forward

00:42:48,400 --> 00:42:53,920
to a more polyglot provega in the near

00:42:51,520 --> 00:42:53,920
future

00:42:55,680 --> 00:42:59,520
all right so i think i have quickly

00:42:57,359 --> 00:43:02,160
covered all the other questions

00:42:59,520 --> 00:43:03,359
um if you have more questions again feel

00:43:02,160 --> 00:43:06,720
free to reach out to

00:43:03,359 --> 00:43:08,319
to me on slack to the team

00:43:06,720 --> 00:43:10,480
check the websites that has a lot of

00:43:08,319 --> 00:43:11,599
information and uh thank you again for

00:43:10,480 --> 00:43:27,839
your attention

00:43:11,599 --> 00:43:27,839
stay safe everyone thank you

00:44:01,760 --> 00:44:03,839

YouTube URL: https://www.youtube.com/watch?v=FFC0X2Tgh-4


