Title: Real-Time Stock Processing With Apache NiFi, Apache Flink and Apache Kafka
Publication date: 2020-10-22
Playlist: ApacheCon @Home 2020: Streaming
Description: 
	Real-Time Stock Processing With Apache NiFi, Apache Flink and Apache Kafka
Pierre Villard, Timothy Spann

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

We will ingest a variety of real-time feeds including stocks with NiFi, filter and process and segment it into Kafka topics. Kafka data will be in Apache Avro format with schemas specified in Cloudera Schema Registry. Apache Flink, Kafka Connect and NiFi will do additional event processing along with machine learning and deep learning. We will store real-time feed data in Apache Kudu for real-time analytics and summaries. Apache OpenNLP, Apache MXNet, CoreNLP, NLTK and SpaCy will be used to analyse stock trend data in streams as well as stock prices and futures. As part of the stream processing we will also be classifying images and stock data with Apache MXNet and DJL. We will also produce cleaned and aggregated data to subscribers via Apache Kafka, Apache Flink SQL and Apache NiFi. We will push to applications, message listeners, web clients, Slack channels and to email, To be useful in our enterprise, we will have full authorization, authentication, auditing, data encryption and data lineage via Apache Ranger, Apache Atlas and Apache NiFi. References: https://community.cloudera.com/t5/Community-Articles/Real-Time-Stock-Processing-With-Apache-NiFi-and-Apache-Kafka/ta-p/249221

Pierre Villard is currently a Senior Product Manager at Cloudera in charge of all the products around Apache NiFi and its subprojects like the NiFi Registry, MiNiFi agents, etc.. He has been active in the Apache NiFi project for the last 4.5 years and is a committer and PMC member of the project. Before joining Cloudera, Pierre worked at Google and Hortonworks where he helped customers develop solutions on-premises and in the cloud by using many technologies including Apache NiFi.
Tim Spann is a Principal DataFlow Field Engineer at Cloudera, the Big Data Zone leader and blogger at DZone and an experienced data engineer with 15 years of experience. He runs the Future of Data Princeton meetup as well as other events. He has spoken at Philly Open SOurce, ApacheCon in Montreal, Strata NYC, Oracle Code NYC, IoT Fusion in Philly, meetups in Princeton, NYC, Philly, Berlin and Prague, DataWorks Summits in San Jose, Berlin and Sydney.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,480 --> 00:00:30,880
oh i guess we're ready to start

00:00:27,199 --> 00:00:33,200
welcome to apachecon if you joined us in

00:00:30,880 --> 00:00:35,200
the other two sessions

00:00:33,200 --> 00:00:36,320
you probably know who i am uh this is

00:00:35,200 --> 00:00:38,559
real-time stock

00:00:36,320 --> 00:00:39,760
processing with apache 95 flink and

00:00:38,559 --> 00:00:43,200
kafka

00:00:39,760 --> 00:00:46,800
got myself and pierre here and he will

00:00:43,200 --> 00:00:49,920
introduce himself when we get there

00:00:46,800 --> 00:00:52,239
who am i tim spam i'm a principal

00:00:49,920 --> 00:00:54,000
dataflow field engineer

00:00:52,239 --> 00:00:55,760
i run a meetup which is running to

00:00:54,000 --> 00:00:57,520
tonight virtually

00:00:55,760 --> 00:00:59,600
so if you're interested in this sort of

00:00:57,520 --> 00:01:02,079
stuff we'll be uh

00:00:59,600 --> 00:01:02,719
doing some fun uh talks there have an

00:01:02,079 --> 00:01:06,080
open

00:01:02,719 --> 00:01:08,960
forum join talk

00:01:06,080 --> 00:01:09,360
uh that's about it yeah over to you here

00:01:08,960 --> 00:01:12,000
um

00:01:09,360 --> 00:01:13,840
so i'm kia villa i'm the product manager

00:01:12,000 --> 00:01:16,880
at cloudera in charge of uh

00:01:13,840 --> 00:01:19,439
everything around apache 95 basically to

00:01:16,880 --> 00:01:20,240
uh all of our products around nifi knife

00:01:19,439 --> 00:01:23,439
registry

00:01:20,240 --> 00:01:24,799
uh minifi agents uh all of our story

00:01:23,439 --> 00:01:28,240
around edge management so

00:01:24,799 --> 00:01:32,240
when it comes to nifi uh that's

00:01:28,240 --> 00:01:34,640
uh something i'm usually aware of um

00:01:32,240 --> 00:01:35,600
i've been involved in the apache nifi

00:01:34,640 --> 00:01:39,200
project uh

00:01:35,600 --> 00:01:42,479
since 2015. i'm a committer

00:01:39,200 --> 00:01:44,479
and pmc member now uh

00:01:42,479 --> 00:01:46,479
if you are already using nifi you

00:01:44,479 --> 00:01:48,880
probably came across one of my blogs

00:01:46,479 --> 00:01:50,240
uh you have some of my details on the on

00:01:48,880 --> 00:01:52,799
this slide

00:01:50,240 --> 00:01:54,159
uh and before joining clutter i worked

00:01:52,799 --> 00:01:57,439
at google and

00:01:54,159 --> 00:01:57,439
hot on walks for a few years

00:01:59,600 --> 00:02:06,799
so this talk is

00:02:02,640 --> 00:02:09,119
really a very that's a basic use case

00:02:06,799 --> 00:02:10,720
but it's a very good use case to

00:02:09,119 --> 00:02:13,520
demonstrate

00:02:10,720 --> 00:02:14,160
how to deal with a streaming use case

00:02:13,520 --> 00:02:15,760
and use

00:02:14,160 --> 00:02:17,520
a combination of the best apache

00:02:15,760 --> 00:02:19,760
solutions uh

00:02:17,520 --> 00:02:21,040
when you are dealing with a streaming

00:02:19,760 --> 00:02:22,800
use case

00:02:21,040 --> 00:02:24,720
so in this case it's really about

00:02:22,800 --> 00:02:27,920
ingesting real time data

00:02:24,720 --> 00:02:30,400
from many sources uh do some analytics

00:02:27,920 --> 00:02:31,440
have a dashboard on top of it something

00:02:30,400 --> 00:02:34,400
simple but

00:02:31,440 --> 00:02:35,360
which is really something common as soon

00:02:34,400 --> 00:02:38,879
as you have

00:02:35,360 --> 00:02:38,879
a streaming use case

00:02:39,440 --> 00:02:45,760
next slide team yeah thanks so before we

00:02:42,560 --> 00:02:46,480
jump into it uh and i will try to be

00:02:45,760 --> 00:02:48,160
quick so

00:02:46,480 --> 00:02:50,319
uh team can spend a lot of time on the

00:02:48,160 --> 00:02:52,800
demo just a few numbers

00:02:50,319 --> 00:02:54,319
about the main projects uh we are going

00:02:52,800 --> 00:02:57,360
to talk about in this uh

00:02:54,319 --> 00:03:00,480
in this talk so nifi um

00:02:57,360 --> 00:03:04,159
um latest version is 112.1

00:03:00,480 --> 00:03:07,200
uh which has been released today so uh

00:03:04,159 --> 00:03:10,239
i can share with you that knife i 121 is

00:03:07,200 --> 00:03:12,640
out um if you don't know

00:03:10,239 --> 00:03:14,800
about it it's been created and open

00:03:12,640 --> 00:03:18,319
sourced by the nsa

00:03:14,800 --> 00:03:22,000
the initial release in the asf was

00:03:18,319 --> 00:03:23,040
back in 2006 uh it's a very active

00:03:22,000 --> 00:03:26,480
community

00:03:23,040 --> 00:03:29,519
uh over 300 contributors over 1

00:03:26,480 --> 00:03:32,000
200 people in the slack channels

00:03:29,519 --> 00:03:33,599
over 3 million docker pools if you want

00:03:32,000 --> 00:03:34,720
to get unburned running very quickly

00:03:33,599 --> 00:03:37,280
with knife i

00:03:34,720 --> 00:03:38,239
strongly suggest you use docker if you

00:03:37,280 --> 00:03:40,319
want

00:03:38,239 --> 00:03:42,480
a knife i stand alone instance very

00:03:40,319 --> 00:03:44,000
quickly that's the best way to be up and

00:03:42,480 --> 00:03:45,440
running with the lattice version very

00:03:44,000 --> 00:03:48,720
quickly

00:03:45,440 --> 00:03:50,480
as i said uh in the apache nifr project

00:03:48,720 --> 00:03:53,920
we have many sub projects so

00:03:50,480 --> 00:03:57,280
we have nifi uh we have agents

00:03:53,920 --> 00:03:59,439
uh both java and c plus versions we also

00:03:57,280 --> 00:04:01,120
have some other versions for android and

00:03:59,439 --> 00:04:03,680
things like that

00:04:01,120 --> 00:04:05,280
we have the knife registry uh which is

00:04:03,680 --> 00:04:07,680
what we use for

00:04:05,280 --> 00:04:10,000
every everything around ci cd moving

00:04:07,680 --> 00:04:12,879
flows from one environment to another

00:04:10,000 --> 00:04:14,159
um so that's also a very useful

00:04:12,879 --> 00:04:17,359
component

00:04:14,159 --> 00:04:18,079
uh kafka right now we are on the 2.6

00:04:17,359 --> 00:04:19,840
release line

00:04:18,079 --> 00:04:21,280
it's been created and opened sourced by

00:04:19,840 --> 00:04:25,360
linkedin uh it's

00:04:21,280 --> 00:04:29,840
in the uh asf since 2011.

00:04:25,360 --> 00:04:30,479
uh flink uh we are on the 1.11 release

00:04:29,840 --> 00:04:33,840
line

00:04:30,479 --> 00:04:36,880
it's been released in 2011.

00:04:33,840 --> 00:04:39,360
um if i'm not saying anything wrong

00:04:36,880 --> 00:04:40,880
it's been a fork from another project

00:04:39,360 --> 00:04:43,759
which was

00:04:40,880 --> 00:04:45,600
called stratosphere uh it's been created

00:04:43,759 --> 00:04:49,280
by collaboration between uh

00:04:45,600 --> 00:04:51,440
some universities uh in germany um

00:04:49,280 --> 00:04:53,840
this is one of the most active projects

00:04:51,440 --> 00:04:57,520
uh in the apache software foundation

00:04:53,840 --> 00:04:59,520
uh over 700 contributors uh that's

00:04:57,520 --> 00:05:01,280
the second repository by the number of

00:04:59,520 --> 00:05:03,440
commits over last year

00:05:01,280 --> 00:05:05,280
uh and it's the most active project on

00:05:03,440 --> 00:05:07,120
the mailing list so

00:05:05,280 --> 00:05:09,280
very strong community very active

00:05:07,120 --> 00:05:12,160
projects if you are looking for

00:05:09,280 --> 00:05:14,800
a streaming engine that's probably the

00:05:12,160 --> 00:05:14,800
one you want

00:05:16,160 --> 00:05:21,120
so um so obviously

00:05:19,280 --> 00:05:23,120
i have the hoodie i'm going to talk

00:05:21,120 --> 00:05:26,000
mainly about knifi

00:05:23,120 --> 00:05:27,680
what is knife i use for so when i

00:05:26,000 --> 00:05:31,360
introduce nifi to people

00:05:27,680 --> 00:05:34,080
um i usually say that knife

00:05:31,360 --> 00:05:34,560
is uh the perfect gateway to get the

00:05:34,080 --> 00:05:38,880
data

00:05:34,560 --> 00:05:40,400
in so when you have a simple use case

00:05:38,880 --> 00:05:42,720
and you have one source

00:05:40,400 --> 00:05:45,199
for uh the data you need for your use

00:05:42,720 --> 00:05:48,000
case you probably don't want nifi

00:05:45,199 --> 00:05:50,560
but when you have many use cases and use

00:05:48,000 --> 00:05:52,320
cases have many sources

00:05:50,560 --> 00:05:53,759
you probably want a consistent way of

00:05:52,320 --> 00:05:56,080
getting the data in

00:05:53,759 --> 00:05:57,600
where you will do uh further processing

00:05:56,080 --> 00:06:00,240
on top of the data

00:05:57,600 --> 00:06:01,520
um it can be very challenging when you

00:06:00,240 --> 00:06:03,840
have many sources

00:06:01,520 --> 00:06:04,960
a large variety of protocols to deal

00:06:03,840 --> 00:06:08,880
with

00:06:04,960 --> 00:06:12,240
many formats many schemas

00:06:08,880 --> 00:06:13,199
you some some sources are batch oriented

00:06:12,240 --> 00:06:15,919
some sources

00:06:13,199 --> 00:06:16,400
are real time knife i can deal with all

00:06:15,919 --> 00:06:19,680
of this

00:06:16,400 --> 00:06:22,000
so uh usually nifi

00:06:19,680 --> 00:06:22,880
is the perfect tool to get the data in

00:06:22,000 --> 00:06:25,360
and then

00:06:22,880 --> 00:06:26,160
distribute it into many uh destinations

00:06:25,360 --> 00:06:29,520
where you will do

00:06:26,160 --> 00:06:32,639
the actual processing so nifi is really

00:06:29,520 --> 00:06:34,240
like some kind of elt tool for both

00:06:32,639 --> 00:06:36,800
streaming and batch

00:06:34,240 --> 00:06:37,759
um you are extracting the data making

00:06:36,800 --> 00:06:39,919
sure it gets

00:06:37,759 --> 00:06:41,360
uh where you need the data to be and you

00:06:39,919 --> 00:06:44,639
make some

00:06:41,360 --> 00:06:48,800
let's say format conversion schema

00:06:44,639 --> 00:06:51,599
validation things like that

00:06:48,800 --> 00:06:52,319
um so this slide is really about what we

00:06:51,599 --> 00:06:55,520
think

00:06:52,319 --> 00:06:56,720
to be the best uh reference architecture

00:06:55,520 --> 00:07:00,080
when it comes to

00:06:56,720 --> 00:07:02,400
uh streaming use case so

00:07:00,080 --> 00:07:04,080
basically you use nifi to collect the

00:07:02,400 --> 00:07:06,960
data from the edge from

00:07:04,080 --> 00:07:07,360
uh any source you have whatever you you

00:07:06,960 --> 00:07:10,560
have

00:07:07,360 --> 00:07:12,880
uh basically uh nifi or minifi agents

00:07:10,560 --> 00:07:16,639
can be used to collect the data

00:07:12,880 --> 00:07:19,759
um we use apache kafka as a

00:07:16,639 --> 00:07:20,160
let's say a buffer uh to store the data

00:07:19,759 --> 00:07:22,639
when

00:07:20,160 --> 00:07:24,560
uh the sources are streaming oriented as

00:07:22,639 --> 00:07:28,560
i said knife i can deal with both

00:07:24,560 --> 00:07:31,520
streaming and batch oriented sources

00:07:28,560 --> 00:07:32,639
but kafka is really great uh if you need

00:07:31,520 --> 00:07:36,000
a buffering layer

00:07:32,639 --> 00:07:38,639
for streaming data um

00:07:36,000 --> 00:07:39,280
then knife ie use is used to distribute

00:07:38,639 --> 00:07:42,240
the data

00:07:39,280 --> 00:07:44,080
into many destinations obviously when

00:07:42,240 --> 00:07:46,639
this is a pure streaming use case we

00:07:44,080 --> 00:07:48,800
probably want to use kafka once again

00:07:46,639 --> 00:07:49,759
so we send this data that has been

00:07:48,800 --> 00:07:52,960
validated

00:07:49,759 --> 00:07:55,360
uh enriched uh um converted

00:07:52,960 --> 00:07:56,240
from one format to another into kafka

00:07:55,360 --> 00:07:59,440
again

00:07:56,240 --> 00:08:02,080
uh and uh from there we use um

00:07:59,440 --> 00:08:04,240
tools like apache fling to do some real

00:08:02,080 --> 00:08:07,680
streaming processing on top of it

00:08:04,240 --> 00:08:11,520
and then we sorry we use

00:08:07,680 --> 00:08:14,560
uh apache druids or apache kudu as uh

00:08:11,520 --> 00:08:17,280
the destination store where you can run

00:08:14,560 --> 00:08:18,160
analytics uh do some time series run sql

00:08:17,280 --> 00:08:22,000
queries

00:08:18,160 --> 00:08:25,759
uh and things like that so that's really

00:08:22,000 --> 00:08:28,479
a very opinionated uh architecture

00:08:25,759 --> 00:08:31,280
of what we recommend with the best

00:08:28,479 --> 00:08:33,680
apache tools you can find

00:08:31,280 --> 00:08:33,680
today

00:08:35,279 --> 00:08:41,440
so before

00:08:38,560 --> 00:08:42,479
i let team be the star of this talk i

00:08:41,440 --> 00:08:45,839
just want to

00:08:42,479 --> 00:08:47,120
quickly say where uh this is going to be

00:08:45,839 --> 00:08:51,200
running so

00:08:47,120 --> 00:08:54,080
uh in this case uh we are leveraging

00:08:51,200 --> 00:08:54,880
uh cdp uh the cloudera data platform

00:08:54,080 --> 00:08:58,000
which

00:08:54,880 --> 00:09:01,680
gives you the ability to start

00:08:58,000 --> 00:09:04,640
dedicated and individual clusters

00:09:01,680 --> 00:09:07,120
based on specific technologies this is a

00:09:04,640 --> 00:09:09,200
great way to ensure very dedicated

00:09:07,120 --> 00:09:11,440
resources based on your needs

00:09:09,200 --> 00:09:14,640
and your use cases and all of the

00:09:11,440 --> 00:09:18,080
clusters with dedicated technologies

00:09:14,640 --> 00:09:21,600
share a consistent layer

00:09:18,080 --> 00:09:23,040
spanning across cloud providers

00:09:21,600 --> 00:09:26,080
on-premises deployments

00:09:23,040 --> 00:09:28,720
uh deployments uh in the cloud and your

00:09:26,080 --> 00:09:32,000
clusters to ensure consistent policies

00:09:28,720 --> 00:09:34,240
consistent schema management uh data

00:09:32,000 --> 00:09:37,360
governments data line age

00:09:34,240 --> 00:09:38,480
all of this um so that's what team is

00:09:37,360 --> 00:09:41,040
going to be

00:09:38,480 --> 00:09:41,680
uh presenting for for the demo right now

00:09:41,040 --> 00:09:43,200
so

00:09:41,680 --> 00:09:44,800
i will be answering any question you

00:09:43,200 --> 00:09:48,000
have in the chat while

00:09:44,800 --> 00:09:51,839
uh tim is doing the demo tim that's

00:09:48,000 --> 00:09:51,839
for you thanks

00:09:52,880 --> 00:09:59,040
very cool yeah we have i'm running in

00:09:56,000 --> 00:10:02,880
a couple of different environments so

00:09:59,040 --> 00:10:04,959
i have a like you mentioned cdp public

00:10:02,880 --> 00:10:08,560
cloud

00:10:04,959 --> 00:10:11,680
running for this i also have

00:10:08,560 --> 00:10:13,360
uh nifi and minifi running in my

00:10:11,680 --> 00:10:15,200
home office here like you saw on that

00:10:13,360 --> 00:10:18,640
first one this is the edge

00:10:15,200 --> 00:10:20,399
and maybe the my laptop's a gateway

00:10:18,640 --> 00:10:22,079
i mean it is not obviously not a

00:10:20,399 --> 00:10:25,120
production environment in my

00:10:22,079 --> 00:10:28,320
office here and then i also have

00:10:25,120 --> 00:10:32,240
a cloudera cluster

00:10:28,320 --> 00:10:33,760
running a number of open source apache

00:10:32,240 --> 00:10:36,560
projects

00:10:33,760 --> 00:10:37,360
in our uh what we call our private cloud

00:10:36,560 --> 00:10:40,160
base

00:10:37,360 --> 00:10:41,920
which is running on uh also happen to be

00:10:40,160 --> 00:10:45,760
running on aws because

00:10:41,920 --> 00:10:47,760
i i don't no one will let me have a

00:10:45,760 --> 00:10:50,000
server room in my house anymore

00:10:47,760 --> 00:10:51,760
unfortunately i wish i did have a set of

00:10:50,000 --> 00:10:53,760
servers here but

00:10:51,760 --> 00:10:54,959
unfortunately i've been told i can't

00:10:53,760 --> 00:10:57,760
have them

00:10:54,959 --> 00:10:59,440
so they're not here okay this is a

00:10:57,760 --> 00:11:00,000
little bit of what this actually looks

00:10:59,440 --> 00:11:03,120
like

00:11:00,000 --> 00:11:03,680
before we start browsing through all the

00:11:03,120 --> 00:11:07,040
different

00:11:03,680 --> 00:11:10,399
uh infrastructure uh

00:11:07,040 --> 00:11:11,279
i have stock data again this one doesn't

00:11:10,399 --> 00:11:14,399
have

00:11:11,279 --> 00:11:16,079
this is a pretty easy one uh if you saw

00:11:14,399 --> 00:11:18,240
the other sessions there's a lot of

00:11:16,079 --> 00:11:19,600
other sources of data that we could be

00:11:18,240 --> 00:11:23,200
showing

00:11:19,600 --> 00:11:25,680
and maybe it makes sense to combine them

00:11:23,200 --> 00:11:27,120
with the stock data that's really

00:11:25,680 --> 00:11:28,640
depends on your company

00:11:27,120 --> 00:11:30,880
if you are a real company you probably

00:11:28,640 --> 00:11:34,800
have multiple sources of this data

00:11:30,880 --> 00:11:37,360
maybe from paid sources maybe bloomberg

00:11:34,800 --> 00:11:40,800
some other financial feeds maybe from

00:11:37,360 --> 00:11:42,480
your in-house databases maybe from logs

00:11:40,800 --> 00:11:44,640
maybe you're combining that for doing

00:11:42,480 --> 00:11:45,120
your sending your machine learning for

00:11:44,640 --> 00:11:46,560
your

00:11:45,120 --> 00:11:48,160
data scientists maybe they need the

00:11:46,560 --> 00:11:50,079
weather data or

00:11:48,160 --> 00:11:52,720
maybe that's from noaa in the public

00:11:50,079 --> 00:11:53,600
data or maybe that's from a paid service

00:11:52,720 --> 00:11:56,880
that has

00:11:53,600 --> 00:11:58,560
hyper localized weather maybe also you

00:11:56,880 --> 00:12:00,480
have

00:11:58,560 --> 00:12:03,200
you know some sensor readings you're

00:12:00,480 --> 00:12:05,519
pulling off of

00:12:03,200 --> 00:12:06,959
uh devices i don't know what devices

00:12:05,519 --> 00:12:09,920
might help for stock

00:12:06,959 --> 00:12:11,600
if you're monitoring stock maybe this is

00:12:09,920 --> 00:12:14,160
devices from

00:12:11,600 --> 00:12:17,440
some of the companies maybe you have a

00:12:14,160 --> 00:12:21,040
proprietary device you put in

00:12:17,440 --> 00:12:22,880
stores manage it monitors foot traffic

00:12:21,040 --> 00:12:24,480
if their foot traffic goes up maybe you

00:12:22,880 --> 00:12:25,680
use that to figure out if you should

00:12:24,480 --> 00:12:27,040
sell

00:12:25,680 --> 00:12:29,040
you know you could get you could get

00:12:27,040 --> 00:12:31,040
pretty uh

00:12:29,040 --> 00:12:32,320
pretty advanced in some of these ideas

00:12:31,040 --> 00:12:36,079
depending on what

00:12:32,320 --> 00:12:40,240
uh what makes sense for you

00:12:36,079 --> 00:12:44,000
okay let me go into a live demo here

00:12:40,240 --> 00:12:46,720
so we left this so data coming into nifi

00:12:44,000 --> 00:12:47,839
i'm pushing some of it right to kudu

00:12:46,720 --> 00:12:52,399
someone's going through

00:12:47,839 --> 00:12:54,399
kafka i'm doing some dashboards i also

00:12:52,399 --> 00:12:58,000
have live events coming through

00:12:54,399 --> 00:13:00,959
uh flink sequel now ultimately

00:12:58,000 --> 00:13:02,639
probably by the end of the year i'm

00:13:00,959 --> 00:13:04,160
gonna have a better demo

00:13:02,639 --> 00:13:06,160
probably gonna find a couple more

00:13:04,160 --> 00:13:09,120
sources so we could do some

00:13:06,160 --> 00:13:11,519
joins there i have a couple other

00:13:09,120 --> 00:13:13,839
sources of stock data and some

00:13:11,519 --> 00:13:16,320
cryptocurrency try to figure a way to

00:13:13,839 --> 00:13:18,320
marry those two data sources together

00:13:16,320 --> 00:13:21,360
but one thing that i want to add to this

00:13:18,320 --> 00:13:23,600
is you might have seen the druid talks

00:13:21,360 --> 00:13:24,480
apache druid is pretty cool and it's

00:13:23,600 --> 00:13:27,200
very easy for

00:13:24,480 --> 00:13:29,519
it to uh pull data from kafka so i have

00:13:27,200 --> 00:13:33,279
nine if i push my data to kafka

00:13:29,519 --> 00:13:36,000
have druid read it and then i'll have

00:13:33,279 --> 00:13:37,680
dashboards on top of that i'm kind of

00:13:36,000 --> 00:13:39,199
lazy to write my own dashboards i've

00:13:37,680 --> 00:13:42,160
been waiting for

00:13:39,199 --> 00:13:42,639
a uh project to come out for that looks

00:13:42,160 --> 00:13:44,880
like

00:13:42,639 --> 00:13:45,839
cloudera will have one so i'll just use

00:13:44,880 --> 00:13:48,399
that to

00:13:45,839 --> 00:13:50,560
display those live dashboards from druid

00:13:48,399 --> 00:13:52,639
you can also do the same thing

00:13:50,560 --> 00:13:55,199
uh i'll show you a little bit on

00:13:52,639 --> 00:13:57,040
visualizing the data as it's in kudu

00:13:55,199 --> 00:13:59,199
but at some point there'll be a

00:13:57,040 --> 00:14:01,760
connector for that for flink

00:13:59,199 --> 00:14:03,839
and the same for apache hue so i can

00:14:01,760 --> 00:14:04,560
have those real-time queries there and

00:14:03,839 --> 00:14:07,760
not in

00:14:04,560 --> 00:14:08,320
the command line which is not the best

00:14:07,760 --> 00:14:11,680
way

00:14:08,320 --> 00:14:15,040
i could also wrap the flink sql

00:14:11,680 --> 00:14:16,079
in an app or i can write say uh apache

00:14:15,040 --> 00:14:19,440
kafka streams

00:14:16,079 --> 00:14:22,399
app in java and

00:14:19,440 --> 00:14:23,839
maybe push as events come in push it to

00:14:22,399 --> 00:14:26,800
a dashboard

00:14:23,839 --> 00:14:29,279
also probably not approved by pierre i

00:14:26,800 --> 00:14:32,160
like to use nifi as a web server

00:14:29,279 --> 00:14:33,040
to host live web apps so i could push

00:14:32,160 --> 00:14:36,959
out events

00:14:33,040 --> 00:14:38,639
over web sockets to uh a mobile app

00:14:36,959 --> 00:14:40,959
so i don't think anyone approves of

00:14:38,639 --> 00:14:42,320
doing that but that that is a way i

00:14:40,959 --> 00:14:45,120
could visualize that

00:14:42,320 --> 00:14:47,040
i've been toying around with that but i

00:14:45,120 --> 00:14:48,800
don't know that's the best idea

00:14:47,040 --> 00:14:52,320
but let's take a look at what we got

00:14:48,800 --> 00:14:55,600
here so we'll start off

00:14:52,320 --> 00:14:58,480
i have uh one of my uh

00:14:55,600 --> 00:14:58,880
clusters here just want to show you

00:14:58,480 --> 00:15:01,199
there's

00:14:58,880 --> 00:15:03,519
a lot of apache projects running in one

00:15:01,199 --> 00:15:06,959
spot i've got apache atlas

00:15:03,519 --> 00:15:10,160
patchy flank hbase hdfs hive

00:15:06,959 --> 00:15:13,360
you impala kafka kudu if you can

00:15:10,160 --> 00:15:15,760
remember all these apache projects

00:15:13,360 --> 00:15:17,839
i i should send you a sticker to say

00:15:15,760 --> 00:15:20,639
good job that's a lot of projects

00:15:17,839 --> 00:15:22,160
but let's let's get into nine fine i've

00:15:20,639 --> 00:15:26,639
got knife running on

00:15:22,160 --> 00:15:30,000
aws uh one thing i have here is

00:15:26,639 --> 00:15:32,880
i'm invoking a rest api to get

00:15:30,000 --> 00:15:34,639
my stock data back now there's a lot of

00:15:32,880 --> 00:15:36,959
different ways to do that

00:15:34,639 --> 00:15:38,560
which is one of the flexible things with

00:15:36,959 --> 00:15:40,639
uh nifi

00:15:38,560 --> 00:15:41,920
one thing i'd suggest is i'll put it

00:15:40,639 --> 00:15:44,560
post in links

00:15:41,920 --> 00:15:45,360
there's some recent videos on how to do

00:15:44,560 --> 00:15:47,759
nifi

00:15:45,360 --> 00:15:50,399
right there's four of them and from mark

00:15:47,759 --> 00:15:53,040
and we'll we'll share those those are

00:15:50,399 --> 00:15:54,000
really great watches so hopefully you

00:15:53,040 --> 00:15:56,639
show there

00:15:54,000 --> 00:15:57,920
but here i'm just having a schedule here

00:15:56,639 --> 00:15:59,120
every 30 seconds

00:15:57,920 --> 00:16:01,199
because i just want to i don't want to

00:15:59,120 --> 00:16:02,639
call them too much and they tell me i'm

00:16:01,199 --> 00:16:04,480
calling them too much

00:16:02,639 --> 00:16:06,079
i've been banned from a couple of sites

00:16:04,480 --> 00:16:09,199
because knife i can read

00:16:06,079 --> 00:16:12,959
rest calls extremely fast

00:16:09,199 --> 00:16:16,560
so i'm calling i called some sites 10

00:16:12,959 --> 00:16:18,160
25 000 times a second that might be too

00:16:16,560 --> 00:16:22,320
much for them

00:16:18,160 --> 00:16:25,040
so be wary nifi is faster than you

00:16:22,320 --> 00:16:26,320
so here i'm just doing a get call to an

00:16:25,040 --> 00:16:28,000
ipi

00:16:26,320 --> 00:16:30,079
and i'm just going to be pulling back uh

00:16:28,000 --> 00:16:31,600
cloudera stock

00:16:30,079 --> 00:16:33,680
might be better to grab someone else's

00:16:31,600 --> 00:16:37,040
stock but that's the one i'm doing

00:16:33,680 --> 00:16:38,000
as you see here data's starting to pile

00:16:37,040 --> 00:16:40,000
in

00:16:38,000 --> 00:16:41,040
so what i'm going to do is i'm going to

00:16:40,000 --> 00:16:44,560
convert it

00:16:41,040 --> 00:16:48,959
from jason to avro

00:16:44,560 --> 00:16:50,320
from jason to uh cleaner jason and then

00:16:48,959 --> 00:16:52,720
because i want to make sure that it

00:16:50,320 --> 00:16:53,680
follows my schema so i have a schema for

00:16:52,720 --> 00:16:55,440
the stock

00:16:53,680 --> 00:16:57,920
it's got a couple fields i care about

00:16:55,440 --> 00:17:00,560
there's a couple i don't care about

00:16:57,920 --> 00:17:02,639
so i pull those in i do a query here if

00:17:00,560 --> 00:17:03,680
i wanted to do some kind of where clause

00:17:02,639 --> 00:17:06,799
to limit it

00:17:03,680 --> 00:17:10,559
or maybe converge fields

00:17:06,799 --> 00:17:13,360
rename them uh concatenate them put sums

00:17:10,559 --> 00:17:16,000
this is apache calcite so you got a

00:17:13,360 --> 00:17:20,079
pretty rich sequel here

00:17:16,000 --> 00:17:20,079
but what i'm going to do is just uh

00:17:20,400 --> 00:17:24,880
a simple select all but what i'm going

00:17:22,559 --> 00:17:27,360
to do is i'm going to add two fields

00:17:24,880 --> 00:17:28,240
the one full with this particular rest

00:17:27,360 --> 00:17:31,280
api

00:17:28,240 --> 00:17:34,320
there's no key and

00:17:31,280 --> 00:17:36,160
i like keys because if i just push this

00:17:34,320 --> 00:17:38,240
data in there

00:17:36,160 --> 00:17:40,000
uh maybe the time stamp works maybe it

00:17:38,240 --> 00:17:42,400
doesn't i like to have a key

00:17:40,000 --> 00:17:43,200
and i also for some reason they don't

00:17:42,400 --> 00:17:45,120
return back

00:17:43,200 --> 00:17:46,559
the symbol i was looking for so i'm

00:17:45,120 --> 00:17:47,280
going to put the cloudera symbol in

00:17:46,559 --> 00:17:50,960
there

00:17:47,280 --> 00:17:53,919
this is a very nice processor

00:17:50,960 --> 00:17:55,679
uh the update record as you see here

00:17:53,919 --> 00:17:57,679
it's jason coming in

00:17:55,679 --> 00:17:59,440
jason coming out i don't have to do

00:17:57,679 --> 00:18:01,200
anything other than

00:17:59,440 --> 00:18:03,039
you know do a slasher in as many

00:18:01,200 --> 00:18:04,960
properties i want to change in all those

00:18:03,039 --> 00:18:07,600
records at once i could do it

00:18:04,960 --> 00:18:08,480
here i'm just hard coding cloudera and

00:18:07,600 --> 00:18:11,840
this is a

00:18:08,480 --> 00:18:14,640
uh a reserved word

00:18:11,840 --> 00:18:15,919
in uh nifi expressions it gives me back

00:18:14,640 --> 00:18:18,559
the unique id

00:18:15,919 --> 00:18:20,320
which is nice so i have a key there and

00:18:18,559 --> 00:18:21,200
then i'm just going to push that data to

00:18:20,320 --> 00:18:24,400
kafka

00:18:21,200 --> 00:18:25,120
here in our other sessions being a kafka

00:18:24,400 --> 00:18:26,960
producer

00:18:25,120 --> 00:18:28,480
is very trivial especially if you're

00:18:26,960 --> 00:18:32,000
using records

00:18:28,480 --> 00:18:34,880
so i got that jason coming in i got avro

00:18:32,000 --> 00:18:36,240
coming out this is important because

00:18:34,880 --> 00:18:39,280
avro

00:18:36,240 --> 00:18:40,400
is a really apache avro is a nice format

00:18:39,280 --> 00:18:43,600
for working with

00:18:40,400 --> 00:18:47,200
spark apps with flink apps

00:18:43,600 --> 00:18:50,400
kafka connect kafka streams nifi

00:18:47,200 --> 00:18:52,160
shows up in my schema works with the

00:18:50,400 --> 00:18:55,200
schema registry very nicely

00:18:52,160 --> 00:18:56,559
and works i can see it very nicely in my

00:18:55,200 --> 00:18:59,200
monitoring tools

00:18:56,559 --> 00:19:01,280
so that's really nice uh the other

00:18:59,200 --> 00:19:02,640
little secret here is i'm sending that

00:19:01,280 --> 00:19:05,600
schema as a header

00:19:02,640 --> 00:19:06,320
which is a nice feature uh nifi does for

00:19:05,600 --> 00:19:08,000
you

00:19:06,320 --> 00:19:10,080
and i put a client id in there so i

00:19:08,000 --> 00:19:11,520
could track who this is

00:19:10,080 --> 00:19:13,919
uh let me just show you what these

00:19:11,520 --> 00:19:16,080
processors look like real quick

00:19:13,919 --> 00:19:18,160
to show you it's not that complex so i'm

00:19:16,080 --> 00:19:22,000
using the name of the schema

00:19:18,160 --> 00:19:22,960
i look registry and then that'll just do

00:19:22,000 --> 00:19:26,400
that for the

00:19:22,960 --> 00:19:29,520
jason and then for the avra writer

00:19:26,400 --> 00:19:29,919
pretty straightforward now i just pushed

00:19:29,520 --> 00:19:33,039
that

00:19:29,919 --> 00:19:36,080
86 000 records to kafka

00:19:33,039 --> 00:19:38,799
in a few seconds this is running from

00:19:36,080 --> 00:19:40,080
a single node nine-five you know it'd be

00:19:38,799 --> 00:19:42,960
nice if it was uh

00:19:40,080 --> 00:19:43,919
a bigger cluster here but it's you know

00:19:42,960 --> 00:19:48,000
i only got

00:19:43,919 --> 00:19:51,440
one node you know 16 cores

00:19:48,000 --> 00:19:54,080
yeah only uh two gig of ram

00:19:51,440 --> 00:19:55,600
not really that powerful machine but i'm

00:19:54,080 --> 00:19:56,160
pushing through these records pretty

00:19:55,600 --> 00:19:58,400
quick

00:19:56,160 --> 00:19:59,200
so we did that first part i've got that

00:19:58,400 --> 00:20:01,919
source

00:19:59,200 --> 00:20:02,720
this was an event oriented source that

00:20:01,919 --> 00:20:05,200
pulled back

00:20:02,720 --> 00:20:06,640
a bunch of records at once i did a

00:20:05,200 --> 00:20:09,840
little cleanup

00:20:06,640 --> 00:20:11,600
i did some like you mentioned elt

00:20:09,840 --> 00:20:14,000
augmented the data i could have done a

00:20:11,600 --> 00:20:15,760
lookup and that lookup could have been

00:20:14,000 --> 00:20:17,280
against a rest source

00:20:15,760 --> 00:20:19,919
it could have been against the database

00:20:17,280 --> 00:20:22,320
could have been against kudu or hbase

00:20:19,919 --> 00:20:24,720
and i can augment and enrich that data

00:20:22,320 --> 00:20:26,480
as it's coming in in a single step

00:20:24,720 --> 00:20:29,200
and as you see here there's no mention

00:20:26,480 --> 00:20:31,120
of what this data looks like

00:20:29,200 --> 00:20:32,480
so this is you can make this pretty

00:20:31,120 --> 00:20:34,480
reusable

00:20:32,480 --> 00:20:36,320
so i had that schema so i'm using this

00:20:34,480 --> 00:20:39,760
schema i could use a different

00:20:36,320 --> 00:20:40,720
schema i could use a different version

00:20:39,760 --> 00:20:44,000
of the schema

00:20:40,720 --> 00:20:47,039
so if i edited this now and

00:20:44,000 --> 00:20:48,640
added another field or

00:20:47,039 --> 00:20:50,400
you know here i already have everything

00:20:48,640 --> 00:20:51,440
nullable i could just make another

00:20:50,400 --> 00:20:54,400
version

00:20:51,440 --> 00:20:55,200
and now pass in version one and version

00:20:54,400 --> 00:20:57,760
two

00:20:55,200 --> 00:20:58,640
and nifi code doesn't have to change

00:20:57,760 --> 00:21:01,679
it's aware

00:20:58,640 --> 00:21:04,000
of schemas and versions so i pass in

00:21:01,679 --> 00:21:06,240
no version number it'll use the latest

00:21:04,000 --> 00:21:08,240
pass in a version number to use that one

00:21:06,240 --> 00:21:10,080
so you don't have to change your code

00:21:08,240 --> 00:21:12,080
when your data changes

00:21:10,080 --> 00:21:14,480
that's nice because you know you get

00:21:12,080 --> 00:21:16,559
mutable data sources out there

00:21:14,480 --> 00:21:19,440
so the data came in let's see where it

00:21:16,559 --> 00:21:22,400
went i pushed it into kafka

00:21:19,440 --> 00:21:23,039
this is that topic just see making sure

00:21:22,400 --> 00:21:25,760
we have

00:21:23,039 --> 00:21:26,799
decent amount of data coming in here i

00:21:25,760 --> 00:21:29,760
can see at a

00:21:26,799 --> 00:21:30,640
glance here this is who's producing the

00:21:29,760 --> 00:21:33,600
data

00:21:30,640 --> 00:21:34,799
that's my nifi producer there here's

00:21:33,600 --> 00:21:38,000
who's reading it

00:21:34,799 --> 00:21:38,400
i've got uh a kafka connect app and i've

00:21:38,000 --> 00:21:41,760
got

00:21:38,400 --> 00:21:43,120
uh a nifi consumer he might be on

00:21:41,760 --> 00:21:45,919
paula's because he's got

00:21:43,120 --> 00:21:46,400
a lag there but let's take a look at the

00:21:45,919 --> 00:21:49,120
data

00:21:46,400 --> 00:21:50,720
as you see here the keys are strings

00:21:49,120 --> 00:21:52,799
that's at uuid

00:21:50,720 --> 00:21:54,400
you can match them up this is good if

00:21:52,799 --> 00:21:56,000
you're trying to figure out

00:21:54,400 --> 00:21:58,320
if you're tracking down a record or

00:21:56,000 --> 00:21:59,760
someone said i didn't get that record

00:21:58,320 --> 00:22:01,520
that was sent

00:21:59,760 --> 00:22:03,919
you know i'm trying to keep my systems

00:22:01,520 --> 00:22:06,720
in sync something's missing

00:22:03,919 --> 00:22:08,640
makes it easy to find it in here

00:22:06,720 --> 00:22:10,320
whatever partition it is

00:22:08,640 --> 00:22:12,640
you know whatever offset it is you could

00:22:10,320 --> 00:22:15,200
browse here pretty easily

00:22:12,640 --> 00:22:17,840
find what you're looking for so i'm

00:22:15,200 --> 00:22:20,880
looking here i see that

00:22:17,840 --> 00:22:22,480
whoever is consuming this there's a lag

00:22:20,880 --> 00:22:24,080
for the nifi one

00:22:22,480 --> 00:22:26,799
so let's see who is supposed to read

00:22:24,080 --> 00:22:28,480
this data

00:22:26,799 --> 00:22:30,799
this guy's over here supposed to be

00:22:28,480 --> 00:22:33,520
reading it so make sure we're

00:22:30,799 --> 00:22:34,880
he's reading it so we don't get behind

00:22:33,520 --> 00:22:36,480
in our data

00:22:34,880 --> 00:22:38,480
got a couple of options here again we're

00:22:36,480 --> 00:22:41,760
only on one node cluster

00:22:38,480 --> 00:22:44,320
not as cool but we read that avro

00:22:41,760 --> 00:22:45,600
in and here i'm converting it to jason

00:22:44,320 --> 00:22:47,919
to do some things

00:22:45,600 --> 00:22:49,120
there's the name see a couple things

00:22:47,919 --> 00:22:51,440
he's getting that schema

00:22:49,120 --> 00:22:52,640
in he's pulling that data and we could

00:22:51,440 --> 00:22:56,000
take a look and see

00:22:52,640 --> 00:22:56,799
the uh provenance to see what data just

00:22:56,000 --> 00:23:00,159
came in

00:22:56,799 --> 00:23:01,919
that's pretty recent uh a bunch of data

00:23:00,159 --> 00:23:03,440
you could see the timestamp so if you're

00:23:01,919 --> 00:23:05,919
trying to track things down

00:23:03,440 --> 00:23:07,120
what's nice with nifi is i turn on

00:23:05,919 --> 00:23:09,679
developer console

00:23:07,120 --> 00:23:11,440
i could see all the rest calls knife

00:23:09,679 --> 00:23:13,120
does everything with rest

00:23:11,440 --> 00:23:15,760
so it makes it very easy if you want to

00:23:13,120 --> 00:23:17,679
reuse that rest yourself

00:23:15,760 --> 00:23:19,120
so that's a nice feature what i'm doing

00:23:17,679 --> 00:23:21,520
here is

00:23:19,120 --> 00:23:23,200
in two steps i consumed it and i'm

00:23:21,520 --> 00:23:26,080
pushing it to kudu

00:23:23,200 --> 00:23:27,600
the reason why i pushed it to kafka is

00:23:26,080 --> 00:23:29,280
to be that buffer

00:23:27,600 --> 00:23:32,159
so i'm never going to lose the data and

00:23:29,280 --> 00:23:34,960
i can also consume it in multiple places

00:23:32,159 --> 00:23:36,720
one here is nifi to push it to kudu and

00:23:34,960 --> 00:23:38,480
i'll show you some other places that i

00:23:36,720 --> 00:23:40,640
can grab that data

00:23:38,480 --> 00:23:42,159
so that's a simple if you're in the

00:23:40,640 --> 00:23:44,240
session today

00:23:42,159 --> 00:23:45,360
we keep mentioning this one maybe

00:23:44,240 --> 00:23:48,880
tomorrow i'm gonna wear my

00:23:45,360 --> 00:23:50,960
apache kudu shirt this upsert

00:23:48,880 --> 00:23:52,080
is awesome i don't have to care if their

00:23:50,960 --> 00:23:54,880
records already there

00:23:52,080 --> 00:23:55,840
it's they're updated if not inserted

00:23:54,880 --> 00:23:59,039
that makes for

00:23:55,840 --> 00:24:02,080
a very happy time for me i'm very

00:23:59,039 --> 00:24:04,640
very happy to have that feature there uh

00:24:02,080 --> 00:24:06,400
normally that might be on another server

00:24:04,640 --> 00:24:07,919
i don't want to hide this from you it's

00:24:06,400 --> 00:24:11,360
too easy uh

00:24:07,919 --> 00:24:13,200
on the same canvas not very uh

00:24:11,360 --> 00:24:14,480
you know generally that might be on

00:24:13,200 --> 00:24:16,240
another cluster

00:24:14,480 --> 00:24:20,559
is a good way to share data between

00:24:16,240 --> 00:24:20,559
clusters or obviously i could just

00:24:20,640 --> 00:24:24,559
here right straight to kudu and cut out

00:24:23,120 --> 00:24:27,200
that kafka step

00:24:24,559 --> 00:24:29,440
but having that buffer is important it's

00:24:27,200 --> 00:24:30,320
also important for different consumers

00:24:29,440 --> 00:24:33,039
of this

00:24:30,320 --> 00:24:34,880
i was in here showing you what's going

00:24:33,039 --> 00:24:36,880
on with those topics

00:24:34,880 --> 00:24:38,480
but if we look here i've got a another

00:24:36,880 --> 00:24:42,320
app for this

00:24:38,480 --> 00:24:44,960
this is a kafka connect app you see

00:24:42,320 --> 00:24:47,440
it's on that topic and i can drill down

00:24:44,960 --> 00:24:50,720
into that topic if i wanted to

00:24:47,440 --> 00:24:54,400
or i could drill down into this app

00:24:50,720 --> 00:24:56,799
again it's a really simple app this is a

00:24:54,400 --> 00:24:57,840
kafka connect app that reads from that

00:24:56,799 --> 00:25:02,159
topic

00:24:57,840 --> 00:25:04,000
and dumps it into hdfs not very exciting

00:25:02,159 --> 00:25:05,440
and it's just gonna drop it in a

00:25:04,000 --> 00:25:08,320
directory

00:25:05,440 --> 00:25:10,320
and do it as avro you know and that's

00:25:08,320 --> 00:25:11,840
the format we had it as so pretty

00:25:10,320 --> 00:25:14,240
straightforward

00:25:11,840 --> 00:25:17,200
now the other thing we're doing is you

00:25:14,240 --> 00:25:20,320
saw nine fives pushing that to kudu

00:25:17,200 --> 00:25:22,960
let's make sure we're getting that data

00:25:20,320 --> 00:25:24,720
so here's our data we're ordering it

00:25:22,960 --> 00:25:27,120
this is a minute ago

00:25:24,720 --> 00:25:28,000
and we could see my talk is not

00:25:27,120 --> 00:25:31,120
improving our stock

00:25:28,000 --> 00:25:32,960
price so pierre you better answer some

00:25:31,120 --> 00:25:36,400
questions so we can get this up to like

00:25:32,960 --> 00:25:38,159
12 or something uh but yeah so you can

00:25:36,400 --> 00:25:41,679
see how easy it is to query

00:25:38,159 --> 00:25:44,320
this is apache hue a really nice tool

00:25:41,679 --> 00:25:44,799
for doing queries what i like about this

00:25:44,320 --> 00:25:48,960
one

00:25:44,799 --> 00:25:51,279
is it's got that uh

00:25:48,960 --> 00:25:52,880
smart technology in here so you know you

00:25:51,279 --> 00:25:54,240
don't have to remember the names of all

00:25:52,880 --> 00:25:56,159
the fields

00:25:54,240 --> 00:25:58,159
you know i start typing it it gets it

00:25:56,159 --> 00:25:59,919
for me that's really helpful

00:25:58,159 --> 00:26:01,279
because i don't always remember what i'm

00:25:59,919 --> 00:26:04,000
doing it's also

00:26:01,279 --> 00:26:05,039
smart enough to know that usually that

00:26:04,000 --> 00:26:08,400
something has to be

00:26:05,039 --> 00:26:10,320
quoted because it's a reserved word

00:26:08,400 --> 00:26:11,840
and if you do it without that things are

00:26:10,320 --> 00:26:14,080
not gonna be happy

00:26:11,840 --> 00:26:16,000
see those funky chicks there that's the

00:26:14,080 --> 00:26:17,520
reserved word

00:26:16,000 --> 00:26:19,360
now if you do something wrong you might

00:26:17,520 --> 00:26:20,240
get a different value just to give you

00:26:19,360 --> 00:26:22,159
an idea

00:26:20,240 --> 00:26:23,919
also have another one here to show you

00:26:22,159 --> 00:26:26,559
the power of you

00:26:23,919 --> 00:26:28,159
which is another great project i just

00:26:26,559 --> 00:26:30,400
have a very simple

00:26:28,159 --> 00:26:33,200
pretty similar query i'm casting the

00:26:30,400 --> 00:26:36,799
values in paula pretty powerful

00:26:33,200 --> 00:26:37,520
to uh cast them to numbers i probably

00:26:36,799 --> 00:26:40,799
should have

00:26:37,520 --> 00:26:42,080
changed my schema numbers but some of

00:26:40,799 --> 00:26:45,120
their data comes back

00:26:42,080 --> 00:26:48,159
weird so i probably should add some more

00:26:45,120 --> 00:26:49,520
uh transformations maybe that's another

00:26:48,159 --> 00:26:51,919
step i should do

00:26:49,520 --> 00:26:54,880
again very easy for me to create a new

00:26:51,919 --> 00:26:56,960
table or drop this table and change it

00:26:54,880 --> 00:26:58,080
reload the data from kafka and have that

00:26:56,960 --> 00:27:00,000
buffer there

00:26:58,080 --> 00:27:02,400
just to get uh maybe i want these as

00:27:00,000 --> 00:27:04,080
numbers maybe i need another field here

00:27:02,400 --> 00:27:06,799
maybe i want to merge this with another

00:27:04,080 --> 00:27:08,240
rest api i've got a couple of sources of

00:27:06,799 --> 00:27:11,039
stock data

00:27:08,240 --> 00:27:12,240
maybe i merge a couple together to get

00:27:11,039 --> 00:27:14,559
some more field

00:27:12,240 --> 00:27:15,360
but just to show you some analytics on

00:27:14,559 --> 00:27:18,640
that data

00:27:15,360 --> 00:27:20,080
so i've got that data in kudu i get

00:27:18,640 --> 00:27:23,279
real-time visualize

00:27:20,080 --> 00:27:24,720
that in a ui but it has these visual

00:27:23,279 --> 00:27:27,360
apps you could do it in q

00:27:24,720 --> 00:27:28,159
or zeppelin again we mentioned maybe

00:27:27,360 --> 00:27:31,679
we'll do it

00:27:28,159 --> 00:27:33,919
with druid on top of this at some point

00:27:31,679 --> 00:27:35,600
uh this tool will start pulling in flink

00:27:33,919 --> 00:27:38,080
sql and silver hue

00:27:35,600 --> 00:27:38,799
so we could do it that way so we showed

00:27:38,080 --> 00:27:41,919
nifi

00:27:38,799 --> 00:27:44,880
consuming the data we showed

00:27:41,919 --> 00:27:46,799
kafka connect consuming the data now

00:27:44,880 --> 00:27:49,200
what's running here

00:27:46,799 --> 00:27:51,440
i'll do some previous if you look

00:27:49,200 --> 00:27:55,600
there's uh

00:27:51,440 --> 00:27:56,640
3 500 pages of these uh stock quotes

00:27:55,600 --> 00:27:59,760
this is

00:27:56,640 --> 00:28:02,720
a flink sql client that

00:27:59,760 --> 00:28:04,159
is doing a query on that topic to see

00:28:02,720 --> 00:28:06,640
the newest data

00:28:04,159 --> 00:28:10,240
let me show you how we did that so we

00:28:06,640 --> 00:28:13,039
have a lot of catalogs we can connect to

00:28:10,240 --> 00:28:13,679
you know how to spell things again once

00:28:13,039 --> 00:28:16,399
this is in

00:28:13,679 --> 00:28:17,679
hue or in another tool this would be a

00:28:16,399 --> 00:28:19,360
little more friendly but this is a

00:28:17,679 --> 00:28:20,480
developer conference i could show you

00:28:19,360 --> 00:28:24,000
command line

00:28:20,480 --> 00:28:26,080
so i'm going to use the uh the registry

00:28:24,000 --> 00:28:27,200
catalog that said schema registry i

00:28:26,080 --> 00:28:30,720
showed you

00:28:27,200 --> 00:28:33,919
and i could see all the tables there

00:28:30,720 --> 00:28:36,159
and then i can look at stocks

00:28:33,919 --> 00:28:37,120
those are the fields and stocks maybe i

00:28:36,159 --> 00:28:40,960
just want to see

00:28:37,120 --> 00:28:44,240
symbol date time

00:28:40,960 --> 00:28:46,559
and close value hopefully i don't need

00:28:44,240 --> 00:28:49,840
quotes there yet

00:28:46,559 --> 00:28:51,120
again make sure maybe the first step you

00:28:49,840 --> 00:28:55,360
should do in any uh

00:28:51,120 --> 00:28:58,559
ingest is is not use

00:28:55,360 --> 00:29:01,600
uh reserved words as uh

00:28:58,559 --> 00:29:04,559
again people who make a rest api and you

00:29:01,600 --> 00:29:07,360
use reserve words his names

00:29:04,559 --> 00:29:09,279
that's i i don't know what i want to say

00:29:07,360 --> 00:29:13,840
about that that's not really cool

00:29:09,279 --> 00:29:13,840
so let's grab some more data

00:29:14,000 --> 00:29:17,600
from over here and that's another reason

00:29:15,919 --> 00:29:22,080
why we push it into

00:29:17,600 --> 00:29:22,080
uh kafka because not since it's inc

00:29:22,399 --> 00:29:25,840
schema in the registry i can just pull

00:29:25,279 --> 00:29:27,760
it back

00:29:25,840 --> 00:29:30,000
and flink i can wrap this in a

00:29:27,760 --> 00:29:31,440
deployable java application that runs in

00:29:30,000 --> 00:29:34,399
yarn or kubernetes

00:29:31,440 --> 00:29:35,600
and this app just runs now i could add

00:29:34,399 --> 00:29:37,440
more to this query

00:29:35,600 --> 00:29:38,640
if you've done spark sql you kind of get

00:29:37,440 --> 00:29:41,360
the idea

00:29:38,640 --> 00:29:43,520
this is a continuous query though as an

00:29:41,360 --> 00:29:45,679
event is pushed into

00:29:43,520 --> 00:29:47,600
published into kafka it's going to be

00:29:45,679 --> 00:29:48,559
consumed on the other end of the flink

00:29:47,600 --> 00:29:50,960
app

00:29:48,559 --> 00:29:53,360
this makes it very easy for you to have

00:29:50,960 --> 00:29:54,640
some kind of continuous dashboard

00:29:53,360 --> 00:29:56,559
obviously most people aren't going to

00:29:54,640 --> 00:29:57,360
want to sit here in the command line

00:29:56,559 --> 00:30:00,559
looking at it

00:29:57,360 --> 00:30:02,000
maybe i do maybe a lot of people who are

00:30:00,559 --> 00:30:04,720
committers out there like this

00:30:02,000 --> 00:30:05,120
as well but you know it's very easy to

00:30:04,720 --> 00:30:08,000
uh

00:30:05,120 --> 00:30:08,799
translate this into uh some app

00:30:08,000 --> 00:30:10,960
somewhere

00:30:08,799 --> 00:30:13,840
i could put a ui on top of it or i could

00:30:10,960 --> 00:30:14,880
have knife push this via websockets to a

00:30:13,840 --> 00:30:16,480
mobile app

00:30:14,880 --> 00:30:18,240
you know very straightforward but just

00:30:16,480 --> 00:30:21,120
to give you an idea

00:30:18,240 --> 00:30:21,840
of why we put it into kafka this buffer

00:30:21,120 --> 00:30:25,840
lets me use

00:30:21,840 --> 00:30:28,559
a lot of different uh consumers of it

00:30:25,840 --> 00:30:31,200
where i don't have to uh put the data

00:30:28,559 --> 00:30:35,440
somewhere complex again this is that

00:30:31,200 --> 00:30:37,600
command line tool running doing that sql

00:30:35,440 --> 00:30:40,080
it's just showing it to the screen as

00:30:37,600 --> 00:30:43,120
the sync i could dump it to a file

00:30:40,080 --> 00:30:45,200
and push it to hdfs or kudu again we

00:30:43,120 --> 00:30:47,520
already have it in kudu

00:30:45,200 --> 00:30:49,279
so and it was extremely straightforward

00:30:47,520 --> 00:30:52,000
to do that

00:30:49,279 --> 00:30:52,960
so this is a very simple app i don't

00:30:52,000 --> 00:30:56,000
know if we've had

00:30:52,960 --> 00:30:59,600
uh too many questions

00:30:56,000 --> 00:30:59,600
yeah i can answer a few

00:31:00,080 --> 00:31:04,720
we want to go how much time we have time

00:31:02,799 --> 00:31:07,360
ran out really fast in the last two

00:31:04,720 --> 00:31:07,360
sessions

00:31:07,600 --> 00:31:15,120
uh i think we still have

00:31:10,799 --> 00:31:15,120
uh eight minutes

00:31:16,559 --> 00:31:20,000
so did anything interesting come up oh

00:31:18,960 --> 00:31:22,720
you can get

00:31:20,000 --> 00:31:23,519
you can't get a knife shirt from apache

00:31:22,720 --> 00:31:28,640
i don't have to

00:31:23,519 --> 00:31:28,640
track down uh certain people to get

00:31:28,960 --> 00:31:33,279
that's pretty cool i'm gonna have to

00:31:31,120 --> 00:31:35,679
take a look at that link

00:31:33,279 --> 00:31:37,840
very cool um so i can go through this

00:31:35,679 --> 00:31:41,279
show you some of the things we're doing

00:31:37,840 --> 00:31:45,519
the different pieces oh i did miss atlas

00:31:41,279 --> 00:31:49,360
another awesome apache project in nifi

00:31:45,519 --> 00:31:50,880
i have a connection to atlas i just want

00:31:49,360 --> 00:31:53,840
to show you that

00:31:50,880 --> 00:31:54,640
i have that here where i'm reporting the

00:31:53,840 --> 00:31:58,399
lineage

00:31:54,640 --> 00:32:03,200
to this atlas why this is

00:31:58,399 --> 00:32:06,640
cool is because here is that kafka topic

00:32:03,200 --> 00:32:09,760
here is the lineage where it's

00:32:06,640 --> 00:32:12,559
how that got into kafka in ninefy

00:32:09,760 --> 00:32:15,679
invoked http

00:32:12,559 --> 00:32:17,440
i did a split there was that query then

00:32:15,679 --> 00:32:19,279
i pushed it to that topic

00:32:17,440 --> 00:32:20,880
and then you could see that second part

00:32:19,279 --> 00:32:24,640
of the app where i consumed it

00:32:20,880 --> 00:32:26,559
and push it into kudu and uh

00:32:24,640 --> 00:32:29,440
in another version you also see any kind

00:32:26,559 --> 00:32:31,519
of flink app or spark app or

00:32:29,440 --> 00:32:32,720
maybe hive or impala things you've done

00:32:31,519 --> 00:32:35,840
with this

00:32:32,720 --> 00:32:36,640
all from atlas it's really helpful way

00:32:35,840 --> 00:32:38,559
to see the

00:32:36,640 --> 00:32:40,000
the full lineage of what's going on with

00:32:38,559 --> 00:32:42,480
your application

00:32:40,000 --> 00:32:43,919
and here you can add classification all

00:32:42,480 --> 00:32:46,399
sort of other things

00:32:43,919 --> 00:32:48,960
it's uh it's a nice way to track that

00:32:46,399 --> 00:32:51,600
just here anything i've been pushing uh

00:32:48,960 --> 00:32:54,960
data to i've got those there we could

00:32:51,600 --> 00:32:57,039
also search in here directly into nifi

00:32:54,960 --> 00:32:58,240
see the flows and i find see what's

00:32:57,039 --> 00:33:00,480
going on there

00:32:58,240 --> 00:33:02,000
there's a lot of stuff in the nifi ones

00:33:00,480 --> 00:33:06,320
you can pop to different

00:33:02,000 --> 00:33:08,080
sections but uh yeah apache atlas is a

00:33:06,320 --> 00:33:10,320
nice way also when you're trying to see

00:33:08,080 --> 00:33:13,600
what's going on with your apps

00:33:10,320 --> 00:33:15,279
you know here's a diagram of my nifi to

00:33:13,600 --> 00:33:18,720
uh

00:33:15,279 --> 00:33:20,880
kudu app pretty cool

00:33:18,720 --> 00:33:25,840
uh would you be able to somehow complete

00:33:20,880 --> 00:33:25,840
the lineage

00:33:27,039 --> 00:33:30,640
if microservices in the middle of the

00:33:28,880 --> 00:33:34,559
pipeline now

00:33:30,640 --> 00:33:36,799
apache atlas has some open connectors

00:33:34,559 --> 00:33:39,600
so you could push that information to

00:33:36,799 --> 00:33:43,600
atlas yourself using their api

00:33:39,600 --> 00:33:45,600
now you can also what could show up here

00:33:43,600 --> 00:33:46,320
is could be uh something missing if

00:33:45,600 --> 00:33:48,480
there's

00:33:46,320 --> 00:33:49,919
see a copper streams app or some other

00:33:48,480 --> 00:33:52,000
app that doesn't

00:33:49,919 --> 00:33:53,440
by default put atlas information in

00:33:52,000 --> 00:33:55,519
there so

00:33:53,440 --> 00:33:57,919
there could be a step like i could have

00:33:55,519 --> 00:33:59,360
had a step in here where someone changed

00:33:57,919 --> 00:34:02,159
it

00:33:59,360 --> 00:34:02,640
you know you might want to keep it clean

00:34:02,159 --> 00:34:04,320
if

00:34:02,640 --> 00:34:06,559
if you're going to have another step

00:34:04,320 --> 00:34:06,880
that say a copter streams microservice

00:34:06,559 --> 00:34:10,240
or

00:34:06,880 --> 00:34:10,720
spring boots or uh quarkus or anything

00:34:10,240 --> 00:34:13,679
else

00:34:10,720 --> 00:34:15,359
have that microservice consume from this

00:34:13,679 --> 00:34:18,079
one and push to another topic

00:34:15,359 --> 00:34:19,679
or push through some other data store if

00:34:18,079 --> 00:34:23,359
it's one of the data stores

00:34:19,679 --> 00:34:23,839
in the apache big data area most of them

00:34:23,359 --> 00:34:27,440
have

00:34:23,839 --> 00:34:28,720
atlas connectors already like hdfs hive

00:34:27,440 --> 00:34:30,879
hbase

00:34:28,720 --> 00:34:31,760
and those will show up yeah and and

00:34:30,879 --> 00:34:34,800
recently

00:34:31,760 --> 00:34:38,240
uh i believe we shipped uh

00:34:34,800 --> 00:34:40,879
atlas 2.1 uh which is also providing a

00:34:38,240 --> 00:34:43,679
completely new api that you can uh

00:34:40,879 --> 00:34:45,440
leverage by yourself to complete the

00:34:43,679 --> 00:34:47,679
line edge based on your use case so

00:34:45,440 --> 00:34:50,720
that's something you could use as well

00:34:47,679 --> 00:34:52,720
i know the yeah the atlas api

00:34:50,720 --> 00:34:55,359
changed a lot recently and it's much

00:34:52,720 --> 00:34:58,000
easier to use it was uh

00:34:55,359 --> 00:34:58,560
it was quite uh difficult to apprehend

00:34:58,000 --> 00:35:01,760
uh

00:34:58,560 --> 00:35:04,880
on the one.x release line um

00:35:01,760 --> 00:35:07,440
recently with the 2.1 version it's it's

00:35:04,880 --> 00:35:07,440
way easier

00:35:08,320 --> 00:35:13,680
oh oh the cop could debate

00:35:11,440 --> 00:35:16,000
yeah like everything in the packaging is

00:35:13,680 --> 00:35:19,839
more than one project for everything

00:35:16,000 --> 00:35:19,839
so there's no other project for nifi

00:35:20,960 --> 00:35:25,440
i don't know who wants to take that one

00:35:22,720 --> 00:35:27,839
that's a that's a divisive one

00:35:25,440 --> 00:35:30,640
yeah i mean there are very good reasons

00:35:27,839 --> 00:35:33,680
uh to uh choose

00:35:30,640 --> 00:35:36,240
one or the other uh

00:35:33,680 --> 00:35:37,359
i mean if we are completely uh honest

00:35:36,240 --> 00:35:40,720
here

00:35:37,359 --> 00:35:43,440
for this specific talk i mean uh kafka

00:35:40,720 --> 00:35:45,920
is something that we provide at platera

00:35:43,440 --> 00:35:48,960
uh pulsar is something we don't provide

00:35:45,920 --> 00:35:51,359
yet i want to say uh so

00:35:48,960 --> 00:35:53,040
that's the reason but from uh a

00:35:51,359 --> 00:35:55,440
technical point of view for this

00:35:53,040 --> 00:35:58,079
specific use case you could use both and

00:35:55,440 --> 00:35:59,040
and nifi also has processors for boom

00:35:58,079 --> 00:36:01,200
style so

00:35:59,040 --> 00:36:02,160
yeah you could use both it's it's a

00:36:01,200 --> 00:36:05,520
perfectly fine

00:36:02,160 --> 00:36:05,520
uh solution as well

00:36:07,119 --> 00:36:11,520
yeah i think that one of the advantages

00:36:09,359 --> 00:36:14,720
is uh

00:36:11,520 --> 00:36:15,119
nifi and flink could work with another

00:36:14,720 --> 00:36:17,200
one

00:36:15,119 --> 00:36:18,320
kafka is nice because there's a lot of

00:36:17,200 --> 00:36:21,680
tooling

00:36:18,320 --> 00:36:23,520
there's a lot of connectors and drivers

00:36:21,680 --> 00:36:27,599
and people have been using it for a long

00:36:23,520 --> 00:36:30,560
time there's a lot of committers

00:36:27,599 --> 00:36:31,920
it makes it pretty easy yeah so

00:36:30,560 --> 00:36:34,720
regarding the

00:36:31,920 --> 00:36:36,800
the discussion about uh pulsar functions

00:36:34,720 --> 00:36:40,079
or kafka connectors

00:36:36,800 --> 00:36:41,570
uh sometimes people are wondering why

00:36:40,079 --> 00:36:43,599
you're using nifi

00:36:41,570 --> 00:36:46,000
[Music]

00:36:43,599 --> 00:36:47,680
at all because you for some use cases

00:36:46,000 --> 00:36:48,800
you could do everything with the pulsar

00:36:47,680 --> 00:36:52,720
functions or

00:36:48,800 --> 00:36:54,560
or kafka connectors and that's true um

00:36:52,720 --> 00:36:56,400
as i said at the beginning uh from my

00:36:54,560 --> 00:36:57,359
point of view knife makes sense when you

00:36:56,400 --> 00:37:00,560
have

00:36:57,359 --> 00:37:02,800
uh many sources uh with very

00:37:00,560 --> 00:37:04,320
different protocols you have batch

00:37:02,800 --> 00:37:07,040
oriented sources

00:37:04,320 --> 00:37:08,480
with large files you have a streaming

00:37:07,040 --> 00:37:11,760
oriented sources

00:37:08,480 --> 00:37:15,280
so knife is really to get the data in

00:37:11,760 --> 00:37:18,800
to make it available and then use uh

00:37:15,280 --> 00:37:20,880
tools like kafka and pulsar

00:37:18,800 --> 00:37:22,640
for doing some of the transformations

00:37:20,880 --> 00:37:25,760
that's also perfectly valid

00:37:22,640 --> 00:37:29,280
um yeah camille is also another option

00:37:25,760 --> 00:37:32,079
uh it's it's really about um also

00:37:29,280 --> 00:37:33,599
do you want something that is really uh

00:37:32,079 --> 00:37:36,880
easy to use you ha

00:37:33,599 --> 00:37:39,839
i mean you drag and drop you can uh

00:37:36,880 --> 00:37:41,520
get the data in from from many sources

00:37:39,839 --> 00:37:44,560
in a consistent way

00:37:41,520 --> 00:37:47,280
and then uh i know some

00:37:44,560 --> 00:37:49,440
some of my colleagues are uh big fans of

00:37:47,280 --> 00:37:51,760
kafka connect or pulsar

00:37:49,440 --> 00:37:53,040
and there are developers and they are

00:37:51,760 --> 00:37:55,440
going to develop

00:37:53,040 --> 00:37:56,800
their own functions or their own kafka

00:37:55,440 --> 00:37:59,839
connectors to

00:37:56,800 --> 00:38:02,320
deal with some data and that's fine

00:37:59,839 --> 00:38:04,000
but when you are in an enterprise you

00:38:02,320 --> 00:38:06,160
probably want a consistent way

00:38:04,000 --> 00:38:08,079
to get the data in and and knife is

00:38:06,160 --> 00:38:09,920
really about this getting the data in

00:38:08,079 --> 00:38:13,119
once it's available

00:38:09,920 --> 00:38:15,280
in your clusters then uh

00:38:13,119 --> 00:38:16,800
yeah there are many tools many options

00:38:15,280 --> 00:38:18,480
uh it's really

00:38:16,800 --> 00:38:20,480
from my point of view you should choose

00:38:18,480 --> 00:38:23,200
whatever

00:38:20,480 --> 00:38:24,079
is the best feast the best fit for your

00:38:23,200 --> 00:38:28,720
use case

00:38:24,079 --> 00:38:28,720
and what uh you will uh let's say

00:38:28,880 --> 00:38:32,000
use the most quickly to get some

00:38:30,880 --> 00:38:33,920
insights on your data

00:38:32,000 --> 00:38:35,040
so i don't have any strong opinions on

00:38:33,920 --> 00:38:37,040
this

00:38:35,040 --> 00:38:40,240
knife is really about getting the data

00:38:37,040 --> 00:38:44,000
in and making it available

00:38:40,240 --> 00:38:47,760
it provides consistent way to access

00:38:44,000 --> 00:38:50,800
many sources provide the data language

00:38:47,760 --> 00:38:52,560
all of this also images

00:38:50,800 --> 00:38:54,000
i i wouldn't want to push an image

00:38:52,560 --> 00:38:56,320
through pulsar but

00:38:54,000 --> 00:38:57,359
now if i hear i'm pulling in webcam

00:38:56,320 --> 00:38:59,839
images

00:38:57,359 --> 00:39:00,560
from remote devices and passing them

00:38:59,839 --> 00:39:03,040
through uh

00:39:00,560 --> 00:39:05,040
deep learning uh i don't know you want

00:39:03,040 --> 00:39:06,800
to do that in cockpit connector or

00:39:05,040 --> 00:39:09,119
pulsar function i don't think you want

00:39:06,800 --> 00:39:13,040
to push images through a

00:39:09,119 --> 00:39:16,400
message or video

00:39:13,040 --> 00:39:16,400
or unstructured data

00:39:18,000 --> 00:39:21,359
yeah so firefighter really shines when

00:39:20,960 --> 00:39:24,240
you

00:39:21,359 --> 00:39:25,839
have uh let's say a large set of use

00:39:24,240 --> 00:39:31,200
cases and a large set of

00:39:25,839 --> 00:39:34,560
different sources but if you have a very

00:39:31,200 --> 00:39:36,000
simple use case uh with uh one source

00:39:34,560 --> 00:39:39,440
one destination

00:39:36,000 --> 00:39:39,839
uh yeah then you probably can do it with

00:39:39,440 --> 00:39:42,880
uh

00:39:39,839 --> 00:39:44,960
with kafka it's more like a

00:39:42,880 --> 00:39:46,000
a larger discussion when you have many

00:39:44,960 --> 00:39:51,040
sources many

00:39:46,000 --> 00:39:51,040
many use cases um yeah

00:39:52,240 --> 00:39:57,599
yeah also if you want to have a

00:39:55,920 --> 00:40:00,880
multi-cloud strategy

00:39:57,599 --> 00:40:03,280
in your company where you have clusters

00:40:00,880 --> 00:40:04,160
and workloads running on premises

00:40:03,280 --> 00:40:06,960
clusters

00:40:04,160 --> 00:40:08,560
and workloads running in the cloud you

00:40:06,960 --> 00:40:11,599
can have a nifi cluster

00:40:08,560 --> 00:40:13,359
on both sides and you can use what we

00:40:11,599 --> 00:40:14,720
call side to side between the knife

00:40:13,359 --> 00:40:18,160
clusters

00:40:14,720 --> 00:40:20,079
this is going to allow you to

00:40:18,160 --> 00:40:22,480
move data back and forth between your

00:40:20,079 --> 00:40:25,119
environments while also

00:40:22,480 --> 00:40:26,960
ensuring consistent uh policies

00:40:25,119 --> 00:40:29,200
consistent data lineage

00:40:26,960 --> 00:40:30,640
um that's something i'm going to talk

00:40:29,200 --> 00:40:34,240
about in a few days

00:40:30,640 --> 00:40:36,000
uh in some blog posts uh but um

00:40:34,240 --> 00:40:38,000
yeah now if i to move data back and

00:40:36,000 --> 00:40:40,160
forth between multiple environments

00:40:38,000 --> 00:40:41,200
is something really powerful especially

00:40:40,160 --> 00:40:43,359
today when

00:40:41,200 --> 00:40:45,359
everyone is talking about multi-cloud

00:40:43,359 --> 00:40:46,800
strategies or when you have multiple

00:40:45,359 --> 00:40:49,599
cloud providers

00:40:46,800 --> 00:40:50,480
uh and it can be a nightmare to deal

00:40:49,599 --> 00:40:52,960
with the

00:40:50,480 --> 00:40:54,480
ingress and aggress costs with your

00:40:52,960 --> 00:40:56,800
cloud providers when you

00:40:54,480 --> 00:40:58,640
have some workloads in azure some

00:40:56,800 --> 00:41:02,400
workloads in google cloud

00:40:58,640 --> 00:41:03,040
uh some stuff in aws uh i was at google

00:41:02,400 --> 00:41:05,760
before

00:41:03,040 --> 00:41:07,040
and uh that was one of the main concern

00:41:05,760 --> 00:41:10,400
of many customers

00:41:07,040 --> 00:41:14,240
uh how to deal with all this

00:41:10,400 --> 00:41:17,440
kind of uh mess to be honest

00:41:14,240 --> 00:41:21,839
so knife is a great answer also

00:41:17,440 --> 00:41:21,839
for this

00:41:23,599 --> 00:41:29,200
i don't know if we are over time or

00:41:27,599 --> 00:41:32,160
if we stay i don't know when the birds

00:41:29,200 --> 00:41:32,160
of a feather start

00:41:32,240 --> 00:41:37,359
yeah well if you still have questions we

00:41:34,880 --> 00:41:39,599
can answer the questions

00:41:37,359 --> 00:41:42,560
uh yeah this is also knife i hosting a

00:41:39,599 --> 00:41:42,560
live web page

00:41:43,760 --> 00:41:49,839
i wouldn't try to do that in a in a

00:41:46,839 --> 00:41:49,839
function

00:41:50,079 --> 00:41:54,079
well knife i being used to expose apis

00:41:52,480 --> 00:41:57,599
is actually quite common

00:41:54,079 --> 00:41:59,440
uh hosting a website with knife

00:41:57,599 --> 00:42:02,000
is probably not something you want to do

00:41:59,440 --> 00:42:03,680
but team is always really good at

00:42:02,000 --> 00:42:07,040
finding some uh

00:42:03,680 --> 00:42:08,640
cool use cases um but uh yeah exposing

00:42:07,040 --> 00:42:11,760
apis with knife is

00:42:08,640 --> 00:42:15,280
is something really common uh we have

00:42:11,760 --> 00:42:18,640
many many users doing this um

00:42:15,280 --> 00:42:20,720
so that's that's perfectly fine

00:42:18,640 --> 00:42:21,760
yeah i'm doing that to push the smm

00:42:20,720 --> 00:42:24,960
alerts

00:42:21,760 --> 00:42:26,560
to nifi since they're json

00:42:24,960 --> 00:42:29,200
i haven't figured out what i want to do

00:42:26,560 --> 00:42:30,240
with them but it's very trivial to hook

00:42:29,200 --> 00:42:31,839
that up

00:42:30,240 --> 00:42:34,480
you just have nine five the rest

00:42:31,839 --> 00:42:44,000
endpoint for alerts coming in

00:42:34,480 --> 00:42:47,760
so we could do whatever you want

00:42:44,000 --> 00:42:47,760
the date of providence is pretty awesome

00:42:48,640 --> 00:42:55,200
yeah yeah

00:42:52,000 --> 00:42:57,680
can you show uh the lane edge directly

00:42:55,200 --> 00:42:58,640
in uh based on the problems that are

00:42:57,680 --> 00:43:00,400
yeah

00:42:58,640 --> 00:43:02,480
this is i don't know maybe you did

00:43:00,400 --> 00:43:05,680
already uh

00:43:02,480 --> 00:43:07,520
this is a really cool feature uh using

00:43:05,680 --> 00:43:10,240
the providence data

00:43:07,520 --> 00:43:10,960
this is also something uh that you can

00:43:10,240 --> 00:43:13,760
use as i

00:43:10,960 --> 00:43:15,520
was uh answering in some uh some

00:43:13,760 --> 00:43:17,520
questions in the chat

00:43:15,520 --> 00:43:19,680
uh provenance data is also something you

00:43:17,520 --> 00:43:21,359
can use to replace specific events in

00:43:19,680 --> 00:43:24,480
case of failures

00:43:21,359 --> 00:43:26,960
so that's something you can leverage um

00:43:24,480 --> 00:43:27,920
for yeah in case you something wrong

00:43:26,960 --> 00:43:30,960
happens

00:43:27,920 --> 00:43:33,440
uh that's that's really powerful uh

00:43:30,960 --> 00:43:35,599
provenance metadata is is is a great

00:43:33,440 --> 00:43:38,640
feature of nine five

00:43:35,599 --> 00:43:41,520
yeah that that one's fun too when you

00:43:38,640 --> 00:43:44,880
when you use nifi to do some knifi

00:43:41,520 --> 00:43:47,760
like i try and i think i have that

00:43:44,880 --> 00:43:49,200
i had one that used the query and ifi

00:43:47,760 --> 00:43:52,400
processor to read

00:43:49,200 --> 00:43:55,359
provenance on one particular

00:43:52,400 --> 00:43:57,119
processor and then push that to kafka

00:43:55,359 --> 00:43:58,400
and then have knife i read that and

00:43:57,119 --> 00:44:00,800
process

00:43:58,400 --> 00:44:01,520
those provenance events and then use

00:44:00,800 --> 00:44:02,960
them for

00:44:01,520 --> 00:44:05,200
i don't know what i'm using for that

00:44:02,960 --> 00:44:08,960
question to kudu

00:44:05,200 --> 00:44:11,200
oh airflow

00:44:08,960 --> 00:44:13,599
knife versus airflow is is a good

00:44:11,200 --> 00:44:13,599
question

00:44:13,680 --> 00:44:20,160
again really depends uh

00:44:17,359 --> 00:44:21,280
what kind of processing and jobs you

00:44:20,160 --> 00:44:24,880
want to

00:44:21,280 --> 00:44:28,079
orchestrate but

00:44:24,880 --> 00:44:32,480
if it's really about job orchestration

00:44:28,079 --> 00:44:36,319
then airflow is probably a better option

00:44:32,480 --> 00:44:39,520
again really depends on the use case

00:44:36,319 --> 00:44:41,440
uh you probably want a combination of

00:44:39,520 --> 00:44:44,640
both for some use cases

00:44:41,440 --> 00:44:48,000
um we i mean happy to discuss it but

00:44:44,640 --> 00:44:51,520
um really depends on the details

00:44:48,000 --> 00:44:55,520
airflow is great uh for orchestration

00:44:51,520 --> 00:44:57,920
uh and and triggering jobs uh spa jobs

00:44:55,520 --> 00:44:59,280
hive jobs uh things like that it's

00:44:57,920 --> 00:45:03,599
really great

00:44:59,280 --> 00:45:06,880
um so yeah airflow is doing things

00:45:03,599 --> 00:45:09,520
that knife i shouldn't be used for

00:45:06,880 --> 00:45:12,880
and the opposite is also true so it

00:45:09,520 --> 00:45:12,880
really depends on the use case

00:45:13,040 --> 00:45:19,839
i think the the queuing and buffering is

00:45:15,200 --> 00:45:21,920
something very unique to nifi yeah

00:45:19,839 --> 00:45:22,880
yeah airflow is is really pure

00:45:21,920 --> 00:45:25,920
orchestration

00:45:22,880 --> 00:45:28,000
um which is great

00:45:25,920 --> 00:45:29,200
you can do orchestration with knife i

00:45:28,000 --> 00:45:31,920
but you can't do

00:45:29,200 --> 00:45:33,599
as much as you could do with airflow in

00:45:31,920 --> 00:45:35,280
terms of orchestration so

00:45:33,599 --> 00:45:36,880
again really depends what you are trying

00:45:35,280 --> 00:45:39,680
to achieve uh

00:45:36,880 --> 00:45:40,319
if if your orchestration needs are

00:45:39,680 --> 00:45:43,119
simple

00:45:40,319 --> 00:45:44,640
um as team said in the chat you have

00:45:43,119 --> 00:45:46,560
scheduling their processor

00:45:44,640 --> 00:45:47,680
so you can already orchestrate quite a

00:45:46,560 --> 00:45:51,440
bit

00:45:47,680 --> 00:45:54,000
uh but you probably don't want

00:45:51,440 --> 00:45:57,359
uh to use nifi for every kind of

00:45:54,000 --> 00:46:01,839
orchestration needs so it really depends

00:45:57,359 --> 00:46:01,839
i don't have a straight answer for this

00:46:02,560 --> 00:46:06,640
i i think keep sparking airflow

00:46:07,920 --> 00:46:14,079
that's what we're doing that seems to

00:46:09,920 --> 00:46:17,680
seems to make the most sense

00:46:14,079 --> 00:46:17,680
an oh our old buddy uzi

00:46:17,760 --> 00:46:21,440
yeah and i don't want to write with you

00:46:20,880 --> 00:46:24,720
though

00:46:21,440 --> 00:46:24,720
airplane flow is pretty nice

00:46:25,440 --> 00:46:32,319
okay uh we we are definitely over there

00:46:29,359 --> 00:46:34,720
i don't know if uh no one kicked this

00:46:32,319 --> 00:46:34,720
out though

00:46:36,400 --> 00:46:39,760
but it's still recording so it's a

00:46:38,880 --> 00:46:42,240
recording well if

00:46:39,760 --> 00:46:43,119
if you still have questions uh the the

00:46:42,240 --> 00:46:45,599
community

00:46:43,119 --> 00:46:47,280
uh is very active so feel free to join

00:46:45,599 --> 00:46:50,880
the apache slack

00:46:47,280 --> 00:46:53,200
uh for nifi uh i can give you the link

00:46:50,880 --> 00:46:54,319
right now uh that can be something

00:46:53,200 --> 00:46:57,280
useful

00:46:54,319 --> 00:46:58,640
um what about your uh session coming up

00:46:57,280 --> 00:47:00,800
do we have a link to that

00:46:58,640 --> 00:47:02,560
i should have thought of that uh i don't

00:47:00,800 --> 00:47:03,920
have a link any but

00:47:02,560 --> 00:47:05,680
i'm trying to see if i could find it

00:47:03,920 --> 00:47:09,119
real quick because that's

00:47:05,680 --> 00:47:12,160
that looks pretty awesome yes so here's

00:47:09,119 --> 00:47:15,359
link to uh the slack where the

00:47:12,160 --> 00:47:16,240
for apache nifi there uh we have a lot

00:47:15,359 --> 00:47:18,160
of people there

00:47:16,240 --> 00:47:19,359
uh if you want to ask questions on the

00:47:18,160 --> 00:47:22,640
mailing lists

00:47:19,359 --> 00:47:25,280
we answer honestly we answer

00:47:22,640 --> 00:47:26,559
all the questions uh the community is

00:47:25,280 --> 00:47:28,640
really active so if

00:47:26,559 --> 00:47:30,720
yeah if you have questions feel free to

00:47:28,640 --> 00:47:33,040
uh to go there

00:47:30,720 --> 00:47:33,040
um

00:47:35,119 --> 00:47:39,119
do you know if there are any plans to

00:47:36,559 --> 00:47:42,960
write bulletins to logs

00:47:39,119 --> 00:47:44,160
so by default it by default if you are

00:47:42,960 --> 00:47:47,280
not changing anything

00:47:44,160 --> 00:47:50,720
any log which is warning or higher

00:47:47,280 --> 00:47:53,359
is also a built-in so and

00:47:50,720 --> 00:47:54,559
and vis-versa so buildings should always

00:47:53,359 --> 00:47:57,760
be loved

00:47:54,559 --> 00:48:00,800
but if you are asking about a specific

00:47:57,760 --> 00:48:04,839
uh location for persisting buildings

00:48:00,800 --> 00:48:08,000
and this information uh right now

00:48:04,839 --> 00:48:09,119
uh that's not possible i mean that's

00:48:08,000 --> 00:48:12,880
completely

00:48:09,119 --> 00:48:16,400
merged into the full logs of nifi

00:48:12,880 --> 00:48:18,319
uh but uh yeah options will be to use

00:48:16,400 --> 00:48:20,460
the site to site reporting tasks for

00:48:18,319 --> 00:48:21,760
built-ins and then use some

00:48:20,460 --> 00:48:24,800
[Music]

00:48:21,760 --> 00:48:27,359
flow to send this data somewhere

00:48:24,800 --> 00:48:28,240
i know there are discussions about

00:48:27,359 --> 00:48:31,839
dedicated

00:48:28,240 --> 00:48:33,280
login files per process group or things

00:48:31,839 --> 00:48:36,480
like that

00:48:33,280 --> 00:48:38,319
that's an ongoing discussion um i

00:48:36,480 --> 00:48:41,599
actually started working on this

00:48:38,319 --> 00:48:42,559
a few years back and it was getting

00:48:41,599 --> 00:48:46,079
messy

00:48:42,559 --> 00:48:49,040
uh so i didn't do it

00:48:46,079 --> 00:48:49,760
that's doable but uh it raises a lot of

00:48:49,040 --> 00:48:53,359
questions

00:48:49,760 --> 00:48:57,280
uh regarding uh the performance impact

00:48:53,359 --> 00:48:57,680
um so yeah right now my recommendation

00:48:57,280 --> 00:49:01,119
will

00:48:57,680 --> 00:49:04,640
be to go through a reporting task

00:49:01,119 --> 00:49:05,520
to have the built-in transformed as flow

00:49:04,640 --> 00:49:07,280
files

00:49:05,520 --> 00:49:08,800
in nifi and then you can have a

00:49:07,280 --> 00:49:11,359
dedicated uh

00:49:08,800 --> 00:49:12,160
flow to deal with the built-ins the way

00:49:11,359 --> 00:49:15,359
you want

00:49:12,160 --> 00:49:16,240
if you want to send it to some places or

00:49:15,359 --> 00:49:19,520
to uh

00:49:16,240 --> 00:49:22,559
send an email or i don't know

00:49:19,520 --> 00:49:25,280
open a jira or whatever that's what i

00:49:22,559 --> 00:49:25,280
would recommend

00:49:29,200 --> 00:49:36,960
um yes the team was talking about uh

00:49:33,119 --> 00:49:40,079
a live station i'm doing in a few days

00:49:36,960 --> 00:49:44,319
uh i don't know where the link

00:49:40,079 --> 00:49:46,800
is uh i'm sure i tweeted it at some

00:49:44,319 --> 00:49:49,280
point but that does not help

00:49:46,800 --> 00:49:50,079
yeah so it must be available somewhere

00:49:49,280 --> 00:49:53,119
uh

00:49:50,079 --> 00:49:55,100
but yeah i'm doing a live station uh on

00:49:53,119 --> 00:49:56,400
thursday

00:49:55,100 --> 00:49:58,720
[Music]

00:49:56,400 --> 00:50:00,480
and the idea is i don't have anything

00:49:58,720 --> 00:50:03,760
prepared

00:50:00,480 --> 00:50:07,839
which is kind of scary

00:50:03,760 --> 00:50:11,040
uh and basically you will be able to ask

00:50:07,839 --> 00:50:14,400
for what you want to see me doing

00:50:11,040 --> 00:50:15,680
um yeah here's the link thanks

00:50:14,400 --> 00:50:18,480
so that's something i'm doing on

00:50:15,680 --> 00:50:19,440
thursday um i know the apache gun is

00:50:18,480 --> 00:50:21,680
still

00:50:19,440 --> 00:50:23,599
live on thursday so you will have to

00:50:21,680 --> 00:50:24,000
choose between the two i'm sorry about

00:50:23,599 --> 00:50:26,880
that

00:50:24,000 --> 00:50:28,319
it's it will be recorded all right yeah

00:50:26,880 --> 00:50:29,119
it will be recorded everything is

00:50:28,319 --> 00:50:31,359
recorded so

00:50:29,119 --> 00:50:32,160
yeah if you register you can watch it

00:50:31,359 --> 00:50:34,400
later

00:50:32,160 --> 00:50:34,400
yep

00:50:36,480 --> 00:50:42,319
cool anything else

00:50:39,520 --> 00:50:43,760
or because i i feel like there is a

00:50:42,319 --> 00:50:45,440
another session right

00:50:43,760 --> 00:50:48,240
okay why no one's kicked this out i

00:50:45,440 --> 00:50:48,240
don't understand

00:50:49,040 --> 00:50:54,960
i don't know when the birds of a purge

00:50:50,720 --> 00:50:58,079
of a feather start for streaming

00:50:54,960 --> 00:51:01,200
uh i don't know um if i click on

00:50:58,079 --> 00:51:02,000
the sessions link i guess i'm kicked out

00:51:01,200 --> 00:51:05,280
of this one so

00:51:02,000 --> 00:51:08,240
yeah i i started a news a new window

00:51:05,280 --> 00:51:09,119
that has started but i guess yeah yeah

00:51:08,240 --> 00:51:12,160
so let's uh

00:51:09,119 --> 00:51:14,370
let's close this one okay yes thank you

00:51:12,160 --> 00:51:15,920
everyone for attending uh this call

00:51:14,370 --> 00:51:18,960
[Music]

00:51:15,920 --> 00:51:23,839
it was a pleasure thanks tim thanks

00:51:18,960 --> 00:51:23,839
again man

00:51:37,440 --> 00:51:39,520

YouTube URL: https://www.youtube.com/watch?v=sTnyu3fRUwE


