Title: Managing Transaction on Ethereum with Apache Airflow
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Big Data (Track 2)
Description: 
	Managing Transaction on Ethereum with Apache Airflow
Michael Ghen

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Apache Airflow is a Python-based workflow management system that can be used to actively monitor and execute transactions on blockchain networks like Ethereum. This presentation is an introduction to Apache Airflow followed by a demonstration of a production deployment. Apache Airflow is an excellent tool for anyone already familiar with Python. Its ability to process jobs and handle errors makes it a good choice tool for managing activity on blockchain networks. The goal of this talk is to demonstrate how Apache Airflow can be used for environmental scanning and batch processing transactions. The demonstration will cover using Airflow and Python for monitoring and executing ERC20 token transactions on the Ethereum blockchain.

Michael Ghen is a computer engineer from Philadelphia that has contributed to Apache Airflow and Apache Unomi. He has a B.S. in computer engineering from Pennsylvania State University and an M.S. in analytics from Brandeis. Currently, he is a GAANN Cybersecurity Fellow at Drexel where he is pursuing a Ph.D. in electrical engineering. He previously served as a data architect and engineer at start-ups and non-profits where he used Apache Airflow to build data pipelines.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,080 --> 00:00:29,039
messages actually so

00:00:25,760 --> 00:00:32,160
um yeah so welcome

00:00:29,039 --> 00:00:33,760
welcome to the the talk um

00:00:32,160 --> 00:00:35,200
can someone just confirm that they can

00:00:33,760 --> 00:00:37,360
see the slides

00:00:35,200 --> 00:00:39,360
uh that are up there you can see the

00:00:37,360 --> 00:00:44,079
slides

00:00:39,360 --> 00:00:47,280
i think it says you can so um

00:00:44,079 --> 00:00:49,760
anybody all right

00:00:47,280 --> 00:00:50,960
slides visible all right let's start uh

00:00:49,760 --> 00:00:53,680
so my name is mike

00:00:50,960 --> 00:00:55,360
yeah so i uh i'm here to present uh

00:00:53,680 --> 00:00:58,559
managing transactions on

00:00:55,360 --> 00:01:00,399
ethereum with apache airflow

00:00:58,559 --> 00:01:04,000
currently i'm just a mining pool

00:01:00,399 --> 00:01:06,479
operator and a phd student at drexel

00:01:04,000 --> 00:01:07,760
previously i was a data architect and

00:01:06,479 --> 00:01:10,479
data platform engineer

00:01:07,760 --> 00:01:12,080
systems engineer working in data centers

00:01:10,479 --> 00:01:13,280
and i've been doing i've been using

00:01:12,080 --> 00:01:15,360
apache airflow

00:01:13,280 --> 00:01:16,560
probably for i don't know probably since

00:01:15,360 --> 00:01:19,759
00:01:16,560 --> 00:01:22,240
late 2016 um to do

00:01:19,759 --> 00:01:23,600
automation and things really got heavy

00:01:22,240 --> 00:01:26,799
in 2017

00:01:23,600 --> 00:01:27,360
and 2018 but i still use it today for

00:01:26,799 --> 00:01:30,400
some of

00:01:27,360 --> 00:01:32,799
my ethereum automation and so that's

00:01:30,400 --> 00:01:34,640
what i'm here to talk about

00:01:32,799 --> 00:01:36,799
a little bit of background on ethereum

00:01:34,640 --> 00:01:38,320
those of you who don't know what it is

00:01:36,799 --> 00:01:40,079
there are really two ideas one is

00:01:38,320 --> 00:01:41,680
ethereum another is ether

00:01:40,079 --> 00:01:43,840
they're actually different so when we'd

00:01:41,680 --> 00:01:46,640
say ethereum we're referring to

00:01:43,840 --> 00:01:47,600
this public computing platform which is

00:01:46,640 --> 00:01:50,640
the collection

00:01:47,600 --> 00:01:54,320
of all of the nodes uh globally

00:01:50,640 --> 00:01:55,759
that run the ethereum software and uh

00:01:54,320 --> 00:01:58,320
the way that you can think about what

00:01:55,759 --> 00:01:59,280
ethereum is is it's a distributed ledger

00:01:58,320 --> 00:02:01,840
technology

00:01:59,280 --> 00:02:02,719
but essentially what it is it's a state

00:02:01,840 --> 00:02:05,280
machine

00:02:02,719 --> 00:02:06,479
and it inc every time someone does an

00:02:05,280 --> 00:02:09,200
ethereum transaction

00:02:06,479 --> 00:02:10,800
they are incrementing the state so there

00:02:09,200 --> 00:02:12,800
is a genesis state

00:02:10,800 --> 00:02:15,360
and all of the sum of all of the

00:02:12,800 --> 00:02:18,000
transactions create these state changes

00:02:15,360 --> 00:02:20,959
uh to give us the current state of the

00:02:18,000 --> 00:02:20,959
ethereum platform

00:02:21,040 --> 00:02:27,920
what a transaction looks like is it has

00:02:24,480 --> 00:02:30,160
a hash and they are collated into blocks

00:02:27,920 --> 00:02:32,160
this isn't really a blockchain talk but

00:02:30,160 --> 00:02:36,080
what is sort of highlighted here is that

00:02:32,160 --> 00:02:37,760
you can do these token transfers uh so

00:02:36,080 --> 00:02:38,959
these are tokens on the ethereum

00:02:37,760 --> 00:02:41,519
platform that are

00:02:38,959 --> 00:02:42,720
that are uh what are called stable coins

00:02:41,519 --> 00:02:43,840
and you can see that this what's

00:02:42,720 --> 00:02:45,440
actually happening here

00:02:43,840 --> 00:02:46,879
uh let me expect to get the pointer

00:02:45,440 --> 00:02:47,519
what's actually happening here is one

00:02:46,879 --> 00:02:49,840
address

00:02:47,519 --> 00:02:51,120
is sending a transaction to many

00:02:49,840 --> 00:02:53,840
addresses

00:02:51,120 --> 00:02:55,040
so this this value here is going to many

00:02:53,840 --> 00:02:56,400
different addresses

00:02:55,040 --> 00:02:58,560
and this is kind of what we mean when we

00:02:56,400 --> 00:03:01,519
say state transition so the balance

00:02:58,560 --> 00:03:03,360
of this user has decreased and the

00:03:01,519 --> 00:03:04,239
balance of this these accounts has

00:03:03,360 --> 00:03:06,720
increased

00:03:04,239 --> 00:03:08,560
and that's kind of a state transition um

00:03:06,720 --> 00:03:10,720
another common one are swaps

00:03:08,560 --> 00:03:12,400
so on the ethereum platform you commonly

00:03:10,720 --> 00:03:14,480
are swapping one token

00:03:12,400 --> 00:03:16,159
for another token this isn't an

00:03:14,480 --> 00:03:17,760
endorsement of either of these tokens i

00:03:16,159 --> 00:03:19,920
literally just pulled this transaction

00:03:17,760 --> 00:03:22,080
fresh today i have no idea what these

00:03:19,920 --> 00:03:24,480
this is i know this is a stable coin

00:03:22,080 --> 00:03:26,080
uh which is how i found this transaction

00:03:24,480 --> 00:03:29,120
um but you can see that

00:03:26,080 --> 00:03:30,640
the the state transitions are kind of

00:03:29,120 --> 00:03:32,239
complicated in the sense that here we're

00:03:30,640 --> 00:03:34,000
going from one to another

00:03:32,239 --> 00:03:36,000
we're going through a few accounts to

00:03:34,000 --> 00:03:39,120
get to the final account

00:03:36,000 --> 00:03:39,840
um another less understood thing about

00:03:39,120 --> 00:03:42,400
ethereum

00:03:39,840 --> 00:03:44,159
is what is ether so i'm sure people have

00:03:42,400 --> 00:03:46,000
heard of ethereum and think like that's

00:03:44,159 --> 00:03:49,120
that thing i can buy on coinbase

00:03:46,000 --> 00:03:51,519
uh but ether is the uh native

00:03:49,120 --> 00:03:52,239
currency for the ethereum platform and

00:03:51,519 --> 00:03:56,080
it's how

00:03:52,239 --> 00:03:58,799
you pay for running uh

00:03:56,080 --> 00:04:00,400
code execution on the ethereum platform

00:03:58,799 --> 00:04:03,280
so it's a native currency

00:04:00,400 --> 00:04:04,879
and all of the any sort of computation

00:04:03,280 --> 00:04:08,400
that needs to be done

00:04:04,879 --> 00:04:12,159
inside of a state transition for example

00:04:08,400 --> 00:04:14,159
uh you know summing all of the balances

00:04:12,159 --> 00:04:16,079
uh or checking if the balance of the

00:04:14,159 --> 00:04:18,320
user is above a threshold

00:04:16,079 --> 00:04:19,600
those those operations just like normal

00:04:18,320 --> 00:04:22,560
computer operations

00:04:19,600 --> 00:04:23,759
have a cost associated with them uh so

00:04:22,560 --> 00:04:26,240
you can see like state

00:04:23,759 --> 00:04:27,759
saving data and loading data from the

00:04:26,240 --> 00:04:28,160
blockchain from the ethereum blockchain

00:04:27,759 --> 00:04:31,120
actually

00:04:28,160 --> 00:04:31,919
caught has a cost and it's in these gas

00:04:31,120 --> 00:04:33,440
units

00:04:31,919 --> 00:04:35,680
so you can see that everything that you

00:04:33,440 --> 00:04:36,560
do let me just not not do that to make

00:04:35,680 --> 00:04:38,080
that go away

00:04:36,560 --> 00:04:40,240
everything that you do on the ethereum

00:04:38,080 --> 00:04:43,040
platform incurs a transaction

00:04:40,240 --> 00:04:44,639
fee and those transaction fees are what

00:04:43,040 --> 00:04:47,840
incentivize people to

00:04:44,639 --> 00:04:50,639
run the ethereum blockchain software

00:04:47,840 --> 00:04:51,440
because running it requires resources

00:04:50,639 --> 00:04:54,000
okay

00:04:51,440 --> 00:04:54,960
so now i'll shift into what airflow is

00:04:54,000 --> 00:04:57,199
so airflow

00:04:54,960 --> 00:04:58,320
is a workflow management system it's a

00:04:57,199 --> 00:05:00,560
platform for

00:04:58,320 --> 00:05:02,400
programmatically authoring scheduling

00:05:00,560 --> 00:05:04,880
and monitoring workflows

00:05:02,400 --> 00:05:05,440
it's sort of an all-in-one integrated

00:05:04,880 --> 00:05:08,479
system

00:05:05,440 --> 00:05:10,400
provides a way to create workflows

00:05:08,479 --> 00:05:12,000
which are called which are typically

00:05:10,400 --> 00:05:14,639
referred to as dags

00:05:12,000 --> 00:05:15,280
uh they are directed acelica graphs so

00:05:14,639 --> 00:05:17,759
these are

00:05:15,280 --> 00:05:18,320
graphs that don't have any loops in them

00:05:17,759 --> 00:05:21,840
they run

00:05:18,320 --> 00:05:24,240
from end to end with no looping and then

00:05:21,840 --> 00:05:25,680
they're within these directed acyclic

00:05:24,240 --> 00:05:28,240
graphs or workflows

00:05:25,680 --> 00:05:28,960
you have various types of operations

00:05:28,240 --> 00:05:31,680
which we call

00:05:28,960 --> 00:05:32,720
operators and operators are what

00:05:31,680 --> 00:05:35,759
actually do

00:05:32,720 --> 00:05:39,240
the uh you know do the functionality

00:05:35,759 --> 00:05:42,479
and each operator is sort of um

00:05:39,240 --> 00:05:46,320
parameterized and when you run

00:05:42,479 --> 00:05:48,000
a workflow the operators get executed

00:05:46,320 --> 00:05:49,120
and we call the execution of the

00:05:48,000 --> 00:05:53,039
operators

00:05:49,120 --> 00:05:56,160
tasks so here are just a couple examples

00:05:53,039 --> 00:05:58,160
of uh directed acyclic graph workflows

00:05:56,160 --> 00:05:59,919
uh on this side this is an old workflow

00:05:58,160 --> 00:06:02,319
that i used to do when i was working

00:05:59,919 --> 00:06:03,840
uh previously i actually pulled this

00:06:02,319 --> 00:06:05,199
from a talk a while ago

00:06:03,840 --> 00:06:06,880
and this is the workflow that i'm going

00:06:05,199 --> 00:06:08,560
to focus on today which is what's

00:06:06,880 --> 00:06:10,880
actually happening here is

00:06:08,560 --> 00:06:12,319
we are there are two wallets and what

00:06:10,880 --> 00:06:13,680
we're doing is we're first checking the

00:06:12,319 --> 00:06:16,720
balance of a wallet

00:06:13,680 --> 00:06:18,639
and then we're sending any surplus uh to

00:06:16,720 --> 00:06:20,880
another wallet and then we're confirming

00:06:18,639 --> 00:06:22,560
that the send was successful

00:06:20,880 --> 00:06:24,800
and then we're completing it and we do

00:06:22,560 --> 00:06:27,680
this we do this workflow twice for two

00:06:24,800 --> 00:06:27,680
different wallets

00:06:27,759 --> 00:06:32,240
um so these workflows i just want to

00:06:30,560 --> 00:06:35,120
flip over here for a second yeah

00:06:32,240 --> 00:06:36,960
so these workflows uh airflow provides

00:06:35,120 --> 00:06:37,360
this really nice interface so this goes

00:06:36,960 --> 00:06:39,759
to

00:06:37,360 --> 00:06:40,880
the point about monitoring workflows uh

00:06:39,759 --> 00:06:42,880
this is the same

00:06:40,880 --> 00:06:45,120
this is the same workflow we were just

00:06:42,880 --> 00:06:47,840
looking at the two wallet check

00:06:45,120 --> 00:06:49,680
and what you see is it for each of the

00:06:47,840 --> 00:06:51,919
tasks that run in the workflow

00:06:49,680 --> 00:06:52,720
this runs every day at midnight actually

00:06:51,919 --> 00:06:54,960
it runs every day

00:06:52,720 --> 00:06:56,400
at uh right before midnight hour before

00:06:54,960 --> 00:06:58,639
midnight

00:06:56,400 --> 00:06:59,599
and you can see each of the little green

00:06:58,639 --> 00:07:02,880
squares here

00:06:59,599 --> 00:07:06,160
are the task instances for a specific

00:07:02,880 --> 00:07:08,240
workflow execution

00:07:06,160 --> 00:07:09,680
so some of the core ideas of apache

00:07:08,240 --> 00:07:11,199
airflow that we have to go over before

00:07:09,680 --> 00:07:12,720
we get to the example are some of the

00:07:11,199 --> 00:07:16,240
words i just said which is dags

00:07:12,720 --> 00:07:18,080
operators hooks and task instances

00:07:16,240 --> 00:07:19,520
so again when we talk about a dag what

00:07:18,080 --> 00:07:22,800
we're talking about is

00:07:19,520 --> 00:07:24,560
a workflow and the example that we're

00:07:22,800 --> 00:07:27,440
going to continue to use is the balance

00:07:24,560 --> 00:07:29,199
check the two wallet balance check all

00:07:27,440 --> 00:07:32,560
of the workflows that you create

00:07:29,199 --> 00:07:36,000
are written in python code and the

00:07:32,560 --> 00:07:37,280
the workflows each workflow is stored in

00:07:36,000 --> 00:07:40,560
a single python

00:07:37,280 --> 00:07:43,759
file and so i have sort of an example of

00:07:40,560 --> 00:07:44,160
my workflows i have one two three four

00:07:43,759 --> 00:07:47,440
five

00:07:44,160 --> 00:07:50,960
workflows here these are pool related

00:07:47,440 --> 00:07:54,479
activities for managing transactions and

00:07:50,960 --> 00:07:57,360
uh each one is a single python file

00:07:54,479 --> 00:07:59,280
and each file should essentially be one

00:07:57,360 --> 00:08:01,919
workflow

00:07:59,280 --> 00:08:03,919
the next little bit is the operators so

00:08:01,919 --> 00:08:04,960
operators describe a single task in a

00:08:03,919 --> 00:08:08,160
workflow

00:08:04,960 --> 00:08:11,280
they sort of map to uh

00:08:08,160 --> 00:08:13,280
you know specific specific

00:08:11,280 --> 00:08:14,879
execution so you have like a python

00:08:13,280 --> 00:08:17,919
operator and an sftp

00:08:14,879 --> 00:08:19,759
operator and mysql operator

00:08:17,919 --> 00:08:21,360
and those things essentially they either

00:08:19,759 --> 00:08:24,240
run queries or

00:08:21,360 --> 00:08:26,400
they execute python code or they you

00:08:24,240 --> 00:08:29,360
know transfer files um

00:08:26,400 --> 00:08:31,199
there is also a final type of operator

00:08:29,360 --> 00:08:33,599
which we refer to as a sensor

00:08:31,199 --> 00:08:34,640
it's a specific type of operator that

00:08:33,599 --> 00:08:36,640
actually does a

00:08:34,640 --> 00:08:37,919
it kind of does like a waiting you know

00:08:36,640 --> 00:08:40,560
it'll sort of loop

00:08:37,919 --> 00:08:42,240
until something happens and then it will

00:08:40,560 --> 00:08:44,240
it will return successfully and

00:08:42,240 --> 00:08:46,240
the ex the workflow can continue after

00:08:44,240 --> 00:08:48,720
that there is also

00:08:46,240 --> 00:08:50,080
cross communication in the workflows or

00:08:48,720 --> 00:08:52,959
in the operators

00:08:50,080 --> 00:08:54,399
there is uh apache airflow has a feature

00:08:52,959 --> 00:08:56,160
called xcom

00:08:54,399 --> 00:08:57,440
which i actually make a lot of use of

00:08:56,160 --> 00:08:59,920
even though i think the

00:08:57,440 --> 00:09:00,480
it's kind of you know a lesser known uh

00:08:59,920 --> 00:09:02,880
feature

00:09:00,480 --> 00:09:04,399
lesser used feature but you can sort of

00:09:02,880 --> 00:09:07,839
cross-communicate between

00:09:04,399 --> 00:09:08,880
workflows which i have some examples of

00:09:07,839 --> 00:09:11,920
the next idea

00:09:08,880 --> 00:09:14,399
so operators are essentially uh

00:09:11,920 --> 00:09:15,360
you know these are these are steps in

00:09:14,399 --> 00:09:17,680
the workflow

00:09:15,360 --> 00:09:18,880
but within the operators there are what

00:09:17,680 --> 00:09:20,399
are called hooks

00:09:18,880 --> 00:09:22,399
and the hooks are essentially

00:09:20,399 --> 00:09:24,720
integrations to other services

00:09:22,399 --> 00:09:26,160
so up top what i have is this is an old

00:09:24,720 --> 00:09:29,600
operator that i created

00:09:26,160 --> 00:09:32,399
which was mysql to google cloud storage

00:09:29,600 --> 00:09:33,040
basically runs a query on mysql takes

00:09:32,399 --> 00:09:35,200
the result

00:09:33,040 --> 00:09:36,880
and saves it in google cloud storage and

00:09:35,200 --> 00:09:39,839
this operator this single

00:09:36,880 --> 00:09:40,880
operator actually consists of two hooks

00:09:39,839 --> 00:09:43,040
so there's one hook

00:09:40,880 --> 00:09:44,399
into connecting to mysql and then

00:09:43,040 --> 00:09:45,360
there's another hook into connecting to

00:09:44,399 --> 00:09:47,279
google storage

00:09:45,360 --> 00:09:50,480
and the hooks are essentially reusable

00:09:47,279 --> 00:09:53,279
across other operators

00:09:50,480 --> 00:09:55,200
the the operators that i created for

00:09:53,279 --> 00:09:57,760
this ethereum use case are

00:09:55,200 --> 00:09:58,480
shown down below there are two operators

00:09:57,760 --> 00:10:01,200
one or two

00:09:58,480 --> 00:10:02,800
there's one operator and two hooks that

00:10:01,200 --> 00:10:04,959
make up that operator

00:10:02,800 --> 00:10:06,160
so the first hook is what's called a web

00:10:04,959 --> 00:10:08,880
3 hook which

00:10:06,160 --> 00:10:10,160
connects to the ethereum blockchain to

00:10:08,880 --> 00:10:12,959
execute code

00:10:10,160 --> 00:10:15,279
and then there is a ethereum wallet hook

00:10:12,959 --> 00:10:18,480
which really just connects locally

00:10:15,279 --> 00:10:21,600
to retrieve the private key

00:10:18,480 --> 00:10:23,760
for a wallet all the wallets on ethereum

00:10:21,600 --> 00:10:24,800
are backed by public private key

00:10:23,760 --> 00:10:27,760
cryptography

00:10:24,800 --> 00:10:31,040
so this is just an integration to get

00:10:27,760 --> 00:10:31,040
that private key safely

00:10:31,279 --> 00:10:34,880
um finally there's this idea of tasks

00:10:33,680 --> 00:10:36,880
and task instances

00:10:34,880 --> 00:10:38,880
like i was sort of saying before when a

00:10:36,880 --> 00:10:39,920
when a workflow executes or a dag

00:10:38,880 --> 00:10:42,560
executes

00:10:39,920 --> 00:10:43,600
the operators they get executed with

00:10:42,560 --> 00:10:46,480
parameters

00:10:43,600 --> 00:10:48,640
and those uh operator executed with

00:10:46,480 --> 00:10:50,079
parameters are referred to as a task

00:10:48,640 --> 00:10:51,839
so all these little green dots you see

00:10:50,079 --> 00:10:54,079
over here these are all tasks

00:10:51,839 --> 00:10:55,360
you can sort of see that uh you know

00:10:54,079 --> 00:10:57,760
they each sort of run

00:10:55,360 --> 00:10:59,600
independently and they can fail and they

00:10:57,760 --> 00:11:00,399
can prevent other tasks from running

00:10:59,600 --> 00:11:04,079
that's sort of the

00:11:00,399 --> 00:11:06,880
directed acyclic graph nature of it um

00:11:04,079 --> 00:11:07,519
and yeah so once they this gives you a

00:11:06,880 --> 00:11:09,040
really good

00:11:07,519 --> 00:11:11,600
monitoring feature because you can see

00:11:09,040 --> 00:11:13,519
what what exactly in the workflow failed

00:11:11,600 --> 00:11:15,519
and you can you know mitigate it after

00:11:13,519 --> 00:11:17,920
that

00:11:15,519 --> 00:11:18,720
um another important thing is airflow

00:11:17,920 --> 00:11:20,720
gives you uh

00:11:18,720 --> 00:11:22,079
centralized monitoring alerting and

00:11:20,720 --> 00:11:24,480
logging um

00:11:22,079 --> 00:11:26,000
one of the really important things about

00:11:24,480 --> 00:11:27,839
this ethereum

00:11:26,000 --> 00:11:29,920
based activity is per if you're going to

00:11:27,839 --> 00:11:31,200
automate lots of transactional ethereum

00:11:29,920 --> 00:11:33,200
you definitely don't want to have

00:11:31,200 --> 00:11:34,480
instances where you're double spending

00:11:33,200 --> 00:11:35,839
or not double spending you're

00:11:34,480 --> 00:11:36,959
essentially you're paying someone twice

00:11:35,839 --> 00:11:39,600
or you're transferring

00:11:36,959 --> 00:11:41,200
more than you wanted to um so monitoring

00:11:39,600 --> 00:11:44,480
and alerting is pretty critical for that

00:11:41,200 --> 00:11:46,320
the other uh equally bad instance uh

00:11:44,480 --> 00:11:48,079
if not actually worse because it hurts

00:11:46,320 --> 00:11:48,720
the customer more than double paying

00:11:48,079 --> 00:11:51,920
them

00:11:48,720 --> 00:11:54,079
is uh if you just don't if it just fails

00:11:51,920 --> 00:11:56,079
so uh airflow kind of gives you some

00:11:54,079 --> 00:11:58,399
features built in to kind of

00:11:56,079 --> 00:12:00,240
monitor and alert and also this is kind

00:11:58,399 --> 00:12:02,079
of important which is to retry because

00:12:00,240 --> 00:12:04,000
the way that ethereum works is when you

00:12:02,079 --> 00:12:05,600
send out a transaction to be executed

00:12:04,000 --> 00:12:06,880
sometimes it just doesn't execute

00:12:05,600 --> 00:12:08,639
because it is a peer-to-peer

00:12:06,880 --> 00:12:10,639
decentralized network and it's kind of

00:12:08,639 --> 00:12:11,440
crazy what happens on it so sometimes it

00:12:10,639 --> 00:12:13,279
fails

00:12:11,440 --> 00:12:15,440
and so there's a way to execute

00:12:13,279 --> 00:12:18,079
re-execute them

00:12:15,440 --> 00:12:18,480
um so what i have here is just a view of

00:12:18,079 --> 00:12:20,160
the

00:12:18,480 --> 00:12:21,760
logging interface it is kind of nice you

00:12:20,160 --> 00:12:23,360
can you can from the

00:12:21,760 --> 00:12:24,959
uh from each of the workflows you can

00:12:23,360 --> 00:12:26,079
just sort of get a log and you can

00:12:24,959 --> 00:12:27,279
scroll right through it so when

00:12:26,079 --> 00:12:28,720
something fails you don't have to go

00:12:27,279 --> 00:12:30,320
digging around log files it

00:12:28,720 --> 00:12:31,920
essentially provides a user interface

00:12:30,320 --> 00:12:35,200
for that which is really helpful

00:12:31,920 --> 00:12:36,720
so all right so that's all about airflow

00:12:35,200 --> 00:12:37,839
now what i want to talk about and walk

00:12:36,720 --> 00:12:38,639
people through and this is going to be

00:12:37,839 --> 00:12:41,760
very technical

00:12:38,639 --> 00:12:44,480
is a very specific example

00:12:41,760 --> 00:12:45,760
of using apache airflow in production to

00:12:44,480 --> 00:12:46,959
do something on ethereum

00:12:45,760 --> 00:12:48,959
and the thing that we're doing on

00:12:46,959 --> 00:12:52,079
ethereum is we're just

00:12:48,959 --> 00:12:53,279
transferring uh ethereum from two

00:12:52,079 --> 00:12:56,320
wallets

00:12:53,279 --> 00:12:57,680
to uh one central wallet so this is a

00:12:56,320 --> 00:12:59,839
really common use case

00:12:57,680 --> 00:13:02,000
uh which is you know you have many

00:12:59,839 --> 00:13:04,160
wallets doing many different things

00:13:02,000 --> 00:13:05,760
and on a periodic basis you wanna check

00:13:04,160 --> 00:13:07,920
the balance if there's anything

00:13:05,760 --> 00:13:08,800
surplus bring it back to the central

00:13:07,920 --> 00:13:10,000
wallet

00:13:08,800 --> 00:13:11,839
you could think of you know maybe an

00:13:10,000 --> 00:13:13,440
exchange that wants to do this i do this

00:13:11,839 --> 00:13:14,959
because i have wallets that accumulate

00:13:13,440 --> 00:13:17,279
ethereum and i want to bring all that

00:13:14,959 --> 00:13:19,839
ethereum back on a periodic basis

00:13:17,279 --> 00:13:21,600
so you sort of see before the workflow

00:13:19,839 --> 00:13:23,200
gets executed we have two wallets that

00:13:21,600 --> 00:13:25,279
have some ethereum in them

00:13:23,200 --> 00:13:26,959
and then after the exploit after the

00:13:25,279 --> 00:13:29,040
workflow gets executed

00:13:26,959 --> 00:13:30,079
we have one wallet that has all the

00:13:29,040 --> 00:13:33,120
ethereum

00:13:30,079 --> 00:13:34,560
right so the way that this sort of works

00:13:33,120 --> 00:13:35,680
this is the same workflow i was showing

00:13:34,560 --> 00:13:38,079
earlier it's a three

00:13:35,680 --> 00:13:38,880
three steps and we do it twice the first

00:13:38,079 --> 00:13:40,639
step is we

00:13:38,880 --> 00:13:42,160
check the balance of the wallet to see

00:13:40,639 --> 00:13:44,320
if there's any surplus

00:13:42,160 --> 00:13:46,720
and then after we check the wallet find

00:13:44,320 --> 00:13:48,800
surplus we then send the surplus

00:13:46,720 --> 00:13:50,399
and then after we send the surplus we

00:13:48,800 --> 00:13:53,519
actually have to wait

00:13:50,399 --> 00:13:54,399
for that transaction to be confirmed by

00:13:53,519 --> 00:13:56,720
the network

00:13:54,399 --> 00:13:58,079
these transactions could take they could

00:13:56,720 --> 00:13:59,920
take a very long time it could take

00:13:58,079 --> 00:14:01,600
several days

00:13:59,920 --> 00:14:03,519
depending on the conditions of the

00:14:01,600 --> 00:14:04,240
network it's sort of a peer-to-peer

00:14:03,519 --> 00:14:06,720
thing so

00:14:04,240 --> 00:14:08,160
you kind of have to wait for it and then

00:14:06,720 --> 00:14:10,000
once both of these finish

00:14:08,160 --> 00:14:12,160
then we just essentially say that we're

00:14:10,000 --> 00:14:13,199
done and you know the done job just

00:14:12,160 --> 00:14:16,079
really

00:14:13,199 --> 00:14:18,399
marks everything as successful in the

00:14:16,079 --> 00:14:21,600
code in the in the python code for this

00:14:18,399 --> 00:14:24,000
workflow you essentially have three

00:14:21,600 --> 00:14:26,079
operators that get executed the first is

00:14:24,000 --> 00:14:27,440
a python operator which just executes

00:14:26,079 --> 00:14:29,680
some python code

00:14:27,440 --> 00:14:31,839
and then the second two operators are

00:14:29,680 --> 00:14:32,320
some reusable operators i created which

00:14:31,839 --> 00:14:35,360
are

00:14:32,320 --> 00:14:37,760
the ethereum send erc20 operator

00:14:35,360 --> 00:14:38,720
which actually sends tokens or sends

00:14:37,760 --> 00:14:40,880
ethereum

00:14:38,720 --> 00:14:41,839
and then we have an ethereum transaction

00:14:40,880 --> 00:14:44,399
confirmation

00:14:41,839 --> 00:14:46,320
sensor which is a type of operator like

00:14:44,399 --> 00:14:48,720
i said earlier that senses

00:14:46,320 --> 00:14:50,560
whether something is happened and then

00:14:48,720 --> 00:14:52,240
after the sensing is confirmed

00:14:50,560 --> 00:14:54,480
after it you know after it senses that

00:14:52,240 --> 00:14:56,240
that happens then it just continues

00:14:54,480 --> 00:14:58,240
so you can see both of these workflows

00:14:56,240 --> 00:15:01,440
they basically have the sensor built

00:14:58,240 --> 00:15:03,440
in so that after we send the transaction

00:15:01,440 --> 00:15:04,959
we have to wait for it to be confirmed

00:15:03,440 --> 00:15:07,199
and then after it's confirmed

00:15:04,959 --> 00:15:08,959
then we can say that we're done and both

00:15:07,199 --> 00:15:09,839
of these because of the way that this is

00:15:08,959 --> 00:15:12,880
set up

00:15:09,839 --> 00:15:14,560
both of these have to complete in order

00:15:12,880 --> 00:15:17,279
for this to complete successfully

00:15:14,560 --> 00:15:19,199
if one of these branches fails then this

00:15:17,279 --> 00:15:21,680
also this job will also fail

00:15:19,199 --> 00:15:23,600
sort of a downstream failure so you can

00:15:21,680 --> 00:15:26,000
see the directed acyclic graph nature

00:15:23,600 --> 00:15:28,240
sort of creates these dependencies

00:15:26,000 --> 00:15:29,680
so and this is just one of the branches

00:15:28,240 --> 00:15:31,440
so there's actually this code gets

00:15:29,680 --> 00:15:33,120
repeated again

00:15:31,440 --> 00:15:35,600
with like two and then you have your

00:15:33,120 --> 00:15:37,759
second branch

00:15:35,600 --> 00:15:40,160
so let's start by looking at the python

00:15:37,759 --> 00:15:42,399
operator piece

00:15:40,160 --> 00:15:43,839
so this is what a python operator

00:15:42,399 --> 00:15:45,680
essentially looks like

00:15:43,839 --> 00:15:47,519
the way that the python operator works

00:15:45,680 --> 00:15:48,959
is and this is probably the basic thing

00:15:47,519 --> 00:15:50,720
that you can do in apache airflow which

00:15:48,959 --> 00:15:51,440
is you can just do everything in python

00:15:50,720 --> 00:15:52,560
operators

00:15:51,440 --> 00:15:54,320
you don't need to use any of the other

00:15:52,560 --> 00:15:55,920
operators you can just wrap some python

00:15:54,320 --> 00:15:58,000
code in a python operator

00:15:55,920 --> 00:15:59,920
and execute it the symbolist job would

00:15:58,000 --> 00:16:02,320
just be like a one-step

00:15:59,920 --> 00:16:03,279
workflow that's just executing some

00:16:02,320 --> 00:16:05,519
python code

00:16:03,279 --> 00:16:06,959
and that kind of functions as cron but

00:16:05,519 --> 00:16:08,399
what you can see is essentially up here

00:16:06,959 --> 00:16:10,240
with the check balance

00:16:08,399 --> 00:16:11,839
what we're doing is we're passing that

00:16:10,240 --> 00:16:14,560
check balance in

00:16:11,839 --> 00:16:15,279
as a python callable to the python

00:16:14,560 --> 00:16:17,120
operator

00:16:15,279 --> 00:16:19,920
and that python operator is going to get

00:16:17,120 --> 00:16:23,040
called by the airflow scheduler

00:16:19,920 --> 00:16:24,800
and it will execute this python code

00:16:23,040 --> 00:16:27,120
the other thing you'll notice is that we

00:16:24,800 --> 00:16:30,959
can actually sort of parameterize it

00:16:27,120 --> 00:16:33,120
so in the setup this function is written

00:16:30,959 --> 00:16:34,800
once but it's executed many times we

00:16:33,120 --> 00:16:36,720
have check one check two check three as

00:16:34,800 --> 00:16:39,600
many checks as we want

00:16:36,720 --> 00:16:41,680
and each time we can specify a specific

00:16:39,600 --> 00:16:44,240
address that we want to check

00:16:41,680 --> 00:16:44,800
um using this you know arguments passing

00:16:44,240 --> 00:16:47,600
method

00:16:44,800 --> 00:16:49,680
so you can sort of see the context here

00:16:47,600 --> 00:16:53,360
gives us a way to key into the

00:16:49,680 --> 00:16:55,040
dictionary down here to get the address

00:16:53,360 --> 00:16:56,800
all right so that's the python operator

00:16:55,040 --> 00:17:00,160
the next operator is the

00:16:56,800 --> 00:17:01,519
send operator so we send erc20 token

00:17:00,160 --> 00:17:03,600
operator

00:17:01,519 --> 00:17:05,919
the way the way that this kind of works

00:17:03,600 --> 00:17:07,280
this like i said this operator is custom

00:17:05,919 --> 00:17:09,679
so i'm gonna have to walk through how it

00:17:07,280 --> 00:17:11,839
was constructed as sort of an example

00:17:09,679 --> 00:17:13,919
um it's consisting of three components

00:17:11,839 --> 00:17:15,679
we have the connection we have the hook

00:17:13,919 --> 00:17:17,280
which connects us to the ethereal

00:17:15,679 --> 00:17:19,360
blockchain and then we have the other

00:17:17,280 --> 00:17:20,880
hook which connects us to the wallet

00:17:19,360 --> 00:17:23,199
which you can think of the wallet is

00:17:20,880 --> 00:17:26,480
just a username and password

00:17:23,199 --> 00:17:27,199
it's a public and private key so let's

00:17:26,480 --> 00:17:30,640
look at the

00:17:27,199 --> 00:17:32,400
ethereum wallet hook part first

00:17:30,640 --> 00:17:34,400
the other nice thing about apache

00:17:32,400 --> 00:17:35,200
airflow is it gives you a user interface

00:17:34,400 --> 00:17:38,160
for managing

00:17:35,200 --> 00:17:38,799
connections and secrets for connections

00:17:38,160 --> 00:17:41,840
and

00:17:38,799 --> 00:17:43,600
in your hooks you can actually

00:17:41,840 --> 00:17:45,679
go in and grab that connection

00:17:43,600 --> 00:17:47,120
information so if you look this

00:17:45,679 --> 00:17:49,440
this wallet hook is actually really

00:17:47,120 --> 00:17:52,559
simple all it's doing is actually

00:17:49,440 --> 00:17:53,679
on the uh on itself it's just setting

00:17:52,559 --> 00:17:56,240
two properties

00:17:53,679 --> 00:17:56,880
it's setting its public key to be equal

00:17:56,240 --> 00:17:59,360
to the

00:17:56,880 --> 00:18:00,559
connection login which is this value

00:17:59,360 --> 00:18:03,840
here

00:18:00,559 --> 00:18:04,640
and it's setting the private key to be

00:18:03,840 --> 00:18:07,360
the connection

00:18:04,640 --> 00:18:08,960
password which is this value down here

00:18:07,360 --> 00:18:11,840
so we set both of the key

00:18:08,960 --> 00:18:13,120
the public key and the password and the

00:18:11,840 --> 00:18:13,600
nice thing about this is we don't need

00:18:13,120 --> 00:18:15,440
to

00:18:13,600 --> 00:18:17,039
you know code our path we don't need to

00:18:15,440 --> 00:18:19,120
put our private key somewhere

00:18:17,039 --> 00:18:21,120
there's already a safe place for us to

00:18:19,120 --> 00:18:22,799
put it which is encrypted and saved like

00:18:21,120 --> 00:18:25,280
all passwords should be saved

00:18:22,799 --> 00:18:26,880
uh in a database for ourselves which is

00:18:25,280 --> 00:18:29,120
much better than you know maybe putting

00:18:26,880 --> 00:18:30,080
a file and loading it up but not as good

00:18:29,120 --> 00:18:31,919
as some other things there are some

00:18:30,080 --> 00:18:33,039
other ways to secure them

00:18:31,919 --> 00:18:35,360
all right so let's look at the other

00:18:33,039 --> 00:18:37,120
side of it which is the the connection

00:18:35,360 --> 00:18:38,559
to the ethereum blockchain

00:18:37,120 --> 00:18:40,559
so the connection to the ethereum

00:18:38,559 --> 00:18:41,760
blockchain we use we use the same

00:18:40,559 --> 00:18:45,440
connections

00:18:41,760 --> 00:18:45,440
interface where we basically

00:18:45,520 --> 00:18:48,720
we have the same connections sorry my

00:18:47,280 --> 00:18:50,640
mouse is like freaking out

00:18:48,720 --> 00:18:52,640
we have the same connection interface

00:18:50,640 --> 00:18:55,200
where we create these connections

00:18:52,640 --> 00:18:56,000
and we specify some information about

00:18:55,200 --> 00:18:58,400
the connection

00:18:56,000 --> 00:18:59,840
in this case the secret here these are

00:18:58,400 --> 00:19:02,080
api keys

00:18:59,840 --> 00:19:03,679
um so they're a little not quite as

00:19:02,080 --> 00:19:05,840
secret as the private keys

00:19:03,679 --> 00:19:07,280
so we can just put them in this uh you

00:19:05,840 --> 00:19:09,039
know this extras field

00:19:07,280 --> 00:19:10,320
there's also not kind of a clear place

00:19:09,039 --> 00:19:12,080
up here where it would put it

00:19:10,320 --> 00:19:13,760
like the private key it's obviously the

00:19:12,080 --> 00:19:14,559
login and password that makes that's a

00:19:13,760 --> 00:19:16,960
good parallel

00:19:14,559 --> 00:19:18,160
but down here the x these are basically

00:19:16,960 --> 00:19:20,799
uh you know

00:19:18,160 --> 00:19:22,960
end points with pr with api keys so we

00:19:20,799 --> 00:19:24,400
sort of wrap them in here

00:19:22,960 --> 00:19:25,919
and then the way it works is it's a very

00:19:24,400 --> 00:19:27,520
similar structure all we're doing here

00:19:25,919 --> 00:19:29,600
we're doing one extra step

00:19:27,520 --> 00:19:32,720
we first set two properties right so we

00:19:29,600 --> 00:19:35,840
set the http endpoint and we set the

00:19:32,720 --> 00:19:36,480
websockets endpoint and then what we do

00:19:35,840 --> 00:19:39,679
is we

00:19:36,480 --> 00:19:41,840
import a python package called web3

00:19:39,679 --> 00:19:44,080
which is a python package that supports

00:19:41,840 --> 00:19:47,280
interfacing with the ethereum blockchain

00:19:44,080 --> 00:19:49,600
clients over our pc connection

00:19:47,280 --> 00:19:51,760
and what we do is we just initialize

00:19:49,600 --> 00:19:54,799
instances of those connections

00:19:51,760 --> 00:19:55,200
so we initialize a web3 connection for

00:19:54,799 --> 00:19:58,160
the

00:19:55,200 --> 00:19:58,880
websocket and we can initialize a web3

00:19:58,160 --> 00:20:02,720
connection

00:19:58,880 --> 00:20:04,880
with the http provider

00:20:02,720 --> 00:20:06,960
all right so that's the two integration

00:20:04,880 --> 00:20:07,760
points and then what we have is we have

00:20:06,960 --> 00:20:10,400
the actual

00:20:07,760 --> 00:20:11,919
operator that does the work so this is a

00:20:10,400 --> 00:20:13,600
little messy i'll walk we'll sort of

00:20:11,919 --> 00:20:16,080
walk through it step by step

00:20:13,600 --> 00:20:17,120
um the first part of this is actually

00:20:16,080 --> 00:20:19,120
there's sort of two

00:20:17,120 --> 00:20:21,039
two parts to this but when you create an

00:20:19,120 --> 00:20:23,200
operator as you kind of saw with the

00:20:21,039 --> 00:20:24,960
python operator there are all of these

00:20:23,200 --> 00:20:26,880
properties these sort of reusable

00:20:24,960 --> 00:20:28,960
properties that you can initialize

00:20:26,880 --> 00:20:30,480
so you see we specify things like the

00:20:28,960 --> 00:20:33,360
contract address

00:20:30,480 --> 00:20:34,559
the pool wallet address and we also

00:20:33,360 --> 00:20:36,880
specify

00:20:34,559 --> 00:20:38,720
which ethereum wallet we want to use so

00:20:36,880 --> 00:20:39,360
this is saying the wallet we created

00:20:38,720 --> 00:20:41,120
earlier

00:20:39,360 --> 00:20:42,880
was called pool wallet one so we're

00:20:41,120 --> 00:20:45,679
going to create pool wallet one

00:20:42,880 --> 00:20:48,159
and the other uh connection that we want

00:20:45,679 --> 00:20:50,080
to use is our inferior connection and

00:20:48,159 --> 00:20:51,760
what happens is the first step of all

00:20:50,080 --> 00:20:53,679
the operators is essentially just to

00:20:51,760 --> 00:20:56,320
initialize all the properties

00:20:53,679 --> 00:20:57,440
that are going to get used later the

00:20:56,320 --> 00:21:00,240
next step of all

00:20:57,440 --> 00:21:01,039
operators is they all have a execute

00:21:00,240 --> 00:21:03,360
function

00:21:01,039 --> 00:21:05,200
so this is sort of the the pattern the

00:21:03,360 --> 00:21:07,520
design pattern and airflow is

00:21:05,200 --> 00:21:09,039
you inherit from the base operator the

00:21:07,520 --> 00:21:11,919
base operator gives you

00:21:09,039 --> 00:21:13,760
all sorts of functionality but the idea

00:21:11,919 --> 00:21:16,480
is that you're going to override

00:21:13,760 --> 00:21:18,159
the execute method in the base operator

00:21:16,480 --> 00:21:19,120
the base operator doesn't implement an

00:21:18,159 --> 00:21:21,360
execute method

00:21:19,120 --> 00:21:23,679
you have to implement the execute method

00:21:21,360 --> 00:21:27,120
so all of the python code that goes

00:21:23,679 --> 00:21:28,559
to executing this transaction

00:21:27,120 --> 00:21:30,320
or doing whatever the operator is going

00:21:28,559 --> 00:21:33,440
to be designed to do all of that

00:21:30,320 --> 00:21:35,440
goes in the execute function here and

00:21:33,440 --> 00:21:36,960
you're overriding or you're essentially

00:21:35,440 --> 00:21:38,960
implementing but it's really kind of an

00:21:36,960 --> 00:21:40,320
over it's an override

00:21:38,960 --> 00:21:42,559
you're overriding something that just

00:21:40,320 --> 00:21:43,039
raises an exception but anyway you put

00:21:42,559 --> 00:21:46,159
all the

00:21:43,039 --> 00:21:47,679
code that you want in here

00:21:46,159 --> 00:21:49,280
so if you remember earlier what i was

00:21:47,679 --> 00:21:51,360
saying was you use

00:21:49,280 --> 00:21:52,400
hooks to sort of do the integration and

00:21:51,360 --> 00:21:54,960
then the operator

00:21:52,400 --> 00:21:55,520
implements those hooks so if you notice

00:21:54,960 --> 00:21:58,480
here

00:21:55,520 --> 00:22:00,080
we are importing the two hooks that we

00:21:58,480 --> 00:22:01,440
use

00:22:00,080 --> 00:22:03,600
the code actually if you look at the

00:22:01,440 --> 00:22:07,679
line numbers this bit of code

00:22:03,600 --> 00:22:09,039
is not in this this is one file

00:22:07,679 --> 00:22:11,280
and then this little bit of code is

00:22:09,039 --> 00:22:14,240
actually what you saw earlier

00:22:11,280 --> 00:22:15,600
just expanded so these are all one file

00:22:14,240 --> 00:22:19,039
if you sort of see it's 20

00:22:15,600 --> 00:22:21,600
line 29 continues up here line 29 so

00:22:19,039 --> 00:22:22,480
we import the hooks that we created

00:22:21,600 --> 00:22:24,720
earlier

00:22:22,480 --> 00:22:27,200
and this time around all we do is we're

00:22:24,720 --> 00:22:29,280
not we're not re-writing the code to

00:22:27,200 --> 00:22:31,039
initialize our web3 connection

00:22:29,280 --> 00:22:32,880
and we're not rewriting the code to get

00:22:31,039 --> 00:22:35,360
the ethereum wallet address

00:22:32,880 --> 00:22:36,320
we're just initializing instances of the

00:22:35,360 --> 00:22:39,120
hooks

00:22:36,320 --> 00:22:40,159
and then that gives us an ability to get

00:22:39,120 --> 00:22:43,360
some of the information

00:22:40,159 --> 00:22:46,240
about the hooks later and use the

00:22:43,360 --> 00:22:48,720
um the objects that are created inside

00:22:46,240 --> 00:22:48,720
the hooks

00:22:48,799 --> 00:22:52,240
so the two objects that we create from

00:22:50,559 --> 00:22:54,720
the hooks one is

00:22:52,240 --> 00:22:56,480
the web 3 connection object which lets

00:22:54,720 --> 00:22:58,640
us interface with ethereum

00:22:56,480 --> 00:23:00,960
the other object is the wallet address

00:22:58,640 --> 00:23:03,600
or the wallet object which has a

00:23:00,960 --> 00:23:04,880
public addre a public address and a

00:23:03,600 --> 00:23:06,799
private key

00:23:04,880 --> 00:23:09,039
and if you see what we're doing here is

00:23:06,799 --> 00:23:10,880
we're actually creating the transaction

00:23:09,039 --> 00:23:13,760
for the ethereum blockchain to be

00:23:10,880 --> 00:23:15,039
executed we are signing that transaction

00:23:13,760 --> 00:23:16,400
with our private key

00:23:15,039 --> 00:23:18,080
to indicate that it's ready to be

00:23:16,400 --> 00:23:20,400
executed or that

00:23:18,080 --> 00:23:22,720
to indicate that we can execute it we

00:23:20,400 --> 00:23:25,360
are signing our own transaction

00:23:22,720 --> 00:23:27,440
um and then down below we actually

00:23:25,360 --> 00:23:30,000
broadcast the transaction out to the

00:23:27,440 --> 00:23:30,000
blockchain

00:23:31,280 --> 00:23:35,679
so the last little bit here is the send

00:23:33,840 --> 00:23:36,159
confirmation so after we broadcast it

00:23:35,679 --> 00:23:38,640
out

00:23:36,159 --> 00:23:40,000
we want to confirm that it was sent and

00:23:38,640 --> 00:23:42,720
this is where we use

00:23:40,000 --> 00:23:45,360
the the pattern called a sensor so

00:23:42,720 --> 00:23:48,400
sensors are just subsets of operators

00:23:45,360 --> 00:23:50,159
the a sensor is an operator it's just a

00:23:48,400 --> 00:23:54,000
special implementation of an

00:23:50,159 --> 00:23:55,760
operator so here is the the confirmation

00:23:54,000 --> 00:23:58,640
sensor operator

00:23:55,760 --> 00:23:59,679
code it inherits from the base sensor

00:23:58,640 --> 00:24:02,480
operator

00:23:59,679 --> 00:24:04,480
and the base sensor operator has an

00:24:02,480 --> 00:24:05,360
execute function that looks a lot like

00:24:04,480 --> 00:24:08,880
this

00:24:05,360 --> 00:24:12,000
where it basically says in the execution

00:24:08,880 --> 00:24:15,120
while the the poke

00:24:12,000 --> 00:24:16,640
uh method does not return true so while

00:24:15,120 --> 00:24:18,559
poke returns false

00:24:16,640 --> 00:24:19,919
we're just going to keep looping and try

00:24:18,559 --> 00:24:22,880
it again later

00:24:19,919 --> 00:24:24,400
so it's appropriately named there is a

00:24:22,880 --> 00:24:25,840
poke function

00:24:24,400 --> 00:24:27,840
and what the poke function is

00:24:25,840 --> 00:24:29,919
responsible for doing in a sensor is it

00:24:27,840 --> 00:24:32,159
either returns true or false

00:24:29,919 --> 00:24:33,360
depending on whether or not the sensor

00:24:32,159 --> 00:24:35,919
has sensed

00:24:33,360 --> 00:24:36,720
what it is looking for in this case what

00:24:35,919 --> 00:24:39,279
we're sensing

00:24:36,720 --> 00:24:40,880
is we're sensing whether the transaction

00:24:39,279 --> 00:24:42,559
was confirmed

00:24:40,880 --> 00:24:44,880
the way that this works is we actually

00:24:42,559 --> 00:24:49,600
pick up the transaction

00:24:44,880 --> 00:24:52,320
from the xcom which is sort of a shared

00:24:49,600 --> 00:24:53,840
memory location within airflow that you

00:24:52,320 --> 00:24:56,080
can put data

00:24:53,840 --> 00:24:57,039
and we specifically are getting the

00:24:56,080 --> 00:24:59,919
transaction

00:24:57,039 --> 00:25:01,679
hash from the previous step and then

00:24:59,919 --> 00:25:02,880
what we do is we actually are just here

00:25:01,679 --> 00:25:05,600
we're just sort of checking the

00:25:02,880 --> 00:25:07,279
transaction to see if it's been executed

00:25:05,600 --> 00:25:08,880
uh we're seeing how many confirmations

00:25:07,279 --> 00:25:10,559
there are uh if

00:25:08,880 --> 00:25:12,720
if there are errors then we basically

00:25:10,559 --> 00:25:14,960
say there are no confirmations

00:25:12,720 --> 00:25:16,559
transaction not found being the primary

00:25:14,960 --> 00:25:19,279
exception that's happening

00:25:16,559 --> 00:25:19,679
um and then what we do is at the bottom

00:25:19,279 --> 00:25:21,600
if you

00:25:19,679 --> 00:25:23,440
let the thing go away is we just make

00:25:21,600 --> 00:25:24,640
sure that there are more confirmations

00:25:23,440 --> 00:25:26,960
than our threshold

00:25:24,640 --> 00:25:29,360
usually you could use one as a threshold

00:25:26,960 --> 00:25:31,360
but two i usually use two as a threshold

00:25:29,360 --> 00:25:33,520
um so you can wait until two

00:25:31,360 --> 00:25:35,200
confirmations on the blockchain

00:25:33,520 --> 00:25:37,360
which means two blocks have been added

00:25:35,200 --> 00:25:40,720
on top of your your execution

00:25:37,360 --> 00:25:42,240
um and that will sort of allow you to

00:25:40,720 --> 00:25:44,240
know that the transaction has been

00:25:42,240 --> 00:25:45,120
completed okay all right so here's the

00:25:44,240 --> 00:25:46,880
poke function

00:25:45,120 --> 00:25:48,400
and the poke function returns a true

00:25:46,880 --> 00:25:51,520
false statement uh

00:25:48,400 --> 00:25:52,480
and then in the execute function of the

00:25:51,520 --> 00:25:55,600
operator

00:25:52,480 --> 00:25:57,360
it's just basically checking while the

00:25:55,600 --> 00:25:59,200
poke has not returned true

00:25:57,360 --> 00:26:01,520
just keep executing and check back on it

00:25:59,200 --> 00:26:01,520
later

00:26:01,679 --> 00:26:05,440
um so i you know one of the things i

00:26:03,840 --> 00:26:06,000
always end with as i kind of wrap up

00:26:05,440 --> 00:26:08,320
here is

00:26:06,000 --> 00:26:10,000
there are other alternatives for

00:26:08,320 --> 00:26:11,919
workflow management and

00:26:10,000 --> 00:26:13,760
kind of execution so you know some of

00:26:11,919 --> 00:26:17,120
them nifi beam

00:26:13,760 --> 00:26:18,960
uh spotify has a project called luigi um

00:26:17,120 --> 00:26:20,240
these are really good projects the thing

00:26:18,960 --> 00:26:23,679
about airflow is it's not

00:26:20,240 --> 00:26:25,200
streaming so in my work my use case here

00:26:23,679 --> 00:26:27,039
it wasn't really

00:26:25,200 --> 00:26:28,960
you know these aren't i don't need a

00:26:27,039 --> 00:26:29,919
like a fire i'm not reading data out of

00:26:28,960 --> 00:26:32,320
a fire hose

00:26:29,919 --> 00:26:34,000
here i'm just doing workflows um i'm not

00:26:32,320 --> 00:26:34,799
executing a lot of workflows either i

00:26:34,000 --> 00:26:36,400
mean

00:26:34,799 --> 00:26:38,000
i'm doing maybe like five or six

00:26:36,400 --> 00:26:41,039
transactions a day or something

00:26:38,000 --> 00:26:43,600
like not even that many transactions um

00:26:41,039 --> 00:26:44,480
but so so the the use case for airflow

00:26:43,600 --> 00:26:46,159
is actually

00:26:44,480 --> 00:26:48,000
a little bit better here you wouldn't

00:26:46,159 --> 00:26:48,720
want to if i was doing the reverse which

00:26:48,000 --> 00:26:50,840
was

00:26:48,720 --> 00:26:53,039
kind of monitoring the ethereum

00:26:50,840 --> 00:26:54,720
blockchain and

00:26:53,039 --> 00:26:56,159
waiting for something to happen and then

00:26:54,720 --> 00:26:58,320
kicking off some work

00:26:56,159 --> 00:27:00,159
then a better use a better tool might be

00:26:58,320 --> 00:27:02,240
one of these streaming solutions

00:27:00,159 --> 00:27:03,919
um but as far as workflow management

00:27:02,240 --> 00:27:06,400
where i'm just executing essentially i'm

00:27:03,919 --> 00:27:08,559
just executing code on a cron job

00:27:06,400 --> 00:27:09,919
this is the airflow just gives you like

00:27:08,559 --> 00:27:12,159
one level a much

00:27:09,919 --> 00:27:13,200
better level of you know monitoring

00:27:12,159 --> 00:27:15,360
alerting

00:27:13,200 --> 00:27:16,960
code management than it would be if you

00:27:15,360 --> 00:27:18,080
did crowd jump and i've seen a lot of

00:27:16,960 --> 00:27:20,480
cron job

00:27:18,080 --> 00:27:21,840
and you know this is it as easy as it is

00:27:20,480 --> 00:27:23,200
to set up a crown job you can just set

00:27:21,840 --> 00:27:26,159
up airflow with one

00:27:23,200 --> 00:27:27,360
uh you know one task or one one operator

00:27:26,159 --> 00:27:30,320
so

00:27:27,360 --> 00:27:30,880
um the other thing is for for uh for

00:27:30,320 --> 00:27:33,440
airflow

00:27:30,880 --> 00:27:35,440
specifically the the main thing that

00:27:33,440 --> 00:27:37,039
always sells me on it is that one i'm

00:27:35,440 --> 00:27:39,440
just really comfortable with airflow's

00:27:37,039 --> 00:27:40,880
uh programming model i found i've

00:27:39,440 --> 00:27:43,520
explored beam

00:27:40,880 --> 00:27:45,360
beam i explored pretty in-depth i just

00:27:43,520 --> 00:27:48,320
the programming model to me

00:27:45,360 --> 00:27:49,600
just never really clicked and so i as as

00:27:48,320 --> 00:27:51,679
much as i wanted to use it

00:27:49,600 --> 00:27:52,799
i never really picked it up because i

00:27:51,679 --> 00:27:54,159
found the programming model just a

00:27:52,799 --> 00:27:55,360
little different i mean it works it's

00:27:54,159 --> 00:27:57,440
great but

00:27:55,360 --> 00:27:58,880
the programming model i understand for

00:27:57,440 --> 00:28:00,399
airflow really well which is why i tend

00:27:58,880 --> 00:28:01,679
to gravitate towards it

00:28:00,399 --> 00:28:03,600
um and then the other thing about

00:28:01,679 --> 00:28:05,679
airflow is the python it

00:28:03,600 --> 00:28:06,880
you can pretty much wrap any python code

00:28:05,679 --> 00:28:08,960
in an operator

00:28:06,880 --> 00:28:11,279
um so that's really helpful it's super

00:28:08,960 --> 00:28:12,880
easy if you already have existing python

00:28:11,279 --> 00:28:14,840
code it's really easy to just wrap it up

00:28:12,880 --> 00:28:17,679
and and deploy it and monitor

00:28:14,840 --> 00:28:18,799
airflow um the other thing for iot

00:28:17,679 --> 00:28:20,559
stakeholders i mean

00:28:18,799 --> 00:28:22,640
yeah there's a couple selling points

00:28:20,559 --> 00:28:23,520
which is that you basically integrate

00:28:22,640 --> 00:28:25,520
any system that

00:28:23,520 --> 00:28:27,200
with python like anything that you can

00:28:25,520 --> 00:28:27,600
integrate with python you can wrap into

00:28:27,200 --> 00:28:29,600
the

00:28:27,600 --> 00:28:30,799
airflow programming model and kind of

00:28:29,600 --> 00:28:33,279
get this

00:28:30,799 --> 00:28:34,159
get this workflow the other thing is

00:28:33,279 --> 00:28:36,240
sort of

00:28:34,159 --> 00:28:38,159
automate deployment of workflows and you

00:28:36,240 --> 00:28:40,559
have i used to do a lot of this where

00:28:38,159 --> 00:28:42,000
you have you know once i have a workflow

00:28:40,559 --> 00:28:44,080
i might have to do that same workflow

00:28:42,000 --> 00:28:46,000
many times with different parameters and

00:28:44,080 --> 00:28:47,279
airflow makes it really nice and easy to

00:28:46,000 --> 00:28:49,919
sort of convert

00:28:47,279 --> 00:28:52,080
to build airflows or to build workflows

00:28:49,919 --> 00:28:54,000
using like yaml files

00:28:52,080 --> 00:28:56,000
just because it is python code you can

00:28:54,000 --> 00:28:59,520
kind of dynamically

00:28:56,000 --> 00:29:01,520
render a workflow and then of course the

00:28:59,520 --> 00:29:04,000
centralized monitoring and alerting

00:29:01,520 --> 00:29:05,679
uh is also a huge added benefit

00:29:04,000 --> 00:29:08,720
something that really gets missed

00:29:05,679 --> 00:29:11,039
uh a lot so um so yeah that that's

00:29:08,720 --> 00:29:13,200
that's the talk here so i appreciate

00:29:11,039 --> 00:29:14,480
everyone uh coming and looking i i know

00:29:13,200 --> 00:29:15,760
we have we have i tried to

00:29:14,480 --> 00:29:17,279
leave some time because i'm sure people

00:29:15,760 --> 00:29:17,919
might have questions about specific

00:29:17,279 --> 00:29:20,799
parts

00:29:17,919 --> 00:29:22,559
so let me just flip over now i can see

00:29:20,799 --> 00:29:24,559
the chat so let me see all right

00:29:22,559 --> 00:29:25,679
how do you assure idiom potency of the

00:29:24,559 --> 00:29:29,120
workflow

00:29:25,679 --> 00:29:31,120
yeah so it's really on you to do that

00:29:29,120 --> 00:29:32,960
uh like the way that i do it is

00:29:31,120 --> 00:29:34,799
essentially usually it's just putting

00:29:32,960 --> 00:29:36,880
things into a database and checking

00:29:34,799 --> 00:29:39,360
that things didn't happen there isn't

00:29:36,880 --> 00:29:40,080
any controls or protections that airflow

00:29:39,360 --> 00:29:42,480
gives you

00:29:40,080 --> 00:29:43,440
it's really your responsibility to do it

00:29:42,480 --> 00:29:45,360
it's a design

00:29:43,440 --> 00:29:47,360
requirement when you make a workflow to

00:29:45,360 --> 00:29:49,200
make sure that they're item potent

00:29:47,360 --> 00:29:51,039
um you know one way to do it would

00:29:49,200 --> 00:29:53,360
essentially just be that

00:29:51,039 --> 00:29:54,399
you know check for failures and then if

00:29:53,360 --> 00:29:56,799
there are failures

00:29:54,399 --> 00:29:57,919
log them i have a i have a workflow

00:29:56,799 --> 00:30:01,039
where essentially

00:29:57,919 --> 00:30:02,000
it sends transact it sends ethereum to

00:30:01,039 --> 00:30:04,799
miners

00:30:02,000 --> 00:30:05,840
and part of that workflow is it will

00:30:04,799 --> 00:30:09,360
actually

00:30:05,840 --> 00:30:10,240
uh it'll actually just check ahead of

00:30:09,360 --> 00:30:12,880
time

00:30:10,240 --> 00:30:13,679
if the record has already been marked as

00:30:12,880 --> 00:30:15,279
paid

00:30:13,679 --> 00:30:17,600
then don't send it again so it's

00:30:15,279 --> 00:30:19,840
basically a sensor in the beginning

00:30:17,600 --> 00:30:21,039
that just says like has this already

00:30:19,840 --> 00:30:24,000
been executed

00:30:21,039 --> 00:30:25,279
if it hasn't then don't execute it and

00:30:24,000 --> 00:30:28,720
in those cases when i

00:30:25,279 --> 00:30:29,440
check the uh the sensor the sensor is

00:30:28,720 --> 00:30:32,480
essentially

00:30:29,440 --> 00:30:32,799
it it won't come back as a failure it

00:30:32,480 --> 00:30:34,559
just

00:30:32,799 --> 00:30:36,080
if it if it doesn't sense that it's

00:30:34,559 --> 00:30:39,120
executed it just hangs

00:30:36,080 --> 00:30:40,880
and someone has to manually intervene

00:30:39,120 --> 00:30:42,240
and then there are a few command line

00:30:40,880 --> 00:30:45,039
tools that give you like a

00:30:42,240 --> 00:30:46,080
a way to kind of manually rerun specific

00:30:45,039 --> 00:30:47,840
tasks

00:30:46,080 --> 00:30:49,520
and if you set up airflow correctly you

00:30:47,840 --> 00:30:51,520
can actually rerun specific tasks

00:30:49,520 --> 00:30:53,279
through the interface

00:30:51,520 --> 00:30:54,640
it just depends on how you set it up you

00:30:53,279 --> 00:30:57,919
have to use like a

00:30:54,640 --> 00:31:00,399
a an executor like celery or kubernetes

00:30:57,919 --> 00:31:02,720
and then you can kind of click to rerun

00:31:00,399 --> 00:31:04,320
tasks

00:31:02,720 --> 00:31:05,840
yeah are there any other questions that

00:31:04,320 --> 00:31:06,640
was that's always a really good question

00:31:05,840 --> 00:31:08,480
which is

00:31:06,640 --> 00:31:10,080
how do you confirm the idiopotency of

00:31:08,480 --> 00:31:11,679
the tran of the transaction it's really

00:31:10,080 --> 00:31:14,240
on you as the engineer

00:31:11,679 --> 00:31:15,519
doing as a designer to you know track

00:31:14,240 --> 00:31:16,640
things and make sure that you're not

00:31:15,519 --> 00:31:18,640
rerunning them

00:31:16,640 --> 00:31:20,080
i do it in a database i have a postgres

00:31:18,640 --> 00:31:23,039
database where i keep a lot of the

00:31:20,080 --> 00:31:24,720
results for this so the workflow that i

00:31:23,039 --> 00:31:26,480
just did if it fails

00:31:24,720 --> 00:31:27,760
it doesn't because it's doing the check

00:31:26,480 --> 00:31:29,760
balance in the beginning

00:31:27,760 --> 00:31:32,240
that workflow doesn't have any instances

00:31:29,760 --> 00:31:33,440
where it might double spend because what

00:31:32,240 --> 00:31:36,399
it'll do is it'll

00:31:33,440 --> 00:31:36,880
if the first workflow flows through and

00:31:36,399 --> 00:31:38,960
and we

00:31:36,880 --> 00:31:41,039
and it gets rerun again by accident

00:31:38,960 --> 00:31:43,679
it'll just see that the check balance

00:31:41,039 --> 00:31:46,000
is uh already been it's it doesn't meet

00:31:43,679 --> 00:31:48,159
the threshold to trigger a payment

00:31:46,000 --> 00:31:50,399
or to trigger a transaction but as far

00:31:48,159 --> 00:31:52,480
as the jobs that i have that send

00:31:50,399 --> 00:31:54,000
from a you know a large wallet it's

00:31:52,480 --> 00:31:55,120
sending small transactions to

00:31:54,000 --> 00:31:57,760
individuals

00:31:55,120 --> 00:31:58,799
those those transactions get recorded

00:31:57,760 --> 00:32:00,320
into a database

00:31:58,799 --> 00:32:01,679
and the first step in the flow is to

00:32:00,320 --> 00:32:04,159
check and confirm that there isn't

00:32:01,679 --> 00:32:06,080
already a transaction that's been sent

00:32:04,159 --> 00:32:07,279
and they also have failure modes such

00:32:06,080 --> 00:32:10,000
that if they fail

00:32:07,279 --> 00:32:11,679
they're not going to just retry until

00:32:10,000 --> 00:32:12,399
somebody has come and checked it it's

00:32:11,679 --> 00:32:14,559
sort of a

00:32:12,399 --> 00:32:15,840
it's sort of a managed by exception

00:32:14,559 --> 00:32:17,120
where if it fails

00:32:15,840 --> 00:32:18,799
it's not going to retry itself

00:32:17,120 --> 00:32:19,120
automatically because there's a risk

00:32:18,799 --> 00:32:23,039
that

00:32:19,120 --> 00:32:23,039
it might double spend so

00:32:23,919 --> 00:32:28,960
yeah so i use both actually i use i use

00:32:26,720 --> 00:32:30,000
time based scheduling for most of the

00:32:28,960 --> 00:32:33,200
workflows

00:32:30,000 --> 00:32:34,320
however uh there are uh there is a

00:32:33,200 --> 00:32:36,960
airflow api

00:32:34,320 --> 00:32:38,960
and so i have i have one or two

00:32:36,960 --> 00:32:42,240
workflows that get triggered

00:32:38,960 --> 00:32:44,159
on a api connect api call so

00:32:42,240 --> 00:32:46,000
another system essentially calls to

00:32:44,159 --> 00:32:48,399
airflow and says trigger this

00:32:46,000 --> 00:32:49,600
work trigger this workflow with these

00:32:48,399 --> 00:32:51,919
properties

00:32:49,600 --> 00:32:53,039
and that executes it and i also have

00:32:51,919 --> 00:32:56,399
another workflow that

00:32:53,039 --> 00:32:59,279
there's a common a common pattern is uh

00:32:56,399 --> 00:33:00,640
doing essentially a workflow that can

00:32:59,279 --> 00:33:03,600
that can trigger

00:33:00,640 --> 00:33:04,480
n number of tasks so it's kind of like a

00:33:03,600 --> 00:33:06,240
fan out

00:33:04,480 --> 00:33:08,159
and you don't know how many tasks it's

00:33:06,240 --> 00:33:10,159
going to run at that time

00:33:08,159 --> 00:33:11,760
for that you actually have to use kind

00:33:10,159 --> 00:33:14,080
of event-based triggering

00:33:11,760 --> 00:33:16,159
and you have to have two flows so if you

00:33:14,080 --> 00:33:18,720
have one work one workflow essentially

00:33:16,159 --> 00:33:20,799
triggers the other workflow

00:33:18,720 --> 00:33:22,640
and number of times depending on what

00:33:20,799 --> 00:33:23,600
the work first workflow so the use case

00:33:22,640 --> 00:33:26,000
for that would be

00:33:23,600 --> 00:33:26,880
i'm going to query my database and i'm

00:33:26,000 --> 00:33:28,960
going to see

00:33:26,880 --> 00:33:30,159
there are 10 payments that need to

00:33:28,960 --> 00:33:33,120
execute

00:33:30,159 --> 00:33:34,240
so the last work part of my workflow is

00:33:33,120 --> 00:33:38,240
going to be to kick

00:33:34,240 --> 00:33:41,919
off 10 more workflows of another type

00:33:38,240 --> 00:33:43,760
um and actually in the slides here

00:33:41,919 --> 00:33:45,600
let me see that's actually what's

00:33:43,760 --> 00:33:50,159
happening in

00:33:45,600 --> 00:33:52,159
uh these two workflows

00:33:50,159 --> 00:33:53,279
yeah i don't know where did it go two of

00:33:52,159 --> 00:33:54,960
these workflows

00:33:53,279 --> 00:33:56,480
let me see if i can find the dashboard

00:33:54,960 --> 00:33:57,840
no maybe i didn't show the dashboard

00:33:56,480 --> 00:33:58,399
because i have a bunch of stuff on it

00:33:57,840 --> 00:34:00,240
but

00:33:58,399 --> 00:34:01,840
basically two of the workflows what i

00:34:00,240 --> 00:34:04,080
have going on is one

00:34:01,840 --> 00:34:04,880
triggers uh a whole bunch of the other

00:34:04,080 --> 00:34:08,799
ones

00:34:04,880 --> 00:34:08,799
um let me just click back and present so

00:34:09,599 --> 00:34:13,119
all right that's a good question thank

00:34:10,960 --> 00:34:21,839
you other questions anyone else have any

00:34:13,119 --> 00:34:21,839
other questions or anything

00:34:27,599 --> 00:34:35,200
no so we have like an extra five minutes

00:34:32,839 --> 00:34:36,639
um i'm not sure i'll stick around for

00:34:35,200 --> 00:34:37,919
more questions

00:34:36,639 --> 00:34:39,280
you know i didn't want to i kind of

00:34:37,919 --> 00:34:39,919
thought people would have a bunch of

00:34:39,280 --> 00:34:49,839
questions

00:34:39,919 --> 00:34:49,839
about this

00:34:52,480 --> 00:34:55,599
are you triggering any jobs based on

00:34:54,159 --> 00:34:58,240
touch files

00:34:55,599 --> 00:34:59,839
um does that mean like if a file exists

00:34:58,240 --> 00:35:02,560
is that what you're asking

00:34:59,839 --> 00:35:04,000
am i triggering any jobs based on touch

00:35:02,560 --> 00:35:06,240
files

00:35:04,000 --> 00:35:07,520
i think uh you could correct me if i'm

00:35:06,240 --> 00:35:09,200
wrong but i think the interpretation

00:35:07,520 --> 00:35:12,320
would be if a file changes

00:35:09,200 --> 00:35:14,480
trigger a workflow i've done something

00:35:12,320 --> 00:35:17,359
similar to that with sftp

00:35:14,480 --> 00:35:19,520
and it wasn't necessarily the the touch

00:35:17,359 --> 00:35:23,040
wasn't what triggered the workflow

00:35:19,520 --> 00:35:23,680
the the trigger was an a time-based

00:35:23,040 --> 00:35:26,960
trigger

00:35:23,680 --> 00:35:28,960
it was a uh just a uh every you know

00:35:26,960 --> 00:35:30,079
i think it was like every three hours it

00:35:28,960 --> 00:35:33,839
would check

00:35:30,079 --> 00:35:37,359
and if the file existed on the sftp

00:35:33,839 --> 00:35:40,400
server then it would pull the file in

00:35:37,359 --> 00:35:43,200
um and that was a that's that

00:35:40,400 --> 00:35:44,240
that pattern i've done a lot actually to

00:35:43,200 --> 00:35:47,440
pull

00:35:44,240 --> 00:35:49,680
some kind of server when a file exists

00:35:47,440 --> 00:35:50,640
uh pull it in you know put it in the

00:35:49,680 --> 00:35:52,000
database

00:35:50,640 --> 00:35:53,839
so and that's kind of the difference

00:35:52,000 --> 00:35:55,359
between sort of a streaming workflow

00:35:53,839 --> 00:35:58,640
where maybe you could set up

00:35:55,359 --> 00:36:02,240
you know a stream that looks at a file

00:35:58,640 --> 00:36:05,440
or looks at a directory or something

00:36:02,240 --> 00:36:07,839
so i'm not sure why this isn't loaded

00:36:05,440 --> 00:36:07,839
back up

00:36:08,079 --> 00:36:11,200
yeah good question i think that i hope

00:36:09,920 --> 00:36:11,520
that was what you were asking about

00:36:11,200 --> 00:36:14,240
touch

00:36:11,520 --> 00:36:14,240
touch files

00:36:15,599 --> 00:36:18,240
other questions

00:36:25,040 --> 00:36:28,079
yeah thanks thanks

00:36:28,240 --> 00:36:30,720
all right so if there are no questions i

00:36:29,520 --> 00:36:31,280
mean i'll hang out for another couple of

00:36:30,720 --> 00:36:35,760
minutes

00:36:31,280 --> 00:36:40,800
um and uh and then i'm gonna take off

00:36:35,760 --> 00:36:42,800
so go see the next talks

00:36:40,800 --> 00:36:43,839
and out bags versus automatic dag

00:36:42,800 --> 00:36:46,640
generation

00:36:43,839 --> 00:36:48,320
yeah i actually you know my the

00:36:46,640 --> 00:36:51,440
automatic

00:36:48,320 --> 00:36:52,800
generation you can't generate a dag that

00:36:51,440 --> 00:36:57,680
has a dynamic

00:36:52,800 --> 00:37:01,119
number of tasks the the number of tasks

00:36:57,680 --> 00:37:03,440
has to be determinate so

00:37:01,119 --> 00:37:04,480
if dynamically the question is what are

00:37:03,440 --> 00:37:08,480
your thoughts on

00:37:04,480 --> 00:37:10,640
fan out dags versus dag generation

00:37:08,480 --> 00:37:11,760
what has to happen if you want to do a

00:37:10,640 --> 00:37:14,560
fan out

00:37:11,760 --> 00:37:16,640
that is not a fixed number so like one

00:37:14,560 --> 00:37:20,400
thing is i have the fan out i have a fan

00:37:16,640 --> 00:37:22,000
in uh at the top so most of everything

00:37:20,400 --> 00:37:25,359
that you've seen is fan out

00:37:22,000 --> 00:37:28,079
um right so here's sort of a here's kind

00:37:25,359 --> 00:37:30,160
of a fan out where we go to two steps

00:37:28,079 --> 00:37:31,760
and then fan out again the two steps fan

00:37:30,160 --> 00:37:32,480
out again to two steps and then at the

00:37:31,760 --> 00:37:35,440
end it's a fan

00:37:32,480 --> 00:37:36,640
in with these two steps here these steps

00:37:35,440 --> 00:37:39,680
are determinate

00:37:36,640 --> 00:37:41,359
in the code so in the code there is a

00:37:39,680 --> 00:37:42,800
there is it's actually in a yaml file

00:37:41,359 --> 00:37:44,320
that defines this

00:37:42,800 --> 00:37:46,000
but it's not like we're dynamically

00:37:44,320 --> 00:37:47,440
saying that you know there's gonna be

00:37:46,000 --> 00:37:49,359
two or there's gonna be one

00:37:47,440 --> 00:37:50,480
the dag here has to be fixed so what you

00:37:49,359 --> 00:37:52,800
really have to do is

00:37:50,480 --> 00:37:55,680
you actually have to create two dags oh

00:37:52,800 --> 00:37:58,240
sorry i keep closing this

00:37:55,680 --> 00:37:59,040
you have to actually create two dags one

00:37:58,240 --> 00:38:02,560
dag

00:37:59,040 --> 00:38:05,440
triggers the other dag n number of times

00:38:02,560 --> 00:38:06,480
so i do this a few times i don't really

00:38:05,440 --> 00:38:07,520
have an example i thought it might be a

00:38:06,480 --> 00:38:09,760
little complicated but

00:38:07,520 --> 00:38:10,560
essentially what happens is it queries a

00:38:09,760 --> 00:38:13,680
database

00:38:10,560 --> 00:38:16,720
and it can return n number of records

00:38:13,680 --> 00:38:17,520
and then for each record we need to do

00:38:16,720 --> 00:38:19,920
something

00:38:17,520 --> 00:38:20,560
and so for that what has to happen is

00:38:19,920 --> 00:38:23,280
you have to

00:38:20,560 --> 00:38:25,680
execute another dag and there is

00:38:23,280 --> 00:38:28,640
actually a trigger dag

00:38:25,680 --> 00:38:29,520
operator so you can the last operator

00:38:28,640 --> 00:38:32,560
that you have

00:38:29,520 --> 00:38:34,240
can trigger any a number of dags

00:38:32,560 --> 00:38:36,880
so that's usually the pattern that i

00:38:34,240 --> 00:38:39,280
operate under is if you have to fan out

00:38:36,880 --> 00:38:40,400
and do an indeterminate number of

00:38:39,280 --> 00:38:43,200
workflows

00:38:40,400 --> 00:38:44,160
those are separate workflows and you

00:38:43,200 --> 00:38:46,560
trigger them

00:38:44,160 --> 00:38:47,599
from another dag with the distinct

00:38:46,560 --> 00:38:49,760
properties

00:38:47,599 --> 00:38:52,240
so if you imagine that database record

00:38:49,760 --> 00:38:53,839
you have 10 you return 10 records

00:38:52,240 --> 00:38:56,320
you take the properties of the first

00:38:53,839 --> 00:38:57,440
record you pass that into another dag

00:38:56,320 --> 00:38:59,200
execution

00:38:57,440 --> 00:39:01,040
then the second record pass that into

00:38:59,200 --> 00:39:02,800
another dag execution

00:39:01,040 --> 00:39:05,200
um and that's that's actually a common

00:39:02,800 --> 00:39:05,599
pattern that i i use in airflow to solve

00:39:05,200 --> 00:39:07,040
that

00:39:05,599 --> 00:39:08,480
and number problems so it's really

00:39:07,040 --> 00:39:09,680
advanced and tricky to figure out so if

00:39:08,480 --> 00:39:11,520
you want to get in touch with me i can

00:39:09,680 --> 00:39:12,960
kind of walk you through it but once you

00:39:11,520 --> 00:39:15,599
figure it out it's actually it's really

00:39:12,960 --> 00:39:17,599
helpful

00:39:15,599 --> 00:39:19,280
the other question do you split the

00:39:17,599 --> 00:39:23,359
source code for the dag

00:39:19,280 --> 00:39:27,200
construction from the dag folder

00:39:23,359 --> 00:39:29,760
i don't actually uh typically my dag

00:39:27,200 --> 00:39:31,680
will construct itself if it's a

00:39:29,760 --> 00:39:33,760
dynamically constructed one

00:39:31,680 --> 00:39:36,000
like if i'm building a dag based on the

00:39:33,760 --> 00:39:38,160
contents of a yaml file

00:39:36,000 --> 00:39:39,440
um i will just keep that that will just

00:39:38,160 --> 00:39:41,599
be part of the dag

00:39:39,440 --> 00:39:43,760
and then the yaml code i will just have

00:39:41,599 --> 00:39:46,320
that within my dags directory

00:39:43,760 --> 00:39:48,000
um under in a folder typically called

00:39:46,320 --> 00:39:50,000
like config or something

00:39:48,000 --> 00:39:51,119
um so i don't split the source code for

00:39:50,000 --> 00:39:52,960
dag construction

00:39:51,119 --> 00:39:54,640
but then again i'm not doing so such

00:39:52,960 --> 00:39:57,440
sophisticated dag construction

00:39:54,640 --> 00:39:58,000
most of my dag construction is just

00:39:57,440 --> 00:40:01,839
python

00:39:58,000 --> 00:40:04,319
files maybe 100 100 lines 200 lines

00:40:01,839 --> 00:40:05,680
or less and there may be doing like you

00:40:04,319 --> 00:40:08,960
know just a few steps

00:40:05,680 --> 00:40:10,480
so yeah i know i know there are a lot of

00:40:08,960 --> 00:40:11,920
the airflow deployments that have far

00:40:10,480 --> 00:40:15,599
more sophisticated

00:40:11,920 --> 00:40:18,079
uh dag construction uh code

00:40:15,599 --> 00:40:20,400
and for those i could imagine they would

00:40:18,079 --> 00:40:22,480
probably split that out

00:40:20,400 --> 00:40:23,520
i in the previous airflow talk i did i

00:40:22,480 --> 00:40:25,760
actually had a

00:40:23,520 --> 00:40:27,359
slide that would show that but basically

00:40:25,760 --> 00:40:30,640
what they do is they'll

00:40:27,359 --> 00:40:33,520
have a system that produces the dags

00:40:30,640 --> 00:40:34,160
and then those dags get produced and put

00:40:33,520 --> 00:40:37,680
into

00:40:34,160 --> 00:40:39,359
a folder on the airflow servers

00:40:37,680 --> 00:40:40,880
so they have two separate code bases

00:40:39,359 --> 00:40:42,319
they have the dag code base and then

00:40:40,880 --> 00:40:44,240
they have the code base where they are

00:40:42,319 --> 00:40:46,400
producing the dags

00:40:44,240 --> 00:40:46,400
so

00:40:48,160 --> 00:40:53,280
yeah all right so thanks for the

00:40:51,839 --> 00:40:56,640
questions i appreciate it

00:40:53,280 --> 00:41:00,240
um i hope everyone found it useful uh

00:40:56,640 --> 00:41:00,640
i will uh i will uh i mean i don't know

00:41:00,240 --> 00:41:04,400
if i

00:41:00,640 --> 00:41:05,920
close i'm gonna close my screen share um

00:41:04,400 --> 00:41:09,760
but i'm gonna i think i'm gonna go to

00:41:05,920 --> 00:41:09,760
the next talk so thanks for thanks for

00:41:18,839 --> 00:41:21,839
watching

00:41:38,640 --> 00:41:40,720

YouTube URL: https://www.youtube.com/watch?v=hXrULXAi9qM


