Title: Presentation of DLab toolset
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Big Data (Track 2)
Description: 
	Presentation of DLab toolset
Mykola Bodnar, Vira Vitanska, Oleg Fuks

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

We are going to introduce DLab: - Similar user experience across AWS, GCP, and Azure clouds - Automatically configurable exploratory environment integrated with enterprise security and templates - Project level collaboration environment across multiple clouds - Aggregated billing with cost comparison across cloud providers - Project level resource management

Mykola Bodnar:
Mykola Bodnar has worked in EPAM since 2019, primary skill DevOps.BigData;
Vira Vitanska:
Vira has worked in EPAM since 2017 as a functional tester.
Oleg Fuks
Oleg Fuks has been working in EPAM since 2019, primary skill is Java.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,720 --> 00:00:30,000
color i

00:00:25,599 --> 00:00:33,280
guess that we can start yes sure

00:00:30,000 --> 00:00:37,360
okay my name is nicola bodnar

00:00:33,280 --> 00:00:40,480
i am apache committer

00:00:37,360 --> 00:00:45,200
and today we are going to

00:00:40,480 --> 00:00:47,840
present the tilap

00:00:45,200 --> 00:00:48,480
so we're going to take to talk about

00:00:47,840 --> 00:00:50,879
deal up

00:00:48,480 --> 00:00:52,399
which is essential tool set for

00:00:50,879 --> 00:00:56,320
analytics

00:00:52,399 --> 00:00:58,480
as well as hybrid cloud orchestrator

00:00:56,320 --> 00:00:59,520
and i would like to quickly walk through

00:00:58,480 --> 00:01:01,199
the problems

00:00:59,520 --> 00:01:03,199
that we are trying to resolve by

00:01:01,199 --> 00:01:07,680
building this platform

00:01:03,199 --> 00:01:07,680
as well as to focus on its main features

00:01:08,560 --> 00:01:12,080
to start this presentation i would like

00:01:10,799 --> 00:01:15,040
to quickly walk you

00:01:12,080 --> 00:01:15,600
through our typical blueprint for

00:01:15,040 --> 00:01:18,720
building

00:01:15,600 --> 00:01:22,640
a big data platform in cloud

00:01:18,720 --> 00:01:26,000
and also to focus on role of

00:01:22,640 --> 00:01:29,200
the lab here

00:01:26,000 --> 00:01:31,520
so as you can see here we've got

00:01:29,200 --> 00:01:33,360
multiple layers on this big data

00:01:31,520 --> 00:01:38,079
blueprint

00:01:33,360 --> 00:01:38,079
it typically starts with data injection

00:01:38,240 --> 00:01:44,880
so we are trying to ingest

00:01:41,680 --> 00:01:47,360
the data from multiple data sources

00:01:44,880 --> 00:01:48,960
which can be relational databases some

00:01:47,360 --> 00:01:52,000
social feeds

00:01:48,960 --> 00:01:55,040
etc the next layer

00:01:52,000 --> 00:01:57,360
is of course the injection so

00:01:55,040 --> 00:01:59,680
basically to speed up development as

00:01:57,360 --> 00:02:00,399
much as possible and to be able to

00:01:59,680 --> 00:02:03,280
quickly

00:02:00,399 --> 00:02:04,799
verify requirements that data engineers

00:02:03,280 --> 00:02:07,439
are trying to solve

00:02:04,799 --> 00:02:09,160
by building the data platform to create

00:02:07,439 --> 00:02:10,720
some repeat prototypes and

00:02:09,160 --> 00:02:13,520
visualizations

00:02:10,720 --> 00:02:15,040
and to be able to validate them with

00:02:13,520 --> 00:02:17,360
client

00:02:15,040 --> 00:02:18,720
we were thinking that we need to create

00:02:17,360 --> 00:02:22,239
thumbs inquisit

00:02:18,720 --> 00:02:25,920
and we have came up with explanatory

00:02:22,239 --> 00:02:29,280
environment which called d-lab

00:02:25,920 --> 00:02:32,560
and as we can see here it's represented

00:02:29,280 --> 00:02:36,319
by data and ml

00:02:32,560 --> 00:02:39,599
explanatory rectangle

00:02:36,319 --> 00:02:41,200
so once we have some models built once

00:02:39,599 --> 00:02:43,599
our data scientists

00:02:41,200 --> 00:02:44,800
or data engineers or data quality

00:02:43,599 --> 00:02:47,599
engineers

00:02:44,800 --> 00:02:48,000
have validates the data they can start

00:02:47,599 --> 00:02:50,239
doing

00:02:48,000 --> 00:02:52,000
some repeat prototypes in parallel to

00:02:50,239 --> 00:02:55,280
infrastructure

00:02:52,000 --> 00:02:58,879
actually being built for all production

00:02:55,280 --> 00:03:01,280
pipelines and this is where we use

00:02:58,879 --> 00:03:01,280
dilap

00:03:02,720 --> 00:03:06,239
wasn't the big data practice we built a

00:03:05,280 --> 00:03:10,000
bunch of

00:03:06,239 --> 00:03:12,480
data science and data projects and we

00:03:10,000 --> 00:03:14,000
typically talked to the guys who've been

00:03:12,480 --> 00:03:16,720
the part of this

00:03:14,000 --> 00:03:17,440
and try to understand what problems

00:03:16,720 --> 00:03:19,440
they've been

00:03:17,440 --> 00:03:20,879
facing while building all those

00:03:19,440 --> 00:03:24,080
platforms

00:03:20,879 --> 00:03:26,319
and typically they say that the cloud

00:03:24,080 --> 00:03:28,480
infrastructure is different

00:03:26,319 --> 00:03:30,159
they would really like to have similar

00:03:28,480 --> 00:03:33,280
sort of experience

00:03:30,159 --> 00:03:36,959
by building those data products

00:03:33,280 --> 00:03:39,200
the second thing is always the security

00:03:36,959 --> 00:03:40,560
essentially when working with sensitive

00:03:39,200 --> 00:03:44,000
types of data

00:03:40,560 --> 00:03:46,879
so data scientists data engineers

00:03:44,000 --> 00:03:48,959
due to lack of computational resources

00:03:46,879 --> 00:03:51,599
they are trying to bring the data from

00:03:48,959 --> 00:03:53,280
the cloud to their local machines

00:03:51,599 --> 00:03:54,720
which is actually a very bad pattern to

00:03:53,280 --> 00:03:57,120
follow

00:03:54,720 --> 00:03:59,519
data scientists also bound to local

00:03:57,120 --> 00:04:00,560
machines because the costs of cluster is

00:03:59,519 --> 00:04:03,040
huge

00:04:00,560 --> 00:04:05,280
the infrastructure as i mentioned before

00:04:03,040 --> 00:04:08,000
is not yet built

00:04:05,280 --> 00:04:10,000
the lack of self-service also brings

00:04:08,000 --> 00:04:11,040
stones of operational requests to the

00:04:10,000 --> 00:04:13,599
iet

00:04:11,040 --> 00:04:14,640
or to the devops organization to

00:04:13,599 --> 00:04:17,120
actually enable

00:04:14,640 --> 00:04:18,160
some policies open some parts to enable

00:04:17,120 --> 00:04:20,239
connectivity

00:04:18,160 --> 00:04:23,120
and this is actually a huge amount of

00:04:20,239 --> 00:04:26,240
time needed to spend by the it teams

00:04:23,120 --> 00:04:28,400
in on the in order for development to be

00:04:26,240 --> 00:04:30,720
actually enabled and

00:04:28,400 --> 00:04:31,680
also we were thinking that adding

00:04:30,720 --> 00:04:34,720
something around

00:04:31,680 --> 00:04:37,840
costa location and monitoring of

00:04:34,720 --> 00:04:37,840
security control

00:04:38,800 --> 00:04:43,520
after all those feedbacks provided by

00:04:41,919 --> 00:04:46,000
our teams

00:04:43,520 --> 00:04:46,800
we thought that we need to build

00:04:46,000 --> 00:04:50,000
something

00:04:46,800 --> 00:04:56,960
for them and it should fill

00:04:50,000 --> 00:05:00,080
all of presented here conditions

00:04:56,960 --> 00:05:03,520
and we have basically engaged

00:05:00,080 --> 00:05:08,000
our best engineers devops

00:05:03,520 --> 00:05:08,000
to build a platform which we called

00:05:08,840 --> 00:05:14,400
d-lab

00:05:11,280 --> 00:05:18,960
so what is dlab tillap

00:05:14,400 --> 00:05:23,600
is a hybrid cloud which can be connected

00:05:18,960 --> 00:05:26,880
to the to three main clouds

00:05:23,600 --> 00:05:30,400
the aws gcp and edge

00:05:26,880 --> 00:05:31,520
at the same time it has easy to use and

00:05:30,400 --> 00:05:34,880
providing similar

00:05:31,520 --> 00:05:36,320
experience across all the clouds web

00:05:34,880 --> 00:05:38,960
interface

00:05:36,320 --> 00:05:40,240
that all the users of the lab can use

00:05:38,960 --> 00:05:42,400
for basically

00:05:40,240 --> 00:05:43,520
seamless experience of doing the data

00:05:42,400 --> 00:05:46,320
analysis

00:05:43,520 --> 00:05:46,560
creating the data models doing any type

00:05:46,320 --> 00:05:53,840
of

00:05:46,560 --> 00:05:53,840
explore to data analysis

00:05:54,800 --> 00:06:00,720
sorry yeah correct

00:05:58,319 --> 00:06:02,160
and to summarize before i proceed to

00:06:00,720 --> 00:06:05,280
develop architecture

00:06:02,160 --> 00:06:08,160
so it's basically the self-service

00:06:05,280 --> 00:06:09,199
that enables data scientists to spin up

00:06:08,160 --> 00:06:12,479
resources

00:06:09,199 --> 00:06:14,960
without any support from it since it has

00:06:12,479 --> 00:06:17,440
very easy to use web interface

00:06:14,960 --> 00:06:19,360
it contains the latest version versions

00:06:17,440 --> 00:06:22,880
of open source tools

00:06:19,360 --> 00:06:25,759
which are always updated the framework

00:06:22,880 --> 00:06:27,840
also allows you to install libraries on

00:06:25,759 --> 00:06:29,280
your notebooks which is pretty essential

00:06:27,840 --> 00:06:31,759
for data scientists

00:06:29,280 --> 00:06:34,479
that is not only for notebooks but for

00:06:31,759 --> 00:06:38,000
clusters as well

00:06:34,479 --> 00:06:40,000
deal up is under a patch 2.0 license

00:06:38,000 --> 00:06:42,720
that means you may use it in both

00:06:40,000 --> 00:06:44,560
commercial and non-commercial use

00:06:42,720 --> 00:06:48,560
and you can collaborate in this

00:06:44,560 --> 00:06:53,199
environment as well

00:06:48,560 --> 00:06:53,199
so um about the architecture

00:06:53,280 --> 00:06:59,440
uh in this one slide the volume

00:06:56,319 --> 00:07:03,120
architecture of the lab is presented on

00:06:59,440 --> 00:07:06,319
this slide it's based on aws aws

00:07:03,120 --> 00:07:06,960
version the amazon cloud so the first

00:07:06,319 --> 00:07:10,319
node

00:07:06,960 --> 00:07:10,319
is self-service node

00:07:11,599 --> 00:07:17,759
it contains the database

00:07:14,720 --> 00:07:20,720
user interface service and may contain

00:07:17,759 --> 00:07:20,720
local endpoint

00:07:20,960 --> 00:07:25,520
as we mentioned before endpoint could be

00:07:23,840 --> 00:07:28,880
located in

00:07:25,520 --> 00:07:32,400
any of three clouds aws

00:07:28,880 --> 00:07:32,400
gcp or asia

00:07:32,720 --> 00:07:38,160
so this is a general shame of

00:07:36,160 --> 00:07:39,360
dilap where the endpoints could be

00:07:38,160 --> 00:07:42,840
located on

00:07:39,360 --> 00:07:44,000
different cloud than the self-service

00:07:42,840 --> 00:07:46,400
node

00:07:44,000 --> 00:07:47,360
but the general architecture is the

00:07:46,400 --> 00:07:52,000
similar for

00:07:47,360 --> 00:07:52,000
gcp and edge

00:07:52,479 --> 00:07:59,039
endpoint contains provisioning service

00:07:56,240 --> 00:07:59,599
all resources management in the cloud is

00:07:59,039 --> 00:08:02,560
done by

00:07:59,599 --> 00:08:04,080
docker containers which are also run on

00:08:02,560 --> 00:08:06,080
endpoint

00:08:04,080 --> 00:08:07,440
for security reasons access to all

00:08:06,080 --> 00:08:10,800
computational resources

00:08:07,440 --> 00:08:10,800
is done by edge node

00:08:10,960 --> 00:08:16,319
which plays role of reverse proxy

00:08:14,240 --> 00:08:18,400
all computational resources are located

00:08:16,319 --> 00:08:23,360
in private network

00:08:18,400 --> 00:08:23,360
endpoint and edge node in public network

00:08:24,479 --> 00:08:29,039
for access to user interface we are

00:08:27,599 --> 00:08:31,120
using keyclock

00:08:29,039 --> 00:08:33,039
which could be connected to third-party

00:08:31,120 --> 00:08:37,599
identity providers like

00:08:33,039 --> 00:08:37,599
active directory or openldap

00:08:39,440 --> 00:08:45,920
so in two words tilap is a sandbox

00:08:43,599 --> 00:08:47,279
you can actually create your environment

00:08:45,920 --> 00:08:49,839
you can break it

00:08:47,279 --> 00:08:50,880
you can reprovision it from scratch

00:08:49,839 --> 00:08:54,080
without breaking

00:08:50,880 --> 00:08:55,279
anyone else environment and this is huge

00:08:54,080 --> 00:08:57,440
benefit

00:08:55,279 --> 00:08:58,480
it also has a multiple building

00:08:57,440 --> 00:09:02,000
templates

00:08:58,480 --> 00:09:05,200
as we call them those are jupiter

00:09:02,000 --> 00:09:06,000
rstudio tapyline as well as well as

00:09:05,200 --> 00:09:09,200
combination

00:09:06,000 --> 00:09:10,800
of jupiter and tensorflow are studio and

00:09:09,200 --> 00:09:14,640
tensorflow

00:09:10,800 --> 00:09:17,040
we also pre-install the most important

00:09:14,640 --> 00:09:17,680
data and science libraries like keras

00:09:17,040 --> 00:09:20,959
pandas

00:09:17,680 --> 00:09:21,760
storage and many many others we also

00:09:20,959 --> 00:09:23,360
added

00:09:21,760 --> 00:09:24,880
the ability to add pluggable

00:09:23,360 --> 00:09:28,080
computational power

00:09:24,880 --> 00:09:30,720
like standalone spark cluster and emr or

00:09:28,080 --> 00:09:30,720
data proc

00:09:30,959 --> 00:09:34,800
as we mentioned before the lab support

00:09:33,360 --> 00:09:37,440
life cycle management

00:09:34,800 --> 00:09:39,360
that means you can actually create your

00:09:37,440 --> 00:09:42,240
environment you can break it you can

00:09:39,360 --> 00:09:44,320
pre-provision it you can stop start or

00:09:42,240 --> 00:09:46,800
terminate resources

00:09:44,320 --> 00:09:49,680
we've also embedded the builder library

00:09:46,800 --> 00:09:53,360
management functionality in gillab

00:09:49,680 --> 00:09:55,680
as well as bucket browser and audit page

00:09:53,360 --> 00:09:56,640
apart from that it's really important to

00:09:55,680 --> 00:09:59,279
mention that

00:09:56,640 --> 00:10:00,399
a working wizard team is all about

00:09:59,279 --> 00:10:02,640
collaboration

00:10:00,399 --> 00:10:04,240
so we did enable this functionality by

00:10:02,640 --> 00:10:07,440
means that installing tool

00:10:04,240 --> 00:10:10,000
called ongit besides from that

00:10:07,440 --> 00:10:12,240
we have a billing functionality where

00:10:10,000 --> 00:10:14,640
you can set some quotas

00:10:12,240 --> 00:10:15,839
assign them for projects for specific

00:10:14,640 --> 00:10:18,320
users

00:10:15,839 --> 00:10:21,760
and also we have the powerful

00:10:18,320 --> 00:10:21,760
administration interface

00:10:22,880 --> 00:10:27,360
so this is pretty much everything about

00:10:25,360 --> 00:10:29,600
introduction of the lab

00:10:27,360 --> 00:10:31,040
and of course as open source product

00:10:29,600 --> 00:10:33,839
under a patch license

00:10:31,040 --> 00:10:34,399
we already made three releases and

00:10:33,839 --> 00:10:36,959
fourth

00:10:34,399 --> 00:10:39,040
version of the lap was realized just a

00:10:36,959 --> 00:10:42,079
few days ago

00:10:39,040 --> 00:10:43,120
and now i want to ask my colleague vira

00:10:42,079 --> 00:10:45,920
vitanska

00:10:43,120 --> 00:10:47,760
to share the presentation of the actual

00:10:45,920 --> 00:10:52,000
environment of d lab

00:10:47,760 --> 00:10:52,000
so vira can you proceed

00:11:01,279 --> 00:11:15,839
hello everyone just a moment

00:11:19,200 --> 00:11:22,480
do you see my screen yes

00:11:25,920 --> 00:11:29,839
do you hear me

00:11:30,640 --> 00:11:43,839
colleagues do you see my screen yes

00:11:44,959 --> 00:11:50,240
just a moment yes it's okay yes

00:11:51,839 --> 00:11:59,360
okay thank you okay

00:11:55,680 --> 00:12:02,399
um as scholar has mentioned i'm vera

00:11:59,360 --> 00:12:05,600
and i am a patter committer and

00:12:02,399 --> 00:12:09,120
it is a pleasure to be here so let's get

00:12:05,600 --> 00:12:11,040
down to the demo our journey starts from

00:12:09,120 --> 00:12:13,519
the login page

00:12:11,040 --> 00:12:15,519
after entering a valid username and

00:12:13,519 --> 00:12:18,160
password

00:12:15,519 --> 00:12:19,920
user is located on the list of resources

00:12:18,160 --> 00:12:23,200
page

00:12:19,920 --> 00:12:23,680
is a self-service web console used to

00:12:23,200 --> 00:12:27,040
create

00:12:23,680 --> 00:12:29,040
and manage exploratory environments

00:12:27,040 --> 00:12:31,680
teams can spin up analytical

00:12:29,040 --> 00:12:33,279
environments with just a single click of

00:12:31,680 --> 00:12:37,200
a mouse

00:12:33,279 --> 00:12:40,480
what can you see here what cloud

00:12:37,200 --> 00:12:44,000
resources have been provisioned

00:12:40,480 --> 00:12:47,040
the second how much money you spend with

00:12:44,000 --> 00:12:47,040
specific resources

00:12:47,920 --> 00:12:51,600
on top of that you can as well filter

00:12:50,480 --> 00:12:54,800
your list by

00:12:51,600 --> 00:12:57,839
instance shapes status

00:12:54,800 --> 00:12:57,839
and many others

00:12:58,800 --> 00:13:02,320
now let me show you how to create

00:13:00,800 --> 00:13:06,000
analytical tools via

00:13:02,320 --> 00:13:09,279
dlab after clicking the create

00:13:06,000 --> 00:13:11,120
new button you see a dialogue where you

00:13:09,279 --> 00:13:14,240
can define parameters

00:13:11,120 --> 00:13:18,320
for your analytical environments

00:13:14,240 --> 00:13:20,480
project and endpoint in what project and

00:13:18,320 --> 00:13:21,760
point you are going to create analytical

00:13:20,480 --> 00:13:25,200
tool

00:13:21,760 --> 00:13:26,880
template here you define whatsapp file

00:13:25,200 --> 00:13:28,399
packages you want to have in your

00:13:26,880 --> 00:13:32,079
disposal

00:13:28,399 --> 00:13:35,279
zeppelin deep learning japaniter

00:13:32,079 --> 00:13:39,839
our studio our studio engine powder

00:13:35,279 --> 00:13:43,279
and japanese tensorflow jupiter lab

00:13:39,839 --> 00:13:46,880
on top of that superset on gcp

00:13:43,279 --> 00:13:48,399
name to identify the source on gilab web

00:13:46,880 --> 00:13:51,440
ui

00:13:48,399 --> 00:13:53,360
instant size we support all shapes we

00:13:51,440 --> 00:13:56,160
support all shapes from the cloud

00:13:53,360 --> 00:14:02,079
written where gilap has been installed

00:13:56,160 --> 00:14:06,000
so the list you see now is configurable

00:14:02,079 --> 00:14:08,560
on top of that we support gpu optimized

00:14:06,000 --> 00:14:10,639
instance shapes which data scientists

00:14:08,560 --> 00:14:13,440
widely use for such users cases

00:14:10,639 --> 00:14:14,839
as image recognition working with video

00:14:13,440 --> 00:14:19,839
streams and

00:14:14,839 --> 00:14:23,120
others custom tag i feel for your tag

00:14:19,839 --> 00:14:25,199
and finally spark configurations

00:14:23,120 --> 00:14:26,959
this is needed when we want a notebook

00:14:25,199 --> 00:14:29,360
to be created with custom spark

00:14:26,959 --> 00:14:32,160
configuration

00:14:29,360 --> 00:14:32,800
if notebook is grey if notebook is

00:14:32,160 --> 00:14:36,079
created

00:14:32,800 --> 00:14:38,079
its status is running after that you are

00:14:36,079 --> 00:14:42,839
able to manage it

00:14:38,079 --> 00:14:44,639
via the action menu let's go to this

00:14:42,839 --> 00:14:48,079
action

00:14:44,639 --> 00:14:49,920
stop notebook a notebook can be stopped

00:14:48,079 --> 00:14:52,320
at any time you need

00:14:49,920 --> 00:14:55,760
stopping notebook will still allow you

00:14:52,320 --> 00:14:55,760
to work with it later

00:14:56,000 --> 00:15:02,000
terminate terminate notebook

00:14:59,440 --> 00:15:02,639
once terminated you can no longer start

00:15:02,000 --> 00:15:04,560
to the

00:15:02,639 --> 00:15:08,240
you can no longer start the notebook

00:15:04,560 --> 00:15:08,240
which has been terminated

00:15:10,720 --> 00:15:16,880
next add compute most of the time

00:15:14,320 --> 00:15:19,279
data scientists start with cloud

00:15:16,880 --> 00:15:20,480
notebooks deployed on a single virtual

00:15:19,279 --> 00:15:23,040
machine

00:15:20,480 --> 00:15:24,160
they create the codebase on top

00:15:23,040 --> 00:15:26,800
relatively small

00:15:24,160 --> 00:15:27,680
data sets just to evaluate where the

00:15:26,800 --> 00:15:30,480
code works

00:15:27,680 --> 00:15:31,120
or not once they see that it is working

00:15:30,480 --> 00:15:33,440
well

00:15:31,120 --> 00:15:36,480
they might need to execute on large

00:15:33,440 --> 00:15:38,800
volumes of production data

00:15:36,480 --> 00:15:42,000
thus they would require to add more

00:15:38,800 --> 00:15:44,240
computational power to their jobs

00:15:42,000 --> 00:15:46,079
gilap helps to add more computational

00:15:44,240 --> 00:15:48,880
resources within single click

00:15:46,079 --> 00:15:48,880
of the mouse

00:15:50,240 --> 00:15:53,279
once create cluster automatically shows

00:15:52,880 --> 00:15:57,440
up

00:15:53,279 --> 00:15:59,759
in corresponding analytic web ui

00:15:57,440 --> 00:16:02,079
you can simply switch through the remote

00:15:59,759 --> 00:16:02,720
kernels of your notebooks to enable

00:16:02,079 --> 00:16:06,560
parallel

00:16:02,720 --> 00:16:06,560
distributed job execution

00:16:06,720 --> 00:16:11,600
we don't limited data scientists to

00:16:08,959 --> 00:16:14,560
stick to a single programming language

00:16:11,600 --> 00:16:15,839
they can switch between various

00:16:14,560 --> 00:16:20,160
programming languages

00:16:15,839 --> 00:16:24,320
we are the kernel menu of every notebook

00:16:20,160 --> 00:16:24,320
scala pyson r

00:16:26,079 --> 00:16:33,920
okay let's go to scheduler

00:16:31,199 --> 00:16:35,440
in order to optimize cloud expansion and

00:16:33,920 --> 00:16:37,680
use cloud resources

00:16:35,440 --> 00:16:39,519
only when needed we have created

00:16:37,680 --> 00:16:41,440
scheduler functionality

00:16:39,519 --> 00:16:42,560
which can effectively manage your

00:16:41,440 --> 00:16:47,600
analytical tool

00:16:42,560 --> 00:16:47,600
and cluster start stop lifecycle

00:16:47,680 --> 00:16:55,440
either on time by spartan or

00:16:51,920 --> 00:16:55,440
buys on in activity

00:16:56,240 --> 00:17:02,880
in addition the users can specify

00:16:59,279 --> 00:17:06,000
a recurring for notable start

00:17:02,880 --> 00:17:11,039
and notebook stop

00:17:06,000 --> 00:17:11,039
scheduler can be also apply on clusters

00:17:16,559 --> 00:17:20,559
next manage libraries

00:17:20,880 --> 00:17:25,199
on the screen data scientist is

00:17:22,799 --> 00:17:27,520
installing needed libraries dependencies

00:17:25,199 --> 00:17:30,720
and frameworks on the analytical

00:17:27,520 --> 00:17:32,640
notebook notebooks and clusters now you

00:17:30,720 --> 00:17:34,960
can see

00:17:32,640 --> 00:17:35,679
i feel advanced for selecting an active

00:17:34,960 --> 00:17:38,799
resource

00:17:35,679 --> 00:17:41,679
to install libraries

00:17:38,799 --> 00:17:42,960
i feel for selecting group of packages

00:17:41,679 --> 00:17:48,240
aptitude

00:17:42,960 --> 00:17:48,240
upda python r java others

00:17:48,960 --> 00:18:01,840
i feel for search available packages

00:17:52,000 --> 00:18:01,840
with autocomplete feature for example

00:18:06,880 --> 00:18:12,320
and the last field it is an optional

00:18:09,360 --> 00:18:15,840
field for library version

00:18:12,320 --> 00:18:19,120
on top of that the user is able to

00:18:15,840 --> 00:18:23,679
downgrade or upgrade a version

00:18:19,120 --> 00:18:23,679
of the install library if it's necessary

00:18:24,960 --> 00:18:29,280
once multiple libraries and additional

00:18:27,440 --> 00:18:30,160
packages have been installed on the

00:18:29,280 --> 00:18:32,640
notebook

00:18:30,160 --> 00:18:34,799
it might be worth creating an image with

00:18:32,640 --> 00:18:35,120
all this software pre-installed such as

00:18:34,799 --> 00:18:37,679
that

00:18:35,120 --> 00:18:40,320
next time data scientist would like to

00:18:37,679 --> 00:18:44,000
create a new analytical tool

00:18:40,320 --> 00:18:46,320
he can leverage and an existing image

00:18:44,000 --> 00:18:49,360
thus saving time for preparation of

00:18:46,320 --> 00:18:49,360
analytical tool

00:18:52,720 --> 00:18:56,000
g-lab enables collaboration capabilities

00:18:55,440 --> 00:18:59,679
across

00:18:56,000 --> 00:19:02,160
data scientists and data science teams

00:18:59,679 --> 00:19:04,080
collaboration is made via a built-in

00:19:02,160 --> 00:19:07,280
tool called ongit

00:19:04,080 --> 00:19:09,360
enable collaboration or code base level

00:19:07,280 --> 00:19:10,880
on top of observed dlab enables

00:19:09,360 --> 00:19:13,679
collaboration on

00:19:10,880 --> 00:19:14,080
data level creating collaborations page

00:19:13,679 --> 00:19:16,400
this

00:19:14,080 --> 00:19:17,280
is accessible for read and write for all

00:19:16,400 --> 00:19:21,360
users

00:19:17,280 --> 00:19:21,360
who have access to dlab

00:19:23,200 --> 00:19:29,760
user just need to fill in the

00:19:26,240 --> 00:19:29,760
repository credentials

00:19:36,799 --> 00:19:43,760
use user can clone repository to a

00:19:40,000 --> 00:19:46,880
notebook it is still opening

00:19:43,760 --> 00:19:49,200
to notebook push pull merge

00:19:46,880 --> 00:19:50,160
and execute many other git operations

00:19:49,200 --> 00:19:54,160
just working with

00:19:50,160 --> 00:19:54,160
web ui on git

00:19:58,400 --> 00:20:07,840
in addition data scientists are able to

00:20:00,880 --> 00:20:07,840
access cloudbacks via dlab web ui

00:20:08,400 --> 00:20:16,480
on the screen user is supposed to

00:20:11,840 --> 00:20:16,480
upload file create a folder

00:20:19,039 --> 00:20:24,240
delete a folder a file

00:20:25,760 --> 00:20:35,120
on top of that download a folder

00:20:28,880 --> 00:20:37,200
copy pass to a folder to a file

00:20:35,120 --> 00:20:39,679
let's i show you quickly overview of

00:20:37,200 --> 00:20:40,720
main functionality of the administration

00:20:39,679 --> 00:20:44,480
page

00:20:40,720 --> 00:20:45,760
first of all manage roles we can create

00:20:44,480 --> 00:20:48,000
deluxe groups and

00:20:45,760 --> 00:20:48,799
assign specific roles and permission to

00:20:48,000 --> 00:20:51,280
them

00:20:48,799 --> 00:20:54,559
once created those deal up groups can be

00:20:51,280 --> 00:20:57,120
linked with actual id groups and users

00:20:54,559 --> 00:20:59,280
on such users login into dela

00:20:57,120 --> 00:21:00,320
permissions corresponding to the dlab

00:20:59,280 --> 00:21:02,960
groups

00:21:00,320 --> 00:21:04,480
automatically to the use automatically

00:21:02,960 --> 00:21:07,840
granted to the user or

00:21:04,480 --> 00:21:10,159
groups of users allowing them to

00:21:07,840 --> 00:21:16,480
leverage specific

00:21:10,159 --> 00:21:20,880
functionalities included but not limited

00:21:16,480 --> 00:21:20,880
working with specific instance shapes

00:21:23,600 --> 00:21:31,840
working with specific software packages

00:21:26,000 --> 00:21:31,840
and templates

00:21:32,080 --> 00:21:36,559
the ability to see billing data

00:21:39,600 --> 00:21:45,840
the ability to create clusters

00:21:46,320 --> 00:21:49,360
the ability to have access to cloud

00:21:48,559 --> 00:21:52,880
buckets

00:21:49,360 --> 00:21:52,880
via dealer web ui

00:21:53,760 --> 00:21:59,840
let's go to the manage project

00:21:56,840 --> 00:21:59,840
management

00:22:03,679 --> 00:22:09,600
on the manage project page the

00:22:05,520 --> 00:22:09,600
administrator is supposed to manage a

00:22:10,840 --> 00:22:15,520
project

00:22:12,400 --> 00:22:15,520
add a remove group

00:22:15,840 --> 00:22:18,720
at endpoint

00:22:18,960 --> 00:22:23,280
environment management the invite

00:22:22,000 --> 00:22:25,679
management page

00:22:23,280 --> 00:22:28,400
allows the administrator to see the list

00:22:25,679 --> 00:22:32,000
of all user environments

00:22:28,400 --> 00:22:34,720
and to stop or terminate

00:22:32,000 --> 00:22:34,720
all of them

00:22:35,760 --> 00:22:40,799
gilap supports connection to any of

00:22:38,080 --> 00:22:44,080
cloud and point

00:22:40,799 --> 00:22:46,640
amazon web service and gcp microsoft

00:22:44,080 --> 00:22:46,640
azure

00:22:48,880 --> 00:22:52,640
one of the dev keys features is ability

00:22:51,919 --> 00:22:55,039
to manage

00:22:52,640 --> 00:22:56,320
and limit quotas for working with cloud

00:22:55,039 --> 00:22:58,320
infrastructure

00:22:56,320 --> 00:23:00,720
this way we provide an easy and

00:22:58,320 --> 00:23:01,039
effective way for delab administrator to

00:23:00,720 --> 00:23:04,159
have

00:23:01,039 --> 00:23:06,880
control our cloud resources usage

00:23:04,159 --> 00:23:08,720
and money spent associated with those

00:23:06,880 --> 00:23:11,520
resources

00:23:08,720 --> 00:23:13,760
we have the ability to manage quota per

00:23:11,520 --> 00:23:18,000
project

00:23:13,760 --> 00:23:23,840
monthly or total period

00:23:18,000 --> 00:23:23,840
and pedulab installation in general

00:23:25,360 --> 00:23:28,960
when it comes to working with cloud and

00:23:27,600 --> 00:23:31,280
creating clusters

00:23:28,960 --> 00:23:32,960
one of the most essential questions

00:23:31,280 --> 00:23:36,400
asked is

00:23:32,960 --> 00:23:39,280
what is the cost of infrastructure

00:23:36,400 --> 00:23:40,240
on d labs billing report paid not only

00:23:39,280 --> 00:23:42,080
answers

00:23:40,240 --> 00:23:43,520
this question but also provides

00:23:42,080 --> 00:23:46,159
available details

00:23:43,520 --> 00:23:49,440
and insights for whether analytics and

00:23:46,159 --> 00:23:52,400
optimization strategy

00:23:49,440 --> 00:23:54,480
you can see total management for whole

00:23:52,400 --> 00:23:57,520
infrastructure

00:23:54,480 --> 00:24:00,240
c money c money spent grouped by

00:23:57,520 --> 00:24:00,240
and filter

00:24:00,720 --> 00:24:09,120
specific user resource type

00:24:05,679 --> 00:24:12,720
instance size status

00:24:09,120 --> 00:24:12,720
project date

00:24:13,919 --> 00:24:19,840
and export report into csv

00:24:22,960 --> 00:24:29,039
and finally the audit page

00:24:26,240 --> 00:24:30,240
the audit feature tracks key activities

00:24:29,039 --> 00:24:32,480
in dlab

00:24:30,240 --> 00:24:35,279
that allows the user to look back at

00:24:32,480 --> 00:24:39,039
changes that have been made in dlab

00:24:35,279 --> 00:24:41,360
users can see when who

00:24:39,039 --> 00:24:43,600
and what stages have been made and

00:24:41,360 --> 00:24:47,919
filtered by

00:24:43,600 --> 00:24:53,120
date user

00:24:47,919 --> 00:24:53,120
product resource type and resource

00:24:53,440 --> 00:25:01,200
so that's all i have for you today

00:24:57,279 --> 00:25:03,919
thank you very much for listening and

00:25:01,200 --> 00:25:14,240
if you have any questions you are free

00:25:03,919 --> 00:25:17,679
to ask us

00:25:14,240 --> 00:25:18,640
yes and give ira so we are waiting for

00:25:17,679 --> 00:25:22,320
questions

00:25:18,640 --> 00:25:24,559
i think you can send your question in

00:25:22,320 --> 00:25:29,840
the chat

00:25:24,559 --> 00:25:29,840
please don't hesitate to answer

00:26:35,120 --> 00:26:39,840
we are still here

00:28:29,520 --> 00:28:34,480
okay i can't see no more questions so

00:28:32,320 --> 00:28:38,559
thank you for your attention

00:28:34,480 --> 00:28:43,360
uh i hope that you liked our tool

00:28:38,559 --> 00:28:47,840
uh it's a big pleasure to introduce it

00:28:43,360 --> 00:28:50,880
so see you on the next pagecon

00:28:47,840 --> 00:28:59,840
have a nice time and bye

00:28:50,880 --> 00:28:59,840
thank you have a nice day bye

00:29:11,360 --> 00:29:13,440

YouTube URL: https://www.youtube.com/watch?v=KZP_jzCGMYo


