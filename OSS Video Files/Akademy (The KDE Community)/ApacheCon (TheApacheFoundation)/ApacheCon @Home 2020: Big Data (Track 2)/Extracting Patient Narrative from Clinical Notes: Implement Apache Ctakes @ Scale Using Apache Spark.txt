Title: Extracting Patient Narrative from Clinical Notes: Implement Apache Ctakes @ Scale Using Apache Spark
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Big Data (Track 2)
Description: 
	Extracting Patient Narrative from Clinical Notes : Implementing Apache Ctakes at scale using Apache Spark
Debdipto Misra

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Patient notes not only document patient history and clinical conditions but are rich in contextual data and are usually more reliable sources of medical information compared to discrete values in the Electronic Health Record (EHR). For a medium-sized integrated Health System like Geisinger this amounts to approximately fifty thousand notes each day. For information extraction on retrospective data, the volume can run into millions of notes depending on the selection criteria. This talk describes the journey taken by the Data Science Team at Geisinger to implement a distributed pipeline which uses Apache Ctakes as the Natural Language Processing (NLP) Engine to annotate notes across the entire spectrum of patient care. From re-writing certain components in the Ctakes engine to architecting data store and pipeline optimization for a better throughput, this talk delves into various technical difficulties faced while aspiring to truly do NLP at scale on clinical notes. Towards the end, the talk also demonstrates few usecases and how using Ctakes has helped clinicians and stakeholders to extract patient narratives from patient notes using Apache Solr and Banana.

Debdipto Misra is a Data Scientist with Geisinger Health. Previously, he worked with AOL Inc. as a Platform Engineer in Audience Analytics and with EMC Corp. as a Systems Engineer. He has worked in the Data Mining and Analytics space for over half a decade. He won a fellowship and presented the “Evolution of Prosthetics using Pattern Recognition on Ultrasound Signals” at the 2014 IEEE Big Data Conference in Washington, DC. He has also published at multiple journals and presented at healthcare conferences like HIMSS. Currently,his main focus is on building capacity planning tools for healthcare organizations for bed-supply demand using various deep learning approaches and integrating it with patient notes.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,640 --> 00:00:28,840
that's fine

00:00:25,439 --> 00:00:30,080
i think i'll probably go with this for

00:00:28,840 --> 00:00:33,440
now

00:00:30,080 --> 00:00:36,559
so as i was saying uh we are in

00:00:33,440 --> 00:00:38,800
rural and seminaryville pennsylvania and

00:00:36,559 --> 00:00:41,360
i work as a data scientist here

00:00:38,800 --> 00:00:43,600
uh and and i joined guy singer around

00:00:41,360 --> 00:00:45,440
four years back in 2016

00:00:43,600 --> 00:00:46,719
and that was also around the time when

00:00:45,440 --> 00:00:48,960
we were setting up

00:00:46,719 --> 00:00:50,000
our data science team and an enterprise

00:00:48,960 --> 00:00:53,039
data platform

00:00:50,000 --> 00:00:55,600
using hadoop and big data um

00:00:53,039 --> 00:00:57,760
so today i'm probably going to talk

00:00:55,600 --> 00:00:59,840
about some of the modifications and

00:00:57,760 --> 00:01:02,719
customizations that we made

00:00:59,840 --> 00:01:04,640
uh on apache ctex and how it really

00:01:02,719 --> 00:01:07,840
helped us

00:01:04,640 --> 00:01:10,880
take some of the projects off the ground

00:01:07,840 --> 00:01:12,000
and i'm going to talk about uh three use

00:01:10,880 --> 00:01:13,920
cases today

00:01:12,000 --> 00:01:16,240
the first one is going to be the

00:01:13,920 --> 00:01:18,720
incidental lung nodule use case

00:01:16,240 --> 00:01:20,400
uh followed by the thyroid module which

00:01:18,720 --> 00:01:23,759
is pretty similar to the first

00:01:20,400 --> 00:01:27,280
first model module and you'll see why

00:01:23,759 --> 00:01:29,840
and then i'll probably talk about

00:01:27,280 --> 00:01:32,079
a few slides about the the project that

00:01:29,840 --> 00:01:34,960
we are currently

00:01:32,079 --> 00:01:36,560
doing right now which again relates to

00:01:34,960 --> 00:01:39,680
stroke

00:01:36,560 --> 00:01:42,399
so without further ado i'll probably

00:01:39,680 --> 00:01:45,920
start with the lung nodule use case

00:01:42,399 --> 00:01:49,200
so as with any health system in the u.s

00:01:45,920 --> 00:01:51,759
uh geisinger gets food a lot

00:01:49,200 --> 00:01:52,399
and one of the causes when the

00:01:51,759 --> 00:01:54,479
leadership

00:01:52,399 --> 00:01:56,719
looked into it was incidental lung

00:01:54,479 --> 00:01:58,399
nodules so we had incidental lung

00:01:56,719 --> 00:02:02,000
nodules which were missing

00:01:58,399 --> 00:02:03,200
in the radiology nodes so what usually

00:02:02,000 --> 00:02:06,960
happens is

00:02:03,200 --> 00:02:10,000
you have someone who comes in for a ct

00:02:06,960 --> 00:02:13,040
the radiologist makes note of a nodule

00:02:10,000 --> 00:02:14,239
in the notes but it does not get

00:02:13,040 --> 00:02:17,360
followed up

00:02:14,239 --> 00:02:17,920
cut to two years later the patient shows

00:02:17,360 --> 00:02:20,840
up

00:02:17,920 --> 00:02:22,239
in the pulmonary clinic with a

00:02:20,840 --> 00:02:24,239
malignancy

00:02:22,239 --> 00:02:25,760
and and what happens is and as i

00:02:24,239 --> 00:02:29,200
mentioned as i stress

00:02:25,760 --> 00:02:32,879
since geisinger caters mostly to a

00:02:29,200 --> 00:02:35,200
semi-urban and rural population most of

00:02:32,879 --> 00:02:36,239
our patients are on medicare and

00:02:35,200 --> 00:02:39,360
medicaid

00:02:36,239 --> 00:02:40,879
and there are stringent cms criterias

00:02:39,360 --> 00:02:44,800
and guidelines which

00:02:40,879 --> 00:02:46,800
actually drive how much we get paid

00:02:44,800 --> 00:02:48,840
so closing this loop on the incidental

00:02:46,800 --> 00:02:50,959
nodules is

00:02:48,840 --> 00:02:51,840
actually a big deal for us both

00:02:50,959 --> 00:02:55,360
clinically and

00:02:51,840 --> 00:02:56,879
financially but but can you actually

00:02:55,360 --> 00:02:59,760
have physicians or nurses

00:02:56,879 --> 00:03:01,519
read through the radiology notes that's

00:02:59,760 --> 00:03:03,440
probably not feasible

00:03:01,519 --> 00:03:05,519
certainly not feasible for a health

00:03:03,440 --> 00:03:07,680
system of geisinger's size

00:03:05,519 --> 00:03:09,440
which turns out around 50 to 60 000

00:03:07,680 --> 00:03:11,440
patient notes each day

00:03:09,440 --> 00:03:13,360
so that's when we started looking at an

00:03:11,440 --> 00:03:16,400
automated way and that's when we

00:03:13,360 --> 00:03:16,400
settled down seated

00:03:16,480 --> 00:03:21,120
so as i mentioned about the malignancy

00:03:18,959 --> 00:03:24,319
twenty percent of the total medicare

00:03:21,120 --> 00:03:27,519
cost is due to cancer and

00:03:24,319 --> 00:03:30,879
and actually not only does it uh

00:03:27,519 --> 00:03:33,599
give the hospital a good roi it also

00:03:30,879 --> 00:03:34,239
helps deliver a bit better patient care

00:03:33,599 --> 00:03:36,080
right

00:03:34,239 --> 00:03:38,720
i mean if there is a sub centimeter

00:03:36,080 --> 00:03:42,000
nodule which gets caught

00:03:38,720 --> 00:03:44,560
a year or even six months prior the

00:03:42,000 --> 00:03:46,319
survival rates actually increase pretty

00:03:44,560 --> 00:03:48,959
extra exponentially and there is a lot

00:03:46,319 --> 00:03:51,360
of literature on that

00:03:48,959 --> 00:03:52,720
so this was the beginning of the close

00:03:51,360 --> 00:03:55,120
the loop project

00:03:52,720 --> 00:03:57,360
uh where we identified the incidental

00:03:55,120 --> 00:04:00,080
log modules through nlp

00:03:57,360 --> 00:04:02,480
then that results actually gets chart

00:04:00,080 --> 00:04:05,680
reviewed by a nurse navigator

00:04:02,480 --> 00:04:08,720
and these and then it gets filtered down

00:04:05,680 --> 00:04:08,720
to a

00:04:09,120 --> 00:04:13,040
scheduler so that they are brought in

00:04:11,439 --> 00:04:14,720
back to the pulmonary clinic

00:04:13,040 --> 00:04:16,479
and today i'm mostly going to talk about

00:04:14,720 --> 00:04:19,120
the primary nodule

00:04:16,479 --> 00:04:19,680
portion that lp part of it so as i

00:04:19,120 --> 00:04:24,320
mentioned

00:04:19,680 --> 00:04:27,040
we have an in-house hadoop platform

00:04:24,320 --> 00:04:28,000
why in-house again people most of you

00:04:27,040 --> 00:04:30,320
who are in healthcare

00:04:28,000 --> 00:04:31,759
probably know the regulatory cost of

00:04:30,320 --> 00:04:33,199
setting something up in the cloud

00:04:31,759 --> 00:04:36,120
although it is happening

00:04:33,199 --> 00:04:37,600
uh but this was way back when in early

00:04:36,120 --> 00:04:40,800
2015-16

00:04:37,600 --> 00:04:42,720
and we wanted to go full in-house we

00:04:40,800 --> 00:04:44,240
you you probably if you if you are in

00:04:42,720 --> 00:04:45,120
the healthcare domain you've probably

00:04:44,240 --> 00:04:47,440
seen

00:04:45,120 --> 00:04:49,680
a bunch of heterogeneous data sources

00:04:47,440 --> 00:04:52,400
from a bunch of different vendors

00:04:49,680 --> 00:04:53,919
again what this makes getting a

00:04:52,400 --> 00:04:56,560
longitudinal picture

00:04:53,919 --> 00:04:58,400
of the patient really difficult so one

00:04:56,560 --> 00:05:00,240
good thing was that with the big data

00:04:58,400 --> 00:05:02,639
hadoop platform we actually

00:05:00,240 --> 00:05:04,080
developed an enterprise data warehouse

00:05:02,639 --> 00:05:11,840
sort of like a data lake

00:05:04,080 --> 00:05:11,840
which we then used for our nlp

00:05:15,120 --> 00:05:21,360
skip this side yeah this one so this is

00:05:18,479 --> 00:05:23,440
so let me talk a bit about the scale of

00:05:21,360 --> 00:05:25,600
the nodes that we are dealing with here

00:05:23,440 --> 00:05:27,120
so we are talking about around around

00:05:25,600 --> 00:05:29,919
200 million notes in

00:05:27,120 --> 00:05:30,800
epic you know historical obviously we

00:05:29,919 --> 00:05:33,520
were not going to

00:05:30,800 --> 00:05:35,039
run it on 200 million nodes we were

00:05:33,520 --> 00:05:35,759
going to have selection criteria for

00:05:35,039 --> 00:05:39,039
selecting

00:05:35,759 --> 00:05:42,560
selecting some of the nodes by using

00:05:39,039 --> 00:05:44,720
procedure codes etc etc

00:05:42,560 --> 00:05:47,039
but still we generate around 60 000

00:05:44,720 --> 00:05:49,520
nodes each day

00:05:47,039 --> 00:05:50,479
and we actually have developed the

00:05:49,520 --> 00:05:53,360
pipeline

00:05:50,479 --> 00:05:54,560
where by using spark we can annotate

00:05:53,360 --> 00:05:57,280
around 50 000

00:05:54,560 --> 00:05:58,319
notes an hour and i'm going to delve

00:05:57,280 --> 00:06:01,120
into how

00:05:58,319 --> 00:06:02,080
and what modifications we did that um

00:06:01,120 --> 00:06:04,840
again this

00:06:02,080 --> 00:06:07,120
slide i'm just going to skip for this

00:06:04,840 --> 00:06:10,240
audience

00:06:07,120 --> 00:06:12,479
similarly with this one so yeah so we

00:06:10,240 --> 00:06:14,800
have so how our pipeline works is we

00:06:12,479 --> 00:06:19,759
have radiology notes for the last

00:06:14,800 --> 00:06:21,199
uh 10 15 years we run it through our

00:06:19,759 --> 00:06:23,440
ctex pipeline

00:06:21,199 --> 00:06:25,360
and one and one of the first

00:06:23,440 --> 00:06:26,240
modifications that we did to our

00:06:25,360 --> 00:06:28,560
pipeline

00:06:26,240 --> 00:06:30,319
is we actually separated the

00:06:28,560 --> 00:06:32,479
tokenization out so we

00:06:30,319 --> 00:06:34,639
run it in stages instead of running the

00:06:32,479 --> 00:06:36,800
whole pipeline from uh

00:06:34,639 --> 00:06:37,680
center from from center boundary

00:06:36,800 --> 00:06:40,720
detection

00:06:37,680 --> 00:06:44,319
all the way up to uh sentiment analysis

00:06:40,720 --> 00:06:48,240
and then in the end we have some custom

00:06:44,319 --> 00:06:49,599
annotators which actually extract the

00:06:48,240 --> 00:06:51,759
some of the attributes for the lung

00:06:49,599 --> 00:06:54,000
nodules out so for example

00:06:51,759 --> 00:06:55,360
it picks out the size the location etc

00:06:54,000 --> 00:06:58,479
and so on and so forth

00:06:55,360 --> 00:07:02,560
but before that we actually run it till

00:06:58,479 --> 00:07:03,759
the umls dictionary to find concepts for

00:07:02,560 --> 00:07:06,720
lung module

00:07:03,759 --> 00:07:09,680
and as you can see that's where kind of

00:07:06,720 --> 00:07:13,280
the bulk of the note gets filtered out

00:07:09,680 --> 00:07:15,440
so around 10 million notes historically

00:07:13,280 --> 00:07:16,560
we filter out around 9.7 million because

00:07:15,440 --> 00:07:19,919
they do not have

00:07:16,560 --> 00:07:22,319
any list of uh quiz which

00:07:19,919 --> 00:07:24,479
which are relevant to the use case we

00:07:22,319 --> 00:07:25,280
are left with around 300 000 which again

00:07:24,479 --> 00:07:27,919
is nothing to

00:07:25,280 --> 00:07:29,360
sneeze at and then we run it through our

00:07:27,919 --> 00:07:33,120
sentiment analysis

00:07:29,360 --> 00:07:38,160
our custom annotator for

00:07:33,120 --> 00:07:38,160
getting the attributes location size etc

00:07:38,400 --> 00:07:41,840
um so some of the modifications that we

00:07:40,800 --> 00:07:44,960
made so far

00:07:41,840 --> 00:07:48,080
first of all every our nodes

00:07:44,960 --> 00:07:52,479
are any on hdfs we use

00:07:48,080 --> 00:07:54,160
hive as our data store and obviously

00:07:52,479 --> 00:07:57,360
processing involved cleaning special

00:07:54,160 --> 00:07:59,520
characters and so on and so forth

00:07:57,360 --> 00:08:00,720
and then what we do is as i mentioned we

00:07:59,520 --> 00:08:03,440
first run

00:08:00,720 --> 00:08:04,639
uh the first three or four stages from

00:08:03,440 --> 00:08:08,479
boundary detection

00:08:04,639 --> 00:08:10,400
uh tokenization just till before

00:08:08,479 --> 00:08:12,560
the dictionary phase which is when the

00:08:10,400 --> 00:08:13,360
dictionary lookup happens and we store

00:08:12,560 --> 00:08:16,479
the cash

00:08:13,360 --> 00:08:20,080
in an age based table uh

00:08:16,479 --> 00:08:22,800
in a base64 format now why

00:08:20,080 --> 00:08:25,120
hbase because with with the scale of

00:08:22,800 --> 00:08:28,080
nodes that we are dealing with here

00:08:25,120 --> 00:08:28,560
it's important that we are able to scale

00:08:28,080 --> 00:08:31,520
and

00:08:28,560 --> 00:08:32,800
if you guys and if you guys have i think

00:08:31,520 --> 00:08:34,719
most of these audience have worked with

00:08:32,800 --> 00:08:38,000
c tech so you guys know that

00:08:34,719 --> 00:08:42,399
uh the cash xml can be pretty verbose

00:08:38,000 --> 00:08:44,560
so what we do is we uh base64 encode it

00:08:42,399 --> 00:08:45,519
and push it to each base by using our

00:08:44,560 --> 00:08:49,200
note id

00:08:45,519 --> 00:08:51,279
as what as the as the key and

00:08:49,200 --> 00:08:54,080
so we do it so first we run it till

00:08:51,279 --> 00:08:56,320
before uh the dictionary annotation then

00:08:54,080 --> 00:08:59,040
we run the dictionary separately

00:08:56,320 --> 00:09:00,640
and once we run the dictionary we filter

00:08:59,040 --> 00:09:02,720
out the nodes based on specific

00:09:00,640 --> 00:09:05,519
queries now how do we select this

00:09:02,720 --> 00:09:07,279
queries that actually varies from use

00:09:05,519 --> 00:09:09,920
case to use case

00:09:07,279 --> 00:09:10,800
usually we work with physicians and

00:09:09,920 --> 00:09:12,800
doctors

00:09:10,800 --> 00:09:14,399
to come up with a list of concepts and

00:09:12,800 --> 00:09:16,640
then of course it's

00:09:14,399 --> 00:09:17,680
it's not very difficult to map that to

00:09:16,640 --> 00:09:19,760
existing

00:09:17,680 --> 00:09:21,360
quiz although again it's not a trivial

00:09:19,760 --> 00:09:25,200
task

00:09:21,360 --> 00:09:28,240
once we see a hit with a particular

00:09:25,200 --> 00:09:30,640
kui that's when we take those notes or

00:09:28,240 --> 00:09:32,959
take those cases to be more exact

00:09:30,640 --> 00:09:33,680
and run it through our sentiment

00:09:32,959 --> 00:09:37,360
annotation

00:09:33,680 --> 00:09:39,440
output and again all our intermediate

00:09:37,360 --> 00:09:41,839
cache files are stored in hbase

00:09:39,440 --> 00:09:44,160
so that we can we don't have to

00:09:41,839 --> 00:09:46,000
reprocess the nodes over and over again

00:09:44,160 --> 00:09:48,080
especially let's say if we have a

00:09:46,000 --> 00:09:51,279
radiology node which we want to run

00:09:48,080 --> 00:09:52,959
with a set of gui c1 and then tomorrow

00:09:51,279 --> 00:09:53,760
we want to run with another set of query

00:09:52,959 --> 00:09:55,519
c2

00:09:53,760 --> 00:09:56,880
we can probably go back and look at the

00:09:55,519 --> 00:09:58,560
cache

00:09:56,880 --> 00:10:00,080
for the pre-dictionary stage and load it

00:09:58,560 --> 00:10:02,320
again so

00:10:00,080 --> 00:10:03,600
once we and then we of course look at

00:10:02,320 --> 00:10:05,920
the sentiment analysis

00:10:03,600 --> 00:10:06,959
and we have the annotation we look at

00:10:05,920 --> 00:10:11,120
the concept whether

00:10:06,959 --> 00:10:11,120
what's the polarity uh whether

00:10:12,880 --> 00:10:19,760
whether it's although i mean a bit of

00:10:16,320 --> 00:10:20,640
a hit and miss for us uh but yeah we can

00:10:19,760 --> 00:10:23,120
get that

00:10:20,640 --> 00:10:24,160
we can get to that particular discussion

00:10:23,120 --> 00:10:26,000
um so yeah

00:10:24,160 --> 00:10:27,440
as i mentioned we have custom annotators

00:10:26,000 --> 00:10:29,200
which again uh

00:10:27,440 --> 00:10:31,440
for each use case so for the long nodule

00:10:29,200 --> 00:10:34,560
use case we have custom annotators

00:10:31,440 --> 00:10:37,440
which then extracts uh

00:10:34,560 --> 00:10:38,640
nodule size location of the nodule and

00:10:37,440 --> 00:10:41,440
so on and so forth

00:10:38,640 --> 00:10:43,519
similarly we have uh custom annotators

00:10:41,440 --> 00:10:45,600
for the higher for the other use cases

00:10:43,519 --> 00:10:47,040
and finally we again store it back on

00:10:45,600 --> 00:10:50,399
hdfs and

00:10:47,040 --> 00:10:54,560
and we and expose it as a hive table

00:10:50,399 --> 00:10:58,839
so that reporting can be based off it

00:10:54,560 --> 00:11:00,720
so for the lung normal use we

00:10:58,839 --> 00:11:03,920
had

00:11:00,720 --> 00:11:06,800
of radiology notes valid

00:11:03,920 --> 00:11:07,920
clinical information and these numbers

00:11:06,800 --> 00:11:09,920
are reflected

00:11:07,920 --> 00:11:11,519
from that validation of that gold

00:11:09,920 --> 00:11:14,959
standard set

00:11:11,519 --> 00:11:16,000
um again so far so long right zero to

00:11:14,959 --> 00:11:18,800
long rates 4b

00:11:16,000 --> 00:11:19,920
that's a clinical criteria that we have

00:11:18,800 --> 00:11:24,160
to label

00:11:19,920 --> 00:11:24,720
the notes on so as you can see long red

00:11:24,160 --> 00:11:28,240
00:11:24,720 --> 00:11:30,000
is incomplete with almost negligible

00:11:28,240 --> 00:11:33,200
risk of cancer all the way up to

00:11:30,000 --> 00:11:34,399
4b and again for making each one of

00:11:33,200 --> 00:11:36,800
those decisions

00:11:34,399 --> 00:11:39,920
you need those extract attributes which

00:11:36,800 --> 00:11:42,959
i which we extract in the last

00:11:39,920 --> 00:11:46,160
stage of our of our annotation which is

00:11:42,959 --> 00:11:49,600
we need our size

00:11:46,160 --> 00:11:51,680
we need polarity and we also need

00:11:49,600 --> 00:11:53,760
the location and we also have a few

00:11:51,680 --> 00:11:58,639
descriptive keywords like whether

00:11:53,760 --> 00:12:01,839
it's growing or not so

00:11:58,639 --> 00:12:04,880
so this is what a typical

00:12:01,839 --> 00:12:09,120
output for the lung nodule

00:12:04,880 --> 00:12:11,839
use case looks like um sorry

00:12:09,120 --> 00:12:13,600
as i mentioned uh you'll probably so so

00:12:11,839 --> 00:12:14,480
so basically the goal of this whole

00:12:13,600 --> 00:12:16,959
exercise

00:12:14,480 --> 00:12:18,399
is kind of to take the unstructured text

00:12:16,959 --> 00:12:22,079
that we have

00:12:18,399 --> 00:12:25,440
from uh uh the notes

00:12:22,079 --> 00:12:26,000
and structure it by and label it and pin

00:12:25,440 --> 00:12:28,560
it

00:12:26,000 --> 00:12:29,040
and this obviously the end goal is to

00:12:28,560 --> 00:12:32,079
kind of

00:12:29,040 --> 00:12:33,200
bin the patients and then have a nurse

00:12:32,079 --> 00:12:35,920
practitioner or

00:12:33,200 --> 00:12:36,800
scheduler reach out to them so this is

00:12:35,920 --> 00:12:39,680
kind of our

00:12:36,800 --> 00:12:41,200
uh are the final output of the lp

00:12:39,680 --> 00:12:43,519
pipeline

00:12:41,200 --> 00:12:45,440
um as i mentioned we had a validation

00:12:43,519 --> 00:12:48,000
set of around thousand nodes

00:12:45,440 --> 00:12:48,560
validated by four physician information

00:12:48,000 --> 00:12:50,320
uh

00:12:48,560 --> 00:12:52,880
we've done the usual type one type two

00:12:50,320 --> 00:12:55,360
errors which you saw

00:12:52,880 --> 00:12:56,079
the next use case is a very similar use

00:12:55,360 --> 00:12:58,800
case

00:12:56,079 --> 00:13:00,079
this is finding incidental thyroid

00:12:58,800 --> 00:13:02,800
nodules

00:13:00,079 --> 00:13:03,839
and again just to give you a brief idea

00:13:02,800 --> 00:13:07,760
about the use case

00:13:03,839 --> 00:13:09,600
we have a bunch of rules and attributes

00:13:07,760 --> 00:13:11,760
that we need to extract

00:13:09,600 --> 00:13:13,360
like whether it's part of the leftist

00:13:11,760 --> 00:13:14,959
mass whether it's heterogeneous

00:13:13,360 --> 00:13:18,480
calcification so on and

00:13:14,959 --> 00:13:20,959
so forth but this is very similar to the

00:13:18,480 --> 00:13:21,920
long-run use case and you can see why

00:13:20,959 --> 00:13:25,519
this is

00:13:21,920 --> 00:13:29,120
again this is an example uh

00:13:25,519 --> 00:13:31,600
ct note that you have and of course

00:13:29,120 --> 00:13:32,880
with the final output when presented in

00:13:31,600 --> 00:13:36,000
this format

00:13:32,880 --> 00:13:39,519
allows us to discretize and pin

00:13:36,000 --> 00:13:39,519
our patients here

00:13:40,399 --> 00:13:44,560
this is the xml the ner and so on and so

00:13:43,839 --> 00:13:47,839
forth

00:13:44,560 --> 00:13:49,120
uh i don't have anything for this slide

00:13:47,839 --> 00:13:52,320
but let me go

00:13:49,120 --> 00:13:54,800
skip over quickly and yeah these are

00:13:52,320 --> 00:13:56,639
our statistics for the lung normal use

00:13:54,800 --> 00:13:59,680
case

00:13:56,639 --> 00:14:02,399
similarly we had the same uh

00:13:59,680 --> 00:14:04,000
validation set by a by a bunch of

00:14:02,399 --> 00:14:04,880
clinician physicians and this was a

00:14:04,000 --> 00:14:07,199
different validation

00:14:04,880 --> 00:14:08,320
this was not the 1096 that we had

00:14:07,199 --> 00:14:11,600
previously

00:14:08,320 --> 00:14:12,560
uh this was uh we just another gold

00:14:11,600 --> 00:14:14,560
standard that we

00:14:12,560 --> 00:14:17,519
that we came up with internally just for

00:14:14,560 --> 00:14:21,120
the tiger modules

00:14:17,519 --> 00:14:22,560
so so this is something which we are

00:14:21,120 --> 00:14:24,800
working on right now

00:14:22,560 --> 00:14:26,160
uh so we are working on a novel

00:14:24,800 --> 00:14:28,480
screening tool

00:14:26,160 --> 00:14:29,440
for stroke prediction so what happens is

00:14:28,480 --> 00:14:31,760
in the er

00:14:29,440 --> 00:14:33,440
when somebody presents themselves with

00:14:31,760 --> 00:14:37,120
stroke or stroke-like

00:14:33,440 --> 00:14:40,399
symptoms it's a bit difficult to discern

00:14:37,120 --> 00:14:43,360
whether it's a stroke mimic or not and

00:14:40,399 --> 00:14:45,760
even before we look at the patient

00:14:43,360 --> 00:14:48,720
history or the clinical criteria

00:14:45,760 --> 00:14:49,279
we want to have sort of like a broad

00:14:48,720 --> 00:14:52,720
filter

00:14:49,279 --> 00:14:54,639
using the ed triage nodes uh to kind of

00:14:52,720 --> 00:14:56,399
separate out the strokes

00:14:54,639 --> 00:14:59,120
and the stroke mimics from the rest of

00:14:56,399 --> 00:15:02,399
the cohort

00:14:59,120 --> 00:15:05,839
uh so somebody experiences dizziness

00:15:02,399 --> 00:15:08,160
works into the e walks into the ed

00:15:05,839 --> 00:15:09,360
the ed triage note is generated which

00:15:08,160 --> 00:15:13,839
usually are

00:15:09,360 --> 00:15:13,839
very small i think

00:15:18,880 --> 00:15:25,360
once the patient is identified

00:15:22,240 --> 00:15:28,720
uh so so obviously we run our ctex

00:15:25,360 --> 00:15:31,199
on the ed notes similarly we

00:15:28,720 --> 00:15:32,480
have a list of curated concepts that we

00:15:31,199 --> 00:15:34,480
are interested in

00:15:32,480 --> 00:15:36,560
and we definitely look at their

00:15:34,480 --> 00:15:38,720
attributes like polarity

00:15:36,560 --> 00:15:40,160
whether it's a sign or symptom etc and

00:15:38,720 --> 00:15:43,440
so on and so forth

00:15:40,160 --> 00:15:44,480
and we triage them accordingly and also

00:15:43,440 --> 00:15:48,079
what happens is

00:15:44,480 --> 00:15:51,680
uh each triage notes gets decomposed

00:15:48,079 --> 00:15:55,279
as a word of quiz if you will

00:15:51,680 --> 00:15:57,519
similar to a bag of words but here

00:15:55,279 --> 00:16:00,160
we actually use quiz instead of words

00:15:57,519 --> 00:16:03,279
which are more robust

00:16:00,160 --> 00:16:05,040
and use that and this and the

00:16:03,279 --> 00:16:07,440
reason i mention is this is later on

00:16:05,040 --> 00:16:08,160
used for training a machine learning

00:16:07,440 --> 00:16:12,320
model

00:16:08,160 --> 00:16:14,959
which we are in which we are thinking of

00:16:12,320 --> 00:16:15,759
implementing in our uh acute care

00:16:14,959 --> 00:16:19,440
setting

00:16:15,759 --> 00:16:22,480
uh and we are working with one vendor

00:16:19,440 --> 00:16:25,920
on on this uh on coming up with this

00:16:22,480 --> 00:16:28,399
implementation um

00:16:25,920 --> 00:16:29,600
so yeah our case control definition so

00:16:28,399 --> 00:16:32,160
we had as

00:16:29,600 --> 00:16:33,759
i mentioned cases are people who

00:16:32,160 --> 00:16:36,639
experience sign symptoms

00:16:33,759 --> 00:16:38,399
for stroke and our super and we have

00:16:36,639 --> 00:16:41,279
super control definitions which

00:16:38,399 --> 00:16:42,480
excludes everybody except those patients

00:16:41,279 --> 00:16:45,839
which we use

00:16:42,480 --> 00:16:47,600
for uh and again we generate care quiz

00:16:45,839 --> 00:16:49,279
for both the cases and the super

00:16:47,600 --> 00:16:52,480
controls which serves as

00:16:49,279 --> 00:16:56,720
the features for our machine learning

00:16:52,480 --> 00:17:00,560
model so

00:16:56,720 --> 00:17:02,639
yeah i mean i'm probably so these are

00:17:00,560 --> 00:17:05,760
some of the concepts that we saw

00:17:02,639 --> 00:17:09,439
when analyzing the stroke uh

00:17:05,760 --> 00:17:10,319
cohort for uh both controls and super

00:17:09,439 --> 00:17:13,839
controls

00:17:10,319 --> 00:17:17,199
uh this is for a super control so the

00:17:13,839 --> 00:17:20,799
and yeah

00:17:17,199 --> 00:17:20,799
so this is for the cases

00:17:21,360 --> 00:17:27,760
so i think i have so our next step

00:17:25,120 --> 00:17:29,919
is obviously integrating this with

00:17:27,760 --> 00:17:33,039
real-time data feed from our

00:17:29,919 --> 00:17:33,840
vendor and then having an alert

00:17:33,039 --> 00:17:35,919
mechanism

00:17:33,840 --> 00:17:37,039
which which can push notifications to

00:17:35,919 --> 00:17:40,480
the ehr to the

00:17:37,039 --> 00:17:43,520
physician or even at least trigger a

00:17:40,480 --> 00:17:45,760
protocol which then would help the

00:17:43,520 --> 00:17:49,120
triage nurse triage the patient

00:17:45,760 --> 00:17:52,080
correctly uh

00:17:49,120 --> 00:17:52,960
and another thing that we want to

00:17:52,080 --> 00:17:54,799
mention is

00:17:52,960 --> 00:17:56,880
so what we have done is we have also

00:17:54,799 --> 00:18:00,160
built a solar dashboard

00:17:56,880 --> 00:18:02,880
of this data that we get after uh

00:18:00,160 --> 00:18:04,720
running it through the pipeline so our

00:18:02,880 --> 00:18:06,559
solar dashboards if you are familiar

00:18:04,720 --> 00:18:09,679
with solar

00:18:06,559 --> 00:18:12,559
not only allows you to type and

00:18:09,679 --> 00:18:13,600
look at and pull up the nodes but you

00:18:12,559 --> 00:18:16,160
can actually

00:18:13,600 --> 00:18:17,120
give do facet search and let's say you

00:18:16,160 --> 00:18:19,760
want to search

00:18:17,120 --> 00:18:20,960
all nodes which have a certain

00:18:19,760 --> 00:18:24,000
medication

00:18:20,960 --> 00:18:27,039
right present you could probably do that

00:18:24,000 --> 00:18:29,280
much better using the output of c

00:18:27,039 --> 00:18:31,360
takes so the index for it has all that

00:18:29,280 --> 00:18:34,240
meta information for each document

00:18:31,360 --> 00:18:35,039
it has the quiz it has the polarity and

00:18:34,240 --> 00:18:37,280
you can use

00:18:35,039 --> 00:18:38,799
facet search on a solar dashboard to

00:18:37,280 --> 00:18:40,320
actually pull up the whole nodes

00:18:38,799 --> 00:18:42,000
and this is also something which is

00:18:40,320 --> 00:18:44,880
operational hospital

00:18:42,000 --> 00:18:45,679
and this is very useful especially for

00:18:44,880 --> 00:18:48,880
doing

00:18:45,679 --> 00:18:51,840
data analysis and data exploration for

00:18:48,880 --> 00:18:54,640
our for our leadership and for our

00:18:51,840 --> 00:18:57,039
doctors and clinicians and physicians

00:18:54,640 --> 00:18:59,600
so yeah this is a nice use case i'm

00:18:57,039 --> 00:19:02,640
using both apache ctx and apache

00:18:59,600 --> 00:19:05,440
solar uh

00:19:02,640 --> 00:19:06,880
finally uh shout out to our leadership

00:19:05,440 --> 00:19:10,000
team

00:19:06,880 --> 00:19:11,280
so i report i come under

00:19:10,000 --> 00:19:13,600
the steel institute for health

00:19:11,280 --> 00:19:14,640
innovation which is led by dr karen

00:19:13,600 --> 00:19:18,320
murphy

00:19:14,640 --> 00:19:19,919
uh dr dave vader is our chief data

00:19:18,320 --> 00:19:22,960
informatics officer

00:19:19,919 --> 00:19:26,480
and of course i report to

00:19:22,960 --> 00:19:27,039
casey who's our abp for the lung nordian

00:19:26,480 --> 00:19:30,080
project

00:19:27,039 --> 00:19:32,000
we had dr patel who is the chair for

00:19:30,080 --> 00:19:34,240
radiology

00:19:32,000 --> 00:19:36,000
and we actually came up that he was and

00:19:34,240 --> 00:19:37,280
him and dr factor again who is a

00:19:36,000 --> 00:19:39,200
pulmonary thoracic

00:19:37,280 --> 00:19:40,320
surgeon they were the driving force

00:19:39,200 --> 00:19:43,360
behind this project

00:19:40,320 --> 00:19:46,799
we had a lot of uh

00:19:43,360 --> 00:19:47,679
help from meg meg horgan she's a nurse

00:19:46,799 --> 00:19:50,160
navigator

00:19:47,679 --> 00:19:51,200
and she actually helped us a lot in

00:19:50,160 --> 00:19:53,280
validating

00:19:51,200 --> 00:19:55,360
coming up with a curated list of

00:19:53,280 --> 00:19:58,400
concepts etcetera and so forth

00:19:55,360 --> 00:20:01,679
uh finally shout out to satish who

00:19:58,400 --> 00:20:04,880
also helped me develop the solar

00:20:01,679 --> 00:20:08,559
and the elasticsearch indexes

00:20:04,880 --> 00:20:10,480
and jody and dhruv for coming up

00:20:08,559 --> 00:20:13,520
so they are part of the engineering team

00:20:10,480 --> 00:20:13,520
and of course with that

00:20:16,400 --> 00:20:21,280
this procreation project uh doctor

00:20:19,919 --> 00:20:23,039
and this is something which is still in

00:20:21,280 --> 00:20:27,039
the works so we

00:20:23,039 --> 00:20:29,120
are looking to take this uh probably

00:20:27,039 --> 00:20:30,960
in production or deployed in the

00:20:29,120 --> 00:20:32,880
hospital early next year

00:20:30,960 --> 00:20:34,080
that's our timeline we'll see how it

00:20:32,880 --> 00:20:36,240
goes

00:20:34,080 --> 00:20:39,520
so i think i have reached the end of my

00:20:36,240 --> 00:20:42,720
slide which is good i wanted to have

00:20:39,520 --> 00:20:49,840
some time left for questions so

00:20:42,720 --> 00:20:49,840
let me go back

00:20:50,720 --> 00:20:55,360
thank you very much so we do have a

00:20:53,840 --> 00:20:57,360
couple of questions waiting

00:20:55,360 --> 00:20:58,720
uh i can see that you're looking at your

00:20:57,360 --> 00:21:02,880
chat so

00:20:58,720 --> 00:21:06,000
i don't need to read them all out to you

00:21:02,880 --> 00:21:08,080
so does c takes work only with english

00:21:06,000 --> 00:21:09,679
definitely not because yesterday i was

00:21:08,080 --> 00:21:11,039
in a session

00:21:09,679 --> 00:21:13,039
where they were using spanish and

00:21:11,039 --> 00:21:16,080
catalan

00:21:13,039 --> 00:21:19,280
but yeah i and i think

00:21:16,080 --> 00:21:20,960
uh they and i think yeah uh sean if you

00:21:19,280 --> 00:21:22,080
if you have more details on this

00:21:20,960 --> 00:21:25,280
probably you can

00:21:22,080 --> 00:21:28,240
uh take this uh uh offline

00:21:25,280 --> 00:21:30,240
but yeah the short answer is it it is

00:21:28,240 --> 00:21:32,159
not only limited to english

00:21:30,240 --> 00:21:33,919
so can you talk more about the solar

00:21:32,159 --> 00:21:35,760
dashboard and indices

00:21:33,919 --> 00:21:36,960
are the queries stored in a field as a

00:21:35,760 --> 00:21:38,559
basic facet

00:21:36,960 --> 00:21:40,000
or is there any ontological aspect to

00:21:38,559 --> 00:21:42,720
the fields yeah so

00:21:40,000 --> 00:21:44,320
how we design so basically uh if you are

00:21:42,720 --> 00:21:47,120
if you are aware of the solar

00:21:44,320 --> 00:21:49,200
architecture you need to create the

00:21:47,120 --> 00:21:52,159
solar indices right

00:21:49,200 --> 00:21:53,520
so what we do is as i mentioned we have

00:21:52,159 --> 00:21:56,159
a hbase table

00:21:53,520 --> 00:21:57,120
we have which has the note id and the

00:21:56,159 --> 00:22:00,480
text

00:21:57,120 --> 00:22:03,200
and then our solar index has the note id

00:22:00,480 --> 00:22:04,960
and our bunch of quiz along with their

00:22:03,200 --> 00:22:06,559
polarity history whatever you want

00:22:04,960 --> 00:22:10,159
whatever attributes you want to put

00:22:06,559 --> 00:22:12,320
in there for each for each uh queen

00:22:10,159 --> 00:22:13,919
at the friend somebody types in the

00:22:12,320 --> 00:22:16,400
search at the lookup

00:22:13,919 --> 00:22:18,480
uh let's say you want to use a loin code

00:22:16,400 --> 00:22:21,760
for a certain medication and want to

00:22:18,480 --> 00:22:23,039
pull up pull up all the uh text or

00:22:21,760 --> 00:22:25,840
all the documents which have that

00:22:23,039 --> 00:22:27,840
knowing code it actually first searches

00:22:25,840 --> 00:22:30,400
in this one in the solar index

00:22:27,840 --> 00:22:32,559
which has your uh the mapping with the

00:22:30,400 --> 00:22:33,600
node id and then it goes to the main

00:22:32,559 --> 00:22:36,240
hbase table

00:22:33,600 --> 00:22:38,480
and fetches it and this places in the

00:22:36,240 --> 00:22:42,320
dashboard

00:22:38,480 --> 00:22:44,720
i hope that answers the questions uh

00:22:42,320 --> 00:22:46,880
okay i see a question do you use c takes

00:22:44,720 --> 00:22:48,640
location of classifier to determine the

00:22:46,880 --> 00:22:50,559
location of the nodule

00:22:48,640 --> 00:22:51,840
that's a good question we actually tried

00:22:50,559 --> 00:22:55,360
using that

00:22:51,840 --> 00:22:58,400
so i think somewhere maybe two years ago

00:22:55,360 --> 00:22:59,600
uh some of them we saw that some of the

00:22:58,400 --> 00:23:02,880
modules

00:22:59,600 --> 00:23:04,880
switched from uh rule based to

00:23:02,880 --> 00:23:06,159
i think svm based some of them were svm

00:23:04,880 --> 00:23:08,799
based and

00:23:06,159 --> 00:23:09,520
our internally when we validated we saw

00:23:08,799 --> 00:23:12,320
that the

00:23:09,520 --> 00:23:14,640
machine learning models were performing

00:23:12,320 --> 00:23:18,320
lower than the rule-based models

00:23:14,640 --> 00:23:20,640
and one of our projects was to

00:23:18,320 --> 00:23:22,000
kind of retrain our models with our

00:23:20,640 --> 00:23:24,559
internal data

00:23:22,000 --> 00:23:26,000
but we faced a roadblock in terms of

00:23:24,559 --> 00:23:27,760
getting training data

00:23:26,000 --> 00:23:30,080
because there is a certain way if you

00:23:27,760 --> 00:23:32,000
are aware of how the data should be

00:23:30,080 --> 00:23:34,080
and we couldn't find a good training

00:23:32,000 --> 00:23:36,799
source so i think

00:23:34,080 --> 00:23:37,360
uh so yes we tried using the location

00:23:36,799 --> 00:23:40,240
off

00:23:37,360 --> 00:23:41,679
and we actually found and for not for

00:23:40,240 --> 00:23:42,799
the long audio project but for a

00:23:41,679 --> 00:23:45,679
different project

00:23:42,799 --> 00:23:47,120
uh we had to report uh certain body

00:23:45,679 --> 00:23:49,120
parts and appendages

00:23:47,120 --> 00:23:50,799
we found some code not in the c takes

00:23:49,120 --> 00:23:51,679
main branch but in one of the developer

00:23:50,799 --> 00:23:55,279
branch

00:23:51,679 --> 00:23:56,640
where some of those kind of was actually

00:23:55,279 --> 00:24:01,200
implemented

00:23:56,640 --> 00:24:02,720
so um yeah so i think there is a version

00:24:01,200 --> 00:24:05,279
somewhere in the

00:24:02,720 --> 00:24:06,640
one of the draft branches i can look in

00:24:05,279 --> 00:24:08,880
my email and find that

00:24:06,640 --> 00:24:10,080
i worked on it maybe a year or even more

00:24:08,880 --> 00:24:11,600
than a year ago

00:24:10,080 --> 00:24:19,840
which actually where location of

00:24:11,600 --> 00:24:19,840
actually works pretty reasonably

00:24:21,120 --> 00:24:33,840
so are there any other questions

00:24:43,600 --> 00:24:48,480
uh yes so we are using the off-the-shelf

00:24:46,960 --> 00:24:51,840
sentiment classifier

00:24:48,480 --> 00:24:55,039
which comes with the ctex uh

00:24:51,840 --> 00:24:56,880
we had some we actually tried out we had

00:24:55,039 --> 00:24:58,159
some we tried to come up with our own

00:24:56,880 --> 00:25:01,279
negation allocator

00:24:58,159 --> 00:25:04,720
and that's where this whole training uh

00:25:01,279 --> 00:25:07,279
the model on our own data set came in uh

00:25:04,720 --> 00:25:08,240
the negation classifier works pretty

00:25:07,279 --> 00:25:12,840
well

00:25:08,240 --> 00:25:15,679
uh that's been my experience so far for

00:25:12,840 --> 00:25:18,720
tesla

00:25:15,679 --> 00:25:22,000
but it has sometimes it has several

00:25:18,720 --> 00:25:25,120
differences and even more than that uh

00:25:22,000 --> 00:25:26,799
especially in healthcare and in

00:25:25,120 --> 00:25:29,120
and if you look at the data in

00:25:26,799 --> 00:25:30,480
healthcare some of the sentences are not

00:25:29,120 --> 00:25:33,760
grammatically correct

00:25:30,480 --> 00:25:37,120
so what happens is the parse tree

00:25:33,760 --> 00:25:38,960
that gets generated is a little bit

00:25:37,120 --> 00:25:40,159
wacky which throws the negation

00:25:38,960 --> 00:25:42,559
classifier off

00:25:40,159 --> 00:25:44,159
so that's what we have seen because

00:25:42,559 --> 00:25:46,559
especially for 80 nodes

00:25:44,159 --> 00:25:47,760
i mean uh if there's a if there's a

00:25:46,559 --> 00:25:50,880
transcriber with the

00:25:47,760 --> 00:25:51,200
physician it's okay but if somebody is

00:25:50,880 --> 00:25:54,480
not

00:25:51,200 --> 00:25:57,679
if somebody is like typing indications

00:25:54,480 --> 00:26:01,440
in many cases grammar periods are missed

00:25:57,679 --> 00:26:03,039
which again uh has an impact on how the

00:26:01,440 --> 00:26:04,400
parse tree is generated which again

00:26:03,039 --> 00:26:08,480
throws off

00:26:04,400 --> 00:26:10,320
everything downstream uh for this one we

00:26:08,480 --> 00:26:13,279
used the machine learning

00:26:10,320 --> 00:26:13,279
negation classifier

00:26:15,440 --> 00:26:18,720
and another thing which i want to

00:26:17,440 --> 00:26:22,400
mention is so

00:26:18,720 --> 00:26:25,600
we run this using apache spark

00:26:22,400 --> 00:26:27,360
so what what so how do we do the lookup

00:26:25,600 --> 00:26:29,360
that's that was one of our main

00:26:27,360 --> 00:26:32,799
challenges so how do how

00:26:29,360 --> 00:26:39,760
we do our lookup is um we actually

00:26:32,799 --> 00:26:42,960
have if you if i go back here

00:26:39,760 --> 00:26:46,320
one second okay

00:26:42,960 --> 00:26:49,360
so we actually have uh containers

00:26:46,320 --> 00:26:50,240
we are on 200 containers and each one of

00:26:49,360 --> 00:26:53,440
them

00:26:50,240 --> 00:26:54,159
loads the whole uml stationary as a hash

00:26:53,440 --> 00:26:58,080
map

00:26:54,159 --> 00:27:01,760
so we so our uh when we run our setup

00:26:58,080 --> 00:27:05,520
or spark job we actually pass a copy

00:27:01,760 --> 00:27:06,000
of the ctek's mappings and the downside

00:27:05,520 --> 00:27:07,919
to that

00:27:06,000 --> 00:27:10,080
is and we tried a bunch of approaches

00:27:07,919 --> 00:27:13,360
one of the approaches that we tried

00:27:10,080 --> 00:27:16,159
was whether we could have like a

00:27:13,360 --> 00:27:17,760
sql light or a sql like database and

00:27:16,159 --> 00:27:20,000
have the containers connect

00:27:17,760 --> 00:27:21,840
to it the problem was if you're running

00:27:20,000 --> 00:27:24,480
with 100 200 containers

00:27:21,840 --> 00:27:25,760
you have to implement your own uh

00:27:24,480 --> 00:27:27,600
demultiplexer

00:27:25,760 --> 00:27:28,960
to handle all the connections otherwise

00:27:27,600 --> 00:27:32,159
it's going to saturate

00:27:28,960 --> 00:27:35,039
your sql server so

00:27:32,159 --> 00:27:36,640
and also it increases your intra cluster

00:27:35,039 --> 00:27:39,039
uh

00:27:36,640 --> 00:27:40,320
bandwidth requirement bottle which is a

00:27:39,039 --> 00:27:41,120
big bottleneck especially if you're

00:27:40,320 --> 00:27:43,760
running

00:27:41,120 --> 00:27:45,200
on a hadoop cluster and which actually

00:27:43,760 --> 00:27:48,320
made our throughput slow

00:27:45,200 --> 00:27:52,159
so how we solved it is we actually

00:27:48,320 --> 00:27:54,000
pass as a zip file the umls dictionary

00:27:52,159 --> 00:27:56,799
so we have to be very careful

00:27:54,000 --> 00:27:58,880
on how we choose our concepts and that's

00:27:56,799 --> 00:28:00,640
why we have this stage when we curate

00:27:58,880 --> 00:28:04,080
quiz right

00:28:00,640 --> 00:28:06,559
and then each container have their own

00:28:04,080 --> 00:28:07,919
copy of the of the dictionary so the

00:28:06,559 --> 00:28:10,080
lookup is very fast

00:28:07,919 --> 00:28:11,840
but the trade-off is each container

00:28:10,080 --> 00:28:17,840
needs at least five gigs of

00:28:11,840 --> 00:28:17,840
memory to run otherwise it's gonna fail

00:28:17,919 --> 00:28:33,840
let me go back to the chat

00:28:30,640 --> 00:28:37,279
it looks banana includes strong

00:28:33,840 --> 00:28:40,480
support for temporal analysis

00:28:37,279 --> 00:28:42,559
yeah we did not use that off the shelf

00:28:40,480 --> 00:28:44,320
for banana

00:28:42,559 --> 00:28:45,840
does that mean your dashboards have both

00:28:44,320 --> 00:28:49,039
longitudinal and by

00:28:45,840 --> 00:28:51,200
node views uh so it

00:28:49,039 --> 00:28:52,399
it definitely had by node views in the

00:28:51,200 --> 00:28:55,679
sense that

00:28:52,399 --> 00:28:58,000
uh you could probably pull up the nodes

00:28:55,679 --> 00:28:59,440
whether we had a longitudinal view of

00:28:58,000 --> 00:29:03,039
the of the

00:28:59,440 --> 00:29:03,840
patient uh i don't think we did because

00:29:03,039 --> 00:29:06,880
we did not

00:29:03,840 --> 00:29:09,279
expose all the node types in our in our

00:29:06,880 --> 00:29:12,240
dashboard

00:29:09,279 --> 00:29:13,279
uh so what i guess i mean there are many

00:29:12,240 --> 00:29:14,880
pitfalls

00:29:13,279 --> 00:29:16,320
uh i don't know if you're talking about

00:29:14,880 --> 00:29:19,520
banana or

00:29:16,320 --> 00:29:23,200
apache ctex uh so recently

00:29:19,520 --> 00:29:25,200
actually we were looking at elastic

00:29:23,200 --> 00:29:26,960
uh because it has similar architecture

00:29:25,200 --> 00:29:30,559
but i personally i think

00:29:26,960 --> 00:29:32,880
uh solar works better for me and

00:29:30,559 --> 00:29:34,240
if you ask and honestly this is again my

00:29:32,880 --> 00:29:37,039
opinion people

00:29:34,240 --> 00:29:37,679
please feel free to disagree uh i think

00:29:37,039 --> 00:29:39,919
kibana

00:29:37,679 --> 00:29:43,520
kiba is a better product than manana but

00:29:39,919 --> 00:29:48,480
solar is a better product than elastic

00:29:43,520 --> 00:29:48,480
so that's kind of my takeaway from this

00:29:52,840 --> 00:29:55,840
project

00:29:59,919 --> 00:30:04,640
all right so let me just do a quick scan

00:30:02,799 --> 00:30:09,840
to see i did not miss

00:30:04,640 --> 00:30:09,840
any questions

00:30:20,240 --> 00:30:24,559
all right then okay then we have one

00:30:23,440 --> 00:30:26,720
question

00:30:24,559 --> 00:30:28,720
did you die identify data for your

00:30:26,720 --> 00:30:30,080
league project no it's all phi this is

00:30:28,720 --> 00:30:33,520
all operational work

00:30:30,080 --> 00:30:35,520
uh it's all translational work so

00:30:33,520 --> 00:30:37,039
this call comes under quality

00:30:35,520 --> 00:30:39,120
improvement and

00:30:37,039 --> 00:30:40,640
that's one of the good things with the

00:30:39,120 --> 00:30:42,159
team that i work in i don't have to

00:30:40,640 --> 00:30:44,240
worry about

00:30:42,159 --> 00:30:45,600
de-identified data and i know what you

00:30:44,240 --> 00:30:47,760
are alluding to

00:30:45,600 --> 00:30:49,679
one of the hardest problem right now

00:30:47,760 --> 00:30:52,320
especially

00:30:49,679 --> 00:30:53,840
in nlp and especially if you are not

00:30:52,320 --> 00:30:56,399
associated with the healthcare

00:30:53,840 --> 00:30:58,880
organization is getting good data

00:30:56,399 --> 00:31:00,240
that's yeah i see where you're coming

00:30:58,880 --> 00:31:02,840
from but luckily now

00:31:00,240 --> 00:31:04,480
since uh i work directly for the health

00:31:02,840 --> 00:31:07,840
system

00:31:04,480 --> 00:31:09,200
i have i have access to all phi and

00:31:07,840 --> 00:31:11,600
patient information which again is

00:31:09,200 --> 00:31:13,440
required for doing the interventions

00:31:11,600 --> 00:31:15,200
like reaching out to them scheduling

00:31:13,440 --> 00:31:18,000
them bringing them back in

00:31:15,200 --> 00:31:21,440
and for the stroke project for triaging

00:31:18,000 --> 00:31:21,440
them from so on and so forth

00:31:24,480 --> 00:31:27,600
will we have access to the recorded

00:31:25,840 --> 00:31:30,399
session i think so

00:31:27,600 --> 00:31:30,399
i think we should

00:31:30,960 --> 00:31:37,760
yes we are and actually we are

00:31:34,240 --> 00:31:41,279
also interested in uh

00:31:37,760 --> 00:31:43,519
i'd so on in merging or at least

00:31:41,279 --> 00:31:46,480
putting out there our code that we have

00:31:43,519 --> 00:31:48,720
developed using apache spark because

00:31:46,480 --> 00:31:49,840
right now the cost to setting up a spark

00:31:48,720 --> 00:31:53,039
cluster is

00:31:49,840 --> 00:31:56,640
next to nothing especially on the hr

00:31:53,039 --> 00:31:59,760
so we are looking at probably

00:31:56,640 --> 00:32:01,360
a publication and then merging it in the

00:31:59,760 --> 00:32:03,440
ctex community

00:32:01,360 --> 00:32:04,640
because we modified heavily some of the

00:32:03,440 --> 00:32:07,840
classes like the lookup

00:32:04,640 --> 00:32:09,200
we modified uh heavily we modified to

00:32:07,840 --> 00:32:12,159
modify a bunch of

00:32:09,200 --> 00:32:13,360
uh the annotator of course the xml files

00:32:12,159 --> 00:32:16,720
so yes that's

00:32:13,360 --> 00:32:16,720
something that we're definitely looking

00:32:26,840 --> 00:32:31,679
into

00:32:29,200 --> 00:32:31,679
thank you

00:32:32,320 --> 00:32:38,240
and thank you dr salova and sean

00:32:36,159 --> 00:32:39,440
thank you that was very interesting and

00:32:38,240 --> 00:32:43,279
yes i i would

00:32:39,440 --> 00:32:45,840
love to see some of that code and uh

00:32:43,279 --> 00:32:47,679
get ctakes running on spark all over the

00:32:45,840 --> 00:32:50,000
place

00:32:47,679 --> 00:32:53,279
yeah yeah i think it's a natural

00:32:50,000 --> 00:32:56,399
evolution that's how i think about it

00:32:53,279 --> 00:32:58,720
i would also be interested uh if

00:32:56,399 --> 00:32:59,440
if we could have a catch up in a year or

00:32:58,720 --> 00:33:02,720
so after

00:32:59,440 --> 00:33:04,880
you've got the uh the stroke

00:33:02,720 --> 00:33:08,080
running in the uh ed that would be

00:33:04,880 --> 00:33:10,559
really neat to see how that turns out

00:33:08,080 --> 00:33:11,279
sure i mean if you guys are interested

00:33:10,559 --> 00:33:14,080
we can

00:33:11,279 --> 00:33:15,679
uh take this offline i think one of our

00:33:14,080 --> 00:33:16,480
developers who was there a couple of

00:33:15,679 --> 00:33:19,760
years ago

00:33:16,480 --> 00:33:21,600
uh brandon uh probably knew somebody

00:33:19,760 --> 00:33:25,840
from your group

00:33:21,600 --> 00:33:25,840
yes i knew brandon yes

00:33:28,000 --> 00:33:31,600
so we can probably if you want we can

00:33:30,880 --> 00:33:34,080
probably

00:33:31,600 --> 00:33:35,360
uh catch up online and you know we'd

00:33:34,080 --> 00:33:37,200
love to

00:33:35,360 --> 00:33:39,120
uh kind of see if there are any

00:33:37,200 --> 00:33:40,080
opportunities and as i said the seat the

00:33:39,120 --> 00:33:41,919
spark code

00:33:40,080 --> 00:33:43,760
we definitely want to open source or at

00:33:41,919 --> 00:33:46,640
least put it out there so that other

00:33:43,760 --> 00:33:49,440
health institutions or even uh other use

00:33:46,640 --> 00:33:52,080
cases can use that

00:33:49,440 --> 00:33:54,080
uh the dev team that has varied from

00:33:52,080 --> 00:33:57,200
time to time

00:33:54,080 --> 00:33:59,039
i when i joined it was just me then we

00:33:57,200 --> 00:34:01,919
got another ft

00:33:59,039 --> 00:34:02,880
uh so it was me and satish for a long

00:34:01,919 --> 00:34:05,600
time

00:34:02,880 --> 00:34:08,320
uh in the last couple of years we had

00:34:05,600 --> 00:34:12,159
our team due to around five or six

00:34:08,320 --> 00:34:12,159
uh some of them were

00:34:12,560 --> 00:34:18,000
right now again it's just satish and me

00:34:15,760 --> 00:34:21,839
just because of how the situation is

00:34:18,000 --> 00:34:21,839
right now

00:34:29,679 --> 00:34:36,000
all right if there are no more questions

00:34:32,839 --> 00:34:37,040
i will log off and i'll probably bump

00:34:36,000 --> 00:34:39,599
into you guys

00:34:37,040 --> 00:34:41,119
in the next session all right thank you

00:34:39,599 --> 00:34:42,480
very much

00:34:41,119 --> 00:34:44,480
thank you thanks i'll see you in a

00:34:42,480 --> 00:34:49,839
minute

00:34:44,480 --> 00:34:49,839
see ya

00:35:04,560 --> 00:35:06,640

YouTube URL: https://www.youtube.com/watch?v=44x8H8l_3P8


