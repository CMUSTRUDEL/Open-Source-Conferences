Title: Getting started with Cassandra the right way
Publication date: 2020-10-21
Playlist: ApacheCon @Home 2020: Cassandra
Description: 
	Getting started with Cassandra the right way
Erick Ramirez

A presentation from ApacheCon @Home 2020
https://apachecon.com/acah2020/

Cassandra users run into problems particularly when they're new to the technology. In this session, I'll talk about: - the common pitfalls so you don't fall into the trap; - top things users ask for help; - how to quickly diagnose issues; - where to get help.

I'm an Apache Cassandra enthusiast at DataStax. I've been educating and helping other users become successful with Cassandra for 7 years. I answer questions on various channels including ASF Slack and the users mailing list.
Captions: 
	00:00:06,420 --> 00:00:10,640
[Music]

00:00:14,160 --> 00:00:17,230
[Music]

00:00:24,480 --> 00:00:28,480
so

00:00:24,960 --> 00:00:28,480
before we get started uh

00:00:28,640 --> 00:00:33,200
we're gonna these are the things that

00:00:32,559 --> 00:00:36,719
i'm gonna be

00:00:33,200 --> 00:00:40,559
uh covering today so um

00:00:36,719 --> 00:00:42,800
this this really is a session about uh

00:00:40,559 --> 00:00:44,079
you know being able to get started with

00:00:42,800 --> 00:00:46,719
cassandra the right way

00:00:44,079 --> 00:00:48,160
so um a couple of months ago uh nate

00:00:46,719 --> 00:00:50,480
asked me to

00:00:48,160 --> 00:00:52,160
to do a talk here at the patchy con um

00:00:50,480 --> 00:00:54,800
and essentially it's

00:00:52,160 --> 00:00:55,680
i'm trying to target the the top

00:00:54,800 --> 00:00:58,719
questions that

00:00:55,680 --> 00:01:01,280
a lot of uh users ask

00:00:58,719 --> 00:01:04,000
in the in the various um channels

00:01:01,280 --> 00:01:06,879
whether it's on asf slack or

00:01:04,000 --> 00:01:06,879
on the mailing list

00:01:07,360 --> 00:01:10,479
and i wanted to go through some of the

00:01:09,439 --> 00:01:12,560
stuff that

00:01:10,479 --> 00:01:14,960
you know things that you wish you knew

00:01:12,560 --> 00:01:18,080
when you first started with cassandra so

00:01:14,960 --> 00:01:19,759
um i'm looking at the people who have

00:01:18,080 --> 00:01:21,759
joined the session and

00:01:19,759 --> 00:01:23,520
um a lot of you are quite experienced so

00:01:21,759 --> 00:01:25,600
that this session is probably not for

00:01:23,520 --> 00:01:27,680
you it was really intended for those who

00:01:25,600 --> 00:01:30,320
are new to cassandra probably

00:01:27,680 --> 00:01:30,960
you know people who are users who have

00:01:30,320 --> 00:01:32,560
uh

00:01:30,960 --> 00:01:34,880
two years or less experience with

00:01:32,560 --> 00:01:37,040
cassandra um

00:01:34,880 --> 00:01:38,320
but anyway here we go so i'm gonna start

00:01:37,040 --> 00:01:41,119
up and um

00:01:38,320 --> 00:01:42,960
just give you give the new users an idea

00:01:41,119 --> 00:01:46,560
of how you can quickly

00:01:42,960 --> 00:01:46,960
um fire up a uh cassandra cluster and

00:01:46,560 --> 00:01:50,000
the

00:01:46,960 --> 00:01:51,920
the you know the top three things that

00:01:50,000 --> 00:01:54,399
you need to configure just to

00:01:51,920 --> 00:01:55,119
get started really quickly i'll talk

00:01:54,399 --> 00:01:57,680
about

00:01:55,119 --> 00:01:58,240
things like how to plan your deployment

00:01:57,680 --> 00:02:00,159
and

00:01:58,240 --> 00:02:01,920
some of the recommended settings i'm not

00:02:00,159 --> 00:02:04,159
going to cover everything so again this

00:02:01,920 --> 00:02:07,200
was intended for

00:02:04,159 --> 00:02:10,000
new users and

00:02:07,200 --> 00:02:10,399
a lot of the things that i get asked a

00:02:10,000 --> 00:02:12,400
lot

00:02:10,399 --> 00:02:14,160
is you know what kind of tools are

00:02:12,400 --> 00:02:16,319
available out there to use with

00:02:14,160 --> 00:02:19,440
cassandra so i'll talk about that

00:02:16,319 --> 00:02:21,599
um a little bit too um and i'll cover

00:02:19,440 --> 00:02:24,800
some of the troubleshooting

00:02:21,599 --> 00:02:26,800
um and then finally um i'll i'll go

00:02:24,800 --> 00:02:27,360
through some of the resources that's

00:02:26,800 --> 00:02:30,640
available

00:02:27,360 --> 00:02:33,360
out there so for new users who are

00:02:30,640 --> 00:02:34,400
you know that they are starting up in

00:02:33,360 --> 00:02:37,200
cassandra

00:02:34,400 --> 00:02:38,560
i'm gonna give you some uh brief

00:02:37,200 --> 00:02:41,680
resources where you can

00:02:38,560 --> 00:02:44,400
get uh learn stuff for free um

00:02:41,680 --> 00:02:45,840
some resources for um when your first

00:02:44,400 --> 00:02:48,640
first time building

00:02:45,840 --> 00:02:50,080
applications on cassandra and you know

00:02:48,640 --> 00:02:53,360
where to go to

00:02:50,080 --> 00:02:57,120
next and maybe ask questions

00:02:53,360 --> 00:02:59,200
um so to get us all so

00:02:57,120 --> 00:03:01,120
just a little bit about me i'm a

00:02:59,200 --> 00:03:04,640
developer advocate for data stacks

00:03:01,120 --> 00:03:07,920
i've been a cassandra enthusiast for

00:03:04,640 --> 00:03:07,920
just over seven years

00:03:08,400 --> 00:03:13,200
and as you would have worked out by now

00:03:11,040 --> 00:03:15,840
i'm based in australia so i

00:03:13,200 --> 00:03:17,200
co-host uh the melbourne and sydney

00:03:15,840 --> 00:03:20,560
meetup groups

00:03:17,200 --> 00:03:21,440
um kind of got started a few years ago

00:03:20,560 --> 00:03:23,920
with that

00:03:21,440 --> 00:03:24,959
and and really why i'm here is because i

00:03:23,920 --> 00:03:27,040
help a lot of

00:03:24,959 --> 00:03:28,879
users in various channels i've mentioned

00:03:27,040 --> 00:03:32,640
already the ass slack

00:03:28,879 --> 00:03:35,440
there's also the cassandra mailing list

00:03:32,640 --> 00:03:37,519
stack overflow when i've got a bit of

00:03:35,440 --> 00:03:40,080
spare time

00:03:37,519 --> 00:03:42,879
having said that i do most of this stuff

00:03:40,080 --> 00:03:45,760
in my spare time on weekends

00:03:42,879 --> 00:03:47,440
night time a lot of times um early in

00:03:45,760 --> 00:03:50,080
the morning being on the other side of

00:03:47,440 --> 00:03:50,080
the planet

00:03:51,040 --> 00:03:57,519
thanks cedric not all of them um

00:03:54,080 --> 00:04:00,400
and we also have uh the the

00:03:57,519 --> 00:04:01,599
youtube channel data stacks divs where

00:04:00,400 --> 00:04:03,840
um i

00:04:01,599 --> 00:04:05,280
you know um there's a bunch of us at

00:04:03,840 --> 00:04:07,760
data stacks that run

00:04:05,280 --> 00:04:09,519
workshops on a weekly basis we have two

00:04:07,760 --> 00:04:10,319
or three workshops on the go all the

00:04:09,519 --> 00:04:13,439
time

00:04:10,319 --> 00:04:14,080
and finally the community.datastax.com

00:04:13,439 --> 00:04:16,320
site so

00:04:14,080 --> 00:04:18,000
that's those are the places where you'll

00:04:16,320 --> 00:04:21,359
find me um

00:04:18,000 --> 00:04:23,600
pretty much most of the time um

00:04:21,359 --> 00:04:24,479
this is stuff that i do in my spare time

00:04:23,600 --> 00:04:26,960
in

00:04:24,479 --> 00:04:29,440
weekends um pretty much all my waking

00:04:26,960 --> 00:04:33,040
hours

00:04:29,440 --> 00:04:34,720
and so after all that um we're gonna get

00:04:33,040 --> 00:04:37,680
started so

00:04:34,720 --> 00:04:38,240
here's stuff about your first uh hello

00:04:37,680 --> 00:04:41,440
world

00:04:38,240 --> 00:04:44,240
deployment for cassandra so

00:04:41,440 --> 00:04:47,120
how do you do installation um you grab

00:04:44,240 --> 00:04:47,680
your stuff off the cassandra.apache.org

00:04:47,120 --> 00:04:51,040
site

00:04:47,680 --> 00:04:53,520
uh so i wanted to talk about the

00:04:51,040 --> 00:04:54,800
different releases as well um in in this

00:04:53,520 --> 00:04:56,880
section because

00:04:54,800 --> 00:04:57,919
again there's a lot of confusion so the

00:04:56,880 --> 00:05:01,759
latest uh

00:04:57,919 --> 00:05:03,199
release is 3.11.8 so that's what the

00:05:01,759 --> 00:05:05,600
that's the stuff that you would deploy

00:05:03,199 --> 00:05:09,039
to production if you're new to cassandra

00:05:05,600 --> 00:05:11,919
um there's a beta release right now for

00:05:09,039 --> 00:05:15,759
cassandra 4.0 so that's the newest

00:05:11,919 --> 00:05:18,720
upcoming version that

00:05:15,759 --> 00:05:20,000
the community has you wouldn't really

00:05:18,720 --> 00:05:23,199
install

00:05:20,000 --> 00:05:26,400
beta2 for your production yet

00:05:23,199 --> 00:05:27,160
because it's not ga so you'd really look

00:05:26,400 --> 00:05:30,000
at

00:05:27,160 --> 00:05:33,039
3.11.8 there's

00:05:30,000 --> 00:05:33,520
installation documents that uh worked on

00:05:33,039 --> 00:05:38,880
to

00:05:33,520 --> 00:05:41,680
update at the apache site um

00:05:38,880 --> 00:05:42,639
so that's pretty much if you follow

00:05:41,680 --> 00:05:46,080
those steps that

00:05:42,639 --> 00:05:47,919
i've put in that document step by step

00:05:46,080 --> 00:05:49,199
uh you're pretty much guaranteed to get

00:05:47,919 --> 00:05:52,240
cassandra up and

00:05:49,199 --> 00:05:55,360
running um and so

00:05:52,240 --> 00:05:56,240
you can do tarball installations uh you

00:05:55,360 --> 00:06:00,319
can do

00:05:56,240 --> 00:06:01,840
rpm or uh you can do there's a dev

00:06:00,319 --> 00:06:04,720
package as well for

00:06:01,840 --> 00:06:06,639
cassandra um but if you're new i would i

00:06:04,720 --> 00:06:08,479
would suggest that doing the tarble

00:06:06,639 --> 00:06:11,120
installation because there's

00:06:08,479 --> 00:06:15,120
less things that can go wrong it's it's

00:06:11,120 --> 00:06:15,120
uh it makes it very simple for you to

00:06:16,479 --> 00:06:21,600
so what about um after you've installed

00:06:19,600 --> 00:06:25,199
cassandra what happens next

00:06:21,600 --> 00:06:26,600
um it's fairly easy there's only one

00:06:25,199 --> 00:06:28,560
file to configure that's the

00:06:26,600 --> 00:06:31,759
cassandra.yaml file

00:06:28,560 --> 00:06:33,280
um and so in this slide i wanted to talk

00:06:31,759 --> 00:06:34,479
about so there's three things really

00:06:33,280 --> 00:06:37,919
that you need to

00:06:34,479 --> 00:06:40,080
um for a cassandra cluster to form

00:06:37,919 --> 00:06:41,680
um all the nodes need to have the same

00:06:40,080 --> 00:06:44,479
uh cluster name

00:06:41,680 --> 00:06:44,960
they need to have um the same seeds at

00:06:44,479 --> 00:06:46,960
least

00:06:44,960 --> 00:06:48,560
so since these are just the ipa

00:06:46,960 --> 00:06:49,840
addresses for

00:06:48,560 --> 00:06:51,759
the nodes that you'll have in the

00:06:49,840 --> 00:06:53,919
cluster

00:06:51,759 --> 00:06:55,199
if you don't configure any of this

00:06:53,919 --> 00:06:59,120
you'll be able to start

00:06:55,199 --> 00:07:01,039
a single node um just just one node

00:06:59,120 --> 00:07:02,960
but the unfortunate thing is it won't be

00:07:01,039 --> 00:07:04,720
able to you won't be able to start any

00:07:02,960 --> 00:07:06,880
other node so you're not really

00:07:04,720 --> 00:07:08,639
operating a cluster it will just be a

00:07:06,880 --> 00:07:11,440
single node deployment

00:07:08,639 --> 00:07:13,599
um so the two things that you need to do

00:07:11,440 --> 00:07:15,400
is configure the listen address

00:07:13,599 --> 00:07:16,960
and the rpc address in the

00:07:15,400 --> 00:07:20,000
cassandra.yaml

00:07:16,960 --> 00:07:21,520
um and so typically what you'll have is

00:07:20,000 --> 00:07:23,840
that in the listen address you'll have

00:07:21,520 --> 00:07:25,520
the private ip address because this is

00:07:23,840 --> 00:07:26,960
how the nodes communicate with each

00:07:25,520 --> 00:07:28,080
other this is how they'll be able to

00:07:26,960 --> 00:07:30,880
gossip

00:07:28,080 --> 00:07:32,560
if you've worked with clusters before so

00:07:30,880 --> 00:07:34,479
this is the internet

00:07:32,560 --> 00:07:35,759
communication so this is a private

00:07:34,479 --> 00:07:38,080
network that the nodes

00:07:35,759 --> 00:07:39,520
uh communicate within each other that's

00:07:38,080 --> 00:07:40,639
what you would configure in the listen

00:07:39,520 --> 00:07:43,680
address

00:07:40,639 --> 00:07:46,639
the rpc address is the ip address that

00:07:43,680 --> 00:07:49,120
is typically a public ip if you've got a

00:07:46,639 --> 00:07:49,759
multi-home uh server so you've got

00:07:49,120 --> 00:07:52,720
multiple

00:07:49,759 --> 00:07:54,800
links and the rpc address is what the

00:07:52,720 --> 00:07:55,360
client or your application will connect

00:07:54,800 --> 00:07:57,120
to

00:07:55,360 --> 00:08:00,080
which is why that's typically a public

00:07:57,120 --> 00:08:03,360
id now if you're just testing it out say

00:08:00,080 --> 00:08:06,720
on on your laptop or

00:08:03,360 --> 00:08:09,360
on the server that also

00:08:06,720 --> 00:08:11,280
you know on a private network then you

00:08:09,360 --> 00:08:15,520
typically have the rpc address and the

00:08:11,280 --> 00:08:17,919
listen address both sharing the same ip

00:08:15,520 --> 00:08:19,120
the problem is when you don't configure

00:08:17,919 --> 00:08:21,840
the rp address

00:08:19,120 --> 00:08:22,879
correctly you won't be able to access

00:08:21,840 --> 00:08:25,759
the node from

00:08:22,879 --> 00:08:27,840
outside the cluster so that's something

00:08:25,759 --> 00:08:31,680
that's um quite important to

00:08:27,840 --> 00:08:35,680
to note as well um i've made a

00:08:31,680 --> 00:08:38,719
uh highlight there that in 4.0

00:08:35,680 --> 00:08:39,839
you need to include the cql port when

00:08:38,719 --> 00:08:42,959
you specify the

00:08:39,839 --> 00:08:44,240
seeds list so it will look like an ip

00:08:42,959 --> 00:08:47,279
and then column nine

00:08:44,240 --> 00:08:49,040
zero four two for every single uh

00:08:47,279 --> 00:08:53,279
node that you can figure so that's

00:08:49,040 --> 00:08:54,399
coming up in 4.0 not in 3.11.8 or 3.0

00:08:53,279 --> 00:08:56,640
yet

00:08:54,399 --> 00:08:57,760
uh oh sorry it won't get um that's not

00:08:56,640 --> 00:09:00,959
how you do it in

00:08:57,760 --> 00:09:05,600
in the the current releases but it

00:09:00,959 --> 00:09:08,399
changes in 4.0 so just be aware of that

00:09:05,600 --> 00:09:10,640
and on that note it's um if you're

00:09:08,399 --> 00:09:13,680
learning as well it's very good to

00:09:10,640 --> 00:09:16,880
if you can help us out and test out uh

00:09:13,680 --> 00:09:19,040
4.0 um play around with it and then

00:09:16,880 --> 00:09:22,399
report any problems um

00:09:19,040 --> 00:09:24,080
that you run into just so um we can get

00:09:22,399 --> 00:09:27,120
a 4.0 release

00:09:24,080 --> 00:09:27,120
g8 pretty soon

00:09:29,200 --> 00:09:31,519
now

00:09:33,200 --> 00:09:38,880
we're going to move on to the section

00:09:35,120 --> 00:09:38,880
about um planning your deployment

00:09:40,480 --> 00:09:47,680
so common question uh how what kind of

00:09:44,160 --> 00:09:51,200
hardware do we deploy cassandra on so

00:09:47,680 --> 00:09:54,080
specifically talking about production um

00:09:51,200 --> 00:09:55,600
i like eight core machines with 32

00:09:54,080 --> 00:09:57,519
gigabytes of ram that's

00:09:55,600 --> 00:09:58,880
that's kind of really your minimum when

00:09:57,519 --> 00:10:01,839
it comes to

00:09:58,880 --> 00:10:02,720
production um but a lot of organizations

00:10:01,839 --> 00:10:05,839
i work with

00:10:02,720 --> 00:10:06,880
deploy nodes with 16 cores and 64 gigs

00:10:05,839 --> 00:10:09,279
of ram

00:10:06,880 --> 00:10:10,160
um but if you're just trying it out you

00:10:09,279 --> 00:10:12,800
know you can run

00:10:10,160 --> 00:10:13,519
a cassandra on a single core machine

00:10:12,800 --> 00:10:17,200
with

00:10:13,519 --> 00:10:20,079
um only you know even just eight gigs

00:10:17,200 --> 00:10:21,600
um you know if you if you really stretch

00:10:20,079 --> 00:10:24,480
you can run cassandra with

00:10:21,600 --> 00:10:26,079
um just uh four gigs of ram obviously

00:10:24,480 --> 00:10:27,839
there's not a lot that you can do with

00:10:26,079 --> 00:10:29,839
it you can't do like a lot of stress

00:10:27,839 --> 00:10:31,839
testing it will only really it's

00:10:29,839 --> 00:10:33,279
you know a single core four gig machine

00:10:31,839 --> 00:10:34,560
is really just something that you do

00:10:33,279 --> 00:10:36,880
where you're doing like

00:10:34,560 --> 00:10:37,680
functional testing and you know maybe

00:10:36,880 --> 00:10:40,800
one or two

00:10:37,680 --> 00:10:41,680
transactions per second type stuff um

00:10:40,800 --> 00:10:44,399
which means that

00:10:41,680 --> 00:10:44,720
you know if you've got a a macbook with

00:10:44,399 --> 00:10:47,760
a

00:10:44,720 --> 00:10:49,839
16 core with 16 cores on it you should

00:10:47,760 --> 00:10:51,120
be fine running like a three node

00:10:49,839 --> 00:10:53,920
cluster

00:10:51,120 --> 00:10:55,120
um but obviously there's not a lot that

00:10:53,920 --> 00:10:58,399
you can do with it but

00:10:55,120 --> 00:10:58,399
you can play around with it

00:10:58,959 --> 00:11:03,200
i highly recommend using ssds can't

00:11:01,600 --> 00:11:05,360
stress that enough um

00:11:03,200 --> 00:11:06,399
you know a lot of people um i was

00:11:05,360 --> 00:11:09,680
fielding a question

00:11:06,399 --> 00:11:13,360
uh just earlier today someone wanted to

00:11:09,680 --> 00:11:16,800
to you know tips on how to tune um

00:11:13,360 --> 00:11:18,240
they clustered to because they run into

00:11:16,800 --> 00:11:21,279
problems when

00:11:18,240 --> 00:11:23,600
uh the traffic um

00:11:21,279 --> 00:11:25,760
goes up a little bit but it turns out

00:11:23,600 --> 00:11:28,240
they're using um spinning disks and

00:11:25,760 --> 00:11:28,800
there's really not much you can you can

00:11:28,240 --> 00:11:32,079
do

00:11:28,800 --> 00:11:33,760
um when it comes to that so uh i highly

00:11:32,079 --> 00:11:36,240
recommend this is these

00:11:33,760 --> 00:11:37,040
um and a one terabyte maybe a two

00:11:36,240 --> 00:11:40,240
terabyte

00:11:37,040 --> 00:11:43,920
uh machine um is the sweet spot

00:11:40,240 --> 00:11:47,360
um and i'll get to why um i recommend

00:11:43,920 --> 00:11:50,399
uh one terabyte ssds or one terabyte

00:11:47,360 --> 00:11:51,440
uh disks um in in a couple of slides

00:11:50,399 --> 00:11:54,240
later

00:11:51,440 --> 00:11:57,600
um because it's mostly about how much

00:11:54,240 --> 00:11:59,600
data you have on the node

00:11:57,600 --> 00:12:00,639
in my experience the general my general

00:11:59,600 --> 00:12:04,079
recommendation

00:12:00,639 --> 00:12:08,079
is to have you know you target the node

00:12:04,079 --> 00:12:10,639
density of about 500 gigs per node

00:12:08,079 --> 00:12:11,839
and as you get closer to that one

00:12:10,639 --> 00:12:13,760
terabyte my

00:12:11,839 --> 00:12:15,120
mark in terms of the amount of data that

00:12:13,760 --> 00:12:17,360
you have on the node

00:12:15,120 --> 00:12:18,880
i would highly recommend that you start

00:12:17,360 --> 00:12:21,120
planning uh

00:12:18,880 --> 00:12:22,320
adding more nodes to your cluster

00:12:21,120 --> 00:12:24,399
because um

00:12:22,320 --> 00:12:27,120
you need to know that there's a there's

00:12:24,399 --> 00:12:30,000
a massive trade-off when it comes to

00:12:27,120 --> 00:12:30,480
dense nodes yes you can run nodes with

00:12:30,000 --> 00:12:34,079
three

00:12:30,480 --> 00:12:36,240
terabytes five terabytes maybe even more

00:12:34,079 --> 00:12:37,839
but it makes it really difficult when it

00:12:36,240 --> 00:12:40,160
comes to

00:12:37,839 --> 00:12:41,200
things like you know uh when you're

00:12:40,160 --> 00:12:43,200
running repairs

00:12:41,200 --> 00:12:44,560
uh repairs take a lot longer when you're

00:12:43,200 --> 00:12:47,680
trying to repair

00:12:44,560 --> 00:12:49,920
you know a one terabyte node compared to

00:12:47,680 --> 00:12:50,160
when you're just repairing 500 gigabytes

00:12:49,920 --> 00:12:53,519
of

00:12:50,160 --> 00:12:55,279
um data things like bootstrapping as

00:12:53,519 --> 00:12:56,240
well when you want to add nodes to your

00:12:55,279 --> 00:12:59,920
cluster

00:12:56,240 --> 00:13:01,760
again you know the the dense nodes um

00:12:59,920 --> 00:13:03,200
you run into more problems when you have

00:13:01,760 --> 00:13:05,600
a you know like when you're

00:13:03,200 --> 00:13:07,920
bootstrapping a one and a half terabyte

00:13:05,600 --> 00:13:08,959
node compared to bootstrapping 500 gigs

00:13:07,920 --> 00:13:11,839
of data

00:13:08,959 --> 00:13:12,240
um similarly when you're decommissioning

00:13:11,839 --> 00:13:14,480
nodes

00:13:12,240 --> 00:13:16,240
um that becomes a problem as well

00:13:14,480 --> 00:13:18,800
because you've got more stuff that

00:13:16,240 --> 00:13:21,920
you've got a

00:13:18,800 --> 00:13:22,320
stream out of the servers so understand

00:13:21,920 --> 00:13:25,360
that

00:13:22,320 --> 00:13:26,160
um when you're choosing um you know how

00:13:25,360 --> 00:13:29,839
you

00:13:26,160 --> 00:13:29,839
how you deploy your clusters

00:13:31,600 --> 00:13:35,519
here's another question that um comes up

00:13:34,399 --> 00:13:39,279
quite a fair bit

00:13:35,519 --> 00:13:42,639
so with your jvm configuration

00:13:39,279 --> 00:13:46,240
if you're in production um you know

00:13:42,639 --> 00:13:47,279
you really should have allocate 16 gigs

00:13:46,240 --> 00:13:50,480
to the heap

00:13:47,279 --> 00:13:50,480
the default uh

00:13:50,560 --> 00:13:57,760
gc for cassandra is cms

00:13:54,480 --> 00:13:58,320
um and you really want to use um cms

00:13:57,760 --> 00:14:00,079
when

00:13:58,320 --> 00:14:03,680
you know you've got that smaller heap

00:14:00,079 --> 00:14:06,720
size which is like 16 to 24

00:14:03,680 --> 00:14:10,480
gigabytes generally um

00:14:06,720 --> 00:14:14,240
once you get to you know 20 gigabytes

00:14:10,480 --> 00:14:17,680
i i highly recommend switching to

00:14:14,240 --> 00:14:21,600
g1 gc um for up to uh

00:14:17,680 --> 00:14:24,800
31 gigabytes um but that means that

00:14:21,600 --> 00:14:26,000
um once you're using a g1 gc you really

00:14:24,800 --> 00:14:28,240
need to

00:14:26,000 --> 00:14:30,000
go up from that original recommendation

00:14:28,240 --> 00:14:31,680
of you know having a machine that's only

00:14:30,000 --> 00:14:34,079
got 32 gigs of ram

00:14:31,680 --> 00:14:36,320
you really need to be pushing up towards

00:14:34,079 --> 00:14:39,839
you know 40 to 48

00:14:36,320 --> 00:14:43,120
gigabyte memory at least on the server

00:14:39,839 --> 00:14:46,399
if you're going to allocate 31 gigs of

00:14:43,120 --> 00:14:48,720
memory to uh g1 gc so

00:14:46,399 --> 00:14:50,000
those are the two things so on smaller

00:14:48,720 --> 00:14:53,519
heaps uh

00:14:50,000 --> 00:14:54,079
cms performs better and small is a

00:14:53,519 --> 00:14:56,880
relative

00:14:54,079 --> 00:14:59,120
term so um you know it for the purposes

00:14:56,880 --> 00:15:03,440
of talking about cassandra it's like

00:14:59,120 --> 00:15:06,800
16 to 20 gigs um even up to 24 gigs

00:15:03,440 --> 00:15:08,000
uh you know if you're used to using cms

00:15:06,800 --> 00:15:10,079
lots of um

00:15:08,000 --> 00:15:11,279
people who have been using cms for a

00:15:10,079 --> 00:15:15,279
long time they stick

00:15:11,279 --> 00:15:16,959
with cms up until 24 gigs

00:15:15,279 --> 00:15:18,880
although in my personal experience

00:15:16,959 --> 00:15:21,600
you're probably better off once

00:15:18,880 --> 00:15:22,160
once you're going beyond that 20 gig

00:15:21,600 --> 00:15:24,880
heap

00:15:22,160 --> 00:15:25,360
you're really better off switching to g1

00:15:24,880 --> 00:15:27,920
gc

00:15:25,360 --> 00:15:29,839
just because g1 performs a lot better

00:15:27,920 --> 00:15:32,000
for larger heat sizes

00:15:29,839 --> 00:15:33,920
so that's just something uh you'd like

00:15:32,000 --> 00:15:37,600
to keep in mind

00:15:33,920 --> 00:15:39,680
um i've made a note there about uh

00:15:37,600 --> 00:15:41,040
you know just sticking to a maximum of

00:15:39,680 --> 00:15:44,240
31 gigs

00:15:41,040 --> 00:15:47,680
that's because a 32 gig is um

00:15:44,240 --> 00:15:50,959
it actually has less addressable uh

00:15:47,680 --> 00:15:54,160
memory or less addressable objects

00:15:50,959 --> 00:15:57,519
than a 31 gig key and have put a

00:15:54,160 --> 00:16:00,639
um a blog post from fabian um

00:15:57,519 --> 00:16:01,759
that talks about um that on 64-bit

00:16:00,639 --> 00:16:05,680
systems

00:16:01,759 --> 00:16:09,040
so um for those who are interested so

00:16:05,680 --> 00:16:12,160
just to reiterate a 32 gig key

00:16:09,040 --> 00:16:13,360
um has less addressable objects than 31

00:16:12,160 --> 00:16:16,480
so only go

00:16:13,360 --> 00:16:16,800
up to a maximum excuse me a maximum of

00:16:16,480 --> 00:16:22,320
um

00:16:16,800 --> 00:16:24,320
31 beats really important to know

00:16:22,320 --> 00:16:25,920
if you're deploying on public clouds

00:16:24,320 --> 00:16:28,480
i've already mentioned that

00:16:25,920 --> 00:16:29,519
i'm a fan of you know like uh eight gig

00:16:28,480 --> 00:16:32,720
uh

00:16:29,519 --> 00:16:36,240
uh sorry eight core 32 gig systems

00:16:32,720 --> 00:16:38,880
um if you're running on aws uh

00:16:36,240 --> 00:16:39,920
i really like the i32x largest starting

00:16:38,880 --> 00:16:42,800
off point

00:16:39,920 --> 00:16:43,440
um lots of organizations would scale up

00:16:42,800 --> 00:16:47,759
to like an

00:16:43,440 --> 00:16:50,959
i3 4x large um

00:16:47,759 --> 00:16:54,639
really like the i3s because of the nvme

00:16:50,959 --> 00:16:58,560
ssds that they come with so you know if

00:16:54,639 --> 00:17:01,199
latency really matters to your use case

00:16:58,560 --> 00:17:01,839
um you've really got to go with the i3s

00:17:01,199 --> 00:17:05,439
although

00:17:01,839 --> 00:17:08,160
um you know i understand that

00:17:05,439 --> 00:17:09,039
some like some don't like the idea of

00:17:08,160 --> 00:17:12,959
running your

00:17:09,039 --> 00:17:17,280
production systems on federal uh storage

00:17:12,959 --> 00:17:20,319
so m5ds are are a good choice for that

00:17:17,280 --> 00:17:25,199
um as opposed to a traditional

00:17:20,319 --> 00:17:28,720
m5 so mainly the difference there in

00:17:25,199 --> 00:17:31,120
a lot of you know a lot of the people

00:17:28,720 --> 00:17:32,320
on the session right now have a lot of

00:17:31,120 --> 00:17:35,679
experience but so

00:17:32,320 --> 00:17:36,960
i'm i'm mostly talking about this for

00:17:35,679 --> 00:17:38,960
the

00:17:36,960 --> 00:17:41,039
uh for those who are new to cassandra

00:17:38,960 --> 00:17:43,440
and new to cloud for example

00:17:41,039 --> 00:17:44,559
um the main difference between an m5 and

00:17:43,440 --> 00:17:47,919
an n5d

00:17:44,559 --> 00:17:51,840
instance is that the m5ds have an

00:17:47,919 --> 00:17:52,720
onboard ssd they are quite good to use

00:17:51,840 --> 00:17:55,760
for

00:17:52,720 --> 00:17:57,039
commit logs because then it makes your

00:17:55,760 --> 00:17:59,840
writes

00:17:57,039 --> 00:18:01,280
really fast so that's that's my

00:17:59,840 --> 00:18:04,799
recommendation

00:18:01,280 --> 00:18:07,360
if you're gonna go with gp2 um

00:18:04,799 --> 00:18:09,280
you can uh but you have to provision

00:18:07,360 --> 00:18:13,120
three and a half terabytes

00:18:09,280 --> 00:18:16,080
um of uh ebs

00:18:13,120 --> 00:18:16,720
to to get uh the 10k ios because you

00:18:16,080 --> 00:18:19,679
only get

00:18:16,720 --> 00:18:20,160
three iops per per gigabyte and really

00:18:19,679 --> 00:18:23,120
for

00:18:20,160 --> 00:18:24,160
uh production workloads on cassandra you

00:18:23,120 --> 00:18:28,080
really need that

00:18:24,160 --> 00:18:32,080
um 10k iops um throughput

00:18:28,080 --> 00:18:33,440
um so um so that gets really expensive

00:18:32,080 --> 00:18:35,440
uh provisioning three and a half

00:18:33,440 --> 00:18:37,120
terabytes when you're really gonna use

00:18:35,440 --> 00:18:40,400
less than one terabyte

00:18:37,120 --> 00:18:42,640
um but that's that's what it is for gp2

00:18:40,400 --> 00:18:43,679
on io one you can you don't have to

00:18:42,640 --> 00:18:45,280
provision uh

00:18:43,679 --> 00:18:46,720
three and a half terabytes because you

00:18:45,280 --> 00:18:50,080
can you can just

00:18:46,720 --> 00:18:51,520
um provision the iops so you can get um

00:18:50,080 --> 00:18:54,240
10k ios

00:18:51,520 --> 00:18:55,360
and and that's for me that's what i

00:18:54,240 --> 00:18:58,799
generally

00:18:55,360 --> 00:19:00,320
recommend on azure it's a little bit

00:18:58,799 --> 00:19:03,760
slightly different so

00:19:00,320 --> 00:19:04,640
um the instance that i like is a

00:19:03,760 --> 00:19:08,960
standard

00:19:04,640 --> 00:19:12,000
d8s which is in v3 right now

00:19:08,960 --> 00:19:14,160
um azure keeps coming up with uh

00:19:12,000 --> 00:19:16,240
newer instance type so that's the

00:19:14,160 --> 00:19:21,200
current model it used to be

00:19:16,240 --> 00:19:24,320
um a uh i think it was a dsv

00:19:21,200 --> 00:19:29,120
three or something what it was called

00:19:24,320 --> 00:19:32,080
the equivalent uh instance type

00:19:29,120 --> 00:19:32,880
on azure you would provision a premium

00:19:32,080 --> 00:19:36,160
storage

00:19:32,880 --> 00:19:39,840
uh p30 is a sweet spot

00:19:36,160 --> 00:19:42,880
so you get that one terabyte um

00:19:39,840 --> 00:19:43,600
the the the good thing about uh those

00:19:42,880 --> 00:19:47,440
instances

00:19:43,600 --> 00:19:52,320
is that um they have an onboard cache

00:19:47,440 --> 00:19:56,080
so i think uh it's it has a 256

00:19:52,320 --> 00:19:59,120
gig cage which can sustain uh 16k

00:19:56,080 --> 00:20:01,919
ios um and and what

00:19:59,120 --> 00:20:02,640
what does that mean so premium storage

00:20:01,919 --> 00:20:05,840
um on

00:20:02,640 --> 00:20:07,600
azure is really the equivalent of a

00:20:05,840 --> 00:20:11,280
network attached disk

00:20:07,600 --> 00:20:13,840
um you know much like um what eds

00:20:11,280 --> 00:20:14,559
is except that the throughput is quite

00:20:13,840 --> 00:20:18,080
low

00:20:14,559 --> 00:20:21,360
um i think the p30s cap out at

00:20:18,080 --> 00:20:22,159
200 megabytes per second so it really

00:20:21,360 --> 00:20:24,799
isn't a lot

00:20:22,159 --> 00:20:26,159
um we were talking in the previous

00:20:24,799 --> 00:20:28,400
session before with some

00:20:26,159 --> 00:20:30,159
you know some clusters have really large

00:20:28,400 --> 00:20:30,640
partitions so imagine if you had like a

00:20:30,159 --> 00:20:32,840
1d

00:20:30,640 --> 00:20:34,240
partition that you're you're

00:20:32,840 --> 00:20:37,840
deserializing um

00:20:34,240 --> 00:20:40,400
having to to to send that across the

00:20:37,840 --> 00:20:41,120
wire with only 200 megabytes per second

00:20:40,400 --> 00:20:42,880
means that

00:20:41,120 --> 00:20:44,240
it'll take you five seconds to read that

00:20:42,880 --> 00:20:47,679
partition of a

00:20:44,240 --> 00:20:49,360
um ap 30 disk because your your you're

00:20:47,679 --> 00:20:51,120
you know transferring that stuff across

00:20:49,360 --> 00:20:54,960
the wire um

00:20:51,120 --> 00:20:56,880
the good thing with the with the the d8s

00:20:54,960 --> 00:20:58,400
instances is that they have with the

00:20:56,880 --> 00:21:02,159
onboard cage

00:20:58,400 --> 00:21:05,919
um i think uh for the d8 s

00:21:02,159 --> 00:21:09,360
it starts with a i think it was 400

00:21:05,919 --> 00:21:13,360
gigabytes of um onboard cache

00:21:09,360 --> 00:21:16,559
which is um a ssd that's embedded in the

00:21:13,360 --> 00:21:20,400
in the instance itself which means that

00:21:16,559 --> 00:21:23,919
um if you're if you're if you have about

00:21:20,400 --> 00:21:25,919
say 500 gigs of data per node it means

00:21:23,919 --> 00:21:29,200
that you're caching

00:21:25,919 --> 00:21:29,760
most of your data on the onboard ssd so

00:21:29,200 --> 00:21:32,080
you're not

00:21:29,760 --> 00:21:33,280
you're not constantly having to drag it

00:21:32,080 --> 00:21:36,480
across the wire

00:21:33,280 --> 00:21:39,039
um on from your p30 disk so

00:21:36,480 --> 00:21:40,080
you instead of reading from the p30

00:21:39,039 --> 00:21:43,200
across

00:21:40,080 --> 00:21:46,480
the the network you're reading you're

00:21:43,200 --> 00:21:48,960
really reading your data off of the um

00:21:46,480 --> 00:21:50,080
onboard ssds after it gets staged

00:21:48,960 --> 00:21:52,240
obviously

00:21:50,080 --> 00:21:54,799
there's a bit of warm-up time that's

00:21:52,240 --> 00:21:56,880
involved in that

00:21:54,799 --> 00:21:58,960
so i've made a note that you need to

00:21:56,880 --> 00:22:00,880
enable the read only cache and you have

00:21:58,960 --> 00:22:04,080
to disable barriers

00:22:00,880 --> 00:22:07,760
um they i've put a

00:22:04,080 --> 00:22:11,440
a link there where you can

00:22:07,760 --> 00:22:13,840
see how you enable the cache on those

00:22:11,440 --> 00:22:13,840
instances

00:22:16,559 --> 00:22:21,039
now some recommended settings

00:22:21,120 --> 00:22:26,240
for virtual nodes uh we've

00:22:24,240 --> 00:22:28,080
we've been talking quite about this

00:22:26,240 --> 00:22:32,159
quite a bit on the mailing list and

00:22:28,080 --> 00:22:33,360
um so the current default is 256 that's

00:22:32,159 --> 00:22:37,039
a really bad

00:22:33,360 --> 00:22:38,799
uh default we we know a lot more now

00:22:37,039 --> 00:22:42,799
than what we used to

00:22:38,799 --> 00:22:45,840
a few years ago um joey lynch

00:22:42,799 --> 00:22:48,000
and the other

00:22:45,840 --> 00:22:49,200
author escapes me at the moment but um

00:22:48,000 --> 00:22:53,280
wrote the paper about

00:22:49,200 --> 00:22:56,240
uh you know numb tokens um

00:22:53,280 --> 00:22:57,600
so generally for me i'm used to

00:22:56,240 --> 00:23:00,559
recommending eight

00:22:57,600 --> 00:23:01,440
um 16 is also a good choice um in terms

00:23:00,559 --> 00:23:04,640
of the

00:23:01,440 --> 00:23:05,600
num tokens um it does mean that there's

00:23:04,640 --> 00:23:09,120
a bit of um

00:23:05,600 --> 00:23:10,480
data skew so your uh your nodes won't

00:23:09,120 --> 00:23:14,400
exactly have

00:23:10,480 --> 00:23:16,480
um you know uh

00:23:14,400 --> 00:23:18,080
balanced data so there might be like a

00:23:16,480 --> 00:23:19,919
10 or 15

00:23:18,080 --> 00:23:22,000
differential so say you might have like

00:23:19,919 --> 00:23:23,520
a node that's 500 gig

00:23:22,000 --> 00:23:26,799
but then you'll have another node that

00:23:23,520 --> 00:23:30,480
might be like 550 560

00:23:26,799 --> 00:23:34,000
gigabytes um if data skew is a

00:23:30,480 --> 00:23:38,559
really big concern uh for you for you

00:23:34,000 --> 00:23:41,760
um then you can go to 32 num tokens

00:23:38,559 --> 00:23:44,799
maybe 64 at the most although um

00:23:41,760 --> 00:23:48,240
that's 64 is probably pushing it

00:23:44,799 --> 00:23:51,919
so um obviously your miles

00:23:48,240 --> 00:23:55,360
may vary because your data might not be

00:23:51,919 --> 00:23:58,240
um completely uh

00:23:55,360 --> 00:23:59,360
random in terms of the distribution and

00:23:58,240 --> 00:24:01,520
you know you might have

00:23:59,360 --> 00:24:03,440
partitions that you know you might have

00:24:01,520 --> 00:24:05,120
partitions that are only one megabyte in

00:24:03,440 --> 00:24:05,760
size and then you have partitions that

00:24:05,120 --> 00:24:09,120
are

00:24:05,760 --> 00:24:10,960
i don't know 500 megabytes in size so

00:24:09,120 --> 00:24:13,039
that would obviously affect your data

00:24:10,960 --> 00:24:16,000
distribution and the

00:24:13,039 --> 00:24:16,960
density on the nodes um but just going

00:24:16,000 --> 00:24:19,440
back um

00:24:16,960 --> 00:24:20,080
you know eight or sixteen it's a good

00:24:19,440 --> 00:24:24,320
choice

00:24:20,080 --> 00:24:28,400
when um um setting your num tokens uh in

00:24:24,320 --> 00:24:31,360
saying the dot yaml um there's a

00:24:28,400 --> 00:24:33,360
ticket at the moment where uh from

00:24:31,360 --> 00:24:35,840
jeremy hanna where

00:24:33,360 --> 00:24:37,679
we've made the recommendation to to

00:24:35,840 --> 00:24:40,880
switch the defaults down to

00:24:37,679 --> 00:24:47,840
16 instead of 256

00:24:40,880 --> 00:24:47,840
just to make it easy for new users

00:24:48,320 --> 00:24:54,080
um really quickly so i'll

00:24:51,520 --> 00:24:55,520
quickly run through the next slides so

00:24:54,080 --> 00:24:58,720
for replication

00:24:55,520 --> 00:25:01,919
um again for new users we recommend that

00:24:58,720 --> 00:25:04,799
you have a three replicas per dc so

00:25:01,919 --> 00:25:06,960
if you have a two dc setup um you know

00:25:04,799 --> 00:25:09,120
the first dc will have three replicas

00:25:06,960 --> 00:25:10,799
and the second dc will have three

00:25:09,120 --> 00:25:13,679
replicas as well

00:25:10,799 --> 00:25:14,320
um even if you're using a single dc

00:25:13,679 --> 00:25:16,480
clusters

00:25:14,320 --> 00:25:18,240
get used to always using network

00:25:16,480 --> 00:25:21,360
topology strategy

00:25:18,240 --> 00:25:24,320
this makes your uh your

00:25:21,360 --> 00:25:26,159
configuration future proof so that when

00:25:24,320 --> 00:25:29,279
when it comes to a time when

00:25:26,159 --> 00:25:30,720
you want to um scale up your cluster and

00:25:29,279 --> 00:25:33,120
add another dc

00:25:30,720 --> 00:25:35,279
it makes the transition really simple if

00:25:33,120 --> 00:25:38,320
you if you started off

00:25:35,279 --> 00:25:40,799
using a network topology strategy so

00:25:38,320 --> 00:25:42,159
as soon as you create new application

00:25:40,799 --> 00:25:45,120
key spaces

00:25:42,159 --> 00:25:47,679
um just use network topology strategy

00:25:45,120 --> 00:25:51,120
even if you have no intention of adding

00:25:47,679 --> 00:25:53,919
um any any dc you know more than

00:25:51,120 --> 00:25:58,240
one dc to your cluster it just gets you

00:25:53,919 --> 00:25:58,240
off to a good start um

00:25:59,440 --> 00:26:04,320
for racks this this one comes up quite a

00:26:02,400 --> 00:26:06,799
lot i feel a lot of questions about

00:26:04,320 --> 00:26:06,799
racks

00:26:07,120 --> 00:26:10,720
i'm a big fan of single rack

00:26:09,039 --> 00:26:14,159
configuration

00:26:10,720 --> 00:26:14,960
it makes it it for me personally i think

00:26:14,159 --> 00:26:18,320
it suits

00:26:14,960 --> 00:26:21,200
most environments

00:26:18,320 --> 00:26:22,559
but if you really want to take advantage

00:26:21,200 --> 00:26:25,760
of

00:26:22,559 --> 00:26:27,520
the cassandra racks and and there are

00:26:25,760 --> 00:26:30,559
advantages to doing that

00:26:27,520 --> 00:26:32,159
so for example if you have um your if

00:26:30,559 --> 00:26:34,159
you have a

00:26:32,159 --> 00:26:35,840
dc where the nodes are distributed

00:26:34,159 --> 00:26:39,279
across three racks you can

00:26:35,840 --> 00:26:40,000
you can say do like a rolling restart of

00:26:39,279 --> 00:26:43,039
all the notes

00:26:40,000 --> 00:26:44,000
in that are on the same rack or you know

00:26:43,039 --> 00:26:46,559
so you can do

00:26:44,000 --> 00:26:47,919
uh patching of those tracks because then

00:26:46,559 --> 00:26:49,120
you're guaranteed that there are two

00:26:47,919 --> 00:26:52,240
other racks that will

00:26:49,120 --> 00:26:55,279
take the load um and

00:26:52,240 --> 00:26:57,120
so in in a couple of slides before the

00:26:55,279 --> 00:26:59,200
general recommendation is that you have

00:26:57,120 --> 00:27:01,279
um three replicas for dc

00:26:59,200 --> 00:27:02,480
so if you're gonna use frax i i

00:27:01,279 --> 00:27:06,159
recommend that you have

00:27:02,480 --> 00:27:09,039
uh three racks um in each dc as well

00:27:06,159 --> 00:27:09,679
if that's not something that you can do

00:27:09,039 --> 00:27:12,080
then

00:27:09,679 --> 00:27:13,919
fall back into a single single rack

00:27:12,080 --> 00:27:16,240
configuration

00:27:13,919 --> 00:27:17,840
uh the main reason for that is that the

00:27:16,240 --> 00:27:20,799
the data distribution

00:27:17,840 --> 00:27:23,039
so i see a lot of folks where they have

00:27:20,799 --> 00:27:25,279
a replication factor of three

00:27:23,039 --> 00:27:27,039
and they only have they have like a two

00:27:25,279 --> 00:27:29,679
rack configuration

00:27:27,039 --> 00:27:30,880
um and and what happens is that the the

00:27:29,679 --> 00:27:33,360
data is not

00:27:30,880 --> 00:27:34,960
balanced um not you know the beta

00:27:33,360 --> 00:27:37,520
distribution

00:27:34,960 --> 00:27:38,559
on the note is not balanced because it's

00:27:37,520 --> 00:27:41,200
hard just to

00:27:38,559 --> 00:27:43,279
divide you know um three replicas on

00:27:41,200 --> 00:27:46,799
across just two racks

00:27:43,279 --> 00:27:49,919
or um you know i've seen uh

00:27:46,799 --> 00:27:51,760
some situations where again still with a

00:27:49,919 --> 00:27:52,080
replication factor of three but they

00:27:51,760 --> 00:27:55,840
have

00:27:52,080 --> 00:27:56,399
five racks um in the dc again you know

00:27:55,840 --> 00:27:58,960
the

00:27:56,399 --> 00:27:59,440
the data distribution is not balanced

00:27:58,960 --> 00:28:01,919
and

00:27:59,440 --> 00:28:04,000
and don't know that you get a lot of a

00:28:01,919 --> 00:28:05,360
lot of benefit from doing that by not

00:28:04,000 --> 00:28:09,200
have by having that

00:28:05,360 --> 00:28:12,640
weird kind of uh configuration so

00:28:09,200 --> 00:28:16,240
um when in doubt um just go with a

00:28:12,640 --> 00:28:18,799
single right configuration

00:28:16,240 --> 00:28:19,760
for smitch um there's a lot of snitches

00:28:18,799 --> 00:28:23,200
out there

00:28:19,760 --> 00:28:24,000
um i i i get that there's a there's an

00:28:23,200 --> 00:28:26,480
appetite

00:28:24,000 --> 00:28:28,240
to use like um specific cloud snitches

00:28:26,480 --> 00:28:31,279
so for example if you're

00:28:28,240 --> 00:28:32,480
easy to use the easy to switch because

00:28:31,279 --> 00:28:34,640
then you know you don't have to

00:28:32,480 --> 00:28:37,520
configure the racks um

00:28:34,640 --> 00:28:38,640
that's all handled for you but i highly

00:28:37,520 --> 00:28:41,840
recommend using

00:28:38,640 --> 00:28:45,279
uh gpfs um

00:28:41,840 --> 00:28:48,480
it's it's very flexible and

00:28:45,279 --> 00:28:50,080
you know this you know at this point you

00:28:48,480 --> 00:28:50,640
might think oh we're only ever going to

00:28:50,080 --> 00:28:53,919
be

00:28:50,640 --> 00:28:56,480
say on um ec2 so you know we're happy to

00:28:53,919 --> 00:28:59,919
sleep with easy to snitch

00:28:56,480 --> 00:29:00,399
but you know when when it comes a time

00:28:59,919 --> 00:29:03,840
when

00:29:00,399 --> 00:29:06,240
you you want to for example uh

00:29:03,840 --> 00:29:07,760
go hybrid so you might have like an

00:29:06,240 --> 00:29:11,520
on-premise dc

00:29:07,760 --> 00:29:15,600
and uh and you know a dc and aws

00:29:11,520 --> 00:29:19,440
or you want to expand your cluster to

00:29:15,600 --> 00:29:20,080
azure um you really need to use gpfs in

00:29:19,440 --> 00:29:22,080
in

00:29:20,080 --> 00:29:23,200
you know it becomes a real pain having

00:29:22,080 --> 00:29:27,440
to switch from

00:29:23,200 --> 00:29:29,279
saying you know an ec2 snitch or a

00:29:27,440 --> 00:29:32,399
google's cloud snitch

00:29:29,279 --> 00:29:36,960
um in the future so

00:29:32,399 --> 00:29:40,399
use up just use gps as a default

00:29:36,960 --> 00:29:43,520
um really quickly um

00:29:40,399 --> 00:29:47,120
again this comes up a lot too uh

00:29:43,520 --> 00:29:47,120
use a strong consistency

00:29:47,600 --> 00:29:52,720
and highly recommend local quorum for

00:29:50,159 --> 00:29:54,960
both reads and rights

00:29:52,720 --> 00:29:56,159
there's there's there's quite a lot of

00:29:54,960 --> 00:29:58,960
come up across um

00:29:56,159 --> 00:29:59,600
organizations that use a consistency

00:29:58,960 --> 00:30:02,880
level of

00:29:59,600 --> 00:30:05,360
two um that's uh

00:30:02,880 --> 00:30:06,399
really problematic because when you when

00:30:05,360 --> 00:30:10,320
you

00:30:06,399 --> 00:30:14,640
um add another dc suddenly your

00:30:10,320 --> 00:30:17,360
uh your uh consistency is no longer

00:30:14,640 --> 00:30:18,240
local so you know there's a chance that

00:30:17,360 --> 00:30:23,440
you could be

00:30:18,240 --> 00:30:25,600
um you know doing uh you're expecting a

00:30:23,440 --> 00:30:28,720
local consistency but

00:30:25,600 --> 00:30:32,000
you're hitting remote notes um

00:30:28,720 --> 00:30:32,720
so it's um so that's um quite important

00:30:32,000 --> 00:30:36,480
to

00:30:32,720 --> 00:30:38,799
to note too so um

00:30:36,480 --> 00:30:41,760
don't allow remote pieces for uh local

00:30:38,799 --> 00:30:41,760
consistencies

00:30:42,640 --> 00:30:47,360
um some more recommended settings from

00:30:45,440 --> 00:30:49,360
an operating system perspective this

00:30:47,360 --> 00:30:52,559
list is not exhaustive

00:30:49,360 --> 00:30:56,480
i've picked the ones that are

00:30:52,559 --> 00:30:59,200
you know easy to knock off

00:30:56,480 --> 00:31:00,399
tcp keeper lives particularly this is

00:30:59,200 --> 00:31:03,519
really important

00:31:00,399 --> 00:31:04,000
if if you've got firewalls between nodes

00:31:03,519 --> 00:31:07,360
between

00:31:04,000 --> 00:31:09,760
dc's which you should have

00:31:07,360 --> 00:31:11,519
because the tcp keeper lights will just

00:31:09,760 --> 00:31:13,279
make sure that you know your connections

00:31:11,519 --> 00:31:16,840
and your sockets

00:31:13,279 --> 00:31:21,519
don't don't get

00:31:16,840 --> 00:31:22,720
disconnected um cpu frequency scaling as

00:31:21,519 --> 00:31:25,600
well disable that

00:31:22,720 --> 00:31:27,440
um straight away if you know

00:31:25,600 --> 00:31:30,480
particularly for

00:31:27,440 --> 00:31:32,080
red hat systems where um you know it's

00:31:30,480 --> 00:31:34,000
enabled by default

00:31:32,080 --> 00:31:35,360
um that will kill the performance of

00:31:34,000 --> 00:31:37,600
your cluster

00:31:35,360 --> 00:31:39,679
um particularly when you hit like low

00:31:37,600 --> 00:31:43,279
traffic periods because uh

00:31:39,679 --> 00:31:46,720
your your server is trying to save um

00:31:43,279 --> 00:31:47,039
power in yeah so the latency goes up

00:31:46,720 --> 00:31:51,039
when

00:31:47,039 --> 00:31:53,440
when you try to do reads for example

00:31:51,039 --> 00:31:56,000
um yeah i knew that this was going to be

00:31:53,440 --> 00:31:58,399
contentious about disabling swap this

00:31:56,000 --> 00:32:01,039
there's a lot of uh you know

00:31:58,399 --> 00:32:04,720
organizations or uh

00:32:01,039 --> 00:32:07,440
you know they love their swap um

00:32:04,720 --> 00:32:07,760
uh i don't understand it but don't get

00:32:07,440 --> 00:32:11,279
it

00:32:07,760 --> 00:32:14,559
um if if if you have to enable swap

00:32:11,279 --> 00:32:17,679
then you know set swapping to um

00:32:14,559 --> 00:32:19,840
one or something um

00:32:17,679 --> 00:32:21,039
it really doesn't um do well when your

00:32:19,840 --> 00:32:24,399
jvm is getting

00:32:21,039 --> 00:32:26,720
uh swapped out um you know you get

00:32:24,399 --> 00:32:28,000
all sorts of weird errors so this is one

00:32:26,720 --> 00:32:31,600
of the first things i check

00:32:28,000 --> 00:32:34,799
when someone asks me you know

00:32:31,600 --> 00:32:37,600
and have a problem with performance or

00:32:34,799 --> 00:32:40,320
you know like strange behavior from

00:32:37,600 --> 00:32:40,320
their cluster

00:32:40,399 --> 00:32:45,600
another good one to to do is to

00:32:43,760 --> 00:32:46,799
to drop the breather head to eight

00:32:45,600 --> 00:32:50,559
kilobytes

00:32:46,799 --> 00:32:53,679
um that's just so you're not uh pulling

00:32:50,559 --> 00:32:57,919
a lot of data off the disk

00:32:53,679 --> 00:33:00,159
and particularly in those um cases where

00:32:57,919 --> 00:33:01,279
you know your cluster has really small

00:33:00,159 --> 00:33:03,360
partitions

00:33:01,279 --> 00:33:04,399
um you can even drop that breather head

00:33:03,360 --> 00:33:07,440
further down to

00:33:04,399 --> 00:33:09,679
um 4ks

00:33:07,440 --> 00:33:10,880
again so you know it increases the

00:33:09,679 --> 00:33:13,440
throughput

00:33:10,880 --> 00:33:14,799
of your cluster because you're you can

00:33:13,440 --> 00:33:17,440
you can

00:33:14,799 --> 00:33:19,679
you know do more reads of this but

00:33:17,440 --> 00:33:24,240
you're only reading small chunks

00:33:19,679 --> 00:33:27,919
um out um and one final thing about um

00:33:24,240 --> 00:33:29,840
operating system uh uh

00:33:27,919 --> 00:33:32,159
tuning is that um disable the

00:33:29,840 --> 00:33:35,679
transparent huge pages are

00:33:32,159 --> 00:33:36,320
defragged um i've put up a link there

00:33:35,679 --> 00:33:38,240
for

00:33:36,320 --> 00:33:39,760
where you can get a little bit more uh

00:33:38,240 --> 00:33:42,880
detail about this uh

00:33:39,760 --> 00:33:42,880
recommended settings

00:33:43,279 --> 00:33:47,600
so we've we've gone through the the

00:33:45,679 --> 00:33:49,279
first and second sections just

00:33:47,600 --> 00:33:50,720
for a bit of reminder i'm gonna quickly

00:33:49,279 --> 00:33:54,480
go on to the

00:33:50,720 --> 00:33:57,519
tools now just to try and stick the time

00:33:54,480 --> 00:33:59,519
so i get asked about this a lot so for

00:33:57,519 --> 00:34:01,519
backups there's cassandra labusa

00:33:59,519 --> 00:34:02,960
by the way these are all open source

00:34:01,519 --> 00:34:06,399
tools they're all

00:34:02,960 --> 00:34:07,519
free for repairs there's cassandra

00:34:06,399 --> 00:34:10,720
reaper

00:34:07,519 --> 00:34:11,919
um makes it really easy to manage your

00:34:10,720 --> 00:34:14,720
repairs

00:34:11,919 --> 00:34:15,359
um you really got to have monitoring

00:34:14,720 --> 00:34:19,040
right so

00:34:15,359 --> 00:34:20,879
um when when fielding questions from

00:34:19,040 --> 00:34:22,560
different users and stuff usually the

00:34:20,879 --> 00:34:24,879
first thing i ask is

00:34:22,560 --> 00:34:25,919
you know i'm asking about some of the

00:34:24,879 --> 00:34:27,839
metrics like

00:34:25,919 --> 00:34:30,079
you know what your what does your

00:34:27,839 --> 00:34:33,679
monitoring look like

00:34:30,079 --> 00:34:37,040
there's a datastax metrics collector for

00:34:33,679 --> 00:34:39,359
apache cassandra which allows you to

00:34:37,040 --> 00:34:42,079
export the metrics to grafana and

00:34:39,359 --> 00:34:45,040
prometheus

00:34:42,079 --> 00:34:46,879
really easy to to get it working out of

00:34:45,040 --> 00:34:49,919
the box if you're already using

00:34:46,879 --> 00:34:52,000
prometheus in your environment for

00:34:49,919 --> 00:34:56,240
benchmarking there's no sql

00:34:52,000 --> 00:34:59,440
pitch this tlp stress from

00:34:56,240 --> 00:35:02,480
the last pickle so these things um

00:34:59,440 --> 00:35:04,000
replace cassandra stress and more

00:35:02,480 --> 00:35:07,599
recently

00:35:04,000 --> 00:35:10,240
harry got accepted uh into the project

00:35:07,599 --> 00:35:12,960
so that's one new thing to look at i

00:35:10,240 --> 00:35:14,560
haven't seen it myself

00:35:12,960 --> 00:35:17,839
and if you're looking doing data

00:35:14,560 --> 00:35:17,839
migration so

00:35:18,000 --> 00:35:24,960
i highly recommend the dsr bulk loader

00:35:21,040 --> 00:35:28,320
you can do you can load and unload

00:35:24,960 --> 00:35:33,599
data into csv or json format

00:35:28,320 --> 00:35:33,599
it's also a good way of doing count um

00:35:33,920 --> 00:35:36,320
and

00:35:38,960 --> 00:35:42,880
uh troubleshooting so i'm just gonna

00:35:41,040 --> 00:35:44,000
quickly power through because i'm i've

00:35:42,880 --> 00:35:46,800
only got four minutes

00:35:44,000 --> 00:35:48,720
left so um really important if you're

00:35:46,800 --> 00:35:51,440
new to cassandra don't just

00:35:48,720 --> 00:35:52,320
stop start your nodes without looking at

00:35:51,440 --> 00:35:55,440
the logs

00:35:52,320 --> 00:35:57,359
always keep watching the logs one really

00:35:55,440 --> 00:35:59,680
important thing to point out is that you

00:35:57,359 --> 00:36:03,200
need to familiarize yourself with

00:35:59,680 --> 00:36:05,760
what a working node looks like um

00:36:03,200 --> 00:36:07,359
you know because sometimes when when you

00:36:05,760 --> 00:36:10,320
hit the problem you know

00:36:07,359 --> 00:36:11,520
you don't know whether something is okay

00:36:10,320 --> 00:36:13,280
or not

00:36:11,520 --> 00:36:15,359
when you're looking at the log entries

00:36:13,280 --> 00:36:16,880
because you know if you don't know what

00:36:15,359 --> 00:36:19,440
a normie

00:36:16,880 --> 00:36:20,480
a working node looks like so that's

00:36:19,440 --> 00:36:23,920
something that's

00:36:20,480 --> 00:36:23,920
really important to keep in mind

00:36:25,040 --> 00:36:28,800
just a bit of a plug so when you're

00:36:27,040 --> 00:36:32,079
asking questions whether it's on

00:36:28,800 --> 00:36:34,560
slack or the mailing list or whatever um

00:36:32,079 --> 00:36:36,160
you know help me help you provide the

00:36:34,560 --> 00:36:37,359
versions of zeke because that's really

00:36:36,160 --> 00:36:40,160
important

00:36:37,359 --> 00:36:42,079
you know the the type of driver that

00:36:40,160 --> 00:36:44,800
you're using in the version

00:36:42,079 --> 00:36:46,880
um the the java version that you're

00:36:44,800 --> 00:36:49,280
using plus the vendor as well that

00:36:46,880 --> 00:36:50,800
uh you know in some cases that's handy

00:36:49,280 --> 00:36:52,240
um

00:36:50,800 --> 00:36:53,839
when you're asking the question tell us

00:36:52,240 --> 00:36:55,680
what the investigation you've already

00:36:53,839 --> 00:36:59,040
done and what what things did you

00:36:55,680 --> 00:37:01,040
already rule out um and it's really

00:36:59,040 --> 00:37:02,560
important that you know instead of just

00:37:01,040 --> 00:37:06,160
providing a random

00:37:02,560 --> 00:37:07,920
uh accept exception um

00:37:06,160 --> 00:37:09,680
you know should you should really

00:37:07,920 --> 00:37:11,040
provide the full error message with the

00:37:09,680 --> 00:37:16,400
full stack trace

00:37:11,040 --> 00:37:16,400
because um that stack trace is um

00:37:17,040 --> 00:37:20,960
i'll talk about the stack trace in a

00:37:18,880 --> 00:37:22,560
second but just quickly

00:37:20,960 --> 00:37:24,960
some of the commands it's really helpful

00:37:22,560 --> 00:37:27,520
when you're uh troubleshooting issues

00:37:24,960 --> 00:37:28,560
so look at no till netstat so the repair

00:37:27,520 --> 00:37:31,440
sessions

00:37:28,560 --> 00:37:33,040
types of read repairs uh tpstats tells

00:37:31,440 --> 00:37:34,480
you about things like drop messages

00:37:33,040 --> 00:37:35,760
whether you're dropping your session so

00:37:34,480 --> 00:37:37,839
you're dropping reads

00:37:35,760 --> 00:37:39,680
also really handy to find out whether

00:37:37,839 --> 00:37:41,520
you've accidentally enabled uh

00:37:39,680 --> 00:37:43,599
tracing and because that's that will

00:37:41,520 --> 00:37:44,240
affect your the performance of your

00:37:43,599 --> 00:37:48,720
cluster

00:37:44,240 --> 00:37:51,200
um heavily there's other commands there

00:37:48,720 --> 00:37:52,880
um two so proxy histograms and table

00:37:51,200 --> 00:37:54,480
histograms if um

00:37:52,880 --> 00:37:56,079
just to get an idea of the kind of

00:37:54,480 --> 00:37:57,680
latencies that you're hitting with your

00:37:56,079 --> 00:38:01,200
cluster

00:37:57,680 --> 00:38:01,200
and table stats as well

00:38:02,320 --> 00:38:05,920
i mentioned about the stack trace if you

00:38:04,079 --> 00:38:09,680
can read a bit of java

00:38:05,920 --> 00:38:12,640
you know um you don't need to be a

00:38:09,680 --> 00:38:13,359
an expert just um do a bit of code

00:38:12,640 --> 00:38:15,359
diving

00:38:13,359 --> 00:38:16,960
um use the stack trace as a starting

00:38:15,359 --> 00:38:18,079
point but make sure that you're looking

00:38:16,960 --> 00:38:19,839
at the right

00:38:18,079 --> 00:38:23,280
cassandra version when you're code

00:38:19,839 --> 00:38:23,280
diving um

00:38:24,079 --> 00:38:29,359
and just really quickly um there's free

00:38:26,720 --> 00:38:30,880
online resources so this data stacks.com

00:38:29,359 --> 00:38:33,680
dave

00:38:30,880 --> 00:38:34,079
is you know like uh tutorials there you

00:38:33,680 --> 00:38:36,720
know

00:38:34,079 --> 00:38:38,560
10 15 minute tutorials uh where you can

00:38:36,720 --> 00:38:39,680
quickly learn some key concepts about

00:38:38,560 --> 00:38:43,040
cassandra

00:38:39,680 --> 00:38:43,040
um there's free courses at

00:38:44,839 --> 00:38:49,920
academy.datastacks.com

00:38:46,640 --> 00:38:52,560
uh and if you're if you're new to

00:38:49,920 --> 00:38:53,920
building apps this datastax.com example

00:38:52,560 --> 00:38:56,320
so we give our

00:38:53,920 --> 00:38:58,240
code examples there to get you started

00:38:56,320 --> 00:39:00,000
really quickly just so you don't have to

00:38:58,240 --> 00:39:02,960
start from scratch

00:39:00,000 --> 00:39:05,280
um and finally if you if you've got any

00:39:02,960 --> 00:39:09,040
questions it's af asf slack

00:39:05,280 --> 00:39:11,359
is the cassandra mailing list um

00:39:09,040 --> 00:39:13,680
i do want to stop on stack overflow too

00:39:11,359 --> 00:39:16,280
when i have a bit of spare time

00:39:13,680 --> 00:39:19,280
and finally there's

00:39:16,280 --> 00:39:19,280
community.datastax.com

00:39:19,760 --> 00:39:24,320
thank you i think i just managed to get

00:39:21,599 --> 00:39:26,960
in thanks a lot

00:39:24,320 --> 00:39:28,880
i'm happy to answer questions on the

00:39:26,960 --> 00:39:43,839
apache on slack if

00:39:28,880 --> 00:39:43,839
you've got any questions

00:39:54,839 --> 00:39:57,839
yes

00:40:45,119 --> 00:40:53,839
come on

00:41:46,160 --> 00:41:48,240

YouTube URL: https://www.youtube.com/watch?v=ULDJLPIlCSA


