Title: #FOSSBack: Coraline Ada Ehmke - The Rising Ethical Storm in Open Source
Publication date: 2021-03-01
Playlist: FOSS Backstage 2021 #FOSSBack
Description: 
	Open source software today is increasingly used in mass surveillance, anti-immigrant violence, protester suppression, racist policing, and other humans rights abuses. The increasing debate around the ethical responsibilities of open source developers threatens to divide our community. What will be our path forward to reconcile software freedom with human freedom?



###########



Follow us on Social Media and join the Community!



Twitter: https://twitter.com/Fossbckstg
LinkedIn: https://www.linkedin.com/groups/8653059/​



FOSS Backstage is an event by Plain Schwarz – https://plainschwarz.com
Captions: 
	00:00:03,520 --> 00:00:07,839
thank you very much for uh

00:00:05,200 --> 00:00:09,679
for listening today my name is coraline

00:00:07,839 --> 00:00:11,120
adamke as mentioned i

00:00:09,679 --> 00:00:13,120
have a lot of years in software

00:00:11,120 --> 00:00:16,080
development and i've been in the open

00:00:13,120 --> 00:00:18,279
source community for about 16 years in

00:00:16,080 --> 00:00:20,320
2014 i invented the code of

00:00:18,279 --> 00:00:21,039
conduct.markdown that you see in almost

00:00:20,320 --> 00:00:23,920
every

00:00:21,039 --> 00:00:25,920
open source repository and i created the

00:00:23,920 --> 00:00:27,680
contributor covenant which was the first

00:00:25,920 --> 00:00:31,119
and most popular code of conduct for

00:00:27,680 --> 00:00:33,440
open source communities

00:00:31,119 --> 00:00:35,280
i want to start by telling you a story

00:00:33,440 --> 00:00:37,440
in the 1960s

00:00:35,280 --> 00:00:38,960
with growing tensions between the us and

00:00:37,440 --> 00:00:41,040
the soviet union

00:00:38,960 --> 00:00:42,239
a computer scientist published a short

00:00:41,040 --> 00:00:44,879
piece that he called

00:00:42,239 --> 00:00:47,039
the parable of the locksmith and this is

00:00:44,879 --> 00:00:48,879
my retelling

00:00:47,039 --> 00:00:50,399
one day a mysterious stranger walked

00:00:48,879 --> 00:00:53,039
into a locksmith shop

00:00:50,399 --> 00:00:54,559
and he came with a proposition he said i

00:00:53,039 --> 00:00:56,800
have a job that needs doing

00:00:54,559 --> 00:00:58,480
and requires someone with your highly

00:00:56,800 --> 00:01:00,559
specialized skills

00:00:58,480 --> 00:01:01,680
i've done my research and you're one of

00:01:00,559 --> 00:01:03,760
the smartest

00:01:01,680 --> 00:01:05,600
and most capable locksmiths in the

00:01:03,760 --> 00:01:07,680
entire city

00:01:05,600 --> 00:01:09,920
the locksmith felt very flattered and

00:01:07,680 --> 00:01:12,799
was more than a little intrigued

00:01:09,920 --> 00:01:13,119
the stranger continued i want to hire

00:01:12,799 --> 00:01:16,159
you

00:01:13,119 --> 00:01:16,640
to open a safe never mind who's safe it

00:01:16,159 --> 00:01:19,119
is

00:01:16,640 --> 00:01:20,799
that's none of your concern just do the

00:01:19,119 --> 00:01:22,880
job i hire you to do

00:01:20,799 --> 00:01:27,360
and i will make you rich beyond your

00:01:22,880 --> 00:01:29,759
wildest dreams the locksmith was excited

00:01:27,360 --> 00:01:31,759
at the proposition of a lucrative job

00:01:29,759 --> 00:01:33,200
but also a bit nervous about not knowing

00:01:31,759 --> 00:01:34,560
who the safe belonged to it seemed

00:01:33,200 --> 00:01:36,320
suspicious

00:01:34,560 --> 00:01:38,079
but the stranger went on there are

00:01:36,320 --> 00:01:39,600
certain other conditions you'll have to

00:01:38,079 --> 00:01:41,600
agree to as well

00:01:39,600 --> 00:01:44,000
i will blindfold you and take your phone

00:01:41,600 --> 00:01:46,000
before bringing you to the safe location

00:01:44,000 --> 00:01:47,920
and you can never tell anyone that i

00:01:46,000 --> 00:01:50,320
hired you

00:01:47,920 --> 00:01:51,759
destructive locksmith is odd but he

00:01:50,320 --> 00:01:53,360
thought about what the manage said about

00:01:51,759 --> 00:01:55,119
making him rich

00:01:53,360 --> 00:01:56,960
he felt like he'd struggled all his life

00:01:55,119 --> 00:02:00,000
and is never properly rewarded for the

00:01:56,960 --> 00:02:02,079
hard work he put in day after day

00:02:00,000 --> 00:02:03,520
you can have all the tools you need to

00:02:02,079 --> 00:02:07,600
do the job the very

00:02:03,520 --> 00:02:10,080
best tools i will spare no expense

00:02:07,600 --> 00:02:12,720
take your time i'll be back tomorrow for

00:02:10,080 --> 00:02:12,720
your answer

00:02:13,120 --> 00:02:16,239
despite his hesitation about the nature

00:02:15,200 --> 00:02:18,000
of the job

00:02:16,239 --> 00:02:20,480
the locksmith spent all night thinking

00:02:18,000 --> 00:02:21,520
about his crummy apartment his shabby

00:02:20,480 --> 00:02:23,840
furniture

00:02:21,520 --> 00:02:24,800
his daughter's dream of one day going to

00:02:23,840 --> 00:02:26,560
college

00:02:24,800 --> 00:02:28,400
from the beginning his family had to

00:02:26,560 --> 00:02:30,080
scrimp and save just to get by and

00:02:28,400 --> 00:02:32,480
anyway he told himself

00:02:30,080 --> 00:02:34,160
if i don't take this job he'll just go

00:02:32,480 --> 00:02:37,280
to another locksmith

00:02:34,160 --> 00:02:39,120
the second best locksmith and the next

00:02:37,280 --> 00:02:43,040
day when the stranger returned

00:02:39,120 --> 00:02:43,040
the locksmith agreed to take the job

00:02:43,200 --> 00:02:47,360
after multiple blindfolded trips to and

00:02:45,519 --> 00:02:50,319
from the unknown location

00:02:47,360 --> 00:02:52,080
the locksmith finally cracked the safe

00:02:50,319 --> 00:02:54,400
he wasn't allowed to see what was inside

00:02:52,080 --> 00:02:56,800
of it the stranger blindfolded him again

00:02:54,400 --> 00:02:58,159
as soon as the lock clicked open but

00:02:56,800 --> 00:03:00,319
true to his word

00:02:58,159 --> 00:03:05,120
the stranger made the locksmith

00:03:00,319 --> 00:03:06,640
exceedingly rich

00:03:05,120 --> 00:03:08,319
we're going to come back to this parable

00:03:06,640 --> 00:03:11,840
and find out what happened when the safe

00:03:08,319 --> 00:03:11,840
was opened in just a few minutes

00:03:11,920 --> 00:03:15,760
this is an hp laserjet one of the first

00:03:14,480 --> 00:03:18,480
laser printers

00:03:15,760 --> 00:03:20,400
it came out in 1983 and at the time a

00:03:18,480 --> 00:03:22,640
man named richard stallman was working

00:03:20,400 --> 00:03:24,560
in an ai lab at xerox

00:03:22,640 --> 00:03:26,560
the lab acquired one of these printers

00:03:24,560 --> 00:03:29,599
it was cutting edge technology

00:03:26,560 --> 00:03:31,519
but it constantly jammed the lab had

00:03:29,599 --> 00:03:32,000
time sharing software so you had to book

00:03:31,519 --> 00:03:34,560
time for

00:03:32,000 --> 00:03:36,720
various resources including a printer

00:03:34,560 --> 00:03:37,760
but if you set aside and book 30 minutes

00:03:36,720 --> 00:03:39,840
for printing

00:03:37,760 --> 00:03:41,599
only to discover that it jammed five

00:03:39,840 --> 00:03:44,000
minutes in you'd be upset

00:03:41,599 --> 00:03:46,319
so stallman and his co-workers decided

00:03:44,000 --> 00:03:46,720
to change the printer driver so that it

00:03:46,319 --> 00:03:48,799
would

00:03:46,720 --> 00:03:51,519
report jams back to the time sharing

00:03:48,799 --> 00:03:54,400
software and users could be notified

00:03:51,519 --> 00:03:54,879
but the software was proprietary and hp

00:03:54,400 --> 00:03:58,400
wouldn't

00:03:54,879 --> 00:03:59,760
share the source code stallman found out

00:03:58,400 --> 00:04:02,080
that a colleague at mit

00:03:59,760 --> 00:04:03,920
had the source code but that person had

00:04:02,080 --> 00:04:04,400
sent a non-disclosure agreement and

00:04:03,920 --> 00:04:07,360
couldn't

00:04:04,400 --> 00:04:08,720
share it solomon got really angry not

00:04:07,360 --> 00:04:10,400
just about the printer

00:04:08,720 --> 00:04:13,120
but about the fact that the world was

00:04:10,400 --> 00:04:15,360
shifting toward proprietary software

00:04:13,120 --> 00:04:16,639
and this incident with a printer would

00:04:15,360 --> 00:04:20,160
lead to the creation

00:04:16,639 --> 00:04:22,479
of the free software movement

00:04:20,160 --> 00:04:24,000
in the mid to late 90s when the world

00:04:22,479 --> 00:04:25,919
discovered the internet

00:04:24,000 --> 00:04:27,360
free software became a popular choice

00:04:25,919 --> 00:04:29,360
for web servers

00:04:27,360 --> 00:04:31,840
apache became the most used web server

00:04:29,360 --> 00:04:33,600
software pedro that still holds

00:04:31,840 --> 00:04:34,880
many systems were based on a common

00:04:33,600 --> 00:04:37,520
stack of software

00:04:34,880 --> 00:04:39,199
with the linux kernel at the base apache

00:04:37,520 --> 00:04:42,160
providing web services

00:04:39,199 --> 00:04:43,759
mysql as a database and a php or perl

00:04:42,160 --> 00:04:46,639
programming languages for

00:04:43,759 --> 00:04:49,280
providing dynamic pages all open source

00:04:46,639 --> 00:04:51,360
technologies

00:04:49,280 --> 00:04:53,040
christine peterson coined the term open

00:04:51,360 --> 00:04:54,720
source in 1998

00:04:53,040 --> 00:04:57,280
and that same year the open source

00:04:54,720 --> 00:04:59,120
definition was pinned by bruce parents

00:04:57,280 --> 00:05:01,120
nine months later the open source

00:04:59,120 --> 00:05:02,720
initiative was was founded

00:05:01,120 --> 00:05:04,160
to promote the use of open source

00:05:02,720 --> 00:05:06,160
software

00:05:04,160 --> 00:05:08,320
coalescing around the idea of software

00:05:06,160 --> 00:05:10,320
freedom the past 20 years

00:05:08,320 --> 00:05:13,199
have seen the open source community

00:05:10,320 --> 00:05:15,120
thrive enjoying a wild success

00:05:13,199 --> 00:05:16,639
and permanently changing the technology

00:05:15,120 --> 00:05:18,560
landscape

00:05:16,639 --> 00:05:25,120
but the world has also changed in the

00:05:18,560 --> 00:05:26,880
past two decades

00:05:25,120 --> 00:05:28,160
around the world we're seeing technology

00:05:26,880 --> 00:05:30,400
being leveraged

00:05:28,160 --> 00:05:32,720
to commit human rights abuses on an

00:05:30,400 --> 00:05:34,800
alarming scale

00:05:32,720 --> 00:05:36,000
and the technology powering these human

00:05:34,800 --> 00:05:39,840
rights abuses

00:05:36,000 --> 00:05:39,840
includes free and open source software

00:05:40,240 --> 00:05:44,720
open source software today is playing a

00:05:42,800 --> 00:05:47,199
critical role in mass surveillance

00:05:44,720 --> 00:05:48,240
anti-immigrant violence protester

00:05:47,199 --> 00:05:50,400
suppression

00:05:48,240 --> 00:05:52,000
racially biased policing and the

00:05:50,400 --> 00:05:54,720
development and use of cruel and

00:05:52,000 --> 00:05:58,240
inhumane weapons

00:05:54,720 --> 00:06:00,639
and open source's complicity isn't a bug

00:05:58,240 --> 00:06:01,600
it's a feature this is actually by

00:06:00,639 --> 00:06:03,520
design

00:06:01,600 --> 00:06:04,639
the open source definition allows for

00:06:03,520 --> 00:06:07,840
use of software

00:06:04,639 --> 00:06:09,600
for any purpose including specifically

00:06:07,840 --> 00:06:11,680
for evil

00:06:09,600 --> 00:06:14,800
they say giving everyone freedom means

00:06:11,680 --> 00:06:17,280
giving evil people freedom too

00:06:14,800 --> 00:06:18,880
but under what other circumstances in

00:06:17,280 --> 00:06:22,080
our human societies

00:06:18,880 --> 00:06:23,280
do we grant complete freedom to evil

00:06:22,080 --> 00:06:26,639
people

00:06:23,280 --> 00:06:26,639
why is open source special

00:06:26,800 --> 00:06:30,080
there's increased discussion among open

00:06:28,720 --> 00:06:32,080
source developers

00:06:30,080 --> 00:06:33,360
about our ethical responsibilities as

00:06:32,080 --> 00:06:35,360
creators

00:06:33,360 --> 00:06:37,440
the debates are heated and the media is

00:06:35,360 --> 00:06:40,240
paying attention

00:06:37,440 --> 00:06:40,560
the fundamental question seems to be are

00:06:40,240 --> 00:06:43,199
we

00:06:40,560 --> 00:06:43,840
responsible for how the technologies we

00:06:43,199 --> 00:06:47,680
develop

00:06:43,840 --> 00:06:50,000
are used and a lot of us are beginning

00:06:47,680 --> 00:06:52,080
to accept that our work in open source

00:06:50,000 --> 00:06:53,199
might be contributing to harm and

00:06:52,080 --> 00:06:56,639
atrocities

00:06:53,199 --> 00:06:58,800
in the u.s and around the world

00:06:56,639 --> 00:07:00,560
in response to these questions we're

00:06:58,800 --> 00:07:02,160
seeing increased interest in ethical

00:07:00,560 --> 00:07:03,840
open source licenses

00:07:02,160 --> 00:07:07,360
including the hippocratic license which

00:07:03,840 --> 00:07:07,360
i created in 2019

00:07:07,599 --> 00:07:12,720
as developers we some we feel powerless

00:07:10,800 --> 00:07:14,800
and we want to find some way to do the

00:07:12,720 --> 00:07:16,639
right thing

00:07:14,800 --> 00:07:18,880
we're horrified by what's happening in

00:07:16,639 --> 00:07:19,520
the world and we're horrified at the

00:07:18,880 --> 00:07:23,520
thought

00:07:19,520 --> 00:07:25,280
that we may be contributing to it

00:07:23,520 --> 00:07:28,479
today we have much bigger ethical

00:07:25,280 --> 00:07:31,199
problems than proprietary software

00:07:28,479 --> 00:07:33,039
stallman wanted a printer driver we want

00:07:31,199 --> 00:07:34,880
to ensure that our work is not used for

00:07:33,039 --> 00:07:38,080
human rights abuses that's what's work

00:07:34,880 --> 00:07:38,080
that's what we're fighting for

00:07:38,800 --> 00:07:42,720
but the conversation about ethics and

00:07:40,720 --> 00:07:44,479
computer science is not new

00:07:42,720 --> 00:07:46,080
it's been happening in our field since

00:07:44,479 --> 00:07:48,560
there was even any such thing as

00:07:46,080 --> 00:07:50,240
software

00:07:48,560 --> 00:07:52,400
i want to introduce you to a man named

00:07:50,240 --> 00:07:54,160
edmund berkeley he was one of the most

00:07:52,400 --> 00:07:55,440
important pioneers of ethics and

00:07:54,160 --> 00:07:57,840
computer science

00:07:55,440 --> 00:07:59,599
in the 20th century yet almost no one

00:07:57,840 --> 00:08:01,280
knows who he is

00:07:59,599 --> 00:08:02,879
you got to start working on computers

00:08:01,280 --> 00:08:05,440
with the navy during world war

00:08:02,879 --> 00:08:06,319
ii and worked alongside admiral grace

00:08:05,440 --> 00:08:07,599
hopper

00:08:06,319 --> 00:08:09,680
he probably showed world's first

00:08:07,599 --> 00:08:11,440
computer magazine and was among the

00:08:09,680 --> 00:08:14,800
first people to propose the idea

00:08:11,440 --> 00:08:14,800
of a personal computer

00:08:14,879 --> 00:08:18,720
berkeley co-founded the association for

00:08:17,360 --> 00:08:21,840
computing machinery

00:08:18,720 --> 00:08:24,080
at columbia university in 1947

00:08:21,840 --> 00:08:25,440
and the organization's charter is to

00:08:24,080 --> 00:08:27,840
foster the open

00:08:25,440 --> 00:08:29,120
interchange of information and promote

00:08:27,840 --> 00:08:32,880
the highest

00:08:29,120 --> 00:08:34,719
professional and ethical standards

00:08:32,880 --> 00:08:36,320
berkeley settled on the committee on the

00:08:34,719 --> 00:08:37,360
social responsibility of computer

00:08:36,320 --> 00:08:39,200
scientists

00:08:37,360 --> 00:08:41,760
which published an historic and

00:08:39,200 --> 00:08:43,440
foundational report in 1958

00:08:41,760 --> 00:08:45,040
on the ethical obligations of

00:08:43,440 --> 00:08:46,959
technologists

00:08:45,040 --> 00:08:50,320
the findings of the report boil down

00:08:46,959 --> 00:08:53,200
into four simple statements

00:08:50,320 --> 00:08:56,560
first that we cannot rightly ignore our

00:08:53,200 --> 00:08:56,560
social responsibilities

00:08:56,720 --> 00:09:00,480
secondly that our social

00:08:58,399 --> 00:09:02,640
responsibilities can't be delegated to

00:09:00,480 --> 00:09:04,959
others

00:09:02,640 --> 00:09:05,680
third we cannot rightly neglect to think

00:09:04,959 --> 00:09:08,399
about how

00:09:05,680 --> 00:09:09,120
our special role can benefit or harm

00:09:08,399 --> 00:09:11,360
society

00:09:09,120 --> 00:09:13,040
in other words we must consider how our

00:09:11,360 --> 00:09:15,279
special capabilities

00:09:13,040 --> 00:09:16,560
can help to advance socially desirable

00:09:15,279 --> 00:09:20,240
applications

00:09:16,560 --> 00:09:22,880
and prevent undesirable outcomes

00:09:20,240 --> 00:09:25,519
and finally we cannot avoid deciding

00:09:22,880 --> 00:09:29,279
between conflicting responsibilities

00:09:25,519 --> 00:09:29,279
we must think how to choose

00:09:32,720 --> 00:09:36,000
the report went on to say that when one

00:09:35,040 --> 00:09:38,320
reflects upon the

00:09:36,000 --> 00:09:39,600
great forces that computer people are

00:09:38,320 --> 00:09:41,440
associated with

00:09:39,600 --> 00:09:43,680
it's no longer difficult to grasp or

00:09:41,440 --> 00:09:45,600
even to accept our heavier than average

00:09:43,680 --> 00:09:47,040
share of responsibility

00:09:45,600 --> 00:09:49,440
the committee believed that given the

00:09:47,040 --> 00:09:53,360
power and potential of computers

00:09:49,440 --> 00:09:55,680
ethical considerations were paramount

00:09:53,360 --> 00:09:58,160
the committee concluded the scientist

00:09:55,680 --> 00:10:00,399
credo knowledge for knowledge's sake

00:09:58,160 --> 00:10:02,079
comes into conflict with our ethical

00:10:00,399 --> 00:10:04,880
responsibilities

00:10:02,079 --> 00:10:06,800
given human society in our century and

00:10:04,880 --> 00:10:07,760
the ethical value system we're using in

00:10:06,800 --> 00:10:10,480
our century

00:10:07,760 --> 00:10:12,880
we can label some classes of work as

00:10:10,480 --> 00:10:15,600
obviously socially desirable

00:10:12,880 --> 00:10:16,839
and other classes of work as obviously

00:10:15,600 --> 00:10:19,200
socially

00:10:16,839 --> 00:10:20,720
undesirable even acknowledging that

00:10:19,200 --> 00:10:24,000
there's a large middle ground

00:10:20,720 --> 00:10:25,360
which cannot be clearly classified

00:10:24,000 --> 00:10:27,120
and it was berkeley who wrote the

00:10:25,360 --> 00:10:28,880
parable of the locksmith

00:10:27,120 --> 00:10:30,959
and remember it was the height of the

00:10:28,880 --> 00:10:34,079
cold war when he wrote it

00:10:30,959 --> 00:10:36,560
the parable ends with this

00:10:34,079 --> 00:10:37,600
a week later the retired locksmith saw a

00:10:36,560 --> 00:10:40,000
news headline

00:10:37,600 --> 00:10:41,839
about the theft of top top secret

00:10:40,000 --> 00:10:44,560
military schematics

00:10:41,839 --> 00:10:46,399
and soon after that the stranger himself

00:10:44,560 --> 00:10:49,200
appeared on the world stage

00:10:46,399 --> 00:10:51,040
declaring himself master of all nations

00:10:49,200 --> 00:10:55,279
backed by the overwhelming threat

00:10:51,040 --> 00:10:55,279
of a devastating soul and superweapon

00:10:56,560 --> 00:11:00,880
berkeley asked the question did the

00:10:58,720 --> 00:11:03,040
locksmith do what was right

00:11:00,880 --> 00:11:04,560
and he contended that the locksmith had

00:11:03,040 --> 00:11:06,560
a responsibility

00:11:04,560 --> 00:11:08,640
to determine whether the stranger was a

00:11:06,560 --> 00:11:09,360
criminal before agreeing to work with

00:11:08,640 --> 00:11:12,800
him so no

00:11:09,360 --> 00:11:14,640
the locksmith did not do what was right

00:11:12,800 --> 00:11:16,240
berkeley believed that the computer

00:11:14,640 --> 00:11:17,600
scientist does not have the right to

00:11:16,240 --> 00:11:19,519
shut their eyes

00:11:17,600 --> 00:11:21,440
in regard to their responsibilities any

00:11:19,519 --> 00:11:23,200
more than the locksmith has

00:11:21,440 --> 00:11:25,040
and he called on his colleagues to

00:11:23,200 --> 00:11:27,040
shoulder their proper social

00:11:25,040 --> 00:11:30,399
responsibilities

00:11:27,040 --> 00:11:30,399
and he was largely ignored

00:11:30,800 --> 00:11:37,519
fast forward about a decade it's 1972

00:11:34,399 --> 00:11:39,519
and the vietnam war is raging berkeley

00:11:37,519 --> 00:11:41,600
and his colleague franz alt had been

00:11:39,519 --> 00:11:43,680
invited to address the acm

00:11:41,600 --> 00:11:46,959
at a special dinner honoring them as

00:11:43,680 --> 00:11:49,680
founders on its 25th anniversary

00:11:46,959 --> 00:11:51,440
franzald's topic was reflections in

00:11:49,680 --> 00:11:52,959
edmond berkeley was to address the

00:11:51,440 --> 00:11:56,560
future looking topic

00:11:52,959 --> 00:11:57,680
of horizons while altz talk was

00:11:56,560 --> 00:11:59,360
celebratory

00:11:57,680 --> 00:12:01,440
providing a retrospective on the

00:11:59,360 --> 00:12:04,079
advances of computer engineering

00:12:01,440 --> 00:12:06,079
and computer science since world war ii

00:12:04,079 --> 00:12:08,800
berkeley's speech took on a distinctly

00:12:06,079 --> 00:12:08,800
different tone

00:12:08,880 --> 00:12:12,320
he told the audience that anyone who is

00:12:11,279 --> 00:12:15,200
working to further

00:12:12,320 --> 00:12:17,120
unethical uses of computers including

00:12:15,200 --> 00:12:19,839
uses of computers and developing

00:12:17,120 --> 00:12:20,959
weapons technology should quit their

00:12:19,839 --> 00:12:23,040
jobs

00:12:20,959 --> 00:12:24,079
he called out members of the audience by

00:12:23,040 --> 00:12:26,000
name

00:12:24,079 --> 00:12:27,600
many of his colleagues were so upset by

00:12:26,000 --> 00:12:28,639
his comments that they stood up and

00:12:27,600 --> 00:12:31,120
walked out

00:12:28,639 --> 00:12:32,880
in the middle of a speech and admiral

00:12:31,120 --> 00:12:35,680
grace hopper was among those who stood

00:12:32,880 --> 00:12:35,680
up and walked out

00:12:36,160 --> 00:12:40,560
berkeley conceived concluded his speech

00:12:38,320 --> 00:12:41,760
by saying that it was a gross neglect of

00:12:40,560 --> 00:12:43,360
responsibility

00:12:41,760 --> 00:12:45,040
that computer scientists were not

00:12:43,360 --> 00:12:49,600
considering their impact

00:12:45,040 --> 00:12:49,600
in terms of societal benefit or harm

00:12:50,399 --> 00:12:55,839
the 1933 census in nazi germany

00:12:53,600 --> 00:12:58,399
used technology and services provided by

00:12:55,839 --> 00:13:00,800
ibm through a german subsidiary

00:12:58,399 --> 00:13:03,279
and proved to be pivotal to the nazis in

00:13:00,800 --> 00:13:04,959
their efforts to identify and destroy

00:13:03,279 --> 00:13:06,399
the country's jewish and romani

00:13:04,959 --> 00:13:08,880
minorities

00:13:06,399 --> 00:13:10,240
ibm in short was complicit in the

00:13:08,880 --> 00:13:13,120
holocaust

00:13:10,240 --> 00:13:16,240
the nazis even shipped ibm's punch cards

00:13:13,120 --> 00:13:18,959
on the trains to concentration camps

00:13:16,240 --> 00:13:20,320
how would you feel if your work had

00:13:18,959 --> 00:13:23,440
contributed to ibm

00:13:20,320 --> 00:13:23,440
census technology

00:13:27,839 --> 00:13:31,040
other scientists faced similar ethical

00:13:30,160 --> 00:13:33,440
dilemmas

00:13:31,040 --> 00:13:35,600
world war one saw the first large-scale

00:13:33,440 --> 00:13:38,240
deployment of chemical weapons

00:13:35,600 --> 00:13:39,760
and the horrors of death by poison gas

00:13:38,240 --> 00:13:41,600
had repercussions throughout the

00:13:39,760 --> 00:13:45,360
chemical production world

00:13:41,600 --> 00:13:47,279
between the 1918 armistice of 1933

00:13:45,360 --> 00:13:48,880
international conferences were held to

00:13:47,279 --> 00:13:51,839
try and limit or abolish

00:13:48,880 --> 00:13:52,800
chemical weapons and to this day in the

00:13:51,839 --> 00:13:55,120
u.s

00:13:52,800 --> 00:13:56,000
no chemical manufacturer produces the

00:13:55,120 --> 00:13:57,860
serum

00:13:56,000 --> 00:14:00,480
used for death by lethal injection

00:13:57,860 --> 00:14:02,160
[Music]

00:14:00,480 --> 00:14:04,000
and after seeing the inhumane

00:14:02,160 --> 00:14:04,800
devastation of the atomic bomb at the

00:14:04,000 --> 00:14:07,680
end of world war

00:14:04,800 --> 00:14:08,240
ii scientists actively sought to limit

00:14:07,680 --> 00:14:10,079
or

00:14:08,240 --> 00:14:11,680
eliminate the bomb threat to human

00:14:10,079 --> 00:14:13,600
civilization

00:14:11,680 --> 00:14:14,800
the bulletin of the atomic scientists

00:14:13,600 --> 00:14:16,800
became the voice

00:14:14,800 --> 00:14:18,079
for the ethical responsibilities of

00:14:16,800 --> 00:14:20,320
physicists

00:14:18,079 --> 00:14:21,920
and the doomsday clock was launched and

00:14:20,320 --> 00:14:24,720
continues to this day

00:14:21,920 --> 00:14:27,120
as a reminder of the danger of doing

00:14:24,720 --> 00:14:27,120
nothing

00:14:27,440 --> 00:14:30,720
but how did the computer science

00:14:29,120 --> 00:14:31,920
community deal with its ethical

00:14:30,720 --> 00:14:34,000
conflicts

00:14:31,920 --> 00:14:35,680
and the realization that they might be

00:14:34,000 --> 00:14:38,720
complicit in genocide

00:14:35,680 --> 00:14:42,000
in other atrocities

00:14:38,720 --> 00:14:42,000
they got up and left the room

00:14:42,399 --> 00:14:46,959
and that's shirking responsibility is

00:14:44,959 --> 00:14:48,240
pervasive in the open source world today

00:14:46,959 --> 00:14:50,720
too

00:14:48,240 --> 00:14:52,240
technology companies routinely rely on

00:14:50,720 --> 00:14:55,839
open source software

00:14:52,240 --> 00:14:57,440
to provide services to ice

00:14:55,839 --> 00:14:59,360
how would we feel about the complicity

00:14:57,440 --> 00:15:01,440
of ibm and the holocaust

00:14:59,360 --> 00:15:04,079
if their plunge card system had been

00:15:01,440 --> 00:15:05,920
released under the gpl

00:15:04,079 --> 00:15:08,959
because that's exactly the situation

00:15:05,920 --> 00:15:08,959
we're facing today

00:15:11,279 --> 00:15:15,279
in 1998 when the open source definition

00:15:14,160 --> 00:15:17,440
was penned

00:15:15,279 --> 00:15:19,040
the greatest evil conceivable by

00:15:17,440 --> 00:15:23,040
computer scientists

00:15:19,040 --> 00:15:25,120
was the market domination of microsoft

00:15:23,040 --> 00:15:26,800
the founding thinkers responsible for

00:15:25,120 --> 00:15:28,480
free and open software

00:15:26,800 --> 00:15:30,480
clearly understood the impact of

00:15:28,480 --> 00:15:32,880
technology on society

00:15:30,480 --> 00:15:35,120
but rather than using an ethical framing

00:15:32,880 --> 00:15:38,959
they chose to focus on technology

00:15:35,120 --> 00:15:38,959
in intellectual property terms

00:15:39,199 --> 00:15:43,440
in 2021 we face threats much greater

00:15:41,920 --> 00:15:45,120
than microsoft

00:15:43,440 --> 00:15:46,560
we're in an age where governments are

00:15:45,120 --> 00:15:47,920
carrying out programs of mass

00:15:46,560 --> 00:15:50,079
surveillance

00:15:47,920 --> 00:15:52,639
using facial recognition to interfere

00:15:50,079 --> 00:15:54,399
with legitimate political protests

00:15:52,639 --> 00:15:57,120
and using technology to carry out

00:15:54,399 --> 00:15:59,440
state-sanctioned genocide and violence

00:15:57,120 --> 00:16:03,519
and open source software is being used

00:15:59,440 --> 00:16:05,759
to power these human rights violations

00:16:03,519 --> 00:16:08,320
in the u.s ice the immigration and

00:16:05,759 --> 00:16:10,160
customs enforcement agency has been

00:16:08,320 --> 00:16:11,120
separating children from their parents

00:16:10,160 --> 00:16:12,880
at the border

00:16:11,120 --> 00:16:14,639
and putting immigrants and asylum

00:16:12,880 --> 00:16:18,079
seekers in cages

00:16:14,639 --> 00:16:19,040
without reliable legal assistance or due

00:16:18,079 --> 00:16:21,440
process

00:16:19,040 --> 00:16:22,079
let alone medical care and there are an

00:16:21,440 --> 00:16:25,199
estimated

00:16:22,079 --> 00:16:26,399
40 000 people currently in ice custody

00:16:25,199 --> 00:16:29,040
and there have been hundreds of

00:16:26,399 --> 00:16:30,720
documented deaths most of them due to

00:16:29,040 --> 00:16:33,199
gross neglect

00:16:30,720 --> 00:16:35,440
and u.s tech companies are collecting

00:16:33,199 --> 00:16:38,720
billions of dollars in contracts

00:16:35,440 --> 00:16:40,399
to support isis programs of terror

00:16:38,720 --> 00:16:42,079
are we also going to get up and leave

00:16:40,399 --> 00:16:45,120
the room when we're faced

00:16:42,079 --> 00:16:47,600
with our own role in human rights abuses

00:16:45,120 --> 00:16:47,600
like these

00:16:48,320 --> 00:16:53,120
so what does this have to do with open

00:16:49,920 --> 00:16:55,199
source let's take a well-known example

00:16:53,120 --> 00:16:57,759
palantir technology is a software

00:16:55,199 --> 00:16:58,880
company co-founded by top trump advisor

00:16:57,759 --> 00:17:00,959
peter thiel

00:16:58,880 --> 00:17:03,519
collects millions of dollars tens of

00:17:00,959 --> 00:17:07,600
millions of dollars from ice every year

00:17:03,519 --> 00:17:09,280
at present palantir has 195 repositories

00:17:07,600 --> 00:17:11,520
hosted on github

00:17:09,280 --> 00:17:13,679
which in turn rely on thousands of open

00:17:11,520 --> 00:17:16,559
source dependencies

00:17:13,679 --> 00:17:19,520
every dependency in use by palantir

00:17:16,559 --> 00:17:21,760
contributes to human rights violations

00:17:19,520 --> 00:17:23,079
i created a an application called

00:17:21,760 --> 00:17:25,919
icebreaker

00:17:23,079 --> 00:17:28,240
icebreaker.dev that tracks all of the

00:17:25,919 --> 00:17:33,840
open source dependencies that volunteer

00:17:28,240 --> 00:17:33,840
is using

00:17:33,919 --> 00:17:38,480
thomas kuhn argues in his seminal book

00:17:36,559 --> 00:17:39,919
the structure of scientific revelation

00:17:38,480 --> 00:17:42,320
revolutions

00:17:39,919 --> 00:17:44,320
that science has always practiced within

00:17:42,320 --> 00:17:46,320
political contexts

00:17:44,320 --> 00:17:49,039
scientists do not operate with complete

00:17:46,320 --> 00:17:52,559
freedom they operate within community

00:17:49,039 --> 00:17:52,559
and societal constraints

00:17:56,080 --> 00:18:00,000
kuhn wrote that revolutions emerge when

00:17:58,559 --> 00:18:01,919
there's a conflict

00:18:00,000 --> 00:18:03,360
between an established paradigm and a

00:18:01,919 --> 00:18:04,720
new paradigm

00:18:03,360 --> 00:18:06,720
and we're seeing this play out in a

00:18:04,720 --> 00:18:08,960
debate between open source

00:18:06,720 --> 00:18:10,480
traditionalists and ethical source

00:18:08,960 --> 00:18:12,480
advocates

00:18:10,480 --> 00:18:13,520
so what can happen as a consequence of

00:18:12,480 --> 00:18:15,200
this debate

00:18:13,520 --> 00:18:16,640
what are the possible outcomes of the

00:18:15,200 --> 00:18:18,559
conflict

00:18:16,640 --> 00:18:20,960
it really depends on how the open source

00:18:18,559 --> 00:18:22,799
establishment responds

00:18:20,960 --> 00:18:24,559
the first possible response is

00:18:22,799 --> 00:18:26,559
procrastination

00:18:24,559 --> 00:18:28,000
in the face of an ethical crisis

00:18:26,559 --> 00:18:31,120
procrastination is not an

00:18:28,000 --> 00:18:32,880
option the need is too urgent

00:18:31,120 --> 00:18:34,320
the second possible response is

00:18:32,880 --> 00:18:36,320
assimilation

00:18:34,320 --> 00:18:38,000
this happens when the establishment

00:18:36,320 --> 00:18:40,080
accommodates a new idea

00:18:38,000 --> 00:18:42,880
and adjusts to it in a conflict-free

00:18:40,080 --> 00:18:44,640
manner and this is my ideal outcome

00:18:42,880 --> 00:18:46,000
i want to give the open source community

00:18:44,640 --> 00:18:48,960
the opportunity

00:18:46,000 --> 00:18:50,720
to accommodate ethical considerations by

00:18:48,960 --> 00:18:51,840
challenging the narrow perspectives of

00:18:50,720 --> 00:18:53,600
freedom zero

00:18:51,840 --> 00:18:57,360
and the open source definition and i

00:18:53,600 --> 00:18:59,919
realize that's heretical

00:18:57,360 --> 00:19:01,840
the most extreme result of the conflict

00:18:59,919 --> 00:19:02,880
between the establishment and a new

00:19:01,840 --> 00:19:05,840
paradigm

00:19:02,880 --> 00:19:05,840
is revolution

00:19:08,160 --> 00:19:11,760
kuhn describes revolutionaries as being

00:19:10,720 --> 00:19:13,840
motivated

00:19:11,760 --> 00:19:16,240
to solve a different problem than the

00:19:13,840 --> 00:19:18,480
establishment has prioritized

00:19:16,240 --> 00:19:19,360
the current debate is whether solving

00:19:18,480 --> 00:19:22,080
the problem

00:19:19,360 --> 00:19:23,520
of software freedom is more significant

00:19:22,080 --> 00:19:26,559
than solving the problem

00:19:23,520 --> 00:19:26,559
of human freedom

00:19:27,200 --> 00:19:33,520
in 1999 u.n secretary general kofi annan

00:19:31,440 --> 00:19:35,440
announced the united nations global

00:19:33,520 --> 00:19:37,120
compact

00:19:35,440 --> 00:19:39,120
it's an agreement to encourage

00:19:37,120 --> 00:19:41,600
businesses to adopt sustainable and

00:19:39,120 --> 00:19:43,360
socially responsible policies

00:19:41,600 --> 00:19:45,440
it's the world's largest corporate

00:19:43,360 --> 00:19:48,240
social responsibility initiative

00:19:45,440 --> 00:19:50,840
with tens of thousands of participants

00:19:48,240 --> 00:19:52,960
and stakeholders in hundreds of

00:19:50,840 --> 00:19:54,799
countries

00:19:52,960 --> 00:19:56,720
the very first section of the compact

00:19:54,799 --> 00:19:58,640
deals with human rights and it states

00:19:56,720 --> 00:20:00,320
that businesses should support and

00:19:58,640 --> 00:20:03,520
respect the protection of

00:20:00,320 --> 00:20:05,919
internationally proclaimed human rights

00:20:03,520 --> 00:20:07,200
and that businesses must make sure that

00:20:05,919 --> 00:20:10,080
they are not complicit

00:20:07,200 --> 00:20:10,480
in human rights abuses complicity in

00:20:10,080 --> 00:20:13,280
this

00:20:10,480 --> 00:20:14,320
in the situ in this uh context has two

00:20:13,280 --> 00:20:16,799
different modes

00:20:14,320 --> 00:20:18,880
the first is directly providing goods or

00:20:16,799 --> 00:20:21,280
services that a company knows

00:20:18,880 --> 00:20:23,360
we use to carry out human rights abuses

00:20:21,280 --> 00:20:25,919
like pound chair

00:20:23,360 --> 00:20:27,440
the second is when a company benefits

00:20:25,919 --> 00:20:29,679
from human rights abuses

00:20:27,440 --> 00:20:30,960
even if it did not possibly assist or

00:20:29,679 --> 00:20:35,520
cause them

00:20:30,960 --> 00:20:37,200
and this is akin to the github situation

00:20:35,520 --> 00:20:38,960
many large tech companies have been

00:20:37,200 --> 00:20:41,039
happily profiting from human rights

00:20:38,960 --> 00:20:42,880
abuses for years

00:20:41,039 --> 00:20:45,200
and i've been calling for those who have

00:20:42,880 --> 00:20:48,080
the safety and privilege to do so

00:20:45,200 --> 00:20:50,159
to accept their ethical responsibilities

00:20:48,080 --> 00:20:51,440
and either organize or change at these

00:20:50,159 --> 00:20:54,559
companies

00:20:51,440 --> 00:20:57,600
or quit their jobs this includes tech

00:20:54,559 --> 00:20:57,600
workers at amazon

00:20:57,919 --> 00:21:00,799
microsoft

00:21:01,280 --> 00:21:03,840
github

00:21:04,720 --> 00:21:07,600
salesforce

00:21:08,080 --> 00:21:10,640
cisco

00:21:11,120 --> 00:21:17,840
and deloitte and many

00:21:14,400 --> 00:21:17,840
many others

00:21:18,240 --> 00:21:24,480
asylum seekers suffer unimaginable

00:21:21,840 --> 00:21:27,440
violence and torture violations of their

00:21:24,480 --> 00:21:29,600
dignity safety and basic human rights

00:21:27,440 --> 00:21:31,360
in government concentration camps across

00:21:29,600 --> 00:21:35,200
the us

00:21:31,360 --> 00:21:37,120
amazon microsoft github salesforce cisco

00:21:35,200 --> 00:21:39,440
and dozens of other companies all

00:21:37,120 --> 00:21:42,480
leverage open source technologies

00:21:39,440 --> 00:21:43,919
to profit from human rights abuses and

00:21:42,480 --> 00:21:44,960
according to the united nations

00:21:43,919 --> 00:21:48,960
definition

00:21:44,960 --> 00:21:48,960
these companies are all complicit

00:21:52,559 --> 00:21:56,640
i believe that as technologists we have

00:21:54,880 --> 00:21:58,480
a moral imperative

00:21:56,640 --> 00:22:01,039
to prevent our work from being used to

00:21:58,480 --> 00:22:01,039
harm others

00:22:04,320 --> 00:22:09,039
responsibility is about impact not

00:22:07,039 --> 00:22:10,960
intent

00:22:09,039 --> 00:22:12,080
freedom for freedom's sake is

00:22:10,960 --> 00:22:16,240
incompatible

00:22:12,080 --> 00:22:16,240
with our responsibility to society

00:22:17,600 --> 00:22:22,080
and as karen sandler from the software

00:22:19,840 --> 00:22:24,080
freedom conservancy once said to me

00:22:22,080 --> 00:22:27,360
software freedom must always be in

00:22:24,080 --> 00:22:29,039
service of human freedom

00:22:27,360 --> 00:22:31,440
and the point is the way that people

00:22:29,039 --> 00:22:33,039
just like you react to the question of

00:22:31,440 --> 00:22:34,559
ethics and open source

00:22:33,039 --> 00:22:37,360
will determine the future of our

00:22:34,559 --> 00:22:41,120
community you have the power

00:22:37,360 --> 00:22:43,200
to influence what happens next

00:22:41,120 --> 00:22:45,039
if you're in the procrastination camp

00:22:43,200 --> 00:22:46,799
and think you can simply ignore

00:22:45,039 --> 00:22:48,480
the debate you're in for a big

00:22:46,799 --> 00:22:49,919
disappointment these issues are not

00:22:48,480 --> 00:22:53,039
going away

00:22:49,919 --> 00:22:56,400
and a growing body of developers

00:22:53,039 --> 00:22:58,720
is speaking out against it

00:22:56,400 --> 00:23:00,960
if you want peaceful revolution

00:22:58,720 --> 00:23:01,679
resolution you're in the assimilation

00:23:00,960 --> 00:23:03,840
camp

00:23:01,679 --> 00:23:05,600
so you can work with traditionalist

00:23:03,840 --> 00:23:08,320
foster organizations

00:23:05,600 --> 00:23:10,720
to focus on some licensure and more on

00:23:08,320 --> 00:23:13,200
promoting ethical standards

00:23:10,720 --> 00:23:16,400
centering justice and equity in the

00:23:13,200 --> 00:23:16,400
practice of open source

00:23:16,640 --> 00:23:20,480
but if the community refuses to

00:23:18,880 --> 00:23:22,240
acknowledge let alone work to address

00:23:20,480 --> 00:23:22,880
the ethical shortcomings of free and

00:23:22,240 --> 00:23:25,679
open

00:23:22,880 --> 00:23:27,200
as it stands today then the only option

00:23:25,679 --> 00:23:30,080
you leave us with

00:23:27,200 --> 00:23:30,080
is revolution

00:23:30,640 --> 00:23:35,360
a proprietary printer driver sparked a

00:23:33,520 --> 00:23:36,480
massive paradigm shift in software

00:23:35,360 --> 00:23:38,159
development

00:23:36,480 --> 00:23:40,320
stallman saw what is he what he

00:23:38,159 --> 00:23:42,240
perceived as an ethical problem

00:23:40,320 --> 00:23:43,919
and created a brilliant way of solving

00:23:42,240 --> 00:23:47,440
it with licensing and that's an

00:23:43,919 --> 00:23:49,279
epic hack today we have much bigger

00:23:47,440 --> 00:23:50,240
ethical problems than proprietary

00:23:49,279 --> 00:23:52,080
software

00:23:50,240 --> 00:23:53,360
and it's up to us to come up with

00:23:52,080 --> 00:23:56,240
another epic hack

00:23:53,360 --> 00:23:57,440
to solve that too stallman wanted a

00:23:56,240 --> 00:23:58,960
printer driver

00:23:57,440 --> 00:24:00,720
we want to prevent our work from being

00:23:58,960 --> 00:24:03,600
used for human rights abuses and that's

00:24:00,720 --> 00:24:06,640
what the revolution is about

00:24:03,600 --> 00:24:07,279
we're all inspired by the promises of

00:24:06,640 --> 00:24:10,720
free

00:24:07,279 --> 00:24:11,919
and open but we also need to exp accept

00:24:10,720 --> 00:24:15,200
responsibility

00:24:11,919 --> 00:24:18,159
for impact and outcomes

00:24:15,200 --> 00:24:19,919
because in the end we're all locksmiths

00:24:18,159 --> 00:24:23,360
and the world is full

00:24:19,919 --> 00:24:23,360
of mysterious strangers

00:24:23,520 --> 00:24:27,200
if you want to join us in working

00:24:25,039 --> 00:24:30,000
towards solutions to the ethical

00:24:27,200 --> 00:24:32,400
challenges we face today in open source

00:24:30,000 --> 00:24:33,520
go to dot ethicalsource.gov read through

00:24:32,400 --> 00:24:36,000
our resources

00:24:33,520 --> 00:24:38,000
watch our talks and continue and

00:24:36,000 --> 00:24:39,360
consider joining us to collaborate on

00:24:38,000 --> 00:24:44,000
ways to resolve

00:24:39,360 --> 00:24:47,840
the crisis of conscious and open source

00:24:44,000 --> 00:24:47,840
thank you for listening

00:24:48,000 --> 00:24:52,240
uh thank you carline that was a really

00:24:49,679 --> 00:24:52,640
interesting talk um there was a lot to

00:24:52,240 --> 00:24:55,520
think

00:24:52,640 --> 00:24:56,080
about there um we are now we have a few

00:24:55,520 --> 00:24:57,840
minutes for

00:24:56,080 --> 00:25:00,000
questions so if people want to ask

00:24:57,840 --> 00:25:02,080
questions please uh write them in the

00:25:00,000 --> 00:25:05,120
chat on the questions bar

00:25:02,080 --> 00:25:08,480
um while we wait for those um

00:25:05,120 --> 00:25:09,919
i have a question um i thought it was

00:25:08,480 --> 00:25:13,520
really interesting that you brought up

00:25:09,919 --> 00:25:17,200
the um point about thomas kuhn

00:25:13,520 --> 00:25:18,159
um and how various kinds of scientific

00:25:17,200 --> 00:25:20,320
research don't

00:25:18,159 --> 00:25:22,720
take place in a vacuum they take place

00:25:20,320 --> 00:25:25,200
in a wider society so they're not

00:25:22,720 --> 00:25:26,480
free from the influences of wider

00:25:25,200 --> 00:25:28,340
society

00:25:26,480 --> 00:25:29,919
i wondered if you thought that um

00:25:28,340 --> 00:25:32,000
[Music]

00:25:29,919 --> 00:25:33,919
changes um the changes that you were

00:25:32,000 --> 00:25:36,159
talking about

00:25:33,919 --> 00:25:37,520
are they more likely to come from inside

00:25:36,159 --> 00:25:40,080
the community or is it

00:25:37,520 --> 00:25:41,200
pressure from outside the community uh

00:25:40,080 --> 00:25:42,720
the wider public

00:25:41,200 --> 00:25:44,559
that you think is going to lead to more

00:25:42,720 --> 00:25:47,919
changes

00:25:44,559 --> 00:25:48,159
um i think the wider public doesn't have

00:25:47,919 --> 00:25:52,559
an

00:25:48,159 --> 00:25:55,840
understanding of the technical linkages

00:25:52,559 --> 00:25:58,400
between work that an individual or a

00:25:55,840 --> 00:26:00,320
small group of contributors to

00:25:58,400 --> 00:26:03,039
and how that gets magnified by an

00:26:00,320 --> 00:26:05,279
organization like amazon or microsoft

00:26:03,039 --> 00:26:07,200
so i don't think i don't think we can

00:26:05,279 --> 00:26:10,240
rely on a public outcry

00:26:07,200 --> 00:26:11,919
to encourage engineers to accept social

00:26:10,240 --> 00:26:12,559
responsibilities i really think it has

00:26:11,919 --> 00:26:14,880
to come from

00:26:12,559 --> 00:26:17,039
inside and we're seeing it come from

00:26:14,880 --> 00:26:19,679
inside the ethical source working group

00:26:17,039 --> 00:26:23,200
is over 200 volunteers now

00:26:19,679 --> 00:26:26,080
as ethicists philosophers technologists

00:26:23,200 --> 00:26:27,039
open source maintainers human rights

00:26:26,080 --> 00:26:30,320
workers

00:26:27,039 --> 00:26:32,960
academics lawyers there's a

00:26:30,320 --> 00:26:34,880
large and growing community of people

00:26:32,960 --> 00:26:36,000
who do take these problems very

00:26:34,880 --> 00:26:38,400
seriously

00:26:36,000 --> 00:26:39,039
and are working in a very creative

00:26:38,400 --> 00:26:40,880
manner

00:26:39,039 --> 00:26:43,840
to come up with different kinds of ways

00:26:40,880 --> 00:26:46,400
of solving the problem

00:26:43,840 --> 00:26:48,559
okay great um we have a question from

00:26:46,400 --> 00:26:50,559
the audience and i'll just read this

00:26:48,559 --> 00:26:52,000
so a few years ago at the chaos

00:26:50,559 --> 00:26:54,240
communication congress

00:26:52,000 --> 00:26:55,840
there was a call to build software in a

00:26:54,240 --> 00:26:58,400
surveillance resistant

00:26:55,840 --> 00:27:00,159
or resilient way do you think there is a

00:26:58,400 --> 00:27:03,039
way to build ethics

00:27:00,159 --> 00:27:04,080
not only into licenses but other things

00:27:03,039 --> 00:27:07,200
too

00:27:04,080 --> 00:27:08,880
i actually uh think licensing i realize

00:27:07,200 --> 00:27:09,520
the ethical source movement is best

00:27:08,880 --> 00:27:10,960
known

00:27:09,520 --> 00:27:13,919
for having produced a hypocritical

00:27:10,960 --> 00:27:14,960
license but our main focus is not on

00:27:13,919 --> 00:27:17,120
licensure

00:27:14,960 --> 00:27:18,960
and we think in fact that the open

00:27:17,120 --> 00:27:20,240
source traditionalists focus on

00:27:18,960 --> 00:27:24,880
licensure

00:27:20,240 --> 00:27:26,720
is a shortcoming licensure is one tool

00:27:24,880 --> 00:27:28,000
and the working group is developing

00:27:26,720 --> 00:27:31,200
multiple tools

00:27:28,000 --> 00:27:31,200
to address this problem

00:27:32,720 --> 00:27:36,480
including uh you know you can really

00:27:34,559 --> 00:27:39,200
think of it as ethics starting at home

00:27:36,480 --> 00:27:40,240
in a lot of ways the way that we manage

00:27:39,200 --> 00:27:42,880
and govern

00:27:40,240 --> 00:27:44,880
our open source communities our codes of

00:27:42,880 --> 00:27:46,880
conduct and how we enforce them

00:27:44,880 --> 00:27:49,200
our governance and how transparent that

00:27:46,880 --> 00:27:52,480
is all of those are really critical to

00:27:49,200 --> 00:27:55,039
producing ethical software

00:27:52,480 --> 00:27:55,679
and really it's about taking the time to

00:27:55,039 --> 00:27:57,760
think about

00:27:55,679 --> 00:28:00,159
outcomes to think about how your

00:27:57,760 --> 00:28:03,279
software could be abused

00:28:00,159 --> 00:28:06,000
if you think about it at the beginning

00:28:03,279 --> 00:28:06,880
it's a lot easier to to your example to

00:28:06,000 --> 00:28:10,240
design

00:28:06,880 --> 00:28:12,159
for safety to design so that the tools

00:28:10,240 --> 00:28:14,320
can't be easily abused

00:28:12,159 --> 00:28:16,240
and we can't stop technology from being

00:28:14,320 --> 00:28:18,480
used in an abusive way

00:28:16,240 --> 00:28:20,399
but we can put up boundaries we can

00:28:18,480 --> 00:28:21,520
create incentives for doing things the

00:28:20,399 --> 00:28:31,840
right way

00:28:21,520 --> 00:28:31,840
we can do a lot better

00:28:43,600 --> 00:28:45,679

YouTube URL: https://www.youtube.com/watch?v=_-WP9g4jCU0


