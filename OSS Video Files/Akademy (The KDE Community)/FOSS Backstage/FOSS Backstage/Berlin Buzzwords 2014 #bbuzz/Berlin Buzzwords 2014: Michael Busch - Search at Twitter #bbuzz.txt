Title: Berlin Buzzwords 2014: Michael Busch - Search at Twitter #bbuzz
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	Twitter's search engine serves billions of queries per day from different Lucene indexes, while appending more than hundreds of millions of tweets per day in real time. This session will give an overview of Twitter's search architecture and the recent changes and improvements that have been made. It will focus on the usage of Lucene and the modifications that have been made to it to support Twitter's unique performance requirements.

Read more:
https://2014.berlinbuzzwords.de/session/search-twitter

About Michael Busch:
https://2014.berlinbuzzwords.de/user/293/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              I guess it's emser hi my name is michael                               bush I work at Twitter in San Francisco                               tech lead off the search team there yeah                               today I would like to talk about our                               search engine the talk has kind of four                               sections i'm going to introduce a little                               bit with numbers that we have to deal                               with and then i'm going to cover the                               search architecture from a high level                                and then i want to dive with into the                                inverted index and some of the like                                ranking tricks we do for relevant search                                all right so yeah twitter has now more                                than                                                                  users we have about                                                   every day we have about more than                                    billion tweets since two thousand two                                thousand six now and yeah sometimes                                probably soon and the world cup starting                                we see new TPS tweets per second records                                I think the current one is thirty-three                                thousand tweets per second um and on the                                search side we have no more than two                                billion search queries per day that has                                increased significantly in the last like                                three or four years since I've worked                                there I want to come a little bit the                                history of Twitter search so I'm into it                                before                                                               any search to acquire the small company                                called semis the small start up with                                like a few people who had built a search                                engine on top of my sequel actually for                                real-time search they joined Twitter and                                first the product look like this before                                it was a separate website basically in                                                                                                 already growing so much that kind of my                                secret solution was kind of falling                                apart I couldn't deal with a lot anymore                                and so we needed to change the                                technology and we decided to use a                                petrol scene um but a heavily modified                                version which I'm going to talk about                                soon then in                                                      change that                                doesn't look like this anymore look back                                then like that where we not only could                                search for recent tweets but also                                relevant tweets so if we introduce                                relevant search using machine later be                                interested in two thousand twelve and                                thirteen we added stuff like spelling                                correction and suggested searches we had                                a type ahead and he actually very                                recently if you can read that in the red                                circle it's very all tweet so previously                                before two thousand i believe                                       only had like the last ten days of tweet                                searchable memory and since last year we                                keep adding more and more tweets so we                                can almost search all tweets all three                                hundred billion tweets in history now                                and you also added more we what we call                                universal search model result types                                basically so now if you search on                                Twitter you get top user accounts you                                get tweets you get photos vines videos                                that kind of stuff um this is the search                                left bar on the search web page you can                                see that we have you have different                                rankings like you can follow for example                                for photos video search new search I'm                                going to cover a little bit why that's                                different compared to the normal search                                ranking we have different search indexes                                for for exam for your social graph so                                that we can see who you follow on                                Twitter and that so that we can only                                return tweets from your followers or                                people you follow I should say and you                                have different systems different search                                systems actually for tweets and users                                for example and here's kind of a summary                                um basically what i just said one thing                                i wanted to point out which is which you                                can't see in the product but it's                                actually very significant and                                interesting change to the racine                                community is that we introduced a new                                posting this format i'm going to touch                                it later that it's very that almost                                fully supports a leucine spec now                                previously it was opting highly                                optimized for tweets so mostly usable                                for short documents but we change that                                such that it supports almost entirely                                seen spec and that gets us closer to                                committing it to an                                 to the open source project all right                                 let's talk about our search architecture                                 I think the screen is a little smaller                                 than mine but I think we can read                                 everything okay so under on the upper                                 hand we see we have a real time stream                                 of tweets raw treats and Jason coming in                                 and we have a component called the                                 analyzer is called and loosing the same                                 thing and the petitioner where does it                                 analyzes and token izes the the tweets                                 and prepares them for indexing so it                                 creates token streams in racine it does                                 terminal normalization lower casing that                                 kind of stuff it also geocoding it                                 expands URL if they are shortened and                                 also does hash petitioning i'm going to                                 show later husband indexes petitioned                                 the output of that analyzes say as i                                 said NY streets that are ready for                                 indexing with racine they are stored                                 actually in the thrift do you guys know                                 what do you guys are familiar with rift                                 it's a serialization data serialization                                 format that Facebook invented and is                                 also open source now yeah the partition                                 analyzer emit street and civilized                                 format and the real-time index our name                                 is early bird code names early bird all                                 tweet systems have have either burden                                 the name or unnamed after bird so how                                 are you seen the nexus called early bird                                 it's a modified modified racine index                                 optimized for real-time search the key                                 differences if you are familiar with                                 leucine leucine sneer real-time feature                                 is that every time you want to be able                                 to search the latest documents that you                                 added to the index writer you kind of                                 have to fly you have to call flash or                                 commit so that they actually commits all                                 the data to somewhere else in memory or                                 two discs so that you can search it so                                 for real time search for very high GPS                                 in our case and QPS and if it won't have                                 a very short latency between tweeting                                 and being able to search                                 tweet that approach doesn't work so well                                 because every time we want to be able to                                 search the late the streets we would                                 have to always call commit and that                                 would trigger a flash to disk or all the                                 memory so we changed that that we                                 connected to the same data structure                                 append and also search in the log                                 freeway and in my last talk at this                                 conference I explained in detail how a                                 memory model and how our concurrency                                 model works oh and I can't do it today                                 for time reasons but if you're                                 interested then again go check it out i                                 believe it's online i should say the                                 real time index is fully memory it                                 covers the last ten days and it's very                                 fast and uses this technology so the                                 cluster layer oh it looks like this so                                 we basically have multiple early bird                                 indexes that I replic replicated n times                                 they are hash partitioned with a fixed                                 number i believe it's like                                       something so we have                                                   brief or maybe                                                         we just bought the dark ID the treaty ID                                 basically by n to assign it to a hash                                 partition and then we have already                                 called time slices those are the same                                 access leucine segments so a segment or                                 time slice is basically its own index                                 that covers a certain time range and on                                 basically on an early bird machine the                                 way it looks I guess that we have                                 complete time slices that are kind of                                 full and you can't depend to them                                 anymore and the green one on top is the                                 writable time sighs and that change i                                 mentioned where you can actually append                                 to the time slice or to the segment and                                 search at the same time and you never                                 have to commit to disk or two to memory                                 only when the second is full and there's                                 some we have some restrictions of how                                 large segments can get then we kind of                                 start a new segment a new on the green a                                 new new rideable m time slice and we                                 actually delete the segment the oldest                                 segment on each machine just gives us                                 rolling window of tweets so that we                                 always have a constant amount of tweets                                 in this class                                           yeah so that's the real time portion of                                 the system the upper part we have also a                                 cutoff line portion which analyzes the                                 tweets sometimes when we have to rebuild                                 it also in a daily job from our archive                                 on on HDFS it also processes the retreat                                 similar to the other and analyze own                                 petition as I mentioned and also                                 aggregates engagement signals and that                                 kind of stuff and also does is it                                 doesn't index deleted tweets of course                                 anymore the drop is a few days behind                                 like three or four days behind because                                 we don't really have to put the most                                 recent days in that archive index                                 because it's already searchable in the                                 in memory index I mean in real time                                 index so I'm therefore after three or                                 four days usually people don't delete                                 like tweets anymore from like a week ago                                 so that's why we almost have no didi                                 treats on the cynics and that's why we                                 don't have to worry about um garbage                                 collection on the canister I mean                                 deleting documents the archive index is                                 a is a standard routine                                                 now want to upgrade to                                               reverse time sorted also because even if                                 we do relevant search and when they                                 return all the treats we stole the                                 ranking is still heavily biased by time                                 so we still try to return recent reads                                 fairly recent tweets um that's why we                                 saw at reverse by reverse time and the                                 cluster layout itself is very similar to                                 the memory run so also fixed number of                                 hash partitions I think the number is                                 different and also the number of tweets                                 per machine is different because we                                 stole them actually in s on SSD and not                                 in memory and currently we actually have                                 two of these archive indexes one is also                                 a memory it has very small like one                                 percent of something of all tweets which                                 are which received the highest                                 engagement I some of retweets or                                 favorites and they are in memory very                                 fast and then we have on SSD another                                 index that use as a fallback if we                                 couldn't find good tweets and then                                 memory one so if you search for                                 something that's not so popular maybe                                 but then the QPS is lower that hits the                                 SSD index and so it makes sense because                                 of the QPS there is limited by I ops                                 also SSDs so it's just a cost                                 optimization basically one component                                 that I should mention is our blender the                                 blender is the thrift aggregator so                                 basically when a search request from                                 from the client comes in at first it's a                                 blender and the blender fans it out to a                                 different system and systems different                                 indexes for example also our social                                 graph or user search index I mentioned                                 earlier users are indexed separately                                 from tweets um and also it knows about                                 our hash partition so it can find out to                                                                                                      results and then merges all the results                                 together and depending on what kind of                                 carried was it's a simple task of just                                 maybe doing a emerge of the search                                 result of a list of multiple list of                                 search result is results or it's a                                 blending of different result types as i                                 as i showed earlier on the slide where                                 we had you know tweets and users and                                 videos and images so then it's a more                                 complicated ranking problem how to merge                                 results of different types together so                                 that they that they useful and then last                                 but not least we have another stream of                                 updates which is basically even people                                 delete the tweet or they favor the                                 retreat of course you're going to index                                 that too so that you can use it for                                 ranking purposes so we have a stream of                                 updates and they are fanned out to all                                 of these early bird index machines and                                 they actually do in place updates and I                                 can show later how that works all right                                 okay so I want to come I want to give a                                 very short introduction on how inverted                                 inexus work because then it's kind of                                 easier to explain some of the other data                                 structures data and an inverted Enox                                 index is basically the fundamental                                 concept how old routine works and also                                 early bird because it's based on the                                 scene so let's say we have let's say we                                 have the six documents on the left side                                 and women the search for words in there                                 so of course we don't scan the documents                                 to find the word we are searching for                                 but instead what we build assists                                 invited index it's very simple thing                                 it's basically dictionary of all unique                                 terms that are contained in those                                 documents so those those are the words                                 on the left side and then we have on the                                 right side what's called posting list                                 and posting this two are basically just                                 linked lists that contain the document                                 IDs in which that term occurs so for                                 example if you look for it worked keeper                                 you can see to curse in documents                                       and then in the dictionary here we can                                 look up the word keeper look up the                                 posting list and the posting this tells                                 us                                                                     to look that look up in which documents                                 that were the curse um I want to quickly                                 oh yeah and one thing I want to point                                 out we store all to purge our metadata                                 in this index so for example here to                                 term frequencies that just the number of                                 documents in which the term occurs                                 there's more metadata we need to store                                 per term and I quickly want to point out                                 which data structure we use for that                                 because of something else or unexplained                                 later I'm we unlike leucine use a hash                                 table to store all terms because leucine                                 actually uses a solid data structure for                                 things like fuzzy queries and other                                 curie types you want it to be sorted we                                 actually don't currently support while                                 high praise for example of as it carries                                 so that's why we don't need a dictionary                                 to be sorted that's why we we have a                                 more memory efficient hash table Oh                                 actually fan Oh of one hash table so as                                 you know hash table has to be oversized                                 for                                 efficient member hash collision handling                                 so the array on the left side is                                 basically our hash table and when we get                                 the first term cat bc we assign the term                                 ID to this terms first term so it gets                                 id                                                                     sesh table and the chair midi is at the                                 same time the index in those arrays that                                 we call the parallel race because                                 they're parallel and the nice thing is                                 that these arrays can be compact so they                                 can have exactly the size the number of                                 unique terms in our index they don't                                 need to be oversized like the hash table                                 because the Charmides isn't see index                                 into those arrays so if you see three                                 terms then we append the terms into a                                 second secondary data structure and like                                 it's like a stringbuilder basically in                                 Java it's a character race and the store                                 to our meta data into those parallel                                 rays for exams the frequencies that they                                 had on the previous slide but also point                                 us to we're posting this starts and like                                 other things we need to keep track of                                 for each term yeah but I basically                                 wanted to point out in the slide that we                                 have term IDs and then that we can as                                 you can see here because we have those                                 texts point us into that string buffer                                 that we could based on the term I dxg                                 look up the label for the term and                                 that's important um in a few minutes                                 okay so the majority of an inverted                                 index is in terms of size is you need                                 for the father posting this the posting                                 is a really huge long list and you want                                 to store them very efficiently so we've                                 seen used to use something called Delta                                 encoding so let's say it so uses it but                                 it uses know a different compression                                 that I have on the slide but so for                                 example if you want to encode the doc                                 ADIZ that on the in the top row there                                                                                                     numbers so what we actually tries                                 instead to encode the deltas between two                                 numbers so for example if you look at                                 the last two numbers like                                              and thousand                                                          and                                                                     if you have a good compression technique                                 then                                 it's beneficial to encode smaller                                 numbers we've seen uses some or used to                                 use something called vian compressions                                 in a newer version it doesn't use viens                                 anymore but until it's simpler to                                 explain beans beans don't use four bytes                                 for an integer by the variable number of                                 bytes and it uses of each byte only                                 seven bits to encode the extra value but                                 the first bit of each by it stores                                 feather the next byte it's part of the                                 same number or if it's a new number                                 that's why you can concatenate multiple                                 bites and it's always a variable length                                 so in the first case if you have a very                                 big number you could use five bytes for                                 one integer but that doesn't really                                 happen very often in an inverted Nix                                 especially because we Delta encoding a                                 bit try to keep some numbers actually                                 small some a downside for us at twitter                                 is that if you have Delta encoding you                                 can only read it and from old to new                                 direction right because each number                                 depends on the previous one so you have                                 to calculate what the actual dark ideas                                 but if you think about real-time search                                 what you actually want to do is you want                                 to return tweets and the opposite order                                 you want to return usually new treats                                 before all treats right so that's why we                                 wanted to have a different encoding                                 which you cannot use read in the                                 opposite direction um that's why in our                                 first version of early but we had a very                                 very simple encoding basically each                                 posting had one integer and we split up                                 into two parts                                                        and the docket is not a delta is an                                 absolute doc ID and since treats can                                 only have found it for the characters we                                 use the other eight bits for the                                 position of a red within the tweet right                                 and since the eight bits you can encode                                 to                                                                    possible text position in the tree to                                 encode that position and then you can if                                 you don't use Delta's you can use you                                 can read it in both directions so we can                                 we can now read in the opposite                                 direction if this is posting list we can                                 written into this direction new to old                                 and you can also do something called                                 early termination so if you don't if you                                 don't want to actually return like let's                                 say the best treat of all time is we                                 really have to read all treats to find                                 the best one of all                                 if you only want to return which is a                                 very frequent thing we do especially                                 with API search on twitter if you want                                 to return the last few results the most                                 recent ones we can actually three for                                 example this case are requested we can                                 read three postings and then terminate                                 the search and return them if you can                                 search from you too old so that's much                                 more efficient of course and searching                                 in the opposite direction just to find                                 the last most recent three tweets yeah                                 so um yeah the combination of searching                                 in neutral direction and being able to                                 do a determination this was a                                 significant performance improvement                                 compared to the traditional way to                                 encode things and I said I already                                 talked last year or two years ago about                                 the memory model so i just have to slide                                 up here because I want to kind of give                                 an idea how it works but not go into                                 much detail um on the top part it's kind                                 of a little bit like Malik it                                 concatenate builds up a linked list for                                 each posting is this kind of feeling                                 dist and each of these green and yellow                                 boxes are just slices of integer race so                                 care for each posting is assigns a                                 number of these slices of these integer                                 ID and integer array slices to posting                                 list and stores those integers that I                                 mentioned earlier in there and then a                                 link slices together what I want to                                 point out is basically that the postings                                 are stored in a race and it's hard if                                 you would ever want to insert something                                 in the middle it's extremely hard                                 because you would have to kind of make                                 room and like push everything away and                                 like rearrange all the ideas if they if                                 you want to keep them sorted and insert                                 something so yeah but I one penalty is                                 we use native race and it's hard to                                 insert something in the middle but                                 that's a frequent problem of inverted                                 Nexus ok so summary years of the first                                 version of our posting is format is that                                 the integers can be written atomically                                 that's another reason we used integers                                 because of our concurrency model also                                 you can see that in my previous talk                                 otherwise that this important package                                 structure is easy I'm we use integer                                 raise also for the benefit of reduced                                 garbage collection of it and each                                 segment can only have                                                   tweets because of the                                                   the dhaka DS and one thing also here is                                 that difference to leucine is that if we                                 see which doesn't happen treats very                                 often because they are short but if you                                 have if the same bird occur across                                 multiple terms within the same tweet we                                 actually store that posting twice that's                                 different to leucine leucine does it                                 anyway that it would only stall at doc                                 ID once and then encode another number                                 which is called the term frequency and                                 that encodes are often that term across                                 for them the same document of course it                                 makes sense for large documents where                                 it's very frequent that vertical                                 multiple times but which feeds they're                                 so so short that it doesn't really                                 happen very often yeah but for the new                                 postings encoding we had we had more                                 vicious goals we wanted to support                                    bit positions like leucine so that it's                                 the we can use a real-time search                                 benefits also for big documents we                                 wanted to store the term frequencies                                 instead of repeating stock ideas for                                 space efficiency because for again for                                 big documents it wouldn't make much                                 sense to do it the other way but we're                                 going to keep the concurrency model we                                 want to keep the space efficiency for                                 short documents and we of course you                                 want to maintain the good performance we                                 see so what we therefore want to do is                                 we want to still stored or cadiz in                                 integers because of the memory model                                 women keep and the concurrency model but                                 now we have the problem that the                                 positions and payloads and you seen can                                 be very variable length because you                                 don't know how how much melody of the                                 store if you if you don't know how often                                 that term cannot curve is in the same                                 document so therefore we encode now the                                 new postings into two different streams                                 the upper one is um                                 the upper bond the yellow boxes and in                                 the the top stream are always                                         they are always fixed size and they                                 encode the doc ID and maybe the gem                                 frequency and they have a corresponding                                 portion in the lower stream yeah in the                                 lower stream of position payload pairs                                 like it could be multiple ones if the                                 again as the term across multiple times                                 in the same document and now I'm we                                 don't want to encode the red pointer so                                 if we actually store it for every                                 posting the point of where the                                 corresponding position payload section                                 starts in the other byte stream I would                                 be very expensive to point out what                                 actually more would be bigger than the                                 integer itself right so that would be                                 another good idea so the idea is that we                                 actually use a skip list which is a                                 frequent technique that also dracaen                                 uses in an inverted next for two reasons                                 one is to speed up searching and the                                 other one is to actually have these                                 political points where we know where the                                 corresponding section starts in the                                 position payload stream so we can if we                                 find like we could search for such a                                 blue skip entry and the doc ID stream                                 and then we would exactly know where the                                 corresponding section and the position                                 payload stream is so um but we have to                                 change our posting is encoding a little                                 bit and then observation years that most                                 streets actually don't need all the                                 eight bits for the text position because                                 the text position section of the                                 character position it's a token offset                                 so if there are ten words in a treat                                 then you don't store the character                                 offset of the tenth word the tenth                                 ricketts text position neg                                               the time a treat of course doesn't have                                 hand for your characters it could I                                 sorry hun Foley different words it could                                 happen maybe in like cjk languages where                                 we don't have white space tokenization                                 and we use by grams for example that                                 could happen that the treat actually                                 really has hundred forty different birds                                 but it's not it doesn't happen very                                 often so we could get away with less                                 than eight bits in most cases that's why                                 we use one bit actually to indicate                                 whether I'm                                 the text position is in lined in this                                 integer or I start separately in this                                 other stream that I had on the previous                                 slide so in lining is only possible if                                 all these because if all these                                 assumptions are true here so the term                                 frequency has to be one which again I                                 said for treat that's most of the time                                 true that word only the same rat only                                 crest once in a tweet the text position                                 has to be smaller than I'm                                              it doesn't fit into seven bits the                                 posting should not have payloads and                                 then our treat in the next we actually                                 don't store payloads right now and fun                                 implementation reason the posting must                                 not be at the same position as one of                                 those blue skip lists but that's an                                 implementation detail so the cool thing                                 then is that now we can support                                       bit positions using the other data                                 structures for for large documents but                                 we maintain the same efficiency using                                 the same data structures for tweets                                 because most of the time for treats the                                 positions will be inlined in those seven                                 bits and it will not really need that                                 additional data structure in most cases                                 so we kind of achieve all the goals we                                 had we wanted to keep the same memory                                 model the same concurrency model that                                 all works performance is the same and                                 actually after we deployed it the index                                 eyes barely increase increase maybe like                                 one person because of those additional                                 skip lists and you can under on our                                 charts you cannot even see very deployed                                 it because the performance was almost                                 identical all right now one talking                                 about ranking yeah so I mentioned                                 already that inverted index of course                                 can be used to if you have a query you                                 can look up some matching doc IDs you                                 know we saw that on the earlier slide                                 also i pointed out with the term                                 dictionaries that they can do labeling                                 if you have a chairman the ID we can use                                 invert the next to look up the term                                 labor but where do we store stuff like                                 you know Retreat retreat counts favorite                                 counts for ranking so for that we have a                                 forward in the next and that one is                                 actually very similar to racine stock                                 values if you are familiar with those                                 and we have additional index in the                                 facet index also similar to                                 elasticsearch I see no solar they have s                                 accounting we have we have we don't have                                 actually the fence accounting feature as                                 such like amazon also on the trade                                 ostrich product but we use very similar                                 data structures for other for other use                                 cases that i'm going to show in a second                                 so the forward index is very similar to                                 lose in doc values at store Street                                 features retreat collins favorite clowns                                 reply counts and other ranking                                 information that we use they are the                                 different students seen as they are in                                 memory and updateable in our case                                 because I mean people favorite and read                                 treat like all the time in real time so                                 we need to update if you need to reflect                                 those changes to accurately rank our                                 tweets and we have a implemented small                                 type system that allows us to pack                                 multiple features into one integer                                 basically so um i think for retreat                                 favorite reply and and for things i can                                 remember we use the same integer and we                                 use a special encoding two packs it into                                 into one integer because if you think                                 about we have three hundred billion                                 tweets that's actually that's actually                                 jason of a treat here and you can see                                 there's a lot of numbers in you and                                 metadata I mean yeah three days only                                 have four characters but actually the                                 what's kind of unique I think about our                                 search problem is that why we have short                                 dawg where we have short documents we                                 have so many that almost the storage of                                 the features for ranking purposes is                                 bigger than the action very Linux                                 inverting is index is fairly small                                 compared to you know other longer                                 documents of course because we don't                                 have so many postings but the forward                                 the next needs to be very big so if you                                 think about if you just want to encode                                 one integer and if you have                                             tweets you need or in this case one                                 being treat and you have maybe                                       replicas or i think we probably even                                 have more then it's already four                                 terabytes of memory which is really                                 expensive so we try to compress as much                                 as we can of course so here's our most                                 famous tweet from the last Oscars that                                 got like three and a half million                                 retreats and two million favorites so                                 these numbers we want to store of course                                 they don't fit into one bite but if you                                 think about it it's not really important                                 if a treat got like                                                                                                    retweets for ranking purposes that                                 doesn't really matter it's more                                 important if it's we got                                           retweets for example so we wanted to we                                 wanted to try to pack it into an integer                                 and if you look at different lock                                 distributions if you actually use stock                                 the base of                                                           nice distribution that assigns different                                 values to the interesting areas right so                                 I'm sorry in this case oops in this case                                 you know if three tests                                                 feet doesn't change the score that much                                 the lock in the right column but if a                                 treat has you know between                                          retweets the value changes like                                 significantly to the ranking value so                                 that's exactly what we want to see the                                 and therefore we use a modified float                                 structure to encode these values into                                 seven bits we only use a next one for                                 four beds in the fraction of three bits                                 and you can see that the resulting curve                                 of that custom float looks very similar                                 to that lock column here                                 okay okay so now for relevance ranking                                 as I said often we just want to maybe                                 return                                                          sometimes we also want to return the                                 best treat of all time and ideally we                                 don't want to have another index that                                 may be solved by relevance but we want                                 to use our existing existing indexes                                 because they re so so they can be don't                                 want to build another one and one                                 observation is that a lot of features                                 are curry independent so we have static                                 signals like I use a text quality of a                                 treat you know if it tests interesting                                 read verses like                                                        know text ability is important dynamic                                 signal diagram of retweets and I my                                 favorites and that kind of stuff or the                                 author's reputation for example could be                                 interesting and then there's curry                                 dependent signals like receives texts                                 score or the language of the person who                                 is searching so you know for someone who                                 searched who's um within Germany should                                 probably see other results in someone                                 who's in languages set to English those                                 things things like very deep end but                                 they are a lot of signals are                                 independent those ideas to actually in                                 the X skip lists for documents that have                                 high curry independent scores so we                                 could think of having many different                                 early bird segments or time slices as i                                 call them earlier yeah on the lower side                                 let's have each eight million documents                                 and then we have a skip list on top of                                 them and the red dot c mark the                                 documents that have a very high very                                 independent score so those are the good                                 tweets right um I'm going to skip this                                 slide                                 and furthermore we can actually have                                 multiple of these kippers and make them                                 hierarchical so we can say you know on                                 the highest one that has very few of the                                 red dots those really mark like the best                                 foods of all time maybe the treat we                                 looked at earlier that it had three                                 million tweets or maybe Obama's tweet                                 when you got reelected and that kind of                                 stuff so they really contain a very                                 small amount of treats but instead most                                 of the other ones so now if you search                                 for if you want to find the best tweet                                 ever for your query we could take your                                 query enter intersected with that                                 highest skip list find a good tweet and                                 if we if we find it we return it if you                                 don't find anything matching then we                                 could actually go down a level and go to                                 the less I'm the less selective skip                                 list search again for your query and                                 maybe find something then and then we go                                 we go the further down until we found a                                 good tweet yeah so I'm the summary is                                 that we do this on the relevance ranking                                 on an index that is all up I time so                                 that we can keep our existing                                 infrastructure like a pending tweets but                                 we use a forward index that is updatable                                 to in real time always apply retweet                                 favorite second of stuff to that an                                 in-memory data structure and then we                                 have a background thread that actually                                 come regularly recompute those skip                                 lists and reflects the changes of those                                 engagement signals so the red dots get                                 recomputed all the time because tweets                                 can have gotten one engagement in the                                 meantime and we achieve very high                                 performance of the in the combination of                                 the skip lists and early termination                                 okay okay one last thing i want to show                                 is I showed ra is a universal search                                 site here because this universe search                                 because it blends different result types                                 and what you can see is that for example                                 you turned photos so now how do we                                 search for photos right I'm only have                                 five minutes left I'll be searched for                                 photos so we the interesting thing is                                 that the document in our index                                 represented to eat not the photo right                                 and now what could happen is you know                                 two people treat the same photo link the                                 first person says you know all that's a                                 cute puppy and the second person says I                                 know cute dog right now if you in the                                 next first street with a URL you only                                 have the red puppy in there someone                                 searched for doc wouldn't find the                                 document that photos so what you                                 actually want to do is you kind of want                                 to update the previous document with the                                 photo URL so that it also contains a                                 great dog but as I showed earlier and                                 then inverted index it's very difficult                                 to in place updates so that's why in                                 especially in real time index if you                                 have an offline Linux you could                                 recompute the whole index often but in                                 the real time in next um you don't want                                 to do that so an also decide especially                                 on Twitter it's very important that you                                 can often find very recent photos for                                 example if the in terms disconnects or                                 officer was a fiery recently and the the                                 photos people took on the street that                                 the iphone showed up on Twitter before                                 anywhere else so you really want to                                 solve this stretching for the problem in                                 real time yeah but because empires                                 posting these updates are heart and                                 through scenes update document call it's                                 really delete and add so it changes the                                 oil of the neck so it would not preserve                                 our time I out the next anymore we                                 needed a different solution and the idea                                 is to use faster to actually for that                                 and the first day a structure not the                                 facets in the product sense and this is                                 how it works again the facet in X is as                                 you get nexted maps from a dog ID to the                                 features a treat contains and features                                 in this case could before the URLs could                                 be hash tags could be at vengeance and                                 what an interesting entities so now if                                 you search if you search for query we                                 look in the posting this we find the                                 matching got IDs and then we look up in                                 the facet index what our term IDs for                                 interesting entities like photo URLs or                                 hashtags that the stream contains and                                 then we have a we maintained during the                                 search a top K heap that has                                 the tupolev end of the term ID that we                                 found in the tweets that match the query                                 and the frequencies account how often                                 that Jeremy Kurt and as I pointed out                                 earlier we can use inverted index to map                                 back from term ID to the term label                                 using the dictionary implementation we                                 have so a last step after we found the                                 top term IDs by conned and have sold                                 them we can use them nor the next two                                 met them back to in this case photo URLs                                 and return the top photos actually that                                 match your query and it this is kind of                                 cool that we can use the NAM inverted                                 index and don't have to build a special                                 index and solve the you know in                                 updatable document problem okay so in                                 summary as I said indexing two                                 identities allows us to search in a                                 tweet centric index for other entities                                 are three types are supported for                                 example you could say find the best                                 photos in San Francisco you know from                                 people i follow documents don't need to                                 be really next and the approach is                                 reusable for a new entity set come up                                 you just have to change our indexing                                 schema for like best vines hashtags                                 mentions videos that kind of stuff and I                                 believe that's it yep questions                                 they'd be life too much time at thanks                                 for the talk um how do you do um                                 type-ahead all right how do you do                                 type-ahead I bet didn't have different                                 index yeah one more question how do you                                 do spell correction yeah so I'm the                                 question is how do we you type ad it's                                 the answers that's actually not their                                 index it's not it's not served by decent                                 Nexus here and it's pretty similar to                                 how will you seen this type at the index                                 prefixes of terms and then we carry that                                 index for term prefixes and can expand                                 to the extra great grace spelling                                 Corrections and it's also like a whole                                 it's another another different index                                 actually yeah so yeah it's not it's not                                 served by GT Nexus a dimension any more                                 questions I'm going to look at the Oreo                                 time talk but i think its release in                                     that was already Oreo time support so                                 could you just maybe a few words how                                 your approach is better yeah i think the                                 question is why don't we use a near                                 real-time feature that will see into pan                                 and introduce yeah i try to touch on it                                 earlier and the the different the reason                                 is that for it work sort of scenes near                                 real-time feature works well if you                                 don't reopen your next we are too often                                 so you have to end scene you have to                                 reopen your index reader to see a fresh                                 view of your index yeah um you have you                                 have to you implicitly losing the set                                 the scene has to flush all these data                                 structures that I had here on the sides                                 I the posting lists and dictionaries it                                 rushes it to disks or a two disc or to a                                 different in memory and directory                                 implementation and that and that causes                                 new segment small segments a lot of                                 small segments especially if you do it                                 very often so you pay later                                 for merging those small segments right                                 so in scenes near time a near real-time                                 search feature the indexing throughput                                 and the search throughput are correlated                                 in our case is completely separate so we                                 can because we never have to flush these                                 data structures we never get small                                 segments and we never have to pay for                                 for merging segments so if you don't get                                 the performance curves like you could                                 you could have an early bird machine and                                 you index as fast as you can with like I                                 on fifty thousand tweets per second                                 index and then you start hitting it with                                 queries right and the indexing                                 performance doesn't go down at all it's                                 completely completely maintains the same                                 performance ok maybe we have time for                                 one more question could you give us some                                 idea how you test your systems are both                                 on the micro level for forum for your                                 the scene modifications as well as the                                 how do you test like the full system                                 yeah so for yeah the question is how do                                 we test the system on a low level                                 actually the cool thing is even though                                 some lot of the data structures an early                                 bird a different from the scene the cool                                  thing is i implement the same the scene                                  AP is which is why i was lazy and just                                  used a lot of the leucine unit test to                                  test for the correctness and that's                                  there's really great coverage we have um                                  we wrote additional unit test to test                                  specifically the concurrency at the new                                  comprehensive model but otherwise we for                                  just correctness of searches we used a                                  lot of sluicing unit tests and then for                                  the system as a whole yeah it's always                                  difficult to fully test distribute                                  system we have we have smoke tests that                                  hit our blender component and test if                                  the expected search results you know                                  from five somebody if you test if you                                  have if you have a fixed day a set and                                  you do a universal search query it hits                                  almost all the systems so if you get the                                  expected result back that's a pretty                                  good indication that you know nothing                                  fundamentally is broken um also we have                                  so many queries we have constant seem of                                  string of queries that a lot of things                                  we test when we when we                                  when we deploy when we do a staging                                  deploy we can you know send a lot of                                  queries to the next and see if anything                                  is breaking so that's the benefit that                                  we have such high traffic okay well                                  thank you very much again for your talk
YouTube URL: https://www.youtube.com/watch?v=akvrdGeZmIE


