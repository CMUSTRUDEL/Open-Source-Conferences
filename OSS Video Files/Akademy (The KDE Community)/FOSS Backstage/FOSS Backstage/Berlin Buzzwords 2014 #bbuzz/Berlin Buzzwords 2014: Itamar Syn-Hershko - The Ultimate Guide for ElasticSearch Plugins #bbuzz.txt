Title: Berlin Buzzwords 2014: Itamar Syn-Hershko - The Ultimate Guide for ElasticSearch Plugins #bbuzz
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	ElasticSearch is a great product - for search, for scale, for analyzing data, and much more. But sometimes you need to do something that is not supported by ElasticSearch out of the box, and that's where plugins come into play.

Join me in this talk to explore the plugins land of ElasticSearch. We will discuss the various ways ElasticSearch can be extended, and the various types of plugins available to do that. By giving concrete examples and browsing the large selection of pre-made plugins, we will see how plugins can help us overcome various challenges. We will also discuss possible issues with plugins, and ways to work around them.

Finally, we will discuss scenarios in which custom plugin development is necessary and can really save the day. By showing a demo of one such scenario, and the way we built and debugged a plugin to solve it, we will complete the picture of the ElasticSearch plugin land, and hopefully inspire you to create your own!

Read more:
https://2014.berlinbuzzwords.de/session/ultimate-guide-elasticsearch-plugins

About Itamar Syn-Hershko:
https://2014.berlinbuzzwords.de/user/183/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              yep okay hi guys just a little bit about                               me about this talk what we're going to                               do you today i'm currently freelancing                               doing a lot of consultancy and the                               custom development work I'm just in the                                                                                                      us in back for a couple of years now                               I've been maintaining the solution                               project with which is the c++ port for                                leucine and then which is now dead and                                now a lost internet project and this                                talk is basically some view some birds                                eye view of elastic search plugins so                                I've been working with elastic search                                for about two years now and we've been                                doing some really nice interesting stuff                                with elastic search we've come to points                                where we had to extend it using various                                mechanisms and basically that's the talk                                where i'm going to show you where you                                can extend it how you can do that when                                you want to do this and so on so this                                talk because it's only                                                going to be a very high level view of                                what you can do how you can do that i'm                                not going to drive too much into details                                but i am going to give references and                                basically where you can take this from                                yeah so the agenda is basically i am                                talking about the integration points                                where we where you can integrate with                                elastic search with loose in then i'm                                going to give you some some showcases                                where you can do that or how i did that                                for special for certain scenarios and                                then talk about some gotchas when you                                write your plug-in or when you integrate                                what what to watch for and then I hope                                we can get to do some Q&A so looking at                                elastic search on a high level no                                offense but elasticsearch generally                                speaking can be thought of as an HTTP                                server on top of leucine so what you can                                see here is basically the elastic search                                server and within that elastic search                                server                                we have loose in so this part here is a                                bit small we are going to zoom in in                                just a second but elasticsearch our                                server basically just takes in rest                                response at rest requests send back                                responses and you can either do indexing                                or querying and those commands or                                requests are going to be delegated to a                                leucine index data signetics has some                                logic happening within it and that logic                                looks a bit like this so we have request                                searching or indexing coming in and then                                you have the query parser you have the                                analysis chain you have the indexing you                                have the search parts we're losing                                actually does its its thing and then in                                the bottom you have the leucine index                                itself the actual files now the                                integration those things that Lucinda's                                can actually be integrated with so let's                                start with the most maybe not                                interesting example which is the query                                parser so when you send a request that                                request that search request can be                                basically a query string now the visual                                the official recommendation is usually                                not to use a query string basically                                because the query parser that comes with                                leucine can throw exceptions can do                                stuff that you don't really want it to                                do so you can either send use some some                                other query types which that elastic                                search provides or you can implement                                your own your own query parser so there                                is actually a simple query parser I                                think it's called that's sort of new to                                seen as well that is a custom query                                parser that actually takes a very                                relaxed syntax and it doesn't throw and                                basically if you want to write your own                                query parser you can do that and then                                you basically integrate that query                                parser with it within elasticsearch you                                tell astok search that whenever a query                                string query comes in to elasticsearch                                it should use that Corey parser and then                                you're pretty much done                                I think there is no way to actually have                                multiple query powers or implementations                                line side by side so if you provide                                acquire powers of your basically replace                                the existing one but that's the most I                                think simple integration point we can we                                 can talk about how you do that will                                 touch that in the end of the talk and                                 then we have the analysis chain now                                 whenever you have indexing coming in or                                 searchers certain searches coming in for                                 example query strings or equestrian                                 queries or you have marked the match                                 family Koreans coming in they're going                                 to go through the analysis chain now                                 what is the analysis chain it's                                 basically probably the most important                                 part of leucine just to demonstrate why                                 so if we have you know one line of text                                 the analysis chain is going to actually                                 take care of tokenization and turn token                                 filtering for you so you have that                                 string that line a stream of one's three                                 lines line of text it's going to be too                                 keen eyes into multiple tokens that's                                 the first part of the analysis chain and                                 then you have the second part way you                                 can have multiple filters doing multiple                                 operations on top of that the entire                                 talking stream or each individual token                                 on itself so you can remove tokens you                                 can add tokens you can manipulate tokens                                 so that's one example there is another                                 example for example that does some askew                                 normalizations Laura casing and usually                                 the analysis chain is going to match                                 from both sides of the indexing and                                 searching so you you're going to index                                 this line of tech this line of text                                 you're going to have multiple terms in                                 the index and when you query you                                 basically probably going to query on                                 only moved on only single items terms                                 and that is going to go through the same                                 process and that basically ensures                                 you're going to get the results that                                 you're looking for all the document                                 that were indexed sometimes however you                                 want you will want to actually use                                 different analyzers for the search part                                 in the indexing part there are good                                 samples for that as well so keep that in                                 mind and there's also some times when                                 you actually want different tokenization                                 behaviors than what's provided so some                                 analyzers some to analyze a solution or                                 some tokenizer to be more exact are                                 going for example to preserve email                                 addresses some will not whatever the                                 behavior that you want can actually                                 change between corpuses and query types                                 and to just finalize my case since we're                                 in Berlin so you have this way of                                 actually combine multiple words together                                 so you do actually want to provide an                                 analyzer that can understand your                                 language your corpus or your whatever                                 searches your users we want to do this                                 is why basically you'd want to write                                 your own analyzer so there are some                                 analyzers that combined it bundled with                                 loose in this is the most basic ones and                                 then you have the ability to actually                                 construct your own analyzer without                                 doing actually any actual code work                                 using just index settings so it's a j                                  JSON document that you put with as a                                 settings are within your within your                                 elastic search cluster or metadata                                 cluster and that's how you can take                                 token filters or tokenizer switch are                                 the two steps that we have shown and                                 construct an analyzer out of them so an                                 analyzer basically is constructed of one                                 tokenizer and one tokenizer and multiple                                 talking streams or none at all and                                 that's your choice what to do so this is                                 one way you can integrate with elastic                                 search constructing an analyzer out of                                 those are those constructs and that's                                 without doing any coding at all                                 that's that feature here by the way is                                 nearing elasticsearch in my mind in my                                 opinion it's it's some sort of a game                                 changer in terms of how you can actually                                 do really interesting stuff with with                                 basically with the scene with doing                                 full-text searches look it up but you                                 can actually go and write your own                                 analyzer so if for example you want to                                 have a tokenizer or you want to have                                 talking filters or you want to have the                                 whole deal that does not do you then                                 don't have that in lucene currently or                                 you don't have that in elasticsearch oh                                 and any other plug-in does not allow you                                 to do that you'll probably go and write                                 this for yourself so I mentioned it's                                 very language dependent and very corpus                                 dependent so here's an example of a                                 plug-in road which actually takes a big                                 problem in the search world which is the                                 Hebrew language it's basically you                                 cannot really index and search on on                                 Hebrew texts using any currently                                 available tools and this is an elastic                                 search plug that I wrote it's open                                 source you can go and look up the code                                 see how I do things there which                                 basically gives you token filters and it                                 gives you a custom tokenizer that lets                                 you index and search Hebrew properly                                 there is some gotcha here we'll get that                                 are in the end basically I'm using a                                 dictionary and that dictionary I need to                                 have it available and that tends to have                                 to present some problems and we are                                 going to look at that in just a bit so                                 going back to the loose in diagram for a                                 second so we just talked about the                                 analysis chain now once we have                                 constructed a query out of a query                                 string or whatever other query that went                                 or needed to go through the analysis                                 chain we're not going to perform the                                 actual search using that query object                                 internally in lucene now here is an ear                                 is probably where the most of the                                 extension points are so let's start with                                 scripting so you can issue a lot of                                 queries and                                 and have filters and have custom scoring                                 and do facets or aggregations do a lot                                 of a lot of those stuff but you might                                 get to a point where you're trying to do                                 something and maybe your model doesn't                                 allow you to do exactly what you want or                                 maybe some scoring some kind you need to                                 do some custom scoring or you need to do                                 custom filtering and so on and that's                                 where the scripting engine of                                 elasticsearch comes into play generally                                 speaking it's it's pretty slow so it                                 works nicely and it is quite performing                                 but you don't want to rely on that once                                 you grow too big or you have many                                 requests coming in and that's something                                 to keep in mind you can definitely start                                 working with that you can definitely                                 write something working and working well                                 with that but at some point you're going                                 to notice it doesn't it doesn't take all                                 you want it to take and that's where you                                 should start looking for alternatives so                                 basically the scripting in elasticsearch                                 is is based on multiple scripting                                 engines the one we used by default is                                 mville you have groovy you have Python                                 there are multiple other scripting                                 languages scripting engines you can use                                 you can obviously write your own                                 scripting engine if for some reason you                                 want to do that but again it's just a                                 scripting engine and that's something to                                 take note of and at some point you're                                 going to get to a point where you want                                 to make this more performant there are                                 two ways to do that one is to go the                                 native scripts route meaning you'll be                                 writing some sort of a plug-in that                                 basically does the actual actual work                                 for you but it's written in Java and                                 it's actually compiled and being an                                 elastic search uses us as a native code                                 or native java JVM code or you can go                                 and in your in your case it makes sense                                 to actually extend elasticsearch to do                                 using some custom actions you might want                                 to go that route although as we will see                                 it has its own pitfalls continuing                                 continuing on that point so basically if                                 you want to do custom scoring or if you                                 want to have an ability to search your                                 corpus and get results ranked in a                                 different way so you can integrate                                 custom similarity which losing by                                 default gives you as I tf-idf but there                                 are other other ways to do that or for                                 example the BM                                                           to maybe integrate other similarity of                                 similarity implementations that's really                                 a expert expert feature use it only if                                 you know what you're doing what is                                 important i think is the function square                                 which britta just previously talked                                 about and that's a really powerful                                 feature that's something that you should                                 really look into if you want to do                                 custom scoring and reflect results the                                 results order based on really complex                                 complex logic but again that's basically                                 script and all that comes with it okay                                 next point in the loose in integration                                 part so you have we have the indexing                                 part and it these are this next point is                                 actually going to affect also searching                                 so in loosing thought for we will soon                                 for sorry we there there's been a new                                 feature added it's called codex                                 basically it means it's some sort of an                                 abstraction layer on how the leucine                                 indexes are going getting written into                                 disc and how they are loaded back again                                 and again expert feature there are some                                 optimizations that you can achieve by                                 actually switching codex so you define a                                 codec basically like that you put a                                 codec definition or you use an existing                                 codec definition or which already you                                 can already have and then in the mapping                                 of your index you're going to tell                                 elasticsearch that this field needs to                                 use                                 is codec and this is basically again an                                 expert feature how you can improve                                 performance because for example some                                 fields make more sense to load them up                                 at once and keep them in memory and some                                 fields do not and that's what codecs                                 let's let you do finishing up on the                                 loose in part we've been seeing how the                                 inner parts of the scene can be                                 integrated with again we're going to see                                 how we can actually do that in in the                                 end but let's for now treat loose in as                                 a black box so we have requests coming                                 in and we want to just pass them to                                 loosen get back the results and now                                 let's look at what we can extend on that                                 part that is elastic search that                                 basically manages losing indexes for us                                 now what I have in this slide is                                 basically where rest query quest                                 requests coming in and I'm basically                                 assuming it's either indexing or queries                                 but that's not true right so in elastic                                 search we have stats and management and                                 metadata custom metadata that we can                                 manage so I left it out of the slide but                                 obviously elasticsearch has that as well                                 so that's zoom out let's now look at                                 what elasticsearch can be extended with                                 so the first thing that we're going to                                 look at now is how once we have one or                                 multiple seen indexes in our                                 installation how we can control how they                                 are moved around so we have one                                 elasticsearch cluster which is one or                                 more servers and assuming we have more                                 than one server will now want to decide                                 how to allocate those shards of you seen                                 indexes between those those servers so                                 that's basically where shall the                                 location control comes into play so by                                 default elastic search allows you gives                                 you quite a lot of power so you can you                                 can tell an index that you want it on a                                 specific server by AP or by tag or                                 specify a bunch of them using tags using                                 blacklist whitelist approaches or you                                 can you can                                 fine-tune things like how many shards I                                 want on a specific note how many shards                                 of a specific index I want on a specific                                 node I you can also tell it to consider                                 disk space for example I want to make                                 sure that disk only has                                              used or only has always has this amount                                 of space free et cetera now that's all                                 already implemented for you and all you                                 have to do is basically play with with                                 some settings again you either using the                                 JSON using JSON the settings the index                                 settings or you can go and change the                                 elastic settlement for most of that you                                 may want in some cases implement your                                 own shadow location logic but it's very                                 very dangerous basically because a lot                                 of times the shouting allocation                                 strategy or the deciders that are in                                 play there's generally more than one in                                 play so you want to make sure that your                                 decider that you if you decide to                                 implement one I don't know taking into                                 account ram usage for example if you                                 cannot do that using tags or rock ideas                                 or whatever and you decide to do this                                 using your own custom code make sure it                                 plays really really nicely again super                                 expert feature one other interesting can                                 you see that sorry about that one really                                 interesting feature that I think worth                                 noticing is that elastic search again is                                 basically some is it's it's an HTTP                                 server and it's a distributed one so                                 once you have a logical deployed you and                                 if you have a plug-in that actually                                 gives you a rest endpoint you can                                 basically go and approach the cluster to                                 perform that for you now that that can                                 have multiple usages one is for example                                 to have your custom logic implemented                                 for search or whatever and then you can                                 expose that Thun on java consumers                                 because Java Java clients you basically                                 usually don't use the                                 the rest api they using the custom                                 serialization protocol of elastic search                                 on another port but non Java clients are                                 going to communicate with elastic search                                 using the rest api so if you have if                                 you've implemented your own logic for                                 example custom search or custom whatever                                 then integrating with the same for                                 example so you may want to implement                                 that rest endpoint so to expose it to                                 consumers one other use case for example                                 which I found actually useful one for                                 example i implemented that custom hebrew                                 search so i actually exposed an HTTP                                 endpoint that lets see me let me peek                                 into the dictionary that is being used                                 now because that's basically an HTTP                                 server I can implement whatever HTTP                                 endpoint and I want in the cluster and                                 basically expose business logic out of                                 that cluster as well and that can prove                                 very useful side note always put elastic                                 search behind a proxy and that way you                                 basically protect yourself from a lot of                                 stuff but what I'm saying that to make                                 sure that that advice doesn't go to                                 exposing your website or whatever out of                                 elastic search just you know internal                                 business logic that you won't distribute                                 it what's being shown here is actually                                 very simplistic code when once you have                                 a request coming in you're going to need                                 to parse it then you need to process it                                 to whatever logic you have to do and                                 then build back the response and send it                                 back now speaking about the rest                                 endpoints or speaking about the rest                                 capabilities of elastic search we can                                 have multiple transports supporting that                                 so by default elasticsearch uses the                                 HTTP HTTP for transport you can you can                                 use apache thrift you can have multiple                                 other transports and elastic search                                 already has its plugins at least you can                                 actually install more transports some I                                 don't actually know why they would be                                 used at                                 used for example the                                                   quite sure of the use cases but                                 apparently people have found use cases                                 for that and that you can do that you                                 can actually even write your own                                 transport and use that so all of a                                 lasting search REST API basically can be                                 exposed via different protocols the                                 thrift protocol for example is one                                 that's often being used to speed up over                                 the default HTTP protocol so let's let's                                 talk about one use case that we had we                                 were we deployed elasticsearch and                                 basically we use it for search and in                                 one project and we had a lot of search                                 action going on but we also need to                                 percolate now percolation basically                                 means an alerting system of on top of                                 elastic search that make sure that                                 whenever you have new document coming in                                 alerts will fire for a list of stored                                 queries that you have in your system now                                 they got back in the day I think it was                                 a year ago elasticsearch didn't have a                                 distributed percolator and we also                                 wanted to make sure that that particular                                 is highly optimized to our use cases                                 because we had a lot of documents coming                                 in regularly so what we did is basically                                 we took the elastic search the actual                                 elasticsearch speculator we pull it out                                 we put it in our own jar file made our                                 optimizations to it optimizations                                 including highlighting again back in the                                 day where the percolator didn't have I                                 lighting we had a lot of query                                 optimization so we basically filter out                                 a lot of queries based on the language                                 stuff like that we added a lot of logs                                 because we really really needed to                                 understand when an alert comes is going                                 to be fired when it didn't we needed to                                 track that so we did a lot of chemical                                 customizations and then we basically                                 compile it again and pushed it as a                                 plug-in but that's a very easy to make                                 plugin because basically all we had to                                 do is take some existing code from                                 elastic sir                                 compile it and then pull pull it in to                                 make elasticsearch detected and then                                 fire it and let it run and again we are                                 going to see how to do that in the end                                 of the talk sometimes you really don't                                 have any other choice but to dig deeper                                 into the API and that's what happened to                                 us here basically this is a we called it                                 the bubble plugin because in the end you                                 would have a visualization which looks                                 like a lot of bubbles but what this is                                 is basically a similar functionality to                                 what you have now is the significant                                 terms facet only it's we did this over a                                 year ago and it has a lot of added logic                                 within that so it's anagrams its                                 approach                                                                 and basically that that emerged from the                                 fact that if we wanted to have this in a                                 distributed in a fast way we really have                                 to dig too deep to dig deep into                                 elasticsearch so the way this works                                 basically you issue a query you get back                                 and for example a thousand results so                                                                                                         the representation that you're looking                                 for and then once you've got the results                                 you're going to go one by one and you're                                 going to do some sort of parsing and                                 some sort of of computations on top of                                 the text on the actual text that is                                 coming back now some documents that's                                 been done on by scraping social networks                                 and websites and blogs some some content                                 can be very very large so if we were                                 querying elasticsearch which is a                                 distributed search engine and you wanted                                 to get back those results and then go                                 one by one and do this pricing                                 calculation that would basically mean                                 you'd have you cannot scale so each such                                 operation it's each such logic is going                                 to take you quite quite a few minutes to                                 perform and think what happens for                                 example when you have multiple people                                 doing this all together now even for one                                 customers where one customer waiting for                                 a couple of minutes for this graphic to                                 show is a bit of the killer                                 what we did we did we are we dug into                                 elasticsearch and basically implemented                                 our own search engine so instead of                                 actually getting back the results and                                 doing stuff we actually took the code                                 from elasticsearch it does a search and                                 returns back the results and instead of                                 returning back results we did all the                                 logic of the text processing on that on                                 that phase now what that allowed us to                                 do is actually have that that                                 calculation or that computation text                                 processing been done on each and every                                 shot in parallel and then instead of                                 returning back all of the documents we                                 would have gotten gotten from this                                 plugin just multiple buckets saying okay                                 this is a significant term and this is a                                 significant terms and those are the the                                 count and then the master node accepting                                 that requires would have just merged                                 those buckets together and gave us this                                 results back which and then we could                                 have generated that graphic now that's a                                 very very very tough to do it broke with                                 every minor version because we dug so                                 deep into the elastic search core but                                 back in the time we didn't really have                                 any other way of doing that also just                                 you know debugging this was a really                                 really really big pain we basically just                                 write a lot of debugging or traces                                 everywhere and then use relax sorry log                                 stash and some Cabana to actually                                 understand the timeline of what's going                                 on very very painful so going back to                                 elasticsearch again just an HTTP server                                 so why not just serve static content out                                 of it and that's where site plugins                                 coming and those probably are the                                 plugins that most of you are already                                 familiar with so cabana marvel big disk                                 and all of those and many others are                                 basically plugins that are just static                                 HTML files or static files in general                                 that you can just tell a sixer to give                                 give give you back once you get them                                 back you can just communicate with the                                 cluster use the with them or maybe                                 sometimes you can just serve files which                                 are not related to                                 success at all and again don't use                                 elasticsearch to serve your website                                 don't expose the elastic search to the                                 outside world some more advanced stuff                                 includes discovery basically how elastic                                 search finds other nodes within the                                 cluster so my personal recommendation is                                 never to use multicast in a production                                 environment rarely are the cases where                                 I've actually seen used to that you                                 usually you would want to be familiar                                 with your servers and then use unicast                                 sometimes during development mostly it's                                 not possible and then you want to have                                 multicast basically auto-detection an                                 auto forming of the cluster this is                                 where you use discovery mechanisms which                                 is in discovery the basic one does                                 automatically for you but sometimes it                                 needs some help with regards to various                                 cloud implementations so those already                                 implemented for the the major cloudy the                                 major clouds already implemented and                                 there is also the zookeeper plugin which                                 I think with worth mentioning even                                 though it's a bit out of date now it's a                                 way for you to actually make sure that                                 you don't get partial partitions which I                                 know is currently being worked on but                                 both noting the late recent versions of                                 elastic search give you the ability to                                 do snapshot and restore functionalities                                 to various locations including file                                 system various clouds and basically                                 again all the major cloud                                 implementations already implemented for                                 you and but you can roll your own and                                 then once you you do that you basically                                 can restore an update sorry snapshot and                                 restore from whatever other                                 implementation you wish let's talk about                                 rivers for a second rivers are being                                 widely used rivers is basically a way                                 for a sick search to digest data meaning                                 you have an elastic search running so                                 you are going to have some sort of a                                 plugin with it within that elasticsearch                                 instance that is going to digest data                                 for example from curing servers from I                                 don't know scraping the web and whatever                                 other implementations are so many                                 implementations out there Oh River                                 plugins are obsolete or about to get                                 obsolete you should as a general note                                 not do that now the idea behind rivers I                                 don't know it may may appeal for some so                                 you have some logic that happens                                 automatically to index data for you the                                 problem with that is that this is very                                 prone to failure as a general rule I                                 will usually recommend people to use the                                 pool based in change ingestion rather                                 sorry push-based rather than pool based                                 so river is pool based is I'm here just                                 give me everything push-based oh I like                                 calling these shoveling is basically I'm                                 here I know my cluster is there and then                                 I can push data to that cluster now when                                 you use the push based you can scale out                                 that pushing the shoveling operation so                                 or you can if you have a backlog you can                                 catch up on that and so on with rivers                                 it's very very very it's more it's more                                 complex than that now you can use log                                 stash there is something that's called                                 stream two years which I found actually                                 very useful to to play with it a bit or                                 sometimes extend sometimes just demo                                 stuff or quickly come up with with                                 shoveling mechanism which you should                                 really look into whatever you do I                                 recommend you don't use the rivers sorry                                 about that so let's let's wrap probably                                 a bit so we have multiple plugin types                                 in elastic search some of them are                                 losing parts which you can play with you                                 can replace in some are some sort of                                 elastic search functionalities that you                                 can either enhance or just a do on your                                 own and installing plugins and once you                                 have a plug-in                                 which has to be a jar basically JVM                                 bytecode it can I it can be a site                                 plugin but again it has to be within a                                 jar and basically you install it using                                 either manually basically unzipping it                                 into the plugins folder of elastic                                 search or using the existing tool that                                 will let you do this that way it will do                                 this for you so you can go and fetch                                 using the tool from from github from                                 maven from from obstacle maven the                                 open-source maven repository so you can                                 use Mary repositories or github or you                                 can just point it to a URL and install                                 from that URL if you cannot publish to                                 github or or maven once you have those                                 plugins installed you can get                                 information about those plugins either                                 using the tool or you can go to the                                 cluster and ask it for using the                                 knowledge info API you can get back a                                 list of nodes and whatever plugins are                                 installed on them once you get that info                                 you can obviously remove plugins if need                                 be so when do you want actually to write                                 plugins don't be this guy don't come and                                 say okay have a problem let's write a                                 plugin that's really try to ignore the                                 urge to write plugins that may be                                 interesting but it can get very quickly                                 very painful that's the next slide we'll                                 see some pain pain points the defaults                                 are pretty good and you can do a lot                                 with description link mechanism you can                                 do a lot with whatever else there is in                                 elasticsearch the aggravations ramp                                 framework just made a lot of faceting                                 much more easier but sometimes you                                 really don't have any other choice so                                 when you do need to have some                                 distributed behavior done and you cannot                                 really achieve that by any of the                                 elastic search ways of doing that like                                 for example the bubble example just gave                                 you this is where you go and do this                                 distributed sorry this is where you go                                 and write a plugin                                 or when we you need to distribute some                                 some rest functionality or when it's                                 just a site plugin but other than that                                 most of the most of the work that of                                 writing a plug-in doesn't really work                                 that that doesn't really work that and                                 what is this work that's I would say                                 it's basically for things so the first                                 thing is really maintenance so once                                 you've written code you will need to                                 maintain it you need to make sure it                                 runs we need to make sure it operates                                 well and again it needs to operate well                                 within the rest of the infrastructure                                 and the deeper you go into the classic                                 Search API the most likely it is to                                 break very very soon once you have a                                 plug-in it's it's a lot of times really                                 paint to actually deploy that and                                 actually version that although there are                                 ways to overcome that using puppet for                                 example it is still a very difficult                                 sometimes to keep up with versioning i                                 mentioned auxiliary data meaning                                 dictionaries for example so if you have                                 an analyzer that actually wants to load                                 the dictionary and use the elastic                                 search mechanism for that again thinking                                 that those that data if it needs to be                                 on the file system and not on some cloud                                 that's going to be challenging there is                                 an open open ticket on elasticsearch                                 elastic repository for may be exposing                                 that and allowing analyzers or plugins                                 to load data out of the document store                                 that is elastic search it's not being                                 worked on currently so it may be may                                 have it may take some time for that to                                 actually come to the core and then you                                 have all the headaches of testing and                                 debugging and again making sure                                 everything ticks and that's a big pain                                 so one final slide how you do that so I                                 know it's a bit small here but the idea                                 is basically creating a plugin class                                 which derives from abstract plug-in and                                 that class basically points to a lot of                                 different implementations that you can                                 have for a plug-in so I would say the                                 most basic one is a module so you say                                 okay here is a module this module                                 does this and that it defines its own                                 tools for elasticsearch and bay and that                                 once you have that module you can just                                 inject it to elasticsearch using this                                 plugin plugin class that plug in class                                 basically is being referred to by some                                 embedded resource within the jar that                                 tells it where to bootstrap everything                                 there there are other things that you                                 can you can come up with so transport                                 actions or rest actions and all of that                                 kind of stuff are basically just classes                                 that you can easily find the                                 documentation just implement them and                                 give this give them your own                                 implementations we're pretty much out of                                 time so I will take one two quick                                 questions and let you all go okay great                                 thanks so taking questions oh so it just                                 a quick feedback on the discovery                                 plugins I know you come from the dotnet                                 world did you use the zero plugin                                 discovery plugin discovery on the plant                                 so it's the natto there are you sure                                 yeah no I haven't I haven't tested it                                 you know no I know I'm usually I'm                                 usually when I'm even more when I'm                                 working with the dead clients I usually                                 just tell them use linux                                    elasticsearch it feels much more natural                                 for me to actually run elasticsearch on                                 on Linux machines and then you know                                 development you can just do and don't                                 let it connect to that good any more                                 questions okay great thank you very much                                 again for your presentation thank you                                 guys                                 you
YouTube URL: https://www.youtube.com/watch?v=FbAO2k57bdg


