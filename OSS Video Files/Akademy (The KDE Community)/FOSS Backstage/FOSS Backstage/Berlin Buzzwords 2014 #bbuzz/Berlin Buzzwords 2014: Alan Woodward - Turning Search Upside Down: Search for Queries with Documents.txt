Title: Berlin Buzzwords 2014: Alan Woodward - Turning Search Upside Down: Search for Queries with Documents
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	While normal search engines allow you to search over large document collections with individual queries, monitoring systems have different requirements: to run large numbers of stored queries over a stream of incoming documents, and provide exact matches for those queries that hit. This can be an expensive process, in terms of time, memory and hardware.  

In this talk I'll discuss the luwak open-source library, built by Flax to solve just this problem, and show how we reduce the problem space by turning the problem upside down, converting queries into documents, and documents into queries.

Read more:
https://2014.berlinbuzzwords.de/session/turning-search-upside-down-search-queries-documents

About Alan Woodward
https://2014.berlinbuzzwords.de/user/321/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              okay okay hi everyone my name is Alan                               Woodward's I went with flax which is                               based in Cambridge in the UK I'm a                               listener seller committer                               and I'm going to talk to you today about                               turning search upside-down which is                               colored nonsensical so what does that                               actually mean so the use cases that we                               are using that we're looking at are                                circumstances where you have lots and                                lots and lots of queries and you want to                                run these queries over a stream of                                documents so in our use case it's four                                clippings companies it's for media                                monitoring but you can also use it for                                things like tagging or classification so                                what you want to do is you have your big                                set of stored queries for media                                monitoring in particular what you want                                to do is you want to identify media                                stories that are of interest to your                                client so you will create a large query                                which says okay if you have any of these                                terms in this document that I'm                                interested in it I want to find out                                about it so you have various different                                think there there is different bits of                                information that you want from these                                these queries you can say either I just                                want to know if this query matches or                                not so if you're tagging for example                                you've got a big query that's had                                anything that matches this query should                                be tagged with this term so it's going                                to say I just wanna know if it matches                                or not you might want scoring                                information you might want exact match                                position the information you wanted to                                say okay I've got this query I want to                                know the exact bits of this document                                that matched this query how we're going                                to do that well the easy answer is you                                use the memory index which is something                                a an object in Lusine which is an index                                for a single document and then you can                                get your so your index your document and                                then you get your any number of queries                                and you run all those queries against                                that document and you pull the results                                out and you respond which is fine it                                works and you can one problem with it                                which is that it's very slow we're                                talking about very very large queries                                these are very complex queries really                                very very big as you point out this                                isn't actually a real query because the                                queries are kind of                                but our client said quite protective                                Larry so this is made at one but anyway                                it gives you an idea of quite how big                                we're talking about and it's not just                                the size of them it's what they consist                                of they are very ugly queries these are                                not queries that are written by people                                who are coders they're not generally                                written by it's certainly not written by                                people who understand how search engines                                work so you'll have lots of world cards                                everywhere you'll have people putting                                the same term in with different                                capitalizations you'll get wild cards                                but at the end end at the beginning of                                terms even though that kills performance                                and that people don't don't really                                understand how stemming works so they                                stick a wild card in the end too to get                                all forms of a word even though there's                                already stemming built in there you'll                                get people who didn't work when you put                                it in once maybe we've put it in the                                query twice that'll work so these are                                enormous queries they have lots and lots                                of wild cards in them which means that                                if you're running one of these queries                                against running every single one of                                these queries against each document                                every one of those queries has to be                                rewritten for that document which takes                                time so typical document that passes                                through this is a client that we've just                                built this for you've got about                                       queries and the typical document goes                                through will match maybe two that's                                nineteen thousand nine hundred and                                ninety eight ninety nine there for some                                reason the queries there which you're                                running for no reason whatsoever they're                                just taking up time and we want to be                                able to reduce the amount of time that's                                 these useless queries take preferably to                                 zero milliseconds and the best way to                                 reduce the amount of time that a query                                 takes is to not run it at all in the                                 first case so what we want to do is we                                 want to pre select the queries that we                                 think are likely to get a hit and we                                 want to filter out those queries that we                                 know aren't going to get a hit it just                                 kind like a search okay you've got a                                 space of queries and you want to search                                 those queries with your document it's a                                 backward search                                 and yes the aim is to get as few false                                 positives as possible so we want to                                 really restrict the number recruiters                                 we're running you want to really only                                 run ones that are have a very decent                                 chance of hitting but you want zero                                 false negatives you don't want to miss                                 out any of those queries that might have                                 got a hit because if you do that then                                 you've got your getting inaccurate                                 results and particularly in the case of                                 media monitoring where now there's quite                                 a lot of competition there                                 if someone says if your client comes                                 along and says this particular article                                 came in that mentioned my name and you                                 missed it why am i paying you this                                 amount of money to do this I'm going to                                 go to your competitor so it's very                                 important that we get no false negatives                                 that we actually retrieve everything we                                 run every query that could possibly get                                 a hit so what we've done is flax we                                 built a Java library called Luwak which                                 does just this it's stores a whole bag                                 of leucine queries you registered them                                 with your with the monitor it stores                                 them in an internal index when a                                 document comes into the monitor that                                 document is then converted into a query                                 which is run over that internal index                                 and that selects which of those store                                 queries to run then runs those queries                                 and gives you gives you your results                                 back from the queries that it has                                 selected to run this is all pluggable                                 there is something called a pre searcher                                 which deals with translating the queries                                 into terms that can be indexed and                                 translates the document into something                                 that could be queried and then the match                                 reporting as well as all pluggable so                                 you can say I just want to know you know                                 is it a match or not I want to let the                                 score they're different matches that you                                 pass to it how does it work so we index                                 queries by having a bunch of things                                 called extractors which are                                 parameterised by the query and you can                                 have again these are pluggable so you                                 can put in your own if you have your own                                 queries and you can have put your own                                 way of extracting terms from them term                                 query is very easy would you say ok                                 we'll just pull the term out                                 numeric queries are turn queries as well                                 underneath so again just pull the term                                 out and a boolean query a boolean you                                 can think of a boolean queries as a kind                                 of tree and we recurse through that                                 query tree and we pull out all the terms                                 that we find within that query tree and                                 we index those we can be a bit cleverer                                 about how we do that ideally you want to                                 be indexing as few terms as possible                                 from a query because you want to only                                 hit and the more terms you index them                                 all likely is that query is going to get                                 hit by any document that's coming in and                                 so if you can if you can reduce the                                 number of terms that you're indexing                                 under then you're going to reduce the                                 number of times it gets hit by a                                 document so how can we do that well we                                 can say obviously any must not Clause                                 and a boolean query don't care about                                 that if if it's a disjunction if it's                                 just got should and must not queries                                 then you do have to index all the                                 various sub clauses also all be all the                                 should clauses but if there are any must                                 causes an if it's a conjunction of any                                 kind then you can ignore everything else                                 and you can say alright I just want to I                                 just need to index one of those                                 conjunction terms because every single                                 one of these terms has to be present in                                 a document for it to actually get a hit                                 when you when you run a query over it                                 you can say okay I only need one which                                 means that we can we have a bit of                                 leeway in how we decide which of these                                 terms to index and you can say how did                                 it well longer terms tend to be rarer so                                 a term like the there is gonna be hid in                                 every single document you don't really                                 want to do that but a longer term like                                 Jabberwock for example it's going to be                                 fairly unusual so that's a better term                                 to index that's gonna hit you know any                                 document that comes in with Jabberwock                                 and it needs to hit that one but                                 anything else that has that in it is not                                 going to match so we can open all that                                 one when you're when you're requesting                                 through the the query tree okay you                                 might have some clauses that actually                                 have quite a lot of terms underneath                                 them so you've got should clause that                                 has a bunch of other should clauses                                 underneath it so you got                                 two terms there on the other hand you've                                 got should clause that's right you've                                 got must cause that has lots of sugar                                 causes underneath it on the other hand                                 you've got a must close that it's got                                 just one term underneath it then okay                                 let's you'll tend to prefer the one with                                 just a single term because again that's                                 fewer terms to index and you're less                                 likely to hit but there are fields that                                 you want to avoid so for example if                                 you've got quite a lot of the queries we                                 can that we have are of the form                                 category X and massive great query and                                 if you're being naive about it then                                 you're gonna say okay well the category                                 X is actually that's the shorter term so                                 let's just index that but it turns out                                 that the category is something that is                                 has very low cardinality and so say                                     of your documents coming through have                                 category X they're all going to get run                                 all those queries that are indexed under                                 that are going to get run and in fact we                                 did I came across this for a client that                                 just working on now where we found that                                 we were we were really not cutting out                                 very many queries and it was because it                                 was using this naive oh okay there are                                 fewer terms and this Junction florist                                 and this one so let's index everything                                 under here and it ended up indexing a                                 really really common term so we do this                                 that we have something called a term                                 waiter which will it takes as input all                                 these various different sub clauses and                                 it runs a number of thing of rules over                                 those sub clauses and gets the score out                                 and the one with the best score is                                 indexed and again this is pluggable so                                 you can choose you can tune it a lot of                                 this stuff is it depends very much on                                 your corpus of queries and on your                                 corpus of documents so we can't say X is                                 going to work for everything yeah some                                 cases well these fields are better in                                 these use cases these fields are better                                 in these use cases so you need to tune                                 it for for your use case and for your                                 set of documents up for your set of                                 queries more complex query things like                                 proximity queries and phrase queries and                                 you can just treat them as conjunctions                                 so again you just need a single term out                                 the phrase and it runs to the term                                 waiter and it chooses that best term so                                 again a phrase like the Jabberwock you                                 can index jab or                                 one cards of fun you saw in the the                                 query earlier that we had lots of fun                                 things with wild cards you had prefix                                 wild cards and suffix wild cards                                 how can you index something that is                                 going to hit the it's going to hit the                                 bits of the wild card that you're                                 interested in what we do is whether                                 there's actually two ways of doing it                                 you can do it by there you can extract                                 the longest in variant substring so if                                 you've got a wild card that's got an                                 asterisks with a beginning and ask first                                 at the end you say okay we'll take the                                 bit in the middle and we'll index that                                 and then a document time when you're                                 building your query out of the document                                 as well as taking all the terms from                                 that document you take all the engrams                                 of all the terms from that document as                                 well so you have the you're going to                                 match any sub strings for the terms and                                 the document all you can suit you can do                                 you can say well actually we're not                                 going to be able to we can't get                                 anything useful out of this well card                                 theory the wild card some query we're                                 going to index it under a special token                                 court on any token which means that all                                 documents are going to match against                                 this query thing is that normally this                                 will appear within a conjunction                                 somewhere so the term waiter is going to                                 check out any tokens in preference it's                                 going to select any other term in                                 preference to an any token so quite                                 often you'll find that even if you've                                 got something with loads and loads of                                 wildcards in it                                 none of those well code tones actually                                 get indexed they get thrown out by the                                 term waiter again it depends on your                                 your documents it depends on your query                                 set all these things need to be measured                                 in experimented with so on the other                                 side how do you take this your input                                 document and turn it into a query you've                                 got this query index you have a bunch of                                 queries which are indexed with against                                 their individual terms and you need to                                 now work out which of those queries are                                 likely to match the documents coming in                                 so the simple answer is you take your                                 document you run it through your                                 analyzer you pull out all the terms from                                 that document and you make a massive                                 great disjunction query and run that                                 against the query index and everything                                 that matches it's something that is                                 likely to hit so you have a specialized                                 collector which you so each each query                                 that generates a hit you then pull that                                 query out and run it against the                                 document we can you can be fairly                                 efficient about this                                 in terms of generating the work pulling                                 all the terms out of the document                                 because the document is already going                                 through analysis in order to be                                 searchable you're creating your memory                                 index that memory index will have a                                 terms a name so you can just iterate                                 through that and pull out all the terms                                 build that into your disjunction query                                 if you have wildcard queries there then                                 you can run that through through the                                 Engram filter so you're pulling out all                                 the substrings of all the terms as well                                 obviously then you also need to                                 deduplicate it because otherwise you                                 know subsequent terms may have they                                 share lots of their substrings and you                                 end up with a disjunction otherwise you                                 end up with a dysfunction query that's                                 actually got lots and lots of the same                                 duplicate clauses in there so we run her                                 we put a d-- duplicate deduplicating                                 token filter on there and we also need                                 to be careful about the the maximum                                 length of terms we had so I had one                                 particular document which was coming                                 through and killing everything and just                                 causing out of memory errors and slowing                                 it all down I don't know work out what                                 was happening it turned out it actually                                 contained that base                                                  which was you know                                                      spaces in it and it was going into the                                 the Engram filter which was then                                 dutifully creating all possible                                 substrings of the                                                      yeah we you put a maximum on there the                                 interesting thing about putting the                                 maximum on of course is that what that                                 maximum should be depends on what                                 language you're using because something                                 like English you can put it about                                    terms and that's going to cover the vast                                 majority if you're doing it German                                 Germans like they're really really long                                 words so you need to put it a bit bigger                                 for different languages this was in fact                                 for Danish which I don't speak at all so                                 it's been quite interesting working with                                 lots of Danish language stuff and people                                 cut them up and saying this this clearly                                 doesn't match I have to say doesn't it                                 and I know you tell me and the other                                 thing you can do is when you've got this                                 you know obviously running a very a very                                 large disjunction query over something                                 over your query index if you have lots                                 of terms in there that aren't going to                                 match anything that's still a bit of a                                 waste each one of these still has to you                                 know it has to pull the terms in                                 and create a scorer although lots of                                 those scores will be null so in order to                                 cut that down we can actually create a                                 token filter that's based on the terms                                 of name of the memory index and strip                                 out anything that's any of the terms in                                 the document generated by this that                                 aren't I'm not going to match anything                                 if they don't exist in them in the query                                 index as well there's another way of you                                 know just making everything slightly                                 more efficient numbers this is the                                 important bit so this is a benchmark I                                 did a couple of weeks ago on a it's a                                 representative corpus for a client that                                 we're working with at the moment                                 and they've got                                                    running it on this so you know this is                                 not the hard work this is not server                                 hardware this is just a MacBook it takes                                 about five seconds to run                                               queries over an average document which                                 is not bad but if we put the preacher on                                 there exactly the same thing it'll do it                                 in a quarter of a second so that's a                                    times                                                                have an SLA that says I need to do                                 things in it approximately                                          second if you don't have the preacher on                                 there then you need                                                  machines so this is a nice a nice saving                                 and looking at what it's actually doing                                 what the pre searcher is actually                                 cutting out of those                                                     running an average of                                     they're still obviously there's a fixed                                 cost to creating the disjunction query                                 from a document that comes in so the                                 without the pre search or with the match                                 help researcher that says just get give                                 me everything give me all the queries it                                 it takes no time to build that to                                 suction query it's not built in as its                                 own query it's just running everything                                 with the pre searcher it's taking of                                 that point to five seconds                                 about                                                          milliseconds that is actually building                                 the query so there's not it's not so                                 completely free there are trade-offs                                 there and again you need to judge that                                 on you need to measure it you need to                                 judge it                                 your document set your query set getting                                 matches out again is pluggable you have                                 something called a candidate matter                                 which is given so for each query that it                                 matches it then passes it to the                                 candidate matcher and you can then do                                 you can run your own query and so that                                 you can customize how exactly gonna run                                 the query so it comes with your outcomes                                 with a couple of standard ones we've got                                 the simple matter which gives you a yes                                 or a no answer did this match did this                                 not match you've got a scoring match set                                 which will go and do the calculate the                                 score now this is this is useful in some                                 cases just using the standards Lucine                                 tf-idf scoring isn't actually going to                                 help very much because you've got a                                 single document there so IDF is always                                 one so it can't depend you can create                                 your own scoring which will generally be                                 creating your own similarities and that                                 will give you again you have to you have                                 to be careful about how you look the                                 about relying on scoring on what you're                                 going to do with scoring but still it's                                 there if you want to use it you can use                                 it the the fun one is the interval                                 matcher because this tells you the exact                                 hit position of everything that matches                                 and this is particularly useful for                                 media monitoring particularly when you                                 have you know if you have an absolutely                                 gigantic query and it comes up with a                                 hit against a document that's three                                 sentences long it's very difficult to                                 work out wait a particularly that                                 document is wrong so in media monitoring                                 this is normally a first pass you you                                 run this you've got your document stream                                 you run these queries against it now                                 give you a set of things that it's found                                 but it's normally then someone will                                 actually go through and by hand check                                 that all of these things make sense                                 because you get false positives all the                                 time and if you want to improve your                                 reduce your false positive rate you want                                 to improve your queries you want to                                 refine your queries you need to know why                                 something has matched                                 and a standard highlighted that's kind                                 of difficult because the standard                                 highlights it doesn't tell you exactly                                 what's matched it gives you a guess it                                 kind of says this is what I think it                                 might have matched but that's often not                                 good enough so there is a branch there                                 is a JIRA open on the scene called                                 loosing two eight seven eight which was                                 largely written by this guy down the                                 front here Simon he did all the                                 difficult stuff I did some boring stuff                                 to make it fit in with everything else                                 and it allows you to determine the exact                                 exact positions of everything that has                                 hit from from a leucine query it also                                 uses something called minimum interval                                 semantics to efficiently run proximity                                 queries so the first iteration of this                                 we were using span queries and spang                                 queries work but they're kind of massive                                 they take up enormous amounts of memory                                 and they're quite slow whereas the                                 minimum interval query ones used much                                 less Ram and they're much quicker I                                 don't have actual numbers in this slide                                 deck about that but it's yeah on the                                 order of four time four or five times                                 faster and about half as much memory                                 taken up with these particular documents                                 in these particular queries and so yeah                                 we have the intervals match which runs                                 out this is this runs using a fork of                                 leucine that I'm maintaining at the                                 moment it will will get merged into                                 trunk at some point really I've been                                 saying it's from it's gonna happen                                 tonight                                 all right so but for the moment this is                                 right so if you're using Luwak there are                                 two versions of the work out there one                                 of which runs off the of this fork that                                 I'm maintaining which gives you the                                 intervals match and another one which                                 just runs off straight leucine for eight                                 and doesn't have any intervals matching                                 goodness but it also it does have a                                 simple match from the scoring matcher                                 and at some point I'll probably try and                                 do a highlighting back sure in there as                                 well so you'll run a highlighter over it                                 and you can use the usual leucine                                 highlighters in there and the other                                 thing the intervals match therefore is                                 useful for is actually if you're writing                                 your own presets or implementation                                 it's useful for debugging it because it                                 will cut it can tell you which terms in                                 a query have matched from from the so                                 it'll tell you what what terms in the                                 query made the pre search to select that                                 particular query to run which is very                                 useful when your so for things like the                                 the wildcards when I was writing the                                 various well collide implementation I                                 was getting lots of spurious matches and                                 it turns out that basically I tend that                                 I'd done it horribly wrong                                 and it wasn't obvious to me how I done                                 it horribly wrong until you go and see                                 which things it's actually matching on                                 and say okay that that term is clearly                                 wrong I can work out why it is that it's                                 matching on that term so I said Luke is                                 all pluggable it's all extendable you                                 can create your own query extractors so                                 at the moment it will fall back to if it                                 encounters the query that it doesn't                                 know how to get terms from it'll fall                                 back to running just extract terms on                                 the query bath and that doesn't make                                 sense so for things like range queries                                 there we have the Ameritrade queries in                                 a lot of the the queries that I'm                                 dealing with but they tend to be added                                 on those filters so I can get away with                                 not trying to work out how to index them                                 I can just index them with an any token                                 and then the term weights will throw                                 that out this won't actually happen in                                 all cases sometimes you really do need                                 to work out how to index a new range                                 filter when I talked about this in                                 Dublin last November and someone came up                                 with a really kind of cunning idea of                                 how to do this unfortunately I was on                                 loads of painkillers at the time and I                                 couldn't I had near an inner ear                                 infection I couldn't hear anything so if                                 that would anybody hear or if anyone                                 comes up with a good idea please come                                 and tell me afterwards and write it down                                 so I don't forget at this time but yeah                                 if you sometimes you want to create your                                 own custom queries then you can create                                 your own custom query extractor as well                                 and say ok this is how I want to index                                 this query you can actually say I'm                                 gonna create a completely different pre                                 search or implementation I think your                                 way of doing it is rubbish I've got a                                 much better idea                                 and it's preset so it's just it's two                                 two methods its index query and build                                 content index query for when you've got                                 a query coming in and build query from                                 when you're building a query from a                                 document you have your own idea of doing                                 that then you can just plug it in and                                 everything else will work around it                                 you can create your own matches there's                                 a so the standard the candidate match                                 again you just have to override a                                 particular method which says here's a                                 query here's a highlight query use these                                 to do whatever you want whether using                                 getting in any whatever information you                                 want out pull requests are always                                 welcome particularly if it's something                                 complicated that I don't understand then                                 you write it and give it to me and I'll                                 pull it into my library that's that's                                 how open-source works                                 yeah and that's and there's the github                                 repository there and yeah I think I've                                 got loads of time for questions because                                 I kind of run through that a little                                 faster than I was expecting                                 there's that's me as well you can                                 contact me Ellen at flax or I'm on                                 Twitter at Romsey anybody have any                                 questions                                 thanks for the talk if you have any                                 questions please wait for the microphone                                 and thank you for a talk one question I                                 can't in not queries and if yes how are                                 you doing this so if it not queer it so                                 not queries in a billion basically we                                 just ignore them because if you think                                 about it a knock Clause is saying if                                 this is present then don't match it in                                 which case you know if so if it's                                 present in the document that's coming in                                 you don't want to match it so you don't                                 want it to hit on that on the the query                                 index so you can just ignore them only I                                 want all the chemistry she does not                                 contain some some time probably three                                 case okay yeah but generally you'll have                                 a so yeah in which case it'll end up                                 being run against every single doctor                                 but then you you kind of have to run                                 that against every single document                                 because every single document could                                 conceivably match that there's not an                                 easy way of cutting down the query space                                 for that it's the quite often you'll                                 find said things like wildcards                                 someone's got a stand a asterisk or                                 previous query of a you think well okay                                 that's going to blow up and that's you                                 know if you're storing a in your terms                                 index then in your query indexed every                                 simple documents going to match that                                 which is true but every single document                                 is probably actually going to get hit on                                 that query as well so you do get                                 pathological queries which are going to                                 slow everything down unfortunately                                 that's the nature of the situation and                                 you know yet if you have a pathological                                 query then there's not much you can do                                 about it you do have to run that against                                 everything                                 um the question is more about scaling                                 out if you have a huge stream of data a                                 large large throughput you may need to                                 share that out and break that stream and                                 send it to multiple servers do it does                                 have any capability for managing queries                                 across a number of instances so yeah                                 that that's the big question is how to                                 shut out the queries at the moment so                                 the bank itself is just a library it's                                 not a full set full scale solution and                                 so we built that the way I know we do is                                 I build web services using drop wizard -                                 which includes live like everyone could                                 be some drop wizard love and yes so so                                 far all the the crew sets we've dealt                                 with have been sufficiently small that                                 they will fit into RAM on a server but                                 yeah I can see how yeah in certain cases                                 you would want to say okay let's split                                 this out the simple ways to say okay                                 we'll just partition it bang down the                                 middle and have these two you know you                                 do something use a message queue or                                 something like that to split your                                 document screen into two and then                                 recombine it at the end yeah Louet                                 doesn't do that out of the box did if                                 you want to do that then you can pay me                                 to build something for you that will do                                 that or somebody else but yeah I would                                 do deal with geolocation queries how I                                 deal with geolocation queries like so                                 yeah so geolocation queries are kind of                                 like that it's a generalization of                                 numeric range query of any kind of range                                 query and yeah at the moment we tended                                 to ignore that primarily because these                                 things normally you're not saying give                                 me everything that's within this                                 bounding box you're saying give me                                 everything within this bounding box that                                 also matches X so we can kind you can                                 kind of say ignore it okay okay we'll                                 get you over give everything that                                 matches X and then you have to go and                                 run run all those all those queries                                 against it but                                 with with the query sense that we've                                 been dealing with and I don't think                                 we've had to deal with anything that has                                 a do geo-tagging and yet I've got                                 someone's talking about it at the moment                                 and yet that will probably involve us                                 having to work out how to do the the                                 reverse indexing of range queries I                                 think the idea one possibility is to try                                 and partition the range up and say okay                                 well we can divide that range up into                                 buckets and index terms from these                                 buckets with different levels of                                 granularity and then when the document                                 comes in you you should have something                                 that will match one of those buckets but                                 which might work but it might not so                                 obviously we need to need to test that                                 and you know in most cases you can get                                 away with just not indexing that but you                                 might find yeah if you run a benchmark                                 and find found that actually you're                                 getting lots and lots of false hits                                 because of that then yeah then it's                                 worth putting the the time in to try and                                 work out how to reverse in to do the                                 reversing index of that anybody else got                                 Seekers delight no more no okay Ellen                                 thank you very thank you for your talk                                 this                                 you
YouTube URL: https://www.youtube.com/watch?v=M3c5_7DxpIk


