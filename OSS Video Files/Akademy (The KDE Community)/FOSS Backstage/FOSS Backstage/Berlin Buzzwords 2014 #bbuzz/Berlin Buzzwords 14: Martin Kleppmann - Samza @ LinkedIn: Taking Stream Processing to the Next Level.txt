Title: Berlin Buzzwords 14: Martin Kleppmann - Samza @ LinkedIn: Taking Stream Processing to the Next Level
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	Stream processing is an essential part of real-time data systems, such as news feeds, live search indexes, real-time analytics, metrics and monitoring. But writing stream processes is still hard, especially when you're dealing with so much data that you have to distribute it across multiple machines. How can you keep the system running smoothly, even when machines fail and bugs occur?

Apache Samza is a new framework for writing scalable stream processing jobs. Like Hadoop and MapReduce for batch processing, it takes care of the hard parts of running your message-processing code on a distributed infrastructure, so that you can concentrate on writing your application using simple APIs. It is in production use at LinkedIn.

This talk will introduce Samza, and show how to use it to solve a range of different problems. Samza has some unique features that make it especially interesting for large deployments, and in this talk we will dig into how they work under the hood.

Read more:
https://2014.berlinbuzzwords.de/session/samza-linkedin-taking-stream-processing-next-level

About Martin Kleppmann:
https://2014.berlinbuzzwords.de/user/227/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              ok hello everybody thank you very much                               for coming I'm so delighted to be here I                               know it's getting towards the end of a                               really packet conference so everybody's                               a bit tired but i'll try and keep it                               interesting keep everyone awake are you                               awake hello yay good i want to talk                               about apache Sansa an open source                               project which I work on for distributed                                stream processing processing high volume                                data streams just very quickly about                                myself so did you know who's this idiot                                talking to you hear my name is Martin                                clapman I am currently working at                                LinkedIn and LinkedIn is sponsoring this                                development on Samsa before that i                                co-founded to startups so I've seen                                things from the small company side as                                well the second which was called                                rapportive it was acquired by linkedin a                                couple of years ago and still working at                                linkedin now I'm also a bit active in                                Apache working on avro and Sam sir now                                also trying to write a book on                                data-intensive applications for O'Reilly                                so that's a whole lot of stuff anyway                                you can find me online as well I                                primarily want to talk about Sam sir but                                I can't really talk about Sam sir                                without talking about kafka these are                                two separate projects but both have come                                out of LinkedIn both share kind of the                                same underlying mindset and although                                they do different things Sam sir is a                                stream processing project kafka is a                                kind of a message broker so it's the                                thing that transports any messages from                                A to B they you can use each                                individually separately they don't have                                a strict dependency on each other but                                they do do they do go together really                                well i kind of think of it like you know                                the like beer and curry bus you can have                                each taken by itself and it's okay by                                itself but take the two together and                                really perfect so a bit of a background                                what kind of things are we actually                                trying to do with these projects one                                example might be if you have a website                                with some kind of news feed like                                features you want you know various                                people posting updates or maybe liking                                things or commenting                                on things or changing their job title or                                whatever it be a lot of stuff happening                                and you want to make sure that that                                information is shown to the right people                                to people who will find it interesting                                who will likely find it valuable engage                                with it it needs to be reasonably timely                                so you don't want to have to wait four                                hours from posting an update until                                people can see it there might be                                complicated business logic associated                                with this like privacy settings so this                                is one example of the kind of things we                                want to do another which is a bit more                                internal two systems would be something                                like updating a search index so if you                                think about LinkedIn it's kind of like                                one massive search index really so you                                add a keyword to your profile and then                                you go to the search box and you search                                for that keywords to see if you appear                                in the search results so that means we                                need pretty near real-time indexing of                                any updates of data that happens here so                                that you can find yourself again doesn't                                have to be totally instantaneous but                                within a couple of seconds is usually                                what we aim for their even more                                internally to the system you know we                                aggregate a lot of logs metrics internal                                data but which service is calling which                                other data that's a huge volume of stuff                                it's really valuable to able to analyze                                that do things like if suddenly there's                                a spike of exceptions being able to                                quickly react to that so again latency                                is fairly critical there within a couple                                of seconds or minutes we want to be able                                to respond to things now if you think                                about sort of data processing systems in                                general there's kind of this spectrum on                                the one extreme you've got synchronous                                tightly coupled services where every                                time something happens you make say a                                rest call on RPC call or whatever to be                                to some other service and that that                                 obviously communicates the information                                 immediately to that other service which                                 is fine for a lot of things but the more                                 of these calls you add the more you                                 tightly couple all of these services and                                 the whole thing can become a bit of a                                 nightmare if there's any individual part                                 of the system that slows down the entire                                 thing slows down so it's really                                 problematic on the other extreme you've                                 got systems like                                 hadoop mapreduce and all of the                                 additional kind of data analysis tools                                 that are coming out which work in a sort                                 of batch processing fashion right where                                 you accumulate a whole bunch of data of                                 some kind of fixed size and then you run                                 some kind of query or analysis on it and                                 then sometime minutes hours maybe even                                 days later you get some results so                                 that's quite nice because you can                                 decouple applications you can have a                                 data set in HDFS once and all sorts of                                 different analyses can be run on that                                 but on the downside there's a lot of                                 latency so we're Samsa fits in is kind                                 of in between these two so it's not                                 synchronous it's for processing that                                 happens asynchronously you still want                                 that nice decoupling that you would get                                 from data pipelines in something like                                 Hadoop but you don't want to wait as                                 long and the model of communication will                                 be very familiar to many of you you know                                 you've got a bunch of users making                                 requests to services those requests are                                 served but as a side effect various                                 events get emitted and at LinkedIn we                                 use Kafka heavily for this and then                                 these events can then in turn be                                 consumed for all sorts of different                                 purposes it might be for purposes of                                 analytics both to show to users or                                 internal analytics you might be updating                                 caches or maintaining indexes you might                                 be sending out push notifications email                                 notifications all sorts of things can                                 happen so this is a kind of pop                                 publish-subscribe communication model                                 right and the types of events we can                                 deal with is it's a very broad spectrum                                 you can think of anything you can think                                 of tracking events which would be                                 clickstream type things so a user                                 clicked on a particular item at a                                 particular time and within a particular                                 session you can even think of database                                 changes you know whenever you make a                                 right to a database you can think of                                 that also as an event something happened                                 namely for primary key X some value                                 changed from Y to Z you can think of any                                 logs you have even system level metrics                                 all of this is kind of event                                 that we can be that we can process and                                 indeed at LinkedIn all of these things                                 do go through Kafka and just to scope                                 the problem a bit so that's the style of                                 system that this is that we're designing                                 here we're thinking of many independent                                 consumers which might be run by                                 different teams across a big company we                                 want the system to have very high                                 throughput of millions of messages per                                 second we want reasonably low latency                                 usually sub                                                           it's like single-digit milliseconds but                                 we're not aiming for you know micro                                 second type things that's out of scope                                 just to give a bit of an idea of the                                 kind of scale we're talking about here a                                 couple of big numbers from LinkedIn's                                 production system as of a week or two                                 ago we use cathcart very heavily for                                 these kind of things we pumped hundreds                                 of billions of messages per day through                                 the system at peak its latest i saw was                                                                                                      message is you can probably work that                                 out I think just under                                              average or so so that adds up to quite a                                 bit of network bandwidth actually this                                 is distributed across hundreds of                                 machines across multiple data centers                                 all of that is just kind of to give a                                 context of what sort of scale we're                                 dealing with so now to Sansa some says a                                 framework that allows you to take all of                                 these message streams and process them                                 and to make that processing as simple as                                 possible while still giving you really                                 powerful tools to work with but the base                                 level API is actually very simple it it                                 looks somewhat like a matter in the                                 MapReduce programming model so at the                                 moment there's this Java API sams itself                                 is actually implemented in Scala you can                                 use whatever JVM language you fancy                                 interface is very simple there's one                                 method which is called process and                                 that's called every time the message                                 comes in and that's it really so every                                 message consists of a key and the value                                 the key is useful for partitioning which                                 I can explain later the message                                 collector allows you to send messages                                 out again so the mess you get one                                 message in zero or more messages can be                                 out                                 as a result of this process call and the                                 coordinator lets you do kind of cluster                                 level management stuff so if you want to                                 implement a data processing or analysis                                 pipeline with this it's useful to take a                                 step back and just as a reference point                                 think about what we do on the batch                                 processing side first okay so with                                 MapReduce or with a higher-level                                 languages like Pig cascading etc similar                                 things apply to spark to any any of                                 these many tools that we've heard about                                 actually these days there are a couple                                 of kind of base level operations they do                                 so number one is filtering records you                                 know either something matches a                                 condition or not that's clear mapping                                 which is just taking one and producing                                 some transformed version of the of the                                 record again one record at a time next                                 now it's starting to get more                                 interesting you might want to join                                 multiple data sets together so take a                                 key of a record from one data set key                                 from record in the other data set and                                 match those up where the key is equal or                                 some function of the key very similar to                                 join is grouping that would be finding                                 all of the items with the same key in                                 one data set then once you've grouped of                                 course you can aggregate as you know                                 some count average whatever you like and                                 crucially you can take the output of one                                 job and feed it in to the input of the                                 next job so in MapReduce you know you                                 would write the output to HDFS to some                                 directory and then you can start a new                                 job or somebody else can start a new job                                 which reads that directory and uses that                                 as its input like that you can build                                 these nice pipelines so we really like                                 that way of operating so can we do the                                 same thing for streams with streams you                                 know there's no beginning there's no end                                 it's just constantly data coming in and                                 we need to deal with it as it happens so                                 if we take each of these operations who                                 want to do and adapt it to streams well                                 filtering it's easy okay you know you                                 take one record in either you pass it on                                 or you throw it away                                 no problem again map operation again                                 very simple you take in one record do a                                 bit of processing on it locally and then                                 pass the modified version on again no                                 problem at all join is where it gets                                 more interesting so you have two streams                                 coming in each of which has some key                                 inside the records now you know what                                 what are you actually joining you have                                 one event which keep with key X on one                                 stream comes in and then at some point                                 later you don't know when another event                                 with the same key X may come in on the                                 other stream somehow we want to match                                 that up we'll talk about that in a                                 minute grouping again eyes I said is                                 actually a very similar operation to                                 joining except that you're just doing                                 the same thing on one stream you're                                 going to have to somehow remember the                                 messages because you don't know when the                                 next message is going to come up                                 aggregation well once you've got the joy                                 nor the the grouping aggregation is kind                                 of doable but you do there's this kind                                 of tricky question about when do you                                 know when you're done you know if you                                 want to aggregate all of the events from                                 one user session for example if you                                 don't know when the user of closed their                                 browser you know you kind of wait and                                 then probably after some time out you                                 say maybe in some cases there's some                                 kind of end event that you can pick up                                 but not in general so oh yes the final                                 of these points the output of one job                                 becoming the input of the next job again                                 we want to use that because it lets us                                 build these really scalable composable                                 data pipelines but we do need to think                                 quite carefully what happens in the case                                 of faults so if a machine dies if                                 somebody deploys a bad version of the                                 code any number of bad things can happen                                 we just want to maintain sanity and that                                 as well so what I want to focus on right                                 now is the stateful parts of stream                                 processing as i said the kind of basic                                 filtering mapping that's easy but the                                 joining the grouping the aggregation                                 that's what's hard so let's work with an                                 example makes it a bit easier to                                 understand say you have a website which                                 has ads on it                                 and you want to know the click-through                                 rates for your ads so you've got events                                 coming in saying oh I had an ad                                 impression i simply loaded a page with                                 an ad on it and on the other side you've                                 got ad clicks which is every time                                 somebody clicked on an ad so if you want                                 to know the click-through rate you need                                 both of those numbers you need to know                                 how many times the ad was shown and                                 which of those times it was clicked on                                 so the joy in here needs to happen but                                 if you think about it there's a problem                                 here so firstly I might load a website                                 load a page with an ad on it then go off                                 for lunch then an hour later come back                                 to my machine and the website is still                                 there and I see the ad and click on it                                 so now there might be an hour delay or                                 even more delay between the impression                                 event and the click event do you still                                 want to join that you know that probably                                 needs to be some kind of maximum window                                 of time over which you're willing to                                 join otherwise you would just end up                                 waiting forever the opposite can happen                                 as well it could happen that you                                 received the click event before you                                 receive the impression event if the                                 impression of a queue is backlogged a                                 bit well you know they'll they'll be                                 some delay in the processing there so                                 you can get out of order delivery that                                 also makes it interesting and so for                                 stream processing we call this a window                                 join where you say okay there's some                                 window of time which may be a minute or                                 an hour or whatever you is appropriate                                 for you over which you willing to make                                 that join but if you want to do that you                                 have to actually buffer the events for                                 that period of time you have to remember                                 that I saw an impression event for some                                 impression ID some unique ID up to an                                 hour ago and then when the click event                                 comes in you can see our I remembered                                 earlier that this event was here so now                                 I can join it so you require state you                                 have to remember for each key that you                                 want to join on what were the messages                                 on the other stream that you saw and for                                 that you need some kind of key value                                 store so how do we implement this in the                                 simplest case you know you could just                                 keep it in memory if it's a small amount                                 of data but                                 let's assume you want a larger window of                                 time so you can't actually fit the data                                 in memory so well one option is you                                 actually put all of that in an external                                 database so you choose Cassandra HBase                                 or MongoDB or react whatever takes your                                 fancy every time a message comes in you                                 all you then go and store it in this key                                 value store and then every time a                                 message comes in on the other stream you                                 take that take the key check do I have                                 something to join with in my store and                                 if so are yes join it and omit the                                 result if not oh okay or maybe you have                                 to store it in order to handle the                                 ordering the problem with using this                                 kind of key value store is the things                                 can get rather slow so samsar is                                 optimized for processing for                                 high-throughput and we can actually get                                 like hundreds of thousands of messages                                 per node through samsa and however if                                 you're talking over the network for                                 every single message you know the QPS                                 you can get out of a database will vary                                 of course a lot by database what kind of                                 hardware you run it on but it can easily                                 be orders of magnitude lower than the                                 throughput so if you do it this way you                                 really risk dropping your throughput of                                 your stream processor massively we don't                                 want to do that so alternative this is                                 where samsar is different from some of                                 the other stream processing frameworks                                 you might have seen like storm what we                                 do is actually every stream processor                                 has with it a little key value store                                 which is right there on the same machine                                 in fact it's in the same process at the                                 moment we're using leveldb for that                                 although actually we're having a few                                 performance problems so we're looking                                 into rocks DB other as in which is                                 Facebook's fork of leveldb but the idea                                 is very much the same because this is in                                 process we can read and write to their                                 things super fast which is absolutely                                 wonderful there's a problem with it                                 which you might be thinking of already                                 but I will come to that in a minute                                 first let me give another example to                                 just make clear                                 quite how useful this kind of stateful                                 stream processing is say you wanted to                                 implement Twitter in Twitter in the                                 simplest kind of possible incarnation                                 you've got two types of events that can                                 happen one is a follow or unfollow event                                 which is which happens every time some                                 kind of follow status changes and the                                 other is somebody tweeted or something                                 and so this is quite interesting now                                 because you can take these follow events                                 and build up the social graph the                                 follower graph and you can take the                                 tweet events and every time someone                                 tweets something you know the list of                                 all of their followers so you write that                                 message out to each of their followers                                 and they can then get notified or it can                                 be streamed to their mobile app or web                                 socket to their browser whatever it be                                 right so how do we implement something                                 like this you have to input streams                                 which we want to join and we need to                                 maintain again some kind of state so say                                 you have two messages coming in first                                 the follower vent so first the event                                 saying user                                                                                                                                   in your key value store so you do                                 something like have a mapping save from                                 user                                                                 followers and that list now includes                                     because we said                                                          and I'll use a fine day to tweet                                 something they say I'm at Berlin                                 buzzwords and it rocks and so all of the                                 followers need to be that that message                                 now needs to be delivered to all of                                 those followers of user                                            stream processor looks in our key value                                 store sees that list of followers and                                 for each of the followers writes out a                                 new message saying notify this user in                                 this case                                                         waiting for them so the result is then                                 some kind of inbox for each user or                                 timeline as Twitter call sir and once                                 you've got that                                 you condense chain further things off it                                 so you could have a job which sends out                                 push notifications or streams to a                                 browser or whatever it be right so this                                 idea of keeping the state is a very                                 powerful one because it allows you to do                                 these kind of joins and what Sam's that                                 tries to do here is to move the                                 computation and the data into the same                                 place it's maybe a bit comparable to the                                 you know the placement of mappers in in                                 MapReduce where you try to put the                                 mapper locale with locality to the data                                 on HDFS here it's kind of the other way                                 around we've started up our protests on                                 a machine and we make sure that the                                 state stays there with the process                                 however there's a big problem with this                                 and that is how do we make this whole                                 thing fault-tolerant now for that I need                                 to explain a bit about the architecture                                 of Sansa how it actually works                                 internally so you might actually find                                 this quite interesting on the basis you                                 have multiple machines and on each the                                 machine probably the first thing you                                 will deploy is Kafka so Kafka acts as                                 the message transport mechanism here                                 Kafka is itself replicated so every item                                 of data every message you write to                                 kathcar will be copied onto however                                 machines you configure say three                                 machines so even if one of those                                 machines go away you know that the data                                 won't be lost the answer the first thing                                 you install the second thing you install                                 is yarn so Sam's actually runs on top of                                 yarn if you have an existing Hadoop to                                 cluster then you can just run it on                                 there and it should work absolutely fine                                 there have been various talks about yarn                                 already so i won't go into too much                                 detail of how it works but the general                                 idea is that each machine has a node                                 manager running on it which is in charge                                 of all of the processes running on that                                 machine and these processes in yarn                                 terminology are called containers and                                 Samsa provides a yarn container and your                                 code your processing                                 code is loaded into those containers and                                 started up so within each of those                                 containers you've got a task instance                                 which is running your code and each of                                 these task instances has this little                                 embedded key value store that I was                                 talking about now now what happens if an                                 entire machine goes boom and all of this                                 is lost so now okay throw away that                                 machine we've got another machine over                                 here on the cluster it's really got                                 Kafka installed on it so at least Kafka                                 we don't need to worry about that will                                 have already been part of the                                 replication but at the moment there's                                 just an empty young node manager sitting                                 there yarn will notice that oh we've                                 lost some containers I guess we should                                 start those up again so it goes and                                 starts up some Samsa containers again                                 Sansa goes ah yeah we've got some empty                                 containers which tasks should they be                                 running and those tasks which were                                 previously running on the failed machine                                 and are we started in the containers on                                 this new machine so far so good but                                 these little key value stores that are                                 attached to each of the stream                                 processing tasks and are empty because                                 we didn't replicate that data you know                                 that those key value stores they're just                                 on the local file system of each machine                                 and that is sadness because we don't                                 like losing data so how do we make sure                                 that we don't lose data this is one of                                 the points where I think Samson's really                                 cool actually I can say that it's really                                 cool because I didn't invent it so I'm                                 not taking any any credit for this at                                 all the idea is every time you write to                                 this local key value store that's                                 embedded in your process you also write                                 to Kafka as I said Kafka is replicated                                 and durable whenever you write something                                 to Kafka you can be sure that it won't                                 be lost it has a key value model you                                 can't look up things by key so it                                 doesn't provide a key value interface                                 all you can do is append to the log                                 but it can do that very very fast it can                                 append to the log incredibly quickly                                 with millions of messages per second as                                 I was saying so what we're effectively                                 doing here is building our own database                                 replication log kind of you know a bit                                 like a writer head log that you would                                 get in a relational database every time                                 you write to your key value store you                                 also write to their stream of things and                                 most of the time nobody's reading from                                 it but that's totally fine Kafka just                                 sits there Kafka has a few optimizations                                 for exactly this kind of thing so if you                                 write the same key over and over and                                 over again that can get compacted in the                                 background so that stops this log from                                 growing unbounded and it means that the                                 restore time is then bounded as well and                                 that's a nice new feature in Kafka                                     if you haven't seen it yet anyway with                                 all of those rights replicated to Kafka                                 we can now go back to this Samsa starts                                 up okay we've got these key value stores                                 but they're empty so let's just consume                                 that replication topic all of those data                                 all of those messages those change                                 messages every time we wrote to the key                                 value store are still there we can just                                 suck all of that in apply them in order                                 and once we've done that we've restored                                 those key value stores to their former                                 glory then I'll contain just what they                                 did beforehand and we are happy so                                 that's quite nice just to recap so the                                 idea here is we replicate all of the                                 right to Kafka we can restore from that                                 and compaction built into Kafka means                                 that we don't end up using all the disk                                 space in the world so I was talking                                 about fault tolerance there's another                                 aspect of full tolerance that's not as                                 often talked about as machines blowing                                 up but it's actually at least as                                 important and that is things go slow and                                 when things go slow you know it's still                                 kind of working but actually everything                                 falls apart and it's the hardest thing                                 to debug because you know sometimes just                                 one thing going slow and cause another                                 thing to go slow and suddenly everything                                 is going slow and you run out of threads                                 and                                 everything is bad so we don't want that                                 to happen in a stream processing                                 environment as I said we want to be able                                 to change jobs together and they might                                 be might be consuming multiple inputs                                 may be producing multiple outputs the                                 output of one job could be consumed by                                 multiple different jobs and you want to                                 be able to compose these things very                                 freely without any constraints in                                 particular you might want different jobs                                 to be maintained by different teams                                 within your company because actually you                                 know this output of one job it's a very                                 nice interface I can you know team X can                                 just say ok we have these jobs two and                                 three and you can consume our output and                                 there'll be a certain SLA to you know                                 the reliability or the speed with which                                 data goes through there and so team y                                 and team said can rely on that build                                 their own jobs which which consume that                                 data team X doesn't need to worry about                                 the fact that it has these consumers you                                 know t-max just provides the data anyone                                 can read it now what happens if this job                                 here maintained by team y goes slow and                                 the turtle is sticking its arms in the                                 leg looking really sad in this case well                                 there are a couple of options option one                                 is you can drop data so you can say okay                                 sorry you weren't fast enough to pick up                                 the data it's gone now sorry but we                                 don't really like that I don't like                                 losing data the second option is back                                 pressure and this is very commonly                                 applied so storm for example again uses                                 this model which is well okay if you're                                 not consuming fast enough let's just                                 wait and give you some time to catch up                                 and then when you're ready to consume                                 some more data will give you some more                                 data the problem with that pressure is                                 that now the producer of this data has                                 to wait for the consumer of this data                                 and when the producer of the data is                                 waiting all other consumers of the same                                 data also have to wait and all producers                                 who are feeding into that producer also                                 have to wait and suddenly everything is                                 way                                 thing for everything just because of one                                 stupid slow job so we don't want that                                 either okay then that would cause the                                 entire system to grind to a halt so the                                 only option we have here is to queue up                                 the data so if somebody's slow to                                 consume it will just store it somewhere                                 so that when they come back and they                                 start protesting fast again that's they                                 can get the data that they missed in the                                 interim now if you're queuing again                                 there are two options either you can                                 queue up in memory and then if you have                                 high volume streams you will run out of                                 memory eventually and then again we have                                 sadness so that leaves actually only one                                 remaining option which is you have to                                 spill this data to disk which kind of                                 sounds like you know the best of a bad                                 bunch but actually Kafka writes                                 everything to disk anyway every single                                 message you write to Kafka is already                                 written to disk and it has specialized                                 in making this disk based architecture                                 work really well so actually what we do                                 with samsar is simply every single job                                 always write its output streams to Kafka                                 this is really nice because anyone can                                 then just consume those and Kafka acts                                 as the buffer the queue in between those                                 jobs and it decouples the jobs from                                 another warrant from one another and                                 Kafka can keep like days or even weeks                                 worth of buffer because disks are cheap                                 and you can use SSDs or you can use                                 spinning hard drives it does all                                 sequential I oh so it actually works                                 remarkably well Sam's are always right                                 its job output to Kafka which kind of by                                 analogy you can think of as MapReduce                                 every single processing stage                                 materializes its output to HDFS which I                                 realize it's kind of out of fashion                                 these days with things like spark which                                 try to not materialize to disk so I                                 guess this turn couldn't just be a                                 counterpoint to that not saying that                                 they're wrong just saying that actually                                 there are advantages if you write to                                 disk because you can then give the                                 stream a name you can tell anyone that                                 they can consume it there's no buffering                                 no back back pressure no dropping of                                 data required                                 it's durable which means that even when                                 things go away when machines go away you                                 can still be available if you want to                                 debug your system and figure out why                                 you're getting bad data you can just                                 attach to one of them you can just look                                 at it it's really beautiful actually and                                 it's a very clean interface between jobs                                 so to recap what I talked about were a                                 few things in Sansa and how we solve                                 those problems one problem we talked                                 about was this buffering one jobs output                                 becomes another jobs in put our solution                                 is simple we write it to kafka kafka                                 takes care of that buffering the other                                 problem I talked about beforehand if you                                 remember the key value store and this                                 state and how do we make that full                                 tolerance even though it's on the same                                 machine and just on one machine we want                                 it not to die no not to lose that state                                 if the machine dies the answer is also                                 we write it to Kafka because Kafka                                 replicates it to multiple machines and                                 makes it durable one final thing that I                                 didn't talk about big out of time but                                 it's also quite interesting to look at                                 is actually the checkpointing so if you                                 need if at some job dies either by                                 hardware or software failure and you                                 need to bring it back up again how do                                 you know where it should start well you                                 need some kind of checkpoints you could                                 write those checkpoints to zookeeper but                                 we found the zookeeper can easily become                                 a bottleneck if you're writing to it too                                 much actually we've got a system that we                                 can write to really well which handles                                 really writes really well guess what we                                 can write it to Casca and that's why                                 there's this great relationship between                                 samsar and Kafka okay so I do encourage                                 you to give it a try it's all open                                 source Kafka is a top level Apache                                 project Samsa is in the incubator at the                                 moment and definitely looking for                                 contributors as well I suggest the first                                 thing to take a look at is actually                                 hello Samsa which is a just a little                                 script which installed the local cluster                                 for you it downloads yarn it downloads                                 zookeeper and the downloads kafka starts                                 those three up and then runs a job which                                 consumes a live feed of edits on                                 Wikipedia so every time someone edits                                 page on Wikipedia did you know they                                 actually published this to an IRC                                 channel we can consume that IRC channel                                 as an input here and then write some                                 Sam's our jobs which do some analytics                                 on that you can just run it in five                                 minutes it's it's really neat so here                                 are some links for you to get started                                 there's a nice blog post by Jake reps                                 the second point here one of my                                 colleagues at LinkedIn who kind of has                                 set out the underlying thinking behind                                 samsa and this mode of stream processing                                 and there's me on Twitter and my blog as                                 well if you fancy so hopefully we have a                                 little bit of time for questions as well                                 a while ago I had some hoping that some                                 say is still quite new and quite                                 immature what's the current state how                                 production-ready is it when will you                                 expect production readiness it's rapidly                                 maturing I should say so it's still a                                 new project that's absolutely true                                 linkedin is running it in production                                 though so we've currently got I think to                                 production jobs and working very                                 actively right now to move more into                                 production as that happens of course we                                 discover issues and we're ironing them                                 out so it's linkedin is betting very                                 heavily on this actually so important                                 jobs are being put on it so if it's not                                 totally mature yet then it will be                                 pretty soon if you compared to other                                 things like rabbitmq activemq or this                                 terrible commercial USB buses palawan                                 could you replace it so I could you                                 imagine that it would be able to replace                                 it in production was the same                                 reliability so while rabbitmq activemq                                 they are more like message brokers so                                 they don't give you a a framework for                                 actually processing the data that would                                 depend on some libraries so Sam's are                                 focuses on the processing side kafka on                                 the message broker side so you could                                 definitely have a sams a job that                                 consumes from something like RabbitMQ or                                 activemq use that as an input that's                                 totally fine some of the fault tolerance                                 things in Sansa rely on semantics of                                 Kafka if you can implement those same                                 semantics with a different queuing with                                 a different broker you can get the same                                 end result but it with some it's easier                                 with some it's harder we we are we're                                 pushing most of our data through Kafka                                 rather than one of the other message                                 queues mainly for scale reasons so Kafka                                 can just handle vastly bigger throughput                                 at reasonably low cost for the for the                                 kind of message throughput we need and                                 the semantics are actually very nice as                                 well                                 hi I came across an interesting solution                                 to the slowness problem which may or may                                 not work up to the slowness problem the                                 slowness Paul tell about where they they                                 applied back pressure which then caused                                 the the sender to start aggregating now                                 that that's an interest it becomes an                                 interesting a data structure problem but                                 it seemed to work for them pretty well                                 and it seems like something that sums                                 that could actually implement as opposed                                 to something like for you know Kafka or                                 rabbitmq potentially yes so at the                                 moment we've deliberately made the                                 framework really simple and made sure                                 that those foundations are really                                 reliable so actually focusing a lot more                                 on the operational side than on the cool                                 research ideas that we have for the                                 future right now but there are loads of                                 potential extensions we could make to                                 the framework that's a good one to keep                                 in mind yes how do you compare some cell                                 for example two espurr with facilitating                                 window joints like Esper has its own                                 query language and can do whatever                                 window joins with in two hours or                                 something do I have to do it myself in                                 Samsa or sir yes so it sounds it                                 provides a very low level interface at                                 the moment just a Java API that you saw                                 and similarly you could have a Java API                                 for reading and writing to the yorkies                                 window joins I just have to do myself                                 and using this key value store yes at                                 the moment those kind of high level                                 operations you have to build yourself we                                 have been thinking a lot about what a                                 good stream processing language a                                 high-level language would look like                                 which then compiles down to these kind                                 of things we haven't rushed into                                 building one yet because we want to make                                 sure that we really understand the                                 problem domain well but this is an                                 invitation to all of you if you think                                 you have good ideas for what a                                 high-level stream processing language                                 would look like by all means please                                 implement them share your ideas that the                                 more ideas we get in this space the                                 better so something like Esper would                                 probably be a good starting point I                                 don't know how well it would work with                                 the distributed nature of samsar but I'm                                 not an expert in Esper so it seems that                                 the philosophy for me all right your                                 architecture                                 like write everything in Kafka which is                                 like a really fast thing so why do you                                 also need another local database to                                 store your data for aggregates and not                                 just write everything in calf kind                                 really from there Kafka has deliberately                                 the simplest possible data structure                                 that could work so the philosophy there                                 is all you can do really is a pen to                                 file all that there two operations one                                 is a pen to file that's the only right                                 you can do and the only read you can do                                 is take a file off set somewhere in this                                 linear sequence and start reading from                                 there so it doesn't provide key value                                 access at all the only thing you can do                                 is sequentially read messages in the                                 order that they were published and                                 because it has this really simple model                                 it can do that really really well but                                 then if you want arbitrary random access                                 to it you then kind of need to index                                 this so you can kind of think of it like                                 a heap file versus and index in a in a                                 relational database and the index is not                                 provided by Kafka so that's something                                 you can then build with Sansa one                                 question for my side please crucial                                 crucial feature is this time window                                 based storage where is it implemented                                 sorry the crucial is what it sees time                                 window they did a lifetime of the events                                 in the stream time window April time                                 time minus baseline lifetime where these                                 features implemented so at the moment                                 there's no built-in implementation of                                 window joins we give you just these                                 low-level api's of receive message                                 published message read from key value                                 store right to key value store and as                                 you can do range queries and a few                                 things like that so that again is                                 deliberate just wanting to make sure                                 that we understand what the API should                                 look like really well before rushing                                 into building something so at the moment                                 each job would have to build the window                                 joint implementation                                 self but it means you can have any kind                                 of implementation you want and then we                                 reckon that you know maybe in six months                                 time or years time we will have seen                                 okay from our experience of seeing these                                                                                                   implementation works really well now we                                 can take that out and put it in the                                 framework but yes it's deliberately                                 focusing on simplicity right now okay                                 are we done then you can always still                                 thank me later thank you very much for                                 coming
YouTube URL: https://www.youtube.com/watch?v=d63kSjxVsGA


