Title: Berlin Buzzwords 2014: Jonathan Ellis - Modern Cassandra #bbuzz
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	Cassandra continues to be the weapon of choice for developers dealing with performance at scale. Whether in social networking (Instagram), scientific computing (SPring-8), or retail (eBay), Cassandra continues to deliver. This talk will look at new features in Cassandra 2.x and the upcoming 3.0, such as lightweight transactions, virtual nodes, a new data model and query language, and more.

Read more:
https://2014.berlinbuzzwords.de/session/modern-cassandra

About Jonathan Ellis:
https://2014.berlinbuzzwords.de/user/329/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              I'm project here of Apache                               I've been doing that for about five                               years four years ago i started a company                               called datastax to commercialize                               Cassandra we have a booth over in the                               the sponsors Hall welcome to stop by and                               find out more about what we're doing                               with Cassandra so cassandra has a little                               bit of a reputation still from the early                                days as a database primarily used in                                social media that impression is is                                outdated now there's thousands of                                companies using Cassandra in all kinds                                of different use cases and different                                workloads and different business areas                                I'd like to look at three of those that                                are representative in in some ways of                                how people use Cassandra and use that as                                a basis for our introduction here so the                                first of those is ebay so big ecommerce                                site uses cassandra in multiple places                                one big one is when you're viewing a                                ebay product page when you're looking at                                an item for sale and the like and want                                buttons those are driven by cassandra                                there's something called the hunch taste                                graph also driven by cassandra the red                                laser time series analytics also by                                cassandra so there's there's actually                                lots of different teams at ebay using                                cassandra for different things and                                there's there's several different                                reasons that ebay chose to build these                                applications on top of Cassandra and I                                want to look into those in a little more                                depth so first of all a several of                                ebay's applications using Cassandra are                                for time series data so when I say time                                series data I mean event data that has a                                chronological component to it so I've                                got three examples                                on this slide on the left you have                                sensor data or monitoring data for you                                know machines or for an Internet of                                Things that kind of data where no I my                                temperature was X at                                                   it was y at                                                   progression of data is an example of                                time series in the upper right this is a                                web server activity log so the log of                                activities of users on your websites can                                be useful time series data what have my                                friends been doing on this site also an                                example of time series data and at the                                bottom we have financial market data                                also a good example of of time series so                                Cassandra's data model gives you the                                ability to have sorted data within                                within a partition and distribute that                                across your cluster which makes it a                                very good fit for time series so a lot                                of people are using it for that another                                factor in ebays review was Cassandra                                support for multiple data centers what                                I've tried to diagram here is a real                                world deployment scenario where I have                                two data centers in the cloud so in                                Amazon ec                                                              two on premise data centers and                                cassandra is totally flexible about                                mixing heterogeneous deployments                                together like this it's not just multi                                data center support in the sense of i                                can fail over if I have a problem but                                rather it's active active so each each                                user in any of these data centers can                                perform reads and writes at local Layton                                sees which then get replicated                                asynchronous                                Lee to the other data centers and                                Cassandra's smart about this when I'm                                replicating too when I know that I need                                to replicate two machines in another                                data center I won't send three copies of                                that row over the network I'll send one                                copy over the web and then the replica                                that receives it will then forward it to                                the other replicas in in that other data                                center ebay also wanted Cassandra                                support for distributed counters so this                                you might be a little difficult to see                                in the back but what's going on in this                                slide is I'm showing how Cassandra's                                counters are partitioned across each                                replica so the the tough part so you're                                probably thinking okay a counter I just                                you know update set x equals x plus                                  you know how hard can that be so it's a                                it's really trivial if you have a single                                 master handling all your updates it is                                 not trivial if you want to handle this                                 asynchronously across multiple data                                 centers if I just if I just had every                                 once in there increments to a single                                 master then you know my latency from                                 from New York to London you know is is                                 going to be you know                                                    that's a lot of latency to add on to                                 each request so instead what we do is we                                 partition a counter across each replica                                 and then each replica is authorized to                                 handle increments for its partition and                                 then the the information isn't                                 propagated to the other replicas                                 asynchronously so in this diagram in the                                 upper left I have a counter whose total                                 value is                                                                 count of three the other partitions have                                 counts of zero they haven't handled any                                 increments yet                                 in the upper right we're going to handle                                 two simultaneous increments the a                                 replica and the B replica get requests                                 to increment the counter by two so a                                 increments it's partitioned by two from                                 three to five the increments it's from                                 zero to two now notice that the counter                                 value is inconsistent in this diagram in                                 the upper right because a thinks the                                 value of the counter is                                               value is five and see thinks the value                                 is                                                                       able to replicate those updates yet at                                 the bottom this is the state after the                                 updates have been replicated now every                                 replica knows that the total value of                                 the counter is seven I Bay also was                                 interested in Cassandra's Hadoop support                                 so let me clarify this a little bit                                 because there's different levels of                                 Hadoop support that a database can                                 provide you know at a very basic level I                                 can provide an input format or an output                                 format that allows me to split up the                                 data into you know sets that Hadoop can                                 run MapReduce jobs over and output data                                 back into the database but Cassandra                                 does more than that because Cassandra's                                 has very flexible support for                                 asynchronous replication I can I can                                 split up my cluster into your                                 application replicas in dark blue and                                 Hadoop replicas in light green and what                                 this does for me is I can tell Cassandra                                 now make sure the data is replicated to                                 both of these halves of the cluster so                                 each of them has their own copy what                                 that means now is I can run my                                 analytical jobs in Hadoop and they will                                 just touch the green nodes so they won't                                 interfere with anything going on serving                                 up millions of requests per second to                                 the users                                 my live web site so this this gives me a                                 workload separation where I don't need                                 to worry about causing performance                                 degradation to the application that                                 that's important to my users another                                 good example of using cassandra is                                 Adobe's audience manager product so                                 audience manager is kind of a content                                 management system for analytics and                                 online advertising and they chose                                 Cassandra for some of the same reasons                                 that eBay did multi data centers on                                 there but also some different ones so                                 looking at those a little bit that at                                 the top of Adobe's list was low latency                                 especially on reads so this is another                                 place where perception of cassandra is                                 has lagged behind a little bit the                                 actual product so cassandra has you may                                 have heard that Cassandra's fast it                                 writes but not not fast it reads so this                                 is this is a production Cassandra                                 monitoring system this isn't Adobe's                                 cluster but this is a is a production                                 Cassandra cluster and these are these                                 are the read Layton sees four of you                                 know three days in december i guess it's                                 actually five days but you can see that                                 the latency this is in milliseconds so                                 the latency average is about half a                                 millisecond a little less than half a                                 millisecond the                                                         we have spikes up to you know five                                 hundred microseconds but very                                 consistently under a millisecond so so                                 Cassandra can deliver this in the real                                 world today we're looking at making this                                 even better in two dot one so that the                                 Cassandra two dot one release is in beta                                                                                                        but here we have the blue line this is                                 this is a                                 performance of operations per second in                                 the blue line is                                                        is two dot one so you can see that that                                 the absolute performance I mean it's                                 it's a little better in two dot one it's                                 maybe five percent better but it's about                                 the same but the important difference is                                 that is that it's much less variable so                                 in                                                                       got worse during compaction 'he's where                                 it got worse during jvm garbage                                 collections in two dot one it's much                                 smoother so we're your that's that's an                                 important value to us to provide                                 consistently good performance not just                                 good performance on average so I want to                                 talk a little bit about how Cassandra                                 does this across a cluster and how we                                 how we spread data across a cluster so                                 the fundamental way we do this is is                                 called consistent hashing on the rose                                 primary key it's it's a little bit more                                 complicated than that it's actually we                                 actually use the first element of the                                 primary key is the partition key but in                                 in the simple case where it's not a                                 compound primary key they you know it                                 equates to the same thing so I'm going                                 to take this I'm going to take this                                 primary key here my username is going to                                 be my primary key in this example and                                 I'm going to hash it and earlier                                 versions of Cassandra used md                                         murmur hash now because it's faster it's                                 important to note that we don't need a                                 cryptographic hash so we're totally fine                                 with hash collisions because all we're                                 doing is we're using this hash to assign                                 rose to replicas it's it that that's all                                 we're using it for so once once we hash                                 the the primary keys we're also going to                                 assign numbers from our hash range to                                 each of the nodes in our cluster so here                                 I've got four nodes in my cluster I'm                                 going to give the first one token zero                                 the next one you know token for next one                                 token eight                                 next one token see so you know counting                                 up in hex along that                                                     going to take those hash values that I                                 computed with murmur hash and I'm going                                 to binary search across the tokens in my                                 cluster to see which which machine that                                 row goes on so Jim goes to note see                                 Carol goes to know d Johnny goes to note                                 a and Suzy goes to note C again so this                                 this shows how we can pick a single                                 replica for each row how do we                                 generalize from that to multiple                                 replicas there's there's actually                                 there's actually a pluggable component                                 in Cassandra called the replication                                 strategy that handles this and the the                                 simplest way as we can just say well if                                 I picked your replica d for my first                                 replica I can just go around clockwise                                 around the token ring and say nodes a                                 and B are going to be my other two                                 replicas but in in practice we want to                                 be a little more sophisticated about                                 this because we know that failures in                                 real clusters are not random they're                                 correlated and they're often correlated                                 to physical location in your data center                                 so we allow you to tell Cassandra what                                 data center and what rack each machine                                 lives in and that way we can make sure                                 that we only have one replica per rack                                 and we'll make sure to scatter the                                 replicas across multiple racks and that                                 way if I have a switch failure that can                                 that can often take out an entire rack a                                 power failure again Rack is often the                                 unit of failure even if I have a cooler                                 malfunction in the data center and                                 machines near the cooler start                                 overheating now the rack is a useful                                 abstraction that says these machines are                                 close together and I want the the                                 replicas far apart so I can avoid                                 correlated failures                                 I've oversimplified just a little bit                                 here because I've been talking about a                                 single token per node and in practice we                                 split it up into hundreds of tokens per                                 node the principle is the same but by                                 het by splitting it up into lots of                                 tokens per node it lets us parallel eyes                                 operations across the cluster so if I'm                                 going to add a new machine to the                                 cluster we call this bootstrapping so                                 here I've got the the virtual nodes as                                 little squares on the slide and I'm                                 going to going to send some of those                                 from each node to the new one so I                                 basically pick it's actually the new                                 node that picks its tokens at random but                                 it results in you know a proportional                                 amount of data being taken from each of                                 the existing nodes and sent to the new                                 one so by doing this my the impact of                                 doing that bootstrap is spread across                                 the entire cluster rather than focused                                 on just one or two this this also                                 impacts rebuilding a note if I lose a                                 machine and I need to rebuild it I want                                 two parallel eyes that across the                                 cluster as much as possible so the end                                 result would be that the new node has                                 you know the same amount of data as the                                 original nodes which all have you lost a                                 little bit of data by sending that to                                 the new one the last example I wanted to                                 talk about is Instagram how they're                                 using Cassandra one of their key                                 qualities they need it in the database                                 was durable rights so in other words if                                 I send a right to Cassandra if I do an                                 insert and Cassandra says yes it is                                 inserted then even if I lose power even                                 if I lose an entire data center that                                 data should still be there when when I                                 recover so the way Cassandra does that                                 is similar to most                                 relational databases where it has a                                 commit log that writes get appended to                                 before they get acknowledged so in the                                 upper left i'm updating a column in a                                 row and so there's a dotted line                                 dividing the slide below the line is on                                 disk above the line is in memory so i'm                                 going to append it to the commit log and                                 then i'm going to put it in a structure                                 in Cassandra's storage engine that's                                 called a mem table and in the mem table                                 I can group up updates to a single row                                 efficiently so notice here's here's                                 another column to the same row so in the                                 mem table it's part of the same                                 structure in the commit log there's two                                 distinct entries because I never                                 override an entry in the commit log I                                 just append new information that means                                 that even if I'm on a spinning disk                                 rather than SSD even if I'm on a                                 magnetic hard disk it's still very fast                                 because I'm not having to do any seeks                                 to move that disk head around so I'm                                 going to do some more updates to                                 different rows and ultimately my commit                                 log gets full enough that I'm that I'm                                 ready to turn it into a data file on                                 disk that's called a flush in the                                 Cassandra storage engine and so I turn                                 it into a data file and I create an                                 index and bloom filter for it and once                                 that's done and once I've synced that to                                 disk then I don't need to keep those                                 commit log entries around because the                                 commit logs just there in case I need to                                 replay from disk after some kind of                                 power failure or maybe someone killed                                 ash                                                                   anything that causes it to stop                                 unceremoniously that's what the commit                                 logs there for so now that I know it's                                 it's it's durable on disk in the storage                                 file I don't need that commit log data                                 anymore and I can clean that up I can                                 recycle the commit log segment and reuse                                 it so Instagram reports that they have                                 fire                                 the six nines of availability on                                 Cassandra so                                                      there's a number of different ways that                                 Cassandra helps achieve that I want to                                 look at just one of those so when I'm                                 doing a reading a Cassandra cluster the                                 client sends its request to some                                 Cassandra node that that becomes the                                 coordinator for this request so any node                                 in the Cassandra cluster can be a                                 coordinator and in fact it's good                                 practice to spread your requests across                                 all the nodes in the cluster so that no                                 single node becomes overloaded and                                 becomes a bottleneck so any node in the                                 cluster can be the coordinator and it                                 doesn't necessarily have to be a replica                                 for that row and in fact in this example                                 it's not a replica so the coordinator                                 each each node in the cluster tracks how                                 busy and how fast to respond the other                                 nodes in the cluster are so the                                 coordinator knows there's three replicas                                 and it knows that that this one here is                                 the fastest to reply recently so it's                                 going to route the request to that                                 replica and then the replica gives the                                 coordinator the row and the coordinator                                 gives it to the client so that's that's                                 the simple case when when everything                                 goes according to plan now a more                                 interesting case is when the coordinator                                 sends a request to a replica and then                                 the replica dies or it loses network                                 connectivity or you know something                                 happens so that that replica can't                                 respond to the request now in older                                 versions of Cassandra the coordinator                                 would say I couldn't do it sorry about                                 that and it would send a timeout                                 exception to the client                                 starting in                                                             stable release we added something called                                 rapid read protection so now when when                                 the coordinators first request doesn't                                 come back to it for any reason it will                                 perform additional requests to other                                 replicas and and failover that will fail                                 over within a single request so this is                                 this is actually configurable about how                                 aggressive you want it to be by default                                 it will retry the slowest one percent of                                 requests but you can make it more                                 aggressive even up to saying always do                                 one more request than I have to for the                                 consistency level that was requested                                 also so by doing doing that extra                                 redundant requests will give me lower                                 latency because now I just have to wait                                 for whichever one gets back to me                                 fastest as well as providing protection                                 against failures so here's what that                                 looks like in an experiment where we had                                 a four node Cassandra cluster we're                                 doing reads from it as hard as we can                                 and then midway through it we killed one                                 of the nodes so like I said there's dim                                 you can have different configurable                                 levels of read protection and those are                                 the lines on the top just different                                 configurations of that but the line that                                 goes all the way to the bottom that's                                 with no read protection so that's what                                 happens when it has to timeout those                                 requests and it and it's not not able to                                 failover until a new request comes in so                                 that's that's been a big success for us                                 in                                                                     know the last                                                       development I'd say our core values have                                 been massive scalability high                                 performance and reliability if you're                                 curious by the way the graph on the                                 right was from a paper published by                                 researchers at the university of tehran                                 to where they the x-axis is the number                                 of nodes in the cluster and the y-axis                                 is the operations per second and it's an                                 interesting paper i would recommend                                 checking it out they did half a dozen                                 different workloads this one here is a                                 mix of reads writes and sequential scans                                 and and they broke that down into the                                 different components in the paper so                                 that's that's kind of what we've                                 delivered in Apache Cassandra you know                                 as kind of our mission statement for the                                 first few years last year we added a new                                 core value of productivity and ease of                                 use so we created a cassandra query                                 language based on SQL these statements                                 on the right are valid in both SQL and                                 cql so create table create index select                                 from where they have those in common too                                 if this the short version of cql is                                 cassandra is a distributed system so                                 we're not going to support joins in the                                 language joins are going to kill your                                 performance in the distributed system so                                 we're going to emphasize denormalization                                 instead a second principle is that we                                 are going to emphasize ventually                                 insistence e instead of transactions now                                 sometimes you do need transaction like                                 function functionality and I'll show you                                 how Cassandra's answer to that in a                                 little bit but fundamentally eventual                                 consistency lets you be it lets you                                 deliver availability and it lets you                                 deliver performance much better than you                                 can do if you're focused on acid                                 transactions there's a great performance                                 by an engineer at Netflix called                                 eventual consistency is not hopeful                                 consistency that's a great introduction                                 to this concept of how eventual                                 consistency is your friend                                 so just a quick taste of of cql and how                                 we how we think about data modeling in                                 Cassandra if I have a use erste below                                 relational database and I want to allow                                 users to have multiple email addresses                                 I'm going to create an addresses table                                 with a many-to-one relationship to my                                 users and then I'll pull those out at                                 runtime with a join so we I already said                                 we don't have joins in c ql by design so                                 the what we do instead is we would use a                                 collection to hold the email addresses                                 so i just in line that into the user row                                 as a set so so you can see that I my                                 column definition here for email                                 addresses is a set of texts so                                 collections in Cassandra are typed so in                                 this case it's uh it's a set of text                                 entries and then I can add email                                 addresses to that row by doing this so                                 here I'm saying take the union of the                                 existing email addresses and these new                                 ones now I could I could also say                                 replace if I didn't have that email                                 addresses plus I could just say set                                 email address as equals this new set                                 generally speaking this if if you're                                 just going to be obliterating what's                                 already there and replacing it with a                                 new collection you know that I guess                                 that's that's fine and that's useful but                                 it's more useful to be able to                                 incrementally and performant Lee add new                                 entries to the collection so unlike                                 unlike document databases for instance                                 when I add new entries to the collection                                 I'm just writing that new entry I'm not                                 rewriting the entire row                                 so I mentioned that sometimes you do                                 need transaction like functionality so                                 what I'm concerned about their is                                 imposing a linear view of operations on                                 the database so an example that I like                                 to use is if you're allowing users to                                 register for your application then it                                 it's it's you need to be you want to                                 make very sure that only one user                                 registers for a given name so in the in                                 a without some kind of transactions I                                 can't provide this so here's what that                                 here's here's what an attempt to do this                                 might look like without transactions one                                 client asks Cassandra does this user                                 already exist Cassandra says no at the                                 same time another user as Cassandra does                                 this user exists Cassandra says no at                                 the same time the first user says okay                                 well since it didn't exist I'm going to                                 insert the row the second user says well                                 since it didn't exist I'm going to                                 insert the row as well so what what ends                                 up happening in Cassandra is the second                                 one ends up overriding the data from the                                 first one because these could be                                 happening on different replicas entirely                                 or even in different data centers so so                                 there's no an insert in Cassandra is not                                 there's no concept of there's a                                 uniqueness constraint that will reject                                 duplicate rows so there's an that that                                 concept doesn't exist in Cassandra so                                 it's going to accept both of the inserts                                 and then the you know one of them is                                 going to overwrite the other so we added                                 we added a feature called lightweight                                 transactions and what that does is it                                 lets you specify to Cassandra the otha                                 the update and the condition to check                                 before performing that update and wrap                                 that into a single statement so in this                                 case when we're inserting new rows that                                 that                                 check is just at the bottom here if not                                 exists so if I say insert if not exists                                 and I have multiple clients doing this                                 at the same time one of them will get a                                 success result which is you know it'll                                 get back a result set that says applied                                 is true the other will get back applied                                 is false and then as as extra                                 information here's the row that already                                 exists that you thought didn't exist and                                 so now it's up to you the application to                                 decide do you want to update the                                 existing rule or do you want to insert a                                 different row so you've got that                                 information now so to you know when                                 you're updating instead of inserting                                 then your your if statement can include                                 existing column values so i can check                                 column values that are it's restricted                                 to a single partition so remember i said                                 that that partitions are the unit of how                                 we spread data across the cluster so by                                 restricting lightweight transactions to                                 a single partition that means i know                                 that i only need to coordinate across                                 one set of replicas I don't need to                                 coordinate across know though entire                                 cluster so that lets me provide                                 boundaries on you know how how                                 concurrent I can I can make this without                                 getting into trouble so under the hood                                 lightweight transactions are built on                                 paxos which gives us some very desirable                                 properties from Cassandra's perspective                                 first of all it's quorum based meaning                                 as long as I have a majority of the                                 replicas for that partition I can make                                 progress so it's it's totally so it's                                 totally okay for some replicas to be                                 down as long as I still have a majority                                 so that's important for Cassandra's                                 goals of delivering availability packs                                 of state is also durable                                 so even if I I start a lightweight                                 transaction and partway through the                                 coordinator dies that's that's still                                 going that's not going to affect my                                 correctness I'm going to be able to                                 finish that with with a new leader if                                 for those of you who said you're already                                 using Cassandra we added a new                                 consistency level for this consistency                                 level dot serial means i'm doing a read                                 and I want that read to know peer into                                 the lightweight transaction machinery                                 and and let me know what that most                                 recent value is as eaten as even                                 including lightweight transactions that                                 are in process of being committed down                                 at the bottom though is the big you know                                 danger warning sign language we're doing                                 for round trips between each replica and                                 the coordinator for a lightweight                                 transaction so it's lightweight in the                                 sense that it doesn't perform locking                                 and lightweight in the sense that                                 there's no begin transaction commit or                                 rollback it's it's rolled into a single                                 statement it's not lightweight in the                                 performance sense so no you did the                                 wrong conclusion from this would be hey                                 I've got lightweight transaction so I'm                                 going to build my entire application                                 using this that would be the wrong                                 lesson the right lesson is it's                                 available for when you really need it                                 and when the alternative is you know                                 corruption or inflicting zookeeper on                                 yourself so those of you who view                                 zookeeper know what I'm talking about                                 yes                                 or conflict we detected the reader                                 actually needs to say I want to be aware                                 of conflicting transactions with this                                 year lie today no sorry yeah let me take                                 questions offline because i only have                                 five minutes or three minutes now so                                 coming up in two dot one I want to just                                 give you a quick taste of what is about                                 to be released next month so I i showed                                 you collections earlier collections do                                 not nest I cannot have a map of sets or                                 a set of lists but in two dot one I can                                 create my own types which could contain                                 collections and then I can have                                 collections of my type so if you look                                 here my address type contains a set of                                 phone numbers my user type contains a                                 map of addresses and so that gives me                                 this nest ability but now it but it but                                 it's strongly typed now so I don't I I                                 get that benefit of a strong schema as                                 well as the ability to build a structure                                 in my database that matches my object                                 hierarchy so a night and I can pull out                                 different pieces of those types with cql                                 so the query here I'm pulling out the                                 citi field and phone field from the the                                 addresses and that's what I get back for                                 one of my users we've also added                                 indexing to collections so here I've got                                 a set of texts for my tags column in my                                 songs table and then I can create an                                 index on that tags column and use that                                 in a query notice that it that we've                                 added a new keyword here though so we've                                 added the contains keyword we could have                                 you could have reused the existing in                                 keyword and then I could have said where                                 blues in tags I could have I could                                 reverse that to use the N key word we                                 went with contains because maps are a                                 special case because maps have keys and                                 values so by default or rather when you                                 use the contains keyword on a map it's                                 going to check the values but we also                                 added the contains keys keyword that                                 will let you check the keys of the map                                 collection as well so beta                                              if you want to play with two dot one                                 works we're hoping to do a release                                 candidate next week and get the final                                 out for the end of June finally I just                                 wanted to give you a heads up for some                                 other cassandra talks at berlin                                 buzzwords later today gary deuce Babic                                 from rackspace is talking about blue                                 flood which is a metrics processing                                 system built on Cassandra also later                                 today is talk on the cassandra java                                 driver tomorrow we have one on time                                 series with cassandra and a longer data                                 modeling talk so the data modeling talk                                 tomorrow is an                                                       we'll be able to get into some more                                 details on doing cassandra modeling and                                 then finally not part of Berlin                                 buzzwords but also in Berlin tomorrow at                                                                                                        up it's about                                                            you know if you google for Berlin                                 cassandra meet up there it is so I'll be                                 happy to take questions oh you can find                                 me at the the data sex booths in the                                 sponsors room and thanks for your time                                 and enjoy the conference                                 you
YouTube URL: https://www.youtube.com/watch?v=-0rdNsn2Rrg


