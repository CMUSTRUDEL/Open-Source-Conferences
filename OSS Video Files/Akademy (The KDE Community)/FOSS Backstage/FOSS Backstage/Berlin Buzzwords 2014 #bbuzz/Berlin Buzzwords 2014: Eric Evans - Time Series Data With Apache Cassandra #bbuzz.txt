Title: Berlin Buzzwords 2014: Eric Evans - Time Series Data With Apache Cassandra #bbuzz
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	Whether it's statistics, weather forecasting, astronomy, finance, or network management, time series data plays a critical role in analytics and forecasting. Unfortunately, while many tools exist for time series storage and analysis, few are able to scale past memory limits, or provide rich query and analytics capabilities outside what is necessary to produce simple plots; For those challenged by large volumes of data, there is much room for improvement.

Apache Cassandra is a fully distributed second-generation database. Cassandra stores data in key-sorted order making it ideal for time series, and its high throughput and linear scalability make it well suited to very large data sets.

This talk will cover some of the requirements and challenges of large scale time series storage and analysis. Cassandra data and query modeling for this use-case will be discussed, and Newts, an open source Cassandra-based time series store under development at The OpenNMS Group will be introduced.

Read more:
https://2014.berlinbuzzwords.de/session/time-series-data-apache-cassandra

About Eric Evans:
https://2014.berlinbuzzwords.de/user/200/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              all right then I guess we'll get started                               so my name is eric evans i'm a member of                               the Cassandra pmc been with the project                               since about the time it entered the                               incubator working for rackspace at the                               time and i work for a company called the                               open end ms group now before i get                               started i'm going to try to correct an                               ongoing problem I have it's happened                                it's happened even here at buzz words                                where I'll be talking about opennms for                                a while I'll be well into a conversation                                and someone will say what did you say                                what did you say the name was is it so                                if you heard if if you weren't able to                                hear the acronym I know this is all my                                fault I I don't enunciate it well enough                                I say too fast so if you're thinking did                                he say sorry mark things that work in                                here if you're thinking did he say open                                eminem's no but I like this idea so if                                anybody wants to work on this let me                                know if you're thinking did he say open                                enemas no I did not and if you want to                                work on this leave me out of it I want                                no part of it no part of this no it's                                nms for network management system which                                is convenient because it is in fact a                                system for managing networks so what                                this means is discovery of your network                                what devices are running on it what kind                                of devices they are is it a cisco switch                                or a linux host running                                                 capabilities what services what agents                                are running on it what's the topology of                                the network how are things                                interconnected what's the critical path                                between devices and then it you'll use                                this information the sort of self                                configure to provision the nodes and                                then you get kind of an asset database                                in the process service monitoring is                                everything from from something as simple                                as ICMP of an IP interface                                up to you know rather sophisticated                                synthetic transactions clicking through                                web page and validating the result we do                                data collection so this is our time                                series use case this is basically what                                the rest of the talk will be about this                                is the collection the storage of time                                series data trending values over time                                threshold engraving the reception of                                external events generating events for                                service failures threshold failures                                deduplication correlation of events and                                turning those into notifications opennms                                is a rather old project amateur project                                it's been around for about                                            the dog years of the internet and                                software that's that's quite a long time                                it's also it is written in Java and it's                                a free software open source software for                                time series data we currently use our D                                tool our d stands for round robin                                database our d to liz is also a very                                very mature project also have been                                around for about                                                        used in a lot of well-known tools it's                                austin stably a serie a solution for                                time series data one that's file based                                and that you you get to sort of                                automatic incremental aggregation so the                                way this works is you create an RD and                                in doing so define all of the metrics                                that will that should be stored within                                it and the aggregations that correspond                                to those metrics so five minute averages                                for you know you want to store                                        of those or one hour averages over the                                course of a year and in doing so all of                                the space that will ever need is                                allocated and each time you update an RD                                with a metric you're incorporating that                                that new value into each of the                                aggregations and when they get so old                                that that they exceed the number you've                                you've allocated they just fall at the                                end                                and it does graphing in fact this is                                actually what it does that's why i said                                ostensibly time series it's really all                                about graphing and everything else is a                                means to this end this is why it does                                aggregations actually it's it's why you                                only get aggregations the raw date is                                not available if you think of the                                problem of drawing a graph you've got a                                canvas of some finite size say                                     pixels in width and you want to plot                                 data that's a sample the five minute                                 intervals and you want to draw the last                                 six months you've clearly got clearly                                 have more data points than you have                                 pixels to draw them in so you need to                                 aggregate that down you also want the                                 points along the x-axis to be evenly                                 distributed and aligned on a common time                                 boundary and and all of this                                 normalization is what these aggregations                                 are for they're meant to be plugged                                 directly into the graph and it's kind of                                 cool having an all-in-one solution for                                 you know storing the data and getting a                                 graph but there is an ugly downside to                                 it and that is the the IO involved this                                 is a read-modify-write so each update of                                 an RD involves reading and writing                                 file-based metadata and you know per                                 metric metadata and of course the the                                 actual values themselves and so kind of                                 at a minimum you get                                                 update a single metric so if you have                                 hundreds of thousands or millions of                                 metrics then that's going to be                                 thousands or tens of thousands of I ops                                 even it you know rather long of sample                                 interval of say five minutes to put that                                 into perspective even a really nice                                 high-end rotational hard drive is only                                 good for about                                                           to say well that's that's certainly                                 within range of an SSD but since you get                                 a finite number of deletes or overwrites                                 in an SSD and since each one of these                                 updates constitutes a new right you'll                                 actually you know the longevity of an                                 SSD is really poor under this kind of                                 workload it's a very high volume and you                                 sort of run through the lifespan of the                                 drive rather quickly dear am based SSD                                 is a really good fit but they're also                                 very expensive and that's kind of what                                 this slide is                                 to show that we're kind of the end of                                 the runway in terms of vertical                                 scalability as engineers we you know we                                 try to make everything as optimal as                                 possible and so the idea of simply                                 throwing more hardware resources at it                                 is kind of unpalatable but vertical                                 scaling is actually a great way to go if                                 you just usually the cheapest thing you                                 can do but only so long as you're                                 available availability of inexpensive                                 commodity hardware outstrips your ax                                 your actual needs and we're clearly I                                 passed that point or getting there so in                                 other words we're sort of drinking from                                 the proverbial fire hose we have more                                 data than we can easily write out this                                 is kind of a bad problem for us this is                                 supposed to be in our wheelhouse this is                                 something that you know it's kind of a                                 you know core functionality networks are                                 getting bigger more complex more devices                                 so more metrics to collect the Internet                                 of Things is upon us and threatens to                                 bring you know just an explosion in the                                 number of devices and and and we don't                                 really have a good enough right                                 throughput as it is it's also                                 interesting maybe maybe ironic that the                                 source of the heiio is is aggregations                                 the aggregations exist explicitly for                                 the purpose of graphing and yet we graph                                 a very very small amount of the data we                                 collect it probably doesn't seem like                                 that to our users but you know the                                 average knock if it has you know                                                                                                               sized team working on any given shift                                 maybe they have a wall board projected                                 up with you know graphs of all their                                 land links you know half a dozen let's                                 say you know they may be periodically                                 looking at graphs of an hour's worth of                                 data or last hours the last day's worth                                 of data you know throughout the day to                                 troubleshoot issues but I mean how many                                 grafts could because somebody actually                                 look at within a given day or                                 meaningfully you know for millions of                                 metrics what actually ends up getting                                 red is just a very small fraction of the                                 data so this is a really poor trade-off                                 to be to be aggregating everything it's                                 like we're optimizing to read every                                 single solitary second of every minute                                 of every metric we have at least once                                 and almost the exact opposite is true                                 there are other problems with our ID for                                 us as well not everything is a graph and                                 so you're trying to perform other forms                                 of analytics on data that's spread out                                 through the file system using api's                                 they're really designed for graphing and                                 the data is already aggregated so                                 there's a loss of resolution that's not                                 ideal rd is a little bit inflexible in                                 order for us to to first store data we                                 would have had to have known about it                                 ahead of time created an already to put                                 it in and then once you do that you                                 can't really change them after the fact                                 we have a variety of problems that have                                 proven intractable to solve incremental                                 backups is kind of a classic example it                                 is file based so you can simply back up                                 the file system but due to the way the                                 bites are laid out on disk there's no                                 easy way to get at just what's changed                                 and then perhaps most importantly you                                 know we're a network management system                                 so if there's a problem with the network                                 we're expected to be available in order                                 to to notify operations there's a                                 problem we're expected to be available                                 so that we can be used to troubleshoot                                 and mitigate the problem but we aren't                                 in fact dependent upon the network and                                 so saying that we you know we rely on                                 the file system is a fancy way of saying                                 that we have a single point of failure                                 and so that's not at all ideal one                                 takeaway i get from rd or at least I                                 think it's already that kind of pointed                                 me at this is that we access metrics in                                 groups already encourages this that you                                 put similar or related metrics that you                                 intend to access together within a                                 single rd and that is that is what we do                                 that is the natural way of modeling this                                 type of data if you think of graphing                                 how likely are you to graph incoming                                 bites from a network interface without                                 also plotting out going on the same                                 graph or coors on a cpu or                                           minute load averages you're usually                                 going to do these things together in                                 fact most of these visualizations are                                 interesting when they let you correlate                                 multiple data points on a single a                                 single graph so we naturally                                 collect things in groups and I think                                 that's that's an important feature so                                 given all of this what does what are                                 open in two meses requirements well what                                 do we need in the way of a time-series                                 storage well we don't have enough                                 throughput so we need something that's                                 higher throughput we need better                                 availability I put late aggregation up                                 here we need to be smarter about                                 aggregation smarter about expending                                 those resources the cost value benefit                                 needs to be better and most importantly                                 it needs to be decoupled from from                                 storage we need to be able to store                                 regardless of whether we have the                                 capacity to to aggregate those and then                                 we need to take advantage of this                                 grouped storage and retrieval we know we                                 access metrics we didn't collect them                                 and store them at the same time so                                 whatever we use should should make that                                 easy and most storage mechanisms are                                 probably going to have a way of                                 optimizing for this and making it more                                 efficient so from the title of talk it's                                 probably no mystery that our solution to                                 this involves Cassandra for those of you                                 not familiar cassandra is an Apache                                 top-level project for a distributed                                 database one that is well known to be                                 highly available and have high                                 throughput and it's also known as a                                 solution that utilizes is tunable                                 consistency you may have heard eventual                                 consistency talking about the same thing                                 eventual consistency has kind of a                                 negative connotation to it and this is                                 this is not a negative or downside I                                 would argue this is this is an important                                 feature and hopefully I I can                                 demonstrate that so let me regale you                                 with the reasons why I think Cassandra                                 is a really good fit for time series                                 data and and for opennms so first                                 looking within a given node in the right                                 path for a single node you won't                                 remember I said that even a nice                                 high-end rotational hard drive is only                                 good for a couple hundred I ops this is                                 this is caused by the fact that they're                                 mechanical and you know to start a new                                 operation to read or write you first                                 must position the head and there's                                 rotational latency how long does it take                                 to move the platter at least                                             as all this is mechanical it all works                                 at fixed speeds and so you can only do                                 so many of the                                 was in the given period of time but once                                 you start an operation once you position                                 the head and you're ready to go they can                                 move a tremendous amount of data so what                                 Cassandra tries to do is optimize for                                 that sequential disk access and the way                                 it does that is with a log structured                                 right path so the client starts by                                 writing the data into an in-memory                                 structure the client right lands in an                                 in-memory structure that's maintained in                                 sorted order and it's also written to a                                 commit log the commit log is simply                                 crash recovery is just to replay back                                 into the mem table that there's an                                 unexpected outage so we don't read from                                 that and thus its append only that's                                 what that keeps the disk access                                 sequential when a threshold is reached                                 the mem table is flushed to disk to                                 create an SS table and they're never                                 updated in place a new one is created                                 each time so those are sequential as                                 well and what this means is that we're                                 optimized for write throughput which is                                 exactly what we need and the fact that                                 sorted on disk makes it a really great                                 fit for time series because you know we                                 we sample things and store them by time                                 time is obviously sorted when you                                 retrieve this data we expect to start                                 with you know some time in the past and                                 and you know take a range of data up to                                 some time either less in the past to the                                 present and we expect to get it back in                                 an in ascending order and that's exactly                                 the way it's persisted pulling back out                                 of a single node and looking at the                                 cluster as a whole obviously if we want                                 to distribute this data we need a way of                                 partitioning the cluster so that we can                                 assign the data to the nodes within it                                 so the way we usually visualize this if                                 you imagine a namespace and covering and                                 encompassing all possible primary keys                                 and you mapped it on to sort of a ring                                 or clockface in ascending order sort of                                 sorted in ascending order working                                 clockwise around the ring lowest value                                 at                                                                    highest value of                                                 position the nodes within within this                                 this namespace and a partition simply                                 becomes the interval between where a                                 node resides on the ring and and the                                 preceding node so when you want to know                                 where something goes you just find its                                 sort order                                 and put it on that node additional                                 copies you just use something that's                                 that's that's deterministic based on the                                 first location once they're all                                 positioned they're all identical none of                                 them are special this is just the                                 algorithm for placement once we have                                 multiple copies of the data then we have                                 to deal with this reality which you may                                 have heard you know either here at buzz                                 words or perhaps at another conference                                 the cap theorem these are all desirable                                 properties we want consistency we want                                 availability and we want partition                                 tolerance but the cap Theory cap theorem                                 tells us we can have at most two of                                 these at any given at any given time                                 it's really pretty intuitive if if you                                 were to write a value to two hosts if                                 you were going to synchronously                                 replicate a value of any value to any                                 two hosts and by synchronous I mean                                 you're going to write it to both of them                                 and it's successful once it's been                                 written to both of them then it follows                                 that that value is consistent you know                                 you've you explicitly made sure that it                                 was but if one of those nodes is down                                 you can't do that you can't write it to                                 both of them because one of them is                                 unavailable you've traded availability                                 in favor of consistency and likewise for                                 an asynchronous replication you may get                                 that availability but you lose the                                 consistency because you can't reason                                 about the data after disconnecting from                                 one host that's all this really means                                 it's just a way of describing the                                 contentious properties of distributed                                 storage so how does Cassandra deal with                                 this well it's actually quite simple                                 rather than making it an all-or-nothing                                 proposition we either synchronously                                 replicate and consider all of the copies                                 on a reed or we asynchronously it's                                 tunable how many of the replicas are                                 synchronous versus asynchronous and it's                                 on a per operation basis so imagine                                 replication factor of three and                                 Cassandra's most utility of consistency                                 levels is quorum which is simply                                 majority so if we have three copies and                                 we write a quorum we'll synchronously                                 replicate the two that's what will                                 constitute successful right if we also                                 read a quorum then we're going to                                 consider two copies we're going to need                                 to retrieve two copies in order to                                 consider that a valid                                 and if we do that there's no way we                                 won't overlap and get at least one of                                 the one of the most recent rights                                 assuming that there was any                                 inconsistency to begin with and so long                                 as the number of copies we synchronously                                 replicate to and that we consider on a                                 reed is more than the replica count will                                 always have read or write consistency                                 you'll always read the last most                                 up-to-date value you wrote what's great                                 about that is that both the read and the                                 right in this scenario could survive a                                 single node failure in the replica group                                 and everything continues on as normal                                 there's the possibility of inconsistency                                 within the cluster but who cares you                                 still reading what you wrote and those                                 values will get fixed eventually so the                                 properties of distribution are that it's                                 symmetrical given the way that algorithm                                 works there's no need for coordination                                 all you need to know is all of the nodes                                 in the cluster which is easy and                                 placement can be done by anybody                                 everyone follows the same rules that                                 makes it very operationally simple to                                 have all of the nodes to be identical it                                 also means it's linearly scalable so you                                 know you can literally double the size                                 of the cluster you know go from five                                 notes to ten and you'll get you know                                 twice the throughput twice the capacity                                 it's redundant because their stores we                                 store multiple copies so if one fails                                 one machine fails in a replica group we                                 don't lose any data and it's highly                                 available because we can game those                                 multiple copies those replicas to trade                                 away a little consistency in favor of                                 availability and still get consistency                                 at the end so on i think is a really                                 really good fit for time series so what                                 does a data model look like for time                                 series time series data again given the                                 requirement for group storage so let's                                 start with the resource our resources i                                 guess in this case is kind of an                                 abstract concept the resource will be                                 that instance that we associate our                                 metrics with or our group of metrics so                                 a resource here could be a host or an                                 application or more importantly since                                 it's a group it might be an ethernet                                 interface on a host if the group is                                 meant to be                                 statistics for the ethernet interface or                                 it could be a processor on that host if                                 it's meant to be the group is meant to                                 represent processor statistics so we're                                 going to want well first let's look in                                 this an abstract terms we're going to                                 want a                                                                this resource and the sample times we're                                 also going to want a one-to-many                                 relationship between the sample times                                 and the metrics that we want to store at                                 that time so if we were modeling this in                                 a relational database this is probably                                 something we would do with a couple of                                 join tables joins are not possible in                                 Cassandra but we do have this nifty                                 support for wide rows in in cql so this                                 would be the DD l for a perhaps an                                 oversimplified version of what I'm                                 talking about let's let TM and vb the                                 the timestamp the metric name and the                                 value respectively and of course the                                 resource is that resource string all of                                 the the magic in this happens in the                                 primary key definition for what's with                                 what's in the parentheses so resource                                 first that means it's the partition key                                 that's the one that determines placement                                 within the cluster if you remember the                                 diagram of the ring and then the the the                                 next columns in order will be the                                 timestamp column and the metric column                                 and what this does is it causes a                                 grouping of the columns in the                                 underlying storage such that we can we                                 can create this one too many mapping                                 first between the resource and time                                 stamps and then time stamps and metrics                                 since the value doesn't doesn't appear                                 in that will have exactly one value for                                 every resource time stamp and metric                                 combination so this is my attempt at                                 visualizing this I don't know how well                                 this is going to work first time I try                                 to like this this is I will stress what                                 I'm trying to convey is the what happens                                 in the underlying storage right so this                                 is not what Cassandra presents you but                                 in the underlying storage everything                                 that is identified by a primary key our                                 resource here is going to is going to be                                 essentially a collection of sorted                                 columns and so that primary key                                 definition what it does is it sets up                                 some compounding of the column names                                 in order to group these and since you                                 know timestamp appears first all of                                 these groupings will be prefixed by a                                 timestamp and it means that all of them                                 will be sorted first by timestamp so                                 what that means is if we select from                                 samples or resources some resource right                                 at that point that automatically                                 indicates that everything that follows                                 all the predicates for the follow will                                 be with from within this single row we                                 can simply find the records in the                                 inning as much as possible they'll be                                 continuous on disk we can simply find                                 those and construct a tabular results                                 set just exactly what we would get if we                                 were using join tables in relational                                 database this is the results you get                                 from Cassandra you would get a tabular                                 result that contains the group of                                 metrics and values for given time stamp                                 it works the same way for a range of                                 timestamps to some you know more                                 interesting you know where timestamp is                                 greater than or equal to t                                           than or equal to t                                                     here is to know that that this would                                 result in you know in a range of columns                                 that again in as much as possible are                                 stored contiguously on disk and so as                                 much as possible or result in a                                 sequential read of the data okay so                                 Cassandra makes a really good time                                 series database you could pretty much                                 pick it up and use it just like it is                                 but as these things usually go there's                                 there's also plenty of room for                                 abstractions for this particular use                                 case so what we've done is we've we have                                 started a project called newts to                                 implement the features that I talked                                 about the late or disconnected                                 aggregation and the grouping and since                                 we think that that our use case for time                                 series storage is there's nothing unique                                 to us that it would be generally useful                                 to others we've made this a separate                                 project and it's it's a standalone                                 datastore that you could use in your own                                 projects we do raw sample storage and                                 retrieval no processing is done on your                                 on your on your samples nope no snow                                 processing is automatically done and you                                 can retrieve the samples exactly as you                                 stored the man you can however perform a                                 query that will result in                                 gations and give you sort of graph ready                                 results and those aggregations will                                 include because again we're storing Raw                                 results that includes like counter                                 values are you know the actual value of                                 the register or store draw so these                                 aggregations can calculate rate from                                 counters you can apply aggregate                                 functions including ones that you write                                 yourself and you can perform arbitrary                                 calculations and even calculations on                                 calculations to scale them or or                                 aggregate them you know multiple                                 aggregates into a single single value so                                 it's pretty flexible and all of this                                 runs a cassandra speed which is pretty                                 rip and fast i was doing some tests                                 right before I came to the conference on                                 rackspace instances performance                                        which is                                                           virtual CPUs and I pretty reliably got                                 about just about                                                    second in jest rate per core so you know                                                                                                  depending however many however many                                 cores you have and that's that's that's                                 pretty pretty fast I think newts has a                                 Java API so you could embed it directly                                 in your project if it's Java there's                                 also a rest endpoint it's a open source                                 Apache License caffeine-free sustainably                                 grown all those buzzwords this is                                 buzzwords right and yeah it's upon                                 github we would love to see                                 contributions I would say it's in sort                                 of a you know maybe late alpha early                                 beta stage the software's actually works                                 pretty good but in the grand tradition                                 of open-source software there's                                 definitely a few usability knits and                                 absolutely no documentation so we                                 haven't really gotten to the point where                                 we consider first release yet so I can I                                 can hand wave that away and say you know                                 it'll all be a good at Italian you know                                 when the time comes but certainly                                 anybody with you know who's slightly                                 initiated I'm sure could make could make                                 good use of it and I will promise                                 everybody here that i will make i will                                 make a                                 i will clear my plate if you want to use                                 it and you have any issues or you like                                 to check it out need explanations or                                 something like that so check it out                                 that's all I have and I guess we have                                 five minutes left so if there's any                                 questions I think we got plenty of time                                 for it grab one down here yeah first of                                 all what's the relation to tie us to be                                 so how much would be awesome to summer                                 base time series door yeah just the                                 comparison to kyles to be okay from your                                 point uh so grouping would be the big                                 one Carlos doesn't do any grouping                                 something in the case as I mentioned                                 where we where we collect                                                a time which is very common that would                                 be                                                                      on text I'm sorry Kyle's to be has text                                 and you can group on them as far as I                                 know you yeah it has tags so that you                                 could switch you could identify our                                 market group of groups but if they're                                 still stored in separate rows right so                                 so it's still still require to                                 retrieving them and still require you                                 know that many queries that many                                 individual queries when I here at the                                 back oh sorry well got a really similar                                 question okay how does it compare to                                 graphite carbon storage to graph I what                                 storage the carbon storage yeah it's                                 integrated with graphite I don't know                                 that's that's that's that's not a                                 distributed storage is it that was                                 probably the big difference yeah I                                 thought you were talking about whisper                                 TV yeah I think that's I think that's                                 like rd without the ordering constraints                                 they can store out of our order data I                                 think otherwise it's pretty similar to                                 already thank you                                 hi could you go back to the data molding                                 slide with your cql place which which DQ                                 all the ddl this one yes did you say                                 that you're the resource here is there                                 ok yeah the resource here is where we                                 can trick instantly call the roki the                                 partition key so does that mean that all                                 of your events for a particular resource                                 end up on the same row yes what happens                                 I mean the row has has limits what                                 happens when you spill over that's a                                 good question so we assume most people                                 will probably use TTL columns so that's                                 that's one thing that they would expire                                 this is not the case right now but we're                                 planning to partition is probably one of                                 the first things I'll do after leaving                                 here is partition that that roki by some                                 time element probably in a probably week                                 or something so that in that case each                                 row will not grow beyond whatever                                 whatever you collect and sentenced or in                                 a weeks period of time ok which is                                 pretty reasonable I work at spotify                                 we're fairly heavy cassandra users and                                 we've had a couple of cases where you                                 sort of store endlessly store things to                                 one single row and even if you delete                                 things they don't disappear in Cassandra                                 because you end up with tombstones so so                                 the effectively your performance for                                 that particular row goes down further                                 and further so you need you will need to                                 partition like you yes like you stay a                                 follow-up question does that mean that                                 if you have very heavy traffic on one                                 particular resource then you create do                                 you create hotspots in there so maybe                                 that's not a I don't I don't anticipate                                 that that would actually be a problem I                                 mean that you would have such high                                 sample frequently or frequency or so                                 many metrics I would probably indicate a                                 modeling problem this this does kind of                                 put the onus on the user to kind of you                                 know to establish what those groups are                                 you can always just store one value per                                 which is the way a lot of time sort of                                 time series databases do it where you                                 know it's essentially a key and a value                                 and the resource would be the key and                                 you know you'd have one value so the                                 grouping is kind of a feature and it's                                 it's incumbent upon the user to decide                                 what makes sense for a group so I think                                 for that to happen you'd have to have a                                 you know a group that didn't make sense                                 a group that was too large it was one                                 back here hi why is the consistency so                                 important for you because basically                                 you're aggregating data which means in                                 my book that if you loose like a few                                 metrics it's not going to usually affect                                 your your aggregates fight yeah we                                 probably don't have really really strong                                 consistency guarantees that doesn't mean                                 that we don't want to replicate and that                                 we don't want you know we don't want to                                 store you know to have a replica count                                 greater than one particularly because                                 again you know so i guess to answer your                                 question we want availability more than                                 anything and so having multiple replicas                                 gives us redundancy and you know yeah we                                 may use a consistency level of one that                                 will actually be a choice that's                                 actually choice through notes that you                                 can choose your consistency for us i                                 think that most use cases for this it                                 would just be one which just means that                                 it's even even more available the                                 availability is even higher okay thanks                                 a follow-up question so how does this                                 compare to say a lock test elasticsearch                                 set up so we're programming data in                                 production I'm sorry how does it compare                                 to what logstash inelastic search mom                                 not sure okay anyone else it went down                                 here                                 hi so is the grouping of the metrics                                 that you do only four different metrics                                 on the same resource you don't you don't                                 want any grouping for metrics on                                 different resources no I think I would                                 probably consider that like an indexing                                 problem probably yeah this this is                                 assuming that you want to you want to to                                 query this data model assumes and newts                                 assumes that you want to query a group                                 of metrics by a resource not necessarily                                 you know a group a group of metrics                                 across the set of resources it would be                                 a different problem i guess and one that                                 this doesn't address a follow-up                                 question so if you store a single wide                                 row for a resource and if you have a                                 large number of metrics for that one                                 resource could that not cause some                                 performance issues I think that's I                                 think that's similar to the question of                                 the back and the answer would be I think                                 if you've grouped correctly you know                                 you're probably you know that a good                                 size group is probably anywhere from two                                 metrics to you know maybe a dozen or                                 maybe even two dozen I think that before                                 you would actually push the the row                                 constraint you know push to the width of                                 the row to the point where you caused                                 performance I think you're sampling                                 sample frequency we would have to be                                 very right not to do the math to be a to                                 give you examples but i think the sample                                 frequency would have to be very very                                 high and the metric group very very                                 large before that became an issue again                                 we're going to partition the row keys so                                 that at most you know I think week is                                 probably what would it be partitioned on                                 and so at most a week's worth of data                                 would be in a given row so would you                                 break up a resource with lots of metrics                                 down into smaller resources yeah okay                                 thanks so to achieve high throughput is                                 there anything on the network layer that                                 you're doing special like what does the                                 transport look like up until well the                                 four core tests that the four core test                                 I was doing where where I was getting                                 about                                                                    you know sixty thousand requests or so                                 that was only generating about                                                                                                                 Meg link would do for                                 that special yeah same same sort of                                 capacity planning to apply to anything                                 else I think anybody else okay thank you                                 you
YouTube URL: https://www.youtube.com/watch?v=xVwo9lsrxfg


