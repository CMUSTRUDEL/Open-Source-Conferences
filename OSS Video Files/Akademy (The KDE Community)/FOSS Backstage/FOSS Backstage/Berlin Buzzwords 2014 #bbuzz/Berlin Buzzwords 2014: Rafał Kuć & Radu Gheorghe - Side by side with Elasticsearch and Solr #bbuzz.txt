Title: Berlin Buzzwords 2014: Rafał Kuć & Radu Gheorghe - Side by side with Elasticsearch and Solr #bbuzz
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	Solr - established, mature and well known open-source search server, commonly used. Elasticsearch - still young, but quickly gaining popularity, with over 200k downloads per month. Both search servers are based on Lucene - the open-source full text searching Java library, but each with their own extensions, their pros and cons.

We all know that Solr and Elasticsearch are different, but what those differences are and which solution is the best fit for a particular use case is a frequent question. We will try to make those differences clear, not by showing slides and compare them, but by showing online demo of both Elasticsearch and Solr:

- Set up and start both search servers. 
- See what you need to prepare and launch Solr and Elasticsearch.
- Index data right after the server was started using the "schemaless" mode
- Create index structure and modify it using the provided API
- Explore different query use cases
- Scale by adding and removing nodes from the cluster, creating indices and managing shards. 
- See how that affects data indexing and querying.
- Monitor and administer clusters.  

See what metrics can be seen out of the box, how to get them and what tools can provide you with the graphical view of all the goodies that each search server can provide.

Read more:
https://2014.berlinbuzzwords.de/session/side-side-elasticsearch-and-solr

About Rafał Kuć:
https://2014.berlinbuzzwords.de/user/199/event/1

About Radu Gheorghe:
https://2014.berlinbuzzwords.de/user/281/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              hello hello everyone welcome to today's                               talk side-by-side with solar and                               elasticsearch we hope you had a nice day                               yesterday at the buzzwords and enjoy the                               after party before we start I would like                               to ask two or three questions how many                               of you know soar okay                               that's nice how many of you know                               elasticsearch great I won't ask the                                third question then before we start I                                will talk about the video search site I                                would like to introduce my colleague rod                                oh don't hide we are working together                                sama text he's a father and a husband we                                were working a consulting side we are                                working together locks on fertilization                                software called logs in he also happens                                to be an outer of elasticsearch in                                action for available at the manager                                early access project so if you want a                                nice book about elasticsearch here's the                                guy to talk to and here's the file my                                colleague we work together on consulting                                projects we work together on logs een he                                works with both elasticsearch and solar                                heroes books about both and he's a                                general nice guy a family man you cannot                                not like him once you get to meet him so                                let's let's have an overview of what                                we're going to talk about today as                                Rafael said I actually didn't say that                                but anyway let's let's imagine the use                                case that we want to build search over                                some video metadata so stuff like who                                the uploader is the title the                                description and so on so at this point                                let's assume that we don't know which                                which one fits best whether it's solar                                or elasticsearch so what we're going to                                do is we're going to show you an                                overview of how you do it in both search                                engines from indexing searching to doing                                some facets of analytics and to                                administering and scaling out your                                cluster we'll start with the data let's                                assume that our documents the videos                                we're going to index actually do the                                metadata about the video                                are stored in adjacent a simple JSON                                file will show you will for development                                mode will use a schema less modes for                                both solar and elasticsearch that's why                                we don't care about schema yet then                                after we index the data we want to run                                searches on it both of course elastic                                search and solar provides that                                functionality we also want to give data                                the meaning so we use facets in solar we                                can use aggregations and percolation in                                elastic search we will talk about it                                later of course a single node can be                                tuned to the way that is going to run                                smooth but at a certain point you end up                                with scaling out and the need of it so                                we'll also show you how to scale out                                both solutions finally maybe not finally                                you want to do backups and if you don't                                do you will do it I was at the point                                where I didn't do them and lesson                                learned that's a fact and finally we'll                                get to an ecosystem around both of those                                because it's large and there are many                                tools that will help you on your way to                                getting to the final product in                                production let's start with a simple                                data file our data files looks like this                                is a simple JSON with a few fields some                                of them are single valued like the ID or                                the title and some of them are multi                                valued like the tax field which has an                                array of values you can look the older                                for all the data files that the provided                                github account there are also commands                                that will allow you to index them                                without any any trouble so let's now                                index the data anyway this is a real car                                I'll switch to the video and show you                                something so we start with unpacking                                both solar and elasticsearch we choose                                the                                                                    and we choose                                                         unpack those two it takes a bit longer                                with sorb because the package is a bit                                weights more after we unpack it in terms                                of solar elasticsearch works with                                schema-less by default in solar we have                                to do some additional things what we                                will do is we actually will remove the                                default collection provided with solar                                 and we'll replace it with this schema                                 less example                                 provide it again with the example                                 deployment Solar has after that we'll                                 need to copy it just a second                                 so we copy it's called this example                                 schema-less and now we can just start                                 them we hit be an elastic search with                                 elastic search and we hit Java jar start                                 and we're and we're ready okay we                                 started solar we can see that an elastic                                 search is starting as well after that we                                 can use the commands provided to get                                 help to index the data it's really                                 simple however there is one additional                                 thing I would like to mention when it                                 comes to solar that the files that are                                 on github they need to be surrounded by                                 square brackets because that's what the                                 solar format is after that if you can                                 see that they're indexed and ready for                                 searching and we will do that in just a                                 few ok let's get back of course we                                 talked that we want to use the schemas                                 first but in production environment you                                 usually don't want to go with schemas                                 why because you want custom analysis                                 defined by you to match your use case in                                 terms of solar we do that by default by                                 altering the schema XML file or                                 providing our own we push the day we                                 push all the configurations to Kisuke                                 per which holds the configurations is                                 responsible for helping with overseer                                 election and stuff like that provides                                 the cluster state the schema XML is a                                 really simple file an XML file that                                 provides all the fields that you will                                 use and that show your index structure                                 and provides all the field types that                                 define your analysis with elastic search                                 you probably know that you have the                                 mapping as the equivalent of the schema                                 and you can put it using the put mapping                                 API and you can also use the put mapping                                 API to extend the existing mapping with                                 new fields you can see that it's in JSON                                 but the key difference here is that with                                 elastic                                 you can have multiple mappings in the                                 same index so this is useful when you                                 have for example videos which have the                                 documents have one structure and users                                 will documents have a different                                 structure and you can put them in the                                 same index under different mapping types                                 let's move to searching if you if you                                 want to run a quick query on                                 elasticsearch you would hit the search                                 endpoint and you would look at the Q                                 parameter and put your Lucene query                                 string there you will get a JSON reply                                 with the results ranked by relevancy                                 score by default and you can see in the                                 source field there there's the original                                 JSON that you indexed when it comes to                                 solar we need to provide the collection                                 name you want to run searches against                                 and we choose the request Handler we                                 want to run our searches to which is the                                 Select one which is here it basically                                 provides the functionality of getting                                 our parameters and passing into the                                 correct request parse a query parser as                                 you can see the queries again simple as                                 it can be we passing the Q parameter                                 with elastic search and because by                                 default solar doesn't return score for                                 each document we need to alter the                                 fields this parameter that's why we                                 decide star which means give me all the                                 stored fields in result and the score                                 the result returned by solar is by                                 default XML file which contains all the                                 stored fields we don't have source in                                 solar and you can change the response                                 format to whatever you choose and it's                                 available like JSON CSV files serialized                                 PHP Java Bean and all the other stuff                                 that's that's there however the standard                                 query URI request query is not something                                 you'll stick for long apparently so                                 that's why solar provides you with                                 multiple request parse the query parsers                                 actually sorry and we can do that we can                                 they have multiple parameters different                                 ones and they just parse our queries for                                 example here we use the standard query                                 parser provided by solar we want to get                                 the documents with the                                 elasticsearch entitle and logs in the                                 tax field and we just run a simple query                                 we can also leverage the query parser                                 functionality and remove the logical                                 operator from the query some and pass it                                 with the additional cue a parameter with                                 elastic search you have the query DSL                                 and I just want to ask who went to the                                 query DSL talk from yesterday                                 alright so for those of you who weren't                                 the point is that you would put a JSON                                 as the payload to your HTTP request and                                 in that JSON you would define your                                 queries in this case you can see there's                                 a bull query which has a shoot clause                                 and that PO query can be used to wrap                                 other queries for example the match                                 query which will look for elastic search                                 in the title and the term query which                                 will look for the exact term logs in the                                 tags field let's move to to some use                                 cases that might not be typical to a                                 search engine for example let's say that                                 we want to be alerted every time we get                                 a new video uploaded with elastic search                                 in the tags field and to do that we can                                 use the percolator and I want to ask who                                 was at the percolator workshop talked                                 yesterday so this is a typical use case                                 the point is you can index queries as                                 you normally index documents except you                                 put them in the Pirkle in dot /                                 percolator type and then you can hit the                                 percolate endpoint with documents and                                 what you will get back is the list of                                 queries that would match the document                                 that you percolate in solar we don't                                 have percolator apparently but imagine                                 of a certain use case we want to have                                 more diversified results with solar for                                 example we would like to have a single                                 document a single video returned for                                 each uploader of our events so what we                                 can do is we can use a grouping call                                 also called field collapsing                                 functionality we can run cue elastic                                 search like the query we've already run                                 and we turn on the grouping                                 functionality by                                 finding the group equals true parameters                                 and we specify the name of the field we                                 want to group on in this case uploaded                                 by which holds our upload lives what                                 solar will do is it will take the terms                                 from the uploaded by field and we'll                                 divide our results returning a single                                 document by default for each of the                                 terms in the uploaded by field so we'll                                 get a single document for new thinking                                 communication which is uploaded for                                 Berlin buzzwords videos for example of                                 course we can alter the default                                 functionality to return more documents                                 the key point here is that solar will                                 return the most relevant documents for                                 each of the groups of course in real                                 world data is not flat at all so both of                                 the the great certain sort an elastic                                 search provides the support for                                 hierarchies imagine the fact that we                                 would like to have names of the                                 presenters like us two here divide it                                 into different fields so we want to                                 avoid cross matches so rather couch                                 wouldn't be a match right so what we can                                 get from solar and elastic search is                                 first the nested documents support its                                 rely on on the blog joint functionality                                 provided by loosing library and actually                                 it indexes that the parent and the                                 nested documents in the same segment so                                 they are nil and they can be searched in                                 a very efficient way the other thing                                 that we can use is the parent-child                                 functionality which in store is a pure                                 query time join an elastic search you                                 need to provide the document identifier                                 the parent document a data fire for the                                 each of the child documents we also want                                 to give our data meaning in terms of                                 solar we have the facet functionality                                 what facet is is actually term connected                                 to some number usually account to build                                 a simple pack cloud of our search                                 results we would use the field faceting                                 on the tax field and what's or we'll do                                 is we'll return all the top count tags                                 the terms from the tax filled with the                                 count specifying how many documents were                                 found with the given tag we also may                                 want to have a variance of that we will                                 if you are only interested in some of                                 the uploaders not all of them we can                                 tune the query to return only the facets                                 for those two uploaders we are                                 interested in and that's why Seoul                                 provides the face of query functionality                                 and in this case the facet query would                                 return only counts for leucine solar                                 revolution and Newton in communications                                 with the elastic search you also have                                 facets but they have been superseded                                 recently by aggregations and I want to                                 ask again who was that the aggregation                                 star came yesterday all right so now                                 quickly sum it up basically aggregations                                 are like facets if you only use them one                                 by one and they are divided in their                                 multiple types and they are dividing two                                 categories there are pocket aggregations                                 like this terms aggregation here which                                 will get you like a tag cloud because it                                 will make you a bucket of documents out                                 of each out of each tag so the documents                                 that match that tag will be in one                                 bucket and the next step                                 tag another bucket and there are metrics                                 aggregations which will only return you                                 one number so for example the                                 cardinality aggregation will get you the                                 number of unique values in a certain                                 field now the real power of facets is                                 aggregations there is the power of                                 aggregations I said facets yes                                 okay so the real power of aggregations                                 is the fact that you can nest them the                                 the bucket aggregations can have sub                                 aggregations so for example we can get                                 the tag cloud but also for each tag we                                 can get the number of videos uploaded                                 yeah for each tag each month                                 does that make sense yes okay okay don't                                 kill me those two things are not equal                                 when it comes to functionality however                                 the subset of functionality in solar we                                 can do with people facets                                 we again set the facet parameter to true                                 to enable them and we use the facet                                 pivot parameter what we'll get in result                                 is that Solar will nest the facets here                                 facet counts for example in this in this                                 case we will get the tags group of                                 facets and under each tag we'll get                                 their views and the number of documents                                 with the given view it's not as powerful                                 as aggregations but still sometimes it's                                 worth checking out what we would like to                                 show you now at least a small portion of                                 it is that we like to graph things all                                 of them                                 we have monitoring solution called SPM                                 in cymatics we have search analytics we                                 also do graph logs and what we will now                                 show you is a small portion of logging                                 graphing right yes how many of you                                 already know Cubana I know some of you                                 don't do all right                                 so Cubana is a okay so Cubana is a                                 visualization tool built to work with                                 elastic search and you can build your                                 own dashboards and basically graph all                                 the things this is just an example of                                 what you can do on the left side you                                 have a widget that will show you the                                 breakdown of videos for each tag and on                                 the right yeah also breakdown of videos                                 for each tag but this time will not show                                 the number of videos put the number of                                 views and if you search for something                                 then all the graphs will be                                 automatically adjusted to only the                                 results that match your search there's                                 also a or actually more than one work of                                 kibana that should work for solar I                                 didn't actually use them but they work                                 and when it comes to operations when it                                 comes to operations you probably want to                                 monitor your search engine the lots of                                 monitoring products out there we have                                 our own SPM that works with                                 elasticsearch solar and a bunch of other                                 stuff but for now we want to show you                                 what works out of the box and with                                 elastic search you have the stats api's                                 which will get you                                 lots of metrics from how much time you                                 spend indexing to how fast your queries                                 are or how much memory is used and stuff                                 like that in solar it's not a single API                                 that is available however we can get                                 statistics from all the ambans that are                                 provided in JMX by solar so we can                                 connect to the JMX using a simple tools                                 just like j console from the GDK that                                 you have and we can check each plug-in                                 that is registered in this JMX mbeans                                 and we can check things like number of                                 requests percentiles error counts                                 average response times average run times                                 and stuff like that the thing is that                                 all those statistics are per node                                 displayed in the solar at mean by                                 default so if you go to the solar mean                                 you can see the standard the top image                                 the standard stuff that when it comes to                                 memory usage and of course the bottom                                 image shows some statistics fetched from                                 the JMX like we can see the handler                                 start timestamp we can see the request                                 number errors timeouts total time                                 averages percentiles and so on in                                 addition to that we have the cluster                                 state which is stored in the zookeeper                                 and provides us with the information                                 about all the cluster related things                                 like where the nodes are how they are                                 named what are the replicas word what                                 are the leaders how healthy there are                                 and stuff like that you can just get it                                 from zookeeper or or from solar we told                                 you in the beginning about the backup                                 however we left the left side of solar                                 or with the backup empty that's on                                 purpose because you can do a hack in                                 salt cloud actually to enable multiple                                 replication handlers however the data                                 will be replicated outside to a second                                 cluster or a second or a secondary node                                 or something like that however that's                                 not automated enough in at least for                                 from our point of view to be considered                                 a viable backup solution because you                                 can't just restore it on-demand you                                 can't store snapshots or in a given time                                 another that's not a viable solution                                 that                                 we would use apparently and that can be                                 used without additional automation with                                 elasticsearch as with everything you                                 have an API this one is called snapshot                                 restored and the point is you you would                                 define a location where you want to                                 store your backups and then you can                                 start running incremental backups by                                 hitting the snapshot API there and you                                 can also use the same API to restore and                                 this works this works across all the                                 data of your cluster so speaking of                                 clusters let let us show you how you                                 would scale out both solar and                                 elasticsearch and I want to ask how many                                 of you already know how solar scales                                 right okay about elastic search a bit                                 more okay great                                 so we'll start our gain video with solar                                 what we'll start with is a single node                                 deployment we will start it and run it                                 in a salt cloud mode however we don't                                 use external zookeeper to keep the                                 single to keep things simple instead we                                 will use an embedded one by specifying                                 the city run parameter will also specify                                 this the host and we just start solar it                                 started however to create a collection                                 we need a configuration to be uploaded                                 to zookeeper so we can just check it                                 just no collections available so let's                                 create one to do that as I already                                 mentioned we need the configuration                                 stored in zookeeper we will do that by                                 using a standard script provided in                                 solid deployment that's the GTA client                                 but we can upload config to a given                                 zookeeper specifying the configuration                                 directory and the name of our collection                                 it will upload leave all the files that                                 are relevant and we can now use the                                 collections API to create a new                                 collection will name it scale this will                                 give it to a single chart with                                 replication one which means it will only                                 create a leader and we use the                                 collection named called IBAs which we                                 recently uploaded when it's given as                                 second actually too                                 and we can now refresh the admin page                                 and we can see that the scale this                                 collection has been created with one                                 shard and placed on a note let's now at                                 the second node because we are running                                 on a single PC we started the node on                                 just a different jelly port and we                                 pointed the ZK host parameter to a local                                 host                                                                    will the next node will use the same                                 zookeeper which was embedded in this                                 first one it started started actually                                 and we can see that the number of nodes                                 were updated and we can now add a                                 replica here so to do that we'll again                                 leverage the collections API with a                                 command called add replicas we specify                                 the shard identifier the collection name                                 and we specify the node name on which we                                 should create the replicas the thing is                                 that solar won't automatically place                                 your replica on the node you want it to                                 be so that's why you need to specify the                                 name of the node you can get the name                                 out of the cluster state however it's                                 built very easily to guess the name                                 because it's an IP address the port                                 underscore solar so let's run the                                 command ok it executes it and now we can                                 look at the admin panel to see what                                 happened as we can see we have two                                 collections now single leader and the                                 second one which is a replica and is                                 active and now let's create a third node                                 running again on the same PC with a                                 different with a different port start it                                 and let's create a second replica here                                 so we'll have high availability on a                                 single PC again collections API were                                 used was used and we have it let's look                                 at the two replicas oh okay so now a                                 little bit of magic let me let's imagine                                 that we have a certain use case we've                                 indexed our data we don't have our                                 initial data available what to do when                                 it comes to a time when we don't have                                 the capacity of a single node to handle                                 data so give us four                                 to death which means that it can split                                 the shark out of the box let's do that                                 let's split our shark into two new ones                                 we do that again with a simple API                                 command which is the split chart as you                                 can see in the bottom we specify the                                 collection name and the shark we want to                                 split the sample as running that command                                 and we'll see in the panel admin panel                                 what happened actually                                 Saur created two collections to shards                                 out of the our initial one the short one                                 oh and the short one one of course all                                 the replicas were created they are now                                 recovering when i refresh it and after                                 that you can see that we have three                                 sharks being available one the original                                 one which is empty and solar left it on                                 purpose                                 there are many use cases where that's                                 how it should be because people still                                 run queries against that chart however                                 that collection that chart will be empty                                 so in the background distributed all the                                 data it divided the data in more or less                                 health and pushed some of the data to                                 one short some of the data to the other                                 shot the hash ranges were divided so the                                 cluster state is again stable and useful                                 and we can now if you want delay delete                                 the initial chart and we'll be left with                                 two two charts of course on large data                                 that can be a painful process but if you                                 don't have any other solutions that's                                 one of the available let's now look at                                 elastic search                                 okay so elastic search is this is yes it                                 is okay so lastly search is clustered by                                 default so if you just start one node                                 you will say hey I'm the master of my                                 own cluster and what we're going to do                                 here is we're going to create a new                                 index with two shards and this thing is                                 the elastic search head plugin it's a                                 small plugin that you can use to                                 visualize the state of your cluster in                                 this case you can see our node and                                 the index with two shots and you can                                 also see for each shot there is one                                 replica that because the last research                                 wants to replicate by default the the                                 data once but in this case because we                                 only have one note it doesn't make sense                                 of the replicas pic are unassigned but                                 if we start another note then by default                                 it will look through multicast it will                                 look to see if there are other notes                                 already available and we have one so it                                 joins the the cluster of the first note                                 and what happens next is that the                                 replicas that were previously unassigned                                 would be created on the new note so now                                 we want to scale out even more so we                                 start to other nodes and again they will                                 join the cluster and from this point on                                 all the shards in the replicas will be                                 balanced across the available nodes any                                 moment now and this also happens when                                 you scale back down so if you shot the                                 unloads what happens is that if a                                 primary shard is not available then the                                 rep one of the replicas will get                                 promoted to a primary and new replicas                                 will be automatically created so you get                                 back to the state that you configured                                 and now we should be back to the one                                 known situation so this was the overview                                 of the features that we wanted to show                                 you should I just thank you I want to                                 show you from solar and elasticsearch                                 but the thing to remember here is that                                 both are very active projects are                                 supported by strong communities so                                 there's juicy stuff always added to both                                 search engines                                 so to get your some of the new juicy                                 things that will happen here so for                                 example let's start with solar we have                                 the facet from by function issue that is                                 being worked on and that will promises                                 to give us a possibility of calculating                                 facets on the on the values of return of                                 return fact by functions so that's                                 something with something very very nice                                 at least in my opinion will also get                                 which is already almost finished the                                 analytics component will allow us to do                                 more extended analysis or our data so                                 solar will be not only search engine                                 with some additional functionalities                                 when it comes to data mining but also an                                 analytics platform finally hopefully                                 four five oh and the talks were started                                 Seoul will get to a point where                                 elasticsearch is right now when it comes                                 to handling and installing it will                                 become a standalone application just                                 like you in silastic search my sequel or                                 any other solutions out there so if you                                 saw no more web app no apparently it                                 will still expose HTTP API because                                 that's solar but but no web app there                                 when it comes to elastic search the                                 thing is remember we mentioned grouping                                 so it was already committed the top hits                                 aggregation will give us the possibility                                 of field collapsing occur grouping on                                 this d                                                                 coming in one three elastic search was                                 committed to master already will have                                 the minimum should match on has child                                 queries which again is a nice thing at                                 least in my opinion we'll be able to                                 control that and finally what we wanted                                 to say is that filter segregation will                                 be also available in elastic search and                                 will give us the possibility of using                                 filters in aggregation calculating                                 aggregations on the basis of the filters                                 finally a few words about what to choose                                 because those are usually the thing that                                 can when a client comes to us and say ok                                 which platform to choose and we tend to                                 say that they're very small                                 very few showstoppers out there to tell                                 you that you shouldn't go with that                                 solution at all however there are many                                 small differences because doors are                                 totally different products that's that's                                 how it is if you are ready at least in                                 our opinion if you already use                                 elasticsearch or solar in your company                                 on your environment go with it why not                                 why bother and chew and tell DevOps                                 to you learn different things to learn                                 how to scale how to tune how to                                 configure it and give them a pain                                 actually they will love it for it if                                 you'd say I'm going to for elasticsearch                                 because we already use it in certain                                 products I'm going for solar because of                                 the same so in our in at least the work                                 with the work we do most projects will                                 fit both solar and elasticsearch there                                 are some things that can't be achieved                                 using one or the other but there are                                 very few use cases that will go that way                                 what I would like to say is go for the                                 one you like the best                                 go for the one you are actually familiar                                 with maybe and you like to laugh would                                 you love to work with but because that's                                 what we actually do so if you want to                                 work with elasticsearch or solar or both                                 we're hiring wherever you are and thank                                 you very much                                 by the way all the commands and things                                 we've used are available on that each                                 would have a github account that URL so                                 if you want to do the scaling for                                 yourself you just run a single command                                 and it will download soul elasticsearch                                 for you it will run the commands and                                 packet index your data and show you the                                 scaling stuff thank you very much thank                                 you                                 okay we rush the gift so if you have any                                 questions please just do the rock star                                 you know so a question about scalability                                 you had so the the video on how to scale                                 solar mm-hmm I have the impression that                                 you had a single point of failure in                                 your in your architecture there the                                 zookeeper exact you you can use multiple                                 zookeepers this is this was only a                                 simplicity for simplicity reasons I've                                 run it with the embedded one actually in                                 production what would like to do is have                                 another example so called with multi                                 multiple zookeepers running and talking                                 to each other apart apparently to have                                 an assemble you need at least three of                                 them to be running those are really nice                                 and light processes to run and in                                 production usually you start with three                                 because that's when you can allow one to                                 fail and still the example to be                                 available solar allows you to give him                                 the it the list of of zookeeper                                 addresses so there is no a single point                                 of failure introduction of course in                                 developer mode or something like that or                                 like the demo here you don't need em                                 extinct some additional cluster of                                 zookeepers but that's that's how it                                 works                                 okay so in your example if if the first                                 node was down then your whole cluster                                 was down yes yes this is this is how it                                 would work in example because we have                                 only a single zookeeper in that's why we                                 didn't show for simplicity reason what                                 happens when the first node was down how                                 the replicas are actually taking the                                 leader in the leader roles however it                                 will happen automatically which solve                                 that's that's the whole reason why we                                 have replicas right however yeah please                                 remember that for production you want                                 and extreme external zookeeper and                                 sample to be running not the one with                                 solar that's not definitive production                                 wise thing                                 I also want to add something about                                 elasticsearch here so what we didn't do                                 and we show you the scale thing is that                                 for example if we have four clusters and                                 four nodes and two can't communicate                                 with the other two then you have a split                                 brain and that is very nasty so what you                                 can do to prevent that is to set up the                                 minimum master nodes configuration to                                 more than half of your cluster so that                                 would what what this does is if on the                                 on the side of the split brain there are                                 less than that configured manual master                                 nodes as in master eligible nodes then                                 those nodes will not form a cluster so                                 that you you won't have a split brain                                 okay any more questions                                 No thank you very much and enjoy the                                 rest of the conference
YouTube URL: https://www.youtube.com/watch?v=LA-rbmuSROM


