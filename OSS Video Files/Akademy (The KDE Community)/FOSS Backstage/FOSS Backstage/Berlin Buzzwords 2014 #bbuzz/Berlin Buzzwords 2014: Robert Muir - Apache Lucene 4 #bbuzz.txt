Title: Berlin Buzzwords 2014: Robert Muir - Apache Lucene 4 #bbuzz
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	Apache Lucene is an open-source search engine library written in Java. This talk will give an overview of its current capabilities.

This talk will give an up-to-date overview of Lucene's features. Many improvements have been added since the last revision of Lucene in Action (e.g. autosuggest and faceting), and many previous talks about these incremental improvements, but the idea is to summarize the current state of what Lucene can do.
 
Read more:
https://2014.berlinbuzzwords.de/session/apache-lucene-4

About Robert Muir:
https://2014.berlinbuzzwords.de/user/297/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              this tall kind of tries to say this is                               Lucy now and this is what we can do I                               can't talk about everything it can do                               because there's too much but we can kind                               of get into the major areas and if you                               haven't usually seen then you might have                               an idea of what this thing is all about                               so just to start this is my idea will                               will overview loose teen so if you                                download this thing and unzip it that's                                what we're going to talk about what are                                the different folders and what can it do                                afterwards I'll just make some general                                conclusions and then we'll have QA we                                can dig into anything that you're                                interested in so again if you download                                bluestein you're going to see a list of                                stuff like this there's actually                                probably                                                               have all the time in the world so we'll                                just do some of them but these are                                basically the different modules of                                leucine it used to be that you had                                leucine core and kind of everything was                                shoved in there and then you had various                                contributions that were external but                                we've tried to organize it so it makes                                more sense in losing four and this is                                what it looks like so we'll kind of go                                through the important ones here starting                                with losing core so the leucine core                                library this is the minimal you need to                                do anything related to search with                                leucine the other stuff is kind of                                optional but but this one's mandatory                                and we'll talk about why so at the basic                                level this is what we're trying to solve                                here the ability to type in some                                keywords like this and and get search                                results very fast they're relevant so                                the key parts of this are a fast                                response time irrelevant results and you                                know everything else is sort of a bonus                                so this is this is what search is all                                about here so how does this work how is                                it fast well the main reason it would be                                fast first to say a database because we                                just searched say billions of web pages                                very quickly is that we have inverted                                index and the index is sort of like back                                of a book you turn to the back of the                                book and you find your search term                                because you sort of know that there you                                know the words in the back of the book                                are in a certain order they make sense                                and then once you find your term then                                you have a list of pages that it appear                                and this is actually exactly what's                                happening with leucine and that's all                                it's doing so you can do it manually or                                you can use listening to do it so this                                process of creating this reverse index                                this is what leucine court does it can                                do it pretty fast you can use multiple                                threads to do it this this all works                                with some hardware you can get like                                speeds like                                                             is pretty fast it does depend on the                                size of your documents and the type of                                processing you're doing what your speed                                will be and we'll talk about some of                                that processing later but in general                                it's pretty fast one thing about it is                                you don't just build this one time like                                I have my book let's build an index for                                it you can sort of do this incrementally                                so you can as you're writing your book                                you know you're also updating the index                                and this is important you can also                                delete things as well so this this sort                                of is different than the old batch model                                and we've seen sort of grown to be very                                well at near real-time search so when                                new documents are coming in there                                they're searchable very quickly beyond                                full text like we think of this is the                                classical I our problem of search but                                these days people have structured data                                is very common so you have numeric                                fields you have dates and listing has                                support for for doing search with these                                kind of things as well so it's it's more                                than just a text search you can use it                                actually to zoo kind of a mix of                                structured data and unstructured data so                                let's talk about how we might customize                                this process probably the most important                                part is called the analysis chain and                                what this does is this this is the rules                                 for when we're creating this index in                                 the back of the book this is the rule                                 for what is going in there when we take                                 a document or a page of a document how                                 do we determine what should go in the                                 index which words are important which                                 ones aren't important you know how                                 should they be listed there and that                                 that's what this is all about and so                                 this is probably the most important part                                 to understand about leucine if you want                                 to improve your search results because                                 this is what it's all about so analysis                                 is at a basic level we think of taking a                                 page and we want to get the words out of                                 it words are pretty good features for                                 search and so on the first                                 for this is a tokenizer how can we split                                 it into words you know a simple one is                                 to split on white space for it for some                                 cases but we might also want to do more                                 we split in two we split into words but                                 this isn't quite enough you know we may                                 want people to be able to type in                                 uppercase or lowercase and in these kind                                 of fancy things so so we might do some                                 normalization and processing as well and                                 this is all language dependent so there                                 are some language independent techniques                                 but generally for each language you have                                 a different strategy and we'll talk                                 about what loosing does here so again we                                 start with a tokenizer we need to split                                 things into words that's the job of the                                 tokenizer and we've seen and then to do                                 the normalization we have token filters                                 and so when I talk about an analysis                                 chain it means you have a combination of                                 these things you have a tokenizer and                                 some filters it's not mandatory to have                                 any of the filters you can just have a                                 tokenizer you can keep things very                                 simple it's probably a good place to                                 start but you got to have something so                                 here's an example tokenizer just to                                 illustrate what I'm talking about so we                                 have we have a small document it's just                                 one sentence and we just want to split                                 it into words this is all it's going to                                 do so there is one of leucine called the                                 whitespace tokenizer and then there's                                 there's                                                               fancy and complicated and some like this                                 one are very simple but in this case                                 this one does a pretty good job it's                                 almost exactly what we want for the                                 token filter again we want to do some                                 normalization the the words that I split                                 weren't quite good enough for search                                 because we want people to type in you                                 know uppercase lowercase we maybe don't                                 want to have worried about plural forms                                 versus singular forms and so we have                                 some filters that can do this we have a                                 lowercase filter and it lower cases                                 these words that were in uppercase and                                 we have a stomach laurels or try to and                                 so there's there's almost a hundred of                                 these filters in the scene to do various                                 tasks so it's really flexible what you                                 can do when you build this chain of                                 processing and you can say I went to                                 first do synonyms and lowercase stop                                 words whatever you want to do so you can                                 also write your own you can plug in if                                 you don't like what we have but I think                                 generally we found that what we have in                                 lucene is enough for a lot of use cases                                 so again we can think of this list of                                 tokenizer xand token filters as an                                 analysis chain we call that enlisting                                 the analyzer and this analyzer is is                                 usually a next time and it's also used a                                 query time so when the documents come in                                 we analyze them when the queries come in                                 we also analyze them as if they were                                 documents and and and that's how search                                 works that's how we have search terms so                                 for the different languages we have                                    languages in the scene out of box so you                                 may find that it does enough for it                                 doesn't but it's better                                 internationalization support than                                 previous versions of leucine so um you                                 know this will be useful for you so now                                 that we've talked about the analysis                                 chain there's a little bit more involved                                 we want to take these queries from the                                 user but we don't want to have to you                                 know define rules to the user like SQL                                 where the user has to type the you know                                 special syntax to get their results how                                 should this work you know if you if you                                 have unpaired punctuation in Google does                                 it give you an error or does it just                                 continue to give you results but in some                                 cases you know maybe you do care you're                                 very specific about what you want and                                 you do want this error like SQL so                                 English seeing we give you we give you                                 both ways to do things and I'll talk                                 about that and basically unlike other                                 search engines we've seen does not have                                 a query language we have several and you                                 can write your own so it's not hardwired                                 into leucine and this is a big benefit                                 so again back to our index let's start                                 to think about how queries could be                                 built from this index we have our search                                 terms and our list of documents                                 associated with each one and I'll make                                 an example here circuit in parallel and                                 we can take these lists and think about                                 how you would do say in or query or an                                 end query or not query and it's the                                 obvious choice is just if we want to do                                 an or then we will Union the lists if we                                 want to do an end we intersect them and                                 for not it's just subtraction so it's                                 working                                 sets right so in this case we just                                 created sort of three queries for our                                 back of the book index that we wrote on                                 a piece of paper and now we have queries                                 and we've seen has api's for this to do                                 end or not programmatically so you don't                                 have to use a query language but it's                                 much nicer to use one because instead of                                 you know having to write an API each                                 time the user can actually use these you                                 know special syntax like the plus sign                                 in Google or and or whatnot and so we                                 have two ways again the strict one                                 throws an exception like SQL and then a                                 lenient one that's that doesn't it just                                 does the best it can takes a guest at                                 what the user wants which is more like                                 Google or if you're not happy with this                                 build your own another feature pretty                                 important is is we we did the search at                                 return the documents but why and and do                                 I care about this document how do I know                                 without actually reading the document                                 it's like chicken in the egg so you know                                 an important feature is called                                 highlighting and what this does is it                                 allows you to make relevance judgment as                                 a user is this document relevant to my                                 search or not it's really important so                                 there's two main features of this that                                 that are key to think about and that's                                 the snippets these are sort of the                                 sentences I'm choosing for this document                                 and then the search terms themselves the                                 this is highlighting what the user                                 actually typed in so they see the                                 context in lucene we have three                                 highlighters they all have different                                 sort of feature sets different                                 capabilities use different data                                 structures and algorithms it depends on                                 your use case I'd recommend just using                                 the one called highlighter as a start                                 but you know you have other choices you                                 can do you can customize how these                                 sentences are picked you can customize                                 how the search terms are highlighted                                 should they be bold or colored red and                                 things like that so you have a lot of                                 flexibility all the highlighters have                                 these features but they work slightly                                 differently for four different cases so                                 we talked about search and entering in                                 keywords it turns out these days this                                 isn't enough like users don't type                                 things correctly users may be don't even                                 know what they're searching for                                 completely so it would be good if as                                 soon as I start typing characters                                 we can start to give them relevant                                 information even if that's just                                 suggesting what they may want to type or                                 actually giving them instant search with                                 documents so when we've seen we kind of                                 think about a suggest package where                                 we're we're suggesting things to the                                 user this might be what you want right                                 and so we're going to suggest either                                 queries or did you mean try to correct                                 your query and these are two features I                                 think are expected these days of any                                 search engine so we start with suggest I                                 think everyone's seen this you know you                                 go into google and you type in a few                                 words and we've already completed with                                 Berlin buzzwords just typing be you so                                 that's that's kind of interesting                                 buzzers is getting pretty popular but we                                 can do this english teen we have the                                 same feature for auto suggest and it has                                 a lot of power and a lot of flexibility                                 one is that analysis ching i talked                                 about the suggester can use that so you                                 can actually implement all those rules                                 like do I want it to be case sensitive                                 or not do I want to remove accents and                                 things like this so the analysis chain                                 plugs in to the suggester and this is a                                 powerful combination I don't recommend                                 anything crazy with it but it's it's                                 enough that you can tweak the behavior a                                 good deal another thing that has that                                 sort of separate from this is the                                 ability to correct typos so you know I i                                 misspelled things all the time and so I                                 always appreciate it when the auto                                 suggester just corrects my spelling is                                 this makes life so much easier this can                                 also be kind of risky you could you can                                 bring back bad suggestions so you have                                 to be careful about it but we do we do                                 offer the the option and leucine to do                                 this and then finally there's sort of                                 another way to correct errors and that's                                 I put the words in the completely wrong                                 order we can think of that as in fixed                                 suggestions so that's it happens                                 occasionally with google it seems kind                                 of rare but you're typing in keywords                                 and then it just suggested you one right                                 in the middle and sort of reorganizes                                 the order of the words you typed in but                                 this can be useful in some cases finally                                 you know there's the idea of suggesting                                 queries to the user but sometimes we                                 want to suggest we want to attach a                                 little bit more like if we're doing                                 Facebook and we do auto-suggest why not                                 show their picture you know why not have                                 a linked right to their Facebook page                                 why should I actually have to search                                 don't suggest a queer                                 you just suggest the person to me so you                                 can attach something called a payload                                 for example the idea of the document or                                 a link to their photo or whatever and                                 you can do this with the scene the same                                 way and finally one part about                                 suggesting is tricky is what about this                                 order of the suggestions coming back you                                 know this is really important to get the                                 right order because usually users are                                 they're looking at this as a type and in                                 the ones you know closest to them or                                 might be the ones they're going to pick                                 so you have this idea that we can kind                                 of define a scoring algorithm for for                                 how these things should be ranked and                                 leucine leaves that to you and we have                                 this module called expressions that                                 allows you to define that and we'll talk                                 about that in a little bit so i talked                                 about suggests we have the idea of did                                 you mean this is sort of after the fact                                 old-school spell checking i think it's                                 it's sort of less useful then then                                 suggest the idea is if you can catch it                                 while they're typing it that's better                                 but sometimes you know it Google                                 suggests something to me I just ignore                                 it and keep typing my wrong stuff anyway                                 and it'll say okay really did you mean                                 this or maybe even I i went ahead and                                 searched on this for you because i                                 really think you screwed it up so                                 instead of returning zero results this                                 still has a use case right you may not                                 want to return zero results so you can                                 just say did you mean this and it's it's                                 something more useful to the user we can                                 do sort of the same similar algorithms                                 and we've seen you can use in grams                                 through to do this kind of correction                                 here you can use edit distance so                                 there's different ways to figure out how                                 to correct typos and you sort of can                                 choose what those are well one thing                                 that's interesting is is when the words                                 themselves you know our have spaces sort                                 of speak they typed in not just                                 misspelled words but you know the the                                 words aren't even correct an example of                                 this is I you know if i type buzzwords                                 and put a space in it we all know                                 buzzwords doesn't have one here but you                                 know if you do this actually Google will                                 bring back Berlin buzzwords it will work                                 fine so this is like a form of spell                                 correction so controlling the ranking of                                 this stuff with the search engine we                                 have this built-in ranking that's you                                 know sort of based on how close the                                 aquarius to the document but for all to                                 suggest how should this work you know                                 how should we rank things and                                 the idea here is that you just define                                 the formula yourself we don't know it                                 usually depends on your use case so this                                 is sort of a newer module added in                                 loosing for and I'll give an example                                 search here I go into Google Maps and                                 just search for beer this is actually a                                 query that I have run recently but uh                                 look at you know on the side it comes                                 back with these with these documents you                                 know these are places I can get beer                                 what is the ranking how did they figure                                 this out is it based on how close they                                 are to me is it based on how many                                 reviews that each one had and what was                                 the average rating I have no idea maybe                                 some combination of those things and                                 practiced right all these different you                                 know things that contribute to the                                 relevance of each one well this is sort                                 of what the expressions module is about                                 is allowing you to just define something                                 like that yourself in JavaScript so you                                 can come by and say leucine score some                                 numeric field you have like like rating                                 or popularity and your and you can even                                 do things like geographic distance just                                 like this example so I'll give a fake                                 version I don't know that this is their                                 ranking algorithm is something I made up                                 but this you know take the average                                 rating multiply it by you know number of                                 ratings / distance something like that                                 this this is what this package does and                                 what and when you do it and you created                                 it it's not it's not slow like                                 JavaScript it uses the language but we                                 we compile it to java bytecodes so it's                                 the same as if you win and leucine and                                 extend it a bunch of classes yourself in                                 Java and wrote your own sort algorithm                                 so it's very fast so we talked about                                 suggestions we've talked about basic                                 searching highlighting what about when                                 it documents get a little more                                 complicated they have saved more than                                 one dimension well this is this is sort                                 of what the joint module is about we can                                 we can look at this example here if                                 you're in the US this is a funny example                                 i think in europe you may not get the                                 joke but uh this three wolf shirt you                                 know I'm gonna go on Amazon I really                                 want this shirt so I might search for                                 the size I want and the color in this                                 case I want it in blue extra large wolf                                 shirt well it may turn out that behind                                 the scenes I sell this product this this                                 wolf shirt                                 they only have you know blue ones in a                                 certain size so I have blue ones in                                 extra-large and I only have the red ones                                 in size small well if I search for you                                 know an extra large one that's red                                 should i should i get back any documents                                 no i mean and this is kind of hard to uh                                 to deal with this normalization in a                                 database you might use a joint                                 historically and so that's how this this                                 feature got its name but the way we                                 solve it is instead of sort of de                                 normalizing this into one big fat row                                 because it doesn't really fit right it's                                 one too many then we'll just actually                                 represent it one too many as a nested                                 document and that's what this this                                 feature allows you to do so i can                                 actually do a search this says search                                 give me a wolf shirt with this size in                                 this color and it sort of joins those                                 those records together so this again                                 it's an alternative you could still do                                 normalize yourself but I think sometimes                                 this is a way more intuitive way to look                                 at your data so there's been two talks                                 on this feature already I think they                                 came at it from                                                          from elastic search side it's called the                                 percolator but this is the idea of                                 turning search backwards I'm turning it                                 around actually I do it in Google I I                                 register an alert it says you know if a                                 new document comes into the internet and                                 it's about this that you know tell me                                 about it send me an email alert me so I                                 don't know if anyone's use this feature                                 but you know I can I can go and register                                 Berlin buzzwords and if a new document                                 shows up talking about Berlin buzzwords                                 I would get notified about it how would                                 you do this you know it sounds pretty                                 tricky but actually leucine already has                                 this feature built-in it's had it for a                                 long time the way it actually works                                 behind the scenes is each time a                                 document comes in we built the back of                                 the book index for that one document we                                 run a ton of queries against it which                                 are all very fast because it's a tiny                                 index and then we throw it all away and                                 I mean it sounds terrible but this                                 actually works really fast and so you                                 can register you know thousands of these                                 alerts and an index of one document run                                 them all very fast less than a second                                 and then send out your alerts and                                 everything works                                 so our back of the book index we've                                 talked about you know all these                                 different capabilities we can build off                                 of it but uh you know how does this                                 thing actually look we know it doesn't                                 actually look like the back of the book                                 that we've been describing but in fact                                 there's compression and and there's                                 there's different choices you can make                                 and different data structures and                                 trade-offs it's what we didn't leave                                 seen is we made these these backends                                 pluggable the way we represent this                                 thing and I'm going to give a little                                 example on you know how that would work                                 so let's take our back of the book index                                 on a piece of paper and let's think                                 about how we might compress this a                                 little bit right just our own form of                                 stupid compression so here's an example                                 I have the O's in the peas and you know                                 what we know here in our back of the                                 book index that all the words beginning                                 with oh we put them under oh and we all                                 the ones under P we put them with P so                                 there's some redundancy here right why                                 do i need to actually have the peas for                                 parallel and proton when I already know                                 they all start with P because they're in                                 the P section so that's exactly how our                                 little compression here is going to work                                 right I'm just removing the redundancy                                 here so this is sort of what the codec                                 module is about I had this idea it's                                 kind of silly and it's a basic example                                 but I did a little bit of compression                                 here and I think maybe this is useful so                                 I can implement a back-end that stores                                 my back of the book index this way and                                 and you might have a different approach                                 that you want to do that's different we                                 don't have to have just one format for                                 leucine anymore we can have choices and                                 they work for different use cases and                                 this is what the Codex module is so for                                 example right now there's someone                                 working on one specific for primary keys                                 unique IDs that there's formats that are                                 sort of geared at different use cases                                 and they're more efficient or and they                                 might be less efficient in general but                                 for this type of data they're they're                                 very good so with the Codex module you                                 can plug this in you can customize how                                 the back of the book index works even if                                 / field level for your documents you can                                 say again that this is the primary key                                 field use use this format this is a you                                 know a big big piece of text use this                                 other format and so you know this is                                 pretty powerful you can you can really                                 implement your own stuff your own                                 customizations to loose teen you could                                 plug into some you know crazy way that                                 the current                                 lucene doesn't have a clean way to do                                 because you have a lot of a lot of power                                 here you're kind of underneath all the                                 guts so an example here would be you                                 know maybe I want to put my terms in a                                 in a try structure or another guy wants                                 a binary tree or whatever and we could                                 argue about it or we could just                                 implement both of them and give people                                 the choice and that's what the Codex                                 module does so I went through a lot of                                 these modules i wish i could do all of                                 them but there's a snotty enough time so                                 what I want to do quickly is list the                                 other modules that we have available                                 with just sort of a quick summary of                                 what they do including the ones I wasn't                                 able to address so we have a                                 benchmarking packaging we've seen this                                 just is a way to sort of write it write                                 a file that says I want to do                                 benchmarking of this specific component                                 it's kind of useful if you're developing                                 leucine code we have a classification                                 this is actually doing document                                 classification based on the statistics                                 in the index so it's an interesting way                                 to look at it that's new that's new and                                 listing for we have a demo module this                                 might be the first place to start if                                 you're actually playing with the code                                 and you're looking at you know this list                                 of folders and thinking well where do I                                 start I start with the demo because this                                 is a small little app that can index                                 stuff and search it and you can maybe                                 your start and build off of that we have                                 faceting which I really wanted to talk                                 about fascinating is is is sort of this                                 this browsing and searching combined                                 that you used to when you go to                                 e-commerce site and it tells you your                                 search match things in these different                                 departments and things like that but                                 this is really powerful it has a lot of                                 features based on it you note just                                 unfastening for example you can use                                 ranges that's it by distance you can                                 plug into the expressions I talked about                                 earlier so it hooks into other into                                 other things we have grouping in a                                 similar way you can group by um you know                                 terms so this is like I have results                                 it's different than the join in the                                 sense that they're not really                                 parent-child they're just related and so                                 this is the idea I just want them                                 together and sometimes when you search                                 like Berlin buzzwords i think is a good                                 one if you search for it you'll find                                 that google returns like five                                 six documents and it groups them all                                 under Berlin buzzwords because they're                                 all at that website so that might be an                                 example use case for grouping but you                                 can group by function you can group by                                 expression so it again has the same                                 hooks into things like fastening does so                                 you can combine these modules to really                                 customize the experience we have a                                 folder full of index tools this is low                                 level stuff like splitting an index in                                 half things like that this can be useful                                 if you're doing a distributed computing                                 you want to split your index to sort of                                 to Rashard and there's some other                                 interesting tools in there like pre sort                                 your index and things like that it's you                                 just have to look and play around I                                 talked about queries we built a little n                                 or and not query for our back of the                                 book index but there's a lot more type                                 of queries you can use for example you                                 know you could imagine an ex or query I                                 don't think it would be useful but you                                 could build it and so that kind of thing                                 goes into the queries module is just                                 additional queries that met someone's                                 use case at one point in time we have                                 replication this is just sort of a                                 simple API to take the contents of one                                 index and keep them in sync across                                 machines and this is useful if you have                                 more website traffic than you know you                                 had before you just want to scale it                                 scale it out by adding more replicas so                                 we have you can do that just what we've                                 seen we have a sandbox uh this is where                                 I like to put code now when I write it                                 because I feel like it has a lower bar                                 to entry but you just you know this is                                 something that it's not quite right                                 about the code but there's some                                 interesting fun stuff in there so look                                 around we have we have spatial support                                 more than what I talked about with the                                 hammer sine function in the expressions                                 that's very basic but there's also you                                 know some some polygons support and more                                 complex geospatial support in that                                 module and we have this test framework                                 finally and there's an important one                                 because this is basically our test                                 harness we use to test Alou scene itself                                 so if you're using loosing as a library                                 you can just you also use our test                                 harness if you'd like to test your own                                 code and we found it does a lot of                                 things like detect file leaks as you                                 know things like that usually if you                                 start with just j unit you're not going                                 to have that level of test cover data                                 box so if you want to use the same test                                 infrastructure that                                 we use it's just a library and you can                                 use it so I kind of ripped through as                                 fast as possible all of the different                                 modules in lucene I wish that I could                                 have gone in depth on each one of them                                 because they're interesting but you know                                 since we only have so much time for a                                 deeper look I would just download                                 leucine unzip it you're going to see the                                 same structure that i just presented                                 here and accept then you can go and look                                 at the source code and get way more                                 information on it if you haven't been to                                 the loosing website we have the javadocs                                 for all the api's you can get the                                 download leucine in action is still be                                 useful it's a good book to start with if                                 you're just getting started with racine                                 but it's a little out of date in the                                 sense that it mostly these modules you                                 won't find in lucena in action because I                                 think they didn't exist at the time so                                 that's it questions                                 please wait for the mic                                 I am actually have several questions one                                 is about generating tokenizer code I                                 remember you were using J flex but it                                 was kind of not very well supported                                 library back then I did anything change                                 from this time and the second question                                 about classification can you please                                 elaborate more on it what kind of                                 classification you do and how does work                                 just in a few words thank God okay let's                                 start first with the the tokenizer one                                 so um yes we still use J flex for for                                 our standard tokenizer but as I                                 mentioned we have                                                        'he's so you don't have to use it if you                                 don't like you you know you could                                 implement your own using using anything                                 you like you can just hand write it in                                 Java code if you want but yeah that is                                 that is our standard one and we still                                 used a flex and one of the committers on                                 j flex is also a leucine committer so i                                 think it's it's it's still being                                 maintained its it's still being released                                 and it works quite well it's just you                                 know the the generated code doesn't look                                 great because it's generated code that's                                 just the way it works as far as the                                 classification module you're asking how                                 the scoring works for classification                                 what type of algorithms as far as we                                 remember we we have K nearest neighbor                                 and there's one more that we have simple                                 simple naive Bayes some yeah so I'm not                                 really a classification guy you're gonna                                 have to look at the code if you want                                 more information on it that's probably                                 the best place to start thank you for a                                 talk have questions are gonna garbage                                 character i think in old times listen                                 was trying to minimize number four Jack                                 two generated during queria so to                                 minimize water and garbage character is                                 it the same as interesting for you                                 change in approach so do you mean um                                 where the code is written a little bit                                 funky way yeah yeah unfortunately it's                                 still this way I think you know                                 ultimately it will improve in Java you                                 see that they're trying to propose                                 changes like value types in Java and so                                 maybe when Java improves we can take a                                 big pass on the code and try to remove                                 some of this complicated                                 but yeah there's some extent you know we                                 try to make it efficient and then                                 there's always sort of a trade-off like                                 you know make the code readable and                                 maintainable and it's open source right                                 this is important but also make it                                 efficient in production and so you                                 there's got to be a balance there right                                 but yeah it's still kind of funky like                                 that right now I thank you for talk the                                 quality of a suggestion module or                                 suggestion function depends a lot on how                                 users use the system is there some way                                 to take into account things like query                                 logs or user clicks in a simple way will                                 the scene well right so basically what                                 we do when it comes to this and that's                                 why we have modules like the expressions                                 module and stuff is we bail out on how                                 you should rank suggestions completely                                 and we leave it totally up to you like                                 you have to figure out this problem so                                 yes I mean we don't provide tools to do                                 state query log analysis or any of that                                 kind of stuff I think on someone else                                 maybe can do a better job than us when                                 it comes to those kind of tools but you                                 know it's something we bail on we just                                 say hey will give you the infrastructure                                 to do suggestions and as far as how you                                 rank them that's that's up to you it's                                 hard I know you're running a lot of time                                 here but in a very few words if you                                 could tell us what what sort of the next                                 big things coming up for the scene the                                 next big thing I wish I knew I mean it                                 one of you guys could come online right                                 now with a big patch that changes                                 everything and then that would be the                                 next big thing right so I don't know I                                 know we're working on improving the way                                 you know positional queries work I think                                 is something that will come in the past                                 they've been kind of slower and and not                                 as flexible as we would like so this is                                 something that we would really like to                                 fix soon so for example the queries sort                                 of like the functionality you get from                                 span queries making this a more core                                 thing that works so I think that'll be                                 more useful it will also improve things                                 like highlighting because we just have                                 better proximity support maybe provide                                 stuff like proximity-based ranking out                                 of box that builds on top of that                                 otherwise I can see like you know more                                 codecs like                                 in this specialized format just                                    unique IDs I think we'll start to see                                 more of that it's it's really useful and                                 practical and we can plug in and cleanly                                 so I think we'll just be an expansion                                 better compression things like that but                                 in general it's open source we don't                                 know there's no plan or anything it's                                 just whatever comes up on the list                                 that's that's will happen                                 so we'd like to thank you again for your                                 talk oh and thanks for your questions                                 too thanks everyone
YouTube URL: https://www.youtube.com/watch?v=KyA44hBB5t4


