Title: Berli Buzzwords 2014: Britta Weber - Scoring for Human Beings #bbuzz
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	When you are running ElasticSearch for for free text search, you probably use Lucenes tf-idf scoring formula to determine the relevancy of a document. This is usually great because this formula is one-size-fits-most for free text queries. But what if you are not one of the most? And when are you not one of them?

In this talk I will explain the basics of determining relevancy of a document and how scores can be customized when using ElasticSearch.

I will start off by recapitulating the vector space model for scoring and how tf-idf works in detail - for human beings. This explanation will be accompanied with practical examples of pitfalls you might encounter when the scored text actually represents tags. I will then give an overview over the options in ElasticSearch to tweak scores arbitrarily by making use of numerical document values but also by using text features stored in the Lucene index. Finally I will show examples of how you can implement your own flavor of scoring functions like tf-idf, language model and cosine similarity without touching a single line of java code.

Read more:
https://2014.berlinbuzzwords.de/session/scoring-human-beings

About Britta Weber: 
https://2014.berlinbuzzwords.de/user/305/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              all right no I'm pritam i work at                               elasticsearch and so I joined                               elasticsearch a year ago so there was                               the first of may but I come from a very                               different background so I came from                               academia and i was working mainly on                               image processing so before i came to                               elasticsearch um i did not actually knew                               what was going on in information                                retrieval right so i came to buzz words                                last year i was only at elastic search                                for one month i was talking to a guy and                                he said oh wow you work for that search                                cool so tell me something when i put in                                google when I put the quotes it gives me                                phrases how does that work with the                                inverted index right that was very                                embarrassing I didn't know I colleague                                saved me right so i went home and shame                                i thought what to do with myself and I                                thought hey I came from academia I'm                                good at reading books right so I read                                this book this is the book if you                                haven't read it and you don't know what                                information retrieval and scoring and                                all the things i'll be talking about is                                about this is a really good starting                                place and there was two or three                                chapters about scoring that were                                particularly interesting for me so what                                I mean by scoring is determine the                                relevance of a document given some                                search request for example given the                                keywords football World Cup what is the                                most relevant news article a user might                                want to read and note that this might                                not just be related to the search things                                the user types in but it might also be                                related to time right might be some you                                want to have a news and not the old so                                are given the criteria someone else job                                or has some expected income or release                                at some place would that be a good                                candidate for the job that I'm currently                                offering right so this is what i mean by                                scoring so anyway i read this book and                                then I thought okay now I know how                                scoring works right at least in theory                                but then I figured well if I'm to be a                                program and maybe I should also figure                                out how this works implementation wise                                how is it actually implemented                                um so so you have to understand if you                                only would actually want to know how                                scoring and elastic search works you                                have to know a little bit about                                elasticsearch and then particularly have                                to know the leucine code base to see                                where things are actually happening and                                I didn't know how to put my experience                                in words so I drew a little comic right                                so so this is me right this is the score                                and I know it comes out here                                miraculously right where does it happen                                oh there was a bummer alright so an AAA                                held on hold on no neither side so i                                will be online later so you can look at                                them intense so so anyway so this brings                                me to the purpose of the talk what's the                                purpose of my talk so our first of all i                                want to relieve you of the burden to                                find the point where to get started                                right after this experience I have the                                feeling it should be much easier to do                                it much easier to understand so this is                                what this talk is going to be about and                                it has basically two parts so the first                                is I will give a short introduction into                                the theory that is into the vector space                                model and this is the most common way                                documents are scored right now                                everywhere and especially if you use                                elastic search and then I will talk                                about how you can tweak scores with                                elastic search so what we have already                                and how also how you can implement new                                things right so at first a little bit of                                theory so tf-idf who have you heard of                                it Oh y'all know everything already                                right okay so okay tf-idf is the most                                common ways to score documents ever if                                you use elastic search and you do not                                define anything you didn't give anything                                then everything you get will be scored                                by TF IDF and that is text will be                                scored but tf-idf so how does it work so                                say you have some query and it would be                                in this case would be proud oops sorry                                brown and fox is the queries or                                 somebody's looking for brown fox may be                                 right and then you have two documents                                 one is the quick brown fox likes brown                                 eyes and the other is the red fox so the                                 first thing you do is you count how                                 often the query terms actually appear                                 you're in the document right so in for                                 document one this would be for example                                 okay Brown appears twice fox appears                                 once and for document one Fox appears                                 once and rounder p                                                     you should note here is that this does                                 not respect any ordering of the terms                                 right and this is also called as why                                 it's sometimes called the bag of words                                 model because there's no ordering left                                 you just put it in your bag and then                                 that's it so now the question is how do                                 we put this into a score how do we give                                 this a numeric value how do we actually                                 say okay and this is the new ordering                                 right you can just count these things                                 but that would be pretty naive so I give                                 you a hint already so you actually look                                 at these things as a vector right and                                 this is where the vector space model                                 calm and this is really just like at                                 school when you had factors and you let                                 your x-axis and y-axis and then to draw                                 your vector and that's it so you                                 actually turn your documents and your                                 query into a vector ok and then how does                                 that look like so here's how this would                                 look like so you would have instead of                                 your x-axis you would have your fox axis                                 and the y axis would become the brown                                 axis and documents and query are both                                 points in this vector space so here for                                 example you would have document one that                                 would be                                                             would have document oh sorry document                                 you as a human one would be a car at                                 coordinate                                                              coordinate                                                             want to figure out is what is the                                 distance between these vectors right in                                 distance I mean you could only just                                 measure the distance of the tips but                                 that doesn't make a whole lot of sense                                 as you can imagine so the first thing                                 people usually talk about when they talk                                 about scoring is they talk about cosine                                 similarity so this is a popular thing in                                 theory not so much in practice I think                                 and the way you look at this is you say                                 okay if your query and you have your                                 documents as a vector but you look at                                 the angle between these two and then you                                 don't actually take the angle as the                                 score but to take the cosine and why the                                 cosine well because the cosine starts at                                 one and then decreases to zero as it                                 approaches                                                              be perpendicular to                                 the query in this vector space ah well                                 we'll just be score of zero and then get                                 negative right so one thing I didn't                                 mention before I just just realized this                                 are if you would have a third term right                                 and talking about vector spaces if you                                 would have a third term the third axis                                 would actually come out of the plane                                 right and then if we would have a fourth                                 term about of a four-dimensional space                                 but I'm not sure how to put this one                                 right answer wait ok this is cosine                                 similarity it's not really well it might                                 be useful for some cases right but if                                 you have longer tags a really natural                                 language text this does not really work                                 out so there's a better way to do this                                 another distance measure that you could                                 think of is you could actually instead                                 of they're doing this angular instead of                                 just looking at the tips project this                                 vector onto the axis that is spanned by                                 the query and this is actually what                                 tf-idf does so you have your query                                 expense this axis here you project both                                 documents perpendicular answer this axis                                 and the score is actually the distance                                 from the origin so document to would                                 score a much lower than document one                                 because the projections just farther                                 away from the origin right and this is                                 what tf-idf does and that's it no not                                 really since no it goes on so so there's                                 two things that are very important when                                 you want to understand will seen scoring                                 so the first is shorter text is more                                 relevant than longer text now this is                                 not completely true but the idea is this                                 say for example you have if you're                                 looking for I don't know holiday in                                 china or something like that and your                                 document basis actually contains tweets                                 where somebody tweets about the holiday                                 in china but it also contains articles                                 and it also contains books may be right                                 when somebody talks in the beginning                                 that he's going to holiday and then the                                 end he's going to a Chinese restaurant                                 that he feels like in China well this                                 wouldn't be too relevant for the Crimea                                 right so what leucine does internally is                                 actually taking this into account and                                 making sure that longer documents are                                 awaited lower depending on how the term                                 frequency is in short the documents are                                 sort of weighted higher okay Hannah how                                 this actually looks is this                                 so say you have your document here this                                 is the original document vector and now                                 it turns out that this document is very                                 long than what you would do is you would                                 shorten this vector depending on how                                 long it is and now you can imagine if                                 the term appears very often then this                                 would be up here somewhere so if your                                 shorten it would still be somewhere here                                 right so it's just a trade of sort of so                                 you shorten this vector is it's longer                                 your length is it a little bit if it's                                 shorter and then depending on that the                                 score gets of course higher or lower now                                 this is something that is independent of                                 the term but there is another very                                 important property that is dependent on                                 the term and that is called the document                                 frequency right and so so the idea is                                 this the words that appear off men                                 documents are less important that words                                 that appear less often think for example                                 of the or what or who aware or something                                 like this right this is usually very                                 completely independent on what you're                                 querying and usually the user is what                                 once they get their keywords done how do                                 you identify the keywords well exactly                                 that you look at the document frequency                                 of this term and then you wait your                                 terms accordingly and the way this would                                 look like a vector space is like this so                                 you have for example fox if fox appears                                 very often in documents you would move                                 the vector a little bit to the left and                                 if it pairs very very rarely then this                                 is a very important term so you would                                 move it a little bit to the right and                                 depending on where you move it the score                                 gets higher and lower right okay so                                 these are the two most important things                                 for tf-idf right now now you probably                                 won't know how it works but as you can                                 imagine I mean there's these two factors                                 that are very important so the questions                                 how many factors are there right okay                                 this is how it really looks like so if                                 you go to the lysene web page there's a                                 is a very nice home page our very nice                                 documentation about how the actual score                                 is computed but this year this for                                 example this is just the term count they                                 decided to put the square root but yeah                                 this year is the document frequency so                                 this is actually used in this formula                                 here and you've probably heard of it                                 this is the inverted document frequency                                 by which you                                 so you wait your terms respectively so                                 this is the length here it is roughly                                   divided by the square root and so on but                                 then you have other factors like the                                 booze there's some very norm they saw                                 them to use but it's still there and so                                 on and so forth right okay so so I hope                                 now you have an idea of what tf-idf is                                 for natural language text and if you                                 ever try it out and you run to strange                                 things maybe have an idea why this might                                 be right there was tf-idf good so the                                 heaven many talks about search on this                                 conference already and you probably know                                 or probably already knew before that as                                 many more fancy equations with lots of                                 Greek letters so so can we also use them                                 and yes you can because elasticsearch is                                 built on top of leucine so everything                                 that is on the scene for scoring                                 implemented you can also use an elastic                                 search so we have language metal                                 scouring the m                                                         so on and so forth so he's linked to the                                 to the homepage to leucine home page if                                 you want to know more about the                                 implementation as you really want them                                 good and how do you learn about this                                 well you read this book you check out                                 the similarity mucho documentation for                                 elastic search and then you read                                 elasticsearch the definite guide which                                 is coming out soon right mm-hmm and then                                 you're done mm-hmm so I'm not going to                                 talk about how to actually put this in a                                 mapping how to actually implement it and                                 not going to sort Jason because you                                 would not remember anyway right you can                                 look this up on the documentation so                                 okay that's right so so one more thing                                 about tf-idf so tf-idf is actually used                                 for for natural texts that is when                                 people write articles when people really                                 communicate when they write miles when                                 they write books and so on and so forth                                 this is what tf-idf is tuned for and                                 this is also what the leucine tf-idf is                                 tuned for so if you're doing usual                                 natural legs queries and natural                                 language text queries tf-idf will                                 probably be sufficient for you so I knew                                 know very few people who actually change                                 the similarity because they had any                                 problems if they are only looking for                                 text right but you might not be                                 satisfied with that                                 you might need more so when what you                                 need to actually tweet the score so                                 first of all are you even have numerical                                 values that you want to take into                                 account say for example you have some                                 popularity rating of some item right                                 yeah I don't know a web page that shows                                 movies for a certain actor then you                                 probably do not just want to order them                                 but you might want to order them maybe                                 by how popular these movies are so to                                 make sure that the user gets good movies                                 and not bad movies right you might want                                 to sell some item and you want to get                                 rid of this item so you put it on top or                                 you it's more caustic so you want to put                                 it on top or its new and that's why you                                 want to put it on top so if you have                                 such an idea and it is in your document                                 you actually want the score to be                                 influenced by that so you might also                                 want to have some distance of an                                 American value say for example you want                                 to book a hotel somewhere and you want                                 to find out well how far is this hotel                                 from this or that location and you want                                 to score to act accordingly that it's                                 been farther away you maybe want to                                 score to be lower than if it's closer                                 and other things you might want to                                 contacts now I said before this this                                 example with the program you're looking                                 for a programmer writing the program are                                 now several languages now suppose a                                 programmer puts ten languages and you're                                 searching for someone who knows java                                 right so what you would actually get                                 it's because of this field things that                                 is taken into account what you will get                                 is all the people that only know Java                                 and nothing else and it's not desirable                                 and also you also do not want the score                                 to be tweaked by the fact that many                                 other people know the language or few                                 other people know the language right it                                 doesn't make sense in this case because                                 it's not natural language is actually                                 text and then maybe you're crazy and you                                 want to write your own text scoring                                 function right this is also one place                                 where you would actually need to treat                                 your score or you want to combine all                                 these right so when I give an example                                 afraid this is actually used just to                                 make sure you are your trust that it's                                 really so can you see that yeah but so                                 this is an example for us at so well but                                 this is a neat little project that                                 people use this actually for for image                                 scoring so                                 a data set of images and they're looking                                 for images that are similar to a                                 particular color so for example here and                                 can click on and I don't know red and                                 then will return me all the red images                                 or images to contain a lot of red or you                                 have green and then you will give me all                                 the images that have something with                                 green and them right so this is                                 something where you would actually need                                 to have your own score right okay so                                 what we have an elastic search is a                                 particular kind of query so that is the                                 functions wearing and it works like                                 this so first of all you put the query                                 or the filter that it would have before                                 just a regular thing and then you can                                 define a bunch of functions and what's                                 going to happen is this query a filter                                 will be executed first I'd return some                                 documents and then these documents will                                 again be scored then reordered and only                                 then will the result be returned now way                                 is that song um all because scoring is a                                 very expensive operation so you really                                 want to filter or query before and sort                                 that out right so you have this query                                 these functions and these apply it well                                 to the matching cups oh yeah and then                                 you can also filter by function so there                                 is many options for these for these                                 functions so you have field value a                                 factor for example uh that would do the                                 thing I would that I said before you                                 have a field for example popularity and                                 you want to actually make this influence                                 the score yes distance funny you have                                 distance functions the way you can see                                 an origin and some sort of scale and                                 then it would tweak the scale according                                 to more however far this field value of                                 this document is from this or that given                                 value we've random scoring if you want                                 to shuffle your results a little bit                                 boost factor which you can use for the                                 tax for example okay and at this point I                                 could give a nice demonstration on and                                 artificial data set and explain how it                                 all works and so on and so forth and but                                 I already did that so I might have a                                 screencast of that right it took me                                 forever to do that I had to listen to my                                 own wise for three days so please please                                 go and watch it because and it's also                                 i'm not going to talk about that right                                 now right so can go and watch and s                                 some some examples on how this can be                                 used here but for the remainder of this                                 talk I actually want to talk about this                                 part so I want to talk about what do you                                 want what do you do is you want to write                                 your own scoring function how can you do                                 that with elasticsearch so i said before                                 you have all these different functions                                 that you can apply and one of them is                                 the script score okay so script culture                                 says okay I take a bunch of parameters                                 and I use these parameters and some                                 values of my document to create my own                                 score right so our parameters can be any                                 constant that are independent of the                                 document and that you can pre-compute                                 language so we have Python groovy anvil                                 native all sorts of things that you can                                 do I mean I hope you find one of the                                 languages you probably know all right                                 another question is what will be in the                                 script what options do you actually have                                 so first of all of course you have the                                 document values so if you want your                                 score to be a sort of influenced by the                                 document values you can access this by a                                 specific variable that's called                                 underscore talk or talk and you can                                 access the actual value so this is your                                 mville notation right it's similar and                                 all the languages but this is the mville                                 notation access the fields are by well                                 by the name of the field and then that                                 value just gives you the value of this                                 field and then you can do all sorts of                                 things with it for example you can say                                 ok I want to square this for some reason                                 or because the scene does it or whatever                                 so this way you can access the talk                                 values and then we have a new thing and                                 this is the one thing I actually want to                                 advertise today it is underscore index                                 and this is a variable that actually                                 allows you to get all the statistics                                 that are in the low seen index and this                                 is the thing that is new and it's super                                 flexible and you can do many things with                                 it so this is where I'm going to talk                                 about it from now on right so what is it                                 an index ok we were talking before about                                 word counts right ooh                                                 really good Harry okay what counselor so                                 and this is actually called the                                 technical                                 for this is term frequency so for                                 example in this document here the quick                                 brown fox likes brown eyes the term                                 frequency of brown would be too and the                                 term frequency of dark fox would                                 actually be one sorry it is wrong okay                                 but you get my meaning right okay and                                 the way your access is really just an                                 Oscar index at the field for this term                                 give me the term frequency and if the                                 term doesn't appear with it will just                                 return                                                             anything hopefully right and this is how                                 the query would look like so so your                                 function score you define script scorer                                 and if you define able and volume don't                                 need anything else and this is the                                 script so this for example would give                                 you documents that contain the term in                                 this case build in most often but you                                 can go further than that you can say                                 okay I want to define a field and in                                 certain words and then I want to iterate                                 over all these terms and some something                                 up for example in this case in this very                                 easy case I just want to sum up all the                                 term frequencies and this will be my new                                 score because I think this is good for                                 some reason it I'd been right good                                 document frequency so this is what I was                                 talking before how often does a term                                 appear in any document regardless of how                                 often it actually appears in it right                                 you can get this also in this case the                                 function would PDF and I mean document                                 frequency for example for I in these two                                 sentences would be too even though the I                                 appears four times right it's just                                 depending on if it's in a document or                                 not okay and there's more stuff I still                                 the term frequency sum total term                                 frequency I'm not going to go into                                 details because it's really nice                                 documented by this wonderful program or                                 so go and check it out one thing that we                                 cannot have in the leucine NX is the                                 token count that is how many words does                                 your document actually contain okay this                                 is something that you have to do well                                 not by yourself you can do it with a                                 word count type so if you want to know                                 more about it as a documentation here                                 you can just configure that before                                 indexing and then it will actually store                                 with document the number of tokens that                                 are in this field so that was Nick Nick                                 sitting there he did that                                 no it's really good all right okay and                                 another thing you have is for example                                 positions okay so together with your own                                 frequencies and document frequencies and                                 all that what is also scored stored or                                 can be stored Palestine is stored by                                 default it's the positions so say for                                 example you have the sentence I am Sam                                 Sam I am then the positions for I would                                 be                                                                                                                                             is good for okay and there is more                                 there's offsets and then there's all                                 sorts of palos and you can all access                                 this through the underscore index right                                 but now I want to show some examples so                                 right so remember T if I have this                                 terrible equation here right you can do                                 it in                                                                   go so this is amit is uppercase sigma                                 it's just a summation right you iterate                                 over all the terms so these are your                                 terms here for example so this just                                 means for each term next TF so the term                                 frequency you can get this with the                                 underscore in next year hold on here and                                 here right and then you just put this                                 here then x IDF so I the f is this                                 horrible thing here but you can just put                                 it in here so this would be that thing                                 the norm this is not exactly the same                                 it's not exactly how it works in the                                 scene but it's a similar thing right                                 right and then you're done GF IDF                                    lines no sim score are no similarity no                                 wait no nothing so write a phrase car                                 and                                                                actually makes use of the positions so                                 you can get the positions for for for                                 example names for John and Smith and                                 then you can just do a list intersection                                 sort of and figure out when Smith                                 appears after John and what's the                                 minimal distance and you can do this in                                                                                                         give you a very rough estimate of the                                 running time ah but maybe since the time                                 is running low I'm not coming sorry                                    all right you put up the                                                out there no problem no no problem okay                                 okay no no it's a good all right all                                 right so so tested for this put a little                                 phrase Cora right I just ran it I don't                                 know that it's it's really stupid right                                 it was a really stupid run time                                 estimation I just ran it five or ten                                 times and then I just compared phrase                                 Goran tf-idf and I try to compare to the                                 scene but as you could sue before it's                                 not really the same so please don't                                 quote this anywhere right don't tweet                                 Britta says elasticsearch can do or                                 something because that's has to be                                 evaluated properly but just to give you                                 an idea what it can do so for this                                 little thing tf-idf leucine is of course                                 quickest                                                               data set a really huge sir Sean okay and                                 while native script which just means you                                 plug in your own Java thing was well                                 roughly four times as much right or five                                 times as much medium and mville well                                 embolus is considerably slower however                                 remember that ml is really easy to do                                 our groovy or Python or whatever you                                 have because you do not have to                                 recompile or anything right you just                                 type it there and then repair supply and                                 then it'll it'll work so it still has                                 its use as I will show in a minute right                                 so practical advice if you actually want                                 to use that if you want to have your own                                 scoring function sort of what you do                                 first thing check if it's already there                                 so we have as I said before we have the                                 field value effect or the distance                                 function the random scoring the boost                                 vector and you can combine all these and                                 you can also combine these together with                                 a leucine score and so on and so forth                                 using the function score square e so so                                 check if it's already there and if it's                                 there with your done that's cool but                                 about is not so use your favorite                                 scripting language to try things out as                                 I said we have plugins for Python groovy                                 anvil JavaScript I'm sure if we have                                 anything else anything ma Ruby really oh                                 oh no this is taped right oh no ok                                 anyway okay okay awesome food right use                                 this to try it out because you will not                                 have to restart you know you will not                                 have to do anything you can just type it                                 somewhere put it in the appropriate                                 folder it will be reloaded automatically                                 no matter how you can configure it that                                 way and then just press apply and you                                 will immediately see the result right it                                 might be a little slower but you will                                 see the result immediately okay so is it                                 fast enough already then you're done if                                 not you can use a native script so                                 didn't I said before we have that I                                 didn't say what it is so what it                                 actually is it's a plug-in you can plug                                 this into elasticsearch a precompiled                                 thing so this is way faster than                                 scripting or faster than scripting at                                 least but because it's it's just in Java                                 so there's no execution overhead                                 whatsoever but it has a downside of                                 course that is it needs to be maintained                                 so whenever elasticsearch changes api or                                 something you will have to you know                                 adjust it somewhere you need to restart                                 the note when you actually change this                                 plugin so if you're actually running                                 this in production or something you                                 don't have to well restart each of the                                 node and that's not a lot of fun right                                 and of course it produces more quote                                 because you have the whole plug-in                                 mechanism overhead right and then you                                 don't want more or less code if you want                                 to see how this actually works there's a                                 nice example by a colleague of mine so                                 so ego motive did have native script                                 example that's also where document that                                 you can actually just check this out on                                 github change your scoring function                                 accordingly follow the advice on the and                                 they really nice read me that explains                                 everything what you have to do and then                                 you're done right so it is fast enough                                 again you're done what is not fast                                 enough um so so this is a different way                                 by which you can try to speed up things                                 a little bit and that is it we have a                                 rescore API so the way this works is                                 usually in functions where you would                                 have your query or filter that's                                 executed than the documents that match                                 the filter are scored by the function                                 score but you could also have something                                 maybe you have a really quick method to                                 get maybe the top                                                      top but they're not really older than                                 the right ordering you want a more                                 accurate ouran maybe with the top end                                 and this is what we score AI is good for                                 so if you know that the best results are                                 within top end and the only one recourse                                 Cordys and you know the scoring it's                                 really heavy you use the risk or API so                                 roughly this looks like this you would                                 have your query and it would say rescore                                 you can get the window size and then you                                 can put your function screen here and                                 this will only execute on a term                                       top                                                                    enough to school but what it's not so                                 leucine is much quicker than than the                                 implementation of the tf-idf as i showed                                 before and the reason is that the scene                                 actually makes use of p computed values                                 so for example this document norm the                                 length storm that i was talking about                                 before is actually stored when indexing                                 right so they put the square root and                                 everything store it as a                                                 then just saw it so they just have to                                 retrieve it and multiply whereas I in my                                 script had to put the square root                                 actually which is of course an intensive                                 operation because it has to be executed                                 on each document so if you have any                                 means to add a star some value with                                 document or to pre-compute them somehow                                 pre-compute them with them try to do                                 this and pass it as a parameter okay so                                 fast enough you're done again this                                 Emperor I'm sorry or nothing no I'm I                                 owe you one I think okay right if it's                                 still not fast enough I'm sorry you have                                 to wait until it all the to do seven or                                 make a pull request for them so what                                 other to do is right now so as I said I                                 mean we do not really precompute any                                 values on the fly or anything when                                 indexing so you might want to have an                                 option to actually precompute something                                 before you index then store this with                                 the document and retrieve it the moment                                 you want to score so we don't have that                                 right now we also don't have something                                 like pre-compute values before search                                 execution on a shard for example the IDF                                 that I was talking about before this big                                 one plus one divided by log and so on                                 and so forth this is something that you                                 could actually precompute per term                                 before the script executes on all the                                 documents and it will save you a lot of                                 time                                 okay we don't have to get currently also                                 this only uses shot statistics so if you                                 get the document frequency you will only                                 get the document frequency of the shard                                 we did not have the DFS crowd and fetch                                 that we usually have yet so this is                                 something we're missing right now                                 another thing that might be good I'm not                                 sure is if you could give address the                                 full text and the parameters and would                                 do the analysis for you depending on a                                 foot field this is a break it down into                                 tokens that would also be good wow yeah                                 that's the to do's so right and then                                 lasting so I spoke to some people on                                 this conference and told them then dial                                 up here face cover                                                     didn't often didn't seem too interested                                 and said you know this is all very cool                                 and this is nice and nice to play around                                 but I I really don't need to treat the                                 score I'm I'm really good with tf-idf                                 works perfect for me but there's more                                 you can do okay so so one thing you can                                 for example you do is you can use it in                                 a script filled also and then a script                                 filled you can do something very                                 different you could for example say okay                                 I want to compute my favorite value or                                 maybe I want to compute my favorite                                 class maybe a trained some naive bayes                                 classifier before and i want to deploy                                 this model inside the script filled and                                 deliver the class on the fly once i                                 retrieve the document right well you can                                 do this if it's based on term statistics                                 that's cool or maybe you haven't trained                                 unit if based classifier yet and you                                 really need to train it so well maybe                                 you need all these time statistics and                                 all that well then you can use it inside                                 the aggregations for example in a script                                 and you can do this for each class and                                 thereby figure out what the term                                 statistics are and train so this is why                                 I find it really cool okay and then                                 write this is more less the end of my                                 talk if you know interested in scoring                                 if you want to know more they were                                 actually a very nice Alan passwords                                 talks here so so Clinton gave a talk                                 about how generally how the elastic                                 search api worked and did also i think                                 talk a little bit about scoring there                                 was a nice talk about it from allison de                                 cebu yakov it just before this one and                                 it was about search quality in practice                                 you can't have a talk on learning how to                                 rank that's also very interest                                 topic and really really broad yeah                                 learning how to rank and if you want to                                 know about implementation details it's                                 the right after me is it a mess in high                                 school and not sure how much is going to                                 say but we'll see right and that was it                                 great thank you very much I'm really                                 sorry about the sign yeah don't please                                 don't so raise your hands for questions                                 okay at the back so what my question is                                 how efficiently do you compile so what I                                 mean is there is of course the                                 efficiency programming language                                 efficiency but what I what I mean is if                                 you walk to invert it lists and see that                                 the word appears in the in list                                       then it leads to you know so to do it                                 efficiently you just have to walk those                                 least you don't have to jump randomly on                                 disk to to get fields of the document so                                 when you compile actually these scripts                                 do they just walked in vertically so                                 they touch something else on disk okay                                 so so the way this works is actually                                 operates on the leucine and necks so so                                 what happens is that once the scoring is                                 so okay it reverses all the documents                                 that match your previous query right and                                 this is directly on the loss union deck                                 so it makes use of all the skip lists                                 and everything and then once you reach                                 the document that actually matched it                                 again uses only the leucine index so                                 it's really just a wrapper for all the                                 you see in functionality that you know                                 before so it will oh okay so yeah in                                 fact it will be as quick as leucine in                                 nexus if that I hope this was your                                 question yeah okay but right I mean                                 apart from the fact that we do not do                                 these pre computations that well would                                 save us a lot of time but yeah and then                                 of course you have if you use a script I                                 mean like Python or I'm not sure how                                 this with GUI I didn't try it out I                                 heard good things about it but with em                                 we'll definitely have this execution                                 overhead and yeah                                 great any more questions wow so this is                                 a question about implementation details                                 I'm sorry it's not very scientific but                                 so you mentioned that writing Java code                                 it's like faster like writing your own                                 plugin hmm but you have to write more                                 code why is that okay so um I defer to                                 my next speaker yeah so there's a the                                 plugin mechanism in an elastic search it                                 works wire via juice right so you have                                 to register sort of the different                                 functions you have the way this works is                                 you you define your scoring function but                                 this has to be inside a particular class                                 that has to provide it by another class                                 that is registered on runtime and loaded                                 and and all that and this all over head                                 the whole what is the name whereas it                                 registered and so on this means you also                                 have to write code for that and I mean                                 it's not a big thing really to do I mean                                 you can just go to the example as a set                                 of eager and check it out yeah that's it                                 it's more core but it's not a lot more                                 code you can still do it it's not as                                 much more code as probably might be when                                 you write your own leucine similarity                                 which you can also do you can also                                 actually I didn't mention that before                                 but you can also write your own leucine                                 similarity and plug that in to                                 elasticsearch so yeah I was just                                 wondering if you want to use like a                                 language one is scoring or something                                 like this how much work would it be                                 could you just briefly comment on i know                                 i'll probably check out the link you                                 head on your slide but if you want to                                 have a language model skoura let's say                                 from the scene do you have to write a                                 plug-in for elasticsearch or how much                                 work would it be to use that yeah so so                                 language man scoring is implemented in                                 lucene and you don't have to write                                 anything to use that you can just plug                                 it in and I'm not even plug it in you                                 can just configure either when you index                                 documents or when you search what                                 actually when your index documents are                                 what similarity you want to use and to                                 scene has to so it has Mercer something                                 smoothing and another one                                 it's both language model modeling and                                 you can just use that right away just                                 from the Java Jason like configuration                                 or exactly it's only just a JSON                                 configuration you define it when you                                 index the documents in your mapping what                                 what what should be used and then that's                                 it I mean the scene does for the                                 language model modeling it as a little                                 trick to make sure it's sup of zero                                 right so usually language model scoring                                 if it implemented by the book you but                                 now get negative source you will not get                                 that from the scene but it's not correct                                 so yeah you can use that yeah it's all                                 in the documentation maybe I should have                                 shown an example that was a thing sir                                 thanks good anyone else great well thank                                 you very much again for your                                 presentation
YouTube URL: https://www.youtube.com/watch?v=xg2pepPcBME


