Title: Berlin Buzzwords 2019: Fredrik Vraalsen â€“ Building applications with Serverless Framework ...
Publication date: 2019-06-28
Playlist: Berlin Buzzwords 2019 #bbuzz
Description: 
	Fredrik Vraalsen talking about "Building applications with Serverless Framework and AWS Lambda".

In this workshop, you will become familiar with how to build serverless applications using Serverless Framework (serverless.com). Serverless Framework enables you to quickly define and configure your application as well as the resources it needs using simple yaml files, and then deploy it to your cloud platform of choice. In this workshop we will be using AWS Lambda. The application itself can be written using a variety of programming languages, such as JavaScript, Python or Java. We will cover how to create a REST API to call your functions, as well as how to use other triggers such as file uploads to S3, modifications in DynamoDB tables, or Kinesis event streams.

Read more:
https://2019.berlinbuzzwords.de/19/session/building-applications-serverless-framework-and-aws-lambda

About Fredrik Vraalsen:
https://2019.berlinbuzzwords.de/users/fredrik-vraalsen

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              all right thank you welcome to this                               workshop so nice to see so many of you                               here yeah                               thanks for the introduction my name is                               Eric Ralston I'm going to talk today                               about mainly a doublet lambda and a tool                               called service framework which makes it                               simpler to build service applications                               using lambda and other cloud services                                we'll go through some of these topics                                how service framework helps us with                                configuration and deployment of our                                application we'll see some examples of                                how we can build different kinds of                                solutions using a DeBellis lambda such                                as a back-end api's or like rest                                services for example how can do event                                processing and we'll go into some of                                these other topics as well in terms how                                you could orchestrate multiple functions                                into a larger application we'll touch on                                things like performance and some tips                                for packaging your application and                                testing so this is a workshop but it's                                you can sort of if you want you can                                clone this repository from github and                                follow along the code if you want you                                can set up your own free Amazon account                                to run things but there are no exercises                                and such along the way but we'll yeah                                also the slides are on a link to the                                slides a PDF is on that web page so Who                                am I                                my name is Radhika said I come from Oslo                                in Norway where I just was since I was                                here last I started working at the city                                government you know slow as a data                                platform architect but before then I've                                been I just realized when I was writing                                this talk that I've reached a milestone                                I've been a professional developer for                                more than half my life so that's a I've                                been working mostly with like back-end                                development                                Java and that kind of stuff but in the                                past couple years working on data                                platform and data analysis                                so what do we do in the city government                                why are we building a data platform and                                what does this have to do with lambda                                and serverless so the city provides a                                lot of services a lot of different                                domains for arranging from like                                infrastructure waterworks and recycling                                and stuff to healthcare and schools and                                kindergartens and whatnot and currently                                these are organized very much as silos                                so there's little sort of collaboration                                between them in terms of sharing data                                sharing services and so on so about two                                years ago there was this vision called                                the story of Tim it's a YouTube video                                it's in a region but it's subtitled if                                you want to have a look at it                                essentially they we want to reshape how                                we provide services to the public                                essentially the users the citizens                                should not have to care about how the                                government is organized so this entails                                having access to the data that you need                                when you need it for example sharing                                giving access to the wants to need it                                providing more personalized content and                                services and also proactive services so                                that we can act you don't necessarily                                have to come to us we can provide you                                services when we know that you need them                                based on life events or things that                                happen where you live or other kinds of                                needs and also you should only need to                                provide us with the data once as opposed                                to having to submit the same information                                multiple times and act as kind of a                                mailman between the different parts of                                the city government least that's our our                                vision so we're building a data platform                                we have a data lake in the middle here                                and we're very focused on things like                                having control over our metadata we have                                a lot of different data sources so my                                previous company we worked with ad                                targeting and stuff like that so it was                                a fairly small domain but here we have                                                                                                      each their own domain and it's not                                really big data as much as it's very                                diverse data but we do need to share                                across                                so what we're trying to do is build this                                 kind of service platform which this data                                 platform is part of to make it easier                                 for developers both in the city                                 government and outside to provide new                                 services as I mentioned it's not big                                 data per se so our assumption as we                                 started building this is that service                                 would be a good fit because we have to                                 provide very many services but it's not                                 very high volume so we're doing things                                 like we're handling a lot of documents                                 essentially like Excel Word and so on                                 different systems that we need to                                 integrate with sensor data come in and                                 of course it varies like the regular                                 data into integrations with databases                                 and external data sources we want to                                 provide as much as as possible out again                                 as open data for other partners or other                                 people to use share with the businesses                                 and commercial partners but also across                                 the public sector and of course enable                                 the users in the city to to do things                                 like analytics analytics and insights so                                 mentioned there's a broad specter here                                 so one of the things I read recently was                                 this article from Todd works which I                                 thought was interesting and to share                                 which talks about this data mesh idea                                 where you have distributed data domains                                 like I said we have very many different                                 domains and we need to have an                                 infrastructure below that so that the                                 different data owners can create their                                 own data pipelines and such so that's                                 kind of what we're trying to build a lot                                 of tooling and tools to enable them to                                 build their own data pipelines                                 self-serve so we shouldn't be sort of                                 the man-in-the-middle bottleneck for                                 them as I said service seems to be a                                 good fit here because we will have a lot                                 of small pipelines love small data sets                                 and so on so what are we using service                                 for in our data platform turn                                 we're using it to build a set of micro                                 services essentially arrest api's to do                                 things like the metadata API is and                                 things like that but we're also building                                 processing pipelines so components for                                 doing data transformations data                                 validations and connecting these                                 together and the the goal right now we                                 need to code this thing essentially                                 ourselves but the goal is for the                                 different developers and users to be                                 able to define this on their own we're                                 using a lot of different services in                                 Amazon these are but a few like your                                 necess for stream processing for example                                 api gateway for rest api s-- step                                 functions for orchestrations and so on                                 and we'll touch on some of these today                                 but not all of them and we use a whole                                 lot more as well so by the way sorry I                                 forgot to mention at the beginning but                                 if you have any questions feel free to                                 stop me and along the way in and ask so                                 we'll touch on these a little bit but                                 the goal here is of course to talk about                                 service framework and AWS lambda so                                 anyone here already using Amazon lambda                                 a couple of people yeah so a lot of this                                 should be fairly familiar for you for                                 you right I won't be able to go into                                 much depth on these topics essentially                                 since I'm trying to cover a fairly broad                                 topic but so the actual lambda functions                                 themselves will be very very simple I'm                                 just trying to show you how we can use                                 service framework to help with some of                                 the issues that you have when you                                 usually develop these functions so                                 lambda is a compute service in Amazon                                 Cloud that lets you deploy and run                                 simple functions so what does that mean                                 you can you can set up sorry you can set                                 up you can upload functions and have                                 them run based on various events or                                 triggers as opposed to uploading a                                 container or a doctor image of sources                                 or some sort so it's just sing single                                 functions essentially                                 you can have a lot of them of course                                 it's service there are no servers to                                 manage it Amazon takes care of all the                                 scaling for you and a kind of stuff so                                 you don't have to worry about that and                                 and you essentially you pay as you go                                 you pay for the amount of compute that                                 you use plus the memory so this is these                                 are kind of the two things you need to                                 think about the runtime is charged per                                 one tenth of a second I believe and also                                 the amount of memory that you reserve                                 for a function comes into play and yeah                                 and it supports a ton of different                                 languages so you I'm not sure if this is                                 complete but this is the one I I saw or                                 the ones I saw recently at least we're                                 using Python for a bunch of stuff we                                 were doing but also not Java but                                 Cortland so anything that runs on the JV                                 I'm essentially you can use as well if                                 you use Java or Scala or coupling go at                                 it and you can also if you want to do                                 something else you can bring your own                                 runtime essentially alright so all good                                 all demos should start with hello world                                 right so this is the simplest function I                                 could create essentially it's Python                                 just takes in so a lambda function will                                 take in an event your input event and a                                 context which is essentially the lambda                                 runtime context where you can do things                                 like query for how much memory you have                                 available or how long run time you have                                 left until your function is terminated                                 because you can think it's                                               the limit you can run a function for and                                 you can do things like logging and so on                                 so what you do when you deploy this is                                 essentially you just set up you deploy                                 this code and you said you tell lambda                                 what your function endpoint is for the                                 name of the class or whatever and the                                 function that it should call so we can                                 do a quick demo                                 if I can't ride some X note I need to go                                 out here and then you just                                 let's see mirror alright if we go here                                 to lambda I already have deployed a                                 couple of lambda functions let's see if                                 I can zoom in a bit that are running it                                 was create just a simple function from                                 scratch you can just call it hello and I                                 don't know note so we'll do it in Python                                 we'll set up a new function for you and                                 give you essentially an editor where you                                 can see the function code and start                                 running writing things and here you see                                 the the lambda dashboard so we have our                                 function here it also has constant you                                 can have some connections for instance                                 here it's automatically set up                                 connection for the cloud watch logging                                 infrastructure you can have various                                 triggers on the on the other side here                                 you can see this list here is kind of                                 things that can trigger your function                                 right now we just want to create a                                 function itself so we requested Python                                 so it's already set up every simple                                 handler function for us which just                                 returns a JSON object essentially with                                 the status code and a body so this would                                 work well for arrests kind of function                                 and if you see here our handler is                                 specified as essentially in Python it's                                 the file name and the function name so                                 we could do if we want to just call this                                 hello for instance we also need to                                 update what to call here if we want to                                 test this we can do so when you create a                                 test event right now we don't have any                                 input data that we want so you can just                                 have an empty empty JSON object                                 I went alright let's test it if we                                 scroll up we should see that execution                                 succeeded and it returned this object                                 that we saw right so you can get started                                 easily with like playing around with the                                 different runtimes and such with this                                 and you can you can go and you can edit                                 the code from this console and start                                 testing and playing around with it and                                 tweaking the different options here so                                 but of course this that's not nice for                                 prototyping and stuff but it's not the                                 way you want to do it in in your                                 production system because you want to                                 have a bit more control so see if we can                                 it's not running separate display so                                 what's the problem                                 well this guy is not too used of course                                 you don't want to have manual                                 configuration and deployment of heavy                                 functions and stuff you want to have                                 essentially your infrastructure as code                                 or at least that's configuration which                                 is typically case not not usually code                                 but more like yeah Mel or Jason so if                                 you if you're familiar with Amazon the                                 the tool that you typically use is                                 called cloud formation and it supports                                 setting up your lambda functions but                                 it's very much it's it's a lot of                                 boilerplate you have to essentially set                                 up all the different endpoints and                                 connections and and so on and - so you                                 have to repeat a lot of stuff for each                                 function that you create a lot of people                                 say use terraform for setting up their                                 infrastructure and services in in in the                                 cloud so terraform is similar to                                 transformation but it supports several                                 cloud several clouds essentially how                                 Amazon realize that said it using cloud                                 formation for this was very tedious so                                 they created something else they called                                 server this application model or Sam                                 not sure why they have a squirrel but as                                 a logo but there you have it but there                                 are also other options so the one that                                 we're going to look at today is the                                 server list framework which is kind of                                 similar in that it focuses on setting up                                 lambdas and functions but it also                                 supports multiple clouds and use another                                 option that we looked at when we were                                 serving different tools with something                                 called two Lumi which is actually                                 infrastructure as code where you instead                                 of configuring as a mole or Jason you                                 actually code your infrastructure using                                 JavaScript or Python or go or I think it                                 supports other languages as well so that                                 has some nice features that you can                                 actually do like unit testing for                                 example of your infrastructure code and                                 things like that but we saw at least                                 when we were looking at it it didn't                                 seem to have support for all the                                 features in the cloud that we wanted to                                 use but it is moving ahead quite rapidly                                 but the talk of the topic of this talk                                 is the service framework so what is that                                 do it's a free tool that you can                                 download they also have this Enterprise                                 version where you get a bunch of other                                 support for having things in the cloud                                 as software-as-a-service but we're only                                 using the free framework essentially so                                 what does it do it helps you configure                                 and deploy your service applications and                                 thus is much simpler than if you have to                                 use the built-in cloud formation for                                 example it supports multiple cloud                                 operators so Google Amazon Microsoft you                                 can also run things on cuban artists or                                 open wisk which is I think it's an                                 Apache project to run service functions                                 ok so let's look at a simple example so                                 similar to this basic hello world                                 function so if you want to follow along                                 in this git repository it's and the                                 directory called one underscore hello so                                 one way to get started with service                                 framework is you can use templates so                                 they provide a bunch of templates for                                 creating essentially the setup for you                                 function so you can for example you can                                 create a template for Amazon function                                 written in Python                                                       and so on and this will generate the the                                 basic configuration files and and                                 bare-bones function implementation for                                 you but let's start from scratch because                                 it's kind of simple the kind of things                                 that we want to do now so a very basic                                 configuration file for service they use                                 a llamo configuration files essentially                                 to tell you tell service what it's                                 supposed to do so here we have define                                 that we want a service named hello we                                 need to tell it which cloud provider we                                 should run it so in this case Amazon in                                 the EU West one region and our runtime                                 is Python                                                            tell it what functions to create so we                                 have one function here called hello with                                 a handler which is the Python code that                                 we want to run when this function is                                 triggered and that code is the same that                                 we saw previously so it's just this                                 handler Python file with a Hello method                                 that will be called so let's see how                                 this works if we deploy it so in that                                 git repository if you if you check out                                 the code there there are some                                 instructions on how to set up how to set                                 up everything if you want to play with                                 this yourself                                 in terms of installing server listening                                 for service framework and so on                                 essentially you get a command called                                 service or SLS for short so we can see                                 that we have this service the ml file                                 here the same that we saw so let me try                                 to deploy this what it will do here is                                 first it will it's actually under the                                 covers it's using cloud formation for                                 setting things up for configuring the                                 resources in in Amazon so what is doing                                 it to begin with here is this                                 an s                                                                     in this takes a little while the first                                 time but once you once you have yours                                 function set up deploying new versions                                 is much faster of course I also suggest                                 that if you want to do this at a larger                                 scale you probably want to set up a                                 dedicated deploy bucket and configure it                                 to use that instead of creating a                                 separate bucket for each function okay                                 so it's created our s                                                 it's packaged and uploaded all the code                                 two lines of it up to s                                           creating another CloudFormation stack                                 for the lambda infrastructure so once                                 this is done we can check out our lambda                                 console to see that we have a function                                 here so I have a bunch of them deployed                                 but this is the one that we if we look                                 at the last modified time this is the                                 one that we just deployed as you can see                                 it's very similar to the one we looked                                 at previously this is the code that I                                 told it to deploy now we can we can test                                 it like we did previously in the console                                 on the web console or we can use service                                 itself to to run the code and test it                                 which is quite nice so you can invoke a                                 function just give it a function name                                 hello and it will call the function                                 unable AWS for you and it will show you                                 the result so that's a easier way to                                 test your functions right now this                                 function of course is very simple it                                 doesn't take any input and so on but                                 we'll get to that if I want to if I want                                 to remove this again I can just say SLS                                 remove and I will take remove the                                 function and destroy the s                                             so on I will do that right now alright                                 so let's go back to the                                 presentation all right so there are some                                 screenshots basically showing what I                                 just did but I didn't talk about was                                 this this output that I got one to                                 deploy finished which shows your buttons                                 of information about your deployed                                 function right now there's not a whole                                 lot here it just shows me the service                                 name it also has this concept of stage                                 so you can have multiple stages in the                                 same account if you want to have like a                                 development version testing version                                 production version and so on we've                                 deployed our dev and production code in                                 separate AWS accounts for us that                                 doesn't really help us that much but if                                 you want to have multiple development                                 versions for example you can have that                                 in the same account with different stage                                 names yeah so essentially this function                                 name is a composite of this service name                                 the stage name and the function itself                                 we saw the invoke and yeah if I did the                                 remove it would just remove all the                                 lambda infrastructure and also remove                                 the s                                                                    up a bucket specifically for this                                 function so what are some use cases for                                 for lambda I think I talked a little bit                                 about it but you can do a lot of                                 different things like you can build                                 back-end API is REST API is for instance                                 using this you can also host essentially                                 simple by about applications using                                 lambda you can use it for event                                 processing or file processing things                                 like ETL transferring data from between                                 different sources the things that we are                                 currently using it for are these                                 back-end and the vendor file processing                                 so essentially our data pipelines and                                 and our various rest services I'm sure                                 there are plenty more use cases but as                                 you can see when we look at how you can                                 trigger these so you can trigger lambda                                 in many different ways                                 you can use                                 you can trigger it through HTTP calls                                 through either this API gateway which                                 we'll see later or also their                                 application tool balancer you can                                 trigger it from various kind of                                 messaging or notification services so                                 SNS is this notification service in AWS                                 and you have asked us as a messaging                                 queue Kinesis is a stream event stream                                 as a service and s                                                      so so for instance we trigger are some                                 pipelines when new files are uploaded to                                 s                                                                       pipelines you can also trigger lambdas                                 when there are changes in your dynamo DB                                 database for instance or when you can                                 also listen to WebSockets to have more                                 long-lived sort of conversations between                                 your your web client and and an lambda                                 if you have sensors you can use the IOT                                 infrastructure in numbers on we                                 essentially just use a REST API for that                                 currently you can trigger it through                                 other things as well                                 I like suffer like speech interfaces                                 cloud watch if you have a large on your                                 infrastructure for example you can                                 trigger various lambda functions through                                 that or just simple scheduled calls like                                 every hour or                                                  also we'll look at today the API gateway                                 integration for rest services or HTTP                                 services and message handling through                                 SMS event time links resinous part of                                 the reason for that I wanted to do                                 kinetics for instance but that's not                                 available in the free account so yeah                                 all right any questions so far or                                 all right so let's look at how we can                                 extend our simple hello function with a                                 REST API to do this we will put the API                                 gateway in front of of lamda there's a                                 bunch of documentation on how you can                                 configure that here on the service                                 framework web page the slides are                                 available as I said on this on this link                                 here so essentially what we need to do                                 is extend our service configuration with                                 this simple we need to define what                                 events will trigger our our function                                 instead of just triggering it manually                                 so in this case we set up an HTTP event                                 with the pass and a method fairly simple                                 stuff we can have of course of course                                 path parameters here like a name we can                                 also have support for query parameters                                 and various headers and such our code                                 will have to look a bit different                                 because the now instead of getting just                                 a payload for instance as an input we                                 will get an event which contains a lot                                 of information about the HTTP requests                                 so for instance our event will now                                 contain a dictionary for a nested set of                                 dictionaries so one of them is path                                 parameters and here we can extract the                                 name parameter from the URL and we can                                 build up our response for example as a                                 JSON object with our with our greeting                                 and return this so in this case we need                                 to return we need to build up the HTTP                                 response essentially but our status                                 which result code and and the body of                                 the response so this this JSON dumps                                 will take care of basically writing this                                 into a string recording it to a string                                 there's a ton of details on how to                                 configure this stuff but yeah there's a                                 link here for more                                 more details you can probably read it                                 right now but if you have a look at the                                 PDFs it should be okay all right so                                 let's have a look at the deploy here                                 it's very similar to what we saw in the                                 previous one but there is no more detail                                 now so for instance if we look at the                                 output for this the result one display                                 is done we'll have an endpoint now so we                                 have defined a get endpoint here which                                 we can call so let's try that                                 switch back to mirror all right I need                                 to move to the correct and I redeploy it                                 so I have a different URL and it's in my                                 slides but okay so here's the endpoint                                 that I want I don't want to have the                                 curly brace name thing so let's say we                                 want to greet Berlin all right                                 so this will by the way if you are doing                                 any sort of rest or HTTP stuff from the                                 command line                                 I suggest installing HTTP PI if you                                 haven't already it's very much nicer to                                 work with and curl all right so here we                                 see a bunch of response details and also                                 the message body that we open right we                                 can of course also call this with the                                 invoked function that we saw earlier                                 with the function name hello if we try                                 to do this now without anything else of                                 course it will fail because we didn't                                 provide the parameter so essentially we                                 will get a Python error message back                                 because we didn't have very good error                                 handling in our code right so we didn't                                 typically we would say this should be a                                                                                                         the passed parameters but we can do that                                 also here on the command line I just                                 need to pass it a data pass the data and                                 now in this case since we're not we're                                 calling the function directly and not                                 through the API gateway we have to                                 emulate the event format that the API                                 gateway sent us so we can do this                                 through saying pass parameters named                                 Berlin                                 should work hopefully yeah there we go                                 so now we also see that entire response                                 that it sends back to API gateway so API                                 get well we'll take this response and                                 convert it to an HTTP response with the                                 correct status code and and body and you                                 can also add things like headers here if                                 you want to for example do course or                                 something like that all right                                 um yeah we saw this stuff yeah all right                                 one thing we haven't talked about is                                 documentation so you go of course if you                                 create a REST API you want good                                 documentation of it out-of-the-box right                                 that's one of the things you don't get                                 here since with this default lambda                                 integration you get pretty much all of                                 the HTTP handling is inside your code                                 and not dealt with by the API gateway it                                 just essentially just wraps the entire                                 HTTP request and sends it to your to                                 your code so if I look at the if I look                                 at the web console for API gateway I can                                 have it generate things like swagger or                                 open API specs from my from my endpoints                                 but here there's very little information                                 it just has the path essentially in the                                 message and it doesn't tell me anything                                 about response format for example                                 fortunately there is a plug-in for                                 service framework that allows you to to                                 extend this so it's called service AWS                                 documentation which allows you to                                 document a bunch of the like endpoints                                 input and output formats and so on                                 and this will then allow you to generate                                 this swagger or open API spec from the                                 API gateway what you need to do is                                 essentially okay if you fall in from the                                 github repo you need to extend your                                 several CML with this documentation                                 essentially descriptions the path                                 parameters in this case with names                                 description and your method response                                 types so and here we have an example of                                 okay so if we respond with application                                 Jason this is our response model and we                                 can just define our response models as                                 essentially Jason schemas and we can                                 also if when you have multiple of these                                 in your file you typically will also                                 want to utilize this include mechanism                                 so you don't have a huge service animal                                 file with all the stuff but these models                                 can also be of course reused across                                 different endpoints for example or our                                 functions if they have the similar input                                 or output formats so in order to apply                                 this this plug-in you just have at this                                 section here to your service CML file                                 and now when you deploy you will get a                                 swagger spec that contains more                                 information than you can generate                                 clients based on that and so on                                 all right I realize I'm running very                                 fast in my slides but please stop me if                                 you have any questions or I think we can                                 all so like I said but all of these                                 examples are fairly simple but if we                                 have time at the end we can go back and                                 maybe try to extend some of them with                                 some improved error handling or look at                                 other ways to connect things so let's                                 look at event processing in our case we                                 want to use the the notification service                                 as an S that's a trigger so similar to                                 our HTTP endpoint we can set up an event                                 type now with the type SNS and by                                 default if you just give it a topic name                                 it will actually also create this topic                                 for you and give you all the necessary                                 permissions to read from it and so on so                                 I'm not you can also of course reuse                                 topics that you have already set up but                                 then you need to provide policies and                                 roles and stuff to be able to access                                 that so I'm not going to go into detail                                 on that stuff today but you can of                                 course reuse infrastructure that you've                                 already set up in your in your account                                 now our handler will look a bit                                 different because of course this event                                 format now will look different than the                                 one that we had for HTTP requests so it                                 will look more like like this all these                                 different event formats are documented                                 of course on the Amazon documentation                                 pages but in this case we get not a                                 single event at a time but a batch of                                 events from SNS so you might get one or                                 you might get multiple so we can do a                                 for loop here over the records in in our                                 input event and extract for example this                                 the actual body of the message now in                                 this case I haven't connected it this                                 function to anything it except                                 it's it's only writing essentially                                 logging what it gets we can you know                                 what we do in our case is typically                                 right so for instance we have a bunch of                                 sensor data coming in and we write the                                 latest observed value into dynamo DB so                                 we can build in a simple API on top of                                 that just query for the last observed                                 value so in order to publish an event                                 here you can either go on the console                                 the SNS to the SNS console and publish                                 the event from there or you can use the                                 command line tool for Amazon Web                                 Services and USNS publish to your region                                 and topic with a message so in this case                                 Hello passwords you get some feedback on                                 the message ID and if I look at at the                                 logs I will see for the lambda function                                 I will see that oh we got this event so                                 you triggered successfully we can try                                 this as well if we let's see where is my                                 pointer there and I need to give you the                                 display                                 there's another service command here as                                 well as info it's a it gives you this                                 information that we had that you saw at                                 the end of the deploy so if you want to                                 get information about the end points and                                 someone you can just run SLS info and it                                 will tell you details about your                                 deployed function um all right but here                                 see I need to go into the actual console                                 to see what it's called simple                                 notification service see if we have any                                 topics here yeah my events so I need to                                 use this AR n which is basically the URL                                 or identifier for for my my topic                                 hello Berlin buzzword nope what did I do                                 wrong                                 published of course oh did it well sorry                                 copy there anything why didn't it work                                 there we go that's a bit slow the                                 network again so that published and                                 message there and if I go back to my                                 logging cloud or logging console find                                 the right log group which one was it                                 event processing this is the one no no                                 this is the one I think yeah it's you to                                 see if always get tripped up by lead see                                 here so here you can see the event that                                 was published or the the log that we did                                 but typically of course you will have                                 this function do something more                                 interesting than just log it                                 all right and one of the things that we                                 are using it for is to collect multiple                                 functions together to create a pipeline                                 and so how do you orchestrate the stuff                                 how do you get them to work play well                                 together essentially so you two two                                 basic options I think one is that you                                 can use the lambda functions fairly                                 standalone and then connect them through                                 like message queues or SNS topics and so                                 forth or the nested stream for example                                 and just use your regular Amazon API is                                 to publish events from your lambdas                                 because you can do whatever you want                                 from your lambdas essentially and then                                 that can trigger other other functions                                 that gives you a nice decoupling which                                 is can be good in some cases but                                 sometimes you have something that works                                 better as a whole and then you might                                 want to have tools for orchestration                                 orchestrating that better so what we use                                 for that is Amazon step functions so                                 this will essentially allows it to build                                 a state machine or a flow another state                                 machine it's more like a flow graph for                                 your data and an execution so you can                                 have various tasks that trigger in a                                 sequence and you can have decision                                 points where you can based on the event                                 data you can trigger one or other paths                                 in your graph for instance a check if                                 you if you validate some data you can do                                 different actions based on whether the                                 data is valid or not so in here in our                                 case we're defining this requires also                                 another plugin by the way several step                                 functions so there's a whole ecosystem                                 of these kind of plugins for different                                 different tools and different services                                 so what we do here we have here we have                                 two functions now one this is to get                                 sensor data with temperatures                                 very simplified compared to the one that                                 we have in our system but so what we                                 essentially try to do here is we want to                                 validate that this temperature data is                                 is valid according to our our schema for                                 instance or that the values that we get                                 in makes sense because we have some                                 sensors now that are fairly cheap so                                 they fail sometimes or they run out of                                 power and then they suddenly reply a                                 report that the temperature in the Oslo                                 fjord is minus                                                      obviously false but zero Kelvin so those                                 kinds of things we want to try to filter                                 out right we also want this these                                 sensors don't know much about other                                 things like where they are located or                                 descriptions and so on so we want to                                 enrich the data with more information so                                 we can do that so we have one function                                 to validate the data that we get in and                                 one to enrich it with some more                                 information so we set up a state machine                                 here so which we call process                                 temperatures so it's triggered by an                                 HTTP endpoint essentially so we can set                                 up very similar to the HTTP trigger we                                 use with API gateway this will trigger                                 the stop function if we post an event to                                 this to this pass and then we have the                                 definition of our actual function                                 orchestration so here we have a state                                 machine called sorry I missing something                                 anyway oh that was on the previous one                                 so we have a set of tasks here and we                                 start at this task about the temperature                                 it connects to this one function that we                                 created and here you can see this this                                 naming here is what this is the actual                                 cloud formation name that this function                                 gets so if didn't know kind of that it                                 will take this name here give capitalize                                 it and add lambda function and then we                                 say okay if this thing succeeds the next                                 task is enriched location and it sort of                                 you can build up a graph here                                 essentially                                 or yeah now our handler in this case has                                 two functions in it one validate                                 temperature and one enriched location so                                 this validate temperature we'll just                                 look at the temperature values and see                                 if they make sense and if not it will                                 throw an exception and it returns the                                 event and that result from this will                                 essentially then be passed on as the                                 input to the next function in my next                                 task exam in our state in our flow graph                                 and here we'll just okay we won't look                                 at we could add for example in our case                                 we have a lookup table which gives us or                                 we can look up the sensor ID and enrich                                 it with more information with for                                 example geographical location and                                 description and so on                                 and then return that so if we do this we                                 will get a new end point essentially                                 let's see if we can have a look at this                                 keep losing my pointer here we go                                 so we go into the orchestration here                                 have a look at the info did you not                                 deploy my own points interesting I just                                 needed to have a check here                                 alright ok this is why I have photos or                                 pictures in my slides the demo effect                                 hits alright let's go back here so much                                 our why that didn't work but anyway                                 so typically you will get this end point                                 where you can post now supposed to get                                 and what this thing if you use this HTTP                                 RFI tool you can create a JSON object                                 using this so this will essentially                                 create a JSON object with the                                 temperature field with the value                                        as your body so this the response here                                 from our HTTP endpoint is that it                                 started executing our state machine and                                 you will get something like this so we                                 get a nice little graph showing us how                                 the functions are connected together                                 yes question right so the question is                                 can you do asynchronous stuff in these                                 or do you have to return the value so                                 you can do asynchronous lambdas in                                 general although in this case I think it                                 makes more sense since you want the                                 output here to go here if you're coding                                 like for instance in in a language like                                 JavaScript or using node that is more of                                 a asynchronous approach then you in in                                 your event handler or your method will                                 take a third argument which is a                                 callback function so you can once your                                 code is done you will call that callback                                 with your with your result is that                                 answer your question yeah                                 so in this case we're looking at the                                 output from the are in enriched location                                 so we see that okay got an input so it                                 passed through the validation step it                                 got the input just passed along and then                                 the output from the function got added a                                 location data now if we had call this                                 with a temperature that was outside our                                 defined range we would see something                                 like this so in this                                 case our valid date temperature function                                 failed with an exception saying it's too                                 cold since I passed it in the                                 temperature minus                                                       simple example of course but in our                                 system right now we have pipelines that                                 look more like this for example so this                                 is a simple pipeline to take in like                                 Excel files convert them to CSV you do                                 some validation and transformations on                                 this and and yeah which the users of our                                 pipeline can define what these                                 transformations are and so on so you can                                 build fairly complex complex stuff and                                 also right now I only showed an example                                 where in the previous one we're sort of                                 the output of this goes directly has                                 input to this but you can configure a                                 bunch of more stuff like how essentially                                 there's essentially a JSON object that                                 flows through here which can you can                                 modify along the way                                 and tell it which parts to pass to this                                 two different functions so we have one                                 question here yes that's rich lambda                                 function I'm not sure if there's it's                                 similar time limit first that functions                                 I don't think so so like the aggregate                                 can be longer I think yeah questions in                                 back this one yeah                                 all right okay so why not so why are                                 these different functions do we don't                                 have a lot of overhead instead of                                 putting everything into one one function                                 so first of all these are written in                                 different languages so some of the code                                 here is Python but this one for example                                 is Coplin so we're using here for                                 example convert our excel file to CSV                                 we're using a Python library for that                                 but here we're using a Java library for                                 doing a cc transformation so that allows                                 us to build kind of things like that                                 because otherwise we would have to                                 reinvent one or the other essentially                                 but yeah of course I mean the                                 granularity here is something that you                                 need to decide also in terms of I think                                 the idea is here if you if you create                                 these kind of pipelines how do you do                                 error handling where does it retry where                                 do try to recover if if something fails                                  and so on so right now each of these                                  steps will output or at least the first                                  two or three will output files to s                                   which the next step will read in so we                                  can we have more sort of history and                                  audit log essentially of what was going                                  on does that make sense                                  yeah good questions but yeah for sure if                                  this has been all one all one language                                  it might make sense to combine some of                                  these steps but these functions of                                  course are also useful in other                                  pipelines so we can combine these in                                  different ways right yes question                                  so sorry I didn't catch the test oh yes                                  yeah so the question is what if we saw                                  in previously that we have batching for                                  input events for from SNS for instance                                  so this one that the trigger for this                                  depth function here is well in our                                  example it was HTTP in our case it's                                  actually another lambda function                                  invoking it but so we don't have a batch                                  of event coming in here I'm not sure how                                  that would work really because how would                                  you do like if one of them fails I don't                                  think you can have like one event here                                  fan-out like                                                          that's what you were asking about I                                  think in our case the the the whole                                  state machine or the whole flow will                                  either fail or succeed yeah does that                                  answer yeah but I think you know in our                                  case all we always have one input event                                  in this case yeah                                  and there are so you you can use several                                  different types of triggers for step                                  functions as well but I'm not sure it                                  doesn't have as many like you have HTTP                                  endpoints you have scheduled timers and                                  maybe one or two more but I don't think                                  you can use SNS for example as a trigger                                  so you'd have to from your SNS topic you                                  could have a lambda that would then                                  trigger your step functions right which                                  would then call it once for each event                                  so make sense any more questions yes one                                  year                                  so can the output or result from this                                  fan out to multiple consumers again for                                  instance it depends on what you do here                                  like for instance here we write output                                  s                                                                      essentially which does further                                  processing of this CSV file it will                                  trigger essentially a number of                                  pipelines so you could but but it's not                                  connected to it's not this one                                  triggering its directly yeah or or we                                  could of course right to SNS or Genesis                                  or something here right but if in order                                  to trigger another orchestration like                                  this you would have to have a lambda                                  function in between your knesset stream                                  for instance and and stuff functions                                  that answer it yeah so yeah I went to                                  the time at least for the stuff that we                                  do now as we produce actually in each                                  step here we produce intermediate files                                  and s                                                         notifications which will then trigger                                  potentially other runs of this yes                                  you can do that yeah we're not doing it                                  in this case but you can call you can do                                  from your lambda you can do whatever you                                  want essentially right as long as you                                  keep within that time limit so if you                                  can call out to two DynamoDB for example                                  to query to join with data there or in                                  our case we have some internal look-up                                  tables that are basically just                                  configuration yeah but you can call                                  external services from your lambda                                  function it's no problem                                  oh yeah yeah yeah that could be an issue                                  and we'll get into that briefly actually                                  on the next slide all right any more                                  questions before we move on all right                                  let's talk about the performance then                                  how many have heard of this cold start                                  problem are you familiar with that yeah                                  so okay so essentially the way lambda                                  works                                  I stole the next picture from a                                  different from an article here the way                                  it does is when you trigger a lambda it                                  will first fetch the code from s                                      will start up a container to run with                                  your runtime and and then once that is                                  bitched at it's rad ready to actually                                  run your code so this part here is                                  what's called a cold start and it adds                                  latency clear code right but what it                                  does is it will reuse this container if                                  you can within some time span defined by                                  Amazon which they don't tell you but you                                  know so you want to try to avoid this or                                  at least keep this as low as possible                                  but what they say is that you should                                  really just worry about this part mainly                                  because it's Amazon's challenge to sort                                  of reduce this as much as possible right                                  that's their deal that's what they can                                  do but there are things you need to take                                  into consideration here so that the                                  lifecycle is essentially that so                                  one container is one execution there's                                  no parallelism inside one container so                                  you run your handler when it's done it                                  can run another or handle another event                                  but it won't do multiple inside a single                                  container in parallel so what happens if                                  you have multiple requests or triggers                                  coming in it will spin up more                                  containers on demand right and then once                                  they are idle it will spin them back                                  down again but there's this time in                                  between when the handler is done what it                                  does is essentially it will freeze the                                  container and the current state in the                                  container and if another request comes                                  in within some given time frame it will                                  thaw that container and will enable that                                  to to run that request or handle at                                  request and then freeze it again but                                  after some time the container will be                                  destroyed and removed so what you want                                  is to have essentially this happened                                  right instead of building up new                                  containers all the time what we see in                                  terms of cold start in our code in in                                  Python and and kopplin or Java JVM it                                  varies but it can be and the cold start                                  to be anywhere from like a couple                                  hundred milliseconds to maybe a second                                  or two                                  typically whereas if you have a                                  container that's ready it's your                                  response time is done in a few                                  milliseconds for the simple services one                                  thing that can can make this quite a bit                                  worse if we is if you're using virtual                                  private cloud services if you if you                                  want to for example query a database                                  that's in a separate private subnet in                                  your in your EPC configuration so you've                                  sort of split your your account into                                  multiple virtual clouds - for particular                                  purposes and so on that's fairly common                                  every time a lambda container needs to                                  connect to that                                  to that vbc it will need to set up a                                  network interfaces a network connection                                  and that can take a long time up to like                                                                                                         reasons why we for example decided to                                  put all of our metadata and stuff for                                  our pipelines in in dynamodb instead of                                  in RDS their sequel as a service because                                  that's not there you don't put you don't                                  put DynamoDB in a V PC because you                                  handle all the security stuff through                                  their regular Identity and Access                                  Management controls                                  whereas if you run like a sequel                                  database it will need to deal with its                                  own security right it's not connected to                                  that I am infrastructure so just to be                                  aware that you can have long cold cold                                  starts especially if you do things like                                  connect to other subnets in your or                                  other V pcs in your network they are                                  working on improving this so instead of                                  every container having to set up their                                  own network interface it's gonna be one                                  between the V pcs or something like that                                  so there they announce something this                                  winter I think that they're working on                                  sometime this year it should be fixed                                  not sure one yes yes right good point so                                  resources that are costly those who                                  typically in your code would typically                                  be set up here right so you want to                                  avoid that you do this in your in your                                  handler code if you set up a network                                  connection best connection for example                                  or some other kind of resource that                                  takes time to set up you want to have                                  that be kept through this freeze and                                  thaw cycle and you can do that if you                                  just put it in like a global variable or                                  a site a singleton or something that                                  survives that sort of outside your                                  handler function that's just part of the                                  regular class setup for example then                                  that will survive                                  and you can reuse that and I've heard                                  people do interesting things like put                                  their cuff crack clients in there and so                                  on which sounded area yeah and then they                                  had to do things like check whether the                                  client was still alive and restarted and                                  so on so yeah you can do crazy stuff                                  right and there in the end                                  a couple more things so packaging your                                  code we haven't looked at that in detail                                  right but for now we've just written                                  very very simple functions that I don't                                  have any dependencies or anything but                                  essentially it will so service framework                                  will deploy a zip file but of course you                                  have to tell it what should be in that                                  zip file so for and you want to try to                                  bundle all your dependencies in there so                                  if you're writing Java code for example                                  you can have Gradle or maven great like                                  it's kind of fat jars that you can point                                  to and have that be your deployment                                  artifact you can also deploy and I                                  actually think that's recommended is to                                  have your dependencies in a separate                                  jars in a library directory and have it                                  put that into the zip file for some                                  reason that supposed to be faster in the                                  cold start or something less code to                                  scan I think when I do the hot the hot                                  path you can also do something called                                  layers so if you have a lot of a lot of                                  kind of libraries or defenses that you                                  reuse across many functions you can                                  create a layer that you can then build                                  your function on top of so if you're                                  using things like numpy or something you                                  look pandas to do numerical analysis for                                  example in Python you can create a layer                                  that contains those libraries which can                                  be fairly large like you can have I'm                                  not sure about the size limits of the                                  layers but these are easily like                                        megabytes that you don't want to upload                                  every time you upload your function                                  that's a good idea to create a layer and                                  then reuse it it's kind of similar to                                  how you do docker images like you build                                  on layers on top of each other I think                                  you can have up to                                           on top of each other in in lambda                                  another thing to think about is the                                  runtime environment is Linux so if                                  you're building your Python code and                                  libraries dependencies on on Mac for                                  example it will not include the correct                                  libraries that like the native libraries                                  so the thing you do there is for python                                  there's another plugin that is called                                  service Python requirements that will if                                  you're not running on Linux it will boot                                  up a docker image to do the packaging                                  essentially so you get the Linux                                  dependencies in there all right                                  testing so we've seen a little bit of it                                  so for instance if you if you just like                                  write everything into your handler                                  function a lot of concerns that are not                                  part of your business logic will creep                                  into your methods things like handing                                  HTTP requests and responses dealing with                                  the SNS event formats and such so like                                  any sort of it's just good practice                                  separate your business logic into                                  separate methods and so on so you can                                  test them unit test them and mock out                                  for example if you call like for                                  instance if you call other s.a.w                                  services like dynamodb rs                                               idea to to have those passed in as                                  dependencies that you can unlock out or                                  use things like in Python you have this                                  the Python AWS libraries are called                                  butoh or Poteau                                                          library which is a mock version of that                                  so you can have you can walk out and do                                  tests for the different AWS services                                  which is very useful so if you want to                                  mock out s                                                              do that and then to set up your mocks                                  and tests that things were put in the                                  right place and so on another thing you                                  can do is also to invoke the functions                                  locally instead of calling out into the                                  cloud so invoke local will run the                                  function on on your local machine                                  instead of                                  course this can run into issues if you                                  want to actually use other cloud                                  infrastructure which is the big kind of                                  hurdle here right if you want to use                                  other services you either have to                                  actually call into the cloud or and walk                                  them out somehow or you can also try to                                  use things like there are some tools                                  that allow you to run things locally                                  like kanessa light or you can actually                                  download a local version of DynamoDB and                                  run it on your machine typically you do                                  this through docker images so there's                                  also a bunch of tips and tricks for                                  testing on the service framework webpage                                  okay so there's a bunch of stuff I                                  haven't talked about we have some time                                  so we can go into stuff which we want                                  setting up other infrastructure like                                  outside that the stuff like if you have                                  stuff that's shared between these                                  functions or pipelines typically you                                  want to set them up outside of service                                  framework so we use terraform for that                                  in our case so we just have to reference                                  the IDs essentially in our inner service                                  framework configurations access control                                  I mentioned briefly but typically you                                  also then need not only to reference the                                  these infrastructure elements but also                                  give them access you need to set up the                                  lambda roles and so on so in our case we                                  haven't set up anything like that so all                                  of the stuff since we package everything                                  we let several as framer create our s                                  and s topic for example it it                                  automatically set up the roles and                                  policies to allow our lambda function to                                  actually connect to that topic but if we                                  have been reusing an existing topic we                                  would need to provide the policies and                                  stuff to do that in terms of the API                                  gateway integrations we looked at                                  there's a bunch of discussions on                                  whether to use this what's called the                                  lambda proxy which is what we saw which                                  essentially passes the entire HTTP                                  request into your into your method and                                  lets you deal with all the details there                                  whether you should use something call                                  the lambda integration instead of lambda                                  proxy so that lets the API                                  I do its work actually like taking care                                  of the HTTP part of it and just passing                                  you and a more domain-specific or                                  business specific event doing the                                  transformations doing the status                                  handling and so on so there this is a                                  link but not sure if it's clickable in                                  the PDF I'll have a I'll have a check if                                  not I'll put it on the github repo so                                  there's a this one links to like five                                  four or five different articles with                                  discussions on pros the cons there and                                  related to that also validation of your                                  input in our code now we would do the                                  validation in our handler but in in the                                  API gateway for example you could do                                  validation of your response or requests                                  and responses or requests I guess by                                  providing for example Jason schemas and                                  also things like the lambda proxy as far                                  as I know doesn't handle or check that                                  you for example call with the correct                                  message or sorry                                  with the collect correct content type                                  and so on so you need to deal with a                                  bunch of that stuff in your code whereas                                  if you use the MOR the lambda                                  integration it's more setup on the API                                  gateway side but you get more out of it                                  as well and versioning of your function                                  so typically you will have if you have a                                  continuous deployment pipeline for                                  example you will have different versions                                  of your function so SLS sorry service                                  framework when it deploys it actually                                  creates new versions of your of your                                  function so if we go in and look at it                                  every time I deploy now I'll get a new                                  version and it just automatically                                  redirects this list to the last one but                                  you can you can have more control over                                  this you can have aliases for example                                  for your function version so you can say                                  that okay this version should be run in                                  production for my production endpoint                                  this other version is my development                                  version they can run on the latest at                                  whatever time and so on alright to wrap                                  up we looked at AWS and its function as                                  a service it's very                                  simple to set up you pay-as-you-go we                                  don't have any servers that cost you                                  money if they don't do anything and it's                                  very scalable and performance from at                                  least for our use cases have been very                                  good service framework helps you with                                  the configuration and deployment and                                  testing and it has a bunch of plugins to                                  do different things some things we're                                  still evaluating this it seems to us                                  that it doesn't support everything of                                  course typically for these kind of tools                                  that are more cloud agnostic they don't                                  support everything or the latest                                  greatest thing so another thing we see                                  is I did it does make the easy stuff                                  simpler it doesn't always make the                                  harder stuff easier or it possible like                                  for example this this API integration                                  API a gateway integration lamda                                  integration it doesn't support all                                  validation stuff there for example so in                                  that case we would have to go to either                                  terraform or this service application                                  model for from AWS but it's perfectly                                  possible to mix and match here to have                                  most of your stuff in service framework                                  but if you need to go outside that you                                  can also include other cloud formation                                  stuff directly into your service framer                                  configuration as well so yeah so we're                                  still evaluating some of these but we've                                  so far been we've been very happy with                                  the service framework so far so any user                                  final questions or feedback feel free to                                  contact me after the talk or as well of                                  course                                  yeah                                  hi really nice presentation Thanks                                  borrowing just a question of the                                  commands you show the server lists are                                  those open to I mean the free ones right                                  because you said there would be also uh                                  yeah so it's all the the service                                  framework is free if you use okay not                                  sure the status of its like open source                                  or something but it's it's on github I                                  believe the enterprise stuff is more                                  about like administration's things like                                  you can put your configuration in the                                  cloud and stuff like that as far as I                                  know and the second one I think the                                  second one would be how do you control                                  the costs of your lambdas I mean a good                                  question cost control like right now                                  we're just monitoring things you can use                                  for example the API gateway to do to                                  handle some of this for your HTTP                                  endpoints so you can you can give                                  different clients different rate limits                                  and things like that but we haven't we                                  haven't done this in practice yet we                                  don't really have that many users yet                                  but we hope to get there okay yeah all                                  right                                  any more questions yeah all right here I                                  would you mind giving a few more details                                  about the layers and sharing across                                  functions ah yes                                  okay maybe I can I can see if I have an                                  example that we can show for the layers                                  let me see if we can find something so                                  essentially what you can do in the                                  layers is you canyou can package                                  dependencies like libraries in there so                                  you don't have to do that every time in                                  in your function in your in your lambda                                  packages because they can grow pretty                                  big so let's see if I have an example                                  trying to remember where okay so in in                                  our                                  and our Excel thing maybe nope now but I                                  know that one thing we have done is in                                  some cases we've put things like we have                                  a bunch of functions that do Python                                  transformations of things using pandas                                  I'm not sure if you familiar with the                                  it's like a numerical library and it's                                  fairly big so we put this in in a layer                                  so we can just say we have a dependency                                  on this layer in our build process and                                  and that that means we can reuse that                                  across a ton of different functions and                                  not have to package that every time so                                  it saves us instead of packaging like                                     megabytes                                  every time we deploy a function we                                  package maybe                                                             so it's faster to deploy faster to                                  package yeah not sure if I answered your                                  question but yeah and you can also put                                  these layers on top of each other so if                                  you have multiple dependencies that                                  build on each other you can you can                                  organize this like I just didn't                                  understand see how the layers are placed                                  in the hard rain gauge how you create                                  like like like I know how to outer                                  layers are in say kubernetes or in doc                                  docker images but not sure how how is it                                  in this case how do you create them you                                  mean or deploy them how doors are                                  physically or done in the ice if said                                  it's a zip file so how do you manage                                  this way it's essentially just Union                                  file system essentially I think you have                                  a set of files and directories and it                                  will put them all together into one big                                  thing I'm not sure what happens if like                                  one layer tries to override fill up                                  files from the one below I assume it                                  will replace them but they haven't tried                                  that we only have one layer in our                                  in our examples okay so the platform                                  will take care of getting or figuring                                  out which layers are common for know we                                  have to specifically create layers yeah                                  and there are some prepackaged once and                                  then there's I think they think about                                  having like a marketplace for these kind                                  of things and so on but yeah yeah so we                                  have to specifically create the layers                                  in our case like in one one deployment                                  at some point has to create a layer and                                  then others can reuse it yeah all right                                  okay thank you very much yeah you're                                  welcome                                  all right since we're done all right                                  thank you                                  [Applause]
YouTube URL: https://www.youtube.com/watch?v=fdr2N74Yebg


