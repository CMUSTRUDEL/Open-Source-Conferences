Title: Berlin Buzzwords 2019: Philipp Krenn – Reaching Zen in ElasticSearch's Coordination #bbuzz
Publication date: 2019-06-27
Playlist: Berlin Buzzwords 2019 #bbuzz
Description: 
	Elasticsearch's cluster coordination system, called Zen Discovery, got a rewrite in version 7.0. Starting from a formal model, the coordination layer was rebuilt to address multiple issues discovered over the years. 

This talk shows the main improvements of the new implementation: Master elections are much faster, the infamous minimum_master_nodes setting has been removed, growing and shrinking clusters becomes safer and easier, and leaves less room to misconfigure the system. Let us join the new, more Zen way of cluster coordination.

Read more:
https://2019.berlinbuzzwords.de/19/session/reaching-zen-elasticsearchs-coordination

About Philipp Krenn:
https://2019.berlinbuzzwords.de/users/philipp-krenn

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              thank you hye-won everybody still awake                               more or less yeah okay                               let's see this is a bit of a threat                               topic so let's see how dry it will be so                               I assume that everybody has an idea what                               elasticsearch is right so we don't need                               to cover like shards and illnesses and                               stuff like that and you know what nodes                               are so we'll just build on top of that                                otherwise shout if anything is missing                                so I work for elastic the company behind                                the entire stack my official role is                                developer advocate so I mostly travel                                around and show what we're changing or                                what we're trying to build and that's                                pretty much my role definition so let's                                see what we have                                so what is what is it even when I say                                cluster coordination what what are you                                expecting when I say cluster                                coordination any expectations what might                                be caster coordination in elasticsearch                                yeah so you have different node types                                that you want to get to yes and the                                general idea is you want to have                                something we call the cluster state so                                the cluster coordination takes care of                                the cluster state now obviously the next                                question is what is the cluster state                                and that is exactly when you have                                different nodes but it's not just the                                different nodes it's much more than that                                so what you have is you have cluster                                wide settings you have index meta data                                so cluster wide settings might be like                                these are all the nodes that make up my                                cluster could be a single node could be                                                                                                  whatever you have there                                you could have index metadata that might                                be for example you have one index that                                is the specific mapping for that those                                are the settings for that index and the                                mapping settings that you have in those                                you could also have additional                                information like for example the index                                is broken up into one or more shards on                                which nodes are these shards are the                                replicas of that chart in sync with the                                primary shard and all of that                                information that is the cluster state so                                that is basically the meta information                                that keeps your cluster life and keeps                                everything working and lots of other                                different pieces this is not about them                                it that data you keep in your cluster                                itself this is just the metadata to keep                                your cluster operational you can check                                what you have in there with underscore                                cluster state and you can only see what                                is kind of like the meta data you have                                in there important is if you lose data                                there in our opinion it's much worse                                than losing a single document we                                losing a single document you have one                                documented discontent losing an entire                                chart or the mapping for some index is                                much worse than that                                and that might have or might impact lots                                of documents and not just a single one                                so for us the cluster state is the thing                                that needs to be in a good state and                                only moving forward if you ever lose any                                cluster updates it's also very bad stay                                for your cluster and that is kind of the                                important part so we want to keep that                                data in a good shape and only moving                                forward one example here this is                                normally very long for example you can                                see I have version                                                     just started up with just my taco                                cluster which I have running locally                                here but that would contain a lot of                                other information so it would know all                                the indices I have in there the mappings                                of those indices like which version of                                which mapping are half and all those                                pieces of information that is the                                cluster state that I have in there now                                the three main components of the entire                                discovery well it kind of tie across the                                state is you have discovery which are                                the other nodes in my cluster what can                                form one cluster you have the master                                election like which single node is the                                master and keeps track of that state and                                that is the only one who can write to                                that cluster state and the publication                                of the cluster state in the end to                                 actually spread out the current cluster                                 state to all the other nodes in your                                 cluster so we've used something called                                 Zen for a long time if it was always so                                 Sen we could discuss but the general                                 idea is we have sent to do the discovery                                 and the election and we've recently for                                 version seven rewritten that to send to                                 however we don't really emphasize sin as                                 a name that much anymore                                 because it's not pluggable as soon as                                 you have elasticsearch you have sent to                                 nowadays doing everything for cluster                                 coordination for you you cannot throw in                                 anything else that is intentional                                 we don't plan to have any alternatives                                 to that so you're stuck with that that's                                 why we generally don't emphasize send                                 that much but this is the thing or                                 implementation that we have in there and                                 the general idea is that Zen is pretty                                 much like whatever is happening in your                                 cluster your master should be pretty                                 stay                                 like sitting in the middle and whatever                                 happens around it doesn't affect its                                 state so much there is the general idea                                 of having this sin idea maybe in the                                 past it wasn't always that sin but the                                 idea is to have it more sin in the                                 future why we have this resiliency page                                 in elasticsearch which documents all the                                 things that could go wrong either in                                 practice or in theory in your cluster                                 and one very important point that we had                                 on there that we were recently able to                                 strike off because of this rewrite of                                 sin was that if you have repeated the                                 repeated is important repeated network                                 procedure partitions you could lose                                 cluster state updates which was a very                                 bad day for the cluster if that happened                                 it was kind of complicated to trigger                                 because it had to be repeated in a                                 specific order and timing window but it                                 could happen                                 and then you would lose important                                 information and there was one part of                                 that cluster reor the sin rewrite that                                 we did it was also because sin initially                                 was kind of like a bit homegrown and was                                 just put together and then patched up                                 over time to just work better and better                                 and we like experimented like these are                                 the right time outs here we know that                                 these are the kind of right settings in                                 combination these normally work but it                                 wasn't really proven or as theoretically                                 founded and grounded as you would want                                 so the general idea was we want to redo                                 this to fix issues like this one and                                 basically with we started with                                 elasticsearch foreign models which is                                 another public repository we have and                                 this started with theoretical                                 specification in TLA plus and we also                                 have model checking for that in TLC I                                 have managed to stay away from those                                 specifications and I don't really know                                 what they're doing but it might look                                 something like this and if this is you                                 thing you might have a great day diving                                 into those I I'm fine and believe my                                 colleagues who work on that and that                                 they can prove that the cluster state is                                 going right from one good state to                                 another good state and we don't have any                                 anomalies like on a theoretical level                                 and then can prove that our algorithms                                 that we build on top of those also do                                 the right thing so                                 discoveries generally we had these three                                 things and the first thing was the                                 discovery where are my master eligible                                 notes is there a master already this is                                 kind of like the part of discovery                                 basically the idea is if you have three                                 nodes they should all come to the same                                 conclusion what your cluster looks like                                 because right now you can see the three                                 nodes all have a different opinion of                                 what the cluster might look like you                                 have like the one in the bottom left                                 thinks there are only two nodes the one                                 on the bottom right thinks directionally                                 four nodes which probably don't exist                                 here but the idea is to have one uniform                                 version of what the cluster looks like                                 and what you have in your system                                 previously you had the following                                 settings or actually first you have the                                 old settings and in seven we have these                                 new settings the old ones still work                                 they're deprecated but they will be                                 removed in the next major version so                                 what used to be Zen ping unicast hosts                                 is now just called discovery seed hosts                                 since I said sin is not pluggable we                                 just threw it out of the API because                                 well you cannot change it anyway you                                 will always have sin in there anyway so                                 by discovery seed host you basically                                 provide the host names of all the hosts                                 or some of the seed hosts that can start                                 forming your cluster initially if you                                 have a more dynamic environment like a                                 cloud provider you could provide either                                 a file or some specific tagging firewall                                 group whatever in from your cloud                                 provider that the nodes find each other                                 and then form a cluster so you don't                                 have to know the DNS names or IP                                 addresses in that setting you could just                                 provide another mean to find the right                                 nodes or if you have a more static                                 setting you could just provide the seed                                 host which is like a set of starting                                 nodes don't have to be all of them but                                 one node needs to reach at least one of                                 the other seat nodes and then they will                                 form one large cluster over all the                                 master election that happens once the                                 nodes have found each other will then be                                 like who should be master and then they                                 will form a cluster and unless something                                 goes terribly wrong they will always be                                 exactly one last node in an                                 elasticsearch cluster and ideally you                                 form that pretty quickly because you                                 cannot run any major updates while you                                 don't have a cluster or you cannot write                                 do any changes actually at all                                 so the general idea is you have that                                 leader and everybody else is following                                 that master note to whatever next state                                 your step you want to take that's the                                 general idea when you have the master so                                 what you did have is and for some the                                 resolution here is not what it should be                                 but it's called discovery send minimum                                 master notes which Simon mentioned in                                 his talk earlier is something you always                                 use to set if you didn't set that you                                 would have a cluster that probably would                                 be in a very bad state the problem is it                                 has to be set manually and the first                                 thing is do you trust your users always                                 to set that correctly as we have learnt                                 you probably should not because people                                 will often set it incorrectly or not set                                 it at all and the other problem is that                                 if you have changed in a number of                                 master eligible nodes you might also run                                 into trouble because what this might                                 look like is let's say we have a three                                 node cluster and you say you start those                                 three nodes up and right now there is no                                 cluster here just three independent                                 nodes and let's say we didn't set                                 minimum master nodes and then you could                                 can see like they could form three                                 independent clusters by the different                                 colors like each one of them could think                                 well I'm the only node I will start my                                 own cluster and there is no way to                                 reconcile that afterwards so you cannot                                 easily merge the data together if you                                 have independent masters and they                                 diverge so that's not to say we want to                                 have what you would always need to do is                                 the majority of three is obviously two                                 so you would need to set it to to you so                                 you could have these two nodes could                                 form a cluster or these two nodes and                                 well there would be a third combination                                 with the combination of two or all of                                 the nodes together form one cluster so                                 that's good that works the problem is                                 what happens if you want to scale that                                 cluster up so let's say we keep the                                 minimum master nodes - but we want to                                 add one more master eligible node what                                 could then happen is that suddenly you                                 add another node and then you have two                                 clusters again because you satisfy that                                 condition their minimum master nodes you                                 have two here you have two there but you                                 have two independent clusters in the end                                 so this is not very healthy the other                                 thing is if you want to scale                                 and you have a single node and you said                                 minimum masternodes to two well you                                 couldn't elect the master so your caster                                 wouldn't do anything so these situations                                 were kind of tricky to always like scale                                 them the master eligible nodes and that                                 set incorrectly on all the nodes that                                 proved to be tricky and people would                                 just set it incorrectly and that was the                                 number one source for issues and data                                 loss in elasticsearch in general so the                                 idea is probably to automate that and                                 make that setting go away so people                                 don't have to set it or have the pain                                 the possibility to set it incorrectly so                                 what we have now is initial master nodes                                 which is basically the list for the very                                 first election so the bootstrap process                                 when the cluster comes up the very first                                 time that setting is being used and                                 after that only the cluster itself will                                 keep track of what are the master                                 eligible nodes and it will automatically                                 set the number of minimum master nodes                                 basically internally you cannot set that                                 explicitly anymore and you don't have to                                 so this is only for the very first                                 bootstrapping approach even when you do                                 a full cluster restart and you have an                                 existing data directory we will keep                                 that information there so this is really                                 just when forming the cluster for the                                 very first time then this initial master                                 nodes a list will be used it is okay to                                 set this on multiple nodes as long as                                 they are all consistent what you                                 shouldn't do is you shouldn't set like                                 one node as the minimum initial master                                 nodes on one node and three on another                                 like the list of those hosts because                                 that would not be easy to like find a                                 conclusion to that if you set it on more                                 than one node it needs to be in a                                 consistent state once a cluster or a                                 node joins a cluster even if it's just                                 being restarted that setting will be                                 ignored so it's just for the very first                                 time you start it up you don't have to                                 set that when a node joins an existing                                 cluster it would just be ignored so you                                 don't have to set it afterwards anymore                                 when you upgrade from version six to                                 seven and you do a full cluster restart                                 then you have to set that if you do a                                 rolling upgrade you don't have to set                                 that because you still have the minimum                                 master nodes from before you're just joy                                 and then the new nodes in seven would                                 figure out like okay these were the                                 right settings in the past and I know                                 how the cluster should look like so I                                 know what the minimum masternodes                                 basically are there is no need to set                                 that explicitly anymore because the                                 cluster will know on its own if you                                 start a cluster fresh and you did not                                 set cluster initial master nodes and you                                 have three nodes what you will get is                                 you will get an error or actually it                                 will get a one message the cluster would                                 not form but it would continuously lock                                 that message and it is actually helpful                                 with that new message because that                                 contains quite a bit of debugging                                 information so this is the first page of                                 three so you can see here I'm logging                                 that I have a three node elasticsearch                                 cluster which my clusters called docker                                 cluster and I'm on the elasticsearch two                                 node here and this one give me will give                                 me continuously messages telling me what                                 is wrong and you can see here master not                                 discovered yet and this node has not                                 previously joined the bootstrap cluster                                 and it will basically say like hey I'm                                 master eligible and I have found these                                 other two nodes so it has found and                                 elasticsearch one and elasticsearch                                 three node though three together                                 well they had learned half the initial                                 master node set but they've found each                                 other but they cannot form a cluster                                 because they don't know maybe there                                 should be three more or maybe there                                 should be two more they don't really                                 know how much there should be in total                                 because you haven't applied that right                                 setting for the very first time you                                 start them up and then you would also                                 get some more information that it will                                 tell you it will try to continue                                 discovering like the current node is the                                 elastic search - that is running this                                 here it will also tell you this was the                                 last cluster state that I knew since                                 this is just right from the start up                                 none of these values have any have been                                 ever set so the cluster has never formed                                 and just didn't form correctly if you                                 want to scale a cluster dynamically once                                 it has formed correctly if you add any                                 nodes that are not master eligible                                 nothing changes everything is like                                 before if you add and must master                                 eligible node just do it because the                                 cluster will then                                 Oh ders another must eligible note do I                                 need to change how many nodes I need to                                 have to actually have the mass selection                                 and have the majority and the Casa we'll                                 figure that out automatically you can                                 also remove mass eligible nodes the only                                 thing you cannot do is do not remove                                 more than half of the master eligible                                 nodes at once otherwise the cluster will                                 not be happy because suddenly it lost                                 the majority and it would not form know                                 how to form a cluster anymore                                 the cluster State publication is                                 basically the last step once you have                                 formed the cluster there's pretty much                                 like the master node does the right                                 operation it tries to apply it to the                                 majority of the master eligible nodes                                 only then it can be sure that the                                 majority has it and if even if the                                 master dies like another node will have                                 that state and then it will actually                                 broadcast the updates which looks pretty                                 much like this so you have this is our                                 master eligible node this line here you                                 get a change for example you add an                                 index or you add a node and then you                                 basically try to publish that event to                                 the majority of the nodes so for example                                 the master has it and one of the other                                 nodes has it so then we have two of the                                 three nodes half that state then you                                 have published it successfully and then                                 you can commit it so then the master                                 commits it to both of the other nodes                                 and then they apply it and that's how                                 you publish the cluster state or an                                 update to the cluster state only the                                 master node can actually change the                                 cluster state and will first apply it to                                 get to the majority of nodes and then                                 once it has the majority it will                                 actually commit that change and that is                                 how the publication works and generally                                 the cluster looks something like this                                 you have the master and it will just                                 have a peer to peer connection to all                                 the other nodes and broadcast to them                                 what is happening in the cluster to wrap                                 up normally I would try or give you a                                 demo with a rolling upgrade and failure                                 states and everything but                                               not quite enough to do that I will                                 publish the slides afterwards basically                                 what you have here is I have my three                                 talker containers in a rolling update                                 scenario these two here the same send                                 ping unicast these were the old settings                                 these two here these you can remove and                                 these are the new settings and you can                                 see the seat host is kind of like a                                 direct representation from this one and                                 instead of saying minimum                                 so notice - you basically provide the                                 list of these are the three nodes that                                 are master eligible and they form the                                 master eligible status in the end okay                                 then - then - generally faster the                                 elections will be much faster it's safer                                 and it should also be more debuggable                                 because the debugging output is better                                 otherwise you should not really notice                                 and except for some bad configurations                                 we haven't really seen much trouble in                                 the discussed forums by the way if you                                 don't have enough of elasticsearch yet                                 today we'll have a meet-up tonight so if                                 you want drinks and more discussions                                 come to commune commander at                                           where we'll have the meet up and have                                 some Modi's elasticsearch talks that's                                 it do we have time for questions yes                                 like two minutes okay any questions how                                 do you discriminate between a dying note                                 and a note that you just remove so                                 suppose that I remove a master note well                                 so what we have is we have these health                                 checks which are basically pings which                                 every X seconds I forgot which how many                                 seconds five or something like that we                                 ping a note and once it's not reachable                                 like I think if we pay fail three pings                                 or something like that don't                                 maybe those numbers are wrong but it's                                 something like that then we'll just                                 assume the note is that we cannot                                 determine if it has really been removed                                 or if it's just like stuck in a long                                 garbage collection for example or if the                                 network is down but then it will just be                                 removed from the cluster and later on if                                 it comes back it can rejoin the cluster                                 but we don't really make that                                 differentiation if it has been                                 explicitly removed or not what you could                                 do is if you know you want to rotate out                                 the node you could for example vacate                                 the location and move all the data that                                 you have on that note if it's a data                                 node and two other nodes and then remove                                 it more gracefully that you don't really                                 have like data being impacted by that                                 but are basically mentis when you remove                                 from after note the cluster rebalances                                 Jung internally does it state state                                 processing if it's the actual master                                 that you removed then the other notes                                 keep pinging that one as well and then                                 we'll figure out okay the master is not                                 reachable anymore and then they will                                 check like hey do we have enough master                                 eligible nodes to actually form a new                                 cluster and then they will hold an                                 election and for minima or an and elect                                 a new master and that is now much faster                                 because we were able previously we had                                 like some tweaks around the time outs                                 with the new protocol that is much                                 quicker than we figure out all the                                 master is not there and we don't have to                                 wait until everybody has made it so this                                 is much quicker but generally everybody                                 is pinging everybody else and when when                                 the node is not reachable it will just                                 be removed and if it was the master node                                 we will hold an election and actually                                 elect another master if you have enough                                 master eligible nodes left because if                                 you have for example three mass eligible                                 nodes and to disappear the remaining one                                 cannot vote because it might just be a                                 network petition and the other two might                                 be somewhere else so you need to have                                 the majority still to be able to do that                                 that's why you cannot remove the                                 majority of mast eligible nodes at once                                 because otherwise the Kaster would just                                 not be able to elect the new master                                 makes sense yes come to me later                                 since we're completely out of time we'll                                 take one more question sure                                 hi hi you mentioned debug ability and                                 I'm also got a question regarding the                                 Zen pings is there any way that because                                 the elasticsearch risk is quite                                 sensitive to network issues to                                 introspect the latency of the pings or                                 if there's like a ongoing issue is the                                 way to like introspect this so I think                                 generally the the error messages that                                 you run into have changed quite a bit                                 and should give you much more                                 information than before I haven't                                 recently tried out like how the time-out                                 message looks like but I think normally                                 it's very verbose and will tell you like                                 hey                                 was not reachable and this is how many                                 times it failed and this is the time it                                 took so that should generally be more                                 debuggable than before yeah so that the                                 idea was also to make the entire thing                                 more debuggable than before because                                 sometimes it was a bit hard to see and                                 as long as people provide like the full                                 stack traces or the full error messages                                 we were in a discuss forums pretty quick                                 to actually debug what was going on the                                 main problem is if we don't have like                                 all the outputs then it's sometimes a                                 bit hard to know what is really                                 happening but given the full of outputs                                 recently from what I've seen debugging                                 improved quite a bit                                 cool thanks a lot                                 [Applause]
YouTube URL: https://www.youtube.com/watch?v=Ns1Erg4I92U


