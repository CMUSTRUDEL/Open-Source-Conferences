Title: Berlin Buzzwords 2019: Michael Gibney â€“ Precise graph-based phrase query with SpanNearQuery #bbuzz
Publication date: 2019-06-18
Playlist: Berlin Buzzwords 2019 #bbuzz
Description: 
	The current implementation of SpanNearQuery in Apache Lucene sacrifices precision and completeness in favor of performance. This tradeoff significantly limits Lucene's usefulness for some potential high-value use cases. This talk introduces a stable patch that makes SpanQuery matching precise and complete, while maintaining performance comparable to that of the extant implementation.

The patch will be discussed in the context of the issue LUCENE-7398, describing the central problem and how it differs from the problem addressed by the new IntervalsSource API.

We will discuss details of the patch implementation, in an effort to familiarize the audience with techniques involved (and hopefully inspire further innovation). Details covered will include:

1. The main word-lattice data structure (linked, circular, resizable-array-backed, 2-dimensional queue with stable node references and support for efficient binary seek, serial traversal, and arbitrary node removal).
2. Performance/GC management for linked data structures (as opposed to the array-based data structures that are more common in the Lucene codebase)
3. Recording in the index: positionLength, nextStartPosition lookahead, and information about possible decrease of endPosition (de-"sausagization" of the index)

Read more:
https://2019.berlinbuzzwords.de/19/session/complete-precise-graph-based-phrase-query-spannearquery

About Michael Gibney:
https://2019.berlinbuzzwords.de/users/michael-gibney

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              thank you all so much for                               for coming out so the tide                               included a specific call-out to Spain                               near query the implementation that I'm                               going to be talking about has was was                               done with span queries but as I'll be                               returning to as kind of a theme a lot of                               the issues that I'm going to be                               discussing about are actually more                                general than that and have to do with                                phrase query or proximity query in in                                Lucene I'm going to start with a brief                                overview of the leucine token stream                                structure the structure is what makes it                                possible to express the richness of                                indexed and query to input so Lucien's                                token stream API was initially assumed a                                more or less linear stream of tokens so                                each token was assumed to have a                                position length of                                                assumed to progress one after another                                since the addition of the position                                lengths attribute in leucine                                         possible to represent tokens as                                branching graph that that can branch and                                merge back together uses of the token                                stream API at index time it's used to                                determine the tokens and token structure                                serialize to the index and a query time                                it's used by various query parsers to                                construct the the structure of queries                                that are run against the index so we                                have an example here of OLED                                manufacturing which would be indexed or                                parsed for query purposes as organic                                light-emitting diode manufacturing or                                organic LED manufacturing or OLED                                manufacturing so talk about the latent                                potential of the position length                                attribute it was introduced in leucine                                                                                                    that information is discarded at index                                time it's not written into the index and                                so that assumption of a linear token                                stream persists for indexed content I                                have a nice picture of braided rivers                                which look cool and are basically stream                                that separate apart and come back                                together so it's possible to do this                                without losing information about token                                adjacency and different branches so to                                fully leverage the structure of the                                token stream API at indexing time would                                require three things to happen more or                                less in concert with each other we would                                have to store the position lengths in                                the index augment the postings API to                                expose position length to index readers                                and update the query implementations to                                leverage index position links as exposed                                through the postings API it's been                                pointed out that the last of these is                                the most challenging and has been a                                problem and causes problems for word                                delimiter graph filter used at index                                time etc so leucine                                                   that it forms the umbrella for a lot of                                what I'm talking about here it's the                                issue is nominally about nested span                                queries but the issue is actually more                                general than that in the absence of                                index position links nested span queries                                were are the the primary and perhaps the                                only way of generating or encountering                                variable in sub-clauses so the issue                                that we're really talking about here is                                variable length subclasses and where he                                phrase queries over those proximity                                queries so we're gonna talk about an                                implementation with span near query but                                the issues are more general than that                                and they apply also to any phrase or                                proximity query implementation as well                                as to the interval source API so for                                purposes of simplicity and generality                                we're gonna focus on the position order                                abstraction of the spans API so not the                                entire spans API necessarily but                                basically the the spans API specifies                                that positions will be exposed in order                                in increasing order by start position of                                a token and then within that secondary                                sort on end position within a token                                so the span positions are advanced                                forward only and within a given - oh I                                already said that                                ah so we make no other assumptions the                                end position might be arbitrarily larger                                and the start position and so we might                                 have actually a decreasing end position                                 which introduces the possibility for new                                 matches so and this helps us avoid the                                 special case avoid the the trap of sort                                 of considering simple term spans to be a                                 special case with a static implicit                                 position length of                                                    happens to be a part of the spans API                                 but it's more generally useful because                                 it's kind of the most sensible way to                                 provide an absolute ordering for                                 something that has a start position and                                 an end position so this is a little                                 picture that references the previous                                 diagram of OLED manufacturing and shows                                 how it's currently recorded in the index                                 so the position length is discarded so                                 all of the terms appear but the                                 adjacency relationships are lost so this                                 can yield surprising results for                                 proximity based queries when graph token                                 filters are applied at index time in the                                 example above partially redundant                                 synthetic phrases like OLED LED emitting                                 diode manufacturing would perfectly                                 match phrase queries whereas a query for                                 the original text in the document                                 OLED manufacturing would only match with                                 a slop greater than or equal to                                       you can kind of see that because the                                 OLED which appears in the original                                 document is actually separated from                                 manufacturing the current recommended                                 practice of performing synonym and word                                 delimiter graph filter expansion only at                                 query time does work around this issue                                 but this practice is problematic because                                 of the importance of context in                                 determining                                 in determining appropriate token stream                                 manipulations and there's a lot of                                 context that's available at index time                                 that is simply not available at query                                 time so this is also an example of a                                 case where decreasing end position can                                 cause matches to not be found so match                                 one would not be found until advancing                                 to position D in in clause two and then                                 once you're at position D in Clause two                                 you have to be able to backtrack to                                 position C in Clause oh sorry zero-based                                 indexing                                 you have to be able to backtrack to                                 position C when your end position                                 decreases so it can get it can get                                 tricky so as a replacement for span near                                 query the current implementation of the                                 interval source API essentially has                                 similar properties to multi phrase query                                 which falls back on an assumption that                                 sorry falls back on enumerate all                                 possible paths through a given query so                                 that works in some ways but it also                                 introduces the potential for exponential                                 query expansion which is which is                                 problematic particularly if you're                                 interested in heavily leveraging                                 synonyms at index time so just checking                                 on okay I'm doing okay time wise so for                                 the foundation for this implementation                                 we have a wrapper that implements the                                 spans interface which can be wrapped                                 around any spans implementation that                                 will support backtracking efficiently                                 without buffering any more positions                                 than necessary so the two key method                                 signatures that that I'll call out here                                 are the next match which includes the                                 concept of this is as a replacement for                                 an extra next start position which is                                 how you advance through spans so this                                 next match is basically the same thing                                 except it includes information about a                                 hard minimum start a soft minimum start                                 start ceiling and a minimum end so the                                 idea is to basically abstract all the                                 information that's necessary to                                 determine whether you need to buffer                                 positions when you advance or whether                                 positions can be discarded and then the                                 reset obviously or obviously provides                                 the backtracking capability so you can                                 say I want to go back to this start                                 position and and proceed from there so                                 you can replay positions I think it                                 covered these yeah and so the start                                 ceiling allows you to I don't get into                                 those more deeply so the the properties                                 of a backtrack of the spans wrapper it's                                 implemented as a position queue sorted                                 according to the order of the positions                                 from the backing spans so it's a it's a                                 sorted queue sorted by virtue of the                                 fact that the input coming from spans is                                 already sorted to conform to to the                                 position order specification of the                                 spans API so it's linked for a fishing                                 iteration and node removal because                                 depending on the position length some of                                 these some of these positions are going                                 to be able to be dropped so they they                                 can be pruned out of the queue so it's                                 kind of a weird queue that normally                                 would remove from would insert one end                                 and remove from the other but you can                                 also take things out of the middle it's                                 also array backed using a circular                                 buffer to support sufficient binary seek                                 because if you're gonna have to be                                 backtracking and resetting to a specific                                 position you want that to be fast and                                 the array is dynamically resizable with                                 the the positions basically the array                                 index is done all the way up to the                                 maximum integer value and then rolls                                 over by design to allow Windows and to                                 allow stable references to the nodes to                                 be to be preserved so for purposes of                                 building matches over the subclause each                                 sub Clause has its own queue of                                 positions that's what we talked about in                                 the last slide nodes in those queues are                                 also linked laterally across subclasses                                 sub-clauses to build matches without                                 duplicating information about the                                 positions so you already have the                                 information stored you just want the                                 nodes and the queue to do sort of double                                 duty both within its position but also                                 across positions to build the matches so                                 you have kind of like a two dimensional                                 queue in a way yeah so maintains                                 references to the previous and next                                 nodes within slop constraints and we                                 mentioned the stable node references                                 that are wrapped around and and that                                 don't just use the index position in the                                 backing array so the resulting word                                 lattice that you end up with is built                                 using the next match method signature                                 that that was referred to in one of the                                 previous slides and so calling next                                 match as part of the algorithm for for                                 building the matches drives a                                 depth-first search to discover and build                                 and cache the edges in the dynamic graph                                 represented by valid nodes at a point in                                 time so it's a dynamic graph in the                                 sense that progressing in different ways                                 can cause certain nodes to become                                 invalidated so you can kind of prune                                 them out and close the gaps up so in the                                 phrase paths that are already explored                                 or cashed                                 enabling match tree traversal to be                                 short-circuited and you have a                                 downstream postfix subtree grafted on to                                 upstream match prefixes you can see that                                 happening here a little bit so you can                                 see the links from B prime to be double                                 Prime and C double prime have been                                 explored from starting from position a                                 but then those links from B prime to the                                 two the third sub Clause are still going                                 to be valid and we know they're going to                                 be valid at B so you don't have to                                 re-explore those and it's a little bit                                 tricky to to explain what's going on                                 here I had a very hard time coming up                                 with a good example but what's going on                                 here is that C prime D prime V Prime and                                 F prime are all much closer to position                                 C so you have links going to all of                                 those so you can note the the fan out                                 that the potential for fan out and also                                 the sort of strange interactions of slop                                 because as you move to different                                 positions you are also consuming slop                                 and are therefore left with less slop                                 available to continue building the tree                                 out to the to the right right so this is                                 a linked approach a lot of the data                                 structures in leucine are array based                                 because they're very fast and the                                 generate little garbage collection if                                 we're using a linked approach which is                                 kind of necessary for this                                 two-dimensional situation where nodes                                 can get yanked out and we want positions                                 to close up there's the there's lots of                                 small transient objects including just                                 not just the storage nodes but also the                                 linking nodes that allow us to build all                                 these links so there's lots of garbage                                 collection potentially so implementing a                                 queue for the nodes and the linking                                 nodes                                 resulted in                                                           performance in comparison to                                 an implementation with object pooling                                 disabled and the the variation there is                                 in keeping with the intermittent nature                                 of long garbage collection related                                 pauses so that was made a big difference                                 so the query implementation finally                                 gives us a really solid reason to                                 implement as opposed to ignore indexed                                 position lengths for purposes of                                 development testing and initial                                 deployment most of the extra information                                 that was needed was implemented with                                 payloads and the encoding of the                                 payloads was accomplished by a token                                 filter this is that sits at the end sort                                 of like the flattened graph filter but                                 it reorders tokens to conform to the                                 ordering specified by the spans api so                                 at query time they're just read out in                                 in a normal order i'd be interested to                                 see what the performance impact would be                                 of using a position length                                 implementation that isn't based on                                 payloads have a sense that it would                                 probably be faster but yeah to be done                                 there's also some other information that                                 is useful start position look ahead                                 so we're buffering all these positions                                 but there are certain efficiencies that                                 can be gained if you're able to sort of                                 look ahead to the neck what the NARC                                 next start position would be so if you                                 do that then it's possible to to avoid                                 buffering entirely for the normal use                                 case because most people's data doesn't                                 have this kind of rich structure but you                                 can use the same approach and it just                                 won't buffer if it doesn't need to                                 buffer so there's some edge cases here                                 you can also make some efficiencies if                                 you know that the end position will                                 never decrease across positions almost                                 always it doesn't but for some cases it                                 it might do so a lot of the time and if                                 the assumption about the position links                                 being one                                 always is valid then you can take                                 advantage of that as well                                 this is currently implemented with four                                 bytes that are pre allocated in the                                 payload and sort of modified after the                                 fact by the default indexing chain                                 there's probably a better way to do that                                 but but for a proof of concept this                                 yielded excellent results so one last                                 thing is common words how many minutes                                 do I have left - okay so common words                                 are a problem for phrases you can use a                                 stop word filter which leaves holes                                 which behave weirdly for for the words                                 that you're removing from the index or                                 from the queries or you can use common                                 grams filter but that makes it so that                                 any word that is included in your common                                 gram has to always be included exactly                                 next to the - its paired term so we're                                 able to work around this by basically                                 pre-filtering the conjunction spans and                                 that worked nicely I can talk more about                                 the details of that if people are                                 interested afterwards there are                                 different match modes because now that                                 the matching is much more precise we can                                 do things like greedy matching and her                                 position matching and paren position                                 that basically ensure that nested                                 sub-clauses expose every valid end                                 position so that we're certain to match                                 everything that needs to be matched so                                 I'm particularly interested in CJK                                 indexing anything that has multi token                                 orthographic variants word delimiter                                 graph filter this also opens up the                                 possibility for creative uses of engrams                                 and shingles that would behave more                                 predictably                                 and yeah more nuanced scoring also                                 potential non non text use cases so                                 anything that can be represented as an                                 ordered stream of discrete possibly                                 overlapping elements each having a start                                 position and an end position I could see                                 this being useful obvious case would be                                 time series data like travel scheduling                                 where you could represent individual                                 trips as tokens it could be pretty fun                                 to mess around with that I have not done                                 that but somebody should thank you some                                 links and thank ya thank you                                 [Applause]
YouTube URL: https://www.youtube.com/watch?v=yoo1hC_InsY


