Title: Berlin Buzzwords 2019: Houston Putman â€“ Running Solr within Kubernetes at Scale #bbuzz
Publication date: 2019-06-20
Playlist: Berlin Buzzwords 2019 #bbuzz
Description: 
	The Search Infrastructure team at Bloomberg runs over a thousand Solr clouds spread across hundreds of machines. This scale creates significant challenges in managing hardware resources. Beyond just managing where clouds are allocated and the resources available across the cluster, tasks that affect multiple clouds, such as upgrading OS versions or taking a machine down for maintenance, can grow into serious undertakings.

Kubernetes is a system designed to help orchestrate large scale applications. However, it has room for improvement in use cases such as running on physical hardware or managing stateful applications. In this talk, Houston Putman will detail how the team has addressed these issues and begun to run production Solr clouds on Kubernetes. He will also share his experience and the performance characteristics when running Solr on Kubernetes vs. on bare metal.

Read more:
https://2019.berlinbuzzwords.de/19/session/running-solr-within-kubernetes-scale

About Houston Putman:
https://2019.berlinbuzzwords.de/users/houston-putman-0

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              hello everyone thanks for coming today                               as was mentioned I'm Houston I'm a                               software developer on the search                               infrastructure team at Bloomberg and                               here I'm in talk to you today about                               running solar on kubernetes um just kind                               of brief into a Bloomberg and what we do                               we're the largest private provider of                               news and business information around the                                world we power tools that help finance                                finance government and law professionals                                throughout the globe and at a very large                                scale having to deliver kind of high                                performance applications that scale and                                are reliable due to the customers that                                we try to support um this kind of leads                                into search infrastructure team we just                                manage a lot of search infrastructure at                                Bloomberg because of the amount of data                                and kind of the reliability that our                                customers kind of rely on I mean so                                because of the scale you can imagine                                that running all of these thousands of                                search engines would become kind of                                cumbersome and lead to a lot of monday                                and activities that you don't really                                want to have to deal with that kind of                                gets into our talk today we're gonna                                first kind of give some baseline                                knowledge about kind of managing solar                                clouds and a kubernetes introduction I'm                                sure that a lot of you all kind of                                understand how solar clouds are managed                                and kind of the basics of kubernetes but                                please kind of deal with the                                introductions because I want to get                                everyone on a baseline knowledge before                                I kind of talk about what we've built                                and the solar cloud operator that we've                                opened source that I'll end with cool so                                imagine managing solar clouds at                                Bloomberg we manage solar clouds at a                                very large scale we have thousands of                                search engines managing tens of billions                                fifties of billions of documents daily                                and so basically there are two different                                ways that we manage our search                                infrastructure and basically two                                different ways of managing solar clouds                                there's the physical management as well                                as the logical management physical                                management is where does data live what                                processes are running connected to                                zookeeper creating these solar clouds                                and the logical management is what is                                the data the                                in these other clouds how is it broken                                up what is the schema define these kind                                of things that you normally think about                                when using search as a kind of consumer                                instead of as a provider so first I'll                                kind of dive into what this physical                                topology that I mentioned before is                                basically this is your infrastructure                                this is your list of servers or virtual                                machines that are running a Java                                processes that are running solar cloud                                these little clouds are connected to                                zookeeper and they are storing solar                                cores which is just parts of the solar                                index that you're using to search next                                you have the logical topology this is                                the other side of how you manage the                                data here data is broken down into                                collections which is just a logical                                grouping of documents that have the same                                schema and that you can do common                                operations on these are further broken                                down by shards which are kind of logical                                splitting of the data so that it can be                                replicated and so solar shards can only                                store up to two billion documents so at                                some point you need to add shards to                                your collection in order to store kind                                of large amounts of data replicas are                                kind of the last level there and this is                                a copy of a shards data that is                                replicated as many times as you want                                just to add in resiliency to your solar                                cloud and this is basically how our                                logical and physical technologies meet                                they house solar cores which is just a                                copy of the index so as I mentioned                                before this our logical topology and so                                basically if we take away the clouds and                                the collections in shards we are left                                with just replicas we can shuffle these                                replicas around however we want and they                                just remain replicas once we bring up                                 the physical topology layer you can see                                 that the server and solar nodes view                                 which is the physical topology view is                                 basically just a reimagining of the same                                 data so that it's seen in a different                                 way so these men these topologies are                                 managed in very different ways logical                                 has a much better                                 kind of set of defined api's and                                 commands within sulla that lets you                                 manage it physical is a little lacking                                 and so with the logical topology you get                                 a lot of implicit features in solar this                                 is through the auto scaling component                                 which lets you add remove replicas to                                 based on load and other things as well                                 as time routed aliases which based on                                 the data within your collection spins up                                 new collections or deletes old ones if                                 you don't need that data anymore or you                                 have like new data coming in with newer                                 dates that you want there's a lot of                                 also explicit API is provided by the                                 collections API that lets you manage                                 this logical topology such as crud                                 operations about around collections                                 replicas and shards creating them                                 splitting them and so on as well as kind                                 of managing your schemas in these                                 collections as well the physical side of                                 the topology this is like dealing around                                 servers solar nodes solar processes this                                 has a far kind of sparser API set so                                 you're able to do a few a little amount                                 of auto scaling which is shuffling                                 replicas or cores across solar nodes as                                 well as a couple explicit commands to                                 the collecting API such as removing a                                 node migrating anode which is migrates                                 all the cores from one solar node to                                 another solar node but in general                                 there's not much there and so when                                 you're running thousands or even just                                 hundreds or dozens of solar clouds doing                                 this physical management of solar clouds                                 can take a lot of time and a lot of                                 energy that you don't really want to                                 spend and so that kind of brings us into                                 the next section of our talk which is                                 kubernetes communities is basically if                                 you haven't heard of it an open source                                 framework that allows for scheduling and                                 operating of processes in a cloud                                 platform a generic cloud platform                                 basically letting you see your set of                                 servers as one giant machine that                                 everything is running on sharing volumes                                 and so on and we'll get into kind of                                 what is communities in a little bit but                                 basically you can just see it as a giant                                 machine that you're running at all your                                 things on and a kind of permeated                                 throughout the industry                                 all the major cloud providers can                                 support it natively as well as kind of                                 provide custom interfaces within it to                                 make the experience better it's kind of                                 important to mention that in kubernetes                                 applications are run in a declarative                                 fashion meaning you give some set of                                 configuration telling humidities what                                 you want your what you want it to run                                 and then kubernetes makes that state                                 happen but as kind of a long side that                                 there's kind of ways that you can have                                 automated processes that manipulate this                                 set of configuration as well which kind                                 of adds a lot of power within                                 communities and lets us do things such                                 as manage solar cloud within it and                                 we'll get to that later                                 so just kind of establishing some                                 terminology this technology we like to                                 overload terms there's two terms here                                 that are used within communities and                                 Sylla that I kind of want to get out                                 there so node node is used in both solar                                 in communities and solar I've used it a                                 couple times already                                 it means it's a solar solar cloud                                 process that is running and connected to                                 zookeeper it can house cores issue quit                                 I respond to queries and indexing but in                                 kubernetes that means I'm very different                                 this just means a like a server or a                                 virtual machine that is running within a                                 coop and East Network replicas is a                                 little more similar between the two and                                 solar we've already kind of define it if                                 a copy of one charge the data that                                 houses the solar core but in kubernetes                                 it means an instantiated in session Stan                                 Shi ation of a pod specification and                                 we'll kind of get into what that means                                 in a little bit so I'm gonna kind of                                 give you a kind of introduction to                                 kubernetes and the things you can do in                                 it we're going to start with the                                 low-level kind of objects that you can                                 create and see how they all build up on                                 top of each other so I'm assuming a                                 lobby I'll have used containerized                                 services in the past containers such as                                 docker just kind of a way of isolating                                 an environment and running a process                                 within an isolated environment it helps                                 you kind of tell what your dependencies                                 are load them in beforehand to make sure                                 that even no matter what is running on                                 your server you can make sure that the                                 correct things are running for your                                 application within this docker container                                 pods are kind of an abstraction on top                                 of containers and manage a lot of the                                 networking volume or like data                                 management around them as well as kind                                 of help make a consistent interface                                 depending on what kind of container                                 using be it dock or be it rocket be any                                 of the other ones and so basically it                                 also lets you add health checks and to                                 make sure that no matter what kind of                                 container you're running within your pod                                 it has a kind of standard way of knowing                                 whether that container is healthy                                 whether it died any of these common                                 operations so that's nice but whenever                                 you're running lots of these pods are                                 lots these containers you want to make                                 sure that if your pod dies it comes back                                 you don't want to just have to manually                                 listen to see oh my application stopped                                 working let me go and spin that back up                                 again                                 replica sets of the way that kubernetes                                 kind of allows you to build an resilient                                 resiliency around pods so that you can                                 make sure that in of in set of your pods                                 are running at any given time so                                 whenever say a pod dies or goes whenever                                 a pod dies you guys down                                 then the pod is deleted the replica set                                 will make sure that a new pod is                                 scheduled and ran whenever that happens                                 so at any given time you can expect say                                 six of your pods to be running so that's                                 nice however it doesn't really do                                 everything you want say you want to                                 upgrade your pod to run a new version of                                 your software you don't want to just                                 upgrade at all though your pods at the                                 same time you want to upgrade in a very                                 safe fashion say a rolling upgrade                                 deployments are a way that cube minis                                 lets you do this it basically manages                                 replica sets as you can see we're just                                 kind of building on top of each other                                 here replica sets manage pods                                 deployments manage replica sets and so                                 it will spin up whenever you want to                                 deploy a new version of your application                                 deployments will spin up a new replica                                 set and very safely                                 delete and add one by one from these                                 repla sets so at first it'll start to                                 bring up a new pod in the new version of                                 your replica set and bring down one pot                                 in previous version if that doesn't work                                 it the upgrade will stop and you'll                                 still have two pods available in your                                 previous repla set however if it does                                 work                                 the deployment won't continue trying to                                 increase the amount of new pods you have                                 and decrease the amount of old pods so                                 that your upgrade works kind of                                 flawlessly seamlessly and so you don't                                 really have to manage anything about                                 making sure your upgrades are safe and                                 reliable and kind of the thing to note                                 here is that even though the old replica                                 set no longer has any running pods                                 crewman Hayes will keep it around just                                 in case you want to rollback versions if                                 something bad happened in your new kind                                 of software upgrade so that's nice we                                 can now kind of consistently run manage                                 applications in a safe and consistent                                 way however while kubernetes gives us                                 kind of like nice tooling around this                                 kubernetes it's not a fix-all solution                                 for all of your problems there are kind                                 of give and takes and networking is one                                 of those big give you one of the give or                                 takes and so basically networking is not                                 necessarily easier within kubernetes and                                 outside of communities and so services                                 are one way which kubernetes has kind of                                 try to introduce basic networking within                                 this framework so as you see before we                                 have our deployment which maps to a                                 replica set which isn't shown and that's                                 eventually mapped pods services are a                                 way of kind of letting pods be                                 addressable so you have all these                                 applications running say that they're                                 HTTP servers you want to be able to                                 reach these pods from other pods and in                                 kubernetes due to security reasons pods                                 aren't addressable you're aren't able to                                 just reach a pod directly you have to go                                 through something that's called a                                 service and so basically services are                                 there just to provide a mapping from a                                 DNS namespace a DNS or a IP address to a                                 set of pods                                 services are given and mapping of pod                                 like a pod selector which basically                                 tells you which podsnap - it doesn't                                 have to go through deployments you can                                 just be running your own individual pods                                 and services will still work with it we                                 just managed it be a deployments because                                 that's generally what's done and so                                 basically you can also create another                                 pod selector give with a new service                                 service B that overlaps with some of the                                 existing pods that are mapped to be a                                 service a this is very useful as we'll                                 see later in the presentation when                                 creating our solar cloud but the                                 important thing here is that pods can be                                 pods are making me map to buy multiple                                 services no services one service they                                 don't really care the services work on a                                 different layer and just provide basic                                 networking however services only really                                 work within a Cooper Nettie's cluster so                                 a client traffic cannot really hit                                 services from outside the cluster this                                 isn't always true you can use load                                 balancing services but this kind of is                                 dependent on the cloud provider that you                                 run kubernetes in and if you run it on                                 bare metal hardware it doesn't really                                 work as well so there's another product                                 that communities kind of offers which is                                 ingress --is and ingresses are a another                                 application that's running inside                                 kubernetes and listens to client traffic                                 coming from outside communities and once                                 the client traffic hits this ingress                                 controller you have defined rules on how                                 to route that traffic it's an important                                 note ingress is only work with HTTP                                 traffic they don't work with based TCP                                 or any of the other standards and so you                                 get kind of because it's HTTP you can do                                 kind of complex routing you can do                                 routing based on hostname so host                                      not routed to service a host                                             to service B or you can do a path level                                 routing so host the reason that to                                 anything you start looking at the path                                 and we see that API v                                                    service a so much like services ingress                                 rules can map to multiple services or no                                 services but basically you have to                                 provide a service for ingress - ow - you                                 can't just provide                                 pods because now all networking within                                 communities has to go through services                                 so I guess the question here is we have                                 all these pieces of infrastructure that                                 kubernetes provides us can we build a                                 solar cloud with these pieces and once                                 we start thinking about that as a few                                 issues start to come up solar nodes or                                 we'd be running them in communities pods                                 have data that is unique to them this is                                 not just the Scylla cores that they're                                 running even though that is unique to                                 them and needs to be stored persistently                                 they have a unique name and address                                 whenever you search little cloud up in                                 zookeeper it's so it stores its kind of                                 the address to locate it and the name                                 that's running under and whenever it                                 restarts it needs to have a consistent                                 name and address for the other nodes in                                 your solar cloud to be able to                                 communicate with it                                 and so the name and address and solar                                 cores that are running I kind of need to                                 be persisted through outages through pod                                 restarts through any of these things                                 I mean having any of them change                                 whenever the pod research does kind of                                 break solar cloud so how are we gonna                                 deal with that so there's a couple of                                 rooms for improvement with kubernetes                                 running stateful applications and the                                 workflow that we've defined already with                                 these deployments the replica sets these                                 services they work very well with                                 stateless applications and you can think                                 of the solar prometheus exporter as one                                 of these things which just basically                                 runs one pod and it queries solar                                 metrics and queries it's other things in                                 exports such Prometheus as you can see                                 that doesn't have any state associated                                 with it it's very easy to run via                                 deployments but these deployments were                                 up because that's really do have issues                                 with the things that we're talking about                                 before which are data persistence and                                 locality kind of consistent naming                                 through pot restarts and kind of                                 consistent addressability as well so                                 what does communities provide us to be                                 able to deal with these problems                                 persistent data has a story in Cuban ace                                 the story is not perfect but it exists                                 there are persistent volumes                                 so if you've used docker docker has                                 volumes that you mountain as directories                                 or other environment variables and                                 docker                                 I mean communities does have a way of                                 kind of managing this they have                                 persistent volumes which are a way of                                 staying storing persistent state and                                 there's a lot of different providers of                                 these there's ones that are just storing                                 local data on your box and on your                                 server but also as your a DBS all the                                 big cloud providers have created their                                 own persistent volumes to be able to use                                 it within their ecosystem other kind of                                 more open source he things such as in FS                                 I think I can't core OS so a couple                                 other ones have their own persistent                                 volume well as well but they all kind of                                 implement this base persistent volume                                 interface that kubernetes can make specs                                 and a persistent volume claim is kind of                                 coupled with this so a persistent volume                                 claim let's something within kubernetes                                 basically asked for a persistent volume                                 resource and kubernetes will then find a                                 persistent volume that has been                                 registered in the same kubernetes                                 cluster and kind of link it to that                                 persistent volume claim so that when a                                 pod that uses that claim restarts and                                 when he comes back up the persistent                                 volume will still be there and be able                                 to kind of be added back onto the pod                                 once it's restarted so how is this used                                 so staple sets are kind of a reimagining                                 of replica sets replica sets were ways                                 of managing in replicas of the pod                                 specification staples has to do the same                                 thing however staple sets do other                                 things swell                                 they now kind of have a standard pod                                 naming structure so that whenever a pod                                 goes down and gets deleted it comes back                                 up with the same name which is very                                 important for things like solar where we                                 need consistent naming and addressing                                 through out pod restarts and kind of                                 additional upgrades and stuff and these                                 persistent volume claims are then now                                 set up natively with stateful sets so                                 that we you pass when you pass in the                                 pod specification that you want to run                                 you also pass in a persistent volume                                 claim that you want to                                 alongside these pods and so as you can                                 see you're here a pod                                 a persistent volume claim is linked to                                 each pod and so whenever our pod went                                 down earlier the persistent volume claim                                 didn't get deleted alongside it it                                 stayed and it's a link to the persistent                                 volume that kubernetes gave it so that                                 when the pod comes back up you can see                                 that has not lost its data our solar                                 cores are still there and they're still                                 be able to be indexed which is nice                                 headless services are okay so we've kind                                 of dealt with these deployments of these                                 staple services having data associated                                 with these stateless services now we                                 kind of have to deal with the networking                                 part of it so headless services are a                                 way that communities has allowed these                                 stateful applications to be able to                                 individually address solar PAH I'm                                 miserable applause terminate these pods                                 within these staple sets so whenever you                                 have a headless service it gives a                                 different host name for each pod in the                                 staple set this is just kind of services                                 manipulating the dns to just add entries                                 for each pod and so whenever the solar                                 pod restarts since the pod has a                                 consistent name the address for that pod                                 will stay the same since it's just the                                 pod named service name name space so at                                 this point we have kind of consistent                                 addressability consistent naming and                                 persistent volumes persistent storage                                 that solar kind of can work more                                 natively with kubernetes and but this                                 does kind of introduce limitation                                 headless services do have limitations                                 associated with them and they don't work                                 with ingress is for one so it doesn't                                 really help us get data from outside of                                 kubernetes back into the kubernetes                                 cluster and they can't also be use of                                 load balancing which is another way of                                 getting services addressed outside of                                 the communities cluster so if we want to                                 run our communities I mean our solar                                 cloud safer in to close community                                 clusters or address our solar cloud                                 nodes individually from outside the                                 community lustre headless services don't                                 really help us very much so and why is                                 this really needed why do we need to run                                 sort of clouds across kubernetes or have                                 clients access it from outside of                                 kubernetes one you won't be able to have                                 rollouts of every piece of your                                 infrastructure and so if you want to                                 have upgrade your kubernetes cluster                                 communities kind of plays a new update                                 every six months usually a big major                                 release and so it's kind of fairly                                 common to see yourself upgrade you know                                 a kubernetes cluster and so if you want                                 to kind of have a staged rollout you                                 need to be able to have multiple                                 kubernetes clusters running your solar                                 applications and you want to have these                                 solar clouds run kind of into the same                                 solar cloud run into different                                 kubernetes clusters talking across them                                 on these staged rollouts don't just                                 include kubernetes they include other                                 pieces of software running in companies                                 and so we're gonna introduce the solar                                 operator later and whenever you're using                                 the solar operator to manage your solar                                 clouds you want to be able to do a                                 staged rollout a set of that as well                                 which also requires multiple kubernetes                                 clusters running multiple solar                                 operators and in general your                                 applications aren't necessarily going to                                 be running the same so a community                                 cluster that your solar clouds are                                 running in and so if you want to use                                 things that's just a solar Jake client                                 I'm sure PI solar has similar                                 capabilities but generally being able to                                 address nodes individual nodes from                                 outside the communities cluster we're                                 not gonna be able to use these headless                                 services so what can we do there's two                                 different ways we can do this but in                                 general the solution is unfortunately                                 you just need to create a separate                                 service for every solar node and we'll                                 kind of explain how this works later but                                 once you have a separate service for                                 every solar node there's two ways to                                 make it addressable from outside we                                 create a load balancer within that                                 service which creates an IP address that                                 Maps digest that individual solar node                                 or we create an ingress which allows for                                 a kind of more complex                                 routing of path and hostname to that                                 solar pod through a common IP address I                                 will say at Bloomberg we kind of prove                                 we like the ingress solution more                                 because we don't like spending up                                 thousands of IP addresses because we run                                 thousands of solar notes within our                                 company                                 so as a because we like ingress more all                                 my solutions will kind of have ingress                                 in there so just that's a caveat and so                                 as you can see here we have our solar                                 cloud running and we have client traffic                                 hitting it from the outside through an                                 ingress these ingress rules then map to                                 different note services we have one                                 common service that routes to all the                                 pods in our solar cloud and then we have                                 individual services that Knapp kind of                                 data and user requests from to an                                 individual pod within solar so the node                                                                                                     these individual node services we can                                 then have the individual pods use the                                 same kind of client request path to end                                 address notes themself so pod                                            if it's doing peer sync with pod                                         go back out to the ingress and have that                                 request routed down to the service and                                 back to down to pod                                                      run solar across multiple kubernetes                                 clusters and it will be able to kind of                                 work natively and talk to pods within                                 its own communities cluster another one                                 and it doesn't really care which one is                                 running in so how have we built the                                 solar cloud in communities as you can                                 see here at the bottom we have a staple                                 set that staple set has four pods                                 running in it these are our four solar                                 cloud pods and then we have a lot of                                 different services these services are                                 one each for all of our solar cloud                                 nodes as well as one common endpoint for                                 all of our nodes together and then a                                 headless service that isn't really used                                 for much at the bottom we have an                                 ingress oh and this ingress has multiple                                 hosts associated with it on the                                 basically the common service of the                                 common solar cloud host as well as                                 individual node hosts as well this is                                 how we route traffic into the kubernetes                                 cluster and into our individual solar                                 nodes so running all these things kind                                 of lets us build a solar cloud within                                 kubernetes however managing all of these                                 different                                 objects can become cumbersome and as I                                 mentioned before we run thousands of                                 solar clouds we don't want to have to go                                 and manually create these staple sets                                 may nearly create these services these                                 in grasses and so on and have a whole                                 management system for that we want                                 communities to be able to do that for us                                 and so communities has these objects                                 called custom researched                                 custom research definitions which allow                                 you to create objects within communities                                 as if they were native to communities                                 such as deployment services staple sets                                 etc and so these custom objects and                                 communities can be anything they can be                                 solar zookeeper Kafka anything we want                                 to create and then controllers are                                 applications that are built on top of                                 these custom resources that allow you to                                 kind of listen to the API server and                                 kubernetes for changes in different like                                 kind of updates creations deletions                                 different operations on instantiation of                                 this custom resource definition and then                                 the controllers they can manipulate the                                 other communities objects to make that                                 state happen so say we have a solar                                 cloud specification the controller would                                 then make sure that all of these things                                 have been created once that kind of CRD                                 has been pushed kubernetes pause so you                                 can take okay so operators are nothing                                 more than just a grouping of controllers                                 they allow for a common kind of actions                                 on a set of technologies so for example                                 solar cloud the silikal operator would                                 have a so a cloud controller a solar                                 cloud backup controller a restoring                                 controller these are just kind of the                                 common operations and other technologies                                 have more kind of technology specific                                 actions associated with them so this                                 specification that we've been talking                                 about the solar cloud resource that                                 we've created has a more simple                                 specification than some of the more                                 mature customer resources out there but                                 there's more in there but kind of taking                                 out the kind of unimportant things and                                 left the ones that are really important                                 basically the main things you need to                                 run solar are the number of solar nodes                                 that you want to run the version of solo                                 that you want to run and                                 as you can see we're just using the                                 default docker solar container that's                                 published in the most recent version and                                 then a zookeeper to connect to the solar                                 cloud operator can create you a                                 zookeeper in the cluster dynamically if                                 you want it to but it's kind of nice to                                 have an external zookeeper that you know                                 is going to be there and reliable that's                                 not running in the same kind of                                 cholesterol or cloud is and so here we                                 pass it an external connection string as                                 well as the CH fruit that we want solar                                 cloud to connect to once this is done so                                 cloud will create the objects of objects                                 that we talked about earlier and return                                 back as status so CRD use have both the                                 specification and a status                                 so once the CRD is created it will                                 basically populate the status section it                                 will tell you how to connect to the                                 solar cloud via maybe zookeeper at the                                 bottom or just a URL at the top as well                                 as the solar nodes that are running and                                 the versions that they're running the                                 status of the solar nodes as well as                                 individual connection strings for those                                 nodes and as you see here at the bottom                                 this cloud is currently doing an upgrade                                 from solar eight point one point zero to                                 eight point one point one and the status                                 section will kind of tell you this                                 status of the nodes through the upgrade                                 and so we have one node that has been                                 upgraded one note that hasn't been                                 updated yet and it seems to be working                                 since the node that is upgraded it's                                 currently ready so soon the last one                                 will be upgraded so I guess kind of                                 finally we've created this little cloud                                 operator it's recently published as open                                 source we finally got it out this last                                 Friday so the builds are not necessarily                                 working but the codes out there would                                 love contributions basically we want                                 this to be the way that Bloomberg runs                                 solar cloud in the future and that have                                 a lot of companies that manage a lot of                                 solar clouds run in the future these                                 slides will be published at some point                                 and if you search Solar operator this                                 not a whole lot out there and I think                                 this is one of the top results so we                                 want as many contributions as possible                                 Bloomberg is kind of big into making                                 open-source things so that we kind of                                 should be the key to the community and                                 that everyone can have kind of the best                                 way to run solar as possible so what is                                 kind of the future of this project                                 there's kind of a lot of things that we                                 need to do the data persistent is the                                 data persistence is there but in general                                 we don't have a good story around it we                                 haven't done a whole lot of testing                                 around the local persistent volumes                                 which are still kind of in their infancy                                 in kubernetes and we haven't done a                                 whole lot of testing around the remote                                 storage capabilities that will                                 definitely be something that we start                                 looking into the summer as we run more                                 things in communities within Bloomberg                                 there's additional operator                                 functionality that we need such as                                 backup and restoring which we're                                 definitely gonna get around to this                                 month and basically a lot of the                                 different operators around there have                                 backup restore capabilities that we kind                                 of want to build a naval it natively to                                 the solar cloud operator and we also                                 want metrics to be provided kind of as                                 easily as possible so spinning up a                                 deployment of the Prometheus exporter                                 would be awesome to do a long cities                                 cloud we just need to kind of get that                                 in there so that's basically what we're                                 doing and what we've done give any                                 questions                                 [Applause]                                 hi okay when you were talking about the                                 ingress rules have you guys tried doing                                 any routing based on collection name at                                 the ingress rule level for like queries                                 and updates going directly to the                                 correct node a lot of running here so no                                 we have not currently done anything                                 around that that'd be saying that I                                 would                                                                  be awesome to add to the operator the we                                 have been working around some other                                 things but this is open source so please                                 help us if you want to have that in                                 there thank you                                 so you mentioned situations where our                                 server dies or a pod dies or stuff like                                 that but how do you tackle situations                                 where the the service is not really dead                                 so it just has like some issues it                                 responds badly it's it's taking long a                                 long time to respond it behaves                                 unnaturally and these situations are                                 more difficult to detect and they there                                 are situation where you actually need to                                 kill the server and to start on a drone                                 and whoever wants to ask a question next                                 should go right here that's a very good                                 question and I agree a hundred percent                                 there's a lot of issues with solar that                                 isn't solar dies and these things are                                 like om in garbage collection issues it                                 can't connect to zookeeper these kind of                                 things on the solar I mean the go back                                 here the kind of POD specification lets                                 you define different health checks and                                 status checks so these be                                 different things and so you can define                                 health checks for your pods to say that                                 if these things don't respond in the way                                 that I want them to kill the pod but                                 there's other things such as status                                 check so if the I don't I'm not an                                 expert in communities let me start with                                 this so if any of you all have                                 Corrections I will take them so you can                                 define like kind of more granular things                                 there so if the pods don't respond in a                                 certain way also kill the pod it's not                                 just like if this HCP endpoint is                                 available keep it up in life there's a                                 lot more things you can do around that                                 and I think given the different versions                                 of solar solar                                                       check Handler than solar                                              where it actually checks whether it's                                 connected to zookeeper in these                                 different things if the course already                                 and so there's different things that we                                 can build into the operator and                                 different ways that we can manage this                                 health hopefully that answer                                 okay I'm gonna give you two questions                                 and you can answer either or both or                                 whatever you want one is just about                                 scaling limits if you've run into any or                                 if you know like how big can you make                                 each thing and then the other question                                 is about if you've done anything about                                 schema updates you know you need to                                 reenacts your whole cluster do you                                 provide any support for that in the                                 operator so um that thing blinded me I                                 forgot a lot but um the first question I                                 ll enter the second question for schema                                 updates and having to rien to cure data                                 I'm not I think that there's some cheer                                 tickets out there to make it better in                                 solar itself there's not a whole lot                                 that the operator does for you there                                 because this is it's more of a kind of                                 logical topology management - similar as                                 the operators more the physical side of                                 actually kind of managing your nodes                                 your processes not the schemas within                                 that's not saying that we can't build it                                 in there it's just not something that's                                 currently there and this is once again                                 in its infancy we want to make it a lot                                 more powerful and solve a lot more                                 problems and I now remember the first                                 question scale um so we've run solar                                 clouds we haven't done like a whole lot                                 of scaling with our operator but I know                                 that we've run within two to kubernetes                                 clusters                                                                same cloud so                                                            than we run and not far more that's                                 basically what we top out at Bloomberg                                 right now so I know there's more of                                 y'all that run thousands so nodes in a                                 cloud and hopefully you can help us test                                 that but I'm not sure how he'll do                                 hopefully well                                 you mentioned on the last slide that the                                 like potential audit remote storage                                 might potentially be too slow which type                                 of storage do you currently use because                                 like what we noticed briefly scene based                                 application on top of Amazon is that                                 they work really really fast if you use                                 locally SSDs as soon as we one like a                                 remote filesystem or something like this                                 performance is completely like one order                                 of magnitude Wells or something like                                 this so yeah the reason I put the local                                 persistent volumes in there before the                                 remote storage is because we currently                                 use local persistent volumes in general                                 they're not really implemented very well                                 in kubernetes right now I think they got                                 in in the last two releases so they're                                 pretty beta at this point and we have                                 not done any remote storage yet that I                                 think we're kind of looking to do that                                 for the backup and restoring right now                                 but in the future I don't see I don't                                 think that we're gonna be running with                                 anything other than local persistent                                 volumes because I mean if you're using                                 solo you want it to be pretty fast                                 probably we haven't done any testing                                 with remote storage yet we probably will                                 but I'm not expecting very much out of                                 it there any particular versions of                                 solar that this would depend on or are                                 there any upcoming features in solar                                 that would benefit this as I mentioned                                 before the like solar has a better kind                                 of liveness check in solar aid and                                 beyond but I think this works with any                                 of the docker containers currently                                 published which i think is solar                                     something on I might be wrong with that                                 another some                                                           run it currently                                                      that it works with those I think solar                                   has better liveness as I said before but                                 I'm not sure that there I've not seen                                 any features that kind of directly                                 contribute to this but I'm I might be                                 wrong there thank you                                 [Applause]
YouTube URL: https://www.youtube.com/watch?v=XUnYvmAeeNU


