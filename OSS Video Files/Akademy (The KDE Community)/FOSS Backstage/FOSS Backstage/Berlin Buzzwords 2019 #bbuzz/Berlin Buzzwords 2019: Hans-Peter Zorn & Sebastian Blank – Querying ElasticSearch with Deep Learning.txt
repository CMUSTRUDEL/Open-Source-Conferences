Title: Berlin Buzzwords 2019: Hans-Peter Zorn & Sebastian Blank â€“ Querying ElasticSearch with Deep Learning
Publication date: 2019-06-20
Playlist: Berlin Buzzwords 2019 #bbuzz
Description: 
	Hans-Peter Zorn and Sebastian Blank talking about "Querying Elasticsearch with Deep Learning to Answer Natural Language Questions "

Natural language is gaining more and more relevance as an interface between man and machine. Already today, we are able to carry out simple task by talking to our smartphone or smart speaker, like Google Home or Alexa. An important challenge for any kind of dialog agent or chatbot is to include external knowledge into the conversation with the user. 

Therefore, such systems need to be able to interact with resources like relational databases or unstructured resources, like search engines. However, the complexity of natural language makes it hard to capture diverse utterances with a set pre-defined rules. Instead, we present an approach that leverages Deep Learning to learn how to query an ElasticSearch given natural language questions. As our model learns to follow the inherent logic of querying, it is even possible to switch to other systems and query languages. This carries a great potential for future applications of ElasticSearch and related NoSQL solutions.

Read more:
https://2019.berlinbuzzwords.de/19/session/querying-elasticsearch-deep-learning-answer-natural-language-questions

About Hans-Peter Zorn:
https://2019.berlinbuzzwords.de/users/hans-peter-zorn

About Sebastian Blank:
https://2019.berlinbuzzwords.de/users/sebastian-blank

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              welcome my name is Hans Peter and we                               will talk about                               and the master thesis of Sebastian who                               were later on in the second part give                               you all the technical details while I                               will just blah blah and this thesis was                               only possible because we had two more                               advisers one of them is dr. Floyd                               William our principal data side instance                                in effects and office our retina from                                the Cosmo Institute of Technology who is                                now into you                                so what is this about                                so yeah what's so just suspecting that                                the battery is low what why did we do                                that                                so basically voice control interaction                                my voice today is used by almost                                everyone this is for me very exciting                                because I was working in dialog systems                                                                                                  didn't work at all and it's really nice                                to have all those devices and people                                interacting by voice for us we had a                                very special use case we had in mind                                which was our vision which is not what                                we saw FTEs but what war where we want                                to go we have an internal interpreter                                children at our company and we have a                                chat systems and we would like to have                                to make it possible to ask questions                                about facts in our enterprise Northwest                                company for example                                which employees to know about Apache                                spark or which projects did we use sulla                                in yet until now so these kinds of                                questions go beyond that what often as                                part of such birth control system black                                cop it goes beyond the typical comments                                like in the actions like Alexa switch                                the light on or okay google play my bad                                mood playlist or turn on the air                                conditioning - but you need to answer                                factual questions and so we the answers                                to questions like this is usually hidden                                behind a barrier behind a query language                                or an API so usually the vast majority                                of the public population doesn't speak                                ask well natively so we can't really                                existed by excess dust content of                                information hierarchy and our goal was                                to build to use machine learning machine                                learning or in particular deep learning                                to overcome this barrier to build the                                models of basically translate translate                                between natural language and such query                                languages so there are two possibilities                                to do that one we call hot lookup and                                one we are we were called soft look up                                what is hard look up with heart raka we                                basically build a machine learning model                                that acts as a directions later between                                natural language and the query language                                so we have Google                                late that translates between English and                                German and we have similar model that                                translate between trimmed and secret or                                elastic search query API that sounds                                feasible because such models exist but                                the problem here is that the trimble is                                not and to end trainable it's not what                                do I mean by that                                usually in machine learning you need                                training data by now everyone know that                                the more they there the better and for                                that kind of amalah we would like to                                train with samples of a question and the                                corresponding answer but we can't build                                such a model and train it because this                                database is in p in between and we can't                                integrate the database into our model so                                it's not differentiable and this way not                                and to end trainable so what we need to                                do is we need to create another data set                                - that s consists of the question and                                the corresponding query and that usually                                doesn't exist we need to create it and                                that is costly there are these the                                second option how to solve this problem                                is so called soft look up which is a                                soft lock that we basically build a                                model that contains all the information                                so we have somehow transfer the                                information from the database into a                                mathematical model into a deep learning                                model and we can do that by really                                putting all the columns in there or                                train it on the on the pairs and then                                the informations effects they are                                 basically cells in this smaller for                                 example memory networks work like that                                 and what the model learns then is                                 basically a mathematical function that                                 maps from the question to effect but                                 that s has some drawbacks first of all                                 you need a lot of training data to do                                 that again but the problem is all the                                 information must fit into the into the                                 deep learning model and that it's                                 usually in the in the main memory and if                                 you have a nice database containing all                                 the effects why do you want to transfer                                 it from the database into your brother                                 and the other thing is it's hard to                                 interpret it as I said it's basically a                                 probability distribution so it's                                 basically that says the answer is X but                                 the probability is high that this                                 question addressed to this fact                                 so that's downside of those soft look up                                 models so the hard lookup looks nice                                 because it is also in a principle like                                 we know to look at such a query                                 statement and understand what it means                                 and why this query probably what returns                                 wrong answer so we can better understand                                 it we have much more capacity and that's                                 why our approach was to find a solution                                 to make the heart lock up and to end                                 trainable and that's what Sebastian will                                 talk about okay thanks do you hear me I                                 think so                                 yeah unless the title says we are using                                 deep learning so we are using neural                                 network Steve mural networks and                                 and I'll pee you will often see this                                 four-step framework which has first you                                 embed the inputs then you encode you                                 attend then you predict and within the                                 next slides I will give you a brief idea                                 how this works and then how we used it                                 so embedding means that we you can                                 imagine a neural network as a very                                 complex function and somehow we are                                 working with words but we need to turn                                 them into numerical values so that's                                 what embedding do and the previous talk                                 I understood it that way that they used                                 tf-idf which is something different word                                 embeddings are trained on large corpora                                 so this for example were to vector there                                 is globe from Stanford University and                                 they trained it for example on Wikipedia                                 to extract a vector pervert                                 so these embeddings typically you have                                 dimensions                                                             what you see here is a artificial a                                 fictional                                                           words where we have a question who was                                 the writer of the move true lies and                                 each dot in this diagram would represent                                 one word which is defined by two                                 coordinates the word who represented by                                 the green dot would locate in the upper                                 left and the word rider in the lower                                 right and one assumption or one finding                                 in the research of word embeddings was                                 that they are able to capture certain                                 relationships in natural language                                 because they are trained on the                                 objective to group similarities in the                                 same areas and as you can imagine with                                                                                                          type of relationships so for example we                                 assume that the word writer would be                                 close to the word author in this vector                                 space in the original papers they also                                 stated that you for example can see that                                 gender relations can be found and so on                                 so at the end                                 this face each word is represented by                                 one vector so the next step we use a                                 recurrent neural network more                                 specifically a lsdm along shorter memory                                 network to transform these vectors                                 pervert into a one vector per sequence                                 per question representation so this blue                                 box in the end is somehow related to the                                 dots you saw on the previous slide so                                 this is the vector that represents our                                 question who was the writer of true lies                                 and which is yeah computed by our                                 encoder I don't go into more detail here                                 there's a lot of cool stuff in the web                                 which you can check out if you are                                 interested this vector representation is                                 then passed to the decoder so you see                                 one decoder cell here which is designed                                 to predict words so you just see one                                 word here but theoretically it predicts                                 word by word step by step and uses as                                 its input this context vector we created                                 in the previous step and if you imagine                                 that you would need to summarize a news                                 article then this context vector would                                 be corresponding to your intuition after                                 you read the article for the first time                                 as soon as you want to write your                                 summary you would then refer back to the                                 original article read another line or                                 you highlighted something and so on and                                 use this in combination with your basic                                 intuition of what the news article is                                 about to write your summary and this was                                 the vague idea of what is known as                                 attention attention mechanisms in yeah                                 deep learning and again in the previous                                 talk the both people spoke about bird                                 which is a system or a system trained on                                 transformers which are only built on                                 attention so this is big big trend in                                 the deep learning community at the                                 moment so now we are at the state that                                 our model predicted one token we had our                                 question this is our model like from the                                 previous slides and will predict                                 multiple tokens to fill this query                                 template so we used in our experiments                                 we used elastic search and we designed                                 that way that we capture three fields                                 the most important is the query                                 condition which captures the entity of                                 the question so the question was who was                                 the writer of true lies and we with our                                 model will predict the start and end                                 token of this entity so we can handle                                 entities of different lengths the query                                 field is then used to identify which                                 category this entity belongs to so here                                 true lies as a movie title and in the                                 end the response field predict or                                 captures which category we want to                                 retrieve from our elastic search and to                                 perform this prediction our model has                                 access to a vocabulary which is defined                                 by some by the database categories and                                 by the tokens from our input questions                                 and that's why it's able to predict                                 these tokens we then operate this query                                 we're an interface on the elastic search                                 which returns a response but a sense                                 Peter discussed earlier we can't train                                 directly on this feedback because it's                                 not differentiable and there is                                 workaround when you use reinforcement                                 learning again that's a big topic at the                                 moment and I won't go into details here                                 but to give you a quick idea how we did                                 it is we provided rewards so like little                                 imagine a crown crowd worker who would                                 do this work and he would gain different                                 money or different rewards financial                                 rewards choose solve the task so if he                                 produces invalid queries he would need                                 to pay                                 two euros for example and will you find                                 invalid queries in that way that it                                 either causes an error or that the                                 database response is empty so no result                                 was retrieved furthermore he would need                                 to pay                                                               query but the result was wrong so                                 further before the movie who was the                                 writer of True Lies when he would                                 retrieve a year or another direct a                                 movie writer then the model would get a                                 penalty on this performance and finally                                 what we are looking for is valid queries                                 with correct results and in our initial                                 experiments we provide a small positive                                 reward plus one and as you can see with                                 the star we varied that in our                                 experiments because we found that it had                                 quite an quite a big impact on the                                 results we found so we evaluated our                                 model on the movie dialogue data set                                 which is provided by Facebook which is                                 open source and the data set contains                                 about                                                                    and a database with                                                    and facts about for example the writer                                 the actors and so on and we stored the                                 metadata in the elasticsearch and gave                                 our model access via this interface and                                 now I will show you what we found what                                 we learned during this project so first                                 as I said we found that the very rewards                                 in our experiments because we found that                                 they changed the performance of our                                 system in the beginning with small                                 positive rewards our model always                                 predicted the same kind of career very                                 simple it was kind of a lazy prediction                                 because it tended to predict the major                                 or the the predominant category which                                 was the movie title and one word of the                                 question so for example just the first                                 word and by this it achieved that all                                 almost or queries were valid so                                        the queries                                 valid but it retrieves no correct                                 results at all so that was not what we                                 aim for                                 so we experimented a little around and                                 we found that by increasing the positive                                 rewards for the belt queries and correct                                 results                                                                                     an empirical choice in the end we found                                 that we were able to improve our                                 performance so the share of vary queries                                 was reduced but we were able to score                                 almost                                                             correct results but still after                                 analyzing these results we found ok our                                 model became better at predicting the                                 entities so it varied the lengths                                 depending on the question that was able                                 to handle questions with just one word                                 as the entity for example Titanic or                                 true lies with two words and so on and                                 so on it also identified the                                 corresponding credit category correctly                                 but the output category the output field                                 was still yeah dominated by the major                                 major category in the data set which is                                 why we use the little trick which is                                 called exploration boni and the                                 intuitive idea is that you provide an                                 extra reward extra financial motivation                                 to say to motivate a model to try                                 something new so Exuma that it had                                     predictions and always say okay give me                                 the movie name then we would try provide                                 a little positive reward to say okay if                                 you try two times to receive the genre                                 or the language the movie was in try it                                 out and we'll see if you improve so that                                 was the result from the previous slide                                 from our minus one minus two plus                                 twenty-five rewards without the reward                                 pony and with we reward pony like this                                 motivation to try something new we found                                 that our model improved significantly so                                 we gained a boost of around                                           was really impressive                                 in my opinion and then we thought okay                                 how good can we get a stir awake that we                                 experiment a little more and engineer a                                 little to even improve more but first we                                 checked how good can we get because in                                 the data set we found that natural                                 language for sure is ambiguous it was a                                 yeah we could have gotten this idea                                 earlier because there's this example                                 there are four movies called the three                                 musketeers in the data set so if I would                                 ask you in which year was the movie the                                 three musketeers released and you would                                 have access to this database with                                 information in it I think more people                                 would tend to predict the number that                                 corresponds to the newest movie but                                 still there would be people voting for                                 the other three movies and this                                 ambiguous entities in the data set                                 accounted for about                                                    say okay we said we wanted to stay end                                 to end that's why we used reinforcement                                 learning so we used the question and as                                 the input and eval or provided rewards                                 for our model to learn and that was yeah                                 the thing I was talking about before and                                 we scored eighty four point two percent                                 here and then we checked okay how good                                 can we get if we are not in the entrant                                 setting but we use this intermediate                                 labels which are available doesn't                                 matter how costly they are at the moment                                 because in the data set they weigh array                                 available and we showed that we could                                 score around six percent better so we                                 see that there is this trade-off that if                                 it's possible to use this intermediate                                 label then there is a little improvement                                 but if these are not available because                                 it's too costly to label them then even                                 with only reinforcement learning we can                                 score quite good there is one little                                 problem with the reinforcement learning                                 part these are the result I showed you                                 before and they're they the models                                 achieved these results on the large data                                 sector ninety six thousand questions                                 when we reduced the samples by random                                 sampling to ten ten thousand we found                                 that the intermediate label approach was                                 quite stable but reinforcement learning                                 suffered a lot and yeah the results were                                 not good at all but yeah sure it could                                 be we didn't do much optimizing for                                 reinforcement learning but we start with                                 the same setting so there is still space                                 for improvement with the reinforcement                                 learning algorithm with or a setting at                                 all or maybe it's not possible to score                                 better with reinforcement learning and                                 another aspect that we found                                 reinforcement learning took lay away                                 longer during training so it took twelve                                 hours on the large data set with                                 reinforcement learning and one hour with                                 intermediate labels a certain part of                                 this training time accounts for the                                 interaction with the elasticsearch which                                 we have in the reinforcement learning                                 setting but not in the intermediate                                 level setting where we could do maybe                                 optimize a little by scaling up the                                 elasticsearch and now I want to come                                 back to the point where hans-peter was                                 comparing soft lookup and hard lookup                                 because that's an interesting question                                 as well we compared both system the one                                 is entering trainable by default we only                                 need to input the data base and our                                 approach is entry and trainable with                                 this little hack so these are our                                 results and these were the results that                                 were reported by the paper of touch at                                 all so we have memory networks which are                                 on a competitive level to our system and                                 we have specialized QA system on                                 embeddings that we can approach with our                                 intermediate the intermediate labels                                 system so there is none of these two                                 approaches neither soft lookup nor hard                                 lookup that really outperforms the other                                 in a significant way                                 so it again depends on the problem is it                                 useful to extract a part of your                                 database feed it to the soft look up or                                 is it okay to just use reinforcement                                 learning or if you have two intermediate                                 labels to use this other approach to                                 solve your problem so what did we learn                                 we apply the sequence the sequence                                 approach with a pointer attention to                                 create database queries from natural                                 language question in the beginning we                                 were quite skeptical if that if this                                 would work but in the end it did for it                                 to to a certain degree furthermore we                                 overcame the problem of non                                 differentiability which we didn't                                 thought about before as well and thereby                                 avoided to produce costly intermediate                                 labels and again with the trick of                                 exploration Boni we were able to                                 overcome this lazy behavior of our                                 network to predict just one category at                                 all and sure there is a road to continue                                 we could aim for or we will aim for more                                 complex questions and different corpora                                 at the moment we're really centered or                                 we we're centered around this one data                                 set so we need to try other data sets                                 from different domains even open domain                                 data sets with more complex questions so                                 at the moment we had questions with one                                 entity in them and you can't for the                                 movie domain for example imagine that                                 who was the director of a movie with                                 Bruce Willis from the year                                            language Japanese or in language English                                 furthermore as I described we need to                                 improve to several sample efficiency of                                 reinforcement learning because as you                                 saw with this two data set there was a                                 big decrease and sure we need to work on                                 the latencies of our database                                 interaction or the reinforcement                                 learning interaction with the database                                 to improve and yeah there have been some                                 developments in the NLP community which                                 the previous talk again talked about as                                 well so this bird model seems to provide                                 a nice idea or a nice way to expand our                                 approach and maybe score better and                                 achieve better results and if you want                                 to read more about this talk in a more                                 detailed way or it was information                                 overload I suggest that you have a look                                 at our blog we have a blog post related                                 to this work we submitted the paper on a                                 research conference and now we are happy                                 to take your questions thank you                                 [Applause]                                 [Music]                                 [Applause]                                 question yeah I started with you I was                                 wondering                                 cost-wise did you compare the hard                                 lookup and soft lookup for the                                 infrastructure yeah we didn't implement                                 the soft look up by ourselves so for our                                 approach we used one GPU server or one                                 GPU and took                                                           loop for the soft look up I don't know                                 if the authors of the paper reported                                 these numbers but I can imagine it's                                 quite resource intense as well and it                                 was a Google paper of Facebook paper I                                 think as well so that some resources to                                 train on                                 my question was about your no results                                 queries so you said that you give a                                 penalty for any response that had no                                 results but I imagine a valid question                                 might not have any answerable given the                                 data set so it makes me assume that                                 maybe your data set doesn't have any                                 questions for which the correct answer                                 is empty but I'm so then my follow-up is                                 would that change your approach if you                                 have to handle that in some fundamental                                 way or is it just a difference in the                                 data okay can you repeat the end how do                                 you handle no results queries that are                                 valid in other words ask a question like                                 what movie has me starring as Batman                                 yeah yeah and Yin our model before we                                 predict or while we are predicting the                                 model output somehow a probability                                 distribution as well and you could set                                 the benchmark so if the model is not                                 sure what does me mean and then the                                 distribution goes into the uniform                                 direction so you could say okay if it's                                 below the benchmark and do nothing                                 also we just knew that for this data                                 that there weren't any correct queries                                 with zero results so if you want to                                 generalize that we would remove that                                 penalty which would probably make the                                 model to convert slower because it has                                 fewer information available but it would                                 work and it's a really interesting                                 question if you consider questions where                                 multiple answers may be correct so                                 there's comes with the design of the                                 reward function in the end you can play                                 around there hi                                 I get another question you mentioned                                 that you go boy you're just embedding                                 side did you use protected by things                                 like glove or water break yeah we use                                 below with                                                            trained on the                                                      covers did                                 variations of dimensionality in the                                 beddings and did you observe like                                 difference between different flavors of                                 four buildings at all no so far we just                                 work with the glove embedding but I can                                 imagine that if we use this contextual                                 embeddings like like bird for example                                 then we with yeah thank you I'm curious                                 about the invalid queries that were                                 malformed did you consider gosh the                                 feedback did you consider training your                                 system to have a classifier for such                                 queries to avoid sending them in the                                 first place I just think such as                                 mechanism might work better I think I                                 didn't understand the question                                 acoustically sorry I'll try again the                                 echo or feedback makes it hard I was                                 just wondering if you tried a classifier                                 for detecting malformed queries because                                 it seems to me like a lot of the                                 malformed queries should be classifiable                                 before ever reaching the elasticsearch                                 cedam yeah no we didn't but yeah to put                                 it into production or to develop it                                 further it's definitely necessary I                                 think yeah you could you could do that                                 part of why we did it                                 also because this kind of research the                                 interesting part is that models like                                 this are able to learn for example                                 sequel just by try a trial and error                                 which is fascinating so they are                                 different as a models that learn sequel                                 by using the hospital early as they make                                 errors and that's for a practical case                                 you would probably use some engineering                                 and shortcuts add that stuff but we also                                 wanted to do some research fair enough I                                 just was curious because often times                                 policy networks have helped in these                                 sorts of applications okay                                 your other question here no okay                                 thanks gang I suppose that thanks
YouTube URL: https://www.youtube.com/watch?v=NMG4tMB5T3U


