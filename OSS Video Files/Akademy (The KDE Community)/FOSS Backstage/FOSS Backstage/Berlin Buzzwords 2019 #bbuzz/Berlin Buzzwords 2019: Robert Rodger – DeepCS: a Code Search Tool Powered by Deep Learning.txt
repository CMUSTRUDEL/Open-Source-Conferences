Title: Berlin Buzzwords 2019: Robert Rodger â€“ DeepCS: a Code Search Tool Powered by Deep Learning
Publication date: 2019-06-27
Playlist: Berlin Buzzwords 2019 #bbuzz
Description: 
	The principal difficulty in implementing a code search engine is the difference in syntax between the natural-language query and computer-language target. Because of this, engines based on traditional IR techniques often have difficulty returning relevant code snippets. 

In this talk we discuss DeepCS, presented by Gu et al at ICSE last year, which uses a deep learning based model to map method definitions and their corresponding textual descriptions to nearby locations in the same feature space. In so doing, this system is also able to map natural-language queries to points in this feature space close to relevant code. This deep learning-based technique performs significantly better than Lucene-based systems, and even out-performs the state-of-the-art system CodeHow.

Read more:
https://2019.berlinbuzzwords.de/19/session/deepcs-code-search-tool-powered-deep-learning

About Robert Rodger:
https://2019.berlinbuzzwords.de/users/robert-rodger

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              said is Robert Roger I'm based in                               Amsterdam and I work as a data scientist                               and added in data science and                               engineering consultancy called ago                               data-driven by the way if any of you are                               looking at moving to the Netherlands and                               you'd like to do any work come talk to                               me during the break anyway last year I                               got up on stage here at Berlin buzzwords                                to talk about an idea for using machine                                learning to build database indexes a                                non-traditional technique for a field                                acquainted with the certainties of                                deterministic algorithms this year I'd                                like again to talk about applying                                machine learning in a novel way this                                time in this search base that's not to                                say that machine learning techniques are                                completely unfamiliar to the search                                community for instance machine learning                                models it's behind every learning to                                rank system which re-rank sets of                                documents based on signals drawn from                                the documents themselves and the query                                that prompted the retrieval machine                                learning classifiers are applied to the                                text of user queries to categorize query                                intent and machine learning systems like                                google's ranked brain can completely                                reformulate in frequently encountered                                user queries in such a way that they                                resemble more common queries for which                                your system is much higher confidence in                                its results now all these techniques                                however surround the system which                                creates the internal representation of                                our documents and typically the way we                                do it now with what essentially boils                                down to inverted indexes is a pretty                                reasonable approach even after applying                                query expansion methods or when we want                                to rewrite we eventually end up wanting                                to check for the presence or absence of                                specific words in our document and                                that's exactly what inverted ingesys do                                well but what happens when the query                                language and the language of the                                document are different for instance if                                our query language had been say English                                and our target language say German we                                could at least try the query using                                Google Translate and                                parsing the result using the usual ir                                tooling but what do you do when the                                query language is English while the                                document language is say Java now this                                is the problem of code search more                                concretely say you're in the situation                                where were working at a company and                                there's this big existing code base                                contributed to by over time dozens or                                more devs and you want to avoid                                rewriting some functionality if there's                                already some method that handles it now                                traditionally what you do is you'd ask                                around by the senior devs or by whomever                                had shoulder the sort of archivist role                                or you refer to some internal code                                documentation source but in stitute                                tional knowledge has a nasty habit of                                going on vacation or getting sick or                                moving on to another company and                                documentation needs to be well first of                                all written and thereafter consistently                                updated so even assuming you've got                                excellent documentation coverage and                                it's up to date that remains the problem                                of searching that documentation with                                traditional IR tools for one IR tools                                tend to focus on word presence and                                ignore word order and these tools will                                then fail us when we for instance want                                the method to queue an event on the run                                sorry to be run on the thread and                                instead gets it through the method that                                will run an event on a thread queue for                                another our tools tend not to be aware                                of semantics synonyms so if we query for                                read in and the documentation says parse                                our search system will miss relevant                                hits and lastly ir tools tend to be                                confused by noise so for instance the                                query get the content of an input stream                                as a string using a specified character                                encoding as relevant token specified and                                character which might lead our search                                system to produce false positives so                                let's say then that a best you can treat                                the doc strings of your codebase is a                                 weak search signal how do you then go                                 about finding relevant code snippets                                 well in principle all that you need to                                 know is embedded in the structure and                                 syntax of the code itself the problem is                                 then finding a way to pair the code with                                 a relevant natural language description                                 of what the code does                                 in such a way that our natural language                                 queries can find it and what I want to                                 talk about today one very modern                                 solution to this problem is called deep                                 CS deep CS creates a mathematical                                 representation of both the code and of                                 natural language where both code                                 snippets and English sentences are                                 mapped to vectors in the same vector                                 space in such a way that for instance                                 the vector for the query extract an                                 object from an XML file gets mapped                                 close to the vector of the code doing                                 exactly that now be clear this is not my                                 idea                                 deep CES was designed by a team                                 consisting of gel dong goo and Sung Kim                                 from the Hong Kong University of Science                                 and Technology and Hongzhang from the                                 University of Newcastle in Australia I                                 just think this is a really neat idea                                 and an interesting example of how                                 contemporary machine learning can play a                                 role in search what those of you who                                 attended                                 Jonathas talk yesterday Bal Vespa might                                 have heard it too as search                                         despite the academic origins of this                                 talk I promised a beginner level                                 introduction so this is how I propose we                                 walk through the idea first we'll talk                                 about vector representations of natural                                 language and in particular how we can go                                 from representations for words to                                 representations of documents second                                 we'll talk about how the same idea can                                 be used to create vector representations                                 of code third we'll talk about how we                                 can learn these two representations                                 simultaneously through what's called a                                 joint embedding and what the authors of                                 the paper accomplished in a model they                                 called the code description and                                 embedding neural network or code n N and                                 lastly we'll talk about how these                                 representations can be first trained and                                 then used to perform code search in a                                 system the authors of the paper called                                 deep CS sound good ok now let's get                                 started                                 so let's start with the more familiar                                 bit transforming a bit of text into a                                 vector now as a first approach we could                                 start with a large data set of text                                 examples and make a dictionary using all                                 the unique words we find in a data set                                 and then to prepare our documents                                 mathematically we make a vector for each                                 of our documents where every vector has                                 become                                 opponent for every word in our                                 dictionary say with component for apples                                 somewhere at the beginning and likewise                                 a component for zombie somewhere in near                                 the end and the values that we put in                                 these vector components are then equal                                 to the number of times the corresponding                                 word appears in the document and a                                 particular for word doesn't appear its                                 component is zero and it's not hard to                                 see that by an away the majority of the                                 components in our document vector will                                 be precisely that zero this type of                                 vector is with one with lots of zeros                                 what's called a sparse representation                                 and it turns out that machine learning                                 models when particular deep learning                                 models don't perform particularly well                                 with high dimensional sparse                                 representations and although there are                                 smart tricks we can employ to improve                                 this representation for instance by                                 reducing dimensionality using by                                 removing stop words or regularizing                                 using tf-idf at the end of the day most                                 of the components remain zero and thus                                 the representation remains                                 unsatisfactory so what we instead want                                 is a low dimensional dense                                 representation and five years ago we                                 almost discovered that has been the                                 catalyst for many of the performance                                 improvements we've seen recently an NLP                                 research and as resulting applications                                 it's called word the Veck sure is                                 familiar to many of you in the room but                                 for those of you who are unfamiliar with                                 the details here's how it works we start                                 with the I the observation that although                                 our data exists in some high dimensional                                 space not all of those dimensions are                                 actually required for representing the                                 data so for instance although we live in                                 a three-dimensional world we can                                 describe or each of us is at any moment                                 using only two numbers namely your                                 latitude and longitude to an extremely                                 high accuracy relative to the scale of                                 the planet now work Tyvek implements                                 this idea in the word space it starts                                 with the encoder/decoder model which go                                 to technique for compressing high                                 dimensional data and what this model                                 does is it tries to squeeze high                                 dimensional data into some low                                 dimensional space and then only using                                 that low dimensional representation                                 predict what the high dimension version                                 originally was and then in the                                 traditional supervised machine learning                                 way we start with two ran                                 transformations one for the encoder one                                 for the decoder we've seen an example we                                 calculate the error on the prediction                                 and we use this error to improve each of                                 the transformation slightly we then                                 iterate on this process over and over                                 using lots of data until the error being                                 generated finds the minimum and the                                 resulting low dimensional                                 representations created by the trained                                 encoder transformation can then be used                                 for downstream tasks that's how an                                 encoder decoder model works in general                                 but with word Tyvek the high dimensional                                 representation of our word is one of                                 those vectors which was as big as our                                 dictionary with zeros everywhere except                                 for a                                                                   to our word it's called the one hot                                 encoding and then this is transformed                                 down to a much smaller vector using an                                 encoder decoder like process but then                                 instead of trying to predict the one                                 high encoded vector of the original word                                 we predict the one hot encodings of the                                 words surrounding the original word in                                 the text so for instance if our sentence                                 was I hope no one has fallen asleep in                                 my talk yet if we want to learn a                                 representation of the word asleep we try                                 to predict the words has fallen in and                                 my and moreover while learning these                                 transformations not only do you try to                                 minimize the error and predicting one of                                 the contexts words but he also tried to                                 maximize the error in predicting a                                 handful of additional words chosen at                                 random from the dictionary like                                 trampoline or esophagus and this might                                 sound like a crazy idea but the                                 resulting small dimensional                                 representations of her words were                                 responsible for huge leaps in NLP                                 machine learning performance not the                                 least of which was Google's neural Trank                                 machine translation model ok now that                                 we've got a small dimensional                                 representation of our words how can we                                 make a small dimensional representation                                 of our document                                 now one approach would be simply to take                                 the average of all the individual word                                 vectors in this text but it turns out                                 this doesn't work the best not in the                                 least because the ordering of the                                 underlying words is ignored so for                                 instance the phrase cast into string                                 means something very different from the                                 phrase cache string to int a more                                 sophisticated approach would be to use                                 an ordering aware a machine learning                                 model and this class of models in the                                 deep learning field is called the                                 current neural network these are                                 stateful models so when an input is                                 passed through not only as an output                                 generator vector sorry alpha vector                                 generated but the internal state is                                 updated as well and this internal state                                 is itself just a vector and the idea is                                 that as you pass your inputs through one                                 by one this internal state vector                                 remembers in some sense what is already                                 seen and actually in real deep learning                                 applications the output vector is                                 typically ignored the only thing we care                                 about is the internal state and how that                                 changes ok so how do we then use this                                 hidden memory vector to represent our                                 documents well one approach would be to                                 simply pass the word vectors of our                                 individual words through the recurrent                                 neural network in the same order as                                 their source words are found in the text                                 letting the hidden vector update itself                                 over and over and then use the final                                 version of the hidden vector as is once                                 the word final word vector has been                                 passed through however even though this                                 vector in some sense remembers all of                                 the words in the text especially for                                 long documents this vector only has a                                 very faint memory of the first words                                 that is only the last words are                                 contributing significantly to the value                                 of the final state of the hidden vector                                 alternatively we could make a copy of                                 the hidden vector and after every update                                 sorry make a copy F and then of the                                 hidden vector after every update and                                 then combine them somehow and this is                                 like our previous proposal of simply                                 combining the individual word vectors                                 but now by using the hidden vectors each                                 vectors information not only about the                                 individual words but also the echoes of                                 the words coming just before those words                                 and therefore importantly their order                                 all that remains is to decide on a way                                 of combining the hidden vectors and we                                 might actually be able to get away with                                 simply averaging them but just as we                                 propose to do with the word vectors                                 sorry averaging them just like we                                 propose to do with the word vectors but                                 the authors of the paper did something                                 different called max pooling and what                                 you do is you make a new vector the same                                 size as all of our hidden vectors and                                 set the value of each component equal to                                 the maximum                                 all the values of that component across                                 all hidden vectors here's an example of                                 the result of this process                                 it's from the paper from the same group                                 but preceding the deep cs                                              here code related actions like start a                                 new write operation on the file and                                 remove the old entries of log file that                                 have been converted into vectors these                                 vectors have then been projected down to                                 two dimensions for us in such a way that                                 the spatial relationships between                                 vectors are preserved and we see that                                 natural clusters arise loading and                                 reading actions form on blob as you save                                 write actions and delete remove actions                                 okay that's it for text to recap we                                 start with some large body of text and                                 identify the unique words we use the                                 ordering of those words in the text to                                 learn a small dimensional embedding of                                 the individual words and finally to                                 represent a phrase sentence or entire                                 document we feed its words in order                                 through a recurrent neural network and                                 combine the resulting hidden vectors via                                 max pooling okay now having seen how to                                 make a small dimensional representation                                 of text we'd like to do something                                 similar with our code snippet however                                 there are a few things we need to keep                                 in mind first of all on the surface the                                 variable and class names we use are                                 themselves text but unlike most in most                                 natural languages there's no implied                                 requirement that the word used directly                                 relate to the action being performed or                                 to the role of the object on the other                                 hand despite how we choose to name                                 things the underlying API calls and                                 control flows are completely and                                 unambiguous and noticing that these                                 calls are ordered and that there's only                                 a finite number of them we realize that                                 we can again just build a dictionary of                                 the API calls and train a small                                 dimensional embedding of them much like                                 what we did with work Tyvek so to do so                                 we start with some large collection of                                 code snippets and for each we generate                                 and traverse its abstract syntax tree                                 collecting an ordered sequence of API                                 calls for instance for each constructor                                 invocation new C we append to our                                 sequence the API C new                                 or for each method call om where o is an                                 instance of Class C we append the API                                 call cm similar for loops and other                                 control logic we can append the                                 Constituent API calls in some                                 deterministic way we then look at all of                                 the sequences of all of our code                                 snippets we make a dictionary of all the                                 API calls we find and we assign a                                 Manhattan coding to each API call                                 we then trained and encoder/decoder                                 model to predict for a given one hunting                                 coding of an API call a particular                                 sequence the one hot encoding of its                                 neighboring API calls in that sequence                                 and just like in the text case this                                 results in a small dimensional                                 representation of each API call lastly                                 to obtain a representation of the API                                 sequence of each code snippet we then                                 pass these vectors in order through our                                 current neural network though a                                 different one from that which we use for                                 the text but having the same                                 architecture we collect the generated                                 hidden vectors and aggregate them via                                 max pooling of course there's some                                 flexibility in the order and the choice                                 of the API calls and how we structure                                 the control logic and so this is not                                 completely sufficient to represent the                                 intent behind the code snippet in a                                 general way so to achieve that what the                                 team behind the CS did was to combine                                 the API sequence embedding with the weak                                 signals originating from the text of the                                 code snippet so first we create a                                 representation of the method name                                 what we do is we split the method name                                 into its constituent tokens we have                                 words in word order and therefore we can                                 apply a word to vector techniques by                                 which by now we are familiar along with                                 the third recurrent neural network to                                 generate an embedding vector secondly                                 just to ensure we don't miss any                                 potential signals we take the method                                 body split all the variable and method                                 names into their constituent words apply                                 the familiar bag of Ord tricks we know                                 from information retrieval like deep                                 lubrication natural language stop word                                 removal and code language stop word                                 removal that is removing all the                                 language keywords and then we embed the                                 remaining words and some small                                 dimensional vectors we don't pass these                                 vectors to an RNN so since unlike the                                 method named words and API calls they                                 have no strict or                                 so instead we put them through a normal                                 feed-forward neural network and max pull                                 the resulting vectors so as a concrete                                 example here's some simple code that                                 converts a date into a calendar we have                                 the method name and we break it up into                                 the words - and calendar the API                                 sequence calendar get instance and                                 calendar set time and lastly we have the                                 unique tokens calendar get instance set                                 time and date which have been extracted                                 from the code method body after having                                 chopped the Java keywords final and                                 return now this process leaves us with                                 three separate vectors representing all                                 the signals we can squeeze out from a                                 method definition together though they                                 have more dimensions than the text                                 vectors we'll use to represent queries                                 as the method name alone has this many                                 dimensions so since we want to be able                                 to compare the two vectors they'll have                                 to have the same length and so simply                                 concatenate avec ters if the code method                                 won't work instead as a final step we                                 concatenate the three put them through a                                 feat for all feed-forward neural network                                 whose output layer is the same size as                                 the text vector so in addition to                                 resulting in a vector of the appropriate                                 size as an added benefit this last                                 transmission will also learn to mix the                                 individual signals coming from the                                 method name API calls and method tokens                                 in the most implemented way so that's it                                 for code to recap first we created an                                 embedding vector for the sequence of API                                 calls first by making a small                                 dimensional representation for each of                                 the API calls and then by combining them                                 with the recurrent neural network in max                                 pooling second we create an embedding of                                 the method name by breaking it up into                                 its constituent words and then using                                 work Tyvek another recurrent neural net                                 and max pooling to combine the resulting                                 word vectors we find all the unique word                                 tokens in the method body convert them                                 to their small dimensional                                 representations pass them through a feed                                 for knurled what neural network and max                                 pool the results and finally we mix and                                 down simple the result of three                                 embedding vectors first by concatenating                                 them and lastly by passing this                                 concatenated vector through a fee                                 for know that so now that we have                                 methods both for creating vectors from                                 text and for creating vectors from code                                 how do we learn these transformations in                                 such a way that the vectors representing                                 text describing some action are close to                                 or equal to the vectors representing                                 code that performs those actions now                                 normally training a machine learning                                 model works by providing the model with                                 an input and a lot target output to                                 predict based on that input and if the                                 model doesn't correctly predict this                                 target we use the error between the                                 prediction and target to slightly adjust                                 the internal parameters of the model so                                 that the next time it makes a better                                 prediction but in the embedding case we                                 don't really have a target output for                                 either the natural language                                 transformation model nor the code                                 transformation model instead our target                                 is that the vector for a piece of text                                 describing an action and the vector                                 embedding the code actually performing                                 that action be close to one another if                                 not overlapping to achieve this we use a                                 technique what's called a joint                                 embedding where instead of looking at                                 the output of the natural language and                                 code transformation separately we                                 compare their vector outputs and we seek                                 to minimize the angle between them                                 additionally just like in work Tyvek it                                 turns out that this training procedure                                 works even better if we simultaneously                                 also seek to maximize the angle between                                 the code snippets vector and the vector                                 of some action description that has                                 nothing to do with the action the code                                 is actually performing so it's by                                 optimizing for this combined gold that                                 we simultaneously train or to embeddings                                 and this joint model is what the authors                                 of the paper called the code description                                 embedding neural network or code and                                 then okay so we've got a method for                                 embedding textual description of actions                                 into a small dimensional vector space                                 we've got a method for embedding the                                 associated code definitions into the                                 same small dimensional vector space and                                 we've got a trick for learning both                                 embedding simultaneously and this is a                                 supervised machine learning problem so                                 where's all the training data going to                                 come from now as a demonstration of the                                 feasibility of this idea the                                 team behind code and then developed a                                 system for code search called DPS the                                 system works in three phases                                 the first uses                                                         and their associated docstrings                                 all scrape from github to train both the                                 code and the natural language embeddings                                 this is done once the code and                                 docstrings are then discarded and only                                 the learned transformations are retained                                 this training dataset is purposely quite                                 broad in order to guarantee that the                                 representations learned will also be                                 useful for as yet unseen code bases that                                 is to say yours next you throw away all                                 the code snippets from your code base                                 without docstrings                                 into the system and the previously                                 learned transformations are then used to                                 convert all of these methods into                                 vectors this is done once but you can                                 imagine a situation where code that was                                 touched during the day has its vector                                 representation recalculated at night                                 notice through that this is a relatively                                 cheap operation relative to the training                                 required to learn the original                                 transformations and lastly now that dps                                 is ready for search when a user of the                                 system wants to find a relevant piece of                                 code he or she enters their natural                                 language query into the system deep CS                                 transforms the textual query into a                                 vector performs a search to find the                                 k-nearest code vectors through that                                 natural language query vector and                                 returns the corresponding code snippets                                 to the user in decreasing order of                                 proximity okay so we've talked today                                 about an interesting problem to                                 embedding code snippets and how that can                                 be jointly learned with a text embedding                                 to improve performance on the code                                 search problem now a natural question is                                 of course to ask is this just a nice                                 story or is there really some strength                                 to the idea so as a test the author's                                 scraped almost                                                           have at least                                                            which were included in the training                                 corpus and then they encoded the methods                                 of those projects they then made a                                 benchmark of queries from the top                                    voted Java programming questions on                                 Stack Overflow queries such as                                 generating random integers in a specific                                 range how do I get a platform dependent                                 newline character                                 and removing whitespace from strings                                 they then looked at the ordered search                                 results with those produced by lean                                 leucine bass systems and by Koh Tao                                 which is what the the authors of the                                 paper considered state-of-the-art and                                 found that and both in terms of position                                 of the first relevant result where lower                                 is better and percentage of relevant                                 results in the top end results or higher                                 is better deep CS vastly outperformed                                 its competitors and what this tells me                                 is that there are almost certainly other                                 niche search tasks out there for which                                 using machine learning and joint                                 embeddings will provide a market                                 performance boost over the non embedding                                 techniques used currently rounding up                                 I'd like to thank gyeonggu Hong Yu Jiang                                 and some Hong Kim for their novel idea                                 my employer NGO data-driven for flying                                 me out here and let me speak on company                                 time and you the audience for your                                 attention and now if there's any time                                 for questions I'd be happy to field them                                 thank you very much Robert we'll go                                 first with the questions wondering were                                 there any explorations of how well this                                 would work for languages with code                                 generation capabilities whether they're                                 like really primitive like C's macros or                                 more advanced like Russ macros because                                 Java seems like an easy scenario for                                 this compared to a lot of other                                 languages so the paper is so the                                 proof-of-concept was done in Java in the                                 paper the authors made a mention that                                 they said that this should work in                                 principle for any other language so long                                 as people are using reasonable names for                                 their variables ok we have another                                 question or yeah exactly                                 wonderful talk thank you so much did the                                 authors look at like sort of security                                 analysis like am i calling methods out                                 of order am i violating a contract I                                 mean did they sort of think of that as                                 future work or no                                 yes correlation to commit messages maybe                                 sorry one more time please our                                 correlation                                 did you check any correlation with                                 connect messages messages no that was                                 not done any other interesting question                                 come on I'm gonna count to three one two                                 three okay no more questions thank you                                 again Robert thank you                                 [Applause]
YouTube URL: https://www.youtube.com/watch?v=d50Li6_Npn0


