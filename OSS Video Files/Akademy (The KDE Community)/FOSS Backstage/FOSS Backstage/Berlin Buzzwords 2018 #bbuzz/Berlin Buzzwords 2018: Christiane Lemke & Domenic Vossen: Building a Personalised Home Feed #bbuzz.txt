Title: Berlin Buzzwords 2018: Christiane Lemke & Domenic Vossen: Building a Personalised Home Feed #bbuzz
Publication date: 2018-06-18
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	Christiane Lemke and Domenic Vossen talking about "Building a Personalised Home Feed Using Kafka Streams and Elasticsearch"

At eBay Kleinanzeigen, we aim to inspire our users with a feed of the best items tailored to them. This becomes an interesting problem with more than 20 million monthly users and over 28 million live ads, with thousands of interactions taking place on our platform every second.

Some of the challenges that pop up are how to deal with new visitors, or ones that only visit occasionally. The posted items are often also very short-lived, as many get sold quickly. This requires us to be responsive (near real-time) with respect to our inventory and the usersâ€™ behaviour to help them find a match and be successful.

Technologies such as Kafka Streams and Elasticsearch allow us to approach the problem in a modern, elegant and scalable way, without the need for specialised clusters and long-running overnight batch jobs.

This talk is presented by eBay Tech.

Read more:
https://2018.berlinbuzzwords.de/18/session/building-personalised-home-feed-using-kafka-streams-and-elasticsearch

About Christiane Lemke:
https://2018.berlinbuzzwords.de/users/christiane-lemke

About Domenic Vossen:
https://2018.berlinbuzzwords.de/users/domenic-vossen

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              yep thank you everybody like you said                               I'm Dominic this is Cassie Anna we both                               worked for eBay Clannad saggin and we                               wanted to share quickly before lunch a                               little bit of a story of how we build a                               personalized home feed for eBay kay you                               bake Lana tagging using Kafka streams                               and elasticsearch now first of all for                               those who don't know it I wanted to say                                a few words about eBay climate Zygon it                                looks like this it's the largest c                                  offering here in Germany we have about                                                                                                        have about                                                           given time in our inventory and we're                                still rapidly growing and traditionally                                we've been mainly a search focused                                platform where we cater mostly to the                                people that kind of have an idea of what                                they're looking for they come to our                                site put in a query make use of our                                categories in attribute structure and                                then hopefully find what they're looking                                for we wanted to add a bit of a more an                                inspiring and discovery kind of                                experience on top of that so that even                                if you don't know exactly what you're                                looking for you come to our platform and                                we kind of inspire you with our hidden                                gems and hopefully something that's                                tailored to you so that you can just                                sort of browse around and yeah just have                                fun also on our platform and that's how                                we came up with the feed you know it                                also from other platforms when you open                                our home screen now you see a feed where                                you can scroll down and hopefully those                                items that you see there are tailored to                                you so that's what we wanted to                                introduce and we have actually and now                                why would this be tricky to give a bit                                of background of our our domain so we                                have of course lots of data so I already                                told you we have like                                                  users per month and that means that if                                we want to show you something                                interesting we need to keep track of                                what you're actually interested in so                                your interactions on the platform we                                need to store them process that somehow                                so we need a way to accommodate for that                                data that's continuously growing                                next that we have what we call                                occasional visitors so every six months                                or you have some users that come to our                                platform say every six months and maybe                                they're looking for something totally                                different like now they're suddenly                                looking for a racing bike in order to                                accommodate that we kind of want to                                capture that information in that same                                session so that when you come to the                                home screen from the search page again                                we immediately can show you racing bikes                                and items like that and not the couch                                that you were searching for six months                                ago then we also have a problem which we                                call yeah short-lived inventory so what                                we mean by short-lived inventory is kind                                of that we have a lot of items that are                                either very specialized or they're very                                popular and they can be gone within a                                few minutes and if we show you these                                awesome items and every time you click                                on them they're gone you're not going to                                have a good experience so we want to                                limit that that risk of showing you                                these stale items and finally we have if                                you have finding interesting items so we                                have                                                                   sift through that B in order to yeah in                                order to present the                                                   interesting ones to show you immediately                                on the first screen cool so we just                                heard why it's not super straightforward                                for a platform like ours to build a                                personalized film feed but looking at                                other platforms in the past years we                                could see that more and more of them                                make sort of personalized feed their                                default landing experience of whatever                                they have on that platform so we can see                                some examples of LinkedIn Pinterest                                Facebook obviously but up until a year                                ago our Start screen from the app still                                looked like this so it could obviously                                be a little more inspiring and so before                                before embarking on that journey of                                building a first nice feed for ourselves                                 it made all the sense in the world to                                 have a look at what other people are                                 doing in that area and we found a lot of                                 stuff on the internet publications tech                                 blog post especially helpful where                                 Pinterest and LinkedIn so if you're                                 working there thanks very much for that                                 and in general we found two main                                 directions you can take when building a                                 personalized feed on your on your home                                 page I'm just going to give a very                                 high-level overview on both of them the                                 first one is to pre calculate feeds                                 every user that you have on your                                 platform this is a simple overview let's                                 go through it step by step so you start                                 by looking at the items you have it                                 could be pins for Pinterest for Eva                                 Klein and siding it's its items it's our                                 ads with the stuff that our users                                 actually want to sell the next thing you                                 look at is at the interactions on your                                 on your platform so for Facebook this                                 could be shares likes posts things like                                 that for us it could be searches or item                                 details view someone something piqued                                 your interest then big magic box you                                 start sticking it into a                                 machine-learning pipeline with the                                 complexity of your choice                                 you build some sort of target function                                 like something to do with engagement or                                 maybe even revenue and then you build a                                 model and you can do that in a more                                 batch processing fashion or you can also                                 do it event-driven as data comes in                                 either way you'll end up with a model                                 that would score incoming items for each                                 user and what would come out of that                                 would be created and created you would                                 create feeds with them and update them                                 as you go and you would store them                                 somewhere so if the user comes to your                                 platform all the works already done you                                 just pick up the feed and that's it                                 so what do we like about this approach                                 obviously a retrieval is super super                                 fast because works already done as I                                 said you can have some very good                                 complexity and your machine learning                                 pipeline you can do some very cool                                 ranking in there what we don't like                                 about it is that a lot of the work that                                 you do actually goes waste it because                                 imagine you just build this awesome item                                 is this awesome function um found these                                 awesome items you sneak into someone's                                 feed and then they only come back to                                 your platform like a month later so                                 that's very rude and by that time you                                 update their feeds a million times for                                 nothing it's also very hard to maintain                                 these materialized feeds so if one items                                 interested interesting for a million of                                 users and it disappears on your platform                                 then you have to delete it in a million                                 feeds and that's maybe not a big problem                                 for Pinterest but it is for us because                                 our items are quite short-lived then the                                 last point is how how fast can you be                                 and getting new items and to users feeds                                 depending on whether or not you do batch                                 processing or how complex your pipeline                                 is                                 does it take you one minute for new                                 items to appear does it take you half an                                 hour we think that's quite a crucial                                 factor for the success of your feet                                 that's quite hard to get right in this                                 scenario what else can you do you can                                 also try calculating your feet on demand                                 same thing you again look into items on                                 your site on user interactions with your                                 site but this time you just stick them                                 into databases may be some sort of                                 aggregations maybe some sort of machine                                 learning as well to come up with clever                                 user features in the end they end up in                                 separate databases you could have one                                 for your items several for your your                                 user features and when the user comes to                                 the site you take the information you                                 have of the user and you search your                                 item repository with that and you build                                 the feeds as the user comes to the                                 platform what do we think about that                                 obviously we like that you don't need                                 any extra storage for the materialized                                 feeds then you don't have the problem of                                 outdated items so yeah I no longer                                 deleting items from                                                    they disappear the architecture is                                 arguably a bit simpler and since all the                                 work happens when the user comes to the                                 platform it's actually quite a lot                                 easier to implement any IB test that you                                 can think of what's a bit more difficult                                 with this approach is response times and                                 there's only so much you can do in terms                                 of ranking when the users already                                 waiting for their feed so you've got a                                 few limits here what did we go for for                                 our first implementation we went for the                                 on-demand version mainly because of the                                 simpler architecture and we really liked                                 the simpler test setup and we really                                 didn't even want to start maintaining                                 when maintaining a million users feeds                                 and we always kept it in the back of our                                 heads that we could do pre calculation                                 of feeds if we needed to but we're not                                 quite there yet so that's the general                                 approach and now we'd like to tell you                                 about we actually built the current                                 version on our platform right so the                                 first part of this problem is                                 calculating the user features so I                                 talked about earlier is we have these                                 interactions of the users on the                                 platform which are these item views and                                 the user searches those are the main                                 bits of information that we use to                                 personalize this feed                                 yeah we need a way to scale ibly store                                 that information and later process that                                 information and we decided to choose                                 Kafka for storing these items views and                                 these user searches because it's uh                                 first of all we're already using Kafka                                 inside our application to decouple                                 certain subsystems using a event-driven                                 architecture and that made it also the                                 sort of the tool of choice it made sense                                 to store this data also in Kafka it also                                 scales really well and it decouples the                                 ingestion from the processing so that's                                 good so we have our initial data and                                 secondly we thought it quite resembled a                                 sort of or we thought it a streaming                                 solution would makes sense because we                                 have this continuous data flowing in and                                 and the volume is quite high and the                                 benefit of a streaming solution is that                                 you can increment your model with every                                 incoming event so rather than having to                                 do these batch jobs and having the delay                                 we can stay up-to-date and catch the                                 user in the same session which is one of                                 the earlier problem statements that we                                 needed to solve so we have Kafka and we                                 want a streaming solution so it kind of                                 made sense to look at Kafka streams to                                 see if that would suit our needs and                                 what we like about Kafka streams is that                                 you don't need a specialized cluster for                                 that like you would with flink for the                                 streaming part if you already have your                                 data in these Kafka topics so it runs as                                 included library inside your java                                 application and you just consume these                                 these data topics and then you process                                 the data and you write the models back                                 to separate Kafka topics which you can                                 then later retrieve for yeah for anyone                                 that requests them really and another                                 nice thing about that is that it becomes                                 really flexible you can really quickly                                 create new Kafka streams applications                                 that you can put side-by-side so what we                                 have is for instance from the same input                                 data we have favorite categories                                 trending searches top location and we                                 have a few things more that we sort of                                 can just set next to our main our user                                 features and then we have in parallel                                 multiple Kafka streams applications                                 which allow is also                                 to quickly iterate on what we have and                                 to a/b test new features that we come up                                 with yeah that's pretty much why we like                                 after screens yeah so now that we solve                                 the the part with the user information                                 we still need to solve our short-lived                                 item problem and the searching and                                 finding um relevant items for you so we                                 need an item repository and this needs                                 to do think two things it's it needs to                                 be a very up-to-date version of the                                 things you currently have on your                                 platform and second it needs to support                                 a range of retrieval functionality some                                 ranking things like that so you can                                 actually build a cool product on top of                                 that and we didn't have to look very far                                 we went for elastic search as our item                                 repository first it was already a tool                                 in our toolbox we use it for our core                                 search and some other use cases at you a                                 client saying and yeah it's as you I'm                                 pretty sure although it's a scalable                                 distributed search engine it has a range                                 of ranking functionalities you can do a                                 sorting by geographic distance out of                                 the box you can do sorting by recency                                 out of the box and if all that built and                                 sorting isn't enough you can even build                                 your own ranking functions so with that                                 we were able to run a good range of very                                 cool experiments like rerunning a user's                                 past searches or finding trending items                                 in your area or drawing items from your                                 favorite categories or categories                                 related to that or even using elastics                                 more like this feature to come up with                                 items that user last viewed so in the                                 end we built queries based on the user                                 information and we pull results from                                 elastic search then we mix all them                                 together and wave them somehow and                                 that's how the final personalized feed                                 gets built and presented to the user so                                 when you stick those two parts together                                 what do you get you get actually a                                 system that is it showing ya quite                                 simple architecture so what you see on                                 the right side is the ingestion flow                                 that I talked about so the searches and                                 the item views they go into kafka topics                                 and then we have a user feature service                                 on top of that which embeds the kafka                                 streams library and it consumes from                                 these input topics does the processing                                 and then writes the output back to Kafka                                 topics and on the left hand side we then                                 have the feed request flow so you open                                 the app and the request goes to our feed                                 service the feed service that retrieves                                 the finalized models and uses those                                 models to create multiples elasticsearch                                 requests and they get fired off to the                                 elasticsearch repository which has a                                 view on our                                                           the response the weighted response gets                                 mixed together and presented back to the                                 user and yeah we're really happy with                                 this set up because each individual part                                 can be scaled so depending on whether                                 data ingestion needs to be skilled or                                 the processing or on the other side                                 actually serving the request we have a                                 quite a flexible architecture that can                                 accommodate for our growth so final                                 thoughts we built this thing it's                                 serving several thousands feeds every                                 second it we are confident it will                                 continue to scale in the future if we                                 were to put a finger on one point of                                 concern and the whole system it would be                                 our elastic cluster because we're                                 growing in two dimensions here it's like                                 very scalable it's inherently scalable                                 but we grow both in the number of feed                                 requests that we have on the platform                                 and we grow in the number of queries                                 that we fire for each feed request that                                 we get so that's something to keep an                                 eye on in the future and requires quite                                 a big cluster already                                 however as Dominic said we were really                                 happy with the set up it solves our                                 product needs for now we have the                                 flexibility we need to run fast                                 experiments and do very cool things                                 there is a tech blog article in the eBay                                 Berlin tech blogs also on the buzz words                                 website and with some links about how                                 other people have approached it and the                                 contents of the talk and if there's                                 anything that we can't answer before the                                 well-deserved lunch break please come                                 approach us at the eBay take booth and                                 also if you want to talk about the jobs                                 that we have in the eBay tech universe                                 so thanks for listening                                 [Music]                                 thank you we still have five minutes for                                 questions any okay so navigates um how                                 would you show for new users so it's a                                 cold start problem yeah so we are lucky                                 that we have many users on our apps and                                 we have very high login rates                                 so usually we were quite confident and                                 the user that we see is actually our                                 user and the Cosco streams thing we                                 monitored the percentage of feeds where                                 we don't have any personalized results                                 for and it was actually not point                                 something percent so something we didn't                                 tackle at that moment so usually as soon                                 as you do your first interaction you                                 will have some sort of personalization                                 in your feed and that was good enough                                 for us yeah and before that it's just                                 randomized so in the moment you click                                 any of those items we are able to in                                 near-real-time already incorporate that                                 into the feet the next time you visit it                                 when you introduce personalized feed                                 what do you solve for and how do you                                 measure it that it increased some metric                                 or and what would this matrix B so what                                 we essentially solve for is is well the                                 people that would not otherwise be                                 spending more time on our platform so we                                 can easily measure that because we then                                 expect that if we do a good job                                 those people spend more time both on the                                 feed but also on individual items and                                 and we just track basically the time                                 spent and and the items viewed on our on                                 our website and with longer sessions                                 more of views also it's a combination of                                 those things but indeed yeah so that's                                 what we track and that's what we sort of                                 optimize for and in your architecture                                 diagram you saw we saw that you carrying                                 some kind of state of dead streams I                                 assume this Kafka tables yeah how big is                                 that state you are having there how big                                 is the state that's a good                                 question so we have first of all we have                                 a replication factor of three three so                                 for redundancy purposes of got effector                                 that in and we have                                                     megabytes partition with                                              for partition so it's                                                                                                                           it's a                                                                  the Kafka topic underneath so that's a                                 compacted Kafka topic which is yeah like                                 key value like a key value table but in                                 the append-only law kind of that stores                                 the user ID with the the model but in                                 order to serve it we use Kafka streams                                 this sort of query API which also is                                 necessary so Kafka streams under the                                 hood it uses rocks DB to make sure that                                 I can do random access lookups because                                 it needs that also for the stream                                 processing and then there's a thin layer                                 on top of that that we reuse to serve                                 these models it's been working well for                                 us some people have said like maybe                                 that's not to be used for querying but                                 so far we've been using an in production                                 and yeah it's working quite well but if                                 you would want to serve it in another                                 way you can simply read through this                                 compacted topic which has the models and                                 you can stick it in any kind of database                                 that you would like if you would require                                 some other yeah some other properties                                 which is also very nice it's a flexible                                 set up we could always move to some                                 other way of querying these models we                                 have one more question those user feeds                                 are they completely personalized by your                                 algorithm or also can the user somehow                                 guide it by marking some categories or                                 something like this not yet product wise                                 we wanted to keep it as a black box so                                 inspiring and very surprising do you                                 have do you have any measures on how                                 effective it is in terms of like                                 click-through like improvements in                                 engagement let's say given the                                 improvements to the feeder yeah we do we                                 always see significant about not always                                 but for most of the experiments that we                                 do we see some significant increases and                                 view items                                 and events and engagement and session                                 length yeah okay thank you all right                                 thank you                                 [Applause]
YouTube URL: https://www.youtube.com/watch?v=5Vm1d-oxZeU


