Title: Berlin Buzzwords 2018: Mark Keinhörster – Scalable OCR pipelines using Python,Tensorflow & Tesseract
Publication date: 2018-06-18
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	In this talk we make a trip through the world of text recognition with free software and go step by step through the individual sections of a flexible and scalable OCR application. In a live demo you will be shown how Tesseract is used for text recognition and how the quality can be significantly improved doing a little pre-processing with openCV. Subsequently the documents are stored and indexed in Elasticsearch to allow full-text search. All this with just a few lines of code and all in the sense of interactive programming with Jupyter.

Agenda
- Quirks and pitfalls in text recognition of scanned documents
- Potential of pre-processing with openCV
- Use Tesseract at scale
- Quantify, compare and revaluate results
- Use of Tensorflow in a production-ready application

Read more:
https://2018.berlinbuzzwords.de/18/session/scalable-ocr-pipelines-using-python-tensorflow-and-tesseract

About Mark Keinhörster:
https://2018.berlinbuzzwords.de/users/mark-keinhorster

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              hello thanks a lot um yeah short for my                               person I'm I'm mark I am working as a                               data guy at code centric mainly working                               with Python working on deep learning                               tasks and a bit of data engineering and                               yeah I'm happy that so many people are                               here and I would like to to talk a                               little bit about the journey of OCR our                               journey of yeah grabbing text from from                                scanned pages at one of our customers                                and this is actually a system that we                                built and that's working in production                                and I would like to to show you a little                                bit so what we did how we did it and                                especially how easy it is to build a                                good working system and then where all                                the tweaks that you can apply to build                                an even better system so yeah shortly so                                what we are talking about for people                                that don't know OCR we are talking about                                optical character recognition and mainly                                we the the the least things that we are                                working on in reality is the OCR itself                                we use tesseract for it which is a                                library or a binary by Google awesome so                                let's go through it and I will show you                                a little bit the tips and tricks that                                you can do to utilize an open source                                library or an open source system using                                stuff like open CV and then we will go                                on and see okay where can we store data                                what can we do to make our results                                better and we will see how you can even                                yeah trick a little bit to get better                                results using elasticsearch let's start                                so the first thing is we want to start                                this what kind of little things we can                                do with a few lines of code best at best                                that we don't have to implement them                                ourselves to make documents better for                                text recognition so and we go through                                this and in the end we see how can we                                scale so it's a bit of code don't get                                scared this is all quite easy code the                                first thing is sometimes when you                                receive scans or a big scan pipeline                                people they put the cheese on the                                scanner                                sometimes they are quite corrupt a a                                little bit skewed rotated whatever and                                most of the tools that you have                                they have big problems and what we                                noticed it it's quite easy to write to                                write some code to rotate cake pages so                                let's look into this kind of algorithm                                it's a few lines of code so this is a                                sample page it's the page is bigger this                                one sample out of a magazine and you see                                this is how a lot of scans appear and if                                you try to recognize text in any with                                any tool you will get really really bad                                results even though these tools have a                                rotation engine or rotation algorithm                                inside it's very generic and often                                doesn't work so well but first thing                                that we can do is let's binarize this                                image and the next algorithm that we use                                it works best on on black white on black                                images so the first thing is so what is                                binarization you see here it's a                                threshold in and we simply say                                everything with a pixel value that's                                less than                                                      everything else is white or it's on                                maximum now we have a colored image so                                and you see here even threshold in it's                                super fast so I don't show you we don't                                have so much time I won't show you the                                code in life but this one is a really                                really fast operation we use open CV                                open computer vision it's an awesome                                open source library which is open                                sourced by Intel and it's it's fairly                                easy to convert such images with just a                                few lines of code one line of code okay                                so what's the next thing we want to                                detect lines to see do we have to rotate                                the image                                another great algorithm also in open CV                                is the half lines or probabilistic half                                lines with a few parameters like we give                                him the line length we living the max                                line gaps or the gaps that this                                algorithm searches and allows to have                                basically gaps in a full line so he                                tries to find lines when there is no gap                                that's longer than                                                      do is if we can find line                                with just one line of code then we look                                 over all the lines take a simple average                                 of the angle of deadline to the                                     degrees and after that we simply rotate                                 the image which is a fairly simple ya                                 call of OpenCV I don't even have it in                                 here and we basically correct our image                                 by by the average angle how does it look                                 so what we see here is we get the lines                                 fine we we take the coordinates out of                                 it we calculate the angle and sum all                                 these angles that we find up this is the                                 nave approach of course if you have a                                 little bit harder examples you might                                 want to on quantities ation there are                                 sometimes some some problems in it so                                 what you take is the most you take the                                 lines that are all quite similar all                                 right we calculate the average angle and                                 that's what we need to correct our page                                 ok -                                                                 quite well this is basically production                                 code and it works really really good and                                 you see here we find most of the lines                                 we find we get a sum of all these                                 average them and even these outliers you                                 they don't hurt us so much you but you                                 can quantify them away even that this                                 technique it works quite awesome it even                                 works for passports so we do a lot of                                 text detection in passports IDs end and                                 end and it's perfect to basically put                                 the IDS in the right in the right way                                 all right the next thing so we can                                 rotate an image what we've noticed is an                                 image has a lot of text different text                                 sizes and and end and what we want to                                 find out is where our text segment that                                 looks similar and most of the time text                                 segments that looked similar that are                                 the segment's that are close together                                 and that leads us to the problem let's                                 break it a little bit down we want to                                 find text segments first that we can                                 feed to our algorithm or to tesseract                                 and for that we use delation and erode                                 this is also a few lines of code and                                 simple probabilistic computing which                                 means it's fast to just detect text                                 segments and for that adulation is                                 nothing more than a convolution it's                                 basically a kernel everything on and                                 it's a matrix multiplication in a                                 sliding window and you assign the value                                 in the in the middle of your sliding                                 window basically here does everybody                                 know what a convolution is no that's a                                 convolution so if you hear it                                 convolutional neural network it's                                 basically pretty close to what we are                                 doing here just you don't use the the or                                 or end operator you simply do a                                 multiplication by a random initialized                                 sliding window and you add always the                                 value of this multiplication basically                                 in this end in the center and this is                                 how the tens of flow or whatever                                 convolutional networks are made up and                                 what kind of these kind of matrices here                                 the kernels get trained to get better                                 features it's the whole idea of                                 convolutional networks so let's look how                                 this works what we see is we start                                 delation dilation means we want to have                                 broader whites so if we notice something                                 white we want to make make a little bit                                 more fat so that's nice that what we see                                 here so we bring these kind of segments                                 closer together and you already notice                                 here you have got some good lines could                                 we do the same part here again with a                                 little bit different kernel a kernel                                 that's not a square but the kernel                                 that's pretty large and afterwards we do                                 an erode and erode is basically the                                 opposite of a delayed it just shrinks                                 the whites a little bit down but what we                                 do with this closing operation we narrow                                 down the gaps so if there was a we                                 delayed we shrink down and what we have                                 is where was a dark point before there's                                 no white and what we have here is we                                 start closing together things that                                 belong together                                 we simply merge text with pixels and now                                 if we do a fine contour that's also                                 OpenCV fairly easy to find contours in                                 an indented picture we find boxes and we                                 find the box                                 from the stuff that we connected and a                                 little bit of filtering that's knave we                                 have better approaches but basically                                 this is already enough to filter all the                                 boxes that do not belong so all the                                 contours that are too small and if we                                 see after filtering what happens an                                 algorithm that selects stuff that                                 belongs together in nearly every                                 application in nearly every image with a                                 few lines of code                                 it's nice magic if you show this to                                 management everybody is happy and adjust                                 a few lines of code pretty fast                                 operations with convolutions so these                                 are the text parts                                 cool let's look again we have more                                 there's some way to talk there is the                                 distance AI and tensor flow just to to                                 bring bring everything down to the real                                 thing we do not use tensor flow for                                 object character recognition there are                                 way better models built by way into more                                 intelligent people then for example me                                 with a lot of more training data to                                 build object character recognition it's                                 a solve problem and I would like to                                 utilize what's get what we got but what                                 we noticed is we had a lot of pictures                                 pictures take processing time and                                 pictures lead to problems and what we                                 did is because we didn't find a solution                                 before we trained a classifier that can                                 decide between pictures and decide                                 between written text so we can filter                                 out and we can under pictures for                                 example filter what's on the picture and                                 put this also in an index and this                                 classifier is a simple convolutional net                                 looks pretty close to the amnesty                                 example but it's fine it's fast it works                                 pretty well the results after evaluation                                 was a                                                                    couldn't believe that so what we started                                 here and this is the next important                                 thing that I if you use tensorflow if                                 you lose Kiera's if you lose use                                 convolutional neural networks look what                                 the network is looking on so and there                                 is same thing it's called great cam                                 computer-aided segmentation and                                 what you can do is basically you can use                                 the the gradients from your machine                                 learning model and apply them to the                                 last convolutional layer and basically                                 calculate back of a sample image                                 why did your convolutional network                                 decided for a class and because of what                                 segments in your image and that's what                                 you see here so we looked at our own                                 results and said hey what made you                                 decide for this class for text and it's                                 quite nice what you see here the red                                 things it's like a heat map the red part                                 makes the convolutional Network decide                                 why it's text and it's looking at text                                 and you see here the blue one this one                                 was which is little bit deciding against                                 it but it's fine and if we compared with                                 an image we can see all nice there are                                 some whatever it looks at but there are                                 some edges that are not normal for text                                 and because of these edges because of                                 everything that's read it decided that                                 this class here is a picture select the                                 next step if you have a model and you                                 want a little bit to understand what                                 your model is doing try to visualize                                 where the CNN where your network is                                 looking at it's one learning that we got                                 from us cool okay that's the a iPod so                                 for the easy things but it works quite                                 well tesseract what does it do                                 it's an instant it's a binary that you                                 can basically use and you have a lot of                                 apps libraries around it like we are                                 using pi OCR it's open source it's                                 maintained by a small group of people                                 but I can really really recommend it                                 because they are really responsive so I                                 had a question I found something and                                 they were responsive in releasing a new                                 version in in just a few days so really                                 nice guys tesseract internally uses a                                 neural network and LS TM and what you                                 get out is a format which gives you                                 lines words and locations that it                                 detected how does it look PSM is the                                 page segmentation mode there's a lot in                                 the documentation where you can look in                                 the interesting part is here create hoc                                 are                                 which gives you basically lines in lines                                 are words that you can concatenate them                                 and you see here also if you build the                                 right docker container with tesseract                                 inside it's very easy to use it and it                                 after the pre-processing it gives you so                                 we have a rate of                                                 hundred percent recognition rate so                                    percent of all images have a recognition                                 recognition rate of                                                      next interesting question how do we get                                 the recognition rate and that's where we                                 use elastic search for and this is where                                 you can really make a difference so what                                 you see here is the the levenshtein                                 distance that we are using if we have a                                 vert recognized with the typo we have an                                 index which contains a dictionary and                                 this is the dictionary of the German                                 language that's why you're working in                                 and the dictionary of domain domain                                 language for example we are working for                                 an insurance company an insurance                                 company is some special words in Germany                                 for the whole domain and having these                                 two in our dictionary gives us the                                 possibility to get word to get suggested                                 set Jess chance for every word that we                                 recognized and our native approach is                                 let's see if we find words that are in                                 the dictionary that's a hit and if not                                 at least give us some suggestions and if                                 we find the document that has all words                                 already in the dictionary and we don't                                 need any suggestion we have a hundred                                 percent recognition rate all right it's                                 a quite naive approach but it works good                                 and it gives you a nice ground truth if                                 you work on that kind of topic plus we                                 use the elastic search also as a search                                 engine to have to be able to search                                 inside pictures with this kind of                                 metadata and you even get pictures where                                 tesseract was detecting a typo which                                 means we have two ways to make our model                                 better we can make our dictionary better                                 maybe add something to the                                 domain-specific language we can build up                                 on picture pre-processing and make our                                 just better or even use new versions of                                 tesseract and compile them maybe in a                                 better manner to make a CEREC faster so                                 you have a lot of little things where                                 you can work on basically just for for                                 detecting text and you can utilize                                 elasticsearch that gives you some real                                 nice suggestions and yeah makes                                 searching way easier and this is a yeah                                 this is the real real world and it works                                 really fast five minutes left                                 perfect last slide scalability now we                                 want to talk about scalability so okay                                 elasticsearch scalability by itself you                                 can scale it around clusters fine                                 but how can you scale the OCR process                                 itself but I've shown you rotation                                 dilation and then text segmentation                                 sharpening of text                                 maybe deleting some watermarks all the                                 stuff that we do we put it into into                                 their own containers and per container                                 we can really scale to wherever you like                                 so you can't make the process itself                                 faster but where you can really well                                 scale is you can basically make more                                 images or or be able to detect more text                                 in more images at the same time for                                 example so what we notice is first of                                 all it's a quite quite old setup which                                 gets better is we don't have any                                 kubernetes whatsoever so no no nice load                                 balancing or let's say no nice load                                 utilization but what we could notice is                                 we can build containers with simple                                 docker on board                                 utilities to apply to every container                                 and                                                                awesome for for ops the guys from from                                 operations they loved it because they                                 say hey please go to                                              allowing something but we utilize the                                 full CPU all the VMS quite well and we                                 can even structure our our                                 infrastructure landscape to have a                                 pre-processing parts to have                                 rotation in parts or to have here                                 tesseract                                 recognition parts and this is really                                 important because what you see is what                                 I've shown you the small pre-processing                                 steps they are super fast they are in                                                                                                       tesseract itself                                                     around                                                               have                                                                forty thousand images per day to                                 recognize and for that what you need is                                 a really really good scalability                                 mechanism and the next part is if you                                 look here your elastic needs to be quite                                 well optimized so the speaker before and                                 elastic new features some of the new                                 features you mentioned like                                 bootstrapping and bootstrapping checks                                 that was where all things that hit us                                 this part here you have to see elastic                                 is asking for every word in the text                                 elastic gets asked on its image onyx                                 index did you know this word which                                 results in                                                               but                                                                   per use if you do this four hundred and                                 forty thousand images per day you know                                 what kind of load elastic is working on                                 our current dictionaries around three                                 million where it's not and yeah in the                                 end we store all the results all the                                 metadata basically in elastic and                                 provide it as a big big search engine                                 layer in front of texts basically that                                 this is the small journey a little bit                                 of what I wanted to show you and I think                                 the five minutes are done quite fast                                 thanks                                 [Applause]                                 you
YouTube URL: https://www.youtube.com/watch?v=9mJ0C7KttYg


