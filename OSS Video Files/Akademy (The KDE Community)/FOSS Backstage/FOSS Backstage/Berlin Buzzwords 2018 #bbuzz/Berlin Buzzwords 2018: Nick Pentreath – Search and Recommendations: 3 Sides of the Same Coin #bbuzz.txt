Title: Berlin Buzzwords 2018: Nick Pentreath â€“ Search and Recommendations: 3 Sides of the Same Coin #bbuzz
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	Recommendation engines are one of the most well-known, widely-used and highest value use cases for applied machine learning. Search and recommender systems are closely linked, often co-existing and intermingling. Indeed, modern search applications at scale typically involve significant elements of machine learning, while personalization systems rely heavily on and are deeply integrated with search engines. In this session, I will explore this link between search and recommendations.

In particular, I will cover three of the most common approaches for using search engines to serve personalized recommendation models. I call these the score then search, native search and custom ranking approaches. I will detail each approach, comparing it with the others in terms of various considerations important for production systems at scale, including the architecture, schemas, performance, quality and flexibility aspects. Finally, I will also contrast these model-based approaches with what is achievable using pure search.

Read more: 
https://2018.berlinbuzzwords.de/18/session/search-and-recommendations-3-sides-same-coin

About Nick Pentreath:
https://2018.berlinbuzzwords.de/users/nick-pentreath

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              so I'm Nick Penn truth ml Nick on                               Twitter and github I'm a principal                               engineer at IBM where I work for code a                               which is the Center for open source data                               and AI technologies I focus on machine                               learning deep learning AI and I'm an                               Apache spark emitter and PMC member and                               I've written a fairly out-of-date book                               on machine learning with spark                                so before we start just a little bit                                about code a it was formally known as                                the spark Technology Center and was                                formed by IBM to to focus on Apache                                spark in the surrounding ecosystem and                                over the course of its its history it                                expanded that mission to really focus on                                AI and deep learning and machine                                learning data science in general so now                                we have rebranded it as code a and we                                focus on enabling the into end AI life                                cycle in the enterprise so we focus on                                spark as well as the Python data science                                stack deep learning frameworks and we've                                got a couple of projects that we've                                released the model acid exchange and the                                fabric for deep learning which I'll                                mention a little bit at the end if we                                have time so today we will start with a                                little overview of recommender systems                                and then look at search and                                recommendations and how they how they                                are integrated and how you can use                                search engines to serve recommender                                models and in particular the three sides                                of the coin so that the three different                                broad approaches that I see to to do                                that and finally end off with some                                performance evaluations and conclusion                                so recommender systems are one of the                                earliest and certainly most high-value                                use cases of machine learning that we've                                seen you know each and every one of us                                are not in our daily lives comes into                                contact with a multitude of recommender                                systems if every day so whether you're                                browsing and your online store you know                                streaming music looking at YouTube using                                your social network apps you're coming                                into contact with some form of                                recommendation and personalization                                system and this is not just pervasive in                                the sense of you're affecting our lives                                but it but it's pervasive in the sense                                of economic impact and value so if we                                can improve the recommendation and                                personalization system                                there's real money to be made there so                                Amazon for example about                                           bottom line is accounted for by the                                recommender system for companies like                                Netflix and other streaming sites it                                might be as high as                                                targeting a lot depends on these these                                systems and models so in your                                recommendation engine you have two types                                of entities users and items the users                                are self-explanatory and without them                                there is no system and the items can be                                anything in this case perhaps you're a                                movie and attached to each of those                                users and items are pieces of metadata                                and activity data so for users it might                                be demographics geolocation for items                                that might be categories tags and the                                content and that aggregated activity                                data might be for the for a movie you                                know the number of likes the number of                                players when it was last played so this                                is an indicator of what is the activity                                around that                                so our system requires us to use this                                metadata and this content in some way so                                for example we want to do filtering and                                grouping we might want to show                                recommendations that are based on a                                category we might only want to show a                                popular items or not so popular items if                                we want sort of longtail recommendations                                we might want to show more recent items                                we also need to apply business rules so                                for example based on age we don't want                                to show age restricted content to                                younger viewers we also might have                                geographical constraints you know data                                privacy regulation so the core piece of                                data that we care about in a recommender                                system is the event this is a user                                interactions every time a user comes and                                interacts with our system they're                                 telling us a little bit about themselves                                 most of the examples that you see in                                 recommender systems and building the                                 models or all around explicit preference                                 data so someone says I give this movie a                                 rating but in most cases the vast                                 majority of data available is of the                                 implicit type so a user comes along and                                 they interacting with the system they                                 don't specifically tell you I really                                 like this movie here's a rating instead                                 you have page views head to cards                                 purchases and you have you know                                 plays follows all these kind of implicit                                 indicators of preference that may mean                                 that the user likes that data item but                                 it may not so a pageview is a light                                 indicator of preference and ad saccade                                 might be a stronger one and a purchase                                 might be the strongest but even if                                 someone purchases something it doesn't                                 necessarily mean they like it because                                 later on they may you know give a                                 negative review or even return that item                                 and unless your system captures that you                                 will never actually know that so these                                 events give us an indication about what                                 user preferences are and attached to                                 each one of these events is a context so                                 every time a user comes and interacts                                 with that system they're using a                                 specific browser at a specific time of                                 day there's a geolocation attached to it                                 and context matters for recommendation                                 because you we may want to recommend for                                 example different movies to a user based                                 on whether they are sitting at home in                                 the evening or whether they're on their                                 commute to work or whether they're at                                 work perhaps for example so since most                                 of this data is implicit we have to                                 think about how to handle implicit data                                 and broadly speaking you can either                                 incorporate it into the model directly                                 and you'll see some examples of that                                 later or you can try and attach some                                 sort of weighting scheme yeah so all of                                 this binary                                                              weight attached so a page view might be                                 a                                                                       a                                                                      difficult to to necessarily do in a                                 principled way but you can you can                                 weight add these weights to the event                                 and then use a standard model but we                                 definitely have to think about how to                                 handle this in the system                                 another key elements of recommendation                                 engines is the cold start problem so                                 when a new user or item comes into the                                 system that is called start for new                                 items we have no historical data so we                                 don't have a model for them and                                 typically one needs to fall back to use                                 basslines                                 or item content to try and create some                                 sort of recommendation a new or unknown                                 user might even either be a completely                                 new user to the system or perhaps                                 they're anonymous they're browsing using                                 using a new device or they have ad                                 blockers or whatever the case may be but                                 in that case again we have no historical                                 data for them and we have some context                                 data but potentially very limited                                 so we cannot directly use most of the                                 kind of collaborative filtering based                                 models that we would normally use except                                 for the fact that we can try and use                                 item similarity for let's say the                                 current item that the user is viewing if                                 we have built a model for that item all                                 the typically we try to represent the                                 user as some sort of aggregation of the                                 items in their session as they're                                 browsing so we try and build up that                                 that user representation on the fly and                                 in some cases contextual models can                                 incorporate by the context data and the                                 short term history of that user during                                 that session so prediction in a                                 recommending recommender system is all                                 about ranking we have to take all the                                 available content or items that we have                                 in our system every once you present the                                 user a list and that list needs to be                                 ranked in order of our estimated                                 estimate of the preference of the user                                 so in other words by likelihood that we                                 think the user will interact with that                                 item and typically we have very very                                 large item sets and we only want to                                 return a very very small set five or ten                                 some of the serving requirements that we                                 have for serving recommendation models                                 this is not exhaustive but these are                                 some key ones as we've mentioned we                                 serving is about ranking large number of                                 items so we need to be able to have a                                 ranking system in almost all cases we                                 want to do be able to do some sort of                                 filtering whether by categories                                 popularity time price to your location                                 any combination slice of slicing and                                 dicing the metadata that we have around                                 items or users we want to be able to                                 filter based on that we'd ideally like                                 to use all the data we have available                                 that prediction time in particular                                 content and context because in                                 especially in the cold start problem                                 that is a rich data that we can use to                                 still make them you're a principal                                 prediction we need to scale both with                                 the item set and the feature set so the                                 item set naturally as we get more items                                 we need to scale that serving system and                                 the feature set as we add more and more                                 features that are used in the model or                                 more and more contextual and metadata                                 that's used in the model we also need to                                 scale their computation we need a handle                                 cold start so but the system needs to                                 perhaps incorporate this additional data                                 that we can use to handle cold start and                                 we also need to you know have some sort                                 of content-based fallback perhaps or                                 item aggregation capability                                 and finally we would ideally like to                                 easily incorporate a new preference data                                 so we train models simply or fold into                                 an existing model without doing a full                                 retraining so that's a brief well answer                                 of recommendation engines and in                                 particular what we need to serve them I                                 will talk about search and                                 recommendations and how they can                                 interlock but first we'll just take a                                 little detour into some of the sort of                                 core models that we're going to discuss                                 today so the ratings matrix is at the                                 the center of most collaborative                                 filtering approaches and this represents                                 the the user interactions in this form                                 of the sparse matrix so the users as                                 rows and the items as columns in this                                 case movies and each interactional                                 rating that the user gives to a movie is                                 represented here so you'll notice it is                                 sparse and not all users rate or movies                                 and it's very large and our goal is                                 really to follow that matrix in we need                                 to predict for those missing entries                                 what are going to be the highest ranked                                 in terms of preference so one of the                                 core earlier models is item                                        co-occurrence and effectively we take                                 that big matrix and we multiply by the                                 transpose of the Med of the same matrix                                 and we get a coherence matrix and each                                 entry specifies that that a                                 co-occurrence happen between the item                                 and the other atom so in other words                                 they were they were interacted with by                                 the same user so this is a this is                                 typically done in a pre-computation                                 fashion so we'd like to pre-compute that                                 entire big matrix offline and then when                                 scoring we can either compute the item                                 so add some similarity on-the-fly or we                                 can again represent the user as a kind                                 of combination of their previous items                                 that they've interacted with and that is                                 effectively a dummy item and then we can                                 use that to to get these similar items                                 and make a recommendation another way of                                 doing this is to try to factorize that                                 matrix so we use a matrix factorization                                 technique and this is really about using                                 a model-based approach to actually try                                 to complete that matrix so one typical                                 approach is to split it into two smaller                                 much smaller                                 Oh cease and try and minimize the                                 reconstruction error so we want to when                                 we multiply those two matrices together                                 get the best estimate of that original                                 matrix and this is nice because it works                                 really well in practice there's really                                 efficient and scalable algorithms for it                                 it's one of the best performing single                                 models that that are typically in use                                 and prediction is really simple you just                                 simply take for a user recommendation                                 that use a vector and we do a dot                                 product between all the item vectors and                                 similarly for height some similarity we                                 just take the item vector and we compute                                 a similarity metric cosine similarity or                                 something like that and it can handle                                 this implicit data that we mentioned                                 before by weighting so there's a form of                                 this model where those ratings are                                 treated the ratings are treated as                                 weights of a binary kind of indicator                                 matrix and by applying the weighting                                 scheme I mentioned earlier you can just                                 use the same model and you get pretty                                 good results so we've seen that scoring                                 and recommendation engines is ranking                                 given a user in a context we ranked                                 available items in order of the chance                                 that a user will interact with them and                                 this looks really similar to a search                                 engine so given a query we compute some                                 similarity over our entire document set                                 and we sort the items based on that                                 similarity score and we return a ranked                                 list so this really makes the question                                 can we use a search engine to serve our                                 recommendations because they look like                                 they're doing pretty much the same thing                                 well at a high level does a search                                 engine meet our requirements well it's                                 custom-made and specifically designed to                                 rank large sets of items so we're good                                 there filtering is core to search engine                                 so that looks good can we use all their                                 debt prediction time well it depends                                 scalability with that height subsets and                                 feature set is baked into the search                                 engine and most of them have high bay                                 high availability elastic scaling these                                 days can handle cold start well again it                                 depends can you easily incorporate new                                 preference data                                 depends so what does it depend on well                                 firstly the the serving and scalability                                 it depends on you using the inverted                                 index so the search engine yeah that's                                 the real Corvette and the way that it                                 can scale and handle queries really fast                                 so we need to massage our problem to fit                                 into that in that model and for the it                                 depends components that really is model                                 dependent so whether you can use all the                                 data prediction time depends on what                                 model you're using the model itself and                                 the computation itself needs to do that                                 and whether you can handle cold start                                 and incorporate new data again depends                                 on the model but as long as the model                                 supports it there should be in theory a                                 way to incorporate it into the search                                 engine in particular though the cold                                 start fall backs for content-based okay                                 so this seems like a good idea we've got                                 a search engine that looks like it does                                 the same thing as a recommender and we                                 should be able to use the same machinery                                 so how do we do that well there many                                 more approaches but I I sort of see                                 three main approaches score then search                                 native search and custom ranking and                                 we'll go through each of them so school                                 then search is the least integrated                                 approach and indeed it's actually based                                 on as it says scoring and then searching                                 so it's two systems and you typically                                 either use a scoring system to complete                                 the row recommendations first and then                                 use the search engine to falter to get                                 the results or you can flip it around                                 and then your first fault of the results                                 or the candidate items at least feed                                 them into the scoring system and then                                 compute your scores so in most search                                 engines you once you've got from the                                 scoring system at the top there once                                 you've got the IDS you can pass those                                 IDs as one of the filters into your                                 search engine and you get your results                                 it and likewise at the bottom your the                                 search engine can spit out a set of IDs                                 that that satisfy your filters and then                                 you can use that to to only score the                                 relevant documents in your scoring                                 system                                 so what are the trade-offs eeeh                                 the first advantage is that you have                                 complete flexibility in the model that                                 you can score so having a dedicated                                 scoring system means you can potentially                                 use very rich contextual models feature                                 models maybe deep learning models for                                 extracting that rich content and you can                                 really focus on optimizing at score and                                 component and get it as as fast as                                 possible the downside and one of the                                 major ones in my view is that you have                                 to maintain at least in two systems so                                 in some cases this may be unavoidable if                                 you want to use a particular model but                                 maintaining your each additional system                                 requires a lot of overhead DevOps and a                                 lot of more things that can go wrong but                                 then you've also got this filtering                                 challenge and that chapter says that                                 let's say you want you you're scoring                                 and then you're searching that scoring                                 system has to spit out a set of                                 candidate IDs that you are then post                                 faulted and if you don't complete enough                                 candidates then you might end up in a                                 case where you don't get enough                                 recommendations because after applying                                 your metadata filtering categories and                                 so on                                 you might you might actually not not                                 have a result set so it's it's a                                 difficult balance to strike how many row                                 recommendations do you compute in the                                 scoring stage to pass into the filtering                                 stage so in some cases that might you                                 know it might make sense to filter first                                 and then score but but you might you                                 might have similar challenges there and                                 and then adding that round trip between                                 systems actually means that your overall                                 system performance can be a lot of a lot                                 slower than you think so the scoring in                                 peace can be really fast but I've been                                 adding the search and the filtering and                                 round trips between them can kill that                                 so the second option is okay let's let's                                 move all the way to the other end of the                                 spectrum and have a completely                                 integrated system so this is what I term                                 native search this is where we want to                                 effectively take that model and put it                                 in a format that the search engine can                                 just use without any modification and                                 typically enough pretty much in all                                 cases this requires pre-computation                                 so you want to pre-compute that model                                 crunch all the numbers and you know                                 throw your massive big data cluster edit                                 and then index those results in a way                                 that makes search faster so broadly                                 speaking one of the the main approaches                                 to this is to use the co-occurrence                                 matrix approach so you take that                                 pre-computed co-occurrence matrix that                                 you did offline and your index it and                                 effectively what you need index is for                                 each item you need to index the most                                 similar items to that so this means                                 actually for each item doing the full                                 pre-computation of one of the most                                 similar items now if you're thinking                                 that this is a lot of work it is a lot                                 of work so doing a brute-force                                 pre-computation approach of this nature                                 scales very very badly or flight' even                                 so it reaches a point where you need to                                 do something smart and that's something                                 smart is typically some form of Thresh                                 holding so you can either threshold                                 based on a score as you go but there's                                 some smart ways to do that in a                                 principled way using the log likelihood                                 ratio and this is a I mentioned the                                 links later but this is done in in some                                 other literature and some of the                                 projects out there on github but the                                 core idea is once you've indexed it in                                 that form then search just becomes a                                 standard search query so if you're if                                 you either represent if you represent                                 the user as the items that they've                                 previously interacted with then you just                                 issue those item IDs as the query string                                 and you get back the results so because                                 you've done a lot of work up front and                                 you pre computed everything and you've                                 indexed it in the correct way you can                                 just drop it straight into your search                                 engine and it does exactly what you what                                 you need so the great thing there is                                 that it's one system and you don't have                                 to change the search engine at all you                                 do all the work offline query time it's                                 really really fast so you know                                    milliseconds                                                             it fits exactly into the search mold                                 it'll it'll tin it'll and you threshold                                 it right this is important it scales                                 really well                                 even as the item set and that kind of                                 features hid that you're using scales up                                 this thus approach will still remain                                 really fast and depending on what model                                 or what approach you use you can use                                 almost all your your data so the                                 particular model that I referred to you                                 later in the link is a cross                                 co-occurrence model so that completes                                 just not just let's say on purchases but                                 on the cross co-occurrence between                                 purchases and pageviews between content                                 tags and pageviews between any kind of                                 item metadata and use a preference later                                 that you can think of you can correlate                                 it back to what you care about which is                                 ultimately let's say a purchase or you                                 know or a play or a stream so that's                                 great and that query time you can you                                 can construct these multiple queries                                 that take into account each of those                                 those components but you really have to                                 decide what to compute upfront so you                                 have to make that decision yeah as a as                                 a modeler and of course the more me the                                 more you do and the more data you put in                                 the more complex that computation is                                 going to be one of the key things here                                 is that is no ordering retained in the                                 index terms so in the raw computation                                 using a threshold approach or log                                 likelihood ratio you these these ones                                 are actually scores and that score has a                                 an interpretation that that the higher                                 it is the more kind of interesting that                                 co-occurrences and and you don't really                                 retain that when you index it in this                                 way so it's very difficult to to really                                 keep that that concept of ordering going                                 and then finally there's it's a lot more                                 difficult to include the rich content                                 data so textual data you can include by                                 using a kind of bag of words and similar                                 approaches but if you want to use images                                 audio for example it's difficult to                                 extract that those features in a way                                 that you can apply it in in this                                 approach so this is implemented in the                                 Universal recommender and the mahute                                 correlated cross occurrence algorithm so                                 if you want to know more those are the                                 places to go                                 okay the third side of the coin is one                                 that I've done quite a bit of work on                                 and this is the custom ranking so the                                 key here is that we want to combine the                                 scoring system and the search engine                                 into one system and we want to do                                 scoring and filtering at the same time                                 online so in real time                                 so typically we were not going to                                 pre-compute here so how does this work                                 well as we've seen before the search                                 engine and I recommend I look fairly                                 similar your search ranking works more                                 or less like this we take a query we                                 extract that query into a term vector                                 that represents the search terms and                                 then we are scoring phase is computing                                 the similarity typically some form of                                 cosine similarity between that query                                 vector and each one of our documents and                                 obviously the documents that that fits a                                 filter and then we sorting is pretty                                 trivial which we sort and we rank so can                                 we use the same machinery exactly this                                 machinery for recommendations well at                                 the analysis phase we just give it a                                 user and typically that's a user item                                 vector so that doesn't really work in                                 the built-in mechanism the term vectors                                 are not the same term vectors as we have                                 in the typical search query so they're                                 kind of just raw double arrays and                                 they're not these kind of binary term                                 vectors the scoring is again not the                                 same but the core of it is that we want                                 to compute some some similarity or                                 custom metric against each of those                                 documents and then once you've got that                                 well the ranking part is exactly the                                 same so how can we bend the search                                 engine to fit our to fit our well I                                 should just point out I'm illustrating                                 this with elasticsearch because that's                                 what I've worked with but it's not                                 limited to that so the first is that we                                 want to tackle this analyzer step so we                                 start with a row vector and we can use a                                 custom analyzer to represent that in a                                 way which is going to make our lives                                 easier later and this is a delimited                                 payload filter so this is a something                                 that's not                                 really that commonly used but                                 effectively it allows you to attach a                                 payload and the payload is typically you                                 know a double or float number to each                                 term so here we actually use the this                                 pipe delimited string and the numbers to                                 the left of the pipe represent the                                 vector indices so those are going to be                                 our terms and the numbers to the right                                 are are our payloads which are vector                                 values so if you look at the way the                                 term vector looks here you can see that                                 the term is                                                           index and our vector and the payload is                                 is a binary version but it's it's this                                 float to payload that we care about so                                 once you've done that we need to use                                 this payload to be something useful and                                 here we're going to use a custom                                 function score query or nona script so                                 we take the the vector which is our                                 query let's say our user or our item                                 vector and we got to pass it into our                                 script and more that's what we do is we                                 extract those payloads for each term in                                 the index and we iterate over each term                                 in that index and we compute the score                                 which is just that payload with the                                 vector value times the value of the                                 query vector at that index so this is                                 exactly dot product and if we normalize                                 it it becomes exactly cosine similarity                                 so now what we've got is a user item                                 vector that we can analyze into a form                                 that can be fed into search term vectors                                 we have a custom scoring function that                                 can score each of those query vectors                                 against our document set and then                                 ranking is pretty much exactly the same                                 so we ticked all these boxes and it                                 could actually use exactly the same                                 machinery to score these matrix                                 factorization factor models and what's                                 nice here is that we get the search for                                 free so the core scoring function is is                                 replaced so instead of using the                                 built-in search similarity we use this                                 as courier dot product or cosine                                 similarity but of course we can mix and                                 match that there are different ways to                                 to blend the the built-in scoring                                 functions and the custom one                                 we get the filtering for free so all of                                 these tags metadata activity data we can                                 slice and dice exactly as we please and                                 we can issue any arbitrary search query'                                 has the the meta query for the scoring                                 function so it'll work exactly as a                                 normal search query adjust that all                                 we're changing is the way that those                                 documents are scored so we get you know                                 the we get the filtering we get free                                 text search we get any of the                                 geolocation and date map type of queries                                 all of that for free in one system so                                 that's the key benefit here is that we                                 can combine these systems into one and                                 potentially we can incorporate these                                 richer models which I've just shown a                                 way to represent a kind of simple matrix                                 factorization model but if we think more                                 generally about your embedding models                                 where we can have different in vectors                                 that represent the users and the items                                 and the contextual data and the content                                 data including you know potentially                                 extracted features from your deep                                 learning model for example for your                                 images and audio we can potentially use                                 that same representation here to make                                 our to make the scoring work so it has                                 its limitations because the scales sort                                 of okay at the moment so as you make                                 those victors longer and bigger and                                 bigger higher and higher dimension and                                 as you add more and more vectors you're                                 adding a significantly to the                                 computation that occurs and so it scales                                 up to a point but you passed a certain                                 point you're not going to be able to                                 incorporate all the all of those models                                 but really this is combining these two                                 approaches these two extremes you know                                 the the pure scoring and separating that                                 system with the pure in the native                                 search and integrating those systems                                 completely and you it sort of sits in                                 the middle and so you get a bit of the                                 best of both worlds but of course you                                 get drawbacks with that so it does                                 require a custom plugin for your search                                 engineer you know if you're running on a                                 very managed environments client                                 environment that might be a problem so                                 this is a this is out there on github as                                 the elasticsearch vector scoring plugin                                 this is a version for solar which Amish                                 later and also a code pattern on IBM                                 code IBM's open source developer site                                 that you can go and check out okay so a                                 little bit about performance and                                 comparing some of these approaches so                                 this is the custom scoring performance                                 and as you can see for for small item                                 sets this is brute-force computations or                                 scoring all all items with no filtering                                 or anything like that for small item                                 sets it works pretty well and it's quite                                 fast but you can kind of see that in                                 particular for large item sets and as we                                 scale this vector size it gets slower                                 and slower                                 likewise you know we can we can try and                                 scale especially at the high end we can                                 scale this computation by adding shards                                 to our cluster so at low low numbers of                                 items adding shards doesn't really                                 matter nor and actually once you're past                                 the certain points it hurts performance                                 but for larger items that makes sense                                 you're adding adding shards distributes                                 a computation across one or more nodes                                 or more processes and we get a speed-up                                 but you know the number of shards that                                 you might apply to this to get that                                 speed-up might be a lot larger than you                                 would otherwise use for you for that                                 particular index so what about comparing                                 to the score then search approach well                                 in this case for a large item set we we                                 can see that they're actually quite                                 similar and the score then search                                 approach is a little bit worse so the                                 scoring piece of that is actually really                                 tiny so the peer scoring computation                                 which is just you know matrix vector                                 operation is really really fast and you                                 can make it a little bit faster but it's                                 not going to make that much difference                                 what really gets you is you're the the                                 sorting and the searching                                 and that's difficult to get away from                                 you know you can improve that a little                                 bit with with your with filtering and                                 but effectively you're incurring up that                                 round-trip that I mentioned earlier so                                 one way to scale the scoring of this                                 brute force approach is by using                                 locality sensitive hashing                                 and in this case what that is really                                 doing is applying some kind of                                 pre-computation                                 or thresholded                                 to that item set so if we're finding the                                 most similar items in a set we are                                 effectively using LSH to only search in                                 certain buckets to find that item so                                 this is kind of this is fairly analogous                                 to the pre-computation we did in the                                 native search approach for co-occurrence                                 we do a an exhaustive computation but                                 instead of doing all the the work we                                 threshold it in some way and Alice H is                                 doing something similar so not too                                 surprisingly you know we can cut that                                 down to around                                                          in the range of the native search                                 approach so by applying some pre                                 computation we get to a similar                                 performance but we also had had some of                                 the drawbacks from that approach so                                 because we've pre computed in Alice H                                 index we only search in certain buckets                                 we might be effectively missing some                                 potential candidate items and some good                                 recommendations so we dramatically cut                                 down the work that we need to do at at                                 run time but we we lose flexibility okay                                 I'm going to very much very briefly                                 mention a couple of peer search                                 approaches that you can look at we don't                                 just in the interest of time so for                                 constant similarity you can just use                                 Bolton more like this queries which                                 works pretty well if you don't have a                                 lot of interaction data where's a                                 fallback and then something that that's                                 quite interesting is to look at                                 significant terms queries so again I                                 went to I wouldn't spend too much time                                 on this and you can come and speak to me                                 afterwards if you're interested but you                                 can effectively use a two-stage query by                                 first getting the set of interactions                                 for let's say user and so you can see                                 the items that they have interacted with                                 in the recent past and then you have a                                 second query which is a significant                                 terms aggregation which uses that item                                 set as the background set and the model                                 that is built into that will will                                 naturally surface the interesting                                 co-occurrences so it's a slightly                                 different algorithm an algorithmic                                 approach to a cur occurrence time                                 problem but you get very similar results                                 and what's nice there is that there's no                                 pre computation involved you do it all                                 at runtime                                 so that maybe a bit slower than the                                 other approaches but it's definitely                                 worth looking at okay so just to                                 conclude as I mentioned for the custom                                 ranking approaches there's a solar                                 version I actually came across today                                 this is an improved performance version                                 of the plug-in that I wrote for                                 elasticsearch so it'll be really                                 interesting to see what the impact is                                 there I mean they claim a you're up to a                                 kind of ten times performance                                 improvement so that makes those numbers                                 that I showed before significantly                                 better and you know I'd like to dig                                 deeper into the Racine internals to see                                 if we can get the benefits of doing kind                                 of bad matrix vector math as well as the                                 the custom scoring it was part of the                                 custom scoring to get speed ups so in                                 summary we have this sort of spectrum of                                 flex maximum model flexibility three to                                 maximum search integration score then                                 search sits on the one end of the                                 spectrum native search sits on the other                                 custom ranking is kind of in the middle                                 so they all have different trade-offs                                 and cost the benefits but these are the                                 three approaches and you know it's                                 obviously up to you to pick the one that                                 suits your model and your your                                 architecture okay so thanks very much                                 for your time I'd encourage you to go                                 and check out co.org                                 as well as the the IBM code patterns and                                 IBM cloud signup links if you want to                                 know more and I'll just say I just want                                 to briefly mention that IBM issued a                                 call for code which is a global                                 initiative to create open source                                 disaster mitigation solutions and                                 there's a $                                                             which is really interesting so please go                                 and check it out and I have six t-shirts                                 for that which which I'm happy to give                                 away now unfortunately only medium sized                                 but I've got six first-come first-serve                                 thanks very much                                 so we have five minute question so um                                 thank you but and what I didn't get is                                 you said that the the third superior                                 approach doesn't use any pre-computation                                 but as I see it you use some kind of                                 metric factors in factorization output                                 for this so the vectors you feed into                                 the index they come from somewhere right                                 correct yeah that's the same so                                 computation wise the same amount like an                                 item to item co-occurrence matrix it                                 probably is similar overall so if you                                 the SP computation involved it's true                                 sir you've got to train a model I mean                                 in all of them not even in the school                                 then search approach is pre-computation                                 because you need a model first compared                                 to the the very smart way of doing                                 co-occurrence so with some threshold or                                 a lot likelihood ratio probably the                                 overall computation is is roughly                                 similar but generally a matrix                                 factorization via LS or will gradient                                 descent on you know is fairly efficient                                 and you don't need to then exhaustively                                 pre compute all the recommendations so                                 that I should be more specific                                 the pre-computation is about computing                                 the recommendations not necessarily the                                 model thank you                                 other question                                 so thank you okay thank you                                 [Applause]                                 [Music]
YouTube URL: https://www.youtube.com/watch?v=7qie8NyXVag


