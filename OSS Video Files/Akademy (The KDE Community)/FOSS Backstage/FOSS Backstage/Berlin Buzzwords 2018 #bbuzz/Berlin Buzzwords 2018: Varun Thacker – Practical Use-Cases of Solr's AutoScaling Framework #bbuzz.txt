Title: Berlin Buzzwords 2018: Varun Thacker – Practical Use-Cases of Solr's AutoScaling Framework #bbuzz
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	The goal of Solr's AutoScaling framework is for search clusters to be able to grow to a trillion documents without much human intervention. The first part of the talk covers AutoScaling framework concepts. We'll talk about AutoScaling Policies and Preferences, the AutoScaling API and event triggers. 

Further, we’ll discuss practical use-cases to keep the cluster healthy and performing optimally, complete with fault tolerance. For example, we'll cover how to achieve these scenarios by utilizing the framework.

Effectively managing disk space by setting triggers and sending out alerts. Maintaining a minimum replication factor when nodes go down. We'll also use rules to make sure the replicas are spread out, thus maximizing fault tolerance.

Scaling out replicas to serve more traffic by setting thresholds. The thresholds could be latency or QPS based. We could also run it as schedulers to better serve peak load. Move replicas around to balance load across the cluster. Indexing triggers: Are shards getting too large? Support for auto shard splits etc.

Read more:
https://2018.berlinbuzzwords.de/18/session/practical-use-cases-solrs-autoscaling-framework

About Varun Thacker:
https://2018.berlinbuzzwords.de/users/varun-thacker

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              hi I'm Varun and we are representing                               lucid works giving a talk on our Soler's                               auto-scaling framework and essentially                               what we are going to learn is how how                               the Soler's new auto-scaling framework                               help you build out abstractions so that                               you don't need to deal with lower-level                               api's to make life easier for you to do                               operations within a solar cluster so the                                agenda being we cannot discuss briefly                                about what is auto-scaling                                then go through concepts like what is                                auto scaling policies what is a                                preference how does the API work and                                then how does this tie into asking solar                                to trigger and do actions on behalf of                                the cluster so while discussing these                                concepts we are going to learn and come                                up with examples of how to use this                                within your cluster so the goal of when                                like the team started working with auto                                scaling was you want to auto scale a                                solar cluster to a trillion documents                                with minimal human intervention by that                                you do not need to build deep solar                                expertise or have like a huge solar                                DevOps team to reach this goal right so                                solar should help you build this out of                                the box so that was the goal we started                                building this framework with why do we                                need auto scaling operations is hard to                                scale right like an Jung who's been                                working on the operations or the                                platform side of things you get sucked                                into this and sometimes it's                                time-consuming it's stuff to build                                expertise and you always require tooling                                around so that you can manage your solar                                cluster right you or not you can't                                manually go start moving replicas around                                that's just not a scalable model right                                so till like the auto scaling framework                                you would get very low-level api is from                                solar so you could have a ps                                        replica from machine                                                   it wouldn't tell you which is the best                                machine I should move the replica to so                                those are the things that we wanted to                                build out in the auto scaling                                framework so how in in a nutshell                                essentially you provide some constraints                                and assumptions about your cluster so                                you define some rules you define what's                                important for me you say is CPU disk                                search latency or update throughput what                                are the constraints that are important                                to you and solar will help you with what                                operations are required to reach that                                desired state now how would you describe                                the cluster right if I want to describe                                the cluster it's going to be a two-part                                process the first part is how do I lay                                out my cluster so some basic assumptions                                about my cluster I want replicas on                                unique nodes people hosting say multiple                                JVMs on the same node you don't want                                solar to add replicas such that both the                                replicas sit on the same physical                                machine right so solar can be Noda where                                things like that all replicas of a shard                                must be on the same rack so if you can                                utilize that at query time then you make                                sure that you improve Layton sees at                                least two replicas must be on the same                                rack and these are just a few examples                                of how you want to define these clusters                                right you don't you want to make sure                                that no particular solar JVM contains                                more than say for solar nodes so what                                that'll ensure is you're never                                overloading one particular JVM right you                                are maxing it out at four cores or four                                replicas the second part about                                describing of cluster is you want solar                                to provide some tools or some ways to                                understand if I reach a state where I                                have more machines or I want to move                                things around                                what is important to me so you want to                                be able to define whether system load                                average say free disk space heap usage                                number of existing solar codes so you                                want to provided some intrinsic values                                where you basically say now I'm going to                                use these to then move things around and                                we're going to talk about exactly this                                this                                driving your cluster in terms of                                auto-scaling policies and preferences so                                 let's start with auto-scaling                                 policies so auto-scaling policies are                                 nothing but it defines the desired layer                                 layout of the cluster essentially it can                                 be done at the cluster level or a per                                 collection level think of it as how many                                 people use the old replica base like the                                 rule based placement strategy where you                                 want to define some rules for the                                 cluster so this encompasses that in a                                 more holistic way within solar so the                                 example that I gave you right you want                                 to set a rule in the cluster where no                                 two replicas sit on the same node that                                 could happen if you have multiple                                 jaebeum's running on the same physical                                 machine right so you want to provide                                 rules such that so some examples that                                 for auto scaling policies would be here                                 is the syntax where you would go ahead                                 and say any node in the solar cluster                                 must not have more than five solar cores                                 of Phi replicas right so you would say                                 for any node I want to make sure that                                 the replicas count is less than five now                                 if you want to do that at a pearl                                 collection basis so now you wanna say                                 for each collection I want to make sure                                 that replicas sit on unique nodes so by                                 saying this I am making sure that my                                 collection is spread out across the                                 cluster the second example basically                                 says do not place more than one replica                                 of a shard on unknown now if you remove                                 the shard like if without the shard each                                 clause in the syntax this rule would                                 apply to the entire collection so you                                 can say for each collection offer each                                 shard now I have a use case where say                                 you want to spread out replicas across                                 availability zones right so if you have                                 hosting solar on AWS or whatever                                 provider that you use                                 I want to spread it spread my replicas                                 across availability zones so all you                                 need to do now is when you start a solar                                 noon you give it a system property just                                 a tag right so you want to give it a tag                                 saying this is availability zone                                      this is availability zone                                         starting up a solar known and then you                                 can define two rules where you're saying                                 basically for each shard make sure that                                 the replicas count is always less than                                   so if I'm creating a to a collection                                 which has two replicas I want to make                                 sure spread across the two availability                                 zones so I'm creating a rule to say on                                 the first availability zone make sure                                 you only have one replicas and do the                                 same for the other availability zone so                                 in this example I'm spreading it across                                 two availability zones and this is                                 essentially morph this nicely morphs                                 into the same example that I've been                                 talking about where multiple JVMs you                                 could start up and you could say this is                                 belonging to a system property where you                                 say this is node                                                         ensure that they're on unique nodes now                                 how does the policy EPA look like it's                                 basically saying you define this Jason                                 where you say set my cluster property                                 your policy and essentially you give it                                 all the rules that you want the cluster                                 to obey so every action that you now do                                 on the cluster will obey these rules and                                 if it can't be satisfied you will not be                                 able to complete that operation so                                 policies went and said these are my                                 heart rules that I want to define for my                                 cluster the second aspect was I want to                                 be able to define some preferences which                                 is basically a language to define load                                 is how I look at it what you're telling                                 solar is within you have multiple knowns                                 how do I say which one is more active so                                 if I want if I get more resources which                                 is more burdened and which replica from                                 those nodes can I move to some extra                                 hardware right so you want to define a                                 language where you can specify what's                                 important in your case so preferences                                 since the defined load is essentially                                 only at a cluster level the policies                                 could be at a cluster level or it could                                 have been at a per collection level but                                 preferences always apply to the cluster                                 level these aren't hard conditions so a                                 policy was a hard condition where you                                 said make sure that they're never                                 violating a rule where availability                                 zones can have more all my replicas                                 right but preferences is not a hard rule                                 we are saying how do I sort that how do                                 i define the cluster load so a few                                 metrics that you could say define your                                 cluster load on would be saying the                                 number of solo course if free disk is a                                 concern you can define it on the disk                                 space that I have left on my nodes the                                 heap usage so if you're using a lot of                                 caching in solar then like maybe you                                 have more replicas sitting on the node                                 and the heap usage is high so you want                                 to make sure that you want to control                                 have control over that or like load                                 average right so you could pick these                                 metrics and say what is important to me                                 and once you define this essentially it                                 will tell solar if it has to move things                                 around which replicas from which node to                                 pick right so the syntax and how you                                 would define a preference is essentially                                 what you tell solar is minimize encores                                 or do you want to maximize on free disks                                 right so you spread you basically give                                 it the sort order where you say minimize                                 or maximize and then you say the metric                                 or the condition that you want to define                                 it on so I want to minimize on course I                                 want to maximize free disk minimize the                                 load on                                 system obviously and essentially this is                                 the syntax how you would define it okay                                 so there were criterias in this syntax                                 where like you don't wanna judge - so                                 learn owns if that disk space there                                 first were like a gigabyte or like five                                 gigabytes read that might be some                                 intermediary proceeded like that's not                                 enough reason to say node one is more                                 important than node                                                   this option called precision where you                                 basically tell solo that if it's within                                 a precision level of in this case                                       both nodes treat them equally right so                                 if the difference between the values of                                 free disks for to solar nodes is within                                 this precision level they are considered                                 equivalent now you can define multiple                                 preferences and what you can then tell                                 is that the precision can have you can                                 have multiple preferences and if you                                 have the same disk space then you move                                 on to the next choice right you move on                                 to the next preference that you've                                 defined so you can define a list of                                 references that solo will sort solar                                 like the nodes on the EPR to do such a                                 thing would be you would say defines                                 cluster preferences you would define the                                 rules that you care about so here I'm                                 saying I want to minimize the solar                                 course on each node and if the solar                                 nodes happen to have the same number of                                 course then Pig disk space as the metric                                 to say this machine is more loaded than                                 the second machine right she's defining                                 multiple preferences in this case if you                                 just want to play around with this and                                 understand once you have defined this                                 how this actually works and how is it                                 picking one solar node over the other                                 there is a Diagnostics endpoint where                                 you are basically it's giving you the                                 sorted order of how it assumed that                                 solon old one was more important than                                 solar node                                                      obviously this is something that's new                                 you're gonna start playing around with                                 it so you want to understand how the                                 feature works and the diagnostic API                                 here can be very useful because you want                                 to be telling solo that sorted on these                                 criterias and understand how it works so                                 there is a sort node sorted nodes order                                 and then essentially if you were                                 violating right remember how I said a                                 preferences is not a hard criteria right                                 so but if you were still over the limit                                 you would see these violations that you                                 would then go ahead and be able to act                                 on so can you see how these tools can                                 help you build or make life for DevOps                                 easier right you are using these tools                                 to now visualize how my cluster is                                 performing you don't need to row longer                                 right EPS to figure these out you are                                 just defining a language and saying this                                 is what I care about you tell me how is                                 my cluster behaving so these were the                                 building blocks where policies and                                 preferences can be used to figure out                                 what to do on a solar cluster now when                                 we added these features they were added                                 so that all the collection api's                                 automatically used these policies and                                 preferences so if you go to create a                                 collection your create collection might                                 fail if one of the policies that you had                                 defined is not met by the criteria right                                 so if it's an impossible task solar will                                 stop and say you know what you cannot do                                 this so the policies will be violated                                 and you'll be getting a hard error and                                 creating the collection when you add a                                 replica today you would need to build                                 some smarts and be able to say                                 when I'm adding a replica where should                                 the replica decide today solo might just                                 pick a node randomly right what you want                                 to do is you want to use the preferences                                 and policies to now just say add a                                 replica and solar will go figure out                                 which node to add it on so the smart                                 that you have to build in to figure out                                 which node it had to go to is now                                 abstracted away similarly when you split                                 shards or you create a shards so if                                 you're doing manual routing you can keep                                 adding shards over time you can use                                 these to figure out where should the                                 shards land up and when you back up and                                 restore collections while doing a                                 restore you need to figure out where is                                 the ideal place to restore a solar                                 collection so the restore API also taps                                 into this so this section of the talk                                 was essentially defining policies                                 defining preferences so that when you do                                 these low-level I would how I define                                 low-level commands is an ad replica                                 today in solar when you said add                                 replicas                                 I have to manually say which node should                                 it go to so its abstracting all of these                                 away and just helping you improve the                                 experience so with this now that we had                                 all of this in place we could tell solar                                 add a feature where whenever you create                                 a collection maintain my replication                                 factor so it might not be obvious to a                                 lot of people who started solar like                                 newly that when you add a collection or                                 create a collection and you say I want                                 three copies of a shard right you say                                 give me three replicas if a node was to                                 go down solar would not maintain its                                 replication factor so you could be down                                 to two replicas and you would not                                 realize this right so solar would not                                 automatically add the third replica on                                 nodes that were remaining so that the                                 replication factor was continued through                                 the life cycle of your cluster you                                 needed to build two                                 to make sure that if a node went down                                 figure out which replicas resided on                                 that and to add them to the other nodes                                 so now you can enable something called                                 Auto add replicas where essentially it                                 will auto create these triggers we'll                                 talk about triggers in just a minute                                 where the replicas will get added to                                 maintain the replication factor                                 obviously this uses the defined policies                                 and preferences while adding the new                                 replicas all you need to do is while                                 creating a collection pass auto add                                 replicas equal to true while creating                                 the collection and this feature will be                                 enabled by default so the experiment                                 that I did while present like making                                 these slides was I had multiple nodes on                                 different availability zones and what I                                 was able to achieve was if I killed a                                 node on one availability zone solar                                 would go maintain the replication factor                                 so it would add a replica and it would                                 also respect the fact that I had defined                                 rules to say maintain replication factor                                 such that availability zones the concept                                 well not more than two replicas should                                 be on each availability zones so while                                 adding the replicas it wouldn't go and                                 create it on the other availability zone                                 and now you'll have both my replicas on                                 the other side of the other zone right                                 so all of these this API or this feature                                 now works with the policies and                                 preferences that you define so this was                                 the task that I kind of just tried out                                 as an example so that we can speak about                                 it now that this was added this feature                                 kind of leverages internally something                                 called solar auto scaling triggers and                                 then event listeners so essentially till                                 now you were defining rules till now you                                 were defining preferences but solar was                                 just giving your Diagnostics API red                                 hood till now what we learned was you                                 just got to see                                 how is my cluster behaving at the                                 current point of time but what if now                                 you want to go and say do something with                                 it right so act on it so which is why                                 solo or alike auto-scaling                                 triggers were added so triggers once                                 activated perform actions such as                                 evaluating the system against the                                 configurations that you have defined so                                 in solar                                                             that were introduced the two triggers                                 mean if a node leaves the cluster or if                                 a node joins the cluster what do you do                                 when these two events happen so by                                 default what happens is in both cases                                 you move replicas around to balance the                                 load so if a node comes up you want to                                 say oh you know what I have an on new                                 node I want to balance my cluster so                                 there was a node that had more cores or                                 more replicas you want to move them                                 around so you would set them add node                                 added trigger and it would go and do                                 this thing in solar seven three more                                 triggers were added so you could add a                                 search rate trigger that means anytime                                 you cross a certain threshold of queries                                 per second you could do like operations                                 on it you could set our schedule trigger                                 to do something if on a periodic basis                                 all you could use solar metrics so solar                                 has a matrix endpoint which has over                                     metrics that it captures on each solar                                 noon so you could leverage these metrics                                 like a search it or an index throughput                                 or requests per second or high CPU                                 volume or high GC all of these metrics                                 that solar collects you want to utilize                                 that and say now do something based on                                 this metric so it was very generic and                                 could allow you to do that here is how                                 you would define a node loss trigger so                                 I say define a trigger called node loss                                 and you basically say wait for                                    minutes so don't just go as soon as this                                 event happens start moving things around                                 maybe I actually provision this node                                 because I wanted to create a new                                 collection or I wanted to do something                                 that I wanted solar to not move things                                 around because I there was something                                 else I had in mind                                 so you basically define a wait for and                                 triggers can be suspended they can be                                 paused and it can be resumed so it's not                                 like once you define a trigger like you                                 need to delete them to get solar to stop                                 doing any actions on it and like we                                 covered in this slide if you do a node                                 lost or a node added sugar                                 it was just move replicas around since                                 that seemed like the logical step to do                                 when you define these triggers similarly                                 you say a node added trigger the same                                 syntax you now the the one that kind of                                 caught my attention was this search read                                 trigger right what you wanted to see is                                 how do I tell solar during peak ours I                                 want to expand or I want to be able to                                 add replicas so that my search volume                                 once it goes high through the day it can                                 expand and serve traffic in a more                                 graceful manner so the search rate                                 trigger was added in solar                                           essentially it monitors the                                          average search rate so it sees the                                 average search rate for a minute and                                 then you can define what to do in that                                 case you can define the search trigger                                 on a pearl collection basis a pearl                                 shard basis or a pearl on a node basis                                 so you can say have a hundred QPS on a                                 solar node and then I want to do an                                 action on it or you can say if a                                 collection gets more than                                               second I think that's reaching a point                                 where I need to add more replicas so                                 since it provided you options to do it                                 on a per node or on a more                                 Lepore collection bases the default                                 actions that come with it were different                                 so when we define it for each node right                                 so when you say it doesn't cross more                                 than                                                                     want solar to do is at that point move                                 things around and make the load on that                                 node less so it moves to the default                                 action your is it moves the replica                                 which has the highest search it to                                 another noon now if you define it on a                                 pearl collection basis right so now when                                 you see if it doesn't go more than                                    coop queries per second for a shard or                                 for a collection the default action that                                 solar will take when you define this                                 trigger is it will add a replica for                                 this shot that goes above this threshold                                 so the default actions vary based on if                                 you define it on a pearl collection                                 basis or on a pearl shard basis or upper                                 node basis the API that you would define                                 this would be you would say I want to                                 create a search rate trigger wait for                                    minutes so capture the matrix and by                                 default in this case since it's on the                                 node level it would go and move things                                 around from that node to make the                                 queries even distribute out evenly so                                 when I now though when I tried this                                 exercise out I looked at this and I said                                 oh ad queries I said like                                                the metric that it was capturing was the                                                                                                      what if I fire                                                          like I will achieve this and solar will                                 do something but like the documentation                                 clearly stated and I had missed this                                 part was essentially it means you need                                 to have a ATS queries per second so it's                                 not per minute although the metric that                                 it's capturing is the                                                  so it wasn't really obvious to me like                                 but seems silly at that point                                 but when you say a tu what you mean is                                                                                            now that these triggers were added the                                 trigger has an action related to it                                 right so all these actions that I'm                                 talking to you about is because solar by                                 default says if you define a trigger you                                 can act on it because that's why you                                 want to define this trigger so the two                                 actions that it supports is a compute                                 plan so it looks at the trigger that                                 you've defined and it says oh you've                                 created a search a trigger and you                                 define it on a per node basis so the                                 compute plan will say move a replica                                 sale of a collection that had the most                                 queries to some other known so the                                 compute plan generates this list of                                 actions that you want solar to perform                                 and the execute plan obviously carries                                 out the operations so if I was to take                                 the whole thing and put it in an example                                 here is how I would say I would define a                                 node added trigger so when you define a                                 node added trigger you want to wait for                                 say                                                                action so you've explicitly said compute                                 a plan and then execute it right now                                 what I thought is III won't know at this                                 point I'm like thinking from a DevOps                                 hat right I'm like you know what I don't                                 trust this just yet what I want to do is                                 I want solar to definitely know that a                                 node was added or the example that I                                 played around with was the search rate                                 trigger right as soon as Serge goes                                 above a threshold                                 I don't want solar to execute the plan                                 so I don't want solar to actually go and                                 start adding replicas moving things                                 around but I want a notification I know                                 that something needs to be performed on                                 the cluster something's not right                                 so if you remove the execute plan like                                 solar will not actually do anything with                                 the plan it will just compute it and                                 tell you oh you need to move replicas                                 X from machine                                                         you look at it you're like ah that makes                                 sense let's go and execute them right so                                 it's like a manual validation process                                 that you might want to do if like you                                 want to be more paranoid and like you                                 probably want to when you're starting to                                 try out a feature new so you could                                 remove this and one thing to keep in                                 mind if you don't define any actions                                 this actions will be performed by                                 default so unless explicitly defined and                                 said you know what only do the compute                                 action plan and not the execute it will                                 go ahead and do both the plans so                                 explicit using the explicit API and say                                 exactly what you want out of the                                 auto-scaling                                 trigger ray now once this trigger was                                 implemented the last section was can I                                 act on it in different ways right                                 apart from executing the plan can I have                                 a listener can I have solo do certain                                 events with it                                 so you're basically I'm saying trigger                                 listeners are nothing but are attached                                 to a trigger to notify important                                 lifecycle events now example of a                                 lifecycle includes a trigger being                                 activated when you abort overall success                                 so when you're moving replicas around                                 you will get notifications that you know                                 what node was added started moving                                 replicas done or failed so you would get                                 notifications now with these listeners                                 today solar has two listeners with it                                 one is it just writes out what                                 operations it's doing to the underlying                                 system collection                                 so it writes this out to the system                                 collection so you define the underscore                                 system collection and every time this                                 trigger is activated you basically                                 create document document saying node                                 added starting operation aborted field                                 success all these events so you can                                 scroll through it and even get a                                 visualization or something if you want                                 to play around and make design a                                 handcrafted solar query to see what was                                 happening the other event listener that                                 solar added was a HTTP listener so an                                 example of the HTTP listener is                                 basically you're saying I want on the                                 trigger that I define on stages aborted                                 succeeded or failed on these three                                 stages of the trigger send out this hit                                 this URL right so the experiment that I                                 did for this talk was I created a search                                 rate trigger I said you know what I                                 don't want solar to go add replicas                                 I just want to define this trigger and                                 then I want to define this HTTP listener                                 to send out alerts to a system right so                                 define the trigger define this alert and                                 you can get maybe an email notification                                 you can integrate this with your cloud                                 provider so that if the search goes                                 above a threshold this will send out a                                 notification to the cloud providers to                                 start spinning up more instances so you                                 can use listeners in that sense so                                 that's all I had for the talk we covered                                 the basics of auto scaling and like                                 hopefully these use cases will help you                                 start using them in ways to help your                                 management of your cluster                                 yeah thank you                                 Thank You bell ringing yeah I see                                 Henry's hello thank you for the talk I                                 wondering if for example you have                                 specified some rule to move your replica                                 to another note if you reach some QP s                                 yeah but well these note reached this                                 level of QPS you moved the replica shirt                                 then this note will reach this solovki P                                 we could be s so you move it back so all                                 the time so we'll just move which is                                 when you want to start off it is you                                 want to create an alert so that you see                                 what's happening in the system right you                                 might not want to trust this in the                                 beginning but what I assume what happens                                 under the hood is since it's moving to                                 the other noon solar also captures the                                 metrics on the other node so if this is                                 not I'm not                                                             move the replica to this node if it's                                 essentially going to violate it there                                 right like so when you use the                                 Diagnostics API it would come under the                                 violation section so it's gonna say you                                 know what there's something wrong but                                 I'm not I can't do anything about it                                 because like it's not going to be a good                                 action anyways so those come under the                                 Diagnostics violations yeah but you have                                 enough resources to move it so there                                 yeah so you do not violate the rules so                                 it's throw its way and every node will                                 just throw it right so so it wouldn't it                                 should not perform the operation and say                                 you know what I'm above the threshold                                 but there's no good action to it you see                                 what I'm saying so you can either                                 specify to move it or just to send it an                                 alert                                 yes No so but if what I'm saying is the                                 move is not mandatory right in this case                                 so it will say it when it goes to move                                 it realizes that the move operation                                 will lead to the other node going above                                 the metric rate trigger right so it will                                 say this operation was aborted right                                 that's where this there were stages in                                 that operation so it will actually not                                 perform the mood and it will come under                                 the violations section when you use the                                 Diagnostics API you know why - it's a                                 violator are you ok we'll take this                                 offline but I'll like maybe it's not                                 very clear I can't have a similar                                 question on that there's a a similar                                 concept when you use a thing called                                 hysteresis to make sure that you don't                                 bounce something between two states to                                 again and again and it's I think that's                                 what you're asking                                 yeah maximum yeah move a replica offer                                 off a node and all there's lots more                                 displaced now all I can now who's about                                 to get back home to this nodes lots of                                 disk space now you need it's not in its                                 infinite set of actions to satisfy the                                 cluster right ok right yeah the other                                 question here it's also going in that                                 direction so before I touch something                                 like moving it so for example if I have                                 something like system load in here in                                 your wheels it does it also figure out                                 if I to that action that maybe on the                                 other machines the system load then goes                                 too high so because it's not easy to                                 calculate in that case but are there                                 some assumptions in it that so just does                                 it just add the statistics and figure                                 out because it would not make any sense                                 if it would make it worse and yeah I'm                                 not sure that system load but I'd                                 definitely imagine that like we want to                                 do something if I'm not a hundred                                 percent sure if you already do it where                                 if it goes above the search rate that                                 you can actually calculate if you hang                                 with to the other unknown then you can                                 whether it will go above the threshold                                 or when you move it and the disk space                                 issue right so solo might abort                                 their operation in that case I don't                                 know whether it's already there or                                 something that's in the plan I can check                                 that offline and get back to you but                                 like system load average will definitely                                 be like another challenge because you                                 it's not easy to go and say you know                                 what I have five replicas on a note but                                 which node is taking the actual                                 resources right so that's probably like                                 a tough one there yeah like those are                                 some things that you can calculate                                 before you actually do the operation I                                 think won't be useful to add to this                                 would be some sort of limit like go and                                 do this operation a maximum of three                                 times okay that's what I'd like so that                                 it doesn't bounce infinitely right like                                 so maybe that's a clearer ticket that                                 we've got to create yeah that's already                                 working on it like absolutely so and by                                 putting a limit in there maybe having a                                 that secondary trigger where it can                                 notify you you know you can alarm off of                                 that and say I've reached a maximum                                 amount of actions that I can take let me                                 notify an operator so that we can now                                 get a human involved but I've done                                 everything I've yeah so that's and like                                 in his case it gets even worse where if                                 you move replicas to the other node and                                 that node starts this trigger and picks                                 some other replicas right so then even                                 this limits might not come into play                                 because you're like it's picking                                 something else right it's not doing the                                 operation on the same replica round                                 well-like the good thing about is I'm                                 not a hunt like you should definitely                                 try it out                                 remove the execute plan let it compute                                 gain some confidence see what it's doing                                 send out alerts start getting your feet                                 wet with that and feedbacks always                                 welcome like stuff like this I'm sure                                 these are concerns that we want to                                 address and I'm like couple of them                                 might already be there I'll have to                                 check and another question yeah if the                                 trigger triggers action right which is                                 unlikely but you noticed so that it                                 begins it's beginning to afraid this                                 action do you have an API to cancel it                                 so you know it's wrong yeah you might                                 like like you can't undo that operation                                 right because like it's a set of                                 collection API calls so you're saying                                 add replicas and like that's all in                                 process so to roll that back like it                                 would need to store state of the whole                                 action right through the whole lifecycle                                 so you'd rather wanted to either do                                 nothing or to trust it and then like                                 completely it's like like just compute                                 it right okay I'm sorry I'm the Qun a                                 because of your honor of time and thank                                 you very much Varun give him a big hand                                 again                                 [Applause]
YouTube URL: https://www.youtube.com/watch?v=D4bi8Pfc4Ts


