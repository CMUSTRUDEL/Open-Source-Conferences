Title: Berlin Buzzwords 2018: Sönke Liebau – Kafka Security - A brief overview of its history ... #bbuzz
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	Sönke Liebau talking about "Kafka Security - A brief overview of its history, current state and how it can be customized".

Kafka Security has come a long way since its early days when none was available whatsoever. In this talk I will give a brief overview of how security evolved in Kafka and explain what currently works, as well as giving a brief outlook into what is currently being developed by the community.

We will discuss authentication via SSL, Kerberos und Delegation tokens and touch the Kafka versions that introduced these features and related major changes. Following that I will explain how to use ACLs in Kafka and how they are implemented internally, which will then serve as the basis for diving down into development of custom authorizers and principal builders to extend the basic Kafka Security - for this we will use the example of authorizing based on the groups a user is assigned in an Active Directory structure.

The talk will be fairly technical, we will look at class structures of Kafka and look at how they interact with each other as well as look at code for an example of extending Kafka security features. However non-technical listeners will also gain i solid understanding of what is possible out of the box and what isn't.

Read more:
https://2018.berlinbuzzwords.de/18/session/kafka-security-brief-overview-its-history-current-state-and-how-it-can-be-customized

About Sönke Liebau:
https://2018.berlinbuzzwords.de/users/sonke-liebau

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              hello everybody thank you for being here                               yeah as he just danced I'll be talking                               about Kafka security a little bit of its                               history and how you can customize it as                               well as what it can do today first a                               little bit about me I'm a partner and                               co-founder at open core which is a well                               tiny consulting company in Germany we                               are three people and we focus                                exclusively on big data and open source                                projects and my personal focus is Kafka                                and holistic search those are my two                                things which is also why I'm standing                                here today I promise to keep this brief                                since you're here you probably all know                                what Kafka does and I've even seen a                                Kafka shirt and the audience somewhere                                so it is a distributed topic oriented                                partitioned replicated commit log so                                basically what that means is you stick                                data in on one end and you get it out it                                on the other end the important                                distinction here being that it's also a                                publish/subscribe system so it doesn't                                actually send you the data but you need                                to connect to it and retrieve the data                                in a active fashion so Kafka itself is                                never the active part in any data                                equation you always need to connect to                                it and retrieve your data and everything                                else internally replication and things                                like that it takes care of for you and                                does that without you noticing it much                                so where does it fit in today's data                                platforms I've stolen this slide from                                confluent blog post so of course Kafka                                is drawn in the middle of the picture                                this is that's just the way that they                                see the world so at the top you have all                                your source systems whatever those might                                be for a bank or automobile vendor or                                insurance company that'll be different                                for each and every one but then all of                                them sent their data towards Kafka and                                what happens then is different depending                                on what you want to do with the data you                                can of course take it out do some                                processing on it join some streams                                create some materialized views or                                whatever you need for your specific use                                case and then stick the data begins                                kafka you can also do real-time                                analytics and feed dashboards out of                                Kafka in real time as the data comes in                                but of course for larger analytics use                                cases you'd probably want to stick all                                your data into HDFS or a more                                traditional data warehouse in order to                                get back to it later and do larger                                processing jobs but what this means is                                pretty much all of your data at some                                point in time is in calf comm which of                                course allows the question what about                                security can we keep it secure in there                                or is that like an open hole in our                                entire security architecture back in the                                day                                                                     that was taken towards security this                                picture is from a TV show called Burn                                Notice about a spy who keeps getting                                into trouble and I think here he has a                                meeting with a crooked cop or something                                and he calls this the ring of trust                                you're either in or you're not and for                                us IT guys of course the wall of fire is                                a quite a good analogy because back in                                the day if you could get through the                                firewall to a kafka you could get data                                out and in and even delete stuff so it                                was a fairly black-and-white picture of                                what you could or could not do but since                                Kafka was developed a bit further and I                                think the the big turning point here was                                when confluent was founded and they                                started developing in earnest on the                                product and putting it out into the                                market so a lot of people are using                                Kafka today and security became more and                                more important so there has been a few                                improvements made over the day over the                                years the first and biggest step was the                                implementation of SSL for authentication                                as well as encryption and Kerberos as an                                authentication mechanism and then later                                on they also added sessile plain                                mechanism sessle's graham and recently                                delegation tokens was the                                youngest addition to the kafka security                                family there's a little bit of a history                                 of when this was implemented you can see                                 version oh nine that was the biggie that                                 brought us SSL and Kerberos and                                 authentication as well as authorization                                 in general so this was the huge code Rob                                 that actually made security possible at                                 all and you can also see that those two                                 were develop sort of together back here                                 the zero numbers zero is the the                                 official Apache bug tracker where things                                 like this are kept track off fairly                                 close to each other and they've actually                                 been documented in the same Kip which is                                 a kafka improvement proposal so any                                 larger or large exchange or pretty much                                 anything that changes public-facing                                 behavior of Kafka needs to be designed                                 as a Kip so sort of documented and                                 discussed before it's actually approved                                 for implementation and you can see that                                 SSL and Kerberos were put into the same                                 Kip for development and that both of                                 those landed a no.                                                  stuff and I'll explain the abbreviations                                 on the next slide and was already there                                 it was fairly obvious to put to have                                 additional implementations in place so                                 the first one that was added was plain                                 which is just username and password and                                 then scram came later on and as I said                                 delegation tokens just hit us in                                         you can see delegation tokens the zero                                 number is actually fairly small as well                                 as the Kip number comes before for                                 example sessle's gram as well so that                                 features a bit larger than the others                                 and has been in development for quite                                 some time                                 and it actually piggy backs on the on                                 the sessile and scram implementation so                                 that was probably also one of the                                 reasons why it took a bit longer because                                 they waited on those to be finished                                 right so abbreviations Cecil is just a                                 simple authentication and security layer                                 which is basically an abstraction of                                 different security                                 and authentication mechanisms so                                 basically - it's just a wrapper around                                 some authentication method and we saw                                 plain plain text and scram male Jas is a                                 way of telling Java how to how to do                                 security so basically in your Jas file                                 you will tell Java that you want to use                                 settle and then GSS API is sort of the                                 same thing as sessile and someone who                                 knows better than me would probably                                 start yelling at me right about now but                                 for me it's also just a wrapper around                                 security mechanisms so if we use                                 Kerberos with Kafka we write a Jas file                                 tell it to use tehsil which then wraps                                 gssapi which then again reps Kerberos                                 which probably has some other mechanism                                 under the hood for authentication again                                 so all of this is fairly convoluted you                                 might say and scram is the Salter                                 challenge and response authentication                                 methods which does away with sending                                 passwords and plaintext over the network                                 layer and we'll have a look at that in                                 more detail on one of the next slides I                                 think all right so what's the                                 authentication options that we have SSL                                 is a fairly obvious choice everybody                                 sort of knows it you have a central                                 point which is your root certificate                                 authority and that signs certificates                                 that you have an issue to your users and                                 servers up here is a server certificate                                 so you can see that you actually have                                 the server name in here and down here a                                 user certificate would not have a server                                 name but rather just my personal name                                 that this was issued to and the way that                                 this thing works is whenever the user                                 connects to a Kafka server and this                                 instance could be anything else as well                                 first the server sends the user his                                 certificate and the user then checks                                 whether this certificate was issued or                                 signed by a certificate authority that                                 he trusts                                 if not then everything fails the second                                 step is that the the users process then                                 checks whether the server                                 name actually matches the server that                                 sent him the certificate which by                                 default is turned off in Kafka if you                                 want this feature then you need to                                 switch to the default to turn this on                                 and at this point the process can stop                                 but the only thing that we achieved then                                 is that we authenticated that the server                                 is who we think he is                                 and we encrypted our communication for                                 authentication of the client or the user                                 down here also needs to send his                                 certificate up to the server so that the                                 server can have a look at it and see if                                 this user is someone or assigned by a                                 certificate authority that he trusts as                                 I said this is fairly well known                                 throughout the the industry most larger                                 companies run cas of their own so this                                 in theory should be easy to implement                                 but walk into a customer's office and                                 tell him that you need five certificates                                 signed by their root CA to set up the                                 server and see what they how they look                                 at you most people actually have trouble                                 with this another issue with this is if                                 a certificate gets stolen or lost then                                 there's no easy way of revoking it                                 certificates usually are valid for one                                 to three years                                 are they the normal terms that you see                                 so if someone gets a hold of one of                                 these certificates and of course you can                                 use it to connect to your cluster and                                 the normal way of taking care of this                                 would be via certificate revocation                                 lists which the server process checks                                 and if the certificate is in there then                                 it wouldn't be accepted as valid however                                 Kafka doesn't do this                                 there's a an open zero for it it's been                                 around for a couple of years now I think                                 and there hasn't been much activity on                                 it so I wouldn't hold my breath whether                                 they'll be intermittent anytime soon and                                 if you sign your certificates with the                                 shorter validity so there's been some                                 discussion around that on the mailing                                 list recently as well you could say sign                                 is certificate just for one day but you                                 need to restart every process that that                                 uses this certificate so that'll that                                 would make you restart at least your                                 clients fairly often if you wanted to do                                 this and there's better options as we'll                                 see on the next couple of slides and one                                 last thing about certificates they                                 always run out at the wrong time you                                 should think that you can actually                                 predict fairly well when a certificate                                 runs out because it's like a fixed date                                 but for some reason everybody is always                                 surprised when it's the certificate                                 expired and then it's Friday before a                                 long weekend it's the Christmas party                                 and your security guys on parental leave                                 and it just doesn't work so so still                                 plane is pretty much just username and                                 password you can figure out via a jas                                 file we've put a Kafka's server                                 configuration snippet of VM and I took                                 this from the official Kafka                                 documentation so if you want to read a                                 bit more about this that's where you can                                 find that as well and as you can see the                                 username and password up here that's how                                 the Kafka brokers talk to each other so                                 this would be used for inter broker                                 communication and then you just stick                                 additional users down here and when your                                 client connects he can send those                                 usernames and passwords along and those                                 would be used for authentication of                                 course it's not really nice to put                                 usernames and passwords in a plain text                                 file like this so up here you have the                                 plain login module you can extend that                                 and customize that to retrieve your                                 passwords from I don't know Active                                 Directory or some sort of database                                 somewhere or use a Hadoop key management                                 server whatever is used in your                                 environment you can connect to that and                                 do this however your password will be                                 sent over the wire in an unencrypted                                 form unless you combine this with                                 transport layer security so this is a I                                 wouldn't recommend this for a production                                 environment necessarily sessile scram is                                 has been invented to pick up on that                                 exact limitation so this the main reason                                 here was to avoid sending clear text                                 passwords over the net so what this does                                 is                                 and I can't really explain this I'm                                 sorry but it sort of sends a random                                 value to the server the server and                                 responds with the challenge which only                                 the client who knows the password can                                 generate a valid value for and that way                                 they sort of figure out that both                                 parties know the password and that it                                 matches without actually transmitting                                 the password over the network passwords                                 for this actually not stored in the Jas                                 file anymore you can see we only have                                 the the admin for inter broker                                 communication up here any more passwords                                 for this a store and zookeeper so in                                 order to administrate this you'd need to                                 be able to access the paper and put                                 stuff in there and what's this also an                                 additional feature that this has is you                                 can bind it to your transport layer                                 security which means that the                                 information from your certificate is                                 somehow part of the exchange for the                                 server for added security to ensure that                                 you actually are who you say you are                                 right sessile gssapi this is the where                                 the money is literally because if you're                                 good at solving Kerberos issues then you                                 can make a lot of money consulting                                 everybody has them and nobody knows how                                 to figure them out                                 Kerberos can be used but actually as I                                 said gssapi is also a reference security                                 mechanisms but it when I say gssapi                                 today I mean Kerberos because this is                                 the only implementation that Kafka                                 supports in this way and it can be used                                 to integrate with Active Directory or                                 different directory services so what                                 that means is your user can on the                                 command line type K in it with his                                 username you'll be asked for his                                 password and that password will then                                 actually be checked in your corporate                                 Active Directory and if that user has                                 the correct password then you'll get a                                 ticket back and can use that extra                                 services there's two different types of                                 principles in Kerberos there's one                                 that's the user principal name which is                                 Who I am                                 so that can be used from pretty much any                                 any machine                                 and service principle names are usually                                 bound to a specific server that's the                                 same deal as with a certificate where                                 the user checks whether the server who                                 sent it is also the one that was issued                                 this certificate yes and as I just said                                 the initial authentication is via                                 password which of course does not work                                 if I want this to run as a automated                                 process that can be restarted or come up                                 when the machine comes up so that's                                 there's also the concept of a key tap                                 which can be used to retrieve a ticket                                 and that key tap is pretty much your                                 password in the file it's a little more                                 complicated than that but what it boils                                 down to is if someone gets a hold of                                 that file he is you for all intents and                                 purposes so protect those files well and                                 on the next slide we can see our                                 Kerberos authentication sort of works so                                 if I'm a client and I want to access the                                 Kafka server back here what I do is I                                 contact the key distribution center                                 which would be Active Directory in the                                 example we just have and try to get a                                 ticket granting ticket the TGT for                                 further speaking the KDC then checks                                 whether I have a valid key table or a                                 password and a little bit more there's a                                 reverse DNS lookup and stuff like that                                 and then I get a ticket back which is a                                 ticket granting ticket sorry in the next                                 step when I want to access cop car I                                 again go to the KDC but this happens                                 transparently in the background I don't                                 have to actually do this myself and with                                 this ticket granting ticket                                 I asked the KDC for a ticket that allows                                 me to incur at open court calm Texas                                 Kafka server one at open court chrome                                 which is that guy back here and with                                 this ticket that I got I'll actually go                                 to this server who can check the ticket                                 without actually talking to Active                                 Directory and if all is well I'm allowed                                 to exit the server so if we now have a                                 larger Kafka cluster say and a hundred                                 machines and I read from a topic that's                                 fairly well distributed across the                                 entire                                 cluster then of course I need to go out                                 and get a ticket for each and every one                                 of those servers and if it's not just me                                 doing this but it might be a smart job                                 that runs distributed over                                           then there'll be quite a few tickets to                                 be issued and maybe I that job retrieves                                 the data and wants to store it into HDFS                                 so again go to the KDC and grab quite a                                 few tickets for storing the data into                                 HDFS so if you have larger jobs there                                 can be quite a bit of pressure on your                                 KDC when you run these so that was one                                 of the main reasons the other one being                                 for distributed jobs if you wanted those                                 to run for a long long time you had to                                 give your key top to the job and                                 distribute that throughout your cluster                                 which as I mentioned you want to keep                                 your feet up fairly close to your heart                                 so people were not too happy with that                                 so then Kafka adopted something that was                                 I was probably not invented in the                                 Hadoop world I'm fairly sure other                                 systems have it as well I first came                                 across it in the Hadoop world so for me                                 it's always been in Hadoop invention so                                 called delegation tokens so those hit in                                 Kafka                                                                   is after we authenticate with a primary                                 authentication method against Kafka so                                 SSL or Kerberos plain Ostrom pretty much                                 anything works we can tell Kafka that                                 we'd like to have a delegation token for                                 the user that we currently authenticated                                 s and then Kafka will pretty much just                                 generate a random value stall that                                 internally and give that back to me and                                 what I can then do is I can use this                                 token to authenticate as myself so if I                                 have for example a distributed spark job                                 I'll just take that token and head it                                 out to all the executors and they'll use                                 that token in their communication with                                 CAF calm and Kafka will say write                                 eurozone Co but the job's never had my                                 key job or needed a certificate or                                 anything else                                 these tokens of course are only valid                                 for Kafka so if someone steals one of                                 those he couldn't use those to access                                 HDFS any database nothing else also                                 these tokens are only valid for a                                 limited amount of time by default they                                 are valid for a day and you can renew                                 them for up to seven days after that                                 there's no way of renewing these unless                                 of course you change the configuration                                 as always nothing that can't be                                 configured after those seven days you                                 need to real CENTAC eight with a primary                                 method of of authentication and get a                                 new ticket so if one of those tokens get                                 stolen and someone actually manages to                                 use it to retrieve data seven days is                                 the maximum that he can can do that for                                 and of course unless certificates or                                 unlike certificates it's fairly easy to                                 revoke these you pretty much just talk I                                 forgot to delete that token and because                                 it's thought internally there once it's                                 gone it can't be used for authentication                                 anymore so the main focus of these                                 things is to be used in long-running                                 distributed jobs so spark streaming and                                 spark streaming actually has internal                                 methods of obtaining these delegation                                 tokens and renewing them for you it just                                 doesn't have these for Kafka yet so if                                 someone feels like building that                                 implementation the entire community                                 would very much appreciate that                                 yeah so this is just the picture there                                 was supposed to click - all right so we                                 have quite a few different                                 authentication methods and we couldn't                                 happily mix and match those in our cop                                 car broker configuration so as you as                                 you see up here you can search the plane                                 and then you can also combine that with                                 SSL sessile plane so your broker                                 configuration you can pretty much have                                 as many ports as you like open with                                 different authentication mechanisms and                                 you just need to keep track of those in                                 your client configuration to be sure                                 that you always connect to a matching                                 port in recent versions I think it was                                 in oh                                          I put it down here Oh                                      there was a change in the way that this                                 is configured it used to be a bit                                 problematic in some Network scenarios                                 especially if netting was involved or                                 you had to go by a proxy to access Kafka                                 then sometimes there was a bit of an                                 issue because your client always                                 connects to the the internal IP address                                 of your Kafka brokers and if that                                 differs from for example a nut server                                 along the way then sometimes there could                                 be issue so sometimes it actually was                                 not even possible to have that scenario                                 so in later versions past                                              actually distinguish distinguish between                                 external and internal network traffic                                 which makes those scenarios much easier                                 to accommodate ok so far we've talked                                 about authentication only so now the                                 cluster knows who I am when I talk to                                 him but so far that's only so much we                                 had already before with the firewall so                                 we could have a black and white scenario                                 you can read or can't read or can write                                 or can't write so in the initial commit                                 that I pointed out earlier version o dot                                                                                                        having a of having access control list                                 ACLs and the reference architecture for                                 this is the simple ACL authorizer which                                 stores its ACLs and zookeeper and it's                                 AC else you can try and read right it's                                 it's fairly standard I won't go into too                                 much detail on this only thing that's                                 noticeable is you can also have super                                 users for those ACLs are not even                                 checked those are just granted any                                 requests that they make those would                                 usually be your Kafka broker so that                                 within the cluster those guys can talk                                 to each other freely what is worth                                 noticing is that all of this is entirely                                 pluggable so the simple ACL authorizer                                 is just a an example so to say of how                                 this can be handled                                 however my personal opinion is that it's                                 it's quite suited                                 for roughly eighteen ninety eight                                 percent of all use cases maybe we can                                 have a quick show of hands who uses                                 Kafka and please keep your hands up                                 and who has security enabled and who is                                 not using these simple ACL authorizer                                 not so who has a customer authorizer                                 okay that's roughly what I expect it to                                 be honest so yeah it works you can                                 define ACLs and it it gives you what's                                 in the what's on the box ACL so there                                 are always granted for resource so you                                 can grant HCL's                                 or writes on topics on consumer groups                                 or the entire cluster there is limited                                 wildcard support as well so you can have                                 star which means everything and there's                                 a few jurors that look into having                                 additional wildcard support support so                                 to say so for resources I think it's                                 close to being able to commit it so in                                 one of the next versions will probably                                 see wildcards in resource names and for                                 IP addresses there's a JIRA that wants                                 to introduce IP ranges and cider                                 notation which is actually being driven                                 by me but those guys up here we're a bit                                 quicker and they changed the way that                                 ACLs are stored so they made my life a                                 bit harder I can't tell you when that'll                                 come but at some point it'll be ready as                                 well and then you can allow or deny                                 actions and you have a default if                                 there's no ACL for a resource where the                                 request should be granted or denied you                                 know I hope yes everybody should be able                                 to read that I think so this is an                                 example of creating ACLs for Bob and                                 Ellis but when elders want to read and                                 write to the test topic and boppin Ellis                                 are allowed to connect from these two                                 machines again I've taken this from the                                 official Kafka documentation so if you                                 want to read a bit more detail about                                 that feel free to go there and check it                                 out                                 and as you can see this has the list of                                 all ACLs that are added so it actually                                 multiplies out every everything that we                                 have up here an ACL is always just for                                 one resource from one host and one                                 principal so we have Bob from machine                                 zero read and this topic so we should be                                 able to find that somewhere down here a                                 lot of emissions for read from zero back                                 there so this one command actually                                 created three six eight ACLs in our zoo                                 keeper and again if we think back to our                                 couple of hundred notes cluster if we                                 want to add those IP addresses to this                                 and then have a couple of more users it                                 can get to be quite a long list of ACLs                                 that are stuck into zookeeper here so                                 now let's say we actually added LS by by                                 mistake so we want to take her out again                                 so instead of add on the slide before                                 will now put remove again have the user                                 ellos operation read/write on this topic                                 and we removed the the hosts because we                                 just want to remove Alice we don't care                                 what host and what now happens is                                 something that user Ellis has allowed                                 pollutions for right from host star                                 those are the ACLs that will be removed                                 and if you check out the current state                                 after removing Alice still has X's                                 because ACLs are always matched exactly                                 and what we try to remove is host star                                 which didn't match that host so that ACL                                 still sticks so what we need to do is                                 actually remove exactly the ACL that we                                 created initially and if you do that and                                 check down here then actually for ACLs                                 will be removed and now only Bob has                                 access anymore so what this example is                                 supposed to demonstrate is this is not a                                 very intuitive tool it's you need to                                 spend some time with it and curse a                                 little before you can actually                                 use it well I think all right so the                                 first line up here is actually something                                 that's quite important to us because we                                 saw we didn't connect to Kafka                                 to administer these ACLs but we actually                                 connected to a zookeeper in Samba so we                                 can only do this from somewhere where we                                 where the firewall allows us to access                                 zookeeper and also we need to be able to                                 write to zookeeper                                 so consumers and producers they don't                                 need zookeeper at all old versions did                                 but the new versions they only talk to                                 Kafka                                 but most of the command-line tools if                                 you create topics if you create ACLs                                 those tools will actually talk to Kazuki                                 by directly which of course makes the                                 question interesting does zookeeper have                                 security because if someone who doesn't                                 have access to Kafka can just go to                                 zookeeper create ACLs for him to our                                 access to Kafka and then get the data                                 that sort of defeats the entire purpose                                 so yes zookeeper does have security you                                 can authenticate there with Kerberos as                                 well which thankfully it's a little                                 issue though because when Kafka creates                                 nodes in do keeper it'll make those                                 world readable which is sort of fine but                                 only writable by itself so what you need                                 to do is impersonate a Kafka broker if                                 you want to add ACLs which means SSH                                 into your machine sudo grab the key type                                 that Kafka runs with issue the command                                 probably talk to someone from IT                                 security why you did that on the                                 production machine and it's all not                                 really nice so that's a new thing which                                 is called the Java admin client which                                 does all the same operations without                                 talking to zookeeper that actually talks                                 to Kafka itself and requests that come                                 from this client go through ACLs                                 themselves so you can actually properly                                 event authorized people to do things                                 however to use that currently you                                 actually need to write Java code because                                 the command-line tools have not yet been                                 migrated over to use that thing there's                                 a couple of Giro's for them and it's                                 I'm sure it's going to happen at some                                 point in time but not yet it's all just                                 to go through this really quickly                                 because I think I'm running out of time                                 this is just the entire authorization                                 sequence if a request comes in if the                                 user comes in the user is checked if                                 it's a super user we allow immediately                                 without doing anything else if not we                                 retrieve LCLs for the resource and the                                 request if we have none we look at this                                 parameter that we can set in the broker                                 configuration and if that is true then                                 we allow the request if not we deny if                                 we have AC else then first we check                                 whether anything should be denied if                                 that's a yes we deny the request if                                 that's a no then we check with that                                 there's an ACL that allows this request                                 and again deny or allow based on that so                                 that's what happens internally when a                                 request is checked against ACLs I                                 apologize for this five minutes before                                 the talk power point decided to up                                 my slides so you'll have to have a                                 little fantasy that the the arrows                                 actually come from down here and go up                                 here we looked at authorization methods                                 earlier and we had quite a few weird                                 plaintext SSL Stram gssapi but in our                                 ECL definition we can only put something                                 a minute ago it was user Bob but where                                 did that Bob come from for example scrum                                 is easy it's just the username but SSL                                 or gssapi a bit more involved                                 so what Kafka does for all these                                 requests if they come in it passes those                                 to a principal builder and that                                 principal builder looks at the                                 authorization context authentication                                 context sorry and based on what method                                 is in there it'll do a variety of things                                 and what it will do I've put into this                                 table so for plain text it can't do                                 anything we don't know anything about                                 the user so that will always be                                 anonymous same thing for SSL if the                                 client didn't send a certificate with                                 this request that's pretty much the same                                 as plain text                                 for sessile plain and senseless Graham                                 where she defined usernames so it's fine                                 to use those for Kerberos it'll be Alexi                                 by default I think it'll be the short                                 thing up front here but you can define                                 off two local rules which is sort of                                 like a regular expression that tells                                 Kafka what it should do with your user                                 principal name and how it should extract                                 the user name from that and for SSL it                                 lets you take the entire certificate all                                 right my pointer died anyway and extract                                 all information that's in there and use                                 that entire string as the username but                                 again all of this is pluggable so if                                 you're not happy with this write your                                 own class extend the Kafka principle                                 builder and you're good to go                                 because what Kafka actually does is well                                 anyway the authenticate request comes to                                 the broker then it gives that to the                                 default Kafka principle builder which                                 the behavior of that we saw on the table                                 earlier that returns a Kafka principle                                 which is then passed to the ACL                                 authorizer                                 which we saw earlier user Bob or user                                 ellos and that then says you're good to                                 go                                 oh no and the response is passed back to                                 the client so both of those classes are                                 configurable and extendable there's                                 that's actually quite a nice example of                                 consistent parameter naming and open                                 source projects and there's two main                                 implementations that are out there                                 Ranger and sentry if you use a Hadoop                                 distribution and your car is part of                                 that then based on whether that Clara or                                 Hortonworks that's what you'll get and                                 what you can use                                 but of course using pre-built stuff is                                 not really fun so in the last five                                 minutes we look at implementing our own                                 Kafka authorizer                                 this is fairly brief I'll just show you                                 a couple of slides with a bit of code                                 and explain what I've done but I've                                 written a blog post on this as well so                                 if you want to code along or look at                                 that please feel free to build and check                                 that out                                 so what we're missing earlier from our                                 from the ability to define ACLs was we                                 had no concept of user groups we always                                 had to authenticate a single user but                                 large corporations usually use Active                                 Directory and group membership in Active                                 Directory for their rights management so                                 what we'll try and do is build an                                 authorizer that looks up the user that                                 authenticated himself an Active                                 Directory retrieves the groups for that                                 user                                 and then allows us to authenticate                                 authorized based on those groups that's                                 four things that we need to do for that                                 we need to create a principle builder                                 that retrieves groups from Active                                 Directory which sounds complex but                                 actually will cheat a bit on that and                                 it's really easy then we did you extend                                 the principle a little bit because the                                 default Kafka principle only has a type                                 and a name which is fine we could have                                 used that for group but users will                                 probably belong to more than one group                                 so there it's not sufficient anymore so                                 we just make a list out of that and then                                 we need to create an authorizer that                                 understands that and enable the user to                                 create and manage ACLs just like we've                                 done on the command line earlier which                                 again is easier than it sounds so this                                 is the complex Kafka principle and now                                 it's actually a bit of a pity that my                                 thing doesn't work anymore and what this                                 is is it's just a little wrapper around                                 the normal Kafka principle so that we                                 can store a list of principles in a                                 single single object which would then be                                 a list of all the group memberships that                                 this user has and looking up the groups                                 I actually stole that part from Hadoop                                 because they have something called a                                 group mapping service provider which is                                 an interface that allows you that you                                 can code against and retrieve groups for                                 users and this specific implementation                                 just checks the local OS user and                                 retrieves groups that that's a member of                                 which you've used something like s SSD                                 or Centrify to manifest users from                                 active directory on your local machine                                 works quite nicely and then to match the                                 ACLs I've taken the simple ACL                                 authorizer and just                                 changed a little bit of code where where                                 necessary so this is pretty much just                                 unpacks our lists of principles and then                                 the only really important part is                                 actually these three lines down here                                 where it checks all the principles that                                 we unpacked from the list against all                                 our as yells and uses or to get those                                 together and if any single one of those                                 matches the thing is allowed and if you                                 put that to the test you can see in the                                 first example that the user is libo at                                 open code calm has allowed permissions                                 for a topic but down here you can see                                 that the group super group which my user                                 is part of also is allowed to access a                                 different topic so we in this example we                                 have authorization based on groups from                                 active directory and what I forgot to                                 mention here is that we can still use                                 the default command line tools just I                                 put it before because what Kafka does                                 for these principles in ACLs here it                                 just splits at the colon and you can                                 stick anything you like before that in                                 your command and so we just could reuse                                 the entire command line tools and with                                 that I think I'm exactly on time thank                                 you very much are there any questions                                 always yes he was has one thank you for                                 a detailed presentation so I used Kafka                                 from back in like oh six oh seven days                                 where there was no such thing as                                 security okay and back in that time that                                 was typical for most big data tools that                                 security was an afterthought normal life                                 cycle so when my clients asked you know                                 how do we solve this security thing my                                 main answer has been well go to the                                 cloud and wrap all your things in                                 containers vm something and use the                                 cloud security                                 names like whatever access control they                                 provide so your strategy is something                                 different right so could you compare                                 pros and cons of these two strategies                                 and help me I would say aside that this                                 is probably a bit more fine grained                                 access control because if you wrap                                 something in a container that's sort of                                 still access control based on who can                                 actually get to the thing if I didn't                                 misunderstand you so what that doesn't                                 allow you to do is give someone access                                 to a specific topic or give someone just                                 read access to a topic but not write                                 access to a topic and you probably need                                 to think about network infrastructure                                 and sort of the overall architecture                                 picture a lot more if you wanted to use                                 that for access control so this is a bit                                 easier I would say but more powerful                                 okay fair enough                                 thank you thanks
YouTube URL: https://www.youtube.com/watch?v=s5mO4_gFLVk


