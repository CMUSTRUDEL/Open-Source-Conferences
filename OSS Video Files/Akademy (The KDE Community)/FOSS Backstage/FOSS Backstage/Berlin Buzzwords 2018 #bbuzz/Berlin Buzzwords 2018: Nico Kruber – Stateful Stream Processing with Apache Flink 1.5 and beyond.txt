Title: Berlin Buzzwords 2018: Nico Kruber â€“ Stateful Stream Processing with Apache Flink 1.5 and beyond
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	Nico Kruber talking about "Whats new in Stateful Stream Processing with Apache Flink 1.5 and beyond".

Come learn about the latest changes in Apache Flink 1.5 and how we made stateful stream processing more powerful, more expressive, and more flexible to support applications that were previously difficult to realize.

Apache Flink 1.5 is the biggest Flink release the community has ever published. Not only does it contain many enhancements for its APIs and libraries but it also comes with major improvements to three of its core components. We reworked the network stack and added a credit-based flow control mechanism which results in even better throughput/latency trade-offs and more efficient checkpoints. Fast local recovery helps to speed up the recovery of applications with large state. Finally, the redesign of Flink's distributed architecture makes Flink fit naturally onto Kubernetes, Yarn, Mesos, and standalone setups with support for resource elasticity.

Read more:
https://2018.berlinbuzzwords.de/18/session/whats-new-stateful-stream-processing-apache-flink-15-and-beyond

About Nico Kruber:
https://2018.berlinbuzzwords.de/users/nico-kruber

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              hi there so let's get started a short a                               few notes about me and the dartisans                               it's a very special day for our artisans                               it was founded by the original creators                               of magic link and as it so happens they                               of today four years ago so it's a                               birthday and a bit younger is actually                               our first product which is the DA                               platform that was announced in September                                                                                                        which eases the deployment of flink jobs                                and hold management of your application                                running on flink so what are we going to                                what I'm am I going to talk about today                                so first I'll give you brief                                introduction about what is Apache flink                                and then we head on to the recent                                changes to it which emerge in the                                release of Apache                                                     weeks ago and I give a brief outlook of                                what is in the in the stages as of now                                and will be in think one at six and                                afterwards so what is the patch you                                think in a nutshell I think allows you                                to do stateful computations over streams                                either real time or historic it is fast                                scalable falter and and in memory or not                                in memory but on disk if you need large                                state it supports event time also                                processing times the different notions                                of time that's rised with your                                applications it has at least once and                                exactly ones guarantees whatever you                                choose whatever you need for application                                and as for a chief link everything it                                sees is basically a stream so if you                                have a continuous streaming program or                                running application based on flink those                                will be basically unbounded streams can                                start in the past and go on into the                                future because you don't know when they                                were going well                                when they will end and it also processes                                batch processes in the same way so those                                streams will then be finished filling                                the applications and patches it could be                                that it's started in the past and ended                                in the past gives your processing                                historic data or it's not in the past                                extends into the future but it will end                                it sometime but for flink itself                                everything is a stream if you want to                                use it you basically have different                                abstractions that you can use so it's                                kind of a layer so in the middle there's                                the data stream a data set API which is                                useful for stream and batch data                                processing this gives you access to                                streams to Windows some aggregations                                like in this example you have some                                stream that comes from sensors you group                                by those sensors and you want to                                aggregate certain data from those                                sensors in Windows below that API you                                have more fine-grained control with the                                process functions there you have access                                to the events themselves to state all                                the individual operators to time                                different notions of time to water marks                                so this is what you would use to                                implement a stateful                                event-driven application it gives you                                more fine-grained control and there's a                                high level abstraction which basically                                eases the entry level into stream                                processing so there's a stream sequel                                and a table API that basically allows                                data analysts to write sequel queries                                that will then be translated into stream                                processing program and run on Finken so                                give some examples for those individual                                levels so in the data stream API you                                always start from sources this is where                                your data comes from we events come from                                then you do some transformations                                everything that you want to need to do I                                want to need to do like assuming your                                source only had strings you might want                                to parse them into some real objects                                that you will work on later so this will                                be a transformation then you like in his                                example before group this by                                in this example the sensor you have                                access to Windows you do sum over over                                the this window and so this will be                                Windows where the window itself will                                accumulate state and aggregate this with                                the function given and everything will                                end up in a sink so stream processing                                 program is always from the sources to                                 the sink and I think you can write to                                 the sources like certain sources you                                 would read for example from Kafka or any                                 other source then idiot transformations                                 inside flink and the sink will either                                 write it back to some sort of some                                 destination also be Kafka or files or s                                  or you could actually talk to to another                                 service that is running at the low level                                 you would have the the process                                 functional core process function where                                 in this example you could join two                                 different streams together you would                                 have to implement this in either Java or                                 Scala and you get access to to every                                 detail in those events in the context                                 from from flink so watermarks for time                                 the time itself what time is it and you                                 are able to register timers so you have                                 very fine grained control over what you                                 want to do but you need to know what                                 you're doing                                 and on higher level this equal it's                                 almost then it's equal except for that                                 the tables are not fixed but those are                                 dynamic tables because you work on a                                 stream you don't know when the stream                                 will end and it's basically almost anti                                 sequel with some extensions like windows                                 in this case a tumbling window but you                                 also have access to not only due to time                                 different time notions because the                                 windows your processing time or even                                 event time so how large or small can                                 fling get well arguably the the biggest                                 user of link is Alibaba                                 they use fling to sort of power parts of                                 their system during the this really                                 crazy shopping day the singles day at                                 the                                                                   have roughly                                                                                                        processed through link link is there for                                 cuff link with her which has a few                                 patches on top of it but they're slowly                                 or they're continuously contributing                                 back to things so the difference is                                 getting less and less between blink and                                 blink so at the in terms of the jobs                                 there thousands of different jobs                                 running they run very large classes of                                 over                                                                    so this is really big and the second                                 example is Netflix their routing                                 pipeline goes through flink and they                                 have also there was a very big user with                                 around three trillion events per day                                 over                                                                    of parallel operators but if link                                 doesn't have to be big it can can run in                                 a single process you could run it on                                 your machine you will not get a highly                                 availability of course because it's a                                 single machine but it does run there as                                 well some users also use it on IOT                                 gateways and for debugging it's also                                 very useful to run in your IDE so let's                                 go to to the changes for fleeing                                 one-five first of all fling Kani                                        numbers it's been roughly                                             work where                                                             to flink within over                                                    were almost                                                              a lot of changes in the codes one of the                                 biggest ones is the changes and                                 deployment and process model so this is                                 not only big one in terms of code but                                 also on what enables us to do now and in                                 the future so what are different sizes                                 that we can use and if you want to use                                 flink there tons of different deployment                                 scenarios one of the common ones is to                                 run it on yarn you can also use me sauce                                 you could use docker and cube inators                                 you can setup flink standalone meaning                                 um- on your machines themselves and so                                 on and so on did so many different                                 scenarios and on top of that there are                                 different usage patterns you could have                                 a few but very long running programs or                                 you can have many short running programs                                 and you want to have a different mode                                 for the two of them because there's some                                 of it of starting a new cluster so                                 there's job isolation wasn't sharing                                 resources if you have a few long-running                                 jobs you might want to have those have                                 those separate from each other but if                                 you have many short running jobs you                                 might want to have a big cluster that is                                 shared among those jobs so you don't                                 need to restart the cluster all over                                 again for every small job and you want                                 you if you have a single cluster you can                                 also share resources so not every small                                 job will use the whole cluster so there                                 you would go for the the sharing part                                 which will be either a session mode that                                 basically sets up a fling cluster                                 without a job and then you can submit                                 jobs into it so it's a cluster for                                 multiple jobs the resources the compute                                 power can be shared across those jobs                                 and as I said it's a separate thing to                                 deploy the cluster and to submit your                                 jobs to it and then there's job mode                                 which will basically set up a fling                                 cluster for each job that you want this                                 is the best thing if you want separation                                 between the jobs so those changes in the                                 deployment model have been introduced                                 and in the flink improvement proposal                                 six this has been around for quite a                                 while it has been worked on and                                 initiated by Alibaba and Tata artisans                                 it introduces generic building blocks so                                 that we are able to create blocks for                                 all the different scenarios that were                                 mentioned before and we go into details                                 a bit more so those building blocks to                                 start basically you have one resource                                 manager there                                 is cluster manager specific so you have                                 one for yarn you have one for me sauce                                 you would have one for community etc etc                                 and for standalone this one may live                                 across jobs and manages the available                                 containers and task managers so task                                 managers are they basically work Rosberg                                 will come to this resource managers                                 responsibility is to acquire and release                                 resources and then there's the                                 dispatcher this also lives across jobs                                 and is the the touch point for job                                 submissions if you have your CLI                                 somewhere and want to submit a job you                                 will go through the dispatcher and this                                 spawns job managers which exists now                                 only for a single job we go to the                                 interactions between those in a minute                                 this is where it is so from the client                                 this can be the web UI or most commonly                                 the CI you would submit the job to watch                                 the dispatcher the dispatcher will then                                 start a job manager for this specific                                 job and well the job manager will talk                                 to the resource manager to ask for slots                                 says well give me this program specifies                                 parallelism of                                                        run this on so the resource manager will                                 talk to yarn me sores etc to spawn task                                 managers those times managers when they                                 start up they register with the resource                                 manager and eventually the job manager                                 can deploy the tasks on those task                                 managers so in yarn this is what it                                 looks like you you tell the yarn                                 resource manager to spawn the                                 application master which will contain a                                 dispatcher and the resource manager                                 specific to John this is basically what                                 I showed before and me so this will be                                 quite similar so those building blocks                                 are very generic and interchangeable                                 where they need to be so this is the per                                 job mode so what are the difference to                                 the situation that has been there before                                 now the jars are in a class part of all                                 components this reduces class loading                                 issues that's one point                                 the second and maybe even bigger point                                 is that we have dynamic resource                                 allocation so we no longer need to                                 specify how many containers we need to                                 run during startup you say your job is                                 parallelism                                                             many task managers and then there's no                                 to face certain job submission anymore                                 so in there before you basically spawned                                 everything and needed to Paul and Paul                                 and ask it what is the cluster running                                 is that running is it running and then                                 submit your job this was working behind                                 the scenes but nevertheless was                                 error-prone and for the session mode                                 it's not too much different in the CLI                                 you would start your cluster this is the                                 one time thing you start your session                                 cluster this will spawn an application                                 master consisting of the resource                                 manager and dispatcher and whenever you                                 submit a job like step three years of                                 mid job a you talk to the dispatcher it                                 will start the job manager for this                                 particular job and ask the resource                                 manager for resources this will organize                                 and start task managers which register                                 with results manager and tell the job                                 manager well I'm here                                 give me some work and whenever you                                 submit a new job this will also go                                 through this through the dispatcher it                                 will start a separate job manager and                                 the same process will happen again so to                                 wrap up this part of the deployment                                 changes we have a new distributed                                 architecture there the last thing to                                 support many different deployment                                 scenarios as shown we now also have a                                 native job mode as well as a session                                 road before the session mode was kind of                                 a heckie heckie thing and the biggest                                 change will be that we now have full                                 resource elasticity so that's one step                                 towards having dynamic scaling and also                                 very nice to have now every call to the                                 job manager every job submission etc is                                 going through rest see you can have your                                 own clients talk to two flink                                 it does not go through akka anymore but                                 you can have basically a standard rest                                 Galt's towards it so that's it for the                                 deployment changes the second part will                                 be around broadcast state which extends                                 the the use cases for flings so imagine                                 you have some kid streams where the                                 events come through and you want to                                 match them against the common rules the                                 common set of rules that should be                                 available to every parallel instance                                 this was not easily possible for you you                                 could not combine a non-key stream with                                 a keyed stream so this is web broadcast                                 it comes in to go into an example you                                 want to match stream a with some shapes                                 against another stream of rules so here                                 you want to match objects of the same                                 color with shapes in a particular order                                 for example the the square first event                                 should be square second event should be                                 a triangle so what you would do you                                 would create a key by first on the color                                 those will be stored into key to say                                 that each parallel instance in here like                                 three imperil instances and then you                                 wouldn't need the rules the rules will                                 need to be spirited to all of the notes                                 so they will be broadcasted they must be                                 stored there as well and this will go                                 into broadcast                                                          connect those two you would say okay                                 this keyed stream works with this                                 broadcast                                                            comes in like here for the first notes                                 we have the square is already stored we                                 have the rule that we're waiting for                                 square and then triangle and the                                 triangle comes in it will then be                                 matched based on this you can access the                                 broadcast at state you can access the                                 rules and then you can work on it                                 and with this like what you could do                                 before is to have a static set of rules                                 you would add this to a program this                                 will be fixed and that's it but what if                                 you want to change what if in the next                                 iteration you want to have a look at                                 something different                                 think about fraud detection you might                                 want to change your rules and not                                 redeploy your job so this is where the                                 broadcast state comes in                                 so I won't go into details for the API                                 this is what the documentation is for                                 it's good for but basically what we have                                 we can have a heat stream or an on                                 Keith's stream that we can connect to a                                 broadcast and stream                                 so this broadcast stream is non Keats                                 it is replicated onto all all threaded                                 instances and it's identical on all                                 tasks even after restoring after                                 rescaling flings takes care of                                 everything takes care of this and you                                 need the ability to connect those two                                 streams to say okay this ki donkeys                                 stream uses this broadcast gene and this                                 is used so that in the processing of the                                 kids tree market stream you know and you                                 have access to this broadcast all right                                 let's go to the next part there have                                 been some big changes in the network                                 stick that we're introduced in                                        what fling basically offers you on a lot                                 on a logical point of view is if you                                 have a subtask one subtask                                             are connected with a the key buyer with                                 a shuffle with satis                                            logically says there's a separate stream                                 between task                                                          also task                                                            abstraction over different things                                 so first the sub has outputs every                                 outgoing stream can be either pipeline                                 then bounded it can be pipelined and                                 unbounded it can also be blocking then                                 there could be different scheduling                                 types all those four subtasks could be                                 scheduled at once                                 task                                                                                                                                        already when the first event from                                       comes in and then at different methods                                 of sending the data through you can have                                 high throughput by buffering some events                                 and then sending bigger chunks of data                                 if your events are small or you can have                                 low latency                                 immediately sending even small got                                 around so this logical separation makes                                 a lot of sense but under the hood it's                                 not that we have a separate channel for                                 each of those communications this will                                 be way too costly so what we do have if                                 there is one task manager with two                                 parallel instances slate subtask                                       work on the same task manager and                                 sometimes                                                                manager but also the same like such                                 manager                                       then all the communication that goes                                 from task manager                                                       single TCP connection so even if                                 suppressive subtask                                                     separate connections to the task manager                                                                                                     there and all the events that come                                 through the the queues will be                                 multiplexed into this connection so what                                 happens there                                 in this scenario let's say there is an                                 input input queue on sub task                                            has been kind of slow because it does a                                 lot of computation or something so                                 buffers pile up on this end and we now                                 have a blue event also coming in for                                 this task but sub tasks for cannot                                 really accept this it is full it doesn't                                 have capacity for this so there's an                                 event in the pipeline that we cannot                                 handle and the other sub tasks like                                 three will process it events at some                                 point it will have no input data anymore                                 and this one single event in that TCP                                 connection is blocking the whole                                 pipeline because this does not get                                 through the next ones also don't get                                 through so sub task                                                   will not do anything because the surplus                                 for was low and so is a single                                 connection there it can block all of the                                 connections which was a severe downside                                 and performance in this regard so what                                 we introduced with                                                   joint work with Alibaba                                 we added credit based flow control a                                 receiver                                 first of all tries to get resources to                                 process data once it has acquired those                                 resources it will assign credit to the                                 sender's let's say receiver says okay I                                 need two buffers to get an to fill it                                 with data from the sender so it asks for                                 two buffers once it has them it assigns                                 to it sends two to the sender and send                                 it the sender now knows okay                                 the receiver has two buffers available I                                 can send it to buffers and they will not                                 be blocked on the channel once the                                 sender is sent and had put has put data                                 onto the communication onto the TCP                                 channel it will not be blocked there at                                 any time because we know the receiver                                 has the capacity to do so and this gives                                 significant improvements on first                                 performance and second on a non                                 checkpoints as well because if we look                                 back at this point the events that might                                 be in the TCP connection cannot only be                                 events from the user but also checkpoint                                 barriers so those will be small data                                 chunks that we sent through indicating                                 that the tasks need to check on their                                 state and as you can see in a very                                 simple program we already have a vast                                 improvement on the checkpoint durations                                 with credit based flow control and a                                 second thing we did not only introduced                                 credit based flow control into the                                 networks like we also improved it a lot                                 and and it's over it so rid reduced the                                 overhead of the network stack and that                                 way the balance between high throughput                                 by buffering a lot of data and then                                 sending big chunks versus sending every                                 event on its own and having low latency                                 is further improved so with a very full                                 buffers only flushing them everyone at                                 milliseconds was which is default we                                 have higher throughput because of the                                 improvements in the and they use                                 but even if you flush every five or two                                 a one second or even send every event                                 there we have a lot higher improvement                                                                                                          context switch so we're not talking                                 about States                                 so whenever flings high-availability                                 basically is based on on checkpoints                                 those checkpoints which store States                                 somewhere in distributed file system and                                 we have those Jackman bearers passing                                 through whenever an operator knows okay                                 I have to checkpoint this my state's                                 somewhere it will store this into stable                                 storage it will do so asynchronously                                 there is a synchronous part which                                 basically creates a copy or copy on                                 writes and then stores this part                                 asynchronously onto some stable storage                                 so during failures whenever a task                                 manager fails the job will be redeployed                                 and we need to restore the state from                                 the stable storage and this is a                                 significant burden if you have a very                                 big state if you have terabytes of                                 states start somewhere and this needs to                                 be loaded so what if Ling five one five                                 introduced is to have some local states                                 so if your task manager survived the                                 scheduling will make sure that the task                                 is put again onto the same task manager                                 and doing let's sort of doing                                 checkpoints you will not only store the                                 checkpoints on this distributed file                                 system but you will also have a copy                                 local on your local disk so you have                                 this one copy and local disk one and                                 distributed file system if your task                                 manager survived then you can restore                                 from the local file system immediately                                 you don't need to download stuff from                                 your distributed file system again if it                                 did not survive well for all those that                                 survived you restore locally and for                                 those who didn't you restore from the                                 distributed file system                                 so there's a significant reduction in                                 the time that you need to restore from a                                 failure there have been some changes in                                 the secret way there is a talk tomorrow                                 so I will not go into details that much                                 my colleague Fabian would present more                                 detail tomorrow so we have some some                                 support for new joins like windowed                                 outer joins and non winnette inner joins                                 and one of the bigger changes there is                                 that we have a sequel clients so it's                                 very easy now to access to data on the                                 to process data on your stream you don't                                 need to write a Java Scala program                                 anymore and put your sequel query in                                 there and submit this you simply run the                                 sequel client you enter your query and                                 you then browse the tables like in this                                 demo you can view at individual events                                 you will see the details basically it's                                 a very handy tool to do some quick                                 calculations oops                                 and now some parts for what's going on                                 at the moment so the release was roughly                                 two weeks ago and the next flink one six                                 is targeted for end of July so what's in                                 the pipeline now and what will guarantee                                 one six and even beyond                                 so the focus points are basically                                 mentioned here is first of all support                                 for Java nine at the moment we run Java                                                                                                         deployment architecture are continuing                                 to give some better and give some                                 improvements for container environments                                 to run on combinators natively and also                                 part of it is having the whole job                                 submission run through rest there's one                                 single point that is not going through                                 guys yet and this is techadon that JIRA                                 ticket then there are two types of                                 states that are currently only store the                                 memory this is timers and operators data                                 we do want to change this we do want to                                 leverage our state backends for those                                 two categories so that not only we can                                 have a very big operator state that is                                 that does not fit into memory anymore                                 but can be stored on disk via rocks DB                                 but also remove some old code then and                                 get some better performance which is                                 already showing there then on the                                 application side we want to change and                                 improve the bucketing sync that is now                                 based on Hadoop file systems to work                                 with fling file systems those fascism                                 will then include like s                                                 other file systems that are available in                                 flink then their changes in pipelines                                 for improving state evaluation to allow                                 type conversions doing restores which is                                 not possible at the moment and then                                 there are a lot of changes in stream                                 sequel we will have a new update by key                                 for table sources we will have more                                 table sources not just Kafka but also on                                 and Kinesis and files and Kaveri stores                                 and the complex event processing CEP                                 will integrate with sequel will use the                                 match recognized clause to make it                                 available there and one more thing the                                 CP performance if used on rock CB is                                 currently not or I can be improved and                                 will be improved there's open full                                 requests for this as well and this is                                 where roughly made it on time and now we                                 have some room for questions and a new                                 deployment models you how does that work                                 with Kerberos key type files do you is                                 not still supported properly                                 that's the supported and it's may go                                 back to                                 [Music]                                 here so you still submit the job this                                 will go to the job manager and task                                 manager so that basically is the same                                 the only thing that changed is the way                                 that you request resources so those will                                 go we should go the same way actually                                 hello hello so talking about dynamic                                 resource allocation is there about                                 dynamic resource allocation is there                                 auto scaling feature or how does it work                                 to its scale what is currently possible                                 is that the flink cluster itself scan                                 scale so you start like in session mode                                 you you spawn up only this one cluster                                 entry point and then whenever you submit                                 a job it will ask for the resources                                 those resources whenever a job finishes                                 will not be given back immediately you                                 will hold onto them for a while and only                                 give them back after some time out so                                 you can which you can configure if you                                 ask for a separate like in a new job                                 like job a and P as in the example job P                                 will ask for more resources so the flink                                 cluster itself will auto scale the job                                 that the job itself will not I mean you                                 cannot you can scale but not                                 automatically what you would do would                                 basically take a snapshot increase the                                 parallelism and start again                                 all right does that answer your question                                 any and and about question about entry                                 sorry                                 society input okay II could you please                                 her mind did you mention how this state                                 can be updated with some timeout because                                 in previously we were using pattern with                                 sleeps to be honest not familiar much                                 with the site inputs stated site input                                 slot estate is kind of a site input yes                                 but I don't think I don't want to give                                 out wrong information so this broadcast                                 state can we update the rules                                 yeah so this is out this is one kind of                                 site and put as you could say it's not                                 the generic so for everything but if you                                 do this pattern there then that's some I                                 have another question and so effectively                                 you can have your flink session running                                 indefinitely claiming only maybe one                                 container and only when you submit a job                                 it will claim additional resources and                                 give them back a while after job                                 finished                                 yes okay that's exactly what you can do                                 that's nice yeah you will share the                                 resources though among different jobs                                 right Thanks so I'm interested in                                 kubernetes setup what can we expect for                                 the next release is this on on the same                                 level what what is present for example                                 for yarn or is it just a more smaller                                 version of scheduling yeah I think there                                 will be first step of having containers                                 pretty but generate containers for                                 customers that will register with the                                 results menteur similar as here where                                 like companies would do this scaling                                 meaning it will launch additional task                                 managers those will register similar to                                 the session mode will then register                                 sorry they're so kinase which would if                                 it was scale it would simply start up                                 more task manager containers those                                 containers will connect to the resource                                 manager and this will have them                                 available there as well and then the job                                 submission goes through dispatcher as                                 well following this are you familiar                                 with the way SPARC is working for                                 submitting jobs are there similar plans                                 to have the kubernetes native way to                                 submit a job I'm not so thanks                                 all right any more questions yeah I'm                                 wondering about the broadcast date you                                 could do something similar previously by                                 using physical partitioning right and I                                 what using physical partitioning                                 physically locating the data                                 broadcasting it to all the nodes and                                 then using like using the physical                                 partitioning connection on a single                                 machine you could do you could do make                                 assumptions about operators location you                                 could hack your way through yeah like                                 whatever you receive the progress states                                 will put it into memory and then it's of                                 course available on the others but you                                 would not have any guarantees like                                 exactly once                                 between those two okay so that's what we                                 got you a drink yes before that was only                                 like say a hack but this is a cleaner                                 solution Thanks                                 and no more question and thank you for a                                 time Vicki thank you                                 [Applause]                                 [Music]
YouTube URL: https://www.youtube.com/watch?v=m12l5ke4Z34


