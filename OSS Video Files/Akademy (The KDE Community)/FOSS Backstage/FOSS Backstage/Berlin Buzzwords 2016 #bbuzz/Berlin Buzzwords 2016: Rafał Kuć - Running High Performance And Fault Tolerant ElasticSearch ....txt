Title: Berlin Buzzwords 2016: Rafał Kuć - Running High Performance And Fault Tolerant ElasticSearch ...
Publication date: 2016-06-11
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	We’ve learned how to run Docker containers. And we’ve learned how to run ElasticSearch. However, to run containerized ElasticSearch nodes and to do that effectively -- and at scale -- takes a little more knowledge and work. Sure, containers can be easily started and stopped; but how do you do that with ElasticSearch inside them?

In this talk we’ll quickly run over the basic Docker+ElasticSearch setup and focus on harder problems:
- Architecting for ElasticSearch fault tolerance and high availability in containerized setup - using sharding, replication, node and shard-awareness for keeping your cluster green
- Running ElasticSearch in different modes with re-usability in mind
- Optimizing and tuning ElasticSearch for popular use cases like ELK
- Ops/Devops - monitoring ElasticSearch & Docker together - which metrics to watch, what they mean, how to act on them and first of all, how to watch them

Read more:
https://2016.berlinbuzzwords.de/session/running-high-performance-and-fault-tolerant-elasticsearch-clusters-docker

About Rafał Kuć:
https://2016.berlinbuzzwords.de/users/rafal-kuc

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              hello everyone nice to see you here and                               welcome to do the second talk here in                               castle house I'll talk a bit on                               elasticsearch in doctor and how to run                               those two together to make use of them a                               briefly introduction I'm an engineer in                               semantics group I do trainings I'm a                               consultant basically all of person who                               goes all around the stack of our of our                                business and today we'll get on with                                three things first of all docker then                                elasticsearch and finally a few metrics                                at the end that you should pay attention                                to whatever running elasticsearch on a                                traditional bare metal on vm or in                                docker especially those were chosen for                                containers so first of all a few things                                about what we are used to right now so                                every one of us developers are used to                                the development environment when we do                                code we test this stuff initially then                                we get on with the test environment                                where people test stuff together right                                so we have parts of the application                                coming from multiple developers that are                                connected together and tests on some                                kind of test environment some larger                                organizations may allow and actually                                allow and do use quality assurance teams                                and QA environments where those are                                closer to production but still not there                                and people do test if something fails                                they get back to the test and                                development and the cycle goes on until                                we actually end up in the production                                environment where all those things run                                for our clients or for us depending on                                what the applications are the problems                                that come with it is there is at least                                three of them the main ones first of all                                the resources are not utilized in a                                   or                                                                  means that we are more or less losing                                money because if we over provision our                                servers like here we have some kind of                                processing power                                that we do not use and we do not want                                that of course some overhead is needed                                always right because we need to be                                prepared for those spikes in usage and                                all of that however still the                                over-provisioning is usually money that                                we lose and the final the third thing                                that we can talk about here is that                                those environments are usually not the                                same there are differences in the                                operating systems the libraries that                                they run the hardware itself so there                                are problems I suppose you all heard it                                works for me so and and I think this is                                a problematic way a problematic thing                                for developers to actually go there look                                okay this is a library problem let's fix                                it that let's update and go and go on                                with development so instead of running                                in a traditional bare metal or virtual                                machines we can put in our case                                elasticsearch in a container a small                                lightweight piece of software and put it                                on all of those environments in the same                                way with the same libraries and being                                sure that all of that will be run in the                                same manner but the question is why                                docker three things that I could think                                of is it's lightweight it's based on                                open standards and it's secure so more                                or less everything we need for running                                successful applications right and but                                why doctor again if we will look at the                                traditional virtual machine and how                                that's run we have a hardware layer at                                the bottom then we have a host operating                                system that runs the hardware that's                                something that we need on top of that we                                have a hypervisor process that controls                                the virtual machine and allows it to run                                guest operating systems those operating                                systems that are a part of each virtual                                machine this is an overhead of a virtual                                machine itself because it needs a                                separate operating system on top of that                                we have libraries for the application                                and finally the application itself this                                is how the traditional virtual machine                                stack looks like then we have the                                container stack that                                but the bottom looks very similar we                                have a hardware layer and the host                                operating system we can't get rid of                                 that yet then we have more or less a                                 hypervisor process in our case it will                                 be a doctor in gene that controls the                                 containers and allows them to actually                                 run finally without the guest operating                                 system we have a small lightweight                                 container that instead of having the                                 full operating system provides us only                                 with the needed parts and allow us to                                 quickly and easily deploy and run                                 application with its libraries without                                 any issues at all so as you can see we                                 gain we remove the guest operating                                 system from the equation and we gain                                 some resources needed for running the                                 Dead part of the of the stack why                                 elasticsearch distributed by design                                 based on the scene with great features                                 lots of features search aggregation                                 monitoring api's all the api's that                                 allow you to control and work with the                                 clusters themselves of course talk to                                 the we talked to eat with JSON it                                 responds with JSON and it has a REST API                                 that's easily usable for us so now how                                 to run elasticsearch on docker and again                                 this is a very straightforward process                                 we just type dr. run minus D and specify                                 the name of the container which in our                                 case is the official elasticsearch                                 container and things start we can also                                 run things like say latest or use the                                 version that we are actually interested                                 in like                                                                 and things will do start automatically                                 for us so dr. will download the needed                                 container either from the official                                 repositories or from private cab and                                 we'll start the container itself we can                                 also provide names for the containers so                                 with they are easier to operate we can                                 provide environment variables like                                 having elasticsearch to use a certain                                 keep like here with minus e switch and                                 providing the proper environment                                 variable                                 understood by elasticsearch or provide                                 some additional properties like here                                 minus D nodename bebas which will make                                 elasticsearch container use the node                                 name and start a name with a given node                                 that's the basics of running however                                 when you run multiple containers on a                                 single very metal machine because we                                 usually want to do that because we want                                 to maximize the usage of our hardware                                 not to lose money we want to put some                                 constraints on the containers so they                                 are not using all of the resources that                                 are available on the machine imagine                                 that one of your containers ran into GC                                 issues or memory or iOS or anything like                                 that then it can eat up memory it can                                 adapt CPUs and we don't want to do that                                 we don't want it to do that so we can                                 for example put constraints on the usage                                 of the memory like with minus M switch                                 and space and specify to G which means I                                 container only use two gigabytes of                                 memory at most we can disable swap or by                                 the way all those all those constraints                                 and commands are available in the                                 reference documentation of da car                                 engines so the link is in the bottom so                                 you can look it up those are only                                 examples in addition to that we have the                                 availability of specifying which course                                 of CPU we want we want to run with the                                 container so we can only limit some if                                 we have                                                             processors we can just say ok that                                 container will use processing CPUs                                 enumerated one and three and that's all                                 nothing else in addition to that we can                                 also put quote on the cpu further                                 limiting down the number of cycles the                                 container is a actually able to use the                                 good practices around that is we should                                 limit container memory because we don't                                 want it to use all of that all of the                                 memories the large amount of memories                                 with having in our bare metal machines                                 we should account for the i/o cash                                 that's especially true for elastic                                 search we should limit the amount of CPU                                 cores room                                 remembering about the garbage collector                                 because if we don't remember about                                 garbage collector and we only constraint                                 on some amount of course for the                                 container we may end up with container                                 not being able to run properly because                                 GC will start to give issues of course                                 we can provide things like properties to                                 elasticsearch when running the it in the                                 docker container but we can also create                                 our own images that are optimized for                                 our use cases right so for example here                                 we create the dockerfile something a                                 file really really a text file called                                 docker file and we specify it contents                                 here it is a very very simple example of                                 how you create an image actually so from                                 elasticsearch means that it is from the                                 official elasticsearch container and we                                 will add a local file called elastic                                 search gamble and put it in the                                 configuration director of the good of                                 the container then a simple build                                 command will give us the ability to run                                 to build the container and run it                                 without further modifying that those                                 work to thinks some configuration and                                 constraints then we have to deal with                                 memory by default the container doesn't                                 expose any network outside of each of it                                 running so whenever you run the elastic                                 search on doctor and you try to for                                 example go to localhost                                                be able to connect to that container and                                 that's where port forwarding by                                    docker gets into play with minus P we                                 can tell which parts from the container                                 should be exposed outside of the                                 container itself here we exposed to                                 ports                                                                                                                                       plastic surg now we'll be able to use                                 the container outside of its own network                                 in docker in addition to that we can                                 lick link containers together to create                                 a very simple plaster for example on                                 local machine to do that we use the                                 minus minus link and we provide the name                                 of the container that we want                                 the starting container to link to so                                 here we link the container that will                                 just run we'll try to run to the                                 container called es                                                     Zen unicast hosts for the container to                                 actually know which elasticsearch node                                 to connect to hear it would connect to                                 the es one means meaning that they would                                 actually create a cluster in addition to                                 the when starting and when the discovery                                 kicks in in elastic search whenever                                 creating your own containers remember to                                 add two things first the network                                 published host and then the standard                                 discoveries and ink unicast host to be                                 able to actually connect multiple                                 containers to each other next thing the                                 good practices is about actually                                 configuring a network to separate part                                 of it for elasticsearch cluster use the                                 common names for doctor and common host                                 names so that you actually know when                                 you're looking at the containers what's                                 happening there expose only needed ports                                 so don't expose any anything unless you                                 need it this is good for security                                 reasons and finally to have a good                                 plaster and expose a sorry point the                                 data and client notes only to the master                                 node so they could connect to each other                                 they don't need to see anything apart                                 from that of course they will talk to                                 each other internally but whenever                                 starting up and when the discovery needs                                 to actually run you need to only point                                 the data and client notes to the masters                                 mmm finally dealing with storage by                                 default the data in your container will                                 be stored in users share elasticsearch                                 data however the problem that comes with                                 it is that it is not persistent so                                 whenever container goes down or you kill                                 it the data will go away there are two                                 things we can do first of all we can map                                 the directories                                 from the container to our local disks                                 like here we map the user sure                                 elasticsearch data to elasticsearch data                                 on our local bare metal machine and it                                 will stay that way and the data will be                                 there keep in mind permissions you need                                 to have properly set permissions for the                                 inside process to be able to access the                                 files on the disk of the or host                                 operating system and the second thing is                                 using sorry is using the data only                                 docker volumes which are persisted and                                 can be shared between containers so they                                 bypass the Union file system then can be                                 shared between containers as we just                                 said and the container can be deleted                                 and the data will still be persisted in                                 a state on a disk inside as a separate                                 volume container so how to create them                                 it's as simple as running the following                                 the following command docker create we                                 map some part of the sorry some part of                                 our local disk to that user share                                 elasticsearch data we provide it with a                                 name it's needed like here yes data this                                 is the name of the container and finally                                 when running docker and the proper                                 container the elasticsearch container                                 itself we can say volumes from and give                                 that name and that we that we've used so                                 that so that the container running                                 elasticsearch will be you will be using                                 the volume container that we've just                                 created so this is about docker itself                                 how to run highly available clusters on                                 with elastic search remember about a few                                 things first of all divided the roles of                                 your notes so masternodes should there                                 should be only master notes only data                                 nodes and only client notes so master                                 notes are not overloaded with the data                                 and and color and sorry queries in                                 addition to that remember about setting                                 the minimum master                                 notes                                                                eligible notes that will help you with                                 network splits and avoiding data                                 corruption how to run those it's as                                 simple as providing the proper                                 parameters for the elastic search                                 container on docker we said node master                                 equals true no data equals false and                                 note that the client equals false and we                                 have a running master we do the same for                                 the client and we can do the same for                                 the data node just different different                                 place to set to set true of course if                                 we're running time based data which                                 elasticsearch is great for we can also                                 help each other meaning we and doctor                                 can help us to run the multiple tiers in                                 our architecture so usually you will end                                 up with having cotton cold tears the hot                                 code the hot air for the recent data                                 real-time searches with all the with all                                 the indexing happening and finally the                                 cold data the archive for for for that                                 however instead of creating different                                 hardware how instead of putting                                 different hardware there we can put                                 different constraints on our containers                                 and just say hey elasticsearch minus                                 denote dot tag equals hot and then                                 during index creation we just use the                                 standard routing the location to put the                                 index in a proper place now if the                                 container has more cpus and more memory                                 it can handle real time data well still                                 have the same flexibility of moving                                 containers around starting them stopping                                 them on demand and all of that of course                                 moving that data is also very easy as                                 it's a part of elastic search api                                 finally as i have                                                        like to tell you a few things around                                 metrics that you should take care about                                 whenever dealing with containerized                                 elasticsearch environment so first of                                 all keep in mind that health api and                                 charts API will give you the idea                                 the top level view of the cluster                                 monitor your CPU usage because that will                                 help you knowing what's during the                                 container halma how much stress you                                 actually put on the container itself                                 it's close to one hundred percent in                                 usage that means that you don't have the                                 overhead of spikes that's bad because                                 elasticsearch and the cluster itself                                 will crash whatever its bags happen or                                 or you won't be able to use                                 elasticsearch because it will be                                 overloaded keep in mind that the memory                                 usage is also helpful for you especially                                 on the graphs where you can see if you                                 need more memory more constraints loosen                                 up the constraints for elastic search or                                 not in addition to that I owe usage is                                 again your friend because that will                                 allow you to see and especially with the                                 correlation with merges and requests                                 rates with what's happening there if                                 that's normal or maybe that spike there                                 is about the merges and we have to do                                 something about them loosen up and allow                                 a longer tail of segments to be there                                 for us to be properly running then the                                 JVM heap and the garbage collection                                 statistics allow us to see what's there                                 in the memory of our JVMs and how the                                 heap is actually being cleared up and                                 how garbage collection works usually                                 won't have fast but often and very fast                                 garbage collection instead of one but                                 longer which can lead us stop the world                                 DC event request and latency allows us                                 to actually see what how we are using                                 our elasticsearch what's there if the                                 spikes there is something we know that                                 will occur on or something that happened                                 and we should take a look in that if you                                 are using                                 a tool elasticsearch and dog values                                 field data cache is mostly not an issue                                 for you but if you still do analyze or                                 if you still use aggregation or analyze                                 fields keep in mind field data can kill                                 you finally indexing again something to                                 look for because you will probably get a                                 lot of indexing in your clusters                                 especially if you're doing analysis on                                 time based data they tell the last ones                                 the Refresh time which will help you                                 with seeing if you are actually okay                                 with refresh you have or if it's too                                 often and how often it happens finally                                 the merge time which will help you                                 knowing what how your I always used and                                 all of that so because we only have                                    minutes I will do if you have any                                 questions to me I would like you to get                                 here i'll be here standing and I answer                                 them all for now that's all thank you                                 very much for listening I know it's been                                 very short and fast but we only have                                    minutes by the way if you keen on that                                 stuff we are hiring at some attacks                                 thank you and enjoy the rest of the                                 conference                                 in stuff I will take one question and                                 then we have a short break before the                                 next talk how do you supervise                                 containers and how do you handle                                 container failures actually that depends                                 on what you actually want to do some how                                 to handle contain your container                                 failures right elasticsearch along with                                 the container itself can be started                                 without the niche for example if you                                 have a monitoring software that will                                 allow you to react on some kind of alert                                 like nodes going down for example at                                 bare metal server went down you can just                                 spin up new containers at the perfect                                 thing around elasticsearch that will be                                 replicated the data will be replicated                                 without any issues you can also use some                                 kind of other more sophisticated                                 solutions like metals and do the all                                 that spinning up and scaling                                 automatically so depending on what you                                 actually want to use their you have an                                 options for example meses is a good                                 thing to look at if you would like to                                 have something that automatically reacts                                 towards being done with the containers                                 right now but that's a different                                 different topics oh yeah all right let's                                 take the speaking again okay if you have                                 any more questions I'm here thank you
YouTube URL: https://www.youtube.com/watch?v=D2zR-6Tke8o


