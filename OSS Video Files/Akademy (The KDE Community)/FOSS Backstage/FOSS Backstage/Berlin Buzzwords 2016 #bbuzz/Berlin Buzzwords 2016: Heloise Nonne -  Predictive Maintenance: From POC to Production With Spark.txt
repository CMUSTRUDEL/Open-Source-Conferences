Title: Berlin Buzzwords 2016: Heloise Nonne -  Predictive Maintenance: From POC to Production With Spark
Publication date: 2016-06-11
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Today's industrial systems produce more and more data everyday. Companies are increasingly using Big Data technologies and data analysis approaches in order to monitor their systems.

I will illustrate this trend with a project of predictive maintenance on trains. In cities where millions of people use public transportation everyday, avoiding faults on trains during circulations is critical. The goal of the project is to predict faults on trains in advance so that can be are dispatched to the workshops accordingly, thus avoiding train delays and reducing maintenance costs.

I'll explain our approach which uses random forests and artificial neural networks with theano, what are the results and how we measure success, and finally how, from developing models on historical data with python, we progressively moved to production and transposed the models to a distributed environment using Spark.

Read more:
https://2016.berlinbuzzwords.de/session/online-learning-vowpal-wabbit-and-hadoop

About Heloise Nonne:
https://2016.berlinbuzzwords.de/users/heloise-nonne

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              thank you good morning everyone so I'm                               going to tell you about a project I've                               been working on recently actually since                               until today as a data scientist from                               this company company which is doing a                               consulting in the designs for many                               clients including SNCF which is the                               French train company and tomorrow I will                               be working as a data scientist for my                                clients so I will switch to SNCF and I'm                                going to talk about predictive                                maintenance and trains so some part of                                it i will talk about when I say we is as                                the scientists from the team who started                                the project with a proof of concept but                                sometimes I'll say we as SNCF although                                at the end of the session I won't take                                questions on the ongoing strikes for                                those going to Paris for the euro I                                don't have predictions on that so you                                can take your questions to the French                                Bundestag but I can't answer on that                                anyway so let me give you some facts                                first and some data to give you some                                context where nine billion people on                                earth two out of three live in urban                                areas and when you take Paris area you                                have                                                                   what does it mean daily for train                                company and since he F has to run                                   lines                                                                there are more than                                                     and moving around all these people so                                that puts a lot of country constraints                                on the train engineers and those                                constraints are very important so mainly                                you are five your trends have to be                                reliable absolutely reliable you need to                                have them available because                                             to run every day I mean you need to be                                well organized                                safety is extremely important you cannot                                make any mistake because lies are a                                stake economies at stake there's a huge                                constrain the costs for maintenance is                                also very high it's important and a                                slight change means different than                                difference in cost and also you have to                                comply with regulations so that's that                                gives you an idea about how the                                different parameters engineers have to                                deal with so all the trains well they                                were not very collected so you had to                                rely on pure engineering so there is a                                lot of knowledge about this and it                                worked but now that's so many people                                take trains every day this may not be                                sufficient to to run so many trains                                every day so you may use connected                                trains but luckily today with Internet                                of Things you have the possibility to                                get data from the trains and now trains                                are digital natives such as this one                                that replace the other one that I showed                                you so those are bombardier trains they                                are pure I mean it's it's filled with                                electronics in it so this is very new it                                coming to kates a lot they are talking                                all the time there is one computer in                                each vehicle so for each train you have                                six you have seven or eight vehicle and                                this computer generates a lot of data so                                it's not that huge for I mean big data                                people like you but for train engineers                                it's really new I mean this type of data                                arriving in real time this is completely                                new in their process so they are                                changing the process to eat this kind of                                data and use it as much as they can to                                improve maintenance and you have                                fourteen forty thousand different                                variable so a human cannot deal with it                                you need nicely designed                                sense to to deal with that so what kind                                of data comes from the trains I mean                                they just monitor everything they                                monitor material functions of the train                                they Molitor operations and then you                                have dates are coming from the wind                                scene with winch screen monitoring I                                mean it just check if there is enough                                liquid to clean it so it's it's really                                huge and safety are also is important                                because you cannot run train if a door                                is open it's it's impossible so you get                                all these data and you use it to improve                                your maintenance so that's what is in                                production today so before classic                                maintenance you had a failure you send a                                 train to workshop you to your diagnostic                                 there and you fix it and you send back                                 your train so this is a very low level                                 in terms of value and analytics and and                                 I mean you don't use the data because                                 you just are in front of the fact and                                 you fix it then you move to connecting                                 maintenance you can do your diagnostic                                 when the Train is in operation so that                                 you know where to send it which were                                 shot should you send your train to and                                 which failure is it about so you can                                 plan your you can plan your maintenance                                 in advance that allows you to have more                                 reliable trains and make it more                                 available as well and then you move                                 again to a proactive that means that you                                 do your dynastic during operations and                                 you can also since you have information                                 about your failure you can prioritize                                 maintenance meaning you can target in                                 priority failures that can have an                                 impact on operations and leave failures                                 that are less important for later so                                 you're planning is optimized now the key                                 benefits are of course increase                                 reliability availability and you reduce                                 your cost you make the right                                 just at the right moment and you move                                 from systemic maintenance such as what                                 you do with your car your car you're                                 sending every two years but sometimes                                 it's not necessary sometimes you should                                 have sent it before sometimes you you                                 can wait to two more years so this is                                 systematic and now they are moved to                                 condition-based maintenance so they                                 monitor recognition and they adapt the                                 maintenance according to it so what's in                                 production today is data analysis so                                 they have filters and they monitor coats                                 coming from trains and they say okay                                 there is an error there is something to                                 do with this train this train is okay                                 and so they have the fleet's the fleet                                 supervisor has a dashboard saying okay                                 this trying is coughing a bit there is                                 something to do with with with it you                                 should plan a maintenance in workshop                                 and remove it from circulation and                                 replace it with another train that's                                 feeling better the question is now can                                 we predict failure before they happen                                 because here its failure I mean there                                 are many Tony Nguyen time so they know                                 exactly when it happens it's better than                                 before but if you can predict it's like                                                                                                       because then you know okay                                              have a high probability to have a                                 problem with this train I'm not going to                                 send it on the tracks I'm going to                                 replace it with another one so you avoid                                 impact and hundreds of people in cities                                 like Paris it's very important so even                                                                                                     something that you win on your operation                                 so you'd like to use I mean everyone                                 talks about Big Data everyone talks                                 about machine learning deep learning so                                 I sense yes thought okay we're going to                                 try this I mean we don't have Big Data                                 technologies in our system in our                                 operation in our production now but                                 let's try it so that has that may have                                 an impact on                                 raishin but also it has an impact on the                                 knowledge as well machine learning can                                 could help to reinforce engineering                                 knowledge in the sense that you have                                 experts trained experts have a very long                                 history of dealing with trains so they                                 know what's happening they have good                                 knowledge of the phenomenon that have up                                 here but sometimes they have pre                                 conceived ideas they have intuition but                                 something may be non-intuitive you may                                 have correlations that you can't                                 anticipate according to you expert                                 knowledge and that's where machine Alec                                 will help on                                                          cannot get cannot extract knowledge but                                 maybe machine learning can add something                                 more they want it won't replace experts                                 but it could add some useful knowledge                                 to it and produce rules AG rules about                                 the physics but also something that may                                 not be explained but that's known                                 another thing also is that when you have                                 new material you need to learn about how                                 its aging and those new trains there are                                 so many electronic functions in it it's                                 new so they don't have                                             running this a chronic part to build                                 knowledge on so you need to construct                                 this new knowledge on this new part of                                 the materials day and it's it's a noun                                 so machine learning and the data could                                 speed up how expert learn about the                                 aging rules so that's the process that                                 they are putting in place to deal with                                 this aging trains are put in place                                 faster                                 so that's how this project was born a                                 sense EF so thought to start this                                 machine earning big data analysis                                 project but the thing is that you have                                 operations you cannot make mistake                                 mistake in production it's not like                                 marketing when you make a mistake you                                 can you target the clients and it's you                                 target it's wrongly that's okay nobody                                 is going to die but trains you don't                                 have room for mistake so for for big                                 data in something completely new for the                                 industry you need to prove that is going                                 to work and you need to prove if it's                                 reliable or not and if it's not reliable                                 there is some uncertainty you have to                                 control it you cannot let an artificial                                 intelligence do something that you can't                                 control so that's why this project was                                 very constrained in terms of in terms of                                 time because we had to prove it worked                                 and we have to prove very fast so the                                 proof-of-concept part we had ten weeks                                 two weeks to learn about the data I get                                 it and meet the third and then eight                                 weeks to do the problem so data cleaning                                 getting the data crossing thanks and                                 countering problems and they'll build a                                 machine learning system and predict                                 failures so that was very very short                                 that constraint is important to have in                                 mind because I mean when I first learn                                 about the project I thought okay yeah                                 we're going to do deep learning X neural                                 networks and everything that you can do                                 that today in eight weeks you have to be                                 pragmatic and you have to stick to                                 existing processes because it has to go                                 very good if it works if it seems to                                 work this has to go very quickly in                                 prediction because there are costs                                 associated with and if you can gain                                 return on it you have to put it in                                 project in production very fast so there                                 was a push to go very quickly although i                                 would have liked as a data scientist i                                 understand why they were                                 I mean SMF was so pushy to put in                                 production but from the data in default                                 of you i would have liked more time to                                 consolidate but this is a constrain and                                 it makes sense so this proof-of-concept                                 was done and then since apparently it                                 worked we put it and we put up a pilot                                 so moving from Park part to a production                                 like to measure to be able to measure                                 what happens in real conditions because                                 there is always a big difference when                                 you work on historical data and real                                 data hot day they are coming from the                                 trains and right now we are at the                                 beginning of this phase that should last                                 for six months we are just going to                                 watch what's happening if the failures                                 are predicted correctly which are                                 predicted wrong to know what's happening                                 because we don't know what what what's                                 going on in in real condition yet and                                 then if it works with if we manage to                                 tune everything we're going to put it in                                 real production and with this comes the                                 red problem the change management                                 because you're pouring a machine                                 learning into an existing process that                                 you cannot change for success processes                                 have been there for a long time and they                                 are there for good reasons so you have                                 to stick to this and adapt but evolve                                 mentally evolve how expert deal with                                 that and that's our questions today so                                 that's the contest contest of at this                                 project and I'm going to tell you the                                 road that we have have done since about                                 the beginning of this this                                 proof-of-concept so the first challenge                                 is that failures I know people are going                                 to say that's not true but I tell you                                 it's true they are very rare very very                                 very I try to ask them to produce more                                 failures but somehow they didn't want to                                 do it so we had to deal with this and                                 for machine learning you don't have                                 examples about                                 you still have to learn from its side                                 it's very difficult a second problem                                 also ish although I mean trains have                                 been running for a long time but these                                 trains have been running for two years                                 at most today it's been two years so at                                 that time we had like                                           available that's very very very small                                 and that's a problem to have efficient                                 machine learning another challenge that                                 you most of you may not encounter I mean                                 if you take a young company such as the                                 longer i know people around here from                                 zalando it's from                                                     few years you take an oil company Google                                                                                                         are digital natives when you take a                                 sense yes it's from                                                      if you're trying to do big data if you                                 are trying to do data analysis you have                                 to deal with data and processes and                                 information systems that are very old                                 and that were born long before big data                                 so that comes with challenges that data                                 big data engineers may not I mean don't                                 anchored her every day because they have                                 nice logs produced by new applications                                 and it's all very nice but well for is                                 in CF it's slightly different so the                                 challenge is about data first is data                                 quality I mean you have unclean data                                 like everywhere but in addition you have                                 data I mean there it's it's not clean or                                 not reliable for different reasons for                                 trains for instance we wanted to do                                 supervised learning so we had to build a                                 target so the target was a failure but                                 failure how a failure is identified it                                 comes from many different sources so                                 either the Train realize itself that                                 there is a failure in that case the time                                 of occurrence of the fear failure is                                 precise because it's new electric system                                 but it may be your driver your driver                                 has a problem so he realized that there                                 is something he there is something a                                 door for instance okay so he stopped the                                 train he gets done his cabin walks along                                 the tracks check on the door closed it                                 manually and then comes back to the                                 cabin he calls someone he pushed a                                 button but the time of occurrence of                                 your failure is completely and precise                                 you have no idea maybe it was                                           before it's your information maybe it                                 was later there is uncertainty about the                                 time it could be the fleet supervisor so                                 there is a lot of uncertainty in in your                                 processes and when you build a target or                                 that I sign this you like when it when                                 it's precise but the target is not                                 precise another thing is all is you need                                 to identify which type of failure it is                                 so you need feedback from technicians in                                 workshops that means they are entering                                 information at the end of their day                                 after fixing several failures on train                                 at at the end of the day they go back                                 they enter this manually in the system                                 that means sometimes it's a natural rate                                 they are they may be in a hurry there                                 may be a an emergency somewhere so there                                 is also something very imp resides                                 although it's a modern modern way to                                 produce data I mean it's                                              but still it's you have to deal with                                 that so you may I mean you may need to                                 do when lp                                                              more noise and in your process so it's                                 data is generated through various and                                 very complex processes some insurances                                 it's like a living organism so there are                                 many functions and it's difficult to                                 deal with it may not be big data but                                 it's big in the sense that it's                                 completely heterogeneous                                 and sometimes getting data is difficult                                 because there may be contracts with a                                 train constructor that doesn't allow the                                 train company to get some type of data                                 for some reason so it's a long process                                 and in eight weeks we some some part of                                 the data we would have liked to have we                                 didn't get but we had the main the core                                 data which was the data coming from the                                 trains the codes and operation data so                                 another funny challenges that we did not                                 anticipate it is that trains dream when                                 they sleep so I didn't know about that                                 I'm sure he didn't know about that                                 either but yes I mean in the system in                                 train computers generate codes I mean                                 the analyzed physical data of vibration                                 and everything and then they said they                                 ike radiate this data and the site code                                 so there are about four these trains are                                 about                                                                   our core data and there was one code                                 saying okay the driver enter the train                                 he pushed button and he started the                                 train and there was another code to say                                 the driver goal of the train and                                 finished his mission and when you want                                 to predict failure you don't want data                                 coming from trains outside of operations                                 because there may be a technicians a                                 technician passing by and Adam are                                 collecting a cable that sends a code but                                 it has no meaning about operation so you                                 have to remove this data so we shall                                 okay that's uh I we did not anticipate                                 that the we didn't know that trains                                 would talk there in their dreams but                                 they do so you have to take out the data                                 and we tried this and then actually the                                 performance of our machine learning                                 system was very bad and we didn't know                                 about that we didn't know why it turned                                 out that actually the process of                                 terminating the mission is                                 is wrong so that the code that we are                                 targeting to take off the useless data                                 was wrong so we were learning about the                                 train stream but it wasn't very useful                                 so actually we had to get the data                                 monitoring so from a completely                                 different information system data saying                                 this train started at this hour from                                 this station and it ended at this hour                                 from this station so that's that's okay                                 data exists but that adds a lot of                                 complexity in your system since okay                                 before you thought you could rely on one                                 source of data that's precise actually                                 it's not precise so you have to cross it                                 with another source and you have to                                 filter out data that means that in                                 production it has a cost in terms of                                 calculation it's it's really important                                 and you may lose two weeks in your                                 project trying to fix this problem and                                 also since the data is produced in                                 production you cannot go back to the                                 systems and ask the people to change to                                 think because people having a hand on                                 how the computer sends data is the                                 constructor so you have to go back then                                 change a contract with the constructor                                 it's impossible to fix I mean in a short                                 time so you have really this constraint                                 that your system is really complex and                                 involve many different entities and                                 that's different from many companies                                 that you know about I think anyway so                                 how did work very quickly because I                                 think you know about this so we have                                 sequences of code and since we are doing                                 supervised learning we need to aggregate                                 this to have one line with one target                                 saying okay at this this hour there was                                 a failure this time there was not a                                 failure and everything so you had                                 somehow to take some time on which youth                                 monitor your data and you count number                                 of each codes things like I                                 means you calculate the average duration                                 of a code thanks a lot so you add you                                 aggregate your data so that you have                                 sequences corresponding to different                                 trains and after the sequences like                                    minutes later you say there was a                                 failure or there was not a failure so                                 that's how we did it that's very simple                                 but we had to be pragmatic and go fast                                 and we thought supervised learning would                                 work because it stable it works almost                                 all the time you take random forest it                                 is going to work anyway it it may have                                 lower performance than neural networks                                 but in eight weeks there is no way you                                 can develop a neural network and do deep                                 learning on this so that was the safe                                 approach we knew were going to work so                                 that that's how it works so we have                                 identified a false in all the trains all                                 the time and to generate lines that has                                 that leads to a fault we take the fault                                 we take a horse and prediction so like                                                                                                       want to go in advance and then you want                                 to share your code for some time so in                                 this example on for hours I take four                                 hours off of codes I aggregate I look at                                 it I feed it to a machine learning                                 system and I it's going to learn whether                                 or not                                                                failure or not so that's how you do with                                 your goggle like a problem you have a                                 history you separate it you learn on                                 thirty seventy percent of your data and                                 then you test it on thirty percent but                                 that's history and real really real life                                 data it's different because you have hot                                 data this is cold data and it makes                                 change and that's actually what we are                                 saying today I mean it changes it's not                                 the same so you have and you need your                                 data in production and you need to have                                 it to work lately like that                                 but when you do it when you do a proof                                 of concept in eight weeks your data                                 scientists work light so I mean it's                                 difficult you have your data engineers                                 that know about spark and the are                                 playing with a cluster and your data                                 sense this work with Python insert                                 reason I mean that's me I know and we                                 had to communicate with the data                                 engineer transposing your our code that                                 was designed very quickly very pragmatic                                 way they had to put it in production and                                 make it work and that was difficult we                                 didn't think at first in terms of                                 distributed computation so we had to                                 change reorder our code so that it would                                 be possible to distribute computation of                                 our trains well I took some time to to                                 design I mean it was different also                                 writing efficient spark code translating                                 from a park written in Python I I                                 thought it would be easier because spark                                 you know they tell you we have data                                 frame it's very much like pandas                                 dataframe well I catch exists is not                                 very true here it is very difficult so                                 it took a lot of a lot of work to                                 transpose it but Indian it's it's it's                                 okay so but there were questions also                                 how do you validate that your pilot's                                 reproduce what your proof of concept did                                 there are differences in implementation                                 I didn't know about that but less is not                                 the same as less than equal in Python                                 and spark so when we would try to                                 compare different at different points                                 how our data was provided so we we took                                 data from the proof of concept and we                                 try to compare the data with a pilot but                                 there were lines didn't match and it                                 took us sometimes to realize that less                                 was not less than equal I mean you don't                                 anticipate this kind of problem so we                                 thought we would develop this in one                                 month and a half actually it was                                 slightly more and there is a question                                 also when you want to compare                                 predictions and tradition performance                                 between a proof of concept and a pilot                                 so we had the random forest implemented                                 in Python in scikit-learn and we had the                                 random forests implemented in a leap but                                 actually one first up somehow random so                                 we cannot compare data with data it's                                 obviously not going to be the same so                                 you have to design new tests statistical                                 tests to be able to say okay this sign                                 is not the same you can't compare                                 trained by train it's impossible so I                                 mean this is new compared I mean machine                                 learning there is some randomness there                                 is some difference that's not the same                                 as doing a proof of concept with the                                 fixed application when you put machine                                 learning there it's you you have new                                 problems so what's our stack so we have                                 Hadoop cluster with spark so we most of                                 the know all data preparation and the                                 machine learning is done it's park and                                 there is some reporting parts that we do                                 because we need to send back information                                 to the experts so we have the web                                 application that's asking astok search                                 where results are stored so thats                                 angularjs that that reduce reporting for                                 the experts the Custer is quite small I                                 mean this is the beginning and the team                                 is learning and everything and there is                                 a question data we have is not so big so                                 we could have actually stick to python                                 and put it in production but we                                 anticipate that's very soon they're                                 going to be more trains generating more                                 data so we thought okay let's start with                                 this and learn right now since we have                                 some slack about time so that tomorrow                                 when we have real big data                                 we have encountered some problems and we                                 are starting to what to work with it so                                 how it works you have I'm sure you know                                 the psych lecture so you have you have                                 an incoming flux you prepare data you                                 store it for the training of your                                 problems your models you have some                                 reporting and hide learn how will it                                 learned and and then you update your                                 model that are in production and that                                 works on a hot data and this produces a                                 stream of near real-time predictions                                 that's sent to expert so that they can                                 use it I'm going to skip that because I                                 don't think it's so important we could                                 come back to this if i have questions                                 but that's how we deal with data and                                 coming from times it's not so so                                 interesting what we are aiming at is to                                 have a prediction so we it predicts                                    minutes before so at some point we                                 expect you have okay I have a one train                                 that's coming out of a workshop and then                                 at some point its aging I mean things                                 are going wrong so we expect that at                                 least we can rely on looking at the                                 history of prediction when failure is                                 going to occur at some point probably                                 your machine learning is going to say                                 I'm sure something is going wrong and                                 the half an hour later that's it's                                 saying I think it's really going wrong                                 and then you can see it increase so                                 that's why how you can take decisions on                                 this and when it reaches some alert                                 thresholds you can send it to a workshop                                 you fix it and then it comes back to                                 zero so that's the reporting for                                 training so we manager the performance                                 on the history so we check that machine                                 learning system worked correctly and                                 that's reporting for the experts so they                                 have their trains                                         the red ones are half problems and they                                 can click on it and have a list of all                                 operations for all the functions of the                                 trains so there is the door function the                                 the matter problem the every function of                                 the on the trend are about I mean it's                                 like metal functions different                                 equipments that our manager then it has                                 a prediction and it tells which is wrong                                 about it so in this case it's video                                 video surveillance and now I'm going to                                 speed up because I took too much time to                                 explain we have real life questions in                                 real life so we are here but we have to                                 implement implement this in our existing                                 process and I already mentioned it you                                 have to convince your expert that your                                 machine learning system I mean it's a                                 black box so and they have to be                                 convinced akande rely on the prediction                                 which are by a sense probabilistic so                                 you you need to control its you need to                                 rely to be able to rely with it and how                                 do you deal with false positive and                                 false negative you cannot send all your                                 training workshop because at some point                                 of your technician is going to say okay                                 but you were sending me trains that                                 don't have a failure and how do you tell                                 them yeah okay destroying I'm sending to                                 you it doesn't have a failure but it's                                 going to have it if you don't explain                                 why you're saying this it's it's                                 impossible you don't know what decision                                 to take technician is not going to to                                 know which door is has to fix so it's a                                 it's difficult and you have to read your                                 machine learning models and extract                                 knowledge from your random forest and                                 it's difficult scientifically taking the                                 terms of Technology and in terms of                                 change management that's where we are                                 right now so the next step is                                 using the pilot in test to find the best                                 parameters I mean how long should we                                 wait and how long should we wanted your                                 data to predict correctly number of                                 trees left and that's long to choose                                 this introduction in real life and we                                 have to chew to choose our threshold at                                 when do you take your decision when do                                 you stop a train and send it to a                                 workshop this has costs and these                                 decisions had to be made with reliable                                 knowledge and although there are many                                 other questions the data evolves there                                 are updates of your computer in trains                                 so data evolves and your machine                                 learning is not stable with this data                                 how do you deal with that how do you                                 ensure the stability of intelligence in                                 production what is a unit test for                                 machine learning system I have no idea i                                 mean i have some ideas but it's new                                 people don't have answer yet for that                                 and so that's our next steps and how do                                 you protect against malicious attacks                                 and that's the questions it's more like                                 my own questions and stuff is not                                 worried about that yet but when you want                                 to really know you're trying company you                                 can try to pour false data for your                                 machine running it's going to learn                                 nonsense and if it's in production it's                                 dangerous because if you manage to feed                                 stupid data to your machine learning and                                 it's it production it's very dangerous                                 so how do you protect again death and                                 how do you design alerts to see that                                 your machine learning is moving from                                 what it should do it's a it is difficult                                 so I'm going to skip the lessons learned                                 you make you will have this presentation                                 available but you need to basically add                                 your data scientists have to think about                                 prediction                                 more a lot before then then what was                                 done here but that's okay now we are                                 charging or the way to do with it and I                                 had some nice things about what's going                                 on right now right now actually we are                                 trying and proof of concept using neural                                 networks but thing is that it's very                                 very unstable most the reason being that                                 the data evolves with time and its                                 really really unstable that's why                                 supervised learning is a lot safer than                                 neural network and I'm supervised                                 learning so with that I thank you for                                 intention and if you have one or two                                 questions                                 Thank You Louise uh we have a question                                 here thank you for a talk very                                 interesting problem I'm just curious                                 what kind of accuracy can you get out of                                 that system with so many variables and                                 so little time to learn you mean in                                 terms of predictions yeah the accuracy I                                 mean it's it's it's not very easy to                                 tune to answer this question right now                                 because I have the answer on historical                                 data but actually accuracy is in itself                                 not so interesting the question is more                                 how much more accurate are you then                                 what's existing already so we try to                                 compare how you know I showed you                                 filters that how are in production today                                 and work on real-time data and we                                 compared these alerts coming from system                                 in production to the alerts that we                                 could have generated with the data and                                 we had what we of course has false                                 positive that's costly and forced                                 negative it's costly in terms of people                                 and impacts and alterations and we could                                 prove I mean we would see I don't have                                 the numbers in mind and it depends on                                 the parameters the number of trees you                                 have in your thing but they were so                                 again I mean they were thing is that you                                 targets the highest highest probability                                 before the first so when you take like                                 the                                                                  know what's in production would say we                                 detect two failures out of                                           would detect six out of                                                an increase and anyway even a slight                                 increase has real impact in sort of cost                                 so that proved the expert that what the                                 the approach was was good and it depends                                 also on which function you're talking                                 about if it's the                                 the doors for instance we were a lot                                 better than for air conditioning since                                 air conditioning actually you have                                 problems both of the time in June July                                 August so we didn't have so many                                 examples so it was a lost a lot less it                                 was not as good as yours Wow I'll just                                 go there and come to                                 thanks for the talk my question is you                                 were saying that you have about                                       variables we're using all of them to                                 train off on all your functions or maybe                                 a pre-selection and saying okay only                                 those                                                                 the other                                                        important for the doors yeah who gave                                 you that information so it's a it's a                                 very good question actually the experts                                 what they do is exactly that they have                                                                                                    beginning of these trains they monitor                                 almost manually and now they did also                                 the constructor I mean they know how the                                 codes were generated it's very long                                 process but they know codes                                      corresponds to this small part of this                                 function of this door but they asked us                                 to okay we know how to do this it's long                                 but we are doing it what we need you to                                 do is to take all the data you don't                                 filter it because we know we have                                 intuitions and we know there are                                 correlations they are non-intuitive                                 interactions between functions on the                                 train that's occur and we don't know                                 about it its weak signal and we want you                                 to use machine learning to extract this                                 weak signal so actually we took                                 everything everything and we cursed also                                 with material data other data coming                                 from different we basically try to take                                 everything we could without filtering                                 I'm afraid I I won't be able to take                                 more questions because we are running                                 out but you can check with alloys and                                 she can take it offline thanks for you                                 and you're standing                                 you
YouTube URL: https://www.youtube.com/watch?v=UW5WYQ6t6C8


