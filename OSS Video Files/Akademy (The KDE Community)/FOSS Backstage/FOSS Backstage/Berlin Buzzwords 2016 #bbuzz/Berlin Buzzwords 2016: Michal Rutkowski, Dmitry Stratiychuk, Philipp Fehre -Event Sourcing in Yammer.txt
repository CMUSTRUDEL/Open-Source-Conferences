Title: Berlin Buzzwords 2016: Michal Rutkowski, Dmitry Stratiychuk, Philipp Fehre -Event Sourcing in Yammer
Publication date: 2016-06-12
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Event Sourcing brings the promise of highly-scalable and loosely-coupled systems that are performant, reliable, and maintainable. It looked like a perfect solution for Yammer's reliability and performance challenges, but nothing comes for free!

Only slightly over a year ago, Yammer's entire system was either based on synchronous calls or Ruby workers and RabbitMQ. For a while, we have been moving performance-critical components out of the Ruby on Rails monolith toward Dropwizard-based services. This has served us well, but with increased reliability requirements, the pressure to simplify and decouple our system's architecture also increased.

Over the course of the last year, we first created a prototype implementation of Event Sourcing and, after validating the idea, have been moving it to a managed Azure Event Hubs based solution. 

We are going to cover not only how to migrate to a new technology, but also look at how to change organizational thinking from a synchronous world to one of event streams. We will tell the war stories of our migration from a self-hosted Kafka cluster to a solution based in the cloud.

Read more:
https://2016.berlinbuzzwords.de/session/event-sourcing-yammer

About Michal Rutkowski:
https://2016.berlinbuzzwords.de/users/michal-rutkowski

About Dmitry Stratiychuk:
https://2016.berlinbuzzwords.de/users/dmitry-stratiychuk

About Philipp Fehre:
https://2016.berlinbuzzwords.de/users/philipp-fehre

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              the mic on yes it is i guess so hello                               I'm Mohammad kofsky and this is joint                               work with my colleagues Dmitry strategic                               in Philip fair so Dmitry had to leave                               unfortunately all ready to cut his plane                               but Philip is here so we can talk to him                               and we afterwards if you want and we                               form part of we are part of a team or we                               we are the team called death SOA team                                and and this work this is about the work                                we did recently over several projects ok                                so can we fix the alignment but ok fair                                enough so yeah so briefly what does this                                talk about so i will first tell you a                                bit about the challenges we face which                                kind of led to this work then i will                                discuss why we actually turn to events                                or sink as a solution and the bulk of                                the talk will be about how we rolled it                                out and what we've learned from that                                roll out and I will conclude with the                                kind of future work we want to do in                                this area so what is yeah mer Yammer as                                the words say it's a enterprise social                                network but what that really means is                                it's a tool which helps teams                                collaborate we try to focus that                                collaboration within groups but we also                                provide more broader spectrum like a                                broader audience discussions and also we                                provide private discussions so there are                                quite a lot of features if you look at                                the those two slides the left-hand side                                shows the inbox view so this is the kind                                of content which is related to you and                                what you haven't read or left for later                                and you're on the right hand side you                                see a group so this is actually the                                Yammer engineering group so that's where                                we describe the broad engineering team                                discusses stuff so our core features                                message posting and messaging if you                                like but in reality if you look at the                                site a single message triggers a lot a                                single message posted event triggers a                                lot of actions which are powered by                                different components which are                                relatively independent so a message is                                typically address to somebody so it has                                to end up in your inbox or to address                                these inbox                                this most likely is posted in the                                context of a group so we want to deliver                                to a group but we also have aggregation                                of use for messages so if somebody is                                following me they will also have a view                                which shows my messages or messages of                                all the people they follow and if I'm                                very popular then that can be actually                                an expensive thing to compute and but                                also message posting triggers a ranking                                system so you see on the right hand side                                there's a little window which has my                                contacts and it's sorted by kind of                                popularity if you like but this again                                that can be affected by who I post to                                and who who's messages I like a reply to                                etc also on their left hand side you                                have the list of groups they have counts                                these need to be updated I have there's                                some real-time notifications depending                                like if I get something to my inbox some                                action happens again this is another                                flow so the gist of it is that a single                                event actually parcel of systems and                                impacts a lot of systems and so we are                                we're kind of a consumer product in the                                sense that we are actually trying to                                discover what our consumers need and                                what actually makes them engage in our                                product but at the same time where we're                                a corporate product so people use Yammer                                they actually quite often pay a license                                feed these days to actually get work                                done so to make that happen I mean to                                make them believe that they can get the                                work done we commit to an SLA so they                                can count on us being up and our                                internal external facing SLA is                                                                                                                                                                                 that's not very that's not a lot so and                                if we don't meet that sli we have to pay                                money sits and our reputation is hurt as                                well so that's very important but also                                since we are trying to attract customers                                is not like yummers not adapted for                                top-down decisions we want to have                                provide a good quality experience of                                 performances big chunk of it but                                 internally was important to us its                                 velocity                                 a so maybe you've heard some other kind                                 of more product focused talks from                                 Yammer but we measure everything and we                                 drive our product decisions based on                                 metrics we run AP tests and we see how                                 we will behave and if a feature is                                 wanted or is used then we keep it if not                                 we potentially scrape scrape it so in                                 that context putting too much spending                                 too much time building a first version                                 of feature just doesn't work because if                                 we have eighty percent chance but the                                 future will stay we don't want to invest                                 too much because it just is too costly                                 but what's important is that these two                                 are a bit slide odds right it's if you                                 want to deliver things fast your is very                                 difficult to meteor sli so the team                                 Philip and Demetri and I are working and                                 it's its focus is actually to help our                                 engineering organization meet these two                                 potentially conflicting requirements so                                 we want to enable people fast feature                                 building but at the same time not                                 compromising our sleigh and in broad                                 strokes what we do is we drive                                 discussion and we try to adopt better                                 archit better patterns around mostly                                 around the architecture but we also try                                 to build tooling and or adopt if there's                                 something of the shelf to make that more                                 make that possible so to give you an                                 example of what kind of work we do is we                                 are currently working on better tooling                                 for process and processed for release                                 management we have quite advanced                                 continuous delivery but there's always                                 room for improvement we also want to get                                 more advanced testing involves likes                                 inferences load testing we before things                                 are release of it we don't have                                 performance regressions we also drive                                 kind of discussion and tooling for best                                 service for best practices around                                 service design and development so we                                 encourage hire people to test for                                 failure especially kind of late latency                                 type fail around higher Layton sees we                                 build tools for would help engineers                                 well meet their quality of service                                 guarantees this is not to be confused                                 with the external SLI we want still our                                 components to kind of commit to some                                 sort of quality of service sli and                                 make it easy for engineers actually meet                                 that commitment but we also do a lot of                                 work around inter-services integration                                 patterns and this talk will be mostly                                 about this so this will be a familiar                                 story probably to most people but Yammer                                 started as a small start-up it was a                                 ruby on rails mana app back by postgres                                 very easy to develop very quick great                                 but as we became successful more                                 features were developed it just grew and                                 it grew to a quiet unwieldy sighs both                                 in terms of management like maintenance                                 but also kind of operational concerns it                                 was difficult to deploy at single point                                 of failure it was very difficult to                                 develop features because the sheer size                                 of the codebase was such but it was very                                 difficult to know what's happening and                                 also performance was hurting because                                 we're reaching the limits of our                                 postgres DB so what we started doing is                                 we started extracting the performance                                 critical components out of the app that                                 was that's how drop wizard was born was                                 born actually of the first few such                                 extractions the typical pattern was that                                 we would use rabbit as to facilitate an                                 asynchronous right to the extracted                                 functionality that functionality would                                 usually have its own data store and                                 would provide some sort of a                                 materialization of a more complex                                 expensive view which would then be back                                 the actual and rails moon app but as we                                 went on we started extracting more we                                 started actually creating user facing                                 services that requires authorization is                                 an authentication access control so we                                 had to create this as services we                                 stopped we started trying to limit the                                 amount of code we add to the monitor app                                 because we didn't want to make it grow                                 we actually wanted to make it make it                                 smaller so this is going quite complex                                 and we are quite early adopters of                                 extracting things into services so but                                 by around the time I joined that's was                                 the service dependency graph in the amur                                 quite difficult to comprehend and that                                 was mid-                                                               today nobody even attempt to draw our                                 defensive graph I think we have                                     something services few hundred nodes we                                 operated in our own DC we are moving to                                 her but it's basically there are                                 multiple it causes multiple pain points                                 because we arrived effectively at a                                 distributed model if and we try to get                                 out of that so what were the real issues                                 we faced so our feature development                                 slowed down quite a bit we have too many                                 inter-service dependencies which makes                                 it difficult to build something our                                 services are pretty chatty which                                 effectively means that we haven't drawn                                 our boundaries like the main boundaries                                 well so developing a new concept                                 typically requires iterating over                                 multiple services which is way more                                 expensive and it should be and we have                                 too many inter-service as their enter                                 team and cross timezone dependencies so                                 different services are kind of maybe not                                 own but maintained or expertise around                                 them is quite often contained in one                                 team which is local to an office that's                                 again if you have features which cross                                 multiple like multiple which go across                                 multiple services that's again quite a                                 bit of a headache for a project team to                                 roll out a feature in such situation but                                 not only that but it also made it                                 difficult for us to meet our SLA we had                                 too many external dependencies on the                                 Reid and bow and right paths that means                                 the chances of failure were actually                                 pretty high and making that the real                                 right path resilient required quite a                                 lot of investment because every                                 component had to be super resilient more                                 cerveny would expect we had a shirt DB                                 again a nice an type well nice a common                                 anti-pattern slows us down single point                                 of failure easy to go easy to break                                 furthermore with such a complex                                 dependency graph we it was beyond                                 comprehension so we had an expected                                 transitive transitive dependencies which                                 would typically we discovered using                                 during a and out                                 through cascading failures and there's                                 this there's a lot of good practice                                 around inter-service communication like                                 circle breaking to prevent cascading                                 failures but still we manage to see                                 quite a few of those because of the                                 complexity of our graph and again                                 because it was so complex it's difficult                                 to cut to test I mean the amount of                                 tests Kate complexity is immense so it                                 was actually relatively easy to roll out                                 the breaking code change which will slip                                 through the cracks so about a year ago                                 it was really bad I would say so we look                                 towards events or sink so there's a very                                 good article on msdn under the storm                                 events or things that's where i took the                                 diagram from but basically what we have                                 here is that instead of keeping the end                                 state of the system we focus on the                                 events that lead to the state change and                                 we keep them in an event store and our                                 views are searched from services would                                 actually subscribe to these events in                                 some fashion and materialized view so a                                 new feature would typically be a new                                 view on an existing events stream but                                 sometimes you will also add an event                                 stream so here we this is a very simple                                 example we have a cart with items so the                                 vents are create a card at an item                                 remove an item and the shopping cart                                 view kind of common one would hear would                                 be to the material as the current state                                 of the of the of the basket of the                                 shopping cart but it also could feed an                                 analytic system which kind of tries to                                 correlate items which are similar as                                 stuff in there completely independent                                 way so what we took away from that and                                 what was important to us was but for a                                 given piece of domain we have one data                                 owner service which coordinates the                                 rights and that's the system which                                 persists the version of the data in the                                 in the state in the primary sort of the                                 record its database and it publishes an                                 event but this kind of update happened                                 that no emotions got published this                                 method could create it                                 and we have multiple view services which                                 listen to those events and update their                                 local state by solidi b and the                                 researcher from these services so what                                 we're after is changing this into                                 something more like this i mean i                                 haven't read on that diagram and it's                                 just more high-level but think of it                                 this way a message comes in there's a                                 data owner for the message model it                                 publishes the event log and then we have                                 a view for a group so it materialized                                 the group view where that message was                                 posted the inbox so delivers to all the                                 people who should get that message                                 potentially a system which scent which                                 reacts the message and sends real-time                                 and notification push notification to                                 mobile to mobile clients there's a                                 subscriber which listens to those events                                 to see who messages with whom so if we                                 could provide better relevance and but                                 what's crucial all these systems are                                 completely independent so if one of them                                 fails none of them are affected adding a                                 new system a new feature which I don't                                 know checks what the which tracks when                                 the user was online so that I can maybe                                 send them a summary if they were offline                                 it's just adding a new subscriber                                 completely independent of previous                                 existing features well all it cares                                 about this message is being sent read                                 and this kind of stuff and so why is                                 this appealing to kind of if we are                                 looking to solve our previous problems                                 well we have less like those view                                 services because they provide                                 materialized views we have less learn                                 time dependencies that affects our SLA                                 but also a performance we have much less                                 chattiness so again it is good for                                 performance but also helps our velocity                                 because we kind of operate within a                                 single service when we are developing a                                 feature if loose coupling serve variant                                 on chat in essence the runtime                                 dependencies but applications in                                 generally more modular so and we publish                                 events not commands I think that's an                                 important point that's probably                                 something one of the bigger challenges                                 of rolling this out because we use so                                 many is we so often used queues in the                                 past people tend to think                                 of in terms of publishing commands but                                 commands provide pub coupling because                                 they're from particular sender to a                                 particular receiver and what we're after                                 here is about a universal message which                                 everybody can subscribe to and take                                 whatever I want be the difference is                                 instead of do this said I did this and                                 you do whatever you want you know what                                 you should do and in a sense it's also                                 provides better encapsulation of                                 services because the recipient knows                                 what how to react relevant the emitter                                 and it also makes it cheap to set up and                                 backfill a new service we and start                                 using it immediately without affecting                                 anything else so what were the                                 challenges we face when we started                                 rolling this rolling this out so first                                 of all we can it's a big change so we                                 can't roll it over night round out                                 overnight but more importantly there are                                 quite a few risks associated with it                                 what we looked at and what you've would                                 have we've seen in the past were                                 typically toy examples which we see it                                 during conference talks which kind of                                 our focus on exemplifying the idea but                                 like they have no way of addressing the                                 real pain points you will experience                                 when you run this this kind of approach                                 in production on a complex system which                                 is constantly changing and so the                                 concerns we had was can this actually                                 deliver like will the benefits not be                                 outweighed by the costs which will face                                 how long will it actually take for us to                                 learn how to do it properly I mean we                                 haven't done it before and what stack to                                 use this will require center of middle                                 were in our application and like what is                                 the cost like how what's the cost of                                 onboarding the technology to for that of                                 the which was used by that stack because                                 you need to have you need to train                                 people how to deal with uncle issues you                                 have to make it make sure that this                                 happens across time zones in a sustained                                 in a sustainable fashion so these are                                 actually high risks and potential high                                 costs so at a high level we had two                                 challenges we needed to validate event                                 sourcing see if it's actually worthwhile                                 and if it is we wanted to choose the                                 best stack but ideally we would like to                                 decouple these two we would like to                                 first validate before we make the big                                 investment in the text                                 back so because if we validate early and                                 deliver value early then we actually                                 have tangible evidence that we need to                                 invest in choosing the text back so what                                 we did was we chose a legacy system                                 which we had it was called vent it was                                 at some point intended for venting but                                 it was used in one particular scenario                                 and it's kind of forgotten and it also                                 had a somewhat awkward design because it                                 was fronted with an HTTP drop proxy                                 bison drop with a little salt sink there                                 was a Kafka back end and there was a                                 HTTP spout which was again a drop with                                 her service which was subscribing to                                 Kafka and relying events which is red                                 and we had some operational experience                                 with Kafka because we use it for our                                 logging pipeline we also use it for                                 should be we used to use it for our                                 metrics tripping pipeline so importantly                                 so this system was allowing us to model                                 the kind of pop sub event log backs                                 concept and it was built of components                                 we're familiar with even though it was                                 super centralized so it provided again a                                 single point of failure and it was had a                                 lot of cruft which wasn't really clear                                 why we needed it long term it's in these                                 are maintenance costs violent points etc                                 actually the reading part is a single                                 point of failure if somebody breaks the                                 configure we could potentially take the                                 whole application out and but crucially                                 it was built of familiar components                                 we're already operating relatively well                                 so that minimized our tech risk and                                 allows us to focus on validation and one                                 of the downsides which is via                                 centralization actually short term was a                                 benefit because it allowed us of it                                 right quickly if we were to update all                                 the clients all the time each time we                                 discover something we did something                                 wrong it would be a massive pain point                                 and slow down so the work we did                                 initially was we operationalized that                                 system fervor so we made sure that it                                 doesn't have some critical bugs which it                                 had because it was somewhat neglected                                 and we established we worked out an                                 api and semantics which was independent                                 of the input implementation this is                                 something we could move forward even if                                 we remove the proxies and we started                                 using pull model versus the push model                                 which the HTTP proxy kind of enforced on                                 us and we also built to link which                                 actually made it easier for our                                 customers would build consumers of the                                 of the vent streams it allowed them to                                 monitor the health of the consumer as                                 well as managing the events and we built                                 end-to-end test Suites one kind of                                 around correctness of the system like                                 not losing data and stuff and of                                 important different if its treated as                                 persistent and we also created fru put                                 and loud put low test so that                                 occasionally we we could comfortably                                 iterate on the system without risking                                 performance degradation and so and this                                 is quite important because this will                                 help us quite relatively quickly to move                                 to the next stack it's like the stack of                                 choice once we think it's worthwhile so                                 to give you an example when we made it                                 possible to generate this kind of                                 dashboards for every consumer very                                 easily we use a tool called wavefront we                                 push our metrics to it and this is our                                 visualization so on the top left corner                                 is probably the most important top left                                 here most important metric is the                                 consumer lag if the consumers are                                 lagging too much it basically means well                                 they have they're in trouble so that's                                 probably what people want to monitor our                                 an important thing of that of wave front                                 is that actually it makes it super easy                                 to programmatically and automatically                                 set up alerts so this kind of removes a                                 lot of friction around setting up any                                 because consumer and providing a quality                                 experience but we also have more kind of                                 fine greenview like hum end-to-end                                 latency processing rates type of errors                                 we see etc so this is but we also                                 provided management tools so this is                                 like a finger an edge case we have to                                 face when you do this kind of                                 transaction log system is you actually                                 can end up with events which are logical                                 corrupt I mean we are hoping for the                                 system itself doesn't corrupt met                                 messages I think there's a version of                                 kafka which actually corrupts                                 using it when it there's a core you have                                 to work around the data corruption when                                 using snappy but that can be resolved                                 but at an application domain level you                                 will also have poison pills would                                 basically cannot messages which the                                 consumer cannot process and doesn't know                                 what to do so so this tool is basically                                 allows us to once we detect where the                                 consumer is stuck by it's like like                                 growing we can actually investigate why                                 if we know it's not the consumer failing                                 because of operational reasons can                                 actually look at the message which                                 causes the problem we can put it to a                                 hospital to unblock immediately and have                                 quick mean time to recover like good                                 mean NP TR and or and we all we can                                 actually look at it and investigate it                                 and see what's the actual cause and was                                 the long-term resolution and this                                 unfortunately is used quite a lot so but                                 the ultimate validation of the idea is                                 to have projects or systems which                                 benefited from what we did and this is                                 this is the view by the end I think end                                 of October last year when we finish this                                 first phase and this was around this was                                 its focuses on messages creation because                                 this is the topic common to all the                                 components would I listed here but                                 there's more basically yeah this is the                                 core event message is created in the                                 past our rails rails application would                                 post this event to multiple rabid queues                                 and then each pipeline will have its own                                 worker doing something now it actually                                 is posted once and everybody is the same                                 event it helped rewrite hours it might                                 it really helped our rewrite search                                 project we moved to elasticsearch from a                                 custom solution mmm it helped our data                                 experts project which was which is very                                 important for our customer for legal                                 reasons but was very old and frequently                                 failing and it also helped our message                                 delivery as I said in the past there are                                 multiple views we must materialize them                                 on right and the old system this was                                 done in one transaction and these                                 aggregate views like                                 who fought the four people who follow me                                 or etc their complex their complex and                                 costly to compute so they actually could                                 cause failures on our inbox and group                                 delivery whereas probably people don't                                 care so much about the aggregations                                 where's inbox and group delivery                                 supercritical and we want to decouple                                 them and this event log concept made it                                 super made it very easy to actually do                                 that so what kind of problems we face                                 because it wasn't all rosy so this was                                 actually probably one of the biggest                                 problems which we still haven't resolved                                 it's we're kind of turning a blind eye                                 on it so what to actually publish in our                                 events because ideally would publish IDs                                 like this model change and this is the                                 version after the change so you can                                 actually access the state at the event                                 emission time but that requires                                 immutable version data which we don't                                 have in most places and it also requires                                 you to have uniform resource identifier                                 than well I mean we obviously do have                                 those but we many places they are full                                 of our different conventions so we're                                 trying to address this obviously but                                 this is a transitional problem so I                                 think in in quite a few places where the                                 size was actually a problem we should                                 lucky enough to have version data and we                                 use actually identify errs but in other                                 places we are publishing the whole data                                 where we can or we are trying to work                                 around this but ideally you want to go                                 to a mutable data and your eyes and                                 something we've discovered is actually                                 that as the application grows well                                 there's a single model owner which                                 coordinates the right actually as we                                 build features we enrich the model so                                 the different enrichments may have                                 different owners but it's because we                                 don't want to have a topic explosion we                                 want to have it conceptually grow with                                 the number of models we have not with                                 the number of features which come and go                                 and we will want to share a topic                                 and we had to actually learn like we had                                 this is something we were challenged                                 initially we were kind of lost like our                                 consumers were failing because somebody                                 some peas are publishing something new                                 and that's why this tool live later                                 earlier showed about for handling bad                                 messages was used quite often but yeah                                 we're at the moment I think it's very                                 and it doesn't happen I mean people                                 we've learned how to write our consumers                                 in a resilient fashion so we know what                                 we are interested in and if it's not                                 what we are what we want we can skip it                                 and just move on so yeah there's a yeah                                 we learned that we are actually sharing                                 data streams and and that this can be                                 costly there is also add option                                 challenges this is kind of a more                                 organizational problem than software                                 architectural problem it is a big part                                 of paradigm shift especially this bit                                 moving from commands to events and we                                 have three offices in two time zones and                                 there are eight hour difference there's                                 a night hour difference and the team                                 which develops this worked on it mostly                                 is in London so knowledge dissemination                                 in an organization of I think two                                 hundred engineers takes time at the                                 moment it means that I quite often am on                                 a call late at night trying to help                                 people use like start using this and                                 long term I'm hoping like as people use                                 it more there are more examples which it                                 won't be required but this is a cost                                 furthermore reaction of experts on this                                 either I mean we were probably working                                 closest to it we know most about it but                                 we're still learning so that's also                                 something we have to accept but good                                 news is but even if it's in perfect it                                 actually had been big impact on network                                 it really helped it really the coupled a                                 lot of teams allowed them to build                                 things faster and in a more resilient                                 way dealing with performance reliability                                 concerns much later than they usually                                 would have to because they work in                                 isolation of other components one                                 favorite we discovered and we kind of                                 didn't know explicitly in before I mean                                 it's no big news but it was something                                 which came out of this work it was                                 hidden in our                                 system before that we we have workflows                                 so basically and what I've highlighted                                 one of the work folks would we get which                                 which is quite explicit in our pipeline                                 is this delivery to inbox group and                                 aggregations is actually it's it has to                                 be coordinated to an extent and the                                 coordinator is that the delivery service                                 that the service which listen to some                                 event and translates into events which                                 then those systems listen to to an                                 extent so they use the event log it is                                 an ok usage but actually we have to do a                                 lot of plumbing as in we have to                                 actually make sure we have to maintain a                                 state machine we have to make sure that                                 things transition correctly this is                                 long-term we don't want to do that                                 manually we we want this to be solved                                 for us we want to have a higher level of                                 abstraction so more or less like this an                                 event but the message good creator comes                                 in the delivery system picks it up and                                 it distributes the task to the three                                 different deliveries and once it's                                 finished it's like a fort for drawing                                 type of job once it's finished it                                 publishes back the state change okay                                 this message has been delivered you can                                 maybe notify the mobile clients because                                 the view is already persisted so so if                                 you look at it what's workflows really                                 are from our point of view this is like                                 a transformation logic which lives                                 outside of the view service boundaries                                 it's quite often more complex it might                                 require retries that you want to maybe                                 scale it out and because it's especially                                 like a good example where you want to                                 scale it out is we have something called                                 an announcement the group can have up to                                                                                                announcement you want to deliver that                                 announcement to everybody that's a big                                 fan out if you're doing materialization                                 right so that you would like to like you                                 want to chunk it up make it do some of                                 this work in parallel and retry the jobs                                 but failed so this is effectively stream                                 processing see QRS kind of conceptually                                 and yes we can express them but as I                                 said before we have to do too much                                 manual work about setting up the                                 coordination where's we would like to                                 just model to work flow because that's                                 what that's the domain model is a                                 workflow it's not whether we publish to                                 this and read from that so we basically                                 are looking for a higher level of                                 abstraction and I will come back to this                                 later in the talk but this is the kind                                 of thing we've discovered and this is                                 like an open problem for us and so                                 what's the future because this is not                                 finished work so we want to move the                                 fully managed solution so as I've                                 mentioned earlier we are running running                                 Kafka and we actually run running it in                                 our own data center which basically                                 means a lot of headaches dealing with                                 outages like house going down for                                 physical reasons the actual instance                                 having problems because of something and                                 if we want to scale we have to do it                                 effectively manually so that's not great                                 that costs us operational resources and                                 we would like to provide our X bindings                                 because it's like event log is                                 effectively an event stream and RX is so                                 well suited so how many people use                                 directs just too ok how many people are                                 familiar with it ok so it's it's                                 basically reactive stream processing so                                 I think like looking at talks about                                 flank I think that expose a similar API                                 basically have stream of events you can                                 map you can filter you can aggregate etc                                 it comes from i means I don't know where                                 it was originally invented but it's been                                 popularized by Netflix recently and we                                 want to remove the centralization HTTP                                 proxy and that are ex-library would be                                 very useful for that and we want to find                                 a solution for the workflows so that we                                 have ongoing so coming back to this                                 managed solution we have an ongoing                                 migration to event hubs well we are a                                 subsidiary of microsoft's so it's kind                                 of natural to go to usher but event hubs                                 are basically an event log offering like                                 Kafka recognizes but it's fully man                                 in this house integer so that means but                                 for us if there if if a host which is                                 responsible for some partitions goes                                 down that happens behind the scenes we                                 don't know about it even and we don't                                 have to deal with provisioning in any                                 way we just simply move a slider we have                                 more transaction units so that's big                                 operational benefit for us it's mqp                                 point one point oh well use that                                 protocol so that means interoperable it                                 is not tied to any particular language                                 and its successful use internally and                                 externally actually we use it or we have                                 already migrated our Kafka metrics Kafka                                 to this to event hubs the reason is a                                 different concern for us to move this                                 part of the system to vent hubs is                                 because requirements are very different                                 metrics can lose data and obviously we                                 don't want it but it's acceptable and                                 it's obviously throughput oriented                                 whereas we are much more latency                                 oriented and like we want to minimize                                 latency because it drives user                                 experience and we can also stata we want                                 to publish synchronously and we're also                                 working as part of this work we are                                 building the RX java sdk we are using we                                 are building it on top of the utterer                                 sdk which is provided by a service                                 fabric team des des kay is powered by                                 present ray which is I think the only                                 implementation of of MVP one point                                      the moment but it provides also some                                 sort of of the higher-level concerns for                                 us it deals with higher level concerns                                 which we don't want to deal with                                 basically it provides us of the tracking                                 so it allows us to keep track where in                                 the event stream we are in case of a                                 restart failure in this kind of scenario                                 plus I assume everybody is familiar with                                 Kafka but just briefly there's a Kafka                                 as a concept of a topic and the topic is                                 Charlotte across multiple partitions and                                 that allows to scale processing for                                 fruit put but what that means in our                                 kind of scenario we want to have one                                 consumer / shard because we want to                                 process events sequentially one after                                 another so the problem we are facing is                                 if we are scaling our consumers out                                 we while we try one of them can die at                                 some point and we want it we want to                                 somebody else resume but we want to have                                 only one and we want to have them evenly                                 spread across the VMS so that's an                                 interesting problem but it's not our                                 business domain so we don't want to deal                                 with it so that's our that's why we are                                 using the sdk for measure because there                                 are for instance JMS bindings if                                 somebody is not so much interested in                                 these in these issues and and we are                                 effectively raising the level of                                 abstraction we hide the whole amqp                                 tracking file / kind of business and                                 we're providing and observable here we                                 go there's your stream of events map it                                 transform it do whatever you want but                                 this is ongoing work and going forward                                 yes I coming back to the workflows this                                 is something which is more in the future                                 we are looking to use our service fabric                                 reliable actors this is a high level                                 pass offering for murderer it's quite                                 widely used within a juror and it powers                                 I think event hubs and all the                                 management sites for instance for                                 forever and it's based on a project                                 Orleans this is a research project from                                 which I think has an open source                                 implementation now it's based it was                                 came out of microsoft research and it                                 was actually successful used for halo to                                 keep track of user stats they use actors                                 to represent users and they manage all                                 their kind of loading unloading from                                 memory when the user comes online and it                                 allowed them to build a very responsive                                 and highly scalable experience for halo                                 so yeah to summarize yeah if by the way                                 just to finish up this is publicly                                 available and I think it's available for                                 dotnet but they are working as we speak                                 on I've on the java java linux mmm set                                 up                                 and you can actually run it locally as                                 well if you want and it's pretty easy to                                 use so just to summarize we successfully                                 used event sourcing to solve our SLA and                                 velocity problems which we inflicted                                 ourselves using building a massive                                 monolith and then distributing it and it                                 actually helped us address both                                 architectural and organizational aspects                                 of the problem which was nice and what                                 was important for us and actually                                 getting this project through was that we                                 focus on the internet if approach which                                 allowed us to reduce risk and deliver                                 value early and this is still ongoing                                 work so yeah it's not finished and                                 hopefully if we'll continue so yeah                                 thank you are there any questions thank                                 you for your talk we just have two                                 minutes the question need to be really                                 short sorry because we have a closing                                 session how do we okay at six well                                 actually I have two questions um the                                 first one is how do you deal with a                                 long-term persistence of the events do                                 you store them for longer than well                                 maybe a couple of days or how do you                                 deal with that and the second question                                 is how do you previous failure in in the                                 different consumers what happens if some                                 if there is some back in the consumer                                 the typical approach and events sourcing                                 is to just recalculate the whole lock                                 how are you dealing with that so so we                                 wanted to have this kind of ideal                                 scenario and this is the one Kafka or                                 what comes next is kind of the whole log                                 unfortunately we cannot do that because                                 we have compliance concerns and we have                                 to enable easy deletion of PII data and                                 that would be very difficult to do in                                 Kafka and basically our customers when                                 they stopped using Yammer or of a                                       rank they have a guarantee that within                                 some number of days their data just                                 disappears so for that we actually use                                 the that's why we mentioned that there's                                 this data owner who                                 database and then so we use Kafka or                                 event log a bit like a more more like a                                 transport layer the moment so if we need                                 to we could put like if we move to                                 immutable version data we could use the                                 primary data source which is the data is                                 written in the service which receives                                 the request before it publishes to the                                 event log we could use it to regenerate                                 the events and get consumers to reply                                 and the African was yeah it was like                                 about restoring a consumer we actually                                 recently had a scenario we had to                                 restart it from backup and replied the                                 difference do we have more questions can                                 we please take it offline because we                                 have a closing session on castle house                                 okay thank you ladies and gentlemen for                                 your presence thank you cube okay                                 you
YouTube URL: https://www.youtube.com/watch?v=SFD8AHXmDyQ


