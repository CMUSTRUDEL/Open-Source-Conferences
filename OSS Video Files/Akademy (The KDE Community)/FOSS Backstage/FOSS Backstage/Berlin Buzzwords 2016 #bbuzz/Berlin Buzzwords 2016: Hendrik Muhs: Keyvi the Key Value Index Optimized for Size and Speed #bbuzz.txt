Title: Berlin Buzzwords 2016: Hendrik Muhs: Keyvi the Key Value Index Optimized for Size and Speed #bbuzz
Publication date: 2016-06-11
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Yet another key-value store? No, it's an index not a store and it is based on 'Finite State technology', but what does that mean?

Keyvi - the short form for "Key value index" - defines a special subtype of the popular key value store (KVS) technologies. As you can imagine from the name, keyvi is an immutable key value store, therefore an index not a store. Keyvi's strengths: high compression ratio and extreme scalability.

Keyvi powers Cliqz Websearch engine, replacing former engines based on Redis and Elastic Search. Serving terrabytes of data at scale and low-latency, keyvi is already proven technology while still being a young OSS project.

But keyvi is also different to well-established NoSQL engines, it is not an efficient implementation of well-known, common used data structures like hash tables and B-Trees. It brings finite state not only to the same level, but efficiently allows approximate, completion and graph matching to boldy go where NoSQL hasn't gone before.

Read more:
https://2016.berlinbuzzwords.de/session/keyvi-key-value-index-optimized-size-and-speed

About Hendrik Muhs:
https://2016.berlinbuzzwords.de/users/hendrik-muhs

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              so hi I'm the new one my name is TV I'm                               a key value index I'm based on finite                               state if you don't know what finite                               state means doesn't matter i think i                               will show it during the doing the talk                               i'm an open source project not even a                               year old so first who's using TV and i'm                               working for clicks and probably also you                               probably don't really know us we are                                building building a browser with anti                                tracking technology as well as                                integrated search so auntie V is part of                                the part of the search engine and yeah I                                mean please install us okay search                                engine wise let's look into let's talk                                look into into the numbers we have like                                                                                                       count it took a long time                                           data points key value pairs our index                                sizes around two and half terabytes that                                number has to be a little bit put into                                context and you will later see why we                                have like                                                        latency and as you might have seen in                                the browser what we do is we do search                                as you type so you are not putting in                                the query press and I get to search                                roulette but we searched while you are                                typing right now we get something like                                six thousand requests per minute we are                                able to do to do more so yeah and                                everything works actually quite fine                                with                                                                   we build it and why didn't we show                                something else so that means that we                                have two little bit look into into the                                history and we started actually quite                                the normal approach if you're building a                                search engine okay                                at stake elasticsearch actually this                                didn't really work quite well far for                                our use case this is more to the fact                                that we are not doing a classical                                full-text search but rather that we do                                do it a little different and so the                                reason for like abandon elasticsearch                                was because it didn't fit our model so                                the next actually our model fit more to                                something like a key value store and we                                switch to read us and we we're super                                maze about it it's great it's simple its                                space efficient and what we also love                                this is if you know ready see                                server-side scripting stuff so you you                                can run lure scripts on server side so                                you're already reducing your search                                result in the on your node in the                                cluster before sending it back saves a                                lot of time we know that networking is                                is one of the biggest bottlenecks still                                Redis was also not not best with more                                users we run actually into capacity                                problems the first capacity problem we                                had was space so the size and when I                                showed you the                                                          of the first slides actually when we                                when we decommissioned Redis our index                                size was five terabytes and with Kiwi                                reduced to two terabytes if you a little                                bit now like we run on AWS if you were a                                little bit now the prices there you can                                calculate yourself how much money that                                that means still other so one capacity                                problem was actually to get enough                                machine machines the other thing is if                                you are getting a large machine because                                everything I mean this is my might not                                have been clear yet if we do this sixty                                MLS second search we actually have to                                serve everything from memory all right                                so if you're getting a large machine and                                Amazon you're also getting a lot a lot                                of CPUs doesn't really fit with Redis                                because                                it's a single-threaded and I think like                                ninety percent of of reddit users don't                                hit this problem but we hit it hard the                                reasons why it signified is also because                                everything is on the heap of the process                                which makes it also quite risky because                                if this process dies you lost it and                                actually takes quite some time to reload                                this stuff so that that's why Kiwi came                                in and first of all it was a massive                                size reduction second it's it's                                multi-threaded so we can do it with many                                processes and the reason for this multi                                threading is because using shared memory                                so memory mapping basically and last but                                 not least due to this memory mapping                                 it's also more reliable because well                                 when it process dies it dies you have                                 other processes no problem if you reload                                 things it's cached in the u.s. it's                                 quickly there so and to give you a                                 little bit more reasoning here is like a                                 very simple size comparison between                                 Radisson TV yeah I mean the first thing                                 you see on the slide okay give you a                                 smaller great if you look a little bit                                 deeper into the numbers you actually see                                 it's not linear all right it's                                 interesting it's like                                                    million pairs is                                                      million                                                              than                                                                     for TV it's kind of interesting this is                                 not linear it's sup linear and when I                                 explain this finite state thing you                                 probably will get why still this this                                 wasn't this is not the the sixty percent                                 space savings that I claimed in the                                 beginning so actually space savings is                                 based on your data and I print here a                                 little bit the compression ratios that                                 you can can get with TV I mean if you                                 know Redis registers a hash table it                                 doesn't matter what you put in                                 from like a space perspective for Q it                                 actually makes a big difference so                                 something like a term dictionary okay                                 then we have like content which was the                                 previous kind of benchmark content is                                 something like okay you have the the                                 text of of the page and so on if you                                 just have filtering that is like like a                                 list of domains which you don't want to                                 but you want to blackness because they                                 are adult content or there you know that                                 they lead to four force or something                                 like that and the most compression you                                 get with scores the scores I mean                                 something like statistical models so                                 basically numbers something that you                                 have in your in your model something                                 some ranking features basically and okay                                 we saw the space now let's look at the                                 at a look at benchmarks I try to make it                                 visible I mean it's always hot actually                                 it's always hard to do benchmarks and                                 you'd always do it wrong and the other                                 thing is with doing this kind of                                 benchmarks is do you measure the store                                 or do you measure your network actually                                 most of the time you virtual network and                                 not the not the store still you can see                                 some stuff here we see that if i try i                                 say try try to make it kind of a fair                                 comparison i put a kiwi into a single                                 threaded mode as Redis and then just                                 compare the one that that's just the                                 blue and the and the yellow one we see                                 it's kind of on pair it is a little bit                                 worse maybe you have to tell a little                                 bit on what a chunk size means if you                                 know Redis you have something like a                                 call the reddest pipeline so actually                                 you are not doing one look up at the                                 time that would be bad because you you                                 would just spend time for your for your                                 networking you wouldn't you would like                                 lose all your audio performance in RPC                                 so what you do is you collect you                                 collect what you want to                                 no send it over the network and then get                                                                                                       step and that's what these chunk size                                 means so there's even a little problem                                 with Kiwi it seems on this                                                                                                                      multi threaded mode it clearly                                 outperforms lettuce and also the the                                 other thing is what if we are not doing                                 IPC which we don't have to because of                                 Chad memory I will explain a little bit                                 more into a gone bit into detail later                                 for this no I pc case but this is just                                 to give you a little bit on an idea what                                 because when you do this kind of                                 benchmarks you have to see what is the                                 cost of the of the extra look up and                                 what is aside from that I pc RPC stuff                                 like that this benchmark was also only                                 on a local machine because what I'm not                                 interesting here is is on the network of                                 course on a network it looks even even                                 completely different so let's a little                                 bit look into how how this thing works                                 and this is a quite super complicated                                 picture but this is the way it is right                                 you have a you have a couple of workers                                 on one side and you have a couple a                                 cluster full of machines on the other                                 side what I haven't told you actually we                                 would not put one Redis on one machine                                 but we would use several registers I                                 mean that's how you scale out Redis you                                 you just start several ones and then you                                 have instead of single threaded you have                                 then I don't off five frets because                                 you've started five ready service so                                 this is a bit complicated let's let's                                 assume a little bit into this just look                                 at one machine so you have a couple of                                 ready service okay still the data is                                 everyone on the heap of this process                                 data access is local so it means I                                 cannot from one ready server I cannot                                 access to the other this is for some                                 applications actually in our search case                                 this                                 is a problem because sometimes you want                                 to have access or some some ranking data                                 you always need right and you can't do                                 that so what you have to do you have to                                 do deep copies you have to put it on                                 Eddie everywhere the server then your                                 size will go up again if one of these                                 reddit servers dies it has to be                                 reloaded and our in our use case we had                                 times like                                                              bad I mean you don't want to have                                    minutes down time so how would it look                                 in key be well as I said before it's                                 shared memory so instead of dividing it                                 into five pieces if I would have five                                 ready service before I would now have                                 just one piece on one machine with a                                 with shared memory I can start as many                                 processes as I want if it crashes no                                 problem you have enough workers you just                                 are new one I mean we use we actually                                 use multiple processes not multiple                                 threads so that's a little bit more                                 robust and the other benefit of this                                 whole thing which I haven't touched upon                                 yet is it readies load something you                                 have to deserialize it so it takes these                                                                                                          put into memory and that's it so there's                                 no diff civilization time so instead of                                 these                                                                 minutes down time because of this shared                                 memory actually could argue like why do                                 I need a server she texture at all                                 actually on the local machine i mean i                                 can just load it right you can do that                                 and because we traditionally started                                 from replacing radio Swift TV we                                 actually haven't really fought about                                 this use case but we later realize that                                 actually read is completely an in-memory                                 store but keavy actually isn't because                                 it's shared memory it's you put it into                                 virtual memory of the operating system                                 so you can have even a bigger index than                                 the size of your RAM on the machine so                                 this is an example we have like an index                                 size of two tablets                                 putting on one machine which is like                                     gigs of ram so it's almost like                                        have to like                                                             the then you can store on on RAM and                                 what the OS is doing is like paging the                                 whole thing right this is compared to to                                 a setup we have right now it's like okay                                                                                                          the Charlotte data and so and the                                 alternative is the putting everything on                                 on SST so basically you have on and the                                 two upper scenarios you have the network                                 I owe on the two lower scenarios you                                 have the disk i/o and we are comparing                                 here is a little bit like this guy over                                 a network I oh and this whole SSD case                                 really on rotation a list forget it but                                 with SSDs is actually quite an                                 interesting case because it completely                                 changes the picture so on a you see like                                 okay on a code when it quite takes                                 sometimes the cold run means you have                                 nothing in your realm you just freshly                                 load it but once something is loaded and                                 actually the in the test we are loading                                 it's also doing some I oh it's not                                 completely without paging we see that it                                 actually works quite well on SST this is                                 something we are working on it's not                                 quite clear ok so I think now you should                                 know the why and now I want to tell you                                 a little bit about the how and now i                                 also like look and look into what what                                 again was is this what finite-state                                 something so this is a actually it's not                                 a fine settings users if you correctly                                 it's finite state automaton nila i just                                 put like four words into into it for you                                 berlin buzzwords past keywords and                                 some of you know that for some of you it                                 just looks a bit similar to something                                 that you know and probably you know this                                 one which is a try a try data structure                                 so what's the difference is it's just                                 that okay this one has a little bit more                                 a little less circles right let's just                                 like kind of obvious as little less                                 circles what we do in a try we we                                 compress prefixes in the in the                                 statements user we also compress                                 suffixes you see that keywords and                                 buzzwords actually share the same suffix                                 it's a little bit hard to always explain                                 this on such a small example but as I                                 showed you before with the compression                                 ratios it quite met us and it's also it                                 it's different on what kind of data you                                 put pudding okay how do we built this                                 thing we have big data right we have                                 like terabytes of data so obviously this                                 whole thing doesn't fit into memory I                                 mean that should be immediately clear                                 what does it mean for us well if we want                                 to construct such a state we have to                                 actually know all the outgoing                                 transitions simple solution we just sort                                 upfront sorting we all learned it in                                 your University it's some external sort                                 it's a solved problem what we in                                 addition have to do is we have to find                                 this this ways to optimize this fing the                                 so-called minimization and what you can                                 do here is now just user use a hash                                 table this has a you're getting back to                                 this problem of everything in memory so                                 your ash table should be quite efficient                                 the other thing is and I'm not making                                 academic career with that statement is                                 we make the hash table bounded that                                 means that the finite state machine will                                 not be minimal this is horrible for                                 academics but in practice this is like                                 saves you and what we what QB also                                 applies is                                 Liu algorithm so at least recently used                                 we just pushed the states in the hash                                 table up which have been minimized and                                 we throw away the ones which don't                                 minimize and in the end view somehow F                                 to stream input and output so i'm not                                 sure if there are some leucine folks                                 here but you know this kind of thing                                 right this leucine has this right they                                 have a finite state since uses deep in                                 lucene somewhere i makin a little bit                                 compare TV and andalusia implementation                                 and okay we have to Samos solve the deep                                 resistance problem so what we need is                                 some kind of clever bit logic and the                                 leucine is also doing it quite clever                                 basically what we've seen does it puts                                 it persists the node as small as                                 possible as some kind of of bit vector                                 the difference to key B is it uses the                                 so-called sparse array packing and I                                 will explain you what what this parcel a                                 pecking means so you have like a say                                 this is like your state and we put that                                 into some some representation into a                                 sparse array of presentations part of a                                 just means okay you have a lot of holes                                 in your in your array so a lot of zeros                                 to make it efficient we use for the                                 labels we use one bite now you can say                                 okay single white encoding we are in the                                 year suit                                                               utf-                                                                   okay i have three states say if i have a                                 utf-                                                                bites I just have free states here which                                 I somehow wrapped into one state so it                                 looks like the same from the outside                                 then we need something like okay every                                 structure needs some kind of pointers                                 right so we have also a vector of                                 pointers here to connect the different                                 states                                 so still be like okay we can put this                                 one after another but that wouldn't work                                 right that would not save the space so                                 how do we combine these and why do we                                 need the labels at all so maybe I hope                                 this gets cleared out so given of these                                 two of these paths race we try to                                 combine them and if we would like in                                 this case we want to try to interleave                                 them that would actually mean this                                 doesn't work it's somehow clashes all                                 day okay next try ah clashes on the                                 beginning next try okay this looks now                                 almost again yeah I think we made it so                                 we finally found a way to put these two                                 things together and it looks in the end                                 it looks like that so we combined both                                 of these sparse representations into one                                 I'm not telling you the whole story                                 that's obviously a little bit more a lot                                 of lot of tiny tricks into to make this                                 super fast and quick we use something                                 like intrinsic there's I told you this                                 this to bite thing there's obviously                                 some kind of variable length encoding                                 behind the scenes we are not using                                 absolute offsets but relatives offsets                                 are saying something like okay gay go                                 five steps left or five steps right we                                 have to get the when we built the                                 structure we have to keep the memory                                 requirement low so we use something like                                 sliding windows and etc etc etc okay                                 let's now let's look at two into the                                 lookup itself and you might already                                 guess it it's quite easy you just start                                 from an offset you go a little bit I you                                 want to look up something like the e                                 there you find a pointer to the next one                                 and then you just repeat the whole thing                                 and out something comes from this pretty                                 interesting in this data structure                                 actually it doesn't matter at all how                                 many data is in there because it only                                 made us the length of your key right as                                 long as you can build this thing the                                 lookup complexity of this thing is n                                 which is the length of your key ok so if                                 I just showed you how to look up and I                                 showed you a little bit a state                                 automaton what we also key value means                                 that we also want to have values and I                                 can just briefly mention that in how it                                 works in key vs is because that's not so                                 much the interesting part is of course                                 we need some kind of buffer where we                                 have the values in and we have some some                                 kind of pointer which points points of                                 that and this is pretty much the same                                 independent of whether us TV or radio so                                 I mean in the end this part is always                                 the same we have types like something                                 like he only which would mean this                                 filter type of things we have something                                 like in so if you just have neat very                                 simple things strings which is actually                                 superseded by Jason Jason means you can                                 like store anything in there there's                                 something like a special subtype which                                 is called in with innervates that's                                 that's for a special use case where you                                 want to while you are looking up go a                                 certain path sounds complicated that's                                 exactly the completion case you're                                 starting with fa and the most you want                                 to want to have the most relevant                                 completion which we probably facebook                                 and you don't want to like traverse the                                 whole thing but you want to have it                                 pretty inefficient then for that you                                 need something like in a weights of                                 course we are not storing Jason as is                                 but using some clever compression with                                 message peg which is a binary                                 representation we can put snobby set                                 live forever on top so I said key value                                 index and not Q value store so                                 what about updates and what about real                                 time that's how I see two questions but                                 I have to challenge that a bit what is                                 really your use case do you really need                                 real time or do you just need to have it                                 fast enough I think most of people just                                 need it fast enough right and the same                                 for the updates okay if you have                                 constant rights constantly right to it                                 TV is not for you use Redis use                                 something else if you are have mostly                                 weeds and a little bit of rights                                 consider it in the end it's the same                                 kind of limitation or thing that that                                 you have in lucene and you see leucine                                 you have these segments and they they                                 are immutable and then the segment's get                                 merged we don't have that yet what feet                                 who is the pragmatic solution of segment                                 matching it's just having one huge                                 master segment and on that we apply just                                 Delta updates and they are not                                 cumulative we are just always replacing                                 them but on the size size wise these                                 data updates are much much smaller and                                 we can like deploy them in in a short                                 amount of time and depending on the use                                 case some we want to update our lives on                                 daily some some stuff just on the amount                                 so what I haven't told you about this is                                 what else can you do with TV because                                 it's it's finite state it's not a hash                                 table you have this little nice graph                                 structure and this finite state some of                                 you might know to somehow sounds like                                 NLP and actually this is where it used                                 to be used so what you can do is if you                                 want you can still build an entity                                 recognizer we are using it also in in                                 spark the other part of things is like                                 all these approximate or completion type                                 of matching things there's also things                                 like you can use it for Gio                                 applications because in the end the geo                                 look up is just an approximate match you                                 are here you want to know where the next                                 drug store is so it's an approximate                                 match in the end all right this it's                                 just a small project right now but still                                 for more infos and material just go to                                 the to the UL there which is right now                                 just to redirect or to get a page but                                 what you find there is like all these                                 more information about that also the                                 papers and so on which are basically                                 like similar it's based on the same                                 stuff that leucine is based on yeah and                                 look around and I hope maybe you have a                                 use for it thank you so I hope that they                                 are some questions thank you Oh many                                 questions I I have a question about one                                 of the first slides you show and you                                 have this FST with suffix compaction yet                                 okay as the Edit teapot FST finite-state                                 with this one this one yes so you have                                 here like buzzwords and keyboards yeah                                 and they end up in the same state how so                                 you can say that you have those two                                 different words in your dictionary okay                                 but how do you associate different                                 values which that wouldn't work in this                                 case okay so this is exactly the point                                 that if well you basically means that                                 your end state is different and then you                                 would not be able to compress it I mean                                 in this example is simplified it with                                 just showing a key only kind of                                 structure in real applications we of                                 course have values and then the the                                 picture changes but still if you have                                 something like ranking data some model                                 data it's the slide that I showed before                                 it                                 still compressors and it's still like                                 what helps TV is giving it a lot lot lot                                 of data because the more data you                                 increase the probability of some kind of                                 duplication in the end you can say this                                 is somehow and deduplication engine                                 Nevermore yes you mentioned the scene                                 has an FST in it that's yeah and but how                                 does it compare to this one and you                                 mentioned you do la interview intervene                                 for compression they have different                                 cooperation machine but performance wise                                 memory wise these kind of things ok I                                 prepared for this question haha that's                                 why I asked yeah I mean the thing the                                 the reason why I didn't show it it's                                 it's again my kind of questioning this                                 benchmarking because it's it's always                                 hard to do benchmarks right and I I                                 follow the the implementation in low                                 scene for quite some time I know it but                                 I'm not an expert on it so what i did                                 was i I just quickly last week                                 implemented some tools to make these                                 kind of benchmarks and the size wise                                 it's almost equal to leucine but I was                                 not able to get a large put in large                                 data I just it for me just crashes the                                 the memory consumption doing the                                 construction is is too high it doesn't                                 work because it basically uses when I                                 said when I showed this hash table thing                                 it uses something unbounded it doesn't                                 have this bounded a hash table for                                 example and that just blows up for look                                 up I did some comparison here because                                 what you have in lucene is you have                                 every stage is is it's not using this                                 positive reefing but it puts all the                                 outgoing transitions in this state so                                 what you have to do is doing a lookup                                 you always do a linear scan in every                                 state and have to find the right spot to                                 continue while you and key we can do the                                 direct you can go                                 directly jump directly so I have a                                 benchmark here but honestly I'm not sure                                 is that due to Java is it you too Lucy                                 due to c plus plus i don't know i don't                                 want to start a language whoa so it is                                 something like eight times faster in TV                                 but i mean if we make a proper                                 comparison we should compare algorithms                                 and not implementations and maybe it's                                 it's some something that leucine folks                                 got code log into and considering taking                                 some of the features out of TV and                                 putting it into the leucine FST                                 implementation Oh questions no thank you
YouTube URL: https://www.youtube.com/watch?v=GBjisdmHe4g


