Title: Berlin Buzzwords 2016: Ramkumar Aiyengar - Building a real-time news search engine #bbuzz
Publication date: 2016-06-13
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	What challenges could a search engine have? Large number of documents? Large query load? Very complex queries? A challenging privileging model? Expected low query latency? High volume of document updates? Updates to documents reflected in milliseconds? Realtime alerting for any search? Absolutely no downtime any time of the day, week or year? What if a search engine had all these challenges? Meet the backend which drives News Search at Bloomberg LP. 

In this talk, Ramkumar Aiyengar talks about how he and his colleagues successfully pushed Solr over the last three years to unchartered territories, to deliver a real-time search engine critical to the workflow of hundreds of thousands of customers worldwide.

Read more:
https://2016.berlinbuzzwords.de/session/building-real-time-news-search-engine

About Ramkumar Aiyengar:
https://2016.berlinbuzzwords.de/users/ramkumar-aiyengar

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              thank you welcome to the building the                               new search engine talk in purple that's                               a feature you have to trust me on that                               so briefly about a Bloomberg and a bit                               about me it almost looks like artsy now                               with the purple on I didn't quite                               intended effect Bloomberg is a                               technology company our focus and                               strength is data you probably know                                Bloomberg through the channel you see on                                TV but the biggest product we do have is                                what is called the terminal which is a                                one-stop shop for people in the                                financial industry as well as garments                                and economists and other people and                                other professional disciplines to get                                data visualize data do calculations on                                data and pretty much carry out their                                workflow based on the screens that the                                terminal provides we also offer other                                vertical portals on on the web for                                various different disciplines like the                                if you are interested in the garments or                                if you're interested if you are a lawyer                                interested litigation and those from our                                customer base a bit about me I started                                Bloomberg nine years back I'm now the                                team lead for the new search team which                                is responsible for the search alerting                                and ingest infrastructure for news there                                are other teams within Bloomberg which                                work on such as well we even have like a                                generating platform which allows people                                to build applications based on search                                Steve my colleague is responsible for                                that but this this job will mostly focus                                on the news side and how we went about                                building the new search platform I                                started with solar leucine pretty much                                sort of like with hello world three                                years back we found during the course of                                a project that we needed to deal with                                solar and leucine and its internals a                                lot we kept coding making changes I'm                                now committed with the project with                                apache so leucine we actually have two                                more computers in the company now after                                me and this talk is going to be a lot                                about the changes we have done to solar                                as well and about what kind of                                challenges we faced and so on                                so even before i go into what we did                                this is pretty much a typical such this                                ecosystem if i would call that what                                happens when you search you go to any                                any any search engine you start typing                                the system starts suggesting queries as                                soon as a user is typing you end up                                typing some query either based on                                suggestion or you type it out yourself                                then the system tries to understand the                                query and tries to figure out what you                                exactly meant using NLP entity                                recognition disambiguation spell                                checking etc at the end of it you get a                                more structured query which looks for                                keywords and metadata of documents you                                search for that you get results often                                you get results which are in millions                                then your biggest problem then is to                                sort the results as the usage dictates                                sometimes the search could be sought                                short order could be something very                                simple like show me in reverse                                chronological order but the most common                                ones and it tends to be by search                                relevance as in how relevant is this                                document to the user you also have some                                cases where you need more                                diversification or you want sort of like                                some results from what of others in in                                essence you get an ordering of the                                results based on the results you have                                retrieved in many cases including ours                                and this this forms a more exciting part                                of what we do there is a real-time                                element to it very unique but you also                                need to display alerts as soon as a new                                search result comes up and then on top                                of that you need to expose facets and be                                able to tell people what else to search                                on and finally you end up sometimes                                recommending searches and recommending                                stories as well for people to do this in                                this talk in particular I'm going to                                focus on just two lines of it as many of                                you probably already know each one of                                this stands a talk by itself you can you                                can't talk for an hour almost on how                                 such infrastructure is built what the                                 entire sort of stack behind it and so on                                 there is a lot to be talked up but in                                 interest interest of time I'll be                                 focusing mostly on the searching and                                 sorting more to do with what sola                                 leucine does                                 as with everything the challenge always                                 is not just an implementation but also                                 the scale of it and Bloomberg has its                                 own share of challenges we have around                                                                                                        them use news we get around                                            searches a day not the greatest amount                                 that you have ever seen quoted but the                                 main challenge there is that the search                                 needs to be real time as well as need to                                 respond fast so our average response                                 time is around                                                       mean is actually less than hundred which                                 is a different entirely interesting                                 story as well which I will skip at this                                 point we get over                                                       sometimes at peak rate it tends to be                                 very spiky traffic as new softness and                                 the real challenge here is that these                                 results need to be available for search                                 in a                                                                     with search this is often a big dilemma                                 you face with how how fast can your                                 search results be retrieved and how how                                 real time is your search really overall                                 we have an index of around                                             stories obviously with news like the                                 older the story goes sometimes it's not                                 just important and we sometimes discuss                                 stories and also as I mentioned this is                                 a real-time system so whatever we do to                                 get initial set of results we also need                                 to alert on top of that especially we                                 have a very strong case for                                 chronological search results we do                                 relevant sorted results as well both are                                 equally important use cases but                                 especially for the chronological search                                 results day traders for example in the                                 financial industry expect results to                                 show up on their screen as soon as it                                 arrives and this holds good for any any                                 search what any search that they come up                                 with it could be arbitrarily complex we                                 are we have around                                                      seif searches and we endeavor to provide                                 a lot Susan hundred millisecond so the                                 story coming in either either in front                                 of their screens or there are other                                 mechanisms available as well in                                 particular what's kind of kept us busy                                 in the last few years and it's still                                 ongoing is we used to have an existing                                 system which was based on a proprietary                                 system it was a it was past tense of                                 end-of-life it was inflexible it had no                                 scalable relevance                                 thing had a lot of other limitations                                 like you typically would associate with                                 a third-party software so around a few                                 years a few years back around three                                 years back we started looking at other                                 solutions especially open source                                 solutions and we did a bit of a survey                                 and we finally ended up with solar                                 leucine for a few reasons many of you                                 probably know this this region features                                 extensible it's actively maintained it's                                 free software which means that we can                                 contribute back to it we can modify the                                 source to our requirements and as a part                                 of this one of the challenges were                                 though was that we had to build in from                                 scratch alerting backend which we did                                 based on leucine in lugok I probably                                 won't have too much of a chance to cover                                 the alerting backend which as a certain                                 of beginning dis also talk of its own                                 but it's it's it's just as exciting at                                 this one the entire exercise was not                                 just a something we did to change the                                 back end but it was an architectural                                 revamp one of the driving goals of this                                 change was to make the entire system                                 scalable and this is especially                                 important in the kind of search that we                                 do news tends to be spiky our                                 requirements change quite dramatically                                 in quick succession and often you are                                 left with the place where you need to                                 scale quite heavily right I need to be                                 prepared for a case where tomorrow I                                 might be getting ten times the amount of                                 load or ten times the number of new                                 stories and I should start thinking                                 ahead in terms of what I should be doing                                 then so this architectural revamp also                                 tries to make this entire system                                 scalable and also maintain a bill as                                 well so that it's very easy to add                                 metadata reindex all the data and so on                                 so as I did it in four easy steps easy                                 being subjective make it work make it                                 fast surprising how many people sort of                                 like don't think think is important the                                 first we spent around a year on the                                 first and more than a year one and half                                 years on the second make it stable                                 that's important and then make it better                                 thank you very much have a nice day ok                                 let's go deeper so before I go any                                 further let's try to understand what                                 actually goes into the system this is                                 what tends to be typical of a search                                 engine you have a document and you have                                 a query in our case in particular we                                 have new stories research documents                                 tweets anything which kind of falls into                                 new sometimes doesn't fall so much                                 introduce things you are interested in                                 public stories mostly but it doesn't                                 have to be I will talk about that a bit                                 for every new story there's a story body                                 obviously there's a headline there's a                                 time of arrival there is source there                                 are tags associated the story I'm draw                                 this talk I'm going to probably skip an                                 entire pipeline of events which is                                 leading up to the search engine one of                                 them is a classifier but which is                                 particular part machine learned part                                 rules-based and that essentially tries                                 to influence the tags associated the                                 story and gives them sort of confidence                                 intervals and then we have queries                                 sometimes they can be a very simple                                 query sometimes it could be a simple                                 query which is put in the user which is                                 interpreted as a more structured complex                                 expression but equally and this this                                 tends to be not a very common use case                                 but is very important for the financial                                 industry is we give them full                                 flexibility over the search query                                 language takes the exposed to search                                 query language to them which admittedly                                 not a lot of people use it's it's still                                 a minority power user base which uses it                                 but it's equally important so in this                                 example for example you have multiple                                 fields you have keywords topics regions                                 sources you have boolean queries                                 proximity zoning operators especially                                 tends to be important sometimes in news                                 because news tends to follow that                                 pattern the most important thing gets                                 mentioned upfront and awful people                                 sometimes look for references in that                                 phrase searches wildcards searches range                                 queries you want time time-based ranges                                 search filters we have we have multiple                                 languages you sometimes want to filter                                 on the relevance of the tag associated                                 with the story that's actually the                                 default by the way                                 some of the interesting aspects of this                                 is there as I mentioned it's an                                 arbitrary complex boolean expression and                                 this applies to both search and alerting                                 have seen users actually sort of like                                 create                                                                  don't ask me why they do it they do it                                 sometimes they almost considered their                                 intellectual property they've built it                                 over yours the years of experience                                 sometimes it could be a list of metadata                                 which is just specified in shorthand                                 let's say I'm a portfolio manager I am                                 interested in a security portfolio which                                 is thousands of securities I just say                                 show me news on my portfolio and that                                 will translate effectively to an odd                                 expression of company a or company b or                                 company c thousand times as you can see                                 that becomes complex from search engine                                 point of view but it's quite easy for                                 the user to enter we have stories from                                 over                                                                     a media company and that's probably one                                 of our biggest sources but equally we                                 have lots of news coming in from major                                 newspapers across the world we have                                 tie-ups with various research providers                                 who provide us news we have social media                                 like from Twitter and the interesting                                 aspect of this is that all of these                                 sources can be turned on or off per user                                 and either as a matter of choice like an                                 old school guy I don't want tweets for                                 example or just because they may not be                                 privy permission for it some of this                                 research content especially sort of like                                 people put in a fair amount of effort to                                 produce a research content and they                                 obviously don't want to share with                                 everyone we thought them paying for so                                 we have AC else which can have few many                                 are all users for each of these sources                                 we have such as in stories in                                    languages one great thing about solar                                 lucene is that it often comes up with                                 very good analysis chains or ways to                                 sort of like tokenize these languages                                 but especially in the sort of like as we                                 went through to production ization every                                 use case is different and that's what                                 you typically realizing a search engine                                 the way we interpret Chinese is not                                 exactly the way Chinese solar interprets                                 Chinese and so on and then that happens                                 for everyone all these languages any                                 user can have a subset of the selected                                 at any point of time so you need to be                                 able to accommodate for multiple                                 languages how we do this we have a new                                 search cloud which has lots of Linux                                 machines hosting hundreds of shards                                 thousands of solar course there are                                 multiple tiers this especially helps in                                 case of news because news tends to focus                                 a lot on the recent stories so you have                                 a recent collection which which we try                                 to use first if that doesn't work out                                 then we use a fuller collection which is                                 likely slower cross data center                                 redundancy obviously for stability                                 reasons which is quite interesting rumor                                 solar point of view because doesn't as                                 yet natively support crowd datacenter                                 and also there are there at any given                                 point of time you could have multiple                                 generations of collections as I said one                                 of the important aspects of this                                 redesign is to allow for easy addition                                 of metadata and sometimes let's say you                                 make a major analysis change you have to                                 reindex all the data so you often end up                                 with multiple generations of the same                                 data coexisting and trying to sort of                                 phase one out of the other as I                                 mentioned previously stories are                                 available for search in                                                  so caching almost doesn't make sense in                                 the way sort of you typically expect it                                 from a solar or leucine level there is                                 obviously lots of caching that happens                                 to the OS level and we depend a lot on                                 it but there is almost very little                                 caching on top of it because kind of                                 pointless by the time you start using                                 the cash it's gone anyway we have custom                                 cumference for almost everything and I                                 think this is what you would expect from                                 a major installation in any case for                                 parsing for indexing for searching for                                 for privileged view suppose filtering                                 some of this I'll go a bit go a go bit                                 more in depth but almost everything is                                 customized to some extent here so that's                                 a story so in the order in which i                                 described first making it work a couple                                 of interesting examples over there and                                 the way I'm going to structure this                                 presentation is I'm just going to give                                 lots and lots of examples so feel free                                 to come back to me towards end of this                                 talk or when we have time for questions                                 more on what exactly are sort of the                                 more interesting details in this I'm                                 just going to go through sort of one                                 after their kind of challenges in in the                                 almost almost like a worse                                 retelling in some sort so the first                                 thing is to make it work right and a big                                 aspect of that is to power search                                 queries in particular we have an                                 in-house search syntax if you recall I                                 mentioned that people have the ability                                 to provide search queries in in a                                 full-fledged boolean expression syntax                                 we need to validate and privileged tags                                 based on databases we have outside solar                                 we need to present part of the search                                 query in the UI even with the person                                 specifies the you are in that native                                 format or the or the expressive format                                 you need to break it down and some                                 present the search query in in a more                                 sort of like you I friendly fashion if                                 you will and sometimes you need to                                 understand the query to do other things                                 on top of the search itself a very                                 interesting example is that we often                                 modify the base set of sources you're                                 getting news from or the set of sources                                 we consider the most important depending                                 on the query because obviously some                                 sources have better information about                                 some topics than others so you need to                                 often customize how you do it so one                                 thing we did to in order to accommodate                                 all of this is that we decided quite                                 early on that it's not going to help us                                 if we try to push all this complexity to                                 solar so we went for a there was this                                 very old ticket which was trying to                                 represent the solar query in an XML                                 format and I say XML you can be semi                                 structured not a big fan of XML myself                                 pretty would have any many in this blue                                 mood agree perhaps but the key part is                                 that is it's it's semi structured and                                 almost very little happens on the solar                                 side before it actually goes to the                                 lucille and so we construct the query                                 well in advance and solar just                                 reinterprets that pretty much and                                 constructs a query object in losing                                 terms so you get through from outside                                 solar to a query object which is getting                                 searched on with minimal translation                                 some translation still needs to be done                                 a very good example is when you specify                                 a keyword that needs to be tokenized and                                 broken down and that's important and                                 that only solar can do because it don't                                 understand the schema                                 but the idea is that you allow as much                                 flexibility as possible so that you can                                 control the carina tighter fashion and                                 it has served as well in many cases as I                                 shall describe in the next few slides                                 sometimes you had to do a lot of                                 optimizations which often means that we                                 create new query types at Lucy level and                                 it was it was going to be a pain if we                                 start exposing all of that in a in a                                 query parser what this allows us to do                                 is that I can just get a builder for the                                 class and then specify it with the                                 arguments for the query straightaway                                 sometimes we needed to originally at                                 least use a fork version of solar this                                 is a for called flax search allenwood                                 bodies around if you can find him used                                 to have a fork of solar consoler                                 intervals which actually helped us with                                 some of the functionality which was not                                 present at the solar originally started                                 it we actually work with him later on to                                 get that upstream with                                               longer the case but in some cases we                                 used a folk version of leucine to get                                 additional query capabilities like kind                                 of something like this right i mean you                                 have you have a phrase expression with                                 the near query nested near queries some                                 of this earlier versions of leucine were                                 not able to work with the next challenge                                 was obviously i mentioned that we had we                                 have a classification system which tries                                 to find out tags a very interesting idea                                 with this classification system is that                                 it has a built in relevant score                                 associated with it it gives you a                                 confidence of if i say the story is                                 about oil it's seventy percent i'm                                 seventy percent confidence about oil or                                 ninety-five percent confident about it's                                 a toy each jury has topics companies                                 regions people attack with it it has                                 each one of them has a relevance there                                 are multiple tags depressing pastori                                 millions overall and the tag relevance                                 needed to be considered for both scoring                                 and filtering if you are scoring search                                 results he wants if and if you ask for                                 are you you obviously want something you                                 have more confidence it's about oil to                                 float up to the top you sometimes use it                                 for filtering when you try to display                                 the Sultan chronological order as well I                                 want                                 in chronological order but I want to                                 restrict my results to only those which                                 have oil at a very high relevance I'm                                 pretty sure so I don't want my feed                                 cluttered with stories which may be or                                 may not be here before you so one very                                 interesting challenge was how do we                                 build this infrastructure in a scalable                                 way as well as allow for normalizing                                 relevance like for example if I have                                 keywords Obamacare or topic health right                                 one is a topic there is a keyword how do                                 you normalize this course one thing we                                 did was to repurpose keyword ranking for                                 these tags pretty much use or tf-idf or                                 in the future if you come up with a                                 different ranking use that instead for                                 tags as much as keywords and that allows                                 us to normalize and we can also modify                                 search is to be filtered based on ninjas                                 of these tf-idf scores so as far as the                                 system sees it it sees                                                   the topic oil and there's a seventy                                 percent confidence or somewhat like that                                 with a logical scale so that's as far as                                 the getting stuff to work I'm so long as                                 I mentioned earlier much of the the job                                 here is to optimize it when we initially                                 started off and we had the initial                                 prototype when you try to push the full                                 load through it if you up nothing came                                 up we did a few optimizations to the                                 point where they at least wouldn't blow                                 up and we started seeing mean times over                                                                                                                                                                                  interesting examples here is to do with                                 Nicolas searching as I described you                                 have like a huge list of companies                                 you're trying to search on in the knife                                 fashion you can do pretty much something                                 like a boolean of thousand ours and the                                 challenge here was that the default                                 setting was such that the company had                                 had a relevance filter set so it was not                                 just a term query on a company it was                                 actually a tuncurry wrapped around a                                 check of what the term frequency range                                 was and that with thousands of them so                                 we went through a series of steps to                                 essentially condense this more and more                                 and finally get it to a place where this                                 entire thing can be represented by one                                 query and we                                 as much of the complexity down to the                                 lowest level possible and that gives us                                 a few orders of magnitude in terms of                                 benefit just in terms of this is a very                                 good example in which I optimized a                                 particular leucine query for the use                                 case and got a very good benefit out of                                 it and another example for this is                                 essentially we have as I mentioned a big                                 user base which is also interested in                                 searching by time this is feature which                                 came on a quite a while back in lucene                                 about a sorting index segments by time                                 so that you can optimize searches by                                 time as well but there was support                                 missing on solar side so we went ahead                                 and implemented it and we factored a few                                 things just so a solar to be able to use                                 that properly so there's some changes                                 like this which are more at the query                                 level which try to optimize the                                 performance there are others which are                                 at a different level in terms of what                                 the hardware we have goes without saying                                 for the kind of scale that you want you                                 need lots of SSDs you can't depend on                                 spinny disk but there is a fair amount                                 of tuning you can do on top of what                                 lucene gives by default in terms of how                                 aggressive your much policy is and this                                 is probably one thing which is often                                 overlooked by a lot of people you can                                 never sort of underestimate the value                                 that kind of tuning gives you you often                                 can end up sort of especially if you                                 have direct really good SSDs there's a                                 lot you can do to just tax your system                                 more and more try to aggressively merge                                 segments together so that you can get a                                 lot more out of your necessities but                                 make you such as faster kind of skipping                                 our few details here of if you need more                                 details on this like please feel to                                 research it to be later so we went past                                 that phase and we get got to a point                                 where we optimized as much as we could                                 to the extent we could and realize that                                 a lot of the bottlenecks were going down                                 to the Java level right searchers would                                 work out fast you till you reach a point                                 where it had a garbage collection                                 collect and for the kind of real-time                                 latency requirements we had there's lot                                 of stuff happening in the indexing side                                 as well and you will end up with garbage                                 collection process for eight seconds                                 kind of pointless having your search                                 come down to less than                                     seconds if you have to sometimes tall                                 for eight seconds so lot you can do to                                 essentially sort of optimize it small                                 inefficiencies multiplied scale that                                 that I think it's it's pretty                                 underappreciated you often sometimes                                 need to know what the colonel is doing                                 as well watch by the time is spent                                 sometimes you can end up with the place                                 where you think you're you're you keep                                 trying to optimize your query then you                                 realize that the query is actually fast                                 that you're not funneling enough through                                 it you might realize that there might be                                 there's some hard-coded number right in                                 the code which is actually limiting it's                                 like some person at some point that like                                 who would need more than                                             guess what we need it so you you have to                                 often go through that analysis to find                                 out where that hard coded number is or                                 where that bottleneck is before you come                                 up and goes without saying and this is                                 more to as operational side you all you                                 also need to do a fair amount of                                 instrumenting along the way so that you                                 can find that number right we were a                                 very interesting place where how many if                                 you guys have used ye AR Kait this a                                 profiler which is pretty common so the                                 first challenge we had with your kid was                                 that you start run at two seconds solar                                 would die just like that because there                                 are their challenges to using something                                 as intrusive as that even with the                                 minimal options turned on so you often                                 have to sort of like building real code                                 instrumentation not rely on a profiler                                 to sometimes give you insights at scale                                 sometimes there is no longer true                                 thankfully I mean we once found the case                                 where jetty had a bug which would                                 sometimes stall and cause a timeout                                 Ramsay in my team is over here he spent                                 a few months trying to nail that down                                 and it turns out that jetty had a race                                 condition which used to trigger                                 thankfully again it's not there with JT                                 nine which would cause request to just                                 wait for the entire time out and install                                 again kind of pointless optimizing if                                 you had wait for                                                      condition sometimes going beyond so we                                 got it to a place where it is fast                                 enough now you need to do scale things                                 on the on the you need to make things                                 more stable one of our biggest                                 challenges was to make this stable                                 across maintenance machine maintenance                                 we often have during weekend sort of                                 like machines going undergoing regular                                 maintenance and hundreds of course                                 essentially a                                 around a quarter to one-sixth of the                                 system going down for maintenance and                                 coming back up and those are places                                 where the distributed coordination of a                                 system as large as this starts getting                                 tested there's still lots of work going                                 on still there's a lot of work needed on                                 scaling what is called the cluster state                                 which holds the entire solar clock                                 together but you often find out that                                 these are things we need to scale and                                 you find out only at a scale where you                                 have like hundreds of shots thousands of                                 course that things start sort of                                 developing cracks if you were notified                                 wise never sort of try to scalar I mean                                 not never but be very careful when                                 trying to scale a solo cloud be                                                                                                            point and you know what the breaking                                 point is in what's the cross by just                                 needs work in many cases it's just an                                 old-fashioned sort of you shouldn't have                                 all your leaders be present in the same                                 place because it just tends to tax the                                 machine out so in some cases you just                                 said leave algorithmic improvements you                                 sort of help scale things better in the                                 other more challenging thing has been                                 that when something goes down comes back                                 up it tries to recover you shouldn't                                 have that effect live traffic or worse                                 it shouldn't affect cloud stability we                                 had cases where something would saturate                                 network performance that when that in                                 turn would affect other traffic which is                                 more critical on the machine and lead                                 the entire cloud to disaster in some                                 cases you can throttle not the greatest                                 of solutions but because your startup                                 takes longer but works we actually                                 recently moved to it if using a                                 different network for this entirely so                                 right at the network level we use a                                 different network interface that that                                 needed some interesting changes on the                                 solar side which we are still working on                                 but we at least have a solution for                                 ourselves at this point using                                 transaction log recovery stories those                                 two kinds of recovery is possible of you                                 you can tune this now and this is one of                                 the changes we had to do so that you try                                 to avoid copying full parts of the                                 indexes to from one machine to another                                 and try to do as little as possible in                                 terms of recovering                                 but there will be problems in particular                                 I think we started from a place where                                 the solar collection with we had had                                 like eight shots and we kept doubling it                                 up and we we figured out that each time                                 we double the number of shots we would                                 find a new race condition right it's                                 almost the race condition of the                                 iteration on what sometimes multiple of                                 them good news is that you don't have to                                 deal with this now I think we started at                                 a place where solar was a lot less                                 stable with these things lots of work                                 has gone from our side from others in                                 the solar community as well there's lots                                 and lots of work which is gone into                                 making things more stable the nice thing                                 here is that well nice depending on how                                 you look at it if there is a dazed                                 condition we will hit it right it's just                                 a matter of time what happens is it safe                                 to stop multiple replicas of a shard                                 simultaneously you'd of thought so but                                 there is a race condition what happens                                 if you shut down just when the lucene                                 indexes in the middle of a merge and the                                 shutdown takes just a little bit longer                                 or little bit less and that triggers                                 race condition what is this a delhi by                                 query happening just around when a                                 leadership switches and then there's a                                 recovery which tries to deal with the                                 delete by prairie and that ends up                                 stalling the recovery process by just                                 the right amount of time to delay                                 leadership transfer and you start                                 getting time modes all of this as like a                                 file line step process leading from one                                 leading to the other two leading to the                                 leading to it finally to a disaster so                                 and the funny bit is that even if I to                                 screw up yet to be controlled about one                                 of our changes was actually to make                                 checks for misbehaving machine each                                 light there was a case where there was a                                 machine which is underperforming all the                                 thousand course I'd asking hey are you                                 healthy can you talk to you again yes if                                 you hadn't asked me I would have been                                 healthy so if there's a network                                 partition that's the reality of life                                 right i mean like network partitions                                 happen will the cloud always heal it                                 should it should it's always it should                                 it doesn't sometimes as with realize                                 sometimes democracy can be annoying when                                 you have leadership elections which kind                                 of say that i have to be elected                                 democratic                                 I can't have a dictator you'll end up                                 going around in circles sometimes one                                 trying to like the other sometimes the                                 problem is not to do with so much with a                                 systemic problem but a small problem                                 which can blow over one of the things                                 with infinite query flexibility is that                                 you can have poisonous queries I can                                 tell you my experience that no good can                                 come out with phrases wild cards and                                 spans indexes you gotta trust me on this                                 people who try to do things right i mean                                 like why don't take copy paste an entire                                 excerpt i have into the search field so                                 that i can find the article that you                                 have not a good idea guys search engine                                 is there so that you can just put a few                                 keywords in or my keyboard has the key                                 stuck I can't figure out what to do                                 about it I call the IT guy up let me go                                 for lunch that thing is sending key                                 presses all the time in the background                                 solo has better and having made this up                                 trust me these these happen these cost                                 out teaches solo now has better circuit                                 breakers for queries this came with                                 around a year or so back which is great                                 because you should realize that a long                                 query doesn't just have a ability to                                 reduce your query bandwidth like you're                                 not just taking a thread away you can                                 actually take down replicas we have                                 taken down replicas because of a                                        query because it did so much garbage                                 collection it created so much garbage                                 that garbage collection went through the                                 roof and took the entire lip licker down                                 so it's great that we have circuit                                 breakers but we can't do better so often                                 you have to account for a certain amount                                 in terms of circuit breakers you that                                 might be too late so I mean the dream                                 would be and you're starting to work on                                 this now to see whether you can have                                 statistical query plans for searches and                                 try to come up with models which can                                 dictate whether research will be slow or                                 fast it's a very hard problem but we can                                 start taking steps there you can use a                                 replica affinity where you often realize                                 that people can be very persistent about                                 their failed queries right i mean like                                 so they've already taken down a replica                                 because of their battery they try again                                 they try again and you reach a point                                 where the system tries to be nice takes                                 on the entire cloud for them                                 you need to use a replica affinity so                                 that that can't happen you need to                                 protect the system against one user                                 taking down the cloud sometimes even if                                 it is systemic failure you need to                                 protect one system from the other often                                 cases a very common cases where you have                                 like a spike of indexing which could                                 starve out searching for example is one                                 of the things to choose on going in the                                 solar community on seeing whether we can                                 isolate thread pools for searching and                                 indexing we have already worked on                                 isolating query Federation so there's a                                 solar process which tries to federate                                 out a query to multiple nodes gets back                                 the results that query doesn't need to                                 host data bytes own though it can this                                 again helps you to sort of isolate the                                 federated use case from the searching                                 use case and kuhn for them differently                                 isolating critical roles like the                                 overseers is something which is present                                 in solar overseer is a very critical                                 part of the component you can't just                                 afford for it to go down so you need to                                 put it in a place where there is very                                 little risk of it going to the future                                 really and this comes back to the query                                 plans thing is like isolating costly                                 queries from cheap ones so it's not just                                 a poisonous way it will just be a costly                                 query but you don't want too many costly                                 critics taking down the system the other                                 angle to this is that it's you often                                 sort of like try to make things too                                 consistent and that's always a problem                                 it's all one happy cloud till garbage                                 gets into the input your system is just                                 becomes as stable as what your input                                 pipeline is and if that input pipeline                                 is changing it has a bug you don't want                                 a definite system where there is bad                                 data everywhere because you have                                 successfully managed to replicate it in                                 real time so sometimes you need tightly                                 coupled replicas and they need multiple                                 copies of them which are loosely coupled                                 so that you can make changes to the                                 input                                                                    coupled replicas then move to the next                                 move to the next and so on the challenge                                 is then is trying to meet me in the                                 right balance where they are loosely                                 coupled but you can still easily                                 synchronize them without having to do                                 sort of like lots of manual work this is                                 something which is which is still pretty                                 hard but there is work we are working                                 with lucid works and charlaine fear in                                 the audience aware a that needs                                 he's working on helping us get CDCR                                 cross data center application to get to                                 a point where it can help the                                 synchronization and soon we will be able                                 to do this much more ultimate in an                                 automated fashion okay we made it stable                                 now to make it better one of the things                                 which we had to carry over from the old                                 system was grouping right you have where                                 there's a different part in the pipeline                                 which tries to collapse content which                                 are which are about the same thing but                                 different newspapers are published it                                 for example that's great as long as its                                 pragmatic the problem with grouping is                                 that especially if you have deep pages                                 and again we have seen users sometimes                                 go to hundreds of pages right I mean                                 especially this is that day job they are                                 looking through new stories then they do                                 tend to go pretty deep on searches but                                 the problem with deep aging is that                                 especially with grouping there is no                                 solution which is available to be more                                 pragmatic about it if the search engine                                 starts thinking that a result in the                                 first page could be grouped with                                 something                                                                retrieve all the hundred and fifty pages                                 of information before it can decide on                                 what to return so there's a fair amount                                 of work we need to go through to cons                                 make it consider window of end results                                 for grouping and then deep paging on                                 something we haven't contributed back                                 but we will eventually one of the big                                 corner stores from last year for us has                                 been to implement a learning to rank                                 framework and solar this is this is this                                 is a pretty big effort spanning multiple                                 teams that we try to get a standard                                 framework wouldn't solar where you can                                 define features define models and be                                 able to rank results get back feature                                 values with responses to train models                                 offline this is being is this in the                                 past part of being sort of pushed                                 upstream there's the going on on trying                                 to commit this upstream and if you're                                 more interested as an entire talk on                                 this film lucid leucine revolution last                                 year just search for learning to rank in                                 solar and that will take you more lastly                                 it's not just useful to show people                                 results is also be useful to show them                                 what they should be looking for that's                                 the trending part of news and what I                                 call intelligent faceting so not you                                 don't just facet but you be more                                 intelligent about what you show up in                                 those play                                 and this is one part where solar can                                 really help the stream document                                 frequencies out to a different system                                 which can then be used as a trend                                 detection pipeline to consume and detect                                 anomalies so that's that's what we have                                 done so far there's there's still a lot                                 going on in the pipeline relevance by                                 itself can almost be something we can                                 talk on for go on for endlessly rhyming                                 you can keep tuning getting better user                                 models one challenge has always been                                 sort of how you can improve what is                                 called information arbitrage when you                                 have information in multiple languages                                 how do you get that effectively better                                 searching across using social media                                 social media as many of users of error                                 is a separate beast by itself it speaks                                 its own language it has its own                                 demographic trying to integrate our new                                 searches in challenge searching and                                 scoring effectively in bulk we often                                 have challenges where we need to run                                 four thousand searches in bulk in a very                                 short amount of time leadership sorted                                 views on search self-explanatory we have                                 two major use cases to do with sort of                                 chronological relevant slack results and                                 often a challenge is to see whether we                                  can combine those two workflows get them                                  to blend better it's pretty much it so                                  that's the hope you can see them that's                                  the that's the Bloomberg team or a part                                  of it which was set loose in solution                                     or                                                                        of solar really the challenges continue                                  perfect just a question how do you store                                  your user cars and how do you do these                                  excess control say say can you vote how                                  do you store the user story I the user                                  searches and how do you do these access                                  control with that it's basically that's                                  not one user can can see and destroy                                  these searches of others so the users                                  queries are stored in sort of like we                                  have separate databases is not in solar                                  we have separate databases which try to                                  sort of partition user queries and                                  there's logic around trying to make them                                  private to the user so that's nothing                                  else or that's that's that's just a                                  separate system which is how tenancies                                  during these queries as it gets to the                                  system it's used in a different ways                                  right not so much its search search is                                  just one query getting in getting out                                  many results but we often need to sort                                  of like have in memory representation                                  sometimes when we do alerting that's                                  something I haven't touched in a lot in                                  detail where you try to sort of like                                  look at all the queries and then try to                                  find out which is there and for a lot of                                  this do you also your question privilege                                  is embedded at the lowest level so that                                  there is no risk of essentially queries                                  getting out of the system and other                                  users seeing other people's results so                                  that's that's a big requirement any of                                  these both and such as well as alerting                                  is you have the lowest layer in this                                  case lucene pretty much handling the                                  provision logic using filtering we've                                  got to prepare the next talk but thank                                  you for your talk do meter data texts                                  have relations such as same as broader                                  and if so how do you query against these                                  relations so the question is do metadata                                  tags of relationships and how can we                                  carry these relationships currently it's                                  not part of the metadata so we have a                                  separate system which tries to                                  understand user intent and converts it                                  to query that sometimes understands                                  machine                                  the relationship between queries but                                  there is a longer-term plan to actually                                  get this into the solar index so that                                  you can I still don't know what we're                                  going to do about it it's it's a pretty                                  interesting challenge but yeah so                                  correctly you can search for those                                  relationships and the index provides                                  mechanism but the connections are                                  outside and we tend to use less in that                                  way so thank you very much
YouTube URL: https://www.youtube.com/watch?v=mz41RGhDu_k


