Title: Berlin Buzzwords 2016: Stephan Ewen - Stream Processor as a Database: Building Online Applications
Publication date: 2016-06-12
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Stephan Ewen talking about "The Stream Processor as a Database: Building Online Applications directly on Streams with Apache Flink and Apache Kafka".

We present a new design pattern for data streaming applications, using Apache Flink and Apache Kafka: Building applications directly on top of the stream processor, rather than on top of key / value databases populated by data streams.

Unlike classical setups that use stream processors or libraries to pre-process / aggregate events and update a database with the results, this setup simply gives the role of the database to the stream processor - here Apache Flink -, routing queries to its workers who directly answer them from their internal state computed over the log of events - Apache Kafka.

Read more:
https://2016.berlinbuzzwords.de/session/stream-processor-database-building-online-applications-directly-streams-apache-flink-and

About Stephan Ewen:
https://2016.berlinbuzzwords.de/users/stephan-ewen

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              working all right thanks for the                               introduction thanks everybody for coming                               here I hope you having a good day                               enjoying this nice day in the London                               have a good conference so far I'm Nam                               Stefan I'm talking about the stream                               processor is a database here with Apache                               chief link and yeah let's get started so                               I always start my talks with this quote                                just to to basically get the said that                                basically set the stage for the kind of                                kind of twist of stream processing that                                that I'm talking about and the way we're                                thinking about stream processing with                                flink because a lot of people still                                think stream processing is something                                that is tailored towards an issue of low                                latency applications and what I really                                have in mind when I say stream                                processing here and it's kind of the                                paradigm behind the way flink is                                developing is that stream processing is                                actually not just a like a low latency                                real-time thing it's it's really a                                paradigm for continuous processing on                                continuous data continuous data being                                basically all data that is not dumped at                                you in like in a terabyte at an instant                                but it's really produced over time you                                know locks sensors everything that you                                but yeah that gets appended and created                                over time accumulates to very large                                amounts but but it's created over time                                and you actually I'm processing this in                                a continuous fashion following this                                continuous paradigm this is a very nice                                program that's all so many problems and                                that's really what our roof link is                                about I'm going to just spend a minute                                or two on a on a flink                                               that are not too familiar with the                                system so far and then and then dive                                into the stream processors the database                                so Apache chief link at its core is a                                streaming data flow system for for                                streaming applications so the the bottom                                layer is the streaming data flow runtime                                it's it's it's a run term of operators                                and streams connected in a directed                                acyclic graph um that that moves data                                between parallel instances processes it                                transforms it produces streams consume                                streams and on top of that of that run                                time we've built to API stream                                processing and API in a batch processing                                API the batch processing API                                also execute on the stream processor so                                it's really basically interpreting batch                                as a special case of streaming and                                running it on a streaming rundt time we                                currently have two different AP ice                                because the batch processing at the i                                has a bit of extra a bit of extra                                semantics and syntactic sugar for four                                cases that just become a little simpler                                if you think of static data sets rather                                than continuous data sets and on top of                                these two FB i--'s there's a bunch of                                libraries for example for complex event                                processing for graphs or machine                                learning all right if you're if you're                                using flink what you're basically doing                                is you're writing a functional program                                in either the java or the scala api's                                you're working with with data streams                                you're applying furniture                                transformations like maps you can                                reorganize data you can apply windows                                and then do aggregation functions and so                                on so this function the program gets                                transformed into a data flow graph and                                the data flow graph get sent to the                                distributed our cluster for execution                                the kind of core pillars of link at                                least of the streaming sites I'm going                                to focus very much on the streaming side                                I mentioned it has the data set API for                                for processing of static data sets upon                                the data sets but I'm going to focus                                very much on the streaming start today                                so the for the four pillars of this                                streaming site which actually I think                                make flink the the nice and versatile                                tool that it is today are are those it's                                a true stream processor with support for                                event times there for processing and a                                bunch of knives api's and libraries and                                those four in combination each each one                                actually am brings some very good                                 aspects with it but all of these four                                 together actually make a very very                                 strong and powerful combination on today                                 the focus I are having this talk will be                                 mainly around the state full site the                                 are the blue or um yeah violet box in                                 the in the bottom left corner so to                                 motivate why why we even want to think                                 about this architecture the stream                                 processor is a database let's actually                                 go through through a very simple very                                 classic use case may be one of the most                                 classic you use cases for stream                                 processing that you can have and that is                                 are creating real-time counters and                                 aggregates so think about the following                                 your                                 you're your system are your company that                                 has a stream of events of user                                 interactions and you just want to create                                 some some real-time aggregates be that                                 to expose them in a dashboard or be that                                 just to you know have a have a data                                 service that you want to offer to your                                 customers that for example if you're                                 let's say your Twitter and you want to                                 offer to to somebody that they can you                                 know look at how often have people                                 interacted with my tweets very very                                 simple thing it may like it might sound                                 like it's a the the simplest thing you                                 can possibly do with stream processing                                 but if you actually want to solve this                                 and to end everything you know the                                 latency scale it very large have it have                                 it run very reliably and and yet                                 efficiently it's it's a very hard thing                                 that that people are still sort of sort                                 of struggling with them over the course                                 of this talk I'm going to actually show                                 you what what uh what the next kind of                                 obstacle I swear we're getting out of                                 the way here so the architecture to                                 implement this is a very very classic                                 streaming architecture you start off                                 with with basically collecting the                                 events that you that you want to analyze                                 you lock them into in something like                                 Kafka you compute the you compute the                                 aggregates in flink and then you expose                                 it some way and one of the you know in                                 one of the many databases or key value                                 stores pick your favorite the                                 implementation of the of the processing                                 job is also fairly simple if you look if                                 you look at it this is an example from                                 from Flinx scholar ap is from on the top                                 line we're simply defining ourselves a                                 as simple a simple type with which                                 you're going to work with basically                                 impressions with an ID and the the                                 number of impressions and then we're                                 creating our stream reading from Kafka                                 we're going to filter and transform the                                 impressions a bit and then on the bottom                                 lines actually show that there the group                                 by a deed by D and then we with some of                                 the impressions in time windows of one                                 hour so far so good um to help you sort                                 of get there get the structure of this                                 program here's his kind of the data for                                 representation of what this what this                                 program balls down too                                 so if I've drawn it with a parallelism                                 of two but I guess you can generalize                                 from there it can be way more parallel                                 than just two threats right I'm starting                                 from cough cough is running through the                                 filter running through the map you're                                 shuffling across the network when you                                 reorganize it by the key by the ID and                                 then building windows summing it up and                                 and writing it somewhere so somebody can                                 actually look at the aggregates it's a                                 that's the basic structure of the job if                                 we run this in in the putting it all                                 together if you run this in the                                 infrastructure it's it's going to look                                 somewhat like that right data from Kafka                                 there's going to be only two operators                                 in the runtime and flink because it's                                 going to condense a lot of the operators                                 together for example the source the                                 filter and the map are going to become                                 one thing the windows and the sink are                                 going to become one thing it's going to                                 run in multiple parallel instances and                                 the data is written just put the reddest                                 icon here it's the one that we use in                                 this example but it could be it could be                                 any other key value store actually um                                 yeah and the results are exposed by a                                 key value store and the queries go                                 against that a key value store right so                                 if you if you say okay let me let me see                                 how many people have interacted so far                                 with with with my tweet with that ID you                                 just pick this up from the key value                                 store so remember now that the the the                                 aggregates they were computing we're                                 like an hour early windows right so                                 you'd he would sort of aggregate data                                 per hour and if you would only ever ride                                 it to the key value stuff after the                                 hours up after the full windows up you'd                                 you'd not have a very very real time                                 up-to-date view of your of your                                 statistics and the key value store                                 because well you could never actually                                 look at any in-flight aggregates or so                                 you could only ever see what is the                                 result of the window especially when you                                 used the event time window functionality                                 in flank and it it it sort of                                 compensates for out of order events and                                 for for some lady events then you know                                 the hour can be compute actually even                                 quite a bit later than the full hour is                                 up so what you probably want to do in                                 this use case is is add something like                                 an in addition to the event I'm                                 watermark trigger that is Flinx internal                                 mechanism to figure out when it's an                                 event time our full                                 at something like a periodic trigger                                 that just lateral areata CLE flushes the                                 current aggregates into the key value                                 store so you could actually pick them up                                 that is that is interestingly not not a                                 very let's say exotic exotic way of                                 doing it a few months back yahoo                                 published a streaming benchmark and that                                 is pretty much exactly what this the                                 sample application the streaming                                 benchmark was doing it was computing                                 windows i think in their case it was                                 just like                                                              computing them inside the stream                                 processor like that and every second                                 exposing them to an outside key value                                 store and allowing you to basically                                 query the up to the second accurate data                                 so looking at this very simple design it                                 may not you know it may feel a little                                 funky you you you flush all these early                                 aggregates always into into readies and                                 then he actually at some point to the                                 final ones and can close the window and                                 move on to the next hour but that                                 apparently that's what people are doing                                 so let's actually look how well it does                                 and looking at how well it does we're                                 going to look at three dimensions a                                 latency throughput and are the                                 scalability with respect to you know how                                 many how many aggregates are actually                                 looking at so are for the latency                                 already mentioned that that yahoo's                                 benchmark was pretty much looking at                                 exactly that use case so for latency let                                 me just you know let me just side their                                 benchmark that was sort of the summary                                 graph from from the experiments they did                                 a cross-linked storm and spark the                                 versions are I think all like half a                                 year back or so but it's it's not like                                 something very very fundamentally change                                 there so there the ballpark's at least                                 are still still the same um and it's                                 it's kind of a throughput latency                                 trade-off and you can see the throughput                                 goes to something like                                                per second and then the latency is                                 anywhere between you know for flink and                                 storm in the in the second rage for                                 spark it actually goes up so let's                                 assume latency is it's actually doing                                 okay in this case the throughput if we                                 if we look at the throughput                                         elements is at something it's ok for a                                 lot of operations but is actually not                                 really the limit of this kind of                                 application so we actually                                 did some ice experiments we looked into                                 the throughput exactly that that job and                                 and just pushed it a little further                                 these experiments were actually done on                                 a on a on a cluster at at Twitter it had                                 the interesting setup that the storage                                 class turned the computer cluster was                                 separate so there was like inside each                                 cluster they had                                                     connections but between the cluster only                                 one gigabit ethernet connections so you                                 could actually see that if you if you                                 look at the implementation flink at                                 least reading the data from Kafka and                                 the setup as as I explained it earlier                                 sort of hit a bottleneck here that one                                 leg is interestingly not up to cough                                 cards really because the like the cross                                 cluster link was just saturated at some                                 point in time if they actually have                                 actually both were running with a                                    gigabit interconnect you could probably                                 go much further there so what were what                                 this was basically doing it was sort of                                 using a trick to to move move the the                                 data directly into the into the into the                                 cluster and read it basically within the                                 same class over tape with                                            with                                                                  you can see that the yahoo benchmark                                 stop somewhere at                                                        per second but you can actually push                                 this if you're if you have a decent                                 network to to quite a lot this was                                 running on                                                             elements per second so I mean throughput                                 seems to be okay in general in that case                                 that they suggested in this benchmark                                 but the most interesting dimension                                 actually that is the motivation for this                                 kind of work and presenting here is the                                 third dimension looking at how does it                                 do with a number of keys so if you                                 actually look at this yahoo benchmark                                 very closely you'll actually see that it                                 had only keeps                                                        the motivation was tracking the                                 interactions with advertising campaigns                                 and they were assuming there were never                                 more than                                                             we'll just take a hundred counters so                                 what this means actually is that every                                 second                                                                   flush to the key value store which                                 doesn't seem like a lot of work doesn't                                 seem like that should pose a challenge                                 for many key value stores so on the                                 other hand it doesn't really reflect a                                 lot of real world use cases right                                 hundred aggregates are definitely on the                                 on the lower end of what people usually                                 have so going back to a motivating                                 example if we want to actually count the                                 if we count the impressions over tweets                                 right then the number of keys you will                                 have within this hourly window actually                                 large I think concretely in the in the                                 example that we did on                                                with                                                                 means that actually every second                                 multiple hundred thousands up to a                                 million keys are updated if we actually                                 look at how does this particular setup                                 perform with these different keys that                                 dimension makes a huge difference right                                 if you flush hundred Keys per second                                 that's going to be fine if you may have                                 to flush a million or hundreds of                                 thousands keys per seconds then you hit                                 you immediately hit a throughput bottle                                 like so the bottleneck in the key value                                 store the bottleneck is writing back the                                 aggregates to the key value store and                                 because flank internally has has a back                                 pressure mechanism if the sink cannot                                 keep up then you know it will just back                                 pressure and will decrease the                                 throughput and it is going to stay                                 longer in kafka so in that case it would                                 yeah the the concrete number here is I                                 think somewhere around                                                  per second that was as much as we could                                 get out of the key value store with that                                 particular setup you could probably                                 expand this by you know building in some                                 manual sharding logic against multiple                                 read his notes and so on I mean even if                                 you take this x                                                          key value store even more resources than                                 we use for the for the stream processor                                 then you can still see that your you may                                 be able to get to get somewhere here or                                 so but you're still far away from what                                 actually the the stream processor can do                                 so it turns out that in this particular                                 application this communication between                                 the stream processor and the database is                                 really the biggest bottleneck and that's                                 actually interesting because if you if                                 you look at what what many of these                                 benchmarks actually do these days they                                 just like benchmarking the hell out of a                                 out of a student possessor in a very in                                 a kind of simple use case right and for                                 for many real-world application that's                                 not really quite quite quite helpful                                 because you know the bottle Mac is often                                 not within a system within a system we                                 can make sure all the parts play                                 together very well but as soon as you                                 have systems that need to interoperate                                 and communicate then you're hitting then                                 you're hitting are completely different                                 bottlenecks that you know another not an                                 individual system can just                                 optimize the hell out of so how can we                                 actually work around that because it                                 doesn't really make sense to build a                                 super scalable and performance read                                 processor and allow this to scale out                                 very far if in the end you know you're                                 going to pay out all the performance                                 anyways when you're trying to do remote                                 updates on a database that's kind of the                                 other motivation for our with the main                                 theme of this talk is queryable state so                                 in a nutshell the idea of curing of the                                 state is actually dead simple it just is                                 are instead of you know saying the real                                 time aggregates we're going to pick them                                 up from reddit or any other database                                 let's pick them up directly from the                                 stream processor why not right so the                                 stream processor apparently has them                                 stored internally somewhere there the                                 windows the early windows you have two                                 counts per key and so on so so they are                                 there we just need to expose them                                 somehow and that is pretty much in this                                 prototype exactly what we did real-time                                 queries in this case we're going exactly                                 directly against flink basically and not                                 against right us anymore there is an if                                 you wish this in an optional still you                                 know flash the windows at the end of of                                 the hourly period or so inches into some                                 archive database and you know as soon as                                 they are immutable you basically do only                                 on one right anymore a output and yeah                                 and then you can actually you know                                 reduce the amount of data you're keeping                                 inside the stream processor and just say                                 you know older queries go gives the                                 database all right on chris go against                                 the go against the stream processor so                                 this architecture is in some sense aah                                 what what this prototype um that we did                                 together with someone at Twitter and a                                 quick project actually implement it and                                 it like in their architecture it fit it                                 very well because they really bought                                 into this concept of lambda so there's                                 going to be a a slow path on something                                 based on MapReduce anyways that that                                 writes to archive database and there's                                 going to be a fast path based on in                                 their case it is herun and some key                                 value store they built internally that                                 they used for the real-time queries so                                 they they kind of had this idea that                                 they would route queries either to the                                 to the results of the slow path or to                                 the Past path based on you know how                                 recent is the result I want to pick up                                 so that actually fit very well the real                                 time crews would go against                                 windows the old database the old crews                                 occur is that refer to data that's                                 further back in the past would go                                 against the archive database so this                                 this extension was actually something                                 that is conceptually it was very easy to                                 build into flank and and there are a few                                 few corner parts that I want to                                 highlight why why why we can actually do                                 this and what happens stream process has                                 been doing this all along it seems like                                 such a natural thing to do this is                                 searches to be a bottleneck and you know                                 why not just immediately pick up the                                 data from the stream processor so                                 there's a few things that stream                                 processors didn't have for for quite a                                 while which is actually quite important                                 if you want to realize something like                                 that and the first the first thing is                                 actually that the stream processor has                                 to be aware of state and has have stayed                                 as a first class citizen if you look at                                 at storm I think prior version one point                                 or just came out it didn't even have a                                 concept of off state that the frame                                 processor was was a wealth arms the                                 state by itself also has to be fault                                 tolerant it's not just about replaying                                 events but the the state itself has to                                 be recovered with good semantically                                 guarantees like exactly once the state                                 also has to be partitioned and and scale                                 out with the operator so it doesn't make                                 sense to have the state in one                                 centralized instance and scale out the                                 computation so the state has to actually                                 scale with the computation like you                                 would start charting a database and                                 scaling it in and out of your state                                 gross right because that's that's how                                 you that's how you actually make it                                 scalable the next thing is if you                                 actually want to expose something like a                                 database from within the stream                                 processor it it becomes a very tough                                 thing if you actually do this based on a                                 mini batch system it is it's much more                                 straightforward if you do it based on a                                 system where actually operations live                                 continuously like a like a proper                                 continuous stream processor and the last                                 the last part is that you know it's it's                                 it's fine to say I keep a keep state in                                 initially in in memory but if you                                 actually want this to work reliably you                                 really would would like to you know have                                 to have the characteristic that each                                 node can store data in memory but also                                 on disk if if the memory becomes scarce                                 so all of these things are things that                                 that fling state mechanism actually                                 offers and where we could actually build                                 this in there the the current state of                                 of queryable state is it's not yet in in                                 any full release there's an open pool                                 record                                 it's for fleeing                                                      you can actually check out this pull                                 request no ran a job instantiate a query                                 client and actually if you some queries                                 into some experiments but the exact                                 design and implementation are a little                                 bit under evolution so we're still                                 trying to you know chew and here and                                 there a bit to see what works best                                 because actually this is going on all                                 the time there's a little caveat so most                                 of these experiments here were actually                                 done not with the exact version of the                                 pull request but with a with a bit of an                                 earlier version of slightly different                                 implementation so the exact numbers may                                 vary a little bit but I think I mean the                                 important thing is that the ballpark                                 which is the same and yeah so it's a                                 it's it's still under under evolution                                 and work in progress I guess the most                                 interesting question is does it actually                                 solve the performance problem and if we                                 actually rerun this whole our                                 implementation with query will state on                                 a million keys then yeah what we                                 actually see is it does solve the                                 problem and it's actually not surprising                                 that you get the exact same through                                 possess used to get before because                                 assuming that in the hundred Keys case                                 there's there's really no bottleneck in                                 the interaction with the key value store                                 in the clear available state on the                                 million keys cases also know what'll                                 make any interaction with the curve with                                 the key value store anymore because the                                 data is simply not written every second                                 right it's just kept in flink and it's                                 kept in the exact same way as it is kept                                 anyways by the window that computes um                                 so this is really literally not overhead                                 here um the applications have to like I                                 mentioned sort of adjust a little bit to                                 this paradigm if you have an application                                 that's only interested in the latest                                 real-time results let's say you just                                 have a dashboard you want to see the                                 state of what is currently going on then                                 you only change that you really do is                                 instead of you know using a Redis client                                 you use the flink are credible state                                 client and basically sent your crews                                 directly directly against flinky if you                                 have a system that is really interested                                 in both the latest and older results                                 then you have to do something that's a                                 little more elaborate you sort of have                                 to work with with a with something like                                 your query service or so you have to                                 make your application aware that they're                                 kind of two different ports where you                                 can pick up results old old results and                                 and up to the left after the second                                 results so this uh like I mentioned this                                 doesn't seem apparently when I first                                 thought about this I thought it was very                                 exotic but I've actually since in a                                 bunch of companies                                 everybody that bought into this idea of                                 the lambda architecture that actually                                 have something like like this query                                 service actually in place internally                                 anyways arm precisely to sort of make                                 application switch between the results                                 computed by the first part and the slow                                 past path of the of the land                                 architecture so what you get here is you                                 still get a lot of the benefits of the                                 lambda architecture in terms of you                                 don't have the of not having lumped                                 architecture I'm sorry you don't have to                                 have the stream processor and the batch                                 processor you literally have one thing                                 only you just have to slightly are                                 direct your courage different ways um                                 out likes next like to look a little bit                                 and how does the queryable state in                                 flink exact how is it exactly                                 implemented in fling and before I dive                                 into this let me quickly do a brief                                 review of the architecture of link so                                 that would make the next part a bit                                 easier to understand so fling case if                                 you wish to two big plus types of                                 processes that are running the job                                 manager which is the master in the task                                 managers which are the workers and then                                 there is the the client site which runs                                 the pink program really the functional                                 program that I've showed on one of the                                 first slides and where this program is                                 inside the client is executed                                 transformed into the data flow graph and                                 sent to the cluster once it has arrived                                 in the cluster in in the master or one                                 of the Masters in a high-availability                                 case the master is going to have a data                                 structure called the data flow or                                 execution graph which is a                                 representation of the parallel data flow                                 of the program and it it basically uses                                 this to schedule our and to track                                 progress and to um yeah just sort of                                 detect failures figure out what needs to                                 be recovered and how and it sense it                                 sends to the to the task manages to the                                 workers are calls to execute certain                                 tasks they task managers then execute                                 the tasks in the resources there's a                                 there's a network manager which handles                                 our streams being exchanged between task                                 managers that handles all the things                                 actually multiplexing are establishing                                 connections and cheering them down and                                 so on so with queryable state there                                 they're actually two pretty much pretty                                 lightweight components that we added to                                 the system are most of the logic is                                 actually in the critic client so the                                 first thing is that are the the job                                 manager has an interv                                 that basically our lets you ask where a                                 certain resource is currently executed                                 so let's assume that we want to access                                 the state of a certain job a certain                                 operator so job would be you know your                                 name of the of the tweet impression job                                 the operation would be on hourly window                                 or the state name in this case would be                                 in on flink operators can have multiple                                 types of state also user-defined States                                 in this case it would just be the window                                 state and then the key would be the the                                 key of your tweet right so this kind of                                 the query that one is sent and and the                                 first thing that it would do is it will                                 actually send a a lock up to the to the                                 state location server which would look                                 into the execution graph which is                                 integrated the scheduler and is aware                                 where is this thing executed right now                                 and we tell the query client we defined                                 it and then this would actually look at                                 the state registry where operators                                 register all the local state that they                                 that they have and then they want to                                 expose and the crew client will just                                 pick it up from there so there's it's                                 kind of a ya think fairly                                 straightforward thing right first you                                 actually look at the location then you                                 could directly create the location the                                 creek line to some some caching so know                                 if not every look up has to actually go                                 through the job manager again and yeah                                 that's actually basically it there's a                                 bit of a retry policy so in case you                                 know something actually failed and were                                 scheduled some are different than the                                 Tasman who is going to respond with nope                                 that's actually not here and and we                                 basically trigger another look up and                                 say okay then tell me where it is now                                 and then you do a second look up where                                 where the state actually is but that's                                 that's basically all all there is in                                 this implementation so it's kind of a                                 kind of a witch lightweight add on to                                 what flink is so why why is this                                 actually now so so fast so what is what                                 is it doing fundamentally differently                                 arm internally then what for example                                 ready so Cassandra would be doing why is                                 they you know putting to a key value                                 store just completely aside from the                                 fact that you have to send some network                                 packets if you put something into a key                                 value store that's on a different                                 machine what is what is the very                                 fundamental difference while you're                                 actually getting such a high performance                                 here compared to just interacting with                                 another key value store and that is um                                 is what I want to talk about next so                                 while diving into this the first thing I                                 have to do is actually give a little                                 credit if you've been here at buzz words                                 a couple of times you'll actually have                                 seen this guy speaking a bunch of times                                 Martin clapman about turning the                                 database inside out and he's been turned                                 he's been speaking about how you know                                 you can actually rethink this paradigm                                 of databases which which log and then                                 right into tables into into something                                 different he was mainly talking about                                 data warehousing with cough can som                                 something in these talks so far I am                                 actually going to pick up some of his                                 like views and terminology to to just                                 explain the to explain why this                                 architecture actually gets this nice                                 performance so in some sense you could                                 actually think that what what this                                 queryable staton flink is doing is this                                 turning the database inside out plus                                 plus so it's out viewed as the as the                                 natural next step from from this kind of                                 ideas so to understand what it's                                 actually what is actually working so                                 differently lettuce let us just look at                                 let's look at some key value store that                                 is actually offering a good amount of                                 durability persistence and consistency                                 that lets repopulate their Cassandra um                                 the right part of Cassandra in                                 particular so if we if we actually write                                 data the first thing that will actually                                 happen is that the data goes to a commit                                 lock and every time you do you flush                                 your updated counters and put them into                                 the Sun for the first thing it does it                                 actually goes to a commit lock then it                                 goes to a mem table in the mem table is                                 you know accumulating data once in a                                 while it's going to be sorted are                                 compacted flashed and becomes an SS                                 table so what we actually see is the                                 first step is about lock durability and                                 that is that's not only a cassandra                                 specific thing if you actually go                                 through all candidata basis and that                                 offer durability that's really virtually                                 always the first step the second                                 interesting thing to notice you is that                                 this ma'am table per se is actually not                                 a persistent thing immediately right sue                                 sue memory as soon as the process goes                                 down or anything it's actually lost but                                 it's not not a big deal because the mem                                 table can always be recomputed using                                 parts of the log and part and d and some                                 other SS tables                                 and another important thing is that                                 really durability this is it's not                                 considered durable before it has been                                 replicated to a quorum of nodes and and                                 the important parts here I mean the the                                 costly parts are actually writing to the                                 lock and doing the replication now if we                                 look actually at our architecture here I                                 mean one interesting observation is why                                 would we actually want to redo this                                 every time for every you know every                                 counter update that we do given that you                                 know our data is actually durably stored                                 in a lock already in Kafka it is it is                                 locked and it is replicated and actually                                 the event stream is anyways our ground                                 truth here so given that that is                                 persistent that's that's a huge thing to                                 build on instead of you know just having                                 a second system that tries to do the                                 exact same thing again keeping things                                 available and durable the the queryable                                 state that we have here in flink you can                                 think of it is it's really just taking                                 over the the role of the of the ma'am                                 table in Cassandra right it's it's                                 something that is not immediately                                 persistent it's really just something                                 that is recon that is persistent in                                 intervals you know like a flink                                 checkpoint think of it as a mint abels                                 persisted on disqus and SS table but in                                 the time in between it'sit's recomputed                                 from the event stream from Kafka so that                                 that means that in this architecture off                                 link is really doing is actually the                                 part that is cheap in Cassandra right                                 it's not the expensive parts only doing                                 the cheap part and it's actually usually                                 a relying on the corporation with Kafka                                 to do the expensive part and and Kafka                                 is actually very performant doing this                                 expensive part because it's not doing a                                 you know / update replication and quorum                                 and logging and everything its religious                                 you know over to you you write data fast                                 into into your topic partition and you                                 know the replication is pipelined and                                 everything so it's not like you're                                 actually tracking your tracking                                 individual things it's it's very much                                 streamlining this whole durability thing                                 which which makes it very efficient if                                 we then actually look at what what                                 processing is here is a little like a                                 little cheap illustration this this is                                 the basically the job that we're                                 executing these operations here the                                 source filter and map and this                                 this is the window at the sum or data is                                 coming from these are locked partitions                                 and the events are flowing to the system                                 there's some basically of virtually                                 stateless stuff happening here they                                 flashed the network there shuffled and                                 then in the window do some operation                                 happening why do you update the calendar                                 or the aggregate and this happens in                                 some form of state index let's let's say                                 it's rocks to be here that's a very                                 common option entering the persistence                                 part inside flink actually consists of                                 two things triggering a checkpoint is                                 basically an operation that comes for                                 free the master is just going to tell                                 the notes it's time to trigger a                                 checkpoint and the notes will inject the                                 checkpoint barrier into the stream a                                 checkpoint barrier is basically a couple                                 of bites that are injected into the                                 stream it's a special special event so                                 that is virtually unnoticeable overhead                                 the checkpoint barriers actually travel                                 through the stream and at some point                                 they're going to reach the operators                                 below this a little more magic involved                                 you know if you have operators with                                 multiple input streams there's an                                 alignment face on the barriers and                                 everything but once these these barriers                                 actually reach these operators all                                 they're going to do is in the in the                                 rocks to be case if you if you pick the                                 asynchronous nap short version um                                 they're only doing a metadata operation                                 again that they're saying okay here are                                 trigger me a a copy on write snapshot so                                 all you're basically getting is um that                                 roxy be puts attack no it's a log                                 structured merge merge tree anyways                                 underneath the hood or something similar                                 to that and changes that anyways                                 appended first and all it's actually                                 doing is it saying I'm not I'm not                                 compacting into the old versions because                                 actually need to hold onto these old                                 versions interest you're not updating                                 new versions and compacting you versions                                 but I'm also going to hold onto the old                                 versions for a while at least so this is                                 if you wish a metadata operation it's                                 it's not really costing anything and                                 then the the part where the checkpoint                                 barriers travel through is actually                                 complete so we have these shadow copies                                 of the state now and then although all                                 the stream streaming problem actually                                 continuous processing it does no updates                                 on or CB and there's a background thread                                 that just takes this copy-on-write view                                 and and flushes it to some durable                                 storage completely in the background                                 it's not it's not really interfering                                 with your streaming computation so that                                 that all together actually sort of I                                 think illustrates while doing the                                 queryable state in a database where you                                 are not in a database the critical state                                 in the stream processor can be so much                                 cheaper than actually doing it in a                                 database and it can it can actually give                                 you very good guarantees if you look at                                 this you know Shadow Copy asynchronous                                 flash trick it's something that Redis                                 uses in the background but then again it                                 doesn't help you a lot there if you want                                 to not lose data because read this is                                 not really integrated with a computation                                 and with with a log and so on so it                                 isn't it doesn't really have the ability                                 to you know recover whatever happened in                                 between the flashes we actually just do                                 this all in the stream processor and                                 something that is designed to work on a                                 lock to replay to snapshot in the                                 background yep you basically just get                                 all parts working together in a way that                                 they you know the don't impose                                 unnecessary over it they don't redo                                 durability work that is actually been                                 done before anyways that's basically the                                 whole story if you wish um the the                                 takeaways of this story are all the                                 following I mean if you didn't if you                                 completely zone out and didn't listen to                                 anything then pay attention just to                                 these two slides like one thing that is                                 nothing very very interesting to notice                                 that cross system interaction is                                 frequently the biggest bottleneck it's                                 not it's often just not in the stream                                 processor itself                                                      the is the communication between the                                 streaming system that is you know all                                 pipelines and flowing and the and the                                 key value store which most key value                                 stores were made for for something else                                 for point point puts and looks at                                 lookups and so on making them                                 immediately visible and so on if you if                                 you actually you can mitigate this                                 bottleneck but just giving a good amount                                 of the key value store row to the stream                                 processor itself and apache flink has                                 very sophisticated support for free                                 state which which makes it which makes                                 it possible and performant to add this                                 about credible state itself kind of the                                 secret sauce behind why its fastest data                                 persistence is very fast with                                 distributed logs like Apache Kafka with                                 which is because it's a specialized                                 thing right it depend only it's                                 remembering replication and everything                                 so this this is just you know just                                 making a sequence of events durable                                 without also making their the view you                                 compute over them durable just solving                                 this one problem good this makes makes                                 it actually fast                                 and then the computed state over over                                 this view of events is actually very                                 fast and flink because um you can do it                                 just with local data structures and with                                 no synchronous parts with just                                 completely asynchronous replication and                                 the the check pointing that that we                                 built in to fling actually actually                                 handles that it's it's the main                                 takeaways thanks                                  thank you Stefan we still have five more                                  minutes for Q&A anyone wants to go first                                  sorry guys on the balcony I will not go                                  there oh ok so let us go this way thanks                                  for then the talk you gave I have one                                  question to your performance figures                                  mm-hmm I just wanted to know if this was                                  where the persistence test or just                                  within memory eat the ones you show that                                  where you show that the state I mean                                  this one here this one yes is it if the                                  you mean is the bottom row is it                                  actually checkpointing or not yes it is                                  actually checkpointing yeah okay thanks                                  yeah thanks again so once you allow                                  arbitrary clients to clear your screen                                  processor directly how does it affect                                  the stream processing because usually                                  have a predictable amount of consumers                                  and you usually scale your screen                                  processor with the amount of data that                                  flows in but now you get unpredictable                                  read load yeah that's actually a very                                  good question so these figures are                                  basically sort of looking at the rights                                  report um you absolutely right as soon                                  as you're starting to throw in a lot of                                  read a lot of red queries the reads and                                  writes are sort of competing for                                  resources right if you if you look at                                  where do we have it at this figure here                                  if you're if you're actually making at                                  the same time an update here and you                                  still hold on to this other snapshot                                  copy your ever iterating over it and                                  you're persisting it this is going to be                                  a little bit of content for resources                                  that's absolutely true so I mean a very                                  natural follow-up would be would be to                                  benchmark this the the read and write                                  traders I think the like the read this                                  there's going to be a bunch of retratos                                  i would agree here because at least in                                  this initial version for example the                                  there's not multiple replicas from which                                  you could actually read right this is                                  something that you would have in                                  Cassandra you have multiple notes that                                  you hold the replicas they can in theory                                  balance the reeds over them that is not                                  yet happening here this sort of a                                  natural follow-up if you wish to to let                                  the notes replicate each other stage                                  basically coordinated on checkpoints or                                  so which which would give you that but                                  in the first version it doesn't have                                  that the read path you're also not                                  seeing good good numbers for the or any                                  numbers for the read part in here                                  because that actually is the part that                                  changed the most in our implementation                                  so far so the first prototype was                                  actually implementing the read paths are                                  based on on our internally oh yeah                                  creating creating actors that would                                  answer the read queries and so on so to                                  sort of allow you to integrate this we                                  didn't want to tie it to our car in the                                  answer we're we're with we created a                                  protocol based on Eddie for the next                                  version and so on and on all of these                                  have slightly different characteristics                                  so there's our this is going to be                                  there's going to be some numbers but I                                  think we have to converge the                                  a little bit before before it makes                                  sense to present something because the                                  read numbers would actually I think                                  change over time with evolution okay so                                  I mean just as a conclusion I think this                                  is sort of it makes a lot of sense for                                  very right heavy right heavy throughputs                                  that was basically the scenarios that                                  motivated it and in which we charted out                                  in which it worked very well if you have                                  scenarios which are basically not doing                                  a lot of riots but extremely read heavy                                  I have we've yet to see I probably would                                  take some some some add-ons to make it                                  suitable for that let us take just one                                  more question does flink also of our                                  authorization for the queries you have                                  if i have different users to do the                                  skills um I in this in this first                                  prototype never doesn't there's um is a                                  whole whole threat in in Flint going on                                  about security permissions right now you                                  know working with kerberos with key taps                                  integrating more with Kafka renewing                                  tokens for Hadoop and so on i think it                                  makes sense to say this basically should                                  extend to queryable state as well at                                  some point in time but at this at this                                  point now and this and the poll regrets                                  that I showed here there's is no                                  implementation of authorization                                  encryption and authentication okay thank                                  you and actually it is not a prototype                                  by the production version of lunch                                  waiting for you just outside thank you                                  very much and see you in           
YouTube URL: https://www.youtube.com/watch?v=VUC_FAjvJww


