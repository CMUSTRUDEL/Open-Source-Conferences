Title: Berlin Buzzwords 2016: Vasia Kalavri - Graphs as Streams: Rethinking Graph Processing in ... #bbuzz
Publication date: 2016-06-12
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Vasia Kalavri talking about "Graphs as Streams: Rethinking Graph Processing in the Streaming Era".

Streaming is the latest hot topic in the big data world. We want to process data immediately and continuously. Modern stream processors have matured significantly and offer exceptional features, including sub-second latencies, high throughput, fault-tolerance, and seamless integration with various data sources and sinks.

Many sources of streaming data consist of related or connected events: user interactions in a social network, web page clicks, movie ratings, product purchases. These connected events can be naturally represented as edges in an evolving graph.

In this talk I will explain how we can leverage a powerful stream processor, such as Apache Flink, and academic research of the past two decades, to build graph streaming applications. I will describe how we can model graphs as streams and how we can compute graph properties without storing and managing the graph state. 

I will introduce useful graph summary data structures and show how they allow us to build graph algorithms in the streaming model, such as connected components, bipartiteness detection, and distance estimation.

Read more:
https://2016.berlinbuzzwords.de/session/graphs-streams-rethinking-graph-processing-streaming-era

About Vasia Kalavri:
https://2016.berlinbuzzwords.de/users/vasia-kalavri

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              thank you hello everyone thank you very                               much for coming to my talk I'm very                               excited to talk to you today about my                               favorite topic which is graphs and                               apparently Berlin buzzwords very topic                               with these streams so yeah stream all                               the things all this conference is about                               streaming if you look at the accepted                               talks at least                                                         stream or streaming in their titles and                                I don't think that's a coincidence we                                have very good streaming technology out                                there we can do amazing things we have                                very low latency we have systems that                                gives us very high throughput good fault                                tolerance guarantee is very nice api's                                the whole ecosystem is thriving really                                and not only we have these good systems                                but also users are very good at shifting                                their mindset very fast from a bad way                                of thinking to a streaming way of                                thinking so we can already do more than                                just counting words we can already do                                complex deven event processing we can                                already do online machine learning we                                can even do streaming sequel I mean this                                is a very exciting time um but what I                                want to share with you today is my                                thoughts on why even though we can do                                all of this amazing stuff why are we                                still stuck in the past when it comes to                                graph processing what about graph                                processing graphs are very dynamic all                                of the applications we have social                                networks purchases ratings everything is                                things events that happen in real time                                however we don't have any libraries for                                graph streaming right why is that um so                                far we've been doing graph processing in                                a very specific way we usually have a                                graph stored in disk we bring it into                                memory we load it into several machines                                like probably partitioned then we do                                some processing we compute and change                                the graph structure or the values of the                                vertices                                and then after the processing is done we                                go back and store it to disk and read                                the result this is this is the way we do                                graph processing today well if all you                                need is to analyze a static graph over                                and over again this model is great right                                I have no problem with that but if you                                want to do something more interesting                                like for example see how PageRank                                changes when your graph changes or how                                your graph might be disconnected if you                                know a user deletes their account or                                something like that then with this model                                that we have today we have to read you                                to redo the whole computation so what we                                have today is slow you have to wait for                                the whole processing to finish before                                you can see any result it's expensive                                because we have to do partitioning and                                you have to replicate in probably to                                minimize the communication between                                machines it has been shown that is many                                times much more expensive and resource                                hungry than if you would run the same                                thing on a laptop and well if your graph                                changes we have to recompute everything                                so this is a very very bad model for                                dynamic graphs m and of course grab                                streaming is not it's not an easy thing                                that's why we don't have anything yet so                                there are many challenges that don't                                appear in other areas of streaming                                applications first we have to maintain                                somehow this graph structure because in                                the core of graph applications are the                                graphs themselves we need to know what                                are the neighbors of its vertex we need                                to know the path we need to traverse the                                graph right so we need to somehow                                efficiently maintain this structure                                somewhere then we need to maintain                                up-to-date results when when they input                                changes and we need to compute on on                                fresh state only so in streaming                                applications usually we are interested                                in the in the latest state so how do we                                maintain this dynamic                                graph in memory at all times so we can                                compute our streaming applications well                                what if I told you you don't need to                                store the graph to analyze a graph you                                don't need the structure of the graph to                                get useful metrics from a graph right                                 this is this is different from what                                 we've doing so far but it's possible and                                 it's not a new idea it's something that                                 was actually introduced                                                 even earlier in a quite different                                 context so grab streaming is a concept                                 developed in academia to solve a quite                                 different problem from what we have                                 today but I think we can learn something                                 from it so the problem they were trying                                 to solve then was that we have a very                                 big graph that does not fit in our                                 limited memory it does fit in disk but                                 we can probably stream it through memory                                 may be several times not too many only                                 few passes we allow and then try to                                 compute something over this this stream                                 and give result so am a core component                                 of this model is graph summaries the                                 idea here is that if you have a huge                                 graph and you have an algorithm that you                                 need to run on this graph to get some                                 result and if you if you stream it                                 through memory maybe you can keep part                                 of it like a summary of it some compact                                 representation that will will fit in                                 your limited memory maybe since your                                 algorithm and a bit and then get the                                 same or a similar result to what you                                 would get if you would run your                                 algorithm on there on the big graph and                                 some examples of these summaries are                                 Spanish for computing if the if a graph                                 is connected and to compute distances                                 between any two vertices specifiers is                                 another summary to estimate cuts in the                                 graph you we have neighborhood sketches                                 and all other kinds of things that have                                 been developed over the years                                 unfortunately I don't have time to give                                 you examples for all of this since this                                 is a short slot but I will give you an                                 example of                                 simple summary and in the word count of                                 graph processing so are you familiar                                 with connected components yes okay some                                 of you so okay the problem is the                                 following we have a graph and we want to                                 compute the connected components of the                                 graph the connect a connected component                                 is a sub graph of the original graph                                 where there is a path between any two                                 vertices so for example here this is a                                 connected component by component because                                 you can go from any vertex to any other                                 vertex and that's a different one right                                 so the way we do this in a bad way is                                 that we assign a label to its vertex and                                 then we iterate over the graph and in                                 every iteration a vertex sends messages                                 to its neighbors and says this is my                                 label and then when a vertex receives                                 the messages it picks the minimum one so                                 after a few iterations the labels                                 propagate in the component and in the                                 end they will all the vertices belonging                                 to the same component will have the same                                 label so for example these messages will                                 go around in iteration zero in iteration                                                                                                          values again we send around messages and                                 so on we continue until all the word                                 this is inside the same component have                                 the same label right this is how we do                                 it in a batch way now what if i told you                                 that we can do this without iterations                                 and without ever storing the graph in                                 memory we don't need to know who's                                 neighbor with whom we only need to keep                                 the right graph summary in this case at                                 this joint set or union find if you if                                 you want and we only need to store the                                 component IDs and what vertices belong                                 in that component we don't need to store                                 the whole graph the edges and everything                                 else so let's see how this would work we                                 have a stream of edges coming we get the                                 first edge                                                              so we create a new component with these                                 two vertices inside the component we get                                 the second                                                                                                       component so we create a new one and we                                 always Tuesday ID the minimum of the                                 vertices inside the component for                                    exists already in component                                              add                                                              existing components nothing is there so                                 we create a new one                                                      the component                                                          we already have this information so we                                 can throw the edge away                                                component                                                                so we now know that there is an edge                                 between some vertices in these two and                                 we can merge these two components into                                 one picking again the minimum component                                 ID and we continue like this right                                 without needing to to store the graph                                 ever and of course we can do this in a                                 distributed way as well so we can have                                 several streams going to different                                 partitions or different different nodes                                 nodes computing local summaries and then                                 periodically merge into a single stream                                 where we get our result so that's an                                 algorithm that was developed really long                                 ago but we somehow forgot about it and                                 we started doing it the bath way the bad                                 news about all this research                                          ago is that it had a slightly different                                 motivation that what we really need                                 today so the problem they were trying to                                 solve was assuming an a bounded graph it                                 was assuming that we have a graph it's                                 too big but it's not endless like the                                 streams resume today so what we need                                 today is a bit different in a sense that                                 we want to continuously process                                 something continuously changing probably                                 forever the second problem is that since                                 this research assumes that the graph is                                 bounded some of the algorithms developed                                 assume that we know the number of                                 vertices or the number of edges and the                                 last problem is that most of these                                 algorithms developed back then were                                 developed for                                 threaded execution the good news is that                                 we live in a different reality than                                     years ago so memory is getting bigger                                 and it's getting super and we know now                                 how to design distributed algorithms so                                 the idea is what if we get inspired by                                 that research and try to relax maybe the                                 assumptions that they had maybe not                                 create so strict summaries and try to                                 evolve these algorithms to bring them to                                 the setting that we have today and the                                 needs and requirements that we have                                 today and that's what I'm trying to do                                 with a colleague of mine at kate's in                                 Stockholm we have built a graph                                 streaming prototype on top of hibachi                                 fling called jelly stream so if you're                                 familiar with fling if you went to any                                 of the talks fling has two api's one for                                 bats one for streaming so for the bats                                 API we have a graph processing API                                 called jelly for static graphs and                                 iterative algorithms and all of this so                                 what the jelly stream would be is an IP                                 I on top of the streaming API of link                                 for dynamic graphs single pass                                 algorithms using summaries and probably                                 giving you approximate computations so                                 sorry with that so yeah the de streaming                                 connected components that we saw before                                 in a distributed setting we could                                 implement it in the streaming API of                                 link very simply like this we have an                                 edge stream a stream of edges basically                                 first we just partition the edge stream                                 well here I just partition by the source                                 ID but you could partition in a smarter                                 way if you want to so we send different                                 edges to different partitions and then                                 we define every how much time do we need                                 the merge to happen with with that time                                 window in flink and then we need to                                 provide how to do the merge so when you                                 receive an edge and you have your local                                 summary how do you merge this adds to                                 your local some                                 basically what i showed before that if i                                 haven't seen the edge before you create                                 a new component or if it connects two                                 different ones you have to merge them so                                 this is what the UDF they would do and                                 then you need to define how would you                                 merge the local states into a global                                 state and actually with with the API we                                 have built you don't even need to do all                                 of this because first we have built                                 several algorithms that you can use                                 yourself just by calling the library                                 method so except from connected                                 components you can also do by partners                                 check some triangle count estimation or                                 window triangle count and some other                                 continues aggregates and we also have                                 more high-level abstractions so the at                                 this format of them algorithm that we                                 saw that you have local states and then                                 you merge them periodically we have seen                                 them in other algorithms as a pattern so                                 we offer an abstraction to build this                                 kind of algorithms more easily so if you                                 liked what I presented today you feel                                 free to check the repository this is not                                 part of hibachi fling it's as I said an                                 experimental API it's our vision to make                                 people stop thinking like vertices and                                 start thinking like I don't know in a                                 more modern streaming way I have also                                 collected a list of graph streaming                                 papers if you're interested in this area                                 and you want to see what has happened                                 and what algorithms you can implement in                                 this model and there is a related talk                                 that mean my colleague gave at force                                 them it's more it's an extensive                                 extended version of this one it has more                                 and more examples if you want to check                                 it out thank you very much                                 Thank You Axl do we have any questions                                 please haha any more questions no now                                 you have to ask something about graphs                                 alright just more like a suggestion so                                 yeah when the Hadoop started so this                                 batch processing there was always also a                                 lot of ideas in cloud air specifically                                 how to handle these graph problems in                                 the batch world and I think it like                                 there was also this page rank how you                                 could do paid rent in map reuse and so                                 probably could take something from their                                 experience in this area so yeah yeah                                 sure I mean this is the same thing right                                 I'm trying to use the technology we have                                 today to bring the problems I like up to                                 date and make use of the tools we have                                 exactly it's the same thing sure thank                                 you any more questions ok sure ok either                                 you didn't get anything or you got                                 everything oh no no more you yeah oh you                                 don't have a question um so I have yeah                                 yeah my tuition would tell me that if                                 you do strewing processing of graphs you                                 assume that the processing is a kind of                                 linear so you mean the complexity yes                                 yeah so what about the problems that are                                 would data theoretically pole polynomial                                 or exponential yes I would your                                 streaming mode sure it's not necessarily                                 linear processing and not all problems                                 are possible in this model of course the                                 idea here is more that you can change                                 the algorithm a bit or you can                                 approximate the result so for connected                                 components that was an easy example what                                 I showed and you get an exact result you                                 get the same result as we would get with                                 buds but other algorithms like Pedro                                 angkor distances and these kind of                                 things that would give you errors in the                                 end so you don't compute the exact same                                 thing as you would compute with batch                                 processing but sometimes it's good                                 enough right and and because you compute                                 on the summary so you don't have all the                                 information that you would have on the                                 on the big graph sure we have time to                                 take one more question awesome just                                 going to be there in a jiffy ok so you                                 were shy hi my question is do these                                 algorithms also work if you think about                                 removing edges or removing vertices from                                 the graph yeah that's a very good                                 question so exhibitions are easy most of                                 these the algorithms that have been                                 developed our about ed's additions but                                 there are also algorithms for edge                                 deletions where you usually have the                                 original graph somehow somewhere stored                                 and then you update the summary in real                                 time and then you just query the summary                                 but if this is what I meant by relaxing                                 the assumptions that used to exist                                 because now we don't have such limited                                 memory or these kind of boundaries that                                 we used to have then so you can do these                                 things more easily than you could back                                 then yeah but yeah there are more                                 complex the deletions for sure but also                                 they're more they're not so usual as the                                 additions usually yeah last chance no                                 that's cool ok you can always catch me                                 up later thank you thank you so much                                 you
YouTube URL: https://www.youtube.com/watch?v=0W-fB0-nGjE


