Title: Berlin Buzzwords 2016: Ira Cohen - Learning the learner: Using machine learning to track performance
Publication date: 2016-06-11
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Ira Cohen talking about "Learning the learner: Using machine learning to track performance of machine learning algorithms".

So you’ve created some machine learning algorithms and tested them out in the lab, and they seem to be working fine. But how can you monitor them in production, especially if they are constantly learning and updating, and you have many of them? This was the challenge we faced at Anodot and I’ll talk about the interesting way we solved it. 

At Anodot, we have approximately 30 different types of machine learning algorithms, each one with its own parameters and tuning capabilities, designed to provide real time anomaly detection. Many of these are online learning algorithms, which get updated with every new piece of data that arrives. Adding to the complexity, the outputs of some of the algorithms act as the inputs others. These algorithms run constantly on the vast number of signals that are sent to our SaaS cloud (currently more than 35 million signals are reported to Anodot every 1 to 5 minutes). We knew from day one that it was crucial to track the performance of these algorithms, so we would know if something happened that improved or degraded their performance, but we were faced with a challenge – how to accomplish this?  

Read more:
https://2016.berlinbuzzwords.de/session/learning-learner-using-machine-learning-track-performance-machine-learning-algorithms

About Ira Cohen:
https://2016.berlinbuzzwords.de/users/ira-cohen

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              what's she learning so I'm the chief                               data scientist for a small start-up                               called Ana dot we're based in Israel                               it's a startup that does anomaly                               detection I'll describe it a little bit                               in a few minutes and as a startup doing                               machine learning we reached quickly                               reached a point where we need to track                               what our algorithms are doing and I'll                                describe how we do it so a little bit                                about the machine learning how many                                people here have background in machine                                learning okay                                so quite a quite a bit so when I when I                                did my PhD image in uh in this area you                                know it used to be about publishing                                papers you take data set you get                                slightly better results and the previous                                guys on the data set in computer vision                                or text or whatever feel it was you                                publish your papers and I see him now                                and nibs you do some theoretical work it                                was very nice                                but we were this was the only people who                                knew what machine learning is but in the                                last few years as we all know there is                                the coming of age of machine learning                                and with many many applications that are                                actually working for large companies it                                started with with a lot of things around                                ads and recommendation systems in                                e-commerce and we're moving into                                autonomic cars that I have deep learning                                engines in them that are going to                                actually change the way our life                                completely so machine learning is coming                                of age and it's also you know sexy now                                to be a data scientist which is I would                                say a synonym for machine learning the                                sexiest job of the                                             according to the Harvard Business Review                                that's that's nice so it's nice to be in                                the field that that is being appreciated                                today but we still have a long way to go                                until until it actually reaches maturity                                so let me talk a little bit about the                                practical machine learning process you                                when you start you start with a problem                                you define it you define a business                                problem is either it's given to you or                                you have to go and figure out what is                                the problem that is the first step and                                decide that machine learning can                                actually help solve that problem the                                next step is to start collecting and                                preparing the data and that is a very                                difficult step but necessarily one if                                you want to try out any algorithms and                                then after you have your data you                                created your features you start training                                and testing your models and you iterate                                a lot of times over that you fail for a                                hundred times and then one hundred and                                first time you actually get some decent                                results you're happy you have good                                models you believe you've found the                                right algorithm that will solve that                                business problem now you deploy it to                                production another step which which is                                not that easy now that you deploy to                                production you have to start tracking                                and monitoring it because it's actually                                going to be in front of people it's                                going to do something continuously and                                you have to make sure it continues to do                                that so that's that's the the five steps                                of the machine learning process and if                                you look at the the world out there of                                of tools and companies that are building                                machine learning capabilities both                                internally and providing them either as                                an open-source or as as actually                                commercial offerings then you see they                                focus a lot first they focused a lot on                                collecting and preparing the data                                I mean Hadoop is basically a new                                platform for for collecting the data and                                then on top of it so many things that                                prepare the data and you have spark and                                you have to affect that which is a                                commercial company doing data data                                preparation and data refinement now you                                have a lot of companies coming out in                                the last year both in the open source                                world and in the non open source doing                                automation around training and testing                                the models so they would they're trying                                to democratize it so everybody can use                                these models without having deep                                 knowledge of the theory behind them                                 tensorflow AWS machine learning Azure                                 machine learning                                 companies like data and spark ml lid                                 which is an open source and of course                                 once you train and test the model you                                 need the mechanism that will actually                                 deploy it to production so a lot of                                 companies work around that and if you                                 look at the                                 scape and this is from March                                           an analysis of the landscape of machine                                 intelligence it's getting very very                                 crowded and busy I mean it's small but                                 for a reason                                 and actually since March there were at                                 least a few others that came into this                                 into this world that are not in this                                 slide so lots of tools platforms and                                 solutions but there's actually one area                                 the fifth step that you don't see a lot                                 of solutions you don't see it being                                 addressed by any of the either open                                 source or commercial solution I deployed                                 it I have my models in production what                                 happens now how do I track and monitor                                 them what do I do                                 so this is a slide I got from data which                                 is the company doing machine learning                                 platform and they put in their slides                                 well you deploy your models you evaluate                                 them now monitor and manage them but                                 what are the steps for doing that oh                                 they're pretty simple actually if you                                 think about it the first step you define                                 what are the performance metrics and                                 expected behaviors of your model if I                                 deployed a recommendation engine and I                                 tested it on a lot of training and test                                 data I can expect some performance out                                 of it when it goes into production and                                 then I can track it over time and see                                 whether that changed if I'm doing                                 classification of faces or                                 classifications of cats and dogs and                                 other objects I know more or less what                                 is my distribution of object recognition                                 that I should expect and if that changes                                 maybe my models go wrong                                 or if I'm building an atonal autonomic                                 car and I trained it on a lot of                                 different objects and to react to a lot                                 of different situations if there is a                                 new situation that comes up I would want                                 to track it with metrics detect it and                                 then refine the models if that is                                 necessary so but how do I do that how do                                 I actually track and monitor all these                                 different performance metrics for all                                 these models that I've trained and doing                                 it manually it's probably not an option                                 and why because it's hard there are many                                 models out there if I'm deploying a                                 Phenom II karzai I cannot do it manually                                 well I cannot wait to the data scientist                                 detects that there is an issue                                 that I didn't recognize the kangaroo in                                 Australia because I never trained my                                 models on detecting kangaroos and wait                                 for the cars to hit it before I actually                                 go and fix these models so it won't be                                 an option to do it manually so what is                                 this solution well there are a lot of                                 solutions I'm going to propose one today                                 and it's one that is kind of biased                                 towards what our company is doing which                                 is anomaly detection so so forgive me if                                 it's a little bit biased towards that                                 but it is a solution that works and it's                                 not only me that that is proposing this                                 solution out there so a little bit about                                 an adult an adult an adult platform is                                 not meant for tracking machine learning                                 algorithms it's really it's a business                                 incident detection platform we take time                                 series signals from many different                                 sources for many different domains                                 either telcos IOT web services ecommerce                                 sites industrial IOT and the platform                                 provides a lot of analytics capability                                 and machine learning capabilities one of                                 them or the major one in there is                                 anomaly detection and the reason we                                 provide that is to detect business                                 incidents automatically without the need                                 of dashboards or manual configurations                                 of static threshold alerts and all the                                 normal things that people do in their                                 monitoring system so some examples of                                 business incidents for example this is a                                 drop in number of visitors for one of                                 our customers and you can see that                                 they're the drop is somewhere in the                                 middle of the towards the end of the day                                 but not on a weekend and the reason it's                                 an anomaly because there is a change in                                 the temporal pattern that is very easy                                 for our eyes to see not necessarily very                                 easy for algorithms to track and detect                                 this is decrease in ad conversion on                                 Android for an for an antic company or                                 my favorite one a price glitch in an                                 e-commerce site where they posted a gift                                 card worth $                                                        Facebook people got the word started                                 buying really quickly at that low price                                 who wouldn't buy and this happens to                                 Airlines a lot and two other ecommerce                                 sites and then they see an increase in                                 the number of                                 purchases of grief gift cards which is                                 great but then the revenue does not                                 increase and the revenue is the graph                                 below does not really increase as                                 expected so that anomaly is actually a                                 price represents a price glitch if you                                 don't detect it really quickly you're                                 going to lose a lot of money so this is                                 why we built an add-on not for tracking                                 machine learning but then on the road on                                 the way at the data scientists it's very                                 easy to understand why the same                                 technology can be applied for another                                 domain so anomaly detection really helps                                 to detect the unknowns and this saves                                 time and money to a lot of industries                                 from web services IOT and security and                                 as I mentioned it helps to also track                                 machine learning algorithms and close                                 the loop by detecting unknowns that you                                 didn't think about when you created your                                 models so you created a classifiers for                                 detecting                                                             twenty thousand and one object came                                 along you wanted to be able to detect                                 that that happened                                 so you can refine your models and                                 improve them either automatically or                                 manually better at least know about it                                 otherwise your models and production are                                 going to perform very poorly or if you                                 introduced a bug like this this is a                                 graph of classification accuracy of an                                 algorithm and you introduced a bug at                                 some point in time because you deployed                                 tuning algorithm and all of a sudden                                 your clock your accuracy drops you want                                 to be able to detect that as quickly as                                 possible so you can fix it and this is                                 just like as I said coming of age of                                 machine learning it has to go out of the                                 lab into the real world and therefore it                                 has to be monitored and tracked and                                 fixed really quickly when it goes wrong                                 just like any other software so a little                                 bit about what is anomaly detection so                                 anomaly detection is it's an interesting                                 field in machine learning let me start                                 with an exercise and see if there is                                 somebody quick here that can detect the                                 anomaly in this picture right there are                                 always two people or three people that                                 detect it really quickly it took me five                                 minutes so don't feel bad so this is                                 this is the anomaly here this penguin                                 and the reason is if you                                 haven't figured out and the eyes are                                 pointed down so we were very good at                                 detecting visual anomalies but this was                                 this was a simple a simple case that                                 were the anomaly is clear usually it's                                 in really an ill-posed problem what is                                 an anomaly anomaly is almost subjective                                 so here are six pictures and and you can                                 probably based on some definitions say                                 that each one of them is an anomaly in                                 some sense right there is only one male                                 one black-and-white picture only one                                 black woman only one an unknown sex                                 woman so every one of these is an                                 anomaly in some sense and it's okay so                                 it's a defined problem but still we use                                 it we use it because we define some sort                                 of definition of what is normal and                                 based on that we can say what is                                 abnormal so I'm going to I mean we're                                 mainly talking about anomaly detection                                 not in images but rather in time series                                 signal because we're tracking                                 performance of things with metrics so                                 metrics you can you can plot over time                                 and really an anomaly detection in time                                 series signal is an an unexpected change                                 in something parallel pattern for one or                                 more combinations of Time series signals                                 and these are real anomalies for various                                 type of businesses and you can see                                 sometimes you have multiple series that                                 are abnormal you have temporal patterns                                 that are seasonal and you have trends                                 that change over time and this happens                                 and these are now these are anomalies by                                 their models definition so a little bit                                 about anomaly detection methods so we're                                 on the same page so the general scheme                                 of anomaly detection at least for time                                 series and again I keep mentioning it's                                 for time series is you you have your                                 graph and the bold blue line is the                                 actual graph and what you try to create                                 is a model of what is the normal                                 behavior of that graph or combination of                                 graphs using a statistical model that is                                 basically that choice of statistical                                 model defines what is normal once you                                 have that                                 devised a statistical test to determine                                 if any of the samples are within that                                 are explained by the model and visually                                 it's that that is the statistical test                                 is shown here using that bandit light                                 blue land band around the graph itself                                 so any sample that is that is not                                 explained by the model in this case goes                                 outside the normal range is an anomaly                                 and that's how you flag it as an anomaly                                 and it normally can be bad and it                                 normally can be good we make no I mean                                 the context of an anomaly is really in                                 the domain that you're applying it to                                 but an anomaly is a change of the                                 deviate a strong deviation from the                                 normal pattern so there are two main                                 types of anomaly detection methods one                                 is online anomaly detection algorithms                                 these are the most commonly used at                                 least for time series signals when                                 you're applying them for in real-time                                 and in them you actually initialize the                                 model with some samples small sample set                                 and for each new sample you test whether                                 it's an anomaly or not and then you                                 update your model so these models                                 continues to get updated and and these                                 are the types of models we use it and a                                 dot because if you want to scale out and                                 B be correct for millions of these time                                 series signals then you have to be you                                 know you have to be adaptive and the                                 world changes all the time some example                                 algorithms for for people who are                                 interested you've got simple moving                                 averages exponential forgetting colt                                 winter's algorithm which is double                                 triple exponential Kalman filters a lot                                 of these are taken from the statistics                                 and signal processing world and not                                 surprisingly so because a single                                 processing deals with time-series                                 signals by the lot the other set of                                 algorithms are batch anomaly detection                                 algorithm they're more there they're                                 better for things that are more static                                 that don't change or you don't need to                                 run them in real-time and you don't need                                 to get anomalies in real-time and also                                 you can afford very large batch jobs of                                 learning in those cases the scheme is                                 you collect historical samples                                 you segment the samples to kind of                                 similar to behaving segments clustering                                 algorithms typically are what are being                                 used and then you cluster them to these                                 segments using some similarity measure                                 and that similar similarity measure is                                 what defines normalcy in a sense and                                 then you mark anomalies any segments or                                 any samples that are out that are not                                 very close to any large cluster so                                 though that those are the anomalies some                                 sample algorithms for that PCA one-sided                                 support vector machines multimodal                                 distributions hidden Markov models that                                 are used a lot in speech but also as                                 anomaly detectors some of the most                                 commercial common ones are variations of                                 k-means DB scan meaning shift algorithms                                 and again you use the clustering you                                 find the clusters and then you find the                                 outliers that are outside of these                                 clusters so I've talked about some of                                 these algorithms now let's switch to how                                 the topic of today how do we use anomaly                                 detection to track machine learning                                 algorithms so I'm going to talk about                                 Anna duck as a use case but you can                                 think about it it's something you can                                 use for any other system that has                                 machine learning so our system in                                 general has five steps to detect                                 anomalies in the first step we collect                                 all these time series signals in real                                 time and then we learn continuously the                                 normal behavior models and here actually                                 are hidden about twelve different                                 algorithms plus a classification                                 algorithm because we we have to like I                                 said not the choice of model that you                                 have will define what is normal and                                 there are so many types of different                                 signals not all of them are very not all                                 them are the same so you have to                                 classify it first to what is what what                                 normal distribution fits it best and                                 then apply that so we have a bunch of                                 algorithms there we have a second level                                 learning that learns to differentiate                                 between anomaly patterns so that's                                 another set of algorithmic models the                                 fourth step we actually learn the                                 relationships between it                                 all these different signals and that                                 that is a set of different clustering                                 algorithms that we use internally and at                                 the end we do semi-supervised learning                                 by taking feedback from our users both                                 implicit and explicit and improving the                                 the models based on that so we have a                                 chain of a bunch of different algorithms                                 just to give you some statistics and the                                 architecture of what we have so you can                                 gaze at the architecture but I'll give                                 you the statistics so we process today                                 over three billion samples a day about                                                                                                          this is from all our customers each one                                 of these metrics has it at least two                                 models one for the normal distribution                                 one for the abnormal sometimes it has                                 three if it's in transition between the                                 models these models get updated with                                 every sample that comes in we have about                                                                                                          updated daily so we run the correlation                                 algorithms every day seven million                                 models that take into account different                                 seasonal patterns that get updated every                                 day                                                                      classification to seasonality detection                                 trend based signing and they all have to                                 interact to produce the result to our                                 customers which is find anomalies on                                 their side so there is a chain of                                 algorithms and we have to monitor all of                                 them it's not just one algorithm that we                                 keep track of its performance we have to                                 track all of them and make sure they                                 work in concert to produce the right                                 result that's that's not not very simple                                 and the architecture is complex I mean                                 we use a lot of open sources if                                 anybody's interested afterwards I can I                                 can describe it in more detail so how do                                 we track the performance of our                                 algorithms we track them with metrics as                                 I mentioned and we have and this is an                                 example of an anomaly we had recently                                 where we deployed something wrong in                                 some of the algorithms and it affected                                 all of them so we had an increase in the                                 nut in the distribution a change in the                                 distribution of seasons detected for all                                 the metrics we had a lot of model                                 switching that happened                                 identity between different models that                                 we have so our classifier wasn't working                                 well our anomaly quality scores also                                 changed and you can see it in the drop                                 there so basically this anomaly was a                                 result of a deployment and of course I                                 could graph them in dashboards and track                                 them manually but I don't want to do                                 that because I have an anomaly detection                                 system so why not let it do the job so                                 of course we set up our means to get a                                 lot of anomaly alert these are some                                 additional examples so this is this is                                 an alert we got and this is an email                                 alert for my for my inbox showing that                                 there is an abnormal increase in the                                 number of high score anomalies and high                                 score are normally metrics and when we                                 get and and when I see this you know I                                 don't know these numbers I couldn't even                                 think about how to set a static                                 threshold for that but I when I see this                                 jump of an increase I know there must be                                 something wrong either customers really                                 sent us different data that caused this                                 or something went wrong with the                                 algorithm and in this case we actually                                 realize what that we need a new type of                                 model and we developed a new type of                                 model so it will take into account this                                 new behavior that one of the customers                                 actually sent to us another example this                                 is a normally with multiple metrics                                 these metrics represent the distribution                                 of seasonality detection algorithms in                                 our system actually this was a good                                 anomaly you can see it more or less May                                                                                                        improvement or sin anomaly detection                                 algorithm and it actually we saw the                                 distribution changed as we expected to                                 provide better results in seasonality                                 detection so we expected this anomaly                                 and when we got it we were very happy                                 but the point is we didn't have to                                 actually track it with any dashboard we                                 could just look at our wait for wait for                                 the email alert and know that it                                 happened so to summarize anomaly                                 detection this fifth step is really a                                 mean to start closing the loop of the                                 machine learning                                 so to track and monitor anomaly                                 detection can help you it's not the                                 final step it's the first step the first                                 step is to really take these anomalies                                 and actually help the machines improve                                 themselves automatically which is                                 probably something you would need when                                 you have mission-critical applications                                 where you don't have the luxury of                                 getting alerts about anomalies and                                 fixing them kind of in the lab so for                                 example autonomic cars would probably                                 require an additional step after                                 anomalies to actually start fixing and                                 identifying new objects so with that I                                 will conclude thank you I'll take any                                 questions thank you very much we have                                 plenty of time for questions we have                                    minutes I think so please fire far away                                 so you all get coffee                                 and there was a step in one of your                                 slides called something like behavioral                                 topology learning which you lost over                                 quite quickly oh yeah can you talk a                                 little bit more about what that involves                                 sure so yeah I didn't want to use this                                 talk as a self-promotion complete                                 self-promotion to to our algorithms so                                 so what do we do here our approach has                                 been Bottoms Up approach to doing                                 anomaly detection so we will first take                                 each signal and learn that by itself do                                 the abnormal learning and then try to                                 combine the anomalous metrics by knowing                                 who is related to whom so here we                                 actually use three types of algorithms                                 one is looking at their the correlations                                 in normal time here we're using a                                 variation of neural network deep                                 learning algorithms so it's not linear                                 correlations but basically using stacked                                 autoencoders you can take in the signals                                 the output is a bunch of alphabet and on                                 that you do actually similarity between                                 pairs of metrics so that's that's one                                 algorithm another algorithm is looking                                 at their correlations when they are                                 abnormal so whenever there are anomalous                                 metrics so let's say I'm measuring an                                 entire system when something goes wrong                                 there are a lot of different signals                                 that go wrong at the same time and they                                 become anomalous                                 so by looking at their looking whether                                 they're correlated they cluster together                                 during these abnormal times rather than                                 their behavior during normal time                                 actually gives us a very strong hint of                                 whether they're related or not so that                                 that actually is one of the strongest                                 hints that we have today it's even                                 stronger than than the normal patterns                                 so a lot of times they look completely                                 different during normal times if you                                 look at memory and CPU for example even                                 for the same machine it might look                                 completely different but if something                                 goes wrong with the machine they will be                                 anomalous regardless that's an analogy                                 and the third one is using metadata that                                 we get from this                                 themselves usually the signals are not                                 just sent as numbers but with some                                 metadata around them and then we do                                 clustering around that to know whether                                 they're related or not so at the end we                                 get this large graph with a lot of links                                 between the metrics and that provides an                                 input to our anomaly detection system                                 yes um you showed would look like an                                 email that you received once an anomaly                                 was detected and it seems like this                                 provides at the bottom there a way to                                 give feedback on false positives how do                                 you handle the detection of false                                 negatives for quality control purposes                                 alright so we haven't figured that out                                 yet                                 I mean we get them but we get them                                 directly from the customer that says oh                                 there was something and you didn't catch                                 it that doesn't happen a lot because                                 often they don't I mean even if we                                 didn't catch it they don't know because                                 they didn't know before                                 and and they're more sensitive to false                                 positives then to false negatives unless                                 it's a really critical issue that we                                 missed so that happens less so in those                                 cases we actually go and do deep                                 investigations ourselves and try to                                 figure out you know why why our models                                 didn't pick it up and sometimes we have                                 to change the models so we haven't found                                 a way to automate the false negatives                                 this is really for the false positives                                 and various types of false positives and                                 also reinforces the good the true                                 positives which is also important                                 my question is very raised previous one                                 how do you integrate the user feedback                                 back to your models right so the way we                                 take the user feedback today so we have                                 this notion of abnormal behavior                                 learning which I glossed over really                                 quickly as well so that that part is                                 actually builds a model or that ranks                                 different anomalies and gives them a                                 probability score based on how they look                                 compared to all other patterns of                                 anomalies that we've saw before and when                                 when we get the user feedback we                                 actually actually start changing those                                 scores so if and this is the way we do                                 it we do it today we have ideas of how                                 we can integrate into other parts of the                                 system this is the first point we tackle                                 because it seemed to be the most                                 relevant so if a user says this is not                                 interesting it means this anomaly                                 pattern is not interesting for a set of                                 metrics that are related to each other                                 and we start reducing this score instead                                 of say instead of mathematics so not                                 interesting could be well because let me                                 give you an example if the number of                                 visitors jumped from                                                    usually                                                                  and jump to                                                            interesting mathematically speaking this                                 looks like a very very big anomaly                                 because it went from                                                                                                                           they say well but this is in babbling                                 and you know                                                       nothing compared to another country like                                 the UK or Germany were usually I have a                                                                                                          anomaly so it's not that mathematically                                 it's wrong it's really it's a false                                 positive contextually rather than then                                 mathematically and then that score lets                                 us actually give it a lower weight so                                 next time he might not get it compared                                 to other anomalies and and the same for                                 whether something is interesting or not                                 something is interesting so maybe if the                                 number of visitors                                 jumped from                                                             might be very interesting anomaly for                                 that person not because mathematically                                 it's more interesting than others                                 because contextually and from business                                 side it is more interesting we have time                                 for more questions so if anybody's                                 interested in more details about the                                 anomaly detection part I'll be happy to                                 provide it provide it later                                 anything about our architecture or                                 algorithms I'll be wrong uh we do have                                 one more question so you use neural                                 networks and what type of learning                                 algorithms you're using your neural                                 networks we're using stacked autoencoder                                 so these are not supervised algorithms                                 um what else that's it that's it okay so                                 no type of genetic algorithms or                                 something like no and not for this                                 component we don't use genetic                                 algorithms anywhere right now in our and                                 how do you handle the the question of                                 topology of your your own networks brute                                 force we have enough data so we just the                                 heck out of it well if we don't have any                                 more questions let's thank our speaker                                 zero once again                                 and you have just got yourself five                                 minutes extra pause in the sunshine here
YouTube URL: https://www.youtube.com/watch?v=z2ITun71E-k


