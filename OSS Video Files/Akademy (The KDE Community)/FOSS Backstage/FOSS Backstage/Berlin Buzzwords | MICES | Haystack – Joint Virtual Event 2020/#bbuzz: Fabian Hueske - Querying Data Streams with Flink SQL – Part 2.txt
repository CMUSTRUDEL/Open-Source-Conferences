Title: #bbuzz: Fabian Hueske - Querying Data Streams with Flink SQL – Part 2
Publication date: 2020-09-10
Playlist: Berlin Buzzwords | MICES | Haystack – Joint Virtual Event 2020
Description: 
	More: https://berlinbuzzwords.de/session/qu...

Apache Flink supports SQL as a unified API for stream and batch processing. SQL is easier to use than Flink’s lower-level APIs and covers a wide variety of use cases. In this hands-on tutorial you will learn how to run SQL queries on data streams with Apache Flink. We will look at the concepts behind continuous queries and dynamic tables and will show you how to solve different use cases with streaming SQL, including enriching and joining streaming data, computing windowed aggregations, and maintaining materialized views in external storage systems.

Prerequisites:
 - No prior knowledge of Apache Flink is required. We assume basic knowledge of SQL
 - You will need a computer with at least 8 GB RAM and Docker installed. To save time during the event, we would also like to ask you to set up the tutorial environment beforehand by following the instructions at https://github.com/ververica/sql-trai...
Captions: 
	                              okay                               let's start                               so far we've talked about apache flank                               um                               or fling sql without not really going                               into                               the topic of time however time is a                               is usually a very important uh important                               aspect of                                stream processing so there's like lots                                of                                lots of different situations when you                                want to work with time in stream                                processing um                                some examples are here if you'd like to                                aggregate data                                based on time something like compute an                                average                                of the last one minute or                                count how many orders we receive where                                uh received within the last hour                                um also enriching streaming data with uh                                data from other sources                                like uh join my screen with the most                                recent                                exchange rate is quite common                                or even if you want to do some kind of                                pattern matching or                                rule evaluation uh for instance                                emit an alert if there were three                                answers of                                unsuccessful attempts uh to lock into my                                service or                                whatever within the last five minutes so                                all of these examples have some                                some temporal component right um                                you uh always kind of like want to bound                                um some kind of evaluation or                                computer computation um in                                within some some time range                                and for many of these use cases uh                                common types of data                                is user interactions when you want to uh                                analyze for instance click data                                from websites or mobile apps log data                                coming from applications machines                                transactions or                                some kind of sensor and                                when you want to do that on                                dynamic tables there's a there's a few                                characteristics that these queries                                typically have                                so first of all the input tables are                                typically                                append only so you basically get a                                stream of                                all events and uh none of the rows                                in your and the table that you write                                your queries on                                are uh ever updated                                um the schema of such a table or defines                                some kind of time event so uh yesterday                                we've seen                                uh when we talked about this uh ddl                                subjects of the battery flank                                we've seen this small watermark clause                                that defines the event time property                                offer of a table and you basically need                                such a such a time attribute in your                                table to in order to be able to                                write queries that work with time                                a query that works with um with time                                usually consists of uh like i call it                                row at the time operators                                uh something like a simple filter or                                projection basically an operator that                                can can be evaluated by looking at a                                single row                                um and so called temporal operators                                uh such as window aggregations                                um joints that work based on time                                or pedal matching that is applied based                                on some                                uh tempura or within a temporal or                                timeout                                so all of these operators are like like                                if you look at what                                uh people usually build when they work                                with uh flinx data stream                                api or some other stream process api                                these are kind of like the traditional                                stream processing operators operations                                uh window allegations                                of joints and so on                                and then when you basically apply                                subject query                                on such an append only table                                then the output table is also an append                                only table                                 which means that it only emits rows                                 and every row that is submitted will                                 never be updated                                 so let's first have a look at how you                                 can define                                 time attributes in a page of link                                 so how is this uh really done                                 so and if if you're like a bit familiar                                 with how                                 apache flink works or flint's status                                 from api works                                 um influence data stream api um when                                 you're using                                 there's two different modes of time                                 there's event time and processing time                                 um event time is defined                                 by uh basically each record is being                                 processed                                 based on a timestamp timestamp that is                                 uh part of the data so the record itself                                 tells the system hey                                 my record is                                 or this event happened at this point in                                 time                                 so you can process the data really based                                 on                                 some some actual data this is uh this is                                 called event time and processing time is                                 a mode where data is being processed                                 based on the time                                 of the machine um when the record is                                 processed so                                 you can think of it having a stream of                                 data and then                                 an event enters the stream processing                                 application                                 and if you then want to group data on                                 time um                                 based for instance uh grouping data on                                                                                                 processes the data will say okay                                 what time is it now it's let's say                                    o'clock                                 and then if you group by                                                 after                                            based on the machine time of the                                 processing machine                                 it will close the window perform the                                 computation um                                 so there's these different types of time                                 in a patch of link event                                 and processing time and both can be                                 handled with a                                 fling seeker                                 in order to to to give access to time                                 and                                 query a timestamp needs to be needs to                                 be part of the table schema                                 and um these timestamps are of the                                 regular zebra typestream type so they're                                 pretty much just uh um it's a                                 it's a sub tab or extends the secret                                 timestamp type                                 but they behave exactly like like                                 you can do with these timestamps                                 whatever you can also do with a secret                                 timestamp                                 and as we seen before these time                                 attributes are declared the table schema                                 so how does it look for for event time                                 so                                 for event time you basically have to                                 define                                 a time stamp as part of the table                                 schema here we call it click time and                                 it's of type timestamp                                 three and this is an actual uh                                 a field that is provided by the that is                                 really                                 part of the data so the um                                 if this is a table backed by for                                 instance by patrick kafka                                 with the jason uh format then the uh                                 js records that we read from apache                                 kafka                                 should have these this c time                                 attribute with an extra timestamp so                                 it's                                 it's actual data that is provided by the                                 data                                 and in addition to this timestamp field                                 we need to define some kind of watermark                                 a watermark                                 watermarks are in flink meta records                                 that are generated based on the                                 timestamps that are being observed so                                 you see                                 here that we define a watermark for this                                 event time attribute c time                                 and we define it as c time minus                                 two minutes so what this basically means                                 is                                 that the uh watermark that the system                                 sees                                 um is always um                                 the uh highest                                 uh c term attribute that was seen by the                                 system uh                                 minus two minutes so um if the c time                                 attribute                                 um uh is uh is sustaining in time                                 um then also the watermark well                                 well about the same but it's always two                                 minutes behind the maximum time                                 and we do this uh we basically subtract                                 these                                 two minutes uh in order to be able to                                 account for                                 records that arrive out of order so                                 flink                                 is a distributed system and most of the                                 uh most of the systems                                 that we reach data from are also                                 distributed systems                                 so it's really hard to guarantee order                                 in these                                 in these systems also                                 also there is the the case that even the                                 data that is written to apache kafka                                 might already be out of order                                 so it's really rare that you can work                                 with data                                 that has a really exact time water                                 so the watermark here is a mechanism to                                 basically to                                 to account for this out of hardness or                                 in this case                                 in this definition here we basically                                 give                                 the c time attribute like a                                 two two minute margin to be out of order                                 and um the operators                                 that flink uses internally these                                 time-based operators for window                                 aggregations and so on                                 they basically look at the watermark                                 records that are being generated                                 automatically generated                                 and based on the watermark they                                 determine what's                                 what the current time is and based on                                 this time they perform their there                                 the computation and also reason about                                 data completeness                                 so for instance when there is a                                 computation that should be performed at                                                                            then                                 [Music]                                 an operator will wait for the water for                                 a watermark that is                                 at least um what did they say                                 and there is a computation that should                                 be performed at                                                    operator will wait for a watermark that                                 is at least                                                                                                    hasn't reached                                                                                                       perform the computation but once the                                 watermark                                 [Music]                                 is at                                                             knows basically that it has seen all the                                 data                                 up to                                                                  computation                                 so depending on how you how you choose                                 this                                 this interval here um                                 this this margin um                                 [Music]                                 you can basically tune um                                 tune the completeness versus the latency                                 of your results                                 if you uh um subtract like a large                                 interval                                 from the from the click animate group                                 let's say you subtract                                 one hour then a computation will kind of                                 be                                 performed um one hour                                 after the highest                                 the click time with the highest                                 attribute was                                 highest value was here so you get the                                 result probably much later                                 but since you have very very large                                 margin to wait for late data                                 you can also be sure that the result is                                 is quite complete if you make sure to                                 make the margin very small                                 like let's say only five seconds                                 then you get um                                 the result uh very soon after the                                 after the click time attribute pass the                                 uh pass the computation boundary                                 but it might be that some of the data                                 the data that was laid is not really                                 part of the computation                                 um for processing time the                                 attribute is defined a little bit                                 differently                                 so here basically a processing time                                 attribute is                                 virtual it doesn't hold any data so um                                 instead when the query accesses this                                 attribute                                 it basically looks up the current                                 local time of the of the machine that is                                 processing this attribute that is                                 performing this uh                                 evaluation of the attribute so in this                                 case                                 if there is if we would have this clicks                                 table                                 defined based on a kafka topic then                                 the the records                                 that we ingest from kafka would not have                                 the click time attribute                                 but it would just be added as a kind of                                 virtual attribute                                 that is basically um                                 evaluated whenever it has been accessed                                 at the same time you can also use the                                 skilltime attribute just as a regular                                 timestamp but whenever you access it                                 basically it                                 will just carry the local time of the                                 machine                                 and there and hence it's not necessarily                                 a                                 deterministic value that you get back                                 so basically once you define these time                                 attributes you can                                 use them kind of like interchangeably so                                 later on it doesn't really matter                                 whether a time                                 time attribute is an event time                                 attribute or processing type attribute                                 whatever you can do with an event                                 attribute you can also do with the                                 processing time attribute                                 however of course the semantics of                                 uh are a bit different whereas in event                                 time you use the actual time and actual                                 timestamp                                 that is coming with the data and hence                                 is very then like                                 precise and exact if you define the                                 time attribute as a processing time                                 attribute then it's                                 not not really deterministic                                 what you get because it's really based                                 on the                                 on the time when the record is being                                 processed                                 okay um let's um talk about                                 temple operators basically operators                                 that work on time so                                 what all of these operators kind of have                                 in common is that they                                 process records by or associating                                 different records based on some                                 temporary condition                                 so for instance you can do a group by                                 window aggregation which is                                 grouping data based on a                                 time window you collect all records                                 that are fall in the same in the same                                 time window for instance if you compute                                 hourly windows                                 then a group by                                 group by within hourly window will                                 aggregate all records                                 that are have a have a                                 event have a timestamp from                                         or those fall into a group or records                                 that are from                                 one to two fall into another group from                                 two to three the next group and so on                                 so basically this is a group by window                                 application                                 over window aggregation uses the uh                                 sql over uh over clause i will have a                                 look about that                                 uh how he has a bit later                                 in this case um the data needs to be                                 or the the over clause needs to uh needs                                 to be defined                                 such that the data is ordered on time                                 there's a                                 time would not join which joins                                 two streams based on a condition where                                 one record is not                                 not further apart than a certain time                                 boundary in the other stream                                 there is a join uh with a so-called                                 temporal table                                 which is a joint that looks up if                                 you have a stream of records and for                                 every record                                 you do a lookup into another table uh                                 based on the                                 uh based on the timestamp of the of the                                 record and you want to get the most                                 recent                                 version of the other table the table                                 stretching over time                                 you can get the most recent version that                                 was uh                                 valid uh for for for the time of this                                 record which has been uh produced                                 and also the pattern matching is also                                 follows temporal conditions                                 um what these operators basically do                                 they track                                 the progress in time to decide when                                 input is complete                                 so if your attribute is an event time                                 attribute                                 then the operators track time by                                 looking at the event time at the                                 watermarks                                 so um when you have an event time                                 operation and you want to perform a                                 computation at                                                                                                      that when the uh                                 when a watermark is received that is uh                                 past                                                      doing a computation based on processing                                 time                                 that should happen at                                                 the operator will basically look at its                                 uh                                 local clock and when the once the clock                                 is past                                            um then the couple tags will be will be                                 performed                                 um since the operators can really                                 track the progress and make a decision                                 when the input is complete                                 they can emit                                 final result rows so results that                                 never have to be updated again this is a                                 very nice property because                                 dealing with updates in your downstream                                 tasks or systems is always always a                                 hassle if you                                 have a have a way to determine that the                                 computation is complete                                 uh based on time that's a that's a very                                 uh                                 convenient feature but it's not only                                 it's not only the                                 a nice property that you can                                 emit final results the other property is                                 that these operators can also                                 automatically clean up their state                                 because once they produce the final                                 result a result that they never need to                                 update again                                 they can also remove all the state that                                 was associated                                 with this result or that was needed to                                 compute this result as soon as the                                 operator knows that some                                 some state is not being not never being                                 used again                                 it can automatically clean up the state                                 and hence you don't have this                                 uh situation where uh state accumulates                                 over a larger time uh                                 uh over uh the over the time that the                                 cure is running                                 but instead when you have uh can you                                 define your computation in a way                                 that um the query                                 defines a temporary balance of the                                 operators then                                 the the operators that process the data                                 know when they can remove the state                                 and hence the query can pretty much run                                 forever                                 in order to make this work uh the temp                                 operators                                 kind of need to uh need a reference to                                 the time attribute                                 that we specified in the uh in the table                                 uh                                 in the ddr clause so all of these                                 temporary operators                                 uh somewhere in there uh                                 when you define the query you need to                                 reference the time attribute and this                                 uh works just with a regular sql center                                 example                                 i'll see some examples how this works                                 based on                                 temporary aggregation so                                 link supports two different types of                                 temporal applications                                 i've talked about this before these are                                 the group by window aggregation and the                                 other window aggregations                                 and uh we'll talk about both of these                                 different types of aggregations                                 now and just use this very simple                                 example table                                 and we assume that c time here is an                                 event time attribute although as i said                                 it doesn't really matter it could also                                 be a processing dimension                                 okay so let's say we want to compute                                 the number of clicks per hour and user                                 then this basically would translate to a                                 group a                                 or to a query that uses a group by                                 window education like this                                 we have a query that just reads                                 from clips um then we have a group by                                 clause                                 we put the user into the group by clause                                 because                                 we want to compute the clicks per user                                 but also per hour                                 so and therefore we add this function                                 call here called                                 tumble tumble is a function that                                 you can think of it as a function that                                 generates a                                 window id and we provide here the click                                 time attribute this is the time                                 attribute                                 and we end a time interval of                                 one of one hour                                 and                                 this will now uh basically perform                                 uh uh all the the data will be grouped                                 into uh into indicated groups based on                                 a user and for every user in in the                                 window                                 of one hour so we have a have a                                 group for                                 the time from                                                         from two to three and so on                                 and the windows by default are kind of                                 like aligned to                                 um are aligned                                 to uh the the epoch time which is                                 like the um first of january                                 uh or uh midnight at uh                                 of first of january uh                                                like the unix timestamp zero                                 so um so we group the data here                                 and then the select clause we just say                                 uh we want to have the user we want to                                 have account                                 and there is this function tumble end                                 which                                 returns the timestamp and timestamp                                 of the of the window so for the window                                 from twelve to one                                 uh tumble and function would return one                                 o'clock for the window from                                 one to two with return two and so on                                 there's also a template start function                                 that                                 returns the the start of the                                 start time of the window and you see                                 here we have uh we referenced the click                                 time attribute                                 twice um in the tumble function                                 here and here um and                                 when you define the query you actually                                 need to specify the                                 this party exactly the same in the                                 select clause as in the in the grouper                                 clause otherwise                                 you will get an error so how                                 would this query be be executed now so                                 let's say we have this clicks table here                                 and the query is                                 already running uh we get some data                                 um the data would be uh basically                                 grouped by the hour                                 and uh for the for the first hour it                                 would produce some some some result                                 for the next hour we will also get some                                 result uh and for the                                 uh uh third hour then                                 then again and as you can see the query                                 always appends the result uh the                                 result rows to the to the table whenever                                 um the computation can be uh can be                                 performed                                 and you see here we have the timestamps                                 here that kind of fallen through the                                 window range from                                                   o'clock                                 and the tumble end function here                                 returns the end timestamp of the window                                 here of one o'clock                                 there is not only the tumble function to                                 that you can use to group data on uh                                 there is also two other functions so                                 tumblr basically looks like this if you                                 have a                                 tumblr function of t here is the time                                 attribute of interval two hours                                 it will have uh non overlapping                                 or slice the slice time to                                 non overlapping windows of two hours                                 if you use the so-called hop window                                 you uh specify two intervals                                 one interval the first interval is the                                 size of the window                                 and the second interval is the                                 um step size in which the windows are                                 shifted                                 so if for instance here if we have a                                 window set of two hours and a                                 step size of one hour then every hour a                                 new window is being started                                 which then lasts for two hours this also                                 means that                                 all records are always being assigned to                                 two windows                                 so since this window is overlapping so                                 this record is part of                                 part of this window but also part of                                 this window                                 and so on and that's basically how we                                 can have overlapping windows                                 and this can be used for some kind of                                 like uh                                 sliding uh sliding smoothing for                                 instance                                 um and then there is also the session                                 window                                 sorry there's a question in the chat                                 oh okay thanks for                                 [Music]                                 um                                 so um the                                 yeah so the this is a good question                                 so there is basically um                                 so the question i suppose you can                                 see the question but the question is if                                 the window is from                                       from                                                      the record from                                            also be in the earlier window so in fact                                 i was a little bit imprecise so the end                                 range is exclusive so everything                                 if you have the in the tumble function                                 so a window from                                                                                                        hour                                 i would start at                                                      close just                                 before one o'clock so                                                                                                               window                                 but uh                                                         so it's uh the end timestamp here is                                 basically the                                 um not not part                                 a record with uh that had a timestamp of                                 of one o'clock would not be part of this                                 window but be part of the next window                                 there is not only the                                 tumble start and tumble and function                                 there is also the super                                 tumbler road time function                                 and this function uh returns the valid                                 uh event developed times                                 time attribute again so another an                                 attribute on which you can                                 do uh next                                 follow-up time operations and uh                                 this is exactly uh the end of the                                 of the window so for instance                                 maybe i guess that was a little bit                                 confusing um so if we                                 have a tumblr window of i'm just                                 chatting write writing something in the                                 chat now                                 if i have this window then                                 [Music]                                 tap it start for the window from                                 uh twelve to one time start would be                                 let's return this number uh                                 and would return                                 this and tumblr                                 road time would return                                 um this and tumble road time is                                 uh tumble start and tumble and are just                                 regular timestamps                                 they can cannot be used for further time                                 operations                                 the reason for that is that they're not                                 really in line with the with the                                 watermarks generated by the system                                 anymore                                 whereas tumbler road time is still                                 aligned with the uh with the watermarks                                 that the query uh                                 processes and therefore you could                                 perform for instance                                 another group by operation based on                                 uh based on the attribute that you get                                 from tumblr rota                                 okay um                                 so in addition to the temple and top                                 windows there's also the uh                                 session window where you again provide a                                 time attribute                                 and then an interval but this interval                                 is does not specify the size of the                                 window                                 but rather it specifies the size of a                                 gap                                 so basically the data is then                                 grouped based on gaps of inactivity                                 inactivity here                                 means not seeing a record within this                                 time range                                 so if we have a session window of                                    minutes defined                                 we would get here for this data here one                                 session uh with these five records                                 then we would have a gap that is larger                                 than                                            hence after                                                             be closed                                 and then as soon as the next record is                                 received                                 the new window is a new                                 session windows started and data is                                 added as long as                                 there's no gap of                                                       minutes                                 and once we find a gap of these                                    minutes                                 this window is again close the                                 computation is performed and when the                                 next                                 record is received and you win is opened                                 um so these group by group by winning                                 allegations                                 like once one way how you can group data                                 based on                                 time the other one is this support over                                 window application                                 let me quickly check um                                 let's see                                 okay                                 no idea how this works um                                 anyway um do you know how the                                 i um                                 are you aware how uh sql over windows                                 work or should i uh                                 go into that a bit                                 i think it's not a okay yeah so it's a                                 rather it's i think it's been part of                                 the uh                                 sql standard for for quite some time but                                 it's not used very often                                 um however i think in the in the context                                 of streaming it's actually a very nice                                 nice way to a nice                                 nice feature you can work with streaming                                 data                                 so um so one example what you can do                                 with these over windows is                                 imagine we have this uh click clicks                                 table                                 uh which gets a new record                                 for every click that a user is doing so                                 let's say we want to compute for every                                 click that was done                                 how often this url was clicked uh                                 in the last in the previous two hours                                 so we kind of like need to perform                                 computation for every input row we're                                 not                                 uh reducing the data but we want based                                 on a on a                                 single row we want to look two hours                                 back in time and count                                 how often the uh the row was clicked and                                 for this                                 there is uh this secret syntax again                                 this is                                 standard sequence netflix it's nothing                                 that we invented                                 and here you can define a so-called                                 window                                 uh window and give it an alias                                 here we give it the alias a w and                                 then the window is defined                                 based on these three clauses the first                                 one is a                                 partition by clause here we partition                                 by url because we kind of want to                                 perform                                 or want to group perform a computation                                 and aggregation based on the url                                 so we want to know how often each                                 individual u                                 each url was was clicked so we                                 partitioned by url                                 uh we have to give an order by claw                                 order                                 condition here and we here in the order                                 by clause we put the                                 click time so here again this is the                                 the point where we have to tell tell the                                 system                                 here we want to perform this operation                                 based on                                 based on our time attribute that the                                 table provides                                 and then you can perform a range                                 that is basically that depends on how                                 the data is ordered                                 and the partition basically tells which                                 data is included into the                                 uh into this partition and                                 here we define the range as between                                 interval                                                                                                       so when you can when you when you think                                 of a of a row it will uh                                 perform a computation here and we                                 basically say we want to perform a                                 current application over this window                                 then when we when the system processes                                 a click coming from clicks it will                                 look what's the url for this click                                 it will look what are all the other urls                                 uh um                                 that i've uh how often was this url                                 clicked within the last two hours                                 um and the data                                 within these last two hours is ordered                                 by                                 by this uh whether by the time attribute                                 i have a                                 little example here let's uh let's hope                                 that this makes it                                 a bit clear so here we say uh count over                                 order by t so we i left the partition                                 part back                                 uh out here because it just just                                 complicate things                                 let's just focus on on the order by                                 clause and the range part                                 and if we know get some data                                 yeah we get a single record here we get                                 the record                                 we have to look two hours back and                                 let's say there was no data for this um                                 this is the first record that we see and                                 then the count aggregation will return                                 one for this record so we get the next                                 record                                 um from this record we look again two                                 hours back and we see                                 hey there was a record and it's exactly                                 this record hence the count for this                                 is uh is two we get the next record                                 here again all the three are still                                 falling to this window                                 the count is three we get the next                                 record                                 these two are not no longer part of the                                 uh are more than two hours apart from                                 this new record here                                 that's why they're not part of the                                 computation so the                                 uh the account aggregation here returns                                 two                                 um another two three                                 and four and you can do pretty much                                 every any                                 uh aggregation function here can be uh                                 can be evaluated over such a                                 such a window you get also some values                                 of                                 some some values of records that are                                 within these two hours                                 or you can compute min max average and                                 so on                                 um yeah so this is a fairly                                 uh fairly convenient uh                                 or powerful syntax for doing lots of                                 uh lots of interesting things over                                 over streams that are like naturally all                                 in by time                                 let me quickly check                                 if this um                                 was that clear how it works oh yes                                 yes please um the order by                                 um argument that's basically to indicate                                 what the range                                 should look at right it doesn't order                                 anything by itself                                 um yes um                                 so you could also also think of if you                                 have an aggregation function that would                                 something like gender last for the first                                 value of the group then the order                                 matters                                 the system here does not really                                 doesn't really order the data                                 unnecessarily it would basically                                 uh um it's really needed so                                 like from from a sequence point of view                                 uh secret does not work on                                 order data right it always works on on                                 on sets of data so we kind of like need                                 to                                 explicitly tell uh tell                                 any database it wants to evaluate an                                 over window                                 how should the data be be ordered so                                 in plain sql uh this also works on                                 basically honor any any audit attributes                                 so not only on time                                 so you could also like in a regular                                 database you could                                 have an overview that just brought us                                 some                                 some numeric values and then                                 performs the computation here in our                                 context here                                 we only support these over if you                                 order on time and that's pretty much                                 because we can like work on                                 evolving data and                                 it only works if we assume the data is                                 already ordered which is the case                                 if we order on time if we would have to                                 order on anything else                                 we could never really finish the order                                 because we would have to wait for more                                 data to see                                 okay so um                                 there's one more thing with respect to                                 time attributes that is like                                 i said these are basically regular                                 timestamps                                 but they have this uh special property                                 that flink                                 basically knows that these time systems                                 are                                 kind of like ascending um and uh                                 ordered with a little bit possibly with                                 a little bit of odorless                                 but uh for that we have the watermarks                                 so um it might happen or depending on                                 what you do                                 how you use these time attributes it                                 might happen that an                                 event time attribute is uh                                 converted or basically yeah is being                                 basically converted into a just regular                                 timestamp it cannot be used                                 as a time attribute so for instance when                                 you have a                                 regular timestamp you could not you                                 cannot use                                 a regular timestamp here in this order                                 by clause because                                 um flink would not know that this is uh                                 this times timestamp is is ascending                                 i could not evaluate this                                 or perform this computation properly so                                 it really needs to be                                 an attribute that isn't                                 as an uh proper time attribute                                 which means flint knows it's ascending                                 if it's just a timestamp any any kind of                                 timestamp you can also                                 have tables with whatever time sims you                                 want                                 but in that case flink lacks the                                  knowledge                                  now that it's ascending and cannot                                  really perform the computation                                  and it could happen that you have a time                                  attribute and that it kind of                                  loses this time property                                  so when this happens um yeah as i said                                  the event attribute becomes just a                                  regular timestamp                                  and it cannot be used in these template                                  operations anymore and this                                  happens for instance once you try to                                  modify the time attribute                                  for instance if you do something like a                                  like this                                  flow operation if you float the                                  timestamp to a minute um                                  then the the result of this will not get                                  an                                  event time attribute anymore but it                                  would just be a                                  regular timestamp um we do that for                                  any kind of computation here so there's                                  also ways                                  that you uh that you could for instance                                  just uh just add a constant to the time                                  and then you would say yeah okay it's                                  still                                  if i add one minute to every timestamp                                  it is still ordered                                  but um we didn't make the system smart                                  enough to really figure out what's the                                  semantics                                  of a of an expression that you apply on                                  the on the timestamp so                                  whenever you use such a time stamp in an                                  expression                                  the result is just a regular time stamp                                  it's not an uh not an inventive                                  attribute                                  so that's uh one one way basically to                                  lose the the time property and                                  uh the other one if you use it in an                                  operator                                  that does not preserve the uh order                                  uh in in in the output so                                  there's uh for instance uh                                  some uh some example here                                  would be um if you use a non-windowed                                  aggregation and you put the                                  clip timestamp into the group by clause                                  then you                                  you can do that you would basically                                  group on the                                  uh on the click time here but                                  the output of this grouper operator                                  operator                                  would first of all would be updated                                  whenever there's a new record coming                                  from clicks                                  um and it would not be in the in the                                  timestamp order anymore                                  so the output of this query would uh the                                  the                                  output of the query uh would not be                                  ordered on clicktime anymore and hence                                  the system has to convert it down into a                                  regular timestep attribute and the same                                  also holds for joints                                  that don't have a temporal condition                                  we will talk about that later in detail                                  but                                  you can think of this as you have a have                                  a table of with                                  some data some records here                                  um that let's say that arrived                                  you started the query one hour ago and                                  you now have the data of                                  one hour here if no record comes from                                  for for the other table it can join with                                  any record in the table so we could join                                  with the first record                                  and then you have to forward the                                  timestamp of the first record                                  then another record comes and joins with                                  the with the last one                                  so you have to forward the record of the                                  last one and then another                                  one comes and joins again with the first                                  one so the order of the timestamp of the                                  of the result is absolutely out of order                                  and                                  hence we cannot really use it as a as a                                  time attribute anymore                                  for processing time attributes this this                                  situation is a little bit easier                                  because there we always                                  just query the time from the from the                                  system                                  so here we just use the uh                                  use the condition when the present time                                  attribute is modified                                  then it also becomes just a regular                                  timestamp and it's not a                                  not another time attribute anymore                                  so yeah to summarize many of the                                  traditional streaming stream processing                                  operations can be                                  can be done with a sql as well                                  and flink provides tamper operators                                  for that to do that efficiently and with                                  the                                  small small state sizes um the input of                                  these                                  input and output of these queries have                                  to be append only tables or the input                                  have to                                  have to be applied only tables in the                                  output then automatically are apparent                                  only tables                                  these queries should only use these                                  record at the time operators like                                  filters the where clause or the select                                  clause                                  or these special time table operators                                  time attributes are defined in the table                                  schema in the ddl                                  you can define event time and or process                                  time adwords you can actually                                  also define tablets that have both                                  and then when the query is actually                                  being processed these                                  template operators process the data                                  based on these time attributes                                  and the output is always final results                                  that's also why the output is only by                                  only tables                                  and these operators also automatically                                  clean up the state                                  when as time moves forward                                  okay then let's have a look at some of                                  the exercises                                  um i would say                                  uh um i'll give you again                                  a few minutes that can uh                                  play with the with the uh or this                                  system so                                  [Music]                                  um it's here                                  number three curious and time and                                  there's a                                  few exercises for this and one for a                                  group by window aggregation and one for                                  an over window application                                  um yeah just                                  let's say at um                                                                                                    yeah see how far you get if you have any                                  questions uh yeah                                  let me know and then we can discuss                                  uh the solution afterwards                                  all right let's have a look at the                                  exercise so                                  the um task here was to                                  count the number of arriving and                                  departing rights                                  per area in minutes of fi                                  in windows of five minutes                                  so the                                  and we're only interested in events that                                  start and end in new york city                                  let's start or end in new york city and                                  areas                                  with at least five arriving and                                  departing rights                                  so this is the uh the query here                                  that's the the result                                  so we are reading from the rights table                                  we filter on the                                  using this user different function is in                                  new york city                                  and then we group on the area id because                                  we want to                                  want to count per area                                  we also want to distinguish between                                  starting and                                  ending right so that's why we put this                                  boolean variable this start here into                                  the group by class as well                                  and then we define the tumble tumbler                                  window of five minutes                                  um and finally in the select clause we                                  kind of repeat all of these things here                                  putting the tumble n function here                                  instead of tumble                                  and during the count aggregation                                  so if we paste this query here                                  and                                  write it then                                  yeah there we go um                                  so this is the area id this is uh                                  for a starting right and this is for an                                  ending right                                  and here's the count                                  and since we have the                                  window of size of five minutes                                  we now and we're basically feeding data                                  at uh                                  the speed of                                                         we are um seeing                                  new events wait a second                                  uh five minutes are                                                                                                         the system can complete a new window                                  aggregation                                  every                                                              uh new data arriving here                                  so and that's uh also kind of like an                                  indication that uh                                  uh that we are working with uh                                  live data here so that data is fed into                                  the                                  kafka topic it is the query reads it out                                  of the kaka topic                                  but it waits until it has seen enough                                  data                                  to then finalize the computation and                                  produce a result for the last                                  five minutes in event time this is also                                  a good                                  um good indication that we are working                                  with event time here                                  if you would use processing time um                                  and we would perform this uh or if we                                  would run this query on a on a process                                  time attribute if right time here was                                  specified as a process time attribute                                  then the system                                  would actually always wait five minutes                                  because the five minutes then                                  based on the um based on the machine                                  time of my computer                                  so um but since we're using event type                                  here there's also this possibility                                  basically to                                  speed up speed up uh processing                                  um it has also the nice property for                                  instance that if we uh                                  would read data from uh i feel reading                                  data                                  uh from the cup from a kafka topic that                                  has already some data in there                                  all the data gets properly                                  properly assigned to the right windows                                  because we're working with the real data                                  if this was like a um                                  it was a processing time time stem                                  we would uh basically add as much data                                  as we can                                  within five minutes i'm not all looking                                  at any of                                  any any time step                                  um for the open window over over window                                  application query                                  here the task is to                                  basically for every uh                                  for every uh departing uh for every                                  write start event                                  we want to see um                                  we want to compute um                                  for for every the task is to                                  to basically identify areas uh uh from                                  which more than                                                         in the last                                             so for that we want to emit a new event                                  for every in euro for every                                  ride departing event where this                                  condition basically is                                  is fulfilled the query looks like this                                  it is a                                  nested theory in this case so let's                                  first have a look at this                                  at the at the inaccurate here                                  we um it's actually                                  three times necessity um                                  so uh the first query here is a simple                                  selection and projection so                                  we read from rights and                                  filter only on on the start events                                  because we're only interested in start                                  events                                  and then we do this projection here                                  computing the area id                                  um and select the right time and the                                  passenger                                  because those are the fields that we                                  need for the uh for the later                                  computation                                  so this is um after this one we only                                  have the start events                                  and did some precalculations here for                                  the area id um                                  then we define a window here again                                  yes w we partition on the area id                                  because                                  um we basically want to perform these                                  computations in the context of the                                  area id order on the right time                                  and then basically on a range of the                                  of the current row and all rows                                  in the range that were were being                                  received                                                                row                                  um yeah and this range here exactly is                                  based                                  on based on this right time                                  attribute here so what do we do with                                  this                                  window so we use it to in this sum                                  computation                                  we basically sum the passenger account                                  over the last                                  over this uh over this window and                                  then we have the area id we have the                                  right time of the uh                                  this is the timestamp of the                                  of the of the row that we're currently                                  processing                                  and then the sum of all the passengers                                  that were within this area um                                  uh                                                                   right start event                                  so this is this query and then since we                                  only interested in                                  in areas where this people count this uh                                  people leaving count was greater than                                     we then put it here again from clause                                  and assign a put filter on there                                  and only interested in people on that                                  into events where more than                                            left                                  so we can                                  simply run this query here                                  and this is basically then how it looks                                  um you could we could also have                                  basically we there's no need really to                                  nest                                  the queries this deep we cannot just                                  could also define views and then use the                                  views                                  and to                                  basically about this deep curiness and                                  then as nesting of curious                                  see now this question                                  no not a question um                                  okay um so                                  um what do we                                  want to do next so um i think we can                                  just                                  continue the uh with the next exercise                                  and namely with the um sorry                                  um namely with the                                  other exercise to write data to external                                  tables                                  yesterday we did this part maintaining                                  it continuously updated                                  view in my sequel we can do a similar                                  thing                                  for writing an append only table to                                  kafka                                  it basically works pretty similar to                                  what we                                  what we did before again there's like                                  the create table statement here                                  with all the properties being being set                                  and yeah then you can                                  write a query that writes to this table                                  and if you want to check whether it's                                  working or not                                  you can run this docker compose command                                  that                                  basically uses kafka's uh so-called                                  console consumer                                  which reads from this topic                                  that the table that is basically the                                  topic backing                                  the table that we defined here then you                                  can see                                  if the query actually wrote something                                  into this topic or not                                  and of course you can again then also                                  check the flink web ui                                  to see how the query looks and cancel it                                  from there                                  so i would uh suggest that you're                                  doing this exercise now maybe for the                                  next                                  um yeah                                  seven minutes or five five to seven                                  minutes so whenever you're done just let                                  me know                                  and after that we can                                  talk a bit about joints in                                  what kind of joints you can do with                                  flink                                  all right that's uh yes                                  please uh this is going really fast when                                  i look at the                                  kafka consumer that's because it's                                  starting                                  from the start of the topic                                  the table that we created this bed is                                  basically                                  creating a consumer that starts from                                  the start of the topic yeah so um                                  that the table of the straights table um                                  we configure that basically you always                                  read from the beginning of the topic                                  so actually the longer you keep the                                  demo environment open the more data is                                  already in the topic                                  so in the beginning it goes really fast                                  and then                                  when it comes to the to the end of the                                  end of the stream or uh then it                                  basically starts to slow down                                  that's the startup mode                                  um let me                                  it says earliest offset yes exactly well                                  this in this case it does not this is                                  actually not really um                                  [Music]                                  it doesn't have an influence on the uh                                  on the exercise that we are doing                                  because                                  we are writing to uh                                  to this uh passenger counts right                                  um so you see this this behavior because                                  right exactly it's the right table is                                  also defined with this uh                                  with this startup mode so for the uh                                  yeah when you know which read from this                                  table again                                  um yeah then it would basically always                                  read from the from the beginning                                  actually this is something that we could                                  even try it should actually work                                  so let's say we are creating this table                                  now                                  um i'm a little bit lazy                                  so the cure here is fairly                                  straightforward it's uh we're just uh                                  um doing a tumbling group eye of                                     minutes                                  and then take the start of the tunnel                                  and so the                                  first time stamp and the                                  [Music]                                  the first time that is part of the data                                  and the first times                                  first time step that is part of the                                  window the first time that is                                  not part of the window anymore and then                                  compute the count                                  and say insert into this                                  uh and if we run this now it's described                                  to the                                  fling cluster symbol of the dashboard                                  we can see this because still running                                  from yesterday                                  so i get this query here                                  and                                  from                                                   pounds                                                                            oh yeah okay it's for every                                             so                                  and yeah since it's                                                   minutes that                                  for every minute that we see a new                                  record every minute                                  so if you said it's going really fast i                                  you know i assume maybe you didn't stop                                  the                                  uh that my brandman since yesterday                                  um yeah and now if you again we can even                                  now query the uh query the table that is                                  uh                                  that we're writing to with the other                                  query that we started                                  okay um                                  let's cancel this query um                                  then i would suggest we now continue                                  with the um                                  with some slides on                                  joining streaming data                                  what time is it okay half an hour and                                  yeah                                  that might be enough or might not be                                  enough um                                  yeah but let's see um                                  if you want to stay longer i'm also                                  happy to uh to finish these uh                                  these slides even if we go over time um                                  yeah                                  okay so um joining tables so                                  um joining is always a bit of a                                  interesting topic when it comes to                                  streaming                                  in like the uh regular sql world                                  joints are very well understood there's                                  different types of joints inner joins                                  outer joins you have                                  different types of predicates that you                                  can use to                                  associate rate rows with each other                                  most usually it's equality predicates                                  where you say some attribute and this                                  table                                  should be equal to the to a predicate in                                  this table                                  um database systems have different join                                  algorithms that                                  they use to speed up                                  speed up joints in different situations                                  and so on and um in                                  traditional sql this all works very well                                  because                                  all data is basically available when                                  when a journal is being processed when                                  you started here with adjoin                                  as i said yesterday conceptually the                                  system takes a snapshot of                                  all tables involved and then it                                  can can be found outside um                                  joining dynamic tables is uh or                                  streams is often considered to be kind                                  of like a challenge                                  first of all because these tables are                                  constantly changing                                  um                                  and if you want to basically join tables                                  with a temporal condition                                  then these tablets should be pet only                                  tables                                  and um when people talk about joining                                  streaming data they often have very                                  different have different scenarios in                                  mind                                  so usually when you talk about streaming                                  joints                                  uh all people are involved first kind of                                  likely to get a                                  common understanding of what they're                                  what they're really talking about                                  um in flink sql we support                                  three different ways to to join dynamic                                  tables so tables that are changing over                                  time                                  the first one is called time window                                  joints                                  the community of the flying community                                  agreed to rename this to interval joints                                  so if you look at the flink                                  documentation uh in one of the next                                  releases                                  you will probably won't find taboo                                  neutron anymore but it will be called                                  interval join                                  there's joints with so-called temporal                                  tables                                  and then something that we can like call                                  regular joints                                  and that's pretty much because the first                                  two                                  are working with uh special time                                  properties and the other ones                                  don't so that's basically the joints                                  that you're                                  kind of would would know from                                  yeah using using sql and regular tables                                  okay how do these joints behave um                                  so the typewriter join uh the use case                                  for for for this                                  tablet join is that you can want to                                  associate                                  rows of two tables uh with each other                                  based                                  on uh uh                                  temporal proximity so the rows                                  should be the rows that join should be                                  close to each other based on some uh                                  time boundary so here we have uh two                                  tables we have the adds                                  at service table this is like the uh                                  a table where we get one                                  record uh whenever we serve a net to a                                  user                                  so s time is the serving time um                                  for uh for a user and then we're serving                                  on for for some on some url so you can                                  think of this yeah                                  as yeah we know the user we know uh the                                  url that the user                                  visited and we served some ad we served                                  an                                  ad for this uh for this link                                  to the user mary at this point in time                                  and                                  here is a clicks table and this clicks                                  table                                  basically has all the clicks so whenever                                  a user                                  clicked on a link we also record the                                  time and the user                                  so and if you would like to know for                                  instance                                  of find all the urls that were clicked                                  within five seconds after they were                                  served as an ad to the user                                  then this is something that could be                                  defined you solved using this                                  tablet.join so here if you look at it                                  we have this uh this ad here we serve                                  and add to user mary                                  for this article uh with id                                   at                                           and there is no click for this                                  there is no click for this uh particular                                  within five seconds                                  you can see this this year was clicked                                  uh about                                  one minute or about two minutes later                                  after it was uh served so it's kind of                                  like falls out of this five                                  five seconds window whereas the next                                  next url that was for user bob                                  at id                                                    within two seconds after it was served                                  to bob and that's why it's                                  part of the results table so whenever                                  you want to join                                  events from two streams that are close                                  to each other based on                                  some temporary boundary then this                                  time we're not joining the is what                                  you're looking for                                  so here um it's defined in a                                  um i have a more more precise definition                                  so time winner join joins records of two                                  append only tables                                  such that the time attributes of the                                  joint records are not more than a                                  specified                                  window interval apart from each other                                  so here this illustration basically says                                  um                                  here the uh this shape here basically                                  indicates                                  the uh the time range that this record                                  is looking for                                  so you can you can create the range in                                  both directions you can say                                  um this record basically wants to join                                  with everything that is                                  one hour arrived um                                  one hour earlier                                  from from an interval from one hour                                  earlier to                                             later and defined                                  this join the other record                                  range is exactly the other way around so                                  this record here                                  would join with everything that arrived                                                                                      up to one hour later and for instance                                  here                                  you can see that these two records here                                  basically                                  meet each other because this one arrived                                  less than one hour earlier then this one                                  here and                                  those two records here would then match                                  and produce a drawing result                                  where is this one here doesn't see                                  anything                                  uh in its uh range and hence it's not                                  shot                                  um the syntax for this um is also just                                  standard sql syntax however again                                  the you can't like need to specify write                                  the join in a certain way                                  uh whether or give a appropriate                                  join condition such that flink will                                  understand this                                  um this uh these these intervals and                                  ranges                                  so um if you specify a query like this                                  um a and b should be tablets that are                                  um append only so they only receive new                                  records                                  we'll never update any records then                                  there needs to be some kind of equality                                  predicate                                  so here we join some some id                                  and then there is a predicate that                                  defines a                                  closed window around                                  the time attributes of a and b so the                                  easiest way to specify this                                  is if you have unlike e t and                                  a t and a and b t are the time                                  attributes of a and                                  b so you can specify the the time                                  attribute of a                                  should be between the time attribute                                  of t minus some time                                  and b uh                                  and bt plus some interval and this way                                  um you um                                  form a closed closed range                                  between these two closed range                                  because you're specifying a lower bound                                  and upper bound                                  that a has to has to match against                                  you could also specify a t equals bt                                  but then the timestamps need to be                                  exactly the same                                  and if you don't say that a t equals bt                                  then you have to specify like an upper a                                  lower bound and an upper bound and                                  you can either do this with a between                                  predicate or with                                  a two uh two two range                                  predicates where eighty uh                                  larger bt minus this and                                     smaller than bt this but the important                                  thing is that like                                  as i said the range that you're defining                                  needs to be                                  needs to be closed                                  so if we want to solve the                                  task that we had here before then                                  the query would look like this we would                                  have the                                  clicks tab and the service table                                  we would join on the url because we're                                  interested                                  on the ul and the user here because                                  we're interested                                  all only on events where the url matches                                  and the user matches                                  and then we would specify that the click                                  time                                  should be between the serving time                                  and the serving time plus an interval of                                  five seconds                                  so here we don't subtract it but it's                                  the lower bound here is basically the                                  serving time it's                                  not really possible that the user clicks                                  before the ad was served but from the                                  time when that's over served                                  to five seconds after that um                                  we want to basically join if a click                                  happened within this time                                  oh okay there's a little bit more so                                  in terms of execution if you're curious                                  like how this executes                                  um what the operator that performs this                                  join                                  in turn does it basically keeps                                  the the the tail of both streams in                                  state                                  and but only the this uh this part of                                  the of the of the table                                  that is needed to answer the join                                  and once the time progresses such that                                  the                                  rows uh fall out of the                                  the john range they removed from state                                  and                                  uh therefore um                                  the the large basically the larger the                                  time it ever gets                                  that you're specifying the more uh state                                  uh is set up by the by the query                                  operator                                  um something that can always happen in                                  uh                                  in in event time processing is that if                                  both                                  tables have kind like a different                                  different timing um on there's                                  some some skew between the data of both                                  tables in that case                                  um kind of the join                                  operates at the speed of the slowest                                  table                                  and this means that more data for the                                  for the other table for the faster table                                  needs to be buffered                                  um yeah joints with temporal tables                                  so the use case here is um                                  that we                                  kind like have again two tabs we have a                                  clicks table here that we had before and                                  then some kind of user history table                                  where we basically                                  this is a table that stores                                  different versions or basically stores                                  the history of                                  a of a user and whenever a user changes                                  um the subscription then a new record is                                  added to this uh user's table history                                  tab                                  uh this history table is therefore like                                  append only                                  so we don't it's not modeled that there                                  is                                  that the user id is a unique is a                                  primary key and we simply update the                                  field                                  but instead uh it's modeled in a way                                  that we keep                                  uh all different versions that whenever                                  something changes we just append a new                                  record                                  with a with a new version time                                  so um and if now we have a                                  have this clicks table here and the user                                  history table here                                  what we basically want to do is um we                                  want to join                                  each uh click here                                  with the current subscription status of                                  the user                                  so if we get this record here for mary                                  uh at                                             uh we basically want to conceptually do                                  a lookup in the                                  in the users table here and join it with                                  the                                  latest value for mary at this time                                  so latest value here for mary is                                  um is the version at                                             and therefore we join the subscription                                  for this record at a later point in time                                  at                                             um there's another click                                  of the zameri uh this time we have to                                  look                                  uh up the current version for uh for                                  uh three o'clock                                  and in the meantime mary had                                  changed her subscription status                                  um to paid and hence we need to join the                                  paid stadium so there is a                                  something that is important here that                                  one usually doesn't really uh cease on                                  the first                                  side and this is this temporal                                  relationship                                  between the click time here                                  between the time stem and the uh                                  and the inversion time the important                                  thing is if                                  we would model this query basically as a                                  simple join without a temporal con                                  temporal condition but have instead a                                  table here where we would where the user                                  would be                                  like a primary key and we would simply                                  update the field here                                  as soon as we would do an update here                                  and we specify the                                  query we want to evaluate it with                                  regular sql semantics                                  as soon as we would change the                                  subscription of a user                                  we would need to update all                                  result rows that we ever processed for                                  this user as well                                  because if this is treated as a as a                                  table that is                                  um that that can change its records                                  at any point in time we also need to be                                  able to update the result                                  and this also means                                  that we would need to store the four                                  clicks table to be able to update the                                  result                                  so um if you want to avoid that we kind                                  of                                  somehow need to encode this                                  this temporary relationship into the                                  join that we always want to join                                  this record with the most recent version                                  that was available before this uh                                  this time stamp so                                  um here the definition                                  is a temporary table gives access to the                                  history of a dynamic table                                  by joining with the temporary table                                  records of an append                                  only table can be joined with the                                  version of the dynamic table                                  that corresponds to that timestamp so if                                  we have this if this is the append early                                  table here                                  this is the clicks table in our previous                                  example and this is the                                  user history table then if we have a                                  record at this point in time it would                                  join                                  with the record at this time if we have                                  a record here it would join with a                                  not with this because there's a new                                  version here simply                                  this and also join with this this will                                  also join with this                                  here then we get an update but there is                                  no record on this                                  uh on the pen only table the next record                                  here on the pen on the table and then                                  gets again the latest version so we                                  always                                  associating each record on the pen only                                  table with the most                                  recent version in the temporary table                                  um this                                  kinda needs uh means we have um                                  the the the temporary tablets defined um                                  kind of as a as a parameterized or as a                                  parameterized view on this history table                                  that basically means that we can                                  query the history table for certain                                  points in time                                  so if we have this history table here                                  and it also needs to have a unique heavy                                  unique e field                                  um if we have this history table here                                  and we want to get the most recent                                  version                                  at uh                                                                                   the values that would correspond to the                                  most recent version here                                  are these so we would get the b value                                  it's from                                                                                                                                from                                                                   and ask the same question that                                  for for the time                                                        values                                  so we get a well okay for c it's the                                  same value because nothing was changed                                  in the meantime                                  but uh a was changed b was changed and                                  there is even a new record for                                  uh for for d at this time                                  um in flink sql we model these template                                  tables as a                                  table valued function that catalog needs                                  to be defined on the                                  on the history table um                                  so and this uh                                  and this is basically what we also did                                  in the in the exercise with this                                  driver driver changes here with the                                  driver changes table                                  uh is the history table and um on this                                  we define this                                  builder function that can be used to                                  access different fields                                  i think that's probably all a little bit                                  abstract but                                  let's have a look at how this how this                                  looks looks in in sql so we have this                                  table a which is this                                  append only table and then                                  we join this this is the standard sql                                  syntax                                  for using it our table table valued                                  function                                  so it's a lateral table and we pass in                                  the                                  time attribute of a as a parameter and                                  this basically means                                  that we want to get the value of this                                  function here                                  at time um                                  at the time for of of the current record                                  so for every record you can you can                                  think of it as                                  as follows um for every record of a                                  we basically do a lookup in the in this                                  in this table function in the temporary                                  table                                  and we for for the lookup we need the                                  time step because we want to get the                                  most recent version with respect to this                                  time step                                  and then we do an equality predicate                                  we do an uh equality join                                  a predicate here on the                                  on the unique key of b so it's basically                                  modeled as a simple lookup                                  against the temporal table based on the                                  time                                  so for the uh exercise that we did for                                  the exam that we did before                                  you would have this clicks table c we                                  would have a                                  uh a joint with the lateral table here                                  with this function users                                  users is a function that is defined on                                  the user history                                  we provide the click time                                  and the the click time of the of each                                  click record                                  and then we join on                                  the user of the click with the                                  id of these user subscriptions tab                                  um                                  for the execution this is um                                  what basically happens is internally is                                  that the                                  um for this temporal table for this                                  users table where we kind of need to be                                  able to look up different versions                                  um we                                  need to keep a few records in state                                  namely uh                                  for each for each unique value of the                                  letter table we keep the most recent                                  version                                  in in in state and                                  for the clicks table we don't need to we                                  don't                                  store any any uh any of these records in                                  instead we don't need to materialize                                  them because                                  [Music]                                  the uh                                  we know that we can for every of these                                  uh for every                                  row from the clicks table we can simply                                  do the lookup                                  and since we have this this uh this                                  temporal condition                                  um that we always want to get the most                                  recent version                                  we can simply do the lookup join the uh                                  result together and emit the result so                                  we don't need to hold any of our any                                  record of c                                  instead but only the most recent version                                  of the                                  of the office of this temporary table                                  and that's maybe                                  now this is always a bit uh                                  tricky to explain i hope it uh                                  made sense uh to some extent we have                                  some exercises also for that in the uh                                  in the um um                                  in the in the week in the repository so                                  you can                                  use that and to to play around with this                                  concept                                  of temporal joining of temporary tables                                  okay now let me briefly go over the                                  like regular join which is actually the                                  join that you                                  kind of know from i should know from sql                                  already um here we are                                  have again two tables there we want to                                  join one is this clicks tab with click                                  events                                  and the other one is sit down i see it's                                  a little bit messed up here                                  um                                  oh no it looks better so one is the                                  clicks header and the other one is a                                  users table                                  so here we modeled more of this exactly                                  as i said before with the table that is                                  just updated there is no                                  we don't track any version so uh                                  let's say we have um the clicks this is                                  the click stability                                  at                                                                    table at                                             if we join them together with a just                                  regular join                                  then we would have mary we would                                  count the number of clicks um and we                                  join it with                                  uh the current subscription same for bob                                  and uh everything's fine at                                             if now the user's table changes                                  at one o'clock we need to update the                                  result that we computed before so                                  at sorry at uh                                  one o'clock murray changes her                                  subscription to paid                                  so this means we now kind of need to                                  update                                  the result that we produced before                                  because it's not valid anymore                                  so uh the subscription here                                  changes from free to paid                                  and if now the clicks table changes at                                                                      uh at two o'clock and we get another                                  record for mary                                  then we need to again                                  update this result because we also want                                  to like count the                                  number of clicks and now the the current                                  uh increases from uh to                                  from one to two so you see                                  at any point in time when something                                  changes in either of the of both tables                                  we need to update the result and                                  in order to be able to do that we need                                  to keep                                  both tables completely                                  in state because uh anything can happen                                  at any point in time we always need to                                  be able to                                  update the result there is no temporary                                  boundary uh                                  for for the computation that would say                                  at this point in time you can be sure                                  that                                  the result will never change this is not                                  there so                                  um we need to keep                                  all data from both tables                                  in state                                  the syntax for this looks uh just as                                  any join in in sql right                                  you have tables a and b                                  and you just give the join condition in                                  the in the where clause                                  uh you can also specify them with the                                  with the                                  join clause so a joins b on                                  uh a uh i a id equals b                                  id so both of both join sentences are                                  supported                                  um yeah but since                                  a and b are both completely held into                                  memory um                                  it's kind of like um advisable                                  um that both input tables are                                  not append only and growing very fast                                  because                                  you just need to buffer all of the data                                  unless you specify                                  this idle state retention and then                                  you might get inconsistent results                                  so the use case for                                  the query that would implement this here                                  would                                  be this we have                                  the clicks table we group on the user                                  account per user                                  and then join this result with the users                                  table                                  on the id user field                                  and this way we can uh                                  the the system translates this into a                                  query where                                  we first basically do the aggregation                                  here on the clicks table so we have                                  for every you we have a for every user                                  we keep the current uh count of clicks                                  and for every user we also have                                  we also have the users table on the                                  other side both are                                  kind of like updating tables that are                                  updated per user                                  and hence not growing very large uh when                                  a new click is added                                  um it doesn't add a new row unless it's                                  a                                  new user but if it's a user that was                                  already there you just have to update                                  the count but not add a new row to this                                  table and both of these tables the                                  result of this query                                  and the users table are held                                  completely in the state of the join                                  operator                                  um yeah so i think i've already said                                  this before as well                                  so regular joints can forward time                                  attributes um                                  because they um                                  any record can join with any other                                  record at any point in time so the                                  order of outputs is uh of                                  the emitted rows is                                  pretty much random so they                                  [Music]                                  cannot that the watermark alignment                                  basically is then lost                                  all right so we have some exercises for                                  for joining these dynamic tables um                                  i think the tutorial time is                                  over if you want to um                                  spend some time looking into these                                  exercises uh                                  uh feel free to do so i'm                                  happy to hang around for a couple more                                  minutes if there's any questions                                  um if not um                                  all of the exercises are here in the                                  wiki you can just                                  uh play around that there is another                                  uh topic about these uh match recognize                                  clauses uh all of the slides that are                                  shown are always linked in the                                  in each of the pages here so if you                                  click for instance here on the                                  pattern matching with let's recognize                                  click on this link here                                  there's the uh pdf for this slide                                  set you can just study it yourself                                  and also do the exercises um                                  okay so i'd say uh                                  this is it um i hope um                                  you had fun learned something um                                  yeah if you want to want to do the                                  drawing exercises feel free to                                  as i said uh have a look at that if not                                  uh                                  enjoy the rest of the conference and the                                  other talks um                                  and yeah if there's any any issues any                                  questions                                  the flink user making this is very very                                  friendly and                                  answers a lot of questions are we also                                  quite active on stack overflow                                  or yeah feel free to open an issue on                                  the                                  training repository yeah whatever works                                  best for you                                  thank you                                  you
YouTube URL: https://www.youtube.com/watch?v=gV4gNax7yuw


