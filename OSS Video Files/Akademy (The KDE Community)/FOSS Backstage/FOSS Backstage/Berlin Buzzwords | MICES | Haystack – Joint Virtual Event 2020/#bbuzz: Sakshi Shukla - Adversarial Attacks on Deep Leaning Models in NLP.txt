Title: #bbuzz: Sakshi Shukla - Adversarial Attacks on Deep Leaning Models in NLP
Publication date: 2020-09-10
Playlist: Berlin Buzzwords | MICES | Haystack â€“ Joint Virtual Event 2020
Description: 
	More: https://berlinbuzzwords.de/session/adversarial-attacks-deep-leaning-models-nlp

This talk is about how adversarial attacks can manipulate our deep learning modules and create drastic variations in the context of data. It focuses on Large Textual data and how functions of Natural Language Processing will be trained over wrong information. These attacks compromise the deep learning models and alter the meaning of the data. It is very critical to protect our models from such attacks to protect our data. The talk describes of the measures which we can implement for our Natural Language Processing models.

Refer the presentation: http://bit.ly/ppt_berlinbuzzwords
Captions: 
	
YouTube URL: https://www.youtube.com/watch?v=JACkw_5zG2Y


