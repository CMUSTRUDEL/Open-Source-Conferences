Title: Berlin Buzzwords 2017: Stefan Vetter, Thomas Fricke - Rolling out Enterprise Kubernetes Clouds @ SAP
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	In this talk we give insights in how we have set up several Kubernetes clouds for SAP. We tell the whole story, from PoC state, first developer installations, testing until production. We implemented on premises, in internal and external IaaS clouds. We used Docker and Rkt, rolled out database applications and implemented deployment pipelines. Special applications have special needs, so we tweaked parameters.

At the end, we implemented several self-installing, self-hosted, self-healing and extendable Kubernetes clusters, which allow application deployment on scale for cutting edge case involving high performance databases and number crunching applications.

Read more:
https://2017.berlinbuzzwords.de/17/session/rolling-out-enterprise-kubernetes-clouds-sap

About Stefan Vetter:
https://2017.berlinbuzzwords.de/users/stefan-vetter

About Thomas Fricke:
https://2017.berlinbuzzwords.de/users/thomas-fricke

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              thank you so well yeah I'm the global                               topic container technology at sa P so we                               in our department are creating the                               architecture to deploy kubernetes at a                               JP and Thomas basically is working                               together with us so Samuel yes so this                               is the second talk at the Berlin                               buzzword so I've been here last year                               exactly about this topic but without                                Stefan so has developed a little bit and                                actually everybody knows know there is                                something like docker and everybody's                                talking about micro services but if you                                come to a startup like SAT which is a                                big company with a big business and big                                container then you face completely                                different problems so if you switch to                                the next sheet so then we will see what                                they told us containers are for shipping                                we build containers it's a unique format                                and you can roll or container and then                                if you it's like any other technology if                                you put something out in the wild people                                play with it and people do things and                                then the scene is changing so the next                                shows what people are also doing become                                containers so housing in containers this                                was not intended but somehow yeah looks                                looks usable you can have a house in                                containers like the thing we had if you                                talk about containers and micro services                                was mostly intended to run stateless                                services in containers or no data you                                know the kettle and eps picture so                                China's in production have been                                considered as pets and then if as a                                syllabus Carolyn is if you don't need                                them anymore far away but then this is a                                picture from turn off us so it's how                                they see the way of dealing with                                legacies of everybody who has survived                                three months of having business in my                                experience as legacy software everybody                                every startup after three months is kind                                of this dragon and then if you are                                successful this dragon is making the                                money for you and therefore you cannot                                kill the dragon because he wants your                                income more less so you are you have to                                deal with it so this is a picture of you                                see yes let's do cloud native up a                                little bit and that's exactly what we                                say is it as a PDF more than one dragon                                there a lot of dragons there and you see                                cloud architecture they do the wizardry                                try to influence the entire beast you                                see the line of debt                                project managers lying around sis admins                                and database admins trying to fight them                                senior developers try to keep it under                                control                                so exactly the picture you you                                foundation think the guy's exactly                                understood what's happening and the                                opposite is also true if you have no                                legacy you don't have a business and to                                be to be honest the next picture people                                are doing something completely different                                with its containers then we have                                imagined Google is known to run                                everything in container so they have                                must have found a way of running even                                their windows in the Google cloud it                                container somehow solution is normally                                your protec a VM inside the container                                which is reversing the thing you would                                expect and put                                put a container around a hypervisor                                which is weird and what I always tell                                people in training this is not the first                                thing you should do with a container but                                if you go to customers and they say oh                                we have this as a PR                                                    fleet it's even older than r                                          running on Windows servers only which                                are very ordered we have paying                                customers which pay us not to be                                migrated to the latest technology it's                                quite impossible to say no and actually                                it works so we tested it and you see the                                final or really book is coming out in                                the next week so windows in kubernetes                                definitely is a topic and this picture                                is from liberals Polyphemus it's a                                living fossil so this way you have an                                imagination what's really happening out                                there if a customer has a business that                                wants to move its business into the                                container and in kubernetes world but                                 and that's the cake that's wrong I mean                                 there's also a use case to run Windows                                 and containers for example um you have                                 good infrastructure like we have a lot                                 of ethical we are building software for                                 line logs for Windows for whatever yeah                                 different versions of this different                                 versions of that so we are now moving to                                 both our stuff and tests Horrible's and                                 do optimizations in containers but what                                 about Windows because we also need to do                                 the same stuff for Windows so should we                                 run to infrastructures like a container                                 infrastructure and a window server                                 infrastructure probably in a VM and for                                 infrastructure or should we just move                                 the windows VMs into containers though                                 so what we surely do is we build up a                                 kubernetes cluster                                 we put the lining spills into containers                                 and we put the Windows virtual machine                                 into containers because windows                                 containers are not ready as of now you                                 cannot use that in production so we                                 basically build our software then in a                                 VM on the container yeah and the                                 interesting part is after we have done                                 this they told us oh it's less pain than                                 running windows the windows way so                                 containers are not solving the problem                                 but they are kind of relief mitigation                                 of the pain of running Windows systems                                 in containers so this is kind of what                                 you can expect if you go to real                                 customers with the real business and it                                 seems to work and we there are recipes                                 in the net how to do it took our                                 smallest two or three weeks to do the                                 entire ecosystem around when you have                                 this kind of solution yeah and okay we                                 talked a lot about companies I cannot                                 expect that everybody of you knows what                                 kubernetes is communities is now in the                                 moment one of the fastest developing                                 open source projects it's from Google                                 Google infrastructure for everybody else                                 it GP part the meaning of this thing is                                 you have the same root of the word as                                 governor or cybernetics so it's                                 kubernetes is governing the entire                                 container system google has an older                                 system which is a kind of joke with this                                 is about they call it bark and the box                                 you might know live in cubes so that is                                 kind of an internal google joke for us                                 important it's in our entire open source                                 ecosystem it's written in gold and the                                 idea is not to manage machines anymore                                 if you look into the open stack of                                 virtualization environment of                                 VMware or the other cloud it's all about                                 how I manage my machines and this is not                                 about managing machines the outcome of                                 kubernetes lazar must be you manage your                                 applications not your machines anymore                                 so it's well-suited for DevOps                                 environment and that's what is the                                 intention behind it so you want to get                                 away of the pain of running hardware                                 this is a promise but I think so                                 delivered something so to take over at                                 this point what Thomas just described is                                 you know your application needs some                                 amount of CPU some amount of memory and                                 stuff like this yeah before containers                                 before kubernetes you were just going                                 there and saying okay I need a machine                                 or a VM that has let's say                                          cores and like                                                          execute my application with container                                 infrastructure and kubernetes you                                 basically describe that in one manifest                                 and then you just deploy your                                 application once twice three times four                                 times doesn't matter and kubernetes                                 takes takes over to schedule this on one                                 of the nodes inside the cluster which                                 basically offers to share the                                 infrastructure the hardware between                                 multiple applications so you can even                                 run multiple attack applications in                                 parallel on the same hardware now and                                 the point is you describe it in that                                 definition for your applications you                                 don't have to describe a virtual machine                                 you don't have to describe an operating                                 system you don't have to describe                                 anything about it you just describe your                                 container and what you need for it and                                 then you deploy it anywhere on                                 googliness                                 that's all and that makes things                                 much more easy and also comes along with                                 the DevOps abroad because the depth now                                 take over the hops photo without you                                 having to drop at the point yeah and                                 this leads to the next slide because                                 here we have a ten thousand six zero                                 view on kubernetes basically so you have                                 multiple possibilities to work with                                 kubernetes basically the final one is a                                 behind so they eat the highway connects                                 to the API server and the server                                 basically puts the informations in to                                 f.                                                              controller to take over the information                                 from edge and the CLE basically                                 implements the API and talks for the API                                 server as well in the UI is just an                                 application to do the sales now and at                                 the end of all this is communicating                                 with cubelets cubelet is basically the                                 local administration application on the                                 real machines that orchestrates the                                 container runtime that is running on the                                 machine to both the containers or to run                                 the containers basically inside the                                 machine so what you really care about is                                 your are either someone or an                                 application or whatever yeah you use an                                 API and you have a container class or                                 damnit you don't need anything else so                                 yeah so and what we also find this we                                 have if we deploy an application for                                 example there are very valuable patterns                                 for example the Diploma now is a                                 first-class citizen of kubernetes so if                                 you do deployment the first thing which                                 is created is a replica set and the                                 wavelet concert is creating actually the                                 number of applications or a number of                                 pots which are collections of containers                                 you need so you're all out                                 any application through a replicant in                                 the replica set chaos that exactly the                                 number you want to have is deployed                                 somewhere in your cluster if your                                 cluster is the soda machines big it has                                 it as a scheduler where to place my                                 application where can I put them and                                 spread them over the cluster and if you                                 do an update one in future another                                 replicas set is spawned and you get                                 another a replica somewhere and then it                                 should disappear here but there okay did                                 not survive everything from power point                                 but don't matter you get a new replica                                 set with a new world and then it's a                                 well-defined thing that you do a rolling                                 roll art in a replica set from a new                                 volume to an old world and you can even                                 roll back if you if you announce the                                 image and something you know works well                                 old also would stop if something breaks                                 if you have an image which is not valid                                 or somehow of the readiness and saliva                                 health probes of the container are not                                 working so their role does not wipe out                                 your entire service because this can be                                 connected to an another kubernetes                                 entity at service which collects all                                 your applications into a single thing                                 and does a round-robin around it so this                                 is kind first time I've seen rolling                                 update as a first class citizen in                                 equipment in an orchestration cluster                                 and by the way you don't have to do                                 rolling updates you can also do                                 Bluegreen deployments as you see blue                                 and green so you can say okay I want to                                 have my new application now deployed                                 here but I just want to have                                            traffic go into the new application                                 because I don't want to have if there's                                 some back in or something like that I                                 want to not to fail all the customers                                 but only every fifth customer so I do a                                 Bluegreen employment so I have both                                 versions of my application running in                                 the cluster and kubernetes takes care of                                 directing the loads to the different                                 plots and the different versions so if I                                 see there is an error in the new version                                 I can just draw it back                                 so all fine old words in there and                                 customers running with the old version                                 or so but if I see everything works out                                 then I can surely remove the blue parts                                 or the old version and leave the                                 customers only to the wing pod now it is                                 quite outstanding because before I've                                 been an inner God up in one bigger                                 involve in Internet company here and we                                 needed I think three or four years to                                 implement for all applications on that                                 platform a rolling update and quite of                                 stable and successful way of deploying                                 applications as role in updating them                                 without service interruption and this is                                 the result service interruption is quite                                 important because this means that you                                 can do continuous live deployments and                                 things like this and you don't have to                                 care about versions you simply say to                                 the developers your version has to                                 comply with other versions plus minus                                 one or two minor version that you don't                                 break the interfaces to fascist this                                 means to have a always one platform                                 where you can really do multiple                                 deployments a day so but we don't want                                 to say that kubernetes solve the                                 problems of updates and also solve the                                 problems that you might have a downtime                                 because if you're running for example                                 databases and the databases needs to                                 converge the data from one version to                                 another usually need the downtime                                 because you cannot run one version and                                 the other version in parallel with the                                 same data store yeah so there are                                 applications where you cannot do it                                 and there are also applications like                                 if you have an application server that                                 doesn't support murky influences so you                                 have to store everything in one                                 application server instead of in two so                                 then you cannot run to port and download                                 now so this means you have to either                                 switch directly which is also possible                                 in Kannada                                 so basically replace it whether                                 deployment so as soon as the new pod get                                 healthy you remove the old one and                                 switch completely to the new one yeah                                 but yeah so kubernetes doesn't solve all                                 the problems because kubernetes doesn't                                 or isn't able to join your application                                 to look into your application to change                                 your application to add support for                                 things that your application doesn't                                 support so only what is possible with                                 your application get much more easy with                                 kubernetes because you don't have to                                 reinstall operating system you don't                                 have to update your virtual machine or                                 your real hardware you don't have to                                 care about updates scenarios because                                 well the container you just exchange the                                 application no its overall environment                                 so you don't have to update an                                 application within the container you                                 just exchange it that's done yeah so so                                 and if you look into a typical more                                 sophisticated applications that you see                                 would not only have databases and the                                 web portal you also have hidden layers                                 for example the load balancer is part of                                 your application because you might have                                 load balancer rules if you ever played                                 with f                                                                talking about                                 and you see there are stateless layers                                 for example the the upper four and they                                 are stateful layers so you have kind of                                 storage you have your sequel databases                                 your no sequel database and you should                                 not underestimate the state in your                                 messaging system if you're on a Kafka a                                 kind of RabbitMQ or zero and Q are any                                 messaging system                                 messaging system has state and is                                 therefore part of the persistent layer                                 and this way you can make everything                                 except these layout status so if you                                 separate your applications then you have                                 the business logic on this layer you                                 have might have a reddish character is                                 not really stateful because it can be                                 regenerated on the fly and you have the                                 web portal traces to the outside and you                                 have the low terms or rules and                                 therefore it's absolutely important to                                 before you start a project to identify                                 the states for layers and anything which                                 is not stable the kettle part can be put                                 into kubernetes immediately without                                 hassle so it's quite easy to put these                                 stateless applications in and then you                                 can do other evolving updates but if you                                 have database every database Manas has                                 its own replication idea if you're                                 looking to post grants or into MongoDB                                 or you name it every replication is                                 different and you have to handle                                 database by database if you have to                                 bring a database into kubernetes this is                                 now possible with stateful sets they are                                 something which is located on a machine                                 where you might have a hard disk you                                 might have SSDs for your data and then                                 you can run a beast like Hana in memory                                 which is backed by kind of disk space                                 and then you can run even Hana databases                                 in incriminated and last year everybody                                 discuss things like are containers ready                                 for production is this prepare for the                                 interface and I would say the SFSP at                                 the enterprise company and if Hana is                                 something you would run in production                                 which is more less occasional oh but you                                 can also stay with out stateless                                 application sets and run stateful                                 applications because if you have our                                 first layer that has a                                 tribution over the overall cluster then                                 you're able to connect to the data on                                 every node so it doesn't matter if you                                 slow the data locally to this node                                 because it's also a viable on any other                                 node in the cluster and this is                                 something for example how we also work                                 on to get the distributed storage engine                                 to automatically detect the disks in the                                 cluster nodes in the kubernetes cluster                                 and offer them to the applications on                                 kubernetes so like I find right so the                                 ecosystem we are working on is basically                                 what you see here so we have a Korra has                                 currently delivered as container lineups                                 we are using the container runtime                                 rocket I move here better because                                 otherwise you might hear this sound                                 again                                 so we are using Rockets as the container                                 runtime I mean most of you might know                                 docker instead why you we provide we use                                 rocket while most of the people use                                 docker well I will explain that in deep                                 later but in general Rockets doesn't                                 offer full rights right away so you have                                 to give every single right to the                                 application in the container while the                                 doctor offers the full rights right away                                 so for example if you start a container                                 of rockets in kubernetes you will be the                                 user named root but root can have to                                 change mods to a file it can it will                                 shown it cannot to a zoo not a zoo do                                 nothing it just doesn't have rights even                                 though it's named rudy                                 well talker everything like this is                                 possible so you have to manually remove                                 the rights the dock                                 while you have to manually add those                                 with rockets and that's basically why we                                 decided for rocket that was the first                                 decision there's another one coming up                                 later                                 yeah we're using Jenkins and Nexus to                                 integrate the container build pipelines                                 and the lifecycle management and the                                 security checking we use Co scale to                                 monitor our kubernetes clusters because                                 our core skill is in my opinion the most                                 advanced monitoring tool for kubernetes                                 right now the code kale just to explain                                 it a little what Co CL you deploy a                                 different set to your kubernetes cluster                                 and every node yugi-boy into the                                 kubernetes cluster will be automatically                                 monitored as well as all the containers                                 in the classroom will be automatically                                 managed monitored because Co scale                                 directly integrates of the kubernetes                                 api and was a container engine and with                                 the servers so you monitor the full                                 stack right away without doing anything                                 you just run Co scale SVD for sure is                                 the key value stored at kubernetes users                                 and we are using flannel in the small                                 clusters for development and calico is                                 meant for the bracken clusters of                                 multi-tenancy so um yeah yeah what will                                 we do in the future                                 I think that's a interesting story                                 so yeah what would all that also                                 describes why we do is rocket right now                                 that's another point we have a secure                                 pot manifest meaning we don't give the                                 pot any right like the containers yeah                                 what kubernetes one four one five                                 rockets had each each container had a                                 rocket process so not like the docker                                 you have a demin to run the containers                                 with rockets you have a binary running                                 one container or                                 reconfiguring and stating one container                                 and which is not the case of docker yeah                                 the same manifests except of the API                                 change in kubernetes you can use for                                 kubernetes with the Cree implementation                                 CRI means container runtime interface                                 it's one more the interfaces the first                                 was CNI the container network interface                                 to make it possible that you can just                                 change the network plug-in and continue                                 working and here with GRI you see you                                 can just exchange the container runtime                                 this is a little broken I'm sorry so the                                 first one is container Lee which is now                                 maintained by the cloud native                                 Foundation which was the container                                 runtime used by docker and created by                                 docker you have the choice for rocket                                 labs maintained by Korres you can use                                 cRIO by Red Hat and do the raised I                                 think two months ago of let's say GA                                 relief of um OCIE                                 which is also a container run time                                 working with the CRI and at the end you                                 exactly have the same picture so you                                 don't have to change your manifest                                 except of the API changes when moving                                 from one kubernetes version to the other                                 yeah so the challenges are the                                 Futurecast we are working on which we                                 are implementing in our infrastructure                                 is large networks meaning a couple of                                 hundreds kubernetes nodes and also                                 multi-tenancy with in the clusters as                                 well as distributed clusters meaning how                                 what kubernetes you can set up multiple                                 clusters for example you have a data                                 center in germany you have a data center                                 in u.s. you have a data center in france                                 in belgium and wherever else yeah                                 and you have in each data center or                                 kubernetes cluster then you can build up                                 a classic Federation and you can                                 administrate all those kubernetes                                 clusters in all the different reasons                                 and data centers over one API of a one                                 control plane so you just execute one                                 command and it will be done in each data                                 center if you run it for each data                                 center or if you just say ok I'm                                 connecting to the German data center but                                 I want the UF data center to change the                                 version this is possible you don't have                                 to care about it to Banaras takes care                                 of this now distributed databases and                                 GPUs for machine learning is also some                                 topic we're currently working on yeah so                                 so this is an example for how we handle                                 big networks so effectively if you look                                 into the basic network model of inators                                 you'll see it's using a Class B Network                                 so                                                                   have two digits or two to two digits                                 less or two to two numbers left for                                 addressing the node and for the port but                                 this means that we are limited to                                     for containers inside a machine of                                     containers or pots in a cinema Fenian                                 you will notice easily that the modern                                 machines are handling more than                                 thousands of containers so even there                                 are examples even that you can handle                                                                                                 raspberry P so this means this model for                                 large machines is limited and the second                                 thing is even harder in the standard                                 model if you only have                                                   your note and this limits you to exactly                                 this                                 network sighs and we are going into a                                 direction where we really soon will see                                 this limit and then we have to exchange                                 the network model and this is possible                                 because we have                                 CNI plug-in and you can use this                                 container network interface to handle to                                 integrate and remove the container in                                 your network so it's called all the time                                 in new container changes its life cycle                                 so if a new container is created you get                                 a list of parameters which can be used                                 to integrate the pot into the network                                 and then they have a demon this is a cat                                 from calico project calico is doing it                                 and they have another cat named chosen                                 for the demon there the felix daemon                                 which does the routing entity iptables                                 and this is not enough because in a big                                 network you have to communicate the IP                                 Jesus IP routes and effectively they                                 solve the problem at calico turning a                                 node into an entire data center so we                                 use the border gateway protocol which is                                 collecting all the internet route                                 information and put it into a kubernetes                                 cluster it's not connected to the BGP                                 outside so this would be a severe                                 security problem but they use the same                                 technology have a demon but you can                                 exchange it by any other border gateway                                 protocol daemon and then it's connecting                                 it to outside route reflectors that you                                 have really huge clusters which are                                 informed about the routes inside the                                 network and the ordinary network have                                 was an overlay network this was                                 tunneling IP over IP without the                                 encryption things like this is also                                 going away and they connect to the                                 physical fabric which mean you can                                 integrate third party products from or                                 software-defined network Venice                                 and get the full performance of your                                    or                                                                kubernetes plots which is quite of                                 interesting if you want to run high in                                 network workloads in kubernetes yeah and                                 also this I mean we separated our                                 networks in kubernetes so our kubernetes                                 infrastructure in our own data center                                 have a different network for deploying                                 and pulling applications containers and                                 stuff like that and a different network                                 for the internal cluster communication                                 as well as a different network if you                                 want to attach remote storage as well as                                 we have a different network for the                                 outside communication of the kubernetes                                 cluster and if you count all this                                 together and then think about that s ap                                 is currently running more than                                         servers in their own data centers plus                                 the colocation data centers class you                                 know one one one year so incoming we                                 have like around I think at the moment                                                                                                          so this is nothing you can run what's                                                                                                     customers then you have to build like                                 thousands of kubernetes classes and this                                 is just incredible so we will not do                                 that                                 and why why we use calico I mean there                                 are others also running with VTP and                                 offering this these solutions likewise                                 to calico but basically we we know a lot                                 of companies that use calico at scale                                 and they are very experienced in that                                 area so we are coming from the OpenStack                                 community and have a lot of experience                                 with certain they turn no into the                                 kunais business as a lot of companies                                 which                                 experiences Olmstead yeah like neuron                                 test yeah which was basically the number                                 one contributed to OpenStack and they                                 are today they basically decided I think                                 one and a half years ago that's the                                 future marking for them is no more open                                 deck but it's kubernetes and I think                                 officially it was said a couple of days                                 ago that they are now moving more into                                 kubernetes and putting down the                                 OpenStack as that so I think they locked                                 it in to court-martial product yeah now                                 but we have to proceed ok so next is ok                                 what really interesting is about                                 database you have might have about this                                 little white rabbit called cap theorem                                 and on the other side you have the                                    sector philosophy or how to run stated                                 systems here you see the nice of the                                 holy to a sector grail and everybody of                                 you who knows the movie from multipliers                                 and I think this little innocent rabbit                                 is killing these Knights for breakfast                                 so what we kind of need is this Holy                                 Hand Grenade of Antioch here which is                                 orchestrating our workload for for                                 distributed databases we are not really                                 we don't have a real solution up to know                                 what we have ideas about this and so                                 this is a real challenge but this reread                                 databases have always been very                                 complicated and challenging and this                                 does not go away if you run it in                                 communities now just a hat is at this                                 point we already have a solution for a                                 CD which is more or less a distributed                                 database even though it's called a key                                 value store but our kubernetes custer's                                 internally                                 the FCC store they are based on                                 themselves so we don't maintain the head                                 city cluster and we don't use something                                 like that the operator from korra's to                                 maintain our a city cluster we basically                                 let kubernetes do the work yes next                                 challenge                                 so yeah machine learning I mean I don't                                 know if you guys heard from dub Korea                                 Sofia is the new machine learning                                 product just presented at the last a                                 fire which was in June or something at                                 the beginning of June I think I don't                                 remember the real date but sub clear                                 from the architectural perspective is                                 working with kubernetes so Sofia                                 integrates kubernetes for machine                                 learning proposals and we are continuing                                 our work about the integration and                                 pushing onto NVIDIA and also some others                                 to integrate multi-tenancy in GPUs which                                 is not possible at the moment because if                                 you saw four graphics well but really I                                 don't care they should make it possible                                 I mean you know and we need it and not                                 only we need it basically everyone that                                 wants to do machine learning and                                 artificial intelligence that GPUs will                                 someday in time need it because you                                 don't want to run a GPU every now and                                 when you have a load you want to share                                 the GPU and you want to run the stuff in                                 parallel if possible so it means they                                 just need to implement it okay so we are                                 basically at the end of the presentation                                 now are there any questions                                 yep                                 I think you get a microphone regarding                                 to the network why don't you just go                                 with plain Network managed outside of                                 container network interface because of                                 your in your scale that you describe it                                 it might make sense I'm asking have you                                 considered well basically we considered                                 a lot of stuff and we thought about a                                 lot of stuff but having a network                                 outside of kubernetes means that network                                 has to be maintained Pam                                 well yes sure there's a network that                                 exists around but this network is not                                 maintaining the containers using the                                 kubernetes cluster and you need to                                 integrate the containers in the                                 kubernetes cuttle which would each other                                 and you need to be able to access the                                 containers I allowed balancing in the                                 kubernetes cluster from outside and you                                 want that to be dynamic so seven                                 effectively the kubernetes of death data                                 center on steroids with moving around                                 port and ending in a performance that no                                 real hardware of our software hardware                                 is able to handle this automatically so                                 many manually adding these things is                                 absolutely impossible and the speed of                                 container spawning and being removed is                                 so fast that you need kind of data                                 center technology autumn eyes yeah the                                 point is for example just just to                                 overcome this for a moment you have a                                 kubernetes cluster yeah your Coronado                                 starter has                                                             nodes that have physical addresses in                                 the network layer yeah but on those                                     nodes you have an application of five                                 containers those five containers are                                 running on three nodes now if you come                                 from outside you don't know where to                                 find those pots because the information                                 is in kubernetes it's not outside                                 so what you can do is you can basically                                 have load balancer outside to address                                 the kubernetes cluster on one of the                                 pots on one of the node when the queue                                 proxy will then forward this request to                                 the real node where the container is                                 running and answer answering the request                                 but you don't want that because what you                                 want is you want to have a direct                                 request to the node and the direct                                 answer outside so what you want is a                                 software-defined never orchestrated by                                 kubernetes the only possibility                                 otherwise you have is to have for                                 example a pipe load balancer and have an                                 ingress implementation in kubernetes to                                 orchestrate a                                                            come to high changing and a really big                                 kubernetes cluster the f                                                will just stop working or basically                                 implement the rules probably a minute                                 after it changed and your service is                                 down a minute and then something you                                 don't want to have I think you can                                 discover the more details yeah I think I                                 think you should and it is great                                 opportunity for you to scattered India                                 because you have half an hour a coffee                                 break right now so if you can take all                                 the cases into the coffee break Thank                                 You Thomas thank you Stefan                                 you
YouTube URL: https://www.youtube.com/watch?v=spuuoZLxJfs


