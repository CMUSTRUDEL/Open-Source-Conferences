Title: Berlin Buzzwords 2017: Diego Ceccarelli, Michael Nilsson - Apache Solr Learning to Rank For The Win!
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Learning to rank is a technique for automatically improving the quality of results produced by a search engine. It was initially proposed in academia around 17 years ago and almost all commercial web search engines  employ it in some form or other. 

At Bloomberg, we decided that it was time for an open source engine to support learning to rank, so we spent more than a year designing and implementing it. The results of our effort have been accepted by the community and our Learning to Rank plugin is now available in the latest release of Apache Solr (version 6.4). 

In this talk we will explain how learning to rank works, how we implemented and integrated it into Apache Solr, and how you can use it to improve the quality of the results in your search engine.

Read more:
https://2017.berlinbuzzwords.de/17/session/apache-solr-learning-rank-win

About Diego Ceccarelli:
https://2017.berlinbuzzwords.de/users/diego-ceccarelli

About Michael Nilsson:
https://2017.berlinbuzzwords.de/users/michael-nilsson

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              all right thank you and first I want to                               welcome all of you guys thanks for                               coming and certainly I really want to                               thank everyone for hosting Berlin                               buzzwords and especially guys in the                               back helping us out hooking everything                               up so thank you and from there we'll                               really jump right in so my name is                               Michael Nelson I'm a software engineer                                here at Bloomberg and for those of you                                that don't know Bloomberg is a software                                company in the financial domain and on                                top of you know being able to of course                                do trading you can also use to analyze a                                lot of data one of the things that we                                really focus on Diego and I is in the                                search domain and for search really                                particularly news is one of the big ones                                we've got a huge collection we index                                about                                                                 it's really spiky at time we have value                                on                                                                      we have some isolated constraints in                                terms of speed                                                         time so it's but it's not just search we                                also do alerting but really we're going                                to dive into the search space because                                you know this is what were gonna be                                talking about so what have we been doing                                in the past few years initially we had                                our own proprietary search system we got                                rid of that it was you know pretty much                                news and flexibility and scale so much                                and of course one of the things out                                there that really helps with this is                                leucine and solar so we actually                                migrated to that of course it provides a                                lot of features you know that we didn't                                have of course it's open source and one                                of the great things about that is that                                if you find something wrong with it you                                can contribute back if it doesn't have                                an improvement or enhancement you can                                write it up and you know if it works out                                and it works for you you have a chance                                of actually contributing it back and one                                of the things that we did is contribute                                the learning to rank plugin which is                                upstream Downs Apache Solr six for                                ranking is a really big deal for us and                                on top of that we actually wanted to                                rearrange our results to hopefully give                                us more relevant results so for those of                                you that don't know learning to rank                                really it's just another way of saying                                machine learn re-ranking and just to                                kind of give you quick                                overview you know why would you want to                                do learning to rank of course you have                                your search bar you have your documents                                that come in and one of the first steps                                that you do you kind of tune what you're                                going to search on you've got your                                normal score your documents come back if                                you search for solar here then you're                                like oh I want to tune the titles worth                                more the descriptions may be worth more                                or less and you kind of tweak that and                                your results get a little bit better and                                then you dive into that you're like oh                                maybe document length is important                                freshness you know how recent are these                                documents you know are these going to be                                published today where they published a                                month ago that that matters and you                                spend a lot of time tweaking this you                                got your solar query right but all that                                time you spent tuning it maybe your                                Lucene query now doesn't work you know                                London query doesn't work Bloomberg                                everything so it takes a lot of time you                                have to be a domain expert to really                                dive into this and actually get the                                ranking right so one of the goals with                                the learning to rank plugin essentially                                was to hopefully autumn ah optimize for                                relevancy of this ranking force and                                really get different machine learning                                models of pluggable into the system so                                if you really wanted to you know write                                your own or support new models that we                                don't support you know you can write a                                Java class and hook it in and on top of                                that since it's actually a part of solar                                you get access to a lot of the rich                                features that so it provides for feature                                engineering so what we're really going                                to get dive into here is essentially the                                pipeline to build out a learning to rank                                 system and where the plug-in actually                                 fits into this and just after that the                                 first thing you has to do is actually                                 collect query document judgments this is                                 going to go into your training set and                                 essentially what this is you have your                                 query and your documents you really need                                 to have someone judge where the                                 documents are good or bad now that could                                 be yes/no thumbs up thumbs down good                                 document bad document for this query                                 Apple you can use a star system in this                                 case maybe Tim Cook for Apple is a                                       of                                                                       out of five and then others like apple                                 seeds not really relevant at all but                                 it's up to you to essentially collect                                 that data                                 and there's a couple ways you can do                                 this you can pay judges experts to                                 actually do this manually you can even                                 crowdsource this there are other                                 platforms out there we can use                                 Mechanical Turk you can use CrowdFlower                                 there are ways to actually you know get                                 this kind of curation now another way is                                 implicitly which you can kind of infer                                 this through user behavior                                 maybe you aggregate a bunch of result                                 clicks you can use a few other things                                 like query your formulation or dwell                                 time to kind of imply what that                                 relevance would be for that query                                 document pair so now that you have a                                 bunch of judgments for all your queries                                 and documents that you think are                                 important and a relevance judgment you                                 neither need to extract the features for                                 those documents and for this same query                                 maybe a few of the features that you'd                                 want to extract in this case I have the                                 query match the title that's pretty                                 important you know so that's a feature                                 that you would write freshness how                                 recent was this document published today                                 yesterday you know that contributes to                                 the score a lot of the things that you                                 would put into your solar query those                                 are typically features that you'd want                                 in our case since were from Bloomberg                                 maybe we want our Bloomberg documents to                                 be up there so maybe I throw that in as                                 a feature and how popular are these                                 documents really this is where like the                                 bread and butter comes in feature                                 engineering is really really where a lot                                 of the work goes in that you have to you                                 know really pretty much write a lot of                                 code or configure ization to essentially                                 extract this information so in this                                 particular case with the plugin you                                 would define a file a features a JSON                                 file and this would be a sample of what                                 that would look like in this case for                                 you know the features I just mentioned                                 earlier did the query match the title                                 what's the freshness is it from                                 Bloomberg who popularity now this JSON                                 file where you can fig the features                                 essentially it's a list of these                                 features that has a name so that way you                                 can identify it when you're extracting                                 the features you specify essentially the                                 class that it's going to reference                                 actually the code that's going to                                 execute and inside the prams one of the                                 good things about this is you can use                                 solar queries to define your features so                                 in this case for the match title I'm                                 using the field feature to search on the                                 title and then essentially whatever text                                 is going to be                                 sin I want to see if it matches that                                 field and the output is going to be the                                 score of that and I'll use that as a                                 feature for freshness I'm actually using                                 a function query and this is you know                                 the standard one that you can see on the                                 Wikipedia page and solar essentially                                 that's what has a you know a descent of                                 depending on how recent the document is                                 to get a higher score the older it is                                 the lower the score so that's                                 essentially the equation there but you                                 can use any function query and define it                                 as your features among many others there                                 so once you've actually defined this                                 JSON file you would deploy the solar                                 using a curl command taking the feature                                 store endpoint so now your features are                                 loaded up into solar and then to                                 actually extract the features you'd copy                                 paste this one line this transformer                                 into your solar config so then you have                                 access to the transformer which you then                                 specify inside of the FL parameter which                                 is where you actually want to which                                 fields you want to return in this case                                 we want to return a fake field which is                                 our features field and the value is                                 going to be the list of all the features                                 and the feature values it will be the                                 feature vector which then you can                                 extract and then from there combine it                                 together into training set for you to                                 train your model now now you have your                                 judgments your list of query documents                                 and judgment relevance now you have the                                 documents and the feature vectors next                                 thing you need to do is combine them                                 into a single file which then you feed                                 to a ranking model now there are a                                 couple different libraries you can use                                 to train the model you can train ranked                                 SVM using live linear you can train                                 landmark using ranked live now for those                                 of you that don't know a model is just                                 essentially it's a function that you                                 optimize in this case we want to                                 optimize ranking over relevancy metrics                                 so that way hopefully we get better                                 results on top now these libraries that                                 you use they're going to output a file                                 which is the definition of your model                                 and what you're going to have to do is                                 essentially deploy that model to solar                                 so now you can use it online and query                                 time to be ranked your results now there                                 is a model file similar to how you would                                 write your features file and deploy it                                 to solar it'd be the same process for                                 defining that model file you essentially                                 would just have to transform the output                                 of whatever library are using into this                                 where you specify the class of the model                                 a name so you can identify it so you can                                 use it and then the params section is                                 essentially depending on which model                                 class you're using the definition of the                                 model itself in this case and I trained                                 my model using lambda mark lamda Mart is                                 essentially a force to freeze in a sense                                 and so this is an array of trees and                                 then you know it just branches out but                                 the details essentially is just really                                 when you train your model it's going to                                 output a file and you're going to                                 convert that file into format like this                                 and deploy it to solar                                 now one of the things that we have                                 though is we're going to be doing a                                 demonstration of all of these steps                                 later on and we have code that does all                                 this for you so you can kind of play                                 around with that later on so just like I                                 said with features you then deploy this                                 file to solar so now you can actually                                 rearrange your results and this is going                                 to be online and this is also using the                                 plug-in where you copy/paste is one line                                 into your solar config to get access to                                 learn to rank a parser plugin and now                                 you can actually rewrite your results                                 using the RQ query so whatever query                                 you're using normally you have your Q                                 with your EDA Smacks                                 that's essentially going to give you                                 your you know it's going to give you                                 your top ten results that you see on the                                 first page but it's going to score you                                 know whatever thousands matched you're                                 going to use this to rear Inc let's say                                 the top five top ten in this case top                                                                                                          model it's a bit more expensive so you                                 don't typically use your machine learn                                 model to score all your documents in the                                 collection you only use it on the top                                 ten top end in this case just because                                 it's a little bit more expensive so kind                                 of diving into the actual request you                                 make our Q equals you have the ltr' this                                 essentially is the name of the parser                                 they're going to use this is standard                                 solar notation in this case LTR is just                                 the name of the parser you're                                 referencing which is what we named it in                                 the solar config then the model name                                 that you want to use model equals that's                                 the name of the model that you deploy to                                 solar so that's what I'm going to be                                 using for rearranging this case I just                                 called it my model name and then reran                                 cox is the                                 number of documents you want to rewrite                                 as the top K in this case                                            specified and then efi this is a way for                                 you to pass in external feature                                 information not all features that you're                                 going to use for training your model are                                 going to exist inside of solar you might                                 have a third party system that helps you                                 identify maybe chlorine scent and maybe                                 that's important the query that comes in                                 didn't match the title that also kind of                                 comes from your client that's something                                 you want to pass in so this is a way for                                 you to pass in essentially any list of                                 key value pairs that you defined in your                                 feature set that it's going to use in                                 reference so now that you're rearranging                                 your results of course the most                                 important part really is are you doing                                 better you need to evaluate your results                                 I'm not going to dive into really all                                 the different kinds of metrics there are                                 this is just a very very small subset                                 many of you I'm sure already know                                 precision that of all the results that                                 came back how many are good that's one                                 way to figure out if things are good or                                 bad                                 recall out of all the good documents in                                 your whole collection how many did you                                 return that's another thing you can use                                 to gauge how good things are F store                                 it's the harmonically in between the two                                 and you can kind of tune if you want a                                 favor precision or recall nd CG                                 normalize this kind of human lose gain                                 this essentially takes in the order of                                 the results into your ranking so that                                 kind of also favors things that if you                                 push to the top that's good if they                                 don't make it all the way to the top                                 that's not so good but this is not you                                 know everything there are a lot of                                 papers out there that really dive in to                                 different metrics you can use em are are                                 mean average decision er there's a lot                                 of them a lot of these there's papers                                 out there a lot of these are on                                 Wikipedia you can kind of implement                                 yourself there libraries out there that                                 kind of implement this for you but                                 really this is essentially what you want                                 to use to measure how good your system                                 is before ranking after re-ranking to                                 really kind of gauge how things are so                                 from there it's time for a demo I'm                                 going to hand it over to Diego for us                                 and he's actually going to step through                                 everything that I kind of followed                                 except with you know a real real code                                 and real demonstration so                                 good luck see mine                                 so now I'm going to do something really                                 dangerous that you should never do in a                                 pole I'm gonna give you a live demo of                                 the plug-in so it could be that I mess                                 up but I'm quite confident because today                                 I did a sacrifice a sacrifice to lots of                                 the god of damage so I hope it will be                                 fine                                 before I start I just have a question                                 for you how many of you know knew before                                 what is precision record can you raise                                 your hands okay out of the room okay                                 thank you so so I'm gonna show you use                                 this demo because with Mike we were                                 discussing how to do the pole can we saw                                 that it was nice to show that it                                 actually works so this demo will be                                 available on the Bloomberg guitar soon                                 and it will be it the demo is a fork of                                 loosing solo so it will be a branch in                                 our the seen solar force so in a couple                                 of weeks I will tweet about that and if                                 you go on the Bloomberg github you can                                 download the code and play with it so                                 how that it's work so first of all so                                 the demo will be automatic everything                                 will go out but I just wanted to point                                 out that if you want to use the plug-in                                 the only thing that you have to do is                                 take your solar schema and add these two                                 lights so one will import the ranker so                                 the guy that actually do their banking                                 inside solar and use much learning and                                 allows you to plug in the learning trend                                 models and other features that are so if                                 you feature to the Stormin that allows                                 you to get in in the response together                                 with your document the future vector of                                 all the features I'm going to show you                                 later how you use this so the example so                                 first of all few words about the setup                                 as you probably know in solar there are                                 several examples that you can run and                                 play with one that is quite popular is                                 tech products and if you go on the                                 learning to rank wiki page on solar you                                 will see that we provide an example on                                 tech product so you just run solar tech                                 products and you get you can play with                                 learning it's rank but the text                                 that is really small so you can't really                                 see outwards with a via connections so                                 for this demo we decided to use the                                 simple Wikipedia JSON down so it's a is                                 the pump from Wikipedia                                 we didn't use the English one because                                 you know it's like four million article                                 and it's several gigabytes one let you                                 download it so it was not easy to like                                 share and provide what we use it's a                                 simple so I don't know if you know but                                 there is a particular Wikipedia there                                 are multiple languages you can see                                 Wikipedia in Japanese in English but                                 this one it is called simple and it                                 contains only the most important article                                 explained in a simple English for people                                 that are not really yeah proficient with                                 English like me so it contains only                                                                                                        to ingest and we converted it in jasmine                                 so we use a library that part the wiki                                 text that it's not really an easy format                                 to to process in solar so it parses the                                 wiki text so like old a format that                                 Wikipedia used for the articles and it                                 produces a JSON with nice fields and                                 then we index into solar in the demo                                 deletes a script that does this and not                                 going to show you now because I don't                                 think it's really interesting but there                                 is a script that you you download the                                 JSON file you run index and it's done                                 and and then I changed the way I provide                                 a schema or for this for the Wikipedia                                 articles that contains all the fields                                 that you will see usually in Wikipedia                                 and then there is a copy field tab so                                 when you run a query you by default to                                 read text and this completely contains                                 all the textual field of Wikipedia                                 article in Wikipedia so okay so now we                                 can start actually doing things so I                                 hope everything will work let me go yeah                                 so first thing is just query the                                 collection so if I go on Safari                                 yes so here you see I'm just screening                                 for all the documents and so this is                                 good so I can show you that the size of                                 the collection is really                                         documents and here I'm just getting                                 random                                 document and I get glory as it does                                 first one and you can see the schema we                                 have like many things so we have the                                 title we have things that I highlighted                                 in the page we have the paragraph that                                 is a list of strings one element for                                 each paragraph we have if there is a                                 list in the article we released we have                                 this section the title ID and so on so                                 this is our typical document in the                                 collection so then what I can do now I                                 can try a create so standard query                                 babbling so here I'm just using the                                 default ranking of solar they wanted to                                 get when you stole it for the first time                                 and at the moment in swordstick                                                                                                             results back and the first one with                                 score                                              east-berlin that could be fine I could                                 say that I'm happy if I see spelling                                 start looking for reading but maybe we                                 can do better in this demo so we so my                                 before show you all the steps so I'm                                 going to go through all these steps when                                 you train a model and show you so the                                 first thing is run the demo I am                                 cheating I've already done this I will                                 skip this they're just running demo it                                 will open up a web page and and the                                 first thing that we want to see is a no                                 data collection so we want to create our                                 training set we want to have some quiz                                 and say which documents were relevant or                                 not for for the quiz so this is what the                                 demo merely provides so I wrote this                                 small prototype using flask in Python                                 and so here on the Left I have a bunch                                 of queries and for each query I have all                                 the Wikipedia pages that they default                                 ranking installer returned with me and                                 then I can mark the results relevant or                                 not I was choosing the query so I choose                                 create on which I felt confident that I                                 knew what was relevant or not there                                 could be that there is something wrong                                 I'm sorry so you can see here in green                                 things are relevant in red things that                                 are not relevant so I can show you                                 actually I could say like bernadtom it's                                 relevant so I click and I put it                                 relevant yeah these are things that I                                 know so Italian dishes Steve Jobs London                                 flutes I like to play the flute learn                                 Python and and so on okay so I have a                                 bunch of queries not really much usually                                 you want to have around                                               when you do a training set or more so                                 the more you put the more the better it                                 is okay so yeah I want to have only this                                 at                                                                      I have a training set so I have a set of                                 queries and and judgments and I want to                                 train a model from these so what do you                                 do if you train a model what you need is                                 to have developments and then for each                                 document you want to produce a list of                                 features so what is a feature again                                 micro sorting about that before a                                 picture in our plugin it's just a JSON                                 snippet and one feature that is                                 particularly interesting here is the                                 freshness that tells us how when the                                 document was created actually so the it                                 was code that we want to give to fresh                                 documents to boost them because usually                                 something was created recently it could                                 be that is relevant and so you can look                                 these in the solar week it's explained                                 it's as this is a standard function                                 query that you use when you want to                                 boost freshness and we are just reusing                                 the Select code we don't have to write                                 code to implement these and so all the                                 feature that for the queries that you                                 can do installer you can do it and the                                 score that you get from solar out of the                                 query will be the value of the feature                                 and so you create this JSON file and                                 then you just send it to solar to put                                 request and solar will keep it in this                                 scheme and you can actually browse it                                 from solar I should have it open yeah                                 so this is inside solar you can assure                                 you so if I go on on solar at this part                                 you you will see the feature                                 specification file so as you can see I                                 have the original score                                 by the default ranking formula solar                                 then I have a feature that tells me the                                 length of the title because like if you                                 have a an article that has a really long                                 title it could be that is not what you                                 really want to see you want to see short                                 things that are probably good articles                                 and and so on this score just if I eat                                 on the thighs or the score is had just                                 eat on the sections and so on and then I                                 have freshness again you can see it                                 sorry about that                                 okay okay so another thing that is                                 interesting is that some feature like                                 these will tell you the score of the                                 query if I match the query only on the                                 list                                 filled in in the article and you can see                                 I don't know in advance what will be the                                 query so in order to plug the query at                                 run time we use the special syntax with                                 the dollar so this means that at runtime                                 in the query you will pass a special                                 field called if F I and we put the query                                 and then the query will be the place                                 there are intact and you will get a good                                 value so let's see this in action so if                                 I want to retrieve now this feature for                                 my query baylene I will just add ask for                                 this special field so feature sorry yes                                 please tell me if you can see so I will                                 I'm just asking for particular field                                 features and I of course and passing the                                 query Valene so as you can see I will                                 get the normal steal the title of the                                 score of solar and then I start I get a                                 string that contains of the feature so I                                 get the original score Don roba all in                                 one string so I can use these to query                                 solar and create a training file to                                 train my model so let me show you an                                 example of training file now to do this                                 okay this is a row training file so this                                 is this format is quite usually used in                                 Academy in academia so it's yeah it's                                 quite sad to see but it's just contained                                 so we have                                 advanced then we have a query ID that                                 represents the actual query for a                                 particular query in the training set and                                 then we have ajust a list of feature ID                                 and the value of the feature okay so you                                 get these two the two you're learning to                                 rank methods that have many and the                                 learning to rank method will try to                                 learn a model that try to respect the                                 value of the fit try to predict the                                 developments on the Left based on the                                 values on the right okay                                 there are many ways to do that there's                                 still people inventing new ways to do                                 that and I'm going to issues show you                                 something some of these methods before                                 we dive into training models and deploy                                 them let me just show you something in                                 the demo page so you see here of my                                 relevant sting and on the right I have                                 metrics implemented so that was what                                 micros talking about before so I have                                 just one method here for now so is the                                 default ranking and I have precision                                 recall and that's major                                 and so you see there is a nap after the                                 position and they add them twice so                                 precision as one and and then I have                                 precision of ten the color tan and                                 athleisure at                                                         that when you the idea behind at one is                                 that instead of just computing the                                 precision considering all the responses                                 that you get for your query you just cut                                 the rest onto the first result it is one                                 and you compute the precision as if your                                 method was returning only the highest                                 score result okay and this is a use case                                 that is really important when you are                                 implementing and feeling lucky                                 basically because what you want is the                                 user to type the query and then you                                 redirects and straight to the article                                 and as you can imagine if you are                                 implementing the search function of                                 Wikipedia you really want these you                                 don't want people to go through the                                 results page and then click on what they                                 want you want to send them straight to                                 the article that they are looking for                                 while precision extends become at                                        f-measure at                                       it's a Google page basically you want to                                 optimize the results page so you usually                                 have send the results that the users see                                 so you really want the top ten results                                 to be good you don't care about what the                                 user will see on the second page because                                 probably is not gonna happen it will                                 leave the search page or it will be                                 appear so as you can see precision at                                 one I'm not going to dive into the other                                 measures but position as one means                                 basically that only                                                    for the query contains something                                 relevant on the first position so it                                 means as I'm just counting here so this                                 is good one this is that one bad                                 and then I'm doing the ratio and this is                                 just like it means that only                                         good and                                                              results on the first position so let's                                 say that we want to do better here so                                 the first thing that we want to do is                                 train a linear model okay I'm fine                                 train a linear model it means that I is                                 the most easy thing so I want something                                 that will take the values of the teacher                                 we combine them as in the at the                                 beginning like multiplying them for some                                 magic number and we return me a score                                 where they agree is the score the better                                 it is and so so this will train a model                                 and we produce a model file that is just                                 something similar to this so it's just a                                 magic number that multiplies the value                                 of the feature and then some to the                                 other magic number that multiplies the                                 value of the feature and so on and and                                 this is a linear model so this produces                                 a linear model put it in a nice JSON and                                 send it to solar and then from now on I                                 can just call me banking giving the name                                 of the model and solar we use this model                                 to rank documents and as you can see I                                 get some ways usually you don't we                                 should not trust them with too much they                                 don't mean much like you can say like oh                                 these got highways it means that it's                                 the most important feature but here we                                 can say something there are two features                                 that don't have a way so they are zero                                 basically we are ignoring these two                                 features which type of score and links                                 length it means that the model things                                 that we don't you know they are not                                 useful for predicting the score and                                 actually it makes sense because wiki                                 title score contains underscore so it                                 probably never match the query                                 in my training set and links length I                                 don't know how you can use link links                                 length of the feature so now I loaded                                 the model into solar and I go back here                                 i refresh oh okay and you can see there                                 is a new model if I click on it yes I                                 get the new ranking using this model and                                 it doesn't look really good yeah                                 so as you can see if I will remember it                                 doesn't look good but the matrix tells                                 these as well so it's not just looking                                 at the result it's really numbers we                                 have numbers that confirm what we are                                 seeing                                 so you see precision at one it's worse                                 actually and yeah the other numbers                                 that'll look great too and the reason                                 for this is that this is just a linear                                 model it doesn't have any knowledge of                                 the ranking is just considering each                                 document stand alone and tries to                                 predict this the final score out of the                                 feature so we can do better there are                                 learning to rank algorithm let's look at                                 the world list that's why in the                                 training set                                 with the query ID and they try to push                                 relevant results on the top and one of                                 these models is rankly and if the model                                 is not cleaner so it's not like that you                                 can do a combination of stores and you                                 get it it's something that is more                                 complex and it's based on tweets so you                                 browse through trees using the featured                                 values and at the end you get that at                                 the end of the tree you get scores that                                 you combine together and these                                 particular library frankly allows you to                                 train your model to optimize a                                 particular metric so in this case I can                                 tell frankly to optimize train a model                                 optimizing precision at one okay so I                                 hope it will go fine so yes so a train a                                 model it did several iteration to try                                 try to optimize over the training set                                 the model and in the end you gave                                 obviously I think I reach the optimum on                                 this training model and I got the                                 precision of one                                                         here it's in solar and you can see                                 position at one is now                                                here and watch your results and you see                                 now it looks better so if I go through                                 you can see that actually many results                                 are green on the top now so it's pushed                                 relevant stuff on the top and if we look                                 at the other metrics we see that now we                                 are really good on precision upon recall                                 that means the number of relevant                                 results on the top increase but still                                 like at                                                                like the default model is still doing                                 better and we are not improving here so                                 what we can do we can try to improve and                                 ECG that is a measure that look really                                 at the ranking so if you are just                                 looking at position of                                                computing the ratio between the relevant                                 and then not relevant results so if you                                 have                                                                  five to position                                                                                                                          relevant on the top                                 but if they are on the top which is                                 better yet precision is still at                                        you don't really get the difference and                                 this is G gives you different values so                                 if they are on the top you will get an                                 ECG one if they are on the bottom you                                 will get I don't know how much probably                                                                                                          optimize real ranking and the CG then                                 and now I got NBC GSN                                              refresh here I get like better I get                                 precision at                                                           results on the top are always relevant                                 you can see so always green not here                                 well I didn't didn't press ok so back                                 Green Green Green Green Green Green                                 happy so as you can see now it's                                 slightly better but still as measure                                 repetition is slightly battery here                                 recall it's the same and the at measure                                 that is just the average of the two is                                 still the same so again you can do                                 better because there are a certain                                 number of trees that these things use so                                 we can increase the number of three and                                 the model will become more specific so                                 it's bigger now so it will take up some                                 time to load yeah so if i refresh now                                 yeah                                 so here again like now I guess at                                 measure                                                         precision of                                                          good so sorry                                                        real life if you see precision at one                                 it's a precision at one equal to one it                                 means that you have a problem because                                 this is something that should never                                 happen it means that you are God and you                                 predict everything and in learning rank                                 it means that you are always fitting the                                 model that's what I am doing here                                 basically basically it's learning for                                 each query what to return                                 and this will means that it's gonna work                                 really well on your training set but                                 then when real users start to ask                                 different things you're probably retinol                                 and crazy things so what you do in real                                 life is that you don't have a small                                 training set but you have different                                 query set and you train on one and then                                 you evaluate on a different one with                                 different queries so you're sure that if                                 you have a new query                                 you're still going good and I have an                                 example here so I have the query Rome                                 pre Rome is not in the training set so I                                 didn't train on this query and if I                                 perform the query wrong here I will get                                 the first result piece of state in in                                 u.s. that is not really what I would                                 expect if I search for Rome                                 if I use a model that is NSG at                                       using                                                                    city in Italy and then I also get like                                 clothing in hands and thrown that still                                 makes sense so it's actually better than                                 the default also if I didn't train on to                                 optimize this particular query so yes so                                 that's all I hope you enjoyed the demo I                                 didn't a very unhappy and now if you                                 have questions we are ready to take down                                 Thanks                                 [Applause]                                 hey thank you can you just talk a little                                 bit about roadmap for learning to rank                                 in terms of adding support for other                                 models and new types of features like                                 that say thanks again so there is this                                 discussion like at the moment when we                                 did when we designed the plugin we                                 assert that a feature is a float and you                                 cannot really have different types of                                 feature and the reason for that is                                 that's like also them like the file that                                 you usually use to Train do the same                                 assertion so a feature is always a float                                 and models that I usually use after the                                 same thing so I'm not sure it's like                                 that if they need to to use different                                 output of different types for a feature                                 but I'm totally open to discuss this                                 being and yes yes I have a ton more                                 think so right now the features that you                                 define it's kind of one-to-one with the                                 features you define and the features you                                 extract but in many instances maybe you                                 want a single feature function to                                 actually output multiple feature values                                 in one go right now the plug-in itself                                 doesn't easily support that it is                                 one-to-one one feature in one feature                                 out one thing we would definitely like                                 to do because we use it as well is maybe                                 we want to find you know ten features                                 and then outputs                                                         would really help in terms of you know                                 us developers writing this stuff would                                 also help in performance too so that's a                                 big one too that we really want to do on                                 top of that in many instances you want                                 to Train chained together ranking models                                 so you have solar that you know                                 essentially ranks your first                                        documents and then you use this to rear                                 Inc maybe the top                                                     just a single second pass it would be                                 nice if then you wanted to do a third                                 pass or a fourth pass on top of the                                 Arirang                                                                                                                                    maybe figuring out the prices if that's                                 low hitting your database you don't want                                 to do that for all your documents so                                 really chaining these together is                                 another thing we would like to do as                                 well                                 yes does it to be a lot of work to do                                 yeah for sure if you guys have ideas or                                 you know you have a use case certainly                                 please contribute back I'd be great yeah                                 and lining the Machine can cover thank                                 you actually I have two questions so                                 first hope humbly we can answer                                 questions to you afterwards we'll be                                 around yeah Larry how much effort do you                                 put in generating a gold standard that                                 is if you go on your Wikipedia data you                                 have your priests so do you really need                                 the first                                                            whether they are relevant do you look                                 for other documents not on the first                                     which might just be very relevant but                                 only match because they contain similans                                 of you free so how much everything is                                 saying about really getting your                                 training set it's like it's a big effort                                 right the bigger your training set the                                 better your model will be you use a                                 combination of explicit data maybe you                                 have your experts in house that judge                                 things right maybe you also send stuff                                 outside to the crowd maybe you have a                                 bunch of popular documents maybe you                                 send that out there too it's essentially                                 you kind of really have to combine                                 everything together to really get a good                                 set of documents that are always on top                                 documents that are always at the tail                                 end something in the middle so that way                                 your model can really pick out the                                 things that are really good about a                                 document and things that are really                                 really bad and knows to push those down                                 so really is it's an ongoing thing it's                                 never like here's my training set and                                 I'm done you always add to it every                                 single time and really like if you find                                 a query that's bad you should kind of                                 curate that add it to your test set or                                 training set so it's just always ongoing                                 so it's a big effort and those I think                                 how you do that depends really by the                                 use case so based on which type of                                 service you have which type of documents                                 which type of users you you want to use                                 different ways to create a training set                                 you still need humans it's not all                                 automatic now that's cool thank you very                                 much we are really tight on schedule and                                 as you know the rooms are quite far from                                 each other so                                 so thank you very much giggle Michael                                 [Applause]
YouTube URL: https://www.youtube.com/watch?v=u8xLuxfMx98


