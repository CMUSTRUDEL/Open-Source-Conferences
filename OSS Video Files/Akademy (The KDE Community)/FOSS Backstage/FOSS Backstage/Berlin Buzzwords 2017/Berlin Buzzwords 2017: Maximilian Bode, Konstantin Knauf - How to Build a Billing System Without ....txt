Title: Berlin Buzzwords 2017: Maximilian Bode, Konstantin Knauf - How to Build a Billing System Without ...
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Traditionally, big data applications rely on the Lambda Architecture in order to achieve low latency as well as completeness. A streaming layer provides real-time previews while a complementary batch layer retrospectively recomputes the correct results. Using a robust stream processor like Apache Flink, we can do without the latter. But can we take it even one step further? This talk will discuss one of the upcoming features of Apache Flink with the potential to do just that.

As a real-world example we have built a prototype for a robust billing system based on Flink and Queryable State. On the one hand, the system exposes the current monthly subtotals in real-time to front-end applications, on the other hand it reports the complete results to downstream systems, e.g. for invoicing. As completeness and correctness are core requirements for a billing system, we will demonstrate the system in multiple failure scenarios, including taskmanager and jobmanager failures as well as unavailability of downstream systems.

This talk will give you an idea of how "Queryable State" combined with a robust stream processor enables new streaming use cases and changes the future of streaming application architecture.

Read more:
https://2017.berlinbuzzwords.de/17/session/queryable-state-or-how-build-billing-system-without-database

About Maximilian Bode:
https://2017.berlinbuzzwords.de/users/maximilian-bode

About Konstantin Knauf:
https://2017.berlinbuzzwords.de/users/konstantin-knauf

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              yeah hi and welcome to this session with                               my colleague Konstantin my name is                               Maximilian and we both work for T and G                               technology consulting which is                               munich-based                               and focused on high-end IT consulting we                               are currently I'm especially focused on                               distributed systems and particular                               real-time processing we both work for                                four telef√≥nica Germany where we have                                built a platform that's processing                                billions of events a day and we are                                proud to say that we are running linked                                in production since the beginning of                                last year what is this talk going to be                                about and you have already from the                                title it's about variable to date so in                                the first part we want to talk a little                                bit about what that is give you a bit of                                motivation secondly we want to share                                with you a use case um in this context                                and requirements of this use case we                                build a prototype um for billing system                                and in the third and a large part of the                                talk we are going to take this prototype                                through different failure scenarios and                                show you how it behaves it's Mike                                somewhat off working yeah okay can I                                continue yes okay so let's give Zara's                                variable stage it's as I've already told                                you it's a feature that was introduced                                in swing one or two um and I want to                                give firstly a quick motivation about                                that um so in the next few slides                                um let's together consider a system with                                two somewhat competing some requirements                                on the one hand you need the system to                                be able to guarantee correctness but                                then on the other hand you want to be                                able to generate low latency inside so                                for example                                of some kind of a webshop where for each                                user you want to know exactly how many                                clicks he had in a day and you want this                                number to be exact but then you also you                                also need um let's say every minute the                                average clicks across users or something                                like that so traditionally what people                                have used in order to solve problems                                like this is a dual approach known as                                the lambda architecture I'm sure many of                                you will know this um so here you have                                two dual layers feed layer with a stream                                processor for example storm but this                                this delivers low latency results but                                can't really be trusted correctness wise                                and then you have a batch layer running                                MapReduce jobs one today and that that                                really computes correct results to be                                trusted right and and so one could see                                some some problems with this kind of                                architecture you have this separate                                systems that you need to develop for in                                different frameworks you have to operate                                the system separately                                um so modern stream processors yeah                                super off okay come video do you want to                                talk to me yeah I think you can give me                                any ways no okay yeah so where was I                                modern stream process is like a kerchief                                link um that are fault tolerant and                                resilient against failures enable us to                                do away with this patch layer so in in                                flink you could just aggregate the those                                minute wise aggregations I talked about                                and put it into a key value store but                                flink can guarantee you also under                                failures and that the results will be                                correct at the end of the day so this is                                the step forward but still um one has                                this external key value store for                                example Redis or whatever                                that needs to be operated operated that                                needs to be scared independently of your                                processing and your stream processor in                                order to give these strong guarantees                                already has to be able to keep track of                                the state internally so why don't we                                just go directly to the stream processor                                and that is what we will state does so                                if you know want to see what what is the                                current average over the last minute of                                clicks you just ask the stream processor                                that's the idea about variable States I                                hope I could give you some motivation                                even though there were technical                                problems but now Constantine is going to                                talk about how its implemented in flink                                right good afternoon for myself as well                                 so I'm guessing most of you know what                                 Apache Fling is just to just to recap                                 the different components they are you                                 have the chart manager which is                                 basically the master node so to say                                 which does all the coordination between                                 the different task managers but it                                 doesn't do any of the work itself and                                 doesn't hold any state and then there                                 you have a lot of you have a lot of task                                 managers multiple task managers which                                 actually do processing which are the                                 workers and the case of Kerrville state                                 you also have the Kerrville State client                                 which is just some process outside of                                 the cluster I think right now it's only                                 possible with the Java process but for                                 only Java client is feasible but                                 separated from everything else okay                                 let's look a little bit into more detail                                 how this thing works for querulous State                                 so as I said the status so we'll focus                                 on the green boxes right now so the                                 curve will state as I said is only what                                 the state is only located in the task                                 managers so for the Kyrgyzstan client to                                 retrieve the state it goes to the task                                 manager directly so the query will state                                 client which is in the client code the                                 key value state client goes to the key                                 value state server of the task managers                                 the most frequently used sort of state                                 and flink is keep state so depending on                                 your key the state is distributed about                                 among multiple task managers so if you                                 now think of the key s whistle                                 subscriber then for different                                 subscribers the key is located on                                 different task managers now the key                                 values the cruellest a client needs to                                 know which cat has managed to go to for                                 a particular for a particular subscriber                                 so since the tasman is or since the duck                                 has no way to know it has this key value                                 state location lookup service which                                 exactly does that it asked the job                                 manager where does subscriber a has its                                 state and then it goes directly for the                                 task manager for the actual data these                                 are basically the purple boxes so how                                 does the job manager know where each                                 state is located on the task manager                                 that's just through the usual occur                                 based notification services between the                                 task management job manager it's just a                                 different account different occur                                 message that the husband just sent to                                 the job manager same way as for example                                 I finished processing this task or I'm                                 I'm currently opening this operator so                                 then the only thing the Kerrville state                                 client needs to know is the job manager                                 and if you have a high availability set                                 up their mouth full job managers so it                                 has to know the active job manager                                 because only this job manager gets all                                 the updates and for this this the leader                                 retrieval service it's now also wrapped                                 into a high availability service I think                                 but basically this we need a retrieval                                 service which is called every time                                 there's a job manager failover so what                                 you should take away from this slide is                                 basically that global State is over or                                 usually it's only communication between                                 the client and the task managers and the                                 top managers only ask once where does                                 this key live and then this is cached                                 because so that's important basically to                                 understand the behavior and some of the                                 failure scenarios we will see in the                                 demo when we kill task managers when we                                 kill shell managers okay ila any                                 questions so far                                 all right                                 so just a quick introduction of our use                                 case we called it queryable billing and                                 basically a prototypical use case which                                 we have condensed from mainly one                                 project we've seen at our client not our                                 own project but a yeah                                 adjacent project so to say which was                                 solve completely differently but then we                                 heard about core of the state and flink                                 and we're like ok most of that we could                                 have done both links and we just wanted                                 to try out how how could one solve that                                 that's for the background so what were                                 the requirements                                 basically you have a telecommunication                                 Network and this telecommunication                                 network generates a couple of events a                                 lot of events usually and these events                                 need to be built so if there's a call                                 there's a text message data usage Peck                                 texts which are booked like daily Fred                                 sled race and this kind of stuff and all                                 these events are collected from the                                 network component and they go into the                                 system and the main purpose of this                                 system is to aggregate them over months                                 aggregate the usage and then forward                                 this information to the downstream                                 system which in our case we said is the                                 invoicing system which is able to send                                 mail in mail invoices to customers                                 besides this main use case we also have                                 a site use case which is on the bottom                                 we also want our clients to give our                                 clients the opportunity to query their                                 current usage in the month by a web                                 application and you can probably already                                 guess variable state I'm just coming in                                 here the one at the bottom is very                                 similar from technical                                 a few very similar requirement probably                                 wants management has heard that you can                                 do this kind of stuff they want some                                 dashboards to do some real-time                                 monitoring monitoring on marketing                                 campaigns and so on                                 maybe you split by different usage                                 scenarios textbook packages which is                                 booked and so on and so on so these are                                 basically the functional requirements                                 but there are also some some quality                                 goals first of all there's correctness                                 we're dealing with invoices here if you                                 send out a lot of invoices with which                                 over count events and stuff like that                                 you will have a lot of a lot of traffic                                 in your user desk and ya lose money this                                 way the other way around you lose money                                 directly by charging people um to view                                 so that's correctness that's number one                                 criterion then you also have robustness                                 if we're dealing with with a distributed                                 system here you always have partial                                 false task managers go down shop                                 managers go down um maybe the the                                 invoicing system goes down so it needs                                 to be robust to these kind of failures                                 but it also needs to be robust to out of                                 order data to late events especially                                 events are coming from such a                                 heterogeneous network as a                                 telecommunication networks were also                                 always some qualified can have a lag of                                 half an hour or events just don't and                                 look forward to through this data center                                 anymore availability is not that much of                                 an issue if you only want to write                                 invoices I mean it only has to be                                 available at the end of the month                                 basically but once you want to also                                 enable the customers to query their life                                 usage you want the system to be up and                                 running most of the time at least                                 scalability is not a core requirement                                 here and of course it's nice if it's                                 elastic because then you can scale it                                 down during the night where they are                                 much less event but yeah we will only                                 basically we won't do that you                                 okay now let's let's talk about the                                 architecture and Maxwell do that so so                                 as far as the technology spec is                                 concerned that we chose to use for this                                 prototype                                 so your basic sketch of that so on on                                 the left hand side you have antennae                                 which signalize will just probably                                 stands for data generator and that we                                 use to generate events that then are to                                 be built somehow and this the data                                 generator has some amount of determinism                                 inside it but also some amount of                                 randomness we are going to go into more                                 detail on that later                                 and then those events are certainly                                 written to to Kafka which is a                                 distributed message message broker might                                 ask you if you haven't heard of that and                                 from where our main component reads in                                 those events which is a fling job the                                 little squirrel over there and then the                                 invoices are written to a distributed                                 file system and the idea is that from                                 this distributed file system the another                                 adjacent system that then sends out                                 mails a mail with the bills to our                                 customers could could fetch those final                                 bills and not not to remarks                                 particularly interesting for people who                                 are already somewhat familiar with link                                 um first notice that this configuration                                 reading from Kafka and writing to a                                 distributed file system it's one where                                 exactly once as possible right because                                 in the case of failures you can restore                                 from a checkpoint and and then you can                                 on the one hand rewind your Kafka source                                 and also truncate the file system and                                 then you can start reprocessing without                                 duplicating any events right and then                                 secondly um well minor point but this                                 this the fact that we are using a                                 distributed file system well we chose                                 that for this prototype but one could                                 have as well this invoicing system yeah                                 being implemented as a service that                                 accepts idempotent HTTP requests yeah                                 and and it worked worked just exactly                                 the same                                 so that was the horizontal lane of                                 invoice creation now for the for the                                 part that's actually concerned with                                 queryable state from our perspective the                                 variable state lines is still a little                                 rough around the edges you probably                                 wouldn't want to put put it directly in                                 your front end so what we did is wrap it                                 in a spring good application and then                                 the JavaScript front-end can fetch its                                 data from there and also here on the                                 right hand side you could build a                                 dashboard and it was like Kahana and but                                 we aren't going to go into more detail                                 here because it's functionally just the                                 same and so rather let's zoom in on the                                 flink job the job graph for those                                 already familiar with pictures like this                                 is what a fling job graph looks like                                 isn't super spectacular right so on the                                 left hand side the events from Kafka are                                 all right in timestamps are assigned                                 watermarks are emitted and so on and                                 then we we want to aggregate a                                 customer's usage for the month so we do                                                                                                     these events up um basically sum up the                                 billable amounts and then write out                                 using marketing thing which is strings                                 standard way of writing to a distributed                                 file system and then what one actually                                 would like to do in an ideal world is                                 make this state in those windows                                 variable directly unfortunately right                                 now that's not possible                                 um so just as a quick technical aside                                 how did we do with this I'm basically                                 duplicated the whole logic with a false                                 function and trigger the windows on each                                 event that comes in and then in the                                 window function that is applied on each                                 event and this date can be made credible                                 so this is the second block that you see                                 on the right-hand side of the graph and                                 slot is basically the same but not keep                                 by customer but keep by event type so                                 how many calls whether and this month                                 how many                                 messages that actually builds how many                                 bookings or flat rates or whatever yeah                                 now we are going to go into the most                                 interesting part so talk                                 yes our demo so we basically set up the                                 whole system in a darker setup so let's                                 just do to give you a rough idea how                                 it's all set up let's see what                                 containers there are and if there are                                 any questions during the demo anything                                 looks suspicious or dubious please ask                                 right away many people from the back                                 reef resource or yeah okay so as you can                                 see we have I think                                                    are four containers which are just a                                 fling cluster to job managers and to                                 task managers so that we can kill one of                                 them and it's still somehow working then                                 there's a one casket broker which makes                                 up the whole casket cluster and                                 zookeeper at the bottom which supports                                 Kafka and also the job manager high                                 availability of link and then there we                                 have four containers which are basically                                 the queryable billing from the data                                 generator which just generates these                                 data all the time these events and put                                 them into Kafka then there is the job                                 itself the QB job which is just the                                 client which submitted to the job to the                                 cluster and doesn't do anything                                 afterwards there's the QB server which                                 is this small spring boot application                                 and the front end is also a separate                                 container which just serve statically                                 the the content for the web application                                 ok so let's first recap the requirements                                 and we will basically go through them                                 and check them during the demo so we                                 have the functional requirements which                                 are on one hand correct invoices on the                                 other hand live updates verbal wireless                                 API then we have the non-functional                                 quality goals                                 which is correctness availability we                                 won't look at scalability because we                                 only have nine customers in this demo so                                 we can say anything about scalability in                                 terms of keys and was only one laptop so                                 yeah robustness at the other hand we                                 will look at later driving event out of                                 ordinance we'll look at tasks manage and                                 job manager failures and also we'll look                                 at failures of the downstream system so                                 just basically the billing system the                                 invoicing system okay let's start with                                 just invoice generation so - so what you                                 can see here is first of all the link UI                                 up there the job is running for                                    minutes now and data is being generated                                 so let's let's have a look at the stream                                 of data which goes into can we so it's                                 that readable from the back yeah okay                                 so basically the events just have a                                 timestamp they have a name Emma Sophia                                 Noah and so on there's some euro amount                                 and a type package message and so on and                                 what the state of generator basically                                 does is it generates random amounts but                                 they always add up to the same value for                                 each customer for each month so it's for                                 Emma for example is always                                              the end of the month everything went                                 well so this is our way now in this demo                                 - to see if we lost any elements or if                                 we over counted if at the end of the                                 month it's always an even amount for                                 each customer then that looks good so we                                 said we were writing to a distributed                                 file system for this docker setup you                                 might have noticed we didn't set up                                 anything like HDFS or something like                                 that so what we are just did is we                                 mounted a darker volume to all the                                 containers or to the flame containers                                 and we use this darker volume as kind of                                 a mock distributed file system                                 it behaves surprisingly similar in some                                 case yeah actually there are some                                 problems but yeah so here we have then                                 one folder for each month and if we look                                 into it it just gives you the month the                                 subscriber user and then the sum so as                                 you can see it's all even amount but                                 there's actually one amount which is not                                 even which is William in March                                       started at at the FO                                                   how how we get about                                                month the event time progress in this                                 demo so William had two hundred forty                                 nine ninety four but then there was a                                 late arriving event so the window got                                 fired again if you're familiar with                                 things way of dealing with lateness                                 so we window always fires when the check                                 point for when the watermark for this                                 time passes but then you can also say I                                 want to keep the stayed around for some                                 more time which is called a loud                                 maintenance and if another event comes                                 after that                                 it will fire again and that's what you                                 see now here in case of severe when                                 there was one event event missing and                                 the window got already fired but then                                 there was an update afterwards with late                                 and arriving events so if we go back to                                 our requirements inverse generation                                 works I mean it's pretty basic but it                                 works correctness works at least in the                                 case where everything goes right which                                 is easy and robustness late events work                                 out of ordinates also work other works                                 so this event stream we didn't see it                                 but the event stream is pretty out of                                 order actually and there are some late                                 events as well these we saw so let's                                 also have a look at the live updates now                                 so as we set this spring food                                 application basically exposes more wraps                                 the queryable state client so we can do                                 a                                 you can just squirrel this service and                                 here for example we get the current we                                 basically going to customers Emer and we                                 get the current amount and this amount                                 increases increases and at at some point                                 it's at                                                                next month again um so this this also                                 works but - we can also have a look at                                 at the type yeah you can also query for                                 the type call for the type text message                                 I think yeah but that's not that                                 convenient for the demo now because we                                 want to see how does it behave if we                                 kill a task manager for example so we                                 basically just have this very small                                 front-end which every two seconds                                 queries this spring good application and                                 it shows the current the current usage                                 of this customer as long as this                                 timestamp is screen it means that it                                 reached the service and the service was                                 able to query this link cluster so yeah                                 right now it's running so I think we can                                 go back to the requirements and check                                 live updates and now start with the more                                 interesting stuff killing the D                                 component so let's start with the task                                 manager so we were just going to kill                                 one of the top managers so and since                                 this clusters very poorly provisioned                                 this will render the job yeah not                                 restartable                                 because we don't have enough slots of                                 course in any setup you wouldn't want to                                 do that but here gives us a little bit                                 more control when the job starts again                                 for those of you who paid attention you                                 saw that either was life a little bit                                 more longer than Emma that was because                                 we killed the task manager where the                                 state of Emma resided and the other task                                 manager that's the the                                 beauty of distributed system it didn't                                 know that the other task manager was                                 killed and keeps running the job and was                                 still able to serve the request by the                                 quill estate client and only when the                                 job manager realized okay the staff                                 manager has gone I need to really                                 restart the job job from a check point                                 it killed the job on the other task                                 manager and either wasn't able to serve                                 these requests or the task manager                                 wasn't able to serve the request for                                 either as well                                 so now let's let's restart the task                                 manager so that we look at the inverse                                 we can look at the universal yes so we                                 are in the last last in words we got                                 were from November                                                    look at the current date and the current                                 date in the lock we have                                         February                                                               that it basically crimes through the                                 catalog and outputs all the invoices                                 correctly so let's restart the task                                 manager and see if the job comes up                                 again                                 okay it's run again and yeah                                 Cuervo states also accessible and again                                 it's basically you can already see a                                                                                                        went through the backlog so let's have a                                 look at the invoices all even amount I                                 think so that looks pretty good                                 and we're also up to date so we have                                 event from April and last invoice we                                 have are from March so that looks good                                 okay so Tasman is a failure it seems to                                 work availability is is compromised                                 though so as long as the job is not                                 running the crew states also not                                 accessible but keep in mind that                                 normally this job would be restarted                                 pretty much instantaneously as long as                                 they are not enough task club and                                 usually your cluster would be                                 provisioned in a way that you can cope                                 with a couple of task manager failures                                 and the job can be restarted immediately                                 but there is a small downtime                                 that's not any case okay let's look at                                 shop manager failure so um which job                                 manager are we currently running on to                                 job manager - okay yeah then we kill                                 jump venture - and see what happens so                                 again the jump managers is that but we                                 will State still works because it                                 doesn't communicate with the job manager                                 once it's running so only when the time                                 out of the leader election service                                 basically                                 kicks in and realizes okay there is no                                 job manage anymore the task managers                                 will be killed by the new job manager                                 and then the cruellest state will not be                                 accessible anymore so again the same                                 like distributed system it's                                 yeah at its best that's irony vanuit                                 okay now we can have a look at your                                 manager one I think yeah so new job                                 managers here but it hasn't recovered                                 the job yet it will eventually yeah I                                 know the core was declined connected to                                 the new job manager and basically run                                 through the all the events from the last                                 checkpoint we can also have a look at                                 the invoices again there are any and                                 even numbers there is one uneven number                                 but there is another update afterwards                                 which brings it up to                                                    for Emma yeah looks good so correctness                                 also in case of job manager failures                                 availability again is a little bit                                 compromised during the switchover but                                 that's also a very short amount of time                                 okay last but not least failure of a                                 downstream system so what does                                 downstream system mean in our case we're                                 writing to the file system so our dancin                                 system is basically the file system if                                 we were writing or if we would do                                 idempotent calls through some REST API                                 it would be the in this service the                                 behavior is pretty much the same so what                                 would we want to have to happen since in                                 these architectures basically Kafka is                                 always the fallback layer we would                                 actually want the processing to stop and                                 the events being yeah saved in Kafka                                 persisted in Kafka and once the                                 downstream system is available again we                                 want to run through the backlog and send                                 all the events to the downstream system                                 so what we are doing here now is as I                                 said our distributed file system is this                                 this docker volume which is called                                 invoices I think or the folder is called                                 invoice and we'll just move it to                                 invoice archive and see what happened                                 and what happens so nothing happens                                 because the month is not over yet so it                                 doesn't try to write out that's why                                 everything is going well right now and                                 at some point it will fail we can                                 already look what the invoice archive                                 last month is now I try to write out and                                 the job fails and is now basically stuck                                 in this restarting restarting failing                                 loop because now it when it starts up I                                 think it checks whether the file system                                 is available and it's not available in                                 this case if it wouldn't do the check it                                 would fail directly in any case because                                 it then goes for all the event and calf                                 guard is then stuck when writing out                                 again so it's running again it's and so                                 on and during the whole time horrible                                 State client test is no way of                                 retrieving the current current usage of                                 the customer                                 okay let's recreate the directory to to                                 end it okay now it's successfully                                 restarted and again go through the                                 catalog yeah let's what was last month                                 it was in November                                                    month which we moved and now it starts                                 with December and all even amounts so                                 again no duplication and no I know lost                                 messages so again it correctness is not                                 all correct ensign in these cases the                                 invoices are correct and complete but                                 availability is pretty much compromised                                 to some it's basically your couple your                                 current state of your computation to you                                 computation so you don't have any any                                 fallback right now if you if you wish                                 stopped summing up you don't have access                                 to your current sum which is a lot                                 different as if you were writing the sum                                 to register for example and we're just                                 updating there then at least it's                                 filling cluster goes down you still have                                 the last you last some in red                                 okay so let's I already started a little                                 bit let's look at some of the the                                 limitations we have with kuru state                                 right now so first of all some of you                                 might have noticed the way we built the                                 Kerrville state now or and the way we                                 use the group will the state now is that                                 we have one state perky but it's not                                 scoped to the window so it's for someone                                 for those of you who are more familiar                                 with link it's basically only heat but                                 the name space is always the void main                                 main same space so there's no way to                                 query the sum for two months at the same                                 time for one customer it's always just                                 the latest the month of the latest event                                 but this will there we saw that that                                 they change it with one three but there                                 wasn't anything done with Kerrville                                 state and one three so I think it was                                 all postponed to one four but it's                                 pretty small six so are pretty small                                 additional feature see and I guess they                                 will leave it in one for the client API                                 max already said it it's pretty                                 cumbersome right now so basically you                                 need to link configuration you need to                                 need to do all the flink type                                 serialization stuff which is not not                                 really convenient so you would want it                                 to be basically aresko I think because                                 then you can really use different                                 clients and not just Java or Scala                                 client where you can basically use these                                 class                                 state size of course is also a                                 limitation so if your if your job                                 I don't know who was in the Stefan's                                 talk a last session but basically as                                 long as as long as you have if you don't                                 have the throughput requirements that                                 you cannot use for CB then you have no                                 limit here but there might be a                                 performance penalty at some point for                                 critical state but if you need to use                                 the memory memories state back-end for                                 performance reasons then your state size                                 cannot be larger than your main memory                                 and last I already touched upon it a bit                                 availability in case of job failures is                                 basically always a problem if your job                                 doesn't come up immediately I mean can                                 do caching and all other stuff so in a                                 lot of case it should work but it's                                 definitely you definitely couple your                                 results to your ongoing computation                                 which is something you should think                                 about ok that's basically it you can                                 check out the code in the slides on                                 github play around with it yourself a                                 little bit and yeah we're happy to take                                 any questions yeah thank you very much                                 much in confirming Maxis the man in the                                 dark here at content in action ok so any                                 questions yeah so could you maybe                                 elaborate a little bit on the                                 limitations you said with state size                                 because I'm interested you said you had                                 a your window was basically                                              would imagine that your very large                                 amount of data in the window and also                                 did you have maybe some problems with                                 the slide of the window because we ran                                 into some problems with having a window                                 of                                                                       to slide by one minute                                 so a lot of copies of the same objects                                 in the data and we had a lot of garbage                                 collection issues whatever so I don't                                 know maybe just some of your experiences                                 with these types of issues so in this                                 case there weren't any any issues                                 because only nine keys and also it's                                 even for for a lot of customers                                 so think about                                                         like that                                 it still shouldn't be too much data                                 because there's always a fault operator                                 as or in this case that it's just one                                 number so it shouldn't be in the                                 gigabyte let's say the state even for                                                                                                         on but yeah we didn't we don't have any                                 sliding windows here I think I saw the                                 mailing list threat on on these here on                                 the yeah many slide yeah it's definitely                                 limitation but I don't have any solution                                 on it I think it's yes it's basically                                 how the windows work and think right now                                 that if you assign it to multiple                                 windows then it's always duplicates the                                 state and that's especially problem if                                 you don't have a fault or reduce                                 functioning for pre aggregation of the                                 window state there's I think talk from                                 from from Stefan as well who's talking a                                 little bit more about how will the state                                 scales in terms of number of keys and                                 state size so it's if you're interested                                 or anyone is interesting especially into                                 a horrible state scales then you should                                 check out check out this this talk I                                 don't know the name but you'll probably                                 find it if if you look for the screen                                 processor at the database                                 Stefan Devon or something less okay                                 so I may not be super familiar with                                 blank but sports the query ability of                                 this data set how flexible is it like in                                 terms of aggregate aggregation or the                                 sort of the time window terms are cactus                                 appetizers it may be a similar question                                 is what someone just asked but I'm                                 assuming because it's a key/value kind                                 of a store a lot of the querying                                 essentially just give me everything for                                 this key for this time period and then                                 just do all the aggregation in code                                 essentially is that it's a fair way of                                 yeah yeah good question so basically at                                 runtime or a query time it's not                                 flexible at all so the way it's                                 implemented right now you the whole                                 aggregation and the time periods has to                                 be um has to be hard-coded or made                                 configure all or whatever but you you                                 can't decide at at very time now I want                                 to do this kind of aggregation um you                                 could of course just fetch the raw data                                 and then aggregate in some fashion but                                 but the objects basically can be any any                                 Java object which is state so it's just                                 need to be able to to serialize and                                 deserialize and the same serialization                                 deserialization penalties apply which                                 apply to all the state animation okay                                 then thank you very much focus talk                                 thank you thank you                                 [Applause]
YouTube URL: https://www.youtube.com/watch?v=QPnJfumBOl4


