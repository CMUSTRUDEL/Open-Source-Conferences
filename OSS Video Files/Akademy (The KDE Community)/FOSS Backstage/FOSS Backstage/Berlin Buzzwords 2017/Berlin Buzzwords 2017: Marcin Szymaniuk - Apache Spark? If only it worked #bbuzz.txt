Title: Berlin Buzzwords 2017: Marcin Szymaniuk - Apache Spark? If only it worked #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Do you have plans to start working with Apache Spark? Are you already working with Spark but you haven’t gotten the expected performance and stability and you are not sure where to look for a fix?

Spark has a very nice API and it promises high performance for crunching large datasets. It’s really easy to write an app in Spark, unfortunately, it’s also easy to write one which doesn’t perform the way you would expect or just fails for no obvious reason.

This talk will consist of multiple common problems you might face when running Spark at full scale and, of course, solutions for solving them. Each of the problems I will cover will come with well-described background and examples so that it will be understood by people with no Spark experience. However, people who are working with Spark are the main audience. The ultimate objective is to give the audience a practical framework for optimizing the most common problems with Spark applications.

Read more:
https://2017.berlinbuzzwords.de/17/session/apache-spark-if-only-it-worked

About Marcin Szymaniuk:
https://2017.berlinbuzzwords.de/users/marcin-szymaniuk

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              do you plan to start data analysis and                               your consider                               using Sparkle read for it have you just                               started using spark and you want to                               avoid pitfalls are you already using                               spark but you are not really sure or                               happy about it performance or stability                               by the next of by the end of next half                               an hour I'll you'll have an overview of                                most common problem faced when running                                spark on production and solutions for                                them my name is marcin I'm data engineer                                act on tooth data I have almost a decade                                of experience I've worked for companies                                like Spotify Apple as you small smaller                                startups so I have quite some experience                                in data and today also the spark part of                                it                                [Applause]                                apache spark if only it worked it's                                quite controversial but it was inspired                                by a blog post I found a few years ago                                so when I was writing my first spark                                application I was looking for solution                                for my problems and I found this blog                                post and author these blog posts was                                giving quite a lot of advices but also                                he was complaining quite a lot about how                                hard is to make spark work reliably on                                production so honestly at that point I                                felt exactly the same but fortunately                                quite a lot has changed since then I've                                learned quite a lot and also sparking                                proof quite a lot so today I'm not going                                to put you off from spark I'm going to                                share my lesson learned so it will be                                easier for you we will start with spark                                execution model and that will be our                                foundation two reason another understand                                various problems you might face on scale                                we will be looking at various classes of                                problems like sizing executors skew data                                locality caching I'll also mention a few                                words about testing and debugging spark                                so what is spark is a general engine for                                distributed data processing it has                                support for various various programming                                languages it supports an API for for                                various program programming languages it                                has support for sequel                                it has streaming library it has machine                                learning library but today we're going                                to focus just on the core of SPARC yeah                                but what it really is why why would you                                need it so like one of the very common                                use cases first part is that you have an                                application you write your data and you                                have some analytics who are connecting                                to the data in order to understand                                what's going on with your users how how                                they are using the application how to                                make them pay why don't they pay to get                                basically some insight from your                                application but that is tricky to scale                                that is also a bit risky because you're                                on analytics might be a bit too greedy                                and and and then then you have a problem                                with with your with your app so so                                another approach very very common very                                very standard one is that you store your                                analytics data somewhere completely else                                so for instance in HDFS and you use                                SPARC to actually run analysis on top                                referrers of your data okay let's spark                                with an execution model sparks                                introduces resilient distributed data                                set and it's basically an abstraction on                                top of distributed data set the                                resilient part of it means it can be                                recalculated if the data is lost so we                                have a data set which which is split                                into multiple partitions into multiple                                nodes and it's just transparent to you                                that is distributed and then when you                                run your SPARC application SPARC                                pipelines operations until they can be                                done in context of just                                single partition until operation on                                given partition don't need data from                                another ones in such a group of                                pipelines operations is called state but                                eventually you want to exchange data                                between partitions eventually you do a                                an operation with like group by key and                                such kind of operation is called shuffle                                and that one we will be actually focus                                focusing on quite a lot because that is                                an expensive one and also that is                                causing quite a lot of problems and your                                 your application usually consists of                                 multiple stages multiple shuffles so so                                 far I was just saying spurred us this                                 and that but the actual execution you                                 need in spark is tasks tasks consists of                                 a code which is supposed to be run on                                 your data and a piece of data so here                                 you can see a block in HDFS so single                                 block in HDFS and end code which is                                 supposed to be run on it is a task and                                 each stage consists of multiple                                 independent tasks tasks get run in                                 executors each executor can run one or                                 more tasks at a time and the at a time                                 part I want to emphasize on because that                                 means spark can reuse the same executor                                 to run task after task after task it can                                 pick up dust from from the pending tasks                                 view and it's a quite nice improvement                                 comparing to to Hadoop so you don't have                                 to spawn new JVM for each task you can                                 reuse the same JVM and everything is                                 orchestrated by a single single driver                                 process                                 so let's zoom in to shuffle you might                                 ask why do I need to know what's going                                 on under the hood why don't I just rely                                 on the very nice spark API                                 why don't I simply let spark do the job                                 and the answer is you really need to                                 understand what's going on under the                                 hood in order to understand problems you                                 might face and eventually solve them so                                 there is a task                                                       some partition it pipelines operation on                                 that partition so it pipelines                                 operations like map flatmap filter and                                 eventually we get a result the result                                 gets stored to a local disk and it gets                                 stored into multiple buckets each bucket                                 is responsible for certain group of keys                                 lookup the other tasks they do exactly                                 the same so at the end of stage                                      have the result of tasks of tasks                                 written in local disks so they can be                                 pulled together all the red buckets are                                 responsible for the same group of keys                                 they can be pulled together and process                                 and and stage number                                             processing it from there                                 so as you can see there is quite a lot                                 of i/o so you're writing data to this                                 we're reading from it we are sending                                 data over the network it's expensive but                                 let's not focus on it for now because it                                 might be that your application actually                                 need multiple shuffles and you can                                 cannot really avoid it you simply have                                 to do it                                 so what could possibly go wrong like                                 famous last sentence so imagine you have                                 your application ready you have tested                                 in log it locally you are quite                                 confident about your business logic and                                 go to a cluster your                                 in large data set and you end up with                                 one of these problems spark is                                 complaining about two gigabytes limit                                 for for the bucket I was showing you                                 spark is complaining about timeouts                                 Sparky is complaining about some memory                                 related problems or executor lost                                 failure none of them is really related                                 to your business logic but but you still                                 can see such kind of problems and you                                 still have to tackle them so why why do                                 we have them it's quite often that you                                 can see such group of problems when your                                 executors are when your tasks are                                 processing too much data so the tasks                                 are simply talking with the data it's                                 either somewhere inside the task                                 somewhere with garbage collection or                                 maybe the tasks are actually fine but                                 there are problems when the data gets                                 sent over the network so there are so                                 where do you look for cooperate how do                                 you actually investigate it you have a                                 pretty nice spark UI for it and it gives                                 you a lot of informations but the                                 information I want to focus on right now                                 is a stage overview which gives you a                                 dug visualization which is kind of an                                 execution plan but also it gives you                                 metrics for each individual tasks so                                 yeah all really works for me                                 yes once again there are multiple tabs                                 er you have you have an overview of what                                 your execution plan looks like now I                                 have to go back yeah and you get a                                 overview of matrix third task so the                                 ones you definitely want to focus on is                                 status of your tasks so if you can see                                 tasks failing you obviously need to go                                 and dig into it and look for a reason                                 they are failing but another matrix                                 which are super important for you is the                                 duration of your tasks garbage                                 collection time which tasks spend on the                                 garbage collection and last but not                                 least amount of data sent do sent or or                                 created created during the shuffle so                                 you want this value values to be not too                                 large and you usually want this value to                                 be kind of equal so if all of the values                                 are large or some of the some of some of                                 your values are really large that means                                 you you have a problem that that means                                 you have you have something to                                 investigate and if you can see if you                                 suspect your task or processing too much                                 data what you could do is you could                                 control you could try to control the                                 level of parallelism so if you pass a                                 non partition parameter to any method                                 which is triggering shuffle you                                 basically tells Park oh I want the group                                 by to produce this many buckets this                                 many tasks so I want to process the                                 result of group by key in that many                                 tasks of course you could also try to                                 give give your executor more memory and                                 sometimes that works but but                                 you are limited that doesn't scale scale                                 very well you cannot do it every single                                 time and one more thing you could do is                                 you could trigger an artificial shuffle                                 so you could trigger repartition                                 to do exclusively tells park that you                                 want to even though you don't need it                                 from the point of your business or if                                 you want to report even the data in                                 order to make sparks life easier so look                                 we have stage which is processing data                                 and three tasks and those tasks are                                 talking so what you do you pass larger                                 number of partition as a parameter and                                 you end up with more tasks but each of                                 them is smaller each of them is                                 processing less data each of them is                                 producing smaller buckets so so the                                 stated dance team has easier job as well                                 but it's not always that simple                                 sometimes you you tell spark to to use                                 to process the data in a lot of tasks                                 and most of the tasks are doing                                 basically nothing but one of them or a                                 few of them are or super heavy so this                                 kind of problems are called                                 caused by skew in your data and to give                                 you an example if you are processing                                 data per country some of your countries                                 are just heavier some of your countries                                 has more transactions more users and and                                 if you group by by the country code you                                 end up with with different sizes of your                                 tasks another example is key being now                                 so if you allow your keys to be now and                                 if you group by it you might end up with                                 like                                                                   in the same task and regardless of how                                 many of them you have most of the job is                                 job is done in in one in one task so                                 very general technique to to deal with                                 such kind of problem is introducing salt                                 to your keys introducing some randomness                                 to your key                                 so look we have a few keys through and                                 let's say we have too many too many of                                 them and we want to split them split                                 them in between multiple tasks we don't                                 want them all to be processed in one                                 task so we add some random random values                                 to them so then they can be processed in                                 separation and then you are responsible                                 for making sure you you merge the result                                 back together you clear the randomness                                 you introduced and making sure that your                                 business logic stays correct another                                 subject which is very important when                                 when you want to actually benefit from                                 using spark is caching so I mentioned                                 RDD so far but I have not mentioned that                                 rdd's are lately evaluated so spark                                 tries to pipeline pipeline as many as                                 many operations as possible it runs them                                 when when the data actually has to be                                 materialized so it does not run them on                                 the fly does not run them it does not                                 store any intermediate result to disk as                                 well so we have the blue RDD one which                                 is calculated out of multiple operations                                 and then we reuse them we reuse already                                 one so we call some some more operations                                 on RDD one and we store the result to                                 disk and let's say we do exactly the                                 same to our DD one or maybe some other                                 operation but but but we we we again                                 call more operations or our DD one we                                 store the result to disk and it works                                 fine with one caveat the blue part gets                                 executed twice and you might be                                 disappointed you might ask why but this                                 is simply what spark does it avoids                                 storing intermediate data to disk and if                                 you don't have the result of calculation                                 of our DD one it has to recalculate                                 everything                                 but spark gives you a mechanism to                                 actually control it so spark gives you                                 caching mechanism so whenever you see a                                 situation like that when you have a                                 branch in your execution plan when you                                 really use some LEDs you can catch the                                 result and you can cache it to memory                                 you can cache it to disk you can cast it                                 to HDFS you can control the replication                                 factor so into how many notes given                                 partition goes and it's up to you what                                 decision you make so first of all as you                                 probably already noticed your your                                 memory will be will be limited so you                                 cannot cash everything and the question                                 is what do I cash so in order to decide                                 what to cash you have to know that you                                 cannot pin an RDD to memory you cannot                                 prioritize rdd's it's just all are you                                 algorithm so caching one thing might                                 mean you losing another thing so you                                 have to make sure that what you're                                 caching is the important one is the                                 heavy to calculate one the one thing                                 which you actually want to keep and you                                 have to make sure that we are not to                                 Brede so so you are not losing some some                                 some not that heavy to alkalize later DD                                 so sorry you are not using the heavy to                                 calculator really because you causing                                 something not that important if you are                                 not sure what to expect what sizes your                                 arteries are you can always go to spark                                 UI and it tells you how much how much                                 memory LEDs are taking in in cash one                                 more important thing is that you don't                                 necessarily have to fit all the already                                 in memory you can cash this just part of                                 it I mean spark will do it for you the                                 only requirement is that the whole                                 partition of an RDD has to fit in memory                                 so spark either causes the whole                                 partition                                 or just nothing okay so we have a                                 strategy for for caching data in memory                                 but why don't - why don't we just cache                                 everything we reuse to disk and it might                                 be a bit counterintuitive but storing                                 data to disk sometimes can be just more                                 expensive than than just recalculating                                 the data so it sounds like a waste but                                 still sometimes for calculation of of                                 your RDD is completely fine and it it's                                 especially true when when when you are                                 considering customer application factor                                 or caching with caching in HDFS which                                 will be much more much more expensive                                 because because then then you have to                                 deal with with network and so on last                                 thing to remember is that the buckets I                                 was showing you in shuffle they get                                 stored and they are kept by spark so                                 they can be reused so when you                                 recalculate when spark recalculate your                                 data it doesn't we calculate it from                                 from the very beginning it we calculated                                 it we calculated from the last shuffle                                 all right let's have a look at what size                                 your executor should be because that's                                 that's a very common common problem so                                 you control how many CPUs you are giving                                 to your executors and that means that                                 means number of tasks run run in                                 parallel per an executor and you also                                 control amount of memory and you have a                                 choice of running very small ones which                                 are and many of them per node and you                                 can have very large one which is                                 occupying most of the node resources you                                 can all also run anything in between the                                 actual decision is very much dependent                                 on your workload but there are a couple                                 of bullet points                                 I want to I want to work on so first of                                 all parks can benefit from running                                 multiple multiple tasks in the same JVM                                 so it can serve some variables across                                 tasks so the review just one copy of                                 this variable instead of a a copy per                                 task also when you when you are heavily                                 cashing things it's just easier for                                 SPARC to feed the cached data in memory                                 if you have like one big chunk of memory                                 instead of instead of smaller ones on                                 the other hand when you run when you run                                 very large executors it's very likely                                 that we will get into garbage collection                                 problems and also one more notion about                                 the large ones if you if your job is not                                 that large and you and you still want to                                 run large executors so let's say you                                 have hundreds of hundreds of nodes in                                 your cluster and you run just tens of                                 executors but large ones that means you                                 don't utilize you don't utilize all the                                 resources you don't you also might have                                 problems with locality which I'll I'll                                 get to so the general hints are if if                                 your workload is like ETL I would say in                                 most cases there is no point in in                                 playing with very large executors and                                 and and risking garbage collection                                 problem I will start with small ones on                                 the other hand if you if you very much                                 rely on caching or if you are using                                 broadcast variables you might need                                 larger ones so you will have to play                                 large executors and and make sure you                                 not end up with problems before we go                                 further let's have a quick look at spark                                 memory model so you decide how much JVM                                 Menor you give you give to an executor                                 this area this space is split into three                                 areas                                 area for your user program area for                                 intermediate buffer buffers used during                                 shuffle and area for cashing up until                                 SPARC                                                                  control that from                                                   balance it but you still can can switch                                 back and and and decide that you are                                 smarter than spark and and assign some                                 buddies to it another very important                                 memory which is outside of the heap is                                 memory overhead this is a memory needed                                 by a container but also this area is                                 where all the off hit memory goes so if                                 you know that you are allocating off                                 heap memory or if you are using the                                 library which does that you have to make                                 sure you make it large enough so keep                                 that in mind                                 also keep marquee keep in mind the                                 operating system so don't be too greedy                                 leave some resources for the operating                                 system if you are using on the yarn ORS                                 or system like that probably your admin                                 took care of that but otherwise make                                 sure you you don't allocate everything                                 if you are not sure about the memory                                 consumption you can always just play                                 around cousin already check how much it                                 takes so you get an overview of what                                 you're dealing with one more thing which                                 is worth trying if you are not sure how                                 many executors you want how how much                                 resources you want to give so let's say                                 you have a job with the same job which                                 is sat which sometimes is taking small                                 inputs sometimes instead of taking very                                 large input you can play with dynamic                                 resource allocation in that situation so                                 spark will start with small number of                                 executors and it will just bump it up                                 while it sees pending tasks locality                                 I've mentioned that already so the                                 concept is borrowed from Hadoop and the                                 concept is super simple                                 note                                                                    process that block so it's easier to to                                 move the execution to the node                                          than moving the data somewhere else and                                 SPARC does does it for you automatically                                 SPARC tries to achieve us highest                                 locality as high local locality as                                 possible but in some situations it's not                                 possible but you can you can help spark                                 to achieve it so let's say you have                                     nodes and you have just                                                  you have and you have IDF size blocks on                                 all                                                              possible to run everything locally                                 because simply have just execution on                                    nodes so the rest                                                       to transfer the data what you could do                                 in order to help spark is you could                                 increase number of exhibitors so you                                 make it more likely that spark has an                                 executor which is waiting and ready to                                 pick up a task in certain locality level                                 if your job is not that large on the                                 other hand maybe it's just better to                                 leave it as is if you really want to                                 control the locality because play with                                 spark locality white parameter so that's                                 a dub-dub param tall spark for how long                                 it should wait for for running a job on                                 given locality level until it just gives                                 up and runs it somewhere else so by                                 using this param you can enforce                                 locality you can give it up entirely but                                 it's super super tricky and the locality                                 level also we can check in in spark UI                                 and it's a property per task so you can                                 see what locality level each task run on                                 and you usually want to see no local not                                 not something different                                 and let's have a similar exercise we've                                 done with                                 shuffle let's do it with join so the                                 regular shuffle join works very similar                                 to what happened in in group by so in                                 both stages spark has to split the                                 result of each task in two buckets and                                 then all the same like buckets                                 responsible for the same keys are going                                 together and they get joined in stage                                 three and as I already mentioned                                 that's an expensive one sometimes you                                 cannot you cannot avoid it but let's see                                 how we could improve it and improving                                 shuffle very often means avoiding it so                                 look at this execution plan Stage one is                                 doing group by key followed by map Stage                                 three is doing exactly the same and then                                 Stage four is joining the results of                                 them two together but you can do some                                 tricks you can be nicer to spark in                                 certain situations so if you know that                                 the map after group by is not modifying                                 the keys you can tell it to spark by                                 using map values instead of map so if                                 you're if you are modifying just values                                 in your key value Spurs the other the                                 other thing you could do is to make sure                                 you are using the same number of                                 partitions in involve group bys                                 so then spark knows that we have exactly                                 the same partitioning scheme in both                                 group bys and we have not modified the                                 keys so the the result partitioning                                 scheme is exactly the same so it can use                                 this fact and end up with such an                                 execution plan                                 so we used to have five stages and four                                 shuttles between them now we have two                                 shuttles less which is usually quite a                                 big win and what happens here is the                                 group by key then followed by map values                                 and then join happens all in the same                                 place there is no data needed to be sent                                 over the network another technique to                                 improve shuffle and again improving                                 shuffle means avoiding it is broadcast                                 variable broadcast variable is a                                 variable which you can send from a                                 driver to every single to every single                                 executor it has to fit in memory so                                 imagine you have to join our dd                                        is very very large in consists of many                                 partitions and you have our DD                                         is tiny so instead of shuffling already                                 one traffic already - and then joining                                 them together what you could do you                                 could broadcast already - so it resists                                 in each executor and then join our DD -                                 to just single partition of our DD                                      memory and then you end up with with the                                 join result without shuffling articles                                 ever large our DD                                                   recap if you control number of                                 partitions and and if you are using map                                 values if you know that you you don't                                 modify your keys that might be super                                 helpful to start to avoid shuffles if                                 you are joining small rdd's with very                                 large one consider using broadcast                                 variable consider broadcasting small                                 rdd's filter before the shuffle not                                 after it that's quite obvious use reduce                                 by key where you can so I was referring                                 to group by key all the time but but                                 reduced like you can can actually limit                                 amount of data sent over the network                                 hums somehow related to toward combiner                                 it in Hadoop does test your code I                                 cannot stress it more I mean it's not                                 only about your qualities also about how                                 fast you can iterate if you if you                                 testing you're testing your code locally                                 you avoid waiting for resources going                                 for a class or waiting until it it                                 finishes the job and then checking the                                 the very large data set test as much as                                 you can locally and SPARC actually                                 supports that pretty well make sure you                                 know what you are optimized for do you                                 do you want to see good work time do you                                 want to see good resource resource users                                 or maybe your time is that creatures                                 that you don't want to rub it hold on on                                 some small improvements also make sure                                 you know the priorities of your jobs so                                 so make sure that you are not hogging                                 the the whole cluster and and other                                 people maybe more important jobs are                                 waiting for you make sure you have some                                 guidelines because it's very likely that                                 in your team this is you as you                                 developers and maybe a few analytics and                                 maybe a few people who wants to run                                 sequel from time to time and they are                                 not that much into or going on under the                                 hood but make sure you you sure the best                                 practices so you don't dig into the same                                 problems all over again and the last                                 comment is somehow related to the title                                 of this talk so SPARC actually works but                                 it really helps to know what's going on                                 under the hood and the more you                                 understand the more you work with it the                                 more you like it okay we I think we have                                 a few minutes for questions right let's                                 take the speaker first for the talk                                 Martin and here all the questions in the                                 audience                                 is one in the phone yeah I yet this one                                 sideway said that if you put on too many                                 executors that you get into GC problems                                 now it was if the executor is very large                                 so if you let's say you you want to                                 process a lot of tasks in context of the                                 same machine so then you need to give it                                 a lot of memory and then for large for                                 large hits                                 it doesn't really behave very well so I                                 got it wrong because you can have                                 actually big boxes with lots of course                                 and you will benefit from them right yes                                 yeah in certain situations yes but but                                 for instance if you are running ETL you                                 probably not that heavily relying on                                 caching so I would say it doesn't make                                 much difference if you small run once                                 and then you know and you step back from                                 all these garbage collection problems                                 thanks more questions this one here on                                 the writer right side for you yeah thank                                 you um do you have any advice about                                 running spark on yarn anything any                                 pitfalls to to look at all anything like                                 that any really a bit more specific I'm                                 basically just someone who's going to                                 quite need to spark and I just wondered                                 if there's anything I should be worrying                                 about if I was running it on top of yarn                                 versus running it now if it was like                                 three years ago I would say you should                                 have been very worried but right now it                                 works quite well thank you we got time                                 for one more question                                 what is the suggestion about runtime of                                 each task should because we saw there                                 only                                                                 freak example so I would say again it's                                 relate its each depending on our                                 workload but I would say a few minutes                                 probably probably a few minutes because                                 usually at least if you are running data                                 from a GDS su you are not each task is                                 in the beginning reading readings like                                 few hundred Meg's so so it doesn't mean                                 if it runs for four for more time it's                                 it's starting to started starting to be                                 worrying but depend depending on your on                                 your workload once you know you once you                                 work with it with your specific                                 application we get you get the feeling                                 in general I would say few minutes up to                                 ten minutes six all right let's think to                                 speak again it was okay I just I just I                                 just want to thank you very much if you                                 have more questions that switch out to                                 me I will be around if you have more                                 questions about the presentation if you                                 have more questions about your use case                                 and also if you are interested in in                                 consulting services or or training                                 services reach out to me thank you                                 [Applause]                                 [Music]
YouTube URL: https://www.youtube.com/watch?v=19OSxob6ntk


