Title: Berlin Buzzwords 17: Doug Turnbull & Jason Kowalewski - We built an Elasticsearch Learning to Rank..
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Doug Turnbull and Jason Kowalewski talking about "We built an Elasticsearch Learning to Rank plugin. Then came the hard part".

Learning to Rank uses machine learning to improve the relevance of search results. In this talk, I discuss how we built a learning to rank plugin for Elasticsearch. But what's more interesting is what happened next. Learning to rank requires new ways of thinking about search relevance, and in this talk I go on to discuss the specific problems faced by production-ready learning to rank systems. We learned these hard way so you don't have to. These systems need to solve a variety of problems including:

- Correctly measuring, using analytics, what a user deems "relevant" or "irrelevant"
- Hypothesizing which features of users, queries, or documents (or query-user dependent features) might correlate to relevance
- Logging/Gathering hypothesized features using the search engine
- Training models in a scalable fashion
- Selecting and evaluate models for appropriateness and minimal error
- Integrating models in a live search system alongside business logic, and other non-relevance considerations
- A/B testing learning to rank models and avoiding future bias of training data

Each of these requires solving pretty tough problems. This talk will discuss our war stories, practical lessons, and the goings-on inside real life search implementations that can help you decide what pitfalls to avoid and decide whether learning to rank is the right direction for your search problem.

Read more:
https://2017.berlinbuzzwords.de/17/session/we-built-elasticsearch-learning-rank-plugin-then-came-hard-part

About Doug Turnbull:
https://2017.berlinbuzzwords.de/users/doug-turnbull

About Jason Kowalewski:
https://2017.berlinbuzzwords.de/users/jason-kowalewski

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              so I'm Doug                               [Applause]                               talk I've ever given in my career I've                               dug and I'm Jason Jason and we're going                               to hear talk about learning to rank that                               we have been working on together in the                               context of job search and as a                               functionality we're adding to as a                               plugin to elastic search and not only                                that but the pain points in the sort of                                bruises that we earned along the way                                space space oh the first lesson we                                learned about learning to rank was oh we                                probably should have tested this huh it                                was working yeah we're engineers it's                                okay                                yeah I watch someone very smart                                yesterday spent about an hour trying to                                print badges so and if you know what's                                happening tomorrow in terms of a                                conference you'll know who I'm talking                                about so I work at open source                                connections I our company focuses pretty                                exclusively on solar and elasticsearch                                relevance problems so ranking how I like                                to tell people that don't know anything                                about search I try to match users to                                your products find the best products for                                them whether it's through search or                                recommendation systems and Jason so I                                work at a company called Snagajob and I                                put this slide up here for context not                                to hit you over the head with marketing                                stuff but probably none of you have                                heard of our company I'm going to take a                                guess but we are the largest marketplace                                for hourly work in the United States and                                so some of the statistics up there with                                four and a half million applications                                people applying to for jobs on our                                platform a month                                                        hired last year on our platform we get                                about a million new workers every month                                in about                                                                around                                                                 around                                                              other side                                making making funny noises sorry all                                right so I'm going to try to explain our                                problem to frame it up just with some                                some examples here and now sorry don't                                get in trouble we have good searches on                                our platform but I'm going to show you                                some really bad ones                                so here the query from McDonald's in                                Anaheim California that's just outside                                of Los Angeles ok                                the first three results are ok but what                                happened here I've returned to Starbucks                                results in the top five why is that well                                we're boosting on title we're saying                                that the title is the most important                                thing in this particular case but we                                also are boosting on things that are                                fresh we have a belief that if a job is                                new it's more likely than people apply                                and get hired to it but in this case the                                English analyzer has done a nice match                                for us on the title of McDonald's Avenue                                in Westminster California which is                                giving us a pretty poor result so let's                                go to Compton California and this result                                get way worse Starbucks is my first                                result the reason for that is because                                that zip code doesn't have any open                                positions so those things get boosted                                right to the top let's go across the                                country to New York City this is Carroll                                Gardens                                so same query so you can see here the                                first three results all five McDonald's                                it's relatively high recall those are                                   to                                                                     could work except in this particular                                geography that's really bad if you've                                been to New York City no one's going to                                do this it's about                                                   probably take you two hours or you could                                probably get a canoe across the Hudson                                Bay snow water taxi yeah it's not not                                good so this makes us sad let's look at                                some data so this is a distribution of                                key words on our platform over the                                course of a week you'll notice here that                                we're lucky when we get a brand so those                                queries that I just gave right there                                that I'd give an example of are                                even very common what's more common is                                that people are saying I want a                                 part-time job                                 I want full-time job the problem with                                 that is that that matches almost every                                 document that we have in our index so                                 yes we can filter down by location but                                 here's an example of this so this is a                                 search that same search for part-time                                 here and the first three results are                                 special skills that I don't have so this                                 search is extremely not personalized to                                 me this is the real problem we have                                 hand-tuned relevance the vector space                                 model BM                                                               field booths are extremely complicated                                 they're difficult to maintain we have                                 tons of rules when you fix one it                                 creates a problem somewhere else when                                 you fix that somewhere else it creates a                                 problem in places that we don't know                                 until we've delivered bad results to our                                 workers and that's something that we                                 don't want to do geography plays a very                                 important factor in relevance so just                                 like you saw in New York City that same                                                                                                         in a smaller or a smaller metropolitan                                 area humans are complicated trying to                                 create heuristics around psychology and                                 human behavior is an incredibly hard                                 thing to do so this is where we decided                                 that learning to rank was something that                                 we were interested in doing we saw the                                 talk from Bloomberg leasing Revolution                                 got inspired by that and then decided                                 that we're a data-driven company to                                 begin with we want to use our data to                                 drive our user relevance so we partnered                                 with Doug and open source connections to                                 implement learning to rank in production                                 to completely rebuild our whole search                                 experience so now kick it over to Doug                                 yeah sure so that kind of frames the                                 picture and I want to talk more about                                 learning to rank in general not just in                                 terms of job search but often when                                 you're doing these relevance problems                                 you might start out trying to gather a                                 sense of correctness for your search so                                 in this case we're switching a movie                                 search and we've got Ramba a bunch of                                 Rambo searches and we've decided to                                 grade them and grade here and usually in                                 search you know you                                 have four means it's an exact perfect                                 match zero means it's a horrible match                                 so we've got Rambo as a great match for                                 the keyword search Rambo obviously first                                 daughter is an absolute terrible result                                 for Rambo same with rocky and this sort                                 of forms the basis of how people might                                 often tune relevance I call this a                                 test-driven relevancy where you have                                 some correctness data in some cases you                                 might just have as little as                                            you might have thousands of queries and                                 as you're testing and manually tuning                                 search results you're getting a sense of                                 okay when I tweaked this title boost                                 Rambo got better but rocky got worse and                                 you can get a sense as you're iterating                                 on search how whether or not you're                                 going in the right direction as a                                 developer as your hand tuning so                                 learning to rank differs because instead                                 of focusing on tuning hand tuning this                                 search engine you're focused on a model                                 you're using the same kind of data as a                                 training set for building a machine                                 learning model that can rank results for                                 you and instead of iterating offline or                                 on a maybe tweaking boosted why not                                 you're really getting at you're playing                                 with a model separating training and                                 test data if you've ever done any                                 machine learning work training a model                                 testing it out to see how accurate it is                                 and the value is Jason kind of said for                                 you is learning to rank I think is                                 really valuable especially when you get                                 into tree based and SVM based models on                                 capturing a lot of context                                 linear base where you're just tweaking                                 the weights on boosts often can't get at                                 the context of in this geography this                                 certain skill yorkers have the certain                                 skill more or this certain distance                                 matters more or less because of how                                 difficult the commute is so you really                                 get at these sort of contextual                                 situations that are really dependent on                                 where you are so                                 learning to rank with elasticsearch is                                 basically baking that model that you                                 trained into the search engine so you                                 take the brains that you just trained                                 maybe you feel like it's pretty accurate                                 and if you solve the Bloomberg talk you                                 basic you saw them do this at the demo                                 with solar but you take that model and                                 you give it to the search engine and you                                 put it in there and you you have a                                 baseline ranking function maybe you                                 retrieve just do simple tf-idf scoring                                 on a couple fields a little bit of hand                                 tuning and then you use your model to                                 rescore the top and search results                                 elasticsearch and solar both have                                 restoring capabilities or rewriting                                 capabilities they'll let you execute a                                 query on a window of your top search                                 results and it gives you the chance to                                 shuffle things up to the top based on                                 the contextual clues of say geography                                 personalization all kinds of signals                                 that you can use during ranking so I was                                 going to fix that that says judgment                                 listed training set how learning to rank                                 works in elasticsearch very briefly is                                 our plugin we start with this CSV file                                 that maybe we hand generated maybe it                                 came from analytics maybe our domain                                 experts told us about it and we use this                                 to go off and gather relevant scores for                                 features we hypothesize correlate with                                 relevance now just like in the solar                                 plug and features correspond here to a                                 elastic search query so here this is a                                 simple feature that's the type tf-idf                                 score of the title field for the                                 keywords and you can see here and this                                 is a file format that's a sort of                                 canonical way of doing these training                                 sets for relevance                                 we've given all our queries an ID we                                 don't need the document ID anymore we                                 left the grade in the Left column so                                 Rambo is query ID one Rocky's query add                                 a two and we started to fill in                                 different features we hypothesize might                                 correspond to relevance based on us                                 going to the last exertion saying hey                                 can you take this document do a title                                 run this query on it and give me the                                 score and you'd run this                                 take this document run this other query                                 and you can the with a lots of search                                 query DSL you get your creative you have                                 no bounds on your creativity you can go                                 and use all kinds of query primitives to                                 build up your your features that you                                 might think are important now we have                                 the elastic search query DSL or elastic                                 search wanting to rank plugin works it                                 integrates with rank Lib which is an                                 academic developed learning to rank                                 system library and what it does                                 basically is takes these rank lid models                                 and you can evaluate them and here we've                                 taken our training set on the left and                                 rank Lib can be run at the command line                                 Java dash jar rank live with a bunch of                                 command line parameters and we've                                 trained a model we spit out a model and                                 in this case it's an ensemble of                                 decision trees a model a model News                                 lambda mark and you can see here that in                                 this case decision trees are actually                                 really good at getting at different                                 context because if you could say if in                                 New York if the distances this look                                 double check the commute distance do                                 with all these other things and there's                                 no way you as a hand tuning person could                                 do that without an extensive amount of                                 ridiculous number of rules so you can                                 see here that we have the first two                                 levels of this decision tree our feature                                 to which was our body score                                 it's basically go left if it's less than                                 that threshold and then eventually we                                 get to a title score and we have a                                 threshold of zero and it'll output a                                 score negative two                                 interestingly in both cases which is                                 sometimes the fun part of machine                                 learning model so what is the last                                 search wanting to rank plug into the                                 first thing it does accepts these models                                 basically using elastic searches                                 scripting functionality and that has a                                 lot of nice features like not having to                                 us to have to think about clustering or                                 anything scripts automatically get                                 distributed around the cluster they get                                 cached and you can store them in the                                 file system you can post them you can                                 even inline them which is for anything                                 that's non-trivial you probably don't                                 want to do                                 in your query and I can give it a name                                 so here I've got a scripting plug-in                                 called rank Lib that the plugin has                                 added and I'm sending that script I just                                 showed you up to rank lip and you do                                 need to crank up the setting on                                 elasticsearch for the maximum size of a                                 script so once you have a model the                                 other thing the plug-in does is it gives                                 you a model you can tell it the model                                 you want to execute in this case Doug's                                 model that we just created and you                                 restate the features that you are using                                 so feature one unfortunately ranked lip                                 syncs in one based indexing and feature                                 to go in the features list and then                                 you're just telling it which model to                                 execute the nice thing about this being                                 a part of the query DSL is you can wrap                                 it in business rules or do all kinds of                                 stuff you have a lot of freedom you can                                 add filters you can make it part of your                                 solution potentially you could execute                                 two or three learning to rank models if                                 you wanted to sort of like open to your                                 creativity but of course you ought to do                                 use this in the context of restoring so                                 we don't actually enforce in this plugin                                 that you do restoring in fact our                                 company's blog is done in learning to                                 rank and I don't do any restoring                                 because there's about seven or eight                                 hundred blog posts and I don't worry                                 about that and it works pretty fast in                                 this case we're actually narrowing it                                 down to the top                                                          elasticsearch we're getting at that the                                 same query I said below and then up top                                 wherever I query I've got my baseline                                 relevant so that I maybe have hand to it                                 a little bit so I think what's                                 interesting is I see when people talk                                 about learning to rank I generally see                                 two solutions one is people baked                                 something into the search engine and the                                 other is maybe they have an API also the                                 search engine where they prefetch like a                                 bunch of results and I really like the                                 approach of making it in the search                                 engine even though it's you know you                                 it's more challenging potentially if you                                 don't have a plug-in to do this the                                 reason I like baking this into the                                 search engine is                                 performance is one reason you can sort                                 of pre-filter you don't to prefetch a                                 thousand results and the second point is                                 actually really important you search                                 engines are basically built to do these                                 query dependent features these ranking                                 signals to get at like to measure the                                 tf-idf score of different titles and                                 it's really got this amazing rich DSL                                 already built in for ranking and sorting                                 things that people are already using to                                 build sophisticated search systems and I                                 already mentioned business rules so we                                 could layer business rules on top of                                 this or figure out a way to do that with                                 a query a DSL and finally I think                                 probably the thing that people take most                                 for granted are just the dumb basic                                 functionality that no one no one pulls                                 their hair out of out about that gets                                 excited about but you really still want                                 facets paging grouping you want to do                                 all these things you want to get                                 autocomplete and spell checking and just                                 get these bells and whistles that people                                 expect from a search solution and                                 building something maybe outside to do                                 your rewriting                                 you're going to have to take you all                                 that to account so I'm going to go                                 through a bunch of lessons that we                                 learned so that was the happy path                                 everything is great and yes it was not                                 that hard to get this to work for our                                 blog but when you go to a real                                 production system that's not                                          posts like we did with Snagajob we                                 started learning lessons the hard way so                                 the first lesson I want to talk about is                                 judgments are really hard to get really                                 good judgments are really hard to get                                 and I think people often don't take into                                 account that the hard part about search                                 is often measuring user behavior and                                 measuring what good searches sometimes                                 that's a lot more challenging than                                 actually doing the whatever fancy                                 relevance work you're going to do it's                                 easy to get excited about solutions it's                                 sometimes less exciting the less easy to                                 get excited about okay was this good or                                 bad or how can we figure this out and                                 you know there's a lot of ways we could                                 define what good searches that's like                                 graphic from my book by mr. Berryman who                                 is an ink scape                                 and these you know you might have the                                 developer say you know we have sue and                                 marketing you CEO comes in and my                                 colleague Eric Pugh likes to refer to                                 the hippo the highest paid person's                                 opinion the CEO comes in and says why is                                 this broken you're like well it doesn't                                 we no one ever searches for that people                                 have pet peeve queries there's a                                 bazillion read ways you can go about                                 getting this data and there's really no                                 one-size-fits-all and in my work doing                                 relevance I've seen this sort of roughly                                 and this isn't a hundred percent like                                 perfect dichotomy but roughly the                                 spectrum of search solutions on the Left                                 which are very consumer facing that are                                 focused on analytics they have a lot of                                 ability to get analytics and search                                 solutions on the right which are more                                 focused on knowledge management where                                 maybe there's                                                          doctors and trying to get five of them                                 in the room to tell you why search is                                 broken is really hard and on the left                                 you have you have problems of trying to                                 figure out like okay I've got all this                                 analytics but I can't go and talk to                                 that person and ask them why they                                 clicked on this thing and so you're                                 constantly looking at analytics trying                                 to get at why why on the right with                                 experts you can at least go to someone                                 and talk to them and get them to tell                                 you why something was relevant or                                 irrelevant so you can get a better sense                                 of how you should be constructing these                                 judgment lists and the on the left the                                 one of the big one of the big costs is                                 really just infrastructure code for                                 analytics like anyone who does a lot of                                 really in-depth like I know Snagajob                                 there's a lot of infrastructure to                                 gather analytics about how people                                 interacting research on the right of                                 course as I said the cost is actually                                 getting like a room of paying a dot five                                 doctors to sit in a room for you for a                                 day and then doing that every week until                                 you get your search to where you want it                                 to be                                 yeah so one big takeaway is there's a                                 lot of non-technical domain expertise to                                 do either of these situations even                                 analytics you sort of need to know your                                 domain really well to understand why do                                 hourly workers do certain things for                                 example in Snagajob so the other thing                                 we learned is grade consistency like you                                 really need a good standard when you're                                 building judgment lists for when                                 something is a four versus something is                                 a three and what you want to really                                 avoid is having like relative grades so                                 if something is this you may be on our                                 blog for example I think I have an                                 example of that we have someone searches                                 for Enterprise Service bus and the best                                 thing we might have when use your                                 Enterprise Service bus is a bunch of old                                 camel articles now when I'm saying                                 what's my golden set for this query it's                                 easy to say I think I'll make that a                                 four that's the best I can do but in                                 reality you sort of need to be really                                 consistent on your criteria and be ok                                 that you're going to have queries that                                 the best thing might be a                                                just might not have good content for                                 that query and to be really consistent                                 because you're going to train something                                 that's a function of a bunch of features                                 so a for-real SP a lot easier for your                                 models to predict like one of four is a                                                                                                         of consistent criteria whether you're                                 using domain expertise or you're                                 gathering analytics is really important                                 for this kind of work so just change the                                 background of that like upper right                                 thing so what should you optimize for                                 and there's a bunch of search metrics                                 that you can think about precision is                                 sort of like the proportion of good                                 stuff I have in end results if I have a                                 hundred floors and you show me the top                                                                                                       precision right so that's a pretty rough                                 metric it doesn't necessarily take into                                 account the position bias you know just                                 a basket of twos and                                 how how far from good stuff is that and                                 DCG is a metric not mystical normalize                                 discount accumulating and it's a metric                                 that can tell you the distance your                                 search is from a golden set so if you                                 take all those judgements and you get                                 the ideal ordering you get four four                                 four four three three three three and                                 you're showing sort of like a to two to                                 four to three                                 it can give you a sense of how far                                 what's the Delta between where you are                                 and the best you could be doing and the                                 downside to that is if the best you have                                 four queries are to your ideal ordering                                 might be like two to two to one and if                                 you do two to two to one                                 you're still going to get a score of one                                 and end ECG these scores tend to go from                                 zero to one so something to take into                                 account is you might be thinking the                                 search result is perfect but it's                                 actually just saying that you're doing                                 your best you can under the certain date                                 under given data so that's a area where                                 that can be misleading there's another                                 statistic that I think is very useful                                 that maybe if you've heard of end ECG                                 this is even a step more obscure                                 it's called expected reciprocal rank er                                 R and what this really does is just says                                 sort of gets it a sense of whether or                                 not users can trust the results so if I                                 scan down can I say this is a do I get a                                 bunch of fours or do I get a why Nana                                 for it has no concept of what the best                                 is out there and if you put a it's                                 really biased towards like if the top                                 one is the top one's really bad you're                                 going to have automatically a really bad                                 er R so it's just focuses on life as                                 user scan down results are you pretty                                 close to having something that looks                                 trustworthy good and this will actually                                 think if there is a you know a - and the                                 best you have for the search results                                 search query is a - you'll still get                                 like a low ARR and that will kind of                                 point at where end ECG maybe doesn't                                 tell give you this information                                 so at Snagajob actually I think there's                                 a balance of ND c g and e RR which Jason                                 will talk about so of course what should                                 we optimize for the answer is yes                                 so this is pretty domain-specific if if                                 you're pretty focused on showing experts                                 all of the information that is possible                                 sort of bore more recall focus you might                                 folk you might think about nd CG over a                                 certain set if you just care about                                 whether or not results look good which                                 is often good and when people are                                 building trust with an application er R                                 is really important so the other less                                 painful lesson we learned is accuracy                                 versus speed it's really easy we gave at                                 Snagajob data science issue and had got                                 extremely beefy ec                                                  imagine getting a spark cluster to do                                 your training it's easy to be on the                                 left here with your with your machine                                 learning training infrastructure or                                 you've got the Deathstar and you're                                 going to build the world's most accurate                                 perfect model with all the compute you                                 have but your search infrastructure is                                 very different than that when it                                 executes models it sort of got to shoot                                 all these little fighters out of the sky                                 because it's got like very short amount                                 of time to get rid of them all or else                                 like the whole thing is going to crash                                 down right so you have not a lot of time                                 for research requests to evaluate these                                 models so it was really important for us                                 when we're doing this to sort of think                                 through ok what's the right balance                                 between accuracy and the performance                                 actually in production a model selection                                 what kinds of models I mean there's                                 ranked SVM there's gradient boosting                                 there's random forests of gradient                                 boosted trees there's linear models                                 linear MA the only I think this matters                                 a lot less than people think cuz people                                 get excited about models I think once I                                 have a model that most people I think                                 once they get a family of models they're                                 familiar with they tend to worry more                                 about sort of garbage in garbage out and                                 tuning the hyper parameters of that                                 model that in their way they're                                 comfortable rather than necessarily like                                 having a focusing too much on changing                                 out different models I do think one area                                 where that's not true is a forced linear                                 models linear models are sort of like                                 optimizing the boosts in your different                                 queries of course like we said with with                                 when Jason showed that example                                 it's hard to get an optimal sense of                                 like in New York you get this                                 but in LA you get this you're just going                                 to get the average of New York and LA                                 and what you prefer is something that                                 can get at context you're going to get                                 down to like okay if LA do this if New                                 York do this other thing                                 and so gradient boosting rank SVM those                                 sorts of models can get at that and I                                 think Grant talked about this yesterday                                 but one of the big things that I've sort                                 of taken away from my learning to rank                                 work is thinking about chaining models                                 together both in performance so you know                                 a simple linear model to maybe to                                 improve precision and then maybe a                                 slightly more complicated model to get                                 nd CG over a larger set so that you're                                 closer to your ideal ranking and then                                 maybe er are over a very short set even                                 ER at                                                                    look trustworthy and as you go from left                                 to right less the most actually off the                                 screen would be like your baseline                                 ranking you're getting extreme even more                                 sophisticated even more complicated                                 models that are slower but doesn't                                 matter because you're only doing a                                 couple of results even less each time so                                 quality and accuracy so this gets out a                                 lot of different things whether you're                                 tuning model parameters or you're trying                                 to figure out which features aka elastic                                 search queries actually matter in your                                 case and in the case of doing gradient                                 boosting it's hard to isolate to one                                 feature and say oh this is the thing                                 this date boost is the thing that put us                                 over the edge and made us that much                                 better made us gave us a                                               or something the reason is is like I                                 said showed before gradient boosting is                                 a set of decision trees and so things                                 often depend on each other it might be                                 if you're in this position if you're                                 searching for movies if use a strong                                 title match may be the recency of the                                 movie for example is really important                                 because we want to show you the latest                                 movie                                 The Fast and Furious series for example                                 but if you're searching for actors you                                 match on actors maybe yours that doesn't                                 matter as much and you just kind of want                                 a random set of movies and date doesn't                                 matter so getting at the figuring out                                 what combination of features helps you                                 the most is actually more important and                                 there's an algorithm called best subset                                 selection which sounds fancy but it's                                 really a you know an extra four loop and                                 my I've just my favorite saying is that                                 every machine learning problem can be                                 solved by just adding one more outer for                                 loop by trying different hyper just                                 trying different stuff more hyper                                 parameters and of course spark pique a                                 spark jobs so before I jump to Jason                                 really quickly I want to point out that                                 in my opinion this is actually harder                                 than doing manual tuning so I think you                                 shouldn't necessarily think that you're                                 doing learning to rank because it makes                                 things easier you have to do a lot more                                 stuff on the right on the left we just                                 got a fairly simple setup you might have                                 some of the stuff on the right like your                                 user click stream data but you actually                                 need a fair amount of stuff to do                                 learning to rank well you need data                                 scientists you still need your search                                 engineers you're in your state business                                 stakeholders and you need to think about                                 other problems like how am I going to                                 train my models how am I going to get                                 analytics or maybe user testing but I                                 think this can be a lot more powerful so                                 get into learning to rank because doing                                 that is really going to get game changer                                 to your business it's like it you think                                 it's going to be for Snagajob so and                                 this is one thought I I left you what I                                 want to leave with is because we're                                 doing such heavily personalized learning                                 to rank we're often thinking about can                                 we just use wanting to rank directly to                                 do recommendation engines the only                                 difference being a search engine a                                 recommendation engine is really whether                                 or not there's keyword they both rank                                 things based on relevance and when                                 you're doing heavily personalized search                                 we might be at a point where we can say                                 here are your recommendations here your                                 search all driven by one system so                                 that's one thing I'm personally excited                                 about                                 so I just want to go over kind of how we                                 went about implementing learning to rank                                 so that everybody here can have kind of                                 a tangible plan of how somebody has done                                 it in the past or currently we're going                                 to hopefully be in production next week                                 and and kind of get some ideas from that                                 as well as some lessons that we learned                                 so step zero before you do anything this                                 is such an iterative process you have to                                 be okay to fail we failed many many                                 times first models did not perform well                                 when you do the initial looking at                                 results you have to trust your metrics                                 it's kind of a kind of a mental shift                                 from the way that we normally think of                                 things with search relevance step one                                 determine how to measure success Doug                                 went over these metrics these are the                                 two that we selected as far as our cost                                 function for our model training we                                 picked NDC G at                                                      optimizing for NDC G at                                        interesting thing about this is that UX                                 and UI actually have a big part in your                                 metrics so our mobile team is developing                                 kind of a next-generation application                                 which does different groupings of jobs                                 which end ECG is basically a positional                                 metric and if you group things together                                 you could have interesting cases where                                 people are getting the search result but                                 not even seeing it so something to                                 definitely think about step two this is                                 super important your baseline ranking                                 function is essentially your first query                                 that you do to elastic search or                                 whatever search engine you're using and                                 this is your best guess at getting the                                 top K before you pass it into the Ries                                 coring phase so our example is use the                                 gaussian decay for distance for                                 freshness we also use the m                                              across different fields and then we have                                 a Geo radius because most of our                                 searches are our geographical kind of                                 what we found out is that the the                                 distance decay wasn't actually                                 aggressive enough and the same with the                                 freshness decay so what was happening                                 was as bad results we're getting into                                 that top                                                                 once bad results get in there learning                                 to rank won't help you so we also have                                 some interesting edge cases with                                 fastenings we have location facets where                                 a user could type in a low                                 station without a lot of context they                                 could type in Arlington for instance                                 well there's an Arlington Texas in the                                 United States and there's an Arlington                                 Virginia which one do they mean well we                                 have to assume that they mean both so                                 what that means is that you have the                                 union of these two things which now goes                                 in and that might be that you have                                                                                                      only                                                                 rear anchor so you have to actually make                                 decisions on what actually makes it into                                 that top                                                                that we're going to let the baseline                                 rank or handle recall and then optimize                                 for precision and the in the actual                                 rescore saves start small with your                                 feature engineering we picked five                                 simple things each one of these a brand                                 similarity zip code title job                                 description and the location are all                                 text similarity fields each one of these                                 features is an elastic search query it                                 each turns into a particular score which                                 then that feature gets added into the                                 model and these things don't involve a                                 lot of complex feature engineering                                 improve them constantly you're going to                                 always be iterating with your future                                 engineering features don't need to be                                 searching things what I mean by that is                                 they don't need to be similarity scores                                 think about content profiles that could                                 be learned via content recommender                                 system it could be commute distance as a                                 function of roads or transit they could                                 be market forces                                 we're largely in a market place so we're                                 subject to macroeconomic forces we can                                 model these as part of the the function                                 of the search engine and also the                                 workers query training models we                                 selected lambda Mart we have an                                 infrastructure where we have a robust                                 data infrastructure collecting user                                 signals so we get those user                                 interactions we turn them into judgments                                 with Apache spark getting future values                                 from elasticsearch we then use the                                 plugin from open source connections to                                 generate those models and then post them                                 into elasticsearch this right now is a                                 manual process we're turning it into an                                 automated process orchestrated with                                 Apache air flow this is another thing                                 that we're thinking about doing you                                 don't also need to just have your user                                 signals turn into judgments you can use                                 things like waiting factor models to                                 actually add additional data                                 your to your judgments here's in real                                 world considerations ranked live only                                 runs on one machine so originally our                                 data scientists were running it on their                                 laptop that gave a limit to the hyper                                 parameter size that they could use could                                 only use I think like                                             judgments max tree depth of                                              a limit to the precision of that model                                 we moved up to relatively large ec                                  machines but we're always going to be                                 constrained by one machine we've thought                                 about using something like XG boost                                 which is a parallel gradient boosting                                 system but we haven't done that yet so                                 Doug talked about this I think it's                                 important we all know this right right                                 if you have bad data it doesn't matter                                 what you do doesn't matter you can have                                 all the sunshine and unicorns you're                                 going to have garbage results and so you                                 need your data to be duplicated you need                                 fraud controls you need to be able to                                 have clean user signals and we've                                 actually had to go back and correct some                                 of this stuff within our system because                                 you can't model your way out of a data                                 problem so this is one thing that I'm                                 not going to talk a lot about but query                                 dependent features are interesting in                                 that you're training offline and when                                 they're evaluated at query time the                                 state of your index could change so if                                 you're using something like tf-idf your                                 scores will actually be different at                                 training time and query time so what we                                 actually have talked about doing is                                 logging query dependent features as a                                 training set and something also to think                                 about integrating with an existing                                 platform we have a system that works                                 drives money so no we don't want to                                 integrate with it we want to just build                                 a parallel system so what we're doing is                                 we're building a completely parallel                                 system putting it under a t-test to                                 deploy it and then we're able to tune an                                 analyze model until we are comfortable                                 with the lift that we're getting in our                                 core metrics last step profit hopefully                                 so what we what we want so our version                                 one of the model actually had lists of                                 about                                 percent in ND CD at                                                      at ten this is our evaluation framework                                 that we wrote by the way which takes a                                 training test split so it's not                                 overfitting don't worry but you know we                                 real-world cases we'll see what happens                                 your hyper parameters matter when we                                 were able to train larger models we got                                 really large increases in our core                                 search metrics and this is a very                                 promising for us that's it and if you                                 have any questions I guess you're on                                 time but there's also some of you might                                 know I wrote a book and there's a                                 discount code for you that I saved to                                 the end so you have to stay here the                                 whole time Peter discount code and if                                 you're interested in the plugin that's                                 the URL we're actually partnering both                                 with Snagajob and the wikimedia                                 foundation on                                                         will be a lot more feature-rich and if                                 you're just said check that out so thank                                 you guys                                 [Applause]
YouTube URL: https://www.youtube.com/watch?v=JqqtWfZQUTU


