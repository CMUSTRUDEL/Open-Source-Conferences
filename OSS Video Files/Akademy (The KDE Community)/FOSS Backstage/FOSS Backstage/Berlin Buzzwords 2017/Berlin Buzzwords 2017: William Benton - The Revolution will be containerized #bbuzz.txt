Title: Berlin Buzzwords 2017: William Benton - The Revolution will be containerized #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	William Benton talking about "The Revolution Will Be Containerized: Architecting the Insightful Applications of Tomorrow".

The Revolution will be containerized: Architecting the insightful applicaions of Tomorrow
Linux containers are increasingly popular with application developers: they offer improved elasticity, fault-tolerance, and portability between different public and private clouds, along with an unbeatable development workflow.

It’s hard to imagine a technology that has had more impact on application developers in the last decade than containers, with the possible exception of ubiquitous analytics. Indeed, analytics is no longer a separate workload that occasionally generates reports on things that happened yesterday; instead, it pulses beneath the rhythms of contemporary business and supports today’s most interesting and vital applications. Since applications depend on analytic capabilities, it makes good sense to deploy our data-processing frameworks alongside our applications.

In this talk, you’ll learn from our expertise deploying Apache Spark and other data-processing frameworks in Linux containers on Kubernetes. We’ll explain what containers are and why you should care about them. We'll cover the benefits of containerizing applications, architectures for analytic applications that make sense in containers, and how to handle external data sources.

You’ll also get practical advice on how to ensure security and isolation, how to achieve high performance, and how to sidestep and negotiate potential challenges. Throughout the talk, we’ll refer back to concrete lessons we’ve learned about containerized analytic jobs ranging from interactive notebooks to production applications. You’ll leave inspired and enabled to deploy high-performance analytic applications without giving up the security you need or the developer-friendly workflow you want.

Read more:
https://2017.berlinbuzzwords.de/17/session/revolution-will-be-containerized-architecting-insightful-applications-tomorrow

About William Benton:
https://2017.berlinbuzzwords.de/users/william-benton

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              thank you so much for joining me for                               this last session it's an honor to be                               here and I'm really grateful for your                               time and attention especially at this                               point in the week my name is Wil Benton                               and I'm a software engineer at Red Hat I                               work on a team that works at the                               intersection of distributed systems data                               science and software engineering and                                today I'm going to tell you why we're                                become really excited about containers                                and container orchestration for                                intelligent applications and by                                intelligent applications I just mean                                applications that have a significant                                analytics component but first I'm going                                to start with some history I bet you                                didn't think I'd go back to the second                                century                                this is ptolemy of alexandria he                                proposed a geocentric model of the                                cosmos imagine the entire universe as a                                set of concentric spheres and calculated                                the sizes of each and the distances to                                each of the heavenly bodies and the                                positions of things now now we know that                                this is wrong but the surprising part                                about Tollan Ptolemaic astronomy is that                                it was actually pretty useful if you                                were willing to put up with a super                                complicated model and make an adjustment                                of a few percent every couple years the                                things didn't get too out of whack you                                could you could use it for agriculture                                and navigation and so on and this is                                what people used until the                                             when Copernicus said well no actually                                the Sun is at the center of the universe                                and this model had several benefits it                                was simpler it required fewer                                adjustments it explained more things and                                it was substantially closer to the truth                                although it's still not not perfect                                right so the interesting thing about                                this is that we like to see human                                progress or the progress of science as                                sort of a cumulative thing right we're                                we're building on everyone's                                accomplishments before us we're standing                                on the shoulders of increasingly large                                giants but                                                            science Thomas Kuhn actually challenged                                this idea by introducing the concept of                                a scientific revolution and a paradigm                                shift when we go from Ptolemy to                                Copernicus we have to throw away a lot                                of the work we did to make sense of the                                cosmos and to make sense of what we done                                like all that work you did to make                                adjustments to the the geocentric model                                is useless once you have a heliocentric                                model so really human progress looks a                                lot more like this you do some things                                you make some                                and you have to throw that paradigm away                                and the cop with a new one                                so Coons book on this topic is called                                the structure of scientific revolutions                                and it's worth reading if you're                                interested in philosophy of science or                                the history of ideas well what does this                                have to do with analytics well for a                                long time we've been operating under a                                cluster centric model where you have a                                compute cluster and you know analytics                                is something you run on your computer as                                a separate workload maybe you devote                                that to generating reports maybe                                occasionally you do some batch model                                training but the demands on this are not                                that great now like the Ptolemaic model                                this paradigm works adequately as long                                as we don't push it too hard but                                increasingly people are pushing it they                                want to run applications in this model                                as well they want to run interactive                                queries and notebooks they want to run                                stream processing and people have done a                                lot of really clever things to extend                                this model and make it work here but I                                think we're seeing a paradigm shift                                where analytics isn't just a separate                                workload that we run on a separate                                analytics cluster analytics is really                                something that underlies a lot of                                interesting applications right if you                                think about the applications you use the                                most the ones that demand your attention                                the ones that demand your money the ones                                 that are on the home screen of your                                 phone those things probably all have                                 significant analytics components so we                                 really want to see a model where instead                                 of thinking about what can we run on our                                 computer we want to think about what do                                 our apps require we want to go from a                                 cluster centric model to an app centric                                 model cluster centric model no longer                                 makes sense if analytics is no longer                                 something we just run on the side so in                                 the rest of this talk I'm going to                                 introduce containers Linux containers                                 and explain why you might want to care                                 about them for developing and deploying                                 your applications I'll present some                                 architectures for running intelligent                                 applications in containers and I'll do a                                 little bit of history on analytic                                 architectures from the past we'll talk                                 about some practical things that you                                 have to worry about to make sure that                                 your containers run correctly and are                                 safe and have high performance and I'll                                 show you where you can go from here so                                 to start off how many people in here                                 have used Linux containers before                                 okay how many of you have a Linux                                 container in production somewhere great                                 so a lot of people have an idea of what                                 a container is but if you ask people to                                 define containers you often get sort of                                 a fuzzy I know if it I see I know it if                                 I see it kind of answer because we                                 really associate containers with a                                 constellation of capabilities rather                                 than with a sort of technical                                 implementation so you'll get answers                                 like Oh a container is really like a                                 lightweight virtual machine or it's a                                 way that I can isolate my applications                                 from one another and they're not going                                 to interfere with one another and some                                 of them just say well this is this is a                                 packaging format this is this is like a                                 docker image right this is something I                                 run in kubernetes and all of these                                 things have some truth to them but                                 they're all wrong in subtle ways right                                 so to figure out why these things are                                 wrong let's look what a container                                 actually is and we'll start by looking                                 at the humble Linux process when you                                 have an ordinary process on a Linux                                 system you have an environment you have                                 an executable and you have pointers to                                 some kernel resources now some of these                                 kernel resources are namespace                                 like your process table your root                                 filesystem and your network route if                                 you're running in a container that just                                 means that the kernel can change these                                 namespaces to control what you see so                                 instead of seeing the same process table                                 as everyone else on the same host you                                 might see a different process table                                 maybe it only includes you instead of                                 seeing the same root filesystem                                 as the init process on your host you                                 might be running in a subdirectory of                                 that root filesystem and your network                                 routes you may have some new routes you                                 may not have all the routes that other                                 processes have we may builder out                                 services directly to this container but                                 other processes on the system can see                                 this process that's running in the                                 container they know that it's there and                                 sometimes this process itself can tell                                 that it's running on a container on                                 another system so a container runtime                                 just provides a convenient way to wrap                                 all this stuff up together and package                                 up a base file system image so you can                                 use it by contrast and you can also                                 impose some resource limits on on                                 containers                                 by I'm sorry that's in miles per hour by                                 contrast virtual machine hypervisor                                 runs an actual operating system kernel                                 as a process and if you're running in a                                 virtual machine you can't tell that you                                 don't have a whole machine to yourself                                 unless there's a serious bug in the                                 hypervisor and other processes running                                 on the same host your virtual machine is                                 running on they just see that you have a                                 virtual machine hypervisor running they                                 can't look inside and see what processes                                 you're running in that virtualized                                 operating system so a container                                 addresses some of the same use cases as                                 VMs but it's not a lightweight VM right                                 if it's a completely different thing and                                 it has some different trade-offs                                 similarly because not every resource                                 that you can access from a Linux process                                 is namespace the container is not a way                                 to totally isolate a provide reasonable                                 isolation at very low cost and a                                 container is not just something you run                                 in docker or kubernetes or a system that                                 that orchestrates containers on you're                                 really running in a container all the                                 time you just might be running in a                                 trivial one right because you're still                                 running a process with namespaces you                                 just might have the same namespaces as                                 everyone else so when we talk about                                 building applications out of containers                                 usually people talk about combining them                                 together in micro service architectures                                 and a micro service architecture is                                 basically where you just have some                                 lightweight modular and generally                                 stateless processes that have                                 well-defined interfaces and contracts                                 and can work well together and this is                                 what we would deploy on a container                                 platform like kubernetes now                                 service-oriented architectures are                                 nothing new and micro services are not                                 free of trade-offs but the trade-offs                                 they have are actually pretty good for                                 the kinds of applications we want to do                                 and we can see what some of the                                 advantages are for operators and                                 developers for operators micro services                                 are really easy to scale up if you have                                 a large single machine you can run as                                 many micro services on it as the machine                                 can stand if you're large single machine                                 is no longer                                 to run your application you can scale                                 out by moving these services to                                 different machines since they                                 communicate through well-defined                                 interfaces they don't have to be                                 co-located on the same physical hardware                                 in fact if these are stateless                                 components and any one of them can you                                 can replace the one to do the job then                                 you get these other nice benefits like                                 you can run a bunch of copies of one of                                 these services behind a load balancing                                 proxy or if one of them crashes and goes                                 away you can replace it trivially micro                                 services have great trade-offs for                                 developers as well because stateless                                 services are easier to test in debug                                 than stateful services how many times                                 have you like tried to reproduce some                                 sequence of events to reproduce a bug in                                 a complicated system it's pretty tough                                 but with micro services you're almost                                 dealing with a bit so this is a bit of a                                 stretch but you're almost dealing with                                 pure functions right you just sort of                                 need to say I have an API I have a                                 contract and does what I get satisfy                                 that contract or not and if it doesn't                                 you know you have a bug and you know                                 where to look for the bug another really                                 huge advantage of micro services for                                 developers is that you have a                                 possibility to develop a great workflow                                 and we saw this in gal there's talk in                                 the last session where you can have                                 tooling that checks for a new commit in                                 a git repository and when when it sees a                                 new commit it fires off continuous                                 integration if continuous integration                                 succeeds it builds a new image with your                                 changed code and it pushes it into                                 production seamlessly without you having                                 to do anything about it you just commit                                 if it works maybe you sign off on it but                                 you automatically get that upgrade and                                 since continuous integration and                                 continuous deployment it's if you really                                 think about it it's just a way to                                 orchestrate an experiment right so this                                 is not just good for developers it's                                 also good for data scientists how many                                 of you have gotten a notebook from a                                 colleague that you couldn't run on your                                 machine and get the same results                                 anyone know books are for reproducible                                 research but they're not always                                 reproducible but if you have a container                                 workflow like this where you have the                                 entire environment that you run it in                                 packaged up in a neat way and then you                                 have continuous integration                                 you can get these better guarantees and                                 really get more reproducible results so                                 another term that we talked about with                                 containerized applications is this idea                                 of cloud native applications in the                                 cloud native computing foundation is an                                 organization that's designed to sort of                                 help people design these kinds of                                 applications and advocate for them and                                 their definition is that we have                                 applications that are containerized                                 which we've covered that are micro                                 service-oriented which we've covered and                                 that are dynamically orchestrated which                                 basically just means that they can scale                                 themselves out elastically now the                                 interesting thing about these                                 definitions is that if we think about                                 contemporary analytics frameworks like                                 Apache spark and Apache flink                                 they scale out elastically right these                                 things are dynamically orchestrated and                                 the thing that might be less obvious is                                 that these things are also micro                                 service-oriented but I'll show how that                                 works on the next slide but I think it's                                 fair to say that if we have two out of                                 three of these the contemporary                                 analytics frameworks we want to use                                 might not be cloud native but they're at                                 least cloud naturalised                                 right so let's see how micro services                                 fit into something like spark if we                                 think about how spark works we have a                                 model where we have a distributed                                 collection that's in chunks of memory on                                 various executor processes and we have a                                 master which distributes tasks to each                                 of these executor x' which then                                 calculate the results so these executor                                 czar essentially microservices to                                 calculate the values of partitions and                                 in fact with spark these things are                                 essentially stateless if we ignore cache                                 which which we can do because it's an                                 optimization right I'm sorry it's late                                 in the day but but if we if we if one of                                 these goes away we have the lineage                                 graph for the RDD or the data frame and                                 we know how to reconstruct it so these                                 things are essentially microservices                                 to calculate the values of partitions ok                                 so that was a sort of whirlwind                                 introduction to containers micro                                 services and cloud native applications I                                 want to talk now about architectures for                                 applications but I'm going to start by                                 contrasting them with architectures                                 people have used in the past                                 let's look at the classic transaction                                 processing database and analytic                                 processing database to start with in                                 this setup we have events that we're                                 going to transform and we have events                                 that come directly from users we're                                 going to federate these with some                                 business logic do some other                                 transformations and put them into a                                 database that's optimized for concurrent                                 rights and and fast commits now this                                 database is not going to be suitable for                                 analytic processing it's probably not                                 even going to be suitable for sort of                                 simple aggregates and it's the thing                                 that our business is running on so we're                                 not going to put analytic processing on                                 it anyway right we don't want to put                                 anything on the critical path so we're                                 periodically going to mirror the data                                 from this database to a different                                 database that's optimized for a                                 different use case that's optimized for                                 reads that's optimized for complicated                                 queries and we'll use that to support                                 analysis which is you know often in this                                 kind of architecture we're talking about                                 reporting we're talking about taking                                 multi-dimensional data and putting it on                                 a spreadsheet but maybe we're also                                 training something and sending that back                                 to our application to use in how it                                 transforms the raw data we see and                                 finally we can support interactive                                 queries by analysts as well so this is a                                 set up that you know we've all seen this                                 in the wild right people have people                                 have done this for a long time it works                                 pretty well databases are great you have                                 joins you have a lot of really useful                                 functionality and databases but what you                                 don't have is you don't really have a                                 great way to scale out the transaction                                 processing part or historically you                                 haven't I mean people are people are                                 working on this right this is this is an                                 interesting active problem so you can't                                 get come on to descale out with this and                                 the analytic processing you have sequel                                 and you have stored procedures but if                                 you want to do anything sort of with                                 training a machine learning model it's a                                 little more painful to do in a database                                 right so this is not perfect for the                                 kinds of apps we want to write and it                                 has some limitations the the sort of                                 Hadoop style data Lake architecture                                 addresses those limitations by saying                                 well we have a lot of commodity hardware                                 and we can provide scale out storage                                 that hardware and oh yeah one of the                                 problems with this transaction                                 processing databases we don't have the                                 raw data around so if we realize we made                                 a mistake with transforming it we have                                 no way to recover what we did unless we                                 keep a keep a log somewhere so with it                                 we're just going to just going to                                 archive all the raw data to our                                 distributed file system and we get scale                                 out storage and then we'll write our                                 compute jobs so that these compute jobs                                 migrate to where the data are so if I'm                                 operating on some some part of the data                                 I'll have a job that runs on it and                                 these these jobs can communicate and                                 shuffle around and write the results                                 back to the distributed file system so                                 this is a great way to get scale out                                 storage and scale up compute on                                 commodity hardware and it's that's been                                 it's been a pretty exciting idea for you                                 know over ten years now the problem that                                 both of these architectures have though                                 is that they're both great ways to sort                                 of do analytics as a workload but                                 they're not necessarily awesome places                                 for applications because there's not                                 really a natural place for all the kinds                                 of applications we want to run in the                                 first case with the with the databases                                 you don't you have to manage and                                 schedule applications outside of the                                 database right and you have to do it in                                 such a way that's sensitive to other                                 demands on your database your                                 transaction processing database can't go                                 down or else you can't do any more                                 business right and so you need to decide                                 which clients to prioritize you need to                                 do rate limiting and so on in the second                                 case you know you can you can run                                 applications that are implemented with                                 the new MapReduce or on yarn but you                                 know maybe that's not the kind of                                 application you wrote right so there's                                 another sort of integration challenge                                 there and you also can't scale out these                                 compute and storage independently                                 because you know you basically need to                                 have as many machines devoted to this as                                 you have voted to your storage so I'm                                 going to argue that architectures that                                 separate analytics from applications                                 again only make sense if analytics is a                                 separate work load we really want to                                 look at an architecture where we're                                 considering the analytic demands of                                 individual applications and that's how                                 we want to deploy                                 applications so I want to propose a                                 really high-level architecture that you                                 can use that makes sense for doing these                                 analytic applications in containers at a                                 high level what is your intelligent                                 application doing well it's getting data                                 from a bunch of different sources it's                                 getting a stream of events right it's                                 getting structured data from databases                                 it's getting unstructured data maybe                                 from file or object storage and I'm                                 going to try not to raise Steve's ire by                                 talking positively about object storage                                 in this talk but it's going to transform                                 data from those sources and it's going                                 to federate the transform data and it's                                 probably going to archive that transform                                 data or maybe archive their raw data                                 somewhere then we're going to do                                 something interesting with that data                                 right we need to learn from it we need                                 to use it to make our application better                                 so we're going to train a model and that                                 model you know maybe that's going to be                                 a service that we run as an individual                                 micro service maybe it's going to be an                                 object that just stores a bunch of                                 coefficients that we store in an                                 in-memory data grid like in finis ban                                 and we might also use these models to                                 influence how we transform incoming data                                 you know to deal with to deal with model                                 drift and so on so we also need to                                 support some user interface components                                 you know maybe there's a developer you                                 is you can add new business rules or                                 explicitly add them all that you've                                 trained outside of the application                                 there's the actual UI for the                                 application which is maybe maybe a                                 website or maybe a mobile app or the                                 backend for a mobile app a reporting                                 interface for the business side and the                                 management interface to make sure that                                 the service is running appropriately and                                 has has decent latency and so on so in                                 this diagram I'm basically using blue                                 for storage persistent or ephemeral                                 storage I'm using orange for compute I'm                                 using green for user interface                                 components now the storage the                                 persistent storage is going to outlive                                 any deployment of our app so it's going                                 to live outside of containers but this                                 operational storage this model cache we                                 have can live in a contain                                 the UIs are often just sort of simple                                 views in tech into the application state                                 they're going to be reading from that                                 operational store they're going to be                                 interacting with components that are                                 interacting with persistent storage so                                 we can easily run those in stateless                                 containers as well now you might say and                                 then the compute part in orange as we've                                 discussed those are already micro                                 services right so you can run those in                                 stateless containers as well now you                                 might say well great so I really want to                                 run my application in containers I                                 already have a spark cluster so why                                 don't I just schedule my applications                                 alongside my spark cluster right well                                 then you get this issue where you need                                 to sort of manage the manage the                                 scheduling so that you're you're dealing                                 with a scheduler for for spark jobs                                 you're dealing with scheduler for                                 application components they need to                                 cooperate so it's really not a good                                 scene it's not ideal right and                                 multi-tenant clean food clusters are                                 pretty hard to manage right I don't                                 think there's anyone argue with that I I                                 think that's a non-controversial point                                 but I don't know no one has willingly                                 argued with me on that in my past but                                 I'm always curious right so so a better                                 model that we've seen is to take this                                 cluster centric model and turned it                                 inside out                                 go to an app centric model and actually                                 put the compute clusters in the                                 application we run everything under                                 container orchestration in in kubernetes                                 or in openshift which is an application                                 platform built on kubernetes and we just                                 say well hey we can get our                                 multi-tenancy at the container                                 orchestration level we can run all of                                 these things together they're cheap to                                 setup and teardown and we can schedule                                 application components along with the                                 compute resources they depend on we can                                 scale these out as we need to and again                                 these analytic components are just micro                                 services they work really well in                                 containers well they work really well in                                 containers once you cover a few                                 potential stumbling blocks and that's                                 what we're going to talk about now we'll                                 start with correctness including                                 security and then we'll talk about                                 performance                                 and after this part of the talk I hope                                 you'll you'll know how to put put                                 containers into practice in a way that                                 will in a way they'll work really well                                 for you first of all I want to talk                                 about security I think with any computer                                 security topic especially with                                 containers you need to think about the                                 continuum of trade-offs you have right                                 and decide what you're comfortable with                                 and so I want to start by explicitly                                 examining the continuum of trade-offs we                                 have let's think about one way to get a                                 whole bunch of job a whole bunch of                                 computers doing a whole bunch of                                 computation individual computers doing                                 their own thing not connected by a                                 network right it's pretty secure right                                 none of these can interfere with each                                 other but it's also not very interesting                                 because they can't cooperate or                                 communicate it's not not very flexible                                 so how about instead we take a bunch of                                 computers that are connected by a                                 network if we if we do this together we                                 can run different services on different                                 dedicated machines now your whole system                                 is probably going to be affected if one                                 service starts misbehaving or crashes                                 but if a service or an operating system                                 on one of these machines crashes it's                                 probably not going to make the rest of                                 the system crash and communication                                 between these machines is always going                                 to happen in well-defined ways it's                                 going to happen via message passing via                                 an explicitly shared file system via                                 something that you can understand and                                 control which is going to limit the                                 potential for problems if something                                 misbehaves and tries to write something                                 that something else has to trust so                                 going a little finer grained we could                                 look at the idea of running a bunch of                                 virtual machines on the same physical                                 machine we have a little we have a look                                 we can pack a bunch of bunch more                                 processes that are isolated on a smaller                                 amount of hardware but we're paying some                                 non-trivial overhead for all of these                                 hypervisors and all of the operating                                 systems that we're running in them and                                 if one of these crashes it's not going                                 to take down the others but if the host                                 crashes it's going to take down                                 everything                                 we can go still finer-grained                                 and imagine running multiple containers                                 in multiple containers with services on                                 the same host now containers offer                                 extremely low overhead like almost                                 imperceptible overhead and the name                                 spacing and photo mechanisms we have                                 offer pretty good isolation typically                                 your containers aren't going to be                                 sharing our file system which eliminates                                 a large class of exploits where one                                 process over writes a file than another                                 process trusts our last option for the                                 most for the lowest overhead is to just                                 run every service as a regular process                                 in the same namespace on the same host                                 there's not really any advantage to                                 doing this over running processes and                                 containers but there's no isolation so                                 there are disadvantages please don't do                                 this I think that the trade-offs                                 containers offer actually make a lot of                                 sense you can get nearly no overhead and                                 a reasonable amount of isolation but                                 there are still some things you can do                                 to improve the isolation that you get                                 the first thing you do is don't trust                                 that isolation or write remember                                 containers do not provide complete                                 isolation                                 if you run SELinux you can dramatically                                 limit your exposure to bugs in your                                 container runtime or to malicious code                                 running in a container su Linux                                 effectively walls off processes and                                 files meaning that even if something                                 escapes the container or can see outside                                 of its namespaces it won't have                                 unrestricted access to the rest of your                                 hosts and in the last six months or so                                 people who are running selinux and                                 production were totally protected from a                                 zero-day exploit and docker so this is                                 actually a real-world concern the second                                 thing to remember is that for the most                                 part users are not namespaced so if                                 you're running as root in a container                                 you're running is wrote on your hosts a                                 containerized process that's running is                                 root and somehow changes or escapes its                                 namespaces can wreak havoc on your                                 system in general you don't want to run                                 things as root in containers for the                                 same reason you don't want to run                                 ordinary processes right why you don't                                 want to pipe you know some random shell                                 script from the Internet to bash as root                                 namespaces for user IDs have been under                                 development and they've been about six                                 months to a year away for quite a while                                 but I don't think many people are                                 running them in production yet they are                                 an experimental option in recent Linux                                 kernels and docker releases but it's                                 still still on the horizon                                 another concern especially if you're                                 doing contemporary analytics is that you                                 might not have a password file in your                                 container so a lot of libraries that you                                 want to use including the Hadoop file                                 system library will want to look up the                                 currently active user from the user ID                                 in the password file to figure out what                                 their name is                                 now if you don't have a password file                                 that's going to fail and crash                                 fortunately there's a program called NSS                                 wrapper that will let you run arbitrary                                 programs with pretend password files so                                 that they can look up the user you're                                 currently running as another security                                 issue we might have to worry about is a                                 denial of service name spacing provides                                 really good isolation for resources that                                 are named spaced but not every resource                                 is named spaced and you could imagine                                 that a process could allocate a lot of                                 resources that are not named spaced and                                 prevent other processes from making                                 progress a more dramatic form of denial                                 of service the stems from the fact that                                 we're all running on the same kernel and                                 you can crash the host right if we crash                                 the host we've essentially denied                                 service to anything else running on the                                 host                                 unfortunately kernel panics from user                                 space code are still pretty rare but                                 this is a good reason to test everything                                 and have good continuous integration and                                 make sure that you're pretty confident                                 that the code works before you put it                                 into production the last security if you                                 will look at is an interesting one for                                 containerized applications if we think                                 about the fact that persistent storage                                 is usually going to live outside of                                 containers and we're usually an access                                 it via a service interface like HDFS or                                 an object store or a different kind of                                 shared file system we are going to have                                 credentials to access that and since our                                 container images are typically immutable                                 and you're going to be using the same                                 image in development tests in production                                 because you want to benefit from your                                 continuous integration right you need                                 some place to keep these credentials                                 the first thing you can do which you                                 which you don't want to do is actually                                 keep these in source control bad idea I                                 don't need to elaborate on that do I                                 didn't think so the second thing you can                                 do is you can actually store sensitive                                 information in the environment and use                                 your container runtime to configure that                                 it's possible this would leak out but                                 this is so much better than then using                                 source control that it's it's it's                                 probably okay and the third and best                                 thing to do is to use a dedicated secret                                 management service like the secrets                                 mechanism in kubernetes or a standalone                                 service like a vault something that's                                 designed to hold secrets is going to                                 give you flexibility and security and                                 that's really where you want to go with                                 managing credentials and secrets okay so                                 we've talked about correctness now I'd                                 like to talk about performance and the                                 first thing you might say which is my                                 first performance pitfall is will all                                 this security talk has me really nervous                                 I bet I could just run a container                                 inside a hypervisor and if I ran all my                                 containers inside hypervisors I'd be                                 okay right                                 well hypervisors introduced kind of a                                 ton of overhead right like on the order                                 of ten percent or so and if you can use                                 more lightweight isolation mechanisms                                 you can preserve your performance so                                 that's the first thing I say is just use                                 the lightweight isolation mechanisms                                 that make sense for containers and                                 except that the trade-offs or security                                 are pretty good anecdotally a lot of                                 people are concerned about the impact                                 that this virtual network routing will                                 have on a data intensive application a                                 colleague of mine has done a lot of                                 testing with machine learning workloads                                 and she's shown that there's typically                                 around a                                                          minimal impact on overall application                                 performance and in many cases the impact                                 of running in containers versus not                                 running hairs is lost in the noise one                                 thing that you do have to worry about                                 though is the performance of your i/o                                 configuration if you have a disk mounted                                 on the container and it's a loopback                                 device you'll have very poor performance                                 for any                                 has to hit that disk so there are best                                 practices for using disks with                                 containers and definitely make sure to                                 check that out and keep that in mind                                 another surprising issue with containers                                 and performance is interaction between                                 resource quotas and common optimizations                                 for example your default garbage                                 collection configuration may use the JVM                                 s parallel GC where you're tuned for                                 throughput and you're going to burn a                                 lot of extra cycles in order to get good                                 throughput a colleague of mine has shown                                 that in containers when you're in a CPU                                 constrained environment it may be better                                 to trade a little bit of throughput or a                                 little bit of latency for not burning                                 all your CPU quota on the garbage                                 collector another interesting issue with                                 containers is the idea of some clever                                 optimizations that certain applications                                 use that have surprising impact in                                 containers if you consider spark spark                                 uses the operating system buffer cache                                 in the shuffle basically when you have a                                 shuffle and spark you write to disk but                                 you don't sink the assumption is that                                 that data is never going to hit the disk                                 and that you're just getting some off                                 heap storage for free and if you run out                                 of actual physical memory it will get                                 will hit the disk but ideally it won't                                 now this is a great optimization in the                                 general cases it's clever its elegant                                 it's nice but that buffer cache usage                                 counts against your memory quota if                                 you're running in a container so you                                 need to think about that the last of                                 surprising interaction between the JVM                                 and containers I want to mention is                                 memory and for a long time the JVM has                                 not been aware of quotas so you could                                 happily ask the JVM to give you more                                 memory than your memory quota would                                 allow and you would only find out that                                 it was a problem when the kernel killed                                 you because you exceeded your resource                                 limit another subtle problem is that the                                 Java runtimes notion of available                                 processor cores didn't take into account                                 CPU resource limits that might be                                 applied to your container so if you're                                 using a recent build of open JDK I'm                                 delighted to tell you that this isn't a                                 problem anymore                                 if not you'll need to worry about                                 setting these limits manually and in                                 conjunction with whatever                                 as you're imposing on your containers                                 and here's what this looks like in a                                 recent OpenJDK it's past build                                       think of open JDK                                                       to open JDK                                                             limits for your heap on the Java you                                 just use this experimental option here                                 and for CPU the runtime get runtime                                 available processors method will do the                                 right thing in recent open JDK so I want                                 to wrap up now by quickly reiterating                                 what we've talked about and show you how                                 to get involved and use these techniques                                 for your own applications the cluster                                 centric model made sense when analytics                                 was a separate workload that ran                                 alongside the rest of our businesses but                                 that's no longer the case as we've seen                                 as we're as we're continuing to see                                 there's a revolution underway from this                                 cluster centric model to an app centric                                 model where we care about apps and                                 analytics really underlie every                                 important capability that we want to                                 provide to our customers or to our users                                 we introduced the ideas of containers                                 container orchestration micro services                                 and cloud native applications which are                                 currently hot topics in general                                 application development but we also                                 discussed some concrete details of how                                 you can take these concepts and apply                                 analytics in those contexts as well on                                 the architectural front we saw that                                 fortunately many of the frameworks we                                 want to use are already cloud native                                 they're already a great fit for                                 containers with a little bit of extra                                 work we've seen that you can embed                                 compute clusters in apps and get                                 multi-tenancy at the resource manager                                 level and we've talked about how you can                                 use storage outside of containers and                                 access it through service interfaces or                                 api's                                 on the correctness front we talked about                                 some common sense security things like                                 don't run in as wrote in the container                                 just because you're in a container and                                 use selinux to minimize your exposure to                                 malicious code and bugs and really be                                 careful with your secrets                                 performance takeaways take advantage of                                 containers                                 don't put your containers and                                 hypervisors don't worry about                                 virtualized networking measure                                 everything but virtualized disk is                                 probably going to be a bigger problem                                 for you than virtualized networking and                                 again measure everything optimizations                                 that are awesome outside of containers                                 may have a really surprising impact when                                 you haven't used them inside containers                                 like using the buffer caches extra off                                 heap storage so fortunately we've done a                                 lot of the hard work for you if you're                                 interested in running spark on OpenShift                                 and kubernetes my team has an open                                 source project called rad on linux do                                 where you can go to get some tooling to                                 spin up a spark cluster in containers                                 alongside your application a                                 containerized spark distribution we have                                 some example applications for how you                                 can sort of take advantage of different                                 aspects of this architecture thank you                                 so much for your time and attention I                                 time an attention are always precious                                 but they're especially so at the end of                                 a great conference if you're like me                                 you're exhausted but you're ready to get                                 back to work and you have some good                                 ideas if some of those ideas involve                                 putting your next application in                                 containers I'd love to hear from you and                                 if you're interested in doing open                                 source work on a global remote team at                                 the intersection of distributed systems                                 data science and software engineering                                 I'm I'd really like to hear a few                                 because it's the last slide in my talk                                 so I have to say that we're hiring thank                                 you thanks for the talk we've time for a                                 couple of questions if anyone has any                                 I've got one um so you mentioned the                                 resource limits at kubernetes and things                                 like that provides good ways of like                                 querying what those limits are for                                 monitoring kind of purposes or do you                                 run into that kind of unexpected barrier                                 often in practice in practice we don't                                 and we did things before before we had                                 the open JDK support we sort of did                                 things the the simple way right of                                 saying like well we're going to set                                 these resource limits and can John                                 on on our GDK in conjunction with the                                 resource limits we have on the container                                 but yeah you can interrogate this stuff                                 and you you know when you set it up do                                 so so we've got a big I think a good                                 picture on how you imagine it for the                                 compute part and you said then storage                                 comes from somewhere like electricity                                  comes from the wall so what would you                                  suggest if you want to complete this                                  architecture and we also need a storage                                  layer would you then say still run in                                  HDFS cluster next to it or what would be                                  your suggestions I think the right                                  answer to that is it depends right and I                                  know you already have HDFS right so I                                  would say you can run HDFS as a peer to                                  Container orchestration and I think that                                  works pretty well you don't have you                                  don't have the locality but there's a                                  lot of interesting sort of debate about                                  whether or not you are really benefiting                                  from locality as much as you thought you                                  were that is an amazing argument do you                                  have materials for that                                  well maybe you can let me give you a                                  look let me give you something up line                                  yeah I have a reference I just said the                                  for the frameworks that all running on a                                  cluster today you can basically package                                  them into containers and spin them up on                                  containers I'm curious if I wanted to                                  dynamic scaling where really the                                  framework itself makes the decision that                                  it wants to acquire more resources how                                  would that play with that approach                                  that's a great question so what we have                                  actually on our project is we have a                                  service that sort of pays attention to                                  SPARC metrics and communicates with                                  kubernetes and says hey give me another                                  container because if you have sparks                                  dynamic resource allocation enabled we                                  say give me another container and spin                                  it up the technical details that we're                                  running a standalone spark cluster                                  inside kubernetes so it looks to the                                  standalone spark cluster as if                                  a new machine just showed up and checked                                  in with your master okay                                  I think we're just a bad at a time                                  thanks again to will the final event of                                  the day is just about to start in castle                                  house so you're all welcome to go over                                  there and for the closing session and                                  let's thank the speaker one last time                                  [Applause]
YouTube URL: https://www.youtube.com/watch?v=4sooT4UfAJw


