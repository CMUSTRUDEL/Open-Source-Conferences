Title: Berlin Buzzwords 2017: Varun Thacker - Road to Auto-Scaling #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Solr exposes low level internal metrics which applications may consume in their monitoring tools. The talk describes various key metrics which a user should monitor carefully to maintain SLAs, both in terms of ingestion rates and query latency.

The second part of the talk presents a cookbook of recipes for admins to use by acting on the metrics. The recipes utilize a set of Solr APIs that will help expand your collection(s) to more nodes, re-shard, add more replicas etc.

The third part of this talk covers the work being done in Solr to help users scale their cluster in an automated fashion. Ultimately, upon completion of the talk, the user should be able to define a set of rules and provide recipes on which Solr may take action when thresholds are hit.

Read more:
https://2017.berlinbuzzwords.de/17/session/road-auto-scaling

About Varun Thacker:
https://2017.berlinbuzzwords.de/users/varun-thacker

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              so hi I'm Burton have been working on                               solar for like five or six years loosely                               been part of the Lucene solar project I                               work at a company called lucid works                               we're like part of my job is helping                               develop solar and implementing solar for                               our clients what I'm going to I'm a                               loose in solar committer as well and in                               this talk what I plan on talking is                                solar Road to auto-scaling that means                                back in solar for we build solar cloud                                which means it built distributed                                capabilities into solar and how we added                                api's but with ApS we needed more things                                like metrics to get more insights into                                your system based on that you could                                stitch up some common recipes to make                                sure that your cluster is always healthy                                and how solar can take all these                                experiences and build for it going                                forward to help you manage your cluster                                in a easier fashion so that was my                                agenda for the talk and I'm going to                                start with just a quick introduction of                                solar cloud so Solar cloud is a set of                                features which add distributed                                capabilities to solar so in this example                                like I am showing you you have like a                                two node solar installation which has                                two shots and like replicas for each                                shot and zookeeper is used for                                coordination between the solar servers                                now the key design aspects here were                                there was like solar cloud doesn't have                                a master node that means there is no one                                single node which accepts all the rights                                the way it works is every shard has its                                own leader which is in charge of                                accepting rights but for query time all                                replicas or all shots are the same so                                anyone is capable of serving queries to                                you so this is like a quick introduction                                of solar cloud I'm assuming most of us                                Europe familiar with it what I'm going                                to now do is move on to what our API is                                that solar supports and what's this                                new things that we built into it                                essentially what we did is we built a                                lot of ApS to help you build your cake                                cluster so it was more like we added                                collections api's to add make                                collections like to delete replicas to                                add shots                                stuff like that right so now we have a                                more regularized API everything is like                                sort of REST API so you have HTTP like                                you can configure most things in your                                solar cluster over api's we have a v                                 API which got released in solar                                six-five that means you have your new                                JSON compliant I'm going to show you an                                example in just a minute with the v                                     is we have introspection you have a PS                                for your schema and you have api's for                                your configs so slowly we've added                                support for most things in your cluster                                to be driven by ApS and you don't need                                to handle it XML or finger-like mess                                around with zookeeper a lot here's an                                example of a API write with the v                                       so you have your endpoint which is like                                the slash we do then you specify                                collections because you want to know                                what are my collection API is and I'm                                saying introspect so what this gives out                                is all the ApS that all the collection                                EP is what are the parameters it                                describes the API and it tells you how                                to use it so it's very self                                understanding API if you are interesting                                more about these v                                                    later today just specifically on it so                                I'd recommend you to go for that one and                                here's an example of how you would                                create a collection with the v                                        right so you would say create and then                                you would give it a name a config num                                shot so the parameter stay the same but                                it's JSON structure more friendly and                                more de self described in like I said                                Solar has a lot of ApS that we built                                right so you can add replicas you can                                call a backup collection you can restore                                a collection you can delete an                                Lia's you can create an alias you can                                add the shard you can delete a shard you                                can do a lot of things right but it's                                not that easy to use them like when I                                say it's not that easy what I mean is                                 you can call add replicas it's a command                                 which supports a few parameters so it's                                 straightforward to use but when you                                 design a cluster and you have to                                 maintain your own cluster you need to                                 have intelligence built in to figure out                                 where should the replicas be sitting                                 right                                 I can't simply tell solo add a replica                                 because then it could pick any node in                                 from your cluster right for all you know                                 it ends up on the same host which is                                 hosting your other replicas so you                                 actually don't get that much of                                 redundancy right so if you're hosting                                 multiple JVMs                                 on the same host so people needed to                                 build these tools to figure out when you                                 call add replicas how do i smartly                                 figure out based on my cluster topology                                 where should it go to right                                 so these api is are there but we have                                 like soullow is working towards like                                 with the auto scaling that i'm gonna                                 like lead to with how this helps you                                 manage your cluster in a better fashion                                 so this is like the aps that we have now                                 another thing with the aps is we don't                                 have much insight as to when to use them                                 so do we know like at what trigger are                                 at what point should we add more                                 replicas because we are getting a lot of                                 queries so solar always had like some                                 metrics that it was exposed through gmx                                 and a rest endpoint but in the six three                                 through six five releases we kind of                                 overhauled how the metrics work so we                                 collect a lot more metrics we use a                                 library called drop Wizard metrics so it                                 helps us collect a lot more information                                 which you can then consume in your                                 monitoring tools you can hit solar with                                 a rest endpoint to figure out what                                 metrics expose and I will show you some                                 of it in just a minute                                 the way job wizard EPS work it has like                                 five types of would you say counter so                                 it has something called counters which                                 are basically just telling you                                 long values right how many times was my                                 how many times did a search requests                                 come in you have meters which basically                                 is like a exponential time decay so                                 tells you within the one minute the five                                 minutes like it's like load average so                                 within the one five                                                intervals how many queries or how many                                 update requests came into my system                                 right then you have meters which is                                 basically telling you you're mean your                                 max your median your percentiles so the                                 meter the histograms give you that with                                 your timers you get stuff like a                                 snapshot of well like the current                                 statistics of your system are and                                 similarly you have gorgeous so all of                                 these are basically terminologies the                                 dropper xored uses to expose all your                                 metrics now the way solar designed it it                                 designed it so that it grouped metrics                                 into so called for registries so what we                                 did is we classified some things as JVM                                 metrics that means whatever like your                                 HTTP thread pools your garbage                                 collection metrics your CPU load                                 averages stuff like that went into your                                 JVM metrics then you have a node level                                 metric registry you have your core level                                 that means for each replica in your                                 index what are my metrics and then you                                 have a jetty level so let's I move back                                 instead of forward so what is a GVM                                 registry right it tells you information                                 about your OS memory it tells you GC                                 statistics it tells you what I of                                 physical memory set starts right now you                                 have your node level metrics which is                                 basically telling you how many like                                 Soler has authentication and                                 authorization so for people hitting your                                 authorization endpoint and how many were                                 failures on                                 your success so maybe you know that the                                 DDoS happen attack happening or someone                                 just internally in our system trying to                                 hit your endpoint and he doesn't know                                 the password or something like that                                 it tells you API request time so it                                 gives you updates and selects how how                                 are they performing what is the                                 percentiles it gives you counts the core                                 registry gives you request handler                                 metrics and it gives you indexing                                 statistics the jetty level registry it                                 gives you thread pool counts so tells                                 you currently in my system how many                                 search requests are going on at that                                 point of time right these level of                                 insights we never had it in the past so                                 along with it being exposed as a gmx and                                 a rest endpoint with the drop result a                                 pfv also has something called reporters                                 what reporters are basically it helps                                 you push these metrics to external                                 systems so if you have your own                                 monitoring tool or if you are using any                                 third-party tool it can reporters api                                 can help you push data to these systems                                 now solar already ships with a few                                 reporters built-in so if i using                                 graphite or if you want to just log it                                 out to a file and then you have a tool                                 to ship that to your own reporting API                                 you can use it that way and what you can                                 also do is you can write a custom                                 reporter so with this plugin what you                                 can do now is you want to push data to                                 your own reporting tool so drop wizard                                 itself comes with like third-party                                 libraries so to save for these reporting                                 tools a lot of them come in built so                                 they're like                                                            that are already there if you just go to                                 the drop fizzer third-party library                                 website so what I did as a proof of                                 experiment when I was preparing for the                                 slides is I was like I'm just going to                                 push this to influx TV because I found                                 this tool called graph on ax which was                                 easy to visualize and I was actually                                 like I got it set up and it just took                                 like a few lines of code to write a                                 custom report oh so if you follow the                                 github project there it's it shows you                                 it has instructions and it's like just a                                 hundred or lines of code to glue it into                                 the solar reporter API so it's very easy                                 now to even push it to your system so                                 till now now we've shown how the metrics                                 come in and why do we need metrics right                                 so now that we have metrics your tools                                 can consume these metrics and use the                                 solar api's to now say in more                                 intelligently decide when should I add a                                 replica when should i shard my system                                 more much in sites like that right so                                 now what I'm going to talk about is a                                 few recipes so how can I take a matrix X                                 X and then say I want to increase a                                 throughput of my system or something                                 like that right so I'm going to talk a                                 little bit about that just before I do                                 that I want to bring out this one                                 concept of solar cloud because I'm going                                 to like use a recipe which kind of                                 relates to this so I'm going to talk a                                 little bit about the solar replication                                 mode what that means is how does                                 replication work in solar cloud right so                                 SOLAS default replication model is                                 designed for consistency what that means                                 is when you add a document to the index                                 it goes to the shard leader now that                                 shard leader writes the document to the                                 transaction log once it has written the                                 document to the transaction log it                                 writes it to its own local Lucene index                                 and it forwards the request to all the                                 other replicas that the shard could have                                 right so you will have many replicas for                                 each shot now all the replicas also                                 write to the transaction log at this                                 point and then decide                                 to the index now the client which well                                 or the port like if you manually send                                 the document to index will only get back                                 success once all the replicas have                                 acknowledged success or failure but like                                 it's a synchronous call you wait till                                 all of them reply back obviously if a                                 replica fails to write solar will put                                 that node into recovery but it's a block                                 like it so it's you're bounded by your                                 slowest replicas right now with solar                                                                                                      months what we added is more replication                                 modes so basically we said we'll bring                                 back like a pull model so people use                                 cases where you don't have say a new                                 real-time use case where you don't want                                 documents to be searchable instantly or                                 where you want to separate reads from                                 writes you're going to be able to create                                 a new type of replication for a replica                                 so and where you only tell that replica                                 to pull from your leader you are not                                 never going to forward the document to                                 that so you're isolating a read from a                                 right so these are application modes                                 that are going to be there in seven oh                                 and there will be talks and blogs about                                 this in the following weeks because a                                 lot of this work is already in there                                 with that I'm going to talk about a                                 three like styles of recipes using our                                 API sand the metrics that we now collect                                 so the first tile is how do we increase                                 query throughput right so how do we know                                 when our queries are not performing well                                 so the syntax I'm using your is the top                                 in the top box is basically the metrics                                 I've just taken three example metrics                                 here that were exposed and the names of                                 these metrics and maybe we should use                                 this to judge when like are we not being                                 able to like avi bottlenecking on                                 something right so the first is our                                 query dot select request times so this                                 gives you stuff like my percentiles your                                 Max and                                 statistics like that you can find the                                 system load average so this is pretty                                 cool now you can even know the solar JVM                                 what how much CPU is it or load averages                                 is consuming and you can also find out                                 through the metrics the GC activity for                                 the process right so these seem like                                 fairly straightforward things you should                                 be monitoring and with this if you want                                 to increase query throughput what would                                 one do right                                 you could simply add replicas and just                                 scale out horizontally if you scale add                                 more replicas you are reducing the load                                 on each server so in turn it might even                                 help you with your query latency as well                                 and what you can also do or like if you                                 don't want to add a new replica if you                                 don't have near real-time requirements                                 some of your replicas can use the new                                 replication model that I just spoke                                 about so they are just serving query                                 traffic that means they are not indexing                                 documents they are fetching indexes from                                 the leader so there is a delay but if                                 you don't care about like it being one                                 minute or still then your leader you can                                 isolate these reads and that way you can                                 increase your query throughput now                                 switching gears how do we improve a                                 query latency right so you can measure                                 stuff like again in the select the                                 request times you will get out the like                                 this is the                                                             minute rate you get the                                                and you also get statistics like your                                 thread pool how many threads are being                                 used right now in the system so you know                                 how many concurrent queries are running                                 now how do we improve latency one thing                                 to understand here is a search for that                                 shot is single threaded that means if a                                 search is for that shot takes                                           we cannot do anything to optimize that                                 so the one way we could go about it to                                 reduce query latency is you could add                                 more shots or you could split existing                                 shots right so that way if a shot was                                 taking five seconds to query now since                                 you have two shots you're going to be                                 using more parallelism and you're going                                 to be getting faster response times                                 obviously there's always a trade-off                                 between throughput and latency but                                 that's a strategy one could use oh and                                 there are other downsides to this like I                                 was pointed out while I was talking                                 about the strategies if you are using                                 like say faceting which is you're using                                 your having lots of shards and your                                 facets are very complicated since you                                 have to merge facets across shards and                                 you have to like calculate more                                 sometimes that overhead could be more                                 than what a splitting like could give                                 benefit you could benefit out of so                                 something worth trying the simplest                                 thing that I ask people to do is create                                 a collection which is one shard in an                                 environment keep adding documents to it                                 till you see query SL is that you would                                 expect it solar can keep right so if you                                 want queries to be under                                     milliseconds keep pumping documents into                                 a one shot collection and querying run a                                 test to see at what point at how many                                 documents does it start getting slower                                 than                                                                     can simply take that and correlate with                                 the number of documents you plan on                                 having inner system eventually or the                                 current like how much you plan on having                                 right now and decide your sharding                                 strategy so that's just like that so                                 that's the way I tell users to go about                                 sorting and improving your query latency                                 now what about indexing right so if you                                 add a lot of documents with index like                                 I've seen people like add a couple of                                 million documents a second how do we                                 achieve those type of throughputs                                 what we do is you could obviously                                 measure stuff like your system load                                 average you would see GC activity                                 another indication of when can a system                                 not handle so much indexing throughput                                 is because of heavy GC or the system                                 always being pegged nodes are going into                                 recovery because you're rights aren't                                 being acknowledged within a particular                                 time all the nodes are going into                                 recovery and you're seeing lots of                                 merges happening in your system so it                                 even exposes statistics like merges                                 through the matrix so if you see like                                 cases like this and if you really want                                 to push your indexing more what could we                                 do right we could simply add more shards                                 again that way we are also scaling out                                 rights and if you have like more disks                                 that you can attach discharge to or like                                 that way is a common practice where                                 people can then scale out their eyes if                                 you are doing bulk indexing you could                                 like reduce the number of replicas for                                 that period of bulk ingestion so you can                                 like you've indexed like                                                 million documents and then you add the                                 replication factor back up to three or                                 whatever you would want to so that would                                 lead to faster bulk injection times you                                 can also use the combination of these                                 new replication types that I spoke about                                 to increase indexing throughput right so                                 if you want to keep three replicas or                                 ten replicas but if you don't have your                                 near-real-time requirements why should                                 you write to all ten of them if they can                                 catch up after a few minutes well and                                 good right so another way you could                                 improve indexing throughput like this so                                 now that we've understood how to use                                 metrics combine them with epi is what is                                 solar doing starting solar                                           make this easy for you right so these                                 are the set of features we are going to                                 be                                 calling it like auto-scaling so to say                                 so I will help you manage your cluster                                 design your cluster better it replaces                                 sollars existing replica placement                                 strategy with a more generic policy                                 engine so you can this like write your                                 own policies and so with auto scaling                                 there will be concepts like an event and                                 a trigger so you can act on events with                                 triggers and stuff like that so I'm                                 going to be talking about it in general                                 like you know just a second                                 so the first concept is what is a policy                                 a policy is essentially a set of rules                                 that you can use at a cluster and a                                 selection level let's take an example                                 that you can Solar has a concept of an                                 overseer node this overseer node is in                                 charge of operations like admin                                 operations so when you add a replica the                                 overseer node actually takes the request                                 and like finds it out to the actual node                                 that should be adding the replicas so                                 what if you want to see say that I have                                 a very big cluster and the overseer                                 should get its own dedicated node so                                 what you could simply say is for node                                 rule as which is not an overseer make                                 sure you have you don't have any                                 replicas on that so you can say don't                                 have replicas on my overseer node you                                 can you can design another policy by                                 saying for a collection for every                                 replicas or for every shot make sure                                 that no single node has more than two of                                 them right so it will be able to figure                                 out when when you call an add replicas                                 you don't like its now if even if you                                 don't specify the node it you can go to                                 a you can give it sensible defaults like                                 this right this is part of solo seven                                 this is rather going to be part of solo                                 seven and what you can do is when you                                 create up or when you call the                                 collections API you can specify these                                 policies so that the collections EPS                                 will respect these policies now comes                                 these concepts called events and                                 triggers so what is an event an event                                 can be like a node loss or a node got                                 added into the system or my search rate                                 went over                                                             events that so you could define in the                                 solar auto-scaling api's with an event                                 what you would                                 is you could perform actions based on                                 triggers so what would what would the                                 trigger do it would compute a plan and                                 set of actions that need to be carried                                 out                                 let's say like what you had asked the                                 system was on a node added event make                                 sure that I add more replicas so that I                                 make sure that that node automatically                                 gets filled up right so when a node gets                                 actually added a trigger will computer                                 plan saying for these collections you                                 had asked that I maintain a replication                                 factor of something so your are the N                                 add replicas calls that I need to make                                 on this new node it can carry it out for                                 you or it could like by default just                                 give you this plan by saying your are                                 the API calls you should be making in                                 the system so it's not gonna like you                                 have the option to just have it printed                                 out and an operator then says here this                                 makes sense I'm going to go execute it                                 say this is still a work in progress so                                 it's been worked upon like if you follow                                 this zero you will see all the work                                 that's been happening in the community                                 with this and looks like by the way this                                 is turning out it's probably not going                                 to be in seven Oh a lot of this events                                 and triggers and how to act on them will                                 be part of solar seven one which will                                 follow seven Oh in a few couple of                                 months so that's the rough plan now                                 what's next we feel like using solar                                 will probably be releasing                                              next month or so like in a couple of                                 months all of these that I spoke about                                 right like et eyes then I spoke about                                 matrix I spoke about some recipes and                                 then the auto scaling all of them will                                 have more detailed and multiple talks at                                 leucine revolution and over the coming                                 months since they'll start at                                 being used in practice and like the                                 auto-scaling stuff will be part of solar                                                                                                     space and see what's upcoming so that's                                 all I had to pretend thank you yeah okay                                 do you have some questions                                 will there be any metrics on replica                                 historic replicas failure in terms of                                 fencing of the note that's starting to                                 have problems would you need to be                                 stirring kind of recovery history                                 separately defense of note sword reckon                                 that's going to be something that would                                 be in okay so what they're saying is if                                 and at any question what asking is when                                 lots of replicas are going into recovery                                 or if they've gone in the past or undo                                 the metrics capture that information I                                 don't know as far as I know that's not                                 something we've added so it doesn't all                                 these metrics right are they not                                 persisted so they can go beyond solo                                 reloads but if you restart a JVM they're                                 gone but at least we could probably                                 expose them that's like worth something                                 you could at least create a JIRA like                                 just show in the last ten minutes how                                 many nodes have gone into recovery or                                 seven sorry yes that's that's a fair                                 enough point so yeah I would say like if                                 you're at least point this out create a                                 JIRA and if if you have like if you have                                 time or if you are inclined to like                                 patches always welcome so another                                 question                                 yeah I thank you for the talk what I                                 want to ask you is the rest our piece                                 you were actually present here do they                                 are available also for solo slave                                 architecture and solar or do their other                                 some recipes you can't use in solo slave                                 are so so your question is all these                                 events triggers are recipes would they                                 be for solo master slave or are these                                 just for solo cloud yes okay so all of                                 these recipes that I spoke about are for                                 solo cloud because these are like                                 sharding and replicas like i guess you                                 could translate a replica to just adding                                 more slaves but i don't know whether you                                 chard with master slave currently in                                 your architecture technically it does                                 supported but otherwise a lot of these                                 concepts were like based on solar cloud                                 people were using like master slave ah                                 please check out the new replication                                 mode which I spoke about such God we                                 called holy replicas which basically                                 integrates this master slave concept                                 because these these pull replicas are                                 essentially like slaves always pulling                                 indexes of the leader so you can then                                 start using the solar cloud management                                 capabilities and all those sharding and                                 the cluster capabilities that is                                 built-in with your solar cloud with your                                 master slave architecture so to say the                                 matrix rasathi                                 is it or will it work for muscles like                                 yes metrics are definitely part of                                 master slave because these are at each                                 jetty level so you will get exposed all                                 of these metrics okay thank you                                 regarding the the pool note level you                                 you are talking about the pool                                 hopeful a trick you can yeah and is                                 there any thing like you can define if                                 it's what's the state of the index it's                                 pulling like for example only fully                                 optimized index or all kinds of merges                                 so is there a way to specify that or is                                 it just a general replication will it                                 take the complete transaction look at                                 anytime and from what I've seen the way                                 it works like this is a new feature                                 going to be released in                                            basically always periodically syncing                                 indexes with the leader so enormously                                 like you could say sink on commit or                                 sink on optimize I don't know whether                                 those triggers are particularly built in                                 just yet I'm not aware of it maybe if he                                 said offline I'll show you but in my                                 what I know the law is you can set up a                                 poll interval and it's consistently                                 sinking the indexes like which got                                 changed in that period of time so if                                 segments were merged or segments were                                 added it's going to pull those and sync                                 up ok so suppose so ok also channel I'll                                 be around and like I think a bunch of us                                 like from the Lucine solo people lawyer                                 so like feel free to ask us questions ok                                 so thanks Lauren                                 and now we have the lunch break and                                 we're estar soft bus - okay sanction                                 [Applause]
YouTube URL: https://www.youtube.com/watch?v=w0WtKKxr-eQ


