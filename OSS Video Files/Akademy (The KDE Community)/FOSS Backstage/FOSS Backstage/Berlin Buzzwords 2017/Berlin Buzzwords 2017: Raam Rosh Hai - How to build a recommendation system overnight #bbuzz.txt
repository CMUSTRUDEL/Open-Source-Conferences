Title: Berlin Buzzwords 2017: Raam Rosh Hai - How to build a recommendation system overnight #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Your CEO runs up to you looking scared. Your competitors are recommending related articles based on context and machine learning and the current ML system keeps crashing.

Our embedded iframe is inside popular news sites with millions of articles and thousands of concurrent visitors, The systemâ€™s uptime should at least match these well established companies. You have to fix it, now.
What do you do? Run? Convince the CEO that Machine Learning and Natural Language Processing are passing trends? Or do you reach for open source tools and set out to do something better than your competitors in just a few days?

We went for the third option; using Elasticsearch, as the heart of this system.

Elasticsearch dynamic templating was used for mappings which support specific types like geopoints and dates but still let users dynamically add fields and events.

We wanted simplicity and reliability in an embarrassingly parallel system, and implemented a reactive streams system. This let us build an asynchronous recommendation engine caching recommendation results in the background so they can be promptly served when asked by the frontend, This has proven resilient enough to give us sleep, simple enough to be maintainable and flexible enough to serve millions of users while keeping costs low.

These kind of scenarios happen on a daily basis; I will demonstrate how the right design decisions got the product out of the door on time, kept management happy and kept us engineers sane despite the time pressures involved. If you are tired of those nightly dinner "treats" here's a solution.

Read more: 
https://2017.berlinbuzzwords.de/17/session/how-build-recommendation-system-overnight

About Raam Rosh Hai:
https://2017.berlinbuzzwords.de/users/raam-rosh-hai

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              hi my name is ROM I'm a data engineer at                               fine hotel and before I lived in                               Amsterdam I work in a small startup that                               had a an engine problem I want to tell                               you the story of how we solve that                               problem we start by quickly explain the                               project requirements and then we go over                               the architecture and why we did what we                               did at the end I will present some                                things that weren't obvious to me from                                the get-go so the main save point of the                                product we were working on was the                                premise to increase the visitors time on                                site we want to help our partners direct                                the users to more content that they                                liked since this product is embedded                                inside the partners page it carries with                                it a few problems we don't know when new                                content is added and we have no                                straightforward way to find out the                                obvious choice is to scrape the partners                                website periodically and index changes                                to a database this is very                                labor-intensive having to create scraper                                for each partner this solution we                                obviously not scale to a time when                                partners will be added interactively and                                not manually by our sales team we plan                                to cut our customers to always display a                                recommendation this meant was that the                                bed answer is better than no answer                                nonetheless the commendation should                                still be useful otherwise nobody would                                click on them these clients that                                symbolize our project in the website has                                much bigger things than ours the uptime                                is quite oppressive they serve news to a                                large portion of Internet users and it's                                a season scratch it will directly affect                                their pages we knew where to deliver                                this feature quickly since the current                                accommodation system we had was not very                                variable it was not seven commendations                                most of the time keeping the steps in                                the process status greatly reduced the                                complexity of our application we could                                treat each part of the program                                independently this meant we can fit the                                whole thing in a head and also grab the                                components easy to change what it is I'm                                making sure data flows in one direction                                inside the pipeline this way we could                                carry all the data we need forward                                throughout transformation steps to solve                                our first program in the king old and                                new articles when they are posted                                we use the fact that users view these                                pages each view would then generate the                                post request which indexes the quickly                                visited page and trigger the commutation                                generation I was surprised to find out                                that the published articles can have the                                body tags and even titles changed so                                constantly indexing these Capitol                                commendations fresh we quickly quickly                                realize we don't have enough manpower or                                budget to maintain a public-facing                                elasticsearch cluster within a small                                team we're only two people so we use                                elastic search capabilities as                                computation engine sending simple                                queries getting a list of results back                                and persisting them in the object store                                assisting the results of the object                                store allows us to run a tiny cluster we                                could control the request rate and apply                                back pressure when needed                                only the ARCA streams application had                                access to the elastic search cluster                                which ensured control overloads on the                                system serving the suggestions for the                                data store allows us to focus on                                delivering delivering value and not                                focusing on extinguishing fires when the                                system crashes so even if you did crash                                no one would notice it because all of                                the other Commendation was still being                                served we didn't have to do too much to                                set up elastic search to do what we                                needed we use the dynamic templates to                                define text fields with the correct                                analyzers this way we didn't have extra                                work when the model change or when we                                want to add more languages the English                                our analyzer has a list of support                                redefined and stemming support which                                fits well with the text with humans we'd                                and we use some dynamic templates we                                could define the text field to be                                 indexing the raw form which have which                                 is helpful for things you want to match                                 as is like tags using this template we                                 could dynamically add languages an                                 indexing we didn't have to waste our                                 time on fiddling with too many settings                                 which reduced unplanned work the query                                 we used was very simple we put each                                 field from a JSON object into a stem                                 quarry and fill the filtered by time                                 range                                 you can see we use the rough fields for                                 things we had to exactly match like IDs                                 keywords and the analyzed field for the                                 title in description we also filter out                                 the current article watch animating                                 suggest suggestions for from the results                                 because obviously each article always                                 matched itself and we don't want it in                                 the results list so the result of this                                 query is then sorted by score and                                 posited to an object or ready to be                                 served to all of our users now when I                                 imagine what the queue does a picture                                 something like this a conference of                                 streams being pulled to a central                                 repository the mental model for picking                                 things from queue is far more                                 straightforward than a web front-end                                 this lets us abstract away all but all                                 but everything by the data we have to                                 work on and we can only focus on that                                 we're in control of the data so                                 application can simply request a piece                                 of work and start working on it                                 immediately this allows us to twist to                                 treat our incoming traffic as a string                                 of data coming in one way being                                 transformed and passed forward which                                 allows impaired embarrassingly parallel                                 applications like ours to the just work                                 in parallel with very little overhead                                 another adventure of using queue of a                                 connecting the computation engine                                 directly to HTTP front-end is that we                                 could recover the collection process                                 from the transformations we wanted to                                 apply to our entities and finally we                                 could of course replace the cute                                 messages in case of a failure                                 so we end up with a classic lambda shape                                 we use the Q to melt all of our traffic                                 and treat it as a single source we then                                 press the messages from the queue to our                                 computation engine producing a list of                                 accommodations which are then persisted                                 to our object store this was just sorry                                 this object store should expose the                                 public API so we will have direct access                                 to the data F                                                        does it out of the box but you can also                                 use ready ladies behind engine X or any                                 key value engine so setting the                                 precomputed recommendations from the                                 objects or further decouple serving the                                 data from digesting is giving us two                                 tracks a one-way track for ingesting                                 data and another one for setting it this                                 mental model translates very naturally                                 into Skyline occur streams we start with                                 the source in our case with Paul for                                 changes and once we get them that                                 published downstream to the                                 transformation steps we convert the                                 incoming payload to a domain object                                 index it the indexing step is used for                                 scraping our partners and keeping the                                 elastic search index up-to-date with a                                 query elastic search with the same data                                 that payload we just indexed and made to                                 create a list of recommendations and if                                 it's a new article it will produce fresh                                 recommendations it was never seen in the                                 object store but if it was already                                 scenes we just overwrite the same key                                 and then we have updated recommendations                                 the list of recommendations then purge                                 to the other store immediately pivot                                 now since indexing the articles and                                 searching for them have no dependency we                                 can tell occur streams that this part                                 could be done in parallel so we just                                 change map to map async                                 easy so what worked well after looking                                 at the problem in understanding it                                 understanding it we threw away all the                                 scraping code we had and we use user                                 pages users page view to index a                                 partner's content so we got rid of                                 technical debt we got rid of a lot of                                 code                                 dedicating it it is pretty nice Chris                                 now I noticed all our partners are using                                 HTML meta tags these tags are used for                                 sharing in social networks so the                                 partners usually put some thought into                                 them decade valuable information so we                                 parse HTML tags on these pages we                                 excited all the needed information on                                 the article and generated                                 recommendations for it this also meant                                 we could turn off the scripting engine                                 which cuts operation costs of course in                                 the technical data I mentioned before                                 the second big win was realizing we                                 could use an object store to save the                                 commendations this saved us a lot of                                 stress since we only had to guarantee                                 the object store is running which in                                 which was in our case a service on AWS                                 so we didn't have to do anything occur                                 streams is a great example of reactive                                 streams implementation it Maps very                                 nicely into the metamodel stream                                 processing and transformations which                                 greatly increase the productivity                                 another advantage of our streams is the                                 async abstraction that lets you write                                 the application as you normally would                                 but see that you've leveraged all                                 available codes using docker was another                                 good bet with that paid off it gave us                                 producible bills which has a sketch many                                 bugs we would usually catch in                                 production like environment sensitive                                 config and all sorts of dependencies                                 that had to be bundled with the                                 application so backing the application                                 logic inside document we could try                                 different environmental deployments very                                 easily but it's not all orders it became                                 clear quite quickly that you can make                                 people learn Scala but you can't make                                 them change the way of thinking they                                 have to be willing to do so so although                                 functional programming concepts are                                 quite easy to explain they are not that                                 convincing your colleagues will have to                                 elevate a pain the encountering using                                 the new paradigm before they are sold on                                 this idea another thing was a monitoring                                 disability application is hard as always                                 this one is no exception                                 the nature of stream processing can make                                 it even more OPEC                                 safety because of explainin see to                                 swellow arrows if you need to explicitly                                 handle the solution so this is very                                 simple actually implementing modeling                                 from the get-go and then when you've got                                 encounter problems you know where to                                 look so to conclude I want to suggest                                 that you try solve the specific                                 screaming for problem that you have                                 right now using a functional programming                                 approach this will let you experience                                 the fluidity of the little paradigm                                 allows the more use functional                                 programming concepts the easier it is to                                 think in this way like any other thing                                 the direct mapping between the lambda                                 architecture and the extremes make it                                 very easy to define the businessman in                                 terms of code this is this notion in                                 Judaism I think in most other religions                                 that you have to experience things                                 yourself                                 in order to believe it believe in it you                                 can't explain why you should believe in                                 something can't explain why you should                                 do something only once you do it you                                 understand so I really think that with                                 the functional problem programming this                                 is the same I can talk about free monads                                 until the cows come home but no one will                                 use it unless they can really understand                                 what they are what they are solving in                                 their own doing and nobody wants to read                                 the terms of log files going to spot a                                 problem this might not even be logged so                                 there's a great collection of libraries                                 that allows monitoring and estimating                                 these to do these applications                                 kay moon is one of them and so with age                                 trace you can check out a stream size if                                 you plan on using ARCA streams it was                                 designed with the streams in mind and                                 all you have to do is in order to                                 instrumental application is to add the                                 config file what are your questions                                 hi I have a question which is did you                                 use any tooling to actually process the                                 generated monitoring data how did you                                 analyze all the stuff that could go                                 recorded to generate it can we have this                                 mic on yes yes so we actually use an H                                 trace and the the library I mentioned                                 before is sending all of the trace                                 records to Zeppelin the thing is a                                 really nice phantom that just visualizes                                 all of the latency in each step of your                                 of your pipeline or when your meet                                 microservices so basically if you can                                 you can just open it and have a look and                                 if you see like a really long like                                 graphic you know you have a hot spot                                 there and you should look into it thank                                 you where else you can lovely and then I                                 will remember to a bit a next question                                 yes Bob this is actually before Estes                                 yes policies if I can elaborate on how                                 we model users so I did mention that but                                 it wasn't you know specific we we came                                 from the assumption that if users read                                 the current articles everything there                                 are probably interested in things like                                 that and we just do that we could use                                 users you simply if you simply simply                                 index the user and then you hope it                                 would be the same because if you can tag                                 it with whatever if you have extra data                                 on on him depends on whatever you have                                 you can match age you can match                                 what city whatever and combined it with                                 the actual articles you are using now I                                 was thinking about putting it in the                                 slide but you can actually use for users                                 you can use stuff like neo                                   just take out elasticsearch used instead                                 and because everything is typed you will                                 only have to change this specific part                                 if you or your colleague already                                 collects prints before either you learn                                 kinda what you were doing the good                                 question so I had I did have a skull                                 experience but my colleagues didn't and                                 especially when the system was done was                                 had to go to like maintenance those                                 people didn't have any kind of skull                                 experience and there was one instance                                 when this really smart developer that                                 was maintaining the code he spent like                                 two days on trying to understand the                                 distance between dot : + + space : + and                                 there is no difference it's just like                                 IntelliJ quick so communicating a lot is                                 really important and not throwing the                                 developers into that it is really nice                                 doing this really slowly letting them                                 understand why they should use this is a                                 much better than just like here's like a                                 bunch of modern monitors formers please                                 have fun with it so yeah do it slowly ok                                 thank you very much they're given                                 burning anger on
YouTube URL: https://www.youtube.com/watch?v=cCOnrjKr85I


