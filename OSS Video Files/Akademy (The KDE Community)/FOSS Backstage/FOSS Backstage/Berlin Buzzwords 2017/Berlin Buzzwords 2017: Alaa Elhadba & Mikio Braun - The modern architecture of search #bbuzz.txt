Title: Berlin Buzzwords 2017: Alaa Elhadba & Mikio Braun - The modern architecture of search #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Information Retrieval (IR) systems are a vital component in the core of successful modern web platforms. The main goal of IR systems is to provide a communication layer that enables customers to establish a retrieval dialogue with underlying data.

The immense explosion of unstructured data drives modern search application to go beyond just fuzzy string matching, to invest in deep understanding of user queries through interpretation of user intention in order to respond with a relevant result set. 

The modern architecture of search is a design of a data-driven IR system that covers the following: 
- Data ingestion pipelines from various sources
- Data retrieval and the lifecycle of a user search query
- Machine learned relevance ranking 
- Personalised search
- Search performance tracking and quality assessment

The talk will discuss the components needed to build an eco-system that is designed to solve the problems of IR in web platforms. What role can Machine learning play in search relevancy? how natural language processing can help provide a solid understanding of search phrases? How data can drive a personalized search experience? What are the challenges of maintaining such a complex system?  

Read more:
https://2017.berlinbuzzwords.de/17/session/modern-architecture-search

About Alaa Elhadba:
https://2017.berlinbuzzwords.de/users/alaa-elhadba

About Mikio Braun:
https://2017.berlinbuzzwords.de/users/mikio-braun

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              all right good afternoon everybody I                               hope you had a good nice lunch break our                               talk is about the modern architecture of                               search and before I start I just want to                               say I don't want to impose any any                               methodology or technology on how to do                               things this is just a layout of                               components and architecture diagram of                               certain teams or certain components that                                are each dedicated to do a certain                                function and our teams are                                cross-functional teams between                                researchers and engineers and they're                                trying to find the best way to do this                                function so I hope there's a key                                learning for someone to see how we do                                things and we're changing the way we're                                doing things all the time but the                                function of each component remains the                                same all right so a quick introduction                                on who we are we're solando who knows                                solando or pretty much everybody I can                                cut the introduction then okay just                                quickly we're not a small company we're                                not a start-up we are used to be an                                online fashion retailer but we're                                becoming now an online platform for                                fashion so we're connecting brand                                stylist smashing bloggers customers                                offline stores everybody who's related                                to fashion on one platform that's what                                we're trying to build and we already are                                connected with                                                         million customers in                                            countries so it's not a small company                                we'll be giving the talk myself my name                                is La Habra I'm part of two teams the                                query understanding an intention team                                which we're going to dive deeply into                                and also part of an architecture team                                was designing how this would work and                                look the vision aligned with the product                                vision in the end and my colleague NICU                                Bron and delivery lead for most of the                                search teams so yeah okay thank you so                                there's a first introduction so right so                                we'll be able you're not just building                                like searchers you think about it search                                is really very very central to any                                e-commerce offering right and and also                                so we are really we don't think of                                ourselves as just a search engine or as                                part of a web website but actually                                really as a platform for search across                                all of the land oh well so here we try                                to picture a bit like how we fit into                                this whole customer cycle and also                                articles like                                so in the lower left you have the                                customer and this is supposed to be a                                monitor this rectangle thing down here                                okay and usually the sort of the journey                                starts with search so they are looking                                for something for black t-shirts and                                then this query ends up with a search                                engine which somehow produces the                                results right but where does the data                                come from so actually some like a few                                steps back there is the factory which is                                producing all the articles and they get                                delivered to our warehouses and and then                                there also we are also taking our own                                photos like we create own content for                                the website and some somewhere during                                this process or the article data gets                                input and gets fed into our system so                                this is one important sort of data and                                then this ends up in search and can                                actually be then be made searchable                                right and of course so only after people                                found articles through search they can                                actually order it this goes back to the                                warehouse and then the delivery guy                                shows up and everybody's happy right and                                at the same time so this is like just                                the one one part of the cycle so article                                data goes to search people can actually                                use it look for it get the results buy                                something and then there are many many                                different things like so how actually                                how do we decide like what to show                                customers first right under we have a                                few hundred thousand articles online at                                all times                                and we need to have some kind of sorting                                to really show the most relevant stuff                                and that's of course also something                                which belongs to search ok they look at                                this all right so before we started with                                 the architecture let's go to old-school                                 search and how we used to do it in the                                 past so in the past we were just doing                                 normal string matching using the search                                 engine right directly out of the box and                                 the idea was that to get the customer                                 input and try to match it across many                                 fields and by doing that we just run                                 smart multi match queries and we try to                                 adjust way it's manually by the hand to                                 find the better or the best combination                                 that would reflect the customer what the                                 customer expects to see from our result                                 set and doing things manually by hand                                 was always very cumbersome because when                                 you fix one bug you make other ten and                                 it was really hard to maintain adding to                                 that so we're trying to do a lot of                                 scoring functions that we also maintain                                 by hand and then everything's become                                 really fuzzy and we cannot keep track of                                 things so that's why we needed a                                 data-driven way to see how                                 can turn this into use machine learning                                 use NLP to improve our customer                                 experience and that's why we wanted to                                 move to a data-driven world all right so                                 this is the layout of components I                                 mentioned in the beginning I'm going to                                 explain how data comes in how cui flows                                 as well so how we can traverse this                                 architecture or this layout of                                 components together and we're going to                                 dig deep in parts parts of it so it's a                                 lot of a lot of different different                                 things and we cannot go deep each one of                                 them needs the talk on its own so we're                                 going to try to get deep in the most                                 important ones all right so let's talk                                 about data ingestion first due to the                                 nature of the data we're dealing with we                                 have three different sources of data                                 either we're using our product data or                                 any data that's going to be searchable                                 or using the logs which we're going to                                 try to learn from and improve our models                                 or we're crawling data from the web                                 which you're going to teach us about the                                 fashion language so the Internet is is                                 rich with all kind of text and we want                                 to learn from this text to improve the                                 customer experience on how to search for                                 fashion using the fashion language then                                 we have another layer for the data                                 ingestion we're trying to transform the                                 incoming data into fit in our models or                                 our data stores then our models are the                                 different components so we have the                                 fashion language where we try to I                                 mention already we try to learn from                                 from the web or phrases store which we                                 try to help the customer write better                                 queries or the named entities we would                                 try to map fashion terms for example                                 like blue is a color leather is a                                 material and so on so we try to use                                 named entity recognition through the                                 store or the content so the searchable                                 content we're trying to do and finally                                 data-driven sorting so how we're going                                 to sort these the results set is going                                 to be shown to the customer all right                                 now we go to the story of a query how                                 would a query would traverse the path in                                 this architecture and the customer                                 journey would be he's writing a query so                                 let's say he starts and write tips in in                                 the search bar adidas and the first                                 thing you will encounter is the query                                 helper and refinement dialogue and this                                 component is responsible for                                 establishing a dialogue with the                                 customer so that's what we're aiming for                                 is to have a conversation with the data                                 and not just full-text search or just                                 we're trying to help him                                 right the better query and if you didn't                                 write the better query then asking                                 questions that what would be the next                                 step to make your query better or to                                 find what you're looking for order                                 completion is about so we want to                                 correct spell we want to predict the                                 next word we want to resolve synonyms or                                 acronyms we want to disambiguate terms                                 we want it to be even more personalized                                 so depending on the customer affinity to                                 certain brands or certain categories                                 they would be ranked first as                                 suggestions according to his input that                                 is coming in and finally we want to use                                 this user feedback to learn how to do                                 that so how would you generate these                                 phrases that the customers are looking                                 at we have two different two different                                 sources either we're using the our                                 original product data or we're using the                                 logs so for the product data we combine                                 different fields together like brand                                 color material category or product name                                 and we generate all possible phrases but                                 based on language rules that are                                 predefined we store this in the phrases                                 store and then retrieval is then using                                 the scoring function which decides what                                 will be shown to the customer first                                 we're going to talk about the retrieving                                 score function later adding Suzette's do                                 we want to learn this person lies too                                 based on the customer logs we can                                 aggregate these together and know which                                 brands and categories he prefers in                                 order to decide this how we do this                                 personalization so the scoring function                                 of doing this suggestions we rely on hit                                 position which means the word that the                                 user is writing is it the first position                                 in the sentence or the second we                                 definitely prefer to be the first and                                 turn frequencies also entity reference                                 so if somebody's starting to write a                                 brand name or just throw in two or three                                 letters we prefer brands over colors for                                 example because this is more relevant                                 for us and also the Revathy where                                 everything means how long is the                                 customer input in comparison to the                                 suggestions that are generated so you                                 cannot enter just one or two words and                                 then you have a six seven words as a                                 suggestion so we're trying to keep it                                 like a proportionate and finally user                                 clicks and user clicks have a certain                                 time decay function which decides okay                                 so clicks that came from last year are                                 less valuable that the same clicks                                 amount that came from yesterday all                                 right so after the customer gets some                                 suggestions writes better query or maybe                                 he doesn't use this correction at all                                 and just write something and sometimes                                 they don't use fashion terms that would                                 be better for what there                                 looking for so not all our customers                                 know how to use fashion language and                                 would they say something like language                                 light which means like a long dress and                                 we we try to learn from other customers                                 who who know the fashion language based                                 on the session domain and we use                                 something called the query query                                 similarity so when people are trying to                                 refine their query we know that and we                                 know it's within the same category we                                 try to learn from it and then when                                 people would search for something                                 similar we would definitely suggest                                 based on the semantic space we already                                 know the semantic meaning of the user                                 what is looking for and we try to match                                 this with something that would get                                 better results for the customer in this                                 case maxi Clyde is the better term to                                 describe these type of dresses and to                                 add personalization I already mentioned                                 so whatever the customers doing we're                                 aggregating back in the search logs and                                 we improve our scoring based on that so                                 this was about suggestions and then                                 let's go to full text search how we                                 understand user queries and how we                                 construct them all right so let's say                                 the user starts with our money later                                 yakin which means our money leather                                 jackets and as you can see there's the                                 type of already so the first thing the                                 flow of query understanding is the first                                 thing we spell check so we fix the user                                 input and then we check against                                 redirects and I'm going to talk about                                 this later but let's say for now there                                 are no redirects and then we do any our                                 scoring so we ask the named entity store                                 what are these terms what do they mean                                 and for us they mean every term goes to                                 the named entity stores are going to be                                 checked for some scores so the term can                                 be ambiguous can mean different things                                 for example Aida which is leather can be                                 a category can be a material and we                                 score that in comparative like according                                 to the customer input we get all                                 possible scores and all possible                                 entities and then the interpretation                                 engine decides based on this course for                                 every term to spawn all different                                 interpretations combined so from every                                 from every map of term to entity we                                 spawn all possible interpretations so                                 our money could be one-time a brand                                 could be one-time a product name later                                 can be immaterial another time can be a                                 fallback can be a category and also we                                 use compound words to split later yakin                                 so we try to set                                 these sorts in German one word but then                                 if we if we want to search for later and                                 yakin alone we have to split them and                                 all these interpretations are spanned                                 out and each one it's a stream of                                 interpretations that each one has its                                 own path and within this path we want to                                 enrich more information based on this                                 enrichment based on this interpretation                                 so we would enrich stuff to try to                                 capture what the customer it's the                                 customer input is missing so we're                                 trying to capture more improve his                                 recall so some some stuff like for                                 example la di akka is also cool Aida is                                 also may be recommended for him or                                 Valley akan and we do this as part of                                 enrichment of this given stream in the                                 end we collect all these streams in                                 parallel everything is just happening in                                 parallel and we have a scoring engine                                 which decides what are the most what are                                 the best interpretations and what can be                                 the customer actually looking for and                                 the problem is if you have a five terms                                 query this could lead to                                         interpretations and that's why before we                                 do any calculation we try to use some                                 rules to improve how we can make a good                                 selection of interpretations and in the                                 end our scoring engine will give us some                                 confidence factors on each on each query                                 that is constructed in the end so we we                                 have a structured query out of the                                 unstructured incoming text from the                                 customer until now we bet high on one                                 interpretation and we use it but we're                                 now also evaluating to provide a result                                 set that combines different                                 interpretations together and then gather                                 feedback from that and see what the                                 customer is actually how we can learn                                 from customer behavior what                                 interpretation is better so back to the                                 other example sometimes sometimes                                 there's always this angry customer this                                 gangster who comes to the store and just                                 steps and blurs out one word to you and                                 you don't know what to do with it so                                 this guy comes to you and just say denim                                 and and what is denim so you're looking                                 for four jackets or pants                                 is it like skinny fit is it a perfect                                 what are you looking for how do I do                                 with it how do I deal with it and that's                                 why there is no data-driven way to deal                                 with that denim is the most ambiguous                                 term in in the fashion language and for                                 that we we have read our                                 so we try to capture we don't want to                                 pick up this guy so we try to capture                                 his his denim wishes by offering the                                 redirect and the redirect is a way of                                 doing guided search so we lend him on a                                 page where he can go through a denim a                                 different customer journey so it's not                                 search anymore but at least he can still                                 continue fulfilling his denim wishes                                 yeah I'm going to hand over to Mickey oh                                 thank you right right so this was the                                 the basic pipeline which we have and the                                 question and so but so far we haven't                                 really talked about the data where does                                 the data come from apart from the actual                                 article data okay so I'm going to start                                 there and then also explore a bit more                                 the mode data different ways of                                 enriching their data okay so as I said                                 in the beginning like the most basic                                 data you have is the article data which                                 can tell you like what are brands that                                 we have for our categories what are                                 colors and that already can give you get                                 you very far one problem is that this                                 data is usually it's sort of collected                                 by by people and it's not really it's                                 not really optimized for the search use                                 case right so there's some                                 inconsistencies and so on that's                                 original of work but then there is also                                 stuff like like new trends like new                                 vocabulary special vocabulary that comes                                 up which is not in the article data                                 right so like it was a trend like both                                 red jeans or hobo or ad so these are all                                 some some more concepts people use to                                 talk about session but which is not                                 really in the article data would be very                                 costly to add to each item and then                                 there is also stuff like occasions like                                 you want to use looking for something                                 for a wedding or for party right and you                                 cannot really go ahead and like for each                                 article decide which protects to put on                                 there so what question is how can we                                 actually in which our data using more                                 data you know to to get good databases                                 for for search so there are two things                                 one on the left right the ideas so you                                 could for example cross section blocks                                 right so there's a lot of text being                                 generated about fashion topics you could                                 crawl all of that and then do natural                                 language processing on that too - both                                 detect your trends but also to                                 understand like with which words are                                 actually related to the trend or you                                 could also will sort of say okay there's                                 a bit                                 stuff which is sort of no and we can try                                 to build an ontology for that right so                                 not like ontology and there's                                           of sense but more so like a curated list                                 of words and you sort of know what they                                 means and know how they relate to                                 articles and also how they relate to one                                 another and then if somebody types in                                 denim right so you could either have in                                 the trends you sort of know what it is                                 or in the ontology actually has it then                                 then and denim end point which then                                 tells you how to expand that thing to                                 map it back down to something which you                                 can actually search right so one more                                 one thing you can use this so you have                                 all these words and one way sort of to                                 automatically derive synonyms between                                 words is an algorithm called word to                                 work words to lick difficult to                                 pronounce okay and so the basic idea of                                 this is the following that the user does                                 some kind of like beside deep learning                                 approach to to learn a representation of                                 the words in a vector space where                                 similarities are semantic so right okay                                 so what does it mean so the basic idea                                 is so you have like stuff like friends                                 with this capital pair so you have all                                 these sentences talking about words okay                                 and the idea is you sort of you take the                                 weather two words occur together as a                                 hint for whether they have similar                                 meaning right so here both words friends                                 pairs both occur with capital and that                                 sort of says okay maybe this is if                                 there's enough statistics to explain                                 that or - right then there's some                                 relationship between these things and                                 what you essentially do is you construct                                 you you sort of you take you encode all                                 the words in this really long vector                                 which has just all zeros except for one                                 at the word which you're looking at so                                 everything is zero except for the one                                 place where that you have front and then                                 what you want to get out of this is you                                 want to have the probability that this                                 word occurs together with France like in                                 the same sentence okay and the model                                 sort of internally you have a much                                 smaller space let's say maybe yes I                                 don't know fifty thousand words here but                                 actually internally you you only have a                                 thousand numbers you're trying to map                                 this through right and then so there's a                                 very nice post here by                                 McCormick's and L which which explains                                 this and steps but the basic idea is you                                 sort of you're building a network which                                 predicts these probabilities based on                                 the input but in a way that it has to                                 reduce the dimensionality and                                 interestingly what comes out is that in                                 this space you have so in this                                 representation in this space words which                                 has similar semantic meaning are also                                 close and you can even do like a bit of                                 arithmetic in there to sort of take do                                 stuff like okay what is like friends to                                 Paris is like London - hmm and then you                                 do this kind of thing and you get out                                 that this actually there to England okay                                 and you can sort of you can do this                                 right you can take all the the fashion                                 blocks that you have and do this kind of                                 analysis and then do something like a                                 data-driven brand for placement or                                 category replacement to sort of help                                 extend the way the search works okay so                                 once we have all of this so we have this                                 big pipeline right we enriched our data                                 from other data sources and we first                                 helped sort of extend the searches with                                 autosuggest and other things we                                 understood the thing and have enough                                 interpretation and then what you have in                                 the end is so you start with this                                 unstructured query which is essentially                                 just the search text you do all this                                 analysis and then you end up with a                                 structured query and then you can fire                                 this again like search of the context                                 tent which would be more classical                                 search engine like elastic search of                                 solar and then all of that you get the                                 result set and then the question is the                                 next question is how do you actually                                 present these results okay and that                                 brings us to data different sorting                                 right so usually when you do search like                                 full-text search you have a lot of                                 indicators of what is relevant to which                                 word which are the documents which                                 contain this word very often and so on                                 but but in this context here because                                 this is more or less a structured query                                 right so this could be show me all                                 articles which are in that category for                                 that color for the brand well there                                 isn't a lot of like the data itself                                 doesn't tell you a lot what is actually                                 relevant or not so what you want to do                                 is you want to take the like all the                                 user interactions and all of that to                                 sort of determine what is what is most                                 relevant                                 okay and actually the problem is pretty                                 so we often say like that that sorting                                 is like the most political feature of                                 search because there are many many                                 stakeholders who want to influence that                                 right so let's say you guys have this                                 article grid and of course the lower you                                 go the less relevant the article should                                 be and then there are stakeholders right                                 to say okay actually I want to push up                                 this article because this is from a                                 brand we made an arrangement we are                                 pushing up stuff a bit right or they say                                 the season has changed now we want to                                 push up all the some articles you want                                 to push down the other articles and all                                 of that and all these people come by and                                 say you know I want to change the                                 sorting in this way or another way yes                                 or actually so there are different ways                                 what you can do about this so it's not                                 just simply you know you look at what                                 people are clicking it or what people                                 are buying and you sort this up but so                                 usually you have some so one thing we                                 have for example doing we are                                 introducing a bucketing logic on the                                 sorting right so we're saying there are                                 different kinds of articles or the                                 articles which sell really well                                 which are their articles where we had a                                 lot of returns or something and we put                                 them into different buckets and that                                 already gives you like a very cause way                                 to steer actually what's up and what so                                 and then within these buckets you can                                 actually use a fully data-driven                                 approach which sort of again the user is                                 the monitor and some from that you get                                 locks which look like this so they're                                 different articles and the the action                                 back keep left clicked on a particular                                 sport and this is the position where to                                 turn                                 occurred in the in the scene right and                                 then what you want to do is you want of                                 course have the articles which are                                 clicked and bought often higher up than                                 the rest and in the end you can use                                 their learning to rank so there were a                                 lot of talks already and this but                                 essentially what you do is you get the                                 the article itself so not the article                                 itself but some representation of that                                 article for example in terms of brands                                 colors and all of that right so you're                                 trying to describe the article to the                                 learning algorithm and you you put in                                 like the the rank where it was clicked                                 and then based on that you're trying to                                 learn a model which predicts well the                                 rank of the like what in which in which                                 order you want to present the articles                                 and you combine all this with a bucket                                 logic to be able to to steer the whole                                 thing for you                                 okay and is learning to rank so there                                 are many different ways to do it there's                                 a one paper from Torino fraeno who                                 actually works and recommendation at the                                 londo so I'm not definitely not going to                                 explain this thing right but in the end                                 so what you have to sasai w that's sort                                 of your model it's a very simple model                                 which sort of takes your your features                                 and just puts different weights on there                                 so it says okay this brand b if it's if                                 it's this brand and actually it should                                 get a weight of                                                          sauna some of all these things and this                                 gives you an ordering and the only                                 interesting thing sort of is that the                                 the loss function you're trying to                                 minimize this piece down here right                                 that's actually what it's trying to                                 measure is if if this function you're                                 predicting gives you the right order                                 right so the main difference between                                 learning to rank and other kinds of                                 learning is the the how you are                                 measuring the the fit of your model well                                 then you don't measure it by whether you                                 can correctly predict the rank or                                 something but if you take the                                 predictions and then sort your items                                 according to this prediction then the                                 the ordering should be the right thing                                 and this is sort of what makes these                                 things a bit complicated but this is a                                 very interesting nice paper which is                                 also very very schedule very well and                                 you can really learn on millions of                                 clicks with very little                                 computation overhead ok so this sort of                                 completes the whole pipeline right so we                                 had to layer the query the extra query                                 we went to different stages we got the                                 results head we sorted it so the last                                 question is what about personalization                                 so personalization I mean very roughly                                 the idea is sort of you're not they all                                 have different different like                                 preferences and so on and the goal is of                                 course to find the most relevant                                 articles for each user and there's a                                 sort of sort of here but preferably also                                 in a way that you have the feeling                                 you're not just interacting with the                                 database but actually something that                                 just users trying to understand you ok                                 indeed now the interesting thing is you                                 should take this kind of data-driven                                 approach then actually it's not that                                 much it doesn't it's not that much more                                 to to add the personalization to all of                                 that                                 right because let's say so you already                                 have a data-driven approach where you                                 put in the features of your articles but                                 you could just enrich this                                 representation also maybe with some of                                 the features which you have on the user                                 and then in the interaction between                                 these things right it's very easy or                                 it's very easily general generalizable                                 so that you can also take into take into                                 account like at all what your what the                                 favorite brands of user or what what is                                 past purchases were and so on and you                                 can just extend it yes okay so this is                                 actually on time this is it so thank you                                 very much all right if we have some time                                 for questions plenty of time for                                 questions because there's one in the                                 back minute hey thanks for your talk                                 I was curious how do you train your what                                 to Vic models which kind of knowledge                                 space data sets or the one basis is to                                 have all these these cross session                                 blocks                                 okay but you have a like a generic                                 crawler or you just take like dedicated                                 set of whitelisted sites and you just go                                 through them yes they are no we have no                                 it sort of the troll also expands itself                                 and sort of takes in links and then                                 discovers new blocks but they have this                                 kind of infrastructure running which is                                 I don't know how many blocks crawling                                 right now but it's a few thousands I                                 think but you can take that and then                                 also expand it with like our Wikipedia                                 dumps and all of that is it the same                                 corpus you train your entity recognizer                                 no think right not I mean the problem is                                 you can it's not so then you have these                                 session blocks but they are not really                                 they are pretty unstructured right and                                 for this entity recognizer you actually                                 have to have like data which is labeled                                 for example                                 Thanks or yeah I mean it's a combination                                 of both we have we mainly rely of course                                 on the fashion content that we have so                                 we have a lot of fashion content from                                 our product data that we can learn from                                 so this is the first generation of our                                 model but we also can get similarities                                 or we can get stuff that is related to                                 it from from crawling the web as well                                 and see how people would relate to stuff                                 and these fashion blogs usually contain                                 a lot of terms and a lot of things that                                 explicitly describe how these fashion                                 products would look like and it's                                 another reference for us to learn from                                 [Applause]                                 you said.you training your models from                                 curries can you talk a little bit about                                 like how what's the reoccurrence                                 frequency of a query like how often you                                 see the same queries and what's the                                 distribution of this can you remember it                                 from your question I didn't get it clear                                 like when if if all your query is that                                 you're seeing at this thing                                 learning is hard right so they need to                                 react EUR to to infer some information                                 from it yeah I mean there's of course                                 the distribution of query so if you look                                 at it as like the top queries and then                                 there's a long tail of queries that are                                 laid out and some of the queries are                                 like coming very frequent so on that                                 distribution I'm not sure how to ask you                                 a question but maybe it isn't obvious                                 with the pin distribution right the                                 you're seeing and a lot of like a small                                 amount of queries that are reappearing a                                 lot of times if this enough to train                                 your models or to trying to categorize                                 queries together to increase the                                 frequencies so okay can I talk about the                                 query query similarity or I don't know                                 as I can ship yeah okay so we in in a                                 way we try to correlate queries together                                 to find the similarities between them                                 from the semantic meaning yeah so this                                 this already exists in the logs and we                                 know which queries are there and if we                                 put this in the back to space model you                                 already can correlate queries together                                 and we can also do it the other way                                 around that instead that we build a                                 model that each product could point to a                                 query as well so this is way where                                 there's lots of ways that we're trying                                 experimenting with to see how we could                                 model this that's that's one way of                                 doing it is welcome                                 all right more questions this one                                 I think you said you're serving                                          different countries your company is                                 operating how do you deal with                                    different or possibly more languages                                 always the same system with different                                 input or how do you do that so there are                                                                                                          correlate on languages and we have                                 different pipelines for example for                                 analyzing each language we have                                 different pipelines we have different                                 challenges in dealing with each language                                 hook down for example the German                                 language has the compound words which                                 this concept doesn't exist in English so                                 that's why we try to deal with each                                 language specifically on understanding                                 on enrichment and on analysis and for                                 search like then when you do the query                                 processing so our our online shop is                                 distributed as each country gets its own                                 domain and each domain would talk its                                 own direct language path so there they                                 do not say they're not together on one                                 on one query search bar for example                                 Thanks after thanks for the told my                                 questions about learning to rank if you                                 have used a solar official                                 implementation of the elasticsearch                                 implementation or some custom solution                                 with the announced sorry which again if                                 you have used they officially last a                                 solid learning today or the elastic                                 stage plug-in or something will die now                                 so okay so an official statement were                                 big fans of elasticsearch first of all                                 and second is we did we do not use them                                 learning to rank from from any we built                                 our own engine and in recommendation and                                 in search and maybe make you could say                                 language about it                                 yes I mean I only know wrote the paper                                 and of course he also did his own                                 implementation of that okay                                 and staying with their learning today                                 about the goal set and about the number                                 of issues that you can just give some                                 numbers to an understanding about you                                 ever deal with arson I think this is                                 pretty detailed yeah maybe maybe we can                                 talk about it like offstage yes yeah you                                 had a slide with an ontology on it my                                 question is what are you using ontology                                 is for first and the second one which                                 kind or which anthologies are you using                                 so we are using so we're using it also                                 to to sort of record additional fashion                                 dictionaries or vocabulary like colors                                 or something but it's I mean so we're                                 still building that up but it's nothing                                 it's again some so that is one of the                                 companies which creates a lot of stuff                                 writes a lot of stuff in-house right so                                 but the idea sort of that you you can't                                 find all kinds of words and then also                                 know how they relate to each other and                                 also our relate to articles and the                                 second question second question is what                                 what was it which ontology also these                                 authorities are had to rated by                                 ourselves on which level do they work so                                 are they top level on top geez domain                                 anthologies you know no I don't know                                 so we have a dedicated team that built                                 this ontology not letting you in Berlin                                 and in Helsinki which should have                                 supported and one of the use cases we                                 want to use these ontology zin different                                 things not just in search so this would                                 would help the company in many different                                 directions correlate terms and fashion                                 fashion terms together and one of which                                 is to try to enrich queries with with                                 better understanding so if the customer                                 writes something and we can we can                                 correlate it for other different terms                                 that can make a better understanding of                                 these requir that's just one use case of                                 how to use autologous okay thank you so                                 a lot of these topics are quite diverse                                 and many teams are working on it so                                 definitely we cannot answer all the                                 questions                                 yeah chat one last question about the                                 learning to rank maybe you said that                                 from the generators query out of after                                 the credit passing you're doing there's                                 not much information you get back as a                                 score from the search engine itself if                                 you want to do learning to wank                                 afterwards you need something like you                                 can do that on three hundred thousand                                 results that comes out of the search                                 engine to calculate and really score                                 them so how do you find something like                                 the top results that then as using to                                 produce better to produce pesticides for                                 the customer because you cannot do that                                 on oil the result yeah not also will the                                 onion so that's what I meant with so we                                 are of course not we ranking each                                 individual item or article but we're                                 actually mapping the article to certain                                 features like the brand stuff like that                                 you know and then the learning to rank                                 works on these features I mean so what                                 we're so that you're not trying to learn                                 whether this this specific issue where                                 this should be but more like the other                                 features of the two so how would that                                 rank because the very very simple thing                                 is why do you want to show people some                                 people are more interested in other                                 brands and then you want to push these                                 up but once you have these sort of                                 things you can of course put this to                                 this course also to the article data and                                 then you know use use normal queries to                                 compute the scoring function based on                                 that for example all right any more                                 questions one in the pepper is one of                                 the father great                                 then we would have time for one more                                 question no we close it afterwards                                 offline discussion                                 hey my question was kind of more                                 specific to where where do you actually                                 fit in the word to Zack Porter                                 because for your named entity                                 recognition you essentially do I guess                                 query expansion and that kind of made                                 sense to me but do you essentially take                                 the output of Ward Tyvek and enrich your                                 data's offline do you also do query                                 expansion with like France and Paris                                 online with that how do you actually                                 like use the output of word Tyvek                                 no okay so yes it is part part of the                                 enrichment process we do different types                                 of enrichments one of them is to use the                                 word Tuvok so for example for to enrich                                 categories or or to find any anything                                 that is similar so to find similar                                 brands as well for stuff that have low                                 result set so if we get like a zero or                                 three to ten result set we can we can                                 replace terms that defined to increase                                 recall for example and this is part of                                 the enrichment as well all right so that                                 then you do this online essentially for                                 like replacing the query terms in a                                 query or categories that you filter on                                 it's not an offline process that you                                 then add more properties to your                                 documents that you search on just there                                 so it's sort of like a post-processing                                 steps if sort of you have very small                                 result sets right because otherwise it                                 would explode the next expansion yeah so                                 the model is pre learned and it on real                                 time so in query time okay so thanks                                 thanks a lot for your attention so we                                 have a booth right around the corner and                                 if you want to work for the Llano i'm                                 talk to us yeah let's take the stick up                                 again                                 that is                                 [Music]
YouTube URL: https://www.youtube.com/watch?v=BhAGrenI_xE


