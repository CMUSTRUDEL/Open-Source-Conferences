Title: Lightning Talk: Nick Pentreath - Native Dense Vector Scoring in Elasticsearch
Publication date: 2020-07-02
Playlist: Lightning Talks -  Berlin Buzzwords | MICES | Haystack – Joint Virtual Event 2020
Description: 
	Lightning talk from Berlin Buzzwords | MICES | Haystack – Joint Event 2020
Captions: 
	                              hello everyone welcome to the lightning                               talk session at Berlin buzzword                                    I'm your host a theorem and I would be                               your host for I would be hosting the                               lightning talk session tonight                               personally looking at the list of topics                               that we have for the sessions today I                               think I'm super excited and I look                               forward to each one of these talks I                                hope you guys have a good time just to                                let you know if you have any questions                                please keep them posting on in my sis                                life channel and I think without further                                delay let's welcome the first speaker                                for tonight Nick over to you thank you                                very much Peter and welcome to yeah this                                is very quick lightning talk on native                                Dean's vector scoring in elastics which                                it likes to be by my first lightning                                talk I normally do longer one so let's                                see if we can get through everything on                                time I'm ml Beck on Twitter our gets up                                and LinkedIn principal engineer working                                at IBM Center for open source data and                                AI technologies focus on machine                                learning and artificial intelligence of                                a principal software how we're a team of                                over opened three open source developers                                at IBM focusing on a wide variety of                                data and AI open source software                                frameworks and projects so we'll start                                just talking about what are vectors and                                you know Victor is essentially a ordered                                an indexed set of numbers very much like                                an array you have different you know                                gain some sparse vectors but the dense                                vectors we'll be talking about today are                                very much narrow and why did I matter                                they actually arise in many different                                scenarios so we can represent various                                things as vectors including images music                                movies it's used they can be used in                                e-commerce and recommendations social                                networks and even documents                                so one example that we're vectors are                                very common is in recommender systems                                and in recommenders we have a set of                                users and we have a set of items so for                                example in movie recommendations the set                                of items might be a list of the set of                                movies or videos and you can see here on                                the bottom left we represent the user                                ratings given to the set of movies as a                                matrix and it's it's a sparse matrix not                                every entry is fold so that means that                                might be user as rated every movie and a                                typical approach for doing recommended                                recommendation systems and recommender                                models is matrix factorization and that                                takes this matrix that we see on the                                left and it splits it up into two                                smaller matrices and first is a user                                matrix and a second is a movie or item                                matrix and each entry eat each column or                                row as it as the case may be in one of                                these matrix that matrices is actually a                                vector so it turns out that you create                                to compute a predicted rating for a                                movie and a user combination we just                                take a user vector and we perform a                                linear algebra operation dot product                                between the user vector and the item                                effective and as a part of this matrix                                and similarly if we want to find similar                                items which power things like products                                you may want to buy we do a similar                                cosine similarity so this looks very                                conceptually similar to you the way                                search ranking works we start with a                                query we represented as a term vector                                kind of primary term vector perhaps we                                compute a similarity and then we sort                                the results by similarity effectively so                                can we use the same set of machinery to                                to compute arbitrary vectors that are                                not necessarily the typical of search                                query vectors so for example in                                recommendations we have a user vector                                the dot product cosine similarity                                Machinery is quite quite similar to what                                we use in search ranking it's a scoring                                and ranking work but the term vectors                                don't necessarily work because the way                                they took that                                arrays and vectors are stored in the                                elastic surgeon you know natively up                                until now has has effectively been meant                                that the the array gets stored as an                                unordered set of numbers so we lose that                                 ordering and we lose the ability to                                 direct the operations we need on those                                 vectors so here's a way around this and                                 up until now a way to do this was to use                                 a different representation for the term                                 vectors and then use a custom plugin                                 which would be your scoring function                                 which would allow you to do things like                                 dot products cosine similarities and                                 other I would treat functions but                                 there's the third require custom code                                 and loading a custom plugin in Java and                                 that adds complexity so definitely it                                 works but it's not necessarily the easy                                 way to do things and for example in an                                 environments where you don't control                                 necessarily the the cluster and you                                 can't add plugins it makes it difficult                                 to use so this has been solved recently                                 in less elasticsearch                                                  vector type effectively an ordered array                                 stored as a binary with added in ES                                     and then vector functions in                                 seven-point-three built-in effects                                 depict the functions of the type that we                                 need for for doing things like                                 similarity and scoring top rights and                                 cosine similarity so you can see there                                 that we've got some attains vector that                                 we can we can have as a mapping you know                                 properties and we just need to specify a                                 dimension so this gives us everything we                                 need if we compared to the what we had                                 previously we can take a vector that                                 represents let's say user what item in                                 recommender systems or what image if we                                 doing image search or documents that is                                 the output of a machine learning model                                 we'll be planning model and we can apply                                 native scoring functions like top                                 products and cosine similarities and so                                 on and get our ranking and this is all                                 now all built in we don't need to do                                 anything funny                                 so I'm going to very quickly try and                                 show                                 example of this and this is a                                 elasticsearch spark recommender that                                 I've credited for my work at IBM this                                 very long notebook I won't go through                                 all of it but works through hard to kind                                 of load data into spark from realistic                                 switching to spark run recommendations                                 and then other movies using this exact                                 functionality that we talked about so                                 the key here that I just want to                                 highlight is that as you see we can                                 simply create a vector type for users                                 which specifies the dense vector type in                                 the dimension and similarly for for                                 items or movies in this case and then                                 all we have to do is actually plug                                 straight into a standard script query                                 let's go to scroll query where the score                                 function is exactly cosine similarity or                                 top product and that's it at the end of                                 just using that functionality we have we                                 get recommended movies and we get                                 similar movies okay                                 yes thank you for sticking with me for                                 these probably a little bit more than                                 five minutes now I encourage you to go                                 and check out the code Padma I mentioned                                 and check out code a.org and find me on                                 Twitter github thank you                                 you
YouTube URL: https://www.youtube.com/watch?v=vbyEYnEFgZQ


