Title: #bbuzz 2015: Georgi Knox - Scale with NSQ: a realtime distributed messaging platform
Publication date: 2015-06-05
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	Find more information here: http://berlinbuzzwords.de/session/scale-nsq-realtime-distributed-messaging-platformtform

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              you it's always hard being the last                               speaker on the last day                               to scale with nsq yes so my name is                               Georgie I'm a back-end software engineer                               originally from Sydney Australia and I                               moved to New York in about the summer of                               last year to work at bitly for those who                               haven't heard of bitly we're a really                               popular URL shortener most of our stack                                is written in Python and go and on                                average we serve around eight to ten                                billion clicks per month and that works                                out to be about                                                   second we then compute a lot of                                interesting analytics around how and                                where those links are shared so we get                                to tackle lots of interesting problems                                of scale at bitly and one of the core                                pieces of our architecture is nsq so                                what is nsq well it's an open source                                real-time distributed messaging platform                                that was built in-house and bitly and                                it's written entirely and go it's now                                been in production for over three years                                and is used by a range of companies that                                you can see here and there are three                                core components that make up and ask you                                that I'll going to go over in this talk                                so to explain how nsq works we'll start                                with a really simple example and build                                on top of that so let's say for example                                this is really early bitly we have a                                single host and an API that shortens                                lengths and returns synchronously to our                                API clients and then a new requirement                                comes in to track metrics against these                                requests don't the naive approach here                                would be to add in a step before we send                                the response back which where we                                synchronously right in to our metric                                system before returning back to our                                client but what would be the problem                                with this approach what happens when our                                metric system goes down will our API                                request then hang or fail what happens                                when our API becomes really popular how                                will we Hale scandal in scaling                                increasing API requests volume or                                breadth of metrics collection so we're                                starting to see that this current setup                                has a tight coupling problem and if we                                continue to build additions to this                                system in the same way we'll end up with                                a real mess of interconnected components                                one way to resolve all of these issues                                is to perform the work of writing into                                our metric system asynchronously that is                                place our data in some sort of queue and                                write in to our metric system via some                                other process that consumes that queue                                this decoupling allows the system to be                                more robust and fault tolerant a bitly                                we use nsq to achieve this let's talk                                briefly about a couple of basic                                messaging patterns which are core                                concepts of nsq this is a broadcast                                delivery mechanism you can see that the                                message is copied across and delivered                                to two distinct groups of consumers a                                and B for example a here could be                                consuming it could be something that                                updates a metric system and consumer B                                might be one that writes metric writes                                the messages to disk for audit logging                                so what does this pattern achieve well                                it allows us to decouple producers and                                consumers the producers don't need to                                know about who is consuming the message                                and similarly the consumers don't know                                or care whether data comes from next we                                have the distribution pattern in this                                messaging pattern data is pushed down a                                pipe where we then load balanced                                messages across Alcon connected                                consumers you'll notice both consumers                                are the same color and they're both                                called consumer a so they're going to be                                doing the same work and that could be                                for example writing messages to disk for                                audit logging what this pattern allows                                for is horizontal scalability as the                                volume of our stream changes we can                                introduce and retire consumers as                                required to handle variable throughput                                the other advantage of this pattern is                                that it's great for failure cases so                                let's see what happens when one of our                                consumers fail                                love that animation when the next                                 message comes through we see that the                                 Kim is the consumers that are still                                 available we'll continue to be able to                                 handle the throughput and lastly when                                 all the consumers die in a fire our                                 queue will hang on to those messages                                 until such a time when new consumers can                                 come back online to handle them these                                 message patterns are the building block                                 for something called nsq D which is the                                 first component in the larger and SQ                                 architecture nsq has a concept of topics                                 and channels which are implemented as                                 primitives a topic is a unique stream of                                 messages and a real world of example of                                 this that bitly might be our klicks                                 topic which is a stream of messages for                                 every click that is made on a bit length                                 on the Internet and a channel is a given                                 copy of that stream of messages for a                                 given set of consumers at bitly for                                 example we might add a few channels of                                 the klicks topic such as metrics channel                                 to count all the things a spam analysis                                 channel to understand if these were in                                 fact in fact legitimate clicks or if                                 they were spam an archive channel which                                 writes each of these messages to disk                                 that so that our data science team can                                 do some analysis at a later point under                                 these under the hood topics and channels                                 are both independent cues - and these                                 properties enable nsq to support both                                 multicast which is a topic Kabat copying                                 each message to end channels and                                 distributed message delivery where a                                 channel equally divides its messages                                 among end consumers and it's important                                 to point out here that both topics and                                 channels are created at runtime so                                 there's no need to describe this                                 hierarchy upfront as producers come and                                 write messages to a given topic the                                 topic will be created conversely if                                 consumers come the channels that they                                 are subscribing to will be created so                                 let's see this in action firstly I'll                                 just add a few consumers so a message is                                 pushed through NS QD                                 and copied across in a topic to all the                                 channels it's then load-balanced to the                                 connected consumers for a specific                                 channel and I'll just show that again so                                 the message is copied across and then                                 delivered to just one of the consumers                                 so what we've just seen here is a                                 combination of broadcast messaging with                                 load balancing and fault tolerance to go                                 through yeah so what's happening under                                 the hood most of this stuff is                                 implemented in with go channels                                 specifically nsq leverages buffered                                 channels to manage in-memory message                                 queues and writes overflow to DES so nsq                                 has this concept of a high watermark                                 where during extended downtime of a                                 downstream system messages will be kept                                 in memory until they reach that                                 watermark and after which time they'll                                 be written to disk then when the                                 downstream systems come back online the                                 messages both on disk and in memory will                                 be sent topics and channels are                                 independent and this means that if one                                 of your downstream systems is having                                 issues then only a single channel will                                 backup and all of the other channels for                                 that topic will still be able to                                 successfully process messages let's go                                 back now to that example of our simple                                 API that we had at the beginning of the                                 talk and we'll walk through some steps                                 to add in NS QD so firstly we'll spin up                                 an instance of NS QD on the same host                                 that runs our API next we'll update our                                 API application to publish to the local                                 NS q instance to queue events now                                 instead of directly writing                                 synchronously into the metric system                                 we'll instead write to NS QD and this                                 can be as simple as performing an HTTP                                 POST request                                 lastly we'll build a consumer in a                                 language of our choosing and using an NS                                 q client library subscribe to that                                 stream of data coming through the                                 channel our consumers can then process                                 the events and write asynchronously into                                 our metrics                                 our consumers can also just be run                                 locally on the same host as our API and                                 nsq the instance by adding an NS QD                                 we've now decoupled the production and                                 consumption of data which means that if                                 the metrics system experiences issues it                                 will be isolated from our system's                                 ability to shorten links and return to                                 our kernel clients the other nice                                 approach of co-locating everything is                                 that we can scale horizontally we can                                 easily put a load balancer in front of                                 two or more hosts and continue to handle                                 increases in incoming volume and sq                                 lookup D is the second component of the                                 nsq architecture so what does a typical                                 nsq cluster look like here you can see                                 three co-located NS QD instances with                                 their API the API is publishing locally                                 to NS QD and topics are created as run                                 at runtime when the first message is                                 received by n s QD on a topic it'll push                                 a registration message over to all                                 lookup D hosts lookup D is the daemon                                 that manages topology information and                                 it's basically just a directory service                                 which matches topics to producers look                                 up the instances don't coordinate so                                 that means that they each have their own                                 independent copy of the mapping of                                 topics to producers and this gives some                                 nice fold fault tolerant characteristics                                 so you could for example lose one of                                 these lookup D instances and the others                                 would continue to service requests just                                 fine in a typical data center you might                                 see three of these so why have we why                                 the need to add lookup there here well                                 if we took look up D out of the picture                                 each consumer would need to hard-code                                 the address of where each of the NS QD                                 instances live and this is kind of a                                 pain what you really want is for the                                 configuration to evolve and be accessed                                 at runtime based on the state of the NS                                 q cluster the NS QD instances maintain a                                 persistent TCP connection to the lookup                                 D instances and register themselves as a                                 as a producer for a given topic and all                                 the channels that they know about                                 this means that consumers can query                                 lookup D for topic locations rather than                                 the hard coding them when they get the                                 IP addresses of these producers they                                 Union them all together and then                                 subscribe to all of them directly of                                 having animation fail here so over time                                 these consumers will learn about the                                 existence of new producers and be able                                 to route around failures because in this                                 example we have co-located and as QD                                 instances with our API what we've done                                 is seamlessly create three shards that                                 our external stream feeds into and that                                 isn't something that we needed to                                 configure up front and again comes as a                                 side-effect of our deployment so back to                                 our original service that we're scaling                                 again this time we'll see what happens                                 when we add in lookup D and some new                                 consumers so nsq will log in and push a                                 registration event across now let's say                                 that we want to archive this topic we                                 can use a NS q                                                       bundled with the NS q are binary                                 download and all it does is write                                 streams to disk this tool works the same                                 way as other consumers where it                                 continually checks in with lookup D to                                 find out where the topics are being                                 produced the consumers could then                                 connect to all discovered producers and                                 subscribe to their topics so now we have                                 a second group of consumers that is                                 consuming the same data and performing                                 some action and this archived data can                                 be really useful because it can be                                 pushed into things like s                                                be used for like an audit log for any                                 production problems so we've seen in                                 this example how discoverability works                                 within nsq by using the lookup directory                                 service lookup D directory service we've                                 been able to decouple producers from                                 consumers and adding in our new set of                                 consumers was really trivial we just                                 specified what topic we were interested                                 in and queried lookup d                                 so what are some nsq guarantees or                                 messages are delivered at least once                                 which means you can and will receive                                 duplicate duplicates and this could be                                 for a variety of reasons such as client                                 timeouts disconnections or riku udders                                 it's the clients responsibility to                                 perform item item potent operations or                                 deegeu messages are also not durable by                                 default we talked previously about the                                 configurable high watermark but by                                 default at bitly we run with a hybrid                                 in-memory on disk setup messages                                 received are unordered so you can't rely                                 on the order of messages being delivered                                 to consumers and this is a result of                                 recuse and the combination of in-memory                                 and on disk storage and the fact that                                 each n SQ d node shares nothing                                 consumers will eventually find all topic                                 producers the discovery service and SQL                                 cup D is designed to be eventually                                 consistent and as mentioned previously                                 lookup D nodes don't coordinate to                                 maintain or state or answer queries                                 topic and channel pausing are a couple                                 of Handy features of nsq tooling here                                 we've had some channels similar to                                 previous slides we've got the metrics                                 channel a reporting channel and an                                 archives channel we really know that                                 normally messages get copied they get                                 delivered and processed successfully but                                 now let's see what happens when we pause                                 the clicks topic messages start pooling                                 at the topic level and this is really                                 useful for a variety of operation things                                 such as renaming channels or introducing                                 new ones in an atomic window you could                                 also introduce new systems that you want                                 your data to right into when we unpause                                 the messages will be processed                                 successfully                                 we also have channel pausing and if we                                 pause the reporting channel here then                                 messages will queue at that channel and                                 again beyond be processed successfully                                 when we unpause a couple more tooling                                 features so this image here is of NS q                                 admin and that's the final component of                                 the whole NS q architecture and what NS                                 q admin does is allow you to view                                 aggregated clusters statistics in real                                 time and perform various administrative                                 tasks so it will show things like queue                                 depths how often messages are being                                 recued and how fast clients are                                 processing things it will also allow you                                 to do things like pause channels and                                 topics and lastly NS Q has something                                 called ephemeral channels and these are                                 channels that disappear when your last                                 client disconnects and are useful for                                 one-off scripts or inspecting a stream                                 for debugging purposes so that's all I                                 have you can find a copy of my slides at                                 this link and I thought given that this                                 is like the final talk on the final day                                 rather than keeping everyone here to                                 answer questions maybe what I'll do is                                 leave it here and if you do have any                                 questions come up and see me thank you
YouTube URL: https://www.youtube.com/watch?v=OwD-W7uU2zU


