Title: Berlin Buzzwords 2015: Andrew Clegg - Signatures, patterns and trends: Timeseries data mining @ Etsy
Publication date: 2015-06-04
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	Etsy loves metrics. Everything that happens in our data centres gets recorded, graphed and stored. But with over a million metrics flowing in constantly, it’s hard for any team to keep on top of all that information. Graphing everything doesn’t scale, and traditional alerting methods based on thresholds become very prone to false positives.

That’s why we started Kale, an open-source software suite for pattern mining and anomaly detection in operational data streams. These are big topics with decades of research, but many of the methods in the literature are ineffective on terabytes of noisy data with unusual statistical characteristics, and techniques that require extensive manual analysis are unsuitable when your ops teams have service levels to maintain.

In this talk I’ll briefly cover the main challenges that traditional statistical methods face in this environment, and introduce some pragmatic alternatives that scale well and are easy to implement (and automate) on ElasticSearch and similar platforms. I’ll talk about the stumbling blocks we encountered with the first release of Kale, and the resulting architectural changes coming in version 2.0. 

And I’ll go into a little technical detail on the algorithms we use for fingerprinting and searching metrics, and detecting different kinds of unusual activity. These techniques have potential applications in clustering, outlier detection, similarity search and supervised learning, and they are not limited to the data centre but can be applied to any high-volume timeseries data.

Read more:
https://2015.berlinbuzzwords.de/session/signatures-patterns-and-trends-timeseries-data-mining-etsy

About Andrew Clegg:
https://2015.berlinbuzzwords.de/users/andrew-clegg

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              hi everyone                               hi I'm glad I've got so many people in                               here when I'm competing with weather                               like that outside so thanks for coming                               so hi yes I'm a data scientist at Etsy                               and if you're not familiar with Etsy                               we're an online marketplace for handmade                               goods vintage goods arts and crafts so I                               was going to put in some visual joke                                here about signature jewelry sewing                                patterns and fashion trends but I                                couldn't make it funny so let's just                                pretend pretend I did that so we're                                headquartered in Brooklyn                                we've got offices in Toronto San                                Francisco London Paris Dublin and also                                here in Berlin maybe one or two others                                I've forgotten as well so just before we                                get started I'll give a bit of                                background about the data science team                                at C we do two main kind of strands of                                work I suppose the first one is what I                                would describe as helping visitors to                                Etsy find personally relevant items that                                they're loved so that means things like                                shop item and user recommendations                                finding trends calculating data-driven                                ranking factors using things like                                personalization information or location                                information that can help drive search                                or ad placement or even navigation on                                the site and also some text mining                                activities to kind of complement search                                to build things like autosuggest and                                related queries and that kind of thing                                so this is more kind of product facing                                engineering work what the engineering                                end of data science and we also do some                                stuff which is more like internal tool                                building developing like algorithms and                                methodologies and pipelines and                                workflows to help with security or                                growth or operations just to helping                                increase the value of Etsy and make make                                it easier for other teams to do their                                jobs using kind of data mining methods                                machine learning methods and so on so                                they might include things like image                                similarity search for                                finding you know images that have been                                stolen or reused or water marked images                                that shouldn't be used for products on                                the sides things I kept building spam                                like classifiers for things like                                marketplace abuse suspicious behavior                                fraud that kind of thing building                                customer lifetime value models for                                estimating how long the customer is                                going to stay with Etsy how often                                they're going to buy and what we're what                                return we're likely to see from them and                                also detecting and diagnosing anomalies                                on the site or on the machines the bakit                                so that's what I'm going to be talking                                about today in the context of a project                                called kale which has been kind of                                ongoing since                                                       overview of what the talks about start                                off by talking a little bit about kale                                version one what we try to do with it                                what succeeded and what didn't work so                                well                                why I joined the company in December                                last year so a lot of kale version one                                happened before I started but I'm still                                going to just say we for convenience I'm                                not trying to take any credit for the                                things that worked or blame for the                                things that didn't I mean I talk a                                little bit more about anomaly detection                                in particular some background on why                                it's a difficult problem but why it's                                also a useful thing to attempt and also                                why a lot of treatments of the topic                                oversimplify the issue and I think                                missed some of them some of the                                important points there and then I'm                                going to talk a little bit about kale                                version                                                               moment how we're approaching the problem                                a little bit differently and why a bit                                of an overview of the architecture and                                why we came to the architectural                                decisions that we did for it and then                                also if I'm feeling brave enough and we                                have enough time by then a live demo of                                the work-in-progress for it and then                                I'll talk a little bit about what                                lessons we learnt from from the                                 successes and failures of ko                                          you can kind of generalize from them if                                 you're doing a normally detection but                                 also if you're launching an open source                                 project and how to make that work or                                 avoid some of the mistakes we made                                 so we we launched kale in almost exactly                                 two years ago in fact at a velocity                                 conference we accompanied with a blog                                 post and release on github and it                                 consisted of two parts really the first                                 part is called skyline which was for                                 anomaly detection and the second part                                 was called oculus which was for                                 similarity search on time series data so                                 the idea was we would have data flowing                                 in from sources like graphite or ganglia                                 where machine level or application level                                 metrics are logged from our servers they                                 would go into skyline and skyline would                                 look for anomalous behavior in those                                 metrics you know for example that peak                                 in that little graph there and then once                                 a anomaly had been found you could then                                 use oculus which is a kind of diagnostic                                 root cause analysis tool to search                                 through the time series database for the                                 backing it for similar metrics from                                 other machines or other metrics from the                                 same machine that showed similar                                 properties so the idea of being that                                 it's a seizure process you look for                                 something that's gone wrong and then you                                 find other things which are behaving the                                 same to try and determine what the cause                                 was it will put together a picture of                                 what was what's actually at fault now we                                 were working some kind of fairly strong                                 constraints we had about a quarter of a                                 million metrics coming in in parallel                                 each of those were sampled with                                 ten-second or                                                      depending on where it came from and we                                 had to build something that was fast                                 enough and responsive enough to be used                                 in kind of an incident management                                 timeframe so doing things has a kind of                                 batch operation in Hadoop or something                                 like that where you might be waiting you                                 know getting an hourly job or a nightly                                 job or something was kind of out of the                                 window we really wanted something that                                 people could use you know if they got                                 paged at                                                               out what was going on                                 and so it had to have a nice user                                 interface as well and not require lots                                 of fiddly tools                                 also fit into our workflow well so that                                 sounds easy right as it turned out it                                 was a lot harder than we thought that's                                 sarcasm by the way that's not actual                                 advice so it's it's not an easy problem                                 and it turned out to be a lot more                                 difficult than then we first thought it                                 would be but it's also not going away we                                 now have about four times as many                                 metrics about a million metrics coming                                 in in parallel all the time and it's not                                 just us that has this issue so Twitter                                 Netflix and Yahoo have all recently                                 released tools for anomaly detection                                 that face different kinds of challenges                                 with different solutions and all address                                 slightly different use cases as well I                                 think all of them are not quite there                                 which is obviously why I why we're                                 working on this at the moment so let's                                 talk a little bit about the what worked                                 well in kale first of all so time series                                 similarity search which is often                                 considered quite a hard problem                                 especially across that many different                                 time series actually we got that working                                 fairly well we we did it with the                                 two-stage process the idea was you would                                 retrieve a fuzzy kind of approximate set                                 of results using a fingerprinting method                                 or signature based method first and then                                 from those candidate resolves use a more                                 exact search method that would give you                                 very precise rack similarity rankings                                 but was a lot more costly so the first                                 stage method that were used for                                 retrieving roughly similar time series                                 by fingerprint was called a shape                                 description alphabet which is an idea                                 that's been around for decades but it's                                 kind of hasn't really seen a lot of use                                 and recently has been revived a little                                 bit it's quite a simple idea the idea is                                 you map line segments in the data so the                                 gradient between successive pairs of                                 points two tokens                                 typically five and it's it's quite sort                                 of quite simple you'd go from depending                                 whether it's a steep upward slope or                                 shallow upward stoat slope a roughly                                 level slope a shallow downward slope or                                 sleep steep downward slope you map it to                                 a different token affected just a                                 different letter and then you can index                                 those with in our case elasticsearch or                                 really any any search engine any loosing                                 based tool or any other similar search                                 tool will do that once you've done that                                 you can use sloppy phrase queries from a                                 time series of interest represented by a                                 set of tokens to through your database                                 of indexed time series and by adjusting                                 the slope factor you can be more or less                                 precise about how many you get back then                                 after that you use you have to use a                                 slightly more costly but accurate                                 ranking method to rank them all by                                 similarity to the search sequence so in                                 our case we use one called fast dynamic                                 time warping I'm not gonna go into the                                 details but you can google it it's                                 basically a kind of dynamic programming                                 based method for aligning to two time                                 series and it's kind of robust to things                                 like than being out of phase and having                                 insertions and deletions and that kind                                 of thing so that worked pretty well we                                 also developed quite a good user                                 experience for kale so it was designed                                 for kind of busy ops people in a hurry                                 to be able to see things quite quickly                                 both parts skyline for normal detection                                 and oculus for similarity search both                                 had nice web interfaces with                                 visualization you know you could see                                 recent behavior you could see past                                 history you could see what metrics were                                 currently kind of in an anomalous state                                 you could click through to visualize                                 them and so on so that also worked                                 pretty well but we didn't really address                                 some of the more fundamental points that                                 well which is why it's no longer in use                                 at Etsy and it hasn't really seen a lot                                 of adoption out there in the open source                                 community either                                 one of the things that proved to be a                                 bit of a blocker to adoption was it had                                 quite a complicated architecture so the                                 parts on the left here are more or less                                 the normally detection parts and the                                 parts on the right here are the                                 similarity search parts but you can see                                 you know to get the whole stack working                                 you needed to install two data stores                                 ready and elasticsearch you needed to                                 have two application servers one was                                 flask which is Python based on the                                 Sinatra which was ruby based you needed                                 to use rescue which is a queuing system                                 there are a total of four languages in                                 use in it because there was a                                 elasticsearch plugin to do the dynamic                                 time warping there was JavaScript used                                 in both of the web interfaces the there                                 was a lot of kind of pipeline plumbing                                 code that isn't really shown on this                                 diagram to kind of wire the bits                                 together now I don't really know of any                                 open source project that has that many                                 different components in and has been a                                 success I mean you might say Hadoop but                                 in Hadoop they are all designed from                                 scratch to work together right they're                                 all part of a coherent ecosystem more or                                 less in this case these were all                                 components that we took from elsewhere                                 and wired them together now even with                                 the aid of things like chef and puppet                                 recipes it was quite hard to actually                                 install this and get this working                                 because most of these needed to be                                 installed on separate machines because                                 they're quite heavy right processes so                                 that was kind of a bit of a blocker to                                 adoption and then also once you've                                 released something like this into the                                 wild you kind of put yourself in the                                 position of having to support something                                 with all of these components which is                                 really difficult as if somebody is                                 installing it and they don't already                                 have knowledge of things like Python or                                 Ruby or elastic search or Redis they're                                 not going to know where the problems are                                 part a isn't talking to Part B that kind                                 of thing so it's if you do something                                 like this you're going to let yourself                                 in for a lot of problems down the line                                 potentially now all of these things were                                 kind of chosen with the right intentions                                 in mind and with the right each                                 individual choice kind of made sense on                                 its own but it was as a coherent whole                                 and we didn't really think through the                                 consequences of that                                 and also we've never really got the                                 anomaly detection part working that well                                 and I'm gonna dwell on this a little bit                                 because coming from a data science point                                 of view this is something that this is                                 where I think I can make the biggest                                 difference and where I've been thinking                                 a lot about how to do a better job of it                                 so the the methods that were used by                                 skyline were kind of mostly inspired by                                 kind of statistical process control that                                 kind of thing where you're your                                        tend to be looking like the output of                                 manufacturing pipelines production lines                                 that kind of thing actually your                                 tolerances are fairly small your                                 expected variation is fairly small and                                 your distributions generally tend to be                                 like Gaussian distributions data from                                 machines and data from websites in                                 general just isn't like that you get                                 lots of non-normal distributions you get                                 power laws you get things which are                                 mixtures of multiple distributions you                                 get like roughness spikes periodic                                 cyclic behavior you get the problem                                 where if you've got half quarter of a                                 million metrics or these days a million                                 metrics then even if you're say look                                 your thresholds for significance is one                                 in a million you know your p-value like                                 ten to the minus six you're going to                                 expect to see false alarms basically all                                 the time just because of the number of                                 comparisons you're doing right so so                                 you've got to think of other ways part                                 from like you can't just keep on turning                                 the p-value down because eventually run                                 into rounding errors and things like                                 that so there was some mitigations that                                 ko                                                                      voting ensembles and auto silencing of                                 repeated alerts which helped a little                                 bit but they they were limited in what                                 they could do because of the kinds of                                 methods that were used to actually                                 detect the nominees in the first place                                 if basically what you're doing is                                 looking at point outliers so individual                                 readings which are more than some Delta                                 away from what you expect even if you're                                 kind of measuring that or threshold in a                                 load of different ways then if you get a                                 false alarm it's going to tend to be a                                 false alarm for a lot of the things in                                 the ensemble at the same time but also                                 there's a bit of a broader problem I                                 think which is which is missed by a lot                                 of presentations and tools                                 on this topic which is that not every                                 anomaly is a point outlier so just for                                 clarity what I mean by point outlier is                                 something like either of these two                                 really big spikes which kind of                                 immediately looks quite a lot higher                                 than the others in there right but so                                 that's that's a fairly obvious kind of                                 spike or it could be a dip going down                                 below where you would expect to see it                                 but not every not the four start there                                 are lots of other ways that machines can                                 misbehave or that users can misbehave                                 even I'll talk about some of the signals                                 for those in a sec but it's important                                 for us as well that not every point                                 outlier still looks like one if you step                                 back and look at more data I mean maybe                                 if we step back and look at ten                                 sequences of this length we would see                                 these happening fairly regularly you                                 know if I only looked at this bit here                                 zoomed in then that would look like a                                 point outlier whereas in the context of                                 everything else                                 it actually looks fairly standard so you                                 have to be able to take into account                                 enough data to get a realistic picture                                 of that oh by the way all of the brass                                 I'm gonna show from various different                                 kinds of web errors that I scraped out                                 of our graphite server it doesn't                                 actually matter what kind they are                                 really I'm just trying to demonstrate                                 the kind of behaviour that you see in                                 these graphs so what else can you see                                 apart from point outliers so a lot of a                                 lot of metrics show kind of periodic                                 cyclic oscillations they could be kind                                 of reflecting the daily cycle of the use                                 of your site or you know weekly or even                                 annual cycles but on this much full                                 scale they can reflect things going on                                 at the level of machines you can get                                 things like garbage collection cycles                                 which so show spikes on a much shorter                                 time scale now if if something suddenly                                 starts to oscillate that wasn't                                 oscillating before or a previously                                 reliable predictable oscillation goes                                 away then that can be a sign that that                                 something odd is happening right and you                                 get distributions that change completely                                 between the same bounds that they're                                 usually in and a something that detects                                 point out lies is kind of useless there                                 because no individual value will be high                                 enough or low enough to actually trigger                                 an alarm because you can still be within                                 range but suddenly see a lot of much                                 higher values near the original peak you                                 get trends that can change as well so                                 something that might be on a healthy                                 upward slope and you know total                                 registrations or something like that                                 could suddenly flatten out that might be                                 a sign that something's gone wrong with                                 your signup process you get things where                                 the baseline of a trend can jump around                                 like in this graph you can get things                                 that should be flat but suddenly start                                 going up or going down that kind of                                 thing and you get I have to admit I've                                 reused a graph here but you get a rare                                 discrete events where you might see them                                 only occasionally with a certain                                 predictable level of regularity suddenly                                 becoming much more regular or regular                                 ones suddenly becoming much less regular                                 and the best bit of all of this is quite                                 often it's not even a problem I mean                                 even setting aside the issue of false                                 positive so you can get something that's                                 a statistical anomaly the genuine                                 anomaly but actually in the grand scheme                                 of things hasn't affected users of your                                 site very much at all if you've got a                                 web farm of hundreds of web servers or a                                 database farm of hundreds of database                                 servers and individual metric                                 misbehaving on one of those machines                                 won't necessarily actually affect                                 people's user experience so what we're                                 doing differently this time so part of                                 the problem with Catwoman's it was kind                                 of difficult to experiment with with                                 different kinds of tests they were all                                 sort of baked into this big                                 infrastructure that you had to install                                 all of in order to really use and also                                 in the similar way to how people who                                 first get into machine learning they                                 think yeah I'll get all of the data I've                                 got loads of data then I'll throw it at                                 an algorithm and the algorithm will sort                                 it out I've got so much data that will                                 just work right and then when you've                                 been doing it for a while you realize                                 that actually most of the work is about                                 pre-processing the data                                 extracting the right features that kind                                 of thing and then that gives the                                 algorithm much better chance of                                 succeeding my hunch is the anomaly                                 detection is actually much like that                                 really being able to pre-process and                                 filter the data in the right way                                 is going to give you a much better                                 chance of getting you know reducing                                 false positives without also missing                                 things so I'm putting together a library                                 of algorithms called time which is kind                                 of the first phase of Kol - it's gonna                                 be platform agnostic so the idea is you                                 know you don't have to install any                                 number of different open-source                                 components that we've said this is all                                 one big stack you might want to run it                                 as a standalone service you might want                                 to embed it in another in a system                                 you've already got you may just want to                                 experiment with it see what works on                                 your data before you commit to using                                 some some platform it's aims to be as as                                 memory efficient and as cache friendly                                 as you can get away with in Java so not                                 doing unnecessary memory allocations                                 trying to allocate buffers upfront and                                 reuse them that kind of thing instead of                                 letting the garbage collector have lots                                 of work to do and it's built on the                                 framework called reactive X which I'm                                 going to talk a bit more about in a                                 minute because it's it's actually really                                 helped with kind of clarifying how how                                 this kind of project should work I think                                 which come from the the dotnet world but                                 has been ported to loads of languages                                 including there's rx Java which is the                                 work was done by Netflix they call it a                                 Netflix original which I guess in the                                 same way as house of cards means it's a                                 remake remake of something else so the                                 components that I'm looking to put into                                 the first release are fall into kind of                                 four main categories really this there's                                 components for signal processing and                                 feature extraction I've been inspired                                 quite a lot by like the DSP world the                                 digital audio world here so things like                                 wavelet decomposition and fast Fourier                                 transforms that you kind of extract or                                 filter out behavior at certain frequency                                 levels that lets you get a handle on                                 those kind of cyclic oscillatory                                 behaviors I was talking about earlier on                                 but also some simpler stuff for things                                 like centering and rescaling and                                 smoothing and trends really all that                                 kind of thing I'm looking including                                 probably just those three statistical                                 tests to start with generalized DSD is a                                 point out                                 test which is also used in in Twitter's                                 anomaly detection our library and the                                 kolmogorov-smirnov test which is for                                 looking at differences in distributions                                 and the mann-whitney u test which is                                 kind of looking at differences in the                                 midpoint of distributions so there they                                 were they tend to work better or worse                                 on data depending on whether the                                 differences are in the tails or in the                                 center the fingerprinting in search                                 components are going to be basically the                                 same as in Cal version                                              description alphabet component for                                 mapping time series into tokens binary                                 clipping which is an even simpler way of                                 doing this which just you sent to the                                 data around zero and and you you map it                                 to one if it's above the line or a zero                                 if it's below the line which actually on                                 certain kinds of data is a very very                                 efficient way to filter out things that                                 can't possibly be matches and then                                 dynamic time warping to do the exact                                 similarity search and I'm also putting                                 together into the interactive demo app                                 which shows how some of these things can                                 fit together and I'll show you that in a                                 moment                                 so a quick word on the design choices                                 and why Java I speak to a lot of ops                                 people about things like this and in the                                 devops world these days things like go                                 they're very popular but I think you're                                 a lot of good reasons cystic would you                                 are for something like this for start it                                 gives us interoperability with platforms                                 that we're using already like                                 elasticsearch log stash and cabana and                                 Kafka and platforms that we've been                                 looking at for doing stream processing                                 including Samsa and spark streaming it                                 also means we can embed it into our                                 Hadoop workflows if we want to work on                                 much bigger datasets more slowly so we                                 do most of our Big Data work on Hadoop                                 with scalding and conjecture so scalding                                 is a scholar library for putting                                 together data processing pipelines and                                 conjecture is a machine learning library                                 in Scala the there is another Etsy open                                 source project I think some of the some                                 of the components of time would actually                                 fit quite well into conjecture for doing                                 very very large parallel time series                                 mining also Android I put that in as a                                 bit of a joke that also demonstrates a                                 something which is important to realize                                 about this which is none of the things                                 in here are really specific to server me                                 Drix we have a team called the office                                 hackers that build kind of like I guess                                 workflow work space productivity gadgets                                 that kind of thing I was talking to them                                 about how you could use things like this                                 for built for doing environmental                                 sensing and detecting I don't know                                 unusual behavior in an office                                 after-hours that might indicate that                                 someone's there who shouldn't be there                                 that kind of thing so yeah nothing in                                 this really I think would be heavyweight                                 enough that you couldn't run it on                                 Android I think that actually kind of                                 fits in quite nicely with Levinas talk                                 yesterday morning you know so she was                                 collecting sensor metrics from a phone                                 and then pushing it to Cassandra to do                                 data mining on but there's also no                                 reason why you couldn't do data mining                                 on a single stream of metrics on the                                 phone these days and it means if user                                 another time series database like say                                 you've got open TS DB which is based on                                 HBase or data stacks which is based on                                 Cassandra because they're both Java it                                 should be fairly easy to to plug the                                 stuff into them and there's a lot more                                 maths and stats resources available in                                 Java than there are and something I go                                 you might ask why nots Karla because we                                 use Scala quite a lot internally but                                 it's Javas much more widespread so if                                 we're looking at producing something                                 that people can contribute to it's less                                 of a barrier to entry and it's also                                 easier to write kind of low-level                                 fast number crunching code in Java so                                 also reactive X so this thing was kind                                 of new to me I discovered it by accident                                 and it seemed to be a perfect fit for                                 this kind of project it's an instance of                                 the functional reactive programming                                 pattern which is kind of an extension of                                 the type safe observer pattern where you                                 have components that emit messages that                                 encapsulate data and other components                                 that process them and it does all the                                 the plumbing and takes out the                                 boilerplate of wiring them together                                 gives you tools to kind of manage those                                 pipelines and apply sort of functional                                 programming paradigms to them so you get                                 operations like map and flatmap and                                 reduce and collect and zip and split and                                 merge and can count and all of those                                 things                                 so it's it's very very well suited to                                 writing these data flow based programs                                 it's a little bit like writing something                                 like a spark work flow or you know a                                 scalding work flow but just within one                                 JVM on a single thread so basically all                                 you need to do is you define all of the                                 things I was talking about earlier on as                                 operators and they all they all obey                                 well most of them about one of these two                                 interfaces so they're either function                                 that returns that takes a block of data                                 just an array of doubles and returns an                                 array of doubles so that's how you'd                                 implement one of the pre-processing                                 operators or you get ones that take an                                 array of doubles and return some result                                 of type T so that's how you'd implement                                 kind of the statistical tests and things                                 then all you need to just wrap your data                                 source as an observable of type double                                 that just admits these arrays of data                                 when it's buffered up enough to work on                                 and you can just then compose these                                 things together to make a pipeline one                                 nice thing about it is it provides nice                                 kind of idiomatic sort of friendly                                 looking DSL for Java right with lambdas                                 also for Scala closure groovy and Kotlin                                 all from the same Rx Java package                                 basically so if you wanted to write a                                 third-party extension or a plug-in for                                 time and you're using one of those                                 languages you could actually write it in                                 a much more familiar thing that was more                                 familiar to your frame of reference that                                 used syntax that was basically exactly                                 the same as your own kind of connections                                 library and then just package it as a                                 jar and drop it in as long as it follows                                 the same interfaces so this is kind of a                                 schematic of what a pipeline in time                                 might look like so you have raw data                                 coming from somewhere could be a                                 database could be a stream and that kind                                 of thing and you'd then split it into                                 blocks you don't set data points one by                                 one through time it's kind of really                                 like a micro batch system rather than a                                 true streaming system then you might do                                 something like apply a wavelet filter                                 which would let you split it into the                                 high frequency components of the signal                                 you know like the rough noise and then                                 the low frequency components so like the                                 underlying trends                                 and long period cycles then you might                                 apply the same a couple of                                 pre-processing steps to both of those                                 streams in parallel they're sorting the                                 blocks and then building overlapping                                 windows out of them so you can compare                                 recent to historical data and then you                                 might want to send the the output of                                 those two parallel pathways into two                                 different statistical tests so something                                 like the coal ma graph Smirnov test for                                 difference and distributions if you                                 don't take out the underlying trend that                                 will go off all the time because you                                 know you're not you're not centered                                 around zero the readings for now might                                 be higher or lower than the readings                                 from earlier on just by dint of that                                 that trend changing whereas the so you                                 might want to just send the                                 high-frequency data through that to look                                 for a differences in kind of local                                 roughness or or noisiness behavior and                                 send the low frequency data for                                 something that looks for sudden changes                                 so I'm going to give like a quick demo                                 of that using the demo which is a work                                 in progress so what this does did to do                                 right so this actually in lieu of having                                 a server to listen to reads data from                                 the microphone over my laptop it sends                                 it through a wavelet filter and then                                 sends the output of that to a comb over                                 of smirnoff test so if I'm sorry                                 oh yes sure sorry the the code isn't the                                 important bit but I can try I don't know                                 how you actually do that actually let me                                 start it running first because it takes                                 a little while to what it's actually                                 doing is it's it's listening to my                                 microphone and taking a volume reading                                 every few milliseconds I don't know if                                 the acoustics here will mess with it at                                 all but yeah don't don't worry too much                                 about looking at the code because it's                                 not a finished product but what this is                                 doing is taking a rms volume reading                                 every few milliseconds and graphing                                 those so this isn't the raw Soundwave                                 data this is the average volume level of                                 what it's picking up from me speaking                                 but then because I've removed the low                                 frequency components with a wavelet                                 filter it's centered around zero so if                                 it gets kind of like generally louder or                                 quieter if I talk a little bit quieter                                 it will still be centered around zero                                 because it's taking out the kind of                                 baseline so it's building up I think ten                                 of these blocks and then after a while                                 it will start showing a p-value readout                                 at the bottom of the screen which is                                 basically how likely the current data is                                 it in the context of any of the previous                                 blocks so if that gets too low right so                                 now it started showing those at the                                 bottom of the screen I wish I could make                                 I don't know how actually made that a                                 bit bigger but we've got one that's                                 point one a point zero four etc etc you                                 know I've set the the p value threshold                                 quite low because I don't want lots of                                 false positives before I suddenly go                                 quiet now you'll see it's it's produced                                 a whoop-whoop at the bottom of the                                 screen there if you can't see from the                                 back you have to trust me it's got zero                                 point zero because the p-value so low                                 and its alerted on that but similarly if                                 I if I do something which is just                                 completely unexpected and doesn't                                 actually match but isn't kind of a                                 complete silence like if I suddenly                                 start doing this then okay it's had a                                 very low p-value but I think it's                                 because of the echoes in here it's                                 actually it's it's never really kind of                                 picking up the silence between the                                 sounds it's the echoes kind of filtering                                 out a little bit                                 so it's an example of how you would need                                 to tune your thresholds and to tune your                                 filtering parameters to suit the data                                 set and the behavior you expect to see                                 in it a little bit so yeah that's a                                 that's just a quick demo it's a bit of a                                 work in progress but I hope that gives                                 you a flavor of how it can work so just                                 quick summary what if we learned well                                 keep your architecture simple especially                                 if you want to release it as an open                                 source project if something's good fit                                 for your problem it doesn't necessarily                                 mean add it to your stack straight away                                 because you've got to think about                                 support operability that kind of thing                                 we have a bit of a meme at Etsy which is                                 prefer boring software as possible                                 interesting problems solved with boring                                 software is better than having to solve                                 boring problems because your software's                                 too new and interesting and don't open                                 source a platform or app unless you've                                 been running it in production for I'll                                 have no plans to stop because otherwise                                 you're left with like an orphaned                                 package that you can't really support so                                 we've also learned Amelie detection is                                 more than just out the Ida Texan okay a                                 one-size-fits-all pipeline probably                                 won't really fit anything that well and                                 also you probably shouldn't actually                                 alert on all the normal ease but think                                 about maybe alerting on business                                 critical anomalies you know things like                                 sign-up rate conversion rate bounce rate                                 the kind of things that you might test                                 in an a/b test right look for anomalies                                 in all of your metrics registered them                                 all but then use those for root cause                                 analysis and diagnostics when you've                                 actually found an anomaly which is                                 affecting user experience for your users                                 and we've also the good UI and workflow                                 will be a really good boost to                                 production and adoption I think kale one                                 was a victim of its own success in that                                 regard because it did look very polished                                 so lots of people when hey this is great                                 it's a fully featured package and                                 actually it turned out under the covers                                 to not be as current as the interface                                 made it seem ensemble methods auto                                 calibration and so on seemed to work                                 quite well for reducing reducing noise                                 from things like this so I'm going to be                                 exploring a bit how we can make those a                                 little bit smarter and it turns out you                                 can get away with doing time series                                 similarity search but you have to                                 constrain the search space a bit at                                 first by fingerprinting in order to make                                 the problem                                 patiently tractable so that's it thank                                 you
YouTube URL: https://www.youtube.com/watch?v=sn-btkORIxg


