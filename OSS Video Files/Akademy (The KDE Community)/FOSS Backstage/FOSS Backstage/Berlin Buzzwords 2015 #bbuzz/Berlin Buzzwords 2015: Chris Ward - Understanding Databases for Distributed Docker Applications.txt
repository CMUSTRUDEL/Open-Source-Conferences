Title: Berlin Buzzwords 2015: Chris Ward - Understanding Databases for Distributed Docker Applications
Publication date: 2015-06-05
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	In this talk we'll focus on the use of Crate alongside Weave in Docker containers, the technical challenges, best practices learned, and getting a simple web application running alongside it. You'll learn about the reasons why Crate.IO is building "yet another NoSQL database" and why it's unique and important when running containerized applications. 

We'll show why the shared-nothing architecture is so important when deploying large clusters and talk about the ways we've leveraged Lucene, Elasticsearch, and built an optimized distributed SQL planner. You will learn how to deploy a Crate cluster within minutes in the cloud using Docker, some of the challenges you'll encounter, and how to overcome them. Crate focuses on super simple integrations with any cloud provider, striving to be as turnkey as possible with minimal up-front configuration required to establish a cluster. Once established, we'll show how to scale the cluster horizontally by simply adding more nodes. 

The session will also give you examples when you should use Crate compared to other similar technologies such as MongoDB, Hadoop, Cassandra or FoundationDB. We'll talk about Crate's strengths and what types of applications are well-suited for this type of data store, as well what is not. Finally we'll outline how to architect an application that is easy to scale using Crate, Docker, Weave, and a simple web application.

Read more:
https://2015.berlinbuzzwords.de/session/understanding-databases-distributed-docker-applications

About Chris Ward:
https://2015.berlinbuzzwords.de/users/chris-ward

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              hello so I'm not yo doc as moved                               I do apologize but so we're going to                               look at an open source a piece of                               software that we've created at Crate and                               it's a distributed database and we're                               going to look at how to handle                               distributed databases with docker that                               said other containers are available                               other distributed databases available                                but there the specific ones we're going                                to focus on and how we got to what we                                created and why and then how we have the                                recommended way we've solved that well                                solved is a big word but helped with the                                distributed database solutions within a                                docker or container context so a little                                bit about me I'm originally from London                                I lived in Australia for a while and now                                in Germany I'm actually a developer                                advocate for crate somewhere between                                technical and non-technical so I'm going                                to mainly talk about how to use what had                                to use the database how to integrate                                with it and how it functions and                                actually have one of our core team here                                who will help answer any of the more                                technical questions you might have about                                how crate is actually made because that                                may interest you it's not questions I                                can answer and I've always loved open                                source I've worked in open source                                software for about                                                     more traditional field and i also have                                been working on other applications of                                open source like a board game and works                                of fiction so a bit of a generalist I                                guess so let's start with the sort of                                big statements and why we took ourselves                                down the path of building a distributed                                database another distributed database                                the founders of crate come from a long                                background of scaling large applications                                and basically for applications of any                                type of size and scale now having one                                database is not enough anymore I think                                we all know that here we can't scale it                                quick enough it's not resilient enough                                not dynamic enough to cope with the                                sorts of applications we're now creating                                and of course the solution to this is                                distributing them multiple instances of                                a database and then multiple ways of                                keeping those multiple instances                                synchronized and we'll look at some of                                those in a minute along the same lines                                in respect to this presentation                                traditionally and I use the word                                traditionally loosely because tradition                                in computer programming is not very long                                ago really data centers would be the way                                we would scale applications we needed                                more capacity we build another data                                center that's not an easy thing to do it                                requires a lot of money a lot of time a                                lot of very specialized skills so we                                then got to the step of virtualization                                and cloud computing which is a bit of a                                buzz word if you forgive the pun but we                                understand what that means computers and                                instances of computers that we can                                access very easily and very quickly when                                we need them and add capacity when we                                need them then more recently we've had                                things like containers again not a new                                concept but the concept has been                                understood and more widely used in the                                past                                                                 ending up with something like compute                                service is something like lambda AWS                                lambda where we've even reduced the                                overhead of services we require for                                application even more to small discreet                                little services that do one particular                                thing for a very quick amount of time                                come and go as quickly as we need them                                and this slide is thanks to this concept                                of where we're going is thanks to aging                                Cockroft whose ex Netflix and it's a                                company that understands complex scaling                                I I guess streaming video is pretty hard                                and traditionally when we've needed to                                change our requirements in an                                application or increase it in size we've                                sort of followed this path this is a                                path that many developers have followed                                in the past and                                would guess that many are here we start                                with something traditional again there's                                that word again a relational database                                 something like my sequel we need more                                 capacity on that my sequel database we                                 add more instances which is great but                                 then we have to worry about master and                                 node setups sharding keeping the                                 information in synchronization and how                                 we're going to do that we realized then                                 we need some document storage so we add                                 a document storage solution and then we                                 need to keep those two pieces working                                 together and again scaling and                                 synchronizing then we need search to                                 search across those two databases and                                 again when we need to add capacity we                                 now have three pieces all interlocking                                 with each other and figuring out how to                                 scale and synchronize and then we might                                 add more and more and more and all of                                 this is of course possible to                                 synchronize and scale but it becomes                                 more and more complicated and we spend                                 less and less time on actually building                                 a grid application and it hasn't really                                 solved the problem that we were trying                                 to solve in the first place we're just                                 creating more problems for ourselves                                 which sometimes we like to do but and                                 with containers and with docker in this                                 specific example keeping data persistent                                 in containers here's a concept where we                                 have an instance of a computer service                                 or an instance of an application or an                                 instance of a database that we may add                                 to we may remove we may remove all of                                 them and double the capacity how when                                 these things are transient do we keep                                 data persistent how does a new instance                                 know what the data even was and where to                                 find it from a previous instance and                                 again there are solutions but they're                                 not simple they take time and depending                                 on the complexity of your application                                 they could take a lot of time this is                                 kind of where we are and why we decided                                 to try something new or a new                                 alternative anyway                                 and crate is an open source project and                                 I'll show you some of the components                                 stack in a minute there's mountains                                 everywhere because it started in Austria                                 actually we now sort of half German half                                 Austrian with a couple of other                                 ethnicities thrown in of course it                                 started out originally as working on                                 elastic search plugins about four years                                 ago when the founders realized actually                                 what we're working on could be more than                                 that and decided to break it out into a                                 separate open source project and still                                 contributing back to elasticsearch one                                 on the way and we'll have a look at some                                 of those contributions in a minute so                                 what is it and this slide is interesting                                 because my colleague and I were in a                                 previous talk where lots of the things                                 we do it was a contradictory opinion on                                 them so so but we've sort of taking some                                 of them a bit further you get a lot of                                 different features and functionalities                                 or combined into one package basically                                 so it's a no sequel style architecture                                 but you can actually use standard sequel                                 for your query language you don't have                                 to learn any new query languages if                                 you're migrating from something like my                                 sequel it's distributed sequel so the                                 various instances of the data can be                                 queried with one normal style sequel                                 query it doesn't matter too much where                                 the data is you'll get the same results                                 and we'll look at a demonstration of                                 that soon we have semi structured                                 records the structures and the schema                                 can change relatively easily and a whole                                 bunch of other features here and the I                                 guess one of the key the key features                                 that we have by default which can be                                 changed through configuration is that                                 all nodes are equal there is no master                                 slave concept by default at extreme                                 scale you may need to start changing                                 that but that medium scale you can                                 generally stick with this type of                                 infrastructure                                 I think the one thing that isn't noted                                 on there is as well that document                                 storage and normal database storage are                                 also included in the same package so you                                 don't have these multiple technologies                                 interlocking with each other they're all                                 in the same crate instances as it were                                 so what's underneath everything as I say                                 create itself is open source but it                                 builds upon other open source components                                 the ones in grey are the light grey or                                 elasticsearch so we're using elastic                                 search at the storage layer and and the                                 dark gray are other components the blue                                 are custom crate components that we have                                 created ourselves but they're all open                                 sourced so all of this is viewable and                                 contributed ball so the crate component                                 and the storage level is handling blob                                 storage lucene is handling index storage                                 and elastic search pretty much                                 everything else at the network layer                                 again custom crate components for blob                                 streaming elastic search for sharding                                 discovery and transport and nettie for                                 the internode communication at the                                 aggregation level so the distributed                                 level it's all custom crepe at the query                                 level we're using facebook presto to                                 pass the sequel elastic search for the                                 scatter gather and I guess one of the                                 most useful crate components is the bulk                                 import export for migration into and out                                 of which hopefully you won't need but                                 into hopefully you will need and at the                                 top again all custom with the dashboard                                 which will look at soon a python shell                                 and in various client libraries which                                 will also have a quick look at for                                 programming languages ok so that's a                                 quick overview let's now look into how                                 it fits in with lovely docker and I                                 think this is always something I have to                                 be clear of                                 we've decided to talk a reasonable                                 amount about how create works with Daka                                 but it works with many other containers                                 and also without containers as well it's                                 important to point out you don't need                                 docker but dr. is also very good for                                 demos because I don't need to have                                 anything special set up on a computer                                 you can just get it running immediately                                 so anyone who's used docker will                                 probably recognize this sequence of                                 commands it's basically saying get the                                 latest image then run it and the first                                 two are running the crate creating a new                                 crate container and letting docker                                 handle the port allocation the final one                                 is then letting us manually set the                                 ports to the two ports that we like to                                 use and I'm not going to just leave that                                 up there I'm actually going to do this                                 so we can see how it is always the                                 challenge of finding your mouse pointer                                 there it is ok I think I have done this                                 demo enough that I can remember this                                 without having to copy and paste it but                                 we'll see i've already done the first                                 step they want to rely on a conference                                 Wi-Fi to pull the image down already and                                 the dash D is so it runs in the                                 background basically                                 ok then we'll run it again we'll run it                                 a third time and i'll explain what has                                 what has happened here so we run the                                 command the dog command to list the                                 instances we now have and we have three                                 instances of craic running and as you                                 can see from here we've let these are                                 the two we relate docker allocate the                                 port and here is the one where we                                 statically said we want to use these                                 ones and because we're on the same host                                 and they will all discover each other                                 and we'll have a three instance cluster                                 just refresh that and there it is and                                 you can see the three up I think my                                 laser pointer actually works                                 unfortunately it's you can see the three                                 up in the sort of middle to top right                                 there's nothing in here at the moment                                 i'll give you our sort of hello world                                 demo will import some tweets and then                                 i'll give you a very quick overview of                                 this admin console i don't really need                                 to do too much ok so this is the admin                                 console i mean it's good for getting up                                 and running but to be honest with you                                 once you start creating a more complex                                 application it becomes less useful i                                 guess that apart from just in the                                 overview it gives us an overview of the                                 data we have this health indicator is an                                 indicator of how the instances of the                                 database of rebalancing when so this is                                 currently telling us that all three                                 nodes in the cluster have the same data                                 and then a later example will start                                 destroying some instances and you'll see                                 it rebalancing but this is so such a                                 small data set that it's not nothing's                                 really happening we have a console which                                 just lets us do some basic playing                                 around with queries                                 yep as you'd expect we can see the table                                 structure we have here also blob tables                                 if we had any and the usually the schema                                 is let's go anyway and the cluster all                                 reasonably straightforward not a                                 particularly thorough example so will                                 step up to something a little more                                 complex I think I will jump straight                                 into it and then i will talk through in                                 a bit more detail so this is not the one                                 I wanted to know it's this one and they                                 all look the same as I'm time that's the                                 one I wanted okay so this is a larger                                 cluster on AWS we currently have                                    nodes we have                                                           of an interesting data set we have the                                 main table we're interested in use this                                 steps to a foe step tracker application                                 so it has steps taken by users each day                                 we have                                                                 see why I can't seem to scroll down                                 anything as things down here which I                                 want to show you but I can't get to them                                 for some reason normally down on that                                 right hand side it also see partition                                 data and the schema but entirely sure                                 why it's not scrolling there okay let's                                 run some queries on this and then we'll                                 illustrate the distributed nature and                                 what that means really so i'm going to                                 log into the if you don't run a query                                 first sorry so in this instance we are                                 sorry                                 in this instance we're looking at the                                 number of steps for a user and adding                                 the sum of all the steps for a                                 particular user and we've got about                                    to                                                                  quick we normally get that kind of                                 number naught point naught                                            great that's great let's try something a                                 little bit more complicated this will                                 take the the steps from that user again                                 and then for a particular month and give                                 the total for each day it's a little bit                                 more complicated but still pretty quick                                 let's remember those numbers naught                                 point naught                                                           actually the quickest it's done it at so                                 far which is good I suppose okay great                                 let's go back to the overview and what                                 we're going to do is firstly i'm going                                 to recreate an instance of the cluster                                 and bring it up to                                                      to look complicated and there's a reason                                 i'm sort of making it look complicated                                 to illustrate a later point but will                                 login to the AWS instance and i want to                                 switch into here and at the moment there                                 is you know there's nothing running on                                 this one this this one is doing nothing                                 at the moment so we're going to create a                                 new instance okay this this comes back                                 to what I alluded to earlier in that the                                 service discovery going on between the                                 nodes generally will only work if                                 everything is on the same host and this                                 is a slight restriction with                                 with docker but it's also a slight                                 restriction with a lot of cloud hosting                                 and this is why we're starting with                                 problems because we're going to talk                                 through the solutions to these problems                                 but and this is one solution but it's a                                 fairly long-winded one so we have to get                                 the publishable IP address from AWS we                                 have to get all the hosts in the cluster                                 then we can run this command which I                                 will clear even though it's on a slide                                 I'll just talk it through here so this                                 is again running it with the static port                                 it's there all on separate hosts                                 separate instances so we don't have to                                 worry about pork conflicts we're mapping                                 it to an existing data directory that                                 exists on disk already this is keeping                                 that persistence the data is already                                 there nothing's happening with it but                                 it's already there available for us to                                 reuse we're setting a heap size because                                 we got to a large data set and here                                 we've got some configuration options                                 that were actually sending to create                                 itself and some of these are                                 recognizable from the underlying                                 elasticsearch and some others that are                                 create specific so that has has run                                 already okay so we go back to our                                 cluster we now have                                                      so slow in explaining things we didn't                                 see the rebalancing but when we destroy                                 it it'll be a lot quicker and we could                                 see it rebalancing but if we go and run                                 some of the same queries will see that I                                 took slightly longer that's interesting                                 but we've got the same dataset even                                 though we just introduced a new instance                                 okay great let's let's have some fun                                 let's actually destroy things I'll just                                 find the ID                                 and let's watch the screen in the                                 background as fun as terminals are watch                                 the thing in the background so killing                                 this instance we go and we see the                                 overview suddenly switch into warning                                 and we don't have fully replicate freely                                 replicated data at the moment it's                                 jumping up and if i can move quick                                 enough we can actually jump into the                                 table level and see specifically what                                 table is under replicated as well i                                 would hazard a guess pretty soon                                 definitely by the end of the talk                                 everything will be rebalanced but i hope                                 from that example you see the point of                                 the simplicity here we've got a                                 distributed set of nodes of a database                                 that we can bring up and down at will or                                 when something goes wrong and we don't                                 have to worry too much about that                                 synchronization and replication it's                                 happening automatically for us oh there                                 we go one hundred percent great ok so                                 that was that's very useful at the at as                                 an example but we wanted to talk about                                 how how to do this better with Daka so                                 I'm gonna take a slight diversion back a                                 step and then we'll get to a better                                 solution than doing this sort of this is                                 great it works setting these host names                                 manually but it's not as dynamic as it                                 could be let some jump back into ok                                 so very quickly coming back we have                                 client libraries for most programming                                 languages some created by our team some                                 created by community and others improved                                 by community as well and as we've                                 already mentioned is familiar sequel so                                 if you're thinking of switching from                                 something that pre-exists that sequel                                 style then development team doesn't have                                 to relearn anything completely i will                                 show you yeah i will do this very                                 quickly I'd like to get on to the more                                 darker specific things but as an example                                 i have three code examples here of                                 fairly simple applications but they're                                 using that same data set of how you                                 would start to use the the database in                                 your application so here's a very simple                                 python example it's it's supposed to                                 emulate the steps being increased so it                                 generates a random amount of steps and a                                 timestamp and writes it to the database                                 that's basically all that's doing but                                 it's a reasonably real-world example and                                 i guess you could see from the top here                                 that we have a specific client adapter                                 for python and it gives you some                                 functionality to connect to the database                                 but then it largely comes down to making                                 sequel style execution statements i will                                 run this because there's one other                                 factor about and about the nature of                                 crate and the way it works and this may                                 be a question you'd like to ask in a bit                                 more detail is we are what is called                                 eventually consistent to keep that speed                                 and performance data obviously it's not                                 magic data has to synchronize somehow                                 and it takes some time                                 so I'm going to run this Python example                                 to illustrate the fact that we create a                                 new record query for that record but                                 it's not actually there yet so again I'm                                 intentionally doing something wrong to                                 sort of illustrate a point but let me                                 just cordon                                 so this will just generate the random                                 timestamp generates the steps I've                                 written to the database and I've queried                                 the database for that line but it's it's                                 not available yet as we saw this is that                                 same database we saw on the AWS cluster                                 it took a few minutes to synchronize if                                 we came back later we'd be able to query                                 for it but let's do illustrate a point                                 that the data isn't available                                 immediately and the negatives and                                 positives of that type of infrastructure                                 will come back to at the end of the                                 presentation we also have a again a                                 fairly basic node example again there's                                 a library available the node libraries                                 are probably some of the some of the                                 more thorough implementations as well we                                 connect to the instance here we have                                 with a sort of more simple query we can                                 do this sort of structure of querying                                 what columns we want the query we want                                 the limit we want and we just log it to                                 console and if we want something a bit                                 more complicated we at the moment as all                                 of these open source so open to                                 improvement we have to run a standard                                 sort of sequel query and again I mean                                 this will be                                 yeah as you'd expect it outputs the                                 results of the queries to console that's                                 all it was doing but this is all to that                                 live database and one final example                                 which I am moderately happy with is an                                 Android example I'll get the emulator                                 running whilst I'm explaining the                                 emulator has got faster but maybe we'll                                 come back to it later but here I'm just                                 clearing the HTTP endpoint we have                                 available normally with an application                                 you probably wouldn't do that you'd have                                 your own back-end but this is just a                                 demo so and demos aren't the real world                                 but just to show you an example of how                                 if there isn't a client library there is                                 an HTTP endpoint available and you can                                 just issue again queries to it as we can                                 see here and this again is doing much                                 the same yeah I don't think I've got                                 time for that is it but it just pulls                                 that list of records and displays them                                 in a list and actually the android                                 emulator is very slow but the                                 application and the query comes back                                 very fast so to shame that that it lets                                 me down oh here we go again not too bad                                 you always have there we go so that's                                 the same data set again there's no fancy                                 visualization but there's pretty quick                                 and this is it emulated firing as well                                 so there's all that lack of performance                                 there so anyway that's some very quick                                 coding examples let's get back to                                 tadakha so very quickly I'm going to                                 look at compose this is a Dockers way of                                 and creating like a text description of                                 the the components in your application                                 infrastructure and I use this it's a                                 very basic example but just because of                                 course if you're going to be creating a                                 micro service type application of many                                 parts something like this helps you just                                 construct that                                 and here's how you would do some of                                 those custom commands with with crate                                 but here's where we want to really get                                 to machine and swarm so dr. machine is                                 its tool of creating virtual machines                                 very easily it's not that hard to create                                 virtual machines without documenting but                                 it makes it even simpler and you can                                 choose the various drivers you want to                                 use be at VirtualBox AWS digitalocean                                 and a whole bunch of other options and                                 this is all fairly standard I'm not                                 going to run this code I'm kind of                                 reaching a conclusion here which is to                                 illustrate the steps along the way so                                 when that comes in more useful is when                                 we want to create a swarm now dr. swarm                                 is a way of creating multiple documents                                 and in grouping them together and this                                 is kind of we want to go this is what we                                 were looking at we want to create a                                 fully distributed database that is                                 everything is aware of each other and                                 when we remove and add instances the                                 data is synchronized that is the point                                 and docker swarm feels like we could                                 take us take us there but if we're on                                 multiple hosts we have that same problem                                 there are ways around it we saw the                                 manual declaration earlier and you can                                 automate that threw a bash script or                                 something like that but it's still may                                 be more complicated than it really needs                                 to be so this is just going through some                                 of those steps we create a discovery                                 token of the the master in the swarm we                                 then create the master give it the token                                 and add it to the swarm we then start                                 creating the the nodes or the slaves                                 give them the same token and at that                                 point in time theoretically we could                                 then go docker info and we'd see a list                                 of all the nodes and masters in that                                 swamp but if we're on AWS or if we're on                                 any other cloud hosting                                 it's not going to work unless again we                                 do something like this that we saw                                 earlier which is fine but yeah so I                                 guess our recommended way at the moment                                 of making this truly distributed                                 database with with docker is we at the                                 moment are using something called weave                                 I'm not going to step through all the                                 points but I'll show you the end result                                 but here's the blog posts that are                                 basically followed to create this                                 example so we've is a software-defined                                 networking technology and integrates                                 with docker and is pretty easy to use                                 and it lets you create overlay networks                                 over all your other networks to                                 basically enabling multicast to work in                                 it claims eddie cloud that's a big claim                                 will say most clouds so let's have a                                 quick look at how that looks                                 so in this instance we've used compute                                 engine we have three we've three we've                                 instances three instances in this                                 demonstration down here all of death of                                 different IP addresses different                                 machines normally if we then ran a crate                                 and docker honor those they wouldn't be                                 able to find each other we've installed                                 we've on each one and got them                                 communicating through the same channels                                 and we end up with this and this this is                                 the end result again I've imported a few                                 tweets into it we have the three                                 instances which are the same three we                                 can see at the bottom of that list and                                 that's it it doesn't really look any                                 different but but there are three nodes                                 on three different machine machines or                                 communicating with each other and if you                                 follow that blog post here it's                                 reasonably straightforward to get it to                                 get it working and we truly have a                                 distributed database across networks and                                 across cloud networks as well it's a                                 slightly underwhelming sort of end point                                 but it looks exactly the same but that                                 is what we have there so just to to wrap                                 up and have some time for questions and                                 if you have any more questions we don't                                 have time to answer I will be here                                 tomorrow as well so what are the use                                 cases for this let's start with the                                 negatives systems that require strong                                 consistency we have that eventual                                 consistency so anything that you one                                 hundred percent need the record to be                                 available the very second it's been                                 written then no and there are use cases                                 where that would be the case say for                                 example financial banks something like                                 that equally the same applies with                                 transactions crate will keep going when                                 when queries fail which may mean that                                 other subsequent queries are not                                 accurate anymore and with a lot of                                 application structures that's fine but                                 there are many is that that isn't fine                                 and strong relational data and currently                                 we don't support proper joins but                                 they're coming very                                 soon and we're sort of ironing out the                                 kinks in the performance that that                                 effects but they're coming very soon so                                 that's on the negative but on the                                 positive things like high volume                                 semi-structured data that changes all                                 the time Internet of Things applications                                 big data applications we have a lot of                                 people using it for business                                 intelligence marketing intelligence so                                 data that it is coming all the time and                                 is changing all the time and the the                                 amount that it comes in that is changing                                 all the time and because of that sequel                                 type language it's very easy to to                                 migrate from my sequel or something like                                 that that's what you've been using so I                                 hope that was a reasonable summary of                                 the concept and how to get it working                                 here's some of our contact details also                                 have some lovely t-shirts and stickers                                 and all that kind of stuff if anyone                                 wants any and a good a few minutes for                                 questions
YouTube URL: https://www.youtube.com/watch?v=gILCPu6lGZo


