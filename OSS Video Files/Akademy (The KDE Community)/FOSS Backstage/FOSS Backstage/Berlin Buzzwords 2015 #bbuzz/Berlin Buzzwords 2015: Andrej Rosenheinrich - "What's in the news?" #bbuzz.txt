Title: Berlin Buzzwords 2015: Andrej Rosenheinrich - "What's in the news?" #bbuzz
Publication date: 2015-06-05
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	Andrej Rosenheinrich talking about '"What's in the news?' - or: why Angela Merkel is not significant"

Bluekiwi.de, Unister's meta search engine, offers an explicit search over news articles. But what about the user who wants to inform herself on what is actually new and important? Watching hundreds of news sources, we collect thousands of news every day - far too many to read or present concisely. So the question becomes how to aggregate, summarize and present the important news of the day.

In this talk, we want to present some strategies we used to aggregate news, figure out what is important and not just common, and what techniques can be used to come up with descriptive teasers. These teasers could be used in turn to trigger useful search queries, thus providing the user with the full news stories behind them. 

Our approach comprises proper entity detection and natural language processing, which we will compare to pure term based techniques. Even if this approach is certainly more laborious than 'out-of-the-box' information retrieval, it is well worth the effort, providing us with understandable and succinct summaries of what's really going on.

Read more:
https://2015.berlinbuzzwords.de/session/whats-news-or-why-angela-merkel-not-significant

About 
https://2015.berlinbuzzwords.de/users/andrej-rosenheinrich

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              I                               and hello and welcome to my talk what's                               in the news or langa lemarchal is not                               significant my name is Andrew was no                               English what I'm going to talk about                               today is some work I've done and some                               experiences have made together a                               colleague of mine dr. Van Dyke man was                               made a responsible for the natural                                language processing part of this project                                but more about that later we both work                                at the research and development center a                                department of the unit sir game behind                                light sick in case you haven't heard                                about you Nestor it's not uncommon user                                is one of the biggest Internet companies                                in Germany You certainly have heard of                                some of our brands with brands like                                happen envelope da or hi Cindy we are                                market leader in online travel sales in                                Germany we're one of the main contenders                                in areas like online flight ticket sales                                hotel reservations but apart from the                                travel area we also running a lot of                                pages in areas like finance like                                shopping like comparison so if that's                                interesting for you go check the website                                unity and usually there are some jobs                                around at locations all over Germany so                                at research and development department                                we do something slightly different our                                main focuses development of blue key bde                                blue key B is a meter search and ok why                                another meet research as a question I                                get answered from TY asked from time to                                time and whatever this laptop is doing                                here why not me to search well doing a                                search is not that difficult today is                                set up a simple full-text search or                                whatever is something you can do there                                are tools around for that it's probably                                ready out of the box if you have to data                                to search and it's always one thing you                                have to keep in mind and what is the                                difference between a search and a good                                search it's of course the relevant of                                your relevance of your results and                                everyone is doing                                some certain things to improve the                                relevance and two of the main ideas                                we're doing what are not so uncommon I                                guess is of course a semantic analysis                                of the key search query and for instance                                here in this case the query would be                                called as Mexico and we would think that                                you probably talked about the sea Gulf                                of Mexico and present you the certain                                results like the defect box in the upper                                right corner for that and so on if I                                would query for go if in Mexico even                                that in a stop word that would not be                                considered in the full text search the                                semantic analysis tells you okay this is                                something different maybe we're talking                                about Mexico and the sport goals in                                Mexico and so semantic analysis helps                                for sure another thing that we're doing                                is we're considering the context or the                                context is actually something that we do                                not know most of the time but context is                                something that would bring different                                result when i'm looking for mexico what                                am I looking for and we're looking for                                facts don't want to go there for                                vacation maybe I need a hotel and so on                                and so we implemented a lot of different                                searches in a different context and                                depending on what we think is the port                                context for the query you use we display                                certain boxes with with such a context                                and you as the user can decide what you                                actually want to see you want to see the                                hotel offers or the facts or the news or                                whatever and as I mentioned one of them                                one of the context modes we wanted to                                have a new search and probably a                                question I do not have to plot out that                                much but why do we want to have a new                                search news our topic of amazing                                interest if you look at Alexa ranking of                                the most visited pages in Germany in the                                top                                                                   new similar we can argue about one or                                two of them pages that i would consider                                as being nice or new similar think even                                for their domains like to online the e                                like gmx de that                                tane a lot of news so news seems to be                                of a huge interest and the other thing                                 about users there's a lot of it around a                                 lot of sources you can think of a lot of                                 news and let's face it a lot of                                 something you can easily you a loose                                 overview is the perfect scenario for                                 research right so it was a no-brainer we                                 wanted to do new search we wanted to                                 have it and we did what we had to do we                                 set up a process to fetch news from many                                 many sources constantly we do some                                 pre-processing on the news we store the                                 news in an index what is cool so we can                                 use all the fancy features of elastic                                 search and with that data we got we                                 implemented the search on it our                                 designers came up with screen front and                                 team put on the page and voila there we                                 go we have a new search with the news                                 box it looks good for us the results are                                 good uses like it we like it everyone's                                 happy but as usual you have a huge                                 amount of data laying around and for                                 sure you start thinking about what can                                 we do with that data it's interesting                                 and we have a lot of news actually it's                                 pretty obvious what you can do or what                                 you would like to do what you'd like to                                 do is aggregate news imagine they're                                 more than                                                           every newspaper is writing about how the                                 last soccer game actually went the                                 result is the same everywhere you don't                                 have to display it                                                     the fact this is the result                                       whatever and maybe you don't want to                                 read all the news because just too many                                 of them I want a short summary a punch                                 line you know this is the fact we won                                 the game and of course as part of the                                 the title we want to figure out what are                                 the important news if I have a five                                 digit number of news every day I cannot                                 read all of them I want to focus on                                 let's say the top                                            we actually know what we want aggregate                                 summarize find the most important news                                 that was the task at hand the only thing                                 we did not know is how to get there so                                 let's start with the last thing years                                 how can we figure out what are actually                                 important news I'm quite sure that I'm                                 not the only one who encountered the                                 task of figuring out what is the                                 important part in the data I have and                                 I'm quite sure that probably almost                                 everyone knows that counting is usually                                 not a solution whatever you count you                                 can count terms you can cut entities or                                 whatever you got um but still everyone                                 is trying that I tried it too it's not                                 working we need something different so                                 what is an idea to figure out what news                                 are important I had an idea in mind and                                 I guess you can already guess what it is                                 because it's in and in the title it's                                 elastic source significant term                                 aggregation that was introduced to think                                 the beginning of last year and in case                                 you haven't attended to talk about the                                 significant term a gregarious terday or                                 you never heard of it was elasticsearch                                 significant term aggregation about you                                 can read up a blog post there's a very                                 good blog post about it or you read the                                 definitive guide that's worth reading                                 anyway and the definitive guide actually                                 explains it the following way the                                 significant terms aggregation finds                                 uncomely common terms in your data set                                 what do we mean by uncommonly common                                 these are terms that are statistically                                 unusual a hell of a definition but what                                 does it mean actually we compared two                                 sets of documents one is the foreground                                 set that is the set of documents you                                 select by a query or however any other                                 background set simplest case is the                                 background set as your whole index you                                 could narrow that down by other filters                                 or whatever and then you compare how                                 often do terms appear in this set of                                 documents and if this frequency is                                 higher in the foreground set then it is                                 in the background set significantly                                 higher                                 then something is happening although                                 this term has a special significance                                 between your foreground said if you                                 imagine I have a term that is in my                                 background set and every                                               and my foreground set it's in every                                 third so this seems to be really really                                 important for my foreground set so this                                 is the idea that we wanted to use                                 choosing the foreground set is pretty                                 simple i could do a range query and say                                 like give me the news of the last                                    hours and then figure out okay what is                                 important during that time with this                                 definition in mind i can actually                                 explain a part of my title as well                                 because i claim that Angela Merkel is                                 not significant why is Angela Merkel not                                 significant well obviously because she's                                 in the news every day there's a poor guy                                 and a in a new as a newspaper that has                                 to fill the page every day or thinking                                 about what to write and just write down                                 and Gail I'm Atlas doing a safe bet so                                 her name will be at least                                             every newspaper every day think about                                 even more extreme example weather                                 forecasts if you take data from one                                 newspaper there will be one article with                                 weather forecast every day and no one                                 would be amazed that tomorrow will be                                 one article by the forecast so this is                                 not significant at all this is nothing                                 you have to look at so significant term                                 aggregations is the idea we want to use                                 but there is a problem with significant                                 terms aggregation and that is what are                                 the terms were you looking at we're                                 using the headlines for a good signal                                 charm aggregation and you could say okay                                 I use the terms that are delivered by                                 elasticsearch but the output of my                                 analyzer that will give you a single                                 token or maybe a bigram whatever you put                                 your index I said your index app or the                                 problem is this usually is not really                                 descriptive another problem is you would                                 not consider grammar you could come up                                 with marker but you also could come                                 with now kids and so on and the medical                                 example usually names will be split as I                                 said the name thing you could do with my                                 grams that will save you an angular                                 marker it wouldn't not save you and that                                 being a lotus ocean a burger but you                                 could go ahead and say okay I have a                                 bunch of pi grams maybe they're                                 overlapping my concatenate them and so                                 on I tried all this it's really funny                                 what results you will get but still the                                 output will in rare cases be well-formed                                 or make sense also ever so just working                                 on simple terms is not going to bring                                 you anywhere em I said we're doing                                 pre-processing one of the things we're                                 doing pre-processing as we do an entity                                 recognition we could use the attitudes                                 of the news for a significant term that                                 is cool somehow because what you will                                 get our clean valid results you don't                                 have to care about names you have proper                                 labels everything is cool still it's not                                 the script of you might know that Angela                                 Merkel was somehow important yesterday                                 by chance but you do not know why                                 another thing with entities you will not                                 find new news if your entity recognition                                 does not know the term you're talking                                 about a company / introducing a new                                 product you will not realize that this                                 is important and not being able to                                 detect something new and use this                                 mistake for sure and last thing and that                                 is a problem for both of it you cannot                                 aggregate on this news i said we want to                                 aggregate but if i know that i have the                                 term angela merkel or the entity angela                                 merkel and it is contained in angular                                 market means francois hollande as well                                 as angela merkel meets Vladimir Putin                                 but you cannot a great and debt because                                 it's the same years it's a different                                 news and you have to figure out                                 something different so at least here we                                 noticed that we have a conceptual                                 problem of the whole thing they have to                                 think about something different and the                                 solution here was pretty obvious we have                                 to move away from token token being a                                 term or an entity or just a single                                 entity whatever you want to call it to                                 effects we have to consider the headline                                 or the news                                 in whole and try to make effect out of                                 it and that's where i was looking                                 sitting in my office with the sad face                                 but stuck here my colleague came up to                                 me ask me what I'm actually trying to do                                 and how the whole thing is working and                                 is that maybe I can help you here on                                 that with some natural language                                 processing approach and he came up with                                 a four-step process that he implemented                                 as a prototype I'll skip the step zero I                                 explained him a detailed in a few                                 moments but just the idea is what are we                                 trying to achieve we want to find the                                 important terms that summarize the                                 sentence or the headline based on the                                 structure of the sentence so how's it                                 working impetus as i said the headline                                 we do some basic NLP staff with the                                 sentence plotting remove some special                                 characters that you don't want to                                 consider that just makes a few of the                                 rules that we will see in a few moments                                 easier we do tokenizing all that is                                 basic standard and in the end we do a                                 part-of-speech tagging everything can be                                 done with out-of-the-box tools for the                                 speech tagging Eustace then a Stanford                                 post a girl with the STS sugs tax ID                                 from from Stuttgart and the example I                                 guess everyone seen something like this                                 before there was a talk from trotting                                 aslam yesterday you have sentence like                                 Angela Merkel Swift amid wat na dena                                 Putin in Moscow a gala as a proper name                                 Merkel is the proper name through the                                 finite verb and so on ok nothing magic                                 in here next step is a chunking step or                                 we also call it phrase detection we have                                 a set of rules a regular grammar and we                                 apply those this grammar to the text                                 sentence and try to figure out actually                                 what tokens together are                                 could be combined to a to a phrase for                                 instance I could say that nominal phrase                                 for me is a sequence of proper names at                                 least one preposition prepositional                                 phrase and so on take the example here                                 you come up with a representation of the                                 phrases like in the bottom of the figure                                 of the page if you don't like this kind                                 of representation you're more into                                 drawings think of it as a syntax tree                                 representation of a sentence the                                 sentence consists of a nominal phrase a                                 verbal phrase a prepositional phrase and                                 so on this is also nothing to magic the                                 only thing you have to come up with what                                 are my phrases what is the set of                                 grammar that is something you have to                                 implement on your own third step we                                 actually use these trees probably a                                 partial trees to extract facts we have a                                 self implemented extraction language                                 with the goal to instil extract                                 important keywords by using a set of                                 rules for instance we have a rules we                                 say okay we have a nominal phrase                                 followed by a verbal phrase if we have                                 something like that okay that is a match                                 and from this match we want to keep                                 certain parts like we want to keep                                 nominal phrase we want to keep the                                 verbal phrase but from the verbal phrase                                 we actually keep the verb there the                                 finite verb add the nominal phrase at                                 the end of it so from our example Angela                                 Merkel truth I Met Ball Vladimir Putin                                 in Moscow what is left over as a fact by                                 this rule is Aguila markets with letting                                 me a poutine we apply all the rules we                                 have to the syndics tree potentially we                                 have a set of results we have to filter                                 out what is the best result for us you                                 can think of a lot of filters actually                                 apply several of them one possible                                 filter could be just the length of the                                 result you get markets roof market with                                 Putin is even better maybe you prefer                                 the longer form market with Putin in                                 Moscow maybe you don't because it's not                                 the idea of summarizing what                                 short summary and that is one filter you                                 could come up with another idea would be                                 coverage what is the web what is the                                 rule of the largest coverage of my                                 syntax tree and so on okay we got those                                 facts and out of those facts in a last                                 step we generate some reason actually we                                 do two things we generate normalized                                 terms out of it and also we want to                                 generate a syntactically well-formed                                 summary something we can present to the                                 user as human readable result as a                                 potential search query you can use on                                 our website to get to the actual news                                 for that summary the first thing the                                 normalized term it's pretty simple we                                 take the keywords be extracted in the                                 last step we normalize them we                                 concatenate them we put all this in a                                 Linux I actually fall asleep off                                 come on so in our case Angela Merkel to                                 Vladimir Putin the normalized                                 concatenated form that we actually store                                 in the index would be mac-                                               we also generate the well-formed summary                                 that is pretty simple we take syntax                                 tree and we remove actually all the                                 parts of the sentence or of the syntax                                 tree that we do not want to keep with                                 our rules and from the example the scent                                 extruder showed here what will be left                                 over is in the end a summary and Gail                                 immaculate with Vladimir Putin what is                                 human readable what is descriptive what                                 is a good result that we can present to                                 our user so what are we doing with that                                 I'm coming to the end we can use the                                 normalized summary year for the                                 significant term query just these are                                 some examples that would show you what                                 kind of normalized summary we would get                                 out career-ending strike at these                                 examples like two weeks ago so just in                                 case you recognize the news and if we                                 have something like this we can easily                                 look up                                 what is develop from summary display to                                 the user and so on so be think we                                 accomplished our mission so in the end                                 to summarize it we found a way by using                                 natural language processing to aggregate                                 news to summarize news and also using                                 elastic search we found out what are the                                 significant news we can display this to                                 the user is an actual example from our                                 website there of course some problems                                 still there it's an iterative process to                                 actually get all these rules correct                                 there are always examples that don't                                 work and move that actually undone and                                 there's only one thing left for me and                                 that is come on it's on my laptop by the                                 way and and that is to actually invite                                 you come and see you that blue de                                 does not feel reimplemented it its life                                 thank you for listening
YouTube URL: https://www.youtube.com/watch?v=wpDWZTyiTxg


