Title: Berlin Buzzwords 2015: Fabian Wilckens - An introduction to Apache Kylin Business Intelligence ...
Publication date: 2015-06-05
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	Fabian Wilckens talking about "An introduction to Apache Kylin - Business Intelligence meets Big Data".

Apache Kylin is an open source distributed analytics engine that originated at ebay, Inc. and provides a SQL-interface and multi-dimensional analysis for online analytical processing. Kylin was recently accepted by the Apache Software Foundation as an incubator project and already has a number of integrations with HDFS, MapReduce, Hive, HBase and Apache Drill.

This session will provide an overview about Apache Kylin, how it works, what it does and will give an introduction to Online Analytical Processing (OLAP), how Business Intelligence works and how Kylin + Hadoop can help in analyzing extremely large datasets.

Read more:
https://2015.berlinbuzzwords.de/session/introduction-apache-kylin-business-intelligence-meets-big-data

About Fabian Wilckens:
https://2015.berlinbuzzwords.de/users/fabian-wilckens

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              okay so what I wanted to                               out today is Apache chi-lin so a lot of                               people may have heard about                               number of apache projects coming up                               every week essentially so the whole                               community changes but one of the most                               interesting projects which I find is                               very very interesting at the moment is                               Apache khylin so and that comes with a                                challenge at the same time so when I                                propose the session today I thought well                                it might be doable in                                                  walk through all the slides and said                                well there's certain assumptions you can                                make because I believe everybody knows                                what Hadoop is right everybody knows                                what Big Data is but does everybody know                                what olav is does everybody know what oh                                Lt P is and this is a bit of the                                challenge that I want to cover today so                                I walk through a bit of OLAP so what is                                it why it's important what challenges                                occur when you're dealing with all up in                                a big data space and how kaylynn solve                                these challenges integrates what to do                                and then I gonna talk a little bit about                                the Rope Maps or where Carlene said it                                and of course if we have some time left                                which I hope I may be able to answer                                some questions afterwards and I'll be                                there for the next couple of days as                                well so very quickly all up all up                                stands for online analytical processing                                and to give you one example one could                                say it's about beer in fact it's about a                                question that may be how many beers were                                ordered in Germany on a yearly basis or                                to be even more specific how many beers                                were ordered in Germany on a yearly                                basis broken down by month but this is                                questions that everybody wants to answer                                right being in retail being in business                                analytics being in business intelligence                                this is the most important questions                                Germans drink beer how much beer do they                                drink when do they drink beer where do                                they drink beer etc etc just to give you                                an example and what you can do with all                                up is you can build something which is                                called an OLAP cube and all of cube may                                look like this this is just a graphical                                representation and I may actually be                                able to ask a question so which or which                                amounted liters or whatever it is right                                whilst ranked in Hamburg in May so                                that's the representation of an OLAP                                cube it consists of two basic things the                                first one is it consists of measures so                                measures of numeric values that                                so-called facts and it consists of                                something which is called a dimension as                                you can see that maybe products that                                maybe some things about orders there may                                be some more granular things that you                                can actually filter on so that's                                basically the filter criterias and you                                have the numeric the facts the                                measurements to actually have an                                aggregated sum or an aggregated number                                of something that could represent                                whatever it may be so if you look at                                that now from all a perspective once                                again you can do certain things which                                are called all up operations right you                                can do things like well I want to know                                how much beer was consumed in Berlin                                over a certain time frame and this is                                incredibly great for analysts because                                it's a model they can greatly work with                                right so you have a relational data                                structure in the background which                                typically works in a relational database                                and this is very good that's a great                                idea but now we came to a world where we                                talked about big data right so what is                                that relational model q building etc in                                the world of big data right so how can                                we do that so and some folks at eBay                                started the project called chi-lin and                                chi-lin is supposed to be the extreme                                all up engine for big data                                Kylene is far as I remember it's sort of                                a dragon thing something mythical like a                                strange creature that existed sometime                                                                                                     chosen as the project name however it                                got open-sourced late last year it's                                currently incubating at Apache and they                                are targeting an initial release fairly                                 soon so expect to see more out of                                 curling in the near future and the goals                                 are really to provide subsequent queries                                 on let's say really large volumes of                                 data like billions and trillions of rows                                 you want to be fully NC compliance and                                 say sequel compliant because all the                                 analysts all the people in data                                 warehouse all the business intelligence                                 people they all know NC sequel and they                                 also want fall all up statements they                                 also want to have full all-out                                 compliance                                 so they want to work with a database or                                 with a system that may look like a                                 database the way they have worked with                                 the database before and what they also                                 want is no one in the BI world wants to                                 work directly on Hadoop right they want                                 to use their fancy applications they                                 want to use the tableau as the platform                                 as the datum years this SAS whatever                                 systems exist on the planet and they                                 want them to smoothly integrate they may                                 change the engine so they don't                                 necessarily care if it's a database in                                 the backend                                 but they want their front-end tools they                                 wanted beautiful they wanted fancy                                 whatever you may call it and the other                                 thing is what they also want to target                                 is to have really a platform that scales                                 to thousands of users right you have the                                 thing of the scale of eBay right so                                 there's not something they played around                                 with but they use internally to produce                                 exactly these cubes on large-scale data                                 sets you can imagine eBay what that's a                                 bit of data what they have right in                                 terms of articles auctions categories                                 etc whatever they can do so what Carlene                                 also does it uses a lot of the                                 components that exist in Hadoop so it                                 basically takes hive to sort of pre join                                 pre articulate pre aggregate views and                                 for queue building it uses MapReduce to                                 generate these excerpts if you will it                                 uses HDFS and HBase to store the values                                 so imagine a cube being a key value pair                                 so there's a number of combinations                                 writing key values in the cube and these                                 things actually stored in HBase so they                                 query through an Z sequel interface and                                 they interfere with HBase directly so                                 when you look at that                                 more from an architectural standpoint                                 you have wife on the one hand side which                                 is essentially used from a cube building                                 engine so it takes star schema data the                                 data you've seen builds the key value                                 data stores that in HBase and then we                                 have a metadata central metadata                                 repository and there's the number of                                 chi-ling components that does for                                 instance occuring engine does the                                 routing there's a rest interface                                 provided there's the ability to plug in                                 through party apps or just you                                 using standard JDBC already received                                 pipe connections to interface with the                                 system however what it can also do it                                 can route the low latency queries                                 through HBase which are really low                                 latency so I need my result in seconds                                 on large-scale data right but it can                                 also theoretically interface with hive                                 to get some mid latency some well                                 minutes to hours ok curious results and                                 if you look at the data flown I think                                 this is one of the most important things                                 about the architecture of Kylene is                                 really to have we have an online data                                 flow which is everything that is in                                 green so these are the active components                                 and you get the blue data flow which is                                 basically the pre calculation that has                                 been done to make the data accessible                                 right through a front-end application                                 and the more important thing is that the                                 OLAP cube stays transparent for the user                                 so what they see is a database kind of                                 structure so it looks like a database                                 and this is the beauty of Hadoop it can                                 pretty much look like everything can                                 look like a database can look like a                                 file system in this case it pretty much                                 looks like what you would expect from a                                 relational database standpoint some                                 highlights about chi-lin because there's                                 so much things to talk about so just                                 some highlights it's extremely fast at                                 scale it was made for scale it was made                                 to scale out there's no let's say                                 there's no no thinking of having at                                 single-threaded so it all runs in                                 parallel there's multi parallel                                 operations and it just scales as you                                 grow it should also provide NC sequel                                 compliance because all these tools are                                 very good at creating NCC per complain                                 statements all these front-end tools are                                 not necessarily good at creating hive                                 statements because hive is just a subset                                 or hive QL is just a subset of the ANSI                                 sequel standard so that's really one of                                 the other design goals they had and                                 seamless integration I talked about that                                 some time now but they want it to work                                 with existing applications so they                                 really want to use it together with                                 whatever front-end application and they                                 want to provide as I said large scale                                 record scans large scale cube building                                 kind of applications so more highlights                                 so it's actually pretty powerful for an                                 incubating project right so this is                                 something that is not particularly                                 community driven it's something that                                 Yvette donated if you want to the                                 community and it's picking up great                                 crazily fast because it just runs on the                                 Hadoop infrastructure that you just have                                 there's no new no fancy component                                 involved which is not proven for years                                 so it uses what has been in production                                 right and this makes it very very                                 interesting to implement Kylian what it                                 also does is it provides a very very                                 great graphical interface that can do                                 certain things so the whole cube design                                 process can be done through a graphical                                 interface so there's no UI start where                                 there's no command line stuff that you                                 need to do so you can actually say well                                 here bi admin you know all the words you                                 know what bi looks like here go ahead                                 design your cubes the way you want it so                                 this is how it looks like you can scroll                                 to that you can work through the process                                 and it will come up with a graphical                                 representation so as you can see it's                                 it's easy to use right it provides some                                 granular security it provides the                                 ability to do job management in Hadoop                                 so ultimately you build the cubes and it                                 will result in a MapReduce job in the                                 end so this is all the way down to the                                 Hadoop integration and furthermore and I                                 think that's a really that's a really                                 cool feature looks a bit like hue so for                                 those of you who have played with you                                 Hadoop user experience it actually lets                                 you query the data in a browser but it                                 will also give you some sort of our                                 interactive feeling because it can                                 produce the results and fancy charts pie                                 charts bar charts whatever you want and                                 it's all open source so it makes it                                 really easy to start with so you don't                                 have to start with let's say building                                 everything from scratch in terms of a bi                                 application but you can say well I may                                 try something using that interface first                                 and then we may see if we can go further                                 or if we really want to put it to                                 production once it's really GA once it's                                 a full top-level Apache project but it                                 will get there eventually it's a little                                 bit on the roadmap and the history                                 was a fairly new project so they started                                 in September essentially two years ago                                 or one and a half years ago and what                                 they achieved so far is in January last                                 year they announced a prototype so take                                 that took them four months to develop a                                 prototype and it kind of escalated from                                 there really so they added more and more                                 and more features to it to provide what                                 I've showed you but this is where we are                                 now the red line should basically show                                 mid of                                                                 to the left and what they also want to                                 do they want to have it more                                 enterprise-grade so they want to                                 integrate it with Excel right it's crazy                                 how many people use Excel to run these                                 kind of analytics right I think                                 excellest more or less the most use bi                                 tool that exists on the planet and I                                 believe it will still be and they are                                 thinking about taking the hive part                                 maybe off and shifted towards drill for                                 those of you who have talked who have                                 watched Ed session about drill which                                 just ended a couple of minutes ago they                                 may think about that for a faster queue                                 building or to query data ad hoc from a                                 cube standpoint and they may be able to                                 add some capacity management some                                 automation routines and possibly and I                                 know that's a big topic nowadays to                                 integrate with spark so provide in                                 memory MapReduce to use the spark                                 framework to do all the aggregations etc                                 so there's a lot of things these guys                                 are actually doing right now so how do                                 you know or how some resources so                                 there's a kind insight it's now on the                                 incubate and Apache as well there's a                                 Twitter account associated with it so if                                 you want you can just participate                                 there's a source code rapid there's some                                 Google Groups etc and everything is                                 about khylin and they are very very                                 happy if you could just help them                                 contribute test it feedback to the                                 community feedback to the developers to                                 the committers and this is how I want to                                 conclude and I'm open to take questions                                 now
YouTube URL: https://www.youtube.com/watch?v=gn8hafmEenU


