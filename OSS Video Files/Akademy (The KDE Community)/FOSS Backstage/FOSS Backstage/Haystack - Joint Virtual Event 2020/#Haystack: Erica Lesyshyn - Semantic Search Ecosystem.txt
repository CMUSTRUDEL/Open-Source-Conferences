Title: #Haystack: Erica Lesyshyn - Semantic Search Ecosystem
Publication date: 2020-07-02
Playlist: Haystack - Joint Virtual Event 2020
Description: 
	More: https://berlinbuzzwords.de/session/semantic-search-ecosystem

EBSCO Health's Search Team applies user intent analysis to increase precision and reduce the time it takes to answer critical medical questions. Learn about the key areas of our search ecosystem that come together to deliver semantic search results for clinicians. We will kick off the discussion with a deep dive into our content enrichment process. We will explore how our Medical Knowledge Graph semantically enhances our content and enables us to disambiguate context. We will then review how we leverage implicit and explicit user signals to help us understand intent. These signals allow us to dynamically generate runtime specific search strategies against Elasticsearch. Finally, we will discuss how we gather judgement lists from subject matter experts and leverage evaluation tools to tune our search results. Please join us as we explore the challenges of building semantic search for the medical domain.
Captions: 
	                              as you heard my name is Eric Ellison and                               I'm a principal software                               at ebsco information services my primary                               focus is to design search solutions for                               EBSCO clinical decisions we are the                               leading provider of evidence-based                               content for point of care practitioners                               clinicians use our search engines to                               diagnose and treat patients today I'm                                going to talk to you about our search                                ecosystem this is really all of the code                                and infrastructure that come together to                                create a search experience for our                                customers I'll start off with an                                overview of our search prep environment                                this is where we take the content that                                has been written by our editorial staff                                and we transform it into something we                                can work with                                we then semantically enrich and decorate                                this content prior to indexing it is                                then available in our search runtime                                environment the medical search platform                                and query intelligence work together to                                construct run time specific search                                strategies based on user intent we also                                incorporate two types of feedback into                                the system user and expert feedback our                                expert feedback area is really where we                                engage with our subject matter experts                                we work with them to create judgment                                lists otherwise known as golden sets                                these really represent the targets that                                we strive for when tuning our search                                results                                additionally we invite them to curate                                our medical knowledge graph and                                participate in surveys and experiments                                we also observe how our end users                                interact with our search results and                                incorporate that feedback back into the                                system at the heart of our ecosystem is                                our medical knowledge graph this allows                                us to semantically understand our domain                                now today I'm going to give you a                                high-level overview of each of these                                areas                                but if you're looking for more                                information I invite you to check out                                haystacks website you'll find there a                                presentation that I did last year on                                query intelligence additionally I'll be                                speaking in August about all of the                                recent work that has been done on our                                medical knowledge graph our search                                ecosystem is really about two to three                                years old the majority of the work that                                the team does is really greenfield                                initiatives as well as migrating from an                                on-prem environment to AWS we currently                                have about six micro services in                                production and a handful of on-demand                                applications our medical knowledge graph                                was conceived about five years ago                                it has since gone through quite a bit of                                transformation over the years it is                                currently composed of about                                        concepts                                                              relationships now terms are primarily                                our entry point into our knowledge graph                                it really represents ways that users                                would search in our system and it can                                also represent synonyms once we have an                                entry point into the graph we can then                                make a correlation between a term and a                                concept now we also can leverage                                relationships so we can traverse through                                this knowledge graph in order to enhance                                our search experience we use this                                medical knowledge graph as part of our                                search prep environment as well as our                                search runtime environment our content                                ingestion pipeline consults heavily with                                our medical knowledge graph in order to                                semantically understand the text it then                                stores it in our elastic search index                                now naturally our search runtime                                environment has to speak in that same                                language so it also relies heavily on                                our medical knowledge graph prior to                                reading from our                                index so let's take a peek at our search                                prep environment this is an                                architectural overview of our content                                and justin pipeline and this particular                                pipeline really handles two main use                                cases first it handles a use case where                                a content editor has published a piece                                of content and it is ready to be                                 searchable another use case is when we                                 completely reprocess all of the content                                 in our system we refer to this as a                                 content ingestion process now regardless                                 of either use case the pipeline behaves                                 the same it essentially listens for                                 these events and then takes action the                                 first thing it does is it goes out to s                                  and it fetches that particular piece of                                 content it goes ahead and transforms it                                 into internal pojos we then take chunks                                 of that content and we pass it off to a                                 concept mapper in order to semantically                                 understand its meaning now we actually                                 do quite a bit of different types of                                 enrichment or decorating against this                                 content but the most compelling impact                                 is really the result of our semantic                                 enrichment it is then saved into our                                 elastic search index and then we go                                 ahead and we notify the other services                                 of the outcome of this particular event                                 I'm going to go ahead and take a deeper                                 dive into our semantic enrichment                                 process here is a snippet sample of text                                 that we're going to go ahead and enrich                                 the bold here is representing a content                                 title fever of unknown origin FUO in                                 adults below is a snippet of text and                                 essentially what we do is we pass these                                 chunks of text to our concept mapping                                 endpoint and really what the endpoint                                 does is it tries to create a connection                                 between these tokens and concepts in our                                 graph for example fever of unknown                                 origin is associated with concept                                 seven five two zero zero zero zero we                                 then go ahead and semantically wrap the                                 original text with these concept IDs now                                 FUO is actually an acronym for fever of                                 unknown origin so we go ahead and we                                 semantically tag it with the same                                 concept ID in its a stop word and so                                 therefore we do not semantically enrich                                 it because it will not add any benefit                                 so this is an example result of what it                                 looks like after Symantec and Richmond                                 has run you can see here fever of                                 unknown origin as well as FUO are both                                 tagged with the same concept ID you can                                 also observe instances where a single                                 piece of text is associated with                                 multiple concepts in our graph for                                 example temperature is associated with                                 three concepts now this actually might                                 be a great area for us to curate so that                                 we can reduce the number of definitions                                 associated with temperature you'll also                                 observe that there's some portions of                                 text that do not get enriched and this                                 essentially is because we either don't                                 have a definition in our map or our                                 knowledge graph or semantically                                 enriching it really wouldn't add any                                 value so really what we're talking about                                 here is taking large chunks of text and                                 comparing it against a knowledge graph                                 so as you can imagine you might                                 encounter some particular problems when                                 you do this now the issues that we                                 encounter primarily are around acronyms                                 so let's take a look at some examples                                 this particular snippet of text in those                                 with heart failure who have had now the                                 terms who and had are actually                                 correlated to acronyms in our graph the                                 term who is defined as World Health                                 Organization and had is defined as                                 Hospital anxiety and depression now                                 that's actually not the usage in this                                 particular sentence so                                 although we have identified these as                                 acronyms we do not semantically enrich                                 them so we have a set of rules that we                                 follow to ensure that we don't overly                                 tag our content we also have to deal                                 with ambiguous acronyms symptoms of AF                                 is an example of this AF is associated                                 with many concepts in our graph and as                                 you can see when I pass this snippet of                                 text to my concept mapper I'm able to                                 easily resolve symptoms but AF is really                                 associated with way too many concepts                                 for me to tag it there would really be                                 no value in me adding all of these                                 concept IDs to this particular acronym                                 so in order to mitigate this issue we                                 ask that our content writers follow the                                 rule of first occurrence and what this                                 does is it allows them to define the                                 meaning of an acronym prior to usage in                                 the content you can see in this                                 particular example that AF is defined by                                 atrial fibrillation they can then use it                                 freely throughout the content and we now                                 understand its meaning and usage so now                                 we're able to disambiguate AF by                                 comparing it to the expansion that was                                 provided to us so in this case we create                                 that connection between atrial                                 fibrillation and AF this is an example                                 of what our index looks like after                                 semantic enrichment has run you can see                                 here a mixture of keywords as well as                                 concept IDs ultimately when we tokenize                                 this text we strip out the cid tax and                                 what we're left with are the raw concept                                 ids as well as the original text so that                                 summer                                 is our search prep environment let's now                                 talk a little bit about our search                                 runtime environment this is an                                 architectural overview of this                                 environment what happens is we receive a                                 request against the medical search                                 platform and the first thing it does is                                 it tries to understand the users intent                                 it sends the query off to query                                 intelligence and query intelligence                                 performs a series of operations first it                                 needs to segment the query it then has a                                 series of decisions it needs to make                                 should it expand the criteria that we                                 use should it narrow it or perhaps you                                 to keep it                                 ultimately what query intelligence does                                 is it returns a set of recommendations                                 to the medical search platform so that                                 it can construct the best runtime search                                 strategy against elasticsearch so let's                                 go ahead and take a peek at how we                                 segment queries in query intelligence so                                 this is an example query paralysis                                 facial nerve and if we were to use a                                 brute force approach we could say that                                 these three tokens are associated with                                 four concepts in our graph you can see                                 here that paralysis would be associated                                 with two concepts                                 whereas facial and nerve are associated                                 with their own however if we go ahead                                 and we look for the longest matching                                 tokens we can become more specific we                                 can then identify that facial nerve                                 actually corresponds to a single concept                                 in our graph so here we've been able to                                 reduce three tokens to three concepts                                 but if we actually take permutations                                 into account we can become even more                                 specific and more targeted ultimately                                 what we're trying to do here is come up                                 with the most precise best case scenario                                 often times when users enter enter terms                                 into a search box they don't really take                                 the order into account so by looking for                                 the longest matching tokens and also                                 performing                                 mutations along with fuzzy matching we                                 can then create a more specific mapping                                 between terms and a concept in our graph                                 and this is important because we want to                                 create that bridge between the way                                 someone searches and the way content is                                 structured here you can see that our                                 content is actually written as facial                                 nerve palsy but by semantically                                 understanding that and additionally                                 performing the query segmentation we can                                 create that bridge between the two                                 worlds                                 now just because we semantically                                 understand the query doesn't mean that                                 we really understand the intent of the                                 user headache is an example of this                                 headache is a really straightforward                                 mapping at our knowledge graph you can                                 see that we have quite a bit of rich                                 synonyms and terms that represent                                 headache but it turns out that headache                                 is a common side effect of many drugs it                                 can also be a symptom of many medical                                 conditions so we really just don't want                                 to blindly pass this semantic                                 understanding along to searching we want                                 to be a little bit more intelligent                                 about that so let's take a look at what                                 I mean let's walk through some examples                                 let's go ahead and take a look at why we                                 would want to expand a particular query                                 so this is an example of a classic query                                 expansion in our model here someone has                                 searched for zoloft and pregnancy now                                 we've been able to segment this                                 particular query into two concepts                                 zoloft pregnancy however there's a                                 problem here                                 we don't actually mention zoloft in our                                 content our content actually mentions                                 antidepressants so what we can do is                                 interrogate our knowledge graph and try                                 to create that bridge between the query                                 and our content you can see in this                                 example here that we are able to                                 traverse our knowledge graph and create                                 that connection between zoloft and anti                                 prescient however if we do so blindly                                 then we will create a lot of recall in                                 our system and that is evident when you                                 look at the expansion of pregnancy                                 really the intent of the user here is                                 that they would be satisfied with                                 content that is antidepressant or zoloft                                 and pregnancy so let's go ahead and walk                                 through an example traversal in our                                 graph to achieve this when someone                                 searches for zoloft we identify that                                 zoloft is a brand name associated with a                                 substance known as sertraline we then go                                 ahead and examine the relationships                                 intergraph associated with this                                 substance we identify that it is                                 actually a member of the drug class                                 known as SSRIs we then expand to its                                 parent which is antidepressants so                                 ultimately in order to create a bridge                                 between zoloft and antidepressants we                                 first had to identify that this was an                                 appropriate candidate to be expanded and                                 then we went ahead and performed two                                 hops to create that bridge so ultimately                                 when query intelligence receives a query                                 such as this what it does is it returns                                 both segments associated with it but it                                 automatically performs that hypernym                                 expansion and notice that it is                                 selective it does not perform this on                                 pregnancy but it did perform this on the                                 product zoloft and you can see in this                                 example payload that we have the                                 concepts IDs associated with the                                 expansion's we also represent the                                 distance of these expansions in our                                 knowledge graph and this allows us to                                 apply a decay weight when searching here                                 when the medical search platform                                 actually executes this particular query                                 it applies the the highest boosting on                                 the original term which is Zoloft and                                 then you can see that it's been decayed                                 as it expands through the graph                                 this allows us to create that bridge                                 between a very specific query and                                 content that is represented in our                                 system so let's go ahead and talk about                                 the reverse scenario of when we would                                 narrow or we would filter down a                                 segmented query so I mentioned earlier                                 that AF is really ambiguous and we have                                 the ability to solve this during                                 semantic enrichment because we follow                                 the rule of first occurrence but when                                 searching we don't have context or at                                 times we have very little context so                                 what we do is we rely on a variety of                                 sources in order to come up with a                                 preferred definition in lack of context                                 in this case we've worked with our                                 subject matter experts and we've also                                 looked at how users interact with this                                 particular query in our system you can                                 see that more often than not individuals                                 click on atrial fibrillation when they                                 search for AF it also corresponds to a                                 category in our content now when we                                 perform that search we go ahead and                                 identify and make that connection                                 between an acronym and its expansion in                                 our content now I should mention here                                 that we're creating a default experience                                 for our customers but we do have the                                 opportunity to get it wrong so you will                                 see in the future that we will offer the                                 ability for our users to pivot and                                 perhaps give us more insight on their                                 intent all right so we talked about how                                 we prep our environment and we talked                                 about how we search it but let's                                 actually dive into how we go ahead and                                 tune this environment our search                                 evaluation tool was conceived out of                                 this notion that we are very successful                                 when we are tightly coupled with subject                                 matter experts the tool really creates                                 this bridge between highly technical                                 engineers and non-technical and users or                                 individuals who really focus primarily                                 in treating patients so we've we've                                 built quite a bit of rich functionality                                 into this tool and it's actually used                                 heavily by the engineers and these                                 subject matter experts one of our most                                 recent additions into this tool is to                                 allow these subject matter experts to                                 curate the graph you can see here that                                 we're adding very little ability for                                 them to interact with the graph but we                                 will be expanding upon this now this                                 actually is a representation of manual                                 curation but we also do some automated                                 curation against the graph and I'll be                                 talking in more detail about that in my                                 discussion in August most importantly                                 though we invite these subject matter                                 experts to generate golden sets or these                                 judgment lists and essentially what we                                 do is we ask them to go ahead and                                 classify the search results into                                 different buckets for a given query so                                 this is an example golden set that's                                 being generated for the query breast                                 cancer we essentially ask these SMEs or                                 subject matter experts to go ahead and                                 create a classification for each title                                 most relevant are those results that we                                 would expect to peer at the top of the                                 page irrelevant                                 shouldn't appear at all and then                                 relevant are fine to appear anywhere in                                 the main search results notice that                                 we're not asking them to give us                                 position one versus three or seven we're                                 simply asking them to group them in                                 buckets                                 once they're grouped into buckets it                                 gives us an opportunity to calculate a                                 grade on how well we are performing                                 against their expectations what we                                 ultimately do is we perform two                                 different types of scoring the first                                 which is most critical is we actually                                 compare how our search results are                                 behaving against the most relevant                                 bucket that they've defined we then also                                 calculate a grade against the entire                                 result set                                 so this                                 an example of analysis that's been run                                 you can see for breast cancer we're                                 performing an A in the top tier result                                 bucket and then overall we have a grade                                 of a B you'll also see here that we have                                 an indicator on whether this golden set                                 is curated or not and essentially what                                 this means is that we give more                                 precedence or more preference to golden                                 sets that have been generated by a group                                 of professionals versus one that was                                 created independently oftentimes we find                                 ourselves having multiple golden sets                                 for the same query so we want to make                                 sure that when we grade ourselves we use                                 the one that most closely aligns                                 potentially with our customers we also                                 use these golden sets heavily when we                                 compare how certain experiments are                                 performing in the system this is an                                 example where we're comparing a baseline                                 against an experiment known as DMP to                                 underscore fuzzy you can see for the                                 query alpha -                                                          better performing in the top tier                                 results as well as overall so it allows                                 us the opportunity to vet out different                                 experiments before promoting it for                                 other eyes to see it we also rely                                 heavily on what we call a workflow                                 comparison in this particular example                                 the user is searching for croup and                                 we're comparing our baseline against an                                 individual who is authenticated as a                                 pediatrician on the left our baseline                                 shows that the fourth hint is associated                                 with children whereas on the right side                                 you can see here that                                                  are associated with children and are                                 probably more important to someone who                                 is personalized as a pediatrician now                                 once we have vetted out these different                                 experiments we then give them off and/or                                 hand them off to our subject matter                                 experts to play around with it and see                                 what they think what we do is we create                                 a blind survey                                 and we passed them a series of queries                                 and we asked them to rate which result                                 sets are better now we randomly pick                                 which side will display the results so                                 that they can't tell the difference                                 ultimately we use this information to                                 decide if an experiment is ready to be                                 promoted to our live environment now                                 once it's in our live environment our                                 user feedback really then comes into                                 play and we use it to address a certain                                 set of queries that we struggle with                                 let's take an example of this breast                                 cancer is a pretty generic query and we                                 have a lot of content in our system that                                 mentions breast cancer in fact all of                                 the titles in this list have the same                                 thing in common they're actually                                 represented by two different concepts                                 you have breast cancer and then some                                 other concept for example chemo                                 prevention screening tumor markers and                                 ultimately when they search its hearts                                 distinguish which one of these is really                                 more relevant than the other but it                                 turns out that breast cancer in women is                                 actually the title that we would like to                                 appear at the top of the page so what we                                 do is we take click data into account                                 and we ultimately use this as a                                 tiebreaking effect so over time we solve                                 these queries based upon how the users                                 interact with the system and here you                                 can see that we can achieve that goal by                                 applying user behavior so that                                 summarizes my presentation I talked                                 about the four main areas of our                                 ecosystem I talked about how we                                 semantically enrich our content and how                                 we try to understand the users intent                                 when querying and I also discussed how                                 we incorporate expert and user feedback                                 into the system and as I mentioned                                 earlier checkout haystacks website for                                 more information on query intelligence                                 and definitely check out my                                 in August on our medical knowledge graph                                 now if you like what you see we're                                 hiring in my team as well as throughout                                 the organization so check out our career                                 website and reach out to me thank you                                 again fantastic thank you very much                                 Erica we do have some questions you've                                 generated a lot of interest here so I'm                                 just going to go to slack and ask some                                 questions for people so Mia asks is it                                 possible to create your knowledge graphs                                 semi-automatically                                 how much expert curation did you require                                 yeah that's so that's a great question                                 so we actually have an automated process                                 that rebuilds the knowledge graph daily                                 we collect quite a bit of information                                 from the public domains and we also                                 source information from our own content                                 and essentially what happens is all of                                 this information REE is reconstructed                                 together in our neo                                                  resolve all of the relationships we                                 perform machine learning based curation                                 to identify duplicates in our graph and                                 then we actually perform a merging of                                 these duplicates upon exporting this                                 graph so ultimately we do have a manual                                 process for building the graph and we                                 have some curation but we're going to                                 continue to embark upon more because                                 ultimately it can be very expensive to                                 have your subject matter experts curate                                 large portions of the graph so we really                                 try to have them focus on hotspots so                                 some hotspots might be acronyms or                                 concepts that are associated with I'm                                 sorry terms that are associated with too                                 many concepts and also of course any                                 poor-performing queries thank you so our                                 next question comes from artem in your                                 example of analyzing tagged text the                                 position of the concept ID is different                                 from the tagged text don't use the                                 concept ID for overlapping with the tag                                 text during search                                 that make sense i I think so when we                                 search we actually search for a                                 combination of concept IDs as well as                                 text and because they're interlace                                 together when we receive a hit from                                 elasticsearch we need to actually                                 perform some type of extraction to make                                 sure that we highlight the correct area                                 so we do have challenges when they're                                 interlace together but allows us the                                 flexibility to semantically attempt to                                 identify hits in our index and then also                                 fall back on keywords so we really get                                 the best of both worlds but then of                                 course we have to mitigate that when we                                 get the content out of the system thank                                 you our next question comes from Tito                                 who asks when you match a medical                                 concept in the query at search runtime                                 do you only search the concept to                                 identify for contact concept identifier                                 for recall or do you also search the                                 keyword string yeah so similar to my                                 last answer we actually perform both so                                 we actually rely heavily on dis Max and                                 I like to describe it in many ways as we                                 throw a lot of spaghetti at a wall and                                 the one that stickiest is the one that                                 actually contributes to the scoring so                                 we examine the text using phrase                                 matching we also use classic boolean                                 logic we use multi match but ultimately                                 we are using a mixture of keywords in                                 addition to concept IDs thank you I love                                 the spaghetti analogy so I'm Scott asks                                 when you evaluate a search experiments                                 with expert rated documents what do you                                 do with documents that haven't been                                 rated yeah that's a great question                                 because as I indicated before we create                                 these runtimes specific search                                 strategies so it can be quite a                                 challenge when you tune                                 however these strategies end up acting                                 on a small subset of queries so for                                 example I had talked about the hypernym                                 expansion example so oftentimes when we                                 perform an experiment it's you                                 on a narrow focus that we're trying to                                 essentially tune but our golden sets                                 really tend to represent at least a                                 portion of all areas or all strategies                                 that we try to hit so you'll see in some                                 cases we have golden sets that are                                 really focused on acronym hotspots                                 others that are focused more on                                 punctuation or plural others that are                                 focused on you know specific expansion                                 or narrowing cases but ultimately you                                 it's only going to be as good as much                                 data as you can compare now we currently                                 have about                                                             lists and our subject matter experts are                                 constantly creating more it's actually                                 really important to us is that queries                                 that perform well should also be                                 represented by these judgment lists not                                 just those that perform poorly because                                 we want to make sure that as we tune we                                 don't have a degrade in performance so                                 we're constantly running this analysis                                 as we make changes and then really the                                 rule is that if it isn't performing                                 better than your baseline we typically                                 don't promote it thank you well I'm                                 afraid we can't get away from this one                                 hotels how do you handle new concepts                                 such as kovat yeah great question so we                                 have a regular cadence upon which we                                 update our graph now the update process                                 itself I had mentioned we actually run                                 it daily right now but to incorporate                                 those vocabularies from the public                                 sources as a little bit more effort so                                 we don't do it as frequently we do                                 however have the ability to add manual                                 concepts into our graph we tend to want                                 to avoid this approach because you don't                                 have the rich relationships that come                                 from it but kovat is a great example                                 because we actually have written quite a                                 bit of content on covet and so we had to                                 react very quickly so we have the                                 ability to create these concepts go                                 ahead and curate them and then we can                                 catch up later                                 with the public vocabularies thank you                                 so we've got time for one last question                                 I'm afraid but remember                                 you can join the breakout room                                 afterwards to carry on discussing these                                 interesting stuff interesting concepts                                 with Erica so I'm going to ask on                                 Charles's behalf how many it's subject                                 matter matter experts do you have and                                 are these full time employees or                                 consultants that review the golfers                                 needed that's a great question so we                                 write our own content and so we have                                 this incredible staff of medical                                 professionals that are top physicians in                                 their fields they are often seeing                                 patients and they're also writing as                                 part of our content and so we actually                                 have about I think                                                 represent different areas or different                                 domains or specialties we meet weekly                                 with them and we talk about future                                 initiatives we discuss any poor                                 performing queries and we also do                                 operations together to curate the graph                                 so we have quite a few on hand some are                                 more involved than others but ultimately                                 the goal is to have even more involved                                 in the process as I had mentioned we've                                 been incorporating more manual curation                                 into our tooling in order to allow a                                 wider audience of subject matter experts                                 to work with our graph okay thank you                                 I've actually misunderstood the time                                 slightly so we do have a little more                                 time for questions if that's okay                                 sure Tom Bergman's asks we look at your                                 specific example so he's wondering why                                 zoloft was expanded in the query but                                 pregnancy was nonce yeah so if I had                                 expanded pregnancy I would have created                                 too much recall in the system so                                 pregnancy if you expand up to the parent                                 ultimately comes down to a female organ                                 right it becomes really very generic and                                 so if I expanded that the search results                                 probably wouldn't make sense so when we                                 expand we really want to make sure that                                 we're we're really careful when we do                                 that or when we make that particular                                 decision really what we try to focus on                                 most is precision we have expert                                 end-users that are working in this                                 and for us we want to make sure that we                                 really shorten the time it takes to                                 answer these critical clinical questions                                 so for us when we do expand and create                                 more results that they have to look                                 through we want to make sure that it's                                 always with the goal of precision in                                 mind thank you and I think we will have                                 our last question now this is another                                 one from T so how do you evaluate and                                 tune the algorithmic expansions function                                 to ensure the system is not returning                                 too many matches how do you avoid                                 watered-down results for precise certain                                 searches yeah it's it's a tough problem                                 to solve so for us because we're very                                 selective we do quite a bit of                                 experiments and blind surveys ultimately                                 with our subject matter experts to                                 evaluate that but but you do absolutely                                 run into trouble so even though we have                                 two point seven million relationships in                                 our graph we really rely heavily mostly                                 on about five hundred and thirty                                 thousand of those relationships so we                                 are selective when we actually perform                                 these expansions and I should mention                                 even though there's these these about                                 five hundred thousand that we use it's                                 only during selective periods so it's                                 really got to meet a certain threshold                                 in order for us to trigger it because                                 otherwise you know the search results                                 can become as you indicated watered down                                 very quickly and you can see a real                                 degrade in performance an example of                                 this is if you went ahead and just                                 blindly expanded any substance if it                                 wasn't a drug brand name and it just any                                 random substance you could see search                                 results that come back that are really                                 not even related to it because you've                                 really traversed too far away in your                                 knowledge graph for it to be relevant                                 you
YouTube URL: https://www.youtube.com/watch?v=PokQR9zVmV4


