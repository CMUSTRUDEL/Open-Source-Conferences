Title: Atita Arora – Exploring the alchemy of Streaming and Solr cloud
Publication date: 2021-06-24
Playlist: Berlin Buzzwords 2021 #bbuzz
Description: 
	This is a normal E-commerce use case that had been relying on earlier standalone Solr and later Master-Slave for ages.
Everything was running smoothly with no performance glitches until one day we had this requirement to support “Unlimited Products” in our shops.
We were confident that things would be smooth with full reindex 2 times a day but looking at the index pipeline duration of 4+ hrs, we realized it needed some cloud magic.
This is where we started and transformed a normal batch index pipeline to a stream index pipeline leveraging Kafka and Redis and achieved a NRT indexing.
Along with that, we did not shy to give our infra a bonus upgrade from Solr 6.6.2 to Solr 8.7 and an add-on migration from the existing Master-Slave to Cloud.
We want to talk about our journey and important lessons learned during this process.

Speaker
Atita Arora – https://2021.berlinbuzzwords.de/member/atita-arora

More: https://2021.berlinbuzzwords.de/session/exploring-alchemy-streaming-and-solr-cloud
Captions: 
	                              hello everyone my name is atita arura                               and i'm an active contributor in search                               community                               i currently work with my toys group and                               today we're going to be talking about                               exploring the alchemy of                               kafka streaming along with solar cloud i                               hope                               i make use of enough time because my                                slides are a little longer                                so my agenda of course i would be                                discussing about the problem the                                proposed solution                                some improvements that we made and i                                hope we leave some time for questions                                and suggestions                                so i would skip this part just to give                                you a brief that my toys                                tmbh was founded in                                                   of auto group                                and we have various other shops that we                                support which have products ranging from                                pregnancy to everything about kids wide                                range of shoes and home furnishing to                                check out                                we have over                                                           statistically speaking we serve about                                                                                                 conversion rate of                                around nine percent uh now small                                snapshot from the last uh black friday                                we served about                                                        one single day                                so after that introduction a little bit                                about our platform that we have changed                                so                                previously it used to look like this                                that we had the data source                                uh the data that would consist of                                everything from the product data                                promotional data                                data from data warehousing and                                everything and whatnot                                all of this data was consumed by our                                batch processors                                uh which is called solar importer the                                main idea of the solar importer was to                                transform the data based on the business                                logic                                and put the documents into solar which                                are then served on the portal through                                the product service                                uh the subsidiary process was also                                supported here for the price and stock                                of course for e-commerce that's a very                                essential thing                                to maintain the uh challenging uh prices                                uh you know attractive prices and the                                stock update but to mention here that                                these stock updates were not processed                                when this                                batch process was running that was one                                of the biggest crucial                                disadvantages to add here is also that                                there were some shortcomings uh that we                                were able to support only the limited                                number of products due to limited                                resources                                the complete catalog reindex which was                                happening twice a day                                was taking close to four hours each time                                and as i just mentioned                                that we were not processing the price                                and stock updates every time this batch                                processes was running                                which means that the know that there                                were no product updates                                while the catalog index was happening                                scaling of course                                does looks worrisome in such kind of                                approach and there was no disaster                                recovery mechanism                                another bad thing is that we had the                                bulky document size because we are                                sowing everything from solar                                so to counter this we wanted to plan                                something that would help us                                in the long run so to begin with we                                wanted to keep only the searchable data                                in solar to reduce the number of fields                                in solar                                and we plan to use redis for supporting                                solar with this thing                                we wanted to reduce the pipeline time to                                not spend four hours but rather should                                be done in the near real time                                we managed to reduce the index footprint                                by reducing the number of fields from                                                                                                    shops                                 the disaster recovery management was                                 achieved through the kafka replay using                                 the kafka connect that i will i'll be                                 showing you in the                                 next slide of course there was no wait                                 for the full re-index anymore                                 we are processing everything in real                                 time and the infrastructure scalability                                 management                                 was achieved through the kubernetes so                                 to give you a sneak peek as to how                                 exactly the architecture looks like                                 i hope i can do justice i would have to                                 go back to the architecture                                 okay come up come up                                 okay i guess everyone can see this                                 so here the data source stays intact as                                 it was instead of being consumed by the                                 batch process                                 we are publishing the respective data                                 into the respective topic                                 topics and this is consumed by the                                 product data topology which processes                                 now                                 the data as per the business logic and                                 combines them and publishes them into                                 one single topic which is then consumed                                 by the                                 master and the variant topology these                                 are very heavyweight                                 and highly available and heavy data                                 processing topologies that we have                                 over here you see is the solar adapter                                 topology                                 the main aim here is to transform the                                 data into                                 the solar documents and publish them                                 into the respective                                 shop topic so after this the data is                                 being read                                 from here into the kafka connect cluster                                 which is then consumed by the solar sync                                 and pushed into the solar which is                                 served through the search service the                                 other data which is non-searchable                                 is published into the redis and it                                 served through redis through the product                                 service                                 so that was of course the major                                 transformation that we did                                 to the uh platform of course we were                                 expecting to see bigger challenges                                 so we did face some challenges on the                                 kafka streams first and the foremost was                                 the slow and expensive                                 kafka state restoration because we're                                 talking about the data magnitude of                                 almost                                                       bootstrapping to help us here i'm going                                 to be showing you how we did that in the                                 next slide                                 uh we had to make a lot of                                 customizations to the kafka solar                                 connect because uh                                 we ran into the race condition with the                                 document addition and deletions                                 so we had to modify the behavior as well                                 for horizontal scalability                                 we based it out of matrix used uh uh                                 metrics here was consumer lags if the                                 consumer lacks increases                                 the certain number we spin up a new pot                                 in the kubernetes                                 to make sure that the consumer lag is                                 taken care of the rock cd customization                                 was done to ensure the cold                                 bootstrapping is supported                                 i would be showing you that uh of course                                 as i also already mentioned that we are                                 maintaining four high volume topology so                                 managing                                 such big amount of data was very                                 challenging                                 we were using the self-managed kafka                                 here but we migrated to msk here                                 we used mirror maker to come to our                                 rescue                                 so this is what i was talking about that                                 by default uh                                 in kafka we use change lock topic uh for                                 the                                 uh state recovery and replay but uh                                 and in this case uh we were taking                                 almost close to like                                                     our                                 kind of data so we had to modify this                                 default behavior instead of using change                                 log topic                                 for recovery data and replay we used the                                 active                                 rocksdb and every time the standby went                                 down                                 instead of replaying everything from                                 changelog topic                                 we copied the rocksdb from the active                                 into the standby                                 with this approach the data recovery was                                 lightning fast                                 uh it's like eight seconds for                                           data                                 and we were able to recover this uh                                 challenge                                 pretty well so this is called cold boots                                 trapping                                 and what did we improve in general as                                 a whole uh transformation that we were                                 able to                                 update the products in real time we got                                 rid of the index pipeline which took                                 four hours now everything is getting                                 updated in real time                                 we upgraded solar from solar                                                                                we also moved from master slave to solar                                 cloud we managed to switch to manage                                 kafka and now we have uh corrected                                 the architectural flaw that everything                                 was served from solar now we're using                                 reddish to support solar with the                                 non-changing fields                                 just in case if you have questions about                                 the future work we are planning to open                                 up to community and we are                                 doing an intensive review of the changes                                 that we have made and we are going to be                                 opening up to the community for the                                 customizations that we have made to the                                 kafka connect                                 the state recovery library slash cold                                 bootstrapping                                 and the kafka connect customizations so                                 just in case you have any questions                                 please                                 feel free to reach out to me and some                                 references for your                                 online offline references                                 so thank you i hope i was able to cover                                 this in                                 five minutes any questions                                 thank you so much uh that was uh                                 you covered such a lot in a short time                                 uh i don't see questions here but i've                                 got a few uh                                 firstly thanks for uh yeah sharing those                                 upstream changes that                                 uh you're anticipating coming back to                                 the community that's that's wonderful to                                 hear                                 and you also listed some challenges                                 there the major challenges that you                                 faced with the                                 uh yeah with the new rollout that you                                 described i wonder how did those                                 challenges                                 fit with the anticipated challenges so                                 like expectations versus reality                                 were the hardest parts the thought the                                 part that you expected to be or yeah was                                 it really quite unpredictable in the end                                 well i i would say that that's a very                                 good question and in fact uh                                 we were anticipating changes we were in                                 fact you know when we did the the poc we                                 were not anticipating the changes like                                 the race condition that it                                 spoke about we were not even looking                                 forward to such kind of race condition                                 that the                                 deletions would come before the editions                                 and we would run into like the blocked                                 uh infra completely similar to that was                                 that                                 the bootstrapping that i spoke about the                                 bootstrapping took                                 close to like                                                            tried we were not even anticipating that                                 because we did not understand or we did                                 not actually estimate                                 the data would grow as big as like                                     gb so yes                                 i would say that a lot of places we did                                 not anticipate all of this to go                                 uh haywire it took us a lot of time it                                 took us about eight months                                 to implement this but we're pretty happy                                 how it looks right now                                 that's great here it's always                                 encouraging to hear how you know how it                                 works in the real world in eight months                                 yeah                                 it sounds quite reasonable considering                                 that the challenges that you face but                                 it's                                 always helpful to benchmark with                                 organizations like that so thank you                                 you
YouTube URL: https://www.youtube.com/watch?v=wush4EBP1bE


