Title: Kevin Watters – Document classification search; joins vs payloads
Publication date: 2021-07-01
Playlist: Berlin Buzzwords 2021 #bbuzz
Description: 
	Payloads are a powerful though seldom utilized feature in the Lucene-Solr ecosystem.  This talk reviews the existing payload support in Lucene and introduces the new features in Lucene and Solr 9  (LUCENE-9659 / SOLR-14787).  The main focus of the talk will be to explore real world search & ml use cases that traditionally utilize a query time join and the application of Lucene payloads to solve them. This talk is for search practitioners interested in utilizing machine learned data in search based analytics dashboards. 

Many Solr based applications attempting to deal with machine learned classifications are forced to implement a parent-child join relationship between a document and its classifications.  This model introduces many additional system constraints and costs at both query and index time to maintain the ability to filter results as desired. 

New features in the payload span query in Lucene provide applications a way to maintain query flexibility without incurring the cost of performing a query-time join.  This greatly simplifies system design and architecture and can provide dramatic improvements to query performance.

A reference implementation will be presented that compares the join and payload approaches.  The demonstration will show how to search for documents that have classifications above a particular confidence threshold at scale.

Speaker: 
Kevin Watters – https://2021.berlinbuzzwords.de/member/kevin-watters

More: https://2021.berlinbuzzwords.de/session/document-classification-search-joins-vs-payloads
Captions: 
	                              hello everybody                               i'm glad everybody could join us today                               very excited to talk about some of the                               the features that we've added to leucine                               and solar                               thinly veiled in a talk about image                               search                               and indexing the output of neural                               networks                                um so who am i i'm the founder of kmw                                technology we've been in operation since                                about                                                           and we primarily focus on solar                                elasticsearch                                and leucine we provide training search                                cluster architecture review                                application development we perform solar                                audits                                uh and we're very very big proponents of                                open source                                contributors supporters and committers                                so before we get into some of the the                                approaches that we took to solving this                                problem i was going to do a quick little                                overview on what payloads are because                                i feel like they're they're often                                overlooked and people don't necessarily                                know what payloads are                                payloads are a piece of binary data that                                can be stored                                at a position in a field of a document                                and                                they're stored in the pos files of the                                index                                and these these pos the pos file and                                lucine index                                provides us with the byte offsets for                                this term's position within a document                                in the pay the payload file                                um and this this allows us to very                                quickly reference that binary data                                uh at query time and there's a couple of                                lucine queries that support this the                                span term check                                uh span check term query and                                a few others but primarily these are                                exposed through uh                                solar's query syntax to the query                                parsers of the payload check                                and the payload score query parsers                                previously the payload check query                                parser could only provo                                perform a pure equality operation like                                does the payload equal a value                                that's specified but we we saw a very                                simple                                improvement to make to that which is                                just to support inequality operations                                that's greater than less than greater                                than or equal to                                and this really opens it up to a wider                                range of                                of use cases with a relatively minimum                                impact to performance compared to normal                                payload                                checks um so what are payloads and solar                                how do you configure them well what they                                they are the special field type                                and the important thing in that field                                type                                is that it uses the delimited payload                                filter                                in the analysis chain what this allows                                you to do is it allows you to encode a                                payload                                with every value so if you see the data                                input format down below                                where you have something like a value a                                pipe and then the payload that you want                                to associate with it and that becomes                                your field data                                current payload encoder decoder support                                for                                integer floating point and the string                                operation or identity as it's also                                sometimes called                                quick review of the solar query parsers                                that support this                                first one which we won't be talking                                about much today is the payload score                                query parser                                which allows you to use this payload                                information                                as part of your relevancy calculation or                                your scoring calculation                                uh useful to know that it's there not                                the focus of this talk                                more interesting was the the payload                                check query parser that can                                 make a determination to match a                                 particular term                                 in a document if the payload equals a                                 particular value and i think that most                                 of this                                 functionality came out of the part of                                 speech                                 searching use cases so that would be                                 searching for the word train                                 only if the train uh word                                 had been tagged as being a noun versus a                                 verb so kind of more granular control                                 not just term matching                                 but uh matching the payload uh as as                                 mentioned before                                 what we've we did is we extended this                                 payload check query parser to add an                                 additional parameter which is the                                 operation                                 op which will match against the payloads                                 and here we specify gt representing a                                 greater than example                                 so if we could imagine having the word                                 train with a payload of                                             search for                                 documents that contain trane where it                                 was                                 had a payload that was greater than that                                 value                                 all right so let's talk about our use                                 case motivation why did we go down this                                 road                                 uh in the first place the the example                                 use case we're going to present here in                                 this talk                                 is um really dealing with the output of                                 neural network model classifications so                                 if you                                 look at like most of the bleeding edge                                 in image recognition uh it's                                 most more than likely you've come across                                 you know convolutional neural networks                                 um some open source popular ones vgg                                   and yolo we used in this example we'll                                 show you a demo of what                                 that output looks like a little bit                                 later in the talk                                 um but generally speaking a neural                                 network you have                                 something like an image where each pixel                                 is a value on the input                                 it goes through the network and then you                                 have an output layer                                 where each one of the outputs usually is                                 a particular label or a classification                                 and the score on that output is like a                                 confidence score                                 so what we end up with is for any given                                 image that we want to classify we end up                                 with a                                 list of classifications and each                                 classification has                                 its confidence score associated with it                                 um other other models like yolo in                                 addition to giving you a category and a                                 confidence threshold it can also give                                 you bounding box information                                 uh about um you know what it detected in                                 the image                                 so we'll come back to this uh in the in                                 the demo at the end of the talk                                 hopefully we have time                                 uh but here's just one way to kind of                                 represent uh                                 payloads in the index uh classified from                                 a machine learned uh model so                                 we have here the                                               dpfs delimited payload                                 floating value s for multi-value field                                 uh and we see the label and the                                 confidence thresholds                                 are are encoded here uh yolo                                 classification gives us the object type                                 in this situation we have an example of                                 a person                                 and that there was one person detected                                 we have positional information                                 x and y coordinates of where in the                                 image                                 that that person was detected and we                                 even can compute things like how large                                 the the person is in the image                                 all of this kind of boils down to a                                 general                                 data model that looks like this is a                                 one-to-many relationship between                                 documents and classifications                                 where you have a document with some data                                 on it that's your parent document and                                 then you potentially have many                                 classifications each one with its label                                 and its own confidence score                                 so the first approach to index something                                 like this the most naive approach and                                 simplest approach by far                                 is if we want to search for all the                                 documents where                                 they had been classified as containing a                                 person with                                      you know confidence or greater one thing                                 we can do is filter it at index time                                 and this is the most you know                                 straightforward way it says you do your                                 classification up front                                 and you only tag the document with the                                 the labels that were above a particular                                 threshold now the pros of this approach                                 is it's incredibly simple                                 it's very fast the index is very small                                 but the real trade-off is that you can't                                 change your mind about what the                                 threshold was                                 at query time because you're throwing                                 that away at index time                                 so if you wanted to change your query to                                 say                                 medium or high confidence thresholds                                 then i need two separate fields to                                 include the different labels and stuff                                 and that complexity just                                 kind of grows as you know you want to                                 tweak what you consider high medium and                                 low                                 so kind of a straightforward approach um                                 for its simplicity but it does not yield                                 any flexibility at query time                                 and if we look at what a document of                                 this style would look like                                 uh obviously you have a document id and                                 maybe you have a field that's like your                                 high confidence labels                                 where you tag the document as being a                                 dog or a cat or whatever it is                                 and a simple you know term query on that                                 field is going to find                                 things that are tagged as being cat or a                                 dog                                 because you did that filtering up front                                 at index time                                 not every model has the same sort of                                 confidence threshold sometimes you want                                 to expose that                                 that confidence threshold to the end                                 users to decide what they consider                                 good output from the model or not um and                                 allow                                 you know the end user to adjust their                                 their recall                                 on this so another approach to setting                                 this up                                 is to use a dynamic field or one field                                 per label that came out of the                                 classification                                 so you could imagine having a field for                                 cat that was a floating point field                                 and that has the score of                                               it is                                 a field for dog a field for a person you                                 know                                 and and this this can work very well i                                 mean the nice thing is that query time                                 this becomes a a search on the label                                 field                                 it's a range search for whatever numeric                                 value you want in there so pretty                                 straightforward very performing queries                                 but one trade-off is that you know you                                 might have                                 a lot of labels and as a result you'll                                 end up with a huge number of fields in                                 your index                                 which as it turns out ends up being                                 extremely expensive in terms of memory                                 usage                                 um and in a solar index or leucine index                                 uh and the other trade-off is you might                                 not know the labels ahead of time so                                 uh you can't necessarily fast it on                                 field names like although i guess you                                 could use like luke to                                 interrogate the index to get all those                                 out um                                 you know it just adds a little bit of                                 extra complex complexity there                                 so what is a document that looks like                                 what would a document like that look                                 like here's here's an example a document                                 with an id                                 has a field for each one of the labels                                 cat dog person and the score                                 and the sample query here is is very                                 straightforward and very simple                                 approach number three that we looked at                                 was actually to use a join query                                 to leverage the inherent quarry time                                 join capabilities that solar and lucine                                 have                                 to index the parent document                                 and the child classification records                                 associated with that we would search                                 through the classification records                                 and perform a joins of the parent                                 document and return just the parent                                 document that had a classification                                 record that that matched the query so                                 the pro on this is it gives you full                                 flexibility in terms of your                                 relational type of queries uh return                                 this parent document if and only if the                                 classification record has a particular                                 label has a particular value                                 and you can do is complicated filtering                                 on the classification records as you                                 like                                 and return just the parent record now                                 [Music]                                 the the big drawback here is of course                                 the join queries are much slower and                                 we're going to show some benchmarks                                 later on                                 that really kind of drive that point                                 home                                 and that's primarily driven aside from                                 the fact that you have to do the join                                 is that you have a vastly increased                                 number of documents in the index                                 as a result of having all these children                                 documents around and search response                                 times generally are kind of linear with                                 the number of documents per shard so                                 that means that when you start going                                 with a join approach you really almost                                 immediately have to think about how are                                 you going to shard                                 or scale up this join and when you do                                 any sort of sharding in an environment                                 where you are doing a join                                 you need to make sure that you're                                 routing all of your documents to the                                 same shard based on their join key                                 otherwise that join query is just not                                 going to work as you expect                                 so a little bit of complexity and if you                                 have the freedom to route by the join                                 key then that's                                 probably not as much of an issue but it                                 definitely needs to be thought about                                 when you're                                 going with an approach like this                                 in a document here here's an example of                                 what a join query with a                                 parent document in the child                                 classification documents would look like                                 we have a simple document whether just                                 an id maybe some other metadata on it                                 and then for our example we did a                                 million parent documents each one having                                 an average of                                    classification documents and the                                 classification documents themselves had                                 a pointer back to the parent                                 uh they have a label and a confidence                                 score and we see an example join query                                 below that does                                 a search for uh classifications                                 for yours is label foo so searching for                                 the foo                                 classification with a confidence point                                 seven five and up                                 joining on the parent id back to the                                 parent document                                 on the id field so definitely doable one                                 thing to note is that with this query                                 here only the parent documents will be                                 returned so the metadata of the                                 child document being classified is is                                 not                                 available to the ui um unless you use                                 the like a child doc transformer to                                 fetch the matching classified document                                 so                                 adding additional complexity not just                                 the query but also to fetch the                                 the matched uh metadata from the                                 classification record all right so this                                 this brings us to                                 um the the payload approach that we we                                 took a look and we                                 we observed this this common use case of                                 being able to search for a label on a                                 document or a term on a document                                 and that term or label came from a                                 machine learned model                                 and it's really almost like a one                                 dimensional join we always knew that                                 we're going to be                                 filtering on a single dimension in this                                 case here                                 the confidence score so we looked at the                                 existing payload check query parser                                 and we're a little disappointed to find                                 that it only supported an equality                                 operation                                 and understanding that at the end of the                                 day this is just paging in a byte array                                 and previously it was doing an equals to                                 implement a comparator                                 interface on that to greater than less                                 than or equal to                                 really was little to no computational                                 overhead                                 so we were confident this approach was                                 going to perform at least as well as                                 normal payload queries do                                 so what we did is we encoded the                                 confidence scores uh                                 as a payload a floating point value                                 and we indexed them and we extended the                                 payload query check                                 parser to support these inequalities                                 to do this and we take a look at what an                                 example document                                 that uses the payload check query parser                                 would look like here we have a single                                 field with the classifications                                 this is effectively the the output layer                                 of the neural network                                 with some human readable labels cat dog                                 and person                                 with the pipe delimiting the term or the                                 label from the confidence score                                 and you see the payload check query                                 parser where you specify the field that                                 you're going to do this on                                 you specify the payload and the                                 operation for the comparison                                 and the original query term which is cat                                 in this case                                 to only find cats that are                                       better confidence score                                 so four different approaches are great                                 but you really need to make an                                 informed decision about why you're                                 choosing to go with one                                 or the other in my opinion the only real                                 way to do that is actually to do some                                 benchmarking                                 so what we did is we generated relative                                 indices                                 uh representative data to                                 prove out some of these benchmarks                                 for indexing benchmarks that we're going                                 to talk about we had a single threaded                                 java application                                 that was just feeding documents into                                 solar                                 with the formats as we've described in                                 the previous slides                                 for those documents we generated one                                 million of them                                 each document had an average of                                    classifications per document                                 and those classifications had a random                                 confidence score assigned to them                                   between                                          there are                                                      in that classification data set that we                                 used to generate so                                 we have a million documents with on                                 average                                                                                                                                    score                                 randomly distributed zero to one so you                                 know kind of a                                 relative representative data set for                                 what we see                                 when we actually use these neural                                 networks and indexing time                                 at quarry time we wanted to make sure                                 that we're looking at the raw query                                 performance and we're not being fooled                                 by any of the caching going on                                 so we again have a single threaded app                                 uh all the filter cache sizes were set                                 to zero                                 so really the only effects of caching                                 that we saw in this benchmark were                                 operating system level caches uh                                 potentially some of the leucine field                                 level caches that get triggered but                                 none of the solar caches were enabled                                 for these benchmarks                                 getting into the actual benchmarks here                                 um                                 the the couple things jump out at us                                 that                                 the approach one where we're filtering                                 data out at index time                                 we were able to index these documents                                 very quickly                                                           the index was was the smallest uh                                 memory usage as reported through the                                 solar console on the core                                 uh the heap usage and was was pretty                                 small ultimately                                 um approach two                                 a bit surprising where we have all of                                 the fields potentially ten thousand                                 fields                                 in the index uh it was the slowest to                                 index um perhaps because the json                                 representation of the document is just                                 much larger                                 it's not as tight of a format we don't                                 really know the exact reason why this is                                 so much slower perhaps it was because                                 there's so many different fields that                                 the index itself has to                                 kind of pay attention to where it's                                 writing that data out in the index it                                 wasn't wasn't super easy for that to                                 be achieved so                                                                                                                    approach too per field approach                                 has major impacts if you're going to be                                 a lot doing a lot of indexing                                 the the other big one that really jumped                                 out at me is that the reported heap                                 usage required for supporting this index                                 nearly a thousand times more memory                                 compared to approach one                                 really highlighting the impact of having                                 a lot of fields in your index                                 approach three using the child document                                 join yielded the largest index overall                                 so you know uh we're talking about small                                 indices here but                                 you know                                            i'm sorry                                                               having the overhead of the additional                                 documents in this situation                                 and really kind of contributed to the                                 index size                                 memory usage not as far out of whack                                 as compared to the per field approach                                   not too bad but interestingly approach                                   with the payloads                                 yielded a slightly larger index than                                 approach                                   but the indexing rate was know about                                    times faster than                                 approach                                                             fast as                                 throwing away data at index time but you                                 know                                 nearly                                                               approach                                                              label approach memory usage surprisingly                                 also is                                 less than original approach one and i                                 think this might just be                                 you know we'll call those roughly                                 equivalent                                 query benchmarks um also very important                                 to pay attention to because we're not                                 just                                 concerned with indexing we're also                                 concerned with querying                                 join queries we're slow so slow in this                                 benchmark that we just stopped after a                                 thousand queries                                 um we'll say that up front approach one                                                                                      running                                                             label                                 no big surprise because this is just a                                 simple term cory                                 uh the range query approach on the per                                 field                                 was the second fastest about                                             a second                                 but notably the average result size for                                 these documents was considerably larger                                 probably because the overhead of all the                                 json uh                                 formatting and stuff so i think that's                                 what really                                 kind of hurt approach two in this this                                 case                                 uh the join parent-child relationship                                 quarters were taken like two seconds um                                 you know of course                                 we turned off caching so that's kind of                                 very negatively affecting this but                                 we're not measuring queries in terms of                                 hundreds of queries per second                                 we're measuring query rates at like half                                 a quarter second                                     quarters per second um                                 [Music]                                 compared to the the payload approach                                 where                                 we don't have the memory hit that we did                                 on the the index side                                 we're still getting about                                               second                                 average result size of these are smaller                                 likely to the tighter uh you know                                 json that we have um overall the query                                 response time                                 yeah you know i mean three milliseconds                                 versus one or two milliseconds in the                                 other approach                                 still in the ballpark                                 so let's uh let's talk a little bit                                 about a quick little demo that we'd like                                 to show                                 um to see what this looks like so we                                 index the cocoa image data set                                 this is about                                                        open source                                 we have a document processing pipeline                                 that has an image processing sub                                 pipeline that handles                                 things like running opencv for blur                                 detection detecting faces                                 and also running things like vgg                                   classification yolo classification                                 and similar we kind of hinted at this                                 document                                 style before here is an example of what                                 the the documents look like in our                                 example index                                 so let me go ahead and                                 switch over to the index here where                                 make this a little bit bigger and we                                 have here                                 an index of a                                                                                                            some questions based on the outputs                                 of those models so here for example let                                 me ask                                 of these images show me the ones where                                 pizza was classified as                                                                                                     we've got                                                                                                     decrease this                                 and now we've got                                                        and let's say i want to find ovens                                 here i'm looking for pictures that have                                 at least one oven in them                                 maybe i'm interested in ovens                                 and pizza which is kind of interesting                                 because now we're                                 we're leveraging the output of one                                 neural network model yolo                                 and another neural network model vg                                      the same time                                 not just to find you know pizzas or                                 ovens but                                 pictures of ovens and pizzas or pizzas                                 and ovens                                 maybe i want ovens and pizzas and people                                 for example                                 people with well that's that kind of                                 looks like a stove but that's an oven                                 you can kind of see a blurry person over                                 here here's a person with a pizza and                                 there's an oven in the background                                 maybe i'm interested in                                 a person with a laptop                                 find those maybe i'm interested in                                 more than one person or a group of                                 people with laptops                                 maybe i'm looking for                                 people whoops                                 at a bakery you know                                 greater than two people at a bakery                                 maybe i want less than two people at a                                 bakery                                 well let's see are less than equal to                                 two and get that people out there                                 there's only one person at a bakery so                                 let's go back now                                 all right what are what are some other                                 things that we need to                                 consider going forward with this um                                 in in some of this work that we did in                                 lucine it kind of appeared that the                                 codec the encoding and decoding of the                                 payloads is a little bit fragmented to                                 be a nice improvement in the code to                                 make it a little more extensible                                 and once that codec library would be a                                 little more extensible it would be a                                 very short                                 lift to do some things like vector                                 matching where if you encoded not just a                                 single floating point value but an array                                 of floating point values you could start                                 doing things like computing cosine                                 similarities                                 once we have these sort of you know                                 classification feature vectors from from                                 these neural networks                                 uh it's a small jump also to look at the                                 the classifications that came out for an                                 image                                 and compose a fine similar to find                                 other images that had similar style                                 classifications and                                 classifications in similar ranges um                                 one of the things that kind of jumped                                 out at me is additional                                 you know things that would be nice to                                 have the syntax for this                                 is a little bit difficult to                                 to work on it's it's not definitely                                 something that an end user would type in                                 uh having some nlu or in nlp sort of                                 front end for query parsing so that you                                 could in natural language say show me a                                 picture of an oven                                 with some pizzas and at least two people                                 uh and translate that into the                                 appropriate query                                 so this was uh all added back in this                                 will be in solar                                                        released                                 um in the tickets the scene                                                                                        uh myself as a contributor and                                 committers                                 gus heck and dave smiley big thank you                                 to them                                 for for helping usher this through to                                 the community                                 and um yeah i think we have two minutes                                 for questions                                 maybe a few more from lucky                                 great talk kevin and us i can read from                                 here                                 even people feel the same it was a great                                 talk with a great                                 example that you have showcased we do                                 have some questions                                 some of the questions are answered by                                 the community itself however someone                                 asked that                                 can this payload approach be used in                                 elasticsearch                                 although the link for this has already                                 been provided but would you like to                                 extend                                 yeah so um the                                 the span payload check query uh                                 in the leucine layer as soon as that is                                 included in the latest                                 elastic surge build then at least the                                 lucine query would be there                                 you would still very much like the need                                 some extension to the existing payload                                 support                                 and elasticsearch so you know being                                 lucine under the covers there's no                                 reason why it couldn't be extended to                                 elastic but it's not currently supported                                 great i think on the same line was the                                 question that how easy                                 it would be to extend the query parser                                 and elastic search as it is done in                                 solar                                 in this talk and i think you've already                                 answered that question yeah yeah                                 yeah absolutely so you know either with                                 uh separate plug-ins                                 uh or extending the existing lucene                                 existing                                 elastic source you'd be able to do that                                 but again                                 this is going to require that                                 elasticsearch is pulling in the latest                                 uh                                 leucine from that the                                                   yep i think max irvin                                 also commenced the same thing probably                                 he has tried uh something on that side                                 already                                 so he uh requests if there is a way to                                 reference the payloads in a                                 painless script uh if that can be                                 provided                                 we we we haven't done that and actually                                 it's kind of looking at it a little bit                                 more                                 um it'd be nice to kind of extend this                                 payload check support                                 into the payload score core reparser so                                 you could start doing things like that                                 [Music]                                 that would be a very nice future                                 enhancement for certain                                 you
YouTube URL: https://www.youtube.com/watch?v=IrMcasPK_sc


