Title: Dmitry Kan & Max Irwin – Vector Search: Ask Me Anything!
Publication date: 2021-06-29
Playlist: Berlin Buzzwords 2021 #bbuzz
Description: 
	Get to know about vector search and ask Dmitry Kan & Max Irwin anything you need to know! This session is presented by "Haystack – The search relevance conference" and hosted by Charlie Hull.

Speaker:
Dmitry Kan – https://2021.berlinbuzzwords.de/member/dmitry-kan
Max Irwin – https://2021.berlinbuzzwords.de/member/max-irwin

More: https://2021.berlinbuzzwords.de/session/ask-me-anything-vector-search
Captions: 
	                              hello                               uh good morning good evening good                               afternoon good day wherever you are in                               the world                               and welcome to berlin buzzwords my                               name's charlie hull                               um i'm from open source connections uh                               we're the search and relevance people                               and we're sponsoring berlin buzzwords                                very happy to do that do check out our                                partner our booth in the partner area so                                this talk actually is presented by the                                haystack conference for partnering with                                buzzwords this year                                um with haystack we aim to share great                                talks on search and relevance                                and bring the community together um                                currently we're running                                a haystack live meetup every few weeks                                i'll drop a link into the chat                                uh you're very welcome to join that                                we've got nearly                                                      to those talks                                and later this year we're evening                                opening hoping to start running physical                                events again                                fingers crossed uh do keep an eye on the                                haystack website                                and i'll post a link to that into the                                chat as well                                but anyway back to tonight's uh ask me                                anything                                so vector search it's the next big thing                                in search right                                well how do you actually do vector                                search why should you consider using it                                does it work how does it work is it                                fast is it slow might it be better than                                good old text search with tfidf                                what are the pros and cons is it even                                ready for mainstream use yet                                well i'm very happy to say to help                                answer some of these questions and we                                have two luminaries of the search world                                we have dmitri khan of silo ai and my                                colleague max                                irwin from open source connections                                we're going to try and answer these                                questions uh debitry and max i'm going                                to                                ask you to introduce yourselves and also                                maybe as a quick uh                                story about how you got so interested in                                this topic so to meet him maybe                                you can kick us off yeah thanks charlie                                hi everyone                                um glad to be here uh so yes                                i'm dmitry khan go by dima for shirt                                i'm currently a principal ai scientist                                with silo ai                                it's the largest private ai lab in the                                nordics                                and i'm currently leading a team of ai                                scientists and search engineers building                                new experiences for web scale search                                so how did i end up in this topic of                                vector search it has been a hobby topic                                for me since                                august last year well apparently there                                was nothing better to do                                and from the first experiment i have set                                out to evaluate vector search from                                the feasibility and production readiness                                point of view                                and it turned out that both solar and                                elasticsearch support vector search                                well technically for solar i had to take                                a custom query plug-in                                into use and for elasticsearch i came                                across elastic and then implementation                                and another goal of mine was to publish                                my findings                                on medium and this helped me to attract                                attention from the larger community                                leading to testing a commercial                                implementation of vector search on                                custom apu boards                                and according to my most recent                                experiment um                                you know this custom solution was the                                best                                um and the second best was um                                elasticsearch                                so i'm continuing my experimentation in                                this area it's really really                                interesting topic for me fantastic                                thanks steven                                uh max hey everybody i'm max irwin i'm a                                managing consultant at open source                                 connections                                 uh i've been working in the search                                 domain for about                                                      little bit longer                                 i started learning and using nlp in                                                                       my initial area of research was actually                                 knowledge graph extraction                                 and vocabulary extraction                                 um and i still tinker there occasionally                                 but                                 i fell into the natural progression of                                 nlp                                 into uh large language models the the                                 burt stuff                                 in the past three years these days i'm                                 actively working on                                 working with clients and trying to bring                                 these models and merge them with the                                 practical tools that we use                                 day-to-day in search technology i'm also                                 writing a couple chapters                                 for the book ai powered search by trade                                 ranger with doug turnbull                                 my chapters are about using large                                 language models with vector search for                                 autocomplete semantic search and                                 question answering                                 i'm focused specifically again on                                 practical tooling and use and the use                                 cases for practitioners                                 and trying to bring all this cool stuff                                 that happens in                                 ivy ivory towers of academia and google                                 and bing into the hands of just us                                 regular folks                                 who are trying to ship ship smaller                                 products day to day                                 fantastic thanks max so the way this is                                 going to work                                 um you can submit questions on vector                                 search for dimitri max                                 in the in the usual fashion in the chat                                 um                                 but we also we thought we'd uh get ahead                                 of ourselves a little and we asked the                                 community                                 a couple weeks ago to send us some                                 questions to get us kicked off and uh                                 maybe to inspire some of your questions                                 so we're going to start with those um                                 hopefully this uh this will be useful uh                                 so we're going to kick off with our                                 first question                                 and uh forgive me i may have to read                                 this from the document because it's                                 complicated                                 uh our first question um and i'm sorry                                 we don't have uh                                 the people who ask these questions                                 written down here but maybe you'll                                 recognize them yourself                                 um a lot of machine learning                                 applications use the                                 face of vice and noi or an nms lib                                 behind a simple web service for                                 approximate nearest neighbor retrieval                                 for example in recommender systems this                                 works well for simple applications                                 but when efficient filtering is required                                 it seems you need to take the leap to a                                 fully fledged search system                                 elasticsearch vesper etc                                 do you think there's an unserviced niche                                 for a face or vice plus filter tool                                 or do you think the additional benefits                                 of a search system like best                                 vespa pays for the additional complexity                                 it brings i'm gonna ask                                 this to the demon oh yeah thank you                                 um well if you are in the elastics                                 search world as i am uh you have two                                 options                                 so um i already mentioned the elastic uh                                 nn plugin                                 it basically implements an lsh                                 locality sensitive hashing algorithm and                                 then if you want to                                 live dangerously you can also go and                                 check out open distro and                                 they implement like a graph method um                                 and it's basically like offhip                                 uh so it builds like uh it's implemented                                 in c plus plus                                 and um elastic and then plugin supports                                 free                                 filtering so you can it's it's it's a                                 it's a typical use case i would say in                                 many search engines when you have a                                 number of you know                                 parameters that you want to filter your                                 search down                                 first and then you will run an a n                                 algorithm on top of that                                 i'd say whichever methods you choose you                                 need to                                 carefully select the hyper parameters uh                                 that each of these algorithms um you                                 know offer                                 in order to bring the best you know                                 performance in terms of indexing speed                                 versus recall versus like memory                                 consumed                                 during indexing and during search and                                 i'd say um at least according to the                                 papers um                                 you know the the graph method the                                 hierarchical                                 navigable small world graph method                                 scales well to                                 uh multi-core architectures and it has                                 like a bunch of heuristics there as well                                 to avoid like local minima                                 when it builds the graph and it builds a                                 well-connected graph as well                                 for like really large set of nodes                                 um but you know like if you go back to                                 the scene                                 building a graph for each segment might                                 become                                 super expensive and so you should                                 consider merging segments                                 down into one segment before uh serving                                 queries                                 um and so generally i think combining                                 filtering with an a n in one single you                                 know pass                                 is is a wise decision because you know                                 if you                                 offer like a multi-step retrieval where                                 you will like                                 first retrieve something then filter                                 down and then                                 you know re-rank now this will this will                                 likely suffer from low speed                                 or low recall of both so so i think                                 combining this into one single phase is                                 really nice and                                 and wise solution max what do you think                                 uh i think that um yes to both i think                                 there's a there is a                                 openness for a niche in the face plus                                 filter                                 um and i uh but i think that there are                                 you know huge things that elasticsearch                                 and vespa                                 for example bring to the table so if                                 you're going to if you're going to build                                 something on top of for example nms lab                                 or face or another vector search uh                                 library                                 you're you're basically doing the same                                 thing as if you were going to start                                 building a search engine off of lucien                                 you can do it but you're going to miss                                 out on all the things that we take for                                 granted with devops and                                 configurability and deployment and                                 sharding replication and all that stuff                                 um so you probably shouldn't roll your                                 own                                 like that and chuck it into production                                 you're going to have a very                                 very hard time with that um                                 zema already mentioned you know the                                 stuff that elastic is working on in some                                 areas there                                 there are some new players that are                                 coming out like gina ai we bb-                                         pinecone are a couple examples that are                                 trying to                                 fill that niche um but those are                                 you know the they're newer they're                                 startups they're uh                                 there's it is it is risky if you want to                                 build some you know an existing                                 big product on top of one of those newer                                 systems                                 um you can check out vespa which is uh                                 definitely the mature product in this                                 space but i think there are a lot of                                 a lot of options you can look at and                                 consider but definitely do the research                                 and make an informed decision                                 fantastic i will mention actually we've                                 had a couple of these vector search                                 engines uh presenting at haystack live                                 so you can go back and check those out                                 they're on our youtube channel                                 um so i'm going to move on to the next                                 question                                 sometimes information is encoded in the                                 language people use                                 i mean layman's terms for layman's                                 content or professional terms                                 professional content                                 so in medicine you might have very                                 different results for acute myocardial                                 infarction and heart attack                                 how do you model these differences as                                 input for a language model                                 um but all are vectors not the answer                                 here for where there are domains where                                 there's information                                 in the meaning but also in the terms uh                                 max do you want to kick us off on this                                 one                                 yeah so this is this is the classic nlp                                 vocabulary mismatch problem but not even                                 not even nlp just the search vocabulary                                 mismatch problem you have a corpus                                 of text that contains one uh                                 one type of language and then you have                                 people searching using a different type                                 of language                                 um there are a couple things here so                                 first of all with vector search you know                                 it's not like this                                 magic thing that you're just going to                                 throw it out there and replace                                 everything that you're doing                                 you know you there are a lot of tools                                 that you can use that we've been using                                 for years                                 um and traditionally this has been                                 solved with synonyms and knowledge                                 graphs right so you can you can do a map                                 so if you see a term that's not in your                                 corpus you can map to the                                 to the language that's in your in your                                 corpus and in your index                                 um there are                                 in terms of bringing this stuff into                                 large language models you can try some                                 hacks of                                 you know fine-tuning by adding                                 additional content                                 to your model that contains uh the                                 language that you want to include                                 but no matter what the the large                                 language model was                                 was trained on an initial vocabulary um                                 and that vocabulary is limited so in                                 invert you have like word pieces and the                                 word pieces are like                                                                                                  if your language deviates from that                                 significantly then even fine tuning may                                 not really help that much                                 um and you can try training your own                                 model and setting your own vocabulary                                 with the merged                                 vocab set and merge content set but                                 that's you know                                 expensive and typically out of the reach                                 for most teams                                 um but you know if if you have the                                 resources                                 uh you know you can you can try that and                                 you know as a hypothesis and test and                                 see how it                                 plays out diva what's your view on this                                 one                                 yeah um i think it's kind of cool when                                 you throw like a                                 bird model for instance at search and                                 you type mathematics and it tells you                                 you know geometry or linear algebra in                                 response                                 it's kind of all cool and fancy but i                                 think when it comes you know to a                                 specific domain                                 you know like financial or healthcare                                 whatever you have                                 i don't think it will capture it so                                 easily and so                                 i agree with max there like you you                                 really need to fine-tune your model                                 uh on the data which might be super                                 expensive as well depending on the size                                 of your corpora                                 uh but at the same time do you really                                 want to go and attack that problem                                 from from the you know large scale model                                 or do you want to just go and configure                                 that                                 old-fashioned dictionary which will work                                 quite well because                                 it's a controlled way you know to offer                                 this experience to your users                                 and and why why to pay so much uh you                                 know money to train a model when you                                 don't see an exact                                 application for it and um yeah i mean                                 i think we will also cover some topics                                 in the future                                 during today but like also establish a                                 baseline for your search                                 like know how how it performs now before                                 you venture into                                 into vector model                                 very sensible uh find try the stuff that                                 you know works before you try the stuff                                 that you don't know if it works                                 um so our next question um                                 somebody's noticed that uh instagram                                 music uses some kind of language model                                 now                                 and if you search for a capitan the                                 french word for captain                                 to find french songs that are called                                 capitaine uh english                                 songs about captains are actually not                                 relevant                                 how do we avoid losing the information                                 contained in the exact words when we                                 search with                                 with meaning as you might have with a                                 vector                                 to me                                 yeah um so actually um                                 as a matter of fact i i'm building uh                                 with my team like a                                 multilingual uh search engine                                 and um we basically have like                                 independent indices for different                                 languages                                 and so when query comes in we do our                                 best to detect a language and so                                 then we will like send the query into                                 the specific                                 index so there is like a high likelihood                                 that                                 it will capture uh the semantics of what                                 you need                                 even even like without vector search um                                 but other than that i think if you if                                 you already implemented like vector                                 search give users                                 control in the in in your user interface                                 like if they                                 if the if they don't agree with the                                 results and they clearly see that search                                 engine didn't nail it                                 you know just give them tools to go back                                 to like old-fashioned lexical                                 uh search with with exact match so                                 that's what i would recommend and i                                 guess you could also                                 try some things like language detection                                 um                                 yeah max what do you think                                 yeah i think uh the important lesson is                                 that                                 uh don't don't just throw away your                                 existing search stack                                 um and uh replace it with with vector                                 search right away you know it's it's                                 it's another uh it's another feature                                 that you would use                                 um so when somebody and and it's it's                                 important to take a step back and think                                 of the the problems that your                                 users have the information needs that                                 your users have so if                                 somebody approaches your search bar and                                 they search for something in quotes or                                 they're looking for an exact term                                 give give them what what they want you                                 know people have been trained on                                 keyword search since like the early                                     so there's a lot of                                 cultural uh cultural stuff that's                                 embedded in just searching for                                 nouns and not providing any other                                 language so                                 when that happens don't don't throw out                                 the ability to do the exact match                                 um and you know                                 do additional things you know use use                                 diversity of search results you know                                 do some federation maybe do some stuff                                 to bring in                                 other things so you get both the best of                                 both worlds you get the exact matching                                 where people have very very fine control                                 over what they're retrieving                                 um and then you also get that that juicy                                 semantic meaning                                 uh relationship from vector search um                                 and combine the two for uh for a better                                 experience                                 fantastic so um while we're um                                 uh asking these pre-canned questions uh                                 do remember to submit your own questions                                 using the the questions tab on the right                                 of this presentation as you're watching                                 us                                 and we'll ask our experts here um                                 i've got a a quick question i'm going to                                 answer myself actually                                 somebody said they have experience of                                 search and keyword search and building                                 taxonomies                                 and they find it hard to work in these                                 fields um                                 i will recommend relevant slack which uh                                 i'll drop a link into the chat                                 and there's a jobs channel there so if                                 you want to do that maybe go on to                                 working in some of the more advanced                                 fields like vector search                                 that's a good place to start so our next                                 submitted question                                 um i'll have to read this one quickly uh                                 carefully because it's complicated                                 um so we see some patterns that have                                 emerged in the space of dense retrieval                                 both from the research side as well in                                 the industry what are your thoughts in                                 what's coming next                                 in dense retrieval where are things                                 heading and what will people need to do                                 to prepare                                 uh demo do you want to start us on this                                 one oh yeah for sure thanks charlie um                                 i think there is like a lot of                                 development going on in this area                                 so i would um dearly recommend you the                                 beer paper if you haven't read it yet                                 i'll try to share the link later but                                 it's it's it's it's an excellent                                 benchmark                                 you know where they compare you know                                 dense methods against                                 re-ranking methods against lexical uh                                 matching using tf idea for bm                                   and um then you can                                 like this paper establishes like the                                 baseline of understanding what's going                                 on in this area                                 um and then uh they've been like some                                 really uh                                 cool uh papers recently for instance                                 training                                 uh embedding model like on byte level                                 so this helps you to um                                 you know solve some daunting issues with                                 misspelling and                                 and other related problems and then                                 another paper applies four year                                 transform                                 to improve you know the speed of birth                                 and                                 it basically became seven seven times                                 faster                                 with like                                                        i'd say the community is moving ahead on                                 solving this like various issues                                 um with the embeddings because um these                                 players actually do use                                 them in production so in in in the                                 client that i'm working for right now                                 uh we are using uh like advanced methods                                 i will not name it                                 but it basically gives really                                 good results on dcg um                                 and another thing from this beer paper                                 is that                                 um you know like dense dense retrieval                                 methods                                 will not generalize well so like they                                 will beat like                                 bm                                                           um trained on on on the same domain as                                 the queries                                 um and also what's interesting and                                 important to understand is like                                 when you apply vector search in your                                 domain                                 uh depending on the size of the                                 documents you need to pick                                 uh the similarity metric very carefully                                 because for instance cosign uh                                 similarity will favor shorter documents                                 while dot product will favor you know                                 longer documents                                 so maybe you need to have some kind of                                 combination of this                                 you know metrics or like a dynamic                                 selection of the metric depending on the                                 use case                                 or the the query intent um and also like                                 performance of vector search at large                                 you know it's an unsolved                                 issue uh so you need to be looking at                                 a bunch of like model configuration                                 parameters that will work best for you                                 uh and sort of like like that's my                                 personal advice                                 pay less attention to the error margins                                 reported by big players because what                                 works for them might not work for you                                 and i will try to share some some some                                 papers with you later as well so                                 well we're lucky to have uh joe                                 christian burgum and uh josh devins in                                 the channel and they're uh they'll be                                 our link buddies tonight so thank you                                 guys for posting links to the papers                                 uh so you've got more more reading to do                                 max what do you think where are things                                 heading                                 uh yeah great great question so when                                 this                                 stuff first started showing up like you                                 know three years ago                                 two three years ago um it was mostly                                 focused on                                 uh retrieval and matching and ranking                                 you know for near                                 replacing not maybe not replacing but                                 using uh approximate nearest neighbor                                 instead of bm                                                            and ranking                                 uh signals i                                 think that what we've seen recently and                                 the things that you really should                                 prepare yourselves for                                 are how it's this technology and these                                 techniques                                 with vector search are being used for                                 the entire search experience                                 so it's auto complete it's spelling                                 query rewriting                                 it's like snippeting and highlighting                                 you know question answering                                 um recommendations personalization                                 classification and enrichment like all                                 of these aspects that we think about in                                 a full search experience                                 we're seeing um we see that google and                                 bing are now using these                                 day-to-day you can do a web search on                                 either of those engines or any of the                                 engines that use                                 bing uh for example well                                 if you look at the page rendered you can                                 you can tell that it's                                 using this technology um and                                 the way it always follows with this                                 technology is you pay attention what the                                 to what the people with the billions of                                 dollars are doing and                                 sooner or later it's going to fold into                                 into the little fish                                 you know folks like us that are trying                                 to do the day-to-day stuff                                 so i recommend that you focus on the                                 fundamentals                                 of how these technologies work we                                 read the papers and if you don't                                 understand the papers of the map that's                                 fine                                 um get involved with the community play                                 around with the huge face                                 uh stuff try out some collab notebooks                                 that people                                 have published just to get a feel of                                 you know how this technology works and                                 then                                 apply it to apply it to your own                                 problems and explore                                 you know and tinker and see what's                                 possible and see                                 see the problems that you run into just                                 keep yourself fresh with experience                                 because that's you know that's how we                                 learn                                 and that's how we go forward with with                                 all these new technologies and anytime                                 something comes up                                 you just got to keep playing with it and                                 the state of the art the soda world                                 we're we'll just keep pushing forward                                 and the community will just keep pushing                                 forward just                                 you know follow what's going on um                                 follow the community and                                 and see what interests you and learn                                 where you feel you have gaps                                 thanks max so we've got a question                                 actually submitted uh online i'm going                                 to                                 to wedge it in here uh while we work                                 through our pre uh                                 our pre-can questions um so i                                 somebody asks um isn't the                                 aforementioned pre-filtering                                 counter-intuitive at least for                                 e-commerce                                 cannot we cannot know beforehand for                                 unregistered customers whether they want                                 to filter by color or price range                                 now do we know what that refers to in                                 our previous conversation                                 um i might need a bit more color there                                 but                                 it probably refers to our i think the                                 when we were talking about                                 um doing pre-filtering um                                 maybe up for language i guess but yeah                                 i'm not entirely sure                                 yeah i guess if i understand the                                 question right is that um                                 if if we apply f let's say we choose                                 between let's say price and size                                 right so we have two filters in the                                 search engine                                 now we have an option just to run the                                 vector search on                                 everything and then basically you know                                 uh do some                                 post filtering or smart ranking and and                                 maybe show                                 two groups of results you know by size                                 and and by                                 by color whatever it is um but                                 the way i see the way i look at it is                                 that you will be also bound by                                 by speed of light so like when you                                 execute                                 execute a vector search right you you                                 will face                                 uh performance issues there will be like                                 a bottleneck like if you look at my blog                                 post                                 um i will i will share the link as well                                 sorry i don't have access to the chat                                 right now but the thing is that                                 uh it's it's quite expensive it's super                                 expensive it's like                                 more than a second uh what it takes to                                 run one single search so                                 you do want to pre-filter you know the                                 space                                 basically you are entering a new space                                 of your documents right and now you                                 you run your vector search with some                                 similarity metric                                 and you are sort of like searching in                                 that                                 local subspace of your documents is it                                 good experience or not                                 it's up to your ux it's up to what you                                 are delivering                                 uh in the product uh so uh maybe                                 still offer the tools to the user if                                 user disagrees you know with the results                                 and you have some hints there that hey                                 we applied                                 some method that maybe we think it's the                                 best but here are the tools if you                                 disagree go and filter                                 out yourself or maybe don't feel there                                 so                                 that that would be my answer great i                                 hope that answers your question                                 i'm going to skip on to one of our our                                 previous questions here                                 uh because i think that this might cover                                 quite a few uh people's uh                                 requests but content length is an                                 interesting one isn't it uh because                                 obviously you know we know in                                 in text matching content length can                                 affect you know the very weighting of                                 the various uh fields we use in our in                                 our ranking formula but                                 uh where is there a content lens sweet                                 spot where                                 dense vectors have a clear advantage                                 over sparse vectors                                 playing tfidf max                                 uh no there there there is and there                                 isn't                                 um so if you look at you know if you're                                 getting embeddings                                 for text if you look at the model                                 you know the model will be limited by                                 you know you'll have some limitation on                                 the number                                 of tokens that you can pass into the                                 model                                 in one step um and                                 so that that's an upfront limitation of                                 the model                                 and architecture that you choose um                                 there are a lot of efforts now to remove                                 that barrier to to make things longer                                 and longer um i would                                 i would ask the question you know                                 assuming that that there were some                                 if there wasn't any limit uh ask                                 yourself the same question                                 just with bm                                                           do this like                                 and i think in a lot of cases it's                                 important to                                 not not just generalize but take a step                                 back and look                                 at the problem like what does it mean to                                 have a relevant document and a relevant                                 piece of information right we there was                                 a                                 my my colleague um bertrand you know                                 he asked a question you know he had a                                 client who was trying to index a                                 document that was hundreds of megabytes                                 and and                                 you know you're wondering well what is                                 what does that mean to have a relevant                                 hit                                 on a document that's hundreds of                                 megabytes in length you know that could                                 be                                 you can contain like a lot of wikipedia                                 in that                                 you know that's so much knowledge so                                 there's this idea of                                 well how do you carve up                                 the text for what you want for your                                 domain                                 and your customer's needs where do you                                 where do you draw the line                                 are people looking for a specific answer                                 are they looking for a passage                                 are they looking for entire books um or                                 chapters                                 uh and that varies from need to need                                 even                                 you know even even in the domain you                                 know you might have                                 situations where you say okay i'm going                                 to give you the whole thing back or i'm                                 just going to give you this one snippet                                 so in terms of the technology limitation                                 um that exists but even even then like                                 understand how you're cutting stuff up                                 and how                                 you want to surface relevant relevant                                 data                                 and you know vector search there is kind                                 of                                 the app the afterthought it's like okay                                 well i have this similarity function                                 um and i'm just going to apply that and                                 get a score uh                                 to to the texts that i have                                 what do you think demo do you think                                 there's a sweet spot where it on                                 content length uh i think if there is a                                 sweet spot it's definitely before                                     word pieces because                                 all neural you know approaches has have                                 this limit and maybe eventually this                                 will be lifted                                 but at this point if you if you read the                                 paper that i mentioned they actually                                 they actually mentioned this limitation                                 there                                 um but the question is again like do you                                 even need that much                                 um you know like if you take a really                                 long document like max                                 we explained just now i i think if it                                 has like a a really diverse set                                 set up like topics in it like if you                                 have like thousands of pages in that                                 document it's like a copy base from                                 wikipedia or something                                 uh you know imagine clustering this you                                 know let's say you're using                                 uh the graph method and in the graph                                 method you will have like                                 this really big you know what hotspots                                 and then this document will be like                                 connected to a bunch of other documents                                 and                                 does it help your user i'm not sure so                                 what                                 what i would do is probably try to like                                 dissect your document in a number of                                 like meaningful blocks                                 so for instance let's say you have a                                 section which is like                                 about a specific topic or introduction                                 or like whatever                                 the mid part of that document um and                                 then                                 you know you could you could for                                 instance go and index those specific                                 sections in in a separate field and then                                 use bm                                                                   need the vector search there right                                 then another approach is that you could                                 summarize the document then the question                                 is if you have thousands of pages can                                 you actually summarize that document i                                 don't think so                                 like you you will probably need a number                                 of summaries                                 and then you could of course encode that                                 those as vectors using like                                 whatever birth like model or whatever                                 you you would like                                 um so i i would say like step                                 back from from like thinking is that                                 vector search that's going to solve                                 my all of my problems is it bm                                         some                                 some not invented yet method and think                                 about                                 what is in your data like ask your                                 domain experts to annotate those                                 documents so you actually have those                                 building blocks                                 at your hands and you can go and like                                 you know experiment with different                                 methods and                                 have some sensible baseline i think bm                                   is a proven                                 proven baseline at the moment and so you                                 know play off of that                                 that that i think would be my                                 recommendation here                                 great thank you so i'm going to just uh                                 flip to a question from the audience                                 uh we've got it's been it's been highly                                 voted and uh                                 somebody has asked how does hit                                 highlighting work in a vector search                                 world max do you want to take that one                                 oh that's a great question so um the way                                 hit highlighting works is uh                                 so you you have a large language model                                 and it's pre-trained                                 uh you have a pre-trained model um the i                                 i'll i'll talk specifically about the                                 question answering                                 aspect of this because this is a form of                                 hit highlighting for closed domain                                 question answer there's there's                                 have the passage uh                                 the query and the thing that you want to                                 highlight                                 right uh so those three things is what                                 you need for                                 for training and test data to fine-tune                                 your model                                 so it it will learn in the fine-tuning                                 task                                 given this passage and given this query                                 you know                                 what what should i what's the word or                                 words                                 that i should uh present um and                                 highlight                                 um and it doesn't make up text it it                                 always it's                                 it's it basically gives you positioning                                 um which works                                 very similar to highlighting right so                                 you fine-tune                                 this model on um on your task                                 on your data and then you have the model                                 and then when you are using this thing                                 in production                                 um you get your search results back                                 uh from a n or bm                                               and you pass in the passages uh that                                 come back in your results                                 into this other model and then it                                 returns the positioning for you and then                                 you can use                                 highlighting there or you could just                                 call it out and you don't have to                                 highlight it in place you can just say                                 here's your answer                                 right so that's that's pretty much                                  uh how it works i'm trying to remember                                  there's a specific data set uh that's                                  available                                  that it's a it's uh                                  it starts with an s but it's escaping me                                  right now because i'm having a brain                                  freeze while i'm trying to talk and                                  answer questions                                  uh but when i remember i'll i'll i'll                                  chuck it into the chat                                  in the in the breakout session                                  great demo what do you think in                                  highlighting                                  yeah i think it's um it's kind of                                  challenging because                                  um if you if you sort of like um                                  if you're just entering this area let's                                  say you as i gave you an example                                  very simple right you you type                                  mathematics and it gives you like                                  linear algebra like can you go and                                  highlight linear algebra having                                  mathematics now                                  so you need to have some way of                                  knowing the distance right so like okay                                  between                                  um mathematics and linear algebra there                                  is like the smallest distance                                  and the model should tell you that so it                                  like you could you could apply like a                                  layer in the                                  in the model let's say let's say                                  attention layer and then see okay                                  which of these words correlate best with                                  the query right                                  and this is what what i think max                                  alluded to as well                                  so let's say you know document is                                  returned                                  and there are like a number of passages                                  there that highly correlate                                  you know with the queries so you can go                                  and highlight them but the question is                                  should you highlight the whole passage                                  or can you actually build a method that                                  will actually                                  highlight individual most prominent                                  words that                                  contribute to to answering your question                                  this is what highlighters usually do                                  right when you go to google and you type                                  something                                  it actually highlights you the the                                  actual you know words to pay attention                                  to and i think                                  you can you can apply like an attention                                  layer again                                  i would need to go and double check that                                  but but this is                                  this is the direction in which i would                                  go um as well and i think there are some                                  other methods                                  somebody mentioned to me like um you                                  know                                  decrypting the the vectors back to words                                  and then trying to see the overlap                                  but i'm not sure if it's like shooting                                  from a canon                                  but i think attention layer might might                                  work better so yeah                                  i i did remember the name of the data                                  set it's a squad                                  is the task                                  one of our link buddies has already                                  posted that in the chat absolutely                                  kevin so                                  we've got our um let's uh have a look at                                  one of our                                  our set questions again um                                  and this is an interesting one what a                                  good and bad use cases for vector search                                  and um fema do you want to start us with                                  that one                                  sure um this is actually an interesting                                  question because i was thinking like                                  in principle you can represent any                                  object as a vector the question is                                  do you have a good model to do that you                                  know you could in principle take                                  well it's known that you can take image                                  you can take                                  sound text um maybe even like a virus                                  signature                                  right if you're like in the into                                  antivirus world                                  um then um i still think that                                  it's important to pick the right                                  similarity metric because you know                                  for different objects um they will have                                  different                                  like structure in the vector like let's                                  say it's a dense vector or like you have                                  a sift                                  data structure um they will have                                  different characteristics                                  and so again if you read that bigger                                  paper you will see that different                                  you know models uh will generalize or                                  not generalize so you'll have to retrain                                  it                                  to that specific object and so i think                                  in general                                  you know vector search has like a really                                  wide applicability area and probably                                  that's why we see so many                                  new interesting startups um                                  and open source projects in this in this                                  field                                  but when it comes to like implementing                                  sort of coming to the bad side                                  like if you if you throw like uh some                                  dance vector approach                                  to all of your queries probably                                  you may end up in a situation that users                                  will be like scratching their head and                                  thinking what's going on here like                                  i'm looking for this specific thing and                                  it and it's telling me about some                                  similar thing that i'm not interested in                                  i'm interested in that specific thing                                  and so                                  this is again the great point to step                                  back and think about                                  establishing the baseline for your                                  search engine um                                  i happen to be a committer at cupid                                  uh and so great tool open source                                  use it or use some other tool to                                  establish the baseline                                  you know i'm doing it with my team                                  currently with a number of                                  for a number of languages and you will                                  learn a ton from from establishing the                                  baseline                                  trust me like ranging from                                  hey you have some problems in the                                  formatting of the document                                  you know to source uh authority                                  or you know freshness of some of the                                  documents and so on                                  so work with your domain experts there                                  and then consider any of the                                  um you know ranking methods                                  like even ltr learning to rank as a                                  black box okay i have the baseline                                  now i can go and apply uh you know                                  different methods one by one                                  and see which one wins and so what other                                  team is doing in our company is that                                  they systematically train uh dance                                  retrieval methods                                  tune some parameters and they have the                                  leaderboard                                  of all of those um with respect to                                  a specific score like gcg on a and dcg                                  and then they also can compute the same                                  metrics on their rival                                  um you know on their rivals and                                  and then that's like a sweet spot where                                  you want to be                                  max what do you think on this one good                                  or bad use cases for vector search                                  yeah um so i'll tell you                                  the the biggest leap that i think                                  most people are going to have to make                                  into vector search mentally                                  is that you know if you come from an                                  inverted index                                  you're very used to a certain way of                                  thinking where                                  you have uh you have your index of a set                                  number of terms and maybe you have some                                  synonyms and then                                  you basically do a match and a lookup                                  in that index directly and then you use                                  bm                                     for similarity scoring with approximate                                  nearest neighbor searching                                  and vector searching it's kind of like                                  this                                  leap into there's this one step that you                                  do for both                                  it's like you get stuff back that                                  matches                                  and then there's a score behind it all                                  in all at once right                                  um so that's i i think that                                  if you get over that                                  that first hump of switching your brain                                  into that                                  i think a lot of the use cases uh                                  good or bad may come naturally when                                  you're thinking about how to apply this                                  into your domain and i can't                                  unfortunately i can't really tell your                                  brain how to make that switch it comes                                  with a lot of playing around and                                  and and learning and figuring it out um                                  but i'll i'll give you some do's and                                  don'ts                                  uh instead of uh you know good and bad                                  use cases because i think there's a                                  whole bunch of stuff that you can try                                  and do and you may it may end up                                  successful                                  it's really hard to answer that                                  generally so i'll say like some some                                  don'ts is                                  you know when you have vectors that come                                  from multiple passages                                  don't try to just average them together                                  uh because you you know                                  to try to increase performance or reduce                                  the space                                  costs that you have that that's not                                  going to work don't try to do that stuff                                  don't use a pre-trained model without                                  first understanding                                  what it was trained on uh and the                                  vocabulary that it contains                                  and then also its limitations compared                                  to your domain don't just like                                  pick a random pre-trained model and be                                  like oh this is what they used in this                                  look notebook i'm going to use this one                                  right under understand the model that                                  you're choosing                                  and using and then and then fine tune it                                  and don't don't just use vector                                  similarity as your only feature                                  for ranking you know you have a lot of                                  stuff that you can use                                  you know we talk about uh                                  search you know when you're surfacing                                  results you don't just use bm                                            bm                                                                     like oh the recency of the date                                  uh you know the the rating on the                                  product and you know all kinds of other                                  features                                  that combine to make up total relevance                                  uh for a document when                                  when somebody's searching for an                                  information need um                                  so that's some stuff into into some dots                                  some do's is like                                  do split up your documents into good                                  passages                                  in the size that fits your architecture                                  your domain your use cases                                  um and then you know you can investigate                                  instead of averaging you can look at                                  things like distillation                                  uh summarization uh pca other other                                  techniques                                  quantization to try to get the                                  performance                                  uh there because you can't just dump raw                                  vectors                                  right now into your index for entire                                  documents                                  you just your compute and your disk will                                  hate you                                  and your ram will hate you for that so                                  you you will have to find a way                                  to get to get there um                                  learn and fine-tune the models i think                                  this is the most                                  probably the most important thing when                                  you are solving a problem for your                                  domain                                  um the use cases for your product                                  will require you to                                  figure out exactly what you want what                                  your starting point                                  will be and how you tune it for the task                                  at hand                                  so you may have a a bunch of a bunch of                                  uk use cases that you want to use this                                  technology for                                  i mentioned some before like                                  autocomplete spelling query writing you                                  can you can do a whole bunch of things                                  so so understand that                                  these may all require different models                                  and different                                  architectures for your need and                                  different fine-tuning tasks                                  and yeah use use this as an additional                                  features and as an additive thing for                                  your experience                                  and your ranking and your retrieval um                                  it's it's gonna be it's going to be                                  additive it's not going to be like i'm                                  going to replace the whole thing                                  right now with vector search uh it's                                  it's another                                  extremely powerful feature uh for search                                  um and use what you know and have                                  learned                                  already and and combine it and play                                  around with it and                                  you know and see how it folds naturally                                  into your stack and into your domain                                  thanks max so i'm just going to jump to                                  it one of the questions submitted by the                                  audience here                                  um we've got a question what about                                  active learning to improve vector search                                  meaning tagging the user inputs and then                                  updating or filtering the vectors                                  what do you think you know yeah it's a                                  great question                                  i think uh you can do that uh                                  so there are like uh if you if you enter                                  dance dance um                                  retrieval methods then there i actually                                  don't remember the method name                                  uh but all everything is in the paper um                                  so one method is that you can combine um                                  the document with the queries that                                  you know naturally match this this                                  document and so you will                                  bubble up the prominence of the of that                                  document during search and so                                  in principle i'm thinking why not you                                  can apply an active learning                                  uh you know approach here where                                  you will identify the the relevant                                  uh queries for a specific document you                                  will need to build some system for that                                  i guess you could use cupid i guess                                  and so you would go and update the                                  the document vector with those new                                  queries                                  and so next time around users are                                  searching                                  with the queries like this uh you will                                  have those documents bubbling up                                  um to the top right so in principle yes                                  i think                                  yes and you should actually in general i                                  like the idea                                  of uh you know seeing your search engine                                  as an evolving model as an evolving                                  organism where you should you should                                  think creatively like what else can we                                  do                                  to actually establish this pipeline of                                  um ideas and improvements because                                  uh it like i've seen cases when                                  you know let's say we apply a specific                                  um                                  vector space model like in principle                                  bm                                          and then we just stop looking forward we                                  just                                  you know we just think okay everything                                  is in the data                                  but it's not true you like you will                                  notice that                                  in the production you will you will see                                  decline in ctr                                  or you will see decline like in what we                                  call exposure                                  which is probably not not like a common                                  metric used but it's basically how often                                  do we show                                  the results from our search engine so if                                  you see any decline there                                  like take those queries and                                  you know throw them into cupid or some                                  other system where you can                                  investigate them with magnifying glass                                  and then                                  looking at all the ways you can encode                                  additional signal from those                                  from those queries and documents into                                  your model                                  i hope that answers the question but                                  yeah what do you think max                                  i i totally agree                                  um i i just have one very important                                  point that i think you need to                                  consider when doing active learning is                                  you need to be very careful of bias                                  um and thinking about who as                                  as a model uh prompt has presented to                                  you of whether it's good or bad and then                                  you want to update the model                                  based on your reaction it's very easy to                                  just kind of quit very quickly go                                  through it and forget                                  that you are a subjective and biased                                  individual um everybody is in their own                                  way                                  and if you are taking even uh                                  crowdsourced data uh from this or or                                  data from                                  uh customers or or users of your product                                  to do active learning there's there's                                  gonna be bias there                                  also so there are teams that are really                                  good with this who are used to                                  dealing with this with learning to rank                                  um data sets                                  um but if you're new to this and you                                  know and                                  you you're used to kind of capturing                                  judgments at a small scale                                  try to remember that you probably want                                  to get more than one                                  opinion on things and you want to                                  understand                                  consensus and disagreement and have                                  discussions about them                                  um instead of just you as one person                                  like update model update model update                                  model because it's just gonna                                  you're gonna over fit to your own to                                  your own uh desires and wishes                                  um and that may drift uh from                                  what uh what your users actually want                                  maybe i also wanted to add and this is                                  like a topic dear to my heart                                  try to release more frequently because                                  if you if you spend                                  a bunch of time thinking about oh i have                                  this cool idea                                  you know i just need another couple of                                  weeks to to polish it                                  by the time you release it you know the                                  season might be a way and you just will                                  not nail it                                  and we see some interesting use case in                                  our search engine right now when                                  you know ctr all of a sudden went down                                  for a specific language                                  but we we've done no release and we are                                  like just figuring out what's going on                                  here                                  right so when you start work from that                                  angle like and go backwards to your                                  model                                  like there is like a long path there and                                  and you can generate a bunch of ideas                                  what you can try                                  great thank you okay so we've got a                                  doozy of a question coming up next we're                                  from the submitted by the uh the                                  audience and i'm wondering who this are                                  that this                                  is um so i'll read this out it's a long                                  one                                  in order to make vector search                                  performance an approximate nearest                                  neighbor approach is typically applied                                  so leucine has hmsw says vaspa                                  given that these a n techniques                                  essentially partition the vector space                                  into a smaller neighborhood                                  it seems natural to shard large indexes                                  by                                  a m neighborhood so that queries could                                  be routed to specific neighborhoods on                                  specific nodes                                  and then we can obviously use for                                  performance neighborhoods with more                                  queries could have more replicas handle                                  nodes                                  this will prevent the entire index from                                  being needed to be searched in every                                  query                                  could this be useful for enormous                                  indexes such as for an open web search                                  engine                                  and what are your thoughts and how                                  feasible this would be to implement with                                  solar vesper elastic                                  et cetera using hmsw or similar                                  algorithms                                  so that's a bit of a mouthful um who                                  wants to take that one first                                  uh maybe i'll maybe i'll take a a stab                                  at it so i                                  i recently reread what won uh one                                  hnsw paper um                                  uh last week uh and i                                  because i really want to understand how                                  this thing works and it's one of those                                  things where it's                                  casually offhand mentioned in the paper                                  of                                  well this thing is you can shard this                                  um i don't think using those exact words                                  but due to the nature of navigable small                                  world                                  and and neighborhoods you can                                  effectively                                  uh shard and split this out uh and and                                  then it'll it'll work                                  like that's how it's kind of presented                                  in the paper um but there's no like                                  implementation detail                                  of course uh so i think that                                  you definitely are gonna have to do this                                  um it is                                  it is possible i don't know the                                  techniques to do it but                                  and i don't know how vespa works i don't                                  know how uh                                  because lucine um lucina has asian sw                                  but solar and elastic are going to be                                  responsible for the sharding of the                                  lucian indices                                  so i think that that's probably a huge                                  barrier                                  to getting this stuff into solar and                                  elastic i don't know if josh is working                                  on this right now for elastic                                  um josh and steam or                                  i think that joe christian might have                                  some comments here about how it works in                                  vespa                                  um but it should be possible and i think                                  it's going to be absolutely necessary                                  uh and i'm hoping that you know i'm just                                  kind of sitting around waiting for                                  uh lucene                                                           into elastic and solar and all this                                  stuff to magically appear i know that's                                  not gonna happen it requires                                  a lot of hard work from a lot of                                  hard-working people                                  um but i i think this is absolutely                                  necessary                                  okay what do you think dima you're                                  working on a big search engine                                  yes uh actually think about tf idf and                                  bm                                    when you have let's say                                             and your query comes in you have some                                  sort of router component which will                                  forward it to independent charts                                  it will it will search for the document                                  score them                                  and then return you let's say top and                                  from each chart                                  ah these uh you know scores compatible                                  i have a strong conviction that they are                                  not why because                                  every shard will have their own like                                  term                                  level statistics um document length                                  which is like local to that chart and                                  there are some solutions which you can                                  for instance                                  you know where you can build a global                                  idea                                  right so um idf which will be                                  like globally updatable like uh                                  distributed cache whatever and                                  probably you will run into some race                                  conditions there i'm pretty sure                                  but but there are ways to attack it                                  right so i think the same exactly same                                  problem                                  exists in in our traditional                                  you know lovely bm                                                if you enter into the graph search all                                  into like um                                  uh clustered search if you pick that                                  paper                                  the hierarchical small world navigable                                  small world graph it's so mouthful that                                  i keep keep reminding myself what's the                                  order of letters there                                  but that method actually explicitly                                  states in the paper                                  that it's not compatible with the uh                                  distributed search and they do mention                                  you know like this famous mathematicians                                  from                                               that proof is obvious and then they die                                  and then like                                                           tries to prove that that                                  theorem and then they you know die                                  almost as well                                  so i think and then they say actually                                  that                                  the previous incarnation of that                                  algorithm when you remove the age                                  so it's not hierarchical it's just a                                  navigable                                  small world graph that's a perfect match                                  for the distributed search engine that's                                  what they say                                  but again you need to go and check it                                  for yourself i don't think that                                  you should easily trust everything                                  that's written in papers                                  you know go and try it for yourself yeah                                  there were a lot of typos in that paper                                  so that should be                                  yeah so what i'm taking away from this                                  is people in the street don't always                                  trust people in academia                                  and also that some of these these areas                                  of mass are effectively cursed                                  and you should navigate them with a                                  great deal of caution                                  it seems that people die if you get too                                  close i'm a bit worried by this                                  cursed mathematics i love that idea okay                                  well we've got um                                  another few minutes we're actually going                                  to uh run on a little                                  uh later than our published end date end                                  time                                  today because we're the last session of                                  the day so we're not going to be jumping                                  into the breakout room                                  you're welcome to stay with us we'd love                                  you to stay with us we're gonna try and                                  get through                                  a few more questions maybe for an extra                                                                                                         but i must just for completeness mention                                  that at the same time                                  we have the workshop uh on digital and                                  ethics running in                                  the machine house and of course there's                                  a spatial lounge                                  for um socializing outside the sessions                                  but if you're gonna stay with us we've                                  got some more questions to get through                                  so let's see what else we have um                                  let's have a look we've got well there's                                  a quick one here maybe you can answer                                  quite quickly how could gpus be                                  leveraged to improve the vector scoring                                  calculations                                  and i'm going to ask that to dima                                  because i believe you looked at this is                                  the gsi                                  um application you looked at those using                                  a gpu isn't it                                  yeah gsi is using so they've built their                                  own custom                                  apu board so it's like associative                                  processing unit so it's not cpu it's not                                  gpu it's like                                  something they're custom you know                                  implementation                                  and um it's it's particularly friendly                                  with                                  matrix you know multiplication and                                  whatnot                                  so so basically um                                  the the the method i think i think they                                  have a bunch of like um                                  uh weight there with the ram so they use                                  a lot of ram and i'm not sure exactly                                  how this board is structured but                                  basically they can even ship that board                                  to you and you can try it um                                  but basically that was the fastest                                  method that i have seen and and i                                  benchmarked you know if you                                  look into my blog post i think                                  the scale of difference was like                                     milliseconds                                  versus like                                                              elastic search uh vector search                                  so that's like a huge huge difference                                  but then again                                  in order in order to to use that method                                  i had to                                  and and i'm sure the team is going to                                  iterate on this but i had to prepare                                  like                                  a numpy array that i would um and it                                  took me like four days to                                  to embed um one million documents                                  in into that space and then ship that                                  array and so they uploaded that                                  it didn't take too long to index and                                  then it was super super fast                                  um but then again this is kind of like a                                  hybrid approach                                  to my sense because you can you can run                                  it on premise you'll have to pay                                  right uh but but then can you actually                                  emulate something like this without an                                  apu                                  uh and then for the gpus i think the the                                  beer paper as well uh mentions something                                  if                                  i remember correctly that you can                                  actually use gpus to                                  to speed up uh your search engine for                                  the vector                                  yeah there was a                                  it's funny that this question was asked                                  because i i haven't tried it yet                                  but two days ago i stumbled across a                                  repo in github                                  uh called cu hnsw                                  which has been you know it looks like                                  it's a couple months of                                  coding that claims to use cuda with hmsw                                  but again i haven't installed it or                                  played with it uh                                  but it's something to look into if you                                  want to just tinker                                  and you have a nvidia card that's                                  capable                                  right well then drop the link into the                                  uh into the chat if you have it                                  i don't have access to the chat i'll                                  drop it into the into our chat charlie                                  and then you can relay it into uh                                  there we go through the magic of copy                                  and paste                                  i shall put it in for everyone no no                                  affiliation i just found this thing and                                  i started to say i'm gonna look at this                                  later                                  which we all know when get upstars that                                  never happens um                                  but but yeah if you're really interested                                  you can go                                  try to install it and see if you can get                                  stuff indexed okay                                  so um we've got a a quick question here                                  i'm going to ask                                  about um                                  actually uh i'm not sure this is vector                                  search related                                  um somebody is asked about seasonality                                  and fine tuning how can we                                  infer when to update uh maybe a small                                  decrease in click metrics would be                                  enough or is there a better way for this                                  kind of problem                                  uh do you wanna ask does that apply to                                  vector search is that                                  referring back to something earlier                                  actually i think it applies to                                  um embedding at large um                                  i i will try to give you that paper but                                  i don't remember from top of my head                                  basically the paper was dealing with                                  seasonality change                                  by you know um basically you can compute                                  like a                                  a stable date range with which you can                                  tag the terms and then you embed them                                  and so the embedding will also have the                                  term as well as the date                                  the date range right and and then you                                  know when you search for instance you                                  can also account for like                                  okay what what season i am in you can                                  definitely know that                                  which which date range you fall in and                                  then you attach that to your term                                  it almost sounds like payload payload                                  based search if you know what i mean                                  right so let's say you have a term and                                  then you can add some characteristics to                                  it                                  and then during the search you can you                                  can pre-filter                                  or like filter the terms that fall into                                  the                                  the specific um category set let's say                                  uh part of speech tag or something else                                  that you might encode there                                  so something similar so that paper is                                  really interesting                                  i don't know if they have a practical                                  implementation i think the code is on                                  github                                  so if you're interested i i will try to                                  to find that paper and post it as well                                  yeah                                  okay um                                  so uh let's go on to our next question                                  from the audience here                                  um so we talked a bit about a n coming                                  into                                  uh lucy nine and this is an interesting                                  question will this be an                                  easy to use feature when it's exposed in                                  elastic search and solar                                  do you think it'll be easy to use for                                  people once they can access it that way                                  max what do you think                                  um i honestly think you know                                  the both of the the the elastic team                                  and the solar community uh write amazing                                  software                                  right and i think that                                  it will definitely be usable um and it                                  should be straightforward to use                                  because at the heart of it the stuff                                  from from a user perspective uh                                  isn't really that complicated you know                                  you can go and you can install nms live                                  right now                                  in index stuff in python and like three                                  lines of code and then you can query it                                  in like a couple lines of code i think                                  the hard part                                  really is getting the vectors and and                                  understanding what you're matching on                                  um so i think that once once this is                                  available uh in solar inelastic                                  um i imagine that it'll be pretty                                  straightforward it'll probably just be                                  like you know you're gonna have a dense                                  vector field                                  and you're gonna specify the analyzer                                  and the similarity function                                  and you'll be able to you'll be able to                                  query it                                  i don't see it being much more difficult                                  than that i think the                                  the hard part is the hard stuff                                  certainly rests on the shoulders of the                                  implementation teams                                  at elasticsearch and and in the solar                                  community                                  who have to think about all the crazy                                  stuff like sharding and                                  performance and memory and heap and all                                  that                                  crazy stuff that you know users of the                                  tools don't                                  necessarily have to worry about right                                  away um but that's something that                                  is gonna also fold into                                  your operations in production of like                                  well                                  how much memory do i give the jvm if i'm                                  using dense vector search                                  um how how should i what's my sharing                                  strategy going to look like uh                                  is this going to impact you know my uh                                  my high availability and disaster                                  recovery strategies                                  you know is it going to be is it going                                  to make my index huge                                  and my memory really big so you know i'm                                  going to have to                                  really not worry about my budget i think                                  those are probably product level                                  questions that are going to come into                                  play                                  and we'll see when we can actually                                  benchmark                                  when this technology is available to us                                  in these engines and we can start                                  indexing stuff and seeing how to use it                                  what do you think timo i mean you've                                  tried these things in your blog posts                                  uh series uh do you think once once it's                                  uh                                  it's going to be easy to use from a                                  practical sense um i like                                  the implementation when it stays inside                                  the gvm if you're on gvm                                  because if you go off here what what                                  will happen is that it's so hard to                                  measure                                  like how much memory you should give it                                  and and usually these algorithms are                                  super greedy                                  actually for your information h and sw                                  algorithm is very greedy on ram                                  you do have some hyper parameters that                                  you can tune and kind of lower the                                  the ram consumption at the expense of                                  like                                  uh the quality of the index um                                  so that's the indexing trend trade-off                                  and then you have the search trade-off                                  where you can also alter some hyper                                  parameters there                                  so but but having said that i still like                                  the idea of let's say                                  if i'm on jvm give me every tool that's                                  on jvm i don't want to go off hip                                  even though it sounds sexy to go of                                  heave but                                  i don't think it's it's super practical                                  and again maybe i will be proven wrong                                  in some time but for now i i would                                  choose this approach versus you know                                  let's say open distro                                  which offers you off-heap implementation                                  of hmsw because i've run                                  into a number of issues i don't want to                                  say that i i'm like um                                  dissatisfied with open distro open                                  digital is a nice                                  you know great way of you know solving a                                  bunch of issues                                  uh and also like scaling your system and                                  also elastic                                  itself elasticsearch you know the                                  vanilla one doesn't have                                  uh any any uh you know algorithm                                  implemented yet                                  um but again um                                  i just well maybe it's just tough luck                                  but i wasn't able to index one million                                  vectors with open distro it just it just                                  crashed on me                                  really really badly and i spent multiple                                  days figuring out what's going on                                  and maybe i just need to give it like a                                  really large machine                                  and then just so like throw money at the                                  problem right                                  which i don't want to do so um                                  another thing uh the practical                                  perspective and i think max mentioned                                  that                                  when you will index you know when you                                  compete in beddings don't choose                                  uh high dimensionality because it's it's                                  so it's so appealing to choose like                                  you know                                                                  uncased vert model and hope for the best                                  the problem is that the index size will                                  be super huge if you look at the bare                                  paper                                  and you compare the uh bm                                              the dense                                  uh dense vectors uh that dance                                  model the difference was yeah it's here                                  i made it i made a note the difference                                  is that                                  uh the colbert model is like                                                                                                                                               that's like huge difference like in                                  terms of cost in terms of memory in                                  terms of retrieval                                  and remember listen like it tries its                                  best to cache the fields                                  but like will it be working okay for                                  super large segments and super large                                  dictionaries probably not so like                                  be careful there                                  yes yes well you can always uh solve                                  problems with                                  more memory obviously um                                  so uh we're coming to the end of our                                  time slot here and                                  uh i want to just just round us off here                                  um i'm afraid we haven't got to                                  everyone's questions in the chat here we                                  didn't get to everyone's questions from                                  our pre-submitted list                                  but uh i do want to thank everybody who                                  submitted a question                                  and uh i hope you've uh hope you've got                                  yours answered                                  um secondly uh huge thanks to both max                                  and dima for uh working so hard on this                                  we've done quite a lot of work ahead                                  ahead of time to make sure we give you                                  some really quality content here so                                  thank you both                                  you
YouTube URL: https://www.youtube.com/watch?v=blFe2yOD1WA


