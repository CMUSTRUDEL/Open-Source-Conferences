Title: Gunnar Morling & Hans-Peter Grahsl – Change Data Streaming Patterns in Distributed Systems
Publication date: 2021-06-30
Playlist: Berlin Buzzwords 2021 #bbuzz
Description: 
	Microservices are one of the big trends in software engineering of the last few years; organising business functionality in several self-contained, loosely coupled services helps teams to work efficiently, make the most suitable technical decisions, and react quickly to new business requirements.

In this session we'll discuss and showcase how open-source change data capture (CDC) with Debezium can help developers with typical challenges they often face when working on microservices. Come and join us to learn how to:

* Employ the outbox pattern for reliable, eventually consistent data exchange between microservices, without incurring unsafe dual writes or tight coupling

* Gradually extract microservices from existing monolithic applications, using CDC and the strangler fig pattern

* Coordinate long-running business transactions across multiple services using CDC-based saga orchestration, ensuring such activity gets consistently applied or aborted by all participating services

Speaker:
Gunnar Morling – 
Hans-Peter Grahsl – 

More: https://2021.berlinbuzzwords.de/session/change-data-streaming-patterns-distributed-systems
Captions: 
	                              welcome to this                               session um thank you so much uh for                               having us um                               it's my first time at building buzzwords                               actually and i live in hamburg so it's                               not that far away but for some reason i                               never made it so i'm very happy                               to be here and the idea for this talk                               too is to                                talk about three common challenges which                                we encounter                                in distributed systems or microservices                                and patterns for overcoming                                those challenges and implementing those                                patterns with change data capture                                so in more depth um what can you expect                                i hope you see my slides by the way so                                we are talking ab or we are going to                                talk about three different patterns the                                first would be the                                outbox pattern which allows us to                                exchange messages between microservices                                in a safe way                                then we are going to talk about this                                trailer fig pattern which allows us to                                move                                to microservices coming from a world of                                model of a monolith                                and lastly we are going to talk about                                the saga pattern which allows us                                to um coordinate long-running                                transaction flows                                across multiple services and now when i                                say we i'm not here alone i'm here with                                my good friend hunt peter so who am i i                                work as a software engineer at reddit                                and i'm the lead of the division project                                which is an open source                                implementation of change there capture                                and i have the honor to be here today                                with                                hans peter grazel who is a technical                                trainer at mid economy                                and he also works as an independent                                consultant and                                software engineer so let's get started                                right into it                                um and before actually i dive or i talk                                or before we talk about those                                particular patterns um let me just give                                give you                                briefly an overview of what the change                                data capture is about and what dimension                                is about                                and the idea is real simple essentially                                you have a database and whenever there's                                an insert or an update or a delete um                                well you would like to react to those                                events                                so if there's a new customer created                                purchase order gets updated                                or something gets deleted you would like                                to react to that and well the canonical                                source                                for getting changes from the database is                                the databases transaction log                                each database has a transaction log and                                it's depend only log whenever something                                changes in the database it will append                                an event to this log and this is what                                the bsm uses as the change of end source                                so it taps into the transaction log                                extracts the changes and sends those                                events to consumers                                and typically this is done by apache                                kafka which allows us to have some nice                                decoupling                                between the event source which would be                                the database and the museum                                and the event consumers and then                                consumers can subscribe to those topics                                by default we would have one topic in                                kafka per table we are capturing                                and they could react to those change                                rates we could use those changements to                                update the cache                                a search index um to run streaming                                queries                                or to exchange data between                                microservices which is what we are going                                to focus                                on in this talk today so let's                                change the capture in a nutshell and i                                very briefly should talk about                                how those change event uh change events                                look like                                and in this case in case of dimension                                this is how such an event would look                                like                                 this actually has three big parts like                                 the old and the new state of the changed                                 row                                 some metadata and the operation type and                                 timestamp                                 so in the alt and new row state there we                                 would have                                 essentially a structure which resembles                                 the tables we are capturing so for each                                 column in our capture tables                                 we would see one field in those parts of                                 the message and now if this is an insert                                 we only would have the after state for                                 an update for instance we would have                                 both so that's all the neural state                                 in terms of metadata there's things like                                 what's the table where this                                 event is coming from what's the database                                 uh maybe the query which caused this                                 change um                                 does this come from what we call an                                 initial snapshot of the data and a few                                 more                                 metadata like this or positioning the                                 log file transaction id and so on and                                 lastly                                 we have this additional metadata like                                 operation type so is it an                                 update is it an insert uh sorry is it an                                 update or it is a great event for                                 instance                                 and the time step when did this change                                 happen so those are the changements                                 which are sent                                 from the database or which are extracted                                 from the database                                 by the museum and sent to consumers via                                 kafka so now let's see                                 how we can um use those change events                                 for implementing those distributed                                 interaction patterns                                 and the first one would be the outbox                                 pattern and well                                 for each of the patterns we are going to                                 talk about briefly what is the                                 problem which we would like to solve                                 here right so and here in this case very                                 often we have a situation where                                 a service needs to update its own                                 database                                 and then at the same time it also would                                 like to notify                                 other services about uh this uh change                                 which happened which happened                                 so our database should be updated and we                                 would like to send a message to other                                 consumers maybe via kafka                                 now the thing is um well we would like                                 to do this consistently right so we                                 don't we want to avoid the situation                                 where we for instance do the database                                 change but not                                 the right of the message to kafka so                                 that's the inconsistencies we would like                                 to avoid                                 and the traveling approach or the                                 apparent approach maybe would be                                 um well to just do what's called a dual                                 write right so our service would                                 try and update its database and at the                                 same time it would send a message                                 um via kafka to consumers but the                                 problem is this what's called                                 dual rides it's not reliable so as those                                 two actions                                 don't happen within one shared                                 transaction it could happen one of them                                 gets applied                                 and the other one fails and now we end                                 up with an inconsistent situation so                                 maybe we already have received and                                 persisted the purchase order                                 in our database but then we forgot or we                                 just failed                                 to notify the shipment service about                                 this order and obviously that's a bad                                 situation so don't do dual rights                                 now the question is how can we avoid                                 this how can we overcome this                                 and this is where the outbox pattern                                 comes into the picture so the idea there                                 is well if we cannot update multiple                                 resources we always can update a single                                 one right we always can go to our                                 database                                 and that's the idea so if a new request                                 comes in let's say for placing a                                 purchase order                                 this service would update its internal                                 table table model so like                                 its order table or the lines table and                                 so on and then                                 within the same transaction it also                                 would write a record to another table                                 which we call the outbox table                                 and this outbox table contains messages                                 which are meant to be sent                                 to external consumers                                 then we would use division to capture                                 the changes just from this outbox table                                 so we would not capture changes from the                                 actual business tables just from this                                 outbox table                                 and we would send them towards those                                 consumers                                 so how would this outbox table look like                                 well in this case                                 um it's a bit based on the ideas of a                                 domain driven design so you have columns                                 there like aggregate type                                 which describes what's the kind of                                 disaggregate is it in order                                 is the customer is it i don't know a                                 recipe or whatever your domain is about                                 we have things like an aggregate id                                 which comes in handy for                                 routing events to make sure we ensure we                                 have a consistent order of those events                                 for the same aggregate and most                                 importantly we have the payload and the                                 payload                                 that really is a structure which you                                 define so it could be anything in this                                 case it's a like json example a json                                 structure                                 and this is now the message which is                                 sent towards your external consumers                                 and now as you do this insert in your                                 database as part                                 of the same transaction in which you                                 also updated your business tables                                 you have uh well transactional                                 guarantees and now                                 all this is applied using at least one                                 semantics so the beast will extract the                                 changes from transaction log                                 and in case of a failure it might go                                 back and read a change which                                 which it already read before a second                                 time so consumers need to be prepared to                                 see duplicates                                 but we will never miss anything we will                                 never end up with inconsistent situation                                 where we have                                 updated our database and not send                                 something to consumers                                 so that's the outbox pattern we will                                 later on see how we can use this uh for                                 more complex interactions                                 for now let's talk about the strength                                 pattern and                                 hans peter can tell you more about that                                 and spit it over to you                                 all right thanks guna so uh the nice                                 thing about the strangler fig pattern is                                 that it can be explained based on a                                 rather illustrative analogy we find in                                 nature so                                 what you see in the background of this                                 image of this                                 slide here is uh a tree structure                                 and this tree itself is wrapped into                                 some other species of plants and they                                 are called stranglerfix                                 and the interesting thing about them is                                 their special growing behavior because                                 those strangler figs                                 they see it in the upper part of their                                 host trees and then                                 they grow from top to bottom until they                                 see in the                                 until they root in the soil themselves                                 now                                 what we can do is we can borrow from                                 this idea we can mimic this special                                 growing behavior in a technical context                                 namely that of a software project                                 migration                                 so we want to show you uh how you can                                 use this pattern again to                                 uh migrate your applications and                                 uh let's uh assume or i think many of                                 you know that there are many full                                 challenges involved when you                                 are um tackled with the task to migrate                                 an existing                                 application into some newer form let's                                 say we want to replace                                 an old monolithic application uh with                                 some more modern micro services based                                 architecture                                 and uh very rarely it is a good idea to                                 try and do this migration in one big                                 uh chunk um so writing everything in                                 uh your micro service stack and then uh                                 trying to have this hard cut over                                 approach                                 is oftentimes doomed to failure                                 now instead we should do it in this                                 strangler fixed way and try to find a                                 way to smoothly and gradual                                 gradually evolve our old system into                                 the newer architecture and when we do                                 that                                 in a step-by-step way this basically                                 means that we have to find a way such                                 that                                 both systems our monolith that we are                                 gradually uh migrating over to services                                 can co-exist with this                                 new services now uh how might this                                 actually work you might wonder                                 and uh for that let's discuss a a                                 concrete example here                                 what we see is a fictional monolithic                                 application in the                                 in the domain of e-commerce here we see                                 a a couple of modules uh three                                 uh to pick to pre-precise and let's                                 assume                                 we want to now uh migrate this monolith                                 uh                                 into uh microservices so let's say we                                 start this migration based on the                                 customer module in the middle                                 now in a first step we would introduce a                                 proxy mechanism could be nginx or                                 anything else that acts as a proxy                                 and at that point in time all the proxy                                 would do                                 is uh just a pass through all read and                                 write requests to the monolith                                 as if nothing is uh there yet                                 so then in a second step let's                                 focus on the persistence layer so here                                 uh                                 we would need to find a way again we are                                 talking about the customer module                                 to bring all those customer related data                                 into its own separate data store                                 because this is how you typically do it                                 you should avoid to have                                 a database for your service or multiple                                 services                                 uh that is shared so we could uh in                                 we could configure uh and use kafka                                 connect we could configure                                 at the bezium source connector that                                 would for instance take                                 all the existing data from a relational                                 database system                                 bring it into uh kafka topics uh                                 and uh from there we could propagate it                                 further with the so-called sync                                 connector                                 depending on what our data store at the                                 target is we can do that                                 with out of the box connectors just by                                 means of configuration                                 so the bcm will not only bring those                                 existing data over to uh kafka topics                                 but it will continuously listen to this                                 to this transaction log and propagate                                 all changes further                                 once we have the customer relevant data                                 over there we could shift our focus back                                 to do the actual migration                                 we could write our customer micro                                 service                                 and we could also do that in a stepwise                                 fashion let's say we want to first                                 introdu                                 uh uh support just uh read based                                 scenarios                                 so we could do that and once this is                                 ready we would then reconfigure the                                 proxy and the proxy would make sure                                 that it would route those client                                 requests that are                                 have originally targeted the monolith                                 for reads over to our new microservice                                 in the second step we could then say we                                 want to extend the microservice and also                                 support write                                 workloads and again once this is done we                                 reconfigure the proxy once more                                 and then our microservice would serve                                 all reads and rights that are relevant                                 for                                 for this customer service at the same                                 time this means that we could                                 more or less shut down or or get rid of                                 this                                 particular functionality in the monolith                                 and then once we write to the                                 microservice of course it will happen in                                 practice                                 that other modules in our monolith might                                 need to be aware of the changes                                 happening                                 in this new micro service and its own                                 separate database                                 for that we would then need to find a                                 way to propagate those changes back into                                 the monolith                                 and again we could then just configure                                 another                                 uh change data capture uh connector uh                                 based on the bezium                                 which uh basically brings the data back                                 to                                 the monolith of course first into kafka                                 and then from there                                 we have a sync connector uh let's                                 briefly reflect                                 what this approach would give us uh so                                 as a first uh of course main benefit we                                 can say that we can reach                                 our ultimate goal of migrating a larger                                 monolithic application                                 uh in an incremental fashion this means                                 we can take these baby steps we can                                 extract                                 service by a feature by feature or                                 module by module                                 into their own services um so uh this                                 means uh                                 inherently we can uh based on how we uh                                 just discussed it support                                 this coexistence and another thing is                                 that we                                 can pause our migration after more or                                 less every step                                 along the journey we could even say we                                 want to completely stop                                 the migration because maybe it was never                                 the idea to migrate really the whole                                 monolith but                                 only parts of it so also this hybrid                                 scenario                                 is very well supported with that                                 strangler fake pattern approach                                 and depending on how we do it and if we                                 get it right we can also support                                 rollbacks if we need to reverse some                                 functionality because of some issues                                 that would happen we could then uh just                                 go back                                 uh and migrate the functionality back                                 into the monolith                                 again the bottom line here is that what                                 we want to achieve uh                                 is considerably lower migration risk                                 than                                 uh when we would contrast that with the                                 big bang                                 migration now uh when we take a second                                 closer look                                 on uh the cdc part of such a solution we                                 might get a                                 slightly more nuanced view remember in                                 its uh original and most a basic form                                 we learned today that cdc gives us this                                 one-to-one replication                                 bit of data between any two systems and                                 we we do that basically on a record by                                 record or change by change                                 uh fashion also we get separate topics                                 for separate tables                                 usually from such cdc solutions as                                 dibysium                                 and this raises a couple of questions                                 when we would transfer data in a                                 one-to-one fashion                                 aren't we somehow leaking our data model                                 from either side and thereby pollute                                 each other's domain model                                 or what about uh if we want to break                                 free from that restriction of only                                 having                                 uh the possibility to transfer records                                 in a one-to-one fashion maybe we want to                                 join records in flight maybe we want to                                 uh in general build any kind of                                 aggregate structure                                 uh and the good news is that while all                                 of these are legitimate concerns we can                                 address them                                 uh and the way we would do that is we                                 would enhance this                                 change data capture pipeline uh and as a                                 first improvement we would uh                                 for instance uh bring in single message                                 transforms or smts for short                                 what they allow us to do is we can                                 manipulate the cdc payload in flight and                                 we can do that                                 with many out-of-the-box                                 smt's uh just by means of configuration                                 uh typical uh                                 modifications are to just include or                                 exclude                                 a particular subset of the whole                                 change event payload or we could rename                                 fields we could change data types we                                 could                                 mask sensitive data we could fully                                 encrypt data                                 and many many more things also important                                 to understand                                 is that we can apply uh smds on both                                 sides of our data flow we can use them                                 on the way into kafka so on the source                                 side or we can use them                                 on the from the way out of kafka on the                                 sink side                                 wherever it is a better fit for our use                                 case                                 remember i said we want to act upon more                                 than one record                                 and a very commonly found use case here                                 is that you need                                 to somehow find a way to join                                 parent-child relationships as they are                                 commonly found in                                 relational databases together uh and                                 maybe you want them to                                 have this coherent kind of aggregate                                 consisting of the parent and all its                                 child records                                 and want to propagate that further                                 towards your sink                                 and this is where stream processes would                                 come into play so we could write for                                 instance a kafka streams application                                 which does exactly that uh for namely                                 joining records based on their foreign                                 key relationship that they have                                 in the data source here                                 when you think about that when you                                 extracted multiple services now                                 you might reach the point where you                                 might want to execute                                 transactions across multiple services                                 and this is in general not easy                                 you try to avoid it as good as you can                                 but sometimes there is just no way                                 around                                 and for that we need uh something more                                 sophisticated and uh this brings me to                                 the third and final pattern of today                                 which is all about sagas so with that                                 back to you guna                                 all right thank you so much hans peter                                 um                                 yes exactly so i mean if we move to                                 microservices                                 from a world of coming from a monolith                                 well we would like to as you say would                                 like to avoid                                 this need for multiple services                                 to you know interact and to                                 achieve on one consistent outcome but                                 sometimes there's just no way                                 around it um no matter how you try and                                 desire to work on your domain um you                                 know to really decouple your services at                                 the end of the day there will be cases                                 where multiple services need to                                 collaborate and they need to                                 achieve one consistent outcome so that's                                 that's the problem so we have those                                 what we could call long-running business                                 transactions                                 and now the problem is we don't                                 typically have protocols like                                 xa to face uh commit protocols which                                 would                                 have been used in the past for                                 implementing such a logic which                                 is distributed across multiple databases                                 so typically we don't have                                 such protocols in a world of                                 microservices um                                 so still we have this need for                                 implementing such flows and of course                                 again it's very important to think about                                 failure cases right so everything is                                 always easy and nice                                 if you just think about the happy path                                 but you also need to think about                                 failure cases what happens if one of the                                 services isn't available                                 or if it fails um so how can we ensure                                 we still have a consistent                                 data outcome so that's where the saga                                 pattern comes into the picture                                 to give you one example so again we're                                 in this domain of e-commerce application                                 and let's say we have three services                                 which are part of this                                 interaction so we have an order service                                 we have a customer service and we have a                                 payment service                                 and now what happens is this order                                 service it receives a                                 request for placing a new purchase order                                 and now it needs to interact with those                                 other two services so it needs to reach                                 out to this customer service                                 to do some sort of credit limit check so                                 we would like to know                                 do we want to accept this order or you                                 know does this customer already have too                                 many pending orders and we don't want to                                 give him another                                 pending order so that's this credit                                 limit check and provided this is okay so                                 we                                 essentially we allocate some credit                                 limit in the customer service for this                                 customer                                 provided this is okay we would like to                                 go to the payment service and                                 initiate the payment and then the order                                 would be in some sort of accepted state                                 so that's the happy path                                 but now let's assume this payment step                                 fails so for for whatever reason the                                 payment doesn't go through maybe the                                 credit card number is involved                                 something like that well then we need to                                 go back to the customer service and we                                 need                                 to compensate we need to undo what this                                 has                                 been doing before so in this case we                                 would need to release this credit amount                                 which had been allocated                                 then it would be in some sort of order                                 rejected state and the overall saga                                 would be in consistent state so all the                                 services have agreed on one final                                 outcome                                 what's important to understand is                                 there's some reduced uh                                 guarantees in terms of the classical                                 transaction                                 semantics so if you think about asset                                 transactions what in particular what you                                 don't have                                 is isolation so if you think about it                                 this customer service                                 once it allocated this credit amount um                                 this already would                                 be visible to other clients                                 also while this entire flow still is                                 running and then maybe                                 this payment check or this payment                                 service you know it agrees or doesn't                                 agree to the overflow                                 and then we might want to undo this                                 change in the customer service                                 but for some time the change in the                                 customer                                 service already was visible to outs to                                 external                                 clients so we have reduced um isolation                                 guarantees here so that's the uh                                 that's an example so now how could this                                 um implement it using change.capture and                                 maybe you already already can guess it                                 so we have this very powerful                                 tool of the outbox pattern so the idea                                 is to                                 use the outbox pattern for coordinating                                 this flow so each service                                 would always go to its own database do                                 whatever it needs to do                                 in terms of updating its domain model                                 updating its own local state and then it                                 would send a message to the next service                                 via its outbox table which then takes                                 over the flow so the order service would                                 send a message to the customer service                                 this will reply then the order service                                 would send another message to the                                 payment service and this would reply and                                 then                                 this flow would be successfully finished                                 or in case of a failure it would look                                 like that so again the order service                                 would do what it has to do it would then                                 pass over control to the customer                                 service                                 um this says okay that's fine i can                                 allocate this credit amount                                 so the order service reaches out now or                                 it sends a message to the payment                                 service and now                                 this payment fails so what we need to do                                 now is we need to                                 again go to the customer service and                                 compensate this                                 uh previously executed action so to                                 release the credit amount                                 so that's how if saga flow could look                                 like in sort in in terms of a                                 failed saga execution so                                 to make it a bit more tangible let's                                 take a look at a demo which i've                                 prepared and                                 um for the sake of time i'm not doing                                 this live but i'm playing back a video                                 so and i'm going to run you through                                 what's happening here                                 so there's a few things running here and                                 um                                 i i got all this running wire compose so                                 we can see what's in there so we got                                 zookeeper we got kafka                                 for our message exchange we got kafka                                 connect which has the division                                 connectors                                 and then we have for each of the                                 services order                                 customer and payment we have um a                                 database                                 which is a postcross database here for                                 the sake of the example and we have the                                 actual service implementation                                 which in this case is a caucus-based                                 microservice                                 quadcores being a stack for building                                 cloud native microservices                                 so all those things are running the next                                 step would be to register the debesium                                 cdc connectors and we can take a look                                 into the configuration of one of them                                 and here                                 so that's the instance of the division                                 postgres connector it's going to the                                 order to be host it's using those                                 credentials order user and so on                                 and then by means of those include                                 filters we are limiting                                 what we are capturing just to this                                 outbox events table so that's the only                                 thing we are interested in here                                 and then we are using a transformation                                 which is called the outbox image router                                 which essentially makes sure that the                                 events from this single outbox table                                 are routed into different topics based                                 on the aggregate type so that the                                 consumer                                 can subscribe to just the changes of a                                 particular aggregate type                                 so now we can place a purchase order and                                 i'm                                 using this very basic rest api in this                                 order service                                 and now i can take a look into the kafka                                 topic or the kafka topics which are used                                 for this message                                 message exchange between the services so                                 the first one would be this credit                                 approval request topic                                 so this has the messages which are sent                                 from order to customer                                 and now as i place orders                                 purchase orders in the other servers we                                 will see obviously that the                                 message is sent to the customer                                 uh to the customer service and we also                                 can take a look into the response                                 topic so now this those are the messages                                 which are sent from                                 customer back to order and again i'm                                 placing another order                                 and i get another response back from                                 customer to order now all those are the                                 proof in the approved status so that's                                 good                                 i could do the same for the exchange for                                 the payment service but really it's the                                 same so it's not so exciting                                 instead let's take a look into what's                                 called the                                 saga execution lock and this is                                 essentially a table which lives within                                 the order service                                 and this keeps track of the state of                                 this saga                                 and now well again i can use the                                 dybusium to extract the changes from                                 this saga execution log table and this                                 is                                 you know we do it here for debugging or                                 exploration purposes so to see what's                                 happening in this                                 saga table there's two fields which are                                 interesting there so this is the                                 zaga status which describes the entire                                 status of this of desire                                 and then the step status which describes                                 the status of the particular steps so                                 now first of all this is started                                 and then the credit approval step this                                 has been started                                 the credit approval step is in the                                 succeeded state                                 payment is started and lastly payment is                                 succeeded                                 and the overall saga is completed                                 so that's a successful uh sagar                                 execution now this order would be                                 accepted                                 you could process we could fulfill it                                 but also let's take a look at                                 a failed order now in this case um i                                 place an order which fails because the                                 credit                                 card number is invalid for the sake of                                 the example so how does that look like                                 so again first of all it's in the                                 started state the credit approval step                                 that started um credit approval is                                 succeeded and payment                                 started and now this payment step fails                                 due to this invalid credit card number                                 and now we see this credit approval step                                 which was successfully                                 executed before this now this                                 compensating step so which means                                 we need to go back and we need to undo                                 it um                                 so um it's compensating and the overall                                 saga that's aborting so we know                                 we need to go back to this uh to some                                 sort of importance thing                                 and lastly the credit approval step                                 that's is now compensated                                 payment has failed and the overalls are                                 like it's in the failed sales and of                                 course we could now                                 explore why is this in a failed state um                                 but                                 that's that's the basic idea um                                 stopping the demo here for the sake of                                 time there's some mornings to this                                 we could talk about item potency here                                 which is done about                                 by means of keeping track of the ids of                                 processed messages                                 you can see this in the entire demo                                 which we will share this                                 link to at the end of the talk so you                                 can see how this is implemented                                 all right so let me go back to the                                 slides and um                                 we are pretty much done i'm just sending                                 over once more to hans peter                                 who will give us a wrap up and some                                 summary of this talk                                 over to you on speedo thank you guna for                                 the nice demo so yeah we are about to                                 wrap this up so i think the                                 uh most important takeaway uh for this                                 session today is hopefully that we                                 we were able to show you that uh cdc is                                 a really powerful tool in fact this it's                                 such a                                 fundamental tool when it comes to                                 building uh event-driven architectures                                 or or microservices                                 and we should really uh use it                                 beyond those uh simplistic one-to-one                                 replication kind of use cases that you                                 very often see so i hope this                                 uh explanation of uh these three                                 patterns namely outbox                                 strangler fig and saga patterns uh gave                                 you some some                                 inspiration some ideas how you could                                 make use of                                 these uh mechanisms in your own                                 uh real world applications uh also if                                 you want to dig deeper uh i would really                                 encourage you to try out a                                 cdc for yourself uh based on the bc                                 which is                                 among the leading change data capture                                 solutions fully open source                                 uh in addition to just being a cdc                                 it comes with uh handy smds very                                 convenient extensions such as                                 outbox pattern support that we discussed                                 today uh and in that regard actually we                                 would have                                 a a call to action for every one of you                                 so if you                                 would like to see um support for the                                 saga pattern                                 similar to what we have seen in in the                                 demo                                 from guna please uh more or less let us                                 know                                 via the project's mailing list which you                                 can find on the bcm dot io                                 with that uh we want to point you just                                 to some further resources                                 again uh two very elaborate uh blog                                 posts about the outbox pattern and saga                                 pattern uh step-by-step instructions the                                 demo repository                                 should be great because the demo you                                 have seen today you can try it out on                                 your own so                                 everything is there for you to run the                                 demos uh                                 at uh the convenience uh that uh                                 you can use it from your home just by                                 using docker                                 compose uh which is all you basically                                 need to run those demos uh with that we                                 want to thank you for joining again                                 thanks for taking the time                                 we would appreciate uh uh to uh to                                 get some questions and hopefully be able                                 to answer them um                                 and yeah let's do the live q a right now                                 or discuss later in the breakout channel                                 thanks                                 you
YouTube URL: https://www.youtube.com/watch?v=CLv2EcYnr2g


