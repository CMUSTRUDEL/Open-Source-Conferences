Title: Caito Scherr – Better, Faster, Stronger Streaming: Your First Dive into Flink SQL
Publication date: 2021-06-30
Playlist: Berlin Buzzwords 2021 #bbuzz
Description: 
	For the most flexible, powerful stream processing engines, it seems like the barrier to entry has never been higher than it is now. If you’ve tried, or have been interested in leveraging the strengths of real-time data processing - maybe for machine learning, IoT, anomaly detection or data analysis - but you’ve been held back: I’ve been there, and it’s frustrating. And that’s why this talk is for you. 

That being said, this talk is also for you if you ARE experienced with stream processing but you want an easy (and if I say so myself, pretty fun) way to add some of the newest, bleeding edge features to your toolbelt.

This session will be about getting started with Flink SQL. Apache Flink’s high level SQL language has the familiarity of the SQL you know and love (or at least, know…), but with some powerful new functionality, and of course, the benefit of being able to be used with Flink and PyFlink. 

More specifically, this will be a pragmatic entry into creating data pipelines with Flink SQL, as well as a sneak peek into some of its newest and most interesting features.

Speaker:
Caito Scherr – https://2021.berlinbuzzwords.de/member/caito-scherr

More: https://2021.berlinbuzzwords.de/session/better-faster-stronger-streaming-your-first-dive-flink-sql
Captions: 
	                              all right                               it is so good to be back at berlin                               buzzwords good to see you all here                               for those of you who don't know me my                               name is kato sher                               and i'm a developer advocate and i work                               at viverica which is a berlin-based tech                               company                               and they built and maintained the open                                source project apache flink                                as well as a related integrated platform                                called the vaverica platform which                                provides                                analytics and streamlines deployments                                and other operations for flink                                i live in portland oregon so nice and                                early here                                and i got started with stream processing                                back in                                     when i was a software engineer at a                                large data analytics company                                and my team there built that company's                                first stream processing data pipeline in                                production                                using flink there was very little stream                                processing in general there                                so it was a pretty steep learning curve                                but also of course                                very worth it you know i'm here now and                                it also means though that i have a                                particular soft spot for hearing about                                people's early adoption stories                                and having been through some of the pain                                points i'm very focused on trying to                                make all that a bit easier                                and hopefully a little bit more fun too                                and                                i got to know my current co-workers when                                i became a fairly regular speaker at                                their conferences                                and i got just completely hooked once i                                met that                                open source community around it really                                the only downside of working for them is                                i guess i have to like squirrels now as                                that's our mascot                                which of course in all fairness is                                pretty cute so i know we have a lot of                                a large german speaking audience today                                but for anyone who's not uh the rough                                translation of the word flink                                in german means nimble so really                                highlighting the flexibility and speed                                of the framework                                and since this is meant to be a very                                beginner friendly talk                                i'll start with some very quick                                introduction uh on flink                                for anyone's unfamiliar and i promise                                it'll be fast and then                                i'll i'll mainly be highlighting just                                the parts that are going to pertain to                                today's topic                                so next i'll discuss why to use sling                                sql                                so why it's a good starting point and                                what some of its strengths are                                and then lastly our demo will include                                just the most straightforward                                process possible for jumping right in                                and being able to just                                build your own data pipelines in just a                                couple quick steps with link sql                                so firstly what even is flink on the                                highest level it is a stateful                                fully distributed processing engine for                                both batch and stream processing                                and more precisely you know for bounded                                and unbounded data streams                                its strengths are in its scalability its                                high performance so think computations                                done at in-memory speed                                and various features like exactly-once                                guarantees and                                robust high-availability options that                                allow for just those really high levels                                of data accuracy and reliability                                additionally there is an ever-growing                                ecosystem around flink of                                libraries connectors other features and                                partnerships with different                                complementary tools and software                                that have really enabled it to fit into                                a pretty wide variety of different use                                cases and pre-existing systems                                um specifically it can be run on pretty                                much any common clustered environment so                                hadoop yarn mesos kubernetes can also be                                run up as a standalone cluster                                 and its uh timing and state features are                                 really where it shines so it allows kind                                 of that extra                                 extra flexibility for what kinds of                                 applications it can be run on                                 and as part of this ecosystem flink has                                 a series of apis                                 so the higher level api the more concise                                 but the less expressive and vice                                 versa so the most expressive is our                                 lowest level process functions                                 and that's going to support flink's                                 precision timing event and any                                 state-related functionality                                 and on the mid-level is the data stream                                 api which powers the unified batch and                                 streaming functions                                 so anything related to windowing exactly                                 once etc                                 and this is where your maps reduces                                 aggregations anything like that's going                                 to take place                                 the table api and the sql client are                                 going to make up that highest level                                 the relational apis here and that's of                                 course what i'll be getting into later                                 and both of these are really optimized                                 for unified batch and streaming                                 processing                                 so the queries are just going to be the                                 same regardless of which processing type                                 you're using                                 and they're also both based on apache                                 calcite                                 so they are also ansi or standard sql                                 compliant                                 taking a little quick step back though                                 so why is it important to have                                 and provide this unified batch and                                 streaming solution                                 so unifying this allows users to be able                                 to reuse code and logic                                 across both batch and streaming                                 processing so you know it's just going                                 to make a lot easier to integrate                                 different                                 applications different systems but it                                 also it helps ensure that semantics are                                 going to be consistent                                 so you don't have to learn a totally new                                 api for each processing mode or for each                                 layer of abstraction                                 and it means you can just simplify your                                 operations and keep your configs keep                                 your processes the same across                                 all these different systems so                                 especially for any distributed system                                 it's just                                 it's all about that simplification and                                 of course it enables you to mix your                                 historical and your real-time data                                 as for the architecture it will look a                                 little bit different depending on                                 what use case it's for and whether it's                                 a batch or streaming scenario                                 but these are pretty common examples for                                 both a batch                                 on the left i assume it's left depending                                 on the mirroring here um                                 and then of course for our streaming                                 scenario on the other side                                 so in our batch example we have our                                 recorded or historical events                                 and although these are queried                                 periodically flank's really precision                                 timing capabilities enabled this to be                                 done pretty efficiently                                 and on the streaming scenario it's going                                 to rely a bit more heavily on flink's                                 internal state functionality                                 and the most typical use cases for all                                 this is event driven applications                                 data analytics applications and data                                 pipeline apps                                 and as for its state it uses a very                                 unique checkpointing and safe pointing                                 mechanism system                                 that i won't really have time to go into                                 here but there's a lot of great talks on                                 that                                 uh the main benefit of that or at least                                 my favorite benefit because i really                                 like geeking out about it is                                 that it enables that exactly once                                 guarantees on the data                                 but moreover that it's it's actually                                 scalable                                 with very minimal performance overhead                                 because of that checkpointing mechanism                                 system um and then even if you're using                                 the more abstracted sql version i do                                 think it's kind of nice just so you have                                 an idea of what a typical                                 code block for this is going to look                                 like and kind of know what's going on                                 under the hood here                                 so this is a typical but very simplified                                 code version for just a really basic                                 flank data pipeline                                 this is not using the sql client again                                 just to kind of                                 show you the code version of that                                 architecture we just looked at                                 so starting off with reading it from a                                 source uh                                 kafka topic is the most common along                                 with pulsar                                 um next is this very very simplified                                 representation of                                 business logic for in the flink app                                 itself so doing a couple basic                                 transforms                                 maps and reduces being the most common                                 to start with                                 and then moving on to specifying what                                 you want by                                 key buy and configuring for your                                 windowing settings                                 and obviously there's a lot more in                                 between typically                                 but um you're you know so dot dot dot                                 and then uh but then you're going to be                                 designating your sinks as the last bit                                 there                                 so that again is just typically what                                 that process looks like                                 so with all that so sounds you know                                 there's all of these great benefits um                                 why are we focusing on flake sql and not                                 everything else in flink                                 and uh for me that actually kind of                                 answers itself for this talk because                                 um with everything else in flank there                                 is so much going on there                                 and that is what makes it such a                                 powerful and flexible tool                                 but it also means it's really nice to                                 have an option that allows you to just                                 really jump right in and start building                                 something that can leverage those                                 strengths                                 without having to learn the entire thing                                 learn the ecosystem learn the code                                 and the framework and do with that whole                                 deep dive so                                 that code example you know as i said was                                 very simplified                                 there's going to be more going on there                                 um it's going to be a bit language                                 dependent and requires more dependencies                                 and on a basic level you know having a                                 powerful ide                                 and build tools and everything so for                                 flink sql um i will go into some of its                                 strengths in a moment but                                 um really i want to emphasize it's all                                 about simplifying your development                                 so that is our theme keeping it simple                                 and the uh its capability is actually                                 very stable too                                 so it's we've been adding flink sql                                 features for about six years                                 and as i mentioned it's based on calcite                                 so it does support that regular sql so                                 the learning curve is                                 just absolutely minimal if you have any                                 other sql experience or database                                 experience                                 um as for the actual benefits of                                 combining sql with a powerful streaming                                 engine                                 so we've covered you know batch and                                 streaming distributed systems that's                                 really great                                 um really it's you know users can focus                                 now on the business logic of being able                                 to still                                 do a powerful streaming system but not                                 have to worry about all those                                 implementation details                                 and along with the fact that it's just                                 sql                                 your your developers don't have to be                                 java or scala experts                                 they don't have to worry about switching                                 your code over to java or scala or                                 python if that's not what you're working                                 in                                 so it makes it just incredibly                                 lightweight and gives developers a bit                                 more autonomy so they can just jump in                                 without any of that                                 and for some of the real world use cases                                 i've got a couple examples here                                 of some companies that are using clink                                 sql we see a lot of people building                                 more unified pipelines for online and                                 offline model training                                 uh independently building end-to-end                                 streaming analytics pipelines                                 and and specifically without having to                                 depend on                                 a specific engineering or operations                                 team just for                                 your pipeline building and also just                                 being able to more easily generate                                 features for machine learning model                                 training in general                                 and one thing i like is kind of                                 comparing the difference between                                 a regular sql engine versus a streaming                                 one so regular one                                 a regular database you're going to                                 execute your query at a certain point in                                 time                                 the engine then takes a snapshot of the                                 table at the time the query is run                                 and then computes the results based on                                 that static snapshot                                 and then the query terminates so pretty                                 straightforward there                                 but with the sql one the query is                                 continuous                                 so you first deploy your query then                                 whenever the data is added to the table                                 the changes are continuously ingested                                 and the results are also continuously                                 updated                                 the query keeps running and it never                                 finishes until you actually cancel the                                 job                                 so it just you know it's streaming so it                                 just keeps going                                 and uh keeping with that level of                                 simplicity so                                 i wanted to include this example this is                                 an example of                                 sessionizing a click stream and count on                                 counting on the number of clicks per                                 session                                 and we've got on one side here the                                 regular flink using the data stream api                                 versus the exact same thing using flink                                 sql                                 so i think this is a pretty powerful                                 comparison and                                 with you know links other apis as i said                                 their queries are going to be dependent                                 on                                 a table program written either in java                                 or scala so                                 you're going to have those build tool                                 dependencies for submitting to the                                 cluster                                 whereas filling sql all writing                                 debugging                                 submitting any sort of table program to                                 a flink                                 cluster is just done you you barely even                                 notice the flint cluster honestly                                 um plus you get some nice visualizations                                 just on the command line                                 so just to recap so basically you get                                 this high-level relation-like way to                                 query your data streams                                 and it's more likely you're already                                 going to know it you've got this unified                                 batch and streaming option                                 and you can process so yeah processing                                 historical and real-time data                                 without having to change any of your                                 logic there and                                 you've got this super super simple                                 option you can build all                                 these complicated applications with that                                 same performance scalability and                                 consistency                                 of any other flink program without                                 having to                                 do all the implementation overhead so                                 now we can get on to the fun part so for                                 the demo                                 um i again i wanted to keep this as                                 simple as possible                                 and uh hopefully you can follow along if                                 you want i know sometimes the download                                 can take a moment here                                 so don't feel sad if it does but                                 i believe these will be up after the                                 conference as well so                                 um firstly the prereqs are extremely                                 simple so                                 you do not need to write any java code                                 but you do need to make sure that you                                 have java                                                           machine                                 so then just make sure you've got that                                 make sure you've on the right version                                 download the current stable snapshot                                 release of flink so there's a link in                                 the docs there and then you unturr it                                 and cd in there and that's it so that is                                 all of your prereqs                                 and then you can jump in so all you have                                 to do start a cluster                                 and at this point you'll be able to open                                 up                                 i'll wait for it to uh yeah so then you                                 can open up your the flink ui so                                 just here on localhost ignore all my                                 tabs and                                 things there and this just comes out of                                 the box of links so                                 again it's just localhost everything is                                 just right there it's super fast                                 and then you can get started on your sql                                 client                                 so all of this is in real time so it's                                 very fast                                 um so once oh and also                                 i'm just using the most basic uh way to                                 start up the sql client                                 you can also explicitly use embedded                                 mode as well                                 so you are not going to miss that you                                 are in the sql client                                 there's definitely no did this work                                 because you will immediately see this                                 gigantic squirrel                                 it doesn't even scroll all the way so if                                 you do not see a gigantic squirrel                                 then something is wrong so uh it's a                                 very quick way to know that                                 you know either you're in or you aren't                                 so as a side note too                                 the client does support a couple                                 different modes for maintaining                                 and visualizing your results so you can                                 also                                 add some different configurations while                                 you're starting it up so                                 there's a table mode so that                                 materializes results in memory                                 and the visualization is going to be in                                 a regular just paginated                                 table the changelog mode does not                                 actually materialize                                 results and visualizes the result stream                                 and but it consists of these insertions                                 and retractions so that's one option                                 one note with that is in order for that                                 mode to stay really responsive                                 since those results are stored in the                                 java heap that change log mode uh will                                 only show the latest                                 thousand changes so there's other things                                 you can do to configure that but that's                                 just kind of                                 the default there and the last mode is                                 tableau mode so this is more like your                                 traditional way                                 that will display the results on the                                 screen just directly in tableau format                                 and the displaying content is going to                                 be influenced by the query execution                                 type                                 for that one um so                                 then this is really basic                                 but this is my like my big psa is that i                                 always check the built-in hello world                                 function                                 because it is a really fast way to find                                 out if something is wrong so                                 you've gotten into the sql client that's                                 super easy you got your gigantic                                 squirrel you know you're in                                 but you could potentially there could                                 potentially still be something else and                                 before you throw a bunch of                                 queries in there that you care about um                                 i like to check this just to make sure                                 that you don't for instance                                 have you know you've overridden your                                 your default port somewhere                                 or um you know if you're doing all this                                 from scratch                                 you are probably not going to have any                                 of these issues but if you already have                                 an older version of flink downloaded                                 somewhere                                 your cluster version and your client                                 version                                 may not be the same so you just want to                                 make sure                                 and i i really do just like doing this                                 little test real fast just to make sure                                 that like okay this is going to work and                                 it's not just some silly                                 thing that you know versioning or ports                                 or something                                 and again trying to make just the                                 absolutely most basic example here                                 so in this one i'm creating a table and                                 reading just from a local csv                                 file i picked something i was already                                 using in my personal life this is                                 um a bunch of friends contributed to                                 this fake                                 journal or diary titles for their                                 experiences during quarantine we wanted                                 to keep it funny but also still really                                 inclusive                                 and just have kind of a relatable way to                                 share feelings that                                 came up this past year and people got so                                 into it i                                 wait within like a week i had over                                     submissions                                 back in like april may of last year uh                                 from friends and family and coworkers                                 and it spread all over slack spaces and                                 text messages so i was like you know                                 what                                 i just want to create an easy pipeline                                 so that anyone can just add it                                 themselves into this pipeline                                 and in this case i'm just doing it as a                                 csv they can add to you and then i can                                 just continuously read                                 from it um and then i can start to                                 quickly sort and determine and do you                                 know                                 use some more interesting uh things with                                 sql on it                                 and uh you know determine which ones                                 have been                                 produced we're making these like fake                                 book covers and which ones will work                                 safe for people to                                 to share work and things like that so                                 just a nice kind of real world                                 uh but very basic example here um so                                 that's it so then you enter that                                 you get this nice display here and as i                                 mentioned there's a bunch of different                                 modes to                                 make this look a little bit nicer so uh                                 next time around i will                                 have that in the demo too where you'll                                 actually be able to see the full the                                 full                                 titles there for some of those um so                                 again a lot of different                                 options for configuring your visuals                                 there which is nice                                 and then one note is that the sql client                                 provides                                 output in this you know real-time but                                 read-only fashion so                                 if you want to store results for you                                 know report or dashboard                                 you do need to write out to another                                 table so this can be achieved really                                 easily just with an insert into                                 statement and once submitted there this                                 will just run                                 and store the results into that sync                                 table directly                                 and that is really nice because it does                                 that instead of loading                                 the results into the system memory so                                 again all of this is optimized for                                 simplicity and performance                                 so just keeping that super easy so with                                 that                                 since we're a bit limited on time i                                 actually grabbed this um                                 these images from my one of my old                                 co-workers who has done an amazing job                                 contributing to this                                 there is a really awesome flink sequel                                 cookbook                                 that my co-workers put together so this                                 is where we                                 regularly share hands-on examples and                                 patterns and                                 use cases for filling sql and there is                                 so much in there                                 i think people were contributing almost                                 on a weekly basis for a while                                 so you can find examples of just about                                 everything                                 from the most basic things to                                 all different configurations for each                                 different basic thing you can do to more                                 advanced things                                 so i definitely recommend it and i will                                 actually have a                                 links to that at the end as well                                 uh just one more example there's also                                 some really nice little demos so                                 there's some demos in the flink sql                                 cookbook most of them using the uh the                                 bavaria platform there                                 and with that um please feel free to                                 reach out to me                                 um i've got my my twitter i'm actually                                 going to be taking a little bit of time                                 off of social media just next week but i                                 will respond this week and the week                                 after                                 and i've got some other mostly stream                                 processing                                 and nerding out on data analytics things                                 on my medium account and website there                                 feel free to also email me if you have                                 questions about this                                 and i know there's a lot on here so i                                 actually have an easier way to grab this                                 um here                                 there we go i promised uh so easy way to                                 grab it                                 um i actually am still uploading the                                 links right now                                 but uh so i save save the qr code                                 and then uh that'll send you to my                                 website and then all of those links will                                 be available by end of the week                                 so and with that um thank you all oh an                                 extra                                 shout out to my my old co-worker marta                                 who did some of the um                                 all of the sql cookbook um things there                                 so                                 huge thank you to all of you for coming                                 and it's been so great to see you all                                 um in virtually anyway                                 and a huge thank you to nina and all of                                 the um                                 all the conference staff as well                                 okay thanks for your talk it's really                                 interesting uh                                 i want to check just the questions to                                 see what we have there uh                                 okay so since we have only one question                                 it says how rich are the querying                                 capabilities                                 compared with normal sql                                 what was it i missed the first part                                 that's right how rich are the                                 capabilities of playing sql versus                                 normal sql                                 oh so because it's all and if i'm                                 understanding the question correctly um                                 because it's all                                 as i mentioned earlier like based on                                 apache calcite it's                                 it's going gonna be you're gonna have                                 the same capabilities there as                                 uh just ansi and standard sql so it's                                 uh that was something that was really                                 important is to be able to keep that um                                 keep all of that as similar as possible                                 on all different all those different                                 levels                                 so yeah and if i if i misunderstood that                                 too feel free to                                 um feel free to also like ping me too                                 and i can give you more detailed                                 uh example of that as well if you want                                 okay                                 uh i'm going to ask one question that i                                 have that maybe uh                                 can we mix these like steps in the                                 middle let's say i want to clean                                 some initial data just with sql and then                                 do more stuff or in the middle                                 or yeah yeah you should be able to and                                 there's actually um i would definitely                                 recommend                                 the i'm trying to think if there's a                                 specific example                                 i think there is some examples of that                                 in the cookbook                                 but don't quote me on that yet um but                                 that's something i can post                                 um i'll try to find that maybe post it                                 to twitter later                                 um and there's also there's a couple                                 other really good talks that do a bunch                                 more                                 things like that a bunch more deep dives                                 into flink sql so                                 there's a couple um i can also                                 is there a good place for me to to add                                 some of those links                                 because i think i'm only in the private                                 chat here so i don't think i can                                 well i suppose but well anyway people                                 can't follow you                                 okay okay cool yeah because i can i can                                 try to link you to some                                 some more resources on that yeah                                 you
YouTube URL: https://www.youtube.com/watch?v=d7q1WbLudEg


