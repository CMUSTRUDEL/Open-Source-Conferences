Title: Ido Nadler & Opher Dubrovsky – Should you read Kafka as a stream or in batch? Should you even care?
Publication date: 2021-06-29
Playlist: Berlin Buzzwords 2021 #bbuzz
Description: 
	Should you consume Kafka in a stream OR batch? When should you choose each one? What is more efficient, and cost effective? Should you even care?

In this talk we’ll give you the tools and metrics to decide which solution you should apply when, and show you a real life example with cost & time comparisons.
To highlight the differences, we’ll dive into a project we’ve done, transitioning from reading Kafka in a stream to reading it in batch. 

By turning conventional thinking on its head and reading our multi-petabyte Kafka stream in batch using Spark and Airflow, we’ve achieved a huge cost reduction of 65% while at the same time getting a more scalable and resilient solution.

Using the learnings and statistics we’ve gained, we’ll explore the tradeoffs and give you the metrics and intuition you’ll need to make such decisions yourself. 

We’ll cover:
- Costs of processing in stream compared to batch
- Scaling up for bursts and reprocessing 
- Making the tradeoff between wait times and costs
- Recovering from outages 
- And much more…

Speaker:
Ido Nadler – https://2021.berlinbuzzwords.de/member/ido-nadler
Opher Dubrovsky – https://2021.berlinbuzzwords.de/member/opher-dubrovsky

More: https://2021.berlinbuzzwords.de/session/should-you-read-kafka-stream-or-batch-should-you-even-care
Captions: 
	                              hi everybody this talk is about                               if you should read kafka as a stream or                               in bet                               we're gonna pit batch against stream and                               see what comes out                               we'll start with stream stream is                               basically                               doing micro deliveries doing many small                               trips                                and as a result you get low wait times                                data comes in and very quickly gets                                delivered                                batch on the other hand is exactly the                                opposite we make                                large deliveries we make few trips as a                                result of that                                but you also have longer waits until                                your data                                arrives so this is a story about a                                stream                                that has gone bad we'll tell you a story                                of a projects we've done                                that used to be a stream and we turned                                it into batch                                and we'll see what the differences were                                and why it made a lot of sense                                we'll go over stream versus batch some                                of the trade-offs                                how we re-architecturated our stream to                                a badge                                and we'll conclude with some                                considerations                                that will make sense for you to consider                                while looking at your projects                                as well before we start i want to                                explain who we are                                my name is offer dubrovsky i'm a big                                data dev lead at nielsen                                and with me is the don adler a big data                                engineer at nielsen                                we deal with data pipelines serverless                                infrastructure                                spark clusters and data analytics                                we are part of nielsen marketing cloud                                and we build marketing segments and                                device device graphs that can be used                                for running marketing campaigns and for                                making                                business decisions uh in a nutshell                                about nielsen marketing cloud                                we are cloud native we process a lot of                                data every day                                roughly                                                               day                                and we store a total of about five                                petabytes                                in our data lake we're heavy users of                                spark                                roughly                                                      across all our spark clusters and we're                                heavy users of lambda functions                                that we also use in some of our                                pipelines all right let's talk about                                stream versus batch trade-offs                                we're going to pit batch against stream                                and we're going to do it right now                                and to do that i want to use an analogy                                of something with all something we're                                all familiar with                                which is pizza delivery so on the left                                we have batch our new champion                                which is using a pizza delivery truck to                                deliver pizzas                                in batch and on the right we have stream                                our lightweight previous champion which                                delivers                                pizzas using delivery scooters that can                                carry three to four pizzas                                in each delivery the challenge is                                to deliver pizzas to a party going on at                                a house                                and we'll compare the differences                                between doing it                                in each of those ways so let's look at                                speed                                if we have                                                          house                                and we are using the pizza delivery                                truck                                that probably will take longer the truck                                needs to wait until                                all the pizzas are ready and then                                driving through the city will also take                                longer for the truck so the total                                delivery time will be                                                                                                      delivery scooters each one can pick up                                the pizzas as they arrive                                and head off immediately to the house                                 so delivery time will be faster they                                 also drive faster through the city                                 so we expect                                                             the pizzas are going to arrive                                 as they flow out of the oven so                                 in terms of speed the stream option is                                 faster however if we look at cost                                 the pizza delivery truck uh                                 cost                                                             if we have                                                         deliver all of them                                 at once so the cost per unit is gonna be                                 just two dollars                                 forty dollars for the delivery divided                                 by                                           but the scooters will need six runs                                 so the                                                                   going to be much cheaper just                                    but still that works out to be three                                 dollars per unit                                 much more expensive                                         so the stream even though it's faster we                                 actually have to pay for that                                 it costs more and if we look at high                                 loads                                 if you compare this to data this is when                                 you have to reprocess a lot of data that                                 was held up somewhere uh                                 there's also a big uh difference here                                 the truck                                 high load in our example is we we had to                                 deliver a hundred pizzas                                 so the truck could still deliver all of                                 them in one run it's still                                                                                           to deliver the                                                         make five runs with each scooter                                 five rounds times                                                   going to take                                                                                                   expensive                                 it's also going to take longer                                 to deliver so you can see that in some                                 scenarios the stream is worse off                                 in all dimensions both speed                                 and cost so should we go with stream or                                 batch                                 in some cases the answer is obvious if                                 you need real-time data then you go with                                 a stream you just need real data no                                 other choice                                 but if you need a lot of aggregations so                                 basically that means you have to wait                                 until all your data arrives before you                                 can do any aggregation                                 you would go with batch because you have                                 to wait anyways                                 but what about all these cases in the                                 middle where you could do either one of                                 them                                 and and it's up to you to decide                                 so to take a look at that option                                 let's see an example system and to do                                 that i'm going to pass it on to ido                                 which will tell you all about it thank                                 you offer                                 let's meet our system it's one of our                                 core systems                                 that process huge amount of data every                                 day                                 this data is being used widely in our                                 company                                 it's a simple etl pipeline                                 that uses spark and consume                                 that consumes data from kafka this kafka                                 cluster is being fed by other kafka                                 clusters spread                                 around the world in our data centers and                                 the results                                 are being written to our data lake in                                 sitting on aws in s                                  now since we have constant stream of                                 data                                 coming along the day we use spark                                 streaming                                 and because let's face it streaming is                                 very cool                                 right overall we process                                 around                                                               which is a lot now if we dive into                                 one of our pipelines then that use a                                 specific topic we call                                 delivery in this specific topic we                                 process                                 around                                                                so in order to be able to consume such                                 amount of data                                 we defined this kafka topic to run with                                                                                 now the way spark cluster spark work is                                 that                                 each kafka consumer is running on top of                                 spark executor that uses                                 its own core so overall we are running                                                                            all running together there and the                                 results are again                                 same amount of files being written to s                                  in a nutshell every few minutes                                 we consume a micro batch from kafka                                 we run some transformation on on this                                 data                                 and the results are being written to                                 s                                                                    right                                 it works perfectly for us                                 but in time reality hits us and we                                 found some issues with this system                                 i'm gonna explain so if we take a look                                 at our stream of data                                 it varies during the day so                                 we found out that during the low hours                                 our cluster is underutilized which means                                 we are paying for resources we do not                                 need                                 on the other hand on peak hours when the                                 traffic                                 exceeded the cluster capacity                                 we were starting to drag behind                                 now let's talk about your birthday                                 you don't want to miss your birthday due                                 to production issues                                 right well in our case it wasn't your                                 birthday                                 but it did was a christmas eve                                 so two years ago on christmas eve                                 we found out that our system was down                                 and we were starting to lose data                                 now the reason for that is because we                                 kafka as a retention policy which was in                                 our case two days                                 and because of an outage the system was                                 down                                 and when we started to                                 consume the data again we were consuming                                 a offsets with which of data that was                                 already deleted by kafka                                 so we we quickly uh went                                 and increased the that the retention                                 policy                                 but we figured out that                                 we have a recovery issue and we are                                 losing data                                 so we we then understood                                 that when you need to reco architect                                 your system                                 you really really think you need to                                 think about recovery because                                 recovery is a ticking time bomb and                                 we will show you later how we fix that                                 issue                                 regarding cost well                                 system systems and and machines cost                                 money right                                 so in our case it cost a lot                                 it the the amount of dollars we needed                                 to pay                                 for every year was four hundred thousand                                 dollars that's a lot                                 so we thought it has to be a better way                                 and we have to rethink and architect                                 re-architect our system                                 our the project goals was to build a                                 system that can be                                 a quickly auto scale according to the                                 traffic                                 coming along the day this will also fix                                 the delivery                                 the delay issues we have on peak hours                                 regarding cost we have to improve our                                 efficiency and cluster capacity                                 so we can gain some cost cutting                                 and regarding recovery as you said as we                                 said before                                 we cut we we knew that recovery                                 a system and able to recover from                                 failure is a must                                 so we thought that we have to we need to                                 spread the work                                 across isolated workers that way we can                                 tailor each one of those                                 those workers to better efficiency                                 but how so we took                                 all of our smart engineers put them on                                 the same room ordered some pizza with                                 scooters of course                                 and we thought on how to do that                                 what we realized that if we look at our                                 stream of data                                 if we use discrete time slots                                 with fixed amount of time let's say                                 hours for example                                 and we we can look at each one of those                                 hours as a separated task that you can                                 tailor according to the                                 amount of data it needs to process                                 so by spinning more and more tasks                                 during the day                                 we can isolate the work from the workers                                 and basically cue a                                 run multiple emrs                                 a in a iso in a full isolation                                 system if we take a look                                 on it on the task perspective                                 each hour is a task some of them                                 are very short shorter than an hour                                 which mean                                 that we can process an hour of data                                 in less time and some of them takes                                 longer than an hour                                 according to the traffic that comes to                                 that arrives to kafka during that hour                                 but that's okay right because even                                 though                                 a a task takes longer than an hour the                                 next                                 task that is processing the next hour                                 will sca will start when it was                                 scheduled so we won't get the any delay                                 better than that when a task ends                                 and we don't need to the cluster anymore                                 uh we terminate the cluster and we                                 free the resources and we start paying                                 for the for the                                 cost time is money right                                 if you think about it this is very                                 similar to how serverless                                 systems work right because you pay                                 for the resources you need when you do                                 the job but when the job is done                                 you free the resources and you stop                                 paying for it                                 regarding a efficiency we are pretty                                 much                                 driving our cluster to a                                             but since we're using spark over eml                                 uh there is some warm-up time uh                                 that that takes from our efficiency                                 so the total efficiency is around                                    percent                                 now of course if we reduce the warm-up                                 time                                 we can get closer and closer to                                     percent                                 efficiency there are some ways to do                                 that                                 and we are already experiencing and                                 playing with a running spark over                                 kubernetes                                 if we compare it to the previous system                                 where                                 in the low hours we were paying for                                 a resources we do not need the efficient                                 efficiency of the previous system was                                 around                                            now if you recall we just said that the                                 new system                                 is around                                               overall we are now                                    cheaper than the previous system which                                 is                                 awesome                                 now let's see let's see the mechanics                                 we use airflow to schedule and control                                 our pipelines so when we need we need to                                 run a task                                 let's start a airflow we spin up an emr                                 cluster                                 between a period of time then this emab                                 cluster                                 will use kafka to convert the time                                 period into offsets and consume the data                                 within kafka between those offsets when                                 there is nothing more to consume                                 the and the job is done the cluster will                                 terminate itself                                 and we're going to start paying for the                                 cost great                                 now when we need to run                                 multiple tasks with multiple time                                 periods                                 maybe together we can just spin up more                                 and more                                 isolated pipelines and that will just                                 work so                                 as a result we now run multiple                                 pipelines running running with multiple                                 topics                                 on multiple time periods                                 and it just work as a charm                                 so to see the results i'm going to pass                                 it back to offer                                 over okay thank you idol                                 so we saw the architecture                                 and understand why it should be better                                 but                                 is it really better let's see some                                 results                                 so the first thing i want to show you                                 is how the system looked before and                                 after                                 on the left you could see that                                 this is what it looked like when it was                                 doing all these micro batches                                 while it was streaming and on the right                                 you could see                                 beyond the transition point we started                                 doing processing                                 once an hour so once an hour we process                                 data and we reduce the amount of data                                 waiting for us in kafka what you're                                 looking here are basically the offsets                                 the amount of lag we have in kafka you                                 can also notice                                 that once in a while we have a bigger                                 gap this                                 means we missed a run and as a result                                 the total data to process the queue goes                                 up                                 but this is okay because as you recall                                 our runs are independent we can just                                 rerun it                                 again later on and this is exactly what                                 happens the system just reruns                                 uh the the that batch job                                 and gets back to normal in terms of                                 cost on the left you can see how the                                 system looked before doing this                                 transition                                 the daily costs were pretty much the                                 same every day                                 uh slightly different if we had to uh                                 rerun or restart a cluster and run it                                 again                                 uh so you can see the the costs were                                 roughly                                                                 topics we were running                                 on the right you could see after the                                 change the                                 the amount of money we pay every day                                 changes every day depending on the                                 amount of                                 data that comes in so this really                                 follows the amount of data                                 you can also see that there's a huge                                 drop in cost in total it's around                                                                                                        at the yearly cost                                 before we were paying around                                         a year and now we're down to                                           year                                 that's                                                   every year just from the move uh to this                                 system which is                                 obviously awesome if you look at the                                 data                                 these are the bytes we are processing                                 per hour and you could see this changes                                 from hour to hour and day to day and our                                 costs are very                                 correlated with that you could look at                                 the cost graph below                                 in green and you can see that it follows                                 very                                 nicely the amount of data we process                                 which is great                                 it means we have a pretty uh serverless                                 type of flow                                 and that we are paying linearly with the                                 amount of data which is                                 a great place to be in let's look at how                                 we handle outages which is something you                                 don't mention which was an issue for us                                 and we really wanted to have better                                 outage handling                                 so this graph shows you the amount of                                 data waiting to be processed                                 in the old system and you can see that                                 it suddenly shoots up                                 we have it we had an outage something                                 was wrong                                 data started to accumulate we had a                                 cluster down or something like that                                 and uh the amount of data waiting in the                                 queue                                 went up in kafka and we                                 started the recovery and ended the                                 recovery here                                 the total time for recovering this took                                 six hours because as the cl as we were                                 trying to                                 recover data we had new data coming in                                 so there was a lot of load on the system                                 let's look at how the new system is                                 handling                                 similar outages so here is the new                                 system                                 you can see it looks a bit different                                 here's an outage that started again we                                 had some downtime with something in the                                 system                                 and here's where the recovery completed                                 notice                                 that from the time we started to recover                                 data                                 it took about                                                           the data                                 and the the reason is here you can even                                 see this on the graph                                 we had five concurrent isolated spark                                 clusters working in parallel                                 uh chugging along at the data and as a                                 result we completed processing                                 all of that outage and recovered the                                 data within                                                                                                      hours before                                 that's about an                                                        in the in our recovery times which is                                 awesome                                 and because we have a retention a time                                 limit                                 of the data this is a huge improvement                                 for us                                 in this new system let's look at the                                 cluster utilization which was really                                 critical for us                                 he don't mention that in the past while                                 we were doing streaming and the cluster                                 was pretty rigid                                 uh we had a lot of times where the                                 cluster was underutilized                                 here this is a a ganglia which basically                                 gives you metrics about                                 the spark clusters you can see                                 that the cluster here is very once it                                 starts processing the data which is that                                 plateau on top                                 uh it's very stable and it keeps uh                                 working at a high utilization in this                                 case it's a over                                            but in some of the other cases it's it's                                 higher than that and                                 over                                                                     and if you look at this part this shows                                 you the load on each of the servers and                                 the clusters                                 in the cluster it's uh it's all red                                 which means they are highly utilized                                 again this is great the clusters are                                 much better utilized                                 and very consistently over time exactly                                 what we wanted                                 all right let's talk about some of the                                 key insights                                 from this project and what you can take                                 with you about the comparison between                                 streaming and batch so the first thing                                 streaming is expensive and in many cases                                 it might not be worth doing unless you                                 really                                 need it for real-time data consider if                                 you really want to go with streaming                                 the other thing is fixed clusters are                                 never perfect                                 during off hours they're very expensive                                 because we have                                 too much capacity that is not really uh                                 used and is the cluster is basically                                 idling away your money                                 and when we have a lot of high loads uh                                 they are too slow to a to process all                                 the data quickly                                 another critical insight is that                                 recovery is critical to manage                                 you really want to man you plan this                                 when you do your architecture                                 this is not something you want to leave                                 as an afterthought                                 to deal with later if you want to have a                                 good life and                                 not too many distractions during your                                 holidays and vacations                                 you definitely want to deal with this in                                 your architecture and make sure that                                 recovery is                                 easy and quick and the last thing is if                                 you introduce isolation and parallelism                                 in your processes and your data                                 pipelines                                 it really allows you to easily scale                                 save on costs and deal with loads                                 in our case the way we approach this is                                 basically                                 splitting the data between fixed time                                 frames                                 in time slots and that gave us the                                 isolations between                                 all the tests and they could be run in                                 parallel in your projects it might be                                 something else that will allow you                                 but you definitely want to think about                                 it                                 all right let's summarize so here are                                 the things we talked about                                 in this talk first the differences                                 between streaming and batch                                 some of the trade-offs and things you                                 should consider when planning                                 such systems we explored one of our                                 projects that                                 used to be a stream and we moved it to a                                 batch                                 and showed you some of the advantages we                                 gained by doing this                                 and we went over some architecture                                 insights that you can take to your own                                 projects                                 conclusions are that streaming has some                                 downsides                                 always think if you really need it uh                                 batch can sometimes be an                                 alternative i'm not saying always                                 because some times you                                 really do need streaming but batch is a                                 definitely a viable alternative                                 and you should also always consider the                                 costs the loads on the system                                 how to recover data and your uptime of                                 the system                                 if you want to learn more here are two                                 talks by colleagues of ours                                 streaming with spark and kafka just                                 follow the tiny url                                 and airflow kubernetes and spark another                                 interesting talk                                 uh by them and if you really want to                                 reach us we're available on linkedin                                 here are handles uh of me my handle                                 and ido idose so feel free to reach out                                 to us                                 all right so with that we'll summarize                                 uh we'll conclude                                 thank you very much for coming to our                                 talk                                 okay so we are now in the qa session uh                                 i just checked and i didn't see any                                 questions so far                                 so i will probably do one question                                 myself because i'm curious                                 did you try with this approach uh to use                                 like                                 more things like spot instances or                                 things like that just to reduce cost                                 good question you know you want to take                                 this because you dealt a lot with the                                 spots                                 yeah uh so we did you                                 we use spot instances we actually is                                 using sport instances even now                                 uh but we we did                                 we did see that                                 we were losing sports instances all the                                 time                                 so that was a problem                                 now when you instead of running in                                 a clustered run cluster that's running                                 all the time using spot instances that                                 might                                 fail and then you need to recover from                                 the                                 spot instance if you run it in small                                 small ones like shorten rounds around                                 like                                 run every hour but only for                                                                                                  unlikely to it's unlikely that the                                 the spot will be lost so it's like even                                 more uh                                 resilient yeah can i expand on this you                                 know i i want                                 the old process that was in streaming we                                 used odds but                                 because it was a long running process                                 like you just said we kept losing uh                                 spots and we had to deal with this it                                 was difficult                                 with the batch process because it's                                 short it can recover if you lose spots                                 it's not a big deal                                 we still use spots but we don't have all                                 these problems we had in the past                                 but i also want to mention we're also                                 using instant fleets which                                 makes it easier and think about it                                 instance fleets give you                                 spots depending on availability and                                 we're starting a cluster every hour                                 which means that one cluster may use a                                 certain instance type                                 another one that starts later on may use                                 something else                                 so this is really awesome                                 okay i have another question is uh why i                                 mean                                 in this in the batch case i suppose it's                                 better to have like uh                                 stronger machines like beefier machines                                 somehow or what was your experience                                 about this                                 uh the nice thing about it is that you                                 don't have to use beefier machines                                 because if you remember because of the                                 isolation                                 each batch is working independently each                                 batch has                                 one hour of data and then it could work                                 as long as it needs                                 so if you have beefier machines maybe it                                 will finish processing in                                               you have weaker machines it may take an                                 hour and a half                                 so the the nice thing about it we                                 basically                                 disconnected the dependency between the                                 amount of data and the                                 type of machines you use and now you can                                 use really                                 you can choose the machines depending on                                 the cost whatever is the cheapest for                                 you                                 in terms of total cost you can use                                 because we are now                                 independent of the machine type which is                                 really really a nice by the way                                 we this helped us save a lot a lot of                                 the savings came from                                 a toying with spots and instances and                                 things like that that we had a hard time                                 doing before                                 okay okay thanks let me just check if                                 there is another question                                 yes uh there are two uh how many                                 partitions were present                                 in the kafka topic for the batch                                 solution given a time range                                 for example one hour how do you                                 determine what offsets                                 do you read from okay cool                                 you know you want to take this i think                                 you love this question yes so                                 uh we're we're using airflow to                                 spin up the cluster every hour so we use                                 airflow                                 timing that tells us                                 like the when to start and when when to                                 end                                 and then we use kafka to convert                                 the the the timestamp to actually                                 uh kafka offsets like each one of the                                 partitions                                 uh as its own manage its own offset                                 right so                                 when you go to kafka and ask for a                                 and the offsets for a specific time                                 time frame it will give you a different                                 offset starting                                 and offsets for each partition                                 and this is how we do that so                                 yeah so in the past in ido can you mute                                 so                                 we don't have the echo in the past we                                 had the                                 we were just reading offsets in kafka                                 for each partition                                 and using that to read the data now that                                 we use the fixed time slots                                 we basically go to kafka ask it                                 which offset is the specific time we                                 want to start and end and use that                                 for reading regarding the other question                                 you asked how many partitions we have                                 so we currently have a                                                 in kafka for the big                                 topics and as a result we're also using                                 clusters with a slightly more cores than                                 that                                 so each core each executor is basically                                 going to one partition and reading it                                 you
YouTube URL: https://www.youtube.com/watch?v=s40DCqQZDr8


