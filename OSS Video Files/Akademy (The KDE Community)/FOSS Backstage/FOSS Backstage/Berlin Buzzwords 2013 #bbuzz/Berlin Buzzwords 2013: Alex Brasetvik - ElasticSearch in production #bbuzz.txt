Title: Berlin Buzzwords 2013: Alex Brasetvik - ElasticSearch in production #bbuzz
Publication date: 2013-06-19
Playlist: Berlin Buzzwords 2013 #bbuzz
Description: 
	This talk covers some of the lessons we've learned from securing and herding hundreds of ElasticSearch clusters. It is applicable whether you operate ElasticSearch in your own infrastructure, in the cloud, or if you're a developer who wants a better understanding of ElasticSearch various failure modes.

ElasticSearch easily lets you develop amazing things, and it has gone to great lengths to make Lucene's features readily available in a distributed setting. However, when it comes to running ElasticSearch in production, you still have a fairly complicated system on your hands: a system with high expectations on network stability, a huge appetite for memory, and a system that assumes all users are trustworthy.

Instead of delving deeply into a few specifics, we give a brief overview of problems you are likely to run into and suggested solutions to these problems. We cover topics that are applicable to both developers and users with ElasticSearch clusters of every shape and size -- with an emphasis on resiliency and security.

Read more:
https://2013.berlinbuzzwords.de/sessions/elasticsearch-production

About Alex Brasetvik
https://2013.berlinbuzzwords.de/users/alex

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	                              so elasticsearch in production is                               ultimately about keeping your end users                               happy and if you ask your marketing                               departments what your users feel like                               they might show you pictures of happy                               people smiling of salads or something                               whereas we as developers or operations                               people sometimes feel things aren't                               completely on track my name is Alex I                                work for pound I've been working with                                search for most of my career did some                                database systems before that I found we                                manage lots and lots of elastic search                                clusters on Amazon's Cloud and when I'm                                not working with search I like to jump                                out of planes and play with the other                                kind of cloud luckily my parachute is a                                bit more stable than amazon's instances                                but it's a good idea to have a reserve                                or a back-up plan regardless of a kind                                of cloud you play with so running lots                                of clusters of various sizes and high                                availability needs we've seen lots of                                different operational challenges but                                also a few misconceptions people have                                about running or using elastic search                                these fall into these categories and                                while                                                                 them thoroughly what follows is more of                                an overview of things you want to learn                                more about first out on memory memory is                                important not just to keep predictable                                performance but also for your clusters                                reliability search engines have a huge                                appetite for memory to keep the                                responses as fast as they do all the                                good stuff has to be in memory so they                                spend lots of effort building and                                continuously maintaining various caches                                like                                filter caches field caches for sorting                                faceting and scripting they assume your                                operating system has enough memory to                                keep out parts of your indices in the                                page cache and also building in excess                                requires lots of memory just for                                comparison postgres is extremely                                cautious when it comes to resource usage                                if it finds it cannot do the operation                                completely in memory it'll do it in                                steps washing to disk it'll get slower                                but it'll continue working whereas                                search engines like elastic search are                                built for speed they have faith in you                                as the user that you've provided it with                                enough memory to do whatever you ask of                                them so if you try to do an impossible                                query with the elastic search like facet                                on a way to large field it'll try and                                eventually blow up with an out of memory                                area and when that happens depending on                                what else is happening in your system at                                the same time a number of bad things can                                happen in the best case your indexing or                                search request will simply fail but                                we've also seen things like cluster                                state corrupted to the point where a                                full cluster restart is necessary and                                Nettie has crashed so the you know it is                                isolated and lots of other things so you                                do not want to end up with any out of                                memory error on your production cluster                                elastic search provides lots of                                endpoints that give you insights into                                its resource usage like cache sizes and                                EEP space usage and more and more                                monitoring systems know how to use these                                so you want to be continuously                                littering your resource usage because                                when you outgrow the page cache on your                                system you'll see a gradual decline in                                performance as more and more requests                                will hit disk whereas when you no longer                                have enough heap space it's more of a                                sudden event you can be serving searches                                with great performance until suddenly                                some out of memory error causes things                                to come crashing down consequently it's                                important to understand the memory                                profile of your searches say for example                                that you're tweaking your relevance                                model and improve some script to use                                another field then your crease needs                                more memory to execute and memory users                                will grow faster as more data comes into                                your system so as you tweak and improve                                your searches in a development or                                staging environment it's important to                                keep your data set realistic resize so                                 we know the true memory usage of your                                 queries before you let them loose on                                 your production cluster having memory                                 efficient queries is a good idea anyway                                 as they tend to be more performant as                                 well so it would be great if you could                                 just throw lots of memory or money at                                 the problem and just forget about it but                                 you can actually have too much memory on                                 a single node as you increase the heap                                 space of your jvm garbage collection                                 becomes more expensive and these garbage                                 collection process can cause impede                                 performance but also cascade to to                                 bigger problems so if your heap space                                 crosses                                                                longer use or the JVM you no longer use                                 pointer compression so we need to jump                                 to around forty eight gigs to actually                                 get more usable heap space and then                                 garbage collection can become more                                 problematically expensive so at that                                 point you may want to actually run                                 multiple nodes on the same physical                                 machine test things obviously to find                                 what fits your case but elasticsearch is                                 built for scaling out and not up so                                 shard appropriately and if you do run                                 multiple nodes on the same physical                                 machine remember to route the replicas                                 correctly so you don't have a single                                 point of failure so that's a lot of                                 memory things continuing with security                                 considerations when running                                 elasticsearch elasticsearch basically                                 has a believes every user to be                                 trustworthy it doesn't have any features                                 to do authentication or authorization it                                 doesn't consider that to be its job                                 which is perfectly fine so we developers                                 need to understand what we can and                                 cannot safely pass on to elasticsearch                                 and a question we often get is whether                                 it's safe to limit access to certain                                 points of of certain indices optionally                                 also wrapping the queries with a filter                                 to limit what the users in searching and                                 first there's the case where a user                                 tries to pass it or sort on them in two                                 large field causing memory problems like                                 they've been through but there's also                                 dynamic scripts elasticsearch has really                                 powerful scripting facilities and while                                 you typically use these for fancy assets                                 or scoring it's important to                                 they're not sandbox so there's nothing                                 preventing a nefarious user from doing                                 whatever the elastic search houses has                                 access to and this includes amble and                                 not just the other language plugins and                                 this is also true when you run elastic                                 search locally for development purposes                                 any website can do n request to                                 localhost and access your data or run                                 code so I advise running things in a                                 virtual machine and to be careful what                                 you have when you run things locally                                 elasticsearch works great on a single                                 node but most people want to scale out                                 that at some point and elasticsearch is                                 impressively easy to use for being a                                 distributed system but it's still dis                                 distributed so and they tend to fail in                                 many ways elasticsearch at has lots of                                 knobs you can tweak it supports lots of                                 different usage patterns it can be                                 lenient and it can be strict or anything                                 in between so we need to adapt these to                                 your needs so this is a setup we see                                 quite a lot you have a node and because                                 you're tired of waking up in the middle                                 of every night you had a replica so this                                 is supposed to be a high-availability                                 setup and if all you do is search this                                 is fine you can lose a node and the                                 other one can continue answering but if                                 you're continuously indexing as well you                                 need to have a majority of nodes                                 available if not you're prone to split                                 brain situations and a split brain                                 occurs when you have sub clusters                                 forming believing they're autonomous and                                 this in turn can lead to irrecoverable                                 data loss so unless you're sure you                                 don't need a majority configure minimum                                 masternodes to be at least half the                                 notes plus                                                              have to be an expensive fully fledged                                 node it can be a cheap node that is                                 mostly idling and when a network                                 partition happens it can break the ties                                 of the master election to ensure you                                 have a majority this applies to                                 availability zones as well if you're                                 running across data centers if you have                                 two nodes in two different zones you can                                 lose either of them and still have a                                 majority but if you run a tiebreaker                                 from a third location you can lose any                                 of the three availability zones and                                 network network partitions and instances                                 crash in lots of different ways it's                                 important to know the failure modes of                                 your underlying infrastructure for                                 example if you're on easy to they do not                                 guarantee that to physic to virtual                                 instances do not have any kind of single                                 point of failure unless they're in                                 different availability zones if you're                                 on a large scale you'll see single lane                                 sis's crash all the time whereas if                                 you're smaller you might experience                                 complete some failures just as often and                                 then these happens you get thundering                                 herd effects as everybody else is                                 scrambling to recover and repair their                                 systems so if you have a mission                                 critical system or just like to sleep at                                 night it's important to have your high                                 availability set up before you actually                                 need it you cannot necessarily rely on a                                 quick repair so assuming you have a                                 stable cluster there's still a few                                 things you need to do on the client side                                 to keep things resilient and performant                                 any requests with side effects should be                                 idempotent meaning you can retry the                                 request if if necessary for except for                                 example if you post the document to an                                 index and you don't get a response you                                 can't know whether the document was                                 indexed nor that it wasn't index and if                                 you leave for example to elasticsearch                                 to assign ids to the document you cannot                                 retry without risking duplicates                                 so keep things retrial if you use the                                 HTTP interface make sure your client                                 library uses a connection pool if not                                 you'll be paying for connection                                 establishment for every single request                                 which is expensive especially if you're                                 using SSL as well the key exchange                                 ceremony takes a lot of time there's a                                 bulk interface we see a surprisingly                                 large number of users not using it it's                                 a lot more efficient when you have lots                                 of data to next at the same time so if                                 you're not already using it check it out                                 but do remember to to actually inspect                                 the responses of the build request as a                                 single sub operation paling will not                                 cause the entire your request to fail                                 there's a similar interface for searches                                 so if you need to do multiple search                                 requests to satisfy your users                                 information need you can use em search                                 and do them in and parallel so in                                 summary elastic search provides great                                 features at great speeds and scale but                                 with anything fast and fun it's                                 important to take a few precautions to                                 stay out of trouble but if you have                                 enough memory to keep your notes                                 reliable you have a nice enough nodes to                                 have a majority when networks fail you                                 carefully sanitize the requests you send                                 to elasticsearch and do things in a                                 reliable way elasticsearch will take you                                 really far                                 there should be some time for questions                                 thanks for listening I'll be available                                 at sounds food as well today and                                 tomorrow so stop by and say hi or thanks                                 you
YouTube URL: https://www.youtube.com/watch?v=gkdfNl0WL-A


