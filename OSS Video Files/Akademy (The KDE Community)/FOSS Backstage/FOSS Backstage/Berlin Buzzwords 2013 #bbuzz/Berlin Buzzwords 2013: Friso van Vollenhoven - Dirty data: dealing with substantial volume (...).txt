Title: Berlin Buzzwords 2013: Friso van Vollenhoven - Dirty data: dealing with substantial volume (...)
Publication date: 2013-06-19
Playlist: Berlin Buzzwords 2013 #bbuzz
Description: 
	Full title: Dirty Data: Dealing With Substantial Volume External Sources

At a large European publisher, we had the challenge of receiving external data from 10+ different sources, adding up to tens of GBs per day. Add to this that the file formats will sometimes change without notifications and that sometimes connections go bad or files go missing. This is while trying to maintain that at least the amount of data is near correct in an environment where the 'correct' amount of data for a source is often a difficult to predict number somewhere between 20M and 50M records for a particular day.

We built a extracting and loading pipeline to get data into Hadoop en expose it via Hive tables, which includes scheduling, reporting, monitoring, transforming and, above all, the ability to respond to changes very quickly. After all, responding to a file format change within the same day or adding a new source in a day are very reasonable user requests (right). We were focused on developer friendliness and rely on a fully open source stack, using Hadoop, Hive, Jenkins, various scripting languages and more.

Read more:
https://2013.berlinbuzzwords.de/sessions/dirty-data-dealing-substantial-volume-external-sources

About Friso van Vollenhoven:
https://2013.berlinbuzzwords.de/users/friso

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
YouTube URL: https://www.youtube.com/watch?v=qYshvXej004


