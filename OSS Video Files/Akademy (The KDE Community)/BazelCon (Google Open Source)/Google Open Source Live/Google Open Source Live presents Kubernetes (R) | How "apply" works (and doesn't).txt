Title: Google Open Source Live presents Kubernetes (R) | How "apply" works (and doesn't)
Publication date: 2021-01-11
Playlist: Google Open Source Live
Description: 
	
Captions: 
	00:00:11,120 --> 00:00:16,320
Welcome, my name is Antoine Pelisse and I'm a software engineer at Google.

00:00:16,320 --> 00:00:20,720
I'm going to talk to you today about how "apply" works, and doesn't

00:00:20,720 --> 00:00:23,760
and how hopefully a server-side apply will save us all.

00:00:24,640 --> 00:00:28,720
So, today I'm going to talk about declarative configuration a lot

00:00:28,720 --> 00:00:32,640
because I think it's very important to how Kubernetes works

00:00:32,640 --> 00:00:36,480
and how foundational it is to its success

00:00:36,480 --> 00:00:39,040
and how it's going to be successful in the future.

00:00:39,680 --> 00:00:42,960
So, after describing what declarative configuration is

00:00:42,960 --> 00:00:47,520
I'm going to talk to you about the implementation that we have in kubectl

00:00:47,520 --> 00:00:51,600
which is how we initially implement the mechanism

00:00:52,160 --> 00:00:55,920
and then I'm going to talk about some of the limitations that we found

00:00:55,920 --> 00:00:58,880
and how we tried to solve them with server-side apply.

00:01:00,400 --> 00:01:04,080
So, what is declarative configuration, and why is it so important?

00:01:05,040 --> 00:01:09,520
I think Brian Grant described it very well in 2014 when he said

00:01:09,520 --> 00:01:13,520
"We want to support management of services via declarative configuration."

00:01:13,520 --> 00:01:17,520
I want to show that this is foundational to Kubernetes.

00:01:17,520 --> 00:01:22,640
This is back in the day, at the very beginning of the project in 2014.

00:01:22,640 --> 00:01:25,840
And this is key to Kubernetes and how it's configured.

00:01:26,560 --> 00:01:31,760
In my opinion, Kubernetes is not just about configuring workloads on the cloud.

00:01:31,760 --> 00:01:35,120
It's very much about how configuration works

00:01:35,120 --> 00:01:38,400
and how you decide what you want the system to look like.

00:01:39,600 --> 00:01:42,960
And so I'm going to focus on that specifically today.

00:01:42,960 --> 00:01:44,640
So, what's declarative configuration?

00:01:46,080 --> 00:01:50,080
We can see on the left, we have a configuration return as YAML.

00:01:51,760 --> 00:01:54,320
And this is declarative. Why is it declarative?

00:01:54,320 --> 00:01:58,160
It's declarative because we do not specify

00:01:58,160 --> 00:02:02,400
how the number of replicas, for example, in this example

00:02:03,200 --> 00:02:04,480
is supposed to change

00:02:04,480 --> 00:02:07,280
but we describe what the value should be.

00:02:07,280 --> 00:02:12,240
So if your system has currently one pod, and we apply this configuration

00:02:12,240 --> 00:02:15,200
we know that we want to increase the number of pods by two.

00:02:15,200 --> 00:02:16,960
But this is not how we describe it.

00:02:16,960 --> 00:02:18,800
We don't describe the fact that

00:02:18,800 --> 00:02:20,880
you have to increase the number of replicas by two.

00:02:20,880 --> 00:02:23,360
We describe the fact that we want to have three.

00:02:23,360 --> 00:02:25,040
And this is very important.

00:02:26,080 --> 00:02:28,160
This is very important for many reasons.

00:02:28,160 --> 00:02:30,240
One of them is that this is repeatable.

00:02:30,800 --> 00:02:34,880
We can do the same thing again and again

00:02:34,880 --> 00:02:38,480
without knowing about the existing contexts of the cluster

00:02:38,480 --> 00:02:42,480
and so this is going to apply to any cluster in the exact same way.

00:02:42,480 --> 00:02:46,640
So, for example, if you want to recover from a broken cluster

00:02:47,920 --> 00:02:50,560
you're going to just have to reapply that configuration

00:02:50,560 --> 00:02:52,080
that you know works well

00:02:52,080 --> 00:02:56,000
and it's going to go back to that state that you know is good.

00:02:56,720 --> 00:02:58,720
If you want to share the configuration with someone

00:02:59,360 --> 00:03:02,640
they can apply the configuration and they're going to have the same state.

00:03:02,640 --> 00:03:04,480
At least they should have the same state.

00:03:05,840 --> 00:03:11,120
It's very typical for people in companies to want to create testing environments

00:03:11,120 --> 00:03:16,320
and they usually want their environments to be very similar for production and testing

00:03:16,320 --> 00:03:17,840
so they know that they're testing the right thing.

00:03:18,480 --> 00:03:23,520
And so, again, repeating the production cluster into a test cluster

00:03:23,520 --> 00:03:25,520
is very convenient and frequent.

00:03:26,640 --> 00:03:30,160
Migrations, obviously, if you want to migrate from one cloud provider

00:03:30,160 --> 00:03:31,520
from one cluster to another

00:03:31,520 --> 00:03:33,760
that's very convenient that this is repeatable.

00:03:35,520 --> 00:03:38,640
Because this is text and because this is easy to read

00:03:38,640 --> 00:03:41,840
it's very easy to review and commit to a Git repository.

00:03:41,840 --> 00:03:46,800
So this is very much done for the GitHub workflows

00:03:46,800 --> 00:03:49,280
where you push the change to a Git repository

00:03:49,280 --> 00:03:52,160
and then it's reviewed by your peers.

00:03:52,880 --> 00:03:56,720
It's easy to review because, again, we don't care about the context

00:03:56,720 --> 00:03:58,720
or the current state of the cluster.

00:03:58,720 --> 00:04:00,240
We only care about what you want.

00:04:00,960 --> 00:04:02,240
You want true replicas.

00:04:02,240 --> 00:04:03,520
Is that a good value or not?

00:04:04,080 --> 00:04:06,720
The person who reviews doesn't need to know anything else

00:04:06,720 --> 00:04:10,480
other than is this the value you want?

00:04:10,480 --> 00:04:13,120
And it's also easy for tools to validate, for example

00:04:13,120 --> 00:04:17,600
because they can just parse this file, look at the value of replicas

00:04:17,600 --> 00:04:20,160
and make sure that it validates a specific policy.

00:04:20,160 --> 00:04:21,600
So, you could have a policy

00:04:21,600 --> 00:04:25,680
that says we must have the number of replicas bigger than three

00:04:25,680 --> 00:04:27,040
and less than 10.

00:04:27,040 --> 00:04:30,400
And here is very easy to write a tool that is going to parse this YAML

00:04:30,400 --> 00:04:31,760
look at the number of replicas

00:04:31,760 --> 00:04:34,720
and make sure that it validates that policy.

00:04:35,600 --> 00:04:38,240
Because it's repeatable, it's also very easy to roll back.

00:04:39,440 --> 00:04:42,880
And Git typically provides this kind of workflow

00:04:42,880 --> 00:04:44,880
so you just have to reverse your commit

00:04:44,880 --> 00:04:46,880
go back to a state that you know works well

00:04:46,880 --> 00:04:51,760
and hopefully everything is going to go back to a good state that we know works.

00:04:52,960 --> 00:04:56,960
I'm going to emphasize specifically that this is what I call data.

00:04:56,960 --> 00:05:02,000
And why I call this "data" rather than "code," for example

00:05:02,000 --> 00:05:04,880
is that this is very easy to parse

00:05:04,880 --> 00:05:08,480
deserialize, and serialize in any common language.

00:05:09,680 --> 00:05:13,760
If we were to use Python for the configuration

00:05:14,320 --> 00:05:18,800
I claim that it would be much harder for any language

00:05:18,800 --> 00:05:20,000
to be able to parse that.

00:05:20,560 --> 00:05:23,840
It's very difficult in any language

00:05:23,840 --> 00:05:26,240
let's say JavaScript, for example

00:05:26,240 --> 00:05:29,920
to parse Python, look for the replicas field

00:05:29,920 --> 00:05:32,800
see that the value is actually a statement

00:05:32,800 --> 00:05:34,960
which may be a function, for example

00:05:34,960 --> 00:05:36,880
and then if you want to see what the value is

00:05:36,880 --> 00:05:39,040
you have to evaluate this statement

00:05:39,040 --> 00:05:43,040
which you can do in JavaScript if the statement is Python.

00:05:43,040 --> 00:05:48,000
There is no Python parse or return in every language that we know of.

00:05:48,000 --> 00:05:52,320
But there is a parser for YAML, hopefully in most languages

00:05:52,960 --> 00:05:55,200
and they're usually very easy to use

00:05:55,200 --> 00:05:58,080
and changing a single value is typically very easy.

00:05:59,040 --> 00:06:03,040
So, now if you want to write a tool that is going to look for this value

00:06:03,040 --> 00:06:07,520
it's much easier if the configuration was written as Python

00:06:07,520 --> 00:06:08,800
or any other language

00:06:08,800 --> 00:06:11,760
because typically languages are not easy to parse.

00:06:14,000 --> 00:06:16,240
This is very convenient for collaboration

00:06:17,120 --> 00:06:20,720
because we want people to collaborate on their configuration

00:06:20,720 --> 00:06:24,560
and we want people to collaborate with machines on their configuration.

00:06:24,560 --> 00:06:27,760
So, we want people and tools to be able to look at the config

00:06:27,760 --> 00:06:30,880
make changes, validate, update as needed

00:06:30,880 --> 00:06:35,600
based, maybe, on a state that could be continuously reconciled.

00:06:35,600 --> 00:06:40,320
And so, an example of that would be a horizontal pod autoscaler

00:06:40,320 --> 00:06:42,320
which would look at the state of your cluster

00:06:42,320 --> 00:06:46,480
and update the value of replicas based on the workload on the cluster

00:06:46,480 --> 00:06:49,120
to suit the current need.

00:06:51,920 --> 00:06:54,640
There are challenges with declarative configuration though.

00:06:55,760 --> 00:07:00,640
There is no typical endpoint in CRUD APIs for declarative endpoints.

00:07:00,640 --> 00:07:03,920
You can create, you can read, you can update, you can delete

00:07:03,920 --> 00:07:06,720
but there is no way to say, hey, this is what I want

00:07:06,720 --> 00:07:11,040
this is what I care about, just do the right thing, do what I need.

00:07:11,040 --> 00:07:14,240
There is no such thing with CRUD APIs.

00:07:14,240 --> 00:07:15,920
So, one example of that is

00:07:15,920 --> 00:07:19,600
that we don't know if the resource needs to be created or updated.

00:07:19,600 --> 00:07:22,320
You have to look if this resource exists.

00:07:22,880 --> 00:07:24,480
If it doesn't, then I'm going to create it

00:07:24,480 --> 00:07:26,240
but then you can have a raise condition.

00:07:27,040 --> 00:07:30,320
This is much more complicated than it looks.

00:07:30,320 --> 00:07:33,440
If you want to update the resource now, it's difficult

00:07:33,440 --> 00:07:38,960
because typically, updating a CRUD API is going to replace the entire object

00:07:38,960 --> 00:07:41,600
and if you only care about specific fields

00:07:41,600 --> 00:07:43,680
and because we want it to be collaborative

00:07:44,320 --> 00:07:46,400
you probably only care about some specific fields.

00:07:46,400 --> 00:07:49,600
Maybe some controllers care about other values in the same object.

00:07:49,600 --> 00:07:53,120
So, we never want to replace the entire object.

00:07:53,120 --> 00:07:54,320
So, we want to merge them.

00:07:55,040 --> 00:07:59,760
For that we have PATCH, but PATCH is very imperative in nature.

00:07:59,760 --> 00:08:03,200
You have to look specifically at the changes that you want to make

00:08:03,200 --> 00:08:04,480
and then apply them.

00:08:05,360 --> 00:08:08,320
There is JSON Merge Patch that does that

00:08:08,320 --> 00:08:10,320
but it doesn't work very well on lists.

00:08:11,120 --> 00:08:14,320
Kubernetes has tons of lists for many reasons.

00:08:14,320 --> 00:08:16,800
It uses associative lists, as you know.

00:08:17,680 --> 00:08:20,560
This is the type of list where the name is actually the key.

00:08:20,560 --> 00:08:22,560
They'll map "hidden" inside a list.

00:08:23,440 --> 00:08:26,800
And JSON Merge Patch just replaces lists altogether.

00:08:27,520 --> 00:08:29,280
If you apply your list in JSON Merge Patch

00:08:29,280 --> 00:08:31,440
it's going to replace the entire list.

00:08:31,440 --> 00:08:34,640
So, if a controller has added anything to the list

00:08:34,640 --> 00:08:36,080
it's going to be overridden.

00:08:37,440 --> 00:08:42,400
So, all of that to say that, basically, it's very hard not to hinder collaboration

00:08:43,040 --> 00:08:44,480
when creating such a system.

00:08:45,120 --> 00:08:48,240
The initial implementation of kubectl apply

00:08:48,800 --> 00:08:52,800
is written on the client and traced to address some of these challenges.

00:08:54,240 --> 00:08:55,600
Here we can see from this tweet

00:08:56,560 --> 00:09:01,120
that kubectl apply is the solution to what I just described.

00:09:01,120 --> 00:09:03,600
It's the declarative configuration tool.

00:09:03,600 --> 00:09:05,840
It allows you to repeat.

00:09:05,840 --> 00:09:08,720
You can take your cluster, make some changes

00:09:08,720 --> 00:09:10,880
apply them to a different cluster

00:09:10,880 --> 00:09:13,680
and hopefully everything is going to just work.

00:09:15,280 --> 00:09:18,400
This is obviously very different from reality

00:09:18,400 --> 00:09:19,520
where you have storage

00:09:19,520 --> 00:09:22,160
and clusters are typically slightly different from each other

00:09:23,040 --> 00:09:25,280
so you need to have some adjustments.

00:09:25,280 --> 00:09:26,720
But basically, this is the idea.

00:09:26,720 --> 00:09:31,200
It's still much easier than taking a lot of code to generate the config

00:09:31,200 --> 00:09:35,920
and making sure it applies properly to a different context.

00:09:35,920 --> 00:09:36,960
So, how does this work?

00:09:38,800 --> 00:09:40,160
How do we apply?

00:09:40,160 --> 00:09:44,800
We do apply by running kubectl apply command.

00:09:44,800 --> 00:09:47,280
And you can apply these to many configurations.

00:09:47,280 --> 00:09:49,600
This is convenient, because again

00:09:49,600 --> 00:09:52,560
we don't have to look at each individual configuration

00:09:52,560 --> 00:09:56,320
and decide if they need to be created or updated.

00:09:58,720 --> 00:10:02,320
This is obviously not meant at all for imperative commands

00:10:02,320 --> 00:10:07,440
e.g. you can't apply "charge credit card" or "open this door."

00:10:07,440 --> 00:10:12,480
Though if you wanted to do open doors, you could rephrase this and say "door open"

00:10:12,480 --> 00:10:14,800
and that would be either true or false

00:10:14,800 --> 00:10:17,840
and this would automatically become declarative.

00:10:18,960 --> 00:10:20,800
This is much more collaborative too

00:10:20,800 --> 00:10:23,680
because it allows us to change any specific fields

00:10:24,800 --> 00:10:27,040
rather than replacing the entire object.

00:10:27,680 --> 00:10:29,040
We'll see in the next slide

00:10:29,040 --> 00:10:31,840
but basically, kubectl apply sends a patch

00:10:31,840 --> 00:10:35,040
and it's literally trying to look at each individual field

00:10:35,600 --> 00:10:37,120
see which ones have changed

00:10:37,120 --> 00:10:41,680
and update the object by sending a patch to change these values.

00:10:42,800 --> 00:10:46,400
The way it decides what has changed and what needs to change

00:10:46,960 --> 00:10:49,360
is based on what you had applied before.

00:10:49,360 --> 00:10:54,160
And so, for that, we save the object the way you had it before

00:10:54,160 --> 00:10:58,720
in the object itself and all these last applied annotations.

00:10:58,720 --> 00:11:00,080
So, you can see here

00:11:00,080 --> 00:11:02,320
we have the entire object that we've seen before

00:11:02,880 --> 00:11:06,160
inside the annotation, saved in the object.

00:11:06,160 --> 00:11:11,440
This is literally how we save the old configuration in Kubernetes

00:11:12,080 --> 00:11:13,680
with kubectl apply.

00:11:13,680 --> 00:11:14,480
How does it work?

00:11:14,480 --> 00:11:17,840
So, we can see on the left that we get the object from the server

00:11:19,200 --> 00:11:21,680
and we can see that the number of replicas is five

00:11:22,320 --> 00:11:26,960
the image is nginx 1.14.2 and it has a sidecar container.

00:11:26,960 --> 00:11:30,160
I've removed the details of the sidecar because they're not relevant here.

00:11:30,720 --> 00:11:32,160
But we can see that there is a sidecar.

00:11:32,800 --> 00:11:36,640
And we can see in the Before, which is coming from the annotation

00:11:38,480 --> 00:11:40,720
that we had three replicas before

00:11:41,840 --> 00:11:44,240
so probably someone must have changed that value

00:11:44,240 --> 00:11:45,520
since we applied last time.

00:11:46,240 --> 00:11:48,640
And the image hasn't changed.

00:11:48,640 --> 00:11:52,000
We can also see that we didn't apply the sidecar initially

00:11:52,000 --> 00:11:55,600
so someone must have an opinion about this sidecar

00:11:55,600 --> 00:11:56,960
but it's definitely not us.

00:11:57,520 --> 00:12:00,800
And then we can see what is being applied now

00:12:00,800 --> 00:12:02,000
in the third column.

00:12:02,960 --> 00:12:04,800
We still want three replicas

00:12:04,800 --> 00:12:09,040
and we want to update the nginx image to 1.14.3.

00:12:11,120 --> 00:12:13,280
We're going to look at these three different objects

00:12:13,280 --> 00:12:16,720
the Current version, the Before version, and the Applied version

00:12:16,720 --> 00:12:18,960
and we're going to perform a three-way merge.

00:12:20,560 --> 00:12:26,320
We're going to compute this new final object that has the number of replicas equal three

00:12:26,320 --> 00:12:28,240
which is the value that you said you wanted.

00:12:29,120 --> 00:12:33,520
We're going to update the image to nginx 1.14.3 as you wanted

00:12:33,520 --> 00:12:37,200
and we're going to conserve the sidecar container

00:12:37,200 --> 00:12:38,880
because you don't have an opinion about that

00:12:38,880 --> 00:12:40,800
so we don't believe that it should be removed.

00:12:41,360 --> 00:12:43,040
Once we have this new object

00:12:43,040 --> 00:12:45,360
we're going to compare it with the existing object

00:12:46,080 --> 00:12:47,200
compute the difference

00:12:47,200 --> 00:12:51,840
and send that difference as a patch to the server.

00:12:52,800 --> 00:12:57,840
All of that sounds good, but obviously there are limitations with this system.

00:12:57,840 --> 00:13:03,600
The patch that we use to send to Kubernetes has been made by the Kubernetes community

00:13:03,600 --> 00:13:05,600
as the needs were coming.

00:13:05,600 --> 00:13:09,280
We made it in a very homegrown way

00:13:09,280 --> 00:13:12,400
without thinking about all the problems we could have with that

00:13:12,960 --> 00:13:15,920
and obviously, we missed many use cases

00:13:15,920 --> 00:13:19,680
and it became insanely hard to update.

00:13:19,680 --> 00:13:22,880
So one of the problems with the patch strategy that we created

00:13:22,880 --> 00:13:25,200
that is called a strategic-merge patch

00:13:25,200 --> 00:13:29,920
is that if we need to make an update to the strategic-merge patch

00:13:30,960 --> 00:13:33,120
we don't have a way to version this strategy.

00:13:33,120 --> 00:13:37,280
So, if we update the client, then we also need to update the server

00:13:37,280 --> 00:13:40,960
but we also need to make sure that the server and the client match

00:13:40,960 --> 00:13:42,640
and that they use the same version.

00:13:42,640 --> 00:13:45,120
And if they don't, then we need some sort of mechanism

00:13:45,120 --> 00:13:48,880
to know if they use the same version or what version they can use.

00:13:48,880 --> 00:13:50,400
And we don't even know the version anyway.

00:13:50,400 --> 00:13:52,800
So, this was very complicated.

00:13:52,800 --> 00:13:56,720
We needed to make the changes over many versions of Kubernetes.

00:13:56,720 --> 00:13:59,840
Any change required two or three releases

00:14:00,560 --> 00:14:03,200
to make sure that we could propagate the change everywhere

00:14:03,760 --> 00:14:06,240
and this was very complicated.

00:14:07,120 --> 00:14:10,240
Knowing that this was never going to be the good solution anyway

00:14:10,240 --> 00:14:12,640
we never implemented it for custom resources.

00:14:13,520 --> 00:14:15,760
So, that doesn't even work for custom resources.

00:14:15,760 --> 00:14:19,120
You can kubectl-apply custom resources

00:14:19,120 --> 00:14:22,880
but you miss a lot of the possibilities that are available to you

00:14:22,880 --> 00:14:24,880
if you're using a built-in type.

00:14:26,160 --> 00:14:29,600
It also has limitations on the collaboration, to be honest.

00:14:29,600 --> 00:14:32,960
It's not solving all the use cases of collaboration that we had in mind.

00:14:33,760 --> 00:14:36,160
And specifically, because the implementation

00:14:36,160 --> 00:14:37,280
which is very complex

00:14:38,000 --> 00:14:41,280
is specifically made in kubectl in Golang.

00:14:41,280 --> 00:14:44,480
And if you want to use any other language than Golang

00:14:44,480 --> 00:14:46,720
there is no way for you to reuse the algorithm.

00:14:46,720 --> 00:14:51,200
You can maybe create a new process and fog to kubectl

00:14:51,200 --> 00:14:52,400
but that's the only way.

00:14:52,400 --> 00:14:56,320
You can't easily create a tool or a library

00:14:56,320 --> 00:15:00,640
that is going to use apply if it's not written in Golang

00:15:00,640 --> 00:15:03,200
or if it's not using the kubectl binary.

00:15:03,200 --> 00:15:05,840
And that's really detrimental for the ecosystem.

00:15:07,280 --> 00:15:11,040
One of the other challenges is that only one actor can apply.

00:15:11,040 --> 00:15:15,280
So, because we have this annotation that says "This is the last thing that you applied"

00:15:15,920 --> 00:15:18,640
no one else can come and use the same annotation obviously

00:15:18,640 --> 00:15:20,800
because they would just not agree.

00:15:22,800 --> 00:15:24,880
So, we could create maybe another annotation.

00:15:25,680 --> 00:15:30,080
But clearly, the people would take the chance

00:15:30,080 --> 00:15:32,400
and just override their fields constantly.

00:15:32,400 --> 00:15:34,080
If you have an opinion about a field

00:15:34,080 --> 00:15:37,040
and I have a different opinion about the same field

00:15:37,040 --> 00:15:40,400
anytime I'm applying, I'm going to override your change

00:15:40,400 --> 00:15:42,960
and anytime you apply, you're going to override my change.

00:15:42,960 --> 00:15:44,480
And we're going to keep fighting like this

00:15:45,120 --> 00:15:48,960
in a way that is sometimes hard to detect

00:15:48,960 --> 00:15:51,920
and sometimes, even if it's easy to detect

00:15:51,920 --> 00:15:54,320
you may detect it, because you've broken your cluster.

00:15:55,760 --> 00:15:58,560
The fields being overridden unintentionally

00:15:58,560 --> 00:16:01,120
is definitely a big problem for collaboration.

00:16:02,080 --> 00:16:05,360
One very good example of that, again using the replicas field

00:16:05,360 --> 00:16:10,240
is that if, let's say, you created a deployment with three replicas

00:16:10,240 --> 00:16:12,240
and later on you want to use an HPA

00:16:12,240 --> 00:16:14,720
to decide automatically how many replicas you want

00:16:15,440 --> 00:16:17,920
and let's say your system is very successful

00:16:17,920 --> 00:16:20,480
and you end up having 1,000 replicas

00:16:21,200 --> 00:16:26,000
now, when you apply your config, you actually apply three by mistake.

00:16:26,800 --> 00:16:30,480
It's going to override this field, the 1,000 replicas

00:16:30,480 --> 00:16:33,280
and you're going to end up with only three

00:16:33,280 --> 00:16:38,400
which may very well break the system and your customers' use cases.

00:16:38,400 --> 00:16:41,520
So, that's actually quite a terrible bug that we want to avoid.

00:16:43,920 --> 00:16:47,200
Finally, one of the problems we had with this approach

00:16:47,200 --> 00:16:50,720
is, again, we didn't know exactly where we were going to end up

00:16:50,720 --> 00:16:51,920
when we started

00:16:51,920 --> 00:16:54,800
and so, because of this lack of systemic approach

00:16:54,800 --> 00:16:58,480
there are many bugs that are very subtle and hard to fix.

00:16:58,480 --> 00:17:00,960
And an example, again, about these replicas

00:17:00,960 --> 00:17:03,040
and take the same example

00:17:03,040 --> 00:17:06,720
if you had these HPAs set the number of replicas to 1,000

00:17:07,440 --> 00:17:09,360
and you actually remove it from your config

00:17:09,360 --> 00:17:13,600
because you don't want to override it so you remove it from your config and apply

00:17:13,600 --> 00:17:17,920
it's actually going to believe that you want to remove the replicas field

00:17:17,920 --> 00:17:20,240
and the problem is when you remove the replicas field

00:17:20,240 --> 00:17:21,600
it gets defaulted to one.

00:17:21,600 --> 00:17:23,840
So, you break your clusters anyway.

00:17:23,840 --> 00:17:26,320
So, there is actually no way

00:17:26,880 --> 00:17:30,000
or only a very complicated way to solve this problem.

00:17:30,000 --> 00:17:33,280
If you want to remove the replicas field, it's probably going to break something.

00:17:33,280 --> 00:17:36,320
And this is very complicated and unfortunate.

00:17:36,880 --> 00:17:40,800
So, we invented server-side apply, which is a new mechanism for…

00:17:41,600 --> 00:17:44,880
which is a new mechanism for applying to a cluster.

00:17:45,600 --> 00:17:50,480
This works by removing every logic we have in kubectl

00:17:50,480 --> 00:17:51,840
and moving it to the server.

00:17:51,840 --> 00:17:57,360
So, it literally was tripping kubectl from any apply logic, any merge logic

00:17:57,360 --> 00:18:00,160
and we're moving it to the cluster with some changes.

00:18:00,880 --> 00:18:01,760
And so, what did we do?

00:18:02,800 --> 00:18:05,280
We created a new endpoint on the API server

00:18:05,280 --> 00:18:08,640
where you can send your intent and say, "This is what I want

00:18:08,640 --> 00:18:11,440
and this is what I care about. Please do so.

00:18:12,720 --> 00:18:16,080
Do not override anything that I'm not specifying in there.

00:18:16,080 --> 00:18:19,040
If I've removed anything, don't break everything, please!"

00:18:20,160 --> 00:18:22,240
And the server is going to take care of all that.

00:18:22,240 --> 00:18:23,600
It's very convenient

00:18:23,600 --> 00:18:26,000
because now you can write a client without doing anything.

00:18:26,000 --> 00:18:27,520
You just have to send the object.

00:18:27,520 --> 00:18:30,720
You just read the file, send it to the proper endpoint

00:18:30,720 --> 00:18:32,880
and it's going to be applied to the cluster.

00:18:34,240 --> 00:18:35,760
It's as easy as doing curl.

00:18:36,720 --> 00:18:39,920
Curl sends this file to this specific URL and boom…

00:18:39,920 --> 00:18:42,800
you have the file merged on the server properly.

00:18:43,600 --> 00:18:48,160
We've been very careful to keep some compatibility with client-side apply

00:18:48,160 --> 00:18:53,680
and so you can still use these mechanisms, and client-side apply at the same time

00:18:54,720 --> 00:18:56,240
and this is still going to work.

00:18:56,240 --> 00:18:59,600
We're going to be very careful to maintain the last applied annotation

00:19:00,880 --> 00:19:02,240
and you can go back and forth

00:19:03,920 --> 00:19:06,480
so that things still work the way you would expect.

00:19:06,480 --> 00:19:09,600
And if you want to go back and try one and go back to the other one

00:19:09,600 --> 00:19:10,480
it's still going to work.

00:19:10,480 --> 00:19:12,320
So, I think that's a very good feature.

00:19:13,680 --> 00:19:15,040
How does that work?

00:19:15,040 --> 00:19:17,760
Well, because we want the collaborative approach

00:19:17,760 --> 00:19:20,080
we've decided to create managers.

00:19:21,120 --> 00:19:23,760
Managers are actors of the system.

00:19:23,760 --> 00:19:28,000
We believe that configurations have many actors

00:19:28,000 --> 00:19:33,120
acting on the same configuration and we want them to work together well

00:19:33,840 --> 00:19:36,480
and prevent any problem that could happen

00:19:36,480 --> 00:19:40,400
if someone is trying to change a field that you have an opinion about.

00:19:40,400 --> 00:19:43,040
So, each actor in the system has a name.

00:19:43,840 --> 00:19:46,480
As you can see on the left

00:19:46,480 --> 00:19:49,600
we have the manager with the kubectl in this case.

00:19:50,240 --> 00:19:54,560
And each actor has at least a field that they manage.

00:19:54,560 --> 00:19:57,040
It's actually not a list; we could call it a set.

00:19:58,240 --> 00:19:59,680
It's a set of fields.

00:19:59,680 --> 00:20:03,200
And these are the fields that we believe you have an opinion about.

00:20:03,200 --> 00:20:06,160
So, if you apply the configuration that we saw before

00:20:06,160 --> 00:20:08,320
you're going to have an opinion about replicas

00:20:08,320 --> 00:20:11,680
you're going to have an opinion about the container image

00:20:11,680 --> 00:20:12,800
and the container name.

00:20:15,200 --> 00:20:18,000
If someone else has an opinion about the same field

00:20:18,000 --> 00:20:19,840
you're going to get a conflict.

00:20:19,840 --> 00:20:23,120
So, what happens is that if somebody

00:20:23,920 --> 00:20:28,000
for example, the HPA has set the number of replicas to a different value

00:20:28,000 --> 00:20:31,680
we're going to notice that they already care about that value.

00:20:31,680 --> 00:20:34,960
So, as you're trying to change the value of the field

00:20:34,960 --> 00:20:38,960
we will send back an error saying someone already has

00:20:38,960 --> 00:20:41,760
and manages this field, they have an opinion.

00:20:41,760 --> 00:20:44,160
Are you sure you want to change the value?

00:20:44,160 --> 00:20:46,880
Because that can be catastrophic if you do.

00:20:46,880 --> 00:20:49,360
And so, the user has two options.

00:20:49,360 --> 00:20:54,480
They can decide to remove the value from their file

00:20:55,040 --> 00:20:58,480
in which case they can then reapply and they're not going to get a conflict

00:20:58,480 --> 00:20:59,840
because they literally said

00:20:59,840 --> 00:21:02,640
"Yeah, indeed, I don't have an opinion about the replicas anymore.

00:21:02,640 --> 00:21:04,160
Let the system decide.

00:21:04,160 --> 00:21:06,080
If someone else has an opinion

00:21:06,080 --> 00:21:09,040
I trust them to have a better opinion than I do.

00:21:09,040 --> 00:21:09,840
Let them do it."

00:21:10,640 --> 00:21:14,640
Or you can use the force flag, which is going to force the value.

00:21:14,640 --> 00:21:17,840
In this case, we'll literally take the value of replicas

00:21:17,840 --> 00:21:21,040
from the manage field of the HPA.

00:21:21,040 --> 00:21:22,560
We're going to take it from them

00:21:22,560 --> 00:21:25,600
and were going to put it back in the field that you manage.

00:21:27,840 --> 00:21:29,520
One interesting feature again

00:21:29,520 --> 00:21:32,160
is the backward compatibility that we want to maintain.

00:21:33,360 --> 00:21:37,600
We can't stop breaking things that work today in Kubernetes

00:21:37,600 --> 00:21:38,640
including controllers.

00:21:39,520 --> 00:21:42,080
It's difficult when there is an error in the controller

00:21:42,080 --> 00:21:45,600
to know about it and for a user to do anything about it.

00:21:46,160 --> 00:21:48,960
So, controllers are always sort of forcing

00:21:49,520 --> 00:21:51,840
and they're not using apply anyway, because apply is new.

00:21:52,480 --> 00:21:56,000
But even if they're not using apply and even if they are not forcing

00:21:56,000 --> 00:21:58,160
we always accept their changes.

00:21:58,160 --> 00:22:01,040
And we only detect that they have a change

00:22:01,040 --> 00:22:03,280
because we can look at the difference.

00:22:03,280 --> 00:22:08,640
So, if the HPA changes just the replicas, it's going to own just the replicas.

00:22:08,640 --> 00:22:10,720
And we know that, because it changed the value

00:22:10,720 --> 00:22:13,760
and whenever you change the value it's because you have an opinion

00:22:14,320 --> 00:22:18,720
and that's how we build the sets for controllers and types

00:22:18,720 --> 00:22:23,120
that did not know about server-side apply or have not used server-side apply before.

00:22:23,120 --> 00:22:26,800
So, we're completing maintaining this backward compatibility

00:22:26,800 --> 00:22:28,560
with the existing workflows.

00:22:28,560 --> 00:22:32,320
And we're just doing the right thing

00:22:32,320 --> 00:22:36,160
by detecting that they have an opinion because they changed something.

00:22:37,680 --> 00:22:41,680
So, now the question is how are objects merged.

00:22:43,920 --> 00:22:47,200
We've tried to keep the logic as simple as possible.

00:22:47,920 --> 00:22:51,200
And by that I mean we literally take what you apply

00:22:51,200 --> 00:22:55,120
we take the existing object and we put it on top.

00:22:55,120 --> 00:22:59,120
So, any value that you specify is going to end up in the object

00:22:59,120 --> 00:23:03,040
and any value that you haven't specified is going to be kept the same.

00:23:04,160 --> 00:23:07,440
Obviously, one of the questions when we do that is how you remove a field

00:23:07,440 --> 00:23:09,600
because if you remove it from your config and apply it

00:23:10,640 --> 00:23:13,440
it's not going to be removed; it's going to keep the current value.

00:23:14,640 --> 00:23:19,200
And so, for that, we just remove the fields if nobody has an opinion about them anymore.

00:23:19,200 --> 00:23:22,720
So, if no one has an opinion about replicas, we just remove it.

00:23:23,760 --> 00:23:25,680
And what happens when replicas are removed?

00:23:25,680 --> 00:23:27,440
It goes back to one.

00:23:29,600 --> 00:23:31,840
But it only happens if no one has an opinion.

00:23:31,840 --> 00:23:35,360
So, if you remove it from your config, but the HPA has set a value

00:23:35,360 --> 00:23:38,160
we're going to know, "Oh, the HPA still cares about that.

00:23:38,160 --> 00:23:40,480
Let's keep the value, because we believe it's correct."

00:23:41,920 --> 00:23:44,240
How do we keep track of who wants what?

00:23:45,120 --> 00:23:47,200
I discussed it a little bit before.

00:23:47,200 --> 00:23:49,840
For controllers, we typically look at what has changed.

00:23:50,720 --> 00:23:55,120
When you apply, we look at all the fields that you have applied

00:23:55,120 --> 00:23:56,480
and we create a set

00:23:56,480 --> 00:24:00,160
a mathematical set of all the fields that you care about.

00:24:01,840 --> 00:24:06,720
And at that time, we look at all the manager sets in the list

00:24:06,720 --> 00:24:09,040
and we intersect them with your set.

00:24:09,600 --> 00:24:12,640
And any intersection that comes as non-empty

00:24:14,080 --> 00:24:15,280
shows the conflict.

00:24:15,280 --> 00:24:20,000
So, we literally take all of these sets and we send them back to the user, saying

00:24:20,000 --> 00:24:22,880
"You have an intersection with this other person

00:24:22,880 --> 00:24:24,800
which means you care about the same field.

00:24:26,160 --> 00:24:28,080
You need to do something about this."

00:24:28,080 --> 00:24:31,520
And as you could see before, we actually save the name of the person

00:24:31,520 --> 00:24:34,160
and for some changes we also keep the date

00:24:34,160 --> 00:24:37,200
so that we know when someone changed the field that you're trying to edit

00:24:37,200 --> 00:24:37,760
so we can say

00:24:37,760 --> 00:24:43,280
"Hey, you're trying to change the field that the HPA has set at this value."

00:24:44,240 --> 00:24:47,520
This is also very important for the out-of-band changes.

00:24:48,240 --> 00:24:51,120
Let's say something is broken in your cluster

00:24:51,120 --> 00:24:57,120
and someone goes and connects and directly edits one of the fields.

00:24:58,320 --> 00:25:02,000
When you reapply, maybe you're going to override that value.

00:25:02,000 --> 00:25:03,520
And we obviously don't want to do that

00:25:03,520 --> 00:25:06,480
because if you do that, your cluster is going to break, right?

00:25:07,600 --> 00:25:10,560
And so, at that time you're going to see a very nice conflict

00:25:10,560 --> 00:25:14,480
that says, you're trying to change this field set by this person.

00:25:14,480 --> 00:25:15,680
Are you sure you want to do so?

00:25:17,280 --> 00:25:20,640
Reasonably, you should ask yourself if this is actually what you want to do.

00:25:23,040 --> 00:25:26,080
Also, finally, this works for built-in types

00:25:26,080 --> 00:25:27,280
and custom resources

00:25:27,280 --> 00:25:30,880
but we're trying to make custom resources work

00:25:31,600 --> 00:25:33,040
the way built-in types work.

00:25:34,320 --> 00:25:37,440
For that, we've tried to make everything look and behave

00:25:37,440 --> 00:25:38,720
as closely as possible.

00:25:38,720 --> 00:25:41,120
So, if you're writing a custom type

00:25:41,760 --> 00:25:46,160
all of this should work exactly the same way as it would if you had a built-in type.

00:25:46,160 --> 00:25:48,240
We don't want you to miss out any feature.

00:25:49,920 --> 00:25:51,600
What are the benefits of that?

00:25:51,600 --> 00:25:55,040
Well, it enables the ecosystem

00:25:55,040 --> 00:25:58,240
because it's so much easier to write apply

00:26:00,000 --> 00:26:04,160
that it's very much easier to write a new tool.

00:26:04,160 --> 00:26:06,640
You don't have to write any logic.

00:26:06,640 --> 00:26:10,080
You just have to send the content to the API server.

00:26:10,080 --> 00:26:11,440
So now, if you want to write a tool

00:26:12,080 --> 00:26:14,800
it's a few lines of code just to update the object

00:26:14,800 --> 00:26:17,280
which is a massive change compared to today

00:26:17,280 --> 00:26:20,640
where you had to either use Go, or use the kubectl tool

00:26:20,640 --> 00:26:23,840
make sure it's shipped properly, that the version is right…

00:26:24,480 --> 00:26:25,840
This is much easier now.

00:26:26,880 --> 00:26:29,760
Obviously, the other change is that we're more collaborative.

00:26:29,760 --> 00:26:31,280
You have multiple appliers.

00:26:32,240 --> 00:26:35,520
We're starting to convert some of the existing controllers

00:26:35,520 --> 00:26:36,720
to use this mechanism

00:26:36,720 --> 00:26:39,520
because we believe it has benefits

00:26:39,520 --> 00:26:41,760
and it's much easier to implement and maintain.

00:26:43,040 --> 00:26:47,840
The user-friendly errors are much better

00:26:47,840 --> 00:26:52,320
and prevent you from breaking your clusters accidentally

00:26:52,960 --> 00:26:56,640
and of course, it improves the human and machine collaboration

00:26:56,640 --> 00:27:01,200
because you can now change parts of the config

00:27:01,200 --> 00:27:03,920
while the machine changes other parts of the config

00:27:05,200 --> 00:27:07,200
without interacting with each other

00:27:07,840 --> 00:27:11,600
and without overriding the values that you don't want to override by accident.

00:27:13,440 --> 00:27:16,640
Now that we have that

00:27:16,640 --> 00:27:18,960
we know that we can apply a lot of configuration

00:27:18,960 --> 00:27:24,880
but I suspect you're soon going to realize that you have too many configuration files.

00:27:25,440 --> 00:27:31,840
It's very common for people to wonder what to do with all of these YAML files.

00:27:31,840 --> 00:27:34,880
I'm sure you've seen that before— you have too many YAML files.

00:27:34,880 --> 00:27:37,120
I've had this problem

00:27:37,120 --> 00:27:40,160
And often you have one version of the file

00:27:40,160 --> 00:27:42,720
and you want to apply it for maybe a test environment

00:27:42,720 --> 00:27:44,240
as I talked about before.

00:27:44,240 --> 00:27:46,000
The problem is that the test environment

00:27:46,000 --> 00:27:49,280
is not the exact same environment as the production.

00:27:49,280 --> 00:27:52,240
You want to use a different database, hopefully.

00:27:53,680 --> 00:27:55,200
You have different requirements.

00:27:55,200 --> 00:27:56,880
You probably don't want as many parts

00:27:56,880 --> 00:27:59,920
You probably don't want it to be deployed to the same place.

00:27:59,920 --> 00:28:02,160
There are many things that are actually different

00:28:02,160 --> 00:28:05,040
between the test environment and the product environment.

00:28:05,040 --> 00:28:09,920
And so, you have very small variations between these configurations

00:28:09,920 --> 00:28:13,360
that can already be made of many different files

00:28:13,360 --> 00:28:17,920
and if you just want to change one value out of these many different configurations

00:28:17,920 --> 00:28:19,920
you're going to have this problem.

00:28:21,600 --> 00:28:23,360
And it starts very quickly.

00:28:23,360 --> 00:28:26,720
Even having two configurations is already too much for me.

00:28:26,720 --> 00:28:29,280
So, I have this problem constantly.

00:28:29,280 --> 00:28:31,440
What we've made is that we've created customize

00:28:31,440 --> 00:28:34,800
because we believe it's as close as possible

00:28:34,800 --> 00:28:38,720
to the principles that we've described in this presentation.

00:28:39,280 --> 00:28:41,760
We believe that customize is collaborative.

00:28:42,560 --> 00:28:46,080
It lets you share the configuration easily.

00:28:46,080 --> 00:28:47,760
But it's also data.

00:28:47,760 --> 00:28:52,080
So, I still believe that the configuration should be data.

00:28:52,080 --> 00:28:53,760
And this is very difficult.

00:28:53,760 --> 00:28:57,040
It's very tempting to use a programming language

00:28:57,040 --> 00:29:00,880
to abstract away some of this redundancy

00:29:01,600 --> 00:29:04,800
but I suspect there is something wrong

00:29:04,800 --> 00:29:07,840
because as soon as the configuration becomes code

00:29:07,840 --> 00:29:10,000
it's not possible to collaborate with machine.

00:29:10,720 --> 00:29:15,760
I do not believe that it's possible to have configurations written as code

00:29:17,040 --> 00:29:19,120
if you want machines to edit them.

00:29:20,800 --> 00:29:23,680
So, that's one of the big challenges that we have today.

00:29:24,640 --> 00:29:27,600
And customize is one of the solutions

00:29:27,600 --> 00:29:29,440
but it has a lot of imitations.

00:29:29,440 --> 00:29:34,000
I know so many solutions exist out there

00:29:34,000 --> 00:29:38,400
but most of them do not treat the configuration as data

00:29:38,400 --> 00:29:40,720
and as collaborative as it should be

00:29:40,720 --> 00:29:45,680
and I think that's one of the problems that we want to fix.

00:29:47,280 --> 00:29:48,240
That's it for me.

00:29:49,040 --> 00:29:50,640
That's all I have for today.

00:29:50,640 --> 00:29:53,840

YouTube URL: https://www.youtube.com/watch?v=TmmDB_9iuUA


