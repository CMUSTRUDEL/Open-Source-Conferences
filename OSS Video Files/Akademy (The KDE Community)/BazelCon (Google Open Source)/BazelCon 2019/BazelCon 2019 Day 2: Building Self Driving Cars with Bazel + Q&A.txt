Title: BazelCon 2019 Day 2: Building Self Driving Cars with Bazel + Q&A
Publication date: 2020-01-15
Playlist: BazelCon 2019
Description: 
	Michael Broll and Nico Valigi, Cruise event: Bazelcon 2019; re_ty: Publish; product: Open Source - General; fullname: Michael Broll, Nico Valigi;
Captions: 
	00:00:01,700 --> 00:00:10,410
good afternoon how's everybody doing

00:00:07,710 --> 00:00:12,660
feeling good good good this mashed

00:00:10,410 --> 00:00:15,509
potatoes getting it all in a nice cozy

00:00:12,660 --> 00:00:18,960
spot lunch was great yeah I really loved

00:00:15,509 --> 00:00:20,340
it it was good we are in our final

00:00:18,960 --> 00:00:22,560
stretch here

00:00:20,340 --> 00:00:24,869
we're gonna go and have a few more

00:00:22,560 --> 00:00:28,380
sessions in this room and of course the

00:00:24,869 --> 00:00:30,000
sessions going on in Khost Live Oak but

00:00:28,380 --> 00:00:32,940
otherwise we're gonna do that and then

00:00:30,000 --> 00:00:35,700
we're gonna wrap up at the end at 3:45

00:00:32,940 --> 00:00:37,320
but I'm super excited by all the

00:00:35,700 --> 00:00:39,809
sessions and I'm super excited about

00:00:37,320 --> 00:00:41,640
this next one as well so right now we've

00:00:39,809 --> 00:00:42,690
got Michael and Nico from Cruz they're

00:00:41,640 --> 00:00:53,100
going to talk about building

00:00:42,690 --> 00:00:55,050
self-driving cars with basil so everyone

00:00:53,100 --> 00:00:57,510
thanks for showing up for this I'm

00:00:55,050 --> 00:01:00,390
Michael I'm Nico and we're software

00:00:57,510 --> 00:01:02,430
engineers Cruz so if you don't know

00:01:00,390 --> 00:01:04,979
about Cruz were a self-driving car

00:01:02,430 --> 00:01:08,189
company based in San Francisco if you

00:01:04,979 --> 00:01:09,780
live in or work in or if you visited SF

00:01:08,189 --> 00:01:11,729
in the past year you've probably seen

00:01:09,780 --> 00:01:14,310
one of our cars in the wilds

00:01:11,729 --> 00:01:16,049
they have our name on it and they also

00:01:14,310 --> 00:01:18,780
have fun little names like piglet or

00:01:16,049 --> 00:01:20,250
tofu but today I'm going to talk to you

00:01:18,780 --> 00:01:21,990
a little bit about how we put the

00:01:20,250 --> 00:01:24,570
software on those cars or rather how we

00:01:21,990 --> 00:01:27,450
build the software for those cars and

00:01:24,570 --> 00:01:28,860
how we've used basil to optimize that

00:01:27,450 --> 00:01:34,439
whole process over the past couple of

00:01:28,860 --> 00:01:35,850
years so first I'd like to talk a little

00:01:34,439 --> 00:01:37,650
bit about some of the unique challenges

00:01:35,850 --> 00:01:40,829
who we're up against with developing

00:01:37,650 --> 00:01:43,020
software crews so like most companies

00:01:40,829 --> 00:01:49,649
were building software that goes on

00:01:43,020 --> 00:01:53,520
servers but those servers move and they

00:01:49,649 --> 00:01:55,710
carry people inside of them and we're

00:01:53,520 --> 00:01:58,530
driving in the real worlds where there

00:01:55,710 --> 00:02:02,700
are pedestrians bicyclists motorcyclists

00:01:58,530 --> 00:02:04,740
other cars and we're doing this in San

00:02:02,700 --> 00:02:06,329
Francisco and if you've ever driven in

00:02:04,740 --> 00:02:09,119
San Francisco frankly if have you ever

00:02:06,329 --> 00:02:12,150
walked on a street in San Francisco you

00:02:09,119 --> 00:02:13,200
know it's not a fun place to drive but

00:02:12,150 --> 00:02:15,330
because it's not a fun

00:02:13,200 --> 00:02:17,930
for human Drive we think it's a great

00:02:15,330 --> 00:02:20,370
place for a robot to learn how to drive

00:02:17,930 --> 00:02:23,340
we also have some fun problems that

00:02:20,370 --> 00:02:28,200
arise just from the software itself our

00:02:23,340 --> 00:02:30,150
code is mostly C++ there are no de facto

00:02:28,200 --> 00:02:31,650
build or dependency management tools so

00:02:30,150 --> 00:02:34,980
you're kind of on your own here it's the

00:02:31,650 --> 00:02:37,080
Wild West it's a complex language so

00:02:34,980 --> 00:02:40,680
naturally tool tool chains are complex

00:02:37,080 --> 00:02:43,290
we support both clang and GCC some teams

00:02:40,680 --> 00:02:45,900
have different needs integrating with

00:02:43,290 --> 00:02:48,840
any build tool takes some patience also

00:02:45,900 --> 00:02:51,480
because of what our code does we need to

00:02:48,840 --> 00:02:53,340
make sure it's as safe as possible part

00:02:51,480 --> 00:02:56,040
of that involves running a lot of

00:02:53,340 --> 00:02:58,620
analysis tools both static and dynamic

00:02:56,040 --> 00:03:01,739
the dynamic analysis comes in the form

00:02:58,620 --> 00:03:03,540
of sanitizers and the unfortunately the

00:03:01,739 --> 00:03:05,280
way these work you can't enable them all

00:03:03,540 --> 00:03:07,019
at once on the same runs so it

00:03:05,280 --> 00:03:09,290
effectively multiplies the amount of

00:03:07,019 --> 00:03:11,760
work you have to do and things like CI

00:03:09,290 --> 00:03:13,560
we also use machine learnings so that

00:03:11,760 --> 00:03:15,510
the car can make sense of the world

00:03:13,560 --> 00:03:19,109
around it this has extra hardware

00:03:15,510 --> 00:03:21,060
requirements in the form of GPUs GPUs

00:03:19,109 --> 00:03:23,609
aren't available in the same quantities

00:03:21,060 --> 00:03:25,560
as things like CPUs or typical VMs and

00:03:23,609 --> 00:03:27,840
the clouds so we have to be a little bit

00:03:25,560 --> 00:03:31,410
smarter and this causes heterogeneous

00:03:27,840 --> 00:03:34,260
environments in CI then causes the need

00:03:31,410 --> 00:03:37,370
to do more tests sharding and make sure

00:03:34,260 --> 00:03:40,139
we're directing tests the right things

00:03:37,370 --> 00:03:42,569
we're also a growing company with a

00:03:40,139 --> 00:03:44,489
growing codebase that creates even more

00:03:42,569 --> 00:03:46,889
problems for us compared to two years

00:03:44,489 --> 00:03:50,250
ago we have about 10 times as many

00:03:46,889 --> 00:03:51,859
people those people write more code

00:03:50,250 --> 00:03:55,260
because that's what they're hired to do

00:03:51,859 --> 00:03:57,510
we spend five times as much cpu time to

00:03:55,260 --> 00:03:59,130
build everything now even with all that

00:03:57,510 --> 00:04:02,040
we've still managed to make build times

00:03:59,130 --> 00:04:04,650
about six times faster so the goal of

00:04:02,040 --> 00:04:07,290
this talk is to shed some light on how

00:04:04,650 --> 00:04:09,510
we've managed to accomplish this we did

00:04:07,290 --> 00:04:11,310
this with a team of four engineers -

00:04:09,510 --> 00:04:13,200
it's our hope that if you're just

00:04:11,310 --> 00:04:15,450
starting out basil or if you're facing

00:04:13,200 --> 00:04:19,229
any of the same problems that you can

00:04:15,450 --> 00:04:21,390
find something useful here so we have a

00:04:19,229 --> 00:04:23,130
few sections to cover in this talk first

00:04:21,390 --> 00:04:24,960
we're going to talk about how we got in

00:04:23,130 --> 00:04:26,050
this mess in the first place Nico

00:04:24,960 --> 00:04:28,289
actually helps

00:04:26,050 --> 00:04:30,280
there actually did all of that for us so

00:04:28,289 --> 00:04:32,139
it's gonna is going to talk about what

00:04:30,280 --> 00:04:33,789
it took to my greatest to Basel then

00:04:32,139 --> 00:04:36,159
we're gonna shift gears and talk about

00:04:33,789 --> 00:04:37,479
how we actually measure things the the

00:04:36,159 --> 00:04:40,060
whole point of this is you know

00:04:37,479 --> 00:04:42,009
improvement and making things faster so

00:04:40,060 --> 00:04:44,319
we think it's valuable to show you how

00:04:42,009 --> 00:04:47,169
we actually actually measure that it's

00:04:44,319 --> 00:04:49,690
our way it's one way but hopefully you

00:04:47,169 --> 00:04:51,039
can find some value in it lastly we'll

00:04:49,690 --> 00:04:52,419
talk about some of the key things we did

00:04:51,039 --> 00:04:57,699
to actually make the builds and tests

00:04:52,419 --> 00:05:00,159
faster okay thanks Michael yeah so I'm

00:04:57,699 --> 00:05:02,050
here to tell you the story of how and

00:05:00,159 --> 00:05:02,530
why we migrated to beta in the first

00:05:02,050 --> 00:05:06,280
place

00:05:02,530 --> 00:05:08,409
and so the fact is on a robot you can

00:05:06,280 --> 00:05:10,330
never have too much cpu so you want your

00:05:08,409 --> 00:05:11,979
code to run as fast as possible which

00:05:10,330 --> 00:05:15,520
means that at some point you end up

00:05:11,979 --> 00:05:18,069
using C++ C++ is really slow to compile

00:05:15,520 --> 00:05:19,900
like a single file can take like three

00:05:18,069 --> 00:05:22,000
or even five minutes depending on like

00:05:19,900 --> 00:05:24,759
the libraries you use and how complex

00:05:22,000 --> 00:05:26,560
the code is which meant like on a

00:05:24,759 --> 00:05:28,990
developer workstation and we use

00:05:26,560 --> 00:05:30,870
powerful workstations so that people can

00:05:28,990 --> 00:05:32,740
run simulations can do all the

00:05:30,870 --> 00:05:35,800
civilization and stuff like that and

00:05:32,740 --> 00:05:37,930
still like two years ago we like yeah

00:05:35,800 --> 00:05:40,270
one fifth of the code we have now it

00:05:37,930 --> 00:05:41,800
still took one hour to build the code so

00:05:40,270 --> 00:05:44,319
I've seen people like do crazy stuff

00:05:41,800 --> 00:05:46,479
they are like the morning ritual you set

00:05:44,319 --> 00:05:48,789
up the build and then you go grab coffee

00:05:46,479 --> 00:05:50,289
maybe go to the bank some people that

00:05:48,789 --> 00:05:52,509
like a nightly script they're like a

00:05:50,289 --> 00:05:55,330
3:00 a.m. every night we like tool

00:05:52,509 --> 00:05:56,770
master build and then they when they get

00:05:55,330 --> 00:05:59,319
to work everything is already built

00:05:56,770 --> 00:06:02,110
hopefully so this is not really great

00:05:59,319 --> 00:06:03,909
and the reason we wanted basil was to

00:06:02,110 --> 00:06:05,800
take advantage of caching basically we

00:06:03,909 --> 00:06:07,659
didn't really care about all the fancy

00:06:05,800 --> 00:06:10,569
correctness features multi-language

00:06:07,659 --> 00:06:12,310
support or anything like that we just

00:06:10,569 --> 00:06:16,000
wanted the bills to go faster basically

00:06:12,310 --> 00:06:17,620
and based on actually delivered so this

00:06:16,000 --> 00:06:20,560
is not my picture I study from the

00:06:17,620 --> 00:06:23,020
internet but we set up a workstation

00:06:20,560 --> 00:06:25,599
under my desk as a remote cache and that

00:06:23,020 --> 00:06:27,729
basically cut down like a master build

00:06:25,599 --> 00:06:30,520
from like one hour to basically five

00:06:27,729 --> 00:06:34,199
minutes or something like that that's it

00:06:30,520 --> 00:06:36,940
four stories how did we actually do it

00:06:34,199 --> 00:06:38,800
the main problem when doing a migration

00:06:36,940 --> 00:06:40,539
like this is that

00:06:38,800 --> 00:06:41,800
one engineers to be productive while

00:06:40,539 --> 00:06:44,650
you're basically moving things around

00:06:41,800 --> 00:06:47,139
underneath them so we had this magical

00:06:44,650 --> 00:06:49,210
script that would basically parse the

00:06:47,139 --> 00:06:50,860
Simek files we had and create

00:06:49,210 --> 00:06:54,009
corresponding build files for beza

00:06:50,860 --> 00:06:57,009
so we never thought anyone to write

00:06:54,009 --> 00:06:58,990
build files they kept writing Simek

00:06:57,009 --> 00:07:01,330
files and then in CI we would basically

00:06:58,990 --> 00:07:04,090
convert them to BL files and of course

00:07:01,330 --> 00:07:05,440
the the script was magic 800 lines of

00:07:04,090 --> 00:07:07,990
Python that would basically just take

00:07:05,440 --> 00:07:09,909
the syntax 3/4 see me do a bunch of like

00:07:07,990 --> 00:07:12,370
heuristics and stuff like that it wasn't

00:07:09,909 --> 00:07:15,550
pretty of course after a few months of

00:07:12,370 --> 00:07:18,490
work using like tools like this we had

00:07:15,550 --> 00:07:21,430
the first PR to enable basil bills in

00:07:18,490 --> 00:07:26,169
September 17 so a little over two years

00:07:21,430 --> 00:07:28,330
ago so once the first say 80% of the

00:07:26,169 --> 00:07:31,539
work was done as always you're basically

00:07:28,330 --> 00:07:34,389
left with the other 80% of the work for

00:07:31,539 --> 00:07:36,969
C++ this meant basically buzz Allah

00:07:34,389 --> 00:07:39,580
fiying the build of like hundred or so

00:07:36,969 --> 00:07:40,990
third-party dependencies instead of just

00:07:39,580 --> 00:07:44,380
importing them from the Ubuntu

00:07:40,990 --> 00:07:47,620
installation for us this polishing work

00:07:44,380 --> 00:07:51,310
took roughly two more months basically

00:07:47,620 --> 00:07:52,719
for our code base and during all of this

00:07:51,310 --> 00:07:54,279
we had a bunch of Education to do

00:07:52,719 --> 00:07:56,889
basically people were changing their

00:07:54,279 --> 00:07:58,870
daily workflow and this is like our now

00:07:56,889 --> 00:08:00,699
lead developer on the team that

00:07:58,870 --> 00:08:02,139
discovers that like skylark is not

00:08:00,699 --> 00:08:04,229
actually Python and you can't actually

00:08:02,139 --> 00:08:08,110
use the standard library

00:08:04,229 --> 00:08:11,169
so the idea during all this time is that

00:08:08,110 --> 00:08:13,449
we had both Simic and basil builds

00:08:11,169 --> 00:08:15,849
working at the same time on the same

00:08:13,449 --> 00:08:17,650
code base and developers could choose to

00:08:15,849 --> 00:08:19,750
use either so basically we have some

00:08:17,650 --> 00:08:22,840
early adopters you have some loggers but

00:08:19,750 --> 00:08:25,270
both work and if we found any bugs or

00:08:22,840 --> 00:08:27,520
missing features we could always tell

00:08:25,270 --> 00:08:29,169
people to like go back to see make for

00:08:27,520 --> 00:08:30,849
like a day or two while we fixed the bug

00:08:29,169 --> 00:08:37,000
and then they could come back to basil

00:08:30,849 --> 00:08:39,099
and so after say so four five six months

00:08:37,000 --> 00:08:41,979
of work when people came back from the

00:08:39,099 --> 00:08:43,810
holidays after Christmas 17 all the

00:08:41,979 --> 00:08:45,970
SIMEX files were like gone from the repo

00:08:43,810 --> 00:08:48,820
I think this is two hundred and

00:08:45,970 --> 00:08:50,709
seventy-five files deleted

00:08:48,820 --> 00:08:52,540
we have been Apple users ever since

00:08:50,709 --> 00:08:54,639
so just to recap

00:08:52,540 --> 00:08:58,500
bitte at the time the company had

00:08:54,639 --> 00:09:01,540
roughly 200 engineers I counted like

00:08:58,500 --> 00:09:04,000
3000 C++ files like a thousand Python

00:09:01,540 --> 00:09:06,250
files and 300 Simek files which is like

00:09:04,000 --> 00:09:09,250
one over three like makes you think very

00:09:06,250 --> 00:09:12,069
hard and so that basically migration to

00:09:09,250 --> 00:09:14,410
craft like six months obviously just me

00:09:12,069 --> 00:09:17,740
from like start to where we could delete

00:09:14,410 --> 00:09:19,630
all the Simek files we have seen like

00:09:17,740 --> 00:09:22,509
many stories of migrations I also want

00:09:19,630 --> 00:09:25,209
to share what I think we learned the

00:09:22,509 --> 00:09:28,600
fact is don't underestimate the human

00:09:25,209 --> 00:09:30,910
factor so early on we decided no goal we

00:09:28,600 --> 00:09:32,920
wanted to make local builds as fast as

00:09:30,910 --> 00:09:34,240
possible we ignored everything gets

00:09:32,920 --> 00:09:36,310
basically we didn't care about C I

00:09:34,240 --> 00:09:38,470
wouldn't care about correctness we just

00:09:36,310 --> 00:09:41,290
wanted to get the local build the

00:09:38,470 --> 00:09:43,360
workstation build number down and that

00:09:41,290 --> 00:09:45,730
basically gave us the early wins to

00:09:43,360 --> 00:09:48,040
basically push the rest of the the basil

00:09:45,730 --> 00:09:51,610
with us we didn't break the existing

00:09:48,040 --> 00:09:53,019
builds we didn't break existing CI until

00:09:51,610 --> 00:09:55,149
we were confident that basically was

00:09:53,019 --> 00:09:57,610
that basil was at parity and like a

00:09:55,149 --> 00:09:59,829
bunch of like customized tool to link

00:09:57,610 --> 00:10:02,500
helped a lot because we could basically

00:09:59,829 --> 00:10:05,410
pour changes over from basil over to

00:10:02,500 --> 00:10:08,889
from C make over to basil automatically

00:10:05,410 --> 00:10:10,569
and finally like I encourage you to

00:10:08,889 --> 00:10:12,130
resist the temptation to like improve

00:10:10,569 --> 00:10:15,490
things as you're doing a migration like

00:10:12,130 --> 00:10:18,069
this it's not the right time to clean up

00:10:15,490 --> 00:10:20,170
technical depth and I mean of course I

00:10:18,069 --> 00:10:22,300
found lots of like skeletons in the

00:10:20,170 --> 00:10:24,040
closet but we just ignore them and like

00:10:22,300 --> 00:10:25,930
went on with the migration it's much

00:10:24,040 --> 00:10:29,199
easier to like clean things up once

00:10:25,930 --> 00:10:30,180
you're like 100 percent basil so back to

00:10:29,199 --> 00:10:37,180
you Michael

00:10:30,180 --> 00:10:40,300
thanks thank you so let's fast forward a

00:10:37,180 --> 00:10:43,389
bit to late 2018 we're still happy with

00:10:40,300 --> 00:10:45,459
basil that's why we're here but we need

00:10:43,389 --> 00:10:48,130
to make things faster and we're not

00:10:45,459 --> 00:10:49,180
exactly sure where to start so before we

00:10:48,130 --> 00:10:50,769
can even think about improving

00:10:49,180 --> 00:10:52,959
performance we need a way to measure it

00:10:50,769 --> 00:10:54,819
after all you can't really improve what

00:10:52,959 --> 00:10:58,060
you don't measure then this whole talk

00:10:54,819 --> 00:10:59,920
is about improvement so the initial

00:10:58,060 --> 00:11:01,360
metrics that we care about aren't

00:10:59,920 --> 00:11:04,060
particularly surprising

00:11:01,360 --> 00:11:06,970
we of course care about build time our

00:11:04,060 --> 00:11:08,470
one objective is to lower this number we

00:11:06,970 --> 00:11:10,270
talk about it everyday it's the first

00:11:08,470 --> 00:11:13,000
thing we bring up when reviewing weekly

00:11:10,270 --> 00:11:14,440
metrics with other teams and most

00:11:13,000 --> 00:11:16,150
importantly it's the first thing

00:11:14,440 --> 00:11:17,830
developers notice when they run builds

00:11:16,150 --> 00:11:21,100
or don't notice that their builds are

00:11:17,830 --> 00:11:23,200
already fast luckily you get more blame

00:11:21,100 --> 00:11:25,600
than praise so you hear things pretty

00:11:23,200 --> 00:11:29,020
quickly but we can't just measure

00:11:25,600 --> 00:11:31,480
end-to-end time knowing how long builds

00:11:29,020 --> 00:11:33,460
take especially over time is indeed how

00:11:31,480 --> 00:11:35,560
we want to measure our impacts but

00:11:33,460 --> 00:11:38,290
without knowing where that time goes

00:11:35,560 --> 00:11:41,260
we're just dealing with a black box so

00:11:38,290 --> 00:11:43,090
we're also already using remote caching

00:11:41,260 --> 00:11:43,690
it's the main way we make our builds

00:11:43,090 --> 00:11:46,300
faster

00:11:43,690 --> 00:11:47,890
so of course remote cache operations are

00:11:46,300 --> 00:11:48,610
important to us and we need to measure

00:11:47,890 --> 00:11:51,640
them somehow

00:11:48,610 --> 00:11:53,860
however we began to suspect that tests

00:11:51,640 --> 00:11:56,440
and CI we're actually rebuilding things

00:11:53,860 --> 00:12:00,310
that were cashed in builds immediately

00:11:56,440 --> 00:12:02,710
prior not a great thing to think and

00:12:00,310 --> 00:12:04,390
cache hit ratios are super helpful and

00:12:02,710 --> 00:12:06,700
telling us whether caching is actually

00:12:04,390 --> 00:12:08,920
effective and we have to remember

00:12:06,700 --> 00:12:10,570
they're actually two caches there's your

00:12:08,920 --> 00:12:13,960
content addressable storage in your

00:12:10,570 --> 00:12:15,670
action cache and when we typically talk

00:12:13,960 --> 00:12:17,980
about cache hit ratios we're talking

00:12:15,670 --> 00:12:20,680
about how many actions we didn't have to

00:12:17,980 --> 00:12:22,960
rerun in a builds but it's important to

00:12:20,680 --> 00:12:25,480
understand the telemetry behind that and

00:12:22,960 --> 00:12:27,430
you actually have multiple writes to

00:12:25,480 --> 00:12:29,080
successfully cache in action results and

00:12:27,430 --> 00:12:31,770
you have multiple reads to successfully

00:12:29,080 --> 00:12:34,690
read and act a cached action results so

00:12:31,770 --> 00:12:38,820
it's important that your cache is highly

00:12:34,690 --> 00:12:42,370
available and very very low error rates

00:12:38,820 --> 00:12:44,140
so that you actually gets effectiveness

00:12:42,370 --> 00:12:46,630
out of your cache it's just one of those

00:12:44,140 --> 00:12:48,310
things fails you know you can do enough

00:12:46,630 --> 00:12:50,200
with retries but at the end of the day

00:12:48,310 --> 00:12:55,540
your your cache has to be super super

00:12:50,200 --> 00:12:58,960
reliable so the way we actually go about

00:12:55,540 --> 00:13:00,960
this is profiling so basil has profiling

00:12:58,960 --> 00:13:03,730
built in it's a pretty awesome feature

00:13:00,960 --> 00:13:06,190
what the data provides you can

00:13:03,730 --> 00:13:08,170
reconstruct a full execution trace of an

00:13:06,190 --> 00:13:11,080
indication down to each individual

00:13:08,170 --> 00:13:13,210
action plus some extra little details so

00:13:11,080 --> 00:13:15,730
this gives us that peek inside the box

00:13:13,210 --> 00:13:17,440
that we want for timing information it

00:13:15,730 --> 00:13:19,300
gives us super low granularity

00:13:17,440 --> 00:13:21,940
we can actually tell where a basal build

00:13:19,300 --> 00:13:24,100
spends most of its time including

00:13:21,940 --> 00:13:26,710
designation on whether something is on

00:13:24,100 --> 00:13:29,170
the critical path this is a very

00:13:26,710 --> 00:13:31,720
important thing track so in our private

00:13:29,170 --> 00:13:34,240
Fork of Basel we also enable profiling

00:13:31,720 --> 00:13:36,340
of remote cache operations along with

00:13:34,240 --> 00:13:39,130
the content hashes of those actual

00:13:36,340 --> 00:13:42,100
requests being made so every cache check

00:13:39,130 --> 00:13:44,110
read and write is included and from this

00:13:42,100 --> 00:13:46,840
we can easily calculate cache hit ratios

00:13:44,110 --> 00:13:48,760
but we can also record the content hash

00:13:46,840 --> 00:13:51,640
of these requests and learn if

00:13:48,760 --> 00:13:53,710
particular blobs are unexpectedly not

00:13:51,640 --> 00:13:54,730
you know coming out so when we run tests

00:13:53,710 --> 00:13:57,850
when we expect them to actually be

00:13:54,730 --> 00:14:00,670
cached it's also worth noting that's

00:13:57,850 --> 00:14:03,820
where you know using the binary format

00:14:00,670 --> 00:14:05,350
in this example here we are just now

00:14:03,820 --> 00:14:09,220
starting a transition to the new JSON

00:14:05,350 --> 00:14:10,540
format which is way easier to use if you

00:14:09,220 --> 00:14:13,030
know unless you've gone through the

00:14:10,540 --> 00:14:16,000
trouble of figuring out how to like

00:14:13,030 --> 00:14:18,370
natively decode the binary format of a

00:14:16,000 --> 00:14:20,770
profile you have to run Basel two to get

00:14:18,370 --> 00:14:23,790
any use out of it and you do that with

00:14:20,770 --> 00:14:23,790
the analyzed profile command

00:14:24,960 --> 00:14:30,130
so using profiling directly for

00:14:28,510 --> 00:14:31,570
individual indications is sort of how we

00:14:30,130 --> 00:14:33,250
started out with this and it's pretty

00:14:31,570 --> 00:14:35,350
straightforward as you solve the

00:14:33,250 --> 00:14:38,620
commands before but we want to use this

00:14:35,350 --> 00:14:41,020
to collect metrics more broadly in an

00:14:38,620 --> 00:14:43,870
automated fashion we want to be able to

00:14:41,020 --> 00:14:45,850
do analyses offline and maybe even

00:14:43,870 --> 00:14:48,130
develop new metrics over time so at the

00:14:45,850 --> 00:14:50,470
very least we need a central data store

00:14:48,130 --> 00:14:52,990
to query these things that we record and

00:14:50,470 --> 00:14:54,210
we should keep just a copy of the raw

00:14:52,990 --> 00:14:56,200
profile data

00:14:54,210 --> 00:14:58,750
unfortunately the basil doesn't have

00:14:56,200 --> 00:15:01,330
anything like the basil event service

00:14:58,750 --> 00:15:03,060
with the event protocol built-in so we

00:15:01,330 --> 00:15:05,860
kind of have to build this ourselves

00:15:03,060 --> 00:15:09,900
luckily we already wrap our basil in a

00:15:05,860 --> 00:15:12,190
script so this is not an uncommon thing

00:15:09,900 --> 00:15:15,610
you know basically we have this tools

00:15:12,190 --> 00:15:18,130
basil thing in our repo which is scripts

00:15:15,610 --> 00:15:19,630
that then calls the real basil but

00:15:18,130 --> 00:15:22,200
before we actually call it we do some

00:15:19,630 --> 00:15:25,150
setup stuff and one of those things is

00:15:22,200 --> 00:15:27,430
building a profile designate a profile

00:15:25,150 --> 00:15:28,310
to output and then waiting for the

00:15:27,430 --> 00:15:32,930
command defend

00:15:28,310 --> 00:15:35,990
and then uploading that profile so when

00:15:32,930 --> 00:15:37,910
we upload the profile we also record

00:15:35,990 --> 00:15:40,280
some metadata about where that

00:15:37,910 --> 00:15:41,960
invocation was run so we record some

00:15:40,280 --> 00:15:46,760
things like command line host name

00:15:41,960 --> 00:15:49,070
number CPU cores the OS version and we

00:15:46,760 --> 00:15:51,830
upload this profile to Google Cloud

00:15:49,070 --> 00:15:54,860
Storage bucket and we record the

00:15:51,830 --> 00:15:57,440
metadata in bigquery from there we can

00:15:54,860 --> 00:15:59,630
process the profile online at our

00:15:57,440 --> 00:16:02,210
leisure and run any number of

00:15:59,630 --> 00:16:04,100
aggregations we want but we also throw

00:16:02,210 --> 00:16:07,900
the raw action data back in bigquery as

00:16:04,100 --> 00:16:10,910
well so we have a few tables and

00:16:07,900 --> 00:16:13,880
everything is basically joined together

00:16:10,910 --> 00:16:17,150
if we need to with an invocation ID so

00:16:13,880 --> 00:16:21,400
we can you know go down to the level of

00:16:17,150 --> 00:16:21,400
individual invitations if we need to so

00:16:22,030 --> 00:16:26,300
what can we do with this data there are

00:16:25,010 --> 00:16:27,590
actually a lot of questions we can

00:16:26,300 --> 00:16:30,350
answer with this data here's just a few

00:16:27,590 --> 00:16:33,530
examples and we go from very broad to

00:16:30,350 --> 00:16:35,510
very specific so we obviously want to be

00:16:33,530 --> 00:16:37,130
able to see a build time distribution

00:16:35,510 --> 00:16:40,130
again that's the number one thing we

00:16:37,130 --> 00:16:41,750
care about so we can go in with the

00:16:40,130 --> 00:16:43,370
power of sequel and bigquery we can

00:16:41,750 --> 00:16:45,140
build out these distributions with

00:16:43,370 --> 00:16:48,560
various percentiles and track them over

00:16:45,140 --> 00:16:51,680
time then we can get down to the level

00:16:48,560 --> 00:16:53,420
of users so we can pretty easily track

00:16:51,680 --> 00:16:55,670
like host names to users in our

00:16:53,420 --> 00:16:57,980
organization and so we can limit the

00:16:55,670 --> 00:17:00,680
metrics and bucket per user and see okay

00:16:57,980 --> 00:17:03,830
what's like the 90th percentile of all

00:17:00,680 --> 00:17:06,140
these users builds and who are the users

00:17:03,830 --> 00:17:09,410
that are having the worst time building

00:17:06,140 --> 00:17:10,790
not everybody complains so it's pretty

00:17:09,410 --> 00:17:13,550
it's pretty good to be able to

00:17:10,790 --> 00:17:14,900
proactively identify these people and so

00:17:13,550 --> 00:17:17,330
we can go and reach out to them and say

00:17:14,900 --> 00:17:19,850
hey why your builds taking so long can

00:17:17,330 --> 00:17:21,440
we help you out we can also go down to

00:17:19,850 --> 00:17:23,330
the level like a set of individual

00:17:21,440 --> 00:17:26,720
indications and we can figure out things

00:17:23,330 --> 00:17:29,540
again why a test run might have you know

00:17:26,720 --> 00:17:30,980
a cache miss on something we should

00:17:29,540 --> 00:17:32,810
expect that if we built something

00:17:30,980 --> 00:17:35,240
immediately prior that everything that

00:17:32,810 --> 00:17:40,280
we need to run that test is already

00:17:35,240 --> 00:17:41,360
ready to go so now we're going to talk

00:17:40,280 --> 00:17:44,210
about how we

00:17:41,360 --> 00:17:46,309
actually made things faster a lot of

00:17:44,210 --> 00:17:47,210
this isn't gonna be super novel but the

00:17:46,309 --> 00:17:49,760
thing I like to stress here is

00:17:47,210 --> 00:17:51,410
optimizations take time and the fun

00:17:49,760 --> 00:17:53,390
thing about upper management is they

00:17:51,410 --> 00:17:56,210
love to know how long things are gonna

00:17:53,390 --> 00:17:58,070
take before you start doing it so if

00:17:56,210 --> 00:17:59,900
nothing else maybe you'll come away with

00:17:58,070 --> 00:18:01,790
at least one example of how long some of

00:17:59,900 --> 00:18:03,260
the stuff takes so you can have a little

00:18:01,790 --> 00:18:05,740
bit of ammunition when you go to try to

00:18:03,260 --> 00:18:09,980
sell this to some of your stakeholders

00:18:05,740 --> 00:18:13,070
so it's still late 2018 we've got these

00:18:09,980 --> 00:18:16,070
new fancy metrics to help guide us since

00:18:13,070 --> 00:18:18,350
the initial migration of Basel we've

00:18:16,070 --> 00:18:20,690
matured a bit in our set up that that

00:18:18,350 --> 00:18:24,590
box in the office under Nico's desk is

00:18:20,690 --> 00:18:27,350
now an actual you know service on real

00:18:24,590 --> 00:18:28,910
server hardware hosted on from so we're

00:18:27,350 --> 00:18:30,679
not limited by you know the small

00:18:28,910 --> 00:18:34,130
bandwidth on on that network interface

00:18:30,679 --> 00:18:36,230
on that little thing and for CI we've

00:18:34,130 --> 00:18:39,770
moose we've moved most of our workflow

00:18:36,230 --> 00:18:41,750
to Google Cloud so we can actually just

00:18:39,770 --> 00:18:42,650
leverage Google Cloud storage to use for

00:18:41,750 --> 00:18:44,960
a CI cache

00:18:42,650 --> 00:18:47,720
there's no implementation there it

00:18:44,960 --> 00:18:49,820
natively implements the API there's also

00:18:47,720 --> 00:18:52,490
no operational overhead so we can get

00:18:49,820 --> 00:18:55,400
rid of you know what was running an AWS

00:18:52,490 --> 00:18:58,010
on a single machine things are mostly

00:18:55,400 --> 00:19:01,400
good but we know we can do better we

00:18:58,010 --> 00:19:04,190
haven't done a whole lot of work to get

00:19:01,400 --> 00:19:05,870
to this point so most of the

00:19:04,190 --> 00:19:08,840
improvements for building tests up to

00:19:05,870 --> 00:19:10,910
this point were actually focused on CI a

00:19:08,840 --> 00:19:12,919
lot of that was not basel specific

00:19:10,910 --> 00:19:15,860
because we had a pretty complex CI set

00:19:12,919 --> 00:19:17,860
up and so local developers are kind of

00:19:15,860 --> 00:19:21,169
still hurting with their local workflow

00:19:17,860 --> 00:19:24,590
builds can still take up to an hour and

00:19:21,169 --> 00:19:26,780
even more some teams keep around long

00:19:24,590 --> 00:19:29,179
live branches which is pretty fun and

00:19:26,780 --> 00:19:30,650
they don't build on them frequently so

00:19:29,179 --> 00:19:32,030
you often get messages and saying hey

00:19:30,650 --> 00:19:34,750
I'm building this agent branch and it's

00:19:32,030 --> 00:19:36,679
taking forever this is problematic

00:19:34,750 --> 00:19:38,540
you know when their code gets out of

00:19:36,679 --> 00:19:40,070
date and you know they probably just

00:19:38,540 --> 00:19:42,260
wipe out their local state because

00:19:40,070 --> 00:19:43,520
they're building you know maybe you know

00:19:42,260 --> 00:19:44,330
there are probably weeks between when

00:19:43,520 --> 00:19:47,840
they're when they're building these

00:19:44,330 --> 00:19:49,400
things and so our remote cache the local

00:19:47,840 --> 00:19:51,260
developer cache doesn't have enough

00:19:49,400 --> 00:19:53,710
storage to actually keep their inputs in

00:19:51,260 --> 00:19:53,710
there the whole time

00:19:53,890 --> 00:19:59,330
there's actually some repeat stuff so

00:19:57,040 --> 00:20:01,580
the most efficient way we solve some of

00:19:59,330 --> 00:20:05,720
these problems was by using compression

00:20:01,580 --> 00:20:09,020
with her remote caching so we decided on

00:20:05,720 --> 00:20:10,730
Z standard compression and found out

00:20:09,020 --> 00:20:12,440
with some basic testing that a fully

00:20:10,730 --> 00:20:15,680
cache build was actually 40 percent

00:20:12,440 --> 00:20:18,200
faster it also allowed us to store about

00:20:15,680 --> 00:20:20,510
six times as much data and not on from

00:20:18,200 --> 00:20:22,550
cache so those teams with the long live

00:20:20,510 --> 00:20:24,710
branches can now keep their stuff in

00:20:22,550 --> 00:20:26,150
there they can go about a month in

00:20:24,710 --> 00:20:28,820
between builds and still have fully

00:20:26,150 --> 00:20:31,790
cache builds and we get the obvious

00:20:28,820 --> 00:20:33,230
speed benefit so it's important to know

00:20:31,790 --> 00:20:36,770
there are some trade-offs to make here

00:20:33,230 --> 00:20:38,810
though nothing's free for one you have

00:20:36,770 --> 00:20:40,130
to trade CPU time for transport time in

00:20:38,810 --> 00:20:42,250
this so while we're transferring

00:20:40,130 --> 00:20:46,100
transporting weight less over the wire

00:20:42,250 --> 00:20:49,160
it does take some time to encode and

00:20:46,100 --> 00:20:52,010
decode these blobs in our case we were

00:20:49,160 --> 00:20:55,370
already i/o bound so that's totally fine

00:20:52,010 --> 00:20:57,020
we have some spare CPU cycles but it's

00:20:55,370 --> 00:20:58,250
just something to consider if you want

00:20:57,020 --> 00:21:00,620
to do something similar like this

00:20:58,250 --> 00:21:07,120
yourself just make sure that you're not

00:21:00,620 --> 00:21:10,970
gonna actually have a regression so

00:21:07,120 --> 00:21:13,640
remote caching is great now it's still

00:21:10,970 --> 00:21:16,100
kind of limited and that it only

00:21:13,640 --> 00:21:18,170
prevents you from repeating yourself so

00:21:16,100 --> 00:21:22,370
it's most effective when changes are

00:21:18,170 --> 00:21:23,750
pretty small and incremental it's in our

00:21:22,370 --> 00:21:26,050
case we saw it's really easy to

00:21:23,750 --> 00:21:28,070
invalidate a large portion of your cache

00:21:26,050 --> 00:21:31,010
this comes in the form of changing

00:21:28,070 --> 00:21:35,330
common dependencies or you know making

00:21:31,010 --> 00:21:37,520
large reef actors and we also have some

00:21:35,330 --> 00:21:40,040
code paths in our in our code base where

00:21:37,520 --> 00:21:42,460
it's pretty easy to car cause large

00:21:40,040 --> 00:21:44,870
unexpected invalidations at the cache

00:21:42,460 --> 00:21:46,640
some of these things we thought maybe we

00:21:44,870 --> 00:21:48,380
could refactor and we dig into the code

00:21:46,640 --> 00:21:52,280
and find out no it's actually not that

00:21:48,380 --> 00:21:53,930
simple so the lesson here is caching

00:21:52,280 --> 00:21:55,790
isn't a one-size-fits-all solution for

00:21:53,930 --> 00:21:59,770
performance at a certain point you need

00:21:55,790 --> 00:22:05,150
to make the actual execution part faster

00:21:59,770 --> 00:22:06,830
so inter remote execution before we kind

00:22:05,150 --> 00:22:09,080
of done things by just giving

00:22:06,830 --> 00:22:11,960
people more cores and their desktops and

00:22:09,080 --> 00:22:13,760
of course like any you know distributed

00:22:11,960 --> 00:22:16,850
systems engineer realizes like you can't

00:22:13,760 --> 00:22:19,370
vertically scale forever so with robot

00:22:16,850 --> 00:22:22,549
execution you effectively give your

00:22:19,370 --> 00:22:26,809
Basel client access to as many cores as

00:22:22,549 --> 00:22:28,970
are on your worker pool so we had these

00:22:26,809 --> 00:22:31,640
beefy desktops with 28 core CPUs which

00:22:28,970 --> 00:22:34,580
are great but nothing compares to what

00:22:31,640 --> 00:22:36,500
you can get with the cloud so with so

00:22:34,580 --> 00:22:39,230
many workers available it's trivial to

00:22:36,500 --> 00:22:41,450
also run a single test like a thousand

00:22:39,230 --> 00:22:44,510
or even a hundred thousand times to

00:22:41,450 --> 00:22:48,080
detect super low flake rates in seconds

00:22:44,510 --> 00:22:50,179
or minutes before that would take you

00:22:48,080 --> 00:22:53,240
probably over an hour to do something to

00:22:50,179 --> 00:22:54,470
do that with some of our tests and to

00:22:53,240 --> 00:22:55,820
the point where we'd probably never

00:22:54,470 --> 00:22:57,889
detect flakiness and some of these

00:22:55,820 --> 00:23:00,950
things I think we actually had an

00:22:57,889 --> 00:23:02,510
example where an engineer ran something

00:23:00,950 --> 00:23:05,809
about a hundred thousand times and found

00:23:02,510 --> 00:23:09,350
five failures like that would have been

00:23:05,809 --> 00:23:11,450
possible without without RP so because

00:23:09,350 --> 00:23:13,850
each action runs on its own worker

00:23:11,450 --> 00:23:15,559
inside a docker container it also can't

00:23:13,850 --> 00:23:17,870
conflict with local resources and other

00:23:15,559 --> 00:23:19,760
tests we actually had some of our tests

00:23:17,870 --> 00:23:20,990
that were marked as exclusive because

00:23:19,760 --> 00:23:23,720
we're like a they're stopping on each

00:23:20,990 --> 00:23:26,510
other we need to just separate them so

00:23:23,720 --> 00:23:28,130
what occlusive does is it actually moves

00:23:26,510 --> 00:23:31,669
all those tests executions to the end

00:23:28,130 --> 00:23:34,159
and then runs them all see really not

00:23:31,669 --> 00:23:38,149
not great for performance so lastly we

00:23:34,159 --> 00:23:40,940
can also share the same cache between

00:23:38,149 --> 00:23:43,610
developers and CI before we had this

00:23:40,940 --> 00:23:45,080
separate cache where you know we don't

00:23:43,610 --> 00:23:47,630
want developers to share the CI cache

00:23:45,080 --> 00:23:49,130
because if you're editing code while

00:23:47,630 --> 00:23:51,110
you're interacting with cache and

00:23:49,130 --> 00:23:53,360
running builds you can risk poisoning

00:23:51,110 --> 00:23:56,899
things and we never want that to happen

00:23:53,360 --> 00:24:01,309
in CI or automated systems because that

00:23:56,899 --> 00:24:02,659
can cause huge huge pain we don't have

00:24:01,309 --> 00:24:03,889
that problem anymore because you can't

00:24:02,659 --> 00:24:08,750
edit the code while it's running on the

00:24:03,889 --> 00:24:10,940
worker so remote execution sounded great

00:24:08,750 --> 00:24:13,730
we realized it was going to be a pretty

00:24:10,940 --> 00:24:15,440
big undertaking though and so we needed

00:24:13,730 --> 00:24:17,179
to take a step back and consider how we

00:24:15,440 --> 00:24:18,880
can provide value in a time effective

00:24:17,179 --> 00:24:22,840
manner again we're

00:24:18,880 --> 00:24:27,340
engineers so with any distributed system

00:24:22,840 --> 00:24:29,740
the operational overhead is nonzero we

00:24:27,340 --> 00:24:31,780
figured we don't want to spend a bunch

00:24:29,740 --> 00:24:34,330
of time building and operating the

00:24:31,780 --> 00:24:36,060
system when maybe somebody else has

00:24:34,330 --> 00:24:38,590
already at least done the building part

00:24:36,060 --> 00:24:40,660
and if we can avoid the operational part

00:24:38,590 --> 00:24:42,490
- then we can focus on the problems that

00:24:40,660 --> 00:24:46,330
you know we are best suited to solve as

00:24:42,490 --> 00:24:47,830
engineers of our company so the other

00:24:46,330 --> 00:24:50,710
problem is developers were feeling a bit

00:24:47,830 --> 00:24:54,220
more pain during local development ci is

00:24:50,710 --> 00:24:56,050
still good enough the the real bad part

00:24:54,220 --> 00:24:57,700
is local builds still take a long time

00:24:56,050 --> 00:25:00,910
and that's the beginning of a

00:24:57,700 --> 00:25:01,930
development cycle so there weren't yeah

00:25:00,910 --> 00:25:02,400
again there weren't any complaints about

00:25:01,930 --> 00:25:06,430
CI

00:25:02,400 --> 00:25:08,650
there were some just not as money and so

00:25:06,430 --> 00:25:11,680
CI was also sort of changing at this

00:25:08,650 --> 00:25:13,480
time in our company and we didn't want

00:25:11,680 --> 00:25:16,900
to add too many changes and mix at once

00:25:13,480 --> 00:25:19,360
so just not not great timing we also

00:25:16,900 --> 00:25:22,150
needed to make sure there are no cases

00:25:19,360 --> 00:25:24,310
of regression with local build time we

00:25:22,150 --> 00:25:26,680
again unfortunately dug ourselves into a

00:25:24,310 --> 00:25:30,610
hole by giving developers these machines

00:25:26,680 --> 00:25:31,960
with 28 cores so there's a thresholds

00:25:30,610 --> 00:25:34,030
for like the number of targets that you

00:25:31,960 --> 00:25:37,600
builds under which local execution is

00:25:34,030 --> 00:25:39,970
actually going to be faster and if our

00:25:37,600 --> 00:25:41,770
you know doves have received our

00:25:39,970 --> 00:25:45,160
education well and not you know doing

00:25:41,770 --> 00:25:47,190
basel built Slashdot all the time then

00:25:45,160 --> 00:25:52,000
that's gonna be a pretty frequent case

00:25:47,190 --> 00:25:53,800
and we also can't let builds fail due to

00:25:52,000 --> 00:25:56,680
availability issues of the remote

00:25:53,800 --> 00:25:59,800
executor in the worst case we should at

00:25:56,680 --> 00:26:02,080
least be able to just revert back to how

00:25:59,800 --> 00:26:04,360
things were before at least it works

00:26:02,080 --> 00:26:07,720
slow but operational is better than not

00:26:04,360 --> 00:26:09,910
operational at all and most importantly

00:26:07,720 --> 00:26:11,440
we needed to include our developers in

00:26:09,910 --> 00:26:14,050
validating this we need a way to let

00:26:11,440 --> 00:26:16,090
them easily opt-in and opt-out of using

00:26:14,050 --> 00:26:18,550
remote execution so they can give us

00:26:16,090 --> 00:26:21,850
feedback but still stay productive the

00:26:18,550 --> 00:26:25,000
whole time even if things go go broken

00:26:21,850 --> 00:26:27,070
or on fire because of this we came up

00:26:25,000 --> 00:26:29,740
with a small list of requirements we

00:26:27,070 --> 00:26:31,580
used a host hosted service at this time

00:26:29,740 --> 00:26:35,180
Google our de

00:26:31,580 --> 00:26:36,140
is available for for use we hear

00:26:35,180 --> 00:26:39,860
Google's pretty good at building

00:26:36,140 --> 00:26:42,380
software and we're already in GCP so it

00:26:39,860 --> 00:26:44,810
seemed like a pretty good fit to ensure

00:26:42,380 --> 00:26:46,970
forward progress we needed to enable

00:26:44,810 --> 00:26:48,800
local fallback in case the remote

00:26:46,970 --> 00:26:52,610
execution environment was experiencing

00:26:48,800 --> 00:26:55,310
issues and we also needed to enable

00:26:52,610 --> 00:26:57,640
dynamic scheduling so what dynamic

00:26:55,310 --> 00:27:00,020
scheduling does is it effectively

00:26:57,640 --> 00:27:01,880
launches an action and executes it

00:27:00,020 --> 00:27:05,120
locally and remotely at the same time

00:27:01,880 --> 00:27:07,340
and whichever finishes first wins so

00:27:05,120 --> 00:27:09,650
this solves our case of not having build

00:27:07,340 --> 00:27:15,200
time regressions with small numbers of

00:27:09,650 --> 00:27:17,270
targets when building locally so in

00:27:15,200 --> 00:27:19,970
order to gradually move into things we

00:27:17,270 --> 00:27:23,210
realized we could break this migration

00:27:19,970 --> 00:27:25,850
down in two phases let's separate builds

00:27:23,210 --> 00:27:30,200
and tests there's a big difference

00:27:25,850 --> 00:27:31,700
between two like builds are a little bit

00:27:30,200 --> 00:27:35,480
different than actually executing the

00:27:31,700 --> 00:27:38,840
code that you're building and we know we

00:27:35,480 --> 00:27:40,970
had some non hermetic tests just making

00:27:38,840 --> 00:27:44,060
builds faster was also gonna be a huge

00:27:40,970 --> 00:27:45,680
win for our devs that's really what they

00:27:44,060 --> 00:27:50,000
do a lot and sometimes just use these

00:27:45,680 --> 00:27:52,430
assets in other ways so initial set up

00:27:50,000 --> 00:27:55,100
to enable builds for a beta audience was

00:27:52,430 --> 00:27:58,040
pretty straightforward we got our RB

00:27:55,100 --> 00:28:02,510
instance set up we configured a real

00:27:58,040 --> 00:28:04,070
platform with docker and we had an image

00:28:02,510 --> 00:28:06,470
that contained all the tools we need to

00:28:04,070 --> 00:28:09,050
build our code base and then we invited

00:28:06,470 --> 00:28:11,000
our users to try it out we gave them a

00:28:09,050 --> 00:28:13,130
way to opt in with a simple config

00:28:11,000 --> 00:28:17,270
option they would just pass dash dash

00:28:13,130 --> 00:28:19,490
config equals RBE and they'd be able to

00:28:17,270 --> 00:28:21,290
then try out remote execution and give

00:28:19,490 --> 00:28:23,690
us feedback through a channel that we

00:28:21,290 --> 00:28:26,540
set up and so from that we got a lot of

00:28:23,690 --> 00:28:29,480
user error reports on little things that

00:28:26,540 --> 00:28:31,280
didn't work or we got a lot of error

00:28:29,480 --> 00:28:34,490
reports on the same thing that didn't

00:28:31,280 --> 00:28:35,720
work just in different ways and in

00:28:34,490 --> 00:28:38,150
addition to getting this direct user

00:28:35,720 --> 00:28:40,670
feedback we also set up an extra step in

00:28:38,150 --> 00:28:43,190
our CI job that shadowed our existing

00:28:40,670 --> 00:28:45,380
build step but using this RBE

00:28:43,190 --> 00:28:47,630
configuration so from this we could make

00:28:45,380 --> 00:28:49,940
in apples-to-apples comparison with real

00:28:47,630 --> 00:28:53,240
builds that succeeded in CI but failed

00:28:49,940 --> 00:28:55,220
remotely and then we could basically dig

00:28:53,240 --> 00:28:58,520
into the logs and pinpoint issues and

00:28:55,220 --> 00:29:00,050
see what was actually going on most of

00:28:58,520 --> 00:29:02,990
the issues we experienced were actually

00:29:00,050 --> 00:29:04,550
due to the dynamic scheduler this wasn't

00:29:02,990 --> 00:29:05,330
surprising we knew there were some

00:29:04,550 --> 00:29:09,620
issues with it

00:29:05,330 --> 00:29:10,910
luckily this was fixed upstream right

00:29:09,620 --> 00:29:13,520
around the time we were wrestling with

00:29:10,910 --> 00:29:19,700
this and we were able to back port that

00:29:13,520 --> 00:29:21,710
fix into our version so from that we

00:29:19,700 --> 00:29:25,610
kind of then released builds to

00:29:21,710 --> 00:29:27,680
everybody and then this entire process

00:29:25,610 --> 00:29:30,110
basically of going from planning to

00:29:27,680 --> 00:29:31,730
actually enabling remote builds by

00:29:30,110 --> 00:29:36,020
default for all the deserves took about

00:29:31,730 --> 00:29:39,200
two months and after that our builds

00:29:36,020 --> 00:29:42,530
were about five times faster and I think

00:29:39,200 --> 00:29:44,680
that was in the worst case so people are

00:29:42,530 --> 00:29:48,290
pretty happy with it

00:29:44,680 --> 00:29:50,180
so next next phase we've got to enable

00:29:48,290 --> 00:29:52,190
tests so once all the builds are working

00:29:50,180 --> 00:29:56,360
we've got to move on to enabling test

00:29:52,190 --> 00:29:58,250
execution RB this is a lot trickier many

00:29:56,360 --> 00:30:01,310
of our tests were not sandboxed

00:29:58,250 --> 00:30:03,740
we knew this and they were just not

00:30:01,310 --> 00:30:06,560
hermetic so tracking down these

00:30:03,740 --> 00:30:08,600
instances of non hermeticism had to be

00:30:06,560 --> 00:30:10,370
done on a case-by-case basis there's

00:30:08,600 --> 00:30:12,410
there's really no magic here you just

00:30:10,370 --> 00:30:15,230
kind of have to do the work and dig in

00:30:12,410 --> 00:30:17,570
and figure it out we also had flaky

00:30:15,230 --> 00:30:20,590
tests that were still around this

00:30:17,570 --> 00:30:23,090
prevented us from reliably cashing tests

00:30:20,590 --> 00:30:25,580
so while we were already paying off tech

00:30:23,090 --> 00:30:29,870
debt we figured why not go in and try to

00:30:25,580 --> 00:30:31,820
fix these flaky tests we also have test

00:30:29,870 --> 00:30:34,580
the require GPUs again that fund

00:30:31,820 --> 00:30:37,760
hardware requirement so we they weren't

00:30:34,580 --> 00:30:39,410
quite ready yet NRB when we started

00:30:37,760 --> 00:30:42,230
doing this so sort of a small question

00:30:39,410 --> 00:30:43,700
mark but we were fine with it because we

00:30:42,230 --> 00:30:45,440
can just filter those tests out they're

00:30:43,700 --> 00:30:46,970
all they're all labeled with tags and so

00:30:45,440 --> 00:30:50,390
we can just query them out and when we

00:30:46,970 --> 00:30:52,880
run them I won't bore you with all the

00:30:50,390 --> 00:30:56,390
details of making non hermetic tests

00:30:52,880 --> 00:30:57,780
hermetic these things are kind of gonna

00:30:56,390 --> 00:30:59,790
be specific

00:30:57,780 --> 00:31:00,840
to our use case and if you have to solve

00:30:59,790 --> 00:31:03,900
the same problem it's gonna be the same

00:31:00,840 --> 00:31:07,440
for you what I will say is that

00:31:03,900 --> 00:31:10,380
something like tools remote is a totally

00:31:07,440 --> 00:31:13,020
invaluable tool in this process it is

00:31:10,380 --> 00:31:15,390
your friends if you find issues with

00:31:13,020 --> 00:31:17,760
running stuff in remote execution and

00:31:15,390 --> 00:31:22,620
wants to reproduce them locally this is

00:31:17,760 --> 00:31:25,620
the way to do it so overall this took

00:31:22,620 --> 00:31:28,380
about four months for tests and that's

00:31:25,620 --> 00:31:30,900
including getting the GPUs we eventually

00:31:28,380 --> 00:31:33,360
got support for GPUs an RBE which was

00:31:30,900 --> 00:31:34,590
awesome getting that set up once we had

00:31:33,360 --> 00:31:37,650
all the other tests running was pretty

00:31:34,590 --> 00:31:40,980
low effort a really cool thing about

00:31:37,650 --> 00:31:43,020
that too is we have to support multiple

00:31:40,980 --> 00:31:46,410
types of GPUs when we're transitioning

00:31:43,020 --> 00:31:48,120
hardware platforms so with the power of

00:31:46,410 --> 00:31:50,160
macros we can just take the same test

00:31:48,120 --> 00:31:51,570
and then split it up and say hey let's

00:31:50,160 --> 00:31:53,940
run it on this platform in this platform

00:31:51,570 --> 00:32:00,060
at the same time and it's RB so they run

00:31:53,940 --> 00:32:02,340
in parallel also we were able to like

00:32:00,060 --> 00:32:04,740
completely remove the exclusive tests

00:32:02,340 --> 00:32:06,150
those things are completely isolated on

00:32:04,740 --> 00:32:09,450
workers now so they can't stomp on each

00:32:06,150 --> 00:32:11,070
other so that gets rid of that whole you

00:32:09,450 --> 00:32:13,140
know long tail of all these things that

00:32:11,070 --> 00:32:15,410
are that are finishing at the end after

00:32:13,140 --> 00:32:19,830
you've already executed all your tests

00:32:15,410 --> 00:32:22,700
we were also to again use RB to detects

00:32:19,830 --> 00:32:26,580
incredibly low flake rates in our tests

00:32:22,700 --> 00:32:28,100
so again you can run these things a

00:32:26,580 --> 00:32:31,650
thousand times a hundred thousand times

00:32:28,100 --> 00:32:33,660
and be like yep it actually is flaky we

00:32:31,650 --> 00:32:35,400
wouldn't have known this otherwise so we

00:32:33,660 --> 00:32:37,470
were able to get rid of these flakes and

00:32:35,400 --> 00:32:41,420
now we can actually reliably cache our

00:32:37,470 --> 00:32:41,420
tests bringing test times down even more

00:32:41,450 --> 00:32:48,360
so we've got builds and tests working on

00:32:44,760 --> 00:32:50,220
RB now fully on-boarded things are great

00:32:48,360 --> 00:32:54,330
what lessons do we learn from this

00:32:50,220 --> 00:32:56,610
process though first and foremost RB

00:32:54,330 --> 00:32:59,160
service is great it's been incredibly

00:32:56,610 --> 00:33:00,810
stable for us and it's allowed a team of

00:32:59,160 --> 00:33:03,330
small engineers like us to actually

00:33:00,810 --> 00:33:06,330
focus on the problems that are specific

00:33:03,330 --> 00:33:09,300
to our company and we are more suited to

00:33:06,330 --> 00:33:10,410
solve we can let the other people that

00:33:09,300 --> 00:33:11,990
have already built these great products

00:33:10,410 --> 00:33:15,080
do the heavy lifting

00:33:11,990 --> 00:33:17,660
we definitely don't regret pushing to

00:33:15,080 --> 00:33:20,630
solve the harder problem of developer

00:33:17,660 --> 00:33:23,360
builds first getting this stuff on a CI

00:33:20,630 --> 00:33:25,460
was trivial after we got all these hard

00:33:23,360 --> 00:33:27,380
problems solved with DES

00:33:25,460 --> 00:33:29,060
and then basically you get all of the

00:33:27,380 --> 00:33:34,430
same benefits in CI that you get locally

00:33:29,060 --> 00:33:35,600
for for free and it was also great

00:33:34,430 --> 00:33:37,730
because our devs could immediately see

00:33:35,600 --> 00:33:39,650
the impacts you know gradually you're

00:33:37,730 --> 00:33:42,130
releasing these things out from the beta

00:33:39,650 --> 00:33:44,210
group to actually releasing everybody

00:33:42,130 --> 00:33:46,520
you know we got a lot of messages of

00:33:44,210 --> 00:33:48,920
people saying wow this is incredible I

00:33:46,520 --> 00:33:50,150
haven't built this repo in weeks and I

00:33:48,920 --> 00:33:51,500
just pulled it down and built it in five

00:33:50,150 --> 00:33:53,000
minutes

00:33:51,500 --> 00:33:56,530
that's that's an incredibly powerful

00:33:53,000 --> 00:33:59,750
thing when it used to take like an hour

00:33:56,530 --> 00:34:01,130
it's also important to understand the

00:33:59,750 --> 00:34:03,830
difference between building your code

00:34:01,130 --> 00:34:05,300
remotely and testing remotely one of

00:34:03,830 --> 00:34:08,510
these things maybe is significantly

00:34:05,300 --> 00:34:10,159
harder than the others if you haven't

00:34:08,510 --> 00:34:12,290
paid a lot of attention to your tests

00:34:10,159 --> 00:34:14,780
targets of as they've developed over

00:34:12,290 --> 00:34:17,540
time if you haven't ensured that they

00:34:14,780 --> 00:34:20,060
are hermetic then you will find out when

00:34:17,540 --> 00:34:22,220
you try to go into remote execution so

00:34:20,060 --> 00:34:24,290
just get ready to pay off tech debt if

00:34:22,220 --> 00:34:25,940
you're not sure about that it's worth it

00:34:24,290 --> 00:34:31,580
but understand that does take some time

00:34:25,940 --> 00:34:34,880
so with all that there is still more to

00:34:31,580 --> 00:34:37,640
do we have changing hard requirements

00:34:34,880 --> 00:34:39,470
for tests all the time and we won't

00:34:37,640 --> 00:34:41,510
actually be able to always satisfy them

00:34:39,470 --> 00:34:43,880
with what's available in the cloud

00:34:41,510 --> 00:34:46,310
we'd like to eventually integrate some

00:34:43,880 --> 00:34:48,980
on-prem hardware with the system there

00:34:46,310 --> 00:34:50,620
it's it's possible there are multiple

00:34:48,980 --> 00:34:52,700
ways that we're think about doing this

00:34:50,620 --> 00:34:55,850
but we want to build something for the

00:34:52,700 --> 00:34:58,580
long term and again we don't want to

00:34:55,850 --> 00:35:01,070
have to maintain all of this

00:34:58,580 --> 00:35:02,690
infrastructure all the time we'd rather

00:35:01,070 --> 00:35:04,940
be able to move on and solve other

00:35:02,690 --> 00:35:07,160
problems because now that builds are

00:35:04,940 --> 00:35:10,790
fast devs are actually actually getting

00:35:07,160 --> 00:35:11,630
us to do other things and efficiency is

00:35:10,790 --> 00:35:15,260
something we're starting to care about

00:35:11,630 --> 00:35:17,900
too so great things are fast we need to

00:35:15,260 --> 00:35:20,100
sort of like maximize the return on our

00:35:17,900 --> 00:35:21,870
investment here

00:35:20,100 --> 00:35:22,980
it's sort of like squeeze the

00:35:21,870 --> 00:35:26,730
performance out of it we have really

00:35:22,980 --> 00:35:28,770
spiky workloads so a lot of time at when

00:35:26,730 --> 00:35:31,260
we're you know at peak capacity with our

00:35:28,770 --> 00:35:34,680
worker pools and remote execution we're

00:35:31,260 --> 00:35:35,850
not using a lot of that stuff so some

00:35:34,680 --> 00:35:37,050
basic things we've done are like

00:35:35,850 --> 00:35:39,690
time-based I was gonna actually actually

00:35:37,050 --> 00:35:42,540
saves us a ton of money but we'll have

00:35:39,690 --> 00:35:44,550
to go further from there no other thing

00:35:42,540 --> 00:35:45,600
is we're doing C++ compilation

00:35:44,550 --> 00:35:47,700
single-threaded

00:35:45,600 --> 00:35:50,580
as some of it actually takes a lot of

00:35:47,700 --> 00:35:52,050
memory so doing you know getting like

00:35:50,580 --> 00:35:53,280
single core machines with a lot of

00:35:52,050 --> 00:35:55,290
memories and really thing you can do in

00:35:53,280 --> 00:35:58,020
the cloud so we have to figure out how

00:35:55,290 --> 00:36:01,020
it's sort of you know accurately use the

00:35:58,020 --> 00:36:04,140
right machines to do those things all

00:36:01,020 --> 00:36:05,580
solvable problems but it's something we

00:36:04,140 --> 00:36:09,840
need to sort of like sink our teeth into

00:36:05,580 --> 00:36:10,920
and figure out so you want to help us

00:36:09,840 --> 00:36:16,950
solve any those problems we're also

00:36:10,920 --> 00:36:19,920
hiring it's worth mentioning and with

00:36:16,950 --> 00:36:26,040
that thank you thank you have some time

00:36:19,920 --> 00:36:28,140
for questions thanks so much as always

00:36:26,040 --> 00:36:32,280
questions will give a few seconds for

00:36:28,140 --> 00:36:35,430
people to hop on stage okay well yeah hi

00:36:32,280 --> 00:36:37,680
i'm sergio from lucid software so i'm

00:36:35,430 --> 00:36:39,990
wondering what you were saying that to

00:36:37,680 --> 00:36:42,630
measure the performance of basil you

00:36:39,990 --> 00:36:43,830
were using the profiler this I mean you

00:36:42,630 --> 00:36:45,960
were using the profile on every

00:36:43,830 --> 00:36:48,000
invocation of basil that any dev was

00:36:45,960 --> 00:36:50,430
doing on their workstations yes did you

00:36:48,000 --> 00:36:54,450
see any significant performance impact

00:36:50,430 --> 00:36:57,090
from that not really it was kind of hard

00:36:54,450 --> 00:36:58,350
to think about that because sort of a

00:36:57,090 --> 00:36:59,910
chicken and egg problem because we're

00:36:58,350 --> 00:37:03,900
like what is what is the performance

00:36:59,910 --> 00:37:06,140
already so it's something we kind of

00:37:03,900 --> 00:37:10,200
want to take a step back and look into

00:37:06,140 --> 00:37:13,020
but yeah we there's no hard answer for

00:37:10,200 --> 00:37:14,670
that is did you encounter like suddenly

00:37:13,020 --> 00:37:15,900
developers being like hey like why are

00:37:14,670 --> 00:37:18,920
things taking a bit longer

00:37:15,900 --> 00:37:18,920
no definitely not yeah

00:37:24,670 --> 00:37:32,230
okay okay well if there's no more

00:37:28,940 --> 00:37:35,950
questions let's thank Michael and Nico

00:37:32,230 --> 00:37:39,460
thanks for coming out super interesting

00:37:35,950 --> 00:37:39,460

YouTube URL: https://www.youtube.com/watch?v=fjfFe98LTm8


