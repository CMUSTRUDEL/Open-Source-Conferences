Title: BazelCon 2019 Day 1: Lightning Talk â€“ Bazel Parallel and Asynchronous Artifact Publishing Pipeline
Publication date: 2020-01-15
Playlist: BazelCon 2019
Description: 
	Liron Tal, Wix event: Bazelcon 2019; re_ty: Publish; product: Open Source - General; fullname: Liron Tal;
Captions: 
	00:00:00,530 --> 00:00:06,480
okay hi everyone my name is Liran Tao

00:00:03,870 --> 00:00:08,280
I'm a software engineer at wix.com and

00:00:06,480 --> 00:00:10,139
today I want to talk about building a

00:00:08,280 --> 00:00:13,200
parallel in a synchronous artifact

00:00:10,139 --> 00:00:15,360
publishing pipeline so in this lightning

00:00:13,200 --> 00:00:17,990
talk of focus on the process of taking

00:00:15,360 --> 00:00:20,670
build outputs such as docker images

00:00:17,990 --> 00:00:23,130
uploading them to a binary repository

00:00:20,670 --> 00:00:25,410
and tagging them incrementally in the

00:00:23,130 --> 00:00:27,599
correct order and the challenges that we

00:00:25,410 --> 00:00:31,619
face to make this process both fast and

00:00:27,599 --> 00:00:35,040
correct so our initial implementation is

00:00:31,619 --> 00:00:37,170
this one we've implemented a publisher

00:00:35,040 --> 00:00:39,360
build step which is running after the

00:00:37,170 --> 00:00:41,610
build has finished it discovers

00:00:39,360 --> 00:00:45,120
artifacts by using custom tags and

00:00:41,610 --> 00:00:47,760
parsing the build event protocol we're

00:00:45,120 --> 00:00:50,250
pushing docker images with a basil run

00:00:47,760 --> 00:00:53,640
of rules docker container push which

00:00:50,250 --> 00:00:55,500
requires the basil workspace and we

00:00:53,640 --> 00:00:57,780
utilize the fact that the build agent

00:00:55,500 --> 00:01:00,629
has access to the build outputs from

00:00:57,780 --> 00:01:04,439
remote workers so this basil run is

00:01:00,629 --> 00:01:07,409
actually working the publisher step

00:01:04,439 --> 00:01:10,799
after it publishes all the docker images

00:01:07,409 --> 00:01:15,270
sends metadata such as like artifact ID

00:01:10,799 --> 00:01:17,430
the commit time and yeah and that's

00:01:15,270 --> 00:01:19,950
pretty much it - a promotion service and

00:01:17,430 --> 00:01:22,500
then the promotion service decides

00:01:19,950 --> 00:01:26,280
whether to increment the version or not

00:01:22,500 --> 00:01:30,030
to increment it so why do we why do we

00:01:26,280 --> 00:01:32,790
need a promotion service so we really

00:01:30,030 --> 00:01:36,450
can't promote based on local reasoning

00:01:32,790 --> 00:01:38,579
on the build agent and the reason we can

00:01:36,450 --> 00:01:40,860
do that is that we're running parallel

00:01:38,579 --> 00:01:43,020
builds on master and as most of you

00:01:40,860 --> 00:01:45,540
pretty pretty much know that if you're

00:01:43,020 --> 00:01:47,759
running parallel stuff you cannot be

00:01:45,540 --> 00:01:49,829
sure of any ordering of those and that

00:01:47,759 --> 00:01:52,860
means that if there are two builds are

00:01:49,829 --> 00:01:55,560
running in parallel and one if one of

00:01:52,860 --> 00:01:57,570
them finishes we cannot rely on the fact

00:01:55,560 --> 00:02:01,740
that it finishes or the other one

00:01:57,570 --> 00:02:05,280
finishes afterwards so we need to set

00:02:01,740 --> 00:02:06,990
some ordering and specifically basally

00:02:05,280 --> 00:02:09,929
is obviously aggressively caching

00:02:06,990 --> 00:02:12,180
targets so one build may have started

00:02:09,929 --> 00:02:13,500
and the build has started afterwards but

00:02:12,180 --> 00:02:16,170
the builds that

00:02:13,500 --> 00:02:18,150
started afterwards we'll use the hard

00:02:16,170 --> 00:02:21,300
work of the previous builds and use the

00:02:18,150 --> 00:02:24,540
cache and may finish before that so we

00:02:21,300 --> 00:02:27,060
need to account for that we also support

00:02:24,540 --> 00:02:28,950
history builds which means that

00:02:27,060 --> 00:02:31,680
developers can decide to rerun their

00:02:28,950 --> 00:02:33,660
previous builds and there isn't any

00:02:31,680 --> 00:02:37,470
state that says that like this is a

00:02:33,660 --> 00:02:40,260
rerun or it's just a new fresh building

00:02:37,470 --> 00:02:42,330
master and we need to know that not to

00:02:40,260 --> 00:02:44,850
promote it even though it's just a build

00:02:42,330 --> 00:02:47,489
that finished now it's actually like a

00:02:44,850 --> 00:02:52,260
fresh build but with stale commits or of

00:02:47,489 --> 00:02:54,989
data in addition we need to support

00:02:52,260 --> 00:02:57,180
multi target artifacts

00:02:54,989 --> 00:02:59,760
most of our artifacts are actually a

00:02:57,180 --> 00:03:02,520
docker image and then some targets which

00:02:59,760 --> 00:03:07,470
contain resources and configs

00:03:02,520 --> 00:03:11,910
similar to what like Etsy showed earlier

00:03:07,470 --> 00:03:13,770
and our promotion service needs to

00:03:11,910 --> 00:03:17,700
aggregate all these targets before it

00:03:13,770 --> 00:03:21,840
can actually promote in addition given

00:03:17,700 --> 00:03:24,299
that we have promotion micro service and

00:03:21,840 --> 00:03:26,730
multiple nodes so it's actually a

00:03:24,299 --> 00:03:28,410
distributed system and incrementing

00:03:26,730 --> 00:03:30,390
correctly in a distributed system is

00:03:28,410 --> 00:03:33,269
something you need to take care of so we

00:03:30,390 --> 00:03:35,280
do that by using an event event based

00:03:33,269 --> 00:03:38,640
architecture and we're charting our

00:03:35,280 --> 00:03:40,620
consumers by the artifact ID so actually

00:03:38,640 --> 00:03:43,079
each promotion flow for each artifact is

00:03:40,620 --> 00:03:45,750
running effectively on a single threaded

00:03:43,079 --> 00:03:48,090
event loop so we get no race conditions

00:03:45,750 --> 00:03:50,790
and all kind of stuff like that and we

00:03:48,090 --> 00:03:53,910
try to minimalize the logic on that like

00:03:50,790 --> 00:03:57,180
critical path to prevent any errors or

00:03:53,910 --> 00:03:59,070
any any other problems and also from

00:03:57,180 --> 00:04:01,680
that part taking a long time we want to

00:03:59,070 --> 00:04:06,329
make that synchronize part as short as

00:04:01,680 --> 00:04:09,209
possible so we've got correct we've got

00:04:06,329 --> 00:04:10,739
all this feature but not fast so as most

00:04:09,209 --> 00:04:13,440
of you know when we've heard for many

00:04:10,739 --> 00:04:16,410
companies here the build part is very

00:04:13,440 --> 00:04:19,140
fast and as you can see in our graphs so

00:04:16,410 --> 00:04:20,910
the build part is green and then the

00:04:19,140 --> 00:04:23,039
yellow part is the publisher step which

00:04:20,910 --> 00:04:26,940
I've described and you can see it takes

00:04:23,039 --> 00:04:30,360
about 30 percent of the overall time

00:04:26,940 --> 00:04:32,940
and it's a bummer it's kind of wasteful

00:04:30,360 --> 00:04:34,680
because as I mentioned before the

00:04:32,940 --> 00:04:38,220
publisher step is waiting for the whole

00:04:34,680 --> 00:04:41,340
bill to finish and somehow we want to

00:04:38,220 --> 00:04:44,580
improve on that and that's not our only

00:04:41,340 --> 00:04:46,260
problem in making that fast in addition

00:04:44,580 --> 00:04:48,870
we're running that builds up the

00:04:46,260 --> 00:04:51,630
publisher build step on orchestration

00:04:48,870 --> 00:04:55,530
machines and those have low I ops which

00:04:51,630 --> 00:04:58,130
actually means that we're we cannot do

00:04:55,530 --> 00:05:02,340
all the parallelization that we want to

00:04:58,130 --> 00:05:04,460
push docker images last but not least is

00:05:02,340 --> 00:05:07,410
that the builds without biting

00:05:04,460 --> 00:05:10,280
optimization that many have already

00:05:07,410 --> 00:05:13,590
talked about has actually made the first

00:05:10,280 --> 00:05:15,470
issue worse for us because it has

00:05:13,590 --> 00:05:18,780
reduced the build time the green lines

00:05:15,470 --> 00:05:21,840
but the yellow lines now are longer

00:05:18,780 --> 00:05:23,790
because our publisher step which needs

00:05:21,840 --> 00:05:26,820
all kinds of targets does not get that

00:05:23,790 --> 00:05:30,450
so it needs it needs to run and do more

00:05:26,820 --> 00:05:33,090
work in the basil run so the ratio for

00:05:30,450 --> 00:05:34,860
us for us has become worse like it

00:05:33,090 --> 00:05:37,650
should be optimization and it optimize

00:05:34,860 --> 00:05:41,850
the build but actually our publishing

00:05:37,650 --> 00:05:45,690
step became even longer so we have again

00:05:41,850 --> 00:05:48,510
correct but not fast and our take - and

00:05:45,690 --> 00:05:51,960
our implementation is in a synchronous

00:05:48,510 --> 00:05:54,150
and parallel and fast one so we

00:05:51,960 --> 00:05:56,880
implemented a publisher service which is

00:05:54,150 --> 00:05:59,669
pulling the results or to know when each

00:05:56,880 --> 00:06:03,000
of our artifacts targets are ready and

00:05:59,669 --> 00:06:06,050
then that's this service downloads and

00:06:03,000 --> 00:06:08,370
publishes each target as soon as

00:06:06,050 --> 00:06:11,010
possible while the build is still

00:06:08,370 --> 00:06:13,919
running so we're trying to parallelize

00:06:11,010 --> 00:06:16,140
this publishing part and actually the

00:06:13,919 --> 00:06:18,330
build part so we're trying to reduce all

00:06:16,140 --> 00:06:21,960
these yellow lines as much as possible

00:06:18,330 --> 00:06:24,990
and move them to the to happen while the

00:06:21,960 --> 00:06:27,570
build in parallel to the build we

00:06:24,990 --> 00:06:31,110
created a macro and a rule which outputs

00:06:27,570 --> 00:06:33,870
the image info from rules docker and we

00:06:31,110 --> 00:06:37,050
use that image info to push to docker

00:06:33,870 --> 00:06:39,510
registry using docker client and we

00:06:37,050 --> 00:06:40,950
actually push only some layers and not

00:06:39,510 --> 00:06:43,980
the whole image because

00:06:40,950 --> 00:06:46,380
we have all kinds of base images that

00:06:43,980 --> 00:06:47,580
there already exist and we know that and

00:06:46,380 --> 00:06:50,850
we don't need to push them so we just

00:06:47,580 --> 00:06:53,160
pushed some layers and after all that we

00:06:50,850 --> 00:06:55,820
just wait for the bill to succeed and

00:06:53,160 --> 00:06:59,360
then we notify the promotion service

00:06:55,820 --> 00:07:02,160
which now only needs to tag correctly

00:06:59,360 --> 00:07:04,830
which is very very fast because all the

00:07:02,160 --> 00:07:11,780
heavy lifting the publishing is already

00:07:04,830 --> 00:07:14,730
happened so actually we're very happy

00:07:11,780 --> 00:07:17,850
but we do depend on some implementation

00:07:14,730 --> 00:07:20,070
details of rules docker we depend just

00:07:17,850 --> 00:07:23,010
on a tiny bit here I see some people

00:07:20,070 --> 00:07:24,630
laughing at the back but it's just a

00:07:23,010 --> 00:07:27,990
tiny bit we're not worried about that

00:07:24,630 --> 00:07:30,960
but we do have a huge win which was

00:07:27,990 --> 00:07:33,240
worth for us is that we do not need to

00:07:30,960 --> 00:07:36,360
run basel outside our build a gents and

00:07:33,240 --> 00:07:38,580
not only basel but also cloning git

00:07:36,360 --> 00:07:40,080
repositories and all stuff like that is

00:07:38,580 --> 00:07:44,310
something that we've had in the past and

00:07:40,080 --> 00:07:47,030
is it's very very painful and we prefer

00:07:44,310 --> 00:07:49,590
being dependent on some minor

00:07:47,030 --> 00:07:51,990
implementation details on like having to

00:07:49,590 --> 00:07:54,750
deal with when running basil and cloning

00:07:51,990 --> 00:07:57,300
git repositories in addition this

00:07:54,750 --> 00:07:59,580
service enjoys really high degree of

00:07:57,300 --> 00:08:03,180
parallelism which means that we can add

00:07:59,580 --> 00:08:05,160
as many instances that we need to speed

00:08:03,180 --> 00:08:07,440
up to make sure it's always faster than

00:08:05,160 --> 00:08:09,240
the build so we can monitor that and

00:08:07,440 --> 00:08:12,260
make sure we have enough instances to

00:08:09,240 --> 00:08:16,850
make that yellow part just disappear and

00:08:12,260 --> 00:08:20,910
finish before the builds really finish

00:08:16,850 --> 00:08:22,740
potentially we're planning to do as

00:08:20,910 --> 00:08:26,250
synchronous trimming to maximize the

00:08:22,740 --> 00:08:28,940
throughput and we have two more features

00:08:26,250 --> 00:08:31,380
I'd like to mention which are upcoming

00:08:28,940 --> 00:08:34,849
the first one we want to do a

00:08:31,380 --> 00:08:38,370
fine-grained promotion which means that

00:08:34,849 --> 00:08:42,690
now we wait for the whole bill to finish

00:08:38,370 --> 00:08:44,910
before we promote but we can let the

00:08:42,690 --> 00:08:47,580
developers figure out what targets they

00:08:44,910 --> 00:08:50,370
want to wait on and just promote their

00:08:47,580 --> 00:08:52,680
version once these targets are ready and

00:08:50,370 --> 00:08:54,930
not for the whole bill to be ready

00:08:52,680 --> 00:08:58,380
another cool feature will

00:08:54,930 --> 00:09:01,020
to add is that we have a continuous

00:08:58,380 --> 00:09:04,560
deployment system and if you want to opt

00:09:01,020 --> 00:09:07,620
in so that each commit of your artifact

00:09:04,560 --> 00:09:09,149
will actually roll out and have a

00:09:07,620 --> 00:09:11,580
continuous deployment we are playing to

00:09:09,149 --> 00:09:13,860
edit it's some kind of a tag so this is

00:09:11,580 --> 00:09:18,089
another nice feature and similar a bit

00:09:13,860 --> 00:09:21,180
to what also Etsy presented that's it so

00:09:18,089 --> 00:09:23,730
this is our journey on making this flow

00:09:21,180 --> 00:09:25,560
both fast and correct and I really hope

00:09:23,730 --> 00:09:27,360
your builds will be just as fast so

00:09:25,560 --> 00:09:28,770
other components in the system just like

00:09:27,360 --> 00:09:41,430
this one will start to become your

00:09:28,770 --> 00:09:54,779
bottlenecks thank you sorry questions

00:09:41,430 --> 00:09:58,760
anyone yeah okay so so I'll try to do

00:09:54,779 --> 00:10:01,440
that quick so we have this destroying oh

00:09:58,760 --> 00:10:04,290
okay so the question is why there builds

00:10:01,440 --> 00:10:07,500
without the bytes has been problematic

00:10:04,290 --> 00:10:09,750
to us so if you can see in destroying we

00:10:07,500 --> 00:10:14,610
have the publisher step and it's doing a

00:10:09,750 --> 00:10:18,470
basil run and with the output of like

00:10:14,610 --> 00:10:23,010
routes docker container push and we need

00:10:18,470 --> 00:10:26,400
a lot of like all kinds of targets to be

00:10:23,010 --> 00:10:28,920
in the workspace already of that let's

00:10:26,400 --> 00:10:32,490
say agent that is running the publisher

00:10:28,920 --> 00:10:32,880
part now because of builds without the

00:10:32,490 --> 00:10:34,709
bytes

00:10:32,880 --> 00:10:38,100
there are remote workers keep some of

00:10:34,709 --> 00:10:42,270
the targets and that part now the basil

00:10:38,100 --> 00:10:44,339
run needs like to bring in more stuff so

00:10:42,270 --> 00:10:46,020
like the build is fast but now this part

00:10:44,339 --> 00:10:51,390
needs to do more work so the ratio the

00:10:46,020 --> 00:10:53,750
overall ratio yeah okay and no any more

00:10:51,390 --> 00:10:53,750

YouTube URL: https://www.youtube.com/watch?v=TD1JDPD0hRA


