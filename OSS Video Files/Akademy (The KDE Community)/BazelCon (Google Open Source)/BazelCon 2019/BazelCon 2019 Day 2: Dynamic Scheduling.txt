Title: BazelCon 2019 Day 2: Dynamic Scheduling
Publication date: 2020-01-16
Playlist: BazelCon 2019
Description: 
	Julio Merino, Google event: Bazelcon 2019; re_ty: Publish; product: Open Source - General; fullname: Julio Merino;
Captions: 
	00:00:02,090 --> 00:00:07,890
hi Ron

00:00:03,540 --> 00:00:10,380
welcome to the second talk and we have

00:00:07,890 --> 00:00:14,960
Julio from basil team talking about

00:00:10,380 --> 00:00:18,390
dynamic execution right hello everyone

00:00:14,960 --> 00:00:21,090
so I've been in the basil team for I

00:00:18,390 --> 00:00:23,880
think about four years now focusing on

00:00:21,090 --> 00:00:26,070
in especially like local execution

00:00:23,880 --> 00:00:27,480
aspects of basil you may have heard my

00:00:26,070 --> 00:00:30,029
name from the Sun boxing stuff

00:00:27,480 --> 00:00:32,099
especially on Mac OS and our team we

00:00:30,029 --> 00:00:34,110
support specifically Mac OS builds and

00:00:32,099 --> 00:00:35,610
iOS builds at Google so we've been doing

00:00:34,110 --> 00:00:37,110
a lot of work to make those faster it

00:00:35,610 --> 00:00:39,540
has been the primary focus of our work

00:00:37,110 --> 00:00:41,399
and today I want to focus on this

00:00:39,540 --> 00:00:44,399
picture that we have called enemy

00:00:41,399 --> 00:00:45,660
execution or dynamic scheduling what

00:00:44,399 --> 00:00:47,610
you're supposed to give you the best of

00:00:45,660 --> 00:00:50,719
the best possible clean builds and

00:00:47,610 --> 00:00:54,510
incremental builds but at the same time

00:00:50,719 --> 00:00:56,699
so in this presentation the main goal is

00:00:54,510 --> 00:00:59,039
to basically walk you through what this

00:00:56,699 --> 00:01:01,559
feature is it's not very complicated

00:00:59,039 --> 00:01:04,260
conceptually but we'll get over that and

00:01:01,559 --> 00:01:06,000
then I'll dive into details of how it

00:01:04,260 --> 00:01:07,920
works and how it doesn't work or it

00:01:06,000 --> 00:01:10,200
didn't work before we've had a lot of

00:01:07,920 --> 00:01:12,180
problems with when sorry it was written

00:01:10,200 --> 00:01:14,250
by someone else a couple of years ago

00:01:12,180 --> 00:01:16,409
philippe from our team and we've been

00:01:14,250 --> 00:01:19,710
we've had to do quite a few of changes

00:01:16,409 --> 00:01:23,299
to make it work better with that said

00:01:19,710 --> 00:01:26,869
let's recap a little bit how basil works

00:01:23,299 --> 00:01:29,369
this obvious to many of you probably but

00:01:26,869 --> 00:01:31,470
so as you know we have a bunch of data

00:01:29,369 --> 00:01:33,750
sources that live on your filesystem

00:01:31,470 --> 00:01:34,500
probably like the red boxes are what I'm

00:01:33,750 --> 00:01:36,119
talking about

00:01:34,500 --> 00:01:39,540
and from there we build this in memory

00:01:36,119 --> 00:01:41,579
graph which are the green boxes and you

00:01:39,540 --> 00:01:43,500
know we have some targets in memory we

00:01:41,579 --> 00:01:45,450
have configured targets we have a bunch

00:01:43,500 --> 00:01:48,000
of actions that we have to run so today

00:01:45,450 --> 00:01:49,619
we're going to focus on a specific the

00:01:48,000 --> 00:01:51,140
action execution part right we have all

00:01:49,619 --> 00:01:53,220
these actions that we have constructed

00:01:51,140 --> 00:01:55,020
which essentially are like command

00:01:53,220 --> 00:01:56,759
invocations compilers linkers whatever

00:01:55,020 --> 00:01:58,439
it is that you have in your build we

00:01:56,759 --> 00:02:02,130
have to run run those things and we want

00:01:58,439 --> 00:02:03,509
to do it fast diving into this so we've

00:02:02,130 --> 00:02:07,920
loaded this into memory and then we have

00:02:03,509 --> 00:02:09,660
the execution phase so we have basically

00:02:07,920 --> 00:02:13,010
two kinds and we can write in different

00:02:09,660 --> 00:02:14,239
ways in a clean build basic

00:02:13,010 --> 00:02:15,950
you have to build everything from

00:02:14,239 --> 00:02:19,250
scratch right you have started with a

00:02:15,950 --> 00:02:22,400
clean project if you check out or

00:02:19,250 --> 00:02:24,019
whatever it is and basil hasn't started

00:02:22,400 --> 00:02:25,909
yet so you have no state on what's

00:02:24,019 --> 00:02:27,650
happening so you do basil build dot a

00:02:25,909 --> 00:02:29,150
dot or whatever it is and then what

00:02:27,650 --> 00:02:30,319
Chris read the bill graphic memory which

00:02:29,150 --> 00:02:32,690
are all the green boxes that you can see

00:02:30,319 --> 00:02:34,819
here and essentially we have to go over

00:02:32,690 --> 00:02:37,760
the whole graph to compile and Link your

00:02:34,819 --> 00:02:40,549
final application the parallelism of

00:02:37,760 --> 00:02:42,709
this process is determined by the dice -

00:02:40,549 --> 00:02:44,959
jobs flag more or less we will get into

00:02:42,709 --> 00:02:48,260
later and essentially here we have two

00:02:44,959 --> 00:02:51,470
CPUs on your machine and that means you

00:02:48,260 --> 00:02:55,160
can only run two preset ones just as we

00:02:51,470 --> 00:02:56,989
do these locally we can also do it

00:02:55,160 --> 00:02:59,780
obviously remotely right if you have

00:02:56,989 --> 00:03:00,769
enable remote execution which thankfully

00:02:59,780 --> 00:03:02,209
there were a couple of talks this

00:03:00,769 --> 00:03:03,349
morning that covered a lot of the stuff

00:03:02,209 --> 00:03:06,680
that I was going to say but I'm not

00:03:03,349 --> 00:03:09,739
gonna say then you can take advantage of

00:03:06,680 --> 00:03:12,079
many more CPUs or workers to run your

00:03:09,739 --> 00:03:14,629
build faster right you have all these

00:03:12,079 --> 00:03:16,310
different workers now we have five

00:03:14,629 --> 00:03:17,959
workers we can run all the actives in

00:03:16,310 --> 00:03:19,849
parallel so essentially you can get the

00:03:17,959 --> 00:03:24,200
possible clean the the best possible

00:03:19,849 --> 00:03:26,989
clean bill time and here again we have

00:03:24,200 --> 00:03:28,549
the job setting which you would have to

00:03:26,989 --> 00:03:33,260
increase to take advantage of these

00:03:28,549 --> 00:03:37,069
parallelism right these four clean bills

00:03:33,260 --> 00:03:38,450
so then we have the same but for

00:03:37,069 --> 00:03:40,880
incrementally let's write an incremental

00:03:38,450 --> 00:03:43,430
build for this talk we will look at

00:03:40,880 --> 00:03:44,660
those that are you know you touch mostly

00:03:43,430 --> 00:03:46,489
leaves you taught to leave of your

00:03:44,660 --> 00:03:49,400
project and that has to traverse the

00:03:46,489 --> 00:03:52,010
graph most edges in one path and has to

00:03:49,400 --> 00:03:54,019
rebuild things in between so in this

00:03:52,010 --> 00:03:55,220
case we touch one dot C which is a

00:03:54,019 --> 00:03:56,720
source file they have no other

00:03:55,220 --> 00:03:58,879
dependencies and that kind of

00:03:56,720 --> 00:04:00,799
invalidated the library belongs to there

00:03:58,879 --> 00:04:04,400
has to be relinked and the final vinery

00:04:00,799 --> 00:04:06,560
that has to be relinked as well in the

00:04:04,400 --> 00:04:08,720
in this case all the white boxes have

00:04:06,560 --> 00:04:10,609
not don't have to be reevaluated because

00:04:08,720 --> 00:04:12,230
you didn't touch anything in them and in

00:04:10,609 --> 00:04:13,699
this case even if you have two CPUs we

00:04:12,230 --> 00:04:17,209
can only use one of them because we're

00:04:13,699 --> 00:04:18,859
limited by be the change that we made so

00:04:17,209 --> 00:04:20,660
that's for local build and in this case

00:04:18,859 --> 00:04:23,539
local will probably gives you a pretty

00:04:20,660 --> 00:04:25,340
good build time because you you just

00:04:23,539 --> 00:04:26,450
need a subset of the resources that you

00:04:25,340 --> 00:04:28,620
have

00:04:26,450 --> 00:04:31,050
so what that means is if you enable

00:04:28,620 --> 00:04:32,820
remote execution you still have all

00:04:31,050 --> 00:04:34,350
those workers that you had before but

00:04:32,820 --> 00:04:39,090
you are only using one of them

00:04:34,350 --> 00:04:41,490
essentially easy and again in this case

00:04:39,090 --> 00:04:43,160
the job setting would be a limiting

00:04:41,490 --> 00:04:45,060
factor I've had a lot of

00:04:43,160 --> 00:04:46,440
invalidations in the graph but in this

00:04:45,060 --> 00:04:49,710
case it's just you know you're using

00:04:46,440 --> 00:04:51,900
only one executor so we say we've been

00:04:49,710 --> 00:04:55,530
seeing we can run things both locally

00:04:51,900 --> 00:04:57,090
and remotely and the way you do that is

00:04:55,530 --> 00:04:59,820
you can't configure it via flags right

00:04:57,090 --> 00:05:01,620
so you could be even fancier as George

00:04:59,820 --> 00:05:05,070
from uber was explaining this morning

00:05:01,620 --> 00:05:07,590
and say well I know that compiling one

00:05:05,070 --> 00:05:09,480
dot C works very well remotely so I'm

00:05:07,590 --> 00:05:11,850
gonna say for this specific action I

00:05:09,480 --> 00:05:14,130
always want it to go to the remote

00:05:11,850 --> 00:05:16,380
worker but for everything else or maybe

00:05:14,130 --> 00:05:17,970
B dot C I know that's very costly to be

00:05:16,380 --> 00:05:20,130
send remotely maybe because it has too

00:05:17,970 --> 00:05:22,560
many inputs or something so I want that

00:05:20,130 --> 00:05:26,720
to always happen locally and you can use

00:05:22,560 --> 00:05:30,120
flags and say well basil do it this way

00:05:26,720 --> 00:05:32,430
using flags has some problems first its

00:05:30,120 --> 00:05:34,650
pain right I'm sure you are all tired of

00:05:32,430 --> 00:05:35,970
passing flags to basil and the other

00:05:34,650 --> 00:05:38,790
problem is that you have to know upfront

00:05:35,970 --> 00:05:40,410
how the actions behave right you need to

00:05:38,790 --> 00:05:42,120
know exactly that this specific action

00:05:40,410 --> 00:05:45,360
or this specific type of actions will

00:05:42,120 --> 00:05:47,280
behave better locally or remotely and if

00:05:45,360 --> 00:05:49,050
things change in your project that

00:05:47,280 --> 00:05:50,790
changes those constraints you need to

00:05:49,050 --> 00:05:52,170
change the flags you need to remember to

00:05:50,790 --> 00:05:55,620
do that and it's hard to evaluate and

00:05:52,170 --> 00:05:57,360
it's hard to decide how to do that the

00:05:55,620 --> 00:06:01,080
other problem is for example if you will

00:05:57,360 --> 00:06:04,140
force B dot C to run locally but via

00:06:01,080 --> 00:06:05,970
this flag then even if that action

00:06:04,140 --> 00:06:07,530
happened to be cached or available in

00:06:05,970 --> 00:06:09,480
the remote cache you wouldn't be able to

00:06:07,530 --> 00:06:11,250
use it because you would never consult

00:06:09,480 --> 00:06:13,830
the remote touch to check your that

00:06:11,250 --> 00:06:15,660
action was there so the solution

00:06:13,830 --> 00:06:16,830
essentially is to use these dynamic

00:06:15,660 --> 00:06:19,650
execution things that we've been talking

00:06:16,830 --> 00:06:21,930
about which is basically for every

00:06:19,650 --> 00:06:24,210
action that you have to run you send it

00:06:21,930 --> 00:06:26,700
to the remote executor and you also run

00:06:24,210 --> 00:06:28,830
it locally and then you just pick

00:06:26,700 --> 00:06:32,910
whatever finishes faster and discard the

00:06:28,830 --> 00:06:35,310
other the other one an important thing

00:06:32,910 --> 00:06:37,770
here is that because you're going to run

00:06:35,310 --> 00:06:39,000
the same action in two places the tool

00:06:37,770 --> 00:06:39,300
chains and the environments have to

00:06:39,000 --> 00:06:41,009
match

00:06:39,300 --> 00:06:44,069
otherwise the output will be different

00:06:41,009 --> 00:06:45,690
and that would be very problematic it's

00:06:44,069 --> 00:06:47,970
a big assumption but if you're using

00:06:45,690 --> 00:06:51,090
remote execution you really need to get

00:06:47,970 --> 00:06:52,979
these things right and it's tricky but

00:06:51,090 --> 00:06:57,539
assuming you can do that then this model

00:06:52,979 --> 00:07:00,629
works pretty well so with this you know

00:06:57,539 --> 00:07:02,639
as I was saying before let's say B that

00:07:00,629 --> 00:07:04,080
see you know it's always faster locally

00:07:02,639 --> 00:07:05,699
but for whatever reason somebody

00:07:04,080 --> 00:07:08,250
happened to build a little more the

00:07:05,699 --> 00:07:09,389
earlier and it was cached then you would

00:07:08,250 --> 00:07:11,340
take advantage of that immediately

00:07:09,389 --> 00:07:13,379
without having to rebuild it in your

00:07:11,340 --> 00:07:16,319
local machine even if you thought that

00:07:13,379 --> 00:07:18,090
building it locally would be faster so

00:07:16,319 --> 00:07:21,629
that is actually dynamic execution in

00:07:18,090 --> 00:07:23,550
concept very simple right so now we dive

00:07:21,629 --> 00:07:25,199
into this a little bit more but first of

00:07:23,550 --> 00:07:26,400
all how do we configure all these things

00:07:25,199 --> 00:07:28,379
today like I was saying you can pass

00:07:26,400 --> 00:07:30,479
some flags and to say I want this to run

00:07:28,379 --> 00:07:32,759
liberally these to run locally so that's

00:07:30,479 --> 00:07:39,960
all we're all done via something we call

00:07:32,759 --> 00:07:42,599
strategies which is basil's abstraction

00:07:39,960 --> 00:07:44,190
around the exec system call as George

00:07:42,599 --> 00:07:45,750
also mentioned this morning so

00:07:44,190 --> 00:07:48,150
essentially when we want to run any sub

00:07:45,750 --> 00:07:50,009
process from within basil we use a

00:07:48,150 --> 00:07:52,050
strategy which is distraction to save a

00:07:50,009 --> 00:07:53,930
bit run this thing and then when you

00:07:52,050 --> 00:07:57,000
have the result give it back to me

00:07:53,930 --> 00:07:59,099
you can change strategies due at any

00:07:57,000 --> 00:08:00,330
time they do not embody that your bill

00:07:59,099 --> 00:08:02,460
graph because essentially they just

00:08:00,330 --> 00:08:04,830
configure the behavior of this function

00:08:02,460 --> 00:08:06,659
of this executive education but they

00:08:04,830 --> 00:08:08,190
don't not change the semantics of the

00:08:06,659 --> 00:08:10,830
output right there should be the same

00:08:08,190 --> 00:08:11,430
output no matter what size you select so

00:08:10,830 --> 00:08:14,400
we have in mind

00:08:11,430 --> 00:08:16,949
I'll cover the major strategies that we

00:08:14,400 --> 00:08:22,020
have today so we can later see how they

00:08:16,949 --> 00:08:23,879
play with the dynamic scheduler the most

00:08:22,020 --> 00:08:26,550
obvious strategy that we have is called

00:08:23,879 --> 00:08:28,620
standalone or local which essentially

00:08:26,550 --> 00:08:30,599
just runs your process in the output

00:08:28,620 --> 00:08:32,640
tree just what it should be with the

00:08:30,599 --> 00:08:34,610
paths to the output files where they are

00:08:32,640 --> 00:08:36,469
they are in the final locations and

00:08:34,610 --> 00:08:38,490
that's it

00:08:36,469 --> 00:08:40,229
spawn is the world we're using the code

00:08:38,490 --> 00:08:44,039
to represent the sub process but it's

00:08:40,229 --> 00:08:47,279
essentially the same thing right easy

00:08:44,039 --> 00:08:49,410
you call standalone exec give run this

00:08:47,279 --> 00:08:51,290
command it runs it somewhere in your

00:08:49,410 --> 00:08:55,730
apple tree and you're done

00:08:51,290 --> 00:08:57,290
that is fine but then in Basel we say

00:08:55,730 --> 00:09:00,290
that we are correct right so we had to

00:08:57,290 --> 00:09:02,140
introduce some boxed execution to make

00:09:00,290 --> 00:09:05,570
sure that these commands do not affect

00:09:02,140 --> 00:09:06,830
do not peek like an unexpected

00:09:05,570 --> 00:09:08,600
dependencies that don't have side

00:09:06,830 --> 00:09:12,230
effects in your system so then you have

00:09:08,600 --> 00:09:14,060
this unboxed strategy this is a bit more

00:09:12,230 --> 00:09:15,380
complex right we have to first for every

00:09:14,060 --> 00:09:17,000
action that we have to run out for every

00:09:15,380 --> 00:09:19,340
command we have to create a sandbox

00:09:17,000 --> 00:09:21,050
first which involves possibly copying

00:09:19,340 --> 00:09:23,720
files or creating a ton of simulating

00:09:21,050 --> 00:09:26,350
bla bla bla prepare the environment then

00:09:23,720 --> 00:09:29,720
we execute the spawn inside that sandbox

00:09:26,350 --> 00:09:32,000
when we are done because this sandbox is

00:09:29,720 --> 00:09:33,260
a separate directory right the outputs

00:09:32,000 --> 00:09:34,610
were not written where they are was

00:09:33,260 --> 00:09:36,290
supposed to be they are written in the

00:09:34,610 --> 00:09:38,120
sandbox we need to move them in place

00:09:36,290 --> 00:09:40,670
and when that's done we can finally

00:09:38,120 --> 00:09:43,670
destroy the sandbox and call today right

00:09:40,670 --> 00:09:44,810
we can say that's done this is costly I

00:09:43,670 --> 00:09:45,260
mean creating a sandbox and we'll see

00:09:44,810 --> 00:09:47,630
later

00:09:45,260 --> 00:09:50,180
creating and destroying is costly the

00:09:47,630 --> 00:09:52,190
fact of running a process inside the

00:09:50,180 --> 00:09:54,410
sandbox itself is also a bit costly not

00:09:52,190 --> 00:09:57,350
so much but it is a little bit I'll get

00:09:54,410 --> 00:09:59,530
to that later and the other strategy

00:09:57,350 --> 00:10:03,470
that we have to consider in this talk is

00:09:59,530 --> 00:10:04,820
the remote strategy very simplified we

00:10:03,470 --> 00:10:08,300
want to run something remotely right we

00:10:04,820 --> 00:10:10,160
send it to remote execution worker and

00:10:08,300 --> 00:10:12,020
then the service comes back to us say

00:10:10,160 --> 00:10:13,550
hey yeah I can run this but I'm missing

00:10:12,020 --> 00:10:15,620
these input files please send them back

00:10:13,550 --> 00:10:17,840
to me so you send up files that you need

00:10:15,620 --> 00:10:20,090
it for reaction you try again until

00:10:17,840 --> 00:10:22,220
you're done and then you finally want

00:10:20,090 --> 00:10:24,110
the remote execution succeed so that's a

00:10:22,220 --> 00:10:31,600
cache hit you download the outputs and

00:10:24,110 --> 00:10:36,220
then that's it we're not going to cover

00:10:31,600 --> 00:10:38,300
the worker strategy but that's the other

00:10:36,220 --> 00:10:41,900
important strategy that we have in basil

00:10:38,300 --> 00:10:45,860
I would say so we had in mind the

00:10:41,900 --> 00:10:47,150
dynamic scheduler and we call it

00:10:45,860 --> 00:10:48,950
scheduler in many places but that's a

00:10:47,150 --> 00:10:50,660
very strong word for what it does it

00:10:48,950 --> 00:10:53,960
just it's actually the thread the

00:10:50,660 --> 00:10:57,680
dynamic fingy scheduler is just one more

00:10:53,960 --> 00:11:00,730
strategy right it's the dynamic

00:10:57,680 --> 00:11:03,800
scheduler just wraps this exact call and

00:11:00,730 --> 00:11:05,070
the dynamic strategy is different than

00:11:03,800 --> 00:11:07,620
the other ones because it's a

00:11:05,070 --> 00:11:09,449
rapping two other different strategies

00:11:07,620 --> 00:11:11,399
one that does things remotely and one

00:11:09,449 --> 00:11:13,889
that does things locally by default that

00:11:11,399 --> 00:11:18,540
would be the remote execution and the

00:11:13,889 --> 00:11:21,420
son boxed strategy so you know you have

00:11:18,540 --> 00:11:22,290
a number of jobs coming in to dynamic

00:11:21,420 --> 00:11:24,000
execution

00:11:22,290 --> 00:11:27,269
that's your parallelism that you have

00:11:24,000 --> 00:11:28,949
defined in your command line essentially

00:11:27,269 --> 00:11:32,190
which 4rb I heard this morning was

00:11:28,949 --> 00:11:35,759
something like what if you Honda doesn't

00:11:32,190 --> 00:11:37,079
know but yeah for a remote service you

00:11:35,759 --> 00:11:39,930
need to provide several hundred probably

00:11:37,079 --> 00:11:42,149
to get good good performance and then

00:11:39,930 --> 00:11:44,699
then I make a seller will send will kind

00:11:42,149 --> 00:11:46,079
of fork and run the same thing twice and

00:11:44,699 --> 00:11:49,949
then we'll pick the fastest result in

00:11:46,079 --> 00:11:51,810
some way that we will see soon now as

00:11:49,949 --> 00:11:56,699
you can imagine this is a there is a

00:11:51,810 --> 00:11:58,740
problem here right if you use the number

00:11:56,699 --> 00:12:00,839
of jobs for the parallelism for the

00:11:58,740 --> 00:12:02,790
remote execution and you try to do the

00:12:00,839 --> 00:12:05,250
same for local execution you will kill

00:12:02,790 --> 00:12:07,050
your machine as I said we have 300

00:12:05,250 --> 00:12:09,959
remote jobs and you try to run 300

00:12:07,050 --> 00:12:11,370
processes locally your laptop for

00:12:09,959 --> 00:12:14,130
example will not tolerate it

00:12:11,370 --> 00:12:16,500
so we have to add one more thing which

00:12:14,130 --> 00:12:18,810
Bay's already had which is this concept

00:12:16,500 --> 00:12:21,860
of local resources right in basil every

00:12:18,810 --> 00:12:25,290
rule and every action pretty much define

00:12:21,860 --> 00:12:30,510
how many CPUs and how much RAM they need

00:12:25,290 --> 00:12:32,779
to run it's a very bad model or

00:12:30,510 --> 00:12:36,420
approximate model but more or less works

00:12:32,779 --> 00:12:37,680
and so you have basic as a tracker so

00:12:36,420 --> 00:12:39,389
that every time it wants to run

00:12:37,680 --> 00:12:40,829
something locally because they do have

00:12:39,389 --> 00:12:42,839
enough spare resources for what you're

00:12:40,829 --> 00:12:46,410
asking me and then it just counts that

00:12:42,839 --> 00:12:49,230
tracks that and that's how we control

00:12:46,410 --> 00:12:52,319
you know we have a subset sorry we have

00:12:49,230 --> 00:12:54,600
n jobs running remotely but then of

00:12:52,319 --> 00:12:56,069
those we only have a small subset

00:12:54,600 --> 00:12:58,800
running locally which are essentially

00:12:56,069 --> 00:13:00,589
bound by your number of CPUs and when

00:12:58,800 --> 00:13:03,149
the local execution start finishing or

00:13:00,589 --> 00:13:04,740
stopped then you free those resources

00:13:03,149 --> 00:13:08,779
and then you can run more of the remote

00:13:04,740 --> 00:13:09,959
actions locally if you have to do that

00:13:08,779 --> 00:13:11,819
okay

00:13:09,959 --> 00:13:15,000
so conceptually that's pretty much

00:13:11,819 --> 00:13:16,829
everything that there is to know how

00:13:15,000 --> 00:13:18,600
does this work in practice and for that

00:13:16,829 --> 00:13:19,920
example I'll focus on the

00:13:18,600 --> 00:13:21,360
the use case we've been working on with

00:13:19,920 --> 00:13:27,510
that essentially IUS builds at Google

00:13:21,360 --> 00:13:29,940
and those have traditionally been local

00:13:27,510 --> 00:13:32,130
only for a long time they didn't have

00:13:29,940 --> 00:13:36,960
access to remote execution for various

00:13:32,130 --> 00:13:38,190
reasons but essentially like the mark

00:13:36,960 --> 00:13:39,690
that we have at work we couldn't reach

00:13:38,190 --> 00:13:44,070
like our production services from Max

00:13:39,690 --> 00:13:46,790
and we didn't really have blades

00:13:44,070 --> 00:13:49,320
well porting blades to the Mac was a big

00:13:46,790 --> 00:13:50,520
project and until that was completely

00:13:49,320 --> 00:13:51,960
done we couldn't use the remote

00:13:50,520 --> 00:13:54,330
execution service that we have in Google

00:13:51,960 --> 00:13:57,330
so people that had to do why US beans

00:13:54,330 --> 00:13:59,790
from their max were forced to use local

00:13:57,330 --> 00:14:01,050
builds only now as you can see from the

00:13:59,790 --> 00:14:05,850
numbers those are some numbers I got

00:14:01,050 --> 00:14:07,560
from one of our large iOS builds is

00:14:05,850 --> 00:14:08,880
project sorry you can see that

00:14:07,560 --> 00:14:10,440
incremental build times and those were

00:14:08,880 --> 00:14:12,300
computed by touching just one of the

00:14:10,440 --> 00:14:15,000
leaf source files that I was showing you

00:14:12,300 --> 00:14:17,970
earlier in the introduction are pretty

00:14:15,000 --> 00:14:20,130
good I mean 17 20 seconds are not great

00:14:17,970 --> 00:14:21,930
but they are not terrible either the

00:14:20,130 --> 00:14:24,750
clinical times are just awful right you

00:14:21,930 --> 00:14:28,620
have to wait almost an hour to build

00:14:24,750 --> 00:14:31,980
your app when you laptop and 20 minutes

00:14:28,620 --> 00:14:34,710
on a very powerful machine that's not

00:14:31,980 --> 00:14:36,720
great so a lot of our work was to

00:14:34,710 --> 00:14:39,600
actually provide remote execution for

00:14:36,720 --> 00:14:41,520
these are yours builds and we spent a

00:14:39,600 --> 00:14:43,290
long time doing that right then we added

00:14:41,520 --> 00:14:46,490
this feature was so happy let's say what

00:14:43,290 --> 00:14:46,490
happened they start to see what happens

00:14:46,760 --> 00:14:52,920
not great

00:14:49,910 --> 00:14:56,000
we spend on doing these you know clean

00:14:52,920 --> 00:15:00,560
bill times massively improved but

00:14:56,000 --> 00:15:03,990
incremental builds are now very bad

00:15:00,560 --> 00:15:06,210
specifically this is what we were

00:15:03,990 --> 00:15:08,880
listening to this morning some actions

00:15:06,210 --> 00:15:11,010
are not designed to be run remotely

00:15:08,880 --> 00:15:13,440
rather they are very bad for various

00:15:11,010 --> 00:15:16,410
reasons in particular in our system

00:15:13,440 --> 00:15:19,560
specifically linking was very bad a few

00:15:16,410 --> 00:15:21,090
years ago just like running a linking

00:15:19,560 --> 00:15:22,320
operation that would take 40 seconds

00:15:21,090 --> 00:15:24,240
your machine it would maybe take like

00:15:22,320 --> 00:15:26,010
eight ten minutes remotely so that's

00:15:24,240 --> 00:15:30,330
where you see there right those numbers

00:15:26,010 --> 00:15:31,860
increasing significantly we could fix

00:15:30,330 --> 00:15:32,460
that and we have actually fixed it we

00:15:31,860 --> 00:15:34,740
made remote

00:15:32,460 --> 00:15:37,020
much better but still you can't beat

00:15:34,740 --> 00:15:38,790
locally local linking for example when

00:15:37,020 --> 00:15:39,930
all the files are already there having

00:15:38,790 --> 00:15:43,140
to send anything remotely will already

00:15:39,930 --> 00:15:46,470
kill your performance so the idea of the

00:15:43,140 --> 00:15:50,130
music ution is to you know solve this

00:15:46,470 --> 00:15:52,260
and if you can take advantage of both

00:15:50,130 --> 00:15:54,780
remote and local resources at the same

00:15:52,260 --> 00:15:57,450
time you essentially get for the rich

00:15:54,780 --> 00:15:59,100
row you can see that we got the best of

00:15:57,450 --> 00:16:03,030
both worlds right for look for clean

00:15:59,100 --> 00:16:04,680
bills we get the remote behavior more or

00:16:03,030 --> 00:16:06,690
less for incremental bills we got

00:16:04,680 --> 00:16:09,150
exactly the local behavior there is no

00:16:06,690 --> 00:16:11,550
some overhead in some cases but it's not

00:16:09,150 --> 00:16:15,150
it's what you don't see it here but it

00:16:11,550 --> 00:16:16,530
exists we will see you later but yeah we

00:16:15,150 --> 00:16:22,980
can get the best of both worlds

00:16:16,530 --> 00:16:24,060
essentially ok so the idea that you have

00:16:22,980 --> 00:16:26,220
to remember if you forget everything

00:16:24,060 --> 00:16:29,160
else as I said that remote execution is

00:16:26,220 --> 00:16:30,780
great but by itself if you don't do

00:16:29,160 --> 00:16:32,430
anything else you may not get all the

00:16:30,780 --> 00:16:35,640
advantage that you might think you might

00:16:32,430 --> 00:16:39,450
get out of your bills please leave the

00:16:35,640 --> 00:16:41,040
side making sure your bill graph is nice

00:16:39,450 --> 00:16:41,730
you don't have gigantic actions and

00:16:41,040 --> 00:16:44,970
everything like this

00:16:41,730 --> 00:16:46,860
but if your bill graph is not friendly

00:16:44,970 --> 00:16:49,200
to parallelization nothing like this

00:16:46,860 --> 00:16:51,930
will help you so first fix your bill

00:16:49,200 --> 00:16:57,060
graph and second use remote and local

00:16:51,930 --> 00:17:00,480
resources at the same time ok now why is

00:16:57,060 --> 00:17:02,610
the dynamic scheduler problematic or

00:17:00,480 --> 00:17:05,490
what's problematic for us it all comes

00:17:02,610 --> 00:17:08,370
down to its history right on the left

00:17:05,490 --> 00:17:10,589
side we have the bill that we have had

00:17:08,370 --> 00:17:12,240
at Google for a long time right they

00:17:10,589 --> 00:17:15,839
have always been for the most part

00:17:12,240 --> 00:17:18,589
remote and they have been run from very

00:17:15,839 --> 00:17:21,660
powerful workstations and the goal of

00:17:18,589 --> 00:17:22,980
the dynamic scalar when it was

00:17:21,660 --> 00:17:25,230
introduced and it was introduced in this

00:17:22,980 --> 00:17:27,480
context was to make incremental build

00:17:25,230 --> 00:17:30,330
times faster specifically for languages

00:17:27,480 --> 00:17:31,890
that benefit from persistent workers and

00:17:30,330 --> 00:17:33,300
I think examples were like dart and

00:17:31,890 --> 00:17:35,190
typescript where you really can benefit

00:17:33,300 --> 00:17:36,750
from those workers being there you don't

00:17:35,190 --> 00:17:38,310
have to send it into the remote

00:17:36,750 --> 00:17:42,450
execution and you get super fast

00:17:38,310 --> 00:17:44,040
behavior there now the problem is for

00:17:42,450 --> 00:17:45,700
our errors builds and actually for any

00:17:44,040 --> 00:17:48,460
build outside of Google

00:17:45,700 --> 00:17:49,690
is all the open-source bills and all

00:17:48,460 --> 00:17:51,639
because you might have

00:17:49,690 --> 00:17:55,059
they are probably different right they

00:17:51,639 --> 00:17:56,380
have been traditionally local only you

00:17:55,059 --> 00:17:58,950
might be running them from machines that

00:17:56,380 --> 00:18:01,240
are not as powerful as a workstation and

00:17:58,950 --> 00:18:04,990
the goal there is to make sure that

00:18:01,240 --> 00:18:10,330
clean bill times are better remote

00:18:04,990 --> 00:18:12,039
execution as we were seeing so this the

00:18:10,330 --> 00:18:13,419
problem is here again that the dynamics

00:18:12,039 --> 00:18:14,860
cavalry was written for the first used

00:18:13,419 --> 00:18:16,299
case and there were some implications in

00:18:14,860 --> 00:18:18,130
the code that prevented it from working

00:18:16,299 --> 00:18:20,980
properly in the second use case and I

00:18:18,130 --> 00:18:22,779
want to dive into some of them now will

00:18:20,980 --> 00:18:25,779
cover three different problems I have

00:18:22,779 --> 00:18:28,269
time their solutions and what our goal

00:18:25,779 --> 00:18:31,299
is essentially for this and then we'll

00:18:28,269 --> 00:18:34,870
be done okay the first problem is output

00:18:31,299 --> 00:18:37,510
locking right we have the rammy

00:18:34,870 --> 00:18:39,610
scheduler running two things at once and

00:18:37,510 --> 00:18:42,100
these two things want to write to the

00:18:39,610 --> 00:18:45,460
same output files right in your output

00:18:42,100 --> 00:18:47,010
tree how do you fix that well you put a

00:18:45,460 --> 00:18:50,019
lock very very simple

00:18:47,010 --> 00:18:52,809
actually the way this works is in the

00:18:50,019 --> 00:18:55,659
code we spawn the two strategies remote

00:18:52,809 --> 00:18:57,370
and local or some box in this case they

00:18:55,659 --> 00:18:59,139
do their stuff and then right before

00:18:57,370 --> 00:19:01,480
they have the outputs available

00:18:59,139 --> 00:19:04,690
they take the lock for that specific

00:19:01,480 --> 00:19:05,799
action and in the remote case we fetch

00:19:04,690 --> 00:19:09,210
the outputs and put them into the

00:19:05,799 --> 00:19:12,960
location and in the sandbox in place we

00:19:09,210 --> 00:19:14,799
move the outputs to where they belong

00:19:12,960 --> 00:19:17,380
that sounds great

00:19:14,799 --> 00:19:19,210
but as you may have heard me say in many

00:19:17,380 --> 00:19:22,149
other places some boxing is slow

00:19:19,210 --> 00:19:25,120
especially your Mac I took these numbers

00:19:22,149 --> 00:19:29,019
from a previous blog post that we had in

00:19:25,120 --> 00:19:31,090
the Basel blog and you can see the red

00:19:29,019 --> 00:19:32,500
boxes are essentially what kills

00:19:31,090 --> 00:19:34,950
performance in the sandbox at least for

00:19:32,500 --> 00:19:37,149
mark o/s written samples very slow

00:19:34,950 --> 00:19:39,490
moving the outputs should actually have

00:19:37,149 --> 00:19:40,840
been green but whatever and destroy

00:19:39,490 --> 00:19:42,370
since the sandbox is actually more

00:19:40,840 --> 00:19:45,399
costly than creating the sandbox itself

00:19:42,370 --> 00:19:47,669
and you can see here for basil the

00:19:45,399 --> 00:19:50,590
penalty of having a sandbox is not great

00:19:47,669 --> 00:19:53,320
but it's not terrible but for the iOS

00:19:50,590 --> 00:19:54,850
apps it's awful and the problem there is

00:19:53,320 --> 00:19:56,529
that our actions have tons of inputs

00:19:54,850 --> 00:19:58,600
which means you have to create tons of

00:19:56,529 --> 00:20:01,419
symlinks when you create the sandbox

00:19:58,600 --> 00:20:02,890
that doesn't work very well the side

00:20:01,419 --> 00:20:05,760
note I've been trying to fix this with

00:20:02,890 --> 00:20:08,289
the sandbox the first implementation but

00:20:05,760 --> 00:20:10,330
it's still not as good as I think it can

00:20:08,289 --> 00:20:11,679
be but it's a side note the side

00:20:10,330 --> 00:20:15,880
projects I don't have much time for it

00:20:11,679 --> 00:20:17,770
so it will get done someday okay so it's

00:20:15,880 --> 00:20:20,410
unboxing is low what do we do right in

00:20:17,770 --> 00:20:21,910
our case we disable some boxing for

00:20:20,410 --> 00:20:23,559
interactive builds because they are too

00:20:21,910 --> 00:20:25,120
slow we still have them enabled insya

00:20:23,559 --> 00:20:26,950
you know and everything that gets

00:20:25,120 --> 00:20:29,830
checked in will be will be some box safe

00:20:26,950 --> 00:20:32,799
but for local for local incrementer

00:20:29,830 --> 00:20:34,270
bills we don't have that so then we need

00:20:32,799 --> 00:20:39,070
to make that enemy scheduler work well

00:20:34,270 --> 00:20:42,750
with without some boxing and so this is

00:20:39,070 --> 00:20:47,169
what happens right we have now the local

00:20:42,750 --> 00:20:49,240
strategy but the problem is if you are

00:20:47,169 --> 00:20:52,360
going to run a compiler or something

00:20:49,240 --> 00:20:54,669
inside the output tree you don't know

00:20:52,360 --> 00:20:57,220
when that binary or that processor is

00:20:54,669 --> 00:20:59,020
going to actually touch output files so

00:20:57,220 --> 00:21:01,929
therefore you must lock the output

00:20:59,020 --> 00:21:03,250
upfront before you start anything in the

00:21:01,929 --> 00:21:04,929
previous cases we did the execution

00:21:03,250 --> 00:21:07,840
before taking the lock but for local

00:21:04,929 --> 00:21:12,220
execution we take the lock before we

00:21:07,840 --> 00:21:14,830
will do anything which you know it works

00:21:12,220 --> 00:21:18,190
if you do it this way it was fine you

00:21:14,830 --> 00:21:20,049
can imagine that you are prioritizing

00:21:18,190 --> 00:21:21,490
local execution more than remote

00:21:20,049 --> 00:21:23,799
execution because you will take a lot

00:21:21,490 --> 00:21:26,320
much fat much sooner than otherwise but

00:21:23,799 --> 00:21:31,840
it works now the problem is we roll this

00:21:26,320 --> 00:21:34,809
out to some teams and we got this right

00:21:31,840 --> 00:21:37,750
these are median build times measured

00:21:34,809 --> 00:21:41,169
from the user's laptops for one specific

00:21:37,750 --> 00:21:43,870
iOS app and blue is the local only build

00:21:41,169 --> 00:21:46,510
times and red are the dynamic build

00:21:43,870 --> 00:21:49,720
times based on what I have explained

00:21:46,510 --> 00:21:51,460
until now you would expect dynamic bills

00:21:49,720 --> 00:21:52,929
to always be better than local bills

00:21:51,460 --> 00:21:55,090
right because you are doing the same

00:21:52,929 --> 00:21:57,549
thing as you're doing locally plus you

00:21:55,090 --> 00:21:58,900
have access to remote resources but you

00:21:57,549 --> 00:22:01,799
can see the lion jumps all over the

00:21:58,900 --> 00:22:05,620
place and it makes no sense

00:22:01,799 --> 00:22:07,330
not good needless to say we measured

00:22:05,620 --> 00:22:09,130
this with micro benchmarks and

00:22:07,330 --> 00:22:11,799
everything was great but when we started

00:22:09,130 --> 00:22:12,490
looking at actual user behavior is when

00:22:11,799 --> 00:22:15,429
we see that things

00:22:12,490 --> 00:22:16,270
we're playing out as we thought so then

00:22:15,429 --> 00:22:19,630
we have to go back and see what's

00:22:16,270 --> 00:22:24,580
happening okay so when the problems is

00:22:19,630 --> 00:22:28,020
there right the remote path is taking

00:22:24,580 --> 00:22:30,700
the lock before downloading anything so

00:22:28,020 --> 00:22:32,770
at that point you have taken a lock you

00:22:30,700 --> 00:22:36,280
have no idea how your network is

00:22:32,770 --> 00:22:37,870
behaving but now you cannot go back at

00:22:36,280 --> 00:22:40,630
that point you have start downloading

00:22:37,870 --> 00:22:42,550
your outputs and that may be slow or it

00:22:40,630 --> 00:22:44,590
may break and if the connection breaks

00:22:42,550 --> 00:22:46,690
for whatever reason you will get stuck

00:22:44,590 --> 00:22:50,740
and you have to control C and start it

00:22:46,690 --> 00:22:53,140
again so how do you do how do we fix

00:22:50,740 --> 00:22:55,600
this well you can imagine is not very

00:22:53,140 --> 00:22:57,910
complicated in theory but in practice

00:22:55,600 --> 00:22:59,620
was a pain we download the outputs

00:22:57,910 --> 00:23:01,179
before we take the lock right we put

00:22:59,620 --> 00:23:05,710
them aside in a separate directory and

00:23:01,179 --> 00:23:08,050
then once we have them all ready we take

00:23:05,710 --> 00:23:10,110
the lock and we put them in place this

00:23:08,050 --> 00:23:13,990
is again very simple when we did this

00:23:10,110 --> 00:23:15,940
there were fun problems because in the

00:23:13,990 --> 00:23:17,920
previous model when the dynamic

00:23:15,940 --> 00:23:20,260
scheduler decides to stop the remote

00:23:17,920 --> 00:23:21,910
path it would always do it before the

00:23:20,260 --> 00:23:23,170
red box right so it would always cancel

00:23:21,910 --> 00:23:25,210
the remote execution it would never

00:23:23,170 --> 00:23:27,760
cancel the downloads but now that we

00:23:25,210 --> 00:23:29,590
move the tunnels before we are issuing

00:23:27,760 --> 00:23:31,720
cancellations on a code path that was

00:23:29,590 --> 00:23:34,140
never designed to take them very well so

00:23:31,720 --> 00:23:36,490
we started seeing like memory leaks and

00:23:34,140 --> 00:23:38,320
things with didn't answer properly and

00:23:36,490 --> 00:23:41,740
they would run in the background and JVM

00:23:38,320 --> 00:23:42,460
would crash not great but when we fixed

00:23:41,740 --> 00:23:44,770
it

00:23:42,460 --> 00:23:46,780
I know Jacob Lee the same change for the

00:23:44,770 --> 00:23:50,380
RB module so you have these in both

00:23:46,780 --> 00:23:52,390
internal and external versions and that

00:23:50,380 --> 00:23:54,250
works we tried that we rolled it out

00:23:52,390 --> 00:23:57,160
like a month ago as you can see in the

00:23:54,250 --> 00:23:59,230
dates and so far the Red Line has stayed

00:23:57,160 --> 00:24:01,750
below the blue line hopefully it will

00:23:59,230 --> 00:24:06,480
stay that way forever but not super

00:24:01,750 --> 00:24:08,500
convinced yet okay so that worked but

00:24:06,480 --> 00:24:12,370
doing these introduced a different

00:24:08,500 --> 00:24:14,140
problem which is now the remote path

00:24:12,370 --> 00:24:16,450
takes much longer than it did before

00:24:14,140 --> 00:24:18,670
right especially if you get a cache hit

00:24:16,450 --> 00:24:20,679
if you get the cache hit remote exec

00:24:18,670 --> 00:24:23,260
will return immediately and then you're

00:24:20,679 --> 00:24:25,000
ready to take the lock but the local

00:24:23,260 --> 00:24:26,870
path might have already taken the lock

00:24:25,000 --> 00:24:28,430
and then even if the remote

00:24:26,870 --> 00:24:30,830
service comes back and says hey you have

00:24:28,430 --> 00:24:32,809
a cache it you can't use it right you're

00:24:30,830 --> 00:24:34,850
now waiting for your local execution to

00:24:32,809 --> 00:24:36,710
finish when maybe downloading the thing

00:24:34,850 --> 00:24:40,580
remote they would take only you know it

00:24:36,710 --> 00:24:43,880
would be a small output file so how do

00:24:40,580 --> 00:24:45,470
we fix this the problem here was

00:24:43,880 --> 00:24:47,720
essentially they were you thinking about

00:24:45,470 --> 00:24:49,820
cooperative locking mechanism right we

00:24:47,720 --> 00:24:51,920
expect every code path to wait and take

00:24:49,820 --> 00:24:53,710
a lock and then decide what to do but

00:24:51,920 --> 00:24:58,340
now we have to change this to become

00:24:53,710 --> 00:25:01,540
kind of pre-emptive right we want the

00:24:58,340 --> 00:25:03,710
local execution to start anytime

00:25:01,540 --> 00:25:05,360
whenever it's ready to have whenever

00:25:03,710 --> 00:25:08,540
there are local resources we let the

00:25:05,360 --> 00:25:10,429
local execution start and then whenever

00:25:08,540 --> 00:25:13,010
the remote code path is ready

00:25:10,429 --> 00:25:15,800
we want it to explicitly cancel the

00:25:13,010 --> 00:25:17,480
local execution wait until everything is

00:25:15,800 --> 00:25:19,220
clean make sure there are no files in

00:25:17,480 --> 00:25:22,040
place and then we're ready to move the

00:25:19,220 --> 00:25:24,050
outputs this is a very problematic

00:25:22,040 --> 00:25:26,600
mirror to flux to enable this behavior

00:25:24,050 --> 00:25:29,330
the first one we had to rewrite the

00:25:26,600 --> 00:25:30,860
dynamic spawn strategy completely to

00:25:29,330 --> 00:25:34,010
implement this kind of cross

00:25:30,860 --> 00:25:37,640
cancellation feature and when that's

00:25:34,010 --> 00:25:39,500
that's it works I think there is still a

00:25:37,640 --> 00:25:41,120
small raise condition somewhere but I'm

00:25:39,500 --> 00:25:44,000
not sure if it's by this feature this

00:25:41,120 --> 00:25:46,490
video exposed it but with that in place

00:25:44,000 --> 00:25:48,559
you can enable the other feature which

00:25:46,490 --> 00:25:50,150
removes the lock from the local path and

00:25:48,559 --> 00:25:52,910
then you can take advantage of this

00:25:50,150 --> 00:25:53,990
model now we still have to - it's not

00:25:52,910 --> 00:25:56,450
the default because you haven't tuned

00:25:53,990 --> 00:26:00,530
performance but when we do you should be

00:25:56,450 --> 00:26:02,960
possible to make it the default okay

00:26:00,530 --> 00:26:05,510
so I mean I mark white wait for cleanup

00:26:02,960 --> 00:26:07,070
there in red because that has also been

00:26:05,510 --> 00:26:09,290
problematic something that seems very

00:26:07,070 --> 00:26:11,300
simple turn out not to be so much and

00:26:09,290 --> 00:26:16,250
the reason is because canceling local

00:26:11,300 --> 00:26:19,340
processes is complicated so as an

00:26:16,250 --> 00:26:22,010
example we have here to paint like

00:26:19,340 --> 00:26:24,230
what's happening inside in basil we have

00:26:22,010 --> 00:26:26,809
a dynamic strategy that starts doing an

00:26:24,230 --> 00:26:30,230
exact towards the local path right and

00:26:26,809 --> 00:26:31,610
the local strategy will then have to run

00:26:30,230 --> 00:26:35,240
a process and the way you run a process

00:26:31,610 --> 00:26:37,280
well you run for can exact and yeah the

00:26:35,240 --> 00:26:39,800
thing running you compiler and at some

00:26:37,280 --> 00:26:40,550
point the remote execution would have

00:26:39,800 --> 00:26:41,870
finished and we

00:26:40,550 --> 00:26:43,910
say well I want to cancel the local

00:26:41,870 --> 00:26:46,880
strategy now because the remote path is

00:26:43,910 --> 00:26:49,940
faster so then the local strategy sends

00:26:46,880 --> 00:26:52,130
a kill signal to the child process you

00:26:49,940 --> 00:26:55,130
wait for the process to go away with

00:26:52,130 --> 00:26:58,580
wait bid which we were not doing before

00:26:55,130 --> 00:27:00,260
so I had to fix that and then we

00:26:58,580 --> 00:27:03,080
returned now the problem is if you don't

00:27:00,260 --> 00:27:05,420
wait sending signals is not synchronous

00:27:03,080 --> 00:27:06,890
right sending a signal to a process the

00:27:05,420 --> 00:27:08,630
process will react to it at some point

00:27:06,890 --> 00:27:10,010
but not immediately so if you don't wait

00:27:08,630 --> 00:27:11,510
for it there is a race condition between

00:27:10,010 --> 00:27:14,660
the process maybe writing some more

00:27:11,510 --> 00:27:16,160
files before actually you and then you

00:27:14,660 --> 00:27:17,900
may get a conflict in the remote

00:27:16,160 --> 00:27:21,740
execution when you try to write to the

00:27:17,900 --> 00:27:24,410
same files easy but now what happens if

00:27:21,740 --> 00:27:29,060
that child process decides to be nasty

00:27:24,410 --> 00:27:30,740
and starts another process right well

00:27:29,060 --> 00:27:33,530
you send a signal to process the process

00:27:30,740 --> 00:27:35,450
dies the grandchild process continues

00:27:33,530 --> 00:27:38,570
running as reparent it to in it and

00:27:35,450 --> 00:27:39,080
you've lost control of it and now we are

00:27:38,570 --> 00:27:41,090
in trouble

00:27:39,080 --> 00:27:42,230
as it turns out there are many tools

00:27:41,090 --> 00:27:44,330
that do this because there are many

00:27:42,230 --> 00:27:46,580
rapper tools shell scripts that wrap

00:27:44,330 --> 00:27:48,470
other tools and when you have a shell

00:27:46,580 --> 00:27:52,340
script that does that then you hit this

00:27:48,470 --> 00:27:54,620
problem so how do we fix it it's not

00:27:52,340 --> 00:27:58,100
difficult in theory you can use a

00:27:54,620 --> 00:28:01,400
process group right we have between the

00:27:58,100 --> 00:28:03,950
fork and exec of the original design you

00:28:01,400 --> 00:28:05,330
do set process group ID for the child

00:28:03,950 --> 00:28:06,950
process right you create a new process

00:28:05,330 --> 00:28:10,040
group and then when you have done that

00:28:06,950 --> 00:28:12,920
you are able to send the signal to the

00:28:10,040 --> 00:28:14,870
whole group and then all the process die

00:28:12,920 --> 00:28:16,370
but you can only wait for one of them

00:28:14,870 --> 00:28:19,190
like wait peeled we run the wait for one

00:28:16,370 --> 00:28:20,960
of them there is still the problem what

00:28:19,190 --> 00:28:23,620
happens with the other child processes

00:28:20,960 --> 00:28:26,900
that have been leaked they are dead

00:28:23,620 --> 00:28:29,030
probably most likely they are dead

00:28:26,900 --> 00:28:30,710
because it's a kill signal so even if

00:28:29,030 --> 00:28:34,100
it's not synchronized they will die very

00:28:30,710 --> 00:28:35,540
quickly but there is still a chance of a

00:28:34,100 --> 00:28:37,370
small race conditions I've been trying

00:28:35,540 --> 00:28:38,900
to fix that actually fix it last week

00:28:37,370 --> 00:28:40,760
but the change must had to be rolled

00:28:38,900 --> 00:28:42,170
back so I will try again but basically

00:28:40,760 --> 00:28:44,740
we have to wait under the process are

00:28:42,170 --> 00:28:47,540
really gone and the way to do that

00:28:44,740 --> 00:28:50,210
varies across platforms I kind of wrote

00:28:47,540 --> 00:28:52,520
about it in the darling at the bottom so

00:28:50,210 --> 00:28:53,750
in Linux we can use the child sub reaper

00:28:52,520 --> 00:28:55,940
feature and a macro

00:28:53,750 --> 00:28:56,930
we have to ward the process table to

00:28:55,940 --> 00:28:58,970
make sure that everything is clean

00:28:56,930 --> 00:29:04,280
before we can actually return control to

00:28:58,970 --> 00:29:06,740
Basel great but Java you cannot do these

00:29:04,280 --> 00:29:09,440
things from Java Java doesn't give you

00:29:06,740 --> 00:29:11,000
give you access to process groups or

00:29:09,440 --> 00:29:15,770
wait PE tour all these things

00:29:11,000 --> 00:29:16,970
so instead basil has this binary and

00:29:15,770 --> 00:29:18,470
this has been dead forever it's not a

00:29:16,970 --> 00:29:20,690
new thing with the dynamics cavalry has

00:29:18,470 --> 00:29:23,480
been there for a long time to control

00:29:20,690 --> 00:29:25,520
test tests but now have this process in

00:29:23,480 --> 00:29:27,650
between which ships with the Basel

00:29:25,520 --> 00:29:30,590
binary and it's a trusted process right

00:29:27,650 --> 00:29:33,590
we know that it behaves well so we can

00:29:30,590 --> 00:29:36,410
exact it and then we can send it sick

00:29:33,590 --> 00:29:38,030
term to kill it instead of a sick kill

00:29:36,410 --> 00:29:40,490
and then we can rely on the process

00:29:38,030 --> 00:29:43,730
rapid of doing the cleanup by itself the

00:29:40,490 --> 00:29:49,940
process wrapper is in C++ or well see

00:29:43,730 --> 00:29:51,710
with some c++ and then yeah basil

00:29:49,940 --> 00:29:54,350
contrasts that that thing is that like a

00:29:51,710 --> 00:29:58,130
unit and we just take advantage of that

00:29:54,350 --> 00:29:59,810
again as I said this was added for for

00:29:58,130 --> 00:30:01,880
testing I think to make sure the test

00:29:59,810 --> 00:30:03,500
didn't leave like surprises behind but

00:30:01,880 --> 00:30:04,700
for us now this is very useful and it

00:30:03,500 --> 00:30:06,710
was good that it was in place otherwise

00:30:04,700 --> 00:30:08,780
we couldn't have done this properly and

00:30:06,710 --> 00:30:11,720
we have had to modify it what the

00:30:08,780 --> 00:30:14,540
waiting until our kids are gone mmm you

00:30:11,720 --> 00:30:17,350
can read more in that basil but and in

00:30:14,540 --> 00:30:19,580
that other blog post in my personal page

00:30:17,350 --> 00:30:23,330
and finally the last problem I want to

00:30:19,580 --> 00:30:26,240
talk about are three artifacts another

00:30:23,330 --> 00:30:29,470
difficulty they showed up so three

00:30:26,240 --> 00:30:32,720
artifacts is a name for essentially

00:30:29,470 --> 00:30:34,070
actions that so typically most of your

00:30:32,720 --> 00:30:35,810
actions will create output files right

00:30:34,070 --> 00:30:37,700
but some actions will create directories

00:30:35,810 --> 00:30:39,020
and you don't know what's inside the

00:30:37,700 --> 00:30:41,720
directory right you just know that this

00:30:39,020 --> 00:30:43,700
action the Koran is specifically Apple

00:30:41,720 --> 00:30:45,440
tools like to do that a lot like I run

00:30:43,700 --> 00:30:47,060
this thing of my source files and then I

00:30:45,440 --> 00:30:48,770
get this output directory with many

00:30:47,060 --> 00:30:52,310
source for many output files inside

00:30:48,770 --> 00:30:53,450
whose names I can't predict easily so

00:30:52,310 --> 00:30:56,540
then we have this concept of three

00:30:53,450 --> 00:31:01,940
artifact which encapsulate this

00:30:56,540 --> 00:31:02,960
there here well we add the two to the

00:31:01,940 --> 00:31:04,730
two cases right we have remote

00:31:02,960 --> 00:31:06,350
executions under own execution not

00:31:04,730 --> 00:31:09,440
sandbox anymore we are looking at

00:31:06,350 --> 00:31:09,890
a standalone because that's where the

00:31:09,440 --> 00:31:11,150
problem lies

00:31:09,890 --> 00:31:15,470
if it's sandbox we wouldn't have this

00:31:11,150 --> 00:31:17,570
problem these strategies star your

00:31:15,470 --> 00:31:21,289
process your process will create some

00:31:17,570 --> 00:31:23,600
output files in a directory and then for

00:31:21,289 --> 00:31:25,400
the remote case we fetch all of them and

00:31:23,600 --> 00:31:27,380
put them in the place and for the local

00:31:25,400 --> 00:31:31,309
case we just wait until the process is

00:31:27,380 --> 00:31:33,860
done and that's it this for clarity in

00:31:31,309 --> 00:31:36,650
this page and the following yellow is

00:31:33,860 --> 00:31:40,760
your sub process and green is all basil

00:31:36,650 --> 00:31:43,880
code so you add to that about what

00:31:40,760 --> 00:31:48,650
happens if your tool is creating more

00:31:43,880 --> 00:31:50,539
files than it should write you have and

00:31:48,650 --> 00:31:53,570
we have seen this of course otherwise I

00:31:50,539 --> 00:31:55,070
wouldn't be talking about it you have a

00:31:53,570 --> 00:31:57,200
wrapper tool that involves some other

00:31:55,070 --> 00:31:59,720
thing and as part of the process you

00:31:57,200 --> 00:32:01,909
create a ton of temporary files in your

00:31:59,720 --> 00:32:04,070
output directory you create the real

00:32:01,909 --> 00:32:06,740
output files and then right before you

00:32:04,070 --> 00:32:08,900
exit you delete the temporary files so

00:32:06,740 --> 00:32:11,929
that the output tree artifact only

00:32:08,900 --> 00:32:15,830
contains the things you care about same

00:32:11,929 --> 00:32:17,330
thing in both cases okay now you have to

00:32:15,830 --> 00:32:18,950
stop these things from running at some

00:32:17,330 --> 00:32:20,809
point and you're so unlucky that the

00:32:18,950 --> 00:32:22,789
cancellation happens there for the

00:32:20,809 --> 00:32:25,159
remote case right you have created

00:32:22,789 --> 00:32:29,900
temporary files you have created output

00:32:25,159 --> 00:32:31,669
files now you stop running that's fine

00:32:29,900 --> 00:32:35,659
you didn't fetch anything to your drive

00:32:31,669 --> 00:32:37,809
so you never saw the temporary files

00:32:35,659 --> 00:32:40,490
they never made it to your disk

00:32:37,809 --> 00:32:43,400
everything is happy basil will take the

00:32:40,490 --> 00:32:45,590
output of the other path scan the list

00:32:43,400 --> 00:32:50,000
of files in the directory and treat

00:32:45,590 --> 00:32:52,929
those as your output really but if that

00:32:50,000 --> 00:32:54,380
happens to happen in the standalone case

00:32:52,929 --> 00:32:56,330
we're in trouble

00:32:54,380 --> 00:32:57,620
right we have canceled remember that the

00:32:56,330 --> 00:32:59,270
standalone execution is running now

00:32:57,620 --> 00:33:01,340
without taking the lock because we have

00:32:59,270 --> 00:33:03,230
this feature to remove the lock so you

00:33:01,340 --> 00:33:05,179
have a process running in your repertory

00:33:03,230 --> 00:33:08,360
it creates a temporary files it creates

00:33:05,179 --> 00:33:09,470
output files and then we stop it there

00:33:08,360 --> 00:33:10,220
is nothing there to clean up the

00:33:09,470 --> 00:33:14,120
temporary files

00:33:10,220 --> 00:33:17,830
so now remote execution wins we fetch

00:33:14,120 --> 00:33:20,340
all the outputs and then basil looks at

00:33:17,830 --> 00:33:22,800
the list of output that is fetched

00:33:20,340 --> 00:33:24,720
the list of files on disk it finds that

00:33:22,800 --> 00:33:26,880
they are different and it freaks out and

00:33:24,720 --> 00:33:31,350
that you will fail to I think plays even

00:33:26,880 --> 00:33:33,060
crashes or something not good so I mean

00:33:31,350 --> 00:33:35,390
we play with different solutions but the

00:33:33,060 --> 00:33:39,780
easiest solution here was to change the

00:33:35,390 --> 00:33:41,550
standalone strategy to when it's

00:33:39,780 --> 00:33:42,810
canceled and waits for the process after

00:33:41,550 --> 00:33:44,580
waiting for the process it goes and

00:33:42,810 --> 00:33:46,740
deletes any three artifacts that are on

00:33:44,580 --> 00:33:48,330
disk cleans them up and so when the

00:33:46,740 --> 00:33:50,490
remote execution path downloads things

00:33:48,330 --> 00:33:53,310
it you know it's a clean directory and

00:33:50,490 --> 00:33:54,360
there will be no side effects and when I

00:33:53,310 --> 00:33:57,510
was saying that there are some bugs

00:33:54,360 --> 00:33:59,700
still in the local localized execution

00:33:57,510 --> 00:34:02,190
thing they are still here I think I'm

00:33:59,700 --> 00:34:05,430
not sure why but that's in some cases it

00:34:02,190 --> 00:34:08,280
still this still fails all right

00:34:05,430 --> 00:34:12,360
and with that that's all I wanted to say

00:34:08,280 --> 00:34:13,770
just remember then I made a secretion I

00:34:12,360 --> 00:34:16,560
think it's a must for good performance

00:34:13,770 --> 00:34:17,640
if you use remote execution if you want

00:34:16,560 --> 00:34:19,860
to play with the new features you have

00:34:17,640 --> 00:34:22,169
those two flags I mentioned and I would

00:34:19,860 --> 00:34:23,909
I'm actually writing this down in a set

00:34:22,169 --> 00:34:25,950
of blog posts that other naval publish

00:34:23,909 --> 00:34:27,210
in the basil block or a my own blog but

00:34:25,950 --> 00:34:29,370
they will be like a summary of

00:34:27,210 --> 00:34:31,590
everything explained here and probably

00:34:29,370 --> 00:34:34,550
cover some more detail and without

00:34:31,590 --> 00:34:34,550
that's it thank you

00:34:38,659 --> 00:34:41,659
questions

00:34:56,480 --> 00:35:06,480
so the question is for the standalone so

00:35:05,070 --> 00:35:08,220
the question is if for some boxing for

00:35:06,480 --> 00:35:10,470
standard execution where we don't take

00:35:08,220 --> 00:35:12,360
the log if we could somehow put the

00:35:10,470 --> 00:35:14,190
output somewhere else so that we don't

00:35:12,360 --> 00:35:20,580
have to so we can actually move them and

00:35:14,190 --> 00:35:22,020
not have the interference may be the

00:35:20,580 --> 00:35:23,310
first thing I thought about it a little

00:35:22,020 --> 00:35:24,870
bit not much but the first thought was

00:35:23,310 --> 00:35:27,450
maybe I could change the command lines

00:35:24,870 --> 00:35:30,480
to point somewhere else but then what

00:35:27,450 --> 00:35:32,850
happens with cache hits complicated the

00:35:30,480 --> 00:35:35,580
second problem is like I had to find a

00:35:32,850 --> 00:35:39,390
portable solution the words of Mac and

00:35:35,580 --> 00:35:42,210
Linux and then yes for Linux I'm sure

00:35:39,390 --> 00:35:47,130
you can do it easily but for Mac you

00:35:42,210 --> 00:35:48,660
can't so then I wasn't I'm sure there

00:35:47,130 --> 00:35:53,400
are other ways to do it but this simply

00:35:48,660 --> 00:35:54,840
the most reasonable telecom is that in

00:35:53,400 --> 00:36:00,270
Windows you can do it as we heard this

00:35:54,840 --> 00:36:01,920
morning great but we don't I do care I

00:36:00,270 --> 00:36:06,950
do care but I don't ever have a chance

00:36:01,920 --> 00:36:06,950
to have time one more question

00:36:14,630 --> 00:36:19,200
ok the question is there are fewer CPUs

00:36:17,550 --> 00:36:21,360
locally than remotely how do we

00:36:19,200 --> 00:36:22,320
prioritize what to run first locally AHA

00:36:21,360 --> 00:36:24,570
that's why I said that

00:36:22,320 --> 00:36:27,870
the scheduler word is very strong there

00:36:24,570 --> 00:36:29,910
is no scheduling here basil just I think

00:36:27,870 --> 00:36:32,220
there are some heuristics in sky frame

00:36:29,910 --> 00:36:34,410
to decide what actions to run based on

00:36:32,220 --> 00:36:36,240
the number of jobs but from there on

00:36:34,410 --> 00:36:38,910
it's just a competition on who has the

00:36:36,240 --> 00:36:40,770
resources first locally I would like to

00:36:38,910 --> 00:36:42,330
make that better but we haven't had a

00:36:40,770 --> 00:36:45,810
chance yet and I don't have any idea

00:36:42,330 --> 00:36:47,990
specifically what we would do anything

00:36:45,810 --> 00:36:47,990
else

00:37:01,640 --> 00:37:06,839
the question is if we have thought about

00:37:04,140 --> 00:37:08,010
looking at historical data to decide

00:37:06,839 --> 00:37:11,640
whether to run something locally

00:37:08,010 --> 00:37:14,339
remotely at some point this came up I

00:37:11,640 --> 00:37:17,819
think someone that knows this system

00:37:14,339 --> 00:37:20,490
very well said that you can't do that

00:37:17,819 --> 00:37:23,299
real time because checking anything

00:37:20,490 --> 00:37:25,799
remotely will kill you performance I

00:37:23,299 --> 00:37:27,660
haven't looked at it more when I that

00:37:25,799 --> 00:37:29,279
came up was well Basel has this

00:37:27,660 --> 00:37:31,079
persistent server that's running all the

00:37:29,279 --> 00:37:32,970
time in the background so maybe in

00:37:31,079 --> 00:37:36,000
between commands you could fetch

00:37:32,970 --> 00:37:45,480
historical data or prepare your own to

00:37:36,000 --> 00:37:48,200
decide things later but right we could

00:37:45,480 --> 00:37:48,200
prefetch it yeah

00:37:55,579 --> 00:38:00,420
maybe it's something else it's kind of

00:37:58,619 --> 00:38:01,800
along those lines like how do how do we

00:38:00,420 --> 00:38:03,630
decide what to run locally versus what

00:38:01,800 --> 00:38:05,550
not looking at history that would be an

00:38:03,630 --> 00:38:12,630
option but we haven't thought about it

00:38:05,550 --> 00:38:13,510
yet much no thank you

00:38:12,630 --> 00:38:20,689
[Music]

00:38:13,510 --> 00:38:20,689

YouTube URL: https://www.youtube.com/watch?v=MF2bahnAueM


