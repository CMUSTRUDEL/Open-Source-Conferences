Title: CppCon 2015: Paul E. McKenney “C++ Atomics..."
Publication date: 2015-10-13
Playlist: CppCon 2015
Description: 
	http://www.Cppcon.org
--
C++ Atomics: The Sad Story of memory_order_consume: A Happy Ending At Last?
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/cppcon/cppcon2015
—
One of the big advantages of C++ atomics is that developers can now let the compiler know about the intent behind their multi-threaded synchronization mechanisms. At least they can tell the compiler as long as the synchronization mechanism in question is not RCU. You see, all production compilers promote RCU's memory_order_consume to memory_order_acquire. Although this promotion does ensure correctness, it also ensures the additional overhead of memory-barrier instructions on weakly ordered systems and of needlessly suppressed compiler optimizations on all systems.

All previous attempts to resolve this issue have foundered on either standard-committee reluctance to eviscerate the standard for a special case, compiler-writer reluctance to eviscerate their compilers for a special case, and kernel-developers reluctance to eviscerate their source base for late-to-the-party compiler support.

But now there is a glimmer of hope in the guise of a small set of small patches to the Linux kernel that eliminate the most challenging use cases. Will this hope be realized? Come to this talk to here the story, which by September will hopefully have a happy ending!
— 
Paul E. McKenney:  Distinguished Engineer, IBM Linux Technology Center
Low-level concurrency in applications and kernels written in C and C++.
—
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,000 --> 00:00:04,920
this is kind of the third of a set we

00:00:01,949 --> 00:00:06,720
had fader talking yesterday about how to

00:00:04,920 --> 00:00:08,849
do atomic especially one on older

00:00:06,720 --> 00:00:12,660
compilers which is an impressive feat

00:00:08,849 --> 00:00:14,700
these days we had Michael talking about

00:00:12,660 --> 00:00:16,920
the atomic in general the various memory

00:00:14,700 --> 00:00:18,270
orders and so I'm coming drilling down

00:00:16,920 --> 00:00:21,869
into the bottom of the depths with

00:00:18,270 --> 00:00:24,029
memorator consume which has been a sort

00:00:21,869 --> 00:00:25,800
of a sad story there's a few people

00:00:24,029 --> 00:00:28,019
they've been involved with it through

00:00:25,800 --> 00:00:30,689
its whole life but maybe we're coming

00:00:28,019 --> 00:00:33,660
inside of a happy ending but let's see

00:00:30,689 --> 00:00:35,250
we got here so I'm gonna talk a little

00:00:33,660 --> 00:00:37,530
bit about why you would want to use it

00:00:35,250 --> 00:00:39,840
the target workloads and why we'd have

00:00:37,530 --> 00:00:41,280
it what the problems are with the

00:00:39,840 --> 00:00:43,200
current definition of the standard and

00:00:41,280 --> 00:00:45,539
some of you who are compiler writers may

00:00:43,200 --> 00:00:48,960
know understand this better than I do or

00:00:45,539 --> 00:00:51,000
feel it more sharply anyway we'll talk

00:00:48,960 --> 00:00:52,620
about some before for prose resolutions

00:00:51,000 --> 00:00:54,030
over the past year and a half there's

00:00:52,620 --> 00:00:55,140
been a number of them put forward and it

00:00:54,030 --> 00:00:57,360
looks like we've got something that

00:00:55,140 --> 00:01:00,510
might be reasonable for two different

00:00:57,360 --> 00:01:01,559
use cases and if we have time I mean

00:01:00,510 --> 00:01:02,879
we've done double checked locking the

00:01:01,559 --> 00:01:04,320
other two so I guess I got a double

00:01:02,879 --> 00:01:07,140
check locking as well and show how you

00:01:04,320 --> 00:01:09,900
do with member consume why not if we

00:01:07,140 --> 00:01:13,350
have time we'll get their target

00:01:09,900 --> 00:01:16,830
workloads so you'd use memory or to

00:01:13,350 --> 00:01:18,420
consume four linked data structures it's

00:01:16,830 --> 00:01:19,710
used basically what it's doing is

00:01:18,420 --> 00:01:21,960
imposing order when you're following

00:01:19,710 --> 00:01:23,729
pointers relying on the fact the

00:01:21,960 --> 00:01:26,009
hardware does that for you in almost all

00:01:23,729 --> 00:01:28,799
cases dec alpha being the exception that

00:01:26,009 --> 00:01:31,590
proves the rule and if you're using this

00:01:28,799 --> 00:01:33,150
there's other things you could do let's

00:01:31,590 --> 00:01:35,549
face it if you don't care about

00:01:33,150 --> 00:01:37,229
performance why don't you just write a

00:01:35,549 --> 00:01:40,020
single-threaded program get on with your

00:01:37,229 --> 00:01:41,340
life in fact why not use a scripting

00:01:40,020 --> 00:01:42,689
language and make it so you don't have

00:01:41,340 --> 00:01:45,600
to mess with compilers and all this

00:01:42,689 --> 00:01:47,460
stuff right so if you're doing this

00:01:45,600 --> 00:01:49,530
performance has to be something you care

00:01:47,460 --> 00:01:53,119
deeply about and it has to be a

00:01:49,530 --> 00:01:55,460
performance level you can't get with a

00:01:53,119 --> 00:02:00,680
sequential process such as a single CPU

00:01:55,460 --> 00:02:02,850
and this is not tongue-in-cheek

00:02:00,680 --> 00:02:05,310
there's a number of cases where you do

00:02:02,850 --> 00:02:08,099
optimization on special code it'll get

00:02:05,310 --> 00:02:10,379
you orders of magnitude in contrast if

00:02:08,099 --> 00:02:13,500
you're adding parallel processors it's

00:02:10,379 --> 00:02:13,770
possible but hard to get a greater speed

00:02:13,500 --> 00:02:15,740
up

00:02:13,770 --> 00:02:19,020
than the number of processors you add

00:02:15,740 --> 00:02:20,340
okay so again if you're boring handle

00:02:19,020 --> 00:02:23,250
single-threaded do it single threaded

00:02:20,340 --> 00:02:26,070
ignore this at the same time before

00:02:23,250 --> 00:02:27,900
what's can't be the only concern if all

00:02:26,070 --> 00:02:29,730
you care about is performance if you

00:02:27,900 --> 00:02:32,640
want performance at any cost

00:02:29,730 --> 00:02:34,800
no matter what my friend you're writing

00:02:32,640 --> 00:02:36,210
hand-coded assembly you're not doing

00:02:34,800 --> 00:02:38,460
this you know I used to see you're not

00:02:36,210 --> 00:02:40,710
use C++ okay

00:02:38,460 --> 00:02:42,540
so we're kind of in the sweet spot where

00:02:40,710 --> 00:02:45,330
we care about performance we need

00:02:42,540 --> 00:02:47,640
parallelism we need the scalability but

00:02:45,330 --> 00:02:50,010
we're willing to give up a little bit so

00:02:47,640 --> 00:02:51,570
let the compiler help us out and to deal

00:02:50,010 --> 00:02:53,820
with that sort of things although quite

00:02:51,570 --> 00:02:55,380
frankly it's quite possible the

00:02:53,820 --> 00:02:58,230
compilers are better at generating code

00:02:55,380 --> 00:03:00,500
than people are today but still if

00:02:58,230 --> 00:03:04,470
you're drawing for that less little bit

00:03:00,500 --> 00:03:06,150
you're down on the metal so in short we

00:03:04,470 --> 00:03:07,470
want to maximize performance but we want

00:03:06,150 --> 00:03:08,850
to maintain all the other nice things

00:03:07,470 --> 00:03:10,970
you know portability maintainability

00:03:08,850 --> 00:03:14,100
reasonable levels of productivity and

00:03:10,970 --> 00:03:15,540
what we do here to get this to work you

00:03:14,100 --> 00:03:17,730
know there's an old saying that I

00:03:15,540 --> 00:03:21,110
disagree with actually this says that

00:03:17,730 --> 00:03:23,610
weak memory requires strong lines and

00:03:21,110 --> 00:03:28,650
well not really what it requires as good

00:03:23,610 --> 00:03:30,330
api's if you have good api's you can get

00:03:28,650 --> 00:03:31,920
the benefits the performance benefits of

00:03:30,330 --> 00:03:33,630
the weak memory and member weak memory

00:03:31,920 --> 00:03:35,850
isn't just the CPU it's also the

00:03:33,630 --> 00:03:37,760
compiler doing things to you for you

00:03:35,850 --> 00:03:41,130
against you something

00:03:37,760 --> 00:03:42,600
and those api's allow that to happen

00:03:41,130 --> 00:03:44,580
allow you to gain that performance

00:03:42,600 --> 00:03:46,080
without having to twist your mind around

00:03:44,580 --> 00:03:49,760
exactly older orderings that are going

00:03:46,080 --> 00:03:49,760
to get and that's that's the goal here

00:03:49,940 --> 00:03:55,440
so why never order consume specifically

00:03:52,890 --> 00:03:58,110
I mean parallelism there's a lot of ways

00:03:55,440 --> 00:03:59,340
to achieve it this is just one first was

00:03:58,110 --> 00:04:02,550
a bit case so let's look at what we're

00:03:59,340 --> 00:04:05,190
doing here so we got to have a diagram

00:04:02,550 --> 00:04:08,310
with arrows and order is in dependencies

00:04:05,190 --> 00:04:10,140
and I've left out the sequence before so

00:04:08,310 --> 00:04:12,810
that Michael had earlier and so we've

00:04:10,140 --> 00:04:14,700
got two threads the top three statements

00:04:12,810 --> 00:04:16,350
are the first thread and running in

00:04:14,700 --> 00:04:18,420
parallel is this other thread down here

00:04:16,350 --> 00:04:20,280
with the bottom three statements and of

00:04:18,420 --> 00:04:25,530
course there's sequence befores between

00:04:20,280 --> 00:04:27,630
each pair of statements there now what

00:04:25,530 --> 00:04:31,740
we're doing is we do a relaxed or 2x sum

00:04:27,630 --> 00:04:35,070
related variable we then do a relaxed or

00:04:31,740 --> 00:04:38,850
to an element within a structure pointed

00:04:35,070 --> 00:04:41,910
to by P the pointer P and after that we

00:04:38,850 --> 00:04:44,640
do a memory order release store of P a

00:04:41,910 --> 00:04:46,650
local variable into some global okay so

00:04:44,640 --> 00:04:49,190
we've taken and we've initialized some

00:04:46,650 --> 00:04:51,060
unrelated variable we filled out a

00:04:49,190 --> 00:04:53,010
element and a structure we're playing

00:04:51,060 --> 00:04:55,320
with and we're taking a point of that

00:04:53,010 --> 00:04:57,750
structure and publishing it in to this

00:04:55,320 --> 00:05:00,960
variable GP that's when one thread is

00:04:57,750 --> 00:05:03,000
doing because we do release there we

00:05:00,960 --> 00:05:05,730
have some notion of ordering between

00:05:03,000 --> 00:05:07,800
that last store and the previous two

00:05:05,730 --> 00:05:10,410
stores all right

00:05:07,800 --> 00:05:12,000
however as Fader pointed out in the last

00:05:10,410 --> 00:05:14,370
turtle we call it memory barrier pairing

00:05:12,000 --> 00:05:17,250
but however you call it you don't get

00:05:14,370 --> 00:05:20,460
ordering just by ordering one thread you

00:05:17,250 --> 00:05:22,080
have to have ordering in both threads if

00:05:20,460 --> 00:05:22,530
you let either thread do things out of

00:05:22,080 --> 00:05:24,900
order

00:05:22,530 --> 00:05:28,680
you haven't got ordering they have to

00:05:24,900 --> 00:05:30,360
both work together and so we have to

00:05:28,680 --> 00:05:31,920
look at what's happening in the reading

00:05:30,360 --> 00:05:34,560
thread down here on the last three lines

00:05:31,920 --> 00:05:37,230
now what it does is it loads that GP

00:05:34,560 --> 00:05:39,210
thing that global pointer that points to

00:05:37,230 --> 00:05:41,910
that structure we filled out with its

00:05:39,210 --> 00:05:44,040
single field a there and if we happen to

00:05:41,910 --> 00:05:46,470
get that pointer we have a dependency

00:05:44,040 --> 00:05:48,540
ordered before relationship between the

00:05:46,470 --> 00:05:50,460
last statement in the first thread and

00:05:48,540 --> 00:05:52,170
the first statement in the second thread

00:05:50,460 --> 00:05:57,330
so there's a diagonal green arrow

00:05:52,170 --> 00:05:59,190
represents that alright and the nice

00:05:57,330 --> 00:06:00,690
thing about this is member to consume if

00:05:59,190 --> 00:06:02,340
we had an efficient memory rotor consume

00:06:00,690 --> 00:06:03,840
which we do not yet by the way that's

00:06:02,340 --> 00:06:05,700
one of the things we're looking at here

00:06:03,840 --> 00:06:07,620
if you have an inefficient one that

00:06:05,700 --> 00:06:11,160
promotes ADD acquire and well life's

00:06:07,620 --> 00:06:12,660
hard sometimes but and then so in Linux

00:06:11,160 --> 00:06:14,010
world we still use balls with cast and

00:06:12,660 --> 00:06:17,910
various other strange and odd horrible

00:06:14,010 --> 00:06:20,840
tricks to get the effect but what

00:06:17,910 --> 00:06:24,480
happens is that the second load is

00:06:20,840 --> 00:06:26,690
loading a field pointed to by cue use

00:06:24,480 --> 00:06:29,400
the local variable we load it into and

00:06:26,690 --> 00:06:33,030
because those are dependent we had to

00:06:29,400 --> 00:06:36,140
use the loaded value into queue to find

00:06:33,030 --> 00:06:38,160
the address for the field cue arrow a

00:06:36,140 --> 00:06:39,820
therefore there's a dependency between

00:06:38,160 --> 00:06:42,220
these two statements

00:06:39,820 --> 00:06:43,930
and that means that they have a

00:06:42,220 --> 00:06:49,060
dependency carry between those two

00:06:43,930 --> 00:06:50,380
statements as a result because we have

00:06:49,060 --> 00:06:53,320
her sing closely for up there between

00:06:50,380 --> 00:06:54,940
the store to field a up there this

00:06:53,320 --> 00:06:59,490
middle statement in the first thread and

00:06:54,940 --> 00:07:02,040
the store into the GP pointer we have a

00:06:59,490 --> 00:07:04,710
confuse to ordering and we have a

00:07:02,040 --> 00:07:07,330
carrying dependency from that

00:07:04,710 --> 00:07:10,270
initialization of field a all the way

00:07:07,330 --> 00:07:12,880
down to the use so we're guaranteed we

00:07:10,270 --> 00:07:14,890
pick this up where you get the value we

00:07:12,880 --> 00:07:18,400
store it up there the one we're not

00:07:14,890 --> 00:07:21,250
going to get pre initialized garbage if

00:07:18,400 --> 00:07:23,110
all we did was relax loads here we could

00:07:21,250 --> 00:07:26,560
get pre initialized garbage because

00:07:23,110 --> 00:07:28,630
again we have to have ordering in both

00:07:26,560 --> 00:07:34,750
threads in order to see the ordering

00:07:28,630 --> 00:07:37,300
over all this we load from GP into queue

00:07:34,750 --> 00:07:40,930
and then we have a queue again here or

00:07:37,300 --> 00:07:42,220
if I'm missing the question yeah yeah I

00:07:40,930 --> 00:07:43,900
don't know I was trying to be more clear

00:07:42,220 --> 00:07:48,910
perhaps as more confusing but life's

00:07:43,900 --> 00:07:50,560
like that what's that oh okay you're

00:07:48,910 --> 00:07:56,110
right that's that is wrong that should

00:07:50,560 --> 00:07:56,500
be going away thank you okay however for

00:07:56,110 --> 00:07:59,140
Rex

00:07:56,500 --> 00:08:01,660
there's no dependency we load Q it has

00:07:59,140 --> 00:08:03,040
nothing whatsoever to do with X there is

00:08:01,660 --> 00:08:04,960
no dependence between those two

00:08:03,040 --> 00:08:07,180
statements there is no ordering between

00:08:04,960 --> 00:08:08,890
these two statements we have ordering

00:08:07,180 --> 00:08:11,440
the first thread not in the second

00:08:08,890 --> 00:08:13,180
thread and therefore this can pick up

00:08:11,440 --> 00:08:15,220
whatever from X it can pick up something

00:08:13,180 --> 00:08:19,240
before that initialization at the very

00:08:15,220 --> 00:08:22,060
top of the slide so memory or a consume

00:08:19,240 --> 00:08:25,170
is nice in that this can just be a

00:08:22,060 --> 00:08:28,600
normal load on almost all architectures

00:08:25,170 --> 00:08:31,870
so very simple instruction very fast nor

00:08:28,600 --> 00:08:34,210
the fish will slow down but there's a

00:08:31,870 --> 00:08:35,620
penalty there's no free lunch if you're

00:08:34,210 --> 00:08:37,690
going to get the ordering you have to

00:08:35,620 --> 00:08:39,669
have dependencies between that initial

00:08:37,690 --> 00:08:43,270
load and the loads or stores that follow

00:08:39,669 --> 00:08:44,620
it now it turns out that if you have a

00:08:43,270 --> 00:08:47,200
linked data structure that happens very

00:08:44,620 --> 00:08:49,810
naturally you go down at some pointer

00:08:47,200 --> 00:08:51,850
and then you do dependent loads off of

00:08:49,810 --> 00:08:53,260
that pointer so those dependency

00:08:51,850 --> 00:08:55,390
happened very naturally

00:08:53,260 --> 00:08:56,830
in linked data structures and so in

00:08:55,390 --> 00:09:00,160
linked data structures this technique

00:08:56,830 --> 00:09:01,840
works very well so we have to pay a

00:09:00,160 --> 00:09:03,160
little bit of penalty for updating we

00:09:01,840 --> 00:09:05,880
have to have that memory barrier or

00:09:03,160 --> 00:09:10,030
something to make that release work on

00:09:05,880 --> 00:09:11,500
the reader side we just issue normal

00:09:10,030 --> 00:09:13,420
instructions and things work nicely for

00:09:11,500 --> 00:09:15,520
us with the exception again of dekha

00:09:13,420 --> 00:09:17,970
alpha but that's discontinued for a

00:09:15,520 --> 00:09:20,950
while and we take care of that otherwise

00:09:17,970 --> 00:09:22,570
so this is kind of the use case is to be

00:09:20,950 --> 00:09:23,800
able to do blinked operation of linked

00:09:22,570 --> 00:09:26,320
data structures that should read at

00:09:23,800 --> 00:09:28,000
ensive ones using very simple very keep

00:09:26,320 --> 00:09:32,410
instructions and getting very high

00:09:28,000 --> 00:09:35,440
performance as a result well okay that's

00:09:32,410 --> 00:09:36,910
great the reader went really fast but so

00:09:35,440 --> 00:09:41,470
what there's got updaters to write

00:09:36,910 --> 00:09:43,420
that's true you do the reason this would

00:09:41,470 --> 00:09:45,040
become important compared to say 25

00:09:43,420 --> 00:09:47,380
years ago when I was first starting to

00:09:45,040 --> 00:09:48,730
do parallel programming is that the

00:09:47,380 --> 00:09:51,220
machines have gotten a lot bigger and

00:09:48,730 --> 00:09:53,710
more complex and they adapt themselves

00:09:51,220 --> 00:09:55,120
to their environment if I plug a memory

00:09:53,710 --> 00:09:56,530
stick what you saw I plugged the video

00:09:55,120 --> 00:09:58,240
in this machine and the slight gesture

00:09:56,530 --> 00:09:59,710
came on if I plug a memory stick into it

00:09:58,240 --> 00:10:02,290
it would pop up and say oh you got a

00:09:59,710 --> 00:10:03,700
memory stick if I were to try do that

00:10:02,290 --> 00:10:06,700
say in the early 80s

00:10:03,700 --> 00:10:09,130
I'd have to recompile the kernel to tell

00:10:06,700 --> 00:10:10,780
about the new device because there

00:10:09,130 --> 00:10:12,520
wasn't enough freaking memory to

00:10:10,780 --> 00:10:13,870
represent the possibility there might be

00:10:12,520 --> 00:10:15,550
a device or might not you had to

00:10:13,870 --> 00:10:17,470
actually tell it I've got these devices

00:10:15,550 --> 00:10:19,270
right now and if you're booted on a

00:10:17,470 --> 00:10:22,600
system that didn't have those devices it

00:10:19,270 --> 00:10:25,480
would probably panic at boot what that

00:10:22,600 --> 00:10:28,450
means is inside this laptop there are

00:10:25,480 --> 00:10:31,420
data structures they represent the

00:10:28,450 --> 00:10:32,140
hardware connected to it the fact that

00:10:31,420 --> 00:10:34,330
it Scott

00:10:32,140 --> 00:10:38,370
doesn't have right now any memory fees

00:10:34,330 --> 00:10:42,970
but it did a while ago and I saved my

00:10:38,370 --> 00:10:48,580
presentation just in case and so those

00:10:42,970 --> 00:10:50,050
structures almost never change I plugged

00:10:48,580 --> 00:10:51,670
hardware into it occasionally but very

00:10:50,050 --> 00:10:53,800
occasionally compared to how much I'm

00:10:51,670 --> 00:10:58,120
using it but I could plug hardware in at

00:10:53,800 --> 00:10:59,890
any time and that means that I have

00:10:58,120 --> 00:11:01,300
things where I'm reading almost all the

00:10:59,890 --> 00:11:01,780
time they always never change but they

00:11:01,300 --> 00:11:05,740
might

00:11:01,780 --> 00:11:06,540
and so this read mostly approach this

00:11:05,740 --> 00:11:08,750
focus on reading

00:11:06,540 --> 00:11:11,400
it's become increasingly important as

00:11:08,750 --> 00:11:13,950
our hardware and software and operating

00:11:11,400 --> 00:11:15,060
systems and applications have become

00:11:13,950 --> 00:11:17,730
more able to adapt to a changing

00:11:15,060 --> 00:11:19,020
environment so that's why it's getting

00:11:17,730 --> 00:11:23,520
more important now that would have been

00:11:19,020 --> 00:11:26,760
say in the 1980s of course you still

00:11:23,520 --> 00:11:28,290
need updates and oddly enough you can

00:11:26,760 --> 00:11:30,030
use memory order consume for updates and

00:11:28,290 --> 00:11:32,100
some people do you can think of it as a

00:11:30,030 --> 00:11:34,650
poor-man's garbage collector so the

00:11:32,100 --> 00:11:36,630
tricks that theta are pointed out could

00:11:34,650 --> 00:11:40,080
work with a garbage collector you can

00:11:36,630 --> 00:11:41,640
use rc4 those as well and that does

00:11:40,080 --> 00:11:45,960
happen people do use those in the linux

00:11:41,640 --> 00:11:47,580
kernel for that reason okay but you know

00:11:45,960 --> 00:11:49,860
we're talking about really small changes

00:11:47,580 --> 00:11:51,660
here right we're talking on PowerPC you

00:11:49,860 --> 00:11:52,980
get rid of an l a-- BSA or maybe and i

00:11:51,660 --> 00:11:55,830
think these are just in the little

00:11:52,980 --> 00:12:00,000
instructions on RN and i get rid of a

00:11:55,830 --> 00:12:03,840
dsb by doing doing this or a DMD excuse

00:12:00,000 --> 00:12:05,220
me on x86 your constraining the compiler

00:12:03,840 --> 00:12:09,170
not allowing to do certain optimizations

00:12:05,220 --> 00:12:12,840
so who cares why would any bake care

00:12:09,170 --> 00:12:16,170
well a few months ago I received this

00:12:12,840 --> 00:12:18,540
patch or a predecessor of it the initial

00:12:16,170 --> 00:12:21,720
patch I received was technically correct

00:12:18,540 --> 00:12:24,750
but gave false positives when various

00:12:21,720 --> 00:12:27,240
tools ran on it okay so this is the

00:12:24,750 --> 00:12:28,650
modified version and don't worry about

00:12:27,240 --> 00:12:33,840
exactly what it is as much a weird

00:12:28,650 --> 00:12:37,140
kernel code but the key point is that it

00:12:33,840 --> 00:12:40,170
saves one store in one load both the

00:12:37,140 --> 00:12:42,360
store in the loader non-atomic how they

00:12:40,170 --> 00:12:47,480
have to be because this is pre c11 and

00:12:42,360 --> 00:12:58,230
we don't have Atomics okay to the stack

00:12:47,480 --> 00:13:00,180
not to a shared variable I initially

00:12:58,230 --> 00:13:04,710
suggested to the submitter that there

00:13:00,180 --> 00:13:08,190
wasn't a pointless patch and actually he

00:13:04,710 --> 00:13:10,050
it was he surprisingly enough this is

00:13:08,190 --> 00:13:12,150
visible at user mode this is a patch

00:13:10,050 --> 00:13:13,380
deep in the kernel and the performance

00:13:12,150 --> 00:13:16,970
of difference is visible at user mode

00:13:13,380 --> 00:13:16,970
with certain benchmarks

00:13:18,140 --> 00:13:22,980
it's not isn't anything and this is

00:13:21,450 --> 00:13:24,690
these are two normal instructions these

00:13:22,980 --> 00:13:26,730
not memory barriers not lock

00:13:24,690 --> 00:13:29,790
constructions not Atomics not nothing

00:13:26,730 --> 00:13:31,230
alright and the thing is is that some

00:13:29,790 --> 00:13:33,900
people do care about performance and the

00:13:31,230 --> 00:13:39,570
Linux kernel is one of many projects the

00:13:33,900 --> 00:13:40,110
needs to accommodate their needs all

00:13:39,570 --> 00:13:42,810
right

00:13:40,110 --> 00:13:45,300
so developers who faced severe

00:13:42,810 --> 00:13:47,100
performance requirements their echo

00:13:45,300 --> 00:13:48,750
thank you if you go throwing extra

00:13:47,100 --> 00:13:51,690
number offense instructions in their

00:13:48,750 --> 00:13:53,070
code they won't appreciate that much and

00:13:51,690 --> 00:13:55,290
they aren't going to thank you about

00:13:53,070 --> 00:13:58,560
extra cache misses either or extra

00:13:55,290 --> 00:13:59,940
atomic instructions and they're also not

00:13:58,560 --> 00:14:04,050
going to thank you for unnecessarily

00:13:59,940 --> 00:14:06,750
suppressing pilot optimizations they've

00:14:04,050 --> 00:14:10,260
told me that rather directly several

00:14:06,750 --> 00:14:11,430
times over the past decade or so it

00:14:10,260 --> 00:14:13,620
don't take my word for it if you don't

00:14:11,430 --> 00:14:16,860
want to but you know look at lkl if you

00:14:13,620 --> 00:14:18,390
want in some cases lk mel is

00:14:16,860 --> 00:14:19,710
insufficient to vent their ire so they

00:14:18,390 --> 00:14:26,280
call me on the telephone and scream at

00:14:19,710 --> 00:14:27,870
me so anyway what if C and C++ are going

00:14:26,280 --> 00:14:29,370
to use supporting low-low development

00:14:27,870 --> 00:14:31,170
and I believe they need to i mean c plus

00:14:29,370 --> 00:14:32,820
c and c++ must serve a lot of different

00:14:31,170 --> 00:14:34,980
needs still get me wrong it's not only

00:14:32,820 --> 00:14:36,090
about low low element but the low level

00:14:34,980 --> 00:14:37,530
development of synchronization

00:14:36,090 --> 00:14:39,990
primitives one of the things we need to

00:14:37,530 --> 00:14:41,370
be able to do in these languages we need

00:14:39,990 --> 00:14:45,840
to support this kind of extreme

00:14:41,370 --> 00:14:47,130
performance and scalability and that's

00:14:45,840 --> 00:14:49,740
why we have a member order consume or

00:14:47,130 --> 00:14:52,290
one reason it's intended to compile as I

00:14:49,740 --> 00:14:56,010
said on a single load most CPUs with no

00:14:52,290 --> 00:14:58,790
added croft and as a result it is quite

00:14:56,010 --> 00:15:00,900
fast of course

00:14:58,790 --> 00:15:03,180
one question is how the heck can use

00:15:00,900 --> 00:15:06,210
this thing and as a fader pointed out

00:15:03,180 --> 00:15:08,130
it's one thing to write concurrent code

00:15:06,210 --> 00:15:11,520
there's another thing to write correct

00:15:08,130 --> 00:15:16,080
concurrent code and we'll take a quick

00:15:11,520 --> 00:15:18,770
look at that there's a guy used to work

00:15:16,080 --> 00:15:21,210
with back in the early 90s

00:15:18,770 --> 00:15:23,730
older guy at the time big bushy beard

00:15:21,210 --> 00:15:27,360
you know long white hair didn't have a

00:15:23,730 --> 00:15:30,450
wand sorry he had a he had a sign on his

00:15:27,360 --> 00:15:32,970
cube though and that sign said only

00:15:30,450 --> 00:15:38,370
those who have gone too far can possibly

00:15:32,970 --> 00:15:40,980
tell you how far you can go so let's go

00:15:38,370 --> 00:15:43,470
all the way here all right I mean let's

00:15:40,980 --> 00:15:45,000
see what happens so we're gonna define

00:15:43,470 --> 00:15:45,870
some primitives here or she read Locke

00:15:45,000 --> 00:15:47,490
think of that kind of like a

00:15:45,870 --> 00:15:50,160
reader/writer lock acquire acquisition

00:15:47,490 --> 00:15:51,900
sort of kind of but not quite and we are

00:15:50,160 --> 00:15:53,610
she read unlock and I do mean that

00:15:51,900 --> 00:15:56,910
counseling to find are so read lock

00:15:53,610 --> 00:15:59,970
Karen Karen new line that's the

00:15:56,910 --> 00:16:01,680
primitive and I really do mean council I

00:15:59,970 --> 00:16:06,300
define our she read lock parent parent

00:16:01,680 --> 00:16:07,650
new line and there's this are so you do

00:16:06,300 --> 00:16:08,820
reference things just remember order

00:16:07,650 --> 00:16:10,440
consume if you look in the length

00:16:08,820 --> 00:16:11,970
Colonel you see some fallible casts and

00:16:10,440 --> 00:16:13,710
stuff like that because that's what we

00:16:11,970 --> 00:16:15,210
have right now to use that with we're

00:16:13,710 --> 00:16:18,180
kind of the same position cater is its

00:16:15,210 --> 00:16:21,870
we have to support compilers that are

00:16:18,180 --> 00:16:23,250
pre c11 I'm going to do a sign choir

00:16:21,870 --> 00:16:25,440
which is a really storage you and you

00:16:23,250 --> 00:16:26,820
might guess those two from that diagram

00:16:25,440 --> 00:16:32,310
with the two threads I showed a few

00:16:26,820 --> 00:16:34,170
slides back now until somebody tells me

00:16:32,310 --> 00:16:38,010
otherwise I'm going to assert that if

00:16:34,170 --> 00:16:39,690
you can use those four primitives there

00:16:38,010 --> 00:16:42,630
can give you the best possible read side

00:16:39,690 --> 00:16:44,670
performance scalability real-time

00:16:42,630 --> 00:16:46,200
response weight freedom and energy

00:16:44,670 --> 00:16:52,200
efficiency at least if you had a good

00:16:46,200 --> 00:16:53,970
consume which we don't get now yeah I'm

00:16:52,200 --> 00:16:55,200
an old guy you guys are young so you

00:16:53,970 --> 00:16:57,840
guys might get to a challenge to beat

00:16:55,200 --> 00:16:59,580
that for the first three of them you're

00:16:57,840 --> 00:17:02,870
going to need especially the first two

00:16:59,580 --> 00:17:05,490
you're gonna need some negative overhead

00:17:02,870 --> 00:17:06,810
which could be a challenge but if you do

00:17:05,490 --> 00:17:11,910
that it's really cool and like you tell

00:17:06,810 --> 00:17:13,589
me how you do it all right of course

00:17:11,910 --> 00:17:14,520
somebody may be objecting at this point

00:17:13,589 --> 00:17:16,770
wait a minute these things aren't

00:17:14,520 --> 00:17:19,770
affecting machine State how are you

00:17:16,770 --> 00:17:21,000
synchronizing anything with them that's

00:17:19,770 --> 00:17:23,310
a good question it's a reasonable

00:17:21,000 --> 00:17:25,020
question and by the way I'm gonna go

00:17:23,310 --> 00:17:26,939
through this really quickly there'll be

00:17:25,020 --> 00:17:28,290
some reference to the slide set I'm

00:17:26,939 --> 00:17:31,559
happy to talk to people later I'll be

00:17:28,290 --> 00:17:33,149
here through mid Friday but

00:17:31,559 --> 00:17:35,610
this is just to give you a flavor of it

00:17:33,149 --> 00:17:39,090
you know and those of you have some

00:17:35,610 --> 00:17:42,600
familiarity with it may gain some more

00:17:39,090 --> 00:17:44,340
as well all right so we're talking about

00:17:42,600 --> 00:17:45,690
linked data structures one of the things

00:17:44,340 --> 00:17:47,519
we do with linked data structures in

00:17:45,690 --> 00:17:50,009
insert new elements into the linked data

00:17:47,519 --> 00:17:51,509
structure so let's take a really really

00:17:50,009 --> 00:17:52,860
simple lake tenaya structure that has

00:17:51,509 --> 00:17:54,779
just a pointer all right

00:17:52,860 --> 00:17:56,129
so either has a point of this no lure

00:17:54,779 --> 00:17:58,230
has a pointer of one thing hanging off

00:17:56,129 --> 00:18:01,110
of it let's start simple we go from

00:17:58,230 --> 00:18:02,999
there right so we have four different

00:18:01,110 --> 00:18:05,249
states here as we're inserting this

00:18:02,999 --> 00:18:09,539
element so we start off with a null

00:18:05,249 --> 00:18:11,610
pointer and we have colors so red means

00:18:09,539 --> 00:18:13,409
that a reader can look at any time now

00:18:11,610 --> 00:18:15,659
remember our read lock doesn't do

00:18:13,409 --> 00:18:16,980
anything I mean not only is it not

00:18:15,659 --> 00:18:18,749
generate instructions the compiler

00:18:16,980 --> 00:18:22,110
back-end doesn't even see it right the C

00:18:18,749 --> 00:18:24,960
processor gets rid of it so we can't do

00:18:22,110 --> 00:18:26,460
anything to stop readers there come

00:18:24,960 --> 00:18:29,340
blasting through and check that pointer

00:18:26,460 --> 00:18:33,090
no matter what we can't even tell about

00:18:29,340 --> 00:18:34,679
it there so we color that red because

00:18:33,090 --> 00:18:36,809
it's kind of dangerous if we do updates

00:18:34,679 --> 00:18:38,519
we got to be careful of that variable

00:18:36,809 --> 00:18:42,330
because readers can come in at any old

00:18:38,519 --> 00:18:44,820
time they want to and access it green

00:18:42,330 --> 00:18:47,279
stuff is stuff where we have the only

00:18:44,820 --> 00:18:48,720
reference to it and so as long as your

00:18:47,279 --> 00:18:50,639
memory allocator is sane and people

00:18:48,720 --> 00:18:51,990
aren't using too many wild pointers you

00:18:50,639 --> 00:18:53,519
can do ever you want to it without

00:18:51,990 --> 00:18:54,779
worrying about interference or without

00:18:53,519 --> 00:18:57,720
worrying about interfering with somebody

00:18:54,779 --> 00:19:00,389
else yellow will get to on the next

00:18:57,720 --> 00:19:02,850
slide so the first thing we do is you do

00:19:00,389 --> 00:19:04,350
allocate a structure and so in the

00:19:02,850 --> 00:19:05,940
second state here we got our structure

00:19:04,350 --> 00:19:07,080
the pointer doesn't point to it

00:19:05,940 --> 00:19:08,720
thankfully because this is got garbage

00:19:07,080 --> 00:19:11,659
in it because this has been initialized

00:19:08,720 --> 00:19:14,309
we got our little local pointer P to it

00:19:11,659 --> 00:19:17,190
so we initialize it now it's got

00:19:14,309 --> 00:19:19,889
definite fields they got values but we

00:19:17,190 --> 00:19:21,690
still can't get in from outside and then

00:19:19,889 --> 00:19:23,700
we use this our co-signed pointer which

00:19:21,690 --> 00:19:26,909
is turns into a consume excuse me a

00:19:23,700 --> 00:19:29,249
release store and I didn't want to try

00:19:26,909 --> 00:19:30,840
to type a full release store into that

00:19:29,249 --> 00:19:33,980
arrow which is why I'm using the Linux

00:19:30,840 --> 00:19:36,410
kernel API rather than c11

00:19:33,980 --> 00:19:39,500
and once we do that suddenly the readers

00:19:36,410 --> 00:19:41,540
can get to it this does the release so

00:19:39,500 --> 00:19:43,160
that a reader getting to it because this

00:19:41,540 --> 00:19:45,680
using a consume load which is what our

00:19:43,160 --> 00:19:49,820
CD reference does those two orderings

00:19:45,680 --> 00:19:51,980
pair and therefore the readers see valid

00:19:49,820 --> 00:19:53,690
data rather than pre initialized cruft

00:19:51,980 --> 00:19:56,780
over here that way they would get if we

00:19:53,690 --> 00:19:58,220
didn't have ordering but because we can

00:19:56,780 --> 00:20:00,350
use the equivalent of consume load

00:19:58,220 --> 00:20:02,870
they're just doing the normal load of

00:20:00,350 --> 00:20:04,160
that pointer I mean they take a cache

00:20:02,870 --> 00:20:06,050
miss the first time they load it because

00:20:04,160 --> 00:20:08,090
we just stored the pointer but after

00:20:06,050 --> 00:20:12,620
that full speed replicating Embry's

00:20:08,090 --> 00:20:15,350
cache very fast so what this means is we

00:20:12,620 --> 00:20:17,480
can safely insert data into a linked

00:20:15,350 --> 00:20:18,710
data structure even though readers are

00:20:17,480 --> 00:20:25,940
plowing through the data structure at

00:20:18,710 --> 00:20:29,300
all times so for insertion we don't need

00:20:25,940 --> 00:20:31,610
to exclude readers we don't need the

00:20:29,300 --> 00:20:32,450
readers to pay the overhead of checking

00:20:31,610 --> 00:20:34,850
where there's this writer

00:20:32,450 --> 00:20:38,110
they can just go blasting through pick

00:20:34,850 --> 00:20:41,360
their stuff up and get some valid data

00:20:38,110 --> 00:20:43,700
so the key point is that our CEO of sign

00:20:41,360 --> 00:20:45,920
pointer and our CD reference avoid load

00:20:43,700 --> 00:20:47,150
and story tearing that means that the

00:20:45,920 --> 00:20:49,610
our shidu reference is either get to the

00:20:47,150 --> 00:20:51,230
old null value for the pointer or it's

00:20:49,610 --> 00:20:53,540
gonna get a valued pointer to real data

00:20:51,230 --> 00:20:56,300
it's not gonna get some bit wise mash up

00:20:53,540 --> 00:20:59,950
of the two players so either way the

00:20:56,300 --> 00:21:03,320
readers going to see something valid of

00:20:59,950 --> 00:21:04,430
course if all we can do is add well we

00:21:03,320 --> 00:21:06,170
either have a garbage collector we've

00:21:04,430 --> 00:21:08,240
got a big memory leak and they're

00:21:06,170 --> 00:21:09,710
actually our garbage collectors I would

00:21:08,240 --> 00:21:11,750
try to complain to standardized and

00:21:09,710 --> 00:21:13,630
always had problems but they're kind of

00:21:11,750 --> 00:21:15,620
out there if you want to use them

00:21:13,630 --> 00:21:18,410
otherwise we need some way to remove

00:21:15,620 --> 00:21:20,980
something with this structure and that's

00:21:18,410 --> 00:21:23,720
what we get to this diagram here and

00:21:20,980 --> 00:21:25,910
this can be thought of how thank Mike

00:21:23,720 --> 00:21:28,730
for this one shortage there's cat meets

00:21:25,910 --> 00:21:30,110
Heisenberg's uncertainty principle we're

00:21:28,730 --> 00:21:31,250
gonna up the ante a little bit here so

00:21:30,110 --> 00:21:32,510
just having a single pointer with a

00:21:31,250 --> 00:21:35,140
single element we're gonna use a linked

00:21:32,510 --> 00:21:38,000
list all right try to get with the times

00:21:35,140 --> 00:21:40,580
and this is animals we got a boil cat in

00:21:38,000 --> 00:21:42,260
a canoe they're all red because it's all

00:21:40,580 --> 00:21:43,730
hooked up their readers can see at any

00:21:42,260 --> 00:21:46,640
of those elements at any time for any

00:21:43,730 --> 00:21:49,360
length of time we can't stop them we

00:21:46,640 --> 00:21:49,360
can't even tell they're there

00:21:50,049 --> 00:21:56,150
but if we were to do a list LRC you and

00:21:53,600 --> 00:21:58,490
that's just a macro inside the Linux

00:21:56,150 --> 00:22:00,590
kernel but the essential point is the

00:21:58,490 --> 00:22:03,470
rear take and store into the Boas next

00:22:00,590 --> 00:22:05,929
pointer a pointer to canoe using an

00:22:03,470 --> 00:22:07,700
atomic store so again we're gonna either

00:22:05,929 --> 00:22:09,740
see the readers means the old value of

00:22:07,700 --> 00:22:12,049
the cat or the new value point of the

00:22:09,740 --> 00:22:16,039
canoe but it's not gonna see some smoosh

00:22:12,049 --> 00:22:18,530
of the two pointers either way whether a

00:22:16,039 --> 00:22:20,450
reader goes here or here it's gonna see

00:22:18,530 --> 00:22:24,380
a valid linked list with real data in

00:22:20,450 --> 00:22:26,450
them and won't be confused now the cat

00:22:24,380 --> 00:22:27,710
is yellow because there might be readers

00:22:26,450 --> 00:22:32,000
there that we reader is there for a

00:22:27,710 --> 00:22:34,700
length of time but new readers can't get

00:22:32,000 --> 00:22:37,100
to the cat anymore you only have to

00:22:34,700 --> 00:22:38,360
worry about the old readers and a new

00:22:37,100 --> 00:22:44,030
reader tries to get to it'll end up with

00:22:38,360 --> 00:22:46,549
a canoe instead isn't tight now if we

00:22:44,030 --> 00:22:48,679
had some magic operation that waited for

00:22:46,549 --> 00:22:50,090
all the old readers remember we don't

00:22:48,679 --> 00:22:52,850
have to wait for the new readers they

00:22:50,090 --> 00:22:54,740
bypassed the cat so if we have some way

00:22:52,850 --> 00:22:57,860
waiting for all the old readers all the

00:22:54,740 --> 00:23:00,110
readers that already exist when we got

00:22:57,860 --> 00:23:02,080
done waiting there wouldn't be any

00:23:00,110 --> 00:23:05,630
readers look in the cat anymore

00:23:02,080 --> 00:23:06,530
any new reader again bypasses the cat so

00:23:05,630 --> 00:23:08,539
we only had the great for the old

00:23:06,530 --> 00:23:11,330
readers once all the old readers are

00:23:08,539 --> 00:23:15,289
waited for nobody's looking at the cab

00:23:11,330 --> 00:23:17,419
except us at that point we can just free

00:23:15,289 --> 00:23:25,730
it and be back down to two elements in

00:23:17,419 --> 00:23:27,289
link list of course it'd be easier to do

00:23:25,730 --> 00:23:28,700
this if the readers were actually

00:23:27,289 --> 00:23:32,470
putting something in memory saying they

00:23:28,700 --> 00:23:32,470
were there which they aren't

00:23:36,520 --> 00:23:40,840
nevertheless

00:23:38,050 --> 00:23:44,260
possible solve this problem in this case

00:23:40,840 --> 00:23:47,230
and this is actually close to how things

00:23:44,260 --> 00:23:49,210
are permitted in one form of RCU in the

00:23:47,230 --> 00:23:51,970
linux kernel

00:23:49,210 --> 00:23:54,100
it's a quiescent based so don't worry

00:23:51,970 --> 00:23:56,560
about the QSB are for a moment anyway if

00:23:54,100 --> 00:23:57,970
you build a server class Linux kernel in

00:23:56,560 --> 00:24:00,730
other words config preempt equals end

00:23:57,970 --> 00:24:03,450
for those that have built kernels you

00:24:00,730 --> 00:24:07,840
end up with this type of approach and

00:24:03,450 --> 00:24:09,130
the trick here is that our Co readers in

00:24:07,840 --> 00:24:11,920
that environment are not permitted to

00:24:09,130 --> 00:24:13,180
block and that's the same rule you have

00:24:11,920 --> 00:24:15,180
for pure spin locks we had some

00:24:13,180 --> 00:24:17,740
discussion on spin locks yesterday and

00:24:15,180 --> 00:24:19,390
one of the key questions that came out

00:24:17,740 --> 00:24:20,860
was wait a minute if you got the spin

00:24:19,390 --> 00:24:22,330
lock in your block that's pure spin lock

00:24:20,860 --> 00:24:25,480
that's gonna cause a problem and you're

00:24:22,330 --> 00:24:27,460
right it is that's why in the Linux

00:24:25,480 --> 00:24:29,200
kernel when you uphold a pure spin lock

00:24:27,460 --> 00:24:32,050
you are not allowed to block every

00:24:29,200 --> 00:24:34,300
period in this story forget it because

00:24:32,050 --> 00:24:36,150
if you do you could have all the CPUs

00:24:34,300 --> 00:24:38,410
now spinning waiting lock you hold

00:24:36,150 --> 00:24:40,690
they're not gonna give up their CPU

00:24:38,410 --> 00:24:42,190
until look at the lock yeah you're not

00:24:40,690 --> 00:24:43,080
gonna give up a lock to get a CPU and

00:24:42,190 --> 00:24:45,700
you have deadlock

00:24:43,080 --> 00:24:47,950
therefore if you're holding a pure spin

00:24:45,700 --> 00:24:51,040
lock in the Linux kernel you do not

00:24:47,950 --> 00:24:54,040
block period if you try it you'll get a

00:24:51,040 --> 00:24:57,850
nasty splat scheduling 12 atomic I think

00:24:54,040 --> 00:25:01,390
it is we have the same rule for our C

00:24:57,850 --> 00:25:03,550
readers once you've done our she read

00:25:01,390 --> 00:25:05,740
lock you are not allowed to block until

00:25:03,550 --> 00:25:07,960
you do the matching arcs you read unlock

00:25:05,740 --> 00:25:09,460
now there are other forms of ours to you

00:25:07,960 --> 00:25:11,590
for example user space we have other

00:25:09,460 --> 00:25:15,820
tricks we use but in the kernel for

00:25:11,590 --> 00:25:18,820
server class builds that's the rule well

00:25:15,820 --> 00:25:20,680
what that means is that if if we have so

00:25:18,820 --> 00:25:22,510
we got the CPU to remove the cat and

00:25:20,680 --> 00:25:24,130
then go synchronize our C which means he

00:25:22,510 --> 00:25:25,450
blocks right because thinking that

00:25:24,130 --> 00:25:27,160
actually waits until the readers are

00:25:25,450 --> 00:25:30,340
done that means that was a context

00:25:27,160 --> 00:25:33,130
switch well if you have a context switch

00:25:30,340 --> 00:25:37,210
you can't be in a reader because readers

00:25:33,130 --> 00:25:39,130
aren't allowed to block so as soon as

00:25:37,210 --> 00:25:40,650
the sakai context switches we know that

00:25:39,130 --> 00:25:43,260
all the previous readers have to be done

00:25:40,650 --> 00:25:44,770
kind of a dull bank-shot

00:25:43,260 --> 00:25:48,850
synchronization if you want to think of

00:25:44,770 --> 00:25:50,410
it that way and then later on CPU 0 he

00:25:48,850 --> 00:25:51,650
does this big long reader up here our

00:25:50,410 --> 00:25:54,890
she read lock a bunch of stuff our

00:25:51,650 --> 00:25:57,440
to read the lock and then he blocks the

00:25:54,890 --> 00:25:59,510
same reasoning he just blocked he's not

00:25:57,440 --> 00:26:02,300
allowed to block inside Holly's to an RC

00:25:59,510 --> 00:26:06,230
reader therefore all previous our

00:26:02,300 --> 00:26:08,060
readers on CP 0 have to be done and we

00:26:06,230 --> 00:26:11,030
applied the same reason to CPU 1 right

00:26:08,060 --> 00:26:12,950
here at this point all three CPUs have

00:26:11,030 --> 00:26:14,510
blocked therefore we know all the

00:26:12,950 --> 00:26:17,480
readers in the system that were in

00:26:14,510 --> 00:26:18,460
existence before we move the cat are

00:26:17,480 --> 00:26:20,630
done

00:26:18,460 --> 00:26:23,350
the only readers left are ones that

00:26:20,630 --> 00:26:27,050
can't possibly get to the cat and

00:26:23,350 --> 00:26:33,260
therefore at this point it is safe to

00:26:27,050 --> 00:26:34,730
free the cat anyway again this is I have

00:26:33,260 --> 00:26:35,810
a guest lecture I go through this like

00:26:34,730 --> 00:26:38,810
one to two hours where I go through

00:26:35,810 --> 00:26:41,630
violently this in detail but that's the

00:26:38,810 --> 00:26:45,380
Cliff Notes version of how you can make

00:26:41,630 --> 00:26:47,180
this work I can remove data from a link

00:26:45,380 --> 00:26:48,380
structure even though the readers are

00:26:47,180 --> 00:26:50,390
plowing through that structure at all

00:26:48,380 --> 00:26:58,040
times any way they want while you're

00:26:50,390 --> 00:26:59,390
doing it all right so let's go back to

00:26:58,040 --> 00:27:00,380
the question we had earlier how the heck

00:26:59,390 --> 00:27:01,850
can you synchronize when your

00:27:00,380 --> 00:27:05,150
synchronization mechanism doesn't affect

00:27:01,850 --> 00:27:07,610
machine state and the thing is they

00:27:05,150 --> 00:27:10,840
don't have to affect machine state what

00:27:07,610 --> 00:27:14,090
the infected is dead is a developer

00:27:10,840 --> 00:27:15,800
because the developer is not allowed to

00:27:14,090 --> 00:27:17,510
block between the time they did that

00:27:15,800 --> 00:27:19,460
arse read lock ended in the Arish read

00:27:17,510 --> 00:27:20,870
unlock all right so we have

00:27:19,460 --> 00:27:25,760
synchronization affecting the developer

00:27:20,870 --> 00:27:27,680
not the system what this means are she

00:27:25,760 --> 00:27:30,160
was there for synchronization via social

00:27:27,680 --> 00:27:30,160
engineering

00:27:30,380 --> 00:27:37,440
has been for over 20 years thing is

00:27:36,210 --> 00:27:39,419
though you know every other

00:27:37,440 --> 00:27:42,710
synchronization mechanism every other

00:27:39,419 --> 00:27:44,850
one has a social engineering component

00:27:42,710 --> 00:27:46,500
you've got you've heard both fader and

00:27:44,850 --> 00:27:49,080
Michael say you know no data races don't

00:27:46,500 --> 00:27:50,549
do that well that's on the developer

00:27:49,080 --> 00:27:53,190
that's a social engineering component

00:27:50,549 --> 00:27:54,960
making this work if you're doing locking

00:27:53,190 --> 00:27:56,309
you see things like look just don't mess

00:27:54,960 --> 00:27:58,020
with this variable look at there anyway

00:27:56,309 --> 00:27:59,309
unless you're holding a lock that's the

00:27:58,020 --> 00:28:01,020
singer's date that's the social

00:27:59,309 --> 00:28:03,419
engineering part there's also a

00:28:01,020 --> 00:28:05,130
mechanical part and lock and also may

00:28:03,419 --> 00:28:08,250
Atomics for the data races and also same

00:28:05,130 --> 00:28:10,049
thing for transactional memory the weird

00:28:08,250 --> 00:28:12,210
thing about our CEO isn't that involve

00:28:10,049 --> 00:28:14,340
social engineering it's that some

00:28:12,210 --> 00:28:18,809
implementations of it only have social

00:28:14,340 --> 00:28:22,260
engineering but by doing that we can use

00:28:18,809 --> 00:28:23,700
these very very lightweight instructions

00:28:22,260 --> 00:28:25,580
in fact we're actually lock and are

00:28:23,700 --> 00:28:28,620
should unlock no instructions whatsoever

00:28:25,580 --> 00:28:32,880
in order to get real synchronization

00:28:28,620 --> 00:28:35,700
work done and of course if you're not in

00:28:32,880 --> 00:28:37,679
the kernel with a server class build

00:28:35,700 --> 00:28:39,000
then I'm sorry our seaweed lock and our

00:28:37,679 --> 00:28:41,010
CV that lock do have a little bit of

00:28:39,000 --> 00:28:42,960
code it's very local but there's some

00:28:41,010 --> 00:28:44,280
there has to do because you're in a

00:28:42,960 --> 00:28:46,799
different environment in the same four

00:28:44,280 --> 00:28:49,049
user space code although there is a

00:28:46,799 --> 00:28:51,179
variant of user space RCU that also has

00:28:49,049 --> 00:28:52,730
a zero cost are should be locking are so

00:28:51,179 --> 00:28:54,780
you'll unlock how those are interested

00:28:52,730 --> 00:28:57,260
there are some references in the back of

00:28:54,780 --> 00:28:57,260
the slide set

00:28:57,640 --> 00:29:06,200
so why are we doing this well this is a

00:29:01,780 --> 00:29:08,810
inhaling machine and we've got different

00:29:06,200 --> 00:29:10,460
operations down here on the rows compare

00:29:08,810 --> 00:29:14,470
and swap with fair exchange instructions

00:29:10,460 --> 00:29:18,110
you have locks cache misses and the top

00:29:14,470 --> 00:29:20,180
five rows there are all within the same

00:29:18,110 --> 00:29:22,400
cork different threads and same core

00:29:20,180 --> 00:29:24,950
hydrothermal system and you notice when

00:29:22,400 --> 00:29:26,000
you go off core things get expensive so

00:29:24,950 --> 00:29:27,830
we're talking almost two orders of

00:29:26,000 --> 00:29:30,830
magnitude more expensive than a clock

00:29:27,830 --> 00:29:32,270
period okay so if you just take a cache

00:29:30,830 --> 00:29:34,940
miss normal instruction takes a cache

00:29:32,270 --> 00:29:37,250
miss you're talking to almost tours you

00:29:34,940 --> 00:29:39,100
might be more expensive than a simple

00:29:37,250 --> 00:29:44,210
register register instruction

00:29:39,100 --> 00:29:47,320
communication is expensive and if you go

00:29:44,210 --> 00:29:51,470
off socket way over tourism magnitude

00:29:47,320 --> 00:29:54,500
really expensive you know it's kind of

00:29:51,470 --> 00:29:56,300
like dr. hurts when I do this don't do

00:29:54,500 --> 00:29:58,040
that that's why I wouldn't be up to the

00:29:56,300 --> 00:30:02,450
top there and that's where our Cu tries

00:29:58,040 --> 00:30:03,800
to be for the readers and the problem we

00:30:02,450 --> 00:30:06,080
have with some synchronization

00:30:03,800 --> 00:30:07,580
mechanisms there down here a lot and you

00:30:06,080 --> 00:30:10,010
do need to do updates which narrowly

00:30:07,580 --> 00:30:11,720
mean being down here but you know be

00:30:10,010 --> 00:30:13,070
careful be smart about it if you're

00:30:11,720 --> 00:30:14,330
gonna do heavy weight synchronization

00:30:13,070 --> 00:30:18,770
get your money's worth out of it that's

00:30:14,330 --> 00:30:20,030
what it comes down to so let's look at

00:30:18,770 --> 00:30:22,490
what this is the hardware structure why

00:30:20,030 --> 00:30:23,690
this would happen and so the speed of

00:30:22,490 --> 00:30:25,250
light and the atomic nature of matter

00:30:23,690 --> 00:30:26,630
that Mike will manage mentioned before

00:30:25,250 --> 00:30:29,750
yep this right here this is the diagram

00:30:26,630 --> 00:30:32,720
so speed of light goes about maybe that

00:30:29,750 --> 00:30:37,340
far and back over and back in a clock

00:30:32,720 --> 00:30:38,510
cycle for two gigahertz and that's you

00:30:37,340 --> 00:30:40,100
know it's nice you know chips are only

00:30:38,510 --> 00:30:42,130
this big right so that should be okay

00:30:40,100 --> 00:30:42,130
right

00:30:42,910 --> 00:30:48,140
well the problem is that speed of light

00:30:45,140 --> 00:30:50,690
in a vacuum how many people how many

00:30:48,140 --> 00:30:58,340
people's computers have contained vacuum

00:30:50,690 --> 00:30:59,660
tubes yeah okay no and the other thing

00:30:58,340 --> 00:31:03,200
is is that we're not talking about light

00:30:59,660 --> 00:31:04,490
we're talking electrons and the best you

00:31:03,200 --> 00:31:05,960
can say about electrons it might make

00:31:04,490 --> 00:31:09,170
thirty percent of speed of light going

00:31:05,960 --> 00:31:09,799
down a wire but you know you have to

00:31:09,170 --> 00:31:10,940
have these

00:31:09,799 --> 00:31:12,499
inconvenient things called transistors

00:31:10,940 --> 00:31:14,389
buffers caches and all this other stuff

00:31:12,499 --> 00:31:16,519
in between time those are like silicon

00:31:14,389 --> 00:31:17,539
not wires and there if you're lucky you

00:31:16,519 --> 00:31:19,850
might be doing three percent of those

00:31:17,539 --> 00:31:21,499
fetal eyes which is pretty fast you're

00:31:19,850 --> 00:31:23,980
trying to keep up with it running but

00:31:21,499 --> 00:31:27,590
but it's pretty slow for these computers

00:31:23,980 --> 00:31:28,549
and so you can see that you know it's

00:31:27,590 --> 00:31:30,169
gonna take a while for stuff to

00:31:28,549 --> 00:31:31,970
propagate back and forth to people see

00:31:30,169 --> 00:31:33,320
if you use across that thing and going

00:31:31,970 --> 00:31:34,970
back to Michael's thing what we can we

00:31:33,320 --> 00:31:36,590
can name these things right you know we

00:31:34,970 --> 00:31:40,429
can give these CPUs names you know like

00:31:36,590 --> 00:31:41,899
Carl's Tom and Fred alright and so these

00:31:40,429 --> 00:31:43,669
changes are kind of proc waiting out

00:31:41,899 --> 00:31:44,869
through the system and so Carl and Tom

00:31:43,669 --> 00:31:47,239
and Fred have a different idea of which

00:31:44,869 --> 00:31:48,950
variable they are because the changes

00:31:47,239 --> 00:31:51,259
are kind of sweeping across system in

00:31:48,950 --> 00:31:53,659
waves and yeah we can make things

00:31:51,259 --> 00:31:55,429
perfectly assessment if we didn't mind

00:31:53,659 --> 00:31:57,289
having everything be perfectly slow

00:31:55,429 --> 00:31:58,700
because we have to wait for all these

00:31:57,289 --> 00:32:00,399
stupid electrons to make it run side of

00:31:58,700 --> 00:32:05,119
the chip to the other all the time

00:32:00,399 --> 00:32:07,070
so this is why we have these weak memory

00:32:05,119 --> 00:32:09,019
operations and then remember we're

00:32:07,070 --> 00:32:10,309
consumed being my favorite example of it

00:32:09,019 --> 00:32:12,830
although not everybody's favorite

00:32:10,309 --> 00:32:16,759
apparently hopefully we're fixing that

00:32:12,830 --> 00:32:18,590
last part a little bit so just this is a

00:32:16,759 --> 00:32:21,230
hash tape or excuse me a binary search

00:32:18,590 --> 00:32:23,230
tree my percent of this last year that's

00:32:21,230 --> 00:32:25,549
the lower one Isis improved it in

00:32:23,230 --> 00:32:28,489
January 2015 got a little bit better

00:32:25,549 --> 00:32:30,950
performance out of it by doing a little

00:32:28,489 --> 00:32:32,809
bit of tuning on it so you can see what

00:32:30,950 --> 00:32:34,220
you know this is super linear don't

00:32:32,809 --> 00:32:38,570
worry about that happens sometimes 60

00:32:34,220 --> 00:32:39,950
CPUs about 90 X but we are actually

00:32:38,570 --> 00:32:42,519
getting some reasonable performance out

00:32:39,950 --> 00:32:44,869
of this thing a reasonable scalability

00:32:42,519 --> 00:32:46,580
at the same time this is a search tree

00:32:44,869 --> 00:32:48,710
that's not necessarily your best choice

00:32:46,580 --> 00:32:49,909
for a parallel algorithm I mean you have

00:32:48,710 --> 00:32:52,489
the stupid root node which is a

00:32:49,909 --> 00:32:55,759
bottleneck and that's usually a bad

00:32:52,489 --> 00:32:57,230
thing so if you're doing concurrent data

00:32:55,759 --> 00:32:59,629
structures a hash table is usually your

00:32:57,230 --> 00:33:00,980
first choice although trees can be

00:32:59,629 --> 00:33:03,289
useful used to pretty careful about how

00:33:00,980 --> 00:33:04,609
you implement them and never order

00:33:03,289 --> 00:33:06,200
consume helps because if you have

00:33:04,609 --> 00:33:07,909
everybody piling through the root node

00:33:06,200 --> 00:33:09,769
if they're doing it without touching

00:33:07,909 --> 00:33:11,029
memory they go faster if they don't

00:33:09,769 --> 00:33:12,259
actually modify the root node marry and

00:33:11,029 --> 00:33:14,149
locks on it's not your reference on it

00:33:12,259 --> 00:33:15,799
they just go flying through it they can

00:33:14,149 --> 00:33:17,389
actually go fast while they're doing

00:33:15,799 --> 00:33:19,490
that which is why we're getting that

00:33:17,389 --> 00:33:22,029
kind of speed up but a hash table would

00:33:19,490 --> 00:33:23,630
be about three at three times faster

00:33:22,029 --> 00:33:26,840
okay

00:33:23,630 --> 00:33:28,610
just depends what you're doing updates

00:33:26,840 --> 00:33:30,710
slow things out a little bit and

00:33:28,610 --> 00:33:33,440
actually 3% of the operation or full

00:33:30,710 --> 00:33:35,720
tree scans which really slows it up but

00:33:33,440 --> 00:33:39,260
as you can see we get reasonably good

00:33:35,720 --> 00:33:45,260
speed-up as we add CPUs not perfect but

00:33:39,260 --> 00:33:46,700
reasonably good this is a very toy in

00:33:45,260 --> 00:33:48,980
our Satine home rotation but with full

00:33:46,700 --> 00:33:51,830
speed readers it's about 20 lines of

00:33:48,980 --> 00:33:55,970
code five of which might turn into

00:33:51,830 --> 00:33:58,160
memory or kusuma someday and people

00:33:55,970 --> 00:34:03,920
still insist that our C was complicated

00:33:58,160 --> 00:34:05,270
not sure why this is the hash table

00:34:03,920 --> 00:34:06,860
again showing a number of different

00:34:05,270 --> 00:34:08,360
things are Cu hazard pointers are almost

00:34:06,860 --> 00:34:10,070
as fast they have some other things

00:34:08,360 --> 00:34:11,750
bucket locking does pretty well until

00:34:10,070 --> 00:34:13,669
you get off socket and then it falls off

00:34:11,750 --> 00:34:17,270
a cliff global locking we expect to be

00:34:13,669 --> 00:34:19,639
bad it is but hazard fighters and RCS do

00:34:17,270 --> 00:34:21,669
quite well in this environment and are

00:34:19,639 --> 00:34:26,870
see you again likes memory order consume

00:34:21,669 --> 00:34:28,280
now this speed comes at a price and this

00:34:26,870 --> 00:34:31,040
comes back to the Iron Triangle that

00:34:28,280 --> 00:34:33,350
Michael talked about earlier what we're

00:34:31,040 --> 00:34:35,570
doing here is we're getting reasonable

00:34:33,350 --> 00:34:36,860
productivity in the Linux kernel people

00:34:35,570 --> 00:34:38,929
were used to RC you use it quite well

00:34:36,860 --> 00:34:40,970
and quite quickly we have really good

00:34:38,929 --> 00:34:44,240
performance as you saw we give up

00:34:40,970 --> 00:34:46,100
generality if you're doing something

00:34:44,240 --> 00:34:47,300
where it's read mostly and you can put

00:34:46,100 --> 00:34:48,710
up with the fact different readers at

00:34:47,300 --> 00:34:49,700
the same time might have different ideas

00:34:48,710 --> 00:34:51,860
of what what's in the data structure

00:34:49,700 --> 00:34:54,500
which is okay surprisingly often strange

00:34:51,860 --> 00:34:56,870
though maybe our Steve works really

00:34:54,500 --> 00:34:59,000
really well that's just great if you

00:34:56,870 --> 00:35:01,280
need consistency it requires a little

00:34:59,000 --> 00:35:02,720
more mechanism you have to add low-level

00:35:01,280 --> 00:35:03,950
locks in various places but it still

00:35:02,720 --> 00:35:06,230
works pretty well and that is using

00:35:03,950 --> 00:35:08,090
lanes kernel if you're starting to write

00:35:06,230 --> 00:35:09,800
a lot well there are parts of Linux

00:35:08,090 --> 00:35:11,060
kernel is still good speed ups that way

00:35:09,800 --> 00:35:13,520
but they're more complicated they're

00:35:11,060 --> 00:35:15,140
harder and they don't get quite as good

00:35:13,520 --> 00:35:17,140
as speed ups as you do if you're using

00:35:15,140 --> 00:35:19,400
RSU for exactly what it's intended for

00:35:17,140 --> 00:35:22,030
if you're mostly doing updates you

00:35:19,400 --> 00:35:24,470
probably want to use something else

00:35:22,030 --> 00:35:25,730
there are a couple exceptions one of

00:35:24,470 --> 00:35:28,250
them is we're using our CEO as a

00:35:25,730 --> 00:35:29,750
poor-man's garbage collector and the

00:35:28,250 --> 00:35:31,220
other one is if you have real time

00:35:29,750 --> 00:35:32,270
constraints on the readers even though

00:35:31,220 --> 00:35:33,290
they don't happen very often they need

00:35:32,270 --> 00:35:35,480
to happen really fast

00:35:33,290 --> 00:35:36,420
in that case our so you still might be

00:35:35,480 --> 00:35:38,549
useful and not

00:35:36,420 --> 00:35:39,809
mostly thing but again if you're mostly

00:35:38,549 --> 00:35:42,690
doing updates you probably did something

00:35:39,809 --> 00:35:43,950
else so on the iron triangle we're

00:35:42,690 --> 00:35:45,329
getting the performance we're getting

00:35:43,950 --> 00:35:51,059
the productivity we're giving up

00:35:45,329 --> 00:35:53,849
generality it's used a fair amount Linux

00:35:51,059 --> 00:35:55,670
kernel back in 2002 late 2002 and it

00:35:53,849 --> 00:35:57,930
first went in I was hoping that someday

00:35:55,670 --> 00:35:59,819
Marcy would be a successful minister

00:35:57,930 --> 00:36:02,190
kn'l as it wasn't dining speedy X in the

00:35:59,819 --> 00:36:05,280
90s before that in other words it might

00:36:02,190 --> 00:36:06,990
have a hundred uses eventually as you

00:36:05,280 --> 00:36:09,859
can see I was somewhat pessimistic we

00:36:06,990 --> 00:36:12,240
passed through 10,000 earlier this year

00:36:09,859 --> 00:36:13,710
this by the way is not my work this is

00:36:12,240 --> 00:36:15,329
the community's work this is showing the

00:36:13,710 --> 00:36:18,180
power of a community that knows how to

00:36:15,329 --> 00:36:19,290
make things happen and I'm proud and

00:36:18,180 --> 00:36:20,630
humbled to be associate with Linux

00:36:19,290 --> 00:36:22,260
kernel community they do amazing things

00:36:20,630 --> 00:36:23,520
not perfect

00:36:22,260 --> 00:36:30,869
while you guys probably know that better

00:36:23,520 --> 00:36:32,450
than I do but this is their work so why

00:36:30,869 --> 00:36:35,040
we want to use our see how is it helping

00:36:32,450 --> 00:36:37,200
we get fastest scalable readers is a big

00:36:35,040 --> 00:36:39,180
thing free is a very good price of

00:36:37,200 --> 00:36:42,710
something identify with pretty heavily

00:36:39,180 --> 00:36:44,790
and nothing is faster doing nothing and

00:36:42,710 --> 00:36:46,470
we've had a number of cases we've got

00:36:44,790 --> 00:36:49,049
orders of magnitude speed up by applying

00:36:46,470 --> 00:36:52,200
our CEO in real code in the kernel and

00:36:49,049 --> 00:36:54,839
elsewhere it also avoids many forms of

00:36:52,200 --> 00:36:57,390
deadlock the first ever use of we didn't

00:36:54,839 --> 00:36:59,130
call Garcia back then back in Dennis PTX

00:36:57,390 --> 00:37:02,910
was mostly about software engineering

00:36:59,130 --> 00:37:04,920
not about speed applying RCU in a

00:37:02,910 --> 00:37:08,190
distributed lock manager allowed my

00:37:04,920 --> 00:37:10,799
co-inventor of RC you to throw 16,000

00:37:08,190 --> 00:37:14,280
lines a really horrible grotesque

00:37:10,799 --> 00:37:18,569
parallel code on the floor along with

00:37:14,280 --> 00:37:20,640
all the bugs it had so the thing is the

00:37:18,569 --> 00:37:23,760
readers don't win anybody so they can't

00:37:20,640 --> 00:37:26,490
deadlock and that's actually kind of

00:37:23,760 --> 00:37:27,720
useful also none of those none of those

00:37:26,490 --> 00:37:29,760
api is retry

00:37:27,720 --> 00:37:31,020
you see ours to read lock your there you

00:37:29,760 --> 00:37:32,250
say synchronize are actually you wait

00:37:31,020 --> 00:37:35,220
you come back there's none of this oh

00:37:32,250 --> 00:37:37,290
sorry try me again later stuff and that

00:37:35,220 --> 00:37:38,910
means we aren't as prone to live locks

00:37:37,290 --> 00:37:42,990
as other synchronization primitives

00:37:38,910 --> 00:37:46,349
might be and these are also well suited

00:37:42,990 --> 00:37:48,680
real-time programming it also eliminates

00:37:46,349 --> 00:37:50,660
the ABA storage Ria's problem

00:37:48,680 --> 00:37:53,030
and this is part of acting like a poor

00:37:50,660 --> 00:37:55,700
man's a garbage collector that's a topic

00:37:53,030 --> 00:37:57,440
that could take a talk in itself and the

00:37:55,700 --> 00:37:59,750
nice thing is it also plays really well

00:37:57,440 --> 00:38:01,640
with other synchronization primitives if

00:37:59,750 --> 00:38:03,160
you want to you can be in a are series

00:38:01,640 --> 00:38:05,690
that critical section and acquire a lock

00:38:03,160 --> 00:38:08,089
or you couldn't atomically incrementing

00:38:05,690 --> 00:38:09,650
or you do a compare and swap it's

00:38:08,089 --> 00:38:11,480
compatible with them and you can use it

00:38:09,650 --> 00:38:13,790
the use of combinations of the different

00:38:11,480 --> 00:38:16,010
primitives in order to get something

00:38:13,790 --> 00:38:17,930
works well across the range of read

00:38:16,010 --> 00:38:21,170
mostly to update mostly and there's a

00:38:17,930 --> 00:38:22,670
number the pathname translation and the

00:38:21,170 --> 00:38:25,960
linux kernel is probably most impressive

00:38:22,670 --> 00:38:27,920
in many ways example of having multiple

00:38:25,960 --> 00:38:33,740
synchronization primitives including RC

00:38:27,920 --> 00:38:35,119
working together nicely okay so I'm not

00:38:33,740 --> 00:38:38,089
going to go through the readers too much

00:38:35,119 --> 00:38:41,329
you you it's what you'd expect if you

00:38:38,089 --> 00:38:43,040
saw it there the key point here is that

00:38:41,329 --> 00:38:45,170
you can have this do something with

00:38:43,040 --> 00:38:48,619
function and the dependency chain goes

00:38:45,170 --> 00:38:50,150
into it so we picked up our seed

00:38:48,619 --> 00:38:52,520
reference which is a memory or a consume

00:38:50,150 --> 00:38:53,930
thing we put in pointer P and we pass

00:38:52,520 --> 00:38:55,460
that pointer into this other function

00:38:53,930 --> 00:38:57,260
and the programmers going to kind of

00:38:55,460 --> 00:39:00,109
expect that the dependency chain goes

00:38:57,260 --> 00:39:01,730
into that function with it and he also

00:39:00,109 --> 00:39:03,020
expects that if we call that function

00:39:01,730 --> 00:39:05,059
multiple times in multiple different

00:39:03,020 --> 00:39:06,290
read side critical sections all the

00:39:05,059 --> 00:39:08,000
defensive chains go in all the various

00:39:06,290 --> 00:39:11,540
places and go into that function where

00:39:08,000 --> 00:39:13,130
they need to so there's kind of fan in

00:39:11,540 --> 00:39:16,190
it also needs a cross compilation unit

00:39:13,130 --> 00:39:17,660
boundaries and we also have fan-out

00:39:16,190 --> 00:39:19,250
there's no more places where there's

00:39:17,660 --> 00:39:20,809
some function that's called that does an

00:39:19,250 --> 00:39:22,549
RC do reference among other things this

00:39:20,809 --> 00:39:25,190
is kind of a why you would do that but

00:39:22,549 --> 00:39:26,569
this is a toy example showing that you

00:39:25,190 --> 00:39:29,710
call some function it does an RCD

00:39:26,569 --> 00:39:31,579
reference hand you back the pointer the

00:39:29,710 --> 00:39:34,010
dependency chain needs to come out

00:39:31,579 --> 00:39:35,510
through the return of that function for

00:39:34,010 --> 00:39:41,540
this to work and does in the linux

00:39:35,510 --> 00:39:43,549
kernel for updaters we wait for grace

00:39:41,540 --> 00:39:46,010
period like you would expect looking at

00:39:43,549 --> 00:39:46,930
that second diagram we showed with a red

00:39:46,010 --> 00:39:49,640
yellow and green

00:39:46,930 --> 00:39:52,040
so we acquire a lock we pick up the old

00:39:49,640 --> 00:39:54,170
pointer we assign the new pointer to it

00:39:52,040 --> 00:39:56,869
which we presumably allocated and filled

00:39:54,170 --> 00:39:58,309
in before this we release the lock we do

00:39:56,869 --> 00:40:00,020
a synchronized RSU to wait for all the

00:39:58,309 --> 00:40:00,869
old readers once all the old readers are

00:40:00,020 --> 00:40:03,240
done

00:40:00,869 --> 00:40:08,549
we can just pay for either thing because

00:40:03,240 --> 00:40:11,579
nobody's looking at it anymore I'll talk

00:40:08,549 --> 00:40:13,559
a little bit colder pendency I mentioned

00:40:11,579 --> 00:40:15,779
before that RCU plays nicely with other

00:40:13,559 --> 00:40:17,970
synchronization mechanisms and so what

00:40:15,779 --> 00:40:19,740
often times you'll do is in this case we

00:40:17,970 --> 00:40:21,809
go to our see read lock we pick up a

00:40:19,740 --> 00:40:22,950
pointer and then we see we're gonna have

00:40:21,809 --> 00:40:25,259
to hold on to this pointer for a very

00:40:22,950 --> 00:40:27,210
long time maybe we're in the networking

00:40:25,259 --> 00:40:28,230
stack we say oops we got a like send

00:40:27,210 --> 00:40:30,089
something over to some of the machine

00:40:28,230 --> 00:40:31,289
and wait for the response and we don't

00:40:30,089 --> 00:40:33,690
want to have a reset critical section

00:40:31,289 --> 00:40:36,210
going over that whole thing so what we

00:40:33,690 --> 00:40:38,789
do is if that happens we increment a

00:40:36,210 --> 00:40:39,930
reference count and at that point - we

00:40:38,789 --> 00:40:42,410
don't do this Linux kernel at this

00:40:39,930 --> 00:40:45,630
moment but we might do a kill dependency

00:40:42,410 --> 00:40:46,680
in order to flag the fact that there are

00:40:45,630 --> 00:40:47,940
no dependencies going through that

00:40:46,680 --> 00:40:51,029
variable anymore we don't need them

00:40:47,940 --> 00:40:53,430
we've got the reference count okay and

00:40:51,029 --> 00:40:57,109
so that's a to kill dependencies a way

00:40:53,430 --> 00:40:57,109
of indicating that we've handed off from

00:40:57,380 --> 00:41:06,509
I'm sorry oh okay I'm sorry okay great

00:41:03,269 --> 00:41:08,579
so I'm sorry I thought an hour I

00:41:06,509 --> 00:41:10,890
obviously I was confused this is the

00:41:08,579 --> 00:41:12,180
current standard I've learned things

00:41:10,890 --> 00:41:14,220
about people hating dependency chains

00:41:12,180 --> 00:41:19,470
I'm gonna do is I'm gonna go through and

00:41:14,220 --> 00:41:23,130
show the resolutions always make sure

00:41:19,470 --> 00:41:25,710
you know how much time you have yes and

00:41:23,130 --> 00:41:27,539
we have what we're suggesting is ways of

00:41:25,710 --> 00:41:30,450
doing without annotations that basically

00:41:27,539 --> 00:41:33,359
restrict the user to what the compilers

00:41:30,450 --> 00:41:35,940
normally do and that means you don't do

00:41:33,359 --> 00:41:37,230
things like white cancel out the

00:41:35,940 --> 00:41:39,299
pointers subtract a pointer for herself

00:41:37,230 --> 00:41:41,700
end up with zero because the pilot will

00:41:39,299 --> 00:41:43,019
just say hey here's a zero and break

00:41:41,700 --> 00:41:44,519
your dependency for you so you rely on

00:41:43,019 --> 00:41:49,230
the fact that happens and allow for that

00:41:44,519 --> 00:41:50,789
to happen and then that's something is

00:41:49,230 --> 00:41:53,249
useful for something like a Linux kernel

00:41:50,789 --> 00:41:54,839
it may not be nice longer term because

00:41:53,249 --> 00:41:56,789
it requires a developer to be keeping

00:41:54,839 --> 00:42:00,029
track what the compiler is doing it's a

00:41:56,789 --> 00:42:02,249
longer term I'm thinking in terms of a

00:42:00,029 --> 00:42:03,829
storage class type of a thing I've had a

00:42:02,249 --> 00:42:05,519
couple of people say they like it

00:42:03,829 --> 00:42:08,940
unfortunately those people were people

00:42:05,519 --> 00:42:11,160
involved original proposal so who knows

00:42:08,940 --> 00:42:13,619
but the idea is to mark the variables

00:42:11,160 --> 00:42:14,710
the carry dependencies so the compiler

00:42:13,619 --> 00:42:16,150
knows oh this variable

00:42:14,710 --> 00:42:19,510
and see therefore I have to be careful

00:42:16,150 --> 00:42:20,950
and it also documents for the developer

00:42:19,510 --> 00:42:22,390
saying oh yeah okay here's old

00:42:20,950 --> 00:42:24,630
appendices here they go in hard they

00:42:22,390 --> 00:42:27,760
come out and everything's nice

00:42:24,630 --> 00:42:28,990
that's the interactions we don't have

00:42:27,760 --> 00:42:31,000
time for double-checked lock but they'll

00:42:28,990 --> 00:42:35,349
be there maybe we have a P and I don't

00:42:31,000 --> 00:42:37,210
know but my hope is we can use the

00:42:35,349 --> 00:42:38,920
restricted dependency change essentially

00:42:37,210 --> 00:42:40,690
documenting what optimization compiler

00:42:38,920 --> 00:42:42,880
use for kernel code and other

00:42:40,690 --> 00:42:44,619
pre-existing large code bases and use a

00:42:42,880 --> 00:42:46,450
storage class for new projects and

00:42:44,619 --> 00:42:48,400
possibly also migrate the old projects

00:42:46,450 --> 00:42:55,599
to it anyway I apologize for running

00:42:48,400 --> 00:43:00,540
over sure okay all right and apologies

00:42:55,599 --> 00:43:00,540

YouTube URL: https://www.youtube.com/watch?v=ZrNQKpOypqU


