Title: CppCon 2019: Matt Kulukundis “Abseil's Open Source Hashtables: 2 Years In”
Publication date: 2019-09-27
Playlist: CppCon 2019
Description: 
	http://CppCon.org
—
Discussion & Comments: https://www.reddit.com/r/cpp/
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/CppCon/CppCon2019
—
Two years ago we announced a new hashtable we were pushing out across Google. One year ago, we open sourced it as part of Abseil. This talk is a retrospective about those efforts. We will cover:

- optimizations after the initial release
- lessons from rollout across google
- design choices that paid dividends
- global monitoring of hashtables
- discoveries made from monitoring
— 
Matt Kulukundis
Staff Software Engineer, Google
Matt is a senior software engineer on the C++ libraries team at Google.  Prior to Google he has worked on compilers, machine learning, and underwater robotics.  In his free time, he scuba dives in warm places.
—
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:08,750 --> 00:00:15,540
all right hello everyone I'm Matt Kula

00:00:11,760 --> 00:00:18,750
Kondos this is my second major talk at

00:00:15,540 --> 00:00:21,630
cpp con and two years ago I presented

00:00:18,750 --> 00:00:24,630
about the opens for the hash table that

00:00:21,630 --> 00:00:26,340
is now open sourced but before I begin I

00:00:24,630 --> 00:00:29,520
want to really clearly state this is the

00:00:26,340 --> 00:00:31,440
work of many people many of the people

00:00:29,520 --> 00:00:33,570
on the slides did the initial work many

00:00:31,440 --> 00:00:35,190
did the open sourcing work primarily

00:00:33,570 --> 00:00:37,410
schandle actually did the open sourcing

00:00:35,190 --> 00:00:39,420
work the slides I'm about to present are

00:00:37,410 --> 00:00:41,489
very heavily the work of Sam Benz akin

00:00:39,420 --> 00:00:45,840
who has done a lot of the optimizations

00:00:41,489 --> 00:00:50,570
in here but by no way am I the primary

00:00:45,840 --> 00:00:54,000
or even the major effort in any of this

00:00:50,570 --> 00:00:55,530
so I'm gonna start giving you a little

00:00:54,000 --> 00:00:58,290
overview of where we're going because

00:00:55,530 --> 00:01:00,559
this talk jumps in pretty fast I marked

00:00:58,290 --> 00:01:02,820
it in on the menu as

00:01:00,559 --> 00:01:05,489
intermediate-advanced but that's in the

00:01:02,820 --> 00:01:07,860
new zealand hiking leveling system not

00:01:05,489 --> 00:01:10,500
in the american hiking leveling system

00:01:07,860 --> 00:01:13,140
so we're going to explore a few internet

00:01:10,500 --> 00:01:15,869
interconnected big questions around our

00:01:13,140 --> 00:01:17,970
hash tables what have we learned while

00:01:15,869 --> 00:01:21,690
deploying them across Google can we

00:01:17,970 --> 00:01:23,580
improve them for CPU efficiency can we

00:01:21,690 --> 00:01:26,700
approve can we improve their memory for

00:01:23,580 --> 00:01:30,179
small tables and can we automatically

00:01:26,700 --> 00:01:33,569
identify tables that are misbehaving at

00:01:30,179 --> 00:01:35,640
scale in a way that's useful so that's

00:01:33,569 --> 00:01:38,550
sort of roughly where we're going but

00:01:35,640 --> 00:01:41,849
I'm gonna start with background there's

00:01:38,550 --> 00:01:45,000
a huge chunk to understand here and I'm

00:01:41,849 --> 00:01:47,729
gonna blitz through what was my 2017 CPP

00:01:45,000 --> 00:01:50,880
con talk without any of the motivation

00:01:47,729 --> 00:01:53,940
I'm just going to explain to you what if

00:01:50,880 --> 00:01:58,670
you want to understand the why go back

00:01:53,940 --> 00:02:01,319
to my 2017 talk it's reasonable I hope

00:01:58,670 --> 00:02:03,450
I'm also going to ask folks hold your

00:02:01,319 --> 00:02:05,429
questions until the end unless it's a

00:02:03,450 --> 00:02:07,380
really quick clarification that you

00:02:05,429 --> 00:02:12,900
believe I can answer in one or two

00:02:07,380 --> 00:02:15,090
sentences so there you have it let's

00:02:12,900 --> 00:02:16,349
start with a bit of terminology the main

00:02:15,090 --> 00:02:19,560
container I'm going to be talking about

00:02:16,349 --> 00:02:22,319
is flat hash set this is sort of like a

00:02:19,560 --> 00:02:23,819
stood unordered map in API except

00:02:22,319 --> 00:02:25,799
that it's more like a vector than a

00:02:23,819 --> 00:02:27,359
linked list it doesn't offer pointer

00:02:25,799 --> 00:02:29,780
stability it keeps the values directly

00:02:27,359 --> 00:02:33,090
in memory and it moves them on rehashes

00:02:29,780 --> 00:02:35,670
it has a metadata array which stores

00:02:33,090 --> 00:02:37,500
metadata obviously about the things and

00:02:35,670 --> 00:02:40,680
it has the slot array where the actual

00:02:37,500 --> 00:02:42,540
values are stored logically these are

00:02:40,680 --> 00:02:44,310
two separate arrays internally in the

00:02:42,540 --> 00:02:46,590
implementation they're just one thing

00:02:44,310 --> 00:02:49,920
because nobody wants to allocate twice

00:02:46,590 --> 00:02:51,750
so when I refer to position 3 I'm often

00:02:49,920 --> 00:02:54,060
referring to both the control byte in

00:02:51,750 --> 00:02:57,030
the metadata ray and the slot in which

00:02:54,060 --> 00:02:59,959
the value at that position is stored so

00:02:57,030 --> 00:03:03,450
now if we take 16 positions together

00:02:59,959 --> 00:03:05,849
that forms a group and you'll see why

00:03:03,450 --> 00:03:12,019
this 16 is important as I expand on it

00:03:05,849 --> 00:03:12,019
the table itself just contains n groups

00:03:13,609 --> 00:03:18,269
when we look when we take our hash code

00:03:16,079 --> 00:03:20,129
ordinarily you start with 64-bit hash

00:03:18,269 --> 00:03:24,060
code we divide it into two parts

00:03:20,129 --> 00:03:26,129
h1 which is the 57 high bits not that we

00:03:24,060 --> 00:03:29,459
guarantee we will continue to use the 57

00:03:26,129 --> 00:03:33,930
High bits but it is right now and these

00:03:29,459 --> 00:03:35,549
7 low bits which is h2 h1 is what you

00:03:33,930 --> 00:03:37,409
take the modulus of it's your

00:03:35,549 --> 00:03:39,209
traditional like I'm gonna mod by my

00:03:37,409 --> 00:03:42,959
table size in order to find my spot in

00:03:39,209 --> 00:03:45,299
the hash table the 7 bits in h2 go into

00:03:42,959 --> 00:03:50,430
the control byte in the metadata we need

00:03:45,299 --> 00:03:54,780
the extra bit to be even more meta this

00:03:50,430 --> 00:03:56,879
is the core insight that made this makes

00:03:54,780 --> 00:04:00,599
swiss table fast this is a little bit of

00:03:56,879 --> 00:04:02,310
code that uses SSE talking with Chandler

00:04:00,599 --> 00:04:08,189
last night I actually learned that it

00:04:02,310 --> 00:04:11,040
uses ssse3 but that's a streaming sim D

00:04:08,189 --> 00:04:14,849
extension it's a it is an instruction

00:04:11,040 --> 00:04:19,799
that basically all CPUs have that allows

00:04:14,849 --> 00:04:28,199
you to do a 16 wide probe sorry 128 byte

00:04:19,799 --> 00:04:29,880
probe all at once so right I'm gonna

00:04:28,199 --> 00:04:31,800
break this apart into smaller parts

00:04:29,880 --> 00:04:35,220
because I don't actually speak assembly

00:04:31,800 --> 00:04:36,900
and most people shouldn't

00:04:35,220 --> 00:04:38,880
this is what it's doing sort of in

00:04:36,900 --> 00:04:42,060
pictures you give it a one byte thing

00:04:38,880 --> 00:04:44,670
and say okay here's a sixteen here's an

00:04:42,060 --> 00:04:46,080
array of 16 bytes give me ones where

00:04:44,670 --> 00:04:48,360
they match and zeros where they don't

00:04:46,080 --> 00:04:49,790
match it's pretty easy let me break it

00:04:48,360 --> 00:04:53,490
step by step

00:04:49,790 --> 00:04:57,990
this instruction just splats out one

00:04:53,490 --> 00:04:59,850
byte sixteen times this instruction

00:04:57,990 --> 00:05:02,370
takes two sixteen byte vectors and

00:04:59,850 --> 00:05:05,760
outputs the mask zeros where they're not

00:05:02,370 --> 00:05:08,190
match ones where they match this

00:05:05,760 --> 00:05:12,300
instruction collapses that back down

00:05:08,190 --> 00:05:16,530
into a not specialized giant thing just

00:05:12,300 --> 00:05:18,090
a single thing that you can scan so you

00:05:16,530 --> 00:05:19,920
put all three of those together and you

00:05:18,090 --> 00:05:21,360
get the thing you want a bit mask that

00:05:19,920 --> 00:05:23,550
says what are your potential matches

00:05:21,360 --> 00:05:25,400
it's a little bit like a bloom filter in

00:05:23,550 --> 00:05:31,380
that regard it can have false positives

00:05:25,400 --> 00:05:33,420
but so we've wrapped that up that looks

00:05:31,380 --> 00:05:36,240
like how we use it and now I'm gonna

00:05:33,420 --> 00:05:38,760
walk us through what is the core loop of

00:05:36,240 --> 00:05:40,980
Swiss table how does it actually do

00:05:38,760 --> 00:05:43,290
anything I'm not going to cover anything

00:05:40,980 --> 00:05:46,020
other than find in any of these slides

00:05:43,290 --> 00:05:47,910
because everything starts with find find

00:05:46,020 --> 00:05:49,320
is just like the only thing you have you

00:05:47,910 --> 00:05:50,910
want to insert an element first you find

00:05:49,320 --> 00:05:52,440
where it goes you want to erase an

00:05:50,910 --> 00:05:54,240
element first you find it you want to

00:05:52,440 --> 00:05:54,960
replace an element well then you find it

00:05:54,240 --> 00:05:59,220
and put it there

00:05:54,960 --> 00:06:01,290
everything is fine so the first thing

00:05:59,220 --> 00:06:05,490
you do is you figure out what group

00:06:01,290 --> 00:06:08,400
you're in so you take the h1 hash mod by

00:06:05,490 --> 00:06:10,470
number groups then because I watched out

00:06:08,400 --> 00:06:12,120
Alexander asked who's talked it's an

00:06:10,470 --> 00:06:18,390
infinite loop everything's an infinite

00:06:12,120 --> 00:06:20,910
loop I so from the group you're gonna

00:06:18,390 --> 00:06:23,430
just advance through the groups one at a

00:06:20,910 --> 00:06:25,650
time as you're trying to find groups

00:06:23,430 --> 00:06:28,140
that have matches here's where the

00:06:25,650 --> 00:06:30,960
smarts come in that h2 and this match

00:06:28,140 --> 00:06:33,419
from what you saw earlier is saying ok

00:06:30,960 --> 00:06:36,350
in this group these are the indices that

00:06:33,419 --> 00:06:39,690
are potential candidate matches for us

00:06:36,350 --> 00:06:43,470
if it's a candidate match then we

00:06:39,690 --> 00:06:45,030
actually need to run EQ right in your

00:06:43,470 --> 00:06:47,430
actual intern actual hash table you're

00:06:45,030 --> 00:06:48,960
running the Equality funked or I should

00:06:47,430 --> 00:06:51,690
tell you all of these slide

00:06:48,960 --> 00:06:54,479
are kind of 80% true because going for a

00:06:51,690 --> 00:06:55,919
hundred percent true actually really

00:06:54,479 --> 00:06:59,250
really impedes understanding of

00:06:55,919 --> 00:07:02,580
something this complicated so here we're

00:06:59,250 --> 00:07:04,349
just using EQ it's slide where and you

00:07:02,580 --> 00:07:06,479
keep advancing groups over and over

00:07:04,349 --> 00:07:07,500
forever and ever and you never stop well

00:07:06,479 --> 00:07:10,380
okay

00:07:07,500 --> 00:07:12,660
sometimes you have to decide nope I

00:07:10,380 --> 00:07:16,199
didn't find it it's empty and here we

00:07:12,660 --> 00:07:21,389
make use of one key fact the table will

00:07:16,199 --> 00:07:24,860
contain at least one empty element we

00:07:21,389 --> 00:07:24,860
never get to a hundred percent capacity

00:07:26,090 --> 00:07:32,280
so these are the two parts where we use

00:07:29,880 --> 00:07:34,440
the hash code logically speaking right

00:07:32,280 --> 00:07:36,509
the h1 hash mod the num groups is

00:07:34,440 --> 00:07:39,090
encoding information about the hash code

00:07:36,509 --> 00:07:41,039
of the object and then the h2 code is

00:07:39,090 --> 00:07:43,860
giving us a little bit more information

00:07:41,039 --> 00:07:46,470
and it is only when both the h1 and h2

00:07:43,860 --> 00:07:48,150
bits match or really the portion of the

00:07:46,470 --> 00:07:51,120
h1 bits we're currently looking at based

00:07:48,150 --> 00:07:52,740
on our modulus and the h2 that we

00:07:51,120 --> 00:07:55,320
actually call the more expensive

00:07:52,740 --> 00:07:57,960
EQ function so this lets you do most of

00:07:55,320 --> 00:07:59,789
your work just burning through one byte

00:07:57,960 --> 00:08:04,110
at a time on those instructions it's

00:07:59,789 --> 00:08:06,150
very dense in l1 cache because the

00:08:04,110 --> 00:08:08,610
metadata array is where all of the

00:08:06,150 --> 00:08:10,440
action and this happens I'm just gonna

00:08:08,610 --> 00:08:12,449
drop the slot array from these slides

00:08:10,440 --> 00:08:14,639
you can just pretend it's there it works

00:08:12,449 --> 00:08:17,550
well enough I'm also going to include

00:08:14,639 --> 00:08:20,030
more groups in these diagrams because

00:08:17,550 --> 00:08:22,440
I'm gonna need more groups later I

00:08:20,030 --> 00:08:26,099
believe it earlier there's a special

00:08:22,440 --> 00:08:28,320
stop marker it's the last last entry

00:08:26,099 --> 00:08:29,699
gets a slot a stop marker and the entire

00:08:28,320 --> 00:08:32,310
purpose of that is if you're just

00:08:29,699 --> 00:08:37,829
scanning across like an iterator it

00:08:32,310 --> 00:08:41,339
tells you when you've reached the end so

00:08:37,829 --> 00:08:42,990
I'm gonna as a slide shift I'm gonna

00:08:41,339 --> 00:08:46,520
start talking about the rollout across

00:08:42,990 --> 00:08:49,709
Google this is a rollout across Google

00:08:46,520 --> 00:08:52,920
by spelling count spelling count is a

00:08:49,709 --> 00:08:55,800
sort of weird thing to use but as a code

00:08:52,920 --> 00:08:58,500
janitor whose job is to get spelling

00:08:55,800 --> 00:09:02,320
counts of things I don't like to zero it

00:08:58,500 --> 00:09:03,640
actually tells me when I'm done in the

00:09:02,320 --> 00:09:06,880
Graff you'll notice that I have both the

00:09:03,640 --> 00:09:08,020
flat hashmap and said which flat is what

00:09:06,880 --> 00:09:11,680
I've been talking about I also have note

00:09:08,020 --> 00:09:13,990
hash map and set node is like flat hash

00:09:11,680 --> 00:09:16,150
map but if you imagine flat hash map as

00:09:13,990 --> 00:09:18,850
a vector node as a vector of unique

00:09:16,150 --> 00:09:21,400
pointers it gives you pointer stability

00:09:18,850 --> 00:09:24,070
which means it's much easier to convert

00:09:21,400 --> 00:09:27,280
legacy structures like gene you see xx

00:09:24,070 --> 00:09:29,800
hash map or stood unordered map over to

00:09:27,280 --> 00:09:32,260
a node hash map because you maintain

00:09:29,800 --> 00:09:35,980
pointer stability and pointer stability

00:09:32,260 --> 00:09:37,900
is a very difficult property to figure

00:09:35,980 --> 00:09:39,520
out statically it's hard to look at code

00:09:37,900 --> 00:09:42,070
and say oh yeah this code doesn't need

00:09:39,520 --> 00:09:43,810
pointer stability or this code does it's

00:09:42,070 --> 00:09:45,730
called escape analysis compiler

00:09:43,810 --> 00:09:48,430
optimizers hate it when you force them

00:09:45,730 --> 00:09:53,230
to use escape analysis fun trick though

00:09:48,430 --> 00:09:56,740
you'd really bother them so this sort of

00:09:53,230 --> 00:09:59,380
shows what you're doing and but it

00:09:56,740 --> 00:10:01,570
doesn't quite give you the sense of how

00:09:59,380 --> 00:10:03,340
much of this is code changes from our

00:10:01,570 --> 00:10:04,750
large-scale changes migrating people

00:10:03,340 --> 00:10:07,150
from the blue and the red to the yellow

00:10:04,750 --> 00:10:09,490
and how much of this is people on their

00:10:07,150 --> 00:10:11,890
own writing the green or the others or

00:10:09,490 --> 00:10:14,920
how much of this is people migrating the

00:10:11,890 --> 00:10:19,000
yellow to the green this is by spelling

00:10:14,920 --> 00:10:21,550
count we're no longer going to 100% this

00:10:19,000 --> 00:10:23,560
is just total counts and so what you can

00:10:21,550 --> 00:10:25,450
see early in the process when we were

00:10:23,560 --> 00:10:27,400
really pushing on the large-scale

00:10:25,450 --> 00:10:30,400
changes to roll this out we made a lot

00:10:27,400 --> 00:10:32,860
of really fast progress if you recall

00:10:30,400 --> 00:10:34,000
Titus's talk from earlier today or if

00:10:32,860 --> 00:10:36,150
you're watching this on youtube I'll

00:10:34,000 --> 00:10:41,160
wait for you to go watch Titus's talk

00:10:36,150 --> 00:10:43,990
great talk wasn't it if you recall

00:10:41,160 --> 00:10:47,290
changing types that cross API boundaries

00:10:43,990 --> 00:10:48,730
is a really hard problem and we kind of

00:10:47,290 --> 00:10:50,860
just punted on it

00:10:48,730 --> 00:10:52,660
we just throw changes at the wall and if

00:10:50,860 --> 00:10:55,510
they compile we ship them and if they

00:10:52,660 --> 00:10:58,810
don't compile we bury them out back and

00:10:55,510 --> 00:11:02,020
it got us to 70% it's a surprisingly

00:10:58,810 --> 00:11:03,790
effective strategy we've hit diminishing

00:11:02,020 --> 00:11:08,170
returns there we're probably not going

00:11:03,790 --> 00:11:10,450
to get past 70% or much past it but you

00:11:08,170 --> 00:11:12,970
can see that Green Line is growing

00:11:10,450 --> 00:11:14,590
tremendously and one of the reasons for

00:11:12,970 --> 00:11:16,150
that is training and education we've

00:11:14,590 --> 00:11:19,240
told people that's the one they should

00:11:16,150 --> 00:11:20,800
and the other is once you do the hard

00:11:19,240 --> 00:11:22,960
work of moving them from the blue to the

00:11:20,800 --> 00:11:24,610
Reds the yellow they actually convert to

00:11:22,960 --> 00:11:26,680
the green themselves they no pointer

00:11:24,610 --> 00:11:28,690
stability and the types are very very

00:11:26,680 --> 00:11:32,140
similar and all their outward behaviors

00:11:28,690 --> 00:11:34,720
so we've fixed most of the pointer

00:11:32,140 --> 00:11:39,700
stability issues that come with these

00:11:34,720 --> 00:11:42,910
migrations these migrations really

00:11:39,700 --> 00:11:44,380
really bump into Hiram's law if you

00:11:42,910 --> 00:11:46,930
haven't heard it before I'll give you a

00:11:44,380 --> 00:11:53,290
moment to read it well I enjoy some of

00:11:46,930 --> 00:11:55,480
this fine Diet Mountain Dew hiram

00:11:53,290 --> 00:11:57,010
actually didn't realize how deep the

00:11:55,480 --> 00:11:59,200
truth of his statement was when he made

00:11:57,010 --> 00:12:02,200
it he just thought it was a sort of flip

00:11:59,200 --> 00:12:04,990
observation but it's actually like

00:12:02,200 --> 00:12:07,000
entropy you can fight against it you can

00:12:04,990 --> 00:12:08,890
minimize it but you cannot eliminate it

00:12:07,000 --> 00:12:13,270
it's always present it is a

00:12:08,890 --> 00:12:15,490
thermodynamic truth of your codebase so

00:12:13,270 --> 00:12:18,700
how does Hiram's law show up with hash

00:12:15,490 --> 00:12:22,600
tables what have we found in our

00:12:18,700 --> 00:12:26,890
migrations anyone know what this prints

00:12:22,600 --> 00:12:28,930
offhand okay that wasn't entirely a fair

00:12:26,890 --> 00:12:31,180
question what is this print if your

00:12:28,930 --> 00:12:36,060
standard libraries libs did C++ version

00:12:31,180 --> 00:12:39,310
5.1 come on they're only six options

00:12:36,060 --> 00:12:41,230
it's three one two and I know this

00:12:39,310 --> 00:12:44,560
offhand I learned this without ever

00:12:41,230 --> 00:12:50,070
trying because I have seen so many tests

00:12:44,560 --> 00:12:52,390
that just do this it's shocking I mean

00:12:50,070 --> 00:12:57,820
welcome to Google we actually wrap it up

00:12:52,390 --> 00:13:02,050
in a proto buffer but this pattern shows

00:12:57,820 --> 00:13:03,790
up over and over fortunately we were we

00:13:02,050 --> 00:13:06,279
were kind of planning on this when we

00:13:03,790 --> 00:13:08,800
started the Swiss table effort this this

00:13:06,279 --> 00:13:11,529
conversion and we wanted to never have

00:13:08,800 --> 00:13:13,540
to fight this fight again we wanted this

00:13:11,529 --> 00:13:16,570
to be the time we spilled our blood and

00:13:13,540 --> 00:13:19,480
the last time so we added randomization

00:13:16,570 --> 00:13:21,850
when we compute the h1 we mix in the

00:13:19,480 --> 00:13:23,380
pointer address of your bucket and we

00:13:21,850 --> 00:13:26,079
use address space space layout

00:13:23,380 --> 00:13:28,660
randomization in order to ensure that

00:13:26,079 --> 00:13:30,190
different buck different tables will

00:13:28,660 --> 00:13:32,319
have different hash

00:13:30,190 --> 00:13:33,850
is you restart the same binary you'll

00:13:32,319 --> 00:13:36,790
still get different hashes you get

00:13:33,850 --> 00:13:39,910
different hashes now h1 only chooses

00:13:36,790 --> 00:13:41,110
between groups so if your table only has

00:13:39,910 --> 00:13:44,529
one group you're not getting any

00:13:41,110 --> 00:13:46,899
randomization from this but we figured

00:13:44,529 --> 00:13:49,089
okay we couldn't figure out a way to do

00:13:46,899 --> 00:13:52,420
it and opt that was fast enough so in

00:13:49,089 --> 00:13:55,209
debug mode about half the time we fill

00:13:52,420 --> 00:13:58,930
the thing backwards just keep you on

00:13:55,209 --> 00:14:01,420
your toes in debug mode this only

00:13:58,930 --> 00:14:08,379
returns true 50% of the time give or

00:14:01,420 --> 00:14:09,610
take this does come at a cost everything

00:14:08,379 --> 00:14:12,459
comes at a cost

00:14:09,610 --> 00:14:17,160
ask chandler in fact go watch his talk

00:14:12,459 --> 00:14:19,209
I'll wait it was a great talk wasn't it

00:14:17,160 --> 00:14:21,939
let's go back and look at this dee doop

00:14:19,209 --> 00:14:24,189
service someone has implemented but

00:14:21,939 --> 00:14:26,139
let's not look at the code so directly

00:14:24,189 --> 00:14:30,220
let's take a step back and think of this

00:14:26,139 --> 00:14:31,990
as if we were a systems architect okay

00:14:30,220 --> 00:14:34,060
that may have been too far of a step

00:14:31,990 --> 00:14:37,959
back let's look at this like we're an

00:14:34,060 --> 00:14:39,730
SRE so Rd doop service is receiving

00:14:37,959 --> 00:14:41,230
things and it's be duping them and

00:14:39,730 --> 00:14:42,550
attending them to caching layer which

00:14:41,230 --> 00:14:45,339
then hands them to our business logic

00:14:42,550 --> 00:14:47,699
and now let's think about this like

00:14:45,339 --> 00:14:51,310
we're an SRE looking at a service outage

00:14:47,699 --> 00:14:54,370
the d-dude service can get lists of

00:14:51,310 --> 00:14:57,639
length n fact n in any permutation so n

00:14:54,370 --> 00:14:59,769
factorial size of inputs and because

00:14:57,639 --> 00:15:03,970
it's table is deterministic it will

00:14:59,769 --> 00:15:06,610
always output a specific permutation on

00:15:03,970 --> 00:15:08,769
the output so it's reducing your inputs

00:15:06,610 --> 00:15:11,139
from n factorial to N and that's

00:15:08,769 --> 00:15:13,329
actually really useful for your caching

00:15:11,139 --> 00:15:16,180
layer what does this look like if we had

00:15:13,329 --> 00:15:20,050
a deterministic input source but we have

00:15:16,180 --> 00:15:22,720
non-deterministic hash tables now we

00:15:20,050 --> 00:15:24,600
take something ordered and inputs and we

00:15:22,720 --> 00:15:28,480
can produce any factorial different

00:15:24,600 --> 00:15:31,120
outputs and your caching layer has

00:15:28,480 --> 00:15:33,250
completely lost its cache hits raid your

00:15:31,120 --> 00:15:38,589
service is falling over you're demanding

00:15:33,250 --> 00:15:41,110
that I roll back a CL ideally in an

00:15:38,589 --> 00:15:43,750
ideal world you're caching service would

00:15:41,110 --> 00:15:46,029
have a stronger sense of equivalence

00:15:43,750 --> 00:15:48,699
it could do sorting or D duping or

00:15:46,029 --> 00:15:50,079
fuzzing like it could also figure out

00:15:48,699 --> 00:15:52,000
when floating point numbers are close

00:15:50,079 --> 00:15:54,610
enough to consider each other equivalent

00:15:52,000 --> 00:15:55,990
I'm gonna put a pin in floating point

00:15:54,610 --> 00:15:59,069
numbers we'll come back to those in a

00:15:55,990 --> 00:15:59,069
bit they're fun

00:15:59,250 --> 00:16:04,389
usually people implement their D dupe

00:16:01,569 --> 00:16:06,759
service something like this it's pretty

00:16:04,389 --> 00:16:08,829
simple right as you see things you throw

00:16:06,759 --> 00:16:10,660
them in your hash table and then you add

00:16:08,829 --> 00:16:13,689
them to your salt and your output them

00:16:10,660 --> 00:16:15,430
and so I've ended up going into a lot of

00:16:13,689 --> 00:16:18,970
things and rewriting them to something

00:16:15,430 --> 00:16:20,500
like this now no matter what the

00:16:18,970 --> 00:16:22,290
ordering of your hash table is you

00:16:20,500 --> 00:16:24,639
preserve the ordering of your inputs

00:16:22,290 --> 00:16:26,579
it's a useful property to have it's

00:16:24,639 --> 00:16:28,810
actually also slightly more efficient

00:16:26,579 --> 00:16:31,870
because now I'm not doing two passes

00:16:28,810 --> 00:16:32,980
across the data if you wanted to

00:16:31,870 --> 00:16:36,970
collapse your inputs

00:16:32,980 --> 00:16:39,040
you should call sort explicitly if that

00:16:36,970 --> 00:16:43,810
was really what you wanted you should

00:16:39,040 --> 00:16:45,279
have said it in your code I mentioned

00:16:43,810 --> 00:16:47,589
floating point numbers a little bit ago

00:16:45,279 --> 00:16:49,720
turns out there are some simple

00:16:47,589 --> 00:16:54,309
summations over floating point numbers

00:16:49,720 --> 00:16:55,899
that are non-deterministic yet you would

00:16:54,309 --> 00:16:58,079
be shocked that addition you've grown up

00:16:55,899 --> 00:17:01,839
with you know and you love it is not

00:16:58,079 --> 00:17:07,209
associative like let that sink in for a

00:17:01,839 --> 00:17:10,839
second a plus B plus C is not equal to a

00:17:07,209 --> 00:17:13,809
plus B plus C when you're using a float

00:17:10,839 --> 00:17:17,679
or a double nobody ever thinks about

00:17:13,809 --> 00:17:19,659
this but it's true and anyone who has a

00:17:17,679 --> 00:17:21,880
golden file test who has a test that

00:17:19,659 --> 00:17:23,829
says I ran my system I gave it this

00:17:21,880 --> 00:17:25,959
input and I expected one point two seven

00:17:23,829 --> 00:17:29,169
eight nine three four five six seven to

00:17:25,959 --> 00:17:30,730
come out doesn't understand these

00:17:29,169 --> 00:17:35,740
differences between precision and

00:17:30,730 --> 00:17:37,450
accuracy now we're gonna take a slight

00:17:35,740 --> 00:17:40,299
turn we're going to consider an

00:17:37,450 --> 00:17:42,820
optimization that we made also for

00:17:40,299 --> 00:17:46,590
shadow I'm told offers good authors do

00:17:42,820 --> 00:17:46,590
it good presenters should also for Shaq

00:17:46,799 --> 00:17:52,960
so let's consider how our probing

00:17:49,750 --> 00:17:54,610
behavior happens across groups we start

00:17:52,960 --> 00:17:57,670
by selecting whatever group our hash

00:17:54,610 --> 00:18:01,150
sends us to and then we advanced

00:17:57,670 --> 00:18:03,520
the next group and then we advance to

00:18:01,150 --> 00:18:04,600
the next group it's pretty easy it's

00:18:03,520 --> 00:18:06,520
actually not linear it's quadratic

00:18:04,600 --> 00:18:09,820
advancement but for slide where we do

00:18:06,520 --> 00:18:12,880
linear but what happens if we let our

00:18:09,820 --> 00:18:15,390
windows float can we break ourselves

00:18:12,880 --> 00:18:19,450
from this tyranny of group alignment

00:18:15,390 --> 00:18:21,160
instead of baking in this idea that it's

00:18:19,450 --> 00:18:23,050
mod num groups and our groups have size

00:18:21,160 --> 00:18:25,930
16 can we drop this

00:18:23,050 --> 00:18:29,320
can we just say it's mod capacity and we

00:18:25,930 --> 00:18:32,340
advance by steps of 16 let's see how it

00:18:29,320 --> 00:18:36,100
plays out when we use it we pick a spot

00:18:32,340 --> 00:18:40,320
okay we advance once seems all right

00:18:36,100 --> 00:18:42,460
let's do it again okay that's less good

00:18:40,320 --> 00:18:45,400
we just read straight off the end of our

00:18:42,460 --> 00:18:47,950
metadata array and right into our slot

00:18:45,400 --> 00:18:52,030
array and no one really knows what's

00:18:47,950 --> 00:18:54,000
there it might be bad it might look like

00:18:52,030 --> 00:18:56,530
we're just not going to go there

00:18:54,000 --> 00:18:59,770
notionally what we wanted to do was this

00:18:56,530 --> 00:19:03,340
we wanted to sort of have this floating

00:18:59,770 --> 00:19:08,400
window span across the thing but that's

00:19:03,340 --> 00:19:11,050
just not how SSE instructions work so

00:19:08,400 --> 00:19:12,850
right if our SSE instructions won't do

00:19:11,050 --> 00:19:14,440
this what do we do well we'll just make

00:19:12,850 --> 00:19:17,020
them happy we're gonna copy the data

00:19:14,440 --> 00:19:19,210
over odds and we're gonna replicate the

00:19:17,020 --> 00:19:22,960
first set of bytes at the end of the

00:19:19,210 --> 00:19:24,640
initial bytes it's unfortunate that we

00:19:22,960 --> 00:19:26,920
need this extra code but we're gonna

00:19:24,640 --> 00:19:29,470
play out this line of reasoning before

00:19:26,920 --> 00:19:34,060
we actually decide whether we like or

00:19:29,470 --> 00:19:36,130
dislike anything so now great we hash

00:19:34,060 --> 00:19:38,500
here we can go we see our replicated

00:19:36,130 --> 00:19:41,380
bytes everything is good the real

00:19:38,500 --> 00:19:44,470
question is how does this perform we

00:19:41,380 --> 00:19:46,150
have micro benchmarks okay we have a lot

00:19:44,470 --> 00:19:50,260
of micro benchmarks so we usually use

00:19:46,150 --> 00:19:51,280
graphs and you know in general what

00:19:50,260 --> 00:19:53,230
you're seeing if you're really looking

00:19:51,280 --> 00:19:54,580
carefully and all of these blue is the

00:19:53,230 --> 00:19:57,670
new implementation orange is the old

00:19:54,580 --> 00:19:59,920
implementation it's slightly better the

00:19:57,670 --> 00:20:02,920
trend is positive it's 5 to 10% I'm

00:19:59,920 --> 00:20:05,890
gonna zoom in on a couple idiot a couple

00:20:02,920 --> 00:20:08,800
obvious examples this is fine this is

00:20:05,890 --> 00:20:09,920
what we're trying to optimize great 10%

00:20:08,800 --> 00:20:12,020
faster I love

00:20:09,920 --> 00:20:15,800
and this is when the table is hot in

00:20:12,020 --> 00:20:17,290
cash when the table is cold in cash 10%

00:20:15,800 --> 00:20:20,750
faster I love it

00:20:17,290 --> 00:20:24,640
okay what about inserting when the table

00:20:20,750 --> 00:20:28,190
is hot in cash this is 10 to 20% slower

00:20:24,640 --> 00:20:32,960
this isn't really surprising because I

00:20:28,190 --> 00:20:34,670
did add code the insert path I could

00:20:32,960 --> 00:20:36,920
show you the result for cold tables and

00:20:34,670 --> 00:20:39,200
it would look much much worse but it's

00:20:36,920 --> 00:20:41,350
not statistically significant so I'm not

00:20:39,200 --> 00:20:44,150
going to it's just a misleading graph

00:20:41,350 --> 00:20:46,060
also do your statistical significance

00:20:44,150 --> 00:20:48,740
when you're benchmarking complex things

00:20:46,060 --> 00:20:52,190
so let's answer the easy question first

00:20:48,740 --> 00:20:56,270
why is it slower it's slower because we

00:20:52,190 --> 00:20:58,520
added an instruction it's really not

00:20:56,270 --> 00:21:01,280
that surprising there's some tricks you

00:20:58,520 --> 00:21:03,140
can do with math to make this not a

00:21:01,280 --> 00:21:05,240
conditional expression and we do them in

00:21:03,140 --> 00:21:07,520
the actual implementation but I didn't

00:21:05,240 --> 00:21:10,430
want to explain those tricks here go

00:21:07,520 --> 00:21:14,960
look at the code on github you'll find

00:21:10,430 --> 00:21:19,070
it it's kind of cool okay why is it

00:21:14,960 --> 00:21:23,270
faster on find let's consider the case

00:21:19,070 --> 00:21:24,950
of doing finds or actually we're

00:21:23,270 --> 00:21:27,200
considering how things get laid out how

00:21:24,950 --> 00:21:31,310
they are inserted in order to understand

00:21:27,200 --> 00:21:33,080
finds both our tables start empty and we

00:21:31,310 --> 00:21:36,440
want to make an insertion right there in

00:21:33,080 --> 00:21:39,290
the old case we align it to the group

00:21:36,440 --> 00:21:42,320
and in the new case our group is just

00:21:39,290 --> 00:21:43,640
right where we want it then we insert it

00:21:42,320 --> 00:21:46,160
right at the spot at the beginning of

00:21:43,640 --> 00:21:48,320
the group we do it again now we want to

00:21:46,160 --> 00:21:50,120
insert here the old case we align it to

00:21:48,320 --> 00:21:52,190
the group and the new case we insert it

00:21:50,120 --> 00:21:56,030
just at the spot where we want it in

00:21:52,190 --> 00:22:00,440
fact we can do it again so this is all

00:21:56,030 --> 00:22:05,000
pretty cool but what is it really

00:22:00,440 --> 00:22:07,520
telling us right logically logically

00:22:05,000 --> 00:22:11,570
this is just one group that's all it is

00:22:07,520 --> 00:22:13,310
and here every single item here is its

00:22:11,570 --> 00:22:15,830
own starting point for a group there are

00:22:13,310 --> 00:22:18,080
more groups and every item is more

00:22:15,830 --> 00:22:20,030
likely to be the first item in its own

00:22:18,080 --> 00:22:21,820
group which means it's the first that

00:22:20,030 --> 00:22:24,129
will be tested for equality

00:22:21,820 --> 00:22:26,479
statistically speaking

00:22:24,129 --> 00:22:29,570
but is there a way to see this more

00:22:26,479 --> 00:22:33,950
directly in the code so here we're just

00:22:29,570 --> 00:22:37,340
looking at the diff right and let's zoom

00:22:33,950 --> 00:22:41,119
in on this first change what are we

00:22:37,340 --> 00:22:46,639
actually doing here remember capacity is

00:22:41,119 --> 00:22:50,029
just num groups times 16 we've got four

00:22:46,639 --> 00:22:53,210
more bits in our h1 hash or functionally

00:22:50,029 --> 00:22:57,259
four more bits in our h1 hash that's why

00:22:53,210 --> 00:22:59,960
we're getting better performance here so

00:22:57,259 --> 00:23:01,909
now we understand what we're trading off

00:22:59,960 --> 00:23:04,549
benchmarks are great for helping us

00:23:01,909 --> 00:23:06,979
understand what we trade off but they're

00:23:04,549 --> 00:23:09,919
horrible because they don't tell you

00:23:06,979 --> 00:23:11,330
anything they just tell you these facts

00:23:09,919 --> 00:23:13,479
but they don't tell you what the

00:23:11,330 --> 00:23:15,440
relative value of these facts are

00:23:13,479 --> 00:23:17,869
fortunately we have a way to cheat at

00:23:15,440 --> 00:23:21,229
Google we just plug it into web search

00:23:17,869 --> 00:23:25,549
and measure the performance you guys do

00:23:21,229 --> 00:23:27,320
that right so it's actually a

00:23:25,549 --> 00:23:29,330
performance improvement of about half a

00:23:27,320 --> 00:23:32,389
percent of web searches overall

00:23:29,330 --> 00:23:35,960
performance that's really good like web

00:23:32,389 --> 00:23:37,489
search uses a lot of CPUs also it

00:23:35,960 --> 00:23:39,979
doesn't actually use that many hash

00:23:37,489 --> 00:23:44,509
tables because for a service like web

00:23:39,979 --> 00:23:50,710
search so this is great so I think we

00:23:44,509 --> 00:23:53,710
should just ship this right wait wait

00:23:50,710 --> 00:23:53,710
Hyrum

00:23:58,240 --> 00:24:07,700
but we already randomized them what do

00:24:00,770 --> 00:24:11,620
you mean only large groups but we

00:24:07,700 --> 00:24:11,620
randomized in debug for small tables oh

00:24:15,040 --> 00:24:21,920
my god this is the sort of entropy Hyrum

00:24:19,670 --> 00:24:23,540
has always tried to warn us about watch

00:24:21,920 --> 00:24:25,790
what happens if I have a small table and

00:24:23,540 --> 00:24:27,560
I insert into it the first insertion can

00:24:25,790 --> 00:24:29,780
go at the beginning for the old one and

00:24:27,560 --> 00:24:31,700
for ours it can go anywhere wherever the

00:24:29,780 --> 00:24:33,740
floating group had it the second

00:24:31,700 --> 00:24:37,030
insertion on the old one always at the

00:24:33,740 --> 00:24:37,030
big always at the beginning people

00:24:37,390 --> 00:24:43,610
depended on this behavior fortunately it

00:24:40,820 --> 00:24:45,470
was only about 20 people we fought hard

00:24:43,610 --> 00:24:47,420
enough against it we put in enough

00:24:45,470 --> 00:24:51,260
randomization that we could make this

00:24:47,420 --> 00:24:53,810
change so on our tutor on October 30th

00:24:51,260 --> 00:24:55,970
Sam Benz Aiken submitted this change and

00:24:53,810 --> 00:25:00,460
then we all went trick-or-treating and

00:24:55,970 --> 00:25:02,750
life was great and then on November 2nd

00:25:00,460 --> 00:25:04,870
just as the sugar from trick-or-treating

00:25:02,750 --> 00:25:07,340
was wearing off someone opened up a bug

00:25:04,870 --> 00:25:09,140
they were seeing a massive increase in

00:25:07,340 --> 00:25:12,890
the cost of the tables on their system

00:25:09,140 --> 00:25:14,330
and they came to us and they said no

00:25:12,890 --> 00:25:17,540
this is like that this is slowed down

00:25:14,330 --> 00:25:20,800
like can you help me fix it and I said

00:25:17,540 --> 00:25:23,300
oh god Sam can you help them fix it

00:25:20,800 --> 00:25:25,910
their code looked a little bit like this

00:25:23,300 --> 00:25:27,770
I've simplified a lot of things here to

00:25:25,910 --> 00:25:30,830
get you this code I'm gonna give you

00:25:27,770 --> 00:25:32,120
guys a moment to think about it and see

00:25:30,830 --> 00:25:43,370
if you come up with any answers while I

00:25:32,120 --> 00:25:47,330
enjoy this fine Diet Mountain Dew anyone

00:25:43,370 --> 00:25:54,790
spotted it really all right I'll give

00:25:47,330 --> 00:25:54,790
you a hint little bit of math

00:25:57,350 --> 00:26:06,540
anyone this is why I needed Sam to fix

00:26:02,460 --> 00:26:08,309
it we had four more bits of h1 hash

00:26:06,540 --> 00:26:10,320
available to us that we started using

00:26:08,309 --> 00:26:16,260
before we weren't using these four bits

00:26:10,320 --> 00:26:18,299
and they were only using them they were

00:26:16,260 --> 00:26:20,520
using the four bits that we had just

00:26:18,299 --> 00:26:23,460
given them to switch between their

00:26:20,520 --> 00:26:25,049
tables so they got these four new bits

00:26:23,460 --> 00:26:28,919
and they were all the same for all their

00:26:25,049 --> 00:26:31,049
tables and hash tables are fickle beasts

00:26:28,919 --> 00:26:33,630
you give them an even slightly bad hash

00:26:31,049 --> 00:26:38,880
function and their performance falls off

00:26:33,630 --> 00:26:40,950
a cliff we really ought to figure out a

00:26:38,880 --> 00:26:43,850
way to identify problems like this

00:26:40,950 --> 00:26:46,110
automatically and surface them better

00:26:43,850 --> 00:26:50,100
but that's a detour for the end of the

00:26:46,110 --> 00:26:51,809
slides I'm gonna go on a small detour

00:26:50,100 --> 00:26:55,260
here first we're gonna talk about our

00:26:51,809 --> 00:26:56,940
second optimization but a little more

00:26:55,260 --> 00:26:59,070
foreshadowing first so people can guess

00:26:56,940 --> 00:27:00,600
what this optimization is hopefully it's

00:26:59,070 --> 00:27:05,610
a little bit more clear or at least

00:27:00,600 --> 00:27:07,410
somewhat less surreal how much memory do

00:27:05,610 --> 00:27:08,880
each of these use I'm not talking about

00:27:07,410 --> 00:27:11,160
the memory of the flat hash set itself

00:27:08,880 --> 00:27:12,570
just how much do they allocate turns out

00:27:11,160 --> 00:27:15,780
it's probably a little heavier than you

00:27:12,570 --> 00:27:17,850
think this top one right you're gonna

00:27:15,780 --> 00:27:19,320
use 16 bytes for the metadata and then

00:27:17,850 --> 00:27:21,780
16 bytes for the replication of the

00:27:19,320 --> 00:27:24,960
metadata and then 15 times your value

00:27:21,780 --> 00:27:29,340
type so to put a single int into a flat

00:27:24,960 --> 00:27:31,559
hash set took 92 bytes and put a single

00:27:29,340 --> 00:27:33,809
string into your flash hat flat hash set

00:27:31,559 --> 00:27:35,940
assuming your string fit in its sso and

00:27:33,809 --> 00:27:38,970
that your string was 32 bytes your size

00:27:35,940 --> 00:27:45,480
up stood string was 32 bytes was half

00:27:38,970 --> 00:27:49,130
okay well let's see if we are more

00:27:45,480 --> 00:27:49,130
likely Sam can do anything about this

00:27:49,640 --> 00:27:55,410
what are our actual requirements for

00:27:52,559 --> 00:27:57,750
this code we have to be able to probe 16

00:27:55,410 --> 00:28:01,110
past the end of our sentinel in case our

00:27:57,750 --> 00:28:04,830
h1 puts us just before the sentinel we

00:28:01,110 --> 00:28:06,720
have to replicate the low bits and this

00:28:04,830 --> 00:28:09,539
in the equivalent positions after our

00:28:06,720 --> 00:28:11,999
sentinel we have to have an empty slot

00:28:09,539 --> 00:28:14,519
somewhere and we have to have a capacity

00:28:11,999 --> 00:28:16,289
that is a power of two minus one I've

00:28:14,519 --> 00:28:17,669
never mentioned that before but it's

00:28:16,289 --> 00:28:19,470
just a fact we don't actually take a

00:28:17,669 --> 00:28:23,580
modulus we do a bit mask because modulus

00:28:19,470 --> 00:28:26,989
is slow interestingly nothing here

00:28:23,580 --> 00:28:29,909
requires that those extra empty slots

00:28:26,989 --> 00:28:31,320
have to be there in any real sense they

00:28:29,909 --> 00:28:33,779
only have to be there in the metadata

00:28:31,320 --> 00:28:36,330
and so there are some powers of two

00:28:33,779 --> 00:28:42,149
we've never considered one three and

00:28:36,330 --> 00:28:45,179
seven what about a table like this we

00:28:42,149 --> 00:28:48,119
moved our end of slot marker over and it

00:28:45,179 --> 00:28:50,849
still fits our requirements we can probe

00:28:48,119 --> 00:28:53,759
sixteen past it we replicated the

00:28:50,849 --> 00:28:57,629
metadata we have an empty slot somewhere

00:28:53,759 --> 00:29:01,559
and it has capacity of two power of two

00:28:57,629 --> 00:29:04,409
minus one so now with this improve

00:29:01,559 --> 00:29:07,639
layout we only need 18 bytes of metadata

00:29:04,409 --> 00:29:09,809
and then some padding because value type

00:29:07,639 --> 00:29:10,109
and so things are looking a little bit

00:29:09,809 --> 00:29:12,059
better

00:29:10,109 --> 00:29:16,019
how big is a flat hash set of a single

00:29:12,059 --> 00:29:20,309
int now it's 24 bytes we've saved over

00:29:16,019 --> 00:29:24,509
2/3 from the original how big is it

00:29:20,309 --> 00:29:27,059
for a flatte hash set of string factor

00:29:24,509 --> 00:29:32,399
of 10 in savings we save so much that we

00:29:27,059 --> 00:29:34,379
should probably change units it's pretty

00:29:32,399 --> 00:29:37,200
easy to see why small tables are better

00:29:34,379 --> 00:29:39,090
how did we do in the benchmarks actually

00:29:37,200 --> 00:29:43,080
I'm not going to show you the find code

00:29:39,090 --> 00:29:52,019
it didn't change right we should just

00:29:43,080 --> 00:29:53,159
ship this this is great what but I don't

00:29:52,019 --> 00:29:54,989
care about people who hard-coded the

00:29:53,159 --> 00:29:58,039
exact allocation size and what do you

00:29:54,989 --> 00:29:58,039
mean pointer stability

00:29:58,150 --> 00:30:12,460
I didn't guarantee that I mean oh my god

00:30:10,240 --> 00:30:15,400
people are depending on our exact rehash

00:30:12,460 --> 00:30:19,030
timing imagine inserting elements into

00:30:15,400 --> 00:30:20,560
the old array versus the new in the old

00:30:19,030 --> 00:30:22,240
array we'd find a spot and put it

00:30:20,560 --> 00:30:24,070
somewhere in the new array we put it

00:30:22,240 --> 00:30:26,440
right at the beginning in its only space

00:30:24,070 --> 00:30:29,500
and then when we try and insert a second

00:30:26,440 --> 00:30:30,520
element we have to rehash to grow it the

00:30:29,500 --> 00:30:32,350
old array we didn't

00:30:30,520 --> 00:30:33,720
fortunately the third element actually

00:30:32,350 --> 00:30:37,750
is okay

00:30:33,720 --> 00:30:40,840
so small miracles so how many people

00:30:37,750 --> 00:30:43,930
actually depended on pointer stability

00:30:40,840 --> 00:30:50,170
for array for her tables with size less

00:30:43,930 --> 00:30:52,510
than 15 about 200 200 that we found and

00:30:50,170 --> 00:30:54,880
fixed beforehand there probably another

00:30:52,510 --> 00:30:58,780
200 that we broke and they fixed

00:30:54,880 --> 00:31:05,980
themselves hyrum really does extract a

00:30:58,780 --> 00:31:08,170
never ending tax upon us so remember how

00:31:05,980 --> 00:31:11,620
I said it would be great if we could

00:31:08,170 --> 00:31:13,420
figure out tables and stuff like let's

00:31:11,620 --> 00:31:15,760
take a moment to sort of step back and

00:31:13,420 --> 00:31:17,740
think about what is the CPU profile for

00:31:15,760 --> 00:31:20,260
a really highly optimized system look

00:31:17,740 --> 00:31:22,450
like it should spend almost all of its

00:31:20,260 --> 00:31:24,340
time inside the body of a really well

00:31:22,450 --> 00:31:27,580
optimized data structure like a hash

00:31:24,340 --> 00:31:29,470
table and what is the CPU profile for a

00:31:27,580 --> 00:31:32,430
system that has been misconfigured look

00:31:29,470 --> 00:31:36,190
like well it will spend all of its time

00:31:32,430 --> 00:31:38,440
inside a hash table so let's play a game

00:31:36,190 --> 00:31:41,890
I am going to show you two performance

00:31:38,440 --> 00:31:45,130
profiles we should vote on who thinks

00:31:41,890 --> 00:31:46,690
the top profile profile a comes from

00:31:45,130 --> 00:31:49,780
something that has a bad hash function

00:31:46,690 --> 00:31:52,540
and who thinks the bottom profile

00:31:49,780 --> 00:31:55,630
profile two comes from something that

00:31:52,540 --> 00:31:59,830
has a bad hash function hey raise your

00:31:55,630 --> 00:32:04,150
hands I got Matt God bolt with a

00:31:59,830 --> 00:32:07,870
tentative hand and nobody else to anyone

00:32:04,150 --> 00:32:10,390
voting for two I got I think people are

00:32:07,870 --> 00:32:11,850
pointing a Chandler Oh Oh Chandler voted

00:32:10,390 --> 00:32:14,970
in the first round

00:32:11,850 --> 00:32:21,990
map God bolts very tentative hand was

00:32:14,970 --> 00:32:25,680
correct but the fact that it's not easy

00:32:21,990 --> 00:32:30,300
is really a damning statement about our

00:32:25,680 --> 00:32:32,610
tools one more show of hands who has

00:32:30,300 --> 00:32:37,680
seen anything like the previous two

00:32:32,610 --> 00:32:39,810
slides before well we got Mac out that's

00:32:37,680 --> 00:32:43,530
good he wasn't just guessing or maybe he

00:32:39,810 --> 00:32:47,160
was this is G this is P prof it is a

00:32:43,530 --> 00:32:50,040
great tool it collects all sorts of

00:32:47,160 --> 00:32:51,720
stuff right you can use it to generate

00:32:50,040 --> 00:32:53,580
these graphs that you've seen you can

00:32:51,720 --> 00:32:56,400
use it to generate the sort of textual

00:32:53,580 --> 00:32:59,190
output you've seen it's all based on an

00:32:56,400 --> 00:33:04,170
open and extensible data format I highly

00:32:59,190 --> 00:33:06,030
recommend people use it it's awesome so

00:33:04,170 --> 00:33:08,100
Google makes heavy use of the fact that

00:33:06,030 --> 00:33:10,440
P products has this extensible data

00:33:08,100 --> 00:33:12,210
format we will take all our different

00:33:10,440 --> 00:33:15,270
things Chris Connolly gave a talk

00:33:12,210 --> 00:33:16,380
actually earlier today on TC Malik those

00:33:15,270 --> 00:33:18,900
of you who are here in the audience

00:33:16,380 --> 00:33:20,700
should create a time machine go forward

00:33:18,900 --> 00:33:24,510
in time until the talk is released on

00:33:20,700 --> 00:33:26,400
YouTube and then watch it on YouTube but

00:33:24,510 --> 00:33:28,530
we use this to collect a ton of things

00:33:26,400 --> 00:33:31,980
we use to collect CPU profiles so that

00:33:28,530 --> 00:33:33,810
we can figure out right we will use sig

00:33:31,980 --> 00:33:36,300
prof to generate stack traces which

00:33:33,810 --> 00:33:38,910
tells us what the CPU is doing we used

00:33:36,300 --> 00:33:41,280
to collect contention absol mutex has

00:33:38,910 --> 00:33:43,560
hooks in it to tell you when it has

00:33:41,280 --> 00:33:45,030
acquired a mutex after failing to

00:33:43,560 --> 00:33:47,820
acquire it for a while so you can

00:33:45,030 --> 00:33:50,220
collect the data about contended mutexes

00:33:47,820 --> 00:33:52,620
TC mallet or our allocation system

00:33:50,220 --> 00:33:56,010
tracks allocations and it can export

00:33:52,620 --> 00:33:57,840
memory usage it's great these are

00:33:56,010 --> 00:34:00,650
obviously too expensive to collect all

00:33:57,840 --> 00:34:03,090
the time so we do sampled collection

00:34:00,650 --> 00:34:06,720
fortunately our fleet is very very large

00:34:03,090 --> 00:34:11,940
and so sampling gets you accurate enough

00:34:06,720 --> 00:34:14,160
data we surface this information at a

00:34:11,940 --> 00:34:15,900
bunch of different ways so the real

00:34:14,160 --> 00:34:19,020
trick in trying to figure this out for

00:34:15,900 --> 00:34:21,630
hash tables is how can we get

00:34:19,020 --> 00:34:24,540
information from hash tables out to some

00:34:21,630 --> 00:34:26,820
kind of sampler in a reasonable way

00:34:24,540 --> 00:34:29,560
this is kind of what you want to do

00:34:26,820 --> 00:34:31,570
right when your table is first

00:34:29,560 --> 00:34:36,490
constructed you roll a die and you say

00:34:31,570 --> 00:34:39,610
Snake Eyes I get to sample but like this

00:34:36,490 --> 00:34:42,220
is way too expensive also you don't want

00:34:39,610 --> 00:34:44,020
the logic for how to sample in the hash

00:34:42,220 --> 00:34:46,030
table you want that hidden in the

00:34:44,020 --> 00:34:47,860
sampler so I'm going to introduce this

00:34:46,030 --> 00:34:49,810
concept of a sample handle into the

00:34:47,860 --> 00:34:55,270
table itself so that someone else can

00:34:49,810 --> 00:35:00,100
decide for me when to sample same idea

00:34:55,270 --> 00:35:02,500
for the time being I'm gonna talk about

00:35:00,100 --> 00:35:04,840
how to make sampling more efficient

00:35:02,500 --> 00:35:07,960
before I go into what we're actually

00:35:04,840 --> 00:35:09,880
sampling right because we don't want it

00:35:07,960 --> 00:35:13,270
to just take a random number and do the

00:35:09,880 --> 00:35:15,340
sample rate so we're gonna focus here on

00:35:13,270 --> 00:35:19,090
what the sampling routine does before we

00:35:15,340 --> 00:35:20,350
figure out when to sample kind of

00:35:19,090 --> 00:35:22,240
notionally it would be nice to do

00:35:20,350 --> 00:35:24,100
something like this we're okay we're

00:35:22,240 --> 00:35:25,930
just gonna sample every nth one because

00:35:24,100 --> 00:35:27,420
like that subtraction is super fast and

00:35:25,930 --> 00:35:29,350
then we can just reset back to it

00:35:27,420 --> 00:35:33,609
unfortunately one this is not thread

00:35:29,350 --> 00:35:35,500
safe and two this is like I don't

00:35:33,609 --> 00:35:38,470
I barely know stats and I know that this

00:35:35,500 --> 00:35:42,430
is bad every and table is gonna get

00:35:38,470 --> 00:35:47,770
weird aliasing artifacts I'm gonna warn

00:35:42,430 --> 00:35:49,600
you this is my view of Statistics right

00:35:47,770 --> 00:35:52,650
like I'm gonna do my best to explain

00:35:49,600 --> 00:35:57,210
this to the stats that follow though I

00:35:52,650 --> 00:35:57,210
try not to ask too many questions please

00:35:57,240 --> 00:36:02,109
so computing a number just to check if

00:36:00,070 --> 00:36:03,850
it's zero is sort of you're doing an

00:36:02,109 --> 00:36:06,160
experiment to see if it succeeds and

00:36:03,850 --> 00:36:08,650
there's actually a distribution to model

00:36:06,160 --> 00:36:11,230
this how many experiments do you need to

00:36:08,650 --> 00:36:12,940
do or to model this statistical thing

00:36:11,230 --> 00:36:14,170
it's you've roll the die did it come up

00:36:12,940 --> 00:36:18,190
zero it's called a Bernoulli

00:36:14,170 --> 00:36:19,869
distribution great but why is that

00:36:18,190 --> 00:36:21,970
useful I've just switched from a

00:36:19,869 --> 00:36:23,080
distribution you know about uniform to a

00:36:21,970 --> 00:36:26,470
distribution you don't know about

00:36:23,080 --> 00:36:28,270
Bernoulli well it turns out that

00:36:26,470 --> 00:36:30,640
repeated applications of a Bernoulli

00:36:28,270 --> 00:36:32,800
distribution until it succeeds is

00:36:30,640 --> 00:36:35,619
another distribution it's called the

00:36:32,800 --> 00:36:37,080
geometric distribution and in fact you

00:36:35,619 --> 00:36:41,610
can make this change

00:36:37,080 --> 00:36:43,890
and now we're back to doing this with

00:36:41,610 --> 00:36:46,650
just a single subtraction except for

00:36:43,890 --> 00:36:48,060
when we decide to sample we when we

00:36:46,650 --> 00:36:49,470
decide to sample we have to recompute

00:36:48,060 --> 00:36:53,190
the math to figure out when we're next

00:36:49,470 --> 00:36:54,870
going to decide the sample fortunately

00:36:53,190 --> 00:36:56,730
that was already expensive we were going

00:36:54,870 --> 00:37:01,470
to sample this one so we're ok with that

00:36:56,730 --> 00:37:03,780
price we're going to assume that all our

00:37:01,470 --> 00:37:08,600
threads are independent is this

00:37:03,780 --> 00:37:12,390
assumption valid no but we don't care

00:37:08,600 --> 00:37:15,780
like one of the things Cassie has told

00:37:12,390 --> 00:37:17,730
me is if you're okay with stating your

00:37:15,780 --> 00:37:20,010
assumptions you can do it in statistics

00:37:17,730 --> 00:37:22,890
I'm going to assume that it's OK for me

00:37:20,010 --> 00:37:24,330
to treat my threads independently and if

00:37:22,890 --> 00:37:26,330
you don't like my conclusions well

00:37:24,330 --> 00:37:29,100
that's your right

00:37:26,330 --> 00:37:30,960
so hopefully you made it this far or are

00:37:29,100 --> 00:37:33,000
willing to just take my word for it on

00:37:30,960 --> 00:37:35,820
the stats I'm not gonna go into any more

00:37:33,000 --> 00:37:37,980
depth on stats but there are more tricks

00:37:35,820 --> 00:37:39,600
in the code itself to make the stats

00:37:37,980 --> 00:37:41,340
work out a little bit better

00:37:39,600 --> 00:37:42,930
I really suggest you go look at it in

00:37:41,340 --> 00:37:48,630
the abseil repo it's in everybody's

00:37:42,930 --> 00:37:51,260
favorite directory internal so now we

00:37:48,630 --> 00:37:55,140
know how to sample and we have to decide

00:37:51,260 --> 00:37:58,950
when to sample and what information to

00:37:55,140 --> 00:38:01,620
record construction for flat hash set

00:37:58,950 --> 00:38:06,180
currently is super cheap no allocations

00:38:01,620 --> 00:38:07,860
nothing people often like put a flat

00:38:06,180 --> 00:38:09,330
hash set on their stack just in case

00:38:07,860 --> 00:38:10,860
they're gonna want it later and then

00:38:09,330 --> 00:38:12,750
they don't they early return out of

00:38:10,860 --> 00:38:15,270
their function or that flag isn't

00:38:12,750 --> 00:38:17,700
enabled for that prodding so we don't

00:38:15,270 --> 00:38:19,200
want to slow down this case ideally we

00:38:17,700 --> 00:38:21,210
want to sort of inject this little bit

00:38:19,200 --> 00:38:23,280
of overhead into a spot where they won't

00:38:21,210 --> 00:38:28,890
notice it like the first time they

00:38:23,280 --> 00:38:32,040
allocate we can get away with it here so

00:38:28,890 --> 00:38:34,740
now we know when we want to sample we

00:38:32,040 --> 00:38:38,640
know how we want to sample we just need

00:38:34,740 --> 00:38:41,880
to figure out what we want to sample so

00:38:38,640 --> 00:38:44,250
what would a useful monitoring system

00:38:41,880 --> 00:38:46,410
give us it should tell us if our tables

00:38:44,250 --> 00:38:49,560
are big kitchen table tell us if our

00:38:46,410 --> 00:38:50,980
tables are both big and empty it should

00:38:49,560 --> 00:38:53,470
tell us if our tables have

00:38:50,980 --> 00:38:54,820
really started probing a lot and if

00:38:53,470 --> 00:38:56,170
they've started probing a lot they

00:38:54,820 --> 00:38:58,630
should tell us something about their

00:38:56,170 --> 00:39:01,090
hash function so we can figure out like

00:38:58,630 --> 00:39:04,540
in what way is it bad it should also

00:39:01,090 --> 00:39:09,250
have no overhead okay we're gonna give a

00:39:04,540 --> 00:39:11,740
little on that one so what can we sample

00:39:09,250 --> 00:39:14,290
that will fit this if our table was big

00:39:11,740 --> 00:39:16,240
that's pretty easy if our table was big

00:39:14,290 --> 00:39:20,020
and empty that's also pretty easy it

00:39:16,240 --> 00:39:21,910
just keeps the size of it if we have to

00:39:20,020 --> 00:39:24,160
prove too much it gets a little bit

00:39:21,910 --> 00:39:26,080
harder we kind of want the average probe

00:39:24,160 --> 00:39:28,330
length but in order to have the average

00:39:26,080 --> 00:39:29,800
Pro length you can't just take the total

00:39:28,330 --> 00:39:31,990
probe length and divide it by the size

00:39:29,800 --> 00:39:33,640
because if someone does insert a race

00:39:31,990 --> 00:39:35,859
insert erase insert erase insert the

00:39:33,640 --> 00:39:37,510
race over and over your size will be one

00:39:35,859 --> 00:39:39,609
and your total probe link will be quite

00:39:37,510 --> 00:39:41,320
large so you actually need the number

00:39:39,609 --> 00:39:47,560
races and then you can get your average

00:39:41,320 --> 00:39:50,560
probe length also how will it tell us if

00:39:47,560 --> 00:39:52,869
your hash function is bad like we could

00:39:50,560 --> 00:39:54,670
try and keep every single hash that's

00:39:52,869 --> 00:39:59,140
been inserted but that's gonna be really

00:39:54,670 --> 00:40:02,170
expensive like what we really want is to

00:39:59,140 --> 00:40:04,990
distill this down a little bit all

00:40:02,170 --> 00:40:07,480
inserted hashes know what if we keep a

00:40:04,990 --> 00:40:11,170
running bitwise or and a running bitwise

00:40:07,480 --> 00:40:14,440
and of our hashes in this case the ore

00:40:11,170 --> 00:40:16,690
is going to go to ffff and the and is

00:40:14,440 --> 00:40:18,310
going to go to zero because in theory

00:40:16,690 --> 00:40:21,070
all your bits should be flipping back

00:40:18,310 --> 00:40:23,619
and forth randomly and if any of those

00:40:21,070 --> 00:40:26,890
don't happen your hash function has

00:40:23,619 --> 00:40:31,180
stuck bits and as we saw earlier stuck

00:40:26,890 --> 00:40:32,650
bits destroy performance best of all you

00:40:31,180 --> 00:40:34,600
can actually compute these incrementally

00:40:32,650 --> 00:40:39,310
right it's just an or equals and an and

00:40:34,600 --> 00:40:41,560
equals it's very very fast so the code

00:40:39,310 --> 00:40:43,300
that reads the samples might of course

00:40:41,560 --> 00:40:46,180
be in a different thread than the code

00:40:43,300 --> 00:40:47,470
that is pushing this data so we're gonna

00:40:46,180 --> 00:40:51,970
throw a stood atomic on it

00:40:47,470 --> 00:40:54,160
everyone loves stowed atomic well we

00:40:51,970 --> 00:40:57,820
also need to know what table is the

00:40:54,160 --> 00:41:01,390
guilty party we need to know who did

00:40:57,820 --> 00:41:02,080
this at this point I think this looks

00:41:01,390 --> 00:41:04,300
pretty good

00:41:02,080 --> 00:41:09,970
like I want to just submit this

00:41:04,300 --> 00:41:11,800
thing see what we can learn right you

00:41:09,970 --> 00:41:22,780
know I kind of expected to see you here

00:41:11,800 --> 00:41:24,340
I wasn't sure why though no I did not

00:41:22,780 --> 00:41:27,130
think about the syscalls

00:41:24,340 --> 00:41:30,430
that mice hash-table could make let's do

00:41:27,130 --> 00:41:36,580
some quick surveys who thinks that this

00:41:30,430 --> 00:41:39,010
is allowed to call malloc okay hands are

00:41:36,580 --> 00:41:43,900
gradually coming up yes I agree this

00:41:39,010 --> 00:41:46,240
should be allowed to call malloc okay

00:41:43,900 --> 00:41:54,510
who thinks that this is allowed to call

00:41:46,240 --> 00:41:59,280
malloc there are a lot fewer hands okay

00:41:54,510 --> 00:41:59,280
who thinks this is allowed to call futex

00:42:00,870 --> 00:42:05,440
futex for those who don't know is the

00:42:03,040 --> 00:42:13,390
system call that often deep in the guts

00:42:05,440 --> 00:42:14,950
underlies a mutex acquisition okay

00:42:13,390 --> 00:42:22,000
how about this is this allowed to call

00:42:14,950 --> 00:42:25,150
futex right these are really sort of

00:42:22,000 --> 00:42:27,370
squirrelly things is does this code leak

00:42:25,150 --> 00:42:29,080
memory I'm gonna give you a moment to

00:42:27,370 --> 00:42:38,740
read it while I enjoy this fine Diet

00:42:29,080 --> 00:42:41,710
Mountain Dew yeah

00:42:38,740 --> 00:42:44,950
Hyrum has made his point yet again I can

00:42:41,710 --> 00:42:46,750
admit I kind of knew this was gonna come

00:42:44,950 --> 00:42:50,560
I actually just submitted it so I would

00:42:46,750 --> 00:42:50,950
find out that's how I do a lot of my

00:42:50,560 --> 00:42:56,290
things

00:42:50,950 --> 00:42:58,990
Titus says I'm a monster wait a minute I

00:42:56,290 --> 00:43:02,050
want to see that last one again what are

00:42:58,990 --> 00:43:03,670
they doing here they're using an arena

00:43:02,050 --> 00:43:06,370
allocator to avoid a whole bunch of

00:43:03,670 --> 00:43:08,950
small allocations okay that makes sense

00:43:06,370 --> 00:43:11,050
but they only have a small bunch of

00:43:08,950 --> 00:43:16,420
small allocations because they're using

00:43:11,050 --> 00:43:19,840
a node hash set that's weird

00:43:16,420 --> 00:43:21,560
maybe I'll just clean this up because

00:43:19,840 --> 00:43:23,000
they have a whole bunch of small

00:43:21,560 --> 00:43:24,680
allocations and they're using a note

00:43:23,000 --> 00:43:29,420
let's just switch them to a flat hash

00:43:24,680 --> 00:43:31,430
set great that got a ton simpler anyone

00:43:29,420 --> 00:43:35,270
remember what stood hash of int is and

00:43:31,430 --> 00:43:37,490
most standard libraries I heard it over

00:43:35,270 --> 00:43:41,360
there oddly not from Marshall it's the

00:43:37,490 --> 00:43:46,310
identity yeah the identity turns out to

00:43:41,360 --> 00:43:50,770
have very poor entropy fortunately this

00:43:46,310 --> 00:43:55,130
is really easy to fix ah much better

00:43:50,770 --> 00:43:56,870
so here's my change it's boiled it up

00:43:55,130 --> 00:43:59,480
sent it to the owner of the code for

00:43:56,870 --> 00:44:01,580
review and I submitted it and it just

00:43:59,480 --> 00:44:03,310
slipped in no one noticed it's

00:44:01,580 --> 00:44:09,610
completely quiet for two weeks

00:44:03,310 --> 00:44:12,710
until I get an email out of nowhere as

00:44:09,610 --> 00:44:15,530
it turns out that hash table was at the

00:44:12,710 --> 00:44:18,860
core loop of Google's walking directions

00:44:15,530 --> 00:44:21,350
and walking directions in Japan has a

00:44:18,860 --> 00:44:24,320
higher connectedness for I don't know

00:44:21,350 --> 00:44:26,060
reasons the team had been unable to

00:44:24,320 --> 00:44:28,670
diagnose this issue using their CPU

00:44:26,060 --> 00:44:30,680
profiles they looked a little like this

00:44:28,670 --> 00:44:32,690
it's a bit hard to read so I'm gonna

00:44:30,680 --> 00:44:36,110
zoom in that was your hint that they're

00:44:32,690 --> 00:44:38,450
probing a lot unless you know deeply

00:44:36,110 --> 00:44:40,430
that that is our probe step you're

00:44:38,450 --> 00:44:44,000
probably not going to spot it for you

00:44:40,430 --> 00:44:45,830
but it comes out clear as day that your

00:44:44,000 --> 00:44:48,110
table has a very large probe length when

00:44:45,830 --> 00:44:52,130
you really can switch to it with good

00:44:48,110 --> 00:44:54,230
statistics so do you remember a pea

00:44:52,130 --> 00:44:56,420
prophec samples from before let's see

00:44:54,230 --> 00:44:59,120
how those are looked different with hash

00:44:56,420 --> 00:45:03,080
tables that are collected based on the

00:44:59,120 --> 00:45:04,460
profiling we've sort of built out so

00:45:03,080 --> 00:45:06,380
we're looking at the core loop of our

00:45:04,460 --> 00:45:09,440
benchmark it uses a ton of tables this

00:45:06,380 --> 00:45:10,790
isn't really surprising I'm going to

00:45:09,440 --> 00:45:14,240
assign to members the audience's

00:45:10,790 --> 00:45:16,220
external memory mr. gobble can you

00:45:14,240 --> 00:45:20,150
remember the first number six nine nine

00:45:16,220 --> 00:45:23,540
seven or about 7k all right mr. Marshall

00:45:20,150 --> 00:45:26,120
or mr. Clow can you remember the second

00:45:23,540 --> 00:45:27,500
number in the red call it 15k this is

00:45:26,120 --> 00:45:29,540
the sort of total number of tables

00:45:27,500 --> 00:45:31,610
allocated you have to remember these

00:45:29,540 --> 00:45:36,410
numbers if you don't it will really

00:45:31,610 --> 00:45:40,160
my entire talk so let's look at what

00:45:36,410 --> 00:45:41,660
metadata we got from this right our bad

00:45:40,160 --> 00:45:43,940
hash tables have really high probe

00:45:41,660 --> 00:45:45,710
lengths there are much more the other

00:45:43,940 --> 00:45:49,130
tags show up but like I'm just zooming

00:45:45,710 --> 00:45:53,900
in on the tags we want right now and our

00:45:49,130 --> 00:45:55,400
good tables not so high probe lengths so

00:45:53,900 --> 00:45:59,210
let's restrict ourself to only

00:45:55,400 --> 00:46:02,660
considering those tables with high probe

00:45:59,210 --> 00:46:04,760
lengths and see what happens we can set

00:46:02,660 --> 00:46:06,470
our tagged focus to say oh no only the

00:46:04,760 --> 00:46:10,430
tables whose probe length is 4 or more

00:46:06,470 --> 00:46:14,540
and our original we had how many do we

00:46:10,430 --> 00:46:17,990
have okay so about 7k and now we have

00:46:14,540 --> 00:46:20,320
about 7k so roughly a hundred percent of

00:46:17,990 --> 00:46:25,070
our tables had bad proplanx

00:46:20,320 --> 00:46:27,680
mr. cloud fifteen and a half k and now

00:46:25,070 --> 00:46:30,020
we're down to two K that's actually a

00:46:27,680 --> 00:46:31,730
huge reduction so here it's really easy

00:46:30,020 --> 00:46:34,910
to see which of these just has a

00:46:31,730 --> 00:46:36,470
pathological hash function perhaps or

00:46:34,910 --> 00:46:41,680
other tags can shed more interesting

00:46:36,470 --> 00:46:46,370
light what bits are stuck negative 2048

00:46:41,680 --> 00:46:50,330
write negative 2048 is actually most of

00:46:46,370 --> 00:46:54,920
our bits are stuck this is indeed a very

00:46:50,330 --> 00:46:56,420
poor hash function so we run these

00:46:54,920 --> 00:46:58,340
things in production we collect the data

00:46:56,420 --> 00:47:00,170
from them all the time we're building

00:46:58,340 --> 00:47:02,600
out pipelines as I speak in order to

00:47:00,170 --> 00:47:04,430
automatically surface to us issues that

00:47:02,600 --> 00:47:07,790
we can you know optimize and get

00:47:04,430 --> 00:47:09,920
promotions off of and every few weeks

00:47:07,790 --> 00:47:11,660
somebody just kind of im's me out of the

00:47:09,920 --> 00:47:13,190
blue and says like oh my god my hash

00:47:11,660 --> 00:47:16,820
table is bad what can I do

00:47:13,190 --> 00:47:19,580
and like the answers very usually it's

00:47:16,820 --> 00:47:23,420
stop writing your own hash use absol

00:47:19,580 --> 00:47:27,700
hash like nine times out of ten and the

00:47:23,420 --> 00:47:27,700
tenth time it's switched to an array

00:47:29,849 --> 00:47:35,770
so this global analysis stuff is really

00:47:33,040 --> 00:47:39,359
useful you just have to get something

00:47:35,770 --> 00:47:42,099
that shows you where your problems are

00:47:39,359 --> 00:47:43,089
I'm now going to open the Florida

00:47:42,099 --> 00:47:45,339
questions

00:47:43,089 --> 00:47:46,720
I might make you repeat or speak slowly

00:47:45,339 --> 00:47:58,000
because this room has a really weird

00:47:46,720 --> 00:48:00,190
echo when people talk I'm actually gonna

00:47:58,000 --> 00:48:03,490
warn the person on camera I'm gonna walk

00:48:00,190 --> 00:48:22,450
down towards the mic so that I can hear

00:48:03,490 --> 00:48:24,130
him by construction of the benchmarks

00:48:22,450 --> 00:48:26,320
the way that I knew it was hot in cash

00:48:24,130 --> 00:48:27,970
is that there are two ways I can start

00:48:26,320 --> 00:48:30,700
the benchmark one is that I make a

00:48:27,970 --> 00:48:32,859
single table and I hit it repeatedly and

00:48:30,700 --> 00:48:34,359
one is that I make a billion tables and

00:48:32,859 --> 00:48:35,950
I just kind of like round-robin through

00:48:34,359 --> 00:48:40,780
them so that they like just pollute my

00:48:35,950 --> 00:48:44,140
cash what in the design of the

00:48:40,780 --> 00:48:45,970
benchmarks I yeah no it's not done for

00:48:44,140 --> 00:48:47,710
us in the benchmarks that I wrote for

00:48:45,970 --> 00:48:51,400
hash tables which is actually open

00:48:47,710 --> 00:48:54,220
sourced there's a github slash Google

00:48:51,400 --> 00:48:56,589
slash hash table - benchmarks it's open

00:48:54,220 --> 00:48:57,730
I want to pull in everyone's hash table

00:48:56,589 --> 00:48:59,230
into it I want to have a good

00:48:57,730 --> 00:49:01,180
conversation about it

00:48:59,230 --> 00:49:03,550
Facebook's hash tables are already in

00:49:01,180 --> 00:49:05,200
there at 14 I've gotten a few of the

00:49:03,550 --> 00:49:08,200
Facebook people to help make sure I have

00:49:05,200 --> 00:49:09,580
the config for it correct like do it it

00:49:08,200 --> 00:49:11,290
also comes with like basic Python

00:49:09,580 --> 00:49:13,500
analysis scripts so you can compare

00:49:11,290 --> 00:49:13,500
these

00:49:20,980 --> 00:49:33,470
wait so you get the mic do these yes we

00:49:29,630 --> 00:49:36,200
did and we saw no appreciable benefit

00:49:33,470 --> 00:49:38,089
for going to 32 wide probing however it

00:49:36,200 --> 00:49:39,349
does make we did those experiments

00:49:38,089 --> 00:49:40,849
before we did the small table

00:49:39,349 --> 00:49:45,920
optimizations so it made your small

00:49:40,849 --> 00:49:47,960
tables ridiculously big and also not as

00:49:45,920 --> 00:49:54,829
many architectures have them and so you

00:49:47,960 --> 00:49:56,720
do restrict yourself a bit there yes we

00:49:54,829 --> 00:49:59,690
looked at Robin Hood probing and it was

00:49:56,720 --> 00:50:01,910
just a loss it turns out to be like all

00:49:59,690 --> 00:50:03,859
the extra complication logic in it like

00:50:01,910 --> 00:50:06,319
blows your inlining budgets blows your

00:50:03,859 --> 00:50:09,200
caches on that and the fact that you can

00:50:06,319 --> 00:50:11,390
just do a 16 deep probe like that just

00:50:09,200 --> 00:50:13,670
is made of such wind that be like I'm

00:50:11,390 --> 00:50:15,999
gonna let pack everything in my is not a

00:50:13,670 --> 00:50:15,999
big deal

00:50:22,580 --> 00:50:42,620
anyone else I really should have brought

00:50:27,320 --> 00:50:44,330
the Diet Mountain Dew absolutely so one

00:50:42,620 --> 00:50:47,360
of the one of the challenges that we had

00:50:44,330 --> 00:50:49,400
for this is we really wanted to fill the

00:50:47,360 --> 00:50:52,580
standards API so that we can do the

00:50:49,400 --> 00:50:54,290
conversions someone else at Google has a

00:50:52,580 --> 00:50:55,700
slightly faster hash table that they've

00:50:54,290 --> 00:50:58,220
implemented specifically for machine

00:50:55,700 --> 00:51:00,440
learning based on the core observation

00:50:58,220 --> 00:51:02,540
that in machine learning sometimes it's

00:51:00,440 --> 00:51:03,920
just okay not to insert things feel like

00:51:02,540 --> 00:51:05,270
you tried to insert they have too many

00:51:03,920 --> 00:51:08,240
collisions for that just go away

00:51:05,270 --> 00:51:10,190
and like that allows you to like have

00:51:08,240 --> 00:51:12,430
hard-coded constants for a lot of things

00:51:10,190 --> 00:51:15,830
that used to be unbounded loops

00:51:12,430 --> 00:51:17,570
they also said like well sure stood pair

00:51:15,830 --> 00:51:18,860
K V that's what the standard wants but I

00:51:17,570 --> 00:51:20,720
want to put all my keys here and all my

00:51:18,860 --> 00:51:22,220
values here and like if you could do

00:51:20,720 --> 00:51:25,250
that you get much better data packing

00:51:22,220 --> 00:51:27,170
also and so if you can weaken the

00:51:25,250 --> 00:51:30,100
standards requirements you can always

00:51:27,170 --> 00:51:32,600
find optimizations but we were

00:51:30,100 --> 00:51:36,610
restricting ourselves to implementing

00:51:32,600 --> 00:51:36,610
standard container mostly

00:51:50,520 --> 00:52:09,970
yes well so let's say I just put

00:52:07,360 --> 00:52:12,970
computing digits of pi in the body of

00:52:09,970 --> 00:52:16,980
make unique it's still conformant but

00:52:12,970 --> 00:52:20,530
it's not good like there is some implied

00:52:16,980 --> 00:52:22,330
guarantees about performance and when

00:52:20,530 --> 00:52:24,550
people have built production services

00:52:22,330 --> 00:52:26,920
and their service starts to fall over

00:52:24,550 --> 00:52:28,660
it's really hard to tell them like nah I

00:52:26,920 --> 00:52:30,520
just don't care that you're 10x slower

00:52:28,660 --> 00:52:38,410
like maybe you should have been nicer

00:52:30,520 --> 00:52:40,660
than me did they know they had a hash

00:52:38,410 --> 00:52:42,460
table they inserted things they got them

00:52:40,660 --> 00:52:44,710
out they expected their hash table to be

00:52:42,460 --> 00:52:46,150
fast I even told them this is the hash

00:52:44,710 --> 00:52:58,360
table you should use when they were like

00:52:46,150 --> 00:53:07,450
a shiny new noogler yes hiram please

00:52:58,360 --> 00:53:10,210
I suspect they do but I haven't found

00:53:07,450 --> 00:53:12,580
them yet and I'm afraid that if I turned

00:53:10,210 --> 00:53:14,800
off the randomization people would start

00:53:12,580 --> 00:53:18,300
relying on it not being there faster

00:53:14,800 --> 00:53:18,300
than they're relying on it being there

00:53:23,340 --> 00:53:27,280
Marshall makes the observation we give

00:53:25,330 --> 00:53:31,740
them consistent results 20% of the time

00:53:27,280 --> 00:53:34,270
hey I mean potentially it's also like

00:53:31,740 --> 00:53:36,700
wedging in randomization in your

00:53:34,270 --> 00:53:38,890
libraries at just the right points is

00:53:36,700 --> 00:53:42,070
very hard to do because you want it to

00:53:38,890 --> 00:53:43,960
be fast you want that and like I've gone

00:53:42,070 --> 00:53:45,640
off to calculate you know Bernoulli

00:53:43,960 --> 00:53:48,510
distribution is not a thing that people

00:53:45,640 --> 00:53:48,510
appreciate

00:53:53,650 --> 00:53:59,300
all right thank you

00:53:57,240 --> 00:53:59,300

YouTube URL: https://www.youtube.com/watch?v=JZE3_0qvrMg


