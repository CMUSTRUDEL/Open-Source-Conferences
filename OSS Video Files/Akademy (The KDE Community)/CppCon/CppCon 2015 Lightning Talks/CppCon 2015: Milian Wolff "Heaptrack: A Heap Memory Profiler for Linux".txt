Title: CppCon 2015: Milian Wolff "Heaptrack: A Heap Memory Profiler for Linux"
Publication date: 2015-10-21
Playlist: CppCon 2015 Lightning Talks
Description: 
	http://www.Cppcon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/cppcon/cppcon2015
—
Lightning Talk
— 
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,000 --> 00:00:05,310
Thanks welcome everyone um I'm you're

00:00:02,310 --> 00:00:08,970
cute KDE guy at this conference also my

00:00:05,310 --> 00:00:10,889
first one very excited so far and i have

00:00:08,970 --> 00:00:13,740
many hats on in my free time I

00:00:10,889 --> 00:00:16,470
contribute a lot to KDE big open source

00:00:13,740 --> 00:00:18,930
project using cute I maintain the K

00:00:16,470 --> 00:00:21,060
develop an ID if any one of you uses

00:00:18,930 --> 00:00:23,660
dead please drop by tell me what you

00:00:21,060 --> 00:00:25,410
think about that I work at kdub

00:00:23,660 --> 00:00:28,230
consultancy company in the cute

00:00:25,410 --> 00:00:30,300
ecosphere and C++ in general but yet

00:00:28,230 --> 00:00:34,350
today I wanted to talk about keep track

00:00:30,300 --> 00:00:37,530
um here are few uses massive or has used

00:00:34,350 --> 00:00:39,510
massive for heap profiling so few of

00:00:37,530 --> 00:00:41,850
human I hope you have used my

00:00:39,510 --> 00:00:45,030
visualization tool to actually interpret

00:00:41,850 --> 00:00:47,940
the results there um I did that tool

00:00:45,030 --> 00:00:50,969
five years ago so to actually figure out

00:00:47,940 --> 00:00:54,300
where your memory is being used in your

00:00:50,969 --> 00:00:56,160
application very useful got super good

00:00:54,300 --> 00:00:59,760
feedback about the visualization part

00:00:56,160 --> 00:01:02,280
there but I had a big issue with it it's

00:00:59,760 --> 00:01:04,920
super slow especially because valgrind

00:01:02,280 --> 00:01:08,340
synchronizes parallel code it easily

00:01:04,920 --> 00:01:09,930
leads to overhead of 100-plus or

00:01:08,340 --> 00:01:12,869
something like a hundred times that or

00:01:09,930 --> 00:01:15,030
something like that or even more and I

00:01:12,869 --> 00:01:18,140
always thought isn't it shouldn't it be

00:01:15,030 --> 00:01:21,210
possible to get something faster and

00:01:18,140 --> 00:01:23,729
while at it couldn't we collect more

00:01:21,210 --> 00:01:25,740
data massive only gives you like okay

00:01:23,729 --> 00:01:28,890
this function allocated this and that

00:01:25,740 --> 00:01:31,439
amount of memory but it is is not able

00:01:28,890 --> 00:01:34,009
to tell you wait a minute you actually

00:01:31,439 --> 00:01:37,799
called this function while this location

00:01:34,009 --> 00:01:39,509
100,000 times at this position or these

00:01:37,799 --> 00:01:42,119
are actually all temporary allocations

00:01:39,509 --> 00:01:43,680
maybe you want to get rid of that so I

00:01:42,119 --> 00:01:46,710
thought about that for a long long time

00:01:43,680 --> 00:01:48,659
and finally came up with the solution

00:01:46,710 --> 00:01:52,170
called heap track it's the open source

00:01:48,659 --> 00:01:54,869
tool you can get it on KDE get which is

00:01:52,170 --> 00:01:57,920
nowadays also being mirrored on github

00:01:54,869 --> 00:02:01,500
and you just run your application

00:01:57,920 --> 00:02:05,759
through heap track and it doesn't think

00:02:01,500 --> 00:02:09,239
it should be faster than massive um and

00:02:05,759 --> 00:02:11,370
then you can visualize the results I

00:02:09,239 --> 00:02:12,600
won't do the live coding here but if you

00:02:11,370 --> 00:02:15,920
want to see it too

00:02:12,600 --> 00:02:19,230
I hunt me down and help show it to you

00:02:15,920 --> 00:02:22,230
the analysis part then it's pretty cool

00:02:19,230 --> 00:02:24,120
as well I'm in the process of working on

00:02:22,230 --> 00:02:26,160
the UI you can generate massive files

00:02:24,120 --> 00:02:28,200
which you can then visualize the massive

00:02:26,160 --> 00:02:30,270
visualize if you really want to but

00:02:28,200 --> 00:02:32,100
that's not really fun because it takes a

00:02:30,270 --> 00:02:34,590
long time to generate a very very

00:02:32,100 --> 00:02:36,690
inefficient massive format so if you

00:02:34,590 --> 00:02:40,110
want to use my keep track format

00:02:36,690 --> 00:02:43,140
directly use keep check GUI and that

00:02:40,110 --> 00:02:45,420
directly gives you the number of

00:02:43,140 --> 00:02:50,130
allocations that have been done at a

00:02:45,420 --> 00:02:53,090
given code point in the peak memory

00:02:50,130 --> 00:02:56,730
allocation that resulted at this point

00:02:53,090 --> 00:03:00,750
you get the number of leak bite so

00:02:56,730 --> 00:03:03,480
essentially once you stop the process

00:03:00,750 --> 00:03:04,860
what hasn't been freed and then you can

00:03:03,480 --> 00:03:07,410
measure your throughput as well so

00:03:04,860 --> 00:03:10,020
allocated is just a bytes allocated in

00:03:07,410 --> 00:03:12,960
total ignoring any dia location anything

00:03:10,020 --> 00:03:16,200
like that and this is all with stack

00:03:12,960 --> 00:03:18,800
traces for every single allocation you

00:03:16,200 --> 00:03:21,930
do and it's still faster than massive

00:03:18,800 --> 00:03:24,870
the thing is I stand on the shoulders of

00:03:21,930 --> 00:03:27,170
giants there and i'll get to that I did

00:03:24,870 --> 00:03:30,000
not write the stag unwinder to do that

00:03:27,170 --> 00:03:33,680
you can both have a bottom-up and

00:03:30,000 --> 00:03:37,140
top-down view which is sometimes useful

00:03:33,680 --> 00:03:40,140
more importantly you still have the same

00:03:37,140 --> 00:03:42,840
visualization you know from massive

00:03:40,140 --> 00:03:44,730
visualizer so these stacked bar charts

00:03:42,840 --> 00:03:46,590
where the red one is the total amount of

00:03:44,730 --> 00:03:50,340
memory being used and below that you see

00:03:46,590 --> 00:03:53,160
the top allocating functions essentially

00:03:50,340 --> 00:03:55,860
you can hover it and get a tooltip and i

00:03:53,160 --> 00:03:57,870
will add all the interactive features as

00:03:55,860 --> 00:04:01,950
well so you can jump to a call stake and

00:03:57,870 --> 00:04:03,930
get more information out of it but as I

00:04:01,950 --> 00:04:07,220
said keep track gives you more than just

00:04:03,930 --> 00:04:10,260
a pure number of allocations right or

00:04:07,220 --> 00:04:12,600
allocated bytes it also counts how many

00:04:10,260 --> 00:04:16,020
allocations you have been doing here you

00:04:12,600 --> 00:04:18,270
see these nice spikes were tons of

00:04:16,020 --> 00:04:19,420
allocations in take place and this is

00:04:18,270 --> 00:04:21,880
actually

00:04:19,420 --> 00:04:24,850
the spell checker being used indicate

00:04:21,880 --> 00:04:28,420
edit or that is very inefficient when it

00:04:24,850 --> 00:04:31,210
comes to allocations and you also track

00:04:28,420 --> 00:04:33,790
the throughput so again the first spike

00:04:31,210 --> 00:04:36,280
here is the spell checker the second one

00:04:33,790 --> 00:04:38,740
is Intel's graphics driver which

00:04:36,280 --> 00:04:41,110
allocates a bunch of memory but it's

00:04:38,740 --> 00:04:43,330
probably fine but if you want to check

00:04:41,110 --> 00:04:47,890
that keep track gives you all the data

00:04:43,330 --> 00:04:49,840
at your hands and also something that

00:04:47,890 --> 00:04:52,530
I've been working on recently is adding

00:04:49,840 --> 00:04:56,350
a so-called flame graph visualization

00:04:52,530 --> 00:04:58,240
it's been invented by Brendan Greg very

00:04:56,350 --> 00:05:01,150
smart guy in the performance area and

00:04:58,240 --> 00:05:04,210
this one's really really neat the the

00:05:01,150 --> 00:05:06,760
width of each bar here gives you the

00:05:04,210 --> 00:05:09,850
cost so the wider something is the more

00:05:06,760 --> 00:05:11,740
it's fence or here it's the number of

00:05:09,850 --> 00:05:14,560
allocations of the more allocations of

00:05:11,740 --> 00:05:17,170
triggers and this way you can easily

00:05:14,560 --> 00:05:20,830
grasp the very complex call stack tree

00:05:17,170 --> 00:05:24,040
and just find hot spots in your code

00:05:20,830 --> 00:05:27,070
that you would not expect to be there so

00:05:24,040 --> 00:05:31,420
I really invite you all to try it out

00:05:27,070 --> 00:05:34,060
it's it's very useful thing one thing

00:05:31,420 --> 00:05:36,400
that I haven't yet added to the heap

00:05:34,060 --> 00:05:40,180
directly but I plan it's super simple to

00:05:36,400 --> 00:05:44,650
do is getting histogram so in the sense

00:05:40,180 --> 00:05:47,140
of what sizes has been have been

00:05:44,650 --> 00:05:50,770
requested by your application and how

00:05:47,140 --> 00:05:52,810
often and here this is a very sad bar

00:05:50,770 --> 00:05:55,630
chart for me or histogram because this

00:05:52,810 --> 00:05:58,960
is every typical cute application cute

00:05:55,630 --> 00:06:01,330
uses its own cue string yeah string

00:05:58,960 --> 00:06:05,530
class which is not small string

00:06:01,330 --> 00:06:07,690
optimized and you see thousands upon

00:06:05,530 --> 00:06:10,510
thousands I mean someone counted in

00:06:07,690 --> 00:06:12,490
acute application acute community think

00:06:10,510 --> 00:06:14,680
he said something like eighty percent or

00:06:12,490 --> 00:06:17,380
sixty percent of the allocations that

00:06:14,680 --> 00:06:20,890
acute application does normally our

00:06:17,380 --> 00:06:22,570
strings below what five jars or six jars

00:06:20,890 --> 00:06:25,330
or something like that it's it's silly

00:06:22,570 --> 00:06:28,960
but that's the case you and keep track

00:06:25,330 --> 00:06:30,390
again finds these things and can give

00:06:28,960 --> 00:06:32,310
you all the data you need

00:06:30,390 --> 00:06:34,800
then you can actually go in and maybe

00:06:32,310 --> 00:06:38,700
fix it right and we do plan to fix this

00:06:34,800 --> 00:06:40,740
for cute 6 by the way so how do i do it

00:06:38,700 --> 00:06:43,680
I said already I'm standing on the

00:06:40,740 --> 00:06:45,570
shoulders of giants um first thing first

00:06:43,680 --> 00:06:48,180
is for linux only because this is what i

00:06:45,570 --> 00:06:51,480
use to debug in profile and make things

00:06:48,180 --> 00:06:54,120
faster a que de pie often have to work

00:06:51,480 --> 00:06:56,070
on windows cute apps as well but because

00:06:54,120 --> 00:06:58,290
it's cross cross platform I can just

00:06:56,070 --> 00:07:00,120
compile the stuff on Linux make it

00:06:58,290 --> 00:07:03,990
faster and it will automatically be

00:07:00,120 --> 00:07:06,360
faster than Microsoft as well so um the

00:07:03,990 --> 00:07:08,960
first trick data slin explicit specific

00:07:06,360 --> 00:07:11,310
is the LD preload trick so you can just

00:07:08,960 --> 00:07:14,400
inject arbitrary code into your

00:07:11,310 --> 00:07:17,130
application before you started keep

00:07:14,400 --> 00:07:18,990
track also allows you to run time

00:07:17,130 --> 00:07:20,850
attached to application as running

00:07:18,990 --> 00:07:22,550
something that massif is not able to do

00:07:20,850 --> 00:07:26,280
because it cannot magically take

00:07:22,550 --> 00:07:29,460
executable injected into the vm and then

00:07:26,280 --> 00:07:31,710
run from there right but here i asked on

00:07:29,460 --> 00:07:34,830
Stack Overflow for the magic to do and

00:07:31,710 --> 00:07:36,450
someone showed me the elf code to do it

00:07:34,830 --> 00:07:39,480
and it actually works which is pretty

00:07:36,450 --> 00:07:42,270
cool so you can after 10 hours in check

00:07:39,480 --> 00:07:45,530
to your application see who is

00:07:42,270 --> 00:07:47,850
triggering this memory increase and then

00:07:45,530 --> 00:07:50,910
visualize it later on it works it's

00:07:47,850 --> 00:07:54,840
pretty cool lip unwind is what I'm using

00:07:50,910 --> 00:07:57,180
to grab the back traces its amazing

00:07:54,840 --> 00:07:59,550
library lots of arcane magic in there

00:07:57,180 --> 00:08:03,300
and it's super super fast I mean I can

00:07:59,550 --> 00:08:05,820
track millions of call stacks in seconds

00:08:03,300 --> 00:08:08,910
and it's it doesn't have that much

00:08:05,820 --> 00:08:11,700
overhead but if you try this out do

00:08:08,910 --> 00:08:13,590
build live online from get because there

00:08:11,700 --> 00:08:15,450
have been some performance optimizations

00:08:13,590 --> 00:08:19,920
and most Linux distributions shape a

00:08:15,450 --> 00:08:22,950
very old version of it and if I profile

00:08:19,920 --> 00:08:25,760
heap trick itself I see some spots in

00:08:22,950 --> 00:08:29,040
heaps in lip online which I hope to

00:08:25,760 --> 00:08:31,590
optimize in the future as well then

00:08:29,040 --> 00:08:33,510
there is lip back trace so unwind gives

00:08:31,590 --> 00:08:36,090
me instruction pointers and lip back

00:08:33,510 --> 00:08:39,330
trace I can then use to translate that

00:08:36,090 --> 00:08:41,700
to yeah basically from the dwarf data to

00:08:39,330 --> 00:08:42,680
get function names and line numbers and

00:08:41,700 --> 00:08:46,100
files and stuff like

00:08:42,680 --> 00:08:48,770
so again this is not my magic code this

00:08:46,100 --> 00:08:52,190
is existing code that I thankfully can

00:08:48,770 --> 00:08:54,860
use and then yeah the keep track GUI is

00:08:52,190 --> 00:08:58,430
what you use to actually visualize the

00:08:54,860 --> 00:09:00,830
stuff in stale installing heap track is

00:08:58,430 --> 00:09:03,200
pretty simple check it out run the sea

00:09:00,830 --> 00:09:06,649
make stuff what you would always do

00:09:03,200 --> 00:09:09,260
don't forget to enable optimizations so

00:09:06,649 --> 00:09:11,180
you should probably pass HD see make

00:09:09,260 --> 00:09:13,220
build type equals r l will step in for

00:09:11,180 --> 00:09:15,170
release because otherwise it's going to

00:09:13,220 --> 00:09:17,240
be slow right now it's a profiler you

00:09:15,170 --> 00:09:21,890
better install it with optimizations

00:09:17,240 --> 00:09:24,230
enabled and so you have to wrap up the

00:09:21,890 --> 00:09:26,180
good thing is it's it's very usable it's

00:09:24,230 --> 00:09:30,350
often much faster especially on embedded

00:09:26,180 --> 00:09:32,540
devices than massive you get tons of

00:09:30,350 --> 00:09:35,480
data out of it much more than you would

00:09:32,540 --> 00:09:37,250
advocate work from massive and it's also

00:09:35,480 --> 00:09:39,560
the foundation for more tools in the

00:09:37,250 --> 00:09:42,890
future I really plan to add features to

00:09:39,560 --> 00:09:44,420
track the P threat API to measure lock

00:09:42,890 --> 00:09:48,560
contention for example it should be

00:09:44,420 --> 00:09:51,410
trivial now the bad thing is that my UI

00:09:48,560 --> 00:09:52,940
part isn't finished yet there's some

00:09:51,410 --> 00:09:55,040
things that I really want to fix

00:09:52,940 --> 00:09:57,620
thankfully Cade up is now sponsoring me

00:09:55,040 --> 00:09:59,900
and for a few days to work on that

00:09:57,620 --> 00:10:02,029
full-time so over the next month's you

00:09:59,900 --> 00:10:03,589
will see something there and I think

00:10:02,029 --> 00:10:05,330
that more people should actually start

00:10:03,589 --> 00:10:08,779
using it because it's very time useful

00:10:05,330 --> 00:10:11,480
and I'll be a darkly part is again yeah

00:10:08,779 --> 00:10:13,760
it's learning specific I saw someone

00:10:11,480 --> 00:10:17,120
adding a VIN heaped record get up

00:10:13,760 --> 00:10:19,640
without telling me he used some other

00:10:17,120 --> 00:10:21,920
technique there to generate the same

00:10:19,640 --> 00:10:24,050
file format that i use and then you can

00:10:21,920 --> 00:10:26,870
use he trick we and get the same thing

00:10:24,050 --> 00:10:28,550
here and yeah if you want to track stack

00:10:26,870 --> 00:10:32,560
memory use massive i don't know any

00:10:28,550 --> 00:10:32,560

YouTube URL: https://www.youtube.com/watch?v=myDWLPBiHn0


