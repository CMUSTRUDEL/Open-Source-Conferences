Title: CppCon 2015: Matt P. Dziubinski "Algorithmic Differentiation: C++ & Extremum Estimation"
Publication date: 2015-10-21
Playlist: CppCon 2015 Lightning Talks
Description: 
	http://www.Cppcon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/cppcon/cppcon2015
—
Lightning Talk
— 
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,060 --> 00:00:03,929
so I'm going to talk about I'll do it

00:00:01,829 --> 00:00:07,020
with the differentiation C++ and extreme

00:00:03,929 --> 00:00:12,090
estimation and I guess I should start

00:00:07,020 --> 00:00:16,800
with the Y so what is it what do we need

00:00:12,090 --> 00:00:19,410
it for and when do we need it so the

00:00:16,800 --> 00:00:22,830
slide there's a few of them I'm just

00:00:19,410 --> 00:00:25,920
going to cover the subset but the full

00:00:22,830 --> 00:00:28,949
type is going to be available online so

00:00:25,920 --> 00:00:31,199
first let's start with the Y the

00:00:28,949 --> 00:00:33,719
scenario is is that we have a bunch of

00:00:31,199 --> 00:00:38,129
data which is usually the bunch of

00:00:33,719 --> 00:00:39,809
numbers that I'm going to call Y what we

00:00:38,129 --> 00:00:44,070
would like to understand about this data

00:00:39,809 --> 00:00:46,800
is to either something that explains how

00:00:44,070 --> 00:00:49,230
they come about or something that is

00:00:46,800 --> 00:00:52,710
going to tell us what the data is going

00:00:49,230 --> 00:00:55,289
to be in the future and the tool we use

00:00:52,710 --> 00:00:56,340
to do that is called a model which is

00:00:55,289 --> 00:01:00,930
used just a bunch of mathematical

00:00:56,340 --> 00:01:03,449
equations that explained us that what we

00:01:00,930 --> 00:01:07,220
need is to have some kind of connection

00:01:03,449 --> 00:01:10,380
between the model and the data and the

00:01:07,220 --> 00:01:12,600
idea is that we try to feed the model to

00:01:10,380 --> 00:01:15,960
the data so we would like to have

00:01:12,600 --> 00:01:19,200
something that either makes the model as

00:01:15,960 --> 00:01:22,350
close as possible to the data which is

00:01:19,200 --> 00:01:24,780
maximizing the closeness or something

00:01:22,350 --> 00:01:28,560
that at least tries to minimize the

00:01:24,780 --> 00:01:31,290
error all models are wrong some models

00:01:28,560 --> 00:01:34,740
are useful we might as well minimize the

00:01:31,290 --> 00:01:37,740
destroyed and see there are different

00:01:34,740 --> 00:01:40,020
names of four that is heavier

00:01:37,740 --> 00:01:41,520
overloading houston numerical computing

00:01:40,020 --> 00:01:44,220
sometimes it's called estimation

00:01:41,520 --> 00:01:45,840
sometimes called calibration something

00:01:44,220 --> 00:01:49,920
it's called training by Tori the same

00:01:45,840 --> 00:01:52,829
thing now the problem is in general we

00:01:49,920 --> 00:01:55,590
don't have a closed form solution that

00:01:52,829 --> 00:01:59,040
is going to tell us the answer it would

00:01:55,590 --> 00:02:01,920
be nice if the numbers are stowed prices

00:01:59,040 --> 00:02:03,390
we would really love to have a simple

00:02:01,920 --> 00:02:05,250
mathematical equation that tells you

00:02:03,390 --> 00:02:06,920
well this stock price is going to be

00:02:05,250 --> 00:02:09,690
exactly that many dollars in the future

00:02:06,920 --> 00:02:13,350
most of the time we don't seem to have

00:02:09,690 --> 00:02:15,630
something that works so the idea is to

00:02:13,350 --> 00:02:18,660
a mathematical equation that's going to

00:02:15,630 --> 00:02:21,450
tell us at least something reasonably

00:02:18,660 --> 00:02:26,210
approximately close by minimization or

00:02:21,450 --> 00:02:28,740
maximization in short by extremum and

00:02:26,210 --> 00:02:32,220
that brings us to numerical optimization

00:02:28,740 --> 00:02:35,130
because our model is a function that is

00:02:32,220 --> 00:02:36,960
a computer program that's the function

00:02:35,130 --> 00:02:40,440
that we would like to feed to the

00:02:36,960 --> 00:02:44,070
numerical data so the way we can

00:02:40,440 --> 00:02:46,320
optimize a function numerically to find

00:02:44,070 --> 00:02:48,810
the parameter that makes our model fit

00:02:46,320 --> 00:02:51,510
the data the most is by numerical

00:02:48,810 --> 00:02:54,810
optimization algorithms there are

00:02:51,510 --> 00:02:57,390
basically two classes of them the first

00:02:54,810 --> 00:03:00,090
one is derivative free the second one is

00:02:57,390 --> 00:03:01,620
gradient based so gradient based really

00:03:00,090 --> 00:03:04,490
means that it's just going to need a

00:03:01,620 --> 00:03:07,470
part of the riveters of a function and

00:03:04,490 --> 00:03:10,620
the derivative of a function tells you

00:03:07,470 --> 00:03:13,760
how much is the output of a function

00:03:10,620 --> 00:03:16,260
changing as I change the input

00:03:13,760 --> 00:03:18,420
parameters so you can think of the

00:03:16,260 --> 00:03:23,130
function being for instance as pit of a

00:03:18,420 --> 00:03:25,410
car or let's say let's roll with the

00:03:23,130 --> 00:03:28,620
speed of a car and the argument being

00:03:25,410 --> 00:03:31,260
the time now if you press the

00:03:28,620 --> 00:03:34,890
accelerator the speed of a car is

00:03:31,260 --> 00:03:38,730
changing right so the rate of change of

00:03:34,890 --> 00:03:41,040
the speed of a car given the rate of

00:03:38,730 --> 00:03:43,470
change in the time line that

00:03:41,040 --> 00:03:45,990
acceleration and acceleration is a

00:03:43,470 --> 00:03:48,480
derivative of a speed function with

00:03:45,990 --> 00:03:51,180
respect to time so the rate of change of

00:03:48,480 --> 00:03:53,640
the output given the rate of change in

00:03:51,180 --> 00:03:56,160
the input that's basically a derivative

00:03:53,640 --> 00:03:59,400
and you can imagine that's pretty useful

00:03:56,160 --> 00:04:00,870
if you try to find the parameter that

00:03:59,400 --> 00:04:03,690
gives you the best function value

00:04:00,870 --> 00:04:06,300
because the relative directly answers

00:04:03,690 --> 00:04:08,250
the question whether those tweaks you do

00:04:06,300 --> 00:04:11,700
in the parameters actually have any

00:04:08,250 --> 00:04:13,740
effect so the others that use

00:04:11,700 --> 00:04:15,570
derivatives that are often better

00:04:13,740 --> 00:04:18,140
they're often faster they're often more

00:04:15,570 --> 00:04:21,239
accurate there's only one problem

00:04:18,140 --> 00:04:23,810
we don't have formulas for derivatives

00:04:21,239 --> 00:04:26,530
either for most practical applications

00:04:23,810 --> 00:04:29,350
so that brings us to

00:04:26,530 --> 00:04:31,570
another layer of indirection now we

00:04:29,350 --> 00:04:34,330
would like to have a numerical algorithm

00:04:31,570 --> 00:04:36,400
going to differentiate out function and

00:04:34,330 --> 00:04:41,430
is going to tell us what is the

00:04:36,400 --> 00:04:45,040
numerical derivative of the function and

00:04:41,430 --> 00:04:48,310
where C++ programmers so preferably

00:04:45,040 --> 00:04:50,590
would like something that is fast but

00:04:48,310 --> 00:04:53,560
also something that is accurate it's

00:04:50,590 --> 00:04:55,480
kind of like the zero overhead principle

00:04:53,560 --> 00:04:59,410
we often like to have a no compromise

00:04:55,480 --> 00:05:02,110
compromise and it would be also nice if

00:04:59,410 --> 00:05:04,419
it's simple so that's essentially the

00:05:02,110 --> 00:05:07,720
idea behind rhythmic differentiation

00:05:04,419 --> 00:05:10,690
it's automatic it only is a chain rule

00:05:07,720 --> 00:05:15,010
which I'm going to explain and also as

00:05:10,690 --> 00:05:17,919
exact as it can be on a computer so when

00:05:15,010 --> 00:05:21,040
I say exact that means there is probably

00:05:17,919 --> 00:05:22,510
something that is not as exact so the

00:05:21,040 --> 00:05:25,210
question is how does it compare to

00:05:22,510 --> 00:05:27,130
different balance of methods and in

00:05:25,210 --> 00:05:28,660
order to explain that it would be a nice

00:05:27,130 --> 00:05:33,370
idea to look at how we can calculate

00:05:28,660 --> 00:05:34,900
derivatives on a computer so a bunch of

00:05:33,370 --> 00:05:38,470
approaches one of them is fine a

00:05:34,900 --> 00:05:40,450
different thing I'm mostly going to talk

00:05:38,470 --> 00:05:42,580
about order to differentiation ad

00:05:40,450 --> 00:05:45,580
there's also symbolic differentiation

00:05:42,580 --> 00:05:48,039
but they are related so starting with

00:05:45,580 --> 00:05:51,280
finite differencing let's go back to the

00:05:48,039 --> 00:05:53,260
example of a speed of a car and suppose

00:05:51,280 --> 00:05:56,770
that we denote the speed of a car with a

00:05:53,260 --> 00:06:00,310
letter F and the argument the letter X

00:05:56,770 --> 00:06:03,310
is time now if you would like to have

00:06:00,310 --> 00:06:07,150
some notion of acceleration of your car

00:06:03,310 --> 00:06:10,960
which it could do is to see how much

00:06:07,150 --> 00:06:14,700
time has passed how much has the speed

00:06:10,960 --> 00:06:18,070
increased and get the ratio of these two

00:06:14,700 --> 00:06:20,650
approximate the acceleration so that's

00:06:18,070 --> 00:06:23,380
pretty much all there is to finite

00:06:20,650 --> 00:06:26,260
differencing and that's the forward

00:06:23,380 --> 00:06:28,539
difference approximation basically

00:06:26,260 --> 00:06:31,330
approximate the derivative but the ratio

00:06:28,539 --> 00:06:34,720
of the changes this is a very easy

00:06:31,330 --> 00:06:36,490
method it's usually relatively fast if

00:06:34,720 --> 00:06:40,360
you have a small number of arguments

00:06:36,490 --> 00:06:42,550
it's usually not very accurate so

00:06:40,360 --> 00:06:45,219
what we improve is two central

00:06:42,550 --> 00:06:47,530
difference approximation which in a

00:06:45,219 --> 00:06:50,770
sense is twice as accurate but it's also

00:06:47,530 --> 00:06:53,289
twice as expensive so that's basically

00:06:50,770 --> 00:06:56,710
the outlay we could analyze this with

00:06:53,289 --> 00:07:00,819
some culturals and the bottom line is

00:06:56,710 --> 00:07:03,460
that the smaller this x that is the

00:07:00,819 --> 00:07:04,689
better the accuracy and that again kind

00:07:03,460 --> 00:07:06,610
of makes intuitive sense if you think

00:07:04,689 --> 00:07:09,819
about it because the step size is your

00:07:06,610 --> 00:07:12,189
resolution so if you were rendering the

00:07:09,819 --> 00:07:15,969
star graphically if you are trying to

00:07:12,189 --> 00:07:18,039
have a visualization that animates the

00:07:15,969 --> 00:07:20,800
motion of the car you can imagine that

00:07:18,039 --> 00:07:24,159
if you increase your resolution if you

00:07:20,800 --> 00:07:26,050
make those time steps smaller then the

00:07:24,159 --> 00:07:28,000
animation is going to become smoother

00:07:26,050 --> 00:07:31,529
because it's going to be more accurate

00:07:28,000 --> 00:07:34,509
so that's essentially the idea behind

00:07:31,529 --> 00:07:38,110
decreasing the step size as something

00:07:34,509 --> 00:07:41,560
that makes the approximation better well

00:07:38,110 --> 00:07:44,919
this idea is true in culturals calculus

00:07:41,560 --> 00:07:49,750
is true for real numbers do we have real

00:07:44,919 --> 00:07:52,750
numbers on computers we have something

00:07:49,750 --> 00:07:56,680
similar so it's called floating point

00:07:52,750 --> 00:07:58,419
numbers they are slightly different they

00:07:56,680 --> 00:08:02,139
are not associative they are not

00:07:58,419 --> 00:08:05,139
distributive here's an example you could

00:08:02,139 --> 00:08:09,250
have a bunch of numbers number a number

00:08:05,139 --> 00:08:14,620
B and number C and what we are going to

00:08:09,250 --> 00:08:18,550
do is to add a plus B plus C when we are

00:08:14,620 --> 00:08:20,379
going to add C plus B plus a and then we

00:08:18,550 --> 00:08:28,000
are going to see if there is any

00:08:20,379 --> 00:08:34,209
difference so what a plus B plus C that

00:08:28,000 --> 00:08:41,529
C plus B plus a so for so root and of

00:08:34,209 --> 00:08:44,380
the difference what mathematicians don't

00:08:41,529 --> 00:08:49,740
like floating point numbers because they

00:08:44,380 --> 00:08:52,600
are not really what they are used now

00:08:49,740 --> 00:08:55,480
the representation and the reason for

00:08:52,600 --> 00:08:58,660
floating point numbers this is not a C++

00:08:55,480 --> 00:09:02,050
standard but most held were follows the

00:08:58,660 --> 00:09:05,260
I Triple E 754 standard it's relatively

00:09:02,050 --> 00:09:08,140
similar to scientific notation so if you

00:09:05,260 --> 00:09:10,600
have ever seen something like 5 times 10

00:09:08,140 --> 00:09:12,579
raised to power 4 that's pretty much

00:09:10,600 --> 00:09:15,579
similar to how floating point numbers

00:09:12,579 --> 00:09:19,420
are stories except that we have to rise

00:09:15,579 --> 00:09:22,260
to some other power and the bottom line

00:09:19,420 --> 00:09:26,079
is that we basically have two main types

00:09:22,260 --> 00:09:29,380
float single precision and double double

00:09:26,079 --> 00:09:32,230
precision and there is a way you can

00:09:29,380 --> 00:09:32,890
measure their accuracy in a relative

00:09:32,230 --> 00:09:36,670
sense

00:09:32,890 --> 00:09:38,769
it's called machine Epsilon so you can

00:09:36,670 --> 00:09:41,920
imagine yourself standing on the number

00:09:38,769 --> 00:09:45,519
axis there is number one and then you

00:09:41,920 --> 00:09:47,290
ask what's the next number after dart so

00:09:45,519 --> 00:09:50,250
you can see that on real numbers you

00:09:47,290 --> 00:09:53,260
should be able to get arbitrarily small

00:09:50,250 --> 00:09:56,170
arbitrary close right there shouldn't be

00:09:53,260 --> 00:09:58,990
any gaps between number one and the

00:09:56,170 --> 00:10:01,240
number next after one while in floating

00:09:58,990 --> 00:10:03,190
point numbers there are gaps because we

00:10:01,240 --> 00:10:06,550
have only finite amount of memory on a

00:10:03,190 --> 00:10:09,430
computer so we cannot store numbers to

00:10:06,550 --> 00:10:12,130
infinite precision we have to stop the

00:10:09,430 --> 00:10:14,230
precision at some point and that point

00:10:12,130 --> 00:10:17,170
in terms of the floating point

00:10:14,230 --> 00:10:19,779
arithmetic is made by machine Epsilon so

00:10:17,170 --> 00:10:23,829
it tells you what is the gap around

00:10:19,779 --> 00:10:26,949
number one and for single precision

00:10:23,829 --> 00:10:28,779
that's going to be of size seven digits

00:10:26,949 --> 00:10:30,880
after the decimal point roughly in

00:10:28,779 --> 00:10:32,440
double precision that's going to be 16

00:10:30,880 --> 00:10:36,010
digit after the decimal point

00:10:32,440 --> 00:10:38,260
so the total accuracy around number one

00:10:36,010 --> 00:10:42,399
that you can represent is just sixteen

00:10:38,260 --> 00:10:44,410
digits and the reason those numbers are

00:10:42,399 --> 00:10:46,360
called floating-point numbers is that

00:10:44,410 --> 00:10:48,579
because this address is actually

00:10:46,360 --> 00:10:50,890
changing so if you move to a higher

00:10:48,579 --> 00:10:51,460
number you have less numbers after the

00:10:50,890 --> 00:10:54,000
decimal

00:10:51,460 --> 00:10:56,649
digits if you move close to zero

00:10:54,000 --> 00:10:59,080
sometimes you use something crazy and

00:10:56,649 --> 00:11:02,050
slow which is called subnormal don't

00:10:59,080 --> 00:11:06,640
worry about that let's say relative

00:11:02,050 --> 00:11:11,290
sense sixteen digits so what does it

00:11:06,640 --> 00:11:14,170
mean for us well there is an implication

00:11:11,290 --> 00:11:16,779
at some point those floating-point

00:11:14,170 --> 00:11:20,320
numbers that we are going to subtract

00:11:16,779 --> 00:11:22,330
are going to get close to each other so

00:11:20,320 --> 00:11:26,050
remember that in this approximation what

00:11:22,330 --> 00:11:28,600
we do is to subtract f of X from f of X

00:11:26,050 --> 00:11:31,540
plus h if you get closer and closer and

00:11:28,600 --> 00:11:33,339
closer at some point the result on the

00:11:31,540 --> 00:11:35,680
computer is going to tell you that the

00:11:33,339 --> 00:11:38,920
difference is zero even though on a

00:11:35,680 --> 00:11:42,760
piece of paper it would not be zero so

00:11:38,920 --> 00:11:43,510
the problem is as we make the step size

00:11:42,760 --> 00:11:45,670
smaller

00:11:43,510 --> 00:11:50,470
at some point there actually increases

00:11:45,670 --> 00:11:53,410
you can represent this graphically it

00:11:50,470 --> 00:11:55,690
looked like this so if this was just

00:11:53,410 --> 00:11:58,120
real numbers on a piece of paper we

00:11:55,690 --> 00:12:00,520
would only see the right half of this

00:11:58,120 --> 00:12:03,250
feeder and we would have the error

00:12:00,520 --> 00:12:05,650
decreasing as the step size grows

00:12:03,250 --> 00:12:08,320
smaller however because we have

00:12:05,650 --> 00:12:10,630
computers using finite amount of memory

00:12:08,320 --> 00:12:12,910
with finite precision floating point

00:12:10,630 --> 00:12:14,320
numbers at some point as we made the

00:12:12,910 --> 00:12:18,400
step size smaller and smaller smaller

00:12:14,320 --> 00:12:22,570
there're actually goes up so finite

00:12:18,400 --> 00:12:25,060
differences not very accurate next ideas

00:12:22,570 --> 00:12:28,060
to symbolic differentiation maybe we

00:12:25,060 --> 00:12:29,980
could encode the known formulas for

00:12:28,060 --> 00:12:31,690
derivative of every single expression

00:12:29,980 --> 00:12:32,740
there is at least every single

00:12:31,690 --> 00:12:37,029
expression that we're gonna use in our

00:12:32,740 --> 00:12:38,950
program problem is symbolic

00:12:37,029 --> 00:12:41,350
differentiation is mostly applicable to

00:12:38,950 --> 00:12:44,589
algebraic expression something you to

00:12:41,350 --> 00:12:45,970
write on a piece of paper and computer

00:12:44,589 --> 00:12:48,520
programs are again a little bit

00:12:45,970 --> 00:12:52,020
different but I happen to have those

00:12:48,520 --> 00:12:54,630
things called variables which well vary

00:12:52,020 --> 00:12:56,950
they also have program branches

00:12:54,630 --> 00:12:58,420
sometimes you have a function that calls

00:12:56,950 --> 00:13:01,000
a function that was another function

00:12:58,420 --> 00:13:03,040
that maybe has a if statement that goes

00:13:01,000 --> 00:13:05,059
to one place to another and this could

00:13:03,040 --> 00:13:06,919
all be overwritten you

00:13:05,059 --> 00:13:08,989
take that and iterate at a bunch of

00:13:06,919 --> 00:13:12,469
times so that usually doesn't happen on

00:13:08,989 --> 00:13:13,969
that piece of paper so are we back to

00:13:12,469 --> 00:13:15,619
square one should we go back to find

00:13:13,969 --> 00:13:17,179
differences well no we would like to

00:13:15,619 --> 00:13:18,559
have our cake and eat it too

00:13:17,179 --> 00:13:21,499
we would like to have something that is

00:13:18,559 --> 00:13:24,049
automatic but also is going to be as

00:13:21,499 --> 00:13:26,659
exact as it can be even comparable to

00:13:24,049 --> 00:13:29,029
simple differentiation so that's all the

00:13:26,659 --> 00:13:31,279
with me differentiation it's actually

00:13:29,029 --> 00:13:32,059
been around since 1960s it just happened

00:13:31,279 --> 00:13:34,909
to be called the back propagation

00:13:32,059 --> 00:13:37,339
algorithm for machine learning in the

00:13:34,909 --> 00:13:38,299
context of neural networks the idea is

00:13:37,339 --> 00:13:40,159
very simple

00:13:38,299 --> 00:13:42,349
it's especially appealing if you have

00:13:40,159 --> 00:13:44,539
been accustomed to functional

00:13:42,349 --> 00:13:48,069
programming you can think of your

00:13:44,539 --> 00:13:51,589
function f or any numerical function as

00:13:48,069 --> 00:13:54,499
a composition of the functions that are

00:13:51,589 --> 00:13:56,929
called by that function may be those

00:13:54,499 --> 00:13:59,209
functions also operators may be those

00:13:56,929 --> 00:14:01,729
are other functions that inside have

00:13:59,209 --> 00:14:04,339
operators but at the end it's basically

00:14:01,729 --> 00:14:06,229
just a bunch of functions so if you

00:14:04,339 --> 00:14:07,999
would like to obtain a derivative of

00:14:06,229 --> 00:14:11,179
this function to just use the chain rule

00:14:07,999 --> 00:14:12,769
and that's the only thing from calculus

00:14:11,179 --> 00:14:14,659
you have to know to understand finite

00:14:12,769 --> 00:14:16,849
differences it's just we understand

00:14:14,659 --> 00:14:26,209
algorithm the differentiation does it

00:14:16,849 --> 00:14:27,589
work well rigor says sometimes a

00:14:26,209 --> 00:14:29,689
thousand volts I think I'm just

00:14:27,589 --> 00:14:31,789
anesthesia the feeder there are two

00:14:29,689 --> 00:14:35,839
parameters in my model that I'm

00:14:31,789 --> 00:14:39,439
interested in parameter a and parameter

00:14:35,839 --> 00:14:42,429
B so that's equation number three and

00:14:39,439 --> 00:14:46,339
that's the only thing that matters here

00:14:42,429 --> 00:14:49,119
let's see if this works I'm going to

00:14:46,339 --> 00:14:52,129
simulate the data from this model and

00:14:49,119 --> 00:14:54,139
I'm just going to give it some secret

00:14:52,129 --> 00:14:56,449
values that I'm not going to share with

00:14:54,139 --> 00:14:58,429
the numerical optimizer I'm just going

00:14:56,449 --> 00:15:04,189
to teach it to myself that a should be

00:14:58,429 --> 00:15:05,719
really 0.10 B should be 0.85 let's do it

00:15:04,189 --> 00:15:10,219
a bunch of times so let's see if we can

00:15:05,719 --> 00:15:12,949
recover them so this is the algorithmic

00:15:10,219 --> 00:15:16,519
differentiation you can see that we have

00:15:12,949 --> 00:15:17,840
parameter a parameter B 10,000

00:15:16,519 --> 00:15:21,350
simulations and it's

00:15:17,840 --> 00:15:26,240
imagine point now this is finite

00:15:21,350 --> 00:15:29,390
differences this is a bit noisier and I

00:15:26,240 --> 00:15:32,990
actually cheated what I did is to cheat

00:15:29,390 --> 00:15:35,330
to my disadvantage and give finite

00:15:32,990 --> 00:15:37,120
differences a chance by picking and

00:15:35,330 --> 00:15:39,350
choosing to a better optimization

00:15:37,120 --> 00:15:43,850
algorithm actually resulted in better

00:15:39,350 --> 00:15:46,370
values for final differences so the

00:15:43,850 --> 00:15:50,780
difference is basically ninety nine

00:15:46,370 --> 00:15:53,150
point four nine percent successful

00:15:50,780 --> 00:15:56,360
convergence for allele differentiation

00:15:53,150 --> 00:15:59,750
and something like 3 percent or final

00:15:56,360 --> 00:16:02,360
differences that's it there are more

00:15:59,750 --> 00:16:05,240
slides more explanations best thing of

00:16:02,360 --> 00:16:07,340
all if you would like to use this there

00:16:05,240 --> 00:16:10,160
is a bunch of awesome open-source

00:16:07,340 --> 00:16:12,320
libraries that also worked with linear

00:16:10,160 --> 00:16:18,200
algebra libraries like I den which I

00:16:12,320 --> 00:16:20,290
highly recommend so check it out thank

00:16:18,200 --> 00:16:20,290

YouTube URL: https://www.youtube.com/watch?v=3be3fznNiPk


