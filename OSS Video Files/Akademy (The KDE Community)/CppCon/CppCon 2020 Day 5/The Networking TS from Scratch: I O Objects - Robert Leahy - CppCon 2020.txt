Title: The Networking TS from Scratch: I O Objects - Robert Leahy - CppCon 2020
Publication date: 2020-10-04
Playlist: CppCon 2020 Day 5
Description: 
	https://cppcon.org/
https://github.com/CppCon/CppCon2020/blob/main/Presentations/the_networking_ts_from_scratch_io_objects/the_networking_ts_from_scratch_io_objects__robert_leahy__cppcon_2020.pdf
---
The facilities of the Networking TS provide a framework within which testable, extensible, asynchronous programs may be written in C++. Alongside this the Networking TS provides concrete “I/O object” types which provide means of performing I/O and thereby allow the authoring of such programs immediately.

Invariably these provided I/O objects will not be sufficient. Datagram and stream sockets do not describe the entire universe of asynchronous I/O. When the time comes to author new I/O objects it will be important to do so within the framework of the Networking TS thereby providing facilities ripe for reuse and composition.

The talk will explore the task of authoring new I/O object types by motivating and illustrating the facilities and patterns the Networking TS provides for this purpose.

---
Robert is a graduate of the University of Victoria where he specialized in graphics, gaming, and digital geometry processing. After 4.5 years in full stack web development he switched to financial infrastructure software development in early 2017. He’s since become involved in the ISO C++ committee while delivering high quality, process-driven code to meet the rigorous performance standards for which finance is so well known.

---
Streamed & Edited by Digital Medium Ltd - events.digital-medium.co.uk
events@digital-medium.co.uk
Captions: 
	00:00:09,200 --> 00:00:13,840
when a new

00:00:10,000 --> 00:00:14,880
pattern or practice a new library or

00:00:13,840 --> 00:00:17,359
feature

00:00:14,880 --> 00:00:20,240
arrives on the scene the first

00:00:17,359 --> 00:00:23,119
instinctual thing we as developers do

00:00:20,240 --> 00:00:24,640
is rush to see what we can build on top

00:00:23,119 --> 00:00:27,359
of it

00:00:24,640 --> 00:00:29,279
what element of our workflow is directly

00:00:27,359 --> 00:00:32,320
improved by this new feature

00:00:29,279 --> 00:00:35,520
or library what does it make

00:00:32,320 --> 00:00:38,800
possible how does it reimagine problems

00:00:35,520 --> 00:00:42,000
we thought we had already solved

00:00:38,800 --> 00:00:42,960
but this vertical integration is not the

00:00:42,000 --> 00:00:45,840
only rubric

00:00:42,960 --> 00:00:47,760
on which we should judge new features we

00:00:45,840 --> 00:00:49,600
shouldn't judge new features based just

00:00:47,760 --> 00:00:52,559
on what we can do with the closed

00:00:49,600 --> 00:00:54,239
set of features that library for example

00:00:52,559 --> 00:00:56,960
comes with

00:00:54,239 --> 00:00:58,640
there's another dimension to the problem

00:00:56,960 --> 00:01:01,680
how can we widen

00:00:58,640 --> 00:01:05,760
the base of that library how can we

00:01:01,680 --> 00:01:08,000
widen the base of that feature

00:01:05,760 --> 00:01:10,159
and in accordance with this formulation

00:01:08,000 --> 00:01:11,840
in the previous two years i gave talks

00:01:10,159 --> 00:01:13,520
about the networking ts where i talked

00:01:11,840 --> 00:01:15,600
about how we could integrate with it

00:01:13,520 --> 00:01:17,360
vertically how we could take the

00:01:15,600 --> 00:01:19,840
features that come out of the box

00:01:17,360 --> 00:01:20,880
build on top of those and use them to

00:01:19,840 --> 00:01:24,880
build powerful

00:01:20,880 --> 00:01:26,560
expressive applications now this year

00:01:24,880 --> 00:01:28,799
i would like to loop back and examine

00:01:26,560 --> 00:01:32,240
something more nuanced and complicated

00:01:28,799 --> 00:01:35,360
but just as essential how can we widen

00:01:32,240 --> 00:01:35,840
the base of the networking ts how can we

00:01:35,360 --> 00:01:38,479
author

00:01:35,840 --> 00:01:40,240
entirely new i o objects that stand

00:01:38,479 --> 00:01:43,119
beside the networking ts

00:01:40,240 --> 00:01:45,840
as a fully integrated consistent part of

00:01:43,119 --> 00:01:48,000
that ecosystem

00:01:45,840 --> 00:01:49,759
but before we jump into that problem

00:01:48,000 --> 00:01:50,799
let's talk a bit about the status of the

00:01:49,759 --> 00:01:54,000
networking ts

00:01:50,799 --> 00:01:55,840
itself just as in previous years the

00:01:54,000 --> 00:02:00,079
networking ts is blocked on

00:01:55,840 --> 00:02:01,520
executors the paper p04443

00:02:00,079 --> 00:02:03,759
for those of us who want to use the

00:02:01,520 --> 00:02:05,840
features of networking this might seem

00:02:03,759 --> 00:02:07,680
annoying it might be frustrating that we

00:02:05,840 --> 00:02:09,599
can't just use networking

00:02:07,680 --> 00:02:11,440
maybe we don't directly care about

00:02:09,599 --> 00:02:14,319
executors

00:02:11,440 --> 00:02:16,319
but is that really true one of the

00:02:14,319 --> 00:02:18,000
things that asynchronous operations do

00:02:16,319 --> 00:02:19,200
is they schedule work to run in the

00:02:18,000 --> 00:02:22,000
background

00:02:19,200 --> 00:02:24,800
this is in fact exactly how they signal

00:02:22,000 --> 00:02:27,920
that those operations have completed

00:02:24,800 --> 00:02:29,760
it's what makes them asynchronous and

00:02:27,920 --> 00:02:32,480
this is exactly the problem the

00:02:29,760 --> 00:02:34,000
executor's effort sets out to solve

00:02:32,480 --> 00:02:36,959
and so if the committee were to

00:02:34,000 --> 00:02:38,959
standardize networking before executors

00:02:36,959 --> 00:02:40,720
we may end up with two divergent or

00:02:38,959 --> 00:02:43,360
conflicting ways of solving

00:02:40,720 --> 00:02:46,560
exactly the same problem which wouldn't

00:02:43,360 --> 00:02:48,239
be very healthy for the ecosystem

00:02:46,560 --> 00:02:50,080
and so we should be happy that the

00:02:48,239 --> 00:02:51,360
committee is holding back a bit

00:02:50,080 --> 00:02:53,760
happy that we're going to get a

00:02:51,360 --> 00:02:56,080
consistent integrated ecosystem

00:02:53,760 --> 00:02:56,879
happy that hopefully all things going

00:02:56,080 --> 00:02:59,599
well

00:02:56,879 --> 00:03:01,599
notwithstanding even more black swans in

00:02:59,599 --> 00:03:04,080
our already tumultuous universe

00:03:01,599 --> 00:03:04,800
networking and executives will land in c

00:03:04,080 --> 00:03:08,480
plus

00:03:04,800 --> 00:03:10,800
23. but if you do want to use

00:03:08,480 --> 00:03:12,400
executors and networking today or at

00:03:10,800 --> 00:03:13,440
least use what we think they'll look

00:03:12,400 --> 00:03:16,800
like when they land in c

00:03:13,440 --> 00:03:18,480
plus 23 you don't need to wait you don't

00:03:16,800 --> 00:03:20,800
need to despair

00:03:18,480 --> 00:03:22,879
because these are library only features

00:03:20,800 --> 00:03:24,640
and boost azio and its standalone

00:03:22,879 --> 00:03:27,920
version which is not part of boost

00:03:24,640 --> 00:03:29,519
azio ship these features today and have

00:03:27,920 --> 00:03:30,400
been shipping various version of these

00:03:29,519 --> 00:03:32,879
features for

00:03:30,400 --> 00:03:33,680
over a decade and so if you want to use

00:03:32,879 --> 00:03:36,879
those features

00:03:33,680 --> 00:03:39,120
just download azio or standalone asio

00:03:36,879 --> 00:03:41,040
this is in fact exactly what i've done

00:03:39,120 --> 00:03:42,080
to prepare the code samples on these

00:03:41,040 --> 00:03:44,080
slides

00:03:42,080 --> 00:03:46,480
i've used the very latest version of

00:03:44,080 --> 00:03:47,519
azio which allows me to demonstrate the

00:03:46,480 --> 00:03:50,959
pathway forward

00:03:47,519 --> 00:03:52,720
for integrating networking with p0443

00:03:50,959 --> 00:03:54,959
something that i'll touch on later in

00:03:52,720 --> 00:03:58,319
the presentation when the opportunity

00:03:54,959 --> 00:03:58,840
arises now let's move to the networking

00:03:58,319 --> 00:04:01,040
ts

00:03:58,840 --> 00:04:02,319
itself actual code written with the

00:04:01,040 --> 00:04:04,480
networking ts

00:04:02,319 --> 00:04:05,840
the things we can actually do with it

00:04:04,480 --> 00:04:07,920
let's look and see what we did

00:04:05,840 --> 00:04:09,599
in previous years and see if we can find

00:04:07,920 --> 00:04:12,560
the hole we're going to fill

00:04:09,599 --> 00:04:14,000
this year two years ago i introduced the

00:04:12,560 --> 00:04:16,239
sequence diagram

00:04:14,000 --> 00:04:17,120
i introduced this asynchronous operation

00:04:16,239 --> 00:04:19,519
async weight

00:04:17,120 --> 00:04:20,479
then right which does exactly what it

00:04:19,519 --> 00:04:22,320
says on the can

00:04:20,479 --> 00:04:24,560
it waits for some amount of time and

00:04:22,320 --> 00:04:26,479
then writes some number of bytes

00:04:24,560 --> 00:04:28,639
the initiator the person who kicks the

00:04:26,479 --> 00:04:29,840
operation off gets the ball rolling with

00:04:28,639 --> 00:04:32,240
async weight

00:04:29,840 --> 00:04:33,199
and then his or her lifetime abruptly

00:04:32,240 --> 00:04:34,880
ends

00:04:33,199 --> 00:04:37,280
this is definitional of asynchronous

00:04:34,880 --> 00:04:38,880
operations if the initiator was waiting

00:04:37,280 --> 00:04:41,199
around for the completion

00:04:38,880 --> 00:04:42,000
it would be a synchronous operation not

00:04:41,199 --> 00:04:45,199
an asynchronous

00:04:42,000 --> 00:04:48,240
operation the timer then proceeds in the

00:04:45,199 --> 00:04:50,160
background until it posts to an executor

00:04:48,240 --> 00:04:51,840
an executor as we discussed in previous

00:04:50,160 --> 00:04:52,880
years is a handle to an execution

00:04:51,840 --> 00:04:54,560
context

00:04:52,880 --> 00:04:56,720
some place that our submitted function

00:04:54,560 --> 00:04:58,560
objects can be invoked

00:04:56,720 --> 00:05:00,639
and in accordance with this formulation

00:04:58,560 --> 00:05:01,360
there is thereafter the invocation of a

00:05:00,639 --> 00:05:03,680
function call

00:05:01,360 --> 00:05:05,039
operator of a completion handler a

00:05:03,680 --> 00:05:07,680
function object which handles the

00:05:05,039 --> 00:05:11,280
completion of an asynchronous operation

00:05:07,680 --> 00:05:12,080
in this case async weight but waiting

00:05:11,280 --> 00:05:14,479
isn't all we're

00:05:12,080 --> 00:05:15,440
setting out to do we're setting out to

00:05:14,479 --> 00:05:18,080
wait and then

00:05:15,440 --> 00:05:20,479
write and so this isn't really a final

00:05:18,080 --> 00:05:22,800
completion handler it's an intermediary

00:05:20,479 --> 00:05:24,160
its job is to layer on top some higher

00:05:22,800 --> 00:05:26,000
level logic

00:05:24,160 --> 00:05:27,280
and implement the entire asynchronous

00:05:26,000 --> 00:05:28,960
operation

00:05:27,280 --> 00:05:31,440
and so this intermediate completion

00:05:28,960 --> 00:05:33,440
handler turns around and kicks off async

00:05:31,440 --> 00:05:34,960
write on a socket or some other kind of

00:05:33,440 --> 00:05:37,759
stream

00:05:34,960 --> 00:05:38,560
now async write itself is made up of

00:05:37,759 --> 00:05:40,479
parts

00:05:38,560 --> 00:05:41,840
it's made up of zero or more calls to

00:05:40,479 --> 00:05:43,840
async write some

00:05:41,840 --> 00:05:45,120
and so these proceed until all the bytes

00:05:43,840 --> 00:05:45,840
are written or there's some error

00:05:45,120 --> 00:05:47,759
condition

00:05:45,840 --> 00:05:48,880
there's a post to an executor and then

00:05:47,759 --> 00:05:52,320
the operation

00:05:48,880 --> 00:05:54,479
finally ends this pattern

00:05:52,320 --> 00:05:56,319
of bringing together higher level logic

00:05:54,479 --> 00:05:58,160
from smaller parts is what we studied in

00:05:56,319 --> 00:06:00,240
the previous two years

00:05:58,160 --> 00:06:01,440
we learned about composed asynchronous

00:06:00,240 --> 00:06:02,960
operations

00:06:01,440 --> 00:06:04,639
we learned how we can iteratively

00:06:02,960 --> 00:06:06,560
construct higher and higher level

00:06:04,639 --> 00:06:09,680
asynchronous logic until

00:06:06,560 --> 00:06:11,199
eventually maybe we can implement our

00:06:09,680 --> 00:06:14,160
entire application

00:06:11,199 --> 00:06:15,440
as one invocation of one highly generic

00:06:14,160 --> 00:06:18,960
highly reusable

00:06:15,440 --> 00:06:22,160
testable initiating function

00:06:18,960 --> 00:06:23,039
in main and the techniques we used to

00:06:22,160 --> 00:06:25,360
accomplish this

00:06:23,039 --> 00:06:27,360
were first and foremost templates and

00:06:25,360 --> 00:06:29,600
named type requirements

00:06:27,360 --> 00:06:30,960
to obtain the kind of generic code that

00:06:29,600 --> 00:06:32,800
we would need

00:06:30,960 --> 00:06:35,120
we can't write truly generic code if

00:06:32,800 --> 00:06:36,560
we're married to sockets and timers of

00:06:35,120 --> 00:06:38,319
concrete types

00:06:36,560 --> 00:06:40,080
and so instead we took a step back and

00:06:38,319 --> 00:06:42,319
realized that we didn't care that we

00:06:40,080 --> 00:06:44,160
were actually working with a socket

00:06:42,319 --> 00:06:46,240
all we cared was that we could write

00:06:44,160 --> 00:06:48,400
some number of bytes

00:06:46,240 --> 00:06:51,039
we didn't care about the socket-ness we

00:06:48,400 --> 00:06:52,960
cared that it was an async right stream

00:06:51,039 --> 00:06:55,199
and so we leveraged generic programming

00:06:52,960 --> 00:06:59,039
to get the benefits of polymorphism

00:06:55,199 --> 00:07:01,120
and static typing but to increase the

00:06:59,039 --> 00:07:03,599
flexibility and power of the ecosystem

00:07:01,120 --> 00:07:05,759
even further that's not all we did

00:07:03,599 --> 00:07:07,520
we deferred to customization points laid

00:07:05,759 --> 00:07:09,599
out by the networking ts

00:07:07,520 --> 00:07:10,800
which allowed our users to inject their

00:07:09,599 --> 00:07:12,400
concerns

00:07:10,800 --> 00:07:15,120
which saved us from having to make

00:07:12,400 --> 00:07:16,560
arbitrary decisions on their behalf

00:07:15,120 --> 00:07:19,039
decisions which were practically

00:07:16,560 --> 00:07:21,360
guaranteed to be incorrect

00:07:19,039 --> 00:07:23,280
for example writing some bytes says

00:07:21,360 --> 00:07:25,039
nothing about parallelism or

00:07:23,280 --> 00:07:27,440
synchronization

00:07:25,039 --> 00:07:29,039
but because at the end of the operation

00:07:27,440 --> 00:07:30,960
we're going to need to submit some work

00:07:29,039 --> 00:07:33,199
for background execution

00:07:30,960 --> 00:07:34,400
we're stuck in this quagmire where maybe

00:07:33,199 --> 00:07:36,560
we have to make a choice about

00:07:34,400 --> 00:07:38,720
parallelism and synchronization

00:07:36,560 --> 00:07:39,759
but at our level of analysis our level

00:07:38,720 --> 00:07:42,880
of context

00:07:39,759 --> 00:07:44,000
we don't know which decision to make and

00:07:42,880 --> 00:07:45,919
so the networking ts

00:07:44,000 --> 00:07:47,680
provides us with mechanisms for allowing

00:07:45,919 --> 00:07:50,400
users to make those decisions

00:07:47,680 --> 00:07:52,400
for us in this case rather than going

00:07:50,400 --> 00:07:54,720
off and choosing some execution context

00:07:52,400 --> 00:07:56,960
for the user's final completion handler

00:07:54,720 --> 00:07:58,639
we defer to the executor association

00:07:56,960 --> 00:07:59,520
that that completion handler carries

00:07:58,639 --> 00:08:01,759
with it

00:07:59,520 --> 00:08:03,360
which customizes the means by which that

00:08:01,759 --> 00:08:06,319
completion handler is invoked

00:08:03,360 --> 00:08:07,280
at every level which allows the user at

00:08:06,319 --> 00:08:09,199
the top level

00:08:07,280 --> 00:08:10,639
knowing all their requirements seeing

00:08:09,199 --> 00:08:12,639
the whole application

00:08:10,639 --> 00:08:14,560
to inject their requirements regarding

00:08:12,639 --> 00:08:17,520
parallelism and synchronization

00:08:14,560 --> 00:08:19,919
down to us so we don't need to make that

00:08:17,520 --> 00:08:19,919
decision

00:08:20,240 --> 00:08:25,520
but we already knew all this we studied

00:08:22,720 --> 00:08:28,240
this in the previous two years

00:08:25,520 --> 00:08:31,520
so where's the hole in our understanding

00:08:28,240 --> 00:08:33,279
what are we trying to fill in this year

00:08:31,520 --> 00:08:34,880
let's take another look at that sequence

00:08:33,279 --> 00:08:37,039
diagram

00:08:34,880 --> 00:08:38,240
after the review we now understand that

00:08:37,039 --> 00:08:40,240
it's within our power

00:08:38,240 --> 00:08:41,760
within our knowledge to implement this

00:08:40,240 --> 00:08:43,519
entire operation

00:08:41,760 --> 00:08:46,080
we can string together the constituent

00:08:43,519 --> 00:08:47,680
parts and project the operation upwards

00:08:46,080 --> 00:08:49,519
to the next level of consumer in the

00:08:47,680 --> 00:08:51,120
stack and

00:08:49,519 --> 00:08:53,519
carrying on with this we could implement

00:08:51,120 --> 00:08:54,320
async right we have the power to string

00:08:53,519 --> 00:08:58,560
together zero

00:08:54,320 --> 00:08:58,560
or more calls to async right some

00:08:58,800 --> 00:09:05,920
but what about async weight what about

00:09:02,240 --> 00:09:06,320
async right some they're just presented

00:09:05,920 --> 00:09:09,360
as

00:09:06,320 --> 00:09:11,680
black boxes as atomic

00:09:09,360 --> 00:09:15,040
taken for granted bits of functionality

00:09:11,680 --> 00:09:18,720
that ship with the networking ts

00:09:15,040 --> 00:09:20,640
how could we build one of these

00:09:18,720 --> 00:09:22,640
how could we build the baseline

00:09:20,640 --> 00:09:24,720
asynchronous operations that our

00:09:22,640 --> 00:09:25,519
formulation of composed asynchronous

00:09:24,720 --> 00:09:28,399
operations

00:09:25,519 --> 00:09:30,800
depends on after all composing

00:09:28,399 --> 00:09:32,720
asynchronous operations is useless

00:09:30,800 --> 00:09:34,160
if there are no asynchronous operations

00:09:32,720 --> 00:09:36,320
to compose

00:09:34,160 --> 00:09:38,640
and while you can reflexively compose

00:09:36,320 --> 00:09:40,480
composed asynchronous operations

00:09:38,640 --> 00:09:42,720
at some level and out of analysis you're

00:09:40,480 --> 00:09:44,480
going to reach the bottom layer

00:09:42,720 --> 00:09:46,560
you're going to need to bootstrap all

00:09:44,480 --> 00:09:49,360
these guarantees and practices

00:09:46,560 --> 00:09:51,200
from nothing and indeed if you think

00:09:49,360 --> 00:09:52,800
about this formulation in the context of

00:09:51,200 --> 00:09:54,640
what we did in previous years

00:09:52,800 --> 00:09:56,320
you'll realize that while our operations

00:09:54,640 --> 00:09:57,760
did pass through guarantees of the

00:09:56,320 --> 00:10:00,880
networking ts

00:09:57,760 --> 00:10:02,880
they did abide by its practices what

00:10:00,880 --> 00:10:05,120
they didn't do is establish those from

00:10:02,880 --> 00:10:07,040
the most basic level

00:10:05,120 --> 00:10:08,399
for the executor association i discussed

00:10:07,040 --> 00:10:10,880
earlier we simply

00:10:08,399 --> 00:10:12,640
wrapped the user's completion handler we

00:10:10,880 --> 00:10:13,920
simply passed through their executor

00:10:12,640 --> 00:10:15,519
association

00:10:13,920 --> 00:10:17,519
and then we took our intermediate

00:10:15,519 --> 00:10:19,040
completion handler and passed it down to

00:10:17,519 --> 00:10:20,640
the next layer

00:10:19,040 --> 00:10:22,480
if it wasn't for the fact that next

00:10:20,640 --> 00:10:23,839
layer actually synthesized those

00:10:22,480 --> 00:10:26,160
guarantees

00:10:23,839 --> 00:10:27,040
actually honored that association at a

00:10:26,160 --> 00:10:29,440
baseline

00:10:27,040 --> 00:10:30,880
from nothing we would not actually have

00:10:29,440 --> 00:10:33,200
passed through the guarantees and

00:10:30,880 --> 00:10:35,120
practices of the networking ts

00:10:33,200 --> 00:10:37,120
we were relying on the baseline layer

00:10:35,120 --> 00:10:39,680
establishing that for us

00:10:37,120 --> 00:10:41,360
but now here we are seeking to implement

00:10:39,680 --> 00:10:43,519
the baseline layer

00:10:41,360 --> 00:10:45,360
we're seeking to implement our own i o

00:10:43,519 --> 00:10:47,680
object which exposes

00:10:45,360 --> 00:10:50,320
totally new asynchronous functionality

00:10:47,680 --> 00:10:52,240
in the context of the networking ts

00:10:50,320 --> 00:10:54,079
the ts of course ships with some of

00:10:52,240 --> 00:10:55,600
these they are the baseline of its

00:10:54,079 --> 00:10:58,640
asynchronous toolbox

00:10:55,600 --> 00:11:00,160
for example stdnet iptcp socket and

00:10:58,640 --> 00:11:02,959
stoodnet steady timer

00:11:00,160 --> 00:11:03,680
are i o objects but this is not an

00:11:02,959 --> 00:11:06,160
exhaustive

00:11:03,680 --> 00:11:08,959
closed set we can imagine new

00:11:06,160 --> 00:11:11,120
asynchronous functionality we might want

00:11:08,959 --> 00:11:13,200
in the financial domain for example we

00:11:11,120 --> 00:11:16,480
may wish to write an

00:11:13,200 --> 00:11:18,399
asynchronous socket which uses efei

00:11:16,480 --> 00:11:21,120
or in other domains we may wish to have

00:11:18,399 --> 00:11:24,000
an asynchronous database access layer

00:11:21,120 --> 00:11:26,399
or maybe just maybe you want to

00:11:24,000 --> 00:11:27,120
asynchronously spool out a few pages to

00:11:26,399 --> 00:11:29,120
be printed

00:11:27,120 --> 00:11:30,800
on that laserjet printer across the

00:11:29,120 --> 00:11:32,800
office

00:11:30,800 --> 00:11:34,240
now each of these possibilities is

00:11:32,800 --> 00:11:35,680
compelling and interesting

00:11:34,240 --> 00:11:37,680
but one of the things they all have in

00:11:35,680 --> 00:11:40,480
common is they involve vendor or

00:11:37,680 --> 00:11:42,959
operating system specific functionality

00:11:40,480 --> 00:11:44,480
and that's not the purpose of this talk

00:11:42,959 --> 00:11:48,399
this isn't a posix

00:11:44,480 --> 00:11:50,240
or a windows talk this is a c plus talk

00:11:48,399 --> 00:11:51,440
so what i'd like to do is extract out

00:11:50,240 --> 00:11:52,560
what's common to these three

00:11:51,440 --> 00:11:54,480
possibilities

00:11:52,560 --> 00:11:55,839
extract out what's necessary to

00:11:54,480 --> 00:11:57,680
integrate them into the framework of the

00:11:55,839 --> 00:11:59,360
networking ts

00:11:57,680 --> 00:12:01,360
and that is the suspension of a

00:11:59,360 --> 00:12:02,560
completion handler at the initiation of

00:12:01,360 --> 00:12:04,480
an operation

00:12:02,560 --> 00:12:06,480
when you go to spool that piece of paper

00:12:04,480 --> 00:12:08,240
to be printed out from the printer

00:12:06,480 --> 00:12:10,000
you need to take the completion handler

00:12:08,240 --> 00:12:11,760
and you to put it to sleep

00:12:10,000 --> 00:12:14,079
and when that print job is finally fully

00:12:11,760 --> 00:12:15,920
spooled you need some way to resume it

00:12:14,079 --> 00:12:17,440
to invoke it and let your user know that

00:12:15,920 --> 00:12:20,639
they can head across the office

00:12:17,440 --> 00:12:22,880
to pick up their printed pages

00:12:20,639 --> 00:12:24,959
what you need if you think about this in

00:12:22,880 --> 00:12:27,200
its analog in the synchronous world

00:12:24,959 --> 00:12:29,200
is a condition variable and so we're

00:12:27,200 --> 00:12:29,760
going to write an asynchronous condition

00:12:29,200 --> 00:12:31,760
variable

00:12:29,760 --> 00:12:33,920
as a means of introducing the patterns

00:12:31,760 --> 00:12:37,040
and practices of writing i o objects

00:12:33,920 --> 00:12:39,360
in the networking ts our i o object

00:12:37,040 --> 00:12:41,360
our asynchronous condition variable our

00:12:39,360 --> 00:12:43,120
basic async event class

00:12:41,360 --> 00:12:44,720
will of course have a type alias to

00:12:43,120 --> 00:12:46,720
expose its template parameter

00:12:44,720 --> 00:12:47,920
the executor that it will store and use

00:12:46,720 --> 00:12:49,279
internally

00:12:47,920 --> 00:12:51,120
and then it will of course have a una

00:12:49,279 --> 00:12:52,320
reconstructor to take in this executor

00:12:51,120 --> 00:12:54,160
and construct itself

00:12:52,320 --> 00:12:56,000
and a get executor member function to

00:12:54,160 --> 00:12:58,399
return that executor

00:12:56,000 --> 00:12:59,920
note that in some conceptions this

00:12:58,399 --> 00:13:01,839
nullery invokable get

00:12:59,920 --> 00:13:04,079
executor member function is actually

00:13:01,839 --> 00:13:06,079
definitional of an i o object

00:13:04,079 --> 00:13:09,680
if it has this member then under this

00:13:06,079 --> 00:13:11,680
definition it is an i o object

00:13:09,680 --> 00:13:13,920
then we pull in those familiar methods

00:13:11,680 --> 00:13:16,079
from condition variable notify one

00:13:13,920 --> 00:13:18,240
and all which variously cause the

00:13:16,079 --> 00:13:21,279
completion of zero or one or

00:13:18,240 --> 00:13:22,240
zero or more asynchronous operations and

00:13:21,279 --> 00:13:25,120
then we have

00:13:22,240 --> 00:13:27,440
the star of the show we have the

00:13:25,120 --> 00:13:30,560
initiating function from our baseline

00:13:27,440 --> 00:13:33,600
from scratch asynchronous operation

00:13:30,560 --> 00:13:33,600
async weight

00:13:33,680 --> 00:13:37,760
now if you think about the formulation

00:13:35,600 --> 00:13:39,760
and motivation for this class

00:13:37,760 --> 00:13:41,760
for this example it was around

00:13:39,760 --> 00:13:42,800
suspension and resumption of completion

00:13:41,760 --> 00:13:45,839
handlers

00:13:42,800 --> 00:13:47,680
and indeed that's all this class does

00:13:45,839 --> 00:13:50,160
which raises the question of how do we

00:13:47,680 --> 00:13:51,680
store those completion handlers

00:13:50,160 --> 00:13:53,360
what do we actually do with them when we

00:13:51,680 --> 00:13:55,680
suspend them and how do we

00:13:53,360 --> 00:13:57,360
resume them and if we try and think

00:13:55,680 --> 00:13:59,199
about this in terms of previous years we

00:13:57,360 --> 00:14:01,519
once again find that we were just

00:13:59,199 --> 00:14:02,399
kicking the can down the road in

00:14:01,519 --> 00:14:04,399
previous years

00:14:02,399 --> 00:14:05,519
we took in and deduced the user's final

00:14:04,399 --> 00:14:06,880
completion handler

00:14:05,519 --> 00:14:08,800
but then we just wrapped it up in our

00:14:06,880 --> 00:14:10,160
own intermediate completion handler

00:14:08,800 --> 00:14:11,839
and then provided this intermediate

00:14:10,160 --> 00:14:13,519
completion handler in turn

00:14:11,839 --> 00:14:15,199
as the completion handler for a lower

00:14:13,519 --> 00:14:16,880
level operation

00:14:15,199 --> 00:14:18,320
the suspension and resumption of that

00:14:16,880 --> 00:14:20,079
completion handler was

00:14:18,320 --> 00:14:22,079
out of our hands it was the

00:14:20,079 --> 00:14:24,480
responsibility of that atomic

00:14:22,079 --> 00:14:25,279
black box lower level that we didn't

00:14:24,480 --> 00:14:28,480
understand

00:14:25,279 --> 00:14:30,320
and didn't think about but now this year

00:14:28,480 --> 00:14:32,000
that can we kick down the road is

00:14:30,320 --> 00:14:33,600
rolling up at our feet

00:14:32,000 --> 00:14:35,519
because we're positioning ourselves at

00:14:33,600 --> 00:14:37,600
that lowest level we're trying to

00:14:35,519 --> 00:14:40,160
bootstrap asynchronous functionality

00:14:37,600 --> 00:14:42,720
from nothing and so given that the

00:14:40,160 --> 00:14:44,720
completion handler could be of any type

00:14:42,720 --> 00:14:47,199
we need to figure out a way to store an

00:14:44,720 --> 00:14:48,639
invocable object of any type

00:14:47,199 --> 00:14:51,120
the first thing that might come to mind

00:14:48,639 --> 00:14:52,639
is stood function but stood function is

00:14:51,120 --> 00:14:54,480
not fit to task

00:14:52,639 --> 00:14:56,720
because stood function requires that its

00:14:54,480 --> 00:14:59,360
target be copyable

00:14:56,720 --> 00:15:00,800
whereas the networking ts only mandates

00:14:59,360 --> 00:15:03,680
that completion handlers

00:15:00,800 --> 00:15:05,440
be movable what we need is something

00:15:03,680 --> 00:15:09,040
like any invocable

00:15:05,440 --> 00:15:12,320
previously known as unique function

00:15:09,040 --> 00:15:14,000
but we also need something more we need

00:15:12,320 --> 00:15:15,440
something that wraps up some of those

00:15:14,000 --> 00:15:16,560
guarantees and practices of the

00:15:15,440 --> 00:15:19,440
networking ts

00:15:16,560 --> 00:15:20,959
that we need to bootstrap from nothing

00:15:19,440 --> 00:15:22,720
we need to take care of some of this

00:15:20,959 --> 00:15:24,079
nuance and see exactly what we're

00:15:22,720 --> 00:15:28,240
getting ourselves in for

00:15:24,079 --> 00:15:29,839
by diving down to the very lowest level

00:15:28,240 --> 00:15:32,399
and so we're going to author this

00:15:29,839 --> 00:15:34,560
pending unary class template

00:15:32,399 --> 00:15:36,639
note that much like stood function it

00:15:34,560 --> 00:15:39,360
has a primary class template

00:15:36,639 --> 00:15:40,079
which is declared but never defined and

00:15:39,360 --> 00:15:41,920
it then has

00:15:40,079 --> 00:15:43,920
one specialization for when the sole

00:15:41,920 --> 00:15:47,120
type provided as a template parameter

00:15:43,920 --> 00:15:48,959
is a function type this specialization

00:15:47,120 --> 00:15:51,199
has two members

00:15:48,959 --> 00:15:52,240
a unit reconstructor which type erases

00:15:51,199 --> 00:15:53,839
its argument

00:15:52,240 --> 00:15:55,839
and a function call operator which

00:15:53,839 --> 00:15:58,160
invokes the target

00:15:55,839 --> 00:16:00,160
but that's not all because that simple

00:15:58,160 --> 00:16:01,759
formulation fails to encapsulate that

00:16:00,160 --> 00:16:02,800
requirement that guarantee of the

00:16:01,759 --> 00:16:05,440
networking ts

00:16:02,800 --> 00:16:06,800
that we should honor and that if you

00:16:05,440 --> 00:16:08,880
remember from last year

00:16:06,800 --> 00:16:10,639
is that completion handlers carry around

00:16:08,880 --> 00:16:11,600
with them not just an associated

00:16:10,639 --> 00:16:13,519
executor

00:16:11,600 --> 00:16:15,600
not just an associated strategy for

00:16:13,519 --> 00:16:18,720
invoking callable objects

00:16:15,600 --> 00:16:20,320
but also an associated allocator a means

00:16:18,720 --> 00:16:22,000
by which they would prefer

00:16:20,320 --> 00:16:23,839
the asynchronous operations to which

00:16:22,000 --> 00:16:26,480
they're submitted to allocate

00:16:23,839 --> 00:16:28,399
memory and so we can see in the comments

00:16:26,480 --> 00:16:30,560
that the una reconstructor

00:16:28,399 --> 00:16:32,720
rather than using new to allocate memory

00:16:30,560 --> 00:16:33,600
for the type erasure uses the associated

00:16:32,720 --> 00:16:36,000
allocator

00:16:33,600 --> 00:16:37,759
it allocates storage using an allocator

00:16:36,000 --> 00:16:39,040
and then forwards the t into that

00:16:37,759 --> 00:16:40,720
storage

00:16:39,040 --> 00:16:42,480
and then when we examine the function

00:16:40,720 --> 00:16:44,480
call operator we come across another

00:16:42,480 --> 00:16:46,399
nuance of the networking ts

00:16:44,480 --> 00:16:48,880
and that's that the networking ts would

00:16:46,399 --> 00:16:51,040
really like it if before the up call

00:16:48,880 --> 00:16:53,199
before we invoke the completion handler

00:16:51,040 --> 00:16:55,680
and indicate our operation is finished

00:16:53,199 --> 00:16:57,759
we de-allocate all of the memory we

00:16:55,680 --> 00:16:59,440
allocated through the user's associated

00:16:57,759 --> 00:17:01,440
allocator

00:16:59,440 --> 00:17:02,480
if you think about it a little bit this

00:17:01,440 --> 00:17:05,520
actually makes

00:17:02,480 --> 00:17:07,520
perfect sense because if you need some

00:17:05,520 --> 00:17:09,360
resources to perform a task

00:17:07,520 --> 00:17:10,720
let's say you need to allocate some

00:17:09,360 --> 00:17:13,360
memory

00:17:10,720 --> 00:17:15,839
if you aren't done with those resources

00:17:13,360 --> 00:17:18,480
if you haven't released them

00:17:15,839 --> 00:17:20,160
you're not really done and so why are

00:17:18,480 --> 00:17:20,880
you going off and invoking a completion

00:17:20,160 --> 00:17:23,679
handler

00:17:20,880 --> 00:17:24,000
when you're not done and so rather than

00:17:23,679 --> 00:17:25,919
just

00:17:24,000 --> 00:17:27,439
invoking the target in place our

00:17:25,919 --> 00:17:29,679
function call operator will take the

00:17:27,439 --> 00:17:31,360
target and move it onto the stack

00:17:29,679 --> 00:17:32,799
get its associated allocator and

00:17:31,360 --> 00:17:35,360
de-allocate the storage

00:17:32,799 --> 00:17:35,840
and only then perform the up call only

00:17:35,360 --> 00:17:39,360
then

00:17:35,840 --> 00:17:41,120
invoke the final completion handler

00:17:39,360 --> 00:17:43,120
note that if you want the fully worked

00:17:41,120 --> 00:17:44,400
version of this class which i've elided

00:17:43,120 --> 00:17:47,120
in the sake of space

00:17:44,400 --> 00:17:48,960
and time you can go to the example code

00:17:47,120 --> 00:17:51,039
that's associated with this talk

00:17:48,960 --> 00:17:53,679
there's a fully worked and tested

00:17:51,039 --> 00:17:55,679
version of the slide

00:17:53,679 --> 00:17:57,679
with this in hand we can now take a stab

00:17:55,679 --> 00:17:59,360
at implementing our i o object

00:17:57,679 --> 00:18:00,880
we can take a stab at synthesizing

00:17:59,360 --> 00:18:03,679
asynchronous functionality

00:18:00,880 --> 00:18:04,160
from nothing we can fill in the body of

00:18:03,679 --> 00:18:06,400
basic

00:18:04,160 --> 00:18:08,080
async event of course we're going to

00:18:06,400 --> 00:18:09,840
store that executor we accept

00:18:08,080 --> 00:18:11,120
as an argument to our constructor and

00:18:09,840 --> 00:18:12,559
then we're going to have a vector of

00:18:11,120 --> 00:18:14,080
these pending objects

00:18:12,559 --> 00:18:16,080
a place to store each and every

00:18:14,080 --> 00:18:18,880
completion handler for each and every

00:18:16,080 --> 00:18:20,720
outstanding asynchronous operation

00:18:18,880 --> 00:18:22,720
we're going to have a totally banal

00:18:20,720 --> 00:18:24,720
implementation of our una reconstructor

00:18:22,720 --> 00:18:26,720
which simply moves the executor into the

00:18:24,720 --> 00:18:28,080
storage that we provided for it

00:18:26,720 --> 00:18:29,919
then we have an equally banal

00:18:28,080 --> 00:18:32,240
implementation of get executor which

00:18:29,919 --> 00:18:33,679
just returns that executor

00:18:32,240 --> 00:18:35,760
and we have a fairly standard

00:18:33,679 --> 00:18:37,679
implementation of notify one

00:18:35,760 --> 00:18:39,440
if there are any any pending completion

00:18:37,679 --> 00:18:41,280
handlers if there aren't any pending

00:18:39,440 --> 00:18:43,520
completion handlers we return zero

00:18:41,280 --> 00:18:45,360
because there's nothing to do otherwise

00:18:43,520 --> 00:18:46,640
we move out the first such completion

00:18:45,360 --> 00:18:48,400
handler

00:18:46,640 --> 00:18:50,080
we pop it out of the vector to make sure

00:18:48,400 --> 00:18:51,520
we don't leave something lying around in

00:18:50,080 --> 00:18:52,720
a move from state in the case of

00:18:51,520 --> 00:18:54,400
exception

00:18:52,720 --> 00:18:56,480
we invoke the completion handler and we

00:18:54,400 --> 00:18:59,360
return one signifying that one

00:18:56,480 --> 00:19:01,120
asynchronous operation was completed

00:18:59,360 --> 00:19:02,880
note that the implementation of notify

00:19:01,120 --> 00:19:04,720
all has some complexity if you want to

00:19:02,880 --> 00:19:05,679
achieve both efficiency and exception

00:19:04,720 --> 00:19:07,520
safety

00:19:05,679 --> 00:19:10,480
at any rate that's not really the topic

00:19:07,520 --> 00:19:12,320
of the talk and so i've elided it

00:19:10,480 --> 00:19:13,520
which brings us to that all important

00:19:12,320 --> 00:19:15,360
member function

00:19:13,520 --> 00:19:17,120
which brings us to the implementation of

00:19:15,360 --> 00:19:18,799
async weight

00:19:17,120 --> 00:19:20,720
we take in a completion handler and we

00:19:18,799 --> 00:19:22,720
grab its associated executor

00:19:20,720 --> 00:19:24,000
providing as a fallback the default

00:19:22,720 --> 00:19:26,960
candidate object

00:19:24,000 --> 00:19:28,640
the executor that we store in our cells

00:19:26,960 --> 00:19:30,960
this is because we need to bootstrap

00:19:28,640 --> 00:19:32,799
that executor association from nothing

00:19:30,960 --> 00:19:35,120
we need to make sure to go off and honor

00:19:32,799 --> 00:19:37,200
it then we package up the user's

00:19:35,120 --> 00:19:39,200
completion handler and the executor and

00:19:37,200 --> 00:19:41,440
we implace into the pendings

00:19:39,200 --> 00:19:42,799
we suspend the completion handler we

00:19:41,440 --> 00:19:45,679
allocate storage for it

00:19:42,799 --> 00:19:47,840
and put it to sleep once it's resumed

00:19:45,679 --> 00:19:48,720
into inside a call to notify one or

00:19:47,840 --> 00:19:50,480
notify all

00:19:48,720 --> 00:19:52,080
we go off and we grab the allocator

00:19:50,480 --> 00:19:52,799
associated with the user's completion

00:19:52,080 --> 00:19:54,160
handler

00:19:52,799 --> 00:19:55,919
because we need to honor that

00:19:54,160 --> 00:19:58,000
requirement as well

00:19:55,919 --> 00:19:59,760
then we use dispatch on the executor

00:19:58,000 --> 00:20:01,520
providing the handler and the allocator

00:19:59,760 --> 00:20:03,200
to make sure we're honoring the user's

00:20:01,520 --> 00:20:05,360
execution requirements

00:20:03,200 --> 00:20:07,600
remember this invocation is taking place

00:20:05,360 --> 00:20:08,880
below notify one or notify all on the

00:20:07,600 --> 00:20:10,480
call stack

00:20:08,880 --> 00:20:12,000
and we don't know anything about the

00:20:10,480 --> 00:20:12,559
environment from which the user is

00:20:12,000 --> 00:20:15,679
calling

00:20:12,559 --> 00:20:17,520
notify one our notify all and therefore

00:20:15,679 --> 00:20:19,200
we need to be very careful to go out and

00:20:17,520 --> 00:20:20,159
make sure we honor their execution

00:20:19,200 --> 00:20:21,760
requirements

00:20:20,159 --> 00:20:24,080
we need to give their associated

00:20:21,760 --> 00:20:24,480
executor an opportunity to invoke that

00:20:24,080 --> 00:20:26,320
work

00:20:24,480 --> 00:20:29,520
rather than invoking it wherever we

00:20:26,320 --> 00:20:32,000
ourselves happen to be invoked

00:20:29,520 --> 00:20:33,440
but there's an issue with this example

00:20:32,000 --> 00:20:34,960
and the issue with this example is that

00:20:33,440 --> 00:20:36,799
we're not actually honoring all the

00:20:34,960 --> 00:20:38,320
requirements of the ts

00:20:36,799 --> 00:20:40,320
we've forgotten about something that was

00:20:38,320 --> 00:20:43,120
introduced two years ago

00:20:40,320 --> 00:20:45,280
about completion tokens the mechanism by

00:20:43,120 --> 00:20:47,120
which the networking ts allows callers

00:20:45,280 --> 00:20:49,200
to customize the mechanism by which

00:20:47,120 --> 00:20:50,880
they're notified of completion

00:20:49,200 --> 00:20:52,559
which allows them to divorce themselves

00:20:50,880 --> 00:20:53,919
from raw completion handlers and use

00:20:52,559 --> 00:20:56,000
things like promises

00:20:53,919 --> 00:20:58,320
and futures to receive the status of

00:20:56,000 --> 00:20:59,760
their asynchronous operation

00:20:58,320 --> 00:21:01,440
and the reason that's been aligned is

00:20:59,760 --> 00:21:02,080
because in previous years we used

00:21:01,440 --> 00:21:04,080
boilerplate

00:21:02,080 --> 00:21:06,400
regarding async result and async

00:21:04,080 --> 00:21:08,559
completion to obtain a return value and

00:21:06,400 --> 00:21:10,080
a final completion handler

00:21:08,559 --> 00:21:12,080
and that's changed in the intervening

00:21:10,080 --> 00:21:12,880
year because there's something new on

00:21:12,080 --> 00:21:14,240
the scene

00:21:12,880 --> 00:21:16,000
which not only takes care of this

00:21:14,240 --> 00:21:18,720
boilerplate but also enables a

00:21:16,000 --> 00:21:20,480
powerful new use pattern because the

00:21:18,720 --> 00:21:22,799
networking ts or at least

00:21:20,480 --> 00:21:24,880
sg4 has kind of green lighted this and

00:21:22,799 --> 00:21:27,360
azio include this new functionality

00:21:24,880 --> 00:21:30,320
called async initiate

00:21:27,360 --> 00:21:31,440
a function template which takes in two

00:21:30,320 --> 00:21:33,600
or more arguments

00:21:31,440 --> 00:21:35,520
an initiation which is a callable object

00:21:33,600 --> 00:21:37,120
that encapsulates all of the logic of

00:21:35,520 --> 00:21:38,640
beginning the operation

00:21:37,120 --> 00:21:40,000
and then the completion token it's going

00:21:38,640 --> 00:21:41,280
to use to learn about the completion

00:21:40,000 --> 00:21:43,200
handler and return type

00:21:41,280 --> 00:21:44,480
note this return type is the deduce type

00:21:43,200 --> 00:21:45,919
that it returns

00:21:44,480 --> 00:21:47,679
and then trailing arguments which will

00:21:45,919 --> 00:21:48,960
be decay copied and forwarded through to

00:21:47,679 --> 00:21:50,640
the initiation

00:21:48,960 --> 00:21:52,080
the initiation receives as its first

00:21:50,640 --> 00:21:53,760
argument the completion handler

00:21:52,080 --> 00:21:55,760
and then his subsequent arguments all of

00:21:53,760 --> 00:21:57,760
these arguments

00:21:55,760 --> 00:21:59,600
this gets rid of all this async result

00:21:57,760 --> 00:22:01,120
and async completion boilerplate

00:21:59,600 --> 00:22:02,880
and makes implementing asynchronous

00:22:01,120 --> 00:22:04,320
operations a lot cleaner

00:22:02,880 --> 00:22:06,080
i don't know about you but pretty much

00:22:04,320 --> 00:22:07,440
every time i had to actually bootstrap

00:22:06,080 --> 00:22:08,799
completion token handling

00:22:07,440 --> 00:22:10,400
i had to actually go and look at the

00:22:08,799 --> 00:22:10,960
documentation or to figure out how to

00:22:10,400 --> 00:22:14,080
write it

00:22:10,960 --> 00:22:15,760
whereas this just writes itself but

00:22:14,080 --> 00:22:17,919
perhaps even more exciting is the fact

00:22:15,760 --> 00:22:19,440
that async initiate actually opens up a

00:22:17,919 --> 00:22:22,400
totally new use case

00:22:19,440 --> 00:22:24,799
exposes a totally new workflow because

00:22:22,400 --> 00:22:26,000
previously the initiation of operations

00:22:24,799 --> 00:22:28,400
in the networking ts

00:22:26,000 --> 00:22:29,120
was eager when you called the initiating

00:22:28,400 --> 00:22:31,120
function

00:22:29,120 --> 00:22:33,840
by the time it returned the operation

00:22:31,120 --> 00:22:36,480
was pending outstanding and executing

00:22:33,840 --> 00:22:38,400
in the background and that's fine when

00:22:36,480 --> 00:22:39,760
you're using promises and futures

00:22:38,400 --> 00:22:41,280
that's fine when you're getting notified

00:22:39,760 --> 00:22:42,320
of completion by way of a completion

00:22:41,280 --> 00:22:43,440
handler

00:22:42,320 --> 00:22:45,360
but what happens if you're using

00:22:43,440 --> 00:22:48,400
something more esoteric

00:22:45,360 --> 00:22:50,640
like senders and receivers from p0443

00:22:48,400 --> 00:22:52,320
or co-routines which were found to

00:22:50,640 --> 00:22:54,720
actually mesh up with this

00:22:52,320 --> 00:22:56,960
paradigm so poorly that using it

00:22:54,720 --> 00:22:57,840
required the allocation of a mutex to

00:22:56,960 --> 00:22:59,440
synchronize

00:22:57,840 --> 00:23:00,880
between the initiation possible

00:22:59,440 --> 00:23:03,760
completion and suspend resume

00:23:00,880 --> 00:23:05,520
cycles of the co routine and so async

00:23:03,760 --> 00:23:07,679
initiate doesn't necessarily just

00:23:05,520 --> 00:23:09,760
invoke your initiation right away with

00:23:07,679 --> 00:23:11,840
the completion handler and arguments

00:23:09,760 --> 00:23:13,760
instead it provides the implementer of

00:23:11,840 --> 00:23:16,080
the completion notification mechanism

00:23:13,760 --> 00:23:17,440
with a way to capture and suspend the

00:23:16,080 --> 00:23:21,120
initiation

00:23:17,440 --> 00:23:23,280
to defer it to be invoked lazily later

00:23:21,120 --> 00:23:25,039
and while this opens up a lot of power

00:23:23,280 --> 00:23:26,480
it opens up a lot of new workflows it

00:23:25,039 --> 00:23:28,960
comes with a sharp edge

00:23:26,480 --> 00:23:30,720
regarding those trailing arguments i

00:23:28,960 --> 00:23:31,760
said before those trailing arguments are

00:23:30,720 --> 00:23:34,240
decay copied

00:23:31,760 --> 00:23:36,080
and forwarded which means that actually

00:23:34,240 --> 00:23:38,640
they will be treated as value types

00:23:36,080 --> 00:23:40,320
copies or moves may occur and so if your

00:23:38,640 --> 00:23:42,159
initiation requires one of the

00:23:40,320 --> 00:23:44,400
parameters to the initiating function

00:23:42,159 --> 00:23:46,400
by reference you need to be sure to

00:23:44,400 --> 00:23:47,919
capture that by reference by capturing

00:23:46,400 --> 00:23:49,360
it in the initiation

00:23:47,919 --> 00:23:50,960
you can't launder it through these

00:23:49,360 --> 00:23:51,760
trailing arguments and hope that it will

00:23:50,960 --> 00:23:55,279
just work

00:23:51,760 --> 00:23:56,960
because it probably won't

00:23:55,279 --> 00:23:58,720
now that we've learned that let's go

00:23:56,960 --> 00:24:00,000
back and modify our initiating function

00:23:58,720 --> 00:24:01,679
so that we actually honor this

00:24:00,000 --> 00:24:03,520
requirement of the ts

00:24:01,679 --> 00:24:05,520
so that we open ourselves up to being to

00:24:03,520 --> 00:24:06,000
notifying our users of completion in any

00:24:05,520 --> 00:24:08,640
way

00:24:06,000 --> 00:24:09,919
not just via completion handlers the

00:24:08,640 --> 00:24:11,120
first thing we're going to do is we're

00:24:09,919 --> 00:24:13,200
going to take and indent

00:24:11,120 --> 00:24:14,799
all the code we had before and put it

00:24:13,200 --> 00:24:16,000
inside a lambda which will be our

00:24:14,799 --> 00:24:18,080
initiation

00:24:16,000 --> 00:24:19,919
that lambda accepts just one argument

00:24:18,080 --> 00:24:21,679
which is the completion handler

00:24:19,919 --> 00:24:23,840
deduced by async initiate from the

00:24:21,679 --> 00:24:26,240
completion token which is passed as the

00:24:23,840 --> 00:24:28,000
second argument to async initiate

00:24:26,240 --> 00:24:30,080
notice that because completion tokens

00:24:28,000 --> 00:24:32,159
may also synthesize return types to be

00:24:30,080 --> 00:24:35,279
returned from the initiating function we

00:24:32,159 --> 00:24:36,799
return whatever async initiate returns

00:24:35,279 --> 00:24:38,559
then we need to go off and we need to

00:24:36,799 --> 00:24:40,480
tweak our signature a bit

00:24:38,559 --> 00:24:42,320
we can't just return void we need to

00:24:40,480 --> 00:24:45,520
return whatever async initiate does

00:24:42,320 --> 00:24:47,039
until we return decal type auto and then

00:24:45,520 --> 00:24:48,000
we're not trafficking in completion

00:24:47,039 --> 00:24:50,000
handlers anymore

00:24:48,000 --> 00:24:51,520
we're trafficking in completion tokens

00:24:50,000 --> 00:24:52,480
and so we rename the appropriate

00:24:51,520 --> 00:24:56,080
template argument

00:24:52,480 --> 00:24:58,799
and parameter to the function

00:24:56,080 --> 00:25:01,279
but this isn't all because if you look

00:24:58,799 --> 00:25:03,279
at where we dispatch into that executor

00:25:01,279 --> 00:25:04,320
you'll notice that's networking ts style

00:25:03,279 --> 00:25:06,400
executors

00:25:04,320 --> 00:25:08,000
the networking ts provides this triplet

00:25:06,400 --> 00:25:08,960
of ways of submitting work to an

00:25:08,000 --> 00:25:12,159
executor

00:25:08,960 --> 00:25:15,200
defer dispatch and post

00:25:12,159 --> 00:25:17,919
but how does p04443 do it

00:25:15,200 --> 00:25:19,679
well it doesn't do it that way because

00:25:17,919 --> 00:25:21,760
what was noticed in the executor's

00:25:19,679 --> 00:25:23,120
effort was that defer dispatch and posts

00:25:21,760 --> 00:25:25,760
do encapsulate

00:25:23,120 --> 00:25:27,039
useful and valuable semantics for

00:25:25,760 --> 00:25:29,360
submitting work

00:25:27,039 --> 00:25:31,200
but they don't capture all the possible

00:25:29,360 --> 00:25:33,679
semantics someone might want

00:25:31,200 --> 00:25:34,720
there are innumerable such semantics and

00:25:33,679 --> 00:25:36,559
those semantics are

00:25:34,720 --> 00:25:38,400
in some sense all orthogonal from each

00:25:36,559 --> 00:25:39,120
other and so the user may wish to

00:25:38,400 --> 00:25:41,679
establish

00:25:39,120 --> 00:25:43,840
any combination and so if we were to

00:25:41,679 --> 00:25:44,640
give each such combination of semantics

00:25:43,840 --> 00:25:46,320
a name

00:25:44,640 --> 00:25:48,880
like we do with deferred dispatch and

00:25:46,320 --> 00:25:50,559
post we'd wind up with a combinatorial

00:25:48,880 --> 00:25:52,240
explosion in the number of functions

00:25:50,559 --> 00:25:55,440
that have to be provided to support

00:25:52,240 --> 00:25:56,880
all such semantics which is clearly

00:25:55,440 --> 00:25:59,760
unacceptable

00:25:56,880 --> 00:26:01,440
and so in p0443 there's one true way to

00:25:59,760 --> 00:26:03,840
submit work to an executor

00:26:01,440 --> 00:26:04,799
the customization point stood execution

00:26:03,840 --> 00:26:06,640
execute

00:26:04,799 --> 00:26:08,240
which you invoke providing the executor

00:26:06,640 --> 00:26:08,720
as the first argument and the work to

00:26:08,240 --> 00:26:11,360
submit

00:26:08,720 --> 00:26:12,799
as the second argument which leaves on

00:26:11,360 --> 00:26:15,360
the table the question of

00:26:12,799 --> 00:26:17,039
how do we establish those semantics how

00:26:15,360 --> 00:26:17,679
can we re-implement the contracts of

00:26:17,039 --> 00:26:21,840
defer

00:26:17,679 --> 00:26:23,520
dispatch and post well the way p0443

00:26:21,840 --> 00:26:25,120
imagines this is by using a mechanism

00:26:23,520 --> 00:26:26,720
called properties

00:26:25,120 --> 00:26:28,720
rather than an executor just being a

00:26:26,720 --> 00:26:30,480
handle to an execution context

00:26:28,720 --> 00:26:32,240
an executor remains a handle to an

00:26:30,480 --> 00:26:35,200
execution context but also

00:26:32,240 --> 00:26:36,840
encapsulates a set of semantics by which

00:26:35,200 --> 00:26:38,240
it submits work to that execution

00:26:36,840 --> 00:26:40,000
context

00:26:38,240 --> 00:26:42,799
these semantics are established by

00:26:40,000 --> 00:26:45,919
so-called concept preserving operations

00:26:42,799 --> 00:26:47,840
prefer and require that is to say

00:26:45,919 --> 00:26:49,600
when you pass prefer an executor it

00:26:47,840 --> 00:26:52,559
returns you a new executor

00:26:49,600 --> 00:26:54,000
possibly of a new type still an executor

00:26:52,559 --> 00:26:55,039
possibly with certain semantics

00:26:54,000 --> 00:26:56,400
established

00:26:55,039 --> 00:26:58,159
whether the semantics are actually

00:26:56,400 --> 00:26:58,960
established or not depends on whether

00:26:58,159 --> 00:27:01,679
you prefer

00:26:58,960 --> 00:27:02,080
or require them as an example of using

00:27:01,679 --> 00:27:04,480
this

00:27:02,080 --> 00:27:06,640
if you wish to re-implement post you

00:27:04,480 --> 00:27:08,640
would require blocking.never

00:27:06,640 --> 00:27:10,080
since one of the semantics of posts is

00:27:08,640 --> 00:27:12,240
that post

00:27:10,080 --> 00:27:13,360
will never await the invocation of the

00:27:12,240 --> 00:27:15,840
function object

00:27:13,360 --> 00:27:17,360
it will not block and then as a hint

00:27:15,840 --> 00:27:18,960
which i'll not really get into here

00:27:17,360 --> 00:27:21,000
a scheduling end to the execution

00:27:18,960 --> 00:27:22,640
context you also prefer

00:27:21,000 --> 00:27:24,640
continuation.fork

00:27:22,640 --> 00:27:26,000
once those concept preserving operations

00:27:24,640 --> 00:27:27,520
return you an executor which

00:27:26,000 --> 00:27:28,240
appropriately encapsulates those

00:27:27,520 --> 00:27:30,640
semantics

00:27:28,240 --> 00:27:32,159
you can use stood execution execute to

00:27:30,640 --> 00:27:34,159
submit that work

00:27:32,159 --> 00:27:37,440
so let's go back and modify our example

00:27:34,159 --> 00:27:39,600
to bring it in line with p0443

00:27:37,440 --> 00:27:41,360
much of it looks the same we still go

00:27:39,600 --> 00:27:43,279
off and get the associated executor and

00:27:41,360 --> 00:27:44,880
we still put the work to sleep

00:27:43,279 --> 00:27:46,640
and we still defer to the completion

00:27:44,880 --> 00:27:47,679
token machinery in the form of async

00:27:46,640 --> 00:27:49,279
initiate

00:27:47,679 --> 00:27:51,440
but once we grab that associated

00:27:49,279 --> 00:27:53,120
allocator things start to look different

00:27:51,440 --> 00:27:54,880
because now there's no dispatch function

00:27:53,120 --> 00:27:56,640
to pass that allocator to

00:27:54,880 --> 00:27:58,320
instead the fact that we want our

00:27:56,640 --> 00:27:59,039
executor to allocate memory with that

00:27:58,320 --> 00:28:01,360
allocator

00:27:59,039 --> 00:28:02,799
becomes a semantic requirement something

00:28:01,360 --> 00:28:03,840
we established through the property

00:28:02,799 --> 00:28:06,640
system

00:28:03,840 --> 00:28:08,559
and so we prefer that the executor

00:28:06,640 --> 00:28:10,159
allocate memory with that allocator by

00:28:08,559 --> 00:28:11,039
attempting to establish the stood

00:28:10,159 --> 00:28:13,760
execution

00:28:11,039 --> 00:28:15,440
allocator property on it note this is a

00:28:13,760 --> 00:28:17,039
preference because you can conceive of

00:28:15,440 --> 00:28:18,000
executors which don't ever allocate

00:28:17,039 --> 00:28:19,840
memory

00:28:18,000 --> 00:28:21,200
and because the networking ts does not

00:28:19,840 --> 00:28:23,600
necessarily make

00:28:21,200 --> 00:28:25,840
allocator associations as binding as

00:28:23,600 --> 00:28:28,640
executor associations

00:28:25,840 --> 00:28:30,240
once we have back this new executor the

00:28:28,640 --> 00:28:31,120
new executor with our semantics

00:28:30,240 --> 00:28:32,799
established

00:28:31,120 --> 00:28:35,039
we can submit it for execution by

00:28:32,799 --> 00:28:38,159
calling stood execution execute

00:28:35,039 --> 00:28:39,840
passing the executor and the handler and

00:28:38,159 --> 00:28:41,039
so now finally we've fully worked

00:28:39,840 --> 00:28:44,399
through our example

00:28:41,039 --> 00:28:47,440
broadly lying with p0443 and supported

00:28:44,399 --> 00:28:49,279
any completion notification mechanism

00:28:47,440 --> 00:28:51,840
which brings us back to the initial

00:28:49,279 --> 00:28:54,799
question we set out to answer

00:28:51,840 --> 00:28:56,240
how do we store users final completion

00:28:54,799 --> 00:29:00,159
handlers

00:28:56,240 --> 00:29:02,640
have we succeeded in that task

00:29:00,159 --> 00:29:04,640
let's review what we've actually done we

00:29:02,640 --> 00:29:06,399
have this pending type erasing wrapper

00:29:04,640 --> 00:29:07,440
which type erases the user's completion

00:29:06,399 --> 00:29:09,039
handler

00:29:07,440 --> 00:29:10,880
and therefore it owns the user's

00:29:09,039 --> 00:29:13,600
completion handler

00:29:10,880 --> 00:29:14,880
it is in turn owned by a vector of such

00:29:13,600 --> 00:29:16,799
objects

00:29:14,880 --> 00:29:18,080
and that vector is resident in our i o

00:29:16,799 --> 00:29:21,600
object and so our i o

00:29:18,080 --> 00:29:24,080
object owns that vector transitively

00:29:21,600 --> 00:29:24,960
this means that our i o object owns the

00:29:24,080 --> 00:29:26,640
targets

00:29:24,960 --> 00:29:28,480
it owns the type erased completion

00:29:26,640 --> 00:29:31,440
handlers

00:29:28,480 --> 00:29:33,600
but this is all type erasure this could

00:29:31,440 --> 00:29:35,360
all involve any type

00:29:33,600 --> 00:29:37,440
and we say any type we mean it could

00:29:35,360 --> 00:29:39,200
have any members

00:29:37,440 --> 00:29:41,279
and one of its members could be the i o

00:29:39,200 --> 00:29:43,200
object itself

00:29:41,279 --> 00:29:45,440
one of its members could transitively

00:29:43,200 --> 00:29:48,080
own the i o object

00:29:45,440 --> 00:29:48,799
this would introduce an ownership cycle

00:29:48,080 --> 00:29:50,720
a cycle

00:29:48,799 --> 00:29:52,640
that would not be broken unless the

00:29:50,720 --> 00:29:54,240
pending is invoked unless it moves the

00:29:52,640 --> 00:29:55,919
object onto the stack and allows its

00:29:54,240 --> 00:29:57,520
lifetime to end

00:29:55,919 --> 00:29:59,440
but this formulation would require that

00:29:57,520 --> 00:30:00,080
every asynchronous operation always

00:29:59,440 --> 00:30:01,760
complete

00:30:00,080 --> 00:30:03,279
in order to ensure all resources are

00:30:01,760 --> 00:30:04,480
cleaned up

00:30:03,279 --> 00:30:06,559
and we don't live in a world that's

00:30:04,480 --> 00:30:08,640
anywhere near that perfect

00:30:06,559 --> 00:30:10,399
users sometimes just walk off on whole

00:30:08,640 --> 00:30:12,159
asynchronous components

00:30:10,399 --> 00:30:13,440
allow their lifetimes to end and move on

00:30:12,159 --> 00:30:15,200
with their lives

00:30:13,440 --> 00:30:18,480
and it will be wholly inappropriate for

00:30:15,200 --> 00:30:22,000
us to leak memory in this instance

00:30:18,480 --> 00:30:24,240
so what can we do well

00:30:22,000 --> 00:30:26,080
we could just ban it we could just

00:30:24,240 --> 00:30:27,679
document the fact that users aren't

00:30:26,080 --> 00:30:29,600
allowed to do this

00:30:27,679 --> 00:30:31,360
we could tell them if you have such an

00:30:29,600 --> 00:30:33,039
ownership cycle and you call my

00:30:31,360 --> 00:30:35,039
initiating function

00:30:33,039 --> 00:30:36,640
whatever happens is your fault you take

00:30:35,039 --> 00:30:38,640
responsibility for it

00:30:36,640 --> 00:30:40,559
the restinio library which is built on

00:30:38,640 --> 00:30:41,039
top of azio and which implements ars

00:30:40,559 --> 00:30:43,440
server

00:30:41,039 --> 00:30:45,360
does exactly this in its documentation

00:30:43,440 --> 00:30:46,799
it tells you that if you attach handlers

00:30:45,360 --> 00:30:48,320
to its connection objects

00:30:46,799 --> 00:30:50,000
which transitively own that connection

00:30:48,320 --> 00:30:52,159
object that's a memory leak

00:30:50,000 --> 00:30:54,480
and restinio accepts no responsibility

00:30:52,159 --> 00:30:56,559
for what happens to you

00:30:54,480 --> 00:30:57,919
but we're establishing the baseline of

00:30:56,559 --> 00:30:59,440
asynchronous i o

00:30:57,919 --> 00:31:01,440
for standard c plus plus in the

00:30:59,440 --> 00:31:03,120
networking ts

00:31:01,440 --> 00:31:04,399
and if you look through ts code or just

00:31:03,120 --> 00:31:05,760
think about it you'll realize this is a

00:31:04,399 --> 00:31:08,080
useful pattern

00:31:05,760 --> 00:31:09,519
if you have a state for a connection

00:31:08,080 --> 00:31:11,120
that connection state should probably

00:31:09,519 --> 00:31:13,519
contain the sockets and timers

00:31:11,120 --> 00:31:15,039
that are associated with that connection

00:31:13,519 --> 00:31:16,799
and all the completion handlers floating

00:31:15,039 --> 00:31:18,320
around implementing the logic associated

00:31:16,799 --> 00:31:20,080
with maintaining that connection

00:31:18,320 --> 00:31:21,760
should probably have some say in the

00:31:20,080 --> 00:31:23,279
ownership of that connection

00:31:21,760 --> 00:31:24,799
they should probably be able to keep it

00:31:23,279 --> 00:31:27,120
alive

00:31:24,799 --> 00:31:28,480
but this is exactly the ownership cycle

00:31:27,120 --> 00:31:30,840
i just laid out

00:31:28,480 --> 00:31:33,279
it's incredibly useful and incredibly

00:31:30,840 --> 00:31:35,440
powerful so how can we support it

00:31:33,279 --> 00:31:37,679
without exposing our users to the risk

00:31:35,440 --> 00:31:40,159
of a memory leak

00:31:37,679 --> 00:31:42,320
well just as we solve problems in

00:31:40,159 --> 00:31:43,519
calculus through a change of variable

00:31:42,320 --> 00:31:45,440
we're going to solve this problem

00:31:43,519 --> 00:31:46,480
through a change of ownership we're

00:31:45,440 --> 00:31:47,919
going to take ownership of the

00:31:46,480 --> 00:31:48,880
completion handlers and we're going to

00:31:47,919 --> 00:31:50,480
offload it

00:31:48,880 --> 00:31:52,320
we're going to outsource it to something

00:31:50,480 --> 00:31:54,559
called a service

00:31:52,320 --> 00:31:56,159
services are built specifically to own

00:31:54,559 --> 00:31:56,559
completion handlers and they are owned

00:31:56,159 --> 00:31:59,519
by

00:31:56,559 --> 00:32:01,760
an execution context when the execution

00:31:59,519 --> 00:32:04,559
context lifetimes ends it destroys

00:32:01,760 --> 00:32:05,840
all of the services and in doing this we

00:32:04,559 --> 00:32:08,640
break the cycle

00:32:05,840 --> 00:32:10,080
we prevent this memory leak we allow

00:32:08,640 --> 00:32:12,399
this ownership cycle to

00:32:10,080 --> 00:32:13,760
cycle to occur but we make sure that

00:32:12,399 --> 00:32:14,880
there will never be an instance where

00:32:13,760 --> 00:32:17,919
our users walk off

00:32:14,880 --> 00:32:20,640
and inadvertently leak memory

00:32:17,919 --> 00:32:22,640
so what does a service look like this

00:32:20,640 --> 00:32:24,320
most basic of services taken directly

00:32:22,640 --> 00:32:26,080
from the azo documentation

00:32:24,320 --> 00:32:28,320
demonstrates what they look like they

00:32:26,080 --> 00:32:29,360
must publicly and unambiguously derive

00:32:28,320 --> 00:32:32,320
from stdnet

00:32:29,360 --> 00:32:34,480
execution context service they must

00:32:32,320 --> 00:32:35,840
provide a member type alias key type

00:32:34,480 --> 00:32:38,159
which is either an alias for

00:32:35,840 --> 00:32:39,360
the type itself or one of its base

00:32:38,159 --> 00:32:41,039
classes

00:32:39,360 --> 00:32:42,799
this formulation is somewhat confusing

00:32:41,039 --> 00:32:45,039
at first but it exists to support

00:32:42,799 --> 00:32:46,399
polymorphic hierarchies of services

00:32:45,039 --> 00:32:50,200
which i will not discuss

00:32:46,399 --> 00:32:52,399
in this talk then services must be

00:32:50,200 --> 00:32:53,760
unreconstructable from a stood net

00:32:52,399 --> 00:32:56,240
execution context

00:32:53,760 --> 00:32:57,360
mutable l value reference the purpose

00:32:56,240 --> 00:33:00,720
for this will become clear

00:32:57,360 --> 00:33:02,159
in two slides then services must provide

00:33:00,720 --> 00:33:04,240
this nullary invocable

00:33:02,159 --> 00:33:05,360
shutdown function which is virtual and

00:33:04,240 --> 00:33:07,039
which they override

00:33:05,360 --> 00:33:08,559
which goes through and destroys all

00:33:07,039 --> 00:33:10,720
their managed objects

00:33:08,559 --> 00:33:12,880
ends the lifetime of each and every

00:33:10,720 --> 00:33:14,320
contained completion handler

00:33:12,880 --> 00:33:16,720
this is part of the two-phase

00:33:14,320 --> 00:33:18,399
de-initialization of services

00:33:16,720 --> 00:33:19,919
now a lot of people's ears prick up when

00:33:18,399 --> 00:33:21,120
you say two-phase initialization or

00:33:19,919 --> 00:33:23,200
de-initialization

00:33:21,120 --> 00:33:24,720
and it's widely derived as generally a

00:33:23,200 --> 00:33:26,559
bad practice

00:33:24,720 --> 00:33:28,720
but it's necessary in this instance in

00:33:26,559 --> 00:33:29,679
order for us to resolve potential webs

00:33:28,720 --> 00:33:31,679
of ownership

00:33:29,679 --> 00:33:33,120
which can become quite complicated and

00:33:31,679 --> 00:33:34,880
intractable

00:33:33,120 --> 00:33:36,240
allow me to discuss this through an

00:33:34,880 --> 00:33:38,000
example

00:33:36,240 --> 00:33:41,200
let's say you have an execution context

00:33:38,000 --> 00:33:43,200
which owns a socket and timer service

00:33:41,200 --> 00:33:44,559
and those socket and timer services are

00:33:43,200 --> 00:33:47,600
referenced by a socket

00:33:44,559 --> 00:33:49,760
and a timer now each those socket

00:33:47,600 --> 00:33:50,880
and timer have some pending asynchronous

00:33:49,760 --> 00:33:52,240
operation

00:33:50,880 --> 00:33:54,399
with some completion handler they've

00:33:52,240 --> 00:33:56,000
suspended which is therefore owned by

00:33:54,399 --> 00:33:57,679
the service

00:33:56,000 --> 00:33:59,200
and in accordance with this formulation

00:33:57,679 --> 00:34:00,159
involving an ownership cycle we've been

00:33:59,200 --> 00:34:01,519
discussing

00:34:00,159 --> 00:34:03,760
those completion handlers share

00:34:01,519 --> 00:34:04,960
ownership of a state which in turn owns

00:34:03,760 --> 00:34:07,600
both of those i o

00:34:04,960 --> 00:34:09,599
objects let's think about what would

00:34:07,600 --> 00:34:10,720
happen if the execution context went

00:34:09,599 --> 00:34:12,399
through its services

00:34:10,720 --> 00:34:13,839
and simply ended their lifetime as it

00:34:12,399 --> 00:34:15,520
shut down

00:34:13,839 --> 00:34:17,599
it might decide to end the lifetime of

00:34:15,520 --> 00:34:19,119
the timer service first

00:34:17,599 --> 00:34:21,200
which would of course end the lifetime

00:34:19,119 --> 00:34:22,800
of the timer completion handler

00:34:21,200 --> 00:34:25,839
which would try to end the lifetime of

00:34:22,800 --> 00:34:28,879
the state but the state's ownership is

00:34:25,839 --> 00:34:31,119
shared and the socket completion handler

00:34:28,879 --> 00:34:32,960
still exists and so the state's lifetime

00:34:31,119 --> 00:34:35,359
does not end

00:34:32,960 --> 00:34:37,040
which leaves this timer lying around

00:34:35,359 --> 00:34:38,879
which has a dangling reference to a

00:34:37,040 --> 00:34:42,399
timer service

00:34:38,879 --> 00:34:43,359
undefined behavior now let's imagine

00:34:42,399 --> 00:34:44,639
we're in the world of two-phase

00:34:43,359 --> 00:34:46,480
de-initialization

00:34:44,639 --> 00:34:48,159
let's imagine that the shutdown method

00:34:46,480 --> 00:34:49,599
of the service exists

00:34:48,159 --> 00:34:51,520
rather than going through and simply

00:34:49,599 --> 00:34:53,599
destroying the associated services

00:34:51,520 --> 00:34:54,879
the execution context calls shutdown on

00:34:53,599 --> 00:34:56,320
the timer service

00:34:54,879 --> 00:34:58,079
this destroys the timer completion

00:34:56,320 --> 00:34:59,440
handler which tries to destroy the state

00:34:58,079 --> 00:35:00,720
which fails because the ownership is

00:34:59,440 --> 00:35:02,640
shared

00:35:00,720 --> 00:35:04,640
but notably well the timer's lifetime

00:35:02,640 --> 00:35:06,480
lives on so does the timer service

00:35:04,640 --> 00:35:08,560
and so that reference is a dangling

00:35:06,480 --> 00:35:10,320
there's no one to find behavior here

00:35:08,560 --> 00:35:11,760
then the execution context calls shut

00:35:10,320 --> 00:35:13,200
down on the socket service

00:35:11,760 --> 00:35:14,720
the socket service destroys its

00:35:13,200 --> 00:35:16,720
completion handler which finally

00:35:14,720 --> 00:35:18,320
destroys the state and then the timer

00:35:16,720 --> 00:35:18,960
and socket have their lifetime come to

00:35:18,320 --> 00:35:20,079
an end but

00:35:18,960 --> 00:35:22,079
they can still go off in their

00:35:20,079 --> 00:35:23,680
destructor and use their services

00:35:22,079 --> 00:35:26,160
because the lifetime of their services

00:35:23,680 --> 00:35:27,760
persists only one shutdown has been

00:35:26,160 --> 00:35:29,040
called on each and every service

00:35:27,760 --> 00:35:31,119
and all the completion handlers are

00:35:29,040 --> 00:35:32,720
destroyed is the destructor of each and

00:35:31,119 --> 00:35:36,800
every service allowed to run

00:35:32,720 --> 00:35:39,119
thereby untangling this complicated web

00:35:36,800 --> 00:35:40,400
which leaves just one question how do we

00:35:39,119 --> 00:35:42,240
get at these services

00:35:40,400 --> 00:35:43,760
they're owned by an execution context

00:35:42,240 --> 00:35:45,599
but how

00:35:43,760 --> 00:35:47,040
the networking ts provides a triplet of

00:35:45,599 --> 00:35:49,280
functions to address this

00:35:47,040 --> 00:35:50,640
the first and simplest is use service

00:35:49,280 --> 00:35:52,160
you provide it with the execution

00:35:50,640 --> 00:35:54,000
context and the service type

00:35:52,160 --> 00:35:56,079
and it returns to you a service key type

00:35:54,000 --> 00:35:57,680
reference note this key type crops up

00:35:56,079 --> 00:35:59,599
again to support those polymorphic

00:35:57,680 --> 00:36:02,320
hierarchies which i will not discuss

00:35:59,599 --> 00:36:03,760
in this talk note also that if you

00:36:02,320 --> 00:36:04,720
service fails to find the service it

00:36:03,760 --> 00:36:06,560
will create one

00:36:04,720 --> 00:36:08,720
using that unit reconstructor that i

00:36:06,560 --> 00:36:10,079
discussed two slides ago

00:36:08,720 --> 00:36:11,839
now maybe your service has some

00:36:10,079 --> 00:36:14,000
parameters you wish to provide to it you

00:36:11,839 --> 00:36:15,839
wish to customize some of its behavior

00:36:14,000 --> 00:36:17,520
in this case you can use make service to

00:36:15,839 --> 00:36:18,800
call an arbitrary constructor on that

00:36:17,520 --> 00:36:20,480
service and associate it with the

00:36:18,800 --> 00:36:22,079
execution context

00:36:20,480 --> 00:36:23,839
which opens up a pattern where you

00:36:22,079 --> 00:36:25,599
create an execution context

00:36:23,839 --> 00:36:27,280
call make service to pre-establish

00:36:25,599 --> 00:36:29,280
custom configured services

00:36:27,280 --> 00:36:32,079
and thereafter io objects calling use

00:36:29,280 --> 00:36:33,839
service will get the customized version

00:36:32,079 --> 00:36:36,720
note that if make service cannot create

00:36:33,839 --> 00:36:38,320
the service it throws an exception

00:36:36,720 --> 00:36:40,240
the last function which i'll hopefully

00:36:38,320 --> 00:36:40,800
just glaze over a bit is has service

00:36:40,240 --> 00:36:43,040
which is

00:36:40,800 --> 00:36:44,560
not very useful in a single threaded

00:36:43,040 --> 00:36:46,160
world you should probably know whether

00:36:44,560 --> 00:36:47,440
or not your execution context has a

00:36:46,160 --> 00:36:49,200
service or not

00:36:47,440 --> 00:36:50,720
and in a multi-threaded world make

00:36:49,200 --> 00:36:51,280
service and youth service are thread

00:36:50,720 --> 00:36:53,200
safe

00:36:51,280 --> 00:36:54,880
so a call today might happen right after

00:36:53,200 --> 00:36:56,400
the return from haz service

00:36:54,880 --> 00:36:57,920
so if you predicate the call to make

00:36:56,400 --> 00:36:58,640
service on the return value of has

00:36:57,920 --> 00:37:00,240
service

00:36:58,640 --> 00:37:02,400
you have a time of check to time abuse

00:37:00,240 --> 00:37:03,920
problem and indeed i've never actually

00:37:02,400 --> 00:37:07,200
observed or written

00:37:03,920 --> 00:37:08,800
a single call to has service now that we

00:37:07,200 --> 00:37:10,000
understand all this machinery

00:37:08,800 --> 00:37:11,680
let's go off and take a look at the

00:37:10,000 --> 00:37:13,200
service that we're going to use to solve

00:37:11,680 --> 00:37:15,200
our ownership problems

00:37:13,200 --> 00:37:17,119
that we're going to use to untangle the

00:37:15,200 --> 00:37:20,079
ownership cycle that i discussed

00:37:17,119 --> 00:37:22,000
earlier it of course publicly and

00:37:20,079 --> 00:37:24,480
unambiguously derives from stood net

00:37:22,000 --> 00:37:26,800
execution context service and it has a

00:37:24,480 --> 00:37:28,720
key type which is simply its own type

00:37:26,800 --> 00:37:30,960
there is no polymorphic hierarchy of

00:37:28,720 --> 00:37:33,440
services involved here

00:37:30,960 --> 00:37:35,280
it has the obligatory unit reconstructor

00:37:33,440 --> 00:37:36,320
and it has the obligatory shutdown

00:37:35,280 --> 00:37:38,960
function

00:37:36,320 --> 00:37:39,839
this shutdown function not only destroys

00:37:38,960 --> 00:37:41,680
all

00:37:39,839 --> 00:37:43,040
owned completion handlers all owned

00:37:41,680 --> 00:37:45,680
objects all owned

00:37:43,040 --> 00:37:48,000
ts but it also causes future calls to

00:37:45,680 --> 00:37:49,920
destroy to be no ops

00:37:48,000 --> 00:37:51,520
in this way when those remaining i o

00:37:49,920 --> 00:37:52,880
objects which we discussed with that

00:37:51,520 --> 00:37:54,560
diagram earlier

00:37:52,880 --> 00:37:56,480
go off and try to use this service in

00:37:54,560 --> 00:37:59,839
their destructor they might pass in a

00:37:56,480 --> 00:38:02,320
dangling pointer to be destroyed

00:37:59,839 --> 00:38:03,119
nothing will happen the pointer will be

00:38:02,320 --> 00:38:04,320
ignored

00:38:03,119 --> 00:38:06,160
and so there will be no undefined

00:38:04,320 --> 00:38:07,359
behavior because the service will

00:38:06,160 --> 00:38:08,960
already shut down

00:38:07,359 --> 00:38:11,760
it will know that object's lifetime has

00:38:08,960 --> 00:38:13,280
come to an end and it has no work to do

00:38:11,760 --> 00:38:15,280
which leaves just one function and

00:38:13,280 --> 00:38:16,560
that's the create function which we use

00:38:15,280 --> 00:38:18,720
to construct an object

00:38:16,560 --> 00:38:21,040
whose ownership is offloaded to the

00:38:18,720 --> 00:38:23,359
service is offloaded transitively

00:38:21,040 --> 00:38:24,720
to the execution context which is free

00:38:23,359 --> 00:38:27,520
from the ownership cycle

00:38:24,720 --> 00:38:29,040
we've been hand-wringing about now just

00:38:27,520 --> 00:38:30,000
as with the pending class template i

00:38:29,040 --> 00:38:31,920
presented earlier

00:38:30,000 --> 00:38:34,000
i've elided the actual implementation of

00:38:31,920 --> 00:38:35,119
this class if you want to take a look at

00:38:34,000 --> 00:38:37,119
how it's implemented

00:38:35,119 --> 00:38:38,880
you can go to the code associated with

00:38:37,119 --> 00:38:42,160
this talk and there's a fully worked

00:38:38,880 --> 00:38:42,960
and tested example of it armed with this

00:38:42,160 --> 00:38:44,400
facility

00:38:42,960 --> 00:38:46,000
we're now going to go back to our

00:38:44,400 --> 00:38:48,240
example and we're going to upgrade

00:38:46,000 --> 00:38:50,320
it so it supports that ownership cycle

00:38:48,240 --> 00:38:52,320
so it doesn't succumb to a memory leak

00:38:50,320 --> 00:38:55,280
when we use that altogether too common

00:38:52,320 --> 00:38:56,640
pattern in the networking ts

00:38:55,280 --> 00:38:58,480
the first thing we're going to do is

00:38:56,640 --> 00:39:00,079
we're going to add two type aliases to

00:38:58,480 --> 00:39:00,720
reduce the amount of typing that we're

00:39:00,079 --> 00:39:03,119
going to have to do

00:39:00,720 --> 00:39:04,800
and make this example less visually

00:39:03,119 --> 00:39:06,960
complicated

00:39:04,800 --> 00:39:08,880
then we add a completely new member to

00:39:06,960 --> 00:39:11,760
our basic async event

00:39:08,880 --> 00:39:13,280
a reference to a type our service type

00:39:11,760 --> 00:39:15,359
this is the service that we're going to

00:39:13,280 --> 00:39:16,880
get our pendings away from and later

00:39:15,359 --> 00:39:18,400
release it to

00:39:16,880 --> 00:39:20,000
then notice that to support this

00:39:18,400 --> 00:39:22,160
offloaded ownership model

00:39:20,000 --> 00:39:24,400
we've upgraded the pendings array from

00:39:22,160 --> 00:39:25,119
an array actually resident in the i o

00:39:24,400 --> 00:39:27,280
object

00:39:25,119 --> 00:39:29,119
to a pointer to an array since its

00:39:27,280 --> 00:39:31,040
ownership is now offloaded to the

00:39:29,119 --> 00:39:32,560
service

00:39:31,040 --> 00:39:34,400
you'll notice that our constructor has

00:39:32,560 --> 00:39:36,160
gotten a bit more complicated

00:39:34,400 --> 00:39:38,160
we've still taken that executor and we

00:39:36,160 --> 00:39:38,960
still use it to populate our executor

00:39:38,160 --> 00:39:40,560
member

00:39:38,960 --> 00:39:42,320
but now we need to go off and grab a

00:39:40,560 --> 00:39:43,599
reference to our service

00:39:42,320 --> 00:39:45,359
the way we're going to do this is we're

00:39:43,599 --> 00:39:45,920
going to make use of that use service

00:39:45,359 --> 00:39:48,000
function

00:39:45,920 --> 00:39:49,520
that i discussed earlier we're going to

00:39:48,000 --> 00:39:51,280
call it and provide as its template

00:39:49,520 --> 00:39:52,960
parameter our service type

00:39:51,280 --> 00:39:54,960
and then we also need to provide a

00:39:52,960 --> 00:39:58,079
reference to the execution context that

00:39:54,960 --> 00:40:00,720
service will be associated with

00:39:58,079 --> 00:40:01,920
but how do we get that reference in

00:40:00,720 --> 00:40:04,079
previous years

00:40:01,920 --> 00:40:05,280
in the old networking ts conception of

00:40:04,079 --> 00:40:07,119
executors

00:40:05,280 --> 00:40:09,359
executors were obligated to have a

00:40:07,119 --> 00:40:11,359
nullery invocable member function

00:40:09,359 --> 00:40:14,240
a getter which returned a reference to

00:40:11,359 --> 00:40:16,520
their associated execution context

00:40:14,240 --> 00:40:18,160
but we're now in the brave new world of

00:40:16,520 --> 00:40:19,760
p0443

00:40:18,160 --> 00:40:22,400
where there's no such requirement on

00:40:19,760 --> 00:40:23,520
executors and so we introduce a new

00:40:22,400 --> 00:40:26,560
operation

00:40:23,520 --> 00:40:28,240
we introduce a new property

00:40:26,560 --> 00:40:30,640
an operation that is not concept

00:40:28,240 --> 00:40:31,920
preserving as prefer and require

00:40:30,640 --> 00:40:34,240
but instead which can be used to

00:40:31,920 --> 00:40:35,760
retrieve heterogeneous values associated

00:40:34,240 --> 00:40:38,240
with a property

00:40:35,760 --> 00:40:39,359
in this instance we wish to query the

00:40:38,240 --> 00:40:42,319
stood execution

00:40:39,359 --> 00:40:43,920
context property of the executor this

00:40:42,319 --> 00:40:45,680
will return to us a reference to the

00:40:43,920 --> 00:40:47,520
underlying execution context

00:40:45,680 --> 00:40:49,520
which we can turn around and pass to use

00:40:47,520 --> 00:40:51,119
service which will then return a

00:40:49,520 --> 00:40:52,800
reference to the service which we can

00:40:51,119 --> 00:40:54,960
use to populate our member

00:40:52,800 --> 00:40:57,119
reference the only thing this leads to

00:40:54,960 --> 00:40:58,480
do then is to initialize our pointer

00:40:57,119 --> 00:41:00,240
which we're going to do by calling

00:40:58,480 --> 00:41:01,040
create on the service to get back a

00:41:00,240 --> 00:41:02,960
pointer

00:41:01,040 --> 00:41:05,520
to a pending vector whose ownership has

00:41:02,960 --> 00:41:07,839
been offloaded to that same service

00:41:05,520 --> 00:41:10,160
now this offloaded membership model is

00:41:07,839 --> 00:41:11,359
clearly manual management of lifetimes

00:41:10,160 --> 00:41:13,359
and therefore we're going to need a

00:41:11,359 --> 00:41:15,200
destructor and so we implement one which

00:41:13,359 --> 00:41:16,960
simply goes off to the service and calls

00:41:15,200 --> 00:41:18,000
destroy and provides the pendings

00:41:16,960 --> 00:41:19,599
pointer

00:41:18,000 --> 00:41:21,440
note that if we're being destroyed in

00:41:19,599 --> 00:41:23,520
response to shutting down services all

00:41:21,440 --> 00:41:24,240
we do is take this pointer and pass it

00:41:23,520 --> 00:41:26,079
in

00:41:24,240 --> 00:41:27,920
the service has already been shut down

00:41:26,079 --> 00:41:29,520
and so it will simply disregard the call

00:41:27,920 --> 00:41:31,359
to destroy as a no-op

00:41:29,520 --> 00:41:34,800
there will be no use of that invalid

00:41:31,359 --> 00:41:36,240
pointer no undefined behavior

00:41:34,800 --> 00:41:37,920
the only thing that remains is to go

00:41:36,240 --> 00:41:38,400
through the rest of the implementation

00:41:37,920 --> 00:41:41,040
of our

00:41:38,400 --> 00:41:41,760
i o object and change a bunch of dots to

00:41:41,040 --> 00:41:43,280
arrows

00:41:41,760 --> 00:41:45,040
because we've changed one of our members

00:41:43,280 --> 00:41:46,079
from being an actual value that lives

00:41:45,040 --> 00:41:47,839
inside the object

00:41:46,079 --> 00:41:49,440
to being a pointer whose lifetime is

00:41:47,839 --> 00:41:52,800
managed elsewhere

00:41:49,440 --> 00:41:53,359
i will save you that process after these

00:41:52,800 --> 00:41:56,240
upgrades

00:41:53,359 --> 00:41:57,839
rio object works if you go to that code

00:41:56,240 --> 00:42:01,280
associated with this talk

00:41:57,839 --> 00:42:03,119
this example is there it has unit tests

00:42:01,280 --> 00:42:05,119
one of the unit tests actually creates

00:42:03,119 --> 00:42:06,960
that ownership cycle we discussed

00:42:05,119 --> 00:42:08,800
ensures the asynchronous operation

00:42:06,960 --> 00:42:09,520
doesn't complete and thus have the cycle

00:42:08,800 --> 00:42:11,440
broken by

00:42:09,520 --> 00:42:12,880
the pending object and then lets

00:42:11,440 --> 00:42:14,720
everything go out of scope and asserts

00:42:12,880 --> 00:42:17,760
that everything is cleaned up

00:42:14,720 --> 00:42:19,680
and those unit tests pass and so now we

00:42:17,760 --> 00:42:20,880
support this use pattern from the

00:42:19,680 --> 00:42:23,119
networking ts

00:42:20,880 --> 00:42:26,880
we support our users having this very

00:42:23,119 --> 00:42:29,599
obvious very natural ownership model

00:42:26,880 --> 00:42:31,040
so we must be done right all the

00:42:29,599 --> 00:42:33,440
ergonomics and guarantees of the

00:42:31,040 --> 00:42:37,359
networking ts must be satisfied

00:42:33,440 --> 00:42:39,200
right well no

00:42:37,359 --> 00:42:41,440
because we need to look more closely at

00:42:39,200 --> 00:42:43,119
the execution context we're using

00:42:41,440 --> 00:42:44,640
we're using them to execute our final

00:42:43,119 --> 00:42:46,160
completion handlers

00:42:44,640 --> 00:42:48,079
and when there's a final completion

00:42:46,160 --> 00:42:50,000
handler awaiting invocation

00:42:48,079 --> 00:42:52,319
clearly the execution context has work

00:42:50,000 --> 00:42:54,240
to do clearly there's some reason for it

00:42:52,319 --> 00:42:55,200
to maintain whatever compute resources

00:42:54,240 --> 00:42:57,119
it manages

00:42:55,200 --> 00:43:00,400
to keep them available to flush out that

00:42:57,119 --> 00:43:02,079
queue of invokable objects

00:43:00,400 --> 00:43:04,319
but what happens when there is no work

00:43:02,079 --> 00:43:06,240
to do what happens when there's no

00:43:04,319 --> 00:43:08,480
function objects awaiting invocation in

00:43:06,240 --> 00:43:10,240
the execution context

00:43:08,480 --> 00:43:13,040
what should the execution context do

00:43:10,240 --> 00:43:14,560
with its computational resources then

00:43:13,040 --> 00:43:16,079
should it maintain them in the hopes

00:43:14,560 --> 00:43:17,280
that someone will submit some work in

00:43:16,079 --> 00:43:20,400
the near future

00:43:17,280 --> 00:43:22,160
or should it allow them to go away

00:43:20,400 --> 00:43:23,920
the execution context which ships with

00:43:22,160 --> 00:43:24,560
the networking ts and which we use most

00:43:23,920 --> 00:43:26,960
often

00:43:24,560 --> 00:43:28,240
stood net io context answers this

00:43:26,960 --> 00:43:29,359
question by saying that if there's no

00:43:28,240 --> 00:43:31,040
pending work to do

00:43:29,359 --> 00:43:32,560
you should surrender the computational

00:43:31,040 --> 00:43:33,119
resources back to where you got them

00:43:32,560 --> 00:43:35,839
from

00:43:33,119 --> 00:43:36,400
it's so-called run functions run run one

00:43:35,839 --> 00:43:38,720
pull

00:43:36,400 --> 00:43:40,400
and pull one will return control of the

00:43:38,720 --> 00:43:42,319
calling thread to the caller

00:43:40,400 --> 00:43:45,040
if they ever run out of work if there's

00:43:42,319 --> 00:43:48,560
no pending function objects

00:43:45,040 --> 00:43:50,079
but one of the definitional things we do

00:43:48,560 --> 00:43:50,560
that we've been going over this entire

00:43:50,079 --> 00:43:53,599
talk

00:43:50,560 --> 00:43:55,119
is we don't submit function objects we

00:43:53,599 --> 00:43:57,440
hold them back

00:43:55,119 --> 00:43:59,040
we suspend them and only submit them

00:43:57,440 --> 00:44:01,119
later

00:43:59,040 --> 00:44:02,880
what happens if in the interim the

00:44:01,119 --> 00:44:04,960
execution context to which we wanted to

00:44:02,880 --> 00:44:06,560
submit them runs out of work

00:44:04,960 --> 00:44:08,079
what happens if it releases those

00:44:06,560 --> 00:44:10,880
computational resources

00:44:08,079 --> 00:44:12,079
that we were depending on what happens

00:44:10,880 --> 00:44:15,200
if that call to run

00:44:12,079 --> 00:44:16,000
returns we could simply demand that the

00:44:15,200 --> 00:44:17,839
user

00:44:16,000 --> 00:44:19,760
of the i o context the person who's

00:44:17,839 --> 00:44:21,440
running it directly

00:44:19,760 --> 00:44:23,200
call it in some kind of loop but that's

00:44:21,440 --> 00:44:24,880
not very ergonomic is it

00:44:23,200 --> 00:44:27,440
now the user needs to have some kind of

00:44:24,880 --> 00:44:28,319
manual tracking regarding when and where

00:44:27,440 --> 00:44:29,839
and how and why

00:44:28,319 --> 00:44:31,440
all their operations have or haven't

00:44:29,839 --> 00:44:32,400
completed and if they can move on with

00:44:31,440 --> 00:44:34,560
their lives or not

00:44:32,400 --> 00:44:36,000
we don't want that we want to enable

00:44:34,560 --> 00:44:38,480
this pattern where users can create

00:44:36,000 --> 00:44:39,440
an execution context start a bunch of

00:44:38,480 --> 00:44:41,760
work

00:44:39,440 --> 00:44:43,520
call run and then when run returns all

00:44:41,760 --> 00:44:46,000
the work is good and truly

00:44:43,520 --> 00:44:46,800
done it's actually finished they can

00:44:46,000 --> 00:44:50,000
move on

00:44:46,800 --> 00:44:53,680
with their lives and so what we need is

00:44:50,000 --> 00:44:55,839
some way of tracking outstanding work

00:44:53,680 --> 00:44:58,400
what we need to do is establish the

00:44:55,839 --> 00:45:00,240
outstanding work.tract property on our

00:44:58,400 --> 00:45:02,240
executor

00:45:00,240 --> 00:45:04,000
when this property is established on an

00:45:02,240 --> 00:45:06,240
executor that executor is

00:45:04,000 --> 00:45:07,839
transformed rather than just being a

00:45:06,240 --> 00:45:09,200
handle to the underlying execution

00:45:07,839 --> 00:45:10,880
context it is both

00:45:09,200 --> 00:45:13,680
a handle to the underlying execution

00:45:10,880 --> 00:45:15,200
context and a handle to the idea of

00:45:13,680 --> 00:45:16,960
outstanding work in the underlying

00:45:15,200 --> 00:45:19,599
execution context

00:45:16,960 --> 00:45:20,880
its lifetime becomes a signal to the

00:45:19,599 --> 00:45:23,440
execution context

00:45:20,880 --> 00:45:25,680
that there is work forthcoming that it

00:45:23,440 --> 00:45:26,480
should keep its computational resources

00:45:25,680 --> 00:45:29,119
available

00:45:26,480 --> 00:45:30,240
that we're going to need it in the near

00:45:29,119 --> 00:45:32,319
future

00:45:30,240 --> 00:45:34,720
until that executor's lifetime ends

00:45:32,319 --> 00:45:37,040
therefore the execution context will

00:45:34,720 --> 00:45:39,520
if it's a stood net i o context not

00:45:37,040 --> 00:45:42,800
allow its run functions to return

00:45:39,520 --> 00:45:44,319
it will not indicate that it is stopped

00:45:42,800 --> 00:45:46,000
and therefore when our asynchronous

00:45:44,319 --> 00:45:47,599
operation finally completes

00:45:46,000 --> 00:45:50,160
assuming we keep such an executor's

00:45:47,599 --> 00:45:52,319
lifetime alive we'll have those compute

00:45:50,160 --> 00:45:53,920
resources to turn around and use

00:45:52,319 --> 00:45:55,760
we'll be able to invoke the final

00:45:53,920 --> 00:45:57,440
completion handler and report that our

00:45:55,760 --> 00:46:00,000
operation is done

00:45:57,440 --> 00:46:01,839
we'll be able to enable this use pattern

00:46:00,000 --> 00:46:02,640
where users set up all their work and

00:46:01,839 --> 00:46:04,400
call run

00:46:02,640 --> 00:46:06,319
and when run returns they know they're

00:46:04,400 --> 00:46:06,720
finished they don't need to implement

00:46:06,319 --> 00:46:10,560
any

00:46:06,720 --> 00:46:13,119
manual checking or management

00:46:10,560 --> 00:46:14,800
so is that all there is to it do we just

00:46:13,119 --> 00:46:17,040
need to go back to our example

00:46:14,800 --> 00:46:19,119
and carry around this one executor with

00:46:17,040 --> 00:46:22,000
this property established

00:46:19,119 --> 00:46:23,839
or is there more to it than that do

00:46:22,000 --> 00:46:27,040
asynchronous operations have just

00:46:23,839 --> 00:46:28,800
one executor or is there more

00:46:27,040 --> 00:46:30,720
because while there's definitely the

00:46:28,800 --> 00:46:32,160
users associated executor

00:46:30,720 --> 00:46:34,240
there's also another executor that

00:46:32,160 --> 00:46:35,599
enters in play that brings in a

00:46:34,240 --> 00:46:38,800
definition of i o object

00:46:35,599 --> 00:46:40,400
i articulated earlier in the talk i o

00:46:38,800 --> 00:46:42,240
objects are perhaps defined by the

00:46:40,400 --> 00:46:44,160
ability to call get executor on them and

00:46:42,240 --> 00:46:46,160
get back an executor

00:46:44,160 --> 00:46:47,680
and this may not be the same executor as

00:46:46,160 --> 00:46:49,280
the one the user has associated with

00:46:47,680 --> 00:46:50,400
their completion handler because this is

00:46:49,280 --> 00:46:53,599
the so-called

00:46:50,400 --> 00:46:55,280
io executor this is the second executor

00:46:53,599 --> 00:46:57,599
that enters into the fray whenever you

00:46:55,280 --> 00:47:00,319
kick off an asynchronous operation

00:46:57,599 --> 00:47:00,800
it's called out by name in the ts it's

00:47:00,319 --> 00:47:03,359
called

00:47:00,800 --> 00:47:05,040
i o executor and it's also the executor

00:47:03,359 --> 00:47:05,599
that is to be provided as the default

00:47:05,040 --> 00:47:07,520
candidate

00:47:05,599 --> 00:47:08,800
object when you are deriving the user's

00:47:07,520 --> 00:47:12,000
associated executor

00:47:08,800 --> 00:47:13,599
using associated executor machinery

00:47:12,000 --> 00:47:15,760
recall that earlier when we called get

00:47:13,599 --> 00:47:17,359
associated executor we not only passed

00:47:15,760 --> 00:47:19,839
the user's completion handler

00:47:17,359 --> 00:47:21,520
but we also passed our io executor we

00:47:19,839 --> 00:47:25,200
passed the executor we'd return

00:47:21,520 --> 00:47:27,040
if get executor was called on rio object

00:47:25,200 --> 00:47:28,640
and so every asynchronous operation

00:47:27,040 --> 00:47:31,680
involves not just one

00:47:28,640 --> 00:47:34,400
but two executors an associated executor

00:47:31,680 --> 00:47:36,160
and an i o executor and our users may

00:47:34,400 --> 00:47:36,960
have some expectation that when they

00:47:36,160 --> 00:47:38,480
awaken

00:47:36,960 --> 00:47:40,960
when their asynchronous operation

00:47:38,480 --> 00:47:43,520
completes that not just the associated

00:47:40,960 --> 00:47:45,040
executor is available for their use

00:47:43,520 --> 00:47:47,200
they may expect that they can turn

00:47:45,040 --> 00:47:49,839
around and use this i o executor

00:47:47,200 --> 00:47:51,440
they may expect that it's still in play

00:47:49,839 --> 00:47:53,280
and so we need to maintain work on it

00:47:51,440 --> 00:47:55,839
for this reason

00:47:53,280 --> 00:47:57,520
but there's another deeper reason

00:47:55,839 --> 00:48:00,000
because i o objects may have

00:47:57,520 --> 00:48:02,240
another deeper relationship with their

00:48:00,000 --> 00:48:04,720
underlying execution context

00:48:02,240 --> 00:48:06,079
because i o objects may require some

00:48:04,720 --> 00:48:08,400
operating system specific

00:48:06,079 --> 00:48:11,040
functionality in order to project the

00:48:08,400 --> 00:48:13,040
asynchronous operations they implement

00:48:11,040 --> 00:48:15,280
consider for example that to implement a

00:48:13,040 --> 00:48:18,880
socket you might need a completion port

00:48:15,280 --> 00:48:20,240
an epoll fd an iou ring or a kq file

00:48:18,880 --> 00:48:22,880
descriptor

00:48:20,240 --> 00:48:24,240
and who is going to keep those serviced

00:48:22,880 --> 00:48:25,760
when your work is off running in the

00:48:24,240 --> 00:48:27,520
background who is going to be paying

00:48:25,760 --> 00:48:28,800
attention to see if it actually

00:48:27,520 --> 00:48:30,720
completes

00:48:28,800 --> 00:48:32,079
the logical answer to this is that you

00:48:30,720 --> 00:48:34,240
may have and require

00:48:32,079 --> 00:48:35,680
a special execution context which does

00:48:34,240 --> 00:48:37,440
exactly this

00:48:35,680 --> 00:48:38,800
you may not care about submitting

00:48:37,440 --> 00:48:40,559
function objects to it

00:48:38,800 --> 00:48:42,400
instead maybe you just care that it

00:48:40,559 --> 00:48:45,040
keeps that epoll fd service

00:48:42,400 --> 00:48:46,960
it keeps dequeuing those notifications

00:48:45,040 --> 00:48:48,240
but if you allow it to run out of work

00:48:46,960 --> 00:48:50,319
if you allow it to release its

00:48:48,240 --> 00:48:51,359
computational resources

00:48:50,319 --> 00:48:53,599
then no one's going to be paying

00:48:51,359 --> 00:48:55,359
attention to that epo fd you're never

00:48:53,599 --> 00:48:56,559
going to get a context when your write

00:48:55,359 --> 00:48:59,520
or read or connect

00:48:56,559 --> 00:49:00,559
is done the user's asynchronous work may

00:48:59,520 --> 00:49:03,680
inexplicably

00:49:00,559 --> 00:49:04,160
stall out and therefore for this reason

00:49:03,680 --> 00:49:05,839
also

00:49:04,160 --> 00:49:07,920
it's imperative that we maintain

00:49:05,839 --> 00:49:08,720
outstanding work.tract on the i o

00:49:07,920 --> 00:49:12,000
executor

00:49:08,720 --> 00:49:13,599
along with the users associated executor

00:49:12,000 --> 00:49:15,680
so let's take a look and see how we

00:49:13,599 --> 00:49:16,240
might do that let's go back to our

00:49:15,680 --> 00:49:18,079
example

00:49:16,240 --> 00:49:20,000
and examine how we can modify it to

00:49:18,079 --> 00:49:21,359
satisfy this last requirement of the

00:49:20,000 --> 00:49:23,599
networking ts

00:49:21,359 --> 00:49:24,400
how we can make our code more ergonomic

00:49:23,599 --> 00:49:26,160
and integrate

00:49:24,400 --> 00:49:28,240
better in the environment the networking

00:49:26,160 --> 00:49:29,680
ts provides

00:49:28,240 --> 00:49:31,760
the first change we're going to make is

00:49:29,680 --> 00:49:33,520
that we need to grab our i o executor

00:49:31,760 --> 00:49:35,040
and try and establish outstanding

00:49:33,520 --> 00:49:37,040
work.tract on it

00:49:35,040 --> 00:49:38,800
and so that's the new first line of our

00:49:37,040 --> 00:49:41,599
initiation function

00:49:38,800 --> 00:49:43,520
note that we use prefer and not require

00:49:41,599 --> 00:49:44,960
and the reason we do this is identical

00:49:43,520 --> 00:49:47,520
to the reason we used prefer

00:49:44,960 --> 00:49:49,839
and not require when we were trying to

00:49:47,520 --> 00:49:51,680
establish the allocator property

00:49:49,839 --> 00:49:53,920
the underlying execution context might

00:49:51,680 --> 00:49:56,319
not have the concept of tracked work

00:49:53,920 --> 00:49:57,520
it might never end it might not have the

00:49:56,319 --> 00:49:59,119
concept of ending

00:49:57,520 --> 00:50:01,119
and therefore it might not support this

00:49:59,119 --> 00:50:02,800
property we don't want to

00:50:01,119 --> 00:50:04,880
upgrade failure to establish this

00:50:02,800 --> 00:50:05,520
property from just not establishing the

00:50:04,880 --> 00:50:07,680
property

00:50:05,520 --> 00:50:09,119
to a hard compile failure by moving from

00:50:07,680 --> 00:50:11,839
preferred to require

00:50:09,119 --> 00:50:13,839
and therefore we're going to use prefer

00:50:11,839 --> 00:50:15,440
then we grab the user's associated

00:50:13,839 --> 00:50:17,680
executor by providing the completion

00:50:15,440 --> 00:50:20,800
handler and the default candidate object

00:50:17,680 --> 00:50:22,400
rio executor but that's not enough it's

00:50:20,800 --> 00:50:23,119
not enough to just get the associated

00:50:22,400 --> 00:50:24,960
executor

00:50:23,119 --> 00:50:26,160
we need to try and establish outstanding

00:50:24,960 --> 00:50:28,720
work.tract on it

00:50:26,160 --> 00:50:29,520
as well and so we turn around and we do

00:50:28,720 --> 00:50:32,640
exactly

00:50:29,520 --> 00:50:34,400
that then with both these executors that

00:50:32,640 --> 00:50:36,880
both track work in hand

00:50:34,400 --> 00:50:38,720
we implace into the pendings array we

00:50:36,880 --> 00:50:40,319
emplace a lambda which captures the

00:50:38,720 --> 00:50:41,200
completion handler and both the

00:50:40,319 --> 00:50:43,680
executors

00:50:41,200 --> 00:50:45,520
thereby ensuring their lifetimes persist

00:50:43,680 --> 00:50:47,200
that the concept of outstanding work in

00:50:45,520 --> 00:50:48,720
those underlying execution context

00:50:47,200 --> 00:50:50,480
persists

00:50:48,720 --> 00:50:51,920
moving inside the lambda that we in

00:50:50,480 --> 00:50:53,680
place into the pendings array

00:50:51,920 --> 00:50:54,960
we still go off and we grab that

00:50:53,680 --> 00:50:56,720
associated allocator

00:50:54,960 --> 00:50:58,880
the one associated with the user's final

00:50:56,720 --> 00:51:00,880
completion handler and we still try and

00:50:58,880 --> 00:51:02,880
establish the allocator property on the

00:51:00,880 --> 00:51:04,559
user's associated executor

00:51:02,880 --> 00:51:06,720
but keep in mind this isn't just the

00:51:04,559 --> 00:51:08,079
user's associated executor

00:51:06,720 --> 00:51:09,760
this is a version of the user's

00:51:08,079 --> 00:51:11,280
associated executor which may have

00:51:09,760 --> 00:51:13,599
outstanding work.tract

00:51:11,280 --> 00:51:14,640
established and therefore after this

00:51:13,599 --> 00:51:17,040
call to prefer

00:51:14,640 --> 00:51:19,440
it may have both outstanding work.tract

00:51:17,040 --> 00:51:21,359
and allocator established

00:51:19,440 --> 00:51:23,839
with this in hand we can submit work

00:51:21,359 --> 00:51:25,359
through stood execution execute

00:51:23,839 --> 00:51:26,960
but keep in mind before we just

00:51:25,359 --> 00:51:27,680
submitted the user's final completion

00:51:26,960 --> 00:51:29,200
handler

00:51:27,680 --> 00:51:31,359
we just passed the completion handler

00:51:29,200 --> 00:51:34,319
itself as the second argument

00:51:31,359 --> 00:51:35,119
but now we can't do this because execute

00:51:34,319 --> 00:51:36,640
might

00:51:35,119 --> 00:51:39,040
put the user's completion handler to

00:51:36,640 --> 00:51:39,599
sleep it might defer the invocation of

00:51:39,040 --> 00:51:41,760
it

00:51:39,599 --> 00:51:43,599
and if that happens we don't want our i

00:51:41,760 --> 00:51:45,760
o executor to run out of work and stall

00:51:43,599 --> 00:51:47,200
out we want to keep it available for the

00:51:45,760 --> 00:51:48,640
user to use when their completion

00:51:47,200 --> 00:51:50,000
handler is invoked

00:51:48,640 --> 00:51:52,079
and so rather than submitting the raw

00:51:50,000 --> 00:51:53,839
completion handler we submit a lambda

00:51:52,079 --> 00:51:56,079
which captures the handler and also

00:51:53,839 --> 00:51:58,960
captures the version of the i o executor

00:51:56,079 --> 00:51:59,520
with outstanding work.tract established

00:51:58,960 --> 00:52:01,280
then

00:51:59,520 --> 00:52:02,960
when the underlying execution context

00:52:01,280 --> 00:52:05,440
gets around to finally invoking our

00:52:02,960 --> 00:52:06,400
function object we move the i o executor

00:52:05,440 --> 00:52:08,480
out of the lambda

00:52:06,400 --> 00:52:10,480
onto the local stack to make sure that

00:52:08,480 --> 00:52:12,480
its lifetime and thus the concept of

00:52:10,480 --> 00:52:13,119
tracked work in the associated execution

00:52:12,480 --> 00:52:15,520
context

00:52:13,119 --> 00:52:17,280
ends in a timely manner and then we

00:52:15,520 --> 00:52:19,280
invoke the completion handler

00:52:17,280 --> 00:52:20,640
we complete the user's asynchronous

00:52:19,280 --> 00:52:23,440
operation

00:52:20,640 --> 00:52:25,440
we're done note that there's no need to

00:52:23,440 --> 00:52:27,119
carry along that version of the user's

00:52:25,440 --> 00:52:28,559
associated executor without standing

00:52:27,119 --> 00:52:30,480
work.tracked anymore

00:52:28,559 --> 00:52:32,319
because we submitted an actual function

00:52:30,480 --> 00:52:33,680
object for invocation in its execution

00:52:32,319 --> 00:52:35,760
context

00:52:33,680 --> 00:52:37,760
and an actual pending function object

00:52:35,760 --> 00:52:39,440
was the original formulation of pending

00:52:37,760 --> 00:52:40,160
work that we established several slides

00:52:39,440 --> 00:52:41,680
ago

00:52:40,160 --> 00:52:43,440
and therefore it's fine to let that

00:52:41,680 --> 00:52:46,480
executor go out of scope but we do

00:52:43,440 --> 00:52:48,160
need to maintain the i o executor

00:52:46,480 --> 00:52:50,480
so now that we've bootstrapped this from

00:52:48,160 --> 00:52:52,240
nothing now that we've added entirely

00:52:50,480 --> 00:52:53,359
new asynchronous functionality to the

00:52:52,240 --> 00:52:56,160
networking ts

00:52:53,359 --> 00:52:57,920
what are the takeaways well the first

00:52:56,160 --> 00:52:59,040
takeaway is that there's a lot of nuance

00:52:57,920 --> 00:53:02,079
and sharp edges

00:52:59,040 --> 00:53:03,520
a lot of moving parts to building

00:53:02,079 --> 00:53:04,240
asynchronous functionality from the

00:53:03,520 --> 00:53:06,319
ground up

00:53:04,240 --> 00:53:08,400
to establishing all the guarantees and

00:53:06,319 --> 00:53:10,160
practices of the networking ts

00:53:08,400 --> 00:53:11,839
and so while this is a valuable tool in

00:53:10,160 --> 00:53:13,200
your toolbox and you should certainly

00:53:11,839 --> 00:53:15,280
use it when appropriate

00:53:13,200 --> 00:53:16,800
you should avoid it if you can your life

00:53:15,280 --> 00:53:17,760
will be easier and less fraught with

00:53:16,800 --> 00:53:19,280
bugs

00:53:17,760 --> 00:53:20,880
if you can get the functionality you

00:53:19,280 --> 00:53:21,839
want through a composed asynchronous

00:53:20,880 --> 00:53:24,240
operation

00:53:21,839 --> 00:53:25,839
then maybe you should do that but you

00:53:24,240 --> 00:53:28,000
now have the tools to turn around and

00:53:25,839 --> 00:53:30,960
bootstrap asynchronous functionality

00:53:28,000 --> 00:53:32,720
from nothing the next thing we explored

00:53:30,960 --> 00:53:34,319
was this common ownership pattern

00:53:32,720 --> 00:53:36,240
this potentially cyclic ownership

00:53:34,319 --> 00:53:38,079
pattern wherein completion handlers

00:53:36,240 --> 00:53:39,119
transitively owned their associated i o

00:53:38,079 --> 00:53:41,040
objects

00:53:39,119 --> 00:53:42,800
and we learned how services fit into the

00:53:41,040 --> 00:53:45,119
ecosystem of the networking ts

00:53:42,800 --> 00:53:46,720
to break this cycle and enable this use

00:53:45,119 --> 00:53:48,800
pattern to make sure that we don't

00:53:46,720 --> 00:53:51,920
arbitrarily close our users off from

00:53:48,800 --> 00:53:53,760
very valuable tools in their toolboxes

00:53:51,920 --> 00:53:54,960
and the last thing we learned was how we

00:53:53,760 --> 00:53:56,640
can put that final

00:53:54,960 --> 00:53:58,800
sheen on top of the patterns and

00:53:56,640 --> 00:54:01,119
practices of the networking ts

00:53:58,800 --> 00:54:02,720
how we can let execution context know

00:54:01,119 --> 00:54:04,480
that they might have submitted function

00:54:02,720 --> 00:54:06,319
objects coming in the future

00:54:04,480 --> 00:54:08,079
how we can indicate to them that there's

00:54:06,319 --> 00:54:10,640
outstanding work and they should keep

00:54:08,079 --> 00:54:12,640
their computational resources available

00:54:10,640 --> 00:54:15,280
and in so doing we provide our users

00:54:12,640 --> 00:54:17,920
with a wonderful consistent pattern

00:54:15,280 --> 00:54:19,760
that they can call run on an i o context

00:54:17,920 --> 00:54:21,119
and when it returns know that all their

00:54:19,760 --> 00:54:22,319
work is done

00:54:21,119 --> 00:54:24,160
that all they need to get their

00:54:22,319 --> 00:54:26,000
asynchronous environment bootstrapped is

00:54:24,160 --> 00:54:28,720
to create an execution context

00:54:26,000 --> 00:54:29,599
an io context to start some work and

00:54:28,720 --> 00:54:31,200
call run

00:54:29,599 --> 00:54:33,119
knowing that under the covers in

00:54:31,200 --> 00:54:35,280
accordance with the patterns practices

00:54:33,119 --> 00:54:37,040
and guarantees of the networking ts

00:54:35,280 --> 00:54:38,960
we'll keep that execution context

00:54:37,040 --> 00:54:41,839
informed of all outstanding work

00:54:38,960 --> 00:54:43,280
until everything is good and truly done

00:54:41,839 --> 00:54:46,160
that when they return from run

00:54:43,280 --> 00:54:46,799
they can move on resting easy because

00:54:46,160 --> 00:54:48,880
when

00:54:46,799 --> 00:54:50,400
widening the base of the networking ts

00:54:48,880 --> 00:54:51,920
we were very careful to read our

00:54:50,400 --> 00:54:53,839
application honoring all the

00:54:51,920 --> 00:54:56,079
requirements and practices

00:54:53,839 --> 00:54:58,880
keeping it as ergonomic as possible

00:54:56,079 --> 00:55:00,799
keeping it as consistent as possible

00:54:58,880 --> 00:55:02,960
and indeed when establishing the

00:55:00,799 --> 00:55:05,599
baseline for asynchronous i o

00:55:02,960 --> 00:55:06,480
in iso standard c plus plus we should

00:55:05,599 --> 00:55:09,680
demand

00:55:06,480 --> 00:55:09,680
nothing less

00:55:09,839 --> 00:55:13,119
and now i have a few minutes to try and

00:55:11,280 --> 00:55:15,760
answer some of your q and a's so let's

00:55:13,119 --> 00:55:17,359
take a look there

00:55:15,760 --> 00:55:19,599
yeah so the first one that i see here is

00:55:17,359 --> 00:55:21,119
a question about covet 19

00:55:19,599 --> 00:55:22,880
and there's there's been discussion

00:55:21,119 --> 00:55:24,720
about whether covet 19 and the fact that

00:55:22,880 --> 00:55:26,160
the committee's been working remotely is

00:55:24,720 --> 00:55:28,079
going to affect the delivery of

00:55:26,160 --> 00:55:30,400
executors and networking

00:55:28,079 --> 00:55:31,359
but those are both very very high

00:55:30,400 --> 00:55:34,480
priority like

00:55:31,359 --> 00:55:36,319
um the paper i think it's p0592 that

00:55:34,480 --> 00:55:39,680
lays out the broad plan for c

00:55:36,319 --> 00:55:41,680
plus plus 23. um basically um executors

00:55:39,680 --> 00:55:42,000
networking and co-routine support are

00:55:41,680 --> 00:55:44,319
the

00:55:42,000 --> 00:55:45,920
the highest priority and so i haven't

00:55:44,319 --> 00:55:47,119
heard anyone say that it's not going to

00:55:45,920 --> 00:55:48,559
get in or they think it's not going to

00:55:47,119 --> 00:55:50,000
get in but what i have heard is people

00:55:48,559 --> 00:55:51,200
who are kind of like

00:55:50,000 --> 00:55:52,400
are we going to be able to do everything

00:55:51,200 --> 00:55:53,599
are we just going to get networking and

00:55:52,400 --> 00:55:56,079
executors so

00:55:53,599 --> 00:55:57,440
i mean we do have a solid year year and

00:55:56,079 --> 00:55:58,799
a half to try and wrap that up and

00:55:57,440 --> 00:56:00,400
there's been a lot of discussion about

00:55:58,799 --> 00:56:01,599
executors over the summer and moving

00:56:00,400 --> 00:56:03,119
into the fall

00:56:01,599 --> 00:56:04,880
we're looking to start actually polling

00:56:03,119 --> 00:56:06,319
that um and so hopefully then we can

00:56:04,880 --> 00:56:08,160
move on to networking and actually

00:56:06,319 --> 00:56:12,079
deliver despite the fact that uh

00:56:08,160 --> 00:56:13,599
covet 19 happened i i didn't actually

00:56:12,079 --> 00:56:16,079
see the the talk before mine

00:56:13,599 --> 00:56:17,520
um uh so yeah i didn't see the efficient

00:56:16,079 --> 00:56:18,480
implementation of a move-only call well

00:56:17,520 --> 00:56:20,240
and i'm sure that

00:56:18,480 --> 00:56:21,920
the example that i'm going to upload in

00:56:20,240 --> 00:56:24,079
the uh the zip

00:56:21,920 --> 00:56:25,599
um the repo associated with this slide

00:56:24,079 --> 00:56:27,200
uh could be improved it's just something

00:56:25,599 --> 00:56:30,160
that i wrote that works that's

00:56:27,200 --> 00:56:31,200
mostly slide where i mean i do use it at

00:56:30,160 --> 00:56:33,839
work but the

00:56:31,200 --> 00:56:34,240
the place that it's used at work is not

00:56:33,839 --> 00:56:35,599
um

00:56:34,240 --> 00:56:37,680
efficiency critical and so i didn't put

00:56:35,599 --> 00:56:40,160
a lot of time into um

00:56:37,680 --> 00:56:41,760
implementing it uh the inheritance from

00:56:40,160 --> 00:56:43,440
service is necessary as

00:56:41,760 --> 00:56:44,720
you know um i would guess the

00:56:43,440 --> 00:56:46,319
inheritance from this service is

00:56:44,720 --> 00:56:46,960
necessary for that shutdown virtual

00:56:46,319 --> 00:56:48,880
method

00:56:46,960 --> 00:56:50,400
i mean it's it's likely it's probable

00:56:48,880 --> 00:56:52,240
that you could implement it by using a

00:56:50,400 --> 00:56:53,839
concept and type erasure

00:56:52,240 --> 00:56:55,280
um but then it's like kind of you're

00:56:53,839 --> 00:56:55,680
back at square one right like you're

00:56:55,280 --> 00:56:57,520
still

00:56:55,680 --> 00:56:58,960
implementing a hierarchy of virtual

00:56:57,520 --> 00:56:59,280
functions on top of it so you may as

00:56:58,960 --> 00:57:01,359
well

00:56:59,280 --> 00:57:02,480
um punt that onto the user interestingly

00:57:01,359 --> 00:57:05,280
enough when

00:57:02,480 --> 00:57:07,040
sg4 networking reviewed the networking

00:57:05,280 --> 00:57:08,559
ts one of the things that was pointed

00:57:07,040 --> 00:57:10,160
out was that it's kind of weird that we

00:57:08,559 --> 00:57:11,680
have a concept called service that

00:57:10,160 --> 00:57:12,480
requires public and unambiguous

00:57:11,680 --> 00:57:14,079
derivation

00:57:12,480 --> 00:57:16,160
from another type like that was pointed

00:57:14,079 --> 00:57:17,680
out as weird in

00:57:16,160 --> 00:57:19,040
uh and there's a prague meeting actually

00:57:17,680 --> 00:57:19,760
in february the last time that we were

00:57:19,040 --> 00:57:22,799
allowed to

00:57:19,760 --> 00:57:26,000
look at each other in person

00:57:22,799 --> 00:57:27,520
um i actually don't expect any problems

00:57:26,000 --> 00:57:29,680
with iou ring that's the next question

00:57:27,520 --> 00:57:31,280
is about iou ring i don't expect any

00:57:29,680 --> 00:57:32,160
problems with iou ring because i've

00:57:31,280 --> 00:57:34,319
actually

00:57:32,160 --> 00:57:36,640
written a toy implementation of an

00:57:34,319 --> 00:57:39,760
executor execution context and i o

00:57:36,640 --> 00:57:41,200
object um that use ilu ring um and it

00:57:39,760 --> 00:57:43,280
worked very well i mean i didn't

00:57:41,200 --> 00:57:45,040
i didn't try and um completely tune it

00:57:43,280 --> 00:57:46,480
but it works and the code is on

00:57:45,040 --> 00:57:48,480
on github and i actually have an

00:57:46,480 --> 00:57:49,599
outstanding uh issue to address with

00:57:48,480 --> 00:57:51,040
that

00:57:49,599 --> 00:57:52,640
uh that looks like all the questions and

00:57:51,040 --> 00:57:53,520
i think we're right on time so i'm gonna

00:57:52,640 --> 00:57:55,440
wrap up there

00:57:53,520 --> 00:58:09,839
if i'm around in the hallway just feel

00:57:55,440 --> 00:58:09,839
free to talk to me about this

00:58:16,400 --> 00:58:18,480

YouTube URL: https://www.youtube.com/watch?v=xgXFZ-rYc4w


