Title: Heterogeneous Programming in C++ with SYCL 2020 - Michael Wong & Gordon Brown - CppCon 2020
Publication date: 2020-09-29
Playlist: CppCon 2020 Day 3
Description: 
	https://cppcon.org/
https://github.com/CppCon/CppCon2020
---
Computer system architecture trends are constantly evolving to provide higher performance and computing power, to support an increasing demand for high-performance computing domains including AI, machine learning, image processing and automotive driving aids. The most recent being the move towards heterogeneity, where a system has one or more co-processors, often a GPU, working with it in parallel. These kinds of systems are everywhere, from desktop machines and high-performance computing supercomputers to mobile and embedded devices.

In 2018 we presented SYCL; an open-standard, single-source standard C++ programming model for heterogeneous platforms, looking specifically at programming GPUs. Since then, as the momentum behind SYCL continues to grow, the SYCL working group within Khronos has been working hard with various hardware vendors, applications developers and universities across the industry to release an update to the standard.

The latest revision of the SYCL specification is SYCL 2020, and it brings a number of significant new features that will dramatically improve how you can program heterogeneous systems in C++.

Firstly, SYCL 2020 will introduce support for unified shared memory (USM) a new option for managing memory in SYCL alongside the existing buffer/accessor abstract which allows pointers and pointer-based structures to be passed directly to device functions. USM also provides a new explicit data management API which provides more fine-grained control over how data is allocated and moved between devices.

SYCL 2020 will also introduce a generalization of the SYCL specification which, while not altering the API in any significant way, allows SYCL implementations to target additional backends to OpenCL such as CUDA, HIP, OpenMP, etc. The most notable example of this is in the recent addition to the open-source SYCL implementation Data-Parallel C++ (DPC++) to support a CUDA backend, allowing SYCL applications to target Nvidia GPUs using the native CUDA driver.

SYCL 2020 will bump the minimum required C++ version to C++17 and will introduce a number of new features that will improve the user experience of writing SYCL applications, as well as further, align SYCL with ISO C++. This includes using class template argument deduction (CTAD) to reduce the verbosity of the SYCL AP and alignment with atomic_ref and the parallel algorithms.

Finally, SYCL 2020 will introduce a number of features which will allow applications to gain better performance by better utilising the hardware including sub-groups, group-based algorithms and optimized reductions.

This talk will present the current state of the SYCL ecosystem, including the supported implementations of which now there are four; ComputeCpp, DPC++, hipSYCL and triSYCL, as well as the range of platforms that are now supported by SYCL via these implementations. It will take a close look specifically at supporting Nvidia GPUs via DPC++â€™s CUDA backend, as this was a widely requested feature by SYCL developers in the C++ community.

This talk will then take a deep dive into the new features that SYCL 2020 is introducing and how these will improve SYCL application development for C++ developers.

Finally, this talk will end with a look at the SYCL standard, and where we hope to see it going in the future.

---
Michael Wong
DE, Codeplay

Gordon Brown
Principal Software Engineer, Codeplay Software Ltd.

---
Streamed & Edited by Digital Medium Ltd - events.digital-medium.co.uk
events@digital-medium.co.uk
Captions: 
	00:00:09,040 --> 00:00:13,120
hi everybody

00:00:10,320 --> 00:00:13,759
welcome to this talk on heterogeneous

00:00:13,120 --> 00:00:17,440
programming

00:00:13,759 --> 00:00:19,520
in c plus with sql 2020

00:00:17,440 --> 00:00:20,880
my name is michael wong along with my

00:00:19,520 --> 00:00:22,800
colleague gordon brown

00:00:20,880 --> 00:00:24,400
we would like to demonstrate to you how

00:00:22,800 --> 00:00:26,160
you can use especially the latest

00:00:24,400 --> 00:00:27,920
upcoming cinco 2020

00:00:26,160 --> 00:00:29,359
to program heterogeneous devices

00:00:27,920 --> 00:00:32,560
accelerators in

00:00:29,359 --> 00:00:32,560
modern c plus plus

00:00:33,360 --> 00:00:36,559
so just a couple of um a quick slide

00:00:35,840 --> 00:00:39,680
about what my

00:00:36,559 --> 00:00:42,239
company's company do um

00:00:39,680 --> 00:00:44,000
does coldplay does a lot of things that

00:00:42,239 --> 00:00:46,960
has to do with accelerated

00:00:44,000 --> 00:00:46,960
gpu computing

00:00:48,640 --> 00:00:50,879
so

00:00:51,760 --> 00:00:54,960
introduce introducing my colleague

00:00:53,360 --> 00:00:57,680
golden brown he is

00:00:54,960 --> 00:00:58,320
a principal engineer he has a background

00:00:57,680 --> 00:00:59,920
in c plus

00:00:58,320 --> 00:01:01,440
programming models for heterogeneous

00:00:59,920 --> 00:01:02,879
systems

00:01:01,440 --> 00:01:05,119
he's been a principal engineer with

00:01:02,879 --> 00:01:07,280
coplay and he's worked on the

00:01:05,119 --> 00:01:08,560
sickle implementation called compute cpp

00:01:07,280 --> 00:01:10,640
since his inception

00:01:08,560 --> 00:01:12,479
he's been a massive contributor to the

00:01:10,640 --> 00:01:14,240
kernel sickle standard and to c

00:01:12,479 --> 00:01:15,600
plus executive and heterogeneous

00:01:14,240 --> 00:01:18,400
programming for two years

00:01:15,600 --> 00:01:18,400
in sg1

00:01:20,640 --> 00:01:23,840
a little bit about myself i'm a

00:01:22,000 --> 00:01:25,520
distinguished engineer with co-play i'm

00:01:23,840 --> 00:01:27,280
also the chair of sicko

00:01:25,520 --> 00:01:28,640
the heterogeneous programming language

00:01:27,280 --> 00:01:30,320
um as well as being the chair of the

00:01:28,640 --> 00:01:32,479
c-plus plus directions group

00:01:30,320 --> 00:01:34,240
i've had to wear many hats over the

00:01:32,479 --> 00:01:37,119
years um

00:01:34,240 --> 00:01:38,400
recently i'm now the chair of the c-plus

00:01:37,119 --> 00:01:41,600
plus sg19

00:01:38,400 --> 00:01:43,200
on machine learning as well as sg14 on

00:01:41,600 --> 00:01:45,280
games development low latency

00:01:43,200 --> 00:01:47,119
financial trading and embedded my career

00:01:45,280 --> 00:01:49,410
has spanned from hyper from

00:01:47,119 --> 00:01:51,200
being a compiler developer engineer

00:01:49,410 --> 00:01:53,200
[Music]

00:01:51,200 --> 00:01:55,040
working writing exception handling code

00:01:53,200 --> 00:01:56,479
and how to how to implement the

00:01:55,040 --> 00:01:58,479
exception handling cms plus

00:01:56,479 --> 00:02:00,960
and object models to high performance

00:01:58,479 --> 00:02:01,520
computing as well and then now towards

00:02:00,960 --> 00:02:03,040
um

00:02:01,520 --> 00:02:04,399
embedded computing with autonomous

00:02:03,040 --> 00:02:05,600
vehicles so i've been doing a lot of

00:02:04,399 --> 00:02:07,600
research lately

00:02:05,600 --> 00:02:09,679
in terms of the safety of autonomous

00:02:07,600 --> 00:02:11,760
vehicles machine learning and ai models

00:02:09,679 --> 00:02:12,720
but i also still stay with my first

00:02:11,760 --> 00:02:14,480
level being

00:02:12,720 --> 00:02:16,000
involved with programming models and

00:02:14,480 --> 00:02:18,560
heterogeneous programming models

00:02:16,000 --> 00:02:18,560
specifically

00:02:19,040 --> 00:02:24,080
so some acknowledgement um a talk like

00:02:22,560 --> 00:02:25,440
this wouldn't have been possible without

00:02:24,080 --> 00:02:26,400
numerous internal and external

00:02:25,440 --> 00:02:28,959
contributions

00:02:26,400 --> 00:02:30,319
and i want to make sure that um that we

00:02:28,959 --> 00:02:33,200
uh we credit them

00:02:30,319 --> 00:02:35,360
wherever credit is due um i even stole

00:02:33,200 --> 00:02:37,280
this disclaimer from them so

00:02:35,360 --> 00:02:38,640
um there might still be errors that

00:02:37,280 --> 00:02:40,800
remain and any that remain

00:02:38,640 --> 00:02:42,160
are all their fault no no actually it's

00:02:40,800 --> 00:02:45,040
our fault

00:02:42,160 --> 00:02:46,319
um they will also use logos from various

00:02:45,040 --> 00:02:46,640
companies and we just want to make sure

00:02:46,319 --> 00:02:50,160
that

00:02:46,640 --> 00:02:52,640
those are credited as we go

00:02:50,160 --> 00:02:54,080
so much of this talk is going to broke

00:02:52,640 --> 00:02:55,440
break down into three as in

00:02:54,080 --> 00:02:57,120
almost all my talks i like to just

00:02:55,440 --> 00:02:59,360
separate it into three items

00:02:57,120 --> 00:03:00,400
um we're going to talk about sickle past

00:02:59,360 --> 00:03:01,440
uh what we're going to talk about the

00:03:00,400 --> 00:03:02,879
origin of sickle

00:03:01,440 --> 00:03:04,800
some of the lessons learned and the

00:03:02,879 --> 00:03:05,920
impact of sickle on the ecosystem

00:03:04,800 --> 00:03:07,920
we're going to talk about the sickle

00:03:05,920 --> 00:03:09,760
present where we are right now

00:03:07,920 --> 00:03:11,920
that sickle being used as a general

00:03:09,760 --> 00:03:12,720
purpose a high performance programming

00:03:11,920 --> 00:03:14,480
model

00:03:12,720 --> 00:03:16,640
and we're going to show you a deep dive

00:03:14,480 --> 00:03:19,040
for what's coming in sickle 2020

00:03:16,640 --> 00:03:20,720
now sql 2020 has not been finalized yet

00:03:19,040 --> 00:03:22,879
but we are allowed to show you

00:03:20,720 --> 00:03:24,400
many of the features that are already

00:03:22,879 --> 00:03:27,280
essentially enshrined

00:03:24,400 --> 00:03:28,720
um in the uh in the standard then we're

00:03:27,280 --> 00:03:30,000
going to look at the sickle future with

00:03:28,720 --> 00:03:32,640
the ecosystems

00:03:30,000 --> 00:03:33,760
that's rapidly gaining uh momentum and

00:03:32,640 --> 00:03:35,840
that sickle now

00:03:33,760 --> 00:03:37,120
acting as a independent working group

00:03:35,840 --> 00:03:39,360
and further super

00:03:37,120 --> 00:03:40,959
tight alignment with iso c plus plus

00:03:39,360 --> 00:03:42,720
contributing in both directions

00:03:40,959 --> 00:03:44,319
taking stuff from micelle superplus and

00:03:42,720 --> 00:03:46,000
contributing our knowledge

00:03:44,319 --> 00:03:47,360
um of heterogeneous programming along

00:03:46,000 --> 00:03:50,480
with other many other people

00:03:47,360 --> 00:03:51,920
into iso c plus plus so

00:03:50,480 --> 00:03:53,840
a little bit about what is sickle is

00:03:51,920 --> 00:03:57,200
chronos kronos is

00:03:53,840 --> 00:03:59,519
a related um consortium of standards

00:03:57,200 --> 00:04:01,040
and they have many of them um i would

00:03:59,519 --> 00:04:01,360
just point out that sickle is a part of

00:04:01,040 --> 00:04:04,480
the

00:04:01,360 --> 00:04:07,280
chronos portfolio of open specifications

00:04:04,480 --> 00:04:07,840
and belongs in the parallel computation

00:04:07,280 --> 00:04:10,159
group

00:04:07,840 --> 00:04:11,360
along with blen along with things like

00:04:10,159 --> 00:04:14,560
sphere sphere

00:04:11,360 --> 00:04:16,079
opencl and nef openvx

00:04:14,560 --> 00:04:17,759
but as such we're also involved with

00:04:16,079 --> 00:04:20,479
things like vision inferencing and

00:04:17,759 --> 00:04:20,479
machine learning

00:04:21,919 --> 00:04:26,960
it is a single source c plus uh

00:04:24,960 --> 00:04:29,440
parallel programming language framework

00:04:26,960 --> 00:04:31,759
that takes a standard iso c plus plus

00:04:29,440 --> 00:04:34,320
application code even tensorflow and

00:04:31,759 --> 00:04:35,040
then compiles them with a host cpu

00:04:34,320 --> 00:04:37,120
compiler

00:04:35,040 --> 00:04:38,720
and a device sickle compiler which

00:04:37,120 --> 00:04:41,120
generates code for many

00:04:38,720 --> 00:04:42,800
kinds of devices the reason i want to

00:04:41,120 --> 00:04:44,320
point out that this is single sources

00:04:42,800 --> 00:04:44,720
because there has been many attempts at

00:04:44,320 --> 00:04:47,120
this

00:04:44,720 --> 00:04:48,800
and some are not single source they

00:04:47,120 --> 00:04:51,680
require separate source

00:04:48,800 --> 00:04:53,600
um some doesn't use isn't capable of

00:04:51,680 --> 00:04:55,600
marrying with modern c plus plus all the

00:04:53,600 --> 00:04:58,560
way up to templates or even up to c

00:04:55,600 --> 00:04:59,280
by 17 20. sickles because of its tight

00:04:58,560 --> 00:05:02,320
alignment

00:04:59,280 --> 00:05:03,600
keeps up with all of those things um all

00:05:02,320 --> 00:05:05,360
the steps of ratification

00:05:03,600 --> 00:05:07,039
c plus plus as well as staying with

00:05:05,360 --> 00:05:08,960
single source which we believe

00:05:07,039 --> 00:05:11,120
has now more or less definitively been

00:05:08,960 --> 00:05:14,560
proven as the best programming model

00:05:11,120 --> 00:05:14,560
for heterogeneous computing

00:05:14,800 --> 00:05:22,400
so the story so far so in 2018

00:05:18,800 --> 00:05:24,400
at iwako in oxford i showed this slide

00:05:22,400 --> 00:05:26,880
setting the stage for sickle pass when

00:05:24,400 --> 00:05:29,600
we had sickle 1.2 in 2015

00:05:26,880 --> 00:05:30,560
and sickle one two one in 2017 and their

00:05:29,600 --> 00:05:33,280
alignment with c

00:05:30,560 --> 00:05:34,160
plus 11. the following year compute cpp

00:05:33,280 --> 00:05:37,120
became the first

00:05:34,160 --> 00:05:38,400
conformant implementations the early

00:05:37,120 --> 00:05:40,560
implementations the computer will

00:05:38,400 --> 00:05:42,080
compute cpp and tricycle which allow

00:05:40,560 --> 00:05:43,440
people to try it out and after a couple

00:05:42,080 --> 00:05:45,360
of years of feedback

00:05:43,440 --> 00:05:47,039
that's when we came out with sql one two

00:05:45,360 --> 00:05:50,320
one the following year

00:05:47,039 --> 00:05:51,520
um compute cpp became the first passing

00:05:50,320 --> 00:05:53,440
the conformance test

00:05:51,520 --> 00:05:56,400
and over the next two years became

00:05:53,440 --> 00:05:58,000
hipsicle and an intel's dpc plus plus

00:05:56,400 --> 00:05:59,759
and there were various extensions that's

00:05:58,000 --> 00:06:02,080
been proposed since then

00:05:59,759 --> 00:06:02,880
we've open source the sickle 121

00:06:02,080 --> 00:06:06,080
conformance

00:06:02,880 --> 00:06:07,680
in may 2019 and dpc plus recently has

00:06:06,080 --> 00:06:09,199
been extended to support cuda we're

00:06:07,680 --> 00:06:12,080
going to talk a lot more about that

00:06:09,199 --> 00:06:12,080
in the rest of this talk

00:06:13,199 --> 00:06:19,039
okay starting on the second step which

00:06:16,160 --> 00:06:19,039
is sickle present

00:06:19,360 --> 00:06:23,360
so today i'm really happy to unveil this

00:06:22,800 --> 00:06:26,000
slide

00:06:23,360 --> 00:06:26,720
about the possible future roadmap of

00:06:26,000 --> 00:06:29,280
sickle

00:06:26,720 --> 00:06:30,319
where in 2020 we plan to release first a

00:06:29,280 --> 00:06:33,919
provisional

00:06:30,319 --> 00:06:34,560
uh in first provincial which already has

00:06:33,919 --> 00:06:36,880
been done

00:06:34,560 --> 00:06:39,440
for public review and feedback leading

00:06:36,880 --> 00:06:40,960
to a final potentially in q4

00:06:39,440 --> 00:06:43,039
we planned this version to be based on

00:06:40,960 --> 00:06:44,880
c-plus plus 17 on the right you can see

00:06:43,039 --> 00:06:46,639
this means it enables exciting c-plus

00:06:44,880 --> 00:06:48,319
plus features like ctad

00:06:46,639 --> 00:06:50,639
class template argument deduction and

00:06:48,319 --> 00:06:52,720
deduction guys that makes the code

00:06:50,639 --> 00:06:53,919
less verbose there are also a number of

00:06:52,720 --> 00:06:55,759
other great features

00:06:53,919 --> 00:06:58,400
which i will highlight you're going to

00:06:55,759 --> 00:07:01,440
see that we released sickle 1.2.1 in

00:06:58,400 --> 00:07:03,599
2017 and previously 1.2 in 2015

00:07:01,440 --> 00:07:05,199
and if you were to predict that we seem

00:07:03,599 --> 00:07:07,199
to be settling down to a cadence of

00:07:05,199 --> 00:07:07,599
releasing new releases every one and a

00:07:07,199 --> 00:07:09,759
half

00:07:07,599 --> 00:07:11,599
three years matching to the iso c plus

00:07:09,759 --> 00:07:13,199
plus schedule you will be correct

00:07:11,599 --> 00:07:15,039
this is because we have adopted a

00:07:13,199 --> 00:07:17,039
basically the same bus train model

00:07:15,039 --> 00:07:18,479
delivery you will also see that we have

00:07:17,039 --> 00:07:20,560
changed the naming scheme

00:07:18,479 --> 00:07:22,000
from what it used to be aligned with

00:07:20,560 --> 00:07:24,639
opencl versioning

00:07:22,000 --> 00:07:25,199
to naming by year just like iso c plus

00:07:24,639 --> 00:07:27,199
plus

00:07:25,199 --> 00:07:28,639
and this allows us to be now based on

00:07:27,199 --> 00:07:30,560
multiple backends

00:07:28,639 --> 00:07:32,319
in addition to opencl which still

00:07:30,560 --> 00:07:32,800
remains our primary back-end but now you

00:07:32,319 --> 00:07:35,199
can have

00:07:32,800 --> 00:07:36,400
different back-ends like like openmp

00:07:35,199 --> 00:07:39,919
cuda

00:07:36,400 --> 00:07:41,199
vulcan cocos raja you will also see that

00:07:39,919 --> 00:07:44,560
we're projecting in

00:07:41,199 --> 00:07:46,479
tentatively that a future sickle is

00:07:44,560 --> 00:07:48,240
going to be released after 2021

00:07:46,479 --> 00:07:49,759
expect exactly the exact version

00:07:48,240 --> 00:07:52,160
obviously to be named later

00:07:49,759 --> 00:07:54,080
and will likely be based on c plus plus

00:07:52,160 --> 00:07:54,639
20 which will be released at the end of

00:07:54,080 --> 00:07:56,639
this year

00:07:54,639 --> 00:07:58,639
now it's been pretty much confirmed so

00:07:56,639 --> 00:07:59,599
this shows essentially our tightest iso

00:07:58,639 --> 00:08:02,479
c plus plus

00:07:59,599 --> 00:08:04,080
alignment injecting our heterogeneous

00:08:02,479 --> 00:08:08,240
knowledge into iso

00:08:04,080 --> 00:08:08,240
and adapting sequence plus features

00:08:09,680 --> 00:08:13,919
next slide so i want to show what a

00:08:12,319 --> 00:08:16,000
pleasure it has been to see sickle

00:08:13,919 --> 00:08:18,720
growth since 2016.

00:08:16,000 --> 00:08:19,440
by my count starting from when i first

00:08:18,720 --> 00:08:21,759
attempted

00:08:19,440 --> 00:08:23,199
when i first attended in frankfurt uh

00:08:21,759 --> 00:08:24,800
they faced

00:08:23,199 --> 00:08:26,479
the face-to-face being to the last

00:08:24,800 --> 00:08:28,879
face-to-face meeting barcelona

00:08:26,479 --> 00:08:29,520
before it got all shut down we doubled

00:08:28,879 --> 00:08:32,080
in size

00:08:29,520 --> 00:08:33,599
uh by two times from averaging 15 people

00:08:32,080 --> 00:08:35,440
over to over 30 people

00:08:33,599 --> 00:08:37,680
in the last meeting we continue to have

00:08:35,440 --> 00:08:41,519
strong attendance from intel

00:08:37,680 --> 00:08:43,599
xilinx codeplay amd arm qualcomm a

00:08:41,519 --> 00:08:45,920
l argon national lab university of

00:08:43,599 --> 00:08:48,160
salerno university of bristol

00:08:45,920 --> 00:08:49,920
externally we've been active in cppcon

00:08:48,160 --> 00:08:53,279
giving sickle talks and tutorials in

00:08:49,920 --> 00:08:54,959
2016 17 18 and 19. thank you to the cp

00:08:53,279 --> 00:08:56,800
beacon programming committee for

00:08:54,959 --> 00:08:57,440
allowing us to do that we have also had

00:08:56,800 --> 00:09:00,080
boss in

00:08:57,440 --> 00:09:01,920
super computing 17 18 19. in the last

00:09:00,080 --> 00:09:04,720
year we actually had two separate vaults

00:09:01,920 --> 00:09:07,040
one that is a standalone sickle ball

00:09:04,720 --> 00:09:08,160
and another along with another one on

00:09:07,040 --> 00:09:10,080
showing how heterogeneous

00:09:08,160 --> 00:09:11,440
iso c plus plus can benefit high

00:09:10,080 --> 00:09:13,200
performance computing

00:09:11,440 --> 00:09:15,200
at super computing 19 the number of

00:09:13,200 --> 00:09:16,160
exico events exploded from two to three

00:09:15,200 --> 00:09:18,320
sickle events

00:09:16,160 --> 00:09:19,279
in 2018 to six to eight sickle events

00:09:18,320 --> 00:09:22,080
that's related

00:09:19,279 --> 00:09:23,120
in the forms of papers talks boss

00:09:22,080 --> 00:09:25,600
keynotes

00:09:23,120 --> 00:09:27,040
at various workshops so as you know in

00:09:25,600 --> 00:09:30,080
the past sickle held an

00:09:27,040 --> 00:09:32,320
annual workshop called dhpcc

00:09:30,080 --> 00:09:34,080
plus i know it's a mouthful never said

00:09:32,320 --> 00:09:37,360
that we were great at acronym

00:09:34,080 --> 00:09:38,959
naming remember our aii so that was in

00:09:37,360 --> 00:09:41,440
that was a workshop in iwako

00:09:38,959 --> 00:09:43,200
as it was not yet its own working group

00:09:41,440 --> 00:09:44,880
yet so on september 22nd

00:09:43,200 --> 00:09:46,480
2019 i'm going to declare that as

00:09:44,880 --> 00:09:47,839
independence day for sicko

00:09:46,480 --> 00:09:49,839
because that's when it became its own

00:09:47,839 --> 00:09:51,920
working group within kronos and now is

00:09:49,839 --> 00:09:52,800
held as an integrated conference with

00:09:51,920 --> 00:09:55,040
iwako

00:09:52,800 --> 00:09:56,480
called sikocon i really wish it was

00:09:55,040 --> 00:09:59,200
called cyclone but hey what the hell i

00:09:56,480 --> 00:09:59,200
can't get everything

00:09:59,600 --> 00:10:04,480
okay so i show here uh how the commits

00:10:02,880 --> 00:10:06,399
have spiked and grown

00:10:04,480 --> 00:10:08,399
in our normal gitlab you can see from

00:10:06,399 --> 00:10:09,920
the spikes when we're about to release

00:10:08,399 --> 00:10:11,920
and the massive recent spikes and

00:10:09,920 --> 00:10:13,279
activity as we prepare for releasing sql

00:10:11,920 --> 00:10:14,959
2020.

00:10:13,279 --> 00:10:17,040
thank you renault for building up these

00:10:14,959 --> 00:10:19,600
slides for us

00:10:17,040 --> 00:10:22,000
so now we want to switch to looking at

00:10:19,600 --> 00:10:22,399
what might be in sql 2020 which you can

00:10:22,000 --> 00:10:24,959
see

00:10:22,399 --> 00:10:25,920
is still under construction so a lot of

00:10:24,959 --> 00:10:29,440
these contents

00:10:25,920 --> 00:10:33,040
is caveat m2 they could still change

00:10:29,440 --> 00:10:34,640
okay now the question here is how do you

00:10:33,040 --> 00:10:36,959
want how do you get involved

00:10:34,640 --> 00:10:38,000
even if you're not a chronos member as

00:10:36,959 --> 00:10:41,680
you can see

00:10:38,000 --> 00:10:43,839
um we are now got permission with kronos

00:10:41,680 --> 00:10:44,880
to move toward a much more open model

00:10:43,839 --> 00:10:46,720
with sickle because

00:10:44,880 --> 00:10:48,399
it's not really a language that is tied

00:10:46,720 --> 00:10:49,920
to any hardware so there's no real

00:10:48,399 --> 00:10:51,920
secret hardware things that we have to

00:10:49,920 --> 00:10:54,160
keep that secret it's really a software

00:10:51,920 --> 00:10:56,480
specification just like class plus it is

00:10:54,160 --> 00:10:58,160
so now we can take public contributions

00:10:56,480 --> 00:10:59,760
or fixes or even features

00:10:58,160 --> 00:11:01,920
as well as suggestions for for new

00:10:59,760 --> 00:11:03,600
features you can even now see many

00:11:01,920 --> 00:11:05,120
companies features on their sickle

00:11:03,600 --> 00:11:06,800
feature git repo

00:11:05,120 --> 00:11:08,480
um these are the ones that have been

00:11:06,800 --> 00:11:10,399
agreed by the sql working group to be

00:11:08,480 --> 00:11:14,320
made public early so you can contribute

00:11:10,399 --> 00:11:15,040
um into it you can be a an advisory

00:11:14,320 --> 00:11:16,240
group member

00:11:15,040 --> 00:11:17,839
so that you don't have to be part of

00:11:16,240 --> 00:11:19,680
sickle you don't have to pay and you can

00:11:17,839 --> 00:11:21,600
advise you can get early looks at our

00:11:19,680 --> 00:11:23,760
look at our specification so this

00:11:21,600 --> 00:11:26,079
enables essentially a more rapid

00:11:23,760 --> 00:11:27,680
feedback cycle so the way it works is

00:11:26,079 --> 00:11:28,640
really simple the github hosts the

00:11:27,680 --> 00:11:31,279
latest public

00:11:28,640 --> 00:11:32,079
ratification that's the public github

00:11:31,279 --> 00:11:34,399
and it allows

00:11:32,079 --> 00:11:35,279
open access and contributions of merge

00:11:34,399 --> 00:11:37,519
requests to fix

00:11:35,279 --> 00:11:39,600
existing features on the github the

00:11:37,519 --> 00:11:41,440
chronos gitlab is the private one

00:11:39,600 --> 00:11:43,760
and it holds the next version of sicko

00:11:41,440 --> 00:11:45,600
that's available to the working group

00:11:43,760 --> 00:11:47,120
some physical features are deemed open

00:11:45,600 --> 00:11:49,360
by the working group and is hosted on

00:11:47,120 --> 00:11:50,240
company git repo

00:11:49,360 --> 00:11:52,560
you're going to see the links for

00:11:50,240 --> 00:11:53,360
coldplay intel xilinx hipsicle later on

00:11:52,560 --> 00:11:55,519
at the bottom of

00:11:53,360 --> 00:11:57,440
the end of the slide talks other sticker

00:11:55,519 --> 00:11:58,959
features are developed under kronos ip

00:11:57,440 --> 00:12:00,880
within the private gitlab

00:11:58,959 --> 00:12:02,000
and both groups progress from extension

00:12:00,880 --> 00:12:03,839
to core

00:12:02,000 --> 00:12:06,000
and after ratification they move the

00:12:03,839 --> 00:12:07,200
gitlab ratifies back to the github the

00:12:06,000 --> 00:12:10,320
public one

00:12:07,200 --> 00:12:12,320
and then we do conformance tests um

00:12:10,320 --> 00:12:15,760
and tests for conformant implementations

00:12:12,320 --> 00:12:15,760
and then we just keep iterating

00:12:16,959 --> 00:12:22,480
so this is the main slide if you

00:12:20,399 --> 00:12:24,240
if you don't if you forget anything try

00:12:22,480 --> 00:12:26,000
to think about this one slide

00:12:24,240 --> 00:12:28,720
where it shows that what might be in

00:12:26,000 --> 00:12:31,040
sickle 2020 and in the top right box

00:12:28,720 --> 00:12:32,800
our general largest philosophy that we

00:12:31,040 --> 00:12:33,839
have followed in our change from sickle

00:12:32,800 --> 00:12:36,000
one to one

00:12:33,839 --> 00:12:38,000
uh and sickle 2020 we want easy

00:12:36,000 --> 00:12:39,680
integration with c plus plus 17

00:12:38,000 --> 00:12:41,519
less verbose length a less verbose

00:12:39,680 --> 00:12:44,480
language that has smaller code

00:12:41,519 --> 00:12:47,120
and simplify common um patterns we want

00:12:44,480 --> 00:12:49,600
to enable multiple backends but simplify

00:12:47,120 --> 00:12:50,880
interoperability while at the same time

00:12:49,600 --> 00:12:53,360
easing porting of c

00:12:50,880 --> 00:12:54,480
plus application to single improving

00:12:53,360 --> 00:12:55,920
programmability

00:12:54,480 --> 00:12:57,920
we want to strike a balance for

00:12:55,920 --> 00:12:59,279
performance and stability by enabling

00:12:57,920 --> 00:13:01,120
backwards compatibility

00:12:59,279 --> 00:13:03,040
with previous release but also

00:13:01,120 --> 00:13:04,160
selectively breaking api to achieve

00:13:03,040 --> 00:13:05,920
higher performance

00:13:04,160 --> 00:13:07,440
we expect that breakage to be minor from

00:13:05,920 --> 00:13:10,959
sql 121 to

00:13:07,440 --> 00:13:13,120
um 2020. on the top left uh you will see

00:13:10,959 --> 00:13:15,200
some of the features we already have

00:13:13,120 --> 00:13:16,240
which we'll take talk which we're going

00:13:15,200 --> 00:13:18,639
to have talks

00:13:16,240 --> 00:13:20,079
um about in this the rest of this talk i

00:13:18,639 --> 00:13:21,120
draw your attention to what's called

00:13:20,079 --> 00:13:22,959
generalization

00:13:21,120 --> 00:13:24,240
program modules host task

00:13:22,959 --> 00:13:26,959
interoperations

00:13:24,240 --> 00:13:28,079
uh interoperability unify shared memory

00:13:26,959 --> 00:13:30,480
and in order cues

00:13:28,079 --> 00:13:31,760
and call out nvidia support and a lot of

00:13:30,480 --> 00:13:34,480
this coordinate is going to go into

00:13:31,760 --> 00:13:36,079
detail about in the bottom right you're

00:13:34,480 --> 00:13:37,200
going to see there are many features in

00:13:36,079 --> 00:13:40,079
the pipeline

00:13:37,200 --> 00:13:40,800
that and and on the far right you're

00:13:40,079 --> 00:13:42,959
going to see that

00:13:40,800 --> 00:13:44,480
our main goal is converging sickle and

00:13:42,959 --> 00:13:47,920
iso while continuing

00:13:44,480 --> 00:13:49,920
doing to strongly support opencl um

00:13:47,920 --> 00:13:51,839
and driving and then driving to support

00:13:49,920 --> 00:13:54,399
even more kinds of chips

00:13:51,839 --> 00:13:57,760
including other kinds of accelerators

00:13:54,399 --> 00:13:59,680
machine learning and ai processors

00:13:57,760 --> 00:14:02,320
the main diagram illustrates our

00:13:59,680 --> 00:14:06,000
philosophy moving from sickle 121 to

00:14:02,320 --> 00:14:08,320
cycle 2020 and iterating this cycle

00:14:06,000 --> 00:14:09,440
with new releases every one and a half

00:14:08,320 --> 00:14:11,040
to three years

00:14:09,440 --> 00:14:13,680
from previous from the previous to the

00:14:11,040 --> 00:14:13,680
next release

00:14:15,279 --> 00:14:19,680
so at this point i want to hand over to

00:14:18,079 --> 00:14:20,320
my colleague odin brown who's going to

00:14:19,680 --> 00:14:22,160
go into

00:14:20,320 --> 00:14:26,160
amazing details about some of the sickle

00:14:22,160 --> 00:14:26,160
2020 that you can benefit from thank you

00:14:27,839 --> 00:14:30,880
okay thanks very much michael hi

00:14:30,240 --> 00:14:32,720
everyone

00:14:30,880 --> 00:14:34,320
thank you very much for uh for watching

00:14:32,720 --> 00:14:36,240
this talk um

00:14:34,320 --> 00:14:37,600
so now in this part i'm going to take

00:14:36,240 --> 00:14:40,480
over and

00:14:37,600 --> 00:14:41,199
go into a bit more of a deep dive into

00:14:40,480 --> 00:14:44,720
some of the

00:14:41,199 --> 00:14:47,920
uh the features that are are planned for

00:14:44,720 --> 00:14:50,720
sql 2020 uh so here

00:14:47,920 --> 00:14:52,000
i have a kind of overview of some of the

00:14:50,720 --> 00:14:54,639
the major features

00:14:52,000 --> 00:14:55,839
as like what michael just mentioned

00:14:54,639 --> 00:14:58,240
generalization

00:14:55,839 --> 00:14:59,760
unified shared memory and there's a lot

00:14:58,240 --> 00:15:00,800
of things like subgroups group

00:14:59,760 --> 00:15:03,040
algorithms

00:15:00,800 --> 00:15:04,320
a lot of simplifications there's a

00:15:03,040 --> 00:15:07,120
feature called modules

00:15:04,320 --> 00:15:08,959
uh it's not to be confused with c plus

00:15:07,120 --> 00:15:09,519
plus 20 modules this is a different

00:15:08,959 --> 00:15:12,880
feature

00:15:09,519 --> 00:15:14,639
or the confusing name um

00:15:12,880 --> 00:15:16,800
one thing to note though that this this

00:15:14,639 --> 00:15:18,720
is as michael said this is a provisional

00:15:16,800 --> 00:15:19,600
specification so it's still subject to

00:15:18,720 --> 00:15:21,600
change

00:15:19,600 --> 00:15:23,760
um although the the reason that we

00:15:21,600 --> 00:15:24,480
release a provisional spec is that the

00:15:23,760 --> 00:15:28,000
working group

00:15:24,480 --> 00:15:29,199
are pretty confident of the the features

00:15:28,000 --> 00:15:30,800
that we're proposing

00:15:29,199 --> 00:15:34,160
and we're looking for kind of feedback

00:15:30,800 --> 00:15:36,560
from implementations and from from users

00:15:34,160 --> 00:15:38,320
and so it's a very strong indication of

00:15:36,560 --> 00:15:41,360
what sql 2020 will look like but it

00:15:38,320 --> 00:15:44,720
is still subject to change

00:15:41,360 --> 00:15:46,160
um unfortunately i don't have time to

00:15:44,720 --> 00:15:48,240
cover all of the features

00:15:46,160 --> 00:15:49,440
i'd like to but i'm going to focus on on

00:15:48,240 --> 00:15:51,600
these five so

00:15:49,440 --> 00:15:52,480
back in generalization a unified shared

00:15:51,600 --> 00:15:55,279
memory

00:15:52,480 --> 00:15:58,079
in order queues host tasks and some api

00:15:55,279 --> 00:15:58,079
simplifications

00:15:58,480 --> 00:16:01,920
uh so starting off with the back end

00:16:00,720 --> 00:16:04,800
generalization

00:16:01,920 --> 00:16:07,279
um so michael went this a little bit

00:16:04,800 --> 00:16:07,279
earlier

00:16:07,360 --> 00:16:12,079
when siko was first uh released it

00:16:10,560 --> 00:16:14,800
uh sickle one put two in the second

00:16:12,079 --> 00:16:16,160
1.2.1 and it was entirely based on

00:16:14,800 --> 00:16:17,680
opencl 1.2

00:16:16,160 --> 00:16:19,519
and this because it was originally

00:16:17,680 --> 00:16:20,240
designed as a high level programming

00:16:19,519 --> 00:16:22,959
model for

00:16:20,240 --> 00:16:24,000
opencl specifically and so it can only

00:16:22,959 --> 00:16:27,199
officially target

00:16:24,000 --> 00:16:29,040
opencl devices there are there are

00:16:27,199 --> 00:16:30,720
implementations or work and progress

00:16:29,040 --> 00:16:31,759
implementations that do support other

00:16:30,720 --> 00:16:35,360
backends

00:16:31,759 --> 00:16:38,000
um and we'll see some of those later um

00:16:35,360 --> 00:16:40,240
but as uh officially as a kind of like

00:16:38,000 --> 00:16:42,880
ratified um

00:16:40,240 --> 00:16:45,440
conform implementations uh you can only

00:16:42,880 --> 00:16:47,839
support opencl devices

00:16:45,440 --> 00:16:48,800
um so one of the things we wanted to do

00:16:47,839 --> 00:16:50,160
once we

00:16:48,800 --> 00:16:52,000
we saw that there was there was

00:16:50,160 --> 00:16:52,399
opportunity for for sickle to support

00:16:52,000 --> 00:16:55,519
other

00:16:52,399 --> 00:16:58,160
programming models as well um we

00:16:55,519 --> 00:16:59,759
we wanted to move the cool in in 2020 to

00:16:58,160 --> 00:17:01,199
move it to more generalized saturation

00:16:59,759 --> 00:17:03,759
programming model

00:17:01,199 --> 00:17:05,919
um so what this means is single 2020 can

00:17:03,759 --> 00:17:09,120
support devices from

00:17:05,919 --> 00:17:10,880
any backend including opencl um the

00:17:09,120 --> 00:17:13,439
execution model and memory model

00:17:10,880 --> 00:17:14,319
remain the same um obviously with

00:17:13,439 --> 00:17:17,760
improvements

00:17:14,319 --> 00:17:18,640
uh from 2020. um and the api is largely

00:17:17,760 --> 00:17:21,039
unaffected

00:17:18,640 --> 00:17:23,839
um not including additional features

00:17:21,039 --> 00:17:27,679
introduced in 2020.

00:17:23,839 --> 00:17:29,919
um and so what what what is a backend

00:17:27,679 --> 00:17:30,880
in in the context of cycle now so i

00:17:29,919 --> 00:17:33,600
reckon is

00:17:30,880 --> 00:17:35,360
essentially any c plus plus uh

00:17:33,600 --> 00:17:36,559
programming model a simple source-based

00:17:35,360 --> 00:17:39,919
programming model

00:17:36,559 --> 00:17:43,039
um so this could be um sort of separate

00:17:39,919 --> 00:17:45,200
compilation models like opencl or cuda

00:17:43,039 --> 00:17:46,080
um it could be like pragma based model

00:17:45,200 --> 00:17:47,600
like openmp

00:17:46,080 --> 00:17:49,520
or it could be something even something

00:17:47,600 --> 00:17:50,559
like vulcan or a library solution like

00:17:49,520 --> 00:17:51,919
tbb

00:17:50,559 --> 00:17:54,000
essentially a back end can be

00:17:51,919 --> 00:17:56,960
implemented on top of any ac plus plus

00:17:54,000 --> 00:17:56,960
based programming model

00:17:57,039 --> 00:18:00,400
um so this this slide may be familiar to

00:17:59,679 --> 00:18:02,799
people who've seen

00:18:00,400 --> 00:18:03,440
cycle talks before um this is the kind

00:18:02,799 --> 00:18:06,640
of

00:18:03,440 --> 00:18:08,960
high level uh cycle ecosystem

00:18:06,640 --> 00:18:10,480
so you have cycle applications and

00:18:08,960 --> 00:18:12,799
they're they're

00:18:10,480 --> 00:18:14,320
written against this sickle api so it's

00:18:12,799 --> 00:18:15,919
template library

00:18:14,320 --> 00:18:17,360
and then underneath that you have a

00:18:15,919 --> 00:18:21,440
cycle runtime which can

00:18:17,360 --> 00:18:24,160
target different devices and in the past

00:18:21,440 --> 00:18:26,080
um you would have a host host device and

00:18:24,160 --> 00:18:28,720
then other opencl devices

00:18:26,080 --> 00:18:29,919
and however in sql 2020 you can now have

00:18:28,720 --> 00:18:32,160
other back-ends

00:18:29,919 --> 00:18:33,120
uh so you still have the host back-end

00:18:32,160 --> 00:18:34,799
um

00:18:33,120 --> 00:18:37,200
but now there's there's potential for

00:18:34,799 --> 00:18:38,480
other back-ends such as vulcan or cuda

00:18:37,200 --> 00:18:40,799
or anything like that

00:18:38,480 --> 00:18:42,400
now this this diagram here is is just

00:18:40,799 --> 00:18:44,160
indicative it's not representative

00:18:42,400 --> 00:18:45,600
of any specific implementations it's

00:18:44,160 --> 00:18:49,280
just going to give you an idea of

00:18:45,600 --> 00:18:50,160
the possibilities a couple of things to

00:18:49,280 --> 00:18:52,640
focus on

00:18:50,160 --> 00:18:53,320
um every single implementation just as

00:18:52,640 --> 00:18:56,400
with

00:18:53,320 --> 00:18:59,280
1.2.1 it must have a host device and it

00:18:56,400 --> 00:19:01,120
must have a host back end in this case

00:18:59,280 --> 00:19:02,720
so this is the host device is

00:19:01,120 --> 00:19:05,200
essentially an emulated

00:19:02,720 --> 00:19:05,919
uh sickle device that follows the same

00:19:05,200 --> 00:19:08,160
execution

00:19:05,919 --> 00:19:09,120
memory model guarantees as any other

00:19:08,160 --> 00:19:13,120
device but

00:19:09,120 --> 00:19:16,640
it runs in on the on the host cpu

00:19:13,120 --> 00:19:16,640
and can be useful for debugging

00:19:17,280 --> 00:19:22,320
next we have uh every single

00:19:20,799 --> 00:19:22,960
implementation must also have at least

00:19:22,320 --> 00:19:25,200
one

00:19:22,960 --> 00:19:26,799
non-host back end so it could be opencl

00:19:25,200 --> 00:19:27,120
or it could be could or could could be

00:19:26,799 --> 00:19:29,840
any

00:19:27,120 --> 00:19:29,840
in the other back end

00:19:30,960 --> 00:19:34,480
uh just to see how that looks like in

00:19:33,200 --> 00:19:37,200
the kind of topology

00:19:34,480 --> 00:19:38,720
um of of devices that are available when

00:19:37,200 --> 00:19:41,520
you run a single application

00:19:38,720 --> 00:19:42,000
um originally in circle 1.2.1 you would

00:19:41,520 --> 00:19:44,000
have

00:19:42,000 --> 00:19:45,360
platforms and devices you know devices

00:19:44,000 --> 00:19:46,400
are the physical devices you're

00:19:45,360 --> 00:19:48,720
targeting

00:19:46,400 --> 00:19:50,480
platforms for essentially the vendors

00:19:48,720 --> 00:19:53,039
but now we have this additional layer

00:19:50,480 --> 00:19:54,240
um for the back end and you can have

00:19:53,039 --> 00:19:56,960
different platforms and devices from

00:19:54,240 --> 00:19:56,960
different back-ends

00:19:58,720 --> 00:20:03,120
one thing to note here is the the host

00:20:00,480 --> 00:20:05,440
device is associated with the host

00:20:03,120 --> 00:20:06,880
platform as you as it was in one to one

00:20:05,440 --> 00:20:08,880
but it's now associated with the host

00:20:06,880 --> 00:20:12,159
back end

00:20:08,880 --> 00:20:13,039
in 2020. um another important thing to

00:20:12,159 --> 00:20:15,120
note is that

00:20:13,039 --> 00:20:16,880
um because signal 2020 can target

00:20:15,120 --> 00:20:19,360
multiple back-ends

00:20:16,880 --> 00:20:20,000
um these different back-ends are

00:20:19,360 --> 00:20:22,240
generally

00:20:20,000 --> 00:20:26,159
completely independent api so for

00:20:22,240 --> 00:20:27,840
example here we have opencl and cuda

00:20:26,159 --> 00:20:30,080
so there's one thing to be aware of is

00:20:27,840 --> 00:20:31,840
that the same physical device could be

00:20:30,080 --> 00:20:34,400
represented by multiple back-ends

00:20:31,840 --> 00:20:36,799
so the same physical gpu could be

00:20:34,400 --> 00:20:40,000
reported by opencl and by cuda so

00:20:36,799 --> 00:20:41,280
um often you may want to just target one

00:20:40,000 --> 00:20:42,320
back-end but if you were to target

00:20:41,280 --> 00:20:45,360
multiple back-ends

00:20:42,320 --> 00:20:49,840
um you you have to be careful of of this

00:20:45,360 --> 00:20:49,840
to avoid contention over the resources

00:20:50,480 --> 00:20:53,600
so with this in mind taking a look at

00:20:52,880 --> 00:20:58,000
the

00:20:53,600 --> 00:20:59,600
um kind of different ways that you can

00:20:58,000 --> 00:21:02,559
write sickle code

00:20:59,600 --> 00:21:03,919
um so there's we kind of defined this as

00:21:02,559 --> 00:21:04,400
three different categories you know

00:21:03,919 --> 00:21:06,480
there's

00:21:04,400 --> 00:21:07,860
generic cycle interoperable sickle and

00:21:06,480 --> 00:21:09,120
then vendor specific cycle

00:21:07,860 --> 00:21:11,200
[Music]

00:21:09,120 --> 00:21:12,640
uh so first of all generic cycle is

00:21:11,200 --> 00:21:13,280
essentially an application written

00:21:12,640 --> 00:21:16,559
against

00:21:13,280 --> 00:21:18,080
the core signal specification and any

00:21:16,559 --> 00:21:20,159
application red against course

00:21:18,080 --> 00:21:21,760
sickle spec is portable across any

00:21:20,159 --> 00:21:24,240
implementation so it's a standard

00:21:21,760 --> 00:21:24,799
api it doesn't matter which which back

00:21:24,240 --> 00:21:26,640
end your

00:21:24,799 --> 00:21:29,120
the implementation supports the same

00:21:26,640 --> 00:21:30,320
code will run everywhere

00:21:29,120 --> 00:21:32,320
obviously that doesn't give you an

00:21:30,320 --> 00:21:34,159
entirely performance portability

00:21:32,320 --> 00:21:37,280
sort of api portability this there's

00:21:34,159 --> 00:21:39,919
still often you will still have to

00:21:37,280 --> 00:21:41,280
tweak applications for different devices

00:21:39,919 --> 00:21:44,320
or different back-ends

00:21:41,280 --> 00:21:47,919
to kind of achieve optimal performance

00:21:44,320 --> 00:21:51,200
next we have interoperable sickle so

00:21:47,919 --> 00:21:53,760
just as in 1.1 with opencl

00:21:51,200 --> 00:21:55,760
signal 2020 has a interoperability api

00:21:53,760 --> 00:21:59,200
which allows you to

00:21:55,760 --> 00:21:59,760
hook into the underlying native backend

00:21:59,200 --> 00:22:02,720
so be

00:21:59,760 --> 00:22:04,080
open cl or cuda or whatever the the api

00:22:02,720 --> 00:22:08,000
of your back end is

00:22:04,080 --> 00:22:11,520
um and do things specific to to that api

00:22:08,000 --> 00:22:13,679
and this is is less portable um so any

00:22:11,520 --> 00:22:15,520
any interoperable sickle code this will

00:22:13,679 --> 00:22:17,200
only be portable to implementations that

00:22:15,520 --> 00:22:18,400
support the same back end

00:22:17,200 --> 00:22:19,919
um and there will be many

00:22:18,400 --> 00:22:20,720
implementations that support the same

00:22:19,919 --> 00:22:22,640
back ends but

00:22:20,720 --> 00:22:26,000
some backends may only be supported by

00:22:22,640 --> 00:22:27,679
one or one implementation perhaps

00:22:26,000 --> 00:22:29,039
and then lastly we have vendor specific

00:22:27,679 --> 00:22:32,080
signals so this is the

00:22:29,039 --> 00:22:33,200
the least portable so in some cases you

00:22:32,080 --> 00:22:35,280
may want to use

00:22:33,200 --> 00:22:37,280
a feature that is specific to one vendor

00:22:35,280 --> 00:22:40,000
it could be an extension

00:22:37,280 --> 00:22:41,039
to support a particular hardware feature

00:22:40,000 --> 00:22:43,600
um

00:22:41,039 --> 00:22:45,280
many implementations of cycle provide

00:22:43,600 --> 00:22:47,679
their own extensions to provide

00:22:45,280 --> 00:22:49,280
functionality that's beyond what's in

00:22:47,679 --> 00:22:51,280
the core specification

00:22:49,280 --> 00:22:53,520
and often these features will find their

00:22:51,280 --> 00:22:56,000
way into the core specification

00:22:53,520 --> 00:22:58,480
after they've been kind of reviewed and

00:22:56,000 --> 00:23:00,960
and considered for the the spec

00:22:58,480 --> 00:23:02,960
um but if you use these features you can

00:23:00,960 --> 00:23:08,000
do that but then that limits you to

00:23:02,960 --> 00:23:10,320
to one specific implementation

00:23:08,000 --> 00:23:11,760
so to kind of give an overview of what

00:23:10,320 --> 00:23:13,760
implementations of sickle

00:23:11,760 --> 00:23:15,280
are available um there's there's four

00:23:13,760 --> 00:23:17,760
main implementations

00:23:15,280 --> 00:23:18,480
and codeplay has a commercial

00:23:17,760 --> 00:23:22,880
implementation

00:23:18,480 --> 00:23:26,000
called cpp and this is the first um

00:23:22,880 --> 00:23:28,159
conformant 1.2.1 implementation

00:23:26,000 --> 00:23:29,280
and there's also dpc plus which is an

00:23:28,159 --> 00:23:31,919
open source

00:23:29,280 --> 00:23:32,960
project led by intel and then it's

00:23:31,919 --> 00:23:34,559
another

00:23:32,960 --> 00:23:36,720
open source project called tricycle

00:23:34,559 --> 00:23:38,960
which was read led by xilinx

00:23:36,720 --> 00:23:40,080
and then there's a fourth called

00:23:38,960 --> 00:23:42,720
hipsicle which is

00:23:40,080 --> 00:23:43,919
led by a heidelberg university

00:23:42,720 --> 00:23:46,880
[Music]

00:23:43,919 --> 00:23:47,600
and the all these implementations vary

00:23:46,880 --> 00:23:49,840
in

00:23:47,600 --> 00:23:51,039
the back ends of the support across the

00:23:49,840 --> 00:23:54,640
different implementations

00:23:51,039 --> 00:23:58,400
there there is opencl cuda openmp

00:23:54,640 --> 00:24:00,000
rockum um and even some standard cpu

00:23:58,400 --> 00:24:03,200
libraries

00:24:00,000 --> 00:24:05,039
um and between these different

00:24:03,200 --> 00:24:06,480
implementations they also support a very

00:24:05,039 --> 00:24:10,000
wide range of

00:24:06,480 --> 00:24:10,880
of devices um so i believe across this

00:24:10,000 --> 00:24:14,000
we have

00:24:10,880 --> 00:24:17,600
uh you know intel amd arm cpus

00:24:14,000 --> 00:24:19,200
intel amd r mali power vr and nvidia

00:24:17,600 --> 00:24:22,080
gpus

00:24:19,200 --> 00:24:23,679
and also um through pcp there's support

00:24:22,080 --> 00:24:24,159
for the renaissance our car platform as

00:24:23,679 --> 00:24:27,520
well

00:24:24,159 --> 00:24:29,520
for automotive so depending on what your

00:24:27,520 --> 00:24:33,840
platform is you may want to

00:24:29,520 --> 00:24:33,840
choose one implementation or another um

00:24:35,440 --> 00:24:38,960
but one one feature that was that's been

00:24:37,679 --> 00:24:43,360
requested quite a lot

00:24:38,960 --> 00:24:46,400
um is support for nvidia gpus

00:24:43,360 --> 00:24:48,480
um and so codeplay um

00:24:46,400 --> 00:24:50,480
did some work uh over the last year to

00:24:48,480 --> 00:24:53,039
to introduce support for

00:24:50,480 --> 00:24:53,520
um nvidia gpus through a cuda back end

00:24:53,039 --> 00:24:56,480
in

00:24:53,520 --> 00:24:57,919
dpc plus plus so dpc plus plus is an

00:24:56,480 --> 00:25:00,400
open source implementation

00:24:57,919 --> 00:25:02,640
um so it's a standard sticker 1.1

00:25:00,400 --> 00:25:04,880
implementation but also has a number of

00:25:02,640 --> 00:25:06,799
extensions for optional features and

00:25:04,880 --> 00:25:09,840
many of these features have

00:25:06,799 --> 00:25:11,600
ended up in cycle 2020 spec

00:25:09,840 --> 00:25:12,960
and it also has a plug-in api for

00:25:11,600 --> 00:25:14,799
allowing you to add

00:25:12,960 --> 00:25:18,400
other back-ends and this is how we we

00:25:14,799 --> 00:25:18,400
introduced the the cuda back-end

00:25:19,039 --> 00:25:23,200
um so just to give a kind of idea of how

00:25:21,919 --> 00:25:25,039
to use this this is

00:25:23,200 --> 00:25:26,480
a open-source repo and there's there's

00:25:25,039 --> 00:25:28,799
regular stable and

00:25:26,480 --> 00:25:30,240
daily releases so you can download that

00:25:28,799 --> 00:25:33,279
and check out there's a getting started

00:25:30,240 --> 00:25:33,279
guide so you can try out

00:25:33,600 --> 00:25:36,880
um just to give an idea the way you use

00:25:36,320 --> 00:25:40,240
this

00:25:36,880 --> 00:25:42,320
is essentially you you call the sickle

00:25:40,240 --> 00:25:46,080
compiler as normal um

00:25:42,320 --> 00:25:46,960
but you would specify the nvidia cuda

00:25:46,080 --> 00:25:49,440
triple

00:25:46,960 --> 00:25:50,159
and then when you you run the code you

00:25:49,440 --> 00:25:53,840
specify

00:25:50,159 --> 00:25:57,039
an environment variable to set the the

00:25:53,840 --> 00:26:00,240
plugin api to target the cuda back-end

00:25:57,039 --> 00:26:03,520
and that's essentially it um

00:26:00,240 --> 00:26:07,039
the as i mentioned before because sickle

00:26:03,520 --> 00:26:09,760
is uh a portable api

00:26:07,039 --> 00:26:11,120
and the implementations are standard so

00:26:09,760 --> 00:26:12,159
code written against one single

00:26:11,120 --> 00:26:13,919
implementation will

00:26:12,159 --> 00:26:15,440
will work and any other implementation

00:26:13,919 --> 00:26:17,520
so to run on

00:26:15,440 --> 00:26:19,520
inverted gpus all you need to do is

00:26:17,520 --> 00:26:21,919
essentially change

00:26:19,520 --> 00:26:23,679
the device selector so that it picks a

00:26:21,919 --> 00:26:25,679
nvidia gpu

00:26:23,679 --> 00:26:28,159
and then and then that will run on the

00:26:25,679 --> 00:26:28,159
gpu

00:26:28,320 --> 00:26:32,559
and just to give a snapshot of the

00:26:30,240 --> 00:26:34,080
current performance of this this is a

00:26:32,559 --> 00:26:36,400
performance figures using the babel

00:26:34,080 --> 00:26:36,400
stream

00:26:36,840 --> 00:26:41,919
benchmark around the g4 gtx 980

00:26:39,840 --> 00:26:43,200
and as you can see the the performance

00:26:41,919 --> 00:26:44,400
of of

00:26:43,200 --> 00:26:46,480
sickle running on the cuda back end

00:26:44,400 --> 00:26:47,840
through dpc plus plus is is very

00:26:46,480 --> 00:26:52,960
comparable to

00:26:47,840 --> 00:26:55,200
native cuda

00:26:52,960 --> 00:26:55,200
yep

00:26:58,400 --> 00:27:03,039
okay the next feature i want to cover is

00:27:00,320 --> 00:27:05,039
some api simplifications

00:27:03,039 --> 00:27:06,559
so one of the big things about cycle

00:27:05,039 --> 00:27:09,760
2020 is it now supports

00:27:06,559 --> 00:27:11,679
sc 17 which has allowed us to you know

00:27:09,760 --> 00:27:15,120
introduce some new features

00:27:11,679 --> 00:27:17,600
um and simplifications to the api

00:27:15,120 --> 00:27:18,399
so this is a typical hello world

00:27:17,600 --> 00:27:21,840
application

00:27:18,399 --> 00:27:24,159
and cycle 1.1 um so

00:27:21,840 --> 00:27:24,880
we essentially we allocate some some

00:27:24,159 --> 00:27:28,240
vectors for

00:27:24,880 --> 00:27:32,000
input output data we create a queue

00:27:28,240 --> 00:27:33,600
to uh enqueue some work to and then

00:27:32,000 --> 00:27:35,360
we create these buffer objects which

00:27:33,600 --> 00:27:36,480
will manage the data to and from the

00:27:35,360 --> 00:27:39,840
device

00:27:36,480 --> 00:27:41,600
um and then we submit a command group

00:27:39,840 --> 00:27:42,880
uh inside that we create accessors to

00:27:41,600 --> 00:27:43,360
say you want to access that data on the

00:27:42,880 --> 00:27:45,679
device

00:27:43,360 --> 00:27:46,559
and then we call this parallel for to

00:27:45,679 --> 00:27:47,919
include the kernel so

00:27:46,559 --> 00:27:49,840
the lamb doesn't inside the parallel for

00:27:47,919 --> 00:27:51,440
there is the

00:27:49,840 --> 00:27:53,360
the actual function that runs on the

00:27:51,440 --> 00:27:54,960
device

00:27:53,360 --> 00:27:56,880
so to go through some of the

00:27:54,960 --> 00:28:00,159
simplifications and now that

00:27:56,880 --> 00:28:00,640
sql 2020 is a general programming model

00:28:00,159 --> 00:28:02,240
we've

00:28:00,640 --> 00:28:04,640
changed the header file to now be sickle

00:28:02,240 --> 00:28:08,320
rather than cl

00:28:04,640 --> 00:28:10,240
and the same goes for the namespace um

00:28:08,320 --> 00:28:12,399
another interesting change we made was

00:28:10,240 --> 00:28:15,840
that you now is no longer required

00:28:12,399 --> 00:28:16,559
to name kernel functions so in instagram

00:28:15,840 --> 00:28:18,320
to one

00:28:16,559 --> 00:28:19,600
you would have to use a typed name the

00:28:18,320 --> 00:28:21,520
lambda

00:28:19,600 --> 00:28:24,960
expression you use for your kernel name

00:28:21,520 --> 00:28:24,960
that's that's no longer necessary

00:28:25,120 --> 00:28:28,559
um next we added some global variables

00:28:28,000 --> 00:28:31,200
for the

00:28:28,559 --> 00:28:34,799
the device selectors um so you don't

00:28:31,200 --> 00:28:34,799
have to instantiate new ones every time

00:28:35,200 --> 00:28:38,240
and next one of the biggest

00:28:36,399 --> 00:28:40,480
simplifications we made was that

00:28:38,240 --> 00:28:42,559
we now introduce ctad and deduction

00:28:40,480 --> 00:28:45,679
guides so to remove a lot of the

00:28:42,559 --> 00:28:48,080
template parameters when uh when

00:28:45,679 --> 00:28:51,120
creating buffers and accessors and and

00:28:48,080 --> 00:28:51,120
ranges and that sort of thing

00:28:51,520 --> 00:28:55,679
and one one thing to note with that

00:28:53,200 --> 00:28:57,679
though is that um when you're

00:28:55,679 --> 00:28:58,799
with ctad it was necessary to introduce

00:28:57,679 --> 00:29:01,600
some tags for

00:28:58,799 --> 00:29:02,799
specifying specific parameters so in

00:29:01,600 --> 00:29:04,799
this case it's the

00:29:02,799 --> 00:29:06,559
access target so here we have read only

00:29:04,799 --> 00:29:07,440
and write only instead of the access

00:29:06,559 --> 00:29:09,039
target

00:29:07,440 --> 00:29:13,679
template parameter so it does the

00:29:09,039 --> 00:29:16,640
equivalent thing

00:29:13,679 --> 00:29:18,399
okay the next feature i want to cover is

00:29:16,640 --> 00:29:21,360
host tasks

00:29:18,399 --> 00:29:22,720
so instead of going to one um there's no

00:29:21,360 --> 00:29:24,960
way to

00:29:22,720 --> 00:29:27,039
call arbitrary c plus code from a task

00:29:24,960 --> 00:29:30,080
graph so when you enqueue

00:29:27,039 --> 00:29:30,960
a chain of work in in sickle and you'd

00:29:30,080 --> 00:29:32,960
have multiple

00:29:30,960 --> 00:29:35,279
functions running and connecting each

00:29:32,960 --> 00:29:37,919
other with dependencies

00:29:35,279 --> 00:29:40,080
but there's no way to inject um kind of

00:29:37,919 --> 00:29:42,720
arbitrary c plus plus code or a callback

00:29:40,080 --> 00:29:43,279
um without synchronizing back to the

00:29:42,720 --> 00:29:46,240
host

00:29:43,279 --> 00:29:49,679
um so tickle 2020 solves this by

00:29:46,240 --> 00:29:52,159
introducing the the host task api

00:29:49,679 --> 00:29:54,399
so stats is quite useful for for

00:29:52,159 --> 00:29:56,240
callbacks you can essentially have a

00:29:54,399 --> 00:29:57,600
c plus code that's triggered when a

00:29:56,240 --> 00:30:01,520
kernel finishes

00:29:57,600 --> 00:30:04,240
um and it can also be used to

00:30:01,520 --> 00:30:05,520
interoperate with the the back end

00:30:04,240 --> 00:30:08,960
native programming models

00:30:05,520 --> 00:30:11,760
which we'll see in a second

00:30:08,960 --> 00:30:13,520
okay um so this is what the host test

00:30:11,760 --> 00:30:16,720
looks like it's very similar to

00:30:13,520 --> 00:30:18,799
the other apis like parallel four um

00:30:16,720 --> 00:30:20,480
but the the code inside here is it's

00:30:18,799 --> 00:30:23,200
native c plus plus

00:30:20,480 --> 00:30:23,840
and host tasks are scheduled in a very

00:30:23,200 --> 00:30:26,320
similar

00:30:23,840 --> 00:30:28,399
same way as the as kernel functions they

00:30:26,320 --> 00:30:30,000
follow the same memory model rules so

00:30:28,399 --> 00:30:33,679
they have dependencies based on

00:30:30,000 --> 00:30:33,679
accessors just as with kernel functions

00:30:33,840 --> 00:30:38,880
uh the code inside the host task is

00:30:36,960 --> 00:30:40,720
native c plus plus so this can include

00:30:38,880 --> 00:30:42,080
calling standard t plus source libraries

00:30:40,720 --> 00:30:43,600
and doing i o

00:30:42,080 --> 00:30:45,200
and the usual kernel function

00:30:43,600 --> 00:30:47,600
restrictions on things like

00:30:45,200 --> 00:30:51,520
recursion and dynamic allocation things

00:30:47,600 --> 00:30:53,200
that i don't apply in here

00:30:51,520 --> 00:30:54,799
um when you're using the host task you

00:30:53,200 --> 00:30:56,880
use accessors to

00:30:54,799 --> 00:30:58,480
kind of request access to data and

00:30:56,880 --> 00:30:59,840
create your dependencies just as with

00:30:58,480 --> 00:31:02,000
kernel functions

00:30:59,840 --> 00:31:04,480
and here we're we're creating host

00:31:02,000 --> 00:31:07,440
accessories by calling get host access

00:31:04,480 --> 00:31:08,720
um and this this makes the data

00:31:07,440 --> 00:31:12,399
available on the device

00:31:08,720 --> 00:31:13,679
um to be accessed when this task is run

00:31:12,399 --> 00:31:16,840
and then these access can be used to

00:31:13,679 --> 00:31:18,640
access the data inside the host task

00:31:16,840 --> 00:31:20,559
function um

00:31:18,640 --> 00:31:21,919
the other feature of host tasks is the

00:31:20,559 --> 00:31:23,760
interop ability so

00:31:21,919 --> 00:31:24,960
in order to enable this you simply pass

00:31:23,760 --> 00:31:27,440
this optional

00:31:24,960 --> 00:31:28,799
interrupt handle parameter to the host

00:31:27,440 --> 00:31:32,000
task

00:31:28,799 --> 00:31:35,840
um and then that handle can be used

00:31:32,000 --> 00:31:37,600
to retrieve the back end api

00:31:35,840 --> 00:31:40,000
objects associated with any sickle

00:31:37,600 --> 00:31:40,000
objects

00:31:40,240 --> 00:31:43,279
one other thing to note with this is

00:31:42,159 --> 00:31:44,480
when you're using a host task for

00:31:43,279 --> 00:31:48,159
interoperability

00:31:44,480 --> 00:31:50,320
um you you want to request the data to

00:31:48,159 --> 00:31:52,480
be available on the device because

00:31:50,320 --> 00:31:53,760
um you want to access the the data

00:31:52,480 --> 00:31:56,240
through you know the

00:31:53,760 --> 00:31:57,760
the back end api memory objects the open

00:31:56,240 --> 00:31:59,039
cell memory objects so the cuda memory

00:31:57,760 --> 00:32:01,600
objects

00:31:59,039 --> 00:32:02,799
and so here you just direct you do a

00:32:01,600 --> 00:32:05,039
regular get access

00:32:02,799 --> 00:32:07,360
to to get to access the memory on the

00:32:05,039 --> 00:32:07,360
device

00:32:07,840 --> 00:32:11,600
um and then these accessors because

00:32:09,519 --> 00:32:13,279
they're pointing to memory on the device

00:32:11,600 --> 00:32:14,720
but the host task itself is running on

00:32:13,279 --> 00:32:15,919
the host you can't access those

00:32:14,720 --> 00:32:17,360
accessories

00:32:15,919 --> 00:32:19,200
directly but you can use them to

00:32:17,360 --> 00:32:22,399
retrieve the native

00:32:19,200 --> 00:32:22,399
backend api objects

00:32:25,519 --> 00:32:29,200
okay so the next feature i think one of

00:32:28,480 --> 00:32:31,200
the

00:32:29,200 --> 00:32:32,960
most exciting ones is unified shared

00:32:31,200 --> 00:32:36,480
memory

00:32:32,960 --> 00:32:38,480
so unified share memory essentially

00:32:36,480 --> 00:32:42,480
provides an alternative

00:32:38,480 --> 00:32:44,559
pointer based memory management model um

00:32:42,480 --> 00:32:46,080
alternative to the uh buffer accessor

00:32:44,559 --> 00:32:49,600
model that you've seen in sickle

00:32:46,080 --> 00:32:51,360
1.2.1 now cycle 2020 still has the same

00:32:49,600 --> 00:32:52,640
buffer accessor model but this is now an

00:32:51,360 --> 00:32:55,919
alternative model

00:32:52,640 --> 00:32:56,559
um which has some benefits so usm

00:32:55,919 --> 00:32:58,640
provides

00:32:56,559 --> 00:33:00,320
a unified virtual address space which

00:32:58,640 --> 00:33:02,320
means you have consistent pointers

00:33:00,320 --> 00:33:05,200
across the hosting device

00:33:02,320 --> 00:33:06,960
um so it means if you allocate a pointer

00:33:05,200 --> 00:33:08,320
that you have the same value on the host

00:33:06,960 --> 00:33:09,600
and device which means the pointer can

00:33:08,320 --> 00:33:11,200
be passed back and forward

00:33:09,600 --> 00:33:13,600
without the need for accessors to

00:33:11,200 --> 00:33:14,960
marshal them back and forth

00:33:13,600 --> 00:33:17,039
and this allows you to have pointer

00:33:14,960 --> 00:33:20,399
based structures like linked lists or

00:33:17,039 --> 00:33:23,519
other kind of things um also

00:33:20,399 --> 00:33:26,000
usm has an explicit memory management

00:33:23,519 --> 00:33:27,360
model which means that rather than

00:33:26,000 --> 00:33:28,480
having automatically

00:33:27,360 --> 00:33:29,919
moving your data and managing

00:33:28,480 --> 00:33:30,720
dependencies like with buffers and

00:33:29,919 --> 00:33:33,200
accessors

00:33:30,720 --> 00:33:34,080
it's explicit so all of the dependencies

00:33:33,200 --> 00:33:35,760
and

00:33:34,080 --> 00:33:37,360
movement has to be has to be done

00:33:35,760 --> 00:33:39,679
manually

00:33:37,360 --> 00:33:41,120
and finally it also allows on some

00:33:39,679 --> 00:33:42,240
devices although shared memory

00:33:41,120 --> 00:33:45,919
allocations

00:33:42,240 --> 00:33:49,679
which are memory allocations which can

00:33:45,919 --> 00:33:49,679
be seen by both the host and the device

00:33:51,519 --> 00:33:54,640
so to give an idea of what this looks

00:33:52,880 --> 00:33:57,360
like so

00:33:54,640 --> 00:33:58,640
so usm memory allocations uh essentially

00:33:57,360 --> 00:34:00,320
return a pointer

00:33:58,640 --> 00:34:02,000
that is consistent across hosting device

00:34:00,320 --> 00:34:03,200
you can pass this pointer back and forth

00:34:02,000 --> 00:34:05,919
between the host and your

00:34:03,200 --> 00:34:06,480
on your device and they'll point to this

00:34:05,919 --> 00:34:08,800
uh

00:34:06,480 --> 00:34:10,159
an address in this virtual address space

00:34:08,800 --> 00:34:12,399
which then

00:34:10,159 --> 00:34:15,839
um points to the underlying memory

00:34:12,399 --> 00:34:19,119
either in cpu memory on your gpu memory

00:34:15,839 --> 00:34:20,800
um and then this this is uh

00:34:19,119 --> 00:34:22,320
yeah and then this the the movement of

00:34:20,800 --> 00:34:24,000
the the data between

00:34:22,320 --> 00:34:25,679
the different actual physical memory

00:34:24,000 --> 00:34:28,800
regions is managed by

00:34:25,679 --> 00:34:30,399
explicit memory operations so this

00:34:28,800 --> 00:34:33,679
allows you to do things like

00:34:30,399 --> 00:34:36,320
uh create a linked list

00:34:33,679 --> 00:34:37,919
um when you allocate memory in usm

00:34:36,320 --> 00:34:40,159
rather than allocating like a

00:34:37,919 --> 00:34:41,440
a buffer of elements of a specific type

00:34:40,159 --> 00:34:44,159
you're allocating a

00:34:41,440 --> 00:34:45,760
region of memory a span of bytes and so

00:34:44,159 --> 00:34:47,040
then any pointer within that region

00:34:45,760 --> 00:34:50,159
memory can freely point to other

00:34:47,040 --> 00:34:51,760
addresses within that region

00:34:50,159 --> 00:34:53,280
and so this is one of the nice things

00:34:51,760 --> 00:34:53,839
about this it makes it a lot easier to

00:34:53,280 --> 00:34:56,480
port

00:34:53,839 --> 00:34:58,879
uh existing code cc plus plus code to

00:34:56,480 --> 00:34:58,879
cycle

00:35:00,000 --> 00:35:03,520
so the way that you copy memory back and

00:35:01,520 --> 00:35:05,119
forward is through the sickle mem copy

00:35:03,520 --> 00:35:06,880
operations

00:35:05,119 --> 00:35:08,720
so the second runtime doesn't outperform

00:35:06,880 --> 00:35:10,079
any data dependency analysis

00:35:08,720 --> 00:35:12,880
so all dependence dependencies are

00:35:10,079 --> 00:35:12,880
managed manually

00:35:13,680 --> 00:35:17,200
um some platforms that i mentioned some

00:35:15,200 --> 00:35:19,440
platforms will support um

00:35:17,200 --> 00:35:20,240
variants of usm where memory allocations

00:35:19,440 --> 00:35:22,160
should be shared

00:35:20,240 --> 00:35:23,680
between the host and devices in this

00:35:22,160 --> 00:35:25,040
case no explicit

00:35:23,680 --> 00:35:27,040
memory operations are required you just

00:35:25,040 --> 00:35:28,839
copy the pointer across and they can can

00:35:27,040 --> 00:35:31,760
access the data

00:35:28,839 --> 00:35:34,720
automatically

00:35:31,760 --> 00:35:35,280
so here's a kind of brief summary of um

00:35:34,720 --> 00:35:37,040
the

00:35:35,280 --> 00:35:38,400
the different versions of usm you can

00:35:37,040 --> 00:35:40,320
have um

00:35:38,400 --> 00:35:42,560
there's more detail of this in the the

00:35:40,320 --> 00:35:44,480
cycle 2020 provisional specification

00:35:42,560 --> 00:35:46,000
um but the features that i've covered so

00:35:44,480 --> 00:35:47,520
far consistent pointers

00:35:46,000 --> 00:35:49,280
point to restructures and explicit

00:35:47,520 --> 00:35:51,359
memory explicit data movement

00:35:49,280 --> 00:35:54,079
uh these are supported by by all forms

00:35:51,359 --> 00:35:56,079
of usm um

00:35:54,079 --> 00:35:58,640
and the including the minimum which is

00:35:56,079 --> 00:36:00,000
explicit usm and then from there there's

00:35:58,640 --> 00:36:03,119
kind of increasing

00:36:00,000 --> 00:36:05,760
versions of usm restricted usm

00:36:03,119 --> 00:36:06,960
supports the shared access that's having

00:36:05,760 --> 00:36:08,720
a single

00:36:06,960 --> 00:36:11,119
memory allocation accessed by both hosts

00:36:08,720 --> 00:36:12,160
and device concurrent usm takes that and

00:36:11,119 --> 00:36:14,000
but also allows

00:36:12,160 --> 00:36:15,520
them to the hosting device access at the

00:36:14,000 --> 00:36:17,920
same time

00:36:15,520 --> 00:36:18,800
um and then system usm essentially

00:36:17,920 --> 00:36:22,000
allows

00:36:18,800 --> 00:36:22,720
um standard allocations with like malloc

00:36:22,000 --> 00:36:24,720
and new

00:36:22,720 --> 00:36:26,720
so it means you don't need to use the

00:36:24,720 --> 00:36:29,119
sickle memory allocation routines to

00:36:26,720 --> 00:36:30,560
allocate memory

00:36:29,119 --> 00:36:32,320
and different devices will support

00:36:30,560 --> 00:36:33,920
different levels of usm the

00:36:32,320 --> 00:36:36,400
the minimum is explicit but everything

00:36:33,920 --> 00:36:38,839
after that is optional

00:36:36,400 --> 00:36:41,760
um so now i'm going to run through the

00:36:38,839 --> 00:36:43,839
example uh that we had had earlier

00:36:41,760 --> 00:36:46,640
um but rewriting this with usm just to

00:36:43,839 --> 00:36:46,640
show how this looks

00:36:47,280 --> 00:36:51,599
um first of all we just calculate the

00:36:50,240 --> 00:36:55,599
size of the the data

00:36:51,599 --> 00:36:59,040
in bytes um for the the vectors

00:36:55,599 --> 00:37:01,359
because this will be useful later um so

00:36:59,040 --> 00:37:03,040
first thing we do is we allocate the

00:37:01,359 --> 00:37:04,320
memory on the device so we do this by

00:37:03,040 --> 00:37:07,119
calling malloc device

00:37:04,320 --> 00:37:07,599
so here we allocate a number of elements

00:37:07,119 --> 00:37:10,160
of float

00:37:07,599 --> 00:37:11,839
we specify the queue to see where which

00:37:10,160 --> 00:37:13,359
device we want to allocate on

00:37:11,839 --> 00:37:17,200
and then the pointer returned will be

00:37:13,359 --> 00:37:18,880
consistent across the the hosting device

00:37:17,200 --> 00:37:20,640
but only dereferencable on the device so

00:37:18,880 --> 00:37:24,160
malek devoid devices

00:37:20,640 --> 00:37:24,160
specifically allocating on the device

00:37:24,320 --> 00:37:28,720
next we perform mem copy operations

00:37:26,960 --> 00:37:32,880
which will copy the data from

00:37:28,720 --> 00:37:34,640
our vectors to the device allocations

00:37:32,880 --> 00:37:36,240
and the these return events which can be

00:37:34,640 --> 00:37:39,440
used to synchronize the completion of

00:37:36,240 --> 00:37:39,440
the the copy operations

00:37:39,920 --> 00:37:44,880
next we call parallel four and one thing

00:37:43,280 --> 00:37:46,079
you'll notice here is that we don't

00:37:44,880 --> 00:37:46,560
create a command group and this is

00:37:46,079 --> 00:37:48,000
because

00:37:46,560 --> 00:37:50,480
with usm because we're not using

00:37:48,000 --> 00:37:51,280
accessors you can skip the command group

00:37:50,480 --> 00:37:52,800
and call these

00:37:51,280 --> 00:37:54,800
shortcut functions which is called

00:37:52,800 --> 00:37:57,680
parallel four directly

00:37:54,800 --> 00:37:59,200
um and then this operation also returns

00:37:57,680 --> 00:38:02,400
an event that can be used to synchronize

00:37:59,200 --> 00:38:02,400
in the completion of the function

00:38:03,040 --> 00:38:06,480
and inside inside the uh the kernel

00:38:05,520 --> 00:38:09,200
itself

00:38:06,480 --> 00:38:09,920
uh we retrieve the id um the reason for

00:38:09,200 --> 00:38:12,400
this is that

00:38:09,920 --> 00:38:13,680
you know with with with accessors uh

00:38:12,400 --> 00:38:16,240
they can be

00:38:13,680 --> 00:38:17,280
subscript uh or indexed using the id

00:38:16,240 --> 00:38:20,480
directly

00:38:17,280 --> 00:38:22,960
and but here we we retrieve the actual

00:38:20,480 --> 00:38:25,359
linear ideas as an integer so we can

00:38:22,960 --> 00:38:28,079
index the the pointers

00:38:25,359 --> 00:38:29,520
but we perform the same addition vector

00:38:28,079 --> 00:38:33,200
edition

00:38:29,520 --> 00:38:34,960
as before and finally we do another mem

00:38:33,200 --> 00:38:37,440
copy to copy the the result back

00:38:34,960 --> 00:38:38,000
uh similar to before and again we we

00:38:37,440 --> 00:38:41,599
take the

00:38:38,000 --> 00:38:42,560
the event um and at each point each one

00:38:41,599 --> 00:38:44,000
of these commands

00:38:42,560 --> 00:38:45,760
we're also passing in the events from

00:38:44,000 --> 00:38:47,280
the previous commands to to chain

00:38:45,760 --> 00:38:48,880
the operations together so this creates

00:38:47,280 --> 00:38:50,320
a kind of dependency

00:38:48,880 --> 00:38:52,480
of all the different operations that are

00:38:50,320 --> 00:38:54,400
being performed and at the end

00:38:52,480 --> 00:38:56,400
we wait on the final event to wait for

00:38:54,400 --> 00:38:57,839
all the work to complete

00:38:56,400 --> 00:39:00,880
and obviously once we're finished we

00:38:57,839 --> 00:39:02,880
have to free up the memory um

00:39:00,880 --> 00:39:04,960
one thing to note this is the secle api

00:39:02,880 --> 00:39:05,760
free not the the standard cc plus plus

00:39:04,960 --> 00:39:07,280
free

00:39:05,760 --> 00:39:09,359
um you you'd only be able to use the

00:39:07,280 --> 00:39:11,440
standard maleconfree with the with

00:39:09,359 --> 00:39:13,680
system usm

00:39:11,440 --> 00:39:14,720
there's also a usm allocator that i'm

00:39:13,680 --> 00:39:16,880
not showing here which

00:39:14,720 --> 00:39:17,839
performs allocation of the allocation in

00:39:16,880 --> 00:39:20,880
this way

00:39:17,839 --> 00:39:23,359
um which is useful if you want to to do

00:39:20,880 --> 00:39:23,359
it that way

00:39:24,400 --> 00:39:29,440
finally in order queues which is kind of

00:39:26,400 --> 00:39:33,680
a small extension to to this

00:39:29,440 --> 00:39:35,839
um so in order versus out of order

00:39:33,680 --> 00:39:37,920
um in order execution means that all

00:39:35,839 --> 00:39:38,800
commands are executed in the order that

00:39:37,920 --> 00:39:41,280
they're enqueued

00:39:38,800 --> 00:39:42,640
so in a strict ordering out of order

00:39:41,280 --> 00:39:44,400
execution means that commands can be

00:39:42,640 --> 00:39:46,800
reordered as long as they satisfy the

00:39:44,400 --> 00:39:50,160
memory model and this is generally how

00:39:46,800 --> 00:39:52,000
sickle cues have worked in sync 1.2.1 um

00:39:50,160 --> 00:39:54,160
so cycle queues are by default out of

00:39:52,000 --> 00:39:56,720
order and but now in 2020

00:39:54,160 --> 00:39:59,119
a queue can be created as in order by

00:39:56,720 --> 00:40:00,400
using this inorder property

00:39:59,119 --> 00:40:03,839
so we're going to take the current

00:40:00,400 --> 00:40:06,160
example we just looked at and do that

00:40:03,839 --> 00:40:06,880
so what we do is we specify this

00:40:06,160 --> 00:40:09,520
property

00:40:06,880 --> 00:40:10,880
to the queue constructor called inorder

00:40:09,520 --> 00:40:12,240
essentially this tells the cue that

00:40:10,880 --> 00:40:13,200
everything that's enqueued to it should

00:40:12,240 --> 00:40:15,599
be

00:40:13,200 --> 00:40:17,119
executed in the order that it was it was

00:40:15,599 --> 00:40:19,760
uh submitted

00:40:17,119 --> 00:40:21,359
so there's no reordering allowed what

00:40:19,760 --> 00:40:23,040
this means is that

00:40:21,359 --> 00:40:25,119
since the queue is in order it's a

00:40:23,040 --> 00:40:27,359
guarantee that there is going to

00:40:25,119 --> 00:40:29,040
follow a very specific order and we

00:40:27,359 --> 00:40:30,720
don't need to to chain these different

00:40:29,040 --> 00:40:32,800
commands together with events anymore so

00:40:30,720 --> 00:40:35,359
this this simplifies the

00:40:32,800 --> 00:40:36,160
usage and this is quite quite useful if

00:40:35,359 --> 00:40:38,400
you know that

00:40:36,160 --> 00:40:40,079
you you don't want you don't want to to

00:40:38,400 --> 00:40:42,480
reorder you know that you're going to

00:40:40,079 --> 00:40:43,119
execute work in a particular order then

00:40:42,480 --> 00:40:44,720
um

00:40:43,119 --> 00:40:46,400
then in order to use can be can be very

00:40:44,720 --> 00:40:49,200
useful and can simplify the

00:40:46,400 --> 00:40:49,200
api quite a lot

00:40:49,599 --> 00:40:53,440
okay and and that's that's that's that

00:40:51,680 --> 00:40:54,160
covers all of the the sickle 2020

00:40:53,440 --> 00:40:57,200
features

00:40:54,160 --> 00:40:59,359
uh that i that have um

00:40:57,200 --> 00:41:01,280
now i'm going to pass over to to michael

00:40:59,359 --> 00:41:06,400
again to go into

00:41:01,280 --> 00:41:08,880
sickle future thank you

00:41:06,400 --> 00:41:10,160
okay uh thank you thank you gordon um

00:41:08,880 --> 00:41:12,400
that was great

00:41:10,160 --> 00:41:13,839
i love looking at how those features how

00:41:12,400 --> 00:41:14,319
we wouldn't how we're doing getting more

00:41:13,839 --> 00:41:16,800
and more c

00:41:14,319 --> 00:41:18,319
plus for 17 alignments here so i'm going

00:41:16,800 --> 00:41:20,160
to talk a little bit about sickle future

00:41:18,319 --> 00:41:22,400
and where we're planning to go

00:41:20,160 --> 00:41:23,359
as a group the first thing that i want

00:41:22,400 --> 00:41:25,920
to look at is

00:41:23,359 --> 00:41:27,200
what is the sickle ecosystem and it's

00:41:25,920 --> 00:41:29,760
rapidly growing

00:41:27,200 --> 00:41:30,960
um so this this slide in particularly

00:41:29,760 --> 00:41:32,640
highlights the

00:41:30,960 --> 00:41:33,920
already large and growing sickle

00:41:32,640 --> 00:41:35,440
ecosystem starting with the

00:41:33,920 --> 00:41:37,040
implementations on the left you know

00:41:35,440 --> 00:41:39,520
that that gordon is talking about

00:41:37,040 --> 00:41:42,800
hipsicle one api dpc plus plus

00:41:39,520 --> 00:41:46,000
from intel our compute cpp

00:41:42,800 --> 00:41:48,319
hipsicle um and then there are many

00:41:46,000 --> 00:41:49,839
research papers that are growing and of

00:41:48,319 --> 00:41:50,800
this i want to point out the exascale

00:41:49,839 --> 00:41:53,440
computing project

00:41:50,800 --> 00:41:55,040
and the celerity for sickle cluster the

00:41:53,440 --> 00:41:56,880
solarity programming

00:41:55,040 --> 00:41:58,560
environment seeks to essentially enable

00:41:56,880 --> 00:42:01,280
developers to scale c

00:41:58,560 --> 00:42:03,920
plus applications to accelerate the

00:42:01,280 --> 00:42:06,240
clusters with pretty much relative ease

00:42:03,920 --> 00:42:07,599
essentially leveraging and extending the

00:42:06,240 --> 00:42:09,920
sickle domain

00:42:07,599 --> 00:42:11,040
specific embedded language by having

00:42:09,920 --> 00:42:13,440
users provide

00:42:11,040 --> 00:42:15,680
minimal information about how data is

00:42:13,440 --> 00:42:17,680
accessed within the compute kernel

00:42:15,680 --> 00:42:19,520
solar cellularity essentially

00:42:17,680 --> 00:42:21,760
automatically distributes the work

00:42:19,520 --> 00:42:25,359
and data so think about mpi but running

00:42:21,760 --> 00:42:27,920
on accelerated c plus plus with sicko

00:42:25,359 --> 00:42:29,680
ecp the extra skill computing project

00:42:27,920 --> 00:42:32,000
allows sql to run on xscale

00:42:29,680 --> 00:42:33,920
super computer systems using intel chips

00:42:32,000 --> 00:42:36,400
being built right now at argonne

00:42:33,920 --> 00:42:38,000
national lab and it's aiming to reach

00:42:36,400 --> 00:42:40,800
extra flop computing that's

00:42:38,000 --> 00:42:41,440
10 to 18 floating point operations per

00:42:40,800 --> 00:42:43,119
second

00:42:41,440 --> 00:42:44,800
with that you can now essentially start

00:42:43,119 --> 00:42:48,400
mapping the universe

00:42:44,800 --> 00:42:51,520
much bigger genome um climate change

00:42:48,400 --> 00:42:53,520
disease um proliferations and spreads so

00:42:51,520 --> 00:42:55,440
much of this is going to be uh

00:42:53,520 --> 00:42:56,800
was has been shown in a keynote by hal

00:42:55,440 --> 00:42:58,800
finkel

00:42:56,800 --> 00:43:01,280
at iowa code this year and there are now

00:42:58,800 --> 00:43:02,480
also several benchmarks involving sicko

00:43:01,280 --> 00:43:04,800
and i want to call university of

00:43:02,480 --> 00:43:06,319
bristol's babel stream that measures the

00:43:04,800 --> 00:43:08,400
performance portability

00:43:06,319 --> 00:43:10,480
of sickle taking along with many other

00:43:08,400 --> 00:43:11,520
acceleration languages like openmp

00:43:10,480 --> 00:43:15,040
opencl

00:43:11,520 --> 00:43:17,520
cuda and openhcc over time

00:43:15,040 --> 00:43:18,720
this has increased um to a suite of four

00:43:17,520 --> 00:43:20,800
to five benchmarks

00:43:18,720 --> 00:43:22,560
uh including uh t leave that measures

00:43:20,800 --> 00:43:24,880
acceleration performance

00:43:22,560 --> 00:43:26,000
there's also intel intel's jeff

00:43:24,880 --> 00:43:29,280
hammond's uh

00:43:26,000 --> 00:43:30,880
um programming research or prk

00:43:29,280 --> 00:43:32,960
it's a suite that contains a number of

00:43:30,880 --> 00:43:35,520
kernel operations plus a

00:43:32,960 --> 00:43:36,800
simple build system intended for a linux

00:43:35,520 --> 00:43:38,640
compatible environment

00:43:36,800 --> 00:43:40,720
most of the code relies on open standard

00:43:38,640 --> 00:43:43,359
programming models using sickle

00:43:40,720 --> 00:43:44,960
and testing the the productivity of

00:43:43,359 --> 00:43:47,760
using these models

00:43:44,960 --> 00:43:48,240
and executing on many computing system

00:43:47,760 --> 00:43:50,640
his

00:43:48,240 --> 00:43:52,319
one interesting conclusion was that most

00:43:50,640 --> 00:43:54,720
of these these these program

00:43:52,319 --> 00:43:56,800
models while it certainly was helpful in

00:43:54,720 --> 00:43:59,359
terms of increasing the productivity

00:43:56,800 --> 00:44:01,040
um there was an older one that was boost

00:43:59,359 --> 00:44:02,960
start compute that he was looking at

00:44:01,040 --> 00:44:04,079
and he found that converting them to

00:44:02,960 --> 00:44:06,319
templates made it

00:44:04,079 --> 00:44:07,520
not as easy to use so take a look at his

00:44:06,319 --> 00:44:10,079
work

00:44:07,520 --> 00:44:11,040
there's also many library libraries now

00:44:10,079 --> 00:44:12,720
in sickles

00:44:11,040 --> 00:44:14,240
supporting linear algebra machine

00:44:12,720 --> 00:44:15,920
learning and parallel

00:44:14,240 --> 00:44:17,839
acceleration and at the bottom you're

00:44:15,920 --> 00:44:18,319
going to see all the active working

00:44:17,839 --> 00:44:19,839
group

00:44:18,319 --> 00:44:21,520
companies that are attending the weeks

00:44:19,839 --> 00:44:22,240
of the weekly calls as well as all the

00:44:21,520 --> 00:44:25,839
face to

00:44:22,240 --> 00:44:25,839
three face-to-face that are going on

00:44:26,640 --> 00:44:32,160
so in this slide i want to point out

00:44:30,000 --> 00:44:34,400
um an extra what an extraordinary

00:44:32,160 --> 00:44:36,800
adoption it has been to see sickle grow

00:44:34,400 --> 00:44:37,920
into the high performance computing

00:44:36,800 --> 00:44:40,160
space

00:44:37,920 --> 00:44:42,079
with the aurora super computer in excess

00:44:40,160 --> 00:44:42,960
scale computing i attribute this to the

00:44:42,079 --> 00:44:45,119
fact that

00:44:42,960 --> 00:44:46,400
we lead iso c plus plus with a language

00:44:45,119 --> 00:44:47,599
that uses standard c

00:44:46,400 --> 00:44:50,160
plus plus but augmented with

00:44:47,599 --> 00:44:51,520
heterogeneous dispatch but not for any

00:44:50,160 --> 00:44:54,160
one device but for

00:44:51,520 --> 00:44:55,440
a democracy a democracy of many

00:44:54,160 --> 00:44:56,480
different device kinds from many

00:44:55,440 --> 00:44:58,560
different vendors

00:44:56,480 --> 00:45:00,560
which is the promised road to getting to

00:44:58,560 --> 00:45:01,760
extra steel computing using accelerated

00:45:00,560 --> 00:45:04,800
you see these guys

00:45:01,760 --> 00:45:06,079
um they code their code lasts for 10 20

00:45:04,800 --> 00:45:08,880
years but their hardware

00:45:06,079 --> 00:45:10,079
is always almost brand new but but it

00:45:08,880 --> 00:45:11,839
only lives for another

00:45:10,079 --> 00:45:13,440
some five years every five years or so

00:45:11,839 --> 00:45:14,400
they switch vendors and uses a different

00:45:13,440 --> 00:45:16,319
hardware

00:45:14,400 --> 00:45:18,000
so you see here that sickle through

00:45:16,319 --> 00:45:20,480
intel's dpc plus

00:45:18,000 --> 00:45:23,359
plus is adopted to be the programming

00:45:20,480 --> 00:45:25,599
model for aurora the first choral

00:45:23,359 --> 00:45:27,359
xscale computer using intel processors

00:45:25,599 --> 00:45:29,680
now they're actually two more coming

00:45:27,359 --> 00:45:30,720
they're called frontier and el capitan

00:45:29,680 --> 00:45:31,359
and they're going to be delivered with

00:45:30,720 --> 00:45:34,079
amd

00:45:31,359 --> 00:45:36,240
processors both cpu and gpu i will point

00:45:34,079 --> 00:45:37,440
out that sickle can run on rockum as one

00:45:36,240 --> 00:45:39,920
of our implementations

00:45:37,440 --> 00:45:43,119
is hypsicol and is demonstrated to work

00:45:39,920 --> 00:45:43,119
on these processors

00:45:44,160 --> 00:45:47,520
so sickle has had tremendous growth in

00:45:46,480 --> 00:45:49,680
the last three years

00:45:47,520 --> 00:45:50,960
um with working group participation of

00:45:49,680 --> 00:45:52,319
00:45:50,960 --> 00:45:54,480
we now have an active presence in

00:45:52,319 --> 00:45:56,079
supercomputing due to u.s national lab

00:45:54,480 --> 00:45:57,680
interest and intel support for the

00:45:56,079 --> 00:46:00,079
aurora supercomputer

00:45:57,680 --> 00:46:02,319
we have active open source collaboration

00:46:00,079 --> 00:46:04,640
implementation using

00:46:02,319 --> 00:46:05,359
llvm clang which hosts its own weekly

00:46:04,640 --> 00:46:06,960
meetings

00:46:05,359 --> 00:46:08,560
uh we're seeing adoption now by high

00:46:06,960 --> 00:46:09,599
performance computing for example

00:46:08,560 --> 00:46:12,160
computing and

00:46:09,599 --> 00:46:13,680
in the self-driving car domain uh using

00:46:12,160 --> 00:46:16,960
the renaissance alcohol

00:46:13,680 --> 00:46:17,440
as well as in some fpga ai and custom

00:46:16,960 --> 00:46:19,520
chips

00:46:17,440 --> 00:46:21,920
uh domains we're going to continue to

00:46:19,520 --> 00:46:22,480
tight to tighten the integration with

00:46:21,920 --> 00:46:25,040
isoc

00:46:22,480 --> 00:46:26,720
plus and opencl but open to adopting

00:46:25,040 --> 00:46:28,640
many other forms of back ends which i

00:46:26,720 --> 00:46:30,640
see there are some questions about that

00:46:28,640 --> 00:46:31,839
um look for more open collaboration

00:46:30,640 --> 00:46:34,000
using github

00:46:31,839 --> 00:46:35,920
and continue the cadence of ratification

00:46:34,000 --> 00:46:38,240
every one and a half to three years

00:46:35,920 --> 00:46:39,599
and just like iso c plus plus we plan to

00:46:38,240 --> 00:46:41,040
look ahead to a future where we

00:46:39,599 --> 00:46:42,720
integrate their features

00:46:41,040 --> 00:46:44,560
and we've been actively participating in

00:46:42,720 --> 00:46:47,119
them along with many other companies

00:46:44,560 --> 00:46:48,160
on things like executors co-routines

00:46:47,119 --> 00:46:50,240
futures

00:46:48,160 --> 00:46:51,520
we plan to adapt the property mechanism

00:46:50,240 --> 00:46:53,200
in the future and

00:46:51,520 --> 00:46:55,280
we're looking closely at adopting things

00:46:53,200 --> 00:46:56,880
like concepts modules and parallel

00:46:55,280 --> 00:46:58,400
algorithms with ranges

00:46:56,880 --> 00:46:59,760
that is something that we pioneered and

00:46:58,400 --> 00:47:02,560
we've been working on in the background

00:46:59,760 --> 00:47:02,560
for quite a while

00:47:03,599 --> 00:47:07,920
so sickle 2020 the final version is

00:47:06,000 --> 00:47:08,720
coming at the end of this year in a few

00:47:07,920 --> 00:47:10,480
months

00:47:08,720 --> 00:47:12,319
and when it comes out i want to urge

00:47:10,480 --> 00:47:13,440
feedback to from you to tell us what

00:47:12,319 --> 00:47:16,079
features you would like

00:47:13,440 --> 00:47:17,839
to add and that are not currently yet in

00:47:16,079 --> 00:47:19,280
sickle 2020 and what you would like to

00:47:17,839 --> 00:47:21,920
aim for in the future

00:47:19,280 --> 00:47:22,640
so the question is how do you join um

00:47:21,920 --> 00:47:25,839
i'm glad

00:47:22,640 --> 00:47:28,480
you asked when i asked

00:47:25,839 --> 00:47:30,079
so in this one slide you see all the

00:47:28,480 --> 00:47:32,079
ways you can join simcoe

00:47:30,079 --> 00:47:34,480
three out of four of these need no money

00:47:32,079 --> 00:47:37,280
you can anyone can suggest a feature

00:47:34,480 --> 00:47:38,000
or fix and a small fee will allow you to

00:47:37,280 --> 00:47:39,839
participate

00:47:38,000 --> 00:47:41,760
in the actual design of the features in

00:47:39,839 --> 00:47:43,359
the working group itself that's at the

00:47:41,760 --> 00:47:45,119
bottom in the center circle

00:47:43,359 --> 00:47:47,599
and a larger voice in the future of

00:47:45,119 --> 00:47:47,599
single

00:47:48,720 --> 00:47:55,119
so sickle is creating what we

00:47:52,079 --> 00:47:56,960
think is a cutting-edge royalty-free

00:47:55,119 --> 00:47:58,800
open standard for heterogeneous c plus

00:47:56,960 --> 00:47:59,920
plus compute vision and inference

00:47:58,800 --> 00:48:01,760
acceleration

00:47:59,920 --> 00:48:03,599
we have a sickle con tutorial that's

00:48:01,760 --> 00:48:06,960
coming up on

00:48:03,599 --> 00:48:08,720
in on monday tuesday and wednesday um

00:48:06,960 --> 00:48:09,920
so and i'm going to show you the time

00:48:08,720 --> 00:48:11,920
and address you can still join that

00:48:09,920 --> 00:48:13,280
sickle sickle tutorial that's coming up

00:48:11,920 --> 00:48:14,000
good that gordon and i are going to be

00:48:13,280 --> 00:48:16,079
teaching

00:48:14,000 --> 00:48:17,119
i'm michael wong chair of sicko and i

00:48:16,079 --> 00:48:20,079
encourage you to join

00:48:17,119 --> 00:48:22,240
kronos in this effort to lead and

00:48:20,079 --> 00:48:23,760
accelerate a portfolio of useful

00:48:22,240 --> 00:48:25,359
standards to enhance your company's

00:48:23,760 --> 00:48:28,079
leadership

00:48:25,359 --> 00:48:29,440
so it is open for all to join and the

00:48:28,079 --> 00:48:31,599
key thing i want to highlight is that

00:48:29,440 --> 00:48:33,920
sql is not owned by any one company

00:48:31,599 --> 00:48:35,280
or dominated by any one company we i

00:48:33,920 --> 00:48:37,119
will make sure that

00:48:35,280 --> 00:48:39,200
by joining you can share you can shape

00:48:37,119 --> 00:48:41,040
sickle to whatever it is that it wants

00:48:39,200 --> 00:48:42,880
uh whatever it is that you might want to

00:48:41,040 --> 00:48:43,680
be to serve your particular community

00:48:42,880 --> 00:48:45,599
better

00:48:43,680 --> 00:48:47,200
we have no stake in any one particular

00:48:45,599 --> 00:48:49,040
hard way even if you still need to serve

00:48:47,200 --> 00:48:50,160
a proprietary version of your hardware

00:48:49,040 --> 00:48:52,240
and that's understandable

00:48:50,160 --> 00:48:53,200
i came from ibm we had to you know make

00:48:52,240 --> 00:48:54,800
sure that um

00:48:53,200 --> 00:48:56,480
somehow we had to develop photo our own

00:48:54,800 --> 00:48:58,240
hardware when i was in ibm

00:48:56,480 --> 00:49:00,640
so we i do not believe these are

00:48:58,240 --> 00:49:03,680
computing i'm sorry competing

00:49:00,640 --> 00:49:05,440
by joining uh our knowledge we can i do

00:49:03,680 --> 00:49:06,720
think we can serve the world better with

00:49:05,440 --> 00:49:08,720
the aim of aligning with

00:49:06,720 --> 00:49:09,920
uh future c plus by standard i know many

00:49:08,720 --> 00:49:11,760
people are trying to head in that

00:49:09,920 --> 00:49:12,720
direction so as a result i count many of

00:49:11,760 --> 00:49:14,720
them as friends

00:49:12,720 --> 00:49:16,079
and the attempt at trying to try to get

00:49:14,720 --> 00:49:18,079
to that stage of furthering

00:49:16,079 --> 00:49:19,680
c plus plus standard but sequels

00:49:18,079 --> 00:49:21,760
standard does take a little longer

00:49:19,680 --> 00:49:22,720
whereas we can change and move a little

00:49:21,760 --> 00:49:24,720
bit faster

00:49:22,720 --> 00:49:26,480
so we want more fan of vendor they have

00:49:24,720 --> 00:49:27,839
they bring valuable platform experience

00:49:26,480 --> 00:49:30,240
we want more academics

00:49:27,839 --> 00:49:31,119
that are involved they bring terrific

00:49:30,240 --> 00:49:34,400
research knowledge

00:49:31,119 --> 00:49:34,400
and more industry members

00:49:34,640 --> 00:49:38,160
and if you like to learn more about

00:49:37,119 --> 00:49:41,040
sickle

00:49:38,160 --> 00:49:42,720
okay this is the the gpu programming

00:49:41,040 --> 00:49:44,720
programming class

00:49:42,720 --> 00:49:46,319
in modern c plus plus using cinco that's

00:49:44,720 --> 00:49:47,280
coming we've been doing this class for

00:49:46,319 --> 00:49:48,640
three years now

00:49:47,280 --> 00:49:50,559
each year has gone more and more

00:49:48,640 --> 00:49:51,200
advanced initially we did a mix of

00:49:50,559 --> 00:49:54,240
parallel c

00:49:51,200 --> 00:49:56,640
plus iso c plus plus programming and gpu

00:49:54,240 --> 00:49:58,160
um beginner programming with sickle that

00:49:56,640 --> 00:50:00,400
was two years ago last year we

00:49:58,160 --> 00:50:01,839
we got the feedback was great with sicko

00:50:00,400 --> 00:50:02,480
let's just go to more and more advanced

00:50:01,839 --> 00:50:04,400
stuff so i

00:50:02,480 --> 00:50:05,760
we dumped all of the parallel seats all

00:50:04,400 --> 00:50:07,680
the isoc

00:50:05,760 --> 00:50:09,200
parallelism concurrency stuff other

00:50:07,680 --> 00:50:11,119
other teachers have done a much

00:50:09,200 --> 00:50:13,359
better job on some of these so we focus

00:50:11,119 --> 00:50:14,960
entirely on the area of our expertise

00:50:13,359 --> 00:50:16,800
which is gpu programming and the

00:50:14,960 --> 00:50:19,040
feedback from last year to this year is

00:50:16,800 --> 00:50:20,079
even better more even more advanced

00:50:19,040 --> 00:50:22,400
stuff um

00:50:20,079 --> 00:50:23,599
so and how does it tie to the latest c

00:50:22,400 --> 00:50:26,480
plus plus 17.

00:50:23,599 --> 00:50:27,680
so even though um sickle 2020 isn't

00:50:26,480 --> 00:50:29,359
ratified yet

00:50:27,680 --> 00:50:31,440
but is well on its way i've been sharing

00:50:29,359 --> 00:50:33,200
those meetings every week

00:50:31,440 --> 00:50:34,400
um there are compilers that have some of

00:50:33,200 --> 00:50:35,119
these features that are potentially

00:50:34,400 --> 00:50:36,480
available so

00:50:35,119 --> 00:50:38,400
that's what we're going to do in the

00:50:36,480 --> 00:50:39,920
next uh in the three-day course

00:50:38,400 --> 00:50:41,599
and with that i'd like to thank thank

00:50:39,920 --> 00:50:44,800
everyone and ask my colleague

00:50:41,599 --> 00:50:46,240
gordon brown to come back on um and so

00:50:44,800 --> 00:50:48,319
we can answer some of the questions that

00:50:46,240 --> 00:50:52,160
i'm seeing on the board

00:50:48,319 --> 00:50:53,680
um so we have about um eight minutes so

00:50:52,160 --> 00:50:55,680
starting with the first question um

00:50:53,680 --> 00:50:57,760
devon asked has there been

00:50:55,680 --> 00:50:59,440
any consideration to introducing smart

00:50:57,760 --> 00:51:02,319
pointers for usm

00:50:59,440 --> 00:51:03,599
so we can use r-a-i-i for malox 3.

00:51:02,319 --> 00:51:06,480
that's a good question

00:51:03,599 --> 00:51:06,960
um gordon do you want to answer that

00:51:06,480 --> 00:51:09,040
sure

00:51:06,960 --> 00:51:10,720
um yeah thanks is is a very good

00:51:09,040 --> 00:51:13,920
question um

00:51:10,720 --> 00:51:17,280
so we so far we have the

00:51:13,920 --> 00:51:18,960
the the low level um api for for malcolm

00:51:17,280 --> 00:51:22,480
3 and then we have the

00:51:18,960 --> 00:51:24,480
usm allocator um as a way of

00:51:22,480 --> 00:51:25,520
performing usm allocation in standard

00:51:24,480 --> 00:51:28,880
containers

00:51:25,520 --> 00:51:32,240
um we have seen um

00:51:28,880 --> 00:51:34,000
some some applications uh create

00:51:32,240 --> 00:51:36,240
kind of smart pointers that would

00:51:34,000 --> 00:51:38,800
perform kind of automatic um

00:51:36,240 --> 00:51:39,760
allocation of the allocation using usm

00:51:38,800 --> 00:51:40,800
um

00:51:39,760 --> 00:51:42,720
it's not something that's in the

00:51:40,800 --> 00:51:44,720
provisional specification but i think it

00:51:42,720 --> 00:51:46,720
is a good idea i think it could be a

00:51:44,720 --> 00:51:49,200
useful feature for physical

00:51:46,720 --> 00:51:50,240
either as a tool that can be used on top

00:51:49,200 --> 00:51:51,599
of sickle or

00:51:50,240 --> 00:51:53,599
as something that could be introduced to

00:51:51,599 --> 00:51:56,880
the the standard if

00:51:53,599 --> 00:51:57,760
great i think that's a good idea uh so

00:51:56,880 --> 00:51:59,440
with that i think

00:51:57,760 --> 00:52:00,960
we've answered that question the next

00:51:59,440 --> 00:52:02,720
question by andrew says

00:52:00,960 --> 00:52:04,800
how will be how will the upcoming

00:52:02,720 --> 00:52:06,160
executives feature integrate with cinco

00:52:04,800 --> 00:52:07,760
so i'll just say that we've been deeply

00:52:06,160 --> 00:52:09,680
involved with this executive along with

00:52:07,760 --> 00:52:12,480
many other people like nvidia

00:52:09,680 --> 00:52:13,280
um like um as well as a number of other

00:52:12,480 --> 00:52:16,160
people from uh

00:52:13,280 --> 00:52:16,880
google and facebook so we definitely

00:52:16,160 --> 00:52:19,680
plan to

00:52:16,880 --> 00:52:21,200
uh so we we know it very well and gordon

00:52:19,680 --> 00:52:22,640
has been an instrumental part of being

00:52:21,200 --> 00:52:23,119
involved in that so gordon can you say

00:52:22,640 --> 00:52:26,400
something

00:52:23,119 --> 00:52:29,680
about that yeah so um

00:52:26,400 --> 00:52:30,800
we've well well working on the the cycle

00:52:29,680 --> 00:52:34,240
specification the

00:52:30,800 --> 00:52:36,319
the sickle working group is is uh

00:52:34,240 --> 00:52:38,240
one of our aims is to try and align with

00:52:36,319 --> 00:52:39,839
with iso c plus plus as much as possible

00:52:38,240 --> 00:52:44,000
for the future so

00:52:39,839 --> 00:52:45,839
um we've always got one eye on um

00:52:44,000 --> 00:52:48,079
the executor's proposal and what's

00:52:45,839 --> 00:52:49,760
happening there both to kind of try to

00:52:48,079 --> 00:52:51,920
align sickle with it so that they're

00:52:49,760 --> 00:52:54,559
compatible and they work well together

00:52:51,920 --> 00:52:54,960
um and that when executors land in c

00:52:54,559 --> 00:52:58,079
plus

00:52:54,960 --> 00:52:59,920
uh circle can kind of

00:52:58,079 --> 00:53:01,760
move into to use some of those features

00:52:59,920 --> 00:53:04,480
and and work with those concepts

00:53:01,760 --> 00:53:06,240
um but also to try and kind of shape

00:53:04,480 --> 00:53:08,640
executors so that that

00:53:06,240 --> 00:53:10,160
supports uh the sickle programming model

00:53:08,640 --> 00:53:12,480
and the signal back ends well

00:53:10,160 --> 00:53:14,640
as well so it's been a kind of back and

00:53:12,480 --> 00:53:15,839
forth between the two standards

00:53:14,640 --> 00:53:18,240
to make sure that they'll work well

00:53:15,839 --> 00:53:19,440
together so i'll ask this question so

00:53:18,240 --> 00:53:21,040
we've been watching the six

00:53:19,440 --> 00:53:22,960
we've been watching participating and

00:53:21,040 --> 00:53:25,040
writing the specification for executives

00:53:22,960 --> 00:53:26,319
do you see anything in executors um that

00:53:25,040 --> 00:53:28,720
we have important

00:53:26,319 --> 00:53:30,559
um that there will be that will make it

00:53:28,720 --> 00:53:33,599
uh counter to all impossible to be

00:53:30,559 --> 00:53:33,599
integrated in the second

00:53:33,760 --> 00:53:40,480
no i i wouldn't say so now i think the

00:53:37,359 --> 00:53:42,559
the executor's proposal has had a lot of

00:53:40,480 --> 00:53:45,520
a lot of authors on it and it's been

00:53:42,559 --> 00:53:47,280
a work in progress for for for quite uh

00:53:45,520 --> 00:53:48,880
for many many years now and i think

00:53:47,280 --> 00:53:50,480
the one of the reasons that it's it's

00:53:48,880 --> 00:53:52,480
taken quite a while to

00:53:50,480 --> 00:53:53,599
to get to a final proposal that's now

00:53:52,480 --> 00:53:56,240
being considered for

00:53:53,599 --> 00:53:57,280
peoplesoft 23 is that we wanted to make

00:53:56,240 --> 00:53:59,200
sure that

00:53:57,280 --> 00:54:00,480
you know the model was kind of the

00:53:59,200 --> 00:54:03,359
abstractions were

00:54:00,480 --> 00:54:04,079
correct for supporting all the various

00:54:03,359 --> 00:54:06,800
different

00:54:04,079 --> 00:54:08,000
um you know ways of heterogeneous and

00:54:06,800 --> 00:54:10,480
asynchronous programming

00:54:08,000 --> 00:54:12,319
including things like cycle and cuda and

00:54:10,480 --> 00:54:14,240
and various other programming models so

00:54:12,319 --> 00:54:15,760
that was really important yeah a real

00:54:14,240 --> 00:54:17,280
democratization of all of these

00:54:15,760 --> 00:54:17,680
different models for different kinds of

00:54:17,280 --> 00:54:20,559
um

00:54:17,680 --> 00:54:21,440
ships so the next question says how does

00:54:20,559 --> 00:54:24,400
sickle

00:54:21,440 --> 00:54:26,000
compare to nvidia's cuda so i i think

00:54:24,400 --> 00:54:27,839
that's a great question um

00:54:26,000 --> 00:54:29,040
um and it's not just nvidia's kudo

00:54:27,839 --> 00:54:30,880
before sickle

00:54:29,040 --> 00:54:33,440
um there were many other frameworks some

00:54:30,880 --> 00:54:35,440
of this is library only like nvidia's uh

00:54:33,440 --> 00:54:37,280
sorry nvidia's thrust i said kudos

00:54:35,440 --> 00:54:39,680
actually thrust the thrust library

00:54:37,280 --> 00:54:41,920
um there is actually an amd bolt library

00:54:39,680 --> 00:54:44,160
as well too there was boost.compute

00:54:41,920 --> 00:54:46,319
which was essentially a c plus plus

00:54:44,160 --> 00:54:48,240
framework on top of opengl

00:54:46,319 --> 00:54:50,559
um chromosomes yell and then there's

00:54:48,240 --> 00:54:51,599
also c plus m which is more properly the

00:54:50,559 --> 00:54:53,920
pedigree

00:54:51,599 --> 00:54:55,920
of profitness for sicko because it

00:54:53,920 --> 00:54:56,799
introduced the first uh implicit uh data

00:54:55,920 --> 00:54:59,119
movement model

00:54:56,799 --> 00:55:01,040
so i would say that i love what nvidia

00:54:59,119 --> 00:55:02,480
does with russ and recruiter

00:55:01,040 --> 00:55:05,200
and i'll also call out that cuda and

00:55:02,480 --> 00:55:08,160
recently g8 a new compiler

00:55:05,200 --> 00:55:08,960
which is more c plus plus like um um

00:55:08,160 --> 00:55:11,359
that has

00:55:08,960 --> 00:55:13,599
better support for c plus plus libraries

00:55:11,359 --> 00:55:14,480
um standard libraries stl so i would say

00:55:13,599 --> 00:55:16,079
that all of these

00:55:14,480 --> 00:55:18,839
are similar in that they were all trying

00:55:16,079 --> 00:55:20,079
to make sure that they have an stl like

00:55:18,839 --> 00:55:23,440
interface so like bolt

00:55:20,079 --> 00:55:23,760
amd's bolt nvidia's thrust boost.compute

00:55:23,440 --> 00:55:26,640
and c

00:55:23,760 --> 00:55:27,839
plug plus m and signal so threat is only

00:55:26,640 --> 00:55:30,319
essentially i believe

00:55:27,839 --> 00:55:32,319
pretty much supports mostly nvidia gpus

00:55:30,319 --> 00:55:35,440
but may also work on some cpus

00:55:32,319 --> 00:55:36,960
through its openmp backend now there are

00:55:35,440 --> 00:55:38,400
other people that are much more familiar

00:55:36,960 --> 00:55:40,160
with us here that will answer that much

00:55:38,400 --> 00:55:42,000
better so i'm trying to be very careful

00:55:40,160 --> 00:55:44,480
i don't say the wrong thing a boat

00:55:42,000 --> 00:55:46,799
however amd's ball uses extensions

00:55:44,480 --> 00:55:48,079
to opencl which are only essentially

00:55:46,799 --> 00:55:51,040
available on amd

00:55:48,079 --> 00:55:52,079
gpu they also provide a microsoft c

00:55:51,040 --> 00:55:55,839
blood plus amp and

00:55:52,079 --> 00:55:56,960
intel tpd back then the c plus plus amp

00:55:55,839 --> 00:55:58,799
from microsoft

00:55:56,960 --> 00:56:00,480
is the only compiler that supports that

00:55:58,799 --> 00:56:02,240
mostly visual c plus i know there are a

00:56:00,480 --> 00:56:05,280
few open compilers but it's

00:56:02,240 --> 00:56:07,040
essentially has declined

00:56:05,280 --> 00:56:09,200
and after it's it's flurried in

00:56:07,040 --> 00:56:10,480
production after about about eight years

00:56:09,200 --> 00:56:12,559
and that's unfortunate because i

00:56:10,480 --> 00:56:13,599
actually really like that um bootstrap

00:56:12,559 --> 00:56:15,280
compute like i said

00:56:13,599 --> 00:56:17,839
um was one of the first granddaddies

00:56:15,280 --> 00:56:20,160
that essentially papered an open sale a

00:56:17,839 --> 00:56:22,319
sequel plus wrapper on top of opencl

00:56:20,160 --> 00:56:23,920
um it's it's it's a it's a great

00:56:22,319 --> 00:56:26,319
experiment sorry and

00:56:23,920 --> 00:56:28,160
using opencl and it's a great experiment

00:56:26,319 --> 00:56:30,720
um but we now know that

00:56:28,160 --> 00:56:32,400
as a way to get to stl interface so

00:56:30,720 --> 00:56:33,920
where sickle comes in is that sickle

00:56:32,400 --> 00:56:36,319
essentially is more of a

00:56:33,920 --> 00:56:37,520
not just a library it's also a language

00:56:36,319 --> 00:56:40,240
and it's a framework

00:56:37,520 --> 00:56:41,440
uh some part of the library that library

00:56:40,240 --> 00:56:45,280
calls the

00:56:41,440 --> 00:56:48,240
call graph um handler that you see

00:56:45,280 --> 00:56:49,920
in the in order slide is actually

00:56:48,240 --> 00:56:51,040
implemented using the clan front end in

00:56:49,920 --> 00:56:52,720
the front end itself

00:56:51,040 --> 00:56:54,720
so that gives us a much more control

00:56:52,720 --> 00:56:55,599
over how things are the philosophy is

00:56:54,720 --> 00:56:57,680
that

00:56:55,599 --> 00:56:59,440
sickle can be adapted for both as a

00:56:57,680 --> 00:57:00,640
single button all the way front end to

00:56:59,440 --> 00:57:03,200
back end compiler

00:57:00,640 --> 00:57:04,400
or it can be adapted as separate as a

00:57:03,200 --> 00:57:06,480
separate compilation

00:57:04,400 --> 00:57:07,839
uh that is more appropriate to things

00:57:06,480 --> 00:57:09,839
like um

00:57:07,839 --> 00:57:11,599
in open um like when you're doing

00:57:09,839 --> 00:57:13,440
graphics or or

00:57:11,599 --> 00:57:14,720
gpu programming or different kinds of

00:57:13,440 --> 00:57:17,520
device programming

00:57:14,720 --> 00:57:18,079
um like in uh accelera in autonomous

00:57:17,520 --> 00:57:20,480
driving

00:57:18,079 --> 00:57:21,760
where you might not see the the the you

00:57:20,480 --> 00:57:22,799
might have a separate compiler

00:57:21,760 --> 00:57:24,960
supplement policy

00:57:22,799 --> 00:57:26,799
compilation system between cpu code and

00:57:24,960 --> 00:57:27,359
the gpu code and they might be separated

00:57:26,799 --> 00:57:29,040
from

00:57:27,359 --> 00:57:30,799
for two three years before you find out

00:57:29,040 --> 00:57:32,160
what they are so in a way i hope that

00:57:30,799 --> 00:57:34,400
gives a reasonable

00:57:32,160 --> 00:57:36,079
um overview of not just how simple

00:57:34,400 --> 00:57:38,079
compared to nvidia's trust but how

00:57:36,079 --> 00:57:40,559
sickle lives within this whole framework

00:57:38,079 --> 00:57:42,000
of many many other frameworks that i've

00:57:40,559 --> 00:57:43,440
been researching and studying

00:57:42,000 --> 00:57:45,280
to make sure that all of them gives

00:57:43,440 --> 00:57:47,520
equal contribution contributions

00:57:45,280 --> 00:57:49,200
to isil squad and in the end i also

00:57:47,520 --> 00:57:50,160
might also mention the contributions of

00:57:49,200 --> 00:57:52,400
national labs

00:57:50,160 --> 00:57:54,880
like cocos and rajas which are also

00:57:52,400 --> 00:57:57,200
essentially library only frameworks

00:57:54,880 --> 00:57:59,200
okay but they are also they also build

00:57:57,200 --> 00:58:00,880
um buildings considering building sickle

00:57:59,200 --> 00:58:03,359
on top of the back end for the

00:58:00,880 --> 00:58:04,880
um for coco um in the high performance

00:58:03,359 --> 00:58:06,240
computing scheme

00:58:04,880 --> 00:58:08,240
so that was a long-winded question we

00:58:06,240 --> 00:58:11,200
got about half 30 seconds left

00:58:08,240 --> 00:58:13,040
um so next question is great would it be

00:58:11,200 --> 00:58:13,760
possibly integrate co-routine generators

00:58:13,040 --> 00:58:15,280
it's sicko

00:58:13,760 --> 00:58:17,119
i have no questions that that is the

00:58:15,280 --> 00:58:19,839
direction that we will be going

00:58:17,119 --> 00:58:21,280
um so i want to i want to quickly answer

00:58:19,839 --> 00:58:22,960
that there's that intention

00:58:21,280 --> 00:58:24,960
and then the next question after that

00:58:22,960 --> 00:58:26,880
says is there work on getting eigen

00:58:24,960 --> 00:58:28,240
matrix operations to use mexico i'm

00:58:26,880 --> 00:58:29,520
really glad you answered i'm really glad

00:58:28,240 --> 00:58:31,839
you answered that we've been working

00:58:29,520 --> 00:58:33,920
heavy on trying to get eigen matrix

00:58:31,839 --> 00:58:35,280
uh working in sickle and contributing

00:58:33,920 --> 00:58:36,799
some of the changes we need eigen and

00:58:35,280 --> 00:58:38,960
major to work

00:58:36,799 --> 00:58:41,119
uh with sikko uh right now they work

00:58:38,960 --> 00:58:43,119
with uh mostly cuda

00:58:41,119 --> 00:58:44,559
so contributing they'll change back to

00:58:43,119 --> 00:58:47,440
eigen okay

00:58:44,559 --> 00:58:49,520
as well as towards tensorflow so that is

00:58:47,440 --> 00:58:51,839
something that we are deeply

00:58:49,520 --> 00:58:52,559
have been involved in the last one the

00:58:51,839 --> 00:58:54,319
next one

00:58:52,559 --> 00:58:55,839
says okay we're really probably running

00:58:54,319 --> 00:58:59,359
out of time so

00:58:55,839 --> 00:59:01,599
i'm gonna probably um pick these copy

00:58:59,359 --> 00:59:02,960
i can answer them in a blog somewhere

00:59:01,599 --> 00:59:05,280
and then

00:59:02,960 --> 00:59:07,119
we also have uh after this we have the

00:59:05,280 --> 00:59:08,319
ask me anything which i think is in the

00:59:07,119 --> 00:59:10,799
break after this

00:59:08,319 --> 00:59:11,599
um i don't know if this will be in the

00:59:10,799 --> 00:59:14,319
same room

00:59:11,599 --> 00:59:15,200
um but uh we can we can always take note

00:59:14,319 --> 00:59:17,760
of the questions

00:59:15,200 --> 00:59:19,040
and we can follow up there as well yes

00:59:17,760 --> 00:59:20,480
i'm gonna copy these so that we don't

00:59:19,040 --> 00:59:21,599
lose them and then we're gonna try to

00:59:20,480 --> 00:59:22,960
close this session now

00:59:21,599 --> 00:59:25,200
thank you very much for attending you

00:59:22,960 --> 00:59:27,440
guys have been wonderful um keep coming

00:59:25,200 --> 00:59:29,040
and keep coming to cppcon it's a place

00:59:27,440 --> 00:59:30,799
to learn all about the best way to get

00:59:29,040 --> 00:59:31,119
heterogeneous computing in the same plus

00:59:30,799 --> 00:59:32,799
plot

00:59:31,119 --> 00:59:35,040
and i would say not just for sinkhole

00:59:32,799 --> 00:59:35,760
but for many other people like cuda like

00:59:35,040 --> 00:59:38,160
like

00:59:35,760 --> 00:59:40,240
like vocals and rajas and hpx as well

00:59:38,160 --> 00:59:47,839
too thanks cheers everybody bye-bye

00:59:40,240 --> 00:59:47,839
thanks everyone thanks bye

01:00:01,520 --> 01:00:03,599

YouTube URL: https://www.youtube.com/watch?v=fxCnpNVPazk


