Title: CppCon 2016: Chandler Carruth “High Performance Code 201: Hybrid Data Structures"
Publication date: 2016-10-01
Playlist: CppCon 2016
Description: 
	http://CppCon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/cppcon/cppcon2016
—
Modern programs’ performance characteristics are often dictated by their data. Whether the cache locality of data access, the size of working set, or avoiding costly memory allocation overhead. Unfortunately, the standard C++ library data structures range from adequate to terrible at controlling these aspects, and they don’t provide any of the core mechanisms needed for extremely efficient data structure design.

This talk will present the core concepts of designing high performance data structures in C++. It is based on years of experience in the LLVM compiler as well as several other large code bases. From these principles, the talk will propose a suite of data structures that provide performance without loss of generality or functionality. As much as this talk will present specific data structure designs, its primary intent will be to give an understanding of what makes these structures have greater performance than more naive approaches.
— 
Chandler Carruth
Google
C++ Lead
San Francisco Bay Area
Chandler Carruth leads the Clang team at Google, building better diagnostics, tools, and more. Previously, he worked on several pieces of Google’s distributed build system. He makes guest appearances helping to maintain a few core C++ libraries across Google’s codebase, and is active in the LLVM and Clang open source communities. He received his M.S. and B.S. in Computer Science from Wake Forest University, but disavows all knowledge of the contents of his Master’s thesis. He is regularly found drinking Cherry Coke Zero in the daytime and pontificating over a single malt scotch in the evening.
—
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,000 --> 00:00:04,759
all right so my name is Chandler Carruth

00:00:02,429 --> 00:00:07,740
I'm up here to talk to you about

00:00:04,759 --> 00:00:09,840
high-performance code how many folks are

00:00:07,740 --> 00:00:13,230
here at CB peak on for their very first

00:00:09,840 --> 00:00:15,420
time whoo oh my goodness has a lot of

00:00:13,230 --> 00:00:18,090
people okay so how many folks have seen

00:00:15,420 --> 00:00:21,869
the the talk from two years ago on

00:00:18,090 --> 00:00:23,070
YouTube okay okay that's that's better

00:00:21,869 --> 00:00:24,630
because I'm not going to repeat that

00:00:23,070 --> 00:00:27,480
talk so this is kind of the second of a

00:00:24,630 --> 00:00:29,369
series right the idea is that the first

00:00:27,480 --> 00:00:31,920
time I talked a lot about kind of things

00:00:29,369 --> 00:00:33,450
that really limit high performance code

00:00:31,920 --> 00:00:35,070
kind of patterns you want to develop

00:00:33,450 --> 00:00:37,290
fundamental things you want to do over

00:00:35,070 --> 00:00:40,410
and over again but I felt bad about that

00:00:37,290 --> 00:00:42,420
top for one reason uh one reason was it

00:00:40,410 --> 00:00:43,800
was very negative right like it wasn't

00:00:42,420 --> 00:00:45,059
actually a very constructive talk I

00:00:43,800 --> 00:00:47,489
didn't tell you guys a lot of things you

00:00:45,059 --> 00:00:49,200
can do and you should do or kind of new

00:00:47,489 --> 00:00:51,510
exciting tools to try and help you out

00:00:49,200 --> 00:00:52,860
writing really fast code so this talk is

00:00:51,510 --> 00:00:54,180
going to try and be a little bit more a

00:00:52,860 --> 00:00:55,530
little bit more upbeat it's going to try

00:00:54,180 --> 00:00:56,670
and help you guys out a little bit more

00:00:55,530 --> 00:00:59,520
we're going to try and actually go

00:00:56,670 --> 00:01:01,920
through and describe some hybrid data

00:00:59,520 --> 00:01:03,660
structures that are going to hopefully

00:01:01,920 --> 00:01:06,930
be very useful for you in writing really

00:01:03,660 --> 00:01:08,310
fast code I just as a little bit of

00:01:06,930 --> 00:01:11,369
background if folks don't know I work at

00:01:08,310 --> 00:01:12,810
Google I work on the LLVM compiler and

00:01:11,369 --> 00:01:16,380
in particular I'm actually going to be

00:01:12,810 --> 00:01:18,900
talking today about lVN's internal data

00:01:16,380 --> 00:01:20,490
structures I turns out that LVM is a

00:01:18,900 --> 00:01:22,770
great example of kind of like really

00:01:20,490 --> 00:01:24,990
high performance code because you have a

00:01:22,770 --> 00:01:27,270
bunch of compiler nerds and I mean a

00:01:24,990 --> 00:01:29,130
bunch of really really kind of bad level

00:01:27,270 --> 00:01:31,590
of compiler nerds all of them

00:01:29,130 --> 00:01:33,420
performance nuts I might be a good

00:01:31,590 --> 00:01:34,890
example of this and and and they're all

00:01:33,420 --> 00:01:36,810
working on this compiler and we actually

00:01:34,890 --> 00:01:39,810
care a lot that the compiler itself is

00:01:36,810 --> 00:01:41,070
very fast right and and you know we're

00:01:39,810 --> 00:01:42,270
all thinking about kind of modern

00:01:41,070 --> 00:01:44,549
computer architectures and the

00:01:42,270 --> 00:01:47,159
challenges that face that we face when

00:01:44,549 --> 00:01:49,259
we try and make compilers run really

00:01:47,159 --> 00:01:50,700
fast and so we end up writing a bunch of

00:01:49,259 --> 00:01:52,049
great data structures writing a bunch of

00:01:50,700 --> 00:01:54,750
algorithms and spending a lot of time

00:01:52,049 --> 00:01:56,640
really tuning examining things to try

00:01:54,750 --> 00:01:58,530
and get the absolute best performance

00:01:56,640 --> 00:02:00,750
out of this so I actually think this is

00:01:58,530 --> 00:02:03,710
a great place to kind of figure out

00:02:00,750 --> 00:02:07,290
about high performance data structures

00:02:03,710 --> 00:02:09,060
so this talk is going I'm going to give

00:02:07,290 --> 00:02:10,170
away all the secrets of this talk before

00:02:09,060 --> 00:02:11,489
we even get into it just so you know

00:02:10,170 --> 00:02:13,920
there's no there's there's nothing

00:02:11,489 --> 00:02:17,130
nothing up my sleeve here all right so

00:02:13,920 --> 00:02:19,380
Ector sets and maps that's it that's all

00:02:17,130 --> 00:02:21,959
we're going to talk about whole hour but

00:02:19,380 --> 00:02:23,610
it's going to be awesome okay so the

00:02:21,959 --> 00:02:25,709
very first data structure is of course a

00:02:23,610 --> 00:02:28,020
vector okay so this is what L viens

00:02:25,709 --> 00:02:30,180
vector kind of looks like now I could

00:02:28,020 --> 00:02:32,700
have shown you the real code from LLVM

00:02:30,180 --> 00:02:33,959
but if I had like you would all have to

00:02:32,700 --> 00:02:35,850
be standing up here in front of the

00:02:33,959 --> 00:02:37,530
screen and squinting really hard and it

00:02:35,850 --> 00:02:39,989
would be really confusing so I've kind

00:02:37,530 --> 00:02:42,600
of distilled all of this down to the

00:02:39,989 --> 00:02:45,180
bare essentials to kind of communicate

00:02:42,600 --> 00:02:49,019
the essence of how LLVM is making these

00:02:45,180 --> 00:02:51,209
data structures fast so this is a pretty

00:02:49,019 --> 00:02:54,390
pretty straightforward small sized

00:02:51,209 --> 00:02:56,250
optimized vector that's that's the key

00:02:54,390 --> 00:02:57,840
idea it's a small size optimized vector

00:02:56,250 --> 00:02:59,670
now that doesn't mean that we expect all

00:02:57,840 --> 00:03:01,680
of the vectors in the entire compiler to

00:02:59,670 --> 00:03:04,230
be small that's actually not the point

00:03:01,680 --> 00:03:06,209
the point is to save on the early small

00:03:04,230 --> 00:03:08,040
allocations because it turns out those

00:03:06,209 --> 00:03:10,110
end up being a really large component of

00:03:08,040 --> 00:03:11,910
the cost of vectors and by doing a small

00:03:10,110 --> 00:03:13,860
size optimization we don't have to

00:03:11,910 --> 00:03:15,930
allocate those on the FreeStore we can

00:03:13,860 --> 00:03:17,819
very quickly use an internal buffer for

00:03:15,930 --> 00:03:19,560
those and we only actually reach out to

00:03:17,819 --> 00:03:21,450
the heap for allocations who were

00:03:19,560 --> 00:03:25,890
growing when we're growing to some some

00:03:21,450 --> 00:03:27,450
substantial size this is this is easily

00:03:25,890 --> 00:03:28,799
the most fundamental data structure that

00:03:27,450 --> 00:03:30,570
we use in the entire compiler when I

00:03:28,799 --> 00:03:31,680
when I get up and I talk about how no no

00:03:30,570 --> 00:03:33,989
vectors all you need

00:03:31,680 --> 00:03:36,359
like really I live and breathe that

00:03:33,989 --> 00:03:38,250
advice okay we use this thing for cues

00:03:36,359 --> 00:03:40,680
for work lists for stacks

00:03:38,250 --> 00:03:42,329
every single kind of basic operation you

00:03:40,680 --> 00:03:44,160
would imagine everything down to and

00:03:42,329 --> 00:03:45,870
including binary heaps and priority

00:03:44,160 --> 00:03:49,680
queues all of them are built on top of

00:03:45,870 --> 00:03:51,510
the back of a small vector in LLVM now I

00:03:49,680 --> 00:03:53,430
get a lot of kind of kind of immediate

00:03:51,510 --> 00:03:55,890
responses of why on earth don't you just

00:03:53,430 --> 00:03:57,510
use two vector you said that data

00:03:55,890 --> 00:04:02,239
structure at least wasn't completely

00:03:57,510 --> 00:04:05,340
broken in the standard I'm sorry it is

00:04:02,239 --> 00:04:07,260
so so even stood vector has a really bad

00:04:05,340 --> 00:04:09,540
problem in the standard because in the

00:04:07,260 --> 00:04:12,060
standard we specified that the iterators

00:04:09,540 --> 00:04:14,790
are not invalidated if you move the

00:04:12,060 --> 00:04:16,739
vector from one location to another now

00:04:14,790 --> 00:04:18,989
this can be convenient at times but it

00:04:16,739 --> 00:04:20,549
has a real problem if you can't

00:04:18,989 --> 00:04:22,169
invalidate the iterators when you move

00:04:20,549 --> 00:04:24,960
from one location to another you can't

00:04:22,169 --> 00:04:26,700
do a small-size optimization you can't

00:04:24,960 --> 00:04:27,780
do it at all it's completely off the

00:04:26,700 --> 00:04:29,250
table

00:04:27,780 --> 00:04:31,080
I think this is this is terrible right

00:04:29,250 --> 00:04:32,160
small size optimizations are a huge win

00:04:31,080 --> 00:04:34,639
they're huge enough win that the

00:04:32,160 --> 00:04:37,260
standard even uses them in the other

00:04:34,639 --> 00:04:39,720
vector in the standard that's spelled in

00:04:37,260 --> 00:04:41,730
a very awkward way of stood bass extreme

00:04:39,720 --> 00:04:44,550
I don't encourage you to write you know

00:04:41,730 --> 00:04:45,900
a custom care traits specialization just

00:04:44,550 --> 00:04:48,450
so that you can use stood basic string

00:04:45,900 --> 00:04:50,040
for your vector instead I think we

00:04:48,450 --> 00:04:52,770
actually need to have a small vector and

00:04:50,040 --> 00:04:54,630
that's what LLVM uses but we can do more

00:04:52,770 --> 00:04:57,270
interesting things than just small size

00:04:54,630 --> 00:05:00,150
optimizations so elegans vector has this

00:04:57,270 --> 00:05:02,490
kind of weird trick that it uses so so

00:05:00,150 --> 00:05:05,340
we kind of take on the left-hand side a

00:05:02,490 --> 00:05:07,919
lot of the guts of the small vector out

00:05:05,340 --> 00:05:10,500
okay and we just leave that small size

00:05:07,919 --> 00:05:12,810
optimized buffer okay

00:05:10,500 --> 00:05:15,180
then on the right hand side we have a

00:05:12,810 --> 00:05:16,320
base class and this base class is

00:05:15,180 --> 00:05:19,650
interesting because it looks exactly

00:05:16,320 --> 00:05:21,630
like a vector nothing fancy here this is

00:05:19,650 --> 00:05:23,190
just a vector it has all of the

00:05:21,630 --> 00:05:25,530
operations that you would expect to have

00:05:23,190 --> 00:05:27,960
on a vector it just doesn't have this

00:05:25,530 --> 00:05:29,250
the buffer and we pass the buffer in

00:05:27,960 --> 00:05:31,260
dynamically through the constructor

00:05:29,250 --> 00:05:33,870
right this is actually a really simple

00:05:31,260 --> 00:05:36,630
pattern but this is powerful because now

00:05:33,870 --> 00:05:39,030
in our interface boundaries whenever we

00:05:36,630 --> 00:05:41,040
want to have an output parameter or an

00:05:39,030 --> 00:05:43,729
input and output parameter that's a

00:05:41,040 --> 00:05:47,160
small vector we can actually type erase

00:05:43,729 --> 00:05:49,380
the size we can remove the size from the

00:05:47,160 --> 00:05:51,270
type completely and we don't pay any

00:05:49,380 --> 00:05:53,669
overhead we don't pay any abstraction

00:05:51,270 --> 00:05:56,039
boundaries right we don't have any cost

00:05:53,669 --> 00:05:58,620
to it we actually just have this nice

00:05:56,039 --> 00:06:00,720
slicing right across the type boundary

00:05:58,620 --> 00:06:02,430
this is really really powerful so all of

00:06:00,720 --> 00:06:04,380
our interfaces into carrying small

00:06:02,430 --> 00:06:06,539
vectors without baking in a particular

00:06:04,380 --> 00:06:08,910
size this even lets us do crazy things

00:06:06,539 --> 00:06:11,370
like have different callers to the same

00:06:08,910 --> 00:06:13,530
routine select different small buffer

00:06:11,370 --> 00:06:16,500
sizes based on their use case based on

00:06:13,530 --> 00:06:18,090
on their expected workload which again

00:06:16,500 --> 00:06:20,700
is a really powerful way to have hybrid

00:06:18,090 --> 00:06:22,560
data structures that adapt that fit the

00:06:20,700 --> 00:06:24,390
problem you actually have rather than

00:06:22,560 --> 00:06:28,560
being you know baked in stone in one

00:06:24,390 --> 00:06:31,229
particular design okay so that was

00:06:28,560 --> 00:06:34,500
vector now we have to talk about sets

00:06:31,229 --> 00:06:36,930
okay so the set it's actually the same

00:06:34,500 --> 00:06:38,909
thing all right this is a really

00:06:36,930 --> 00:06:41,039
unoriginal talk I'm sorry for that so

00:06:38,909 --> 00:06:41,840
the set is also just a small size

00:06:41,039 --> 00:06:44,460
optimized

00:06:41,840 --> 00:06:47,640
but but we aren't doing the set the same

00:06:44,460 --> 00:06:48,900
way that stood unordered set works for

00:06:47,640 --> 00:06:51,000
example okay

00:06:48,900 --> 00:06:53,940
we're instead using open addressing here

00:06:51,000 --> 00:06:56,400
we just have an array of buckets flat in

00:06:53,940 --> 00:06:57,870
memory we use quadratic probing I didn't

00:06:56,400 --> 00:06:59,340
want to write quadratic probing up here

00:06:57,870 --> 00:07:01,830
on the slide because it's really boring

00:06:59,340 --> 00:07:03,300
and it's really gross right but it's a

00:07:01,830 --> 00:07:05,130
very straightforward approach right you

00:07:03,300 --> 00:07:07,500
you just probe a flat array of buckets

00:07:05,130 --> 00:07:09,150
nothing to it and when you have a small

00:07:07,500 --> 00:07:10,830
size optimization you can even save on

00:07:09,150 --> 00:07:12,780
the allocation you have an inline buffer

00:07:10,830 --> 00:07:16,320
that you get to start off your bucket

00:07:12,780 --> 00:07:17,670
array with okay really really

00:07:16,320 --> 00:07:19,590
straightforward thing now the last thing

00:07:17,670 --> 00:07:21,660
you're going to see on this bottom is is

00:07:19,590 --> 00:07:25,140
that we have a traits object we actually

00:07:21,660 --> 00:07:27,000
put all of our hashing hash table traits

00:07:25,140 --> 00:07:28,980
into a single traits object instead of

00:07:27,000 --> 00:07:31,800
having to wait on order map does and I

00:07:28,980 --> 00:07:33,030
know reset does and it has you know the

00:07:31,800 --> 00:07:35,340
kind of expected things you can get a

00:07:33,030 --> 00:07:36,870
hash right you can you actually hash the

00:07:35,340 --> 00:07:38,280
value you can also compare things

00:07:36,870 --> 00:07:40,320
because we want to have the ability to

00:07:38,280 --> 00:07:41,730
compare things in a customized way but

00:07:40,320 --> 00:07:43,620
we also have two other routines you can

00:07:41,730 --> 00:07:46,110
get an empty value and you can get a

00:07:43,620 --> 00:07:49,140
tombstone value and this is actually

00:07:46,110 --> 00:07:52,290
what allows a very simple approach to to

00:07:49,140 --> 00:07:54,300
a flat quadratically probed hash table

00:07:52,290 --> 00:07:56,460
to work we need to be able to create

00:07:54,300 --> 00:07:58,860
this bucket array right and populate it

00:07:56,460 --> 00:08:00,390
with empty keys and we need to know that

00:07:58,860 --> 00:08:02,940
they're empty so that we know we can put

00:08:00,390 --> 00:08:05,730
new entries into them and if we start

00:08:02,940 --> 00:08:08,040
probing and then start erasing we're

00:08:05,730 --> 00:08:09,780
going to leave we need to leave markers

00:08:08,040 --> 00:08:12,810
behind so we understand that there are

00:08:09,780 --> 00:08:14,640
actually are values along a probing path

00:08:12,810 --> 00:08:16,500
right and you have to keep probing it's

00:08:14,640 --> 00:08:19,530
not just an empty slot these tombstones

00:08:16,500 --> 00:08:23,220
for that this does require your types to

00:08:19,530 --> 00:08:24,870
expose to kind of you know fake values

00:08:23,220 --> 00:08:27,150
that you can identify it's really

00:08:24,870 --> 00:08:30,150
important but most of our types we can

00:08:27,150 --> 00:08:32,180
do this with that's it this is all the

00:08:30,150 --> 00:08:34,410
the logic that goes into us having a set

00:08:32,180 --> 00:08:36,810
and you can imagine then what the map

00:08:34,410 --> 00:08:39,000
looks like the mat just generalizes this

00:08:36,810 --> 00:08:41,370
to a key and of value right we still use

00:08:39,000 --> 00:08:43,680
the same traits right but it's focused

00:08:41,370 --> 00:08:45,330
on the key we actually have to

00:08:43,680 --> 00:08:46,890
re-implement some things because we want

00:08:45,330 --> 00:08:49,590
to be we want to be fairly careful about

00:08:46,890 --> 00:08:51,890
the value here one thing that LLVM tries

00:08:49,590 --> 00:08:54,390
very hard to do is that for empty

00:08:51,890 --> 00:08:55,200
buckets and for tombstone buckets we

00:08:54,390 --> 00:08:57,750
don't put a

00:08:55,200 --> 00:09:00,450
we pair into those buckets we actually

00:08:57,750 --> 00:09:02,640
just put the key into them so that the

00:09:00,450 --> 00:09:05,040
value in the pair doesn't actually have

00:09:02,640 --> 00:09:07,800
to have these these special States in it

00:09:05,040 --> 00:09:10,080
and that requires some special code it's

00:09:07,800 --> 00:09:12,480
not - not too fancy and of course we

00:09:10,080 --> 00:09:14,910
layer a small size optimization on top

00:09:12,480 --> 00:09:19,050
of all of this all right

00:09:14,910 --> 00:09:22,010
that's so so that's the talk

00:09:19,050 --> 00:09:25,140
ten minutes what do you think right okay

00:09:22,010 --> 00:09:26,880
so so there are a few other things we

00:09:25,140 --> 00:09:28,980
should probably discuss before we call

00:09:26,880 --> 00:09:31,350
it quits on this though okay that but

00:09:28,980 --> 00:09:33,120
this I do want to emphasize that is the

00:09:31,350 --> 00:09:34,770
core foundations of all the data

00:09:33,120 --> 00:09:37,050
structures that we use throughout the

00:09:34,770 --> 00:09:39,000
entirety of LLVM compiler okay almost

00:09:37,050 --> 00:09:41,520
everything else you see that's really

00:09:39,000 --> 00:09:43,500
interesting is a very domain-specific

00:09:41,520 --> 00:09:45,030
data structure it's one that we've

00:09:43,500 --> 00:09:46,830
crafted to solve a particular problem

00:09:45,030 --> 00:09:49,290
with a very particular set of

00:09:46,830 --> 00:09:51,900
constraints other data structures you

00:09:49,290 --> 00:09:54,390
see tend to be abstractions around

00:09:51,900 --> 00:09:56,070
domain-specific problems they don't tend

00:09:54,390 --> 00:09:58,770
to be fully general they tend to have

00:09:56,070 --> 00:10:02,340
really particular use cases the the

00:09:58,770 --> 00:10:04,850
general purpose tools we use like 99% of

00:10:02,340 --> 00:10:07,110
the time are just these three tools okay

00:10:04,850 --> 00:10:08,730
also if you're like looking the ldm

00:10:07,110 --> 00:10:11,130
codebase live by the way they're all

00:10:08,730 --> 00:10:13,560
spelled differently and like they are

00:10:11,130 --> 00:10:15,510
they suffer from over a decade of kind

00:10:13,560 --> 00:10:16,980
of organic growth I've cleaned a lot of

00:10:15,510 --> 00:10:20,160
this up to try and just present the core

00:10:16,980 --> 00:10:21,690
ideas here in a way you can get but we

00:10:20,160 --> 00:10:24,870
should at least talk about one thing

00:10:21,690 --> 00:10:28,020
before we get out of here um some people

00:10:24,870 --> 00:10:30,180
get really grumpy about these these

00:10:28,020 --> 00:10:31,320
small size optimized containers and when

00:10:30,180 --> 00:10:33,630
I say some people need at least one

00:10:31,320 --> 00:10:36,150
person in the audience because they tell

00:10:33,630 --> 00:10:38,130
me over and over again I should be using

00:10:36,150 --> 00:10:42,780
an alligator for this I don't need to

00:10:38,130 --> 00:10:44,010
build yet another container so I want to

00:10:42,780 --> 00:10:47,400
actually talk about this so we

00:10:44,010 --> 00:10:49,920
understand why LLVM continues to

00:10:47,400 --> 00:10:53,610
actually use custom containers rather

00:10:49,920 --> 00:10:55,710
than alligators uh it's it's interesting

00:10:53,610 --> 00:10:57,930
right so alligators seem like they

00:10:55,710 --> 00:11:00,660
should work so this is this is lifted

00:10:57,930 --> 00:11:03,000
directly from Howard Henin's suggestion

00:11:00,660 --> 00:11:05,190
to the LLVM community that they should

00:11:03,000 --> 00:11:07,770
stop writing custom containers and use

00:11:05,190 --> 00:11:08,790
alligators and he proposed this version

00:11:07,770 --> 00:11:11,310
of small vector

00:11:08,790 --> 00:11:13,110
which relies on a short alec allocator

00:11:11,310 --> 00:11:14,430
that has a lot of code in it because

00:11:13,110 --> 00:11:16,200
alligators require a lot of boilerplate

00:11:14,430 --> 00:11:18,450
it's actually really simple though it

00:11:16,200 --> 00:11:20,160
just looks like it has a small buffer in

00:11:18,450 --> 00:11:21,450
it and it allows you to use that small

00:11:20,160 --> 00:11:23,460
buffer for the allocations and the

00:11:21,450 --> 00:11:25,500
vector and you construct things in this

00:11:23,460 --> 00:11:28,260
way and it works great okay

00:11:25,500 --> 00:11:30,720
this solution absolutely works but there

00:11:28,260 --> 00:11:34,590
are two limitations to it that really

00:11:30,720 --> 00:11:36,060
get a way of LLVM is usage patterns the

00:11:34,590 --> 00:11:38,000
first one comes when you when you start

00:11:36,060 --> 00:11:40,530
putting these on interface boundaries

00:11:38,000 --> 00:11:42,480
alright and this happens a lot we end up

00:11:40,530 --> 00:11:44,190
with a lot of small vectors on interface

00:11:42,480 --> 00:11:47,310
boundaries because they end up being a

00:11:44,190 --> 00:11:49,200
vocabulary container for us but I've got

00:11:47,310 --> 00:11:51,450
a bug in this code and I've got a bug in

00:11:49,200 --> 00:11:54,030
the code because I didn't remember to

00:11:51,450 --> 00:11:56,040
update the size parameter and I have to

00:11:54,030 --> 00:11:58,530
keep these things in sync across all the

00:11:56,040 --> 00:12:00,300
different callers they've also lost the

00:11:58,530 --> 00:12:03,000
ability to have kind of a customized

00:12:00,300 --> 00:12:05,220
size for different callers without the

00:12:03,000 --> 00:12:08,460
the function I'm calling knowing how to

00:12:05,220 --> 00:12:10,470
do that now I I don't know how to solve

00:12:08,460 --> 00:12:11,880
this with alligators today I mean Howard

00:12:10,470 --> 00:12:13,380
Howard may know how to solve this

00:12:11,880 --> 00:12:14,850
someone else may come up with a way to

00:12:13,380 --> 00:12:17,010
solve this but looking at it it seems

00:12:14,850 --> 00:12:20,030
really annoying to actually get this to

00:12:17,010 --> 00:12:22,920
work to get the kind of very low cost

00:12:20,030 --> 00:12:26,880
interface design that we have with a

00:12:22,920 --> 00:12:30,180
custom container here the second problem

00:12:26,880 --> 00:12:32,760
I have I think is more fundamental so

00:12:30,180 --> 00:12:34,890
one thing that we actually do again very

00:12:32,760 --> 00:12:36,810
often is we have small vectors in the

00:12:34,890 --> 00:12:39,240
return type and this actually works

00:12:36,810 --> 00:12:40,980
really well for us because people using

00:12:39,240 --> 00:12:42,510
auto now right throughout all teams code

00:12:40,980 --> 00:12:44,160
base we use auto and so we don't

00:12:42,510 --> 00:12:45,840
actually write the return types for

00:12:44,160 --> 00:12:47,310
these functions very often we don't have

00:12:45,840 --> 00:12:49,380
a lot of the actual small sizes

00:12:47,310 --> 00:12:51,180
scattered about the code base of LLVM

00:12:49,380 --> 00:12:54,480
right they just have auto you can update

00:12:51,180 --> 00:12:56,280
the the small size where we return it no

00:12:54,480 --> 00:12:59,400
problem at all it goes you know every

00:12:56,280 --> 00:13:01,440
single call site picks that up but if

00:12:59,400 --> 00:13:04,050
you do this with an alligator right we

00:13:01,440 --> 00:13:05,280
have a bug here right we're returning a

00:13:04,050 --> 00:13:08,430
vector that's allocated memory

00:13:05,280 --> 00:13:10,080
potentially on the stack okay and so

00:13:08,430 --> 00:13:13,380
this this can actually lead to subtle

00:13:10,080 --> 00:13:16,290
bugs and again maybe there is a way to

00:13:13,380 --> 00:13:18,450
to embed the small size alligator inside

00:13:16,290 --> 00:13:20,260
of the vector object but again it seems

00:13:18,450 --> 00:13:23,380
really challenging to me

00:13:20,260 --> 00:13:25,030
and having a custom container makes all

00:13:23,380 --> 00:13:27,130
these problems go away we get our value

00:13:25,030 --> 00:13:29,410
semantics back for this container and

00:13:27,130 --> 00:13:31,840
it's fairly easy for us to you know pin

00:13:29,410 --> 00:13:33,460
down the value semantics we want even

00:13:31,840 --> 00:13:35,680
when it's in a small size optimized

00:13:33,460 --> 00:13:37,180
State and that's important that's really

00:13:35,680 --> 00:13:46,560
really important to the usability of the

00:13:37,180 --> 00:13:48,670
API making sense okay silence so I've

00:13:46,560 --> 00:13:50,170
talked a whole bunch about small size

00:13:48,670 --> 00:13:53,980
optimization right and that's really the

00:13:50,170 --> 00:13:55,330
only kind of critical thing here but how

00:13:53,980 --> 00:13:58,510
do you actually get it to be effective

00:13:55,330 --> 00:14:01,480
right small size optimization works way

00:13:58,510 --> 00:14:04,480
better when your values are really small

00:14:01,480 --> 00:14:08,260
right when you have very high density to

00:14:04,480 --> 00:14:09,730
the values and so the bigger challenge

00:14:08,260 --> 00:14:12,040
in a lot of ways than coming up with a

00:14:09,730 --> 00:14:14,620
bunch of fancy data structures that use

00:14:12,040 --> 00:14:16,750
small size optimization that optimize

00:14:14,620 --> 00:14:18,550
for small values it's like how do we

00:14:16,750 --> 00:14:20,710
actually make things small enough to

00:14:18,550 --> 00:14:23,380
benefit from this so a bunch of LOV ends

00:14:20,710 --> 00:14:25,660
time is actually spent making its data

00:14:23,380 --> 00:14:28,210
its values especially the ones we put

00:14:25,660 --> 00:14:30,310
into the data structures as small as

00:14:28,210 --> 00:14:32,290
compact and as efficient as possible and

00:14:30,310 --> 00:14:33,490
and I'm going to try and show you some

00:14:32,290 --> 00:14:35,680
of the techniques for that because it

00:14:33,490 --> 00:14:37,450
turns out that's more important than

00:14:35,680 --> 00:14:39,940
having the containers the containers are

00:14:37,450 --> 00:14:43,620
easy using the containers and using them

00:14:39,940 --> 00:14:47,620
effectively tends to take a lot of work

00:14:43,620 --> 00:14:50,620
okay so the first key idea here is to

00:14:47,620 --> 00:14:52,540
give large objects address identity so

00:14:50,620 --> 00:14:54,130
what do I mean by address identity the

00:14:52,540 --> 00:14:55,600
first thing to think about is does your

00:14:54,130 --> 00:14:58,780
object have some intrinsic identity

00:14:55,600 --> 00:15:00,490
right is your object like fundamentally

00:14:58,780 --> 00:15:02,920
unique if you have two objects are they

00:15:00,490 --> 00:15:04,330
going to compare equal right it turns

00:15:02,920 --> 00:15:05,890
out for a lot of large objects

00:15:04,330 --> 00:15:07,030
especially that we work with in the

00:15:05,890 --> 00:15:09,430
compiler and that I've worked with at

00:15:07,030 --> 00:15:11,170
Google most of the large ones have

00:15:09,430 --> 00:15:14,410
identity there's something unique about

00:15:11,170 --> 00:15:16,480
that object okay and and that means that

00:15:14,410 --> 00:15:19,000
if we allocate it carefully we allocate

00:15:16,480 --> 00:15:22,000
it at a stable location we can actually

00:15:19,000 --> 00:15:24,880
borrow its address to represent that

00:15:22,000 --> 00:15:27,490
identity okay so we could just use the

00:15:24,880 --> 00:15:29,140
address the pointer as a stand-in for

00:15:27,490 --> 00:15:31,300
the identity of the object and all of a

00:15:29,140 --> 00:15:33,459
sudden we've taken the object which is

00:15:31,300 --> 00:15:36,189
quite large and we've made it

00:15:33,459 --> 00:15:38,470
a pointer which is very small I mean in

00:15:36,189 --> 00:15:40,990
the simplest tribulus case you have a

00:15:38,470 --> 00:15:42,879
little vector of unique pointers for a

00:15:40,990 --> 00:15:45,220
big object this seems like such a

00:15:42,879 --> 00:15:47,529
trivial use case this actually comes up

00:15:45,220 --> 00:15:50,050
all the time in real code okay you

00:15:47,529 --> 00:15:52,509
actually we do this in tons of places in

00:15:50,050 --> 00:15:54,850
ll geum's code and this gives us a few

00:15:52,509 --> 00:15:57,220
advantages right it gives us stable

00:15:54,850 --> 00:15:59,439
pointers to big object if we need to

00:15:57,220 --> 00:16:01,449
create a set or something else out of

00:15:59,439 --> 00:16:04,029
this we have stable addresses here

00:16:01,449 --> 00:16:06,879
they're not going to move around if big

00:16:04,029 --> 00:16:08,860
object is very expensive to move right

00:16:06,879 --> 00:16:10,749
resizing this vector is going to be a

00:16:08,860 --> 00:16:13,209
lot faster than if we put the big

00:16:10,749 --> 00:16:15,149
objects in place in the vector okay this

00:16:13,209 --> 00:16:18,429
can actually make things faster directly

00:16:15,149 --> 00:16:21,009
if big object isn't movable at all if it

00:16:18,429 --> 00:16:22,449
contains for example a mutex right then

00:16:21,009 --> 00:16:23,709
this can be essential because there's

00:16:22,449 --> 00:16:26,230
there's literally no other choice

00:16:23,709 --> 00:16:27,369
available to you now a lot of people

00:16:26,230 --> 00:16:29,170
look at this and they're like why don't

00:16:27,369 --> 00:16:31,240
you use a list this is what list was

00:16:29,170 --> 00:16:32,619
built for and you're not saving any in

00:16:31,240 --> 00:16:35,559
directions here right you've got a

00:16:32,619 --> 00:16:36,639
pointer already just use a list so there

00:16:35,559 --> 00:16:38,980
are two problems with that one though

00:16:36,639 --> 00:16:40,869
the first problem with the list is that

00:16:38,980 --> 00:16:42,879
a list doesn't have a pointer it has two

00:16:40,869 --> 00:16:44,860
pointers right and I don't want to pay

00:16:42,879 --> 00:16:47,379
for anything I don't have to I want I

00:16:44,860 --> 00:16:49,240
want this to be as lean as it can be now

00:16:47,379 --> 00:16:50,529
I could use for word list okay but

00:16:49,240 --> 00:16:52,389
fourth list comes with a lot of

00:16:50,529 --> 00:16:55,240
constraints all right it's very hard to

00:16:52,389 --> 00:16:56,259
mutate for word list but it is just one

00:16:55,240 --> 00:16:58,959
pointer so it would be the equivalent

00:16:56,259 --> 00:17:01,089
space here an interesting thing is that

00:16:58,959 --> 00:17:04,140
this will often be faster than for word

00:17:01,089 --> 00:17:06,819
list and for somewhat surprising reason

00:17:04,140 --> 00:17:08,350
so imagine you're walking this container

00:17:06,819 --> 00:17:09,490
if you're not iterating the container

00:17:08,350 --> 00:17:11,559
you don't care about the difference

00:17:09,490 --> 00:17:13,600
between list and vector but if you are

00:17:11,559 --> 00:17:14,949
iterating this container you're going to

00:17:13,600 --> 00:17:17,049
see an interesting difference between

00:17:14,949 --> 00:17:19,600
for word lists and a vector of unique

00:17:17,049 --> 00:17:21,699
pointers because as you're iterating

00:17:19,600 --> 00:17:23,199
you're going to be looking at one object

00:17:21,699 --> 00:17:25,209
and then in the next object and then the

00:17:23,199 --> 00:17:27,370
next object okay and you're probably

00:17:25,209 --> 00:17:29,380
doing this on a fairly modern processor

00:17:27,370 --> 00:17:31,690
okay modern CPU and that modern

00:17:29,380 --> 00:17:33,789
processor it's going to try and and

00:17:31,690 --> 00:17:35,559
speculate a lot of the operations you're

00:17:33,789 --> 00:17:37,840
doing ahead of time and so it's going to

00:17:35,559 --> 00:17:39,190
be doing things out of order one of the

00:17:37,840 --> 00:17:41,200
things that the processor is going to

00:17:39,190 --> 00:17:43,809
try very hard to do is to figure out

00:17:41,200 --> 00:17:46,040
what memory you're going to reference

00:17:43,809 --> 00:17:49,340
next okay

00:17:46,040 --> 00:17:51,380
that's really what it wants to know now

00:17:49,340 --> 00:17:53,720
if you write a loop over a small vector

00:17:51,380 --> 00:17:56,060
of unique pointers right you're going to

00:17:53,720 --> 00:17:58,460
be able to make that very clear to the

00:17:56,060 --> 00:18:00,800
processor because you have a loop index

00:17:58,460 --> 00:18:02,630
that's just an offset into this array

00:18:00,800 --> 00:18:05,960
essentially as far as the processor is

00:18:02,630 --> 00:18:08,600
concerned and each pointer in that array

00:18:05,960 --> 00:18:10,880
you lookyou load memory from and so each

00:18:08,600 --> 00:18:12,860
pointer in that array is memory that the

00:18:10,880 --> 00:18:15,680
processor needs to populate into its

00:18:12,860 --> 00:18:17,480
cache and actually make available what

00:18:15,680 --> 00:18:20,720
happens when you iterate a forward list

00:18:17,480 --> 00:18:24,140
though for a four it lists the next

00:18:20,720 --> 00:18:26,890
memory you're going to access you can't

00:18:24,140 --> 00:18:30,680
find without reading the current element

00:18:26,890 --> 00:18:33,230
okay so if you you know get a cache miss

00:18:30,680 --> 00:18:35,540
on the first element of yours forward

00:18:33,230 --> 00:18:38,000
list you also get a cache miss on

00:18:35,540 --> 00:18:40,220
finding the address of the next element

00:18:38,000 --> 00:18:43,370
okay and that's true the whole way down

00:18:40,220 --> 00:18:44,900
and and this kind of thing it makes a

00:18:43,370 --> 00:18:46,460
big difference when you add it all up

00:18:44,900 --> 00:18:48,200
and you do this all over the place in

00:18:46,460 --> 00:18:49,460
your code base so you want to think

00:18:48,200 --> 00:18:51,650
about these kinds of trade-offs when

00:18:49,460 --> 00:18:54,380
you're looking at data structures at the

00:18:51,650 --> 00:18:56,060
high end of performance but this isn't

00:18:54,380 --> 00:18:59,680
enough okay even even this still isn't

00:18:56,060 --> 00:19:03,110
enough in a lot of cases we're paying a

00:18:59,680 --> 00:19:04,280
pointers worth of overhead here we may

00:19:03,110 --> 00:19:06,110
not want to do that we don't want to

00:19:04,280 --> 00:19:07,820
keep this vector around we may

00:19:06,110 --> 00:19:09,980
accidentally end up with a very large

00:19:07,820 --> 00:19:12,050
vector that's only about you know 60%

00:19:09,980 --> 00:19:13,700
full that may be problematic for some

00:19:12,050 --> 00:19:15,950
reason we have some other techniques

00:19:13,700 --> 00:19:17,720
that we use as well but probably the

00:19:15,950 --> 00:19:19,460
biggest reason to not like this

00:19:17,720 --> 00:19:21,560
technique is that it doesn't give you

00:19:19,460 --> 00:19:23,960
any locality for these large objects

00:19:21,560 --> 00:19:25,460
right there just allocated wherever your

00:19:23,960 --> 00:19:28,880
memory allocator sees fit

00:19:25,460 --> 00:19:32,450
there's no locality at all so LVM uses

00:19:28,880 --> 00:19:34,190
this really horrible piece of code which

00:19:32,450 --> 00:19:36,710
I've actually simplified and made less

00:19:34,190 --> 00:19:38,720
horrible but it's still pretty bad um so

00:19:36,710 --> 00:19:41,330
this is it's like hacked up variant of

00:19:38,720 --> 00:19:43,280
allocators which is a terrible API I'm

00:19:41,330 --> 00:19:45,890
not endorsing the API here at all but

00:19:43,280 --> 00:19:47,750
the idea of it is really useful what

00:19:45,890 --> 00:19:50,390
this does is it allocates chunks of

00:19:47,750 --> 00:19:51,740
memory okay and it allocates a large

00:19:50,390 --> 00:19:55,040
chunk at a time in this case a whole

00:19:51,740 --> 00:19:57,530
page at a time and it keeps those pages

00:19:55,040 --> 00:19:58,940
around and it just hands out regions of

00:19:57,530 --> 00:20:01,370
those pages to

00:19:58,940 --> 00:20:03,670
to users this is essentially the world's

00:20:01,370 --> 00:20:05,900
worst Malak implementation right

00:20:03,670 --> 00:20:08,060
seriously most valve consultations start

00:20:05,900 --> 00:20:11,540
something like this the nice thing about

00:20:08,060 --> 00:20:13,670
this is it's local so I can create one

00:20:11,540 --> 00:20:16,130
of these for my particular code path and

00:20:13,670 --> 00:20:19,010
I can carefully allocate large objects

00:20:16,130 --> 00:20:21,170
on one of these and force them to have

00:20:19,010 --> 00:20:22,910
strong locality okay

00:20:21,170 --> 00:20:24,350
and I will waste a lot of memory because

00:20:22,910 --> 00:20:26,210
I'm going to allocate an entire page

00:20:24,350 --> 00:20:27,980
ahead of time unless I allocate a large

00:20:26,210 --> 00:20:29,750
number of these this could be very

00:20:27,980 --> 00:20:32,450
wasteful but I can adopt a very

00:20:29,750 --> 00:20:33,740
simplistic model if I know that I'm

00:20:32,450 --> 00:20:35,360
going to allocate a lot of these and I

00:20:33,740 --> 00:20:37,280
know that I care about the locality I

00:20:35,360 --> 00:20:39,290
can kind of adopt this model eagerly

00:20:37,280 --> 00:20:42,020
whereas a malloc implementation has to

00:20:39,290 --> 00:20:43,820
make a lot of very hard trade-offs the

00:20:42,020 --> 00:20:45,170
big simplification here is that there

00:20:43,820 --> 00:20:46,580
are no trade-offs to make we're

00:20:45,170 --> 00:20:48,860
essentially letting you the programmer

00:20:46,580 --> 00:20:50,960
make the trade-offs instead this does

00:20:48,860 --> 00:20:53,840
slab allocation every time we run out of

00:20:50,960 --> 00:20:56,390
space we get a new page of memory we

00:20:53,840 --> 00:20:59,540
then carve it up it's really fast it's

00:20:56,390 --> 00:21:01,310
incredibly fast okay the amount of

00:20:59,540 --> 00:21:02,930
things that this saves that a malloc

00:21:01,310 --> 00:21:04,550
implementation has to do even though

00:21:02,930 --> 00:21:07,250
they look essentially the same under the

00:21:04,550 --> 00:21:10,130
hood is astonishing and this lets us get

00:21:07,250 --> 00:21:13,010
stable addresses and reasonably high

00:21:10,130 --> 00:21:14,900
locality for large objects okay and once

00:21:13,010 --> 00:21:16,340
we have that we're off to the races we

00:21:14,900 --> 00:21:18,560
can put those addresses into data

00:21:16,340 --> 00:21:20,540
structures and containers and we can use

00:21:18,560 --> 00:21:21,950
small size optimization and other very

00:21:20,540 --> 00:21:27,220
cache friendly techniques on those

00:21:21,950 --> 00:21:29,740
containers making sense hopefully okay

00:21:27,220 --> 00:21:32,870
we will keep going so sometimes even

00:21:29,740 --> 00:21:34,550
pointers are too large right

00:21:32,870 --> 00:21:36,560
sometimes point you just have too many

00:21:34,550 --> 00:21:38,330
pieces of data you actually need to pack

00:21:36,560 --> 00:21:40,550
things more densely when that's the case

00:21:38,330 --> 00:21:42,050
just use an index right we've just

00:21:40,550 --> 00:21:43,850
talked about having a vector of unique

00:21:42,050 --> 00:21:45,800
pointers if you if you have a small

00:21:43,850 --> 00:21:47,870
vector of unique pointers you can use a

00:21:45,800 --> 00:21:49,130
very small index into that and you can

00:21:47,870 --> 00:21:51,530
save a lot of memory that way there are

00:21:49,130 --> 00:21:53,990
a lot of ways to kind of force the size

00:21:51,530 --> 00:21:56,630
equation down and down and down until

00:21:53,990 --> 00:21:59,990
you actually have small enough pieces of

00:21:56,630 --> 00:22:02,720
data to work with okay so the next big

00:21:59,990 --> 00:22:05,210
ticket item here is to aggressively pack

00:22:02,720 --> 00:22:07,580
bits together and this is probably the

00:22:05,210 --> 00:22:11,600
most complicated thing to ldm does to

00:22:07,580 --> 00:22:13,190
make its object small well

00:22:11,600 --> 00:22:14,600
the first realization when you're

00:22:13,190 --> 00:22:17,420
figuring out how to pack bits together

00:22:14,600 --> 00:22:20,090
is we just spend a bunch of time turning

00:22:17,420 --> 00:22:21,500
everything into a pointer right I mean a

00:22:20,090 --> 00:22:24,140
whole bunch of effort turning everything

00:22:21,500 --> 00:22:25,970
into pointers you know gotten a few of

00:22:24,140 --> 00:22:28,390
them but fortunately our pointers are a

00:22:25,970 --> 00:22:30,440
bit different from the xkcd pointers in

00:22:28,390 --> 00:22:33,410
xkcd pointers have these really

00:22:30,440 --> 00:22:36,620
unfortunate last characters a C and E

00:22:33,410 --> 00:22:38,150
here I don't know why you use those our

00:22:36,620 --> 00:22:40,490
pointers look something a bit more like

00:22:38,150 --> 00:22:41,690
this and it's a consequence of looking a

00:22:40,490 --> 00:22:43,730
bit more like this there's an

00:22:41,690 --> 00:22:46,970
opportunity there are these four zeros

00:22:43,730 --> 00:22:49,790
in the pointer I love these four zeros

00:22:46,970 --> 00:22:51,740
there they're essential okay these four

00:22:49,790 --> 00:22:55,220
zeros are like the most valuable four

00:22:51,740 --> 00:22:58,090
zeros in my entire program LVM does

00:22:55,220 --> 00:23:00,680
everything in the low bits of a pointer

00:22:58,090 --> 00:23:02,870
so this is where we're going to get most

00:23:00,680 --> 00:23:05,810
of the wins for packing data into

00:23:02,870 --> 00:23:07,310
smaller and smaller sizes all right now

00:23:05,810 --> 00:23:09,350
now you see what I'm talking about when

00:23:07,310 --> 00:23:10,820
I say I have a lot of code all right so

00:23:09,350 --> 00:23:13,130
let's actually step through what this is

00:23:10,820 --> 00:23:15,410
doing the very first thing we need to do

00:23:13,130 --> 00:23:17,690
is we need to classify things that are

00:23:15,410 --> 00:23:20,210
pointer like what does it mean to be

00:23:17,690 --> 00:23:23,570
pointer like well it means that you can

00:23:20,210 --> 00:23:25,100
be converted to and from an integer with

00:23:23,570 --> 00:23:27,800
the same number of bits as a pointer

00:23:25,100 --> 00:23:30,050
that's that's what this you wait put RT

00:23:27,800 --> 00:23:31,970
get pointer thing is about I've only

00:23:30,050 --> 00:23:35,390
provided one direction because the slide

00:23:31,970 --> 00:23:38,030
is already too big okay it also means

00:23:35,390 --> 00:23:40,160
that we can look at you and figure out

00:23:38,030 --> 00:23:43,250
you know how many free bits there are

00:23:40,160 --> 00:23:44,660
inside of the object and this this is

00:23:43,250 --> 00:23:46,730
the kind of generic template it works

00:23:44,660 --> 00:23:49,040
for for pointers right we just look at

00:23:46,730 --> 00:23:51,110
the alignment of the object we you know

00:23:49,040 --> 00:23:52,820
take the log two of it I understand this

00:23:51,110 --> 00:23:54,230
doesn't compile right but you get the

00:23:52,820 --> 00:23:56,210
idea we take the alignment of the object

00:23:54,230 --> 00:23:58,310
take the log two we know how many zeros

00:23:56,210 --> 00:24:00,610
there are in the low bits right we can

00:23:58,310 --> 00:24:03,140
convert back and forth very trivially

00:24:00,610 --> 00:24:05,180
now we can build a data structure on top

00:24:03,140 --> 00:24:06,830
of this so this is this is one of the

00:24:05,180 --> 00:24:09,740
most hilarious data structures in LTM

00:24:06,830 --> 00:24:13,480
it's a pointer in pair and it's this and

00:24:09,740 --> 00:24:16,370
and it is the size of a pointer okay and

00:24:13,480 --> 00:24:18,110
so it contains it takes a pointer type

00:24:16,370 --> 00:24:19,640
right it takes the number of integer

00:24:18,110 --> 00:24:22,280
bits that you would like it takes an

00:24:19,640 --> 00:24:23,990
integer type umm and it takes this

00:24:22,280 --> 00:24:25,280
traits object that describes that

00:24:23,990 --> 00:24:26,660
pointer type

00:24:25,280 --> 00:24:28,970
you know we need to make sure that the

00:24:26,660 --> 00:24:30,560
integer bits like fit into the free bit

00:24:28,970 --> 00:24:32,780
to the pointer type but if everything

00:24:30,560 --> 00:24:34,520
fits right we can shift things around we

00:24:32,780 --> 00:24:37,120
can mask things in and out and we get to

00:24:34,520 --> 00:24:39,800
reuse these low bits it's pretty nice

00:24:37,120 --> 00:24:42,140
making sense everybody like this little

00:24:39,800 --> 00:24:44,690
little clever data structure there's so

00:24:42,140 --> 00:24:46,430
much more we can do with this the next

00:24:44,690 --> 00:24:48,200
thing we realized is right some of the

00:24:46,430 --> 00:24:50,900
time we we have indices instead of

00:24:48,200 --> 00:24:52,760
pointers but the indices they look kind

00:24:50,900 --> 00:24:55,130
of like pointers right they they're

00:24:52,760 --> 00:24:57,760
smaller usually they don't need all 64

00:24:55,130 --> 00:25:00,440
bits we want a way to store integers

00:24:57,760 --> 00:25:02,240
like they were pointers with a bunch of

00:25:00,440 --> 00:25:05,120
zero bits at the bottom where we aren't

00:25:02,240 --> 00:25:07,880
using the data and so we built this

00:25:05,120 --> 00:25:10,250
pointer embedded int type which takes an

00:25:07,880 --> 00:25:12,590
integer type and the number of bits that

00:25:10,250 --> 00:25:14,690
integer type needs and it stores that

00:25:12,590 --> 00:25:18,580
integer in the high bits of a pointer

00:25:14,690 --> 00:25:21,500
and leaves the rest of it zero and then

00:25:18,580 --> 00:25:24,170
we have the pointer of the traits class

00:25:21,500 --> 00:25:25,820
where we surface to other other users by

00:25:24,170 --> 00:25:29,240
the way we've got free bits in our

00:25:25,820 --> 00:25:31,160
object the low bits are all zeros and we

00:25:29,240 --> 00:25:34,280
tell them how to convert to and from the

00:25:31,160 --> 00:25:37,160
object right and this allows us to wire

00:25:34,280 --> 00:25:40,880
in integers as well as pointers into

00:25:37,160 --> 00:25:43,490
this pointer integer pair making some

00:25:40,880 --> 00:25:47,540
sense we can go a lot further though

00:25:43,490 --> 00:25:51,770
turns out a pointer integer pair is a

00:25:47,540 --> 00:25:54,320
pointer like type it has zeros that are

00:25:51,770 --> 00:25:56,210
free in the low bits we can surface this

00:25:54,320 --> 00:25:57,500
it's a fairly simple computation you

00:25:56,210 --> 00:25:59,300
take the free bits of the original

00:25:57,500 --> 00:26:01,550
pointer take off the integer bits you're

00:25:59,300 --> 00:26:03,890
going to use you have that many free

00:26:01,550 --> 00:26:06,140
bits left and so we can build nested

00:26:03,890 --> 00:26:08,570
pairs like this and we actually use this

00:26:06,140 --> 00:26:11,240
to kind of build up data structures all

00:26:08,570 --> 00:26:16,250
of which reside within a single pointers

00:26:11,240 --> 00:26:17,840
memory okay then we get to my favorite

00:26:16,250 --> 00:26:19,490
one of these there's a lot of code

00:26:17,840 --> 00:26:21,230
missing here I'm sorry but this is this

00:26:19,490 --> 00:26:21,680
is this is this is what kind of ties it

00:26:21,230 --> 00:26:26,510
all together

00:26:21,680 --> 00:26:29,120
we now have a pointer some type okay

00:26:26,510 --> 00:26:31,940
so I'll step through we start off by

00:26:29,120 --> 00:26:35,050
defining this kind of nonce class

00:26:31,940 --> 00:26:39,110
template all this does is bundle a

00:26:35,050 --> 00:26:43,220
particular in value a particular

00:26:39,110 --> 00:26:46,210
Poynter to like type and a traits class

00:26:43,220 --> 00:26:50,860
for that pointer like type okay

00:26:46,210 --> 00:26:53,570
now the N value has to be a particular

00:26:50,860 --> 00:26:55,220
value to discriminate one pointer type

00:26:53,570 --> 00:26:58,010
from another pointer type so you can't

00:26:55,220 --> 00:26:59,990
you can't have these things overlap we

00:26:58,010 --> 00:27:02,330
then build up this pointer some type

00:26:59,990 --> 00:27:04,670
class template okay and we we

00:27:02,330 --> 00:27:06,950
parameterize it with some number of

00:27:04,670 --> 00:27:08,620
member types here but they're actually

00:27:06,950 --> 00:27:11,630
member templates they're actually

00:27:08,620 --> 00:27:14,270
instantiation zuv this pointer some type

00:27:11,630 --> 00:27:16,580
member okay and so each one of them

00:27:14,270 --> 00:27:19,460
Associates a particular value with a

00:27:16,580 --> 00:27:21,710
particular pointer like type we also

00:27:19,460 --> 00:27:25,240
give it a tag type which has to be some

00:27:21,710 --> 00:27:27,980
integer like type usually an enum and

00:27:25,240 --> 00:27:30,080
what we do is we store the tag type

00:27:27,980 --> 00:27:34,370
value in the low bits of the pointer and

00:27:30,080 --> 00:27:36,169
we then use the tag values to make a

00:27:34,370 --> 00:27:38,030
nice discriminated union between these

00:27:36,169 --> 00:27:40,669
different things right it's it's variant

00:27:38,030 --> 00:27:42,500
but with a lot of time spent packing

00:27:40,669 --> 00:27:44,570
bits into smaller and smaller sizes and

00:27:42,500 --> 00:27:48,620
not a lot of time spent on really fancy

00:27:44,570 --> 00:27:49,790
api's or exception safety um didn't need

00:27:48,620 --> 00:27:51,500
them they're just pointers right they're

00:27:49,790 --> 00:27:54,590
all they're all very small little

00:27:51,500 --> 00:27:56,330
objects and we have nice little helper

00:27:54,590 --> 00:27:58,640
methods right we can get the tag value

00:27:56,330 --> 00:28:01,010
out of this we can test whether a

00:27:58,640 --> 00:28:03,290
pointer subtype is a particular pointer

00:28:01,010 --> 00:28:05,059
type if we can we can do a get which

00:28:03,290 --> 00:28:07,250
will try to get a particular pointer

00:28:05,059 --> 00:28:09,950
type out and it'll give us a nice mel

00:28:07,250 --> 00:28:12,290
representation if it's if the the tag is

00:28:09,950 --> 00:28:13,970
set to a different value so we can write

00:28:12,290 --> 00:28:16,070
little you know pattern matching like

00:28:13,970 --> 00:28:18,890
libraries on top of this and we have

00:28:16,070 --> 00:28:22,700
just gobs of this all over LLVM is code

00:28:18,890 --> 00:28:25,280
base okay everybody following this

00:28:22,700 --> 00:28:30,860
pointer like this pointer some type

00:28:25,280 --> 00:28:33,610
craziness okay so then we can use this

00:28:30,860 --> 00:28:36,650
to build one of my favorite all-time

00:28:33,610 --> 00:28:40,400
hybrid data structures this is called a

00:28:36,650 --> 00:28:43,370
tiny pointer vector and this too is a

00:28:40,400 --> 00:28:45,500
pointer like type okay so how does this

00:28:43,370 --> 00:28:47,450
work what we do is we have an enum which

00:28:45,500 --> 00:28:50,270
describes two states for the vector to

00:28:47,450 --> 00:28:51,770
be in one of them is an inline state

00:28:50,270 --> 00:28:53,059
this actually has small size

00:28:51,770 --> 00:28:54,829
optimization built in

00:28:53,059 --> 00:28:57,319
one of them is an inline state the other

00:28:54,829 --> 00:28:59,299
one is a vector state okay

00:28:57,319 --> 00:29:01,279
and tiny reporter vector right it has a

00:28:59,299 --> 00:29:03,619
type so so we know that and then we

00:29:01,279 --> 00:29:06,819
build up this some type here okay and

00:29:03,619 --> 00:29:10,999
the some type uses this enum to

00:29:06,819 --> 00:29:13,069
discriminate between either a pointer

00:29:10,999 --> 00:29:16,759
type which is T in this case which is

00:29:13,069 --> 00:29:18,979
stored in line or a vector a pointer to

00:29:16,759 --> 00:29:20,809
a vector right a unique pointer to a

00:29:18,979 --> 00:29:24,259
whole vector we've allocated somewhere

00:29:20,809 --> 00:29:27,079
on the heap and then we have just that

00:29:24,259 --> 00:29:28,609
some type as the value and and we can

00:29:27,079 --> 00:29:30,019
write I've written out just you know

00:29:28,609 --> 00:29:31,339
operator square bracket to kind of give

00:29:30,019 --> 00:29:34,069
you a feel for what this ends up looking

00:29:31,339 --> 00:29:36,199
like right we go in we check whether we

00:29:34,069 --> 00:29:37,639
are in the inline State right if we are

00:29:36,199 --> 00:29:38,899
in the inline state we don't really need

00:29:37,639 --> 00:29:41,599
to know what the index is there's

00:29:38,899 --> 00:29:44,269
exactly one index available and we just

00:29:41,599 --> 00:29:46,699
give you that pointer value directly no

00:29:44,269 --> 00:29:48,769
heap allocations nothing at all and if

00:29:46,699 --> 00:29:50,569
we're not in the inline State then we

00:29:48,769 --> 00:29:53,599
for down to an actual vector allocated

00:29:50,569 --> 00:30:04,069
on the heap the rest of the methods look

00:29:53,599 --> 00:30:06,829
exactly the same as this so the most

00:30:04,069 --> 00:30:09,619
useful place for this is when you need a

00:30:06,829 --> 00:30:11,599
multi map alright because it turns out

00:30:09,619 --> 00:30:13,249
we don't like multi maps we like we like

00:30:11,599 --> 00:30:15,979
those three things I presented earlier

00:30:13,249 --> 00:30:18,409
with like vectors sets and maps but it's

00:30:15,979 --> 00:30:21,259
really annoying to put an enormous small

00:30:18,409 --> 00:30:24,349
size optimized vector into the value of

00:30:21,259 --> 00:30:25,909
a small size optimized map you end up

00:30:24,349 --> 00:30:29,419
with something that is not very small or

00:30:25,909 --> 00:30:32,889
fast or optimized but what we can do is

00:30:29,419 --> 00:30:36,859
we can if we happen to have pointer like

00:30:32,889 --> 00:30:40,519
value types we can put this tiny pointer

00:30:36,859 --> 00:30:43,339
vector into the value of agents map and

00:30:40,519 --> 00:30:45,529
it's only the size of a pointer and so

00:30:43,339 --> 00:30:47,809
this remains very compact very very

00:30:45,529 --> 00:30:50,119
small and in a lot of cases if you have

00:30:47,809 --> 00:30:51,799
only one right this will actually be

00:30:50,119 --> 00:30:54,139
just as fast as a pointer it won't use

00:30:51,799 --> 00:30:56,539
any extra memory but it will gracefully

00:30:54,139 --> 00:30:59,209
degrade allocate memory as necessary to

00:30:56,539 --> 00:31:01,489
handle larger and larger sizes and this

00:30:59,209 --> 00:31:03,169
turns out to be incredibly useful in

00:31:01,489 --> 00:31:04,879
LLVM there are a lot of cases where you

00:31:03,169 --> 00:31:06,290
have a multi map because you have to

00:31:04,879 --> 00:31:08,060
have the multi map

00:31:06,290 --> 00:31:11,090
you know the overwhelming majority of

00:31:08,060 --> 00:31:14,330
cases you have one value or zero values

00:31:11,090 --> 00:31:16,070
we can even address that here and I

00:31:14,330 --> 00:31:17,630
think this one in particular I would

00:31:16,070 --> 00:31:20,360
love to see someone implement this with

00:31:17,630 --> 00:31:22,600
an alligator and these would be really

00:31:20,360 --> 00:31:23,870
challenging to get with an alligator

00:31:22,600 --> 00:31:26,390
okay

00:31:23,870 --> 00:31:27,500
the last tip of course is use bit fields

00:31:26,390 --> 00:31:29,810
I have to tell you guys about this this

00:31:27,500 --> 00:31:31,400
is the classic way you do bit packing

00:31:29,810 --> 00:31:32,930
but I couldn't I couldn't not mention

00:31:31,400 --> 00:31:34,520
the other fundamental thing we do to

00:31:32,930 --> 00:31:38,210
reduce the size for objects in LLVM and

00:31:34,520 --> 00:31:40,790
clang okay so we've we've come up with

00:31:38,210 --> 00:31:42,860
this elaborate system of making things

00:31:40,790 --> 00:31:44,960
small and once you make everything very

00:31:42,860 --> 00:31:47,900
small we put them into these three data

00:31:44,960 --> 00:31:49,550
structures vector a set and a map the

00:31:47,900 --> 00:31:51,950
set and the map are these open

00:31:49,550 --> 00:31:54,680
addressing hash tables that we probe

00:31:51,950 --> 00:31:57,680
quadratically we're often using pointers

00:31:54,680 --> 00:32:00,650
as our as our identity so we have a real

00:31:57,680 --> 00:32:02,240
problem when we need ordering okay like

00:32:00,650 --> 00:32:04,070
a real problem I mean you shouldn't be

00:32:02,240 --> 00:32:07,010
relying on the ordering of some kind of

00:32:04,070 --> 00:32:09,290
hash table anyways it's a really bad

00:32:07,010 --> 00:32:10,970
idea we're trying to make it on non

00:32:09,290 --> 00:32:13,370
portable with the change the standard

00:32:10,970 --> 00:32:14,960
because it's such a bad idea but if you

00:32:13,370 --> 00:32:16,310
if you want to get worse you really

00:32:14,960 --> 00:32:18,140
really don't want to rely on the

00:32:16,310 --> 00:32:21,230
ordering of a hash table peed on a

00:32:18,140 --> 00:32:22,910
pointer because if you were on him with

00:32:21,230 --> 00:32:24,860
address space layout randomization you

00:32:22,910 --> 00:32:27,170
are going to have an extremely bad time

00:32:24,860 --> 00:32:28,820
it does not work well at all this is

00:32:27,170 --> 00:32:30,380
actually a common bug we have an LLVM

00:32:28,820 --> 00:32:32,390
because people people make this mistake

00:32:30,380 --> 00:32:35,930
so it's important to think about how you

00:32:32,390 --> 00:32:37,970
get ordering back when you need it of

00:32:35,930 --> 00:32:40,550
course if you have any possibility to

00:32:37,970 --> 00:32:42,860
sort a vector do so this is fantastic if

00:32:40,550 --> 00:32:44,750
you have some some fundamental ordering

00:32:42,860 --> 00:32:47,120
property you can simply assert over your

00:32:44,750 --> 00:32:49,910
data set you're home free you've got

00:32:47,120 --> 00:32:52,190
you've got a great solution but you

00:32:49,910 --> 00:32:54,260
don't always have this sometimes you do

00:32:52,190 --> 00:32:57,590
not have an intrinsic ordering to your

00:32:54,260 --> 00:32:59,720
data you have to find some other way of

00:32:57,590 --> 00:33:02,090
putting your data together and you still

00:32:59,720 --> 00:33:04,580
need it to be ordered this comes up a

00:33:02,090 --> 00:33:06,950
lot in compilers where we need to be

00:33:04,580 --> 00:33:08,840
deterministic in our behavior and we

00:33:06,950 --> 00:33:10,730
really have to be deterministic in our

00:33:08,840 --> 00:33:13,190
behavior we don't even care in many

00:33:10,730 --> 00:33:16,280
cases which ordering we use but we have

00:33:13,190 --> 00:33:17,810
to use an ordering and and this is this

00:33:16,280 --> 00:33:19,670
is a real challenge when you've built up

00:33:17,810 --> 00:33:22,070
all of your data structures around on

00:33:19,670 --> 00:33:25,180
containers okay and so we need some

00:33:22,070 --> 00:33:28,430
techniques here this gave rise to

00:33:25,180 --> 00:33:33,020
another data structure of course this is

00:33:28,430 --> 00:33:34,310
our set vector and it does exactly what

00:33:33,020 --> 00:33:36,380
we think this is this it's completely

00:33:34,310 --> 00:33:38,210
done I've actually like I've actually

00:33:36,380 --> 00:33:40,190
copied all of the important code here

00:33:38,210 --> 00:33:45,140
because all it does is it takes a vector

00:33:40,190 --> 00:33:47,510
and a set okay and when you insert into

00:33:45,140 --> 00:33:49,580
this thing it checks the set first and

00:33:47,510 --> 00:33:51,380
then puts it onto the vector and when

00:33:49,580 --> 00:33:53,390
you want to iterate it it just walks the

00:33:51,380 --> 00:33:55,640
vector there is no rocket science here

00:33:53,390 --> 00:33:58,370
at all and this thing is incredibly

00:33:55,640 --> 00:34:00,470
efficient and incredibly fast we use it

00:33:58,370 --> 00:34:05,270
all over the place in the compiler and

00:34:00,470 --> 00:34:08,750
it works wonderfully okay and we can of

00:34:05,270 --> 00:34:11,000
course generalize this to a map okay and

00:34:08,750 --> 00:34:12,590
with the math we have to be a little bit

00:34:11,000 --> 00:34:14,450
more careful right but we just have a

00:34:12,590 --> 00:34:16,070
vector and a map and we even get to do

00:34:14,450 --> 00:34:17,780
something really nice because we don't

00:34:16,070 --> 00:34:20,330
want to store the values twice we can

00:34:17,780 --> 00:34:22,580
rely on keys being small I mean we

00:34:20,330 --> 00:34:24,650
really do rely on keys being small but

00:34:22,580 --> 00:34:26,090
the value type might be larger it might

00:34:24,650 --> 00:34:28,220
not be something we can duplicate

00:34:26,090 --> 00:34:30,380
everywhere right we might want copies of

00:34:28,220 --> 00:34:32,360
the value all over the place but we can

00:34:30,380 --> 00:34:34,370
we can solve that with with this because

00:34:32,360 --> 00:34:37,160
we have a vector and so we actually just

00:34:34,370 --> 00:34:40,700
have the map be a map to it index into

00:34:37,160 --> 00:34:41,810
the vector right and so even to build up

00:34:40,700 --> 00:34:44,510
this data structure we're literally

00:34:41,810 --> 00:34:46,610
reusing the concepts from the rest of

00:34:44,510 --> 00:34:49,610
the talk okay and so this is how we kind

00:34:46,610 --> 00:34:52,160
of piece together the the kind of

00:34:49,610 --> 00:34:55,669
fundamental things we need in order to

00:34:52,160 --> 00:34:57,680
have this now there's one more cool

00:34:55,669 --> 00:34:59,330
trick that I wanted to mention here the

00:34:57,680 --> 00:35:01,100
LLVM doesn't implement this yet because

00:34:59,330 --> 00:35:04,340
we haven't we haven't gotten to it yet

00:35:01,100 --> 00:35:06,650
for whatever reason the cool trick here

00:35:04,340 --> 00:35:09,710
is to is to think about what we're doing

00:35:06,650 --> 00:35:11,660
with a small vector and a small map or

00:35:09,710 --> 00:35:14,780
or or a small vector and small set

00:35:11,660 --> 00:35:15,920
they're the same difference okay so when

00:35:14,780 --> 00:35:18,620
we're doing these things we're

00:35:15,920 --> 00:35:20,420
allocating these small buffers but we're

00:35:18,620 --> 00:35:22,580
allocating two of them one for the

00:35:20,420 --> 00:35:24,890
vector and one for the set that's a

00:35:22,580 --> 00:35:26,300
little unfortunate what's more

00:35:24,890 --> 00:35:28,910
unfortunate is that it doesn't always

00:35:26,300 --> 00:35:32,270
make sense to use a you know hashed

00:35:28,910 --> 00:35:32,810
probed hash table data structure if you

00:35:32,270 --> 00:35:35,000
have

00:35:32,810 --> 00:35:37,130
very small number of values if you have

00:35:35,000 --> 00:35:39,800
a set of like four things that's

00:35:37,130 --> 00:35:41,180
overkill it's actually slow and it would

00:35:39,800 --> 00:35:44,180
be really nice if instead when we had

00:35:41,180 --> 00:35:46,910
really small containers if we actually

00:35:44,180 --> 00:35:48,260
just use kind of a linear scan right

00:35:46,910 --> 00:35:51,320
rather than doing any kind of fancy

00:35:48,260 --> 00:35:53,690
probing and hashing if you think about

00:35:51,320 --> 00:35:56,450
it if we do a linear scan and we have

00:35:53,690 --> 00:35:59,840
this kind of combined set vector or map

00:35:56,450 --> 00:36:01,970
vector and we do a linear scan here

00:35:59,840 --> 00:36:04,520
we're going to have two different small

00:36:01,970 --> 00:36:06,890
buffers both of them with a linear

00:36:04,520 --> 00:36:08,600
ordering of values and we're going to do

00:36:06,890 --> 00:36:10,580
a linear scan over well that's wasteful

00:36:08,600 --> 00:36:12,950
so we can actually change these data

00:36:10,580 --> 00:36:15,830
structures to share a single small

00:36:12,950 --> 00:36:18,110
buffer okay and then we can do the

00:36:15,830 --> 00:36:20,000
linear scan there and that's the vector

00:36:18,110 --> 00:36:21,680
when it's small and then as it grows we

00:36:20,000 --> 00:36:23,870
can allocate ourselves a set and we can

00:36:21,680 --> 00:36:25,280
allocate ourselves a big vector and we

00:36:23,870 --> 00:36:28,640
can fill it up and we can do the proper

00:36:25,280 --> 00:36:30,530
hash based set operations and so this

00:36:28,640 --> 00:36:31,820
stuff scales really really nicely we

00:36:30,530 --> 00:36:33,830
haven't gotten to that because this

00:36:31,820 --> 00:36:36,020
implementation is actually fast enough

00:36:33,830 --> 00:36:37,580
that no one's complained right no one's

00:36:36,020 --> 00:36:39,980
actually run into this but there's even

00:36:37,580 --> 00:36:42,740
more we can do to kind of you know tweak

00:36:39,980 --> 00:36:44,270
in tune the small size optimization to

00:36:42,740 --> 00:36:49,880
really deliver the last mile of

00:36:44,270 --> 00:36:52,730
performance oh right so I just presented

00:36:49,880 --> 00:36:55,370
two and a half small size optimized

00:36:52,730 --> 00:36:57,980
structures and an incredibly crazy

00:36:55,370 --> 00:37:01,250
amount of code doing kind of pointer bit

00:36:57,980 --> 00:37:13,220
packing and I've gotten absolutely no

00:37:01,250 --> 00:37:15,490
questions yes there's one question a

00:37:13,220 --> 00:37:19,390
commission about your tagged pointers

00:37:15,490 --> 00:37:21,710
how do they play with CPU pretty page a

00:37:19,390 --> 00:37:22,880
question about the packed pointers how

00:37:21,710 --> 00:37:24,940
do they play with sorry can you repeat

00:37:22,880 --> 00:37:28,100
that last part

00:37:24,940 --> 00:37:29,470
CPU bridge how do they play with CPU

00:37:28,100 --> 00:37:31,700
prefetching uh

00:37:29,470 --> 00:37:34,370
I mean they're not the most friendly

00:37:31,700 --> 00:37:36,950
things to CPU prefetching sadly at the

00:37:34,370 --> 00:37:38,240
same time if they're in the cache and we

00:37:36,950 --> 00:37:40,760
can like load them and put them into

00:37:38,240 --> 00:37:43,800
pointer into registers in the pointer

00:37:40,760 --> 00:37:45,330
forum the prefecture will still do it uh

00:37:43,800 --> 00:37:46,650
looking at the actual load operation

00:37:45,330 --> 00:37:48,810
right the operating to the load

00:37:46,650 --> 00:37:51,090
operation is actually the Pointer kind

00:37:48,810 --> 00:37:53,160
of restored it means that there's less

00:37:51,090 --> 00:37:54,780
time you can see it ahead of time but we

00:37:53,160 --> 00:37:56,700
can also insert explicit prefetching

00:37:54,780 --> 00:37:58,410
that does that arithmetic to get rid of

00:37:56,700 --> 00:38:00,210
the integer bits and to produce a

00:37:58,410 --> 00:38:02,730
pristine pointer for prefetching if you

00:38:00,210 --> 00:38:03,750
need it by the way if you do have

00:38:02,730 --> 00:38:05,760
questions please come up to the

00:38:03,750 --> 00:38:07,020
microphones and I'm already I'm already

00:38:05,760 --> 00:38:09,390
nervous because Howard has headed up to

00:38:07,020 --> 00:38:11,400
a microphone yes with small set vector

00:38:09,390 --> 00:38:13,470
how do you remove items how do you know

00:38:11,400 --> 00:38:16,620
which element of a vector portion the

00:38:13,470 --> 00:38:21,800
items in so the question is with a small

00:38:16,620 --> 00:38:21,800
set vector how do you remove items

00:38:22,010 --> 00:38:29,700
slowly specifically linearly we walk the

00:38:27,570 --> 00:38:31,560
entire thing to find them I it's it's

00:38:29,700 --> 00:38:34,230
not great we've we looked at doing a

00:38:31,560 --> 00:38:37,020
small set vector the exact same way we

00:38:34,230 --> 00:38:39,090
do the the map vector so that we

00:38:37,020 --> 00:38:40,710
actually have an index but it is a lot

00:38:39,090 --> 00:38:43,170
of overhead and it turns out almost all

00:38:40,710 --> 00:38:44,310
the users we have for set vector don't

00:38:43,170 --> 00:38:45,450
ever remove things until they're

00:38:44,310 --> 00:38:48,660
finished and then they delete the whole

00:38:45,450 --> 00:38:51,120
thing and so it's somewhat tune tailored

00:38:48,660 --> 00:38:53,850
to the use cases we happen to have okay

00:38:51,120 --> 00:38:56,880
Howard go ahead oh my name is Howard in

00:38:53,850 --> 00:39:01,470
it I noticed that you're completely

00:38:56,880 --> 00:39:04,410
ignoring the issue of time zones how

00:39:01,470 --> 00:39:09,060
could I have missed that nice talk thank

00:39:04,410 --> 00:39:10,890
you very much thanks by the way in case

00:39:09,060 --> 00:39:15,210
anyone's wondering uh Howard has a great

00:39:10,890 --> 00:39:16,800
talk about time zones yes John okay

00:39:15,210 --> 00:39:18,120
my name is John Laika's and I have

00:39:16,800 --> 00:39:21,420
something to do with allocators but

00:39:18,120 --> 00:39:23,490
that's not my question the first the

00:39:21,420 --> 00:39:25,290
first question is can you tell me when

00:39:23,490 --> 00:39:27,900
you when you're ignoring the low order

00:39:25,290 --> 00:39:31,830
4-bit four bits why is it four zeros and

00:39:27,900 --> 00:39:35,550
not two or three I what the question is

00:39:31,830 --> 00:39:38,970
why oh my goodness this is way back why

00:39:35,550 --> 00:39:42,690
was this four zeros rather than two or

00:39:38,970 --> 00:39:44,280
three zeros uh I have I have many

00:39:42,690 --> 00:39:47,400
answers for you unfortunately number one

00:39:44,280 --> 00:39:50,850
answer is because I wrote the code ran

00:39:47,400 --> 00:39:52,740
it in gdb and that's the number I got uh

00:39:50,850 --> 00:39:55,620
the number two answer is because I'm

00:39:52,740 --> 00:39:57,270
running on a Linux 64-bit system

00:39:55,620 --> 00:39:59,730
this probably reaches out to Malik and

00:39:57,270 --> 00:40:01,350
Malik on my Linux 64-bit systems and

00:39:59,730 --> 00:40:03,540
most people's Linux 60 wrote systems

00:40:01,350 --> 00:40:06,120
just happens to always give you 16 byte

00:40:03,540 --> 00:40:07,770
aligned memory okay that works I

00:40:06,120 --> 00:40:11,220
couldn't figure it out yeah no I have

00:40:07,770 --> 00:40:14,180
one more question it's a very complex

00:40:11,220 --> 00:40:18,440
space when you talk about the size

00:40:14,180 --> 00:40:21,690
locality and doing bit operations and

00:40:18,440 --> 00:40:24,000
obviously if you have and the access if

00:40:21,690 --> 00:40:25,650
you have sort of arbitrary access in a

00:40:24,000 --> 00:40:29,640
list versus if you have sequential

00:40:25,650 --> 00:40:32,100
access but my question is I guess can

00:40:29,640 --> 00:40:34,740
you give us some insight into where the

00:40:32,100 --> 00:40:36,780
higher cost and I think we'd agree that

00:40:34,740 --> 00:40:39,060
doing bit operations can be a higher

00:40:36,780 --> 00:40:40,620
cost than not doing the bit operations

00:40:39,060 --> 00:40:42,600
having something that's slightly bigger

00:40:40,620 --> 00:40:46,620
but still small enough to fit inside

00:40:42,600 --> 00:40:48,420
cache or cache lines etc so the question

00:40:46,620 --> 00:40:53,510
really is at what point do we start

00:40:48,420 --> 00:40:56,640
seeing the cost of doing the bit packing

00:40:53,510 --> 00:41:00,090
outweigh the the benefit of compacting

00:40:56,640 --> 00:41:02,610
our data this is a great question so

00:41:00,090 --> 00:41:04,740
this is this is fundamentally the the

00:41:02,610 --> 00:41:05,760
cost we're paying right this is this is

00:41:04,740 --> 00:41:08,460
the thing that does most of the bit

00:41:05,760 --> 00:41:10,650
packing so the key insight here are a

00:41:08,460 --> 00:41:12,210
couple of things one well there's a lot

00:41:10,650 --> 00:41:15,030
of code here there's not a lot of

00:41:12,210 --> 00:41:16,260
dynamically executed code right so so

00:41:15,030 --> 00:41:19,080
one thing that helps us is that things

00:41:16,260 --> 00:41:21,090
like the the computing the shift values

00:41:19,080 --> 00:41:22,800
computing the masks all that happens at

00:41:21,090 --> 00:41:24,150
compile time it's all con sexpert so

00:41:22,800 --> 00:41:26,430
we're actually paying for in terms of

00:41:24,150 --> 00:41:28,830
overhead our shifts and masks and ORS

00:41:26,430 --> 00:41:30,840
and processors those are the

00:41:28,830 --> 00:41:33,360
instructions processors are fastest at

00:41:30,840 --> 00:41:36,120
in the entire world so the overhead here

00:41:33,360 --> 00:41:38,640
is remarkably low we have I don't know

00:41:36,120 --> 00:41:41,130
of any point which we have measured an

00:41:38,640 --> 00:41:44,640
overhead of doing bit packing into

00:41:41,130 --> 00:41:46,560
pointers I mean that doesn't mean it

00:41:44,640 --> 00:41:48,690
doesn't exist it almost certainly exists

00:41:46,560 --> 00:41:50,250
but it's very very low the other thing

00:41:48,690 --> 00:41:52,290
to think about is if you have a one or

00:41:50,250 --> 00:41:55,200
two or three bit integer and you have a

00:41:52,290 --> 00:41:58,350
64 bit pointer anything you do other

00:41:55,200 --> 00:42:00,270
than pack those bits in will waste you

00:41:58,350 --> 00:42:02,490
know eight times the number of bits at

00:42:00,270 --> 00:42:05,430
least as you had in your integer and so

00:42:02,490 --> 00:42:08,190
the savings are relatively large to the

00:42:05,430 --> 00:42:09,470
problem at hand so I've seen in all of

00:42:08,190 --> 00:42:11,210
your map examples that you

00:42:09,470 --> 00:42:13,970
store both the keys and the values in

00:42:11,210 --> 00:42:15,650
knepper is there any look any situation

00:42:13,970 --> 00:42:17,210
where super beneficial to store all the

00:42:15,650 --> 00:42:18,970
keys together all the values together

00:42:17,210 --> 00:42:22,490
maybe when you have a heavy lookup

00:42:18,970 --> 00:42:24,380
situation so the question is in in all

00:42:22,490 --> 00:42:33,470
of my map examples which are further

00:42:24,380 --> 00:42:34,700
back here uh eventually we we store the

00:42:33,470 --> 00:42:36,590
key in the value in a single bucket

00:42:34,700 --> 00:42:39,650
you're like in a pair in a bucket um

00:42:36,590 --> 00:42:41,060
this is this is true there's a lot of

00:42:39,650 --> 00:42:43,940
interesting ideas around having separate

00:42:41,060 --> 00:42:45,710
buckets for keys and values I we don't

00:42:43,940 --> 00:42:47,270
do that I think that there probably is a

00:42:45,710 --> 00:42:50,240
win there especially for fairly sparse

00:42:47,270 --> 00:42:52,220
hash tables but we don't see a lot of

00:42:50,240 --> 00:42:53,720
win for for dense hash tables the real

00:42:52,220 --> 00:42:55,490
problem for us is that we're going to

00:42:53,720 --> 00:42:57,800
have to actually examine the key if we

00:42:55,490 --> 00:43:00,080
could cheat and not look at the key that

00:42:57,800 --> 00:43:02,359
would be a huge win if we were walking

00:43:00,080 --> 00:43:04,369
large portions of the hash table

00:43:02,359 --> 00:43:06,200
then it would also be problematic to be

00:43:04,369 --> 00:43:08,060
skipping over a bunch of value entries

00:43:06,200 --> 00:43:10,160
but if we're walking large portions of

00:43:08,060 --> 00:43:12,170
the hash table where we're probing and

00:43:10,160 --> 00:43:13,369
we shouldn't be probing that much we

00:43:12,170 --> 00:43:15,920
should be growing the hash table or

00:43:13,369 --> 00:43:17,180
fixing our hash function and so so I

00:43:15,920 --> 00:43:19,580
don't think that's really the biggest

00:43:17,180 --> 00:43:21,230
thing the biggest wins we've seen and

00:43:19,580 --> 00:43:23,510
these aren't in LLVM actually this is

00:43:21,230 --> 00:43:25,910
more in Google's code are around doing a

00:43:23,510 --> 00:43:29,030
better job of hashing and probing to

00:43:25,910 --> 00:43:30,440
look at fewer keys right rather than

00:43:29,030 --> 00:43:32,810
trying to separate the data structures

00:43:30,440 --> 00:43:34,790
you're already very random access and so

00:43:32,810 --> 00:43:36,320
I worry that you're just random access

00:43:34,790 --> 00:43:38,150
into two arrays and it doesn't help you

00:43:36,320 --> 00:43:40,460
as much as it does in kind of sequential

00:43:38,150 --> 00:43:41,960
patterns a lot of that those stems from

00:43:40,460 --> 00:43:44,150
the fact that we work very hard to not

00:43:41,960 --> 00:43:45,349
iterate the actual map and if you're

00:43:44,150 --> 00:43:49,550
iterating it I think that'd be a

00:43:45,349 --> 00:43:52,250
different a different two questions in

00:43:49,550 --> 00:43:53,839
this regard do you have any relative

00:43:52,250 --> 00:43:57,380
performance measurements that you can

00:43:53,839 --> 00:43:59,990
show us to compare these the structure

00:43:57,380 --> 00:44:01,940
access with their counterparts and the

00:43:59,990 --> 00:44:04,099
other you mentioned using bit fields are

00:44:01,940 --> 00:44:06,980
you talking about struct defined bit

00:44:04,099 --> 00:44:09,950
fields or bit masks in the traditional

00:44:06,980 --> 00:44:12,140
seed bit mask sense so two questions we

00:44:09,950 --> 00:44:13,670
deal with the first one so the first

00:44:12,140 --> 00:44:15,470
question is do I have relative

00:44:13,670 --> 00:44:18,680
performance numbers and I'm embarrassed

00:44:15,470 --> 00:44:20,030
to say that I don't really I anecdotally

00:44:18,680 --> 00:44:21,800
when we have made changes to the

00:44:20,030 --> 00:44:22,710
compiler to to introduce these kinds of

00:44:21,800 --> 00:44:24,870
data structures

00:44:22,710 --> 00:44:27,150
we have seen very very dramatic

00:44:24,870 --> 00:44:28,770
performance swings usually though that's

00:44:27,150 --> 00:44:31,350
because there was a very bad problem to

00:44:28,770 --> 00:44:33,270
start with a lot of what LVM is doing is

00:44:31,350 --> 00:44:35,430
systematically following these patterns

00:44:33,270 --> 00:44:38,160
so that we kind of take off the the

00:44:35,430 --> 00:44:40,710
broad creep of performance at the bottom

00:44:38,160 --> 00:44:42,210
of our stack if you write benchmarks you

00:44:40,710 --> 00:44:43,800
can measure very dramatic performance

00:44:42,210 --> 00:44:45,420
differences though I always hesitate to

00:44:43,800 --> 00:44:47,460
do that because the benchmarks actually

00:44:45,420 --> 00:44:49,200
misleading here write real code doesn't

00:44:47,460 --> 00:44:52,050
look like a benchmark that does nothing

00:44:49,200 --> 00:44:55,650
other than like the access a small hash

00:44:52,050 --> 00:44:57,660
table that's in the working set I the

00:44:55,650 --> 00:45:00,510
the second question was about bit fields

00:44:57,660 --> 00:45:02,550
when I say that fields I mean bit fields

00:45:00,510 --> 00:45:04,770
as in you know bit field members of a

00:45:02,550 --> 00:45:06,990
struct but they're present in both C and

00:45:04,770 --> 00:45:09,300
C++ they're not the sequel specificity

00:45:06,990 --> 00:45:12,420
construct I certainly would not advocate

00:45:09,300 --> 00:45:15,660
anyone manually pack bits when they

00:45:12,420 --> 00:45:20,330
don't need to write like the the code

00:45:15,660 --> 00:45:22,800
required to to pack the bits in here is

00:45:20,330 --> 00:45:24,600
horrible right you don't want to write

00:45:22,800 --> 00:45:27,060
this code you want to actually use a bit

00:45:24,600 --> 00:45:29,180
field to destruct it you can write I

00:45:27,060 --> 00:45:31,260
guess I was I was referring to the

00:45:29,180 --> 00:45:33,180
traditional performance difference

00:45:31,260 --> 00:45:36,630
between using a bit field and a struct

00:45:33,180 --> 00:45:38,280
versus using bit masks with the math so

00:45:36,630 --> 00:45:39,110
if you if you see a performance

00:45:38,280 --> 00:45:41,370
difference in your implementation

00:45:39,110 --> 00:45:44,400
between using a bit field and a struct

00:45:41,370 --> 00:45:45,510
and writing out the math manually you

00:45:44,400 --> 00:45:47,490
should file a bug with your vendor

00:45:45,510 --> 00:45:48,570
because there's no reason for that if

00:45:47,490 --> 00:45:55,100
anything the bit field should be

00:45:48,570 --> 00:45:56,580
substantially faster so you mentioned a

00:45:55,100 --> 00:45:58,470
small vector

00:45:56,580 --> 00:46:01,710
imple type racing the size of the small

00:45:58,470 --> 00:46:03,480
buffer being advantage I would expect

00:46:01,710 --> 00:46:07,170
you can go one step further new

00:46:03,480 --> 00:46:08,490
something like GSL span to even

00:46:07,170 --> 00:46:11,430
generalize across different kinds of

00:46:08,490 --> 00:46:12,750
containers so the observation is that

00:46:11,430 --> 00:46:14,160
you can use something like geocell span

00:46:12,750 --> 00:46:16,350
to generalize across different kinds of

00:46:14,160 --> 00:46:18,210
containers and in fact the array ref

00:46:16,350 --> 00:46:20,520
proposal that predates the span proposal

00:46:18,210 --> 00:46:22,020
was based on an array ref type in Ella

00:46:20,520 --> 00:46:24,510
Williams code base in Google's code base

00:46:22,020 --> 00:46:26,100
we use it very heavily the key thing is

00:46:24,510 --> 00:46:28,740
that you can't modify the actual

00:46:26,100 --> 00:46:30,540
structure though the real the really

00:46:28,740 --> 00:46:32,160
amazing thing about the small vector in

00:46:30,540 --> 00:46:34,650
pole is that you can actually grow the

00:46:32,160 --> 00:46:36,359
container from that reduced data type

00:46:34,650 --> 00:46:41,069
not just inspect it

00:46:36,359 --> 00:46:44,789
not just mutate the values within it so

00:46:41,069 --> 00:46:47,690
you talked about using slab a locator to

00:46:44,789 --> 00:46:50,069
get a better locality

00:46:47,690 --> 00:46:52,499
have you tried or measured using

00:46:50,069 --> 00:46:55,589
structure like a deck and pre allocating

00:46:52,499 --> 00:46:58,950
stuff like say P Nike what you need and

00:46:55,589 --> 00:47:01,619
using that instead so so the question is

00:46:58,950 --> 00:47:04,470
can we instead pre-allocate what we need

00:47:01,619 --> 00:47:06,690
rather than using slab allocators the

00:47:04,470 --> 00:47:08,880
answer to this is is yes and we do this

00:47:06,690 --> 00:47:11,400
a fair amount so we'll often reserve

00:47:08,880 --> 00:47:13,739
vectors to kind of very carefully chosen

00:47:11,400 --> 00:47:16,349
sizes and then like them those kinds of

00:47:13,739 --> 00:47:19,499
things but they tend to form a pretty

00:47:16,349 --> 00:47:21,029
subtle pitfalls okay because if you ever

00:47:19,499 --> 00:47:23,640
if you ever get that reservation wrong

00:47:21,029 --> 00:47:26,220
you then have a very surprising cliff in

00:47:23,640 --> 00:47:28,710
your performance where suddenly you have

00:47:26,220 --> 00:47:30,599
to go and move a large you know pile of

00:47:28,710 --> 00:47:31,980
data to new out locations the other

00:47:30,599 --> 00:47:33,150
problem is it can be a correctness bug

00:47:31,980 --> 00:47:35,400
instead of just a performance bug

00:47:33,150 --> 00:47:37,739
because you don't actually have that

00:47:35,400 --> 00:47:39,660
address stability guarantee from any of

00:47:37,739 --> 00:47:41,549
those containers now we could use

00:47:39,660 --> 00:47:43,680
something like deck to get this right

00:47:41,549 --> 00:47:48,509
this standard deck but the the standard

00:47:43,680 --> 00:47:49,859
deck data type is really quite bad III

00:47:48,509 --> 00:47:51,239
wouldn't recommend anyone use it for

00:47:49,859 --> 00:47:52,769
anything if you look at the

00:47:51,239 --> 00:47:54,480
implementation constraints the the

00:47:52,769 --> 00:47:55,589
constraints placed upon its its

00:47:54,480 --> 00:47:57,420
iterators and its invalidation

00:47:55,589 --> 00:47:59,519
constraints it's painted into a very

00:47:57,420 --> 00:48:00,900
unpleasant corner and it has very few

00:47:59,519 --> 00:48:07,079
opportunities to be an efficient data

00:48:00,900 --> 00:48:11,210
structure yeah I have a question about

00:48:07,079 --> 00:48:13,710
the for word list yes so um

00:48:11,210 --> 00:48:17,460
usually whenever people iterate over

00:48:13,710 --> 00:48:18,839
objects they tend to use them and when

00:48:17,460 --> 00:48:20,369
they use them the for word list

00:48:18,839 --> 00:48:23,789
prefetches them if it's carefully

00:48:20,369 --> 00:48:28,200
designed where the pointer is stored so

00:48:23,789 --> 00:48:33,299
why would that be not not good compared

00:48:28,200 --> 00:48:35,249
to say a vector of pointers to objects

00:48:33,299 --> 00:48:37,559
so the question is why can't this the

00:48:35,249 --> 00:48:39,420
for word list do the prefetching for you

00:48:37,559 --> 00:48:41,789
by pointing out where the next memory

00:48:39,420 --> 00:48:44,190
location is and it certainly can the

00:48:41,789 --> 00:48:47,130
problem is that that next memory

00:48:44,190 --> 00:48:49,049
location is still dependent on actually

00:48:47,130 --> 00:48:50,040
loading the cache line with the list

00:48:49,049 --> 00:48:52,500
entry in it

00:48:50,040 --> 00:48:56,340
and so you have this dependency chain

00:48:52,500 --> 00:48:59,550
every next pointer sits on the next

00:48:56,340 --> 00:49:02,280
cache line right and so you can't look

00:48:59,550 --> 00:49:04,020
more than one ahead exactly one and

00:49:02,280 --> 00:49:05,850
that's a real limitation of modern

00:49:04,020 --> 00:49:08,520
processors right as if you have an array

00:49:05,850 --> 00:49:10,920
of pointers right every single one of

00:49:08,520 --> 00:49:12,600
those pointers is visible immediately

00:49:10,920 --> 00:49:14,460
there's no dependency there's no

00:49:12,600 --> 00:49:16,560
uncertainty like the processor knows

00:49:14,460 --> 00:49:18,870
exactly where they're going

00:49:16,560 --> 00:49:21,690
follow-up question absolute you are

00:49:18,870 --> 00:49:26,790
saying that the modern architecture can

00:49:21,690 --> 00:49:29,700
actually do these loads in parallel

00:49:26,790 --> 00:49:31,050
somewhat in some cases it doesn't even

00:49:29,700 --> 00:49:33,390
matter if it can do the loads in

00:49:31,050 --> 00:49:35,280
parallel though merely having the

00:49:33,390 --> 00:49:37,200
sequential chaining between cache misses

00:49:35,280 --> 00:49:39,120
is going to cause stalls to become

00:49:37,200 --> 00:49:41,550
visible the aren't visible if you can

00:49:39,120 --> 00:49:43,950
actually addy couple the two the two

00:49:41,550 --> 00:49:46,590
operations so even if you can just just

00:49:43,950 --> 00:49:48,780
alive one of the cache line stalls

00:49:46,590 --> 00:49:50,070
loading the next one and overlap some of

00:49:48,780 --> 00:49:52,080
the operations are going to see wins

00:49:50,070 --> 00:49:53,580
immediately and even with prefetching

00:49:52,080 --> 00:49:55,620
you you don't see this happen with with

00:49:53,580 --> 00:49:59,670
linked lists thank you

00:49:55,620 --> 00:50:00,810
absolutely well we're running out of

00:49:59,670 --> 00:50:03,080
time but I have a little bit more time

00:50:00,810 --> 00:50:07,080
if there's any more questions

00:50:03,080 --> 00:50:11,010
hi and do you use some containers like

00:50:07,080 --> 00:50:15,420
try and how they are implemented do I

00:50:11,010 --> 00:50:20,490
use some containers like try G are i.e

00:50:15,420 --> 00:50:22,080
yes I do use containers like a try I I

00:50:20,490 --> 00:50:25,230
think there may be one place in all the

00:50:22,080 --> 00:50:28,410
compiler where we use try it's very very

00:50:25,230 --> 00:50:30,180
unusual they mostly show up in things

00:50:28,410 --> 00:50:32,400
like simple tables and other kind of

00:50:30,180 --> 00:50:33,870
text processing operations and we have

00:50:32,400 --> 00:50:35,220
relatively few of those in the compiler

00:50:33,870 --> 00:50:37,620
I think that's just that's just my

00:50:35,220 --> 00:50:39,540
personal bias working on LLVM the Tri

00:50:37,620 --> 00:50:43,860
data structures are fabulous things I'm

00:50:39,540 --> 00:50:45,810
just not an expert in the middle before

00:50:43,860 --> 00:50:48,000
answering one of the questions so I

00:50:45,810 --> 00:50:50,280
mentioned that if there is a performance

00:50:48,000 --> 00:50:52,740
difference between bit masks integers

00:50:50,280 --> 00:50:54,120
versus bit filled structures then you

00:50:52,740 --> 00:50:55,320
should contact your compiler vendor

00:50:54,120 --> 00:50:58,710
because there shouldn't be a big

00:50:55,320 --> 00:51:01,260
difference I was I was wondering are due

00:50:58,710 --> 00:51:02,850
to ABI standards if you return in a bit

00:51:01,260 --> 00:51:03,869
past integer it can be returned in

00:51:02,850 --> 00:51:07,589
registers

00:51:03,869 --> 00:51:10,019
and and register you later and do you

00:51:07,589 --> 00:51:11,670
know if beat field structure can be

00:51:10,019 --> 00:51:13,890
returned the same way and would that be

00:51:11,670 --> 00:51:16,769
a reason for performance difference I

00:51:13,890 --> 00:51:18,630
I'm not an avi expert I know that the

00:51:16,769 --> 00:51:20,730
ABI allows us to return some structures

00:51:18,630 --> 00:51:22,109
and registers though I would hope that

00:51:20,730 --> 00:51:24,660
allows us to return structures with bit

00:51:22,109 --> 00:51:26,579
fields in them in registers I also hope

00:51:24,660 --> 00:51:29,460
that you don't have a function call

00:51:26,579 --> 00:51:31,499
return in the hot path I hear that that

00:51:29,460 --> 00:51:32,789
that will like even if it gets the

00:51:31,499 --> 00:51:34,019
Cullen convention right even if you gets

00:51:32,789 --> 00:51:37,200
it in registers that's still going to be

00:51:34,019 --> 00:51:39,119
somewhat unfortunate but I would need to

00:51:37,200 --> 00:51:43,349
you need to ask an API expert rather

00:51:39,119 --> 00:51:46,170
than myself Chandler do you guys reclaim

00:51:43,349 --> 00:51:50,249
it's on the upper end as well so like on

00:51:46,170 --> 00:51:52,259
1x you have both your x86 Linux systems

00:51:50,249 --> 00:51:54,299
your pointers are 16-bit aligned but you

00:51:52,259 --> 00:51:55,619
also are only using 48 bits of address

00:51:54,299 --> 00:51:57,059
space or can you not reclaim them

00:51:55,619 --> 00:51:59,249
because of address space randomization

00:51:57,059 --> 00:52:02,579
so the question is do we reclaim these

00:51:59,249 --> 00:52:05,339
the high bits that on some platforms and

00:52:02,579 --> 00:52:07,859
some pointer sizes are actually known to

00:52:05,339 --> 00:52:09,619
be the same value whether they're ones

00:52:07,859 --> 00:52:11,460
or zeros we actually leave those alone

00:52:09,619 --> 00:52:13,920
we leave them alone for a bunch of

00:52:11,460 --> 00:52:15,630
reasons some of it is because they're

00:52:13,920 --> 00:52:17,400
not as many bits that we can touch there

00:52:15,630 --> 00:52:18,900
as we might like because of address

00:52:17,400 --> 00:52:21,480
space layout randomization is as Bryce

00:52:18,900 --> 00:52:23,579
mentioned there also other reasons to

00:52:21,480 --> 00:52:25,410
leave them alone so Intel and other

00:52:23,579 --> 00:52:27,839
people keep warning us that they want to

00:52:25,410 --> 00:52:30,119
take those bits back and we listen and

00:52:27,839 --> 00:52:31,799
so we're not we're not kind of baking in

00:52:30,119 --> 00:52:33,989
an assumption about that we also do want

00:52:31,799 --> 00:52:35,970
to run LLVM on 32-bit architectures and

00:52:33,989 --> 00:52:37,559
all of the pointer alignment tricks here

00:52:35,970 --> 00:52:39,029
still work on a 32-bit architecture but

00:52:37,559 --> 00:52:40,739
we started stealing from the high bits

00:52:39,029 --> 00:52:42,930
we'd have to turn those optimizations

00:52:40,739 --> 00:52:45,839
off which would add a lot of complexity

00:52:42,930 --> 00:52:47,700
the final interesting observation is we

00:52:45,839 --> 00:52:50,009
can we can grow the alignment of our

00:52:47,700 --> 00:52:52,049
types however much we need to in order

00:52:50,009 --> 00:52:54,900
to get the number of bits we want and we

00:52:52,049 --> 00:52:56,099
do that and we do that more on 64-bit

00:52:54,900 --> 00:52:57,900
architectures where we know we have the

00:52:56,099 --> 00:52:59,640
address space to do it and so we can

00:52:57,900 --> 00:53:01,980
just we can just push the bits we need

00:52:59,640 --> 00:53:03,930
into the bottom by taking that space in

00:53:01,980 --> 00:53:06,569
the address space rather than abusing

00:53:03,930 --> 00:53:08,579
the the high bits we if we need to so we

00:53:06,569 --> 00:53:09,809
can take the remaining two questions

00:53:08,579 --> 00:53:13,950
fairly quickly and then I want to let

00:53:09,809 --> 00:53:16,130
the next presenter get up here way back

00:53:13,950 --> 00:53:19,040
to the beginning one of the

00:53:16,130 --> 00:53:21,110
arguments for using small vector instead

00:53:19,040 --> 00:53:23,720
of state vector had to do with iterator

00:53:21,110 --> 00:53:26,450
invalidation but I didn't catch what

00:53:23,720 --> 00:53:28,760
that argument was sorry so the question

00:53:26,450 --> 00:53:30,590
is what was this iterator in validation

00:53:28,760 --> 00:53:32,510
that causes a problem with standard

00:53:30,590 --> 00:53:35,300
vector having a small size optimization

00:53:32,510 --> 00:53:37,730
the iterators are not invalidated on

00:53:35,300 --> 00:53:40,250
move of the standard vector object

00:53:37,730 --> 00:53:42,320
itself and if you are in a small size

00:53:40,250 --> 00:53:43,640
and you have an iterator it will be

00:53:42,320 --> 00:53:48,080
invalidated if you move it from one

00:53:43,640 --> 00:53:50,450
location to another as you're actually

00:53:48,080 --> 00:53:54,740
going to copy from one in-line buffer to

00:53:50,450 --> 00:53:58,940
the other on move in a small vector but

00:53:54,740 --> 00:54:00,770
not it is okay thank you so this may be

00:53:58,940 --> 00:54:04,640
a 10 second question I might be

00:54:00,770 --> 00:54:05,540
misinformed but the piece of information

00:54:04,640 --> 00:54:08,030
from this is going to have the most

00:54:05,540 --> 00:54:12,020
impact on my code is that you said bit

00:54:08,030 --> 00:54:16,310
sets are should be faster or the same as

00:54:12,020 --> 00:54:19,700
bit wise math on integers that we've all

00:54:16,310 --> 00:54:21,680
done at some point so the reason why I

00:54:19,700 --> 00:54:24,590
use integers directly my code instead

00:54:21,680 --> 00:54:27,020
bit sets is that someone who's read

00:54:24,590 --> 00:54:27,500
pieces of the standard but not cover to

00:54:27,020 --> 00:54:30,320
cover

00:54:27,500 --> 00:54:32,030
I see a number of times I see I'm

00:54:30,320 --> 00:54:33,980
reading through something and I say if T

00:54:32,030 --> 00:54:37,330
is it says if T is not a bit set and

00:54:33,980 --> 00:54:39,710
then lists a whole bunch of other rules

00:54:37,330 --> 00:54:41,200
are there things I should be worried

00:54:39,710 --> 00:54:44,450
about there or I'm at just being

00:54:41,200 --> 00:54:47,150
neurotic though they're kind of

00:54:44,450 --> 00:54:48,740
terrifying I still think you should use

00:54:47,150 --> 00:54:50,990
them I think it's less terrifying than

00:54:48,740 --> 00:54:52,400
writing complex math yourself and hoping

00:54:50,990 --> 00:54:53,780
you get it ripe and then debugging it

00:54:52,400 --> 00:54:57,590
when you get it wrong because I hate

00:54:53,780 --> 00:54:59,060
debugging my code they're not the rules

00:54:57,590 --> 00:55:00,470
aren't going to bite you too badly they

00:54:59,060 --> 00:55:01,940
mostly are caught by compiler error

00:55:00,470 --> 00:55:03,590
messages these aren't like Oh your

00:55:01,940 --> 00:55:06,380
compiler your code is going to crash

00:55:03,590 --> 00:55:08,030
randomly without warning on the rules

00:55:06,380 --> 00:55:10,010
come in two places you can't form

00:55:08,030 --> 00:55:12,020
references to bit fields two bit field

00:55:10,010 --> 00:55:13,520
members which is a little annoying but

00:55:12,020 --> 00:55:14,660
you can work around quick quite easily

00:55:13,520 --> 00:55:19,730
with something like a reference wrapper

00:55:14,660 --> 00:55:21,170
and the second one is is I you you you

00:55:19,730 --> 00:55:22,250
have data race constraints with bit

00:55:21,170 --> 00:55:23,600
fields all the bit fields are

00:55:22,250 --> 00:55:26,000
essentially merged into one large

00:55:23,600 --> 00:55:28,370
integer for you and and that's what the

00:55:26,000 --> 00:55:29,809
you know any access is to then so it

00:55:28,370 --> 00:55:31,670
acts is the entire memory location

00:55:29,809 --> 00:55:32,719
the merge set of bit fields these don't

00:55:31,670 --> 00:55:36,859
really come up in kind of day-to-day

00:55:32,719 --> 00:55:39,439
stuff LLVM we have had far more bugs

00:55:36,859 --> 00:55:41,630
with people writing math than with the

00:55:39,439 --> 00:55:43,819
bit fields themselves so I would I would

00:55:41,630 --> 00:55:46,630
generally lean in that direction all

00:55:43,819 --> 00:55:46,630

YouTube URL: https://www.youtube.com/watch?v=vElZc6zSIXM


