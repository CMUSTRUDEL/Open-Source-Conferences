Title: CppCon 2016: Matthew Bentley “Colonies, performance and why you should care"
Publication date: 2016-09-29
Playlist: CppCon 2016
Description: 
	http://CppCon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/cppcon/cppcon2016
—
In game development and many other high-performance, highly-modular development architectures, maintaining valid references to container elements regardless of erasure and insertion is often crucial. While there are many workarounds for this, typically using std::vector with various methods to avoid invalidation, to date there exist no generalized solutions to the problem which also provide strong cache performance.

plf::colony, a proposed unordered container class from the SG14 working group, is one attempt to remedy this situation: it provides fast insertion, erasure and iteration performance while maintaining pointer stability to non-erased elements, which is unaffected by both insertion and erasure.

In this talk we’ll explore both the structure and comparative performance of plf::colony, contrasting it with other standard library containers and their potential modifications, showing how it can outperform many typical alternatives where large amounts of insertions and erasures are concerned. This will include details on:

The “jump-counting” skipfield pattern, a new numeric pattern which has better performance than its boolean counterpart.

plf::stack, a replacement for std::stack with stronger stack performance than other standard library containers.

The chained-group allocation pattern, common to both containers.

If you’re not interested in new containers, you may still pick up a few concepts to help you with improving your own implementations and high-performance C++ code. If you are interested in better containers, or better container usage, you should definitely attend this talk.
— 
Matthew Bentley
Computer Engineer
Matt Bentley was born in 1978 and never recovered from the experience. He started programming in 1986, completing a BSc Computer Science 1999, before spending three years working for a legal publishing firm, getting chronic fatigue syndrone, quitting, building a music studio, recovering, getting interested in programming again, building a game engine, and stumbling across some generalized solutions to some old problems.
—
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:01,909 --> 00:00:08,069
hi I'm Matt obviously so I always like

00:00:06,540 --> 00:00:10,500
to start with this quote because it's

00:00:08,069 --> 00:00:12,509
something that's sort of you know jeong

00:00:10,500 --> 00:00:14,490
bandied around a lot nowadays on

00:00:12,509 --> 00:00:16,619
stackoverflow and various forums and

00:00:14,490 --> 00:00:20,430
what-have-you and it's generally sort of

00:00:16,619 --> 00:00:22,170
used as a way of essentially you know

00:00:20,430 --> 00:00:25,529
hammering on UVs for thinking about

00:00:22,170 --> 00:00:28,109
optimization and it's usually used in

00:00:25,529 --> 00:00:29,490
the context of saying micro optimization

00:00:28,109 --> 00:00:31,500
is bad and this sort of thing you

00:00:29,490 --> 00:00:34,100
shouldn't be thinking about optimization

00:00:31,500 --> 00:00:36,780
at all you should let the compiler do it

00:00:34,100 --> 00:00:39,780
whereas in its original full quality

00:00:36,780 --> 00:00:41,399
ssin what it's actually saying is yes

00:00:39,780 --> 00:00:43,500
you should optimize you should think

00:00:41,399 --> 00:00:46,170
about optimization you should think

00:00:43,500 --> 00:00:48,570
about micro optimization as well but you

00:00:46,170 --> 00:00:51,120
should be wise about how you optimize

00:00:48,570 --> 00:00:52,530
and where you're optimizing you should

00:00:51,120 --> 00:00:55,289
optimize the three-percent

00:00:52,530 --> 00:01:04,260
but you should do that after you're

00:00:55,289 --> 00:01:06,630
identified where it is so about 12 years

00:01:04,260 --> 00:01:08,369
ago or so I couldn't walk for about ten

00:01:06,630 --> 00:01:10,439
minutes without having to lie down for a

00:01:08,369 --> 00:01:11,820
couple of hours afterwards so the

00:01:10,439 --> 00:01:16,080
concept of efficiency and performance

00:01:11,820 --> 00:01:18,360
has a slightly more real-world perhaps

00:01:16,080 --> 00:01:20,670
personal quality for me than it does for

00:01:18,360 --> 00:01:22,740
maybe a lot of you and I tend to see it

00:01:20,670 --> 00:01:24,810
more externally than solely within

00:01:22,740 --> 00:01:29,520
Computer Applications and whatnot for

00:01:24,810 --> 00:01:31,590
example Google Maps for example is a

00:01:29,520 --> 00:01:33,210
good example of sort of computers and

00:01:31,590 --> 00:01:34,619
real world efficiency coming together

00:01:33,210 --> 00:01:38,270
you've got all sorts of things like

00:01:34,619 --> 00:01:41,250
image compression network compression

00:01:38,270 --> 00:01:43,170
browser efficiency JavaScript efficiency

00:01:41,250 --> 00:01:45,240
all these different sort of things

00:01:43,170 --> 00:01:46,890
coming together to increase this

00:01:45,240 --> 00:01:50,100
real-world efficiency if you think about

00:01:46,890 --> 00:01:51,840
the millions maybe billions of litres of

00:01:50,100 --> 00:01:52,649
petrol that the app has saved since its

00:01:51,840 --> 00:01:55,170
inception

00:01:52,649 --> 00:01:57,630
not to mention driving time you know use

00:01:55,170 --> 00:02:00,479
of frustration wear and tear all that

00:01:57,630 --> 00:02:03,469
sort of thing now the only reason I'm

00:02:00,479 --> 00:02:06,270
saying that is just to illustrate that

00:02:03,469 --> 00:02:07,799
what we do as computer programmers does

00:02:06,270 --> 00:02:09,330
make a difference in the real world and

00:02:07,799 --> 00:02:11,489
sometimes that's not very visible

00:02:09,330 --> 00:02:13,530
that's why conferences like this are

00:02:11,489 --> 00:02:13,830
quite good because they bring all of us

00:02:13,530 --> 00:02:16,020
to

00:02:13,830 --> 00:02:17,420
in a way that we can see each other's

00:02:16,020 --> 00:02:20,160
efforts and that sort of thing

00:02:17,420 --> 00:02:22,130
so a little bit of background about

00:02:20,160 --> 00:02:29,820
myself

00:02:22,130 --> 00:02:32,430
yeah a programmer jokes alright so yeah

00:02:29,820 --> 00:02:36,720
started programming quite really got my

00:02:32,430 --> 00:02:38,760
BSC when I was 21 programmed in some

00:02:36,720 --> 00:02:40,740
legal publishing firms and then quit out

00:02:38,760 --> 00:02:43,140
of that to have a long term illness

00:02:40,740 --> 00:02:45,150
instead and then about three or so years

00:02:43,140 --> 00:02:46,950
ago I decided wanted to get back into

00:02:45,150 --> 00:02:50,640
programming specifically I wanted to

00:02:46,950 --> 00:02:52,740
make some games and I decided I wanted

00:02:50,640 --> 00:02:53,220
to write my own game engine because why

00:02:52,740 --> 00:02:56,510
not

00:02:53,220 --> 00:02:56,510
you should only take a couple of months

00:02:58,040 --> 00:03:04,320
so one year later the game engine is

00:03:02,070 --> 00:03:06,780
finished and obviously I've lost learned

00:03:04,320 --> 00:03:08,640
a lot in the meantime because it had

00:03:06,780 --> 00:03:11,700
been about you know 10 years or so since

00:03:08,640 --> 00:03:14,190
I touched C++ and obviously a lot has

00:03:11,700 --> 00:03:15,750
changed and the first thing I did was I

00:03:14,190 --> 00:03:17,459
went through all the open source game

00:03:15,750 --> 00:03:20,280
engines that were available and kind of

00:03:17,459 --> 00:03:22,140
looked through what they were doing and

00:03:20,280 --> 00:03:24,600
I kept on it coming across this thing

00:03:22,140 --> 00:03:26,489
called Victor now you've got to remember

00:03:24,600 --> 00:03:28,380
that when I completed university the

00:03:26,489 --> 00:03:30,630
standard library was kind of a thing but

00:03:28,380 --> 00:03:32,880
nobody was really using it it wasn't

00:03:30,630 --> 00:03:35,030
that much of a thing so we learned how

00:03:32,880 --> 00:03:38,100
to make linked lists not how to use them

00:03:35,030 --> 00:03:40,830
so this thing Victor kind of went all

00:03:38,100 --> 00:03:42,840
this kind of looks like an extendable

00:03:40,830 --> 00:03:44,400
array of some description looks like it

00:03:42,840 --> 00:03:49,110
could be very useful for games no

00:03:44,400 --> 00:03:50,820
actually kind of not really why is that

00:03:49,110 --> 00:03:53,100
and any game programmer here will know

00:03:50,820 --> 00:03:54,989
sort of some of the workarounds that we

00:03:53,100 --> 00:03:56,760
have for dealing with Victor but just

00:03:54,989 --> 00:03:58,890
for the sake of argument I'll go over

00:03:56,760 --> 00:04:03,690
what are the problems with Victor and

00:03:58,890 --> 00:04:05,450
its default state so crappy erasure

00:04:03,690 --> 00:04:08,340
performance for large amounts of data

00:04:05,450 --> 00:04:11,670
even if you using arrays if then you get

00:04:08,340 --> 00:04:13,890
per frame jitter or if you even if

00:04:11,670 --> 00:04:17,100
you've got small amounts of large data

00:04:13,890 --> 00:04:19,680
so large elements poor insertion

00:04:17,100 --> 00:04:22,800
performance if you're inserting on the

00:04:19,680 --> 00:04:25,560
fly is singly insert invalidates all

00:04:22,800 --> 00:04:27,330
your pointers and iterators it doesn't

00:04:25,560 --> 00:04:30,270
invalidate indexes array

00:04:27,330 --> 00:04:32,669
is invalidates pointers miss erasers and

00:04:30,270 --> 00:04:35,520
indexes to all elements after the erased

00:04:32,669 --> 00:04:37,680
element and it requires a single

00:04:35,520 --> 00:04:41,099
continuous memory block which can be

00:04:37,680 --> 00:04:42,419
problematic depending on RAM limitations

00:04:41,099 --> 00:04:46,500
in your system and that sort of thing

00:04:42,419 --> 00:04:49,080
juda fragmentation so why are all these

00:04:46,500 --> 00:04:51,659
things problematic for games well to go

00:04:49,080 --> 00:04:53,729
into that we first have to analyze what

00:04:51,659 --> 00:04:57,780
is game data in general because it's not

00:04:53,729 --> 00:05:00,360
quite the same as other domains so this

00:04:57,780 --> 00:05:02,039
is stuff that I've garnered a from my

00:05:00,360 --> 00:05:04,590
own experience B from talking to other

00:05:02,039 --> 00:05:06,599
developers C from talking to the SG 14

00:05:04,590 --> 00:05:09,440
group and it seems to be relatively

00:05:06,599 --> 00:05:12,150
consistent the first thing is that

00:05:09,440 --> 00:05:14,009
elements within containers team to

00:05:12,150 --> 00:05:15,030
utilize elements within other containers

00:05:14,009 --> 00:05:18,330
doesn't matter whether you're talking

00:05:15,030 --> 00:05:20,580
about a flat C style array or you know a

00:05:18,330 --> 00:05:22,740
victor or whatever the things are going

00:05:20,580 --> 00:05:24,389
to refer to other things so if you're a

00:05:22,740 --> 00:05:26,819
game programmer you already know if

00:05:24,389 --> 00:05:28,800
you're not then with most games nowadays

00:05:26,819 --> 00:05:31,500
there's some sort of entity component

00:05:28,800 --> 00:05:35,069
system usually combined with a little

00:05:31,500 --> 00:05:37,979
bit of i/o and so you might have your

00:05:35,069 --> 00:05:40,199
base level object an entity and it

00:05:37,979 --> 00:05:42,449
refers to say a sprite and then sound

00:05:40,199 --> 00:05:43,949
and so on and such forth and you're

00:05:42,449 --> 00:05:45,690
going to have multiple instances of

00:05:43,949 --> 00:05:48,629
various different kinds of things like

00:05:45,690 --> 00:05:50,900
walls or enemies or whatever so you're

00:05:48,629 --> 00:05:54,539
not going to want to have those

00:05:50,900 --> 00:05:56,039
resources within the object itself

00:05:54,539 --> 00:05:59,849
you're going to want to refer to them

00:05:56,039 --> 00:06:02,039
otherwise your waste memory etc so any

00:05:59,849 --> 00:06:04,110
container or use of a container which

00:06:02,039 --> 00:06:07,279
invalidates kind of your linkages

00:06:04,110 --> 00:06:09,449
between containers is not going to fly

00:06:07,279 --> 00:06:11,099
by the way throughout this talk I'm

00:06:09,449 --> 00:06:12,659
gonna be going to be using the term

00:06:11,099 --> 00:06:15,750
lengths just as a shorthand way of

00:06:12,659 --> 00:06:18,240
saying iterators slash pointers slash

00:06:15,750 --> 00:06:21,889
indexes basically whatever you're using

00:06:18,240 --> 00:06:24,360
to get one thing to refer to another

00:06:21,889 --> 00:06:27,000
order is unimportant for the most part

00:06:24,360 --> 00:06:29,219
so generally would just got data iterate

00:06:27,000 --> 00:06:31,020
over a transformer this refers to that

00:06:29,219 --> 00:06:32,339
would bring in this stuff goes out to

00:06:31,020 --> 00:06:36,270
the screen and magic happens we have a

00:06:32,339 --> 00:06:38,459
game small to medium sized classes and

00:06:36,270 --> 00:06:40,680
structs are the norm not scalar types

00:06:38,459 --> 00:06:43,100
obviously if you're using a struct

00:06:40,680 --> 00:06:45,900
for a configuration that's the exception

00:06:43,100 --> 00:06:48,270
by the way obviously this is an all game

00:06:45,900 --> 00:06:50,880
data this is just kind of the bulk

00:06:48,270 --> 00:06:53,970
majority of stuff can't generalize too

00:06:50,880 --> 00:06:57,210
much erasing or otherwise deactivating

00:06:53,970 --> 00:06:59,400
objects in real time is common you kill

00:06:57,210 --> 00:07:02,789
an enemy you destroy a wall that thing

00:06:59,400 --> 00:07:05,759
no longer needs to get kind of iterated

00:07:02,789 --> 00:07:07,620
over and creating new objects and adding

00:07:05,759 --> 00:07:08,580
them into a game in real time is also

00:07:07,620 --> 00:07:10,350
common

00:07:08,580 --> 00:07:13,259
so spawning things for example if you

00:07:10,350 --> 00:07:15,570
have a more good then you know player

00:07:13,259 --> 00:07:18,060
pops into an area and you have to add

00:07:15,570 --> 00:07:20,220
stuff in there so basically having some

00:07:18,060 --> 00:07:22,919
kind of extensible container is useful

00:07:20,220 --> 00:07:24,599
more stuff we don't always know in

00:07:22,919 --> 00:07:26,849
advance how many elements there will be

00:07:24,599 --> 00:07:29,400
in a container pre development or

00:07:26,849 --> 00:07:31,410
necessarily during play again for during

00:07:29,400 --> 00:07:33,539
play the Mamaw Pagar example is good

00:07:31,410 --> 00:07:35,610
because you don't know how many players

00:07:33,539 --> 00:07:37,580
are going to be in a particular area and

00:07:35,610 --> 00:07:45,419
that effects the number of creatures and

00:07:37,580 --> 00:07:46,169
what-have-you pre development that's

00:07:45,419 --> 00:07:49,650
pretty obvious

00:07:46,169 --> 00:07:51,599
I mean math you work on a game you're

00:07:49,650 --> 00:07:55,080
refining things you're taking stuff out

00:07:51,599 --> 00:07:56,940
you're putting stuff in etc the number

00:07:55,080 --> 00:07:58,889
of objects that we tend to have in games

00:07:56,940 --> 00:08:01,199
is not what you tend to see on online

00:07:58,889 --> 00:08:03,870
benchmarks so a million integers or

00:08:01,199 --> 00:08:06,120
whatever so for a typical indie game you

00:08:03,870 --> 00:08:07,590
could be looking at maybe a hundred to a

00:08:06,120 --> 00:08:10,199
thousand objects per level if you're

00:08:07,590 --> 00:08:12,680
talking triple-a then I think Mike Acton

00:08:10,199 --> 00:08:15,120
said sunset overdrive used about

00:08:12,680 --> 00:08:18,360
eighty-four thousand objects per game

00:08:15,120 --> 00:08:19,740
level for performance reasons memory

00:08:18,360 --> 00:08:21,539
storage which is more or less contagious

00:08:19,740 --> 00:08:23,909
is preferred I think everybody's gone

00:08:21,539 --> 00:08:25,620
over this enough in previous CP pecans

00:08:23,909 --> 00:08:29,610
that I don't need to go into great

00:08:25,620 --> 00:08:32,279
detail but you know the usual story ram

00:08:29,610 --> 00:08:33,959
speeds have gone like that CPU speeds

00:08:32,279 --> 00:08:36,300
have gone like that and we've got this

00:08:33,959 --> 00:08:38,339
slightly ever widening gap between the

00:08:36,300 --> 00:08:40,380
two which means that we can get

00:08:38,339 --> 00:08:42,089
approximately 200 instructions done in

00:08:40,380 --> 00:08:44,640
the same time as it takes to fetch one

00:08:42,089 --> 00:08:46,500
integer from main memory so the name of

00:08:44,640 --> 00:08:48,000
the game is to get everything into the

00:08:46,500 --> 00:08:50,190
cache and the best way of ensuring that

00:08:48,000 --> 00:08:52,950
everything is in the cache is to have it

00:08:50,190 --> 00:08:54,550
contagious in memory speaking of which

00:08:52,950 --> 00:08:55,870
memory usage and

00:08:54,550 --> 00:08:57,459
constraints are often critical

00:08:55,870 --> 00:08:59,589
considerations so if you're on a closed

00:08:57,459 --> 00:09:01,390
platform that's obvious but even if

00:08:59,589 --> 00:09:04,209
you're on PC you don't know how much

00:09:01,390 --> 00:09:06,610
memory the end user is going to have and

00:09:04,209 --> 00:09:09,519
you don't necessarily yeah necessarily

00:09:06,610 --> 00:09:11,740
know how much RAM they've got left

00:09:09,519 --> 00:09:15,310
whatever applications they've got open

00:09:11,740 --> 00:09:16,810
etc and the last point is that we

00:09:15,310 --> 00:09:19,000
generally don't want containers which

00:09:16,810 --> 00:09:23,500
allocate upon initialization we want

00:09:19,000 --> 00:09:24,910
them to allocate upon first insertion so

00:09:23,500 --> 00:09:25,540
an example of how this could be

00:09:24,910 --> 00:09:28,060
problematic

00:09:25,540 --> 00:09:30,670
would be something like a quadtree using

00:09:28,060 --> 00:09:32,140
that for collision detection and for

00:09:30,670 --> 00:09:35,110
those of you who don't know a quadtree

00:09:32,140 --> 00:09:38,260
tends to be made up of nodes sub nodes

00:09:35,110 --> 00:09:40,750
sub sub nodes etc etc and each of those

00:09:38,260 --> 00:09:44,769
nodes can contain collision blocks or it

00:09:40,750 --> 00:09:47,190
might not so it may just contain sub

00:09:44,769 --> 00:09:50,200
nodes so if you're using something like

00:09:47,190 --> 00:09:53,589
Lib standard C++ as dear complementation

00:09:50,200 --> 00:09:55,930
which allocates upon initialization then

00:09:53,589 --> 00:09:57,730
every time you allocate a node it's also

00:09:55,930 --> 00:09:59,500
going to allocate another chunk of

00:09:57,730 --> 00:10:01,660
memory for the dick regardless of

00:09:59,500 --> 00:10:03,100
whether or not that memory gets used so

00:10:01,660 --> 00:10:05,320
you lose memory but you also lose

00:10:03,100 --> 00:10:09,790
performance because allocating memory is

00:10:05,320 --> 00:10:11,860
problematic so what are some of the more

00:10:09,790 --> 00:10:13,600
common victor workarounds there's a

00:10:11,860 --> 00:10:18,850
whole bunch of them but I just thought

00:10:13,600 --> 00:10:20,500
I'd go into a couple I think Chandler

00:10:18,850 --> 00:10:23,350
Carruth is going to be going into a few

00:10:20,500 --> 00:10:27,399
of them during his talks so you might

00:10:23,350 --> 00:10:29,140
have to eat my hat after that one anyway

00:10:27,399 --> 00:10:30,459
first one using a boolean flag or

00:10:29,140 --> 00:10:33,190
something similar to indicate that

00:10:30,459 --> 00:10:35,200
something's being raised for both of

00:10:33,190 --> 00:10:37,300
these will basically have to use indexes

00:10:35,200 --> 00:10:39,640
to refer to elements within the

00:10:37,300 --> 00:10:42,760
container because pointers will get

00:10:39,640 --> 00:10:45,910
invalidated upon insertion but using a

00:10:42,760 --> 00:10:47,740
boolean flag to indicator Asia the good

00:10:45,910 --> 00:10:49,510
thing about this is that it's really

00:10:47,740 --> 00:10:51,399
fast to raise the bad thing about this

00:10:49,510 --> 00:10:53,230
is that it's actually quite slow to

00:10:51,399 --> 00:10:55,690
iterate over the data and I'll go into

00:10:53,230 --> 00:10:58,589
why that is and second what just up my

00:10:55,690 --> 00:10:58,589
lapel malloc

00:11:00,660 --> 00:11:06,010
second one using a victor of indexes

00:11:04,330 --> 00:11:08,200
referring to a victor of elements so

00:11:06,010 --> 00:11:11,200
you've got your elements ten of them and

00:11:08,200 --> 00:11:14,920
then you've got your vector of indexes 0

00:11:11,200 --> 00:11:18,010
1 2 3 4 5 6 7 8 9 so when you raise your

00:11:14,920 --> 00:11:19,510
raise from the victor of indexes not the

00:11:18,010 --> 00:11:21,250
victor of elements and then when you

00:11:19,510 --> 00:11:23,950
iterate you iterate over the victor of

00:11:21,250 --> 00:11:28,540
indexes to access the elements so say

00:11:23,950 --> 00:11:30,220
you want to arrays element 4 so you get

00:11:28,540 --> 00:11:34,360
rid of that and the victor of indexes so

00:11:30,220 --> 00:11:36,190
it's 0 1 2 3 5 6 7 8 9 and then when you

00:11:34,360 --> 00:11:39,149
iterate over the data it just skips

00:11:36,190 --> 00:11:43,810
element 4 so the good thing about that

00:11:39,149 --> 00:11:45,640
is that it's relatively fast for

00:11:43,810 --> 00:11:49,480
iteration the bad thing about it is that

00:11:45,640 --> 00:11:51,870
it's pretty slow for AirAsia's because

00:11:49,480 --> 00:11:55,029
you still get that reallocation cost

00:11:51,870 --> 00:11:57,730
whenever you do the erasure and the

00:11:55,029 --> 00:12:00,820
vector of indexes neither solution frees

00:11:57,730 --> 00:12:03,160
up memory to the OS so if you keep on

00:12:00,820 --> 00:12:04,990
inserting into and erasing from on the

00:12:03,160 --> 00:12:07,360
fly then you're going to get a gradually

00:12:04,990 --> 00:12:09,160
increasing container size and both of

00:12:07,360 --> 00:12:12,640
them of course have relatively slow

00:12:09,160 --> 00:12:14,080
singular insertion on-the-fly speeds so

00:12:12,640 --> 00:12:16,480
the alternative that i've been working

00:12:14,080 --> 00:12:18,430
on for the past couple years an

00:12:16,480 --> 00:12:22,529
alternative of many definitely not

00:12:18,430 --> 00:12:27,550
saying it's the only alternative

00:12:22,529 --> 00:12:28,870
it's an unordered container sumter a

00:12:27,550 --> 00:12:30,190
permissive zealand license which

00:12:28,870 --> 00:12:31,600
basically means you can use it for

00:12:30,190 --> 00:12:34,180
whatever you can modify it blah blah

00:12:31,600 --> 00:12:37,029
blah so long as you don't pretend that

00:12:34,180 --> 00:12:39,760
you wrote up it never invalidates

00:12:37,029 --> 00:12:42,550
pointers to non erased elements it

00:12:39,760 --> 00:12:45,490
reuses memory from erased elements and

00:12:42,550 --> 00:12:47,680
frees them to the OS performance is

00:12:45,490 --> 00:12:50,020
geared towards small to large classes

00:12:47,680 --> 00:12:52,300
and structs rather than scalar types and

00:12:50,020 --> 00:12:53,980
in the context of all those game data

00:12:52,300 --> 00:12:55,930
requirements as faster than any

00:12:53,980 --> 00:12:58,870
unmodified standard library container

00:12:55,930 --> 00:13:00,670
and I'll go over what its performances

00:12:58,870 --> 00:13:04,360
like compared to the modifications and a

00:13:00,670 --> 00:13:07,240
little bit so what is it sort of

00:13:04,360 --> 00:13:11,490
abstract design uses multiple memory

00:13:07,240 --> 00:13:13,270
blocks which prevents element pointer

00:13:11,490 --> 00:13:15,970
invalidation upon insertion

00:13:13,270 --> 00:13:18,220
the blocks are free to the OS if they

00:13:15,970 --> 00:13:20,200
become empty the blocks must be

00:13:18,220 --> 00:13:22,149
removable with low performance cost and

00:13:20,200 --> 00:13:23,980
without pointers to elements being

00:13:22,149 --> 00:13:28,930
invalidated so for example we couldn't

00:13:23,980 --> 00:13:30,940
use one one way of implementing a dick

00:13:28,930 --> 00:13:32,350
for example is to have a victor of

00:13:30,940 --> 00:13:35,110
memory box and we couldn't do that

00:13:32,350 --> 00:13:36,700
because when you got rid of one of the

00:13:35,110 --> 00:13:38,529
memory blocks all of the other memory

00:13:36,700 --> 00:13:40,990
blocks would reallocate so you get

00:13:38,529 --> 00:13:45,120
reallocation cost and also you get those

00:13:40,990 --> 00:13:47,500
pointers being invalidated it also

00:13:45,120 --> 00:13:50,290
records all the erased elements in a

00:13:47,500 --> 00:13:54,339
skip field and the skip field design

00:13:50,290 --> 00:13:56,290
itself must have allow for rather zero

00:13:54,339 --> 00:14:00,310
one time complexity plus plus and minus

00:13:56,290 --> 00:14:02,459
most operations so my specific

00:14:00,310 --> 00:14:04,300
implementation of this at the moment

00:14:02,459 --> 00:14:05,980
uses what I call a chain group

00:14:04,300 --> 00:14:08,830
allocation pattern but you could also

00:14:05,980 --> 00:14:11,260
call it a doubly-linked intrusive list

00:14:08,830 --> 00:14:13,959
of nodes I prefer not to use the ten

00:14:11,260 --> 00:14:15,580
nodes or linked lists because when I

00:14:13,959 --> 00:14:17,860
think about that I think about singular

00:14:15,580 --> 00:14:19,410
elements rather than collections but it

00:14:17,860 --> 00:14:23,050
doesn't actually matter it's all just

00:14:19,410 --> 00:14:25,839
nomenclature these contain memory blocks

00:14:23,050 --> 00:14:28,600
block metadata and skip fields I use

00:14:25,839 --> 00:14:31,300
peel if stack which is my own stack

00:14:28,600 --> 00:14:35,079
implementation for recording and reusing

00:14:31,300 --> 00:14:38,680
a raised element locations and I've

00:14:35,079 --> 00:14:40,240
developed a basically a generic numeric

00:14:38,680 --> 00:14:42,459
pattern called a jump counting skip

00:14:40,240 --> 00:14:46,000
field which enables zero one time

00:14:42,459 --> 00:14:50,260
complexity iterator operations so go

00:14:46,000 --> 00:14:52,540
into each of those very briefly so the

00:14:50,260 --> 00:14:55,570
good thing about having a sort of linked

00:14:52,540 --> 00:14:57,250
list kind of format for memory blocks as

00:14:55,570 --> 00:14:59,880
opposed to something like a vector of

00:14:57,250 --> 00:15:02,880
pointers or whatever is that it makes

00:14:59,880 --> 00:15:05,770
releasing the memory blocks very quick

00:15:02,880 --> 00:15:09,790
you don't get that reallocation cost and

00:15:05,770 --> 00:15:11,050
you don't give any pointer problems for

00:15:09,790 --> 00:15:12,579
example if you're doing a vector of

00:15:11,050 --> 00:15:14,529
memory blocks rather than pointers to

00:15:12,579 --> 00:15:16,690
memory blocks there's a growth factor of

00:15:14,529 --> 00:15:19,540
two but you could use anything typically

00:15:16,690 --> 00:15:21,490
and the minimum and maximum group sizes

00:15:19,540 --> 00:15:23,320
are customizable so for example if you

00:15:21,490 --> 00:15:26,240
use the size of your keishon you need

00:15:23,320 --> 00:15:28,279
the size of your elements then you could

00:15:26,240 --> 00:15:31,820
set your minimum and maximum sizes to

00:15:28,279 --> 00:15:33,610
the same amount and have them fit onto

00:15:31,820 --> 00:15:36,770
the case a little bit better or whatever

00:15:33,610 --> 00:15:40,820
peel if stack it's basically just a

00:15:36,770 --> 00:15:42,980
faster stack implementation so faster

00:15:40,820 --> 00:15:45,920
than any standard library container in

00:15:42,980 --> 00:15:49,010
set context for non scalar types and for

00:15:45,920 --> 00:15:50,959
large numbers of scalar types regardless

00:15:49,010 --> 00:15:53,990
of Kampala and that includes vector and

00:15:50,959 --> 00:15:55,970
Dec of course the performance advantage

00:15:53,990 --> 00:15:58,190
over the standard library components

00:15:55,970 --> 00:16:01,459
increases with the size of the element

00:15:58,190 --> 00:16:04,070
being stored also uses that chain group

00:16:01,459 --> 00:16:09,680
allocation pattern minimum and maximum

00:16:04,070 --> 00:16:11,240
group sizes are also customizable so so

00:16:09,680 --> 00:16:14,810
for all of the benchmarks that I'm going

00:16:11,240 --> 00:16:18,459
to be presenting today vertical scale is

00:16:14,810 --> 00:16:21,140
duration in microseconds less is better

00:16:18,459 --> 00:16:23,350
horizontal scale is number of elements

00:16:21,140 --> 00:16:26,330
in the container so here we're comparing

00:16:23,350 --> 00:16:29,600
PLF stack versus standard vector there's

00:16:26,330 --> 00:16:33,350
a standard stack under GCC this is total

00:16:29,600 --> 00:16:35,810
time so this time to push all of the

00:16:33,350 --> 00:16:44,660
elements into the container and then pop

00:16:35,810 --> 00:16:46,820
them all off and read each of them also

00:16:44,660 --> 00:16:47,240
for all of the tests that I'm doing

00:16:46,820 --> 00:16:49,490
today

00:16:47,240 --> 00:16:52,579
I'm just using small struts if you want

00:16:49,490 --> 00:16:55,070
to seed results for scalar types or

00:16:52,579 --> 00:16:57,110
large structs go to the website although

00:16:55,070 --> 00:16:58,910
I need to update the benchmarks on there

00:16:57,110 --> 00:17:00,550
because there in that day should be from

00:16:58,910 --> 00:17:05,329
the beginning of the year

00:17:00,550 --> 00:17:11,420
this is GCC 5 on the same platform same

00:17:05,329 --> 00:17:13,880
OS this is M SVC 2015 so PL if stack

00:17:11,420 --> 00:17:14,510
performance doesn't change match the

00:17:13,880 --> 00:17:18,050
other ones

00:17:14,510 --> 00:17:22,160
quite a bit so for the rest of the test

00:17:18,050 --> 00:17:24,800
I'm going to be using GCC so how does it

00:17:22,160 --> 00:17:28,550
get used in colony basically when

00:17:24,800 --> 00:17:31,400
something gets are raised the memory

00:17:28,550 --> 00:17:33,830
location for that element gets pushed

00:17:31,400 --> 00:17:35,960
onto the stack the next time the colony

00:17:33,830 --> 00:17:38,360
has an insertion happen the chicks that

00:17:35,960 --> 00:17:39,860
stack if the stack is empty then it just

00:17:38,360 --> 00:17:42,049
inserts to the back of the

00:17:39,860 --> 00:17:44,269
if it's not empty then it pops a

00:17:42,049 --> 00:17:47,990
location off the stack and it reuses it

00:17:44,269 --> 00:17:49,490
hence the container is unordered because

00:17:47,990 --> 00:17:51,500
you don't know where in the container

00:17:49,490 --> 00:17:57,230
that element that you insert it's going

00:17:51,500 --> 00:17:58,879
to end up so now I'm just going to go

00:17:57,230 --> 00:18:00,730
into jump counting skip filled pattern

00:17:58,879 --> 00:18:04,570
but before I do that I have to describe

00:18:00,730 --> 00:18:06,470
why I can't use a boolean skip filled

00:18:04,570 --> 00:18:07,759
instead of something else because

00:18:06,470 --> 00:18:10,309
boolean skip fields are kind of

00:18:07,759 --> 00:18:12,590
convenient and simple

00:18:10,309 --> 00:18:15,049
the main problem in terms of the

00:18:12,590 --> 00:18:16,639
standard is that if you're using a

00:18:15,049 --> 00:18:20,679
boolean skip field then it makes your

00:18:16,639 --> 00:18:23,450
iteration time complexity Oh random so

00:18:20,679 --> 00:18:27,379
if you imagine you've got your skip

00:18:23,450 --> 00:18:31,309
field 0 0 1 1 1 0 0 1 1 1 1 1 whatever

00:18:27,379 --> 00:18:33,320
between any two non raised elements you

00:18:31,309 --> 00:18:35,330
don't actually know in advance how many

00:18:33,320 --> 00:18:37,970
raised elements there's going to be in

00:18:35,330 --> 00:18:43,190
between them and that means that when

00:18:37,970 --> 00:18:44,419
you go plus plus it might have 50 skip

00:18:43,190 --> 00:18:46,070
filled nodes that it needs to check

00:18:44,419 --> 00:18:48,049
before it finds the next non raised

00:18:46,070 --> 00:18:51,440
element or it might have one or it might

00:18:48,049 --> 00:18:54,440
have 0 etc so the standard says we can't

00:18:51,440 --> 00:18:56,659
have them have to have 0 1 operations on

00:18:54,440 --> 00:18:57,980
our iterators so can't do that but the

00:18:56,659 --> 00:19:00,350
actual real problem with it

00:18:57,980 --> 00:19:04,840
is that each of those checks on each of

00:19:00,350 --> 00:19:08,840
those boolean nodes is a branching op so

00:19:04,840 --> 00:19:10,549
depending on how many ages you have you

00:19:08,840 --> 00:19:12,759
can have very good performance or you

00:19:10,549 --> 00:19:15,440
can have really really bad performance

00:19:12,759 --> 00:19:19,720
and it makes your code entirely

00:19:15,440 --> 00:19:21,769
dependent on CPU branch prediction and

00:19:19,720 --> 00:19:23,360
the other thing of course is that

00:19:21,769 --> 00:19:25,730
generally when we're doing a boolean

00:19:23,360 --> 00:19:27,440
skip field unless we're getting really

00:19:25,730 --> 00:19:29,570
specialized we don't tend to do a bit

00:19:27,440 --> 00:19:31,759
field because that fields are slower

00:19:29,570 --> 00:19:38,360
than byte level addressing so we end up

00:19:31,759 --> 00:19:40,879
wasting memory as well so jump counting

00:19:38,360 --> 00:19:44,649
skip field pattern Council jumps ie the

00:19:40,879 --> 00:19:47,869
number of consecutive arrays elements

00:19:44,649 --> 00:19:49,369
the updating of the field in terms of

00:19:47,869 --> 00:19:50,210
the mathematics and the programming is

00:19:49,369 --> 00:19:51,799
very efficient

00:19:50,210 --> 00:19:53,760
there's no branching code for the

00:19:51,799 --> 00:19:57,030
iteration

00:19:53,760 --> 00:19:59,220
so the iteration code becomes a lot

00:19:57,030 --> 00:20:02,730
simpler the erasure and insertion code

00:19:59,220 --> 00:20:05,550
becomes a little bit more complex so

00:20:02,730 --> 00:20:08,280
this allows for time complexity oh one

00:20:05,550 --> 00:20:11,310
operations on your iterator we're going

00:20:08,280 --> 00:20:12,960
to go into it a little bit but you know

00:20:11,310 --> 00:20:15,390
we don't have a couple of hours for me

00:20:12,960 --> 00:20:17,910
to totally boy you so if you want to

00:20:15,390 --> 00:20:19,770
know like the entire algorithms and the

00:20:17,910 --> 00:20:21,510
whole thing there's a seven thousand

00:20:19,770 --> 00:20:23,850
word paper on my website you can go

00:20:21,510 --> 00:20:25,050
there and read through it and I promise

00:20:23,850 --> 00:20:29,610
you by the end of it you will be

00:20:25,050 --> 00:20:33,270
thoroughly bored so just a little bit of

00:20:29,610 --> 00:20:35,240
benchmarking so this is comparing PLF

00:20:33,270 --> 00:20:37,650
colony using a jump counting skip field

00:20:35,240 --> 00:20:38,880
versus their victor work around with the

00:20:37,650 --> 00:20:41,700
boolean skip field that we talked about

00:20:38,880 --> 00:20:44,370
earlier versus a colony using a boolean

00:20:41,700 --> 00:20:47,340
skip field so this is prior to any

00:20:44,370 --> 00:20:48,960
Erasers happening in the container and

00:20:47,340 --> 00:20:51,450
you can see that victor is doing a

00:20:48,960 --> 00:20:54,560
little better the boolean colony is

00:20:51,450 --> 00:20:56,880
doing a little bit worse so let's erase

00:20:54,560 --> 00:21:00,120
25% of all of the elements and the

00:20:56,880 --> 00:21:05,160
container randomly and see what happens

00:21:00,120 --> 00:21:07,260
to the iteration speed so suddenly kill

00:21:05,160 --> 00:21:10,230
colony is doing a little bit better and

00:21:07,260 --> 00:21:12,780
the tool to boolean implementations are

00:21:10,230 --> 00:21:15,600
doing much worse so let's jump that up

00:21:12,780 --> 00:21:20,910
to 50% of all elements in the container

00:21:15,600 --> 00:21:22,710
are erased at random unsurprisingly the

00:21:20,910 --> 00:21:27,150
other two get worse again now let's go

00:21:22,710 --> 00:21:29,070
up to 75% somewhat surprisingly the

00:21:27,150 --> 00:21:31,320
other two do better in this context than

00:21:29,070 --> 00:21:37,680
they did at 50% would anybody like to

00:21:31,320 --> 00:21:41,910
hazard a guess why yeah exactly so if we

00:21:37,680 --> 00:21:43,140
go back a little bit 0% erasures all of

00:21:41,910 --> 00:21:45,750
these skip fields are just a bunch of

00:21:43,140 --> 00:21:48,030
zeros so the cpu branch prediction works

00:21:45,750 --> 00:21:49,650
perfectly and the boolean

00:21:48,030 --> 00:21:50,370
implementations can actually do pretty

00:21:49,650 --> 00:21:53,780
darn well

00:21:50,370 --> 00:21:55,950
once you get up to 25% erasures then

00:21:53,780 --> 00:21:59,250
basically you've got a one in four

00:21:55,950 --> 00:22:00,810
chance of acacia mass at 50% basically

00:21:59,250 --> 00:22:02,550
the branch prediction can't work at all

00:22:00,810 --> 00:22:06,540
because it's just getting a completely

00:22:02,550 --> 00:22:07,290
random stream of zeros and ones and at

00:22:06,540 --> 00:22:09,690
00:22:07,290 --> 00:22:13,020
since you go back to having one in four

00:22:09,690 --> 00:22:15,450
chunk chance of vacation us again so

00:22:13,020 --> 00:22:21,270
that's basically why boolean Schofield

00:22:15,450 --> 00:22:22,680
suck so so comparison between jump

00:22:21,270 --> 00:22:26,970
carrying Schofield the format and

00:22:22,680 --> 00:22:28,500
boolean Schofield so basically the

00:22:26,970 --> 00:22:30,810
equivalent jump counting skip field is

00:22:28,500 --> 00:22:34,050
on the right the first thing you'll

00:22:30,810 --> 00:22:36,930
notice is that no singular erasers are

00:22:34,050 --> 00:22:38,100
exactly the same this day as ones once

00:22:36,930 --> 00:22:40,170
you've got a couple in the road that

00:22:38,100 --> 00:22:41,820
become - - once you get more than that

00:22:40,170 --> 00:22:43,800
you get this sort of increment by one

00:22:41,820 --> 00:22:46,230
notation where the first number

00:22:43,800 --> 00:22:48,660
describes how many consecutive erasers

00:22:46,230 --> 00:22:50,670
there are so does the last number and in

00:22:48,660 --> 00:22:52,290
between you get a two three or two three

00:22:50,670 --> 00:22:58,050
four or what-have-you depending on the

00:22:52,290 --> 00:22:59,760
size of the Schofield block so I'm just

00:22:58,050 --> 00:23:02,310
using the term Schofield block to refer

00:22:59,760 --> 00:23:06,420
to any number of consecutive roast

00:23:02,310 --> 00:23:09,660
elements how is this useful okay so for

00:23:06,420 --> 00:23:11,910
a boolean Schofield has to check every

00:23:09,660 --> 00:23:13,800
single field for the jump counting skip

00:23:11,910 --> 00:23:15,930
field goes zero zero three jump three

00:23:13,800 --> 00:23:17,820
zero zero four jump four etc obviously

00:23:15,930 --> 00:23:20,820
if you're going in Reverse then you're

00:23:17,820 --> 00:23:22,380
doing exactly the same thing and you

00:23:20,820 --> 00:23:24,240
might be asking well that's fine but

00:23:22,380 --> 00:23:26,790
what about you know the two three in the

00:23:24,240 --> 00:23:30,330
middle there what's that useful for that

00:23:26,790 --> 00:23:32,670
comes into play when you're reinserting

00:23:30,330 --> 00:23:35,160
back into the colony later on earlier I

00:23:32,670 --> 00:23:36,690
talked about you push the location to

00:23:35,160 --> 00:23:38,400
the stack and pop it back off and reuse

00:23:36,690 --> 00:23:41,460
it that's what that's for

00:23:38,400 --> 00:23:44,610
but I'll get into that in a bit so

00:23:41,460 --> 00:23:47,610
comparison of iteration code so in this

00:23:44,610 --> 00:23:50,190
context we're looking at the Skip field

00:23:47,610 --> 00:23:53,970
being separate to the memory block for

00:23:50,190 --> 00:23:55,740
the elements which may not be all may

00:23:53,970 --> 00:23:57,930
not be implemented that way in all cases

00:23:55,740 --> 00:23:59,970
but just for the sake of argument we're

00:23:57,930 --> 00:24:02,100
doing it that way in this case so you

00:23:59,970 --> 00:24:04,200
have your pointer to your element and

00:24:02,100 --> 00:24:07,080
your pointer to the Skip field node

00:24:04,200 --> 00:24:08,640
associated with that element and if

00:24:07,080 --> 00:24:10,860
you're doing a boolean skip field then

00:24:08,640 --> 00:24:13,410
you just increment both of those check

00:24:10,860 --> 00:24:15,120
the Skip field node and if it's one then

00:24:13,410 --> 00:24:17,670
you loop it again a loop again until

00:24:15,120 --> 00:24:20,640
such point as you reach a non raised

00:24:17,670 --> 00:24:23,460
element for jump counting skip field

00:24:20,640 --> 00:24:25,350
you did the same thing you add one to

00:24:23,460 --> 00:24:27,840
the element point in the skip field

00:24:25,350 --> 00:24:31,110
pointer and then you just add the value

00:24:27,840 --> 00:24:32,550
at the skip field node to both the

00:24:31,110 --> 00:24:36,930
element pointer and the skip field

00:24:32,550 --> 00:24:39,440
pointer so there's no branching so

00:24:36,930 --> 00:24:42,750
arisia from the jump counting skip field

00:24:39,440 --> 00:24:46,290
in this case where the arrow is is

00:24:42,750 --> 00:24:48,180
basically to denote the Skip field node

00:24:46,290 --> 00:24:50,730
associated with the element which we

00:24:48,180 --> 00:24:53,580
want to erase so the first thing that we

00:24:50,730 --> 00:24:56,430
have to do is check the nodes to the

00:24:53,580 --> 00:25:01,890
left and the right of the skip field

00:24:56,430 --> 00:25:03,720
node and basically there's four cases

00:25:01,890 --> 00:25:07,470
which resolve down to a single switch

00:25:03,720 --> 00:25:09,120
statement if both of them both of the

00:25:07,470 --> 00:25:11,220
left hand and the right hand node are

00:25:09,120 --> 00:25:13,050
zero then that means there's no

00:25:11,220 --> 00:25:16,650
consecutive erased elements we just set

00:25:13,050 --> 00:25:18,990
the field node to one second example if

00:25:16,650 --> 00:25:21,030
only the left hand node is nonzero that

00:25:18,990 --> 00:25:22,740
means that we're at the end of a skip

00:25:21,030 --> 00:25:24,960
field block and we update the block on

00:25:22,740 --> 00:25:27,360
that basis similarly if for the third

00:25:24,960 --> 00:25:29,910
one if only the right hand node is

00:25:27,360 --> 00:25:31,770
nonzero that means that we're at the

00:25:29,910 --> 00:25:34,560
beginning of skip field block we update

00:25:31,770 --> 00:25:35,280
the block on that basis and if both are

00:25:34,560 --> 00:25:37,380
nonzero

00:25:35,280 --> 00:25:39,840
that means we're in between to skip

00:25:37,380 --> 00:25:43,940
field blocks and we basically join the

00:25:39,840 --> 00:25:46,800
two blocks and update them on that basis

00:25:43,940 --> 00:25:48,930
similarly for reinsertion so this is

00:25:46,800 --> 00:25:51,900
where we're popping a memory location

00:25:48,930 --> 00:25:55,830
off the stack and reusing it upon

00:25:51,900 --> 00:25:59,570
insertion so in this case the arrow

00:25:55,830 --> 00:26:01,860
corresponds to the skip field node

00:25:59,570 --> 00:26:04,470
associated with the memory location

00:26:01,860 --> 00:26:05,400
which we want to reuse so if both left

00:26:04,470 --> 00:26:09,210
and right are 0

00:26:05,400 --> 00:26:12,750
it's just a single raised element no

00:26:09,210 --> 00:26:15,540
consecutive raises set it to 0 if only

00:26:12,750 --> 00:26:16,950
the left hand node is nonzero we're at

00:26:15,540 --> 00:26:19,080
the end of the block we update the block

00:26:16,950 --> 00:26:20,910
on that basis if the right one is

00:26:19,080 --> 00:26:23,640
nonzero we're at the beginning of the

00:26:20,910 --> 00:26:25,680
block updated on that basis if both left

00:26:23,640 --> 00:26:27,960
and right are nonzero this is where that

00:26:25,680 --> 00:26:30,630
increment by one notation comes into

00:26:27,960 --> 00:26:34,470
play so in the bottom example there the

00:26:30,630 --> 00:26:37,049
3 indicates how far we are away

00:26:34,470 --> 00:26:39,630
to the left from the first non raised

00:26:37,049 --> 00:26:41,280
element and with that information we can

00:26:39,630 --> 00:26:43,380
find the start of the skip field block

00:26:41,280 --> 00:26:45,480
and when we know the start of the skip

00:26:43,380 --> 00:26:47,880
field block we also know how many

00:26:45,480 --> 00:26:50,309
numbers sorry how many elements are in

00:26:47,880 --> 00:26:52,440
the skip field block and we can split

00:26:50,309 --> 00:26:56,340
the Schofield block on that basis and

00:26:52,440 --> 00:26:58,500
update into two blocks again if you want

00:26:56,340 --> 00:27:02,549
to see all the boring mouths look at the

00:26:58,500 --> 00:27:04,620
paper so that's all very useful when now

00:27:02,549 --> 00:27:05,400
you vaguely know how a colony works and

00:27:04,620 --> 00:27:07,830
all that jazz

00:27:05,400 --> 00:27:10,620
how does it perform so we're going to

00:27:07,830 --> 00:27:14,520
have a deaf match gonna start with just

00:27:10,620 --> 00:27:15,929
raw performance comparing against just

00:27:14,520 --> 00:27:18,510
standard library containers and we're

00:27:15,929 --> 00:27:21,240
not going to worry about all those pesky

00:27:18,510 --> 00:27:25,710
game requirements like keeping all our

00:27:21,240 --> 00:27:29,100
links valid and that sort of jazz so I

00:27:25,710 --> 00:27:31,559
haven't included some of the C++ 11 long

00:27:29,100 --> 00:27:34,220
ones like unordered map because the

00:27:31,559 --> 00:27:37,799
performance difference wasn't that great

00:27:34,220 --> 00:27:40,590
so I'm gonna start with just inserting

00:27:37,799 --> 00:27:42,600
singly a whole bunch of times into each

00:27:40,590 --> 00:27:44,730
of the containers measuring that and

00:27:42,600 --> 00:27:48,000
that's just to measure sort of on the

00:27:44,730 --> 00:27:51,929
fly insertion performance then going to

00:27:48,000 --> 00:27:54,179
arrays from each of the containers 25%

00:27:51,929 --> 00:27:56,880
of all elements at random and then we're

00:27:54,179 --> 00:28:02,780
going to iterate over the data so not

00:27:56,880 --> 00:28:06,809
terribly real world but just ok so

00:28:02,780 --> 00:28:10,559
insertion performance map multi suit

00:28:06,809 --> 00:28:14,120
most not doing so great Victor doing ok

00:28:10,559 --> 00:28:16,890
colony and dick doing pretty well

00:28:14,120 --> 00:28:18,720
yeah Lib standard C++ as dick

00:28:16,890 --> 00:28:20,940
implementation is pretty good so

00:28:18,720 --> 00:28:22,890
logarithmic scale we see a little bit of

00:28:20,940 --> 00:28:25,370
a crunch there between 100 and 1000

00:28:22,890 --> 00:28:27,780
elements victor starts to look alright

00:28:25,370 --> 00:28:30,590
but for the rest of it it's more or less

00:28:27,780 --> 00:28:33,470
dick and colony doing very well

00:28:30,590 --> 00:28:36,539
so erasure performance linear scale

00:28:33,470 --> 00:28:39,419
obviously this isn't terribly useful the

00:28:36,539 --> 00:28:43,320
two standing out there dick and victor

00:28:39,419 --> 00:28:46,049
without using the remover formulation so

00:28:43,320 --> 00:28:48,060
we'll go to the logarithmic scale so

00:28:46,049 --> 00:28:50,430
dick and victor without using remove

00:28:48,060 --> 00:28:52,890
in this particular context not very good

00:28:50,430 --> 00:28:56,130
would remove F more or less on a power

00:28:52,890 --> 00:28:59,750
of colony map and Maltese it don't do

00:28:56,130 --> 00:29:02,130
too well analyst does pretty well

00:28:59,750 --> 00:29:05,280
iteration performance here we see more

00:29:02,130 --> 00:29:08,550
CC at map and list sucking wildly the

00:29:05,280 --> 00:29:11,430
others doing pretty well so if we go to

00:29:08,550 --> 00:29:13,770
the logarithmic scale colony is doing

00:29:11,430 --> 00:29:15,240
well but not as well as dick or Victor

00:29:13,770 --> 00:29:19,560
and we see a pretty weird thing

00:29:15,240 --> 00:29:21,750
happening with list and I in quiet

00:29:19,560 --> 00:29:24,000
around on the GCC forums and the general

00:29:21,750 --> 00:29:27,810
consensus was and this was basically

00:29:24,000 --> 00:29:30,210
validated by further testing because

00:29:27,810 --> 00:29:31,980
list iteration is essentially very

00:29:30,210 --> 00:29:34,710
simple it's just follow this point of

00:29:31,980 --> 00:29:37,740
follow this pointer as long as all of

00:29:34,710 --> 00:29:39,570
your list data is in the cache then that

00:29:37,740 --> 00:29:42,150
iteration speed can actually be very

00:29:39,570 --> 00:29:43,830
fast but unfortunately once you get

00:29:42,150 --> 00:29:46,290
competition for the cache or once your

00:29:43,830 --> 00:29:48,540
data no longer entirely fits within the

00:29:46,290 --> 00:29:50,550
cache then your performance starts to

00:29:48,540 --> 00:29:52,800
get quite bad so the other tests I did

00:29:50,550 --> 00:29:54,600
we're just increasing and decreasing the

00:29:52,800 --> 00:29:56,820
size of the element being stored and

00:29:54,600 --> 00:30:02,040
that sort of lip goes up and down

00:29:56,820 --> 00:30:04,260
accordingly so who won that round Colony

00:30:02,040 --> 00:30:07,230
had good insertion excellent erasure

00:30:04,260 --> 00:30:09,330
speed reasonable iteration speed victor

00:30:07,230 --> 00:30:11,430
had poor insertion speed poor Asia

00:30:09,330 --> 00:30:14,010
without remover for good with removeth

00:30:11,430 --> 00:30:15,560
an excellent iteration speed dick pretty

00:30:14,010 --> 00:30:18,990
much the same as Victor it sipped

00:30:15,560 --> 00:30:23,220
not quite as good for iteration and it

00:30:18,990 --> 00:30:26,430
has a good insertion speed so whoops

00:30:23,220 --> 00:30:28,350
skips one so next round we're going to

00:30:26,430 --> 00:30:31,890
start worrying about those pesky game

00:30:28,350 --> 00:30:33,510
requirements so here we're using those

00:30:31,890 --> 00:30:35,370
two victor workarounds that we talked

00:30:33,510 --> 00:30:40,020
about earlier a victor with the boolean

00:30:35,370 --> 00:30:41,670
scope field and a index victor of index

00:30:40,020 --> 00:30:44,640
is referring to a victor of elements

00:30:41,670 --> 00:30:46,260
we're going to do sort of a similar

00:30:44,640 --> 00:30:48,680
thing with dick we're going to have a

00:30:46,260 --> 00:30:54,120
dick with a boolean skip field and

00:30:48,680 --> 00:30:56,670
basically a dick of pointers referring

00:30:54,120 --> 00:30:58,110
to a dick of elements and the reason we

00:30:56,670 --> 00:30:59,910
can do that with dick

00:30:58,110 --> 00:31:01,420
whereas we can't with Victor is because

00:30:59,910 --> 00:31:07,120
dick doesn't and Val

00:31:01,420 --> 00:31:10,990
date pointers upon insertion so same

00:31:07,120 --> 00:31:13,480
tests insertion speed obviously the

00:31:10,990 --> 00:31:16,120
victor ones not doing as well colony and

00:31:13,480 --> 00:31:18,250
pointer dick more or less Nick Nick and

00:31:16,120 --> 00:31:20,410
the boolean dick is doing quite a bit

00:31:18,250 --> 00:31:24,070
better because essentially it's got less

00:31:20,410 --> 00:31:26,020
to insert it's a lot simpler erasure

00:31:24,070 --> 00:31:28,240
speed logarithmic scale

00:31:26,020 --> 00:31:31,630
so again without remover fraught so

00:31:28,240 --> 00:31:34,120
great with remover dick the index Victor

00:31:31,630 --> 00:31:36,640
and pointer dick approach more or less

00:31:34,120 --> 00:31:39,130
on a power of colony depending on how

00:31:36,640 --> 00:31:42,060
many elements there are and the boolean

00:31:39,130 --> 00:31:44,620
dick and the boolean vector approach

00:31:42,060 --> 00:31:48,780
both are the best simply because you're

00:31:44,620 --> 00:31:48,780
just flicking about so much faster

00:31:48,840 --> 00:31:53,770
iteration speed no surprises there the

00:31:51,670 --> 00:31:55,930
boolean approaches don't do so well

00:31:53,770 --> 00:31:58,210
after you have arrays 25% of all the

00:31:55,930 --> 00:32:00,400
elements colony doing pretty well but

00:31:58,210 --> 00:32:03,940
again not as good as index vector or

00:32:00,400 --> 00:32:06,340
pointer deck so we pretty much had the

00:32:03,940 --> 00:32:08,350
same winners for the second round but

00:32:06,340 --> 00:32:13,420
we've just disqualified the boolean

00:32:08,350 --> 00:32:16,420
workarounds essentially so up until this

00:32:13,420 --> 00:32:19,750
point all of the tests have been you

00:32:16,420 --> 00:32:22,030
know relatively non real-world fairly

00:32:19,750 --> 00:32:25,180
what you'd see on online benchmarks and

00:32:22,030 --> 00:32:34,240
that sort of thing so we're going to try

00:32:25,180 --> 00:32:35,880
doing slightly more real-world tests so

00:32:34,240 --> 00:32:39,820
we're going to take each of these

00:32:35,880 --> 00:32:43,090
containers and we're going to vaguely

00:32:39,820 --> 00:32:45,790
simulate simulate thirty minutes of game

00:32:43,090 --> 00:32:49,240
time so one hundred and eight thousand

00:32:45,790 --> 00:32:51,040
frames assuming 60 frames a second which

00:32:49,240 --> 00:32:55,690
is somewhere halfway in between average

00:32:51,040 --> 00:32:57,970
gaming time for mobile NPC we're going

00:32:55,690 --> 00:33:00,010
to basically iterate over the data in

00:32:57,970 --> 00:33:05,250
each of the containers for every frame

00:33:00,010 --> 00:33:06,790
and at random during each minute so each

00:33:05,250 --> 00:33:08,650
3,600 frames

00:33:06,790 --> 00:33:11,830
we're going to arrays and insert at

00:33:08,650 --> 00:33:15,220
random one percent of all the elements

00:33:11,830 --> 00:33:17,320
in each of the containers and then we're

00:33:15,220 --> 00:33:20,230
increase that 5% and then we're going to

00:33:17,320 --> 00:33:23,140
increase that timber see now this may

00:33:20,230 --> 00:33:25,780
not match all use cases obviously some

00:33:23,140 --> 00:33:27,970
games have much less things coming into

00:33:25,780 --> 00:33:31,120
play and being raised or whatever some

00:33:27,970 --> 00:33:33,070
of them have more but it really depends

00:33:31,120 --> 00:33:37,059
on the karmic tot that type of game that

00:33:33,070 --> 00:33:40,090
you've got so so this is just the total

00:33:37,059 --> 00:33:42,850
time taken so the total duration time to

00:33:40,090 --> 00:33:44,679
simulate that half an hour of game time

00:33:42,850 --> 00:33:47,440
so we see here with one percent

00:33:44,679 --> 00:33:49,659
modification Colony not really doing so

00:33:47,440 --> 00:33:50,650
well it's got a little bit of a bump

00:33:49,659 --> 00:33:52,409
there in the middle which I haven't

00:33:50,650 --> 00:33:55,030
quite worked out yet but I am going to

00:33:52,409 --> 00:33:57,520
we can also see that the remover

00:33:55,030 --> 00:33:59,950
variants aren't doing so well which is

00:33:57,520 --> 00:34:03,100
fairly obvious because basically with

00:33:59,950 --> 00:34:06,669
either got 1 or 0 Eurasia's happening

00:34:03,100 --> 00:34:10,359
per frame generally speaking let's see

00:34:06,669 --> 00:34:11,889
what's happening with memory so we can

00:34:10,359 --> 00:34:14,740
see that colony is doing a bit better

00:34:11,889 --> 00:34:17,520
than the vector approach but not by that

00:34:14,740 --> 00:34:20,560
much but it's more or less on a par with

00:34:17,520 --> 00:34:24,490
point a deck in terms of memory usage so

00:34:20,560 --> 00:34:26,889
at 1% modification per minute probably

00:34:24,490 --> 00:34:28,419
not going to look at colony at least not

00:34:26,889 --> 00:34:32,609
for a half an hour of gameplay

00:34:28,419 --> 00:34:35,349
so let's bump it up to 5% modification

00:34:32,609 --> 00:34:38,429
so suddenly we see beyond a certain

00:34:35,349 --> 00:34:41,320
number of elements the other

00:34:38,429 --> 00:34:44,409
implementations of container workarounds

00:34:41,320 --> 00:34:47,710
start to suffer a little bit this colony

00:34:44,409 --> 00:34:49,419
stays pretty much consistent and what's

00:34:47,710 --> 00:34:50,649
happening in memory is at this point

00:34:49,419 --> 00:34:52,780
because the vector and deck

00:34:50,649 --> 00:34:58,030
implementations can't actually arrays

00:34:52,780 --> 00:35:00,880
from their containers with or free up

00:34:58,030 --> 00:35:04,180
their data without invalidating pointers

00:35:00,880 --> 00:35:06,369
or indexes so they've just got

00:35:04,180 --> 00:35:08,170
insertions happening raisers happening

00:35:06,369 --> 00:35:11,050
and the containers are just gradually

00:35:08,170 --> 00:35:12,940
growing so at 5%

00:35:11,050 --> 00:35:14,619
both of those implementations are using

00:35:12,940 --> 00:35:16,869
twice as much memory as colony and

00:35:14,619 --> 00:35:19,420
that's consistent what's the logarithmic

00:35:16,869 --> 00:35:21,670
scale that's consistent all the way back

00:35:19,420 --> 00:35:23,560
regardless of however many elements

00:35:21,670 --> 00:35:25,900
you've got in your container after half

00:35:23,560 --> 00:35:27,310
an hour colony's going to be using half

00:35:25,900 --> 00:35:28,870
as much memory just because of that

00:35:27,310 --> 00:35:30,790
element location we

00:35:28,870 --> 00:35:34,300
cycling in the freeing up of blocks so

00:35:30,790 --> 00:35:36,640
jumping up to 10% you can see that the

00:35:34,300 --> 00:35:38,290
other containers start getting even more

00:35:36,640 --> 00:35:41,170
wildly out of scope in terms of

00:35:38,290 --> 00:35:43,840
performance and you can anticipate that

00:35:41,170 --> 00:35:46,780
the longer you run the simulation for

00:35:43,840 --> 00:35:48,790
that sort of lip that you get there will

00:35:46,780 --> 00:35:53,410
go further and further back down the

00:35:48,790 --> 00:35:55,300
number of elements memory so at 10%

00:35:53,410 --> 00:35:57,910
modification the other tui basically

00:35:55,300 --> 00:36:01,210
using four times as much memory so

00:35:57,910 --> 00:36:03,490
that's kind of vaguely interesting so it

00:36:01,210 --> 00:36:05,950
looks like Colony seems to be better for

00:36:03,490 --> 00:36:08,830
hire modification scenarios and it seems

00:36:05,950 --> 00:36:10,540
to be doing better and better based on

00:36:08,830 --> 00:36:12,730
the amount of modification that you've

00:36:10,540 --> 00:36:15,730
got at least compared to those two

00:36:12,730 --> 00:36:19,180
vector and dick modifications so let's

00:36:15,730 --> 00:36:21,040
do an even more extreme example let's

00:36:19,180 --> 00:36:24,750
arrays and insert a certain number of

00:36:21,040 --> 00:36:27,730
elements per frame instead of per minute

00:36:24,750 --> 00:36:29,050
which sounds I don't know a little bit

00:36:27,730 --> 00:36:31,060
extreme but when you think about

00:36:29,050 --> 00:36:34,810
something like bullets you know you can

00:36:31,060 --> 00:36:37,270
have 100 or maybe even 500 for a more

00:36:34,810 --> 00:36:39,850
eager bullets flying out per second and

00:36:37,270 --> 00:36:42,160
then one minute or no not one minute one

00:36:39,850 --> 00:36:43,630
second or two seconds later most of them

00:36:42,160 --> 00:36:45,610
have disappeared or lodged into

00:36:43,630 --> 00:36:48,850
something or gone off the game map or

00:36:45,610 --> 00:36:50,980
whatever also quadtree opt read nodes

00:36:48,850 --> 00:36:53,410
you get a lot of modification to a frame

00:36:50,980 --> 00:36:56,070
and outside of games you can look like

00:36:53,410 --> 00:36:59,500
heavy model modification cells like

00:36:56,070 --> 00:37:02,740
cellular or atomic simulation that sort

00:36:59,500 --> 00:37:04,000
of thing so starting off with 1% and

00:37:02,740 --> 00:37:07,200
we're going to use a much shorter term

00:37:04,000 --> 00:37:10,900
frame just a one minute of game time so

00:37:07,200 --> 00:37:13,030
3,600 frames so this is logarithmic

00:37:10,900 --> 00:37:14,590
scale because the linear scale kind of

00:37:13,030 --> 00:37:15,820
looks like that we're colonies at the

00:37:14,590 --> 00:37:19,120
bottom and the other ones are up like

00:37:15,820 --> 00:37:22,330
that so with this really high

00:37:19,120 --> 00:37:25,060
modification rate colony is basically

00:37:22,330 --> 00:37:27,310
around about a factor of 10 faster than

00:37:25,060 --> 00:37:30,130
the other ones and we can see here that

00:37:27,310 --> 00:37:33,220
because obviously we've got a lot more

00:37:30,130 --> 00:37:35,080
erasers happening per frame the removeth

00:37:33,220 --> 00:37:38,320
variants are doing quite a bit better as

00:37:35,080 --> 00:37:41,470
well I'm put up to 5% colony does better

00:37:38,320 --> 00:37:43,540
again and 10% better again

00:37:41,470 --> 00:37:46,630
in terms of memory usage at that point

00:37:43,540 --> 00:37:48,730
so for 1% modification per frame colony

00:37:46,630 --> 00:37:54,280
is using 34 times less than the other

00:37:48,730 --> 00:38:00,310
two 5% it's using 172 times less after

00:37:54,280 --> 00:38:02,620
one minute and at 10% it's using 340

00:38:00,310 --> 00:38:04,990
times less memory after one minute of

00:38:02,620 --> 00:38:06,910
simulation which is why I can't run this

00:38:04,990 --> 00:38:09,040
simulation for more than a minute

00:38:06,910 --> 00:38:13,860
because if I run it for half an hour it

00:38:09,040 --> 00:38:16,690
uses more memory than my computer hat so

00:38:13,860 --> 00:38:20,020
bottom line what is kala mean vaguely

00:38:16,690 --> 00:38:23,470
useful for basically high modification

00:38:20,020 --> 00:38:26,440
scenarios so if you've got a scenario

00:38:23,470 --> 00:38:28,270
where you haven't got too much

00:38:26,440 --> 00:38:31,540
modification going on maybe you've got

00:38:28,270 --> 00:38:33,130
one or two the rages and insertions here

00:38:31,540 --> 00:38:34,990
and there over the course of half an

00:38:33,130 --> 00:38:37,720
hour you probably wouldn't be reaching

00:38:34,990 --> 00:38:40,870
for colony but if you've got more than

00:38:37,720 --> 00:38:43,990
one percent raises or insertions

00:38:40,870 --> 00:38:46,390
happening per 3,600 iterations over your

00:38:43,990 --> 00:38:49,690
data that's when you would use it so

00:38:46,390 --> 00:38:51,340
medium to high modification scenarios if

00:38:49,690 --> 00:38:53,440
you've got less than that if you've got

00:38:51,340 --> 00:38:55,600
less than two percent of your elements

00:38:53,440 --> 00:38:57,700
being inserted or arrays maybe you want

00:38:55,600 --> 00:39:00,250
to look at one of these dear core victor

00:38:57,700 --> 00:39:02,410
approaches but whatever you do you

00:39:00,250 --> 00:39:06,160
probably don't want to be using boolean

00:39:02,410 --> 00:39:08,010
scope fields in general so generally

00:39:06,160 --> 00:39:10,690
speaking the higher the ratio of

00:39:08,010 --> 00:39:12,820
modification to iteration the greater

00:39:10,690 --> 00:39:15,820
the performance and memory saving you

00:39:12,820 --> 00:39:19,140
get out of using colony and that's

00:39:15,820 --> 00:39:22,300
pretty much it for coding more or less

00:39:19,140 --> 00:39:24,610
that the title of the talk was colonies

00:39:22,300 --> 00:39:26,140
performance and why you should care I've

00:39:24,610 --> 00:39:27,640
gone into colonies have gone into

00:39:26,140 --> 00:39:30,250
performance I haven't really gone into

00:39:27,640 --> 00:39:32,770
why you should care and this is just a

00:39:30,250 --> 00:39:35,980
generalized statement about thinking

00:39:32,770 --> 00:39:38,250
about performance in computing going

00:39:35,980 --> 00:39:44,800
back to what I was saying at the start

00:39:38,250 --> 00:39:46,360
and I think it's fairly it's possible

00:39:44,800 --> 00:39:48,100
that over the next 10 to 20 years we're

00:39:46,360 --> 00:39:50,160
going to see a fairly strong performance

00:39:48,100 --> 00:39:52,360
crunch in computing on the software side

00:39:50,160 --> 00:39:54,310
there's a couple of reasons for that

00:39:52,360 --> 00:39:54,789
some of them are internal to computers

00:39:54,310 --> 00:39:57,339
some of them

00:39:54,789 --> 00:39:58,569
or external the internal reasons we're

00:39:57,339 --> 00:40:00,160
kind of scraping the bottom of the

00:39:58,569 --> 00:40:02,499
barrel a lot of the time in terms of

00:40:00,160 --> 00:40:04,349
what we can get out of our hardware now

00:40:02,499 --> 00:40:07,089
how much we can increase the performance

00:40:04,349 --> 00:40:09,219
if you look at the 90s or whatever we

00:40:07,089 --> 00:40:11,140
were more or less doubling CPU speeds

00:40:09,219 --> 00:40:13,779
every year or every couple of years but

00:40:11,140 --> 00:40:15,999
that low-hanging fruit is gone and now

00:40:13,779 --> 00:40:17,890
it's all down to you know more efficient

00:40:15,999 --> 00:40:21,880
pipelining cache all that sort of jazz

00:40:17,890 --> 00:40:25,799
and paralyzing parallelizing not

00:40:21,880 --> 00:40:28,959
paralyzing where we can but of course

00:40:25,799 --> 00:40:32,410
parallelizing has a fairly limited scope

00:40:28,959 --> 00:40:35,499
to an extent so we have to kind of look

00:40:32,410 --> 00:40:38,410
at things in a kind of context where

00:40:35,499 --> 00:40:39,910
this is sort of what we got and we are

00:40:38,410 --> 00:40:42,640
going to get gradual performance

00:40:39,910 --> 00:40:45,339
increases but short of a major sort of

00:40:42,640 --> 00:40:47,919
computing technology revolution we're

00:40:45,339 --> 00:40:49,719
not going to get the kind of 200%

00:40:47,919 --> 00:40:52,029
performance increases that we were

00:40:49,719 --> 00:40:55,179
getting in the 90s so we can't rely on

00:40:52,029 --> 00:40:58,299
hardware now to sort out all our

00:40:55,179 --> 00:41:00,369
performance problems for us at the same

00:40:58,299 --> 00:41:02,109
time externally in the real world people

00:41:00,369 --> 00:41:03,939
are obviously using computers more and

00:41:02,109 --> 00:41:06,099
more they're demanding more from them

00:41:03,939 --> 00:41:07,630
and they're doing more with them if you

00:41:06,099 --> 00:41:10,119
look at the 90s again everybody was

00:41:07,630 --> 00:41:12,369
doing everything still on paper so on

00:41:10,119 --> 00:41:15,359
faxes whatever now everything's

00:41:12,369 --> 00:41:18,069
transitions to digital documents media

00:41:15,359 --> 00:41:20,380
communication why because it's

00:41:18,069 --> 00:41:21,640
essentially more efficient and the other

00:41:20,380 --> 00:41:23,619
thing that's going to drive that

00:41:21,640 --> 00:41:27,249
efficiency I think economically is

00:41:23,619 --> 00:41:28,989
basically sheer sort of population

00:41:27,249 --> 00:41:31,390
numbers that sort of thing we've got

00:41:28,989 --> 00:41:34,839
roughly double the number of people on

00:41:31,390 --> 00:41:37,089
the planet they were when I was born at

00:41:34,839 --> 00:41:39,189
the same time we have some diminishing

00:41:37,089 --> 00:41:41,529
natural resources that sort of jazz I

00:41:39,189 --> 00:41:43,929
mentioned Google Maps earlier that's a

00:41:41,529 --> 00:41:46,359
good example of using computing

00:41:43,929 --> 00:41:48,609
technology to greatly increase our

00:41:46,359 --> 00:41:50,469
real-world efficiency and use of

00:41:48,609 --> 00:41:52,809
resources and I think we're going to

00:41:50,469 --> 00:41:57,039
need a lot more of that over the coming

00:41:52,809 --> 00:41:59,169
years and I think at the front of that

00:41:57,039 --> 00:42:01,659
performance crunch is probably going to

00:41:59,169 --> 00:42:03,789
be C++ in terms of programming because

00:42:01,659 --> 00:42:06,369
we don't really have anything else that

00:42:03,789 --> 00:42:08,099
accesses that high level of our

00:42:06,369 --> 00:42:10,259
distraction and the low level

00:42:08,099 --> 00:42:13,259
distraction at the same time and that

00:42:10,259 --> 00:42:15,479
low level is really important for being

00:42:13,259 --> 00:42:17,940
able to modify for different Hardware

00:42:15,479 --> 00:42:22,380
scenarios getting access to registers

00:42:17,940 --> 00:42:24,209
all that sort of jazz but we're going to

00:42:22,380 --> 00:42:25,920
have to look at a lot of change in the

00:42:24,209 --> 00:42:28,319
language and in the way that we do

00:42:25,920 --> 00:42:31,979
computing and some of that change is

00:42:28,319 --> 00:42:33,690
going to be hard one because now I

00:42:31,979 --> 00:42:36,029
imagine whoever wrote this quote was

00:42:33,690 --> 00:42:38,279
kind of pissed off at academics but at

00:42:36,029 --> 00:42:40,949
more or less applies to any scenario

00:42:38,279 --> 00:42:43,440
we've got a knowledge field which has

00:42:40,949 --> 00:42:45,239
got a great level of complexity in it

00:42:43,440 --> 00:42:47,849
and I don't think anybody would argue

00:42:45,239 --> 00:42:52,049
against the fact that C++ at this point

00:42:47,849 --> 00:42:55,769
has a great level of complexity and the

00:42:52,049 --> 00:42:58,650
problem of that is that the kinds of

00:42:55,769 --> 00:43:00,420
minds that come towards programming tend

00:42:58,650 --> 00:43:02,039
to be very intelligent and we tend to

00:43:00,420 --> 00:43:04,140
get very wrapped up in ourselves in

00:43:02,039 --> 00:43:05,729
terms of thinking of ourselves as

00:43:04,140 --> 00:43:08,339
knowing a lot the sort of jurors and I'm

00:43:05,729 --> 00:43:11,670
not disputing myself from that at all

00:43:08,339 --> 00:43:14,269
I'm just as bad the only problem with

00:43:11,670 --> 00:43:17,190
that is that once you know a lot then

00:43:14,269 --> 00:43:19,949
when what you know changes there tends

00:43:17,190 --> 00:43:21,449
to be some resistance to change and

00:43:19,949 --> 00:43:24,630
we're already seeing a bit of that with

00:43:21,449 --> 00:43:26,999
SD 14 and various other movements that

00:43:24,630 --> 00:43:28,410
are happening so my last point with that

00:43:26,999 --> 00:43:31,739
is simply to say that I think it

00:43:28,410 --> 00:43:33,239
behooves us all including myself to look

00:43:31,739 --> 00:43:35,069
at the ways that we are holding

00:43:33,239 --> 00:43:38,309
ourselves back in terms of the computer

00:43:35,069 --> 00:43:40,739
industry and in terms of C++ and the way

00:43:38,309 --> 00:43:42,920
we program and that sort of thing and

00:43:40,739 --> 00:43:46,430
that's all I've got

00:43:42,920 --> 00:43:46,430
any questions

00:43:51,620 --> 00:44:07,980
yeah questions yep sorry eventually yeah

00:44:03,990 --> 00:44:08,520
I want to get it into boost first if I

00:44:07,980 --> 00:44:10,800
can

00:44:08,520 --> 00:44:12,300
the main problem for that is basically

00:44:10,800 --> 00:44:14,040
finding the time to work on the

00:44:12,300 --> 00:44:17,190
documentation and get it into the boost

00:44:14,040 --> 00:44:19,890
format I think once it's gone through

00:44:17,190 --> 00:44:22,500
that process then I'll be in a bit of a

00:44:19,890 --> 00:44:25,020
sort of position to write something up

00:44:22,500 --> 00:44:27,210
in terms of a proposal I think the

00:44:25,020 --> 00:44:30,180
biggest problem with that is really

00:44:27,210 --> 00:44:32,100
going to be separating out what makes a

00:44:30,180 --> 00:44:34,350
colony a colony from an abstract point

00:44:32,100 --> 00:44:37,680
of view versus an implementation point

00:44:34,350 --> 00:44:40,500
of view so yeah but eventually at the

00:44:37,680 --> 00:44:42,300
moment it's just sort of freeform for

00:44:40,500 --> 00:44:56,910
whoever wants to use it and modify it

00:44:42,300 --> 00:45:00,390
and whatnot so yeah yeah yeah so the

00:44:56,910 --> 00:45:04,200
question was when you modify the Skip

00:45:00,390 --> 00:45:05,940
field structure in rare instances you

00:45:04,200 --> 00:45:08,430
might have to update the Skip field for

00:45:05,940 --> 00:45:10,620
the entire block for example if I mean

00:45:08,430 --> 00:45:14,160
basically if all of the elements and the

00:45:10,620 --> 00:45:16,380
Skip field so if all of the elements in

00:45:14,160 --> 00:45:19,770
that particular block have been erased

00:45:16,380 --> 00:45:21,750
but one or two depending on where the

00:45:19,770 --> 00:45:23,670
elements that you're raising are then

00:45:21,750 --> 00:45:26,790
you could be updating a whole lot of the

00:45:23,670 --> 00:45:29,160
block I thought this would be

00:45:26,790 --> 00:45:30,960
problematic but in terms of actual

00:45:29,160 --> 00:45:33,960
implementation it turns out that it's

00:45:30,960 --> 00:45:36,510
not and the reason for that is again

00:45:33,960 --> 00:45:39,840
there's no real branching happening but

00:45:36,510 --> 00:45:42,660
the other thing is that like I said

00:45:39,840 --> 00:45:44,580
earlier when you have these blocks and

00:45:42,660 --> 00:45:48,120
they become empty they get freed to the

00:45:44,580 --> 00:45:52,250
OS so that takes out a lot of those sort

00:45:48,120 --> 00:45:54,780
of big long strings of erased elements

00:45:52,250 --> 00:45:57,150
and the other thing in terms of my

00:45:54,780 --> 00:46:03,150
implementation of colony basically I've

00:45:57,150 --> 00:46:04,780
got a 16-bit unsigned int skip field and

00:46:03,150 --> 00:46:09,960
so the block sizes

00:46:04,780 --> 00:46:13,120
Limited at max to 65535 elements and

00:46:09,960 --> 00:46:19,630
that just limits the amount of that kind

00:46:13,120 --> 00:46:21,100
of skip field update factor so you know

00:46:19,630 --> 00:46:25,240
you could imagine if you had unlimited

00:46:21,100 --> 00:46:27,040
block size if it went up to a 64-bit

00:46:25,240 --> 00:46:29,980
size or whatever then you could end up

00:46:27,040 --> 00:46:32,170
having to update huge amounts of skip

00:46:29,980 --> 00:46:35,440
field nodes for a given erasure but

00:46:32,170 --> 00:46:37,570
keeping those block sizes smaller but

00:46:35,440 --> 00:46:38,980
still not too small because remember

00:46:37,570 --> 00:46:41,130
we're talking about games we're not

00:46:38,980 --> 00:46:43,930
talking about a huge number of objects

00:46:41,130 --> 00:46:46,510
it just cuts down on what the

00:46:43,930 --> 00:46:48,010
performance cost of that is and in terms

00:46:46,510 --> 00:46:50,340
of the benchmarking that I've done at

00:46:48,010 --> 00:46:52,810
least I haven't found that to be a

00:46:50,340 --> 00:47:07,120
significantly you know detrimental

00:46:52,810 --> 00:47:09,160
factor yeah yes so the question was are

00:47:07,120 --> 00:47:11,170
there any other problem domains that

00:47:09,160 --> 00:47:13,330
would benefit from this these techniques

00:47:11,170 --> 00:47:15,520
I think any problem domain where you're

00:47:13,330 --> 00:47:18,490
using for whatever reason a boolean

00:47:15,520 --> 00:47:21,130
scope field binary scope field or an

00:47:18,490 --> 00:47:22,870
equivalent you definitely benefit from

00:47:21,130 --> 00:47:24,430
at least looking into the job counting

00:47:22,870 --> 00:47:29,170
scope field pattern and seeing whether

00:47:24,430 --> 00:47:31,560
that would fit into that scenario taking

00:47:29,170 --> 00:47:35,170
into account that kind of block size

00:47:31,560 --> 00:47:37,420
thing that I talked about earlier in

00:47:35,170 --> 00:47:39,280
terms of the other stuff I'm not so

00:47:37,420 --> 00:47:42,760
familiar with other domains but

00:47:39,280 --> 00:47:47,740
basically any domain which has unordered

00:47:42,760 --> 00:47:51,670
data which is modified significantly and

00:47:47,740 --> 00:47:54,610
where the ratio skews towards you know

00:47:51,670 --> 00:47:57,340
reasonable amount of mod iteration and a

00:47:54,610 --> 00:47:58,540
reasonable amount of modification then

00:47:57,340 --> 00:48:03,940
you're going to get some performance

00:47:58,540 --> 00:48:06,960
benefit from using a colony yeah anybody

00:48:03,940 --> 00:48:06,960
else yes

00:48:08,060 --> 00:48:20,400
sorry could you say that again what are

00:48:17,250 --> 00:48:26,970
in the skip field yeah 16 but for my

00:48:20,400 --> 00:48:30,360
implementation but actually I eat each

00:48:26,970 --> 00:48:43,410
element so it adds 16 but and for

00:48:30,360 --> 00:48:46,280
unsilent for each element basically yeah

00:48:43,410 --> 00:48:48,810
ideally and so the general question was

00:48:46,280 --> 00:48:51,360
how much I mean basically how much

00:48:48,810 --> 00:48:53,430
memory wastage do you get from having

00:48:51,360 --> 00:48:56,610
that jump counting skip field there and

00:48:53,430 --> 00:49:00,120
in terms of my implementation 16-bit but

00:48:56,610 --> 00:49:02,430
actually I just remembered you can it's

00:49:00,120 --> 00:49:06,270
part of the template you can change the

00:49:02,430 --> 00:49:08,490
size of the skip field which also sorry

00:49:06,270 --> 00:49:10,020
the skip field and signed it enter type

00:49:08,490 --> 00:49:12,540
which also changes

00:49:10,020 --> 00:49:15,240
the maximum size of each of the memory

00:49:12,540 --> 00:49:17,040
blocks so for example if you only had

00:49:15,240 --> 00:49:21,090
you know you were only thinking about

00:49:17,040 --> 00:49:24,990
having maybe 200 to 400 elements then

00:49:21,090 --> 00:49:28,710
you might want to change it to a you int

00:49:24,990 --> 00:49:31,590
8 type instead of a youant 16 and then

00:49:28,710 --> 00:49:36,780
you only get you know a byte wastage per

00:49:31,590 --> 00:49:39,570
element yes so ideally in terms of in

00:49:36,780 --> 00:49:41,550
terms of what you're storing you're

00:49:39,570 --> 00:49:43,380
going to be better off having storing

00:49:41,550 --> 00:49:46,680
something that's larger than 16 but

00:49:43,380 --> 00:49:48,600
integer but yeah it just depends what

00:49:46,680 --> 00:49:50,400
you're doing again for the gaming

00:49:48,600 --> 00:49:52,290
scenario we're looking at structs in

00:49:50,400 --> 00:49:54,930
classes so pretty much everything is

00:49:52,290 --> 00:50:02,900
larger than 1/16 I don't so almost

00:49:54,930 --> 00:50:02,900
things yeah anybody else yep

00:50:05,970 --> 00:50:15,460
totally couldn't hear that sorry I do

00:50:11,110 --> 00:50:17,290
not know the question is how does colony

00:50:15,460 --> 00:50:18,820
behave in a concurrent environment I

00:50:17,290 --> 00:50:20,710
would really like to know that I would

00:50:18,820 --> 00:50:22,300
really like somebody to step up and kind

00:50:20,710 --> 00:50:25,000
of go hey I'm gonna take colony I'm

00:50:22,300 --> 00:50:27,970
gonna make a multi-threaded version of

00:50:25,000 --> 00:50:30,370
it at the current point in time the

00:50:27,970 --> 00:50:33,310
thread-safe guarantees are basically the

00:50:30,370 --> 00:50:35,320
same as the standard library so you know

00:50:33,310 --> 00:50:41,320
concurrent reads the fine concurrent

00:50:35,320 --> 00:50:44,260
writes not so much I'm not sure what the

00:50:41,320 --> 00:50:46,120
performance differences would be in a

00:50:44,260 --> 00:50:51,010
concurrent environment but I would be

00:50:46,120 --> 00:50:56,680
very interested to know yeah anybody

00:50:51,010 --> 00:50:59,100
else know looks like we're done thank

00:50:56,680 --> 00:50:59,100

YouTube URL: https://www.youtube.com/watch?v=wBER1R8YyGY


