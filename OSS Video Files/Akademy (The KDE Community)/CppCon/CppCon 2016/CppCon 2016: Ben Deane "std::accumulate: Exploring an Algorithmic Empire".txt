Title: CppCon 2016: Ben Deane "std::accumulate: Exploring an Algorithmic Empire"
Publication date: 2016-10-02
Playlist: CppCon 2016
Description: 
	http://CppCon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/cppcon/cppcon2016
—
What is the most powerful algorithm in the STL? In the world? There are many cases to be made. But this talk explores what I think is a pretty good candidate, which C++ calls std::accumulate(). Tucked away in ＜numeric＞, perhaps relatively unregarded when compared with workhorses like std::find_if() and std::partition(); nevertheless, std::accumulate() is in some sense the ur-algorithm on sequences.

Let’s explore the result of looking at code through an accumulate-shaped lens, how tweaking the algorithm for better composability can unlock many more uses, and how it can be further genericized with applications to parallelism, tree structures, and heterogeneous sequences.

std::accumulate(): it’s not just for adding things up!
— 
Ben Deane
Principal Software Engineer, Blizzard Entertainment
Ben has been writing games for almost 20 years, and in C++ for most of that. He is currently a Principal Engineer at Blizzard Entertainment where he works on the Battle.net team. He's always looking for useful new techniques in C++, and he likes functional programming.
—
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,050 --> 00:00:07,170
good morning I have 9 o'clock so let's

00:00:03,360 --> 00:00:09,570
get started so apologies for the

00:00:07,170 --> 00:00:10,440
grandiose title but it worked wonders

00:00:09,570 --> 00:00:14,849
with the program for me to hear from

00:00:10,440 --> 00:00:18,660
that apparently so this talk came about

00:00:14,849 --> 00:00:23,609
I gave a talk turn this on

00:00:18,660 --> 00:00:26,880
I gave the talk at work maybe a couple

00:00:23,609 --> 00:00:28,380
of years ago now and it was based on it

00:00:26,880 --> 00:00:30,599
was very much inspired by seán parents

00:00:28,380 --> 00:00:33,480
seasoning talks and I had a slide in

00:00:30,599 --> 00:00:34,980
that talk that said my claim is that

00:00:33,480 --> 00:00:38,489
this is the most powerful algorithm in

00:00:34,980 --> 00:00:40,710
the world and at the time I said but

00:00:38,489 --> 00:00:43,140
that's another talk so this is the

00:00:40,710 --> 00:00:45,239
result of that this is that talk so

00:00:43,140 --> 00:00:46,890
still accumulate on talk about

00:00:45,239 --> 00:00:49,500
accumulated will things and start off

00:00:46,890 --> 00:00:52,890
fairly slowly gently so here's a

00:00:49,500 --> 00:00:57,210
cumulate we all will know it and love it

00:00:52,890 --> 00:00:58,680
perhaps one thing I found one thing to

00:00:57,210 --> 00:01:00,629
notice here is that it looks like this a

00:00:58,680 --> 00:01:02,550
lot of kind of value semantics going on

00:01:00,629 --> 00:01:05,460
and perhaps you might think of other

00:01:02,550 --> 00:01:06,630
copies but I in my experience I found

00:01:05,460 --> 00:01:09,869
that compilers are pretty good at

00:01:06,630 --> 00:01:11,130
optimizing those copies away I took a

00:01:09,869 --> 00:01:12,720
look at this with an instrumented class

00:01:11,130 --> 00:01:15,240
that you know counted copies and moves

00:01:12,720 --> 00:01:16,470
and and compared to a version that I've

00:01:15,240 --> 00:01:18,600
accumulated that used to kind of

00:01:16,470 --> 00:01:20,430
explicit moves and I found almost no

00:01:18,600 --> 00:01:23,159
difference the only difference was in

00:01:20,430 --> 00:01:28,290
the very first input parameter pass to

00:01:23,159 --> 00:01:30,360
the posture the function itself so you

00:01:28,290 --> 00:01:31,680
know these are typical users and where

00:01:30,360 --> 00:01:33,000
this is not what you're here for this is

00:01:31,680 --> 00:01:35,220
this is kind of like what you think of

00:01:33,000 --> 00:01:37,110
when you first meet the cumulate yes we

00:01:35,220 --> 00:01:39,409
can compute you know triangle numbers

00:01:37,110 --> 00:01:42,299
and factorials and this is very boring

00:01:39,409 --> 00:01:44,640
but what else can we do so so something

00:01:42,299 --> 00:01:46,680
else very simple we can do is compute a

00:01:44,640 --> 00:01:49,500
maximum value again you're all here at

00:01:46,680 --> 00:01:50,670
CP con so you all know this I hope

00:01:49,500 --> 00:01:54,240
everyone's convinced this will find the

00:01:50,670 --> 00:01:56,189
maximum value by the way ask questions

00:01:54,240 --> 00:01:57,960
if you have any gender talk I'll try and

00:01:56,189 --> 00:02:00,570
answer them or tell you that I'm about

00:01:57,960 --> 00:02:02,969
to answer them in the other slide so we

00:02:00,570 --> 00:02:08,970
could write min element in a value-based

00:02:02,969 --> 00:02:11,790
sense and do something like this we can

00:02:08,970 --> 00:02:13,350
also do things like accumulating boolean

00:02:11,790 --> 00:02:15,570
values

00:02:13,350 --> 00:02:17,220
and this is very similar to the the all

00:02:15,570 --> 00:02:18,780
of any of a none of in the library

00:02:17,220 --> 00:02:21,180
except without the nice shortcut

00:02:18,780 --> 00:02:21,690
behavior so you might think why would we

00:02:21,180 --> 00:02:24,320
do this

00:02:21,690 --> 00:02:27,240
it isn't very interesting as it stands

00:02:24,320 --> 00:02:29,910
but things become a little more

00:02:27,240 --> 00:02:31,380
interesting if we look at the signature

00:02:29,910 --> 00:02:37,440
of the function that gets passed to

00:02:31,380 --> 00:02:38,460
accumulate so it had these types you

00:02:37,440 --> 00:02:39,600
know perhaps we used to think of these

00:02:38,460 --> 00:02:44,160
types of being the same but they can

00:02:39,600 --> 00:02:48,600
vary so let's look at things when they

00:02:44,160 --> 00:02:50,250
differ so here's a simple example a more

00:02:48,600 --> 00:02:52,500
interesting case again accumulating

00:02:50,250 --> 00:02:54,480
bullying's but in this case it's sort of

00:02:52,500 --> 00:02:56,240
inspired by hopes of his favorite 10

00:02:54,480 --> 00:03:00,360
lines of code we've got some kind of

00:02:56,240 --> 00:03:02,190
weak point a cache here and we've got a

00:03:00,360 --> 00:03:04,260
function to load you know we're asking

00:03:02,190 --> 00:03:07,610
for a bunch of a bunch of things we want

00:03:04,260 --> 00:03:10,530
to load into the cache now because

00:03:07,610 --> 00:03:13,140
because get thing returns a shared

00:03:10,530 --> 00:03:16,770
pointer which we can treat like a

00:03:13,140 --> 00:03:18,810
boolean we can accumulate across the

00:03:16,770 --> 00:03:20,280
things that we pass in and we don't

00:03:18,810 --> 00:03:21,570
actually want the shortcut behavior here

00:03:20,280 --> 00:03:23,550
because we're asking for all of these

00:03:21,570 --> 00:03:26,130
IDs some a little bit some will be in

00:03:23,550 --> 00:03:27,540
the cache some won't for the ones that

00:03:26,130 --> 00:03:29,250
won't we actually do want to service all

00:03:27,540 --> 00:03:32,520
of them and ask for all of them and get

00:03:29,250 --> 00:03:36,270
back what we get back is whether we need

00:03:32,520 --> 00:03:37,710
to service the requests or not so here

00:03:36,270 --> 00:03:39,420
you can imagine making make async

00:03:37,710 --> 00:03:41,340
requests actually doesn't work and kind

00:03:39,420 --> 00:03:44,520
of presumably pushes a request on to

00:03:41,340 --> 00:03:46,290
some other queue and then we know from

00:03:44,520 --> 00:03:49,520
the result of accumulate whether all the

00:03:46,290 --> 00:03:55,170
things are cached or not and we can call

00:03:49,520 --> 00:03:57,810
a service service async requests so note

00:03:55,170 --> 00:04:00,780
that so we don't want a shortcut here

00:03:57,810 --> 00:04:04,020
and you'll note the order of arguments

00:04:00,780 --> 00:04:05,820
to and here so we're not so where the

00:04:04,020 --> 00:04:13,290
cached argument comes second and we're

00:04:05,820 --> 00:04:15,990
always calling get thing so this kind of

00:04:13,290 --> 00:04:18,150
pattern can be useful just because we

00:04:15,990 --> 00:04:19,890
use many function results as if they

00:04:18,150 --> 00:04:21,380
were boolean values in control flow

00:04:19,890 --> 00:04:25,110
sometimes it's actual boolean's

00:04:21,380 --> 00:04:26,669
oftentimes it's pointers could be zero

00:04:25,110 --> 00:04:28,590
results of you know

00:04:26,669 --> 00:04:31,590
compression tracheotomy is like a stroke

00:04:28,590 --> 00:04:33,330
amp and you know we write boolean

00:04:31,590 --> 00:04:34,979
operators for you in conversion

00:04:33,330 --> 00:04:38,039
operators for our classes a lot anytime

00:04:34,979 --> 00:04:40,979
we want to write if X and that means we

00:04:38,039 --> 00:04:42,659
can use accumulate to collect those kind

00:04:40,979 --> 00:04:44,759
of function values and again it's

00:04:42,659 --> 00:04:46,259
similar to the standard library the new

00:04:44,759 --> 00:04:51,930
algorithms but where we don't want the

00:04:46,259 --> 00:04:54,240
short-circuiting baby ok so so we can

00:04:51,930 --> 00:04:57,060
accumulate boolean values there's a

00:04:54,240 --> 00:04:59,819
bunch more things we can accumulate and

00:04:57,060 --> 00:05:02,460
all of these things have something in

00:04:59,819 --> 00:05:04,770
common so joining strings we can

00:05:02,460 --> 00:05:06,210
accumulate into one big string this is

00:05:04,770 --> 00:05:07,500
very similar to building requests from

00:05:06,210 --> 00:05:10,139
key value pairs if you think about an

00:05:07,500 --> 00:05:14,550
HTTP request the headers or the

00:05:10,139 --> 00:05:17,370
arguments merging JSON objects you can

00:05:14,550 --> 00:05:22,099
imagine that we could accumulate a bunch

00:05:17,370 --> 00:05:24,659
of JSON objects into one big JSON object

00:05:22,099 --> 00:05:27,389
multiplying matrices is also something

00:05:24,659 --> 00:05:30,680
we can accumulate so the question is

00:05:27,389 --> 00:05:34,589
whether all these have in common and

00:05:30,680 --> 00:05:36,150
what they have in common is that they're

00:05:34,589 --> 00:05:38,460
all mono it's which you probably

00:05:36,150 --> 00:05:41,039
remember because it's been talked about

00:05:38,460 --> 00:05:43,469
a lot in conferences so basically a

00:05:41,039 --> 00:05:45,120
monoid is a set of objects and an

00:05:43,469 --> 00:05:46,889
operation such that the operation is

00:05:45,120 --> 00:05:49,289
closed over the set it's associative and

00:05:46,889 --> 00:05:52,710
there's an identity element and this is

00:05:49,289 --> 00:05:53,729
exactly kind of what we need in fact a

00:05:52,710 --> 00:05:57,689
little bit stronger than what we need in

00:05:53,729 --> 00:06:00,289
some cases to accumulate things so

00:05:57,689 --> 00:06:03,770
here's an example I was talking about

00:06:00,289 --> 00:06:05,550
HTTP headers here's an example of

00:06:03,770 --> 00:06:09,569
rewriting something in terms of

00:06:05,550 --> 00:06:11,610
accumulate so we've got a we've got

00:06:09,569 --> 00:06:13,919
headers here as a map of key value pairs

00:06:11,610 --> 00:06:15,779
and we're just with you know this is

00:06:13,919 --> 00:06:17,789
curl I don't know if you're familiar

00:06:15,779 --> 00:06:19,949
with it but it's a C style interface and

00:06:17,789 --> 00:06:23,819
we're just building up a list of headers

00:06:19,949 --> 00:06:27,479
by appending a string of our on to our

00:06:23,819 --> 00:06:30,469
header list so this is a raw loop and we

00:06:27,479 --> 00:06:33,360
could rewrite it in accumulate style

00:06:30,469 --> 00:06:36,810
here the we're just going through the

00:06:33,360 --> 00:06:38,490
headers again and appending to the list

00:06:36,810 --> 00:06:40,560
and we're accumulating list of headers

00:06:38,490 --> 00:06:43,980
and the result here is that

00:06:40,560 --> 00:06:46,170
it's it's one expression there's no

00:06:43,980 --> 00:06:49,560
declaration and initialization split I

00:06:46,170 --> 00:06:53,100
feel like here we here we you know we

00:06:49,560 --> 00:06:54,810
declare curl headers and then we mutate

00:06:53,100 --> 00:06:57,360
it here we just declare it and

00:06:54,810 --> 00:06:59,670
initialize it in one line so this this

00:06:57,360 --> 00:07:06,090
allows us to if we like to use almost

00:06:59,670 --> 00:07:07,680
always Auto style so once you start

00:07:06,090 --> 00:07:09,810
looking for mods they turn out to be

00:07:07,680 --> 00:07:12,540
everywhere and any mode can be

00:07:09,810 --> 00:07:14,400
accumulated so some examples just a few

00:07:12,540 --> 00:07:16,919
examples additional integers

00:07:14,400 --> 00:07:19,500
concatenating strings Union sets merging

00:07:16,919 --> 00:07:21,870
objects of all kinds what we've seen in

00:07:19,500 --> 00:07:24,230
the boolean cases housing is Aman ID

00:07:21,870 --> 00:07:26,850
applying AI behaviors could be a monoid

00:07:24,230 --> 00:07:31,370
composing images you know set

00:07:26,850 --> 00:07:33,300
intersections optional is Aman ID and

00:07:31,370 --> 00:07:35,880
once you realize that what you're

00:07:33,300 --> 00:07:38,070
dealing with is a mono

00:07:35,880 --> 00:07:40,350
ie that you can compose you have a

00:07:38,070 --> 00:07:43,760
binary operation and then you can run

00:07:40,350 --> 00:07:47,880
accumulate it can simplify your api's

00:07:43,760 --> 00:07:49,410
this happened when I was at work and I

00:07:47,880 --> 00:07:51,330
was and I was looking at a friend's code

00:07:49,410 --> 00:07:53,370
and he was wondering how to he had

00:07:51,330 --> 00:07:55,470
actually he wasn't even working in C++

00:07:53,370 --> 00:07:57,750
he was working in JavaScript and he had

00:07:55,470 --> 00:07:59,100
a list of objects and he wanted to kind

00:07:57,750 --> 00:08:00,630
of merge them all into one object get

00:07:59,100 --> 00:08:02,400
all you know accumulate all of the

00:08:00,630 --> 00:08:04,320
effectively key value pairs in the

00:08:02,400 --> 00:08:10,010
JavaScript object it all he had was a

00:08:04,320 --> 00:08:12,330
binary function to merge two and I

00:08:10,010 --> 00:08:14,070
looked at it with him and then I

00:08:12,330 --> 00:08:15,630
suddenly realized well you know all you

00:08:14,070 --> 00:08:17,190
need to do the binding function is all

00:08:15,630 --> 00:08:18,900
unique because you just reduce in

00:08:17,190 --> 00:08:20,340
JavaScript across the across the

00:08:18,900 --> 00:08:27,870
collection of objects and that is

00:08:20,340 --> 00:08:29,310
exactly accumulate so a type can be a

00:08:27,870 --> 00:08:32,820
monoid in more than one way and the

00:08:29,310 --> 00:08:36,300
obvious example of this is integers they

00:08:32,820 --> 00:08:38,960
can be a monoid under addition they can

00:08:36,300 --> 00:08:42,000
also be a monoid under multiplication

00:08:38,960 --> 00:08:44,099
and the identity for addition is 0 and

00:08:42,000 --> 00:08:47,520
the identity for multiplication is 1 as

00:08:44,099 --> 00:08:49,050
I'm sure you know also any function that

00:08:47,520 --> 00:08:50,700
returns a mind we saw the functions

00:08:49,050 --> 00:08:53,100
returning she had put a which we treat

00:08:50,700 --> 00:08:54,000
this boolean any function that returns

00:08:53,100 --> 00:08:55,439
an one ID

00:08:54,000 --> 00:08:57,300
can itself be treated as I'm one-eyed

00:08:55,439 --> 00:09:02,639
because you can just aggregate the

00:08:57,300 --> 00:09:08,819
output of the function and saying the

00:09:02,639 --> 00:09:12,060
same thing in a different way map so if

00:09:08,819 --> 00:09:15,120
if the value in a map is a mono forms

00:09:12,060 --> 00:09:17,970
amyloid then the map itself is a mod

00:09:15,120 --> 00:09:19,589
because you can imagine so so that's

00:09:17,970 --> 00:09:22,560
really the same thing as the function

00:09:19,589 --> 00:09:24,959
claim because if we think of functions

00:09:22,560 --> 00:09:29,610
as regular functions that don't depend

00:09:24,959 --> 00:09:30,209
on any external input then you could

00:09:29,610 --> 00:09:31,470
implement

00:09:30,209 --> 00:09:33,720
I mean theory you can implement any

00:09:31,470 --> 00:09:39,329
function as just a map from inputs to

00:09:33,720 --> 00:09:42,629
outputs alright enough of the abstract

00:09:39,329 --> 00:09:45,329
algebra so why would we do this and why

00:09:42,629 --> 00:09:47,850
wouldn't we just write a loop well one

00:09:45,329 --> 00:09:49,290
thing I've mentioned is that when we do

00:09:47,850 --> 00:09:51,860
this we we don't have a declaration

00:09:49,290 --> 00:09:54,750
initialization split which is it is good

00:09:51,860 --> 00:09:58,649
it's often easier to write the binary

00:09:54,750 --> 00:10:00,689
function than to think about summing a

00:09:58,649 --> 00:10:03,750
collection of things I'm gonna say

00:10:00,689 --> 00:10:06,600
something for you know aggregating it

00:10:03,750 --> 00:10:08,490
and it simplifies an API if you can with

00:10:06,600 --> 00:10:10,439
your writing an API and you can identify

00:10:08,490 --> 00:10:15,000
that a type you're providing to your

00:10:10,439 --> 00:10:16,860
users form zaman I'd then all you have

00:10:15,000 --> 00:10:19,559
to do is provide them with that merging

00:10:16,860 --> 00:10:21,420
function that binary function and they

00:10:19,559 --> 00:10:27,389
get you know accumulate for free

00:10:21,420 --> 00:10:29,490
effectively and you also get incremental

00:10:27,389 --> 00:10:30,899
computation because you can take you can

00:10:29,490 --> 00:10:32,129
accumulate that parts of it where you

00:10:30,899 --> 00:10:37,829
can take the result of accumulate and

00:10:32,129 --> 00:10:39,360
keep on accumulating things into it of

00:10:37,829 --> 00:10:44,970
course also we get the potential for

00:10:39,360 --> 00:10:47,459
parallel computation if if we can use

00:10:44,970 --> 00:10:48,750
something like ok that you know the

00:10:47,459 --> 00:10:51,720
parallel can't part of cumulate perhaps

00:10:48,750 --> 00:10:55,709
in in in the in modern c++ will be

00:10:51,720 --> 00:10:57,930
reduce and its friends and if our types

00:10:55,709 --> 00:11:00,449
are right then we don't have to just

00:10:57,930 --> 00:11:03,230
accumulate things linearly we could you

00:11:00,449 --> 00:11:05,790
know but since the mono da per ation is

00:11:03,230 --> 00:11:07,860
associative it means you can accumulate

00:11:05,790 --> 00:11:09,300
a bunch of things of

00:11:07,860 --> 00:11:11,100
bunch of things over here and when you

00:11:09,300 --> 00:11:16,649
accumulate the results you get the right

00:11:11,100 --> 00:11:18,149
answer okay so this is sort of what

00:11:16,649 --> 00:11:21,180
accumulate does it turns binary

00:11:18,149 --> 00:11:22,290
functions into enery functions because

00:11:21,180 --> 00:11:24,839
it allows you to operate over

00:11:22,290 --> 00:11:26,880
collections with binary functions it

00:11:24,839 --> 00:11:31,140
collects as we've seen the results of

00:11:26,880 --> 00:11:33,510
functions whose outputs are monoidal and

00:11:31,140 --> 00:11:35,550
in some sense because it's it offers us

00:11:33,510 --> 00:11:38,160
this incremental ability it allows us to

00:11:35,550 --> 00:11:40,290
treat part-whole hierarchies uniformly

00:11:38,160 --> 00:11:43,230
so you can you can keep on folding

00:11:40,290 --> 00:11:44,880
things in and that that in it's that

00:11:43,230 --> 00:11:48,779
also allows us to do parallel

00:11:44,880 --> 00:11:54,120
computation so a little aside about

00:11:48,779 --> 00:11:57,720
parallel computation monoids you can see

00:11:54,120 --> 00:12:01,410
here basically why parallelism works on

00:11:57,720 --> 00:12:04,680
the more laid you've got identity this

00:12:01,410 --> 00:12:06,209
is the identity doesn't matter if we

00:12:04,680 --> 00:12:07,410
have anything here because we've got an

00:12:06,209 --> 00:12:09,149
identity which is zero this is just

00:12:07,410 --> 00:12:10,529
adding up numbers and you can see that

00:12:09,149 --> 00:12:13,250
we get the right thing because the

00:12:10,529 --> 00:12:15,990
operation is associative

00:12:13,250 --> 00:12:19,320
here is another example of computing an

00:12:15,990 --> 00:12:20,640
amine and this just involves keeping

00:12:19,320 --> 00:12:22,860
track of the pair of thinks the count of

00:12:20,640 --> 00:12:24,269
numbers and the sum and they keep track

00:12:22,860 --> 00:12:25,829
of those separately and again we get the

00:12:24,269 --> 00:12:31,010
right answer because the operation is

00:12:25,829 --> 00:12:35,519
associative and we have an identity and

00:12:31,010 --> 00:12:37,589
so reduce which is new in super 17 it's

00:12:35,519 --> 00:12:39,720
really the same as accumulate except

00:12:37,589 --> 00:12:41,870
that the sequence can be processed in

00:12:39,720 --> 00:12:45,449
any order perhaps according to policy

00:12:41,870 --> 00:12:48,990
and it works because of T but what you

00:12:45,449 --> 00:12:52,170
get is you gain the parallelism but you

00:12:48,990 --> 00:12:54,959
lose the type variation because to have

00:12:52,170 --> 00:12:56,399
parallelism I think you need you know it

00:12:54,959 --> 00:12:57,720
basically assumes that you're you're

00:12:56,399 --> 00:13:00,870
doing a generalized sum of things at the

00:12:57,720 --> 00:13:02,600
same type but if you're if you're

00:13:00,870 --> 00:13:05,130
actually using things of different types

00:13:02,600 --> 00:13:06,540
then there's probably a linear

00:13:05,130 --> 00:13:12,240
computation required to keep folding

00:13:06,540 --> 00:13:14,820
things in if you work in big data then

00:13:12,240 --> 00:13:16,020
model is really are everywhere some

00:13:14,820 --> 00:13:18,449
examples of that you've got regular

00:13:16,020 --> 00:13:21,650
indicate averages top top end

00:13:18,449 --> 00:13:24,020
calculations histograms

00:13:21,650 --> 00:13:26,300
is just the bucket of you know a bunch

00:13:24,020 --> 00:13:28,130
of buckets of values you can imagine how

00:13:26,300 --> 00:13:29,960
to combine two histograms you simply add

00:13:28,130 --> 00:13:35,240
the buckets together you know bucket

00:13:29,960 --> 00:13:37,850
wise a bunch of probabilistic data

00:13:35,240 --> 00:13:41,480
structures are also Mao's things like

00:13:37,850 --> 00:13:44,839
bloom filters distributions hyper

00:13:41,480 --> 00:13:46,960
log-log is a a data structure which

00:13:44,839 --> 00:13:53,180
allows you to count uniques

00:13:46,960 --> 00:13:54,800
probabilistically and again this is so

00:13:53,180 --> 00:13:57,920
this link this is just a screenshot from

00:13:54,800 --> 00:14:00,410
a good site which allows you to play

00:13:57,920 --> 00:14:02,810
with hyper log log a bit the basic of

00:14:00,410 --> 00:14:04,850
hyper log log is that you're keeping a

00:14:02,810 --> 00:14:07,640
register file here and each one of the

00:14:04,850 --> 00:14:09,440
values in this register file is computed

00:14:07,640 --> 00:14:11,480
with a max operation according to the

00:14:09,440 --> 00:14:14,480
observable bit field you've seen and so

00:14:11,480 --> 00:14:17,120
it's trivial to merge multiple register

00:14:14,480 --> 00:14:19,820
files you just do a bucket wise max and

00:14:17,120 --> 00:14:24,920
that itself is monoidal and so the whole

00:14:19,820 --> 00:14:26,120
thing becomes accumulate able but that's

00:14:24,920 --> 00:14:28,970
beyond the scope of this talk so you can

00:14:26,120 --> 00:14:31,430
end up it on your own time so mano the

00:14:28,970 --> 00:14:34,910
semigroups semigroups are more nodes

00:14:31,430 --> 00:14:36,260
with the relaxed with you don't need no

00:14:34,910 --> 00:14:38,750
identity to be a semigroup you just need

00:14:36,260 --> 00:14:41,000
associativity but they're the key to

00:14:38,750 --> 00:14:42,860
parallelism and the other key is the

00:14:41,000 --> 00:14:45,800
ability this ability to combine summary

00:14:42,860 --> 00:14:49,510
data so for example with the

00:14:45,800 --> 00:14:52,100
distribution stuff if you've got

00:14:49,510 --> 00:14:53,900
district distributions can be combined

00:14:52,100 --> 00:14:55,459
so if you if you've done expensive

00:14:53,900 --> 00:14:58,790
training on your data set to form a

00:14:55,459 --> 00:15:02,270
distribution let's say you you used you

00:14:58,790 --> 00:15:04,190
have programmer salaries in Europe and

00:15:02,270 --> 00:15:05,540
programmer salaries in the US and you do

00:15:04,190 --> 00:15:07,820
training on both of those sets and you

00:15:05,540 --> 00:15:09,170
you form two different distributions you

00:15:07,820 --> 00:15:10,550
can you don't have to in order to

00:15:09,170 --> 00:15:12,350
combine the distributions you don't have

00:15:10,550 --> 00:15:14,089
to redo the training on the combined set

00:15:12,350 --> 00:15:18,380
you can just combine the distributions

00:15:14,089 --> 00:15:23,720
because that's what this that's what

00:15:18,380 --> 00:15:25,459
monoids do for you anyway so that was a

00:15:23,720 --> 00:15:29,150
little aside now let's get on to some

00:15:25,459 --> 00:15:32,500
some C++ and look at accumulating other

00:15:29,150 --> 00:15:35,360
things so right now accumulate works on

00:15:32,500 --> 00:15:37,570
linear sequences

00:15:35,360 --> 00:15:41,720
how could we make it work on

00:15:37,570 --> 00:15:43,250
multi-dimensional structures so one

00:15:41,720 --> 00:15:44,690
thing we could do if we had a binary

00:15:43,250 --> 00:15:47,230
tree or something is just define the

00:15:44,690 --> 00:15:50,180
linear traversal on it in the usual way

00:15:47,230 --> 00:15:52,279
and this would work if we could do that

00:15:50,180 --> 00:15:54,649
the nodes of the tree are still

00:15:52,279 --> 00:15:56,839
homogeneous what if the tree was a

00:15:54,649 --> 00:15:58,760
little more complex like let's say a

00:15:56,839 --> 00:16:01,550
JSON object is a familiar example of a

00:15:58,760 --> 00:16:06,860
of a tree a tree based structure that is

00:16:01,550 --> 00:16:08,390
fairly heterogeneous so so here's

00:16:06,860 --> 00:16:13,880
accumulate the cincture of accumulate

00:16:08,390 --> 00:16:16,970
now the insight here is that the initial

00:16:13,880 --> 00:16:19,399
value T is really dealing with the case

00:16:16,970 --> 00:16:21,110
when we have an empty sequence and the

00:16:19,399 --> 00:16:23,079
binary operation deals with the other

00:16:21,110 --> 00:16:25,070
case when we have a non-empty sequence

00:16:23,079 --> 00:16:27,640
so we really have two things we're

00:16:25,070 --> 00:16:29,779
dealing with and this is similar to how

00:16:27,640 --> 00:16:31,700
vectors and sequences of defined in

00:16:29,779 --> 00:16:34,220
functional languages we can think of

00:16:31,700 --> 00:16:37,339
sequence accumulation as as these two

00:16:34,220 --> 00:16:39,440
cases so either it's an empty vector or

00:16:37,339 --> 00:16:44,240
it's a vector consisting of you know

00:16:39,440 --> 00:16:46,310
element plus vector so this is kind of a

00:16:44,240 --> 00:16:48,949
recursive definition and if we think of

00:16:46,310 --> 00:16:52,449
accumulate in this way it's the key to

00:16:48,949 --> 00:16:56,209
accumulating nonlinear data structures

00:16:52,449 --> 00:16:57,440
so here's an example of the accumulate

00:16:56,209 --> 00:17:00,800
that we know kind of written in that

00:16:57,440 --> 00:17:03,230
style so if we think of the initial

00:17:00,800 --> 00:17:05,169
value not as a value but a function to

00:17:03,230 --> 00:17:07,280
call in the case of an empty vector and

00:17:05,169 --> 00:17:09,530
and the binary operation is of course

00:17:07,280 --> 00:17:10,459
the other function of call then

00:17:09,530 --> 00:17:11,750
accumulator looks something like this

00:17:10,459 --> 00:17:16,030
now it's recursive we wouldn't use this

00:17:11,750 --> 00:17:22,699
but this this is the key to getting to

00:17:16,030 --> 00:17:28,610
accumulating on things so here is a

00:17:22,699 --> 00:17:30,110
simple JSON value there's a variant and

00:17:28,610 --> 00:17:32,090
if you're familiar with JSON I mean it

00:17:30,110 --> 00:17:35,510
can just be these these six things ball

00:17:32,090 --> 00:17:38,570
number string know or an array of array

00:17:35,510 --> 00:17:41,030
of JSON values or a object which is a

00:17:38,570 --> 00:17:43,190
set of key value pairs where the keys

00:17:41,030 --> 00:17:48,070
are strings and the values are JSON

00:17:43,190 --> 00:17:50,620
values so in order to

00:17:48,070 --> 00:17:52,480
to accumulate this you know so in the

00:17:50,620 --> 00:17:54,520
vector case we had or in the sequence

00:17:52,480 --> 00:17:55,720
case we had we had two functions one to

00:17:54,520 --> 00:17:57,700
deal with the empty sequence I'm going

00:17:55,720 --> 00:18:00,940
to deal with sequence with something in

00:17:57,700 --> 00:18:05,700
it because we have six options for the

00:18:00,940 --> 00:18:05,700
JSON value here we need six functions

00:18:06,180 --> 00:18:09,390
luckily these functions are pretty

00:18:08,290 --> 00:18:13,000
simple so let's look at just

00:18:09,390 --> 00:18:16,330
accumulating rendering a JSON data

00:18:13,000 --> 00:18:17,590
structure with an accumulation so we

00:18:16,330 --> 00:18:19,120
know how to render a ball a doubler

00:18:17,590 --> 00:18:22,600
string and the null these are all

00:18:19,120 --> 00:18:25,180
trivial we know how to render an array

00:18:22,600 --> 00:18:27,400
all we do is render square brackets

00:18:25,180 --> 00:18:30,070
either side and we iterate the array and

00:18:27,400 --> 00:18:31,660
we render each value in the array I

00:18:30,070 --> 00:18:32,590
didn't put up the code to join here but

00:18:31,660 --> 00:18:34,450
you can imagine what it does it just

00:18:32,590 --> 00:18:39,940
joins together the strings with with the

00:18:34,450 --> 00:18:42,640
comma in between and similarly for the

00:18:39,940 --> 00:18:44,830
JSON object how we render an object is

00:18:42,640 --> 00:18:47,260
very much the same we render the the

00:18:44,830 --> 00:18:50,590
braces either side and we just iterate

00:18:47,260 --> 00:18:53,890
through the effectively the map and we

00:18:50,590 --> 00:18:55,930
render the first the first the first in

00:18:53,890 --> 00:18:58,420
the map is the string and the second in

00:18:55,930 --> 00:19:01,420
the map is itself a JSON value which we

00:18:58,420 --> 00:19:02,650
make a call to render okay so these six

00:19:01,420 --> 00:19:07,600
functions I hope you agree are all

00:19:02,650 --> 00:19:11,790
simple to write and then in theory all

00:19:07,600 --> 00:19:14,050
we need to do is call our call our

00:19:11,790 --> 00:19:18,520
multi-dimensional accumulate which I'm

00:19:14,050 --> 00:19:20,020
just calling fold a shorter word and we

00:19:18,520 --> 00:19:22,150
pass it these six functions to deal with

00:19:20,020 --> 00:19:25,470
the six cases in the JSON value and JIT

00:19:22,150 --> 00:19:30,550
and we pass it the JSON value obviously

00:19:25,470 --> 00:19:32,080
so there is a way to write this function

00:19:30,550 --> 00:19:34,980
all that I'll go through this is one way

00:19:32,080 --> 00:19:39,070
to write it it involves a little

00:19:34,980 --> 00:19:42,190
template or e so we've got it takes a

00:19:39,070 --> 00:19:44,500
variant of some size in this case a JSON

00:19:42,190 --> 00:19:47,350
value is a variant and it takes a bunch

00:19:44,500 --> 00:19:50,020
of functions one to deal with each value

00:19:47,350 --> 00:19:51,760
in that's possible in the variant and we

00:19:50,020 --> 00:19:54,640
just delegate to this fold that function

00:19:51,760 --> 00:19:56,350
which we which we call the which we call

00:19:54,640 --> 00:20:01,950
with the the index is actually active in

00:19:56,350 --> 00:20:05,889
the variant so in this case

00:20:01,950 --> 00:20:07,599
remember that we're not providing an

00:20:05,889 --> 00:20:10,749
initial value here effective it's

00:20:07,599 --> 00:20:16,869
implicit in in dealing with each of the

00:20:10,749 --> 00:20:21,450
six cases okay so this fold at is itself

00:20:16,869 --> 00:20:23,529
a function which ends up now in my

00:20:21,450 --> 00:20:25,269
formulation here I have a recursive

00:20:23,529 --> 00:20:28,499
template definition coming up there may

00:20:25,269 --> 00:20:31,059
be better ways to do it but basically

00:20:28,499 --> 00:20:33,009
we've given six functions were given a

00:20:31,059 --> 00:20:35,859
variant and we know the active index in

00:20:33,009 --> 00:20:40,899
that variant and so my basic what I

00:20:35,859 --> 00:20:47,589
basically do here is form the index

00:20:40,899 --> 00:20:50,139
sequence for those for those of size six

00:20:47,589 --> 00:20:54,969
and step through until I hit the one

00:20:50,139 --> 00:21:01,599
that's equivalent to the index so that's

00:20:54,969 --> 00:21:03,309
what this is doing so this is my

00:21:01,599 --> 00:21:04,659
function list I'm effectively coming

00:21:03,309 --> 00:21:08,139
down the function list here's the head

00:21:04,659 --> 00:21:12,759
and the tail of the functions and I'm

00:21:08,139 --> 00:21:14,289
saying if actually I'm not forming an

00:21:12,759 --> 00:21:15,639
index sequence if someone has a

00:21:14,289 --> 00:21:16,690
formulation that does form in a sequence

00:21:15,639 --> 00:21:20,759
it might probably faster than the

00:21:16,690 --> 00:21:23,679
recursive template definition but so

00:21:20,759 --> 00:21:25,779
this is the variant index and we're

00:21:23,679 --> 00:21:28,059
saying if if this is equal to our

00:21:25,779 --> 00:21:30,879
template parameter then we must be at

00:21:28,059 --> 00:21:34,450
the right function and so we just called

00:21:30,879 --> 00:21:39,249
the function on the and getting the

00:21:34,450 --> 00:21:42,299
value either that there int otherwise we

00:21:39,249 --> 00:21:49,029
brokers and we just go to the next

00:21:42,299 --> 00:21:51,999
template and the final you know the the

00:21:49,029 --> 00:21:55,299
end case is that this actually never

00:21:51,999 --> 00:21:56,559
gets called but if we run off the end it

00:21:55,299 --> 00:21:58,389
never gets called because of the static

00:21:56,559 --> 00:22:00,129
assert saying that we must have enough

00:21:58,389 --> 00:22:03,700
functions to deal with the things in the

00:22:00,129 --> 00:22:06,429
variant but if we run off the end this

00:22:03,700 --> 00:22:08,830
deals with the recursion this deals with

00:22:06,429 --> 00:22:11,169
the termination of the type recursion in

00:22:08,830 --> 00:22:14,910
particular because the return value R

00:22:11,169 --> 00:22:20,060
here is is needed

00:22:14,910 --> 00:22:23,190
because it is computed from just

00:22:20,060 --> 00:22:24,210
assuming that these things over sir or

00:22:23,190 --> 00:22:26,520
return the same type

00:22:24,210 --> 00:22:28,850
I just compute it from the result of the

00:22:26,520 --> 00:22:28,850
first one

00:22:33,330 --> 00:22:38,960
yes F and F F F F s are cool objects you

00:22:40,130 --> 00:22:51,660
know not storing them yes oh so there

00:22:49,590 --> 00:23:05,250
yes that is their advantage to

00:22:51,660 --> 00:23:09,330
forwarding rather than conference right

00:23:05,250 --> 00:23:11,360
so yes i'm using i'm using forwarding

00:23:09,330 --> 00:23:14,070
references here the comment is that

00:23:11,360 --> 00:23:16,890
maybe constant references could be

00:23:14,070 --> 00:23:19,950
usable but then if the thing doesn't

00:23:16,890 --> 00:23:25,440
have a Const operator a call operator

00:23:19,950 --> 00:23:29,160
then that would work so yes and it would

00:23:25,440 --> 00:23:31,020
be a compile error indeed so basically

00:23:29,160 --> 00:23:34,220
this this little bit of code is just

00:23:31,020 --> 00:23:36,570
saying at the end of the day

00:23:34,220 --> 00:23:38,910
take your variant take a bunch of

00:23:36,570 --> 00:23:40,290
functions and whichever value is active

00:23:38,910 --> 00:23:54,330
in the variant called the appropriate

00:23:40,290 --> 00:23:57,030
function on that value and then write so

00:23:54,330 --> 00:23:59,490
because it's recursive now presumably

00:23:57,030 --> 00:24:00,930
the function itself then ends up

00:23:59,490 --> 00:24:04,170
remember the recursive definition of

00:24:00,930 --> 00:24:07,620
like printing the array or printing the

00:24:04,170 --> 00:24:13,260
JSON it would then result in rehearsing

00:24:07,620 --> 00:24:14,370
and accumulating the variant so when you

00:24:13,260 --> 00:24:18,180
look at the sink of this function it

00:24:14,370 --> 00:24:21,780
looks a lot like visitation and it is

00:24:18,180 --> 00:24:24,060
fairly similar so I mean from that sense

00:24:21,780 --> 00:24:28,050
accumulation is perhaps not that far out

00:24:24,060 --> 00:24:32,220
of our everyday you know experience

00:24:28,050 --> 00:24:33,960
so this this is a generic accumulate for

00:24:32,220 --> 00:24:39,210
variance or at least one formulation of

00:24:33,960 --> 00:24:40,730
it and but if you don't if you don't

00:24:39,210 --> 00:24:42,840
have a variant if you just have a

00:24:40,730 --> 00:24:44,700
recursively specified data structure in

00:24:42,840 --> 00:24:47,460
some way you can still accumulate that

00:24:44,700 --> 00:24:50,630
using the same the same idea basically

00:24:47,460 --> 00:24:53,880
you have a function for each possible

00:24:50,630 --> 00:24:55,260
sort of in functional language they're

00:24:53,880 --> 00:24:57,900
called constructors but each possible

00:24:55,260 --> 00:25:02,010
thing that you could have in your in

00:24:57,900 --> 00:25:04,530
your data type and use this kind of

00:25:02,010 --> 00:25:44,160
visitation pattern to accumulate the

00:25:04,530 --> 00:25:47,550
thing recursively yes yeah right right

00:25:44,160 --> 00:25:49,710
so the comment is yes you need n

00:25:47,550 --> 00:25:52,950
functions for your n possible values and

00:25:49,710 --> 00:25:54,570
so your visit your recursion here the

00:25:52,950 --> 00:25:57,390
way I've formulated the in terms of

00:25:54,570 --> 00:25:58,800
recursive template is order n I'm not

00:25:57,390 --> 00:26:00,360
claiming that my formulation is the best

00:25:58,800 --> 00:26:03,660
I'm just saying here's what's possible

00:26:00,360 --> 00:26:08,300
with accumulation so I welcome anyone

00:26:03,660 --> 00:26:08,300
who has better ideas to make this faster

00:26:16,190 --> 00:26:24,060
okay so so Vinson has the experience

00:26:21,360 --> 00:26:25,920
that a similar thing he used actually

00:26:24,060 --> 00:26:29,210
was well optimized by the compiler to

00:26:25,920 --> 00:26:29,210
something like a switch statement

00:26:30,080 --> 00:26:33,980
okay so you think why would we do this

00:26:32,149 --> 00:26:35,419
because it separates the traversal of

00:26:33,980 --> 00:26:37,100
our they structure from the operation

00:26:35,419 --> 00:26:39,529
that we need to do on it and as you as

00:26:37,100 --> 00:26:42,710
you could see writing those rendering

00:26:39,529 --> 00:26:44,419
functions were as trivial and having the

00:26:42,710 --> 00:26:47,090
way to just run them over the data

00:26:44,419 --> 00:26:49,399
structure allows us to you know separate

00:26:47,090 --> 00:26:51,500
out what we're doing from the traversal

00:26:49,399 --> 00:26:53,600
and so we could do lots of other things

00:26:51,500 --> 00:26:55,220
so we saw like rendering the tree as a

00:26:53,600 --> 00:26:56,990
string we could compute things like

00:26:55,220 --> 00:26:59,090
depth resort depths or fringes of trees

00:26:56,990 --> 00:27:00,140
we could you know looking further afield

00:26:59,090 --> 00:27:01,640
we could do things like lighting

00:27:00,140 --> 00:27:02,960
contributions maybe and if you have a

00:27:01,640 --> 00:27:05,360
quadtree our NOC tree something like

00:27:02,960 --> 00:27:06,889
that you could do sing graph operations

00:27:05,360 --> 00:27:09,289
and the list kind of goes on you know

00:27:06,889 --> 00:27:11,330
these are these are typical recursive

00:27:09,289 --> 00:27:16,100
data structures in my line of work I'm

00:27:11,330 --> 00:27:17,809
sure you could think of your own so this

00:27:16,100 --> 00:27:20,830
this technique is useful when you have a

00:27:17,809 --> 00:27:22,880
kind of a heterogeneous hierarchy that

00:27:20,830 --> 00:27:24,200
might be difficult to define a linear

00:27:22,880 --> 00:27:26,299
traversal for you know if you have a

00:27:24,200 --> 00:27:30,559
plain binary tree you might still want

00:27:26,299 --> 00:27:33,289
to provide a linear traversal of it you

00:27:30,559 --> 00:27:38,919
know depth-first or whatever but but

00:27:33,289 --> 00:27:43,789
this is a heterogeneous way to do that

00:27:38,919 --> 00:27:45,559
so we've seen how to accumulate you know

00:27:43,789 --> 00:27:48,590
a cube a gives us accumulation over a

00:27:45,559 --> 00:27:51,039
sequence that that's it gives you that

00:27:48,590 --> 00:27:53,600
technique gives us accumulation over a

00:27:51,039 --> 00:27:57,110
heterogeneous hierarchy let's look at

00:27:53,600 --> 00:27:57,620
heterogeneous sequences okay tuples if

00:27:57,110 --> 00:28:02,389
you like

00:27:57,620 --> 00:28:06,080
so this accumulate again so type 1 and

00:28:02,389 --> 00:28:08,210
type 2 here - the binary operation might

00:28:06,080 --> 00:28:10,309
be different so what this is saying is

00:28:08,210 --> 00:28:14,600
that we know how to fold values are type

00:28:10,309 --> 00:28:18,889
2 into type 1 so what if we just allowed

00:28:14,600 --> 00:28:20,899
type 2 to be different every time and

00:28:18,889 --> 00:28:22,100
the accumulator accumulator stays fixed

00:28:20,899 --> 00:28:24,620
but we know that this is saying we know

00:28:22,100 --> 00:28:27,289
how to fold all kinds of things into the

00:28:24,620 --> 00:28:29,000
accumulator and there's one obvious

00:28:27,289 --> 00:28:32,720
example of this which is practically

00:28:29,000 --> 00:28:34,639
ubiquitous and it's just outputting to a

00:28:32,720 --> 00:28:36,139
know string effectively this is saying

00:28:34,639 --> 00:28:38,539
we know we now have to fold tons of

00:28:36,139 --> 00:28:41,020
things into a no stream we know you know

00:28:38,539 --> 00:28:42,790
we write these functions every day and

00:28:41,020 --> 00:28:45,790
so if

00:28:42,790 --> 00:28:48,670
had something like this a fold for

00:28:45,790 --> 00:28:50,260
tuples then we could expect output like

00:28:48,670 --> 00:28:52,780
this so in this case there's a generic

00:28:50,260 --> 00:28:54,460
lambda which just says you know we know

00:28:52,780 --> 00:28:58,570
how to fold a ton of things into an ova

00:28:54,460 --> 00:29:00,250
stream and there's a tuple and we we

00:28:58,570 --> 00:29:02,320
call fold and we pass it the tuple and

00:29:00,250 --> 00:29:06,930
then our initial value here is actually

00:29:02,320 --> 00:29:14,290
C out and then and then it just ends up

00:29:06,930 --> 00:29:15,910
outputting all that stuff to see out now

00:29:14,290 --> 00:29:18,220
this is possible as well in it and and

00:29:15,910 --> 00:29:20,890
one formulation of it is very similar to

00:29:18,220 --> 00:29:28,030
the the variant thing that you already

00:29:20,890 --> 00:29:31,960
saw now one one thing providing C out

00:29:28,030 --> 00:29:34,900
here I had the thought that I could we

00:29:31,960 --> 00:29:38,170
could structure this function to to take

00:29:34,900 --> 00:29:40,150
in some sense the empty tuple rather

00:29:38,170 --> 00:29:42,190
than you know what we saw before with

00:29:40,150 --> 00:29:43,960
variant was we didn't have an initial

00:29:42,190 --> 00:29:47,140
value because we effectively that was

00:29:43,960 --> 00:29:49,090
implicit in dealing with every case that

00:29:47,140 --> 00:29:51,400
the that be some type the variant could

00:29:49,090 --> 00:29:53,140
be in in this case there's a choice

00:29:51,400 --> 00:29:56,610
between either providing the initial

00:29:53,140 --> 00:29:59,710
value the initial oh stream here or

00:29:56,610 --> 00:30:01,990
somehow you know making that function

00:29:59,710 --> 00:30:03,790
deal with empty tuple and that would be

00:30:01,990 --> 00:30:07,120
the case where we provided effectively

00:30:03,790 --> 00:30:08,950
the initial value either way as possible

00:30:07,120 --> 00:30:14,290
I think this way for this use case is a

00:30:08,950 --> 00:30:17,070
little cleaner and and the fold for

00:30:14,290 --> 00:30:18,940
tuples look something like this

00:30:17,070 --> 00:30:20,680
I'll leave the implementation that's

00:30:18,940 --> 00:30:22,690
next size to you guys it's quite similar

00:30:20,680 --> 00:30:24,700
to that to the variant style it's not

00:30:22,690 --> 00:30:26,920
too difficult but actually dealing with

00:30:24,700 --> 00:30:28,810
streams you know because they're non

00:30:26,920 --> 00:30:30,370
movable does take a little tricky Ness

00:30:28,810 --> 00:30:31,450
and that's the reason for the deco type

00:30:30,370 --> 00:30:37,450
although though they had to have in

00:30:31,450 --> 00:30:41,530
there okay so so what we've seen so far

00:30:37,450 --> 00:30:43,060
so accumulate gives us you know one

00:30:41,530 --> 00:30:46,320
function and we can relate over a

00:30:43,060 --> 00:30:50,230
linnaeus a linear homogeneous structure

00:30:46,320 --> 00:30:52,380
if we do the the nonlinear that only the

00:30:50,230 --> 00:30:55,060
linear tree traversal just on our

00:30:52,380 --> 00:30:56,950
homogeneous tree structure we get

00:30:55,060 --> 00:31:00,870
something very similar

00:30:56,950 --> 00:31:03,610
if we have a accumulate over a variant

00:31:00,870 --> 00:31:05,830
then we need to provide n functions to

00:31:03,610 --> 00:31:07,240
deal with the N values that could be in

00:31:05,830 --> 00:31:09,100
the variant but it allows us to

00:31:07,240 --> 00:31:10,809
accumulate the multi-dimensional

00:31:09,100 --> 00:31:13,780
structure and the heterogeneous

00:31:10,809 --> 00:31:15,340
structure and then a tuple is itself a

00:31:13,780 --> 00:31:18,940
linear structure but it's a

00:31:15,340 --> 00:31:20,559
heterogeneous structure also so again we

00:31:18,940 --> 00:31:24,790
have effectively n functions although it

00:31:20,559 --> 00:31:28,750
might be a function template like like

00:31:24,790 --> 00:31:30,550
the Alpha things in the iostream so this

00:31:28,750 --> 00:31:33,360
is the Empire that we've got so far and

00:31:30,550 --> 00:31:35,679
all of these could be parallelizable

00:31:33,360 --> 00:31:40,600
given the appropriate semigroup

00:31:35,679 --> 00:31:43,059
structure you can imagine that you could

00:31:40,600 --> 00:31:45,010
break off parts of if you had a JSON

00:31:43,059 --> 00:31:48,040
object a very large tree or something

00:31:45,010 --> 00:31:50,200
you could farm out sub trees and

00:31:48,040 --> 00:31:53,470
parallel ice those operations and then

00:31:50,200 --> 00:31:55,030
you know given those results you could

00:31:53,470 --> 00:32:03,100
accumulate those results back up on that

00:31:55,030 --> 00:32:05,620
on a different process okay so naturally

00:32:03,100 --> 00:32:07,090
the question arises at least to me if we

00:32:05,620 --> 00:32:11,559
have accumulate what's the opposite of

00:32:07,090 --> 00:32:13,390
accumulate so if accumulate is somehow

00:32:11,559 --> 00:32:16,350
folding up a data structure to produce a

00:32:13,390 --> 00:32:19,270
value then the opposite would be

00:32:16,350 --> 00:32:22,030
unfolding a seed value to produce a data

00:32:19,270 --> 00:32:27,520
structure and this is something we don't

00:32:22,030 --> 00:32:30,820
see much in C++ yet parsing yeah but I

00:32:27,520 --> 00:32:32,380
mean a lot of these things can be viewed

00:32:30,820 --> 00:32:33,250
if you view it through one lens they

00:32:32,380 --> 00:32:34,240
look one way and if you view them

00:32:33,250 --> 00:32:37,750
through a different lens they look at

00:32:34,240 --> 00:32:38,850
another way and which he chooses is down

00:32:37,750 --> 00:32:44,050
to you

00:32:38,850 --> 00:32:46,510
so if accumulate looks like this then I

00:32:44,050 --> 00:32:49,870
think perhaps unfold as I'm calling it

00:32:46,510 --> 00:32:51,610
looks something like this so it takes a

00:32:49,870 --> 00:32:53,860
function and it takes an output iterator

00:32:51,610 --> 00:32:57,490
which we're going to write to and it

00:32:53,860 --> 00:32:59,710
takes some kind of seed value the

00:32:57,490 --> 00:33:01,030
initial value and the idea is that we're

00:32:59,710 --> 00:33:04,800
going to call the function repeatedly

00:33:01,030 --> 00:33:07,480
with this initial value that that

00:33:04,800 --> 00:33:10,619
reduces over time I'm going to write the

00:33:07,480 --> 00:33:13,509
results to the alpha iterator

00:33:10,619 --> 00:33:16,959
so so the question this what should the

00:33:13,509 --> 00:33:19,149
signature of F be and how do we know

00:33:16,959 --> 00:33:23,049
when we're done right so these are two

00:33:19,149 --> 00:33:25,149
questions that arise so f is going to be

00:33:23,049 --> 00:33:29,409
the opposite of the binary operation

00:33:25,149 --> 00:33:31,599
that we pass to accumulate so if we kind

00:33:29,409 --> 00:33:34,809
of just invert that it means that we

00:33:31,599 --> 00:33:36,369
return the pair the result is going to

00:33:34,809 --> 00:33:39,339
be the thing that we write into the

00:33:36,369 --> 00:33:41,979
output iterator and then it's going to

00:33:39,339 --> 00:33:43,289
return the new value of our seed that

00:33:41,979 --> 00:33:48,549
we're going to pass to the next

00:33:43,289 --> 00:33:50,499
invocation of F and in general the

00:33:48,549 --> 00:33:53,589
result to write to the iterator could be

00:33:50,499 --> 00:33:55,359
a range or a sequence of values so it's

00:33:53,589 --> 00:33:58,509
not just necessarily just one value but

00:33:55,359 --> 00:33:59,769
it could be you know it might not just

00:33:58,509 --> 00:34:02,019
be a char for instance it could be a

00:33:59,769 --> 00:34:07,319
string to write into the the string that

00:34:02,019 --> 00:34:11,829
we are unfolding to so there's a few

00:34:07,319 --> 00:34:14,799
choices over how to define F choice one

00:34:11,829 --> 00:34:15,879
or house--it so I should say how to the

00:34:14,799 --> 00:34:21,039
other question which is how do we know

00:34:15,879 --> 00:34:23,859
when we're done right one choice is to

00:34:21,039 --> 00:34:26,139
say well we'll we'll have some sentinel

00:34:23,859 --> 00:34:28,000
value of of the same type as the seed

00:34:26,139 --> 00:34:31,440
and when the seed reaches that value is

00:34:28,000 --> 00:34:34,029
returned by F eventually then we're done

00:34:31,440 --> 00:34:35,919
we could also say we have a sentinel

00:34:34,029 --> 00:34:37,210
value of the the other type that the

00:34:35,919 --> 00:34:43,349
function returns do you know that the

00:34:37,210 --> 00:34:46,779
second part of the pair which is fine

00:34:43,349 --> 00:34:50,849
but both of these choices involve having

00:34:46,779 --> 00:34:53,200
a sentinel value inside the type and

00:34:50,849 --> 00:34:55,269
from my talk yesterday I don't really

00:34:53,200 --> 00:34:58,240
like that the obvious choice to me in

00:34:55,269 --> 00:34:59,710
this case is to use an optional because

00:34:58,240 --> 00:35:02,650
that provides you with a sentinel value

00:34:59,710 --> 00:35:04,990
which is outside of your type so if F

00:35:02,650 --> 00:35:10,809
returns an optional we can simply

00:35:04,990 --> 00:35:14,049
terminate when it returns no opt so this

00:35:10,809 --> 00:35:18,089
is what unfold might look like the

00:35:14,049 --> 00:35:20,259
function so we're taking the seed value

00:35:18,089 --> 00:35:21,940
and we've got a full loop initially

00:35:20,259 --> 00:35:22,940
we're calling the function with the seed

00:35:21,940 --> 00:35:26,630
value

00:35:22,940 --> 00:35:28,520
oh here is an optional and you know it

00:35:26,630 --> 00:35:30,800
has a conversion to boolean whether it's

00:35:28,520 --> 00:35:33,890
a null opt or I should say that that

00:35:30,800 --> 00:35:37,910
fails when it's a Mel opt and we know

00:35:33,890 --> 00:35:40,609
that we can we can keep we can move the

00:35:37,910 --> 00:35:42,079
second of the pair that was returned

00:35:40,609 --> 00:35:46,910
assuming that assuming that F returns

00:35:42,079 --> 00:35:49,280
something it was a pair of range to

00:35:46,910 --> 00:35:53,390
write to our output iterator and new

00:35:49,280 --> 00:35:56,900
seed value and so inside the for loop

00:35:53,390 --> 00:35:59,420
we're simply moving the range to write

00:35:56,900 --> 00:36:01,010
it to our output iterator and the for

00:35:59,420 --> 00:36:04,040
loop terminates when we return null opt

00:36:01,010 --> 00:36:09,200
and you know each time round it recalls

00:36:04,040 --> 00:36:11,119
with the new seed and finally of course

00:36:09,200 --> 00:36:12,950
we return the iterator the output

00:36:11,119 --> 00:36:16,099
iterator because the law of useful

00:36:12,950 --> 00:36:18,109
return makes us do so that we should do

00:36:16,099 --> 00:36:24,170
that otherwise the caller wouldn't know

00:36:18,109 --> 00:36:28,160
where the outputted toreador was so

00:36:24,170 --> 00:36:30,260
here's a very trivial example this is

00:36:28,160 --> 00:36:33,109
this is a function that we might pass to

00:36:30,260 --> 00:36:36,440
to unfold and this is a function written

00:36:33,109 --> 00:36:39,950
to turn a you know an Arabic number into

00:36:36,440 --> 00:36:41,900
a string of the Roman numeral and you

00:36:39,950 --> 00:36:44,270
can see that although you know Roman

00:36:41,900 --> 00:36:46,280
numerals aren't that great

00:36:44,270 --> 00:36:47,750
hence this function has a lot of if

00:36:46,280 --> 00:36:51,619
statement but this function I hope you

00:36:47,750 --> 00:36:53,660
can see is fairly trivial to write you

00:36:51,619 --> 00:36:56,450
just you just go down and down and down

00:36:53,660 --> 00:36:58,700
and you're reducing the seed each time

00:36:56,450 --> 00:37:02,270
and you're just outputting whatever you

00:36:58,700 --> 00:37:04,880
need to output and then you're calling

00:37:02,270 --> 00:37:09,500
code just looks like this you just

00:37:04,880 --> 00:37:11,690
unfold that function over you're over

00:37:09,500 --> 00:37:16,550
your seed value and what you get back is

00:37:11,690 --> 00:37:22,550
the string so that's a that's a you know

00:37:16,550 --> 00:37:24,619
fun little formulation so you know

00:37:22,550 --> 00:37:26,569
Marshall I said when I said about

00:37:24,619 --> 00:37:31,369
unfolding Marshall said he call it he'd

00:37:26,569 --> 00:37:33,650
call it pausing fold and unfold really

00:37:31,369 --> 00:37:35,030
are the same if you if you kind of look

00:37:33,650 --> 00:37:36,800
at them through different lenses so you

00:37:35,030 --> 00:37:39,440
know or accumulate

00:37:36,800 --> 00:37:40,640
we're conventionally we're taking a data

00:37:39,440 --> 00:37:44,480
structure and we're reducing it to a

00:37:40,640 --> 00:37:46,070
value and and unfold we are taking a

00:37:44,480 --> 00:37:47,960
seed value and expanding it to a data

00:37:46,070 --> 00:37:50,390
structure but really the seed value

00:37:47,960 --> 00:37:53,180
itself is sort of you know decreasing

00:37:50,390 --> 00:37:55,010
each time so you could say we're taking

00:37:53,180 --> 00:37:57,440
one data structure and transforming into

00:37:55,010 --> 00:37:58,130
another with either of these

00:37:57,440 --> 00:38:00,200
formulations

00:37:58,130 --> 00:38:06,740
and you know which you choose to use

00:38:00,200 --> 00:38:09,050
it's really a matter of convenience as I

00:38:06,740 --> 00:38:11,630
say structures are themselves values in

00:38:09,050 --> 00:38:13,490
this view of the world so between them

00:38:11,630 --> 00:38:19,340
you know accumulation and unfolding

00:38:13,490 --> 00:38:44,300
allows you to do generalized sort of

00:38:19,340 --> 00:38:47,630
data structure transformations yes yes

00:38:44,300 --> 00:38:50,150
oh right right right yes so parsing

00:38:47,630 --> 00:38:52,340
thinking about the Communists if we

00:38:50,150 --> 00:38:54,020
think about a JSON you know the JSON

00:38:52,340 --> 00:38:57,109
thing we'll be talking about the example

00:38:54,020 --> 00:39:00,650
I presented was was accumulating a JSON

00:38:57,109 --> 00:39:02,990
value and producing the string of course

00:39:00,650 --> 00:39:09,820
going the other way is exactly pausing

00:39:02,990 --> 00:39:12,050
the string to produce the JSON value so

00:39:09,820 --> 00:39:13,580
that's the end of the main part of my

00:39:12,050 --> 00:39:15,680
talk but I have this PostScript which is

00:39:13,580 --> 00:39:22,369
kind of so at this point does anyone

00:39:15,680 --> 00:39:24,560
have any questions no great well alright

00:39:22,369 --> 00:39:27,260
so I have a postscript which is kind of

00:39:24,560 --> 00:39:30,590
how this talk came about which is titled

00:39:27,260 --> 00:39:33,250
the fruits of algorithmic perversions so

00:39:30,590 --> 00:39:36,590
I woke up one morning and as you do I

00:39:33,250 --> 00:39:38,600
thought to myself if I was stuck on a

00:39:36,590 --> 00:39:42,770
desert island which algorithms would I

00:39:38,600 --> 00:39:45,109
take with me what are the building block

00:39:42,770 --> 00:39:46,790
algorithms in the STL now I've watched

00:39:45,109 --> 00:39:50,090
Shawn parents talk so like it like we

00:39:46,790 --> 00:39:52,430
all have and so you know maybe it party

00:39:50,090 --> 00:39:54,830
we talked earlier about partition rotate

00:39:52,430 --> 00:39:58,940
reverse these are all building block

00:39:54,830 --> 00:40:02,990
algorithms in the STL if you know maybe

00:39:58,940 --> 00:40:05,180
there are some others so I thought which

00:40:02,990 --> 00:40:07,220
algorithm is the most powerful and what

00:40:05,180 --> 00:40:09,290
if I couldn't write any loops except for

00:40:07,220 --> 00:40:11,300
just one to implement the one algorithm

00:40:09,290 --> 00:40:13,640
and I was stuck with that and which one

00:40:11,300 --> 00:40:17,710
would I pick and so that was what led me

00:40:13,640 --> 00:40:21,980
to to try out accumulate so I so I did

00:40:17,710 --> 00:40:24,560
so I looked at all the algorithms and

00:40:21,980 --> 00:40:28,520
here they are the the priests 2 plus 17

00:40:24,560 --> 00:40:29,720
this there's 90 of them I believe now

00:40:28,520 --> 00:40:32,300
some of these we can just remove

00:40:29,720 --> 00:40:34,730
straight away swap an ear to swap they

00:40:32,300 --> 00:40:38,000
really aren't loops so so get rid of

00:40:34,730 --> 00:40:39,320
those one these in particular Stefan

00:40:38,000 --> 00:40:40,700
would make an angry face at me if I

00:40:39,320 --> 00:40:47,150
implement it so I got rid of random

00:40:40,700 --> 00:40:49,630
shuffle and then of the remainder some

00:40:47,150 --> 00:40:52,160
are sort of binary search style things

00:40:49,630 --> 00:40:56,500
which aren't really amenable to linear

00:40:52,160 --> 00:40:59,630
traversals and some are heap operations

00:40:56,500 --> 00:41:03,410
which also involve jumping around inside

00:40:59,630 --> 00:41:06,170
your sequence but of the remainder there

00:41:03,410 --> 00:41:08,840
are 77 that remain these are basically

00:41:06,170 --> 00:41:10,790
plain loops and with a bit of

00:41:08,840 --> 00:41:12,230
jiggery-pokery and bending the rules I

00:41:10,790 --> 00:41:17,030
was able to implement all of them in

00:41:12,230 --> 00:41:24,080
terms of accumulate how long did it take

00:41:17,030 --> 00:41:25,370
me you know probably a few weeks maybe a

00:41:24,080 --> 00:41:27,350
month of evenings something like that

00:41:25,370 --> 00:41:32,990
just just on the off you know sort of

00:41:27,350 --> 00:41:35,270
thing so one of the key things that

00:41:32,990 --> 00:41:39,470
unlocked it was so so of course the

00:41:35,270 --> 00:41:43,670
cumulate does work on iterators but the

00:41:39,470 --> 00:41:45,230
one thing I so we dereference the thing

00:41:43,670 --> 00:41:49,010
that we passed the binary operation here

00:41:45,230 --> 00:41:50,900
and if we don't do that know that I'm

00:41:49,010 --> 00:41:53,420
suggesting that you know the SDL should

00:41:50,900 --> 00:41:55,430
be updated at all but but just

00:41:53,420 --> 00:41:57,730
reformulating humilate in terms of in in

00:41:55,430 --> 00:42:00,140
this format allowed me to treat

00:41:57,730 --> 00:42:02,270
iterators as accumulator with values and

00:42:00,140 --> 00:42:05,380
that's what allowed me to implement all

00:42:02,270 --> 00:42:05,380
the rest of the algorithms

00:42:06,040 --> 00:42:11,930
so now I'm the first to admit that some

00:42:09,290 --> 00:42:14,869
of these some of these things are little

00:42:11,930 --> 00:42:16,280
abusive using exceptions for control

00:42:14,869 --> 00:42:18,950
flow it's not something I usually like

00:42:16,280 --> 00:42:19,880
to do but you know for things like find

00:42:18,950 --> 00:42:23,240
which have the early-out

00:42:19,880 --> 00:42:26,230
I did do that reverse reverse I was

00:42:23,240 --> 00:42:30,260
particularly pleased with it involves

00:42:26,230 --> 00:42:32,660
accumulating a function and as you as

00:42:30,260 --> 00:42:34,220
you step down the forward iterator you

00:42:32,660 --> 00:42:35,960
wrap the previous function that you've

00:42:34,220 --> 00:42:37,760
accumulated a new function and then at

00:42:35,960 --> 00:42:40,070
the end you call the whole stack of

00:42:37,760 --> 00:42:45,410
functions and it unwinds the sequence in

00:42:40,070 --> 00:42:48,290
Reverse so the point of this really is

00:42:45,410 --> 00:42:50,110
to say that when you do kind of

00:42:48,290 --> 00:42:52,340
algorithmic perversions like this

00:42:50,110 --> 00:42:53,690
interesting alternatives can arise you

00:42:52,340 --> 00:42:55,850
know I'm not suggesting that we should

00:42:53,690 --> 00:42:58,340
ever actually use those formulations of

00:42:55,850 --> 00:43:02,840
reverse or use exceptions for control

00:42:58,340 --> 00:43:04,400
flow but you know with when you start

00:43:02,840 --> 00:43:06,710
looking at accumulate you you realize

00:43:04,400 --> 00:43:10,570
that you can do other algorithms like

00:43:06,710 --> 00:43:14,950
find all you know parallel find if a

00:43:10,570 --> 00:43:17,750
parallel adjacent find might be possible

00:43:14,950 --> 00:43:20,240
min element that returns an optional

00:43:17,750 --> 00:43:25,340
value might be an interesting

00:43:20,240 --> 00:43:28,119
formulation and all sort with forward

00:43:25,340 --> 00:43:32,180
iterators in fact there was a I think

00:43:28,119 --> 00:43:33,710
p227 was a proposal that that proposes

00:43:32,180 --> 00:43:36,950
weakening the iterator categories of

00:43:33,710 --> 00:43:41,840
some of the algorithms like sort and I

00:43:36,950 --> 00:44:01,490
think what do you remember the others

00:43:41,840 --> 00:44:02,540
Marshall okay great okay so that so

00:44:01,490 --> 00:44:04,160
there's an interesting paper that

00:44:02,540 --> 00:44:05,570
proposes weakening the iterator

00:44:04,160 --> 00:44:07,940
categories because right now sort

00:44:05,570 --> 00:44:10,820
requires a random access iterator and

00:44:07,940 --> 00:44:14,150
you know we know algorithms that can

00:44:10,820 --> 00:44:15,590
work with forward iterators so that

00:44:14,150 --> 00:44:17,739
would that would be an interesting thing

00:44:15,590 --> 00:44:23,420
perhaps

00:44:17,739 --> 00:44:25,640
so the really the conclusion of this

00:44:23,420 --> 00:44:27,739
talk is that I would I would suggest to

00:44:25,640 --> 00:44:29,239
you that almost everything can be

00:44:27,739 --> 00:44:31,849
expressed as some form of accumulation

00:44:29,239 --> 00:44:36,229
when I when I go hunting for raw loops

00:44:31,849 --> 00:44:37,969
in my code base I I found increasingly

00:44:36,229 --> 00:44:39,709
that I was you know as well as saying oh

00:44:37,969 --> 00:44:43,729
that's a that's a find that's a

00:44:39,709 --> 00:44:45,920
partition what that's a rotate kind of

00:44:43,729 --> 00:44:47,660
the overarching thing would be that's an

00:44:45,920 --> 00:44:49,189
accumulate that's in the cumulate you

00:44:47,660 --> 00:44:51,709
can do that with accumulate that could

00:44:49,189 --> 00:44:53,989
be in a human later now these should

00:44:51,709 --> 00:44:55,880
everywhere that's for you to decide but

00:44:53,989 --> 00:44:57,920
when you get used to seeing these

00:44:55,880 --> 00:45:03,859
monoidal patterns and things that can be

00:44:57,920 --> 00:45:06,199
accumulated they end up everywhere here

00:45:03,859 --> 00:45:06,829
are some links which you can peruse at

00:45:06,199 --> 00:45:08,839
your leisure

00:45:06,829 --> 00:45:12,400
they'll this will be in the slides of

00:45:08,839 --> 00:45:17,719
course so oh you wanna take a picture

00:45:12,400 --> 00:45:20,869
okay so so really so anytime you write

00:45:17,719 --> 00:45:24,949
an API look to see if any of the types

00:45:20,869 --> 00:45:26,989
you're providing are more noodle or or

00:45:24,949 --> 00:45:29,029
under any operations you provide because

00:45:26,989 --> 00:45:31,489
if you can identify that and document it

00:45:29,029 --> 00:45:33,469
then you open the opportunity for your

00:45:31,489 --> 00:45:38,900
for your use of your API to get all this

00:45:33,469 --> 00:45:40,039
stuff for free look for opportunities

00:45:38,900 --> 00:45:41,359
where you're applying a function in a

00:45:40,039 --> 00:45:43,939
loop if the output the function is a

00:45:41,359 --> 00:45:47,150
monoid it could be a place where you can

00:45:43,939 --> 00:45:51,130
use acumulate moloids are everywhere of

00:45:47,150 --> 00:45:54,019
course and think you know consider

00:45:51,130 --> 00:45:55,489
folding over heterogeneous sequences and

00:45:54,019 --> 00:45:57,069
multi-dimensional structures using

00:45:55,489 --> 00:46:00,229
formulations like the ones i've shown

00:45:57,069 --> 00:46:02,199
they can be useful too and what that the

00:46:00,229 --> 00:46:04,249
use they give you is effectively

00:46:02,199 --> 00:46:05,869
separating the traversal from the

00:46:04,249 --> 00:46:07,999
operation you can go ahead and define

00:46:05,869 --> 00:46:12,529
multiple operations and treat them the

00:46:07,999 --> 00:46:14,569
same way in the traversal and then

00:46:12,529 --> 00:46:16,160
unfolds are another way you can think

00:46:14,569 --> 00:46:18,619
about things and you can combine them

00:46:16,160 --> 00:46:24,289
out with folds to produce arbitrary

00:46:18,619 --> 00:46:27,170
transformations and finally algorithmic

00:46:24,289 --> 00:46:29,460
perversions I highly recommend looking I

00:46:27,170 --> 00:46:31,440
highly recommend looking at the STL

00:46:29,460 --> 00:46:34,369
and trying to write your own algorithms

00:46:31,440 --> 00:46:37,530
and Marshall has a talk about that later

00:46:34,369 --> 00:46:43,040
and in the end accumulation is not just

00:46:37,530 --> 00:46:43,040
for the boring stuff so thanks very much

00:46:54,109 --> 00:46:58,410
okay so Marshalls comment is that my

00:46:56,760 --> 00:47:03,359
algorithms are more interesting than his

00:46:58,410 --> 00:47:23,670
I'm not sure that's fair but anyone have

00:47:03,359 --> 00:47:29,820
questions yes okay

00:47:23,670 --> 00:47:33,089
so right so you can't always use so the

00:47:29,820 --> 00:47:35,220
comment is the comment is sometimes you

00:47:33,089 --> 00:47:36,619
have you try to use accumulate but you

00:47:35,220 --> 00:47:40,170
can't because you don't have iterators

00:47:36,619 --> 00:47:43,440
so the the non iterator accumulate or

00:47:40,170 --> 00:47:46,170
the accumulation over things other than

00:47:43,440 --> 00:48:00,330
iterators is pretty useful and worth

00:47:46,170 --> 00:48:04,160
generalizing you think okay so other

00:48:00,330 --> 00:48:07,680
examples of unfolding actually I

00:48:04,160 --> 00:48:09,599
so unfold this is a it's a thing that

00:48:07,680 --> 00:48:11,940
happens in in functional languages and I

00:48:09,599 --> 00:48:13,650
went to a friend who's a pretty is a you

00:48:11,940 --> 00:48:16,080
know pretty of a with with that kind of

00:48:13,650 --> 00:48:18,119
thing much more up-to-date than I am and

00:48:16,080 --> 00:48:21,390
I and I asked him you know at a

00:48:18,119 --> 00:48:23,670
functional meetup group I said it looks

00:48:21,390 --> 00:48:24,839
like unfold is very similar to fold what

00:48:23,670 --> 00:48:27,480
where would you use one and where would

00:48:24,839 --> 00:48:28,920
you use another and in typical fashion

00:48:27,480 --> 00:48:33,150
he said well they're both you know

00:48:28,920 --> 00:48:35,339
they're both sort of implicit things you

00:48:33,150 --> 00:48:36,540
can do on a sequence or they he he gave

00:48:35,339 --> 00:48:41,630
an answer which wasn't terribly

00:48:36,540 --> 00:48:41,630
satisfying I think it makes sense

00:48:43,200 --> 00:48:48,030
maybe it makes sense just by convention

00:48:44,690 --> 00:48:49,589
for thinking about the either reducing a

00:48:48,030 --> 00:48:52,829
date structure to what we might think of

00:48:49,589 --> 00:48:54,180
as normally a value or unfolding a seed

00:48:52,829 --> 00:48:57,329
I mean it's similar in some sense to

00:48:54,180 --> 00:48:58,710
generate or generate n when you're when

00:48:57,329 --> 00:49:01,049
you're but then you're you know you're

00:48:58,710 --> 00:49:02,520
using a seed value you're calling a

00:49:01,049 --> 00:49:05,910
generator function to fill in the

00:49:02,520 --> 00:49:08,339
sequence I don't have a hard and fast

00:49:05,910 --> 00:49:12,240
rule to say you should use this unfold

00:49:08,339 --> 00:49:23,819
here and accumulate here but they are

00:49:12,240 --> 00:49:28,470
quite similar yeah you'd call it Factory

00:49:23,819 --> 00:49:33,710
yeah so so unfolding pausing making

00:49:28,470 --> 00:49:33,710
objects in some way Deepti serialization

00:49:44,510 --> 00:49:56,750
right in the back there so factoring a

00:49:54,270 --> 00:50:00,569
number could be viewed as unfold in a

00:49:56,750 --> 00:50:02,700
highly unperformed as they come in

00:50:00,569 --> 00:50:03,750
yeah I have a feeling that when you fact

00:50:02,700 --> 00:50:06,630
that you know factoring a number is a

00:50:03,750 --> 00:50:08,400
pretty well well well understood and

00:50:06,630 --> 00:50:11,940
attacked operation and I doubt that

00:50:08,400 --> 00:50:14,309
unfold would be that's true a new

00:50:11,940 --> 00:50:17,450
approaches new approaches and as they

00:50:14,309 --> 00:50:20,450
are rhythmical versions a good thing

00:50:17,450 --> 00:50:20,450
yeah

00:50:46,450 --> 00:50:51,890
so the comment is that the folding

00:50:50,510 --> 00:50:55,960
heterogeneous things looks really

00:50:51,890 --> 00:50:57,260
powerful similar to composing functions

00:50:55,960 --> 00:51:02,360
yes

00:50:57,260 --> 00:51:11,930
function composition is a mod so so you

00:51:02,360 --> 00:51:17,180
could you could do that and well yeah

00:51:11,930 --> 00:51:28,760
maybe I mean as STL 2 is you know coming

00:51:17,180 --> 00:51:30,890
perhaps write a paper yes that's true if

00:51:28,760 --> 00:51:33,770
there's an implementation which which

00:51:30,890 --> 00:51:36,080
you can show that the committee is being

00:51:33,770 --> 00:51:40,300
used and solving a problem that that

00:51:36,080 --> 00:51:40,300
does a lot to to gain their attention

00:51:48,520 --> 00:51:55,430
yes yes the the searching stuff that

00:51:53,060 --> 00:51:57,830
Marshall did for 17 is an example of

00:51:55,430 --> 00:51:59,780
that also I would say the special math

00:51:57,830 --> 00:52:01,400
functions are an example of that there

00:51:59,780 --> 00:52:02,540
was already you know special math

00:52:01,400 --> 00:52:03,950
functions aren't something that I'm

00:52:02,540 --> 00:52:05,380
likely to use him every day but there

00:52:03,950 --> 00:52:07,880
was already you know there is a

00:52:05,380 --> 00:52:09,820
community that wants them there was

00:52:07,880 --> 00:52:13,250
already a high quality implementation

00:52:09,820 --> 00:52:15,110
and on the reverse side you know the the

00:52:13,250 --> 00:52:18,140
the implementation thing is there one of

00:52:15,110 --> 00:52:20,000
the reasons why concepts aren't yet in

00:52:18,140 --> 00:52:22,120
the standard but still in the TS because

00:52:20,000 --> 00:52:26,680
there was not enough implementation

00:52:22,120 --> 00:52:26,680
experience yet yeah

00:52:43,340 --> 00:52:49,320
right so the observation is yes

00:52:46,040 --> 00:52:51,060
enclosure if you've watched Ricky's

00:52:49,320 --> 00:52:54,090
torque on transducers and followed that

00:52:51,060 --> 00:52:56,880
stuff you'll know that transducers are a

00:52:54,090 --> 00:52:59,760
a similar thing where that's sort of

00:52:56,880 --> 00:53:01,080
teasing apart traversals from from what

00:52:59,760 --> 00:53:04,860
you're doing to the data structure and

00:53:01,080 --> 00:53:06,600
in similar fashion everything can be

00:53:04,860 --> 00:53:08,940
implemented in terms of fault and

00:53:06,600 --> 00:53:09,630
transducers yeah this is this is very

00:53:08,940 --> 00:53:11,190
much

00:53:09,630 --> 00:53:14,370
you know I'm cribbing everything from

00:53:11,190 --> 00:53:16,110
functional languages here so but

00:53:14,370 --> 00:53:20,390
hopefully you know giving it a C+ spin

00:53:16,110 --> 00:53:48,900
and and showing where it might be useful

00:53:20,390 --> 00:53:52,500
was there a question over here okay so

00:53:48,900 --> 00:53:55,410
yeah that will be interesting so so the

00:53:52,500 --> 00:53:58,530
idea is if you formylated unfold in

00:53:55,410 --> 00:54:01,440
terms of a pull rather than a push you

00:53:58,530 --> 00:54:03,890
could have well the example given was an

00:54:01,440 --> 00:54:08,150
MPEG decoder pulling frames off a cue

00:54:03,890 --> 00:54:08,150
that would be an interesting formulation

00:54:08,690 --> 00:54:12,770

YouTube URL: https://www.youtube.com/watch?v=B6twozNPUoA


