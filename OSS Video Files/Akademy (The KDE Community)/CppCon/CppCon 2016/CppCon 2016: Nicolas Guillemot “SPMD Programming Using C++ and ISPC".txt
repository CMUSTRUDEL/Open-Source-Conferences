Title: CppCon 2016: Nicolas Guillemot “SPMD Programming Using C++ and ISPC"
Publication date: 2016-10-02
Playlist: CppCon 2016
Description: 
	http://CppCon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/cppcon/cppcon2016
—
Love writing blazing fast SIMD code on CPU? Tired of dealing with ugly intrinsics and clumsy SIMD float4 classes? Has your compiler's auto-vectorization ever stopped working, causing unpredictable performance regressions? Wish you could write efficient SIMD code without locking yourself into a specific instruction set, while still taking advantage of a range of hardware from old desktops to new Intel Xeon Phi rigs? 

The solution is here, and it's called SPMD! 

SPMD is an elegant parallel programming technique for writing SIMD code, which automates the tedious constructions normally required when using intrinsics or assembly, breaks free of ties to specific instruction sets, and still allows you to work at the granularity of SIMD vectors when necessary. 

This talk will first review the underlying theory of SPMD, then introduce the ISPC programming language as an example of what SPMD code looks like. We'll also look at how SPMD is used on GPUs like AMD's GCN. Finally, we will see how SPMD code can be written in unextended C++.
— 
Nicolas Guillemot
MSc Student, University of Victoria
Hi, nice to meet you! My name is Nicolas, and my main interests are game development, real-time rendering, graphics hardware and graphics APIs. I tackle problems at the intersection of designing efficient computer algorithms and leveraging the strengths of hardware. My favorite thing about C++ is that it lets me write detailed systems-level code and high-level GUI code together in a single robust language.
—
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,030 --> 00:00:04,080
so welcome to my talk I'm gonna be

00:00:02,010 --> 00:00:05,940
talking today about SPMD programming C++

00:00:04,080 --> 00:00:08,790
basically are we gonna write a sim

00:00:05,940 --> 00:00:11,340
decode and C++ that's gonna be easy and

00:00:08,790 --> 00:00:14,219
fun so just a little bit about me my

00:00:11,340 --> 00:00:16,260
name is Nicolas I mostly work in BO

00:00:14,219 --> 00:00:17,940
games technology in the past I've worked

00:00:16,260 --> 00:00:20,400
at some Game Studios like in Lights

00:00:17,940 --> 00:00:23,010
entertainments and you sports I've also

00:00:20,400 --> 00:00:25,260
worked at Intel doing graphics right now

00:00:23,010 --> 00:00:27,750
I'm working a computer graphics research

00:00:25,260 --> 00:00:30,060
lab at University of Victoria by the way

00:00:27,750 --> 00:00:34,380
that's me as my girlfriend Jessica and

00:00:30,060 --> 00:00:36,510
these are our two cats so here's the

00:00:34,380 --> 00:00:38,190
overview for today's talk first I'm

00:00:36,510 --> 00:00:39,899
gonna talk to you about just basic Sims

00:00:38,190 --> 00:00:41,219
II building blocks so just the basic

00:00:39,899 --> 00:00:43,559
fundamentals of how to write code using

00:00:41,219 --> 00:00:47,309
cindy after that i'm gonna give you an

00:00:43,559 --> 00:00:48,510
introduction to what SPMD is and in

00:00:47,309 --> 00:00:49,920
order to get you comfortable with the

00:00:48,510 --> 00:00:51,480
idea of SPMD we're gonna look at some

00:00:49,920 --> 00:00:53,219
case that use of where SpMT is used in

00:00:51,480 --> 00:00:55,649
the wild and be able to understand how

00:00:53,219 --> 00:00:57,210
to deeper level finally I'm going to

00:00:55,649 --> 00:00:59,399
show you how to do SPMD programming in

00:00:57,210 --> 00:01:02,910
C++ using a small library I've made

00:00:59,399 --> 00:01:06,330
called VPS BMD so I would like her to do

00:01:02,910 --> 00:01:07,770
let's begin so for simply building

00:01:06,330 --> 00:01:09,750
blocks I'm gonna basically show you how

00:01:07,770 --> 00:01:11,340
to write some basic sanity code using

00:01:09,750 --> 00:01:11,850
intrinsics which I'll explain in a

00:01:11,340 --> 00:01:15,330
second

00:01:11,850 --> 00:01:16,710
so the big idea of sim d is if you're

00:01:15,330 --> 00:01:18,960
not aware it stands for a single

00:01:16,710 --> 00:01:20,580
instruction multiple data which means

00:01:18,960 --> 00:01:22,470
that in one instruction you're doing up

00:01:20,580 --> 00:01:25,350
you know you don't operation on multiple

00:01:22,470 --> 00:01:27,450
operands you know in parallel so for

00:01:25,350 --> 00:01:29,220
example if you have these four floats

00:01:27,450 --> 00:01:31,619
and you want to add them in parallel

00:01:29,220 --> 00:01:34,259
with four other floats you can Det in

00:01:31,619 --> 00:01:35,670
one operation and so in one sim the

00:01:34,259 --> 00:01:36,990
instruction you can do an addition in

00:01:35,670 --> 00:01:39,540
parallel that gives you the result of

00:01:36,990 --> 00:01:40,829
four floats and part like that so if you

00:01:39,540 --> 00:01:44,100
have to translate this to actual you

00:01:40,829 --> 00:01:47,159
know today C++ code you could do it like

00:01:44,100 --> 00:01:51,479
this so okay ease you into this notation

00:01:47,159 --> 00:01:52,649
here these statements initialize the

00:01:51,479 --> 00:01:54,840
input so you can see the top of the

00:01:52,649 --> 00:01:57,390
slide so you can see on the left there

00:01:54,840 --> 00:02:00,420
there's a kind of a new type maybe this

00:01:57,390 --> 00:02:03,689
is m1 28 so the idea is that's 128-bit

00:02:00,420 --> 00:02:05,460
datatype that's a non-standard type the

00:02:03,689 --> 00:02:08,250
reason why it's hard 28 bits is because

00:02:05,460 --> 00:02:10,259
in 128 bits you can store four 32-bit

00:02:08,250 --> 00:02:13,480
objects so those you store four floats

00:02:10,259 --> 00:02:16,000
and you can initialize these very

00:02:13,480 --> 00:02:18,430
in a variety of ways but right now we're

00:02:16,000 --> 00:02:20,530
just using mmm set PS and this is a

00:02:18,430 --> 00:02:22,330
intrinsic function that lets you

00:02:20,530 --> 00:02:24,849
initialize one of these hemos twenty

00:02:22,330 --> 00:02:26,290
eighths with four specific values which

00:02:24,849 --> 00:02:30,190
basically it'll translate something like

00:02:26,290 --> 00:02:32,170
a move or a load so let's say we

00:02:30,190 --> 00:02:33,970
initialize these values and by the way I

00:02:32,170 --> 00:02:35,260
should mention that mmm at the start

00:02:33,970 --> 00:02:37,180
that's just the namespace for all these

00:02:35,260 --> 00:02:40,450
intrinsics for the faithful instruction

00:02:37,180 --> 00:02:42,730
sets and PS stands for packed single

00:02:40,450 --> 00:02:43,930
precision float so the word packed is to

00:02:42,730 --> 00:02:46,060
emphasize the fact that there's more

00:02:43,930 --> 00:02:49,510
than one object being put into the same

00:02:46,060 --> 00:02:51,190
object right and the S for a single

00:02:49,510 --> 00:02:52,660
precision is just to say that's 32-bit

00:02:51,190 --> 00:02:54,819
floats so that's how you decode

00:02:52,660 --> 00:02:57,879
basically these and these intrinsic

00:02:54,819 --> 00:03:00,549
names to do the addition it's actually

00:02:57,879 --> 00:03:02,560
pretty straightforward so mmm add PS to

00:03:00,549 --> 00:03:04,239
just add to pack single position float

00:03:02,560 --> 00:03:05,829
registers and that's how you get the

00:03:04,239 --> 00:03:08,680
results you can see on the top of the

00:03:05,829 --> 00:03:11,290
slide moving on you know that's how you

00:03:08,680 --> 00:03:12,400
doing operation on four objects but on

00:03:11,290 --> 00:03:14,590
four floats but what if you want to do

00:03:12,400 --> 00:03:16,540
it on an array of floats so that you do

00:03:14,590 --> 00:03:18,190
that is basically you just iterates over

00:03:16,540 --> 00:03:20,769
the array of floats in steps of Sindhi

00:03:18,190 --> 00:03:23,380
with so you might start here do a

00:03:20,769 --> 00:03:25,690
parallel addition here move on to the

00:03:23,380 --> 00:03:28,389
next one in a step of four do another

00:03:25,690 --> 00:03:30,700
one moving a step of four do another one

00:03:28,389 --> 00:03:33,669
alright that's how you get an addition

00:03:30,700 --> 00:03:34,900
using sim D on an array of elements if

00:03:33,669 --> 00:03:36,669
you have to write this in C++ code we

00:03:34,900 --> 00:03:38,739
can do something like this so for

00:03:36,669 --> 00:03:42,220
simplicity we will assume that the N is

00:03:38,739 --> 00:03:45,760
a say multiple of four just so we don't

00:03:42,220 --> 00:03:46,959
have any weird trailing objects and the

00:03:45,760 --> 00:03:49,060
for loop you're pretty familiar it's

00:03:46,959 --> 00:03:51,669
just a saml for a loop but incrementing

00:03:49,060 --> 00:03:53,650
it steps of four so at every loop we

00:03:51,669 --> 00:03:56,769
load the operands that are gonna be

00:03:53,650 --> 00:03:58,450
inputted so here let's use the load PS

00:03:56,769 --> 00:03:59,590
intrinsic which just yes takes an

00:03:58,450 --> 00:04:02,440
average of memory and loads the four

00:03:59,590 --> 00:04:04,690
floats there so we've got two arrays and

00:04:02,440 --> 00:04:05,829
put one input to that perform the

00:04:04,690 --> 00:04:08,500
addition just the same way as the last

00:04:05,829 --> 00:04:10,959
slide and finally store back the results

00:04:08,500 --> 00:04:13,480
to memory using the store PS instruction

00:04:10,959 --> 00:04:16,479
which will or sorry intrinsic voice we

00:04:13,480 --> 00:04:18,090
shall write it so the output array so

00:04:16,479 --> 00:04:21,070
it's as simple as that

00:04:18,090 --> 00:04:22,960
now that was how to implement the loop

00:04:21,070 --> 00:04:24,159
and when it's all trivially Pera like

00:04:22,960 --> 00:04:26,880
it's just a loop everything's pretty

00:04:24,159 --> 00:04:29,130
easy but what if you have an if

00:04:26,880 --> 00:04:30,780
and then it gets kind of weird cuz it's

00:04:29,130 --> 00:04:32,940
not as obvious how to actually turn this

00:04:30,780 --> 00:04:34,410
into a sim decode so I'm gonna show you

00:04:32,940 --> 00:04:37,500
how to do that and I'm gonna show you

00:04:34,410 --> 00:04:38,400
how to do it step-by-step and so the way

00:04:37,500 --> 00:04:40,830
that's gonna work is that there's gonna

00:04:38,400 --> 00:04:42,720
be basically two things moving here two

00:04:40,830 --> 00:04:45,090
moving pieces there's gonna be a mask

00:04:42,720 --> 00:04:47,580
which tells you which of the currents

00:04:45,090 --> 00:04:49,860
crepitations are active and that in here

00:04:47,580 --> 00:04:52,770
is the input and the reason why there's

00:04:49,860 --> 00:04:54,120
four numbers under a is because if we

00:04:52,770 --> 00:04:55,230
convert this function into a sim D

00:04:54,120 --> 00:04:57,060
version of that function it's gonna be

00:04:55,230 --> 00:05:00,060
working on four inputs in parallel

00:04:57,060 --> 00:05:01,620
giving you four results and so basically

00:05:00,060 --> 00:05:02,550
what I want you to think about this the

00:05:01,620 --> 00:05:03,960
way I want you to think about this is

00:05:02,550 --> 00:05:05,670
think about as if we're running this

00:05:03,960 --> 00:05:06,750
function four times in parallel like if

00:05:05,670 --> 00:05:10,080
it was running on four threads in

00:05:06,750 --> 00:05:11,220
parallel and each of those threads of

00:05:10,080 --> 00:05:13,140
execution they're gonna be represented

00:05:11,220 --> 00:05:15,420
by one column in the image as I'm going

00:05:13,140 --> 00:05:18,630
to show and to explain more that the

00:05:15,420 --> 00:05:19,950
mask thing it means that those lanes are

00:05:18,630 --> 00:05:23,250
active and you'll see what that means in

00:05:19,950 --> 00:05:24,810
a second and just explain the not zero

00:05:23,250 --> 00:05:29,300
is to say that it's it's like all one's

00:05:24,810 --> 00:05:31,890
like all fully hi to see that's active

00:05:29,300 --> 00:05:33,660
so the way that you put this in Sim D is

00:05:31,890 --> 00:05:35,730
when you get to a conditional statement

00:05:33,660 --> 00:05:37,290
like this if here what you do is you

00:05:35,730 --> 00:05:39,660
evaluate the expressions a less than 0

00:05:37,290 --> 00:05:41,460
but in since if we could read this as

00:05:39,660 --> 00:05:42,960
sim D the value of a is actually four

00:05:41,460 --> 00:05:44,250
values and so the result of the

00:05:42,960 --> 00:05:47,340
comparison is different depending on the

00:05:44,250 --> 00:05:50,490
value so you can see on the left there

00:05:47,340 --> 00:05:51,900
I've only turned on the elements of the

00:05:50,490 --> 00:05:53,850
mask where the comparison returned true

00:05:51,900 --> 00:05:55,980
and the ones that are blue are the ones

00:05:53,850 --> 00:05:57,180
so the comparison failed and I kind of

00:05:55,980 --> 00:06:00,750
like color coded on the right as well

00:05:57,180 --> 00:06:02,250
and so the way it works is that when you

00:06:00,750 --> 00:06:05,520
do the statements inside the if block

00:06:02,250 --> 00:06:07,740
where you assign 0 to a for example that

00:06:05,520 --> 00:06:09,780
assignment only happens on the lanes of

00:06:07,740 --> 00:06:12,480
execution that are currently active so

00:06:09,780 --> 00:06:13,980
you can see on the right there for 8 the

00:06:12,480 --> 00:06:16,200
elements are in blue which are not

00:06:13,980 --> 00:06:17,730
active those ones didn't get affected by

00:06:16,200 --> 00:06:20,820
the assignment of 0 only the ones that

00:06:17,730 --> 00:06:22,350
are active got it got assigned to 0 when

00:06:20,820 --> 00:06:23,850
we got to the else you can just put the

00:06:22,350 --> 00:06:25,920
mask that's when we were doing it and

00:06:23,850 --> 00:06:28,830
now the points that are off of the on

00:06:25,920 --> 00:06:31,470
and the ones that are on or off and when

00:06:28,830 --> 00:06:33,840
we do a plus equals 1 that addition of 1

00:06:31,470 --> 00:06:36,690
only affects the lanes of execution

00:06:33,840 --> 00:06:40,469
where the mask is active in the else

00:06:36,690 --> 00:06:42,029
block so finally you return the result

00:06:40,469 --> 00:06:43,769
what do you know we get the results of

00:06:42,029 --> 00:06:47,819
busy dysfunction being around four times

00:06:43,769 --> 00:06:49,800
in parallel using sim D so I'm going to

00:06:47,819 --> 00:06:52,830
translate the same function again but

00:06:49,800 --> 00:06:54,139
this time using intrinsics and if you

00:06:52,830 --> 00:06:56,159
know intrinsic swell ago you'll see that

00:06:54,139 --> 00:06:57,929
I'm kind of like cheating here there's

00:06:56,159 --> 00:07:00,899
like some shortcuts of notation that

00:06:57,929 --> 00:07:02,159
don't actually work so this is basically

00:07:00,899 --> 00:07:04,889
just to fit it on slide so you'll have

00:07:02,159 --> 00:07:06,569
to excuse me for that so going over the

00:07:04,889 --> 00:07:08,580
same process again we start with a mask

00:07:06,569 --> 00:07:11,339
that's all on initially and the inputs

00:07:08,580 --> 00:07:13,619
for a the first step we do a comparison

00:07:11,339 --> 00:07:15,509
so this is the compare less than just

00:07:13,619 --> 00:07:16,800
doing a less than comparison and so the

00:07:15,509 --> 00:07:18,449
result of the comparison is actually

00:07:16,800 --> 00:07:22,800
exactly what it's shown in the mask

00:07:18,449 --> 00:07:25,050
value so then the next statement I'm

00:07:22,800 --> 00:07:27,599
using this blend V intrinsic my blend B

00:07:25,050 --> 00:07:30,089
does is it takes two values and it

00:07:27,599 --> 00:07:32,669
merges them based on the values in a

00:07:30,089 --> 00:07:34,679
mask so the value of mass decides

00:07:32,669 --> 00:07:38,189
whether the result should be taken from

00:07:34,679 --> 00:07:40,379
the from a or from zero and so that's

00:07:38,189 --> 00:07:42,209
how the two was the two values a and

00:07:40,379 --> 00:07:45,059
zero are merged into one value based on

00:07:42,209 --> 00:07:46,169
the results of the comparison now you

00:07:45,059 --> 00:07:48,240
get to the else blog so you just flip

00:07:46,169 --> 00:07:50,369
the mask using this imaginary not

00:07:48,240 --> 00:07:51,899
intrinsic which doesn't exist but it's

00:07:50,369 --> 00:07:54,990
convenient and it's nice if it did exist

00:07:51,899 --> 00:07:56,879
and then when we get to the two the

00:07:54,990 --> 00:07:58,589
blend be for the else block it's

00:07:56,879 --> 00:08:00,389
basically the same thing where were

00:07:58,589 --> 00:08:02,369
merging values of a and a plus one based

00:08:00,389 --> 00:08:03,479
on the result the masked so only the the

00:08:02,369 --> 00:08:06,329
lanes that are active in the else block

00:08:03,479 --> 00:08:08,369
get +1 and the ones that didn't don't

00:08:06,329 --> 00:08:10,379
change and there you go we get the final

00:08:08,369 --> 00:08:11,579
result so that's pretty much how you

00:08:10,379 --> 00:08:13,979
would actually implement this using

00:08:11,579 --> 00:08:15,539
intrinsic and and match it matches very

00:08:13,979 --> 00:08:16,039
closely what the assembly code would

00:08:15,539 --> 00:08:18,989
look like

00:08:16,039 --> 00:08:20,610
so if else is pretty basic so what about

00:08:18,989 --> 00:08:23,099
all the other control flow you get in a

00:08:20,610 --> 00:08:26,129
regular C program like for a while or

00:08:23,099 --> 00:08:28,379
switch or continue you know those are

00:08:26,129 --> 00:08:29,999
all possible and I think that what I've

00:08:28,379 --> 00:08:31,860
covered so far is enough for you to

00:08:29,999 --> 00:08:33,149
understand how to implement them so I'm

00:08:31,860 --> 00:08:35,009
leaving as an expense for the reader and

00:08:33,149 --> 00:08:36,269
just as a hint is just masks like

00:08:35,009 --> 00:08:39,930
everything's just masks like everywhere

00:08:36,269 --> 00:08:42,360
so that's basically the TLDR if I

00:08:39,930 --> 00:08:44,670
implement all these other things now

00:08:42,360 --> 00:08:46,639
this I've shown you so far how to write

00:08:44,670 --> 00:08:48,750
seam decode using assembly intrinsics

00:08:46,639 --> 00:08:51,230
but it's not always the best choice for

00:08:48,750 --> 00:08:54,029
the job so let's see some pros and cons

00:08:51,230 --> 00:08:54,340
it's nice that the intrinsics are

00:08:54,029 --> 00:08:56,500
actually

00:08:54,340 --> 00:08:58,960
be pretty close to assembly so in that

00:08:56,500 --> 00:09:00,670
way you can kind of like maybe just sum

00:08:58,960 --> 00:09:02,980
up you know assembly level optimizations

00:09:00,670 --> 00:09:05,050
of your code but the problem is that

00:09:02,980 --> 00:09:07,180
it's so ugly to implement stuff like

00:09:05,050 --> 00:09:09,190
if-else and for loops and stuff that

00:09:07,180 --> 00:09:11,230
actually it's it's hard to actually make

00:09:09,190 --> 00:09:12,670
your algorithm better and it turns out

00:09:11,230 --> 00:09:14,710
that a lot of time that actually has a

00:09:12,670 --> 00:09:16,480
better payoff and then puts it around

00:09:14,710 --> 00:09:19,480
with little like changes of assembly

00:09:16,480 --> 00:09:21,850
code also pretty knowing is the codes

00:09:19,480 --> 00:09:24,040
not really portable it's it's bound to

00:09:21,850 --> 00:09:27,460
like a particular rule the ones I showed

00:09:24,040 --> 00:09:29,200
our balance are basically like x86 but

00:09:27,460 --> 00:09:30,700
even like if you if you look like a

00:09:29,200 --> 00:09:32,650
certain intrinsic like stringent

00:09:30,700 --> 00:09:34,330
intrinsics only work on certain x86

00:09:32,650 --> 00:09:37,480
processors so it's not even portable

00:09:34,330 --> 00:09:38,800
like across x86 on top of that so if you

00:09:37,480 --> 00:09:40,690
if you haven't been to this problem in

00:09:38,800 --> 00:09:43,180
production and you might report to like

00:09:40,690 --> 00:09:44,800
arm or something you'll have to write

00:09:43,180 --> 00:09:46,690
your code again and so not only are

00:09:44,800 --> 00:09:47,650
gonna have duplicated code but actually

00:09:46,690 --> 00:09:49,360
you're gonna have like complicated

00:09:47,650 --> 00:09:51,340
duplicate code because this is like this

00:09:49,360 --> 00:09:53,410
is like assembly ish code and it's it's

00:09:51,340 --> 00:09:55,540
not very easy to read or write and

00:09:53,410 --> 00:09:57,310
there's lots of tricky details so it's

00:09:55,540 --> 00:10:00,280
not easy to duplicate this code and

00:09:57,310 --> 00:10:02,380
actually do it properly so how can you

00:10:00,280 --> 00:10:04,960
fix these problems well the solution I'm

00:10:02,380 --> 00:10:09,280
here to talk to you about today is SPMD

00:10:04,960 --> 00:10:11,350
honest imd so lots of acronyms here so

00:10:09,280 --> 00:10:13,810
let me explain so SPMD stands for a

00:10:11,350 --> 00:10:16,000
single program multiple data what it

00:10:13,810 --> 00:10:18,160
means is that you write a program as if

00:10:16,000 --> 00:10:20,710
it was just a regular old serial program

00:10:18,160 --> 00:10:22,600
but in reality the serial code you're

00:10:20,710 --> 00:10:25,300
running actually corresponds to doing

00:10:22,600 --> 00:10:27,250
Sindhi work so we're gonna go more into

00:10:25,300 --> 00:10:28,330
this it warranted a detail about this so

00:10:27,250 --> 00:10:30,310
don't worry if it doesn't make sense

00:10:28,330 --> 00:10:31,840
right away one of the things that's

00:10:30,310 --> 00:10:34,690
really nice about it that you'll learn

00:10:31,840 --> 00:10:36,070
to appreciate hopefully is that with

00:10:34,690 --> 00:10:38,140
this design you get where they call

00:10:36,070 --> 00:10:40,840
maximal convergence and what maximal

00:10:38,140 --> 00:10:43,030
convergence means is that let's put it

00:10:40,840 --> 00:10:44,800
this way earlier I told you that you

00:10:43,030 --> 00:10:46,150
should see the code being run as for

00:10:44,800 --> 00:10:48,610
instances of the same program running in

00:10:46,150 --> 00:10:50,710
parallel and you could implement that

00:10:48,610 --> 00:10:52,150
with for POSIX threads like if you want

00:10:50,710 --> 00:10:53,950
to run a function four times in parallel

00:10:52,150 --> 00:10:55,060
you could just spawn four threads run

00:10:53,950 --> 00:10:57,670
the same function from the four threads

00:10:55,060 --> 00:10:58,960
and that would work the problem is that

00:10:57,670 --> 00:11:00,790
if you want to be able to communicate

00:10:58,960 --> 00:11:02,020
between these threads so for example

00:11:00,790 --> 00:11:03,370
maybe you have some computation that's

00:11:02,020 --> 00:11:06,070
only that's that's dumb once and then

00:11:03,370 --> 00:11:07,030
shared between other threads if you

00:11:06,070 --> 00:11:07,870
don't do that kind of communication is

00:11:07,030 --> 00:11:09,130
gonna be really tedious

00:11:07,870 --> 00:11:10,800
you'd have to put like mutexes and stuff

00:11:09,130 --> 00:11:14,140
in barriers and all sorts of weird stuff

00:11:10,800 --> 00:11:15,820
but with Cindy you just you don't need

00:11:14,140 --> 00:11:17,200
that like there's no like Hardware

00:11:15,820 --> 00:11:18,790
threads that are running on different

00:11:17,200 --> 00:11:20,590
like different speeds

00:11:18,790 --> 00:11:23,020
it's just lockstep Cindy you don't need

00:11:20,590 --> 00:11:25,000
barriers there's no redness you can kind

00:11:23,020 --> 00:11:26,350
of just like communicate between these

00:11:25,000 --> 00:11:29,560
different distances of the programming

00:11:26,350 --> 00:11:30,910
run and the way you can see it kind of

00:11:29,560 --> 00:11:32,980
is this kind of like it's a kind of like

00:11:30,910 --> 00:11:35,290
secret ization at sequence points so

00:11:32,980 --> 00:11:36,580
it's one way you could see is like if it

00:11:35,290 --> 00:11:38,260
was multiple threads running it'd be

00:11:36,580 --> 00:11:40,210
like a mutex to lock like earth to

00:11:38,260 --> 00:11:42,100
synchronize them like in between every

00:11:40,210 --> 00:11:44,080
statement and actually this person was

00:11:42,100 --> 00:11:47,710
pretty closely to what actual c++ works

00:11:44,080 --> 00:11:50,470
like today because of sequence points so

00:11:47,710 --> 00:11:52,570
moving on I want you to get a feel for

00:11:50,470 --> 00:11:54,910
SPMD to understand kind of like how it

00:11:52,570 --> 00:11:56,800
works and and your mind around like

00:11:54,910 --> 00:11:58,060
thinking in the SpMT kind of way so

00:11:56,800 --> 00:12:00,100
we're gonna be looking at two case

00:11:58,060 --> 00:12:02,740
studies the first one is is PC which is

00:12:00,100 --> 00:12:04,600
a CPU programming language for SIM T and

00:12:02,740 --> 00:12:07,770
we're also me looking at our house

00:12:04,600 --> 00:12:11,560
shaders work on the AMD GCN GPU which is

00:12:07,770 --> 00:12:12,790
GPU programming language and so you

00:12:11,560 --> 00:12:15,310
don't necessarily need to focus too much

00:12:12,790 --> 00:12:16,720
on the details of ice PC or AMD but more

00:12:15,310 --> 00:12:20,500
I want you to get familiar with the idea

00:12:16,720 --> 00:12:25,150
of SPMD so history number one is the SP

00:12:20,500 --> 00:12:27,040
C compiler so ice PC is a compiler for a

00:12:25,150 --> 00:12:30,580
C programming language made by my father

00:12:27,040 --> 00:12:31,840
and some other people I guess is PC guy

00:12:30,580 --> 00:12:33,550
github diodes where you can find it if

00:12:31,840 --> 00:12:35,020
you want to go check it out

00:12:33,550 --> 00:12:37,120
she's gonna do a quick overview here

00:12:35,020 --> 00:12:39,310
it's basically a C like language for

00:12:37,120 --> 00:12:41,550
SPMD on SIMD in fact it was originally

00:12:39,310 --> 00:12:43,420
based on a C compiler so it's very close

00:12:41,550 --> 00:12:44,770
another way you can see it if you're a

00:12:43,420 --> 00:12:46,090
graphics programmer this might make more

00:12:44,770 --> 00:12:49,660
sense for you it's it's like shaders for

00:12:46,090 --> 00:12:51,400
the CPU so it's actually it's an Intel

00:12:49,660 --> 00:12:53,350
project but it's actually open source it

00:12:51,400 --> 00:12:55,000
supports a wide variety of platforms to

00:12:53,350 --> 00:12:57,820
basically hooks into LLVM at the end of

00:12:55,000 --> 00:13:00,850
day so you got x86 64 you got an arm you

00:12:57,820 --> 00:13:04,390
got xeon phi it works on ps4 so that's

00:13:00,850 --> 00:13:06,850
all good now let's move on to an actual

00:13:04,390 --> 00:13:07,870
example of how use ice PC so just gonna

00:13:06,850 --> 00:13:11,230
walk you through this code here and

00:13:07,870 --> 00:13:13,150
hopefully it's gonna be insightful so

00:13:11,230 --> 00:13:15,670
here's the signature for the function

00:13:13,150 --> 00:13:16,840
I'm gonna demonstrate this is a simple

00:13:15,670 --> 00:13:19,630
function it's gonna do only a little bit

00:13:16,840 --> 00:13:21,220
of trivial work you can see a few new

00:13:19,630 --> 00:13:23,019
things here from a regular

00:13:21,220 --> 00:13:25,300
program first of all you can see there's

00:13:23,019 --> 00:13:27,399
a uniform keyboard that shows up so the

00:13:25,300 --> 00:13:29,800
uniform keyword in is PC means that

00:13:27,399 --> 00:13:32,800
value is a scalar which is like

00:13:29,800 --> 00:13:35,019
basically if you come from C++ when you

00:13:32,800 --> 00:13:37,509
see uniform Biscay it's the same thing

00:13:35,019 --> 00:13:39,310
as if it was in C++ I mean basically if

00:13:37,509 --> 00:13:40,779
you want translate this to C++ just take

00:13:39,310 --> 00:13:42,639
off the uniform keyword and it means the

00:13:40,779 --> 00:13:44,589
same thing but that's how I see it

00:13:42,639 --> 00:13:46,990
anyways and then there's a new keyword

00:13:44,589 --> 00:13:48,779
also on the left here export and so what

00:13:46,990 --> 00:13:51,069
export does is just I species way of

00:13:48,779 --> 00:13:53,470
creating the foreign function interface

00:13:51,069 --> 00:13:55,870
so this says that this function can be

00:13:53,470 --> 00:13:58,689
called from C and it works into toll-f

00:13:55,870 --> 00:14:00,550
fi system so this function is going to

00:13:58,689 --> 00:14:01,660
loop over the array for inputs and keep

00:14:00,550 --> 00:14:06,100
just interpretation and write the

00:14:01,660 --> 00:14:08,949
outputs so this is a for each loop in

00:14:06,100 --> 00:14:11,680
Nice VC which is again like a small

00:14:08,949 --> 00:14:12,970
temperature from how C works but should

00:14:11,680 --> 00:14:15,250
be pretty easy to understand how it

00:14:12,970 --> 00:14:17,680
works basically just does a loop over

00:14:15,250 --> 00:14:20,290
the range 0 to n it's like a it's like a

00:14:17,680 --> 00:14:23,199
what is it half upper bound so it it

00:14:20,290 --> 00:14:24,100
goes to n minus 1 and then that's how

00:14:23,199 --> 00:14:26,199
we're gonna write our loop that goes

00:14:24,100 --> 00:14:28,389
over the same boots so the first thing

00:14:26,199 --> 00:14:31,059
it does is it loads the inputs for one

00:14:28,389 --> 00:14:32,350
step of the computation and again we've

00:14:31,059 --> 00:14:34,629
got a new keyword here so this new

00:14:32,350 --> 00:14:37,569
keyword here bearing is very interesting

00:14:34,629 --> 00:14:40,629
one what it means is that the value of

00:14:37,569 --> 00:14:42,279
this variable V is different depending

00:14:40,629 --> 00:14:43,389
on the program instance so I was saying

00:14:42,279 --> 00:14:45,339
earlier that you should think about SP

00:14:43,389 --> 00:14:47,110
decode as or a Sindhi code that's going

00:14:45,339 --> 00:14:48,730
to be code you should see it as a bunch

00:14:47,110 --> 00:14:51,069
of different instances of the same

00:14:48,730 --> 00:14:52,629
program or any parallel and what the

00:14:51,069 --> 00:14:54,579
varying keyword here means it means that

00:14:52,629 --> 00:14:56,800
in each of these instances this variable

00:14:54,579 --> 00:14:58,569
has a different value which is different

00:14:56,800 --> 00:15:00,069
from the uniform variables the uniform

00:14:58,569 --> 00:15:01,779
variables have the same value and every

00:15:00,069 --> 00:15:04,000
program instance because they're scalar

00:15:01,779 --> 00:15:07,540
so that's that's a distinction that's

00:15:04,000 --> 00:15:08,709
made between those two and so what's

00:15:07,540 --> 00:15:11,079
interesting here is like the index

00:15:08,709 --> 00:15:13,360
variable for example the index variable

00:15:11,079 --> 00:15:15,250
in the first iteration of this loop is

00:15:13,360 --> 00:15:17,230
actually the index itself is a varying

00:15:15,250 --> 00:15:19,720
variable so the index in the first loop

00:15:17,230 --> 00:15:21,970
if you're running on SSE to the index

00:15:19,720 --> 00:15:23,589
might correspond to 0 1 2 3 so it's

00:15:21,970 --> 00:15:25,290
actually responding to 4 values of the

00:15:23,589 --> 00:15:28,300
four first indices of the iteration and

00:15:25,290 --> 00:15:31,120
when you index the array V in with this

00:15:28,300 --> 00:15:32,920
varying value you're indexing with four

00:15:31,120 --> 00:15:34,300
indices so that means you actually know

00:15:32,920 --> 00:15:34,780
it for example with us as u2

00:15:34,300 --> 00:15:36,540
so

00:15:34,780 --> 00:15:38,980
that actually loads for values and

00:15:36,540 --> 00:15:40,570
that's why V has a varying values

00:15:38,980 --> 00:15:43,390
because you're loading for values with

00:15:40,570 --> 00:15:45,100
different indices from the same array so

00:15:43,390 --> 00:15:47,080
once you've loaded this this variable

00:15:45,100 --> 00:15:47,980
from memory you can do some computation

00:15:47,080 --> 00:15:49,300
with it so I'm just gonna show an

00:15:47,980 --> 00:15:52,870
if-else again

00:15:49,300 --> 00:15:53,920
so it begins with an if and the

00:15:52,870 --> 00:15:56,290
interesting thing is that this if

00:15:53,920 --> 00:15:57,430
comparison since B is varying the result

00:15:56,290 --> 00:15:58,720
of the comparison has a different value

00:15:57,430 --> 00:16:02,020
depending on the programming sense and

00:15:58,720 --> 00:16:03,700
so the code inside the if block should

00:16:02,020 --> 00:16:05,530
only appear as if it should only appear

00:16:03,700 --> 00:16:07,300
to have run inside the program instances

00:16:05,530 --> 00:16:08,590
where the tests passed and the way

00:16:07,300 --> 00:16:09,970
that's implemented is exactly I showed

00:16:08,590 --> 00:16:12,520
you earlier with the masking and the

00:16:09,970 --> 00:16:14,200
blending and all that stuff then we got

00:16:12,520 --> 00:16:15,670
the else block same thing as earlier

00:16:14,200 --> 00:16:17,740
again where it'll just like flip the

00:16:15,670 --> 00:16:19,660
mask and then run the else block and the

00:16:17,740 --> 00:16:21,460
assignment of like square root of V to V

00:16:19,660 --> 00:16:23,740
will only actually appear to have

00:16:21,460 --> 00:16:26,410
happened in the instances of the program

00:16:23,740 --> 00:16:28,980
where the test resulted in the else

00:16:26,410 --> 00:16:31,270
branch being run finally at the end

00:16:28,980 --> 00:16:34,780
we're at the outputs back to the V out

00:16:31,270 --> 00:16:36,910
array and so again index is a varying

00:16:34,780 --> 00:16:38,860
variable so this right the memory

00:16:36,910 --> 00:16:41,620
actually corresponds to the for writes

00:16:38,860 --> 00:16:44,410
the memory in parallel by writing to the

00:16:41,620 --> 00:16:46,080
indices 0 1 2 3 in the first iteration

00:16:44,410 --> 00:16:48,430
of the loop for example

00:16:46,080 --> 00:16:50,920
so there's actually an interesting thing

00:16:48,430 --> 00:16:52,750
here it was like the way I explained

00:16:50,920 --> 00:16:55,660
this is I explain this in terms of like

00:16:52,750 --> 00:16:57,670
kind of like how the SIMD works for it

00:16:55,660 --> 00:16:59,920
but one thing you can do is actually

00:16:57,670 --> 00:17:01,810
this variant keyword if you just like

00:16:59,920 --> 00:17:03,790
you know if you're just interesting the

00:17:01,810 --> 00:17:05,170
idea that just imagine it wasn't there

00:17:03,790 --> 00:17:08,319
just imagine it's not actually on the

00:17:05,170 --> 00:17:10,000
slide and if you imagine it's not there

00:17:08,319 --> 00:17:12,220
you'll notice that the code actually

00:17:10,000 --> 00:17:13,209
reads like a regular C program you don't

00:17:12,220 --> 00:17:15,100
actually have to think about the fact

00:17:13,209 --> 00:17:16,510
that it's Cindy it's just if you read

00:17:15,100 --> 00:17:18,310
this and you imagine it's just like some

00:17:16,510 --> 00:17:20,290
weird sea dialect you would see a for

00:17:18,310 --> 00:17:21,459
each loop and you would see an index and

00:17:20,290 --> 00:17:23,410
it would do an if else and then write to

00:17:21,459 --> 00:17:25,540
memory and there'd be like there'd be my

00:17:23,410 --> 00:17:27,880
thing is specially weird about this and

00:17:25,540 --> 00:17:29,650
actually a nice PC bearing is the

00:17:27,880 --> 00:17:31,060
default qualifier so if you leave it out

00:17:29,650 --> 00:17:33,520
it'll slick a pile and do the same thing

00:17:31,060 --> 00:17:34,690
and that's kind of like the idea of SPC

00:17:33,520 --> 00:17:36,310
is that you can write programs that

00:17:34,690 --> 00:17:38,500
appear as if they're just a regular old

00:17:36,310 --> 00:17:40,150
C program and reality that's running in

00:17:38,500 --> 00:17:41,230
is running back to rice code and so you

00:17:40,150 --> 00:17:42,070
can kinda like shift between these two

00:17:41,230 --> 00:17:43,570
perspectives when you're writing code

00:17:42,070 --> 00:17:45,520
like either you think about it was like

00:17:43,570 --> 00:17:47,260
okay it's just a C program and I'm just

00:17:45,520 --> 00:17:48,100
writing it like it's a C program or you

00:17:47,260 --> 00:17:49,210
can get like

00:17:48,100 --> 00:17:50,320
you can kinda like switch your mind to

00:17:49,210 --> 00:17:51,610
the other mode where you're thinking

00:17:50,320 --> 00:17:54,130
like okay it's actually a vector here

00:17:51,610 --> 00:17:55,240
and a scalar here and blah blah so you

00:17:54,130 --> 00:17:58,570
can't like switch back and forth these

00:17:55,240 --> 00:18:00,340
two modes of work when you finish

00:17:58,570 --> 00:18:02,919
writing this program making pilots with

00:18:00,340 --> 00:18:04,419
the SPC compiler so you know if it's

00:18:02,919 --> 00:18:06,250
called simple dice PC on your file

00:18:04,419 --> 00:18:07,660
system you just compile it and as a

00:18:06,250 --> 00:18:09,610
result you'll get two files you'll get a

00:18:07,660 --> 00:18:11,049
header like a C header or C loss header

00:18:09,610 --> 00:18:13,030
that you can include from your C++ code

00:18:11,049 --> 00:18:14,650
to build a call this function and then

00:18:13,030 --> 00:18:16,120
also give you an object file like an

00:18:14,650 --> 00:18:19,480
object file that you can just link to

00:18:16,120 --> 00:18:22,450
your program and I'll just work so I

00:18:19,480 --> 00:18:23,650
should pretty easy to integrate alright

00:18:22,450 --> 00:18:25,480
so moving on we're gonna look at a

00:18:23,650 --> 00:18:27,720
second case that you know now we're

00:18:25,480 --> 00:18:31,000
gonna look at shaders on the MV GCN and

00:18:27,720 --> 00:18:32,260
so GCN maybe if you're a gamer it might

00:18:31,000 --> 00:18:34,120
sound like GameCube but it's like

00:18:32,260 --> 00:18:36,520
GameCube it's graphics core next so

00:18:34,120 --> 00:18:37,870
graphics core next this NPC parent GPU

00:18:36,520 --> 00:18:40,809
architecture and we talked about it a

00:18:37,870 --> 00:18:42,970
little bit so it's not just the GPU

00:18:40,809 --> 00:18:44,320
architecture actually GCN it's it's also

00:18:42,970 --> 00:18:45,909
an instruction set architecture in the

00:18:44,320 --> 00:18:47,110
sense that they have specified that can

00:18:45,909 --> 00:18:50,740
actual assembly language so you can use

00:18:47,110 --> 00:18:52,210
the program for it this you know this is

00:18:50,740 --> 00:18:54,940
kind of like part of a big push for

00:18:52,210 --> 00:18:56,200
gpgpu so especially like if you're

00:18:54,940 --> 00:18:58,270
programming on game consoles right now

00:18:56,200 --> 00:19:00,850
you probably have done a lot of compute

00:18:58,270 --> 00:19:02,380
code tends to be that has to be the

00:19:00,850 --> 00:19:04,929
faster way to write code on consoles

00:19:02,380 --> 00:19:06,429
right now and namely that's like

00:19:04,929 --> 00:19:08,770
probably most important cases that are

00:19:06,429 --> 00:19:10,750
these in my my like daily life it's

00:19:08,770 --> 00:19:12,880
mostly important to know about em GCN

00:19:10,750 --> 00:19:16,419
because it is a GPU used in current

00:19:12,880 --> 00:19:18,039
generation game consoles so let's look

00:19:16,419 --> 00:19:20,289
at some basics because I'm gonna show

00:19:18,039 --> 00:19:21,970
you some assembly code and I want to

00:19:20,289 --> 00:19:22,630
first make sure that we know what the

00:19:21,970 --> 00:19:26,500
notation means

00:19:22,630 --> 00:19:27,850
so GCN has two sets of registers that

00:19:26,500 --> 00:19:29,830
has a set of back two registers and a

00:19:27,850 --> 00:19:31,360
set of scalar registers so the scaler

00:19:29,830 --> 00:19:33,280
registers I'm gonna talk about in a

00:19:31,360 --> 00:19:36,840
second but the vector registers are

00:19:33,280 --> 00:19:38,799
named r0 r1 r2 and r3 and r4 and etc and

00:19:36,840 --> 00:19:40,990
each of these vector registers

00:19:38,799 --> 00:19:43,539
corresponds to you could say a sim D

00:19:40,990 --> 00:19:47,020
register with 64 values it's actually

00:19:43,539 --> 00:19:48,010
very wide to 64 and you can actually

00:19:47,020 --> 00:19:50,169
operate on them in a pretty

00:19:48,010 --> 00:19:53,559
straightforward way so for example this

00:19:50,169 --> 00:19:55,780
instruction here V add F 32 just does 64

00:19:53,559 --> 00:19:57,549
additions in parallel so it'll take R 0

00:19:55,780 --> 00:19:59,320
and R 1 do these two are parallel

00:19:57,549 --> 00:20:01,450
additions and write the result to R 2

00:19:59,320 --> 00:20:01,929
and so you can you probably guess like

00:20:01,450 --> 00:20:03,309
the VR

00:20:01,929 --> 00:20:05,769
where the story means that's a vector

00:20:03,309 --> 00:20:07,779
operation and f32 means it's a 32-bit

00:20:05,769 --> 00:20:11,710
floor operation should be not too

00:20:07,779 --> 00:20:13,210
surprising so this is vector registers

00:20:11,710 --> 00:20:15,580
but there's also scalar registers and so

00:20:13,210 --> 00:20:19,269
the scalar registers are named s your s

00:20:15,580 --> 00:20:22,269
0 s 1 s 2 etc and you can use them for

00:20:19,269 --> 00:20:23,649
scalar operations so for example here in

00:20:22,269 --> 00:20:26,590
this case I'm doing an ant so just a

00:20:23,649 --> 00:20:28,269
bitwise and between s 0 and s 1 slowing

00:20:26,590 --> 00:20:30,490
results in s 2 and again you can

00:20:28,269 --> 00:20:32,710
probably guess the prefix s underscore

00:20:30,490 --> 00:20:36,909
is for scalar and be 32 to say that's a

00:20:32,710 --> 00:20:38,110
32-bit operation moving on there's a few

00:20:36,909 --> 00:20:40,720
special registers that you need to know

00:20:38,110 --> 00:20:43,330
about first one is VCC so the vector

00:20:40,720 --> 00:20:44,919
condition code this is me you do a

00:20:43,330 --> 00:20:47,559
comparison like for example here compare

00:20:44,919 --> 00:20:48,820
less then between R 0 and R 1 since

00:20:47,559 --> 00:20:50,740
those are vector registers the

00:20:48,820 --> 00:20:53,019
comparison has more than one result as

00:20:50,740 --> 00:20:54,850
64 results and they're encoded as a bit

00:20:53,019 --> 00:20:56,759
set like 64 bits where each bit

00:20:54,850 --> 00:20:59,379
corresponds to the past didn't fail and

00:20:56,759 --> 00:21:01,240
so when you do a comparison like that

00:20:59,379 --> 00:21:04,480
one the output is stored in the BCC

00:21:01,240 --> 00:21:06,700
register so that's how that works and by

00:21:04,480 --> 00:21:08,669
the way the VCC register you can maybe

00:21:06,700 --> 00:21:10,659
you notice a color coding the purple

00:21:08,669 --> 00:21:12,519
letters I'm using here are four vectors

00:21:10,659 --> 00:21:14,590
and the blue letters are first scalars

00:21:12,519 --> 00:21:19,269
so PCC is actually a scalar register of

00:21:14,590 --> 00:21:20,820
64 bits ok moving on there's the another

00:21:19,269 --> 00:21:24,009
special register the execution mask

00:21:20,820 --> 00:21:25,149
called exec and so the execution mask

00:21:24,009 --> 00:21:26,590
was actually very similar to the mask

00:21:25,149 --> 00:21:28,119
that I showed you earlier in this talk

00:21:26,590 --> 00:21:30,970
when I was demonstrating how to convert

00:21:28,119 --> 00:21:33,549
C code to assign B code and basically

00:21:30,970 --> 00:21:35,740
what it does is just the value of the

00:21:33,549 --> 00:21:38,019
exact mask is used to mask out any

00:21:35,740 --> 00:21:41,679
operations that the GP does so whenever

00:21:38,019 --> 00:21:44,259
you do an operation with vectors it will

00:21:41,679 --> 00:21:47,529
only affect the execution lanes that are

00:21:44,259 --> 00:21:48,639
set in the exec register and you can

00:21:47,529 --> 00:21:50,799
actually just arbitrarily read and write

00:21:48,639 --> 00:21:52,779
to this so for example here I'm doing an

00:21:50,799 --> 00:21:55,119
end of a BCC and exec and storing that

00:21:52,779 --> 00:21:56,919
in exec and that's a very common pattern

00:21:55,119 --> 00:21:57,490
you'll see because it's used to like

00:21:56,919 --> 00:21:59,529
mask

00:21:57,490 --> 00:22:00,730
execution for like an if block for

00:21:59,529 --> 00:22:03,610
example if you died like a person and

00:22:00,730 --> 00:22:04,360
use that comparison as a for an if so

00:22:03,610 --> 00:22:06,369
moving on

00:22:04,360 --> 00:22:08,769
let's look at how this is actually used

00:22:06,369 --> 00:22:10,929
to compile code so on the left here you

00:22:08,769 --> 00:22:12,340
can see a very simple OpenGL shader

00:22:10,929 --> 00:22:13,659
program or COAG it could be a direct

00:22:12,340 --> 00:22:14,930
actuator program honestly it's it's

00:22:13,659 --> 00:22:17,150
simple enough that it could be a bisque

00:22:14,930 --> 00:22:18,740
any language at this point but for the

00:22:17,150 --> 00:22:21,380
sake of for the sake of discussion as as

00:22:18,740 --> 00:22:23,660
soon as the shader if we want to

00:22:21,380 --> 00:22:25,930
translate the shader into gcn assembly

00:22:23,660 --> 00:22:27,770
you would do it like this so let's begin

00:22:25,930 --> 00:22:29,810
hopefully you're not too small hopefully

00:22:27,770 --> 00:22:31,640
you can I'll read it we would begin by

00:22:29,810 --> 00:22:33,620
doing a comparison so this says compare

00:22:31,640 --> 00:22:35,360
greater then between the two inputs so

00:22:33,620 --> 00:22:36,380
it matches the first line of code and in

00:22:35,360 --> 00:22:40,550
the function that just does a greater

00:22:36,380 --> 00:22:41,780
than comparison then the trick is so

00:22:40,550 --> 00:22:44,600
this is like an added dimension too I

00:22:41,780 --> 00:22:46,190
showed you earlier in this shading

00:22:44,600 --> 00:22:49,340
language is possible that the calling

00:22:46,190 --> 00:22:50,570
function exact mask was not all on like

00:22:49,340 --> 00:22:52,340
in the example I showed you earlier the

00:22:50,570 --> 00:22:54,440
execution mask was all on at the start

00:22:52,340 --> 00:22:56,600
which was like a nice assumption but in

00:22:54,440 --> 00:22:58,460
this case you can't assume that the

00:22:56,600 --> 00:23:00,620
exact register is is all on when it's

00:22:58,460 --> 00:23:01,790
function starts so what that means is

00:23:00,620 --> 00:23:02,930
like if we're gonna be messing around

00:23:01,790 --> 00:23:04,190
with the exact register you have to make

00:23:02,930 --> 00:23:07,280
sure that it goes back to what it needs

00:23:04,190 --> 00:23:09,800
to be at the node function and so this

00:23:07,280 --> 00:23:11,300
one should begins by storing into a

00:23:09,800 --> 00:23:12,680
temporary variable the value of the

00:23:11,300 --> 00:23:15,080
execution mask and that way it's gonna

00:23:12,680 --> 00:23:17,870
be able to restore it at the end all

00:23:15,080 --> 00:23:21,110
right then similar to how I showed you

00:23:17,870 --> 00:23:22,970
in last slide just do an end of the

00:23:21,110 --> 00:23:24,440
execution mask at the BCC and that I'll

00:23:22,970 --> 00:23:26,300
make it so that only the lanes that

00:23:24,440 --> 00:23:29,300
passed the greater-than comparison are

00:23:26,300 --> 00:23:32,960
gonna be active from for the ones that

00:23:29,300 --> 00:23:34,130
started off alright then the so this

00:23:32,960 --> 00:23:36,170
kinda like a few things happening here

00:23:34,130 --> 00:23:37,370
if you direct your attention to the

00:23:36,170 --> 00:23:38,450
purple line of code here you can see

00:23:37,370 --> 00:23:41,150
that's the multiplication that's

00:23:38,450 --> 00:23:42,920
happening inside the F block and then

00:23:41,150 --> 00:23:45,620
around it I've got like a bit of like

00:23:42,920 --> 00:23:46,940
control for logic so here you can see

00:23:45,620 --> 00:23:48,440
the label for the else block which

00:23:46,940 --> 00:23:50,330
corresponds to of course the else part

00:23:48,440 --> 00:23:52,790
of the program here and above it I've

00:23:50,330 --> 00:23:55,940
got this branch so what I'm doing here

00:23:52,790 --> 00:23:58,160
is actually it's doing a branch if the

00:23:55,940 --> 00:24:00,710
VCC is zero and so what that means is

00:23:58,160 --> 00:24:03,020
like if the comparisons all failed

00:24:00,710 --> 00:24:04,220
that means that nobody is going to be

00:24:03,020 --> 00:24:07,550
running the if block in the sense of

00:24:04,220 --> 00:24:10,250
like if if nobody if you if you input it

00:24:07,550 --> 00:24:12,680
like a set of a set of values for a and

00:24:10,250 --> 00:24:15,410
B and the pairs and resulted in no

00:24:12,680 --> 00:24:16,790
passes like everything failed that means

00:24:15,410 --> 00:24:18,680
that you don't even need to run the if

00:24:16,790 --> 00:24:20,090
block you can just not run it and that's

00:24:18,680 --> 00:24:21,530
what happening here so if everybody

00:24:20,090 --> 00:24:23,000
filled the test it oh just branch

00:24:21,530 --> 00:24:24,470
directly to the else block and not run

00:24:23,000 --> 00:24:26,900
the F block it's kind of a little

00:24:24,470 --> 00:24:28,790
optimization there you'll see pretty

00:24:26,900 --> 00:24:30,680
commonly so

00:24:28,790 --> 00:24:32,150
moving on we got to the else plot the

00:24:30,680 --> 00:24:34,340
first thing we do is we flip the mask

00:24:32,150 --> 00:24:35,630
like I was talking about earlier but

00:24:34,340 --> 00:24:37,730
there's like an added detail here again

00:24:35,630 --> 00:24:39,200
which is that we have to take into

00:24:37,730 --> 00:24:40,640
consideration that the mass was not all

00:24:39,200 --> 00:24:42,710
on at the start so this is just making

00:24:40,640 --> 00:24:44,660
sure that you take into account the fact

00:24:42,710 --> 00:24:47,090
that the initial mass was not all on and

00:24:44,660 --> 00:24:49,790
and and that to make sure that you

00:24:47,090 --> 00:24:51,500
respect the original constraints all

00:24:49,790 --> 00:24:53,570
right and then very similarly to before

00:24:51,500 --> 00:24:55,430
we do a little branch trick to make it

00:24:53,570 --> 00:24:57,140
so that if none of the execution lanes

00:24:55,430 --> 00:24:59,060
are on and we just branch and skip the

00:24:57,140 --> 00:24:59,540
else block entirely but if that didn't

00:24:59,060 --> 00:25:01,820
happen

00:24:59,540 --> 00:25:04,880
then we do a sub and that'll do the

00:25:01,820 --> 00:25:07,130
subtraction between the two inputs and I

00:25:04,880 --> 00:25:08,690
should mention just be clear that this

00:25:07,130 --> 00:25:10,940
multiplication the subtraction that

00:25:08,690 --> 00:25:12,830
happened in this code they only affect

00:25:10,940 --> 00:25:14,540
the lanes that were set in the exact

00:25:12,830 --> 00:25:16,040
mask okay so this is kind like a little

00:25:14,540 --> 00:25:17,630
bit difference because in the earlier

00:25:16,040 --> 00:25:20,030
example I have to explicitly do it like

00:25:17,630 --> 00:25:22,370
a blend instruction but in this case

00:25:20,030 --> 00:25:24,790
it's actually just done implicitly so

00:25:22,370 --> 00:25:26,420
it's just everything's masked always and

00:25:24,790 --> 00:25:27,890
alright so that's the end of the

00:25:26,420 --> 00:25:29,180
function so just bring back the

00:25:27,890 --> 00:25:30,830
execution master whatever's at the start

00:25:29,180 --> 00:25:33,920
and we've all cleaned up our slate and

00:25:30,830 --> 00:25:37,490
it all works so that's all I want to say

00:25:33,920 --> 00:25:39,020
for GC and assembly all right in summary

00:25:37,490 --> 00:25:41,420
where did we learn from these case

00:25:39,020 --> 00:25:43,340
studies so first of all we've seen that

00:25:41,420 --> 00:25:46,790
we can use SPMTs map sealing we justice

00:25:43,340 --> 00:25:48,710
IMD the cool that we can write is high

00:25:46,790 --> 00:25:50,930
level so we can use it to write like

00:25:48,710 --> 00:25:52,940
loops and traditionals and ways that let

00:25:50,930 --> 00:25:54,980
us write like better algorithms more

00:25:52,940 --> 00:25:58,550
easily rather than focusing on little

00:25:54,980 --> 00:26:00,170
assembly finicky details and the nice

00:25:58,550 --> 00:26:02,780
thing is like once you understand how

00:26:00,170 --> 00:26:05,960
the C code Maps through intrinsics or

00:26:02,780 --> 00:26:07,130
assembly you can still kind of like look

00:26:05,960 --> 00:26:08,660
at the code and understand what the

00:26:07,130 --> 00:26:11,030
performance is going to be like because

00:26:08,660 --> 00:26:12,530
you know how the implementation details

00:26:11,030 --> 00:26:13,790
work basically in the sense that you

00:26:12,530 --> 00:26:14,870
know those give me something ask in here

00:26:13,790 --> 00:26:17,840
and this can be some jumps here it's

00:26:14,870 --> 00:26:20,420
like no make sure that whatever just to

00:26:17,840 --> 00:26:21,860
say like it's possible to understand

00:26:20,420 --> 00:26:23,540
what's actually happening behind the

00:26:21,860 --> 00:26:24,860
hood and that's like an important

00:26:23,540 --> 00:26:27,320
characteristic of c-like languages

00:26:24,860 --> 00:26:29,890
because of course we wouldn't be writing

00:26:27,320 --> 00:26:32,060
see everything have a performance so

00:26:29,890 --> 00:26:34,790
another cool thing is that I showed you

00:26:32,060 --> 00:26:36,020
that it runs both on CPU and GPU so it

00:26:34,790 --> 00:26:39,950
shows that this part I'm actually has

00:26:36,020 --> 00:26:41,600
quite a bit of versatility and I've

00:26:39,950 --> 00:26:42,770
shown you also that these languages

00:26:41,600 --> 00:26:43,640
exist today

00:26:42,770 --> 00:26:45,590
like today you can write

00:26:43,640 --> 00:26:49,010
high-performance CPU or GPU code using

00:26:45,590 --> 00:26:53,120
SPMD like languages but you can't really

00:26:49,010 --> 00:26:54,590
do this in C++ so how can we do this new

00:26:53,120 --> 00:26:56,330
code in C++ which is the description of

00:26:54,590 --> 00:26:58,730
my answer for the rest of this talk

00:26:56,330 --> 00:27:00,230
basically and so the way that I've

00:26:58,730 --> 00:27:04,430
suggested to implement this in C++ so

00:27:00,230 --> 00:27:08,630
far is what I call VPS BMD which is way

00:27:04,430 --> 00:27:10,160
to write SPMD code in C++ so what is

00:27:08,630 --> 00:27:12,590
SpMT RCPS pindy

00:27:10,160 --> 00:27:15,410
CBP SPMD is a little header only library

00:27:12,590 --> 00:27:17,180
I've made it's a subset of is BC in

00:27:15,410 --> 00:27:19,730
plain C++ so basically I just look at

00:27:17,180 --> 00:27:20,660
like the ICC spec and I just go like oh

00:27:19,730 --> 00:27:22,880
I like this function I like this

00:27:20,660 --> 00:27:25,220
function I just like put them in so it's

00:27:22,880 --> 00:27:29,120
basically khatola ripoff but it it works

00:27:25,220 --> 00:27:30,590
so it's implemented with intrinsic s--

00:27:29,120 --> 00:27:32,540
like the actual header itself contains

00:27:30,590 --> 00:27:34,280
intrinsic stuff but when you write the

00:27:32,540 --> 00:27:35,600
code you don't have to care about what

00:27:34,280 --> 00:27:37,730
specific instructions that you're

00:27:35,600 --> 00:27:40,250
running for really and that's that's the

00:27:37,730 --> 00:27:41,990
same thing with ice BC for example and

00:27:40,250 --> 00:27:43,370
if you want to get like the executive

00:27:41,990 --> 00:27:45,650
summary of how it's actually implemented

00:27:43,370 --> 00:27:47,480
is basically just control flow is

00:27:45,650 --> 00:27:50,000
represented by lambdas and these lambdas

00:27:47,480 --> 00:27:52,580
are executed with masks that's like the

00:27:50,000 --> 00:27:54,560
one sentence summary of how this library

00:27:52,580 --> 00:27:56,570
works and I'll go in more detail in the

00:27:54,560 --> 00:27:57,680
next slides and I should mention this

00:27:56,570 --> 00:28:00,800
library is just like a proof of concept

00:27:57,680 --> 00:28:03,530
so I've only implemented what I needed

00:28:00,800 --> 00:28:05,150
for my tests and I summary for

00:28:03,530 --> 00:28:06,410
production although I've had a lot of

00:28:05,150 --> 00:28:08,480
people are interested in it so maybe we

00:28:06,410 --> 00:28:09,530
can actually like take a bit more

00:28:08,480 --> 00:28:13,400
seriously and turn to something that's

00:28:09,530 --> 00:28:15,110
actually useful all right so just going

00:28:13,400 --> 00:28:17,140
to show you quickly how to translate ice

00:28:15,110 --> 00:28:19,160
beauty types test EVPs media types so

00:28:17,140 --> 00:28:20,480
earlier we were talking about uniform

00:28:19,160 --> 00:28:22,190
ants and you have front float and I told

00:28:20,480 --> 00:28:23,300
you that when you see a uniform inter

00:28:22,190 --> 00:28:24,860
uniform flow it's basically the same

00:28:23,300 --> 00:28:27,290
thing as if it was just one INT or one

00:28:24,860 --> 00:28:29,030
float just like a regular c scaler and

00:28:27,290 --> 00:28:29,930
so that's how I should be convenient

00:28:29,030 --> 00:28:31,940
because if you want to present these

00:28:29,930 --> 00:28:33,920
types in C++ it's actually just a

00:28:31,940 --> 00:28:36,110
regular interflow there's nothing quite

00:28:33,920 --> 00:28:37,670
special about that but what about

00:28:36,110 --> 00:28:39,890
varying it the varying float these are

00:28:37,670 --> 00:28:42,530
kind of like new and exotic in sickle

00:28:39,890 --> 00:28:43,760
cell and so the way that I've translate

00:28:42,530 --> 00:28:45,680
that is I create my own types

00:28:43,760 --> 00:28:48,500
vient and B float which represent a

00:28:45,680 --> 00:28:52,100
variants or varying float so these are

00:28:48,500 --> 00:28:53,270
types that are given by CBP SPMD moving

00:28:52,100 --> 00:28:55,460
on I'll show you a quick example of how

00:28:53,270 --> 00:28:56,630
to do control flow so you can get a

00:28:55,460 --> 00:29:00,620
probably a feel for what

00:28:56,630 --> 00:29:02,750
is gonna look like uh for a sweetie a

00:29:00,620 --> 00:29:04,640
CPS moon decode you can see I've added

00:29:02,750 --> 00:29:08,120
like my own versions for control flow so

00:29:04,640 --> 00:29:10,670
here instead of if I say SP MDF and for

00:29:08,120 --> 00:29:13,850
example here when I do be less than

00:29:10,670 --> 00:29:15,680
three the value of V is a varying float

00:29:13,850 --> 00:29:17,690
so the comparison less than three

00:29:15,680 --> 00:29:21,260
actually is a like it returns like a

00:29:17,690 --> 00:29:24,290
varying bool and based on the results of

00:29:21,260 --> 00:29:25,790
this varying bool the function or the

00:29:24,290 --> 00:29:27,680
code that's that's inside this lambda

00:29:25,790 --> 00:29:30,670
here is gonna be run with a mask that's

00:29:27,680 --> 00:29:34,580
that fix that if test into consideration

00:29:30,670 --> 00:29:38,120
so to give you an idea of how this

00:29:34,580 --> 00:29:41,600
actually works just gonna kind of like

00:29:38,120 --> 00:29:43,160
quickly go over not it's like a

00:29:41,600 --> 00:29:44,390
simplified version of the SVM D if

00:29:43,160 --> 00:29:45,650
implementation it's like a bit more

00:29:44,390 --> 00:29:47,540
complicated if you actually look at it

00:29:45,650 --> 00:29:49,450
but I think I'll give you like a big

00:29:47,540 --> 00:29:51,920
idea of how this is supposed to work

00:29:49,450 --> 00:29:53,540
it's basically very similar to what

00:29:51,920 --> 00:29:56,930
we've seen before but now written in C

00:29:53,540 --> 00:29:59,810
so same as always save the old execution

00:29:56,930 --> 00:30:02,750
mask into a temporary variable then I'll

00:29:59,810 --> 00:30:04,550
do an and to apply the if test so that

00:30:02,750 --> 00:30:07,660
now the institution mask only has its

00:30:04,550 --> 00:30:09,920
lane active where the if test passed

00:30:07,660 --> 00:30:11,870
then I'll just run the all off

00:30:09,920 --> 00:30:13,520
optimization so if the execution mask is

00:30:11,870 --> 00:30:16,240
all off just don't run the if block at

00:30:13,520 --> 00:30:18,380
all it's just a cute little optimism and

00:30:16,240 --> 00:30:21,230
otherwise it's just run the if body so

00:30:18,380 --> 00:30:22,310
just passing a lambda there and finally

00:30:21,230 --> 00:30:24,200
at the end of the day just restore the

00:30:22,310 --> 00:30:25,520
execution mask so it's basically like

00:30:24,200 --> 00:30:26,990
that's like again that's a simplified

00:30:25,520 --> 00:30:29,150
version it's a little bit more

00:30:26,990 --> 00:30:31,130
complicated in practice but that's

00:30:29,150 --> 00:30:33,380
basically the principle and that's it's

00:30:31,130 --> 00:30:34,640
pretty much at the end of day that's

00:30:33,380 --> 00:30:39,320
it's as pretty much as suppose it gets

00:30:34,640 --> 00:30:41,090
so alright so now to have meant the

00:30:39,320 --> 00:30:42,770
varying variables like V here which is

00:30:41,090 --> 00:30:44,990
like a V float I'm going to quickly show

00:30:42,770 --> 00:30:47,120
you the again simplified version of how

00:30:44,990 --> 00:30:49,240
this is implemented so the V float in VN

00:30:47,120 --> 00:30:53,240
classes are basically just wrappers for

00:30:49,240 --> 00:30:55,070
Emma 28 types or m62 56 types whatever

00:30:53,240 --> 00:30:59,000
is the intrinsic implementation detail

00:30:55,070 --> 00:31:00,500
data type the mathematical operations

00:30:59,000 --> 00:31:03,080
like the x operation or just implemented

00:31:00,500 --> 00:31:04,580
with operator overloads and so here if

00:31:03,080 --> 00:31:05,720
you do operate at times on 2d floats it

00:31:04,580 --> 00:31:07,400
just doesn't multi s like a

00:31:05,720 --> 00:31:09,260
multiplication of two passing precision

00:31:07,400 --> 00:31:10,220
floats and one thing you might notice is

00:31:09,260 --> 00:31:11,930
that

00:31:10,220 --> 00:31:14,000
in this multiplication here I'm not

00:31:11,930 --> 00:31:16,070
taking the mask into consideration which

00:31:14,000 --> 00:31:18,500
is a little bit weird but actually it

00:31:16,070 --> 00:31:19,940
works because the trick is that it does

00:31:18,500 --> 00:31:22,820
really matter if you multiply things

00:31:19,940 --> 00:31:24,170
together that are masked out it's like

00:31:22,820 --> 00:31:26,000
yeah it'll do some multiplications that

00:31:24,170 --> 00:31:27,890
are gonna be thrown away so it's not the

00:31:26,000 --> 00:31:29,270
best thing but it doesn't actually

00:31:27,890 --> 00:31:33,800
matter that you have these these like

00:31:29,270 --> 00:31:35,210
unnecessary values because if the the

00:31:33,800 --> 00:31:36,290
fact that they're they're necessary is

00:31:35,210 --> 00:31:38,620
gonna be reflected only when you

00:31:36,290 --> 00:31:41,270
actually do it like a load or store so

00:31:38,620 --> 00:31:43,850
actually like it's kind of I'm it or is

00:31:41,270 --> 00:31:45,530
it the the store and the load are things

00:31:43,850 --> 00:31:48,140
that take the execution mask to account

00:31:45,530 --> 00:31:50,210
so this is actually partly why if you

00:31:48,140 --> 00:31:51,680
have some foresight you'll see that this

00:31:50,210 --> 00:31:53,990
is actually why I have to put store into

00:31:51,680 --> 00:31:58,100
a function so I can access the execution

00:31:53,990 --> 00:31:59,240
mask from from this function and so when

00:31:58,100 --> 00:32:00,380
you do a store it'll take a bet

00:31:59,240 --> 00:32:03,410
execution mask into account and only

00:32:00,380 --> 00:32:04,820
blend values then so that's basically

00:32:03,410 --> 00:32:08,930
how the masking is actually implemented

00:32:04,820 --> 00:32:11,780
and yeah so let's look at a sample

00:32:08,930 --> 00:32:13,430
program of how this works so this is

00:32:11,780 --> 00:32:15,980
going to be some ugliness but I promise

00:32:13,430 --> 00:32:18,800
it's all for a good reason at least so

00:32:15,980 --> 00:32:20,540
far so when you want to write a spam D

00:32:18,800 --> 00:32:22,940
program or an SVG function with this

00:32:20,540 --> 00:32:24,860
framework you have to write you have to

00:32:22,940 --> 00:32:27,050
actually wrap into a struct so instead

00:32:24,860 --> 00:32:28,370
of a function it's a struct so this is

00:32:27,050 --> 00:32:30,740
like declaring a function called simple

00:32:28,370 --> 00:32:32,120
but instead you make it a struct and you

00:32:30,740 --> 00:32:36,170
have to inherit from STD kernel

00:32:32,120 --> 00:32:37,730
now the body of the function I can have

00:32:36,170 --> 00:32:39,620
it can have any return type you want and

00:32:37,730 --> 00:32:41,660
can take any arguments you want but the

00:32:39,620 --> 00:32:43,490
convention is just that it has to be

00:32:41,660 --> 00:32:44,630
called underscore call and again I

00:32:43,490 --> 00:32:48,860
promise this is a good reason for this

00:32:44,630 --> 00:32:50,150
well a good reason for now so this is

00:32:48,860 --> 00:32:51,560
gonna be very similar to this simple

00:32:50,150 --> 00:32:53,870
program that I showed earlier with ice

00:32:51,560 --> 00:32:55,340
BC so we're gonna do a for each loop and

00:32:53,870 --> 00:32:58,010
you can see I've implemented my own ice

00:32:55,340 --> 00:32:59,810
cream V for each pass in the upper bound

00:32:58,010 --> 00:33:01,690
and lower bound and I'll just loop

00:32:59,810 --> 00:33:04,400
through that and at every iteration

00:33:01,690 --> 00:33:05,750
it'll call the lambda that corresponds

00:33:04,400 --> 00:33:08,510
to one iteration of this for each loop

00:33:05,750 --> 00:33:11,000
and so you can see we've got the index

00:33:08,510 --> 00:33:12,440
variable it's back but now it's actually

00:33:11,000 --> 00:33:13,250
there's a new type that I haven't

00:33:12,440 --> 00:33:16,460
introduced you yet

00:33:13,250 --> 00:33:18,830
here it's ELINT so ELINT is a linear int

00:33:16,460 --> 00:33:21,530
and what a linear int means is it's

00:33:18,830 --> 00:33:22,850
actually a special case of bearing so

00:33:21,530 --> 00:33:23,470
when you have a varying variable in the

00:33:22,850 --> 00:33:24,940
gem most general

00:33:23,470 --> 00:33:26,620
a varying variable has a completely

00:33:24,940 --> 00:33:30,070
different value in every execution lane

00:33:26,620 --> 00:33:32,169
but we have a linear value it means that

00:33:30,070 --> 00:33:33,970
the value is increasing by one without B

00:33:32,169 --> 00:33:35,650
lane which is actually very important

00:33:33,970 --> 00:33:37,240
because it means that instead of doing a

00:33:35,650 --> 00:33:39,010
gather operation you can do a load

00:33:37,240 --> 00:33:40,570
instruction which is maybe like maybe

00:33:39,010 --> 00:33:42,490
this is gibberish to you but there's

00:33:40,570 --> 00:33:44,530
just say that if you if you load from

00:33:42,490 --> 00:33:46,000
memory with contiguous indices it can be

00:33:44,530 --> 00:33:47,980
a very simple load that just like reads

00:33:46,000 --> 00:33:49,659
out those values if you do a load from

00:33:47,980 --> 00:33:51,669
memory with different indices like

00:33:49,659 --> 00:33:53,169
completely random indices there's still

00:33:51,669 --> 00:33:54,940
instructions to do that but it's much

00:33:53,169 --> 00:33:58,179
slower than doing a regular old plain

00:33:54,940 --> 00:33:59,400
load although the gap is closing it's

00:33:58,179 --> 00:34:04,179
getting better and with re-architecture

00:33:59,400 --> 00:34:07,900
so very limited before load the inputs

00:34:04,179 --> 00:34:09,609
into a B float this time and then here's

00:34:07,900 --> 00:34:11,290
the if-else so a bit gnarly because of

00:34:09,609 --> 00:34:13,780
the lambda notation but hopefully you

00:34:11,290 --> 00:34:15,220
know two unreadable or you can see about

00:34:13,780 --> 00:34:17,109
the f-test at the start would be less

00:34:15,220 --> 00:34:18,820
than three and then I pass in the if

00:34:17,109 --> 00:34:21,250
block and the else block has lambdas and

00:34:18,820 --> 00:34:23,349
so the idea is that this being the

00:34:21,250 --> 00:34:25,179
if-else statement is going to do the

00:34:23,349 --> 00:34:26,710
comparison and then is gonna run the if

00:34:25,179 --> 00:34:28,419
block and the else block with the

00:34:26,710 --> 00:34:33,760
appropriate mask set in between the

00:34:28,419 --> 00:34:35,800
calls okay and finally you store the

00:34:33,760 --> 00:34:37,359
results back to memory so you can see

00:34:35,800 --> 00:34:39,070
there's a explicit load and store

00:34:37,359 --> 00:34:41,020
function names which is something I'll

00:34:39,070 --> 00:34:44,679
talk about later but other than that

00:34:41,020 --> 00:34:46,450
hopefully not too unreasonable if you

00:34:44,679 --> 00:34:48,520
actually want to call this this this

00:34:46,450 --> 00:34:49,659
function its program you can do like

00:34:48,520 --> 00:34:50,919
this so let's just suppose you've got

00:34:49,659 --> 00:34:53,320
some input array and some output array

00:34:50,919 --> 00:34:54,790
that you've set up here's what kind of

00:34:53,320 --> 00:34:57,010
like what the mean would look like so

00:34:54,790 --> 00:34:59,589
you use this SPMD call function and

00:34:57,010 --> 00:35:01,420
instead of passing in like okay so you

00:34:59,589 --> 00:35:02,830
passionately the the function name you

00:35:01,420 --> 00:35:04,720
want to call or I guess the kernel need

00:35:02,830 --> 00:35:05,650
gonna call has empty arguments and then

00:35:04,720 --> 00:35:06,640
you just pass in the argument of the

00:35:05,650 --> 00:35:08,950
function as if it was just regular

00:35:06,640 --> 00:35:11,109
function call and that's gonna invoke

00:35:08,950 --> 00:35:13,089
the kernel and in this case since you're

00:35:11,109 --> 00:35:15,849
calling this this kernel from outside of

00:35:13,089 --> 00:35:18,550
the kernel it's gonna start off unmasked

00:35:15,849 --> 00:35:23,230
like this damascena be fully or fully on

00:35:18,550 --> 00:35:25,390
I guess so this is like no maybe I first

00:35:23,230 --> 00:35:26,800
it's kind of like is it really gonna

00:35:25,390 --> 00:35:28,300
work because you know we've got lambdas

00:35:26,800 --> 00:35:30,490
everywhere we've got this like V float

00:35:28,300 --> 00:35:33,040
type we've got like these magical stores

00:35:30,490 --> 00:35:34,750
and floats and stuff so like is this

00:35:33,040 --> 00:35:36,040
gonna hurt performance it's a big

00:35:34,750 --> 00:35:36,430
question because all this is an

00:35:36,040 --> 00:35:39,099
optimized

00:35:36,430 --> 00:35:41,079
if you think about it so I did some

00:35:39,099 --> 00:35:43,270
performance tests so what I did

00:35:41,079 --> 00:35:46,630
basically is I took the sample programs

00:35:43,270 --> 00:35:49,480
from the ISP see examples folder and I

00:35:46,630 --> 00:35:51,640
the examples folder and is bc contains

00:35:49,480 --> 00:35:53,740
an implementation in c++ and it contains

00:35:51,640 --> 00:35:55,750
an implementation is PC and so I took

00:35:53,740 --> 00:35:57,549
those programs and i ported them and I

00:35:55,750 --> 00:35:59,619
created a CBP SPMD version of those

00:35:57,549 --> 00:36:03,220
programs and I used that to compare the

00:35:59,619 --> 00:36:05,529
performance so starting off with the

00:36:03,220 --> 00:36:09,789
plain C++ code I brand this noise

00:36:05,529 --> 00:36:11,619
function code 100 times I think and that

00:36:09,789 --> 00:36:12,940
took 45 4 5 seconds which is actually

00:36:11,619 --> 00:36:15,819
pretty long time

00:36:12,940 --> 00:36:17,680
porting it directly to CPS BMD lowered

00:36:15,819 --> 00:36:19,089
the runtime down to 10 seconds we just

00:36:17,680 --> 00:36:21,490
like a 410 speed-up right off the bat

00:36:19,089 --> 00:36:24,000
which is actually pretty good but then I

00:36:21,490 --> 00:36:26,470
ran the ice PC version of a program and

00:36:24,000 --> 00:36:29,799
it did a lot better so it's like almost

00:36:26,470 --> 00:36:31,720
around twice as fast so it's kind of a

00:36:29,799 --> 00:36:33,579
disappointment but you know I thought

00:36:31,720 --> 00:36:35,980
hey this is C++ we should be able to

00:36:33,579 --> 00:36:38,980
make things fast how could I specie beat

00:36:35,980 --> 00:36:41,109
us so I just mystification found out

00:36:38,980 --> 00:36:43,180
that actually it seems like civil slows

00:36:41,109 --> 00:36:44,529
compilers just like aren't optimizing

00:36:43,180 --> 00:36:46,539
aggressively enough at some stuff

00:36:44,529 --> 00:36:47,770
especially gathers like SBC is way

00:36:46,539 --> 00:36:49,299
better at finding like we're done and

00:36:47,770 --> 00:36:51,760
gathers and pulling them out of loop it

00:36:49,299 --> 00:36:53,230
just say like the optimization it's like

00:36:51,760 --> 00:36:54,220
much more aware of like what's fast and

00:36:53,230 --> 00:36:58,180
what slow in terms of architecture it

00:36:54,220 --> 00:36:59,740
seems so I found what optimizations I

00:36:58,180 --> 00:37:01,539
specie was doing and basically just

00:36:59,740 --> 00:37:03,069
redid by hand and I went around did a

00:37:01,539 --> 00:37:04,869
few other things just like tweaks and

00:37:03,069 --> 00:37:07,059
stuff and then ended up getting hey so a

00:37:04,869 --> 00:37:08,950
little bit faster nice PC with a bit of

00:37:07,059 --> 00:37:10,809
work and I found actually like running

00:37:08,950 --> 00:37:14,020
it with profile guide optimization made

00:37:10,809 --> 00:37:15,670
it even faster so you know getting up to

00:37:14,020 --> 00:37:17,890
9x performance that actually feels

00:37:15,670 --> 00:37:19,720
pretty good because this is running on a

00:37:17,890 --> 00:37:21,099
BX 2 in the X 2 instruction set and the

00:37:19,720 --> 00:37:23,859
FX 2 instruction said let's who run

00:37:21,099 --> 00:37:25,180
vectors of width 8 so it's kind of like

00:37:23,859 --> 00:37:27,750
super linear speed-up which is kind of

00:37:25,180 --> 00:37:30,400
like what but hey works I guess

00:37:27,750 --> 00:37:31,990
and also on Monday Barney's true ship

00:37:30,400 --> 00:37:34,299
said that he wanted like 10 times

00:37:31,990 --> 00:37:35,440
improvements to C++ and I was looking at

00:37:34,299 --> 00:37:37,329
the sly of City and I was like oh no

00:37:35,440 --> 00:37:38,859
it's like it's like 9 X it's like not

00:37:37,329 --> 00:37:40,510
high enough but then I know it's like

00:37:38,859 --> 00:37:42,730
actually I ran this program on my laptop

00:37:40,510 --> 00:37:44,380
here which is a newer architecture than

00:37:42,730 --> 00:37:45,940
the one at the top of the slide there

00:37:44,380 --> 00:37:47,319
and actually with the improvements in

00:37:45,940 --> 00:37:48,760
the architecture hey it's actually

00:37:47,319 --> 00:37:49,750
relative to the first one let's up to

00:37:48,760 --> 00:37:51,340
the older architecture

00:37:49,750 --> 00:37:53,440
playing super close code it's actually

00:37:51,340 --> 00:37:56,080
11 times faster so I think this is proof

00:37:53,440 --> 00:37:57,640
that if you want like a even more than

00:37:56,080 --> 00:37:59,620
10 times improvement in civil source

00:37:57,640 --> 00:38:01,840
code we can't actually accomplish that

00:37:59,620 --> 00:38:04,960
with a combination of using Cindy and

00:38:01,840 --> 00:38:08,980
you know embracing your architectures so

00:38:04,960 --> 00:38:10,240
hey this it's promising I've got some

00:38:08,980 --> 00:38:12,340
other examples so for example here's the

00:38:10,240 --> 00:38:13,780
man robot set again like you can't write

00:38:12,340 --> 00:38:14,950
out to talk about colors and with Cindy

00:38:13,780 --> 00:38:18,340
without having a none of us said

00:38:14,950 --> 00:38:20,020
apparently so at first but just like

00:38:18,340 --> 00:38:22,270
regular C++ code doing a thousand runs

00:38:20,020 --> 00:38:24,640
took almost 100 seconds it's actually

00:38:22,270 --> 00:38:27,130
like almost painfully long to wait for I

00:38:24,640 --> 00:38:29,200
poured a street to see bps BMD and went

00:38:27,130 --> 00:38:32,440
down to like 2 times or you know 53

00:38:29,200 --> 00:38:34,630
seconds not bad but still pretty slow

00:38:32,440 --> 00:38:36,460
compared to everything else no it's like

00:38:34,630 --> 00:38:39,400
ICC the otaku part is a bit better job

00:38:36,460 --> 00:38:40,900
so down to 30 seconds that's nice and

00:38:39,400 --> 00:38:42,130
basically just like these differences

00:38:40,900 --> 00:38:45,610
between Capas that are so huge I think

00:38:42,130 --> 00:38:47,170
it just makes me see that we need to

00:38:45,610 --> 00:38:48,280
make like a power vendors aware if I cut

00:38:47,170 --> 00:38:50,050
out two mice code for this basically

00:38:48,280 --> 00:38:52,000
that's what it but that's what it means

00:38:50,050 --> 00:38:54,010
to me

00:38:52,000 --> 00:38:55,630
moving on though it's it's again like I

00:38:54,010 --> 00:38:58,570
species I managed to get like a huge

00:38:55,630 --> 00:39:01,180
speed up from this GPS can decode going

00:38:58,570 --> 00:39:02,920
down to 16 seconds and again in this

00:39:01,180 --> 00:39:04,420
case I was like come on this is C++ be

00:39:02,920 --> 00:39:06,400
sure to do better so I went in and like

00:39:04,420 --> 00:39:07,690
figure out where the bottlenecks were

00:39:06,400 --> 00:39:09,940
and did a bunch of optimization stuff

00:39:07,690 --> 00:39:11,590
and realized I okay so does this waste

00:39:09,940 --> 00:39:13,750
actually speed it up and and then I got

00:39:11,590 --> 00:39:17,320
down to 15 seconds but with some work

00:39:13,750 --> 00:39:18,340
right so again like kinda like similar

00:39:17,320 --> 00:39:19,840
to the first one

00:39:18,340 --> 00:39:21,610
it was floored that I specie at first

00:39:19,840 --> 00:39:22,990
but with some hand optimizations you can

00:39:21,610 --> 00:39:24,820
you can get it back to where it's

00:39:22,990 --> 00:39:26,050
supposed to be I've got a few more

00:39:24,820 --> 00:39:27,310
examples so this one is a volume

00:39:26,050 --> 00:39:28,990
rendering example where I takes a point

00:39:27,310 --> 00:39:32,620
cloud and renders it as a nice-looking

00:39:28,990 --> 00:39:33,910
stream of I know smoke I didn't have

00:39:32,620 --> 00:39:36,100
time to actually like hand optimize this

00:39:33,910 --> 00:39:39,160
one so I kind of like just a minute

00:39:36,100 --> 00:39:40,990
defeat still though the superclass code

00:39:39,160 --> 00:39:43,510
like the regular old C++ code is pretty

00:39:40,990 --> 00:39:46,420
slow and just putting at the cps BMV got

00:39:43,510 --> 00:39:49,210
a huge speed up on both visual C++ and

00:39:46,420 --> 00:39:51,970
Intel compiler running a nice PC still

00:39:49,210 --> 00:39:54,010
is the champion but the gap is not so

00:39:51,970 --> 00:39:57,970
far compared to the Intel compiler

00:39:54,010 --> 00:40:01,360
example all right and since Finance is

00:39:57,970 --> 00:40:03,609
so important in C++ I've supported some

00:40:01,360 --> 00:40:05,319
of the I guess like

00:40:03,609 --> 00:40:07,329
finance algorithms like I don't really

00:40:05,319 --> 00:40:09,819
I'm familiar with them but I think these

00:40:07,329 --> 00:40:11,549
are used for like stock buying stocks or

00:40:09,819 --> 00:40:14,469
something like that I don't really know

00:40:11,549 --> 00:40:17,499
anyways i ported this code without even

00:40:14,469 --> 00:40:18,519
knowing what it does and so the you know

00:40:17,499 --> 00:40:23,650
you can still see an improvement from

00:40:18,519 --> 00:40:25,209
plain c++ so running the epsp new

00:40:23,650 --> 00:40:26,859
version of binomial options got me a

00:40:25,209 --> 00:40:28,779
small speed up and i species still a

00:40:26,859 --> 00:40:30,609
little bit faster actually it's kind of

00:40:28,779 --> 00:40:32,380
surprising that the binomial options is

00:40:30,609 --> 00:40:33,459
like it's really not getting that much

00:40:32,380 --> 00:40:34,690
juice out of Cindy and I haven't

00:40:33,459 --> 00:40:36,579
investigated why but that's like an

00:40:34,690 --> 00:40:38,609
interesting case out of all the examples

00:40:36,579 --> 00:40:40,930
that it seems to not scale that well and

00:40:38,609 --> 00:40:43,539
then there's a black Scholes algorithm

00:40:40,930 --> 00:40:45,849
that one got all faster with CPS BMD

00:40:43,539 --> 00:40:47,680
with a straight port from just getting a

00:40:45,849 --> 00:40:51,549
four x feet up like that running with

00:40:47,680 --> 00:40:52,779
IntelliJ faster but again here I specie

00:40:51,549 --> 00:40:55,420
was a champion and I didn't have time to

00:40:52,779 --> 00:40:57,729
make a hint optimized version

00:40:55,420 --> 00:41:00,459
so to summarize all these examples

00:40:57,729 --> 00:41:02,589
here's some nice craft so the plane

00:41:00,459 --> 00:41:04,509
Super Plus is the blue bar and the

00:41:02,589 --> 00:41:07,569
orange bar is CPSP in these performance

00:41:04,509 --> 00:41:10,029
relative to the the blue ones I species

00:41:07,569 --> 00:41:11,650
the gray bar and then when I took the

00:41:10,029 --> 00:41:15,400
time to optimize it that's the yellow

00:41:11,650 --> 00:41:16,869
bar so I can shape you should give you

00:41:15,400 --> 00:41:19,539
like a big idea of what's going on here

00:41:16,869 --> 00:41:21,069
it seems like if you want like the you

00:41:19,539 --> 00:41:23,229
know really great results and like not

00:41:21,069 --> 00:41:24,519
have to do any like tricky optimizations

00:41:23,229 --> 00:41:25,989
up and all that kind of stuff you can

00:41:24,519 --> 00:41:29,049
just use I specie today and that seems

00:41:25,989 --> 00:41:31,779
like probably the best choice but if you

00:41:29,049 --> 00:41:33,309
really want to C++ code and you're

00:41:31,779 --> 00:41:36,489
willing to maybe profile your code and

00:41:33,309 --> 00:41:38,680
maybe like I don't deal with the fact

00:41:36,489 --> 00:41:41,380
that current compilers or maybe not as

00:41:38,680 --> 00:41:44,170
good at optimizing vector code CBP ice

00:41:41,380 --> 00:41:47,229
cream he might be an option so that's

00:41:44,170 --> 00:41:48,819
the performance of it but the court

00:41:47,229 --> 00:41:51,670
earlier is still like had a lot of ugly

00:41:48,819 --> 00:41:53,799
parts and so what I want talking about

00:41:51,670 --> 00:41:56,709
now is just like all the quirks of how

00:41:53,799 --> 00:41:58,779
this works and part of the idea of these

00:41:56,709 --> 00:42:00,910
perks is that it's going to be also like

00:41:58,779 --> 00:42:03,369
a way to suggest improvements this is a

00:42:00,910 --> 00:42:04,359
closed language so one of the first

00:42:03,369 --> 00:42:05,949
works is the fact that you have to

00:42:04,359 --> 00:42:08,949
actually explicitly load it in store and

00:42:05,949 --> 00:42:10,269
the reason why is because what I'd like

00:42:08,949 --> 00:42:11,739
to do is I'd like to make it so that

00:42:10,269 --> 00:42:14,109
when you do an assignment so if you

00:42:11,739 --> 00:42:17,319
float with the operator assignment I

00:42:14,109 --> 00:42:19,359
like you to do a like a mask store but

00:42:17,319 --> 00:42:20,949
that's not possible and because I need

00:42:19,359 --> 00:42:22,599
the execution mask in that assignment

00:42:20,949 --> 00:42:24,160
operator and that assignment operator

00:42:22,599 --> 00:42:25,390
has to be a member function of you float

00:42:24,160 --> 00:42:27,640
which doesn't have access to the

00:42:25,390 --> 00:42:30,279
execution mask and something happens for

00:42:27,640 --> 00:42:31,869
like my my V float ref class so lethal

00:42:30,279 --> 00:42:34,180
ref is supposed to be like it's the

00:42:31,869 --> 00:42:36,910
results of an indexing operation and so

00:42:34,180 --> 00:42:38,559
I mean you convert that to a V flow to

00:42:36,910 --> 00:42:41,289
gives you like the results of floating

00:42:38,559 --> 00:42:42,670
from the address and again this this

00:42:41,289 --> 00:42:44,319
conversion operator has to be a member

00:42:42,670 --> 00:42:48,489
function so I can't access the execution

00:42:44,319 --> 00:42:50,440
mask and a member function so you know

00:42:48,489 --> 00:42:51,969
but that's why I can't use it maybe it

00:42:50,440 --> 00:42:53,739
says you're close defect because I don't

00:42:51,969 --> 00:42:54,759
see why this isn't really possible they

00:42:53,739 --> 00:42:57,369
maybe it's just like we don't have the

00:42:54,759 --> 00:42:59,229
syntax for it or something when I wish I

00:42:57,369 --> 00:43:01,479
could just write is just like how my V

00:42:59,229 --> 00:43:03,569
flow class and then read the assignment

00:43:01,479 --> 00:43:06,459
operator in the body of STD kernel and

00:43:03,569 --> 00:43:09,519
in that case I can access the execution

00:43:06,459 --> 00:43:11,289
mask and like I mean like I already have

00:43:09,519 --> 00:43:13,150
this code it's just that it's called

00:43:11,289 --> 00:43:15,039
like load and store instead of being

00:43:13,150 --> 00:43:16,719
called operator assignments so other

00:43:15,039 --> 00:43:20,109
than like syntactical issues I don't see

00:43:16,719 --> 00:43:21,930
why this isn't possible but so yeah

00:43:20,109 --> 00:43:23,859
maybe that's an improvement as possible

00:43:21,930 --> 00:43:25,959
another thing you might have noticed if

00:43:23,859 --> 00:43:26,829
you if you look carefully is that when I

00:43:25,959 --> 00:43:28,930
index race

00:43:26,829 --> 00:43:32,769
I say index operator instead of pointer

00:43:28,930 --> 00:43:34,420
of index which is like a bit weird so

00:43:32,769 --> 00:43:36,940
the reason why is because you can't

00:43:34,420 --> 00:43:38,920
overload the operator to index a float

00:43:36,940 --> 00:43:40,390
pointer because I guess you just can't

00:43:38,920 --> 00:43:43,660
overload operators from building classes

00:43:40,390 --> 00:43:45,160
like that as far as I can tell so I kind

00:43:43,660 --> 00:43:46,719
of like abuse this identity here which

00:43:45,160 --> 00:43:48,369
by the way this works in all C programs

00:43:46,719 --> 00:43:49,690
just the fact that like when you do

00:43:48,369 --> 00:43:51,849
pointer if I it's the same thing as

00:43:49,690 --> 00:43:53,039
doing star pointer plus I which is the

00:43:51,849 --> 00:43:55,299
same thing as being higher plus pointer

00:43:53,039 --> 00:43:56,799
dereference which is the same thing as

00:43:55,299 --> 00:44:00,279
being a pointer like this actually works

00:43:56,799 --> 00:44:00,880
in all C programs and so by using that

00:44:00,279 --> 00:44:03,640
identity

00:44:00,880 --> 00:44:06,459
I just overloaded the operator for VN so

00:44:03,640 --> 00:44:08,739
you say vient like quote no braces flow

00:44:06,459 --> 00:44:09,729
pointer and Biscay when you translate

00:44:08,739 --> 00:44:12,339
code you just have to switch the order

00:44:09,729 --> 00:44:14,469
of the like the the arguments to the the

00:44:12,339 --> 00:44:16,690
braces operator and or the square braces

00:44:14,469 --> 00:44:18,969
operator and other than that it kinda

00:44:16,690 --> 00:44:21,190
just works so kind like a dirty trick

00:44:18,969 --> 00:44:23,529
and it's basically just syntax but maybe

00:44:21,190 --> 00:44:25,539
there's a way to fix this by adding new

00:44:23,529 --> 00:44:29,469
like waste for overlaying operators in

00:44:25,539 --> 00:44:31,150
C++ another quirk is the need to call

00:44:29,469 --> 00:44:32,320
SPMD call like

00:44:31,150 --> 00:44:34,360
it'd be nice if you could just call it

00:44:32,320 --> 00:44:35,230
as if it was a regular function like as

00:44:34,360 --> 00:44:36,850
if it just worked like a regular

00:44:35,230 --> 00:44:39,760
function but instead you've to the SPMD

00:44:36,850 --> 00:44:41,830
call and the reason why is because when

00:44:39,760 --> 00:44:43,420
you call a function like a SPMD function

00:44:41,830 --> 00:44:45,160
from another function you have to

00:44:43,420 --> 00:44:49,480
actually do an implicit like pass by

00:44:45,160 --> 00:44:50,740
value of the execution mask and so right

00:44:49,480 --> 00:44:51,790
now that's not possible like you know

00:44:50,740 --> 00:44:53,770
it's kind of weird because it is

00:44:51,790 --> 00:44:55,090
possible to implicitly pass like that

00:44:53,770 --> 00:44:56,110
this pointer like this pointer is

00:44:55,090 --> 00:44:59,650
something that simplicity pass between

00:44:56,110 --> 00:45:01,960
member functions but the execution mask

00:44:59,650 --> 00:45:04,450
like you can't do that right now so I

00:45:01,960 --> 00:45:07,690
don't maybe this way to fix that and

00:45:04,450 --> 00:45:09,580
other than that thank you other than

00:45:07,690 --> 00:45:10,900
that this is busy at work so it's like

00:45:09,580 --> 00:45:12,220
if you call it from the outside of an

00:45:10,900 --> 00:45:14,590
SPD kernel I'll just call the function

00:45:12,220 --> 00:45:16,120
with a mask that's all on and if you

00:45:14,590 --> 00:45:18,580
call a CMD call from inside an SPG

00:45:16,120 --> 00:45:19,870
kernel then it'll like the only thing

00:45:18,580 --> 00:45:22,150
like the body first when you call is

00:45:19,870 --> 00:45:24,250
actually extremely small all it does is

00:45:22,150 --> 00:45:26,290
it copies the mask and then calls the

00:45:24,250 --> 00:45:28,810
function that's all it does and so that

00:45:26,290 --> 00:45:30,340
also explains maybe y-nough also

00:45:28,810 --> 00:45:32,560
explains why it's called underscore call

00:45:30,340 --> 00:45:34,630
the reason I made a suit you have to

00:45:32,560 --> 00:45:35,770
call it under spare calls because it's

00:45:34,630 --> 00:45:36,970
just to give you a hint that like you're

00:45:35,770 --> 00:45:39,430
not supposed to touch this basically

00:45:36,970 --> 00:45:41,050
like if you have to explicitly say dot

00:45:39,430 --> 00:45:50,260
underscore call like you know you're

00:45:41,050 --> 00:45:59,680
doing something wrong so I just read is

00:45:50,260 --> 00:46:16,120
it really I don't think so yep

00:45:59,680 --> 00:46:19,540
so wrong well good so so that's why I

00:46:16,120 --> 00:46:24,520
call it like that and it's kind of ugly

00:46:19,540 --> 00:46:25,570
but it works for now another quirk is

00:46:24,520 --> 00:46:28,300
that there's these lambdas everywhere

00:46:25,570 --> 00:46:30,850
and like these lambdas like it's not

00:46:28,300 --> 00:46:32,620
like you can do much with it like this

00:46:30,850 --> 00:46:34,240
is basically just noise it doesn't

00:46:32,620 --> 00:46:35,560
actually add anything like it there's a

00:46:34,240 --> 00:46:37,240
functionality that you can have like

00:46:35,560 --> 00:46:39,210
these lambdas with that they that

00:46:37,240 --> 00:46:42,640
capture everything and just do whatever

00:46:39,210 --> 00:46:44,020
so from what I saw it seemed like they

00:46:42,640 --> 00:46:44,890
usually get in lined so it's not really

00:46:44,020 --> 00:46:46,059
like a performance

00:46:44,890 --> 00:46:48,369
now you don't actually get transit into

00:46:46,059 --> 00:46:50,799
function calls most of the time but just

00:46:48,369 --> 00:46:51,999
ugly syntax so I don't know if there's

00:46:50,799 --> 00:46:53,470
actually a good way to fix this other

00:46:51,999 --> 00:46:57,460
than actually changing the single source

00:46:53,470 --> 00:46:58,690
grammar so maybe in the future there's

00:46:57,460 --> 00:46:59,890
gonna be like an actual extension of the

00:46:58,690 --> 00:47:02,769
grammar that lets you do something like

00:46:59,890 --> 00:47:04,630
this more easily I hope maybe there's a

00:47:02,769 --> 00:47:06,369
way to do with macros I haven't really

00:47:04,630 --> 00:47:07,630
thought about too hard because I just

00:47:06,369 --> 00:47:09,430
dislike macros and I feel like that's

00:47:07,630 --> 00:47:11,079
defined the purpose but maybe there's a

00:47:09,430 --> 00:47:14,289
way to do it if somebody something it

00:47:11,079 --> 00:47:15,880
was like a clean way to do that all

00:47:14,289 --> 00:47:16,839
right next thing is the fact that you

00:47:15,880 --> 00:47:18,160
have to inherit from my stream is

00:47:16,839 --> 00:47:19,599
eternal so it's like why do you have to

00:47:18,160 --> 00:47:21,910
inherit from Eastern you criminal the

00:47:19,599 --> 00:47:23,619
reason why is because it gives you the

00:47:21,910 --> 00:47:25,690
executioner mask and also gives you the

00:47:23,619 --> 00:47:26,680
related logic for the execution mask so

00:47:25,690 --> 00:47:29,650
that's that's basically I have to

00:47:26,680 --> 00:47:31,299
inherit from that and I kind of see it

00:47:29,650 --> 00:47:32,650
like it's not necessarily a bad thing

00:47:31,299 --> 00:47:35,019
because actually it could be used to

00:47:32,650 --> 00:47:37,319
configure the implementation the Cindy

00:47:35,019 --> 00:47:39,220
so for example whenever you buy that is

00:47:37,319 --> 00:47:41,499
imagine you want to write a kernel that

00:47:39,220 --> 00:47:44,200
you know you wanted to use a px - this

00:47:41,499 --> 00:47:46,059
is just like in theory maybe if it could

00:47:44,200 --> 00:47:47,529
be like an SMD kernel avx2 and then that

00:47:46,059 --> 00:47:49,299
way you're guaranteed about the

00:47:47,529 --> 00:47:51,400
instruction set is being used for your

00:47:49,299 --> 00:47:52,749
kernel alternatively maybe it could be

00:47:51,400 --> 00:47:54,609
something like this we're like you got a

00:47:52,749 --> 00:47:55,989
template argument for the width and that

00:47:54,609 --> 00:47:57,460
can be useful because when you're

00:47:55,989 --> 00:47:59,440
writing code that interfaces between

00:47:57,460 --> 00:48:01,029
like cindy code like this this code in

00:47:59,440 --> 00:48:01,960
another code as long as you want you

00:48:01,029 --> 00:48:03,489
want to assume that just like you're

00:48:01,960 --> 00:48:04,720
working in blocks blocks of 16 like

00:48:03,489 --> 00:48:07,509
maybe you're working in blocks of 16

00:48:04,720 --> 00:48:08,890
pixels or something like that and the

00:48:07,509 --> 00:48:10,809
fact that you're using an instruction

00:48:08,890 --> 00:48:12,400
said that works in terms of 4 or in

00:48:10,809 --> 00:48:14,680
terms of 8 or in terms of 16 it's kinda

00:48:12,400 --> 00:48:17,079
like an implementation detail so be able

00:48:14,680 --> 00:48:18,670
to say that like be able to say that

00:48:17,079 --> 00:48:20,769
this kernel should run with with an

00:48:18,670 --> 00:48:22,210
emulated width of 16 is something that

00:48:20,769 --> 00:48:23,769
could be pretty convenient and it's

00:48:22,210 --> 00:48:26,529
obviously just to give you an idea like

00:48:23,769 --> 00:48:28,989
if you're running like a SPD kernel that

00:48:26,529 --> 00:48:30,400
is supposed to pretend to be 16 wide but

00:48:28,989 --> 00:48:32,349
the instruction set you're using only

00:48:30,400 --> 00:48:34,450
has four wide vectors it basically means

00:48:32,349 --> 00:48:35,710
that every operation is crippled like

00:48:34,450 --> 00:48:38,049
just every statement just happens four

00:48:35,710 --> 00:48:39,609
times that that's what it means and

00:48:38,049 --> 00:48:51,730
other than that I think that that's

00:48:39,609 --> 00:48:53,710
pretty much it so yeah I think I'm

00:48:51,730 --> 00:48:55,119
to exploit that but the promise is when

00:48:53,710 --> 00:48:56,590
you do the SPG call you have to be able

00:48:55,119 --> 00:49:06,400
to set the mask and all that kind of

00:48:56,590 --> 00:49:08,320
stuff so yeah it'd be nice to do like I

00:49:06,400 --> 00:49:09,190
don't I I kind of got it working but

00:49:08,320 --> 00:49:10,869
there's a lot of things that could be

00:49:09,190 --> 00:49:14,010
improved by people who who know better

00:49:10,869 --> 00:49:15,910
or like the detailed roles of SIBO fuss

00:49:14,010 --> 00:49:17,619
yeah I'm actually gonna talk about that

00:49:15,910 --> 00:49:20,700
in a second yeah

00:49:17,619 --> 00:49:24,040
so in conclusion we've seen today that

00:49:20,700 --> 00:49:27,280
SPMD is like a actually pretty like

00:49:24,040 --> 00:49:28,900
widespread portable way to write code

00:49:27,280 --> 00:49:31,900
that seems to be you know works on both

00:49:28,900 --> 00:49:34,480
CPUs and GPUs so it's actually pretty

00:49:31,900 --> 00:49:35,710
nice I've shown you that you can

00:49:34,480 --> 00:49:37,540
actually commit to it and relatively

00:49:35,710 --> 00:49:38,890
simple sequel close code so like I

00:49:37,540 --> 00:49:40,090
didn't write any like weird template

00:49:38,890 --> 00:49:42,970
metaprogramming stuff there was no Mac

00:49:40,090 --> 00:49:44,290
was involved it was just like like this

00:49:42,970 --> 00:49:47,380
Ben you kernel class that just like has

00:49:44,290 --> 00:49:49,210
a few like functions in it and it runs

00:49:47,380 --> 00:49:50,920
slam does so it's nothing like too

00:49:49,210 --> 00:49:53,290
spooky I think anybody can understand it

00:49:50,920 --> 00:49:54,609
really based on the performance

00:49:53,290 --> 00:49:55,780
measurements that I did it seems like

00:49:54,609 --> 00:49:56,440
today if you want to write code that

00:49:55,780 --> 00:49:59,590
looks like this

00:49:56,440 --> 00:50:01,300
the best bet is to use is PC but hey

00:49:59,590 --> 00:50:02,980
maybe tomorrow C++ is gonna be the best

00:50:01,300 --> 00:50:05,710
choice so hopefully we can work through

00:50:02,980 --> 00:50:06,910
it something like that maybe we're

00:50:05,710 --> 00:50:09,400
missing like language support in terms

00:50:06,910 --> 00:50:11,500
of like new syntax is for things like I

00:50:09,400 --> 00:50:13,450
showed earlier maybe we also need to

00:50:11,500 --> 00:50:15,330
have compilers be more aware of how to

00:50:13,450 --> 00:50:17,950
optimize code for Cindy architectures

00:50:15,330 --> 00:50:19,390
which is a thing that maybe me maybe

00:50:17,950 --> 00:50:21,270
explains like the big differences in

00:50:19,390 --> 00:50:24,130
performance between different compilers

00:50:21,270 --> 00:50:25,810
but hey we've got the right people in

00:50:24,130 --> 00:50:27,100
the room at the conference so you know

00:50:25,810 --> 00:50:29,950
let's think about how we can close this

00:50:27,100 --> 00:50:31,780
gap other than that thanks for listening

00:50:29,950 --> 00:50:33,490
we have any questions or comments let's

00:50:31,780 --> 00:50:35,080
talk about it you can find the

00:50:33,490 --> 00:50:37,270
implementation here again it's not

00:50:35,080 --> 00:50:38,530
production ready it's just like it only

00:50:37,270 --> 00:50:40,330
implements what I needed for the

00:50:38,530 --> 00:50:42,340
performance measurements I did before

00:50:40,330 --> 00:50:44,619
basically and if you want talking on

00:50:42,340 --> 00:50:47,190
Twitter here's my Twitter that's all

00:50:44,619 --> 00:50:47,190
thank you

00:50:57,980 --> 00:51:03,240
right so so as far as I know when you

00:51:01,410 --> 00:51:05,310
write into Simon's operator okay so I'll

00:51:03,240 --> 00:51:07,320
be the question the question is why

00:51:05,310 --> 00:51:09,330
can't access the execution mass from

00:51:07,320 --> 00:51:11,010
inside the assignment operator the

00:51:09,330 --> 00:51:13,380
reason why is because as far as I could

00:51:11,010 --> 00:51:14,940
tell the assignment operator has to be a

00:51:13,380 --> 00:51:17,040
member function of the class that it's

00:51:14,940 --> 00:51:19,530
assigning to and so it has to be a

00:51:17,040 --> 00:51:22,080
member function of V float and V float

00:51:19,530 --> 00:51:24,420
is a separate type from STD kernel and

00:51:22,080 --> 00:51:26,340
so it has to be able to access the

00:51:24,420 --> 00:51:27,780
execution mask that that's stored India

00:51:26,340 --> 00:51:31,770
is going to be kernel that contains it

00:51:27,780 --> 00:51:33,630
and in this case I'll take this way to

00:51:31,770 --> 00:51:34,770
do that it's a goes plus and like yeah

00:51:33,630 --> 00:51:36,210
maybe I could do something like maybe I

00:51:34,770 --> 00:51:37,980
could store the pointer to the SMD

00:51:36,210 --> 00:51:40,140
kernel from inside the V float but I

00:51:37,980 --> 00:51:48,980
decided that seems like to or head so

00:51:40,140 --> 00:51:51,210
yeah yeah the kernel is an object and

00:51:48,980 --> 00:51:54,420
all it does is give you the execution

00:51:51,210 --> 00:51:55,920
mask and and it gives you the functions

00:51:54,420 --> 00:51:56,790
that are necessary to rate SPME code

00:51:55,920 --> 00:51:59,120
like you just inherit those

00:51:56,790 --> 00:51:59,120
functionalities

00:52:16,820 --> 00:52:20,550
okay actually fluid is defined like in

00:52:19,290 --> 00:52:24,660
the scope of assume you colonel like

00:52:20,550 --> 00:52:25,620
it's like a inner class yeah but but I

00:52:24,660 --> 00:52:31,950
think I wasn't really change anything

00:52:25,620 --> 00:52:34,590
about how big a nice is totally yeah so

00:52:31,950 --> 00:52:39,560
you can look at the code yeah let's

00:52:34,590 --> 00:52:39,560
let's move on yeah right

00:53:06,250 --> 00:53:10,100
so I'm repeat I'm gonna try to summarize

00:53:08,690 --> 00:53:11,930
this comment then where you're

00:53:10,100 --> 00:53:18,680
suggesting is that we could implement

00:53:11,930 --> 00:54:19,070
this by returning evaluated like like to

00:53:18,680 --> 00:54:22,070
see that thank you so the question I'll

00:54:19,070 --> 00:54:24,230
try to summarize or the comment is is if

00:54:22,070 --> 00:54:27,410
you try to extend the native Cindy with

00:54:24,230 --> 00:54:28,700
by duplicating every operation does that

00:54:27,410 --> 00:54:32,330
not lead to the case where you actually

00:54:28,700 --> 00:54:32,810
do need to put a barrier and I think it

00:54:32,330 --> 00:54:35,120
doesn't

00:54:32,810 --> 00:54:36,590
my main like inherently the reason why I

00:54:35,120 --> 00:54:38,000
think it doesn't is because I specie

00:54:36,590 --> 00:54:40,670
lets you do it in the sense that I

00:54:38,000 --> 00:54:42,680
specie lets you say like run this AVX

00:54:40,670 --> 00:54:44,600
code as if it was 16 wide and that works

00:54:42,680 --> 00:54:46,700
so I assume like the model doesn't

00:54:44,600 --> 00:54:49,490
prevent it it should in theory work I

00:54:46,700 --> 00:54:51,020
haven't got a proof of concept in CPSP

00:54:49,490 --> 00:54:53,300
MD so maybe there's some other details

00:54:51,020 --> 00:54:55,370
I'm not thinking of but I think it works

00:54:53,300 --> 00:54:56,660
and I think the important part to keep

00:54:55,370 --> 00:54:58,190
in mind is that

00:54:56,660 --> 00:55:01,280
the synchronization happens at sequence

00:54:58,190 --> 00:55:03,590
points so that means is like in one

00:55:01,280 --> 00:55:04,940
statement which will be executed

00:55:03,590 --> 00:55:07,910
multiple times if you're doing like a

00:55:04,940 --> 00:55:09,830
wider with like or at least it'll be

00:55:07,910 --> 00:55:11,410
executed once but it'll be executed and

00:55:09,830 --> 00:55:14,360
they'll do multiple vector operations

00:55:11,410 --> 00:55:16,460
you can't assume that like you can't

00:55:14,360 --> 00:55:21,410
communicate between lanes of execution I

00:55:16,460 --> 00:55:24,770
guess like yeah you you know how kind of

00:55:21,410 --> 00:55:26,090
say you you can't communicate you can't

00:55:24,770 --> 00:55:28,780
communicate using shared memory between

00:55:26,090 --> 00:55:31,040
lanes of execution inside one statement

00:55:28,780 --> 00:55:34,300
you can only do it in between statements

00:55:31,040 --> 00:55:37,310
and I think that that makes it work out

00:55:34,300 --> 00:55:38,900
so I mean it's kinda like mind-bending

00:55:37,310 --> 00:55:42,680
so maybe we can think about a bit longer

00:55:38,900 --> 00:55:44,630
but I think it should work and I think

00:55:42,680 --> 00:55:46,550
that the reason why well what is it I

00:55:44,630 --> 00:55:48,920
think the reason why I buried a

00:55:46,550 --> 00:55:51,320
necessary on a GPU for example is

00:55:48,920 --> 00:55:52,610
because you actually do have multiple

00:55:51,320 --> 00:55:54,350
threads of execution in the sense that

00:55:52,610 --> 00:55:55,250
like but by the word thread I mean it's

00:55:54,350 --> 00:55:56,930
actually different pieces of hardware

00:55:55,250 --> 00:56:00,350
running the same code in parallel or

00:55:56,930 --> 00:56:02,150
without being in lockstep so since these

00:56:00,350 --> 00:56:04,220
different executions are non locks that

00:56:02,150 --> 00:56:07,960
get to put a barrier but in this case

00:56:04,220 --> 00:56:07,960
it's in lockstep so it's a bit simpler

00:56:14,890 --> 00:56:29,090
so right so right so to repeat that on a

00:56:23,900 --> 00:56:32,510
GPU how can I say this doesn't scale two

00:56:29,090 --> 00:56:34,520
GPUs because GPUs I guess you're saying

00:56:32,510 --> 00:56:35,720
needs to be wider and need to be running

00:56:34,520 --> 00:56:38,120
at multiple threads like actual

00:56:35,720 --> 00:56:40,160
different Hardware threads and this

00:56:38,120 --> 00:56:42,740
model doesn't consider that I guess and

00:56:40,160 --> 00:56:46,460
I think I think you're right about that

00:56:42,740 --> 00:56:48,230
and I think that that that problem might

00:56:46,460 --> 00:56:49,550
be on GPU vendors and GPU vendors hands

00:56:48,230 --> 00:56:51,350
that they have to make a more flexible

00:56:49,550 --> 00:56:55,400
computation model that that's my opinion

00:56:51,350 --> 00:56:56,930
but yeah but Biscay like I mean the way

00:56:55,400 --> 00:56:58,670
the original GPU is like they'll have

00:56:56,930 --> 00:57:00,770
these different like they'll have these

00:56:58,670 --> 00:57:03,350
independent streams of like wavefronts

00:57:00,770 --> 00:57:04,940
of like 64 64 bytes vector operations

00:57:03,350 --> 00:57:08,060
but they're all getting scheduled in a

00:57:04,940 --> 00:57:10,340
penalty and I don't think we have a good

00:57:08,060 --> 00:57:11,630
way of like controlling that

00:57:10,340 --> 00:57:13,490
from our code anyway that would make

00:57:11,630 --> 00:57:18,620
sense to C++ right now but maybe in the

00:57:13,490 --> 00:57:19,370
future right

00:57:18,620 --> 00:57:25,550
but locks that would kill the

00:57:19,370 --> 00:57:28,100
performance so as long as you're inside

00:57:25,550 --> 00:57:29,030
of one rate front yeah and actually I

00:57:28,100 --> 00:57:30,470
think that's a that's the thing that's

00:57:29,030 --> 00:57:33,170
getting more more more and more popular

00:57:30,470 --> 00:57:34,640
I think like shader model six I think it

00:57:33,170 --> 00:57:36,980
is like the the new your shader model of

00:57:34,640 --> 00:57:38,480
explosives may level operations so that

00:57:36,980 --> 00:57:42,110
kind of stuff is something that I guess

00:57:38,480 --> 00:57:49,310
we'll be seeing more and more all right

00:57:42,110 --> 00:57:51,830
any more questions comments the license

00:57:49,310 --> 00:57:55,190
I think it maybe it's MIT or something I

00:57:51,830 --> 00:57:56,960
remember it should be not a problem yeah

00:57:55,190 --> 00:57:58,280
if it's a problem Tommy and I can do

00:57:56,960 --> 00:58:05,090
anything necessary to make it possible

00:57:58,280 --> 00:58:08,150
to fix yep anybody else okay I think

00:58:05,090 --> 00:58:10,270
we're just about done so thank you for

00:58:08,150 --> 00:58:10,270

YouTube URL: https://www.youtube.com/watch?v=UgaQCg-0ZoU


