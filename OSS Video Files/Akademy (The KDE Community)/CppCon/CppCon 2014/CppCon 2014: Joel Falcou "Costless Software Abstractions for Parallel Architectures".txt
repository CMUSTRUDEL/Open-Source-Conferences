Title: CppCon 2014: Joel Falcou "Costless Software Abstractions for Parallel Architectures"
Publication date: 2014-10-22
Playlist: CppCon 2014
Description: 
	http://www.cppcon.org
â€”
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/CppCon/CppCon2014
--
Performing large, intensive or non-trivial computing on array like data structures is one of the most common task in scientific computing, video game development and other fields. This matter of fact is backed up by the large number of tools, languages and libraries to perform such tasks. If we restrict ourselves to C++ based solutions, more than a dozen such libraries exists from BLAS/LAPACK C++ binding to template meta-programming based Blitz++ or Eigen. If all of these libraries provide good performance or good abstraction, none of them seems to fit the need of so many different user types.

Moreover, as parallel system complexity grows, the need to maintain all those components quickly become unwieldy. This talk explores various software design techniques - like Generative Programming, MetaProgramming and Generic Programming - and their application to the implementation of a parallel computing librariy in such a way that:

- abstraction and expressiveness are maximized - cost over efficiency is minimized

We'll skim over various applications and see how they can benefit from such tools. We will conclude by discussing what lessons were learnt from this kind of implementation and how those lessons can translate into new directions for the language itself.
--
Joel Falcou is an assistant professor at the University Paris-Sud and researcher at the Laboratoire de Recherche d'Informatique in Orsay, France. His researches focus on studying generative programming idioms and techniques to design tools for parallel software development. The two main parts of those works are : exploration of Embedded Domain Specific Language design for parallel computing on various architectures and the definition of a formal framework for reasoning about meta-programs and prove their compile-time correctness. Applications range from real-time image processing on embedded architectures to High Performance Computing on multi-core clusters. 

He is also NumScale SAS scientific advisor. NumScale mission is to assist businesses in the exploration and subsequently the mastery of high-performance computing systems. 
--
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,149 --> 00:00:06,420
I'm Jofuku I'm an acident professor from

00:00:03,870 --> 00:00:08,849
University Paracels and the CTO of nem

00:00:06,420 --> 00:00:10,110
square which is a company which deals

00:00:08,849 --> 00:00:13,469
with providing tools for

00:00:10,110 --> 00:00:15,839
high-performance computing to non expert

00:00:13,469 --> 00:00:19,800
in computing so this talk would be about

00:00:15,839 --> 00:00:22,710
more like tears about journeys and

00:00:19,800 --> 00:00:26,250
something else about the challenge we

00:00:22,710 --> 00:00:28,439
think people currently faces concerning

00:00:26,250 --> 00:00:30,359
the use and mastering of fair

00:00:28,439 --> 00:00:34,920
programming in general in different

00:00:30,359 --> 00:00:38,309
context and how we try to solve these

00:00:34,920 --> 00:00:43,040
problems and how C++ LP does is doing

00:00:38,309 --> 00:00:44,879
this and what we handed up with so

00:00:43,040 --> 00:00:47,489
parallel programming and pair

00:00:44,879 --> 00:00:51,660
architectures is basically the odd topic

00:00:47,489 --> 00:00:55,530
of since a couple of decades most modern

00:00:51,660 --> 00:00:58,079
hardware's innovation are on war we're

00:00:55,530 --> 00:01:00,120
driven by the need expressed by

00:00:58,079 --> 00:01:01,710
scientific computing community being I

00:01:00,120 --> 00:01:04,500
mean all the guys doing high-energy

00:01:01,710 --> 00:01:08,189
physics or all the data mining stuff or

00:01:04,500 --> 00:01:11,340
I speed imaging and so prairie

00:01:08,189 --> 00:01:14,060
architectures is what he's a solution

00:01:11,340 --> 00:01:16,740
that vendors has found to to have this

00:01:14,060 --> 00:01:20,070
very demanding application be running at

00:01:16,740 --> 00:01:21,600
the correct path the problem is that for

00:01:20,070 --> 00:01:23,460
a long time parry architectures was

00:01:21,600 --> 00:01:25,140
basically something that you will you

00:01:23,460 --> 00:01:28,350
will find in a very huge company of

00:01:25,140 --> 00:01:30,540
academia but now there is a lot of small

00:01:28,350 --> 00:01:32,460
to medium-sized companies that actually

00:01:30,540 --> 00:01:35,070
requires this kind of performances and

00:01:32,460 --> 00:01:38,549
so for designing their product faster or

00:01:35,070 --> 00:01:42,390
to actually be a product in itself okay

00:01:38,549 --> 00:01:44,280
and for some of those company of some of

00:01:42,390 --> 00:01:46,439
this research group it's actually

00:01:44,280 --> 00:01:48,780
difficult to have the local experts

00:01:46,439 --> 00:01:50,640
doing the actual science of the actual

00:01:48,780 --> 00:01:52,439
engineering and next to that having

00:01:50,640 --> 00:01:54,720
people just dedicated to actually know

00:01:52,439 --> 00:01:57,240
how to program those damn machine and

00:01:54,720 --> 00:01:59,939
the problem is actually make going you

00:01:57,240 --> 00:02:01,829
know walls and walls has smashing become

00:01:59,939 --> 00:02:03,570
more and more complex if I just take a

00:02:01,829 --> 00:02:08,310
look at this laptop I just bought like

00:02:03,570 --> 00:02:10,289
six months ago it's already a huge beast

00:02:08,310 --> 00:02:12,430
I have four logical cores with I don't

00:02:10,289 --> 00:02:14,379
know Meany

00:02:12,430 --> 00:02:16,450
extremely extension set I have like

00:02:14,379 --> 00:02:19,959
three or four types of memory and

00:02:16,450 --> 00:02:23,230
cashiers I have a small inboard GPUs I

00:02:19,959 --> 00:02:26,560
have an actual NVIDIA GPU inside with 40

00:02:23,230 --> 00:02:28,329
aides muta codes inside and his own set

00:02:26,560 --> 00:02:30,219
of memory and if I wanted to actually

00:02:28,329 --> 00:02:33,400
write an application taking care of all

00:02:30,219 --> 00:02:35,079
of those details I would have to end or

00:02:33,400 --> 00:02:39,280
something like three or five different

00:02:35,079 --> 00:02:41,379
API and programming model so if this is

00:02:39,280 --> 00:02:44,400
complex for somebody which is actually

00:02:41,379 --> 00:02:46,569
dealing with that as his day-to-day job

00:02:44,400 --> 00:02:48,549
imagine how its complex for something

00:02:46,569 --> 00:02:52,120
for somebody which is a physicist or

00:02:48,549 --> 00:02:56,500
statisticians and the actual problem is

00:02:52,120 --> 00:02:58,959
not going to be solved just by waiting

00:02:56,500 --> 00:03:02,500
for different tools or whatever for a

00:02:58,959 --> 00:03:06,069
long time if we consider the performance

00:03:02,500 --> 00:03:08,109
versus expressiveness trade-off for a

00:03:06,069 --> 00:03:13,150
long time people didn't have very much

00:03:08,109 --> 00:03:14,919
choice anyway so if you climbed up the

00:03:13,150 --> 00:03:17,949
performance later you will lose

00:03:14,919 --> 00:03:20,440
expressiveness but not by much and doing

00:03:17,949 --> 00:03:23,379
this D so this was basically the exact

00:03:20,440 --> 00:03:26,349
same thing okay but you changed it when

00:03:23,379 --> 00:03:28,329
we get those mythical assign the enabled

00:03:26,349 --> 00:03:30,040
processors basically all of this just

00:03:28,329 --> 00:03:32,919
get lumped into these sequential blobs

00:03:30,040 --> 00:03:35,169
and if you get if you wanted to get to

00:03:32,919 --> 00:03:36,790
the next level of performances you get

00:03:35,169 --> 00:03:40,479
the massive flaws in the expressiveness

00:03:36,790 --> 00:03:42,280
okay and now it's not even going better

00:03:40,479 --> 00:03:45,340
we have GPUs or gem 5 distributed

00:03:42,280 --> 00:03:47,319
systems threading signle and all

00:03:45,340 --> 00:03:50,319
combination of that and everything just

00:03:47,319 --> 00:03:52,989
yet more and more spread out so the

00:03:50,319 --> 00:03:58,030
question is can we actually be around

00:03:52,989 --> 00:04:00,120
there and around there okay which is as

00:03:58,030 --> 00:04:02,560
expressive as in normal languages and

00:04:00,120 --> 00:04:05,169
being able to take care of all those

00:04:02,560 --> 00:04:07,180
kind of performance sources so that was

00:04:05,169 --> 00:04:11,979
a challenge we wanted to to have a look

00:04:07,180 --> 00:04:13,329
at so in to do so because the challenge

00:04:11,979 --> 00:04:15,040
is not enough we wanted to have some

00:04:13,329 --> 00:04:16,900
constraint because it will be too easy

00:04:15,040 --> 00:04:18,849
you know so we wanted to be

00:04:16,900 --> 00:04:21,459
non-destructive in the sense that we

00:04:18,849 --> 00:04:23,320
didn't want to force people to change

00:04:21,459 --> 00:04:26,100
the way they program all day long and

00:04:23,320 --> 00:04:29,880
the way they use build systems okay

00:04:26,100 --> 00:04:32,800
does to be has easy to use as possible

00:04:29,880 --> 00:04:34,330
another point was we found out after a

00:04:32,800 --> 00:04:36,819
lot of experimentation that the best

00:04:34,330 --> 00:04:39,580
optimization is not cranking out this

00:04:36,819 --> 00:04:42,250
very optimized bit flipping algorithms

00:04:39,580 --> 00:04:44,050
using I don't know what instruction set

00:04:42,250 --> 00:04:46,539
it was finding the proper demand-driven

00:04:44,050 --> 00:04:48,610
optic optimization that you cannot

00:04:46,539 --> 00:04:50,500
actually ask a compiler to find for you

00:04:48,610 --> 00:04:52,330
you have to have an expert of the domain

00:04:50,500 --> 00:04:53,860
telling you yeah but you know this stuff

00:04:52,330 --> 00:04:56,110
it's really better if you do it this way

00:04:53,860 --> 00:04:59,229
and we wanted to find a way to actually

00:04:56,110 --> 00:05:03,130
incorporate that the API has to be

00:04:59,229 --> 00:05:05,320
intuitive and as a clear landscape is

00:05:03,130 --> 00:05:07,900
ever moving we want it to be easily

00:05:05,320 --> 00:05:12,520
portable on what amount of architectures

00:05:07,900 --> 00:05:16,389
and we want it to be efficient if not I

00:05:12,520 --> 00:05:18,639
mean I can just write Java so what did

00:05:16,389 --> 00:05:22,139
we do we try to find a way to design

00:05:18,639 --> 00:05:25,120
tools I C++ library to address point one

00:05:22,139 --> 00:05:27,520
C++ because Peter Peters getting a nice

00:05:25,120 --> 00:05:28,720
abstraction layer and a nice API and the

00:05:27,520 --> 00:05:31,840
libraries because that way we are

00:05:28,720 --> 00:05:33,729
trivial to use we designed those

00:05:31,840 --> 00:05:36,370
libraries as domain-specific embedded

00:05:33,729 --> 00:05:39,370
languages what we get on what C stuff

00:05:36,370 --> 00:05:41,409
are a bit later which help us giving

00:05:39,370 --> 00:05:44,620
this API stuff with these Dominick

00:05:41,409 --> 00:05:47,020
optimization layers and we use a

00:05:44,620 --> 00:05:50,020
parallel programming model called Paris

00:05:47,020 --> 00:05:52,930
skeletons as called as parametric

00:05:50,020 --> 00:05:56,110
parameter parallel components to help us

00:05:52,930 --> 00:05:59,080
with four points and use generative

00:05:56,110 --> 00:06:02,380
programming to ensure performances so

00:05:59,080 --> 00:06:04,659
all all these stuff get together well so

00:06:02,380 --> 00:06:06,460
problem is that if you use and structure

00:06:04,659 --> 00:06:09,580
with parallelisms writing a peri

00:06:06,460 --> 00:06:11,199
programming is very odd okay and you

00:06:09,580 --> 00:06:15,099
will have our time debugging it you will

00:06:11,199 --> 00:06:17,080
have our time making it portable and so

00:06:15,099 --> 00:06:20,800
you don't really want to do that what

00:06:17,080 --> 00:06:23,800
you want to do is actually use a model

00:06:20,800 --> 00:06:27,190
for your programming your problem your

00:06:23,800 --> 00:06:30,759
peripheral and there is a lot of care

00:06:27,190 --> 00:06:33,940
programming models either based on some

00:06:30,759 --> 00:06:38,440
kind of aerial performance model like

00:06:33,940 --> 00:06:39,830
all the parameter P nbsp models okay you

00:06:38,440 --> 00:06:42,470
have data centric models we

00:06:39,830 --> 00:06:44,570
the data structure in any semantics will

00:06:42,470 --> 00:06:47,690
drive the prioritization that was pig

00:06:44,570 --> 00:06:51,340
ass and all PS related stuff does or HTA

00:06:47,690 --> 00:06:55,060
and you are what we call pattern centric

00:06:51,340 --> 00:06:58,490
pattern models which are actors and

00:06:55,060 --> 00:06:59,780
skeletons so we decided to use keratins

00:06:58,490 --> 00:07:01,910
because they have a lot of nice

00:06:59,780 --> 00:07:04,460
properties so what what's the parrot

00:07:01,910 --> 00:07:07,130
skeleton so Paris Krypton was something

00:07:04,460 --> 00:07:10,400
designed in 1989 by Mariko

00:07:07,130 --> 00:07:11,660
which are designed them as patterns in

00:07:10,400 --> 00:07:13,580
parallel positions the same way you have

00:07:11,660 --> 00:07:16,010
patterned in sequential application and

00:07:13,580 --> 00:07:17,540
those pattern can be generalized and

00:07:16,010 --> 00:07:20,510
turned into something you can assemble

00:07:17,540 --> 00:07:22,670
and compose and being composable is

00:07:20,510 --> 00:07:25,550
actually trimming useful in pair economy

00:07:22,670 --> 00:07:27,800
and from a functional point of view

00:07:25,550 --> 00:07:29,150
skeletons aiiow order functions which

00:07:27,800 --> 00:07:31,490
means there are functions which

00:07:29,150 --> 00:07:34,940
parameters can be other functions okay

00:07:31,490 --> 00:07:39,250
and trivially those function arguments

00:07:34,940 --> 00:07:41,480
can be your fine-grained sequential

00:07:39,250 --> 00:07:43,820
operation you want to orchestrate on

00:07:41,480 --> 00:07:45,590
your machine and basically writing a

00:07:43,820 --> 00:07:47,450
pair petition is just composing

00:07:45,590 --> 00:07:52,070
skeletons and your function into a

00:07:47,450 --> 00:07:54,380
stateless object so basically there is a

00:07:52,070 --> 00:07:56,660
couple of classical skeletons that we

00:07:54,380 --> 00:07:58,310
will just find out trivially you have

00:07:56,660 --> 00:08:00,500
mapped which is basically putting your

00:07:58,310 --> 00:08:04,190
same function to everybody into a data

00:08:00,500 --> 00:08:07,550
set for the perform relevant scan which

00:08:04,190 --> 00:08:10,340
basically resemble what you can find to

00:08:07,550 --> 00:08:12,590
the standard library actually and you

00:08:10,340 --> 00:08:14,480
have task-oriented skeletons like far

00:08:12,590 --> 00:08:16,100
which is basically I have a task there

00:08:14,480 --> 00:08:18,290
and the task there and nobody talked to

00:08:16,100 --> 00:08:21,230
each others ok so you can just partition

00:08:18,290 --> 00:08:23,690
your parallel system this way pipeline

00:08:21,230 --> 00:08:28,010
which just make - dependency over time

00:08:23,690 --> 00:08:31,490
and form or slavemasters depending on

00:08:28,010 --> 00:08:33,440
where you go is used for load balancing

00:08:31,490 --> 00:08:35,240
issues you basically have a stream of

00:08:33,440 --> 00:08:37,040
data coming in a pool of slave

00:08:35,240 --> 00:08:39,680
processors and you judge the tribute to

00:08:37,040 --> 00:08:43,010
walk to those slaves processes as time

00:08:39,680 --> 00:08:45,560
goes and actually expressing a prior

00:08:43,010 --> 00:08:47,780
application of sewing by using

00:08:45,560 --> 00:08:50,180
combination of that is trivial and just

00:08:47,780 --> 00:08:52,280
looks like functional programming anyway

00:08:50,180 --> 00:08:53,630
and you will just have to find your way

00:08:52,280 --> 00:08:56,120
to decompose your problem

00:08:53,630 --> 00:08:58,600
skeletons so I don't know if anybody is

00:08:56,120 --> 00:09:02,540
familiar with MapReduce the Google stuff

00:08:58,600 --> 00:09:04,430
right who knows about MapReduce okay so

00:09:02,540 --> 00:09:08,210
basically MapReduce is various curtains

00:09:04,430 --> 00:09:10,190
okay even if they came they claim

00:09:08,210 --> 00:09:14,660
otherwise that basically we're map and

00:09:10,190 --> 00:09:15,650
for that's MapReduce and well the thing

00:09:14,660 --> 00:09:17,030
is that you can actually write to

00:09:15,650 --> 00:09:19,100
application without having to deal with

00:09:17,030 --> 00:09:21,020
parallelism details you just say I'm

00:09:19,100 --> 00:09:23,720
composing those skeletons one into the

00:09:21,020 --> 00:09:26,810
others and dot doesn't have to do

00:09:23,720 --> 00:09:28,370
anything to maintain it except being

00:09:26,810 --> 00:09:32,150
sure that the implementation of each

00:09:28,370 --> 00:09:34,430
stratum is correct and some clever math

00:09:32,150 --> 00:09:36,650
guy actually demonstrated that you can

00:09:34,430 --> 00:09:38,480
actually reason on skeleton composition

00:09:36,650 --> 00:09:42,470
and prove that your program is fairly

00:09:38,480 --> 00:09:44,090
correct which can be something nice to

00:09:42,470 --> 00:09:47,570
have when you walk on certified

00:09:44,090 --> 00:09:50,020
environment and if the semantics of the

00:09:47,570 --> 00:09:51,980
each skeleton is set in stone

00:09:50,020 --> 00:09:54,470
implementation is free so you can have a

00:09:51,980 --> 00:09:56,330
map over a bunch of assignee vectors you

00:09:54,470 --> 00:09:58,340
can have a map distributed over stress

00:09:56,330 --> 00:10:00,350
and you can distribute over thread using

00:09:58,340 --> 00:10:02,630
piece read using OpenMP using TBB

00:10:00,350 --> 00:10:06,080
whatever you can distribute over network

00:10:02,630 --> 00:10:08,420
same same stuff it's map so we can just

00:10:06,080 --> 00:10:11,240
use that as some kind of layers to

00:10:08,420 --> 00:10:14,540
access to adware and just live with that

00:10:11,240 --> 00:10:16,460
and whenever you compose skeleton in

00:10:14,540 --> 00:10:19,850
itself with different architectural

00:10:16,460 --> 00:10:22,070
support you just emulate support for

00:10:19,850 --> 00:10:24,620
article architectures so if you do a map

00:10:22,070 --> 00:10:26,900
on NPR I'll just call a map on OpenMP

00:10:24,620 --> 00:10:29,360
calling a map and assign me you just go

00:10:26,900 --> 00:10:32,090
down your architectures yah-tchi and

00:10:29,360 --> 00:10:33,680
everybody is happy and was together so

00:10:32,090 --> 00:10:36,230
that's the kind of father we wanted to

00:10:33,680 --> 00:10:38,120
have to be able to simplify the amount

00:10:36,230 --> 00:10:40,730
of work we wanted to do and so the

00:10:38,120 --> 00:10:42,620
question is how to have all those

00:10:40,730 --> 00:10:44,630
function composition of function

00:10:42,620 --> 00:10:47,660
composition of sequential function being

00:10:44,630 --> 00:10:49,310
efficient at the end so this model of

00:10:47,660 --> 00:10:50,540
development we took was what we call

00:10:49,310 --> 00:10:52,910
generative programming which is

00:10:50,540 --> 00:10:54,620
something that was proposed in 2000

00:10:52,910 --> 00:10:57,710
something by schnauzers key and from and

00:10:54,620 --> 00:11:00,080
other guys which basically is all we

00:10:57,710 --> 00:11:01,910
want so as he says an every complex

00:11:00,080 --> 00:11:04,400
application can be derived from a

00:11:01,910 --> 00:11:06,610
domain-specific description of the

00:11:04,400 --> 00:11:09,310
application then

00:11:06,610 --> 00:11:11,800
get past to a translator and this

00:11:09,310 --> 00:11:13,870
translator will pick up components that

00:11:11,800 --> 00:11:16,180
can be private right depending on what

00:11:13,870 --> 00:11:18,370
what kind of patterns are found into

00:11:16,180 --> 00:11:21,190
this description and the actual type use

00:11:18,370 --> 00:11:22,750
into the description and also it picked

00:11:21,190 --> 00:11:24,730
up the component it would just build

00:11:22,750 --> 00:11:28,000
whatever it needs to be done for the

00:11:24,730 --> 00:11:29,890
application and what we found out is

00:11:28,000 --> 00:11:32,890
that let's say we want to do this and

00:11:29,890 --> 00:11:35,620
use our Paris Fritton whatever

00:11:32,890 --> 00:11:37,560
perispirit on will just be there as sub

00:11:35,620 --> 00:11:40,180
component of the systems and we can just

00:11:37,560 --> 00:11:42,310
take this domain-specific description we

00:11:40,180 --> 00:11:44,800
wanted to have anyway point two and

00:11:42,310 --> 00:11:46,420
three get into that and find a way to do

00:11:44,800 --> 00:11:48,850
this and the question out do you write

00:11:46,420 --> 00:11:51,269
this translator well how many of you

00:11:48,850 --> 00:11:55,450
went to water brown talked yesterday

00:11:51,269 --> 00:11:59,279
okay so social is metal follow me which

00:11:55,450 --> 00:11:59,279
suggests me to program everything okay

00:11:59,880 --> 00:12:07,300
so in fact there is multiple way to do

00:12:05,350 --> 00:12:10,269
change the programming sou write your

00:12:07,300 --> 00:12:12,730
own compilers it works not very

00:12:10,269 --> 00:12:14,829
efficient in term of types and efforts

00:12:12,730 --> 00:12:18,160
but it works you can use external

00:12:14,829 --> 00:12:20,079
pre-processing to like p4 or whatever or

00:12:18,160 --> 00:12:22,180
you can use with the programming so for

00:12:20,079 --> 00:12:24,670
the guys that were not compatible talked

00:12:22,180 --> 00:12:26,709
yesterday many programming is writing of

00:12:24,670 --> 00:12:29,290
computer programs that can analyze

00:12:26,709 --> 00:12:32,440
transform and generate other program as

00:12:29,290 --> 00:12:33,640
if there were data so a program is just

00:12:32,440 --> 00:12:38,019
a bunch of data you want to manipulate

00:12:33,640 --> 00:12:39,699
okay and well how to do that in C++ so

00:12:38,019 --> 00:12:42,279
simplest recipe type programming just

00:12:39,699 --> 00:12:45,220
rely on the simplest rest templates of

00:12:42,279 --> 00:12:48,240
languages in which you can endure types

00:12:45,220 --> 00:12:51,640
and integral constant at compile time

00:12:48,240 --> 00:12:55,199
like it was actually of pure functional

00:12:51,640 --> 00:12:59,620
languages and in fact you can prove that

00:12:55,199 --> 00:13:00,880
C++ templates in itself is a Turing

00:12:59,620 --> 00:13:02,589
complete language so you can do

00:13:00,880 --> 00:13:05,740
arbitrary computation at compile time

00:13:02,589 --> 00:13:08,560
into the C++ compilers and when I say

00:13:05,740 --> 00:13:11,769
arbitrary I say arbitrary and that's

00:13:08,560 --> 00:13:13,899
cool because well one stuff we wanted to

00:13:11,769 --> 00:13:15,640
compute is we have a description of

00:13:13,899 --> 00:13:16,390
languages and we want to turn it into

00:13:15,640 --> 00:13:19,890
something else

00:13:16,390 --> 00:13:19,890
or is it called

00:13:19,960 --> 00:13:23,320
what's the name of tools that take a

00:13:21,190 --> 00:13:24,970
language description a program within

00:13:23,320 --> 00:13:25,450
some languages turn it into something

00:13:24,970 --> 00:13:28,480
else

00:13:25,450 --> 00:13:30,940
that's a compiler and the compiler is a

00:13:28,480 --> 00:13:33,310
program so you can write a compiler

00:13:30,940 --> 00:13:36,120
using some languages so what about

00:13:33,310 --> 00:13:40,960
writing the compiler using meta program

00:13:36,120 --> 00:13:44,440
okay so to do this but you can do that

00:13:40,960 --> 00:13:47,050
like you know using whatever but let's

00:13:44,440 --> 00:13:48,520
have a method to our madness okay so we

00:13:47,050 --> 00:13:51,130
go back to this definition of

00:13:48,520 --> 00:13:53,830
domain-specific embedded languages the

00:13:51,130 --> 00:13:56,320
SEL that's a mouthful so what did yes

00:13:53,830 --> 00:13:58,660
here so what's the DSL first so DSL is

00:13:56,320 --> 00:14:01,210
domain-specific languages it's a small

00:13:58,660 --> 00:14:04,150
usually declarative language that can be

00:14:01,210 --> 00:14:06,310
used to define a way to express solution

00:14:04,150 --> 00:14:08,470
to a very narrow set of problems

00:14:06,310 --> 00:14:11,170
if you ever wrote to make file you were

00:14:08,470 --> 00:14:12,100
using a DSL if you ever run SQL you are

00:14:11,170 --> 00:14:14,320
using a DSL

00:14:12,100 --> 00:14:15,820
okay so DSL can or cannot be

00:14:14,320 --> 00:14:19,030
turing-complete that's not a problem

00:14:15,820 --> 00:14:21,270
and what's the GS yeah well it's a DSL

00:14:19,030 --> 00:14:25,300
that just is embedded into another

00:14:21,270 --> 00:14:28,330
usually general-purpose languages so to

00:14:25,300 --> 00:14:31,270
do this in C++ well when we just abuse

00:14:28,330 --> 00:14:33,160
or use depending on which side of the

00:14:31,270 --> 00:14:36,330
fence you are sitting on operator

00:14:33,160 --> 00:14:38,620
overloading and using a very well-known

00:14:36,330 --> 00:14:41,920
idioms which expression template that we

00:14:38,620 --> 00:14:43,330
get on that afterwards and using this we

00:14:41,920 --> 00:14:46,990
can carry arbitrary cementing

00:14:43,330 --> 00:14:49,300
information on code fragment so we can

00:14:46,990 --> 00:14:53,020
capture a fragment of statement and slap

00:14:49,300 --> 00:14:56,530
some information on that and we can just

00:14:53,020 --> 00:14:58,180
pass around those code fragments as far

00:14:56,530 --> 00:14:59,860
as we want into the evaluation process

00:14:58,180 --> 00:15:02,200
and whenever we need those extra

00:14:59,860 --> 00:15:04,210
informations we can just pick them up

00:15:02,200 --> 00:15:07,930
and do whatever we want and we can

00:15:04,210 --> 00:15:10,360
actually turn a code or a library

00:15:07,930 --> 00:15:12,490
self-aware of a possible optimization

00:15:10,360 --> 00:15:16,090
that's with what we're using called acti

00:15:12,490 --> 00:15:17,800
active libraries which otherwise do a

00:15:16,090 --> 00:15:20,160
very simple thing we were we will be

00:15:17,800 --> 00:15:24,190
able to capture arbitrary statement

00:15:20,160 --> 00:15:26,200
abstract syntax tree as a whole and not

00:15:24,190 --> 00:15:28,870
same with high-level semantic

00:15:26,200 --> 00:15:31,210
information and we can actually as an

00:15:28,870 --> 00:15:32,410
expression level generate arbitrary code

00:15:31,210 --> 00:15:33,520
from these iced tea and those

00:15:32,410 --> 00:15:36,280
information

00:15:33,520 --> 00:15:38,800
or which is even better we can just pass

00:15:36,280 --> 00:15:41,830
Isis around as parameters of functions

00:15:38,800 --> 00:15:44,650
to trigger some form of interprocedural

00:15:41,830 --> 00:15:46,090
optimization okay but we can do that

00:15:44,650 --> 00:15:48,460
with whatever semantics we want

00:15:46,090 --> 00:15:52,630
so basically expression templates are

00:15:48,460 --> 00:15:54,610
just compiler inside the compiler and to

00:15:52,630 --> 00:15:56,770
do this what we do is we use booze Frodo

00:15:54,610 --> 00:16:02,020
so it doesn't have to write all the

00:15:56,770 --> 00:16:04,300
crush types and machinery that's

00:16:02,020 --> 00:16:06,640
something okay that could be codified

00:16:04,300 --> 00:16:10,990
hidden copy past the same slide twice

00:16:06,640 --> 00:16:14,140
whatever so let me know about that

00:16:10,990 --> 00:16:17,980
already okay so what are the advantages

00:16:14,140 --> 00:16:22,570
well we can actually introduce a

00:16:17,980 --> 00:16:25,000
de-esser into c++ c DSL can be as

00:16:22,570 --> 00:16:28,270
specific to the domain as possible okay

00:16:25,000 --> 00:16:30,100
right and we do this as a library so

00:16:28,270 --> 00:16:34,210
nobody get disrupted okay

00:16:30,100 --> 00:16:36,000
and as we define tribes to carry the

00:16:34,210 --> 00:16:39,370
semantics that means that we can we

00:16:36,000 --> 00:16:43,420
resolve semantics driven optimization at

00:16:39,370 --> 00:16:45,280
compile time and as we didn't have any

00:16:43,420 --> 00:16:47,050
information about what's going on we can

00:16:45,280 --> 00:16:49,930
bind to arbitrary runtimes

00:16:47,050 --> 00:16:51,850
later on so basically just like we put a

00:16:49,930 --> 00:16:54,700
language into your into your language

00:16:51,850 --> 00:16:59,110
and we compile we force a compiler to

00:16:54,700 --> 00:17:00,880
compile what we want so an example let's

00:16:59,110 --> 00:17:04,000
say for example we want to have this

00:17:00,880 --> 00:17:06,839
find a mattress base operator going on

00:17:04,000 --> 00:17:10,240
so if we look at this statement okay

00:17:06,839 --> 00:17:12,760
what happen is that if if you were a

00:17:10,240 --> 00:17:15,250
compiler you will see that as something

00:17:12,760 --> 00:17:17,260
that resembles these three okay I'm

00:17:15,250 --> 00:17:19,540
assigning something to X and if

00:17:17,260 --> 00:17:21,730
something is the sum between the CAHSEE

00:17:19,540 --> 00:17:25,810
news of a and the product between DNA

00:17:21,730 --> 00:17:28,800
and this tree there is basically

00:17:25,810 --> 00:17:32,080
flattening to this very complex types

00:17:28,800 --> 00:17:33,910
okay that's the type that the

00:17:32,080 --> 00:17:35,620
declarations that the type which is

00:17:33,910 --> 00:17:37,090
basically a Faton uses oh it's an

00:17:35,620 --> 00:17:39,370
expression of assignment between the

00:17:37,090 --> 00:17:41,920
matrix and an expression of plus

00:17:39,370 --> 00:17:44,680
etcetera external and the interesting

00:17:41,920 --> 00:17:47,260
point is that in red there you have the

00:17:44,680 --> 00:17:50,260
structure of the code okay what

00:17:47,260 --> 00:17:52,780
on on the node of the tree and we have

00:17:50,260 --> 00:17:56,650
information about what is manipulated by

00:17:52,780 --> 00:18:00,010
three a B X and so on okay so if we look

00:17:56,650 --> 00:18:02,020
at that this types is basically this so

00:18:00,010 --> 00:18:04,810
we can apply a bit or e transform at

00:18:02,020 --> 00:18:07,840
compile time and turn this into

00:18:04,810 --> 00:18:09,760
something else and for example we can

00:18:07,840 --> 00:18:12,250
say yeah well what about turning that

00:18:09,760 --> 00:18:15,540
into a natural look nest you know going

00:18:12,250 --> 00:18:18,960
over every element of every matrixes and

00:18:15,540 --> 00:18:23,700
just turn that into a element-wise

00:18:18,960 --> 00:18:27,100
computation of what's inside matrixes

00:18:23,700 --> 00:18:29,440
okay so blue for the data red for

00:18:27,100 --> 00:18:33,100
whatever is going on in the in the tree

00:18:29,440 --> 00:18:34,450
and let's say you have information there

00:18:33,100 --> 00:18:37,210
about what kind of architecture you have

00:18:34,450 --> 00:18:39,130
well what about slapping some openmp

00:18:37,210 --> 00:18:42,250
pragma on top of that or vector writing

00:18:39,130 --> 00:18:45,070
these or doing both whatever so this

00:18:42,250 --> 00:18:45,580
transformation there we can do whatever

00:18:45,070 --> 00:18:48,100
we want

00:18:45,580 --> 00:18:50,320
okay if you wanted to turn this into a

00:18:48,100 --> 00:18:53,440
string and ship it to a Fortran compiler

00:18:50,320 --> 00:18:55,960
or to a GPU or something like that we

00:18:53,440 --> 00:18:58,480
can just do that not a problem we can do

00:18:55,960 --> 00:19:00,100
whatever we want but if to do something

00:18:58,480 --> 00:19:02,320
meaningful what we actually need there

00:19:00,100 --> 00:19:04,210
is a static information about the

00:19:02,320 --> 00:19:06,880
architectures that's something we have

00:19:04,210 --> 00:19:09,670
to add so this code actually do whatever

00:19:06,880 --> 00:19:13,930
we want on the given architectures so

00:19:09,670 --> 00:19:15,400
basically if we just go back to this

00:19:13,930 --> 00:19:17,140
definition of general programming what

00:19:15,400 --> 00:19:19,780
we do is that we just add another layer

00:19:17,140 --> 00:19:21,610
on that so we add the domain specific

00:19:19,780 --> 00:19:23,680
application description there to which

00:19:21,610 --> 00:19:27,070
repair a domain-specific architectural

00:19:23,680 --> 00:19:28,650
description using a small DSL describing

00:19:27,070 --> 00:19:31,290
architectures in the hierarchical way

00:19:28,650 --> 00:19:33,430
this stuff get translated into

00:19:31,290 --> 00:19:36,520
architectural components which are

00:19:33,430 --> 00:19:37,900
actually instance instances of the

00:19:36,520 --> 00:19:40,540
skeleton we need on a given

00:19:37,900 --> 00:19:42,520
architectures and once we selected that

00:19:40,540 --> 00:19:45,640
we pour everything of all those patterns

00:19:42,520 --> 00:19:47,410
into this which is the components for

00:19:45,640 --> 00:19:50,620
the application that get translated and

00:19:47,410 --> 00:19:53,440
built from a preselection of the proper

00:19:50,620 --> 00:19:55,900
implementation of each components so we

00:19:53,440 --> 00:19:57,700
feed the compiler to information this is

00:19:55,900 --> 00:19:59,860
a high level description of whatever I

00:19:57,700 --> 00:20:01,029
am trying to do okay let's figure out

00:19:59,860 --> 00:20:03,789
how to do it properly

00:20:01,029 --> 00:20:05,709
and this is a description of what kind

00:20:03,789 --> 00:20:08,499
of architecture you have and how you

00:20:05,709 --> 00:20:10,059
should be able to exploit this

00:20:08,499 --> 00:20:13,019
information to give me the proper

00:20:10,059 --> 00:20:18,159
component to generating my efficient

00:20:13,019 --> 00:20:20,049
code from my application and the point

00:20:18,159 --> 00:20:23,229
is that everything from zeros there is

00:20:20,049 --> 00:20:25,449
that if you happening at compile time so

00:20:23,229 --> 00:20:29,079
we probably have zero overhead at the

00:20:25,449 --> 00:20:35,199
end that's what we want to be at the end

00:20:29,079 --> 00:20:37,629
of all of that so what do you do resolve

00:20:35,199 --> 00:20:39,219
this so what we wanted to have is some

00:20:37,629 --> 00:20:41,079
kind of demonstration that we can

00:20:39,219 --> 00:20:44,049
actually do this in a lot of different

00:20:41,079 --> 00:20:46,119
scenarios demonstrates that sparest

00:20:44,049 --> 00:20:50,039
written is a viable param programming

00:20:46,119 --> 00:20:52,569
model for that and that with

00:20:50,039 --> 00:20:55,029
sufficiently advanced metal program

00:20:52,569 --> 00:20:57,429
systems we can actually go from point A

00:20:55,029 --> 00:21:00,429
to point B without having to go outside

00:20:57,429 --> 00:21:02,589
the sequences compiler so we did a bunch

00:21:00,429 --> 00:21:06,939
of stuff I won't talk about all of that

00:21:02,589 --> 00:21:09,159
so we have VSP plus plus which is a BSL

00:21:06,939 --> 00:21:11,909
geniux the prospect PSP library so BSP

00:21:09,159 --> 00:21:14,379
is a very constrained programming model

00:21:11,909 --> 00:21:16,089
which has a good idea to have an

00:21:14,379 --> 00:21:17,979
analytical performance model so whenever

00:21:16,089 --> 00:21:20,879
you look at your algorithm you know by

00:21:17,979 --> 00:21:23,319
advance how many times he takes ok and

00:21:20,879 --> 00:21:23,769
that both work on chaired and this with

00:21:23,319 --> 00:21:26,889
a memory

00:21:23,769 --> 00:21:28,239
we have Kraft which is a DSL for direct

00:21:26,889 --> 00:21:31,149
skeleton programming not very

00:21:28,239 --> 00:21:33,759
interesting just there for historical

00:21:31,149 --> 00:21:36,369
purpose we have both sim D which is a

00:21:33,759 --> 00:21:38,739
DSL for a natural portable design the

00:21:36,369 --> 00:21:42,369
programming style that also happens to

00:21:38,739 --> 00:21:44,079
use curtains and we have n t2 which is a

00:21:42,369 --> 00:21:45,579
matter of like DSL for scientific

00:21:44,079 --> 00:21:47,169
computing which we speak a bit more

00:21:45,579 --> 00:21:50,349
about right now

00:21:47,169 --> 00:21:51,249
so what's n t2 so n t2 is numeric code

00:21:50,349 --> 00:21:54,069
template toolbox

00:21:51,249 --> 00:21:56,739
it's basically MATLAB in C++ without

00:21:54,069 --> 00:22:02,049
also without all the crafts and with

00:21:56,739 --> 00:22:04,529
actual performance and which is designed

00:22:02,049 --> 00:22:07,959
to actually be walking on whatever

00:22:04,529 --> 00:22:11,229
CPU or GPU you have and be easily

00:22:07,959 --> 00:22:14,320
extendable so it's built on to two

00:22:11,229 --> 00:22:15,730
layers so we use boosting D and

00:22:14,320 --> 00:22:17,799
the related tools for the inco

00:22:15,730 --> 00:22:20,169
optimizations and we use recursive ferry

00:22:17,799 --> 00:22:23,409
skeletons to build up on medicals and

00:22:20,169 --> 00:22:24,880
other systems and your code actually is

00:22:23,409 --> 00:22:27,009
an impendent of the architecture you

00:22:24,880 --> 00:22:29,409
want to target and the runtime you want

00:22:27,009 --> 00:22:30,759
to use to exploit this diet it means

00:22:29,409 --> 00:22:33,789
that if you are in the mythical systems

00:22:30,759 --> 00:22:35,860
and you don't really know if on for this

00:22:33,789 --> 00:22:39,100
very practical application openmp could

00:22:35,860 --> 00:22:40,899
be better than TV Bo or pthreads

00:22:39,100 --> 00:22:42,880
well you can just write your code once

00:22:40,899 --> 00:22:45,610
and compile it twice with different

00:22:42,880 --> 00:22:47,590
object is an option on the compiler to

00:22:45,610 --> 00:22:49,690
choose between those three runtime and

00:22:47,590 --> 00:22:55,409
you can compare performance quite fast

00:22:49,690 --> 00:22:57,700
so this is a bunch of feature lists so I

00:22:55,409 --> 00:22:59,500
know that this table looks like the

00:22:57,700 --> 00:23:05,129
Samsung versus a poor comparative

00:22:59,500 --> 00:23:08,620
comparisons okay but we did our best so

00:23:05,129 --> 00:23:11,129
we have a matter of like API we have

00:23:08,620 --> 00:23:14,320
bindings for blasting up at runtime

00:23:11,129 --> 00:23:16,480
because linear algebras is a job in

00:23:14,320 --> 00:23:19,750
itself so and currently is at the best

00:23:16,480 --> 00:23:22,120
stuff out there we are we have one of

00:23:19,750 --> 00:23:24,970
the few Magma bindings magma is a GPU

00:23:22,120 --> 00:23:27,100
version of lapack so whenever you use

00:23:24,970 --> 00:23:28,990
entity on the GPU systems and you use

00:23:27,100 --> 00:23:31,570
linear algebra we go on the GPU in the

00:23:28,990 --> 00:23:34,480
transparent way okay

00:23:31,570 --> 00:23:36,100
we basically support whatever assigned

00:23:34,480 --> 00:23:39,639
the extension intern ever thought about

00:23:36,100 --> 00:23:42,879
including xeon phi we have support for

00:23:39,639 --> 00:23:45,399
PowerPC and for arm multi-threading and

00:23:42,879 --> 00:23:49,809
we have a prototype for CUDA supports so

00:23:45,399 --> 00:23:52,539
we basically run everywhere with we try

00:23:49,809 --> 00:23:58,149
to have decent - very decent performance

00:23:52,539 --> 00:24:00,879
everywhere - and so ok so what does it

00:23:58,149 --> 00:24:02,649
looks like so this is a simple principle

00:24:00,879 --> 00:24:04,899
of what what you want to do when you

00:24:02,649 --> 00:24:06,730
write it called magenta - so you have a

00:24:04,899 --> 00:24:09,730
very simple or multi-dimensional array

00:24:06,730 --> 00:24:11,679
which is called table that just happened

00:24:09,730 --> 00:24:13,870
to walks like matlab array so it has a

00:24:11,679 --> 00:24:17,110
variable number of dimension between 1

00:24:13,870 --> 00:24:20,500
and 4 or 5 remember right now and

00:24:17,110 --> 00:24:22,750
whatever function you want to use it so

00:24:20,500 --> 00:24:24,519
the joke we have is that well if you

00:24:22,750 --> 00:24:26,379
want to do something just look up the

00:24:24,519 --> 00:24:27,630
MATLAB documentation and just write the

00:24:26,379 --> 00:24:30,600
damn function

00:24:27,630 --> 00:24:33,650
justice code and we probably walk 90% of

00:24:30,600 --> 00:24:37,320
the time so we have over 500 functions

00:24:33,650 --> 00:24:40,290
of Matt's signal processing statistics

00:24:37,320 --> 00:24:40,890
whatever and just walk on table on

00:24:40,290 --> 00:24:43,350
scaler

00:24:40,890 --> 00:24:45,840
in the transparent way so how does it

00:24:43,350 --> 00:24:48,420
work so let's say you walked with MATLAB

00:24:45,840 --> 00:24:51,120
first it happens okay so you take your

00:24:48,420 --> 00:24:54,300
mashup code you copy it into a C++ file

00:24:51,120 --> 00:24:58,560
you had some include and you do a bunch

00:24:54,300 --> 00:25:00,900
of changes for syntax visions you

00:24:58,560 --> 00:25:02,940
compile and well that's done you

00:25:00,900 --> 00:25:04,770
finished you converted you you're only

00:25:02,940 --> 00:25:07,580
like MATLAB code which we should

00:25:04,770 --> 00:25:10,740
probably slow into a tsipras's version

00:25:07,580 --> 00:25:12,540
okay that's what that's what they say on

00:25:10,740 --> 00:25:15,450
the team okay so let's have an example

00:25:12,540 --> 00:25:18,900
so how many of you are actually familiar

00:25:15,450 --> 00:25:22,530
with MATLAB syntax okay so I will

00:25:18,900 --> 00:25:25,020
explain that so first line what we do is

00:25:22,530 --> 00:25:27,720
we create an array called a1 which

00:25:25,020 --> 00:25:31,440
basically contains number from 1 to 1000

00:25:27,720 --> 00:25:35,250
spaced regularly and then we decide to

00:25:31,440 --> 00:25:39,060
have a normal distribution of random

00:25:35,250 --> 00:25:41,700
numbers to a-1 and what we do is that we

00:25:39,060 --> 00:25:43,920
compute some matrix product between a1

00:25:41,700 --> 00:25:46,860
in these transpose and we do Lu

00:25:43,920 --> 00:25:49,170
decomposition into X and for whatever

00:25:46,860 --> 00:25:52,080
reason what we compute the square root

00:25:49,170 --> 00:25:55,800
of the Sun between a1 square and a 2

00:25:52,080 --> 00:25:59,400
squared divided by the number of

00:25:55,800 --> 00:26:02,880
elements in a 1 ok well how do you turn

00:25:59,400 --> 00:26:04,530
that into C++ well you just do that so

00:26:02,880 --> 00:26:07,920
contribute to match that we need types

00:26:04,530 --> 00:26:10,410
ok so let's say table of double colon is

00:26:07,920 --> 00:26:12,950
not very simple that you can put

00:26:10,410 --> 00:26:16,740
anywhere in C++ so we turn that into

00:26:12,950 --> 00:26:19,760
underscore okay random is random in

00:26:16,740 --> 00:26:23,430
sizes size new marriage new mail ok and

00:26:19,760 --> 00:26:25,650
everywhere is a u so T cross transpose

00:26:23,430 --> 00:26:27,560
become a transpose function we have M

00:26:25,650 --> 00:26:30,750
times for the magic notification

00:26:27,560 --> 00:26:33,210
everything is basically the same and we

00:26:30,750 --> 00:26:34,950
found it although this column there so

00:26:33,210 --> 00:26:38,280
what does it means

00:26:34,950 --> 00:26:41,250
: in the in an indexing context matlab's

00:26:38,280 --> 00:26:43,320
means every element along this dimension

00:26:41,250 --> 00:26:46,050
okay and when you use it like this with

00:26:43,320 --> 00:26:50,150
only one dimension it means every

00:26:46,050 --> 00:26:53,700
element you know in this matrix is okay

00:26:50,150 --> 00:26:57,120
but in the Colin wise fashion okay so we

00:26:53,700 --> 00:26:58,950
can the same way we turn this Colin into

00:26:57,120 --> 00:27:02,100
this and the score we just reuse

00:26:58,950 --> 00:27:04,110
underscore in these places and done

00:27:02,100 --> 00:27:06,720
that's all you have to change this a

00:27:04,110 --> 00:27:08,310
bunch of also function like that okay

00:27:06,720 --> 00:27:11,730
and that's pretty much it

00:27:08,310 --> 00:27:13,710
okay so it's it's designed to transform

00:27:11,730 --> 00:27:15,750
this matter code into regular C++ code

00:27:13,710 --> 00:27:20,220
quite fast of course you can actually

00:27:15,750 --> 00:27:22,110
write directly C++ code in yet and for

00:27:20,220 --> 00:27:25,020
people that really want to be working in

00:27:22,110 --> 00:27:28,050
C++ we are obviously compatible with the

00:27:25,020 --> 00:27:29,970
traditional STL concept so table this

00:27:28,050 --> 00:27:31,950
random access sequence that give you

00:27:29,970 --> 00:27:34,350
iterators and so on and so on

00:27:31,950 --> 00:27:37,910
so you can actually go back and forth

00:27:34,350 --> 00:27:41,040
between C++ die and MATLAB style code

00:27:37,910 --> 00:27:42,870
using this so that's not really in a

00:27:41,040 --> 00:27:45,120
very interesting code just to do this

00:27:42,870 --> 00:27:47,130
way what we can do with that so but how

00:27:45,120 --> 00:27:49,710
does it works okay in practice so I have

00:27:47,130 --> 00:27:51,960
this because I spoke about spirit and

00:27:49,710 --> 00:27:53,010
and so on so others it works so let's

00:27:51,960 --> 00:27:55,800
say you have this statement

00:27:53,010 --> 00:27:58,500
you call be divided by the sum of C plus

00:27:55,800 --> 00:28:01,980
D okay so basically what you have is

00:27:58,500 --> 00:28:04,110
that you have this I see okay and what

00:28:01,980 --> 00:28:06,630
we do is that at compile time every node

00:28:04,110 --> 00:28:08,370
into this Ice T is flagged with

00:28:06,630 --> 00:28:13,110
something that tell us what kind of roof

00:28:08,370 --> 00:28:14,400
nest this operation will prefer and if

00:28:13,110 --> 00:28:16,590
you look at that you see that you have

00:28:14,400 --> 00:28:19,920
an 11 twice operation going on there we

00:28:16,590 --> 00:28:21,030
will divide B by something okay but if

00:28:19,920 --> 00:28:22,650
something is there is a partial

00:28:21,030 --> 00:28:24,810
reduction okay so it needs a different

00:28:22,650 --> 00:28:28,520
kind of rudeness so what you really want

00:28:24,810 --> 00:28:31,110
to be able to do is extract this subtree

00:28:28,520 --> 00:28:33,480
evaluate it into a temporary and put the

00:28:31,110 --> 00:28:35,760
temporary back so we can have a properly

00:28:33,480 --> 00:28:37,800
you know orchestrated loop nest and

00:28:35,760 --> 00:28:41,460
that's what we do at compile time by

00:28:37,800 --> 00:28:46,080
just crawling down the ice T we will

00:28:41,460 --> 00:28:48,770
just slice tree okay put that into a

00:28:46,080 --> 00:28:51,000
temporary that get references there

00:28:48,770 --> 00:28:52,920
generate the first loop nest using the

00:28:51,000 --> 00:28:54,840
fourth ferritin and then use the

00:28:52,920 --> 00:28:57,150
transform of map skeleton to

00:28:54,840 --> 00:28:58,890
the rest of the operation and if you

00:28:57,150 --> 00:29:01,610
look at that you see that we sliced

00:28:58,890 --> 00:29:03,960
there because we were combining

00:29:01,610 --> 00:29:06,060
elementwise operation with us with a

00:29:03,960 --> 00:29:08,430
reduction but in the case of the

00:29:06,060 --> 00:29:10,970
reduction we can actually keep the

00:29:08,430 --> 00:29:14,430
element wise operation inside because

00:29:10,970 --> 00:29:16,740
reduction of map is composable where map

00:29:14,430 --> 00:29:19,260
of reduction is not so we are going to

00:29:16,740 --> 00:29:25,140
detect this kind of patterns and slice

00:29:19,260 --> 00:29:27,840
it as we wish but there is a problem

00:29:25,140 --> 00:29:29,610
what happen if you do that and let's say

00:29:27,840 --> 00:29:31,410
you want to generate code for this so or

00:29:29,610 --> 00:29:33,660
every loop Ness is true your to generate

00:29:31,410 --> 00:29:37,130
and let's say you do that using an open

00:29:33,660 --> 00:29:39,990
MP back in or or an intent TBD back end

00:29:37,130 --> 00:29:44,460
well you will have a first feral region

00:29:39,990 --> 00:29:48,390
over there okay and then another one and

00:29:44,460 --> 00:29:50,370
so we get separated by a barrier so we

00:29:48,390 --> 00:29:52,740
could be very you know artistic and

00:29:50,370 --> 00:29:55,920
tricky and try to use open imp in no way

00:29:52,740 --> 00:29:58,260
because we we are you know we like

00:29:55,920 --> 00:30:00,000
gambling and so let's pretend that I can

00:29:58,260 --> 00:30:03,090
not work there and everything will work

00:30:00,000 --> 00:30:04,680
correctly normally what will happen is

00:30:03,090 --> 00:30:06,210
that you would pass a test but every

00:30:04,680 --> 00:30:09,030
time you will deploy that on the client

00:30:06,210 --> 00:30:11,100
it will you won't walk ok that's that's

00:30:09,030 --> 00:30:12,840
alright walk so we really have we really

00:30:11,100 --> 00:30:14,790
want to have a buyers there but if we

00:30:12,840 --> 00:30:17,610
start having a buyer every time we

00:30:14,790 --> 00:30:21,240
change you know look nest it would be

00:30:17,610 --> 00:30:23,220
costly and it's even worsse without

00:30:21,240 --> 00:30:25,740
having OpenMP actually let's say you

00:30:23,220 --> 00:30:27,720
have multiple statement the power of

00:30:25,740 --> 00:30:30,180
expression templates only stops at the

00:30:27,720 --> 00:30:31,920
first semicolon you fine ok and whenever

00:30:30,180 --> 00:30:34,860
you have another statement going on

00:30:31,920 --> 00:30:36,060
it's another context and the expression

00:30:34,860 --> 00:30:37,890
template system doesn't know what's

00:30:36,060 --> 00:30:40,140
what's going on the statement before and

00:30:37,890 --> 00:30:43,530
you will generate loop nest or a loop

00:30:40,140 --> 00:30:45,840
nest and if the algorithm is meant to

00:30:43,530 --> 00:30:47,970
not to be a bit more optimized than that

00:30:45,840 --> 00:30:49,740
and you will basically trash your cache

00:30:47,970 --> 00:30:51,390
locality because you will keep going

00:30:49,740 --> 00:30:54,300
over and over again different thickness

00:30:51,390 --> 00:30:56,910
and you will get bad performances so you

00:30:54,300 --> 00:30:58,470
get bad performances because either you

00:30:56,910 --> 00:31:00,990
want variance between statements or

00:30:58,470 --> 00:31:03,480
because you have a poor data quality and

00:31:00,990 --> 00:31:08,450
we wanted to find a way to fight against

00:31:03,480 --> 00:31:10,250
that first idea was well let's

00:31:08,450 --> 00:31:11,890
semicolon into something that the

00:31:10,250 --> 00:31:15,020
expression template system can recognize

00:31:11,890 --> 00:31:17,450
so what about abusing this poor comma

00:31:15,020 --> 00:31:19,190
operator so you can change statement

00:31:17,450 --> 00:31:21,080
with comma you know all over again and

00:31:19,190 --> 00:31:22,940
all over again and so you will get your

00:31:21,080 --> 00:31:26,500
expression template growing up and

00:31:22,940 --> 00:31:34,850
choose our first actual semicolon well

00:31:26,500 --> 00:31:38,420
the bad news is it works but if you ever

00:31:34,850 --> 00:31:41,570
want to see a C++ symbol which name

00:31:38,420 --> 00:31:45,050
makes one megabyte of characters that's

00:31:41,570 --> 00:31:46,700
what you want to do okay so when we were

00:31:45,050 --> 00:31:48,500
comparing this kind of stuff with the

00:31:46,700 --> 00:31:50,570
beginning symbol inside I can tell you

00:31:48,500 --> 00:31:52,580
we can actually compile the code you

00:31:50,570 --> 00:31:56,240
know what eleven thirty something you

00:31:52,580 --> 00:32:00,380
know go to lunch at home cook something

00:31:56,240 --> 00:32:03,200
that could you know very comfy lunch and

00:32:00,380 --> 00:32:05,660
come back get a coffee and we probably

00:32:03,200 --> 00:32:07,760
not finished compiling yet okay around

00:32:05,660 --> 00:32:09,650
that two or something so it was not

00:32:07,760 --> 00:32:12,490
really practical and the other issue is

00:32:09,650 --> 00:32:13,940
that these tricks was using destructors

00:32:12,490 --> 00:32:15,980
to trigger

00:32:13,940 --> 00:32:18,110
evaluation of the statement because

00:32:15,980 --> 00:32:20,210
basically what happens that these commas

00:32:18,110 --> 00:32:23,120
sequence build the temporary objects

00:32:20,210 --> 00:32:24,890
containing all the expressions and the

00:32:23,120 --> 00:32:26,720
only way to force the iteration is to

00:32:24,890 --> 00:32:30,100
wait for this temporary object to be

00:32:26,720 --> 00:32:32,510
destroyed and we ever ate everything

00:32:30,100 --> 00:32:34,400
well except what happens if you are in

00:32:32,510 --> 00:32:36,560
the distributed systems and you want to

00:32:34,400 --> 00:32:39,320
catch an exception because some of our

00:32:36,560 --> 00:32:41,210
your notes just dropped and the system

00:32:39,320 --> 00:32:43,520
of transferring the data just raise an

00:32:41,210 --> 00:32:45,770
exception so you get an exception raised

00:32:43,520 --> 00:32:48,140
in the descriptors which probably means

00:32:45,770 --> 00:32:52,820
you'll never catch it okay so we ditched

00:32:48,140 --> 00:32:55,820
that those were issues and reasons and

00:32:52,820 --> 00:32:58,910
well we tell them to something else

00:32:55,820 --> 00:33:01,460
which makes more sense I will show you

00:32:58,910 --> 00:33:03,500
one solution there for the shared memory

00:33:01,460 --> 00:33:07,400
systems and we show another one to the

00:33:03,500 --> 00:33:11,240
example for the regular system so on on

00:33:07,400 --> 00:33:13,160
a mythical machine that say what we

00:33:11,240 --> 00:33:15,740
really want to do is enabling some kind

00:33:13,160 --> 00:33:17,750
of task pipelining between statements

00:33:15,740 --> 00:33:20,380
that's what we want to do okay and

00:33:17,750 --> 00:33:22,190
instead of doing like stupid guys okay

00:33:20,380 --> 00:33:24,470
let's do it

00:33:22,190 --> 00:33:26,360
so we added some more skeletons to

00:33:24,470 --> 00:33:29,539
actually express this notion of

00:33:26,360 --> 00:33:32,570
pipelining okay and we use futures so

00:33:29,539 --> 00:33:34,730
either from standards or from hpx to

00:33:32,570 --> 00:33:38,179
ultimately create a synchronous

00:33:34,730 --> 00:33:41,539
pipelines between statements and what we

00:33:38,179 --> 00:33:44,600
do is that we retake our iced tea okay

00:33:41,539 --> 00:33:46,460
so the IC goes this way and if you take

00:33:44,600 --> 00:33:49,129
you three and you put it on there and

00:33:46,460 --> 00:33:52,269
you go from up to down what you have

00:33:49,129 --> 00:33:56,299
your dependency graph between tasks done

00:33:52,269 --> 00:33:59,179
so what happens well remember that what

00:33:56,299 --> 00:34:02,389
we really want to do is put in TMP into

00:33:59,179 --> 00:34:05,179
a future fire that into some bunch of

00:34:02,389 --> 00:34:07,789
threads and then stop that and wait for

00:34:05,179 --> 00:34:09,470
Champy's they're put into a thread and

00:34:07,789 --> 00:34:11,869
probably go see what's the next

00:34:09,470 --> 00:34:13,790
statement is all about because I don't

00:34:11,869 --> 00:34:16,359
have to wait for this to be completed to

00:34:13,790 --> 00:34:18,589
go to the next line so I just

00:34:16,359 --> 00:34:22,280
synchronously go over all my expression

00:34:18,589 --> 00:34:25,220
template statement and fires futures for

00:34:22,280 --> 00:34:27,230
each part of them automatically directly

00:34:25,220 --> 00:34:30,369
from this expression template shares

00:34:27,230 --> 00:34:34,399
so this basically gets turned into that

00:34:30,369 --> 00:34:37,250
okay so we slice every loop nest of a

00:34:34,399 --> 00:34:42,260
different bunch of data block so we can

00:34:37,250 --> 00:34:45,349
have multiple grain size block over

00:34:42,260 --> 00:34:47,929
there and every staff there just fills

00:34:45,349 --> 00:34:50,510
these futures that get pipeline over

00:34:47,929 --> 00:34:53,179
there which in this case the same number

00:34:50,510 --> 00:34:55,220
of workers and what happened so it goes

00:34:53,179 --> 00:34:57,349
there extract this fill it into a

00:34:55,220 --> 00:34:59,030
futures like object that we judge

00:34:57,349 --> 00:35:02,240
generate all those workers walking on

00:34:59,030 --> 00:35:03,799
sub parts of the expressions and we

00:35:02,240 --> 00:35:05,540
forget about that and we go to the next

00:35:03,799 --> 00:35:07,880
one that just builds the same kind of

00:35:05,540 --> 00:35:10,190
walking elements waiting on these

00:35:07,880 --> 00:35:12,170
futures and then we go to the next

00:35:10,190 --> 00:35:14,470
statement user if there is any other

00:35:12,170 --> 00:35:17,270
statement and so on and so on and

00:35:14,470 --> 00:35:19,520
magically every futures with complete

00:35:17,270 --> 00:35:21,890
some point figure whatever is next and

00:35:19,520 --> 00:35:24,829
you will just primer down all your ice

00:35:21,890 --> 00:35:27,099
tea tree without having to know the

00:35:24,829 --> 00:35:30,559
sequence of them at compile time and

00:35:27,099 --> 00:35:32,240
actually it took us a long time to go

00:35:30,559 --> 00:35:34,369
there because we are quite certain that

00:35:32,240 --> 00:35:35,890
doing all of this at runtime will eat up

00:35:34,369 --> 00:35:39,079
all our speed-up

00:35:35,890 --> 00:35:41,300
because you know allocating bunch of

00:35:39,079 --> 00:35:45,290
workers in the vector firing you know

00:35:41,300 --> 00:35:47,270
futures and so on and actually well it

00:35:45,290 --> 00:35:49,940
was actually faster than ugly you know

00:35:47,270 --> 00:35:52,940
crow matrix so we forgot about the comma

00:35:49,940 --> 00:35:56,810
traits and give that and it's it's can

00:35:52,940 --> 00:35:58,400
actually very well because as long as

00:35:56,810 --> 00:36:00,349
you have I mean if you have a very long

00:35:58,400 --> 00:36:02,540
single element wise the expression not a

00:36:00,349 --> 00:36:04,310
problem you get a very nice deep tree

00:36:02,540 --> 00:36:07,849
that you would generate with people

00:36:04,310 --> 00:36:10,099
Walker for it and just wait for that

00:36:07,849 --> 00:36:13,670
okay and go to the next stuff you

00:36:10,099 --> 00:36:15,800
probably be non related to this guy so

00:36:13,670 --> 00:36:18,140
we will fire another bunch of futures

00:36:15,800 --> 00:36:21,020
and so on and so on and if you happens

00:36:18,140 --> 00:36:25,910
to find out something like a core B plus

00:36:21,020 --> 00:36:27,589
C Z equals 1 over a so all the

00:36:25,910 --> 00:36:32,089
expressions temperate system would just

00:36:27,589 --> 00:36:34,480
do the you're a equals and block okay

00:36:32,089 --> 00:36:38,089
and you will do so your Z equal

00:36:34,480 --> 00:36:40,280
rereading every parts of a and Block in

00:36:38,089 --> 00:36:42,920
this case well you slices I just have

00:36:40,280 --> 00:36:44,869
computing a fire futures go to the next

00:36:42,920 --> 00:36:45,470
stuff and just wait and so on and so on

00:36:44,869 --> 00:36:48,680
and so on

00:36:45,470 --> 00:36:51,890
so it just it just works actually that

00:36:48,680 --> 00:36:55,670
was the funny thing so some examples

00:36:51,890 --> 00:37:01,160
okay I've selected three very simple

00:36:55,670 --> 00:37:02,930
demo for different purposes this one is

00:37:01,160 --> 00:37:04,670
actually something we like very much

00:37:02,930 --> 00:37:07,310
because the algorithm is actually

00:37:04,670 --> 00:37:09,170
something that makes sense and it does a

00:37:07,310 --> 00:37:10,970
lot of changes so this is a motion

00:37:09,170 --> 00:37:13,520
detection algorithm using an algorithm

00:37:10,970 --> 00:37:16,329
called Sigma Delta which was proposed by

00:37:13,520 --> 00:37:19,310
like Assange and I forgot the other name

00:37:16,329 --> 00:37:21,800
and the idea is that when you do motion

00:37:19,310 --> 00:37:23,930
detection usually in imaging what you do

00:37:21,800 --> 00:37:27,290
is something rational name which says

00:37:23,930 --> 00:37:29,180
okay I have my frame coming at t1 and my

00:37:27,290 --> 00:37:33,230
next frame and I just drew a picture

00:37:29,180 --> 00:37:35,390
wise you know subtractions and I will

00:37:33,230 --> 00:37:38,089
just apply some threshold and whatever

00:37:35,390 --> 00:37:40,640
is above the threshold is moving but if

00:37:38,089 --> 00:37:42,530
you have an image where the contrast is

00:37:40,640 --> 00:37:44,869
very different in different part of the

00:37:42,530 --> 00:37:47,329
images we have enough time finding a

00:37:44,869 --> 00:37:49,070
proper specials that we get what you

00:37:47,329 --> 00:37:50,600
want okay

00:37:49,070 --> 00:37:54,350
so the Sigma Delta algorithm is very

00:37:50,600 --> 00:37:56,870
smart because it basically as a Gaussian

00:37:54,350 --> 00:37:59,390
model of the likeness on every pixels

00:37:56,870 --> 00:38:02,060
and whenever a pixels change is

00:37:59,390 --> 00:38:03,650
lightening a value for more than three

00:38:02,060 --> 00:38:06,710
times the Sigma of the distribution

00:38:03,650 --> 00:38:09,080
that's movement okay so basically you

00:38:06,710 --> 00:38:11,930
have tons of small Goshen's going on on

00:38:09,080 --> 00:38:14,090
every pixels it looks complicated and

00:38:11,930 --> 00:38:16,490
slow and actually when you look at the

00:38:14,090 --> 00:38:18,320
algorithm you can implement it with like

00:38:16,490 --> 00:38:21,560
addition subtraction and tests that's

00:38:18,320 --> 00:38:24,500
very impressive and it works with very

00:38:21,560 --> 00:38:26,600
very few operation it has very low

00:38:24,500 --> 00:38:30,620
arithmetic density and it's basically

00:38:26,600 --> 00:38:34,220
bound up by memory access and it usually

00:38:30,620 --> 00:38:38,240
used small integrals for implementation

00:38:34,220 --> 00:38:38,480
and so the challenge was all far can we

00:38:38,240 --> 00:38:41,180
go

00:38:38,480 --> 00:38:43,220
compare to the actual state of the

00:38:41,180 --> 00:38:46,640
atomization of this algorithm written by

00:38:43,220 --> 00:38:49,820
n in C so so the mg2 code is actually

00:38:46,640 --> 00:38:52,940
rather small so what do you get as an

00:38:49,820 --> 00:38:54,680
input is the background frame in which

00:38:52,940 --> 00:38:57,440
we will put all the pixels that doesn't

00:38:54,680 --> 00:39:00,080
move the actual new frame we want to

00:38:57,440 --> 00:39:00,830
process and the table containing the

00:39:00,080 --> 00:39:04,100
variance

00:39:00,830 --> 00:39:06,560
okay of the pixels and what you do is

00:39:04,100 --> 00:39:09,290
basically comparing the frame to the

00:39:06,560 --> 00:39:11,930
background and updating the background

00:39:09,290 --> 00:39:14,330
accordingly by either decrementing it or

00:39:11,930 --> 00:39:15,800
incrementing it traditionally you will

00:39:14,330 --> 00:39:18,080
compute the distance between the

00:39:15,800 --> 00:39:21,470
background ISM and so uh detect the

00:39:18,080 --> 00:39:24,290
frames you will compute the value of the

00:39:21,470 --> 00:39:25,370
local volunteers and depending if there

00:39:24,290 --> 00:39:27,950
is any difference

00:39:25,370 --> 00:39:30,880
okay well as though you have denser

00:39:27,950 --> 00:39:33,860
variance or you let it go like it is and

00:39:30,880 --> 00:39:37,310
where are the movement the movement are

00:39:33,860 --> 00:39:41,060
everywhere the difference images because

00:39:37,310 --> 00:39:46,850
on the variant done so only operation is

00:39:41,060 --> 00:39:50,180
that one two three four five six seven

00:39:46,850 --> 00:39:50,540
eight nine well twelve operations of me

00:39:50,180 --> 00:39:54,530
like that

00:39:50,540 --> 00:39:56,540
walking on child that's a very nice

00:39:54,530 --> 00:39:58,730
algorithms okay everything is completely

00:39:56,540 --> 00:40:02,309
parallel everywhere so it's trivial to

00:39:58,730 --> 00:40:03,930
impede it's trivial to implement

00:40:02,309 --> 00:40:06,089
assigned aversion of these algorithms

00:40:03,930 --> 00:40:08,759
that what's done to the reference paper

00:40:06,089 --> 00:40:11,249
we used okay so that's what we got as as

00:40:08,759 --> 00:40:14,130
performance so we confuse the number of

00:40:11,249 --> 00:40:17,609
CPU cycles we consume to compute one

00:40:14,130 --> 00:40:21,689
picture of the output okay so the color

00:40:17,609 --> 00:40:23,880
version returned in C okay with the

00:40:21,689 --> 00:40:26,640
latest version of GCC with all co2

00:40:23,880 --> 00:40:29,219
vectorizing or pushin on okay to have a

00:40:26,640 --> 00:40:32,489
fair comparisons give us something

00:40:29,219 --> 00:40:34,769
around 16 or 18 cycles per point okay

00:40:32,489 --> 00:40:37,229
for 512 squared

00:40:34,769 --> 00:40:41,549
images and that's it is the same speed

00:40:37,229 --> 00:40:43,619
for for the 1,000 by 1,000 so let's have

00:40:41,549 --> 00:40:45,749
a look at the what what is this color

00:40:43,619 --> 00:40:47,939
the blue curve yeah small light blue

00:40:45,749 --> 00:40:50,699
colors there so this is the actual

00:40:47,939 --> 00:40:52,890
reference performance from the original

00:40:50,699 --> 00:40:57,449
paper okay writing in C and whatever

00:40:52,890 --> 00:41:02,609
okay using using sse2 so you basically

00:40:57,449 --> 00:41:05,939
go from 1/16 to 1.5 1.6 that's time

00:41:02,609 --> 00:41:10,079
tense times video okay and so what do we

00:41:05,939 --> 00:41:12,359
do so we can actually use just a signle

00:41:10,079 --> 00:41:14,009
okay so you take your entry to code you

00:41:12,359 --> 00:41:18,809
saw there and you compile using manuals

00:41:14,009 --> 00:41:21,749
msse to just that and we got to a bit

00:41:18,809 --> 00:41:24,869
above - okay so we have a speed up of 7

00:41:21,749 --> 00:41:28,410
instead of 10 that's not bad

00:41:24,869 --> 00:41:31,259
all we can use menticles using OpenMP so

00:41:28,410 --> 00:41:34,920
this is a this is a photo machine yes so

00:41:31,259 --> 00:41:38,279
with 2 and 4 cause ok and we got pretty

00:41:34,920 --> 00:41:43,890
much what we expect to get okay and we

00:41:38,279 --> 00:41:47,609
can combine sine V + OpenMP so GCC my

00:41:43,890 --> 00:41:50,719
function dot cpp - msse - - f OpenMP

00:41:47,609 --> 00:41:55,769
done and we get bit more speed up so

00:41:50,719 --> 00:41:59,479
1516 and hard 1518 ok which is actually

00:41:55,769 --> 00:42:02,609
not three point six times 648 because

00:41:59,479 --> 00:42:04,859
around there at about one point eight

00:42:02,609 --> 00:42:07,499
cycle payment we just eat the memory

00:42:04,859 --> 00:42:09,779
buyers okay that's the time we spend

00:42:07,499 --> 00:42:13,439
just loading the values and with no way

00:42:09,779 --> 00:42:15,330
to go faster than that we're probably a

00:42:13,439 --> 00:42:18,300
bit much but not much

00:42:15,330 --> 00:42:19,950
than one cycle per elements so if we

00:42:18,300 --> 00:42:21,630
look at this side we have decent

00:42:19,950 --> 00:42:25,350
performance compared to the actual

00:42:21,630 --> 00:42:28,770
references okay so ten to seven that we

00:42:25,350 --> 00:42:31,650
with best in no efforts and when we

00:42:28,770 --> 00:42:34,260
combine with OpenMP will just continue I

00:42:31,650 --> 00:42:35,850
don't have the swag there don't know

00:42:34,260 --> 00:42:38,370
where they are but we just implemented

00:42:35,850 --> 00:42:42,330
the same algorithm using a B x2 which is

00:42:38,370 --> 00:42:44,940
supporting 32 wide register of

00:42:42,330 --> 00:42:49,320
engineered cars and we get to speed up

00:42:44,940 --> 00:42:52,350
our 127 and we didn't even touch the

00:42:49,320 --> 00:42:55,020
crow so we can actually go pretty far

00:42:52,350 --> 00:42:57,510
into you know being close to what you're

00:42:55,020 --> 00:43:00,360
an expert could have written by ends you

00:42:57,510 --> 00:43:01,740
know using whatever Trixie knew about so

00:43:00,360 --> 00:43:03,270
it doesn't have to use the tricks we

00:43:01,740 --> 00:43:05,640
know them in the library use them for

00:43:03,270 --> 00:43:08,480
you so another example which is

00:43:05,640 --> 00:43:10,800
completely different so the classical

00:43:08,480 --> 00:43:15,110
let's compute the black and Scholes call

00:43:10,800 --> 00:43:19,740
and input price okay using the classical

00:43:15,110 --> 00:43:21,270
implementation using nom CDF so I'm not

00:43:19,740 --> 00:43:23,760
completely not an expert into this

00:43:21,270 --> 00:43:25,530
algorithm so the birds goes in and the

00:43:23,760 --> 00:43:28,290
value goes out okay but don't ask me

00:43:25,530 --> 00:43:29,820
what's going on okay so only stuff I

00:43:28,290 --> 00:43:32,100
know is that it's very easy because you

00:43:29,820 --> 00:43:34,650
are blog and exponential and nom CDF

00:43:32,100 --> 00:43:37,620
which is basically polynomial polynomial

00:43:34,650 --> 00:43:40,980
approximation of the norm of the error

00:43:37,620 --> 00:43:44,010
function okay this probably eat herbs

00:43:40,980 --> 00:43:45,570
like 100 cycles for point alone okay so

00:43:44,010 --> 00:43:47,730
that's the way to do it so you have some

00:43:45,570 --> 00:43:49,860
intermediate table because we want to

00:43:47,730 --> 00:43:52,320
not be computing stuff too much okay and

00:43:49,860 --> 00:43:55,650
you just apply the function right and

00:43:52,320 --> 00:43:57,810
you look as a result of that we will see

00:43:55,650 --> 00:44:01,140
later that well it go faster but it's

00:43:57,810 --> 00:44:05,760
not very spectacular why well we have

00:44:01,140 --> 00:44:08,790
one two three four statements okay and

00:44:05,760 --> 00:44:10,410
every time as I say reduce voluminous

00:44:08,790 --> 00:44:15,350
and in also look net and another loop

00:44:10,410 --> 00:44:17,220
net so if you compare this code using

00:44:15,350 --> 00:44:19,380
share memory systems

00:44:17,220 --> 00:44:20,910
the futures systems will kick in and

00:44:19,380 --> 00:44:23,190
just do the right thing

00:44:20,910 --> 00:44:24,960
so now let's pretend you cannot run this

00:44:23,190 --> 00:44:27,930
on the mythical system for whatever

00:44:24,960 --> 00:44:29,160
reasons well you can manually actually

00:44:27,930 --> 00:44:32,400
apply loop fusion

00:44:29,160 --> 00:44:35,849
operation it's a quite simple way to do

00:44:32,400 --> 00:44:38,010
that so you will actually pre-allocate

00:44:35,849 --> 00:44:40,680
all the temporaries there and you will

00:44:38,010 --> 00:44:43,410
use a tie function that basically say

00:44:40,680 --> 00:44:45,809
okay guys I have all those four tables

00:44:43,410 --> 00:44:47,670
to fill in and this is the fourth

00:44:45,809 --> 00:44:50,010
statement you I want you to put inside

00:44:47,670 --> 00:44:51,630
this one into this one this one there

00:44:50,010 --> 00:44:55,020
this one there and this one there and

00:44:51,630 --> 00:44:58,650
this generates a single fat group nest

00:44:55,020 --> 00:45:00,390
in in which we will just evaluate every

00:44:58,650 --> 00:45:03,510
statement one after the other on the

00:45:00,390 --> 00:45:06,809
same point basically getting back to

00:45:03,510 --> 00:45:08,460
data low quality ends of performances so

00:45:06,809 --> 00:45:10,799
that's another way to solve this mystery

00:45:08,460 --> 00:45:12,539
statement problem sometimes you want to

00:45:10,799 --> 00:45:14,579
use it even if you have futures because

00:45:12,539 --> 00:45:17,430
for whatever reasons of the algorithms

00:45:14,579 --> 00:45:19,020
the future ization make the cash and

00:45:17,430 --> 00:45:22,920
happy for whatever reason and you want

00:45:19,020 --> 00:45:25,020
to do that so we just like that for the

00:45:22,920 --> 00:45:27,329
for the users so the funny thing is that

00:45:25,020 --> 00:45:29,549
yeah it looks like ty from from the

00:45:27,329 --> 00:45:31,380
topper library but not opera actually

00:45:29,549 --> 00:45:34,500
created okay

00:45:31,380 --> 00:45:36,210
this build an expression object that has

00:45:34,500 --> 00:45:37,680
a specialist in many operators that we

00:45:36,210 --> 00:45:40,260
just say how I should give me a tie

00:45:37,680 --> 00:45:42,059
there I would just take that and you

00:45:40,260 --> 00:45:45,029
know doozy do the zipping off everybody

00:45:42,059 --> 00:45:48,809
okay nothing actually leaks out of that

00:45:45,029 --> 00:45:52,109
so this is the speed-up you get when you

00:45:48,809 --> 00:45:54,930
do that stupidly okay so these

00:45:52,109 --> 00:45:58,200
calibrations again see optimized blah

00:45:54,930 --> 00:46:03,510
blah blah it's 150 some a bit less than

00:45:58,200 --> 00:46:10,289
150 the sse2 version is is rather bleak

00:46:03,510 --> 00:46:15,210
ok 1.89 AVX is not better with 2.9 okay

00:46:10,289 --> 00:46:18,210
and for the you know for the exercise

00:46:15,210 --> 00:46:20,010
which has disabled the utilization or

00:46:18,210 --> 00:46:23,549
using your planning piece there and got

00:46:20,010 --> 00:46:26,010
some speed up okay not much and now we

00:46:23,549 --> 00:46:32,839
put everything back and we used I would

00:46:26,010 --> 00:46:35,369
go basically twice faster okay well a

00:46:32,839 --> 00:46:38,279
bit less than twice faster for there but

00:46:35,369 --> 00:46:41,460
we basically it's a the limit there and

00:46:38,279 --> 00:46:42,870
we go up to 12 times faster when you use

00:46:41,460 --> 00:46:45,450
lex-2 and and the four

00:46:42,870 --> 00:46:50,220
machine so we can actually have this

00:46:45,450 --> 00:46:53,040
kind of control on the code you generate

00:46:50,220 --> 00:46:56,970
okay we are walking to have more options

00:46:53,040 --> 00:46:59,820
like you can actually specifies us this

00:46:56,970 --> 00:47:02,400
very statement has to be enrolled this

00:46:59,820 --> 00:47:04,890
much time if some conditions are met and

00:47:02,400 --> 00:47:07,470
so on and so on so you can basically

00:47:04,890 --> 00:47:10,950
write you can write your code nightly

00:47:07,470 --> 00:47:12,090
first okay just write the algorithm you

00:47:10,950 --> 00:47:13,920
look at the dependent you look at the

00:47:12,090 --> 00:47:16,710
performances and either everything works

00:47:13,920 --> 00:47:18,720
out of the box done and if not you can

00:47:16,710 --> 00:47:20,610
actually have a look at why it's exactly

00:47:18,720 --> 00:47:22,260
not delivering performances and we have

00:47:20,610 --> 00:47:24,630
all those small tools let's say for

00:47:22,260 --> 00:47:26,700
advanced users so you can actually can

00:47:24,630 --> 00:47:28,950
take back to control on on the generated

00:47:26,700 --> 00:47:30,390
code okay but it doesn't know what to do

00:47:28,950 --> 00:47:32,370
well send a problem if you just want to

00:47:30,390 --> 00:47:36,720
have something that run relatively fast

00:47:32,370 --> 00:47:39,150
just write it and it's done and another

00:47:36,720 --> 00:47:40,980
case where this fitter ization system is

00:47:39,150 --> 00:47:44,660
very cool is that we can actually take

00:47:40,980 --> 00:47:47,340
complex algorithm like Lu for example

00:47:44,660 --> 00:47:49,950
and turn it into a full-blown a

00:47:47,340 --> 00:47:51,960
synchronous algorithm so there is

00:47:49,950 --> 00:47:54,390
actually a way to make to write any

00:47:51,960 --> 00:47:56,640
decomposition in in the 'no synchronous

00:47:54,390 --> 00:47:58,590
way because you look at how the any of

00:47:56,640 --> 00:48:00,420
the competition walks so you solve a

00:47:58,590 --> 00:48:02,880
small system on the corner of the

00:48:00,420 --> 00:48:04,920
matches you will update the panel b

00:48:02,880 --> 00:48:07,350
below and the panel on the right and

00:48:04,920 --> 00:48:09,240
then go to the next diagonal block but

00:48:07,350 --> 00:48:12,030
the next diagonal block doesn't care if

00:48:09,240 --> 00:48:12,840
it was a pan-arab done yet so you can

00:48:12,030 --> 00:48:15,230
actually fires

00:48:12,840 --> 00:48:17,430
you have your critical paths along the

00:48:15,230 --> 00:48:19,560
diagonal and every other panels you

00:48:17,430 --> 00:48:25,190
don't give a crap so just put it into a

00:48:19,560 --> 00:48:28,350
future okay that's what this non-trivial

00:48:25,190 --> 00:48:30,750
jag haven't tried to tell you okay so

00:48:28,350 --> 00:48:34,980
you have basically four kernels or a

00:48:30,750 --> 00:48:36,570
triangular factorization I don't know

00:48:34,980 --> 00:48:38,850
what is that another kind of doing

00:48:36,570 --> 00:48:40,980
another stuff on some panels and also

00:48:38,850 --> 00:48:43,980
another factorization for the other

00:48:40,980 --> 00:48:46,320
panel and so on and you just go down

00:48:43,980 --> 00:48:49,170
this tree for every block in your

00:48:46,320 --> 00:48:51,210
matrixes and what does it give you so

00:48:49,170 --> 00:48:56,740
that's such a what we do with without

00:48:51,210 --> 00:48:59,500
mode okay so this is 8,000 by 8,000

00:48:56,740 --> 00:49:03,760
Trixie's dense and we apply this Lu

00:48:59,500 --> 00:49:07,180
decomposition on you between 1 and 48

00:49:03,760 --> 00:49:09,280
cause things of course am y'know so I

00:49:07,180 --> 00:49:14,619
don't know yeah so that's what I don't

00:49:09,280 --> 00:49:18,220
remember oh that's a name D machine ok

00:49:14,619 --> 00:49:21,040
so it was that and so actually the red

00:49:18,220 --> 00:49:23,350
stuff is in current care run on this so

00:49:21,040 --> 00:49:26,010
I probably suppose that it's not that

00:49:23,350 --> 00:49:29,050
great because it's a name D machine

00:49:26,010 --> 00:49:32,050
knowing in turn you know I hope there is

00:49:29,050 --> 00:49:34,960
no inter guy in the room no it's ok so

00:49:32,050 --> 00:49:39,610
in column Kansas machine caps up around

00:49:34,960 --> 00:49:44,770
the 95 98 gigaflops and we just climbed

00:49:39,610 --> 00:49:49,619
down up to 135 okay and the code to call

00:49:44,770 --> 00:49:49,619
that it just X equal nu of why don't I

00:49:52,800 --> 00:50:01,500
don't know I don't know where okay so

00:49:58,510 --> 00:50:04,600
this guy to me it's actually buried so

00:50:01,500 --> 00:50:06,490
I'm always worried about benchmark using

00:50:04,600 --> 00:50:09,790
interred tools on non Intel processors

00:50:06,490 --> 00:50:13,240
that's why but well anyway even if we

00:50:09,790 --> 00:50:15,130
stop there before these kruky behaviors

00:50:13,240 --> 00:50:16,570
we are basically in the same ballpark on

00:50:15,130 --> 00:50:19,990
M key okay

00:50:16,570 --> 00:50:22,600
and that's something we just do now on a

00:50:19,990 --> 00:50:24,630
lot of different lapack style algorithm

00:50:22,600 --> 00:50:27,850
we just turn them into some kind of

00:50:24,630 --> 00:50:31,480
future rise algorithms okay and well

00:50:27,850 --> 00:50:33,550
just walk out of the box so okay so we

00:50:31,480 --> 00:50:36,220
did all of that we got these tools so

00:50:33,550 --> 00:50:41,609
question is what did we learn of all of

00:50:36,220 --> 00:50:41,609
that okay what what a timing

00:50:42,510 --> 00:50:48,880
first some philosophical stance okay we

00:50:47,020 --> 00:50:51,130
think that building software libraries

00:50:48,880 --> 00:50:53,650
as as a generative systems that just

00:50:51,130 --> 00:50:55,330
rebuild itself is exactly what you want

00:50:53,650 --> 00:50:57,940
when you deal with parallelism for

00:50:55,330 --> 00:51:00,790
various reasons because other will

00:50:57,940 --> 00:51:03,430
change so much and you want to be able

00:51:00,790 --> 00:51:06,580
to regenerate whatever valent of your

00:51:03,430 --> 00:51:08,710
code and because at the user level you

00:51:06,580 --> 00:51:10,540
may have different you need a different

00:51:08,710 --> 00:51:13,240
time and you want to have some kind of

00:51:10,540 --> 00:51:15,520
adaptive to for doing this the other

00:51:13,240 --> 00:51:17,050
stuff we learn is that it's a very known

00:51:15,520 --> 00:51:18,580
random stuff that when you write your

00:51:17,050 --> 00:51:20,230
languages in the compiler if she doesn't

00:51:18,580 --> 00:51:22,230
have any architectural information

00:51:20,230 --> 00:51:26,170
you're generated code with yourselves

00:51:22,230 --> 00:51:28,240
fact is for de sel at the same point if

00:51:26,170 --> 00:51:31,180
you don't give your expression template

00:51:28,240 --> 00:51:32,830
or whatever DSL generate or codes so

00:51:31,180 --> 00:51:34,480
information about the target

00:51:32,830 --> 00:51:37,090
architectures well you will get blend

00:51:34,480 --> 00:51:38,620
code and blend performances the question

00:51:37,090 --> 00:51:41,530
was how to actually inject all those

00:51:38,620 --> 00:51:43,420
knowledge into the systems and by

00:51:41,530 --> 00:51:45,460
integrating this description into the

00:51:43,420 --> 00:51:47,710
generic and generative process just

00:51:45,460 --> 00:51:53,590
actually increase the to portability and

00:51:47,710 --> 00:51:56,230
and in performances but it's not for me

00:51:53,590 --> 00:51:58,450
it's not enough we need to formalize

00:51:56,230 --> 00:51:59,830
those generic and generative components

00:51:58,450 --> 00:52:01,660
with respect to pair resume and with

00:51:59,830 --> 00:52:05,650
respect to the languages and what I

00:52:01,660 --> 00:52:08,640
really want to do is turn all those big

00:52:05,650 --> 00:52:11,020
quote acts like expression templates

00:52:08,640 --> 00:52:12,910
program engineer jennifer mean using

00:52:11,020 --> 00:52:15,280
policies and thanks patching and

00:52:12,910 --> 00:52:17,980
whatever into some kind of factor

00:52:15,280 --> 00:52:20,320
language features because I think as

00:52:17,980 --> 00:52:23,160
users of C++ I should not have to write

00:52:20,320 --> 00:52:26,440
all those kruky damned complex voodoo

00:52:23,160 --> 00:52:28,870
C++ template magic to get that it should

00:52:26,440 --> 00:52:32,740
be like out of the box with using some

00:52:28,870 --> 00:52:35,140
kind of tools provided by the languages

00:52:32,740 --> 00:52:38,500
so currently what we try to do is

00:52:35,140 --> 00:52:40,570
looking at concept first the first idea

00:52:38,500 --> 00:52:43,360
is that instead of having a type based

00:52:40,570 --> 00:52:45,610
attack base or a system for saying ho

00:52:43,360 --> 00:52:48,910
guys this function is it's totally a

00:52:45,610 --> 00:52:51,580
reduction just that slice it just use

00:52:48,910 --> 00:52:54,520
concept of loading okay get your ice tea

00:52:51,580 --> 00:52:56,020
and help your I Steve models some kind

00:52:54,520 --> 00:52:58,420
of concept depending on what kind of

00:52:56,020 --> 00:53:00,490
fairy operation is being done and just

00:52:58,420 --> 00:53:02,950
use citrus press of concept overloading

00:53:00,490 --> 00:53:06,340
to slice the operation okay

00:53:02,950 --> 00:53:08,050
so unique stuff like is easy stuff that

00:53:06,340 --> 00:53:10,210
apparel ice-t is this operation

00:53:08,050 --> 00:53:11,980
associative is this something I can turn

00:53:10,210 --> 00:53:15,460
into a reduction and so on and so on and

00:53:11,980 --> 00:53:17,350
see how simply this one Y concept can

00:53:15,460 --> 00:53:21,310
able to do that that's something I want

00:53:17,350 --> 00:53:22,660
to try well that means that we could we

00:53:21,310 --> 00:53:23,859
could actually have a public interface

00:53:22,660 --> 00:53:25,480
for use

00:53:23,859 --> 00:53:28,119
said that when said users to write new

00:53:25,480 --> 00:53:30,039
skeletons into the systems gone instead

00:53:28,119 --> 00:53:32,380
of having to tell them oh yeah you have

00:53:30,039 --> 00:53:34,690
to add these 12 different types and

00:53:32,380 --> 00:53:37,599
these 12 dispatching stuff and probably

00:53:34,690 --> 00:53:38,950
these are fun read stuff so the system

00:53:37,599 --> 00:53:41,559
can actually know what you want to do

00:53:38,950 --> 00:53:44,470
well just model this concept and it will

00:53:41,559 --> 00:53:46,180
be done okay and concept refinement

00:53:44,470 --> 00:53:48,309
could actually help us extend to staff

00:53:46,180 --> 00:53:50,799
by for example learning okay I have a

00:53:48,309 --> 00:53:53,680
data parallel map like operation that

00:53:50,799 --> 00:53:55,380
can be refined in a inaudible data

00:53:53,680 --> 00:53:58,119
parallel operation and so on and so on

00:53:55,380 --> 00:53:59,799
and we can actually use that research on

00:53:58,119 --> 00:54:03,099
function properties so you can actually

00:53:59,799 --> 00:54:05,829
have well decent temperature or messages

00:54:03,099 --> 00:54:08,529
okay which is the main issues with this

00:54:05,829 --> 00:54:12,489
kind of techniques if you are into

00:54:08,529 --> 00:54:14,499
gigabyte sighs you know log of arrows

00:54:12,489 --> 00:54:17,529
from GCC well don't change anything

00:54:14,499 --> 00:54:20,140
okay but I heard and some of our key and

00:54:17,529 --> 00:54:21,489
say to us that well it could be good if

00:54:20,140 --> 00:54:24,069
you could actually have meaningful

00:54:21,489 --> 00:54:27,210
message that doesn't you know fill the

00:54:24,069 --> 00:54:32,319
screen before for five minutes okay so

00:54:27,210 --> 00:54:33,519
well could be great if okay I can

00:54:32,319 --> 00:54:36,430
actually have some kind of resolution

00:54:33,519 --> 00:54:40,059
system directly into the languages okay

00:54:36,430 --> 00:54:42,339
and so I can directly interact with the

00:54:40,059 --> 00:54:46,259
with the iced-tea representation of some

00:54:42,339 --> 00:54:50,609
statement and do stuff with it okay and

00:54:46,259 --> 00:54:55,349
we also think that assign the operation

00:54:50,609 --> 00:54:59,410
we are in 2014 okay s IDs out since what

00:54:55,349 --> 00:55:03,190
1993 something that's how many times 20

00:54:59,410 --> 00:55:04,930
years now could be damn cool if it will

00:55:03,190 --> 00:55:08,019
be like in the standard two because like

00:55:04,930 --> 00:55:11,499
well everybody used it okay everybody

00:55:08,019 --> 00:55:16,690
should be using it so well while walking

00:55:11,499 --> 00:55:19,210
on that actually could we have some kind

00:55:16,690 --> 00:55:21,099
of ice-t of operation that just give it

00:55:19,210 --> 00:55:23,230
a statement you give you some kind of

00:55:21,099 --> 00:55:24,789
standardized expression tree and you

00:55:23,230 --> 00:55:30,059
walk with that and done okay

00:55:24,789 --> 00:55:32,859
instead of having true oops so I

00:55:30,059 --> 00:55:34,599
completely that when you use stuff like

00:55:32,859 --> 00:55:37,520
booze for the war on an N made

00:55:34,599 --> 00:55:39,890
expression template systems so

00:55:37,520 --> 00:55:42,890
fire actually combines the ice-t of one

00:55:39,890 --> 00:55:44,240
statement five times it's the first time

00:55:42,890 --> 00:55:46,370
because you have to don't know what's

00:55:44,240 --> 00:55:48,350
going on and then it has to regenerate

00:55:46,370 --> 00:55:50,330
the type inside the expression template

00:55:48,350 --> 00:55:52,100
type systems and then you'd have to pass

00:55:50,330 --> 00:55:54,110
that again to know what's going on into

00:55:52,100 --> 00:55:56,780
each parts and then again when you

00:55:54,110 --> 00:55:59,330
generate a new code that's a bit much

00:55:56,780 --> 00:56:02,540
okay so can we have some kind of either

00:55:59,330 --> 00:56:06,200
ice-t of operator or or meter types

00:56:02,540 --> 00:56:08,390
keywords that you can say Oh F of meta T

00:56:06,200 --> 00:56:09,740
I don't want to value I want the ice-t

00:56:08,390 --> 00:56:11,620
of whatever you pass to me and I will

00:56:09,740 --> 00:56:13,670
deal with it inside something like this

00:56:11,620 --> 00:56:17,300
the main issue is that we probably

00:56:13,670 --> 00:56:18,950
requires vendors to agree on on an

00:56:17,300 --> 00:56:22,490
intermediate representation of the ice

00:56:18,950 --> 00:56:24,710
tea which may be problematic especially

00:56:22,490 --> 00:56:26,870
on some companions which I won't name

00:56:24,710 --> 00:56:28,990
that doesn't even have ice tea in the

00:56:26,870 --> 00:56:33,460
first place

00:56:28,990 --> 00:56:36,830
yep I would let you guess which one

00:56:33,460 --> 00:56:40,130
another problem with extraction template

00:56:36,830 --> 00:56:42,680
is okay fine I can write a equal B plus

00:56:40,130 --> 00:56:45,590
C and something magic happens okay and

00:56:42,680 --> 00:56:48,770
I'm walking with C++ 11 so what about

00:56:45,590 --> 00:56:51,260
writing Auto a equal b / c question

00:56:48,770 --> 00:56:52,850
what's the type of a if b and c is

00:56:51,260 --> 00:56:55,730
captured by an expression template

00:56:52,850 --> 00:56:58,250
system well it would be some kind of

00:56:55,730 --> 00:56:59,960
early as type okay and probably not the

00:56:58,250 --> 00:57:03,500
matrix or a string or whatever types you

00:56:59,960 --> 00:57:05,540
want it to be so what you may want is a

00:57:03,500 --> 00:57:08,390
way to say yeah you know this auto

00:57:05,540 --> 00:57:10,040
operations there in fact that's not what

00:57:08,390 --> 00:57:13,750
i want i want to whatever and the

00:57:10,040 --> 00:57:16,460
writing types of my expression so we

00:57:13,750 --> 00:57:18,410
want a proposal for that with better

00:57:16,460 --> 00:57:20,530
Gosling in the episode ER I'm not sure

00:57:18,410 --> 00:57:23,630
the number is right probably this one

00:57:20,530 --> 00:57:25,880
yes about having a customization point

00:57:23,630 --> 00:57:27,950
for operator auto so you can say oh I

00:57:25,880 --> 00:57:32,030
have a type and when you do auto on this

00:57:27,950 --> 00:57:34,250
type actually it's this other type okay

00:57:32,030 --> 00:57:37,460
it looks quite a dock for these issues

00:57:34,250 --> 00:57:40,400
but actually also simplifies the ending

00:57:37,460 --> 00:57:43,970
of all kind of proxy types you have a

00:57:40,400 --> 00:57:46,010
wrapper or something okay and whenever

00:57:43,970 --> 00:57:47,750
you you compute a wrapper or something

00:57:46,010 --> 00:57:49,430
you and you really want to put it into

00:57:47,750 --> 00:57:51,170
something and you want it to do that

00:57:49,430 --> 00:57:53,780
using auto it will become

00:57:51,170 --> 00:57:56,390
is complicated so you can have rapper

00:57:53,780 --> 00:57:59,390
types changes using auto record whatever

00:57:56,390 --> 00:58:01,609
and get whatever type you want we also

00:57:59,390 --> 00:58:03,619
try to get a simply commutation to the

00:58:01,609 --> 00:58:07,790
standards that's pretty much bought for

00:58:03,619 --> 00:58:10,990
different reasons I'm quoting the end

00:58:07,790 --> 00:58:13,270
document just for historical you know

00:58:10,990 --> 00:58:15,829
references

00:58:13,270 --> 00:58:19,819
we probably try to get that back again

00:58:15,829 --> 00:58:23,540
but well it meets some kind of

00:58:19,819 --> 00:58:25,309
resistance for whatever reason but yeah

00:58:23,540 --> 00:58:27,020
so we try to actually put stuff you know

00:58:25,309 --> 00:58:28,430
back into the languages so we can

00:58:27,020 --> 00:58:30,650
actually brought all of that without

00:58:28,430 --> 00:58:33,049
having to spend you know too much time

00:58:30,650 --> 00:58:36,290
pulling out our hair from our head and

00:58:33,049 --> 00:58:39,380
and they begin megabytes of error

00:58:36,290 --> 00:58:42,890
messages so I think that's pretty much

00:58:39,380 --> 00:58:45,109
done so just some stuff we're working on

00:58:42,890 --> 00:58:47,150
the two-level so we have this prototype

00:58:45,109 --> 00:58:48,770
for a single sole GPU support so you

00:58:47,150 --> 00:58:52,640
basically write would call you the NT to

00:58:48,770 --> 00:58:54,500
in the CPP file you can file with the

00:58:52,640 --> 00:58:56,930
proper option to say yeah I want that to

00:58:54,500 --> 00:58:58,940
be on GPU and we will derive the correct

00:58:56,930 --> 00:59:01,700
could open share colonel directly from

00:58:58,940 --> 00:59:04,690
the ISD inside the C++ code so it

00:59:01,700 --> 00:59:07,280
doesn't even right up to right critical

00:59:04,690 --> 00:59:10,130
we have a PhD students or - I don't

00:59:07,280 --> 00:59:12,500
remember one that work on this routed

00:59:10,130 --> 00:59:17,260
system so we can actually support large

00:59:12,500 --> 00:59:20,510
clusters funnily enough it's quite

00:59:17,260 --> 00:59:23,180
similar to supporting GPU because

00:59:20,510 --> 00:59:24,890
actually GPU just disputed system which

00:59:23,180 --> 00:59:26,750
is very close to your PC but it's

00:59:24,890 --> 00:59:30,140
something else with his own memory

00:59:26,750 --> 00:59:32,839
you know unit and we start to add

00:59:30,140 --> 00:59:35,390
application - yeah big data data science

00:59:32,839 --> 00:59:39,099
in general and try to get meaningful

00:59:35,390 --> 00:59:41,150
algorithm for this type of application

00:59:39,099 --> 00:59:43,609
and what we want to do at the language

00:59:41,150 --> 00:59:45,650
level so in addition to whatever I just

00:59:43,609 --> 00:59:48,650
talked about is actually have a way to

00:59:45,650 --> 00:59:50,240
formalize meter programming so we

00:59:48,650 --> 00:59:52,280
stopped looking like a bunch of ugly

00:59:50,240 --> 00:59:54,410
acts okay

00:59:52,280 --> 00:59:57,470
another funky stuff which is more

00:59:54,410 --> 01:00:00,049
theoretical is you have some time you

00:59:57,470 --> 01:00:02,030
are you have a DSL for very specific you

01:00:00,049 --> 01:00:04,160
know domain and people actually

01:00:02,030 --> 01:00:04,910
demonstrate and certify this language to

01:00:04,160 --> 01:00:08,060
be

01:00:04,910 --> 01:00:10,010
correct okay question is is the

01:00:08,060 --> 01:00:13,700
correctness of a bunch of program

01:00:10,010 --> 01:00:15,770
returning the given DSL transfer to the

01:00:13,700 --> 01:00:17,570
implementation using C++ and expression

01:00:15,770 --> 01:00:20,000
templates do we conserve whatever

01:00:17,570 --> 01:00:21,170
properties the original language as that

01:00:20,000 --> 01:00:23,210
could be cool because you could actually

01:00:21,170 --> 01:00:24,620
have a certified language for whatever I

01:00:23,210 --> 01:00:27,050
don't know

01:00:24,620 --> 01:00:28,730
I run nothing so whatever and you turn

01:00:27,050 --> 01:00:31,070
it into a very efficient implementation

01:00:28,730 --> 01:00:33,440
using C++ and you can still say to your

01:00:31,070 --> 01:00:37,010
boss yes it's certified because this is

01:00:33,440 --> 01:00:39,590
a proof and how many of you know about

01:00:37,010 --> 01:00:42,530
poor yellow model I should have known

01:00:39,590 --> 01:00:45,770
that the older model is a very

01:00:42,530 --> 01:00:48,710
interesting model for model modeling a

01:00:45,770 --> 01:00:50,810
loop nest so the gist is that if you

01:00:48,710 --> 01:00:52,880
have a loop nest and you look at the

01:00:50,810 --> 01:00:54,290
boundaries okay and you have a multiple

01:00:52,880 --> 01:00:56,510
dimension loop nest you look at all the

01:00:54,290 --> 01:00:58,400
boundaries and you basically draw up or

01:00:56,510 --> 01:01:01,790
you'll run into so many dimensional

01:00:58,400 --> 01:01:03,380
space okay and the cool polyhedron in

01:01:01,790 --> 01:01:05,450
this model are the ones that just looks

01:01:03,380 --> 01:01:08,000
like a big cube or rectangles because

01:01:05,450 --> 01:01:09,470
you can just slice it okay and the way

01:01:08,000 --> 01:01:12,620
you slice it is the way you will make it

01:01:09,470 --> 01:01:14,540
parallel okay but sometimes your memory

01:01:12,620 --> 01:01:17,560
access pattern is more complex and your

01:01:14,540 --> 01:01:20,210
polyhedron is just some odd shape and

01:01:17,560 --> 01:01:23,210
the game is to say okay let's take this

01:01:20,210 --> 01:01:25,070
strange geometry turn it into a

01:01:23,210 --> 01:01:28,010
rectangle and slice it and regenerate

01:01:25,070 --> 01:01:30,080
code so this is very interesting because

01:01:28,010 --> 01:01:31,970
you can actually formalize a lot of code

01:01:30,080 --> 01:01:34,520
transformation like loop unrolling loop

01:01:31,970 --> 01:01:37,340
peeling paralyzation into this model and

01:01:34,520 --> 01:01:39,680
it's an actual mathematical model of

01:01:37,340 --> 01:01:41,090
your loop nest so the idea is that can

01:01:39,680 --> 01:01:43,460
we actually meet a program this kind of

01:01:41,090 --> 01:01:46,220
stuff directly so we just looked at the

01:01:43,460 --> 01:01:47,570
expression builds a polyhedron a private

01:01:46,220 --> 01:01:50,470
transformation donate before generating

01:01:47,570 --> 01:01:53,030
the code instead to have tons of ad hoc

01:01:50,470 --> 01:01:55,820
optimizer for unrolling and for loops

01:01:53,030 --> 01:01:59,210
fitting and Oliver so I think that's all

01:01:55,820 --> 01:02:00,890
we actually have available on github if

01:01:59,210 --> 01:02:03,170
you want to play with it and if you have

01:02:00,890 --> 01:02:07,190
a couple dozen minutes to compile some

01:02:03,170 --> 01:02:09,200
example if you actually use that feel

01:02:07,190 --> 01:02:10,840
free to you know send us back report and

01:02:09,200 --> 01:02:13,820
whatever

01:02:10,840 --> 01:02:16,730
nope

01:02:13,820 --> 01:02:18,950
I know it still for whatever it is very

01:02:16,730 --> 01:02:20,750
it's a permissive completely non-trivial

01:02:18,950 --> 01:02:23,900
to changing or not only should name on

01:02:20,750 --> 01:02:25,430
github so don't ask me okay yeah so

01:02:23,900 --> 01:02:27,800
everything is there we have some issues

01:02:25,430 --> 01:02:30,770
Packer don't don't hesitate to a pingas

01:02:27,800 --> 01:02:33,950
if you have in issues if you are exotic

01:02:30,770 --> 01:02:38,750
systems we are pretty much also a p2 of

01:02:33,950 --> 01:02:40,820
return of experimental yes and we're

01:02:38,750 --> 01:02:43,160
pretty much happy to have any kind of

01:02:40,820 --> 01:02:46,640
eternal design of tools and try to make

01:02:43,160 --> 01:02:47,990
it better for waivers so thank you and

01:02:46,640 --> 01:03:01,790
thank for your attention if there is any

01:02:47,990 --> 01:03:04,310
question okay I have a question you have

01:03:01,790 --> 01:03:06,620
a question I do so what are you

01:03:04,310 --> 01:03:09,110
envisioning for changes and

01:03:06,620 --> 01:03:12,680
metaprogramming things up that would

01:03:09,110 --> 01:03:14,090
make you happy and that would would be

01:03:12,680 --> 01:03:16,570
something that would even be viable for

01:03:14,090 --> 01:03:16,570
the language

01:03:16,600 --> 01:03:27,080
once we a see what once should I repeat

01:03:20,150 --> 01:03:31,960
oh okay so what could make me happy in

01:03:27,080 --> 01:03:36,050
term of meta programming well two things

01:03:31,960 --> 01:03:37,520
first thing is that the separation

01:03:36,050 --> 01:03:40,340
between the compile time in the runtime

01:03:37,520 --> 01:03:43,670
world is a big awkward due to the

01:03:40,340 --> 01:03:46,670
temperate syntax okay one stuff which is

01:03:43,670 --> 01:03:48,950
very interesting is the way we solved a

01:03:46,670 --> 01:03:50,510
bunch of this problem because actually

01:03:48,950 --> 01:03:52,850
we use template for doing two things in

01:03:50,510 --> 01:03:55,280
C++ where we should we should have two

01:03:52,850 --> 01:03:57,380
different mechanisms so we use it for

01:03:55,280 --> 01:04:00,200
generic function and class definition

01:03:57,380 --> 01:04:03,380
okay and we use it for doing type

01:04:00,200 --> 01:04:05,240
introspection basically in these that's

01:04:03,380 --> 01:04:07,910
two different stuff so you have generics

01:04:05,240 --> 01:04:09,920
and you have mixing and what we probably

01:04:07,910 --> 01:04:11,570
need is whenever I do generally

01:04:09,920 --> 01:04:17,840
programming I'm just building a bunch of

01:04:11,570 --> 01:04:21,200
mixing and mixing them okay well so what

01:04:17,840 --> 01:04:24,800
the first thing should be split that as

01:04:21,200 --> 01:04:27,200
a template legacy syntax be generic you

01:04:24,800 --> 01:04:29,000
know way of specifying things

01:04:27,200 --> 01:04:31,130
have something to say a this is a called

01:04:29,000 --> 01:04:33,530
fragment I want you to carry around and

01:04:31,130 --> 01:04:36,109
apply whenever I fit it which is the

01:04:33,530 --> 01:04:38,060
case for example in meteor panel or

01:04:36,109 --> 01:04:39,980
template a skill you have a notion you

01:04:38,060 --> 01:04:42,380
have a type code fragment of something

01:04:39,980 --> 01:04:44,300
and you can just build those code

01:04:42,380 --> 01:04:45,650
fragment from regular expression and you

01:04:44,300 --> 01:04:47,660
just carry it around and you have an

01:04:45,650 --> 01:04:50,270
operator for saying okay I want to

01:04:47,660 --> 01:04:51,980
concatenate two code fragment or I want

01:04:50,270 --> 01:04:54,829
to evaluate the code fragment to actual

01:04:51,980 --> 01:04:59,810
code so that could be a nice thing and

01:04:54,829 --> 01:05:03,020
the second thing is that again on this

01:04:59,810 --> 01:05:05,270
compile time runtime frontier sometimes

01:05:03,020 --> 01:05:07,250
you just want to have you have some

01:05:05,270 --> 01:05:10,220
constants lying around in the runtime

01:05:07,250 --> 01:05:11,900
world and you will be very happy if you

01:05:10,220 --> 01:05:14,300
could actually propagate it into the

01:05:11,900 --> 01:05:17,020
compile time world because I don't see

01:05:14,300 --> 01:05:19,730
why when I write code which is f of 1

01:05:17,020 --> 01:05:23,390
literally I have no way to know that

01:05:19,730 --> 01:05:25,250
statically it's a 1 I should be able to

01:05:23,390 --> 01:05:26,780
do that because it's really statically

01:05:25,250 --> 01:05:28,970
one I want to know it into the other

01:05:26,780 --> 01:05:31,160
side and know statically to one and

01:05:28,970 --> 01:05:35,210
apply whatever stuff I need to that

01:05:31,160 --> 01:05:36,950
that's more complex but already by

01:05:35,210 --> 01:05:39,140
splitting the way that we use the same

01:05:36,950 --> 01:05:42,020
freaking syntax for generic functions

01:05:39,140 --> 01:05:44,660
and code generation introspections could

01:05:42,020 --> 01:05:47,359
clear up a lot of things as means we

01:05:44,660 --> 01:05:49,220
could have stuff like D like yeah as it

01:05:47,359 --> 01:05:53,230
actually has a static if and the static

01:05:49,220 --> 01:05:56,270
for construct that you can actually

01:05:53,230 --> 01:05:58,400
contract into our you know add something

01:05:56,270 --> 01:06:00,079
so you can write at if something the

01:05:58,400 --> 01:06:02,390
blah blah and if everything is constant

01:06:00,079 --> 01:06:04,849
into the F well you basically brought

01:06:02,390 --> 01:06:06,950
something like a CD conditional blah

01:06:04,849 --> 01:06:09,349
blah blah except you've wrote an if so

01:06:06,950 --> 01:06:11,180
the semantics is more clear it's the

01:06:09,349 --> 01:06:14,180
same set of keywords the same set of

01:06:11,180 --> 01:06:16,910
controls total of controls except the

01:06:14,180 --> 01:06:19,280
add just turn it into a static stuff so

01:06:16,910 --> 01:06:21,770
I don't have to write a few functional

01:06:19,280 --> 01:06:24,109
recursive bunch of code to do my loop

01:06:21,770 --> 01:06:26,510
unrolling I just write ad for something

01:06:24,109 --> 01:06:29,060
a bunch of code and the code yet in row

01:06:26,510 --> 01:06:30,890
but you cannot do that if you have to be

01:06:29,060 --> 01:06:33,230
compatible with the old way template was

01:06:30,890 --> 01:06:34,970
we have to split that you have templates

01:06:33,230 --> 01:06:37,700
for generosity and you have this code

01:06:34,970 --> 01:06:41,300
fragment notion is that I think the

01:06:37,700 --> 01:06:43,400
biggest stuff we need to do slice around

01:06:41,300 --> 01:06:48,950
and the third point that was the two

01:06:43,400 --> 01:06:52,760
first is my wish is that the reflection

01:06:48,950 --> 01:06:54,590
walking group actually start to look at

01:06:52,760 --> 01:06:57,080
arbitrary code fragment instead of

01:06:54,590 --> 01:07:00,170
values and types so I can actually ask

01:06:57,080 --> 01:07:02,240
you know introspection about okay I have

01:07:00,170 --> 01:07:04,760
this expression lying around how many I

01:07:02,240 --> 01:07:07,040
mean how many technology inside or how

01:07:04,760 --> 01:07:09,740
many times do I cross a plus operator in

01:07:07,040 --> 01:07:11,420
this statement because actually I mean

01:07:09,740 --> 01:07:12,770
if you have information and types and

01:07:11,420 --> 01:07:14,480
then value the next step is that you

01:07:12,770 --> 01:07:17,630
have an introspection on arbitrary

01:07:14,480 --> 01:07:19,670
statement and I don't think there is

01:07:17,630 --> 01:07:21,890
much of status in writing this into a

01:07:19,670 --> 01:07:24,170
compiler I mean it's not trivial but

01:07:21,890 --> 01:07:26,600
everything is there already so you can

01:07:24,170 --> 01:07:28,820
actually just ask that in proper syntax

01:07:26,600 --> 01:07:30,770
and cover that with the fact you said

01:07:28,820 --> 01:07:31,990
when you speak template into and you

01:07:30,770 --> 01:07:36,740
probably have something which is saying

01:07:31,990 --> 01:07:38,780
for for historical reports the first

01:07:36,740 --> 01:07:43,630
version of that was written in tablet

01:07:38,780 --> 01:07:46,190
Haskell and it was probably like a

01:07:43,630 --> 01:07:48,830
artful sort of the size for the same

01:07:46,190 --> 01:07:53,660
amount of you know ability of building

01:07:48,830 --> 01:07:56,680
blocks and whatever so the main obstacle

01:07:53,660 --> 01:07:59,090
is actually having enough people

01:07:56,680 --> 01:08:01,390
championing this idea that it's actually

01:07:59,090 --> 01:08:04,550
useful and not you know some kind of

01:08:01,390 --> 01:08:06,680
Voodoo style act some guys somewhere

01:08:04,550 --> 01:08:09,550
actually use for whatever reasons

01:08:06,680 --> 01:08:12,140
instead of doing normal T purpose and

01:08:09,550 --> 01:08:18,980
that's probably the main issues to get

01:08:12,140 --> 01:08:20,509
it through yes

01:08:18,980 --> 01:08:25,430
are you familiar with the Julian

01:08:20,509 --> 01:08:28,400
language yes okay yes because it's a

01:08:25,430 --> 01:08:31,580
question a lot of well there's a lot of

01:08:28,400 --> 01:08:34,790
your ideas of how to approve C++ sound

01:08:31,580 --> 01:08:36,529
like Julia yeah so the main program in

01:08:34,790 --> 01:08:37,940
Julia is that when you go to a client

01:08:36,529 --> 01:08:40,970
say oh yeah you know you couldn't do

01:08:37,940 --> 01:08:42,710
that injury as a guy like in what so the

01:08:40,970 --> 01:08:46,009
day it's actually have you know I mean

01:08:42,710 --> 01:08:49,160
it's like D I wish I can do that Indian

01:08:46,009 --> 01:08:51,170
still selling stuff to clients so the ID

01:08:49,160 --> 01:08:53,000
or Julia or whatever next level

01:08:51,170 --> 01:08:54,680
languages actually get fruit into the

01:08:53,000 --> 01:08:54,859
industries and people start using it in

01:08:54,680 --> 01:08:56,719
too

01:08:54,859 --> 01:08:57,949
your context I will take that and just

01:08:56,719 --> 01:09:00,440
flush it down the drain

01:08:57,949 --> 01:09:03,889
okay and rewrite it into a proper

01:09:00,440 --> 01:09:05,420
languages that I mean that's for

01:09:03,889 --> 01:09:07,460
practical reason we still doing just

01:09:05,420 --> 01:09:09,319
with you prosperous but at some point we

01:09:07,460 --> 01:09:12,469
have to go to people that I mean you

01:09:09,319 --> 01:09:15,049
know already changing from C to C press

01:09:12,469 --> 01:09:16,730
press was almost traumatism so if you

01:09:15,049 --> 01:09:20,029
want them to go elsewhere you know you

01:09:16,730 --> 01:09:30,259
know it won't fly so Bryce you had a

01:09:20,029 --> 01:09:32,139
question so the question is people are

01:09:30,259 --> 01:09:35,060
saying is that who you are as I write

01:09:32,139 --> 01:09:36,770
yes I think they are right but the

01:09:35,060 --> 01:09:41,150
problem is that you shouldn't be that

01:09:36,770 --> 01:09:43,279
much as so to do that for me Z so use

01:09:41,150 --> 01:09:46,100
case of this and the result we can get

01:09:43,279 --> 01:09:48,049
with that are meaningful enough to say

01:09:46,100 --> 01:09:51,139
okay guys we should make something so

01:09:48,049 --> 01:09:53,540
all of these crap could be written like

01:09:51,139 --> 01:09:56,270
no less crappy way without having you

01:09:53,540 --> 01:09:58,070
know requiring you to be some kind of I

01:09:56,270 --> 01:10:01,670
don't know aliens from the planet Zagreb

01:09:58,070 --> 01:10:03,199
or whatever so but again that goes with

01:10:01,670 --> 01:10:04,909
the first point we we need to have

01:10:03,199 --> 01:10:07,130
traction to make people from the

01:10:04,909 --> 01:10:09,199
community or every people around

01:10:07,130 --> 01:10:10,580
understand that that is not just some

01:10:09,199 --> 01:10:14,719
kind of playground stuff and you can

01:10:10,580 --> 01:10:17,840
actually make you know meaningful result

01:10:14,719 --> 01:10:18,980
with that so I mean to me one of the

01:10:17,840 --> 01:10:20,389
arguments to make if you look at a

01:10:18,980 --> 01:10:21,920
language like Fortran which I would

01:10:20,389 --> 01:10:23,900
argue in terms of high performance

01:10:21,920 --> 01:10:26,659
languages for doing numerical stuff

01:10:23,900 --> 01:10:28,190
whose the competitor Fortran who has all

01:10:26,659 --> 01:10:30,619
these cool features which let you do

01:10:28,190 --> 01:10:32,570
this sort of like built into the

01:10:30,619 --> 01:10:36,409
language this support for doing this

01:10:32,570 --> 01:10:38,510
stuff with arrays Fortran and if we sure

01:10:36,409 --> 01:10:41,360
we could add that stuff to C++ you know

01:10:38,510 --> 01:10:43,580
sort of the language of all craziness

01:10:41,360 --> 01:10:48,130
prefer arrays or we could add the tools

01:10:43,580 --> 01:10:51,560
to be able to build you know property s

01:10:48,130 --> 01:10:53,540
the thing is that applying that to a

01:10:51,560 --> 01:10:55,940
rebase competition you just and most

01:10:53,540 --> 01:10:58,130
trivial example you can write I mean you

01:10:55,940 --> 01:11:01,460
can you think take that and I don't know

01:10:58,130 --> 01:11:06,349
I mean I mean converting out the Fortran

01:11:01,460 --> 01:11:08,000
it's I mean that's what train yes and

01:11:06,349 --> 01:11:08,630
one of the reason that Fortran code is

01:11:08,000 --> 01:11:10,130
actually fast

01:11:08,630 --> 01:11:11,330
it's not because it's fall trend because

01:11:10,130 --> 01:11:13,639
at the end of the day it's a compiler

01:11:11,330 --> 01:11:16,070
generating as many languages is because

01:11:13,639 --> 01:11:17,810
the first rule of Fortran is you have no

01:11:16,070 --> 01:11:20,840
freaking areas between a race of

01:11:17,810 --> 01:11:22,760
different name per yawns and so you can

01:11:20,840 --> 01:11:24,710
be aggressive on the optimization and

01:11:22,760 --> 01:11:27,440
that's basically what we emulate there

01:11:24,710 --> 01:11:29,389
right we fall so the compiler to know

01:11:27,440 --> 01:11:30,739
about ok it's a it's an array no cell

01:11:29,389 --> 01:11:32,360
you see let me do what I know to do

01:11:30,739 --> 01:11:34,969
because that's probably best for to what

01:11:32,360 --> 01:11:38,179
we want try to be doing so I mean I

01:11:34,969 --> 01:11:41,389
think the argument is to be made is you

01:11:38,179 --> 01:11:44,210
know it really does and it yes maybe

01:11:41,389 --> 01:11:45,770
it's voodoo but it C++ is a multi

01:11:44,210 --> 01:11:48,020
program multi-paradigm programming

01:11:45,770 --> 01:11:49,760
language well it will enable more

01:11:48,020 --> 01:11:52,280
parallel what I fear will be the answer

01:11:49,760 --> 01:11:55,940
is that yeah but that's implementation

01:11:52,280 --> 01:11:58,159
qoi details so we don't give a crap just

01:11:55,940 --> 01:12:01,550
use battery I get a question about the

01:11:58,159 --> 01:12:03,920
whole sim D in the standard thing is an

01:12:01,550 --> 01:12:05,810
objection to that that for maybe there's

01:12:03,920 --> 01:12:08,020
embedded systems where you don't have

01:12:05,810 --> 01:12:10,699
sim D and what do you what do you mean

01:12:08,020 --> 01:12:12,710
that was nobody give a crap about

01:12:10,699 --> 01:12:15,110
getting your speed up or for when you

01:12:12,710 --> 01:12:17,270
can have a speed-up of 100 using GPUs so

01:12:15,110 --> 01:12:19,449
you should be focusing your fault on GPU

01:12:17,270 --> 01:12:24,080
end of quote

01:12:19,449 --> 01:12:26,449
now well that's silly but fish yeah but

01:12:24,080 --> 01:12:30,250
oh yeah and the other friend I have

01:12:26,449 --> 01:12:30,250
another one the other thing you want was

01:12:30,429 --> 01:12:35,210
white standard in standardizing these

01:12:33,170 --> 01:12:39,020
kind of technologies that change all the

01:12:35,210 --> 01:12:41,050
time and are not major yeah yes

01:12:39,020 --> 01:12:43,760
we got GPU is so much mirror you know

01:12:41,050 --> 01:12:46,760
well with red symmetry I means other

01:12:43,760 --> 01:12:48,350
than ease all the time in the sense that

01:12:46,760 --> 01:12:50,120
every time you have a new family of

01:12:48,350 --> 01:12:52,010
processor you get new function but it

01:12:50,120 --> 01:12:55,790
still the same freaking programming

01:12:52,010 --> 01:12:58,270
modernizing the 90s right so and GPU SMT

01:12:55,790 --> 01:13:01,429
just assigning these guys with a cookie

01:12:58,270 --> 01:13:02,780
hardware to make it work so whatever you

01:13:01,429 --> 01:13:05,420
put it in the standard

01:13:02,780 --> 01:13:07,489
what about compilers what is the

01:13:05,420 --> 01:13:10,639
solution for a compiler on a platform

01:13:07,489 --> 01:13:14,729
where you don't have sim D I mean if

01:13:10,639 --> 01:13:18,780
it's part of this yeah

01:13:14,729 --> 01:13:21,150
yeah what we do is that if you have no

01:13:18,780 --> 01:13:24,539
sign in this report we fall back to

01:13:21,150 --> 01:13:26,219
having a strongly enrolled operation of

01:13:24,539 --> 01:13:28,139
blocks on blocks of whatever size you

01:13:26,219 --> 01:13:29,010
decide in this colorway and you just

01:13:28,139 --> 01:13:31,949
back up back up

01:13:29,010 --> 01:13:33,659
so having no assignment he is I think

01:13:31,949 --> 01:13:35,579
he's the same as having a sign the

01:13:33,659 --> 01:13:38,729
instruction set with vector of size one

01:13:35,579 --> 01:13:42,479
don't end up storing okay

01:13:38,729 --> 01:13:44,280
and it's totally I mean it that's not

01:13:42,479 --> 01:13:47,369
that's not where the problem problem

01:13:44,280 --> 01:13:49,739
lies fact is that some people think that

01:13:47,369 --> 01:13:52,559
it's actually a compiler work to do this

01:13:49,739 --> 01:13:53,880
because it's very lowly though but that

01:13:52,559 --> 01:13:55,769
means that the quality of the auto

01:13:53,880 --> 01:13:58,800
vectorization is bound to you so

01:13:55,769 --> 01:14:01,639
compiler you use in this case we just do

01:13:58,800 --> 01:14:05,670
every same damn thing every time so well

01:14:01,639 --> 01:14:07,679
but yeah apparently having c++ you know

01:14:05,670 --> 01:14:09,959
automatically going on GPU with a

01:14:07,679 --> 01:14:13,219
magical keyword on a CD transform was

01:14:09,959 --> 01:14:16,769
apparently what people wanted so well

01:14:13,219 --> 01:14:19,380
another question yeah i first of all

01:14:16,769 --> 01:14:22,019
congratulate you for seems to be very

01:14:19,380 --> 01:14:23,969
good work we have been working on this

01:14:22,019 --> 01:14:27,179
type of thing ourselves for many years

01:14:23,969 --> 01:14:32,190
wrote like finite elements over with

01:14:27,179 --> 01:14:39,209
proto yeah and and and and need it for

01:14:32,190 --> 01:14:42,260
gigabyte to compile all it's very simple

01:14:39,209 --> 01:14:45,829
question what's your success on having

01:14:42,260 --> 01:14:50,300
scientists using this type of thing like

01:14:45,829 --> 01:14:50,300
scientists that know Fortran right oh

01:14:51,320 --> 01:14:56,309
well it's very currently it's very local

01:14:54,150 --> 01:14:58,459
so we have a bunch of guy from the our

01:14:56,309 --> 01:15:01,979
our Matt laboratory starting using that

01:14:58,459 --> 01:15:04,829
we have a couple of project plan but he

01:15:01,979 --> 01:15:07,650
didn't fly for different reason I mean

01:15:04,829 --> 01:15:13,320
government-funded project with some team

01:15:07,650 --> 01:15:21,800
of the Atlas Sun experiment we have a

01:15:13,320 --> 01:15:24,719
bunch of users doing outside instrument

01:15:21,800 --> 01:15:27,449
simulation so you can actually say I

01:15:24,719 --> 01:15:28,470
want to get out this way and I want you

01:15:27,449 --> 01:15:30,960
know an effect this way

01:15:28,470 --> 01:15:35,360
on the guitar and plays that and so

01:15:30,960 --> 01:15:37,860
writing DSP code generating all of this

01:15:35,360 --> 01:15:39,500
and we have a bunch of clients doing

01:15:37,860 --> 01:15:43,950
finance with that

01:15:39,500 --> 01:15:47,820
so mostly expert kind of experts that's

01:15:43,950 --> 01:15:51,390
kind of expert into more I mean except

01:15:47,820 --> 01:15:52,860
for the DSP guys they are mostly not non

01:15:51,390 --> 01:15:56,070
expert into this kind of thing just

01:15:52,860 --> 01:15:57,900
watch the code and talk and done you can

01:15:56,070 --> 01:16:00,540
get you know lower than that

01:15:57,900 --> 01:16:02,580
the DSP guy is very specific you know

01:16:00,540 --> 01:16:05,040
cases because usually they know what

01:16:02,580 --> 01:16:07,530
they want to do and apparently they

01:16:05,040 --> 01:16:10,140
found the code generation good enough to

01:16:07,530 --> 01:16:15,480
don't have to bother really doing you

01:16:10,140 --> 01:16:17,130
know further than that but we I think we

01:16:15,480 --> 01:16:18,960
are guilty to not being you know more

01:16:17,130 --> 01:16:23,040
vocal about that and you know I mean a

01:16:18,960 --> 01:16:24,960
full-blown PR campaign but well profit

01:16:23,040 --> 01:16:27,930
started maybe to be serious like two

01:16:24,960 --> 01:16:32,520
years ago now before it was a long you

01:16:27,930 --> 01:16:34,320
know mess of different project and

01:16:32,520 --> 01:16:37,740
academic all stuff you get structured

01:16:34,320 --> 01:16:39,900
like three years ago now so we should

01:16:37,740 --> 01:16:44,010
put more people into it yes just another

01:16:39,900 --> 01:16:47,610
question you you compared your table now

01:16:44,010 --> 01:16:49,340
one of the columns was was eigen yes so

01:16:47,610 --> 01:16:53,730
how do you compare yourself with eigen

01:16:49,340 --> 01:17:03,630
in terms of obviously linear performance

01:16:53,730 --> 01:17:08,820
yes so because here is a list of support

01:17:03,630 --> 01:17:11,670
right I mean you have there some some

01:17:08,820 --> 01:17:13,230
pretty good names but and they they kind

01:17:11,670 --> 01:17:17,640
of compare themselves more or less okay

01:17:13,230 --> 01:17:19,560
but eigen seems to be bar mkl Argan

01:17:17,640 --> 01:17:23,700
seems to be you know yeah king of the

01:17:19,560 --> 01:17:28,830
hill right eigen is actually our damn

01:17:23,700 --> 01:17:31,040
nemesis it's actually funny because we

01:17:28,830 --> 01:17:34,080
win on some point for example we have a

01:17:31,040 --> 01:17:36,030
larger support of I sign is an eigen so

01:17:34,080 --> 01:17:38,460
if we want to cheat actually we take a

01:17:36,030 --> 01:17:40,830
you know we take a sixteen cause machine

01:17:38,460 --> 01:17:41,820
is a B x2 and we also phenols are you

01:17:40,830 --> 01:17:44,460
know you know

01:17:41,820 --> 01:17:46,170
the point where I gained you still

01:17:44,460 --> 01:17:52,380
better than us but we are walking on it

01:17:46,170 --> 01:17:54,540
it's on small sized matrixes where we

01:17:52,380 --> 01:17:55,829
know what to do for that I mean we just

01:17:54,540 --> 01:17:57,719
didn't bother right now because our

01:17:55,829 --> 01:17:59,820
first experiment was requiring you know

01:17:57,719 --> 01:18:02,070
ten or thousand stuff I get I can beat

01:17:59,820 --> 01:18:04,139
mkl oh yeah yeah I know I know and they

01:18:02,070 --> 01:18:06,000
flap back and they do a lot of stuff

01:18:04,139 --> 01:18:09,270
because yeah when you are four elements

01:18:06,000 --> 01:18:11,369
in your matrixes well I can write Lu

01:18:09,270 --> 01:18:13,110
decomposition my cell phone on a small

01:18:11,369 --> 01:18:15,480
paper and you will go faster than the

01:18:13,110 --> 01:18:17,369
food run algorithms so but we are trying

01:18:15,480 --> 01:18:20,909
to fix that that's the point where I get

01:18:17,369 --> 01:18:22,739
very bad better performance on earth for

01:18:20,909 --> 01:18:24,659
its terrific historical reasons we

01:18:22,739 --> 01:18:26,429
didn't bother with this kind of small

01:18:24,659 --> 01:18:27,900
stir because well it's not what we

01:18:26,429 --> 01:18:29,820
needed to solve at the beginning of the

01:18:27,900 --> 01:18:34,560
project we're now looking at that and

01:18:29,820 --> 01:18:37,020
try to fix this I think we fix it or I

01:18:34,560 --> 01:18:40,500
have a branch where we fix already's for

01:18:37,020 --> 01:18:42,510
the small small matrixes on element wise

01:18:40,500 --> 01:18:44,429
operation that was quite trivial to do

01:18:42,510 --> 01:18:47,820
so if you do a called B plus C divided

01:18:44,429 --> 01:18:49,290
by cross use of X and all your matrixes

01:18:47,820 --> 01:18:53,639
is three element it should be faster

01:18:49,290 --> 01:18:56,880
than day before the other stuff we try

01:18:53,639 --> 01:18:59,219
to fix is that we found that it's

01:18:56,880 --> 01:19:01,349
trivially quite strangely that there is

01:18:59,219 --> 01:19:06,050
no none of those library actually deals

01:19:01,349 --> 01:19:08,909
with mÃ©dicos except in big kernels and

01:19:06,050 --> 01:19:10,530
what we found out is that I mean if you

01:19:08,909 --> 01:19:12,929
want to start firing opening piece

01:19:10,530 --> 01:19:14,790
friends let's let's get simple if you

01:19:12,929 --> 01:19:17,520
have 16 elements is no way it will be

01:19:14,790 --> 01:19:18,630
faster so I am a student walking on a

01:19:17,520 --> 01:19:21,119
small static

01:19:18,630 --> 01:19:24,139
cross model so you look at the iced tea

01:19:21,119 --> 01:19:26,460
at compile time guesstimate the

01:19:24,139 --> 01:19:27,989
complexity of the compilations look at

01:19:26,460 --> 01:19:29,040
the number of elements and if it's not

01:19:27,989 --> 01:19:30,719
big enough okay

01:19:29,040 --> 01:19:32,489
even if I have multi thread I will just

01:19:30,719 --> 01:19:34,320
use the classical stuff and you don't

01:19:32,489 --> 01:19:37,800
pay for whatever that's that's ongoing

01:19:34,320 --> 01:19:39,239
work and that currently the main selling

01:19:37,800 --> 01:19:41,820
point of eigen if you have very small

01:19:39,239 --> 01:19:46,139
matrix use iron maybe or or use bigger

01:19:41,820 --> 01:19:48,780
matrix I don't know and and on the on

01:19:46,139 --> 01:19:53,699
the point of linear algebra so that's

01:19:48,780 --> 01:19:55,650
the next step we didn't want it to waste

01:19:53,699 --> 01:20:01,550
efforts we implementing your

01:19:55,650 --> 01:20:04,500
so we use that back right now and blasts

01:20:01,550 --> 01:20:07,290
in CUDA could do pass and and could

01:20:04,500 --> 01:20:10,020
blast whenever you have support to that

01:20:07,290 --> 01:20:11,730
yeah well we have support for that true

01:20:10,020 --> 01:20:13,830
the magma binding actually because magma

01:20:11,730 --> 01:20:16,260
requires ku blast so whenever we use

01:20:13,830 --> 01:20:19,020
magma bang you have two glass

01:20:16,260 --> 01:20:23,550
we still haven't non mang mang related

01:20:19,020 --> 01:20:29,340
to the supports that's incoming next for

01:20:23,550 --> 01:20:30,690
different reasons because again what

01:20:29,340 --> 01:20:33,090
happened if you have two small

01:20:30,690 --> 01:20:35,610
mattresses and so on so we have to sell

01:20:33,090 --> 01:20:37,530
saw these cost model issues and then we

01:20:35,610 --> 01:20:39,000
probably be in the other points that we

01:20:37,530 --> 01:20:40,860
didn't want to spend any faults with

01:20:39,000 --> 01:20:42,840
writing all the senior algorithms

01:20:40,860 --> 01:20:45,360
because guy from lapack knows our stuff

01:20:42,840 --> 01:20:48,150
inside out and most of the times at the

01:20:45,360 --> 01:20:51,270
best algorithm you have except for you

01:20:48,150 --> 01:20:52,890
know I mean you know quick subcritical

01:20:51,270 --> 01:20:55,620
or algorithm that nobody actually know

01:20:52,890 --> 01:20:58,620
how to write what we trying to do now is

01:20:55,620 --> 01:21:01,800
actually not requiring lapack anymore

01:20:58,620 --> 01:21:05,370
because all lapack algorithms are

01:21:01,800 --> 01:21:07,950
basically blast function dancing

01:21:05,370 --> 01:21:10,650
together so if you have like we do for

01:21:07,950 --> 01:21:12,780
Lu we we can reconstruct the more

01:21:10,650 --> 01:21:15,660
parallel wares algorithm and we just

01:21:12,780 --> 01:21:17,970
depend on blasts and we will probably

01:21:15,660 --> 01:21:20,730
have a look at writing your boost assign

01:21:17,970 --> 01:21:23,010
the implementation of blasts and so we

01:21:20,730 --> 01:21:24,960
can have the choice between using some

01:21:23,010 --> 01:21:27,600
for existing blast slapback banging or

01:21:24,960 --> 01:21:36,800
going through our systems that's again

01:21:27,600 --> 01:21:38,860
an ongoing Wars yes okay thank you

01:21:36,800 --> 01:21:38,860

YouTube URL: https://www.youtube.com/watch?v=BApBvh888-U


