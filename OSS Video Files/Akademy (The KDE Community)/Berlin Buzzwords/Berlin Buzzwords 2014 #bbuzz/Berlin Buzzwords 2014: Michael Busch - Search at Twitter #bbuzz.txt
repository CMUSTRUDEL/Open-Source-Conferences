Title: Berlin Buzzwords 2014: Michael Busch - Search at Twitter #bbuzz
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	Twitter's search engine serves billions of queries per day from different Lucene indexes, while appending more than hundreds of millions of tweets per day in real time. This session will give an overview of Twitter's search architecture and the recent changes and improvements that have been made. It will focus on the usage of Lucene and the modifications that have been made to it to support Twitter's unique performance requirements.

Read more:
https://2014.berlinbuzzwords.de/session/search-twitter

About Michael Busch:
https://2014.berlinbuzzwords.de/user/293/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:06,100 --> 00:00:11,549
I guess it's emser hi my name is michael

00:00:09,250 --> 00:00:15,070
bush I work at Twitter in San Francisco

00:00:11,549 --> 00:00:16,570
tech lead off the search team there yeah

00:00:15,070 --> 00:00:21,939
today I would like to talk about our

00:00:16,570 --> 00:00:23,980
search engine the talk has kind of four

00:00:21,939 --> 00:00:26,530
sections i'm going to introduce a little

00:00:23,980 --> 00:00:28,630
bit with numbers that we have to deal

00:00:26,530 --> 00:00:30,160
with and then i'm going to cover the

00:00:28,630 --> 00:00:32,439
search architecture from a high level

00:00:30,160 --> 00:00:34,989
and then i want to dive with into the

00:00:32,439 --> 00:00:39,809
inverted index and some of the like

00:00:34,989 --> 00:00:39,809
ranking tricks we do for relevant search

00:00:42,690 --> 00:00:49,929
all right so yeah twitter has now more

00:00:47,109 --> 00:00:52,269
than 255 million active monthly active

00:00:49,929 --> 00:00:57,249
users we have about 500 million tweets

00:00:52,269 --> 00:00:59,260
every day we have about more than 300

00:00:57,249 --> 00:01:02,579
billion tweets since two thousand two

00:00:59,260 --> 00:01:04,659
thousand six now and yeah sometimes

00:01:02,579 --> 00:01:07,990
probably soon and the world cup starting

00:01:04,659 --> 00:01:10,630
we see new TPS tweets per second records

00:01:07,990 --> 00:01:14,710
I think the current one is thirty-three

00:01:10,630 --> 00:01:17,740
thousand tweets per second um and on the

00:01:14,710 --> 00:01:22,079
search side we have no more than two

00:01:17,740 --> 00:01:25,149
billion search queries per day that has

00:01:22,079 --> 00:01:26,289
increased significantly in the last like

00:01:25,149 --> 00:01:29,350
three or four years since I've worked

00:01:26,289 --> 00:01:32,250
there I want to come a little bit the

00:01:29,350 --> 00:01:34,780
history of Twitter search so I'm into it

00:01:32,250 --> 00:01:37,810
before 2008 word I didn't really have

00:01:34,780 --> 00:01:39,219
any search to acquire the small company

00:01:37,810 --> 00:01:43,270
called semis the small start up with

00:01:39,219 --> 00:01:44,950
like a few people who had built a search

00:01:43,270 --> 00:01:47,759
engine on top of my sequel actually for

00:01:44,950 --> 00:01:51,369
real-time search they joined Twitter and

00:01:47,759 --> 00:01:54,640
first the product look like this before

00:01:51,369 --> 00:01:57,820
it was a separate website basically in

00:01:54,640 --> 00:01:59,289
2010 when i joined twitter it was

00:01:57,820 --> 00:02:00,549
already growing so much that kind of my

00:01:59,289 --> 00:02:02,710
secret solution was kind of falling

00:02:00,549 --> 00:02:05,020
apart I couldn't deal with a lot anymore

00:02:02,710 --> 00:02:08,170
and so we needed to change the

00:02:05,020 --> 00:02:12,370
technology and we decided to use a

00:02:08,170 --> 00:02:14,050
petrol scene um but a heavily modified

00:02:12,370 --> 00:02:19,720
version which I'm going to talk about

00:02:14,050 --> 00:02:20,470
soon then in 2011.the made a small

00:02:19,720 --> 00:02:21,970
change that

00:02:20,470 --> 00:02:24,880
doesn't look like this anymore look back

00:02:21,970 --> 00:02:26,740
then like that where we not only could

00:02:24,880 --> 00:02:28,000
search for recent tweets but also

00:02:26,740 --> 00:02:31,870
relevant tweets so if we introduce

00:02:28,000 --> 00:02:33,190
relevant search using machine later be

00:02:31,870 --> 00:02:37,210
interested in two thousand twelve and

00:02:33,190 --> 00:02:40,810
thirteen we added stuff like spelling

00:02:37,210 --> 00:02:43,750
correction and suggested searches we had

00:02:40,810 --> 00:02:46,270
a type ahead and he actually very

00:02:43,750 --> 00:02:50,350
recently if you can read that in the red

00:02:46,270 --> 00:02:52,480
circle it's very all tweet so previously

00:02:50,350 --> 00:02:55,480
before two thousand i believe 12 the

00:02:52,480 --> 00:02:59,560
only had like the last ten days of tweet

00:02:55,480 --> 00:03:00,940
searchable memory and since last year we

00:02:59,560 --> 00:03:02,620
keep adding more and more tweets so we

00:03:00,940 --> 00:03:04,470
can almost search all tweets all three

00:03:02,620 --> 00:03:10,600
hundred billion tweets in history now

00:03:04,470 --> 00:03:12,670
and you also added more we what we call

00:03:10,600 --> 00:03:14,050
universal search model result types

00:03:12,670 --> 00:03:16,300
basically so now if you search on

00:03:14,050 --> 00:03:19,390
Twitter you get top user accounts you

00:03:16,300 --> 00:03:25,410
get tweets you get photos vines videos

00:03:19,390 --> 00:03:28,870
that kind of stuff um this is the search

00:03:25,410 --> 00:03:31,540
left bar on the search web page you can

00:03:28,870 --> 00:03:33,459
see that we have you have different

00:03:31,540 --> 00:03:35,170
rankings like you can follow for example

00:03:33,459 --> 00:03:37,090
for photos video search new search I'm

00:03:35,170 --> 00:03:39,700
going to cover a little bit why that's

00:03:37,090 --> 00:03:42,880
different compared to the normal search

00:03:39,700 --> 00:03:46,660
ranking we have different search indexes

00:03:42,880 --> 00:03:48,190
for for exam for your social graph so

00:03:46,660 --> 00:03:49,780
that we can see who you follow on

00:03:48,190 --> 00:03:51,150
Twitter and that so that we can only

00:03:49,780 --> 00:03:54,790
return tweets from your followers or

00:03:51,150 --> 00:03:56,290
people you follow I should say and you

00:03:54,790 --> 00:03:58,780
have different systems different search

00:03:56,290 --> 00:04:02,260
systems actually for tweets and users

00:03:58,780 --> 00:04:05,049
for example and here's kind of a summary

00:04:02,260 --> 00:04:07,510
um basically what i just said one thing

00:04:05,049 --> 00:04:08,739
i wanted to point out which is which you

00:04:07,510 --> 00:04:09,820
can't see in the product but it's

00:04:08,739 --> 00:04:11,080
actually very significant and

00:04:09,820 --> 00:04:13,750
interesting change to the racine

00:04:11,080 --> 00:04:15,489
community is that we introduced a new

00:04:13,750 --> 00:04:19,180
posting this format i'm going to touch

00:04:15,489 --> 00:04:20,859
it later that it's very that almost

00:04:19,180 --> 00:04:22,900
fully supports a leucine spec now

00:04:20,859 --> 00:04:26,530
previously it was opting highly

00:04:22,900 --> 00:04:28,750
optimized for tweets so mostly usable

00:04:26,530 --> 00:04:30,789
for short documents but we change that

00:04:28,750 --> 00:04:32,740
such that it supports almost entirely

00:04:30,789 --> 00:04:34,000
seen spec and that gets us closer to

00:04:32,740 --> 00:04:39,210
committing it to an

00:04:34,000 --> 00:04:41,830
to the open source project all right

00:04:39,210 --> 00:04:47,380
let's talk about our search architecture

00:04:41,830 --> 00:04:49,960
I think the screen is a little smaller

00:04:47,380 --> 00:04:54,100
than mine but I think we can read

00:04:49,960 --> 00:04:56,710
everything okay so under on the upper

00:04:54,100 --> 00:05:00,570
hand we see we have a real time stream

00:04:56,710 --> 00:05:03,820
of tweets raw treats and Jason coming in

00:05:00,570 --> 00:05:05,830
and we have a component called the

00:05:03,820 --> 00:05:07,860
analyzer is called and loosing the same

00:05:05,830 --> 00:05:12,220
thing and the petitioner where does it

00:05:07,860 --> 00:05:14,200
analyzes and token izes the the tweets

00:05:12,220 --> 00:05:16,360
and prepares them for indexing so it

00:05:14,200 --> 00:05:18,460
creates token streams in racine it does

00:05:16,360 --> 00:05:22,410
terminal normalization lower casing that

00:05:18,460 --> 00:05:25,870
kind of stuff it also geocoding it

00:05:22,410 --> 00:05:28,450
expands URL if they are shortened and

00:05:25,870 --> 00:05:32,580
also does hash petitioning i'm going to

00:05:28,450 --> 00:05:35,740
show later husband indexes petitioned

00:05:32,580 --> 00:05:37,210
the output of that analyzes say as i

00:05:35,740 --> 00:05:40,510
said NY streets that are ready for

00:05:37,210 --> 00:05:41,770
indexing with racine they are stored

00:05:40,510 --> 00:05:43,650
actually in the thrift do you guys know

00:05:41,770 --> 00:05:45,820
what do you guys are familiar with rift

00:05:43,650 --> 00:05:48,580
it's a serialization data serialization

00:05:45,820 --> 00:05:53,200
format that Facebook invented and is

00:05:48,580 --> 00:05:56,560
also open source now yeah the partition

00:05:53,200 --> 00:06:01,150
analyzer emit street and civilized

00:05:56,560 --> 00:06:03,490
format and the real-time index our name

00:06:01,150 --> 00:06:07,540
is early bird code names early bird all

00:06:03,490 --> 00:06:12,250
tweet systems have have either burden

00:06:07,540 --> 00:06:13,890
the name or unnamed after bird so how

00:06:12,250 --> 00:06:16,690
are you seen the nexus called early bird

00:06:13,890 --> 00:06:19,870
it's a modified modified racine index

00:06:16,690 --> 00:06:21,550
optimized for real-time search the key

00:06:19,870 --> 00:06:24,040
differences if you are familiar with

00:06:21,550 --> 00:06:25,960
leucine leucine sneer real-time feature

00:06:24,040 --> 00:06:28,120
is that every time you want to be able

00:06:25,960 --> 00:06:30,160
to search the latest documents that you

00:06:28,120 --> 00:06:31,570
added to the index writer you kind of

00:06:30,160 --> 00:06:33,220
have to fly you have to call flash or

00:06:31,570 --> 00:06:35,740
commit so that they actually commits all

00:06:33,220 --> 00:06:37,930
the data to somewhere else in memory or

00:06:35,740 --> 00:06:41,950
two discs so that you can search it so

00:06:37,930 --> 00:06:44,410
for real time search for very high GPS

00:06:41,950 --> 00:06:46,330
in our case and QPS and if it won't have

00:06:44,410 --> 00:06:47,160
a very short latency between tweeting

00:06:46,330 --> 00:06:48,900
and being able to search

00:06:47,160 --> 00:06:51,270
tweet that approach doesn't work so well

00:06:48,900 --> 00:06:52,350
because every time we want to be able to

00:06:51,270 --> 00:06:53,700
search the late the streets we would

00:06:52,350 --> 00:06:56,550
have to always call commit and that

00:06:53,700 --> 00:06:58,560
would trigger a flash to disk or all the

00:06:56,550 --> 00:07:00,060
memory so we changed that that we

00:06:58,560 --> 00:07:02,940
connected to the same data structure

00:07:00,060 --> 00:07:05,670
append and also search in the log

00:07:02,940 --> 00:07:09,090
freeway and in my last talk at this

00:07:05,670 --> 00:07:11,430
conference I explained in detail how a

00:07:09,090 --> 00:07:13,200
memory model and how our concurrency

00:07:11,430 --> 00:07:14,580
model works oh and I can't do it today

00:07:13,200 --> 00:07:16,320
for time reasons but if you're

00:07:14,580 --> 00:07:19,110
interested then again go check it out i

00:07:16,320 --> 00:07:21,810
believe it's online i should say the

00:07:19,110 --> 00:07:24,990
real time index is fully memory it

00:07:21,810 --> 00:07:29,760
covers the last ten days and it's very

00:07:24,990 --> 00:07:31,830
fast and uses this technology so the

00:07:29,760 --> 00:07:34,230
cluster layer oh it looks like this so

00:07:31,830 --> 00:07:37,760
we basically have multiple early bird

00:07:34,230 --> 00:07:42,270
indexes that I replic replicated n times

00:07:37,760 --> 00:07:44,250
they are hash partitioned with a fixed

00:07:42,270 --> 00:07:46,140
number i believe it's like 22 or

00:07:44,250 --> 00:07:48,510
something so we have 22 h partitions a

00:07:46,140 --> 00:07:50,490
brief or maybe 25 I'm it's very simple

00:07:48,510 --> 00:07:54,690
we just bought the dark ID the treaty ID

00:07:50,490 --> 00:07:57,300
basically by n to assign it to a hash

00:07:54,690 --> 00:07:58,680
partition and then we have already

00:07:57,300 --> 00:08:01,110
called time slices those are the same

00:07:58,680 --> 00:08:03,840
access leucine segments so a segment or

00:08:01,110 --> 00:08:06,600
time slice is basically its own index

00:08:03,840 --> 00:08:08,610
that covers a certain time range and on

00:08:06,600 --> 00:08:10,650
basically on an early bird machine the

00:08:08,610 --> 00:08:12,900
way it looks I guess that we have

00:08:10,650 --> 00:08:14,280
complete time slices that are kind of

00:08:12,900 --> 00:08:16,290
full and you can't depend to them

00:08:14,280 --> 00:08:18,000
anymore and the green one on top is the

00:08:16,290 --> 00:08:19,919
writable time sighs and that change i

00:08:18,000 --> 00:08:22,260
mentioned where you can actually append

00:08:19,919 --> 00:08:23,700
to the time slice or to the segment and

00:08:22,260 --> 00:08:26,390
search at the same time and you never

00:08:23,700 --> 00:08:29,100
have to commit to disk or two to memory

00:08:26,390 --> 00:08:30,840
only when the second is full and there's

00:08:29,100 --> 00:08:34,050
some we have some restrictions of how

00:08:30,840 --> 00:08:38,010
large segments can get then we kind of

00:08:34,050 --> 00:08:41,250
start a new segment a new on the green a

00:08:38,010 --> 00:08:45,030
new new rideable m time slice and we

00:08:41,250 --> 00:08:46,650
actually delete the segment the oldest

00:08:45,030 --> 00:08:49,260
segment on each machine just gives us

00:08:46,650 --> 00:08:50,610
rolling window of tweets so that we

00:08:49,260 --> 00:08:53,780
always have a constant amount of tweets

00:08:50,610 --> 00:08:53,780
in this class 10 memory

00:08:57,100 --> 00:09:03,790
yeah so that's the real time portion of

00:09:00,649 --> 00:09:08,630
the system the upper part we have also a

00:09:03,790 --> 00:09:11,240
cutoff line portion which analyzes the

00:09:08,630 --> 00:09:15,440
tweets sometimes when we have to rebuild

00:09:11,240 --> 00:09:19,459
it also in a daily job from our archive

00:09:15,440 --> 00:09:21,320
on on HDFS it also processes the retreat

00:09:19,459 --> 00:09:23,000
similar to the other and analyze own

00:09:21,320 --> 00:09:25,160
petition as I mentioned and also

00:09:23,000 --> 00:09:26,990
aggregates engagement signals and that

00:09:25,160 --> 00:09:28,910
kind of stuff and also does is it

00:09:26,990 --> 00:09:31,839
doesn't index deleted tweets of course

00:09:28,910 --> 00:09:34,519
anymore the drop is a few days behind

00:09:31,839 --> 00:09:36,380
like three or four days behind because

00:09:34,519 --> 00:09:37,640
we don't really have to put the most

00:09:36,380 --> 00:09:39,680
recent days in that archive index

00:09:37,640 --> 00:09:42,320
because it's already searchable in the

00:09:39,680 --> 00:09:45,829
in memory index I mean in real time

00:09:42,320 --> 00:09:48,050
index so I'm therefore after three or

00:09:45,829 --> 00:09:50,630
four days usually people don't delete

00:09:48,050 --> 00:09:52,970
like tweets anymore from like a week ago

00:09:50,630 --> 00:09:54,290
so that's why we almost have no didi

00:09:52,970 --> 00:09:56,720
treats on the cynics and that's why we

00:09:54,290 --> 00:09:58,459
don't have to worry about um garbage

00:09:56,720 --> 00:10:03,529
collection on the canister I mean

00:09:58,459 --> 00:10:08,120
deleting documents the archive index is

00:10:03,529 --> 00:10:12,850
a is a standard routine 4.4 index right

00:10:08,120 --> 00:10:15,589
now want to upgrade to 4.8 soon it's

00:10:12,850 --> 00:10:17,959
reverse time sorted also because even if

00:10:15,589 --> 00:10:19,820
we do relevant search and when they

00:10:17,959 --> 00:10:21,500
return all the treats we stole the

00:10:19,820 --> 00:10:26,260
ranking is still heavily biased by time

00:10:21,500 --> 00:10:29,810
so we still try to return recent reads

00:10:26,260 --> 00:10:32,870
fairly recent tweets um that's why we

00:10:29,810 --> 00:10:34,399
saw at reverse by reverse time and the

00:10:32,870 --> 00:10:35,990
cluster layout itself is very similar to

00:10:34,399 --> 00:10:37,610
the memory run so also fixed number of

00:10:35,990 --> 00:10:39,500
hash partitions I think the number is

00:10:37,610 --> 00:10:41,510
different and also the number of tweets

00:10:39,500 --> 00:10:43,760
per machine is different because we

00:10:41,510 --> 00:10:46,070
stole them actually in s on SSD and not

00:10:43,760 --> 00:10:48,920
in memory and currently we actually have

00:10:46,070 --> 00:10:51,470
two of these archive indexes one is also

00:10:48,920 --> 00:10:53,930
a memory it has very small like one

00:10:51,470 --> 00:10:56,390
percent of something of all tweets which

00:10:53,930 --> 00:10:58,070
are which received the highest

00:10:56,390 --> 00:10:59,779
engagement I some of retweets or

00:10:58,070 --> 00:11:01,910
favorites and they are in memory very

00:10:59,779 --> 00:11:06,470
fast and then we have on SSD another

00:11:01,910 --> 00:11:07,699
index that use as a fallback if we

00:11:06,470 --> 00:11:09,050
couldn't find good tweets and then

00:11:07,699 --> 00:11:11,560
memory one so if you search for

00:11:09,050 --> 00:11:15,230
something that's not so popular maybe

00:11:11,560 --> 00:11:17,750
but then the QPS is lower that hits the

00:11:15,230 --> 00:11:19,910
SSD index and so it makes sense because

00:11:17,750 --> 00:11:22,880
of the QPS there is limited by I ops

00:11:19,910 --> 00:11:30,620
also SSDs so it's just a cost

00:11:22,880 --> 00:11:34,970
optimization basically one component

00:11:30,620 --> 00:11:36,710
that I should mention is our blender the

00:11:34,970 --> 00:11:38,420
blender is the thrift aggregator so

00:11:36,710 --> 00:11:41,480
basically when a search request from

00:11:38,420 --> 00:11:44,210
from the client comes in at first it's a

00:11:41,480 --> 00:11:46,400
blender and the blender fans it out to a

00:11:44,210 --> 00:11:48,650
different system and systems different

00:11:46,400 --> 00:11:50,750
indexes for example also our social

00:11:48,650 --> 00:11:52,190
graph or user search index I mentioned

00:11:50,750 --> 00:11:55,670
earlier users are indexed separately

00:11:52,190 --> 00:11:57,560
from tweets um and also it knows about

00:11:55,670 --> 00:12:00,050
our hash partition so it can find out to

00:11:57,560 --> 00:12:01,820
2n replicas to get a complete set of

00:12:00,050 --> 00:12:05,750
results and then merges all the results

00:12:01,820 --> 00:12:08,090
together and depending on what kind of

00:12:05,750 --> 00:12:10,580
carried was it's a simple task of just

00:12:08,090 --> 00:12:12,920
maybe doing a emerge of the search

00:12:10,580 --> 00:12:14,870
result of a list of multiple list of

00:12:12,920 --> 00:12:16,460
search result is results or it's a

00:12:14,870 --> 00:12:18,140
blending of different result types as i

00:12:16,460 --> 00:12:20,740
as i showed earlier on the slide where

00:12:18,140 --> 00:12:23,030
we had you know tweets and users and

00:12:20,740 --> 00:12:25,990
videos and images so then it's a more

00:12:23,030 --> 00:12:28,730
complicated ranking problem how to merge

00:12:25,990 --> 00:12:33,860
results of different types together so

00:12:28,730 --> 00:12:35,840
that they that they useful and then last

00:12:33,860 --> 00:12:37,640
but not least we have another stream of

00:12:35,840 --> 00:12:39,350
updates which is basically even people

00:12:37,640 --> 00:12:40,730
delete the tweet or they favor the

00:12:39,350 --> 00:12:43,580
retreat of course you're going to index

00:12:40,730 --> 00:12:45,290
that too so that you can use it for

00:12:43,580 --> 00:12:48,680
ranking purposes so we have a stream of

00:12:45,290 --> 00:12:51,370
updates and they are fanned out to all

00:12:48,680 --> 00:12:54,230
of these early bird index machines and

00:12:51,370 --> 00:13:00,550
they actually do in place updates and I

00:12:54,230 --> 00:13:00,550
can show later how that works all right

00:13:04,090 --> 00:13:08,480
okay so I want to come I want to give a

00:13:06,740 --> 00:13:09,860
very short introduction on how inverted

00:13:08,480 --> 00:13:12,740
inexus work because then it's kind of

00:13:09,860 --> 00:13:15,800
easier to explain some of the other data

00:13:12,740 --> 00:13:17,210
structures data and an inverted Enox

00:13:15,800 --> 00:13:19,370
index is basically the fundamental

00:13:17,210 --> 00:13:21,620
concept how old routine works and also

00:13:19,370 --> 00:13:26,630
early bird because it's based on the

00:13:21,620 --> 00:13:28,400
scene so let's say we have let's say we

00:13:26,630 --> 00:13:31,520
have the six documents on the left side

00:13:28,400 --> 00:13:33,410
and women the search for words in there

00:13:31,520 --> 00:13:34,550
so of course we don't scan the documents

00:13:33,410 --> 00:13:36,170
to find the word we are searching for

00:13:34,550 --> 00:13:38,030
but instead what we build assists

00:13:36,170 --> 00:13:40,550
invited index it's very simple thing

00:13:38,030 --> 00:13:41,930
it's basically dictionary of all unique

00:13:40,550 --> 00:13:44,630
terms that are contained in those

00:13:41,930 --> 00:13:46,790
documents so those those are the words

00:13:44,630 --> 00:13:48,320
on the left side and then we have on the

00:13:46,790 --> 00:13:50,330
right side what's called posting list

00:13:48,320 --> 00:13:53,210
and posting this two are basically just

00:13:50,330 --> 00:13:55,790
linked lists that contain the document

00:13:53,210 --> 00:14:00,400
IDs in which that term occurs so for

00:13:55,790 --> 00:14:04,340
example if you look for it worked keeper

00:14:00,400 --> 00:14:07,610
you can see to curse in documents 14 15

00:14:04,340 --> 00:14:09,740
and then in the dictionary here we can

00:14:07,610 --> 00:14:11,180
look up the word keeper look up the

00:14:09,740 --> 00:14:12,970
posting list and the posting this tells

00:14:11,180 --> 00:14:16,280
us 1.5 so it's a very simple operation

00:14:12,970 --> 00:14:20,180
to look that look up in which documents

00:14:16,280 --> 00:14:23,180
that were the curse um I want to quickly

00:14:20,180 --> 00:14:25,310
oh yeah and one thing I want to point

00:14:23,180 --> 00:14:27,440
out we store all to purge our metadata

00:14:25,310 --> 00:14:29,690
in this index so for example here to

00:14:27,440 --> 00:14:31,580
term frequencies that just the number of

00:14:29,690 --> 00:14:33,380
documents in which the term occurs

00:14:31,580 --> 00:14:35,600
there's more metadata we need to store

00:14:33,380 --> 00:14:36,950
per term and I quickly want to point out

00:14:35,600 --> 00:14:38,630
which data structure we use for that

00:14:36,950 --> 00:14:42,680
because of something else or unexplained

00:14:38,630 --> 00:14:45,200
later I'm we unlike leucine use a hash

00:14:42,680 --> 00:14:49,220
table to store all terms because leucine

00:14:45,200 --> 00:14:51,590
actually uses a solid data structure for

00:14:49,220 --> 00:14:53,720
things like fuzzy queries and other

00:14:51,590 --> 00:14:57,020
curie types you want it to be sorted we

00:14:53,720 --> 00:14:58,370
actually don't currently support while

00:14:57,020 --> 00:15:00,410
high praise for example of as it carries

00:14:58,370 --> 00:15:02,450
so that's why we don't need a dictionary

00:15:00,410 --> 00:15:05,260
to be sorted that's why we we have a

00:15:02,450 --> 00:15:10,250
more memory efficient hash table Oh

00:15:05,260 --> 00:15:11,870
actually fan Oh of one hash table so as

00:15:10,250 --> 00:15:13,170
you know hash table has to be oversized

00:15:11,870 --> 00:15:16,480
for

00:15:13,170 --> 00:15:18,670
efficient member hash collision handling

00:15:16,480 --> 00:15:21,550
so the array on the left side is

00:15:18,670 --> 00:15:24,640
basically our hash table and when we get

00:15:21,550 --> 00:15:26,800
the first term cat bc we assign the term

00:15:24,640 --> 00:15:29,440
ID to this terms first term so it gets

00:15:26,800 --> 00:15:31,840
id0 id0 gets hashed somewhere into the

00:15:29,440 --> 00:15:34,480
sesh table and the chair midi is at the

00:15:31,840 --> 00:15:35,800
same time the index in those arrays that

00:15:34,480 --> 00:15:39,970
we call the parallel race because

00:15:35,800 --> 00:15:42,190
they're parallel and the nice thing is

00:15:39,970 --> 00:15:44,700
that these arrays can be compact so they

00:15:42,190 --> 00:15:47,320
can have exactly the size the number of

00:15:44,700 --> 00:15:49,060
unique terms in our index they don't

00:15:47,320 --> 00:15:51,310
need to be oversized like the hash table

00:15:49,060 --> 00:15:53,470
because the Charmides isn't see index

00:15:51,310 --> 00:15:55,780
into those arrays so if you see three

00:15:53,470 --> 00:15:59,050
terms then we append the terms into a

00:15:55,780 --> 00:16:00,760
second secondary data structure and like

00:15:59,050 --> 00:16:05,520
it's like a stringbuilder basically in

00:16:00,760 --> 00:16:07,990
Java it's a character race and the store

00:16:05,520 --> 00:16:09,340
to our meta data into those parallel

00:16:07,990 --> 00:16:11,260
rays for exams the frequencies that they

00:16:09,340 --> 00:16:14,200
had on the previous slide but also point

00:16:11,260 --> 00:16:15,730
us to we're posting this starts and like

00:16:14,200 --> 00:16:19,600
other things we need to keep track of

00:16:15,730 --> 00:16:21,100
for each term yeah but I basically

00:16:19,600 --> 00:16:23,350
wanted to point out in the slide that we

00:16:21,100 --> 00:16:25,120
have term IDs and then that we can as

00:16:23,350 --> 00:16:28,150
you can see here because we have those

00:16:25,120 --> 00:16:31,600
texts point us into that string buffer

00:16:28,150 --> 00:16:33,550
that we could based on the term I dxg

00:16:31,600 --> 00:16:36,220
look up the label for the term and

00:16:33,550 --> 00:16:42,730
that's important um in a few minutes

00:16:36,220 --> 00:16:47,500
okay so the majority of an inverted

00:16:42,730 --> 00:16:48,970
index is in terms of size is you need

00:16:47,500 --> 00:16:51,130
for the father posting this the posting

00:16:48,970 --> 00:16:53,740
is a really huge long list and you want

00:16:51,130 --> 00:16:55,810
to store them very efficiently so we've

00:16:53,740 --> 00:16:58,600
seen used to use something called Delta

00:16:55,810 --> 00:16:59,830
encoding so let's say it so uses it but

00:16:58,600 --> 00:17:04,780
it uses know a different compression

00:16:59,830 --> 00:17:06,880
that I have on the slide but so for

00:17:04,780 --> 00:17:09,610
example if you want to encode the doc

00:17:06,880 --> 00:17:12,580
ADIZ that on the in the top row there

00:17:09,610 --> 00:17:13,780
515 9000 and so forth those are big

00:17:12,580 --> 00:17:15,490
numbers so what we actually tries

00:17:13,780 --> 00:17:17,770
instead to encode the deltas between two

00:17:15,490 --> 00:17:19,720
numbers so for example if you look at

00:17:17,770 --> 00:17:21,430
the last two numbers like 100 thousand

00:17:19,720 --> 00:17:24,030
and thousand 90s the difference is 90

00:17:21,430 --> 00:17:26,200
and 90 is a smaller number to encode so

00:17:24,030 --> 00:17:26,620
if you have a good compression technique

00:17:26,200 --> 00:17:28,600
then

00:17:26,620 --> 00:17:30,940
it's beneficial to encode smaller

00:17:28,600 --> 00:17:32,380
numbers we've seen uses some or used to

00:17:30,940 --> 00:17:34,480
use something called vian compressions

00:17:32,380 --> 00:17:36,550
in a newer version it doesn't use viens

00:17:34,480 --> 00:17:39,610
anymore but until it's simpler to

00:17:36,550 --> 00:17:41,740
explain beans beans don't use four bytes

00:17:39,610 --> 00:17:45,880
for an integer by the variable number of

00:17:41,740 --> 00:17:47,470
bytes and it uses of each byte only

00:17:45,880 --> 00:17:49,809
seven bits to encode the extra value but

00:17:47,470 --> 00:17:51,880
the first bit of each by it stores

00:17:49,809 --> 00:17:53,140
feather the next byte it's part of the

00:17:51,880 --> 00:17:55,360
same number or if it's a new number

00:17:53,140 --> 00:17:57,280
that's why you can concatenate multiple

00:17:55,360 --> 00:17:58,809
bites and it's always a variable length

00:17:57,280 --> 00:18:02,370
so in the first case if you have a very

00:17:58,809 --> 00:18:04,750
big number you could use five bytes for

00:18:02,370 --> 00:18:06,400
one integer but that doesn't really

00:18:04,750 --> 00:18:08,200
happen very often in an inverted Nix

00:18:06,400 --> 00:18:09,600
especially because we Delta encoding a

00:18:08,200 --> 00:18:17,260
bit try to keep some numbers actually

00:18:09,600 --> 00:18:19,900
small some a downside for us at twitter

00:18:17,260 --> 00:18:22,600
is that if you have Delta encoding you

00:18:19,900 --> 00:18:25,330
can only read it and from old to new

00:18:22,600 --> 00:18:26,950
direction right because each number

00:18:25,330 --> 00:18:29,040
depends on the previous one so you have

00:18:26,950 --> 00:18:31,120
to calculate what the actual dark ideas

00:18:29,040 --> 00:18:32,170
but if you think about real-time search

00:18:31,120 --> 00:18:34,570
what you actually want to do is you want

00:18:32,170 --> 00:18:37,200
to return tweets and the opposite order

00:18:34,570 --> 00:18:39,610
you want to return usually new treats

00:18:37,200 --> 00:18:40,929
before all treats right so that's why we

00:18:39,610 --> 00:18:42,700
wanted to have a different encoding

00:18:40,929 --> 00:18:47,800
which you cannot use read in the

00:18:42,700 --> 00:18:49,270
opposite direction um that's why in our

00:18:47,800 --> 00:18:51,580
first version of early but we had a very

00:18:49,270 --> 00:18:54,760
very simple encoding basically each

00:18:51,580 --> 00:18:57,070
posting had one integer and we split up

00:18:54,760 --> 00:18:58,630
into two parts 24 bits for the doc ID

00:18:57,070 --> 00:19:01,990
and the docket is not a delta is an

00:18:58,630 --> 00:19:03,550
absolute doc ID and since treats can

00:19:01,990 --> 00:19:05,440
only have found it for the characters we

00:19:03,550 --> 00:19:07,330
use the other eight bits for the

00:19:05,440 --> 00:19:10,600
position of a red within the tweet right

00:19:07,330 --> 00:19:14,020
and since the eight bits you can encode

00:19:10,600 --> 00:19:15,970
to 155 numbers that's enough for each

00:19:14,020 --> 00:19:20,320
possible text position in the tree to

00:19:15,970 --> 00:19:21,700
encode that position and then you can if

00:19:20,320 --> 00:19:23,170
you don't use Delta's you can use you

00:19:21,700 --> 00:19:25,030
can read it in both directions so we can

00:19:23,170 --> 00:19:26,710
we can now read in the opposite

00:19:25,030 --> 00:19:29,380
direction if this is posting list we can

00:19:26,710 --> 00:19:31,000
written into this direction new to old

00:19:29,380 --> 00:19:33,850
and you can also do something called

00:19:31,000 --> 00:19:35,530
early termination so if you don't if you

00:19:33,850 --> 00:19:37,150
don't want to actually return like let's

00:19:35,530 --> 00:19:39,730
say the best treat of all time is we

00:19:37,150 --> 00:19:40,450
really have to read all treats to find

00:19:39,730 --> 00:19:41,800
the best one of all

00:19:40,450 --> 00:19:44,050
if you only want to return which is a

00:19:41,800 --> 00:19:46,390
very frequent thing we do especially

00:19:44,050 --> 00:19:49,510
with API search on twitter if you want

00:19:46,390 --> 00:19:51,340
to return the last few results the most

00:19:49,510 --> 00:19:52,870
recent ones we can actually three for

00:19:51,340 --> 00:19:54,610
example this case are requested we can

00:19:52,870 --> 00:19:57,490
read three postings and then terminate

00:19:54,610 --> 00:19:59,080
the search and return them if you can

00:19:57,490 --> 00:20:00,640
search from you too old so that's much

00:19:59,080 --> 00:20:03,010
more efficient of course and searching

00:20:00,640 --> 00:20:11,140
in the opposite direction just to find

00:20:03,010 --> 00:20:14,380
the last most recent three tweets yeah

00:20:11,140 --> 00:20:16,330
so um yeah the combination of searching

00:20:14,380 --> 00:20:18,030
in neutral direction and being able to

00:20:16,330 --> 00:20:20,020
do a determination this was a

00:20:18,030 --> 00:20:22,360
significant performance improvement

00:20:20,020 --> 00:20:24,820
compared to the traditional way to

00:20:22,360 --> 00:20:26,350
encode things and I said I already

00:20:24,820 --> 00:20:27,850
talked last year or two years ago about

00:20:26,350 --> 00:20:31,090
the memory model so i just have to slide

00:20:27,850 --> 00:20:33,280
up here because I want to kind of give

00:20:31,090 --> 00:20:38,530
an idea how it works but not go into

00:20:33,280 --> 00:20:41,100
much detail um on the top part it's kind

00:20:38,530 --> 00:20:43,840
of a little bit like Malik it

00:20:41,100 --> 00:20:44,860
concatenate builds up a linked list for

00:20:43,840 --> 00:20:47,110
each posting is this kind of feeling

00:20:44,860 --> 00:20:49,960
dist and each of these green and yellow

00:20:47,110 --> 00:20:51,640
boxes are just slices of integer race so

00:20:49,960 --> 00:20:53,830
care for each posting is assigns a

00:20:51,640 --> 00:20:56,830
number of these slices of these integer

00:20:53,830 --> 00:20:59,170
ID and integer array slices to posting

00:20:56,830 --> 00:21:01,270
list and stores those integers that I

00:20:59,170 --> 00:21:02,950
mentioned earlier in there and then a

00:21:01,270 --> 00:21:05,140
link slices together what I want to

00:21:02,950 --> 00:21:07,690
point out is basically that the postings

00:21:05,140 --> 00:21:09,370
are stored in a race and it's hard if

00:21:07,690 --> 00:21:10,690
you would ever want to insert something

00:21:09,370 --> 00:21:12,400
in the middle it's extremely hard

00:21:10,690 --> 00:21:13,780
because you would have to kind of make

00:21:12,400 --> 00:21:17,500
room and like push everything away and

00:21:13,780 --> 00:21:19,060
like rearrange all the ideas if they if

00:21:17,500 --> 00:21:22,540
you want to keep them sorted and insert

00:21:19,060 --> 00:21:25,360
something so yeah but I one penalty is

00:21:22,540 --> 00:21:26,920
we use native race and it's hard to

00:21:25,360 --> 00:21:29,110
insert something in the middle but

00:21:26,920 --> 00:21:34,870
that's a frequent problem of inverted

00:21:29,110 --> 00:21:36,460
Nexus ok so summary years of the first

00:21:34,870 --> 00:21:38,440
version of our posting is format is that

00:21:36,460 --> 00:21:40,300
the integers can be written atomically

00:21:38,440 --> 00:21:42,370
that's another reason we used integers

00:21:40,300 --> 00:21:43,630
because of our concurrency model also

00:21:42,370 --> 00:21:45,490
you can see that in my previous talk

00:21:43,630 --> 00:21:51,040
otherwise that this important package

00:21:45,490 --> 00:21:54,440
structure is easy I'm we use integer

00:21:51,040 --> 00:21:56,059
raise also for the benefit of reduced

00:21:54,440 --> 00:21:58,580
garbage collection of it and each

00:21:56,059 --> 00:22:01,700
segment can only have 16.7 mega million

00:21:58,580 --> 00:22:06,259
tweets because of the 24 bits views for

00:22:01,700 --> 00:22:08,450
the dhaka DS and one thing also here is

00:22:06,259 --> 00:22:10,460
that difference to leucine is that if we

00:22:08,450 --> 00:22:12,559
see which doesn't happen treats very

00:22:10,460 --> 00:22:14,509
often because they are short but if you

00:22:12,559 --> 00:22:17,000
have if the same bird occur across

00:22:14,509 --> 00:22:18,830
multiple terms within the same tweet we

00:22:17,000 --> 00:22:20,360
actually store that posting twice that's

00:22:18,830 --> 00:22:22,759
different to leucine leucine does it

00:22:20,360 --> 00:22:25,370
anyway that it would only stall at doc

00:22:22,759 --> 00:22:26,929
ID once and then encode another number

00:22:25,370 --> 00:22:29,059
which is called the term frequency and

00:22:26,929 --> 00:22:31,279
that encodes are often that term across

00:22:29,059 --> 00:22:33,409
for them the same document of course it

00:22:31,279 --> 00:22:35,149
makes sense for large documents where

00:22:33,409 --> 00:22:36,470
it's very frequent that vertical

00:22:35,149 --> 00:22:37,820
multiple times but which feeds they're

00:22:36,470 --> 00:22:41,120
so so short that it doesn't really

00:22:37,820 --> 00:22:44,779
happen very often yeah but for the new

00:22:41,120 --> 00:22:47,389
postings encoding we had we had more

00:22:44,779 --> 00:22:50,360
vicious goals we wanted to support 32

00:22:47,389 --> 00:22:52,549
bit positions like leucine so that it's

00:22:50,360 --> 00:22:55,159
the we can use a real-time search

00:22:52,549 --> 00:22:57,259
benefits also for big documents we

00:22:55,159 --> 00:22:59,090
wanted to store the term frequencies

00:22:57,259 --> 00:23:00,769
instead of repeating stock ideas for

00:22:59,090 --> 00:23:02,179
space efficiency because for again for

00:23:00,769 --> 00:23:04,669
big documents it wouldn't make much

00:23:02,179 --> 00:23:05,990
sense to do it the other way but we're

00:23:04,669 --> 00:23:07,759
going to keep the concurrency model we

00:23:05,990 --> 00:23:09,409
want to keep the space efficiency for

00:23:07,759 --> 00:23:10,850
short documents and we of course you

00:23:09,409 --> 00:23:15,200
want to maintain the good performance we

00:23:10,850 --> 00:23:17,950
see so what we therefore want to do is

00:23:15,200 --> 00:23:20,659
we want to still stored or cadiz in

00:23:17,950 --> 00:23:22,879
integers because of the memory model

00:23:20,659 --> 00:23:25,240
women keep and the concurrency model but

00:23:22,879 --> 00:23:28,879
now we have the problem that the

00:23:25,240 --> 00:23:30,769
positions and payloads and you seen can

00:23:28,879 --> 00:23:33,320
be very variable length because you

00:23:30,769 --> 00:23:35,870
don't know how how much melody of the

00:23:33,320 --> 00:23:37,460
store if you if you don't know how often

00:23:35,870 --> 00:23:41,870
that term cannot curve is in the same

00:23:37,460 --> 00:23:44,649
document so therefore we encode now the

00:23:41,870 --> 00:23:50,950
new postings into two different streams

00:23:44,649 --> 00:23:50,950
the upper one is um

00:23:51,680 --> 00:23:57,630
the upper bond the yellow boxes and in

00:23:55,050 --> 00:23:59,610
the the top stream are always 32 bits

00:23:57,630 --> 00:24:01,710
they are always fixed size and they

00:23:59,610 --> 00:24:04,470
encode the doc ID and maybe the gem

00:24:01,710 --> 00:24:10,320
frequency and they have a corresponding

00:24:04,470 --> 00:24:12,600
portion in the lower stream yeah in the

00:24:10,320 --> 00:24:14,460
lower stream of position payload pairs

00:24:12,600 --> 00:24:16,440
like it could be multiple ones if the

00:24:14,460 --> 00:24:21,630
again as the term across multiple times

00:24:16,440 --> 00:24:23,490
in the same document and now I'm we

00:24:21,630 --> 00:24:24,810
don't want to encode the red pointer so

00:24:23,490 --> 00:24:27,330
if we actually store it for every

00:24:24,810 --> 00:24:29,130
posting the point of where the

00:24:27,330 --> 00:24:31,320
corresponding position payload section

00:24:29,130 --> 00:24:32,460
starts in the other byte stream I would

00:24:31,320 --> 00:24:34,590
be very expensive to point out what

00:24:32,460 --> 00:24:36,060
actually more would be bigger than the

00:24:34,590 --> 00:24:39,420
integer itself right so that would be

00:24:36,060 --> 00:24:42,660
another good idea so the idea is that we

00:24:39,420 --> 00:24:45,510
actually use a skip list which is a

00:24:42,660 --> 00:24:47,280
frequent technique that also dracaen

00:24:45,510 --> 00:24:50,040
uses in an inverted next for two reasons

00:24:47,280 --> 00:24:51,780
one is to speed up searching and the

00:24:50,040 --> 00:24:54,660
other one is to actually have these

00:24:51,780 --> 00:24:57,590
political points where we know where the

00:24:54,660 --> 00:25:02,460
corresponding section starts in the

00:24:57,590 --> 00:25:04,710
position payload stream so we can if we

00:25:02,460 --> 00:25:07,680
find like we could search for such a

00:25:04,710 --> 00:25:09,690
blue skip entry and the doc ID stream

00:25:07,680 --> 00:25:11,880
and then we would exactly know where the

00:25:09,690 --> 00:25:18,120
corresponding section and the position

00:25:11,880 --> 00:25:19,560
payload stream is so um but we have to

00:25:18,120 --> 00:25:21,720
change our posting is encoding a little

00:25:19,560 --> 00:25:22,950
bit and then observation years that most

00:25:21,720 --> 00:25:25,860
streets actually don't need all the

00:25:22,950 --> 00:25:27,690
eight bits for the text position because

00:25:25,860 --> 00:25:29,280
the text position section of the

00:25:27,690 --> 00:25:30,870
character position it's a token offset

00:25:29,280 --> 00:25:33,480
so if there are ten words in a treat

00:25:30,870 --> 00:25:34,710
then you don't store the character

00:25:33,480 --> 00:25:37,680
offset of the tenth word the tenth

00:25:34,710 --> 00:25:39,360
ricketts text position neg 10 so most of

00:25:37,680 --> 00:25:41,310
the time a treat of course doesn't have

00:25:39,360 --> 00:25:42,990
hand for your characters it could I

00:25:41,310 --> 00:25:45,360
sorry hun Foley different words it could

00:25:42,990 --> 00:25:47,400
happen maybe in like cjk languages where

00:25:45,360 --> 00:25:50,280
we don't have white space tokenization

00:25:47,400 --> 00:25:51,390
and we use by grams for example that

00:25:50,280 --> 00:25:52,650
could happen that the treat actually

00:25:51,390 --> 00:25:53,880
really has hundred forty different birds

00:25:52,650 --> 00:25:56,640
but it's not it doesn't happen very

00:25:53,880 --> 00:25:59,550
often so we could get away with less

00:25:56,640 --> 00:26:01,380
than eight bits in most cases that's why

00:25:59,550 --> 00:26:04,160
we use one bit actually to indicate

00:26:01,380 --> 00:26:06,440
whether I'm

00:26:04,160 --> 00:26:08,900
the text position is in lined in this

00:26:06,440 --> 00:26:10,010
integer or I start separately in this

00:26:08,900 --> 00:26:14,810
other stream that I had on the previous

00:26:10,010 --> 00:26:16,940
slide so in lining is only possible if

00:26:14,810 --> 00:26:18,560
all these because if all these

00:26:16,940 --> 00:26:20,390
assumptions are true here so the term

00:26:18,560 --> 00:26:21,830
frequency has to be one which again I

00:26:20,390 --> 00:26:23,450
said for treat that's most of the time

00:26:21,830 --> 00:26:26,030
true that word only the same rat only

00:26:23,450 --> 00:26:27,650
crest once in a tweet the text position

00:26:26,030 --> 00:26:30,110
has to be smaller than I'm 27 otherwise

00:26:27,650 --> 00:26:32,270
it doesn't fit into seven bits the

00:26:30,110 --> 00:26:33,470
posting should not have payloads and

00:26:32,270 --> 00:26:36,740
then our treat in the next we actually

00:26:33,470 --> 00:26:38,660
don't store payloads right now and fun

00:26:36,740 --> 00:26:40,070
implementation reason the posting must

00:26:38,660 --> 00:26:41,870
not be at the same position as one of

00:26:40,070 --> 00:26:46,160
those blue skip lists but that's an

00:26:41,870 --> 00:26:48,800
implementation detail so the cool thing

00:26:46,160 --> 00:26:51,320
then is that now we can support 32 32

00:26:48,800 --> 00:26:53,810
bit positions using the other data

00:26:51,320 --> 00:26:56,030
structures for for large documents but

00:26:53,810 --> 00:26:57,290
we maintain the same efficiency using

00:26:56,030 --> 00:27:00,350
the same data structures for tweets

00:26:57,290 --> 00:27:01,970
because most of the time for treats the

00:27:00,350 --> 00:27:05,750
positions will be inlined in those seven

00:27:01,970 --> 00:27:07,220
bits and it will not really need that

00:27:05,750 --> 00:27:09,860
additional data structure in most cases

00:27:07,220 --> 00:27:12,770
so we kind of achieve all the goals we

00:27:09,860 --> 00:27:14,360
had we wanted to keep the same memory

00:27:12,770 --> 00:27:16,040
model the same concurrency model that

00:27:14,360 --> 00:27:19,250
all works performance is the same and

00:27:16,040 --> 00:27:21,080
actually after we deployed it the index

00:27:19,250 --> 00:27:22,670
eyes barely increase increase maybe like

00:27:21,080 --> 00:27:24,800
one person because of those additional

00:27:22,670 --> 00:27:26,480
skip lists and you can under on our

00:27:24,800 --> 00:27:27,800
charts you cannot even see very deployed

00:27:26,480 --> 00:27:36,230
it because the performance was almost

00:27:27,800 --> 00:27:43,160
identical all right now one talking

00:27:36,230 --> 00:27:44,840
about ranking yeah so I mentioned

00:27:43,160 --> 00:27:46,730
already that inverted index of course

00:27:44,840 --> 00:27:48,890
can be used to if you have a query you

00:27:46,730 --> 00:27:50,360
can look up some matching doc IDs you

00:27:48,890 --> 00:27:52,010
know we saw that on the earlier slide

00:27:50,360 --> 00:27:53,330
also i pointed out with the term

00:27:52,010 --> 00:27:55,220
dictionaries that they can do labeling

00:27:53,330 --> 00:27:56,540
if you have a chairman the ID we can use

00:27:55,220 --> 00:28:01,400
invert the next to look up the term

00:27:56,540 --> 00:28:04,190
labor but where do we store stuff like

00:28:01,400 --> 00:28:06,200
you know Retreat retreat counts favorite

00:28:04,190 --> 00:28:07,280
counts for ranking so for that we have a

00:28:06,200 --> 00:28:10,280
forward in the next and that one is

00:28:07,280 --> 00:28:12,100
actually very similar to racine stock

00:28:10,280 --> 00:28:15,320
values if you are familiar with those

00:28:12,100 --> 00:28:17,660
and we have additional index in the

00:28:15,320 --> 00:28:20,000
facet index also similar to

00:28:17,660 --> 00:28:22,730
elasticsearch I see no solar they have s

00:28:20,000 --> 00:28:24,380
accounting we have we have we don't have

00:28:22,730 --> 00:28:26,660
actually the fence accounting feature as

00:28:24,380 --> 00:28:29,330
such like amazon also on the trade

00:28:26,660 --> 00:28:31,550
ostrich product but we use very similar

00:28:29,330 --> 00:28:33,730
data structures for other for other use

00:28:31,550 --> 00:28:36,020
cases that i'm going to show in a second

00:28:33,730 --> 00:28:37,340
so the forward index is very similar to

00:28:36,020 --> 00:28:39,830
lose in doc values at store Street

00:28:37,340 --> 00:28:42,440
features retreat collins favorite clowns

00:28:39,830 --> 00:28:45,140
reply counts and other ranking

00:28:42,440 --> 00:28:46,730
information that we use they are the

00:28:45,140 --> 00:28:48,110
different students seen as they are in

00:28:46,730 --> 00:28:51,830
memory and updateable in our case

00:28:48,110 --> 00:28:53,420
because I mean people favorite and read

00:28:51,830 --> 00:28:55,820
treat like all the time in real time so

00:28:53,420 --> 00:28:58,670
we need to update if you need to reflect

00:28:55,820 --> 00:29:02,780
those changes to accurately rank our

00:28:58,670 --> 00:29:05,600
tweets and we have a implemented small

00:29:02,780 --> 00:29:07,310
type system that allows us to pack

00:29:05,600 --> 00:29:10,910
multiple features into one integer

00:29:07,310 --> 00:29:12,830
basically so um i think for retreat

00:29:10,910 --> 00:29:14,960
favorite reply and and for things i can

00:29:12,830 --> 00:29:16,810
remember we use the same integer and we

00:29:14,960 --> 00:29:20,270
use a special encoding two packs it into

00:29:16,810 --> 00:29:21,440
into one integer because if you think

00:29:20,270 --> 00:29:23,720
about we have three hundred billion

00:29:21,440 --> 00:29:26,750
tweets that's actually that's actually

00:29:23,720 --> 00:29:27,920
jason of a treat here and you can see

00:29:26,750 --> 00:29:29,720
there's a lot of numbers in you and

00:29:27,920 --> 00:29:31,190
metadata I mean yeah three days only

00:29:29,720 --> 00:29:33,170
have four characters but actually the

00:29:31,190 --> 00:29:36,740
what's kind of unique I think about our

00:29:33,170 --> 00:29:38,150
search problem is that why we have short

00:29:36,740 --> 00:29:42,170
dawg where we have short documents we

00:29:38,150 --> 00:29:43,970
have so many that almost the storage of

00:29:42,170 --> 00:29:46,040
the features for ranking purposes is

00:29:43,970 --> 00:29:48,380
bigger than the action very Linux

00:29:46,040 --> 00:29:51,470
inverting is index is fairly small

00:29:48,380 --> 00:29:52,760
compared to you know other longer

00:29:51,470 --> 00:29:55,610
documents of course because we don't

00:29:52,760 --> 00:29:59,300
have so many postings but the forward

00:29:55,610 --> 00:30:00,440
the next needs to be very big so if you

00:29:59,300 --> 00:30:03,350
think about if you just want to encode

00:30:00,440 --> 00:30:05,570
one integer and if you have 300 billion

00:30:03,350 --> 00:30:07,190
tweets you need or in this case one

00:30:05,570 --> 00:30:08,570
being treat and you have maybe 10 10

00:30:07,190 --> 00:30:10,730
replicas or i think we probably even

00:30:08,570 --> 00:30:12,260
have more then it's already four

00:30:10,730 --> 00:30:14,510
terabytes of memory which is really

00:30:12,260 --> 00:30:17,510
expensive so we try to compress as much

00:30:14,510 --> 00:30:19,490
as we can of course so here's our most

00:30:17,510 --> 00:30:21,290
famous tweet from the last Oscars that

00:30:19,490 --> 00:30:23,630
got like three and a half million

00:30:21,290 --> 00:30:25,100
retreats and two million favorites so

00:30:23,630 --> 00:30:28,370
these numbers we want to store of course

00:30:25,100 --> 00:30:29,870
they don't fit into one bite but if you

00:30:28,370 --> 00:30:31,549
think about it it's not really important

00:30:29,870 --> 00:30:33,970
if a treat got like

00:30:31,549 --> 00:30:36,169
1 million 1 million and a thousand

00:30:33,970 --> 00:30:37,100
retweets for ranking purposes that

00:30:36,169 --> 00:30:39,019
doesn't really matter it's more

00:30:37,100 --> 00:30:44,389
important if it's we got 10 vs 100

00:30:39,019 --> 00:30:47,179
retweets for example so we wanted to we

00:30:44,389 --> 00:30:50,299
wanted to try to pack it into an integer

00:30:47,179 --> 00:30:52,460
and if you look at different lock

00:30:50,299 --> 00:30:56,480
distributions if you actually use stock

00:30:52,460 --> 00:31:01,940
the base of 1.1 then we kind of got a

00:30:56,480 --> 00:31:05,239
nice distribution that assigns different

00:31:01,940 --> 00:31:09,980
values to the interesting areas right so

00:31:05,239 --> 00:31:12,889
I'm sorry in this case oops in this case

00:31:09,980 --> 00:31:15,080
you know if three tests 5,000 or 10,000

00:31:12,889 --> 00:31:18,499
feet doesn't change the score that much

00:31:15,080 --> 00:31:21,799
the lock in the right column but if a

00:31:18,499 --> 00:31:24,590
treat has you know between 1 and 10

00:31:21,799 --> 00:31:27,049
retweets the value changes like

00:31:24,590 --> 00:31:30,259
significantly to the ranking value so

00:31:27,049 --> 00:31:34,399
that's exactly what we want to see the

00:31:30,259 --> 00:31:37,840
and therefore we use a modified float

00:31:34,399 --> 00:31:41,419
structure to encode these values into

00:31:37,840 --> 00:31:42,980
seven bits we only use a next one for

00:31:41,419 --> 00:31:46,700
four beds in the fraction of three bits

00:31:42,980 --> 00:31:49,609
and you can see that the resulting curve

00:31:46,700 --> 00:31:53,889
of that custom float looks very similar

00:31:49,609 --> 00:31:53,889
to that lock column here

00:31:58,950 --> 00:32:06,899
okay okay so now for relevance ranking

00:32:03,679 --> 00:32:10,200
as I said often we just want to maybe

00:32:06,899 --> 00:32:12,269
return 10recent good tweets but

00:32:10,200 --> 00:32:15,090
sometimes we also want to return the

00:32:12,269 --> 00:32:16,440
best treat of all time and ideally we

00:32:15,090 --> 00:32:18,000
don't want to have another index that

00:32:16,440 --> 00:32:20,039
may be solved by relevance but we want

00:32:18,000 --> 00:32:24,269
to use our existing existing indexes

00:32:20,039 --> 00:32:27,419
because they re so so they can be don't

00:32:24,269 --> 00:32:29,120
want to build another one and one

00:32:27,419 --> 00:32:32,100
observation is that a lot of features

00:32:29,120 --> 00:32:34,139
are curry independent so we have static

00:32:32,100 --> 00:32:36,149
signals like I use a text quality of a

00:32:34,139 --> 00:32:40,559
treat you know if it tests interesting

00:32:36,149 --> 00:32:42,539
read verses like 10 * blah that the you

00:32:40,559 --> 00:32:45,149
know text ability is important dynamic

00:32:42,539 --> 00:32:47,809
signal diagram of retweets and I my

00:32:45,149 --> 00:32:50,639
favorites and that kind of stuff or the

00:32:47,809 --> 00:32:52,169
author's reputation for example could be

00:32:50,639 --> 00:32:53,940
interesting and then there's curry

00:32:52,169 --> 00:32:57,210
dependent signals like receives texts

00:32:53,940 --> 00:32:58,950
score or the language of the person who

00:32:57,210 --> 00:33:01,919
is searching so you know for someone who

00:32:58,950 --> 00:33:03,419
searched who's um within Germany should

00:33:01,919 --> 00:33:06,750
probably see other results in someone

00:33:03,419 --> 00:33:08,130
who's in languages set to English those

00:33:06,750 --> 00:33:09,809
things things like very deep end but

00:33:08,130 --> 00:33:12,779
they are a lot of signals are

00:33:09,809 --> 00:33:15,000
independent those ideas to actually in

00:33:12,779 --> 00:33:19,980
the X skip lists for documents that have

00:33:15,000 --> 00:33:21,840
high curry independent scores so we

00:33:19,980 --> 00:33:23,909
could think of having many different

00:33:21,840 --> 00:33:25,850
early bird segments or time slices as i

00:33:23,909 --> 00:33:28,049
call them earlier yeah on the lower side

00:33:25,850 --> 00:33:30,690
let's have each eight million documents

00:33:28,049 --> 00:33:32,940
and then we have a skip list on top of

00:33:30,690 --> 00:33:35,730
them and the red dot c mark the

00:33:32,940 --> 00:33:37,889
documents that have a very high very

00:33:35,730 --> 00:33:42,630
independent score so those are the good

00:33:37,889 --> 00:33:44,779
tweets right um I'm going to skip this

00:33:42,630 --> 00:33:44,779
slide

00:33:47,330 --> 00:33:50,870
and furthermore we can actually have

00:33:49,520 --> 00:33:53,030
multiple of these kippers and make them

00:33:50,870 --> 00:33:55,370
hierarchical so we can say you know on

00:33:53,030 --> 00:33:57,530
the highest one that has very few of the

00:33:55,370 --> 00:33:58,880
red dots those really mark like the best

00:33:57,530 --> 00:34:00,200
foods of all time maybe the treat we

00:33:58,880 --> 00:34:01,850
looked at earlier that it had three

00:34:00,200 --> 00:34:03,230
million tweets or maybe Obama's tweet

00:34:01,850 --> 00:34:05,330
when you got reelected and that kind of

00:34:03,230 --> 00:34:07,850
stuff so they really contain a very

00:34:05,330 --> 00:34:09,890
small amount of treats but instead most

00:34:07,850 --> 00:34:11,960
of the other ones so now if you search

00:34:09,890 --> 00:34:15,230
for if you want to find the best tweet

00:34:11,960 --> 00:34:16,700
ever for your query we could take your

00:34:15,230 --> 00:34:19,520
query enter intersected with that

00:34:16,700 --> 00:34:21,080
highest skip list find a good tweet and

00:34:19,520 --> 00:34:22,880
if we if we find it we return it if you

00:34:21,080 --> 00:34:24,230
don't find anything matching then we

00:34:22,880 --> 00:34:29,270
could actually go down a level and go to

00:34:24,230 --> 00:34:31,190
the less I'm the less selective skip

00:34:29,270 --> 00:34:32,900
list search again for your query and

00:34:31,190 --> 00:34:35,570
maybe find something then and then we go

00:34:32,900 --> 00:34:44,030
we go the further down until we found a

00:34:35,570 --> 00:34:47,180
good tweet yeah so I'm the summary is

00:34:44,030 --> 00:34:50,930
that we do this on the relevance ranking

00:34:47,180 --> 00:34:53,210
on an index that is all up I time so

00:34:50,930 --> 00:34:55,340
that we can keep our existing

00:34:53,210 --> 00:34:58,460
infrastructure like a pending tweets but

00:34:55,340 --> 00:35:01,010
we use a forward index that is updatable

00:34:58,460 --> 00:35:03,980
to in real time always apply retweet

00:35:01,010 --> 00:35:05,450
favorite second of stuff to that an

00:35:03,980 --> 00:35:07,400
in-memory data structure and then we

00:35:05,450 --> 00:35:09,920
have a background thread that actually

00:35:07,400 --> 00:35:12,890
come regularly recompute those skip

00:35:09,920 --> 00:35:15,290
lists and reflects the changes of those

00:35:12,890 --> 00:35:18,290
engagement signals so the red dots get

00:35:15,290 --> 00:35:19,880
recomputed all the time because tweets

00:35:18,290 --> 00:35:22,730
can have gotten one engagement in the

00:35:19,880 --> 00:35:25,600
meantime and we achieve very high

00:35:22,730 --> 00:35:29,830
performance of the in the combination of

00:35:25,600 --> 00:35:34,640
the skip lists and early termination

00:35:29,830 --> 00:35:37,340
okay okay one last thing i want to show

00:35:34,640 --> 00:35:39,410
is I showed ra is a universal search

00:35:37,340 --> 00:35:40,880
site here because this universe search

00:35:39,410 --> 00:35:43,940
because it blends different result types

00:35:40,880 --> 00:35:45,770
and what you can see is that for example

00:35:43,940 --> 00:35:49,910
you turned photos so now how do we

00:35:45,770 --> 00:35:54,080
search for photos right I'm only have

00:35:49,910 --> 00:36:00,960
five minutes left I'll be searched for

00:35:54,080 --> 00:36:04,410
photos so we the interesting thing is

00:36:00,960 --> 00:36:06,210
that the document in our index

00:36:04,410 --> 00:36:07,890
represented to eat not the photo right

00:36:06,210 --> 00:36:11,490
and now what could happen is you know

00:36:07,890 --> 00:36:13,290
two people treat the same photo link the

00:36:11,490 --> 00:36:15,839
first person says you know all that's a

00:36:13,290 --> 00:36:18,630
cute puppy and the second person says I

00:36:15,839 --> 00:36:21,240
know cute dog right now if you in the

00:36:18,630 --> 00:36:22,500
next first street with a URL you only

00:36:21,240 --> 00:36:23,730
have the red puppy in there someone

00:36:22,500 --> 00:36:25,800
searched for doc wouldn't find the

00:36:23,730 --> 00:36:27,720
document that photos so what you

00:36:25,800 --> 00:36:31,890
actually want to do is you kind of want

00:36:27,720 --> 00:36:34,560
to update the previous document with the

00:36:31,890 --> 00:36:36,960
photo URL so that it also contains a

00:36:34,560 --> 00:36:38,670
great dog but as I showed earlier and

00:36:36,960 --> 00:36:42,030
then inverted index it's very difficult

00:36:38,670 --> 00:36:43,680
to in place updates so that's why in

00:36:42,030 --> 00:36:44,849
especially in real time index if you

00:36:43,680 --> 00:36:47,040
have an offline Linux you could

00:36:44,849 --> 00:36:48,839
recompute the whole index often but in

00:36:47,040 --> 00:36:52,560
the real time in next um you don't want

00:36:48,839 --> 00:36:53,640
to do that so an also decide especially

00:36:52,560 --> 00:36:58,349
on Twitter it's very important that you

00:36:53,640 --> 00:37:01,260
can often find very recent photos for

00:36:58,349 --> 00:37:04,680
example if the in terms disconnects or

00:37:01,260 --> 00:37:06,300
officer was a fiery recently and the the

00:37:04,680 --> 00:37:07,950
photos people took on the street that

00:37:06,300 --> 00:37:10,230
the iphone showed up on Twitter before

00:37:07,950 --> 00:37:12,119
anywhere else so you really want to

00:37:10,230 --> 00:37:15,150
solve this stretching for the problem in

00:37:12,119 --> 00:37:17,099
real time yeah but because empires

00:37:15,150 --> 00:37:19,349
posting these updates are heart and

00:37:17,099 --> 00:37:21,030
through scenes update document call it's

00:37:19,349 --> 00:37:22,410
really delete and add so it changes the

00:37:21,030 --> 00:37:24,060
oil of the neck so it would not preserve

00:37:22,410 --> 00:37:26,790
our time I out the next anymore we

00:37:24,060 --> 00:37:28,140
needed a different solution and the idea

00:37:26,790 --> 00:37:29,940
is to use faster to actually for that

00:37:28,140 --> 00:37:33,210
and the first day a structure not the

00:37:29,940 --> 00:37:38,609
facets in the product sense and this is

00:37:33,210 --> 00:37:41,070
how it works again the facet in X is as

00:37:38,609 --> 00:37:43,980
you get nexted maps from a dog ID to the

00:37:41,070 --> 00:37:45,839
features a treat contains and features

00:37:43,980 --> 00:37:48,599
in this case could before the URLs could

00:37:45,839 --> 00:37:52,020
be hash tags could be at vengeance and

00:37:48,599 --> 00:37:56,040
what an interesting entities so now if

00:37:52,020 --> 00:37:57,359
you search if you search for query we

00:37:56,040 --> 00:37:59,369
look in the posting this we find the

00:37:57,359 --> 00:38:02,400
matching got IDs and then we look up in

00:37:59,369 --> 00:38:04,740
the facet index what our term IDs for

00:38:02,400 --> 00:38:07,260
interesting entities like photo URLs or

00:38:04,740 --> 00:38:09,480
hashtags that the stream contains and

00:38:07,260 --> 00:38:14,250
then we have a we maintained during the

00:38:09,480 --> 00:38:17,190
search a top K heap that has

00:38:14,250 --> 00:38:18,720
the tupolev end of the term ID that we

00:38:17,190 --> 00:38:21,060
found in the tweets that match the query

00:38:18,720 --> 00:38:26,130
and the frequencies account how often

00:38:21,060 --> 00:38:31,320
that Jeremy Kurt and as I pointed out

00:38:26,130 --> 00:38:33,450
earlier we can use inverted index to map

00:38:31,320 --> 00:38:34,950
back from term ID to the term label

00:38:33,450 --> 00:38:38,910
using the dictionary implementation we

00:38:34,950 --> 00:38:41,130
have so a last step after we found the

00:38:38,910 --> 00:38:42,990
top term IDs by conned and have sold

00:38:41,130 --> 00:38:46,290
them we can use them nor the next two

00:38:42,990 --> 00:38:48,240
met them back to in this case photo URLs

00:38:46,290 --> 00:38:50,670
and return the top photos actually that

00:38:48,240 --> 00:38:52,590
match your query and it this is kind of

00:38:50,670 --> 00:38:54,090
cool that we can use the NAM inverted

00:38:52,590 --> 00:38:57,200
index and don't have to build a special

00:38:54,090 --> 00:39:00,360
index and solve the you know in

00:38:57,200 --> 00:39:04,800
updatable document problem okay so in

00:39:00,360 --> 00:39:08,720
summary as I said indexing two

00:39:04,800 --> 00:39:11,010
identities allows us to search in a

00:39:08,720 --> 00:39:13,110
tweet centric index for other entities

00:39:11,010 --> 00:39:14,970
are three types are supported for

00:39:13,110 --> 00:39:16,860
example you could say find the best

00:39:14,970 --> 00:39:19,650
photos in San Francisco you know from

00:39:16,860 --> 00:39:21,780
people i follow documents don't need to

00:39:19,650 --> 00:39:23,550
be really next and the approach is

00:39:21,780 --> 00:39:24,900
reusable for a new entity set come up

00:39:23,550 --> 00:39:28,770
you just have to change our indexing

00:39:24,900 --> 00:39:32,280
schema for like best vines hashtags

00:39:28,770 --> 00:39:38,000
mentions videos that kind of stuff and I

00:39:32,280 --> 00:39:38,000
believe that's it yep questions

00:39:43,170 --> 00:39:53,560
they'd be life too much time at thanks

00:39:50,890 --> 00:39:56,680
for the talk um how do you do um

00:39:53,560 --> 00:39:59,550
type-ahead all right how do you do

00:39:56,680 --> 00:40:02,829
type-ahead I bet didn't have different

00:39:59,550 --> 00:40:05,020
index yeah one more question how do you

00:40:02,829 --> 00:40:06,670
do spell correction yeah so I'm the

00:40:05,020 --> 00:40:08,290
question is how do we you type ad it's

00:40:06,670 --> 00:40:11,260
the answers that's actually not their

00:40:08,290 --> 00:40:14,530
index it's not it's not served by decent

00:40:11,260 --> 00:40:18,369
Nexus here and it's pretty similar to

00:40:14,530 --> 00:40:21,070
how will you seen this type at the index

00:40:18,369 --> 00:40:25,390
prefixes of terms and then we carry that

00:40:21,070 --> 00:40:30,040
index for term prefixes and can expand

00:40:25,390 --> 00:40:32,440
to the extra great grace spelling

00:40:30,040 --> 00:40:34,810
Corrections and it's also like a whole

00:40:32,440 --> 00:40:37,990
it's another another different index

00:40:34,810 --> 00:40:42,940
actually yeah so yeah it's not it's not

00:40:37,990 --> 00:40:49,599
served by GT Nexus a dimension any more

00:40:42,940 --> 00:40:52,480
questions I'm going to look at the Oreo

00:40:49,599 --> 00:40:54,849
time talk but i think its release in 2.9

00:40:52,480 --> 00:40:56,829
that was already Oreo time support so

00:40:54,849 --> 00:41:00,520
could you just maybe a few words how

00:40:56,829 --> 00:41:03,250
your approach is better yeah i think the

00:41:00,520 --> 00:41:04,750
question is why don't we use a near

00:41:03,250 --> 00:41:06,940
real-time feature that will see into pan

00:41:04,750 --> 00:41:11,680
and introduce yeah i try to touch on it

00:41:06,940 --> 00:41:15,339
earlier and the the different the reason

00:41:11,680 --> 00:41:19,150
is that for it work sort of scenes near

00:41:15,339 --> 00:41:20,650
real-time feature works well if you

00:41:19,150 --> 00:41:22,359
don't reopen your next we are too often

00:41:20,650 --> 00:41:24,780
so you have to end scene you have to

00:41:22,359 --> 00:41:33,369
reopen your index reader to see a fresh

00:41:24,780 --> 00:41:36,400
view of your index yeah um you have you

00:41:33,369 --> 00:41:39,130
have to you implicitly losing the set

00:41:36,400 --> 00:41:40,480
the scene has to flush all these data

00:41:39,130 --> 00:41:43,839
structures that I had here on the sides

00:41:40,480 --> 00:41:46,270
I the posting lists and dictionaries it

00:41:43,839 --> 00:41:48,250
rushes it to disks or a two disc or to a

00:41:46,270 --> 00:41:51,220
different in memory and directory

00:41:48,250 --> 00:41:52,900
implementation and that and that causes

00:41:51,220 --> 00:41:54,099
new segment small segments a lot of

00:41:52,900 --> 00:41:56,290
small segments especially if you do it

00:41:54,099 --> 00:41:58,330
very often so you pay later

00:41:56,290 --> 00:42:00,970
for merging those small segments right

00:41:58,330 --> 00:42:03,460
so in scenes near time a near real-time

00:42:00,970 --> 00:42:05,620
search feature the indexing throughput

00:42:03,460 --> 00:42:08,710
and the search throughput are correlated

00:42:05,620 --> 00:42:10,780
in our case is completely separate so we

00:42:08,710 --> 00:42:12,040
can because we never have to flush these

00:42:10,780 --> 00:42:13,660
data structures we never get small

00:42:12,040 --> 00:42:16,540
segments and we never have to pay for

00:42:13,660 --> 00:42:18,130
for merging segments so if you don't get

00:42:16,540 --> 00:42:19,750
the performance curves like you could

00:42:18,130 --> 00:42:21,760
you could have an early bird machine and

00:42:19,750 --> 00:42:23,080
you index as fast as you can with like I

00:42:21,760 --> 00:42:26,800
on fifty thousand tweets per second

00:42:23,080 --> 00:42:28,510
index and then you start hitting it with

00:42:26,800 --> 00:42:29,800
queries right and the indexing

00:42:28,510 --> 00:42:32,730
performance doesn't go down at all it's

00:42:29,800 --> 00:42:36,400
completely completely maintains the same

00:42:32,730 --> 00:42:41,560
performance ok maybe we have time for

00:42:36,400 --> 00:42:44,770
one more question could you give us some

00:42:41,560 --> 00:42:49,870
idea how you test your systems are both

00:42:44,770 --> 00:42:52,270
on the micro level for forum for your

00:42:49,870 --> 00:42:53,920
the scene modifications as well as the

00:42:52,270 --> 00:42:57,850
how do you test like the full system

00:42:53,920 --> 00:43:00,420
yeah so for yeah the question is how do

00:42:57,850 --> 00:43:02,740
we test the system on a low level

00:43:00,420 --> 00:43:04,870
actually the cool thing is even though

00:43:02,740 --> 00:43:06,550
some lot of the data structures an early

00:43:04,870 --> 00:43:08,020
bird a different from the scene the cool

00:43:06,550 --> 00:43:10,210
thing is i implement the same the scene

00:43:08,020 --> 00:43:12,730
AP is which is why i was lazy and just

00:43:10,210 --> 00:43:15,630
used a lot of the leucine unit test to

00:43:12,730 --> 00:43:18,540
test for the correctness and that's

00:43:15,630 --> 00:43:21,280
there's really great coverage we have um

00:43:18,540 --> 00:43:23,290
we wrote additional unit test to test

00:43:21,280 --> 00:43:25,600
specifically the concurrency at the new

00:43:23,290 --> 00:43:27,850
comprehensive model but otherwise we for

00:43:25,600 --> 00:43:30,190
just correctness of searches we used a

00:43:27,850 --> 00:43:31,420
lot of sluicing unit tests and then for

00:43:30,190 --> 00:43:33,220
the system as a whole yeah it's always

00:43:31,420 --> 00:43:37,510
difficult to fully test distribute

00:43:33,220 --> 00:43:41,890
system we have we have smoke tests that

00:43:37,510 --> 00:43:44,440
hit our blender component and test if

00:43:41,890 --> 00:43:46,150
the expected search results you know

00:43:44,440 --> 00:43:48,160
from five somebody if you test if you

00:43:46,150 --> 00:43:51,760
have if you have a fixed day a set and

00:43:48,160 --> 00:43:54,700
you do a universal search query it hits

00:43:51,760 --> 00:43:56,410
almost all the systems so if you get the

00:43:54,700 --> 00:43:58,080
expected result back that's a pretty

00:43:56,410 --> 00:44:00,970
good indication that you know nothing

00:43:58,080 --> 00:44:02,920
fundamentally is broken um also we have

00:44:00,970 --> 00:44:06,310
so many queries we have constant seem of

00:44:02,920 --> 00:44:09,700
string of queries that a lot of things

00:44:06,310 --> 00:44:11,320
we test when we when we

00:44:09,700 --> 00:44:14,200
when we deploy when we do a staging

00:44:11,320 --> 00:44:18,160
deploy we can you know send a lot of

00:44:14,200 --> 00:44:21,370
queries to the next and see if anything

00:44:18,160 --> 00:44:27,040
is breaking so that's the benefit that

00:44:21,370 --> 00:44:30,450
we have such high traffic okay well

00:44:27,040 --> 00:44:30,450

YouTube URL: https://www.youtube.com/watch?v=akvrdGeZmIE


