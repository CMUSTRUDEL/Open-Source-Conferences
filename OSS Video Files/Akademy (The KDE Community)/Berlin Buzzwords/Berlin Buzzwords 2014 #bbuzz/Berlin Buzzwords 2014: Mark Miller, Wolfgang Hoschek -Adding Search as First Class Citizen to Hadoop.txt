Title: Berlin Buzzwords 2014: Mark Miller, Wolfgang Hoschek -Adding Search as First Class Citizen to Hadoop
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	So far Search has largely been missing as a first class citizen from the Hadoop ecosystem. We describe how Cloudera Search deeply integrates SolrCloud/Lucene with Hadoop. This enables rich user friendly low latency Search and Analytics over Big Data stored in HDFS and HBase as well as Near Real Time Search and Analytics over streaming data such as logs, social media, structured and unstructured data, all in a manner that is flexible, scalable, reliable, cost-effective and easy to operate.

GFS, MapReduce and BigTable were originally built to store and index the web. Apache Hadoop, HDFS and HBase implement these concepts in open source. Proprietary Google Search sits on top of this infrastructure, and we wanted to build something similar in open source for Hadoop.

Read more:
https://2014.berlinbuzzwords.de/session/adding-search-first-class-citizen-hadoop

About Mark Miller
https://2014.berlinbuzzwords.de/user/317/event/1

About Wolfgang Hoschek:
https://2014.berlinbuzzwords.de/user/299/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:06,910 --> 00:00:11,780
all right hello everyone welcome to

00:00:09,830 --> 00:00:14,109
finding the needle in a big haystack

00:00:11,780 --> 00:00:17,810
we're going to be talking about

00:00:14,109 --> 00:00:22,010
integrating search with Hadoop this is a

00:00:17,810 --> 00:00:24,350
two-person talk so a lot Wolfgang start

00:00:22,010 --> 00:00:27,350
off with a little bit of his bio real

00:00:24,350 --> 00:00:28,940
quick and I'll take over all right my

00:00:27,350 --> 00:00:30,800
name is Wolfgang whooping hashtag and

00:00:28,940 --> 00:00:33,559
I'm a search engineer at the claddagh

00:00:30,800 --> 00:00:35,120
research team you know I previously

00:00:33,559 --> 00:00:37,870
worked in various different places

00:00:35,120 --> 00:00:40,879
including in Europe at CERN the European

00:00:37,870 --> 00:00:44,149
our research center for particle physics

00:00:40,879 --> 00:00:46,370
i worked on berkeley lab and then in

00:00:44,149 --> 00:00:48,289
various startups in a bay area including

00:00:46,370 --> 00:00:50,120
sky tag for example and what all of

00:00:48,289 --> 00:00:52,100
these things have in common is that you

00:00:50,120 --> 00:00:53,659
know I worked with you know large

00:00:52,100 --> 00:00:57,139
amounts of data I'm making sense out of

00:00:53,659 --> 00:01:00,079
game building VII servers building

00:00:57,139 --> 00:01:02,870
worldwide analytic systems that crunch a

00:01:00,079 --> 00:01:04,540
lot of data and producer you know real

00:01:02,870 --> 00:01:06,920
time results in the end you know after

00:01:04,540 --> 00:01:10,580
considerable amount of trials and errors

00:01:06,920 --> 00:01:14,480
and i'm also an Apache isoleucine

00:01:10,580 --> 00:01:16,820
committer from way back in the day I'm a

00:01:14,480 --> 00:01:19,220
flume commuter commit around the HBase

00:01:16,820 --> 00:01:21,470
indexer project will hear more on that

00:01:19,220 --> 00:01:23,930
later on kite and more plans and so

00:01:21,470 --> 00:01:25,640
forth and so without much further ado

00:01:23,930 --> 00:01:29,450
I'll hand it over to mark who's going to

00:01:25,640 --> 00:01:31,340
talk about some more yeah so quick

00:01:29,450 --> 00:01:33,080
introduction to me my name is Mark

00:01:31,340 --> 00:01:34,580
Miller I'm a leucine solar committer

00:01:33,080 --> 00:01:37,460
I've been playing around with we've seen

00:01:34,580 --> 00:01:40,010
since 2006 been a committer since around

00:01:37,460 --> 00:01:42,680
two thousand eight previously I worked

00:01:40,010 --> 00:01:45,230
for lucid works which is the commercial

00:01:42,680 --> 00:01:46,610
entity behind or attempts to be the

00:01:45,230 --> 00:01:48,920
commercial entity behind we've seen in

00:01:46,610 --> 00:01:51,020
solar I was the core engineering manager

00:01:48,920 --> 00:01:53,500
there for a couple years and currently

00:01:51,020 --> 00:01:56,240
I'm a software engineer at Cloudera

00:01:53,500 --> 00:01:59,690
co-creator of solar cloud with yannick

00:01:56,240 --> 00:02:03,110
sealy which is solar's clustering and in

00:01:59,690 --> 00:02:06,050
distributed capabilities it's a little

00:02:03,110 --> 00:02:07,790
bit of the agenda first we're going to

00:02:06,050 --> 00:02:10,129
talk about Big Data and search kind of

00:02:07,790 --> 00:02:13,190
setting the stage the cloud era search

00:02:10,129 --> 00:02:14,959
architecture some near real-time in

00:02:13,190 --> 00:02:15,930
batch use cases and then finally

00:02:14,959 --> 00:02:19,799
conclusion

00:02:15,930 --> 00:02:23,069
in QA so first the enterprise data hub

00:02:19,799 --> 00:02:25,950
this is kind of Clara's vision of the

00:02:23,069 --> 00:02:27,780
future for for handling big data the

00:02:25,950 --> 00:02:30,510
idea is basically that you have all of

00:02:27,780 --> 00:02:33,269
your data in one place on HDFS and you

00:02:30,510 --> 00:02:35,639
bring in various processes to deal with

00:02:33,269 --> 00:02:37,739
that data allows you to store you know a

00:02:35,639 --> 00:02:40,139
ton a ton of data on commodity hardware

00:02:37,739 --> 00:02:41,609
very cheaply and then you know bring the

00:02:40,139 --> 00:02:45,659
processing to the data rather than

00:02:41,609 --> 00:02:47,519
moving the data around so you know you

00:02:45,659 --> 00:02:49,980
can see where search fits fits into this

00:02:47,519 --> 00:02:51,900
this is kind of taking the the single

00:02:49,980 --> 00:02:53,159
node model where where you need you want

00:02:51,900 --> 00:02:55,620
to be able to store data you want to be

00:02:53,159 --> 00:02:57,930
able to process data and of course you

00:02:55,620 --> 00:03:00,569
also want to be able to search data so

00:02:57,930 --> 00:03:03,930
Hadoop obviously deals with the storing

00:03:00,569 --> 00:03:05,909
and processing of data and you know this

00:03:03,930 --> 00:03:10,169
this is a talk about bringing search to

00:03:05,909 --> 00:03:13,079
that to that ball game so the idea of

00:03:10,169 --> 00:03:15,090
adding search is that search tends to be

00:03:13,079 --> 00:03:18,209
easy everybody knows search you see a

00:03:15,090 --> 00:03:20,190
Google box and it's pretty clear what to

00:03:18,209 --> 00:03:22,979
do type in some search terms hit return

00:03:20,190 --> 00:03:26,310
and you get your results back so you

00:03:22,979 --> 00:03:27,959
know dealing with MapReduce kind of

00:03:26,310 --> 00:03:29,459
takes an expert you're generally kind of

00:03:27,959 --> 00:03:31,229
a low level programmer you've got to

00:03:29,459 --> 00:03:33,780
understand some of the distributed

00:03:31,229 --> 00:03:36,479
paradigms you know you kind of got to be

00:03:33,780 --> 00:03:38,159
an expert SQL brings things up a level

00:03:36,479 --> 00:03:40,590
it's a little easier a lot of people

00:03:38,159 --> 00:03:43,500
know SQL but but generally not everybody

00:03:40,590 --> 00:03:44,879
knows SQL search you know everybody

00:03:43,500 --> 00:03:47,040
knows search everybody knows how to

00:03:44,879 --> 00:03:49,349
search google so bringing search the

00:03:47,040 --> 00:03:51,689
hadoop kind of opens up the range of

00:03:49,349 --> 00:03:55,349
what had you can do for people to it to

00:03:51,689 --> 00:03:58,590
a much wider audience so what is

00:03:55,349 --> 00:04:01,829
cloudera search it's basically full text

00:03:58,590 --> 00:04:03,900
search with faceted navigation we allow

00:04:01,829 --> 00:04:06,810
for for both you know efficient bat

00:04:03,900 --> 00:04:08,879
search batch indexing near real-time

00:04:06,810 --> 00:04:10,500
search where basically data is coming in

00:04:08,879 --> 00:04:12,209
and being indexed well people are

00:04:10,500 --> 00:04:13,979
searching for that data with with very

00:04:12,209 --> 00:04:17,400
low latency from when it comes into when

00:04:13,979 --> 00:04:18,870
you can search it on-demand indexing so

00:04:17,400 --> 00:04:22,639
how we chose to integrate search the

00:04:18,870 --> 00:04:25,320
Hadoop was to integrate with Apache Solr

00:04:22,639 --> 00:04:27,000
Hadoop being an Apache project it's kind

00:04:25,320 --> 00:04:29,040
of a nice marriage to bring in solar

00:04:27,000 --> 00:04:31,650
which is also Apache based

00:04:29,040 --> 00:04:34,140
very similar communities in a lot of

00:04:31,650 --> 00:04:37,680
ways very similar architectures and how

00:04:34,140 --> 00:04:40,230
things are configured has a very

00:04:37,680 --> 00:04:42,140
established mature community it's always

00:04:40,230 --> 00:04:45,150
been around since about two thousand six

00:04:42,140 --> 00:04:47,190
so it's it's it's been you know fairly

00:04:45,150 --> 00:04:49,800
hardened over time although some of the

00:04:47,190 --> 00:04:52,890
distributed stuff is a little newer it

00:04:49,800 --> 00:04:54,510
started out as a single box solution and

00:04:52,890 --> 00:04:57,170
now people are using it you know up to

00:04:54,510 --> 00:05:00,300
two hundreds of boxes in some cases um

00:04:57,170 --> 00:05:03,330
so basically the idea to integrate

00:05:00,300 --> 00:05:05,310
search you know what do we do first we

00:05:03,330 --> 00:05:07,620
basically decided you know let's do some

00:05:05,310 --> 00:05:10,110
first-class integrations with the rest

00:05:07,620 --> 00:05:12,600
of the Hadoop ecosystem so let's

00:05:10,110 --> 00:05:15,510
integrate solar with MapReduce let's

00:05:12,600 --> 00:05:17,880
integrate solar with HBase let's

00:05:15,510 --> 00:05:21,870
integrate solar with flume all of these

00:05:17,880 --> 00:05:23,940
kind of well-known Hadoop projects lets

00:05:21,870 --> 00:05:25,470
you know contribute back to to each of

00:05:23,940 --> 00:05:26,850
these open source projects all of these

00:05:25,470 --> 00:05:30,210
integration points to make it really

00:05:26,850 --> 00:05:33,000
easy to to add search to what

00:05:30,210 --> 00:05:35,150
everybody's already doing with Hadoop so

00:05:33,000 --> 00:05:38,790
we're using one hundred percent solar

00:05:35,150 --> 00:05:40,140
it's all you know unmodified open-source

00:05:38,790 --> 00:05:42,210
solar we don't really have anything

00:05:40,140 --> 00:05:43,980
proprietary we're just taking what's

00:05:42,210 --> 00:05:47,670
already out there and integrating it

00:05:43,980 --> 00:05:49,140
with the rest of these projects so that

00:05:47,670 --> 00:05:52,110
the cloud our search architecture

00:05:49,140 --> 00:05:53,910
overview in the middle there you have

00:05:52,110 --> 00:05:56,370
the soil cloud cluster clad air search

00:05:53,910 --> 00:05:58,560
only works in solar cloud mode solar

00:05:56,370 --> 00:06:02,460
basically has two modes one which is

00:05:58,560 --> 00:06:05,910
kind of the old mode is mostly a single

00:06:02,460 --> 00:06:08,040
box solution it did it did offer

00:06:05,910 --> 00:06:09,780
previously distributed search but it was

00:06:08,040 --> 00:06:12,480
up to you to kind of index the data

00:06:09,780 --> 00:06:15,000
yourself to deal with failover or fault

00:06:12,480 --> 00:06:17,280
tolerance it was really easy to search

00:06:15,000 --> 00:06:19,710
across multiple boxes but you know there

00:06:17,280 --> 00:06:22,140
was a lot of do-it-yourself clue to make

00:06:19,710 --> 00:06:24,090
that work well solar cloud kind of adds

00:06:22,140 --> 00:06:26,550
a lot of the cluster and high

00:06:24,090 --> 00:06:28,560
availability and automatic failover that

00:06:26,550 --> 00:06:30,330
a lot of people kind of had to used to

00:06:28,560 --> 00:06:33,990
build themselves now you get it out of

00:06:30,330 --> 00:06:36,930
the box so as you can see we we've done

00:06:33,990 --> 00:06:39,180
integrations both with HDFS so that

00:06:36,930 --> 00:06:41,030
solar cloud will run natively on HDFS

00:06:39,180 --> 00:06:42,820
rather than on the local file system

00:06:41,030 --> 00:06:45,850
integration with

00:06:42,820 --> 00:06:48,190
space so that as you're indexing dated

00:06:45,850 --> 00:06:50,710
HBase that that can immediately be

00:06:48,190 --> 00:06:52,960
available for search as well as flume

00:06:50,710 --> 00:06:55,000
data can come into flume and be piped

00:06:52,960 --> 00:06:57,570
off in the solar along with you know

00:06:55,000 --> 00:07:01,390
whatever other sinks you have like HDFS

00:06:57,570 --> 00:07:03,160
and then it's basically a high-level

00:07:01,390 --> 00:07:05,470
overview will kind of dig into some of

00:07:03,160 --> 00:07:08,350
these another great integration is with

00:07:05,470 --> 00:07:10,600
Hugh he was a graphical interface into a

00:07:08,350 --> 00:07:12,460
lot of the Hadoop projects and it's

00:07:10,600 --> 00:07:14,800
added some really great support for

00:07:12,460 --> 00:07:18,990
solar where you can kind of generate

00:07:14,800 --> 00:07:21,280
these really quick GUI search

00:07:18,990 --> 00:07:23,350
integrations where you can do drag and

00:07:21,280 --> 00:07:26,560
drop to to kind of create a whole

00:07:23,350 --> 00:07:28,570
interface for searching and and having

00:07:26,560 --> 00:07:30,340
facets on the side where you just you

00:07:28,570 --> 00:07:32,050
know drag over this is where I want my

00:07:30,340 --> 00:07:34,630
facets this is the fields I want to pass

00:07:32,050 --> 00:07:36,370
it on um if you haven't checked out you

00:07:34,630 --> 00:07:38,680
really really awesome interface and do a

00:07:36,370 --> 00:07:40,060
lot of Hadoop projects and and that the

00:07:38,680 --> 00:07:43,540
job they've done integrating with solar

00:07:40,060 --> 00:07:45,190
is it's pretty amazing so some of the

00:07:43,540 --> 00:07:48,640
challenges we had in doing this

00:07:45,190 --> 00:07:51,910
integration um you know making it very

00:07:48,640 --> 00:07:53,620
scalable very reliable that's that's

00:07:51,910 --> 00:07:55,450
kind of still an ongoing process but

00:07:53,620 --> 00:07:58,270
what we've done a lot of work to improve

00:07:55,450 --> 00:08:00,340
this just the fact that we run natively

00:07:58,270 --> 00:08:03,970
on HDFS adds a lot of reliability

00:08:00,340 --> 00:08:06,550
because HDFS is very hardened stable you

00:08:03,970 --> 00:08:08,110
know has its own replication it's it's

00:08:06,550 --> 00:08:10,360
been around long enough in bank online

00:08:08,110 --> 00:08:12,100
enough by by many you know large

00:08:10,360 --> 00:08:14,710
organizations people doing stuff with a

00:08:12,100 --> 00:08:18,120
lot of data so it's it's it's just very

00:08:14,710 --> 00:08:21,370
solid and adds an extra layer of

00:08:18,120 --> 00:08:24,640
reliability you're not likely to Tino to

00:08:21,370 --> 00:08:26,470
have a corrupt index or lose any data we

00:08:24,640 --> 00:08:28,660
wanted to provide near real-time search

00:08:26,470 --> 00:08:30,130
at at a very large scale you know people

00:08:28,660 --> 00:08:31,870
dealing with the loop are generally

00:08:30,130 --> 00:08:35,020
dealing with terabytes or petabytes of

00:08:31,870 --> 00:08:36,580
data so you know we want to be able to

00:08:35,020 --> 00:08:38,020
be able ingest data at a very high

00:08:36,580 --> 00:08:40,690
volume while still providing your

00:08:38,020 --> 00:08:42,460
real-time search at the same time we

00:08:40,690 --> 00:08:44,680
want to be able to index a lot of data

00:08:42,460 --> 00:08:46,000
very fast you know if you can't index

00:08:44,680 --> 00:08:49,000
that fast and you're dealing with

00:08:46,000 --> 00:08:50,470
terabytes of data then you know searches

00:08:49,000 --> 00:08:51,760
is kind of useless you don't want to

00:08:50,470 --> 00:08:54,490
take a year to be able to put in your

00:08:51,760 --> 00:08:55,690
your terabytes of data so that's that's

00:08:54,490 --> 00:08:56,649
really where kind of our MapReduce

00:08:55,690 --> 00:08:59,050
integration come

00:08:56,649 --> 00:09:01,569
where you can use your you know 400 node

00:08:59,050 --> 00:09:03,790
MapReduce cluster to build indexes and

00:09:01,569 --> 00:09:06,670
deploy them to Silver Cloud and then

00:09:03,790 --> 00:09:09,430
another issue was usability there's this

00:09:06,670 --> 00:09:11,470
kind of been a lot of usability issues

00:09:09,430 --> 00:09:13,689
in terms of getting solar and solar

00:09:11,470 --> 00:09:16,209
cloud up to speed the community is

00:09:13,689 --> 00:09:18,429
focused a lot on some of the the core

00:09:16,209 --> 00:09:20,230
problems that are kind of deeper and

00:09:18,429 --> 00:09:22,569
more technical and not as much on the

00:09:20,230 --> 00:09:23,889
usability so as we were doing these

00:09:22,569 --> 00:09:26,379
integrations we spent a lot of time

00:09:23,889 --> 00:09:28,059
making usability a little better we

00:09:26,379 --> 00:09:29,860
worked on a tool called solar control

00:09:28,059 --> 00:09:32,410
that makes it a lot easier to kind of

00:09:29,860 --> 00:09:34,809
manage configuration and and creating

00:09:32,410 --> 00:09:36,970
and collections and adding replicas and

00:09:34,809 --> 00:09:38,559
things like that so we spend a lot of

00:09:36,970 --> 00:09:43,059
time kind of improving lose a bit

00:09:38,559 --> 00:09:45,220
usability so a little bit about apache

00:09:43,059 --> 00:09:47,439
Lucene and solar which is what we're

00:09:45,220 --> 00:09:49,869
integrating in we've seen is a full-text

00:09:47,439 --> 00:09:52,929
search library extremely fast extremely

00:09:49,869 --> 00:09:54,490
compact extremely efficient probably

00:09:52,929 --> 00:09:56,110
most of you have heard of it it's pretty

00:09:54,490 --> 00:09:58,660
much that a facto standard for search

00:09:56,110 --> 00:10:01,509
these days easily the best open-source

00:09:58,660 --> 00:10:02,889
search library I think I used to work a

00:10:01,509 --> 00:10:04,660
lot more on the scene it's it's an

00:10:02,889 --> 00:10:07,120
extremely fun project to work on has a

00:10:04,660 --> 00:10:09,519
fantastic community I spend a lot more

00:10:07,120 --> 00:10:11,259
time on solar now solar is basically a

00:10:09,519 --> 00:10:13,899
search engine built on top of leucine

00:10:11,259 --> 00:10:16,779
that adds things like highlighting

00:10:13,899 --> 00:10:18,249
faceted search spell checking the

00:10:16,779 --> 00:10:20,499
distributed capabilities that come with

00:10:18,249 --> 00:10:24,759
solar cloud so kind of like the next

00:10:20,499 --> 00:10:27,639
layer up and then so solar cloud itself

00:10:24,759 --> 00:10:32,410
this this was basically an initiative

00:10:27,639 --> 00:10:34,240
started in 2009 arm that that it's

00:10:32,410 --> 00:10:36,670
basically attempting to make large-scale

00:10:34,240 --> 00:10:39,730
distributed search easier like I said

00:10:36,670 --> 00:10:41,259
before solar even back in like 2007

00:10:39,730 --> 00:10:43,720
could do distributed search but it was

00:10:41,259 --> 00:10:46,389
up to you to figure out how to get your

00:10:43,720 --> 00:10:48,549
data on on the individual nodes solar

00:10:46,389 --> 00:10:50,439
cloud basically starts doing that

00:10:48,549 --> 00:10:52,660
automatically for you you just start

00:10:50,439 --> 00:10:54,910
adding data to the cluster it figures

00:10:52,660 --> 00:10:57,429
out where to put the data by hashing it

00:10:54,910 --> 00:10:59,499
and it kind of handles you know if a

00:10:57,429 --> 00:11:02,079
node goes down how to deal with that and

00:10:59,499 --> 00:11:07,299
and and provide fault tolerance search

00:11:02,079 --> 00:11:09,610
um yeah so so basically one of the first

00:11:07,299 --> 00:11:10,440
things we started working on was making

00:11:09,610 --> 00:11:13,140
solar

00:11:10,440 --> 00:11:16,230
that it could natively work with HDFS

00:11:13,140 --> 00:11:19,860
this was fairly important to Cloudera

00:11:16,230 --> 00:11:24,360
because pretty much all of their systems

00:11:19,860 --> 00:11:26,610
run on HDFS and you really don't want to

00:11:24,360 --> 00:11:28,560
introduce a new component that relies on

00:11:26,610 --> 00:11:30,180
local file system storage because it's

00:11:28,560 --> 00:11:32,250
just a new level of complexity in terms

00:11:30,180 --> 00:11:33,570
of dealing with configuration and

00:11:32,250 --> 00:11:35,160
management you know you've got to look

00:11:33,570 --> 00:11:36,600
at each node and you've got to make sure

00:11:35,160 --> 00:11:38,670
they all have the right amount of

00:11:36,600 --> 00:11:39,990
filesystem space and if you're running

00:11:38,670 --> 00:11:42,720
out of space you've got a deal with each

00:11:39,990 --> 00:11:44,370
of those nodes and add more space once

00:11:42,720 --> 00:11:45,930
you're running on HDFS that becomes much

00:11:44,370 --> 00:11:48,240
less of a headache you can use existing

00:11:45,930 --> 00:11:51,650
tools and management applications just

00:11:48,240 --> 00:11:53,730
add more space to your HDFS cluster and

00:11:51,650 --> 00:11:55,680
it's kind of less of a management

00:11:53,730 --> 00:11:58,050
headache you get some other benefits by

00:11:55,680 --> 00:12:00,090
running out running off HDFS let's say

00:11:58,050 --> 00:12:02,280
you want to use MapReduce to to build

00:12:00,090 --> 00:12:04,530
indexes you can immediately start

00:12:02,280 --> 00:12:06,540
serving those indexes straight from HDFS

00:12:04,530 --> 00:12:08,310
with solar without having to like copy

00:12:06,540 --> 00:12:10,320
them off to the local filesystem a

00:12:08,310 --> 00:12:13,620
practice that there was pretty common in

00:12:10,320 --> 00:12:15,300
the past you also can do some cool

00:12:13,620 --> 00:12:19,530
things in terms of failover that I'll

00:12:15,300 --> 00:12:22,830
talk about a little more so the HDFS

00:12:19,530 --> 00:12:25,800
integration there's a low level 2 scene

00:12:22,830 --> 00:12:29,370
directory abstraction that allows you to

00:12:25,800 --> 00:12:32,130
basically plug in a new class so that

00:12:29,370 --> 00:12:34,860
you can write a leucine or really seen

00:12:32,130 --> 00:12:37,310
index from almost anything if you

00:12:34,860 --> 00:12:40,140
implement this directory structure so

00:12:37,310 --> 00:12:43,170
what we did is there's a project called

00:12:40,140 --> 00:12:44,340
Apache blur that kind of you know headed

00:12:43,170 --> 00:12:45,840
the way in this and they they

00:12:44,340 --> 00:12:47,490
implemented what's called an HDFS

00:12:45,840 --> 00:12:50,460
directory which knows how to read and

00:12:47,490 --> 00:12:51,840
write directly to HDFS so you know we

00:12:50,460 --> 00:12:55,170
talked to them and we ended up borrowing

00:12:51,840 --> 00:12:57,660
this code there can be some performance

00:12:55,170 --> 00:12:59,310
issues reading writing the HDFS it's

00:12:57,660 --> 00:13:01,890
actually faster than you think but in

00:12:59,310 --> 00:13:04,020
some cases the reeds can be slower than

00:13:01,890 --> 00:13:06,930
you'd like so they also introduced

00:13:04,020 --> 00:13:08,490
what's called a block cash so that when

00:13:06,930 --> 00:13:11,190
you're doing reads you know it'll read a

00:13:08,490 --> 00:13:12,960
lot more and cash it locally you can you

00:13:11,190 --> 00:13:15,480
can do this off heap as well using

00:13:12,960 --> 00:13:17,250
direct buffers to to make sure you're

00:13:15,480 --> 00:13:18,660
not running into garbage collection

00:13:17,250 --> 00:13:22,140
issues and you don't have to size or

00:13:18,660 --> 00:13:23,850
heap really huge this this block cash is

00:13:22,140 --> 00:13:25,589
basically a replacement for the

00:13:23,850 --> 00:13:29,790
the local file system cache in a lot of

00:13:25,589 --> 00:13:31,709
cases so you tend to want it to be a ton

00:13:29,790 --> 00:13:32,940
of RAM and having it off heap just

00:13:31,709 --> 00:13:39,180
basically makes that a lot more

00:13:32,940 --> 00:13:41,130
efficient so let's see so basically in

00:13:39,180 --> 00:13:43,079
solar there's a directory factory

00:13:41,130 --> 00:13:44,639
extraction that lets you plug in

00:13:43,079 --> 00:13:46,889
different we've seen directory

00:13:44,639 --> 00:13:48,300
implementations in the past there's

00:13:46,889 --> 00:13:49,709
actually the only one that really worked

00:13:48,300 --> 00:13:52,860
well with solar and that was the local

00:13:49,709 --> 00:13:54,959
file system implementation and so like

00:13:52,860 --> 00:13:56,399
if you wanted to replication or some of

00:13:54,959 --> 00:13:59,069
the other more advanced features and

00:13:56,399 --> 00:14:00,990
solar if only worked if you had this

00:13:59,069 --> 00:14:02,910
local file system implementation so one

00:14:00,990 --> 00:14:04,319
of the first things we did is we started

00:14:02,910 --> 00:14:05,910
expanding solar so that it could

00:14:04,319 --> 00:14:08,579
actually do replication and all of these

00:14:05,910 --> 00:14:11,009
things with any valid directly

00:14:08,579 --> 00:14:13,800
implementation so that led us basically

00:14:11,009 --> 00:14:15,569
add this HDFS implementation and still

00:14:13,800 --> 00:14:17,279
take advantage of replication which is

00:14:15,569 --> 00:14:19,199
pretty important for solar cloud when a

00:14:17,279 --> 00:14:22,500
node goes down and you bring it back up

00:14:19,199 --> 00:14:24,029
later it's got to replicate from you

00:14:22,500 --> 00:14:27,449
know an existing node that already has

00:14:24,029 --> 00:14:29,069
the data so basically we kind of

00:14:27,449 --> 00:14:30,689
borrowed this HDFS directly

00:14:29,069 --> 00:14:32,490
implementation we plugged it into solar

00:14:30,689 --> 00:14:33,870
we kind of spruced it up to make it work

00:14:32,490 --> 00:14:35,490
a little better with solar there were a

00:14:33,870 --> 00:14:37,860
couple of oddities that didn't really

00:14:35,490 --> 00:14:39,240
fit with our architecture but we spruced

00:14:37,860 --> 00:14:41,220
it up we got all that to work pretty

00:14:39,240 --> 00:14:42,750
well there's still some optimizations we

00:14:41,220 --> 00:14:44,250
want to do but we found performance was

00:14:42,750 --> 00:14:47,519
actually fairly similar to local

00:14:44,250 --> 00:14:50,639
filesystem solar cloud also has a

00:14:47,519 --> 00:14:52,769
transaction log so that if a node goes

00:14:50,639 --> 00:14:54,540
down if it crashes when it starts back

00:14:52,769 --> 00:14:56,519
up it can replay from the transaction

00:14:54,540 --> 00:14:58,800
log and not lose any data this was also

00:14:56,519 --> 00:15:00,509
written to the local filesystem and so

00:14:58,800 --> 00:15:02,579
having that in the local file system

00:15:00,509 --> 00:15:03,990
again the same as having your index on

00:15:02,579 --> 00:15:05,970
the local filesystem kind of added a

00:15:03,990 --> 00:15:07,740
management headache so we also created

00:15:05,970 --> 00:15:09,300
new implementation for that they can

00:15:07,740 --> 00:15:11,910
write the transaction log directly to

00:15:09,300 --> 00:15:14,220
HDFS there's there's kind of some side

00:15:11,910 --> 00:15:16,259
benefits in this and that if you only

00:15:14,220 --> 00:15:18,509
have if you have no replicas and you

00:15:16,259 --> 00:15:20,639
only have one node serving a shard and

00:15:18,509 --> 00:15:22,589
that shard goes down you can actually

00:15:20,639 --> 00:15:25,019
bring that shard up on another node and

00:15:22,589 --> 00:15:28,439
still have the transaction log to replay

00:15:25,019 --> 00:15:29,490
and not actually lose any data so once

00:15:28,439 --> 00:15:31,620
we implemented both of these

00:15:29,490 --> 00:15:34,019
abstractions we basically had kind of

00:15:31,620 --> 00:15:36,209
first-class support for HDFS with solar

00:15:34,019 --> 00:15:37,590
when you start up solar you can pass a

00:15:36,209 --> 00:15:40,050
couple system property

00:15:37,590 --> 00:15:46,380
and basically be writing all of your

00:15:40,050 --> 00:15:48,600
data other than the logs to HDFS so auto

00:15:46,380 --> 00:15:50,190
auto replica failover this is kind of

00:15:48,600 --> 00:15:54,060
actually one of the great things to come

00:15:50,190 --> 00:15:56,360
out of running on HDFS um so when you're

00:15:54,060 --> 00:15:58,710
running on a CFS if a node goes down

00:15:56,360 --> 00:16:01,170
that that data is actually still

00:15:58,710 --> 00:16:03,720
available in HDFS so in the standard

00:16:01,170 --> 00:16:06,210
local filesystem case if a node goes

00:16:03,720 --> 00:16:08,550
down you have to have a replica still

00:16:06,210 --> 00:16:10,830
around to fall over to right and then

00:16:08,550 --> 00:16:12,660
you can add more replicas and they'll

00:16:10,830 --> 00:16:14,850
replicate the index from the existing

00:16:12,660 --> 00:16:16,320
replica to get back up to speed but if

00:16:14,850 --> 00:16:17,670
you lose all of your replicas for a

00:16:16,320 --> 00:16:20,190
shard your kind of dead in the water

00:16:17,670 --> 00:16:21,990
you're not going to be able to serve you

00:16:20,190 --> 00:16:23,430
know one part of your index until

00:16:21,990 --> 00:16:25,980
someone comes in and manually brings

00:16:23,430 --> 00:16:27,000
those machines back up so this is a

00:16:25,980 --> 00:16:29,760
feature that I'm actually currently

00:16:27,000 --> 00:16:31,230
working on it's not finished but it's

00:16:29,760 --> 00:16:33,300
pretty close it's going to be in soon

00:16:31,230 --> 00:16:35,700
and and what this lets you do is even if

00:16:33,300 --> 00:16:38,100
you lose every replica in your shard

00:16:35,700 --> 00:16:42,090
because that data still served in HDFS

00:16:38,100 --> 00:16:45,600
you can actually recreate a core a solar

00:16:42,090 --> 00:16:48,690
core on a machine that's still up and it

00:16:45,600 --> 00:16:50,970
can start serving that data from that

00:16:48,690 --> 00:16:52,800
shard and and and this is kind of a big

00:16:50,970 --> 00:16:55,350
advantage to the local file system and

00:16:52,800 --> 00:16:57,330
that you can you you know you can

00:16:55,350 --> 00:16:59,490
essentially if you start with 30 nodes

00:16:57,330 --> 00:17:01,230
and you go down to only one node up and

00:16:59,490 --> 00:17:03,390
all the rest died you can essentially

00:17:01,230 --> 00:17:05,640
fall over to serving your entire index

00:17:03,390 --> 00:17:07,110
from that one node in most cases it's

00:17:05,640 --> 00:17:09,390
not going to be performing to go down to

00:17:07,110 --> 00:17:12,240
one node but you know it's it's just

00:17:09,390 --> 00:17:14,160
kind of cool that basically it's it's

00:17:12,240 --> 00:17:15,600
you know fault tolerant down to pretty

00:17:14,160 --> 00:17:17,820
much any level because the data is

00:17:15,600 --> 00:17:20,040
always available in HDFS and it just

00:17:17,820 --> 00:17:21,510
takes starting up a solar core on an

00:17:20,040 --> 00:17:25,830
existing machine to start serving it

00:17:21,510 --> 00:17:29,060
again I'll pass over to Wolfgang to talk

00:17:25,830 --> 00:17:29,060
about a couple of the other integrations

00:17:30,410 --> 00:17:35,280
all right so let's talk a little bit

00:17:33,030 --> 00:17:37,620
about more of the injection site so we

00:17:35,280 --> 00:17:40,650
have some integration points in a near

00:17:37,620 --> 00:17:42,930
real-time indexing into solar using

00:17:40,650 --> 00:17:45,570
apache flume as an ingestion system

00:17:42,930 --> 00:17:49,140
flume is you know one of the projects as

00:17:45,570 --> 00:17:50,730
part of the Hadoop ecosystem that got

00:17:49,140 --> 00:17:52,650
very widely used

00:17:50,730 --> 00:17:55,740
other people use it to stream data into

00:17:52,650 --> 00:17:59,700
HDFS for SNA as a near real-time

00:17:55,740 --> 00:18:01,950
mechanism to say like no load lock files

00:17:59,700 --> 00:18:04,590
that are incrementally you know produced

00:18:01,950 --> 00:18:08,220
in to HDFS other kinds of data not just

00:18:04,590 --> 00:18:11,910
like text data but also binary data or

00:18:08,220 --> 00:18:14,790
all sorts of things and so we took flume

00:18:11,910 --> 00:18:18,030
and flume meaning a bunch of flume

00:18:14,790 --> 00:18:20,130
agents and have them consume data such

00:18:18,030 --> 00:18:24,059
as log files or other kind of in front

00:18:20,130 --> 00:18:26,130
of data and then forward have this state

00:18:24,059 --> 00:18:28,320
of being forwarded through various flume

00:18:26,130 --> 00:18:30,720
agents in a distributed system you know

00:18:28,320 --> 00:18:35,160
hierarchy or graph or tree shaped like

00:18:30,720 --> 00:18:37,940
form into solar and into HDFS starting

00:18:35,160 --> 00:18:41,580
from the notion initially that all data

00:18:37,940 --> 00:18:43,620
lands in HDFS pretty much unmodified so

00:18:41,580 --> 00:18:46,320
that is for her for a very long time has

00:18:43,620 --> 00:18:49,679
been like the the common mode of

00:18:46,320 --> 00:18:52,830
operating Hadoop that whatever data gets

00:18:49,679 --> 00:18:55,130
ingested pretty much gets stored in its

00:18:52,830 --> 00:18:58,290
raw form without with little or no

00:18:55,130 --> 00:19:01,590
formatting or transformation and so

00:18:58,290 --> 00:19:03,510
given that what we had to do is find a

00:19:01,590 --> 00:19:05,820
way how to take that data in near real

00:19:03,510 --> 00:19:08,309
time and also stuff it into solar but as

00:19:05,820 --> 00:19:10,890
you will of course know it doesn't make

00:19:08,309 --> 00:19:12,840
too much sense to store raw data and

00:19:10,890 --> 00:19:15,059
solar but rather that data needs to

00:19:12,840 --> 00:19:17,340
conform to some search application model

00:19:15,059 --> 00:19:20,669
that actually makes sense and so there

00:19:17,340 --> 00:19:22,770
is some some some step in between that

00:19:20,669 --> 00:19:24,929
needs to be done in order to convert the

00:19:22,770 --> 00:19:27,179
data from A to B into you know into the

00:19:24,929 --> 00:19:30,990
format that's actually make sense for a

00:19:27,179 --> 00:19:32,640
search application and so flume is a

00:19:30,990 --> 00:19:34,860
very modular system you can plug

00:19:32,640 --> 00:19:37,260
yourself in at various levels and very

00:19:34,860 --> 00:19:39,690
various different points and the most

00:19:37,260 --> 00:19:41,790
natural point for plugging in this solar

00:19:39,690 --> 00:19:44,549
ingestion mechanism is at the sink level

00:19:41,790 --> 00:19:46,740
where you have something called a flume

00:19:44,549 --> 00:19:49,440
more flying solar sync which is sense

00:19:46,740 --> 00:19:51,540
essentially a plug-in point that that

00:19:49,440 --> 00:19:54,030
can take a stream of data and then

00:19:51,540 --> 00:19:56,040
transform that theater into whatever

00:19:54,030 --> 00:20:00,780
data model is required by solar and then

00:19:56,040 --> 00:20:04,290
send it es / j standard solar api into

00:20:00,780 --> 00:20:06,960
into solar for indexing and

00:20:04,290 --> 00:20:10,380
you can type the very same data also

00:20:06,960 --> 00:20:12,120
into HDFS so it's it you but usually

00:20:10,380 --> 00:20:14,400
people use this you know to stream data

00:20:12,120 --> 00:20:16,740
into both targets rather than it into

00:20:14,400 --> 00:20:19,620
one target to retain the ability to have

00:20:16,740 --> 00:20:22,050
all of their data in HDFS in its raw

00:20:19,620 --> 00:20:24,030
form so later on you can run arbitrary

00:20:22,050 --> 00:20:26,340
processing over it you can change your

00:20:24,030 --> 00:20:28,410
mind you might not even know today what

00:20:26,340 --> 00:20:30,030
you're going to do with your data are

00:20:28,410 --> 00:20:31,920
year from now so you have all the

00:20:30,030 --> 00:20:34,050
flexibility that specially Hadoop hoop

00:20:31,920 --> 00:20:36,960
group gives you because you have rotted

00:20:34,050 --> 00:20:39,150
in HDFS but you also have what is

00:20:36,960 --> 00:20:40,860
currently today the best to the best of

00:20:39,150 --> 00:20:43,080
our knowledge you know what's what's the

00:20:40,860 --> 00:20:44,730
most meaningful way how to index that

00:20:43,080 --> 00:20:46,290
data and solar and make it available to

00:20:44,730 --> 00:20:48,300
searches through that near real-time

00:20:46,290 --> 00:20:50,580
mechanism so it's not an either/or but

00:20:48,300 --> 00:20:52,050
it's a you know both of these things are

00:20:50,580 --> 00:20:55,940
available to you and typically what

00:20:52,050 --> 00:20:55,940
people use both in convene combination

00:20:56,120 --> 00:21:01,110
then flume is also reliable in the sense

00:20:59,310 --> 00:21:05,130
that you know you can fail over between

00:21:01,110 --> 00:21:08,850
hosts that go down it can also scale out

00:21:05,130 --> 00:21:11,220
in that you can petition it so many

00:21:08,850 --> 00:21:13,080
nodes can work on subsets of the in

00:21:11,220 --> 00:21:14,880
potato at the same time so this is a

00:21:13,080 --> 00:21:17,490
scalable and reliable ingestion system

00:21:14,880 --> 00:21:19,380
that works very well and the way it gets

00:21:17,490 --> 00:21:22,410
configured is by a little configuration

00:21:19,380 --> 00:21:24,030
file that refers to what we call a more

00:21:22,410 --> 00:21:26,280
flying configuration file yet another

00:21:24,030 --> 00:21:29,340
configuration file that essentially in

00:21:26,280 --> 00:21:31,380
some dsl small little dsl type like form

00:21:29,340 --> 00:21:32,910
specifies how the input data and you

00:21:31,380 --> 00:21:35,130
know whether it's a log line or whether

00:21:32,910 --> 00:21:37,290
it's a you know a photo or whether it's

00:21:35,130 --> 00:21:39,030
a microsoft word document or maybe it's

00:21:37,290 --> 00:21:44,520
like some clickstream data or whatever

00:21:39,030 --> 00:21:47,310
it may be how it gets transformed the

00:21:44,520 --> 00:21:48,540
other thing that people told us you know

00:21:47,310 --> 00:21:53,550
would be really interesting and really

00:21:48,540 --> 00:21:57,450
very valuable is to make a HBase be able

00:21:53,550 --> 00:21:59,940
to research over to a is to make a

00:21:57,450 --> 00:22:03,870
system that can search data that's

00:21:59,940 --> 00:22:06,240
stored in HBase so HBase is you know a

00:22:03,870 --> 00:22:08,310
no sequel store that is different from

00:22:06,240 --> 00:22:11,160
HDFS in that you know you can update

00:22:08,310 --> 00:22:15,090
data in it which you can in HDFS very

00:22:11,160 --> 00:22:17,700
easily so it's an incident it's a

00:22:15,090 --> 00:22:20,460
storage manager if you like that you

00:22:17,700 --> 00:22:23,490
can be used for old TP updates and so

00:22:20,460 --> 00:22:26,250
these old EP updates you know should be

00:22:23,490 --> 00:22:28,649
able should should be able to to get

00:22:26,250 --> 00:22:30,450
searched take like for example you know

00:22:28,649 --> 00:22:33,630
an online shopping store or something

00:22:30,450 --> 00:22:35,340
like an ebay type like system or so you

00:22:33,630 --> 00:22:37,889
can imagine that people as they update

00:22:35,340 --> 00:22:39,299
their data into database you know other

00:22:37,889 --> 00:22:40,679
applications would like to search that

00:22:39,299 --> 00:22:42,720
data and they would rather like to do

00:22:40,679 --> 00:22:44,850
that in year real time rather than say

00:22:42,720 --> 00:22:47,940
like an hour down the road or maybe a

00:22:44,850 --> 00:22:50,370
data on the road and so we came up with

00:22:47,940 --> 00:22:53,190
this way of plugging ourselves into HBS

00:22:50,370 --> 00:22:55,679
in one particular way that allows us to

00:22:53,190 --> 00:22:59,399
do this in a non intrusive way meaning

00:22:55,679 --> 00:23:01,500
that we don't actually perturb you know

00:22:59,399 --> 00:23:03,809
their reliability and and the

00:23:01,500 --> 00:23:06,059
performance of the HBase itself and the

00:23:03,809 --> 00:23:08,820
applications that I do updates in a

00:23:06,059 --> 00:23:10,380
space and we plugged ourselves in a way

00:23:08,820 --> 00:23:13,289
that's fairly flexible so you can

00:23:10,380 --> 00:23:15,090
specify how exactly you know the data

00:23:13,289 --> 00:23:17,309
should be indexed and transformed on the

00:23:15,090 --> 00:23:19,350
way it scales in that you can

00:23:17,309 --> 00:23:21,929
horizontally scale it out and use any

00:23:19,350 --> 00:23:23,760
number of nodes and processes to do that

00:23:21,929 --> 00:23:26,639
kind of indexing step and it's also

00:23:23,760 --> 00:23:30,480
reliable in that you know no data will

00:23:26,639 --> 00:23:31,799
ever get lost and so the data that

00:23:30,480 --> 00:23:33,990
hasn't been delivered yet to the

00:23:31,799 --> 00:23:35,789
indexing system will be retried and it

00:23:33,990 --> 00:23:38,539
will eventually make it intuitive solar

00:23:35,789 --> 00:23:41,880
so you can keep your solar index

00:23:38,539 --> 00:23:44,309
consistent with the HBase index as long

00:23:41,880 --> 00:23:45,720
as you allow for a little bit of lag so

00:23:44,309 --> 00:23:47,850
in other words this is an eventually

00:23:45,720 --> 00:23:49,409
consistent system not a system that is

00:23:47,850 --> 00:23:52,110
immediately consistent and the reason

00:23:49,409 --> 00:23:53,760
why is because for search applications

00:23:52,110 --> 00:23:57,630
more often than not indeed in the

00:23:53,760 --> 00:23:59,340
overwhelming percentage of cases this is

00:23:57,630 --> 00:24:01,200
good enough it's good enough to be

00:23:59,340 --> 00:24:03,330
eventually consistent as long as you

00:24:01,200 --> 00:24:06,269
will be consistent there I know in a

00:24:03,330 --> 00:24:08,460
fairly reasonable amount of time and the

00:24:06,269 --> 00:24:10,230
strong consistency is not required this

00:24:08,460 --> 00:24:13,559
allow is the key feature that allows us

00:24:10,230 --> 00:24:16,529
to put ourselves outside of the right

00:24:13,559 --> 00:24:19,080
path of HBase so we don't we don't

00:24:16,529 --> 00:24:21,000
impact another reliability and the

00:24:19,080 --> 00:24:24,649
performance of the primary application

00:24:21,000 --> 00:24:24,649
that applies updates to hbase

00:24:25,340 --> 00:24:30,740
again this component called the lily

00:24:29,210 --> 00:24:33,320
HBase indexer that I've been describing

00:24:30,740 --> 00:24:35,000
is configured through this little

00:24:33,320 --> 00:24:37,580
configuration file called more flying

00:24:35,000 --> 00:24:39,830
configuration file this dsl that where

00:24:37,580 --> 00:24:42,500
you can say like you know take that HP

00:24:39,830 --> 00:24:44,300
seller that the HBase row and here's how

00:24:42,500 --> 00:24:46,520
you transform it into a solar input

00:24:44,300 --> 00:24:48,590
document or you know it conforms to the

00:24:46,520 --> 00:24:50,150
leucine data model and you know what

00:24:48,590 --> 00:24:52,370
what the data what the data actually is

00:24:50,150 --> 00:24:54,860
that you want to index an indexing solar

00:24:52,370 --> 00:25:00,470
for that HP cell and how it should be

00:24:54,860 --> 00:25:02,510
analyzed and so forth this is actually

00:25:00,470 --> 00:25:04,850
work that we've done with our good

00:25:02,510 --> 00:25:06,410
colleagues at energy data we were very

00:25:04,850 --> 00:25:08,360
very happy to find out that they had

00:25:06,410 --> 00:25:10,790
goals that have a very similar to ours

00:25:08,360 --> 00:25:12,860
and so we set out to do this together as

00:25:10,790 --> 00:25:15,050
an open source project it's available in

00:25:12,860 --> 00:25:16,940
github under and under the apache

00:25:15,050 --> 00:25:18,980
license you're welcome to check that out

00:25:16,940 --> 00:25:21,670
and chime in and help us move this

00:25:18,980 --> 00:25:25,160
forward it's essentially you know

00:25:21,670 --> 00:25:28,130
implemented as a listener to the

00:25:25,160 --> 00:25:30,590
replication API that HBase has had for a

00:25:28,130 --> 00:25:34,100
very long time and that is by now very

00:25:30,590 --> 00:25:37,370
much hardened and reliable and in a

00:25:34,100 --> 00:25:39,980
heavy used by many customers so we

00:25:37,370 --> 00:25:42,380
pretend so H besides these API where you

00:25:39,980 --> 00:25:44,660
can say we're similar to say my sequel

00:25:42,380 --> 00:25:46,880
Oracle or indeed any any other database

00:25:44,660 --> 00:25:48,980
you can listen in to the to the oltp

00:25:46,880 --> 00:25:50,840
updates that are are applied to the base

00:25:48,980 --> 00:25:53,030
table you know and so that a replication

00:25:50,840 --> 00:25:56,630
API essentially look plays back you know

00:25:53,030 --> 00:25:59,090
all the edits that happened to to a to H

00:25:56,630 --> 00:26:01,070
base and we just simply you know plug

00:25:59,090 --> 00:26:04,760
ourselves in at that level and pretend

00:26:01,070 --> 00:26:06,230
to be a secondary HBase cluster you know

00:26:04,760 --> 00:26:09,490
which we are not but we should pretend

00:26:06,230 --> 00:26:09,490
to be an

00:26:15,760 --> 00:26:18,760
hbase.regionserver.blockcachecount

00:26:19,390 --> 00:26:24,920
rather than store it the data into into

00:26:22,520 --> 00:26:26,840
yet another secondary HBase we store it

00:26:24,920 --> 00:26:29,480
in solar you know after having

00:26:26,840 --> 00:26:33,670
transformed it using this this

00:26:29,480 --> 00:26:33,670
morpholine ETL step

00:26:34,280 --> 00:26:44,610
alright so after having a this I should

00:26:39,270 --> 00:26:46,800
I should mention also that we we early

00:26:44,610 --> 00:26:48,510
on we decided that you know you know

00:26:46,800 --> 00:26:52,620
Hadoop traditionally comes from comes

00:26:48,510 --> 00:26:54,480
from a world of batch for from a world

00:26:52,620 --> 00:26:56,730
of massive massively scalable batch

00:26:54,480 --> 00:26:58,530
processing and year relative was going

00:26:56,730 --> 00:27:00,990
to be important moving forward and

00:26:58,530 --> 00:27:03,690
becoming more and more important over

00:27:00,990 --> 00:27:05,640
time but the need for badge isn't going

00:27:03,690 --> 00:27:06,870
to go away anytime soon and indeed you

00:27:05,640 --> 00:27:09,390
know my impression is that you will

00:27:06,870 --> 00:27:11,160
never go away and then the more near

00:27:09,390 --> 00:27:12,900
real-time processing you do as a side

00:27:11,160 --> 00:27:15,240
effect the more data you're going to

00:27:12,900 --> 00:27:17,640
store and keep you know perhaps in some

00:27:15,240 --> 00:27:19,980
historic archive in HDFS and the more

00:27:17,640 --> 00:27:21,780
important actually a scale scalable

00:27:19,980 --> 00:27:24,210
batch processing is is going to be so

00:27:21,780 --> 00:27:26,880
batch isn't going going away at all and

00:27:24,210 --> 00:27:29,400
we need to support pat bad batch in a in

00:27:26,880 --> 00:27:30,960
a performant way it's just a fact of

00:27:29,400 --> 00:27:36,360
life the batch processing is more cost

00:27:30,960 --> 00:27:38,660
effective and 0 / a per unit of data

00:27:36,360 --> 00:27:41,040
item than a near real-time in a

00:27:38,660 --> 00:27:43,560
processing could ever be so bad for

00:27:41,040 --> 00:27:46,650
remains very important and so we

00:27:43,560 --> 00:27:48,360
integrated solar and MapReduce and the

00:27:46,650 --> 00:27:50,370
result is you know a system that again

00:27:48,360 --> 00:27:54,020
is very flexible in that you can specify

00:27:50,370 --> 00:27:56,040
how your data should be transformed and

00:27:54,020 --> 00:27:58,800
massaged into something that solar

00:27:56,040 --> 00:28:00,690
understands it's scalable in that it can

00:27:58,800 --> 00:28:02,640
route take advantage of all the mapper

00:28:00,690 --> 00:28:05,340
slots and reduces lots that you have on

00:28:02,640 --> 00:28:07,710
your HBase class on your map reduce

00:28:05,340 --> 00:28:09,660
cluster which can be you know very very

00:28:07,710 --> 00:28:11,640
large even though you might your solar

00:28:09,660 --> 00:28:13,560
installation might not be so so large

00:28:11,640 --> 00:28:17,730
you can still take take advantage of

00:28:13,560 --> 00:28:19,530
your a big MapReduce cluster that maybe

00:28:17,730 --> 00:28:21,990
is you know also used for other purposes

00:28:19,530 --> 00:28:24,390
and you will just use it for in some

00:28:21,990 --> 00:28:26,430
massive indexing stat for for a little

00:28:24,390 --> 00:28:29,010
while and then hand it off hand it back

00:28:26,430 --> 00:28:32,250
to some some other tenants on that

00:28:29,010 --> 00:28:35,310
cluster and so in this way by massively

00:28:32,250 --> 00:28:37,710
parallel izing the indexing step in some

00:28:35,310 --> 00:28:40,440
reliable way which is what you know

00:28:37,710 --> 00:28:43,650
MapReduce basically stands for you know

00:28:40,440 --> 00:28:45,600
we we allow people the flexibility to

00:28:43,650 --> 00:28:46,620
re-index their data without having to

00:28:45,600 --> 00:28:48,600
wait for a year which is

00:28:46,620 --> 00:28:50,910
really unacceptable or to change their

00:28:48,600 --> 00:28:52,559
mind later about how their you know

00:28:50,910 --> 00:28:54,870
their index we should really look like

00:28:52,559 --> 00:28:57,740
and so they're able to iterate you know

00:28:54,870 --> 00:29:01,230
on their data model without it being

00:28:57,740 --> 00:29:03,600
prohibitive and so the other interesting

00:29:01,230 --> 00:29:05,460
thing about combining a batch and year

00:29:03,600 --> 00:29:07,380
real-time here is that you were using

00:29:05,460 --> 00:29:10,200
this you can implement something like a

00:29:07,380 --> 00:29:13,050
lander architecture were you index you

00:29:10,200 --> 00:29:14,550
know you know the last year of data that

00:29:13,050 --> 00:29:17,580
you integrate that you have using

00:29:14,550 --> 00:29:20,010
MapReduce into solar and then going

00:29:17,580 --> 00:29:21,690
forward you know the the most recent

00:29:20,010 --> 00:29:24,210
data that's streaming through some

00:29:21,690 --> 00:29:27,570
online system with updates that happen

00:29:24,210 --> 00:29:30,270
you know air yeah that happened

00:29:27,570 --> 00:29:32,340
immediately though this this data can be

00:29:30,270 --> 00:29:34,320
interested in near real time using flume

00:29:32,340 --> 00:29:37,410
directly into solar so you can combine

00:29:34,320 --> 00:29:39,480
those two approaches to you know to

00:29:37,410 --> 00:29:40,980
index today ninety-nine percent of the

00:29:39,480 --> 00:29:43,920
data using MapReduce and the remaining

00:29:40,980 --> 00:29:46,440
remaining 1% which is to present it in

00:29:43,920 --> 00:29:48,809
that's generated right now in near

00:29:46,440 --> 00:29:51,270
real-time put them all into you know the

00:29:48,809 --> 00:29:53,100
same solar a cloud cluster and then

00:29:51,270 --> 00:29:55,710
answer queries that combine the historic

00:29:53,100 --> 00:30:00,570
theater and the most recent data using a

00:29:55,710 --> 00:30:04,740
uniform interface so that's a fairly

00:30:00,570 --> 00:30:07,830
interesting so the way it would you can

00:30:04,740 --> 00:30:10,350
also you can index data that's in HDFS

00:30:07,830 --> 00:30:12,660
just plain files whatever files they may

00:30:10,350 --> 00:30:14,580
be what are the sequence files the text

00:30:12,660 --> 00:30:16,470
files or whether it's parquet files or

00:30:14,580 --> 00:30:20,040
whether it's a ver files or you know

00:30:16,470 --> 00:30:22,950
some other arbitrary data format or you

00:30:20,040 --> 00:30:26,900
can you know index HBase tables using

00:30:22,950 --> 00:30:29,340
MapReduce in this in this scalable batch

00:30:26,900 --> 00:30:31,830
indexing step so the way it works is

00:30:29,340 --> 00:30:34,590
that essentially a bunch of mappers get

00:30:31,830 --> 00:30:36,600
fired off they munch you know take take

00:30:34,590 --> 00:30:39,000
take a subset of the input files you

00:30:36,600 --> 00:30:40,740
know transform the data produce solar

00:30:39,000 --> 00:30:43,470
input documents you know they get sent

00:30:40,740 --> 00:30:45,630
off to a bunch of reducers which run you

00:30:43,470 --> 00:30:47,640
know like on that MapReduce cluster the

00:30:45,630 --> 00:30:50,730
reducers actually each producer is like

00:30:47,640 --> 00:30:53,610
a small little you know solar shard in

00:30:50,730 --> 00:30:55,380
its own way like a micro chart it's it's

00:30:53,610 --> 00:30:56,520
it's a fully fully functional solar

00:30:55,380 --> 00:30:59,010
server that just happens to be

00:30:56,520 --> 00:31:00,960
instantiated temporarily indexes data

00:30:59,010 --> 00:31:02,730
writes it to HDFS and

00:31:00,960 --> 00:31:04,919
and when all the reduces are finished

00:31:02,730 --> 00:31:06,779
you can optionally you know merge a

00:31:04,919 --> 00:31:08,909
large number of charge into a smaller

00:31:06,779 --> 00:31:10,500
number of charge meaning that the number

00:31:08,909 --> 00:31:12,840
of shots that you desire for your solar

00:31:10,500 --> 00:31:15,570
for your solar cluster and then you can

00:31:12,840 --> 00:31:18,360
using a go live step merge those

00:31:15,570 --> 00:31:21,419
segments merge those indexes into the

00:31:18,360 --> 00:31:23,490
solar cloud as an as a final step and

00:31:21,419 --> 00:31:25,200
that final step is optional you don't

00:31:23,490 --> 00:31:27,720
have to do that if you're happy to just

00:31:25,200 --> 00:31:29,610
bring up your solar service in the way

00:31:27,720 --> 00:31:31,980
mark already suggested that just like

00:31:29,610 --> 00:31:34,260
read data from HDFS you can do that too

00:31:31,980 --> 00:31:36,470
or you know using that goal of step you

00:31:34,260 --> 00:31:43,740
can merge the data into a live customer

00:31:36,470 --> 00:31:46,529
facing solid Rochester I already talked

00:31:43,740 --> 00:31:47,789
about most of these things here one of

00:31:46,529 --> 00:31:49,169
the interesting things ended up a little

00:31:47,789 --> 00:31:51,510
bit more on the technical side is that

00:31:49,169 --> 00:31:53,159
you know indeed you can use more reduces

00:31:51,510 --> 00:31:54,600
that you have solar charge doing the

00:31:53,159 --> 00:31:57,210
indexing this is pretty interesting

00:31:54,600 --> 00:32:00,090
because it turns out that you know

00:31:57,210 --> 00:32:02,700
indexing is by and large a CPU bound

00:32:00,090 --> 00:32:05,309
step so it makes sense to use all of the

00:32:02,700 --> 00:32:06,750
CPU cores that you have your available

00:32:05,309 --> 00:32:08,820
in your cluster if that's what you

00:32:06,750 --> 00:32:12,299
desire according to your you know your

00:32:08,820 --> 00:32:14,399
your administration and policies if

00:32:12,299 --> 00:32:16,799
that's what you desire to do the

00:32:14,399 --> 00:32:19,260
indexing so you can use all reduces lots

00:32:16,799 --> 00:32:21,059
on your cluster if you want to do the

00:32:19,260 --> 00:32:23,279
indexing and then there's a final

00:32:21,059 --> 00:32:25,169
merging step to merge the segment's into

00:32:23,279 --> 00:32:27,450
a smaller number of segments which is

00:32:25,169 --> 00:32:31,230
comparatively less expensive than the

00:32:27,450 --> 00:32:33,299
indexing into in in in the reducers

00:32:31,230 --> 00:32:35,190
itself so this is why these works in

00:32:33,299 --> 00:32:37,260
such a scalable manner much more

00:32:35,190 --> 00:32:38,850
scalable than you know having a map or

00:32:37,260 --> 00:32:42,750
only job they would send the data

00:32:38,850 --> 00:32:46,080
directly using solo che into a solar

00:32:42,750 --> 00:32:48,630
client cluster all right a couple of

00:32:46,080 --> 00:32:50,610
minutes on the little library that we

00:32:48,630 --> 00:32:53,039
are that we developed in or for that

00:32:50,610 --> 00:32:55,470
purpose there's a little library for

00:32:53,039 --> 00:32:57,570
extraction transformation and loading in

00:32:55,470 --> 00:32:59,580
a streaming manner that we developed is

00:32:57,570 --> 00:33:02,789
called kite morph Lions it's an immortal

00:32:59,580 --> 00:33:04,470
and life so Java library that was

00:33:02,789 --> 00:33:07,380
developed as part of the cloud there a

00:33:04,470 --> 00:33:09,419
search project and since we found out

00:33:07,380 --> 00:33:11,399
you know that is actually applicable in

00:33:09,419 --> 00:33:12,870
other contexts as well we you know so

00:33:11,399 --> 00:33:15,759
like

00:33:12,870 --> 00:33:18,190
moved it out of cloud air search and put

00:33:15,759 --> 00:33:20,649
it into a general-purpose reusable forum

00:33:18,190 --> 00:33:22,419
such as a kite and the way it works is

00:33:20,649 --> 00:33:24,460
like and it's actually very simple it's

00:33:22,419 --> 00:33:25,929
a Java library that allows you to take

00:33:24,460 --> 00:33:27,759
any take data from any kind of data

00:33:25,929 --> 00:33:30,220
source and process it in whatever

00:33:27,759 --> 00:33:32,049
arbitrary way and then sent the results

00:33:30,220 --> 00:33:33,730
you know into some kind of target and

00:33:32,049 --> 00:33:35,230
whatever that target maybe you can you

00:33:33,730 --> 00:33:37,450
can you can plug yourself in there

00:33:35,230 --> 00:33:40,720
typically solar or it's HDFS or it might

00:33:37,450 --> 00:33:42,100
be HBase or you know whatever and so at

00:33:40,720 --> 00:33:44,200
its core it's basically a chain of

00:33:42,100 --> 00:33:46,210
commands that take some in potato it's

00:33:44,200 --> 00:33:48,039
just like similar to unix pipelines you

00:33:46,210 --> 00:33:49,419
know at least conceptually take some you

00:33:48,039 --> 00:33:51,639
know each of the components take some in

00:33:49,419 --> 00:33:53,649
potato munches it spit something out and

00:33:51,639 --> 00:33:55,389
the next component you know again takes

00:33:53,649 --> 00:33:57,820
the output of the previous component

00:33:55,389 --> 00:33:59,649
punches it in some way transforms it now

00:33:57,820 --> 00:34:01,870
that's something with it and maybe

00:33:59,649 --> 00:34:03,190
cleans the data or annotate it you know

00:34:01,870 --> 00:34:05,710
and then sends it to the next command

00:34:03,190 --> 00:34:08,169
and that that command might be a command

00:34:05,710 --> 00:34:10,929
that's that actually sends the data into

00:34:08,169 --> 00:34:14,079
solar you know such as the load solar

00:34:10,929 --> 00:34:16,899
command so using this this mechanism

00:34:14,079 --> 00:34:19,659
people are able to describe you know

00:34:16,899 --> 00:34:21,520
like sort of item one item at a time

00:34:19,659 --> 00:34:25,060
type like transformations in a very

00:34:21,520 --> 00:34:27,040
simple way and lots of people are using

00:34:25,060 --> 00:34:28,510
this especially because it doesn't

00:34:27,040 --> 00:34:31,179
actually require any kind of you know

00:34:28,510 --> 00:34:33,310
sophisticated programming it's it's a

00:34:31,179 --> 00:34:35,589
DSL that can be used but simply by

00:34:33,310 --> 00:34:37,839
editing a configuration file and so it's

00:34:35,589 --> 00:34:39,760
fairly approachable and easy to get

00:34:37,839 --> 00:34:42,810
started with and people have had lots of

00:34:39,760 --> 00:34:45,520
success indexing data in you know in

00:34:42,810 --> 00:34:50,950
various manners without actually having

00:34:45,520 --> 00:34:53,379
to be Java programmers pre-flight to

00:34:50,950 --> 00:34:55,780
mention that you know you could use this

00:34:53,379 --> 00:34:57,190
library not just 2 into 2 sin theta in

00:34:55,780 --> 00:34:59,800
the solar cloud but into your own

00:34:57,190 --> 00:35:02,319
application it's really you know has no

00:34:59,800 --> 00:35:04,270
dependency on solar cloud at all except

00:35:02,319 --> 00:35:07,170
for that there is one optional module

00:35:04,270 --> 00:35:09,430
you know for solar and that module is

00:35:07,170 --> 00:35:10,900
responsible to implement the commands

00:35:09,430 --> 00:35:12,970
you know that relate to loading data

00:35:10,900 --> 00:35:16,089
into solar but all the other commands

00:35:12,970 --> 00:35:18,099
you know are in different maven modules

00:35:16,089 --> 00:35:20,740
and so you can use this independently

00:35:18,099 --> 00:35:23,680
for other search service if to if that's

00:35:20,740 --> 00:35:25,780
what you wanted to do here's a brief

00:35:23,680 --> 00:35:29,290
example of

00:35:25,780 --> 00:35:31,420
more flying configuration file that you

00:35:29,290 --> 00:35:34,090
know say assume you have a simple line

00:35:31,420 --> 00:35:35,830
you know from some textual log file the

00:35:34,090 --> 00:35:38,440
typical kind of thing that has you know

00:35:35,830 --> 00:35:40,330
like a date in there and maybe some a

00:35:38,440 --> 00:35:42,400
bunch of strings that relate to who what

00:35:40,330 --> 00:35:44,020
process wrote this stuff is just looked

00:35:42,400 --> 00:35:45,910
ye or something like this and and a

00:35:44,020 --> 00:35:49,270
message or so in some say me say me

00:35:45,910 --> 00:35:51,040
informal you know format and you'd like

00:35:49,270 --> 00:35:53,860
to extract you know a bunch of fields

00:35:51,040 --> 00:35:55,480
out of this you know select a priority

00:35:53,860 --> 00:35:58,390
times and hostname so forth and so forth

00:35:55,480 --> 00:36:00,460
people usually reside to regular

00:35:58,390 --> 00:36:02,590
expressions to to parse this stuff in

00:36:00,460 --> 00:36:04,630
more or less nasty manners out of these

00:36:02,590 --> 00:36:06,580
text files that have they have never

00:36:04,630 --> 00:36:09,640
been you know implemented you know with

00:36:06,580 --> 00:36:11,740
much of an API in mind and so there's

00:36:09,640 --> 00:36:14,620
one command such as that's called garage

00:36:11,740 --> 00:36:17,620
and you can specify there some rules as

00:36:14,620 --> 00:36:19,600
to know how some regular expressions as

00:36:17,620 --> 00:36:21,370
to how to extract the data out of that

00:36:19,600 --> 00:36:23,140
text line and where a field starts and

00:36:21,370 --> 00:36:24,520
where it stops and so forth basically

00:36:23,140 --> 00:36:26,920
the way it works is like it's like a

00:36:24,520 --> 00:36:28,360
it's like a convenient you know user

00:36:26,920 --> 00:36:31,300
interface to regular expressions you

00:36:28,360 --> 00:36:33,520
don't specify a regular expression by

00:36:31,300 --> 00:36:35,530
writing it down but rather by specify a

00:36:33,520 --> 00:36:38,230
regular expression by name in this case

00:36:35,530 --> 00:36:40,870
like say like positive integer or syslog

00:36:38,230 --> 00:36:43,420
time stamp or syslog host and that

00:36:40,870 --> 00:36:45,190
really is a regular expression that's in

00:36:43,420 --> 00:36:46,420
some external configuration file that

00:36:45,190 --> 00:36:48,520
you don't have to write that somebody

00:36:46,420 --> 00:36:50,620
else already wrote so you can reuse

00:36:48,520 --> 00:36:52,600
regular expressions simply by you know

00:36:50,620 --> 00:36:53,920
using them by name and you might be

00:36:52,600 --> 00:36:55,660
familiar with this because this is

00:36:53,920 --> 00:36:58,270
actually as a matter of fact precisely

00:36:55,660 --> 00:36:59,920
what locks tinged us and we felt free no

00:36:58,270 --> 00:37:02,530
Twp you know this great idea that the

00:36:59,920 --> 00:37:04,390
lock says people had and you know we

00:37:02,530 --> 00:37:06,190
provide exactly the same kind of feature

00:37:04,390 --> 00:37:08,800
set that locks those users you know to

00:37:06,190 --> 00:37:13,020
do this it's a it's a great idea and we

00:37:08,800 --> 00:37:16,900
were happy to take advantage of of that

00:37:13,020 --> 00:37:18,820
similar leader commands say like to you

00:37:16,900 --> 00:37:22,330
know split a file into a records you

00:37:18,820 --> 00:37:24,280
know in case of women records are spread

00:37:22,330 --> 00:37:26,320
across multiple lines and you don't spar

00:37:24,280 --> 00:37:29,110
system line by line but rather you know

00:37:26,320 --> 00:37:33,250
multi-line thing so there's a variety of

00:37:29,110 --> 00:37:35,710
of of commands in there for all sorts of

00:37:33,250 --> 00:37:38,650
purposes that you can you can pick up

00:37:35,710 --> 00:37:39,369
and sort of sort of satisfies the 8020

00:37:38,650 --> 00:37:41,670
rule

00:37:39,369 --> 00:37:45,220
if there's stuff that isn't part of the

00:37:41,670 --> 00:37:47,859
predefined you know functionality set no

00:37:45,220 --> 00:37:50,079
you can extend it in the library in a

00:37:47,859 --> 00:37:53,589
bunch of ways the easiest way is to just

00:37:50,079 --> 00:37:55,420
write some Java code as a snippet sort

00:37:53,589 --> 00:37:57,849
of like directly in line in that

00:37:55,420 --> 00:38:00,519
configuration file and it gets compiled

00:37:57,849 --> 00:38:02,259
on the fly you know as the program runs

00:38:00,519 --> 00:38:05,049
and then you know gets compiled in the

00:38:02,259 --> 00:38:07,720
regular a java bytecodes you know and

00:38:05,049 --> 00:38:10,630
then executed at runtime and so you can

00:38:07,720 --> 00:38:12,819
if you're all your logic is like lower

00:38:10,630 --> 00:38:14,799
casing some strings you know or doing a

00:38:12,819 --> 00:38:16,480
little bit of you know processing and

00:38:14,799 --> 00:38:19,299
one or two or three or four five lines

00:38:16,480 --> 00:38:21,880
of Java it's entirely you know rational

00:38:19,299 --> 00:38:24,099
to just dump a little bit of Java code

00:38:21,880 --> 00:38:25,839
right into the configuration file and so

00:38:24,099 --> 00:38:29,259
that gets gets executed and takes care

00:38:25,839 --> 00:38:32,799
of your custom functionality there is a

00:38:29,259 --> 00:38:34,869
as i try to hint that you know the usual

00:38:32,799 --> 00:38:38,289
there's commands with the usual suspects

00:38:34,869 --> 00:38:40,900
in the Hadoop ecosystem like parque

00:38:38,289 --> 00:38:44,170
files are 0 files CSV and text and so

00:38:40,900 --> 00:38:46,720
forth Jason XML and then you know we

00:38:44,170 --> 00:38:48,369
also import into teka project so

00:38:46,720 --> 00:38:50,980
whatever parses are available as part of

00:38:48,369 --> 00:38:54,039
tika you can use those too so you know

00:38:50,980 --> 00:38:55,599
they're there are thousands of parcels

00:38:54,039 --> 00:38:57,579
out there that you don't want to write

00:38:55,599 --> 00:38:59,230
trust me but you know you can take

00:38:57,579 --> 00:39:00,549
advantage you know if tika with which

00:38:59,230 --> 00:39:02,589
has already done you know a large

00:39:00,549 --> 00:39:05,019
fraction of the hard work out there and

00:39:02,589 --> 00:39:08,319
so we reuse that as i mentioned HBase

00:39:05,019 --> 00:39:09,970
rose sales and importantly you can also

00:39:08,319 --> 00:39:11,499
write your own commands of course so you

00:39:09,970 --> 00:39:13,359
can plug in your own command and then

00:39:11,499 --> 00:39:15,369
that command does it's just a regular

00:39:13,359 --> 00:39:17,140
Java class and it would take like you

00:39:15,369 --> 00:39:20,440
know 10 lines of code and does whatever

00:39:17,140 --> 00:39:23,349
you want so that's essentially the idea

00:39:20,440 --> 00:39:25,660
behind most lines a bunch of other

00:39:23,349 --> 00:39:28,539
things you know like geo super Cheers

00:39:25,660 --> 00:39:30,460
report I you know and so forth and I'm

00:39:28,539 --> 00:39:32,829
not going to go to detail that the way

00:39:30,460 --> 00:39:34,690
it works is in regarding performance is

00:39:32,829 --> 00:39:36,579
that a very simple approach similar to

00:39:34,690 --> 00:39:40,059
the map it whose approach you know each

00:39:36,579 --> 00:39:42,400
more flying is really compiled on the

00:39:40,059 --> 00:39:44,680
fly and runs in a single thread all the

00:39:42,400 --> 00:39:48,160
commands run in the very same single

00:39:44,680 --> 00:39:49,900
thread and sew handing off data from one

00:39:48,160 --> 00:39:52,539
command to the other is truly just a

00:39:49,900 --> 00:39:53,050
method call there's no serialization in

00:39:52,539 --> 00:39:55,090
between

00:39:53,050 --> 00:39:57,130
there's no Q in between there's no

00:39:55,090 --> 00:39:59,530
threat context switches no nothing it's

00:39:57,130 --> 00:40:01,150
just like you know one object calling

00:39:59,530 --> 00:40:02,980
another object with nothing in between

00:40:01,150 --> 00:40:06,310
this is the reason why this is really

00:40:02,980 --> 00:40:08,590
fast and so the way you get scale out is

00:40:06,310 --> 00:40:10,840
by simply running many instances of the

00:40:08,590 --> 00:40:14,380
more flying typically one per cpu core a

00:40:10,840 --> 00:40:17,620
two per cpu core among on many nodes so

00:40:14,380 --> 00:40:22,510
that's a typical kind of embarrassing

00:40:17,620 --> 00:40:26,260
lee parallel processing model okay and

00:40:22,510 --> 00:40:29,500
then as Mark already hinted you know

00:40:26,260 --> 00:40:32,710
there's a nice uui that's sits on top of

00:40:29,500 --> 00:40:34,210
it that that you will use presumably to

00:40:32,710 --> 00:40:37,330
get started super easy to get started

00:40:34,210 --> 00:40:39,010
very very sweet and sexy but eventually

00:40:37,330 --> 00:40:41,080
you might actually end up with your own

00:40:39,010 --> 00:40:42,370
UI and you know he can you know of

00:40:41,080 --> 00:40:44,410
course you don't have to use that you

00:40:42,370 --> 00:40:46,900
know any solar application that runs on

00:40:44,410 --> 00:40:49,000
standard solar will also run on Cloudera

00:40:46,900 --> 00:40:50,440
search and sodas there's like no locking

00:40:49,000 --> 00:40:52,530
or anything like this but this is a good

00:40:50,440 --> 00:40:55,030
starting point we also integrated a

00:40:52,530 --> 00:40:58,660
search with security infrastructure

00:40:55,030 --> 00:41:00,700
called Apache century and so we worked

00:40:58,660 --> 00:41:03,910
on cluster level access control index

00:41:00,700 --> 00:41:05,530
level access control the latest thing is

00:41:03,910 --> 00:41:07,120
document level access control and then

00:41:05,530 --> 00:41:08,740
going forward there is going to be some

00:41:07,120 --> 00:41:10,780
work on field level access control as

00:41:08,740 --> 00:41:13,060
well as well to make sure that the only

00:41:10,780 --> 00:41:14,650
substance of data are available to the

00:41:13,060 --> 00:41:16,810
right kind of people with the right kind

00:41:14,650 --> 00:41:20,200
of integrate kind of roles and

00:41:16,810 --> 00:41:21,640
permissions and then you know the way it

00:41:20,200 --> 00:41:23,260
gets managed is through clattering

00:41:21,640 --> 00:41:25,360
manager I think that you know like I

00:41:23,260 --> 00:41:27,250
mean the basic the basic scale out

00:41:25,360 --> 00:41:29,500
preposition is that you can scale out

00:41:27,250 --> 00:41:32,590
your data in your cluster and whatever

00:41:29,500 --> 00:41:34,720
it is that you're doing by a factor XA

00:41:32,590 --> 00:41:36,310
factor 10 in fact 100 without actually

00:41:34,720 --> 00:41:37,780
having to employ 10 times more people or

00:41:36,310 --> 00:41:39,790
hundred times more people that's you

00:41:37,780 --> 00:41:42,100
know if you have to hire a no x times

00:41:39,790 --> 00:41:44,800
more people to do you know x times more

00:41:42,100 --> 00:41:46,720
more data working that's just a red flag

00:41:44,800 --> 00:41:49,060
it's not going to happen and so cloudera

00:41:46,720 --> 00:41:50,530
manager is like the letter answer to

00:41:49,060 --> 00:41:53,110
this you know where we say like you know

00:41:50,530 --> 00:41:55,480
you can operate manage you know your

00:41:53,110 --> 00:41:57,340
cluster without having to you employ a

00:41:55,480 --> 00:41:59,560
huge amount of new human resources and

00:41:57,340 --> 00:42:03,220
so in in doing so you'll save a lot of

00:41:59,560 --> 00:42:05,230
time and effort and so that's about it

00:42:03,220 --> 00:42:08,470
you can try this out you know there

00:42:05,230 --> 00:42:10,740
a new project that recently went live

00:42:08,470 --> 00:42:13,270
called Cloudera life that's maybe the

00:42:10,740 --> 00:42:14,890
the easiest way to get started is

00:42:13,270 --> 00:42:17,619
basically just you know an online

00:42:14,890 --> 00:42:19,900
website women of super already running

00:42:17,619 --> 00:42:22,869
an instantiated and you can see with

00:42:19,900 --> 00:42:25,420
some a bunch of sample data sets and all

00:42:22,869 --> 00:42:27,070
of the you know services already up and

00:42:25,420 --> 00:42:29,320
running and you can just click around

00:42:27,070 --> 00:42:31,390
there and you know do your own your own

00:42:29,320 --> 00:42:33,010
thing and try it out and then maybe you

00:42:31,390 --> 00:42:36,730
know later on dry which on machine or

00:42:33,010 --> 00:42:39,760
whatever so it's a new easy way to to

00:42:36,730 --> 00:42:41,170
see how to our works in practice alright

00:42:39,760 --> 00:42:43,060
thanks very much i think we've used up

00:42:41,170 --> 00:42:44,170
by our time i hope we have still have

00:42:43,060 --> 00:42:45,609
time for some questions you know

00:42:44,170 --> 00:42:47,500
considering that this is the last

00:42:45,609 --> 00:42:51,330
session so we get the little bit of an

00:42:47,500 --> 00:42:51,330
advantage over everybody else out there

00:42:53,940 --> 00:43:10,000
okay questions are you planning to run

00:43:07,840 --> 00:43:17,830
solo on yon as well as it a standalone

00:43:10,000 --> 00:43:20,290
demon we think with we're thinking about

00:43:17,830 --> 00:43:23,140
it at this time you know we're not

00:43:20,290 --> 00:43:26,070
running on yarn precisely because you

00:43:23,140 --> 00:43:29,920
know as you know like people usually

00:43:26,070 --> 00:43:32,020
expect solo two key results in pretty

00:43:29,920 --> 00:43:34,090
much millisecond time frame in a very

00:43:32,020 --> 00:43:36,900
very low latency results you know for

00:43:34,090 --> 00:43:39,790
interactive theories and you know

00:43:36,900 --> 00:43:41,290
integrating I know solar with a resource

00:43:39,790 --> 00:43:52,630
management system that's more a

00:43:41,290 --> 00:43:54,130
heavyweight so integrating into a system

00:43:52,630 --> 00:43:56,109
that that's more heavyweights such as

00:43:54,130 --> 00:43:58,119
yarn is a bit of a challenge so at this

00:43:56,109 --> 00:43:59,859
point we are not providing yarn

00:43:58,119 --> 00:44:02,109
integration but we're exploring and

00:43:59,859 --> 00:44:04,690
considering in like how what's best way

00:44:02,109 --> 00:44:06,970
to move form it is definitely the idea

00:44:04,690 --> 00:44:09,100
is that we integrate in a resource

00:44:06,970 --> 00:44:11,050
control system at this point in time it

00:44:09,100 --> 00:44:12,150
is really just in look at the operating

00:44:11,050 --> 00:44:14,250
system

00:44:12,150 --> 00:44:16,950
you know where you know you're

00:44:14,250 --> 00:44:19,049
statically in partition you know the

00:44:16,950 --> 00:44:21,119
resources rather than dynamically

00:44:19,049 --> 00:44:22,920
because this is justin billion no not

00:44:21,119 --> 00:44:29,279
enough time to switch in a millisecond

00:44:22,920 --> 00:44:31,740
time frame um yes maybe one for mark but

00:44:29,279 --> 00:44:39,480
you mentioned that celeron HDFS had

00:44:31,740 --> 00:44:41,579
before okay oh hello hi one for mark you

00:44:39,480 --> 00:44:43,319
mentioned that sullen HDFS had

00:44:41,579 --> 00:44:45,720
performance fairly similar to the local

00:44:43,319 --> 00:44:49,079
phone system could you elaborate on that

00:44:45,720 --> 00:44:51,599
a bit yeah I mean we haven't done their

00:44:49,079 --> 00:44:53,130
extensive testing to where I i I'd be

00:44:51,599 --> 00:44:55,890
willing to give like conclusive numbers

00:44:53,130 --> 00:44:59,000
but in kind of my like you know kind of

00:44:55,890 --> 00:45:01,829
off the cuff testing I've generally seen

00:44:59,000 --> 00:45:05,099
you know maybe a ten to fifteen percent

00:45:01,829 --> 00:45:06,630
performance loss although there's

00:45:05,099 --> 00:45:09,420
there's a lot of optimizations that we

00:45:06,630 --> 00:45:13,020
haven't done yet we haven't turned on

00:45:09,420 --> 00:45:14,849
like you know short circuit reads we

00:45:13,020 --> 00:45:18,000
have in there's various kind of coding

00:45:14,849 --> 00:45:19,950
optimizations actually one of our HDFS

00:45:18,000 --> 00:45:21,599
guys Todd with Kim I was looking through

00:45:19,950 --> 00:45:24,599
some of the code that we did and he had

00:45:21,599 --> 00:45:27,450
various ideas for some speed ups so

00:45:24,599 --> 00:45:29,400
right now it's actually been pretty

00:45:27,450 --> 00:45:31,589
close but we think that that will be

00:45:29,400 --> 00:45:33,690
able to pretty much match it in a lot of

00:45:31,589 --> 00:45:36,329
cases too because people using Hadoop

00:45:33,690 --> 00:45:38,819
tend to have like 12 drives in HDFS kind

00:45:36,329 --> 00:45:41,670
of stripes across that you can actually

00:45:38,819 --> 00:45:43,079
see greater performance although then

00:45:41,670 --> 00:45:46,049
it's not really in an apples-to-apples

00:45:43,079 --> 00:45:49,829
comparison on so there is some overhead

00:45:46,049 --> 00:45:52,319
our goal is to actually you know meet

00:45:49,829 --> 00:45:54,270
local file system performance exactly

00:45:52,319 --> 00:45:55,950
and we think with with a couple changes

00:45:54,270 --> 00:45:58,529
we can eventually get there we've

00:45:55,950 --> 00:46:00,510
definitely focused more on I'm kind of

00:45:58,529 --> 00:46:03,480
stability and initial features over

00:46:00,510 --> 00:46:05,339
performance so far though okay follow-up

00:46:03,480 --> 00:46:07,740
question with do you think you'll ever

00:46:05,339 --> 00:46:10,829
support SSDs as well it's all kind of

00:46:07,740 --> 00:46:14,430
splits HDFS to get kind of faster disk

00:46:10,829 --> 00:46:17,490
i/o for the solo instances so will it

00:46:14,430 --> 00:46:20,190
will be on a single HDFS Wolfgang's are

00:46:17,490 --> 00:46:22,420
the end of SSDs

00:46:20,190 --> 00:46:25,900
there's nothing that prevents you today

00:46:22,420 --> 00:46:28,150
too you know configure and provision and

00:46:25,900 --> 00:46:30,940
HDFS cluster sitting on SSDs if that's

00:46:28,150 --> 00:46:32,290
what you want to do i do know that going

00:46:30,940 --> 00:46:34,630
forward you know people are thinking

00:46:32,290 --> 00:46:36,910
about introducing hsm there's a

00:46:34,630 --> 00:46:39,790
hierarchical storage management instead

00:46:36,910 --> 00:46:42,310
into a tube were you know you could you

00:46:39,790 --> 00:46:44,950
know combined you know spindles you know

00:46:42,310 --> 00:46:47,710
rotating disk and just ease and rob and

00:46:44,950 --> 00:46:50,230
perhaps nug non-volatile memory and her

00:46:47,710 --> 00:46:57,190
other storage tiers somewhere somewhere

00:46:50,230 --> 00:47:00,070
in between but that is future talk hi

00:46:57,190 --> 00:47:02,580
have you done any stats run lower

00:47:00,070 --> 00:47:05,740
streaming files from s3 as inputs

00:47:02,580 --> 00:47:07,600
because in in one of the case i am

00:47:05,740 --> 00:47:09,730
trying like we have millions of files in

00:47:07,600 --> 00:47:14,170
s3 and it was really taking a lot of

00:47:09,730 --> 00:47:17,020
time to complete the whole indexing we

00:47:14,170 --> 00:47:18,430
don't have an s3 connector something out

00:47:17,020 --> 00:47:21,790
of the box you know we don't provide

00:47:18,430 --> 00:47:24,240
functionality of that but having said

00:47:21,790 --> 00:47:27,160
that i don't anticipate you know that

00:47:24,240 --> 00:47:30,390
any slower than whenever the network

00:47:27,160 --> 00:47:30,390
link it gives you a coming out of

00:47:33,180 --> 00:47:40,060
currently the marine dexter tool streams

00:47:37,180 --> 00:47:42,130
their data in the morin map runner it

00:47:40,060 --> 00:47:44,920
just reached a whole file and then

00:47:42,130 --> 00:47:46,870
indexes it so why not we had a kind of a

00:47:44,920 --> 00:47:48,550
combined file input format or something

00:47:46,870 --> 00:47:51,640
because each file would not fill the

00:47:48,550 --> 00:47:53,890
whole life hdfs block so that you know

00:47:51,640 --> 00:47:56,680
the split allocations and other things

00:47:53,890 --> 00:47:58,990
which are due provides so thus the file

00:47:56,680 --> 00:48:01,000
is being streamed read in the streaming

00:47:58,990 --> 00:48:03,130
fashion you know it's not like read all

00:48:01,000 --> 00:48:06,040
into main memory and then once what's my

00:48:03,130 --> 00:48:08,530
main memory gets indexed so it is read

00:48:06,040 --> 00:48:10,680
in a string fashion if that's the

00:48:08,530 --> 00:48:10,680
question

00:48:35,979 --> 00:48:39,650
right so the current production

00:48:38,269 --> 00:48:42,439
implementation is optimized for

00:48:39,650 --> 00:48:45,799
flexibility in that it allows you to to

00:48:42,439 --> 00:48:47,869
index and process arbitrary input data

00:48:45,799 --> 00:48:49,910
formats including formats that are not

00:48:47,869 --> 00:48:52,489
suitable in the in the head tube sense

00:48:49,910 --> 00:48:54,769
so like you know like multi-line you

00:48:52,489 --> 00:48:56,539
know you know input formats you know

00:48:54,769 --> 00:48:58,609
where you know like sometimes you know a

00:48:56,539 --> 00:48:59,959
record is like five lines line sometimes

00:48:58,609 --> 00:49:03,229
it's like three lines lon and things

00:48:59,959 --> 00:49:05,299
like that so our CSV files you know this

00:49:03,229 --> 00:49:08,749
man multiple lines lines and so forth

00:49:05,299 --> 00:49:12,829
but so it's optimized for flexibility

00:49:08,749 --> 00:49:15,650
and also reads you know from reads one

00:49:12,829 --> 00:49:16,969
file in one thread but we also have a

00:49:15,650 --> 00:49:19,309
tool in the works you know that allows

00:49:16,969 --> 00:49:21,199
you to combine you know splittable input

00:49:19,309 --> 00:49:24,199
files and non splittable until input

00:49:21,199 --> 00:49:27,439
files so that splittable input files can

00:49:24,199 --> 00:49:31,339
be distributed among as many task as

00:49:27,439 --> 00:49:33,589
they are input splits okay thank you

00:49:31,339 --> 00:49:35,179
very much and I think we move on to the

00:49:33,589 --> 00:49:37,959
party now and you can ask them questions

00:49:35,179 --> 00:49:37,959

YouTube URL: https://www.youtube.com/watch?v=DVo1SLbhNIE


