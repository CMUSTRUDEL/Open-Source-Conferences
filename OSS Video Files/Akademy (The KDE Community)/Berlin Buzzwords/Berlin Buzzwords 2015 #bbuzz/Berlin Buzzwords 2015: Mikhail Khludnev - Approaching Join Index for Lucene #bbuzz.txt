Title: Berlin Buzzwords 2015: Mikhail Khludnev - Approaching Join Index for Lucene #bbuzz
Publication date: 2015-06-03
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	Lucene works great with independent text documents, but real life problems often require to handle relations between documents. Aside of several workarounds, like term encodings, field collapsing or term positions, we have two mainstream approaches to handle document relations: join and block-join. Both have their downsides. Join lacks performance, while block-join makes is really expensive to handle index updates, since it requires to wipe a whole block of related documents.

This session presents an attempt to apply join index, borrowed from RDBMS world, for addressing drawbacks of the both join approaches currently present in Lucene. We will look into the idea per se, possible implementation approaches, and review the benchmarking results.     

Read more:
https://2015.berlinbuzzwords.de/session/approaching-join-index-lucene

About Mikhail Khludnev:
https://2015.berlinbuzzwords.de/users/mikhail-khludnev

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:05,530 --> 00:00:16,360
thank you hi guys how are you do you

00:00:10,389 --> 00:00:18,250
like coffee and Kate ok my name is

00:00:16,360 --> 00:00:20,890
Victor food if I'm want to talk about

00:00:18,250 --> 00:00:23,950
joints in racine about different giant

00:00:20,890 --> 00:00:32,529
of limitation in racine I work in

00:00:23,950 --> 00:00:34,829
company does it work some hell I work in

00:00:32,529 --> 00:00:38,800
company group great dynamics our

00:00:34,829 --> 00:00:42,300
customers are American retailers our

00:00:38,800 --> 00:00:44,499
headquarter in Silicon Valley we used to

00:00:42,300 --> 00:00:48,999
provide in different engineering

00:00:44,499 --> 00:00:51,670
services for taylors we we do back-end

00:00:48,999 --> 00:00:55,359
development now we do data analytics for

00:00:51,670 --> 00:00:59,769
internet advertisement and I've work in

00:00:55,359 --> 00:01:03,429
team which delivers a search button for

00:00:59,769 --> 00:01:07,240
e-commerce for searching in product

00:01:03,429 --> 00:01:11,649
catalogs for customers I'm a principal

00:01:07,240 --> 00:01:15,070
engineer I spoke in last Lucy in

00:01:11,649 --> 00:01:20,259
conferences I made several little

00:01:15,070 --> 00:01:23,140
contribution into solar code base for

00:01:20,259 --> 00:01:26,710
example I contributed the blog showing

00:01:23,140 --> 00:01:30,579
very parser and update flow for solar

00:01:26,710 --> 00:01:34,930
but it was just the prototype and if you

00:01:30,579 --> 00:01:39,759
full solar gira you know that movie was

00:01:34,930 --> 00:01:45,420
really upset by the ad hoc the way which

00:01:39,759 --> 00:01:52,000
solar handles blow join so I'm really

00:01:45,420 --> 00:01:55,210
regret about it my favorite contribution

00:01:52,000 --> 00:01:58,570
most enjoying was an attempt to fix

00:01:55,210 --> 00:02:01,259
threats in data import tumblr have you

00:01:58,570 --> 00:02:05,170
heard about dating box handler in solar

00:02:01,259 --> 00:02:07,210
so you know there was sitting to enable

00:02:05,170 --> 00:02:11,200
multi threading but it's a little bit

00:02:07,210 --> 00:02:15,069
unstable and when my fix was committed

00:02:11,200 --> 00:02:17,200
there and branch three dot x committee

00:02:15,069 --> 00:02:19,050
has decided to completely remove threats

00:02:17,200 --> 00:02:23,650
from dating porch under

00:02:19,050 --> 00:02:26,740
right after I fix all concurrency back

00:02:23,650 --> 00:02:30,850
during the long debug session you know

00:02:26,740 --> 00:02:35,260
I'm not sure how it depended is my

00:02:30,850 --> 00:02:38,770
contribution at all nobody told me they

00:02:35,260 --> 00:02:44,560
just dropped it so this is an advantage

00:02:38,770 --> 00:02:47,620
section session that's why I expect that

00:02:44,560 --> 00:02:50,380
you are aware of how we see in searches

00:02:47,620 --> 00:02:52,750
how it applies updates by staking

00:02:50,380 --> 00:02:54,880
segments one on each other what is doc

00:02:52,750 --> 00:02:58,060
wireless and why do you need to care

00:02:54,880 --> 00:03:01,720
about joints at all because it might be

00:02:58,060 --> 00:03:03,820
sort of specification you know that many

00:03:01,720 --> 00:03:06,940
people use the scene solar elastic and

00:03:03,820 --> 00:03:10,930
doesn't and don't care about joints but

00:03:06,940 --> 00:03:14,380
I care and I suppose that you share my

00:03:10,930 --> 00:03:18,820
concerns about joints so here's the plan

00:03:14,380 --> 00:03:21,820
for today I want to discuss existing

00:03:18,820 --> 00:03:29,250
implementation of joint queries in the

00:03:21,820 --> 00:03:33,580
scene and propose some d you d-1 okay

00:03:29,250 --> 00:03:36,580
leucine is pretty good and reliable and

00:03:33,580 --> 00:03:39,610
efficient in essential searching

00:03:36,580 --> 00:03:44,830
filtering and it's also pretty strong in

00:03:39,610 --> 00:03:50,830
analytics features it starts from facets

00:03:44,830 --> 00:03:53,920
and now leucine and solar her have have

00:03:50,830 --> 00:03:57,790
implementation for distributed pivot

00:03:53,920 --> 00:04:00,820
facets for heat maps it's pretty strong

00:03:57,790 --> 00:04:05,850
in analytics it makes them pretty

00:04:00,820 --> 00:04:09,880
powerful tool set but there is the still

00:04:05,850 --> 00:04:13,239
have a weakness it's a robust join so

00:04:09,880 --> 00:04:16,419
they still lack of universal always

00:04:13,239 --> 00:04:21,459
efficient to an algorithm we have few of

00:04:16,419 --> 00:04:24,430
them but we easily can face an edge case

00:04:21,459 --> 00:04:27,820
where some particular joint where it

00:04:24,430 --> 00:04:29,920
doesn't work well and usually join looks

00:04:27,820 --> 00:04:31,750
like this

00:04:29,920 --> 00:04:34,810
that's what we have in relational

00:04:31,750 --> 00:04:39,250
databases we have the two entity types

00:04:34,810 --> 00:04:42,180
and we have relations somehow declared

00:04:39,250 --> 00:04:46,900
between two entity types for example x

00:04:42,180 --> 00:04:50,620
equal keys so one product that is equal

00:04:46,900 --> 00:04:56,220
to another product lady before we look

00:04:50,620 --> 00:05:00,970
into particular implementation I like to

00:04:56,220 --> 00:05:04,960
look onto this problem and to join

00:05:00,970 --> 00:05:08,380
operation in general so let's depict one

00:05:04,960 --> 00:05:13,030
entity types by squares and second

00:05:08,380 --> 00:05:15,580
entity ties by triangles so it's our two

00:05:13,030 --> 00:05:20,140
entity types in the index or in database

00:05:15,580 --> 00:05:24,750
whatever then we declare some predicate

00:05:20,140 --> 00:05:29,130
which actually define the relation and

00:05:24,750 --> 00:05:32,920
this definition which can be read by

00:05:29,130 --> 00:05:36,070
primary key is equal to Frankie in fact

00:05:32,920 --> 00:05:39,520
it defines the third set the set of

00:05:36,070 --> 00:05:43,270
relation couples so we can draw it by

00:05:39,520 --> 00:05:46,480
this by grouping the triangle and square

00:05:43,270 --> 00:05:50,130
right and get this this is this little

00:05:46,480 --> 00:05:54,700
house so our relation is a set of

00:05:50,130 --> 00:05:57,570
relation tuples looks like this that's

00:05:54,700 --> 00:06:03,750
what we will work with in this talk

00:05:57,570 --> 00:06:07,420
let's also limit our discussion of

00:06:03,750 --> 00:06:11,380
explanation by the typical keys is one

00:06:07,420 --> 00:06:14,020
too many relation we can call one entity

00:06:11,380 --> 00:06:19,660
types as parent and second entity types

00:06:14,020 --> 00:06:22,360
as children and limit the relation to

00:06:19,660 --> 00:06:26,580
one too many case so every parent can

00:06:22,360 --> 00:06:34,050
have several children but not vice versa

00:06:26,580 --> 00:06:37,660
and it allows us to grope in the

00:06:34,050 --> 00:06:40,480
relational tuples into these multi-story

00:06:37,660 --> 00:06:43,590
buildings so it's like relational groups

00:06:40,480 --> 00:06:47,190
and just grow groped relation top

00:06:43,590 --> 00:06:49,800
so now we are ready to execute generic

00:06:47,190 --> 00:06:55,890
joint operation usually it looks like

00:06:49,800 --> 00:06:59,870
this we have children site query or

00:06:55,890 --> 00:07:03,420
predicate which select some certain

00:06:59,870 --> 00:07:05,520
children and and entities so while

00:07:03,420 --> 00:07:10,230
executing joint operations we need to

00:07:05,520 --> 00:07:14,610
loop through them and somehow obtained

00:07:10,230 --> 00:07:19,770
the relation tuples belongs to the

00:07:14,610 --> 00:07:21,870
children entities and through the

00:07:19,770 --> 00:07:25,770
relation tuples we can navigate to

00:07:21,870 --> 00:07:28,470
associated parents like this and it

00:07:25,770 --> 00:07:31,170
seems like joint operations is our that

00:07:28,470 --> 00:07:35,280
only thing which we need to do we just

00:07:31,170 --> 00:07:38,700
calculated associated parents from

00:07:35,280 --> 00:07:42,650
children that in fact in general form of

00:07:38,700 --> 00:07:46,470
joint we somehow sometimes can have

00:07:42,650 --> 00:07:48,600
second filter which is applied to parent

00:07:46,470 --> 00:07:53,310
site of joint operations it looks like

00:07:48,600 --> 00:07:56,280
this and the we also need to intersect

00:07:53,310 --> 00:07:58,770
the set of associated parents with these

00:07:56,280 --> 00:08:01,500
predicates with this parent filter and

00:07:58,770 --> 00:08:05,910
here you can spot the opportunity for

00:08:01,500 --> 00:08:08,040
optimization so you see if the parent

00:08:05,910 --> 00:08:10,920
filter is highly selective if it passed

00:08:08,040 --> 00:08:14,370
only few parents there is no much sense

00:08:10,920 --> 00:08:19,520
to calculate all associated parents

00:08:14,370 --> 00:08:23,010
right in this case you can employ this

00:08:19,520 --> 00:08:25,550
fact and start to execute joint

00:08:23,010 --> 00:08:28,580
operation into the opposite direction

00:08:25,550 --> 00:08:32,640
looks like this we can start from

00:08:28,580 --> 00:08:35,160
looping our few parents and just the

00:08:32,640 --> 00:08:37,950
navigate through relation tuples to the

00:08:35,160 --> 00:08:40,170
associated children and check their for

00:08:37,950 --> 00:08:46,230
intersection with the Gideon children

00:08:40,170 --> 00:08:49,320
filter I think that enough in the for

00:08:46,230 --> 00:08:53,580
this level of generality so I want to

00:08:49,320 --> 00:08:56,670
summarize that joint operation is the

00:08:53,580 --> 00:09:00,120
intersection of three sets sets

00:08:56,670 --> 00:09:03,480
of parents sets of children and join

00:09:00,120 --> 00:09:07,770
relation where sets of parents and

00:09:03,480 --> 00:09:11,340
children we we are provided in queer

00:09:07,770 --> 00:09:14,040
time so every time we get the new subset

00:09:11,340 --> 00:09:18,840
of children and parents and join

00:09:14,040 --> 00:09:22,230
relation is more static it's defined by

00:09:18,840 --> 00:09:26,060
data so our data forms the joint

00:09:22,230 --> 00:09:31,320
relation set and then one note about

00:09:26,060 --> 00:09:36,240
joined relation set that some algorithm

00:09:31,320 --> 00:09:39,060
might not even build these tuples this

00:09:36,240 --> 00:09:42,000
relation tuples some implementation for

00:09:39,060 --> 00:09:44,940
example like nested loops join calculate

00:09:42,000 --> 00:09:51,530
this relation tuples like dynamically

00:09:44,940 --> 00:09:53,400
during nested loop well like this and

00:09:51,530 --> 00:09:55,560
depending on the particular business

00:09:53,400 --> 00:09:58,500
problem we might need to output

00:09:55,560 --> 00:10:01,890
different size of joint operations some

00:09:58,500 --> 00:10:03,540
sometimes we need to return only parents

00:10:01,890 --> 00:10:07,860
sometimes Vinatieri to all the children

00:10:03,540 --> 00:10:10,880
or even sometimes we need to return both

00:10:07,860 --> 00:10:15,540
of them grouped together but

00:10:10,880 --> 00:10:20,360
nevertheless it's up to us to choose

00:10:15,540 --> 00:10:23,520
proper direction for enumeration so

00:10:20,360 --> 00:10:26,940
considering the particular selectivity

00:10:23,520 --> 00:10:29,400
particular set cardinality we can loop

00:10:26,940 --> 00:10:32,460
through children or through parents it's

00:10:29,400 --> 00:10:36,300
up to us we can mind the computational

00:10:32,460 --> 00:10:42,720
efficiency here so now it's time to look

00:10:36,300 --> 00:10:45,780
at the first implementation it's a query

00:10:42,720 --> 00:10:51,510
time joint which is implemented in class

00:10:45,780 --> 00:10:56,250
join you it you uses doc values the

00:10:51,510 --> 00:11:01,590
special data type where we need to store

00:10:56,250 --> 00:11:05,850
our IDs so the parent IDs is stored in

00:11:01,590 --> 00:11:08,400
the queries column so what it does it

00:11:05,850 --> 00:11:12,990
loop through children which is

00:11:08,400 --> 00:11:18,390
which are called to sign 22 it's a from

00:11:12,990 --> 00:11:21,960
sight of join it obtain the value of

00:11:18,390 --> 00:11:24,690
parent AZ for every children and drop

00:11:21,960 --> 00:11:28,890
them into accumulator in this set of

00:11:24,690 --> 00:11:32,220
terms so that's what it does it just

00:11:28,890 --> 00:11:34,920
scanned children and collect parent IDs

00:11:32,220 --> 00:11:38,910
and the second stage of joint operation

00:11:34,920 --> 00:11:43,110
is searching for the accused parent IDs

00:11:38,910 --> 00:11:49,560
it's done like regular turn queries so

00:11:43,110 --> 00:11:53,910
in fact the query time join execute term

00:11:49,560 --> 00:11:57,200
varies from the scene parent IDs many

00:11:53,910 --> 00:12:00,420
times so the more results you have the

00:11:57,200 --> 00:12:02,940
more operation you do and there is one

00:12:00,420 --> 00:12:06,900
problem with it that Lucy interim

00:12:02,940 --> 00:12:08,940
dictionary is not built for doing

00:12:06,900 --> 00:12:11,790
frequent thermal cups it's a little bit

00:12:08,940 --> 00:12:14,670
expensive operation and it's a the main

00:12:11,790 --> 00:12:20,070
problem is query time Jen so we discuss

00:12:14,670 --> 00:12:26,880
it a little bit later once again now we

00:12:20,070 --> 00:12:31,940
obtain parent documents and we can

00:12:26,880 --> 00:12:31,940
intersect them with the parent predicate

00:12:32,360 --> 00:12:38,300
here's the second implementation which

00:12:34,740 --> 00:12:42,540
is blog join block join is a quite

00:12:38,300 --> 00:12:46,380
clever idea it utilizes the fact that

00:12:42,540 --> 00:12:50,880
we've seen models document these

00:12:46,380 --> 00:12:55,290
document numbers so it assigns numbers

00:12:50,880 --> 00:12:57,900
to the document and it allows a certain

00:12:55,290 --> 00:13:01,380
type of nature relation between

00:12:57,900 --> 00:13:04,110
documents so in the scene internally

00:13:01,380 --> 00:13:08,400
token documents are not just identified

00:13:04,110 --> 00:13:11,340
they assigned numbers so we can employ

00:13:08,400 --> 00:13:15,470
this relation between numbers we can say

00:13:11,340 --> 00:13:18,950
which documents comes after another and

00:13:15,470 --> 00:13:21,810
what actually block joined us

00:13:18,950 --> 00:13:25,350
Howard openings are numbered so we can

00:13:21,810 --> 00:13:29,160
just in the exam in blocks or in groups

00:13:25,350 --> 00:13:32,250
and just put every parent right after

00:13:29,160 --> 00:13:34,620
their children and do seem provide

00:13:32,250 --> 00:13:37,410
special API for them and what it does is

00:13:34,620 --> 00:13:41,940
just assign internal numbers guy

00:13:37,410 --> 00:13:45,270
consequently on children and the parent

00:13:41,940 --> 00:13:52,080
goes right after them looks like this

00:13:45,270 --> 00:13:58,020
then in query time we can obtain obtain

00:13:52,080 --> 00:14:01,080
this information about parents in just

00:13:58,020 --> 00:14:04,950
in form of simple bit set and it allows

00:14:01,080 --> 00:14:08,430
us to navigate from month navigate from

00:14:04,950 --> 00:14:12,210
children to parents looks like this we

00:14:08,430 --> 00:14:14,670
loop through children documents and this

00:14:12,210 --> 00:14:19,440
simple bit set scanning we can navigate

00:14:14,670 --> 00:14:23,880
to the parent belongs to these children

00:14:19,440 --> 00:14:26,760
that's what it can and continue to find

00:14:23,880 --> 00:14:33,030
all associated parents but in fact it

00:14:26,760 --> 00:14:37,170
does more efficient thing the scene has

00:14:33,030 --> 00:14:40,710
out written which is called Li leapfrog

00:14:37,170 --> 00:14:43,830
four intersecting queries for executing

00:14:40,710 --> 00:14:46,620
contraction query and it's done in

00:14:43,830 --> 00:14:49,650
really efficient way so what it can done

00:14:46,620 --> 00:14:53,520
here instead of looping all parents by

00:14:49,650 --> 00:14:57,420
the same direction lucene can realize

00:14:53,520 --> 00:15:00,030
that the many associated parents are

00:14:57,420 --> 00:15:02,720
really redundant and we need don't need

00:15:00,030 --> 00:15:06,440
to obtain them and it can advance

00:15:02,720 --> 00:15:10,050
children side of joint operation over

00:15:06,440 --> 00:15:12,390
unnecessary parents right so this

00:15:10,050 --> 00:15:15,870
algorithm is already in the scene it's

00:15:12,390 --> 00:15:18,420
called leapfrog so our the most

00:15:15,870 --> 00:15:21,300
selective side of joint operations start

00:15:18,420 --> 00:15:25,350
to lead Joe an operation avoiding

00:15:21,300 --> 00:15:29,210
unnecessary step it's really performance

00:15:25,350 --> 00:15:29,210
breakthrough so

00:15:29,380 --> 00:15:35,990
listen does it advances children side of

00:15:33,560 --> 00:15:39,050
joy and liberation and now it can

00:15:35,990 --> 00:15:42,920
continue to do this from the first

00:15:39,050 --> 00:15:48,820
children of the parent which matches the

00:15:42,920 --> 00:15:51,890
given parent filter something like that

00:15:48,820 --> 00:15:55,370
okay let's summarize let's break down

00:15:51,890 --> 00:15:59,270
the comparative performance of these joy

00:15:55,370 --> 00:16:01,760
and implementation searching by query

00:15:59,270 --> 00:16:06,100
time join is slow and the question is

00:16:01,760 --> 00:16:10,940
why it's so slow there are two reasons

00:16:06,100 --> 00:16:15,470
there isn't not number one because it it

00:16:10,940 --> 00:16:18,920
in cold expensive operation of Durham

00:16:15,470 --> 00:16:21,500
look up many times so it's not what Lucy

00:16:18,920 --> 00:16:25,399
interim dictionary was created for and

00:16:21,500 --> 00:16:28,420
the second problem is that it always

00:16:25,399 --> 00:16:32,480
looped through all children and then

00:16:28,420 --> 00:16:35,660
search for parents then even you supply

00:16:32,480 --> 00:16:38,180
highly selective parent filter it can

00:16:35,660 --> 00:16:40,940
not any help speed up the joint

00:16:38,180 --> 00:16:47,589
operation these are two issues with the

00:16:40,940 --> 00:16:51,200
current Joyner to query time Jen and

00:16:47,589 --> 00:16:54,529
blog join which is indexed and during is

00:16:51,200 --> 00:16:56,600
pretty fast right because it doesn't

00:16:54,529 --> 00:17:00,050
heat any expensive data structure it

00:16:56,600 --> 00:17:03,980
doesn't hit any expensive operation it's

00:17:00,050 --> 00:17:08,170
just pretty lightweight and always it

00:17:03,980 --> 00:17:10,730
utilizes the leapfrog algorithm to

00:17:08,170 --> 00:17:13,100
execute joint operation in the most

00:17:10,730 --> 00:17:15,650
efficient way and more than that you

00:17:13,100 --> 00:17:19,220
don't need to care about selectivity of

00:17:15,650 --> 00:17:21,410
the filtering stents tenant statements

00:17:19,220 --> 00:17:25,910
the scene does it for you automatically

00:17:21,410 --> 00:17:30,260
and it's it's perfect there is some cost

00:17:25,910 --> 00:17:32,750
of in index inside the most often

00:17:30,260 --> 00:17:36,200
question about join what do I need to do

00:17:32,750 --> 00:17:39,260
if I need to update some entities in

00:17:36,200 --> 00:17:41,780
joint operation so in case of paratime

00:17:39,260 --> 00:17:42,320
join you need to bother about it at all

00:17:41,780 --> 00:17:45,580
there is

00:17:42,320 --> 00:17:49,669
zero indexed and burden right he just

00:17:45,580 --> 00:17:52,039
cost you nothing and in blog Joe and

00:17:49,669 --> 00:17:55,659
there is an issue right because you need

00:17:52,039 --> 00:17:59,179
to establish it you need to keep this

00:17:55,659 --> 00:18:02,750
constraint of blocked index you cannot

00:17:59,179 --> 00:18:07,220
just reindex single children right in to

00:18:02,750 --> 00:18:10,159
reindex roadblock and it might seem snot

00:18:07,220 --> 00:18:14,389
as a big deal at all because leucine is

00:18:10,159 --> 00:18:16,539
quite performant in index time and for

00:18:14,389 --> 00:18:20,029
example we can say that there is no

00:18:16,539 --> 00:18:22,220
difference in rain indexing performance

00:18:20,029 --> 00:18:25,039
between single document and between we

00:18:22,220 --> 00:18:27,399
indexing damn talking it it's really

00:18:25,039 --> 00:18:32,840
hard to evidence the difference between

00:18:27,399 --> 00:18:35,029
cost of these really reindex in but in

00:18:32,840 --> 00:18:38,539
some edge cases for example if you have

00:18:35,029 --> 00:18:44,840
really huge blocks it might be a big

00:18:38,539 --> 00:18:50,870
problem so as as I said you always need

00:18:44,840 --> 00:18:53,450
to enlarge the scope of index update and

00:18:50,870 --> 00:18:56,090
for example if your blog has really huge

00:18:53,450 --> 00:19:00,019
for example thousand document then

00:18:56,090 --> 00:19:02,450
instead of updating let's say a thousand

00:19:00,019 --> 00:19:05,750
of children you need to reindex all

00:19:02,450 --> 00:19:08,779
their block and you might end up with

00:19:05,750 --> 00:19:12,080
updated millions of documents it might

00:19:08,779 --> 00:19:16,909
be sensible costs and the second problem

00:19:12,080 --> 00:19:20,539
is it that from just system design it is

00:19:16,909 --> 00:19:23,419
not convenient property at all what we

00:19:20,539 --> 00:19:25,370
have usually we have separate system

00:19:23,419 --> 00:19:29,080
which runs some sort of business process

00:19:25,370 --> 00:19:32,779
react to events and search engine and

00:19:29,080 --> 00:19:35,779
business process just want to tell our

00:19:32,779 --> 00:19:38,750
indexing part just please reindex one

00:19:35,779 --> 00:19:42,860
document I have some changes and with

00:19:38,750 --> 00:19:45,620
the blog draw and design search engines

00:19:42,860 --> 00:19:49,510
needs somehow realize what is the source

00:19:45,620 --> 00:19:51,950
data for nearby documents right it

00:19:49,510 --> 00:19:55,340
usually need to call the document

00:19:51,950 --> 00:19:59,670
storage for the

00:19:55,340 --> 00:20:01,830
natan sibling documents and in some

00:19:59,670 --> 00:20:08,220
architectures is not what we can afford

00:20:01,830 --> 00:20:11,420
I have one more concerned about blog Joe

00:20:08,220 --> 00:20:16,110
and regarding query time but I just I

00:20:11,420 --> 00:20:18,990
feel it a little bit subtle concerned so

00:20:16,110 --> 00:20:22,710
I want to skip it for now let's discuss

00:20:18,990 --> 00:20:25,730
it somewhere later so blog John is

00:20:22,710 --> 00:20:30,270
perfectly in query time so and then I

00:20:25,730 --> 00:20:32,700
tried to find the algorithm to develop

00:20:30,270 --> 00:20:35,130
the tailgate which will be somewhere in

00:20:32,700 --> 00:20:40,110
the middle because it's not possible to

00:20:35,130 --> 00:20:43,850
be faster than block join right that's

00:20:40,110 --> 00:20:49,080
what I try to pursue in my research and

00:20:43,850 --> 00:20:51,780
the idea was to provide Joe an index in

00:20:49,080 --> 00:20:55,500
in the scene the idea is straightforward

00:20:51,780 --> 00:20:58,350
I will want to use a same doc values

00:20:55,500 --> 00:21:01,650
column but I wish to put not external

00:20:58,350 --> 00:21:05,550
IDs in this column but i want to put

00:21:01,650 --> 00:21:08,040
document numbers in it now I don't need

00:21:05,550 --> 00:21:11,640
to run the expensive step of resolving

00:21:08,040 --> 00:21:16,200
the external IDs to talk numbers so I

00:21:11,640 --> 00:21:18,900
just need to put them in to put the talk

00:21:16,200 --> 00:21:21,240
numbers of the associated parents in doc

00:21:18,900 --> 00:21:25,470
values column but there is problems

00:21:21,240 --> 00:21:28,830
because it's not even it's not possible

00:21:25,470 --> 00:21:31,860
english seen api right now i cannot

00:21:28,830 --> 00:21:35,490
supply document numbers as a source date

00:21:31,860 --> 00:21:39,120
of my documents that's why I find the

00:21:35,490 --> 00:21:42,750
workaround I apply updates in two stages

00:21:39,120 --> 00:21:47,330
so first I index the source data and

00:21:42,750 --> 00:21:50,670
then i apply join index to this column

00:21:47,330 --> 00:21:54,270
by updatable de cuales so i can reindex

00:21:50,670 --> 00:21:59,040
whoa column its recent feature in lucene

00:21:54,270 --> 00:22:01,260
and if I if I able to do that and put a

00:21:59,040 --> 00:22:05,750
document numbers of the associated

00:22:01,260 --> 00:22:08,720
parents in doc values now the joint is

00:22:05,750 --> 00:22:11,360
pretty straightforward I need to loop

00:22:08,720 --> 00:22:14,180
through children documents and just

00:22:11,360 --> 00:22:18,530
collect parent document numbers then I

00:22:14,180 --> 00:22:22,430
have to sort it now it's mandatory step

00:22:18,530 --> 00:22:24,950
because recently out of order collecting

00:22:22,430 --> 00:22:28,550
was prohibited in in the scene so but

00:22:24,950 --> 00:22:30,560
now nevertheless is the process of joint

00:22:28,550 --> 00:22:34,190
operations is quite simple with these

00:22:30,560 --> 00:22:37,190
index then we just sort associated

00:22:34,190 --> 00:22:40,970
parent IDs and intersect with parent

00:22:37,190 --> 00:22:43,190
filter but more than that here is an

00:22:40,970 --> 00:22:45,620
opportunity if you use binary the

00:22:43,190 --> 00:22:48,500
queries we can put a whole list of

00:22:45,620 --> 00:22:51,290
associated children in the cell of

00:22:48,500 --> 00:22:55,400
binary the quarians column and now we

00:22:51,290 --> 00:22:58,220
have an opportunity to start during

00:22:55,400 --> 00:23:01,190
operation on opposite way on more

00:22:58,220 --> 00:23:05,960
efficient way if we have highly

00:23:01,190 --> 00:23:09,340
selective filter like this then we need

00:23:05,960 --> 00:23:12,710
to just loop through few parents and

00:23:09,340 --> 00:23:15,200
check the associated children for

00:23:12,710 --> 00:23:19,130
intersection with the given children

00:23:15,200 --> 00:23:26,630
fielder and Rob parents into result if

00:23:19,130 --> 00:23:31,970
it if they intersect okay I spoke about

00:23:26,630 --> 00:23:35,260
this prototype at odeon and recently I

00:23:31,970 --> 00:23:39,350
found quite interesting JIRA it's about

00:23:35,260 --> 00:23:44,030
reporting global ordinal query time

00:23:39,350 --> 00:23:46,760
joint from elasticsearch to loosen it is

00:23:44,030 --> 00:23:50,300
pretty interesting it's a shame shame

00:23:46,760 --> 00:23:52,700
shame on me that I didn't know about it

00:23:50,300 --> 00:23:55,820
so let's look into it it's pretty

00:23:52,700 --> 00:24:01,280
interesting thing it's called global

00:23:55,820 --> 00:24:03,950
original query time join so it works

00:24:01,280 --> 00:24:08,120
almost like we're time join but it uses

00:24:03,950 --> 00:24:10,850
sorted dog values do you know what the

00:24:08,120 --> 00:24:15,140
feature in sorted Dok levels why it's

00:24:10,850 --> 00:24:18,410
necessary did know about them so they

00:24:15,140 --> 00:24:19,500
was developed for providing sourcing by

00:24:18,410 --> 00:24:21,360
field value for

00:24:19,500 --> 00:24:23,520
example if you need to sort your

00:24:21,360 --> 00:24:27,900
document by some product name for

00:24:23,520 --> 00:24:30,660
example in this case instead of sorting

00:24:27,900 --> 00:24:34,160
by strings because comparing strings is

00:24:30,660 --> 00:24:38,850
expensive operation during index time

00:24:34,160 --> 00:24:41,520
for every such column leucine builds

00:24:38,850 --> 00:24:44,460
separate index where it collect all

00:24:41,520 --> 00:24:47,220
values from this column data placate

00:24:44,460 --> 00:24:50,580
them sort them and assign ordinal

00:24:47,220 --> 00:24:54,060
numbers and then it's tour these numbers

00:24:50,580 --> 00:24:56,070
in the column and right now if we need

00:24:54,060 --> 00:24:59,150
to sort by this column we can compare

00:24:56,070 --> 00:25:04,200
numbers and sort by numbers which is

00:24:59,150 --> 00:25:08,850
quite cheaper than comparing strings so

00:25:04,200 --> 00:25:14,520
and these query utilizes this pretty

00:25:08,850 --> 00:25:18,950
cool structure what it does it loops

00:25:14,520 --> 00:25:24,420
children and obtain the associated

00:25:18,950 --> 00:25:27,360
ordinal numbers of parent keys something

00:25:24,420 --> 00:25:31,070
like this and it also drops them into

00:25:27,360 --> 00:25:33,090
accumulator but in case of ordinals

00:25:31,070 --> 00:25:36,860
accumulator is pretty straightforward

00:25:33,090 --> 00:25:40,370
it's just a bit set it's much more

00:25:36,860 --> 00:25:43,860
compact and efficient data structure and

00:25:40,370 --> 00:25:48,710
it is second stage it loops through

00:25:43,860 --> 00:25:52,560
parents and does the same thing it's

00:25:48,710 --> 00:25:56,060
obtained the original number of the

00:25:52,560 --> 00:26:00,830
parent key and check the beat set for

00:25:56,060 --> 00:26:04,200
intersection let's go it recognizes that

00:26:00,830 --> 00:26:08,610
any of the children has the same value

00:26:04,200 --> 00:26:14,700
of the parent key so and now let's

00:26:08,610 --> 00:26:19,520
compare all the implementation here's a

00:26:14,700 --> 00:26:22,700
URL to loosen fork where I put my

00:26:19,520 --> 00:26:27,300
implementation of joining the xquery and

00:26:22,700 --> 00:26:31,830
where I extended the lucene benchmark

00:26:27,300 --> 00:26:35,100
model to benchmark join algorithms

00:26:31,830 --> 00:26:39,269
these are not great hardness but it

00:26:35,100 --> 00:26:42,110
warps and does well what we need so I'm

00:26:39,269 --> 00:26:47,370
able to run pretty fast benchmarks for

00:26:42,110 --> 00:26:50,700
all these queries so what we see here

00:26:47,370 --> 00:26:53,940
blog joe and outperforms query time join

00:26:50,700 --> 00:26:57,140
and it's what we expect but it worse to

00:26:53,940 --> 00:27:01,590
mention that benchmark is not really

00:26:57,140 --> 00:27:04,460
representative what I evidence at

00:27:01,590 --> 00:27:08,730
practice that blog joe and outperforms

00:27:04,460 --> 00:27:11,399
quilt and join at orders of magnitude so

00:27:08,730 --> 00:27:15,059
it's way faster it's more faster than

00:27:11,399 --> 00:27:18,750
several times might be further in ten

00:27:15,059 --> 00:27:22,010
times and even more now nevertheless it

00:27:18,750 --> 00:27:24,179
these being small benchmarks show us

00:27:22,010 --> 00:27:27,809
something which is related to the

00:27:24,179 --> 00:27:30,450
practice now you can see that join index

00:27:27,809 --> 00:27:34,200
perform pretty well it performs better

00:27:30,450 --> 00:27:35,940
than join with you and here it seems

00:27:34,200 --> 00:27:41,909
like joint index faster than global

00:27:35,940 --> 00:27:47,250
ordinals query it's not correct is not

00:27:41,909 --> 00:27:52,409
true because I had to apply updates for

00:27:47,250 --> 00:27:56,970
join index in quite rarely so all these

00:27:52,409 --> 00:28:00,149
three queries from leucine ping bed

00:27:56,970 --> 00:28:03,149
bench market by frequent updates by two

00:28:00,149 --> 00:28:07,760
times per second and I have to apply

00:28:03,149 --> 00:28:10,200
updates to join index in much lower rate

00:28:07,760 --> 00:28:14,460
because of the problem with updates

00:28:10,200 --> 00:28:17,039
which I will discuss later so what we

00:28:14,460 --> 00:28:21,440
see that join index is a perspective

00:28:17,039 --> 00:28:24,120
idea but there is a big problem visit so

00:28:21,440 --> 00:28:27,720
right now I cannot apply updates

00:28:24,120 --> 00:28:32,490
incremental II but we also see that

00:28:27,720 --> 00:28:35,789
global orginals it Cooper it's a great

00:28:32,490 --> 00:28:39,139
and performant query time join and I

00:28:35,789 --> 00:28:44,559
quite recommend it to use instead of

00:28:39,139 --> 00:28:50,289
plain old query time join ok here is

00:28:44,559 --> 00:28:53,499
comparison chart during index fast and

00:28:50,289 --> 00:28:56,919
global original query also fast but

00:28:53,499 --> 00:29:02,649
lockjaw and faster anyway because blog

00:28:56,919 --> 00:29:06,700
Joanne can join in boss direction a so

00:29:02,649 --> 00:29:10,029
it joins in most efficient way and it it

00:29:06,700 --> 00:29:13,080
joins themselves you don't need to

00:29:10,029 --> 00:29:18,450
choose the efficient wave for

00:29:13,080 --> 00:29:24,159
enumeration ok global orginals has

00:29:18,450 --> 00:29:26,769
almost zero cost for update and there is

00:29:24,159 --> 00:29:32,039
a big problem with applying updates on

00:29:26,769 --> 00:29:35,519
joint index the reason is that just for

00:29:32,039 --> 00:29:40,299
simplicity just make simple prototype I

00:29:35,519 --> 00:29:42,340
fully recalculate the full column of joy

00:29:40,299 --> 00:29:48,909
and index every time you apply any

00:29:42,340 --> 00:29:52,799
update so I didn't reach the initial aim

00:29:48,909 --> 00:29:56,110
and somewhere in the middle of the way

00:29:52,799 --> 00:29:58,210
but it's proved the general idea and

00:29:56,110 --> 00:30:05,080
they still consider it this perspective

00:29:58,210 --> 00:30:11,559
and here are revised plan I plan to work

00:30:05,080 --> 00:30:15,759
in in in incremental join index update i

00:30:11,559 --> 00:30:19,389
think it's possible that will allow us

00:30:15,759 --> 00:30:21,929
to join in both direction to execute

00:30:19,389 --> 00:30:25,990
join operation in the most efficient way

00:30:21,929 --> 00:30:31,179
which is not possible in a global

00:30:25,990 --> 00:30:33,940
original join so far and i need need

00:30:31,179 --> 00:30:40,080
need to upscale the benchmark to

00:30:33,940 --> 00:30:44,799
highlight the hardest the thickest of

00:30:40,080 --> 00:30:47,399
kinds of every implementation so current

00:30:44,799 --> 00:30:51,810
pinch mark is too small to represent any

00:30:47,399 --> 00:30:55,650
real challenges for queries

00:30:51,810 --> 00:30:58,410
the soul for from me for today we lookin

00:30:55,650 --> 00:31:02,670
to join implementations we've lookin to

00:30:58,410 --> 00:31:05,430
joint problem in general I give you an

00:31:02,670 --> 00:31:07,620
example of how we can use updateable dog

00:31:05,430 --> 00:31:11,880
values but it's not the proper way to

00:31:07,620 --> 00:31:15,030
use them but they recommend them for

00:31:11,880 --> 00:31:17,610
using in your application it's pretty in

00:31:15,030 --> 00:31:21,390
interesting feature and there wasn't

00:31:17,610 --> 00:31:24,360
some ideas for speeding up query time

00:31:21,390 --> 00:31:27,240
join if you struggle with it performance

00:31:24,360 --> 00:31:30,900
but now they're all legacy and absolute

00:31:27,240 --> 00:31:33,870
they don't have much sense now I can

00:31:30,900 --> 00:31:36,600
recommend to use global ordinals join if

00:31:33,870 --> 00:31:39,630
you need fast query time join here are a

00:31:36,600 --> 00:31:43,770
few references if you won't go deeper in

00:31:39,630 --> 00:31:45,930
these and all these problems and here is

00:31:43,770 --> 00:31:49,650
a shortcut to access the slides if you

00:31:45,930 --> 00:31:53,510
wish so now I'm open for questions we

00:31:49,650 --> 00:31:56,490
have some time left k you are welcome

00:31:53,510 --> 00:32:02,300
why that's the questions and thank the

00:31:56,490 --> 00:32:04,360
speaker thank you thanks for your time

00:32:02,300 --> 00:32:04,360

YouTube URL: https://www.youtube.com/watch?v=z1RqZsjhIMM


