Title: Berlin Buzzwords 2015: Tudor Golubenco, Monica Sarbu â€“ Application performance management w  open...
Publication date: 2015-06-02
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	The talk proposes and demonstrates a methodology for monitoring  and troubleshooting the performance of a typical web application by using Elasticsearch as an event analytics engine. It discusses ways of collecting performance metrics for the transaction data (response time, error codes, URL path, data base tables, etc.), the appropriate level of details captured, sampling techniques and tips for efficiently storing the data.

It then shows how to use Elasticsearch aggregations to provide the application performance specific metrics (response time percentiles, error rates) at a global level and also segmented over multiple dimensions (service, server, URL path, etc.). It shows how to use these techniques and visualisations to perform a top-down analysis through the data in order to identify a performance issue.

During the talk, the audience learns how Packetbeat, Yahoo Boomerang, Logstash, ElasticSearch, Kibana and Bonito work together for a complete application performance management solution that is more applicable and more flexible than the commercial offerings.

Read more:
https://2015.berlinbuzzwords.de/session/application-performance-management-open-source-tools

About Tudor Golubenco:
https://2015.berlinbuzzwords.de/users/tudor-golubenco

About Monica Sarbu:
https://2015.berlinbuzzwords.de/users/monica-sarbu

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:05,759 --> 00:00:14,650
thank you and welcome to our talk so

00:00:11,950 --> 00:00:16,150
for background information on us we are

00:00:14,650 --> 00:00:18,189
too soft

00:00:16,150 --> 00:00:20,439
we have lots of experience in a

00:00:18,189 --> 00:00:23,050
voice-over-ip monitoring because they're

00:00:20,439 --> 00:00:24,640
used to your work on a startup that was

00:00:23,050 --> 00:00:27,220
doing just that a voice over IP

00:00:24,640 --> 00:00:30,130
monitoring product this startup was

00:00:27,220 --> 00:00:33,100
acquired first by Acme packet which at

00:00:30,130 --> 00:00:35,620
its turn it was acquired by Oracle and

00:00:33,100 --> 00:00:38,079
then we started to work the two of us

00:00:35,620 --> 00:00:39,760
started to work full-time on this packet

00:00:38,079 --> 00:00:43,300
did project that we're going to talk

00:00:39,760 --> 00:00:46,059
about today and because we are on the

00:00:43,300 --> 00:00:48,160
scale track of the of the conference I'm

00:00:46,059 --> 00:00:51,520
going to start by talking about scaling

00:00:48,160 --> 00:00:54,280
a little bit and there are two aspects

00:00:51,520 --> 00:00:57,820
of scaling that I find interesting one

00:00:54,280 --> 00:00:59,560
is the technical side as your startup

00:00:57,820 --> 00:01:03,040
has a lot of success and you want to

00:00:59,560 --> 00:01:05,409
reach more and more users you will scale

00:01:03,040 --> 00:01:08,469
your infrastructure to tens hundreds

00:01:05,409 --> 00:01:11,680
thousands of servers at the same time

00:01:08,469 --> 00:01:16,000
there's the organism Oracle aspect in

00:01:11,680 --> 00:01:17,770
which as you grow your company you scale

00:01:16,000 --> 00:01:19,840
to hundreds thousands and tens of

00:01:17,770 --> 00:01:22,060
thousands of employees may be engineers

00:01:19,840 --> 00:01:24,880
product managers marketing people and so

00:01:22,060 --> 00:01:27,280
on and it's interesting that these two

00:01:24,880 --> 00:01:30,459
aspects of scaling are actually closely

00:01:27,280 --> 00:01:33,069
interlinked they are linked by what's

00:01:30,459 --> 00:01:35,200
known as the Conway's law which says

00:01:33,069 --> 00:01:37,179
that organizations which design systems

00:01:35,200 --> 00:01:38,529
are constrained to produce designs which

00:01:37,179 --> 00:01:41,459
are copies of the communication

00:01:38,529 --> 00:01:43,929
structures of these organizations right

00:01:41,459 --> 00:01:46,209
so what often happens is that at the

00:01:43,929 --> 00:01:48,579
beginning the organization looks

00:01:46,209 --> 00:01:51,579
something like this it's split into a UI

00:01:48,579 --> 00:01:53,380
team back-end team a database team and

00:01:51,579 --> 00:01:56,079
and so on

00:01:53,380 --> 00:01:57,939
and the system that they produce also

00:01:56,079 --> 00:02:01,659
looks like this right this is how it

00:01:57,939 --> 00:02:04,119
happens as the company grows they start

00:02:01,659 --> 00:02:06,999
to realize that this doesn't scale very

00:02:04,119 --> 00:02:09,009
well and for multiple reasons but one of

00:02:06,999 --> 00:02:11,590
the reasons is that when new features

00:02:09,009 --> 00:02:14,620
comes up there needs to be implemented

00:02:11,590 --> 00:02:17,080
it affects all these teams and all these

00:02:14,620 --> 00:02:19,480
parts of the systems so you get a lots

00:02:17,080 --> 00:02:22,870
of interlocking between them and lots of

00:02:19,480 --> 00:02:25,300
communication overhead so that's why in

00:02:22,870 --> 00:02:27,820
the most more recent years people have

00:02:25,300 --> 00:02:28,959
started to adopt micro services they are

00:02:27,820 --> 00:02:31,329
used to successful

00:02:28,959 --> 00:02:34,390
by companies like Netflix and Spotify

00:02:31,329 --> 00:02:36,849
and so on where they split the

00:02:34,390 --> 00:02:39,640
functionality of the of the overall

00:02:36,849 --> 00:02:41,849
service in lots of small small services

00:02:39,640 --> 00:02:45,000
and you have small teams working on them

00:02:41,849 --> 00:02:46,959
so each of these services are

00:02:45,000 --> 00:02:49,180
self-contained they talk between

00:02:46,959 --> 00:02:51,819
themselves with an API so they can be

00:02:49,180 --> 00:02:54,730
simple they can be written in different

00:02:51,819 --> 00:02:56,859
programming languages which is a good

00:02:54,730 --> 00:03:00,189
way of bringing fresh technology in your

00:02:56,859 --> 00:03:05,129
company and everyone is happy about this

00:03:00,189 --> 00:03:08,379
usually and while each of these systems

00:03:05,129 --> 00:03:10,510
in by themselves are very simple the

00:03:08,379 --> 00:03:12,639
overall system gets can get quite

00:03:10,510 --> 00:03:15,340
complex right the complexity is not

00:03:12,639 --> 00:03:18,489
removed is more like moved into the

00:03:15,340 --> 00:03:20,799
communication between them and in fact

00:03:18,489 --> 00:03:22,930
it often happens that things get so

00:03:20,799 --> 00:03:25,260
complex that no one in the company has

00:03:22,930 --> 00:03:28,930
an overview of really what's going on

00:03:25,260 --> 00:03:32,560
with the whole system and is that a bad

00:03:28,930 --> 00:03:34,569
thing or is that a good thing I think

00:03:32,560 --> 00:03:36,069
it's a good thing and I think we have to

00:03:34,569 --> 00:03:39,489
accept the fact that if we want to

00:03:36,069 --> 00:03:42,069
create truly advanced systems they will

00:03:39,489 --> 00:03:44,409
be more advanced that any of us can can

00:03:42,069 --> 00:03:47,049
understand them even if we help help

00:03:44,409 --> 00:03:51,040
creating them and in fact I think this

00:03:47,049 --> 00:03:52,689
is how if we do read this right this

00:03:51,040 --> 00:03:56,229
will resemble the way evolution works

00:03:52,689 --> 00:03:59,470
right just like the DNA evolves to adapt

00:03:56,229 --> 00:04:01,419
to new environments by mutations you

00:03:59,470 --> 00:04:05,650
have your system which adapt to new

00:04:01,419 --> 00:04:09,250
requirements using git commits and pull

00:04:05,650 --> 00:04:11,709
requests and so on right and it's

00:04:09,250 --> 00:04:13,509
important to choose the right mutations

00:04:11,709 --> 00:04:15,759
because if you choose the bad mutations

00:04:13,509 --> 00:04:19,479
you're going to be extinct as a company

00:04:15,759 --> 00:04:21,190
right or you will become a rat or a

00:04:19,479 --> 00:04:22,509
kitchen bug or something like this

00:04:21,190 --> 00:04:24,310
that's not very pleasant

00:04:22,509 --> 00:04:26,440
on the other hand if you choose all the

00:04:24,310 --> 00:04:29,919
good mutations you will become maybe one

00:04:26,440 --> 00:04:32,139
of the greater apps it's or dolphin

00:04:29,919 --> 00:04:36,550
which is the most intelligent lifeform

00:04:32,139 --> 00:04:38,260
on earth okay and how do you how do you

00:04:36,550 --> 00:04:40,360
choose the

00:04:38,260 --> 00:04:42,850
good mutations from the bad mutations

00:04:40,360 --> 00:04:44,590
they are of course multiple multiple

00:04:42,850 --> 00:04:46,960
approaches that you can have but I think

00:04:44,590 --> 00:04:50,890
one of the things that's really

00:04:46,960 --> 00:04:53,020
important is monitoring you you need to

00:04:50,890 --> 00:04:55,270
define a set of KPIs also on the

00:04:53,020 --> 00:04:58,270
business tiles side of things you have

00:04:55,270 --> 00:05:00,010
KPIs and you apply mutations and you see

00:04:58,270 --> 00:05:00,730
if things are going well or things are

00:05:00,010 --> 00:05:05,260
going bad

00:05:00,730 --> 00:05:07,480
and equally on the technical side you

00:05:05,260 --> 00:05:11,290
should monitor things like response

00:05:07,480 --> 00:05:14,080
times latency availability error rates

00:05:11,290 --> 00:05:16,600
and so on so that you know when things

00:05:14,080 --> 00:05:18,430
are going well and where things are not

00:05:16,600 --> 00:05:21,910
going well also when things are not

00:05:18,430 --> 00:05:24,220
going well you want to be quickly be

00:05:21,910 --> 00:05:26,290
able to identify the mutations that are

00:05:24,220 --> 00:05:30,700
problematic so you can remove them as

00:05:26,290 --> 00:05:33,190
soon as possible so because we recognize

00:05:30,700 --> 00:05:39,850
that this problem is is both very

00:05:33,190 --> 00:05:42,490
important and also difficult we decided

00:05:39,850 --> 00:05:45,180
to work on this on monitoring and

00:05:42,490 --> 00:05:47,860
troubleshooting distributed applications

00:05:45,180 --> 00:05:50,770
okay now let's see what our requirements

00:05:47,860 --> 00:05:52,900
for this kind of monitoring solution so

00:05:50,770 --> 00:05:55,060
it should be scalable and reliable I

00:05:52,900 --> 00:05:58,000
will say it needs to be more scalable

00:05:55,060 --> 00:06:00,970
and real reliable than an application in

00:05:58,000 --> 00:06:04,030
monitors it has to extract data from

00:06:00,970 --> 00:06:04,900
different sources it has to have low

00:06:04,030 --> 00:06:06,910
overhead

00:06:04,900 --> 00:06:09,750
we don't want to question if we want to

00:06:06,910 --> 00:06:11,920
enable monitoring or not low

00:06:09,750 --> 00:06:15,310
configuration in a highly dynamic

00:06:11,920 --> 00:06:17,140
infrastructure servers go down and up

00:06:15,310 --> 00:06:19,540
and we don't want to do any manual

00:06:17,140 --> 00:06:22,240
configuration and it should be simple

00:06:19,540 --> 00:06:24,340
and easy to understand so everyone from

00:06:22,240 --> 00:06:30,700
the company should be able to interpret

00:06:24,340 --> 00:06:33,970
what the monetary system it shows so we

00:06:30,700 --> 00:06:35,710
think a good start for monitoring

00:06:33,970 --> 00:06:38,500
solution is to look at the communication

00:06:35,710 --> 00:06:40,690
between the components distributed

00:06:38,500 --> 00:06:43,840
systems nowadays they are very different

00:06:40,690 --> 00:06:46,390
one from each other they use different

00:06:43,840 --> 00:06:49,090
programming languages different framers

00:06:46,390 --> 00:06:50,830
even different operating systems but

00:06:49,090 --> 00:06:52,690
what they have in common is the

00:06:50,830 --> 00:06:55,570
the communication between them it's

00:06:52,690 --> 00:06:57,820
using the network and the protocol they

00:06:55,570 --> 00:07:01,650
are using are more and more standard for

00:06:57,820 --> 00:07:07,180
example they use HTTP API and different

00:07:01,650 --> 00:07:11,110
RPC is like JSON RPC treats RPC they are

00:07:07,180 --> 00:07:14,230
so proto database protocols like my

00:07:11,110 --> 00:07:17,770
sickle and Postgres SSL and so on

00:07:14,230 --> 00:07:21,970
my key data is objective so we don't

00:07:17,770 --> 00:07:25,770
have to rely on locks when we want to

00:07:21,970 --> 00:07:29,440
debug an issue and no latency overhead

00:07:25,770 --> 00:07:32,950
so it works the monitoring solution it

00:07:29,440 --> 00:07:36,970
works by having a cop looking at a copy

00:07:32,950 --> 00:07:40,390
of the traffic okay so we started a

00:07:36,970 --> 00:07:43,510
packet bit and the packet with project

00:07:40,390 --> 00:07:48,090
and it was launched almost one year ago

00:07:43,510 --> 00:07:52,990
it's open source is written in golang

00:07:48,090 --> 00:07:55,330
yeah so let's see what is pack a bit so

00:07:52,990 --> 00:07:56,950
pick a bit consists of a qubit shippers

00:07:55,330 --> 00:08:00,670
that are installing an application

00:07:56,950 --> 00:08:03,610
servers they follow the TPC TCP stream

00:08:00,670 --> 00:08:07,240
stickers upper layer protocols like HTTP

00:08:03,610 --> 00:08:09,250
red is my sequel PostgreSQL thrift RPC

00:08:07,240 --> 00:08:13,360
and so on then they correlate the

00:08:09,250 --> 00:08:16,030
request is a response and they get data

00:08:13,360 --> 00:08:18,700
and measurements from from the

00:08:16,030 --> 00:08:21,790
transactions and also from the from the

00:08:18,700 --> 00:08:26,440
environment and generate a JSON object

00:08:21,790 --> 00:08:30,280
for each transaction here is an example

00:08:26,440 --> 00:08:34,600
of a JSON object this is the Select

00:08:30,280 --> 00:08:37,240
query to a post SQL as you can see the

00:08:34,600 --> 00:08:40,930
method is select the number of rows

00:08:37,240 --> 00:08:44,140
returned by the queries to response time

00:08:40,930 --> 00:08:49,210
is 12 and then size of the response is

00:08:44,140 --> 00:08:52,210
representing invite out so we have all

00:08:49,210 --> 00:08:54,640
the shippers installed on your in an in

00:08:52,210 --> 00:08:57,640
your system and they are collecting a

00:08:54,640 --> 00:09:00,390
lot of data what we do is the data why

00:08:57,640 --> 00:09:03,620
can we analyze it how can you analyze it

00:09:00,390 --> 00:09:06,190
so the traditional way to do this

00:09:03,620 --> 00:09:09,170
first you decide what matrix you want to

00:09:06,190 --> 00:09:13,190
measure for example the number of

00:09:09,170 --> 00:09:16,370
requests a server can have or the number

00:09:13,190 --> 00:09:19,100
of the ORS the response time percentage

00:09:16,370 --> 00:09:22,160
then your write code we strike the

00:09:19,100 --> 00:09:26,120
matrix and then you store them in a

00:09:22,160 --> 00:09:29,690
database for example it can be a time

00:09:26,120 --> 00:09:31,790
series database and if you want to drill

00:09:29,690 --> 00:09:35,779
down to look at the transactions that

00:09:31,790 --> 00:09:38,120
cause an issue or a peak then you have

00:09:35,779 --> 00:09:40,700
to store the transactional database and

00:09:38,120 --> 00:09:44,089
this time this database can be a normal

00:09:40,700 --> 00:09:47,600
database and features like drilling down

00:09:44,089 --> 00:09:49,400
and topping queries are very difficult

00:09:47,600 --> 00:09:53,390
to implement in the traditional way

00:09:49,400 --> 00:09:57,800
because you have the matrix and the

00:09:53,390 --> 00:10:00,050
transaction stored in different way so

00:09:57,800 --> 00:10:04,820
our solution to this is to use the elk

00:10:00,050 --> 00:10:08,120
spec and to push all the generated JSON

00:10:04,820 --> 00:10:10,970
object to elasticsearch and here we have

00:10:08,120 --> 00:10:11,630
optionally you can use Redis and

00:10:10,970 --> 00:10:14,450
logstash

00:10:11,630 --> 00:10:17,029
to have a bit of buffering before

00:10:14,450 --> 00:10:19,610
inserting the elasticsearch additionally

00:10:17,029 --> 00:10:21,470
you can use log stash for changing the

00:10:19,610 --> 00:10:25,100
data for example if you want to add a

00:10:21,470 --> 00:10:28,060
new tag or you want to change your field

00:10:25,100 --> 00:10:31,370
name you can do that with log stash and

00:10:28,060 --> 00:10:34,220
if you you if you want you can also

00:10:31,370 --> 00:10:37,640
configure package B to insert the data

00:10:34,220 --> 00:10:39,290
data directly into elastic search on the

00:10:37,640 --> 00:10:45,260
top of the elastic search you can use

00:10:39,290 --> 00:10:47,870
Cabana to visualize the data yeah so why

00:10:45,260 --> 00:10:50,270
did we choose Alex death because it

00:10:47,870 --> 00:10:53,270
proved to be a good solution for logs

00:10:50,270 --> 00:10:56,120
and our solution is more more or less

00:10:53,270 --> 00:10:59,330
similar with this and it's scalable it

00:10:56,120 --> 00:11:02,540
proves that it there our installation

00:10:59,330 --> 00:11:05,870
with more than a million events per

00:11:02,540 --> 00:11:08,450
second it offers the clear and simple

00:11:05,870 --> 00:11:11,510
flow for the data first you have the

00:11:08,450 --> 00:11:14,270
shippers that are generating the data

00:11:11,510 --> 00:11:16,270
then optionally you have the log fish

00:11:14,270 --> 00:11:18,760
that are transporting the data

00:11:16,270 --> 00:11:21,070
then you have the elasticsearch that are

00:11:18,760 --> 00:11:23,410
in this in the data and Cabana to

00:11:21,070 --> 00:11:25,420
visualize the data and the most

00:11:23,410 --> 00:11:28,120
important one is that you don't have to

00:11:25,420 --> 00:11:30,880
create the metrics beforehand and it

00:11:28,120 --> 00:11:35,070
comes with features like drilling down

00:11:30,880 --> 00:11:38,650
and top and features out of the box

00:11:35,070 --> 00:11:40,480
all right now to part the visualizing

00:11:38,650 --> 00:11:45,250
part of the data which is which is more

00:11:40,480 --> 00:11:47,650
fun I think so we're using Cabana Cabana

00:11:45,250 --> 00:11:49,480
for for visualization this is the

00:11:47,650 --> 00:11:52,420
discover top for it you might know it

00:11:49,480 --> 00:11:54,820
and we just show here how easy it is to

00:11:52,420 --> 00:11:57,510
find all my sequel errors for example

00:11:54,820 --> 00:12:01,300
right we put a filter on status not okay

00:11:57,510 --> 00:12:03,430
and a filter on type my sequel and there

00:12:01,300 --> 00:12:05,500
you have it you can also of course the

00:12:03,430 --> 00:12:09,730
free text search because well it's

00:12:05,500 --> 00:12:12,220
elastic search so we can search packet

00:12:09,730 --> 00:12:14,560
beat also comes with a set of predefined

00:12:12,220 --> 00:12:16,480
dashboards right so usually when you see

00:12:14,560 --> 00:12:18,250
Bona you start with a blank page and you

00:12:16,480 --> 00:12:20,830
have a bit of work to create your

00:12:18,250 --> 00:12:22,900
widgets and so on but we speak a bit

00:12:20,830 --> 00:12:25,180
because we know exactly how the data

00:12:22,900 --> 00:12:26,950
looks like we can predefined some of

00:12:25,180 --> 00:12:30,220
these dashboards for you so then you

00:12:26,950 --> 00:12:32,080
have some pretty good examples 41 our

00:12:30,220 --> 00:12:35,020
dashboards that you can you can start

00:12:32,080 --> 00:12:38,020
from for example here in the first row

00:12:35,020 --> 00:12:39,910
we have a simple count of the of the

00:12:38,020 --> 00:12:43,150
different transactions types so for

00:12:39,910 --> 00:12:46,840
different protocols HTTP database RPC

00:12:43,150 --> 00:12:48,820
and so on and on the second row we have

00:12:46,840 --> 00:12:52,120
some little bit more advanced

00:12:48,820 --> 00:12:53,980
visualizations for response times based

00:12:52,120 --> 00:12:56,470
only on the response times and I

00:12:53,980 --> 00:12:59,650
actually that's what I want to go a bit

00:12:56,470 --> 00:13:03,370
deeper into for example this one the

00:12:59,650 --> 00:13:06,250
percentage values over time they are

00:13:03,370 --> 00:13:07,960
done in elastic search by combining the

00:13:06,250 --> 00:13:11,290
date histogram with the percentage

00:13:07,960 --> 00:13:13,150
aggregations in general if you have a

00:13:11,290 --> 00:13:17,020
monitoring solution that gives you just

00:13:13,150 --> 00:13:20,950
averages for things like response time

00:13:17,020 --> 00:13:23,320
or load time or delay and so on that's

00:13:20,950 --> 00:13:24,940
not very good right averages are really

00:13:23,320 --> 00:13:27,540
not good for that thing it's much better

00:13:24,940 --> 00:13:29,860
to use things like percentiles and

00:13:27,540 --> 00:13:32,769
luckily in elastic search there

00:13:29,860 --> 00:13:35,680
the percentile segregation which does

00:13:32,769 --> 00:13:38,620
exactly that this is how the request

00:13:35,680 --> 00:13:41,230
looks like looks like you just give it

00:13:38,620 --> 00:13:43,510
the field where the data is found in our

00:13:41,230 --> 00:13:46,269
case in the packet the data case it's

00:13:43,510 --> 00:13:49,990
called response time and the percents

00:13:46,269 --> 00:13:51,810
that you want and this is how the

00:13:49,990 --> 00:13:56,070
response looks like right

00:13:51,810 --> 00:13:59,079
you just get aggregation and free values

00:13:56,070 --> 00:14:01,000
one thing you should know is that the

00:13:59,079 --> 00:14:03,910
percentage aggregation is using an

00:14:01,000 --> 00:14:06,820
approximate algorithm it's the digest by

00:14:03,910 --> 00:14:09,790
Ted learning and the funny thing is that

00:14:06,820 --> 00:14:11,920
Ted Anning has talked the Balian

00:14:09,790 --> 00:14:14,079
buzzwords I think right here just after

00:14:11,920 --> 00:14:17,950
lunch so I'm not going to talk too much

00:14:14,079 --> 00:14:20,140
about this but what you should remember

00:14:17,950 --> 00:14:22,440
is that it's an approximate algorithm

00:14:20,140 --> 00:14:24,940
but its properties make it very very

00:14:22,440 --> 00:14:30,760
convenient for for this type of data

00:14:24,940 --> 00:14:32,980
that we have okay and I as I said we

00:14:30,760 --> 00:14:35,070
need to come to create that graph we

00:14:32,980 --> 00:14:38,800
need to combine it with a date histogram

00:14:35,070 --> 00:14:42,430
and what the day histogram does is just

00:14:38,800 --> 00:14:45,640
blitz your your time interval in a small

00:14:42,430 --> 00:14:48,550
in your data in a small time intervals

00:14:45,640 --> 00:14:50,680
small or large in this case we use one

00:14:48,550 --> 00:14:53,110
minute but it's important to note that

00:14:50,680 --> 00:14:55,440
it can actually be one second or one

00:14:53,110 --> 00:14:57,910
millisecond so there's really no

00:14:55,440 --> 00:15:01,110
limitation in the resolution you get on

00:14:57,910 --> 00:15:06,040
graphs which i think is pretty cool

00:15:01,110 --> 00:15:07,779
all right and if you if if you so if you

00:15:06,040 --> 00:15:10,570
send that the request you get a response

00:15:07,779 --> 00:15:12,760
like this the key is always the start of

00:15:10,570 --> 00:15:14,980
the interval so the of the time interval

00:15:12,760 --> 00:15:18,250
in this case and the top count is

00:15:14,980 --> 00:15:20,709
included by default and in order to

00:15:18,250 --> 00:15:22,930
produce that graph we combine the two so

00:15:20,709 --> 00:15:25,839
you have a date histogram and nested

00:15:22,930 --> 00:15:29,350
within it is the percentage aggregation

00:15:25,839 --> 00:15:32,860
that we saw before and if you put them

00:15:29,350 --> 00:15:35,199
together the answer looks like this so

00:15:32,860 --> 00:15:37,540
now you have a list of intervals and for

00:15:35,199 --> 00:15:40,240
each intervals the free values for the

00:15:37,540 --> 00:15:43,089
for the percentile three we requested

00:15:40,240 --> 00:15:45,189
okay so if you plot that it looks like

00:15:43,089 --> 00:15:50,290
this which is what we wanted to start

00:15:45,189 --> 00:15:53,800
from now the Cabana config for that it

00:15:50,290 --> 00:15:56,709
it's also very simple on the y-axis you

00:15:53,800 --> 00:15:58,899
select the percentage percentage and on

00:15:56,709 --> 00:16:00,639
the x-axis you select the date histogram

00:15:58,899 --> 00:16:02,769
and this is how Cabana creates the

00:16:00,639 --> 00:16:07,199
request very similar with whatever I

00:16:02,769 --> 00:16:09,069
show it before and you get dive graph

00:16:07,199 --> 00:16:11,589
right

00:16:09,069 --> 00:16:13,779
okay so this is the latency histogram

00:16:11,589 --> 00:16:16,149
that shows it so this is a good way to

00:16:13,779 --> 00:16:18,790
show you an overview of the response

00:16:16,149 --> 00:16:22,379
time of your application for example in

00:16:18,790 --> 00:16:26,319
this diagram you see that most of your

00:16:22,379 --> 00:16:28,449
requests are a certain lasted 40

00:16:26,319 --> 00:16:35,350
milliseconds and there are a few that

00:16:28,449 --> 00:16:38,019
take up to 60 milliseconds in to

00:16:35,350 --> 00:16:40,809
implementation elasticsearch you create

00:16:38,019 --> 00:16:44,709
a histogram aggregation on the response

00:16:40,809 --> 00:16:48,040
time field within 10 milliseconds

00:16:44,709 --> 00:16:51,549
interval and this splits the data in in

00:16:48,040 --> 00:16:54,579
buckets by response time and you have a

00:16:51,549 --> 00:16:56,649
bucket in the head time interval from 0

00:16:54,579 --> 00:16:58,629
to 10 milliseconds and whether another

00:16:56,649 --> 00:17:01,480
one from 10 milliseconds to 20

00:16:58,629 --> 00:17:04,510
milliseconds and so on this is how the

00:17:01,480 --> 00:17:07,510
request will look like and the response

00:17:04,510 --> 00:17:11,409
that we get back contains the key which

00:17:07,510 --> 00:17:13,209
is a start of the interval that in the

00:17:11,409 --> 00:17:15,309
dock count which is a number of

00:17:13,209 --> 00:17:19,929
transactions that are included in this

00:17:15,309 --> 00:17:23,980
bucket if we put this in a graph we get

00:17:19,929 --> 00:17:27,390
something like this and we get a later

00:17:23,980 --> 00:17:30,399
cigarette the histogram that is

00:17:27,390 --> 00:17:33,880
constructed for the entire interval but

00:17:30,399 --> 00:17:37,149
what if we want to see the evolution of

00:17:33,880 --> 00:17:40,510
the latency histogram over time we can

00:17:37,149 --> 00:17:42,880
implement this in any elastic search by

00:17:40,510 --> 00:17:45,429
combining with a date histogram

00:17:42,880 --> 00:17:49,059
aggregation and is as you can see in the

00:17:45,429 --> 00:17:50,809
request we have our latency histogram

00:17:49,059 --> 00:17:55,490
nested in the

00:17:50,809 --> 00:17:58,100
that histogram aggregation and this is a

00:17:55,490 --> 00:18:01,179
response that we get back for the

00:17:58,100 --> 00:18:04,370
request and it contains a list of

00:18:01,179 --> 00:18:08,360
objects for each interval and each

00:18:04,370 --> 00:18:12,379
object contains all all the buckets with

00:18:08,360 --> 00:18:14,029
all the values for the response time and

00:18:12,379 --> 00:18:17,330
if we put this in a graph we see

00:18:14,029 --> 00:18:20,419
something like this where each part is

00:18:17,330 --> 00:18:22,789
represented it is representing in a in a

00:18:20,419 --> 00:18:29,690
time interval and the stacked colors

00:18:22,789 --> 00:18:31,820
represent latency histogram if we want

00:18:29,690 --> 00:18:35,269
to configure this in key bar now we need

00:18:31,820 --> 00:18:37,730
to set the y-axis to count and as access

00:18:35,269 --> 00:18:41,419
is to date histogram on time step and

00:18:37,730 --> 00:18:45,379
also to add the subrogation histogram on

00:18:41,419 --> 00:18:47,600
the response time all right

00:18:45,379 --> 00:18:50,690
another interesting feature that we make

00:18:47,600 --> 00:18:53,090
use of a lot from elasticsearch is the

00:18:50,690 --> 00:18:54,889
aggregations where you do top 10

00:18:53,090 --> 00:18:59,149
something right so you can do for

00:18:54,889 --> 00:19:04,519
example top 10 most frequent SQL queries

00:18:59,149 --> 00:19:06,830
or top 10 slowest HTTP code HTTP

00:19:04,519 --> 00:19:10,850
requests and so on right these are very

00:19:06,830 --> 00:19:13,909
useful for monitoring and let me pick

00:19:10,850 --> 00:19:16,039
one of the examples here it's it's maybe

00:19:13,909 --> 00:19:19,220
not the most visually appealing one but

00:19:16,039 --> 00:19:22,460
it's very useful it so shows you the

00:19:19,220 --> 00:19:24,230
slowest RPC methods sorted not by

00:19:22,460 --> 00:19:25,759
average as I said the average doesn't

00:19:24,230 --> 00:19:29,539
really make sense for this kind of data

00:19:25,759 --> 00:19:31,639
but but by the 99% of right and the the

00:19:29,539 --> 00:19:35,149
way that works is that it combines the

00:19:31,639 --> 00:19:38,570
terms and percentage aggregations the

00:19:35,149 --> 00:19:41,509
term segregation it splits the data in

00:19:38,570 --> 00:19:43,610
buckets like any aggregation does but

00:19:41,509 --> 00:19:45,740
what's different here is that it the

00:19:43,610 --> 00:19:48,860
buckets are dynamically built right it

00:19:45,740 --> 00:19:51,289
creates one for each unique value and by

00:19:48,860 --> 00:19:53,029
default it only returns the top 10 by by

00:19:51,289 --> 00:19:56,090
document count because of course there

00:19:53,029 --> 00:19:57,789
can be lots of unique values in the

00:19:56,090 --> 00:20:01,519
general case

00:19:57,789 --> 00:20:03,420
so the yeah it's also important to note

00:20:01,519 --> 00:20:06,540
here that the counts are

00:20:03,420 --> 00:20:08,430
proximate because each sharp might have

00:20:06,540 --> 00:20:11,430
a different opinion about what the top

00:20:08,430 --> 00:20:14,460
10 top tens are right so you cannot make

00:20:11,430 --> 00:20:16,260
it precise from there that reason but

00:20:14,460 --> 00:20:19,200
the good news is that elasticsearch will

00:20:16,260 --> 00:20:20,280
tell you how big there or can be so if

00:20:19,200 --> 00:20:22,380
you send this request

00:20:20,280 --> 00:20:25,590
where will you just choose field method

00:20:22,380 --> 00:20:28,290
and size 10 you get a response like this

00:20:25,590 --> 00:20:32,130
and you see in doc count error upper

00:20:28,290 --> 00:20:35,460
bound you get that in this case there is

00:20:32,130 --> 00:20:39,330
no error that you should expect and then

00:20:35,460 --> 00:20:43,590
you get the list of as we as I did it

00:20:39,330 --> 00:20:45,870
here with no without any ordering just

00:20:43,590 --> 00:20:49,110
the default one by dog count you get the

00:20:45,870 --> 00:20:50,910
most frequent RPC method calls from from

00:20:49,110 --> 00:20:54,240
the data right which are calculate

00:20:50,910 --> 00:20:57,660
depending in this case but now if we

00:20:54,240 --> 00:21:00,360
want to order it by the 99% deals we can

00:20:57,660 --> 00:21:02,850
do that by using a sub aggregation on

00:21:00,360 --> 00:21:08,610
the on the percentage and use the order

00:21:02,850 --> 00:21:10,500
close to to say that which which of

00:21:08,610 --> 00:21:13,050
these sub obligations we want to use and

00:21:10,500 --> 00:21:15,540
order descending or ascending so if you

00:21:13,050 --> 00:21:17,040
send them this request then the response

00:21:15,540 --> 00:21:20,280
will look something like this

00:21:17,040 --> 00:21:22,370
right so it's it's it's no longer sorted

00:21:20,280 --> 00:21:25,380
by dog count but it's sorted by the

00:21:22,370 --> 00:21:27,420
response times percentiles and you also

00:21:25,380 --> 00:21:30,930
get the values there so you can Det use

00:21:27,420 --> 00:21:33,450
that to put into a into a graph if you

00:21:30,930 --> 00:21:36,690
want to do this in a in Cubana

00:21:33,450 --> 00:21:40,020
you choose the metric percentage and

00:21:36,690 --> 00:21:42,630
then you can when you configure the

00:21:40,020 --> 00:21:44,070
terms aggregations it offers you to

00:21:42,630 --> 00:21:47,580
order by it so that's also very

00:21:44,070 --> 00:21:49,200
convenient all right before we move to

00:21:47,580 --> 00:21:51,990
the next thing I just want to mention

00:21:49,200 --> 00:21:54,510
and a couple of tips one is that there

00:21:51,990 --> 00:21:58,590
is a live demo demo dot elastic dot go

00:21:54,510 --> 00:22:01,290
slash packet bit which you where you can

00:21:58,590 --> 00:22:04,650
see and play with this this type of data

00:22:01,290 --> 00:22:08,450
I also put examples for aggregations

00:22:04,650 --> 00:22:10,740
that we have in this github repo and

00:22:08,450 --> 00:22:13,710
also I wanted to mention that you should

00:22:10,740 --> 00:22:15,780
use sense it's a chromatin I have to

00:22:13,710 --> 00:22:17,169
admit I learned the way to too late

00:22:15,780 --> 00:22:19,429
about it and I

00:22:17,169 --> 00:22:21,950
fiddling with Carl to do these kind of

00:22:19,429 --> 00:22:23,210
things you should yeah if you just in

00:22:21,950 --> 00:22:26,599
case you don't know about it

00:22:23,210 --> 00:22:30,139
you should really use it right another

00:22:26,599 --> 00:22:32,719
tip is that when you use Cabana you can

00:22:30,139 --> 00:22:34,789
always see what aggregations are sent

00:22:32,719 --> 00:22:37,190
this was reality in Cabana free as well

00:22:34,789 --> 00:22:40,940
but it's also works in Cleburne ofor so

00:22:37,190 --> 00:22:42,859
you can click on the on the arrow there

00:22:40,940 --> 00:22:45,349
and choose the request tab and you can

00:22:42,859 --> 00:22:48,320
see exactly what the aggregations are

00:22:45,349 --> 00:22:50,330
sent to elasticsearch so it's a good way

00:22:48,320 --> 00:22:54,679
of learning new aggregations you just

00:22:50,330 --> 00:22:59,659
look how Cabana does it okay now let's

00:22:54,679 --> 00:23:03,830
talk a bit about the future and as

00:22:59,659 --> 00:23:05,599
Monica said in the beginning we the the

00:23:03,830 --> 00:23:08,659
problem we are trying to solve was about

00:23:05,599 --> 00:23:10,159
monitoring distributed systems and we

00:23:08,659 --> 00:23:12,799
thought it's a good way to start with

00:23:10,159 --> 00:23:14,210
packet did they respect data but that

00:23:12,799 --> 00:23:16,759
was always meant to be just the

00:23:14,210 --> 00:23:20,359
beginning the beginning and actually we

00:23:16,759 --> 00:23:23,960
wanted to add over time more sources of

00:23:20,359 --> 00:23:26,149
data so like OS readings for CPU memory

00:23:23,960 --> 00:23:30,619
and so on maybe called instrumentation

00:23:26,149 --> 00:23:32,149
tracing data from API gateways or just

00:23:30,619 --> 00:23:35,989
internal stats from from different

00:23:32,149 --> 00:23:38,869
servers right and we are talking with

00:23:35,989 --> 00:23:41,029
Shai been on who you might know is the

00:23:38,869 --> 00:23:44,960
city of elastic the company behind

00:23:41,029 --> 00:23:47,389
elastic search cabana and log stash and

00:23:44,960 --> 00:23:50,440
we realized that we have quite a bit of

00:23:47,389 --> 00:23:55,039
a common vision regarding these things

00:23:50,440 --> 00:23:59,570
so so here's some great news to announce

00:23:55,039 --> 00:24:03,830
that we recently join forces elastic and

00:23:59,570 --> 00:24:06,799
so packet bit will is from now on is

00:24:03,830 --> 00:24:10,369
part of elastic project is one of the

00:24:06,799 --> 00:24:13,309
elastic project like a last like keep an

00:24:10,369 --> 00:24:15,559
eye on the log stash and we also also

00:24:13,309 --> 00:24:21,289
have to change your bits of mass code to

00:24:15,559 --> 00:24:24,710
include the elastic bubble and we are

00:24:21,289 --> 00:24:28,190
keeping the project open-source moreover

00:24:24,710 --> 00:24:30,049
we change the license from GPL version 2

00:24:28,190 --> 00:24:37,590
to a posse

00:24:30,049 --> 00:24:41,820
and yeah yeah we can yeah so our mission

00:24:37,590 --> 00:24:45,929
is inelastic now is to ship operational

00:24:41,820 --> 00:24:50,729
data to elasticsearch not only a packet

00:24:45,929 --> 00:24:52,799
data but all kinds of of data right so

00:24:50,729 --> 00:24:55,320
we we came up with this idea that we can

00:24:52,799 --> 00:24:58,350
we have now packet like we have now

00:24:55,320 --> 00:25:00,840
packet bit for packet data we could have

00:24:58,350 --> 00:25:03,389
also filed bit for log files for example

00:25:00,840 --> 00:25:07,009
this actually already exists in the form

00:25:03,389 --> 00:25:11,669
of locks that for order but we want to

00:25:07,009 --> 00:25:13,889
improve it and make it a real bit and in

00:25:11,669 --> 00:25:16,470
the future we can also have other other

00:25:13,889 --> 00:25:18,599
bits as well these are just ideas but

00:25:16,470 --> 00:25:21,210
they could have like a top bit for CPU

00:25:18,599 --> 00:25:24,330
memory and so on a metric speed which

00:25:21,210 --> 00:25:27,749
could use plugins like Nagios or sense

00:25:24,330 --> 00:25:30,059
of dies or you can have ROM bit which

00:25:27,749 --> 00:25:32,399
comes from real user monitoring bit

00:25:30,059 --> 00:25:37,499
which takes data from the browser these

00:25:32,399 --> 00:25:41,190
are just just different ideas that we

00:25:37,499 --> 00:25:42,899
could implement in the future yeah so if

00:25:41,190 --> 00:25:45,210
you want to stay in touch with us we

00:25:42,899 --> 00:25:48,599
have a Twitter account take it at packet

00:25:45,210 --> 00:25:52,080
bit we also have a forum and discuss dot

00:25:48,599 --> 00:25:54,629
Elysee dot coded slash this slash bits

00:25:52,080 --> 00:25:56,700
and also we are preparing for the

00:25:54,629 --> 00:26:00,179
webinar and we encourage you to sign for

00:25:56,700 --> 00:26:03,479
our webinar the webinar will be a bit

00:26:00,179 --> 00:26:07,259
different than our talk it will contain

00:26:03,479 --> 00:26:10,080
more practical hands-on like how to

00:26:07,259 --> 00:26:15,119
configure Becky B's how to run it and so

00:26:10,080 --> 00:26:17,159
on so feel free to sign up alright and

00:26:15,119 --> 00:26:19,580
that this was it if you have any

00:26:17,159 --> 00:26:19,580

YouTube URL: https://www.youtube.com/watch?v=x5vA-HIYHmE


