Title: Berlin Buzzwords 2015: Stephan Ewen - Apache Flink deep-dive #bbuzz
Publication date: 2015-06-03
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	Apache Flink is a distributed engine for batch and streaming data analysis. Flink offers familiar programming APIs based on parallel collections that represent data streams and transformations and window definitions on these collections.

Flink supports these APIs with a robust execution backend. Both batch and streaming APIs are backed by the same execution engine that has true streaming capabilities, resulting in true real-time stream processing and latency reduction in many batch programs. 

Flink implements its own memory manager and custom data processing algorithms inside the JVM, which makes the system behave very robustly both in-memory and under memory pressure. Flink has iterative processing built-in, implementing native iteration operators that create dataflows with feedback. Finally, Flink contains its own cost-based optimizer, type extraction, and data serialization stack.

Read more:
https://2015.berlinbuzzwords.de/session/apache-flink-deep-dive

About Stephan Ewen:
https://2015.berlinbuzzwords.de/users/sewen

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:00,000 --> 00:00:02,030
I

00:00:05,980 --> 00:00:12,010
thank you hello everybody my name is

00:00:10,389 --> 00:00:16,059
Stefan I'm

00:00:12,010 --> 00:00:19,500
out Apache chief link today basically

00:00:16,059 --> 00:00:25,050
been here a year ago talking about a

00:00:19,500 --> 00:00:29,590
project called stratosphere that was

00:00:25,050 --> 00:00:33,129
back then a project coming out of half

00:00:29,590 --> 00:00:35,020
of university research collaborative

00:00:33,129 --> 00:00:38,020
research here in the in the in the area

00:00:35,020 --> 00:00:40,840
of Berlin and it was just very very very

00:00:38,020 --> 00:00:42,940
recently last year that it had been

00:00:40,840 --> 00:00:46,750
accepted at the Apache Incubator as a

00:00:42,940 --> 00:00:49,449
project was um sorry I just to the

00:00:46,750 --> 00:00:51,430
button here yeah it was that it had been

00:00:49,449 --> 00:00:52,659
accepted as a as an Apache project into

00:00:51,430 --> 00:00:55,690
the incubator was still called

00:00:52,659 --> 00:00:58,000
stratosphere back then I think we we

00:00:55,690 --> 00:01:01,930
knew that we were renaming it to flink

00:00:58,000 --> 00:01:04,629
so now now a year later I'm actually

00:01:01,930 --> 00:01:06,130
here to to show you what what what this

00:01:04,629 --> 00:01:09,790
has become what actually fling has

00:01:06,130 --> 00:01:12,640
become within a year um a little about

00:01:09,790 --> 00:01:14,860
myself maybe I think the by when the

00:01:12,640 --> 00:01:16,900
program is wrong we just accidentally

00:01:14,860 --> 00:01:21,160
forward copied the the one from last

00:01:16,900 --> 00:01:24,790
year so the the core the core team

00:01:21,160 --> 00:01:26,920
behind flink that I'm net that started

00:01:24,790 --> 00:01:28,960
this this effort giving it to the Apache

00:01:26,920 --> 00:01:31,090
Incubator and so honest it's no longer

00:01:28,960 --> 00:01:33,460
with the university even though it says

00:01:31,090 --> 00:01:34,720
it in the program um a bunch of us

00:01:33,460 --> 00:01:37,750
actually started a company here in

00:01:34,720 --> 00:01:39,910
Berlin courted artisans and where yeah

00:01:37,750 --> 00:01:42,780
we're we're developing flink we are

00:01:39,910 --> 00:01:47,980
supporting people who who want to use it

00:01:42,780 --> 00:01:50,950
okay um let me let me try and calibrate

00:01:47,980 --> 00:01:52,420
a little bit to the 22 how much you you

00:01:50,950 --> 00:01:54,010
may have heard her may have not heard

00:01:52,420 --> 00:01:55,659
about fling before so I can I can't

00:01:54,010 --> 00:02:00,220
briefly ask you who of you has actually

00:01:55,659 --> 00:02:02,220
heard of link before this talk but it's

00:02:00,220 --> 00:02:04,780
a good bunch who of you has actually

00:02:02,220 --> 00:02:08,590
tried it out in terms of downloaded it

00:02:04,780 --> 00:02:10,330
and try to try to write write a few jobs

00:02:08,590 --> 00:02:15,489
that's actually a few hands at least I

00:02:10,330 --> 00:02:17,080
was actually cool to see okay to get a

00:02:15,489 --> 00:02:22,660
little bit the notion who have used

00:02:17,080 --> 00:02:25,460
familiar with storm spark

00:02:22,660 --> 00:02:28,580
all right I don't ask what my produce I

00:02:25,460 --> 00:02:31,430
assume that this is I see a lot of hands

00:02:28,580 --> 00:02:33,800
there okay that's actually good so let

00:02:31,430 --> 00:02:37,660
me try and use this to put things into

00:02:33,800 --> 00:02:39,650
perspective a little bit okay so um what

00:02:37,660 --> 00:02:41,990
what would you can see here is that

00:02:39,650 --> 00:02:43,400
since the last last time we were here at

00:02:41,990 --> 00:02:45,050
bill in buzz words we started out with

00:02:43,400 --> 00:02:47,210
the system called called stratosphere it

00:02:45,050 --> 00:02:51,730
was a pretty pretty small thing it had a

00:02:47,210 --> 00:02:54,920
bit of a rant I'm core a betch API and a

00:02:51,730 --> 00:02:56,750
few modes to run your jobs and within

00:02:54,920 --> 00:02:58,310
this one year actually the the fling

00:02:56,750 --> 00:03:00,800
community has grown this 22 quite a

00:02:58,310 --> 00:03:03,040
quite a fat stack which can which can do

00:03:00,800 --> 00:03:07,300
do a few very interesting things and um

00:03:03,040 --> 00:03:12,140
I'd like to introduce you to those and

00:03:07,300 --> 00:03:17,300
in this talk so um first of all in the

00:03:12,140 --> 00:03:19,280
heart what is fling fling is a it's a

00:03:17,300 --> 00:03:21,590
net it's an entire like software stack

00:03:19,280 --> 00:03:25,490
but the very heart of link is a

00:03:21,590 --> 00:03:28,190
streaming data flow engine an engine

00:03:25,490 --> 00:03:30,290
that that thing's of programs in terms

00:03:28,190 --> 00:03:32,780
of operators and data streams that

00:03:30,290 --> 00:03:34,670
connect them it is in some sense like

00:03:32,780 --> 00:03:37,730
like a storm topology only that these

00:03:34,670 --> 00:03:40,700
operators may be extremely rich and that

00:03:37,730 --> 00:03:42,980
the that the way of communication and

00:03:40,700 --> 00:03:45,080
thinking about state and snapshotting

00:03:42,980 --> 00:03:47,330
and so on works differently but yeah I

00:03:45,080 --> 00:03:48,560
mean the notion of having a data flow is

00:03:47,330 --> 00:03:53,060
a bit like a streaming streaming

00:03:48,560 --> 00:03:55,580
topology this streaming data flow engine

00:03:53,060 --> 00:03:57,620
can present itself actually as a as a

00:03:55,580 --> 00:04:00,200
batch processor and as a stream

00:03:57,620 --> 00:04:04,220
processor both at the same boat at the

00:04:00,200 --> 00:04:05,810
at the same time and I mean it seems

00:04:04,220 --> 00:04:07,489
natural that the streaming data flow can

00:04:05,810 --> 00:04:08,750
present itself as a stream processors as

00:04:07,489 --> 00:04:11,000
a batch processor I'm going to talk a

00:04:08,750 --> 00:04:15,170
little bit about those those details

00:04:11,000 --> 00:04:17,030
later a streaming engine turns out to be

00:04:15,170 --> 00:04:19,340
actually quite a good fit for fit for

00:04:17,030 --> 00:04:21,830
for a batch processor and while this may

00:04:19,340 --> 00:04:23,690
initially sound a little esoteric for

00:04:21,830 --> 00:04:26,900
those of you that have read a little bit

00:04:23,690 --> 00:04:28,880
into let's say the the the blog posts

00:04:26,900 --> 00:04:31,729
from yeah from Martin clapman or Jay

00:04:28,880 --> 00:04:33,590
crafts well they might be familiar with

00:04:31,729 --> 00:04:34,820
the term cup architecture was a which is

00:04:33,590 --> 00:04:37,310
exactly that concept

00:04:34,820 --> 00:04:39,140
running batch programs as special cases

00:04:37,310 --> 00:04:40,730
of swimming programs so this is sort of

00:04:39,140 --> 00:04:43,250
what the concept that fling follows here

00:04:40,730 --> 00:04:47,720
as well I'll share a few details in a

00:04:43,250 --> 00:04:49,940
bit so on top of these these AP is the

00:04:47,720 --> 00:04:53,600
bed api we call that the data set API

00:04:49,940 --> 00:04:56,810
thinking of a set as a yeah as a fixed

00:04:53,600 --> 00:04:59,330
size data set distributed on the data

00:04:56,810 --> 00:05:02,900
stream API speaking of data streams as

00:04:59,330 --> 00:05:05,960
infinite streams of data on top of this

00:05:02,900 --> 00:05:07,970
data set the badge API we've we've added

00:05:05,960 --> 00:05:10,580
a couple of libraries so there's support

00:05:07,970 --> 00:05:12,500
to to run Hadoop you had to your dupe

00:05:10,580 --> 00:05:14,900
functions map functions reduce functions

00:05:12,500 --> 00:05:16,940
input formats or performance there's

00:05:14,900 --> 00:05:21,350
something called it the table API which

00:05:16,940 --> 00:05:25,220
is a way of exposing these data sets in

00:05:21,350 --> 00:05:27,260
in a more logical way so not not with a

00:05:25,220 --> 00:05:30,350
physical schema in the sense of there's

00:05:27,260 --> 00:05:32,150
a class or at a pole or so in Java or

00:05:30,350 --> 00:05:33,890
Scala that defines what this is but

00:05:32,150 --> 00:05:36,020
something like a sequel schema that

00:05:33,890 --> 00:05:38,630
defines the data that goes that goes

00:05:36,020 --> 00:05:40,940
through there a graph api called jelly

00:05:38,630 --> 00:05:42,470
and machine learning library called yeah

00:05:40,940 --> 00:05:44,270
we haven't come up with a very good

00:05:42,470 --> 00:05:46,730
neighbor right now it's just called ml

00:05:44,270 --> 00:05:49,850
at this point in time we're still open

00:05:46,730 --> 00:05:51,470
to good suggestions there and there's

00:05:49,850 --> 00:05:53,900
this quite a bit of work in progress so

00:05:51,470 --> 00:05:55,940
this there's an adapter to run where

00:05:53,900 --> 00:05:58,130
Google Cloud dataflow on on fling kits

00:05:55,940 --> 00:06:00,560
it's google's hosted service so if you

00:05:58,130 --> 00:06:02,660
want to run it um if you want to run it

00:06:00,560 --> 00:06:05,900
on your own data infrastructure you need

00:06:02,660 --> 00:06:08,450
you need another runner and flink is one

00:06:05,900 --> 00:06:10,700
of the candidates there I'm RQL this

00:06:08,450 --> 00:06:14,300
another Apache project for I think of a

00:06:10,700 --> 00:06:16,460
very very principled functional our API

00:06:14,300 --> 00:06:18,500
based on list comprehensions and kiss

00:06:16,460 --> 00:06:20,000
skating I would assume a lot of your

00:06:18,500 --> 00:06:23,660
only heard of cascading is was one of

00:06:20,000 --> 00:06:25,310
the first um first tools on top of on

00:06:23,660 --> 00:06:27,290
top of MapReduce to build more elaborate

00:06:25,310 --> 00:06:30,590
programs so there's also work on running

00:06:27,290 --> 00:06:32,060
his kidding at above link on the other

00:06:30,590 --> 00:06:34,250
side of data streams we have

00:06:32,060 --> 00:06:36,380
interestingly even though the runtime is

00:06:34,250 --> 00:06:37,910
streaming we've spent initially a lot of

00:06:36,380 --> 00:06:39,440
work on the bedside because that seemed

00:06:37,910 --> 00:06:41,000
to be what people were familiar with

00:06:39,440 --> 00:06:43,790
what they were using they were looking

00:06:41,000 --> 00:06:46,310
at and we've recently started exposing

00:06:43,790 --> 00:06:48,950
the the streaming capabilities of link a

00:06:46,310 --> 00:06:51,380
lot more with this data stream API

00:06:48,950 --> 00:06:53,720
and started putting a few libraries on

00:06:51,380 --> 00:06:56,870
top of that as well so this table API is

00:06:53,720 --> 00:06:59,050
in I say in a restricted form also are

00:06:56,870 --> 00:07:02,000
running on the data stream abstraction

00:06:59,050 --> 00:07:03,590
some more as a very recent project that

00:07:02,000 --> 00:07:04,850
that entered Apache but it's very very

00:07:03,590 --> 00:07:06,650
interesting it's actually a machine

00:07:04,850 --> 00:07:10,340
learning library on top of streaming so

00:07:06,650 --> 00:07:12,080
it's um it thinks in terms of streams

00:07:10,340 --> 00:07:13,910
with asynchronous feedback and tries to

00:07:12,080 --> 00:07:17,840
do online learners are based on these

00:07:13,910 --> 00:07:22,280
streams and yeah cloud dataflow also has

00:07:17,840 --> 00:07:24,890
streaming streaming component and we're

00:07:22,280 --> 00:07:27,410
porting this actually to to the data

00:07:24,890 --> 00:07:29,480
stream API as well so with these

00:07:27,410 --> 00:07:33,140
abstractions sitting on top of on top of

00:07:29,480 --> 00:07:35,600
the fling stack there's a oh yeah a

00:07:33,140 --> 00:07:37,160
couple of ways to run this I'm in your

00:07:35,600 --> 00:07:38,750
infrastructure so you can you can always

00:07:37,160 --> 00:07:40,850
run it locally in your IDE for debugging

00:07:38,750 --> 00:07:42,200
you can run it where we call remote is

00:07:40,850 --> 00:07:44,360
we should probably call the spare metal

00:07:42,200 --> 00:07:45,830
also it is if you just run the flink

00:07:44,360 --> 00:07:48,380
demon on every machine it can run it

00:07:45,830 --> 00:07:50,840
there you can run it through yarn you

00:07:48,380 --> 00:07:54,050
can run it just embed it in in other

00:07:50,840 --> 00:07:55,970
java applications where it uses a very

00:07:54,050 --> 00:07:58,640
very lightweight non-parallel way of

00:07:55,970 --> 00:08:00,770
executing programs and and what is very

00:07:58,640 --> 00:08:05,030
interesting is that actually tells is on

00:08:00,770 --> 00:08:08,600
this on this slide here apache tez is a

00:08:05,030 --> 00:08:11,660
project that started out as um as part

00:08:08,600 --> 00:08:14,720
of the of the initiative to to make high

00:08:11,660 --> 00:08:17,360
faster i think it's mainly use actually

00:08:14,720 --> 00:08:18,860
as the distributed scheduling and

00:08:17,360 --> 00:08:25,010
communication back end of the newer

00:08:18,860 --> 00:08:26,810
versions of yeah hi fountas and the the

00:08:25,010 --> 00:08:28,400
architecture of link is layered in such

00:08:26,810 --> 00:08:30,770
a way that we can swap a lot of

00:08:28,400 --> 00:08:33,410
components at individual parts so we can

00:08:30,770 --> 00:08:36,110
actually say that we execute a streaming

00:08:33,410 --> 00:08:37,760
data flow if these streams happen to be

00:08:36,110 --> 00:08:40,430
file streams or so so they're actually

00:08:37,760 --> 00:08:41,900
not infinite streams but finite streams

00:08:40,430 --> 00:08:44,240
they happen to represent batch programs

00:08:41,900 --> 00:08:47,930
we can actually run those on on this tez

00:08:44,240 --> 00:08:49,730
engine which which is yeah which is for

00:08:47,930 --> 00:08:51,890
it's pretty good for a fuse cases

00:08:49,730 --> 00:08:53,510
because it implements them very very

00:08:51,890 --> 00:08:57,110
neat characteristics with yarn

00:08:53,510 --> 00:08:59,930
elasticity and auto scaling and so on ok

00:08:57,110 --> 00:09:06,589
but this talks about the core of link

00:08:59,930 --> 00:09:08,450
so um in order to understand why why we

00:09:06,589 --> 00:09:13,610
push the design of the architecture of

00:09:08,450 --> 00:09:15,500
link the way the way it is we we should

00:09:13,610 --> 00:09:16,940
have a look at what we're actually the

00:09:15,500 --> 00:09:21,470
use cases that were that we were trying

00:09:16,940 --> 00:09:23,149
to solve with flink and the set of use

00:09:21,470 --> 00:09:25,580
cases has become extremely diverse in

00:09:23,149 --> 00:09:28,100
that field so we're we're definitely not

00:09:25,580 --> 00:09:30,670
looking at any any use cases from the

00:09:28,100 --> 00:09:33,040
area of the same or transactional

00:09:30,670 --> 00:09:37,130
processing the field where you would use

00:09:33,040 --> 00:09:39,170
no sequel style databases HBase MongoDB

00:09:37,130 --> 00:09:41,240
Cassandra so no flink is purely in the

00:09:39,170 --> 00:09:42,890
analytical side but the analytical side

00:09:41,240 --> 00:09:48,050
in itself has become very very diverse

00:09:42,890 --> 00:09:49,970
and here here are four for use cases

00:09:48,050 --> 00:09:51,470
that I think sort of categorized a

00:09:49,970 --> 00:09:53,180
pretty broad spectrum of things that we

00:09:51,470 --> 00:09:54,680
were trying to do trying to run

00:09:53,180 --> 00:09:57,140
streaming topologies real-time streaming

00:09:54,680 --> 00:09:59,270
topologies with with complex operations

00:09:57,140 --> 00:10:03,170
and low low latency complex operations

00:09:59,270 --> 00:10:05,300
in terms of um being able to flexibly

00:10:03,170 --> 00:10:08,150
window with the events dreams and and

00:10:05,300 --> 00:10:11,330
detect patterns on the event streams at

00:10:08,150 --> 00:10:13,370
the same time of course match pipelines

00:10:11,330 --> 00:10:16,540
are probably the most the most

00:10:13,370 --> 00:10:18,620
established use case of those

00:10:16,540 --> 00:10:21,350
large-scale machine learning is becoming

00:10:18,620 --> 00:10:23,240
increasingly interesting and people are

00:10:21,350 --> 00:10:25,310
still are still showing quite an

00:10:23,240 --> 00:10:28,279
interesting graph analysis as well so

00:10:25,310 --> 00:10:30,230
we're trying to to look okay but how can

00:10:28,279 --> 00:10:32,600
you build an engine that is that is a

00:10:30,230 --> 00:10:36,290
good match for these diverse use cases

00:10:32,600 --> 00:10:38,000
and in the terms of that that the engine

00:10:36,290 --> 00:10:40,700
really has primitives to execute the

00:10:38,000 --> 00:10:43,370
operations that are are needed for these

00:10:40,700 --> 00:10:46,250
for these use cases natively natively in

00:10:43,370 --> 00:10:49,070
the in the sense of that we don't try to

00:10:46,250 --> 00:10:53,060
work around certain characteristics and

00:10:49,070 --> 00:10:54,950
buildings around that sort of yeah sort

00:10:53,060 --> 00:10:57,350
of mitigate these effects but have have

00:10:54,950 --> 00:10:58,790
proper primitives in there so in order

00:10:57,350 --> 00:11:01,130
to make this a bit more concrete what

00:10:58,790 --> 00:11:02,930
does what is a native support mean have

00:11:01,130 --> 00:11:06,490
two examples of what what is not native

00:11:02,930 --> 00:11:09,529
this may actually have to explain it so

00:11:06,490 --> 00:11:11,180
if you look at machine learning in in

00:11:09,529 --> 00:11:12,830
this field one of the first things that

00:11:11,180 --> 00:11:16,310
that people did

00:11:12,830 --> 00:11:18,740
was yeah mapreduce came out it was was

00:11:16,310 --> 00:11:21,110
great and in the way it gave you a very

00:11:18,740 --> 00:11:25,850
very nice and easy way of our scaling

00:11:21,110 --> 00:11:27,680
computation and in order to run the 22

00:11:25,850 --> 00:11:29,510
to do the patterns that a lot of the

00:11:27,680 --> 00:11:32,990
machine learning algorithms have the

00:11:29,510 --> 00:11:34,940
iterative computations where you're

00:11:32,990 --> 00:11:37,520
repeatedly loop of the training data in

00:11:34,940 --> 00:11:38,900
order to refine the parameters the way

00:11:37,520 --> 00:11:41,390
people were implementing this is they

00:11:38,900 --> 00:11:43,730
were saying okay let me let me ask yet

00:11:41,390 --> 00:11:47,720
me right one step as a MapReduce program

00:11:43,730 --> 00:11:50,120
and then repeatedly execute this um so

00:11:47,720 --> 00:11:52,460
in some sense you were just running

00:11:50,120 --> 00:11:54,550
multiple jobs one after another and it

00:11:52,460 --> 00:11:58,360
and it's very interesting in some sense

00:11:54,550 --> 00:12:00,500
this space is to a large extent still

00:11:58,360 --> 00:12:01,970
actually still at this model I think I

00:12:00,500 --> 00:12:04,550
mean people have come up with better

00:12:01,970 --> 00:12:07,040
things in terms of caching invariant

00:12:04,550 --> 00:12:08,720
stuff in memory representing data

00:12:07,040 --> 00:12:11,300
structures in a way they can be reused

00:12:08,720 --> 00:12:12,590
across steps but for a lot of systems

00:12:11,300 --> 00:12:18,800
that still pretty much what they're

00:12:12,590 --> 00:12:20,960
doing and another another use case is if

00:12:18,800 --> 00:12:23,810
you want to do streaming and what you

00:12:20,960 --> 00:12:26,480
have is a batch processor you can you

00:12:23,810 --> 00:12:28,700
can do a lot of very very small batch

00:12:26,480 --> 00:12:30,650
jobs right you can discretize the stream

00:12:28,700 --> 00:12:32,840
you can you can chunk it up and to into

00:12:30,650 --> 00:12:35,450
little parts and then run run a batch

00:12:32,840 --> 00:12:37,070
part for each for each of those and how

00:12:35,450 --> 00:12:38,270
are large these parts are sort of

00:12:37,070 --> 00:12:40,550
depends on what you want to do right

00:12:38,270 --> 00:12:44,000
there can be daily they can be now they

00:12:40,550 --> 00:12:46,910
can be a second um this does work for

00:12:44,000 --> 00:12:48,890
for a good set of use cases it is put

00:12:46,910 --> 00:12:52,280
restrictions on on what you can do

00:12:48,890 --> 00:12:55,550
across these these mini these matches

00:12:52,280 --> 00:12:58,070
these yeah stream dis chris discretized

00:12:55,550 --> 00:12:59,570
units so when whenever you you have

00:12:58,070 --> 00:13:01,040
something that's not a that's not an

00:12:59,570 --> 00:13:04,430
easy aggregation that you carry across

00:13:01,040 --> 00:13:08,720
this is this may be a bit tricky to work

00:13:04,430 --> 00:13:10,450
with so what we're looking at what is it

00:13:08,720 --> 00:13:14,030
what is a good abstraction actually to

00:13:10,450 --> 00:13:15,800
to work with these use cases and and and

00:13:14,030 --> 00:13:19,390
that sort of gave is the the corner

00:13:15,800 --> 00:13:21,830
points for for the design of link and

00:13:19,390 --> 00:13:24,650
well what those are not all of them I

00:13:21,830 --> 00:13:25,040
think those are the four most important

00:13:24,650 --> 00:13:26,930
ones

00:13:25,040 --> 00:13:30,649
that have sort of surfaced over the over

00:13:26,930 --> 00:13:32,089
the last year and not number one is I've

00:13:30,649 --> 00:13:34,910
already hinted at that is the big at the

00:13:32,089 --> 00:13:38,870
beginning is well actually execute

00:13:34,910 --> 00:13:40,730
execute things are streams the batch

00:13:38,870 --> 00:13:42,380
paradigm made a very very strong move

00:13:40,730 --> 00:13:44,120
into this into this field with MapReduce

00:13:42,380 --> 00:13:46,670
but we're actually seeing that the

00:13:44,120 --> 00:13:49,819
streaming code is sort of a sort of

00:13:46,670 --> 00:13:51,949
coming back because done done the right

00:13:49,819 --> 00:13:53,779
way it has it has a few interesting

00:13:51,949 --> 00:13:55,579
advantages over the batch paradigm and

00:13:53,779 --> 00:13:57,170
interestingly if subsumes it because you

00:13:55,579 --> 00:14:00,560
can always think of patches a special

00:13:57,170 --> 00:14:04,819
case of streaming the the second corner

00:14:00,560 --> 00:14:07,850
point is um if you want to do a turret

00:14:04,819 --> 00:14:10,940
of computation it's actually a good

00:14:07,850 --> 00:14:13,790
thing to sort of have this in the system

00:14:10,940 --> 00:14:17,300
in the runtime in the data flow allow

00:14:13,790 --> 00:14:20,149
for a certain controlled way of feeding

00:14:17,300 --> 00:14:21,290
back data because if if you're doing

00:14:20,149 --> 00:14:23,750
this if you're actually making the

00:14:21,290 --> 00:14:25,519
system aware of these iterations it can

00:14:23,750 --> 00:14:29,480
do a few a few nice things and is also

00:14:25,519 --> 00:14:31,910
not bound to to to certain barriers so

00:14:29,480 --> 00:14:34,130
um as you are if you execute things in

00:14:31,910 --> 00:14:36,350
in luck in super steps and synchronous

00:14:34,130 --> 00:14:40,730
super steps in the the bulk synchronous

00:14:36,350 --> 00:14:42,620
parallelism paradigm the third point and

00:14:40,730 --> 00:14:44,240
this is this is probably more

00:14:42,620 --> 00:14:47,000
interesting for streaming but we see it

00:14:44,240 --> 00:14:49,040
also for graph analysis is to to to

00:14:47,000 --> 00:14:51,560
really think about what to do with state

00:14:49,040 --> 00:14:54,290
during computation the the paradigm of

00:14:51,560 --> 00:14:56,060
the of the batch processing is has been

00:14:54,290 --> 00:14:58,339
pretty much you have an input you have

00:14:56,060 --> 00:15:00,290
an output the function produces its

00:14:58,339 --> 00:15:02,750
output based on the input this no state

00:15:00,290 --> 00:15:04,579
they concern themselves with this is

00:15:02,750 --> 00:15:06,319
good for a lot of cases statelessness

00:15:04,579 --> 00:15:09,290
makes things extremely easy to reason

00:15:06,319 --> 00:15:11,420
about easy to paralyze and so on um for

00:15:09,290 --> 00:15:14,029
certain operations having a way of of

00:15:11,420 --> 00:15:15,800
having state is extremely beneficial and

00:15:14,029 --> 00:15:17,420
there are ways of actually abstracting

00:15:15,800 --> 00:15:20,029
states such that it isn't break that

00:15:17,420 --> 00:15:21,380
paradigm in some cases it does in some

00:15:20,029 --> 00:15:23,360
cases you also have to worry them

00:15:21,380 --> 00:15:26,060
exactly what how does this affect my

00:15:23,360 --> 00:15:29,480
fault tolerance and we're going to talk

00:15:26,060 --> 00:15:32,089
about that in a bit and the fourth point

00:15:29,480 --> 00:15:36,230
is something that has come up also in

00:15:32,089 --> 00:15:37,939
the the last year's more and more um it

00:15:36,230 --> 00:15:38,819
seems the Java ecosystem is really

00:15:37,939 --> 00:15:40,799
dominating

00:15:38,819 --> 00:15:44,039
this this field at least in the in the

00:15:40,799 --> 00:15:47,549
open source the open source space with a

00:15:44,039 --> 00:15:50,339
few exceptions and if you want to do

00:15:47,549 --> 00:15:51,749
something data intensive just relying on

00:15:50,339 --> 00:15:54,479
the garbage collector to handle all the

00:15:51,749 --> 00:15:56,129
data is it's not always working out the

00:15:54,479 --> 00:15:57,779
way you would want it to work out so at

00:15:56,129 --> 00:15:59,459
some point you have to start worrying

00:15:57,779 --> 00:16:01,379
about how to use memory if you're going

00:15:59,459 --> 00:16:02,939
to get intensive and you can do this in

00:16:01,379 --> 00:16:05,970
the JVM more and more projects or doing

00:16:02,939 --> 00:16:07,739
this it sits in the very core of link i

00:16:05,970 --> 00:16:10,829
think the spark patrick is starting to

00:16:07,739 --> 00:16:12,119
pick this up as well projects in c++

00:16:10,829 --> 00:16:14,309
like and Paula are doing it anyways

00:16:12,119 --> 00:16:17,819
because you have to I think drill is

00:16:14,309 --> 00:16:20,459
doing this quite quite enough quite

00:16:17,819 --> 00:16:25,439
sophisticated way so yeah it's one of

00:16:20,459 --> 00:16:26,970
our corner points as well okay um I'll

00:16:25,439 --> 00:16:28,529
show you the the stack a little bit

00:16:26,970 --> 00:16:30,029
before you remember the libraries on top

00:16:28,529 --> 00:16:33,929
of the badge and the streaming API and

00:16:30,029 --> 00:16:36,749
then the runtime if you write a program

00:16:33,929 --> 00:16:42,029
against such a system what what is what

00:16:36,749 --> 00:16:43,799
does it look like what how does the the

00:16:42,029 --> 00:16:46,829
execution the life size of such a

00:16:43,799 --> 00:16:49,229
program behave so here's here's an

00:16:46,829 --> 00:16:50,789
example of such a program it's it's a

00:16:49,229 --> 00:16:52,949
toy program it's a very naive way of

00:16:50,789 --> 00:16:56,869
computing transitive closure but yeah

00:16:52,949 --> 00:16:59,699
you're just for the sake of example um

00:16:56,869 --> 00:17:03,019
what flink does to every program is it

00:16:59,699 --> 00:17:05,459
transforms it into a parallel data flow

00:17:03,019 --> 00:17:08,009
it does that in an interface that we

00:17:05,459 --> 00:17:09,870
call pre-flight which runs on on the

00:17:08,009 --> 00:17:12,059
flink line side so you're running a set

00:17:09,870 --> 00:17:14,269
of server processes in your cluster our

00:17:12,059 --> 00:17:17,759
master process worker processes and

00:17:14,269 --> 00:17:20,129
there's a client process when you when

00:17:17,759 --> 00:17:21,750
you give your program to fling so what

00:17:20,129 --> 00:17:25,470
it is it takes this Java or scholar

00:17:21,750 --> 00:17:27,209
program and it goes through it a bit it

00:17:25,470 --> 00:17:28,830
builds a data flow graph and it sends it

00:17:27,209 --> 00:17:31,590
through these two components type

00:17:28,830 --> 00:17:33,899
extraction and optimizer tab extraction

00:17:31,590 --> 00:17:36,870
is it's just a way to say okay we want

00:17:33,899 --> 00:17:38,279
to know at every function exactly what

00:17:36,870 --> 00:17:40,830
is the data types that go in and out

00:17:38,279 --> 00:17:43,259
because we can use that to to our to

00:17:40,830 --> 00:17:44,700
generate schema to generate serializers

00:17:43,259 --> 00:17:47,129
and compare this to do some some

00:17:44,700 --> 00:17:50,039
checking that you know if you happen to

00:17:47,129 --> 00:17:51,779
manage to to use some casts and cheat

00:17:50,039 --> 00:17:52,320
around the type and Friends of the

00:17:51,779 --> 00:17:54,840
compile

00:17:52,320 --> 00:17:56,759
to figure out that this doesn't crash at

00:17:54,840 --> 00:17:59,070
runtime and and also if we can pre

00:17:56,759 --> 00:18:01,980
generate this utilizes we can we can do

00:17:59,070 --> 00:18:06,059
our are managed memory operations much

00:18:01,980 --> 00:18:08,549
much better a bit more about this in a

00:18:06,059 --> 00:18:10,169
few set and a few minutes another part

00:18:08,549 --> 00:18:12,179
that's I think freely interesting is the

00:18:10,169 --> 00:18:15,750
is the optimizer that we added to the

00:18:12,179 --> 00:18:18,539
system which which looks at these

00:18:15,750 --> 00:18:20,539
programs and and and determines a few

00:18:18,539 --> 00:18:23,130
things where you like join algorithms

00:18:20,539 --> 00:18:27,149
where to where to catch data in the loop

00:18:23,130 --> 00:18:28,710
invariant way the result of all that is

00:18:27,149 --> 00:18:29,850
this streaming data flow which is then

00:18:28,710 --> 00:18:32,279
given to the master and the master

00:18:29,850 --> 00:18:33,929
starts deploying these operators into

00:18:32,279 --> 00:18:35,250
the cluster they make handshakes on the

00:18:33,929 --> 00:18:38,850
streams that they produce and consume

00:18:35,250 --> 00:18:42,750
and the master checks yeah the the

00:18:38,850 --> 00:18:44,639
dataflow topology and the metadata so

00:18:42,750 --> 00:18:46,500
let me let me talk to you about the

00:18:44,639 --> 00:18:48,720
remainder this is very very high level

00:18:46,500 --> 00:18:53,700
very coarse-grained the remainder based

00:18:48,720 --> 00:18:55,470
on on on use case by use case yeah so

00:18:53,700 --> 00:18:57,210
the first use case I would like to talk

00:18:55,470 --> 00:18:59,340
about this is data streaming analysis

00:18:57,210 --> 00:19:00,929
because that if you started with a

00:18:59,340 --> 00:19:02,429
streaming engine that's a that's but

00:19:00,929 --> 00:19:08,129
that's sort of what what naturally comes

00:19:02,429 --> 00:19:10,320
and to give a bit of a of a context and

00:19:08,129 --> 00:19:12,659
and how we always see this this field

00:19:10,320 --> 00:19:16,649
and where we see where wavelength fits

00:19:12,659 --> 00:19:21,149
in um I've come to think of of streaming

00:19:16,649 --> 00:19:24,299
infrastructure is in in the way that

00:19:21,149 --> 00:19:26,820
that the companies use it of how they

00:19:24,299 --> 00:19:30,419
usually have these three parts they have

00:19:26,820 --> 00:19:33,360
a part that that gathers data that yeah

00:19:30,419 --> 00:19:36,509
produces the initial streams these are

00:19:33,360 --> 00:19:38,700
adapters to database logs to two sensors

00:19:36,509 --> 00:19:41,879
to just to have a logs and so on and

00:19:38,700 --> 00:19:44,190
then there's a second component it's

00:19:41,879 --> 00:19:47,779
often called the broker where I think

00:19:44,190 --> 00:19:50,330
Apache Kafka's is sort of becoming the

00:19:47,779 --> 00:19:54,600
technology of choice in this area it's a

00:19:50,330 --> 00:20:00,840
combination of a it's a it's a message

00:19:54,600 --> 00:20:03,960
queue slash log that yeah that is a just

00:20:00,840 --> 00:20:05,370
a very good system for for gathering

00:20:03,960 --> 00:20:06,660
data buffering it

00:20:05,370 --> 00:20:09,540
making it available for multiple

00:20:06,660 --> 00:20:11,460
consumers in a reliable way and then

00:20:09,540 --> 00:20:13,010
there's the third part which is taking

00:20:11,460 --> 00:20:17,010
these dreams consuming them and

00:20:13,010 --> 00:20:18,990
enriching them computing things over

00:20:17,010 --> 00:20:20,730
these streams and this may naturally

00:20:18,990 --> 00:20:22,410
feed back into the program and be

00:20:20,730 --> 00:20:27,660
available available for further

00:20:22,410 --> 00:20:30,270
consumption so for for streaming let me

00:20:27,660 --> 00:20:34,410
let me actually skip this slide and into

00:20:30,270 --> 00:20:36,660
it to it figure by figure um one of the

00:20:34,410 --> 00:20:38,250
one of the core parts of link is that

00:20:36,660 --> 00:20:39,720
really everything is executed in a

00:20:38,250 --> 00:20:43,559
streaming way so whenever you have a

00:20:39,720 --> 00:20:45,510
shuffle or or yeah and an alter all

00:20:43,559 --> 00:20:47,580
connection between operators in the

00:20:45,510 --> 00:20:50,580
graph travels and broadcasts the data

00:20:47,580 --> 00:20:55,110
communication is actually can actually

00:20:50,580 --> 00:20:57,210
be streamed it is in many cases so that

00:20:55,110 --> 00:20:58,920
means that when elements come in here

00:20:57,210 --> 00:21:01,080
and they pass the one Operator pass to

00:20:58,920 --> 00:21:02,880
the next this let's say this computes a

00:21:01,080 --> 00:21:05,100
hash a hash code to determine to which

00:21:02,880 --> 00:21:06,690
target is ended and it sends it over to

00:21:05,100 --> 00:21:08,100
this to this machine there's there's no

00:21:06,690 --> 00:21:09,990
synchronization boundaries where this

00:21:08,100 --> 00:21:11,730
really has to has to stop there's a

00:21:09,990 --> 00:21:13,679
there's a bit of buffering with a with

00:21:11,730 --> 00:21:15,090
an upper latency bound if the buffers

00:21:13,679 --> 00:21:17,640
are not full by that time they're gonna

00:21:15,090 --> 00:21:21,030
get flushed in order to guarantee that

00:21:17,640 --> 00:21:23,220
the that we do not want infinitely keep

00:21:21,030 --> 00:21:26,550
infinitely keep data on and hold it back

00:21:23,220 --> 00:21:30,030
so so there is one thing that yeah this

00:21:26,550 --> 00:21:32,790
is um you find the same thing in storm I

00:21:30,030 --> 00:21:34,620
would say or in yeah and some somewhere

00:21:32,790 --> 00:21:36,870
the connections are implemented as Kafka

00:21:34,620 --> 00:21:40,140
cues but they make sense if you want to

00:21:36,870 --> 00:21:44,910
go for low latency and another thing is

00:21:40,140 --> 00:21:46,890
that we spent a lot of time and we're

00:21:44,910 --> 00:21:50,670
still spending a lot of time and in

00:21:46,890 --> 00:21:52,590
trying to to see what what are the what

00:21:50,670 --> 00:21:55,020
are the api's that you need to to

00:21:52,590 --> 00:21:57,600
flexibly define define the streaming

00:21:55,020 --> 00:22:00,179
workflows and the the current state that

00:21:57,600 --> 00:22:02,720
that we have in in the data stream API

00:22:00,179 --> 00:22:04,890
on fling is as long as you can see here

00:22:02,720 --> 00:22:06,840
this is the word count example I

00:22:04,890 --> 00:22:09,179
apologize for that you've probably seen

00:22:06,840 --> 00:22:10,679
it a million times is this a slight

00:22:09,179 --> 00:22:13,560
variation of it so this is you know this

00:22:10,679 --> 00:22:15,210
is where data showed you again here's

00:22:13,560 --> 00:22:16,890
the the best variant the data set

00:22:15,210 --> 00:22:18,300
variant is the data stream very entered

00:22:16,890 --> 00:22:19,000
has a lot differences and it has this

00:22:18,300 --> 00:22:22,420
this

00:22:19,000 --> 00:22:24,370
version of defining windows of a certain

00:22:22,420 --> 00:22:26,430
length and a certain trigger interval

00:22:24,370 --> 00:22:29,410
this is just an example here so

00:22:26,430 --> 00:22:33,220
windowing in flink in the current and

00:22:29,410 --> 00:22:35,950
the current windowing implementation are

00:22:33,220 --> 00:22:38,560
defined exactly like this you have a you

00:22:35,950 --> 00:22:40,990
define how long are elements staying in

00:22:38,560 --> 00:22:43,060
Windows and how often are these windows

00:22:40,990 --> 00:22:46,240
evaluated so with these two policies you

00:22:43,060 --> 00:22:47,950
can sort of quite flexibly define what

00:22:46,240 --> 00:22:49,900
you can do you can use counts you can

00:22:47,950 --> 00:22:53,080
use time you can use some user-defined

00:22:49,900 --> 00:22:55,330
characteristics although as the the more

00:22:53,080 --> 00:23:00,160
the more in transparent that gets to the

00:22:55,330 --> 00:23:02,380
system it becomes yeah it becomes a

00:23:00,160 --> 00:23:06,340
little a little trickier to define but

00:23:02,380 --> 00:23:07,750
in in general de the this syntax is a

00:23:06,340 --> 00:23:10,000
bit like that so we try to follow this

00:23:07,750 --> 00:23:13,510
this this fluent functional better

00:23:10,000 --> 00:23:16,360
syntax md and the windowing mechanism

00:23:13,510 --> 00:23:20,590
the way it it's being it's still under

00:23:16,360 --> 00:23:22,330
heavy evolution right now but it has it

00:23:20,590 --> 00:23:24,210
has evolved into something that is less

00:23:22,330 --> 00:23:26,920
that's quite interesting and flexible so

00:23:24,210 --> 00:23:28,270
some an interesting example that one of

00:23:26,920 --> 00:23:29,770
the committee's likes to give us you can

00:23:28,270 --> 00:23:32,320
actually use this windowing system to

00:23:29,770 --> 00:23:34,690
define to define and analysis where you

00:23:32,320 --> 00:23:37,210
say if I have a trace of GPS coordinate

00:23:34,690 --> 00:23:39,010
second I can use this to say every time

00:23:37,210 --> 00:23:40,780
this thing moved more than a mile give

00:23:39,010 --> 00:23:43,240
me the average speed over the last five

00:23:40,780 --> 00:23:48,940
minutes or so so this this is up as

00:23:43,240 --> 00:23:52,120
possible with that okay um yeah this is

00:23:48,940 --> 00:23:53,620
just a follow-up here's a little longer

00:23:52,120 --> 00:23:56,380
coat excerpt from an example that

00:23:53,620 --> 00:24:00,280
implements a pipeline of processing of

00:23:56,380 --> 00:24:02,410
stock prices and and is actually

00:24:00,280 --> 00:24:05,890
monitoring for price variations of more

00:24:02,410 --> 00:24:07,480
than more than five percent and yeah you

00:24:05,890 --> 00:24:10,090
can you can basically see how it works I

00:24:07,480 --> 00:24:12,820
mean these AP is or I think what people

00:24:10,090 --> 00:24:14,710
nowadays are are used to and we try to

00:24:12,820 --> 00:24:17,200
follow this familiar pattern on the on

00:24:14,710 --> 00:24:18,970
the streaming site again you can see the

00:24:17,200 --> 00:24:21,070
window definitions here operations like

00:24:18,970 --> 00:24:24,280
mapping over a window you can group by

00:24:21,070 --> 00:24:26,429
by Fiat names of the case classes and so

00:24:24,280 --> 00:24:29,950
on so this should give you a pretty

00:24:26,429 --> 00:24:32,190
pretty high level on our way of doing of

00:24:29,950 --> 00:24:35,080
doing things

00:24:32,190 --> 00:24:38,170
something that that we're actually kind

00:24:35,080 --> 00:24:41,530
of proud of the way we we are we figured

00:24:38,170 --> 00:24:42,670
out how to do this is how we do the the

00:24:41,530 --> 00:24:45,940
the fault tolerance and the

00:24:42,670 --> 00:24:47,890
checkpointing because we were aiming for

00:24:45,940 --> 00:24:49,620
for guarantees for exactly once

00:24:47,890 --> 00:24:52,420
guarantees in such a system without the

00:24:49,620 --> 00:24:54,880
necessity to chop the stream up into

00:24:52,420 --> 00:24:57,070
many batches and and the way that we

00:24:54,880 --> 00:24:59,500
that we realized this in the end was

00:24:57,070 --> 00:25:01,150
actually implementing a variant of the

00:24:59,500 --> 00:25:03,760
Chandi lampard algorithm on top of the

00:25:01,150 --> 00:25:04,840
streaming system um it's up it's not

00:25:03,760 --> 00:25:06,730
important that you're familiar with this

00:25:04,840 --> 00:25:08,740
algorithm it's it's actually fairly

00:25:06,730 --> 00:25:11,130
fairly old algorithm like a lot of the

00:25:08,740 --> 00:25:13,330
fundamental algorithms in this field

00:25:11,130 --> 00:25:16,390
getting a bit of renaissance right now

00:25:13,330 --> 00:25:18,190
I'm with our with systems also like to

00:25:16,390 --> 00:25:21,160
see blood GraphLab I'm building on top

00:25:18,190 --> 00:25:23,770
of that and so on and the the basic idea

00:25:21,160 --> 00:25:27,400
of of this algorithm on top of the

00:25:23,770 --> 00:25:28,990
streaming topology is the following we

00:25:27,400 --> 00:25:30,910
have we have data streams here and

00:25:28,990 --> 00:25:32,350
periodically we start pushing so-called

00:25:30,910 --> 00:25:35,470
barriers to these streams and these

00:25:32,350 --> 00:25:37,540
barriers logically chopped the stream

00:25:35,470 --> 00:25:38,860
into into different generations a pre

00:25:37,540 --> 00:25:40,810
checkpoint in a post checkpoint

00:25:38,860 --> 00:25:44,980
generation and this barriers just it

00:25:40,810 --> 00:25:46,840
slides through the streaming topology it

00:25:44,980 --> 00:25:49,510
can slide through each stream at its own

00:25:46,840 --> 00:25:51,310
speed when M it flushes the stream and

00:25:49,510 --> 00:25:53,500
pushes elements before it and whenever

00:25:51,310 --> 00:25:55,210
it reaches an operator it triggers a

00:25:53,500 --> 00:25:57,580
checkpoint of the state and that

00:25:55,210 --> 00:26:02,110
operator that checkpoint can actually be

00:25:57,580 --> 00:26:04,450
written asynchronously the when when as

00:26:02,110 --> 00:26:07,720
soon as the as soon as the s the rioting

00:26:04,450 --> 00:26:09,850
starts the barrier can can can leave

00:26:07,720 --> 00:26:11,260
that operator and flow on and as soon as

00:26:09,850 --> 00:26:12,460
they have reached the end and the

00:26:11,260 --> 00:26:14,770
sources acknowledge that they've

00:26:12,460 --> 00:26:16,360
received all of these all of these

00:26:14,770 --> 00:26:17,710
barriers that slide through and all

00:26:16,360 --> 00:26:19,450
operators acknowledge that they're done

00:26:17,710 --> 00:26:20,980
with their with a checkpoint you know

00:26:19,450 --> 00:26:22,900
that actually this part is persistent

00:26:20,980 --> 00:26:24,220
and the interesting thing is why these

00:26:22,900 --> 00:26:25,210
barriers are sliding through with the

00:26:24,220 --> 00:26:27,220
operations can actually continue

00:26:25,210 --> 00:26:28,450
continue working so you start emitting

00:26:27,220 --> 00:26:30,520
this and you start pushing it through

00:26:28,450 --> 00:26:33,220
and data immediately comes comes after

00:26:30,520 --> 00:26:35,170
that it requires a little bit of finesse

00:26:33,220 --> 00:26:36,400
how you how you do the state handling

00:26:35,170 --> 00:26:39,160
and make sure that while you're writing

00:26:36,400 --> 00:26:41,200
you're not you're not overriding what

00:26:39,160 --> 00:26:42,590
you're doing in your data structures but

00:26:41,200 --> 00:26:44,720
these are things you can

00:26:42,590 --> 00:26:46,309
yeah these are these are things where

00:26:44,720 --> 00:26:49,549
data so I just exists that figure this

00:26:46,309 --> 00:26:52,429
out so this is a very um yet it can give

00:26:49,549 --> 00:26:54,049
you sort of it can give you the benefit

00:26:52,429 --> 00:26:55,730
of mini batching in terms of exactly

00:26:54,049 --> 00:26:58,250
once without without interrupting the

00:26:55,730 --> 00:27:03,919
streams this is this is basically what

00:26:58,250 --> 00:27:06,260
comes out of that okay um so much about

00:27:03,919 --> 00:27:09,669
streaming I have a few minutes that's

00:27:06,260 --> 00:27:14,210
good so I can talk about batch pipelines

00:27:09,669 --> 00:27:16,520
so um when we talk about batch pipelines

00:27:14,210 --> 00:27:19,039
this is um this is just running one

00:27:16,520 --> 00:27:22,429
example it's a visualization from from a

00:27:19,039 --> 00:27:25,070
batch program since flink things in of

00:27:22,429 --> 00:27:27,830
everything data flows there's it's sort

00:27:25,070 --> 00:27:30,740
of a against a natural thing to to just

00:27:27,830 --> 00:27:33,980
render these data flows as as such

00:27:30,740 --> 00:27:36,500
graphs this is basically this is using

00:27:33,980 --> 00:27:38,390
the d3 library and a little a little

00:27:36,500 --> 00:27:40,399
JavaScript to take a fling program and

00:27:38,390 --> 00:27:42,049
render it as a graph so these things

00:27:40,399 --> 00:27:44,210
your data sources these are our

00:27:42,049 --> 00:27:46,330
functions like maps map will reduce

00:27:44,210 --> 00:27:50,809
there are binary functions like joins

00:27:46,330 --> 00:27:52,880
unions and so on and they're this

00:27:50,809 --> 00:27:55,429
program for example I think it computes

00:27:52,880 --> 00:27:58,640
candidate flights based on on on

00:27:55,429 --> 00:28:01,700
schedules from from various airlines um

00:27:58,640 --> 00:28:04,850
if you run this on top of link and I

00:28:01,700 --> 00:28:06,710
said it's a streaming data flow how what

00:28:04,850 --> 00:28:08,899
is the is there anything you have to

00:28:06,710 --> 00:28:10,460
look look out for a few if you execute

00:28:08,899 --> 00:28:11,720
batch programs almost on a streaming

00:28:10,460 --> 00:28:14,299
data flow engine what does that actually

00:28:11,720 --> 00:28:19,279
mean executing batch flows on streaming

00:28:14,299 --> 00:28:20,750
data flow so there are few dualities

00:28:19,279 --> 00:28:23,630
between batch processing and stream

00:28:20,750 --> 00:28:25,820
processing where you can actually view

00:28:23,630 --> 00:28:29,149
batch processing as a special case of

00:28:25,820 --> 00:28:32,299
off stream processing so if we think of

00:28:29,149 --> 00:28:34,490
stream streaming programs as processing

00:28:32,299 --> 00:28:37,520
infinite streams then a batch process a

00:28:34,490 --> 00:28:40,309
batch program is a program that runs

00:28:37,520 --> 00:28:42,020
over a finite stream and this this is

00:28:40,309 --> 00:28:43,970
actually not very surprising right i

00:28:42,020 --> 00:28:46,669
mean every time you write a MapReduce

00:28:43,970 --> 00:28:48,890
program and you read a file from HDFS

00:28:46,669 --> 00:28:50,600
usually don't get the file as a batch

00:28:48,890 --> 00:28:54,080
copy into memory right you get a fine

00:28:50,600 --> 00:28:55,640
stream so in some sets right running a

00:28:54,080 --> 00:28:56,540
batch program as a streaming program is

00:28:55,640 --> 00:29:00,310
just following this

00:28:56,540 --> 00:29:02,990
paradigm conclusively to the end in

00:29:00,310 --> 00:29:04,400
streaming programs you can and whatever

00:29:02,990 --> 00:29:05,810
you do grouping you can never group the

00:29:04,400 --> 00:29:09,170
entire stream because it's never going

00:29:05,810 --> 00:29:10,670
to end there's never a point when when

00:29:09,170 --> 00:29:12,130
you say okay I have all elements for

00:29:10,670 --> 00:29:15,320
this group I can now do whatever

00:29:12,130 --> 00:29:17,210
aggregation or reduce function I want to

00:29:15,320 --> 00:29:19,940
run over that group so you have to

00:29:17,210 --> 00:29:21,980
introduce windows in beds you don't have

00:29:19,940 --> 00:29:23,480
to do that but you can think of it of

00:29:21,980 --> 00:29:25,730
just having one window that spans

00:29:23,480 --> 00:29:27,470
everything if you if you have this

00:29:25,730 --> 00:29:29,000
notion in there then again this is just

00:29:27,470 --> 00:29:32,870
a special case of a streaming program

00:29:29,000 --> 00:29:34,730
with a very large window and streaming

00:29:32,870 --> 00:29:37,460
programs need pipeline data exchange

00:29:34,730 --> 00:29:39,530
always otherwise you're not staying

00:29:37,460 --> 00:29:41,840
within your latency for for a batch

00:29:39,530 --> 00:29:43,250
program you can also use pipeline data

00:29:41,840 --> 00:29:45,310
exchange there's really no no

00:29:43,250 --> 00:29:48,200
fundamental reason why not to do that

00:29:45,310 --> 00:29:50,450
unless you have scheduling constraints

00:29:48,200 --> 00:29:52,760
that lets say the producers of data

00:29:50,450 --> 00:29:54,320
think mappers and the consumers of data

00:29:52,760 --> 00:29:55,910
i think reducers cannot be brought

00:29:54,320 --> 00:29:57,800
online at the same time in which case

00:29:55,910 --> 00:29:59,840
you may want to fall back to a to a

00:29:57,800 --> 00:30:01,880
blocking data exchange which you can

00:29:59,840 --> 00:30:03,650
think of as a stream that is fully

00:30:01,880 --> 00:30:05,510
buffered so I producer can just produce

00:30:03,650 --> 00:30:06,740
stuff push it into the stream and the

00:30:05,510 --> 00:30:09,470
stream has a buffer that is large enough

00:30:06,740 --> 00:30:11,060
that it can just push all its data into

00:30:09,470 --> 00:30:13,820
the stream go away and then the route

00:30:11,060 --> 00:30:16,370
the consumer comes up and and drains

00:30:13,820 --> 00:30:19,730
this stream so this is really internally

00:30:16,370 --> 00:30:21,980
halfling things about these programs so

00:30:19,730 --> 00:30:25,130
what does this mean if you run a batch

00:30:21,980 --> 00:30:26,690
program it means that yeah you cannot

00:30:25,130 --> 00:30:29,810
really read any of these texts there but

00:30:26,690 --> 00:30:32,030
I hope you can it can sort of see there

00:30:29,810 --> 00:30:34,940
see that the data flow graph structure

00:30:32,030 --> 00:30:38,150
here which is important so just to tell

00:30:34,940 --> 00:30:40,700
you their little boxes here which if you

00:30:38,150 --> 00:30:42,260
could read them they would tell some

00:30:40,700 --> 00:30:43,850
characteristics of the stream that's

00:30:42,260 --> 00:30:46,190
flowing from here to here something like

00:30:43,850 --> 00:30:47,750
okay this is just a one to one forward

00:30:46,190 --> 00:30:50,030
stream this is a stream that is using a

00:30:47,750 --> 00:30:53,540
hash petitioners to split itself up this

00:30:50,030 --> 00:30:55,970
is a stream that is um yeah that is that

00:30:53,540 --> 00:30:57,860
is yeah that is materialized as a

00:30:55,970 --> 00:30:59,390
pipeline breakers or produce first then

00:30:57,860 --> 00:31:01,520
consumed or it's a stream that is really

00:30:59,390 --> 00:31:03,700
pipelined and in a lot of these programs

00:31:01,520 --> 00:31:07,220
you can you can run a lot of them as

00:31:03,700 --> 00:31:08,600
truly pipeline streams interestingly the

00:31:07,220 --> 00:31:11,120
operators or

00:31:08,600 --> 00:31:13,580
are often blocking if you have a sword

00:31:11,120 --> 00:31:15,440
you do consume your entire input stream

00:31:13,580 --> 00:31:17,450
then sort and then produce so the the

00:31:15,440 --> 00:31:19,280
operators are blocking and your you're

00:31:17,450 --> 00:31:20,960
not running everything at the same time

00:31:19,280 --> 00:31:22,760
as you would with a lot of streaming

00:31:20,960 --> 00:31:24,830
programs but mainly because of the

00:31:22,760 --> 00:31:27,140
characteristics of the of the operations

00:31:24,830 --> 00:31:29,180
running the operators and if you have

00:31:27,140 --> 00:31:31,040
that it's actually good thing to exploit

00:31:29,180 --> 00:31:33,110
this so if you run this on flink if you

00:31:31,040 --> 00:31:34,460
throw out this program it's not going to

00:31:33,110 --> 00:31:36,110
just bring up everything at the same

00:31:34,460 --> 00:31:38,150
time and try to run it it's going to

00:31:36,110 --> 00:31:40,190
start streaming the data and as soon as

00:31:38,150 --> 00:31:42,590
it streams are available for the

00:31:40,190 --> 00:31:45,410
successors the successes are brought up

00:31:42,590 --> 00:31:47,300
and the predecessors are torn down as as

00:31:45,410 --> 00:31:51,040
they are streams are produced and

00:31:47,300 --> 00:31:52,790
consumed so it the net effect of

00:31:51,040 --> 00:31:54,050
including this and scheduling is

00:31:52,790 --> 00:31:57,590
actually that the execution doesn't

00:31:54,050 --> 00:31:59,270
behave all that different then then a

00:31:57,590 --> 00:32:02,060
batch execution with the exception that

00:31:59,270 --> 00:32:04,790
the lifetime of the operators overlays

00:32:02,060 --> 00:32:07,310
so if you if you look at the at the at

00:32:04,790 --> 00:32:09,410
the breakdown of a flink a flink job

00:32:07,310 --> 00:32:11,600
this is from the from the web front-end

00:32:09,410 --> 00:32:13,190
after after has been executed it's

00:32:11,600 --> 00:32:14,960
pretty short job actually one second or

00:32:13,190 --> 00:32:18,380
so it's just an example on toy data but

00:32:14,960 --> 00:32:20,180
it gives you an impression you can see a

00:32:18,380 --> 00:32:21,500
lot of these things may start at the

00:32:20,180 --> 00:32:25,370
same time if you have enough resources

00:32:21,500 --> 00:32:27,770
they may run and even though this it

00:32:25,370 --> 00:32:30,380
says drawing here and this has co group

00:32:27,770 --> 00:32:32,630
even though this joint produces input to

00:32:30,380 --> 00:32:34,340
this Co group the co group starts very

00:32:32,630 --> 00:32:36,260
very soon after the join because as the

00:32:34,340 --> 00:32:38,150
joint is producing data the co groups

00:32:36,260 --> 00:32:41,300
already consuming it putting it into its

00:32:38,150 --> 00:32:44,390
sort buffers starting to to sort the

00:32:41,300 --> 00:32:45,980
first parts maybe even attempting to

00:32:44,390 --> 00:32:48,380
start merges in the background and and

00:32:45,980 --> 00:32:49,700
all of that it's a bit like when when

00:32:48,380 --> 00:32:51,290
map produced introduced that the

00:32:49,700 --> 00:32:52,700
reducers can come up early well then

00:32:51,290 --> 00:32:55,550
while the mappers are still producing

00:32:52,700 --> 00:33:00,800
things it's sort of similar like that

00:32:55,550 --> 00:33:03,950
but in a more general paradigm all right

00:33:00,800 --> 00:33:05,990
one thing that we learned this is really

00:33:03,950 --> 00:33:09,080
important if you want to do such a thing

00:33:05,990 --> 00:33:11,210
is managing the operators properly

00:33:09,080 --> 00:33:13,100
because if these operators are up at the

00:33:11,210 --> 00:33:15,350
same time there may be parts of this

00:33:13,100 --> 00:33:18,020
coke running in the same JVMs disjoin

00:33:15,350 --> 00:33:19,280
and if you don't make these operators

00:33:18,020 --> 00:33:21,120
behave they're going to kill each other

00:33:19,280 --> 00:33:22,800
they're just going to one

00:33:21,120 --> 00:33:24,210
one is allocating its data structured

00:33:22,800 --> 00:33:26,070
make some assumption the other one makes

00:33:24,210 --> 00:33:27,420
a similar assumption and then they're

00:33:26,070 --> 00:33:30,540
going to eat a wage others memory and

00:33:27,420 --> 00:33:32,430
the jvm and just boom that's the way so

00:33:30,540 --> 00:33:34,050
one one of the really important things

00:33:32,430 --> 00:33:36,290
that we we learned you have to do for

00:33:34,050 --> 00:33:38,220
this is actually manage memory and I

00:33:36,290 --> 00:33:39,870
don't have time to go into this into

00:33:38,220 --> 00:33:43,790
detail there's been a recent blog post

00:33:39,870 --> 00:33:46,230
about that from from one of my fellow

00:33:43,790 --> 00:33:48,450
yeah fling committers far beyond has

00:33:46,230 --> 00:33:51,180
written an awesome blog post about this

00:33:48,450 --> 00:33:53,220
so whoever's interested i recommend go

00:33:51,180 --> 00:33:54,920
to the fling clock and check it out just

00:33:53,220 --> 00:33:57,120
going to give you the very basics um

00:33:54,920 --> 00:33:58,620
with fling test is at startup it

00:33:57,120 --> 00:34:02,130
reserves a certain portion of the heap

00:33:58,620 --> 00:34:04,740
by allocating byte arrays think of it as

00:34:02,130 --> 00:34:09,270
as memory segments that are a memory

00:34:04,740 --> 00:34:11,220
manager in an EOC program owns and that

00:34:09,270 --> 00:34:13,500
that logically divides the heap in to

00:34:11,220 --> 00:34:15,419
enter the data structures that the that

00:34:13,500 --> 00:34:17,340
the workers need for themselves the

00:34:15,419 --> 00:34:19,409
memory that we use for sorting hashing

00:34:17,340 --> 00:34:21,179
caching data and then some remaining

00:34:19,409 --> 00:34:23,280
heap space that is for for the user code

00:34:21,179 --> 00:34:24,750
I think the races don't quite match we

00:34:23,280 --> 00:34:26,940
leave a little more than they have to

00:34:24,750 --> 00:34:28,679
the user code and it looks like that on

00:34:26,940 --> 00:34:31,530
this figure but this is the conceptual

00:34:28,679 --> 00:34:33,330
thing and then all operations place data

00:34:31,530 --> 00:34:35,250
always in binary forms into the manage

00:34:33,330 --> 00:34:37,740
memory buffers and try to walk their

00:34:35,250 --> 00:34:39,360
work on this binary data as much as

00:34:37,740 --> 00:34:40,980
possible so they really built the hash

00:34:39,360 --> 00:34:43,050
tables in binary form the even sort

00:34:40,980 --> 00:34:46,050
binary data to a large extent without

00:34:43,050 --> 00:34:49,200
ever deserialising it into objects by by

00:34:46,050 --> 00:34:50,970
means of of this special serialization

00:34:49,200 --> 00:34:53,419
framework that we that we built for

00:34:50,970 --> 00:34:55,950
flink and that that uses this type

00:34:53,419 --> 00:34:57,600
information and extraction that runs in

00:34:55,950 --> 00:35:01,170
the client that I showed you on on some

00:34:57,600 --> 00:35:02,730
very early early arm slide while you

00:35:01,170 --> 00:35:04,260
submit the program you look at the tabs

00:35:02,730 --> 00:35:05,940
you pre generate the co lasers and you

00:35:04,260 --> 00:35:07,440
pre generate utilities and analyze

00:35:05,940 --> 00:35:09,510
classes to figure out okay how do

00:35:07,440 --> 00:35:11,220
actually compare data in its binary

00:35:09,510 --> 00:35:13,110
encoding for some data types it's

00:35:11,220 --> 00:35:15,270
trivial for others you have to sort of

00:35:13,110 --> 00:35:17,100
compose and change and coatings for

00:35:15,270 --> 00:35:20,270
certain situations and then you can do

00:35:17,100 --> 00:35:23,130
that and yeah the net effect is that

00:35:20,270 --> 00:35:25,560
even if you run out of memory so it

00:35:23,130 --> 00:35:27,420
gives you very robust behavior in memory

00:35:25,560 --> 00:35:29,730
but also if memory runs out you get a

00:35:27,420 --> 00:35:31,590
very graceful behavior because you can

00:35:29,730 --> 00:35:33,630
just take bunches of these pages and

00:35:31,590 --> 00:35:35,920
move them between memory and disk and

00:35:33,630 --> 00:35:39,150
yeah especially this is for her for the

00:35:35,920 --> 00:35:42,490
house join it behaves pretty gracefully

00:35:39,150 --> 00:35:47,080
okay let me skip over this a little bit

00:35:42,490 --> 00:35:51,000
and just give you one last yeah one last

00:35:47,080 --> 00:35:54,099
thing before for my time runs out I

00:35:51,000 --> 00:35:55,900
mentioned earlier on that I'll most

00:35:54,099 --> 00:35:57,339
systems if you're running iterative jobs

00:35:55,900 --> 00:36:00,150
actually doing that by submitting

00:35:57,339 --> 00:36:03,580
multiple programs into the cluster I'm

00:36:00,150 --> 00:36:06,510
the same thing again and again and try

00:36:03,580 --> 00:36:08,650
and keep intermediate data in memory

00:36:06,510 --> 00:36:10,930
what we've built in fling is a way of

00:36:08,650 --> 00:36:12,160
having a feedback in there in the data

00:36:10,930 --> 00:36:14,680
flow so you have a function that

00:36:12,160 --> 00:36:16,330
encapsulate seeeeee this step that you

00:36:14,680 --> 00:36:19,030
are repeatedly executing and rather than

00:36:16,330 --> 00:36:22,030
deploying it again and again consuming

00:36:19,030 --> 00:36:24,070
the previous deployments data you deploy

00:36:22,030 --> 00:36:29,050
it once and you allow it to feed back

00:36:24,070 --> 00:36:30,730
its results to the beginning um this has

00:36:29,050 --> 00:36:32,440
the nice characteristic of first of all

00:36:30,730 --> 00:36:34,089
you're only deploying this once you can

00:36:32,440 --> 00:36:37,180
actually keep data structures around

00:36:34,089 --> 00:36:39,450
across iterations it has because we

00:36:37,180 --> 00:36:41,260
surface this in the API the nice

00:36:39,450 --> 00:36:43,089
characteristic that the system knows

00:36:41,260 --> 00:36:45,160
about that it can figure out for you

00:36:43,089 --> 00:36:48,580
what is loop invariant and and cash that

00:36:45,160 --> 00:36:51,130
in memory and yeah and with all that we

00:36:48,580 --> 00:36:54,220
were actually able to to get some some

00:36:51,130 --> 00:36:56,560
pretty good results on on on very heavy

00:36:54,220 --> 00:36:58,150
algorithms in the machine learning space

00:36:56,560 --> 00:37:01,540
so this is a slight you may have seen

00:36:58,150 --> 00:37:03,310
this if you went to the talk from till

00:37:01,540 --> 00:37:05,410
yesterday he was talking about machine

00:37:03,310 --> 00:37:07,660
learning with flink this is um the

00:37:05,410 --> 00:37:09,520
matrix factorization use case that they

00:37:07,660 --> 00:37:14,140
were scared to some I think a pretty

00:37:09,520 --> 00:37:16,420
good scheme actually on are not true

00:37:14,140 --> 00:37:18,820
large heart whistled factorizing a

00:37:16,420 --> 00:37:20,890
matrix of 28 billion entities means

00:37:18,820 --> 00:37:24,550
you're dealing with many terabytes of

00:37:20,890 --> 00:37:27,160
intermediate data sets although the

00:37:24,550 --> 00:37:29,230
input data is is only yeah it's a bit

00:37:27,160 --> 00:37:31,119
below below a terabyte of input data the

00:37:29,230 --> 00:37:34,330
algorithm has the notion of of blowing

00:37:31,119 --> 00:37:37,540
up intermediate results vastly and doing

00:37:34,330 --> 00:37:38,980
doing complex computations and and the

00:37:37,540 --> 00:37:40,480
way of having this very well-behaved

00:37:38,980 --> 00:37:41,920
feedback loop is very well-behaved

00:37:40,480 --> 00:37:46,880
memory management actually allows you to

00:37:41,920 --> 00:37:48,740
UM to scale this pretty far on a decent

00:37:46,880 --> 00:37:51,829
on a not overly large cluster actually

00:37:48,740 --> 00:37:53,779
and the next thing that you can actually

00:37:51,829 --> 00:37:55,609
do if you do closed loop iterations is

00:37:53,779 --> 00:37:58,309
and I was sitting at that earlier is you

00:37:55,609 --> 00:38:01,609
can you can keep state across individual

00:37:58,309 --> 00:38:05,359
invocations of of whatever you do inside

00:38:01,609 --> 00:38:07,220
your generations I'm not going to going

00:38:05,359 --> 00:38:09,799
to go into details this concept called

00:38:07,220 --> 00:38:11,690
Delta iterations is is a way we try to

00:38:09,799 --> 00:38:13,640
abstract mutable state in a way that it

00:38:11,690 --> 00:38:18,349
doesn't break the functional abstraction

00:38:13,640 --> 00:38:20,269
um the one net effect that you can get

00:38:18,349 --> 00:38:22,849
off keeping state around let me only

00:38:20,269 --> 00:38:25,009
give you that on before ever for a

00:38:22,849 --> 00:38:27,289
rabbit up is that you can write

00:38:25,009 --> 00:38:30,349
algorithms such that they work on

00:38:27,289 --> 00:38:33,440
whatever I need to work on whatever work

00:38:30,349 --> 00:38:35,869
needs to be done depending on the

00:38:33,440 --> 00:38:39,200
changes in the previous step and you can

00:38:35,869 --> 00:38:40,609
you can not look at the let's say

00:38:39,200 --> 00:38:43,880
they're already converged parameters

00:38:40,609 --> 00:38:45,500
that you that you can exclude because

00:38:43,880 --> 00:38:47,750
they haven't changed for a while and

00:38:45,500 --> 00:38:49,490
none of their of their training points

00:38:47,750 --> 00:38:50,539
give you any new inside so why should

00:38:49,490 --> 00:38:53,000
they change now you can write the

00:38:50,539 --> 00:38:57,049
algorithm to ignore those points and and

00:38:53,000 --> 00:39:00,740
selectively compute what is what you

00:38:57,049 --> 00:39:03,470
discover as a new update in in a

00:39:00,740 --> 00:39:05,900
subsequent iteration and just update

00:39:03,470 --> 00:39:08,359
that into into the mutable state if you

00:39:05,900 --> 00:39:10,609
go back to to that abstraction which you

00:39:08,359 --> 00:39:11,900
have in most systems the result is

00:39:10,609 --> 00:39:13,819
whatever comes out of the step function

00:39:11,900 --> 00:39:15,500
so you have to implicitly carry forward

00:39:13,819 --> 00:39:18,170
all all your results every time

00:39:15,500 --> 00:39:19,880
otherwise they're going to be lost the

00:39:18,170 --> 00:39:21,799
net effect of keeping status you can

00:39:19,880 --> 00:39:23,599
just compute on what needs to change you

00:39:21,799 --> 00:39:25,880
have some stage that actually holds

00:39:23,599 --> 00:39:26,930
whatever your result should be and this

00:39:25,880 --> 00:39:29,390
is going to be the result of your

00:39:26,930 --> 00:39:30,890
computation so with that you can

00:39:29,390 --> 00:39:32,150
actually implement a lot of graph

00:39:30,890 --> 00:39:34,190
algorithms or machine learning

00:39:32,150 --> 00:39:38,029
algorithms which have this structure of

00:39:34,190 --> 00:39:42,710
being of having graphical dependencies

00:39:38,029 --> 00:39:44,509
between their parameters in a in a in a

00:39:42,710 --> 00:39:47,180
very efficient way so this is this is a

00:39:44,509 --> 00:39:49,069
slot comparison if you go from Hadoop to

00:39:47,180 --> 00:39:50,569
the Latina Eve way of iterating with

00:39:49,069 --> 00:39:52,880
fling you get all these caching and

00:39:50,569 --> 00:39:54,589
memory deployment benefits and so on and

00:39:52,880 --> 00:39:57,259
if you then say okay let me switch to

00:39:54,589 --> 00:39:59,690
the Delta model you can actually again

00:39:57,259 --> 00:40:00,530
shrink this computation and you can see

00:39:59,690 --> 00:40:02,590
that especially

00:40:00,530 --> 00:40:05,120
if you if you do more iterations the

00:40:02,590 --> 00:40:07,820
later the iteration is the less work it

00:40:05,120 --> 00:40:09,560
usually does so if you you can you can

00:40:07,820 --> 00:40:11,060
get to too much lower error rates which

00:40:09,560 --> 00:40:13,400
is focusing on the parameters that

00:40:11,060 --> 00:40:15,620
that's still that's still relevant

00:40:13,400 --> 00:40:18,920
adding few durations doesn't cost all

00:40:15,620 --> 00:40:22,100
that much in that model okay there was a

00:40:18,920 --> 00:40:25,880
lot of contents thanks for for for

00:40:22,100 --> 00:40:27,800
staying with me um I'm going to put up

00:40:25,880 --> 00:40:31,330
this slide for the for the end it's what

00:40:27,800 --> 00:40:33,560
what we're working on right now um

00:40:31,330 --> 00:40:35,000
streaming is on a heavy development I

00:40:33,560 --> 00:40:36,800
think it has some some very interesting

00:40:35,000 --> 00:40:39,080
characteristics right now in the way it

00:40:36,800 --> 00:40:41,930
it allows you to do low latency with

00:40:39,080 --> 00:40:45,520
states with state with user-defined

00:40:41,930 --> 00:40:48,650
state without ya without sacrificing the

00:40:45,520 --> 00:40:51,080
the nice cities of a of a proper stream

00:40:48,650 --> 00:40:52,550
processor we're working on master

00:40:51,080 --> 00:40:54,710
failover e because in highly available

00:40:52,550 --> 00:40:57,620
we don't have this in the we don't have

00:40:54,710 --> 00:40:59,150
this in the system as of yet but it's

00:40:57,620 --> 00:41:02,540
pretty crucial for highly available

00:40:59,150 --> 00:41:04,520
streaming setups monitoring integration

00:41:02,540 --> 00:41:07,640
with other apache projects and well of

00:41:04,520 --> 00:41:09,260
course i like like usual the library is

00:41:07,640 --> 00:41:10,970
actually the most active part static

00:41:09,260 --> 00:41:13,670
most people because they have a they

00:41:10,970 --> 00:41:16,270
have a comparatively low bearing of

00:41:13,670 --> 00:41:19,390
entry if you want to work on something

00:41:16,270 --> 00:41:22,520
and if you find this interesting and our

00:41:19,390 --> 00:41:25,280
excited i want to learn more will

00:41:22,520 --> 00:41:28,250
actually have a link conference called

00:41:25,280 --> 00:41:31,010
fling forward later this year in October

00:41:28,250 --> 00:41:33,860
here in Berlin actually in co2 exactly

00:41:31,010 --> 00:41:36,590
where buzzwords was yet last year so if

00:41:33,860 --> 00:41:38,510
you're a frequent buzzwords guest you

00:41:36,590 --> 00:41:41,810
will know this place it's um it's also

00:41:38,510 --> 00:41:45,110
nice location and where we're putting

00:41:41,810 --> 00:41:46,760
together the the program so if you are

00:41:45,110 --> 00:41:48,050
playing around with fling if you're

00:41:46,760 --> 00:41:52,490
working with that if you have prototypes

00:41:48,050 --> 00:41:53,780
experiences suggestions for four

00:41:52,490 --> 00:41:56,960
features and improvements that you want

00:41:53,780 --> 00:42:01,130
to share the call for for participation

00:41:56,960 --> 00:42:04,400
is still open so feel ya feel free to to

00:42:01,130 --> 00:42:07,510
also yeah share your share your ideas

00:42:04,400 --> 00:42:09,570
and results with us thank you

00:42:07,510 --> 00:42:09,570

YouTube URL: https://www.youtube.com/watch?v=zHF4EoXf7Hk


