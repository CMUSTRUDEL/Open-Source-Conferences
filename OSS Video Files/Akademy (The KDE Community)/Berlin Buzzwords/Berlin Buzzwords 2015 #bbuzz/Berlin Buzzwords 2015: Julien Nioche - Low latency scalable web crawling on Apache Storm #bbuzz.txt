Title: Berlin Buzzwords 2015: Julien Nioche - Low latency scalable web crawling on Apache Storm #bbuzz
Publication date: 2015-06-04
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	In this talk I will introduce Storm-Crawler, a collection of resources for building low-latency, large scale web crawlers on Apache Storm. We will compare with similar projects like Apache Nutch and present several use cases where the storm-crawler is being used.  In particular we will see how the Storm-crawler can be used with ElasticSearch and Kibana for crawling and indexing web pages.

Read more:
https://2015.berlinbuzzwords.de/session/low-latency-scalable-web-crawling-apache-storm

About Julien Nioche:
https://2015.berlinbuzzwords.de/users/julien-nioche

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:06,220 --> 00:00:11,510
thanks for coming and thanks to you the

00:00:09,430 --> 00:00:12,670
organizers for giving me the opportunity

00:00:11,510 --> 00:00:16,570
to give these

00:00:12,670 --> 00:00:23,250
this talk so yeah this top is this

00:00:16,570 --> 00:00:29,590
working no it's not working no mines

00:00:23,250 --> 00:00:35,070
just use this some right i watch blood

00:00:29,590 --> 00:00:35,070
yeah no simple

00:00:45,920 --> 00:00:56,979
since we plug the sorry about that all

00:00:52,159 --> 00:01:04,210
right next year's a track for portal

00:00:56,979 --> 00:01:07,210
yeah okay and the arrows are not working

00:01:04,210 --> 00:01:07,210
right

00:01:16,100 --> 00:01:23,780
ah yeah see probably I've been to I

00:01:22,009 --> 00:01:26,570
think it's my third time here in Berlin

00:01:23,780 --> 00:01:28,190
it's nice to be back so some of you

00:01:26,570 --> 00:01:31,520
might have seen me in the past talking

00:01:28,190 --> 00:01:33,680
about other things if not so i run this

00:01:31,520 --> 00:01:36,310
door pebble which is a small control

00:01:33,680 --> 00:01:39,560
consultancy based in bristol in the UK

00:01:36,310 --> 00:01:41,720
doing pretty much anything with tags on

00:01:39,560 --> 00:01:43,039
a large scale so going from web crawling

00:01:41,720 --> 00:01:44,990
which is what I'll be talking about

00:01:43,039 --> 00:01:47,710
today to your natural language

00:01:44,990 --> 00:01:51,920
processing building search systems or

00:01:47,710 --> 00:01:55,039
machine learning what we do a dish of

00:01:51,920 --> 00:01:59,149
Babel is mostly using open source and

00:01:55,039 --> 00:02:02,450
especially Apache stuff so I use our

00:01:59,149 --> 00:02:05,509
contribute or I'm a committer encore fum

00:02:02,450 --> 00:02:08,810
30 projects Apache notch which is a web

00:02:05,509 --> 00:02:12,140
crawler which I'll mention in my sides

00:02:08,810 --> 00:02:18,319
but other Apache things like tea cow and

00:02:12,140 --> 00:02:23,959
so on who knows about apache notch okay

00:02:18,319 --> 00:02:27,470
well supposing and you so who's been to

00:02:23,959 --> 00:02:32,540
the talk this morning about storm yeah

00:02:27,470 --> 00:02:33,859
cool excellent great now the project

00:02:32,540 --> 00:02:35,840
that I want to tell you about today is

00:02:33,859 --> 00:02:38,720
called stone quarry which is a very

00:02:35,840 --> 00:02:40,280
original name and it basically does what

00:02:38,720 --> 00:02:44,150
it says on the tin it's about building

00:02:40,280 --> 00:02:49,070
web crawlers on Apache storm so it's a

00:02:44,150 --> 00:02:52,489
collection of resources it's an SDK the

00:02:49,070 --> 00:02:54,650
curd lives on github the it's and apache

00:02:52,489 --> 00:02:58,280
license and all the artifacts azhar

00:02:54,650 --> 00:03:00,320
maven central so you can pull the stuff

00:02:58,280 --> 00:03:03,380
the other jars in there in the usual

00:03:00,320 --> 00:03:07,130
ways it's a relatively young project I

00:03:03,380 --> 00:03:11,239
mean compared to notch it's been around

00:03:07,130 --> 00:03:13,459
for probably a half but it's it's very

00:03:11,239 --> 00:03:17,000
active it's growing fast it went from me

00:03:13,459 --> 00:03:21,950
being the only committed to having three

00:03:17,000 --> 00:03:23,780
more committees and yes we've just

00:03:21,950 --> 00:03:27,380
released a new version last week

00:03:23,780 --> 00:03:30,079
literally so what I wanted to achieve

00:03:27,380 --> 00:03:32,640
with the storm caller was to have

00:03:30,079 --> 00:03:34,079
something that that can scale what

00:03:32,640 --> 00:03:37,980
doesn't have to mean we don't all need

00:03:34,079 --> 00:03:39,780
to do billions of pages but something

00:03:37,980 --> 00:03:45,150
that can potentially scale if needed

00:03:39,780 --> 00:03:48,030
something that can do low latency also

00:03:45,150 --> 00:03:51,450
be able to use more easy to use and

00:03:48,030 --> 00:03:54,420
extend we'll have a comparison with much

00:03:51,450 --> 00:03:56,060
later and and also of course all the

00:03:54,420 --> 00:03:59,459
nice features that we want to have like

00:03:56,060 --> 00:04:01,439
processing site Maps or be able to do

00:03:59,459 --> 00:04:04,230
web scraping which is it of you know

00:04:01,439 --> 00:04:06,810
those people need to do be able to do

00:04:04,230 --> 00:04:09,980
that in a nice way and also your things

00:04:06,810 --> 00:04:13,769
like your site map politeness all these

00:04:09,980 --> 00:04:16,470
things that we want the web crawler what

00:04:13,769 --> 00:04:18,509
it's not being an sdk is a well packaged

00:04:16,470 --> 00:04:20,729
application so there's a minimum amount

00:04:18,509 --> 00:04:25,410
of code and configuration that you need

00:04:20,729 --> 00:04:28,590
to do there's also no a global global

00:04:25,410 --> 00:04:30,960
processing of of the pages like doing a

00:04:28,590 --> 00:04:33,330
pagerank like no she can do that's

00:04:30,960 --> 00:04:35,099
because it's that's backend specific it

00:04:33,330 --> 00:04:38,310
depends on on where you store your your

00:04:35,099 --> 00:04:40,650
your data and it will be done typically

00:04:38,310 --> 00:04:43,169
with them you know a MapReduce or a

00:04:40,650 --> 00:04:45,630
spark job so that's that's without side

00:04:43,169 --> 00:04:47,460
the scope of the storm corner and yeah

00:04:45,630 --> 00:04:50,580
it doesn't have any fancy you I just or

00:04:47,460 --> 00:04:54,210
dashboard it you use the you'd use the

00:04:50,580 --> 00:04:56,849
storm UI and but also you can plug the

00:04:54,210 --> 00:04:59,099
the store metrics to various back end so

00:04:56,849 --> 00:05:01,949
in a way it's quite flexible you can can

00:04:59,099 --> 00:05:05,729
integrate it in whatever you're planning

00:05:01,949 --> 00:05:10,289
to do with your project so yeah I

00:05:05,729 --> 00:05:13,620
mentioned nudge nudge is as you know a

00:05:10,289 --> 00:05:15,539
very popular piece of software not only

00:05:13,620 --> 00:05:18,180
because you gave birth to Hadoop just a

00:05:15,539 --> 00:05:19,889
minor detail but also because it's one

00:05:18,180 --> 00:05:22,800
of the few projects that you can use to

00:05:19,889 --> 00:05:24,539
build large-scale crawlers and I happen

00:05:22,800 --> 00:05:26,190
to know it pretty well I've been a

00:05:24,539 --> 00:05:29,310
committer on nudge fourth quarter but a

00:05:26,190 --> 00:05:30,930
while now so yeah people often ask me

00:05:29,310 --> 00:05:34,500
why feed on the storm quarter you

00:05:30,930 --> 00:05:37,370
already have nudge so one of the reasons

00:05:34,500 --> 00:05:39,779
was that yeah no chiz batch driven so

00:05:37,370 --> 00:05:42,180
imagine you do you know it works by

00:05:39,779 --> 00:05:43,440
steps you do a first step of generations

00:05:42,180 --> 00:05:45,690
you select all the

00:05:43,440 --> 00:05:47,310
or else that you want to fetch then you

00:05:45,690 --> 00:05:49,410
do the actual fetching of these URLs

00:05:47,310 --> 00:05:51,630
then the you pass them to get the out

00:05:49,410 --> 00:05:55,500
links and also the actual content of the

00:05:51,630 --> 00:05:57,000
pages and next step is to update the

00:05:55,500 --> 00:06:01,140
what's called the crawl DB which is a

00:05:57,000 --> 00:06:02,580
sort of database about the URLs and then

00:06:01,140 --> 00:06:04,680
you can index of course the other pages

00:06:02,580 --> 00:06:06,990
so that's five or six different steps

00:06:04,680 --> 00:06:08,640
they all run sequentially which means

00:06:06,990 --> 00:06:10,530
that when you're fetching you're not

00:06:08,640 --> 00:06:12,450
passing when you're passing or updating

00:06:10,530 --> 00:06:15,120
or generating you're not fetching so

00:06:12,450 --> 00:06:17,070
you're not in terms of the use of the

00:06:15,120 --> 00:06:19,170
resources is it's not really optimal you

00:06:17,070 --> 00:06:21,750
should be you should be always fetching

00:06:19,170 --> 00:06:24,150
always passing always updating so you're

00:06:21,750 --> 00:06:28,590
optimizing your network you'll CPU your

00:06:24,150 --> 00:06:32,010
disk access everything the main thing is

00:06:28,590 --> 00:06:34,950
that with all these bad jobs you have

00:06:32,010 --> 00:06:37,980
very little control as to when URLs

00:06:34,950 --> 00:06:40,800
actually fetched which means that for if

00:06:37,980 --> 00:06:44,220
you need to handle low latency imagine

00:06:40,800 --> 00:06:48,270
you have you need to scrape a site that

00:06:44,220 --> 00:06:50,490
uses sessions sessions are often time

00:06:48,270 --> 00:06:52,350
limited with with nerds you have to do

00:06:50,490 --> 00:06:55,140
all sorts of contortions to be able to

00:06:52,350 --> 00:06:57,540
do that it's not a very natural fit with

00:06:55,140 --> 00:07:04,980
the stone color yeah it's a much better

00:06:57,540 --> 00:07:09,540
fit what else yeah but storm corners

00:07:04,980 --> 00:07:13,530
were is a lot more flexible to use very

00:07:09,540 --> 00:07:15,840
often you just reuse the existing

00:07:13,530 --> 00:07:18,780
classes in the SDK and I've had quite a

00:07:15,840 --> 00:07:21,540
few users who literally had like three

00:07:18,780 --> 00:07:24,450
java classes a couple of configuration

00:07:21,540 --> 00:07:26,790
files and bank they could be a scalable

00:07:24,450 --> 00:07:31,169
crawler just just with that so it's um

00:07:26,790 --> 00:07:33,630
it's quite elegant in a way so but it's

00:07:31,169 --> 00:07:36,840
not you know as ready to use as much of

00:07:33,630 --> 00:07:39,330
course not you install it and hopefully

00:07:36,840 --> 00:07:40,919
luckily you are you able to use it and

00:07:39,330 --> 00:07:43,260
that's it you can play the configuration

00:07:40,919 --> 00:07:47,130
again the song caller is nasty case you

00:07:43,260 --> 00:07:48,600
need to build a bit of code but you know

00:07:47,130 --> 00:07:51,990
a lot of the sum of the codes and all of

00:07:48,600 --> 00:07:53,910
the concepts were both from nudge so

00:07:51,990 --> 00:07:56,550
some color pretty would not existed

00:07:53,910 --> 00:07:58,110
without it but the nice thing is that

00:07:56,550 --> 00:08:00,360
a man should contribute some of this

00:07:58,110 --> 00:08:03,780
stuff back to nudge so it works both

00:08:00,360 --> 00:08:05,460
ways so that there was a talk this

00:08:03,780 --> 00:08:08,580
morning about storms was really good so

00:08:05,460 --> 00:08:11,850
I can go very quickly over the my storm

00:08:08,580 --> 00:08:15,240
slides so yeah stories a distributed

00:08:11,850 --> 00:08:18,900
real-time computation system top level

00:08:15,240 --> 00:08:21,270
project and apache so mix of closure and

00:08:18,900 --> 00:08:24,750
java and it's used for all sorts of

00:08:21,270 --> 00:08:27,000
things you're terminally takes continues

00:08:24,750 --> 00:08:31,380
computation and so on twitter very

00:08:27,000 --> 00:08:33,720
popular piece of software the concept

00:08:31,380 --> 00:08:35,550
and that's where we like with with storm

00:08:33,720 --> 00:08:37,290
is that there are it's nice and easy to

00:08:35,550 --> 00:08:39,030
understand but it is quite powerful at

00:08:37,290 --> 00:08:41,160
the same time so as we've seen this

00:08:39,030 --> 00:08:43,650
morning have spouts that generate

00:08:41,160 --> 00:08:45,660
doubles on two streams and then you have

00:08:43,650 --> 00:08:49,740
bolts operating on these tuples and

00:08:45,660 --> 00:08:54,240
modifying them or creating new ones so

00:08:49,740 --> 00:08:55,740
basically a spout both streams so what

00:08:54,240 --> 00:08:59,250
do we have in the toolbox what does

00:08:55,740 --> 00:09:01,890
strong quarter provide as a project so

00:08:59,250 --> 00:09:04,650
we've separated the occurred into two

00:09:01,890 --> 00:09:06,690
modules one core along with year the

00:09:04,650 --> 00:09:09,210
stuff you would necessarily probably

00:09:06,690 --> 00:09:10,910
definitely use with the somme quarter

00:09:09,210 --> 00:09:13,080
and the other one we put all the young

00:09:10,910 --> 00:09:15,900
stuff which is related to external

00:09:13,080 --> 00:09:18,350
projects like elastic search or tikal

00:09:15,900 --> 00:09:21,420
just to keep things separated and simple

00:09:18,350 --> 00:09:26,490
they also got it here walker if you at

00:09:21,420 --> 00:09:28,110
least one repository of external

00:09:26,490 --> 00:09:32,340
contribution so people have their own

00:09:28,110 --> 00:09:35,820
github repository wow already half we

00:09:32,340 --> 00:09:37,440
have to speed up so next one so the main

00:09:35,820 --> 00:09:41,430
both you need is obviously the one that

00:09:37,440 --> 00:09:44,160
does the fetching so it's a yeah the

00:09:41,430 --> 00:09:47,340
ones don't of you who are familiar with

00:09:44,160 --> 00:09:48,960
natural recognized some of the some of

00:09:47,340 --> 00:09:51,840
the concept so it's yeah multi threaded

00:09:48,960 --> 00:09:54,180
rod bolts that has internally multiple

00:09:51,840 --> 00:09:56,310
threads to do the fetching and puts all

00:09:54,180 --> 00:09:58,620
the incoming tuples in 2 q's so that

00:09:56,310 --> 00:10:00,090
that's way of handling the uprightness

00:09:58,620 --> 00:10:03,540
that you make you can you can have

00:10:00,090 --> 00:10:06,930
control as to the the rate at which you

00:10:03,540 --> 00:10:09,089
send queries to your server there's also

00:10:06,930 --> 00:10:12,250
a simpler version of the bolts

00:10:09,089 --> 00:10:16,959
but that other one requires two terms or

00:10:12,250 --> 00:10:19,180
the politeness at the spot level yeah

00:10:16,959 --> 00:10:21,100
and there's the the protocols are it's

00:10:19,180 --> 00:10:23,680
nutan protocol neutral in the sense that

00:10:21,100 --> 00:10:26,199
you know the protocols are a separate

00:10:23,680 --> 00:10:28,420
component it's not part of the defector

00:10:26,199 --> 00:10:30,850
itself so you can can we use the default

00:10:28,420 --> 00:10:32,529
one based on them apache HTTP client but

00:10:30,850 --> 00:10:35,620
you can also write a custom one if you

00:10:32,529 --> 00:10:38,139
needed to the second most important

00:10:35,620 --> 00:10:42,790
component is the one that does the other

00:10:38,139 --> 00:10:45,279
passing of the pages so this one is yeah

00:10:42,790 --> 00:10:47,100
it's based on J soup and it handles on

00:10:45,279 --> 00:10:49,470
the HTML but if you need other formats

00:10:47,100 --> 00:10:51,970
remember I mentioned earlier there is a

00:10:49,470 --> 00:10:57,310
one based on tika which is in the

00:10:51,970 --> 00:10:59,440
external part of the code and so this is

00:10:57,310 --> 00:11:01,230
possible to extract the text from the

00:10:59,440 --> 00:11:03,990
documents and also the Earthlings and

00:11:01,230 --> 00:11:06,819
endless metadata from from the web page

00:11:03,990 --> 00:11:11,069
but it does two things it calls the url

00:11:06,819 --> 00:11:14,110
url filters which are pluggable sort of

00:11:11,069 --> 00:11:16,120
glasses which allow you to normalize or

00:11:14,110 --> 00:11:18,069
filter out links so it's basically how

00:11:16,120 --> 00:11:21,010
you control the expansion of your you're

00:11:18,069 --> 00:11:25,149
cruel and also pass filters which are

00:11:21,010 --> 00:11:27,639
again pluggable classes which is where

00:11:25,149 --> 00:11:30,459
you can do for instance extract metadata

00:11:27,639 --> 00:11:32,560
with xpath or do whatever you want to do

00:11:30,459 --> 00:11:35,230
in terms of scraping so these are the

00:11:32,560 --> 00:11:39,790
most commonly use things unless that's

00:11:35,230 --> 00:11:41,470
all all happens within them j tsubasa so

00:11:39,790 --> 00:11:44,740
as I said yeah pass filter is just

00:11:41,470 --> 00:11:48,190
basically a simple simple interface it's

00:11:44,740 --> 00:11:50,800
configured with the JSON file and it

00:11:48,190 --> 00:11:52,779
comes with a few default implementation

00:11:50,800 --> 00:11:55,660
so there's this one BMX pass filter

00:11:52,779 --> 00:11:58,720
where in the adjacent file you just give

00:11:55,660 --> 00:12:00,639
it a number of XPath expressions and

00:11:58,720 --> 00:12:02,649
then it will store all the matches into

00:12:00,639 --> 00:12:05,759
the metadata for the page so it's nice

00:12:02,649 --> 00:12:08,620
and easy way of doing scraping really

00:12:05,759 --> 00:12:11,680
same with your URL filters so that's how

00:12:08,620 --> 00:12:14,910
you control the how your your call

00:12:11,680 --> 00:12:17,589
expands and yeah there's number of

00:12:14,910 --> 00:12:19,810
filters available I won't go into the

00:12:17,589 --> 00:12:22,339
details because I'm running out of time

00:12:19,810 --> 00:12:24,740
so a very basic topology

00:12:22,339 --> 00:12:29,509
like this you have some spout putting

00:12:24,740 --> 00:12:31,430
your l's from say a queue or any any

00:12:29,509 --> 00:12:33,430
form of what some form of external

00:12:31,430 --> 00:12:37,040
storage it has to come from somewhere

00:12:33,430 --> 00:12:40,779
and then yeah some partitioning to make

00:12:37,040 --> 00:12:44,499
sure that the URLs are sent to your

00:12:40,779 --> 00:12:46,939
single so your else from a single domain

00:12:44,499 --> 00:12:48,470
go to the same instance of a fetcher

00:12:46,939 --> 00:12:50,350
again you can have just more than one

00:12:48,470 --> 00:12:52,550
instance of you see of all these bolt

00:12:50,350 --> 00:12:54,199
yeah the past thing and then you do

00:12:52,550 --> 00:12:56,779
something with it you would index it

00:12:54,199 --> 00:12:59,029
with solar elasticsearch or will store

00:12:56,779 --> 00:13:01,850
it in a database so that's a very very

00:12:59,029 --> 00:13:05,050
very basic topology from the point of

00:13:01,850 --> 00:13:09,139
view of the topples this is the sort of

00:13:05,050 --> 00:13:13,220
fields and topples pass between the the

00:13:09,139 --> 00:13:15,379
these various components yeah the slides

00:13:13,220 --> 00:13:18,259
would be online be easier to find them

00:13:15,379 --> 00:13:22,629
later so as I said the spout could be

00:13:18,259 --> 00:13:26,929
something as simple as rabbitmq or AWS

00:13:22,629 --> 00:13:29,629
SQS and the indexer can be elastic shot

00:13:26,929 --> 00:13:32,870
search or solar all the components in

00:13:29,629 --> 00:13:35,480
gray are you know the ones provided by

00:13:32,870 --> 00:13:37,490
storm crow by default so what and then

00:13:35,480 --> 00:13:39,769
some of the new ones for the indexing

00:13:37,490 --> 00:13:41,269
could also come from some Cola so it's

00:13:39,769 --> 00:13:44,149
very likely you'll need to basically

00:13:41,269 --> 00:13:46,309
just provide a spout implementation the

00:13:44,149 --> 00:13:49,839
topology class itself and that's it but

00:13:46,309 --> 00:13:53,899
but your uncle right what about

00:13:49,839 --> 00:13:55,579
recursive calls so when we have that

00:13:53,899 --> 00:13:58,269
works fine when you have just a set list

00:13:55,579 --> 00:14:00,230
of URLs and everything but when we have

00:13:58,269 --> 00:14:02,839
recursive calls we need something a

00:14:00,230 --> 00:14:05,829
little bit more or failure you need

00:14:02,839 --> 00:14:08,959
something a little bit more complex so

00:14:05,829 --> 00:14:11,300
that's what a proper call would look

00:14:08,959 --> 00:14:13,279
like you have you start from seeds and

00:14:11,300 --> 00:14:16,759
then you follow our link so some some

00:14:13,279 --> 00:14:19,790
links can take you back to the URLs

00:14:16,759 --> 00:14:21,290
you've already visited some of the links

00:14:19,790 --> 00:14:25,189
you don't want to go the ones with the

00:14:21,290 --> 00:14:30,110
year your stop sign that's what you need

00:14:25,189 --> 00:14:32,209
the your url filters for so one thing

00:14:30,110 --> 00:14:34,220
that the storm called stone color does

00:14:32,209 --> 00:14:35,939
for handling guests like like this is

00:14:34,220 --> 00:14:38,209
that we use I mentioned this

00:14:35,939 --> 00:14:40,379
rooms before and in storm you can have

00:14:38,209 --> 00:14:42,569
there's a default stream but you can

00:14:40,379 --> 00:14:45,359
have as many different streams and give

00:14:42,569 --> 00:14:46,979
them a name as you want so the strategy

00:14:45,359 --> 00:14:49,619
we use is to have one which is called

00:14:46,979 --> 00:14:53,039
status so the components like the

00:14:49,619 --> 00:14:55,829
fetcher or pass will omit the the normal

00:14:53,039 --> 00:14:59,509
or the output for a given document on

00:14:55,829 --> 00:15:03,449
the standard stream but also generate

00:14:59,509 --> 00:15:05,789
other typos on the status stream to send

00:15:03,449 --> 00:15:08,009
that to another bolt that you'd have

00:15:05,789 --> 00:15:10,859
which is I called it state to sub data

00:15:08,009 --> 00:15:13,769
here and that boat will be in charge of

00:15:10,859 --> 00:15:16,829
basically send that to some sort of

00:15:13,769 --> 00:15:19,319
storage where a DBE or elasticsearch or

00:15:16,829 --> 00:15:21,899
whatever you want what you'd have you

00:15:19,319 --> 00:15:24,119
know the urls will be stored you'd

00:15:21,899 --> 00:15:26,639
basically have one entry per URL if you

00:15:24,119 --> 00:15:28,319
are sending that back to cuse yeah you

00:15:26,639 --> 00:15:30,599
don't want to add a URL to the queue

00:15:28,319 --> 00:15:33,509
every time you find it as not linking so

00:15:30,599 --> 00:15:35,339
bit more more complex but yeah with

00:15:33,509 --> 00:15:37,739
these two streams you can that's how you

00:15:35,339 --> 00:15:40,349
can deal with it so yeah that's the

00:15:37,739 --> 00:15:43,319
status that topple can have so it's been

00:15:40,349 --> 00:15:46,439
either discovered or already fetched or

00:15:43,319 --> 00:15:49,979
every direction or an error if you think

00:15:46,439 --> 00:15:52,559
of you have a dodgy PDF document and

00:15:49,979 --> 00:15:54,779
Nick mentioned some of the stuff you can

00:15:52,559 --> 00:15:58,699
come across with with tika for instance

00:15:54,779 --> 00:16:02,099
um so yeah you can get an hour so the

00:15:58,699 --> 00:16:05,399
status of data just its function is to

00:16:02,099 --> 00:16:07,409
write to the storage and and what you

00:16:05,399 --> 00:16:09,749
can do is you can extend there's this

00:16:07,409 --> 00:16:12,209
natural abstract class you can reuse and

00:16:09,749 --> 00:16:15,959
makes your life easier to write such

00:16:12,209 --> 00:16:19,129
components yeah I mentioned the core

00:16:15,959 --> 00:16:21,779
part of the project and the external

00:16:19,129 --> 00:16:24,839
parts there is there are very few of

00:16:21,779 --> 00:16:26,669
things for elasticsearch I mentioned

00:16:24,839 --> 00:16:29,189
them now not now that we've seen the

00:16:26,669 --> 00:16:30,749
other state to stream and so on so yeah

00:16:29,189 --> 00:16:34,019
there's obviously an indexer bolt that

00:16:30,749 --> 00:16:37,889
takes document document index index them

00:16:34,019 --> 00:16:41,279
but there's also a status of data boat

00:16:37,889 --> 00:16:43,100
and an elastic search spout bolt so

00:16:41,279 --> 00:16:45,869
these are useful doing recursive calls

00:16:43,100 --> 00:16:48,239
and there's also one thing I read like

00:16:45,869 --> 00:16:49,550
is the matrix consumer so storm can

00:16:48,239 --> 00:16:52,940
generate metrics as now

00:16:49,550 --> 00:16:55,339
CPI for that and this class allows you

00:16:52,940 --> 00:16:57,769
to send the metrics to elasticsearch

00:16:55,339 --> 00:17:00,830
then you can you can use cabana for

00:16:57,769 --> 00:17:03,260
instance to display the metrics of your

00:17:00,830 --> 00:17:07,429
corner so you can see the pages per

00:17:03,260 --> 00:17:09,079
second and so on so I've already

00:17:07,429 --> 00:17:12,230
mentioned some of it so how to use it

00:17:09,079 --> 00:17:15,020
well the thing you need to do is maybe

00:17:12,230 --> 00:17:16,760
at least write a topology class so where

00:17:15,020 --> 00:17:17,929
you define you know the bolts and are

00:17:16,760 --> 00:17:20,480
they they they are connected to each

00:17:17,929 --> 00:17:25,630
other or you can take the example worn

00:17:20,480 --> 00:17:28,100
in code and Hacket you probably need to

00:17:25,630 --> 00:17:31,100
write if your resource files for their

00:17:28,100 --> 00:17:33,710
URL filters and pass filters package the

00:17:31,100 --> 00:17:35,870
stuff with with maven or any other tool

00:17:33,710 --> 00:17:38,450
you like and and then yeah you call

00:17:35,870 --> 00:17:41,240
storm on it and bang you have a crawler

00:17:38,450 --> 00:17:42,710
that can scale and with minimal amount

00:17:41,240 --> 00:17:45,890
of code to write and minimal

00:17:42,710 --> 00:17:48,260
configuration so that's why the topology

00:17:45,890 --> 00:17:50,600
class would look like and I'm not sure

00:17:48,260 --> 00:17:51,890
you can see very well but yeah we can

00:17:50,600 --> 00:17:54,110
see all the different bolts and how they

00:17:51,890 --> 00:17:55,700
are connected and an RV they are grouped

00:17:54,110 --> 00:17:59,470
as well just got important for

00:17:55,700 --> 00:18:03,679
politeness and also for performance

00:17:59,470 --> 00:18:06,020
that's year the storm you I so if you

00:18:03,679 --> 00:18:08,660
launch storm and distributed mode you'd

00:18:06,020 --> 00:18:10,370
see something like this you can see how

00:18:08,660 --> 00:18:11,870
your boats are performing and the

00:18:10,370 --> 00:18:13,850
latency of each bolt so you can you can

00:18:11,870 --> 00:18:15,950
find bottlenecks it's a pretty good

00:18:13,850 --> 00:18:20,150
pretty good tool and a good way of

00:18:15,950 --> 00:18:22,040
monitoring your your crawler so quickly

00:18:20,150 --> 00:18:24,380
through that it's been used them yeah

00:18:22,040 --> 00:18:26,600
bye-bye I've used it for califica lines

00:18:24,380 --> 00:18:28,580
and political committees well people who

00:18:26,600 --> 00:18:30,200
are now committers have used it for

00:18:28,580 --> 00:18:32,240
their for that project so we've had

00:18:30,200 --> 00:18:33,890
cases from in a very simple ones where

00:18:32,240 --> 00:18:36,140
you have a list of it existing list of

00:18:33,890 --> 00:18:37,400
URLs we wanted to fetch and pass them so

00:18:36,140 --> 00:18:40,850
that's pretty straightforward so that

00:18:37,400 --> 00:18:44,570
was just rabbitmq as a for the spelt and

00:18:40,850 --> 00:18:46,520
then elastic for the indexing to pretty

00:18:44,570 --> 00:18:51,530
much every possible use case in between

00:18:46,520 --> 00:18:53,630
20 to more complex complex crawls with a

00:18:51,530 --> 00:18:55,400
full recursive thing and I choose

00:18:53,630 --> 00:18:58,340
dynamic DB and that's was running on it

00:18:55,400 --> 00:19:02,630
that's running on production and on on

00:18:58,340 --> 00:19:03,970
ec2 what's next so I said just released

00:19:02,630 --> 00:19:06,230
point 5

00:19:03,970 --> 00:19:09,050
there's been some work done on the

00:19:06,230 --> 00:19:11,540
documentation but who likes writing

00:19:09,050 --> 00:19:14,810
documentation so this yet if you

00:19:11,540 --> 00:19:17,450
definitely be more work on that also

00:19:14,810 --> 00:19:22,130
said that's an sdk once we probably try

00:19:17,450 --> 00:19:24,320
and do and have like an example that you

00:19:22,130 --> 00:19:28,250
know an example project showing the fool

00:19:24,320 --> 00:19:30,110
because if corner things probably based

00:19:28,250 --> 00:19:32,450
on the existing components we have for

00:19:30,110 --> 00:19:34,700
elasticsearch that would be a good

00:19:32,450 --> 00:19:37,100
example of to show how to use them use

00:19:34,700 --> 00:19:39,680
storm quota and yeah probably add add a

00:19:37,100 --> 00:19:43,160
few more paths and URL filters and and

00:19:39,680 --> 00:19:44,930
and so on one thing that will certainly

00:19:43,160 --> 00:19:47,450
happen is to have a selenium based

00:19:44,930 --> 00:19:51,770
protocol implementation so that you can

00:19:47,450 --> 00:19:55,100
deal with these pesky Ajax pages that's

00:19:51,770 --> 00:19:58,160
it few resources so there's a very good

00:19:55,100 --> 00:20:00,590
book published by Manning on storm which

00:19:58,160 --> 00:20:04,490
will really helped me on understand it

00:20:00,590 --> 00:20:09,310
better but the otherwise yeah the body

00:20:04,490 --> 00:20:12,710
said the project on github and as yeah

00:20:09,310 --> 00:20:19,880
links for storming notch as well that's

00:20:12,710 --> 00:20:22,840
it journey questions thanks let's oh I

00:20:19,880 --> 00:20:22,840

YouTube URL: https://www.youtube.com/watch?v=97G2Ur2VIPI


