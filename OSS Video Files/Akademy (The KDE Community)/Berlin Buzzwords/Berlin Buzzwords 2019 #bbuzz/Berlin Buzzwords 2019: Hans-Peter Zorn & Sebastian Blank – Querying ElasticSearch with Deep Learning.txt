Title: Berlin Buzzwords 2019: Hans-Peter Zorn & Sebastian Blank â€“ Querying ElasticSearch with Deep Learning
Publication date: 2019-06-20
Playlist: Berlin Buzzwords 2019 #bbuzz
Description: 
	Hans-Peter Zorn and Sebastian Blank talking about "Querying Elasticsearch with Deep Learning to Answer Natural Language Questions "

Natural language is gaining more and more relevance as an interface between man and machine. Already today, we are able to carry out simple task by talking to our smartphone or smart speaker, like Google Home or Alexa. An important challenge for any kind of dialog agent or chatbot is to include external knowledge into the conversation with the user. 

Therefore, such systems need to be able to interact with resources like relational databases or unstructured resources, like search engines. However, the complexity of natural language makes it hard to capture diverse utterances with a set pre-defined rules. Instead, we present an approach that leverages Deep Learning to learn how to query an ElasticSearch given natural language questions. As our model learns to follow the inherent logic of querying, it is even possible to switch to other systems and query languages. This carries a great potential for future applications of ElasticSearch and related NoSQL solutions.

Read more:
https://2019.berlinbuzzwords.de/19/session/querying-elasticsearch-deep-learning-answer-natural-language-questions

About Hans-Peter Zorn:
https://2019.berlinbuzzwords.de/users/hans-peter-zorn

About Sebastian Blank:
https://2019.berlinbuzzwords.de/users/sebastian-blank

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:06,860 --> 00:00:14,030
welcome my name is Hans Peter and we

00:00:11,130 --> 00:00:14,030
will talk about

00:00:15,250 --> 00:00:21,850
and the master thesis of Sebastian who

00:00:18,670 --> 00:00:24,910
were later on in the second part give

00:00:21,850 --> 00:00:30,359
you all the technical details while I

00:00:24,910 --> 00:00:35,970
will just blah blah and this thesis was

00:00:30,359 --> 00:00:39,340
only possible because we had two more

00:00:35,970 --> 00:00:41,890
advisers one of them is dr. Floyd

00:00:39,340 --> 00:00:45,580
William our principal data side instance

00:00:41,890 --> 00:00:50,230
in effects and office our retina from

00:00:45,580 --> 00:00:51,780
the Cosmo Institute of Technology who is

00:00:50,230 --> 00:00:54,700
now into you

00:00:51,780 --> 00:00:59,860
so what is this about

00:00:54,700 --> 00:01:08,770
so yeah what's so just suspecting that

00:00:59,860 --> 00:01:09,210
the battery is low what why did we do

00:01:08,770 --> 00:01:15,640
that

00:01:09,210 --> 00:01:21,189
so basically voice control interaction

00:01:15,640 --> 00:01:24,640
my voice today is used by almost

00:01:21,189 --> 00:01:27,520
everyone this is for me very exciting

00:01:24,640 --> 00:01:31,390
because I was working in dialog systems

00:01:27,520 --> 00:01:36,220
10 years ago also and stuff really

00:01:31,390 --> 00:01:40,140
didn't work at all and it's really nice

00:01:36,220 --> 00:01:49,680
to have all those devices and people

00:01:40,140 --> 00:01:49,680
interacting by voice for us we had a

00:01:50,729 --> 00:01:58,000
very special use case we had in mind

00:01:54,250 --> 00:02:00,759
which was our vision which is not what

00:01:58,000 --> 00:02:05,049
we saw FTEs but what war where we want

00:02:00,759 --> 00:02:09,030
to go we have an internal interpreter

00:02:05,049 --> 00:02:13,260
children at our company and we have a

00:02:09,030 --> 00:02:16,269
chat systems and we would like to have

00:02:13,260 --> 00:02:23,470
to make it possible to ask questions

00:02:16,269 --> 00:02:27,579
about facts in our enterprise Northwest

00:02:23,470 --> 00:02:31,459
company for example

00:02:27,579 --> 00:02:35,810
which employees to know about Apache

00:02:31,459 --> 00:02:43,700
spark or which projects did we use sulla

00:02:35,810 --> 00:02:49,280
in yet until now so these kinds of

00:02:43,700 --> 00:02:53,150
questions go beyond that what often as

00:02:49,280 --> 00:02:56,870
part of such birth control system black

00:02:53,150 --> 00:03:00,290
cop it goes beyond the typical comments

00:02:56,870 --> 00:03:05,239
like in the actions like Alexa switch

00:03:00,290 --> 00:03:08,989
the light on or okay google play my bad

00:03:05,239 --> 00:03:14,120
mood playlist or turn on the air

00:03:08,989 --> 00:03:19,549
conditioning - but you need to answer

00:03:14,120 --> 00:03:25,209
factual questions and so we the answers

00:03:19,549 --> 00:03:29,780
to questions like this is usually hidden

00:03:25,209 --> 00:03:37,489
behind a barrier behind a query language

00:03:29,780 --> 00:03:40,940
or an API so usually the vast majority

00:03:37,489 --> 00:03:44,900
of the public population doesn't speak

00:03:40,940 --> 00:03:48,229
ask well natively so we can't really

00:03:44,900 --> 00:03:51,379
existed by excess dust content of

00:03:48,229 --> 00:03:54,349
information hierarchy and our goal was

00:03:51,379 --> 00:03:58,939
to build to use machine learning machine

00:03:54,349 --> 00:04:02,150
learning or in particular deep learning

00:03:58,939 --> 00:04:04,579
to overcome this barrier to build the

00:04:02,150 --> 00:04:08,359
models of basically translate translate

00:04:04,579 --> 00:04:14,329
between natural language and such query

00:04:08,359 --> 00:04:18,169
languages so there are two possibilities

00:04:14,329 --> 00:04:23,090
to do that one we call hot lookup and

00:04:18,169 --> 00:04:29,150
one we are we were called soft look up

00:04:23,090 --> 00:04:32,349
what is hard look up with heart raka we

00:04:29,150 --> 00:04:36,610
basically build a machine learning model

00:04:32,349 --> 00:04:39,830
that acts as a directions later between

00:04:36,610 --> 00:04:40,889
natural language and the query language

00:04:39,830 --> 00:04:44,069
so we have Google

00:04:40,889 --> 00:04:47,219
late that translates between English and

00:04:44,069 --> 00:04:49,949
German and we have similar model that

00:04:47,219 --> 00:04:56,990
translate between trimmed and secret or

00:04:49,949 --> 00:05:02,810
elastic search query API that sounds

00:04:56,990 --> 00:05:07,889
feasible because such models exist but

00:05:02,810 --> 00:05:13,020
the problem here is that the trimble is

00:05:07,889 --> 00:05:14,550
not and to end trainable it's not what

00:05:13,020 --> 00:05:16,740
do I mean by that

00:05:14,550 --> 00:05:19,889
usually in machine learning you need

00:05:16,740 --> 00:05:25,680
training data by now everyone know that

00:05:19,889 --> 00:05:28,169
the more they there the better and for

00:05:25,680 --> 00:05:34,259
that kind of amalah we would like to

00:05:28,169 --> 00:05:38,550
train with samples of a question and the

00:05:34,259 --> 00:05:40,979
corresponding answer but we can't build

00:05:38,550 --> 00:05:44,430
such a model and train it because this

00:05:40,979 --> 00:05:47,819
database is in p in between and we can't

00:05:44,430 --> 00:05:52,650
integrate the database into our model so

00:05:47,819 --> 00:05:55,289
it's not differentiable and this way not

00:05:52,650 --> 00:06:00,080
and to end trainable so what we need to

00:05:55,289 --> 00:06:03,870
do is we need to create another data set

00:06:00,080 --> 00:06:07,439
- that s consists of the question and

00:06:03,870 --> 00:06:10,349
the corresponding query and that usually

00:06:07,439 --> 00:06:15,330
doesn't exist we need to create it and

00:06:10,349 --> 00:06:18,360
that is costly there are these the

00:06:15,330 --> 00:06:22,439
second option how to solve this problem

00:06:18,360 --> 00:06:24,659
is so called soft look up which is a

00:06:22,439 --> 00:06:28,370
soft lock that we basically build a

00:06:24,659 --> 00:06:32,669
model that contains all the information

00:06:28,370 --> 00:06:36,870
so we have somehow transfer the

00:06:32,669 --> 00:06:39,120
information from the database into a

00:06:36,870 --> 00:06:43,759
mathematical model into a deep learning

00:06:39,120 --> 00:06:47,550
model and we can do that by really

00:06:43,759 --> 00:06:51,950
putting all the columns in there or

00:06:47,550 --> 00:06:55,400
train it on the on the pairs and then

00:06:51,950 --> 00:07:00,590
the informations effects they are

00:06:55,400 --> 00:07:03,710
basically cells in this smaller for

00:07:00,590 --> 00:07:07,910
example memory networks work like that

00:07:03,710 --> 00:07:10,820
and what the model learns then is

00:07:07,910 --> 00:07:14,570
basically a mathematical function that

00:07:10,820 --> 00:07:20,060
maps from the question to effect but

00:07:14,570 --> 00:07:22,520
that s has some drawbacks first of all

00:07:20,060 --> 00:07:31,580
you need a lot of training data to do

00:07:22,520 --> 00:07:36,350
that again but the problem is all the

00:07:31,580 --> 00:07:39,080
information must fit into the into the

00:07:36,350 --> 00:07:43,520
deep learning model and that it's

00:07:39,080 --> 00:07:45,380
usually in the in the main memory and if

00:07:43,520 --> 00:07:48,320
you have a nice database containing all

00:07:45,380 --> 00:07:50,180
the effects why do you want to transfer

00:07:48,320 --> 00:07:52,250
it from the database into your brother

00:07:50,180 --> 00:07:56,390
and the other thing is it's hard to

00:07:52,250 --> 00:07:59,090
interpret it as I said it's basically a

00:07:56,390 --> 00:08:03,280
probability distribution so it's

00:07:59,090 --> 00:08:06,680
basically that says the answer is X but

00:08:03,280 --> 00:08:09,730
the probability is high that this

00:08:06,680 --> 00:08:13,790
question addressed to this fact

00:08:09,730 --> 00:08:15,820
so that's downside of those soft look up

00:08:13,790 --> 00:08:21,080
models so the hard lookup looks nice

00:08:15,820 --> 00:08:24,380
because it is also in a principle like

00:08:21,080 --> 00:08:26,930
we know to look at such a query

00:08:24,380 --> 00:08:31,670
statement and understand what it means

00:08:26,930 --> 00:08:35,330
and why this query probably what returns

00:08:31,670 --> 00:08:39,410
wrong answer so we can better understand

00:08:35,330 --> 00:08:44,780
it we have much more capacity and that's

00:08:39,410 --> 00:08:48,440
why our approach was to find a solution

00:08:44,780 --> 00:08:52,100
to make the heart lock up and to end

00:08:48,440 --> 00:08:55,010
trainable and that's what Sebastian will

00:08:52,100 --> 00:08:56,270
talk about okay thanks do you hear me I

00:08:55,010 --> 00:08:58,970
think so

00:08:56,270 --> 00:09:01,910
yeah unless the title says we are using

00:08:58,970 --> 00:09:04,310
deep learning so we are using neural

00:09:01,910 --> 00:09:07,190
network Steve mural networks and

00:09:04,310 --> 00:09:10,370
and I'll pee you will often see this

00:09:07,190 --> 00:09:12,320
four-step framework which has first you

00:09:10,370 --> 00:09:15,110
embed the inputs then you encode you

00:09:12,320 --> 00:09:17,440
attend then you predict and within the

00:09:15,110 --> 00:09:20,180
next slides I will give you a brief idea

00:09:17,440 --> 00:09:24,830
how this works and then how we used it

00:09:20,180 --> 00:09:26,990
so embedding means that we you can

00:09:24,830 --> 00:09:30,380
imagine a neural network as a very

00:09:26,990 --> 00:09:32,750
complex function and somehow we are

00:09:30,380 --> 00:09:35,630
working with words but we need to turn

00:09:32,750 --> 00:09:39,440
them into numerical values so that's

00:09:35,630 --> 00:09:41,900
what embedding do and the previous talk

00:09:39,440 --> 00:09:44,180
I understood it that way that they used

00:09:41,900 --> 00:09:46,130
tf-idf which is something different word

00:09:44,180 --> 00:09:49,700
embeddings are trained on large corpora

00:09:46,130 --> 00:09:52,190
so this for example were to vector there

00:09:49,700 --> 00:09:54,490
is globe from Stanford University and

00:09:52,190 --> 00:09:58,550
they trained it for example on Wikipedia

00:09:54,490 --> 00:10:01,370
to extract a vector pervert

00:09:58,550 --> 00:10:05,529
so these embeddings typically you have

00:10:01,370 --> 00:10:08,839
dimensions 200 300 400 dimensional and

00:10:05,529 --> 00:10:12,170
what you see here is a artificial a

00:10:08,839 --> 00:10:14,990
fictional 2d representation of such

00:10:12,170 --> 00:10:17,450
words where we have a question who was

00:10:14,990 --> 00:10:20,240
the writer of the move true lies and

00:10:17,450 --> 00:10:22,430
each dot in this diagram would represent

00:10:20,240 --> 00:10:26,510
one word which is defined by two

00:10:22,430 --> 00:10:29,270
coordinates the word who represented by

00:10:26,510 --> 00:10:32,000
the green dot would locate in the upper

00:10:29,270 --> 00:10:36,620
left and the word rider in the lower

00:10:32,000 --> 00:10:40,640
right and one assumption or one finding

00:10:36,620 --> 00:10:43,930
in the research of word embeddings was

00:10:40,640 --> 00:10:45,770
that they are able to capture certain

00:10:43,930 --> 00:10:47,450
relationships in natural language

00:10:45,770 --> 00:10:50,270
because they are trained on the

00:10:47,450 --> 00:10:53,030
objective to group similarities in the

00:10:50,270 --> 00:10:55,430
same areas and as you can imagine with

00:10:53,030 --> 00:10:58,490
300 dimensions you can capture different

00:10:55,430 --> 00:11:02,209
type of relationships so for example we

00:10:58,490 --> 00:11:06,080
assume that the word writer would be

00:11:02,209 --> 00:11:09,830
close to the word author in this vector

00:11:06,080 --> 00:11:12,110
space in the original papers they also

00:11:09,830 --> 00:11:16,910
stated that you for example can see that

00:11:12,110 --> 00:11:18,380
gender relations can be found and so on

00:11:16,910 --> 00:11:21,620
so at the end

00:11:18,380 --> 00:11:26,080
this face each word is represented by

00:11:21,620 --> 00:11:28,190
one vector so the next step we use a

00:11:26,080 --> 00:11:32,270
recurrent neural network more

00:11:28,190 --> 00:11:36,020
specifically a lsdm along shorter memory

00:11:32,270 --> 00:11:39,590
network to transform these vectors

00:11:36,020 --> 00:11:43,280
pervert into a one vector per sequence

00:11:39,590 --> 00:11:47,810
per question representation so this blue

00:11:43,280 --> 00:11:49,760
box in the end is somehow related to the

00:11:47,810 --> 00:11:51,890
dots you saw on the previous slide so

00:11:49,760 --> 00:11:54,200
this is the vector that represents our

00:11:51,890 --> 00:11:57,410
question who was the writer of true lies

00:11:54,200 --> 00:12:01,010
and which is yeah computed by our

00:11:57,410 --> 00:12:04,730
encoder I don't go into more detail here

00:12:01,010 --> 00:12:06,290
there's a lot of cool stuff in the web

00:12:04,730 --> 00:12:09,710
which you can check out if you are

00:12:06,290 --> 00:12:12,530
interested this vector representation is

00:12:09,710 --> 00:12:18,470
then passed to the decoder so you see

00:12:12,530 --> 00:12:22,070
one decoder cell here which is designed

00:12:18,470 --> 00:12:25,970
to predict words so you just see one

00:12:22,070 --> 00:12:29,360
word here but theoretically it predicts

00:12:25,970 --> 00:12:33,020
word by word step by step and uses as

00:12:29,360 --> 00:12:35,300
its input this context vector we created

00:12:33,020 --> 00:12:38,150
in the previous step and if you imagine

00:12:35,300 --> 00:12:40,550
that you would need to summarize a news

00:12:38,150 --> 00:12:44,660
article then this context vector would

00:12:40,550 --> 00:12:47,000
be corresponding to your intuition after

00:12:44,660 --> 00:12:49,520
you read the article for the first time

00:12:47,000 --> 00:12:53,360
as soon as you want to write your

00:12:49,520 --> 00:12:56,300
summary you would then refer back to the

00:12:53,360 --> 00:12:58,250
original article read another line or

00:12:56,300 --> 00:13:00,800
you highlighted something and so on and

00:12:58,250 --> 00:13:02,600
use this in combination with your basic

00:13:00,800 --> 00:13:05,900
intuition of what the news article is

00:13:02,600 --> 00:13:09,010
about to write your summary and this was

00:13:05,900 --> 00:13:13,280
the vague idea of what is known as

00:13:09,010 --> 00:13:16,280
attention attention mechanisms in yeah

00:13:13,280 --> 00:13:20,360
deep learning and again in the previous

00:13:16,280 --> 00:13:24,890
talk the both people spoke about bird

00:13:20,360 --> 00:13:26,900
which is a system or a system trained on

00:13:24,890 --> 00:13:30,080
transformers which are only built on

00:13:26,900 --> 00:13:32,450
attention so this is big big trend in

00:13:30,080 --> 00:13:36,890
the deep learning community at the

00:13:32,450 --> 00:13:41,930
moment so now we are at the state that

00:13:36,890 --> 00:13:44,960
our model predicted one token we had our

00:13:41,930 --> 00:13:46,820
question this is our model like from the

00:13:44,960 --> 00:13:48,950
previous slides and will predict

00:13:46,820 --> 00:13:52,640
multiple tokens to fill this query

00:13:48,950 --> 00:13:54,590
template so we used in our experiments

00:13:52,640 --> 00:13:58,460
we used elastic search and we designed

00:13:54,590 --> 00:14:00,560
that way that we capture three fields

00:13:58,460 --> 00:14:03,260
the most important is the query

00:14:00,560 --> 00:14:06,980
condition which captures the entity of

00:14:03,260 --> 00:14:09,650
the question so the question was who was

00:14:06,980 --> 00:14:11,450
the writer of true lies and we with our

00:14:09,650 --> 00:14:14,090
model will predict the start and end

00:14:11,450 --> 00:14:17,330
token of this entity so we can handle

00:14:14,090 --> 00:14:19,880
entities of different lengths the query

00:14:17,330 --> 00:14:23,720
field is then used to identify which

00:14:19,880 --> 00:14:26,480
category this entity belongs to so here

00:14:23,720 --> 00:14:29,630
true lies as a movie title and in the

00:14:26,480 --> 00:14:32,300
end the response field predict or

00:14:29,630 --> 00:14:36,440
captures which category we want to

00:14:32,300 --> 00:14:39,980
retrieve from our elastic search and to

00:14:36,440 --> 00:14:42,380
perform this prediction our model has

00:14:39,980 --> 00:14:45,650
access to a vocabulary which is defined

00:14:42,380 --> 00:14:50,360
by some by the database categories and

00:14:45,650 --> 00:14:52,670
by the tokens from our input questions

00:14:50,360 --> 00:14:56,770
and that's why it's able to predict

00:14:52,670 --> 00:14:59,780
these tokens we then operate this query

00:14:56,770 --> 00:15:01,880
we're an interface on the elastic search

00:14:59,780 --> 00:15:05,390
which returns a response but a sense

00:15:01,880 --> 00:15:07,790
Peter discussed earlier we can't train

00:15:05,390 --> 00:15:10,330
directly on this feedback because it's

00:15:07,790 --> 00:15:12,650
not differentiable and there is

00:15:10,330 --> 00:15:16,070
workaround when you use reinforcement

00:15:12,650 --> 00:15:17,930
learning again that's a big topic at the

00:15:16,070 --> 00:15:22,820
moment and I won't go into details here

00:15:17,930 --> 00:15:27,190
but to give you a quick idea how we did

00:15:22,820 --> 00:15:29,690
it is we provided rewards so like little

00:15:27,190 --> 00:15:33,250
imagine a crown crowd worker who would

00:15:29,690 --> 00:15:36,800
do this work and he would gain different

00:15:33,250 --> 00:15:40,790
money or different rewards financial

00:15:36,800 --> 00:15:42,890
rewards choose solve the task so if he

00:15:40,790 --> 00:15:43,700
produces invalid queries he would need

00:15:42,890 --> 00:15:46,940
to pay

00:15:43,700 --> 00:15:48,500
two euros for example and will you find

00:15:46,940 --> 00:15:50,210
invalid queries in that way that it

00:15:48,500 --> 00:15:53,000
either causes an error or that the

00:15:50,210 --> 00:15:56,870
database response is empty so no result

00:15:53,000 --> 00:15:59,630
was retrieved furthermore he would need

00:15:56,870 --> 00:16:01,240
to pay 1 euro if he produced a valid

00:15:59,630 --> 00:16:03,890
query but the result was wrong so

00:16:01,240 --> 00:16:05,740
further before the movie who was the

00:16:03,890 --> 00:16:09,760
writer of True Lies when he would

00:16:05,740 --> 00:16:13,520
retrieve a year or another direct a

00:16:09,760 --> 00:16:17,060
movie writer then the model would get a

00:16:13,520 --> 00:16:19,700
penalty on this performance and finally

00:16:17,060 --> 00:16:22,880
what we are looking for is valid queries

00:16:19,700 --> 00:16:25,280
with correct results and in our initial

00:16:22,880 --> 00:16:27,980
experiments we provide a small positive

00:16:25,280 --> 00:16:30,140
reward plus one and as you can see with

00:16:27,980 --> 00:16:32,950
the star we varied that in our

00:16:30,140 --> 00:16:36,320
experiments because we found that it had

00:16:32,950 --> 00:16:39,730
quite an quite a big impact on the

00:16:36,320 --> 00:16:43,520
results we found so we evaluated our

00:16:39,730 --> 00:16:45,830
model on the movie dialogue data set

00:16:43,520 --> 00:16:49,100
which is provided by Facebook which is

00:16:45,830 --> 00:16:53,710
open source and the data set contains

00:16:49,100 --> 00:16:59,270
about 96 thousand questions about movies

00:16:53,710 --> 00:17:01,520
and a database with 17 thousand movies

00:16:59,270 --> 00:17:05,870
and facts about for example the writer

00:17:01,520 --> 00:17:09,380
the actors and so on and we stored the

00:17:05,870 --> 00:17:12,860
metadata in the elasticsearch and gave

00:17:09,380 --> 00:17:15,080
our model access via this interface and

00:17:12,860 --> 00:17:20,060
now I will show you what we found what

00:17:15,080 --> 00:17:24,290
we learned during this project so first

00:17:20,060 --> 00:17:26,600
as I said we found that the very rewards

00:17:24,290 --> 00:17:29,000
in our experiments because we found that

00:17:26,600 --> 00:17:31,190
they changed the performance of our

00:17:29,000 --> 00:17:33,620
system in the beginning with small

00:17:31,190 --> 00:17:36,230
positive rewards our model always

00:17:33,620 --> 00:17:39,890
predicted the same kind of career very

00:17:36,230 --> 00:17:43,970
simple it was kind of a lazy prediction

00:17:39,890 --> 00:17:46,310
because it tended to predict the major

00:17:43,970 --> 00:17:48,740
or the the predominant category which

00:17:46,310 --> 00:17:50,390
was the movie title and one word of the

00:17:48,740 --> 00:17:53,300
question so for example just the first

00:17:50,390 --> 00:17:57,320
word and by this it achieved that all

00:17:53,300 --> 00:17:57,870
almost or queries were valid so 99% of

00:17:57,320 --> 00:18:00,419
the queries

00:17:57,870 --> 00:18:02,789
valid but it retrieves no correct

00:18:00,419 --> 00:18:03,390
results at all so that was not what we

00:18:02,789 --> 00:18:06,289
aim for

00:18:03,390 --> 00:18:08,909
so we experimented a little around and

00:18:06,289 --> 00:18:11,340
we found that by increasing the positive

00:18:08,909 --> 00:18:12,980
rewards for the belt queries and correct

00:18:11,340 --> 00:18:15,900
results

00:18:12,980 --> 00:18:19,320
2:25 which was yeah

00:18:15,900 --> 00:18:21,419
an empirical choice in the end we found

00:18:19,320 --> 00:18:23,940
that we were able to improve our

00:18:21,419 --> 00:18:27,270
performance so the share of vary queries

00:18:23,940 --> 00:18:30,320
was reduced but we were able to score

00:18:27,270 --> 00:18:34,789
almost 50% or more than 50% of the

00:18:30,320 --> 00:18:37,440
correct results but still after

00:18:34,789 --> 00:18:40,260
analyzing these results we found ok our

00:18:37,440 --> 00:18:42,029
model became better at predicting the

00:18:40,260 --> 00:18:43,830
entities so it varied the lengths

00:18:42,029 --> 00:18:48,419
depending on the question that was able

00:18:43,830 --> 00:18:50,279
to handle questions with just one word

00:18:48,419 --> 00:18:52,770
as the entity for example Titanic or

00:18:50,279 --> 00:18:56,490
true lies with two words and so on and

00:18:52,770 --> 00:18:58,919
so on it also identified the

00:18:56,490 --> 00:19:03,480
corresponding credit category correctly

00:18:58,919 --> 00:19:07,919
but the output category the output field

00:19:03,480 --> 00:19:11,399
was still yeah dominated by the major

00:19:07,919 --> 00:19:13,649
major category in the data set which is

00:19:11,399 --> 00:19:16,380
why we use the little trick which is

00:19:13,649 --> 00:19:18,929
called exploration boni and the

00:19:16,380 --> 00:19:21,899
intuitive idea is that you provide an

00:19:18,929 --> 00:19:27,000
extra reward extra financial motivation

00:19:21,899 --> 00:19:31,200
to say to motivate a model to try

00:19:27,000 --> 00:19:33,360
something new so Exuma that it had 100

00:19:31,200 --> 00:19:35,760
predictions and always say okay give me

00:19:33,360 --> 00:19:38,460
the movie name then we would try provide

00:19:35,760 --> 00:19:42,630
a little positive reward to say okay if

00:19:38,460 --> 00:19:46,380
you try two times to receive the genre

00:19:42,630 --> 00:19:49,200
or the language the movie was in try it

00:19:46,380 --> 00:19:51,090
out and we'll see if you improve so that

00:19:49,200 --> 00:19:54,690
was the result from the previous slide

00:19:51,090 --> 00:19:57,450
from our minus one minus two plus

00:19:54,690 --> 00:20:00,380
twenty-five rewards without the reward

00:19:57,450 --> 00:20:03,090
pony and with we reward pony like this

00:20:00,380 --> 00:20:05,940
motivation to try something new we found

00:20:03,090 --> 00:20:09,270
that our model improved significantly so

00:20:05,940 --> 00:20:11,340
we gained a boost of around 30% which

00:20:09,270 --> 00:20:15,149
was really impressive

00:20:11,340 --> 00:20:18,149
in my opinion and then we thought okay

00:20:15,149 --> 00:20:21,840
how good can we get a stir awake that we

00:20:18,149 --> 00:20:26,460
experiment a little more and engineer a

00:20:21,840 --> 00:20:28,529
little to even improve more but first we

00:20:26,460 --> 00:20:31,710
checked how good can we get because in

00:20:28,529 --> 00:20:33,360
the data set we found that natural

00:20:31,710 --> 00:20:36,870
language for sure is ambiguous it was a

00:20:33,360 --> 00:20:39,210
yeah we could have gotten this idea

00:20:36,870 --> 00:20:41,669
earlier because there's this example

00:20:39,210 --> 00:20:43,289
there are four movies called the three

00:20:41,669 --> 00:20:47,610
musketeers in the data set so if I would

00:20:43,289 --> 00:20:50,340
ask you in which year was the movie the

00:20:47,610 --> 00:20:51,840
three musketeers released and you would

00:20:50,340 --> 00:20:55,230
have access to this database with

00:20:51,840 --> 00:20:57,210
information in it I think more people

00:20:55,230 --> 00:20:59,279
would tend to predict the number that

00:20:57,210 --> 00:21:02,279
corresponds to the newest movie but

00:20:59,279 --> 00:21:04,580
still there would be people voting for

00:21:02,279 --> 00:21:08,190
the other three movies and this

00:21:04,580 --> 00:21:13,679
ambiguous entities in the data set

00:21:08,190 --> 00:21:16,409
accounted for about 4% additionally we

00:21:13,679 --> 00:21:19,080
say okay we said we wanted to stay end

00:21:16,409 --> 00:21:21,929
to end that's why we used reinforcement

00:21:19,080 --> 00:21:26,879
learning so we used the question and as

00:21:21,929 --> 00:21:30,840
the input and eval or provided rewards

00:21:26,879 --> 00:21:33,269
for our model to learn and that was yeah

00:21:30,840 --> 00:21:35,610
the thing I was talking about before and

00:21:33,269 --> 00:21:38,549
we scored eighty four point two percent

00:21:35,610 --> 00:21:43,440
here and then we checked okay how good

00:21:38,549 --> 00:21:46,649
can we get if we are not in the entrant

00:21:43,440 --> 00:21:48,960
setting but we use this intermediate

00:21:46,649 --> 00:21:50,820
labels which are available doesn't

00:21:48,960 --> 00:21:52,590
matter how costly they are at the moment

00:21:50,820 --> 00:21:56,340
because in the data set they weigh array

00:21:52,590 --> 00:21:59,700
available and we showed that we could

00:21:56,340 --> 00:22:02,460
score around six percent better so we

00:21:59,700 --> 00:22:04,740
see that there is this trade-off that if

00:22:02,460 --> 00:22:08,820
it's possible to use this intermediate

00:22:04,740 --> 00:22:12,840
label then there is a little improvement

00:22:08,820 --> 00:22:15,840
but if these are not available because

00:22:12,840 --> 00:22:17,549
it's too costly to label them then even

00:22:15,840 --> 00:22:23,640
with only reinforcement learning we can

00:22:17,549 --> 00:22:25,230
score quite good there is one little

00:22:23,640 --> 00:22:27,270
problem with the reinforcement learning

00:22:25,230 --> 00:22:30,870
part these are the result I showed you

00:22:27,270 --> 00:22:33,120
before and they're they the models

00:22:30,870 --> 00:22:35,160
achieved these results on the large data

00:22:33,120 --> 00:22:38,880
sector ninety six thousand questions

00:22:35,160 --> 00:22:41,730
when we reduced the samples by random

00:22:38,880 --> 00:22:45,390
sampling to ten ten thousand we found

00:22:41,730 --> 00:22:47,580
that the intermediate label approach was

00:22:45,390 --> 00:22:50,490
quite stable but reinforcement learning

00:22:47,580 --> 00:22:56,580
suffered a lot and yeah the results were

00:22:50,490 --> 00:22:59,250
not good at all but yeah sure it could

00:22:56,580 --> 00:23:01,590
be we didn't do much optimizing for

00:22:59,250 --> 00:23:04,650
reinforcement learning but we start with

00:23:01,590 --> 00:23:06,720
the same setting so there is still space

00:23:04,650 --> 00:23:08,580
for improvement with the reinforcement

00:23:06,720 --> 00:23:12,510
learning algorithm with or a setting at

00:23:08,580 --> 00:23:13,919
all or maybe it's not possible to score

00:23:12,510 --> 00:23:15,440
better with reinforcement learning and

00:23:13,919 --> 00:23:18,570
another aspect that we found

00:23:15,440 --> 00:23:21,059
reinforcement learning took lay away

00:23:18,570 --> 00:23:22,559
longer during training so it took twelve

00:23:21,059 --> 00:23:25,230
hours on the large data set with

00:23:22,559 --> 00:23:27,480
reinforcement learning and one hour with

00:23:25,230 --> 00:23:30,720
intermediate labels a certain part of

00:23:27,480 --> 00:23:32,610
this training time accounts for the

00:23:30,720 --> 00:23:34,020
interaction with the elasticsearch which

00:23:32,610 --> 00:23:35,940
we have in the reinforcement learning

00:23:34,020 --> 00:23:39,600
setting but not in the intermediate

00:23:35,940 --> 00:23:43,320
level setting where we could do maybe

00:23:39,600 --> 00:23:46,410
optimize a little by scaling up the

00:23:43,320 --> 00:23:48,570
elasticsearch and now I want to come

00:23:46,410 --> 00:23:51,260
back to the point where hans-peter was

00:23:48,570 --> 00:23:54,059
comparing soft lookup and hard lookup

00:23:51,260 --> 00:23:56,429
because that's an interesting question

00:23:54,059 --> 00:23:59,910
as well we compared both system the one

00:23:56,429 --> 00:24:02,730
is entering trainable by default we only

00:23:59,910 --> 00:24:05,040
need to input the data base and our

00:24:02,730 --> 00:24:06,900
approach is entry and trainable with

00:24:05,040 --> 00:24:08,850
this little hack so these are our

00:24:06,900 --> 00:24:12,450
results and these were the results that

00:24:08,850 --> 00:24:15,360
were reported by the paper of touch at

00:24:12,450 --> 00:24:17,730
all so we have memory networks which are

00:24:15,360 --> 00:24:20,730
on a competitive level to our system and

00:24:17,730 --> 00:24:23,820
we have specialized QA system on

00:24:20,730 --> 00:24:26,220
embeddings that we can approach with our

00:24:23,820 --> 00:24:30,600
intermediate the intermediate labels

00:24:26,220 --> 00:24:32,970
system so there is none of these two

00:24:30,600 --> 00:24:36,000
approaches neither soft lookup nor hard

00:24:32,970 --> 00:24:37,590
lookup that really outperforms the other

00:24:36,000 --> 00:24:41,310
in a significant way

00:24:37,590 --> 00:24:45,590
so it again depends on the problem is it

00:24:41,310 --> 00:24:48,600
useful to extract a part of your

00:24:45,590 --> 00:24:52,260
database feed it to the soft look up or

00:24:48,600 --> 00:24:53,910
is it okay to just use reinforcement

00:24:52,260 --> 00:24:56,490
learning or if you have two intermediate

00:24:53,910 --> 00:25:00,740
labels to use this other approach to

00:24:56,490 --> 00:25:03,510
solve your problem so what did we learn

00:25:00,740 --> 00:25:07,230
we apply the sequence the sequence

00:25:03,510 --> 00:25:09,570
approach with a pointer attention to

00:25:07,230 --> 00:25:10,890
create database queries from natural

00:25:09,570 --> 00:25:13,830
language question in the beginning we

00:25:10,890 --> 00:25:16,350
were quite skeptical if that if this

00:25:13,830 --> 00:25:19,890
would work but in the end it did for it

00:25:16,350 --> 00:25:23,070
to to a certain degree furthermore we

00:25:19,890 --> 00:25:25,860
overcame the problem of non

00:25:23,070 --> 00:25:28,920
differentiability which we didn't

00:25:25,860 --> 00:25:31,920
thought about before as well and thereby

00:25:28,920 --> 00:25:35,100
avoided to produce costly intermediate

00:25:31,920 --> 00:25:37,380
labels and again with the trick of

00:25:35,100 --> 00:25:41,220
exploration Boni we were able to

00:25:37,380 --> 00:25:44,580
overcome this lazy behavior of our

00:25:41,220 --> 00:25:50,000
network to predict just one category at

00:25:44,580 --> 00:25:53,760
all and sure there is a road to continue

00:25:50,000 --> 00:25:55,680
we could aim for or we will aim for more

00:25:53,760 --> 00:25:58,290
complex questions and different corpora

00:25:55,680 --> 00:26:00,210
at the moment we're really centered or

00:25:58,290 --> 00:26:04,350
we we're centered around this one data

00:26:00,210 --> 00:26:07,020
set so we need to try other data sets

00:26:04,350 --> 00:26:10,170
from different domains even open domain

00:26:07,020 --> 00:26:12,660
data sets with more complex questions so

00:26:10,170 --> 00:26:15,060
at the moment we had questions with one

00:26:12,660 --> 00:26:17,540
entity in them and you can't for the

00:26:15,060 --> 00:26:22,380
movie domain for example imagine that

00:26:17,540 --> 00:26:27,660
who was the director of a movie with

00:26:22,380 --> 00:26:30,240
Bruce Willis from the year 2014 or in

00:26:27,660 --> 00:26:32,520
language Japanese or in language English

00:26:30,240 --> 00:26:34,670
furthermore as I described we need to

00:26:32,520 --> 00:26:37,080
improve to several sample efficiency of

00:26:34,670 --> 00:26:39,270
reinforcement learning because as you

00:26:37,080 --> 00:26:43,710
saw with this two data set there was a

00:26:39,270 --> 00:26:45,930
big decrease and sure we need to work on

00:26:43,710 --> 00:26:47,970
the latencies of our database

00:26:45,930 --> 00:26:51,660
interaction or the reinforcement

00:26:47,970 --> 00:26:55,410
learning interaction with the database

00:26:51,660 --> 00:26:58,530
to improve and yeah there have been some

00:26:55,410 --> 00:27:00,870
developments in the NLP community which

00:26:58,530 --> 00:27:04,140
the previous talk again talked about as

00:27:00,870 --> 00:27:07,950
well so this bird model seems to provide

00:27:04,140 --> 00:27:11,450
a nice idea or a nice way to expand our

00:27:07,950 --> 00:27:14,580
approach and maybe score better and

00:27:11,450 --> 00:27:17,940
achieve better results and if you want

00:27:14,580 --> 00:27:20,400
to read more about this talk in a more

00:27:17,940 --> 00:27:23,370
detailed way or it was information

00:27:20,400 --> 00:27:25,260
overload I suggest that you have a look

00:27:23,370 --> 00:27:29,300
at our blog we have a blog post related

00:27:25,260 --> 00:27:32,610
to this work we submitted the paper on a

00:27:29,300 --> 00:27:35,450
research conference and now we are happy

00:27:32,610 --> 00:27:38,150
to take your questions thank you

00:27:35,450 --> 00:27:39,610
[Applause]

00:27:38,150 --> 00:27:41,370
[Music]

00:27:39,610 --> 00:27:49,860
[Applause]

00:27:41,370 --> 00:27:50,580
question yeah I started with you I was

00:27:49,860 --> 00:27:52,740
wondering

00:27:50,580 --> 00:27:54,740
cost-wise did you compare the hard

00:27:52,740 --> 00:27:57,750
lookup and soft lookup for the

00:27:54,740 --> 00:28:00,990
infrastructure yeah we didn't implement

00:27:57,750 --> 00:28:05,490
the soft look up by ourselves so for our

00:28:00,990 --> 00:28:08,160
approach we used one GPU server or one

00:28:05,490 --> 00:28:11,730
GPU and took 12 hours for one training

00:28:08,160 --> 00:28:14,190
loop for the soft look up I don't know

00:28:11,730 --> 00:28:15,990
if the authors of the paper reported

00:28:14,190 --> 00:28:17,850
these numbers but I can imagine it's

00:28:15,990 --> 00:28:20,040
quite resource intense as well and it

00:28:17,850 --> 00:28:23,520
was a Google paper of Facebook paper I

00:28:20,040 --> 00:28:26,150
think as well so that some resources to

00:28:23,520 --> 00:28:26,150
train on

00:28:37,970 --> 00:28:42,599
my question was about your no results

00:28:40,710 --> 00:28:44,669
queries so you said that you give a

00:28:42,599 --> 00:28:46,889
penalty for any response that had no

00:28:44,669 --> 00:28:49,409
results but I imagine a valid question

00:28:46,889 --> 00:28:51,629
might not have any answerable given the

00:28:49,409 --> 00:28:53,159
data set so it makes me assume that

00:28:51,629 --> 00:28:55,739
maybe your data set doesn't have any

00:28:53,159 --> 00:28:59,659
questions for which the correct answer

00:28:55,739 --> 00:29:02,190
is empty but I'm so then my follow-up is

00:28:59,659 --> 00:29:04,259
would that change your approach if you

00:29:02,190 --> 00:29:06,179
have to handle that in some fundamental

00:29:04,259 --> 00:29:08,220
way or is it just a difference in the

00:29:06,179 --> 00:29:11,999
data okay can you repeat the end how do

00:29:08,220 --> 00:29:13,889
you handle no results queries that are

00:29:11,999 --> 00:29:17,460
valid in other words ask a question like

00:29:13,889 --> 00:29:23,849
what movie has me starring as Batman

00:29:17,460 --> 00:29:26,909
yeah yeah and Yin our model before we

00:29:23,849 --> 00:29:28,679
predict or while we are predicting the

00:29:26,909 --> 00:29:31,830
model output somehow a probability

00:29:28,679 --> 00:29:34,950
distribution as well and you could set

00:29:31,830 --> 00:29:38,940
the benchmark so if the model is not

00:29:34,950 --> 00:29:42,509
sure what does me mean and then the

00:29:38,940 --> 00:29:44,220
distribution goes into the uniform

00:29:42,509 --> 00:29:47,340
direction so you could say okay if it's

00:29:44,220 --> 00:29:51,659
below the benchmark and do nothing

00:29:47,340 --> 00:29:55,109
also we just knew that for this data

00:29:51,659 --> 00:30:00,389
that there weren't any correct queries

00:29:55,109 --> 00:30:03,529
with zero results so if you want to

00:30:00,389 --> 00:30:08,220
generalize that we would remove that

00:30:03,529 --> 00:30:12,679
penalty which would probably make the

00:30:08,220 --> 00:30:16,349
model to convert slower because it has

00:30:12,679 --> 00:30:18,299
fewer information available but it would

00:30:16,349 --> 00:30:21,179
work and it's a really interesting

00:30:18,299 --> 00:30:24,179
question if you consider questions where

00:30:21,179 --> 00:30:26,759
multiple answers may be correct so

00:30:24,179 --> 00:30:28,739
there's comes with the design of the

00:30:26,759 --> 00:30:32,460
reward function in the end you can play

00:30:28,739 --> 00:30:34,379
around there hi

00:30:32,460 --> 00:30:36,179
I get another question you mentioned

00:30:34,379 --> 00:30:37,919
that you go boy you're just embedding

00:30:36,179 --> 00:30:40,679
side did you use protected by things

00:30:37,919 --> 00:30:45,080
like glove or water break yeah we use

00:30:40,679 --> 00:30:48,149
below with 300 dimensions and a train

00:30:45,080 --> 00:30:50,230
trained on the 42 billion Wikipedia

00:30:48,149 --> 00:30:52,639
covers did

00:30:50,230 --> 00:30:54,230
variations of dimensionality in the

00:30:52,639 --> 00:30:57,529
beddings and did you observe like

00:30:54,230 --> 00:31:00,230
difference between different flavors of

00:30:57,529 --> 00:31:03,259
four buildings at all no so far we just

00:31:00,230 --> 00:31:05,330
work with the glove embedding but I can

00:31:03,259 --> 00:31:07,490
imagine that if we use this contextual

00:31:05,330 --> 00:31:15,289
embeddings like like bird for example

00:31:07,490 --> 00:31:17,870
then we with yeah thank you I'm curious

00:31:15,289 --> 00:31:21,019
about the invalid queries that were

00:31:17,870 --> 00:31:24,740
malformed did you consider gosh the

00:31:21,019 --> 00:31:27,590
feedback did you consider training your

00:31:24,740 --> 00:31:29,720
system to have a classifier for such

00:31:27,590 --> 00:31:32,360
queries to avoid sending them in the

00:31:29,720 --> 00:31:35,720
first place I just think such as

00:31:32,360 --> 00:31:36,590
mechanism might work better I think I

00:31:35,720 --> 00:31:39,529
didn't understand the question

00:31:36,590 --> 00:31:43,700
acoustically sorry I'll try again the

00:31:39,529 --> 00:31:46,249
echo or feedback makes it hard I was

00:31:43,700 --> 00:31:49,490
just wondering if you tried a classifier

00:31:46,249 --> 00:31:52,220
for detecting malformed queries because

00:31:49,490 --> 00:31:54,669
it seems to me like a lot of the

00:31:52,220 --> 00:31:57,110
malformed queries should be classifiable

00:31:54,669 --> 00:32:02,419
before ever reaching the elasticsearch

00:31:57,110 --> 00:32:04,129
cedam yeah no we didn't but yeah to put

00:32:02,419 --> 00:32:06,409
it into production or to develop it

00:32:04,129 --> 00:32:09,220
further it's definitely necessary I

00:32:06,409 --> 00:32:11,590
think yeah you could you could do that

00:32:09,220 --> 00:32:15,889
part of why we did it

00:32:11,590 --> 00:32:18,200
also because this kind of research the

00:32:15,889 --> 00:32:22,100
interesting part is that models like

00:32:18,200 --> 00:32:25,249
this are able to learn for example

00:32:22,100 --> 00:32:27,200
sequel just by try a trial and error

00:32:25,249 --> 00:32:29,899
which is fascinating so they are

00:32:27,200 --> 00:32:32,990
different as a models that learn sequel

00:32:29,899 --> 00:32:37,429
by using the hospital early as they make

00:32:32,990 --> 00:32:42,590
errors and that's for a practical case

00:32:37,429 --> 00:32:47,480
you would probably use some engineering

00:32:42,590 --> 00:32:51,649
and shortcuts add that stuff but we also

00:32:47,480 --> 00:32:53,980
wanted to do some research fair enough I

00:32:51,649 --> 00:32:57,080
just was curious because often times

00:32:53,980 --> 00:33:00,789
policy networks have helped in these

00:32:57,080 --> 00:33:00,789
sorts of applications okay

00:33:01,160 --> 00:33:13,990
your other question here no okay

00:33:06,740 --> 00:33:13,990

YouTube URL: https://www.youtube.com/watch?v=NMG4tMB5T3U


