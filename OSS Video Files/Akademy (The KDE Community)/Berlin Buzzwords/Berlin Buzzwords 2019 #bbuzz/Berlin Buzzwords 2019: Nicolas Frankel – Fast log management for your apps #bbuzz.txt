Title: Berlin Buzzwords 2019: Nicolas Frankel â€“ Fast log management for your apps #bbuzz
Publication date: 2019-06-20
Playlist: Berlin Buzzwords 2019 #bbuzz
Description: 
	So, you've migrated your application to Reactive Microservices to get the last ounce of performance from your servers. Still want more? Perhaps you forgot about the logs: logs can be one of the few roadblocks on the road to ultimate performance.

At Exoscale, we faced the same challenges as everyone: the application produces logs, and they need to be stored in our log storage - ElasticSearch, with the minimum of fuss and the fastest way possible.

In this talk, I'll show you some insider tips and tricks taken from our experience put you on the track toward fast(er) log management. Without revealing too much, it involves async loggers, JSON, Kafka and Logstash.

Read more:
https://2019.berlinbuzzwords.de/19/session/fast-log-management-your-apps

About Nicolas Frankel:
https://2019.berlinbuzzwords.de/users/nicolas-frankel

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:07,120 --> 00:00:11,930
hi everyone things to be for this talk

00:00:09,680 --> 00:00:14,990
about rock management's and Nicola

00:00:11,930 --> 00:00:15,769
Frankel I've been for like more than 15

00:00:14,990 --> 00:00:18,349
years

00:00:15,769 --> 00:00:20,779
like developer architects as a

00:00:18,349 --> 00:00:23,539
consultant in different context and for

00:00:20,779 --> 00:00:25,580
different companies and like since last

00:00:23,539 --> 00:00:27,590
September I decided to come to talk to

00:00:25,580 --> 00:00:29,359
conferences and be a developer advocate

00:00:27,590 --> 00:00:32,390
because you know where you have less

00:00:29,359 --> 00:00:35,239
kettles and less timelines to respect

00:00:32,390 --> 00:00:37,610
even when I was a developer and an

00:00:35,239 --> 00:00:40,070
architect I I was very interested in the

00:00:37,610 --> 00:00:42,220
other side of the wall in the ops world

00:00:40,070 --> 00:00:44,840
so monitoring and stuff like that I

00:00:42,220 --> 00:00:47,780
worked for a company called exascale we

00:00:44,840 --> 00:00:49,430
are European cloud provider our

00:00:47,780 --> 00:00:52,610
companies in Switzerland but we have

00:00:49,430 --> 00:00:55,040
data centers all around Europe actually

00:00:52,610 --> 00:00:57,710
that's one of the reason I am doing this

00:00:55,040 --> 00:00:59,510
talk is because it's some of the stuff

00:00:57,710 --> 00:01:01,539
that I'm going to describe is how we do

00:00:59,510 --> 00:01:01,539
it

00:01:01,840 --> 00:01:08,509
who here cannot understand that this is

00:01:06,289 --> 00:01:11,420
Java I am sorry I have been the Java

00:01:08,509 --> 00:01:16,280
developer but everybody understand that

00:01:11,420 --> 00:01:23,990
right okay can you tell me what's the

00:01:16,280 --> 00:01:30,649
problem with this statement it compiles

00:01:23,990 --> 00:01:34,880
and insurance but there is an issue know

00:01:30,649 --> 00:01:38,509
type check and the I'm using SLA for G

00:01:34,880 --> 00:01:41,240
so this like double square stuff double

00:01:38,509 --> 00:01:43,280
bracket will be replaced by code get

00:01:41,240 --> 00:01:48,789
price so now everything should work as

00:01:43,280 --> 00:01:48,789
as expected but sorry oh but it doesn't

00:01:49,929 --> 00:01:54,950
get price might be super expensive if

00:01:52,729 --> 00:01:57,470
you have done any e-commerce stuff I

00:01:54,950 --> 00:02:00,679
mean the price is not a value it's a

00:01:57,470 --> 00:02:06,289
computation the computation might take a

00:02:00,679 --> 00:02:09,349
long time so if I if I do it this is the

00:02:06,289 --> 00:02:12,110
codes and I want to run it and I want to

00:02:09,349 --> 00:02:15,200
light log the start time and the end

00:02:12,110 --> 00:02:18,250
time so I can like get the time it takes

00:02:15,200 --> 00:02:18,250
me to do that

00:02:20,409 --> 00:02:27,170
it's not because it's Java is just like

00:02:23,150 --> 00:02:29,959
super long it takes a long time and if

00:02:27,170 --> 00:02:34,760
we check the implementation of get price

00:02:29,959 --> 00:02:36,530
it's well it's very stupid but it means

00:02:34,760 --> 00:02:38,360
it means to simulate the fact that it

00:02:36,530 --> 00:02:40,370
takes a long time and it does takes a

00:02:38,360 --> 00:02:45,470
long time and and the problem with that

00:02:40,370 --> 00:02:47,840
is it happens a lot and if you want you

00:02:45,470 --> 00:02:50,540
might want to get the price in some

00:02:47,840 --> 00:02:52,879
context and you might not be interested

00:02:50,540 --> 00:02:56,120
in other contexts but the log statement

00:02:52,879 --> 00:03:02,269
must be there all the time so you might

00:02:56,120 --> 00:03:06,069
say okay normally this only happens when

00:03:02,269 --> 00:03:09,590
I like I'm in at the debug level and

00:03:06,069 --> 00:03:13,609
still every time I get this computation

00:03:09,590 --> 00:03:16,190
done even if I am at the info level so

00:03:13,609 --> 00:03:20,810
one of the way to bypass that is to say

00:03:16,190 --> 00:03:24,410
okay we can every time we check if we

00:03:20,810 --> 00:03:26,660
are at the right level so if we say

00:03:24,410 --> 00:03:31,340
every time we say each debug enabled and

00:03:26,660 --> 00:03:37,299
we are not debug then it's super fast

00:03:31,340 --> 00:03:41,139
again but the problem in that case is

00:03:37,299 --> 00:03:43,879
that it's super boring for the developer

00:03:41,139 --> 00:03:46,730
it's not one lock statement somewhere

00:03:43,879 --> 00:03:49,879
it's log statements everywhere that need

00:03:46,730 --> 00:03:51,859
to do that worse not only it's boring

00:03:49,879 --> 00:03:54,699
but it's error prone because it's super

00:03:51,859 --> 00:03:58,099
easy to D to do like that

00:03:54,699 --> 00:04:02,199
to add light and synchronization between

00:03:58,099 --> 00:04:05,239
the wall and the log statement itself

00:04:02,199 --> 00:04:08,510
this is bad because then you will again

00:04:05,239 --> 00:04:11,840
get faced with the same problem but this

00:04:08,510 --> 00:04:13,639
is also bad because it's the reverse in

00:04:11,840 --> 00:04:19,299
that case you you don't get what you

00:04:13,639 --> 00:04:22,690
want so this is all only marginally

00:04:19,299 --> 00:04:22,690
fixing the issue

00:04:24,490 --> 00:04:37,000
what could be a good way to do that to

00:04:33,349 --> 00:04:39,979
put the logic inside the logger yes and

00:04:37,000 --> 00:04:43,270
we can put the logic inside the logger

00:04:39,979 --> 00:04:51,319
and actually we can do it in a way that

00:04:43,270 --> 00:04:55,039
sorry it's not this one it's this one

00:04:51,319 --> 00:05:00,069
here I created what I call a lazy logger

00:04:55,039 --> 00:05:03,020
and this lazy logger actually gets not

00:05:00,069 --> 00:05:05,990
the log message itself but a wrapper

00:05:03,020 --> 00:05:08,530
around the message like in Java it's

00:05:05,990 --> 00:05:11,389
called a supplier which is like not a

00:05:08,530 --> 00:05:13,520
rapper a rapper function so when I call

00:05:11,389 --> 00:05:16,550
get I will get the result but so far

00:05:13,520 --> 00:05:22,789
it's lazy and in that case it's very

00:05:16,550 --> 00:05:25,880
easy for me to say ok and here it's also

00:05:22,789 --> 00:05:27,590
very fast not as fast as manual stuff

00:05:25,880 --> 00:05:32,139
because I need to create the object

00:05:27,590 --> 00:05:32,139
itself but it's it like nicely fast

00:05:38,460 --> 00:05:43,300
so one of the problem is it starts from

00:05:41,530 --> 00:05:45,460
the developer the developer must be

00:05:43,300 --> 00:05:47,500
aware that something is happening when

00:05:45,460 --> 00:05:49,060
he writes a lock statement and someone

00:05:47,500 --> 00:05:51,540
must provide him with the tools to

00:05:49,060 --> 00:05:54,940
handle that second problem is

00:05:51,540 --> 00:05:57,580
unfortunately log doesn't happen in like

00:05:54,940 --> 00:06:00,130
the virtual world we are bounced to the

00:05:57,580 --> 00:06:02,620
real world and so we must be aware of

00:06:00,130 --> 00:06:05,260
where we are logging in which physical

00:06:02,620 --> 00:06:07,450
drive we are logging it can be a hard

00:06:05,260 --> 00:06:10,360
drive it can be a SSD it can be a

00:06:07,450 --> 00:06:12,310
network file system and now we go to the

00:06:10,360 --> 00:06:16,180
other side of the chain which means that

00:06:12,310 --> 00:06:20,080
the administrator must know and must

00:06:16,180 --> 00:06:23,560
like fix the fact where where we log the

00:06:20,080 --> 00:06:25,990
stuff so it depending on on the physical

00:06:23,560 --> 00:06:28,120
device you must be aware that you will

00:06:25,990 --> 00:06:35,680
have different performances again no big

00:06:28,120 --> 00:06:37,810
magic is just stuff to take care of the

00:06:35,680 --> 00:06:40,060
writing process the the write log

00:06:37,810 --> 00:06:42,880
writing process is your planned stream

00:06:40,060 --> 00:06:45,669
you write the bytes you close the stream

00:06:42,880 --> 00:06:48,760
and actually opening the stream and

00:06:45,669 --> 00:06:51,040
closing the stream text a non-negligible

00:06:48,760 --> 00:06:55,270
time compared to writing to bite

00:06:51,040 --> 00:06:58,960
themselves so perhaps we could just open

00:06:55,270 --> 00:07:01,180
the stream writes multiple chunks of

00:06:58,960 --> 00:07:03,940
bytes and then close the stream and

00:07:01,180 --> 00:07:07,840
opening and closing would be just done

00:07:03,940 --> 00:07:10,870
once a that is possible in most

00:07:07,840 --> 00:07:13,150
frameworks because by default logging is

00:07:10,870 --> 00:07:15,760
synchronous but there is nothing

00:07:13,150 --> 00:07:18,840
preventing you from doing a synchronous

00:07:15,760 --> 00:07:22,060
logging this is exactly what I described

00:07:18,840 --> 00:07:24,790
however when you start having this a

00:07:22,060 --> 00:07:27,940
synchronous logging ideas then again

00:07:24,790 --> 00:07:30,190
you've got other issues so this is how

00:07:27,940 --> 00:07:33,070
you can do it with SLE 4G again in the

00:07:30,190 --> 00:07:37,390
Java world but I'm sure that in your own

00:07:33,070 --> 00:07:41,710
tech stack you've got the same using log

00:07:37,390 --> 00:07:45,130
back you've got configuration now first

00:07:41,710 --> 00:07:47,830
configuration is what's the size of the

00:07:45,130 --> 00:07:49,840
buffer of course because it's in

00:07:47,830 --> 00:07:50,850
synchrony oh so you must buffer the

00:07:49,840 --> 00:07:54,810
writes

00:07:50,850 --> 00:07:58,020
the second is sometimes you will get a

00:07:54,810 --> 00:08:00,780
lot of messages and some messages like

00:07:58,020 --> 00:08:02,970
error and info are much more important

00:08:00,780 --> 00:08:05,850
than other messages and when the queue

00:08:02,970 --> 00:08:08,340
starts being full perhaps it's better to

00:08:05,850 --> 00:08:12,500
discard those non very important

00:08:08,340 --> 00:08:15,900
messages than doing something else

00:08:12,500 --> 00:08:19,320
another configuration that you have is a

00:08:15,900 --> 00:08:22,110
is it better to really be very very fast

00:08:19,320 --> 00:08:24,600
or to drop messages is it better to have

00:08:22,110 --> 00:08:28,560
every info every piece of that available

00:08:24,600 --> 00:08:30,930
or to be slower and you must decide for

00:08:28,560 --> 00:08:34,880
yourself in your context but again it's

00:08:30,930 --> 00:08:38,099
a configuration that you must choose and

00:08:34,880 --> 00:08:41,520
of course the log message itself is not

00:08:38,099 --> 00:08:43,680
very important by itself what is

00:08:41,520 --> 00:08:45,510
important is the context of the log

00:08:43,680 --> 00:08:46,230
message so of course you've got the

00:08:45,510 --> 00:08:48,420
timestamp

00:08:46,230 --> 00:08:50,220
you've got the log level you've got to

00:08:48,420 --> 00:08:52,740
thread them the class name the file name

00:08:50,220 --> 00:08:55,380
whatever the metal name whatever there

00:08:52,740 --> 00:08:58,980
are a lot of important metadata that you

00:08:55,380 --> 00:09:02,040
might want to capture the thing is not

00:08:58,980 --> 00:09:05,480
all of them are free I mean most of them

00:09:02,040 --> 00:09:09,870
might be very expensive to compute again

00:09:05,480 --> 00:09:15,030
so it's a trade-off between I want this

00:09:09,870 --> 00:09:18,330
data and it slows me down some of them

00:09:15,030 --> 00:09:20,610
are very very expensive to compute so

00:09:18,330 --> 00:09:23,610
perhaps it's better to write them down

00:09:20,610 --> 00:09:25,860
in the log message but then you get the

00:09:23,610 --> 00:09:27,990
same problem as I mentioned before you

00:09:25,860 --> 00:09:29,550
might not have the right information so

00:09:27,990 --> 00:09:32,760
the line number you might decide to

00:09:29,550 --> 00:09:35,670
write it by hand but then if you if

00:09:32,760 --> 00:09:37,440
somebody adds like lines of code before

00:09:35,670 --> 00:09:43,860
your statement then you've gotten

00:09:37,440 --> 00:09:46,290
synchronised again and even if you have

00:09:43,860 --> 00:09:48,450
everything then it's not very

00:09:46,290 --> 00:09:51,270
insteresting by itself I mean how many

00:09:48,450 --> 00:09:57,360
of you go to a server and reads the log

00:09:51,270 --> 00:10:03,480
file anymore it it does

00:09:57,360 --> 00:10:06,480
thanks in general what you also do is at

00:10:03,480 --> 00:10:11,759
some point you like get everything into

00:10:06,480 --> 00:10:14,689
a centralized place do you do that more

00:10:11,759 --> 00:10:17,189
or less okay let's say more or less

00:10:14,689 --> 00:10:19,439
because you want to correlate the events

00:10:17,189 --> 00:10:22,079
that happen sometimes on the same

00:10:19,439 --> 00:10:25,709
machine between like different nodes in

00:10:22,079 --> 00:10:27,239
the cluster or stuff like that so you

00:10:25,709 --> 00:10:28,860
might know that a elasticsearch you

00:10:27,239 --> 00:10:31,529
might know but Splunk about Greylock

00:10:28,860 --> 00:10:33,899
they are different like frameworks and

00:10:31,529 --> 00:10:35,339
engines and tech stacks to do the ads I

00:10:33,899 --> 00:10:37,439
tend to be more familiar with

00:10:35,339 --> 00:10:41,269
elasticsearch so that will be what I

00:10:37,439 --> 00:10:47,069
will be using in the rest of this talk

00:10:41,269 --> 00:10:49,860
anyway in general you use additional

00:10:47,069 --> 00:10:51,269
metadata because now it becomes even

00:10:49,860 --> 00:10:53,009
more complex because you have like

00:10:51,269 --> 00:10:55,889
different log files so you will need to

00:10:53,009 --> 00:10:59,749
know which log file is a source and

00:10:55,889 --> 00:11:02,669
perhaps you have like different IPS or

00:10:59,749 --> 00:11:04,980
directly you use the AWS name you might

00:11:02,669 --> 00:11:06,569
and probably should have different

00:11:04,980 --> 00:11:09,239
environment so you must know that this

00:11:06,569 --> 00:11:12,269
log file is like production this log

00:11:09,239 --> 00:11:13,769
file is staging and again you might have

00:11:12,269 --> 00:11:16,470
different clouds own if you are using

00:11:13,769 --> 00:11:21,480
the cloud well this is additional

00:11:16,470 --> 00:11:23,850
metadata that you probably need and if

00:11:21,480 --> 00:11:26,069
you just lock that it's not very

00:11:23,850 --> 00:11:28,220
interesting and it's just like if you

00:11:26,069 --> 00:11:32,100
are doing backups but never try restore

00:11:28,220 --> 00:11:34,499
and you know all those logs you want to

00:11:32,100 --> 00:11:40,829
search I mean that's the point of the

00:11:34,499 --> 00:11:43,860
logs and now comes the problem if you

00:11:40,829 --> 00:11:46,139
want to be very very fast then you can

00:11:43,860 --> 00:11:48,929
ingest your logs put everything into

00:11:46,139 --> 00:11:53,279
elasticsearch and every time you search

00:11:48,929 --> 00:11:56,069
it's going to take a long time or you

00:11:53,279 --> 00:11:58,019
can decide that every time you send a

00:11:56,069 --> 00:12:01,199
log message this log message is

00:11:58,019 --> 00:12:04,100
structured so you must put the right

00:12:01,199 --> 00:12:07,709
information into the right bucket and

00:12:04,100 --> 00:12:11,130
everything will be fine and of course it

00:12:07,709 --> 00:12:14,300
takes time to analyze too porous

00:12:11,130 --> 00:12:17,550
and to put them into the right place so

00:12:14,300 --> 00:12:19,620
if we are using the elastic stack you

00:12:17,550 --> 00:12:25,740
can have file bit that scrap the log

00:12:19,620 --> 00:12:29,310
files and send it to log stash to parse

00:12:25,740 --> 00:12:32,370
the stuff that in turn will send it to

00:12:29,310 --> 00:12:33,990
elasticsearch and here you can see that

00:12:32,370 --> 00:12:37,530
I've been an architect because I can

00:12:33,990 --> 00:12:41,280
draw nice UML diagrams so they are like

00:12:37,530 --> 00:12:43,470
two phases creation so the application

00:12:41,280 --> 00:12:46,230
create the log file and at some point

00:12:43,470 --> 00:12:48,690
file bits text log file read the log

00:12:46,230 --> 00:12:50,940
file and send the log to log stash and

00:12:48,690 --> 00:12:55,530
log stash transform the log into JSON

00:12:50,940 --> 00:12:57,090
and push J'son to elasticsearch and I

00:12:55,530 --> 00:13:00,120
don't know if you have been using log

00:12:57,090 --> 00:13:02,810
stash and the grog patterns it's not

00:13:00,120 --> 00:13:05,760
super fun to do first and depending on

00:13:02,810 --> 00:13:08,370
the log file that you will be parsing it

00:13:05,760 --> 00:13:11,370
can be very complex and again complexity

00:13:08,370 --> 00:13:13,410
means that it takes time also I think

00:13:11,370 --> 00:13:16,140
that log stash is written in Ruby right

00:13:13,410 --> 00:13:21,390
and let's say it's perhaps not the

00:13:16,140 --> 00:13:25,980
fastest language ever so I have this

00:13:21,390 --> 00:13:29,670
like super nice log message that gets

00:13:25,980 --> 00:13:31,800
scrapped and in the end that is how I

00:13:29,670 --> 00:13:37,410
want to interpret it to send it to

00:13:31,800 --> 00:13:39,660
elasticsearch so that at this point I

00:13:37,410 --> 00:13:43,440
can say okay find me everything that

00:13:39,660 --> 00:13:49,440
happens on the info level and during

00:13:43,440 --> 00:13:50,190
this class but if we think about it for

00:13:49,440 --> 00:13:56,340
a second

00:13:50,190 --> 00:13:59,280
actually that's not necessary think

00:13:56,340 --> 00:14:03,390
about it we are creating like a string

00:13:59,280 --> 00:14:07,910
and then we pour sit to create Jason why

00:14:03,390 --> 00:14:07,910
don't we create jason just directly

00:14:16,459 --> 00:14:22,620
so here I'm always my my stupid example

00:14:20,269 --> 00:14:26,009
for the developer it doesn't change

00:14:22,620 --> 00:14:31,500
anything it's just that now when I run

00:14:26,009 --> 00:14:33,690
it I already create J'son the important

00:14:31,500 --> 00:14:35,819
part is it must be on the same line so

00:14:33,690 --> 00:14:38,040
again you don't need to say to a file

00:14:35,819 --> 00:14:40,829
bit okay you must compute the fact that

00:14:38,040 --> 00:14:42,509
two lines two consecutive lines might or

00:14:40,829 --> 00:14:49,050
might not be part of the same log

00:14:42,509 --> 00:14:54,360
message and if you are using SL f4j and

00:14:49,050 --> 00:14:56,490
log back it's pretty stupid I mean it's

00:14:54,360 --> 00:15:09,180
just the pattern that it needs to be

00:14:56,490 --> 00:15:11,610
like this it's not no black magic so

00:15:09,180 --> 00:15:13,709
this is what I what I get again it's

00:15:11,610 --> 00:15:15,350
from different lines but you shouldn't

00:15:13,709 --> 00:15:20,610
do it

00:15:15,350 --> 00:15:23,690
and your architectures is simpler your

00:15:20,610 --> 00:15:28,649
performances will be better it's

00:15:23,690 --> 00:15:32,190
everybody wins that also what you can

00:15:28,649 --> 00:15:35,010
think about is I've talked about like

00:15:32,190 --> 00:15:38,519
writing on the disk and then scrapping

00:15:35,010 --> 00:15:41,069
from the disk and perhaps in some cases

00:15:38,519 --> 00:15:44,190
you might think that it's not very good

00:15:41,069 --> 00:15:47,399
ID so on one side at least your

00:15:44,190 --> 00:15:50,310
persistence but on the other side it

00:15:47,399 --> 00:15:52,920
takes more time what if we could if you

00:15:50,310 --> 00:15:54,930
could just send the event logs to the

00:15:52,920 --> 00:15:58,800
place that you want so you could

00:15:54,930 --> 00:16:00,630
directly create an appender to send the

00:15:58,800 --> 00:16:03,480
logs to elasticsearch in the first place

00:16:00,630 --> 00:16:06,269
nothing prevents you from doing that in

00:16:03,480 --> 00:16:09,750
that case however the problem becomes

00:16:06,269 --> 00:16:12,389
that well everything will be in memory

00:16:09,750 --> 00:16:16,079
and if something happens then you will

00:16:12,389 --> 00:16:18,810
lose data also I mentioned a lot of time

00:16:16,079 --> 00:16:23,460
that there is like sweet spots between

00:16:18,810 --> 00:16:28,230
light consistency or persistence and and

00:16:23,460 --> 00:16:30,330
being like fast for that I encourage you

00:16:28,230 --> 00:16:33,270
to consider the fact that you might do

00:16:30,330 --> 00:16:35,580
like hot reloading of configuration like

00:16:33,270 --> 00:16:37,649
line numbers are not very important and

00:16:35,580 --> 00:16:39,779
take a lot of time to compute sometimes

00:16:37,649 --> 00:16:41,850
however they are become very important

00:16:39,779 --> 00:16:43,980
for whatever reason so you might have

00:16:41,850 --> 00:16:45,360
like hot reloading for saying a I have a

00:16:43,980 --> 00:16:48,450
problem on this server for whatever

00:16:45,360 --> 00:16:49,980
reason I need to get the line number I

00:16:48,450 --> 00:16:51,870
don't want to switch off my GBM and

00:16:49,980 --> 00:16:53,760
restart it again so author landing

00:16:51,870 --> 00:16:56,130
configuration might be handy because you

00:16:53,760 --> 00:16:58,380
change just change the configuration on

00:16:56,130 --> 00:17:03,149
the server and then you've got the line

00:16:58,380 --> 00:17:06,270
numbers finally how we do it at XO scale

00:17:03,149 --> 00:17:11,069
because that was best picture I I showed

00:17:06,270 --> 00:17:13,319
you and this is meant to like G mode the

00:17:11,069 --> 00:17:14,640
fact that whatever is best of read in

00:17:13,319 --> 00:17:18,120
your context might be completely

00:17:14,640 --> 00:17:20,300
different so we are using syslog-ng

00:17:18,120 --> 00:17:23,280
instead of five bits because for

00:17:20,300 --> 00:17:24,990
whatever reason when we started it was

00:17:23,280 --> 00:17:27,839
not available five bit was not available

00:17:24,990 --> 00:17:30,179
and people at exhaustion are more like

00:17:27,839 --> 00:17:32,880
sysadmin and they are very familiar with

00:17:30,179 --> 00:17:38,490
syslog-ng and also we have Kafka in

00:17:32,880 --> 00:17:42,240
between this is not super fast this is

00:17:38,490 --> 00:17:45,240
not what we want however in our cases as

00:17:42,240 --> 00:17:47,850
I said we are a cloud provider and we

00:17:45,240 --> 00:17:50,540
are using logs to Bill our customer so

00:17:47,850 --> 00:17:53,250
this is not only logs to the events and

00:17:50,540 --> 00:17:58,140
we do a lot of the computation of the

00:17:53,250 --> 00:17:59,850
events of the billing in Kafka so Kafka

00:17:58,140 --> 00:18:03,090
is a place to go where we do a lot of

00:17:59,850 --> 00:18:05,130
life business rules and so it's better

00:18:03,090 --> 00:18:07,410
for us to send everything into Kafka and

00:18:05,130 --> 00:18:11,130
only then to push it to elasticsearch

00:18:07,410 --> 00:18:12,600
when when we need it so depending on

00:18:11,130 --> 00:18:17,700
your context what I showed you might be

00:18:12,600 --> 00:18:20,490
very different so summary it involves

00:18:17,700 --> 00:18:22,320
everyone so the first is developers but

00:18:20,490 --> 00:18:25,050
cent not the result of the computation

00:18:22,320 --> 00:18:26,940
but the computation itself to the log so

00:18:25,050 --> 00:18:29,550
that you don't compute something that is

00:18:26,940 --> 00:18:32,880
not necessary you should consider the

00:18:29,550 --> 00:18:35,280
physical side file system you should go

00:18:32,880 --> 00:18:37,610
as synchronous if speed is more

00:18:35,280 --> 00:18:40,279
important than reliability of

00:18:37,610 --> 00:18:41,659
you shouldn't use expensive metadata but

00:18:40,279 --> 00:18:44,240
if you do then you should consider

00:18:41,659 --> 00:18:48,259
having a hot reloading so that when you

00:18:44,240 --> 00:18:50,600
need it you have them of course just

00:18:48,259 --> 00:18:53,240
like putting stuff into elasticsearch or

00:18:50,600 --> 00:18:55,669
any data storage is not important the

00:18:53,240 --> 00:18:57,740
real stuff that you want is to search so

00:18:55,669 --> 00:18:59,539
you should consider perhaps not the fact

00:18:57,740 --> 00:19:01,190
that the fact that the logs are super

00:18:59,539 --> 00:19:03,230
fast but the fact also that the search

00:19:01,190 --> 00:19:06,799
in the log is super fast so of course

00:19:03,230 --> 00:19:09,619
use schema on writes and then don't care

00:19:06,799 --> 00:19:13,039
about poor Singh and growing and having

00:19:09,619 --> 00:19:17,059
a big growing pattern just send JSON

00:19:13,039 --> 00:19:19,220
directly if you want to have like

00:19:17,059 --> 00:19:21,259
performant logs everybody should be

00:19:19,220 --> 00:19:24,470
involved it should go from the developer

00:19:21,259 --> 00:19:26,960
to the cset min to the architect and of

00:19:24,470 --> 00:19:28,970
course it's all a matter of contexts and

00:19:26,960 --> 00:19:31,940
I've been a consultant the answer is

00:19:28,970 --> 00:19:34,129
always it depends so don't take

00:19:31,940 --> 00:19:36,529
everything that I told you here as with

00:19:34,129 --> 00:19:40,009
a pinch of salt because in your context

00:19:36,529 --> 00:19:42,049
might be completely different answer so

00:19:40,009 --> 00:19:44,419
yeah you can with my blog you can read

00:19:42,049 --> 00:19:46,249
our blog the blog of my company and you

00:19:44,419 --> 00:19:48,470
can follow me on Twitter and perhaps now

00:19:46,249 --> 00:19:50,600
I have like one minute for questions one

00:19:48,470 --> 00:19:53,420
minute for questions like one question

00:19:50,600 --> 00:19:58,059
thank you for the nice talk

00:19:53,420 --> 00:19:58,059

YouTube URL: https://www.youtube.com/watch?v=U71Ju3y40fE


