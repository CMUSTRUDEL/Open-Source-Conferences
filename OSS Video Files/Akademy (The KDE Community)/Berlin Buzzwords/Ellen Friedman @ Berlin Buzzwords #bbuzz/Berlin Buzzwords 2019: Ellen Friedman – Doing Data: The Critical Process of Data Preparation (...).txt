Title: Berlin Buzzwords 2019: Ellen Friedman – Doing Data: The Critical Process of Data Preparation (...)
Publication date: 2020-02-12
Playlist: Ellen Friedman @ Berlin Buzzwords #bbuzz
Description: 
	Full title: Doing Data: The Critical Process of Data Preparation for Machine Learning and More

Machine learning is rapidly being democratized and is becoming something that developers at large can use effectively. To do so, however, developers need to add appropriate data skills to their coding skills. It’s not the advanced algorithms and modelling they must learn -- that may be left to the data scientists. Instead, the most important part of a machine learning system turns out to be the data preparation itself and the importance of the data is often underestimated, especially by people new to these approaches. 

Data preparation is essential to learn, and clever techniques for data exploration, feature extraction and data versioning can be applied across a wide variety of machine learning projects. In fact, in some cases, data exploration and feature extraction actually reveal solutions that can actually make the machine learning part of a machine learning system optional. Honing data preparation skills is useful for both experienced data scientists and for newcomers.

This presentation will cover practical techniques for data engineering with specific examples. We will focus on three areas of data preparation: data exploration, feature extraction and data management for machine learning systems, and we will give examples from real world stories of where these approaches are effective. The approaches we examine are powerful yet simple enough for people new to machine learning to easily understand, and they may surprise more experienced data scientists as well. We include the rationale behind the approaches along with specific implementation to make it easier for the audience to apply these techniques to their own situations.

Read more:
https://2019.berlinbuzzwords.de/19/session/doing-data-critical-process-data-preparation-machine-learning-and-more

About Ellen Friedman:
https://2019.berlinbuzzwords.de/users/ellen-friedman-0

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:07,540 --> 00:00:11,980
as he said my name is Ellen treatment

00:00:09,490 --> 00:00:13,900
I'm delighted to be here in Berlin such

00:00:11,980 --> 00:00:15,940
a wonderful city a little bit toasty

00:00:13,900 --> 00:00:19,390
it's so wonderful and to be here for

00:00:15,940 --> 00:00:21,880
this 10th buzzwords conference I've been

00:00:19,390 --> 00:00:22,870
here every year I think except one since

00:00:21,880 --> 00:00:25,720
00:00:22,870 --> 00:00:28,270
thanks to Isabel who got me inspired for

00:00:25,720 --> 00:00:30,610
this conference and I met just some

00:00:28,270 --> 00:00:32,559
amazing people that have led to a lot of

00:00:30,610 --> 00:00:35,230
other interesting projects and

00:00:32,559 --> 00:00:37,210
conversations in my life and I'm trying

00:00:35,230 --> 00:00:38,559
to recognize some of those other people

00:00:37,210 --> 00:00:42,249
in the audience it's actually very hard

00:00:38,559 --> 00:00:44,769
to see you with the lights I am a

00:00:42,249 --> 00:00:47,589
committer for two apache projects Apache

00:00:44,769 --> 00:00:49,690
drill and Apache mahute and sort of

00:00:47,589 --> 00:00:52,600
fitting the conversations that you heard

00:00:49,690 --> 00:00:54,639
yesterday and and this morning I'm

00:00:52,600 --> 00:00:56,920
actually a committer who doesn't write

00:00:54,639 --> 00:00:59,049
code I help build community and raise

00:00:56,920 --> 00:01:01,960
awareness for those projects there are

00:00:59,049 --> 00:01:03,670
many roles for people in our patchy but

00:01:01,960 --> 00:01:06,250
in addition to the very important one of

00:01:03,670 --> 00:01:08,950
writing code and I'm an example of

00:01:06,250 --> 00:01:10,450
somebody who's in enjoyed being able to

00:01:08,950 --> 00:01:12,430
contribute to the projects and those

00:01:10,450 --> 00:01:14,979
other roles and I've also written a

00:01:12,430 --> 00:01:17,530
number of books on topics related to

00:01:14,979 --> 00:01:20,649
this short books mostly for O'Reilly a

00:01:17,530 --> 00:01:24,850
longer book for Manning calm Akutan

00:01:20,649 --> 00:01:26,530
action no slides yet ok I'm going to

00:01:24,850 --> 00:01:28,090
start off and just say some of the

00:01:26,530 --> 00:01:30,189
things I want to talk to you about today

00:01:28,090 --> 00:01:32,229
are things that are really powerful

00:01:30,189 --> 00:01:34,539
techniques to make your machine learning

00:01:32,229 --> 00:01:36,219
projects work every different project

00:01:34,539 --> 00:01:38,740
obviously has different needs but these

00:01:36,219 --> 00:01:40,359
are some that have very broad in general

00:01:38,740 --> 00:01:42,159
impact and there's some of the things

00:01:40,359 --> 00:01:44,829
that can have the biggest impact on your

00:01:42,159 --> 00:01:47,829
project now sometimes when you hear

00:01:44,829 --> 00:01:52,359
about something like this you want to

00:01:47,829 --> 00:01:54,850
hear the exciting latest sexy complex

00:01:52,359 --> 00:01:57,490
algorithm and a huge new technique or a

00:01:54,850 --> 00:02:00,130
very fancy tool and those things are all

00:01:57,490 --> 00:02:02,740
very good but in fact there are some

00:02:00,130 --> 00:02:05,560
very basic skills really fundamental

00:02:02,740 --> 00:02:07,929
skills that have in some cases the

00:02:05,560 --> 00:02:10,210
biggest impact on weather projects are a

00:02:07,929 --> 00:02:12,400
success these are not always the things

00:02:10,210 --> 00:02:14,440
that people most want to hear but in

00:02:12,400 --> 00:02:16,690
fact they're often overlooked say in

00:02:14,440 --> 00:02:18,520
courses and and there are things that

00:02:16,690 --> 00:02:19,840
people learn kind of through experience

00:02:18,520 --> 00:02:23,410
and those are some of the

00:02:19,840 --> 00:02:25,680
I want to share with you today know if

00:02:23,410 --> 00:02:28,629
we had the slides you would see a

00:02:25,680 --> 00:02:31,780
picture from a laboratory of people

00:02:28,629 --> 00:02:33,550
reaching down into a very cold deep

00:02:31,780 --> 00:02:35,980
freezer with their hands and gloves

00:02:33,550 --> 00:02:37,690
pulling out blood samples I wasn't going

00:02:35,980 --> 00:02:40,690
to start with that as a kind of unusual

00:02:37,690 --> 00:02:44,379
example of how people dealt with data

00:02:40,690 --> 00:02:46,360
with the value that can be in data how

00:02:44,379 --> 00:02:48,400
you have to store and protect data for

00:02:46,360 --> 00:02:51,010
long periods of time and the importance

00:02:48,400 --> 00:02:52,780
of documenting what you've done so that

00:02:51,010 --> 00:02:55,000
you can go back later and deal with it

00:02:52,780 --> 00:02:56,530
so this is a real-world example quite

00:02:55,000 --> 00:02:58,840
different than probably what most of you

00:02:56,530 --> 00:03:01,090
work on turns out there's a very large

00:02:58,840 --> 00:03:02,440
medical laboratory in Canada learned

00:03:01,090 --> 00:03:04,510
this recently from people at the

00:03:02,440 --> 00:03:06,819
University of Calgary a very large

00:03:04,510 --> 00:03:10,329
medical laboratory and they froze blood

00:03:06,819 --> 00:03:13,420
samples for years I think something like

00:03:10,329 --> 00:03:16,209
30 years they took blood samples from

00:03:13,420 --> 00:03:18,250
patients they did whatever tests were

00:03:16,209 --> 00:03:20,260
available at the time specifically for

00:03:18,250 --> 00:03:23,130
the analysis that they were doing but

00:03:20,260 --> 00:03:25,720
they recognized that those blood samples

00:03:23,130 --> 00:03:27,370
combined with a patient history with

00:03:25,720 --> 00:03:31,090
some knowledge of the outcome of that

00:03:27,370 --> 00:03:33,220
patient have value that go beyond the

00:03:31,090 --> 00:03:35,470
project the the analysis that they were

00:03:33,220 --> 00:03:37,209
doing at the time but they didn't have

00:03:35,470 --> 00:03:39,519
the techniques to be able to release

00:03:37,209 --> 00:03:41,530
that value from the blood the blood

00:03:39,519 --> 00:03:43,329
basically contained the data

00:03:41,530 --> 00:03:44,889
it wasn't the blood molecules itself

00:03:43,329 --> 00:03:48,400
they were disease markers that were in

00:03:44,889 --> 00:03:50,470
blood and so they froze them preserve

00:03:48,400 --> 00:03:52,060
them very little document it so that

00:03:50,470 --> 00:03:55,180
somebody years later could go back to

00:03:52,060 --> 00:03:57,340
that sample use it find the data in the

00:03:55,180 --> 00:03:59,260
sample and be able to understand what

00:03:57,340 --> 00:04:01,750
happened and it turns out this actually

00:03:59,260 --> 00:04:03,849
did happen years later with modern

00:04:01,750 --> 00:04:05,380
genetic techniques they were got be able

00:04:03,849 --> 00:04:07,359
to go out back and look for disease

00:04:05,380 --> 00:04:10,269
markers match those up with outcomes

00:04:07,359 --> 00:04:12,160
it's just a wealth of information the

00:04:10,269 --> 00:04:14,560
reason I wanted to share that kind of

00:04:12,160 --> 00:04:16,690
unusual example with you is it's not

00:04:14,560 --> 00:04:19,120
unlike what all of you face as you work

00:04:16,690 --> 00:04:20,950
with data and it's something it's you

00:04:19,120 --> 00:04:22,690
have a lot of what you have to think

00:04:20,950 --> 00:04:25,060
about to get your current project done

00:04:22,690 --> 00:04:28,150
but if you think about the fact that

00:04:25,060 --> 00:04:30,729
data contains knowledge basically

00:04:28,150 --> 00:04:33,400
information that you or somebody else

00:04:30,729 --> 00:04:35,710
may want in the future in some cases

00:04:33,400 --> 00:04:37,060
very different projects maybe different

00:04:35,710 --> 00:04:39,130
techniques developing you want to be

00:04:37,060 --> 00:04:41,740
able to go back to that data so the

00:04:39,130 --> 00:04:44,320
ability to store essentially raw data

00:04:41,740 --> 00:04:46,419
raw data that retains a lot of its

00:04:44,320 --> 00:04:49,360
features before you've process it down

00:04:46,419 --> 00:04:51,669
to your current project to treat that

00:04:49,360 --> 00:04:54,100
data almost with the status of having

00:04:51,669 --> 00:04:56,229
data and production even longer for code

00:04:54,100 --> 00:04:58,240
is written it's kind of an analogy to

00:04:56,229 --> 00:05:00,190
what they did with the blood samples but

00:04:58,240 --> 00:05:02,199
also keep in mind even having the

00:05:00,190 --> 00:05:04,270
foresight to save those blood samples

00:05:02,199 --> 00:05:06,190
for so long and be able to go back to

00:05:04,270 --> 00:05:08,590
them with modern techniques if they

00:05:06,190 --> 00:05:10,180
hadn't documented what each sample

00:05:08,590 --> 00:05:11,650
represented what the outcome of the

00:05:10,180 --> 00:05:14,050
patient was and so forth

00:05:11,650 --> 00:05:15,880
very very well it would have had very

00:05:14,050 --> 00:05:18,430
little value because they wouldn't be

00:05:15,880 --> 00:05:20,560
able to understand in context what that

00:05:18,430 --> 00:05:22,210
data means and the same thing applies to

00:05:20,560 --> 00:05:24,400
whatever you're doing if you're building

00:05:22,210 --> 00:05:27,099
a recommendation system to sell things

00:05:24,400 --> 00:05:29,430
some sort of an analysis system to do

00:05:27,099 --> 00:05:32,289
predictive maintenance an IOT data

00:05:29,430 --> 00:05:34,479
security fraud analysis whatever it is

00:05:32,289 --> 00:05:36,460
deep learning whatever it is that you're

00:05:34,479 --> 00:05:38,979
building machine learning for it's

00:05:36,460 --> 00:05:41,169
really important to preserve data

00:05:38,979 --> 00:05:43,539
protect it well even poor that the code

00:05:41,169 --> 00:05:45,849
is finished document in such a way that

00:05:43,539 --> 00:05:47,949
you can go back to it that somebody else

00:05:45,849 --> 00:05:49,479
can go back to it and there are other

00:05:47,949 --> 00:05:52,060
issues I want to talk about but that's

00:05:49,479 --> 00:05:55,060
probably the single single biggest one

00:05:52,060 --> 00:05:58,300
that people overlook until it's too late

00:05:55,060 --> 00:06:00,460
later when you say oh we could have

00:05:58,300 --> 00:06:02,229
looked at this feature but we've now

00:06:00,460 --> 00:06:04,090
thrown that away or it's been processed

00:06:02,229 --> 00:06:07,990
away it's too late to do anything about

00:06:04,090 --> 00:06:09,760
that now a lot of the stories that I

00:06:07,990 --> 00:06:11,710
want to tell you today and these

00:06:09,760 --> 00:06:14,110
beautiful slides that I've developed for

00:06:11,710 --> 00:06:15,880
you today are based not just on my own

00:06:14,110 --> 00:06:17,800
experience but on stories I've heard

00:06:15,880 --> 00:06:18,940
over the years from a number of

00:06:17,800 --> 00:06:20,979
different data scientists and

00:06:18,940 --> 00:06:24,130
particularly I have a lot of input on

00:06:20,979 --> 00:06:26,889
this talk for two data scientists Joe

00:06:24,130 --> 00:06:29,919
blue and Ted Dunning both of whom are

00:06:26,889 --> 00:06:32,710
data scientists and experts at map our

00:06:29,919 --> 00:06:34,449
technologies and both of whom have

00:06:32,710 --> 00:06:36,820
worked together in previous companies as

00:06:34,449 --> 00:06:38,889
well between them collectively I think

00:06:36,820 --> 00:06:41,349
they have something like about 35 years

00:06:38,889 --> 00:06:43,450
of experience building various kinds of

00:06:41,349 --> 00:06:45,070
machine learning systems and the good

00:06:43,450 --> 00:06:47,200
thing is that you can learn from their

00:06:45,070 --> 00:06:50,020
experience you don't have to spend

00:06:47,200 --> 00:06:52,150
five or thirty five years redoing some

00:06:50,020 --> 00:06:54,130
of the same mistakes that they did in

00:06:52,150 --> 00:06:55,480
order to learn what they now know so

00:06:54,130 --> 00:06:57,700
there's a lot of practical real-world

00:06:55,480 --> 00:07:01,450
experience that applies to things as

00:06:57,700 --> 00:07:02,980
well so a starting point for this is to

00:07:01,450 --> 00:07:07,330
consider has anybody here actually

00:07:02,980 --> 00:07:09,340
participated in a cattle contest a few

00:07:07,330 --> 00:07:13,630
of you how many people here have worked

00:07:09,340 --> 00:07:14,860
with machine learning before okay much

00:07:13,630 --> 00:07:20,700
bigger part of the audience and I

00:07:14,860 --> 00:07:27,570
expected sure I could do my presentation

00:07:20,700 --> 00:07:27,570
on a right okay so is this

00:07:33,529 --> 00:07:42,039
I haven't unstick it's down there do you

00:07:37,909 --> 00:07:44,859
want yeah just hand me my purse and wow

00:07:42,039 --> 00:07:46,759
I'm not sure these slides were worth it

00:07:44,859 --> 00:07:48,649
we're going to go through the slides

00:07:46,759 --> 00:08:03,379
really fast where you get them up and

00:07:48,649 --> 00:08:05,539
going so I sat at breakfast with Larsen

00:08:03,379 --> 00:08:07,339
we talked over some of the horror

00:08:05,539 --> 00:08:09,499
stories so things that can happen right

00:08:07,339 --> 00:08:11,209
at the beginning of a presentation when

00:08:09,499 --> 00:08:15,229
something goes wrong with the slides I

00:08:11,209 --> 00:08:17,599
think that was a bad idea I'm just

00:08:15,229 --> 00:08:22,869
saying for future reference don't do

00:08:17,599 --> 00:08:24,619
that that's what don't do that okay

00:08:22,869 --> 00:08:28,009
where was I

00:08:24,619 --> 00:08:30,439
yes Kago contest those are terrific

00:08:28,009 --> 00:08:32,959
contest it gives people a great

00:08:30,439 --> 00:08:35,209
incentive to compete to learn about new

00:08:32,959 --> 00:08:37,879
algorithms especially to tune their own

00:08:35,209 --> 00:08:39,680
skills in terms of tuning algorithms but

00:08:37,879 --> 00:08:41,689
they're quite different than the real

00:08:39,680 --> 00:08:43,370
world for one thing you're usually given

00:08:41,689 --> 00:08:45,350
the question as opposed to figuring it

00:08:43,370 --> 00:08:47,959
out yourself you're given training data

00:08:45,350 --> 00:08:49,910
you may have to decide which features to

00:08:47,959 --> 00:08:52,759
use to extract from that training data

00:08:49,910 --> 00:08:55,430
but the training data has been cleaned

00:08:52,759 --> 00:08:57,680
up focused prepared to be appropriate as

00:08:55,430 --> 00:08:59,990
training data in most cases and the real

00:08:57,680 --> 00:09:01,550
world is not quite so kind to you so

00:08:59,990 --> 00:09:04,069
basically what you're having to do in

00:09:01,550 --> 00:09:06,319
real-world projects is to prepare your

00:09:04,069 --> 00:09:09,740
own chemical contest for yourself and

00:09:06,319 --> 00:09:12,559
that is a whole lot of work now again

00:09:09,740 --> 00:09:14,029
when we get the slides up I'll show you

00:09:12,559 --> 00:09:15,860
an image it actually came out of the

00:09:14,029 --> 00:09:18,970
Google paper making the point that

00:09:15,860 --> 00:09:22,459
there's a lot of technical debt are we

00:09:18,970 --> 00:09:24,980
not yet okay a lot of technical debt and

00:09:22,459 --> 00:09:27,079
doing machine learning because it isn't

00:09:24,980 --> 00:09:28,670
just the model and the learning process

00:09:27,079 --> 00:09:31,279
itself it's this massive amount of

00:09:28,670 --> 00:09:33,139
logistics around it how you handle model

00:09:31,279 --> 00:09:37,129
deployment how you handle data

00:09:33,139 --> 00:09:41,360
preparation and ooh this is so exciting

00:09:37,129 --> 00:09:43,339
hello my name is Ellen let's see if I

00:09:41,360 --> 00:09:44,990
can get the glitches this is my contact

00:09:43,339 --> 00:09:47,250
information I'll repeat it at the end

00:09:44,990 --> 00:09:48,870
when people tell you that

00:09:47,250 --> 00:09:50,550
the basic things that can make a big

00:09:48,870 --> 00:09:51,899
difference it's kind of like you know I

00:09:50,550 --> 00:09:54,269
need to lose weight I want to be

00:09:51,899 --> 00:09:56,790
healthier I want to find some fancy diet

00:09:54,269 --> 00:09:59,279
or fancy technique and sometimes the

00:09:56,790 --> 00:10:01,709
right advice is I should just try eating

00:09:59,279 --> 00:10:04,589
less and exercising not always what you

00:10:01,709 --> 00:10:07,740
want to hear and in fact those things

00:10:04,589 --> 00:10:09,540
can be very very powerful but it doesn't

00:10:07,740 --> 00:10:12,540
mean that they're easy to do and I have

00:10:09,540 --> 00:10:14,579
to say with regard to eating less there

00:10:12,540 --> 00:10:16,529
are some real barriers to that and some

00:10:14,579 --> 00:10:17,579
of those barriers are found right here

00:10:16,529 --> 00:10:20,069
in Berlin

00:10:17,579 --> 00:10:23,699
okay so I'm doing my best to get past

00:10:20,069 --> 00:10:25,740
that barrier but back to machine

00:10:23,699 --> 00:10:28,310
learning what makes it work well a big

00:10:25,740 --> 00:10:32,910
part of what makes it learn work or lurk

00:10:28,310 --> 00:10:34,560
work is the data and I just want to

00:10:32,910 --> 00:10:36,060
remind people I thought there might be

00:10:34,560 --> 00:10:37,800
some real beginners in the audience and

00:10:36,060 --> 00:10:39,089
in case there are but when you're

00:10:37,800 --> 00:10:41,670
talking to somebody even if you're

00:10:39,089 --> 00:10:45,089
experienced help them understand that

00:10:41,670 --> 00:10:47,490
the data is a key part of how you build

00:10:45,089 --> 00:10:49,860
a model the data is actually part of

00:10:47,490 --> 00:10:52,410
what builds the model and this isn't a

00:10:49,860 --> 00:10:54,269
single process you don't just write it

00:10:52,410 --> 00:10:56,459
run and done it's something you're going

00:10:54,269 --> 00:10:59,100
to do over again evaluate tweak and go

00:10:56,459 --> 00:11:01,290
back through you're often developing the

00:10:59,100 --> 00:11:03,389
training data holding out some data for

00:11:01,290 --> 00:11:05,339
testing going back through that cycle

00:11:03,389 --> 00:11:09,809
more than one time well we're going to

00:11:05,339 --> 00:11:11,339
talk about today in the past as I said

00:11:09,809 --> 00:11:13,079
the machine learning bit is that little

00:11:11,339 --> 00:11:15,149
red bed in the middle that's the actual

00:11:13,079 --> 00:11:17,610
models their learning process and it's a

00:11:15,149 --> 00:11:20,250
really small part of this huge process

00:11:17,610 --> 00:11:21,899
is excellent paper about technical debt

00:11:20,250 --> 00:11:25,589
machine learning systems that came out

00:11:21,899 --> 00:11:27,660
from Google some years ago but in past

00:11:25,589 --> 00:11:29,399
presentations I've talked more about the

00:11:27,660 --> 00:11:32,009
things on the right how do you handle

00:11:29,399 --> 00:11:34,470
the the model deployment the model

00:11:32,009 --> 00:11:36,240
evaluation and so forth and today I want

00:11:34,470 --> 00:11:39,120
to focus more on the things on the left

00:11:36,240 --> 00:11:41,759
that focus on data itself data

00:11:39,120 --> 00:11:44,040
collection data verification feature

00:11:41,759 --> 00:11:47,100
extraction especially that's a big part

00:11:44,040 --> 00:11:49,259
of this process so they're really three

00:11:47,100 --> 00:11:50,670
areas related to data that I want to

00:11:49,259 --> 00:11:52,439
talk about these aren't the only things

00:11:50,670 --> 00:11:54,240
you need to do but there's some that

00:11:52,439 --> 00:11:55,740
have a huge impact and they're some that

00:11:54,240 --> 00:11:59,790
sometimes they're kind of glossed over

00:11:55,740 --> 00:12:00,720
especially in courses one is what is the

00:11:59,790 --> 00:12:02,819
data you're working

00:12:00,720 --> 00:12:04,290
with and is it really what you think it

00:12:02,819 --> 00:12:06,360
is or is it really what somebody else

00:12:04,290 --> 00:12:09,600
told you it is you really have to verify

00:12:06,360 --> 00:12:11,550
it do you know what features you want to

00:12:09,600 --> 00:12:13,560
build and once you decide what features

00:12:11,550 --> 00:12:16,019
you want to build how are you going to

00:12:13,560 --> 00:12:18,089
go about building them and the last one

00:12:16,019 --> 00:12:20,579
ooh and apparently moving to another

00:12:18,089 --> 00:12:22,949
system kind of did some interesting

00:12:20,579 --> 00:12:25,379
things to the slides but the last one is

00:12:22,949 --> 00:12:27,509
this idea of once you've done all that

00:12:25,379 --> 00:12:29,339
work and all that preparation do you

00:12:27,509 --> 00:12:31,730
know what you've done we'll whip through

00:12:29,339 --> 00:12:34,050
this because this was my story about the

00:12:31,730 --> 00:12:38,339
blood samples which you don't need to

00:12:34,050 --> 00:12:42,089
hear again these are the people I

00:12:38,339 --> 00:12:43,860
referred to by the way Ted is a huge fan

00:12:42,089 --> 00:12:46,259
of buzzwords this is the first time he's

00:12:43,860 --> 00:12:47,459
missed it since 2011 he had some

00:12:46,259 --> 00:12:49,589
meetings and things going on in

00:12:47,459 --> 00:12:53,279
California was very sad not to be here

00:12:49,589 --> 00:12:55,589
but says hello to all of you cattle

00:12:53,279 --> 00:12:57,689
versus the real world as I said real

00:12:55,589 --> 00:12:59,910
world is not so quite so clean and neat

00:12:57,689 --> 00:13:01,470
as Kegel and in the real world you're

00:12:59,910 --> 00:13:04,110
doing the work that somebody else did

00:13:01,470 --> 00:13:07,110
for you before the cowbell contest now

00:13:04,110 --> 00:13:10,639
in that first topic of is data what you

00:13:07,110 --> 00:13:13,709
really think it is verify data

00:13:10,639 --> 00:13:15,149
absolutely verify it go in look at it

00:13:13,709 --> 00:13:17,220
make sure it's what you think you

00:13:15,149 --> 00:13:20,279
recorded if somebody else told you what

00:13:17,220 --> 00:13:21,809
it is make sure that you understood what

00:13:20,279 --> 00:13:23,519
they said correctly and make sure that

00:13:21,809 --> 00:13:26,819
they weren't making a mistake about it

00:13:23,519 --> 00:13:29,730
ask a lot of questions another aspect of

00:13:26,819 --> 00:13:33,000
that early stage of looking at data is

00:13:29,730 --> 00:13:34,529
to explore it and what I mean by that

00:13:33,000 --> 00:13:36,449
we've already explored it some just to

00:13:34,529 --> 00:13:39,089
make sure it is whatever somebody told

00:13:36,449 --> 00:13:41,579
you it was but you go in with some

00:13:39,089 --> 00:13:43,889
assumptions about data obviously you

00:13:41,579 --> 00:13:46,319
wouldn't be using that data set if you

00:13:43,889 --> 00:13:48,149
didn't already have some a priori idea

00:13:46,319 --> 00:13:49,889
of what features you want to build but

00:13:48,149 --> 00:13:52,079
there may be other value in that that

00:13:49,889 --> 00:13:55,470
you want to use as well that you will

00:13:52,079 --> 00:13:57,839
find by literally just examining the

00:13:55,470 --> 00:14:00,720
data and in some cases that's examining

00:13:57,839 --> 00:14:02,839
it via various tools in other cases it's

00:14:00,720 --> 00:14:05,639
examining it just as a visual

00:14:02,839 --> 00:14:07,949
examination or draw yourself a picture

00:14:05,639 --> 00:14:09,559
and see what comes out from that and

00:14:07,949 --> 00:14:12,480
there can be some really valuable

00:14:09,559 --> 00:14:13,930
surprises that come out so taking a

00:14:12,480 --> 00:14:16,149
moment for that early data

00:14:13,930 --> 00:14:18,220
exploration is a really important thing

00:14:16,149 --> 00:14:20,830
to do one reason I mentioned Apache

00:14:18,220 --> 00:14:24,190
drill is a great tool to do that drill

00:14:20,830 --> 00:14:26,520
is a sequel engine a sequel query engine

00:14:24,190 --> 00:14:27,850
that works on very large distributed

00:14:26,520 --> 00:14:30,279
datasets

00:14:27,850 --> 00:14:32,230
it is quite efficient other things are

00:14:30,279 --> 00:14:34,720
also quite efficient but drill is

00:14:32,230 --> 00:14:37,330
extremely unusual in the flexibility

00:14:34,720 --> 00:14:39,190
that it offers it discovers schema on

00:14:37,330 --> 00:14:41,500
the fly and so that makes it very

00:14:39,190 --> 00:14:44,230
appropriate for this exploration piece

00:14:41,500 --> 00:14:45,640
because you don't have to do a lot of

00:14:44,230 --> 00:14:47,709
data prep before you start asking

00:14:45,640 --> 00:14:49,510
questions about the data if you have to

00:14:47,709 --> 00:14:51,399
spend hours and days and weeks preparing

00:14:49,510 --> 00:14:52,959
it's kind of defeats the purpose of

00:14:51,399 --> 00:14:55,779
jumping in to see what you have and

00:14:52,959 --> 00:14:58,240
drill is just a classic tool for making

00:14:55,779 --> 00:15:00,220
that work so when this first idea of

00:14:58,240 --> 00:15:01,870
verify said I was going to tell you some

00:15:00,220 --> 00:15:04,300
real-world stories that came from some

00:15:01,870 --> 00:15:06,850
of these data experts and this story

00:15:04,300 --> 00:15:09,339
actually happened this one I think came

00:15:06,850 --> 00:15:11,920
from Ted not I don't may have been Joe

00:15:09,339 --> 00:15:13,600
but I think was Ted years ago he was

00:15:11,920 --> 00:15:15,850
working for our company call ID

00:15:13,600 --> 00:15:20,490
analytics he was building a fraud

00:15:15,850 --> 00:15:23,860
credit-card fraud detection system and

00:15:20,490 --> 00:15:27,040
he was given data from a large financial

00:15:23,860 --> 00:15:29,230
institution Ted used a column that they

00:15:27,040 --> 00:15:31,360
live labeled fraud thinking these were

00:15:29,230 --> 00:15:33,820
fraud events that makes sense and he

00:15:31,360 --> 00:15:36,070
built his model based on that and he

00:15:33,820 --> 00:15:37,930
knew you need to verify data so he even

00:15:36,070 --> 00:15:40,540
talked to the customer ahead of time and

00:15:37,930 --> 00:15:42,520
said this is what I'm gonna use and this

00:15:40,540 --> 00:15:44,110
is you know I said this is what it is

00:15:42,520 --> 00:15:45,970
and there was a conversation back and

00:15:44,110 --> 00:15:47,950
forth this is where domain knowledge

00:15:45,970 --> 00:15:49,900
matters you have to understand from

00:15:47,950 --> 00:15:52,060
somebody else who understands that data

00:15:49,900 --> 00:15:53,470
or what it is and in this case the

00:15:52,060 --> 00:15:55,209
customer was actually quite

00:15:53,470 --> 00:15:56,470
knowledgeable on a technical side as

00:15:55,209 --> 00:15:58,270
well that's not always the case

00:15:56,470 --> 00:16:00,250
sometimes that's a communication issue

00:15:58,270 --> 00:16:05,680
but it turned out in this particular

00:16:00,250 --> 00:16:08,079
case that wasn't actually data for fraud

00:16:05,680 --> 00:16:11,140
events it was actually an ID for fraud

00:16:08,079 --> 00:16:13,570
analyst it gave really odd results and

00:16:11,140 --> 00:16:16,690
even though Ted had talked to the

00:16:13,570 --> 00:16:18,970
customer ahead the the things that he

00:16:16,690 --> 00:16:22,420
said the way he communicated what he was

00:16:18,970 --> 00:16:23,740
doing they didn't hear what he said

00:16:22,420 --> 00:16:26,180
there was just a breakdown in

00:16:23,740 --> 00:16:29,240
communication I use that as an exam

00:16:26,180 --> 00:16:30,410
because even in a case like that trying

00:16:29,240 --> 00:16:32,080
to do the right thing with people

00:16:30,410 --> 00:16:35,300
knowledgeable on both sides

00:16:32,080 --> 00:16:37,880
communication can go awry so is really

00:16:35,300 --> 00:16:38,480
important to make use of that domain

00:16:37,880 --> 00:16:41,540
knowledge

00:16:38,480 --> 00:16:44,450
absolutely verify double-check find ways

00:16:41,540 --> 00:16:46,220
to have people say back to you what they

00:16:44,450 --> 00:16:48,140
think you just said to them to make sure

00:16:46,220 --> 00:16:51,800
that there's not a misunderstanding at

00:16:48,140 --> 00:16:55,160
that stage clear communication is

00:16:51,800 --> 00:16:56,630
absolutely essential and this can you

00:16:55,160 --> 00:16:58,220
can I'm sure have run into other

00:16:56,630 --> 00:16:58,790
examples where that's going to be the

00:16:58,220 --> 00:17:00,890
case

00:16:58,790 --> 00:17:03,710
now I wanted to just give you a fun

00:17:00,890 --> 00:17:06,710
example as an analogy for this idea of

00:17:03,710 --> 00:17:09,020
exploring data and finding out what's in

00:17:06,710 --> 00:17:10,850
there and you'll find sometimes that the

00:17:09,020 --> 00:17:13,670
value and data jumps out at you in ways

00:17:10,850 --> 00:17:17,180
that you didn't expect how many people

00:17:13,670 --> 00:17:20,350
in the room have come from a place where

00:17:17,180 --> 00:17:23,030
in your native language the word 40

00:17:20,350 --> 00:17:26,860
starts with a P sound it's something

00:17:23,030 --> 00:17:30,350
like t take a bunch of people here okay

00:17:26,860 --> 00:17:32,210
your your the blue dot on the map how

00:17:30,350 --> 00:17:36,100
many people here come from a part of the

00:17:32,210 --> 00:17:39,380
world where T starts as sounds like

00:17:36,100 --> 00:17:42,170
cha-cha as a chess sound like you're the

00:17:39,380 --> 00:17:44,060
red dot on the map and it turns out when

00:17:42,170 --> 00:17:45,950
you look at this you start to see a

00:17:44,060 --> 00:17:48,110
pattern without a whole lot of deep

00:17:45,950 --> 00:17:52,010
knowledge you start to see a pattern of

00:17:48,110 --> 00:17:54,620
the distribution of the word T as T or

00:17:52,010 --> 00:17:58,880
something like T a T sound versus cha it

00:17:54,620 --> 00:18:00,320
turns out that he came from China it

00:17:58,880 --> 00:18:03,940
came from different roots and different

00:18:00,320 --> 00:18:09,110
cultures and where it came by a an

00:18:03,940 --> 00:18:11,510
overland route it mostly moved through

00:18:09,110 --> 00:18:14,210
cultures that pronounce it as something

00:18:11,510 --> 00:18:16,160
related to chai there were other sources

00:18:14,210 --> 00:18:19,910
of tea in China a lot of these came

00:18:16,160 --> 00:18:22,520
early through Dutch trading it came

00:18:19,910 --> 00:18:24,320
through through ocean routes and those

00:18:22,520 --> 00:18:27,020
were distributed around these different

00:18:24,320 --> 00:18:28,730
coastal regions and it came from a

00:18:27,020 --> 00:18:31,250
region of China where the word sounded

00:18:28,730 --> 00:18:33,380
more like a tea sound and ended up going

00:18:31,250 --> 00:18:36,350
through Dutch and came out as the word

00:18:33,380 --> 00:18:38,480
tea there's a red dot out there which is

00:18:36,350 --> 00:18:39,530
actually turns out to be Portugal where

00:18:38,480 --> 00:18:41,330
tea arrived by

00:18:39,530 --> 00:18:44,290
see and center by Lam but oddly enough

00:18:41,330 --> 00:18:46,940
has a CH sound it's kind of an outlier I

00:18:44,290 --> 00:18:49,430
just thought this was a fun example and

00:18:46,940 --> 00:18:50,990
even in this example having observed

00:18:49,430 --> 00:18:52,700
something like that it certainly doesn't

00:18:50,990 --> 00:18:54,260
prove that that's correct you'd have to

00:18:52,700 --> 00:18:56,000
do a lot of digging find out some

00:18:54,260 --> 00:18:58,100
background information figure out if

00:18:56,000 --> 00:19:01,610
this apparent pattern is actually real

00:18:58,100 --> 00:19:03,920
but just by visualizing data just by

00:19:01,610 --> 00:19:05,810
some exploration you start to see a

00:19:03,920 --> 00:19:07,820
trend and you say it's out trend may be

00:19:05,810 --> 00:19:09,200
worth exploring and you will see the

00:19:07,820 --> 00:19:12,110
same thing as true in your own

00:19:09,200 --> 00:19:14,240
situations this is a real-world example

00:19:12,110 --> 00:19:15,530
where a data exploration made a big

00:19:14,240 --> 00:19:17,390
difference I'm sorry this talk is going

00:19:15,530 --> 00:19:20,500
to lose about half of it or go over but

00:19:17,390 --> 00:19:24,290
we'll just plow on and see what happens

00:19:20,500 --> 00:19:26,270
this was a big European Services

00:19:24,290 --> 00:19:28,940
Provider can't say exactly which one or

00:19:26,270 --> 00:19:30,620
what kind of service they have

00:19:28,940 --> 00:19:32,570
complaints of they were getting

00:19:30,620 --> 00:19:34,790
complaints of for service but when they

00:19:32,570 --> 00:19:37,430
went back into the data and the reports

00:19:34,790 --> 00:19:39,620
they were looking at averages from you

00:19:37,430 --> 00:19:41,210
know reporting and the averages all look

00:19:39,620 --> 00:19:42,490
good they didn't see any problem at all

00:19:41,210 --> 00:19:44,690
so they couldn't figure out why people

00:19:42,490 --> 00:19:47,000
felt like they were getting poor service

00:19:44,690 --> 00:19:48,200
because of poor response time and so

00:19:47,000 --> 00:19:49,940
they came to it this is a map our

00:19:48,200 --> 00:19:51,470
customer they came to map bar this

00:19:49,940 --> 00:19:53,030
looked like a really hard problem

00:19:51,470 --> 00:19:54,710
because the data just didn't seem to

00:19:53,030 --> 00:19:56,480
show what was going on they were gonna

00:19:54,710 --> 00:19:58,610
need some kind of complex machine

00:19:56,480 --> 00:20:00,710
learning analysis to find out what was

00:19:58,610 --> 00:20:03,350
the anomaly what was the problem and the

00:20:00,710 --> 00:20:05,030
person who did this who actually isn't a

00:20:03,350 --> 00:20:07,160
data scientist it started with somebody

00:20:05,030 --> 00:20:10,580
just to examine the data and one of our

00:20:07,160 --> 00:20:13,340
excellent engineers in the UK jumped in

00:20:10,580 --> 00:20:14,690
first he used Apache drill and he did

00:20:13,340 --> 00:20:16,910
what you should do first which is just

00:20:14,690 --> 00:20:19,130
explore the data to figure out they told

00:20:16,910 --> 00:20:21,170
him what they you know the customer said

00:20:19,130 --> 00:20:23,420
this is what the data is and he explored

00:20:21,170 --> 00:20:25,820
it and he immediately found that there

00:20:23,420 --> 00:20:27,980
were a number of regions where the data

00:20:25,820 --> 00:20:30,440
had dropped completely it simply wasn't

00:20:27,980 --> 00:20:32,660
being reported and so what this company

00:20:30,440 --> 00:20:34,400
had done is they had been averaging the

00:20:32,660 --> 00:20:36,290
average of reports from areas where

00:20:34,400 --> 00:20:38,900
everything worked right and surprisingly

00:20:36,290 --> 00:20:41,090
that looked good and the areas where

00:20:38,900 --> 00:20:43,100
they would drop signals also dropped the

00:20:41,090 --> 00:20:45,620
reports they weren't even showing up in

00:20:43,100 --> 00:20:47,840
the data so rather than this being a

00:20:45,620 --> 00:20:49,220
hard problem and having to spend months

00:20:47,840 --> 00:20:51,350
you know building an elaborate thing he

00:20:49,220 --> 00:20:53,149
went back in about three three days and

00:20:51,350 --> 00:20:54,859
said I found the problem this is what it

00:20:53,149 --> 00:20:56,179
as you have dropped signals here they

00:20:54,859 --> 00:20:57,229
didn't even need to do machine learning

00:20:56,179 --> 00:20:59,779
now

00:20:57,229 --> 00:21:01,399
often this would still be the first step

00:20:59,779 --> 00:21:03,469
that you would do in a machine learning

00:21:01,399 --> 00:21:06,019
problem but you can see how valuable

00:21:03,469 --> 00:21:08,059
that is to just examine what you have

00:21:06,019 --> 00:21:10,279
and see what pops out at you and also

00:21:08,059 --> 00:21:12,409
you'll discover patterns that you may

00:21:10,279 --> 00:21:14,509
want to make use of and in many cases

00:21:12,409 --> 00:21:15,919
it's not that rare you find that you

00:21:14,509 --> 00:21:19,219
don't actually have to do machine

00:21:15,919 --> 00:21:21,589
learning at all let's go to the second

00:21:19,219 --> 00:21:23,330
topic which is features how do you build

00:21:21,589 --> 00:21:25,099
features how do you know which features

00:21:23,330 --> 00:21:26,929
to build which ones are gonna be

00:21:25,099 --> 00:21:28,759
valuable to you well the first thing I

00:21:26,929 --> 00:21:31,549
want you to keep in mind again unlike a

00:21:28,759 --> 00:21:33,379
cowgirl contest is that it's not just a

00:21:31,549 --> 00:21:35,089
matter of choosing between a collection

00:21:33,379 --> 00:21:36,320
of features that are offered to you but

00:21:35,089 --> 00:21:38,869
in the real world you're gonna actually

00:21:36,320 --> 00:21:41,269
build those features now at this moment

00:21:38,869 --> 00:21:43,190
I expect somebody to jump in here or at

00:21:41,269 --> 00:21:45,049
least in their mind be asking but what

00:21:43,190 --> 00:21:46,909
about deep learning deep learning is

00:21:45,049 --> 00:21:48,979
going to discover those features for you

00:21:46,909 --> 00:21:50,719
and you're absolutely right that is one

00:21:48,979 --> 00:21:52,879
of the aspects of what deep learning is

00:21:50,719 --> 00:21:55,099
doing deep learning isn't appropriate

00:21:52,879 --> 00:21:57,739
for every situation and indeed it may be

00:21:55,099 --> 00:21:59,389
far more complex and sophisticated and

00:21:57,739 --> 00:22:01,969
advanced and what you need for a lot of

00:21:59,389 --> 00:22:04,549
situations but it's also true that deep

00:22:01,969 --> 00:22:06,229
learning techniques don't always

00:22:04,549 --> 00:22:08,389
discover the features that you need

00:22:06,229 --> 00:22:09,859
there are some situations where you need

00:22:08,389 --> 00:22:11,929
features that would never be discovered

00:22:09,859 --> 00:22:14,059
that way and so it's just good to know

00:22:11,929 --> 00:22:17,299
both techniques and to realize that this

00:22:14,059 --> 00:22:19,669
that you have more than one option so

00:22:17,299 --> 00:22:21,710
there is no specific right answer about

00:22:19,669 --> 00:22:22,729
what makes the right feature and then

00:22:21,710 --> 00:22:24,769
we'll talk a little about how you

00:22:22,729 --> 00:22:26,869
develop the feature after you decide

00:22:24,769 --> 00:22:28,849
what is the right feature it really is a

00:22:26,869 --> 00:22:30,589
trial and error or I'll say a trial and

00:22:28,849 --> 00:22:32,269
success keep trying different things and

00:22:30,589 --> 00:22:34,580
see what works in order to find the

00:22:32,269 --> 00:22:37,129
winners but there are some general areas

00:22:34,580 --> 00:22:39,369
kind of criteria to look for obviously

00:22:37,129 --> 00:22:41,929
you want good performance in the model

00:22:39,369 --> 00:22:43,639
feasibility and by that I mean do you

00:22:41,929 --> 00:22:45,529
actually have the data you would need to

00:22:43,639 --> 00:22:48,559
build that feature do you have the right

00:22:45,529 --> 00:22:50,359
to use it do you have access to it is it

00:22:48,559 --> 00:22:52,639
data that is going to be handled at a

00:22:50,359 --> 00:22:54,529
scale that will give you a response in

00:22:52,639 --> 00:22:56,359
the time that you need you know for the

00:22:54,529 --> 00:22:57,950
practical applications always keep in

00:22:56,359 --> 00:23:00,019
mind your your real world

00:22:57,950 --> 00:23:02,059
SLA s as you build these things so

00:23:00,019 --> 00:23:04,489
feasibility is a big thing and the one I

00:23:02,059 --> 00:23:06,139
think that is most often overlooked but

00:23:04,489 --> 00:23:06,830
you really hear this from people who

00:23:06,139 --> 00:23:08,419
have a lot of it

00:23:06,830 --> 00:23:11,929
experience with real-world machine

00:23:08,419 --> 00:23:14,149
learning is the interpretability of a

00:23:11,929 --> 00:23:17,510
feature and this last one is a luxury

00:23:14,149 --> 00:23:19,340
you don't always get to do that but if

00:23:17,510 --> 00:23:21,890
you have a choice of features and what I

00:23:19,340 --> 00:23:25,159
mean by interpretability is literally

00:23:21,890 --> 00:23:28,250
can this feature we understand stood by

00:23:25,159 --> 00:23:29,990
person who's an on data scientist why is

00:23:28,250 --> 00:23:32,120
this important even is it easy to

00:23:29,990 --> 00:23:33,769
understand by other data scientists it's

00:23:32,120 --> 00:23:35,510
important because it's easier to build

00:23:33,769 --> 00:23:37,549
consensus around the project you're

00:23:35,510 --> 00:23:39,679
building it's easier to explain to

00:23:37,549 --> 00:23:41,269
people the results what they're getting

00:23:39,679 --> 00:23:42,500
from this it's easier to explain to

00:23:41,269 --> 00:23:44,179
somebody who's going to fund your

00:23:42,500 --> 00:23:46,039
project and give you the resources you

00:23:44,179 --> 00:23:48,500
need maybe you're trying to build some

00:23:46,039 --> 00:23:50,809
kind of a system to detect what happens

00:23:48,500 --> 00:23:53,029
for big telecommunication system who's

00:23:50,809 --> 00:23:54,620
concerned about churn they want to see

00:23:53,029 --> 00:23:56,179
what's leading up to churn they have

00:23:54,620 --> 00:23:58,700
somebody in a call center who's going to

00:23:56,179 --> 00:23:59,929
act on these results or credit card

00:23:58,700 --> 00:24:00,919
fraud you have somebody's going to act

00:23:59,929 --> 00:24:02,690
on these results

00:24:00,919 --> 00:24:04,820
can you explain to somebody in a fraud

00:24:02,690 --> 00:24:07,519
center what these features and what this

00:24:04,820 --> 00:24:09,590
result means and so if you have the

00:24:07,519 --> 00:24:12,260
choice to build features that are

00:24:09,590 --> 00:24:14,960
interpretable by humans that's a huge

00:24:12,260 --> 00:24:16,880
advantage in a huge luxury doesn't mean

00:24:14,960 --> 00:24:21,019
you have to do that but where you can do

00:24:16,880 --> 00:24:22,850
it it can be really helpful how do you

00:24:21,019 --> 00:24:24,080
decide what features you might want to

00:24:22,850 --> 00:24:25,580
look through well one thing you can do

00:24:24,080 --> 00:24:27,470
is think through the behaviors of the

00:24:25,580 --> 00:24:28,700
thing you're studying if you're building

00:24:27,470 --> 00:24:31,309
some kind of a system to do

00:24:28,700 --> 00:24:32,679
recomendation or to look at behaviors of

00:24:31,309 --> 00:24:34,970
people who are buying things online

00:24:32,679 --> 00:24:36,649
think about the steps that they might

00:24:34,970 --> 00:24:38,980
take right before they buy things if

00:24:36,649 --> 00:24:41,179
it's a person who's about to leave a

00:24:38,980 --> 00:24:43,010
telecommunication systems what are some

00:24:41,179 --> 00:24:44,570
events it might happen right before that

00:24:43,010 --> 00:24:46,730
just literally put yourself in that

00:24:44,570 --> 00:24:48,740
place and think through it and that will

00:24:46,730 --> 00:24:50,690
will show you everything but it will put

00:24:48,740 --> 00:24:52,190
you on the right path to see what data

00:24:50,690 --> 00:24:54,409
you need and then you can go find out if

00:24:52,190 --> 00:24:56,299
that data actually exists let's start

00:24:54,409 --> 00:25:00,769
with the example of credit card fraud

00:24:56,299 --> 00:25:02,299
credit card fraud detection and this is

00:25:00,769 --> 00:25:05,389
hilarious I was going to look at you for

00:25:02,299 --> 00:25:11,179
the halfway point as we hit that slide

00:25:05,389 --> 00:25:12,320
he says go faster in this case you have

00:25:11,179 --> 00:25:14,240
to actually put yourself in the

00:25:12,320 --> 00:25:16,070
situation of being a fraudster yourself

00:25:14,240 --> 00:25:17,630
what would you do if you're trying to

00:25:16,070 --> 00:25:19,970
steal things from people by stealing

00:25:17,630 --> 00:25:20,410
cards let's take a simple example you

00:25:19,970 --> 00:25:22,630
stole

00:25:20,410 --> 00:25:24,040
a debit card at least in the US these

00:25:22,630 --> 00:25:26,200
debit cards work with a PIN number

00:25:24,040 --> 00:25:28,240
that's a problem because you've got the

00:25:26,200 --> 00:25:30,610
card but you don't know the pin so maybe

00:25:28,240 --> 00:25:32,410
a choice you make as a fraudster is you

00:25:30,610 --> 00:25:34,780
decide to use it as a credit card

00:25:32,410 --> 00:25:36,760
instead of a debit card in the u.s. that

00:25:34,780 --> 00:25:39,160
switches and lets you do it by signature

00:25:36,760 --> 00:25:42,490
the reason that's an advantage is it's

00:25:39,160 --> 00:25:44,620
easier to fake a signature than it is to

00:25:42,490 --> 00:25:47,050
fake a pin number now it doesn't mean

00:25:44,620 --> 00:25:48,820
that as a feature that you need to

00:25:47,050 --> 00:25:50,710
actually analyze whether that was an

00:25:48,820 --> 00:25:52,360
accurate signature or what signature it

00:25:50,710 --> 00:25:55,420
is what you're looking for is a change

00:25:52,360 --> 00:25:57,340
in behavior from using pin to using a

00:25:55,420 --> 00:26:00,250
signature and this could be done for

00:25:57,340 --> 00:26:01,810
other reasons like intentionally damage

00:26:00,250 --> 00:26:03,340
the chip so you have to use a mag

00:26:01,810 --> 00:26:05,170
straight and that pushes you again

00:26:03,340 --> 00:26:07,600
towards signature you think like the

00:26:05,170 --> 00:26:09,340
fraudster what would they do and this

00:26:07,600 --> 00:26:11,680
can leave clues that you can actually

00:26:09,340 --> 00:26:13,240
discover yourself by the way I wanted to

00:26:11,680 --> 00:26:16,030
tell you joke and I'm so late I'm gonna

00:26:13,240 --> 00:26:18,550
do it anyway I was picked William

00:26:16,030 --> 00:26:20,500
Shakespeare as my signature here because

00:26:18,550 --> 00:26:23,080
I was actually named after William

00:26:20,500 --> 00:26:25,060
Shakespeare I mean my name is Ellen but

00:26:23,080 --> 00:26:27,130
I was named long after William

00:26:25,060 --> 00:26:31,180
Shakespeare lived okay there you go

00:26:27,130 --> 00:26:32,950
that's your token joke other behaviors

00:26:31,180 --> 00:26:34,960
that point to fraud as fraudsters take a

00:26:32,950 --> 00:26:37,510
card they go out and do some small

00:26:34,960 --> 00:26:38,500
transactions or test probes to see if

00:26:37,510 --> 00:26:40,210
they're going to be able to do this

00:26:38,500 --> 00:26:43,300
before they really go you know for the

00:26:40,210 --> 00:26:45,430
big big haul now if we go to experts and

00:26:43,300 --> 00:26:47,500
they say this often happens at a gas

00:26:45,430 --> 00:26:49,180
station because it's a small transaction

00:26:47,500 --> 00:26:50,740
there's nobody there to actually observe

00:26:49,180 --> 00:26:52,870
what's going on and they can just drive

00:26:50,740 --> 00:26:54,760
away and so we say well maybe we could

00:26:52,870 --> 00:26:57,040
use that and build features from that

00:26:54,760 --> 00:26:59,380
how do I do that I might build a risk

00:26:57,040 --> 00:27:02,080
table as a reference that risk table

00:26:59,380 --> 00:27:03,970
could be used designed to look for probe

00:27:02,080 --> 00:27:05,860
events I could design a separate risk

00:27:03,970 --> 00:27:08,080
table to look for the actual fraud event

00:27:05,860 --> 00:27:10,000
and here is how that works you want to

00:27:08,080 --> 00:27:13,270
generalize from what the expert says

00:27:10,000 --> 00:27:15,010
they say gas station you think merchant

00:27:13,270 --> 00:27:18,310
types so you can make it a broader thing

00:27:15,010 --> 00:27:21,400
they say just before you a fraud happens

00:27:18,310 --> 00:27:23,500
here's behavior do you say let's look

00:27:21,400 --> 00:27:26,170
for different time windows of what just

00:27:23,500 --> 00:27:28,690
before means you're going to compare

00:27:26,170 --> 00:27:30,540
those events for frauds and non frauds

00:27:28,690 --> 00:27:33,620
you're going to look at the relative

00:27:30,540 --> 00:27:35,990
occurrence of those events and

00:27:33,620 --> 00:27:39,380
for that you're gonna do a risk table

00:27:35,990 --> 00:27:41,630
that has a log of the ratio of the fraud

00:27:39,380 --> 00:27:43,160
counts to the non fraud counts you'll do

00:27:41,630 --> 00:27:45,020
that for different merchants i'ts and

00:27:43,160 --> 00:27:47,690
then you'll start to compare that back

00:27:45,020 --> 00:27:49,820
to individual windows here's an example

00:27:47,690 --> 00:27:51,590
this is totally fake data it's just made

00:27:49,820 --> 00:27:53,900
up but it is typical of what you see and

00:27:51,590 --> 00:27:56,270
I am gonna go fast now but what are you

00:27:53,900 --> 00:27:58,400
want to call your attention to we we new

00:27:56,270 --> 00:28:00,650
to look for gas stations so that first

00:27:58,400 --> 00:28:02,780
line is gas stations and you notice that

00:28:00,650 --> 00:28:05,360
the number of events there is roughly

00:28:02,780 --> 00:28:07,250
about 60,000 for fraud and non fraud

00:28:05,360 --> 00:28:09,110
that's surprising it's not surprising

00:28:07,250 --> 00:28:10,970
when you look at the number of samples

00:28:09,110 --> 00:28:13,850
obviously there are a lot more non fraud

00:28:10,970 --> 00:28:17,390
samples and so the sample size is

00:28:13,850 --> 00:28:19,760
actually a 10x difference that means the

00:28:17,390 --> 00:28:21,679
the risk the occurrence of this in fraud

00:28:19,760 --> 00:28:23,600
situations is about 10 times what it

00:28:21,679 --> 00:28:26,450
would be in on fraud sister situations

00:28:23,600 --> 00:28:29,059
that last column your log risks ratio is

00:28:26,450 --> 00:28:30,620
a pretty large positive number that's an

00:28:29,059 --> 00:28:32,990
indicator that's what you expect to see

00:28:30,620 --> 00:28:35,210
we'll just look at tea room apparently

00:28:32,990 --> 00:28:36,860
people don't go out and get tea right

00:28:35,210 --> 00:28:38,960
before they're gonna commit a felony

00:28:36,860 --> 00:28:40,940
that's what this tells us you have a

00:28:38,960 --> 00:28:43,190
pretty small negative numbers are pretty

00:28:40,940 --> 00:28:44,780
large a negative number jump down to the

00:28:43,190 --> 00:28:47,390
bottom though Pizza Delivery is a

00:28:44,780 --> 00:28:49,970
surprise you've got quite a positive

00:28:47,390 --> 00:28:51,890
number apparently they do go out and get

00:28:49,970 --> 00:28:54,620
pizza they just don't get tea with it

00:28:51,890 --> 00:28:57,230
and why I wanted to show you this is

00:28:54,620 --> 00:28:59,030
this is something that you discover it's

00:28:57,230 --> 00:29:00,830
not what the expert told you the expert

00:28:59,030 --> 00:29:04,160
gave you a pointer in the direction to

00:29:00,830 --> 00:29:05,870
go you expanded that generalize it began

00:29:04,160 --> 00:29:08,720
to actually explore the data and this

00:29:05,870 --> 00:29:10,760
pops out maybe Pizza Delivery is also a

00:29:08,720 --> 00:29:13,130
feature you want to use and combined

00:29:10,760 --> 00:29:16,040
with others to look for probe events and

00:29:13,130 --> 00:29:19,070
so how you would build this is now for

00:29:16,040 --> 00:29:20,870
an individual card the set of events for

00:29:19,070 --> 00:29:23,390
that card overtime window I think this

00:29:20,870 --> 00:29:26,360
is about a day you look this up in your

00:29:23,390 --> 00:29:28,010
wrist table you enter those numbers you

00:29:26,360 --> 00:29:29,750
look at them collectively in some way I

00:29:28,010 --> 00:29:31,700
think this time it was just a sum but

00:29:29,750 --> 00:29:34,670
you're just trying to say over different

00:29:31,700 --> 00:29:36,559
windows for a particular card for

00:29:34,670 --> 00:29:38,929
particular set of events compared back

00:29:36,559 --> 00:29:41,860
to our risk table how likely is it that

00:29:38,929 --> 00:29:44,420
fraud is happening on that credit card

00:29:41,860 --> 00:29:47,090
other things you can do is to augment

00:29:44,420 --> 00:29:47,510
data add other data to the feature that

00:29:47,090 --> 00:29:49,610
you

00:29:47,510 --> 00:29:52,550
maybe you know a merchant ID you might

00:29:49,610 --> 00:29:53,780
look up the location of that and combine

00:29:52,550 --> 00:29:57,380
those and that gives you an additional

00:29:53,780 --> 00:30:00,350
feature data transformation which can be

00:29:57,380 --> 00:30:02,270
quite simple but hugely powerful in this

00:30:00,350 --> 00:30:05,510
case something as simple as taking the

00:30:02,270 --> 00:30:07,250
log of a value it's also helpful to have

00:30:05,510 --> 00:30:10,280
some domain knowledge or common sense

00:30:07,250 --> 00:30:12,680
here if you're looking at a tour to Euro

00:30:10,280 --> 00:30:15,380
difference in transition at rent to

00:30:12,680 --> 00:30:18,080
transactions that tour euro difference

00:30:15,380 --> 00:30:19,730
may make a lot more impact where you're

00:30:18,080 --> 00:30:22,130
going from ten to twelve and one hundred

00:30:19,730 --> 00:30:24,170
one hundred and two small tranche in

00:30:22,130 --> 00:30:26,870
changes in the data gives you a more

00:30:24,170 --> 00:30:29,210
meaningful way to look for data a look

00:30:26,870 --> 00:30:30,830
at data velocity is such a common

00:30:29,210 --> 00:30:32,480
feature I just wanted to mention it

00:30:30,830 --> 00:30:35,750
itself and especially if you think about

00:30:32,480 --> 00:30:38,600
things like credit card fraud the geo

00:30:35,750 --> 00:30:41,420
distance or geolocation over time is a

00:30:38,600 --> 00:30:43,670
velocity issue if you go out and you buy

00:30:41,420 --> 00:30:45,320
a beer here in Berlin and ten minutes

00:30:43,670 --> 00:30:47,750
later you buy a beautiful pearl necklace

00:30:45,320 --> 00:30:49,490
in Singapore something's not right

00:30:47,750 --> 00:30:52,670
okay so that's something you can look

00:30:49,490 --> 00:30:54,230
for but expand that ask yourself how

00:30:52,670 --> 00:30:56,330
many different ways can you look at

00:30:54,230 --> 00:30:58,730
velocity you might look at the number of

00:30:56,330 --> 00:31:01,130
events over time you might look at the

00:30:58,730 --> 00:31:03,050
amount to spend over time and you can

00:31:01,130 --> 00:31:05,090
think of other ones as well so again

00:31:03,050 --> 00:31:06,650
always expand the number of ways that

00:31:05,090 --> 00:31:09,740
you look at things and that gives you a

00:31:06,650 --> 00:31:11,720
much stronger situation jumping into the

00:31:09,740 --> 00:31:13,670
third topic we've talked about a lot of

00:31:11,720 --> 00:31:15,950
different ways that you make decisions

00:31:13,670 --> 00:31:18,410
about what features you use that you

00:31:15,950 --> 00:31:21,110
take data that experts gave you but you

00:31:18,410 --> 00:31:23,000
examine it you verify it you do process

00:31:21,110 --> 00:31:26,120
and you do transformations you do

00:31:23,000 --> 00:31:28,010
augmentation you build the features you

00:31:26,120 --> 00:31:30,890
build your training set that's a lot of

00:31:28,010 --> 00:31:32,270
work and you've picked your algorithm

00:31:30,890 --> 00:31:33,680
you've written the code for your model

00:31:32,270 --> 00:31:35,120
you're going to go through the training

00:31:33,680 --> 00:31:36,440
process you're going to have a trained

00:31:35,120 --> 00:31:39,410
model you're going to deploy it into

00:31:36,440 --> 00:31:42,350
production how do you know what you

00:31:39,410 --> 00:31:43,790
actually did how can you go back to

00:31:42,350 --> 00:31:45,140
leader and know what you did how do you

00:31:43,790 --> 00:31:46,130
know what you did with the code how do

00:31:45,140 --> 00:31:48,140
you know why you did it

00:31:46,130 --> 00:31:50,570
how do you know how you develop that

00:31:48,140 --> 00:31:52,220
training data why did you develop it

00:31:50,570 --> 00:31:55,040
what data did it come from

00:31:52,220 --> 00:31:56,870
what were the assumptions where is the

00:31:55,040 --> 00:31:58,520
training data now has somebody helpfully

00:31:56,870 --> 00:32:01,130
written over it and you can't go back to

00:31:58,520 --> 00:32:04,309
it there's a great deal that you

00:32:01,130 --> 00:32:06,380
to keep track of as we said just to

00:32:04,309 --> 00:32:08,470
remind you the data is a key part of

00:32:06,380 --> 00:32:10,700
this and what I didn't mention before is

00:32:08,470 --> 00:32:12,470
oftentimes you actually do this for

00:32:10,700 --> 00:32:14,150
cross validation and training where you

00:32:12,470 --> 00:32:15,470
take your training set and cut it

00:32:14,150 --> 00:32:17,299
different ways and you're doing it over

00:32:15,470 --> 00:32:19,400
and over again just in a single round

00:32:17,299 --> 00:32:23,419
basically of training you have a lot to

00:32:19,400 --> 00:32:25,429
keep track of go back to my slides this

00:32:23,419 --> 00:32:28,190
is a really nice paper by Ted a very

00:32:25,429 --> 00:32:30,110
recent blog post that explains a lot of

00:32:28,190 --> 00:32:33,289
this about the role of data in a model

00:32:30,110 --> 00:32:34,730
what this would say is that data really

00:32:33,289 --> 00:32:36,770
makes the model here we do a better

00:32:34,730 --> 00:32:38,720
version if you have different training

00:32:36,770 --> 00:32:40,820
data you have a different model can't

00:32:38,720 --> 00:32:43,789
emphasize this enough we're not saying

00:32:40,820 --> 00:32:46,909
by training data I use this you know a

00:32:43,789 --> 00:32:49,700
certain class of events to look at

00:32:46,909 --> 00:32:51,950
training we mean literally the exact

00:32:49,700 --> 00:32:54,140
data that you used to train that model

00:32:51,950 --> 00:32:56,900
and so you have versions of data just as

00:32:54,140 --> 00:33:00,080
you would have versions of code if I ask

00:32:56,900 --> 00:33:02,630
you is it okay for only one person to

00:33:00,080 --> 00:33:05,690
compile your production source code

00:33:02,630 --> 00:33:07,730
you'd probably say no no no no okay in

00:33:05,690 --> 00:33:10,340
this case should be right but exactly

00:33:07,730 --> 00:33:13,700
the same thing actually applies to data

00:33:10,340 --> 00:33:17,690
you need ways to do data version control

00:33:13,700 --> 00:33:19,940
and to document the data source where

00:33:17,690 --> 00:33:22,100
it's stored be able to preserve it just

00:33:19,940 --> 00:33:24,500
like you froze those you didn't somebody

00:33:22,100 --> 00:33:26,990
froze those blood samples you have to

00:33:24,500 --> 00:33:28,970
know what you did where it is how to go

00:33:26,990 --> 00:33:31,130
back to it and you have to do this in

00:33:28,970 --> 00:33:33,559
such a way it's like writing a note to

00:33:31,130 --> 00:33:35,210
your future self okay could you come

00:33:33,559 --> 00:33:37,370
back to it six months or a year from now

00:33:35,210 --> 00:33:40,760
and be able to do it because you will

00:33:37,370 --> 00:33:42,860
want to not only to turn and repeat a

00:33:40,760 --> 00:33:44,390
project you're working on because you're

00:33:42,860 --> 00:33:46,250
now working on something different and

00:33:44,390 --> 00:33:48,740
like the blood sample you realize that

00:33:46,250 --> 00:33:50,330
there's valuable data and valuable

00:33:48,740 --> 00:33:52,909
features maybe in the raw part of that

00:33:50,330 --> 00:33:55,580
project data that you could now make use

00:33:52,909 --> 00:33:57,470
of but the other reason is so that you

00:33:55,580 --> 00:33:59,600
can share this with other people on your

00:33:57,470 --> 00:34:01,250
team this is important it's writing

00:33:59,600 --> 00:34:02,840
notes to your future self or it's

00:34:01,250 --> 00:34:04,549
writing notes to that person who gets

00:34:02,840 --> 00:34:06,919
hired when you get your big promotion

00:34:04,549 --> 00:34:08,960
and bumped up and somebody else comes in

00:34:06,919 --> 00:34:11,330
and starts working on your project so

00:34:08,960 --> 00:34:13,700
it's really important to say this and

00:34:11,330 --> 00:34:14,960
document it do a number of ways to do it

00:34:13,700 --> 00:34:17,240
this was just a reminder

00:34:14,960 --> 00:34:19,040
slide that you know that that machine

00:34:17,240 --> 00:34:21,379
learning is an iterative process it's

00:34:19,040 --> 00:34:22,550
not just a single thing there are a

00:34:21,379 --> 00:34:25,760
number of different ways to do it

00:34:22,550 --> 00:34:28,190
notebooks are excellent you can share

00:34:25,760 --> 00:34:29,450
code that way you can document what

00:34:28,190 --> 00:34:31,040
you're doing there are a lot of

00:34:29,450 --> 00:34:34,760
different choices of notebooks these are

00:34:31,040 --> 00:34:36,470
two excellent ones but think about what

00:34:34,760 --> 00:34:39,379
you do with code and think about how you

00:34:36,470 --> 00:34:41,359
do the analogous thing with data it's

00:34:39,379 --> 00:34:43,790
completely familiar have a new person

00:34:41,359 --> 00:34:45,589
come in they may be fork off code you

00:34:43,790 --> 00:34:48,200
may be store what's going on and get

00:34:45,589 --> 00:34:50,179
that's all familiar to everybody here

00:34:48,200 --> 00:34:52,520
but when you try to do the same thing

00:34:50,179 --> 00:34:55,159
with data these training sets can be

00:34:52,520 --> 00:34:57,020
enormous so you have to find a tool that

00:34:55,159 --> 00:34:58,970
lets you do this effectively with data

00:34:57,020 --> 00:35:01,220
you may be documenting what you do

00:34:58,970 --> 00:35:03,559
partly in that notebook but where do you

00:35:01,220 --> 00:35:06,079
store the data itself where do you store

00:35:03,559 --> 00:35:08,900
the different versions of training data

00:35:06,079 --> 00:35:11,329
now I work with people who work with map

00:35:08,900 --> 00:35:13,040
our data platform it's a superb platform

00:35:11,329 --> 00:35:14,390
for doing machine learning partly

00:35:13,040 --> 00:35:17,660
because it's a large-scale distributed

00:35:14,390 --> 00:35:20,420
platform but unlike Hadoop based systems

00:35:17,660 --> 00:35:22,970
data is directly available to machine

00:35:20,420 --> 00:35:25,099
learning tools you can use our you can

00:35:22,970 --> 00:35:27,980
use Python tensorflow

00:35:25,099 --> 00:35:29,420
MX net hgo whatever you want directly on

00:35:27,980 --> 00:35:31,730
the data you don't have to copy things

00:35:29,420 --> 00:35:34,819
in and out but it's also very useful

00:35:31,730 --> 00:35:37,280
because map r has something called map

00:35:34,819 --> 00:35:39,470
or volumes and based on volumes you make

00:35:37,280 --> 00:35:41,750
snapshots real point in time

00:35:39,470 --> 00:35:44,630
honest-to-god snapshots they're cheap

00:35:41,750 --> 00:35:45,890
they easy to make they don't use up a

00:35:44,630 --> 00:35:47,809
lot of storage space because they're

00:35:45,890 --> 00:35:50,480
just pointing back to original data so

00:35:47,809 --> 00:35:52,819
this becomes just a superb tool for data

00:35:50,480 --> 00:35:56,059
versioning and you can actually put a

00:35:52,819 --> 00:35:59,119
readme file right there in the snapshot

00:35:56,059 --> 00:36:01,069
with the the data the training data or

00:35:59,119 --> 00:36:03,770
the raw data itself you can also

00:36:01,069 --> 00:36:06,079
document that back in the notebook it's

00:36:03,770 --> 00:36:09,410
really important to do multiple ways of

00:36:06,079 --> 00:36:11,000
documentation this is a webinar you'll

00:36:09,410 --> 00:36:15,109
have my slides I recommend you go back

00:36:11,000 --> 00:36:17,270
to it there's a finish company that does

00:36:15,109 --> 00:36:19,640
builds machine learning pipelines as a

00:36:17,270 --> 00:36:22,010
tool and they did a webinar and

00:36:19,640 --> 00:36:24,290
basically do a live demonstration

00:36:22,010 --> 00:36:26,990
showing how they architect their

00:36:24,290 --> 00:36:28,369
solutions and how they use snapshots to

00:36:26,990 --> 00:36:30,410
version data

00:36:28,369 --> 00:36:32,269
what aspects of data versioning are

00:36:30,410 --> 00:36:35,029
important to them it's a it's a really

00:36:32,269 --> 00:36:37,729
nice short little video that you might

00:36:35,029 --> 00:36:40,430
want to take a look at these are some of

00:36:37,729 --> 00:36:43,880
the things that you want to look at I'm

00:36:40,430 --> 00:36:45,549
at the end of my time I think should I

00:36:43,880 --> 00:36:49,249
talk for another minute or two

00:36:45,549 --> 00:36:50,749
yes no yes okay these are some of the

00:36:49,249 --> 00:36:53,150
things that you want to document and

00:36:50,749 --> 00:36:55,219
again you know go back to it but keep in

00:36:53,150 --> 00:36:57,529
mind what's your document for training

00:36:55,219 --> 00:37:02,299
data is different than what you document

00:36:57,529 --> 00:37:04,219
for the code the trained model and how

00:37:02,299 --> 00:37:05,960
you got there there's slightly different

00:37:04,219 --> 00:37:09,079
things and you'll want to keep track of

00:37:05,960 --> 00:37:12,680
both of them including the path name for

00:37:09,079 --> 00:37:15,559
the training snapshot itself why you

00:37:12,680 --> 00:37:17,839
chose what you did how will you pick

00:37:15,559 --> 00:37:20,569
things like a random number generator to

00:37:17,839 --> 00:37:24,140
actually build in the learning process

00:37:20,569 --> 00:37:28,130
itself go back to this list go back to

00:37:24,140 --> 00:37:30,049
that blog reference that I put up by Ted

00:37:28,130 --> 00:37:33,259
and you'll see this explained in some

00:37:30,049 --> 00:37:35,269
detail one last thing I wanted you to

00:37:33,259 --> 00:37:36,950
think about is a lot of people are used

00:37:35,269 --> 00:37:38,809
to the idea of unit testing when it

00:37:36,950 --> 00:37:41,509
comes to code they don't think in those

00:37:38,809 --> 00:37:42,920
terms in terms of data but that's really

00:37:41,509 --> 00:37:45,019
important it's kind of a new thing for

00:37:42,920 --> 00:37:46,940
people to do and what you're basically

00:37:45,019 --> 00:37:49,369
doing is in addition to all the things

00:37:46,940 --> 00:37:52,670
that we just said is design unit tests

00:37:49,369 --> 00:37:55,190
that are constantly testing to say is

00:37:52,670 --> 00:37:57,109
what we're doing now what we were doing

00:37:55,190 --> 00:38:00,469
before has there been a change in data

00:37:57,109 --> 00:38:04,969
and those unit tests can be designed to

00:38:00,469 --> 00:38:06,559
look at outputs from the machine

00:38:04,969 --> 00:38:09,190
learning model and that's kind of cool

00:38:06,559 --> 00:38:11,599
because some changes in input data

00:38:09,190 --> 00:38:13,489
happen but they don't really matter you

00:38:11,599 --> 00:38:15,140
don't have a substantial problem or a

00:38:13,489 --> 00:38:17,210
difference in the output and you don't

00:38:15,140 --> 00:38:19,099
have to waste time looking at those you

00:38:17,210 --> 00:38:21,469
can just keep looking at outputs and say

00:38:19,099 --> 00:38:23,210
are we still in terrains that make sense

00:38:21,469 --> 00:38:27,349
and a different approach is to actually

00:38:23,210 --> 00:38:32,779
design unit test data training to unit

00:38:27,349 --> 00:38:34,519
data train testing that that look at the

00:38:32,779 --> 00:38:36,529
input data and you're actually looking

00:38:34,519 --> 00:38:39,349
for the changes before they go in that's

00:38:36,529 --> 00:38:41,690
a very good way to do it - for doing

00:38:39,349 --> 00:38:44,330
that second one there's an excellent

00:38:41,690 --> 00:38:47,090
paper on data validation and I recommend

00:38:44,330 --> 00:38:49,520
you go to that link but however you

00:38:47,090 --> 00:38:51,590
decide to do it or do it both ways again

00:38:49,520 --> 00:38:53,390
it's a step that's often overlooked but

00:38:51,590 --> 00:38:55,310
it's really valuable you catch things

00:38:53,390 --> 00:38:58,250
quickly as they begin to change and they

00:38:55,310 --> 00:39:01,730
often do change so these are a couple of

00:38:58,250 --> 00:39:03,260
books that use related topics they're

00:39:01,730 --> 00:39:07,010
available as a free download

00:39:03,260 --> 00:39:09,350
courtesy of Matt Barr please continue to

00:39:07,010 --> 00:39:11,270
support women in big data it's not just

00:39:09,350 --> 00:39:13,520
good for women it's good for society and

00:39:11,270 --> 00:39:16,160
from one woman in Big Data

00:39:13,520 --> 00:39:18,650
thanks and also thank you very much for

00:39:16,160 --> 00:39:21,200
putting up with the anomaly with the

00:39:18,650 --> 00:39:29,219
slides right at the beginning thank you

00:39:21,200 --> 00:39:29,219

YouTube URL: https://www.youtube.com/watch?v=z-zYXamPnOQ


