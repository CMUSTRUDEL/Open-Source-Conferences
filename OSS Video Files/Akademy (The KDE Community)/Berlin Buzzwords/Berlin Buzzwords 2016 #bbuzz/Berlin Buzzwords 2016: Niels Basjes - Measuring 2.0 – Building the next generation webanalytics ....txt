Title: Berlin Buzzwords 2016: Niels Basjes - Measuring 2.0 – Building the next generation webanalytics ...
Publication date: 2016-06-12
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	At bol.com we want to help the customer find what they wanted. To automate this process we need to understand what products/promotions we showed them and which of those made them happy. With the fine grained personalization that has been introduced over the last few years we see that just measuring ‘what page’ we showed - like all the standard web analytics systems do - is no longer enough. So we need something different. In order to get a solution that will support our business for the coming years we raised the bar to the top: Measure everything and analyze in near-realtime.

In this talk Niels Basjes will explain the project "Measuring 2.0", our next generation web analytics measuring and processing stack, that is to go live in the spring of 2016. Niels will go into:
- the custom built measuring system that will produce over 50.000 measurements per second
- the processing system and the algorithms implemented with Apache Flink
- why we did not choose Storm or Spark for this task
- the development and operational hurdles needed to make this type of solution run in production
- the architectural concepts to make this data available in the personalization services we have

Read more:
https://2016.berlinbuzzwords.de/session/measuring-20-building-next-generation-webanalytics-solution-using-apache-flink

About Niels Basjes:
https://2016.berlinbuzzwords.de/users/niels-basjes

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:02,330 --> 00:00:07,259
okay uh welcome everybody we had some

00:00:05,370 --> 00:00:08,730
technical hiccups so I'm running it now

00:00:07,259 --> 00:00:10,280
on a Mac so the phones will look

00:00:08,730 --> 00:00:12,719
slightly different

00:00:10,280 --> 00:00:15,059
my name is news brushes I'm going to

00:00:12,719 --> 00:00:16,920
delete IT architects at ball become the

00:00:15,059 --> 00:00:20,340
biggest online retailer in the Dutch

00:00:16,920 --> 00:00:22,350
language area of the Benelux I'm going

00:00:20,340 --> 00:00:24,630
to have talk about measuring 2.0 a

00:00:22,350 --> 00:00:27,390
project has started a few years ago as

00:00:24,630 --> 00:00:31,019
you know a bit of frustration of the

00:00:27,390 --> 00:00:34,160
status quo the overviews of talk I'll

00:00:31,019 --> 00:00:37,050
talk a bit about balls comm what we do

00:00:34,160 --> 00:00:39,059
what we use to to build those things

00:00:37,050 --> 00:00:42,480
upon and what's wrong with that

00:00:39,059 --> 00:00:44,460
and then I go into measuring 2.0 in the

00:00:42,480 --> 00:00:47,070
next generation thing that also includes

00:00:44,460 --> 00:00:51,660
a lot of real time streaming parts based

00:00:47,070 --> 00:00:53,699
on Apache flink nowadays okay um bit of

00:00:51,660 --> 00:00:56,520
backgrounds I have a master's degree in

00:00:53,699 --> 00:00:58,079
both computer science and business I've

00:00:56,520 --> 00:01:00,359
had various software development

00:00:58,079 --> 00:01:02,039
research and architect roles and I'm a

00:01:00,359 --> 00:01:03,780
heavy contributor to a lot of the Big

00:01:02,039 --> 00:01:07,229
Data projects and I'm a committer of

00:01:03,780 --> 00:01:09,960
Apache opera so what is ball has come

00:01:07,229 --> 00:01:13,530
like I said biggest online retailer in

00:01:09,960 --> 00:01:17,460
the Dutch language area to give you a

00:01:13,530 --> 00:01:19,860
bit of sense of scale our catalog is any

00:01:17,460 --> 00:01:23,119
14 million items of which about 11

00:01:19,860 --> 00:01:26,850
million are available for sale right now

00:01:23,119 --> 00:01:29,509
6 million active customers tens of

00:01:26,850 --> 00:01:32,970
millions of active visits each month our

00:01:29,509 --> 00:01:35,340
number of pageviews per year is over 2

00:01:32,970 --> 00:01:36,900
and a half billion and it may not be

00:01:35,340 --> 00:01:41,700
surprising to you that we've been using

00:01:36,900 --> 00:01:44,119
Hadoop in production since 2010 the main

00:01:41,700 --> 00:01:46,829
application we use it for is

00:01:44,119 --> 00:01:49,770
personalization we want to make the

00:01:46,829 --> 00:01:52,320
customers happy help them visiting our

00:01:49,770 --> 00:01:55,259
website and the first thing we built

00:01:52,320 --> 00:01:57,360
back then was search suggestions when

00:01:55,259 --> 00:01:59,610
you type some letters you get suggested

00:01:57,360 --> 00:02:02,640
search terms that's based on click

00:01:59,610 --> 00:02:05,009
traffic by customers nowadays we also

00:02:02,640 --> 00:02:07,079
look at your purchase history what you

00:02:05,009 --> 00:02:12,750
looked at what you put in your shopping

00:02:07,079 --> 00:02:14,080
list and what you didn't buy so if you

00:02:12,750 --> 00:02:16,960
look at the homepage as a red

00:02:14,080 --> 00:02:22,110
customer there's a lot there heart this

00:02:16,960 --> 00:02:25,270
is based on what I call measuring 1.0

00:02:22,110 --> 00:02:27,820
well there are some issues with that and

00:02:25,270 --> 00:02:33,310
the biggest one is that the data arrives

00:02:27,820 --> 00:02:36,730
in blocks of 24 hours so the

00:02:33,310 --> 00:02:38,470
personalization is the day behind when

00:02:36,730 --> 00:02:40,030
we know what a better recommendation is

00:02:38,470 --> 00:02:42,820
the customer has already left and we

00:02:40,030 --> 00:02:46,360
have to hope they come back and as you

00:02:42,820 --> 00:02:48,820
may know the value of data decreases

00:02:46,360 --> 00:02:52,780
rapidly with time and what you would

00:02:48,820 --> 00:02:55,720
want is to stay in the low minutes maybe

00:02:52,780 --> 00:02:59,560
even seconds range to give feedback to

00:02:55,720 --> 00:03:03,250
improve health them new measurements are

00:02:59,560 --> 00:03:06,580
done using using javascript so we have

00:03:03,250 --> 00:03:08,740
this kind of stuff in the HTML and as

00:03:06,580 --> 00:03:10,390
you see here there are variables they're

00:03:08,740 --> 00:03:14,380
called llevarse and properties and

00:03:10,390 --> 00:03:16,810
they're limited you know it's heavy on

00:03:14,380 --> 00:03:20,920
the client we cannot measure everything

00:03:16,810 --> 00:03:22,720
and they're unclear so what happens also

00:03:20,920 --> 00:03:25,989
with the limitation of the llevarse they

00:03:22,720 --> 00:03:28,930
get reused depending on the page some

00:03:25,989 --> 00:03:30,790
llevarse mean different things makes it

00:03:28,930 --> 00:03:34,750
very hard to use the data for our data

00:03:30,790 --> 00:03:37,690
science guys data is incomplete it's

00:03:34,750 --> 00:03:39,760
inaccurate sometimes the JavaScript is

00:03:37,690 --> 00:03:42,400
slow and it's important to realize that

00:03:39,760 --> 00:03:46,420
this technology puts everything in the

00:03:42,400 --> 00:03:47,830
URL now a product the description we use

00:03:46,420 --> 00:03:48,519
for a single product looks something

00:03:47,830 --> 00:03:51,850
like this

00:03:48,519 --> 00:03:55,150
and the worst case I've seen over the

00:03:51,850 --> 00:03:58,120
years is this thing it's our all deals

00:03:55,150 --> 00:04:01,140
page all the things we are actively

00:03:58,120 --> 00:04:04,690
promoting at this at a point in time and

00:04:01,140 --> 00:04:09,269
this one had 34 of them throughout the

00:04:04,690 --> 00:04:15,090
website and that resulted in this baby

00:04:09,269 --> 00:04:15,090
if you put that in URL things break

00:04:15,330 --> 00:04:22,500
they really do so you miss data as you

00:04:20,730 --> 00:04:29,250
may understand things needed to change

00:04:22,500 --> 00:04:31,410
and our business goal was that we wanted

00:04:29,250 --> 00:04:33,540
to be able to know exactly what was

00:04:31,410 --> 00:04:36,090
going on on the webshop right now

00:04:33,540 --> 00:04:42,720
because we wanted to assist the visitors

00:04:36,090 --> 00:04:44,900
right now so while sorry

00:04:42,720 --> 00:04:47,940
while the visitor is still on the site

00:04:44,900 --> 00:04:49,980
we want to give them the best experience

00:04:47,940 --> 00:04:52,860
possible based on everything they've

00:04:49,980 --> 00:04:54,860
done so far including the last few

00:04:52,860 --> 00:04:57,990
clicks

00:04:54,860 --> 00:05:00,240
but in addition some processes in terms

00:04:57,990 --> 00:05:03,420
of their algorithm our batch oriented

00:05:00,240 --> 00:05:05,790
and even those we want to run multiple

00:05:03,420 --> 00:05:07,770
times per day things like search

00:05:05,790 --> 00:05:11,520
suggestions search rank the sorting of

00:05:07,770 --> 00:05:13,200
our products and recommendations so

00:05:11,520 --> 00:05:15,840
that's why I started the project which

00:05:13,200 --> 00:05:18,240
we now call measuring 2.0 and it's

00:05:15,840 --> 00:05:20,760
really all about making better

00:05:18,240 --> 00:05:23,730
measurements being able to process them

00:05:20,760 --> 00:05:26,010
faster with lower latency and as a

00:05:23,730 --> 00:05:31,169
consequence making applications more

00:05:26,010 --> 00:05:34,980
relevant so the goals are really high I

00:05:31,169 --> 00:05:37,350
just want everything all interactions

00:05:34,980 --> 00:05:40,260
all users even Googlebot because they

00:05:37,350 --> 00:05:41,700
don't do JavaScript all the details I

00:05:40,260 --> 00:05:44,720
want to know exactly what was on the

00:05:41,700 --> 00:05:48,600
page I wanted data to be more reliable

00:05:44,720 --> 00:05:51,300
lower load on the clients and the lowest

00:05:48,600 --> 00:05:55,410
possible agency so just you know

00:05:51,300 --> 00:05:56,790
everything but in addition because of

00:05:55,410 --> 00:05:58,200
the complexity of making these

00:05:56,790 --> 00:06:00,600
measurements I want to tell you a lot

00:05:58,200 --> 00:06:03,120
easier for the developers and I also

00:06:00,600 --> 00:06:07,010
want to allow business people to ask new

00:06:03,120 --> 00:06:11,130
questions we didn't think of before okay

00:06:07,010 --> 00:06:15,419
but over time over the last few years

00:06:11,130 --> 00:06:18,600
the laws have means playing a part of

00:06:15,419 --> 00:06:21,419
this nowadays we have privacy laws that

00:06:18,600 --> 00:06:24,060
say you can't do profiling form on data

00:06:21,419 --> 00:06:26,310
for more than two years of course

00:06:24,060 --> 00:06:28,950
security don't want us to record

00:06:26,310 --> 00:06:29,639
security sensitive stuff and on the

00:06:28,950 --> 00:06:31,590
other hand our

00:06:29,639 --> 00:06:33,629
data science guys want to do profiling

00:06:31,590 --> 00:06:36,120
on multiple years you know recommender

00:06:33,629 --> 00:06:40,009
system we have currently uses over five

00:06:36,120 --> 00:06:43,530
years of clickstream data as an example

00:06:40,009 --> 00:06:46,979
so how do we solve that one well let's

00:06:43,530 --> 00:06:48,659
start with measuring everything when I

00:06:46,979 --> 00:06:50,909
mean measuring everything I really mean

00:06:48,659 --> 00:06:53,159
everything in terms of the interactions

00:06:50,909 --> 00:06:56,849
so regular weapon all ethics they

00:06:53,159 --> 00:06:59,009
measure the page just the page and then

00:06:56,849 --> 00:07:01,139
maybe what kind of pages was it who

00:06:59,009 --> 00:07:03,870
visited but what I want to know is all

00:07:01,139 --> 00:07:07,289
the parts of the page and why they were

00:07:03,870 --> 00:07:09,599
put there and what was then put in so

00:07:07,289 --> 00:07:11,310
example in the bottom right you see a

00:07:09,599 --> 00:07:13,560
block of recommended recommended

00:07:11,310 --> 00:07:15,090
products I want to know that that group

00:07:13,560 --> 00:07:16,860
was there because it was a

00:07:15,090 --> 00:07:23,129
recommendation and not some kind of

00:07:16,860 --> 00:07:26,639
campaign cause and effect in these

00:07:23,129 --> 00:07:29,279
events is the most important thing for

00:07:26,639 --> 00:07:31,620
us if you look at the type of analytics

00:07:29,279 --> 00:07:34,080
we do the type of applications its

00:07:31,620 --> 00:07:36,779
banner optimization you show something

00:07:34,080 --> 00:07:39,779
they click or they don't a be testing

00:07:36,779 --> 00:07:42,029
same thing search suggestions look at

00:07:39,779 --> 00:07:44,430
the search term in relation to what

00:07:42,029 --> 00:07:46,710
people did with it actually beauty

00:07:44,430 --> 00:07:48,599
modeling the banner in terms of what

00:07:46,710 --> 00:07:51,060
people did with it so it's all

00:07:48,599 --> 00:07:55,050
behavioral analytics it's all cause and

00:07:51,060 --> 00:07:56,849
effect type of processing the high-level

00:07:55,050 --> 00:07:59,460
data structure I designed for this

00:07:56,849 --> 00:08:02,460
project is therefore a very simple

00:07:59,460 --> 00:08:05,479
record that has an entity and the effect

00:08:02,460 --> 00:08:08,909
on that entity and a cause and that

00:08:05,479 --> 00:08:11,339
cause on the other end you also have

00:08:08,909 --> 00:08:13,770
hooks you know in terms of website the

00:08:11,339 --> 00:08:17,430
things you can click on usually Add to

00:08:13,770 --> 00:08:19,589
Cart go to product page and so if I have

00:08:17,430 --> 00:08:23,879
a cause a reason for entering the

00:08:19,589 --> 00:08:26,969
website maybe a banner I record a bunch

00:08:23,879 --> 00:08:29,669
of things these are the products I put

00:08:26,969 --> 00:08:32,010
on the page for various reasons and then

00:08:29,669 --> 00:08:34,409
somebody clicks ok I know which one they

00:08:32,010 --> 00:08:37,289
clicked and I know what the consequences

00:08:34,409 --> 00:08:40,260
were and that continues all the way up

00:08:37,289 --> 00:08:42,510
to hey I bought something and now

00:08:40,260 --> 00:08:43,529
because I have all the causes I can

00:08:42,510 --> 00:08:45,360
trace it back to

00:08:43,529 --> 00:08:48,180
the route and our uncles all can also

00:08:45,360 --> 00:08:52,019
trace which other things competed and

00:08:48,180 --> 00:08:53,879
which one okay so that's that's that's

00:08:52,019 --> 00:08:55,680
the high level cause-and-effect data

00:08:53,879 --> 00:08:57,990
structure how do we get these

00:08:55,680 --> 00:09:00,319
measurements because that is also bit of

00:08:57,990 --> 00:09:03,809
a challenge the JavaScript is really bad

00:09:00,319 --> 00:09:06,569
now if we look at how can we measure if

00:09:03,809 --> 00:09:07,499
we take the basic high level technical

00:09:06,569 --> 00:09:10,259
process

00:09:07,499 --> 00:09:11,910
it's the browser doing a request through

00:09:10,259 --> 00:09:14,910
the web server to the application server

00:09:11,910 --> 00:09:18,660
and the response going back doing it in

00:09:14,910 --> 00:09:21,569
JavaScript means you know what really

00:09:18,660 --> 00:09:25,199
happened on the browser but the quality

00:09:21,569 --> 00:09:27,689
of the data is really poor if you loo

00:09:25,199 --> 00:09:30,959
use the Apache access locks for example

00:09:27,689 --> 00:09:33,240
you actually only know at URL level what

00:09:30,959 --> 00:09:35,930
happened and but you don't know what was

00:09:33,240 --> 00:09:39,449
in there and what wide was put in there

00:09:35,930 --> 00:09:42,120
if you dig a little deeper some tools

00:09:39,449 --> 00:09:44,699
supports sniffing so you extract the

00:09:42,120 --> 00:09:46,949
HTML so you can know in detail what was

00:09:44,699 --> 00:09:49,769
put in there but you still don't know

00:09:46,949 --> 00:09:53,040
why the only place you know why is at

00:09:49,769 --> 00:09:55,980
the application server level so what we

00:09:53,040 --> 00:09:59,220
chose as an implementation strategy is

00:09:55,980 --> 00:10:01,709
to do a hybrid measure as many details

00:09:59,220 --> 00:10:05,399
as possible at the application server

00:10:01,709 --> 00:10:07,470
level tag everything with an ID and then

00:10:05,399 --> 00:10:09,899
those IDs get shipped to the browser

00:10:07,470 --> 00:10:13,110
where we know what happened to it

00:10:09,899 --> 00:10:14,550
and in case of users like Googlebot we

00:10:13,110 --> 00:10:16,740
don't know what they did with it but we

00:10:14,550 --> 00:10:18,540
know the user agent so that's fine too

00:10:16,740 --> 00:10:23,459
we still know exactly what we ship to

00:10:18,540 --> 00:10:24,839
them and in case we do stuff on the on

00:10:23,459 --> 00:10:27,389
the client side it has to be as

00:10:24,839 --> 00:10:32,220
lightweight as possible we do as as few

00:10:27,389 --> 00:10:34,529
things as possible there so that that

00:10:32,220 --> 00:10:37,709
will give us a data so we have the data

00:10:34,529 --> 00:10:41,610
we have the advanced model how do we

00:10:37,709 --> 00:10:44,129
process it okay remember we said hey for

00:10:41,610 --> 00:10:46,670
online situations we want to be in the

00:10:44,129 --> 00:10:50,249
low millicent in the low second ranges

00:10:46,670 --> 00:10:52,139
we want to have long history in offline

00:10:50,249 --> 00:10:54,269
we want to do incremental batches hey

00:10:52,139 --> 00:10:56,640
that sounds familiar people call that a

00:10:54,269 --> 00:10:58,740
lot of architecture that

00:10:56,640 --> 00:11:00,480
that sounds really good but the nasty

00:10:58,740 --> 00:11:03,240
thing about a lot the architecture is

00:11:00,480 --> 00:11:07,080
that it is about combining the real-time

00:11:03,240 --> 00:11:07,620
and a batch part at query time so far so

00:11:07,080 --> 00:11:10,050
good

00:11:07,620 --> 00:11:12,900
but if you look at all the papers and

00:11:10,050 --> 00:11:14,850
presentations about it most of them as

00:11:12,900 --> 00:11:17,640
far as I've seen all of them

00:11:14,850 --> 00:11:20,960
they say you cut the boundary between

00:11:17,640 --> 00:11:24,390
those two at a specific millisecond and

00:11:20,960 --> 00:11:27,090
if you do that you cut the streams you

00:11:24,390 --> 00:11:29,550
cut the caused event streams that is

00:11:27,090 --> 00:11:31,910
fine if your twitter where everything is

00:11:29,550 --> 00:11:35,040
a single message that's not fine for us

00:11:31,910 --> 00:11:37,470
because if you if this is you know an

00:11:35,040 --> 00:11:39,930
idea of the traffic pattern and these

00:11:37,470 --> 00:11:43,290
streams are the visits you know cutting

00:11:39,930 --> 00:11:46,110
at a daily basis at the the you know the

00:11:43,290 --> 00:11:49,080
quiet point of the day you cut only a

00:11:46,110 --> 00:11:49,680
few if you want to do batches every 50

00:11:49,080 --> 00:11:54,600
minutes

00:11:49,680 --> 00:11:56,730
you get this this results in data that

00:11:54,600 --> 00:12:01,230
is near impossible to process for our

00:11:56,730 --> 00:12:03,930
data science guys so few years ago I sat

00:12:01,230 --> 00:12:06,660
down and I made a really complicated

00:12:03,930 --> 00:12:09,300
design and I call it this session I love

00:12:06,660 --> 00:12:11,730
the architecture which is essentially

00:12:09,300 --> 00:12:14,550
the lovely architecture with a few

00:12:11,730 --> 00:12:17,520
additions that I don't see in other

00:12:14,550 --> 00:12:20,280
presentations and the first one is

00:12:17,520 --> 00:12:22,380
bounded event streams that cause and

00:12:20,280 --> 00:12:26,360
effect relationship because that is that

00:12:22,380 --> 00:12:29,850
is paramount for us queries take time

00:12:26,360 --> 00:12:31,770
something I also miss is the the fact

00:12:29,850 --> 00:12:34,650
that everywhere I read they assume

00:12:31,770 --> 00:12:37,530
careers take zero seconds so there is no

00:12:34,650 --> 00:12:40,890
locking between expiring the data from

00:12:37,530 --> 00:12:45,360
the real-time part and etc you need that

00:12:40,890 --> 00:12:47,370
and service-orientation few years ago I

00:12:45,360 --> 00:12:51,180
introduced micro services at our company

00:12:47,370 --> 00:12:53,310
and everything we built has to fit in

00:12:51,180 --> 00:12:54,930
there we have to fit it in such a way

00:12:53,310 --> 00:13:00,000
that other people can build applications

00:12:54,930 --> 00:13:04,770
on top of it now as you might understand

00:13:00,000 --> 00:13:07,280
in terms of web browsers there is a few

00:13:04,770 --> 00:13:10,680
terms I need to explain otherwise it

00:13:07,280 --> 00:13:13,020
it's hard to understand the browser

00:13:10,680 --> 00:13:15,930
it's something that it's installed on

00:13:13,020 --> 00:13:17,700
the computer now if you open it and

00:13:15,930 --> 00:13:21,330
visit a website you usually get a cookie

00:13:17,700 --> 00:13:23,030
with a unique ID a session ID but that

00:13:21,330 --> 00:13:25,470
stays active for weeks

00:13:23,030 --> 00:13:27,870
people don't close their browser anymore

00:13:25,470 --> 00:13:30,750
they suspend them so the value is

00:13:27,870 --> 00:13:33,570
retained over a long periods of time now

00:13:30,750 --> 00:13:36,810
as I said I need bounded streams so I

00:13:33,570 --> 00:13:39,270
have to enforce a bound and that's what

00:13:36,810 --> 00:13:41,910
I call a visit if you're inactive for

00:13:39,270 --> 00:13:43,950
thirty minutes I cut it and if you're

00:13:41,910 --> 00:13:45,990
active continuously for more 12 more

00:13:43,950 --> 00:13:51,270
than 12 hours you're not human so I can

00:13:45,990 --> 00:13:52,350
cut it now and most cause and effect

00:13:51,270 --> 00:13:54,300
relationships are really only

00:13:52,350 --> 00:13:57,240
interesting when it's a human so this is

00:13:54,300 --> 00:14:01,910
this is this is fine so everything we do

00:13:57,240 --> 00:14:06,480
is towards building these visits streams

00:14:01,910 --> 00:14:08,430
so how do we process that okay the

00:14:06,480 --> 00:14:09,870
high-level design I came up with and

00:14:08,430 --> 00:14:13,320
it's this is actually the thing I'm

00:14:09,870 --> 00:14:16,080
building and I'm testing right now is

00:14:13,320 --> 00:14:18,210
that new events arrive from the

00:14:16,080 --> 00:14:19,860
measurement infrastructure which I'll

00:14:18,210 --> 00:14:21,960
show in a few minutes

00:14:19,860 --> 00:14:24,780
then I have some kind of administration

00:14:21,960 --> 00:14:27,090
about the active visits you know people

00:14:24,780 --> 00:14:28,740
actively on the website and when they

00:14:27,090 --> 00:14:33,270
started and have been active for the

00:14:28,740 --> 00:14:36,630
last time etc that visit ID is generated

00:14:33,270 --> 00:14:40,290
and tagged on to the measurement those

00:14:36,630 --> 00:14:42,690
go out in real time via Kafka so others

00:14:40,290 --> 00:14:45,450
can use their real time stream with the

00:14:42,690 --> 00:14:48,930
visit IDs but they're also persisted in

00:14:45,450 --> 00:14:51,090
a buffer and in a time every so many

00:14:48,930 --> 00:14:54,600
minutes I extract the visits that have

00:14:51,090 --> 00:14:57,030
been completed into files those get

00:14:54,600 --> 00:15:01,020
stored on HDFS so you can do large-scale

00:14:57,030 --> 00:15:02,670
queries and analytics on that in case

00:15:01,020 --> 00:15:04,650
you want to build an application against

00:15:02,670 --> 00:15:06,660
this that actually implements the full

00:15:04,650 --> 00:15:09,120
session I love the architecture it will

00:15:06,660 --> 00:15:10,500
look something like this and the query

00:15:09,120 --> 00:15:13,710
boundary you see here is an

00:15:10,500 --> 00:15:15,360
administration of which visits are still

00:15:13,710 --> 00:15:17,070
in the stream and not yet in the batch

00:15:15,360 --> 00:15:18,930
layer and vice versa

00:15:17,070 --> 00:15:21,140
and all the locking that has to do with

00:15:18,930 --> 00:15:23,760
currying and inspiring those things I

00:15:21,140 --> 00:15:24,779
have a design I'm not going to build it

00:15:23,760 --> 00:15:27,570
it's too

00:15:24,779 --> 00:15:29,670
nobody needs it because talking to all

00:15:27,570 --> 00:15:33,300
the other people that build applications

00:15:29,670 --> 00:15:36,660
what I see is that most only need the

00:15:33,300 --> 00:15:38,760
real-time stream in case they want to do

00:15:36,660 --> 00:15:41,430
stuff with long-term history of a

00:15:38,760 --> 00:15:44,730
customer of a visitor we can have a

00:15:41,430 --> 00:15:47,070
small aggregate pre-computed which may

00:15:44,730 --> 00:15:48,660
be one or two kilobytes with the

00:15:47,070 --> 00:15:50,610
products they're interested in the

00:15:48,660 --> 00:15:53,399
categories are interested in and things

00:15:50,610 --> 00:15:56,190
like that and just load them in memory

00:15:53,399 --> 00:15:57,899
in the stream component as soon as you

00:15:56,190 --> 00:16:00,899
see the first event with that customer

00:15:57,899 --> 00:16:03,120
ID and of course you have the batch

00:16:00,899 --> 00:16:08,610
operation processes that now can run

00:16:03,120 --> 00:16:10,620
every 15 minutes now the privacy thing I

00:16:08,610 --> 00:16:12,690
mentioned earlier is a bit of a question

00:16:10,620 --> 00:16:14,700
how do you handle that how do you how

00:16:12,690 --> 00:16:17,420
can you do the privacy analytics at

00:16:14,700 --> 00:16:20,610
long-term now privacy protection says

00:16:17,420 --> 00:16:23,160
identifiable data cannot be used for

00:16:20,610 --> 00:16:27,660
personally identifiable profiling over

00:16:23,160 --> 00:16:29,850
more than two years and and that is

00:16:27,660 --> 00:16:32,490
really about data elements that you can

00:16:29,850 --> 00:16:34,500
use to point to this individual like IP

00:16:32,490 --> 00:16:38,430
address and customer number and things

00:16:34,500 --> 00:16:41,310
like that but what is profiling really

00:16:38,430 --> 00:16:44,760
over long term it's looking for behavior

00:16:41,310 --> 00:16:47,730
patterns because the personalized things

00:16:44,760 --> 00:16:49,529
lose value when they're more than 1 1

00:16:47,730 --> 00:16:51,540
and a half years old then they're not as

00:16:49,529 --> 00:16:53,790
relevant anymore for the behavior

00:16:51,540 --> 00:16:57,690
patterns of that visitor people change

00:16:53,790 --> 00:17:00,000
and after about a year it becomes less

00:16:57,690 --> 00:17:04,860
relevant so this is only about more

00:17:00,000 --> 00:17:06,809
anonymous profiling and the query

00:17:04,860 --> 00:17:09,720
pattern you see in those kinds of

00:17:06,809 --> 00:17:11,850
analytics are usually about group by

00:17:09,720 --> 00:17:15,929
customer ID because I want to know what

00:17:11,850 --> 00:17:18,179
that person did over a longer period but

00:17:15,929 --> 00:17:22,169
if that's the real question then these

00:17:18,179 --> 00:17:24,059
queries give the same answer because if

00:17:22,169 --> 00:17:26,760
you encrypt it or you hash it or even

00:17:24,059 --> 00:17:29,040
salted in hashes the group I will still

00:17:26,760 --> 00:17:32,220
yield the same result hash collisions

00:17:29,040 --> 00:17:35,330
and hash relations are if you look for

00:17:32,220 --> 00:17:37,559
large-scale patents are not important so

00:17:35,330 --> 00:17:39,450
what we chose

00:17:37,559 --> 00:17:41,999
that for the data in motion the

00:17:39,450 --> 00:17:43,950
streaming stuff we persist that in Kafka

00:17:41,999 --> 00:17:47,070
and that expires after a couple of weeks

00:17:43,950 --> 00:17:50,899
and for the data at rest the

00:17:47,070 --> 00:17:54,389
identifiable ones are simply deleted and

00:17:50,899 --> 00:17:57,749
the anonymous ones are salted with a

00:17:54,389 --> 00:18:00,600
yearly salt so we in our IT operations

00:17:57,749 --> 00:18:03,090
we have a system that will have a secret

00:18:00,600 --> 00:18:05,580
salt everything it's salted with that

00:18:03,090 --> 00:18:07,919
hashed and we only persist the hash and

00:18:05,580 --> 00:18:10,230
nobody not even me not an order data

00:18:07,919 --> 00:18:12,509
says science guys have access to the

00:18:10,230 --> 00:18:15,059
salt so nobody can reverse-engineer it

00:18:12,509 --> 00:18:19,619
and by splitting the access permissions

00:18:15,059 --> 00:18:22,139
between the two we keep that safe so

00:18:19,619 --> 00:18:24,570
what this is that is that unnamed

00:18:22,139 --> 00:18:28,710
individuals we can do analysis over the

00:18:24,570 --> 00:18:31,529
last two years but anonymized we can do

00:18:28,710 --> 00:18:32,009
analysis on a yearly basis for much

00:18:31,529 --> 00:18:33,990
longer

00:18:32,009 --> 00:18:37,019
but it's anonymized and you still have

00:18:33,990 --> 00:18:41,159
all the details to do the real business

00:18:37,019 --> 00:18:43,919
value in our analytics so how do you

00:18:41,159 --> 00:18:47,249
build something like this well the

00:18:43,919 --> 00:18:50,220
design I created is I'm going into a

00:18:47,249 --> 00:18:53,039
little bit more detail now is that we're

00:18:50,220 --> 00:18:54,840
going to introduce a measuring several

00:18:53,039 --> 00:18:56,999
measuring components into our web

00:18:54,840 --> 00:18:59,190
front-end part of it is in the

00:18:56,999 --> 00:19:01,950
application server that records the

00:18:59,190 --> 00:19:05,970
details of what and why and puts that in

00:19:01,950 --> 00:19:08,490
Kafka and puts the IDS of those

00:19:05,970 --> 00:19:14,299
measurements in the HTML that are then

00:19:08,490 --> 00:19:17,999
via JavaScript put back also into Kafka

00:19:14,299 --> 00:19:19,710
that's mostly about what was put on the

00:19:17,999 --> 00:19:23,639
screen and what was clicks and things

00:19:19,710 --> 00:19:26,580
like that then the session riser which

00:19:23,639 --> 00:19:29,610
has showed you just before with one

00:19:26,580 --> 00:19:31,980
extra thing and that's geoip we would

00:19:29,610 --> 00:19:33,720
like to know what country that visitor

00:19:31,980 --> 00:19:36,960
came from was it Netherlands Belgium

00:19:33,720 --> 00:19:40,049
Germany US whatever just the country

00:19:36,960 --> 00:19:46,470
code and we output that as I showed

00:19:40,049 --> 00:19:49,259
earlier in Kafka and as files this part

00:19:46,470 --> 00:19:51,399
is the personally identifiable stuff so

00:19:49,259 --> 00:19:54,129
from there we have an anonymous Asian

00:19:51,399 --> 00:19:57,609
filter that anonymizes it and outputs

00:19:54,129 --> 00:20:01,149
the date the same data anonymized also

00:19:57,609 --> 00:20:03,549
in Kafka and also as files and those can

00:20:01,149 --> 00:20:06,119
be then used for dashboarding and for

00:20:03,549 --> 00:20:08,469
recommender systems and things like that

00:20:06,119 --> 00:20:12,969
now a couple of years ago I started my

00:20:08,469 --> 00:20:14,379
first prototype to build this ah this

00:20:12,969 --> 00:20:16,719
gives a good impression of what it was

00:20:14,379 --> 00:20:19,059
like because I tried it at that time

00:20:16,719 --> 00:20:21,339
with using Apache storm stream

00:20:19,059 --> 00:20:24,909
processing low latency lots of people

00:20:21,339 --> 00:20:29,229
using it sounds like a plan until you

00:20:24,909 --> 00:20:32,710
try to do it back then the API is for me

00:20:29,229 --> 00:20:34,419
really unfriendly this was actually

00:20:32,710 --> 00:20:36,909
copied and pasted at last week from

00:20:34,419 --> 00:20:39,369
their website so the API hasn't changed

00:20:36,909 --> 00:20:41,529
much you have to make sure that the

00:20:39,369 --> 00:20:46,509
names of the bolts it's all match

00:20:41,529 --> 00:20:49,899
otherwise it simply doesn't work it's an

00:20:46,509 --> 00:20:51,999
at least once streaming thing if you

00:20:49,899 --> 00:20:53,649
need exactly once you go to trident if

00:20:51,999 --> 00:20:56,259
you go to try did you go to micro

00:20:53,649 --> 00:21:00,549
batching and that means latency much

00:20:56,259 --> 00:21:02,710
more than I want and storm when I tried

00:21:00,549 --> 00:21:04,749
it is completely stateless now a few

00:21:02,710 --> 00:21:07,839
weeks ago they said it they now have

00:21:04,749 --> 00:21:09,759
stateful things but the thing I tried is

00:21:07,839 --> 00:21:12,369
completely stateless so building in the

00:21:09,759 --> 00:21:17,919
state of the visit is incredibly hard

00:21:12,369 --> 00:21:19,859
and at that time it was said you can run

00:21:17,919 --> 00:21:22,239
it on yarn but I never get that to run

00:21:19,859 --> 00:21:25,539
perhaps that now works but back then it

00:21:22,239 --> 00:21:26,979
didn't so how about spark streaming you

00:21:25,539 --> 00:21:29,139
know lots of libraries and tools are

00:21:26,979 --> 00:21:32,759
very good toolkit but also micro

00:21:29,139 --> 00:21:35,739
batching and I don't want that latency

00:21:32,759 --> 00:21:38,409
so then came last year at Berlin

00:21:35,739 --> 00:21:40,149
buzzwords I talked to Stefan and I asked

00:21:38,409 --> 00:21:42,039
him some questions because I already had

00:21:40,149 --> 00:21:44,919
a lot quite a bit of experience in doing

00:21:42,039 --> 00:21:47,919
it with storm how does it work in flink

00:21:44,919 --> 00:21:50,379
well flank is also low latency but it's

00:21:47,919 --> 00:21:52,389
exactly once and that's mainly because

00:21:50,379 --> 00:21:56,109
it has the recoverability of the stage

00:21:52,389 --> 00:21:58,989
built in and it runs on yarn and the

00:21:56,109 --> 00:22:01,119
state managed in the framework also

00:21:58,989 --> 00:22:03,489
supports all these checkpoints and safe

00:22:01,119 --> 00:22:04,790
points and things that make it easy to

00:22:03,489 --> 00:22:07,600
recover after

00:22:04,790 --> 00:22:10,280
failure or restart of the application

00:22:07,600 --> 00:22:13,370
it's also really nice is that as a

00:22:10,280 --> 00:22:15,650
concept of Windows a window is a group

00:22:13,370 --> 00:22:18,680
of elements that you can combine into a

00:22:15,650 --> 00:22:22,580
well extremely streaming lis built up

00:22:18,680 --> 00:22:28,340
batch which makes it really useful for

00:22:22,580 --> 00:22:32,000
the type of analysis I want to do and to

00:22:28,340 --> 00:22:36,190
me this feature event time is the

00:22:32,000 --> 00:22:38,630
biggest plus of flink I've ever seen it

00:22:36,190 --> 00:22:42,140
means that if you bring down the

00:22:38,630 --> 00:22:44,420
application for say a day extreme case

00:22:42,140 --> 00:22:47,960
and you bring it up again so it reads

00:22:44,420 --> 00:22:50,240
from Kafka then all the events of timing

00:22:47,960 --> 00:22:54,230
out 30 minutes in the 12 hours are based

00:22:50,240 --> 00:22:56,840
on the time in the data so you can

00:22:54,230 --> 00:22:59,630
process a day worth of data it may be I

00:22:56,840 --> 00:23:02,630
don't know 20 minutes and still have all

00:22:59,630 --> 00:23:08,540
the timeouts correct that is the biggest

00:23:02,630 --> 00:23:10,520
plus of link there are challenges the

00:23:08,540 --> 00:23:11,720
first one I ran into was reading and

00:23:10,520 --> 00:23:14,390
writing from HBase

00:23:11,720 --> 00:23:16,520
on a secure cluster so I fixed that and

00:23:14,390 --> 00:23:19,340
we still have the problem that after

00:23:16,520 --> 00:23:22,490
seven days the Hadoop delegation tokens

00:23:19,340 --> 00:23:24,290
timeout and then any job dies also the

00:23:22,490 --> 00:23:27,200
spark jobs we run on the cluster does

00:23:24,290 --> 00:23:31,820
just die after seven days it's a setting

00:23:27,200 --> 00:23:34,040
but still it's it's a finite time and my

00:23:31,820 --> 00:23:36,380
windows the data in my windows is too

00:23:34,040 --> 00:23:38,360
big to fit into memory so right now I'm

00:23:36,380 --> 00:23:40,910
shoving them into HBase that's what I

00:23:38,360 --> 00:23:43,190
haven't graphs a little later also but I

00:23:40,910 --> 00:23:46,270
have to evaluate the rocks DB which is

00:23:43,190 --> 00:23:50,960
in the newer versions of link available

00:23:46,270 --> 00:23:53,360
also very careful the exactly ones is on

00:23:50,960 --> 00:23:55,970
the processing and on the kafka inputs

00:23:53,360 --> 00:23:58,490
but not on the Kafka output in case of a

00:23:55,970 --> 00:24:00,440
distortion and a replay of some events

00:23:58,490 --> 00:24:04,820
you get duplicate events in the Kafka

00:24:00,440 --> 00:24:08,810
output something to be aware of so how

00:24:04,820 --> 00:24:11,780
do I assign deficit IDs in string the

00:24:08,810 --> 00:24:13,790
window implementation buffers until the

00:24:11,780 --> 00:24:15,260
window is complete and then flushes it

00:24:13,790 --> 00:24:17,630
so that's too long

00:24:15,260 --> 00:24:18,440
so I had to build my own custom operator

00:24:17,630 --> 00:24:20,570
I had somehow

00:24:18,440 --> 00:24:23,720
from the data artisan guys thank you

00:24:20,570 --> 00:24:27,409
very much for that so I built that and

00:24:23,720 --> 00:24:30,620
how does that look well there is the

00:24:27,409 --> 00:24:34,460
sign visit ID operator that received the

00:24:30,620 --> 00:24:37,129
events has a bit of state and shoves

00:24:34,460 --> 00:24:39,769
them out again then they're stored in

00:24:37,129 --> 00:24:41,960
HBase and in Kafka and then threw in on

00:24:39,769 --> 00:24:46,730
an anonymization filter and they're also

00:24:41,960 --> 00:24:50,240
stored in HBase and Kafka then the

00:24:46,730 --> 00:24:52,159
watermarks arrived and based on the

00:24:50,240 --> 00:24:54,679
watermarks I say hey there is an expire

00:24:52,159 --> 00:24:58,549
of this visit i time it out and I send

00:24:54,679 --> 00:25:00,919
out an end of visit event those are then

00:24:58,549 --> 00:25:03,470
grouped in a window to avoid too many

00:25:00,919 --> 00:25:05,929
files on the Hadoop cluster I group the

00:25:03,470 --> 00:25:08,779
the end of visit events and then when I

00:25:05,929 --> 00:25:11,539
have a window of intended visits I pull

00:25:08,779 --> 00:25:17,120
out all the events from the HBase and I

00:25:11,539 --> 00:25:19,309
store them in park' files when I started

00:25:17,120 --> 00:25:22,789
I made this design and then when I

00:25:19,309 --> 00:25:24,710
started to build it I turns out that you

00:25:22,789 --> 00:25:28,129
can only have one output type of an

00:25:24,710 --> 00:25:30,169
operator instead of two so I had to do

00:25:28,129 --> 00:25:33,559
some stuff and the watermarks are really

00:25:30,169 --> 00:25:36,379
really important so what I ended up

00:25:33,559 --> 00:25:38,240
building is well this is the same but I

00:25:36,379 --> 00:25:42,799
had to multiplex them because one type

00:25:38,240 --> 00:25:44,629
of output and then they go out and then

00:25:42,799 --> 00:25:47,840
I pull out the ended visit events again

00:25:44,629 --> 00:25:50,870
and there I had to generate new bottom

00:25:47,840 --> 00:25:53,929
arts because without those watermarks

00:25:50,870 --> 00:25:56,269
the windows don't work and from there

00:25:53,929 --> 00:25:58,789
it's more or less the same while

00:25:56,269 --> 00:26:00,980
building this I realized that those end

00:25:58,789 --> 00:26:02,899
of visiting events may be useful for

00:26:00,980 --> 00:26:08,029
downstream applications so I decided to

00:26:02,899 --> 00:26:10,100
keep them in if you're building

00:26:08,029 --> 00:26:13,639
something like this debugging the

00:26:10,100 --> 00:26:16,429
watermarks is essential and it turns out

00:26:13,639 --> 00:26:19,700
that they're quite tricky to get right

00:26:16,429 --> 00:26:22,399
if your data is too messy so that's not

00:26:19,700 --> 00:26:27,440
a flink problem is really how clean is

00:26:22,399 --> 00:26:29,509
your data so I needed to do some

00:26:27,440 --> 00:26:31,550
debugging of the combination of the

00:26:29,509 --> 00:26:33,230
watermark and event and

00:26:31,550 --> 00:26:36,170
do that I wrote a very simple operator

00:26:33,230 --> 00:26:37,820
that that simply prints them because in

00:26:36,170 --> 00:26:39,560
an operator code you can process

00:26:37,820 --> 00:26:41,060
watermarks and process the events and

00:26:39,560 --> 00:26:45,590
all it does is prints them to the

00:26:41,060 --> 00:26:47,450
console for development purposes now if

00:26:45,590 --> 00:26:50,750
you're building a streaming application

00:26:47,450 --> 00:26:57,380
you have to realize that requirements

00:26:50,750 --> 00:27:00,650
will change it happens and what we do is

00:26:57,380 --> 00:27:05,750
we use Apache Avro the ideal schema

00:27:00,650 --> 00:27:07,340
language to define the schemas and that

00:27:05,750 --> 00:27:09,920
is nice because it generates really

00:27:07,340 --> 00:27:11,840
useable Java classes and it supports

00:27:09,920 --> 00:27:14,840
name-based schema evolution

00:27:11,840 --> 00:27:16,880
out-of-the-box so if you have a class

00:27:14,840 --> 00:27:20,930
with a new if you have a record with a

00:27:16,880 --> 00:27:25,240
newer schema you can simply read it

00:27:20,930 --> 00:27:29,090
using Apache Avro in the newer situation

00:27:25,240 --> 00:27:32,540
we have chosen parque to persist the

00:27:29,090 --> 00:27:34,880
data in files because I'm writing the

00:27:32,540 --> 00:27:37,790
event streams on a per session basis on

00:27:34,880 --> 00:27:40,040
a per visit basis what you see is in

00:27:37,790 --> 00:27:43,130
that range they all have the same IP

00:27:40,040 --> 00:27:44,810
address same user agent most of them

00:27:43,130 --> 00:27:47,570
have the same customer number and a lot

00:27:44,810 --> 00:27:50,150
of attributes are all the same so using

00:27:47,570 --> 00:27:53,900
the column-oriented parque format makes

00:27:50,150 --> 00:27:56,060
that compress really really well also

00:27:53,900 --> 00:27:58,160
porque is supported by the tools we use

00:27:56,060 --> 00:28:01,790
to read and query again so that's also

00:27:58,160 --> 00:28:05,120
big plus and writing our records into

00:28:01,790 --> 00:28:07,310
park' files is really easy because part

00:28:05,120 --> 00:28:11,930
a has actually actually has supports for

00:28:07,310 --> 00:28:13,970
that now in the streaming scenario we

00:28:11,930 --> 00:28:15,650
use Kafka like I mentioned so it's a

00:28:13,970 --> 00:28:18,170
highly it's a high throughput low

00:28:15,650 --> 00:28:20,870
latency transport pipe that persists the

00:28:18,170 --> 00:28:24,500
data for a couple of weeks so how do we

00:28:20,870 --> 00:28:27,230
put that record we have as a byte array

00:28:24,500 --> 00:28:31,070
in Kafka okay how do you see realize

00:28:27,230 --> 00:28:34,580
that the important thing to realize is

00:28:31,070 --> 00:28:39,010
that Apache Avro needs the original

00:28:34,580 --> 00:28:43,220
schema to deserialize a byte array again

00:28:39,010 --> 00:28:44,870
so you need the original schema now in

00:28:43,220 --> 00:28:45,410
the test case I'm running right now the

00:28:44,870 --> 00:28:48,170
original

00:28:45,410 --> 00:28:50,540
schema is like 10 kilobytes and the

00:28:48,170 --> 00:28:52,700
record is like foreign bytes and I don't

00:28:50,540 --> 00:28:55,000
want to attach the entire schema to

00:28:52,700 --> 00:28:59,270
every message so how do you do that

00:28:55,000 --> 00:29:01,460
because the schema will change if the

00:28:59,270 --> 00:29:03,560
schema changes and you know you have

00:29:01,460 --> 00:29:06,230
like say you persist the messages for

00:29:03,560 --> 00:29:08,540
four weeks and you have two weeks of old

00:29:06,230 --> 00:29:10,580
schema and two weeks of new schema and

00:29:08,540 --> 00:29:13,040
you hook up a new application it must be

00:29:10,580 --> 00:29:16,790
able to read all the records how do you

00:29:13,040 --> 00:29:19,340
do that well that is something I'm

00:29:16,790 --> 00:29:22,850
working on right now it's an opera

00:29:19,340 --> 00:29:26,240
project where I've said I'm going to

00:29:22,850 --> 00:29:28,610
make a wrapper around the normal

00:29:26,240 --> 00:29:31,460
serialize afro record that I call a

00:29:28,610 --> 00:29:34,250
message which essentially contains the

00:29:31,460 --> 00:29:36,790
fingerprint of the schema if you combine

00:29:34,250 --> 00:29:40,160
that with a pluggable schema database

00:29:36,790 --> 00:29:43,300
which you can do in well any system

00:29:40,160 --> 00:29:47,600
really maybe a property file maybe maybe

00:29:43,300 --> 00:29:49,700
a Redis or whatever then you can store

00:29:47,600 --> 00:29:51,650
all the versions of all the schemas in

00:29:49,700 --> 00:29:54,500
there and retrieve them by fingerprint

00:29:51,650 --> 00:29:56,510
so any une consuming system can then

00:29:54,500 --> 00:30:01,040
deserialize the record and read it in

00:29:56,510 --> 00:30:03,410
their local version of the schema now

00:30:01,040 --> 00:30:05,090
this at bottom we have been doing these

00:30:03,410 --> 00:30:08,300
Big Data things for quite a while

00:30:05,090 --> 00:30:10,700
so you may realize that it's this is not

00:30:08,300 --> 00:30:14,030
a hype this is what most of our teams

00:30:10,700 --> 00:30:17,120
are required to do most of our

00:30:14,030 --> 00:30:19,930
development teams use HBase and the

00:30:17,120 --> 00:30:22,190
Hadoop cluster to do part of their work

00:30:19,930 --> 00:30:25,810
so if you think this is cool

00:30:22,190 --> 00:30:30,400
don't hesitate join us contact me and

00:30:25,810 --> 00:30:30,400
talk questions

00:30:47,240 --> 00:30:51,750
hello I don't thank for the joke so I

00:30:50,309 --> 00:30:54,480
have a question regarding this our

00:30:51,750 --> 00:30:57,390
schema mm why don't you guys use our

00:30:54,480 --> 00:31:01,470
registry for starting your schema sorry

00:30:57,390 --> 00:31:03,419
our registry schema registry for storing

00:31:01,470 --> 00:31:05,610
a schema that is already built one in

00:31:03,419 --> 00:31:07,080
yeah I think confluence right I wrote

00:31:05,610 --> 00:31:10,650
one yeah a confluence yeah yeah yeah I

00:31:07,080 --> 00:31:13,230
know I know but for now I'm saying that

00:31:10,650 --> 00:31:16,110
within the Afro project I'm making it

00:31:13,230 --> 00:31:18,360
pluggable so if somebody says I want to

00:31:16,110 --> 00:31:20,659
use the confluent implementation they

00:31:18,360 --> 00:31:23,580
can they can simply attach it to that

00:31:20,659 --> 00:31:26,130
pluggable interface but if somebody says

00:31:23,580 --> 00:31:28,230
no I just want to use property files or

00:31:26,130 --> 00:31:30,960
I want to use a proprietary thing like

00:31:28,230 --> 00:31:33,600
we have internally then that becomes

00:31:30,960 --> 00:31:36,000
also possible so I want to want to keep

00:31:33,600 --> 00:31:37,740
that a bit more flexible and something

00:31:36,000 --> 00:31:40,190
I'm also building in to keep it a bit

00:31:37,740 --> 00:31:43,620
more flexible is that the actual

00:31:40,190 --> 00:31:46,409
serialization of the message body I want

00:31:43,620 --> 00:31:48,900
it to be pluggable also in order to

00:31:46,409 --> 00:31:51,179
support encryption so if somebody says

00:31:48,900 --> 00:31:54,000
no I want to persist all the streaming

00:31:51,179 --> 00:31:57,030
messages in an encrypted form in Kafka

00:31:54,000 --> 00:31:58,409
that is also possible but still a

00:31:57,030 --> 00:32:02,659
work-in-progress it's not yet finished

00:31:58,409 --> 00:32:02,659
but I'm working on it yeah

00:32:05,390 --> 00:32:13,780
I I you said you had to put the state

00:32:09,110 --> 00:32:18,200
into HBase so what was the size of your

00:32:13,780 --> 00:32:20,059
window state on each worker okay um I

00:32:18,200 --> 00:32:22,429
did some calculations because I know the

00:32:20,059 --> 00:32:24,890
traffic level of our website and the

00:32:22,429 --> 00:32:29,059
estimate is that we have to keep about

00:32:24,890 --> 00:32:31,450
we will get something like 50,000 events

00:32:29,059 --> 00:32:35,360
per second during the peak of our season

00:32:31,450 --> 00:32:36,980
and the events are in the experiments

00:32:35,360 --> 00:32:40,100
I'm running now they're about half a

00:32:36,980 --> 00:32:42,410
kilobyte in size each and then with all

00:32:40,100 --> 00:32:46,090
the timeouts taken into account that

00:32:42,410 --> 00:32:49,490
that runs into the to many gigabytes in

00:32:46,090 --> 00:32:52,610
RAM that is so that's why I'm saying and

00:32:49,490 --> 00:32:55,220
I have to persist it to disk or I have

00:32:52,610 --> 00:32:58,250
to convince the boss to get a lot more

00:32:55,220 --> 00:33:00,620
servers to keep it in memory but you

00:32:58,250 --> 00:33:04,130
know persisting it to disk and I'm doing

00:33:00,620 --> 00:33:06,370
low tests using HBase that that works

00:33:04,130 --> 00:33:06,370
quite well

00:33:10,299 --> 00:33:17,030
hi nice the phone hey thanks for the

00:33:13,850 --> 00:33:19,130
talk quick question on this like

00:33:17,030 --> 00:33:20,900
security and expiry of the access tokens

00:33:19,130 --> 00:33:22,400
what do you actually do to work around

00:33:20,900 --> 00:33:24,290
this do you have something like a script

00:33:22,400 --> 00:33:26,270
that periodically yeah just make sure

00:33:24,290 --> 00:33:28,760
the tropas yeah completely killed and

00:33:26,270 --> 00:33:30,919
restarted sort of new tokens yes

00:33:28,760 --> 00:33:34,309
the timeout set for the hadoop

00:33:30,919 --> 00:33:35,570
delegation tokens is 168 hours that's

00:33:34,309 --> 00:33:38,929
the default setting in the Hadoop

00:33:35,570 --> 00:33:42,169
cluster it turns out for a very strange

00:33:38,929 --> 00:33:44,120
reason that the the jobs died after

00:33:42,169 --> 00:33:46,040
exactly a hundred and seventy three and

00:33:44,120 --> 00:33:48,860
a half hours so that's five and a half

00:33:46,040 --> 00:33:50,929
hours later and it's so exact that I've

00:33:48,860 --> 00:33:52,910
run the experiment several times and

00:33:50,929 --> 00:33:55,940
they all died within a range of 30

00:33:52,910 --> 00:33:58,730
seconds so for some reason that's the

00:33:55,940 --> 00:34:00,770
cutoff point and what we have now is for

00:33:58,730 --> 00:34:03,020
the fling jobs running on a cluster we

00:34:00,770 --> 00:34:05,540
have picked a point in the week where

00:34:03,020 --> 00:34:07,309
it's most quiet and there we simply kill

00:34:05,540 --> 00:34:10,010
them and restart them so that's once

00:34:07,309 --> 00:34:11,899
every 168 hours so we have a bit of room

00:34:10,010 --> 00:34:16,060
to spare and because we control the

00:34:11,899 --> 00:34:16,060
restart that works quite well for now

00:34:17,090 --> 00:34:22,350
are you actually using a safe point or

00:34:19,530 --> 00:34:23,940
so to resume from from the previous

00:34:22,350 --> 00:34:26,370
execution after you basically kill it

00:34:23,940 --> 00:34:29,880
and restart it or eventually let it pick

00:34:26,370 --> 00:34:30,690
up the applications we have right now in

00:34:29,880 --> 00:34:34,950
production

00:34:30,690 --> 00:34:36,510
don't use Windows and in those specific

00:34:34,950 --> 00:34:39,750
applications with our background

00:34:36,510 --> 00:34:42,510
analytics jobs losing one or two records

00:34:39,750 --> 00:34:46,020
is not that much of a deal so at this

00:34:42,510 --> 00:34:47,790
point we don't use it yet okay then

00:34:46,020 --> 00:34:49,290
maybe the final remark I'm not sure if

00:34:47,790 --> 00:34:51,720
you've seen it there's actually a threat

00:34:49,290 --> 00:34:54,450
that is stealing exactly with this like

00:34:51,720 --> 00:34:57,000
Kerberos tokens and an exploration and

00:34:54,450 --> 00:34:59,160
so on where we're trying to add some

00:34:57,000 --> 00:35:00,510
functionality to you know attach key

00:34:59,160 --> 00:35:01,830
taps to a job so it will actually

00:35:00,510 --> 00:35:03,540
automatically renew these things Oh

00:35:01,830 --> 00:35:03,930
excellent hopefully gonna be in in a few

00:35:03,540 --> 00:35:13,260
months

00:35:03,930 --> 00:35:14,640
okay that's good thank you umm I suspect

00:35:13,260 --> 00:35:17,460
don't know why your tokens are expiring

00:35:14,640 --> 00:35:19,170
a bit after that time is because they do

00:35:17,460 --> 00:35:21,090
the renewal in advance and twelve and a

00:35:19,170 --> 00:35:23,490
half hours later all dice okay

00:35:21,090 --> 00:35:25,290
as someone who has painful experience or

00:35:23,490 --> 00:35:27,030
for Kerberos and yon I will say that

00:35:25,290 --> 00:35:29,610
actually what you do is ask the flink

00:35:27,030 --> 00:35:31,050
people to do some token renewal which

00:35:29,610 --> 00:35:32,970
can not only be done with a key tab

00:35:31,050 --> 00:35:34,950
because people hate key tabs around but

00:35:32,970 --> 00:35:37,440
actually just have something push out

00:35:34,950 --> 00:35:37,970
fresh tokens your desktop or Lucy or

00:35:37,440 --> 00:35:43,310
something like that

00:35:37,970 --> 00:35:43,310
that's what other people do okay thanks

00:35:50,070 --> 00:35:57,740
have you thought about an end-to-end ray

00:35:54,180 --> 00:36:02,880
meant when it impotency way to get

00:35:57,740 --> 00:36:05,880
exactly ones output for the Kefka sink I

00:36:02,880 --> 00:36:09,900
have thought about it I put up my idea

00:36:05,880 --> 00:36:12,540
on the flink user list but that would

00:36:09,900 --> 00:36:14,840
require quite a hefty change in the

00:36:12,540 --> 00:36:19,080
output because the idea I had is that

00:36:14,840 --> 00:36:22,590
when you output messages into Kafka you

00:36:19,080 --> 00:36:26,550
record the in the output sink in terms

00:36:22,590 --> 00:36:28,860
of state where you left periodically and

00:36:26,550 --> 00:36:32,760
then in a recovery scenario you would

00:36:28,860 --> 00:36:35,190
have the sink acts as a client and read

00:36:32,760 --> 00:36:39,420
in till the point where it sees the

00:36:35,190 --> 00:36:41,390
message that it has to output next but

00:36:39,420 --> 00:36:45,180
that would be a bit of a hefty rewrite

00:36:41,390 --> 00:36:47,430
and I haven't taken the time yet to to

00:36:45,180 --> 00:36:49,620
try to build that yet but if you feel

00:36:47,430 --> 00:36:54,680
like billing it please do we'd be useful

00:36:49,620 --> 00:36:54,680
for to everybody thank you

00:36:59,920 --> 00:37:05,110

YouTube URL: https://www.youtube.com/watch?v=qwbGQDpxmVg


