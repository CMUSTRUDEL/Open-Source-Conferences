Title: Berlin Buzzwords 2016: Stephan Ewen - Stream Processor as a Database: Building Online Applications
Publication date: 2016-06-12
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Stephan Ewen talking about "The Stream Processor as a Database: Building Online Applications directly on Streams with Apache Flink and Apache Kafka".

We present a new design pattern for data streaming applications, using Apache Flink and Apache Kafka: Building applications directly on top of the stream processor, rather than on top of key / value databases populated by data streams.

Unlike classical setups that use stream processors or libraries to pre-process / aggregate events and update a database with the results, this setup simply gives the role of the database to the stream processor - here Apache Flink -, routing queries to its workers who directly answer them from their internal state computed over the log of events - Apache Kafka.

Read more:
https://2016.berlinbuzzwords.de/session/stream-processor-database-building-online-applications-directly-streams-apache-flink-and

About Stephan Ewen:
https://2016.berlinbuzzwords.de/users/stephan-ewen

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:02,240 --> 00:00:07,410
working all right thanks for the

00:00:05,370 --> 00:00:08,880
introduction thanks everybody for coming

00:00:07,410 --> 00:00:10,440
here I hope you having a good day

00:00:08,880 --> 00:00:14,099
enjoying this nice day in the London

00:00:10,440 --> 00:00:16,710
have a good conference so far I'm Nam

00:00:14,099 --> 00:00:18,660
Stefan I'm talking about the stream

00:00:16,710 --> 00:00:23,609
processor is a database here with Apache

00:00:18,660 --> 00:00:26,490
chief link and yeah let's get started so

00:00:23,609 --> 00:00:29,970
I always start my talks with this quote

00:00:26,490 --> 00:00:31,850
just to to basically get the said that

00:00:29,970 --> 00:00:34,230
basically set the stage for the kind of

00:00:31,850 --> 00:00:36,329
kind of twist of stream processing that

00:00:34,230 --> 00:00:37,590
that I'm talking about and the way we're

00:00:36,329 --> 00:00:40,320
thinking about stream processing with

00:00:37,590 --> 00:00:41,670
flink because a lot of people still

00:00:40,320 --> 00:00:43,410
think stream processing is something

00:00:41,670 --> 00:00:46,829
that is tailored towards an issue of low

00:00:43,410 --> 00:00:48,180
latency applications and what I really

00:00:46,829 --> 00:00:49,950
have in mind when I say stream

00:00:48,180 --> 00:00:52,140
processing here and it's kind of the

00:00:49,950 --> 00:00:53,850
paradigm behind the way flink is

00:00:52,140 --> 00:00:56,399
developing is that stream processing is

00:00:53,850 --> 00:00:58,320
actually not just a like a low latency

00:00:56,399 --> 00:00:59,940
real-time thing it's it's really a

00:00:58,320 --> 00:01:02,850
paradigm for continuous processing on

00:00:59,940 --> 00:01:05,040
continuous data continuous data being

00:01:02,850 --> 00:01:08,280
basically all data that is not dumped at

00:01:05,040 --> 00:01:10,049
you in like in a terabyte at an instant

00:01:08,280 --> 00:01:12,720
but it's really produced over time you

00:01:10,049 --> 00:01:15,210
know locks sensors everything that you

00:01:12,720 --> 00:01:17,430
but yeah that gets appended and created

00:01:15,210 --> 00:01:19,830
over time accumulates to very large

00:01:17,430 --> 00:01:23,070
amounts but but it's created over time

00:01:19,830 --> 00:01:24,509
and you actually I'm processing this in

00:01:23,070 --> 00:01:27,090
a continuous fashion following this

00:01:24,509 --> 00:01:29,759
continuous paradigm this is a very nice

00:01:27,090 --> 00:01:31,560
program that's all so many problems and

00:01:29,759 --> 00:01:34,920
that's really what our roof link is

00:01:31,560 --> 00:01:37,530
about I'm going to just spend a minute

00:01:34,920 --> 00:01:38,640
or two on a on a flink 1014 for those

00:01:37,530 --> 00:01:40,590
that are not too familiar with the

00:01:38,640 --> 00:01:42,710
system so far and then and then dive

00:01:40,590 --> 00:01:45,750
into the stream processors the database

00:01:42,710 --> 00:01:49,110
so Apache chief link at its core is a

00:01:45,750 --> 00:01:50,939
streaming data flow system for for

00:01:49,110 --> 00:01:52,649
streaming applications so the the bottom

00:01:50,939 --> 00:01:56,250
layer is the streaming data flow runtime

00:01:52,649 --> 00:01:58,170
it's it's it's a run term of operators

00:01:56,250 --> 00:02:01,110
and streams connected in a directed

00:01:58,170 --> 00:02:02,820
acyclic graph um that that moves data

00:02:01,110 --> 00:02:04,439
between parallel instances processes it

00:02:02,820 --> 00:02:06,930
transforms it produces streams consume

00:02:04,439 --> 00:02:09,360
streams and on top of that of that run

00:02:06,930 --> 00:02:11,069
time we've built to API stream

00:02:09,360 --> 00:02:13,840
processing and API in a batch processing

00:02:11,069 --> 00:02:15,849
API the batch processing API

00:02:13,840 --> 00:02:18,010
also execute on the stream processor so

00:02:15,849 --> 00:02:19,330
it's really basically interpreting batch

00:02:18,010 --> 00:02:21,250
as a special case of streaming and

00:02:19,330 --> 00:02:22,390
running it on a streaming rundt time we

00:02:21,250 --> 00:02:23,920
currently have two different AP ice

00:02:22,390 --> 00:02:26,440
because the batch processing at the i

00:02:23,920 --> 00:02:28,750
has a bit of extra a bit of extra

00:02:26,440 --> 00:02:30,310
semantics and syntactic sugar for four

00:02:28,750 --> 00:02:31,840
cases that just become a little simpler

00:02:30,310 --> 00:02:34,900
if you think of static data sets rather

00:02:31,840 --> 00:02:36,280
than continuous data sets and on top of

00:02:34,900 --> 00:02:38,019
these two FB i--'s there's a bunch of

00:02:36,280 --> 00:02:39,489
libraries for example for complex event

00:02:38,019 --> 00:02:43,150
processing for graphs or machine

00:02:39,489 --> 00:02:44,739
learning all right if you're if you're

00:02:43,150 --> 00:02:46,239
using flink what you're basically doing

00:02:44,739 --> 00:02:48,690
is you're writing a functional program

00:02:46,239 --> 00:02:51,099
in either the java or the scala api's

00:02:48,690 --> 00:02:51,880
you're working with with data streams

00:02:51,099 --> 00:02:54,030
you're applying furniture

00:02:51,880 --> 00:02:56,950
transformations like maps you can

00:02:54,030 --> 00:02:58,780
reorganize data you can apply windows

00:02:56,950 --> 00:03:00,459
and then do aggregation functions and so

00:02:58,780 --> 00:03:02,910
on so this function the program gets

00:03:00,459 --> 00:03:05,519
transformed into a data flow graph and

00:03:02,910 --> 00:03:10,200
the data flow graph get sent to the

00:03:05,519 --> 00:03:10,200
distributed our cluster for execution

00:03:10,769 --> 00:03:16,569
the kind of core pillars of link at

00:03:15,340 --> 00:03:17,859
least of the streaming sites I'm going

00:03:16,569 --> 00:03:19,660
to focus very much on the streaming side

00:03:17,859 --> 00:03:21,850
I mentioned it has the data set API for

00:03:19,660 --> 00:03:24,069
for processing of static data sets upon

00:03:21,850 --> 00:03:25,470
the data sets but I'm going to focus

00:03:24,069 --> 00:03:27,970
very much on the streaming start today

00:03:25,470 --> 00:03:30,310
so the for the four pillars of this

00:03:27,970 --> 00:03:32,200
streaming site which actually I think

00:03:30,310 --> 00:03:34,780
make flink the the nice and versatile

00:03:32,200 --> 00:03:37,569
tool that it is today are are those it's

00:03:34,780 --> 00:03:39,370
a true stream processor with support for

00:03:37,569 --> 00:03:41,910
event times there for processing and a

00:03:39,370 --> 00:03:44,650
bunch of knives api's and libraries and

00:03:41,910 --> 00:03:46,690
those four in combination each each one

00:03:44,650 --> 00:03:49,030
actually am brings some very good

00:03:46,690 --> 00:03:50,919
aspects with it but all of these four

00:03:49,030 --> 00:03:54,880
together actually make a very very

00:03:50,919 --> 00:03:57,340
strong and powerful combination on today

00:03:54,880 --> 00:03:59,109
the focus I are having this talk will be

00:03:57,340 --> 00:04:02,470
mainly around the state full site the

00:03:59,109 --> 00:04:05,889
are the blue or um yeah violet box in

00:04:02,470 --> 00:04:07,480
the in the bottom left corner so to

00:04:05,889 --> 00:04:09,639
motivate why why we even want to think

00:04:07,480 --> 00:04:11,200
about this architecture the stream

00:04:09,639 --> 00:04:14,260
processor is a database let's actually

00:04:11,200 --> 00:04:16,030
go through through a very simple very

00:04:14,260 --> 00:04:17,680
classic use case may be one of the most

00:04:16,030 --> 00:04:19,900
classic you use cases for stream

00:04:17,680 --> 00:04:22,479
processing that you can have and that is

00:04:19,900 --> 00:04:24,789
are creating real-time counters and

00:04:22,479 --> 00:04:25,680
aggregates so think about the following

00:04:24,789 --> 00:04:28,710
your

00:04:25,680 --> 00:04:30,509
you're your system are your company that

00:04:28,710 --> 00:04:32,490
has a stream of events of user

00:04:30,509 --> 00:04:35,009
interactions and you just want to create

00:04:32,490 --> 00:04:37,770
some some real-time aggregates be that

00:04:35,009 --> 00:04:40,039
to expose them in a dashboard or be that

00:04:37,770 --> 00:04:41,970
just to you know have a have a data

00:04:40,039 --> 00:04:43,800
service that you want to offer to your

00:04:41,970 --> 00:04:45,150
customers that for example if you're

00:04:43,800 --> 00:04:46,949
let's say your Twitter and you want to

00:04:45,150 --> 00:04:48,780
offer to to somebody that they can you

00:04:46,949 --> 00:04:50,580
know look at how often have people

00:04:48,780 --> 00:04:54,780
interacted with my tweets very very

00:04:50,580 --> 00:04:56,550
simple thing it may like it might sound

00:04:54,780 --> 00:04:57,840
like it's a the the simplest thing you

00:04:56,550 --> 00:04:59,340
can possibly do with stream processing

00:04:57,840 --> 00:05:01,889
but if you actually want to solve this

00:04:59,340 --> 00:05:05,610
and to end everything you know the

00:05:01,889 --> 00:05:08,250
latency scale it very large have it have

00:05:05,610 --> 00:05:10,229
it run very reliably and and yet

00:05:08,250 --> 00:05:12,960
efficiently it's it's a very hard thing

00:05:10,229 --> 00:05:14,820
that that people are still sort of sort

00:05:12,960 --> 00:05:16,050
of struggling with them over the course

00:05:14,820 --> 00:05:18,360
of this talk I'm going to actually show

00:05:16,050 --> 00:05:20,849
you what what uh what the next kind of

00:05:18,360 --> 00:05:23,849
obstacle I swear we're getting out of

00:05:20,849 --> 00:05:26,759
the way here so the architecture to

00:05:23,849 --> 00:05:29,340
implement this is a very very classic

00:05:26,759 --> 00:05:31,080
streaming architecture you start off

00:05:29,340 --> 00:05:32,909
with with basically collecting the

00:05:31,080 --> 00:05:34,740
events that you that you want to analyze

00:05:32,909 --> 00:05:37,620
you lock them into in something like

00:05:34,740 --> 00:05:39,870
Kafka you compute the you compute the

00:05:37,620 --> 00:05:42,060
aggregates in flink and then you expose

00:05:39,870 --> 00:05:43,650
it some way and one of the you know in

00:05:42,060 --> 00:05:47,729
one of the many databases or key value

00:05:43,650 --> 00:05:49,949
stores pick your favorite the

00:05:47,729 --> 00:05:52,770
implementation of the of the processing

00:05:49,949 --> 00:05:54,150
job is also fairly simple if you look if

00:05:52,770 --> 00:05:57,870
you look at it this is an example from

00:05:54,150 --> 00:05:59,820
from Flinx scholar ap is from on the top

00:05:57,870 --> 00:06:02,940
line we're simply defining ourselves a

00:05:59,820 --> 00:06:04,889
as simple a simple type with which

00:06:02,940 --> 00:06:06,599
you're going to work with basically

00:06:04,889 --> 00:06:09,479
impressions with an ID and the the

00:06:06,599 --> 00:06:11,340
number of impressions and then we're

00:06:09,479 --> 00:06:13,190
creating our stream reading from Kafka

00:06:11,340 --> 00:06:16,110
we're going to filter and transform the

00:06:13,190 --> 00:06:18,810
impressions a bit and then on the bottom

00:06:16,110 --> 00:06:22,380
lines actually show that there the group

00:06:18,810 --> 00:06:23,789
by a deed by D and then we with some of

00:06:22,380 --> 00:06:29,430
the impressions in time windows of one

00:06:23,789 --> 00:06:31,020
hour so far so good um to help you sort

00:06:29,430 --> 00:06:33,030
of get there get the structure of this

00:06:31,020 --> 00:06:34,560
program here's his kind of the data for

00:06:33,030 --> 00:06:36,390
representation of what this what this

00:06:34,560 --> 00:06:38,970
program balls down too

00:06:36,390 --> 00:06:41,160
so if I've drawn it with a parallelism

00:06:38,970 --> 00:06:42,870
of two but I guess you can generalize

00:06:41,160 --> 00:06:45,390
from there it can be way more parallel

00:06:42,870 --> 00:06:46,590
than just two threats right I'm starting

00:06:45,390 --> 00:06:49,050
from cough cough is running through the

00:06:46,590 --> 00:06:50,490
filter running through the map you're

00:06:49,050 --> 00:06:52,800
shuffling across the network when you

00:06:50,490 --> 00:06:54,930
reorganize it by the key by the ID and

00:06:52,800 --> 00:06:56,670
then building windows summing it up and

00:06:54,930 --> 00:06:59,310
and writing it somewhere so somebody can

00:06:56,670 --> 00:07:02,400
actually look at the aggregates it's a

00:06:59,310 --> 00:07:07,980
that's the basic structure of the job if

00:07:02,400 --> 00:07:08,940
we run this in in the putting it all

00:07:07,980 --> 00:07:10,370
together if you run this in the

00:07:08,940 --> 00:07:13,740
infrastructure it's it's going to look

00:07:10,370 --> 00:07:15,630
somewhat like that right data from Kafka

00:07:13,740 --> 00:07:17,340
there's going to be only two operators

00:07:15,630 --> 00:07:18,810
in the runtime and flink because it's

00:07:17,340 --> 00:07:20,700
going to condense a lot of the operators

00:07:18,810 --> 00:07:22,230
together for example the source the

00:07:20,700 --> 00:07:24,540
filter and the map are going to become

00:07:22,230 --> 00:07:27,000
one thing the windows and the sink are

00:07:24,540 --> 00:07:30,770
going to become one thing it's going to

00:07:27,000 --> 00:07:33,780
run in multiple parallel instances and

00:07:30,770 --> 00:07:35,460
the data is written just put the reddest

00:07:33,780 --> 00:07:37,140
icon here it's the one that we use in

00:07:35,460 --> 00:07:39,380
this example but it could be it could be

00:07:37,140 --> 00:07:42,450
any other key value store actually um

00:07:39,380 --> 00:07:44,910
yeah and the results are exposed by a

00:07:42,450 --> 00:07:47,190
key value store and the queries go

00:07:44,910 --> 00:07:49,290
against that a key value store right so

00:07:47,190 --> 00:07:50,910
if you if you say okay let me let me see

00:07:49,290 --> 00:07:52,800
how many people have interacted so far

00:07:50,910 --> 00:07:54,300
with with with my tweet with that ID you

00:07:52,800 --> 00:08:01,080
just pick this up from the key value

00:07:54,300 --> 00:08:02,610
store so remember now that the the the

00:08:01,080 --> 00:08:03,930
aggregates they were computing we're

00:08:02,610 --> 00:08:05,460
like an hour early windows right so

00:08:03,930 --> 00:08:08,250
you'd he would sort of aggregate data

00:08:05,460 --> 00:08:09,390
per hour and if you would only ever ride

00:08:08,250 --> 00:08:11,370
it to the key value stuff after the

00:08:09,390 --> 00:08:13,760
hours up after the full windows up you'd

00:08:11,370 --> 00:08:15,960
you'd not have a very very real time

00:08:13,760 --> 00:08:17,760
up-to-date view of your of your

00:08:15,960 --> 00:08:19,770
statistics and the key value store

00:08:17,760 --> 00:08:21,780
because well you could never actually

00:08:19,770 --> 00:08:23,520
look at any in-flight aggregates or so

00:08:21,780 --> 00:08:27,270
you could only ever see what is the

00:08:23,520 --> 00:08:28,650
result of the window especially when you

00:08:27,270 --> 00:08:31,320
used the event time window functionality

00:08:28,650 --> 00:08:33,120
in flank and it it it sort of

00:08:31,320 --> 00:08:34,979
compensates for out of order events and

00:08:33,120 --> 00:08:37,590
for for some lady events then you know

00:08:34,979 --> 00:08:39,000
the hour can be compute actually even

00:08:37,590 --> 00:08:41,220
quite a bit later than the full hour is

00:08:39,000 --> 00:08:43,229
up so what you probably want to do in

00:08:41,220 --> 00:08:44,640
this use case is is add something like

00:08:43,229 --> 00:08:47,130
an in addition to the event I'm

00:08:44,640 --> 00:08:48,660
watermark trigger that is Flinx internal

00:08:47,130 --> 00:08:50,030
mechanism to figure out when it's an

00:08:48,660 --> 00:08:52,040
event time our full

00:08:50,030 --> 00:08:55,070
at something like a periodic trigger

00:08:52,040 --> 00:08:56,420
that just lateral areata CLE flushes the

00:08:55,070 --> 00:08:58,510
current aggregates into the key value

00:08:56,420 --> 00:09:01,250
store so you could actually pick them up

00:08:58,510 --> 00:09:04,550
that is that is interestingly not not a

00:09:01,250 --> 00:09:06,710
very let's say exotic exotic way of

00:09:04,550 --> 00:09:09,050
doing it a few months back yahoo

00:09:06,710 --> 00:09:10,730
published a streaming benchmark and that

00:09:09,050 --> 00:09:12,170
is pretty much exactly what this the

00:09:10,730 --> 00:09:14,210
sample application the streaming

00:09:12,170 --> 00:09:15,890
benchmark was doing it was computing

00:09:14,210 --> 00:09:18,770
windows i think in their case it was

00:09:15,890 --> 00:09:20,120
just like 10 second windows and it was

00:09:18,770 --> 00:09:21,590
computing them inside the stream

00:09:20,120 --> 00:09:23,540
processor like that and every second

00:09:21,590 --> 00:09:26,200
exposing them to an outside key value

00:09:23,540 --> 00:09:31,000
store and allowing you to basically

00:09:26,200 --> 00:09:34,640
query the up to the second accurate data

00:09:31,000 --> 00:09:36,650
so looking at this very simple design it

00:09:34,640 --> 00:09:39,440
may not you know it may feel a little

00:09:36,650 --> 00:09:41,210
funky you you you flush all these early

00:09:39,440 --> 00:09:42,950
aggregates always into into readies and

00:09:41,210 --> 00:09:44,540
then he actually at some point to the

00:09:42,950 --> 00:09:46,550
final ones and can close the window and

00:09:44,540 --> 00:09:47,720
move on to the next hour but that

00:09:46,550 --> 00:09:51,620
apparently that's what people are doing

00:09:47,720 --> 00:09:55,160
so let's actually look how well it does

00:09:51,620 --> 00:09:56,600
and looking at how well it does we're

00:09:55,160 --> 00:09:59,570
going to look at three dimensions a

00:09:56,600 --> 00:10:01,670
latency throughput and are the

00:09:59,570 --> 00:10:03,080
scalability with respect to you know how

00:10:01,670 --> 00:10:08,090
many how many aggregates are actually

00:10:03,080 --> 00:10:10,250
looking at so are for the latency

00:10:08,090 --> 00:10:11,720
already mentioned that that yahoo's

00:10:10,250 --> 00:10:14,330
benchmark was pretty much looking at

00:10:11,720 --> 00:10:16,730
exactly that use case so for latency let

00:10:14,330 --> 00:10:18,980
me just you know let me just side their

00:10:16,730 --> 00:10:21,350
benchmark that was sort of the summary

00:10:18,980 --> 00:10:24,110
graph from from the experiments they did

00:10:21,350 --> 00:10:26,540
a cross-linked storm and spark the

00:10:24,110 --> 00:10:29,330
versions are I think all like half a

00:10:26,540 --> 00:10:31,040
year back or so but it's it's not like

00:10:29,330 --> 00:10:33,050
something very very fundamentally change

00:10:31,040 --> 00:10:35,690
there so there the ballpark's at least

00:10:33,050 --> 00:10:37,010
are still still the same um and it's

00:10:35,690 --> 00:10:38,330
it's kind of a throughput latency

00:10:37,010 --> 00:10:40,340
trade-off and you can see the throughput

00:10:38,330 --> 00:10:41,630
goes to something like 180,000 events

00:10:40,340 --> 00:10:43,730
per second and then the latency is

00:10:41,630 --> 00:10:45,380
anywhere between you know for flink and

00:10:43,730 --> 00:10:48,230
storm in the in the second rage for

00:10:45,380 --> 00:10:49,820
spark it actually goes up so let's

00:10:48,230 --> 00:10:52,550
assume latency is it's actually doing

00:10:49,820 --> 00:10:54,680
okay in this case the throughput if we

00:10:52,550 --> 00:10:57,380
if we look at the throughput 180,000

00:10:54,680 --> 00:10:58,700
elements is at something it's ok for a

00:10:57,380 --> 00:11:01,100
lot of operations but is actually not

00:10:58,700 --> 00:11:03,850
really the limit of this kind of

00:11:01,100 --> 00:11:05,380
application so we actually

00:11:03,850 --> 00:11:08,170
did some ice experiments we looked into

00:11:05,380 --> 00:11:10,170
the throughput exactly that that job and

00:11:08,170 --> 00:11:12,550
and just pushed it a little further

00:11:10,170 --> 00:11:18,759
these experiments were actually done on

00:11:12,550 --> 00:11:20,589
a on a on a cluster at at Twitter it had

00:11:18,759 --> 00:11:21,819
the interesting setup that the storage

00:11:20,589 --> 00:11:23,440
class turned the computer cluster was

00:11:21,819 --> 00:11:24,670
separate so there was like inside each

00:11:23,440 --> 00:11:26,529
cluster they had 10 Gigabit Ethernet

00:11:24,670 --> 00:11:29,680
connections but between the cluster only

00:11:26,529 --> 00:11:31,029
one gigabit ethernet connections so you

00:11:29,680 --> 00:11:32,440
could actually see that if you if you

00:11:31,029 --> 00:11:35,860
look at the implementation flink at

00:11:32,440 --> 00:11:37,630
least reading the data from Kafka and

00:11:35,860 --> 00:11:39,519
the setup as as I explained it earlier

00:11:37,630 --> 00:11:40,990
sort of hit a bottleneck here that one

00:11:39,519 --> 00:11:43,060
leg is interestingly not up to cough

00:11:40,990 --> 00:11:45,220
cards really because the like the cross

00:11:43,060 --> 00:11:46,630
cluster link was just saturated at some

00:11:45,220 --> 00:11:47,860
point in time if they actually have

00:11:46,630 --> 00:11:49,480
actually both were running with a 10

00:11:47,860 --> 00:11:52,180
gigabit interconnect you could probably

00:11:49,480 --> 00:11:55,230
go much further there so what were what

00:11:52,180 --> 00:11:58,540
this was basically doing it was sort of

00:11:55,230 --> 00:12:00,759
using a trick to to move move the the

00:11:58,540 --> 00:12:02,680
data directly into the into the into the

00:12:00,759 --> 00:12:04,470
cluster and read it basically within the

00:12:02,680 --> 00:12:08,230
same class over tape with 10 gigabit

00:12:04,470 --> 00:12:09,880
with 10 gigabit link and you could um

00:12:08,230 --> 00:12:14,889
you can see that the yahoo benchmark

00:12:09,880 --> 00:12:16,120
stop somewhere at 180,000 180,000 events

00:12:14,889 --> 00:12:17,860
per second but you can actually push

00:12:16,120 --> 00:12:20,319
this if you're if you have a decent

00:12:17,860 --> 00:12:22,269
network to to quite a lot this was

00:12:20,319 --> 00:12:25,449
running on 10 machine so to 15 million

00:12:22,269 --> 00:12:27,399
elements per second so I mean throughput

00:12:25,449 --> 00:12:29,550
seems to be okay in general in that case

00:12:27,399 --> 00:12:31,870
that they suggested in this benchmark

00:12:29,550 --> 00:12:33,850
but the most interesting dimension

00:12:31,870 --> 00:12:35,410
actually that is the motivation for this

00:12:33,850 --> 00:12:36,880
kind of work and presenting here is the

00:12:35,410 --> 00:12:40,149
third dimension looking at how does it

00:12:36,880 --> 00:12:41,680
do with a number of keys so if you

00:12:40,149 --> 00:12:43,300
actually look at this yahoo benchmark

00:12:41,680 --> 00:12:46,139
very closely you'll actually see that it

00:12:43,300 --> 00:12:48,279
had only keeps 100 counters so it was

00:12:46,139 --> 00:12:49,810
the motivation was tracking the

00:12:48,279 --> 00:12:50,740
interactions with advertising campaigns

00:12:49,810 --> 00:12:52,389
and they were assuming there were never

00:12:50,740 --> 00:12:54,189
more than 100 advertising campaign so

00:12:52,389 --> 00:12:55,630
we'll just take a hundred counters so

00:12:54,189 --> 00:12:57,490
what this means actually is that every

00:12:55,630 --> 00:12:58,660
second 100 counters and keys are sort of

00:12:57,490 --> 00:13:00,850
flush to the key value store which

00:12:58,660 --> 00:13:02,920
doesn't seem like a lot of work doesn't

00:13:00,850 --> 00:13:05,680
seem like that should pose a challenge

00:13:02,920 --> 00:13:07,389
for many key value stores so on the

00:13:05,680 --> 00:13:08,680
other hand it doesn't really reflect a

00:13:07,389 --> 00:13:11,589
lot of real world use cases right

00:13:08,680 --> 00:13:13,029
hundred aggregates are definitely on the

00:13:11,589 --> 00:13:15,610
on the lower end of what people usually

00:13:13,029 --> 00:13:17,600
have so going back to a motivating

00:13:15,610 --> 00:13:20,420
example if we want to actually count the

00:13:17,600 --> 00:13:23,149
if we count the impressions over tweets

00:13:20,420 --> 00:13:24,680
right then the number of keys you will

00:13:23,149 --> 00:13:27,529
have within this hourly window actually

00:13:24,680 --> 00:13:30,380
large I think concretely in the in the

00:13:27,529 --> 00:13:33,649
example that we did on 3d impressions

00:13:30,380 --> 00:13:34,910
with 500 million Keys per hour which

00:13:33,649 --> 00:13:36,170
means that actually every second

00:13:34,910 --> 00:13:39,829
multiple hundred thousands up to a

00:13:36,170 --> 00:13:41,750
million keys are updated if we actually

00:13:39,829 --> 00:13:44,810
look at how does this particular setup

00:13:41,750 --> 00:13:46,399
perform with these different keys that

00:13:44,810 --> 00:13:48,139
dimension makes a huge difference right

00:13:46,399 --> 00:13:51,319
if you flush hundred Keys per second

00:13:48,139 --> 00:13:52,759
that's going to be fine if you may have

00:13:51,319 --> 00:13:54,649
to flush a million or hundreds of

00:13:52,759 --> 00:13:56,149
thousands keys per seconds then you hit

00:13:54,649 --> 00:13:59,329
you immediately hit a throughput bottle

00:13:56,149 --> 00:14:01,610
like so the bottleneck in the key value

00:13:59,329 --> 00:14:03,019
store the bottleneck is writing back the

00:14:01,610 --> 00:14:05,959
aggregates to the key value store and

00:14:03,019 --> 00:14:07,579
because flank internally has has a back

00:14:05,959 --> 00:14:09,920
pressure mechanism if the sink cannot

00:14:07,579 --> 00:14:11,449
keep up then you know it will just back

00:14:09,920 --> 00:14:12,589
pressure and will decrease the

00:14:11,449 --> 00:14:16,310
throughput and it is going to stay

00:14:12,589 --> 00:14:19,490
longer in kafka so in that case it would

00:14:16,310 --> 00:14:21,709
yeah the the concrete number here is I

00:14:19,490 --> 00:14:23,300
think somewhere around 280,000 elements

00:14:21,709 --> 00:14:25,610
per second that was as much as we could

00:14:23,300 --> 00:14:29,230
get out of the key value store with that

00:14:25,610 --> 00:14:32,089
particular setup you could probably

00:14:29,230 --> 00:14:34,189
expand this by you know building in some

00:14:32,089 --> 00:14:36,199
manual sharding logic against multiple

00:14:34,189 --> 00:14:38,240
read his notes and so on I mean even if

00:14:36,199 --> 00:14:41,300
you take this x 10 or so and use for the

00:14:38,240 --> 00:14:43,730
key value store even more resources than

00:14:41,300 --> 00:14:46,040
we use for the for the stream processor

00:14:43,730 --> 00:14:47,750
then you can still see that your you may

00:14:46,040 --> 00:14:49,699
be able to get to get somewhere here or

00:14:47,750 --> 00:14:51,290
so but you're still far away from what

00:14:49,699 --> 00:14:53,779
actually the the stream processor can do

00:14:51,290 --> 00:14:55,970
so it turns out that in this particular

00:14:53,779 --> 00:14:57,500
application this communication between

00:14:55,970 --> 00:15:00,829
the stream processor and the database is

00:14:57,500 --> 00:15:02,240
really the biggest bottleneck and that's

00:15:00,829 --> 00:15:03,860
actually interesting because if you if

00:15:02,240 --> 00:15:05,329
you look at what what many of these

00:15:03,860 --> 00:15:07,279
benchmarks actually do these days they

00:15:05,329 --> 00:15:10,399
just like benchmarking the hell out of a

00:15:07,279 --> 00:15:12,589
out of a student possessor in a very in

00:15:10,399 --> 00:15:14,089
a kind of simple use case right and for

00:15:12,589 --> 00:15:16,160
for many real-world application that's

00:15:14,089 --> 00:15:18,019
not really quite quite quite helpful

00:15:16,160 --> 00:15:19,490
because you know the bottle Mac is often

00:15:18,019 --> 00:15:20,689
not within a system within a system we

00:15:19,490 --> 00:15:22,069
can make sure all the parts play

00:15:20,689 --> 00:15:23,569
together very well but as soon as you

00:15:22,069 --> 00:15:26,300
have systems that need to interoperate

00:15:23,569 --> 00:15:27,680
and communicate then you're hitting then

00:15:26,300 --> 00:15:29,930
you're hitting are completely different

00:15:27,680 --> 00:15:31,220
bottlenecks that you know another not an

00:15:29,930 --> 00:15:37,279
individual system can just

00:15:31,220 --> 00:15:39,199
optimize the hell out of so how can we

00:15:37,279 --> 00:15:40,759
actually work around that because it

00:15:39,199 --> 00:15:42,800
doesn't really make sense to build a

00:15:40,759 --> 00:15:44,269
super scalable and performance read

00:15:42,800 --> 00:15:46,279
processor and allow this to scale out

00:15:44,269 --> 00:15:48,050
very far if in the end you know you're

00:15:46,279 --> 00:15:49,850
going to pay out all the performance

00:15:48,050 --> 00:15:52,519
anyways when you're trying to do remote

00:15:49,850 --> 00:15:54,620
updates on a database that's kind of the

00:15:52,519 --> 00:15:58,399
other motivation for our with the main

00:15:54,620 --> 00:15:59,629
theme of this talk is queryable state so

00:15:58,399 --> 00:16:01,699
in a nutshell the idea of curing of the

00:15:59,629 --> 00:16:04,519
state is actually dead simple it just is

00:16:01,699 --> 00:16:06,259
are instead of you know saying the real

00:16:04,519 --> 00:16:07,819
time aggregates we're going to pick them

00:16:06,259 --> 00:16:09,379
up from reddit or any other database

00:16:07,819 --> 00:16:11,060
let's pick them up directly from the

00:16:09,379 --> 00:16:12,949
stream processor why not right so the

00:16:11,060 --> 00:16:14,269
stream processor apparently has them

00:16:12,949 --> 00:16:16,220
stored internally somewhere there the

00:16:14,269 --> 00:16:18,199
windows the early windows you have two

00:16:16,220 --> 00:16:19,399
counts per key and so on so so they are

00:16:18,199 --> 00:16:22,730
there we just need to expose them

00:16:19,399 --> 00:16:25,610
somehow and that is pretty much in this

00:16:22,730 --> 00:16:27,889
prototype exactly what we did real-time

00:16:25,610 --> 00:16:30,319
queries in this case we're going exactly

00:16:27,889 --> 00:16:33,379
directly against flink basically and not

00:16:30,319 --> 00:16:36,800
against right us anymore there is an if

00:16:33,379 --> 00:16:39,230
you wish this in an optional still you

00:16:36,800 --> 00:16:42,079
know flash the windows at the end of of

00:16:39,230 --> 00:16:45,079
the hourly period or so inches into some

00:16:42,079 --> 00:16:46,639
archive database and you know as soon as

00:16:45,079 --> 00:16:51,949
they are immutable you basically do only

00:16:46,639 --> 00:16:53,449
on one right anymore a output and yeah

00:16:51,949 --> 00:16:55,220
and then you can actually you know

00:16:53,449 --> 00:16:56,660
reduce the amount of data you're keeping

00:16:55,220 --> 00:16:58,399
inside the stream processor and just say

00:16:56,660 --> 00:17:00,019
you know older queries go gives the

00:16:58,399 --> 00:17:02,959
database all right on chris go against

00:17:00,019 --> 00:17:06,429
the go against the stream processor so

00:17:02,959 --> 00:17:09,679
this architecture is in some sense aah

00:17:06,429 --> 00:17:11,480
what what this prototype um that we did

00:17:09,679 --> 00:17:13,280
together with someone at Twitter and a

00:17:11,480 --> 00:17:15,919
quick project actually implement it and

00:17:13,280 --> 00:17:17,510
it like in their architecture it fit it

00:17:15,919 --> 00:17:19,100
very well because they really bought

00:17:17,510 --> 00:17:22,130
into this concept of lambda so there's

00:17:19,100 --> 00:17:23,630
going to be a a slow path on something

00:17:22,130 --> 00:17:24,980
based on MapReduce anyways that that

00:17:23,630 --> 00:17:26,900
writes to archive database and there's

00:17:24,980 --> 00:17:28,789
going to be a fast path based on in

00:17:26,900 --> 00:17:30,620
their case it is herun and some key

00:17:28,789 --> 00:17:32,179
value store they built internally that

00:17:30,620 --> 00:17:33,440
they used for the real-time queries so

00:17:32,179 --> 00:17:34,909
they they kind of had this idea that

00:17:33,440 --> 00:17:37,640
they would route queries either to the

00:17:34,909 --> 00:17:39,980
to the results of the slow path or to

00:17:37,640 --> 00:17:41,690
the Past path based on you know how

00:17:39,980 --> 00:17:43,100
recent is the result I want to pick up

00:17:41,690 --> 00:17:44,310
so that actually fit very well the real

00:17:43,100 --> 00:17:47,150
time crews would go against

00:17:44,310 --> 00:17:49,200
windows the old database the old crews

00:17:47,150 --> 00:17:50,940
occur is that refer to data that's

00:17:49,200 --> 00:17:54,330
further back in the past would go

00:17:50,940 --> 00:17:55,620
against the archive database so this

00:17:54,330 --> 00:17:57,810
this extension was actually something

00:17:55,620 --> 00:17:59,550
that is conceptually it was very easy to

00:17:57,810 --> 00:18:00,840
build into flank and and there are a few

00:17:59,550 --> 00:18:03,750
few corner parts that I want to

00:18:00,840 --> 00:18:05,370
highlight why why why we can actually do

00:18:03,750 --> 00:18:06,990
this and what happens stream process has

00:18:05,370 --> 00:18:08,340
been doing this all along it seems like

00:18:06,990 --> 00:18:09,900
such a natural thing to do this is

00:18:08,340 --> 00:18:11,700
searches to be a bottleneck and you know

00:18:09,900 --> 00:18:14,220
why not just immediately pick up the

00:18:11,700 --> 00:18:15,300
data from the stream processor so

00:18:14,220 --> 00:18:16,980
there's a few things that stream

00:18:15,300 --> 00:18:18,690
processors didn't have for for quite a

00:18:16,980 --> 00:18:19,830
while which is actually quite important

00:18:18,690 --> 00:18:21,450
if you want to realize something like

00:18:19,830 --> 00:18:22,800
that and the first the first thing is

00:18:21,450 --> 00:18:24,450
actually that the stream processor has

00:18:22,800 --> 00:18:26,580
to be aware of state and has have stayed

00:18:24,450 --> 00:18:28,980
as a first class citizen if you look at

00:18:26,580 --> 00:18:30,690
at storm I think prior version one point

00:18:28,980 --> 00:18:32,460
or just came out it didn't even have a

00:18:30,690 --> 00:18:35,280
concept of off state that the frame

00:18:32,460 --> 00:18:36,840
processor was was a wealth arms the

00:18:35,280 --> 00:18:38,280
state by itself also has to be fault

00:18:36,840 --> 00:18:40,020
tolerant it's not just about replaying

00:18:38,280 --> 00:18:41,430
events but the the state itself has to

00:18:40,020 --> 00:18:44,640
be recovered with good semantically

00:18:41,430 --> 00:18:47,340
guarantees like exactly once the state

00:18:44,640 --> 00:18:49,530
also has to be partitioned and and scale

00:18:47,340 --> 00:18:50,670
out with the operator so it doesn't make

00:18:49,530 --> 00:18:52,110
sense to have the state in one

00:18:50,670 --> 00:18:53,610
centralized instance and scale out the

00:18:52,110 --> 00:18:55,680
computation so the state has to actually

00:18:53,610 --> 00:18:57,720
scale with the computation like you

00:18:55,680 --> 00:18:59,070
would start charting a database and

00:18:57,720 --> 00:19:01,590
scaling it in and out of your state

00:18:59,070 --> 00:19:02,820
gross right because that's that's how

00:19:01,590 --> 00:19:05,580
you that's how you actually make it

00:19:02,820 --> 00:19:06,870
scalable the next thing is if you

00:19:05,580 --> 00:19:07,950
actually want to expose something like a

00:19:06,870 --> 00:19:09,990
database from within the stream

00:19:07,950 --> 00:19:11,430
processor it it becomes a very tough

00:19:09,990 --> 00:19:13,680
thing if you actually do this based on a

00:19:11,430 --> 00:19:14,910
mini batch system it is it's much more

00:19:13,680 --> 00:19:17,040
straightforward if you do it based on a

00:19:14,910 --> 00:19:19,110
system where actually operations live

00:19:17,040 --> 00:19:23,580
continuously like a like a proper

00:19:19,110 --> 00:19:27,330
continuous stream processor and the last

00:19:23,580 --> 00:19:29,280
the last part is that you know it's it's

00:19:27,330 --> 00:19:32,610
it's fine to say I keep a keep state in

00:19:29,280 --> 00:19:34,290
initially in in memory but if you

00:19:32,610 --> 00:19:36,570
actually want this to work reliably you

00:19:34,290 --> 00:19:38,130
really would would like to you know have

00:19:36,570 --> 00:19:40,380
to have the characteristic that each

00:19:38,130 --> 00:19:42,770
node can store data in memory but also

00:19:40,380 --> 00:19:45,270
on disk if if the memory becomes scarce

00:19:42,770 --> 00:19:47,160
so all of these things are things that

00:19:45,270 --> 00:19:49,110
that fling state mechanism actually

00:19:47,160 --> 00:19:52,650
offers and where we could actually build

00:19:49,110 --> 00:19:56,430
this in there the the current state of

00:19:52,650 --> 00:19:57,780
of queryable state is it's not yet in in

00:19:56,430 --> 00:19:58,110
any full release there's an open pool

00:19:57,780 --> 00:20:02,309
record

00:19:58,110 --> 00:20:03,450
it's for fleeing 377 nine it is a you

00:20:02,309 --> 00:20:06,090
you can actually check out this pull

00:20:03,450 --> 00:20:07,380
request no ran a job instantiate a query

00:20:06,090 --> 00:20:09,270
client and actually if you some queries

00:20:07,380 --> 00:20:10,470
into some experiments but the exact

00:20:09,270 --> 00:20:11,670
design and implementation are a little

00:20:10,470 --> 00:20:12,990
bit under evolution so we're still

00:20:11,670 --> 00:20:15,260
trying to you know chew and here and

00:20:12,990 --> 00:20:17,549
there a bit to see what works best

00:20:15,260 --> 00:20:19,170
because actually this is going on all

00:20:17,549 --> 00:20:20,580
the time there's a little caveat so most

00:20:19,170 --> 00:20:22,380
of these experiments here were actually

00:20:20,580 --> 00:20:23,910
done not with the exact version of the

00:20:22,380 --> 00:20:25,500
pull request but with a with a bit of an

00:20:23,910 --> 00:20:27,179
earlier version of slightly different

00:20:25,500 --> 00:20:29,370
implementation so the exact numbers may

00:20:27,179 --> 00:20:30,630
vary a little bit but I think I mean the

00:20:29,370 --> 00:20:34,830
important thing is that the ballpark

00:20:30,630 --> 00:20:36,780
which is the same and yeah so it's a

00:20:34,830 --> 00:20:39,480
it's it's still under under evolution

00:20:36,780 --> 00:20:40,679
and work in progress I guess the most

00:20:39,480 --> 00:20:42,210
interesting question is does it actually

00:20:40,679 --> 00:20:43,830
solve the performance problem and if we

00:20:42,210 --> 00:20:45,660
actually rerun this whole our

00:20:43,830 --> 00:20:47,220
implementation with query will state on

00:20:45,660 --> 00:20:48,750
a million keys then yeah what we

00:20:47,220 --> 00:20:50,340
actually see is it does solve the

00:20:48,750 --> 00:20:51,780
problem and it's actually not surprising

00:20:50,340 --> 00:20:53,880
that you get the exact same through

00:20:51,780 --> 00:20:55,710
possess used to get before because

00:20:53,880 --> 00:20:57,450
assuming that in the hundred Keys case

00:20:55,710 --> 00:20:58,919
there's there's really no bottleneck in

00:20:57,450 --> 00:21:00,299
the interaction with the key value store

00:20:58,919 --> 00:21:02,610
in the clear available state on the

00:21:00,299 --> 00:21:04,110
million keys cases also know what'll

00:21:02,610 --> 00:21:05,460
make any interaction with the curve with

00:21:04,110 --> 00:21:06,960
the key value store anymore because the

00:21:05,460 --> 00:21:08,700
data is simply not written every second

00:21:06,960 --> 00:21:11,280
right it's just kept in flink and it's

00:21:08,700 --> 00:21:13,650
kept in the exact same way as it is kept

00:21:11,280 --> 00:21:16,200
anyways by the window that computes um

00:21:13,650 --> 00:21:20,700
so this is really literally not overhead

00:21:16,200 --> 00:21:22,530
here um the applications have to like I

00:21:20,700 --> 00:21:24,540
mentioned sort of adjust a little bit to

00:21:22,530 --> 00:21:26,040
this paradigm if you have an application

00:21:24,540 --> 00:21:27,419
that's only interested in the latest

00:21:26,040 --> 00:21:28,650
real-time results let's say you just

00:21:27,419 --> 00:21:30,570
have a dashboard you want to see the

00:21:28,650 --> 00:21:31,830
state of what is currently going on then

00:21:30,570 --> 00:21:34,290
you only change that you really do is

00:21:31,830 --> 00:21:35,850
instead of you know using a Redis client

00:21:34,290 --> 00:21:38,400
you use the flink are credible state

00:21:35,850 --> 00:21:41,190
client and basically sent your crews

00:21:38,400 --> 00:21:43,080
directly directly against flinky if you

00:21:41,190 --> 00:21:45,780
have a system that is really interested

00:21:43,080 --> 00:21:48,120
in both the latest and older results

00:21:45,780 --> 00:21:49,620
then you have to do something that's a

00:21:48,120 --> 00:21:52,350
little more elaborate you sort of have

00:21:49,620 --> 00:21:54,150
to work with with a with something like

00:21:52,350 --> 00:21:56,340
your query service or so you have to

00:21:54,150 --> 00:21:57,750
make your application aware that they're

00:21:56,340 --> 00:21:59,760
kind of two different ports where you

00:21:57,750 --> 00:22:02,429
can pick up results old old results and

00:21:59,760 --> 00:22:05,730
and up to the left after the second

00:22:02,429 --> 00:22:08,040
results so this uh like I mentioned this

00:22:05,730 --> 00:22:09,240
doesn't seem apparently when I first

00:22:08,040 --> 00:22:11,190
thought about this I thought it was very

00:22:09,240 --> 00:22:12,029
exotic but I've actually since in a

00:22:11,190 --> 00:22:13,710
bunch of companies

00:22:12,029 --> 00:22:15,059
everybody that bought into this idea of

00:22:13,710 --> 00:22:16,710
the lambda architecture that actually

00:22:15,059 --> 00:22:18,059
have something like like this query

00:22:16,710 --> 00:22:21,149
service actually in place internally

00:22:18,059 --> 00:22:23,009
anyways arm precisely to sort of make

00:22:21,149 --> 00:22:24,599
application switch between the results

00:22:23,009 --> 00:22:26,129
computed by the first part and the slow

00:22:24,599 --> 00:22:29,549
past path of the of the land

00:22:26,129 --> 00:22:31,019
architecture so what you get here is you

00:22:29,549 --> 00:22:33,690
still get a lot of the benefits of the

00:22:31,019 --> 00:22:35,609
lambda architecture in terms of you

00:22:33,690 --> 00:22:37,379
don't have the of not having lumped

00:22:35,609 --> 00:22:38,519
architecture I'm sorry you don't have to

00:22:37,379 --> 00:22:40,019
have the stream processor and the batch

00:22:38,519 --> 00:22:42,090
processor you literally have one thing

00:22:40,019 --> 00:22:45,499
only you just have to slightly are

00:22:42,090 --> 00:22:48,239
direct your courage different ways um

00:22:45,499 --> 00:22:49,859
out likes next like to look a little bit

00:22:48,239 --> 00:22:51,089
and how does the queryable state in

00:22:49,859 --> 00:22:53,940
flink exact how is it exactly

00:22:51,089 --> 00:22:56,429
implemented in fling and before I dive

00:22:53,940 --> 00:22:58,109
into this let me quickly do a brief

00:22:56,429 --> 00:23:00,119
review of the architecture of link so

00:22:58,109 --> 00:23:03,839
that would make the next part a bit

00:23:00,119 --> 00:23:05,669
easier to understand so fling case if

00:23:03,839 --> 00:23:07,019
you wish to two big plus types of

00:23:05,669 --> 00:23:08,580
processes that are running the job

00:23:07,019 --> 00:23:10,769
manager which is the master in the task

00:23:08,580 --> 00:23:13,139
managers which are the workers and then

00:23:10,769 --> 00:23:14,820
there is the the client site which runs

00:23:13,139 --> 00:23:16,409
the pink program really the functional

00:23:14,820 --> 00:23:19,519
program that I've showed on one of the

00:23:16,409 --> 00:23:21,629
first slides and where this program is

00:23:19,519 --> 00:23:23,009
inside the client is executed

00:23:21,629 --> 00:23:25,799
transformed into the data flow graph and

00:23:23,009 --> 00:23:27,749
sent to the cluster once it has arrived

00:23:25,799 --> 00:23:29,700
in the cluster in in the master or one

00:23:27,749 --> 00:23:32,820
of the Masters in a high-availability

00:23:29,700 --> 00:23:34,619
case the master is going to have a data

00:23:32,820 --> 00:23:36,749
structure called the data flow or

00:23:34,619 --> 00:23:38,700
execution graph which is a

00:23:36,749 --> 00:23:40,589
representation of the parallel data flow

00:23:38,700 --> 00:23:42,599
of the program and it it basically uses

00:23:40,589 --> 00:23:45,950
this to schedule our and to track

00:23:42,599 --> 00:23:48,989
progress and to um yeah just sort of

00:23:45,950 --> 00:23:52,979
detect failures figure out what needs to

00:23:48,989 --> 00:23:54,809
be recovered and how and it sense it

00:23:52,979 --> 00:23:56,969
sends to the to the task manages to the

00:23:54,809 --> 00:23:59,729
workers are calls to execute certain

00:23:56,969 --> 00:24:01,289
tasks they task managers then execute

00:23:59,729 --> 00:24:02,999
the tasks in the resources there's a

00:24:01,289 --> 00:24:05,009
there's a network manager which handles

00:24:02,999 --> 00:24:07,229
our streams being exchanged between task

00:24:05,009 --> 00:24:09,839
managers that handles all the things

00:24:07,229 --> 00:24:11,549
actually multiplexing are establishing

00:24:09,839 --> 00:24:15,089
connections and cheering them down and

00:24:11,549 --> 00:24:16,649
so on so with queryable state there

00:24:15,089 --> 00:24:18,419
they're actually two pretty much pretty

00:24:16,649 --> 00:24:20,129
lightweight components that we added to

00:24:18,419 --> 00:24:22,529
the system are most of the logic is

00:24:20,129 --> 00:24:24,570
actually in the critic client so the

00:24:22,529 --> 00:24:25,740
first thing is that are the the job

00:24:24,570 --> 00:24:29,280
manager has an interv

00:24:25,740 --> 00:24:31,350
that basically our lets you ask where a

00:24:29,280 --> 00:24:35,130
certain resource is currently executed

00:24:31,350 --> 00:24:36,750
so let's assume that we want to access

00:24:35,130 --> 00:24:39,480
the state of a certain job a certain

00:24:36,750 --> 00:24:41,730
operator so job would be you know your

00:24:39,480 --> 00:24:45,330
name of the of the tweet impression job

00:24:41,730 --> 00:24:47,730
the operation would be on hourly window

00:24:45,330 --> 00:24:49,320
or the state name in this case would be

00:24:47,730 --> 00:24:51,210
in on flink operators can have multiple

00:24:49,320 --> 00:24:53,010
types of state also user-defined States

00:24:51,210 --> 00:24:55,710
in this case it would just be the window

00:24:53,010 --> 00:24:57,120
state and then the key would be the the

00:24:55,710 --> 00:24:59,610
key of your tweet right so this kind of

00:24:57,120 --> 00:25:00,840
the query that one is sent and and the

00:24:59,610 --> 00:25:02,940
first thing that it would do is it will

00:25:00,840 --> 00:25:04,320
actually send a a lock up to the to the

00:25:02,940 --> 00:25:05,670
state location server which would look

00:25:04,320 --> 00:25:07,320
into the execution graph which is

00:25:05,670 --> 00:25:09,420
integrated the scheduler and is aware

00:25:07,320 --> 00:25:12,300
where is this thing executed right now

00:25:09,420 --> 00:25:13,950
and we tell the query client we defined

00:25:12,300 --> 00:25:15,650
it and then this would actually look at

00:25:13,950 --> 00:25:17,820
the state registry where operators

00:25:15,650 --> 00:25:18,990
register all the local state that they

00:25:17,820 --> 00:25:21,000
that they have and then they want to

00:25:18,990 --> 00:25:23,130
expose and the crew client will just

00:25:21,000 --> 00:25:25,140
pick it up from there so there's it's

00:25:23,130 --> 00:25:26,520
kind of a ya think fairly

00:25:25,140 --> 00:25:27,900
straightforward thing right first you

00:25:26,520 --> 00:25:29,700
actually look at the location then you

00:25:27,900 --> 00:25:31,500
could directly create the location the

00:25:29,700 --> 00:25:32,940
creek line to some some caching so know

00:25:31,500 --> 00:25:36,300
if not every look up has to actually go

00:25:32,940 --> 00:25:38,250
through the job manager again and yeah

00:25:36,300 --> 00:25:39,929
that's actually basically it there's a

00:25:38,250 --> 00:25:41,190
bit of a retry policy so in case you

00:25:39,929 --> 00:25:42,570
know something actually failed and were

00:25:41,190 --> 00:25:44,130
scheduled some are different than the

00:25:42,570 --> 00:25:46,110
Tasman who is going to respond with nope

00:25:44,130 --> 00:25:47,580
that's actually not here and and we

00:25:46,110 --> 00:25:50,070
basically trigger another look up and

00:25:47,580 --> 00:25:51,870
say okay then tell me where it is now

00:25:50,070 --> 00:25:53,640
and then you do a second look up where

00:25:51,870 --> 00:25:55,740
where the state actually is but that's

00:25:53,640 --> 00:25:59,600
that's basically all all there is in

00:25:55,740 --> 00:26:02,370
this implementation so it's kind of a

00:25:59,600 --> 00:26:08,490
kind of a witch lightweight add on to

00:26:02,370 --> 00:26:11,700
what flink is so why why is this

00:26:08,490 --> 00:26:13,350
actually now so so fast so what is what

00:26:11,700 --> 00:26:18,000
is it doing fundamentally differently

00:26:13,350 --> 00:26:22,260
arm internally then what for example

00:26:18,000 --> 00:26:23,820
ready so Cassandra would be doing why is

00:26:22,260 --> 00:26:25,770
they you know putting to a key value

00:26:23,820 --> 00:26:27,390
store just completely aside from the

00:26:25,770 --> 00:26:29,010
fact that you have to send some network

00:26:27,390 --> 00:26:30,300
packets if you put something into a key

00:26:29,010 --> 00:26:31,860
value store that's on a different

00:26:30,300 --> 00:26:32,970
machine what is what is the very

00:26:31,860 --> 00:26:34,380
fundamental difference while you're

00:26:32,970 --> 00:26:36,270
actually getting such a high performance

00:26:34,380 --> 00:26:39,100
here compared to just interacting with

00:26:36,270 --> 00:26:41,919
another key value store and that is um

00:26:39,100 --> 00:26:43,510
is what I want to talk about next so

00:26:41,919 --> 00:26:45,039
while diving into this the first thing I

00:26:43,510 --> 00:26:48,610
have to do is actually give a little

00:26:45,039 --> 00:26:50,020
credit if you've been here at buzz words

00:26:48,610 --> 00:26:51,700
a couple of times you'll actually have

00:26:50,020 --> 00:26:53,260
seen this guy speaking a bunch of times

00:26:51,700 --> 00:26:56,289
Martin clapman about turning the

00:26:53,260 --> 00:26:58,690
database inside out and he's been turned

00:26:56,289 --> 00:27:00,730
he's been speaking about how you know

00:26:58,690 --> 00:27:02,950
you can actually rethink this paradigm

00:27:00,730 --> 00:27:05,260
of databases which which log and then

00:27:02,950 --> 00:27:06,820
right into tables into into something

00:27:05,260 --> 00:27:08,230
different he was mainly talking about

00:27:06,820 --> 00:27:11,710
data warehousing with cough can som

00:27:08,230 --> 00:27:12,940
something in these talks so far I am

00:27:11,710 --> 00:27:15,429
actually going to pick up some of his

00:27:12,940 --> 00:27:18,100
like views and terminology to to just

00:27:15,429 --> 00:27:19,659
explain the to explain why this

00:27:18,100 --> 00:27:22,210
architecture actually gets this nice

00:27:19,659 --> 00:27:23,860
performance so in some sense you could

00:27:22,210 --> 00:27:25,630
actually think that what what this

00:27:23,860 --> 00:27:27,340
queryable staton flink is doing is this

00:27:25,630 --> 00:27:30,159
turning the database inside out plus

00:27:27,340 --> 00:27:32,350
plus so it's out viewed as the as the

00:27:30,159 --> 00:27:37,720
natural next step from from this kind of

00:27:32,350 --> 00:27:39,340
ideas so to understand what it's

00:27:37,720 --> 00:27:41,500
actually what is actually working so

00:27:39,340 --> 00:27:43,240
differently lettuce let us just look at

00:27:41,500 --> 00:27:46,330
let's look at some key value store that

00:27:43,240 --> 00:27:48,549
is actually offering a good amount of

00:27:46,330 --> 00:27:51,690
durability persistence and consistency

00:27:48,549 --> 00:27:54,130
that lets repopulate their Cassandra um

00:27:51,690 --> 00:27:57,610
the right part of Cassandra in

00:27:54,130 --> 00:28:00,640
particular so if we if we actually write

00:27:57,610 --> 00:28:03,039
data the first thing that will actually

00:28:00,640 --> 00:28:04,929
happen is that the data goes to a commit

00:28:03,039 --> 00:28:06,549
lock and every time you do you flush

00:28:04,929 --> 00:28:07,780
your updated counters and put them into

00:28:06,549 --> 00:28:09,580
the Sun for the first thing it does it

00:28:07,780 --> 00:28:11,289
actually goes to a commit lock then it

00:28:09,580 --> 00:28:12,789
goes to a mem table in the mem table is

00:28:11,289 --> 00:28:14,230
you know accumulating data once in a

00:28:12,789 --> 00:28:16,390
while it's going to be sorted are

00:28:14,230 --> 00:28:19,600
compacted flashed and becomes an SS

00:28:16,390 --> 00:28:22,750
table so what we actually see is the

00:28:19,600 --> 00:28:24,549
first step is about lock durability and

00:28:22,750 --> 00:28:25,929
that is that's not only a cassandra

00:28:24,549 --> 00:28:28,000
specific thing if you actually go

00:28:25,929 --> 00:28:30,880
through all candidata basis and that

00:28:28,000 --> 00:28:34,120
offer durability that's really virtually

00:28:30,880 --> 00:28:36,370
always the first step the second

00:28:34,120 --> 00:28:38,080
interesting thing to notice you is that

00:28:36,370 --> 00:28:40,299
this ma'am table per se is actually not

00:28:38,080 --> 00:28:41,440
a persistent thing immediately right sue

00:28:40,299 --> 00:28:43,150
sue memory as soon as the process goes

00:28:41,440 --> 00:28:45,130
down or anything it's actually lost but

00:28:43,150 --> 00:28:46,690
it's not not a big deal because the mem

00:28:45,130 --> 00:28:49,600
table can always be recomputed using

00:28:46,690 --> 00:28:51,640
parts of the log and part and d and some

00:28:49,600 --> 00:28:53,530
other SS tables

00:28:51,640 --> 00:28:55,510
and another important thing is that

00:28:53,530 --> 00:28:57,130
really durability this is it's not

00:28:55,510 --> 00:29:01,840
considered durable before it has been

00:28:57,130 --> 00:29:04,360
replicated to a quorum of nodes and and

00:29:01,840 --> 00:29:06,520
the important parts here I mean the the

00:29:04,360 --> 00:29:09,760
costly parts are actually writing to the

00:29:06,520 --> 00:29:11,760
lock and doing the replication now if we

00:29:09,760 --> 00:29:14,020
look actually at our architecture here I

00:29:11,760 --> 00:29:15,310
mean one interesting observation is why

00:29:14,020 --> 00:29:16,750
would we actually want to redo this

00:29:15,310 --> 00:29:18,700
every time for every you know every

00:29:16,750 --> 00:29:21,460
counter update that we do given that you

00:29:18,700 --> 00:29:24,490
know our data is actually durably stored

00:29:21,460 --> 00:29:28,540
in a lock already in Kafka it is it is

00:29:24,490 --> 00:29:30,520
locked and it is replicated and actually

00:29:28,540 --> 00:29:33,340
the event stream is anyways our ground

00:29:30,520 --> 00:29:34,960
truth here so given that that is

00:29:33,340 --> 00:29:36,850
persistent that's that's a huge thing to

00:29:34,960 --> 00:29:38,470
build on instead of you know just having

00:29:36,850 --> 00:29:40,120
a second system that tries to do the

00:29:38,470 --> 00:29:45,520
exact same thing again keeping things

00:29:40,120 --> 00:29:47,830
available and durable the the queryable

00:29:45,520 --> 00:29:49,330
state that we have here in flink you can

00:29:47,830 --> 00:29:51,190
think of it is it's really just taking

00:29:49,330 --> 00:29:52,780
over the the role of the of the ma'am

00:29:51,190 --> 00:29:54,730
table in Cassandra right it's it's

00:29:52,780 --> 00:29:56,260
something that is not immediately

00:29:54,730 --> 00:29:59,320
persistent it's really just something

00:29:56,260 --> 00:30:00,880
that is recon that is persistent in

00:29:59,320 --> 00:30:02,530
intervals you know like a flink

00:30:00,880 --> 00:30:04,270
checkpoint think of it as a mint abels

00:30:02,530 --> 00:30:06,520
persisted on disqus and SS table but in

00:30:04,270 --> 00:30:11,590
the time in between it'sit's recomputed

00:30:06,520 --> 00:30:14,260
from the event stream from Kafka so that

00:30:11,590 --> 00:30:16,750
that means that in this architecture off

00:30:14,260 --> 00:30:19,300
link is really doing is actually the

00:30:16,750 --> 00:30:20,830
part that is cheap in Cassandra right

00:30:19,300 --> 00:30:21,970
it's not the expensive parts only doing

00:30:20,830 --> 00:30:24,460
the cheap part and it's actually usually

00:30:21,970 --> 00:30:27,070
a relying on the corporation with Kafka

00:30:24,460 --> 00:30:28,420
to do the expensive part and and Kafka

00:30:27,070 --> 00:30:30,370
is actually very performant doing this

00:30:28,420 --> 00:30:33,280
expensive part because it's not doing a

00:30:30,370 --> 00:30:34,750
you know / update replication and quorum

00:30:33,280 --> 00:30:37,660
and logging and everything its religious

00:30:34,750 --> 00:30:39,940
you know over to you you write data fast

00:30:37,660 --> 00:30:41,530
into into your topic partition and you

00:30:39,940 --> 00:30:43,270
know the replication is pipelined and

00:30:41,530 --> 00:30:44,740
everything so it's not like you're

00:30:43,270 --> 00:30:46,450
actually tracking your tracking

00:30:44,740 --> 00:30:48,190
individual things it's it's very much

00:30:46,450 --> 00:30:51,850
streamlining this whole durability thing

00:30:48,190 --> 00:30:53,140
which which makes it very efficient if

00:30:51,850 --> 00:30:55,330
we then actually look at what what

00:30:53,140 --> 00:30:59,380
processing is here is a little like a

00:30:55,330 --> 00:31:01,390
little cheap illustration this this is

00:30:59,380 --> 00:31:03,580
the basically the job that we're

00:31:01,390 --> 00:31:05,200
executing these operations here the

00:31:03,580 --> 00:31:07,570
source filter and map and this

00:31:05,200 --> 00:31:09,610
this is the window at the sum or data is

00:31:07,570 --> 00:31:11,649
coming from these are locked partitions

00:31:09,610 --> 00:31:13,990
and the events are flowing to the system

00:31:11,649 --> 00:31:15,940
there's some basically of virtually

00:31:13,990 --> 00:31:17,409
stateless stuff happening here they

00:31:15,940 --> 00:31:19,389
flashed the network there shuffled and

00:31:17,409 --> 00:31:20,470
then in the window do some operation

00:31:19,389 --> 00:31:23,139
happening why do you update the calendar

00:31:20,470 --> 00:31:25,480
or the aggregate and this happens in

00:31:23,139 --> 00:31:26,710
some form of state index let's let's say

00:31:25,480 --> 00:31:30,220
it's rocks to be here that's a very

00:31:26,710 --> 00:31:32,350
common option entering the persistence

00:31:30,220 --> 00:31:34,840
part inside flink actually consists of

00:31:32,350 --> 00:31:36,760
two things triggering a checkpoint is

00:31:34,840 --> 00:31:38,799
basically an operation that comes for

00:31:36,760 --> 00:31:39,970
free the master is just going to tell

00:31:38,799 --> 00:31:41,649
the notes it's time to trigger a

00:31:39,970 --> 00:31:43,750
checkpoint and the notes will inject the

00:31:41,649 --> 00:31:46,419
checkpoint barrier into the stream a

00:31:43,750 --> 00:31:47,740
checkpoint barrier is basically a couple

00:31:46,419 --> 00:31:49,899
of bites that are injected into the

00:31:47,740 --> 00:31:52,649
stream it's a special special event so

00:31:49,899 --> 00:31:54,940
that is virtually unnoticeable overhead

00:31:52,649 --> 00:31:56,110
the checkpoint barriers actually travel

00:31:54,940 --> 00:31:57,220
through the stream and at some point

00:31:56,110 --> 00:31:59,380
they're going to reach the operators

00:31:57,220 --> 00:32:00,549
below this a little more magic involved

00:31:59,380 --> 00:32:01,600
you know if you have operators with

00:32:00,549 --> 00:32:02,769
multiple input streams there's an

00:32:01,600 --> 00:32:05,620
alignment face on the barriers and

00:32:02,769 --> 00:32:07,029
everything but once these these barriers

00:32:05,620 --> 00:32:09,220
actually reach these operators all

00:32:07,029 --> 00:32:10,750
they're going to do is in the in the

00:32:09,220 --> 00:32:12,899
rocks to be case if you if you pick the

00:32:10,750 --> 00:32:15,490
asynchronous nap short version um

00:32:12,899 --> 00:32:17,289
they're only doing a metadata operation

00:32:15,490 --> 00:32:20,860
again that they're saying okay here are

00:32:17,289 --> 00:32:23,799
trigger me a a copy on write snapshot so

00:32:20,860 --> 00:32:26,230
all you're basically getting is um that

00:32:23,799 --> 00:32:28,600
roxy be puts attack no it's a log

00:32:26,230 --> 00:32:30,580
structured merge merge tree anyways

00:32:28,600 --> 00:32:33,880
underneath the hood or something similar

00:32:30,580 --> 00:32:35,440
to that and changes that anyways

00:32:33,880 --> 00:32:36,700
appended first and all it's actually

00:32:35,440 --> 00:32:38,409
doing is it saying I'm not I'm not

00:32:36,700 --> 00:32:39,669
compacting into the old versions because

00:32:38,409 --> 00:32:40,809
actually need to hold onto these old

00:32:39,669 --> 00:32:42,159
versions interest you're not updating

00:32:40,809 --> 00:32:43,389
new versions and compacting you versions

00:32:42,159 --> 00:32:46,090
but I'm also going to hold onto the old

00:32:43,389 --> 00:32:47,649
versions for a while at least so this is

00:32:46,090 --> 00:32:50,429
if you wish a metadata operation it's

00:32:47,649 --> 00:32:54,070
it's not really costing anything and

00:32:50,429 --> 00:32:55,360
then the the part where the checkpoint

00:32:54,070 --> 00:32:57,010
barriers travel through is actually

00:32:55,360 --> 00:32:58,779
complete so we have these shadow copies

00:32:57,010 --> 00:33:00,340
of the state now and then although all

00:32:58,779 --> 00:33:02,559
the stream streaming problem actually

00:33:00,340 --> 00:33:04,510
continuous processing it does no updates

00:33:02,559 --> 00:33:06,639
on or CB and there's a background thread

00:33:04,510 --> 00:33:09,850
that just takes this copy-on-write view

00:33:06,639 --> 00:33:11,470
and and flushes it to some durable

00:33:09,850 --> 00:33:13,419
storage completely in the background

00:33:11,470 --> 00:33:17,480
it's not it's not really interfering

00:33:13,419 --> 00:33:20,490
with your streaming computation so that

00:33:17,480 --> 00:33:22,169
that all together actually sort of I

00:33:20,490 --> 00:33:23,820
think illustrates while doing the

00:33:22,169 --> 00:33:25,529
queryable state in a database where you

00:33:23,820 --> 00:33:27,509
are not in a database the critical state

00:33:25,529 --> 00:33:28,769
in the stream processor can be so much

00:33:27,509 --> 00:33:30,899
cheaper than actually doing it in a

00:33:28,769 --> 00:33:32,999
database and it can it can actually give

00:33:30,899 --> 00:33:34,590
you very good guarantees if you look at

00:33:32,999 --> 00:33:35,850
this you know Shadow Copy asynchronous

00:33:34,590 --> 00:33:37,830
flash trick it's something that Redis

00:33:35,850 --> 00:33:39,240
uses in the background but then again it

00:33:37,830 --> 00:33:40,740
doesn't help you a lot there if you want

00:33:39,240 --> 00:33:42,330
to not lose data because read this is

00:33:40,740 --> 00:33:43,769
not really integrated with a computation

00:33:42,330 --> 00:33:45,330
and with with a log and so on so it

00:33:43,769 --> 00:33:47,129
isn't it doesn't really have the ability

00:33:45,330 --> 00:33:49,259
to you know recover whatever happened in

00:33:47,129 --> 00:33:50,580
between the flashes we actually just do

00:33:49,259 --> 00:33:52,470
this all in the stream processor and

00:33:50,580 --> 00:33:54,059
something that is designed to work on a

00:33:52,470 --> 00:33:55,409
lock to replay to snapshot in the

00:33:54,059 --> 00:33:57,570
background yep you basically just get

00:33:55,409 --> 00:33:58,860
all parts working together in a way that

00:33:57,570 --> 00:34:00,659
they you know the don't impose

00:33:58,860 --> 00:34:02,429
unnecessary over it they don't redo

00:34:00,659 --> 00:34:06,330
durability work that is actually been

00:34:02,429 --> 00:34:09,000
done before anyways that's basically the

00:34:06,330 --> 00:34:11,819
whole story if you wish um the the

00:34:09,000 --> 00:34:14,099
takeaways of this story are all the

00:34:11,819 --> 00:34:15,720
following I mean if you didn't if you

00:34:14,099 --> 00:34:17,429
completely zone out and didn't listen to

00:34:15,720 --> 00:34:20,550
anything then pay attention just to

00:34:17,429 --> 00:34:22,079
these two slides like one thing that is

00:34:20,550 --> 00:34:23,429
nothing very very interesting to notice

00:34:22,079 --> 00:34:25,200
that cross system interaction is

00:34:23,429 --> 00:34:27,300
frequently the biggest bottleneck it's

00:34:25,200 --> 00:34:31,349
not it's often just not in the stream

00:34:27,300 --> 00:34:33,690
processor itself 11 big bottleneck is

00:34:31,349 --> 00:34:35,310
the is the communication between the

00:34:33,690 --> 00:34:36,990
streaming system that is you know all

00:34:35,310 --> 00:34:39,060
pipelines and flowing and the and the

00:34:36,990 --> 00:34:40,619
key value store which most key value

00:34:39,060 --> 00:34:42,540
stores were made for for something else

00:34:40,619 --> 00:34:43,770
for point point puts and looks at

00:34:42,540 --> 00:34:46,500
lookups and so on making them

00:34:43,770 --> 00:34:49,050
immediately visible and so on if you if

00:34:46,500 --> 00:34:50,970
you actually you can mitigate this

00:34:49,050 --> 00:34:52,409
bottleneck but just giving a good amount

00:34:50,970 --> 00:34:56,010
of the key value store row to the stream

00:34:52,409 --> 00:34:57,810
processor itself and apache flink has

00:34:56,010 --> 00:35:00,270
very sophisticated support for free

00:34:57,810 --> 00:35:03,200
state which which makes it which makes

00:35:00,270 --> 00:35:06,569
it possible and performant to add this

00:35:03,200 --> 00:35:09,359
about credible state itself kind of the

00:35:06,569 --> 00:35:10,680
secret sauce behind why its fastest data

00:35:09,359 --> 00:35:12,750
persistence is very fast with

00:35:10,680 --> 00:35:14,460
distributed logs like Apache Kafka with

00:35:12,750 --> 00:35:15,780
which is because it's a specialized

00:35:14,460 --> 00:35:17,490
thing right it depend only it's

00:35:15,780 --> 00:35:20,640
remembering replication and everything

00:35:17,490 --> 00:35:22,170
so this this is just you know just

00:35:20,640 --> 00:35:25,020
making a sequence of events durable

00:35:22,170 --> 00:35:27,060
without also making their the view you

00:35:25,020 --> 00:35:29,520
compute over them durable just solving

00:35:27,060 --> 00:35:30,660
this one problem good this makes makes

00:35:29,520 --> 00:35:33,750
it actually fast

00:35:30,660 --> 00:35:34,859
and then the computed state over over

00:35:33,750 --> 00:35:37,980
this view of events is actually very

00:35:34,859 --> 00:35:40,289
fast and flink because um you can do it

00:35:37,980 --> 00:35:41,579
just with local data structures and with

00:35:40,289 --> 00:35:43,339
no synchronous parts with just

00:35:41,579 --> 00:35:45,809
completely asynchronous replication and

00:35:43,339 --> 00:35:47,549
the the check pointing that that we

00:35:45,809 --> 00:35:50,819
built in to fling actually actually

00:35:47,549 --> 00:35:53,960
handles that it's it's the main

00:35:50,819 --> 00:35:53,960
takeaways thanks

00:35:59,359 --> 00:36:07,730
thank you Stefan we still have five more

00:36:02,490 --> 00:36:10,130
minutes for Q&A anyone wants to go first

00:36:07,730 --> 00:36:25,619
sorry guys on the balcony I will not go

00:36:10,130 --> 00:36:29,010
there oh ok so let us go this way thanks

00:36:25,619 --> 00:36:30,660
for then the talk you gave I have one

00:36:29,010 --> 00:36:33,869
question to your performance figures

00:36:30,660 --> 00:36:37,530
mm-hmm I just wanted to know if this was

00:36:33,869 --> 00:36:40,800
where the persistence test or just

00:36:37,530 --> 00:36:45,510
within memory eat the ones you show that

00:36:40,800 --> 00:36:47,760
where you show that the state I mean

00:36:45,510 --> 00:36:49,260
this one here this one yes is it if the

00:36:47,760 --> 00:36:51,390
you mean is the bottom row is it

00:36:49,260 --> 00:36:55,130
actually checkpointing or not yes it is

00:36:51,390 --> 00:36:55,130
actually checkpointing yeah okay thanks

00:37:03,849 --> 00:37:10,400
yeah thanks again so once you allow

00:37:07,599 --> 00:37:13,609
arbitrary clients to clear your screen

00:37:10,400 --> 00:37:14,950
processor directly how does it affect

00:37:13,609 --> 00:37:18,109
the stream processing because usually

00:37:14,950 --> 00:37:20,990
have a predictable amount of consumers

00:37:18,109 --> 00:37:22,280
and you usually scale your screen

00:37:20,990 --> 00:37:24,170
processor with the amount of data that

00:37:22,280 --> 00:37:27,740
flows in but now you get unpredictable

00:37:24,170 --> 00:37:29,780
read load yeah that's actually a very

00:37:27,740 --> 00:37:32,540
good question so these figures are

00:37:29,780 --> 00:37:34,579
basically sort of looking at the rights

00:37:32,540 --> 00:37:36,470
report um you absolutely right as soon

00:37:34,579 --> 00:37:39,020
as you're starting to throw in a lot of

00:37:36,470 --> 00:37:41,210
read a lot of red queries the reads and

00:37:39,020 --> 00:37:44,319
writes are sort of competing for

00:37:41,210 --> 00:37:46,700
resources right if you if you look at

00:37:44,319 --> 00:37:49,730
where do we have it at this figure here

00:37:46,700 --> 00:37:53,150
if you're if you're actually making at

00:37:49,730 --> 00:37:55,160
the same time an update here and you

00:37:53,150 --> 00:37:56,839
still hold on to this other snapshot

00:37:55,160 --> 00:37:58,550
copy your ever iterating over it and

00:37:56,839 --> 00:37:59,990
you're persisting it this is going to be

00:37:58,550 --> 00:38:01,460
a little bit of content for resources

00:37:59,990 --> 00:38:02,960
that's absolutely true so I mean a very

00:38:01,460 --> 00:38:05,390
natural follow-up would be would be to

00:38:02,960 --> 00:38:07,910
benchmark this the the read and write

00:38:05,390 --> 00:38:09,589
traders I think the like the read this

00:38:07,910 --> 00:38:12,680
there's going to be a bunch of retratos

00:38:09,589 --> 00:38:14,230
i would agree here because at least in

00:38:12,680 --> 00:38:17,240
this initial version for example the

00:38:14,230 --> 00:38:18,470
there's not multiple replicas from which

00:38:17,240 --> 00:38:19,550
you could actually read right this is

00:38:18,470 --> 00:38:20,900
something that you would have in

00:38:19,550 --> 00:38:22,250
Cassandra you have multiple notes that

00:38:20,900 --> 00:38:24,710
you hold the replicas they can in theory

00:38:22,250 --> 00:38:26,390
balance the reeds over them that is not

00:38:24,710 --> 00:38:28,760
yet happening here this sort of a

00:38:26,390 --> 00:38:30,410
natural follow-up if you wish to to let

00:38:28,760 --> 00:38:32,900
the notes replicate each other stage

00:38:30,410 --> 00:38:34,460
basically coordinated on checkpoints or

00:38:32,900 --> 00:38:35,660
so which which would give you that but

00:38:34,460 --> 00:38:38,510
in the first version it doesn't have

00:38:35,660 --> 00:38:40,730
that the read path you're also not

00:38:38,510 --> 00:38:42,260
seeing good good numbers for the or any

00:38:40,730 --> 00:38:44,030
numbers for the read part in here

00:38:42,260 --> 00:38:45,200
because that actually is the part that

00:38:44,030 --> 00:38:47,359
changed the most in our implementation

00:38:45,200 --> 00:38:48,980
so far so the first prototype was

00:38:47,359 --> 00:38:52,069
actually implementing the read paths are

00:38:48,980 --> 00:38:53,480
based on on our internally oh yeah

00:38:52,069 --> 00:38:55,010
creating creating actors that would

00:38:53,480 --> 00:38:58,700
answer the read queries and so on so to

00:38:55,010 --> 00:38:59,869
sort of allow you to integrate this we

00:38:58,700 --> 00:39:02,630
didn't want to tie it to our car in the

00:38:59,869 --> 00:39:04,220
answer we're we're with we created a

00:39:02,630 --> 00:39:05,660
protocol based on Eddie for the next

00:39:04,220 --> 00:39:07,040
version and so on and on all of these

00:39:05,660 --> 00:39:09,319
have slightly different characteristics

00:39:07,040 --> 00:39:11,450
so there's our this is going to be

00:39:09,319 --> 00:39:15,060
there's going to be some numbers but I

00:39:11,450 --> 00:39:16,710
think we have to converge the

00:39:15,060 --> 00:39:18,240
a little bit before before it makes

00:39:16,710 --> 00:39:19,440
sense to present something because the

00:39:18,240 --> 00:39:24,930
read numbers would actually I think

00:39:19,440 --> 00:39:26,460
change over time with evolution okay so

00:39:24,930 --> 00:39:28,470
I mean just as a conclusion I think this

00:39:26,460 --> 00:39:31,010
is sort of it makes a lot of sense for

00:39:28,470 --> 00:39:33,060
very right heavy right heavy throughputs

00:39:31,010 --> 00:39:34,500
that was basically the scenarios that

00:39:33,060 --> 00:39:36,660
motivated it and in which we charted out

00:39:34,500 --> 00:39:38,850
in which it worked very well if you have

00:39:36,660 --> 00:39:40,260
scenarios which are basically not doing

00:39:38,850 --> 00:39:43,440
a lot of riots but extremely read heavy

00:39:40,260 --> 00:39:46,050
I have we've yet to see I probably would

00:39:43,440 --> 00:39:48,630
take some some some add-ons to make it

00:39:46,050 --> 00:39:53,100
suitable for that let us take just one

00:39:48,630 --> 00:39:55,710
more question does flink also of our

00:39:53,100 --> 00:39:58,530
authorization for the queries you have

00:39:55,710 --> 00:40:01,260
if i have different users to do the

00:39:58,530 --> 00:40:04,380
skills um I in this in this first

00:40:01,260 --> 00:40:08,370
prototype never doesn't there's um is a

00:40:04,380 --> 00:40:12,900
whole whole threat in in Flint going on

00:40:08,370 --> 00:40:15,240
about security permissions right now you

00:40:12,900 --> 00:40:18,810
know working with kerberos with key taps

00:40:15,240 --> 00:40:20,880
integrating more with Kafka renewing

00:40:18,810 --> 00:40:24,660
tokens for Hadoop and so on i think it

00:40:20,880 --> 00:40:26,610
makes sense to say this basically should

00:40:24,660 --> 00:40:29,340
extend to queryable state as well at

00:40:26,610 --> 00:40:31,050
some point in time but at this at this

00:40:29,340 --> 00:40:33,210
point now and this and the poll regrets

00:40:31,050 --> 00:40:34,920
that I showed here there's is no

00:40:33,210 --> 00:40:43,440
implementation of authorization

00:40:34,920 --> 00:40:45,600
encryption and authentication okay thank

00:40:43,440 --> 00:40:47,340
you and actually it is not a prototype

00:40:45,600 --> 00:40:50,220
by the production version of lunch

00:40:47,340 --> 00:40:53,900
waiting for you just outside thank you

00:40:50,220 --> 00:40:53,900

YouTube URL: https://www.youtube.com/watch?v=VUC_FAjvJww


