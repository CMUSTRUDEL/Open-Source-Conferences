Title: Berlin Buzzwords 2016: Eric Evans - Wikimedia Content API: A Cassandra Use-case #bbuzz
Publication date: 2016-06-12
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	The Wikimedia Foundation is a non-profit and charitable organization driven by a vision of a world where every human can freely share in the sum of all knowledge. Each month Wikimedia sites serve over 18 billion page views to 500 million unique visitors around the world.

Among the many resources offered by Wikimedia is a public-facing API that provides low-latency, programmatic access to full-history content and meta-data, in a variety of formats.  Commonly, results from this system are the product of computationally intensive transformations, and must be pre-generated and persisted to meet latency expectations.  Unsurprisingly, there are numerous challenges to providing low-latency storage of such a massive data-set, in a demanding, globally distributed environment.

In this talk, we will cover the Wikimedia content API, and it's use of Apache Cassandra, a massively-scalable distributed database, as storage for a diverse and growing set of use-cases. Trials, tribulations, and triumphs, of both a development and operational nature will be discussed.

Read more:
https://2016.berlinbuzzwords.de/session/wikimedia-content-api-cassandra-use-case

About Eric Evans:
https://2016.berlinbuzzwords.de/users/eric-evans

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:02,540 --> 00:00:08,580
right so thank you all for coming my

00:00:06,420 --> 00:00:12,480
name is eric evans i work for the

00:00:08,580 --> 00:00:14,670
wikimedia foundation full disclosure i

00:00:12,480 --> 00:00:17,250
am also a member of the cassandra pmc

00:00:14,670 --> 00:00:19,410
and there was a time when i worked on

00:00:17,250 --> 00:00:22,230
Cassandra a full time that was my job

00:00:19,410 --> 00:00:24,480
that is not the capacity that I'm

00:00:22,230 --> 00:00:27,660
presenting today my time at the

00:00:24,480 --> 00:00:29,189
foundation has kind of given me the best

00:00:27,660 --> 00:00:32,790
opportunity I've had so far at easton

00:00:29,189 --> 00:00:35,010
from modern modern day cassandra to

00:00:32,790 --> 00:00:36,780
develop an application against Cassandra

00:00:35,010 --> 00:00:39,270
and to be involved in the operations of

00:00:36,780 --> 00:00:41,850
the cluster and it's been you know quite

00:00:39,270 --> 00:00:45,510
an eye-opener so to be on the other side

00:00:41,850 --> 00:00:49,140
of the fence so that's kind of the frame

00:00:45,510 --> 00:00:52,020
of reference for this for this talk the

00:00:49,140 --> 00:00:57,210
wikimedia foundation well Wikimedia in

00:00:52,020 --> 00:01:01,379
general is an umbrella that represents a

00:00:57,210 --> 00:01:03,739
number of member projects I'm all sort

00:01:01,379 --> 00:01:06,840
of in the scope of free knowledge

00:01:03,739 --> 00:01:09,590
collaboratively edited free knowledge it

00:01:06,840 --> 00:01:12,330
is our mission for a world in which

00:01:09,590 --> 00:01:16,710
every single human can freely access to

00:01:12,330 --> 00:01:19,799
some of all knowledge the projects in

00:01:16,710 --> 00:01:23,520
total amount to over 16 billion page

00:01:19,799 --> 00:01:26,070
views every month I believe it is my

00:01:23,520 --> 00:01:28,020
understanding that if you were to add up

00:01:26,070 --> 00:01:29,820
the aggregate traffic that it would be

00:01:28,020 --> 00:01:34,770
equal to about the number of 5th ranked

00:01:29,820 --> 00:01:37,700
web property wikipedia alone at 38

00:01:34,770 --> 00:01:40,290
million articles in almost 300 languages

00:01:37,700 --> 00:01:44,939
10,000 the articles every day is ranked

00:01:40,290 --> 00:01:47,700
number 6 all by itself so let's look at

00:01:44,939 --> 00:01:49,079
the architecture a little bit just to

00:01:47,700 --> 00:01:51,630
give some background I'm going to build

00:01:49,079 --> 00:01:54,899
a use case and then talk a little bit

00:01:51,630 --> 00:01:56,219
about our use of cassandra and sort of

00:01:54,899 --> 00:02:00,119
our experiences but let me start with

00:01:56,219 --> 00:02:02,310
some background one of those logos on

00:02:00,119 --> 00:02:04,770
the on the screen of all the projects

00:02:02,310 --> 00:02:06,960
was for mediawiki which isn't

00:02:04,770 --> 00:02:09,149
technically a free knowledge project is

00:02:06,960 --> 00:02:10,649
a free software project it's the

00:02:09,149 --> 00:02:11,090
software that we host all of the wiki's

00:02:10,649 --> 00:02:14,480
at

00:02:11,090 --> 00:02:16,489
at at wikimedia and it's it's kind of

00:02:14,480 --> 00:02:19,610
old school it's very mature applications

00:02:16,489 --> 00:02:21,500
been around for quite a while and so you

00:02:19,610 --> 00:02:22,940
know for all those people who are who

00:02:21,500 --> 00:02:24,830
jumped all the latest languages and

00:02:22,940 --> 00:02:29,950
frameworks it's kind of boring it's a

00:02:24,830 --> 00:02:32,739
lamp stack linux apache mysql and PHP

00:02:29,950 --> 00:02:36,739
but very simple very straightforward and

00:02:32,739 --> 00:02:38,510
yet the most comprehensive architecture

00:02:36,739 --> 00:02:41,060
diagram i could find was this one and

00:02:38,510 --> 00:02:43,599
even i can tell that this oversimplifies

00:02:41,060 --> 00:02:45,920
a great deal and emits a great deal

00:02:43,599 --> 00:02:48,440
clearly that's a lot more complicated

00:02:45,920 --> 00:02:52,130
looking than a simple lamp stack

00:02:48,440 --> 00:02:53,540
architecture i'm not going to dive into

00:02:52,130 --> 00:02:55,549
that architecture diagram and try to

00:02:53,540 --> 00:02:58,129
explain everything even if even if I

00:02:55,549 --> 00:03:00,530
could it was just sort of to demonstrate

00:02:58,129 --> 00:03:03,560
that when you're hosting it Wikipedia

00:03:00,530 --> 00:03:05,299
scale and the number of features and the

00:03:03,560 --> 00:03:07,459
number of integrations that at Wikimedia

00:03:05,299 --> 00:03:10,370
hosts things get rapidly much more

00:03:07,459 --> 00:03:13,579
complex I'm going to focus on just one

00:03:10,370 --> 00:03:16,730
of those complexities which is visual

00:03:13,579 --> 00:03:20,720
editor so as most of you probably know

00:03:16,730 --> 00:03:22,970
any in a wiki we have this concept of

00:03:20,720 --> 00:03:27,260
well in mediawiki at least is called

00:03:22,970 --> 00:03:30,889
wikitext of a a plain text format that

00:03:27,260 --> 00:03:33,799
is relatively friendly for humans to

00:03:30,889 --> 00:03:35,720
edit and the reason for that is what we

00:03:33,799 --> 00:03:38,239
need to send to the browser is HTML and

00:03:35,720 --> 00:03:41,840
editing that directly is decidedly not

00:03:38,239 --> 00:03:44,090
friendly so the way this works is you

00:03:41,840 --> 00:03:46,489
know you have a web form you enter in

00:03:44,090 --> 00:03:48,709
your wiki text you know you match save

00:03:46,489 --> 00:03:51,109
and you're presented with you know the

00:03:48,709 --> 00:03:52,579
HTML representation of that document and

00:03:51,109 --> 00:03:56,000
at the core of all this obviously is a

00:03:52,579 --> 00:03:57,500
conversion from wiki text to HTML when

00:03:56,000 --> 00:03:59,900
you want to go back and edit again you

00:03:57,500 --> 00:04:01,970
go back to the last edited version of

00:03:59,900 --> 00:04:04,220
the wiki text document you edit it and

00:04:01,970 --> 00:04:06,650
click Save and you Marshall that into

00:04:04,220 --> 00:04:10,220
HTML for the browser what visual editor

00:04:06,650 --> 00:04:13,220
gives you is a wussy wig editor what you

00:04:10,220 --> 00:04:16,639
see is what you get so when you match

00:04:13,220 --> 00:04:19,549
edit and visual editor is enabled you

00:04:16,639 --> 00:04:21,109
stay on that HTML representation editor

00:04:19,549 --> 00:04:23,400
controls appear and allow you to select

00:04:21,109 --> 00:04:25,770
formatting you know

00:04:23,400 --> 00:04:28,380
whether you're editing a section header

00:04:25,770 --> 00:04:30,540
or paragraph bullets links the sort of

00:04:28,380 --> 00:04:32,910
thing and then when you manage to save

00:04:30,540 --> 00:04:34,560
the editor controls disappear this is

00:04:32,910 --> 00:04:40,650
really nice it's not a JavaScript hacked

00:04:34,560 --> 00:04:42,330
this uses html5 content editable so it's

00:04:40,650 --> 00:04:46,050
a very nice editing experience this is

00:04:42,330 --> 00:04:48,060
really great because as as much as much

00:04:46,050 --> 00:04:50,490
friendlier as wikitext is for editing

00:04:48,060 --> 00:04:51,750
HTML it's still kind of off-putting to

00:04:50,490 --> 00:04:55,350
it to most people so this is really

00:04:51,750 --> 00:04:57,389
lowers the barrier to contribution but

00:04:55,350 --> 00:04:59,789
it goes without saying that it also

00:04:57,389 --> 00:05:02,780
requires that we're able to convert from

00:04:59,789 --> 00:05:05,789
HTML back to wiki text because we have

00:05:02,780 --> 00:05:09,690
15 years of history 38 million articles

00:05:05,789 --> 00:05:11,310
in Wikipedia alone worth of history a

00:05:09,690 --> 00:05:13,590
lot of people are still going to prefer

00:05:11,310 --> 00:05:16,080
editing wikitext we can't just change to

00:05:13,590 --> 00:05:18,180
editing HTML it's a big ship take a long

00:05:16,080 --> 00:05:20,849
time to steer so we need to be able to

00:05:18,180 --> 00:05:23,699
go not only from wiki text to HTML from

00:05:20,849 --> 00:05:26,789
HTML back to wiki text and that's not as

00:05:23,699 --> 00:05:29,940
simple as it might sound one example of

00:05:26,789 --> 00:05:31,830
a complication there is history we

00:05:29,940 --> 00:05:34,349
expect to be able to do character-based

00:05:31,830 --> 00:05:36,960
diffs between arbitrary revisions of a

00:05:34,349 --> 00:05:39,419
document so if in the conversion from

00:05:36,960 --> 00:05:41,820
HTML back to wiki text you normalize any

00:05:39,419 --> 00:05:44,639
portion of the document outside of what

00:05:41,820 --> 00:05:49,590
the the editor did themselves then you

00:05:44,639 --> 00:05:51,449
create a dirty diff so the way you do

00:05:49,590 --> 00:05:55,020
that is at the time that you're

00:05:51,449 --> 00:05:57,419
marshalling the wiki text to HTML for

00:05:55,020 --> 00:05:59,880
that given version the given revision of

00:05:57,419 --> 00:06:01,860
wiki text you kind of evaluate as you go

00:05:59,880 --> 00:06:03,780
what would it take to preserve this

00:06:01,860 --> 00:06:06,330
formatting on the round trip back from

00:06:03,780 --> 00:06:08,639
HTML and you supply that information in

00:06:06,330 --> 00:06:12,090
the form of additional metadata so if

00:06:08,639 --> 00:06:14,940
you look at this first line this is an

00:06:12,090 --> 00:06:17,880
example in wiki text of of a wiki link

00:06:14,940 --> 00:06:20,039
of an internal link to a page named food

00:06:17,880 --> 00:06:23,430
in the same namespace that we're editing

00:06:20,039 --> 00:06:25,710
it and the link text will be bar but

00:06:23,430 --> 00:06:27,300
when Marshall to HTML you know it's just

00:06:25,710 --> 00:06:30,479
an anchor so there's really no way to

00:06:27,300 --> 00:06:33,180
tell it from you know one link type from

00:06:30,479 --> 00:06:36,160
another so in this case we pass an rdf a

00:06:33,180 --> 00:06:38,110
attribute that indicates that when we

00:06:36,160 --> 00:06:41,110
round trip back to to wiki text that

00:06:38,110 --> 00:06:44,710
this should be a wiki link a little bit

00:06:41,110 --> 00:06:46,540
more complex example if the link text is

00:06:44,710 --> 00:06:48,460
the product of a template and we want to

00:06:46,540 --> 00:06:51,130
trance clued that template into the

00:06:48,460 --> 00:06:53,290
final output we don't want to take that

00:06:51,130 --> 00:06:54,880
output then and push that back into the

00:06:53,290 --> 00:06:57,310
wiki text we want to get the template

00:06:54,880 --> 00:07:00,790
back again so in this case you know

00:06:57,310 --> 00:07:04,240
we're out that value text the link value

00:07:00,790 --> 00:07:05,800
in a span with attributes to indicate

00:07:04,240 --> 00:07:07,510
that that's a template and then we have

00:07:05,800 --> 00:07:09,820
this data par soy tu attribute is

00:07:07,510 --> 00:07:12,430
private attribute that stores the actual

00:07:09,820 --> 00:07:14,290
template itself and in practice and more

00:07:12,430 --> 00:07:16,390
complicated examples that private

00:07:14,290 --> 00:07:18,250
attribute can actually get really you

00:07:16,390 --> 00:07:20,950
know really verbose can get right down

00:07:18,250 --> 00:07:21,970
to character and bite offsets in an

00:07:20,950 --> 00:07:24,550
effort to you have all the information

00:07:21,970 --> 00:07:28,120
necessary to to reconstitute that

00:07:24,550 --> 00:07:30,940
original text formatting so we do this

00:07:28,120 --> 00:07:33,160
conversion to HTML it's round trip about

00:07:30,940 --> 00:07:35,620
HTML with a stateless microservice

00:07:33,160 --> 00:07:39,250
called parsley which is written in

00:07:35,620 --> 00:07:41,740
nodejs it exists specifically for this

00:07:39,250 --> 00:07:43,570
service taking specific revision of wiki

00:07:41,740 --> 00:07:46,320
text and create the HTML representation

00:07:43,570 --> 00:07:49,830
that can then be edited and and

00:07:46,320 --> 00:07:53,380
converted back to wiki text without

00:07:49,830 --> 00:07:57,010
altering any any without introducing any

00:07:53,380 --> 00:07:58,870
non-normative changes the reason this is

00:07:57,010 --> 00:08:01,419
an external service primarily is because

00:07:58,870 --> 00:08:03,850
visual editor is is a is an extension

00:08:01,419 --> 00:08:05,950
it's an add-on to mediawiki and because

00:08:03,850 --> 00:08:08,370
this wouldn't be a good general purpose

00:08:05,950 --> 00:08:10,690
solution for converting to HTML

00:08:08,370 --> 00:08:14,380
converting like this is computationally

00:08:10,690 --> 00:08:16,240
intensive so it's slower the output is

00:08:14,380 --> 00:08:18,210
larger so it takes longer to transfer

00:08:16,240 --> 00:08:20,680
which would make page load times higher

00:08:18,210 --> 00:08:23,590
the DOM is just even more complex and

00:08:20,680 --> 00:08:25,210
takes browsers longer to load so you

00:08:23,590 --> 00:08:27,190
know we targeted only at users who are

00:08:25,210 --> 00:08:29,440
going to need to edit that each tml and

00:08:27,190 --> 00:08:32,320
we use a lighter weight conversion for

00:08:29,440 --> 00:08:34,780
the general general case also having it

00:08:32,320 --> 00:08:36,490
as an external service lets the scale it

00:08:34,780 --> 00:08:37,960
out horizontally so this is one of those

00:08:36,490 --> 00:08:40,150
things that contributes to that extra

00:08:37,960 --> 00:08:42,880
complexity on that on that architecture

00:08:40,150 --> 00:08:45,100
diagram part so it is stateless though

00:08:42,880 --> 00:08:46,860
so we host it behind another service

00:08:45,100 --> 00:08:49,579
from the from Wickham

00:08:46,860 --> 00:08:52,019
you called rest base which is a sort of

00:08:49,579 --> 00:08:57,329
services aggregator that performs

00:08:52,019 --> 00:09:00,269
durable caching of responses so it looks

00:08:57,329 --> 00:09:02,190
something like this those durable Cashin

00:09:00,269 --> 00:09:04,350
occurs in Cassandra we persist those

00:09:02,190 --> 00:09:06,000
response values in Cassandra and there

00:09:04,350 --> 00:09:08,610
are other services that we aggregate

00:09:06,000 --> 00:09:11,510
behind rest base as well examples

00:09:08,610 --> 00:09:15,570
include mobile content service we have

00:09:11,510 --> 00:09:18,690
Android and iOS clients applications

00:09:15,570 --> 00:09:21,079
that exist to provide a more Native feel

00:09:18,690 --> 00:09:23,130
for those in those those platforms

00:09:21,079 --> 00:09:26,220
sometimes that involves transforming the

00:09:23,130 --> 00:09:28,589
content the mobile content service does

00:09:26,220 --> 00:09:32,250
those transformations and then can

00:09:28,589 --> 00:09:35,810
persist those in rest base so that's my

00:09:32,250 --> 00:09:40,320
use case let's look a little bit at

00:09:35,810 --> 00:09:45,209
cassandra cassandra is use in that this

00:09:40,320 --> 00:09:46,950
purpose so we have two data centers we

00:09:45,209 --> 00:09:48,720
use Cassandra's network topology

00:09:46,950 --> 00:09:52,350
strategy to distribute a total of six

00:09:48,720 --> 00:09:56,339
six replicas three each across two data

00:09:52,350 --> 00:09:58,500
centers in in Cassandra parlance we also

00:09:56,339 --> 00:10:03,660
distribute within the data center across

00:09:58,500 --> 00:10:05,760
three racks in reality for us the row is

00:10:03,660 --> 00:10:07,220
the level of infrastructure isolation

00:10:05,760 --> 00:10:10,860
we're looking for that's where we have a

00:10:07,220 --> 00:10:12,390
where we share common p to use so we can

00:10:10,860 --> 00:10:14,070
lose an entire row in a data center and

00:10:12,390 --> 00:10:16,110
still be available we can lose an entire

00:10:14,070 --> 00:10:20,250
data center and be available it's just

00:10:16,110 --> 00:10:21,959
really nice we run 18 hosts 18 physical

00:10:20,250 --> 00:10:24,810
machines but we have a 50 note-for-note

00:10:21,959 --> 00:10:27,149
cassandra cluster so we have three times

00:10:24,810 --> 00:10:29,760
more cassandra nodes than we do hosts

00:10:27,149 --> 00:10:32,850
and i will expound on that in a little

00:10:29,760 --> 00:10:34,440
bit here we use deflate compression and

00:10:32,850 --> 00:10:36,300
cassandra which is a little unusual it's

00:10:34,440 --> 00:10:38,160
not the default there aren't very many

00:10:36,300 --> 00:10:40,500
people using the plate and we also get

00:10:38,160 --> 00:10:43,589
higher compression sizes which I will

00:10:40,500 --> 00:10:46,680
explain as well and it is a read heavy

00:10:43,589 --> 00:10:48,420
workload for Cassandra which probably

00:10:46,680 --> 00:10:50,970
comes as no surprise given I described

00:10:48,420 --> 00:10:53,490
it as that's a durable cash but 521 is

00:10:50,970 --> 00:10:56,970
maybe not as as higher Reed Reed heavy

00:10:53,490 --> 00:10:58,470
as you would think on every single

00:10:56,970 --> 00:10:59,760
document edit we fire off an

00:10:58,470 --> 00:11:02,910
asynchronous job too

00:10:59,760 --> 00:11:05,040
I'm the cash you know hedging our bets

00:11:02,910 --> 00:11:07,980
against someone might maybe wanting to

00:11:05,040 --> 00:11:09,870
edit that in that visual editor so the

00:11:07,980 --> 00:11:11,910
right right rate is maybe a bit higher

00:11:09,870 --> 00:11:16,860
and you might expect and this is kind of

00:11:11,910 --> 00:11:20,550
a second-tier cash to our CDN so rest

00:11:16,860 --> 00:11:24,600
base is hit to produce this output only

00:11:20,550 --> 00:11:26,520
when there's a cache miss on the CDN all

00:11:24,600 --> 00:11:28,770
right so let's look at the the data

00:11:26,520 --> 00:11:30,840
model if you look at this in Cassandra

00:11:28,770 --> 00:11:32,940
ddl like what you would use to create

00:11:30,840 --> 00:11:34,830
the table and I'll limit this just to

00:11:32,940 --> 00:11:37,200
the HTML storage and this is a bit

00:11:34,830 --> 00:11:41,420
oversimplified we have these attributes

00:11:37,200 --> 00:11:45,180
domain title revision tid and value

00:11:41,420 --> 00:11:49,800
domain is the is the the Wikimedia site

00:11:45,180 --> 00:11:51,960
domain so en.wikipedia.org wikipedia.org

00:11:49,800 --> 00:11:54,650
something like that title is the

00:11:51,960 --> 00:11:57,830
document title revision is the

00:11:54,650 --> 00:12:00,390
monotonically increasing revision ID

00:11:57,830 --> 00:12:02,870
supplied by mediawiki so whenever

00:12:00,390 --> 00:12:05,640
someone edits a document in mediawiki

00:12:02,870 --> 00:12:08,640
mediawiki assigns it a new revision this

00:12:05,640 --> 00:12:10,620
is that revision the tid value here is

00:12:08,640 --> 00:12:12,300
kind of a misnomer I guess is also a

00:12:10,620 --> 00:12:14,640
sort of revision it's one that is

00:12:12,300 --> 00:12:17,730
created by rest base it is meant to

00:12:14,640 --> 00:12:20,310
indicate the revision of the HTML for

00:12:17,730 --> 00:12:21,870
that revision of document and the reason

00:12:20,310 --> 00:12:24,060
this is necessary is that we do full

00:12:21,870 --> 00:12:25,700
page renders and so there's always some

00:12:24,060 --> 00:12:28,200
sort of trance cluded material in there

00:12:25,700 --> 00:12:29,730
if you think in terms of say a template

00:12:28,200 --> 00:12:31,380
if a template is edited some were

00:12:29,730 --> 00:12:33,330
centrally every document that includes

00:12:31,380 --> 00:12:36,240
that template would then need to be rear

00:12:33,330 --> 00:12:40,380
end ered even if those those documents

00:12:36,240 --> 00:12:42,450
themselves didn't change so it's sort of

00:12:40,380 --> 00:12:45,390
a revision of the revision is the HTML

00:12:42,450 --> 00:12:48,480
revision of the wiki text revision and

00:12:45,390 --> 00:12:51,540
then blob blob of course value is where

00:12:48,480 --> 00:12:54,380
we store the HTML itself the way these

00:12:51,540 --> 00:12:58,020
clustered primary keys work in Cassandra

00:12:54,380 --> 00:12:59,910
determines the layout of the data so the

00:12:58,020 --> 00:13:01,800
first first component of that

00:12:59,910 --> 00:13:03,360
parenthesized value is always the

00:13:01,800 --> 00:13:05,820
partition key is what determines

00:13:03,360 --> 00:13:07,580
placement in the cluster the term is

00:13:05,820 --> 00:13:10,530
distribution around around the network

00:13:07,580 --> 00:13:12,570
in this case that is also you know

00:13:10,530 --> 00:13:13,560
parenthesized value it's the domain and

00:13:12,570 --> 00:13:17,250
title

00:13:13,560 --> 00:13:19,560
it's like a 2-tuple a pair so every

00:13:17,250 --> 00:13:22,260
domain title unique domain title

00:13:19,560 --> 00:13:24,480
combination is used to do to determine

00:13:22,260 --> 00:13:27,690
placement within the cluster these

00:13:24,480 --> 00:13:29,940
subsequent values set up a mini to one

00:13:27,690 --> 00:13:32,730
relationship between them themselves and

00:13:29,940 --> 00:13:36,060
the values superior adjacent to the left

00:13:32,730 --> 00:13:37,890
so for each unique domain title we can

00:13:36,060 --> 00:13:40,560
have an arbitrary number of revisions

00:13:37,890 --> 00:13:42,960
and for each unique domain title

00:13:40,560 --> 00:13:46,290
revision we can have an arbitrary number

00:13:42,960 --> 00:13:47,700
of these T IDs the renders and since the

00:13:46,290 --> 00:13:50,550
value does not appear in that that

00:13:47,700 --> 00:13:54,020
definition for each unique domain title

00:13:50,550 --> 00:13:56,850
revision tid will be exactly one value

00:13:54,020 --> 00:13:59,490
and this also sets up ordering ordering

00:13:56,850 --> 00:14:02,040
of the data the order the data is

00:13:59,490 --> 00:14:03,660
actually persisted on disk so that it is

00:14:02,040 --> 00:14:06,029
ordered first by revision and then by

00:14:03,660 --> 00:14:09,200
tid so if you select and limit one you

00:14:06,029 --> 00:14:12,540
essentially get the most recent value

00:14:09,200 --> 00:14:15,690
another way of looking at that is a like

00:14:12,540 --> 00:14:18,450
this again for a domain and title pair

00:14:15,690 --> 00:14:20,220
we can have one or more revisions and

00:14:18,450 --> 00:14:23,430
for each revision we can have one or

00:14:20,220 --> 00:14:24,630
more of the renders of that HTML this is

00:14:23,430 --> 00:14:25,980
kind of important because this is the

00:14:24,630 --> 00:14:29,820
way the data ends up being laid out on

00:14:25,980 --> 00:14:31,410
disk at least in each table file the

00:14:29,820 --> 00:14:34,260
data is laid out like this in sorted

00:14:31,410 --> 00:14:37,800
order which is important because of

00:14:34,260 --> 00:14:39,420
compression for example one thing that

00:14:37,800 --> 00:14:41,460
all general-purpose compression

00:14:39,420 --> 00:14:44,550
algorithms have in common is that they

00:14:41,460 --> 00:14:46,860
look for repetition and attempt to store

00:14:44,550 --> 00:14:50,280
back references to a single copy of that

00:14:46,860 --> 00:14:53,940
repetitive material that works well for

00:14:50,280 --> 00:14:56,700
us because most revisions most whether

00:14:53,940 --> 00:14:58,380
the renders individual HTML renders of a

00:14:56,700 --> 00:15:01,800
particular revision or the revisions

00:14:58,380 --> 00:15:03,810
themselves is it is most typical that

00:15:01,800 --> 00:15:05,970
the content alt changes between them

00:15:03,810 --> 00:15:09,180
very little that the amount of

00:15:05,970 --> 00:15:11,279
repetition is very very high so

00:15:09,180 --> 00:15:15,810
Cassandra gives us this tunable chunk

00:15:11,279 --> 00:15:17,370
length kb that determines the size of

00:15:15,810 --> 00:15:20,190
data as it's being streamed off disk

00:15:17,370 --> 00:15:23,010
that will be given to the compressor

00:15:20,190 --> 00:15:26,100
implementation so by widening that chunk

00:15:23,010 --> 00:15:27,870
length we're able to find more of that

00:15:26,100 --> 00:15:31,850
petition and bring the compression sizes

00:15:27,870 --> 00:15:36,779
down with with within reasonable limits

00:15:31,850 --> 00:15:39,600
deflate has a fixed 37k window size so

00:15:36,779 --> 00:15:42,149
documents that exceed 37 k the you know

00:15:39,600 --> 00:15:43,589
the HTML render you know that starts to

00:15:42,149 --> 00:15:45,720
fall off rather quickly the benefits of

00:15:43,589 --> 00:15:47,040
given this which is why we've been

00:15:45,720 --> 00:15:49,040
looking at a compression algorithm

00:15:47,040 --> 00:15:51,440
called brawley which is relatively new

00:15:49,040 --> 00:15:54,149
brought to you by the folks at Google

00:15:51,440 --> 00:15:58,440
we've written a cassandra implementation

00:15:54,149 --> 00:16:00,509
for it I didn't have ready for this for

00:15:58,440 --> 00:16:02,250
this talk and you know formal results

00:16:00,509 --> 00:16:04,290
anything I really felt confident to

00:16:02,250 --> 00:16:06,180
stand behind but the initial results are

00:16:04,290 --> 00:16:09,240
very promising we've done quite a bit of

00:16:06,180 --> 00:16:10,800
testing using settings that are

00:16:09,240 --> 00:16:12,089
comparable that allow an

00:16:10,800 --> 00:16:14,610
apples-to-apples comparison between

00:16:12,089 --> 00:16:17,509
deflate and the results match up pretty

00:16:14,610 --> 00:16:20,519
well with the you know publicly posted

00:16:17,509 --> 00:16:22,649
comparisons of broadly to deflate which

00:16:20,519 --> 00:16:26,069
is that you get smaller compressed sizes

00:16:22,649 --> 00:16:27,660
at a lower computational cost so it's a

00:16:26,069 --> 00:16:29,160
win either way but one of the things

00:16:27,660 --> 00:16:30,870
that broadly will let you do is will let

00:16:29,160 --> 00:16:32,279
you open that window up so now we can

00:16:30,870 --> 00:16:36,180
kind of almost treat it like a binary

00:16:32,279 --> 00:16:37,889
differ and one of the examples i'll post

00:16:36,180 --> 00:16:39,660
these slides afterwards i have links to

00:16:37,889 --> 00:16:42,529
some tickets here there's a little bit

00:16:39,660 --> 00:16:44,399
more detail in this ticket on the slide

00:16:42,529 --> 00:16:48,300
but one of the examples there were

00:16:44,399 --> 00:16:50,069
documents that are two 250k in size and

00:16:48,300 --> 00:16:53,009
with a for Meg chunk length and a

00:16:50,069 --> 00:16:55,139
corresponding brought the window size we

00:16:53,009 --> 00:16:56,519
were able to get compressed sizes of one

00:16:55,139 --> 00:17:00,230
point seven three percent of the

00:16:56,519 --> 00:17:04,230
original which is really really good

00:17:00,230 --> 00:17:06,329
okay so compression has been a pretty

00:17:04,230 --> 00:17:08,549
important topic for us something we

00:17:06,329 --> 00:17:09,870
spend a lot of time on impaction is also

00:17:08,549 --> 00:17:12,959
something that's occupied a fair amount

00:17:09,870 --> 00:17:14,699
of our time compaction and cassandra is

00:17:12,959 --> 00:17:17,270
is basically the price you pay for

00:17:14,699 --> 00:17:20,130
having a log structured storage engine

00:17:17,270 --> 00:17:23,100
it's an asynchronous background process

00:17:20,130 --> 00:17:24,630
that attempts to to keep up with the

00:17:23,100 --> 00:17:27,059
with the rights that are occurring and

00:17:24,630 --> 00:17:30,179
reorganize the data to make it more

00:17:27,059 --> 00:17:33,480
optimal for the reeds cassandra presents

00:17:30,179 --> 00:17:36,030
a metric a histogram called SS tables /

00:17:33,480 --> 00:17:37,900
read essentially the number of SS tables

00:17:36,030 --> 00:17:41,150
that need to be

00:17:37,900 --> 00:17:44,210
contacted in order to satisfy reads and

00:17:41,150 --> 00:17:45,950
we watch that very closely because read

00:17:44,210 --> 00:17:47,510
latency tracks pretty closely with the

00:17:45,950 --> 00:17:49,190
number of SS tables that you have to

00:17:47,510 --> 00:17:51,680
sort of merge together to get the

00:17:49,190 --> 00:17:54,340
picture of your your results and it

00:17:51,680 --> 00:17:56,900
speaks to the efficacy of compaction so

00:17:54,340 --> 00:17:58,340
with compaction at a minimum what you

00:17:56,900 --> 00:18:00,980
want to do is get the total number of

00:17:58,340 --> 00:18:03,560
files down you know minimize that you

00:18:00,980 --> 00:18:06,260
know bound the number of SS table files

00:18:03,560 --> 00:18:07,580
you have if possible you'd like to to

00:18:06,260 --> 00:18:11,210
order them in such a way that the

00:18:07,580 --> 00:18:13,580
results are closer together cassandra

00:18:11,210 --> 00:18:16,160
has three different kinds of compaction

00:18:13,580 --> 00:18:18,950
strategies sighs tiered levelled and

00:18:16,160 --> 00:18:21,350
date tears sighs tiered is the simplest

00:18:18,950 --> 00:18:24,500
it just combines files of similar size

00:18:21,350 --> 00:18:27,020
together to create you know fewer larger

00:18:24,500 --> 00:18:29,890
files but it's completely oblivious to

00:18:27,020 --> 00:18:32,030
column distribution level compaction

00:18:29,890 --> 00:18:33,500
which is the compaction strategy we

00:18:32,030 --> 00:18:36,230
started out with is perhaps the most

00:18:33,500 --> 00:18:39,500
optimized for read and breeds in like

00:18:36,230 --> 00:18:42,380
the general sense it uses files of fixed

00:18:39,500 --> 00:18:44,360
sizes and organizes them in levels where

00:18:42,380 --> 00:18:46,670
each successive level has an

00:18:44,360 --> 00:18:50,000
exponentially increasing number of SS

00:18:46,670 --> 00:18:52,730
table files but the files within each of

00:18:50,000 --> 00:18:55,220
these levels are non-overlapping so if

00:18:52,730 --> 00:18:57,410
you imagine a simple point query that

00:18:55,220 --> 00:18:59,210
tends to be the SS tables / read for

00:18:57,410 --> 00:19:02,660
level compaction tends to be no worse

00:18:59,210 --> 00:19:05,120
than the number of levels which is which

00:19:02,660 --> 00:19:07,670
is very good it's the downside of that

00:19:05,120 --> 00:19:10,220
and I the reason I say we used to use it

00:19:07,670 --> 00:19:13,850
is that a the compaction throughput is

00:19:10,220 --> 00:19:15,620
very high it's just constantly busy you

00:19:13,850 --> 00:19:18,620
madly compacting data in the background

00:19:15,620 --> 00:19:21,680
so it uses a lot of i/o which brings us

00:19:18,620 --> 00:19:25,010
to day tiered compaction which tends to

00:19:21,680 --> 00:19:26,660
gain the fact that we know the

00:19:25,010 --> 00:19:29,750
timestamps of the data that was written

00:19:26,660 --> 00:19:31,970
and so if your data set is total ordered

00:19:29,750 --> 00:19:33,800
if your values that you're storing and

00:19:31,970 --> 00:19:36,890
querying against are only ever

00:19:33,800 --> 00:19:40,300
increasing then so is time and so if we

00:19:36,890 --> 00:19:41,980
compact together data according to

00:19:40,300 --> 00:19:45,940
similarity in time

00:19:41,980 --> 00:19:47,919
no tears based on the date datetime then

00:19:45,940 --> 00:19:50,590
that will you know also place your data

00:19:47,919 --> 00:19:53,080
closer together so given the sort of

00:19:50,590 --> 00:19:54,850
MVCC structure of our data model this

00:19:53,080 --> 00:19:58,210
seems like an absolute way in like this

00:19:54,850 --> 00:20:00,970
should be the one for us it has turned

00:19:58,210 --> 00:20:04,510
out in practice though that that is not

00:20:00,970 --> 00:20:06,730
the case i would try to explain in

00:20:04,510 --> 00:20:08,470
detail why it is not the case but it's

00:20:06,730 --> 00:20:10,380
i'm worried i would just get it wrong

00:20:08,470 --> 00:20:14,559
it's very hard to reason about the way

00:20:10,380 --> 00:20:16,419
dtcs actually works what i can tell you

00:20:14,559 --> 00:20:18,460
is that the optimizations are easily

00:20:16,419 --> 00:20:21,580
defeated by any kind of out of order

00:20:18,460 --> 00:20:24,850
right and cassandra that is it is almost

00:20:21,580 --> 00:20:27,490
no i don't want to use hyperbole but it

00:20:24,850 --> 00:20:30,220
feels almost impossible to avoid you

00:20:27,490 --> 00:20:31,780
know any any out of order right so read

00:20:30,220 --> 00:20:33,820
repair for example is something we

00:20:31,780 --> 00:20:35,950
usually rely on to keep the integrity of

00:20:33,820 --> 00:20:37,510
the data read repair will create out of

00:20:35,950 --> 00:20:39,360
order rights and it will essentially

00:20:37,510 --> 00:20:42,760
essentially to feel the optimizations

00:20:39,360 --> 00:20:47,110
provided here you know updates of the

00:20:42,760 --> 00:20:50,080
data of any kind produce out of order

00:20:47,110 --> 00:20:52,030
rights again i've got a ticket here if

00:20:50,080 --> 00:20:54,640
you'd like to read like a more detailed

00:20:52,030 --> 00:20:56,200
explanation of how it has failed in our

00:20:54,640 --> 00:21:00,549
specific environment you can go look at

00:20:56,200 --> 00:21:02,860
that but the the summary is we're

00:21:00,549 --> 00:21:05,770
currently using dtcs and it does not

00:21:02,860 --> 00:21:07,870
work well for us what we're planning to

00:21:05,770 --> 00:21:09,970
do about that is win when these

00:21:07,870 --> 00:21:12,220
optimizations are defeated you're

00:21:09,970 --> 00:21:13,720
essentially left with one tier one date

00:21:12,220 --> 00:21:17,020
here you know it's kind of flattens the

00:21:13,720 --> 00:21:18,960
structure out and since dtcs does size

00:21:17,020 --> 00:21:21,880
tiered compaction within within the

00:21:18,960 --> 00:21:23,710
tears we're essentially running sighs to

00:21:21,880 --> 00:21:26,140
your compaction so we may need to switch

00:21:23,710 --> 00:21:27,970
to that to be to be clear about about

00:21:26,140 --> 00:21:29,830
how this is working there's also another

00:21:27,970 --> 00:21:31,360
compaction strategies that exists

00:21:29,830 --> 00:21:32,650
outside the Cassandra tree right now

00:21:31,360 --> 00:21:34,570
that is gaining a lot of popularity

00:21:32,650 --> 00:21:37,090
called time window compaction strategy

00:21:34,570 --> 00:21:39,309
that attempts to do to build the same

00:21:37,090 --> 00:21:40,900
sort of optimizations that again you

00:21:39,309 --> 00:21:42,600
know if you ordered by time and your

00:21:40,900 --> 00:21:45,340
data set is meant to be total ordered

00:21:42,600 --> 00:21:49,059
then it will place your results near

00:21:45,340 --> 00:21:51,669
each other so we're planning to take a

00:21:49,059 --> 00:21:54,070
good look at that one of the things we

00:21:51,669 --> 00:21:54,550
may just do is just lower note density

00:21:54,070 --> 00:21:56,980
just

00:21:54,550 --> 00:21:58,690
reduce the size of the individual

00:21:56,980 --> 00:22:01,240
Cassandra nodes by deploying more of

00:21:58,690 --> 00:22:03,040
them and the reason that works is again

00:22:01,240 --> 00:22:05,920
you're interested as as tables / read

00:22:03,040 --> 00:22:08,530
and so if the efficacy of the compactor

00:22:05,920 --> 00:22:10,270
strategy is poor and the number of SS

00:22:08,530 --> 00:22:12,790
tables versus the total number of s's

00:22:10,270 --> 00:22:14,890
tables that we read from is too high

00:22:12,790 --> 00:22:16,450
then one way of solving that is just to

00:22:14,890 --> 00:22:18,280
simply reduce the total number of SS

00:22:16,450 --> 00:22:23,950
tables which reducing the data set size

00:22:18,280 --> 00:22:26,920
will do alright so moving on garbage

00:22:23,950 --> 00:22:28,540
collection it's a Java app it's latency

00:22:26,920 --> 00:22:30,280
sensitive it's got a lot of throughput

00:22:28,540 --> 00:22:32,940
so obviously garbage collection has been

00:22:30,280 --> 00:22:34,990
an issue I should come as no surprise

00:22:32,940 --> 00:22:37,570
which is one of the reasons that we have

00:22:34,990 --> 00:22:40,810
been fairly early adopters of G 1 G C

00:22:37,570 --> 00:22:44,200
been using it for quite a while now g1

00:22:40,810 --> 00:22:46,060
is short for garbage first it is meant

00:22:44,200 --> 00:22:48,550
to be a successor to concurrent mark

00:22:46,060 --> 00:22:52,770
sweep is different in that it is an

00:22:48,550 --> 00:22:56,410
incremental parallel compacting

00:22:52,770 --> 00:22:58,990
collector so it's always kind of looking

00:22:56,410 --> 00:23:01,600
for the low-hanging fruit and copying

00:22:58,990 --> 00:23:04,120
regions from one location to another to

00:23:01,600 --> 00:23:06,700
keep keep the heap continually compacted

00:23:04,120 --> 00:23:09,160
and it works really well it works in

00:23:06,700 --> 00:23:10,840
fact it works fantastic particularly if

00:23:09,160 --> 00:23:12,220
you can give it a little more memory

00:23:10,840 --> 00:23:16,570
than what you might normally need it can

00:23:12,220 --> 00:23:18,790
kind of paper over some of the some of

00:23:16,570 --> 00:23:20,260
some of the sort of impedance mismatches

00:23:18,790 --> 00:23:22,450
between the way an application that

00:23:20,260 --> 00:23:24,790
Cassandra works and a generational

00:23:22,450 --> 00:23:27,340
theory the one exception the one problem

00:23:24,790 --> 00:23:29,890
we have had is is what the you know this

00:23:27,340 --> 00:23:33,400
is this is the the g1 terminology

00:23:29,890 --> 00:23:36,760
humongous objects is with these yes its

00:23:33,400 --> 00:23:38,710
so-called humongous objects so what g1

00:23:36,760 --> 00:23:40,930
does is at startup if you have not

00:23:38,710 --> 00:23:43,810
explicitly specified otherwise it

00:23:40,930 --> 00:23:46,390
divides the heap up into it makes its

00:23:43,810 --> 00:23:50,850
own determination to divide the heap up

00:23:46,390 --> 00:23:53,350
into some number of regions of some size

00:23:50,850 --> 00:23:55,510
if the objects is your allocating to

00:23:53,350 --> 00:23:57,430
these regions are one half the size of

00:23:55,510 --> 00:23:58,900
the region or larger than it sort of

00:23:57,430 --> 00:24:01,960
special cases that it treats them

00:23:58,900 --> 00:24:04,060
exceptionally it will only allocate one

00:24:01,960 --> 00:24:05,520
object / humongous region and these

00:24:04,060 --> 00:24:08,610
humongous regions have to be

00:24:05,520 --> 00:24:10,290
contiguous so if you have too many of

00:24:08,610 --> 00:24:11,970
them then they will you know they'll be

00:24:10,290 --> 00:24:13,740
the usage of the heat will be very

00:24:11,970 --> 00:24:16,980
inefficient you'll waste a lot of heap

00:24:13,740 --> 00:24:19,140
and you will fragment the heat they're

00:24:16,980 --> 00:24:21,810
meant to be treated exceptional so the

00:24:19,140 --> 00:24:24,720
number of them should be exceptional in

00:24:21,810 --> 00:24:26,910
our case we saw with 1212 get keeps we

00:24:24,720 --> 00:24:28,890
saw region sizes being calculated for

00:24:26,910 --> 00:24:30,930
mags which meant anything to Meg's or

00:24:28,890 --> 00:24:33,000
larger was being allocated humongous

00:24:30,930 --> 00:24:34,800
they were a bit too many of them and it

00:24:33,000 --> 00:24:37,230
kind of destroyed the efficiency of the

00:24:34,800 --> 00:24:39,210
the collector so we have since set that

00:24:37,230 --> 00:24:42,210
up to eight that's something to keep in

00:24:39,210 --> 00:24:43,290
mind enable GC logging have a look at

00:24:42,210 --> 00:24:44,790
that it's pretty obvious when you're

00:24:43,290 --> 00:24:50,910
getting too many too many human mungus

00:24:44,790 --> 00:24:52,230
allocations okay so on node density if

00:24:50,910 --> 00:24:54,750
you talk to anybody in the Cassandra

00:24:52,230 --> 00:24:55,980
community pretty much everybody who has

00:24:54,750 --> 00:24:58,140
any experience with Cassandra will

00:24:55,980 --> 00:25:01,320
always recommend that if given a choice

00:24:58,140 --> 00:25:05,160
you should run more nodes of a smaller

00:25:01,320 --> 00:25:08,100
size than you know larger larger nodes

00:25:05,160 --> 00:25:10,890
and fewer larger nodes it's not really

00:25:08,100 --> 00:25:12,840
documented anywhere you know it's not in

00:25:10,890 --> 00:25:14,790
any of the formal documentation that's

00:25:12,840 --> 00:25:16,470
probably because rightfully so anybody

00:25:14,790 --> 00:25:20,250
who says this ought to be ashamed it

00:25:16,470 --> 00:25:23,730
kind of it kind of ignores the realities

00:25:20,250 --> 00:25:26,880
of growing hardware you know hardware is

00:25:23,730 --> 00:25:28,320
becoming more and more capable and you

00:25:26,880 --> 00:25:31,020
know data center costs that you can't

00:25:28,320 --> 00:25:35,640
vertically scale across available

00:25:31,020 --> 00:25:38,310
hardware issues that we've had running

00:25:35,640 --> 00:25:39,750
nodes that were to dance are quite

00:25:38,310 --> 00:25:42,690
numerous but I'll just limit into the

00:25:39,750 --> 00:25:44,850
ones that I've discussed so far again if

00:25:42,690 --> 00:25:48,030
the efficacy compact compaction is not

00:25:44,850 --> 00:25:49,680
good then lowering no density lowers the

00:25:48,030 --> 00:25:51,990
data set size under control of a single

00:25:49,680 --> 00:25:53,700
node and that means that you know the

00:25:51,990 --> 00:25:57,390
number of SS tables contacted will be

00:25:53,700 --> 00:25:59,490
smaller also the throughput this is

00:25:57,390 --> 00:26:03,240
created by compaction and it will be

00:25:59,490 --> 00:26:04,800
less and if compacted the throughput for

00:26:03,240 --> 00:26:05,850
compaction is high along with all the

00:26:04,800 --> 00:26:08,040
rest of the throughput that's higher

00:26:05,850 --> 00:26:10,500
will in turn make GC works if you're no

00:26:08,040 --> 00:26:12,420
density is too high so we've had

00:26:10,500 --> 00:26:15,030
problems with no density being too high

00:26:12,420 --> 00:26:16,280
and had that creep issues for us and

00:26:15,030 --> 00:26:18,700
we've had to deal with it and that's why

00:26:16,280 --> 00:26:21,550
on that earlier slide I mentioned

00:26:18,700 --> 00:26:23,430
we have three times as many Cassandra

00:26:21,550 --> 00:26:27,100
nodes as we do host to run them on and

00:26:23,430 --> 00:26:30,130
how we deal with that is we spin up

00:26:27,100 --> 00:26:32,410
processes so we use puppet in our

00:26:30,130 --> 00:26:34,600
environment so we just use puppet to to

00:26:32,410 --> 00:26:36,550
create you know multiple configuration

00:26:34,600 --> 00:26:38,980
directories that reference multiple data

00:26:36,550 --> 00:26:41,380
file directories and we have multiple

00:26:38,980 --> 00:26:43,900
systemd units that just spin up multiple

00:26:41,380 --> 00:26:47,800
processes with no effort to limit

00:26:43,900 --> 00:26:49,600
contention or anything and to make

00:26:47,800 --> 00:26:53,200
matters worse we have them all running

00:26:49,600 --> 00:26:54,940
on one single shared raid 0 array so we

00:26:53,200 --> 00:26:57,670
have quite the impressive blast radius

00:26:54,940 --> 00:26:59,320
going on here we lose one disk we lose

00:26:57,670 --> 00:27:01,630
the array we lose you know five

00:26:59,320 --> 00:27:06,370
terabytes of storage and 33 Cassandra

00:27:01,630 --> 00:27:09,310
notes go down probably not the best what

00:27:06,370 --> 00:27:12,160
I wish we had done was used a mechanism

00:27:09,310 --> 00:27:14,440
you know design for no allocating

00:27:12,160 --> 00:27:17,290
hardware resources to the processes like

00:27:14,440 --> 00:27:19,180
virtualization containers just

00:27:17,290 --> 00:27:22,870
purchasing blades would have been better

00:27:19,180 --> 00:27:27,040
i think you know to get to keep that one

00:27:22,870 --> 00:27:31,090
to one host parody if necessary anything

00:27:27,040 --> 00:27:34,660
but about what we did probably and so to

00:27:31,090 --> 00:27:36,960
kind of wrap things up what has worked

00:27:34,660 --> 00:27:39,940
well for us with Cassandra in general is

00:27:36,960 --> 00:27:42,130
sort of the core features the things

00:27:39,940 --> 00:27:44,530
that differentiate Cassandra from from

00:27:42,130 --> 00:27:47,380
the other databases are still you know

00:27:44,530 --> 00:27:49,540
still make it the right choice the way

00:27:47,380 --> 00:27:52,380
to nabol consistency works to let us

00:27:49,540 --> 00:27:54,550
trade away you know point in time a bit

00:27:52,380 --> 00:27:59,290
consistency in order to buy availability

00:27:54,550 --> 00:28:00,550
the multi data center awareness you know

00:27:59,290 --> 00:28:02,530
the visibility it's very well

00:28:00,550 --> 00:28:05,350
instrumented it makes it you know rather

00:28:02,530 --> 00:28:09,280
rather easy if you if you need to dig in

00:28:05,350 --> 00:28:10,510
and troubleshoot something it's getting

00:28:09,280 --> 00:28:12,040
to the point where kassandra's reached

00:28:10,510 --> 00:28:14,140
that kind of critical mass and there's a

00:28:12,040 --> 00:28:16,060
ubiquity there it makes it you know much

00:28:14,140 --> 00:28:18,280
easier to find you know libraries and

00:28:16,060 --> 00:28:20,650
supported applications and you know to

00:28:18,280 --> 00:28:23,380
find help if you you know you search the

00:28:20,650 --> 00:28:25,810
web or you know to find people who are

00:28:23,380 --> 00:28:27,700
willing to share their experiences all

00:28:25,810 --> 00:28:30,100
in all it has been you know if I sounded

00:28:27,700 --> 00:28:31,510
critical at any point it has worked out

00:28:30,100 --> 00:28:32,830
really well and

00:28:31,510 --> 00:28:37,090
so that is just attributed as sort of

00:28:32,830 --> 00:28:41,380
the core the core functionality what

00:28:37,090 --> 00:28:42,820
isn't so good is usability and I

00:28:41,380 --> 00:28:45,880
probably would have balked at this a

00:28:42,820 --> 00:28:47,560
year ago I'm sure you know many of my

00:28:45,880 --> 00:28:49,750
colleagues within the project would balk

00:28:47,560 --> 00:28:51,580
at it and probably rightfully point out

00:28:49,750 --> 00:28:53,320
that usability is so much better than it

00:28:51,580 --> 00:28:54,930
used to be that actually makes it worse

00:28:53,320 --> 00:28:57,070
because usability is still pretty bad

00:28:54,930 --> 00:29:02,860
that just means it was worse it would

00:28:57,070 --> 00:29:04,420
have one point compaction is maybe this

00:29:02,860 --> 00:29:06,460
is perhaps getting over critical but

00:29:04,420 --> 00:29:07,960
compaction is a pretty good example the

00:29:06,460 --> 00:29:12,040
fact that you have to worry about this

00:29:07,960 --> 00:29:14,110
at all i think is you know you know that

00:29:12,040 --> 00:29:16,300
it's more than simply implementation

00:29:14,110 --> 00:29:18,280
detail it's kind of bad from the

00:29:16,300 --> 00:29:20,410
usability standpoint that you have to

00:29:18,280 --> 00:29:21,790
not only understand your data model in

00:29:20,410 --> 00:29:23,350
your access patterns which i think is

00:29:21,790 --> 00:29:25,090
reasonable but you also have to

00:29:23,350 --> 00:29:29,770
thoroughly understand those compaction

00:29:25,090 --> 00:29:32,170
strategy algorithms and then and and you

00:29:29,770 --> 00:29:34,570
know really get low level into the you

00:29:32,170 --> 00:29:35,950
know to the to the analysis of how

00:29:34,570 --> 00:29:37,870
they're working in the trouble you know

00:29:35,950 --> 00:29:39,520
the troubleshooting and tuning feels

00:29:37,870 --> 00:29:40,930
very much like in any other application

00:29:39,520 --> 00:29:42,730
like that ought to be an implementation

00:29:40,930 --> 00:29:45,520
detail not to say that it would be

00:29:42,730 --> 00:29:48,250
that's an easy problem to solve but it

00:29:45,520 --> 00:29:53,020
does make kassandra's not that not that

00:29:48,250 --> 00:29:54,610
usable controlling a streaming for you

00:29:53,020 --> 00:29:56,680
know like bootstraps and d commissions

00:29:54,610 --> 00:30:00,040
and the sort of things really like crazy

00:29:56,680 --> 00:30:02,020
wonky I mean your concurrency you're

00:30:00,040 --> 00:30:03,520
available throughput is a function of

00:30:02,020 --> 00:30:06,490
how many nodes are available to stream

00:30:03,520 --> 00:30:08,380
like there's no per node concurrency so

00:30:06,490 --> 00:30:11,470
you can either overwhelm the node if you

00:30:08,380 --> 00:30:13,000
don't throttle it down or you can end up

00:30:11,470 --> 00:30:14,410
you know with terabytes of data to

00:30:13,000 --> 00:30:16,540
transfer it just a few megabytes per

00:30:14,410 --> 00:30:19,450
second and the only option would be to

00:30:16,540 --> 00:30:22,210
increase the number of nodes that's

00:30:19,450 --> 00:30:23,950
that's bizarre to me but it took you

00:30:22,210 --> 00:30:25,810
know like again getting on the other

00:30:23,950 --> 00:30:31,390
side of the fence before I realized that

00:30:25,810 --> 00:30:33,070
was even an issue jmx is a miserable way

00:30:31,390 --> 00:30:35,680
of having to interact with the system

00:30:33,070 --> 00:30:37,750
for monitoring and management and you

00:30:35,680 --> 00:30:39,160
know full disclosure I probably had more

00:30:37,750 --> 00:30:40,690
to do with this decision and it really

00:30:39,160 --> 00:30:42,220
it is Cassandra than anybody else you

00:30:40,690 --> 00:30:42,610
can probably lay this at my feet more

00:30:42,220 --> 00:30:45,160
than

00:30:42,610 --> 00:30:46,780
more than anyone elses but it just means

00:30:45,160 --> 00:30:50,440
that everything has to know it's kind of

00:30:46,780 --> 00:30:52,840
a baroque you know way of dealing with

00:30:50,440 --> 00:30:55,510
you know way of coding against Cassandra

00:30:52,840 --> 00:30:57,520
anyway but it's very very much limited

00:30:55,510 --> 00:30:59,530
to Java so you know this is the kind of

00:30:57,520 --> 00:31:01,720
thing where I think you know if it were

00:30:59,530 --> 00:31:03,429
open to dynamic languages you probably

00:31:01,720 --> 00:31:06,370
probably see a lot better tooling for

00:31:03,429 --> 00:31:08,470
Cassandra at this point and then as I

00:31:06,370 --> 00:31:11,950
mentioned the the vertical scaling story

00:31:08,470 --> 00:31:14,110
is just awful we run 16-core machines

00:31:11,950 --> 00:31:16,299
with 128 gigs of memory and five

00:31:14,110 --> 00:31:18,280
terabytes of disk space and we simply

00:31:16,299 --> 00:31:20,410
cannot fully utilize that hardware in a

00:31:18,280 --> 00:31:23,200
good way in a performant way what we're

00:31:20,410 --> 00:31:24,669
forced to to run more than one cassandra

00:31:23,200 --> 00:31:30,070
process on the machine just to be able

00:31:24,669 --> 00:31:31,809
to to fully utilize that hardware and

00:31:30,070 --> 00:31:35,470
then to get away from the bad and into

00:31:31,809 --> 00:31:37,570
the ugly upgrading between major

00:31:35,470 --> 00:31:40,870
versions has been really really painful

00:31:37,570 --> 00:31:43,150
it has always been painful I was kind of

00:31:40,870 --> 00:31:45,460
surprised to see that it's just still is

00:31:43,150 --> 00:31:47,350
painful some of this is kind of just

00:31:45,460 --> 00:31:49,240
normal quality control issues things

00:31:47,350 --> 00:31:52,510
that somehow managed to get by without

00:31:49,240 --> 00:31:55,120
getting fixed others are just like

00:31:52,510 --> 00:31:58,030
there's just no excuse for you know like

00:31:55,120 --> 00:32:00,610
what seems like wholly arbitrary changes

00:31:58,030 --> 00:32:01,840
to metric names for example so you have

00:32:00,610 --> 00:32:03,460
to go in and retool all your graphs

00:32:01,840 --> 00:32:06,850
because I don't know because somebody

00:32:03,460 --> 00:32:08,740
wanted to change the case of a you know

00:32:06,850 --> 00:32:11,919
the capitalization of a metric name or

00:32:08,740 --> 00:32:14,140
something really painful the upgrade

00:32:11,919 --> 00:32:15,760
process I know a lot of people have

00:32:14,140 --> 00:32:17,230
related to me that they don't even

00:32:15,760 --> 00:32:19,540
consider Cassandra upgradeable I

00:32:17,230 --> 00:32:22,690
wouldn't go that far but I do know more

00:32:19,540 --> 00:32:24,160
than one person who's actually said that

00:32:22,690 --> 00:32:26,020
it is their policy it has been their

00:32:24,160 --> 00:32:27,340
policy since the beginning and are

00:32:26,020 --> 00:32:30,179
standing by it that they would just

00:32:27,340 --> 00:32:32,710
stand up a new cluster in migrant to it

00:32:30,179 --> 00:32:36,730
and then the release process or that you

00:32:32,710 --> 00:32:39,309
know or the quality of releases is bad

00:32:36,730 --> 00:32:43,600
it's always been bad it's kind of been

00:32:39,309 --> 00:32:46,570
you know the folklore that sort of the

00:32:43,600 --> 00:32:48,640
the passed down knowledge for people

00:32:46,570 --> 00:32:50,470
who've been around only to upgrade

00:32:48,640 --> 00:32:53,500
unlike the sixth release you know just

00:32:50,470 --> 00:32:54,730
sit out the first five because there's

00:32:53,500 --> 00:32:55,870
going to be lots of problems let other

00:32:54,730 --> 00:32:57,760
people shake that out

00:32:55,870 --> 00:32:59,140
like so bad to the point that there's

00:32:57,760 --> 00:33:00,670
nobody shaking out those bugs because

00:32:59,140 --> 00:33:04,360
everybody is waiting for the dot the dot

00:33:00,670 --> 00:33:07,600
six and the problem here has always been

00:33:04,360 --> 00:33:08,950
you know one of trying to balance the

00:33:07,600 --> 00:33:13,960
amount of features in the churn in the

00:33:08,950 --> 00:33:15,400
code you know with with those bug fixes

00:33:13,960 --> 00:33:18,190
and maintaining a stable stable

00:33:15,400 --> 00:33:20,290
trajectory so we adopted this new

00:33:18,190 --> 00:33:22,660
release process modeled after Intel's

00:33:20,290 --> 00:33:24,160
tick tock that makes even-numbered

00:33:22,660 --> 00:33:26,559
releases mean one thing an odd-numbered

00:33:24,160 --> 00:33:27,940
releases mean another and feature more

00:33:26,559 --> 00:33:31,750
feature type stuff goes into one and

00:33:27,940 --> 00:33:33,070
more bug fixes going to the other and if

00:33:31,750 --> 00:33:35,559
this has done anything to solve the

00:33:33,070 --> 00:33:36,880
problem I don't think you know I don't

00:33:35,559 --> 00:33:37,929
think you could prove that one way or

00:33:36,880 --> 00:33:39,880
the other all it's done is obfuscated

00:33:37,929 --> 00:33:43,360
where that sweet spot is you know where

00:33:39,880 --> 00:33:46,240
it is that where the stability that

00:33:43,360 --> 00:33:47,380
you're looking for lies and anybody that

00:33:46,240 --> 00:33:48,820
disputes that you just look on the

00:33:47,380 --> 00:33:50,470
Cassandra mailing list at all the people

00:33:48,820 --> 00:33:52,300
who ask you know what version should I

00:33:50,470 --> 00:33:55,630
be running is you know it's maddening

00:33:52,300 --> 00:33:58,030
with trying to trying to figure that out

00:33:55,630 --> 00:34:00,480
so that is definitely not that is

00:33:58,030 --> 00:34:03,429
definitely not worked out in my opinion

00:34:00,480 --> 00:34:05,160
and so with that I think I have a few

00:34:03,429 --> 00:34:11,010
minutes left for questions if anybody's

00:34:05,160 --> 00:34:11,010
got them thank you

00:34:15,509 --> 00:34:26,019
any questions okay um I was wondering

00:34:23,169 --> 00:34:28,990
how painful scaling out like adding

00:34:26,019 --> 00:34:30,970
nodes to a cluster is for that's easy

00:34:28,990 --> 00:34:33,579
yeah feeling out horizontally is easy

00:34:30,970 --> 00:34:35,500
but the impact of transfers or anything

00:34:33,579 --> 00:34:37,569
like that when between notes when you

00:34:35,500 --> 00:34:39,869
add in one does i have as i repeat that

00:34:37,569 --> 00:34:41,980
last part does the impact of transfers

00:34:39,869 --> 00:34:44,950
from one node to another when you add

00:34:41,980 --> 00:34:46,990
nodes have any impact or well they don't

00:34:44,950 --> 00:34:51,250
need to i mentioned from usability

00:34:46,990 --> 00:34:54,039
standpoint streaming if you're using a

00:34:51,250 --> 00:34:56,079
rack where data center set up like we

00:34:54,039 --> 00:34:57,789
are what Cassandra does when it builds a

00:34:56,079 --> 00:35:00,670
stream plan for a bootstrap to add a new

00:34:57,789 --> 00:35:03,220
node is it looks for you know the

00:35:00,670 --> 00:35:05,740
minimal number of nodes that have the

00:35:03,220 --> 00:35:07,150
replicas it needs that are nearest to it

00:35:05,740 --> 00:35:09,990
so if you're running in a you know

00:35:07,150 --> 00:35:11,920
rocawear data center where's

00:35:09,990 --> 00:35:14,559
configuration that's the nodes they're

00:35:11,920 --> 00:35:16,059
in the same same rack so if for example

00:35:14,559 --> 00:35:17,740
you have two nodes or you're

00:35:16,059 --> 00:35:20,230
bootstrapping in the second node your

00:35:17,740 --> 00:35:21,940
stream concurrency is one and if you're

00:35:20,230 --> 00:35:25,119
using compressed compression then that

00:35:21,940 --> 00:35:27,250
one thread can become bottleneck on cpu

00:35:25,119 --> 00:35:29,200
utilization we see about four megabytes

00:35:27,250 --> 00:35:30,789
per second if you have several terabytes

00:35:29,200 --> 00:35:32,589
of data to transfer at four megabytes

00:35:30,789 --> 00:35:34,869
per second going to take a very long

00:35:32,589 --> 00:35:36,940
time to do the only way to get that

00:35:34,869 --> 00:35:38,890
through put up is to have more nodes in

00:35:36,940 --> 00:35:41,500
that rack that can be involved in the

00:35:38,890 --> 00:35:43,180
stream but if you have too many than a

00:35:41,500 --> 00:35:44,289
u.s. it could be overwhelming you know

00:35:43,180 --> 00:35:46,029
it could you could you know the stream

00:35:44,289 --> 00:35:48,490
concurrency then goes up but that's okay

00:35:46,029 --> 00:35:50,710
because you can throttle that down by

00:35:48,490 --> 00:35:52,269
adjusting the outbound throughput of all

00:35:50,710 --> 00:35:54,849
of the nodes that are streaming to the

00:35:52,269 --> 00:35:57,460
node so if you're bootstrapping new

00:35:54,849 --> 00:36:00,789
nodes into into iraq you have to change

00:35:57,460 --> 00:36:02,500
all of the outbound throttles all the

00:36:00,789 --> 00:36:04,180
outbound throughputs as you add each new

00:36:02,500 --> 00:36:07,630
node and the total available through

00:36:04,180 --> 00:36:11,730
prayer changes so yeah the usability

00:36:07,630 --> 00:36:11,730
story this is a mess there

00:36:12,279 --> 00:36:25,579
okay any other questions hi it looks

00:36:23,660 --> 00:36:29,089
like you've had your share of problems

00:36:25,579 --> 00:36:32,089
with Cassandra if you were to do it all

00:36:29,089 --> 00:36:37,579
over again would use shoes Cassandra or

00:36:32,089 --> 00:36:40,609
would you choose anything else yeah I

00:36:37,579 --> 00:36:41,960
don't really know you know again some of

00:36:40,609 --> 00:36:42,980
the features that were important i mean

00:36:41,960 --> 00:36:44,599
we're trying to hit certain performance

00:36:42,980 --> 00:36:48,079
targets and we're trying to do it at a

00:36:44,599 --> 00:36:50,630
certain costs and we're you know we're

00:36:48,079 --> 00:36:52,279
trying to you know to we're trying to

00:36:50,630 --> 00:36:54,079
end up with it you know like an active

00:36:52,279 --> 00:36:55,490
active set up across multiple data

00:36:54,079 --> 00:36:57,680
centers and we're trying to maintain you

00:36:55,490 --> 00:36:59,299
know certain availability and i don't

00:36:57,680 --> 00:37:01,039
know of any alternative that would have

00:36:59,299 --> 00:37:04,279
solved all of those you know in any

00:37:01,039 --> 00:37:07,869
better better way so i don't know that

00:37:04,279 --> 00:37:09,980
it changes the you know that it changes

00:37:07,869 --> 00:37:11,749
you know what i would do if i could go

00:37:09,980 --> 00:37:13,880
back again oh I also came into this

00:37:11,749 --> 00:37:15,470
after it was already deployed so it

00:37:13,880 --> 00:37:18,559
wasn't something it wasn't a decision

00:37:15,470 --> 00:37:20,269
that I influenced either way but I don't

00:37:18,559 --> 00:37:21,950
really know of an alternative that would

00:37:20,269 --> 00:37:23,239
have been better of course if somebody

00:37:21,950 --> 00:37:27,489
knows of an alternative it'd be better

00:37:23,239 --> 00:37:27,489
okay thank you

00:37:31,210 --> 00:37:38,210
to what extent do you think are the

00:37:35,349 --> 00:37:40,960
vertical scaling problems problems that

00:37:38,210 --> 00:37:45,460
you experience are attributable to Java

00:37:40,960 --> 00:37:48,290
rather to Java than to Cassandra itself

00:37:45,460 --> 00:37:50,180
because the garbage collection and the

00:37:48,290 --> 00:37:52,220
for example the point of compressions

00:37:50,180 --> 00:37:55,340
and problems that every Java process

00:37:52,220 --> 00:37:57,140
probably has yeah definitely I think

00:37:55,340 --> 00:38:00,830
there's there's kind of an impedance

00:37:57,140 --> 00:38:03,770
mismatch between an application like

00:38:00,830 --> 00:38:05,840
Cassandra and I you know any garbage

00:38:03,770 --> 00:38:07,550
collected languages you know people

00:38:05,840 --> 00:38:09,590
pretty quick to jump on Java you know

00:38:07,550 --> 00:38:13,070
and GC issues but i think it probably

00:38:09,590 --> 00:38:14,660
has one of the most robust you know set

00:38:13,070 --> 00:38:16,760
of garbage collectors of any language

00:38:14,660 --> 00:38:18,050
but it's just kind of a you know

00:38:16,760 --> 00:38:21,650
mismatch between that kind of

00:38:18,050 --> 00:38:23,480
application and anna garbage collector

00:38:21,650 --> 00:38:25,460
and garden you know generational garbage

00:38:23,480 --> 00:38:26,840
collectors nor operate on the premise

00:38:25,460 --> 00:38:29,090
that everything is either very very

00:38:26,840 --> 00:38:30,800
short-lived or very long-lived perhaps

00:38:29,090 --> 00:38:32,570
some of the lifespan of the application

00:38:30,800 --> 00:38:34,160
I kassandra's got a lot of middle ground

00:38:32,570 --> 00:38:36,349
there it's got a lot of sort of medium

00:38:34,160 --> 00:38:38,119
lived objects that kind of get you have

00:38:36,349 --> 00:38:40,310
the potential to be prematurely tenured

00:38:38,119 --> 00:38:41,930
out of out of young Gen and you know

00:38:40,310 --> 00:38:44,060
which really screws up the efficiency

00:38:41,930 --> 00:38:45,619
and then on top of all that it's

00:38:44,060 --> 00:38:48,109
extremely latency sensitive because it's

00:38:45,619 --> 00:38:49,790
a database so you know even if the piles

00:38:48,109 --> 00:38:51,560
times aren't really that bad under you

00:38:49,790 --> 00:38:53,720
know like for most typical applications

00:38:51,560 --> 00:38:55,339
that you know just just inconsistent

00:38:53,720 --> 00:38:56,720
pause times as a problem for database

00:38:55,339 --> 00:38:59,270
even if the pauses themselves aren't

00:38:56,720 --> 00:39:01,790
like that aren't that bad so yeah some

00:38:59,270 --> 00:39:03,320
of that is definitely JVM and cassandra

00:39:01,790 --> 00:39:04,580
has done a lot of there's been a lot of

00:39:03,320 --> 00:39:07,070
interesting you know like off heap

00:39:04,580 --> 00:39:08,869
optimizations in Cassandra a lot of a

00:39:07,070 --> 00:39:16,820
lot of good work to make that less of a

00:39:08,869 --> 00:39:19,000
problem we are at the top of the hour so

00:39:16,820 --> 00:39:23,150
is it short question that you've got

00:39:19,000 --> 00:39:27,740
okay that's well maybe trivial well I'll

00:39:23,150 --> 00:39:29,810
do search within mckee Wikimedia so I

00:39:27,740 --> 00:39:33,099
was that implemented I'm sorry I did

00:39:29,810 --> 00:39:36,230
search whole searching in Wikimedia

00:39:33,099 --> 00:39:38,270
commedia implemented can search me

00:39:36,230 --> 00:39:40,920
implemented in Cassandra and not not

00:39:38,270 --> 00:39:43,890
really I mean

00:39:40,920 --> 00:39:45,210
I believe the question was what

00:39:43,890 --> 00:39:49,320
technology is used for the search

00:39:45,210 --> 00:39:50,520
functionality in Wikipedia oh yeah

00:39:49,320 --> 00:39:54,300
probably not the best person to ask

00:39:50,520 --> 00:39:57,050
another resistors a I believe you know

00:39:54,300 --> 00:40:00,750
in mediawiki it's it's serious search

00:39:57,050 --> 00:40:03,740
but you know under the Wikimedia

00:40:00,750 --> 00:40:07,020
infrastructure we also use lastic search

00:40:03,740 --> 00:40:11,190
okay we need to give time for next

00:40:07,020 --> 00:40:13,860
speaker to set his session up thank you

00:40:11,190 --> 00:40:16,100
Eric once again and if anyone wants to

00:40:13,860 --> 00:40:16,100

YouTube URL: https://www.youtube.com/watch?v=xIpiGLdIQzU


