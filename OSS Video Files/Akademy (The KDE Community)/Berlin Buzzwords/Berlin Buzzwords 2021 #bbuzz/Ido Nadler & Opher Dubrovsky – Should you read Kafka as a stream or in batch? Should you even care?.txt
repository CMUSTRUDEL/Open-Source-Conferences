Title: Ido Nadler & Opher Dubrovsky – Should you read Kafka as a stream or in batch? Should you even care?
Publication date: 2021-06-29
Playlist: Berlin Buzzwords 2021 #bbuzz
Description: 
	Should you consume Kafka in a stream OR batch? When should you choose each one? What is more efficient, and cost effective? Should you even care?

In this talk we’ll give you the tools and metrics to decide which solution you should apply when, and show you a real life example with cost & time comparisons.
To highlight the differences, we’ll dive into a project we’ve done, transitioning from reading Kafka in a stream to reading it in batch. 

By turning conventional thinking on its head and reading our multi-petabyte Kafka stream in batch using Spark and Airflow, we’ve achieved a huge cost reduction of 65% while at the same time getting a more scalable and resilient solution.

Using the learnings and statistics we’ve gained, we’ll explore the tradeoffs and give you the metrics and intuition you’ll need to make such decisions yourself. 

We’ll cover:
- Costs of processing in stream compared to batch
- Scaling up for bursts and reprocessing 
- Making the tradeoff between wait times and costs
- Recovering from outages 
- And much more…

Speaker:
Ido Nadler – https://2021.berlinbuzzwords.de/member/ido-nadler
Opher Dubrovsky – https://2021.berlinbuzzwords.de/member/opher-dubrovsky

More: https://2021.berlinbuzzwords.de/session/should-you-read-kafka-stream-or-batch-should-you-even-care
Captions: 
	00:00:08,480 --> 00:00:13,200
hi everybody this talk is about

00:00:10,559 --> 00:00:14,160
if you should read kafka as a stream or

00:00:13,200 --> 00:00:16,720
in bet

00:00:14,160 --> 00:00:19,039
we're gonna pit batch against stream and

00:00:16,720 --> 00:00:21,039
see what comes out

00:00:19,039 --> 00:00:22,080
we'll start with stream stream is

00:00:21,039 --> 00:00:25,039
basically

00:00:22,080 --> 00:00:25,680
doing micro deliveries doing many small

00:00:25,039 --> 00:00:29,279
trips

00:00:25,680 --> 00:00:31,760
and as a result you get low wait times

00:00:29,279 --> 00:00:33,040
data comes in and very quickly gets

00:00:31,760 --> 00:00:35,280
delivered

00:00:33,040 --> 00:00:36,320
batch on the other hand is exactly the

00:00:35,280 --> 00:00:39,280
opposite we make

00:00:36,320 --> 00:00:40,480
large deliveries we make few trips as a

00:00:39,280 --> 00:00:43,360
result of that

00:00:40,480 --> 00:00:44,079
but you also have longer waits until

00:00:43,360 --> 00:00:48,320
your data

00:00:44,079 --> 00:00:48,879
arrives so this is a story about a

00:00:48,320 --> 00:00:51,920
stream

00:00:48,879 --> 00:00:53,520
that has gone bad we'll tell you a story

00:00:51,920 --> 00:00:55,840
of a projects we've done

00:00:53,520 --> 00:00:56,960
that used to be a stream and we turned

00:00:55,840 --> 00:00:59,920
it into batch

00:00:56,960 --> 00:01:02,320
and we'll see what the differences were

00:00:59,920 --> 00:01:04,960
and why it made a lot of sense

00:01:02,320 --> 00:01:06,479
we'll go over stream versus batch some

00:01:04,960 --> 00:01:09,360
of the trade-offs

00:01:06,479 --> 00:01:10,320
how we re-architecturated our stream to

00:01:09,360 --> 00:01:12,400
a badge

00:01:10,320 --> 00:01:13,680
and we'll conclude with some

00:01:12,400 --> 00:01:16,479
considerations

00:01:13,680 --> 00:01:18,320
that will make sense for you to consider

00:01:16,479 --> 00:01:20,640
while looking at your projects

00:01:18,320 --> 00:01:22,000
as well before we start i want to

00:01:20,640 --> 00:01:24,080
explain who we are

00:01:22,000 --> 00:01:26,880
my name is offer dubrovsky i'm a big

00:01:24,080 --> 00:01:29,360
data dev lead at nielsen

00:01:26,880 --> 00:01:30,880
and with me is the don adler a big data

00:01:29,360 --> 00:01:33,520
engineer at nielsen

00:01:30,880 --> 00:01:34,799
we deal with data pipelines serverless

00:01:33,520 --> 00:01:38,720
infrastructure

00:01:34,799 --> 00:01:41,840
spark clusters and data analytics

00:01:38,720 --> 00:01:43,600
we are part of nielsen marketing cloud

00:01:41,840 --> 00:01:46,159
and we build marketing segments and

00:01:43,600 --> 00:01:48,560
device device graphs that can be used

00:01:46,159 --> 00:01:49,200
for running marketing campaigns and for

00:01:48,560 --> 00:01:53,040
making

00:01:49,200 --> 00:01:54,720
business decisions uh in a nutshell

00:01:53,040 --> 00:01:57,600
about nielsen marketing cloud

00:01:54,720 --> 00:01:58,479
we are cloud native we process a lot of

00:01:57,600 --> 00:02:01,119
data every day

00:01:58,479 --> 00:02:01,920
roughly 60 terabytes of new data every

00:02:01,119 --> 00:02:04,640
day

00:02:01,920 --> 00:02:05,520
and we store a total of about five

00:02:04,640 --> 00:02:08,239
petabytes

00:02:05,520 --> 00:02:09,119
in our data lake we're heavy users of

00:02:08,239 --> 00:02:13,280
spark

00:02:09,119 --> 00:02:15,840
roughly 6 000 nodes every day

00:02:13,280 --> 00:02:18,080
across all our spark clusters and we're

00:02:15,840 --> 00:02:20,840
heavy users of lambda functions

00:02:18,080 --> 00:02:23,200
that we also use in some of our

00:02:20,840 --> 00:02:27,040
pipelines all right let's talk about

00:02:23,200 --> 00:02:30,400
stream versus batch trade-offs

00:02:27,040 --> 00:02:32,560
we're going to pit batch against stream

00:02:30,400 --> 00:02:36,080
and we're going to do it right now

00:02:32,560 --> 00:02:38,560
and to do that i want to use an analogy

00:02:36,080 --> 00:02:40,080
of something with all something we're

00:02:38,560 --> 00:02:43,840
all familiar with

00:02:40,080 --> 00:02:48,800
which is pizza delivery so on the left

00:02:43,840 --> 00:02:48,800
we have batch our new champion

00:02:49,040 --> 00:02:53,440
which is using a pizza delivery truck to

00:02:52,000 --> 00:02:57,280
deliver pizzas

00:02:53,440 --> 00:03:00,560
in batch and on the right we have stream

00:02:57,280 --> 00:03:01,519
our lightweight previous champion which

00:03:00,560 --> 00:03:04,640
delivers

00:03:01,519 --> 00:03:06,879
pizzas using delivery scooters that can

00:03:04,640 --> 00:03:10,159
carry three to four pizzas

00:03:06,879 --> 00:03:13,760
in each delivery the challenge is

00:03:10,159 --> 00:03:15,200
to deliver pizzas to a party going on at

00:03:13,760 --> 00:03:17,200
a house

00:03:15,200 --> 00:03:18,720
and we'll compare the differences

00:03:17,200 --> 00:03:21,680
between doing it

00:03:18,720 --> 00:03:23,360
in each of those ways so let's look at

00:03:21,680 --> 00:03:25,840
speed

00:03:23,360 --> 00:03:26,480
if we have 20 pizzas to deliver to a

00:03:25,840 --> 00:03:28,799
house

00:03:26,480 --> 00:03:30,239
and we are using the pizza delivery

00:03:28,799 --> 00:03:33,200
truck

00:03:30,239 --> 00:03:34,400
that probably will take longer the truck

00:03:33,200 --> 00:03:36,720
needs to wait until

00:03:34,400 --> 00:03:39,040
all the pizzas are ready and then

00:03:36,720 --> 00:03:40,959
driving through the city will also take

00:03:39,040 --> 00:03:42,480
longer for the truck so the total

00:03:40,959 --> 00:03:46,080
delivery time will be

00:03:42,480 --> 00:03:48,879
45 minutes if however we use the pizza

00:03:46,080 --> 00:03:50,560
delivery scooters each one can pick up

00:03:48,879 --> 00:03:53,680
the pizzas as they arrive

00:03:50,560 --> 00:03:55,840
and head off immediately to the house

00:03:53,680 --> 00:03:58,319
so delivery time will be faster they

00:03:55,840 --> 00:04:00,959
also drive faster through the city

00:03:58,319 --> 00:04:02,480
so we expect 15 minute delivery time and

00:04:00,959 --> 00:04:05,599
the pizzas are going to arrive

00:04:02,480 --> 00:04:08,959
as they flow out of the oven so

00:04:05,599 --> 00:04:12,400
in terms of speed the stream option is

00:04:08,959 --> 00:04:16,000
faster however if we look at cost

00:04:12,400 --> 00:04:19,440
the pizza delivery truck uh

00:04:16,000 --> 00:04:21,199
cost 40 dollars for each run but

00:04:19,440 --> 00:04:22,479
if we have 20 pizzas the truck can

00:04:21,199 --> 00:04:25,199
deliver all of them

00:04:22,479 --> 00:04:26,320
at once so the cost per unit is gonna be

00:04:25,199 --> 00:04:29,759
just two dollars

00:04:26,320 --> 00:04:31,360
forty dollars for the delivery divided

00:04:29,759 --> 00:04:34,880
by 20 pizzas

00:04:31,360 --> 00:04:37,840
but the scooters will need six runs

00:04:34,880 --> 00:04:40,080
so the 20 pizzas and the cost per run is

00:04:37,840 --> 00:04:42,080
going to be much cheaper just 10

00:04:40,080 --> 00:04:43,440
but still that works out to be three

00:04:42,080 --> 00:04:46,880
dollars per unit

00:04:43,440 --> 00:04:49,840
much more expensive 50 more

00:04:46,880 --> 00:04:51,520
so the stream even though it's faster we

00:04:49,840 --> 00:04:54,320
actually have to pay for that

00:04:51,520 --> 00:04:55,040
it costs more and if we look at high

00:04:54,320 --> 00:04:56,800
loads

00:04:55,040 --> 00:04:59,199
if you compare this to data this is when

00:04:56,800 --> 00:05:02,240
you have to reprocess a lot of data that

00:04:59,199 --> 00:05:04,880
was held up somewhere uh

00:05:02,240 --> 00:05:05,600
there's also a big uh difference here

00:05:04,880 --> 00:05:08,400
the truck

00:05:05,600 --> 00:05:10,320
high load in our example is we we had to

00:05:08,400 --> 00:05:12,240
deliver a hundred pizzas

00:05:10,320 --> 00:05:13,840
so the truck could still deliver all of

00:05:12,240 --> 00:05:17,440
them in one run it's still

00:05:13,840 --> 00:05:19,759
45 minutes but the stream

00:05:17,440 --> 00:05:22,320
to deliver the 100 pizzas will need to

00:05:19,759 --> 00:05:24,720
make five runs with each scooter

00:05:22,320 --> 00:05:25,360
five rounds times 15 minutes that's

00:05:24,720 --> 00:05:28,320
going to take

00:05:25,360 --> 00:05:29,600
75 minutes so not only is it more

00:05:28,320 --> 00:05:32,800
expensive

00:05:29,600 --> 00:05:35,600
it's also going to take longer

00:05:32,800 --> 00:05:38,000
to deliver so you can see that in some

00:05:35,600 --> 00:05:41,360
scenarios the stream is worse off

00:05:38,000 --> 00:05:44,320
in all dimensions both speed

00:05:41,360 --> 00:05:46,080
and cost so should we go with stream or

00:05:44,320 --> 00:05:48,960
batch

00:05:46,080 --> 00:05:51,199
in some cases the answer is obvious if

00:05:48,960 --> 00:05:53,120
you need real-time data then you go with

00:05:51,199 --> 00:05:54,560
a stream you just need real data no

00:05:53,120 --> 00:05:58,000
other choice

00:05:54,560 --> 00:06:00,000
but if you need a lot of aggregations so

00:05:58,000 --> 00:06:02,880
basically that means you have to wait

00:06:00,000 --> 00:06:04,400
until all your data arrives before you

00:06:02,880 --> 00:06:06,240
can do any aggregation

00:06:04,400 --> 00:06:07,840
you would go with batch because you have

00:06:06,240 --> 00:06:09,600
to wait anyways

00:06:07,840 --> 00:06:11,680
but what about all these cases in the

00:06:09,600 --> 00:06:13,360
middle where you could do either one of

00:06:11,680 --> 00:06:16,880
them

00:06:13,360 --> 00:06:20,160
and and it's up to you to decide

00:06:16,880 --> 00:06:23,120
so to take a look at that option

00:06:20,160 --> 00:06:25,039
let's see an example system and to do

00:06:23,120 --> 00:06:28,160
that i'm going to pass it on to ido

00:06:25,039 --> 00:06:29,600
which will tell you all about it thank

00:06:28,160 --> 00:06:32,400
you offer

00:06:29,600 --> 00:06:33,680
let's meet our system it's one of our

00:06:32,400 --> 00:06:36,479
core systems

00:06:33,680 --> 00:06:37,360
that process huge amount of data every

00:06:36,479 --> 00:06:40,160
day

00:06:37,360 --> 00:06:42,160
this data is being used widely in our

00:06:40,160 --> 00:06:45,360
company

00:06:42,160 --> 00:06:48,639
it's a simple etl pipeline

00:06:45,360 --> 00:06:51,919
that uses spark and consume

00:06:48,639 --> 00:06:54,160
that consumes data from kafka this kafka

00:06:51,919 --> 00:06:55,919
cluster is being fed by other kafka

00:06:54,160 --> 00:06:58,560
clusters spread

00:06:55,919 --> 00:06:59,440
around the world in our data centers and

00:06:58,560 --> 00:07:03,120
the results

00:06:59,440 --> 00:07:06,479
are being written to our data lake in

00:07:03,120 --> 00:07:09,039
sitting on aws in s3

00:07:06,479 --> 00:07:09,520
now since we have constant stream of

00:07:09,039 --> 00:07:11,680
data

00:07:09,520 --> 00:07:12,720
coming along the day we use spark

00:07:11,680 --> 00:07:15,440
streaming

00:07:12,720 --> 00:07:16,319
and because let's face it streaming is

00:07:15,440 --> 00:07:19,680
very cool

00:07:16,319 --> 00:07:23,440
right overall we process

00:07:19,680 --> 00:07:26,960
around 60 terabyte of data every day

00:07:23,440 --> 00:07:29,759
which is a lot now if we dive into

00:07:26,960 --> 00:07:31,440
one of our pipelines then that use a

00:07:29,759 --> 00:07:34,639
specific topic we call

00:07:31,440 --> 00:07:35,360
delivery in this specific topic we

00:07:34,639 --> 00:07:39,120
process

00:07:35,360 --> 00:07:41,199
around 20 terabytes of data every day

00:07:39,120 --> 00:07:42,560
so in order to be able to consume such

00:07:41,199 --> 00:07:46,520
amount of data

00:07:42,560 --> 00:07:48,960
we defined this kafka topic to run with

00:07:46,520 --> 00:07:52,000
1250 partitions

00:07:48,960 --> 00:07:52,639
now the way spark cluster spark work is

00:07:52,000 --> 00:07:56,000
that

00:07:52,639 --> 00:07:58,000
each kafka consumer is running on top of

00:07:56,000 --> 00:08:02,440
spark executor that uses

00:07:58,000 --> 00:08:05,120
its own core so overall we are running

00:08:02,440 --> 00:08:08,000
1250 cores

00:08:05,120 --> 00:08:09,759
all running together there and the

00:08:08,000 --> 00:08:13,520
results are again

00:08:09,759 --> 00:08:16,720
same amount of files being written to s3

00:08:13,520 --> 00:08:20,160
in a nutshell every few minutes

00:08:16,720 --> 00:08:23,120
we consume a micro batch from kafka

00:08:20,160 --> 00:08:23,759
we run some transformation on on this

00:08:23,120 --> 00:08:26,879
data

00:08:23,759 --> 00:08:30,240
and the results are being written to

00:08:26,879 --> 00:08:31,440
s3 as per k files well sounds simple

00:08:30,240 --> 00:08:34,880
right

00:08:31,440 --> 00:08:40,560
it works perfectly for us

00:08:34,880 --> 00:08:44,000
but in time reality hits us and we

00:08:40,560 --> 00:08:47,839
found some issues with this system

00:08:44,000 --> 00:08:49,120
i'm gonna explain so if we take a look

00:08:47,839 --> 00:08:52,240
at our stream of data

00:08:49,120 --> 00:08:56,080
it varies during the day so

00:08:52,240 --> 00:08:59,120
we found out that during the low hours

00:08:56,080 --> 00:09:02,000
our cluster is underutilized which means

00:08:59,120 --> 00:09:04,160
we are paying for resources we do not

00:09:02,000 --> 00:09:07,519
need

00:09:04,160 --> 00:09:08,080
on the other hand on peak hours when the

00:09:07,519 --> 00:09:11,519
traffic

00:09:08,080 --> 00:09:15,600
exceeded the cluster capacity

00:09:11,519 --> 00:09:19,680
we were starting to drag behind

00:09:15,600 --> 00:09:21,600
now let's talk about your birthday

00:09:19,680 --> 00:09:23,279
you don't want to miss your birthday due

00:09:21,600 --> 00:09:27,600
to production issues

00:09:23,279 --> 00:09:28,480
right well in our case it wasn't your

00:09:27,600 --> 00:09:32,959
birthday

00:09:28,480 --> 00:09:36,160
but it did was a christmas eve

00:09:32,959 --> 00:09:39,519
so two years ago on christmas eve

00:09:36,160 --> 00:09:42,800
we found out that our system was down

00:09:39,519 --> 00:09:46,080
and we were starting to lose data

00:09:42,800 --> 00:09:49,120
now the reason for that is because we

00:09:46,080 --> 00:09:50,640
kafka as a retention policy which was in

00:09:49,120 --> 00:09:53,839
our case two days

00:09:50,640 --> 00:09:54,720
and because of an outage the system was

00:09:53,839 --> 00:09:58,320
down

00:09:54,720 --> 00:10:01,680
and when we started to

00:09:58,320 --> 00:10:05,120
consume the data again we were consuming

00:10:01,680 --> 00:10:07,519
a offsets with which of data that was

00:10:05,120 --> 00:10:10,560
already deleted by kafka

00:10:07,519 --> 00:10:12,959
so we we quickly uh went

00:10:10,560 --> 00:10:14,480
and increased the that the retention

00:10:12,959 --> 00:10:18,480
policy

00:10:14,480 --> 00:10:20,959
but we figured out that

00:10:18,480 --> 00:10:23,760
we have a recovery issue and we are

00:10:20,959 --> 00:10:27,279
losing data

00:10:23,760 --> 00:10:30,240
so we we then understood

00:10:27,279 --> 00:10:31,040
that when you need to reco architect

00:10:30,240 --> 00:10:33,200
your system

00:10:31,040 --> 00:10:35,360
you really really think you need to

00:10:33,200 --> 00:10:39,120
think about recovery because

00:10:35,360 --> 00:10:41,440
recovery is a ticking time bomb and

00:10:39,120 --> 00:10:43,839
we will show you later how we fix that

00:10:41,440 --> 00:10:43,839
issue

00:10:45,040 --> 00:10:51,360
regarding cost well

00:10:48,399 --> 00:10:52,560
system systems and and machines cost

00:10:51,360 --> 00:10:55,760
money right

00:10:52,560 --> 00:10:59,519
so in our case it cost a lot

00:10:55,760 --> 00:11:00,240
it the the amount of dollars we needed

00:10:59,519 --> 00:11:03,279
to pay

00:11:00,240 --> 00:11:06,800
for every year was four hundred thousand

00:11:03,279 --> 00:11:10,480
dollars that's a lot

00:11:06,800 --> 00:11:12,880
so we thought it has to be a better way

00:11:10,480 --> 00:11:15,600
and we have to rethink and architect

00:11:12,880 --> 00:11:18,160
re-architect our system

00:11:15,600 --> 00:11:20,000
our the project goals was to build a

00:11:18,160 --> 00:11:22,399
system that can be

00:11:20,000 --> 00:11:23,440
a quickly auto scale according to the

00:11:22,399 --> 00:11:26,880
traffic

00:11:23,440 --> 00:11:27,680
coming along the day this will also fix

00:11:26,880 --> 00:11:31,600
the delivery

00:11:27,680 --> 00:11:34,720
the delay issues we have on peak hours

00:11:31,600 --> 00:11:37,920
regarding cost we have to improve our

00:11:34,720 --> 00:11:41,279
efficiency and cluster capacity

00:11:37,920 --> 00:11:44,079
so we can gain some cost cutting

00:11:41,279 --> 00:11:44,720
and regarding recovery as you said as we

00:11:44,079 --> 00:11:47,920
said before

00:11:44,720 --> 00:11:51,200
we cut we we knew that recovery

00:11:47,920 --> 00:11:54,399
a system and able to recover from

00:11:51,200 --> 00:11:54,399
failure is a must

00:11:54,720 --> 00:11:59,680
so we thought that we have to we need to

00:11:57,839 --> 00:12:02,880
spread the work

00:11:59,680 --> 00:12:04,480
across isolated workers that way we can

00:12:02,880 --> 00:12:08,000
tailor each one of those

00:12:04,480 --> 00:12:11,360
those workers to better efficiency

00:12:08,000 --> 00:12:14,399
but how so we took

00:12:11,360 --> 00:12:16,880
all of our smart engineers put them on

00:12:14,399 --> 00:12:18,800
the same room ordered some pizza with

00:12:16,880 --> 00:12:23,600
scooters of course

00:12:18,800 --> 00:12:23,600
and we thought on how to do that

00:12:23,839 --> 00:12:28,480
what we realized that if we look at our

00:12:26,800 --> 00:12:31,760
stream of data

00:12:28,480 --> 00:12:33,760
if we use discrete time slots

00:12:31,760 --> 00:12:35,519
with fixed amount of time let's say

00:12:33,760 --> 00:12:38,240
hours for example

00:12:35,519 --> 00:12:40,560
and we we can look at each one of those

00:12:38,240 --> 00:12:42,240
hours as a separated task that you can

00:12:40,560 --> 00:12:45,760
tailor according to the

00:12:42,240 --> 00:12:48,320
amount of data it needs to process

00:12:45,760 --> 00:12:49,920
so by spinning more and more tasks

00:12:48,320 --> 00:12:54,399
during the day

00:12:49,920 --> 00:12:57,760
we can isolate the work from the workers

00:12:54,399 --> 00:13:00,800
and basically cue a

00:12:57,760 --> 00:13:04,839
run multiple emrs

00:13:00,800 --> 00:13:08,320
a in a iso in a full isolation

00:13:04,839 --> 00:13:11,760
system if we take a look

00:13:08,320 --> 00:13:15,519
on it on the task perspective

00:13:11,760 --> 00:13:18,079
each hour is a task some of them

00:13:15,519 --> 00:13:19,200
are very short shorter than an hour

00:13:18,079 --> 00:13:22,880
which mean

00:13:19,200 --> 00:13:25,760
that we can process an hour of data

00:13:22,880 --> 00:13:27,839
in less time and some of them takes

00:13:25,760 --> 00:13:30,000
longer than an hour

00:13:27,839 --> 00:13:32,560
according to the traffic that comes to

00:13:30,000 --> 00:13:34,959
that arrives to kafka during that hour

00:13:32,560 --> 00:13:36,000
but that's okay right because even

00:13:34,959 --> 00:13:39,839
though

00:13:36,000 --> 00:13:40,560
a a task takes longer than an hour the

00:13:39,839 --> 00:13:43,760
next

00:13:40,560 --> 00:13:45,760
task that is processing the next hour

00:13:43,760 --> 00:13:49,279
will sca will start when it was

00:13:45,760 --> 00:13:52,480
scheduled so we won't get the any delay

00:13:49,279 --> 00:13:55,839
better than that when a task ends

00:13:52,480 --> 00:13:58,880
and we don't need to the cluster anymore

00:13:55,839 --> 00:14:01,279
uh we terminate the cluster and we

00:13:58,880 --> 00:14:02,560
free the resources and we start paying

00:14:01,279 --> 00:14:06,959
for the for the

00:14:02,560 --> 00:14:08,959
cost time is money right

00:14:06,959 --> 00:14:10,560
if you think about it this is very

00:14:08,959 --> 00:14:14,000
similar to how serverless

00:14:10,560 --> 00:14:16,079
systems work right because you pay

00:14:14,000 --> 00:14:18,480
for the resources you need when you do

00:14:16,079 --> 00:14:20,800
the job but when the job is done

00:14:18,480 --> 00:14:23,519
you free the resources and you stop

00:14:20,800 --> 00:14:23,519
paying for it

00:14:24,320 --> 00:14:28,240
regarding a efficiency we are pretty

00:14:27,680 --> 00:14:32,000
much

00:14:28,240 --> 00:14:35,760
driving our cluster to a 100 percent

00:14:32,000 --> 00:14:38,800
but since we're using spark over eml

00:14:35,760 --> 00:14:42,000
uh there is some warm-up time uh

00:14:38,800 --> 00:14:44,720
that that takes from our efficiency

00:14:42,000 --> 00:14:46,320
so the total efficiency is around 75

00:14:44,720 --> 00:14:49,360
percent

00:14:46,320 --> 00:14:50,399
now of course if we reduce the warm-up

00:14:49,360 --> 00:14:53,680
time

00:14:50,399 --> 00:14:54,240
we can get closer and closer to 100

00:14:53,680 --> 00:14:57,040
percent

00:14:54,240 --> 00:14:57,680
efficiency there are some ways to do

00:14:57,040 --> 00:15:00,720
that

00:14:57,680 --> 00:15:03,519
and we are already experiencing and

00:15:00,720 --> 00:15:06,160
playing with a running spark over

00:15:03,519 --> 00:15:08,880
kubernetes

00:15:06,160 --> 00:15:09,680
if we compare it to the previous system

00:15:08,880 --> 00:15:12,880
where

00:15:09,680 --> 00:15:16,639
in the low hours we were paying for

00:15:12,880 --> 00:15:18,639
a resources we do not need the efficient

00:15:16,639 --> 00:15:20,639
efficiency of the previous system was

00:15:18,639 --> 00:15:23,199
around 30 percent

00:15:20,639 --> 00:15:24,800
now if you recall we just said that the

00:15:23,199 --> 00:15:27,839
new system

00:15:24,800 --> 00:15:31,440
is around 75 percent so

00:15:27,839 --> 00:15:34,480
overall we are now 60

00:15:31,440 --> 00:15:35,040
cheaper than the previous system which

00:15:34,480 --> 00:15:37,519
is

00:15:35,040 --> 00:15:37,519
awesome

00:15:38,160 --> 00:15:45,040
now let's see let's see the mechanics

00:15:41,680 --> 00:15:47,839
we use airflow to schedule and control

00:15:45,040 --> 00:15:48,800
our pipelines so when we need we need to

00:15:47,839 --> 00:15:52,959
run a task

00:15:48,800 --> 00:15:54,240
let's start a airflow we spin up an emr

00:15:52,959 --> 00:15:57,680
cluster

00:15:54,240 --> 00:15:58,480
between a period of time then this emab

00:15:57,680 --> 00:16:01,680
cluster

00:15:58,480 --> 00:16:04,480
will use kafka to convert the time

00:16:01,680 --> 00:16:08,079
period into offsets and consume the data

00:16:04,480 --> 00:16:10,240
within kafka between those offsets when

00:16:08,079 --> 00:16:12,880
there is nothing more to consume

00:16:10,240 --> 00:16:14,000
the and the job is done the cluster will

00:16:12,880 --> 00:16:15,519
terminate itself

00:16:14,000 --> 00:16:18,000
and we're going to start paying for the

00:16:15,519 --> 00:16:21,120
cost great

00:16:18,000 --> 00:16:23,680
now when we need to run

00:16:21,120 --> 00:16:24,560
multiple tasks with multiple time

00:16:23,680 --> 00:16:27,440
periods

00:16:24,560 --> 00:16:28,320
maybe together we can just spin up more

00:16:27,440 --> 00:16:31,680
and more

00:16:28,320 --> 00:16:35,040
isolated pipelines and that will just

00:16:31,680 --> 00:16:38,079
work so

00:16:35,040 --> 00:16:41,040
as a result we now run multiple

00:16:38,079 --> 00:16:42,320
pipelines running running with multiple

00:16:41,040 --> 00:16:45,759
topics

00:16:42,320 --> 00:16:49,680
on multiple time periods

00:16:45,759 --> 00:16:51,920
and it just work as a charm

00:16:49,680 --> 00:16:53,279
so to see the results i'm going to pass

00:16:51,920 --> 00:16:56,880
it back to offer

00:16:53,279 --> 00:17:00,000
over okay thank you idol

00:16:56,880 --> 00:17:02,880
so we saw the architecture

00:17:00,000 --> 00:17:03,199
and understand why it should be better

00:17:02,880 --> 00:17:04,959
but

00:17:03,199 --> 00:17:06,400
is it really better let's see some

00:17:04,959 --> 00:17:09,919
results

00:17:06,400 --> 00:17:12,640
so the first thing i want to show you

00:17:09,919 --> 00:17:13,600
is how the system looked before and

00:17:12,640 --> 00:17:17,520
after

00:17:13,600 --> 00:17:19,439
on the left you could see that

00:17:17,520 --> 00:17:21,439
this is what it looked like when it was

00:17:19,439 --> 00:17:24,240
doing all these micro batches

00:17:21,439 --> 00:17:24,880
while it was streaming and on the right

00:17:24,240 --> 00:17:27,439
you could see

00:17:24,880 --> 00:17:28,720
beyond the transition point we started

00:17:27,439 --> 00:17:32,080
doing processing

00:17:28,720 --> 00:17:34,960
once an hour so once an hour we process

00:17:32,080 --> 00:17:36,799
data and we reduce the amount of data

00:17:34,960 --> 00:17:39,120
waiting for us in kafka what you're

00:17:36,799 --> 00:17:41,600
looking here are basically the offsets

00:17:39,120 --> 00:17:42,799
the amount of lag we have in kafka you

00:17:41,600 --> 00:17:44,880
can also notice

00:17:42,799 --> 00:17:46,000
that once in a while we have a bigger

00:17:44,880 --> 00:17:49,600
gap this

00:17:46,000 --> 00:17:52,559
means we missed a run and as a result

00:17:49,600 --> 00:17:53,200
the total data to process the queue goes

00:17:52,559 --> 00:17:55,760
up

00:17:53,200 --> 00:17:57,520
but this is okay because as you recall

00:17:55,760 --> 00:17:58,240
our runs are independent we can just

00:17:57,520 --> 00:18:01,200
rerun it

00:17:58,240 --> 00:18:03,520
again later on and this is exactly what

00:18:01,200 --> 00:18:06,559
happens the system just reruns

00:18:03,520 --> 00:18:09,760
uh the the that batch job

00:18:06,559 --> 00:18:11,840
and gets back to normal in terms of

00:18:09,760 --> 00:18:13,840
cost on the left you can see how the

00:18:11,840 --> 00:18:14,720
system looked before doing this

00:18:13,840 --> 00:18:16,799
transition

00:18:14,720 --> 00:18:18,000
the daily costs were pretty much the

00:18:16,799 --> 00:18:20,400
same every day

00:18:18,000 --> 00:18:22,880
uh slightly different if we had to uh

00:18:20,400 --> 00:18:23,600
rerun or restart a cluster and run it

00:18:22,880 --> 00:18:26,000
again

00:18:23,600 --> 00:18:29,120
uh so you can see the the costs were

00:18:26,000 --> 00:18:30,640
roughly 850 dollars a day for these two

00:18:29,120 --> 00:18:32,960
topics we were running

00:18:30,640 --> 00:18:33,919
on the right you could see after the

00:18:32,960 --> 00:18:36,240
change the

00:18:33,919 --> 00:18:37,840
the amount of money we pay every day

00:18:36,240 --> 00:18:38,559
changes every day depending on the

00:18:37,840 --> 00:18:41,200
amount of

00:18:38,559 --> 00:18:42,559
data that comes in so this really

00:18:41,200 --> 00:18:44,240
follows the amount of data

00:18:42,559 --> 00:18:46,080
you can also see that there's a huge

00:18:44,240 --> 00:18:48,799
drop in cost in total it's around

00:18:46,080 --> 00:18:50,400
60 percent drop in cost so if you look

00:18:48,799 --> 00:18:53,600
at the yearly cost

00:18:50,400 --> 00:18:56,559
before we were paying around 400 000

00:18:53,600 --> 00:18:57,120
a year and now we're down to 160 000 a

00:18:56,559 --> 00:19:00,640
year

00:18:57,120 --> 00:19:03,919
that's 240 000 in saving

00:19:00,640 --> 00:19:05,280
every year just from the move uh to this

00:19:03,919 --> 00:19:08,880
system which is

00:19:05,280 --> 00:19:10,480
obviously awesome if you look at the

00:19:08,880 --> 00:19:12,799
data

00:19:10,480 --> 00:19:15,679
these are the bytes we are processing

00:19:12,799 --> 00:19:18,640
per hour and you could see this changes

00:19:15,679 --> 00:19:20,640
from hour to hour and day to day and our

00:19:18,640 --> 00:19:22,880
costs are very

00:19:20,640 --> 00:19:24,480
correlated with that you could look at

00:19:22,880 --> 00:19:27,760
the cost graph below

00:19:24,480 --> 00:19:28,240
in green and you can see that it follows

00:19:27,760 --> 00:19:30,640
very

00:19:28,240 --> 00:19:31,679
nicely the amount of data we process

00:19:30,640 --> 00:19:35,039
which is great

00:19:31,679 --> 00:19:36,240
it means we have a pretty uh serverless

00:19:35,039 --> 00:19:38,960
type of flow

00:19:36,240 --> 00:19:40,400
and that we are paying linearly with the

00:19:38,960 --> 00:19:43,200
amount of data which is

00:19:40,400 --> 00:19:45,120
a great place to be in let's look at how

00:19:43,200 --> 00:19:47,440
we handle outages which is something you

00:19:45,120 --> 00:19:49,360
don't mention which was an issue for us

00:19:47,440 --> 00:19:50,559
and we really wanted to have better

00:19:49,360 --> 00:19:53,360
outage handling

00:19:50,559 --> 00:19:55,039
so this graph shows you the amount of

00:19:53,360 --> 00:19:57,440
data waiting to be processed

00:19:55,039 --> 00:19:59,280
in the old system and you can see that

00:19:57,440 --> 00:20:01,520
it suddenly shoots up

00:19:59,280 --> 00:20:02,400
we have it we had an outage something

00:20:01,520 --> 00:20:04,400
was wrong

00:20:02,400 --> 00:20:06,400
data started to accumulate we had a

00:20:04,400 --> 00:20:09,440
cluster down or something like that

00:20:06,400 --> 00:20:10,000
and uh the amount of data waiting in the

00:20:09,440 --> 00:20:13,200
queue

00:20:10,000 --> 00:20:15,520
went up in kafka and we

00:20:13,200 --> 00:20:17,600
started the recovery and ended the

00:20:15,520 --> 00:20:21,200
recovery here

00:20:17,600 --> 00:20:24,799
the total time for recovering this took

00:20:21,200 --> 00:20:25,440
six hours because as the cl as we were

00:20:24,799 --> 00:20:28,240
trying to

00:20:25,440 --> 00:20:30,799
recover data we had new data coming in

00:20:28,240 --> 00:20:33,360
so there was a lot of load on the system

00:20:30,799 --> 00:20:34,240
let's look at how the new system is

00:20:33,360 --> 00:20:37,440
handling

00:20:34,240 --> 00:20:38,159
similar outages so here is the new

00:20:37,440 --> 00:20:41,760
system

00:20:38,159 --> 00:20:43,919
you can see it looks a bit different

00:20:41,760 --> 00:20:45,919
here's an outage that started again we

00:20:43,919 --> 00:20:46,720
had some downtime with something in the

00:20:45,919 --> 00:20:49,520
system

00:20:46,720 --> 00:20:50,400
and here's where the recovery completed

00:20:49,520 --> 00:20:53,280
notice

00:20:50,400 --> 00:20:54,480
that from the time we started to recover

00:20:53,280 --> 00:20:57,280
data

00:20:54,480 --> 00:20:58,640
it took about 40 minutes to recover all

00:20:57,280 --> 00:21:01,360
the data

00:20:58,640 --> 00:21:02,559
and the the reason is here you can even

00:21:01,360 --> 00:21:05,360
see this on the graph

00:21:02,559 --> 00:21:07,679
we had five concurrent isolated spark

00:21:05,360 --> 00:21:10,559
clusters working in parallel

00:21:07,679 --> 00:21:12,640
uh chugging along at the data and as a

00:21:10,559 --> 00:21:14,960
result we completed processing

00:21:12,640 --> 00:21:16,000
all of that outage and recovered the

00:21:14,960 --> 00:21:18,720
data within

00:21:16,000 --> 00:21:19,760
40 minutes comparing compared to six

00:21:18,720 --> 00:21:23,600
hours before

00:21:19,760 --> 00:21:26,080
that's about an 85 percent improvement

00:21:23,600 --> 00:21:27,120
in the in our recovery times which is

00:21:26,080 --> 00:21:30,320
awesome

00:21:27,120 --> 00:21:31,039
and because we have a retention a time

00:21:30,320 --> 00:21:33,919
limit

00:21:31,039 --> 00:21:34,799
of the data this is a huge improvement

00:21:33,919 --> 00:21:37,440
for us

00:21:34,799 --> 00:21:39,280
in this new system let's look at the

00:21:37,440 --> 00:21:40,960
cluster utilization which was really

00:21:39,280 --> 00:21:43,280
critical for us

00:21:40,960 --> 00:21:44,960
he don't mention that in the past while

00:21:43,280 --> 00:21:46,400
we were doing streaming and the cluster

00:21:44,960 --> 00:21:48,159
was pretty rigid

00:21:46,400 --> 00:21:50,159
uh we had a lot of times where the

00:21:48,159 --> 00:21:52,799
cluster was underutilized

00:21:50,159 --> 00:21:55,280
here this is a a ganglia which basically

00:21:52,799 --> 00:21:58,480
gives you metrics about

00:21:55,280 --> 00:22:01,200
the spark clusters you can see

00:21:58,480 --> 00:22:03,120
that the cluster here is very once it

00:22:01,200 --> 00:22:04,640
starts processing the data which is that

00:22:03,120 --> 00:22:07,679
plateau on top

00:22:04,640 --> 00:22:09,840
uh it's very stable and it keeps uh

00:22:07,679 --> 00:22:12,080
working at a high utilization in this

00:22:09,840 --> 00:22:14,960
case it's a over 85 percent

00:22:12,080 --> 00:22:16,080
but in some of the other cases it's it's

00:22:14,960 --> 00:22:19,360
higher than that and

00:22:16,080 --> 00:22:21,760
over 90 which is really nice utilization

00:22:19,360 --> 00:22:23,600
and if you look at this part this shows

00:22:21,760 --> 00:22:24,640
you the load on each of the servers and

00:22:23,600 --> 00:22:27,360
the clusters

00:22:24,640 --> 00:22:29,440
in the cluster it's uh it's all red

00:22:27,360 --> 00:22:31,919
which means they are highly utilized

00:22:29,440 --> 00:22:33,600
again this is great the clusters are

00:22:31,919 --> 00:22:36,240
much better utilized

00:22:33,600 --> 00:22:37,919
and very consistently over time exactly

00:22:36,240 --> 00:22:39,360
what we wanted

00:22:37,919 --> 00:22:41,039
all right let's talk about some of the

00:22:39,360 --> 00:22:42,960
key insights

00:22:41,039 --> 00:22:45,679
from this project and what you can take

00:22:42,960 --> 00:22:49,440
with you about the comparison between

00:22:45,679 --> 00:22:53,520
streaming and batch so the first thing

00:22:49,440 --> 00:22:56,480
streaming is expensive and in many cases

00:22:53,520 --> 00:22:56,880
it might not be worth doing unless you

00:22:56,480 --> 00:23:00,159
really

00:22:56,880 --> 00:23:02,000
need it for real-time data consider if

00:23:00,159 --> 00:23:04,480
you really want to go with streaming

00:23:02,000 --> 00:23:06,000
the other thing is fixed clusters are

00:23:04,480 --> 00:23:08,799
never perfect

00:23:06,000 --> 00:23:09,679
during off hours they're very expensive

00:23:08,799 --> 00:23:13,120
because we have

00:23:09,679 --> 00:23:15,200
too much capacity that is not really uh

00:23:13,120 --> 00:23:17,200
used and is the cluster is basically

00:23:15,200 --> 00:23:20,320
idling away your money

00:23:17,200 --> 00:23:23,520
and when we have a lot of high loads uh

00:23:20,320 --> 00:23:25,120
they are too slow to a to process all

00:23:23,520 --> 00:23:27,360
the data quickly

00:23:25,120 --> 00:23:29,919
another critical insight is that

00:23:27,360 --> 00:23:32,480
recovery is critical to manage

00:23:29,919 --> 00:23:34,480
you really want to man you plan this

00:23:32,480 --> 00:23:36,240
when you do your architecture

00:23:34,480 --> 00:23:37,840
this is not something you want to leave

00:23:36,240 --> 00:23:40,080
as an afterthought

00:23:37,840 --> 00:23:41,279
to deal with later if you want to have a

00:23:40,080 --> 00:23:43,360
good life and

00:23:41,279 --> 00:23:44,960
not too many distractions during your

00:23:43,360 --> 00:23:47,360
holidays and vacations

00:23:44,960 --> 00:23:49,120
you definitely want to deal with this in

00:23:47,360 --> 00:23:50,000
your architecture and make sure that

00:23:49,120 --> 00:23:53,679
recovery is

00:23:50,000 --> 00:23:56,480
easy and quick and the last thing is if

00:23:53,679 --> 00:23:58,960
you introduce isolation and parallelism

00:23:56,480 --> 00:23:59,679
in your processes and your data

00:23:58,960 --> 00:24:02,240
pipelines

00:23:59,679 --> 00:24:04,400
it really allows you to easily scale

00:24:02,240 --> 00:24:07,600
save on costs and deal with loads

00:24:04,400 --> 00:24:08,559
in our case the way we approach this is

00:24:07,600 --> 00:24:10,640
basically

00:24:08,559 --> 00:24:11,679
splitting the data between fixed time

00:24:10,640 --> 00:24:13,760
frames

00:24:11,679 --> 00:24:15,039
in time slots and that gave us the

00:24:13,760 --> 00:24:16,799
isolations between

00:24:15,039 --> 00:24:19,279
all the tests and they could be run in

00:24:16,799 --> 00:24:21,039
parallel in your projects it might be

00:24:19,279 --> 00:24:23,760
something else that will allow you

00:24:21,039 --> 00:24:24,400
but you definitely want to think about

00:24:23,760 --> 00:24:26,480
it

00:24:24,400 --> 00:24:28,320
all right let's summarize so here are

00:24:26,480 --> 00:24:30,799
the things we talked about

00:24:28,320 --> 00:24:33,279
in this talk first the differences

00:24:30,799 --> 00:24:35,039
between streaming and batch

00:24:33,279 --> 00:24:36,559
some of the trade-offs and things you

00:24:35,039 --> 00:24:39,760
should consider when planning

00:24:36,559 --> 00:24:40,559
such systems we explored one of our

00:24:39,760 --> 00:24:43,279
projects that

00:24:40,559 --> 00:24:43,919
used to be a stream and we moved it to a

00:24:43,279 --> 00:24:46,320
batch

00:24:43,919 --> 00:24:48,240
and showed you some of the advantages we

00:24:46,320 --> 00:24:50,960
gained by doing this

00:24:48,240 --> 00:24:52,960
and we went over some architecture

00:24:50,960 --> 00:24:54,240
insights that you can take to your own

00:24:52,960 --> 00:24:56,960
projects

00:24:54,240 --> 00:24:58,159
conclusions are that streaming has some

00:24:56,960 --> 00:25:00,720
downsides

00:24:58,159 --> 00:25:02,480
always think if you really need it uh

00:25:00,720 --> 00:25:04,320
batch can sometimes be an

00:25:02,480 --> 00:25:06,159
alternative i'm not saying always

00:25:04,320 --> 00:25:08,880
because some times you

00:25:06,159 --> 00:25:10,880
really do need streaming but batch is a

00:25:08,880 --> 00:25:13,520
definitely a viable alternative

00:25:10,880 --> 00:25:15,840
and you should also always consider the

00:25:13,520 --> 00:25:18,799
costs the loads on the system

00:25:15,840 --> 00:25:20,000
how to recover data and your uptime of

00:25:18,799 --> 00:25:21,600
the system

00:25:20,000 --> 00:25:23,440
if you want to learn more here are two

00:25:21,600 --> 00:25:25,279
talks by colleagues of ours

00:25:23,440 --> 00:25:27,039
streaming with spark and kafka just

00:25:25,279 --> 00:25:30,000
follow the tiny url

00:25:27,039 --> 00:25:31,279
and airflow kubernetes and spark another

00:25:30,000 --> 00:25:33,360
interesting talk

00:25:31,279 --> 00:25:35,840
uh by them and if you really want to

00:25:33,360 --> 00:25:38,880
reach us we're available on linkedin

00:25:35,840 --> 00:25:42,080
here are handles uh of me my handle

00:25:38,880 --> 00:25:43,200
and ido idose so feel free to reach out

00:25:42,080 --> 00:25:45,919
to us

00:25:43,200 --> 00:25:47,360
all right so with that we'll summarize

00:25:45,919 --> 00:25:49,120
uh we'll conclude

00:25:47,360 --> 00:25:51,039
thank you very much for coming to our

00:25:49,120 --> 00:25:54,480
talk

00:25:51,039 --> 00:25:56,480
okay so we are now in the qa session uh

00:25:54,480 --> 00:25:58,080
i just checked and i didn't see any

00:25:56,480 --> 00:25:59,840
questions so far

00:25:58,080 --> 00:26:01,679
so i will probably do one question

00:25:59,840 --> 00:26:04,799
myself because i'm curious

00:26:01,679 --> 00:26:05,200
did you try with this approach uh to use

00:26:04,799 --> 00:26:08,000
like

00:26:05,200 --> 00:26:10,640
more things like spot instances or

00:26:08,000 --> 00:26:12,159
things like that just to reduce cost

00:26:10,640 --> 00:26:13,919
good question you know you want to take

00:26:12,159 --> 00:26:15,279
this because you dealt a lot with the

00:26:13,919 --> 00:26:18,480
spots

00:26:15,279 --> 00:26:21,600
yeah uh so we did you

00:26:18,480 --> 00:26:24,640
we use spot instances we actually is

00:26:21,600 --> 00:26:27,919
using sport instances even now

00:26:24,640 --> 00:26:31,039
uh but we we did

00:26:27,919 --> 00:26:34,880
we did see that

00:26:31,039 --> 00:26:36,080
we were losing sports instances all the

00:26:34,880 --> 00:26:39,360
time

00:26:36,080 --> 00:26:42,480
so that was a problem

00:26:39,360 --> 00:26:45,200
now when you instead of running in

00:26:42,480 --> 00:26:47,279
a clustered run cluster that's running

00:26:45,200 --> 00:26:47,760
all the time using spot instances that

00:26:47,279 --> 00:26:50,559
might

00:26:47,760 --> 00:26:51,279
fail and then you need to recover from

00:26:50,559 --> 00:26:56,240
the

00:26:51,279 --> 00:26:56,240
spot instance if you run it in small

00:26:56,480 --> 00:27:00,080
small ones like shorten rounds around

00:26:59,679 --> 00:27:03,120
like

00:27:00,080 --> 00:27:06,320
run every hour but only for

00:27:03,120 --> 00:27:09,520
20 minutes or 30 minutes you are

00:27:06,320 --> 00:27:12,400
unlikely to it's unlikely that the

00:27:09,520 --> 00:27:13,200
the spot will be lost so it's like even

00:27:12,400 --> 00:27:15,679
more uh

00:27:13,200 --> 00:27:17,039
resilient yeah can i expand on this you

00:27:15,679 --> 00:27:19,760
know i i want

00:27:17,039 --> 00:27:21,039
the old process that was in streaming we

00:27:19,760 --> 00:27:22,720
used odds but

00:27:21,039 --> 00:27:25,760
because it was a long running process

00:27:22,720 --> 00:27:27,600
like you just said we kept losing uh

00:27:25,760 --> 00:27:29,039
spots and we had to deal with this it

00:27:27,600 --> 00:27:30,799
was difficult

00:27:29,039 --> 00:27:32,960
with the batch process because it's

00:27:30,799 --> 00:27:34,080
short it can recover if you lose spots

00:27:32,960 --> 00:27:36,399
it's not a big deal

00:27:34,080 --> 00:27:38,799
we still use spots but we don't have all

00:27:36,399 --> 00:27:40,320
these problems we had in the past

00:27:38,799 --> 00:27:41,840
but i also want to mention we're also

00:27:40,320 --> 00:27:44,159
using instant fleets which

00:27:41,840 --> 00:27:45,600
makes it easier and think about it

00:27:44,159 --> 00:27:47,919
instance fleets give you

00:27:45,600 --> 00:27:50,240
spots depending on availability and

00:27:47,919 --> 00:27:52,240
we're starting a cluster every hour

00:27:50,240 --> 00:27:53,840
which means that one cluster may use a

00:27:52,240 --> 00:27:56,000
certain instance type

00:27:53,840 --> 00:27:57,039
another one that starts later on may use

00:27:56,000 --> 00:28:00,559
something else

00:27:57,039 --> 00:28:03,520
so this is really awesome

00:28:00,559 --> 00:28:04,720
okay i have another question is uh why i

00:28:03,520 --> 00:28:06,559
mean

00:28:04,720 --> 00:28:08,559
in this in the batch case i suppose it's

00:28:06,559 --> 00:28:10,399
better to have like uh

00:28:08,559 --> 00:28:12,320
stronger machines like beefier machines

00:28:10,399 --> 00:28:13,520
somehow or what was your experience

00:28:12,320 --> 00:28:15,600
about this

00:28:13,520 --> 00:28:18,000
uh the nice thing about it is that you

00:28:15,600 --> 00:28:20,480
don't have to use beefier machines

00:28:18,000 --> 00:28:21,279
because if you remember because of the

00:28:20,480 --> 00:28:23,679
isolation

00:28:21,279 --> 00:28:24,399
each batch is working independently each

00:28:23,679 --> 00:28:27,760
batch has

00:28:24,399 --> 00:28:29,120
one hour of data and then it could work

00:28:27,760 --> 00:28:31,279
as long as it needs

00:28:29,120 --> 00:28:33,279
so if you have beefier machines maybe it

00:28:31,279 --> 00:28:35,200
will finish processing in 20 minutes if

00:28:33,279 --> 00:28:36,320
you have weaker machines it may take an

00:28:35,200 --> 00:28:38,320
hour and a half

00:28:36,320 --> 00:28:39,360
so the the nice thing about it we

00:28:38,320 --> 00:28:41,919
basically

00:28:39,360 --> 00:28:43,200
disconnected the dependency between the

00:28:41,919 --> 00:28:46,320
amount of data and the

00:28:43,200 --> 00:28:47,039
type of machines you use and now you can

00:28:46,320 --> 00:28:48,799
use really

00:28:47,039 --> 00:28:51,039
you can choose the machines depending on

00:28:48,799 --> 00:28:51,360
the cost whatever is the cheapest for

00:28:51,039 --> 00:28:53,440
you

00:28:51,360 --> 00:28:55,360
in terms of total cost you can use

00:28:53,440 --> 00:28:57,600
because we are now

00:28:55,360 --> 00:28:59,600
independent of the machine type which is

00:28:57,600 --> 00:29:02,080
really really a nice by the way

00:28:59,600 --> 00:29:03,360
we this helped us save a lot a lot of

00:29:02,080 --> 00:29:05,840
the savings came from

00:29:03,360 --> 00:29:07,440
a toying with spots and instances and

00:29:05,840 --> 00:29:09,440
things like that that we had a hard time

00:29:07,440 --> 00:29:11,679
doing before

00:29:09,440 --> 00:29:13,440
okay okay thanks let me just check if

00:29:11,679 --> 00:29:16,080
there is another question

00:29:13,440 --> 00:29:17,440
yes uh there are two uh how many

00:29:16,080 --> 00:29:19,600
partitions were present

00:29:17,440 --> 00:29:21,840
in the kafka topic for the batch

00:29:19,600 --> 00:29:23,919
solution given a time range

00:29:21,840 --> 00:29:25,440
for example one hour how do you

00:29:23,919 --> 00:29:28,880
determine what offsets

00:29:25,440 --> 00:29:30,320
do you read from okay cool

00:29:28,880 --> 00:29:33,279
you know you want to take this i think

00:29:30,320 --> 00:29:37,520
you love this question yes so

00:29:33,279 --> 00:29:40,880
uh we're we're using airflow to

00:29:37,520 --> 00:29:43,120
spin up the cluster every hour so we use

00:29:40,880 --> 00:29:48,000
airflow

00:29:43,120 --> 00:29:50,559
timing that tells us

00:29:48,000 --> 00:29:51,200
like the when to start and when when to

00:29:50,559 --> 00:29:54,559
end

00:29:51,200 --> 00:29:58,159
and then we use kafka to convert

00:29:54,559 --> 00:30:00,960
the the the timestamp to actually

00:29:58,159 --> 00:30:01,840
uh kafka offsets like each one of the

00:30:00,960 --> 00:30:04,159
partitions

00:30:01,840 --> 00:30:05,520
uh as its own manage its own offset

00:30:04,159 --> 00:30:08,640
right so

00:30:05,520 --> 00:30:12,480
when you go to kafka and ask for a

00:30:08,640 --> 00:30:15,600
and the offsets for a specific time

00:30:12,480 --> 00:30:16,720
time frame it will give you a different

00:30:15,600 --> 00:30:20,240
offset starting

00:30:16,720 --> 00:30:24,240
and offsets for each partition

00:30:20,240 --> 00:30:27,039
and this is how we do that so

00:30:24,240 --> 00:30:27,360
yeah so in the past in ido can you mute

00:30:27,039 --> 00:30:30,240
so

00:30:27,360 --> 00:30:31,840
we don't have the echo in the past we

00:30:30,240 --> 00:30:34,159
had the

00:30:31,840 --> 00:30:35,279
we were just reading offsets in kafka

00:30:34,159 --> 00:30:38,080
for each partition

00:30:35,279 --> 00:30:40,159
and using that to read the data now that

00:30:38,080 --> 00:30:43,520
we use the fixed time slots

00:30:40,159 --> 00:30:45,760
we basically go to kafka ask it

00:30:43,520 --> 00:30:48,559
which offset is the specific time we

00:30:45,760 --> 00:30:50,640
want to start and end and use that

00:30:48,559 --> 00:30:52,880
for reading regarding the other question

00:30:50,640 --> 00:30:57,120
you asked how many partitions we have

00:30:52,880 --> 00:30:58,880
so we currently have a 1250 partitions

00:30:57,120 --> 00:31:01,919
in kafka for the big

00:30:58,880 --> 00:31:05,200
topics and as a result we're also using

00:31:01,919 --> 00:31:07,440
clusters with a slightly more cores than

00:31:05,200 --> 00:31:07,440
that

00:31:07,679 --> 00:31:19,840
so each core each executor is basically

00:31:10,159 --> 00:31:19,840
going to one partition and reading it

00:31:33,760 --> 00:31:35,840

YouTube URL: https://www.youtube.com/watch?v=s40DCqQZDr8


