Title: Kevin Watters – Document classification search; joins vs payloads
Publication date: 2021-07-01
Playlist: Berlin Buzzwords 2021 #bbuzz
Description: 
	Payloads are a powerful though seldom utilized feature in the Lucene-Solr ecosystem.  This talk reviews the existing payload support in Lucene and introduces the new features in Lucene and Solr 9  (LUCENE-9659 / SOLR-14787).  The main focus of the talk will be to explore real world search & ml use cases that traditionally utilize a query time join and the application of Lucene payloads to solve them. This talk is for search practitioners interested in utilizing machine learned data in search based analytics dashboards. 

Many Solr based applications attempting to deal with machine learned classifications are forced to implement a parent-child join relationship between a document and its classifications.  This model introduces many additional system constraints and costs at both query and index time to maintain the ability to filter results as desired. 

New features in the payload span query in Lucene provide applications a way to maintain query flexibility without incurring the cost of performing a query-time join.  This greatly simplifies system design and architecture and can provide dramatic improvements to query performance.

A reference implementation will be presented that compares the join and payload approaches.  The demonstration will show how to search for documents that have classifications above a particular confidence threshold at scale.

Speaker: 
Kevin Watters – https://2021.berlinbuzzwords.de/member/kevin-watters

More: https://2021.berlinbuzzwords.de/session/document-classification-search-joins-vs-payloads
Captions: 
	00:00:07,200 --> 00:00:11,440
hello everybody

00:00:08,160 --> 00:00:13,519
i'm glad everybody could join us today

00:00:11,440 --> 00:00:15,519
very excited to talk about some of the

00:00:13,519 --> 00:00:17,199
the features that we've added to leucine

00:00:15,519 --> 00:00:20,160
and solar

00:00:17,199 --> 00:00:20,640
thinly veiled in a talk about image

00:00:20,160 --> 00:00:23,199
search

00:00:20,640 --> 00:00:25,039
and indexing the output of neural

00:00:23,199 --> 00:00:28,160
networks

00:00:25,039 --> 00:00:30,080
um so who am i i'm the founder of kmw

00:00:28,160 --> 00:00:32,880
technology we've been in operation since

00:00:30,080 --> 00:00:34,880
about 2010 we're based in boston

00:00:32,880 --> 00:00:35,920
and we primarily focus on solar

00:00:34,880 --> 00:00:39,040
elasticsearch

00:00:35,920 --> 00:00:40,640
and leucine we provide training search

00:00:39,040 --> 00:00:43,120
cluster architecture review

00:00:40,640 --> 00:00:44,160
application development we perform solar

00:00:43,120 --> 00:00:46,640
audits

00:00:44,160 --> 00:00:47,680
uh and we're very very big proponents of

00:00:46,640 --> 00:00:51,920
open source

00:00:47,680 --> 00:00:51,920
contributors supporters and committers

00:00:52,320 --> 00:00:57,120
so before we get into some of the the

00:00:55,360 --> 00:00:58,480
approaches that we took to solving this

00:00:57,120 --> 00:01:00,800
problem i was going to do a quick little

00:00:58,480 --> 00:01:03,039
overview on what payloads are because

00:01:00,800 --> 00:01:04,879
i feel like they're they're often

00:01:03,039 --> 00:01:07,040
overlooked and people don't necessarily

00:01:04,879 --> 00:01:10,000
know what payloads are

00:01:07,040 --> 00:01:11,360
payloads are a piece of binary data that

00:01:10,000 --> 00:01:14,159
can be stored

00:01:11,360 --> 00:01:14,640
at a position in a field of a document

00:01:14,159 --> 00:01:16,880
and

00:01:14,640 --> 00:01:17,840
they're stored in the pos files of the

00:01:16,880 --> 00:01:20,720
index

00:01:17,840 --> 00:01:21,759
and these these pos the pos file and

00:01:20,720 --> 00:01:24,840
lucine index

00:01:21,759 --> 00:01:27,840
provides us with the byte offsets for

00:01:24,840 --> 00:01:30,479
this term's position within a document

00:01:27,840 --> 00:01:32,880
in the pay the payload file

00:01:30,479 --> 00:01:35,360
um and this this allows us to very

00:01:32,880 --> 00:01:37,280
quickly reference that binary data

00:01:35,360 --> 00:01:39,040
uh at query time and there's a couple of

00:01:37,280 --> 00:01:40,799
lucine queries that support this the

00:01:39,040 --> 00:01:44,399
span term check

00:01:40,799 --> 00:01:46,079
uh span check term query and

00:01:44,399 --> 00:01:47,680
a few others but primarily these are

00:01:46,079 --> 00:01:49,360
exposed through uh

00:01:47,680 --> 00:01:50,799
solar's query syntax to the query

00:01:49,360 --> 00:01:55,040
parsers of the payload check

00:01:50,799 --> 00:01:56,640
and the payload score query parsers

00:01:55,040 --> 00:01:58,159
previously the payload check query

00:01:56,640 --> 00:02:01,040
parser could only provo

00:01:58,159 --> 00:02:03,680
perform a pure equality operation like

00:02:01,040 --> 00:02:06,560
does the payload equal a value

00:02:03,680 --> 00:02:07,200
that's specified but we we saw a very

00:02:06,560 --> 00:02:08,640
simple

00:02:07,200 --> 00:02:11,360
improvement to make to that which is

00:02:08,640 --> 00:02:12,879
just to support inequality operations

00:02:11,360 --> 00:02:14,560
that's greater than less than greater

00:02:12,879 --> 00:02:16,560
than or equal to

00:02:14,560 --> 00:02:17,599
and this really opens it up to a wider

00:02:16,560 --> 00:02:20,879
range of

00:02:17,599 --> 00:02:23,120
of use cases with a relatively minimum

00:02:20,879 --> 00:02:24,560
impact to performance compared to normal

00:02:23,120 --> 00:02:29,120
payload

00:02:24,560 --> 00:02:31,360
checks um so what are payloads and solar

00:02:29,120 --> 00:02:33,280
how do you configure them well what they

00:02:31,360 --> 00:02:35,200
they are the special field type

00:02:33,280 --> 00:02:36,400
and the important thing in that field

00:02:35,200 --> 00:02:38,640
type

00:02:36,400 --> 00:02:39,599
is that it uses the delimited payload

00:02:38,640 --> 00:02:42,959
filter

00:02:39,599 --> 00:02:45,120
in the analysis chain what this allows

00:02:42,959 --> 00:02:46,640
you to do is it allows you to encode a

00:02:45,120 --> 00:02:48,800
payload

00:02:46,640 --> 00:02:50,480
with every value so if you see the data

00:02:48,800 --> 00:02:52,480
input format down below

00:02:50,480 --> 00:02:54,319
where you have something like a value a

00:02:52,480 --> 00:02:55,840
pipe and then the payload that you want

00:02:54,319 --> 00:02:58,640
to associate with it and that becomes

00:02:55,840 --> 00:03:01,599
your field data

00:02:58,640 --> 00:03:02,640
current payload encoder decoder support

00:03:01,599 --> 00:03:05,760
for

00:03:02,640 --> 00:03:08,319
integer floating point and the string

00:03:05,760 --> 00:03:11,040
operation or identity as it's also

00:03:08,319 --> 00:03:11,040
sometimes called

00:03:12,000 --> 00:03:15,840
quick review of the solar query parsers

00:03:14,400 --> 00:03:17,280
that support this

00:03:15,840 --> 00:03:19,760
first one which we won't be talking

00:03:17,280 --> 00:03:21,280
about much today is the payload score

00:03:19,760 --> 00:03:23,120
query parser

00:03:21,280 --> 00:03:24,480
which allows you to use this payload

00:03:23,120 --> 00:03:26,480
information

00:03:24,480 --> 00:03:28,159
as part of your relevancy calculation or

00:03:26,480 --> 00:03:30,159
your scoring calculation

00:03:28,159 --> 00:03:32,319
uh useful to know that it's there not

00:03:30,159 --> 00:03:34,640
the focus of this talk

00:03:32,319 --> 00:03:36,640
more interesting was the the payload

00:03:34,640 --> 00:03:38,640
check query parser that can

00:03:36,640 --> 00:03:39,760
make a determination to match a

00:03:38,640 --> 00:03:42,879
particular term

00:03:39,760 --> 00:03:44,560
in a document if the payload equals a

00:03:42,879 --> 00:03:45,200
particular value and i think that most

00:03:44,560 --> 00:03:47,599
of this

00:03:45,200 --> 00:03:48,560
functionality came out of the part of

00:03:47,599 --> 00:03:50,959
speech

00:03:48,560 --> 00:03:53,040
searching use cases so that would be

00:03:50,959 --> 00:03:56,080
searching for the word train

00:03:53,040 --> 00:03:59,280
only if the train uh word

00:03:56,080 --> 00:04:02,080
had been tagged as being a noun versus a

00:03:59,280 --> 00:04:03,680
verb so kind of more granular control

00:04:02,080 --> 00:04:06,319
not just term matching

00:04:03,680 --> 00:04:07,680
but uh matching the payload uh as as

00:04:06,319 --> 00:04:09,360
mentioned before

00:04:07,680 --> 00:04:11,280
what we've we did is we extended this

00:04:09,360 --> 00:04:12,640
payload check query parser to add an

00:04:11,280 --> 00:04:13,519
additional parameter which is the

00:04:12,640 --> 00:04:16,880
operation

00:04:13,519 --> 00:04:19,359
op which will match against the payloads

00:04:16,880 --> 00:04:20,560
and here we specify gt representing a

00:04:19,359 --> 00:04:22,720
greater than example

00:04:20,560 --> 00:04:25,040
so if we could imagine having the word

00:04:22,720 --> 00:04:26,639
train with a payload of 0.75 we can

00:04:25,040 --> 00:04:29,120
search for

00:04:26,639 --> 00:04:29,919
documents that contain trane where it

00:04:29,120 --> 00:04:31,440
was

00:04:29,919 --> 00:04:33,199
had a payload that was greater than that

00:04:31,440 --> 00:04:34,720
value

00:04:33,199 --> 00:04:37,040
all right so let's talk about our use

00:04:34,720 --> 00:04:37,919
case motivation why did we go down this

00:04:37,040 --> 00:04:41,040
road

00:04:37,919 --> 00:04:42,479
uh in the first place the the example

00:04:41,040 --> 00:04:43,120
use case we're going to present here in

00:04:42,479 --> 00:04:47,360
this talk

00:04:43,120 --> 00:04:50,000
is um really dealing with the output of

00:04:47,360 --> 00:04:50,560
neural network model classifications so

00:04:50,000 --> 00:04:53,600
if you

00:04:50,560 --> 00:04:57,199
look at like most of the bleeding edge

00:04:53,600 --> 00:04:59,040
in image recognition uh it's

00:04:57,199 --> 00:05:01,440
most more than likely you've come across

00:04:59,040 --> 00:05:05,600
you know convolutional neural networks

00:05:01,440 --> 00:05:07,360
um some open source popular ones vgg16

00:05:05,600 --> 00:05:08,560
and yolo we used in this example we'll

00:05:07,360 --> 00:05:10,160
show you a demo of what

00:05:08,560 --> 00:05:11,680
that output looks like a little bit

00:05:10,160 --> 00:05:14,479
later in the talk

00:05:11,680 --> 00:05:15,680
um but generally speaking a neural

00:05:14,479 --> 00:05:18,160
network you have

00:05:15,680 --> 00:05:20,720
something like an image where each pixel

00:05:18,160 --> 00:05:22,639
is a value on the input

00:05:20,720 --> 00:05:24,240
it goes through the network and then you

00:05:22,639 --> 00:05:26,880
have an output layer

00:05:24,240 --> 00:05:29,520
where each one of the outputs usually is

00:05:26,880 --> 00:05:31,840
a particular label or a classification

00:05:29,520 --> 00:05:33,600
and the score on that output is like a

00:05:31,840 --> 00:05:36,639
confidence score

00:05:33,600 --> 00:05:39,199
so what we end up with is for any given

00:05:36,639 --> 00:05:39,759
image that we want to classify we end up

00:05:39,199 --> 00:05:42,320
with a

00:05:39,759 --> 00:05:43,680
list of classifications and each

00:05:42,320 --> 00:05:46,880
classification has

00:05:43,680 --> 00:05:50,639
its confidence score associated with it

00:05:46,880 --> 00:05:52,639
um other other models like yolo in

00:05:50,639 --> 00:05:54,160
addition to giving you a category and a

00:05:52,639 --> 00:05:56,240
confidence threshold it can also give

00:05:54,160 --> 00:06:00,000
you bounding box information

00:05:56,240 --> 00:06:02,400
uh about um you know what it detected in

00:06:00,000 --> 00:06:04,560
the image

00:06:02,400 --> 00:06:05,759
so we'll come back to this uh in the in

00:06:04,560 --> 00:06:07,199
the demo at the end of the talk

00:06:05,759 --> 00:06:08,960
hopefully we have time

00:06:07,199 --> 00:06:10,240
uh but here's just one way to kind of

00:06:08,960 --> 00:06:13,840
represent uh

00:06:10,240 --> 00:06:17,199
payloads in the index uh classified from

00:06:13,840 --> 00:06:21,400
a machine learned uh model so

00:06:17,199 --> 00:06:24,240
we have here the 16 underscore

00:06:21,400 --> 00:06:27,280
dpfs delimited payload

00:06:24,240 --> 00:06:29,120
floating value s for multi-value field

00:06:27,280 --> 00:06:31,120
uh and we see the label and the

00:06:29,120 --> 00:06:35,680
confidence thresholds

00:06:31,120 --> 00:06:37,919
are are encoded here uh yolo

00:06:35,680 --> 00:06:39,520
classification gives us the object type

00:06:37,919 --> 00:06:40,160
in this situation we have an example of

00:06:39,520 --> 00:06:42,560
a person

00:06:40,160 --> 00:06:44,000
and that there was one person detected

00:06:42,560 --> 00:06:46,000
we have positional information

00:06:44,000 --> 00:06:47,280
x and y coordinates of where in the

00:06:46,000 --> 00:06:50,240
image

00:06:47,280 --> 00:06:53,120
that that person was detected and we

00:06:50,240 --> 00:06:56,880
even can compute things like how large

00:06:53,120 --> 00:06:56,880
the the person is in the image

00:06:58,000 --> 00:07:01,199
all of this kind of boils down to a

00:07:00,000 --> 00:07:03,440
general

00:07:01,199 --> 00:07:05,199
data model that looks like this is a

00:07:03,440 --> 00:07:07,120
one-to-many relationship between

00:07:05,199 --> 00:07:08,960
documents and classifications

00:07:07,120 --> 00:07:10,479
where you have a document with some data

00:07:08,960 --> 00:07:11,840
on it that's your parent document and

00:07:10,479 --> 00:07:14,160
then you potentially have many

00:07:11,840 --> 00:07:17,520
classifications each one with its label

00:07:14,160 --> 00:07:19,759
and its own confidence score

00:07:17,520 --> 00:07:21,440
so the first approach to index something

00:07:19,759 --> 00:07:23,360
like this the most naive approach and

00:07:21,440 --> 00:07:25,280
simplest approach by far

00:07:23,360 --> 00:07:26,720
is if we want to search for all the

00:07:25,280 --> 00:07:28,880
documents where

00:07:26,720 --> 00:07:31,039
they had been classified as containing a

00:07:28,880 --> 00:07:33,520
person with 0.75

00:07:31,039 --> 00:07:35,280
you know confidence or greater one thing

00:07:33,520 --> 00:07:36,319
we can do is filter it at index time

00:07:35,280 --> 00:07:38,000
and this is the most you know

00:07:36,319 --> 00:07:39,680
straightforward way it says you do your

00:07:38,000 --> 00:07:42,479
classification up front

00:07:39,680 --> 00:07:44,960
and you only tag the document with the

00:07:42,479 --> 00:07:47,520
the labels that were above a particular

00:07:44,960 --> 00:07:49,120
threshold now the pros of this approach

00:07:47,520 --> 00:07:52,800
is it's incredibly simple

00:07:49,120 --> 00:07:54,639
it's very fast the index is very small

00:07:52,800 --> 00:07:56,240
but the real trade-off is that you can't

00:07:54,639 --> 00:07:57,199
change your mind about what the

00:07:56,240 --> 00:07:58,319
threshold was

00:07:57,199 --> 00:08:00,560
at query time because you're throwing

00:07:58,319 --> 00:08:02,720
that away at index time

00:08:00,560 --> 00:08:03,599
so if you wanted to change your query to

00:08:02,720 --> 00:08:05,759
say

00:08:03,599 --> 00:08:07,599
medium or high confidence thresholds

00:08:05,759 --> 00:08:09,120
then i need two separate fields to

00:08:07,599 --> 00:08:10,720
include the different labels and stuff

00:08:09,120 --> 00:08:13,440
and that complexity just

00:08:10,720 --> 00:08:15,360
kind of grows as you know you want to

00:08:13,440 --> 00:08:16,240
tweak what you consider high medium and

00:08:15,360 --> 00:08:19,680
low

00:08:16,240 --> 00:08:22,080
so kind of a straightforward approach um

00:08:19,680 --> 00:08:24,000
for its simplicity but it does not yield

00:08:22,080 --> 00:08:25,919
any flexibility at query time

00:08:24,000 --> 00:08:27,680
and if we look at what a document of

00:08:25,919 --> 00:08:29,360
this style would look like

00:08:27,680 --> 00:08:30,960
uh obviously you have a document id and

00:08:29,360 --> 00:08:32,560
maybe you have a field that's like your

00:08:30,960 --> 00:08:34,000
high confidence labels

00:08:32,560 --> 00:08:36,080
where you tag the document as being a

00:08:34,000 --> 00:08:39,360
dog or a cat or whatever it is

00:08:36,080 --> 00:08:40,800
and a simple you know term query on that

00:08:39,360 --> 00:08:43,519
field is going to find

00:08:40,800 --> 00:08:44,240
things that are tagged as being cat or a

00:08:43,519 --> 00:08:45,839
dog

00:08:44,240 --> 00:08:48,720
because you did that filtering up front

00:08:45,839 --> 00:08:48,720
at index time

00:08:50,160 --> 00:08:53,839
not every model has the same sort of

00:08:52,080 --> 00:08:54,959
confidence threshold sometimes you want

00:08:53,839 --> 00:08:56,880
to expose that

00:08:54,959 --> 00:08:59,120
that confidence threshold to the end

00:08:56,880 --> 00:09:02,160
users to decide what they consider

00:08:59,120 --> 00:09:02,800
good output from the model or not um and

00:09:02,160 --> 00:09:05,200
allow

00:09:02,800 --> 00:09:06,080
you know the end user to adjust their

00:09:05,200 --> 00:09:08,880
their recall

00:09:06,080 --> 00:09:09,360
on this so another approach to setting

00:09:08,880 --> 00:09:12,880
this up

00:09:09,360 --> 00:09:14,959
is to use a dynamic field or one field

00:09:12,880 --> 00:09:16,560
per label that came out of the

00:09:14,959 --> 00:09:18,480
classification

00:09:16,560 --> 00:09:20,640
so you could imagine having a field for

00:09:18,480 --> 00:09:23,279
cat that was a floating point field

00:09:20,640 --> 00:09:24,080
and that has the score of 0.75 whatever

00:09:23,279 --> 00:09:27,120
it is

00:09:24,080 --> 00:09:27,519
a field for dog a field for a person you

00:09:27,120 --> 00:09:29,839
know

00:09:27,519 --> 00:09:31,920
and and this this can work very well i

00:09:29,839 --> 00:09:35,360
mean the nice thing is that query time

00:09:31,920 --> 00:09:36,640
this becomes a a search on the label

00:09:35,360 --> 00:09:39,440
field

00:09:36,640 --> 00:09:40,959
it's a range search for whatever numeric

00:09:39,440 --> 00:09:44,800
value you want in there so pretty

00:09:40,959 --> 00:09:44,800
straightforward very performing queries

00:09:45,120 --> 00:09:48,959
but one trade-off is that you know you

00:09:48,320 --> 00:09:52,080
might have

00:09:48,959 --> 00:09:53,680
a lot of labels and as a result you'll

00:09:52,080 --> 00:09:54,800
end up with a huge number of fields in

00:09:53,680 --> 00:09:57,760
your index

00:09:54,800 --> 00:10:00,080
which as it turns out ends up being

00:09:57,760 --> 00:10:01,200
extremely expensive in terms of memory

00:10:00,080 --> 00:10:05,920
usage

00:10:01,200 --> 00:10:07,440
um and in a solar index or leucine index

00:10:05,920 --> 00:10:09,839
uh and the other trade-off is you might

00:10:07,440 --> 00:10:11,839
not know the labels ahead of time so

00:10:09,839 --> 00:10:13,200
uh you can't necessarily fast it on

00:10:11,839 --> 00:10:14,640
field names like although i guess you

00:10:13,200 --> 00:10:16,399
could use like luke to

00:10:14,640 --> 00:10:18,079
interrogate the index to get all those

00:10:16,399 --> 00:10:19,920
out um

00:10:18,079 --> 00:10:22,959
you know it just adds a little bit of

00:10:19,920 --> 00:10:25,120
extra complex complexity there

00:10:22,959 --> 00:10:26,560
so what is a document that looks like

00:10:25,120 --> 00:10:28,399
what would a document like that look

00:10:26,560 --> 00:10:29,360
like here's here's an example a document

00:10:28,399 --> 00:10:31,040
with an id

00:10:29,360 --> 00:10:33,440
has a field for each one of the labels

00:10:31,040 --> 00:10:35,600
cat dog person and the score

00:10:33,440 --> 00:10:38,880
and the sample query here is is very

00:10:35,600 --> 00:10:38,880
straightforward and very simple

00:10:39,279 --> 00:10:43,440
approach number three that we looked at

00:10:41,519 --> 00:10:46,640
was actually to use a join query

00:10:43,440 --> 00:10:49,279
to leverage the inherent quarry time

00:10:46,640 --> 00:10:50,560
join capabilities that solar and lucine

00:10:49,279 --> 00:10:53,600
have

00:10:50,560 --> 00:10:56,959
to index the parent document

00:10:53,600 --> 00:10:59,120
and the child classification records

00:10:56,959 --> 00:11:01,360
associated with that we would search

00:10:59,120 --> 00:11:03,360
through the classification records

00:11:01,360 --> 00:11:05,279
and perform a joins of the parent

00:11:03,360 --> 00:11:08,000
document and return just the parent

00:11:05,279 --> 00:11:11,120
document that had a classification

00:11:08,000 --> 00:11:12,880
record that that matched the query so

00:11:11,120 --> 00:11:15,120
the pro on this is it gives you full

00:11:12,880 --> 00:11:17,680
flexibility in terms of your

00:11:15,120 --> 00:11:19,839
relational type of queries uh return

00:11:17,680 --> 00:11:21,600
this parent document if and only if the

00:11:19,839 --> 00:11:24,000
classification record has a particular

00:11:21,600 --> 00:11:26,800
label has a particular value

00:11:24,000 --> 00:11:28,320
and you can do is complicated filtering

00:11:26,800 --> 00:11:28,880
on the classification records as you

00:11:28,320 --> 00:11:31,910
like

00:11:28,880 --> 00:11:33,600
and return just the parent record now

00:11:31,910 --> 00:11:35,440
[Music]

00:11:33,600 --> 00:11:37,120
the the big drawback here is of course

00:11:35,440 --> 00:11:38,320
the join queries are much slower and

00:11:37,120 --> 00:11:39,040
we're going to show some benchmarks

00:11:38,320 --> 00:11:41,040
later on

00:11:39,040 --> 00:11:42,160
that really kind of drive that point

00:11:41,040 --> 00:11:44,800
home

00:11:42,160 --> 00:11:46,640
and that's primarily driven aside from

00:11:44,800 --> 00:11:49,040
the fact that you have to do the join

00:11:46,640 --> 00:11:51,839
is that you have a vastly increased

00:11:49,040 --> 00:11:53,760
number of documents in the index

00:11:51,839 --> 00:11:55,760
as a result of having all these children

00:11:53,760 --> 00:11:57,600
documents around and search response

00:11:55,760 --> 00:11:59,760
times generally are kind of linear with

00:11:57,600 --> 00:12:01,200
the number of documents per shard so

00:11:59,760 --> 00:12:02,959
that means that when you start going

00:12:01,200 --> 00:12:04,399
with a join approach you really almost

00:12:02,959 --> 00:12:05,680
immediately have to think about how are

00:12:04,399 --> 00:12:08,800
you going to shard

00:12:05,680 --> 00:12:10,639
or scale up this join and when you do

00:12:08,800 --> 00:12:12,560
any sort of sharding in an environment

00:12:10,639 --> 00:12:13,600
where you are doing a join

00:12:12,560 --> 00:12:15,519
you need to make sure that you're

00:12:13,600 --> 00:12:17,760
routing all of your documents to the

00:12:15,519 --> 00:12:19,440
same shard based on their join key

00:12:17,760 --> 00:12:21,120
otherwise that join query is just not

00:12:19,440 --> 00:12:24,079
going to work as you expect

00:12:21,120 --> 00:12:26,079
so a little bit of complexity and if you

00:12:24,079 --> 00:12:28,160
have the freedom to route by the join

00:12:26,079 --> 00:12:30,000
key then that's

00:12:28,160 --> 00:12:31,200
probably not as much of an issue but it

00:12:30,000 --> 00:12:32,079
definitely needs to be thought about

00:12:31,200 --> 00:12:35,279
when you're

00:12:32,079 --> 00:12:35,279
going with an approach like this

00:12:35,839 --> 00:12:40,320
in a document here here's an example of

00:12:37,519 --> 00:12:41,680
what a join query with a

00:12:40,320 --> 00:12:43,600
parent document in the child

00:12:41,680 --> 00:12:45,600
classification documents would look like

00:12:43,600 --> 00:12:48,079
we have a simple document whether just

00:12:45,600 --> 00:12:51,120
an id maybe some other metadata on it

00:12:48,079 --> 00:12:53,360
and then for our example we did a

00:12:51,120 --> 00:12:54,880
million parent documents each one having

00:12:53,360 --> 00:12:57,200
an average of 50

00:12:54,880 --> 00:12:58,880
classification documents and the

00:12:57,200 --> 00:13:00,639
classification documents themselves had

00:12:58,880 --> 00:13:02,240
a pointer back to the parent

00:13:00,639 --> 00:13:05,200
uh they have a label and a confidence

00:13:02,240 --> 00:13:06,160
score and we see an example join query

00:13:05,200 --> 00:13:09,519
below that does

00:13:06,160 --> 00:13:11,920
a search for uh classifications

00:13:09,519 --> 00:13:13,200
for yours is label foo so searching for

00:13:11,920 --> 00:13:15,040
the foo

00:13:13,200 --> 00:13:16,639
classification with a confidence point

00:13:15,040 --> 00:13:19,120
seven five and up

00:13:16,639 --> 00:13:21,040
joining on the parent id back to the

00:13:19,120 --> 00:13:25,040
parent document

00:13:21,040 --> 00:13:26,880
on the id field so definitely doable one

00:13:25,040 --> 00:13:28,720
thing to note is that with this query

00:13:26,880 --> 00:13:30,639
here only the parent documents will be

00:13:28,720 --> 00:13:33,279
returned so the metadata of the

00:13:30,639 --> 00:13:33,680
child document being classified is is

00:13:33,279 --> 00:13:37,360
not

00:13:33,680 --> 00:13:39,440
available to the ui um unless you use

00:13:37,360 --> 00:13:41,680
the like a child doc transformer to

00:13:39,440 --> 00:13:42,160
fetch the matching classified document

00:13:41,680 --> 00:13:44,079
so

00:13:42,160 --> 00:13:45,839
adding additional complexity not just

00:13:44,079 --> 00:13:49,279
the query but also to fetch the

00:13:45,839 --> 00:13:52,560
the matched uh metadata from the

00:13:49,279 --> 00:13:53,839
classification record all right so this

00:13:52,560 --> 00:13:57,040
this brings us to

00:13:53,839 --> 00:13:58,399
um the the payload approach that we we

00:13:57,040 --> 00:14:00,639
took a look and we

00:13:58,399 --> 00:14:02,959
we observed this this common use case of

00:14:00,639 --> 00:14:04,959
being able to search for a label on a

00:14:02,959 --> 00:14:06,959
document or a term on a document

00:14:04,959 --> 00:14:08,480
and that term or label came from a

00:14:06,959 --> 00:14:10,240
machine learned model

00:14:08,480 --> 00:14:12,160
and it's really almost like a one

00:14:10,240 --> 00:14:13,680
dimensional join we always knew that

00:14:12,160 --> 00:14:16,079
we're going to be

00:14:13,680 --> 00:14:16,800
filtering on a single dimension in this

00:14:16,079 --> 00:14:20,160
case here

00:14:16,800 --> 00:14:22,240
the confidence score so we looked at the

00:14:20,160 --> 00:14:24,320
existing payload check query parser

00:14:22,240 --> 00:14:26,079
and we're a little disappointed to find

00:14:24,320 --> 00:14:27,120
that it only supported an equality

00:14:26,079 --> 00:14:28,639
operation

00:14:27,120 --> 00:14:31,040
and understanding that at the end of the

00:14:28,639 --> 00:14:33,040
day this is just paging in a byte array

00:14:31,040 --> 00:14:34,800
and previously it was doing an equals to

00:14:33,040 --> 00:14:36,880
implement a comparator

00:14:34,800 --> 00:14:38,240
interface on that to greater than less

00:14:36,880 --> 00:14:40,959
than or equal to

00:14:38,240 --> 00:14:41,920
really was little to no computational

00:14:40,959 --> 00:14:43,519
overhead

00:14:41,920 --> 00:14:45,199
so we were confident this approach was

00:14:43,519 --> 00:14:48,000
going to perform at least as well as

00:14:45,199 --> 00:14:49,600
normal payload queries do

00:14:48,000 --> 00:14:51,360
so what we did is we encoded the

00:14:49,600 --> 00:14:54,560
confidence scores uh

00:14:51,360 --> 00:14:56,399
as a payload a floating point value

00:14:54,560 --> 00:14:58,560
and we indexed them and we extended the

00:14:56,399 --> 00:15:02,000
payload query check

00:14:58,560 --> 00:15:04,880
parser to support these inequalities

00:15:02,000 --> 00:15:06,079
to do this and we take a look at what an

00:15:04,880 --> 00:15:09,440
example document

00:15:06,079 --> 00:15:11,199
that uses the payload check query parser

00:15:09,440 --> 00:15:12,720
would look like here we have a single

00:15:11,199 --> 00:15:15,440
field with the classifications

00:15:12,720 --> 00:15:17,199
this is effectively the the output layer

00:15:15,440 --> 00:15:19,600
of the neural network

00:15:17,199 --> 00:15:20,560
with some human readable labels cat dog

00:15:19,600 --> 00:15:23,279
and person

00:15:20,560 --> 00:15:26,639
with the pipe delimiting the term or the

00:15:23,279 --> 00:15:28,320
label from the confidence score

00:15:26,639 --> 00:15:30,800
and you see the payload check query

00:15:28,320 --> 00:15:31,839
parser where you specify the field that

00:15:30,800 --> 00:15:33,519
you're going to do this on

00:15:31,839 --> 00:15:35,680
you specify the payload and the

00:15:33,519 --> 00:15:38,079
operation for the comparison

00:15:35,680 --> 00:15:39,040
and the original query term which is cat

00:15:38,079 --> 00:15:42,320
in this case

00:15:39,040 --> 00:15:46,240
to only find cats that are 75 or

00:15:42,320 --> 00:15:46,240
better confidence score

00:15:47,920 --> 00:15:51,680
so four different approaches are great

00:15:50,079 --> 00:15:54,079
but you really need to make an

00:15:51,680 --> 00:15:55,440
informed decision about why you're

00:15:54,079 --> 00:15:58,480
choosing to go with one

00:15:55,440 --> 00:16:00,160
or the other in my opinion the only real

00:15:58,480 --> 00:16:01,680
way to do that is actually to do some

00:16:00,160 --> 00:16:04,560
benchmarking

00:16:01,680 --> 00:16:05,680
so what we did is we generated relative

00:16:04,560 --> 00:16:08,720
indices

00:16:05,680 --> 00:16:12,320
uh representative data to

00:16:08,720 --> 00:16:12,320
prove out some of these benchmarks

00:16:12,560 --> 00:16:16,079
for indexing benchmarks that we're going

00:16:14,079 --> 00:16:17,759
to talk about we had a single threaded

00:16:16,079 --> 00:16:20,320
java application

00:16:17,759 --> 00:16:21,519
that was just feeding documents into

00:16:20,320 --> 00:16:24,480
solar

00:16:21,519 --> 00:16:27,120
with the formats as we've described in

00:16:24,480 --> 00:16:29,519
the previous slides

00:16:27,120 --> 00:16:30,399
for those documents we generated one

00:16:29,519 --> 00:16:33,040
million of them

00:16:30,399 --> 00:16:35,040
each document had an average of 50

00:16:33,040 --> 00:16:36,720
classifications per document

00:16:35,040 --> 00:16:38,560
and those classifications had a random

00:16:36,720 --> 00:16:40,800
confidence score assigned to them 0

00:16:38,560 --> 00:16:43,839
between 0 and 1.

00:16:40,800 --> 00:16:45,839
there are 10 000 unique labels

00:16:43,839 --> 00:16:47,440
in that classification data set that we

00:16:45,839 --> 00:16:49,360
used to generate so

00:16:47,440 --> 00:16:51,680
we have a million documents with on

00:16:49,360 --> 00:16:54,480
average 50 classifications spanning

00:16:51,680 --> 00:16:54,959
10 000 different labels uh each with a

00:16:54,480 --> 00:16:57,759
score

00:16:54,959 --> 00:16:59,920
randomly distributed zero to one so you

00:16:57,759 --> 00:17:02,079
know kind of a

00:16:59,920 --> 00:17:03,440
relative representative data set for

00:17:02,079 --> 00:17:04,880
what we see

00:17:03,440 --> 00:17:07,360
when we actually use these neural

00:17:04,880 --> 00:17:09,199
networks and indexing time

00:17:07,360 --> 00:17:10,559
at quarry time we wanted to make sure

00:17:09,199 --> 00:17:12,160
that we're looking at the raw query

00:17:10,559 --> 00:17:13,839
performance and we're not being fooled

00:17:12,160 --> 00:17:17,360
by any of the caching going on

00:17:13,839 --> 00:17:20,000
so we again have a single threaded app

00:17:17,360 --> 00:17:21,039
uh all the filter cache sizes were set

00:17:20,000 --> 00:17:22,880
to zero

00:17:21,039 --> 00:17:24,720
so really the only effects of caching

00:17:22,880 --> 00:17:26,959
that we saw in this benchmark were

00:17:24,720 --> 00:17:28,400
operating system level caches uh

00:17:26,959 --> 00:17:30,080
potentially some of the leucine field

00:17:28,400 --> 00:17:31,919
level caches that get triggered but

00:17:30,080 --> 00:17:35,120
none of the solar caches were enabled

00:17:31,919 --> 00:17:35,120
for these benchmarks

00:17:36,160 --> 00:17:39,200
getting into the actual benchmarks here

00:17:38,320 --> 00:17:41,679
um

00:17:39,200 --> 00:17:42,240
the the couple things jump out at us

00:17:41,679 --> 00:17:44,320
that

00:17:42,240 --> 00:17:46,000
the approach one where we're filtering

00:17:44,320 --> 00:17:47,520
data out at index time

00:17:46,000 --> 00:17:50,320
we were able to index these documents

00:17:47,520 --> 00:17:53,360
very quickly 11 000 documents a second

00:17:50,320 --> 00:17:56,320
the index was was the smallest uh

00:17:53,360 --> 00:17:58,160
memory usage as reported through the

00:17:56,320 --> 00:18:00,559
solar console on the core

00:17:58,160 --> 00:18:02,240
uh the heap usage and was was pretty

00:18:00,559 --> 00:18:05,440
small ultimately

00:18:02,240 --> 00:18:08,320
um approach two

00:18:05,440 --> 00:18:10,000
a bit surprising where we have all of

00:18:08,320 --> 00:18:10,559
the fields potentially ten thousand

00:18:10,000 --> 00:18:14,240
fields

00:18:10,559 --> 00:18:17,600
in the index uh it was the slowest to

00:18:14,240 --> 00:18:19,600
index um perhaps because the json

00:18:17,600 --> 00:18:20,400
representation of the document is just

00:18:19,600 --> 00:18:23,360
much larger

00:18:20,400 --> 00:18:25,039
it's not as tight of a format we don't

00:18:23,360 --> 00:18:27,120
really know the exact reason why this is

00:18:25,039 --> 00:18:28,559
so much slower perhaps it was because

00:18:27,120 --> 00:18:30,320
there's so many different fields that

00:18:28,559 --> 00:18:31,760
the index itself has to

00:18:30,320 --> 00:18:33,360
kind of pay attention to where it's

00:18:31,760 --> 00:18:35,280
writing that data out in the index it

00:18:33,360 --> 00:18:40,480
wasn't wasn't super easy for that to

00:18:35,280 --> 00:18:42,080
be achieved so 209 documents versus 11

00:18:40,480 --> 00:18:45,520
000 documents clearly this

00:18:42,080 --> 00:18:48,320
approach too per field approach

00:18:45,520 --> 00:18:49,919
has major impacts if you're going to be

00:18:48,320 --> 00:18:51,919
a lot doing a lot of indexing

00:18:49,919 --> 00:18:54,480
the the other big one that really jumped

00:18:51,919 --> 00:18:58,000
out at me is that the reported heap

00:18:54,480 --> 00:19:00,640
usage required for supporting this index

00:18:58,000 --> 00:19:03,120
nearly a thousand times more memory

00:19:00,640 --> 00:19:05,520
compared to approach one

00:19:03,120 --> 00:19:09,200
really highlighting the impact of having

00:19:05,520 --> 00:19:10,960
a lot of fields in your index

00:19:09,200 --> 00:19:14,080
approach three using the child document

00:19:10,960 --> 00:19:16,640
join yielded the largest index overall

00:19:14,080 --> 00:19:18,080
so you know uh we're talking about small

00:19:16,640 --> 00:19:21,360
indices here but

00:19:18,080 --> 00:19:26,160
you know 2.6 gig uh

00:19:21,360 --> 00:19:27,679
i'm sorry 216 meg and this sample index

00:19:26,160 --> 00:19:29,919
having the overhead of the additional

00:19:27,679 --> 00:19:32,400
documents in this situation

00:19:29,919 --> 00:19:33,360
and really kind of contributed to the

00:19:32,400 --> 00:19:36,960
index size

00:19:33,360 --> 00:19:40,880
memory usage not as far out of whack

00:19:36,960 --> 00:19:43,600
as compared to the per field approach 2

00:19:40,880 --> 00:19:44,960
not too bad but interestingly approach 4

00:19:43,600 --> 00:19:47,520
with the payloads

00:19:44,960 --> 00:19:49,120
yielded a slightly larger index than

00:19:47,520 --> 00:19:51,760
approach 2

00:19:49,120 --> 00:19:52,799
but the indexing rate was know about 15

00:19:51,760 --> 00:19:55,200
times faster than

00:19:52,799 --> 00:19:55,919
approach 2. so it's certainly not as

00:19:55,200 --> 00:19:58,720
fast as

00:19:55,919 --> 00:19:58,960
throwing away data at index time but you

00:19:58,720 --> 00:20:00,640
know

00:19:58,960 --> 00:20:02,960
nearly 10 times faster than the join

00:20:00,640 --> 00:20:06,320
approach 15 times faster than the per

00:20:02,960 --> 00:20:06,960
label approach memory usage surprisingly

00:20:06,320 --> 00:20:09,440
also is

00:20:06,960 --> 00:20:11,200
less than original approach one and i

00:20:09,440 --> 00:20:13,600
think this might just be

00:20:11,200 --> 00:20:16,080
you know we'll call those roughly

00:20:13,600 --> 00:20:16,080
equivalent

00:20:16,880 --> 00:20:21,360
query benchmarks um also very important

00:20:19,600 --> 00:20:22,640
to pay attention to because we're not

00:20:21,360 --> 00:20:24,240
just

00:20:22,640 --> 00:20:26,080
concerned with indexing we're also

00:20:24,240 --> 00:20:28,240
concerned with querying

00:20:26,080 --> 00:20:29,760
join queries we're slow so slow in this

00:20:28,240 --> 00:20:30,640
benchmark that we just stopped after a

00:20:29,760 --> 00:20:33,760
thousand queries

00:20:30,640 --> 00:20:35,520
um we'll say that up front approach one

00:20:33,760 --> 00:20:37,440
600 queries a second

00:20:35,520 --> 00:20:38,559
running 10 000 queries one for each

00:20:37,440 --> 00:20:40,159
label

00:20:38,559 --> 00:20:41,760
no big surprise because this is just a

00:20:40,159 --> 00:20:44,320
simple term cory

00:20:41,760 --> 00:20:45,280
uh the range query approach on the per

00:20:44,320 --> 00:20:48,640
field

00:20:45,280 --> 00:20:49,520
was the second fastest about 350 queries

00:20:48,640 --> 00:20:52,240
a second

00:20:49,520 --> 00:20:55,360
but notably the average result size for

00:20:52,240 --> 00:20:57,120
these documents was considerably larger

00:20:55,360 --> 00:20:58,400
probably because the overhead of all the

00:20:57,120 --> 00:21:00,880
json uh

00:20:58,400 --> 00:21:01,679
formatting and stuff so i think that's

00:21:00,880 --> 00:21:03,919
what really

00:21:01,679 --> 00:21:05,200
kind of hurt approach two in this this

00:21:03,919 --> 00:21:08,960
case

00:21:05,200 --> 00:21:11,520
uh the join parent-child relationship

00:21:08,960 --> 00:21:12,240
quarters were taken like two seconds um

00:21:11,520 --> 00:21:14,640
you know of course

00:21:12,240 --> 00:21:16,799
we turned off caching so that's kind of

00:21:14,640 --> 00:21:18,720
very negatively affecting this but

00:21:16,799 --> 00:21:20,000
we're not measuring queries in terms of

00:21:18,720 --> 00:21:22,559
hundreds of queries per second

00:21:20,000 --> 00:21:24,480
we're measuring query rates at like half

00:21:22,559 --> 00:21:26,300
a quarter second 0.5

00:21:24,480 --> 00:21:28,159
quarters per second um

00:21:26,300 --> 00:21:31,120
[Music]

00:21:28,159 --> 00:21:31,919
compared to the the payload approach

00:21:31,120 --> 00:21:34,559
where

00:21:31,919 --> 00:21:36,799
we don't have the memory hit that we did

00:21:34,559 --> 00:21:38,799
on the the index side

00:21:36,799 --> 00:21:40,000
we're still getting about 250 queries a

00:21:38,799 --> 00:21:43,280
second

00:21:40,000 --> 00:21:46,880
average result size of these are smaller

00:21:43,280 --> 00:21:50,480
likely to the tighter uh you know

00:21:46,880 --> 00:21:51,760
json that we have um overall the query

00:21:50,480 --> 00:21:54,080
response time

00:21:51,760 --> 00:21:55,760
yeah you know i mean three milliseconds

00:21:54,080 --> 00:21:56,559
versus one or two milliseconds in the

00:21:55,760 --> 00:21:59,840
other approach

00:21:56,559 --> 00:21:59,840
still in the ballpark

00:22:00,559 --> 00:22:05,280
so let's uh let's talk a little bit

00:22:03,360 --> 00:22:06,000
about a quick little demo that we'd like

00:22:05,280 --> 00:22:09,039
to show

00:22:06,000 --> 00:22:10,880
um to see what this looks like so we

00:22:09,039 --> 00:22:13,679
index the cocoa image data set

00:22:10,880 --> 00:22:14,960
this is about 118 000 images through

00:22:13,679 --> 00:22:17,840
open source

00:22:14,960 --> 00:22:19,440
we have a document processing pipeline

00:22:17,840 --> 00:22:21,039
that has an image processing sub

00:22:19,440 --> 00:22:23,120
pipeline that handles

00:22:21,039 --> 00:22:25,919
things like running opencv for blur

00:22:23,120 --> 00:22:28,799
detection detecting faces

00:22:25,919 --> 00:22:32,080
and also running things like vgg16

00:22:28,799 --> 00:22:34,320
classification yolo classification

00:22:32,080 --> 00:22:35,919
and similar we kind of hinted at this

00:22:34,320 --> 00:22:39,760
document

00:22:35,919 --> 00:22:41,280
style before here is an example of what

00:22:39,760 --> 00:22:42,960
the the documents look like in our

00:22:41,280 --> 00:22:47,280
example index

00:22:42,960 --> 00:22:47,280
so let me go ahead and

00:22:48,640 --> 00:22:55,039
switch over to the index here where

00:22:51,840 --> 00:22:55,679
make this a little bit bigger and we

00:22:55,039 --> 00:22:58,799
have here

00:22:55,679 --> 00:23:02,799
an index of a 118

00:22:58,799 --> 00:23:05,760
000 images and we want to start asking

00:23:02,799 --> 00:23:08,799
some questions based on the outputs

00:23:05,760 --> 00:23:09,760
of those models so here for example let

00:23:08,799 --> 00:23:11,840
me ask

00:23:09,760 --> 00:23:13,520
of these images show me the ones where

00:23:11,840 --> 00:23:16,799
pizza was classified as

00:23:13,520 --> 00:23:17,880
0.75 or above great and we see that

00:23:16,799 --> 00:23:21,200
we've got

00:23:17,880 --> 00:23:22,320
855. maybe i want more recall i can

00:23:21,200 --> 00:23:27,120
decrease this

00:23:22,320 --> 00:23:27,120
and now we've got 1100 pictures of pizza

00:23:28,559 --> 00:23:33,919
and let's say i want to find ovens

00:23:35,760 --> 00:23:40,720
here i'm looking for pictures that have

00:23:37,520 --> 00:23:44,320
at least one oven in them

00:23:40,720 --> 00:23:47,120
maybe i'm interested in ovens

00:23:44,320 --> 00:23:48,400
and pizza which is kind of interesting

00:23:47,120 --> 00:23:50,080
because now we're

00:23:48,400 --> 00:23:52,000
we're leveraging the output of one

00:23:50,080 --> 00:23:55,360
neural network model yolo

00:23:52,000 --> 00:23:56,480
and another neural network model vg16 at

00:23:55,360 --> 00:23:59,039
the same time

00:23:56,480 --> 00:23:59,919
not just to find you know pizzas or

00:23:59,039 --> 00:24:02,720
ovens but

00:23:59,919 --> 00:24:03,440
pictures of ovens and pizzas or pizzas

00:24:02,720 --> 00:24:06,400
and ovens

00:24:03,440 --> 00:24:09,200
maybe i want ovens and pizzas and people

00:24:06,400 --> 00:24:09,200
for example

00:24:09,440 --> 00:24:13,520
people with well that's that kind of

00:24:11,200 --> 00:24:15,200
looks like a stove but that's an oven

00:24:13,520 --> 00:24:17,120
you can kind of see a blurry person over

00:24:15,200 --> 00:24:20,400
here here's a person with a pizza and

00:24:17,120 --> 00:24:20,400
there's an oven in the background

00:24:20,559 --> 00:24:28,640
maybe i'm interested in

00:24:23,600 --> 00:24:33,840
a person with a laptop

00:24:28,640 --> 00:24:33,840
find those maybe i'm interested in

00:24:33,919 --> 00:24:39,279
more than one person or a group of

00:24:35,840 --> 00:24:39,279
people with laptops

00:24:39,600 --> 00:24:46,559
maybe i'm looking for

00:24:42,720 --> 00:24:50,000
people whoops

00:24:46,559 --> 00:24:52,000
at a bakery you know

00:24:50,000 --> 00:24:54,159
greater than two people at a bakery

00:24:52,000 --> 00:24:55,039
maybe i want less than two people at a

00:24:54,159 --> 00:24:57,360
bakery

00:24:55,039 --> 00:24:59,840
well let's see are less than equal to

00:24:57,360 --> 00:25:04,000
two and get that people out there

00:24:59,840 --> 00:25:04,000
there's only one person at a bakery so

00:25:04,240 --> 00:25:08,400
let's go back now

00:25:10,159 --> 00:25:14,000
all right what are what are some other

00:25:12,320 --> 00:25:17,120
things that we need to

00:25:14,000 --> 00:25:19,120
consider going forward with this um

00:25:17,120 --> 00:25:21,279
in in some of this work that we did in

00:25:19,120 --> 00:25:23,840
lucine it kind of appeared that the

00:25:21,279 --> 00:25:25,600
codec the encoding and decoding of the

00:25:23,840 --> 00:25:27,279
payloads is a little bit fragmented to

00:25:25,600 --> 00:25:29,120
be a nice improvement in the code to

00:25:27,279 --> 00:25:30,960
make it a little more extensible

00:25:29,120 --> 00:25:32,640
and once that codec library would be a

00:25:30,960 --> 00:25:33,600
little more extensible it would be a

00:25:32,640 --> 00:25:35,520
very short

00:25:33,600 --> 00:25:38,080
lift to do some things like vector

00:25:35,520 --> 00:25:39,919
matching where if you encoded not just a

00:25:38,080 --> 00:25:41,520
single floating point value but an array

00:25:39,919 --> 00:25:43,120
of floating point values you could start

00:25:41,520 --> 00:25:45,760
doing things like computing cosine

00:25:43,120 --> 00:25:48,080
similarities

00:25:45,760 --> 00:25:50,240
once we have these sort of you know

00:25:48,080 --> 00:25:51,600
classification feature vectors from from

00:25:50,240 --> 00:25:54,559
these neural networks

00:25:51,600 --> 00:25:56,320
uh it's a small jump also to look at the

00:25:54,559 --> 00:25:56,880
the classifications that came out for an

00:25:56,320 --> 00:25:59,919
image

00:25:56,880 --> 00:26:02,240
and compose a fine similar to find

00:25:59,919 --> 00:26:03,520
other images that had similar style

00:26:02,240 --> 00:26:06,720
classifications and

00:26:03,520 --> 00:26:08,000
classifications in similar ranges um

00:26:06,720 --> 00:26:10,240
one of the things that kind of jumped

00:26:08,000 --> 00:26:11,679
out at me is additional

00:26:10,240 --> 00:26:13,840
you know things that would be nice to

00:26:11,679 --> 00:26:17,279
have the syntax for this

00:26:13,840 --> 00:26:19,440
is a little bit difficult to

00:26:17,279 --> 00:26:21,679
to work on it's it's not definitely

00:26:19,440 --> 00:26:25,039
something that an end user would type in

00:26:21,679 --> 00:26:27,279
uh having some nlu or in nlp sort of

00:26:25,039 --> 00:26:29,360
front end for query parsing so that you

00:26:27,279 --> 00:26:30,480
could in natural language say show me a

00:26:29,360 --> 00:26:33,279
picture of an oven

00:26:30,480 --> 00:26:34,640
with some pizzas and at least two people

00:26:33,279 --> 00:26:38,720
uh and translate that into the

00:26:34,640 --> 00:26:41,840
appropriate query

00:26:38,720 --> 00:26:44,640
so this was uh all added back in this

00:26:41,840 --> 00:26:45,440
will be in solar 9 when when solar 9 is

00:26:44,640 --> 00:26:48,640
released

00:26:45,440 --> 00:26:52,080
um in the tickets the scene 96

00:26:48,640 --> 00:26:54,640
59 and solar 14 787

00:26:52,080 --> 00:26:55,360
uh myself as a contributor and

00:26:54,640 --> 00:26:57,440
committers

00:26:55,360 --> 00:26:58,400
gus heck and dave smiley big thank you

00:26:57,440 --> 00:27:00,400
to them

00:26:58,400 --> 00:27:01,760
for for helping usher this through to

00:27:00,400 --> 00:27:05,279
the community

00:27:01,760 --> 00:27:06,400
and um yeah i think we have two minutes

00:27:05,279 --> 00:27:09,679
for questions

00:27:06,400 --> 00:27:09,679
maybe a few more from lucky

00:27:10,080 --> 00:27:13,840
great talk kevin and us i can read from

00:27:13,440 --> 00:27:15,919
here

00:27:13,840 --> 00:27:16,880
even people feel the same it was a great

00:27:15,919 --> 00:27:19,039
talk with a great

00:27:16,880 --> 00:27:20,320
example that you have showcased we do

00:27:19,039 --> 00:27:22,320
have some questions

00:27:20,320 --> 00:27:24,159
some of the questions are answered by

00:27:22,320 --> 00:27:24,799
the community itself however someone

00:27:24,159 --> 00:27:26,480
asked that

00:27:24,799 --> 00:27:28,000
can this payload approach be used in

00:27:26,480 --> 00:27:29,600
elasticsearch

00:27:28,000 --> 00:27:31,600
although the link for this has already

00:27:29,600 --> 00:27:32,720
been provided but would you like to

00:27:31,600 --> 00:27:35,760
extend

00:27:32,720 --> 00:27:39,039
yeah so um the

00:27:35,760 --> 00:27:42,000
the span payload check query uh

00:27:39,039 --> 00:27:43,279
in the leucine layer as soon as that is

00:27:42,000 --> 00:27:45,440
included in the latest

00:27:43,279 --> 00:27:47,279
elastic surge build then at least the

00:27:45,440 --> 00:27:49,679
lucine query would be there

00:27:47,279 --> 00:27:51,919
you would still very much like the need

00:27:49,679 --> 00:27:52,480
some extension to the existing payload

00:27:51,919 --> 00:27:54,559
support

00:27:52,480 --> 00:27:56,080
and elasticsearch so you know being

00:27:54,559 --> 00:27:57,600
lucine under the covers there's no

00:27:56,080 --> 00:28:01,279
reason why it couldn't be extended to

00:27:57,600 --> 00:28:03,440
elastic but it's not currently supported

00:28:01,279 --> 00:28:04,720
great i think on the same line was the

00:28:03,440 --> 00:28:06,640
question that how easy

00:28:04,720 --> 00:28:08,640
it would be to extend the query parser

00:28:06,640 --> 00:28:09,440
and elastic search as it is done in

00:28:08,640 --> 00:28:12,559
solar

00:28:09,440 --> 00:28:14,240
in this talk and i think you've already

00:28:12,559 --> 00:28:17,039
answered that question yeah yeah

00:28:14,240 --> 00:28:18,399
yeah absolutely so you know either with

00:28:17,039 --> 00:28:21,279
uh separate plug-ins

00:28:18,399 --> 00:28:22,080
uh or extending the existing lucene

00:28:21,279 --> 00:28:24,799
existing

00:28:22,080 --> 00:28:25,520
elastic source you'd be able to do that

00:28:24,799 --> 00:28:27,120
but again

00:28:25,520 --> 00:28:29,039
this is going to require that

00:28:27,120 --> 00:28:29,440
elasticsearch is pulling in the latest

00:28:29,039 --> 00:28:32,880
uh

00:28:29,440 --> 00:28:34,559
leucine from that the 9x branch correct

00:28:32,880 --> 00:28:36,399
yep i think max irvin

00:28:34,559 --> 00:28:38,480
also commenced the same thing probably

00:28:36,399 --> 00:28:39,600
he has tried uh something on that side

00:28:38,480 --> 00:28:42,559
already

00:28:39,600 --> 00:28:44,320
so he uh requests if there is a way to

00:28:42,559 --> 00:28:47,200
reference the payloads in a

00:28:44,320 --> 00:28:47,919
painless script uh if that can be

00:28:47,200 --> 00:28:50,320
provided

00:28:47,919 --> 00:28:51,840
we we we haven't done that and actually

00:28:50,320 --> 00:28:52,480
it's kind of looking at it a little bit

00:28:51,840 --> 00:28:55,520
more

00:28:52,480 --> 00:28:57,360
um it'd be nice to kind of extend this

00:28:55,520 --> 00:28:59,760
payload check support

00:28:57,360 --> 00:29:01,960
into the payload score core reparser so

00:28:59,760 --> 00:29:03,440
you could start doing things like that

00:29:01,960 --> 00:29:05,520
[Music]

00:29:03,440 --> 00:29:13,840
that would be a very nice future

00:29:05,520 --> 00:29:13,840
enhancement for certain

00:29:27,360 --> 00:29:29,440

YouTube URL: https://www.youtube.com/watch?v=IrMcasPK_sc


