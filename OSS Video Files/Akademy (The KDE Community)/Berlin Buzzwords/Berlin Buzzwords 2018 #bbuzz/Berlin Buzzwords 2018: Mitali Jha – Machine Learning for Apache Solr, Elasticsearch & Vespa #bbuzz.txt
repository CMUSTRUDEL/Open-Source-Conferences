Title: Berlin Buzzwords 2018: Mitali Jha â€“ Machine Learning for Apache Solr, Elasticsearch & Vespa #bbuzz
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	Apache Solr, Elasticsearch and Vespa are three of the most popular general purpose search engines that are used in search, recommendations and analytics based applications. Machine learning is a critical aid to improving relevance beyond the native ranking algorithms (e.g. TF-IDF, BM25 etc.) by leveraging editorial judgements and user behaviour and factoring them into ranking of results. This is known as "learning to rank" (LTR) or "machine learned ranking" (MLR) etc.

In this talk, the speaker presents a comparison of machine learning frameworks across all of these search engines. The comparison is followed by a quick demonstration on how to use all of these frameworks. This talk is aimed at those who are looking to decide upon which search engine to use in their applications based on the machine learned ranking capabilities available for it, and the ease of using such features.

Read more:
https://2018.berlinbuzzwords.de/18/session/machine-learning-apache-solr-elasticsearch-vespa

About Mitali Jha:
https://2018.berlinbuzzwords.de/users/mitali-jha

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:04,530 --> 00:00:11,970
hi everyone I'm Natalia and I work on

00:00:10,380 --> 00:00:15,629
machine learning projects in a company

00:00:11,970 --> 00:00:17,370
called crossover so I'm sorry for all

00:00:15,629 --> 00:00:19,580
the experts here because my talk is

00:00:17,370 --> 00:00:23,430
geared more towards the beginners of

00:00:19,580 --> 00:00:25,830
learning to rank that is the developers

00:00:23,430 --> 00:00:28,170
who have already built an a search

00:00:25,830 --> 00:00:29,670
engine application but I get to leverage

00:00:28,170 --> 00:00:31,980
the machine learning capabilities for

00:00:29,670 --> 00:00:33,840
ranking now this is just a very

00:00:31,980 --> 00:00:35,579
high-level introduction on how to use

00:00:33,840 --> 00:00:38,640
learning to rank and it's not intended

00:00:35,579 --> 00:00:42,449
for the audience who has leveraged the

00:00:38,640 --> 00:00:45,780
machine learning capabilities so what is

00:00:42,449 --> 00:00:47,519
learning to rank now learning to rank is

00:00:45,780 --> 00:00:50,730
a class of machine learning algorithms

00:00:47,519 --> 00:00:54,659
that outputs models that are used for

00:00:50,730 --> 00:00:56,909
ranking the query search results based

00:00:54,659 --> 00:00:59,219
on optimization of feature values now

00:00:56,909 --> 00:01:01,229
generally what happens is that when a

00:00:59,219 --> 00:01:04,140
developer starts building a search

00:01:01,229 --> 00:01:06,350
engine application he normally Tunes the

00:01:04,140 --> 00:01:09,869
ranking parameters in a way so as to

00:01:06,350 --> 00:01:12,390
achieve maximum achieve as relevant

00:01:09,869 --> 00:01:15,390
results as possible however with the

00:01:12,390 --> 00:01:20,549
machine learning capabilities capturing

00:01:15,390 --> 00:01:22,469
user behavior and logging so better and

00:01:20,549 --> 00:01:25,200
more optimal results can be achieved

00:01:22,469 --> 00:01:27,450
without even having to have the domain

00:01:25,200 --> 00:01:30,390
expertise by training the machine learnt

00:01:27,450 --> 00:01:35,820
model and using this trained model for

00:01:30,390 --> 00:01:38,850
banking so now I would walk you through

00:01:35,820 --> 00:01:41,009
the demos of the three search engines

00:01:38,850 --> 00:01:44,430
starting off alphabetically from

00:01:41,009 --> 00:01:46,950
elasticsearch so the LTR plugin for

00:01:44,430 --> 00:01:50,939
elastic search comes as a third-party

00:01:46,950 --> 00:01:54,090
plugin oh it happened okay comes as a

00:01:50,939 --> 00:01:58,039
third-party plugin which is provided by

00:01:54,090 --> 00:02:01,499
open source connections this was

00:01:58,039 --> 00:02:03,119
developed by dr. bull so if you have any

00:02:01,499 --> 00:02:07,229
queries you can always reach out to him

00:02:03,119 --> 00:02:09,270
he must be here somewhere then the basic

00:02:07,229 --> 00:02:11,640
concepts here are feature stored now

00:02:09,270 --> 00:02:14,010
what is a feature store a feature store

00:02:11,640 --> 00:02:16,230
is actually a place where different sets

00:02:14,010 --> 00:02:17,370
of feature sets get stored say for

00:02:16,230 --> 00:02:19,950
example

00:02:17,370 --> 00:02:22,140
a team identifies defines a set of

00:02:19,950 --> 00:02:24,090
feature sets which gets stored in a

00:02:22,140 --> 00:02:26,700
feature store and at the same time of

00:02:24,090 --> 00:02:29,849
different team defines yet another set

00:02:26,700 --> 00:02:31,590
of feature sets which goes and sits in

00:02:29,849 --> 00:02:36,390
the same feature store at the same time

00:02:31,590 --> 00:02:40,110
living side-by-side parallely so during

00:02:36,390 --> 00:02:42,959
training we need to select one of the

00:02:40,110 --> 00:02:46,140
future stores from here which goes ahead

00:02:42,959 --> 00:02:49,260
to trainer model the next concept is to

00:02:46,140 --> 00:02:51,810
is a model store this is similar to a

00:02:49,260 --> 00:02:54,510
feature store but here the algorithm

00:02:51,810 --> 00:02:57,569
which has so the algorithm must have

00:02:54,510 --> 00:03:00,299
generated a model which needs to be

00:02:57,569 --> 00:03:03,959
uploaded into a model store onto the

00:03:00,299 --> 00:03:06,780
search engine now while rewriting the

00:03:03,959 --> 00:03:08,670
query results we need to select one of

00:03:06,780 --> 00:03:12,180
the model one of the models from this

00:03:08,670 --> 00:03:16,099
model store and which actually helps in

00:03:12,180 --> 00:03:19,530
which then goes further to Arirang the

00:03:16,099 --> 00:03:22,019
feature value scores the third concept

00:03:19,530 --> 00:03:25,109
is query D scoring now what happens is

00:03:22,019 --> 00:03:28,400
that a search engine originally read

00:03:25,109 --> 00:03:30,900
ank's its query results on the basis of

00:03:28,400 --> 00:03:33,870
what is called as native ranking or

00:03:30,900 --> 00:03:37,500
native scoring but in order to achieve

00:03:33,870 --> 00:03:40,889
more optimal results there's a concept

00:03:37,500 --> 00:03:42,780
of query scoring which then read ank's

00:03:40,889 --> 00:03:46,440
which is also called as second phase

00:03:42,780 --> 00:03:48,530
ranking which reruns the feature value

00:03:46,440 --> 00:03:50,849
sets in order to achieve better results

00:03:48,530 --> 00:03:52,859
so this is the place where query D

00:03:50,849 --> 00:03:55,260
scoring comes into picture then elastic

00:03:52,859 --> 00:03:57,629
ltr' supports libraries like rank clip

00:03:55,260 --> 00:04:01,579
and extra boost and rank lip has got a

00:03:57,629 --> 00:04:04,109
set of algorithms like it supports

00:04:01,579 --> 00:04:06,959
linear regression logistic regression

00:04:04,109 --> 00:04:11,220
then decision tree based models then

00:04:06,959 --> 00:04:13,319
lambda mat etc so for the purpose of

00:04:11,220 --> 00:04:16,620
this demo I have used the movies

00:04:13,319 --> 00:04:18,299
database tmdb dataset which comes as a

00:04:16,620 --> 00:04:21,090
toy example with the learning to rank

00:04:18,299 --> 00:04:24,389
elastic search demo it consists of

00:04:21,090 --> 00:04:30,139
movies for further reference you can go

00:04:24,389 --> 00:04:32,449
to this link and documentation so

00:04:30,139 --> 00:04:40,729
I now walk you through the demo

00:04:32,449 --> 00:04:42,409
elasticsearch is running just okay so

00:04:40,729 --> 00:04:44,960
the first script is the Python script

00:04:42,409 --> 00:04:46,729
for utils which is actively accessing

00:04:44,960 --> 00:04:49,159
which is used for accessing the

00:04:46,729 --> 00:04:51,169
elasticsearch cluster it comes it

00:04:49,159 --> 00:04:53,870
contains parameters like elasticsearch

00:04:51,169 --> 00:04:59,569
host authentication password hostname

00:04:53,870 --> 00:05:02,900
and the port so we run the script the

00:04:59,569 --> 00:05:04,909
next script is the python script for

00:05:02,900 --> 00:05:08,060
prepare which actually downloads the

00:05:04,909 --> 00:05:11,029
tmdb data set and the rank chevron jar

00:05:08,060 --> 00:05:12,469
file so the interest of time and the

00:05:11,029 --> 00:05:14,810
fact that internet usually doesn't work

00:05:12,469 --> 00:05:19,610
during demos I'm not going to run this

00:05:14,810 --> 00:05:21,169
file we move on to the third step so the

00:05:19,610 --> 00:05:24,080
very first step after starting up

00:05:21,169 --> 00:05:28,909
elasticsearch in LTR demo is to Index

00:05:24,080 --> 00:05:31,669
this tmdb data set so we run this script

00:05:28,909 --> 00:05:34,550
and we see here that elastics are

00:05:31,669 --> 00:05:37,460
elasticsearch Klein gets initialized and

00:05:34,550 --> 00:05:40,400
reached the team DB data set which then

00:05:37,460 --> 00:05:43,039
gets indexed on to elasticsearch since

00:05:40,400 --> 00:05:45,800
this data set contains lot of records

00:05:43,039 --> 00:05:47,449
almost about 27,000 movies I'm not going

00:05:45,800 --> 00:05:52,039
to wait for the indexing to complete

00:05:47,449 --> 00:05:55,699
rather move on to the next step which is

00:05:52,039 --> 00:05:58,479
to train a model so training a model

00:05:55,699 --> 00:06:00,620
involves some helper methods like

00:05:58,479 --> 00:06:05,810
judgments taught by collect feature stop

00:06:00,620 --> 00:06:08,180
I and load features taught by so we also

00:06:05,810 --> 00:06:13,789
see here that a path gets created where

00:06:08,180 --> 00:06:17,659
features are stored in order to be used

00:06:13,789 --> 00:06:20,979
for our models and we go back and see if

00:06:17,659 --> 00:06:23,300
the indexing has been completed or not

00:06:20,979 --> 00:06:25,699
okay so indexing has been completed and

00:06:23,300 --> 00:06:27,889
we see that poison is the last movie to

00:06:25,699 --> 00:06:29,270
be indexed which is also the last thing

00:06:27,889 --> 00:06:36,729
to have in life if you ever choose to

00:06:29,270 --> 00:06:36,729
have it so yes we run the script

00:06:37,740 --> 00:06:44,520
and then move on to the Python script

00:06:41,010 --> 00:06:46,620
for train so this is a very important

00:06:44,520 --> 00:06:50,610
step because this involves training the

00:06:46,620 --> 00:06:52,740
module this starts off by connecting to

00:06:50,610 --> 00:06:55,410
elasticsearch and the very first step is

00:06:52,740 --> 00:06:57,870
to create an initial default feature

00:06:55,410 --> 00:07:06,900
store for the purpose of this demo we

00:06:57,870 --> 00:07:09,840
have identified certain features like

00:07:06,900 --> 00:07:12,650
title and overview we see here that

00:07:09,840 --> 00:07:18,180
these features are identified by

00:07:12,650 --> 00:07:20,940
ordinals so the main idea here is that

00:07:18,180 --> 00:07:23,220
the user defined key verse should match

00:07:20,940 --> 00:07:25,890
the title for a particular query which

00:07:23,220 --> 00:07:26,820
then becomes the feature score for this

00:07:25,890 --> 00:07:31,080
feature title

00:07:26,820 --> 00:07:34,290
similarly the overview match for this

00:07:31,080 --> 00:07:36,420
query becomes the feature score for the

00:07:34,290 --> 00:07:39,120
feature overview now a feature in

00:07:36,420 --> 00:07:44,220
elasticsearch is an elastic search query

00:07:39,120 --> 00:07:46,320
and it can be anything like say how old

00:07:44,220 --> 00:07:48,590
a movie is or anything that correlates

00:07:46,320 --> 00:07:51,780
to the user's sense of relevance and

00:07:48,590 --> 00:07:54,120
feature scores that I yielded here are

00:07:51,780 --> 00:08:00,840
then used for training and evaluating

00:07:54,120 --> 00:08:03,210
the module so we define a feature store

00:08:00,840 --> 00:08:05,340
here and then this is an empty feature

00:08:03,210 --> 00:08:07,320
store obviously and then the second step

00:08:05,340 --> 00:08:11,160
is to load these feature scores back

00:08:07,320 --> 00:08:14,910
into elastic search then comes the

00:08:11,160 --> 00:08:18,930
concept of judgments list so I show you

00:08:14,910 --> 00:08:21,090
what a judgments file looks like ok so

00:08:18,930 --> 00:08:24,240
this is a three tuple judgment list

00:08:21,090 --> 00:08:25,980
which actually tells us how relevant a

00:08:24,240 --> 00:08:29,220
document is with respect to a search

00:08:25,980 --> 00:08:34,110
query it transits of grades query ID and

00:08:29,220 --> 00:08:37,020
the query itself so we see here that the

00:08:34,110 --> 00:08:39,480
movie Rambo for query ID 1 which is

00:08:37,020 --> 00:08:41,730
Rambo receives a grade of 4 which means

00:08:39,480 --> 00:08:44,030
that the user found this movie to be

00:08:41,730 --> 00:08:46,650
extremely relevant for query Rambo

00:08:44,030 --> 00:08:50,860
similarly the movie first daughter

00:08:46,650 --> 00:08:53,350
receives a grade of 0 for the query RAM

00:08:50,860 --> 00:08:55,150
which means that the user found the

00:08:53,350 --> 00:08:57,760
first Auto movie to be not to be

00:08:55,150 --> 00:09:03,460
relevant at all for the query tampo and

00:08:57,760 --> 00:09:05,500
henceforth so we use this judgment a

00:09:03,460 --> 00:09:07,960
sample judgments dot txt file now in

00:09:05,500 --> 00:09:11,080
order for a ranch lab model to work it

00:09:07,960 --> 00:09:12,940
needs this judgment file along with the

00:09:11,080 --> 00:09:16,360
two more columns which have the feature

00:09:12,940 --> 00:09:24,100
score values which are extracted from

00:09:16,360 --> 00:09:26,770
the elasticsearch so we run this and we

00:09:24,100 --> 00:09:28,630
see here that the ranked clip this

00:09:26,770 --> 00:09:33,550
training is happening for each of these

00:09:28,630 --> 00:09:36,100
ten modules and train module simply uses

00:09:33,550 --> 00:09:38,950
the sample judgments with features file

00:09:36,100 --> 00:09:41,830
and the rank clip then generates a

00:09:38,950 --> 00:09:43,530
module and save model so the model

00:09:41,830 --> 00:09:45,880
generated from Lang clip is then

00:09:43,530 --> 00:09:51,690
uploaded into the model store of

00:09:45,880 --> 00:09:54,580
elasticsearch we learn this and see that

00:09:51,690 --> 00:09:58,600
each of the ten models are getting

00:09:54,580 --> 00:10:00,580
trained so while this takes some time we

00:09:58,600 --> 00:10:04,420
move on to the next script with which is

00:10:00,580 --> 00:10:07,930
actually acquiring acquiring the results

00:10:04,420 --> 00:10:10,600
and re ranking them on the basis of this

00:10:07,930 --> 00:10:12,400
trained model so we see that this is a

00:10:10,600 --> 00:10:15,850
simple elastic search query across the

00:10:12,400 --> 00:10:20,020
two fields title and overview and this

00:10:15,850 --> 00:10:22,780
is an important step here which we're LT

00:10:20,020 --> 00:10:25,840
our plugin comes into picture so this is

00:10:22,780 --> 00:10:28,090
actually d scoring or re-ranking or the

00:10:25,840 --> 00:10:31,000
second phase of ranking of the query

00:10:28,090 --> 00:10:37,540
results based on the parameters keywords

00:10:31,000 --> 00:10:39,430
and model we see if all the models have

00:10:37,540 --> 00:10:41,770
been trained and yes all the ten models

00:10:39,430 --> 00:10:47,730
have been trained we quickly see what

00:10:41,770 --> 00:10:53,260
one of the model files look like okay so

00:10:47,730 --> 00:10:55,600
this is for lambda mot model and we this

00:10:53,260 --> 00:10:57,550
is an XML format we see that the

00:10:55,600 --> 00:11:00,339
features core value for feature one

00:10:57,550 --> 00:11:04,030
which is title is ten point three six

00:11:00,339 --> 00:11:06,040
something and for feature two which for

00:11:04,030 --> 00:11:10,150
overview the feature score value is

00:11:06,040 --> 00:11:12,610
eleven point nine five okay so we run

00:11:10,150 --> 00:11:16,350
the Python script for search taught by

00:11:12,610 --> 00:11:19,540
and then we run the final query which is

00:11:16,350 --> 00:11:23,800
searching for Rambo query in the lambda

00:11:19,540 --> 00:11:26,970
math model and we see the order of the

00:11:23,800 --> 00:11:30,040
movies so this is the order in which the

00:11:26,970 --> 00:11:32,950
feature values of the movies have been

00:11:30,040 --> 00:11:34,720
read and of what the model thought

00:11:32,950 --> 00:11:36,550
should have been the best order so this

00:11:34,720 --> 00:11:40,060
pretty much covers the demo for

00:11:36,550 --> 00:11:41,620
elasticsearch then we move on to the

00:11:40,060 --> 00:11:45,010
learning to rank for solar

00:11:41,620 --> 00:11:46,960
so the LTR plugin for solar comes out of

00:11:45,010 --> 00:11:49,150
the box as a contrib modules which was

00:11:46,960 --> 00:11:51,010
initially provided by Bloomberg the

00:11:49,150 --> 00:11:52,990
basic concepts remain the same feature

00:11:51,010 --> 00:11:55,300
store model store and query D ranking

00:11:52,990 --> 00:11:58,350
and it supports libraries like libous

00:11:55,300 --> 00:12:02,020
feelable inia rank a partial because it

00:11:58,350 --> 00:12:04,750
supposed only few algorithms like lambda

00:12:02,020 --> 00:12:07,450
MOT being one of them and deep learning

00:12:04,750 --> 00:12:09,420
for J the support of which is going to

00:12:07,450 --> 00:12:14,110
come

00:12:09,420 --> 00:12:16,570
so the ltr' plugin for solar demo comes

00:12:14,110 --> 00:12:20,130
with tech products which you can find

00:12:16,570 --> 00:12:22,690
here you can go through this

00:12:20,130 --> 00:12:25,180
documentation but for the purpose of

00:12:22,690 --> 00:12:27,490
Apple to Apple comparison I have used

00:12:25,180 --> 00:12:31,360
the same tmdb data set which I used for

00:12:27,490 --> 00:12:33,850
elastic search so we'll go to insomnia

00:12:31,360 --> 00:12:39,580
rest client and the very first step is

00:12:33,850 --> 00:12:45,089
to create collection with shard 1 and

00:12:39,580 --> 00:12:50,670
the name of the collection is tmdb ok

00:12:45,089 --> 00:12:52,810
then we index all the data on to solar

00:12:50,670 --> 00:12:55,390
this again is going to take a while

00:12:52,810 --> 00:13:01,150
because it contains about 27,000 movies

00:12:55,390 --> 00:13:03,430
so while the indexing is happening I'll

00:13:01,150 --> 00:13:06,550
walk you through the next set of steps

00:13:03,430 --> 00:13:08,530
which involves enabling the LTR plugin

00:13:06,550 --> 00:13:10,900
so there are three main components for

00:13:08,530 --> 00:13:13,839
enabling the LTI plugin one is to add

00:13:10,900 --> 00:13:16,649
the ltr' query parser the second is to

00:13:13,839 --> 00:13:19,259
add feature cache feature cache is

00:13:16,649 --> 00:13:21,899
on top of the feature store which is

00:13:19,259 --> 00:13:24,480
used for caching features and the third

00:13:21,899 --> 00:13:26,279
step is to add LTI transformer now we

00:13:24,480 --> 00:13:33,809
see whether all the documents have been

00:13:26,279 --> 00:13:36,779
indexed okay so all the documents have

00:13:33,809 --> 00:13:41,009
been indexed here then we add the ltr'

00:13:36,779 --> 00:13:42,720
query parser add the feature cache we

00:13:41,009 --> 00:13:51,619
can also set the size for this feature

00:13:42,720 --> 00:14:00,779
value cache and at the LTR transformer

00:13:51,619 --> 00:14:03,089
now we add the features here so just

00:14:00,779 --> 00:14:04,980
like a feature in elastic search is an

00:14:03,089 --> 00:14:09,569
elastic search query feature and solar

00:14:04,980 --> 00:14:11,519
is a solar query so now we hit the query

00:14:09,569 --> 00:14:13,589
to extract features which is going to

00:14:11,519 --> 00:14:23,970
extract all the features core values

00:14:13,589 --> 00:14:26,999
from solar ok so we see that the value

00:14:23,970 --> 00:14:28,740
for the title feature is 12 point

00:14:26,999 --> 00:14:30,660
something and 10 point something for

00:14:28,740 --> 00:14:33,529
overview feature which is almost similar

00:14:30,660 --> 00:14:36,269
to what we saw in case of elastic search

00:14:33,529 --> 00:14:38,939
since the feature values scores are

00:14:36,269 --> 00:14:41,009
similar the models will also be similar

00:14:38,939 --> 00:14:43,259
hence I'm not going to retrain the model

00:14:41,009 --> 00:14:46,800
rather use the same model which was used

00:14:43,259 --> 00:14:49,370
in case of elastic search and I add the

00:14:46,800 --> 00:14:49,370
model here

00:14:56,830 --> 00:15:04,940
this takes about 23 seconds so we can

00:15:02,450 --> 00:15:07,550
add these feature value scores we can

00:15:04,940 --> 00:15:09,890
plug into the judgments list and hand it

00:15:07,550 --> 00:15:13,430
over to Tran clip to train and rank the

00:15:09,890 --> 00:15:16,370
model ok and then we run the final ltr'

00:15:13,430 --> 00:15:19,760
query for the strained model so the

00:15:16,370 --> 00:15:21,920
re-ranking scored so it uses the

00:15:19,760 --> 00:15:24,290
rehanging parameter with the default LCR

00:15:21,920 --> 00:15:27,800
model and it rewrites the top in

00:15:24,290 --> 00:15:30,320
documents which is 300 in this case the

00:15:27,800 --> 00:15:36,080
arirang stir query results and we see

00:15:30,320 --> 00:15:38,330
that the order is the same as what we

00:15:36,080 --> 00:15:42,620
saw in case of elastic search so this

00:15:38,330 --> 00:15:46,760
completes the demo for solar LCR and

00:15:42,620 --> 00:15:48,740
then we move on to Vespa so Vespa offers

00:15:46,760 --> 00:15:51,350
the first-class support for LTR basic

00:15:48,740 --> 00:15:56,950
concepts include tensors so like we saw

00:15:51,350 --> 00:15:59,300
that in elastic search or solar the

00:15:56,950 --> 00:16:02,050
feature value scores are scalar

00:15:59,300 --> 00:16:04,190
quantities in case of Vespa it can be

00:16:02,050 --> 00:16:07,910
multi-dimensional quantities as well

00:16:04,190 --> 00:16:09,980
which are called tensors so tensors can

00:16:07,910 --> 00:16:12,710
be anything ranging from scalars to

00:16:09,980 --> 00:16:14,870
matrices to higher dimensional values

00:16:12,710 --> 00:16:17,510
and then models of course and the first

00:16:14,870 --> 00:16:19,430
and second phase ranking expressions so

00:16:17,510 --> 00:16:21,050
second phase ranking is required on top

00:16:19,430 --> 00:16:24,470
of the native ranking to achieve better

00:16:21,050 --> 00:16:28,070
results then Vespa supports tensorflow

00:16:24,470 --> 00:16:30,400
library okay so we use real world data

00:16:28,070 --> 00:16:34,160
here from one of the panel competitions

00:16:30,400 --> 00:16:36,339
which handles the block-post about 1.1

00:16:34,160 --> 00:16:40,670
million blog posts are there and

00:16:36,339 --> 00:16:43,339
captures users preferences for lighting

00:16:40,670 --> 00:16:44,810
those blog posts you can always go to

00:16:43,339 --> 00:16:49,310
this documentation for further

00:16:44,810 --> 00:16:51,890
information so for the purpose of saving

00:16:49,310 --> 00:16:53,750
time and that the fact that I've got a

00:16:51,890 --> 00:16:54,260
very low handle laptop and the data set

00:16:53,750 --> 00:16:56,600
was huge

00:16:54,260 --> 00:17:02,030
I have pre-recorded the demos I'm going

00:16:56,600 --> 00:17:04,100
to run through them okay so I start off

00:17:02,030 --> 00:17:06,260
by starting vespa through a docker

00:17:04,100 --> 00:17:07,340
command which assigns 10 gigabytes of

00:17:06,260 --> 00:17:10,760
memory

00:17:07,340 --> 00:17:12,200
the application is huge so especial was

00:17:10,760 --> 00:17:13,700
already running in the background so I

00:17:12,200 --> 00:17:16,360
did not have to start it and then

00:17:13,700 --> 00:17:19,010
ensuring that Vespa has started properly

00:17:16,360 --> 00:17:20,930
the application status is 200 which is

00:17:19,010 --> 00:17:23,600
good and then the third step is to

00:17:20,930 --> 00:17:28,490
deploy the sample application now what

00:17:23,600 --> 00:17:31,070
is a sample application it consists of

00:17:28,490 --> 00:17:34,130
models Kweli profiles search definitions

00:17:31,070 --> 00:17:35,780
and a definition of which hosts the

00:17:34,130 --> 00:17:38,480
application will run on search

00:17:35,780 --> 00:17:40,730
definitions the schema of the

00:17:38,480 --> 00:17:48,260
collections the collections here are

00:17:40,730 --> 00:17:51,220
blog post and users now a document of

00:17:48,260 --> 00:17:54,500
type blog post has the following fields

00:17:51,220 --> 00:17:59,210
date in the gmt format language title

00:17:54,500 --> 00:18:03,740
author etc apart from this schema it

00:17:59,210 --> 00:18:05,060
also includes the ranking profiles first

00:18:03,740 --> 00:18:13,910
phase ranking and the second phase

00:18:05,060 --> 00:18:15,560
ranking okay then we see whether the

00:18:13,910 --> 00:18:18,470
sample application has been deployed or

00:18:15,560 --> 00:18:21,670
not so in other words whether the

00:18:18,470 --> 00:18:21,670
collections have been created

00:18:46,870 --> 00:18:52,020
I missed something okay

00:18:57,200 --> 00:19:04,270
okay then the next step is to split the

00:19:01,640 --> 00:19:07,850
data set in training and test data sets

00:19:04,270 --> 00:19:10,750
the test data sets comprises of about

00:19:07,850 --> 00:19:14,810
25% split whereas train data set

00:19:10,750 --> 00:19:17,840
comprises 75% of the split I have pre

00:19:14,810 --> 00:19:20,060
computed the data in the training and

00:19:17,840 --> 00:19:22,850
test data sets and also pre generated

00:19:20,060 --> 00:19:28,010
the ten cells for training so I did not

00:19:22,850 --> 00:19:29,390
have to run this again then the next

00:19:28,010 --> 00:19:36,740
step is to train a model using

00:19:29,390 --> 00:19:40,970
tensorflow library so training a model

00:19:36,740 --> 00:19:44,000
took about 20 hours of run time so I had

00:19:40,970 --> 00:19:49,820
to pre train this model and here we see

00:19:44,000 --> 00:19:52,880
the output of this trained model so the

00:19:49,820 --> 00:19:54,560
sample application comes shipped with

00:19:52,880 --> 00:19:58,130
this pre trained model so we don't even

00:19:54,560 --> 00:20:00,230
have to deploy it again then the next

00:19:58,130 --> 00:20:04,480
step is to index the blog posts and use

00:20:00,230 --> 00:20:04,480
a data into vespa using this big script

00:20:05,320 --> 00:20:15,560
okay so once the data has been indexed

00:20:10,430 --> 00:20:21,440
and the model has been deployed we now

00:20:15,560 --> 00:20:24,170
see them in action so first we run a

00:20:21,440 --> 00:20:26,270
query search for Pegasus we see here

00:20:24,170 --> 00:20:30,410
that the Vespa query format is very

00:20:26,270 --> 00:20:36,890
similar to SQL from sequel and is called

00:20:30,410 --> 00:20:42,620
YQL we run this query and see the titles

00:20:36,890 --> 00:20:46,670
or the interview they 1:02 etc now we

00:20:42,620 --> 00:20:50,360
run the same query but with the point of

00:20:46,670 --> 00:20:52,660
view of a logged in user for user ID

00:20:50,360 --> 00:20:52,660
this

00:20:55,830 --> 00:21:05,260
and see that the titles are different

00:21:00,010 --> 00:21:07,240
I do believe or whatever because these

00:21:05,260 --> 00:21:09,190
these results are more geared towards

00:21:07,240 --> 00:21:11,620
users interests hence we see a

00:21:09,190 --> 00:21:14,310
difference here so this pretty much

00:21:11,620 --> 00:21:17,350
covers the Vespa demo

00:21:14,310 --> 00:21:19,660
4ltr a quick example that comes to my

00:21:17,350 --> 00:21:22,830
mind which relates which is in relation

00:21:19,660 --> 00:21:27,280
to the Vespa demo is say for example

00:21:22,830 --> 00:21:29,850
user hits a query for Munich and the

00:21:27,280 --> 00:21:32,530
search engine comes up with results

00:21:29,850 --> 00:21:35,440
relating pertaining to Munich's weather

00:21:32,530 --> 00:21:38,650
or the buildings or whatever but say if

00:21:35,440 --> 00:21:41,470
the if that user wants to see is more

00:21:38,650 --> 00:21:43,900
interested in sports and specifically

00:21:41,470 --> 00:21:47,050
football then with the help of machine

00:21:43,900 --> 00:21:51,870
learning capabilities the search engine

00:21:47,050 --> 00:21:55,900
should show the results say some some

00:21:51,870 --> 00:21:58,690
football team in Munich so this is

00:21:55,900 --> 00:22:04,480
pretty much it yeah all right let's

00:21:58,690 --> 00:22:06,550
think the speaker take it I suggest to

00:22:04,480 --> 00:22:08,530
take the questions offline and we now

00:22:06,550 --> 00:22:11,020
conclude this first session of today and

00:22:08,530 --> 00:22:14,290
the Casa house and break for lunch lunch

00:22:11,020 --> 00:22:16,330
break is about an hour and taken I've

00:22:14,290 --> 00:22:19,870
just taken just next doors in the patio

00:22:16,330 --> 00:22:21,880
we reassemble here to or enjoy your

00:22:19,870 --> 00:22:23,140
lunch and see you later thank you thank

00:22:21,880 --> 00:22:27,880
you

00:22:23,140 --> 00:22:27,880

YouTube URL: https://www.youtube.com/watch?v=DyfkzOTFpDc


