Title: Berlin Buzzwords 2018: Nico Kruber â€“ Stateful Stream Processing with Apache Flink 1.5 and beyond
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	Nico Kruber talking about "Whats new in Stateful Stream Processing with Apache Flink 1.5 and beyond".

Come learn about the latest changes in Apache Flink 1.5 and how we made stateful stream processing more powerful, more expressive, and more flexible to support applications that were previously difficult to realize.

Apache Flink 1.5 is the biggest Flink release the community has ever published. Not only does it contain many enhancements for its APIs and libraries but it also comes with major improvements to three of its core components. We reworked the network stack and added a credit-based flow control mechanism which results in even better throughput/latency trade-offs and more efficient checkpoints. Fast local recovery helps to speed up the recovery of applications with large state. Finally, the redesign of Flink's distributed architecture makes Flink fit naturally onto Kubernetes, Yarn, Mesos, and standalone setups with support for resource elasticity.

Read more:
https://2018.berlinbuzzwords.de/18/session/whats-new-stateful-stream-processing-apache-flink-15-and-beyond

About Nico Kruber:
https://2018.berlinbuzzwords.de/users/nico-kruber

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:04,570 --> 00:00:14,860
hi there so let's get started a short a

00:00:12,250 --> 00:00:17,050
few notes about me and the dartisans

00:00:14,860 --> 00:00:19,779
it's a very special day for our artisans

00:00:17,050 --> 00:00:24,099
it was founded by the original creators

00:00:19,779 --> 00:00:25,899
of magic link and as it so happens they

00:00:24,099 --> 00:00:30,070
of today four years ago so it's a

00:00:25,899 --> 00:00:31,689
birthday and a bit younger is actually

00:00:30,070 --> 00:00:34,329
our first product which is the DA

00:00:31,689 --> 00:00:37,240
platform that was announced in September

00:00:34,329 --> 00:00:42,010
2017 and there's now generally available

00:00:37,240 --> 00:00:45,760
which eases the deployment of flink jobs

00:00:42,010 --> 00:00:50,500
and hold management of your application

00:00:45,760 --> 00:00:53,020
running on flink so what are we going to

00:00:50,500 --> 00:00:54,670
what I'm am I going to talk about today

00:00:53,020 --> 00:00:56,620
so first I'll give you brief

00:00:54,670 --> 00:00:59,739
introduction about what is Apache flink

00:00:56,620 --> 00:01:02,079
and then we head on to the recent

00:00:59,739 --> 00:01:05,649
changes to it which emerge in the

00:01:02,079 --> 00:01:09,760
release of Apache 1.5 just roughly two

00:01:05,649 --> 00:01:12,970
weeks ago and I give a brief outlook of

00:01:09,760 --> 00:01:15,880
what is in the in the stages as of now

00:01:12,970 --> 00:01:19,090
and will be in think one at six and

00:01:15,880 --> 00:01:23,740
afterwards so what is the patch you

00:01:19,090 --> 00:01:26,460
think in a nutshell I think allows you

00:01:23,740 --> 00:01:30,729
to do stateful computations over streams

00:01:26,460 --> 00:01:33,430
either real time or historic it is fast

00:01:30,729 --> 00:01:35,830
scalable falter and and in memory or not

00:01:33,430 --> 00:01:40,000
in memory but on disk if you need large

00:01:35,830 --> 00:01:41,890
state it supports event time also

00:01:40,000 --> 00:01:44,440
processing times the different notions

00:01:41,890 --> 00:01:47,850
of time that's rised with your

00:01:44,440 --> 00:01:51,010
applications it has at least once and

00:01:47,850 --> 00:01:54,750
exactly ones guarantees whatever you

00:01:51,010 --> 00:02:00,460
choose whatever you need for application

00:01:54,750 --> 00:02:03,700
and as for a chief link everything it

00:02:00,460 --> 00:02:05,860
sees is basically a stream so if you

00:02:03,700 --> 00:02:08,799
have a continuous streaming program or

00:02:05,860 --> 00:02:10,750
running application based on flink those

00:02:08,799 --> 00:02:13,419
will be basically unbounded streams can

00:02:10,750 --> 00:02:16,989
start in the past and go on into the

00:02:13,419 --> 00:02:17,980
future because you don't know when they

00:02:16,989 --> 00:02:21,819
were going well

00:02:17,980 --> 00:02:25,150
when they will end and it also processes

00:02:21,819 --> 00:02:27,250
batch processes in the same way so those

00:02:25,150 --> 00:02:30,299
streams will then be finished filling

00:02:27,250 --> 00:02:32,950
the applications and patches it could be

00:02:30,299 --> 00:02:34,360
that it's started in the past and ended

00:02:32,950 --> 00:02:36,970
in the past gives your processing

00:02:34,360 --> 00:02:38,560
historic data or it's not in the past

00:02:36,970 --> 00:02:40,560
extends into the future but it will end

00:02:38,560 --> 00:02:46,030
it sometime but for flink itself

00:02:40,560 --> 00:02:48,040
everything is a stream if you want to

00:02:46,030 --> 00:02:50,349
use it you basically have different

00:02:48,040 --> 00:02:52,930
abstractions that you can use so it's

00:02:50,349 --> 00:02:56,019
kind of a layer so in the middle there's

00:02:52,930 --> 00:02:58,060
the data stream a data set API which is

00:02:56,019 --> 00:02:59,950
useful for stream and batch data

00:02:58,060 --> 00:03:01,900
processing this gives you access to

00:02:59,950 --> 00:03:04,810
streams to Windows some aggregations

00:03:01,900 --> 00:03:07,569
like in this example you have some

00:03:04,810 --> 00:03:08,680
stream that comes from sensors you group

00:03:07,569 --> 00:03:11,410
by those sensors and you want to

00:03:08,680 --> 00:03:16,150
aggregate certain data from those

00:03:11,410 --> 00:03:18,160
sensors in Windows below that API you

00:03:16,150 --> 00:03:21,640
have more fine-grained control with the

00:03:18,160 --> 00:03:24,849
process functions there you have access

00:03:21,640 --> 00:03:27,790
to the events themselves to state all

00:03:24,849 --> 00:03:30,910
the individual operators to time

00:03:27,790 --> 00:03:33,250
different notions of time to water marks

00:03:30,910 --> 00:03:34,329
so this is what you would use to

00:03:33,250 --> 00:03:37,419
implement a stateful

00:03:34,329 --> 00:03:40,510
event-driven application it gives you

00:03:37,419 --> 00:03:44,530
more fine-grained control and there's a

00:03:40,510 --> 00:03:46,569
high level abstraction which basically

00:03:44,530 --> 00:03:48,910
eases the entry level into stream

00:03:46,569 --> 00:03:53,139
processing so there's a stream sequel

00:03:48,910 --> 00:03:56,400
and a table API that basically allows

00:03:53,139 --> 00:03:59,139
data analysts to write sequel queries

00:03:56,400 --> 00:04:02,169
that will then be translated into stream

00:03:59,139 --> 00:04:03,819
processing program and run on Finken so

00:04:02,169 --> 00:04:06,780
give some examples for those individual

00:04:03,819 --> 00:04:09,069
levels so in the data stream API you

00:04:06,780 --> 00:04:11,129
always start from sources this is where

00:04:09,069 --> 00:04:13,139
your data comes from we events come from

00:04:11,129 --> 00:04:15,250
then you do some transformations

00:04:13,139 --> 00:04:19,090
everything that you want to need to do I

00:04:15,250 --> 00:04:20,979
want to need to do like assuming your

00:04:19,090 --> 00:04:22,930
source only had strings you might want

00:04:20,979 --> 00:04:25,090
to parse them into some real objects

00:04:22,930 --> 00:04:29,050
that you will work on later so this will

00:04:25,090 --> 00:04:32,790
be a transformation then you like in his

00:04:29,050 --> 00:04:35,800
example before group this by

00:04:32,790 --> 00:04:39,640
in this example the sensor you have

00:04:35,800 --> 00:04:41,790
access to Windows you do sum over over

00:04:39,640 --> 00:04:44,890
the this window and so this will be

00:04:41,790 --> 00:04:48,130
Windows where the window itself will

00:04:44,890 --> 00:04:50,440
accumulate state and aggregate this with

00:04:48,130 --> 00:04:52,900
the function given and everything will

00:04:50,440 --> 00:04:54,640
end up in a sink so stream processing

00:04:52,900 --> 00:04:56,670
program is always from the sources to

00:04:54,640 --> 00:04:59,500
the sink and I think you can write to

00:04:56,670 --> 00:05:01,840
the sources like certain sources you

00:04:59,500 --> 00:05:04,150
would read for example from Kafka or any

00:05:01,840 --> 00:05:06,340
other source then idiot transformations

00:05:04,150 --> 00:05:08,800
inside flink and the sink will either

00:05:06,340 --> 00:05:12,160
write it back to some sort of some

00:05:08,800 --> 00:05:15,370
destination also be Kafka or files or s3

00:05:12,160 --> 00:05:18,820
or you could actually talk to to another

00:05:15,370 --> 00:05:20,290
service that is running at the low level

00:05:18,820 --> 00:05:22,360
you would have the the process

00:05:20,290 --> 00:05:25,000
functional core process function where

00:05:22,360 --> 00:05:27,070
in this example you could join two

00:05:25,000 --> 00:05:29,440
different streams together you would

00:05:27,070 --> 00:05:32,530
have to implement this in either Java or

00:05:29,440 --> 00:05:35,140
Scala and you get access to to every

00:05:32,530 --> 00:05:37,600
detail in those events in the context

00:05:35,140 --> 00:05:40,840
from from flink so watermarks for time

00:05:37,600 --> 00:05:42,700
the time itself what time is it and you

00:05:40,840 --> 00:05:44,350
are able to register timers so you have

00:05:42,700 --> 00:05:46,360
very fine grained control over what you

00:05:44,350 --> 00:05:47,760
want to do but you need to know what

00:05:46,360 --> 00:05:50,740
you're doing

00:05:47,760 --> 00:05:54,400
and on higher level this equal it's

00:05:50,740 --> 00:05:56,560
almost then it's equal except for that

00:05:54,400 --> 00:05:58,180
the tables are not fixed but those are

00:05:56,560 --> 00:06:00,040
dynamic tables because you work on a

00:05:58,180 --> 00:06:05,860
stream you don't know when the stream

00:06:00,040 --> 00:06:09,010
will end and it's basically almost anti

00:06:05,860 --> 00:06:14,260
sequel with some extensions like windows

00:06:09,010 --> 00:06:17,020
in this case a tumbling window but you

00:06:14,260 --> 00:06:18,490
also have access to not only due to time

00:06:17,020 --> 00:06:20,380
different time notions because the

00:06:18,490 --> 00:06:24,460
windows your processing time or even

00:06:20,380 --> 00:06:27,820
event time so how large or small can

00:06:24,460 --> 00:06:30,100
fling get well arguably the the biggest

00:06:27,820 --> 00:06:33,460
user of link is Alibaba

00:06:30,100 --> 00:06:36,190
they use fling to sort of power parts of

00:06:33,460 --> 00:06:38,890
their system during the this really

00:06:36,190 --> 00:06:41,770
crazy shopping day the singles day at

00:06:38,890 --> 00:06:43,789
the 11th of November there at peak we

00:06:41,770 --> 00:06:46,829
have roughly

00:06:43,789 --> 00:06:51,119
470 million records per second that is

00:06:46,829 --> 00:06:52,829
processed through link link is there for

00:06:51,119 --> 00:06:55,259
cuff link with her which has a few

00:06:52,829 --> 00:06:57,809
patches on top of it but they're slowly

00:06:55,259 --> 00:06:59,249
or they're continuously contributing

00:06:57,809 --> 00:07:00,749
back to things so the difference is

00:06:59,249 --> 00:07:06,559
getting less and less between blink and

00:07:00,749 --> 00:07:09,119
blink so at the in terms of the jobs

00:07:06,559 --> 00:07:11,579
there thousands of different jobs

00:07:09,119 --> 00:07:15,449
running they run very large classes of

00:07:11,579 --> 00:07:19,579
over 5,000 nodes with 500,000 CPU cores

00:07:15,449 --> 00:07:22,169
so this is really big and the second

00:07:19,579 --> 00:07:24,029
example is Netflix their routing

00:07:22,169 --> 00:07:26,369
pipeline goes through flink and they

00:07:24,029 --> 00:07:28,559
have also there was a very big user with

00:07:26,369 --> 00:07:32,579
around three trillion events per day

00:07:28,559 --> 00:07:36,959
over 2,000 jobs lots of containers lots

00:07:32,579 --> 00:07:39,239
of parallel operators but if link

00:07:36,959 --> 00:07:41,369
doesn't have to be big it can can run in

00:07:39,239 --> 00:07:43,019
a single process you could run it on

00:07:41,369 --> 00:07:44,339
your machine you will not get a highly

00:07:43,019 --> 00:07:46,679
availability of course because it's a

00:07:44,339 --> 00:07:48,479
single machine but it does run there as

00:07:46,679 --> 00:07:51,269
well some users also use it on IOT

00:07:48,479 --> 00:08:00,209
gateways and for debugging it's also

00:07:51,269 --> 00:08:03,689
very useful to run in your IDE so let's

00:08:00,209 --> 00:08:07,379
go to to the changes for fleeing

00:08:03,689 --> 00:08:09,569
one-five first of all fling Kani 1/5 in

00:08:07,379 --> 00:08:13,049
numbers it's been roughly 5 months of

00:08:09,569 --> 00:08:16,409
work where 106 contributors added code

00:08:13,049 --> 00:08:19,849
to flink within over 1500 commits there

00:08:16,409 --> 00:08:23,669
were almost 800 JIRA issues resolved and

00:08:19,849 --> 00:08:25,439
a lot of changes in the codes one of the

00:08:23,669 --> 00:08:27,929
biggest ones is the changes and

00:08:25,439 --> 00:08:30,659
deployment and process model so this is

00:08:27,929 --> 00:08:35,039
not only big one in terms of code but

00:08:30,659 --> 00:08:38,069
also on what enables us to do now and in

00:08:35,039 --> 00:08:41,159
the future so what are different sizes

00:08:38,069 --> 00:08:44,069
that we can use and if you want to use

00:08:41,159 --> 00:08:46,829
flink there tons of different deployment

00:08:44,069 --> 00:08:49,920
scenarios one of the common ones is to

00:08:46,829 --> 00:08:52,290
run it on yarn you can also use me sauce

00:08:49,920 --> 00:08:55,190
you could use docker and cube inators

00:08:52,290 --> 00:08:59,720
you can setup flink standalone meaning

00:08:55,190 --> 00:09:01,280
um- on your machines themselves and so

00:08:59,720 --> 00:09:03,620
on and so on did so many different

00:09:01,280 --> 00:09:06,410
scenarios and on top of that there are

00:09:03,620 --> 00:09:09,380
different usage patterns you could have

00:09:06,410 --> 00:09:11,690
a few but very long running programs or

00:09:09,380 --> 00:09:14,900
you can have many short running programs

00:09:11,690 --> 00:09:16,610
and you want to have a different mode

00:09:14,900 --> 00:09:18,800
for the two of them because there's some

00:09:16,610 --> 00:09:20,720
of it of starting a new cluster so

00:09:18,800 --> 00:09:23,120
there's job isolation wasn't sharing

00:09:20,720 --> 00:09:27,290
resources if you have a few long-running

00:09:23,120 --> 00:09:29,180
jobs you might want to have those have

00:09:27,290 --> 00:09:30,890
those separate from each other but if

00:09:29,180 --> 00:09:33,260
you have many short running jobs you

00:09:30,890 --> 00:09:34,850
might want to have a big cluster that is

00:09:33,260 --> 00:09:36,500
shared among those jobs so you don't

00:09:34,850 --> 00:09:42,650
need to restart the cluster all over

00:09:36,500 --> 00:09:45,260
again for every small job and you want

00:09:42,650 --> 00:09:47,900
you if you have a single cluster you can

00:09:45,260 --> 00:09:50,690
also share resources so not every small

00:09:47,900 --> 00:09:55,760
job will use the whole cluster so there

00:09:50,690 --> 00:09:58,370
you would go for the the sharing part

00:09:55,760 --> 00:10:00,380
which will be either a session mode that

00:09:58,370 --> 00:10:03,080
basically sets up a fling cluster

00:10:00,380 --> 00:10:05,600
without a job and then you can submit

00:10:03,080 --> 00:10:08,720
jobs into it so it's a cluster for

00:10:05,600 --> 00:10:11,390
multiple jobs the resources the compute

00:10:08,720 --> 00:10:17,570
power can be shared across those jobs

00:10:11,390 --> 00:10:19,670
and as I said it's a separate thing to

00:10:17,570 --> 00:10:21,830
deploy the cluster and to submit your

00:10:19,670 --> 00:10:23,810
jobs to it and then there's job mode

00:10:21,830 --> 00:10:27,050
which will basically set up a fling

00:10:23,810 --> 00:10:31,070
cluster for each job that you want this

00:10:27,050 --> 00:10:37,280
is the best thing if you want separation

00:10:31,070 --> 00:10:39,680
between the jobs so those changes in the

00:10:37,280 --> 00:10:42,080
deployment model have been introduced

00:10:39,680 --> 00:10:44,089
and in the flink improvement proposal

00:10:42,080 --> 00:10:45,380
six this has been around for quite a

00:10:44,089 --> 00:10:48,190
while it has been worked on and

00:10:45,380 --> 00:10:51,140
initiated by Alibaba and Tata artisans

00:10:48,190 --> 00:10:55,910
it introduces generic building blocks so

00:10:51,140 --> 00:10:57,440
that we are able to create blocks for

00:10:55,910 --> 00:11:01,970
all the different scenarios that were

00:10:57,440 --> 00:11:05,089
mentioned before and we go into details

00:11:01,970 --> 00:11:07,460
a bit more so those building blocks to

00:11:05,089 --> 00:11:08,450
start basically you have one resource

00:11:07,460 --> 00:11:10,250
manager there

00:11:08,450 --> 00:11:11,810
is cluster manager specific so you have

00:11:10,250 --> 00:11:14,570
one for yarn you have one for me sauce

00:11:11,810 --> 00:11:17,780
you would have one for community etc etc

00:11:14,570 --> 00:11:20,270
and for standalone this one may live

00:11:17,780 --> 00:11:22,310
across jobs and manages the available

00:11:20,270 --> 00:11:23,990
containers and task managers so task

00:11:22,310 --> 00:11:26,650
managers are they basically work Rosberg

00:11:23,990 --> 00:11:28,790
will come to this resource managers

00:11:26,650 --> 00:11:31,100
responsibility is to acquire and release

00:11:28,790 --> 00:11:33,680
resources and then there's the

00:11:31,100 --> 00:11:36,770
dispatcher this also lives across jobs

00:11:33,680 --> 00:11:38,690
and is the the touch point for job

00:11:36,770 --> 00:11:40,640
submissions if you have your CLI

00:11:38,690 --> 00:11:42,860
somewhere and want to submit a job you

00:11:40,640 --> 00:11:46,700
will go through the dispatcher and this

00:11:42,860 --> 00:11:50,480
spawns job managers which exists now

00:11:46,700 --> 00:11:54,310
only for a single job we go to the

00:11:50,480 --> 00:11:54,310
interactions between those in a minute

00:11:56,860 --> 00:12:04,670
this is where it is so from the client

00:12:01,190 --> 00:12:08,810
this can be the web UI or most commonly

00:12:04,670 --> 00:12:11,060
the CI you would submit the job to watch

00:12:08,810 --> 00:12:12,770
the dispatcher the dispatcher will then

00:12:11,060 --> 00:12:15,590
start a job manager for this specific

00:12:12,770 --> 00:12:17,690
job and well the job manager will talk

00:12:15,590 --> 00:12:21,380
to the resource manager to ask for slots

00:12:17,690 --> 00:12:23,240
says well give me this program specifies

00:12:21,380 --> 00:12:25,910
parallelism of 20 give me 20 slots to

00:12:23,240 --> 00:12:29,990
run this on so the resource manager will

00:12:25,910 --> 00:12:31,940
talk to yarn me sores etc to spawn task

00:12:29,990 --> 00:12:33,350
managers those times managers when they

00:12:31,940 --> 00:12:35,960
start up they register with the resource

00:12:33,350 --> 00:12:39,620
manager and eventually the job manager

00:12:35,960 --> 00:12:43,130
can deploy the tasks on those task

00:12:39,620 --> 00:12:46,040
managers so in yarn this is what it

00:12:43,130 --> 00:12:48,260
looks like you you tell the yarn

00:12:46,040 --> 00:12:50,240
resource manager to spawn the

00:12:48,260 --> 00:12:51,770
application master which will contain a

00:12:50,240 --> 00:12:58,610
dispatcher and the resource manager

00:12:51,770 --> 00:13:01,760
specific to John this is basically what

00:12:58,610 --> 00:13:03,230
I showed before and me so this will be

00:13:01,760 --> 00:13:06,340
quite similar so those building blocks

00:13:03,230 --> 00:13:09,980
are very generic and interchangeable

00:13:06,340 --> 00:13:12,980
where they need to be so this is the per

00:13:09,980 --> 00:13:15,500
job mode so what are the difference to

00:13:12,980 --> 00:13:17,540
the situation that has been there before

00:13:15,500 --> 00:13:20,060
now the jars are in a class part of all

00:13:17,540 --> 00:13:22,220
components this reduces class loading

00:13:20,060 --> 00:13:23,720
issues that's one point

00:13:22,220 --> 00:13:25,460
the second and maybe even bigger point

00:13:23,720 --> 00:13:27,560
is that we have dynamic resource

00:13:25,460 --> 00:13:30,110
allocation so we no longer need to

00:13:27,560 --> 00:13:32,150
specify how many containers we need to

00:13:30,110 --> 00:13:36,680
run during startup you say your job is

00:13:32,150 --> 00:13:39,860
parallelism 20 and it will ask for this

00:13:36,680 --> 00:13:41,800
many task managers and then there's no

00:13:39,860 --> 00:13:47,660
to face certain job submission anymore

00:13:41,800 --> 00:13:49,190
so in there before you basically spawned

00:13:47,660 --> 00:13:50,690
everything and needed to Paul and Paul

00:13:49,190 --> 00:13:52,250
and ask it what is the cluster running

00:13:50,690 --> 00:13:54,080
is that running is it running and then

00:13:52,250 --> 00:13:56,030
submit your job this was working behind

00:13:54,080 --> 00:13:59,120
the scenes but nevertheless was

00:13:56,030 --> 00:14:01,880
error-prone and for the session mode

00:13:59,120 --> 00:14:04,340
it's not too much different in the CLI

00:14:01,880 --> 00:14:05,840
you would start your cluster this is the

00:14:04,340 --> 00:14:09,410
one time thing you start your session

00:14:05,840 --> 00:14:11,120
cluster this will spawn an application

00:14:09,410 --> 00:14:13,310
master consisting of the resource

00:14:11,120 --> 00:14:15,680
manager and dispatcher and whenever you

00:14:13,310 --> 00:14:18,440
submit a job like step three years of

00:14:15,680 --> 00:14:19,850
mid job a you talk to the dispatcher it

00:14:18,440 --> 00:14:22,220
will start the job manager for this

00:14:19,850 --> 00:14:24,410
particular job and ask the resource

00:14:22,220 --> 00:14:26,960
manager for resources this will organize

00:14:24,410 --> 00:14:30,230
and start task managers which register

00:14:26,960 --> 00:14:31,910
with results manager and tell the job

00:14:30,230 --> 00:14:34,970
manager well I'm here

00:14:31,910 --> 00:14:36,710
give me some work and whenever you

00:14:34,970 --> 00:14:38,210
submit a new job this will also go

00:14:36,710 --> 00:14:39,680
through this through the dispatcher it

00:14:38,210 --> 00:14:47,630
will start a separate job manager and

00:14:39,680 --> 00:14:49,340
the same process will happen again so to

00:14:47,630 --> 00:14:52,280
wrap up this part of the deployment

00:14:49,340 --> 00:14:54,140
changes we have a new distributed

00:14:52,280 --> 00:14:55,730
architecture there the last thing to

00:14:54,140 --> 00:14:58,880
support many different deployment

00:14:55,730 --> 00:15:00,770
scenarios as shown we now also have a

00:14:58,880 --> 00:15:02,720
native job mode as well as a session

00:15:00,770 --> 00:15:07,010
road before the session mode was kind of

00:15:02,720 --> 00:15:09,950
a heckie heckie thing and the biggest

00:15:07,010 --> 00:15:13,610
change will be that we now have full

00:15:09,950 --> 00:15:18,140
resource elasticity so that's one step

00:15:13,610 --> 00:15:21,470
towards having dynamic scaling and also

00:15:18,140 --> 00:15:23,960
very nice to have now every call to the

00:15:21,470 --> 00:15:27,470
job manager every job submission etc is

00:15:23,960 --> 00:15:30,140
going through rest see you can have your

00:15:27,470 --> 00:15:32,510
own clients talk to two flink

00:15:30,140 --> 00:15:35,870
it does not go through akka anymore but

00:15:32,510 --> 00:15:40,430
you can have basically a standard rest

00:15:35,870 --> 00:15:45,710
Galt's towards it so that's it for the

00:15:40,430 --> 00:15:48,140
deployment changes the second part will

00:15:45,710 --> 00:15:51,790
be around broadcast state which extends

00:15:48,140 --> 00:15:54,920
the the use cases for flings so imagine

00:15:51,790 --> 00:15:57,170
you have some kid streams where the

00:15:54,920 --> 00:15:59,000
events come through and you want to

00:15:57,170 --> 00:16:00,529
match them against the common rules the

00:15:59,000 --> 00:16:02,260
common set of rules that should be

00:16:00,529 --> 00:16:05,480
available to every parallel instance

00:16:02,260 --> 00:16:08,870
this was not easily possible for you you

00:16:05,480 --> 00:16:11,390
could not combine a non-key stream with

00:16:08,870 --> 00:16:14,990
a keyed stream so this is web broadcast

00:16:11,390 --> 00:16:19,420
it comes in to go into an example you

00:16:14,990 --> 00:16:23,450
want to match stream a with some shapes

00:16:19,420 --> 00:16:26,960
against another stream of rules so here

00:16:23,450 --> 00:16:29,839
you want to match objects of the same

00:16:26,960 --> 00:16:33,140
color with shapes in a particular order

00:16:29,839 --> 00:16:34,670
for example the the square first event

00:16:33,140 --> 00:16:37,040
should be square second event should be

00:16:34,670 --> 00:16:40,120
a triangle so what you would do you

00:16:37,040 --> 00:16:42,410
would create a key by first on the color

00:16:40,120 --> 00:16:44,060
those will be stored into key to say

00:16:42,410 --> 00:16:47,660
that each parallel instance in here like

00:16:44,060 --> 00:16:49,100
three imperil instances and then you

00:16:47,660 --> 00:16:51,529
wouldn't need the rules the rules will

00:16:49,100 --> 00:16:54,770
need to be spirited to all of the notes

00:16:51,529 --> 00:16:58,940
so they will be broadcasted they must be

00:16:54,770 --> 00:17:01,400
stored there as well and this will go

00:16:58,940 --> 00:17:03,170
into broadcast 8 then you would need to

00:17:01,400 --> 00:17:05,390
connect those two you would say okay

00:17:03,170 --> 00:17:08,510
this keyed stream works with this

00:17:05,390 --> 00:17:10,610
broadcast 8 and whenever a new event

00:17:08,510 --> 00:17:14,630
comes in like here for the first notes

00:17:10,610 --> 00:17:15,709
we have the square is already stored we

00:17:14,630 --> 00:17:17,420
have the rule that we're waiting for

00:17:15,709 --> 00:17:19,220
square and then triangle and the

00:17:17,420 --> 00:17:21,079
triangle comes in it will then be

00:17:19,220 --> 00:17:22,490
matched based on this you can access the

00:17:21,079 --> 00:17:25,250
broadcast at state you can access the

00:17:22,490 --> 00:17:27,770
rules and then you can work on it

00:17:25,250 --> 00:17:30,230
and with this like what you could do

00:17:27,770 --> 00:17:32,900
before is to have a static set of rules

00:17:30,230 --> 00:17:35,210
you would add this to a program this

00:17:32,900 --> 00:17:37,100
will be fixed and that's it but what if

00:17:35,210 --> 00:17:38,990
you want to change what if in the next

00:17:37,100 --> 00:17:40,480
iteration you want to have a look at

00:17:38,990 --> 00:17:44,390
something different

00:17:40,480 --> 00:17:45,800
think about fraud detection you might

00:17:44,390 --> 00:17:48,560
want to change your rules and not

00:17:45,800 --> 00:17:51,330
redeploy your job so this is where the

00:17:48,560 --> 00:17:53,890
broadcast state comes in

00:17:51,330 --> 00:17:55,480
so I won't go into details for the API

00:17:53,890 --> 00:17:58,960
this is what the documentation is for

00:17:55,480 --> 00:18:03,730
it's good for but basically what we have

00:17:58,960 --> 00:18:06,909
we can have a heat stream or an on

00:18:03,730 --> 00:18:08,380
Keith's stream that we can connect to a

00:18:06,909 --> 00:18:13,659
broadcast and stream

00:18:08,380 --> 00:18:18,010
so this broadcast stream is non Keats

00:18:13,659 --> 00:18:20,950
it is replicated onto all all threaded

00:18:18,010 --> 00:18:23,320
instances and it's identical on all

00:18:20,950 --> 00:18:24,580
tasks even after restoring after

00:18:23,320 --> 00:18:27,490
rescaling flings takes care of

00:18:24,580 --> 00:18:28,929
everything takes care of this and you

00:18:27,490 --> 00:18:31,029
need the ability to connect those two

00:18:28,929 --> 00:18:35,380
streams to say okay this ki donkeys

00:18:31,029 --> 00:18:39,399
stream uses this broadcast gene and this

00:18:35,380 --> 00:18:42,309
is used so that in the processing of the

00:18:39,399 --> 00:18:46,510
kids tree market stream you know and you

00:18:42,309 --> 00:18:48,940
have access to this broadcast all right

00:18:46,510 --> 00:18:50,620
let's go to the next part there have

00:18:48,940 --> 00:18:54,039
been some big changes in the network

00:18:50,620 --> 00:18:56,950
stick that we're introduced in 1 5 so

00:18:54,039 --> 00:19:01,210
what fling basically offers you on a lot

00:18:56,950 --> 00:19:04,179
on a logical point of view is if you

00:19:01,210 --> 00:19:06,549
have a subtask one subtask 2 and those

00:19:04,179 --> 00:19:09,669
are connected with a the key buyer with

00:19:06,549 --> 00:19:12,730
a shuffle with satis 3 and 4 it

00:19:09,669 --> 00:19:16,360
logically says there's a separate stream

00:19:12,730 --> 00:19:20,380
between task 1 and 3 task 1 and 4 and

00:19:16,360 --> 00:19:22,419
also task 2 and 3 & 2 & 4 this is an

00:19:20,380 --> 00:19:25,720
abstraction over different things

00:19:22,419 --> 00:19:27,940
so first the sub has outputs every

00:19:25,720 --> 00:19:30,070
outgoing stream can be either pipeline

00:19:27,940 --> 00:19:33,250
then bounded it can be pipelined and

00:19:30,070 --> 00:19:34,419
unbounded it can also be blocking then

00:19:33,250 --> 00:19:37,960
there could be different scheduling

00:19:34,419 --> 00:19:39,730
types all those four subtasks could be

00:19:37,960 --> 00:19:42,940
scheduled at once

00:19:39,730 --> 00:19:45,100
task 3 and 4 could be scheduled when 1 &

00:19:42,940 --> 00:19:47,799
2 are complete or they could start

00:19:45,100 --> 00:19:51,100
already when the first event from 1 & 2

00:19:47,799 --> 00:19:55,330
comes in and then at different methods

00:19:51,100 --> 00:19:58,029
of sending the data through you can have

00:19:55,330 --> 00:19:59,980
high throughput by buffering some events

00:19:58,029 --> 00:20:03,309
and then sending bigger chunks of data

00:19:59,980 --> 00:20:03,890
if your events are small or you can have

00:20:03,309 --> 00:20:05,930
low latency

00:20:03,890 --> 00:20:11,630
immediately sending even small got

00:20:05,930 --> 00:20:14,440
around so this logical separation makes

00:20:11,630 --> 00:20:17,060
a lot of sense but under the hood it's

00:20:14,440 --> 00:20:18,500
not that we have a separate channel for

00:20:17,060 --> 00:20:20,810
each of those communications this will

00:20:18,500 --> 00:20:23,150
be way too costly so what we do have if

00:20:20,810 --> 00:20:25,250
there is one task manager with two

00:20:23,150 --> 00:20:28,300
parallel instances slate subtask 1 & 2

00:20:25,250 --> 00:20:30,890
work on the same task manager and

00:20:28,300 --> 00:20:33,770
sometimes 3 & 4 work on a different task

00:20:30,890 --> 00:20:34,870
manager but also the same like such

00:20:33,770 --> 00:20:37,040
manager 1 & 2

00:20:34,870 --> 00:20:41,240
then all the communication that goes

00:20:37,040 --> 00:20:45,800
from task manager 1 2002 goes through a

00:20:41,240 --> 00:20:49,370
single TCP connection so even if

00:20:45,800 --> 00:20:51,170
suppressive subtask 1 & 2 will not have

00:20:49,370 --> 00:20:54,200
separate connections to the task manager

00:20:51,170 --> 00:20:56,090
2 so we have a single connection in

00:20:54,200 --> 00:20:58,070
there and all the events that come

00:20:56,090 --> 00:21:01,670
through the the queues will be

00:20:58,070 --> 00:21:04,180
multiplexed into this connection so what

00:21:01,670 --> 00:21:04,180
happens there

00:21:04,960 --> 00:21:11,060
in this scenario let's say there is an

00:21:07,670 --> 00:21:12,500
input input queue on sub task 4 and this

00:21:11,060 --> 00:21:14,090
has been kind of slow because it does a

00:21:12,500 --> 00:21:16,940
lot of computation or something so

00:21:14,090 --> 00:21:18,830
buffers pile up on this end and we now

00:21:16,940 --> 00:21:21,350
have a blue event also coming in for

00:21:18,830 --> 00:21:24,650
this task but sub tasks for cannot

00:21:21,350 --> 00:21:27,530
really accept this it is full it doesn't

00:21:24,650 --> 00:21:28,880
have capacity for this so there's an

00:21:27,530 --> 00:21:34,670
event in the pipeline that we cannot

00:21:28,880 --> 00:21:37,220
handle and the other sub tasks like

00:21:34,670 --> 00:21:39,880
three will process it events at some

00:21:37,220 --> 00:21:46,190
point it will have no input data anymore

00:21:39,880 --> 00:21:48,020
and this one single event in that TCP

00:21:46,190 --> 00:21:50,090
connection is blocking the whole

00:21:48,020 --> 00:21:51,890
pipeline because this does not get

00:21:50,090 --> 00:21:54,230
through the next ones also don't get

00:21:51,890 --> 00:21:55,970
through so sub task 3 will be idle it

00:21:54,230 --> 00:22:00,470
will not do anything because the surplus

00:21:55,970 --> 00:22:02,870
for was low and so is a single

00:22:00,470 --> 00:22:07,010
connection there it can block all of the

00:22:02,870 --> 00:22:09,380
connections which was a severe downside

00:22:07,010 --> 00:22:12,220
and performance in this regard so what

00:22:09,380 --> 00:22:15,050
we introduced with 1.5 that was also

00:22:12,220 --> 00:22:17,920
joint work with Alibaba

00:22:15,050 --> 00:22:19,280
we added credit based flow control a

00:22:17,920 --> 00:22:23,620
receiver

00:22:19,280 --> 00:22:26,450
first of all tries to get resources to

00:22:23,620 --> 00:22:28,760
process data once it has acquired those

00:22:26,450 --> 00:22:32,390
resources it will assign credit to the

00:22:28,760 --> 00:22:36,410
sender's let's say receiver says okay I

00:22:32,390 --> 00:22:38,660
need two buffers to get an to fill it

00:22:36,410 --> 00:22:41,030
with data from the sender so it asks for

00:22:38,660 --> 00:22:45,410
two buffers once it has them it assigns

00:22:41,030 --> 00:22:47,240
to it sends two to the sender and send

00:22:45,410 --> 00:22:49,190
it the sender now knows okay

00:22:47,240 --> 00:22:53,780
the receiver has two buffers available I

00:22:49,190 --> 00:22:55,730
can send it to buffers and they will not

00:22:53,780 --> 00:22:57,500
be blocked on the channel once the

00:22:55,730 --> 00:22:59,600
sender is sent and had put has put data

00:22:57,500 --> 00:23:02,540
onto the communication onto the TCP

00:22:59,600 --> 00:23:04,250
channel it will not be blocked there at

00:23:02,540 --> 00:23:10,850
any time because we know the receiver

00:23:04,250 --> 00:23:14,750
has the capacity to do so and this gives

00:23:10,850 --> 00:23:17,210
significant improvements on first

00:23:14,750 --> 00:23:18,800
performance and second on a non

00:23:17,210 --> 00:23:21,470
checkpoints as well because if we look

00:23:18,800 --> 00:23:24,730
back at this point the events that might

00:23:21,470 --> 00:23:28,220
be in the TCP connection cannot only be

00:23:24,730 --> 00:23:33,320
events from the user but also checkpoint

00:23:28,220 --> 00:23:35,929
barriers so those will be small data

00:23:33,320 --> 00:23:37,880
chunks that we sent through indicating

00:23:35,929 --> 00:23:43,760
that the tasks need to check on their

00:23:37,880 --> 00:23:47,360
state and as you can see in a very

00:23:43,760 --> 00:23:48,890
simple program we already have a vast

00:23:47,360 --> 00:23:54,410
improvement on the checkpoint durations

00:23:48,890 --> 00:23:56,420
with credit based flow control and a

00:23:54,410 --> 00:23:57,590
second thing we did not only introduced

00:23:56,420 --> 00:23:59,090
credit based flow control into the

00:23:57,590 --> 00:24:01,880
networks like we also improved it a lot

00:23:59,090 --> 00:24:04,070
and and it's over it so rid reduced the

00:24:01,880 --> 00:24:05,960
overhead of the network stack and that

00:24:04,070 --> 00:24:07,940
way the balance between high throughput

00:24:05,960 --> 00:24:10,460
by buffering a lot of data and then

00:24:07,940 --> 00:24:12,610
sending big chunks versus sending every

00:24:10,460 --> 00:24:17,900
event on its own and having low latency

00:24:12,610 --> 00:24:19,640
is further improved so with a very full

00:24:17,900 --> 00:24:22,910
buffers only flushing them everyone at

00:24:19,640 --> 00:24:24,410
milliseconds was which is default we

00:24:22,910 --> 00:24:27,650
have higher throughput because of the

00:24:24,410 --> 00:24:30,950
improvements in the and they use

00:24:27,650 --> 00:24:33,429
but even if you flush every five or two

00:24:30,950 --> 00:24:36,230
a one second or even send every event

00:24:33,429 --> 00:24:48,409
there we have a lot higher improvement 1

00:24:36,230 --> 00:24:52,970
5 than 1 for one more thing is a minor

00:24:48,409 --> 00:24:53,690
context switch so we're not talking

00:24:52,970 --> 00:24:56,830
about States

00:24:53,690 --> 00:25:00,169
so whenever flings high-availability

00:24:56,830 --> 00:25:01,610
basically is based on on checkpoints

00:25:00,169 --> 00:25:05,679
those checkpoints which store States

00:25:01,610 --> 00:25:05,679
somewhere in distributed file system and

00:25:06,010 --> 00:25:10,190
we have those Jackman bearers passing

00:25:08,270 --> 00:25:12,380
through whenever an operator knows okay

00:25:10,190 --> 00:25:15,350
I have to checkpoint this my state's

00:25:12,380 --> 00:25:17,500
somewhere it will store this into stable

00:25:15,350 --> 00:25:20,179
storage it will do so asynchronously

00:25:17,500 --> 00:25:23,179
there is a synchronous part which

00:25:20,179 --> 00:25:26,440
basically creates a copy or copy on

00:25:23,179 --> 00:25:29,860
writes and then stores this part

00:25:26,440 --> 00:25:32,990
asynchronously onto some stable storage

00:25:29,860 --> 00:25:35,450
so during failures whenever a task

00:25:32,990 --> 00:25:38,210
manager fails the job will be redeployed

00:25:35,450 --> 00:25:40,520
and we need to restore the state from

00:25:38,210 --> 00:25:42,529
the stable storage and this is a

00:25:40,520 --> 00:25:44,240
significant burden if you have a very

00:25:42,529 --> 00:25:45,860
big state if you have terabytes of

00:25:44,240 --> 00:25:49,340
states start somewhere and this needs to

00:25:45,860 --> 00:25:52,159
be loaded so what if Ling five one five

00:25:49,340 --> 00:25:57,740
introduced is to have some local states

00:25:52,159 --> 00:26:00,140
so if your task manager survived the

00:25:57,740 --> 00:26:02,510
scheduling will make sure that the task

00:26:00,140 --> 00:26:07,399
is put again onto the same task manager

00:26:02,510 --> 00:26:10,159
and doing let's sort of doing

00:26:07,399 --> 00:26:11,480
checkpoints you will not only store the

00:26:10,159 --> 00:26:13,370
checkpoints on this distributed file

00:26:11,480 --> 00:26:15,919
system but you will also have a copy

00:26:13,370 --> 00:26:19,070
local on your local disk so you have

00:26:15,919 --> 00:26:21,049
this one copy and local disk one and

00:26:19,070 --> 00:26:23,659
distributed file system if your task

00:26:21,049 --> 00:26:25,340
manager survived then you can restore

00:26:23,659 --> 00:26:27,169
from the local file system immediately

00:26:25,340 --> 00:26:30,169
you don't need to download stuff from

00:26:27,169 --> 00:26:33,110
your distributed file system again if it

00:26:30,169 --> 00:26:35,630
did not survive well for all those that

00:26:33,110 --> 00:26:38,260
survived you restore locally and for

00:26:35,630 --> 00:26:40,400
those who didn't you restore from the

00:26:38,260 --> 00:26:43,250
distributed file system

00:26:40,400 --> 00:26:46,520
so there's a significant reduction in

00:26:43,250 --> 00:26:51,920
the time that you need to restore from a

00:26:46,520 --> 00:26:53,390
failure there have been some changes in

00:26:51,920 --> 00:26:56,050
the secret way there is a talk tomorrow

00:26:53,390 --> 00:26:58,340
so I will not go into details that much

00:26:56,050 --> 00:27:01,640
my colleague Fabian would present more

00:26:58,340 --> 00:27:04,760
detail tomorrow so we have some some

00:27:01,640 --> 00:27:06,950
support for new joins like windowed

00:27:04,760 --> 00:27:09,770
outer joins and non winnette inner joins

00:27:06,950 --> 00:27:12,590
and one of the bigger changes there is

00:27:09,770 --> 00:27:17,410
that we have a sequel clients so it's

00:27:12,590 --> 00:27:21,620
very easy now to access to data on the

00:27:17,410 --> 00:27:23,690
to process data on your stream you don't

00:27:21,620 --> 00:27:25,160
need to write a Java Scala program

00:27:23,690 --> 00:27:28,550
anymore and put your sequel query in

00:27:25,160 --> 00:27:34,100
there and submit this you simply run the

00:27:28,550 --> 00:27:36,679
sequel client you enter your query and

00:27:34,100 --> 00:27:40,130
you then browse the tables like in this

00:27:36,679 --> 00:27:43,760
demo you can view at individual events

00:27:40,130 --> 00:27:45,890
you will see the details basically it's

00:27:43,760 --> 00:27:50,680
a very handy tool to do some quick

00:27:45,890 --> 00:27:54,100
calculations oops

00:27:50,680 --> 00:27:55,450
and now some parts for what's going on

00:27:54,100 --> 00:27:58,630
at the moment so the release was roughly

00:27:55,450 --> 00:28:02,110
two weeks ago and the next flink one six

00:27:58,630 --> 00:28:03,760
is targeted for end of July so what's in

00:28:02,110 --> 00:28:06,000
the pipeline now and what will guarantee

00:28:03,760 --> 00:28:09,790
one six and even beyond

00:28:06,000 --> 00:28:12,640
so the focus points are basically

00:28:09,790 --> 00:28:15,070
mentioned here is first of all support

00:28:12,640 --> 00:28:21,340
for Java nine at the moment we run Java

00:28:15,070 --> 00:28:23,679
8 and Scala 212 then the changes in the

00:28:21,340 --> 00:28:27,910
deployment architecture are continuing

00:28:23,679 --> 00:28:29,380
to give some better and give some

00:28:27,910 --> 00:28:35,580
improvements for container environments

00:28:29,380 --> 00:28:38,440
to run on combinators natively and also

00:28:35,580 --> 00:28:40,420
part of it is having the whole job

00:28:38,440 --> 00:28:41,530
submission run through rest there's one

00:28:40,420 --> 00:28:44,710
single point that is not going through

00:28:41,530 --> 00:28:49,120
guys yet and this is techadon that JIRA

00:28:44,710 --> 00:28:50,770
ticket then there are two types of

00:28:49,120 --> 00:28:54,970
states that are currently only store the

00:28:50,770 --> 00:28:57,370
memory this is timers and operators data

00:28:54,970 --> 00:28:59,559
we do want to change this we do want to

00:28:57,370 --> 00:29:02,530
leverage our state backends for those

00:28:59,559 --> 00:29:06,040
two categories so that not only we can

00:29:02,530 --> 00:29:08,170
have a very big operator state that is

00:29:06,040 --> 00:29:11,070
that does not fit into memory anymore

00:29:08,170 --> 00:29:15,730
but can be stored on disk via rocks DB

00:29:11,070 --> 00:29:17,530
but also remove some old code then and

00:29:15,730 --> 00:29:20,500
get some better performance which is

00:29:17,530 --> 00:29:23,770
already showing there then on the

00:29:20,500 --> 00:29:26,260
application side we want to change and

00:29:23,770 --> 00:29:28,960
improve the bucketing sync that is now

00:29:26,260 --> 00:29:31,030
based on Hadoop file systems to work

00:29:28,960 --> 00:29:33,850
with fling file systems those fascism

00:29:31,030 --> 00:29:35,679
will then include like s3 and all of the

00:29:33,850 --> 00:29:41,110
other file systems that are available in

00:29:35,679 --> 00:29:45,580
flink then their changes in pipelines

00:29:41,110 --> 00:29:48,460
for improving state evaluation to allow

00:29:45,580 --> 00:29:50,470
type conversions doing restores which is

00:29:48,460 --> 00:29:51,670
not possible at the moment and then

00:29:50,470 --> 00:29:54,760
there are a lot of changes in stream

00:29:51,670 --> 00:29:56,170
sequel we will have a new update by key

00:29:54,760 --> 00:29:59,050
for table sources we will have more

00:29:56,170 --> 00:30:02,080
table sources not just Kafka but also on

00:29:59,050 --> 00:30:04,480
and Kinesis and files and Kaveri stores

00:30:02,080 --> 00:30:07,360
and the complex event processing CEP

00:30:04,480 --> 00:30:09,820
will integrate with sequel will use the

00:30:07,360 --> 00:30:14,080
match recognized clause to make it

00:30:09,820 --> 00:30:17,770
available there and one more thing the

00:30:14,080 --> 00:30:20,080
CP performance if used on rock CB is

00:30:17,770 --> 00:30:21,280
currently not or I can be improved and

00:30:20,080 --> 00:30:25,450
will be improved there's open full

00:30:21,280 --> 00:30:27,910
requests for this as well and this is

00:30:25,450 --> 00:30:37,540
where roughly made it on time and now we

00:30:27,910 --> 00:30:41,470
have some room for questions and a new

00:30:37,540 --> 00:30:45,790
deployment models you how does that work

00:30:41,470 --> 00:30:47,640
with Kerberos key type files do you is

00:30:45,790 --> 00:30:52,360
not still supported properly

00:30:47,640 --> 00:30:53,210
that's the supported and it's may go

00:30:52,360 --> 00:30:56,309
back to

00:30:53,210 --> 00:30:56,309
[Music]

00:31:02,600 --> 00:31:12,240
here so you still submit the job this

00:31:10,590 --> 00:31:13,770
will go to the job manager and task

00:31:12,240 --> 00:31:16,620
manager so that basically is the same

00:31:13,770 --> 00:31:18,390
the only thing that changed is the way

00:31:16,620 --> 00:31:24,620
that you request resources so those will

00:31:18,390 --> 00:31:24,620
go we should go the same way actually

00:31:33,470 --> 00:31:40,680
hello hello so talking about dynamic

00:31:37,910 --> 00:31:43,230
resource allocation is there about

00:31:40,680 --> 00:31:46,650
dynamic resource allocation is there

00:31:43,230 --> 00:31:49,890
auto scaling feature or how does it work

00:31:46,650 --> 00:31:52,470
to its scale what is currently possible

00:31:49,890 --> 00:31:56,940
is that the flink cluster itself scan

00:31:52,470 --> 00:31:59,880
scale so you start like in session mode

00:31:56,940 --> 00:32:02,340
you you spawn up only this one cluster

00:31:59,880 --> 00:32:04,170
entry point and then whenever you submit

00:32:02,340 --> 00:32:06,960
a job it will ask for the resources

00:32:04,170 --> 00:32:09,210
those resources whenever a job finishes

00:32:06,960 --> 00:32:11,430
will not be given back immediately you

00:32:09,210 --> 00:32:13,260
will hold onto them for a while and only

00:32:11,430 --> 00:32:15,270
give them back after some time out so

00:32:13,260 --> 00:32:17,400
you can which you can configure if you

00:32:15,270 --> 00:32:20,160
ask for a separate like in a new job

00:32:17,400 --> 00:32:22,500
like job a and P as in the example job P

00:32:20,160 --> 00:32:25,130
will ask for more resources so the flink

00:32:22,500 --> 00:32:28,590
cluster itself will auto scale the job

00:32:25,130 --> 00:32:30,810
that the job itself will not I mean you

00:32:28,590 --> 00:32:32,820
cannot you can scale but not

00:32:30,810 --> 00:32:35,760
automatically what you would do would

00:32:32,820 --> 00:32:38,840
basically take a snapshot increase the

00:32:35,760 --> 00:32:38,840
parallelism and start again

00:32:44,990 --> 00:32:59,590
all right does that answer your question

00:32:47,529 --> 00:33:00,820
any and and about question about entry

00:32:59,590 --> 00:33:05,120
sorry

00:33:00,820 --> 00:33:07,669
society input okay II could you please

00:33:05,120 --> 00:33:10,820
her mind did you mention how this state

00:33:07,669 --> 00:33:13,520
can be updated with some timeout because

00:33:10,820 --> 00:33:20,720
in previously we were using pattern with

00:33:13,520 --> 00:33:24,409
sleeps to be honest not familiar much

00:33:20,720 --> 00:33:27,830
with the site inputs stated site input

00:33:24,409 --> 00:33:33,200
slot estate is kind of a site input yes

00:33:27,830 --> 00:33:36,350
but I don't think I don't want to give

00:33:33,200 --> 00:33:37,909
out wrong information so this broadcast

00:33:36,350 --> 00:33:42,169
state can we update the rules

00:33:37,909 --> 00:33:43,370
yeah so this is out this is one kind of

00:33:42,169 --> 00:33:46,669
site and put as you could say it's not

00:33:43,370 --> 00:33:51,830
the generic so for everything but if you

00:33:46,669 --> 00:33:53,419
do this pattern there then that's some I

00:33:51,830 --> 00:33:57,320
have another question and so effectively

00:33:53,419 --> 00:33:59,419
you can have your flink session running

00:33:57,320 --> 00:34:02,120
indefinitely claiming only maybe one

00:33:59,419 --> 00:34:04,279
container and only when you submit a job

00:34:02,120 --> 00:34:06,710
it will claim additional resources and

00:34:04,279 --> 00:34:07,250
give them back a while after job

00:34:06,710 --> 00:34:08,960
finished

00:34:07,250 --> 00:34:12,230
yes okay that's exactly what you can do

00:34:08,960 --> 00:34:16,990
that's nice yeah you will share the

00:34:12,230 --> 00:34:16,990
resources though among different jobs

00:34:21,679 --> 00:34:30,230
right Thanks so I'm interested in

00:34:25,700 --> 00:34:34,740
kubernetes setup what can we expect for

00:34:30,230 --> 00:34:36,659
the next release is this on on the same

00:34:34,740 --> 00:34:41,129
level what what is present for example

00:34:36,659 --> 00:34:47,879
for yarn or is it just a more smaller

00:34:41,129 --> 00:34:53,279
version of scheduling yeah I think there

00:34:47,879 --> 00:34:54,809
will be first step of having containers

00:34:53,279 --> 00:34:56,279
pretty but generate containers for

00:34:54,809 --> 00:34:58,559
customers that will register with the

00:34:56,279 --> 00:35:00,539
results menteur similar as here where

00:34:58,559 --> 00:35:02,789
like companies would do this scaling

00:35:00,539 --> 00:35:05,099
meaning it will launch additional task

00:35:02,789 --> 00:35:06,839
managers those will register similar to

00:35:05,099 --> 00:35:15,210
the session mode will then register

00:35:06,839 --> 00:35:16,740
sorry they're so kinase which would if

00:35:15,210 --> 00:35:18,630
it was scale it would simply start up

00:35:16,740 --> 00:35:20,339
more task manager containers those

00:35:18,630 --> 00:35:22,349
containers will connect to the resource

00:35:20,339 --> 00:35:24,779
manager and this will have them

00:35:22,349 --> 00:35:26,220
available there as well and then the job

00:35:24,779 --> 00:35:32,279
submission goes through dispatcher as

00:35:26,220 --> 00:35:35,579
well following this are you familiar

00:35:32,279 --> 00:35:38,099
with the way SPARC is working for

00:35:35,579 --> 00:35:40,079
submitting jobs are there similar plans

00:35:38,099 --> 00:35:46,190
to have the kubernetes native way to

00:35:40,079 --> 00:35:46,190
submit a job I'm not so thanks

00:35:49,150 --> 00:36:01,390
all right any more questions yeah I'm

00:35:58,690 --> 00:36:03,249
wondering about the broadcast date you

00:36:01,390 --> 00:36:06,309
could do something similar previously by

00:36:03,249 --> 00:36:09,599
using physical partitioning right and I

00:36:06,309 --> 00:36:13,740
what using physical partitioning

00:36:09,599 --> 00:36:17,490
physically locating the data

00:36:13,740 --> 00:36:21,730
broadcasting it to all the nodes and

00:36:17,490 --> 00:36:25,119
then using like using the physical

00:36:21,730 --> 00:36:27,700
partitioning connection on a single

00:36:25,119 --> 00:36:30,339
machine you could do you could do make

00:36:27,700 --> 00:36:32,430
assumptions about operators location you

00:36:30,339 --> 00:36:34,960
could hack your way through yeah like

00:36:32,430 --> 00:36:37,089
whatever you receive the progress states

00:36:34,960 --> 00:36:38,980
will put it into memory and then it's of

00:36:37,089 --> 00:36:40,569
course available on the others but you

00:36:38,980 --> 00:36:42,160
would not have any guarantees like

00:36:40,569 --> 00:36:44,920
exactly once

00:36:42,160 --> 00:36:47,079
between those two okay so that's what we

00:36:44,920 --> 00:36:49,990
got you a drink yes before that was only

00:36:47,079 --> 00:36:53,220
like say a hack but this is a cleaner

00:36:49,990 --> 00:36:53,220
solution Thanks

00:37:03,940 --> 00:37:09,190
and no more question and thank you for a

00:37:08,029 --> 00:37:09,640
time Vicki thank you

00:37:09,190 --> 00:37:12,699
[Applause]

00:37:09,640 --> 00:37:12,699

YouTube URL: https://www.youtube.com/watch?v=m12l5ke4Z34


