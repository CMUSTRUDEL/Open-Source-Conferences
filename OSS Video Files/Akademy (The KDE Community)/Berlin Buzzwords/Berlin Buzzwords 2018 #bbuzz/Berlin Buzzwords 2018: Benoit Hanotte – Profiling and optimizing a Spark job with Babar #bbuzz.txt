Title: Berlin Buzzwords 2018: Benoit Hanotte â€“ Profiling and optimizing a Spark job with Babar #bbuzz
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	New data-processing frameworks such as Apache Spark and Flink have made writing Apache Hadoop jobs very easy. However, as the data grows, developers face new challenges: from stability issues to allocating the right amount of resources, large jobs are often hard to tune and debug as their distributed nature and scale make them hard to observe.

Babar, an open source profiler developed at Criteo, was introduced to make it easier for users to profile their Hadoop jobs and their resource usage with little effort and instrumentation. It helps understand CPU usage, memory consumption and GC load over the entire application, as well as where the CPU time is spent using flame graph visualizations.

In this session, we will see how to instrument an Apache Spark job and go through its optimization in order to improve latency and stability, while reducing its footprint on the cluster.

Read more:
https://2018.berlinbuzzwords.de/18/session/profiling-and-optimizing-spark-job-babar

About Benoit Hanotte:
https://2018.berlinbuzzwords.de/users/benoit-hanotte

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:04,630 --> 00:00:10,100
hello my name is Benoit notes I'm a

00:00:08,330 --> 00:00:11,809
software engineer at Cray do and I we

00:00:10,100 --> 00:00:14,990
talk about providing optimizing spark

00:00:11,809 --> 00:00:16,640
jobs with tools we developed first

00:00:14,990 --> 00:00:18,860
before we can if you world about Korea

00:00:16,640 --> 00:00:20,840
we're in the online advertisement

00:00:18,860 --> 00:00:23,030
business and our motto is connecting

00:00:20,840 --> 00:00:26,210
shoppers who sings and need and love so

00:00:23,030 --> 00:00:27,770
the idea is to to present users with

00:00:26,210 --> 00:00:29,600
relevant advertisement driven products

00:00:27,770 --> 00:00:31,760
rahman services and only present do

00:00:29,600 --> 00:00:34,309
salvat iseman to users that might be

00:00:31,760 --> 00:00:35,989
interested in it and to do so we use a

00:00:34,309 --> 00:00:37,910
lot of machine learning and because we

00:00:35,989 --> 00:00:40,550
use machine learning we need to store

00:00:37,910 --> 00:00:43,430
and process a lot of data and for that

00:00:40,550 --> 00:00:45,170
we've built a Hadoop cluster just a few

00:00:43,430 --> 00:00:47,810
numbers about the cluster it's alpha

00:00:45,170 --> 00:00:49,940
beta bytes of data ingested daily 15

00:00:47,810 --> 00:00:51,890
petabytes of data read daily and more

00:00:49,940 --> 00:00:54,860
than four thousand nodes it's close to

00:00:51,890 --> 00:00:56,750
100,000 CPU cores on the cluster which

00:00:54,860 --> 00:01:00,530
makes it the largest I do cluster in

00:00:56,750 --> 00:01:02,809
Europe and because we've got so many

00:01:00,530 --> 00:01:04,759
products we have a very diverse

00:01:02,809 --> 00:01:06,770
ecosystem running on top of it's from

00:01:04,759 --> 00:01:10,249
MapReduce to mapper and MapReduce based

00:01:06,770 --> 00:01:13,700
frameworks cascading scalding to other

00:01:10,249 --> 00:01:16,340
frameworks spark fleeing secret engines

00:01:13,700 --> 00:01:19,880
as well such as Ivan presto and so

00:01:16,340 --> 00:01:22,880
recently teams were refactoring products

00:01:19,880 --> 00:01:24,229
or building new products move away from

00:01:22,880 --> 00:01:27,319
a produced based remarks to no

00:01:24,229 --> 00:01:30,229
alternatives and one very popular

00:01:27,319 --> 00:01:32,209
alternative is spark one main reason

00:01:30,229 --> 00:01:34,279
that it advertised is very fast and

00:01:32,209 --> 00:01:37,189
efficient processing Hadoop so it seems

00:01:34,279 --> 00:01:38,599
like a very good choice right that's

00:01:37,189 --> 00:01:41,869
what they advertise on their website and

00:01:38,599 --> 00:01:44,509
so teams a lot of teams build on your

00:01:41,869 --> 00:01:47,539
products on top of spark the frame that

00:01:44,509 --> 00:01:49,789
we didn't see more efficiency or faster

00:01:47,539 --> 00:01:50,919
processing in fact we saw a lot of

00:01:49,789 --> 00:01:53,899
instability

00:01:50,919 --> 00:01:56,899
between containers lost out of memory

00:01:53,899 --> 00:01:59,810
euros yarn killing of containers on the

00:01:56,899 --> 00:02:02,590
cluster randomly it seems also jobs

00:01:59,810 --> 00:02:05,810
taking way too long for processing

00:02:02,590 --> 00:02:09,830
clearly it wasn't what we expected and

00:02:05,810 --> 00:02:11,780
so jobs were very unstable and teams

00:02:09,830 --> 00:02:13,760
were solving this instability by just

00:02:11,780 --> 00:02:15,980
allocating a lot more memory or

00:02:13,760 --> 00:02:18,390
resources to their jobs compared to what

00:02:15,980 --> 00:02:21,330
we had before which was not

00:02:18,390 --> 00:02:22,910
viable solution for the long-term on the

00:02:21,330 --> 00:02:25,050
cluster because does it cost

00:02:22,910 --> 00:02:26,670
infrastructure cost mainly and so

00:02:25,050 --> 00:02:28,140
clearly we needed to better understand

00:02:26,670 --> 00:02:30,360
what was happening and also root for the

00:02:28,140 --> 00:02:33,180
spark jobs to better be able to tune

00:02:30,360 --> 00:02:37,770
then and optimize them so that they are

00:02:33,180 --> 00:02:40,500
good citizens on our cluster for this we

00:02:37,770 --> 00:02:42,600
decided to build a small tool provider

00:02:40,500 --> 00:02:44,430
for distribute applications on Hadoop

00:02:42,600 --> 00:02:47,220
which we call Baba

00:02:44,430 --> 00:02:48,660
we've it with part but not only it's not

00:02:47,220 --> 00:02:50,250
really tight when you framework visit

00:02:48,660 --> 00:02:52,440
with spark as I said but also sky

00:02:50,250 --> 00:02:55,739
leading I've it should work with link if

00:02:52,440 --> 00:02:57,810
you use blink and there were four main

00:02:55,739 --> 00:03:00,840
reasons who I wanted to develop this

00:02:57,810 --> 00:03:03,540
profiler first I needed to be very easy

00:03:00,840 --> 00:03:06,239
to get started with there exists other

00:03:03,540 --> 00:03:08,070
providers you may have heard of study

00:03:06,239 --> 00:03:09,420
for instance but they are required for a

00:03:08,070 --> 00:03:11,489
structure whether it's database whether

00:03:09,420 --> 00:03:14,100
it's some current code being installed

00:03:11,489 --> 00:03:16,560
on your computer nodes or that was a

00:03:14,100 --> 00:03:18,870
very high barrier countries or country

00:03:16,560 --> 00:03:22,500
for users and that explained why nobody

00:03:18,870 --> 00:03:24,239
was actually using them at creo second I

00:03:22,500 --> 00:03:25,829
need to be made hot stupid applications

00:03:24,239 --> 00:03:27,870
because of this nature makes them very

00:03:25,829 --> 00:03:30,360
hard to observe from start to hand if

00:03:27,870 --> 00:03:33,000
you want to Ricci is agent that entirety

00:03:30,360 --> 00:03:35,790
of your job the profile needs to be made

00:03:33,000 --> 00:03:37,829
for that study to work at scale because

00:03:35,790 --> 00:03:40,110
sometimes everything works fine and

00:03:37,829 --> 00:03:41,579
preparation data on sample data and once

00:03:40,110 --> 00:03:43,769
you move to production data then

00:03:41,579 --> 00:03:45,540
everything goes bad and you need to

00:03:43,769 --> 00:03:46,890
understand what's what's happening at

00:03:45,540 --> 00:03:50,160
that scale so you need to work with

00:03:46,890 --> 00:03:51,510
large scale apps and finally results

00:03:50,160 --> 00:03:53,760
need to be very easy to understand

00:03:51,510 --> 00:03:55,920
because teams don't want to spend a lot

00:03:53,760 --> 00:03:57,780
of time trying to figure out all to

00:03:55,920 --> 00:03:59,760
exploit the results and because it's

00:03:57,780 --> 00:04:02,519
been useful to us we've open sourced it

00:03:59,760 --> 00:04:04,290
it's on github on our github account so

00:04:02,519 --> 00:04:04,590
it's a github.com slash creatures raj

00:04:04,290 --> 00:04:07,320
babbar

00:04:04,590 --> 00:04:10,829
if you fancy having a look and so if we

00:04:07,320 --> 00:04:13,560
talk about architecture quickly so Bubba

00:04:10,829 --> 00:04:15,450
come with a Java IDE Jones so it's a jar

00:04:13,560 --> 00:04:17,970
that you can attach to the executor JVM

00:04:15,450 --> 00:04:20,220
and that will instrument the JVM so if

00:04:17,970 --> 00:04:22,169
we get matrix from the JVM it reads

00:04:20,220 --> 00:04:23,580
nonpolar so your stack traces and it

00:04:22,169 --> 00:04:24,060
will get metrics from the operating

00:04:23,580 --> 00:04:26,430
system

00:04:24,060 --> 00:04:28,470
if you use Linux so that you can get

00:04:26,430 --> 00:04:30,840
metrics not only for your java code but

00:04:28,470 --> 00:04:32,169
also native libraries for compression

00:04:30,840 --> 00:04:34,360
decompression

00:04:32,169 --> 00:04:36,550
Python codes that you may run outside of

00:04:34,360 --> 00:04:39,129
the JVM on your executors and so on and

00:04:36,550 --> 00:04:40,990
so these metrics would be locked to the

00:04:39,129 --> 00:04:42,610
local file system and when your

00:04:40,990 --> 00:04:45,009
application completes yarn aggregates

00:04:42,610 --> 00:04:48,099
your container logs to a single file on

00:04:45,009 --> 00:04:51,029
the Hadoop on a GFS and Baba just need

00:04:48,099 --> 00:04:54,430
to process this file to build a final

00:04:51,029 --> 00:04:57,069
report as an HTML file so if we look at

00:04:54,430 --> 00:04:58,810
what a report looks like it's so as I

00:04:57,069 --> 00:05:02,110
said in HTML files that team members can

00:04:58,810 --> 00:05:04,900
send through slack archive on on their

00:05:02,110 --> 00:05:06,939
wiki pages and so on there are six main

00:05:04,900 --> 00:05:08,349
tabs and this report as the first one is

00:05:06,939 --> 00:05:10,360
containers so it's interesting to see

00:05:08,349 --> 00:05:12,009
your containers life side column and

00:05:10,360 --> 00:05:15,639
containers are running at any given time

00:05:12,009 --> 00:05:17,680
also the the timeline of each container

00:05:15,639 --> 00:05:19,210
then we've got memory how much memory

00:05:17,680 --> 00:05:20,969
you use and resolve on your

00:05:19,210 --> 00:05:23,529
infrastructure which is hard to

00:05:20,969 --> 00:05:27,310
otherwise have a good idea of what's

00:05:23,529 --> 00:05:29,080
happening on yarn and we spoke CPU as

00:05:27,310 --> 00:05:33,009
well or your executor is using memory

00:05:29,080 --> 00:05:35,729
CPU well as the bottlenecks garbage

00:05:33,009 --> 00:05:39,310
collection to tune your memory i/o and

00:05:35,729 --> 00:05:40,839
finally traces so your stack traces at

00:05:39,310 --> 00:05:44,349
Bob our samples presented as frame

00:05:40,839 --> 00:05:46,089
graphs and so let's start with flame

00:05:44,349 --> 00:05:48,009
graphs if you don't know what frame

00:05:46,089 --> 00:05:50,710
graphs are it's a visualization to

00:05:48,009 --> 00:05:53,649
quickly identify expensive code paths in

00:05:50,710 --> 00:05:55,360
your code base so imagine we've got a

00:05:53,649 --> 00:05:57,250
very simple application represented by

00:05:55,360 --> 00:06:00,279
this pseudocode there is the root method

00:05:57,250 --> 00:06:01,960
a according to method B and C and each

00:06:00,279 --> 00:06:04,659
of the stream is a diamond cutting a

00:06:01,960 --> 00:06:06,460
last method D so if we want to build a

00:06:04,659 --> 00:06:09,490
flame raffle for this application we

00:06:06,460 --> 00:06:10,839
just have ruth without a as i said and a

00:06:09,490 --> 00:06:12,219
course like from top to bottom so

00:06:10,839 --> 00:06:14,740
parents we thought would be at the top

00:06:12,219 --> 00:06:16,990
Jeremy Todd right underneath that so as

00:06:14,740 --> 00:06:19,899
I said a scoring method B which in turn

00:06:16,990 --> 00:06:21,999
is cutting with a D and Wendy and B

00:06:19,899 --> 00:06:24,120
completes and a scoring C which in is

00:06:21,999 --> 00:06:25,240
current D and then the application

00:06:24,120 --> 00:06:27,430
completes

00:06:25,240 --> 00:06:28,960
so which the vertical axis axis is a

00:06:27,430 --> 00:06:31,149
call stack and the horizontal axis

00:06:28,960 --> 00:06:32,949
represents CPU times so the the width of

00:06:31,149 --> 00:06:35,319
the block is proportional to the CPU

00:06:32,949 --> 00:06:37,300
times I spend and so because a the

00:06:35,319 --> 00:06:39,879
written is one word person CPU time and

00:06:37,300 --> 00:06:42,729
B being only 40% of the width of a is

00:06:39,879 --> 00:06:44,769
40% CPU time and so here we can see D

00:06:42,729 --> 00:06:45,940
would be 20% CPU time so it's very

00:06:44,769 --> 00:06:47,740
interesting because not

00:06:45,940 --> 00:06:50,230
you can see what which cut paths are

00:06:47,740 --> 00:06:52,660
used in your application but you can

00:06:50,230 --> 00:06:55,660
also see all expensive they are on CPU

00:06:52,660 --> 00:06:57,820
time and so that's very convenient to

00:06:55,660 --> 00:06:59,650
for instance optimize a job and avoid

00:06:57,820 --> 00:07:01,750
premature optimization because some time

00:06:59,650 --> 00:07:03,900
you buy something and you realize at the

00:07:01,750 --> 00:07:06,460
end or too late that actually it was not

00:07:03,900 --> 00:07:09,310
the bottleneck of your application so

00:07:06,460 --> 00:07:12,130
let's apply that to a sample job imagine

00:07:09,310 --> 00:07:14,350
we are joining two data sets so we spark

00:07:12,130 --> 00:07:16,570
very simple join we open two data set we

00:07:14,350 --> 00:07:18,760
read them we join them and we write the

00:07:16,570 --> 00:07:20,770
result to disk if we provide it with

00:07:18,760 --> 00:07:22,600
bah-bah we get the frame graphs of the

00:07:20,770 --> 00:07:24,550
entire application not just one executor

00:07:22,600 --> 00:07:27,460
but all the executives together and that

00:07:24,550 --> 00:07:29,680
would give a frame graph like this and

00:07:27,460 --> 00:07:30,970
so as I said before it's reconvening to

00:07:29,680 --> 00:07:32,290
see what's happening inside your

00:07:30,970 --> 00:07:34,000
application if you look at this firm

00:07:32,290 --> 00:07:37,510
graph we can clearly see the process of

00:07:34,000 --> 00:07:38,860
this puck join so first we can see we

00:07:37,510 --> 00:07:40,750
read the data because as you can see

00:07:38,860 --> 00:07:43,570
it's all the park heads input format

00:07:40,750 --> 00:07:46,750
code so we can see that reading takes

00:07:43,570 --> 00:07:49,930
approximately 35% of our CPU times then

00:07:46,750 --> 00:07:53,200
that the records are sorted map side and

00:07:49,930 --> 00:07:55,930
then finally stylized for the shuffle

00:07:53,200 --> 00:07:58,810
and after the show for the data is dis

00:07:55,930 --> 00:08:00,550
alized drooped so joined and finally

00:07:58,810 --> 00:08:02,470
written to disk so we can clearly see

00:08:00,550 --> 00:08:04,960
the process on the cost of each step and

00:08:02,470 --> 00:08:07,090
here we see that reading is very

00:08:04,960 --> 00:08:08,830
expensive but we also see that sir icing

00:08:07,090 --> 00:08:10,570
the sizing for the shofar is incredibly

00:08:08,830 --> 00:08:12,940
expensive and so that's the first thing

00:08:10,570 --> 00:08:15,400
we can take from from this frame breath

00:08:12,940 --> 00:08:16,780
for this joint if we want to if want to

00:08:15,400 --> 00:08:19,050
optimize something we need to optimize

00:08:16,780 --> 00:08:21,730
the shuffles the shuffle stage and

00:08:19,050 --> 00:08:23,320
basically avoiding citation because it's

00:08:21,730 --> 00:08:24,790
not really network and it's not I use

00:08:23,320 --> 00:08:26,350
that's expensive that sir ization in

00:08:24,790 --> 00:08:28,120
this case and if you wanted to convince

00:08:26,350 --> 00:08:30,580
ourselves of this fact we can have a

00:08:28,120 --> 00:08:33,339
look at the CPU time spent by the

00:08:30,580 --> 00:08:35,410
application so Baba can give you this

00:08:33,339 --> 00:08:37,839
graph which is a midi entire CPU time

00:08:35,410 --> 00:08:40,510
spent by your executor and boss for user

00:08:37,839 --> 00:08:42,610
and system mode and if we look system

00:08:40,510 --> 00:08:45,220
mode is during the shuffle is very

00:08:42,610 --> 00:08:46,780
insignificant versus user mode so it's

00:08:45,220 --> 00:08:48,880
really not disk and I Oh which will

00:08:46,780 --> 00:08:51,190
happen in system mode it's really sir

00:08:48,880 --> 00:08:53,830
ization in user mode so if once you

00:08:51,190 --> 00:08:55,930
optimize this job and so we need to

00:08:53,830 --> 00:08:58,089
optimize probably the shuffle answer

00:08:55,930 --> 00:08:59,350
ization stage and so we need to pick

00:08:58,089 --> 00:09:02,560
models accordingly because

00:08:59,350 --> 00:09:04,510
as we've seen because salvation is so

00:09:02,560 --> 00:09:07,270
expensive it's often more interesting to

00:09:04,510 --> 00:09:08,800
pick a data representation for you for

00:09:07,270 --> 00:09:10,810
your data for your records so the

00:09:08,800 --> 00:09:12,820
mothers that feels allies in this arise

00:09:10,810 --> 00:09:14,680
very efficiently in self trying to

00:09:12,820 --> 00:09:17,440
minimize the footprint in memory and

00:09:14,680 --> 00:09:20,350
also using specialized sizes can be huge

00:09:17,440 --> 00:09:23,230
gain in our case our using so for this

00:09:20,350 --> 00:09:25,450
join using special sizes can be 40% cpu

00:09:23,230 --> 00:09:27,130
gain time gain not only because it will

00:09:25,450 --> 00:09:29,800
size better but that so because spark is

00:09:27,130 --> 00:09:31,840
able to apply further optimizations when

00:09:29,800 --> 00:09:34,810
it has custom sizes for each of your

00:09:31,840 --> 00:09:36,130
classes and if we looked at the flame

00:09:34,810 --> 00:09:37,720
graph we could see that it's really in

00:09:36,130 --> 00:09:42,010
the sort face that spark is able to

00:09:37,720 --> 00:09:44,020
optimize by using an i/o based salt and

00:09:42,010 --> 00:09:46,570
another place where we are not expecting

00:09:44,020 --> 00:09:48,880
is the models choice to have an impact

00:09:46,570 --> 00:09:51,100
is in the size estimation of the objects

00:09:48,880 --> 00:09:54,460
if you know spark spark positions its

00:09:51,100 --> 00:09:56,770
memory into three different areas use a

00:09:54,460 --> 00:09:58,360
user memory exaction memory in storage

00:09:56,770 --> 00:10:00,310
memory and in order to be able to know

00:09:58,360 --> 00:10:00,790
how much memory how much of this memory

00:10:00,310 --> 00:10:03,100
is used

00:10:00,790 --> 00:10:04,600
spark needs to estimate the size of the

00:10:03,100 --> 00:10:06,730
objects and it does so by going through

00:10:04,600 --> 00:10:08,140
the object recursively and that can be

00:10:06,730 --> 00:10:10,600
very expensive we can see here that

00:10:08,140 --> 00:10:12,430
we're spending in this frame graph we

00:10:10,600 --> 00:10:14,500
can see that we're spending 18% of the

00:10:12,430 --> 00:10:17,260
CPU time just estimating the size of our

00:10:14,500 --> 00:10:19,300
objects and in some cases it can be even

00:10:17,260 --> 00:10:23,380
worse we've seen up to 30% CPU time

00:10:19,300 --> 00:10:24,820
spent just estimating the size with very

00:10:23,380 --> 00:10:27,220
large JSON objects with Android of

00:10:24,820 --> 00:10:29,680
columns so picking models can be a huge

00:10:27,220 --> 00:10:32,800
optimization for this kind of joints in

00:10:29,680 --> 00:10:36,010
this as in this example and so now that

00:10:32,800 --> 00:10:38,230
we've seen that we can profile to try to

00:10:36,010 --> 00:10:41,140
optimize or cut path try to remove

00:10:38,230 --> 00:10:42,640
inefficiencies now in our code we can

00:10:41,140 --> 00:10:44,200
also have a look at what's happening for

00:10:42,640 --> 00:10:46,120
the memory allocation because memories

00:10:44,200 --> 00:10:50,740
of an a difficult topic we spark and

00:10:46,120 --> 00:10:52,600
sometimes you need to deep dive to set

00:10:50,740 --> 00:10:55,360
the memory correctly set the memory

00:10:52,600 --> 00:10:58,030
settings correctly and so if once you

00:10:55,360 --> 00:10:59,890
see always memory used by our example

00:10:58,030 --> 00:11:02,800
join on the cluster spark and provide

00:10:59,890 --> 00:11:04,780
that Baba can provide this graph so

00:11:02,800 --> 00:11:06,640
first there is a graph about total use

00:11:04,780 --> 00:11:08,530
memory so here we can see first the

00:11:06,640 --> 00:11:10,810
total JVM heap memory used on your

00:11:08,530 --> 00:11:12,130
cluster so the Java heap memory so that

00:11:10,810 --> 00:11:13,210
is some at any moment in your

00:11:12,130 --> 00:11:15,010
application of

00:11:13,210 --> 00:11:16,840
the amount of heat memory used by all

00:11:15,010 --> 00:11:18,760
your executor receives a true peak at

00:11:16,840 --> 00:11:21,550
200 gigabytes of free memory for this

00:11:18,760 --> 00:11:23,110
example join but heap memories not every

00:11:21,550 --> 00:11:24,700
everything that's on your memory stick

00:11:23,110 --> 00:11:26,140
it's not everything that's on your

00:11:24,700 --> 00:11:27,850
physical memory because you will add on

00:11:26,140 --> 00:11:30,250
top of heap memory you've got some Java

00:11:27,850 --> 00:11:32,140
overhead and you would have some native

00:11:30,250 --> 00:11:35,470
libraries or in stands for compression

00:11:32,140 --> 00:11:38,590
decompression or out of memory and out

00:11:35,470 --> 00:11:40,540
of heap buffers for the shuffle phase so

00:11:38,590 --> 00:11:42,820
by bacchanals to show you the physical

00:11:40,540 --> 00:11:44,620
memory used so we can see that while we

00:11:42,820 --> 00:11:46,990
are using 200 gigabytes of heap memory

00:11:44,620 --> 00:11:48,910
we are actually using 300 gigabytes of

00:11:46,990 --> 00:11:50,500
physical memory so we need to account

00:11:48,910 --> 00:11:53,650
for that when when we are dimensioning

00:11:50,500 --> 00:11:55,420
our job and finally it can show the

00:11:53,650 --> 00:11:57,760
result memory so that the memory you ask

00:11:55,420 --> 00:11:59,290
your cluster to give to your application

00:11:57,760 --> 00:12:01,450
and that's not available to any other

00:11:59,290 --> 00:12:05,320
application the cursor so it's really

00:12:01,450 --> 00:12:07,300
important to not over reserved memory

00:12:05,320 --> 00:12:09,160
because otherwise it's just wasted it's

00:12:07,300 --> 00:12:11,650
not available to other applications and

00:12:09,160 --> 00:12:14,500
you're not using it and so it's very

00:12:11,650 --> 00:12:16,720
important for SPARC jobs and for large

00:12:14,500 --> 00:12:18,190
large applications actually to dimension

00:12:16,720 --> 00:12:19,770
and tune your memory correctly and

00:12:18,190 --> 00:12:21,910
that's often a very difficult topic

00:12:19,770 --> 00:12:23,350
because if you don't treat correctly

00:12:21,910 --> 00:12:26,500
your application will die and if you

00:12:23,350 --> 00:12:31,150
allocate too much you will you will over

00:12:26,500 --> 00:12:32,830
reserve on allocate memory so first one

00:12:31,150 --> 00:12:34,480
thing that you need to set with this bag

00:12:32,830 --> 00:12:37,060
application is the executor memory so

00:12:34,480 --> 00:12:38,860
that's basically the heap memory setting

00:12:37,060 --> 00:12:40,630
and so if we look at another graph that

00:12:38,860 --> 00:12:42,550
Babar provides is a maximum use memory

00:12:40,630 --> 00:12:44,530
for any container so it represents the

00:12:42,550 --> 00:12:45,880
largest container at any time in your

00:12:44,530 --> 00:12:48,070
applications that's very useful to

00:12:45,880 --> 00:12:49,780
dimension as a memory setting so here we

00:12:48,070 --> 00:12:51,610
can see that at most the largest

00:12:49,780 --> 00:12:53,560
container will use at most 5 gigabytes

00:12:51,610 --> 00:12:55,810
of heap memory so we can set the

00:12:53,560 --> 00:12:57,880
executor memory just vs 5 gigabytes

00:12:55,810 --> 00:13:00,940
giving a bit self Headroom

00:12:57,880 --> 00:13:02,440
but not too much so we could give 16

00:13:00,940 --> 00:13:03,940
five gigabytes and so that's the

00:13:02,440 --> 00:13:05,560
executor memory and now we need to

00:13:03,940 --> 00:13:07,570
resolve the memory on the cluster to

00:13:05,560 --> 00:13:09,520
accommodate not only for JVM heap memory

00:13:07,570 --> 00:13:12,610
but for the physical memory as I

00:13:09,520 --> 00:13:14,410
discussed before and so if we look at

00:13:12,610 --> 00:13:17,110
physical memory we see that actually we

00:13:14,410 --> 00:13:19,750
are over seven gigabytes so we need to

00:13:17,110 --> 00:13:21,430
reserve enough memory so that we can

00:13:19,750 --> 00:13:24,010
accommodate for the seven gigabytes so

00:13:21,430 --> 00:13:26,329
we the result memory is a spark is a to

00:13:24,010 --> 00:13:28,220
memory plus the overhead memory

00:13:26,329 --> 00:13:30,829
and so we need to set these values that

00:13:28,220 --> 00:13:32,660
we resolved over seven so approximately

00:13:30,829 --> 00:13:35,420
seven point five gigabytes of memory for

00:13:32,660 --> 00:13:37,459
instance and we can see that we have

00:13:35,420 --> 00:13:39,079
fitting the largest executor tightly

00:13:37,459 --> 00:13:41,029
inside the reserve memory so we are not

00:13:39,079 --> 00:13:43,040
allocating too much and not too little

00:13:41,029 --> 00:13:44,720
otherwise yarn would just kill our

00:13:43,040 --> 00:13:47,360
applications which is a very common

00:13:44,720 --> 00:13:51,579
thing when you're first writing your new

00:13:47,360 --> 00:13:53,809
spark jobs and finally when you're

00:13:51,579 --> 00:13:56,749
dimensioning memory there is offer the

00:13:53,809 --> 00:13:59,629
issue of garbage collection because if

00:13:56,749 --> 00:14:00,799
you allocate too much JVM memory then

00:13:59,629 --> 00:14:02,569
you don't have issues with garbage

00:14:00,799 --> 00:14:04,309
collection but then most of this memory

00:14:02,569 --> 00:14:05,629
is wasted otherwise if you allocate to

00:14:04,309 --> 00:14:08,360
details and garbage collection will be

00:14:05,629 --> 00:14:09,920
we've spent a significant amount of CPU

00:14:08,360 --> 00:14:12,679
time in your application and that's

00:14:09,920 --> 00:14:13,579
probably a bad thing and that's wasted

00:14:12,679 --> 00:14:15,860
CPU time somehow

00:14:13,579 --> 00:14:18,410
so Baba can help you is that as well

00:14:15,860 --> 00:14:21,350
because we can see the garbage

00:14:18,410 --> 00:14:23,779
collection metrics for your executors

00:14:21,350 --> 00:14:25,730
but not only just the garbage fashion

00:14:23,779 --> 00:14:27,649
values that spark will give you but more

00:14:25,730 --> 00:14:29,929
detailed more detailed one because we

00:14:27,649 --> 00:14:32,239
know how much major and minor GC we are

00:14:29,929 --> 00:14:34,249
doing so that's helpful to dimension not

00:14:32,239 --> 00:14:36,799
only your heap memory but also the

00:14:34,249 --> 00:14:39,049
generations inside inside of it and

00:14:36,799 --> 00:14:40,730
we've seen some times with for instance

00:14:39,049 --> 00:14:43,299
machine learning algorithms when we've

00:14:40,730 --> 00:14:45,559
got very large vectors in memory that

00:14:43,299 --> 00:14:47,809
diamond or Reda mentioning generations

00:14:45,559 --> 00:14:52,399
is more important than read I'm

00:14:47,809 --> 00:14:54,049
mentioning the JVM heap memory so as I

00:14:52,399 --> 00:14:55,489
said we've seen that profiling can help

00:14:54,049 --> 00:14:56,899
you first understand what's happening

00:14:55,489 --> 00:15:00,079
inside your applications because these

00:14:56,899 --> 00:15:01,549
frameworks often black boxes when you

00:15:00,079 --> 00:15:03,019
write your first bag job you don't we

00:15:01,549 --> 00:15:04,879
know what's happening underneath and so

00:15:03,019 --> 00:15:07,970
having for instance the stack traces is

00:15:04,879 --> 00:15:10,189
incredibly useful so again it's very

00:15:07,970 --> 00:15:13,579
helpful to optimize what really matters

00:15:10,189 --> 00:15:15,829
and not optimize something that have no

00:15:13,579 --> 00:15:18,290
important so reoptimize in for your cpu

00:15:15,829 --> 00:15:20,989
time provide a profiler is incredibly

00:15:18,290 --> 00:15:22,999
useful and finally it helps understand

00:15:20,989 --> 00:15:25,129
the resources allocation and all to

00:15:22,999 --> 00:15:27,949
better tune it so that your application

00:15:25,129 --> 00:15:30,470
behaves as good as it can on your

00:15:27,949 --> 00:15:32,509
infrastructure and so because this to

00:15:30,470 --> 00:15:33,919
Baba has helped so much we saw

00:15:32,509 --> 00:15:36,079
everything it can be useful to other

00:15:33,919 --> 00:15:38,889
people too and we're open source as I

00:15:36,079 --> 00:15:41,449
said before again it's on github.com

00:15:38,889 --> 00:15:44,539
slash four slash Baba

00:15:41,449 --> 00:15:47,480
it's very simple - very nice to have a

00:15:44,539 --> 00:15:49,429
look at yeah thank you

00:15:47,480 --> 00:15:50,839
so there are many C's that won't fit in

00:15:49,429 --> 00:15:52,610
twenty minutes but if you want to dis

00:15:50,839 --> 00:15:54,410
get about this project or other projects

00:15:52,610 --> 00:15:57,230
we've got at credo we've got a booth in

00:15:54,410 --> 00:15:59,689
the next room and feel free to come see

00:15:57,230 --> 00:16:02,240
us and have a talk with us bunch of us

00:15:59,689 --> 00:16:18,619
are here in Berlin I think we've got

00:16:02,240 --> 00:16:21,579
time for questions right hi thanks for

00:16:18,619 --> 00:16:26,629
the talk so in my experience some jobs

00:16:21,579 --> 00:16:29,899
use a lot of hip memory and I know that

00:16:26,629 --> 00:16:32,329
one thing they use it for is for these

00:16:29,899 --> 00:16:36,459
buffers to read the shuffle files so

00:16:32,329 --> 00:16:39,679
doing about any other thing that that

00:16:36,459 --> 00:16:42,169
that uses this hip memory and why it is

00:16:39,679 --> 00:16:42,529
so large because intuitively I think

00:16:42,169 --> 00:16:46,489
just

00:16:42,529 --> 00:16:48,739
buffers cannot be so so big so yes there

00:16:46,489 --> 00:16:51,799
are few things so buffers for shuffle

00:16:48,739 --> 00:16:53,569
definitely there is also a native codecs

00:16:51,799 --> 00:16:55,429
for compression decompression if you

00:16:53,569 --> 00:16:58,699
write for instance Parkhead files and

00:16:55,429 --> 00:17:00,049
use a gzip or edit for you can get

00:16:58,699 --> 00:17:02,239
better performance by using native

00:17:00,049 --> 00:17:03,679
codecs that's how you can provide they

00:17:02,239 --> 00:17:04,459
need to be compiled for architecture but

00:17:03,679 --> 00:17:06,529
they will provide much better

00:17:04,459 --> 00:17:09,020
performance and they work with our feet

00:17:06,529 --> 00:17:11,360
memory because they are native code so

00:17:09,020 --> 00:17:13,610
things that when you use for instance

00:17:11,360 --> 00:17:15,409
five gigabytes of heap memory Java needs

00:17:13,610 --> 00:17:17,209
to commit more memory so that it has

00:17:15,409 --> 00:17:19,129
available memory to grow your hip and

00:17:17,209 --> 00:17:21,559
this committed memory which is called

00:17:19,129 --> 00:17:23,569
committed memory and Baba can show there

00:17:21,559 --> 00:17:25,699
is a graph for that as well

00:17:23,569 --> 00:17:27,949
will increase the physical memory use

00:17:25,699 --> 00:17:30,260
even if you don't use this available HID

00:17:27,949 --> 00:17:32,269
memory it will be committed and it will

00:17:30,260 --> 00:17:37,480
take some physical memory which is why

00:17:32,269 --> 00:17:37,480
we system so much Headroom of our memory

00:17:39,580 --> 00:17:54,320
yep so we don't we don't run it on so we

00:17:52,879 --> 00:17:57,590
look first we don't run it in production

00:17:54,320 --> 00:17:59,989
because there is still some overhead CPU

00:17:57,590 --> 00:18:01,899
time a few percent at most and memory as

00:17:59,989 --> 00:18:04,489
well and so it's not really desirable

00:18:01,899 --> 00:18:06,350
what we do is we run it on there are

00:18:04,489 --> 00:18:08,360
jobs jobs that we are developing and we

00:18:06,350 --> 00:18:09,769
know they will take a lot of resources

00:18:08,360 --> 00:18:12,080
we want to optimize them before we

00:18:09,769 --> 00:18:13,639
release them to production and for

00:18:12,080 --> 00:18:16,129
production otherwise we uses or tools

00:18:13,639 --> 00:18:19,700
such as dr. elephants for instance made

00:18:16,129 --> 00:18:20,659
by LinkedIn which is doesn't take any

00:18:19,700 --> 00:18:22,220
overhead on your application just

00:18:20,659 --> 00:18:27,070
processes some logs

00:18:22,220 --> 00:18:29,029
the final logs yeah so it's more

00:18:27,070 --> 00:18:31,039
Explorer what's happening before your

00:18:29,029 --> 00:18:35,210
recent pollution but we run sometimes on

00:18:31,039 --> 00:18:37,100
production data sorry I haven't got the

00:18:35,210 --> 00:18:39,440
question maybe it was very similar to my

00:18:37,100 --> 00:18:43,700
question but can you talk a bit about

00:18:39,440 --> 00:18:45,799
the runtime costs so especially so I've

00:18:43,700 --> 00:18:48,980
seen you you're using power for

00:18:45,799 --> 00:18:52,940
reporting right and also you have shown

00:18:48,980 --> 00:18:55,009
some profiling so my assumption would be

00:18:52,940 --> 00:18:57,139
you are not using the profiling in the

00:18:55,009 --> 00:18:59,749
production system right but I using then

00:18:57,139 --> 00:19:04,519
the reporting stuff in production and

00:18:59,749 --> 00:19:06,049
what are the costs there so yeah it was

00:19:04,519 --> 00:19:07,820
a bit similar we don't choose Baba in

00:19:06,049 --> 00:19:10,460
production because there is quite some

00:19:07,820 --> 00:19:13,070
hover we could we've measured it it's a

00:19:10,460 --> 00:19:17,480
few percent in CPU time and it's a few

00:19:13,070 --> 00:19:20,840
dozens of megabytes in memory but what

00:19:17,480 --> 00:19:24,259
Baba provides is probably - too much

00:19:20,840 --> 00:19:26,600
information - to re run it in production

00:19:24,259 --> 00:19:29,840
because you won't be able to do much of

00:19:26,600 --> 00:19:31,609
it we we do use it to optimize the jobs

00:19:29,840 --> 00:19:33,019
before they go to production some very

00:19:31,609 --> 00:19:36,080
large jobs that we know will have a

00:19:33,019 --> 00:19:37,759
large impact on the cluster but for

00:19:36,080 --> 00:19:40,909
production jobs we use other tools such

00:19:37,759 --> 00:19:42,919
as dr. elephant from England which just

00:19:40,909 --> 00:19:45,049
process job contours and will give you

00:19:42,919 --> 00:19:49,549
reports and can also give you hints

00:19:45,049 --> 00:19:51,440
based on heuristics yeah sorry we don't

00:19:49,549 --> 00:19:52,860
have more time for the questions so

00:19:51,440 --> 00:19:53,480
thank you very much

00:19:52,860 --> 00:20:00,380
thank you

00:19:53,480 --> 00:20:00,380

YouTube URL: https://www.youtube.com/watch?v=Tcg5YFxrVsk


