Title: Berlin Buzzwords 2017: Raam Rosh Hai - How to build a recommendation system overnight #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Your CEO runs up to you looking scared. Your competitors are recommending related articles based on context and machine learning and the current ML system keeps crashing.

Our embedded iframe is inside popular news sites with millions of articles and thousands of concurrent visitors, The systemâ€™s uptime should at least match these well established companies. You have to fix it, now.
What do you do? Run? Convince the CEO that Machine Learning and Natural Language Processing are passing trends? Or do you reach for open source tools and set out to do something better than your competitors in just a few days?

We went for the third option; using Elasticsearch, as the heart of this system.

Elasticsearch dynamic templating was used for mappings which support specific types like geopoints and dates but still let users dynamically add fields and events.

We wanted simplicity and reliability in an embarrassingly parallel system, and implemented a reactive streams system. This let us build an asynchronous recommendation engine caching recommendation results in the background so they can be promptly served when asked by the frontend, This has proven resilient enough to give us sleep, simple enough to be maintainable and flexible enough to serve millions of users while keeping costs low.

These kind of scenarios happen on a daily basis; I will demonstrate how the right design decisions got the product out of the door on time, kept management happy and kept us engineers sane despite the time pressures involved. If you are tired of those nightly dinner "treats" here's a solution.

Read more: 
https://2017.berlinbuzzwords.de/17/session/how-build-recommendation-system-overnight

About Raam Rosh Hai:
https://2017.berlinbuzzwords.de/users/raam-rosh-hai

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:07,340 --> 00:00:12,570
hi my name is ROM I'm a data engineer at

00:00:10,440 --> 00:00:14,549
fine hotel and before I lived in

00:00:12,570 --> 00:00:17,550
Amsterdam I work in a small startup that

00:00:14,549 --> 00:00:18,779
had a an engine problem I want to tell

00:00:17,550 --> 00:00:21,990
you the story of how we solve that

00:00:18,779 --> 00:00:24,150
problem we start by quickly explain the

00:00:21,990 --> 00:00:26,609
project requirements and then we go over

00:00:24,150 --> 00:00:28,710
the architecture and why we did what we

00:00:26,609 --> 00:00:30,330
did at the end I will present some

00:00:28,710 --> 00:00:34,320
things that weren't obvious to me from

00:00:30,330 --> 00:00:36,030
the get-go so the main save point of the

00:00:34,320 --> 00:00:37,830
product we were working on was the

00:00:36,030 --> 00:00:40,680
premise to increase the visitors time on

00:00:37,830 --> 00:00:42,269
site we want to help our partners direct

00:00:40,680 --> 00:00:46,080
the users to more content that they

00:00:42,269 --> 00:00:48,479
liked since this product is embedded

00:00:46,080 --> 00:00:50,640
inside the partners page it carries with

00:00:48,479 --> 00:00:52,379
it a few problems we don't know when new

00:00:50,640 --> 00:00:56,220
content is added and we have no

00:00:52,379 --> 00:00:57,809
straightforward way to find out the

00:00:56,220 --> 00:00:59,460
obvious choice is to scrape the partners

00:00:57,809 --> 00:01:00,930
website periodically and index changes

00:00:59,460 --> 00:01:04,320
to a database this is very

00:01:00,930 --> 00:01:06,180
labor-intensive having to create scraper

00:01:04,320 --> 00:01:07,770
for each partner this solution we

00:01:06,180 --> 00:01:09,750
obviously not scale to a time when

00:01:07,770 --> 00:01:12,899
partners will be added interactively and

00:01:09,750 --> 00:01:15,270
not manually by our sales team we plan

00:01:12,899 --> 00:01:17,549
to cut our customers to always display a

00:01:15,270 --> 00:01:19,229
recommendation this meant was that the

00:01:17,549 --> 00:01:21,179
bed answer is better than no answer

00:01:19,229 --> 00:01:23,070
nonetheless the commendation should

00:01:21,179 --> 00:01:26,009
still be useful otherwise nobody would

00:01:23,070 --> 00:01:27,869
click on them these clients that

00:01:26,009 --> 00:01:30,060
symbolize our project in the website has

00:01:27,869 --> 00:01:32,159
much bigger things than ours the uptime

00:01:30,060 --> 00:01:34,950
is quite oppressive they serve news to a

00:01:32,159 --> 00:01:36,659
large portion of Internet users and it's

00:01:34,950 --> 00:01:41,729
a season scratch it will directly affect

00:01:36,659 --> 00:01:43,920
their pages we knew where to deliver

00:01:41,729 --> 00:01:45,899
this feature quickly since the current

00:01:43,920 --> 00:01:48,869
accommodation system we had was not very

00:01:45,899 --> 00:01:52,319
variable it was not seven commendations

00:01:48,869 --> 00:01:54,149
most of the time keeping the steps in

00:01:52,319 --> 00:01:55,770
the process status greatly reduced the

00:01:54,149 --> 00:01:56,880
complexity of our application we could

00:01:55,770 --> 00:01:59,939
treat each part of the program

00:01:56,880 --> 00:02:01,560
independently this meant we can fit the

00:01:59,939 --> 00:02:04,979
whole thing in a head and also grab the

00:02:01,560 --> 00:02:06,679
components easy to change what it is I'm

00:02:04,979 --> 00:02:09,240
making sure data flows in one direction

00:02:06,679 --> 00:02:10,979
inside the pipeline this way we could

00:02:09,240 --> 00:02:14,220
carry all the data we need forward

00:02:10,979 --> 00:02:16,500
throughout transformation steps to solve

00:02:14,220 --> 00:02:19,290
our first program in the king old and

00:02:16,500 --> 00:02:21,390
new articles when they are posted

00:02:19,290 --> 00:02:23,939
we use the fact that users view these

00:02:21,390 --> 00:02:25,950
pages each view would then generate the

00:02:23,939 --> 00:02:27,629
post request which indexes the quickly

00:02:25,950 --> 00:02:31,829
visited page and trigger the commutation

00:02:27,629 --> 00:02:34,140
generation I was surprised to find out

00:02:31,829 --> 00:02:38,640
that the published articles can have the

00:02:34,140 --> 00:02:41,129
body tags and even titles changed so

00:02:38,640 --> 00:02:45,060
constantly indexing these Capitol

00:02:41,129 --> 00:02:47,159
commendations fresh we quickly quickly

00:02:45,060 --> 00:02:48,780
realize we don't have enough manpower or

00:02:47,159 --> 00:02:52,349
budget to maintain a public-facing

00:02:48,780 --> 00:02:56,819
elasticsearch cluster within a small

00:02:52,349 --> 00:02:58,079
team we're only two people so we use

00:02:56,819 --> 00:02:59,909
elastic search capabilities as

00:02:58,079 --> 00:03:01,620
computation engine sending simple

00:02:59,909 --> 00:03:03,950
queries getting a list of results back

00:03:01,620 --> 00:03:05,730
and persisting them in the object store

00:03:03,950 --> 00:03:08,430
assisting the results of the object

00:03:05,730 --> 00:03:10,049
store allows us to run a tiny cluster we

00:03:08,430 --> 00:03:12,709
could control the request rate and apply

00:03:10,049 --> 00:03:15,450
back pressure when needed

00:03:12,709 --> 00:03:16,980
only the ARCA streams application had

00:03:15,450 --> 00:03:19,290
access to the elastic search cluster

00:03:16,980 --> 00:03:23,760
which ensured control overloads on the

00:03:19,290 --> 00:03:25,319
system serving the suggestions for the

00:03:23,760 --> 00:03:27,150
data store allows us to focus on

00:03:25,319 --> 00:03:29,699
delivering delivering value and not

00:03:27,150 --> 00:03:32,040
focusing on extinguishing fires when the

00:03:29,699 --> 00:03:34,019
system crashes so even if you did crash

00:03:32,040 --> 00:03:35,549
no one would notice it because all of

00:03:34,019 --> 00:03:40,319
the other Commendation was still being

00:03:35,549 --> 00:03:42,239
served we didn't have to do too much to

00:03:40,319 --> 00:03:45,120
set up elastic search to do what we

00:03:42,239 --> 00:03:46,470
needed we use the dynamic templates to

00:03:45,120 --> 00:03:48,870
define text fields with the correct

00:03:46,470 --> 00:03:51,900
analyzers this way we didn't have extra

00:03:48,870 --> 00:03:55,470
work when the model change or when we

00:03:51,900 --> 00:03:57,090
want to add more languages the English

00:03:55,470 --> 00:03:59,940
our analyzer has a list of support

00:03:57,090 --> 00:04:02,220
redefined and stemming support which

00:03:59,940 --> 00:04:05,940
fits well with the text with humans we'd

00:04:02,220 --> 00:04:07,139
and we use some dynamic templates we

00:04:05,940 --> 00:04:08,790
could define the text field to be

00:04:07,139 --> 00:04:10,590
indexing the raw form which have which

00:04:08,790 --> 00:04:15,209
is helpful for things you want to match

00:04:10,590 --> 00:04:16,650
as is like tags using this template we

00:04:15,209 --> 00:04:17,970
could dynamically add languages an

00:04:16,650 --> 00:04:19,440
indexing we didn't have to waste our

00:04:17,970 --> 00:04:23,610
time on fiddling with too many settings

00:04:19,440 --> 00:04:26,039
which reduced unplanned work the query

00:04:23,610 --> 00:04:28,260
we used was very simple we put each

00:04:26,039 --> 00:04:29,909
field from a JSON object into a stem

00:04:28,260 --> 00:04:32,120
quarry and fill the filtered by time

00:04:29,909 --> 00:04:32,120
range

00:04:32,790 --> 00:04:36,940
you can see we use the rough fields for

00:04:35,050 --> 00:04:39,340
things we had to exactly match like IDs

00:04:36,940 --> 00:04:43,870
keywords and the analyzed field for the

00:04:39,340 --> 00:04:45,310
title in description we also filter out

00:04:43,870 --> 00:04:48,430
the current article watch animating

00:04:45,310 --> 00:04:50,740
suggest suggestions for from the results

00:04:48,430 --> 00:04:53,350
because obviously each article always

00:04:50,740 --> 00:04:56,830
matched itself and we don't want it in

00:04:53,350 --> 00:04:58,450
the results list so the result of this

00:04:56,830 --> 00:05:00,400
query is then sorted by score and

00:04:58,450 --> 00:05:05,200
posited to an object or ready to be

00:05:00,400 --> 00:05:08,200
served to all of our users now when I

00:05:05,200 --> 00:05:09,610
imagine what the queue does a picture

00:05:08,200 --> 00:05:11,350
something like this a conference of

00:05:09,610 --> 00:05:15,040
streams being pulled to a central

00:05:11,350 --> 00:05:16,419
repository the mental model for picking

00:05:15,040 --> 00:05:18,550
things from queue is far more

00:05:16,419 --> 00:05:22,479
straightforward than a web front-end

00:05:18,550 --> 00:05:24,639
this lets us abstract away all but all

00:05:22,479 --> 00:05:27,510
but everything by the data we have to

00:05:24,639 --> 00:05:29,530
work on and we can only focus on that

00:05:27,510 --> 00:05:31,030
we're in control of the data so

00:05:29,530 --> 00:05:32,260
application can simply request a piece

00:05:31,030 --> 00:05:35,770
of work and start working on it

00:05:32,260 --> 00:05:37,300
immediately this allows us to twist to

00:05:35,770 --> 00:05:39,550
treat our incoming traffic as a string

00:05:37,300 --> 00:05:41,500
of data coming in one way being

00:05:39,550 --> 00:05:43,560
transformed and passed forward which

00:05:41,500 --> 00:05:47,350
allows impaired embarrassingly parallel

00:05:43,560 --> 00:05:49,890
applications like ours to the just work

00:05:47,350 --> 00:05:52,600
in parallel with very little overhead

00:05:49,890 --> 00:05:53,860
another adventure of using queue of a

00:05:52,600 --> 00:05:56,320
connecting the computation engine

00:05:53,860 --> 00:05:57,640
directly to HTTP front-end is that we

00:05:56,320 --> 00:05:59,140
could recover the collection process

00:05:57,640 --> 00:06:01,090
from the transformations we wanted to

00:05:59,140 --> 00:06:02,620
apply to our entities and finally we

00:06:01,090 --> 00:06:05,820
could of course replace the cute

00:06:02,620 --> 00:06:05,820
messages in case of a failure

00:06:07,780 --> 00:06:13,370
so we end up with a classic lambda shape

00:06:10,960 --> 00:06:15,560
we use the Q to melt all of our traffic

00:06:13,370 --> 00:06:17,390
and treat it as a single source we then

00:06:15,560 --> 00:06:19,010
press the messages from the queue to our

00:06:17,390 --> 00:06:21,620
computation engine producing a list of

00:06:19,010 --> 00:06:26,210
accommodations which are then persisted

00:06:21,620 --> 00:06:28,040
to our object store this was just sorry

00:06:26,210 --> 00:06:29,900
this object store should expose the

00:06:28,040 --> 00:06:33,110
public API so we will have direct access

00:06:29,900 --> 00:06:35,420
to the data F 3 which is what we use

00:06:33,110 --> 00:06:38,840
does it out of the box but you can also

00:06:35,420 --> 00:06:42,410
use ready ladies behind engine X or any

00:06:38,840 --> 00:06:43,970
key value engine so setting the

00:06:42,410 --> 00:06:46,100
precomputed recommendations from the

00:06:43,970 --> 00:06:48,380
objects or further decouple serving the

00:06:46,100 --> 00:06:50,780
data from digesting is giving us two

00:06:48,380 --> 00:06:56,300
tracks a one-way track for ingesting

00:06:50,780 --> 00:06:58,430
data and another one for setting it this

00:06:56,300 --> 00:07:02,540
mental model translates very naturally

00:06:58,430 --> 00:07:04,400
into Skyline occur streams we start with

00:07:02,540 --> 00:07:05,960
the source in our case with Paul for

00:07:04,400 --> 00:07:07,670
changes and once we get them that

00:07:05,960 --> 00:07:11,180
published downstream to the

00:07:07,670 --> 00:07:12,670
transformation steps we convert the

00:07:11,180 --> 00:07:16,700
incoming payload to a domain object

00:07:12,670 --> 00:07:18,530
index it the indexing step is used for

00:07:16,700 --> 00:07:21,380
scraping our partners and keeping the

00:07:18,530 --> 00:07:22,970
elastic search index up-to-date with a

00:07:21,380 --> 00:07:25,850
query elastic search with the same data

00:07:22,970 --> 00:07:28,880
that payload we just indexed and made to

00:07:25,850 --> 00:07:32,120
create a list of recommendations and if

00:07:28,880 --> 00:07:33,920
it's a new article it will produce fresh

00:07:32,120 --> 00:07:35,600
recommendations it was never seen in the

00:07:33,920 --> 00:07:38,030
object store but if it was already

00:07:35,600 --> 00:07:41,500
scenes we just overwrite the same key

00:07:38,030 --> 00:07:41,500
and then we have updated recommendations

00:07:41,830 --> 00:07:45,970
the list of recommendations then purge

00:07:43,880 --> 00:07:48,530
to the other store immediately pivot

00:07:45,970 --> 00:07:51,560
now since indexing the articles and

00:07:48,530 --> 00:07:52,880
searching for them have no dependency we

00:07:51,560 --> 00:07:55,670
can tell occur streams that this part

00:07:52,880 --> 00:07:57,940
could be done in parallel so we just

00:07:55,670 --> 00:08:04,040
change map to map async

00:07:57,940 --> 00:08:05,270
easy so what worked well after looking

00:08:04,040 --> 00:08:07,850
at the problem in understanding it

00:08:05,270 --> 00:08:10,580
understanding it we threw away all the

00:08:07,850 --> 00:08:13,880
scraping code we had and we use user

00:08:10,580 --> 00:08:18,350
pages users page view to index a

00:08:13,880 --> 00:08:20,180
partner's content so we got rid of

00:08:18,350 --> 00:08:20,889
technical debt we got rid of a lot of

00:08:20,180 --> 00:08:25,300
code

00:08:20,889 --> 00:08:28,580
dedicating it it is pretty nice Chris

00:08:25,300 --> 00:08:31,490
now I noticed all our partners are using

00:08:28,580 --> 00:08:33,229
HTML meta tags these tags are used for

00:08:31,490 --> 00:08:34,669
sharing in social networks so the

00:08:33,229 --> 00:08:39,440
partners usually put some thought into

00:08:34,669 --> 00:08:41,240
them decade valuable information so we

00:08:39,440 --> 00:08:42,709
parse HTML tags on these pages we

00:08:41,240 --> 00:08:43,729
excited all the needed information on

00:08:42,709 --> 00:08:46,639
the article and generated

00:08:43,729 --> 00:08:48,259
recommendations for it this also meant

00:08:46,639 --> 00:08:50,509
we could turn off the scripting engine

00:08:48,259 --> 00:08:54,040
which cuts operation costs of course in

00:08:50,509 --> 00:08:54,040
the technical data I mentioned before

00:08:54,130 --> 00:08:58,490
the second big win was realizing we

00:08:57,019 --> 00:09:00,680
could use an object store to save the

00:08:58,490 --> 00:09:02,839
commendations this saved us a lot of

00:09:00,680 --> 00:09:05,690
stress since we only had to guarantee

00:09:02,839 --> 00:09:08,389
the object store is running which in

00:09:05,690 --> 00:09:12,170
which was in our case a service on AWS

00:09:08,389 --> 00:09:14,569
so we didn't have to do anything occur

00:09:12,170 --> 00:09:16,880
streams is a great example of reactive

00:09:14,569 --> 00:09:18,500
streams implementation it Maps very

00:09:16,880 --> 00:09:20,089
nicely into the metamodel stream

00:09:18,500 --> 00:09:22,870
processing and transformations which

00:09:20,089 --> 00:09:25,459
greatly increase the productivity

00:09:22,870 --> 00:09:27,170
another advantage of our streams is the

00:09:25,459 --> 00:09:28,399
async abstraction that lets you write

00:09:27,170 --> 00:09:29,870
the application as you normally would

00:09:28,399 --> 00:09:33,649
but see that you've leveraged all

00:09:29,870 --> 00:09:35,240
available codes using docker was another

00:09:33,649 --> 00:09:37,759
good bet with that paid off it gave us

00:09:35,240 --> 00:09:38,990
producible bills which has a sketch many

00:09:37,759 --> 00:09:40,850
bugs we would usually catch in

00:09:38,990 --> 00:09:43,160
production like environment sensitive

00:09:40,850 --> 00:09:44,149
config and all sorts of dependencies

00:09:43,160 --> 00:09:47,779
that had to be bundled with the

00:09:44,149 --> 00:09:49,250
application so backing the application

00:09:47,779 --> 00:09:51,290
logic inside document we could try

00:09:49,250 --> 00:09:57,069
different environmental deployments very

00:09:51,290 --> 00:10:00,079
easily but it's not all orders it became

00:09:57,069 --> 00:10:01,910
clear quite quickly that you can make

00:10:00,079 --> 00:10:04,189
people learn Scala but you can't make

00:10:01,910 --> 00:10:06,230
them change the way of thinking they

00:10:04,189 --> 00:10:07,850
have to be willing to do so so although

00:10:06,230 --> 00:10:10,130
functional programming concepts are

00:10:07,850 --> 00:10:13,430
quite easy to explain they are not that

00:10:10,130 --> 00:10:15,230
convincing your colleagues will have to

00:10:13,430 --> 00:10:17,540
elevate a pain the encountering using

00:10:15,230 --> 00:10:22,759
the new paradigm before they are sold on

00:10:17,540 --> 00:10:25,160
this idea another thing was a monitoring

00:10:22,759 --> 00:10:26,480
disability application is hard as always

00:10:25,160 --> 00:10:28,579
this one is no exception

00:10:26,480 --> 00:10:30,180
the nature of stream processing can make

00:10:28,579 --> 00:10:32,740
it even more OPEC

00:10:30,180 --> 00:10:34,600
safety because of explainin see to

00:10:32,740 --> 00:10:38,020
swellow arrows if you need to explicitly

00:10:34,600 --> 00:10:40,540
handle the solution so this is very

00:10:38,020 --> 00:10:42,730
simple actually implementing modeling

00:10:40,540 --> 00:10:44,380
from the get-go and then when you've got

00:10:42,730 --> 00:10:49,750
encounter problems you know where to

00:10:44,380 --> 00:10:51,520
look so to conclude I want to suggest

00:10:49,750 --> 00:10:53,290
that you try solve the specific

00:10:51,520 --> 00:10:55,600
screaming for problem that you have

00:10:53,290 --> 00:10:58,030
right now using a functional programming

00:10:55,600 --> 00:10:59,740
approach this will let you experience

00:10:58,030 --> 00:11:03,430
the fluidity of the little paradigm

00:10:59,740 --> 00:11:05,650
allows the more use functional

00:11:03,430 --> 00:11:08,230
programming concepts the easier it is to

00:11:05,650 --> 00:11:10,210
think in this way like any other thing

00:11:08,230 --> 00:11:11,860
the direct mapping between the lambda

00:11:10,210 --> 00:11:13,600
architecture and the extremes make it

00:11:11,860 --> 00:11:18,750
very easy to define the businessman in

00:11:13,600 --> 00:11:21,100
terms of code this is this notion in

00:11:18,750 --> 00:11:22,330
Judaism I think in most other religions

00:11:21,100 --> 00:11:23,050
that you have to experience things

00:11:22,330 --> 00:11:25,480
yourself

00:11:23,050 --> 00:11:28,450
in order to believe it believe in it you

00:11:25,480 --> 00:11:29,680
can't explain why you should believe in

00:11:28,450 --> 00:11:32,380
something can't explain why you should

00:11:29,680 --> 00:11:34,480
do something only once you do it you

00:11:32,380 --> 00:11:36,700
understand so I really think that with

00:11:34,480 --> 00:11:39,040
the functional problem programming this

00:11:36,700 --> 00:11:41,950
is the same I can talk about free monads

00:11:39,040 --> 00:11:44,410
until the cows come home but no one will

00:11:41,950 --> 00:11:46,420
use it unless they can really understand

00:11:44,410 --> 00:11:52,570
what they are what they are solving in

00:11:46,420 --> 00:11:54,670
their own doing and nobody wants to read

00:11:52,570 --> 00:11:58,170
the terms of log files going to spot a

00:11:54,670 --> 00:12:00,220
problem this might not even be logged so

00:11:58,170 --> 00:12:01,690
there's a great collection of libraries

00:12:00,220 --> 00:12:02,860
that allows monitoring and estimating

00:12:01,690 --> 00:12:05,140
these to do these applications

00:12:02,860 --> 00:12:09,340
kay moon is one of them and so with age

00:12:05,140 --> 00:12:10,990
trace you can check out a stream size if

00:12:09,340 --> 00:12:12,760
you plan on using ARCA streams it was

00:12:10,990 --> 00:12:14,410
designed with the streams in mind and

00:12:12,760 --> 00:12:16,150
all you have to do is in order to

00:12:14,410 --> 00:12:21,990
instrumental application is to add the

00:12:16,150 --> 00:12:21,990
config file what are your questions

00:12:30,860 --> 00:12:36,680
hi I have a question which is did you

00:12:34,670 --> 00:12:38,690
use any tooling to actually process the

00:12:36,680 --> 00:12:40,730
generated monitoring data how did you

00:12:38,690 --> 00:12:44,660
analyze all the stuff that could go

00:12:40,730 --> 00:13:02,240
recorded to generate it can we have this

00:12:44,660 --> 00:13:04,790
mic on yes yes so we actually use an H

00:13:02,240 --> 00:13:06,650
trace and the the library I mentioned

00:13:04,790 --> 00:13:08,750
before is sending all of the trace

00:13:06,650 --> 00:13:11,150
records to Zeppelin the thing is a

00:13:08,750 --> 00:13:16,130
really nice phantom that just visualizes

00:13:11,150 --> 00:13:17,570
all of the latency in each step of your

00:13:16,130 --> 00:13:20,230
of your pipeline or when your meet

00:13:17,570 --> 00:13:23,030
microservices so basically if you can

00:13:20,230 --> 00:13:25,940
you can just open it and have a look and

00:13:23,030 --> 00:13:27,890
if you see like a really long like

00:13:25,940 --> 00:13:32,090
graphic you know you have a hot spot

00:13:27,890 --> 00:13:39,500
there and you should look into it thank

00:13:32,090 --> 00:13:43,000
you where else you can lovely and then I

00:13:39,500 --> 00:13:43,000
will remember to a bit a next question

00:13:47,560 --> 00:13:55,820
yes Bob this is actually before Estes

00:13:51,820 --> 00:13:59,300
yes policies if I can elaborate on how

00:13:55,820 --> 00:14:03,350
we model users so I did mention that but

00:13:59,300 --> 00:14:06,260
it wasn't you know specific we we came

00:14:03,350 --> 00:14:08,300
from the assumption that if users read

00:14:06,260 --> 00:14:09,590
the current articles everything there

00:14:08,300 --> 00:14:13,700
are probably interested in things like

00:14:09,590 --> 00:14:19,820
that and we just do that we could use

00:14:13,700 --> 00:14:22,460
users you simply if you simply simply

00:14:19,820 --> 00:14:24,350
index the user and then you hope it

00:14:22,460 --> 00:14:26,630
would be the same because if you can tag

00:14:24,350 --> 00:14:29,570
it with whatever if you have extra data

00:14:26,630 --> 00:14:34,569
on on him depends on whatever you have

00:14:29,570 --> 00:14:38,480
you can match age you can match

00:14:34,569 --> 00:14:41,290
what city whatever and combined it with

00:14:38,480 --> 00:14:44,120
the actual articles you are using now I

00:14:41,290 --> 00:14:46,250
was thinking about putting it in the

00:14:44,120 --> 00:14:48,139
slide but you can actually use for users

00:14:46,250 --> 00:14:51,589
you can use stuff like neo4j

00:14:48,139 --> 00:14:53,779
just take out elasticsearch used instead

00:14:51,589 --> 00:14:58,300
and because everything is typed you will

00:14:53,779 --> 00:14:58,300
only have to change this specific part

00:15:06,250 --> 00:15:11,480
if you or your colleague already

00:15:09,230 --> 00:15:14,029
collects prints before either you learn

00:15:11,480 --> 00:15:16,550
kinda what you were doing the good

00:15:14,029 --> 00:15:18,620
question so I had I did have a skull

00:15:16,550 --> 00:15:21,889
experience but my colleagues didn't and

00:15:18,620 --> 00:15:24,170
especially when the system was done was

00:15:21,889 --> 00:15:25,790
had to go to like maintenance those

00:15:24,170 --> 00:15:29,449
people didn't have any kind of skull

00:15:25,790 --> 00:15:32,389
experience and there was one instance

00:15:29,449 --> 00:15:35,269
when this really smart developer that

00:15:32,389 --> 00:15:36,860
was maintaining the code he spent like

00:15:35,269 --> 00:15:42,139
two days on trying to understand the

00:15:36,860 --> 00:15:45,220
distance between dot : + + space : + and

00:15:42,139 --> 00:15:49,339
there is no difference it's just like

00:15:45,220 --> 00:15:53,899
IntelliJ quick so communicating a lot is

00:15:49,339 --> 00:15:56,000
really important and not throwing the

00:15:53,899 --> 00:16:00,199
developers into that it is really nice

00:15:56,000 --> 00:16:02,689
doing this really slowly letting them

00:16:00,199 --> 00:16:05,899
understand why they should use this is a

00:16:02,689 --> 00:16:08,329
much better than just like here's like a

00:16:05,899 --> 00:16:16,320
bunch of modern monitors formers please

00:16:08,329 --> 00:16:18,570
have fun with it so yeah do it slowly ok

00:16:16,320 --> 00:16:22,009
thank you very much they're given

00:16:18,570 --> 00:16:22,009

YouTube URL: https://www.youtube.com/watch?v=cCOnrjKr85I


