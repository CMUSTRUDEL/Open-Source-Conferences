Title: Berlin Buzzwords 2017: Holden Karau - A Brief Tour of the Magic Behind Apache Spark #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Apache Spark is one the most popular general purpose distributed systems in the past few years. Apache Spark has APIs in Scala, Java, Python and more recently a few different attempts to provide support for R, C#, and Julia.

This talk covers the core concepts of Apache Spark, but then switches gears into how the "magic" of Spark can have unintended consequences on your programs. You will gain a better understanding of impact of lazy evaluation, the shift away from arbitrary lambda expressions to "statements", and of course the "dreaded" shuffle (plus a few more concepts). 

Read more:
https://2017.berlinbuzzwords.de/17/session/brief-tour-magic-behind-apache-spark

About Holden Karau:
https://2017.berlinbuzzwords.de/users/holden-karau

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:06,560 --> 00:00:12,120
thank you all for having me yeah so this

00:00:09,300 --> 00:00:14,879
is a very brief tour of the magic behind

00:00:12,120 --> 00:00:16,350
spark they only have 20 minutes so we

00:00:14,879 --> 00:00:19,350
will leave a lot of the magic behind

00:00:16,350 --> 00:00:22,619
it's very sad and my co-presenter today

00:00:19,350 --> 00:00:26,369
is boo she is wearing her witch's hat

00:00:22,619 --> 00:00:30,779
for for the magic part she she's very

00:00:26,369 --> 00:00:32,400
she likes magic a lot yeah so my name is

00:00:30,779 --> 00:00:34,230
Holden my preferred pronouns are here

00:00:32,400 --> 00:00:37,650
her it's tattooed on my wrist in case

00:00:34,230 --> 00:00:39,630
you forget and I'm a principal software

00:00:37,650 --> 00:00:42,060
engineer at IBM's Park Technology Center

00:00:39,630 --> 00:00:45,000
in San Francisco I like it to give me

00:00:42,060 --> 00:00:47,490
money to work on open-source I'm a sport

00:00:45,000 --> 00:00:49,500
committer but I mostly work on Python so

00:00:47,490 --> 00:00:52,380
if things are broken I will blame

00:00:49,500 --> 00:00:54,660
someone else if they work I will take

00:00:52,380 --> 00:00:57,060
credit and they've worked with a bunch

00:00:54,660 --> 00:00:59,670
of other companies before IBM on a bunch

00:00:57,060 --> 00:01:00,930
of distributed system stuff if you want

00:00:59,670 --> 00:01:04,229
to follow me on Twitter it's just my

00:01:00,930 --> 00:01:06,180
name Holden Caro right now it's mostly

00:01:04,229 --> 00:01:09,480
someone being kind of really sad about

00:01:06,180 --> 00:01:11,160
living in America and the slides from

00:01:09,480 --> 00:01:15,480
today and my other talks will go on

00:01:11,160 --> 00:01:18,600
SlideShare and I have some other spark

00:01:15,480 --> 00:01:21,570
videos if you want to see a longer

00:01:18,600 --> 00:01:24,600
version with more magic you can you can

00:01:21,570 --> 00:01:27,270
find different magic on YouTube and some

00:01:24,600 --> 00:01:30,240
of my other talks and just to be like

00:01:27,270 --> 00:01:31,800
super clear I added the slide after the

00:01:30,240 --> 00:01:35,370
American election which made me really

00:01:31,800 --> 00:01:37,700
sad but I'm trans and queer and Canadian

00:01:35,370 --> 00:01:39,840
I'm on a work visa where I where I live

00:01:37,700 --> 00:01:42,960
and it's when they're talking about

00:01:39,840 --> 00:01:44,970
taking away so that's fun

00:01:42,960 --> 00:01:47,280
and I consider myself so part of the

00:01:44,970 --> 00:01:49,200
project out there community and this is

00:01:47,280 --> 00:01:50,880
really just like I mean if you don't

00:01:49,200 --> 00:01:52,830
know other people like me we're normal

00:01:50,880 --> 00:01:55,229
people we write the same shitty spark

00:01:52,830 --> 00:01:57,540
jobs that you do we get out of memory

00:01:55,229 --> 00:01:59,040
exceptions I don't have a secret Java

00:01:57,540 --> 00:02:02,130
garbage collector that I'm hiding from

00:01:59,040 --> 00:02:04,710
you right like we're all just software

00:02:02,130 --> 00:02:07,100
developers and we're nice people or I

00:02:04,710 --> 00:02:12,110
mean close enough right

00:02:07,100 --> 00:02:15,970
hmmm this is my employer they give me

00:02:12,110 --> 00:02:18,470
money so they get a slide we have this

00:02:15,970 --> 00:02:20,900
very nice-looking Lobby with a lot of

00:02:18,470 --> 00:02:22,720
green in it which is supposed to

00:02:20,900 --> 00:02:25,190
indicate that we make good software

00:02:22,720 --> 00:02:28,400
because green is the color of a passing

00:02:25,190 --> 00:02:31,880
Jenkins build so a green Lobby means

00:02:28,400 --> 00:02:34,010
that your software totally works if

00:02:31,880 --> 00:02:36,110
you're ever considering buying something

00:02:34,010 --> 00:02:39,550
from IBM I don't know what it is we sell

00:02:36,110 --> 00:02:43,069
anymore but please buy it

00:02:39,550 --> 00:02:44,870
yeah whatever the yeah oh and I'm not

00:02:43,069 --> 00:02:47,330
alone like I work with a bunch of other

00:02:44,870 --> 00:02:50,450
people on SPARC and they're nice people

00:02:47,330 --> 00:02:51,800
as well so we're going to talk about oh

00:02:50,450 --> 00:02:53,300
wait I'm going to assume you're nice

00:02:51,800 --> 00:02:54,950
people you've laughed at many of my

00:02:53,300 --> 00:02:57,590
really crappy jokes so we're off to a

00:02:54,950 --> 00:02:59,209
good start I am really curious though

00:02:57,590 --> 00:03:01,190
how many people are completely new to

00:02:59,209 --> 00:03:06,650
Apache spark is this anyone's for a

00:03:01,190 --> 00:03:09,290
spark talk okay cool um this talk is

00:03:06,650 --> 00:03:11,690
probably not the best introduction to

00:03:09,290 --> 00:03:13,640
spark um because we we try and look

00:03:11,690 --> 00:03:16,340
behind the covers a little bit hopefully

00:03:13,640 --> 00:03:18,230
you'll still find it useful but you

00:03:16,340 --> 00:03:20,480
probably want to check out Paco's

00:03:18,230 --> 00:03:24,730
introduction to spark talk after this if

00:03:20,480 --> 00:03:27,560
I don't scare you away from using spark

00:03:24,730 --> 00:03:32,329
how many people are like diehard our

00:03:27,560 --> 00:03:34,700
users really okay how many people are

00:03:32,329 --> 00:03:39,620
diehard our users that don't use Python

00:03:34,700 --> 00:03:42,079
I would thank God okay um so all of the

00:03:39,620 --> 00:03:42,680
examples are in the scholar Python ah so

00:03:42,079 --> 00:03:45,079
good

00:03:42,680 --> 00:03:46,970
I don't know R well enough yet so for

00:03:45,079 --> 00:03:49,100
the people who are new to spark why why

00:03:46,970 --> 00:03:50,420
should you be thinking about spark so I

00:03:49,100 --> 00:03:52,880
think a lot of people come to spark

00:03:50,420 --> 00:03:56,030
because they have a MapReduce job

00:03:52,880 --> 00:03:58,489
they're running it and sixteen well

00:03:56,030 --> 00:04:00,709
eight hours into their 16 24 hour job

00:03:58,489 --> 00:04:04,040
they're like I bet I can learn spark

00:04:00,709 --> 00:04:05,540
before this finishes and yes you can you

00:04:04,040 --> 00:04:08,269
can learn spark in the time it takes a

00:04:05,540 --> 00:04:09,910
MapReduce job to run the API is pretty

00:04:08,269 --> 00:04:12,650
simple

00:04:09,910 --> 00:04:14,870
the other reason that people come is

00:04:12,650 --> 00:04:16,820
their data frames stopped fitting in

00:04:14,870 --> 00:04:18,380
their MacBook Pros main memory and

00:04:16,820 --> 00:04:20,250
they're like the solution to this

00:04:18,380 --> 00:04:25,050
problem is distributed systems

00:04:20,250 --> 00:04:26,940
and now they have n problems but on the

00:04:25,050 --> 00:04:28,590
other hand their code might work so

00:04:26,940 --> 00:04:30,450
hopefully one of these things is

00:04:28,590 --> 00:04:36,480
relevant to you but the reason we're all

00:04:30,450 --> 00:04:38,940
here today is magic okay cool let's do

00:04:36,480 --> 00:04:41,550
some magic um so there's a lot of magic

00:04:38,940 --> 00:04:46,290
aids that makes spark as a distributed

00:04:41,550 --> 00:04:48,930
system like work or like computer

00:04:46,290 --> 00:04:51,330
answers the dag and the query planner

00:04:48,930 --> 00:04:53,310
are really like the core building block

00:04:51,330 --> 00:04:55,320
of the magic of spark it's the part

00:04:53,310 --> 00:04:56,480
which lets us optimizer do all sorts of

00:04:55,320 --> 00:04:59,460
really cool things

00:04:56,480 --> 00:05:01,740
spark is lazily evaluated and as a

00:04:59,460 --> 00:05:03,210
result spark doesn't actually do the

00:05:01,740 --> 00:05:05,100
things we asked it to do until we

00:05:03,210 --> 00:05:08,490
absolutely force it kind of like a

00:05:05,100 --> 00:05:10,950
really lazy 16-year old who's like yeah

00:05:08,490 --> 00:05:12,240
yeah I took out the garbage Oh fine okay

00:05:10,950 --> 00:05:13,650
you want to go check I'll actually take

00:05:12,240 --> 00:05:16,710
out the garbage

00:05:13,650 --> 00:05:18,570
but unlike your lazy 16 year old spark

00:05:16,710 --> 00:05:21,440
is able to use this to do pipelining and

00:05:18,570 --> 00:05:24,450
combined a lot of steps and save time

00:05:21,440 --> 00:05:26,490
the other thing which I think is really

00:05:24,450 --> 00:05:28,440
important as a distributed system is

00:05:26,490 --> 00:05:30,900
sparks resiliency model is a little bit

00:05:28,440 --> 00:05:33,270
different than some other traditional

00:05:30,900 --> 00:05:35,610
distributed systems so it depends on

00:05:33,270 --> 00:05:37,860
recompute rather than sort of

00:05:35,610 --> 00:05:39,750
traditional resiliency of saving results

00:05:37,860 --> 00:05:41,160
out to a bunch of different machines and

00:05:39,750 --> 00:05:43,410
this is really important because the

00:05:41,160 --> 00:05:46,380
only thing slower than a disk is three

00:05:43,410 --> 00:05:49,800
disks over our network and that's sort

00:05:46,380 --> 00:05:52,290
of the traditional resiliency model and

00:05:49,800 --> 00:05:53,729
we can also do interesting operations

00:05:52,290 --> 00:05:57,720
without the serialization because

00:05:53,729 --> 00:05:58,950
someone spent too much time drinking and

00:05:57,720 --> 00:06:00,930
we'll we'll look at some of these

00:05:58,950 --> 00:06:03,210
different pieces of magic but we're not

00:06:00,930 --> 00:06:04,710
going to cover all of them there was a

00:06:03,210 --> 00:06:06,720
really lovely talk yesterday which

00:06:04,710 --> 00:06:09,090
talked about some of the stuff happening

00:06:06,720 --> 00:06:11,130
in the shuffle and some other magic it

00:06:09,090 --> 00:06:13,380
wasn't called magic for some reason but

00:06:11,130 --> 00:06:16,560
I mean artistic differences I respect

00:06:13,380 --> 00:06:18,300
that if you miss that talk I have a go

00:06:16,560 --> 00:06:20,610
to Chicago talk which talks about some

00:06:18,300 --> 00:06:24,390
of the same things and you should watch

00:06:20,610 --> 00:06:26,580
that well yeah so the the reason we all

00:06:24,390 --> 00:06:28,080
use spark is that our data is magically

00:06:26,580 --> 00:06:31,560
distributed across our cluster along

00:06:28,080 --> 00:06:33,490
with our work at some point our RTD or

00:06:31,560 --> 00:06:36,310
our data frame there are

00:06:33,490 --> 00:06:38,590
collection is forced to exist right if

00:06:36,310 --> 00:06:40,780
spark was able to never do any work I

00:06:38,590 --> 00:06:42,310
mean you could just not write your

00:06:40,780 --> 00:06:44,380
software to begin with and it would run

00:06:42,310 --> 00:06:47,080
much faster you probably wouldn't get

00:06:44,380 --> 00:06:49,630
paid as much but you know would be

00:06:47,080 --> 00:06:51,610
perfectly fine but when this happens

00:06:49,630 --> 00:06:54,099
it's really important that our data is

00:06:51,610 --> 00:06:56,319
distributed but there's this catch that

00:06:54,099 --> 00:06:59,229
spark tries to understand where data is

00:06:56,319 --> 00:07:02,020
to some degree and this is done with

00:06:59,229 --> 00:07:04,690
this thing called partition errs and in

00:07:02,020 --> 00:07:06,370
spark normally when we load our data in

00:07:04,690 --> 00:07:08,289
it doesn't really understand what the

00:07:06,370 --> 00:07:09,940
layout of our data is but if we need to

00:07:08,289 --> 00:07:12,190
do something like a join or if we need

00:07:09,940 --> 00:07:13,599
to sort our data spark has to understand

00:07:12,190 --> 00:07:17,020
where the different keys for our data

00:07:13,599 --> 00:07:19,659
are and partition errs are deterministic

00:07:17,020 --> 00:07:23,770
and this deterministic nature of

00:07:19,659 --> 00:07:25,659
partition errs breaks some of the really

00:07:23,770 --> 00:07:27,340
cool magic right are magically

00:07:25,659 --> 00:07:30,159
distributed collection that I can

00:07:27,340 --> 00:07:33,430
pretend just works starts to have some

00:07:30,159 --> 00:07:34,930
constraints so when I say magically

00:07:33,430 --> 00:07:37,719
distributed what we actually mean is

00:07:34,930 --> 00:07:40,570
that each of these gnomes is responsible

00:07:37,719 --> 00:07:42,520
for some of my data and when I ask these

00:07:40,570 --> 00:07:44,680
when I ask my spark cluster to do some

00:07:42,520 --> 00:07:46,150
work each of these 300 gnomes are going

00:07:44,680 --> 00:07:49,599
to go off and do that little work on

00:07:46,150 --> 00:07:51,789
their own but once I like want to get my

00:07:49,599 --> 00:07:53,770
keys in order these gnomes have to talk

00:07:51,789 --> 00:07:55,599
to each other to figure out like hey

00:07:53,770 --> 00:07:57,639
which which pieces of the data do you

00:07:55,599 --> 00:08:00,219
have which pieces of the data you have

00:07:57,639 --> 00:08:02,319
and at that point we start trying to

00:08:00,219 --> 00:08:04,449
assign gnomes different pieces of the

00:08:02,319 --> 00:08:06,460
data to deal with specifically rather

00:08:04,449 --> 00:08:09,520
than each just giving them like some

00:08:06,460 --> 00:08:10,900
random set of records the problem is we

00:08:09,520 --> 00:08:13,210
might give one of those gnomes the

00:08:10,900 --> 00:08:15,270
responsibility for the null key and at

00:08:13,210 --> 00:08:17,919
that point that gnome gets really sad

00:08:15,270 --> 00:08:20,729
because most of your data is no because

00:08:17,919 --> 00:08:23,199
the client lied to you or didn't lie but

00:08:20,729 --> 00:08:25,360
that they told you their data was evenly

00:08:23,199 --> 00:08:27,159
distributed what they meant is the data

00:08:25,360 --> 00:08:28,780
where my keys exist is evenly

00:08:27,159 --> 00:08:31,000
distributed and then our gnome

00:08:28,780 --> 00:08:33,700
responsible for the null key goes on a

00:08:31,000 --> 00:08:35,529
bender it just doesn't come back and

00:08:33,700 --> 00:08:39,279
then our job fails because we have this

00:08:35,529 --> 00:08:41,050
very sad gnome or actually then the

00:08:39,279 --> 00:08:42,310
gnome fails and we try it on another

00:08:41,050 --> 00:08:43,900
gnome and then we try it on another

00:08:42,310 --> 00:08:45,490
gnome and now we have three dead gnomes

00:08:43,900 --> 00:08:49,390
and

00:08:45,490 --> 00:08:52,270
thankfully gnomes don't count but you

00:08:49,390 --> 00:08:54,640
know things things start to go poorly at

00:08:52,270 --> 00:08:56,880
this point and so yeah this is this is

00:08:54,640 --> 00:09:00,010
the key skew problem it's the sort of

00:08:56,880 --> 00:09:02,589
part where sparks magic distribution of

00:09:00,010 --> 00:09:05,310
data stops working and my traditional

00:09:02,589 --> 00:09:08,080
example for this is handlebar moustaches

00:09:05,310 --> 00:09:08,620
because as someone that lives in San

00:09:08,080 --> 00:09:11,290
Francisco

00:09:08,620 --> 00:09:12,820
I mean software is great and make a lot

00:09:11,290 --> 00:09:14,860
of money on software it's pretty good

00:09:12,820 --> 00:09:17,080
but there's this thing where I have to

00:09:14,860 --> 00:09:19,390
do work and that's just like not really

00:09:17,080 --> 00:09:21,190
my style so I want to get out of the

00:09:19,390 --> 00:09:23,440
software business and start selling

00:09:21,190 --> 00:09:25,839
moustache wax to people and they're

00:09:23,440 --> 00:09:27,459
normally there's someone I knew you have

00:09:25,839 --> 00:09:28,630
a pretty good moustache okay normally

00:09:27,459 --> 00:09:30,580
there's someone in the front row is like

00:09:28,630 --> 00:09:34,240
a really rockin moustache and we can we

00:09:30,580 --> 00:09:35,980
can talk but in this case I want to know

00:09:34,240 --> 00:09:39,370
where I should be opening my moustache

00:09:35,980 --> 00:09:42,640
wax shop so I've got this this data and

00:09:39,370 --> 00:09:45,250
this is American zip codes right and you

00:09:42,640 --> 00:09:47,649
have postal codes that I assume have the

00:09:45,250 --> 00:09:49,660
same problems but so once I try and sort

00:09:47,649 --> 00:09:52,270
my data it's it's going to go really

00:09:49,660 --> 00:09:53,470
poorly right but that was talked about

00:09:52,270 --> 00:09:55,300
yesterday so we're going to talk about

00:09:53,470 --> 00:09:56,980
what happens if I try and call goodbye

00:09:55,300 --> 00:09:59,200
key in my data I might be trying to

00:09:56,980 --> 00:10:01,600
figure out like I want to send some

00:09:59,200 --> 00:10:04,390
really high quality targeted marketing

00:10:01,600 --> 00:10:06,190
to all of the people in whichever zip

00:10:04,390 --> 00:10:07,120
code has the most handlebar mustaches

00:10:06,190 --> 00:10:09,160
because that's where I'm going to open

00:10:07,120 --> 00:10:11,110
my moustache wax shop so I'm going to

00:10:09,160 --> 00:10:13,000
take my RDD I'm going to call group by

00:10:11,110 --> 00:10:18,550
key on it and then things are going to

00:10:13,000 --> 00:10:21,550
go fabulously mmm okay well the problem

00:10:18,550 --> 00:10:26,140
is when we call group by key spark

00:10:21,550 --> 00:10:28,420
creates this RDD where it's this key and

00:10:26,140 --> 00:10:30,940
this list of all of the records for that

00:10:28,420 --> 00:10:33,700
key and then afterwards I can do some

00:10:30,940 --> 00:10:38,050
type of arbitrary transformation on that

00:10:33,700 --> 00:10:39,399
RDD and that's great but we think this

00:10:38,050 --> 00:10:41,290
shouldn't be too bad right because

00:10:39,399 --> 00:10:44,320
sparks optimizer doesn't actually have

00:10:41,290 --> 00:10:46,180
to make that RDD exists until we get to

00:10:44,320 --> 00:10:48,070
the point where we save it up to disk or

00:10:46,180 --> 00:10:49,810
you know I start sending out my Flyers

00:10:48,070 --> 00:10:53,949
to all of the people about my moustache

00:10:49,810 --> 00:10:56,540
wax shop the problem is that spark can't

00:10:53,949 --> 00:10:58,850
see inside of our lambda expressions

00:10:56,540 --> 00:11:04,370
and this is this is like the limitation

00:10:58,850 --> 00:11:06,890
of the magic of spark once we all of our

00:11:04,370 --> 00:11:08,750
maps are flat maps all of the things

00:11:06,890 --> 00:11:10,820
that we do spark and understand what

00:11:08,750 --> 00:11:12,740
we're asking it to do except you can't

00:11:10,820 --> 00:11:15,890
see inside of what we ask it to do so

00:11:12,740 --> 00:11:17,870
let's okay I'm going to go to this one

00:11:15,890 --> 00:11:19,970
really quickly so the problem is that

00:11:17,870 --> 00:11:23,210
spark can't see inside of this lambda

00:11:19,970 --> 00:11:27,050
expression so it doesn't know that we

00:11:23,210 --> 00:11:29,180
want the counts here right even though

00:11:27,050 --> 00:11:31,850
it's able to delay the computation until

00:11:29,180 --> 00:11:33,980
we save this result out to disk spark

00:11:31,850 --> 00:11:36,260
isn't able to move this counting up

00:11:33,980 --> 00:11:38,060
above grouping the values together by

00:11:36,260 --> 00:11:40,070
key because really what we want to do is

00:11:38,060 --> 00:11:42,380
as we're going through for each zip code

00:11:40,070 --> 00:11:44,660
I want to be keeping track of the number

00:11:42,380 --> 00:11:45,880
of people who are in the zip code that I

00:11:44,660 --> 00:11:50,330
can send these high-quality

00:11:45,880 --> 00:11:52,970
advertisements to but because it can't

00:11:50,330 --> 00:11:55,810
see inside of my lambda sparked into the

00:11:52,970 --> 00:11:59,290
magic breaks and then boo gets very sad

00:11:55,810 --> 00:12:02,290
and this happens again

00:11:59,290 --> 00:12:07,370
so key skew plus black boxes equals

00:12:02,290 --> 00:12:08,660
sadness but it's okay we're going to

00:12:07,370 --> 00:12:10,520
we're going to make this work we're

00:12:08,660 --> 00:12:12,680
going to do well okay we're going to see

00:12:10,520 --> 00:12:14,470
an example with literally kilobytes of

00:12:12,680 --> 00:12:17,090
data because I ran this on an airplane

00:12:14,470 --> 00:12:19,430
rather than a real cluster but we can

00:12:17,090 --> 00:12:23,150
see I've got some input data it's 385

00:12:19,430 --> 00:12:25,820
kilobytes and my shuffle read is 48

00:12:23,150 --> 00:12:27,740
kilobytes but if instead from my

00:12:25,820 --> 00:12:30,560
handlebar mustache workshop I replace

00:12:27,740 --> 00:12:32,480
this with reduced by key or aggregate by

00:12:30,560 --> 00:12:34,970
key and was computing like the number of

00:12:32,480 --> 00:12:38,180
people who were interested in handlebar

00:12:34,970 --> 00:12:40,340
mustaches in San Francisco this would go

00:12:38,180 --> 00:12:42,710
a lot better and this is because when I

00:12:40,340 --> 00:12:44,690
replace my operations with things that

00:12:42,710 --> 00:12:46,850
spark and get sort of more information

00:12:44,690 --> 00:12:49,250
about spark is able to sort of start

00:12:46,850 --> 00:12:51,410
pipelining these a lot better so instead

00:12:49,250 --> 00:12:53,630
of constructing a giant list and

00:12:51,410 --> 00:12:55,550
shuffling this list around spark is able

00:12:53,630 --> 00:12:57,650
to compute the summary statistic on each

00:12:55,550 --> 00:12:59,090
individual gnome and then each gnome

00:12:57,650 --> 00:13:01,220
just has to tell the other gnomes

00:12:59,090 --> 00:13:03,590
how many handlebar mustaches are in each

00:13:01,220 --> 00:13:05,360
zip code and that's a lot more efficient

00:13:03,590 --> 00:13:07,670
than having to go to every other node

00:13:05,360 --> 00:13:09,440
when be like hey these are all of the

00:13:07,670 --> 00:13:09,900
handlebar mustaches in San Francisco

00:13:09,440 --> 00:13:13,110
because I

00:13:09,900 --> 00:13:14,880
that's just going to take forever we get

00:13:13,110 --> 00:13:16,860
a map side reduction for free which

00:13:14,880 --> 00:13:19,590
means that this is 11 kilobytes rather

00:13:16,860 --> 00:13:22,110
than 48 kilobytes and that's not like I

00:13:19,590 --> 00:13:24,900
mean kilobytes not a super exciting but

00:13:22,110 --> 00:13:26,310
if we replace that K with the T or even

00:13:24,900 --> 00:13:28,440
a G right like that could that could

00:13:26,310 --> 00:13:30,720
make a difference but the really

00:13:28,440 --> 00:13:33,300
important part is that like that 48

00:13:30,720 --> 00:13:34,950
kilobytes was probably all going to one

00:13:33,300 --> 00:13:37,350
gnome like that was all going to the

00:13:34,950 --> 00:13:40,350
gnome responsible for San Francisco so

00:13:37,350 --> 00:13:43,350
we had one very sad gnome and here you

00:13:40,350 --> 00:13:45,780
know we we have like one kind of sad

00:13:43,350 --> 00:13:48,150
gnome but it's only sad for the number

00:13:45,780 --> 00:13:49,950
of other gnomes in our cluster not sad

00:13:48,150 --> 00:13:53,190
for the number of handlebar mustaches in

00:13:49,950 --> 00:13:54,960
San Francisco and in terms of we tend to

00:13:53,190 --> 00:13:56,490
have more humans and computers sort of

00:13:54,960 --> 00:13:58,590
more records than the number of

00:13:56,490 --> 00:14:01,050
computers in our cluster if you have one

00:13:58,590 --> 00:14:02,160
computer per record in your data

00:14:01,050 --> 00:14:03,900
processing pipeline

00:14:02,160 --> 00:14:06,150
I would love to sell you a support

00:14:03,900 --> 00:14:07,710
contract but like this is not going to

00:14:06,150 --> 00:14:12,480
fine if you want to write your code that

00:14:07,710 --> 00:14:14,370
way so the other option is we can we can

00:14:12,480 --> 00:14:16,770
spend a lot of time trying to make

00:14:14,370 --> 00:14:18,390
things work and sparks our DD API and

00:14:16,770 --> 00:14:21,270
like taking all of our lambda

00:14:18,390 --> 00:14:23,100
expressions thinking carefully like oh I

00:14:21,270 --> 00:14:25,200
did a group by key and then I had this

00:14:23,100 --> 00:14:26,850
like reduction afterwards

00:14:25,200 --> 00:14:30,000
can I rewrite my reduction into an

00:14:26,850 --> 00:14:33,450
aggregate or we could just go ahead and

00:14:30,000 --> 00:14:35,250
use sparks data set API and I really

00:14:33,450 --> 00:14:37,770
think the data set API is a really cool

00:14:35,250 --> 00:14:39,480
piece of magic where admittedly I have

00:14:37,770 --> 00:14:41,430
to give up my like arbitrary lambda

00:14:39,480 --> 00:14:44,520
expression some of the time I can still

00:14:41,430 --> 00:14:46,890
use them but I can just like give spark

00:14:44,520 --> 00:14:49,470
some hints and stuff will just work for

00:14:46,890 --> 00:14:50,640
me and it's really cool magic and it's

00:14:49,470 --> 00:14:53,040
the best kind of magic because I don't

00:14:50,640 --> 00:14:56,430
have to think about it so let's look at

00:14:53,040 --> 00:14:59,460
an example using the data set API so

00:14:56,430 --> 00:15:00,120
here I'm interested in figuring out the

00:14:59,460 --> 00:15:03,270
fuzziness

00:15:00,120 --> 00:15:06,650
of the happy pandas and this is really

00:15:03,270 --> 00:15:09,750
cool because these expressions are

00:15:06,650 --> 00:15:11,820
mostly data set expressions but then at

00:15:09,750 --> 00:15:14,520
the end because I forgot how to do some

00:15:11,820 --> 00:15:16,920
I just used your reduce and so this is

00:15:14,520 --> 00:15:18,720
an arbitrary lambda at the very end but

00:15:16,920 --> 00:15:22,650
the first two bits are in sparks little

00:15:18,720 --> 00:15:23,740
cool DFL and I mean trying to convince

00:15:22,650 --> 00:15:25,510
people to use a DSL

00:15:23,740 --> 00:15:28,000
like you know trying to sell people

00:15:25,510 --> 00:15:30,060
handlebar moustache wax it's a little

00:15:28,000 --> 00:15:32,620
difficult but it's really awesome

00:15:30,060 --> 00:15:34,090
because the first bit like we've got

00:15:32,620 --> 00:15:36,760
this filter expression where we're

00:15:34,090 --> 00:15:39,570
looking for happy pandas spark is able

00:15:36,760 --> 00:15:43,510
to do some really awesome things for us

00:15:39,570 --> 00:15:46,150
so if I have data about pandas spark is

00:15:43,510 --> 00:15:47,590
able to only load the information about

00:15:46,150 --> 00:15:49,810
the happy pandas because it can

00:15:47,590 --> 00:15:51,490
understand what's happening in here but

00:15:49,810 --> 00:15:53,650
if I have a lambda expression inside of

00:15:51,490 --> 00:15:55,780
their spark can't figure out what my

00:15:53,650 --> 00:15:58,420
condition is but because we write it in

00:15:55,780 --> 00:16:00,220
this DSL like the magical optimizer can

00:15:58,420 --> 00:16:02,440
take care of it and the fastest data

00:16:00,220 --> 00:16:06,820
that I can ever load is the data that I

00:16:02,440 --> 00:16:10,030
don't load and the Select also means

00:16:06,820 --> 00:16:12,010
like spark will automatically only if

00:16:10,030 --> 00:16:13,900
we've got columnar data will only load

00:16:12,010 --> 00:16:15,370
the attribute about how fuzzy the pandas

00:16:13,900 --> 00:16:16,840
are so if we have a bunch of other

00:16:15,370 --> 00:16:18,880
information about like where the Panda

00:16:16,840 --> 00:16:25,600
came from we wouldn't have to load that

00:16:18,880 --> 00:16:28,270
in from disk either yeah okay yeah um

00:16:25,600 --> 00:16:30,970
and and if you want to still use your

00:16:28,270 --> 00:16:32,470
cool arbitrary lambda expressions you

00:16:30,970 --> 00:16:34,330
totally can

00:16:32,470 --> 00:16:36,550
I do this a lot because it turns out I'm

00:16:34,330 --> 00:16:38,770
pretty bad at writing things in sequel

00:16:36,550 --> 00:16:41,500
like languages and I'm much better at

00:16:38,770 --> 00:16:43,840
writing lambda expressions and it's

00:16:41,500 --> 00:16:45,850
really convenient because this map is

00:16:43,840 --> 00:16:49,270
still distributed across my cluster all

00:16:45,850 --> 00:16:51,100
of the existing spark magic so works and

00:16:49,270 --> 00:16:53,680
I don't have to switch paradigms or

00:16:51,100 --> 00:16:57,670
something like that to get between the

00:16:53,680 --> 00:17:01,710
different types of magic and here's an

00:16:57,670 --> 00:17:05,860
example in Python for the Python people

00:17:01,710 --> 00:17:09,100
it's not as pretty in Python this

00:17:05,860 --> 00:17:11,350
party's actually my fault I've totally

00:17:09,100 --> 00:17:13,270
been meaning to fix this but it turns

00:17:11,350 --> 00:17:16,390
out it's kind of hard to do like static

00:17:13,270 --> 00:17:18,700
typing in Python and a lot of the magic

00:17:16,390 --> 00:17:20,290
that we do involve static typing so we

00:17:18,700 --> 00:17:22,810
we have to be a little bit more verbose

00:17:20,290 --> 00:17:25,780
in Python to just help spark out but

00:17:22,810 --> 00:17:28,100
it's still not too bad right like we you

00:17:25,780 --> 00:17:32,460
know mm-hm

00:17:28,100 --> 00:17:34,350
I'm sorry Python users um but it's okay

00:17:32,460 --> 00:17:36,179
it's okay this little bit of sadness

00:17:34,350 --> 00:17:38,400
right like the fact that I have to write

00:17:36,179 --> 00:17:40,470
this like weird ro expression here like

00:17:38,400 --> 00:17:45,179
that's not the end of the world and it's

00:17:40,470 --> 00:17:46,620
so much faster it's so much faster um so

00:17:45,179 --> 00:17:49,530
bigger is bad

00:17:46,620 --> 00:17:51,420
smaller is good unless you if you're

00:17:49,530 --> 00:17:53,670
selling support contracts totally use

00:17:51,420 --> 00:17:56,610
group by key if you build by it's like

00:17:53,670 --> 00:17:58,679
the CPU cycle but otherwise you probably

00:17:56,610 --> 00:18:01,140
actually want to use reduced by key or

00:17:58,679 --> 00:18:02,940
you want to use data frames right and we

00:18:01,140 --> 00:18:05,130
can see that data frames outperform

00:18:02,940 --> 00:18:07,440
reduced by key right and this is for

00:18:05,130 --> 00:18:08,940
really simple aggregate so even even

00:18:07,440 --> 00:18:11,550
when I'm writing intelligent things

00:18:08,940 --> 00:18:13,530
inside of rdd's things can get a lot

00:18:11,550 --> 00:18:19,890
faster and sparks data frames and data

00:18:13,530 --> 00:18:21,840
sets um so why is it so much faster so

00:18:19,890 --> 00:18:24,210
the really cool thing is that we can

00:18:21,840 --> 00:18:26,160
sort on the serialized data previously

00:18:24,210 --> 00:18:28,020
when we were doing our sort we would

00:18:26,160 --> 00:18:29,910
have to deserialize and re serialize our

00:18:28,020 --> 00:18:32,970
data for pretty much every step inside

00:18:29,910 --> 00:18:34,740
of the shuffle inspark the the really

00:18:32,970 --> 00:18:36,450
important part though is that spark can

00:18:34,740 --> 00:18:39,720
understand the aggregation that's

00:18:36,450 --> 00:18:41,790
happening and this gives us a very space

00:18:39,720 --> 00:18:43,500
efficient way to store things and also

00:18:41,790 --> 00:18:47,130
allows the optimizer to do a lot of

00:18:43,500 --> 00:18:50,130
really cool things and so what what can

00:18:47,130 --> 00:18:52,110
we do in this DSL so we can do a lot of

00:18:50,130 --> 00:18:54,210
the things that we're used to doing in

00:18:52,110 --> 00:18:56,880
spark we can do filters we can do

00:18:54,210 --> 00:18:59,220
drawings we can do group bys and we get

00:18:56,880 --> 00:19:02,130
some new fancy things too if you want to

00:18:59,220 --> 00:19:05,010
run arbitrary sequel statements on data

00:19:02,130 --> 00:19:06,630
frames but it's totally doable you just

00:19:05,010 --> 00:19:08,429
have to pretend you're living in the 90s

00:19:06,630 --> 00:19:11,130
because that's when we picked up the

00:19:08,429 --> 00:19:12,870
sequel standard from but if you if you

00:19:11,130 --> 00:19:15,330
don't mind a trip back to like sequel 90

00:19:12,870 --> 00:19:17,970
tool and you can you can run arbitrary

00:19:15,330 --> 00:19:20,370
sequel expressions and the other thing

00:19:17,970 --> 00:19:22,860
which you can do now really easily is

00:19:20,370 --> 00:19:25,020
you can do windowed expressions and you

00:19:22,860 --> 00:19:27,300
can you can totally do all of these

00:19:25,020 --> 00:19:29,880
things in rdd's right they're just

00:19:27,300 --> 00:19:32,880
really painful to do right if I want to

00:19:29,880 --> 00:19:35,670
compute a window in Rd deal and this

00:19:32,880 --> 00:19:37,500
like magic distribution of my data like

00:19:35,670 --> 00:19:39,900
it kind of breaks because I have to

00:19:37,500 --> 00:19:40,230
think about like what happens when one

00:19:39,900 --> 00:19:43,620
No

00:19:40,230 --> 00:19:45,720
has like part of the window that I'd be

00:19:43,620 --> 00:19:47,700
writing like it has records one through

00:19:45,720 --> 00:19:50,010
four and the other gnome has records

00:19:47,700 --> 00:19:52,559
four through six and my window is

00:19:50,010 --> 00:19:54,840
computed over these two pieces I have to

00:19:52,559 --> 00:19:56,549
like think about that and then the

00:19:54,840 --> 00:19:58,500
really more important part is I have to

00:19:56,549 --> 00:19:59,910
remember to test that because even

00:19:58,500 --> 00:20:02,520
though I thought about it I probably got

00:19:59,910 --> 00:20:04,710
it wrong or I can just use the window

00:20:02,520 --> 00:20:08,040
expressions and let's sparks equal take

00:20:04,710 --> 00:20:09,630
care of it for me um and as someone who

00:20:08,040 --> 00:20:12,660
has like screwed up writing window

00:20:09,630 --> 00:20:15,919
expressions on rdd's before like this is

00:20:12,660 --> 00:20:18,360
something that I really enjoy doing

00:20:15,919 --> 00:20:20,490
there's a long list of the built-in

00:20:18,360 --> 00:20:21,990
aggregations at work if you want to

00:20:20,490 --> 00:20:24,270
write your own custom aggregations is

00:20:21,990 --> 00:20:28,320
totally supported you can go here and

00:20:24,270 --> 00:20:29,850
see the list but group-by becomes safe

00:20:28,320 --> 00:20:32,820
which i think is really important

00:20:29,850 --> 00:20:34,679
because group by key sounds totally

00:20:32,820 --> 00:20:37,500
reasonable except for the part where

00:20:34,679 --> 00:20:40,730
normally destroys you inside of spark Rd

00:20:37,500 --> 00:20:43,350
DeLand because it does terrible things

00:20:40,730 --> 00:20:45,270
we can compute multiple aggregates I

00:20:43,350 --> 00:20:48,960
know if you're coming from a traditional

00:20:45,270 --> 00:20:50,820
single machine background this is not at

00:20:48,960 --> 00:20:52,169
all impressive but when you have to

00:20:50,820 --> 00:20:54,660
compute three different aggregates

00:20:52,169 --> 00:20:56,400
inside of a reduced by key step you end

00:20:54,660 --> 00:20:58,500
up with like five different variables

00:20:56,400 --> 00:21:00,059
you're keeping track of and you really

00:20:58,500 --> 00:21:04,260
hope you don't screw any of them up

00:21:00,059 --> 00:21:06,900
um so hmm there is a catch though with

00:21:04,260 --> 00:21:11,820
everything it explodes under certain

00:21:06,900 --> 00:21:15,090
circumstances so all new magic is not

00:21:11,820 --> 00:21:17,030
guaranteed to work 100% of the time if

00:21:15,090 --> 00:21:19,710
you're doing iterative machine learning

00:21:17,030 --> 00:21:22,260
come talk to me and we can talk about

00:21:19,710 --> 00:21:23,520
how to work around this problem but

00:21:22,260 --> 00:21:24,929
there's some extra knobs that you'll

00:21:23,520 --> 00:21:26,700
have to tune in your spark cluster to

00:21:24,929 --> 00:21:30,150
make it really work but other than that

00:21:26,700 --> 00:21:32,190
the magic should be pretty fine oh and I

00:21:30,150 --> 00:21:34,110
promised the conference organizers that

00:21:32,190 --> 00:21:37,320
I would only have one slide of trying to

00:21:34,110 --> 00:21:39,480
shamelessly pitch you on a book so this

00:21:37,320 --> 00:21:41,250
is the one side of stream lessly trying

00:21:39,480 --> 00:21:43,870
to pitch you on a book you can buy this

00:21:41,250 --> 00:21:45,290
book it's about spark um

00:21:43,870 --> 00:21:47,970
[Music]

00:21:45,290 --> 00:21:50,280
presumably you're interested in spark if

00:21:47,970 --> 00:21:53,509
you're not it is a great gift for cats

00:21:50,280 --> 00:21:56,429
they love the box that comes in

00:21:53,509 --> 00:21:58,409
hmm please don't return the book

00:21:56,429 --> 00:22:00,059
afterwards so you definitely want to

00:21:58,409 --> 00:22:02,850
keep it to remind yourself of the bucks

00:22:00,059 --> 00:22:05,130
you got for your cat and it's actually

00:22:02,850 --> 00:22:06,870
is on print on Amazon as of this morning

00:22:05,130 --> 00:22:08,100
so don't don't don't worry about it

00:22:06,870 --> 00:22:10,559
although if you want to give me your

00:22:08,100 --> 00:22:13,909
email address to spam I always love

00:22:10,559 --> 00:22:16,380
collecting people's email addresses um

00:22:13,909 --> 00:22:19,710
there's supposed to be another side but

00:22:16,380 --> 00:22:23,250
really really that's the most important

00:22:19,710 --> 00:22:27,509
slide anyways um because my computer

00:22:23,250 --> 00:22:28,500
just froze and will so yeah you to do I

00:22:27,509 --> 00:22:31,440
think we're pretty much out of time

00:22:28,500 --> 00:22:35,220
anyways right so does I Drive time for a

00:22:31,440 --> 00:22:40,379
question very quickly does anyone have a

00:22:35,220 --> 00:22:42,840
super quick question for boo no

00:22:40,379 --> 00:22:46,250
questions okay wait three questions what

00:22:42,840 --> 00:22:51,330
come on make up your mind

00:22:46,250 --> 00:22:54,360
so is it often that you see a situation

00:22:51,330 --> 00:22:57,090
that you want to rewrite your your data

00:22:54,360 --> 00:22:59,759
frame query into rdd's because the

00:22:57,090 --> 00:23:01,799
optimizer gets it wrong totally that's a

00:22:59,759 --> 00:23:05,279
really good question and the answer is

00:23:01,799 --> 00:23:08,429
not super often most of the time when I

00:23:05,279 --> 00:23:10,139
see this happen I want to give some more

00:23:08,429 --> 00:23:11,730
hints to the optimizer because you can

00:23:10,139 --> 00:23:15,480
you can give the optimizer a bunch of

00:23:11,730 --> 00:23:17,159
hence the times when I normally end up

00:23:15,480 --> 00:23:19,169
wanting to rewrite it is this so I'm

00:23:17,159 --> 00:23:21,690
doing an iterative graph algorithm or

00:23:19,169 --> 00:23:23,820
something that looks kind of like an

00:23:21,690 --> 00:23:27,149
iterative graph algorithm or like a CD

00:23:23,820 --> 00:23:28,919
or something like this because then the

00:23:27,149 --> 00:23:31,250
optimizer even if I give it all the ins

00:23:28,919 --> 00:23:37,019
in the world still makes really

00:23:31,250 --> 00:23:38,820
interesting decisions but it's it's

00:23:37,019 --> 00:23:40,950
normally normally the answer is give it

00:23:38,820 --> 00:23:42,539
more hints and then if you get really

00:23:40,950 --> 00:23:45,990
stuck you can always just go back to our

00:23:42,539 --> 00:23:50,580
deal and but like it's not something

00:23:45,990 --> 00:23:53,840
that I find myself doing super often all

00:23:50,580 --> 00:23:53,840
right thank you Holden cool

00:23:54,520 --> 00:23:56,580

YouTube URL: https://www.youtube.com/watch?v=nZngJBdVK8g


