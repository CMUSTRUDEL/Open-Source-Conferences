Title: Berlin Buzzwords 2017: Alan Woodward - How does a Lucene Query actually work? #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	When you submit a query to Elasticsearch or Apache Solr, underneath all the shiny user interfaces it's a Lucene Query that's doing all the grunt work.  But what actually happens when your query is processed?  And how come it's so damn fast?

This talk will guide you through the code paths that Lucene takes when executing a query, explaining the data structures and algorithms used, from simple term queries to more complex booleans and custom scoring methods. It will be useful for people writing their own queries or similarities, wanting to optimize how their queries are run, or just plain curious about how an awesome piece of software actually works.

Read more:
https://2017.berlinbuzzwords.de/17/session/how-does-lucene-query-actually-work

About Alan Woodward:
https://2017.berlinbuzzwords.de/users/alan-woodward

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:06,810 --> 00:00:10,500
hello everyone my name is Alan

00:00:08,400 --> 00:00:12,180
Woodward's I'm from flax such as

00:00:10,500 --> 00:00:15,600
Microsoft insultin see based in the UK

00:00:12,180 --> 00:00:17,310
and I'm going to talk to you about how

00:00:15,600 --> 00:00:20,550
you query at Lucene index what actually

00:00:17,310 --> 00:00:22,349
happens when you run a query to start

00:00:20,550 --> 00:00:23,849
off with we have the slide that the

00:00:22,349 --> 00:00:27,509
marketing manager makes me put up at all

00:00:23,849 --> 00:00:29,669
these talks so yes this is who flax is

00:00:27,509 --> 00:00:32,160
with open-source consultancy based in

00:00:29,669 --> 00:00:35,130
Cambridge we've been around for a while

00:00:32,160 --> 00:00:36,570
we do lots of interesting stuff hit me

00:00:35,130 --> 00:00:38,600
up if you want to see more details on

00:00:36,570 --> 00:00:38,600
that

00:00:39,649 --> 00:00:45,390
so the talk today what I'm going to

00:00:42,510 --> 00:00:48,809
basically do is take you through some of

00:00:45,390 --> 00:00:50,519
the the Java classes that that are

00:00:48,809 --> 00:00:53,670
required that you use when you run a

00:00:50,519 --> 00:00:55,949
query and Lucy will talk about how

00:00:53,670 --> 00:00:58,010
things match we'll talk about how you

00:00:55,949 --> 00:01:00,960
collect all those matching documents

00:00:58,010 --> 00:01:03,960
we'll go through the details of how

00:01:00,960 --> 00:01:05,780
Matthew and the simpler queries work and

00:01:03,960 --> 00:01:08,390
I'll talk about query caching as well

00:01:05,780 --> 00:01:10,580
this is sort of an entry level talk

00:01:08,390 --> 00:01:13,620
Adrian here is doing another talk at

00:01:10,580 --> 00:01:15,780
half-past four which is on more details

00:01:13,620 --> 00:01:18,720
on how particular types of slow queries

00:01:15,780 --> 00:01:22,560
work so that's a nice follow-up to this

00:01:18,720 --> 00:01:24,930
one but the most important thing is why

00:01:22,560 --> 00:01:28,860
should I care why you cares how things

00:01:24,930 --> 00:01:32,130
work this talk the idea initially came

00:01:28,860 --> 00:01:34,590
from a workshop I did at Glasgow

00:01:32,130 --> 00:01:35,540
Strathclyde University last year called

00:01:34,590 --> 00:01:39,810
loosing 4ir

00:01:35,540 --> 00:01:42,900
which was introducing the Lucene open

00:01:39,810 --> 00:01:45,240
source java library to students

00:01:42,900 --> 00:01:49,380
academics working on information

00:01:45,240 --> 00:01:50,850
retrieval who tend to not use sort of

00:01:49,380 --> 00:01:52,790
commercial software in their own

00:01:50,850 --> 00:01:55,800
research they use things like Terrier

00:01:52,790 --> 00:01:57,840
which is lots of papers are published on

00:01:55,800 --> 00:02:02,370
this but then no one outside the

00:01:57,840 --> 00:02:05,640
academia uses it and all their research

00:02:02,370 --> 00:02:08,160
and the things they were doing based on

00:02:05,640 --> 00:02:11,310
this scene were making certain

00:02:08,160 --> 00:02:13,200
assumptions about how queries work how

00:02:11,310 --> 00:02:13,650
documents are collected how things are

00:02:13,200 --> 00:02:16,170
scored

00:02:13,650 --> 00:02:18,250
we don't actually apply to the scene so

00:02:16,170 --> 00:02:19,870
okay well if you're

00:02:18,250 --> 00:02:21,880
cont UN query if you're writing your own

00:02:19,870 --> 00:02:25,140
similarity for doing any kind of this

00:02:21,880 --> 00:02:28,090
this sort of level of research or

00:02:25,140 --> 00:02:29,440
implementation then it helps know what

00:02:28,090 --> 00:02:31,810
the framework does how it all fits

00:02:29,440 --> 00:02:32,890
together plus the main reason why you

00:02:31,810 --> 00:02:37,530
should care is because it's interesting

00:02:32,890 --> 00:02:37,530
no we're all geeks that's why we're here

00:02:38,160 --> 00:02:41,980
so here's some of the classes I'm going

00:02:40,570 --> 00:02:44,620
to talk about there's lots of them they

00:02:41,980 --> 00:02:45,820
have scary names some of them have names

00:02:44,620 --> 00:02:47,140
which is there because that's what they

00:02:45,820 --> 00:02:49,930
were called when leucine one was

00:02:47,140 --> 00:02:51,250
released fifteen years ago and their

00:02:49,930 --> 00:02:53,850
purpose has changed entirely but they

00:02:51,250 --> 00:02:56,709
still have the same name but there we go

00:02:53,850 --> 00:02:59,890
we start off with we have an index

00:02:56,709 --> 00:03:03,310
weekend so the illicit index is a bunch

00:02:59,890 --> 00:03:05,320
of files on disk and the the way that's

00:03:03,310 --> 00:03:07,720
stored is pluggable they have different

00:03:05,320 --> 00:03:09,700
codecs but the these are the

00:03:07,720 --> 00:03:11,260
implementation of how all these data

00:03:09,700 --> 00:03:12,610
structures are stored is incomplete

00:03:11,260 --> 00:03:14,410
hidden from the client generally

00:03:12,610 --> 00:03:16,120
speaking and you get access to

00:03:14,410 --> 00:03:19,620
everything through the index reader

00:03:16,120 --> 00:03:24,340
class so this gives you access to the

00:03:19,620 --> 00:03:28,299
inverted index to dock values document

00:03:24,340 --> 00:03:31,000
to like a database table to the KD tree

00:03:28,299 --> 00:03:32,530
which is nu and leucine 6 which is a

00:03:31,000 --> 00:03:37,780
better way of storing dimensional data

00:03:32,530 --> 00:03:41,950
and Emeric data term vectors general

00:03:37,780 --> 00:03:44,590
corpus statistics things like number of

00:03:41,950 --> 00:03:46,120
documents that have a particular term or

00:03:44,590 --> 00:03:48,519
the number total number of terms total

00:03:46,120 --> 00:03:50,350
member tokens all the things you need

00:03:48,519 --> 00:03:54,670
when you're executing a query and when

00:03:50,350 --> 00:03:56,170
you're scoring a query so the index

00:03:54,670 --> 00:03:58,450
reader gives you access to all these

00:03:56,170 --> 00:04:00,549
things then the index search wraps our

00:03:58,450 --> 00:04:02,829
index reader and that exposes a bunch of

00:04:00,549 --> 00:04:05,380
methods helper methods to actually run

00:04:02,829 --> 00:04:06,340
your queries so this is the important

00:04:05,380 --> 00:04:09,600
thing when you're doing a search the

00:04:06,340 --> 00:04:12,030
first thing you need is a searcher and

00:04:09,600 --> 00:04:15,010
then the next thing you need is a query

00:04:12,030 --> 00:04:17,109
so we have a query object which is an

00:04:15,010 --> 00:04:19,530
abstract class and this defines what you

00:04:17,109 --> 00:04:22,810
actually want to get from your index so

00:04:19,530 --> 00:04:24,880
it's a term query or you're getting a

00:04:22,810 --> 00:04:26,169
single clip searching for a single term

00:04:24,880 --> 00:04:28,840
if it's a boolean you're searching for

00:04:26,169 --> 00:04:31,060
this or that this and that the phrase

00:04:28,840 --> 00:04:33,820
query you want to get things with

00:04:31,060 --> 00:04:36,070
terms next to each other all the

00:04:33,820 --> 00:04:38,950
different types of queries are had their

00:04:36,070 --> 00:04:40,300
own class they're independent of your

00:04:38,950 --> 00:04:41,950
index rate then you can run the same

00:04:40,300 --> 00:04:44,470
query against lots of different index

00:04:41,950 --> 00:04:47,290
readers lots of different indexes and

00:04:44,470 --> 00:04:48,700
you're obviously at different documents

00:04:47,290 --> 00:04:49,510
back because the documents and all these

00:04:48,700 --> 00:04:52,590
different in this it's gonna be

00:04:49,510 --> 00:04:54,580
different but the kind of fundamental

00:04:52,590 --> 00:04:57,550
abstract notion and what it is that

00:04:54,580 --> 00:04:59,890
you're going to retrieve it's

00:04:57,550 --> 00:05:04,840
independent of the actual thing you're

00:04:59,890 --> 00:05:07,330
searching over they're immutable this is

00:05:04,840 --> 00:05:09,760
an important thing if you're using query

00:05:07,330 --> 00:05:10,420
caches you need to make sure your query

00:05:09,760 --> 00:05:12,490
is immutable

00:05:10,420 --> 00:05:13,480
you can go and change it under the hood

00:05:12,490 --> 00:05:17,010
then suddenly you're going to start

00:05:13,480 --> 00:05:17,010
getting wrong results back from a cache

00:05:18,210 --> 00:05:22,570
yes the body if you're writing your own

00:05:20,350 --> 00:05:24,220
queries ever then bear in mind you need

00:05:22,570 --> 00:05:25,210
to make it make sure it's immutable

00:05:24,220 --> 00:05:27,130
otherwise you're gonna start getting

00:05:25,210 --> 00:05:31,300
weird results back from from your index

00:05:27,130 --> 00:05:33,400
searcher now that the important thing

00:05:31,300 --> 00:05:37,540
here is the queries independent of the

00:05:33,400 --> 00:05:39,580
index reader so under the hood when you

00:05:37,540 --> 00:05:40,990
actually run the query delusi needs to

00:05:39,580 --> 00:05:43,540
turn that query object into something

00:05:40,990 --> 00:05:46,300
that is relevant to that particular

00:05:43,540 --> 00:05:49,840
index and what we have here is it's

00:05:46,300 --> 00:05:52,150
called a weight normally this is all hid

00:05:49,840 --> 00:05:53,650
so when you're externally when you're

00:05:52,150 --> 00:05:55,210
running a query you just run the query

00:05:53,650 --> 00:05:57,010
against the index and you get your top

00:05:55,210 --> 00:06:00,070
box back so that you don't see the

00:05:57,010 --> 00:06:02,200
weight but this is used internally and

00:06:00,070 --> 00:06:07,420
it's the specific representation of this

00:06:02,200 --> 00:06:09,870
query for this index reader yeah and it

00:06:07,420 --> 00:06:13,090
may take to your query that relates to

00:06:09,870 --> 00:06:14,410
everything in the index so not specific

00:06:13,090 --> 00:06:18,880
bits for the index it's kind of a global

00:06:14,410 --> 00:06:22,240
view over your index you create it by

00:06:18,880 --> 00:06:25,990
calling create up create weight not all

00:06:22,240 --> 00:06:28,090
queries can do this it's a slight I know

00:06:25,990 --> 00:06:30,640
it's kind of a bit of a rough edge in

00:06:28,090 --> 00:06:32,380
the in the Lucene API that you can have

00:06:30,640 --> 00:06:34,630
a query that can't actually create a

00:06:32,380 --> 00:06:35,800
weight though I think that ought to be

00:06:34,630 --> 00:06:39,280
sort of be two different classes there

00:06:35,800 --> 00:06:41,290
but that's a another discussion there's

00:06:39,280 --> 00:06:42,740
a certain types of queries you need to

00:06:41,290 --> 00:06:45,620
rewrite them against in particular in

00:06:42,740 --> 00:06:47,150
read the first so I talk on top of some

00:06:45,620 --> 00:06:49,099
queries when I give an example here like

00:06:47,150 --> 00:06:50,509
a wild card or a regular expression what

00:06:49,099 --> 00:06:52,759
that will do is you give it an index

00:06:50,509 --> 00:06:57,199
reader and it rewrites itself into a

00:06:52,759 --> 00:06:59,810
disjunction query so we had the weight

00:06:57,199 --> 00:07:04,910
and the weight looks at the global view

00:06:59,810 --> 00:07:08,030
in the index next I need to talk to a

00:07:04,910 --> 00:07:10,610
bit about that the the structure of the

00:07:08,030 --> 00:07:14,449
the Lucene index so before I can sort of

00:07:10,610 --> 00:07:18,620
go and explain what happens next so your

00:07:14,449 --> 00:07:21,349
Lucene index structure it's not one big

00:07:18,620 --> 00:07:24,400
monolithic thing it's actually consists

00:07:21,349 --> 00:07:27,800
of lots of different segments of index

00:07:24,400 --> 00:07:32,360
each segment itself is a kind of an

00:07:27,800 --> 00:07:35,150
index in itself they're built in memory

00:07:32,360 --> 00:07:38,240
when you add documents to your index

00:07:35,150 --> 00:07:40,759
writer it'll match everything up buffer

00:07:38,240 --> 00:07:41,930
everything it builds your segment and

00:07:40,759 --> 00:07:45,949
then it flushes it out to disk when you

00:07:41,930 --> 00:07:47,690
call commit and then also when you when

00:07:45,949 --> 00:07:48,979
you call commit when something's to disk

00:07:47,690 --> 00:07:50,690
you have another background process

00:07:48,979 --> 00:07:51,949
which will merge segments together so

00:07:50,690 --> 00:07:53,930
you don't end up with lots and lots of

00:07:51,949 --> 00:07:55,280
tiny segments then someone will get most

00:07:53,930 --> 00:07:59,570
together into larger segments behind the

00:07:55,280 --> 00:08:02,479
scenes why do we do this

00:07:59,570 --> 00:08:04,759
the main reason is to means that you can

00:08:02,479 --> 00:08:06,860
do incremental indexing really easily so

00:08:04,759 --> 00:08:09,740
when you're adding new documents you

00:08:06,860 --> 00:08:11,479
don't have to go and change already

00:08:09,740 --> 00:08:13,699
existing index structures you can just

00:08:11,479 --> 00:08:15,740
add another index structure another

00:08:13,699 --> 00:08:18,469
index onto the end of your existing

00:08:15,740 --> 00:08:21,110
index and you don't add to update

00:08:18,469 --> 00:08:24,159
anything so that's good for speed of

00:08:21,110 --> 00:08:28,130
indexing and it's also good for

00:08:24,159 --> 00:08:29,360
immutability and data integrity you can

00:08:28,130 --> 00:08:31,699
make sure that you know what you can

00:08:29,360 --> 00:08:32,719
must checksum and you know that when

00:08:31,699 --> 00:08:34,520
you've got that set of bytes that

00:08:32,719 --> 00:08:36,860
particular index segment once it's

00:08:34,520 --> 00:08:38,060
written once you can read it in you've

00:08:36,860 --> 00:08:43,520
got to check your checksum and you can

00:08:38,060 --> 00:08:47,209
be sure that the data is correct so the

00:08:43,520 --> 00:08:49,430
index reader gives you a view over all

00:08:47,209 --> 00:08:52,560
these individual segments

00:08:49,430 --> 00:08:55,649
we have a leaves method these returns a

00:08:52,560 --> 00:08:57,630
bunch of leaf reader context the leaf

00:08:55,649 --> 00:09:03,360
reader context is a view over an

00:08:57,630 --> 00:09:08,220
individual segment but it also it has an

00:09:03,360 --> 00:09:10,050
ID which has a an ordinal which means

00:09:08,220 --> 00:09:12,810
they're ordered within the segment and

00:09:10,050 --> 00:09:15,959
it also records a dock base so you can

00:09:12,810 --> 00:09:17,970
map your ID from that segment in terms

00:09:15,959 --> 00:09:22,170
of a global space of IDs over the whole

00:09:17,970 --> 00:09:25,020
index and it also Polly feeder context

00:09:22,170 --> 00:09:27,720
also exposes a leaf reader which is like

00:09:25,020 --> 00:09:30,660
an index reader but it's for individual

00:09:27,720 --> 00:09:35,760
segments so what does this all mean to

00:09:30,660 --> 00:09:37,529
surging well your index reader gives you

00:09:35,760 --> 00:09:41,130
the top level view that's the view over

00:09:37,529 --> 00:09:42,480
the whole index you can get some access

00:09:41,130 --> 00:09:44,010
to some data structures that way but

00:09:42,480 --> 00:09:45,149
it's kind of an inefficient way of doing

00:09:44,010 --> 00:09:46,890
it because it's going to have to merge

00:09:45,149 --> 00:09:50,190
the data structures from all the

00:09:46,890 --> 00:09:51,779
individual segments together so

00:09:50,190 --> 00:09:53,670
generally the way we search things we

00:09:51,779 --> 00:09:54,779
actually you iterate over all the

00:09:53,670 --> 00:09:57,000
segments you do a search of a one

00:09:54,779 --> 00:09:58,500
segment such as the next segment segment

00:09:57,000 --> 00:10:04,170
search over the next one and then

00:09:58,500 --> 00:10:05,399
combine those results wait again it

00:10:04,170 --> 00:10:08,010
gives you that view over the whole thing

00:10:05,399 --> 00:10:10,529
so if you want to actually do your

00:10:08,010 --> 00:10:13,589
search you can't use a weight because

00:10:10,529 --> 00:10:15,899
our weight is too too granular we need a

00:10:13,589 --> 00:10:17,810
different object and that object is

00:10:15,899 --> 00:10:20,730
called a scorer

00:10:17,810 --> 00:10:23,220
so the scorer maintains your state for

00:10:20,730 --> 00:10:25,470
the query for each individual leaf

00:10:23,220 --> 00:10:27,450
reader so you have the query top level

00:10:25,470 --> 00:10:30,899
which is index reader independence then

00:10:27,450 --> 00:10:32,190
you have weight which is the the

00:10:30,899 --> 00:10:34,500
representation of that query for this

00:10:32,190 --> 00:10:36,660
index reader for this at the top level

00:10:34,500 --> 00:10:38,459
and then you have a scorer which is the

00:10:36,660 --> 00:10:41,610
representation of that query for each

00:10:38,459 --> 00:10:44,070
individual segment it's providing

00:10:41,610 --> 00:10:45,329
iterative documents so when you say okay

00:10:44,070 --> 00:10:46,800
I've got my segment I've got my score

00:10:45,329 --> 00:10:48,480
over this segment I can just call this

00:10:46,800 --> 00:10:52,620
iterator and it will return all the

00:10:48,480 --> 00:10:54,360
documents that match pin turn it also

00:10:52,620 --> 00:10:57,449
gives you access to scoring mechanism

00:10:54,360 --> 00:10:59,880
hence why it's called the scorer so you

00:10:57,449 --> 00:11:00,830
get the doc doc ID set iterator is

00:10:59,880 --> 00:11:03,020
returned

00:11:00,830 --> 00:11:05,180
you advance over your your iterator and

00:11:03,020 --> 00:11:06,440
then you can call score Adult School for

00:11:05,180 --> 00:11:08,510
each document you're sitting on and it

00:11:06,440 --> 00:11:11,720
will give you the score for that

00:11:08,510 --> 00:11:15,380
document generated by wait wait not

00:11:11,720 --> 00:11:17,000
scorer and there is a shortcut here if

00:11:15,380 --> 00:11:18,560
you know that this particular score

00:11:17,000 --> 00:11:20,660
isn't going to match anything in this

00:11:18,560 --> 00:11:25,970
particular segment it'll just return now

00:11:20,660 --> 00:11:28,340
and you can sort of shortcut actually

00:11:25,970 --> 00:11:32,150
have score is a it's a bit of a legacy

00:11:28,340 --> 00:11:34,340
name because scoring isn't necessarily

00:11:32,150 --> 00:11:36,230
the score as primary purpose you can

00:11:34,340 --> 00:11:37,460
still use it to iterate over document

00:11:36,230 --> 00:11:39,170
even when you're not actually interested

00:11:37,460 --> 00:11:44,500
in the score if you're using as a filter

00:11:39,170 --> 00:11:48,980
for example so let's tie it all together

00:11:44,500 --> 00:11:50,710
we've got your query objects independent

00:11:48,980 --> 00:11:54,200
of everything just a representation of

00:11:50,710 --> 00:11:56,990
what you want to what you want to

00:11:54,200 --> 00:11:58,460
retrieve from a particular index given

00:11:56,990 --> 00:12:01,430
your index reader you have a query

00:11:58,460 --> 00:12:03,230
generator in generator weight to maximum

00:12:01,430 --> 00:12:06,410
documents the weight generates a score

00:12:03,230 --> 00:12:08,540
for each segment and that score then

00:12:06,410 --> 00:12:11,390
gives you a doc ID set iterator which

00:12:08,540 --> 00:12:13,010
will iterate over all the matching

00:12:11,390 --> 00:12:15,590
documents in that seven let's give you

00:12:13,010 --> 00:12:18,410
two bits of pseudocode here so you can

00:12:15,590 --> 00:12:22,670
create your weight you iterate over all

00:12:18,410 --> 00:12:24,950
the leaves within your index you create

00:12:22,670 --> 00:12:28,430
your scorer for each leaf you get your

00:12:24,950 --> 00:12:31,160
iterator for that scorer and then you

00:12:28,430 --> 00:12:32,750
iterate over the is rater so the

00:12:31,160 --> 00:12:37,370
important thing is what do we do with

00:12:32,750 --> 00:12:40,670
that duck ID once we have it so the next

00:12:37,370 --> 00:12:43,370
class we look at is the collector and

00:12:40,670 --> 00:12:45,170
this says okay I've got a list of all my

00:12:43,370 --> 00:12:47,740
matching documents what do I want to do

00:12:45,170 --> 00:12:50,840
with those documents as they've come in

00:12:47,740 --> 00:12:53,000
again the collector has the same dual

00:12:50,840 --> 00:12:55,010
structure it has the top-level collector

00:12:53,000 --> 00:12:56,900
which is for the for the whole search

00:12:55,010 --> 00:12:58,130
and then a leaf collector which is the

00:12:56,900 --> 00:13:03,320
representation of that collector for

00:12:58,130 --> 00:13:08,390
each segment and when you go through in

00:13:03,320 --> 00:13:09,590
our the pseudocode ad earlier and as you

00:13:08,390 --> 00:13:11,980
get each document you then call

00:13:09,590 --> 00:13:13,960
collector collects

00:13:11,980 --> 00:13:15,190
with that with the document ID that's

00:13:13,960 --> 00:13:15,970
matching so it can give you that

00:13:15,190 --> 00:13:18,370
pseudocode again

00:13:15,970 --> 00:13:21,540
and you can say here in the middle here

00:13:18,370 --> 00:13:24,400
we call in collection with a document ID

00:13:21,540 --> 00:13:26,380
this is obviously heavily simplifies

00:13:24,400 --> 00:13:28,240
there's a number of other things that

00:13:26,380 --> 00:13:30,310
listen allows you to do you can search

00:13:28,240 --> 00:13:33,820
leaves in parallel you've passed an

00:13:30,310 --> 00:13:35,530
executor in some scores will actually

00:13:33,820 --> 00:13:37,090
score a whole bunch of documents at the

00:13:35,530 --> 00:13:38,620
same time this and they put a belt score

00:13:37,090 --> 00:13:41,800
up which is good for performance in

00:13:38,620 --> 00:13:43,120
certain circumstances this I'm not

00:13:41,800 --> 00:13:45,360
talking like deleted documents here

00:13:43,120 --> 00:13:47,530
which adds another complication either

00:13:45,360 --> 00:13:48,580
if you need to be able to skip over

00:13:47,530 --> 00:13:50,830
documents that you know they've actually

00:13:48,580 --> 00:13:51,700
been deleted in the index and you can

00:13:50,830 --> 00:13:53,110
also have something called a lien

00:13:51,700 --> 00:13:58,510
termination so if you have for example

00:13:53,110 --> 00:14:00,430
assorted assorted index and you can if

00:13:58,510 --> 00:14:02,500
you're if you're trying to collect

00:14:00,430 --> 00:14:03,880
things in sorted order and you know that

00:14:02,500 --> 00:14:05,470
once you got to a certain duck I D

00:14:03,880 --> 00:14:07,180
because the index itself is sorted you

00:14:05,470 --> 00:14:10,440
can stop iterating over everything you

00:14:07,180 --> 00:14:14,290
can jump out that but that's basically

00:14:10,440 --> 00:14:17,100
the the nucleus of what happens when you

00:14:14,290 --> 00:14:17,100
searching this see

00:14:27,230 --> 00:14:30,990
so they seem to have a bunch of

00:14:29,070 --> 00:14:33,720
collectors that come with it

00:14:30,990 --> 00:14:34,770
the when you normal search when you

00:14:33,720 --> 00:14:36,300
search for a query and say like oh I

00:14:34,770 --> 00:14:39,330
want to get the top ten highest scoring

00:14:36,300 --> 00:14:42,080
results from this query listing uses

00:14:39,330 --> 00:14:44,760
something called a top score collector

00:14:42,080 --> 00:14:48,180
when you're sorting by field it uses the

00:14:44,760 --> 00:14:49,800
top field collector you can create your

00:14:48,180 --> 00:14:55,920
own collector and pass that in there's a

00:14:49,800 --> 00:14:58,170
public method on searcher excuse me

00:14:55,920 --> 00:15:00,930
so all these top end collector classes

00:14:58,170 --> 00:15:03,270
use a priority queue which means that

00:15:00,930 --> 00:15:06,170
obviously for doing deep paging if you

00:15:03,270 --> 00:15:09,270
want to say okay I want to get the

00:15:06,170 --> 00:15:11,580
1700's results to the 1700 and pinch

00:15:09,270 --> 00:15:12,600
results if if you're using a priority

00:15:11,580 --> 00:15:15,240
queue what it has to do is it then

00:15:12,600 --> 00:15:19,670
allocates you know space for all those

00:15:15,240 --> 00:15:24,750
top 1700 zones and then throws away the

00:15:19,670 --> 00:15:26,160
most of them so what in that what loosin

00:15:24,750 --> 00:15:28,650
allows you to do is actually exposes

00:15:26,160 --> 00:15:33,390
this method called search after which

00:15:28,650 --> 00:15:34,260
allows a live scene to to determine

00:15:33,390 --> 00:15:35,970
whether you're going to put something in

00:15:34,260 --> 00:15:40,530
the priority queue based on both the top

00:15:35,970 --> 00:15:42,839
and the bottom values so this is when if

00:15:40,530 --> 00:15:46,200
you look at solar or elasticsearch and

00:15:42,839 --> 00:15:48,390
if you you know just page through doing

00:15:46,200 --> 00:15:50,070
next next next next next in one of these

00:15:48,390 --> 00:15:52,560
search applications you'll be tend to

00:15:50,070 --> 00:15:53,970
run out of memory and things die but if

00:15:52,560 --> 00:15:56,580
you use a scroll ghwarri or a cursor

00:15:53,970 --> 00:15:58,530
mark under the scenes that's using the

00:15:56,580 --> 00:16:07,470
search after method and so there's much

00:15:58,530 --> 00:16:09,930
more memory efficient so in terms of how

00:16:07,470 --> 00:16:11,910
you score things and what information

00:16:09,930 --> 00:16:14,670
you have to hand when you're doing the

00:16:11,910 --> 00:16:15,870
scoring collection is going down as you

00:16:14,670 --> 00:16:19,020
iterate through things so they've done a

00:16:15,870 --> 00:16:20,820
document at a time so your scoring

00:16:19,020 --> 00:16:24,350
algorithm doesn't actually know anything

00:16:20,820 --> 00:16:28,390
about how many document you've matched

00:16:24,350 --> 00:16:30,920
what documents have matched before after

00:16:28,390 --> 00:16:34,640
and this is actually information that

00:16:30,920 --> 00:16:37,850
this can be quite useful for general

00:16:34,640 --> 00:16:39,710
scoring algorithms so Lucine actually

00:16:37,850 --> 00:16:44,360
provides another class called are--

00:16:39,710 --> 00:16:45,770
scorer and this allows you to do a first

00:16:44,360 --> 00:16:47,540
class search which is going to collect

00:16:45,770 --> 00:16:52,160
all your documents you can score those

00:16:47,540 --> 00:16:55,660
with your standards your standard

00:16:52,160 --> 00:16:58,820
scoring mechanism you'll be m25 where is

00:16:55,660 --> 00:17:00,470
you collect those top thousand Oxford's

00:16:58,820 --> 00:17:04,000
or whatever and then you use a restore

00:17:00,470 --> 00:17:07,939
to to go and do more complicated scoring

00:17:04,000 --> 00:17:09,260
on those those collected results so

00:17:07,939 --> 00:17:10,819
something like learning to rank which

00:17:09,260 --> 00:17:15,410
Diego and so if you see I was talking

00:17:10,819 --> 00:17:17,240
about earlier will use this method it's

00:17:15,410 --> 00:17:21,650
you collect everything first and then

00:17:17,240 --> 00:17:23,510
you run in underscore again so what

00:17:21,650 --> 00:17:25,280
we'll do now is we'll a couple of

00:17:23,510 --> 00:17:26,990
queries to see how does the score

00:17:25,280 --> 00:17:30,080
iteration actually works how things are

00:17:26,990 --> 00:17:33,890
implemented the simplest one is time

00:17:30,080 --> 00:17:36,590
query so this just makes the post in

00:17:33,890 --> 00:17:38,690
generation from your leaf readers so

00:17:36,590 --> 00:17:42,230
which is just an iterator over the

00:17:38,690 --> 00:17:44,510
postings list of a particular term so

00:17:42,230 --> 00:17:46,760
you have where we have our ideas eraser

00:17:44,510 --> 00:17:49,100
which basically just delegated directly

00:17:46,760 --> 00:17:52,340
to be the postings enumeration which

00:17:49,100 --> 00:17:54,020
will x-ray over your postings list if

00:17:52,340 --> 00:17:56,540
the posting was an in racing there's no

00:17:54,020 --> 00:17:58,610
that means there's no matching terms for

00:17:56,540 --> 00:18:01,430
this particular token in that segment so

00:17:58,610 --> 00:18:03,410
the whole thing returns now very simple

00:18:01,430 --> 00:18:05,120
very straightforward very fast it

00:18:03,410 --> 00:18:08,590
doesn't need to do anything clever it's

00:18:05,120 --> 00:18:08,590
just literally reading bites off disk

00:18:08,950 --> 00:18:17,360
boolean queries is the more complicated

00:18:12,110 --> 00:18:19,550
one this is kind of the the most your

00:18:17,360 --> 00:18:21,710
that the heavy duty Heather the work

00:18:19,550 --> 00:18:25,670
hard worker of the loosing queries and

00:18:21,710 --> 00:18:27,650
family and so you can have a billion

00:18:25,670 --> 00:18:28,790
queries you can have muss clauses you

00:18:27,650 --> 00:18:30,320
can have should clauses you can have

00:18:28,790 --> 00:18:32,960
must not clauses you can have filter

00:18:30,320 --> 00:18:34,280
clauses and different combinations of

00:18:32,960 --> 00:18:35,690
all these things will actually result in

00:18:34,280 --> 00:18:38,810
different scores being used under the

00:18:35,690 --> 00:18:40,910
hood so if you only have mus clauses

00:18:38,810 --> 00:18:43,610
it's a pure conjunction then we use

00:18:40,910 --> 00:18:45,320
conjunction score oh if you only have

00:18:43,610 --> 00:18:46,850
 clauses it's a pure disjunction we

00:18:45,320 --> 00:18:49,400
use a distinction in some scorer

00:18:46,850 --> 00:18:52,760
we have rec opt scorer so required and

00:18:49,400 --> 00:18:54,290
optional combinations of those and then

00:18:52,760 --> 00:18:56,900
if you've got must not clauses on there

00:18:54,290 --> 00:19:01,040
as well you have the rec Explorer so

00:18:56,900 --> 00:19:02,680
required an excluded scorer these all

00:19:01,040 --> 00:19:05,240
work in different ways

00:19:02,680 --> 00:19:09,320
conjunction scorer is it's probably the

00:19:05,240 --> 00:19:10,790
simplest one in that it just score has

00:19:09,320 --> 00:19:13,040
been expose that thing called a cost

00:19:10,790 --> 00:19:15,740
which is kind of a guess of how

00:19:13,040 --> 00:19:18,620
complicated it's going to be to run this

00:19:15,740 --> 00:19:21,740
to iterate over this particular score so

00:19:18,620 --> 00:19:23,300
conjunction score sorts by by the costs

00:19:21,740 --> 00:19:25,520
and said okay whatever the whatever the

00:19:23,300 --> 00:19:29,360
lowest costs score is I've been used at

00:19:25,520 --> 00:19:31,640
to drive my iteration it calls next off

00:19:29,360 --> 00:19:35,300
on that and then it will advance

00:19:31,640 --> 00:19:39,050
everything else to the same one to the

00:19:35,300 --> 00:19:40,700
same duck ID if if we have a match there

00:19:39,050 --> 00:19:42,460
then excellent everything's on the same

00:19:40,700 --> 00:19:46,520
document we can match we return that ID

00:19:42,460 --> 00:19:48,950
if it's not then we find out what the

00:19:46,520 --> 00:19:50,510
maximum ID of all the stores is and then

00:19:48,950 --> 00:19:53,900
advance the lead document to that one

00:19:50,510 --> 00:19:57,380
again so we're using the the lowest cost

00:19:53,900 --> 00:20:00,470
score to drive the iteration which means

00:19:57,380 --> 00:20:06,050
you can you can skip over more

00:20:00,470 --> 00:20:10,850
complicated scores the disjunction query

00:20:06,050 --> 00:20:14,150
uses a priority queue and it's a it's a

00:20:10,850 --> 00:20:16,030
heap implementation I think scores will

00:20:14,150 --> 00:20:20,870
advance to the first matching documents

00:20:16,030 --> 00:20:24,230
whatever the lowest yet score the lowest

00:20:20,870 --> 00:20:28,760
doc ID you start off with that these

00:20:24,230 --> 00:20:30,140
have to drive the iteration you call

00:20:28,760 --> 00:20:33,170
next off on the whatever it is that's

00:20:30,140 --> 00:20:36,140
got the lowest duck ID your update

00:20:33,170 --> 00:20:37,700
update the heap and the current ID is

00:20:36,140 --> 00:20:42,950
off ID at the bottom of half of the

00:20:37,700 --> 00:20:44,780
queue I'm simplifying here obviously but

00:20:42,950 --> 00:20:48,050
that's generally general speaking what

00:20:44,780 --> 00:20:50,240
the algorithm is the point optional

00:20:48,050 --> 00:20:54,020
scorer combines conjunction disjunction

00:20:50,240 --> 00:20:55,550
and the important a nice thing to point

00:20:54,020 --> 00:20:57,140
out here is if if we don't care about

00:20:55,550 --> 00:20:59,720
scores if we only care about matches

00:20:57,140 --> 00:21:01,580
then we can just ignore the destruction

00:20:59,720 --> 00:21:02,930
part entirely because it's the

00:21:01,580 --> 00:21:04,790
conjunction part which is driving

00:21:02,930 --> 00:21:06,590
whether something matches on disjunction

00:21:04,790 --> 00:21:09,260
just adds to the score

00:21:06,590 --> 00:21:11,630
if scores are acquired then it advances

00:21:09,260 --> 00:21:13,580
using the conjunction and then advances

00:21:11,630 --> 00:21:17,360
the disjunction up to that same points

00:21:13,580 --> 00:21:22,430
that's that same Dolph ID to get the

00:21:17,360 --> 00:21:26,300
scores and then required exclusion

00:21:22,430 --> 00:21:28,040
scorer contains yes so it takes any of

00:21:26,300 --> 00:21:30,140
the other three scores to drive the

00:21:28,040 --> 00:21:31,580
iteration and then we have our exclusion

00:21:30,140 --> 00:21:33,650
score as well and it just adults at the

00:21:31,580 --> 00:21:36,560
child score and checks against the other

00:21:33,650 --> 00:21:39,460
one resolution Sakura to tell whether

00:21:36,560 --> 00:21:39,460
something should match or not

00:21:41,060 --> 00:21:45,830
phrase query so this is if you're you

00:21:43,340 --> 00:21:47,900
want to find out it's basically a

00:21:45,830 --> 00:21:49,910
conjunction I want this this document

00:21:47,900 --> 00:21:53,990
akin to contain both these terms by also

00:21:49,910 --> 00:21:56,570
want them to be next to each other so

00:21:53,990 --> 00:21:58,400
and there are two different types of

00:21:56,570 --> 00:22:02,030
score there's exact phrase which is okay

00:21:58,400 --> 00:22:03,890
I these two need to be a fixed fixed

00:22:02,030 --> 00:22:06,470
number of positions apart or the sloppy

00:22:03,890 --> 00:22:07,330
phrase scorer which is a terrifying ball

00:22:06,470 --> 00:22:10,910
of wax

00:22:07,330 --> 00:22:12,770
kind of works we think there are some

00:22:10,910 --> 00:22:14,900
tests which have been ignored for about

00:22:12,770 --> 00:22:17,170
10 years because no one can work out

00:22:14,900 --> 00:22:21,740
whether they're supposed to work or not

00:22:17,170 --> 00:22:26,120
and yet so again it's a specialized

00:22:21,740 --> 00:22:27,680
conjunction we you check to see the

00:22:26,120 --> 00:22:28,910
documents got all the terms in there and

00:22:27,680 --> 00:22:30,410
once you found doctrine which has all

00:22:28,910 --> 00:22:35,360
the terms and it didn't go and check the

00:22:30,410 --> 00:22:36,980
positions there are so there are ways of

00:22:35,360 --> 00:22:39,320
speeding this up using something called

00:22:36,980 --> 00:22:40,670
T phase iteration which Anton has been

00:22:39,320 --> 00:22:45,830
talk about later on this afternoon

00:22:40,670 --> 00:22:46,760
several patterns come to his talk so

00:22:45,830 --> 00:22:49,700
there's I'm going talk about query

00:22:46,760 --> 00:22:51,260
caching so we have all these these

00:22:49,700 --> 00:22:52,580
different scores and what essentially

00:22:51,260 --> 00:22:56,720
they produce at the end is they produced

00:22:52,580 --> 00:22:58,300
a set it said iterator over a bit set

00:22:56,720 --> 00:23:01,200
purse

00:22:58,300 --> 00:23:03,340
which if you've got a very complex query

00:23:01,200 --> 00:23:06,090
it's quite useful to be able to catch

00:23:03,340 --> 00:23:09,820
that now if you want scores as well then

00:23:06,090 --> 00:23:11,500
the problem with trying to catch that is

00:23:09,820 --> 00:23:12,460
that it's not very compressible scores

00:23:11,500 --> 00:23:15,580
come out as floats

00:23:12,460 --> 00:23:18,370
if you end up matching something no over

00:23:15,580 --> 00:23:20,800
a very large set of your rooms s it'd be

00:23:18,370 --> 00:23:22,330
a very large proportion of the index

00:23:20,800 --> 00:23:24,220
you're going to end up trying to store

00:23:22,330 --> 00:23:26,860
lots and lots and lots of float values

00:23:24,220 --> 00:23:28,660
which don't compress tool and also it's

00:23:26,860 --> 00:23:33,040
specific for that index so that you

00:23:28,660 --> 00:23:38,710
can't share it between different index

00:23:33,040 --> 00:23:41,110
readers so but if you're we have stuff

00:23:38,710 --> 00:23:42,370
that doesn't isn't scoring it's just

00:23:41,110 --> 00:23:44,770
being used to filter stuff out then

00:23:42,370 --> 00:23:46,840
that's nicely cashable and in the next

00:23:44,770 --> 00:23:52,900
lecture has a query cache that will will

00:23:46,840 --> 00:23:55,450
handle all this for you yes so rather

00:23:52,900 --> 00:23:58,420
than calling quick query doctor weight

00:23:55,450 --> 00:24:01,240
directly we go through the index search

00:23:58,420 --> 00:24:03,400
instead indexes or create weight and

00:24:01,240 --> 00:24:06,280
then the index searcher will say okay if

00:24:03,400 --> 00:24:09,400
I don't need any scores and this will

00:24:06,280 --> 00:24:12,090
wrap it wraps that weight with with

00:24:09,400 --> 00:24:14,800
something called caching wrapper weight

00:24:12,090 --> 00:24:17,140
which can then to tell them whether or

00:24:14,800 --> 00:24:18,310
not it's connected well it can determine

00:24:17,140 --> 00:24:21,760
whether or not you've already run that

00:24:18,310 --> 00:24:24,460
query and if you have then it can

00:24:21,760 --> 00:24:25,930
retrieve results from its cache if you

00:24:24,460 --> 00:24:32,230
haven't it can run it in the background

00:24:25,930 --> 00:24:34,060
and cache that result yeah so when you

00:24:32,230 --> 00:24:35,860
what we call scorer caching right for

00:24:34,060 --> 00:24:38,320
white those and C goes to C it's

00:24:35,860 --> 00:24:40,630
actually already got the bit set

00:24:38,320 --> 00:24:41,770
somewhere and the important thing is

00:24:40,630 --> 00:24:44,770
because cash and prizes at the segment

00:24:41,770 --> 00:24:46,210
level it's not the view over the whole

00:24:44,770 --> 00:24:47,800
indexes the view over each individual

00:24:46,210 --> 00:24:51,310
segments so if you're doing incremental

00:24:47,800 --> 00:24:53,620
indexing you have a bunch of data that's

00:24:51,310 --> 00:24:55,510
come in you open your search you open a

00:24:53,620 --> 00:24:58,090
new in next reader and you open a new

00:24:55,510 --> 00:24:59,770
searcher you might find actually quite a

00:24:58,090 --> 00:25:01,060
lot of the data in there is exactly the

00:24:59,770 --> 00:25:03,670
same as it was in your previous search

00:25:01,060 --> 00:25:06,520
if you just added a new segment on the

00:25:03,670 --> 00:25:07,970
end you still got a lot of the same data

00:25:06,520 --> 00:25:10,370
structures there

00:25:07,970 --> 00:25:13,100
and you can share your query cache

00:25:10,370 --> 00:25:15,470
between these two index searches and

00:25:13,100 --> 00:25:18,350
because it's got a view over the same

00:25:15,470 --> 00:25:19,940
segments it can reuse all that you don't

00:25:18,350 --> 00:25:21,590
have to regenerate where your caches you

00:25:19,940 --> 00:25:24,860
don't invalidate everything just by

00:25:21,590 --> 00:25:31,789
opening up a new segment this is a very

00:25:24,860 --> 00:25:34,970
useful thing how can we tell that

00:25:31,789 --> 00:25:38,360
scoring is not required whether two ways

00:25:34,970 --> 00:25:41,269
a particular collector might not be

00:25:38,360 --> 00:25:43,970
interested in scores so for example a

00:25:41,269 --> 00:25:45,289
collector that sorts things by I field

00:25:43,970 --> 00:25:50,690
values it doesn't really care about the

00:25:45,289 --> 00:25:53,720
scores it can so it's available for

00:25:50,690 --> 00:25:57,889
caching and also when you're when you

00:25:53,720 --> 00:25:59,539
pass things as still ters to billion

00:25:57,889 --> 00:26:01,070
query constants so she should be fully

00:25:59,539 --> 00:26:03,980
inquiry occurred or filter that's

00:26:01,070 --> 00:26:06,440
obviously you can say okay these

00:26:03,980 --> 00:26:08,899
particular elements of the billion query

00:26:06,440 --> 00:26:11,299
I don't care about the scores and these

00:26:08,899 --> 00:26:12,409
and just using the filter stuff out in

00:26:11,299 --> 00:26:17,629
which case we can use that they're

00:26:12,409 --> 00:26:21,169
awaiting for caching yeah right I kind

00:26:17,629 --> 00:26:27,710
of burnt through these they don't have

00:26:21,169 --> 00:26:30,110
any questions standard two highlights

00:26:27,710 --> 00:26:33,409
we still had a few minutes so if you

00:26:30,110 --> 00:26:35,899
have any questions right now there is

00:26:33,409 --> 00:26:38,899
time for that it's not there is a longer

00:26:35,899 --> 00:26:45,320
break today to intimidate us to do it in

00:26:38,899 --> 00:26:47,149
public okay so the way cuz you've

00:26:45,320 --> 00:26:49,490
explained it everything seems to have

00:26:47,149 --> 00:26:52,700
kind of an overall version and then a

00:26:49,490 --> 00:26:54,769
leaf version yes I guess the way you've

00:26:52,700 --> 00:26:58,220
explained it score is effectively a leaf

00:26:54,769 --> 00:27:00,830
wait has anyone ever kind of considered

00:26:58,220 --> 00:27:03,470
renaming it or is that just generically

00:27:00,830 --> 00:27:05,269
that's about I think it's one of those

00:27:03,470 --> 00:27:08,179
things that someone could come up with a

00:27:05,269 --> 00:27:13,549
new name for it and then everyone else

00:27:08,179 --> 00:27:15,019
would hate it so it's we covered naming

00:27:13,549 --> 00:27:16,250
things and cache invalidation here so

00:27:15,019 --> 00:27:17,330
yeah obviously it's all the hard

00:27:16,250 --> 00:27:20,509
problems

00:27:17,330 --> 00:27:29,289
but yet now that it's that that will be

00:27:20,509 --> 00:27:29,289
a good description any more questions

00:27:30,429 --> 00:27:35,779
bit of a vague one but if you wanted to

00:27:33,139 --> 00:27:37,850
trade through a live Lusine query is

00:27:35,779 --> 00:27:39,649
there any way to see all this company

00:27:37,850 --> 00:27:42,919
well I was you can't separate using the

00:27:39,649 --> 00:27:44,269
debugger there aren't hooks for that

00:27:42,919 --> 00:27:46,730
kind of thing generally because this is

00:27:44,269 --> 00:27:48,739
then this is the hot loop in the middle

00:27:46,730 --> 00:27:51,549
of Lucy this is the very very fast stuff

00:27:48,739 --> 00:27:55,309
so there aren't really any ways of

00:27:51,549 --> 00:27:56,720
exposing that automatically one thing

00:27:55,309 --> 00:27:57,799
you could do I suppose well you could

00:27:56,720 --> 00:28:01,220
pass you can implement your own

00:27:57,799 --> 00:28:02,539
collector which you know because in it

00:28:01,220 --> 00:28:07,009
stack traces or whatever whenever it

00:28:02,539 --> 00:28:08,389
hits a particular document and and you

00:28:07,009 --> 00:28:10,070
can do wrapping collectors so you could

00:28:08,389 --> 00:28:13,340
have a collector that you know delegates

00:28:10,070 --> 00:28:15,549
to your top scorer or the top scorer top

00:28:13,340 --> 00:28:19,039
Phil Kline sort heaven or what have you

00:28:15,549 --> 00:28:29,059
but yes I mean I love most of this just

00:28:19,039 --> 00:28:30,700
by stepping through the debugger so you

00:28:29,059 --> 00:28:33,710
quickly talk about the Reece core

00:28:30,700 --> 00:28:36,350
functionality when the initial path

00:28:33,710 --> 00:28:38,480
happens where do the documents the

00:28:36,350 --> 00:28:41,419
matching documents reside them to be

00:28:38,480 --> 00:28:45,200
restored okay yes so I didn't I didn't

00:28:41,419 --> 00:28:49,970
cover top dogs so when you when you use

00:28:45,200 --> 00:28:51,799
a top score collector obviously the

00:28:49,970 --> 00:28:53,659
collector just said it and it just just

00:28:51,799 --> 00:28:55,100
pulled these documents in and then each

00:28:53,659 --> 00:28:56,749
collector implementation will then have

00:28:55,100 --> 00:28:59,509
another method on it says which you call

00:28:56,749 --> 00:29:01,100
at the end say okay I now have some

00:28:59,509 --> 00:29:02,359
results back these are the results I've

00:29:01,100 --> 00:29:05,659
got these are the top ones I'm gonna

00:29:02,359 --> 00:29:08,210
give you so rescore takes top Doc's

00:29:05,659 --> 00:29:10,899
implementation and that just I mean

00:29:08,210 --> 00:29:12,739
that's literally just an array of it's

00:29:10,899 --> 00:29:15,379
basically just a wrapper of an array of

00:29:12,739 --> 00:29:18,379
its yeah which is the dark IDs it

00:29:15,379 --> 00:29:21,350
doesn't store anything else so if you're

00:29:18,379 --> 00:29:22,700
then you know if you're in solar or

00:29:21,350 --> 00:29:25,009
elasticsearch if you're then trying to

00:29:22,700 --> 00:29:26,869
pretend on lots of field values what

00:29:25,009 --> 00:29:28,519
what they have to do is then go through

00:29:26,869 --> 00:29:29,749
for each of those doc IDs and go and

00:29:28,519 --> 00:29:31,179
retrieve them separately from store

00:29:29,749 --> 00:29:32,320
fields which is a bit

00:29:31,179 --> 00:29:34,090
which is why you had you ever do that

00:29:32,320 --> 00:29:35,980
first like the top ten you don't do it

00:29:34,090 --> 00:29:39,570
we in the collector is everything

00:29:35,980 --> 00:29:42,340
happening there but yes if a risk or the

00:29:39,570 --> 00:29:44,769
you would you do your search you get

00:29:42,340 --> 00:29:49,200
your top Doc's instance back at any past

00:29:44,769 --> 00:29:49,200
actor to risk or a we use those Don IDs

00:29:50,789 --> 00:29:55,630
you mentioned earlier that segments

00:29:53,649 --> 00:29:57,820
could decide not to score in a sense

00:29:55,630 --> 00:30:01,690
family terminate can you talk what

00:29:57,820 --> 00:30:05,250
support there is for determination if

00:30:01,690 --> 00:30:07,210
any I'll have to remember it is now so

00:30:05,250 --> 00:30:09,759
in a way it basically works is the

00:30:07,210 --> 00:30:11,649
throws an exception is early termination

00:30:09,759 --> 00:30:16,240
exception there are a number of

00:30:11,649 --> 00:30:17,679
different ways you can do that the so

00:30:16,240 --> 00:30:19,720
they're the tool I can think of off the

00:30:17,679 --> 00:30:21,220
top of my head of timed ones you can say

00:30:19,720 --> 00:30:23,470
well I want to put a time limit on this

00:30:21,220 --> 00:30:25,029
query if it's going to take longer than

00:30:23,470 --> 00:30:28,149
10 milliseconds I just will need to bail

00:30:25,029 --> 00:30:29,860
out and so you can put that auditing

00:30:28,149 --> 00:30:33,279
segment as it starts offing say okay

00:30:29,860 --> 00:30:33,820
I've got a new score here have I run out

00:30:33,279 --> 00:30:35,879
of time

00:30:33,820 --> 00:30:38,200
but you can also do it as part of the

00:30:35,879 --> 00:30:41,440
part of the iteration within the score

00:30:38,200 --> 00:30:44,080
itself you can say okay when you call

00:30:41,440 --> 00:30:45,129
next off word about it well okay we run

00:30:44,080 --> 00:30:47,409
out of time now throw an early

00:30:45,129 --> 00:30:48,610
terminating exception and then the other

00:30:47,409 --> 00:30:52,059
way of doing that is if you've got a

00:30:48,610 --> 00:30:54,279
sorted index so say you're interested in

00:30:52,059 --> 00:30:55,419
returning things by date you can say

00:30:54,279 --> 00:30:58,360
well I'm going to sort everything in

00:30:55,419 --> 00:30:59,860
this index so that the the latest things

00:30:58,360 --> 00:31:01,360
come at the beginning of the index and

00:30:59,860 --> 00:31:03,009
new going so going back in time as you

00:31:01,360 --> 00:31:04,269
iterate through and if you're only

00:31:03,009 --> 00:31:04,899
interested in stuff has happened since

00:31:04,269 --> 00:31:06,909
yesterday

00:31:04,899 --> 00:31:09,220
as you get through as you're iterating

00:31:06,909 --> 00:31:12,070
through you can see okay well I've got

00:31:09,220 --> 00:31:15,250
to this document here has a field value

00:31:12,070 --> 00:31:17,049
that's sort of beyond the where I'm

00:31:15,250 --> 00:31:19,029
interested in so I know that everything

00:31:17,049 --> 00:31:20,919
else I hit in the situation is not going

00:31:19,029 --> 00:31:22,120
to be irrelevant for me so you can just

00:31:20,919 --> 00:31:24,220
bail out then and throw your early

00:31:22,120 --> 00:31:26,409
termination exception and that'll handle

00:31:24,220 --> 00:31:32,470
at the top level in the index I've

00:31:26,409 --> 00:31:35,320
searched after I had a question so when

00:31:32,470 --> 00:31:36,940
you call create score on the way clear

00:31:35,320 --> 00:31:39,429
you're going to make multiple scores in

00:31:36,940 --> 00:31:41,649
a single index because an index has

00:31:39,429 --> 00:31:43,720
multiple segments yeah practically

00:31:41,649 --> 00:31:44,830
speaking when would you create multiple

00:31:43,720 --> 00:31:48,399
waves from a soon

00:31:44,830 --> 00:31:50,140
query at the top low like obviously a

00:31:48,399 --> 00:31:51,789
boolean query we'll call create way

00:31:50,140 --> 00:31:53,529
underneath the hood on all the sub

00:31:51,789 --> 00:31:56,019
quarters but when would the boolean

00:31:53,529 --> 00:31:59,230
queries create wavy called multiple

00:31:56,019 --> 00:32:00,820
times I use say both times for different

00:31:59,230 --> 00:32:03,370
queries or multiple times within the

00:32:00,820 --> 00:32:04,419
same good within the same query now

00:32:03,370 --> 00:32:06,100
generally speaking tend to be called

00:32:04,419 --> 00:32:08,110
once okay there's never an instance

00:32:06,100 --> 00:32:10,179
where it's not called where it's called

00:32:08,110 --> 00:32:12,909
more than once because I also know that

00:32:10,179 --> 00:32:14,470
from my experience it's only usually

00:32:12,909 --> 00:32:16,299
called ones but I don't know yeah I

00:32:14,470 --> 00:32:19,000
think it's only called once it can be

00:32:16,299 --> 00:32:21,399
quite a heavy operations as well it will

00:32:19,000 --> 00:32:23,529
be do certainly for things like term

00:32:21,399 --> 00:32:25,480
queries it goes and it when you create

00:32:23,529 --> 00:32:27,870
the weight it also goes and reads lots

00:32:25,480 --> 00:32:30,580
of information from the index about know

00:32:27,870 --> 00:32:33,130
where in each segment it needs to jump

00:32:30,580 --> 00:32:36,039
to to get to read the terms index and

00:32:33,130 --> 00:32:38,950
does a wrap up front and yet that can be

00:32:36,039 --> 00:32:40,240
quite a said IO intensive operation that

00:32:38,950 --> 00:32:42,880
can be quite a slow operation so you

00:32:40,240 --> 00:32:48,700
want to make sure that that's not

00:32:42,880 --> 00:32:51,870
happening more than once and as it is

00:32:48,700 --> 00:32:54,730
under the other point yeah very much I

00:32:51,870 --> 00:32:57,480
wanted to understand which parts of the

00:32:54,730 --> 00:32:59,950
query year our most expensive and and

00:32:57,480 --> 00:33:02,679
actually alluded to it and probably it

00:32:59,950 --> 00:33:07,630
green is going to Tokyo right yes so

00:33:02,679 --> 00:33:09,549
generally speaking any query that

00:33:07,630 --> 00:33:11,470
involves positions is going to be slower

00:33:09,549 --> 00:33:12,970
because it's not just you're not just

00:33:11,470 --> 00:33:14,260
iterating through postings lists you're

00:33:12,970 --> 00:33:17,260
also having to then go and check

00:33:14,260 --> 00:33:19,539
positions and it's not one operation per

00:33:17,260 --> 00:33:23,889
document you hate it's actually several

00:33:19,539 --> 00:33:25,870
operations there are so there's various

00:33:23,889 --> 00:33:28,450
payload queries which is a similar thing

00:33:25,870 --> 00:33:31,120
it's reading three positions and then

00:33:28,450 --> 00:33:35,260
reading payload bytes out a position and

00:33:31,120 --> 00:33:36,789
doing comparisons on those so that's why

00:33:35,260 --> 00:33:40,350
yeah that's what and that's why you have

00:33:36,789 --> 00:33:42,909
this cost exposed so if you've got a

00:33:40,350 --> 00:33:44,950
conjunction query that has one you know

00:33:42,909 --> 00:33:47,080
very simple term query and one quite

00:33:44,950 --> 00:33:49,779
complicated span query or something like

00:33:47,080 --> 00:33:52,659
that then you want to drive it with that

00:33:49,779 --> 00:33:54,490
term query and make sure that you're not

00:33:52,659 --> 00:33:56,529
having to do all these complicated

00:33:54,490 --> 00:33:58,179
operations on this more than this

00:33:56,529 --> 00:34:00,009
heavier scorer that

00:33:58,179 --> 00:34:01,629
actually we know we're not going to hear

00:34:00,009 --> 00:34:08,169
that document anyway because injunction

00:34:01,629 --> 00:34:09,190
of the turquoise doesn't match I think

00:34:08,169 --> 00:34:11,449
we're good

00:34:09,190 --> 00:34:13,760
thank you very much Alan thank you

00:34:11,449 --> 00:34:16,879
[Applause]

00:34:13,760 --> 00:34:16,879

YouTube URL: https://www.youtube.com/watch?v=Z-yG-KvIuD8


