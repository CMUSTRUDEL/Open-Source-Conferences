Title: #bbuzz: Caito Scherr - Streaming, Fast and Slow
Publication date: 2020-06-24
Playlist: Berlin Buzzwords | MICES | Haystack â€“ Joint Virtual Event 2020
Description: 
	More: https://berlinbuzzwords.de/session/streaming-fast-and-slow

What if you were given 2 weeks to prepare for running your first marathon, and had to be able to keep up with the fastest runner?
This is the story of a small team that jumped head first into building a top tier stream processing (Apache Flink) service on a tight timeline, and how they prepared for being able to keep up with the fastest components. 

This talk will be of interest to those who want to build larger, more complex stream processing applications (and quickly), but will also benefit anyone who is looking to adopt a new streaming technology (or use it in a way that is new to their company), at any scale. Other takeaways include pragmatic steps to leverage unique Flink features to more effectively solve common, real world data streaming problems.
Captions: 
	00:00:14,400 --> 00:00:17,520
hello everyone

00:00:15,599 --> 00:00:19,359
and welcome to streaming fast and slow

00:00:17,520 --> 00:00:21,119
how to successfully be an early adopter

00:00:19,359 --> 00:00:22,960
of stream processing at your company

00:00:21,119 --> 00:00:25,119
with a particular focus on integration

00:00:22,960 --> 00:00:26,960
operations and analytics

00:00:25,119 --> 00:00:28,720
my name is kato sher and i'm a software

00:00:26,960 --> 00:00:31,599
engineer and i live in portland oregon

00:00:28,720 --> 00:00:32,640
in the u.s i have a variety of hobbies

00:00:31,599 --> 00:00:34,960
including woodworking

00:00:32,640 --> 00:00:37,200
dance and running and i first started

00:00:34,960 --> 00:00:38,879
working with stream processing in 2017

00:00:37,200 --> 00:00:40,559
with apache flank

00:00:38,879 --> 00:00:42,239
i'm here because of an experience i had

00:00:40,559 --> 00:00:43,440
as an early adopter of stream processing

00:00:42,239 --> 00:00:45,200
at my old company

00:00:43,440 --> 00:00:46,879
for a top tier project and i want to

00:00:45,200 --> 00:00:48,800
talk about the things i learned

00:00:46,879 --> 00:00:51,120
about successfully integrating new

00:00:48,800 --> 00:00:53,120
streaming application into a complex

00:00:51,120 --> 00:00:54,719
non-streaming ecosystem on a short

00:00:53,120 --> 00:00:55,520
timeline

00:00:54,719 --> 00:00:57,440
so i'm going to start with some

00:00:55,520 --> 00:00:58,640
background what the challenges were our

00:00:57,440 --> 00:01:00,239
use case

00:00:58,640 --> 00:01:01,760
next i'll go over integrating stream

00:01:00,239 --> 00:01:02,879
processing into a non-streaming

00:01:01,760 --> 00:01:04,879
ecosystem

00:01:02,879 --> 00:01:06,640
which is the fun part where the people

00:01:04,879 --> 00:01:08,560
problems and tech problems really tend

00:01:06,640 --> 00:01:09,840
to go hand in hand

00:01:08,560 --> 00:01:12,159
next i'll go over what we learned about

00:01:09,840 --> 00:01:13,920
operations and lastly i'll cover

00:01:12,159 --> 00:01:15,439
analytics focusing on monitoring and

00:01:13,920 --> 00:01:16,960
alerting

00:01:15,439 --> 00:01:17,920
before we go into background this is

00:01:16,960 --> 00:01:18,960
probably a good time to set some

00:01:17,920 --> 00:01:20,799
definitions

00:01:18,960 --> 00:01:22,720
i'm referring to my team here as early

00:01:20,799 --> 00:01:24,000
adopters but that can mean a lot of

00:01:22,720 --> 00:01:26,080
different things to different people

00:01:24,000 --> 00:01:27,759
so in this context i'm mainly referring

00:01:26,080 --> 00:01:28,479
to being the first one or first team at

00:01:27,759 --> 00:01:30,240
your company

00:01:28,479 --> 00:01:31,920
that's building a stream processing app

00:01:30,240 --> 00:01:33,759
particularly for production use

00:01:31,920 --> 00:01:35,200
or even more specifically the first one

00:01:33,759 --> 00:01:36,479
to use a particular framework at your

00:01:35,200 --> 00:01:37,840
company

00:01:36,479 --> 00:01:39,360
this is also a good time to mention that

00:01:37,840 --> 00:01:40,880
unfortunately the project i'm talking

00:01:39,360 --> 00:01:42,560
about here is not open source

00:01:40,880 --> 00:01:44,399
so please still feel free to reach out

00:01:42,560 --> 00:01:45,840
to me about it but there are some

00:01:44,399 --> 00:01:48,079
proprietary things that i may not be

00:01:45,840 --> 00:01:50,079
able to talk about

00:01:48,079 --> 00:01:51,759
okay so on a high level this project was

00:01:50,079 --> 00:01:53,920
to create a new data pipeline

00:01:51,759 --> 00:01:55,200
to organize track and store customer

00:01:53,920 --> 00:01:56,960
usage information

00:01:55,200 --> 00:01:58,960
in a way that's highly secure and can be

00:01:56,960 --> 00:02:00,159
queried for in real time by various

00:01:58,960 --> 00:02:01,920
sources

00:02:00,159 --> 00:02:03,360
on the logistical side this is a top

00:02:01,920 --> 00:02:04,640
tier system that would need to interact

00:02:03,360 --> 00:02:06,960
with every product

00:02:04,640 --> 00:02:08,399
and a variety of other apps and services

00:02:06,960 --> 00:02:11,680
particularly those involving

00:02:08,399 --> 00:02:12,560
accounts or subscriptions in terms of

00:02:11,680 --> 00:02:14,319
people in process

00:02:12,560 --> 00:02:16,239
there's a familiar story of a tight

00:02:14,319 --> 00:02:17,280
timeline and a small team

00:02:16,239 --> 00:02:19,280
but this had the additional

00:02:17,280 --> 00:02:20,879
complications of also being at a company

00:02:19,280 --> 00:02:23,040
that was completely new to the framework

00:02:20,879 --> 00:02:25,440
we selected and was also relatively new

00:02:23,040 --> 00:02:26,800
to stream processing

00:02:25,440 --> 00:02:28,720
this is an example of what customers

00:02:26,800 --> 00:02:29,840
would see which represents usage for

00:02:28,720 --> 00:02:31,680
their account

00:02:29,840 --> 00:02:33,519
with subscriptions to various products

00:02:31,680 --> 00:02:34,720
and this shows three of usually about

00:02:33,519 --> 00:02:36,319
seven

00:02:34,720 --> 00:02:38,000
so this needs to be accurate because it

00:02:36,319 --> 00:02:39,599
will be closely tied with billing

00:02:38,000 --> 00:02:41,680
and it would need to be accessible in

00:02:39,599 --> 00:02:44,400
near real time because customers

00:02:41,680 --> 00:02:47,200
sales etc may want to check their usage

00:02:44,400 --> 00:02:48,560
at any time on a really granular level

00:02:47,200 --> 00:02:50,560
how many minutes they were connected to

00:02:48,560 --> 00:02:52,400
the product how many cpu did they use

00:02:50,560 --> 00:02:54,319
in the last hour for another project

00:02:52,400 --> 00:02:55,680
product etc

00:02:54,319 --> 00:02:57,280
and i feel like we already have a nice

00:02:55,680 --> 00:02:58,080
list of buzzwords going here so i'm

00:02:57,280 --> 00:03:00,720
going to throw in

00:02:58,080 --> 00:03:01,280
some high throughput this shows just one

00:03:00,720 --> 00:03:03,519
customer

00:03:01,280 --> 00:03:05,440
here in the in the slide who could have

00:03:03,519 --> 00:03:07,840
data for seven plus project

00:03:05,440 --> 00:03:08,640
products some having multiple units of

00:03:07,840 --> 00:03:10,560
measurement

00:03:08,640 --> 00:03:12,080
data retention specifications and

00:03:10,560 --> 00:03:14,000
subscription tiers

00:03:12,080 --> 00:03:15,280
add in the fact that there's a lot of

00:03:14,000 --> 00:03:17,360
metadata about

00:03:15,280 --> 00:03:20,000
a lot of this and then of course

00:03:17,360 --> 00:03:21,440
multiplied by a huge number of customers

00:03:20,000 --> 00:03:23,280
so we needed a system that could handle

00:03:21,440 --> 00:03:24,959
this growth and sustainably handle it

00:03:23,280 --> 00:03:26,239
for the foreseeable future

00:03:24,959 --> 00:03:27,760
luckily there's some frameworks out

00:03:26,239 --> 00:03:29,200
there that can solve for all of these

00:03:27,760 --> 00:03:31,280
challenges which is awesome

00:03:29,200 --> 00:03:32,720
and they can do so in really a powerful

00:03:31,280 --> 00:03:35,760
and impressive ways

00:03:32,720 --> 00:03:39,519
so problem solved right

00:03:35,760 --> 00:03:41,280
in the end yeah um but in order to use

00:03:39,519 --> 00:03:42,159
the features that would end up solving

00:03:41,280 --> 00:03:43,680
all of our problems

00:03:42,159 --> 00:03:45,519
we would need to integrate this new

00:03:43,680 --> 00:03:47,040
application to a large complex

00:03:45,519 --> 00:03:50,400
pre-existing system

00:03:47,040 --> 00:03:53,040
that may not be prepared at all

00:03:50,400 --> 00:03:54,239
for the impact of a powerful fast stream

00:03:53,040 --> 00:03:57,599
processing framework

00:03:54,239 --> 00:03:58,000
um that you're adding into it so we knew

00:03:57,599 --> 00:03:59,519
this

00:03:58,000 --> 00:04:01,200
that we would need to compensate for

00:03:59,519 --> 00:04:03,120
certain operational costs like storage

00:04:01,200 --> 00:04:04,239
capacity for storing state since we

00:04:03,120 --> 00:04:06,480
picked apache flink

00:04:04,239 --> 00:04:08,480
storing save points uh since those don't

00:04:06,480 --> 00:04:10,720
normally get cleaned up by the framework

00:04:08,480 --> 00:04:12,879
however we may not have been prepared

00:04:10,720 --> 00:04:15,120
for how much we needed to factor in

00:04:12,879 --> 00:04:16,799
the use cases of our dependent upstream

00:04:15,120 --> 00:04:20,000
and downstream apps into our program

00:04:16,799 --> 00:04:20,000
design and configuration

00:04:20,560 --> 00:04:26,960
so why streaming fast and slow

00:04:24,000 --> 00:04:28,320
first i want to talk about speed one of

00:04:26,960 --> 00:04:30,080
the reasons people love some of the most

00:04:28,320 --> 00:04:31,919
popular stream processing frameworks is

00:04:30,080 --> 00:04:34,720
because they optimize for low latency

00:04:31,919 --> 00:04:36,560
and can consume data obscenely fast

00:04:34,720 --> 00:04:38,720
both apache flank and apache spark for

00:04:36,560 --> 00:04:40,240
instance can process tens of millions of

00:04:38,720 --> 00:04:43,040
records per second which

00:04:40,240 --> 00:04:44,639
of course is awesome so these frameworks

00:04:43,040 --> 00:04:45,759
can enable you to stream data through a

00:04:44,639 --> 00:04:47,759
top speed

00:04:45,759 --> 00:04:49,680
cool but this means that the first

00:04:47,759 --> 00:04:52,080
problem that we encountered was

00:04:49,680 --> 00:04:53,680
as the engineer or engineering team how

00:04:52,080 --> 00:04:57,280
do you keep up with something that

00:04:53,680 --> 00:04:59,280
that's that fast to me it was kind of

00:04:57,280 --> 00:05:02,240
like training for a big sporting event

00:04:59,280 --> 00:05:03,360
like a marathon for your first time i

00:05:02,240 --> 00:05:04,639
actually had a great example of this

00:05:03,360 --> 00:05:06,479
happen to me last august

00:05:04,639 --> 00:05:08,479
in the before times when you could go

00:05:06,479 --> 00:05:10,479
outside with people in large groups

00:05:08,479 --> 00:05:12,240
um as i mentioned one of my hobbies is

00:05:10,479 --> 00:05:14,240
running and i signed up for a multiple

00:05:12,240 --> 00:05:14,800
day relay race with thousands of other

00:05:14,240 --> 00:05:17,120
runners

00:05:14,800 --> 00:05:18,479
across half the state of oregon i also

00:05:17,120 --> 00:05:19,520
may have signed up late and had about

00:05:18,479 --> 00:05:21,039
two weeks to train

00:05:19,520 --> 00:05:23,520
so it ended up being a very appropriate

00:05:21,039 --> 00:05:24,400
analogy uh the race was like nothing i'd

00:05:23,520 --> 00:05:25,680
ever done before

00:05:24,400 --> 00:05:27,600
i would need to run on multiple

00:05:25,680 --> 00:05:29,199
different types of terrain and different

00:05:27,600 --> 00:05:30,960
temperatures and times a day

00:05:29,199 --> 00:05:32,720
i would need to navigate areas i'd never

00:05:30,960 --> 00:05:34,880
been to and coordinate with lots of

00:05:32,720 --> 00:05:37,039
other people running before and after me

00:05:34,880 --> 00:05:38,000
and i would need to be able to integrate

00:05:37,039 --> 00:05:40,240
well with the

00:05:38,000 --> 00:05:42,000
streams of people running alongside me

00:05:40,240 --> 00:05:44,080
and on other routes at different paces

00:05:42,000 --> 00:05:46,000
intersecting with mine

00:05:44,080 --> 00:05:47,440
i had to come to terms with the fact

00:05:46,000 --> 00:05:48,880
that just because i'm a runner

00:05:47,440 --> 00:05:50,479
does not mean i'm prepared for this

00:05:48,880 --> 00:05:52,720
special kind of race

00:05:50,479 --> 00:05:54,479
just like how just because my team was

00:05:52,720 --> 00:05:56,000
full of talented engineers and had

00:05:54,479 --> 00:05:57,360
healthy applications

00:05:56,000 --> 00:05:59,199
didn't mean that we were automatically

00:05:57,360 --> 00:06:00,160
prepared for jumping in and keeping up

00:05:59,199 --> 00:06:02,160
with a new

00:06:00,160 --> 00:06:04,080
super fast stream processing framework

00:06:02,160 --> 00:06:05,520
at that scale

00:06:04,080 --> 00:06:08,000
but it also didn't mean that we couldn't

00:06:05,520 --> 00:06:10,080
do it or even that we couldn't do it on

00:06:08,000 --> 00:06:11,840
that tight timeline

00:06:10,080 --> 00:06:13,360
it just meant that we had to be extra

00:06:11,840 --> 00:06:15,680
cognizant of a few critical things

00:06:13,360 --> 00:06:17,440
before we started

00:06:15,680 --> 00:06:19,360
in both scenarios it wasn't just about

00:06:17,440 --> 00:06:21,680
understanding stream processing or being

00:06:19,360 --> 00:06:24,080
a skilled engineer or athlete

00:06:21,680 --> 00:06:24,960
it was about how much of the teams

00:06:24,080 --> 00:06:27,039
around you

00:06:24,960 --> 00:06:29,199
understood the process and how well you

00:06:27,039 --> 00:06:30,479
understood your impact on the others

00:06:29,199 --> 00:06:32,800
in order to really integrate that

00:06:30,479 --> 00:06:34,479
successfully

00:06:32,800 --> 00:06:36,080
for the relay race i had to completely

00:06:34,479 --> 00:06:37,759
reevaluate how i trained

00:06:36,080 --> 00:06:39,600
i had to prepare to integrate the

00:06:37,759 --> 00:06:41,360
aspects of running as familiar with

00:06:39,600 --> 00:06:43,120
into a large complicated event that

00:06:41,360 --> 00:06:44,720
involved lots of other teams running in

00:06:43,120 --> 00:06:46,080
parallel to us

00:06:44,720 --> 00:06:48,639
i would need to run in a way that could

00:06:46,080 --> 00:06:50,160
be made compatible with their processes

00:06:48,639 --> 00:06:51,759
and meet the standards of the event

00:06:50,160 --> 00:06:53,599
system as a whole

00:06:51,759 --> 00:06:56,080
my team had to be aware of the running

00:06:53,599 --> 00:06:57,120
patterns and understand how to address

00:06:56,080 --> 00:06:58,400
issues that came up

00:06:57,120 --> 00:07:00,560
with the teams that we were running

00:06:58,400 --> 00:07:02,400
upstream of us on the route

00:07:00,560 --> 00:07:04,240
in both situations we had to strengthen

00:07:02,400 --> 00:07:04,960
some communication processes within the

00:07:04,240 --> 00:07:06,639
team

00:07:04,960 --> 00:07:08,560
but more importantly we had to be able

00:07:06,639 --> 00:07:10,240
to communicate well with other teams

00:07:08,560 --> 00:07:11,840
that we wouldn't normally be interacting

00:07:10,240 --> 00:07:14,319
with on a normal daily

00:07:11,840 --> 00:07:17,120
jog just because by nature of there

00:07:14,319 --> 00:07:18,960
being such an ongoing stream of runners

00:07:17,120 --> 00:07:21,120
and that stream contained so many

00:07:18,960 --> 00:07:22,720
runners we had to recognize that our

00:07:21,120 --> 00:07:26,160
presence would now be impacting them in

00:07:22,720 --> 00:07:26,160
ways that we had not before

00:07:26,639 --> 00:07:29,840
i also had to invest in completely new

00:07:28,240 --> 00:07:31,440
running gear my old gear and other

00:07:29,840 --> 00:07:33,680
resources that i'd used in the past

00:07:31,440 --> 00:07:35,680
past had been fine when i was running

00:07:33,680 --> 00:07:37,440
only in small batches

00:07:35,680 --> 00:07:39,440
but may not be able to hold up to this

00:07:37,440 --> 00:07:41,840
new situation

00:07:39,440 --> 00:07:42,720
when i'm running in small batches with

00:07:41,840 --> 00:07:45,840
time to stop

00:07:42,720 --> 00:07:47,120
check my progress refuel or readjust

00:07:45,840 --> 00:07:48,720
there's certain resources i can just

00:07:47,120 --> 00:07:49,840
skip if they're inconvenient like

00:07:48,720 --> 00:07:51,440
wearing the right shoes

00:07:49,840 --> 00:07:53,360
even getting the right fuel or

00:07:51,440 --> 00:07:53,759
rehydration but of course if you're

00:07:53,360 --> 00:07:55,840
running

00:07:53,759 --> 00:07:57,280
anything continuously you have to figure

00:07:55,840 --> 00:07:58,000
out ways to check your progress and

00:07:57,280 --> 00:07:59,840
adjust your gear

00:07:58,000 --> 00:08:01,360
while you're still running and of course

00:07:59,840 --> 00:08:03,599
to be able to do that often if needed

00:08:01,360 --> 00:08:05,759
and sustainably

00:08:03,599 --> 00:08:07,759
so even if my old gear did miraculously

00:08:05,759 --> 00:08:08,240
hold up for such a seemingly endless

00:08:07,759 --> 00:08:10,479
dream

00:08:08,240 --> 00:08:11,360
of running is it worth it for it to just

00:08:10,479 --> 00:08:13,120
merely hold up

00:08:11,360 --> 00:08:14,639
or is it worth investing in resources

00:08:13,120 --> 00:08:15,759
that you feel confident will be able to

00:08:14,639 --> 00:08:17,280
scale with you

00:08:15,759 --> 00:08:19,759
ones that can really keep up to your

00:08:17,280 --> 00:08:21,599
full potential for power and speed

00:08:19,759 --> 00:08:22,960
and of course having to adequately test

00:08:21,599 --> 00:08:24,840
the resources making sure they're

00:08:22,960 --> 00:08:26,879
selecting the best ones and the best

00:08:24,840 --> 00:08:28,560
configurations

00:08:26,879 --> 00:08:30,080
additionally in this situation we'd be

00:08:28,560 --> 00:08:31,599
running through uncharted territory with

00:08:30,080 --> 00:08:33,680
no cell phone reception

00:08:31,599 --> 00:08:35,440
as in no existing way to track our

00:08:33,680 --> 00:08:37,279
progress for that area

00:08:35,440 --> 00:08:39,839
so we need to re-evaluate how we

00:08:37,279 --> 00:08:41,760
monitored our runners health and speed

00:08:39,839 --> 00:08:43,440
and how we could alert on any potential

00:08:41,760 --> 00:08:45,120
stops in progress or other related

00:08:43,440 --> 00:08:47,200
issues

00:08:45,120 --> 00:08:48,880
so in this analogy maybe you're a really

00:08:47,200 --> 00:08:50,480
experienced engineer

00:08:48,880 --> 00:08:53,040
maybe you've even worked with some other

00:08:50,480 --> 00:08:54,800
really powerful fast really athletic

00:08:53,040 --> 00:08:56,399
streaming frameworks before

00:08:54,800 --> 00:08:57,839
maybe your applications are really

00:08:56,399 --> 00:08:59,279
healthy and they've been in good enough

00:08:57,839 --> 00:09:02,080
shape to accommodate other really

00:08:59,279 --> 00:09:03,839
impressive changes and new technologies

00:09:02,080 --> 00:09:05,760
the engineering team that i was on was

00:09:03,839 --> 00:09:07,040
also comprised of experienced engineers

00:09:05,760 --> 00:09:09,120
who had dealt with a lot of

00:09:07,040 --> 00:09:10,640
really new and different things and most

00:09:09,120 --> 00:09:12,160
of our applications were also in really

00:09:10,640 --> 00:09:14,080
good shape

00:09:12,160 --> 00:09:15,519
however just like in the relay race we

00:09:14,080 --> 00:09:17,519
found that in order to keep up with the

00:09:15,519 --> 00:09:19,200
speed of stream processing particularly

00:09:17,519 --> 00:09:21,040
when as powerful as flank

00:09:19,200 --> 00:09:23,279
and especially when integrating our new

00:09:21,040 --> 00:09:24,480
service service into something so large

00:09:23,279 --> 00:09:26,320
and complex

00:09:24,480 --> 00:09:28,160
we still had to really slow down and

00:09:26,320 --> 00:09:30,800
make some serious adjustments to how we

00:09:28,160 --> 00:09:32,160
normally went about that process

00:09:30,800 --> 00:09:34,399
we had to be particularly careful in

00:09:32,160 --> 00:09:36,160
this case about how we impacted the tech

00:09:34,399 --> 00:09:38,160
ecosystem around us

00:09:36,160 --> 00:09:40,880
could the non-streaming sources upstream

00:09:38,160 --> 00:09:42,480
of us and downstream apps and our sync

00:09:40,880 --> 00:09:43,920
where the data ends up in our case

00:09:42,480 --> 00:09:45,600
internal data stores

00:09:43,920 --> 00:09:48,160
be able to handle this new continuous

00:09:45,600 --> 00:09:49,440
stream and could the ecosystem of people

00:09:48,160 --> 00:09:51,040
and teams around us

00:09:49,440 --> 00:09:52,480
be able to troubleshoot any issues that

00:09:51,040 --> 00:09:55,839
come up if they're unfamiliar with

00:09:52,480 --> 00:09:58,000
stream processing or flink concepts

00:09:55,839 --> 00:09:59,440
we need to drastically adjust our gear

00:09:58,000 --> 00:10:02,320
our resources like our container

00:09:59,440 --> 00:10:04,320
configurations memory allocation etc

00:10:02,320 --> 00:10:05,519
and this one seems obvious because of

00:10:04,320 --> 00:10:06,720
course you'd want to accommodate a

00:10:05,519 --> 00:10:08,160
higher amount of data that you'd be

00:10:06,720 --> 00:10:10,000
expecting to receive

00:10:08,160 --> 00:10:11,279
you want to set yourself up for scaling

00:10:10,000 --> 00:10:13,040
upwards

00:10:11,279 --> 00:10:14,720
and you know but in this case we had to

00:10:13,040 --> 00:10:16,160
be extra clear with stakeholders and

00:10:14,720 --> 00:10:18,000
others that might be in charge

00:10:16,160 --> 00:10:19,200
of say approving the resources we've

00:10:18,000 --> 00:10:20,560
requested

00:10:19,200 --> 00:10:22,959
especially if they're unfamiliar with

00:10:20,560 --> 00:10:25,200
stream processing that we may actually

00:10:22,959 --> 00:10:27,040
need more resources than just that

00:10:25,200 --> 00:10:29,519
but also we may likely need more

00:10:27,040 --> 00:10:30,959
ownership of those resources than before

00:10:29,519 --> 00:10:33,279
so you know or whoever was in charge of

00:10:30,959 --> 00:10:34,240
those resources that person would also

00:10:33,279 --> 00:10:35,440
need to be familiar with stream

00:10:34,240 --> 00:10:37,760
processing

00:10:35,440 --> 00:10:39,120
i'll get into that later so we would

00:10:37,760 --> 00:10:39,920
need to be able to allocate extra

00:10:39,120 --> 00:10:42,240
resources

00:10:39,920 --> 00:10:44,240
and have more autonomy over them to be

00:10:42,240 --> 00:10:46,160
able to handle potential data spikes

00:10:44,240 --> 00:10:47,760
and if the scene stream stops and

00:10:46,160 --> 00:10:49,200
restarts unexpectedly

00:10:47,760 --> 00:10:50,399
and any other issues that we hadn't

00:10:49,200 --> 00:10:51,920
really had to deal with when we were

00:10:50,399 --> 00:10:53,760
processing data in batches

00:10:51,920 --> 00:10:55,200
which we as the engineers who have

00:10:53,760 --> 00:10:56,000
researched stream processing would

00:10:55,200 --> 00:10:57,120
understand

00:10:56,000 --> 00:10:59,440
but again it's really about

00:10:57,120 --> 00:11:01,360
understanding who else in your ecosystem

00:10:59,440 --> 00:11:04,399
is aware of that

00:11:01,360 --> 00:11:06,399
finally we were in uncharted territory

00:11:04,399 --> 00:11:08,240
since we couldn't just stop and examine

00:11:06,399 --> 00:11:09,360
a well-defined batch of data once it'd

00:11:08,240 --> 00:11:10,480
already been processed

00:11:09,360 --> 00:11:11,839
or wait until the records are

00:11:10,480 --> 00:11:13,600
successfully written out to our data

00:11:11,839 --> 00:11:14,959
store at the very end of the pipeline

00:11:13,600 --> 00:11:17,120
we would need to find better ways of

00:11:14,959 --> 00:11:18,959
looking inside the pipeline to monitor

00:11:17,120 --> 00:11:21,760
our throughput latency and any other

00:11:18,959 --> 00:11:24,240
potential unexpected stops or spikes

00:11:21,760 --> 00:11:25,920
before they become an issue and again

00:11:24,240 --> 00:11:27,839
this seems really obvious

00:11:25,920 --> 00:11:29,040
but i want to really emphasize the scale

00:11:27,839 --> 00:11:31,040
that we're dealing with here and just

00:11:29,040 --> 00:11:33,680
how much more that complicates it

00:11:31,040 --> 00:11:35,360
so this was a particularly important uh

00:11:33,680 --> 00:11:36,640
issue since many of the teams

00:11:35,360 --> 00:11:37,920
we have so many different teams that

00:11:36,640 --> 00:11:41,519
interacted with us and that we're

00:11:37,920 --> 00:11:41,519
writing out to our pipeline as well

00:11:41,760 --> 00:11:47,279
so starting with integration um asks for

00:11:44,480 --> 00:11:49,200
integrating into the technical ecosystem

00:11:47,279 --> 00:11:50,959
this is a sad one uh some of the best

00:11:49,200 --> 00:11:51,519
features of stream processing for your

00:11:50,959 --> 00:11:53,360
team

00:11:51,519 --> 00:11:55,440
can also be the biggest drawbacks for

00:11:53,360 --> 00:11:58,720
teams that interact with you

00:11:55,440 --> 00:12:00,240
just ouch so firstly

00:11:58,720 --> 00:12:02,639
if you're unifying streams of data owned

00:12:00,240 --> 00:12:04,720
by different teams you may have

00:12:02,639 --> 00:12:06,320
you may find that some of those teams

00:12:04,720 --> 00:12:07,760
who thought they all treated their data

00:12:06,320 --> 00:12:10,560
the same

00:12:07,760 --> 00:12:11,680
maybe don't um so we found that it's

00:12:10,560 --> 00:12:13,839
best to assume

00:12:11,680 --> 00:12:15,680
that all of these teams upstream of you

00:12:13,839 --> 00:12:17,120
may be treating their data differently

00:12:15,680 --> 00:12:19,440
and and of course to make sure to have

00:12:17,120 --> 00:12:21,440
those conversations early in the process

00:12:19,440 --> 00:12:23,600
so in our case we had really specific

00:12:21,440 --> 00:12:25,839
needs for aggregating data

00:12:23,600 --> 00:12:27,040
and exactly what that needed to look

00:12:25,839 --> 00:12:28,720
like so

00:12:27,040 --> 00:12:30,720
not all teams were able to implement

00:12:28,720 --> 00:12:32,399
logic fast enough on their ends

00:12:30,720 --> 00:12:33,920
to sufficiently adhere to our schema

00:12:32,399 --> 00:12:35,440
before launch again this is for a

00:12:33,920 --> 00:12:36,240
project that's on a tight timeline so

00:12:35,440 --> 00:12:38,240
how do you

00:12:36,240 --> 00:12:39,519
be successful in that shorter amount of

00:12:38,240 --> 00:12:41,279
time so

00:12:39,519 --> 00:12:42,560
we had to factor that into our time and

00:12:41,279 --> 00:12:43,920
design

00:12:42,560 --> 00:12:45,440
we actually ended up creating a second

00:12:43,920 --> 00:12:47,279
flink app that provided all the

00:12:45,440 --> 00:12:49,279
aggregation calculations on the data

00:12:47,279 --> 00:12:51,200
that still needed it

00:12:49,279 --> 00:12:53,279
but this wasn't just an issue of extra

00:12:51,200 --> 00:12:54,959
engineering hours spent on coding

00:12:53,279 --> 00:12:56,639
this meant we now had a complicated

00:12:54,959 --> 00:12:58,240
ownership problem

00:12:56,639 --> 00:13:00,240
we had to get really creative about how

00:12:58,240 --> 00:13:01,120
we split up who owned pre-aggregated

00:13:00,240 --> 00:13:03,519
data

00:13:01,120 --> 00:13:05,360
for which teams and subsequently who was

00:13:03,519 --> 00:13:06,800
responsible for alerting and monitoring

00:13:05,360 --> 00:13:08,800
on it

00:13:06,800 --> 00:13:10,639
this in turn meant that we had to become

00:13:08,800 --> 00:13:11,839
a lot more familiar with another team's

00:13:10,639 --> 00:13:14,320
domain in order to have

00:13:11,839 --> 00:13:17,120
context for even the small slice of

00:13:14,320 --> 00:13:18,639
their system that we were monitoring for

00:13:17,120 --> 00:13:20,240
and i want to emphasize that for some of

00:13:18,639 --> 00:13:22,079
the biggest hurdles we had

00:13:20,240 --> 00:13:23,760
the best resolutions came from really

00:13:22,079 --> 00:13:25,760
slowing down and talking with those

00:13:23,760 --> 00:13:28,639
upstream and downstream teams

00:13:25,760 --> 00:13:29,040
really optimizing for our understanding

00:13:28,639 --> 00:13:31,839
of

00:13:29,040 --> 00:13:32,880
our impact on each other's domains and

00:13:31,839 --> 00:13:34,480
letting that data

00:13:32,880 --> 00:13:36,240
inform our architecture and design

00:13:34,480 --> 00:13:38,079
process

00:13:36,240 --> 00:13:39,519
otherwise you could end up at the last

00:13:38,079 --> 00:13:40,639
minute with data in a form that's

00:13:39,519 --> 00:13:42,240
unusable for you

00:13:40,639 --> 00:13:43,920
or you could end up with no one wanting

00:13:42,240 --> 00:13:45,040
to take ownership of monitoring and

00:13:43,920 --> 00:13:47,199
consequently

00:13:45,040 --> 00:13:48,079
insufficient insight into your data and

00:13:47,199 --> 00:13:51,519
worse insufficient

00:13:48,079 --> 00:13:52,639
alerting and this leads to some other

00:13:51,519 --> 00:13:55,920
related issues

00:13:52,639 --> 00:13:58,160
oops yeah with uh did not skip ahead

00:13:55,920 --> 00:13:59,600
with being an early adopter and part of

00:13:58,160 --> 00:14:02,800
that is i want to talk about

00:13:59,600 --> 00:14:04,240
creating and automating community within

00:14:02,800 --> 00:14:05,760
our within your company

00:14:04,240 --> 00:14:07,279
for the stream processing framework that

00:14:05,760 --> 00:14:09,120
you've selected

00:14:07,279 --> 00:14:10,639
and basically how this was really one of

00:14:09,120 --> 00:14:12,560
the best ways we found to mitigate some

00:14:10,639 --> 00:14:14,399
of those roadblocks

00:14:12,560 --> 00:14:16,160
this was helpful because as i mentioned

00:14:14,399 --> 00:14:17,920
we were impacting teams in ways that we

00:14:16,160 --> 00:14:19,839
had not impacted them before

00:14:17,920 --> 00:14:21,920
we were also using shared resources like

00:14:19,839 --> 00:14:22,959
aws buckets and internal container and

00:14:21,920 --> 00:14:24,639
deployment tools

00:14:22,959 --> 00:14:26,720
in a way that they had never been used

00:14:24,639 --> 00:14:27,279
before either this meant we needed to

00:14:26,720 --> 00:14:29,360
understand

00:14:27,279 --> 00:14:30,959
other teams applications much better

00:14:29,360 --> 00:14:32,800
than we'd normally have to

00:14:30,959 --> 00:14:34,079
but it also meant that other teams and

00:14:32,800 --> 00:14:37,040
leaders architects

00:14:34,079 --> 00:14:38,560
etc suddenly needed to be familiar with

00:14:37,040 --> 00:14:40,480
our monitoring

00:14:38,560 --> 00:14:42,639
as well as be familiar with some basic

00:14:40,480 --> 00:14:46,320
stream processing and flink concepts

00:14:42,639 --> 00:14:46,320
so they could understand our monitoring

00:14:46,399 --> 00:14:50,639
so what do i mean by automating an

00:14:48,320 --> 00:14:52,720
internal community

00:14:50,639 --> 00:14:54,399
okay so if we address each inter-team

00:14:52,720 --> 00:14:56,399
related issue as it comes up

00:14:54,399 --> 00:14:57,519
this would be a long and painful process

00:14:56,399 --> 00:14:58,000
and it would keep us away from our

00:14:57,519 --> 00:15:00,720
engineering

00:14:58,000 --> 00:15:02,399
work so we found that the heart of most

00:15:00,720 --> 00:15:04,320
these issues were the same

00:15:02,399 --> 00:15:06,160
engineers having to repeatedly advocate

00:15:04,320 --> 00:15:08,480
for or explain our system or flink

00:15:06,160 --> 00:15:09,920
concepts to others

00:15:08,480 --> 00:15:11,760
this meant though that we could easily

00:15:09,920 --> 00:15:13,839
automate resolution for these issues

00:15:11,760 --> 00:15:15,920
and make a virtuous cycle of information

00:15:13,839 --> 00:15:17,839
sharing through creating things like a

00:15:15,920 --> 00:15:20,079
safe space for others to experiment with

00:15:17,839 --> 00:15:21,600
stream processing and in our case flink

00:15:20,079 --> 00:15:23,120
as well as providing interactive

00:15:21,600 --> 00:15:26,000
documentation and of course

00:15:23,120 --> 00:15:27,440
a good detailed map so here's where the

00:15:26,000 --> 00:15:28,399
running analogy gets a little too

00:15:27,440 --> 00:15:30,160
literal

00:15:28,399 --> 00:15:32,639
so my team for the relay race were also

00:15:30,160 --> 00:15:34,320
my co-workers in a different org though

00:15:32,639 --> 00:15:36,320
so my running team and my engineering

00:15:34,320 --> 00:15:38,480
team both use the same internal

00:15:36,320 --> 00:15:40,800
platform to both create blog posts that

00:15:38,480 --> 00:15:44,079
both cover the same two topics

00:15:40,800 --> 00:15:45,839
including we both had how-to manuals

00:15:44,079 --> 00:15:47,279
for anyone who was interested in either

00:15:45,839 --> 00:15:49,040
training like my running team

00:15:47,279 --> 00:15:50,639
or creating their own flink cluster and

00:15:49,040 --> 00:15:52,480
how to integrate that with the internal

00:15:50,639 --> 00:15:54,079
tools at that company

00:15:52,480 --> 00:15:56,639
we each also had an overview for the

00:15:54,079 --> 00:15:59,440
project with a glossary of terms

00:15:56,639 --> 00:16:01,600
which was really helpful uh the blog

00:15:59,440 --> 00:16:03,120
format of course was chosen specifically

00:16:01,600 --> 00:16:05,040
so that people from other teams

00:16:03,120 --> 00:16:06,720
leadership etc could ask questions or

00:16:05,040 --> 00:16:09,279
even give advice in the comments

00:16:06,720 --> 00:16:10,480
super simple super effective um sharing

00:16:09,279 --> 00:16:12,000
these posts saved us

00:16:10,480 --> 00:16:15,120
so much time and having to explain what

00:16:12,000 --> 00:16:18,800
the heck we're working on in both cases

00:16:15,120 --> 00:16:21,279
so as for supporting experimentation

00:16:18,800 --> 00:16:23,600
both for the launch of the relay race

00:16:21,279 --> 00:16:25,600
and for our new streaming application

00:16:23,600 --> 00:16:27,680
my team in both situations created

00:16:25,600 --> 00:16:28,959
accessible chat rooms to support people

00:16:27,680 --> 00:16:30,240
who are experimenting with

00:16:28,959 --> 00:16:32,160
and wanting to get help for something

00:16:30,240 --> 00:16:34,240
that was new for them

00:16:32,160 --> 00:16:36,720
in both cases people would ask each

00:16:34,240 --> 00:16:38,639
other questions about what resources

00:16:36,720 --> 00:16:40,079
progress monitoring tools and other

00:16:38,639 --> 00:16:41,199
things that people were used that were

00:16:40,079 --> 00:16:42,639
related

00:16:41,199 --> 00:16:44,240
people would ask if others wanted to

00:16:42,639 --> 00:16:45,120
collaborate on training sessions

00:16:44,240 --> 00:16:46,959
together

00:16:45,120 --> 00:16:48,800
they would encourage others for how well

00:16:46,959 --> 00:16:50,480
their sessions went and commiserated

00:16:48,800 --> 00:16:53,519
when experiment failed

00:16:50,480 --> 00:16:54,480
this sounds basic because it is super

00:16:53,519 --> 00:16:56,399
basic

00:16:54,480 --> 00:16:57,680
but it was an incredibly important

00:16:56,399 --> 00:16:59,600
baseline for us

00:16:57,680 --> 00:17:01,279
that enabled us to cultivate a group of

00:16:59,600 --> 00:17:03,120
people who felt comfortable

00:17:01,279 --> 00:17:05,199
doing their own work to become more

00:17:03,120 --> 00:17:07,120
knowledgeable and became increasingly

00:17:05,199 --> 00:17:08,880
more enthusiastic about participating

00:17:07,120 --> 00:17:11,039
and helping each other out

00:17:08,880 --> 00:17:11,919
in the end my team was able to lean on

00:17:11,039 --> 00:17:14,160
them

00:17:11,919 --> 00:17:16,000
a lot uh and lean on this whole

00:17:14,160 --> 00:17:17,679
community that we had built

00:17:16,000 --> 00:17:19,520
and they were able to help us out and

00:17:17,679 --> 00:17:22,000
actually get us unstuck on a lot of real

00:17:19,520 --> 00:17:22,720
problems really big problems um later on

00:17:22,000 --> 00:17:25,520
in the project

00:17:22,720 --> 00:17:27,039
so it was huge and i couldn't share the

00:17:25,520 --> 00:17:28,640
internal work slack but here's a

00:17:27,039 --> 00:17:29,760
screenshot from the slack space for the

00:17:28,640 --> 00:17:32,080
running team

00:17:29,760 --> 00:17:34,000
um so just replace elevation gain with

00:17:32,080 --> 00:17:34,960
records per second and miles with kafka

00:17:34,000 --> 00:17:37,840
topics and you can

00:17:34,960 --> 00:17:38,720
you could basically swap those two out

00:17:37,840 --> 00:17:41,520
thirdly

00:17:38,720 --> 00:17:43,600
always take a map in both scenarios this

00:17:41,520 --> 00:17:46,320
wasn't just about having a math

00:17:43,600 --> 00:17:48,080
map of the pathway from start to finish

00:17:46,320 --> 00:17:49,200
but it was essential that we clarified

00:17:48,080 --> 00:17:51,039
the integration points

00:17:49,200 --> 00:17:53,360
along the way so other teams could

00:17:51,039 --> 00:17:55,600
quickly assess where they were and who

00:17:53,360 --> 00:17:57,360
they impacted in case of an emergency

00:17:55,600 --> 00:18:00,160
again it's all about making this

00:17:57,360 --> 00:18:02,320
very efficient and easy to read so with

00:18:00,160 --> 00:18:03,919
each more detailed iteration

00:18:02,320 --> 00:18:05,600
of our map uh other teams that

00:18:03,919 --> 00:18:06,080
interacted us with us were able to

00:18:05,600 --> 00:18:08,000
become

00:18:06,080 --> 00:18:10,400
more and more autonomous giving us more

00:18:08,000 --> 00:18:12,000
time to work on our engineering work

00:18:10,400 --> 00:18:14,400
another essential map that we used in

00:18:12,000 --> 00:18:16,480
both cases was a flow chart for incident

00:18:14,400 --> 00:18:17,919
response and triage

00:18:16,480 --> 00:18:19,679
if you get lost in the woods and end up

00:18:17,919 --> 00:18:20,320
running in a circle which did happen to

00:18:19,679 --> 00:18:22,320
someone

00:18:20,320 --> 00:18:24,320
or your flink application stops and

00:18:22,320 --> 00:18:27,440
instead of restarting successfully it

00:18:24,320 --> 00:18:28,640
begins to cycle for minutes on end scary

00:18:27,440 --> 00:18:30,400
stuff

00:18:28,640 --> 00:18:33,039
in both scenarios the incident response

00:18:30,400 --> 00:18:35,039
flow charts were ridiculously simple

00:18:33,039 --> 00:18:36,400
because that's exactly what you need if

00:18:35,039 --> 00:18:40,960
you get lost in three in the morning

00:18:36,400 --> 00:18:42,720
either way which brings us to operations

00:18:40,960 --> 00:18:44,960
most people here probably have a good

00:18:42,720 --> 00:18:47,760
idea of the main operational drawbacks

00:18:44,960 --> 00:18:49,520
drawbacks and risks of stream processing

00:18:47,760 --> 00:18:51,280
like storage

00:18:49,520 --> 00:18:52,720
particularly with frameworks like flink

00:18:51,280 --> 00:18:53,600
where you might be storing things like

00:18:52,720 --> 00:18:54,960
save points

00:18:53,600 --> 00:18:56,960
in a different way that you're storing

00:18:54,960 --> 00:19:00,160
elements like your state's state

00:18:56,960 --> 00:19:01,440
snapshots most well architected stream

00:19:00,160 --> 00:19:03,520
processing frameworks

00:19:01,440 --> 00:19:06,080
have some features or workarounds that

00:19:03,520 --> 00:19:08,880
make this pretty easily remedy though

00:19:06,080 --> 00:19:10,799
we even planned ahead for this project

00:19:08,880 --> 00:19:12,720
um for how well

00:19:10,799 --> 00:19:14,640
that flinks specifically would integrate

00:19:12,720 --> 00:19:16,960
technically with the tools that we'd be

00:19:14,640 --> 00:19:18,640
using and had support for

00:19:16,960 --> 00:19:20,480
a lot of our choices had to do with how

00:19:18,640 --> 00:19:23,520
well it could integrate with things

00:19:20,480 --> 00:19:25,120
like mesos and zookeeper however

00:19:23,520 --> 00:19:27,039
because this was a large company with

00:19:25,120 --> 00:19:28,559
lots of operations separated into

00:19:27,039 --> 00:19:30,240
specialized teams

00:19:28,559 --> 00:19:31,760
we still had issues with the fact that

00:19:30,240 --> 00:19:33,120
just because these tools are technically

00:19:31,760 --> 00:19:35,200
compatible

00:19:33,120 --> 00:19:36,320
didn't mean that they were configured in

00:19:35,200 --> 00:19:37,600
a way that was going to be really

00:19:36,320 --> 00:19:39,360
helpful to us

00:19:37,600 --> 00:19:41,280
it also meant that we had no control

00:19:39,360 --> 00:19:42,960
over reconfiguring them

00:19:41,280 --> 00:19:45,039
and they might be a shared resource in

00:19:42,960 --> 00:19:46,559
which case configuration would be slow

00:19:45,039 --> 00:19:48,559
and involve a lot of completely

00:19:46,559 --> 00:19:50,320
unrelated teams as well

00:19:48,559 --> 00:19:52,320
internal deployment tools are probably

00:19:50,320 --> 00:19:54,000
the most common example for this

00:19:52,320 --> 00:19:55,919
and something that we did have to find a

00:19:54,000 --> 00:19:57,760
workaround for

00:19:55,919 --> 00:20:00,320
since we didn't own them and deployment

00:19:57,760 --> 00:20:02,720
is used by just about every team

00:20:00,320 --> 00:20:03,679
reconfiguring them for just our use case

00:20:02,720 --> 00:20:06,640
was

00:20:03,679 --> 00:20:08,159
was and would be a very arduous process

00:20:06,640 --> 00:20:10,240
we worked around this by creating and

00:20:08,159 --> 00:20:12,159
owning a deploy script in the beginning

00:20:10,240 --> 00:20:14,240
so we could we could get started and

00:20:12,159 --> 00:20:15,919
still be able to deploy and and be able

00:20:14,240 --> 00:20:17,840
to iterate quickly

00:20:15,919 --> 00:20:20,000
and we did that while we were working on

00:20:17,840 --> 00:20:22,799
a more automated long-term solution

00:20:20,000 --> 00:20:25,039
which we were eventually able to do and

00:20:22,799 --> 00:20:26,320
at first we manually uploaded the script

00:20:25,039 --> 00:20:27,919
and that was something we were able to

00:20:26,320 --> 00:20:29,600
hook into the tools using a hook that we

00:20:27,919 --> 00:20:30,960
wrote as well so there was a lot that

00:20:29,600 --> 00:20:33,200
went in there for

00:20:30,960 --> 00:20:35,120
creating this uh on our team from

00:20:33,200 --> 00:20:38,559
scratch

00:20:35,120 --> 00:20:39,280
so lastly analytics with the running

00:20:38,559 --> 00:20:40,559
analogy

00:20:39,280 --> 00:20:42,320
it was important to make sure that

00:20:40,559 --> 00:20:45,360
monitoring was well coordinated

00:20:42,320 --> 00:20:47,280
between teams and our stakeholders

00:20:45,360 --> 00:20:48,880
in this case in the running case

00:20:47,280 --> 00:20:50,720
stakeholders could be the rest of your

00:20:48,880 --> 00:20:51,840
team who's ahead or behind you or it

00:20:50,720 --> 00:20:53,280
could be your family

00:20:51,840 --> 00:20:55,039
who's following your progress on a

00:20:53,280 --> 00:20:56,720
running app that's streaming your gps

00:20:55,039 --> 00:20:58,000
signal to them in real time which was

00:20:56,720 --> 00:20:59,840
pretty cool

00:20:58,000 --> 00:21:01,600
during the relay race my stakeholders

00:20:59,840 --> 00:21:03,280
which was my family were remotely

00:21:01,600 --> 00:21:05,120
following my progress on the app

00:21:03,280 --> 00:21:06,559
and when my progress stopped and

00:21:05,120 --> 00:21:07,120
disappeared suddenly at three in the

00:21:06,559 --> 00:21:09,360
morning

00:21:07,120 --> 00:21:11,919
with no way of alerting them that was

00:21:09,360 --> 00:21:13,520
some pretty unhappy stakeholders

00:21:11,919 --> 00:21:15,039
and none of us wants unhappy

00:21:13,520 --> 00:21:16,559
stakeholders

00:21:15,039 --> 00:21:18,400
so although my team learned that we

00:21:16,559 --> 00:21:20,559
needed better monitoring for

00:21:18,400 --> 00:21:21,600
our running routes kind of like a

00:21:20,559 --> 00:21:23,679
pipeline

00:21:21,600 --> 00:21:25,440
it helped that the the team at least

00:21:23,679 --> 00:21:26,640
knew what the normal pace was for each

00:21:25,440 --> 00:21:29,039
runner

00:21:26,640 --> 00:21:29,679
which gave them a reasonable threshold

00:21:29,039 --> 00:21:31,520
to know

00:21:29,679 --> 00:21:33,360
when to alert of a certain duration of

00:21:31,520 --> 00:21:34,080
time it passed without seeing a runner

00:21:33,360 --> 00:21:37,120
exit the

00:21:34,080 --> 00:21:38,880
pipeline luckily the engineering team

00:21:37,120 --> 00:21:41,120
made several features to compensate for

00:21:38,880 --> 00:21:42,640
this including creating unique fields to

00:21:41,120 --> 00:21:45,200
key data on just for

00:21:42,640 --> 00:21:46,240
within the pipeline in the stream

00:21:45,200 --> 00:21:48,159
processing scenario

00:21:46,240 --> 00:21:49,600
stakeholders often ended up being teams

00:21:48,159 --> 00:21:52,080
that own the applications

00:21:49,600 --> 00:21:52,640
upstream and downstream of us as i said

00:21:52,080 --> 00:21:54,159
earlier

00:21:52,640 --> 00:21:56,240
we found that we had to be much more

00:21:54,159 --> 00:21:57,440
familiar with particularly our upstream

00:21:56,240 --> 00:21:59,440
applications

00:21:57,440 --> 00:22:01,440
than we'd ever needed to be for our old

00:21:59,440 --> 00:22:03,039
batch applications

00:22:01,440 --> 00:22:05,039
and this is particularly true for

00:22:03,039 --> 00:22:06,799
applications that may have really

00:22:05,039 --> 00:22:09,200
sensitive alerting around

00:22:06,799 --> 00:22:10,320
increases or pauses and data flow

00:22:09,200 --> 00:22:12,640
especially

00:22:10,320 --> 00:22:13,679
if their way of alerting and what they

00:22:12,640 --> 00:22:15,520
want to alert on

00:22:13,679 --> 00:22:17,360
is not totally aligned with what you're

00:22:15,520 --> 00:22:19,440
looking for um

00:22:17,360 --> 00:22:21,039
and again that might sound obvious but

00:22:19,440 --> 00:22:22,240
it was something that we really had to

00:22:21,039 --> 00:22:23,600
pause and take a

00:22:22,240 --> 00:22:25,679
pretty solid look at so if you're

00:22:23,600 --> 00:22:26,320
relying on their alerting to signify any

00:22:25,679 --> 00:22:27,679
issues

00:22:26,320 --> 00:22:29,600
that might legitimately impact your

00:22:27,679 --> 00:22:29,919
pipeline definitely a great opportunity

00:22:29,600 --> 00:22:32,480
for

00:22:29,919 --> 00:22:33,280
collaborating on that and re-evaluating

00:22:32,480 --> 00:22:35,120
that

00:22:33,280 --> 00:22:37,360
so for ensuring that these teams

00:22:35,120 --> 00:22:39,440
understood our monitoring

00:22:37,360 --> 00:22:41,600
most of that was about 45 minutes of

00:22:39,440 --> 00:22:43,360
relabeling our dashboards and posting

00:22:41,600 --> 00:22:44,960
them in our stakeholder slack

00:22:43,360 --> 00:22:46,720
so ended up being pretty efficient

00:22:44,960 --> 00:22:48,880
actually so for instance

00:22:46,720 --> 00:22:50,799
we may need to monitor spikes and data

00:22:48,880 --> 00:22:52,799
from a particular source

00:22:50,799 --> 00:22:54,640
like one of our incoming kafka topics

00:22:52,799 --> 00:22:57,039
but the data coming in from that source

00:22:54,640 --> 00:22:57,679
only affects one of our downstream teams

00:22:57,039 --> 00:22:59,840
so

00:22:57,679 --> 00:23:00,720
if we wanted to be nice and keep things

00:22:59,840 --> 00:23:02,320
really efficient

00:23:00,720 --> 00:23:03,760
we wanted to make sure that it was

00:23:02,320 --> 00:23:05,440
really clear in the labeling so that

00:23:03,760 --> 00:23:06,559
only that team would know that it

00:23:05,440 --> 00:23:08,400
affected them

00:23:06,559 --> 00:23:09,520
and also that they would absolutely know

00:23:08,400 --> 00:23:10,880
that it that they should be paying

00:23:09,520 --> 00:23:12,640
attention to it as well so they wouldn't

00:23:10,880 --> 00:23:15,200
miss it

00:23:12,640 --> 00:23:17,440
and uh earlier going back to the the

00:23:15,200 --> 00:23:19,919
running analogy

00:23:17,440 --> 00:23:22,159
so in that several day relay race those

00:23:19,919 --> 00:23:24,880
issues like unexpected stops in progress

00:23:22,159 --> 00:23:26,240
could signify a really serious issue so

00:23:24,880 --> 00:23:28,559
it was imperative to have a way to

00:23:26,240 --> 00:23:30,480
monitor an alert on this

00:23:28,559 --> 00:23:32,080
it was also important to understand as i

00:23:30,480 --> 00:23:32,799
said earlier the typical pace of a

00:23:32,080 --> 00:23:34,400
runner

00:23:32,799 --> 00:23:36,080
or in the stream processing case it's

00:23:34,400 --> 00:23:38,640
important to know what normal

00:23:36,080 --> 00:23:39,200
looks like for your application and i

00:23:38,640 --> 00:23:41,919
don't just

00:23:39,200 --> 00:23:43,760
mean kind of a good enough gut feeling

00:23:41,919 --> 00:23:45,760
but really making sure the whole team

00:23:43,760 --> 00:23:46,960
understands what normal is on a very

00:23:45,760 --> 00:23:49,760
granular level

00:23:46,960 --> 00:23:50,480
we also found that for all of our older

00:23:49,760 --> 00:23:53,520
projects

00:23:50,480 --> 00:23:55,279
and all the other um non-streaming

00:23:53,520 --> 00:23:56,559
applications that we started from

00:23:55,279 --> 00:23:58,080
scratch

00:23:56,559 --> 00:23:59,600
really only the team needed to know what

00:23:58,080 --> 00:24:01,360
normal looked like and for this

00:23:59,600 --> 00:24:03,600
situation we found that a lot more

00:24:01,360 --> 00:24:05,360
stakeholders architects etc

00:24:03,600 --> 00:24:06,640
also needed to be made aware of what

00:24:05,360 --> 00:24:08,080
normal looks like

00:24:06,640 --> 00:24:10,000
because it's just gonna have that much

00:24:08,080 --> 00:24:11,919
wider impact so

00:24:10,000 --> 00:24:14,080
um it doesn't really have to be that

00:24:11,919 --> 00:24:16,400
complicated is what we found

00:24:14,080 --> 00:24:18,720
so what i have here in these slides is a

00:24:16,400 --> 00:24:20,480
bit of an oversimplified example

00:24:18,720 --> 00:24:22,799
but we've got three products that were

00:24:20,480 --> 00:24:26,080
upstream of us represented here

00:24:22,799 --> 00:24:26,559
in this situation 9 10 to 9 15 time

00:24:26,080 --> 00:24:28,880
spike

00:24:26,559 --> 00:24:30,480
was normal but we only knew that was

00:24:28,880 --> 00:24:31,600
normal by talking to those upstream

00:24:30,480 --> 00:24:34,799
teams

00:24:31,600 --> 00:24:35,919
and we also found that just knowing what

00:24:34,799 --> 00:24:37,360
normal is

00:24:35,919 --> 00:24:38,720
and just saying okay i've checked that

00:24:37,360 --> 00:24:40,320
box i know what it is i'm going to put

00:24:38,720 --> 00:24:42,640
it in documentation or whatever

00:24:40,320 --> 00:24:44,240
isn't always enough because what if they

00:24:42,640 --> 00:24:46,960
change their schedule

00:24:44,240 --> 00:24:49,279
or what if one team's products event

00:24:46,960 --> 00:24:52,159
time processing is based in utc

00:24:49,279 --> 00:24:53,279
and the other in pst uh most of these

00:24:52,159 --> 00:24:54,960
things were not a problem

00:24:53,279 --> 00:24:57,039
until we started combining those data

00:24:54,960 --> 00:24:59,200
streams into one pipeline

00:24:57,039 --> 00:25:01,440
uh also what if one of those time zones

00:24:59,200 --> 00:25:03,440
does daylight savings and one doesn't

00:25:01,440 --> 00:25:06,240
so finding those things out ahead of

00:25:03,440 --> 00:25:09,200
time was incredibly helpful

00:25:06,240 --> 00:25:10,640
um and it's really about again not just

00:25:09,200 --> 00:25:12,000
finding what normal is now

00:25:10,640 --> 00:25:13,600
but what normal is going to look like in

00:25:12,000 --> 00:25:14,480
the future what normals look like in the

00:25:13,600 --> 00:25:17,600
past

00:25:14,480 --> 00:25:20,480
and keeping an eye on if normal changes

00:25:17,600 --> 00:25:22,240
and how long of a period of time means

00:25:20,480 --> 00:25:23,360
normal and what is good and bad in that

00:25:22,240 --> 00:25:26,559
situation

00:25:23,360 --> 00:25:27,600
so again that normal spike might move in

00:25:26,559 --> 00:25:29,279
the future

00:25:27,600 --> 00:25:30,880
so it's really about understanding what

00:25:29,279 --> 00:25:32,720
their as in the upstream teams

00:25:30,880 --> 00:25:35,440
threshold for alerting is and how that's

00:25:32,720 --> 00:25:35,440
going to impact you

00:25:35,600 --> 00:25:39,279
and it's again it's about ensuring if

00:25:37,679 --> 00:25:41,520
you're monitoring the right metrics

00:25:39,279 --> 00:25:42,799
and what you're doing to ensure you know

00:25:41,520 --> 00:25:45,120
what those metrics

00:25:42,799 --> 00:25:46,480
not being correct means so in this one

00:25:45,120 --> 00:25:48,400
we actually had some debates

00:25:46,480 --> 00:25:50,320
um again this is just an example but

00:25:48,400 --> 00:25:51,120
it's an example of basically a real life

00:25:50,320 --> 00:25:53,600
thing

00:25:51,120 --> 00:25:55,039
of you know we had the threshold a

00:25:53,600 --> 00:25:55,600
little bit higher so it was actually

00:25:55,039 --> 00:25:58,640
above

00:25:55,600 --> 00:26:00,480
that the spike that's in red um

00:25:58,640 --> 00:26:02,240
and the upstream teams let us know like

00:26:00,480 --> 00:26:03,840
no this actually really matters that

00:26:02,240 --> 00:26:05,919
spike is bad we want to make sure that

00:26:03,840 --> 00:26:08,240
we are alerting on that the instant

00:26:05,919 --> 00:26:09,919
it comes up there even though that same

00:26:08,240 --> 00:26:10,640
spike is perfectly fine if it happens

00:26:09,919 --> 00:26:13,120
within

00:26:10,640 --> 00:26:14,480
the 910 to 915 range so it's really

00:26:13,120 --> 00:26:16,240
understanding about where that threshold

00:26:14,480 --> 00:26:16,559
is for those teams and not just about

00:26:16,240 --> 00:26:20,559
for

00:26:16,559 --> 00:26:22,720
for your pipeline as well um

00:26:20,559 --> 00:26:23,600
so yeah like are there daily spikes that

00:26:22,720 --> 00:26:26,080
are okay

00:26:23,600 --> 00:26:27,840
and uh and again this example i think

00:26:26,080 --> 00:26:29,919
one of these was that the app

00:26:27,840 --> 00:26:31,120
did that team's app did right like on a

00:26:29,919 --> 00:26:34,159
once a day batch

00:26:31,120 --> 00:26:35,760
so it's all very good stuff to know and

00:26:34,159 --> 00:26:37,200
in both scenarios

00:26:35,760 --> 00:26:39,760
seeing a slowdown in progress might

00:26:37,200 --> 00:26:41,200
actually be okay but it's all about

00:26:39,760 --> 00:26:43,120
the fact that you want to calculate a

00:26:41,200 --> 00:26:45,520
threshold to alert on based on that

00:26:43,120 --> 00:26:48,720
normal and based on what abnormally slow

00:26:45,520 --> 00:26:50,480
is for that particular application or

00:26:48,720 --> 00:26:52,240
data stream or that runner

00:26:50,480 --> 00:26:55,200
and so you know when you really need to

00:26:52,240 --> 00:26:55,200
start getting concerned

00:26:56,159 --> 00:27:00,720
so in the end i love working with stream

00:26:58,799 --> 00:27:03,440
processing because it can be so

00:27:00,720 --> 00:27:05,440
incredibly fast frameworks like apache

00:27:03,440 --> 00:27:08,080
flink spark and kafka streams

00:27:05,440 --> 00:27:09,600
have amazing features that can and and

00:27:08,080 --> 00:27:11,600
honestly genuinely for us

00:27:09,600 --> 00:27:13,760
did solve a lot of really big

00:27:11,600 --> 00:27:15,200
complicated problems

00:27:13,760 --> 00:27:16,960
however keeping up with something that

00:27:15,200 --> 00:27:18,880
fast and powerful can definitely take

00:27:16,960 --> 00:27:20,399
some creative readjustments to integrate

00:27:18,880 --> 00:27:22,720
if you're putting that into a

00:27:20,399 --> 00:27:24,080
pre-existing non-streaming system

00:27:22,720 --> 00:27:26,320
uh take it from me though when you speed

00:27:24,080 --> 00:27:27,440
through that finish line totally worth

00:27:26,320 --> 00:27:29,039
it so with that

00:27:27,440 --> 00:27:30,320
thank you so much everyone and i'm

00:27:29,039 --> 00:27:30,799
really looking forward to meeting you

00:27:30,320 --> 00:27:32,799
all

00:27:30,799 --> 00:27:34,399
in the social and in the slack space so

00:27:32,799 --> 00:27:36,000
come say hi

00:27:34,399 --> 00:27:38,080
and a special thank you to berlin

00:27:36,000 --> 00:27:41,200
buzzwords haystack mices

00:27:38,080 --> 00:27:43,679
and all the event staff and um yeah

00:27:41,200 --> 00:27:43,679
big thanks

00:27:44,480 --> 00:27:48,159
so thank you everyone to join the

00:27:47,200 --> 00:27:51,679
session with kaido

00:27:48,159 --> 00:27:52,880
hi uh so feel free to post any questions

00:27:51,679 --> 00:27:57,200
on the channel

00:27:52,880 --> 00:27:59,840
bebas1 or directly message to her

00:27:57,200 --> 00:27:59,840
and uh yeah

00:28:00,799 --> 00:28:03,919
cool thank you so much thank you uh very

00:28:02,720 --> 00:28:04,559
much for moderating this this was

00:28:03,919 --> 00:28:07,600
awesome

00:28:04,559 --> 00:28:10,159
uh very surreal to watch myself talk

00:28:07,600 --> 00:28:11,600
oh that was super fun and yeah feel free

00:28:10,159 --> 00:28:14,000
to post up on the channel um

00:28:11,600 --> 00:28:16,480
i as i as martina mentioned i won't be

00:28:14,000 --> 00:28:18,159
able to join the breakout session um but

00:28:16,480 --> 00:28:19,279
i'm here for the conference and i'll be

00:28:18,159 --> 00:28:21,520
at all the socials and

00:28:19,279 --> 00:28:22,960
like seriously please feel free to reach

00:28:21,520 --> 00:28:31,840
out to me over slack or the

00:28:22,960 --> 00:28:31,840
umbrella meetings i promise and friendly

00:28:45,600 --> 00:28:47,679

YouTube URL: https://www.youtube.com/watch?v=6AHDYEwLi6Y


