Title: Tracing Ceph Using Jaeger-BlkKin
Publication date: 2019-02-25
Playlist: DevConfUS 2018
Description: 
	BlkKin is a custom end-to-end tracing infrastructure for Ceph. It captures the work done to process individual requests within and among Ceph’s components. But, it can only be turned on for individual requests and cannot be left always-on due to the resulting overhead. We present Jaeger-BlkKin, which can be used in always-on fashion in production with low overhead. Jaeger-BlkKin is constructed by replacing much of Blkkin’s tracing functionality with that of Jaeger, a widely-deployed open source tracing infrastructure. Jaeger-Blkkin is OpenTracing compatible, meaning that it can be replaced easily with other, even more advanced tracing infrastructures when they become available.
Captions: 
	00:00:02,530 --> 00:00:15,309
I request you all to kinda settle down

00:00:11,379 --> 00:00:17,830
next up we have a very fond mentor of

00:00:15,309 --> 00:00:20,440
mine and a passion of a PhD student and

00:00:17,830 --> 00:00:22,870
Northeastern University money Abdi she's

00:00:20,440 --> 00:00:30,430
gonna talk about and 2n tracing and

00:00:22,870 --> 00:00:32,110
self-worth Jaeger hello everyone my name

00:00:30,430 --> 00:00:34,960
is Vania and today I'm talking about

00:00:32,110 --> 00:00:37,329
enter and tracing instead using Jaeger

00:00:34,960 --> 00:00:41,820
this is a joint work between MOC

00:00:37,329 --> 00:00:41,820
northeastern bu and red hat and

00:00:43,690 --> 00:00:50,050
self is a larger scale distributed

00:00:45,280 --> 00:00:52,570
system and it consists of many notes and

00:00:50,050 --> 00:00:54,670
it is highly praised by community and it

00:00:52,570 --> 00:00:58,270
has been and it has been deployed over

00:00:54,670 --> 00:01:01,239
many data centers around the world now

00:00:58,270 --> 00:01:03,970
let's look at the self architecture and

00:01:01,239 --> 00:01:08,650
take a look at how seven works actually

00:01:03,970 --> 00:01:10,780
we have self nodes and from seven nodes

00:01:08,650 --> 00:01:13,720
we start from the client and here are

00:01:10,780 --> 00:01:16,630
the client knows client nodes client

00:01:13,720 --> 00:01:19,390
node sense they go to back in and write

00:01:16,630 --> 00:01:21,430
data read data and write data from ant

00:01:19,390 --> 00:01:24,460
to back-end and they are there are there

00:01:21,430 --> 00:01:26,500
are tons of clients and then there are

00:01:24,460 --> 00:01:29,280
always signals which are used to store

00:01:26,500 --> 00:01:32,259
data within the staff and we have the

00:01:29,280 --> 00:01:35,610
metadata server which is used for

00:01:32,259 --> 00:01:38,910
storing metadata information for service

00:01:35,610 --> 00:01:44,560
and Seneca Lions also communicate with

00:01:38,910 --> 00:01:47,560
surface storage to reduce API and then

00:01:44,560 --> 00:01:50,110
we have monitors and monitors are useful

00:01:47,560 --> 00:01:53,099
for maintaining the clustering and the

00:01:50,110 --> 00:01:53,099
cluster status

00:01:55,130 --> 00:02:02,420
nerves are insufficient for debugging

00:01:58,189 --> 00:02:05,720
and let me give you an example of self

00:02:02,420 --> 00:02:08,270
debugging a problem instead here as you

00:02:05,720 --> 00:02:10,459
can see is a very very simple write

00:02:08,270 --> 00:02:13,370
request that the user can issue and a

00:02:10,459 --> 00:02:16,670
client can issue to self and as you can

00:02:13,370 --> 00:02:19,850
see a very simple write request for very

00:02:16,670 --> 00:02:21,890
tiny amount of data first issue a check

00:02:19,850 --> 00:02:25,340
metadata request and the technology I

00:02:21,890 --> 00:02:29,239
request involves many many clients many

00:02:25,340 --> 00:02:32,480
many OS T's and then the user Rockstar

00:02:29,239 --> 00:02:35,630
to write data to back-end and again it

00:02:32,480 --> 00:02:37,940
involves several OS T's and then the

00:02:35,630 --> 00:02:41,000
user starts to update the metadata and

00:02:37,940 --> 00:02:43,610
finish and commits the write request and

00:02:41,000 --> 00:02:46,819
it can't and it again it involves many

00:02:43,610 --> 00:02:49,760
other OS these Anka Lions and notes and

00:02:46,819 --> 00:02:53,660
now assume that the problem happens here

00:02:49,760 --> 00:02:56,810
and something goes wrong and the request

00:02:53,660 --> 00:02:58,819
crashes or something gets a slow as you

00:02:56,810 --> 00:03:01,070
can see we have many OS these and many

00:02:58,819 --> 00:03:04,220
components involves in this operation

00:03:01,070 --> 00:03:06,440
how can we define which OS he has the

00:03:04,220 --> 00:03:08,930
problem and how can we how can we find

00:03:06,440 --> 00:03:11,120
out which OS the could or which

00:03:08,930 --> 00:03:13,280
component could have the problem this is

00:03:11,120 --> 00:03:15,950
one problem with logging that we cannot

00:03:13,280 --> 00:03:18,350
extract those information and the other

00:03:15,950 --> 00:03:20,540
thing is that if even be can find out

00:03:18,350 --> 00:03:23,030
which probe which note has the problem

00:03:20,540 --> 00:03:25,970
we have to look at the box that could

00:03:23,030 --> 00:03:29,090
even be tons of gigabytes of data and

00:03:25,970 --> 00:03:31,730
looking look into those bugs is so hard

00:03:29,090 --> 00:03:33,770
especially stitching together different

00:03:31,730 --> 00:03:36,350
parts of the law that can

00:03:33,770 --> 00:03:38,960
make the problem is overwhelming and

00:03:36,350 --> 00:03:41,060
it's so hot the other thing is that we

00:03:38,960 --> 00:03:46,460
are unable to show the communication

00:03:41,060 --> 00:03:50,540
between notes through the logs and these

00:03:46,460 --> 00:03:52,310
deaf community and there is the unders

00:03:50,540 --> 00:03:54,140
the end-to-end tracing and to

00:03:52,310 --> 00:03:57,320
interesting is a new approach that

00:03:54,140 --> 00:04:01,250
creates that creates the request flow

00:03:57,320 --> 00:04:03,980
from the logs and as you can see and as

00:04:01,250 --> 00:04:06,320
you can see in this figure it creates a

00:04:03,980 --> 00:04:08,630
flow for the requests that we generate

00:04:06,320 --> 00:04:11,150
and issued to the user and it's becoming

00:04:08,630 --> 00:04:13,610
extremely popular everywhere for example

00:04:11,150 --> 00:04:16,970
oh and tracing has the consistent API

00:04:13,610 --> 00:04:19,010
between between all softwares for

00:04:16,970 --> 00:04:22,490
implementing and to and tracing into

00:04:19,010 --> 00:04:25,280
into system and it is and one of its

00:04:22,490 --> 00:04:27,230
implementation is jäger tracing seven

00:04:25,280 --> 00:04:29,510
community also has a start thinking

00:04:27,230 --> 00:04:32,120
about having end-to-end tracing into

00:04:29,510 --> 00:04:35,390
their system and they implement blocking

00:04:32,120 --> 00:04:38,510
as blocking as it's end-to-end tracing

00:04:35,390 --> 00:04:42,170
infrastructure however blocking has some

00:04:38,510 --> 00:04:44,510
limitations and it's it's great that

00:04:42,170 --> 00:04:47,300
they are start thinking to use that but

00:04:44,510 --> 00:04:49,490
we think that it is very limited and

00:04:47,300 --> 00:04:51,440
it's better to use another approaches

00:04:49,490 --> 00:04:54,830
that can provide more advanced

00:04:51,440 --> 00:04:57,739
functionality for us so here if you look

00:04:54,830 --> 00:05:00,389
at the table you can see that

00:04:57,739 --> 00:05:03,599
you can see different features that I

00:05:00,389 --> 00:05:05,489
list as then features of open trade as

00:05:03,599 --> 00:05:08,399
the features of tracing that we want to

00:05:05,489 --> 00:05:11,249
support and be compared blocking with a

00:05:08,399 --> 00:05:13,769
Jaeger implementation of open eyes open

00:05:11,249 --> 00:05:16,309
tracing tracer let's look at advanced

00:05:13,769 --> 00:05:18,959
features advanced features such as

00:05:16,309 --> 00:05:20,999
advanced visualization can we have

00:05:18,959 --> 00:05:23,339
advanced visualization with blocking no

00:05:20,999 --> 00:05:25,979
we cannot have because blocking has its

00:05:23,339 --> 00:05:28,589
own a specific type of presenting

00:05:25,979 --> 00:05:30,449
request and we cannot replace blocking

00:05:28,589 --> 00:05:32,879
but we cannot replace blocking

00:05:30,449 --> 00:05:35,189
visualizer with any visualizer that we

00:05:32,879 --> 00:05:38,069
want the other thing is that can we use

00:05:35,189 --> 00:05:40,199
blocking in production unfortunately not

00:05:38,069 --> 00:05:43,860
and it has two reasons one of them is

00:05:40,199 --> 00:05:46,979
that to be able to use blocking we need

00:05:43,860 --> 00:05:49,349
to start tracing on and off but it

00:05:46,979 --> 00:05:51,239
cannot be used in a production system

00:05:49,349 --> 00:05:53,789
because in the production system to be

00:05:51,239 --> 00:05:56,099
able to debug a system you shouldn't you

00:05:53,789 --> 00:05:58,079
shouldn't drear on the procedure and you

00:05:56,099 --> 00:06:00,719
shouldn't reproduce their logs however

00:05:58,079 --> 00:06:03,779
we have the open tracing environment

00:06:00,719 --> 00:06:08,189
which can enable which can enable online

00:06:03,779 --> 00:06:11,489
tracing using sampling and the other one

00:06:08,189 --> 00:06:14,159
is that open the blocking provides its

00:06:11,489 --> 00:06:16,739
own API and it provides its own way of

00:06:14,159 --> 00:06:19,229
tracing however in the data center that

00:06:16,739 --> 00:06:21,179
has many many applications and have many

00:06:19,229 --> 00:06:23,909
many components involved in a single

00:06:21,179 --> 00:06:26,009
request having a very specific type of

00:06:23,909 --> 00:06:29,399
tracing is not good and it's better to

00:06:26,009 --> 00:06:30,730
be able to have all components traced

00:06:29,399 --> 00:06:33,550
visiting with as

00:06:30,730 --> 00:06:35,860
with the standard API and open tracing

00:06:33,550 --> 00:06:38,110
again Yaeger using open tracing provides

00:06:35,860 --> 00:06:40,660
this functionality for us the other

00:06:38,110 --> 00:06:43,210
thing is that can we live can we

00:06:40,660 --> 00:06:45,490
leverage community improvements using

00:06:43,210 --> 00:06:48,340
blocking blocking is a specific to self

00:06:45,490 --> 00:06:50,530
however Jaeger and open tracing is used

00:06:48,340 --> 00:06:53,530
by large community of open source

00:06:50,530 --> 00:06:55,990
software's and they can liberate new and

00:06:53,530 --> 00:06:58,900
new advanced team new advanced features

00:06:55,990 --> 00:07:04,480
that are coming and they can improve

00:06:58,900 --> 00:07:07,420
their tracing infrastructure so in this

00:07:04,480 --> 00:07:10,540
talk we are trying to add in support for

00:07:07,420 --> 00:07:12,580
open tracing infrastructure as fast as

00:07:10,540 --> 00:07:17,140
possible by layering open tracing

00:07:12,580 --> 00:07:20,320
underneath API now let's look at how

00:07:17,140 --> 00:07:23,590
open trace how open tracing works and

00:07:20,320 --> 00:07:25,890
then have and have an introduction on

00:07:23,590 --> 00:07:29,500
how tracing works and how Yaeger

00:07:25,890 --> 00:07:34,150
implements open tracing and how blocking

00:07:29,500 --> 00:07:36,330
implements open tracing now take let's

00:07:34,150 --> 00:07:40,120
take a look an anatomy of open tracing

00:07:36,330 --> 00:07:42,640
let's start with client users issue

00:07:40,120 --> 00:07:44,970
request to clients and then we have

00:07:42,640 --> 00:07:47,100
trace points

00:07:44,970 --> 00:07:51,150
we have to response and each trace

00:07:47,100 --> 00:07:54,780
points is used by the tracing API and

00:07:51,150 --> 00:07:57,180
the tracing API associated to metadata

00:07:54,780 --> 00:08:00,240
information to context information to

00:07:57,180 --> 00:08:04,140
this trace points and they are called

00:08:00,240 --> 00:08:06,780
melody they are called traction span ID

00:08:04,140 --> 00:08:11,270
and trace ID a collection of trace

00:08:06,780 --> 00:08:14,670
points also we are calling them span so

00:08:11,270 --> 00:08:17,160
we have tracing agent the tracing agent

00:08:14,670 --> 00:08:19,980
receives trace points from tracing from

00:08:17,160 --> 00:08:24,570
tracing API and source them and catch

00:08:19,980 --> 00:08:29,010
them temporarily on the undead on its

00:08:24,570 --> 00:08:31,080
own system and then send them to you

00:08:29,010 --> 00:08:33,450
tracing back and tracing back and is

00:08:31,080 --> 00:08:35,880
responsible for getting traces from all

00:08:33,450 --> 00:08:37,800
over components in the system stitch

00:08:35,880 --> 00:08:40,110
traces that are related to a single

00:08:37,800 --> 00:08:43,789
request together and store them for

00:08:40,110 --> 00:08:43,789
further use in the future

00:08:44,720 --> 00:08:49,980
and now let's look at how blocking

00:08:47,640 --> 00:08:52,640
implements these infrastructures and how

00:08:49,980 --> 00:08:55,700
jäger implements these infrastructures

00:08:52,640 --> 00:08:59,040
again if you look at the figures we have

00:08:55,700 --> 00:09:01,380
OSD and Rados as our clients and we have

00:08:59,040 --> 00:09:04,650
traced points that are issued that are

00:09:01,380 --> 00:09:08,130
generated with user instrumentation and

00:09:04,650 --> 00:09:10,110
then we have plug-in API login api takes

00:09:08,130 --> 00:09:12,510
trace points and using blocking

00:09:10,110 --> 00:09:15,270
functionality we associate tracing

00:09:12,510 --> 00:09:19,700
context such as a span ID and trace idea

00:09:15,270 --> 00:09:23,610
to those to those trace points and then

00:09:19,700 --> 00:09:27,000
blocking sense the sense those trace

00:09:23,610 --> 00:09:31,350
point to exit Eng elgyn NCT engine works

00:09:27,000 --> 00:09:34,200
as the tracing trace engine for address

00:09:31,350 --> 00:09:37,160
engine for blocking and it stores and

00:09:34,200 --> 00:09:40,320
caches the metadata trace information

00:09:37,160 --> 00:09:43,650
temporally in the in its disk and it's

00:09:40,320 --> 00:09:47,130
Bob and it's a story and its meringue

00:09:43,650 --> 00:09:50,520
and then we used bubble trace and also

00:09:47,130 --> 00:09:53,310
Zipkin just to stitch together data to

00:09:50,520 --> 00:09:56,460
collect data from all nodes around the

00:09:53,310 --> 00:09:59,160
system and then stitch them together and

00:09:56,460 --> 00:10:01,350
present the request workflow and as you

00:09:59,160 --> 00:10:04,440
can see in here bubble trace and zip

00:10:01,350 --> 00:10:06,580
came together works as the tracing back

00:10:04,440 --> 00:10:08,870
end

00:10:06,580 --> 00:10:10,930
now let's take a look at Jaeger

00:10:08,870 --> 00:10:14,570
architecture and see how Jaeger works

00:10:10,930 --> 00:10:17,390
again we have OSD and Rados as our

00:10:14,570 --> 00:10:19,399
client nodes and behalf trace points and

00:10:17,390 --> 00:10:22,100
these trace points are trans and this

00:10:19,399 --> 00:10:25,610
trace point our sense to Jaeger agent

00:10:22,100 --> 00:10:27,680
through view to open tracing API because

00:10:25,610 --> 00:10:31,250
Yeager is implemented underneath the

00:10:27,680 --> 00:10:33,920
open tracing API so they when a user

00:10:31,250 --> 00:10:36,830
issues a trace point the open tracing

00:10:33,920 --> 00:10:39,800
API associated metadata information

00:10:36,830 --> 00:10:42,680
associate wrapped span ID and trace ID

00:10:39,800 --> 00:10:44,630
to those to those trace points and sends

00:10:42,680 --> 00:10:46,850
them back to Jaeger age and Jaeger

00:10:44,630 --> 00:10:50,149
agents sourced and temporarily and then

00:10:46,850 --> 00:10:52,029
to UDP it says them to Jaeger collector

00:10:50,149 --> 00:10:54,740
the Jaeger collector collects you

00:10:52,029 --> 00:10:57,440
collect traces from different from many

00:10:54,740 --> 00:10:59,660
different nodes and then stitch them

00:10:57,440 --> 00:11:02,660
together and provide stitch them

00:10:59,660 --> 00:11:05,540
together and provide a unified view for

00:11:02,660 --> 00:11:07,640
each request in the system as you can

00:11:05,540 --> 00:11:11,089
see before the Jaeger collector sense

00:11:07,640 --> 00:11:13,130
they talk back to source data into its

00:11:11,089 --> 00:11:15,170
distributed storage or any other storage

00:11:13,130 --> 00:11:17,959
type that is provided by the user it

00:11:15,170 --> 00:11:20,750
first kudos data into memory and then

00:11:17,959 --> 00:11:23,270
sends them back also Jaeger provides

00:11:20,750 --> 00:11:25,160
sampling for us and for sampling we have

00:11:23,270 --> 00:11:27,800
different type of sampling that is

00:11:25,160 --> 00:11:29,720
provided by jäger but this Jaeger

00:11:27,800 --> 00:11:34,070
collector is issuing The Hague the

00:11:29,720 --> 00:11:38,800
sampling policy to two other agents and

00:11:34,070 --> 00:11:38,800
ask them to do sampling for the great

00:11:38,850 --> 00:11:46,619
so one of the steps of one of our steps

00:11:43,470 --> 00:11:49,679
of replacing Blackie Nvidia here was how

00:11:46,619 --> 00:11:51,959
to map API how to map API of blocking

00:11:49,679 --> 00:11:56,369
with the API of the a year it was not a

00:11:51,959 --> 00:11:58,649
very one-to-one mapping and it has some

00:11:56,369 --> 00:12:00,989
type of complications one of them is

00:11:58,649 --> 00:12:03,389
that let's take a look at how we start

00:12:00,989 --> 00:12:05,249
and a trace point on how we start on a

00:12:03,389 --> 00:12:07,709
span in the a year and how we start it

00:12:05,249 --> 00:12:10,109
in blocking Interlaken we have to first

00:12:07,709 --> 00:12:11,939
call trace function and then we have to

00:12:10,109 --> 00:12:13,679
use and then we have to use init

00:12:11,939 --> 00:12:16,769
function to initiate to initialize a

00:12:13,679 --> 00:12:19,049
trace this work together has many

00:12:16,769 --> 00:12:21,660
different variations over the self code

00:12:19,049 --> 00:12:24,629
and it should support different type of

00:12:21,660 --> 00:12:27,509
different type of calling however we can

00:12:24,629 --> 00:12:30,959
however we try to replace it with

00:12:27,509 --> 00:12:34,019
sources panel function in year and we

00:12:30,959 --> 00:12:38,729
modify the functionality of the Jaeger

00:12:34,019 --> 00:12:42,179
API to start the span instead of using a

00:12:38,729 --> 00:12:44,600
year using block in the spans and then

00:12:42,179 --> 00:12:47,369
we have the event and people function in

00:12:44,600 --> 00:12:48,629
blocking the event function is used for

00:12:47,369 --> 00:12:51,239
us for annotating

00:12:48,629 --> 00:12:52,889
the span with the time and stuff and the

00:12:51,239 --> 00:12:56,999
key mail function is used to annotate

00:12:52,889 --> 00:12:59,879
the span with with an integer value or

00:12:56,999 --> 00:13:02,220
with a string value however on the other

00:12:59,879 --> 00:13:04,379
hand open tracing API support block AV

00:13:02,220 --> 00:13:06,600
which which is used to annotate

00:13:04,379 --> 00:13:09,089
everything that we want we can we don't

00:13:06,600 --> 00:13:12,329
we are not limited to very specific type

00:13:09,089 --> 00:13:15,299
of type of annotation we can have any

00:13:12,329 --> 00:13:18,179
annotation we want using lock AV and

00:13:15,299 --> 00:13:20,729
then open tracing have any tracer which

00:13:18,179 --> 00:13:22,639
which which is used to attach the tray

00:13:20,729 --> 00:13:24,779
the application the application

00:13:22,639 --> 00:13:26,999
component to the tracing engine which is

00:13:24,779 --> 00:13:27,980
presented in the system however because

00:13:26,999 --> 00:13:30,110
blocking is

00:13:27,980 --> 00:13:31,700
it's not using an always-on method and

00:13:30,110 --> 00:13:34,280
you have to turn it on and turn it off

00:13:31,700 --> 00:13:36,980
we don't have such functionality but

00:13:34,280 --> 00:13:40,040
like the other thing is that for

00:13:36,980 --> 00:13:42,170
propagating the information between two

00:13:40,040 --> 00:13:44,570
different components we have the inject

00:13:42,170 --> 00:13:49,640
function in open tracing API and the

00:13:44,570 --> 00:13:52,010
corresponding one was and portrays in in

00:13:49,640 --> 00:13:54,140
blocking API however it was not again a

00:13:52,010 --> 00:13:56,030
one-to-one mapping and we need to modify

00:13:54,140 --> 00:13:59,990
some and we need to have some

00:13:56,030 --> 00:14:02,210
modifications to be able to add to add

00:13:59,990 --> 00:14:04,070
the inject function the other one is the

00:14:02,210 --> 00:14:07,790
code trees which is used by the receiver

00:14:04,070 --> 00:14:10,340
of request and extract the metadata from

00:14:07,790 --> 00:14:13,430
the other node extract the context data

00:14:10,340 --> 00:14:16,550
from the other node and then build a new

00:14:13,430 --> 00:14:18,050
trace based on that and it is again it

00:14:16,550 --> 00:14:23,110
was not a one to one corresponding

00:14:18,050 --> 00:14:25,670
between extract function and the and the

00:14:23,110 --> 00:14:28,250
decode the code trace function and we

00:14:25,670 --> 00:14:31,240
again have some modification to make

00:14:28,250 --> 00:14:31,240
those possible

00:14:31,340 --> 00:14:36,440
now let's take a look at our

00:14:33,020 --> 00:14:39,230
implementation what we have done was

00:14:36,440 --> 00:14:41,090
that we first want to have the least

00:14:39,230 --> 00:14:44,420
amount of modification that could be

00:14:41,090 --> 00:14:46,760
that could be added to the system so if

00:14:44,420 --> 00:14:49,430
we look at the figure one by one

00:14:46,760 --> 00:14:51,380
on the Left I present the blocking

00:14:49,430 --> 00:14:53,390
architecture and on the right it is the

00:14:51,380 --> 00:14:55,520
Jaeger architecture we have self

00:14:53,390 --> 00:14:58,370
components and we didn't modify any self

00:14:55,520 --> 00:15:00,320
components in in our first round of

00:14:58,370 --> 00:15:02,029
implementation and we have self

00:15:00,320 --> 00:15:04,370
components the same then we have

00:15:02,029 --> 00:15:07,760
blocking API and we use blocking API

00:15:04,370 --> 00:15:09,470
both for year and four for our Jaeger

00:15:07,760 --> 00:15:11,420
functionality and for blocking

00:15:09,470 --> 00:15:13,880
functionality and we replace the

00:15:11,420 --> 00:15:16,400
blocking functionality underneath to

00:15:13,880 --> 00:15:19,310
instead of inserting two instead of

00:15:16,400 --> 00:15:21,860
inserting information into trace points

00:15:19,310 --> 00:15:24,680
into exit Eng it sends them to Jaeger

00:15:21,860 --> 00:15:27,710
agent and then we we have to be enabled

00:15:24,680 --> 00:15:30,230
agar agent on each node and we connect

00:15:27,710 --> 00:15:34,300
the Jaeger functionality to to our yoga

00:15:30,230 --> 00:15:37,190
agent Jaeger agent again sends data to

00:15:34,300 --> 00:15:40,550
Jaeger collector actually after the

00:15:37,190 --> 00:15:41,780
block in API we removed everything and

00:15:40,550 --> 00:15:45,350
we replace them with the Jaeger

00:15:41,780 --> 00:15:48,500
functionality our modification has 200

00:15:45,350 --> 00:15:50,780
lines almost 300 lines of code however

00:15:48,500 --> 00:15:52,310
for adding new trace for it because we

00:15:50,780 --> 00:15:54,890
want to become high table with open

00:15:52,310 --> 00:15:57,290
tracing API and we want to compatible

00:15:54,890 --> 00:15:59,930
with open tracing with open source

00:15:57,290 --> 00:16:01,670
community so for adding trace point we

00:15:59,930 --> 00:16:03,800
adding nutrients points we are using

00:16:01,670 --> 00:16:06,560
open tracing API and we are not using

00:16:03,800 --> 00:16:08,630
blocking API for new trace points that

00:16:06,560 --> 00:16:11,630
we are added to the system and what was

00:16:08,630 --> 00:16:14,450
so hard in our modification there was no

00:16:11,630 --> 00:16:15,950
contact consistency on context

00:16:14,450 --> 00:16:19,820
propagation and we

00:16:15,950 --> 00:16:25,670
have exactly one to one mapping between

00:16:19,820 --> 00:16:29,000
the between the components also set to

00:16:25,670 --> 00:16:32,510
be able to to be able to provide context

00:16:29,000 --> 00:16:35,510
for vacation self modifies the API of

00:16:32,510 --> 00:16:38,389
safe functions but it was not what is

00:16:35,510 --> 00:16:43,100
desired and we implemented to have a

00:16:38,389 --> 00:16:45,260
more advanced feature and here is an

00:16:43,100 --> 00:16:50,839
example of traces as you can see in this

00:16:45,260 --> 00:16:52,670
figure each line shows different

00:16:50,839 --> 00:16:54,649
component and each column shows

00:16:52,670 --> 00:16:57,949
different component each line shows a

00:16:54,649 --> 00:17:01,190
single span and the lengths of each line

00:16:57,949 --> 00:17:04,910
shows the latency of this of data as you

00:17:01,190 --> 00:17:08,240
can see it's a little bit small but in

00:17:04,910 --> 00:17:10,069
here you can see that we can also we can

00:17:08,240 --> 00:17:13,280
also able to annotate the latency of

00:17:10,069 --> 00:17:14,870
each span within the within the trace

00:17:13,280 --> 00:17:17,000
the other thing that you can show is

00:17:14,870 --> 00:17:21,069
that the hierarchy the hierarchy that is

00:17:17,000 --> 00:17:23,299
visible through the span is the is the

00:17:21,069 --> 00:17:25,010
causative relationship and happens

00:17:23,299 --> 00:17:29,140
before relationship is in different

00:17:25,010 --> 00:17:29,140
terraced font and spans in the system

00:17:29,659 --> 00:17:36,299
now let's take a look at our evaluation

00:17:32,779 --> 00:17:39,120
for evaluating our work we evaluate this

00:17:36,299 --> 00:17:41,730
overhead we evaluate memory overhead and

00:17:39,120 --> 00:17:43,919
we also evaluate the CPU overhead we

00:17:41,730 --> 00:17:45,990
want to evaluate because all tracing

00:17:43,919 --> 00:17:47,850
infrastructure comes with an overhead

00:17:45,990 --> 00:17:49,380
and first of all we want to see what was

00:17:47,850 --> 00:17:56,100
the overhead that be imposed to the

00:17:49,380 --> 00:17:57,990
system so our experimental setup for our

00:17:56,100 --> 00:18:00,690
experimental setup we had two type of

00:17:57,990 --> 00:18:03,000
notes one of them was the note that we

00:18:00,690 --> 00:18:04,440
set up the color it was a physical note

00:18:03,000 --> 00:18:07,710
that we start off step closer on that

00:18:04,440 --> 00:18:11,940
and it was it has 64 gigabyte RAM it has

00:18:07,710 --> 00:18:13,860
232 CPU it has 10 gigabit per second

00:18:11,940 --> 00:18:16,500
knee and it has two HD digital drives

00:18:13,860 --> 00:18:20,159
and then for the collector not that we

00:18:16,500 --> 00:18:22,289
want to collect every traces from the

00:18:20,159 --> 00:18:25,830
system together we use a virtual note

00:18:22,289 --> 00:18:29,600
that has 32 gigabyte RAM and 12 visual

00:18:25,830 --> 00:18:29,600
cores and a virtual disk

00:18:30,090 --> 00:18:35,550
we're on our experiment for 15 for 15

00:18:33,750 --> 00:18:38,580
minutes and the reason was that we

00:18:35,550 --> 00:18:40,890
during that 15 minutes we issue several

00:18:38,580 --> 00:18:42,450
read and write requests however there

00:18:40,890 --> 00:18:44,190
are some background activity that

00:18:42,450 --> 00:18:46,680
happens in the step and for those

00:18:44,190 --> 00:18:48,270
activity we also generate some traces so

00:18:46,680 --> 00:18:50,850
we want to be able to capture those

00:18:48,270 --> 00:18:53,910
races then we define a time frame of 15

00:18:50,850 --> 00:19:00,810
minutes and we capture and we get our

00:18:53,910 --> 00:19:03,360
statistics during those 15 minutes here

00:19:00,810 --> 00:19:05,460
is the overhead is the disk overhead for

00:19:03,360 --> 00:19:10,560
writing and reading data and also for

00:19:05,460 --> 00:19:12,840
the for the background overhead as you

00:19:10,560 --> 00:19:15,120
can see the x-axis shows the time

00:19:12,840 --> 00:19:18,750
duration of 15 minutes and the y-axis

00:19:15,120 --> 00:19:22,170
shows the trace that the amount of data

00:19:18,750 --> 00:19:24,510
that was generated due to tracing we run

00:19:22,170 --> 00:19:26,880
our experiments for different sampling

00:19:24,510 --> 00:19:29,310
rates for 20% sampling rates for 50%

00:19:26,880 --> 00:19:31,920
sampling rates and 400% sampling rate

00:19:29,310 --> 00:19:33,870
and as you can see it was not a linear

00:19:31,920 --> 00:19:36,780
relationship between different sampling

00:19:33,870 --> 00:19:39,210
between different sampling rates because

00:19:36,780 --> 00:19:42,240
it's a probability based model and then

00:19:39,210 --> 00:19:45,000
the other thing that is visible here is

00:19:42,240 --> 00:19:47,910
that this this model of sending data

00:19:45,000 --> 00:19:49,980
that we sent nothing and insensate

00:19:47,910 --> 00:19:53,310
understand nothing understand data is

00:19:49,980 --> 00:19:56,550
come it's coming from the from the fact

00:19:53,310 --> 00:20:00,950
that we have the cap we have caching on

00:19:56,550 --> 00:20:00,950
both agent side ad on the collector side

00:20:01,410 --> 00:20:07,320
we also look at the memory overhead that

00:20:03,840 --> 00:20:09,510
was imposed by our infrastructure as you

00:20:07,320 --> 00:20:11,670
can see in the figure the x-axis again

00:20:09,510 --> 00:20:14,670
shows the time of 15 minutes within the

00:20:11,670 --> 00:20:17,310
system and then the y-axis shows the

00:20:14,670 --> 00:20:20,160
memory overhead of the memory overhead

00:20:17,310 --> 00:20:22,800
in megabytes in megabytes and again we

00:20:20,160 --> 00:20:26,070
run our mechanism for our tests our

00:20:22,800 --> 00:20:29,970
evaluation for 20 percent for 50 percent

00:20:26,070 --> 00:20:32,760
and for 100 percent of sampling rate and

00:20:29,970 --> 00:20:35,430
as you can see the amount of the amount

00:20:32,760 --> 00:20:37,560
of memory overhead was slightly

00:20:35,430 --> 00:20:39,510
different between different types of the

00:20:37,560 --> 00:20:41,940
between different types of sampling and

00:20:39,510 --> 00:20:44,490
it was not a huge overhead and it was

00:20:41,940 --> 00:20:49,110
less than one plus one 1/10 percent of

00:20:44,490 --> 00:20:51,360
memory overhead overall system then we

00:20:49,110 --> 00:20:53,880
look at also CPU overhead and for

00:20:51,360 --> 00:20:56,040
looking at CPU overhead again we the

00:20:53,880 --> 00:20:58,170
x-axis shows the time which was 15

00:20:56,040 --> 00:21:00,720
minutes and then the y-axis shows the

00:20:58,170 --> 00:21:03,660
CPU usage in percentage and as you can

00:21:00,720 --> 00:21:09,210
see we run it for different sampling 20%

00:21:03,660 --> 00:21:13,680
50% 100% and our Sun our maximum maximum

00:21:09,210 --> 00:21:16,700
CPU overhead was almost 8% for the for

00:21:13,680 --> 00:21:16,700
the collector notes

00:21:17,270 --> 00:21:22,670
for the future board we are seeing to

00:21:20,420 --> 00:21:26,600
have several future works here first of

00:21:22,670 --> 00:21:29,440
all we want to use the alt message - we

00:21:26,600 --> 00:21:33,800
want to use the out log message because

00:21:29,440 --> 00:21:36,350
because self code has a rich body of log

00:21:33,800 --> 00:21:38,720
messages and they all say they almost

00:21:36,350 --> 00:21:40,970
have log messages all over the code on

00:21:38,720 --> 00:21:43,130
all components we want to use those log

00:21:40,970 --> 00:21:44,900
messages to annotate our traces because

00:21:43,130 --> 00:21:47,510
we believe that those information are

00:21:44,900 --> 00:21:49,520
really valuable and reproducing them

00:21:47,510 --> 00:21:51,530
needs a huge effort so we would be

00:21:49,520 --> 00:21:53,210
preferred to use those log messages this

00:21:51,530 --> 00:21:55,550
is one of the first effort that we want

00:21:53,210 --> 00:21:58,070
to have as our future work the other

00:21:55,550 --> 00:21:59,570
thing is that we are we are trying to

00:21:58,070 --> 00:22:02,570
add more trace points on different

00:21:59,570 --> 00:22:04,520
components for example currently Steph

00:22:02,570 --> 00:22:06,920
has several components but not all of

00:22:04,520 --> 00:22:09,080
them has response we we try to add more

00:22:06,920 --> 00:22:12,110
trace points to client side to be able

00:22:09,080 --> 00:22:18,050
to capture more sophisticated and more

00:22:12,110 --> 00:22:19,970
complicated traces the other thing that

00:22:18,050 --> 00:22:21,980
we are interested to capture is

00:22:19,970 --> 00:22:24,530
synchronization point because in order

00:22:21,980 --> 00:22:27,140
to be able to present a correct view of

00:22:24,530 --> 00:22:29,600
the system we need to know when our

00:22:27,140 --> 00:22:31,550
concurrency is finishes when are

00:22:29,600 --> 00:22:35,030
concurrent threads are merged together

00:22:31,550 --> 00:22:36,710
and provide a single single and reach to

00:22:35,030 --> 00:22:39,800
a single point and we need to capture

00:22:36,710 --> 00:22:42,410
the synchronization point for them also

00:22:39,800 --> 00:22:44,300
we want to have we want to be able to

00:22:42,410 --> 00:22:47,090
find frequent patterns within those

00:22:44,300 --> 00:22:49,730
traces reading those traces to be able

00:22:47,090 --> 00:22:51,470
to have a better debugging to provide

00:22:49,730 --> 00:22:53,920
better debugging opportunity for the

00:22:51,470 --> 00:22:55,760
users because for example if we can be

00:22:53,920 --> 00:22:57,950
retrived

00:22:55,760 --> 00:22:59,990
if we can be able to retrieve frequent

00:22:57,950 --> 00:23:01,850
patterns we can detect we can detect

00:22:59,990 --> 00:23:03,410
what was happening wrong in other

00:23:01,850 --> 00:23:06,260
patterns but we don't need to look the

00:23:03,410 --> 00:23:08,510
holes the hole traces to be able to show

00:23:06,260 --> 00:23:10,400
that they can we can loot we can look at

00:23:08,510 --> 00:23:15,920
specific parts of the trace to be able

00:23:10,400 --> 00:23:17,870
to detect anomaly in several traces and

00:23:15,920 --> 00:23:20,150
at the summary we enable advanced

00:23:17,870 --> 00:23:22,550
end-to-end tracing in safe using Jaeger

00:23:20,150 --> 00:23:26,090
we replace blocky Nvidia here and we

00:23:22,550 --> 00:23:28,160
kept locking trace points and as there

00:23:26,090 --> 00:23:30,620
were and the add new trace files using

00:23:28,160 --> 00:23:32,720
open tracing API our overhead CPU and

00:23:30,620 --> 00:23:34,880
memory was less than one person and our

00:23:32,720 --> 00:23:37,810
discover head was less than six 60

00:23:34,880 --> 00:23:37,810
megabytes per second

00:23:51,260 --> 00:23:56,910
possible to for me to take what you've

00:23:54,900 --> 00:24:00,570
done and put it on a self plus tur and

00:23:56,910 --> 00:24:03,480
then run it we are planning to have it

00:24:00,570 --> 00:24:06,270
up a stream and yes it could if it's

00:24:03,480 --> 00:24:08,910
open source project it's because you

00:24:06,270 --> 00:24:11,370
learn all the bits already there exactly

00:24:08,910 --> 00:24:13,410
they are available in my github well

00:24:11,370 --> 00:24:15,420
yeah but it's not on other stream code

00:24:13,410 --> 00:24:18,120
of self I mean I can share the

00:24:15,420 --> 00:24:21,450
repository with you yeah it's all

00:24:18,120 --> 00:24:25,060
available thank you actually make

00:24:21,450 --> 00:24:27,460
modifications to bigger or was it all

00:24:25,060 --> 00:24:30,700
no like after you

00:24:27,460 --> 00:24:32,590
we only adapting to your API but for

00:24:30,700 --> 00:24:34,330
adding synchronization point we need to

00:24:32,590 --> 00:24:37,150
have modification to Jaeger because

00:24:34,330 --> 00:24:40,810
currently Jaeger Jaeger is not able to

00:24:37,150 --> 00:24:44,380
capture synchronization points but we

00:24:40,810 --> 00:24:49,410
want to add this feature to Jaeger as

00:24:44,380 --> 00:24:49,410
well because it's very important for us

00:24:51,010 --> 00:24:54,700
you mentioned the context propagation is

00:24:52,990 --> 00:24:57,370
hard and it's slow it's not like

00:24:54,700 --> 00:25:01,480
slipping down that was resolved how much

00:24:57,370 --> 00:25:03,190
faster would be the 38 w3c traced SPECT

00:25:01,480 --> 00:25:04,810
open and I suspect that's going to get

00:25:03,190 --> 00:25:07,300
approved Friday by the end of October

00:25:04,810 --> 00:25:12,370
would that make this easier in the

00:25:07,300 --> 00:25:15,280
future my context propagation for

00:25:12,370 --> 00:25:19,300
context propagation there's one thing

00:25:15,280 --> 00:25:21,340
that is that was so hard in self

00:25:19,300 --> 00:25:23,350
actually the way that they implement

00:25:21,340 --> 00:25:27,310
blocking and have instrumentation point

00:25:23,350 --> 00:25:32,380
in self and it was they modify self API

00:25:27,310 --> 00:25:35,920
I think they modify self API and it

00:25:32,380 --> 00:25:39,160
makes things much harder to get rid of

00:25:35,920 --> 00:25:40,960
those parts and what we were thinking to

00:25:39,160 --> 00:25:43,420
use is that actually this is available

00:25:40,960 --> 00:25:45,610
for Jager we can use thread-local

00:25:43,420 --> 00:25:47,860
storage to keep them metadata

00:25:45,610 --> 00:25:49,690
information interesting in local thread

00:25:47,860 --> 00:25:51,760
and then we drive those information

00:25:49,690 --> 00:25:53,530
whenever we wants to create and span

00:25:51,760 --> 00:25:57,070
instead of modifying all over the post

00:25:53,530 --> 00:25:58,450
and change every API in the code because

00:25:57,070 --> 00:26:01,700
currently this is the way that they are

00:25:58,450 --> 00:26:04,180
the PSL implemented is not very good

00:26:01,700 --> 00:26:07,070
and one more question in general

00:26:04,180 --> 00:26:08,630
distributing tracing is typically not

00:26:07,070 --> 00:26:11,930
mainstream today because it's very hard

00:26:08,630 --> 00:26:13,700
to add it to your code this is kind of a

00:26:11,930 --> 00:26:15,590
first example I've seen of someone that

00:26:13,700 --> 00:26:17,900
had tracing and tried to move to a

00:26:15,590 --> 00:26:19,910
different tracing which seems like an

00:26:17,900 --> 00:26:21,200
even additional layer of complexity

00:26:19,910 --> 00:26:23,360
right because you're kind of rewriting

00:26:21,200 --> 00:26:25,970
something you've already done there any

00:26:23,360 --> 00:26:28,060
tips or lessons learned from that going

00:26:25,970 --> 00:26:30,980
forward that may be useful for others

00:26:28,060 --> 00:26:33,050
they actually take good thing about open

00:26:30,980 --> 00:26:36,440
tracing is that open tracing actually

00:26:33,050 --> 00:26:39,380
open tracing is is the way to answer

00:26:36,440 --> 00:26:43,100
this question and it provides a standard

00:26:39,380 --> 00:26:46,310
API for any tracing infrastructure that

00:26:43,100 --> 00:26:48,950
you want to have underneath for example

00:26:46,310 --> 00:26:52,550
you have a specific function and that's

00:26:48,950 --> 00:26:55,520
API and you use that API for tracing

00:26:52,550 --> 00:26:57,530
your system then there is no matter what

00:26:55,520 --> 00:26:59,680
tracing infrastructure you are using you

00:26:57,530 --> 00:27:02,240
can use Jaeger you can use another

00:26:59,680 --> 00:27:04,610
tracing infrastructure but since you

00:27:02,240 --> 00:27:07,010
have the same API you can have different

00:27:04,610 --> 00:27:09,140
modules on the system different software

00:27:07,010 --> 00:27:11,960
on your system to be instrumented with

00:27:09,140 --> 00:27:14,330
the same reusing the same API and you

00:27:11,960 --> 00:27:17,500
don't have the difficulty to going from

00:27:14,330 --> 00:27:19,340
this yeah you're going from this tracing

00:27:17,500 --> 00:27:22,060
infrastructure to another tracing

00:27:19,340 --> 00:27:22,060
infrastructure

00:27:29,480 --> 00:27:33,919
where does the sampling happen like in

00:27:32,299 --> 00:27:36,139
one of the pictures it looked like you

00:27:33,919 --> 00:27:37,580
were doing all the trace points and then

00:27:36,139 --> 00:27:41,720
they were just getting stripped apart so

00:27:37,580 --> 00:27:44,059
it's less storage space or actually

00:27:41,720 --> 00:27:46,909
Jaeger provides several type of sampling

00:27:44,059 --> 00:27:49,070
you can have you can one of them is the

00:27:46,909 --> 00:27:51,409
remote sampling that is imposed by the

00:27:49,070 --> 00:27:53,419
collector and collector decides which

00:27:51,409 --> 00:27:55,220
novel and collector decides on the

00:27:53,419 --> 00:27:57,260
sampling rate and this is what we have

00:27:55,220 --> 00:27:59,659
evaluated on our system but there is

00:27:57,260 --> 00:28:01,490
another approaches and there is and

00:27:59,659 --> 00:28:03,440
other types of sampling that they

00:28:01,490 --> 00:28:08,000
provided through Jaeger that enables

00:28:03,440 --> 00:28:10,370
each agent to sample by itself and the

00:28:08,000 --> 00:28:11,720
different sampling getting well so but

00:28:10,370 --> 00:28:14,210
what I mean is when you're doing

00:28:11,720 --> 00:28:15,909
sampling does that mean that only 20% of

00:28:14,210 --> 00:28:18,889
the trace points actually get turned on

00:28:15,909 --> 00:28:20,620
or do all they got turned on in the data

00:28:18,889 --> 00:28:24,830
get they generate gets thrown away or

00:28:20,620 --> 00:28:26,840
where's the CPU if then if we enable it

00:28:24,830 --> 00:28:31,429
on the agent side we for example take

00:28:26,840 --> 00:28:33,860
one of take every tenth of the if we

00:28:31,429 --> 00:28:35,539
define it as 10% we get every tenth of

00:28:33,860 --> 00:28:38,059
the trace point and then propagate those

00:28:35,539 --> 00:28:40,010
generate actually trace trace points for

00:28:38,059 --> 00:28:41,720
them and propagate them but it's enabled

00:28:40,010 --> 00:28:45,380
by the collector as the way that we

00:28:41,720 --> 00:28:47,299
evaluate our system the trace the agent

00:28:45,380 --> 00:28:49,429
collects all trace points and then

00:28:47,299 --> 00:28:52,149
sample them and sent them back to use to

00:28:49,429 --> 00:28:52,149
the hydrogen

00:28:53,809 --> 00:28:59,190
so the key to getting this really

00:28:56,280 --> 00:29:01,410
efficient is the sampling at the agent

00:28:59,190 --> 00:29:04,100
how come you couldn't do that something

00:29:01,410 --> 00:29:08,250
at the agent we decide which node which

00:29:04,100 --> 00:29:10,650
actually we decide on the request to be

00:29:08,250 --> 00:29:12,660
sampled and then some sentimental data

00:29:10,650 --> 00:29:14,790
that it is something why don't you use

00:29:12,660 --> 00:29:17,160
that's the key to getting really low CPU

00:29:14,790 --> 00:29:24,840
overhead riders - so how come you didn't

00:29:17,160 --> 00:29:26,910
use that approach I didn't have much

00:29:24,840 --> 00:29:30,299
time to run more experiments because

00:29:26,910 --> 00:29:32,190
this so is it feasible yeah it's just a

00:29:30,299 --> 00:29:34,710
configuration file that I have to

00:29:32,190 --> 00:29:38,540
specify I see ok it's different

00:29:34,710 --> 00:29:41,700
configuration that we have to impose the

00:29:38,540 --> 00:29:44,370
I'd like - can you fit this into the

00:29:41,700 --> 00:29:45,960
broader context of why you're doing this

00:29:44,370 --> 00:29:48,299
like is this just for an alternative

00:29:45,960 --> 00:29:50,600
debugging thing or what's the use cases

00:29:48,299 --> 00:29:53,220
for collecting tracing information

00:29:50,600 --> 00:29:55,230
collecting information tracing

00:29:53,220 --> 00:29:57,600
information used for many things one of

00:29:55,230 --> 00:29:59,700
them one of them is debugging the other

00:29:57,600 --> 00:30:01,860
thing is that performance evaluation of

00:29:59,700 --> 00:30:04,980
the system for example if we want to

00:30:01,860 --> 00:30:07,200
evaluate what is the what is that if we

00:30:04,980 --> 00:30:09,450
change if you have an optimization on

00:30:07,200 --> 00:30:11,820
the system if we have traces from

00:30:09,450 --> 00:30:14,730
previous execution and if we know how

00:30:11,820 --> 00:30:16,710
traces was executed previously and with

00:30:14,730 --> 00:30:19,320
our modification with our optimization

00:30:16,710 --> 00:30:21,660
how traces was how request was executed

00:30:19,320 --> 00:30:23,309
and what is the traces now then we have

00:30:21,660 --> 00:30:25,850
a better comparison between the two and

00:30:23,309 --> 00:30:28,850
we can evaluate our optimization better

00:30:25,850 --> 00:30:28,850
yes

00:30:32,930 --> 00:30:35,770
in an efficient

00:30:36,570 --> 00:30:43,070
I cannot hear you

00:30:39,330 --> 00:30:43,070
any more questions for Ted

00:30:43,390 --> 00:30:47,520
thank you very much money that was great

00:30:45,280 --> 00:30:47,520

YouTube URL: https://www.youtube.com/watch?v=NHoI9F9bZeM


