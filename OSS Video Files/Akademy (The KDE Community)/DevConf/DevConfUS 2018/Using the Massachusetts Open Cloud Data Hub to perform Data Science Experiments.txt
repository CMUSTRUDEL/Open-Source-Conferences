Title: Using the Massachusetts Open Cloud Data Hub to perform Data Science Experiments
Publication date: 2019-02-21
Playlist: DevConfUS 2018
Description: 
	Have a great idea for a Data Science experiment but don't have the hardware to run it?  The Massachusetts Open Cloud (MOC) and Red Hat have partnered to deploy the Data Hub, an open source AI as a Service platform, into the MOC giving you access to hardware and support required for leading edge experiments.  
The MOC Infrastructure as a Service platform combined with current Data Science development tools provides you with an alternative to using public clouds to execute your experiments.
Captions: 
	00:00:03,560 --> 00:00:17,500
[Music]

00:00:14,369 --> 00:00:20,260
okay everybody for the first session

00:00:17,500 --> 00:00:23,050
after lunch we have our intriguer a

00:00:20,260 --> 00:00:24,550
professor at Boston University and a

00:00:23,050 --> 00:00:26,680
principal investigator at the

00:00:24,550 --> 00:00:29,770
Massachusetts open cloud along with

00:00:26,680 --> 00:00:31,840
Stephen Jules a senior manager accredits

00:00:29,770 --> 00:00:34,149
AI Center of Excellence who will be

00:00:31,840 --> 00:00:36,399
talking about using the Massachusetts

00:00:34,149 --> 00:00:43,329
open cloud to perform data science

00:00:36,399 --> 00:00:44,890
experiments so I'm Stephen I'm not sure

00:00:43,329 --> 00:00:46,929
how many of you in here before for

00:00:44,890 --> 00:00:49,449
Daniel session where he talked about Red

00:00:46,929 --> 00:00:51,429
Hat strategy toward AI one of the topics

00:00:49,449 --> 00:00:53,190
he covered was around the open data hub

00:00:51,429 --> 00:00:55,420
and the data implementation we have

00:00:53,190 --> 00:00:56,829
in-house at Red Hat and how we've now

00:00:55,420 --> 00:00:58,929
deployed that up to the Massachusetts

00:00:56,829 --> 00:01:00,190
open cloud so today we're going to talk

00:00:58,929 --> 00:01:01,569
a little bit about the Massachusetts

00:01:00,190 --> 00:01:03,399
Oakland cloud then we're going to talk

00:01:01,569 --> 00:01:04,809
about how the which components of the

00:01:03,399 --> 00:01:06,850
data hub we put in there and then we'll

00:01:04,809 --> 00:01:08,980
do a demo for those of you that are in

00:01:06,850 --> 00:01:10,630
academia run open source community this

00:01:08,980 --> 00:01:11,710
will be directly applicable to you for

00:01:10,630 --> 00:01:13,630
how you can put data into that

00:01:11,710 --> 00:01:15,310
environment and then analyze that data

00:01:13,630 --> 00:01:17,950
and feed that back into your

00:01:15,310 --> 00:01:19,450
applications so to start we horn with us

00:01:17,950 --> 00:01:20,410
here today and he's going to talk to you

00:01:19,450 --> 00:01:22,270
for those of you that aren't familiar

00:01:20,410 --> 00:01:25,450
about what the MOC is and what it's been

00:01:22,270 --> 00:01:28,100
designed to do alright so I saw this

00:01:25,450 --> 00:01:30,479
chart from Dan I love it it's I'm which

00:01:28,100 --> 00:01:32,310
public cloud it's it's basically a

00:01:30,479 --> 00:01:34,770
reinvention of the mainframe so it's got

00:01:32,310 --> 00:01:36,899
all these benefits right but what

00:01:34,770 --> 00:01:39,299
they've got is you're leasing compute

00:01:36,899 --> 00:01:42,060
power in environment you're locked into

00:01:39,299 --> 00:01:43,170
it right it's incredibly expensive like

00:01:42,060 --> 00:01:45,270
you could put your data up to the cloud

00:01:43,170 --> 00:01:48,360
it's free it's really expensive to pull

00:01:45,270 --> 00:01:50,729
your data out of its cloud and it's

00:01:48,360 --> 00:01:52,350
using open source but it's actually not

00:01:50,729 --> 00:01:56,909
really contributing back to the open

00:01:52,350 --> 00:01:58,979
source community so can this you know we

00:01:56,909 --> 00:02:01,259
know that cloud gives you this enormous

00:01:58,979 --> 00:02:03,690
advantage for users of the elasticity

00:02:01,259 --> 00:02:06,929
for data centers of better good

00:02:03,690 --> 00:02:08,910
operations we can locate this over Paris

00:02:06,929 --> 00:02:10,860
cheap so a lot of people feel that the

00:02:08,910 --> 00:02:11,670
future of computing is in the cloud but

00:02:10,860 --> 00:02:12,840
does it really gonna be in these

00:02:11,670 --> 00:02:15,980
proprietary clouds

00:02:12,840 --> 00:02:19,640
[Music]

00:02:15,980 --> 00:02:21,200
that lags for about a minute there so so

00:02:19,640 --> 00:02:23,090
we don't think so we think an

00:02:21,200 --> 00:02:24,650
alternative model of a cloud as possible

00:02:23,090 --> 00:02:26,540
what we call an open cloud exchange

00:02:24,650 --> 00:02:28,790
where multiple different entities can

00:02:26,540 --> 00:02:31,010
stand up infrastructure and compete with

00:02:28,790 --> 00:02:32,750
each other and and collaborate with each

00:02:31,010 --> 00:02:35,209
other where multiple different entities

00:02:32,750 --> 00:02:37,190
can stand up you know larger cloud

00:02:35,209 --> 00:02:38,989
services on top of that I mean we

00:02:37,190 --> 00:02:41,569
shouldn't stand up research offerings

00:02:38,989 --> 00:02:42,830
alongside these production offerings you

00:02:41,569 --> 00:02:45,799
know when we first started having this

00:02:42,830 --> 00:02:47,060
idea of creating open cloud and I could

00:02:45,799 --> 00:02:49,549
talk about the technologies we've done

00:02:47,060 --> 00:02:51,650
to do this we start talking to economist

00:02:49,549 --> 00:02:54,049
and you know there's already 48 types of

00:02:51,650 --> 00:02:55,430
VMs on Amazon what's gonna happen if we

00:02:54,049 --> 00:02:57,560
have something where there's thousands

00:02:55,430 --> 00:03:00,110
effects at the ends now that seems crazy

00:02:57,560 --> 00:03:02,780
and and complicated but the thing they

00:03:00,110 --> 00:03:06,170
talked to us about was you're gonna get

00:03:02,780 --> 00:03:08,989
intermediaries platforms like big data

00:03:06,170 --> 00:03:10,340
platforms web platforms HPC platforms

00:03:08,989 --> 00:03:12,380
and in fact we're gonna be talking about

00:03:10,340 --> 00:03:13,940
when those intermediaries today it can

00:03:12,380 --> 00:03:16,340
select between these thousands of

00:03:13,940 --> 00:03:18,650
different options in an open cloud where

00:03:16,340 --> 00:03:20,030
there's lots of competition variety so

00:03:18,650 --> 00:03:23,269
this is our vision of an open cloud

00:03:20,030 --> 00:03:25,250
exchange and the idea is that once we

00:03:23,269 --> 00:03:26,630
created this in one data center we can

00:03:25,250 --> 00:03:28,600
actually replicate this out to other

00:03:26,630 --> 00:03:30,940
data

00:03:28,600 --> 00:03:33,700
[Music]

00:03:30,940 --> 00:03:36,100
this isn't crazy current clouds are

00:03:33,700 --> 00:03:37,780
incredibly expensive since this is

00:03:36,100 --> 00:03:40,930
actually being filmed in on YouTube I

00:03:37,780 --> 00:03:43,710
can't tell you the numbers but let's say

00:03:40,930 --> 00:03:47,230
it's well over 20 times as expensive to

00:03:43,710 --> 00:03:49,780
use and today one of today's clouds then

00:03:47,230 --> 00:03:52,360
if you took a modern data center at

00:03:49,780 --> 00:03:54,460
least our IR data center at the MGH PCC

00:03:52,360 --> 00:03:56,710
you amortize the cost of the data center

00:03:54,460 --> 00:03:59,590
over 20 years the cost of computers over

00:03:56,710 --> 00:04:01,540
3 years the cost of operation staff it's

00:03:59,590 --> 00:04:03,520
incredibly expensive the on-demand

00:04:01,540 --> 00:04:06,520
pricing and even the lease pricing is a

00:04:03,520 --> 00:04:09,670
lot more expensive than our cost to

00:04:06,520 --> 00:04:11,310
operate these facilities much of

00:04:09,670 --> 00:04:13,480
industry is locked out of today's clouds

00:04:11,310 --> 00:04:16,270
there's obviously lots of great software

00:04:13,480 --> 00:04:17,560
to develop these with and there's most

00:04:16,270 --> 00:04:20,760
people that don't want to be locked into

00:04:17,560 --> 00:04:22,650
the cloud so

00:04:20,760 --> 00:04:24,450
we had an incredible opportunity in this

00:04:22,650 --> 00:04:25,830
region the universities in the

00:04:24,450 --> 00:04:28,170
surrounding area had actually built a

00:04:25,830 --> 00:04:30,720
new data center it's really up there

00:04:28,170 --> 00:04:32,750
there we go the MGH BC this Center this

00:04:30,720 --> 00:04:35,160
is incredible facility this was built by

00:04:32,750 --> 00:04:37,350
combination of MIT Harvard bu

00:04:35,160 --> 00:04:39,750
Northeastern and the UMass system it's

00:04:37,350 --> 00:04:40,950
15 megawatts I don't know if that means

00:04:39,750 --> 00:04:43,410
a to you but that's like the power

00:04:40,950 --> 00:04:45,960
requirements of a town of a large town

00:04:43,410 --> 00:04:47,310
this thing has two acres it's the only

00:04:45,960 --> 00:04:50,070
place where I've seen where you measure

00:04:47,310 --> 00:04:53,490
computer space and acres right so two

00:04:50,070 --> 00:04:55,530
acres of space for computers incredible

00:04:53,490 --> 00:04:57,270
facility right located right next to

00:04:55,530 --> 00:05:02,580
Roger of dam seventy percent of the

00:04:57,270 --> 00:05:04,140
power comes from is green and because of

00:05:02,580 --> 00:05:06,180
the nature of this is the prices are

00:05:04,140 --> 00:05:07,470
incredibly cheaper than in Boston so

00:05:06,180 --> 00:05:09,300
these are the stuff change to do this

00:05:07,470 --> 00:05:11,220
there's a picture of us with the

00:05:09,300 --> 00:05:13,470
governor announcing the project to

00:05:11,220 --> 00:05:15,180
create an open cloud it's being renamed

00:05:13,470 --> 00:05:17,640
the Massillon Club from Massachusetts

00:05:15,180 --> 00:05:19,230
open cloud it's got all these

00:05:17,640 --> 00:05:22,740
universities participating the effort

00:05:19,230 --> 00:05:24,810
the airforce the state our core partners

00:05:22,740 --> 00:05:26,490
we're red has been really key partner

00:05:24,810 --> 00:05:27,930
from us from the beginning and a lot of

00:05:26,490 --> 00:05:31,380
other partners that have contributed in

00:05:27,930 --> 00:05:33,900
various ways to the project it's real

00:05:31,380 --> 00:05:36,000
it's an operating Club today these

00:05:33,900 --> 00:05:39,630
numbers were as of last week this is to

00:05:36,000 --> 00:05:41,760
this week so it's it's it's a

00:05:39,630 --> 00:05:44,280
functioning cloud at a relatively modest

00:05:41,760 --> 00:05:46,410
scale we have about 400 users directly

00:05:44,280 --> 00:05:48,840
and last time we figured out it's over

00:05:46,410 --> 00:05:51,290
10,000 users indirectly using the

00:05:48,840 --> 00:05:52,700
service in various ways

00:05:51,290 --> 00:05:56,750
[Music]

00:05:52,700 --> 00:05:58,880
and this is a different shark day and

00:05:56,750 --> 00:06:01,130
it's resulted in tens of millions of

00:05:58,880 --> 00:06:02,240
dollars of grants because this is one of

00:06:01,130 --> 00:06:03,860
the few clouds up there where

00:06:02,240 --> 00:06:07,760
researchers can get involved do

00:06:03,860 --> 00:06:09,650
innovation change things and it's moving

00:06:07,760 --> 00:06:11,330
from a project that's a small team

00:06:09,650 --> 00:06:13,460
developing this as its own kind of

00:06:11,330 --> 00:06:16,040
isolate project into that G departments

00:06:13,460 --> 00:06:18,440
actually working on this as a production

00:06:16,040 --> 00:06:19,820
service because this is being reused by

00:06:18,440 --> 00:06:22,670
real users that want to get their work

00:06:19,820 --> 00:06:25,940
done so increasingly what's happened is

00:06:22,670 --> 00:06:27,440
people don't want to use HPC aren't just

00:06:25,940 --> 00:06:29,510
using the data center for

00:06:27,440 --> 00:06:31,010
high-performance computing but I want to

00:06:29,510 --> 00:06:33,260
do data analytics they want to do

00:06:31,010 --> 00:06:34,610
machine learning the data science

00:06:33,260 --> 00:06:38,240
initiatives from all of our different

00:06:34,610 --> 00:06:39,650
universities and so two of the projects

00:06:38,240 --> 00:06:41,780
I'd like to mention that are just coming

00:06:39,650 --> 00:06:44,450
up now northeastern storage exchange

00:06:41,780 --> 00:06:46,700
that got funded for 10 petabytes of

00:06:44,450 --> 00:06:48,440
storage to start off with but it's

00:06:46,700 --> 00:06:50,180
doubled in size before it even started

00:06:48,440 --> 00:06:52,190
so it's now 20 petabytes of storage

00:06:50,180 --> 00:06:53,390
they'll be available for people to host

00:06:52,190 --> 00:06:56,300
their datasets from all over the region

00:06:53,390 --> 00:06:58,040
and Harvard dataverse which is the

00:06:56,300 --> 00:07:00,740
largest data center plus 4 in the world

00:06:58,040 --> 00:07:04,340
that today runs on AWS is being shifted

00:07:00,740 --> 00:07:07,220
move to the MOC so it's a going concern

00:07:04,340 --> 00:07:09,590
and we're really excited about this

00:07:07,220 --> 00:07:12,050
project because this actually is kind of

00:07:09,590 --> 00:07:15,170
our realization of an intermediary and

00:07:12,050 --> 00:07:17,270
it's also something which is really high

00:07:15,170 --> 00:07:19,740
demand by the users of the MOC

00:07:17,270 --> 00:07:21,080
[Music]

00:07:19,740 --> 00:07:22,719
all right

00:07:21,080 --> 00:07:25,599
[Music]

00:07:22,719 --> 00:07:27,639
so like we talked about earlier alright

00:07:25,599 --> 00:07:30,249
so the data hub is based on a set of

00:07:27,639 --> 00:07:32,379
common services and common applications

00:07:30,249 --> 00:07:34,749
that are out there and in the data

00:07:32,379 --> 00:07:36,219
science and data manager world and we

00:07:34,749 --> 00:07:38,499
see that basically breaking into three

00:07:36,219 --> 00:07:40,509
themes right so we have our platform and

00:07:38,499 --> 00:07:41,829
workflow theme these are things these

00:07:40,509 --> 00:07:43,509
are like what the operators are

00:07:41,829 --> 00:07:45,189
concerned with when it comes to how do I

00:07:43,509 --> 00:07:46,719
operate the data platform here at the

00:07:45,189 --> 00:07:49,179
bottom how do I make sure I have my

00:07:46,719 --> 00:07:50,949
identity policies identified how are we

00:07:49,179 --> 00:07:52,689
doing the management operations

00:07:50,949 --> 00:07:54,669
monitoring alerting of all of those

00:07:52,689 --> 00:07:56,529
systems and then how are we making this

00:07:54,669 --> 00:07:58,269
a self-service system so that our users

00:07:56,529 --> 00:07:59,829
can come in and do this on their own

00:07:58,269 --> 00:08:02,319
without constantly having to interact

00:07:59,829 --> 00:08:04,599
with the administrators themselves and

00:08:02,319 --> 00:08:06,309
then from a workflow lifecycles

00:08:04,599 --> 00:08:07,959
standpoint this is something DevOps has

00:08:06,309 --> 00:08:10,839
down pretty good right so this is based

00:08:07,959 --> 00:08:13,239
on kubernetes jenkins things like that

00:08:10,839 --> 00:08:15,519
for managing their the code pushes the

00:08:13,239 --> 00:08:18,039
application life cycles those that layer

00:08:15,519 --> 00:08:19,839
itself moving further up the stack

00:08:18,039 --> 00:08:22,209
that's where we start to put in our

00:08:19,839 --> 00:08:23,349
reusable models and modules so this is

00:08:22,209 --> 00:08:24,939
where you have a team of folks that are

00:08:23,349 --> 00:08:26,199
putting in things like common libraries

00:08:24,939 --> 00:08:28,809
and common services that have

00:08:26,199 --> 00:08:31,029
reusability across whether they're in

00:08:28,809 --> 00:08:33,189
house applications customer applications

00:08:31,029 --> 00:08:35,409
or someone else's bespoke application

00:08:33,189 --> 00:08:38,680
this is where we look to derive a lot of

00:08:35,409 --> 00:08:40,899
the community investment and intellect

00:08:38,680 --> 00:08:43,509
in how we deploy what we call our AI

00:08:40,899 --> 00:08:45,699
library as a series of common analytics

00:08:43,509 --> 00:08:47,680
that folks can then use in their

00:08:45,699 --> 00:08:50,410
applications so think of things like

00:08:47,680 --> 00:08:52,689
anomaly detection flake analysis

00:08:50,410 --> 00:08:54,610
something anything the CI developer or

00:08:52,689 --> 00:08:57,189
an application developer can work into

00:08:54,610 --> 00:08:59,800
their CI workflow to help make them more

00:08:57,189 --> 00:09:01,600
productive help them get to the root

00:08:59,800 --> 00:09:03,730
cause of failures quicker and make their

00:09:01,600 --> 00:09:05,889
code quality better and help iterate

00:09:03,730 --> 00:09:07,100
over the releases of those that software

00:09:05,889 --> 00:09:09,140
faster

00:09:07,100 --> 00:09:11,210
and then the third layer is at the top

00:09:09,140 --> 00:09:12,260
which is basically where the custom

00:09:11,210 --> 00:09:14,480
development comes in

00:09:12,260 --> 00:09:16,790
so this is where communities businesses

00:09:14,480 --> 00:09:18,320
data scientists are coming in taking

00:09:16,790 --> 00:09:21,170
advantage of those shared services

00:09:18,320 --> 00:09:22,970
writing those into applications or

00:09:21,170 --> 00:09:24,890
chaining together them together in such

00:09:22,970 --> 00:09:27,290
a way that they're getting added value

00:09:24,890 --> 00:09:28,670
out of them in that environment that's

00:09:27,290 --> 00:09:30,590
where they also may need to do their own

00:09:28,670 --> 00:09:32,900
data science experiments so we can give

00:09:30,590 --> 00:09:34,670
you something common like a commodity

00:09:32,900 --> 00:09:36,890
like a flake analysis a correlation

00:09:34,670 --> 00:09:38,810
analysis things like that that are

00:09:36,890 --> 00:09:40,370
pretty well defined but giving you a

00:09:38,810 --> 00:09:43,130
custom trained model to determine

00:09:40,370 --> 00:09:45,140
whether for fraud detection or for

00:09:43,130 --> 00:09:47,030
natural language processing or for image

00:09:45,140 --> 00:09:48,620
detection that's not something we can

00:09:47,030 --> 00:09:49,820
necessarily give you the commodity level

00:09:48,620 --> 00:09:52,010
that's something you may want to Train

00:09:49,820 --> 00:09:53,600
specific to your data and that's where

00:09:52,010 --> 00:09:55,940
what we want to do is enable that tool

00:09:53,600 --> 00:09:57,740
chain and that data science workflow for

00:09:55,940 --> 00:09:59,930
users to be able to come in easily get

00:09:57,740 --> 00:10:01,720
access to the environment put data into

00:09:59,930 --> 00:10:04,130
the environment analyze their data

00:10:01,720 --> 00:10:06,290
iterate on that and then publish that

00:10:04,130 --> 00:10:07,910
information out to whether it's a stored

00:10:06,290 --> 00:10:11,270
model that some application is in

00:10:07,910 --> 00:10:13,310
surfacing further downstream or whether

00:10:11,270 --> 00:10:15,050
it's actually getting bundled up into

00:10:13,310 --> 00:10:17,210
another service that has an endpoint

00:10:15,050 --> 00:10:19,430
that then other users can call into and

00:10:17,210 --> 00:10:20,870
that entire model lifecycle management

00:10:19,430 --> 00:10:21,190
is something we're looking to enable

00:10:20,870 --> 00:10:23,730
here

00:10:21,190 --> 00:10:26,780
[Music]

00:10:23,730 --> 00:10:29,780
and now an update

00:10:26,780 --> 00:10:32,300
should be coming the bits take a little

00:10:29,780 --> 00:10:36,920
while I guess to get from back there up

00:10:32,300 --> 00:10:38,480
here there we go so this is the concepts

00:10:36,920 --> 00:10:40,280
behind the open data hub in the

00:10:38,480 --> 00:10:42,290
Massachusetts Oakland cloud and the open

00:10:40,280 --> 00:10:44,390
data hub project in general what it's

00:10:42,290 --> 00:10:46,250
designed to do is basically give you

00:10:44,390 --> 00:10:49,730
capabilities when it comes to data

00:10:46,250 --> 00:10:51,500
ingestion normalization and storage data

00:10:49,730 --> 00:10:54,290
exploration around reporting and

00:10:51,500 --> 00:10:55,970
analysis and then analytic and lifecycle

00:10:54,290 --> 00:10:58,310
management around data science

00:10:55,970 --> 00:11:00,380
experimentation publishing that into

00:10:58,310 --> 00:11:03,980
services and managing the workflow

00:11:00,380 --> 00:11:06,680
therein and so the Massachusetts Oakland

00:11:03,980 --> 00:11:08,360
cloud is basically a meta project around

00:11:06,680 --> 00:11:11,270
bringing together the technologies that

00:11:08,360 --> 00:11:12,530
would comprise this platform so with

00:11:11,270 --> 00:11:14,000
when you're out there in the industry or

00:11:12,530 --> 00:11:16,040
when you're talking with folks a lot of

00:11:14,000 --> 00:11:17,990
the technologies that are used to enable

00:11:16,040 --> 00:11:19,610
these types of capabilities are pretty

00:11:17,990 --> 00:11:22,000
common everywhere you go you hear things

00:11:19,610 --> 00:11:24,380
like Kafka you hear things like Jenkins

00:11:22,000 --> 00:11:27,020
those things have become commodities and

00:11:24,380 --> 00:11:30,800
what we're trying to do is alleviate the

00:11:27,020 --> 00:11:32,930
pain from individual users or companies

00:11:30,800 --> 00:11:34,250
who want to stand up this from actually

00:11:32,930 --> 00:11:35,660
having to worry about hosting that

00:11:34,250 --> 00:11:37,850
infrastructure themselves it's already

00:11:35,660 --> 00:11:39,440
going to be their self-service model you

00:11:37,850 --> 00:11:41,480
come in and you take advantage of it and

00:11:39,440 --> 00:11:44,210
so what we're bringing together is a set

00:11:41,480 --> 00:11:46,670
of communities vendors users operators

00:11:44,210 --> 00:11:48,320
and academics to do that in a fully open

00:11:46,670 --> 00:11:49,940
source way where we're getting the

00:11:48,320 --> 00:11:52,339
benefit of everyone's intellect

00:11:49,940 --> 00:11:53,810
everyone's experience users know what

00:11:52,339 --> 00:11:55,370
they want to do to actually use the

00:11:53,810 --> 00:11:57,440
system operators and what it takes to

00:11:55,370 --> 00:11:58,580
really operate the system and so we're

00:11:57,440 --> 00:12:00,440
Red Hat traditionally it's been really

00:11:58,580 --> 00:12:02,450
really great in the open-source world

00:12:00,440 --> 00:12:03,920
around we know how to write code and we

00:12:02,450 --> 00:12:06,500
know how to package code we know how to

00:12:03,920 --> 00:12:08,089
push that code this is an evolution for

00:12:06,500 --> 00:12:09,950
Red Hat where it comes to how do we go

00:12:08,089 --> 00:12:11,360
into open source operations and how are

00:12:09,950 --> 00:12:14,850
we going to open source the data

00:12:11,360 --> 00:12:17,980
management lifecycle entirely

00:12:14,850 --> 00:12:19,749
and I'll hit next 11 and the focus here

00:12:17,980 --> 00:12:21,850
is on reproducibility right that's why

00:12:19,749 --> 00:12:23,920
we're using open source projects feeding

00:12:21,850 --> 00:12:26,439
into this the open data hub is not

00:12:23,920 --> 00:12:28,360
writing a new Kafka we're not writing a

00:12:26,439 --> 00:12:29,709
new service broker we're taking those

00:12:28,360 --> 00:12:31,660
and we're putting them together in such

00:12:29,709 --> 00:12:33,009
a way that it leads for a more usable

00:12:31,660 --> 00:12:35,499
platform things are gonna be

00:12:33,009 --> 00:12:37,389
pre-configured so a user coming in it

00:12:35,499 --> 00:12:39,189
doesn't have to worry about where their

00:12:37,389 --> 00:12:41,470
spark instances or where's my data

00:12:39,189 --> 00:12:42,819
storage that's gonna be in there all you

00:12:41,470 --> 00:12:45,850
need to worry about is coming in and

00:12:42,819 --> 00:12:46,959
actually doing your analysis the other

00:12:45,850 --> 00:12:48,910
thing we want to be able to do is let

00:12:46,959 --> 00:12:51,610
projects pick and choose which services

00:12:48,910 --> 00:12:54,160
they actually want to be encumbered with

00:12:51,610 --> 00:12:55,689
not everybody needs the full stack you

00:12:54,160 --> 00:12:57,189
know you may have data that's already

00:12:55,689 --> 00:12:58,629
sitting out there hosted somewhere and

00:12:57,189 --> 00:13:00,339
you just need to bring that data in and

00:12:58,629 --> 00:13:03,160
then analyze it because maybe you don't

00:13:00,339 --> 00:13:05,619
buy the expensive GPUs right but the MOC

00:13:03,160 --> 00:13:07,299
has them so that's great take your data

00:13:05,619 --> 00:13:09,279
run in the MOC environment take

00:13:07,299 --> 00:13:11,139
advantage of that GPU horsepower and

00:13:09,279 --> 00:13:12,790
then move on to whatever the next thing

00:13:11,139 --> 00:13:16,350
in your value chain is so you can come

00:13:12,790 --> 00:13:19,929
in at any layer of the stack you wish

00:13:16,350 --> 00:13:22,299
and so the of all of those things we

00:13:19,929 --> 00:13:26,110
just talked about the first use case we

00:13:22,299 --> 00:13:29,170
have targeted here assuming it shows up

00:13:26,110 --> 00:13:31,749
it's a brilliant use case is basically

00:13:29,170 --> 00:13:33,639
around data science experimentation and

00:13:31,749 --> 00:13:35,350
this is an early adopter environment

00:13:33,639 --> 00:13:37,299
right now but it's basically geared

00:13:35,350 --> 00:13:40,089
toward the data scientist who has data

00:13:37,299 --> 00:13:42,429
wants to come in analyze that data needs

00:13:40,089 --> 00:13:44,470
access to spark or tensorflow and it's

00:13:42,429 --> 00:13:46,749
comfortable with jupiter notebooks so

00:13:44,470 --> 00:13:50,470
what we've enabled is set for our

00:13:46,749 --> 00:13:54,040
storage and s3 apache spark for how we

00:13:50,470 --> 00:13:56,529
do data management tensorflow and then a

00:13:54,040 --> 00:13:59,970
series of jupiter notebooks out there to

00:13:56,529 --> 00:13:59,970
take advantage of these capabilities

00:14:00,210 --> 00:14:03,899
and so enough talking right you actually

00:14:02,370 --> 00:14:06,720
see the thing work and how easy this

00:14:03,899 --> 00:14:14,520
really is right so that's what we'll do

00:14:06,720 --> 00:14:17,040
next let me put this up here I'd say I'm

00:14:14,520 --> 00:14:25,500
kind of worried we'll see how good this

00:14:17,040 --> 00:14:27,690
does this all right so the MOC

00:14:25,500 --> 00:14:29,910
environment basically so I'm going to

00:14:27,690 --> 00:14:32,459
assume like the the where this picks up

00:14:29,910 --> 00:14:34,860
is at the point where you have already

00:14:32,459 --> 00:14:36,149
gotten a login from the MOC team and you

00:14:34,860 --> 00:14:37,740
can actually get into the system right

00:14:36,149 --> 00:14:41,070
so there's a request for that you get a

00:14:37,740 --> 00:14:42,899
login password and you can log in so I'm

00:14:41,070 --> 00:14:46,350
gonna hit refresh on this because it's

00:14:42,899 --> 00:14:48,570
probably gonna take it a minute alright

00:14:46,350 --> 00:14:50,520
so I'm going to login to the MOC

00:14:48,570 --> 00:14:52,500
environment the first thing we're gonna

00:14:50,520 --> 00:15:02,149
want to do is get some data up here

00:14:52,500 --> 00:15:04,370
right that's wrong that's right

00:15:02,149 --> 00:15:09,350
here we go now we'll have valid

00:15:04,370 --> 00:15:11,240
credentials so the first thing we want

00:15:09,350 --> 00:15:12,290
to do I'm gonna upload data just so you

00:15:11,240 --> 00:15:13,819
can see how easy it is if you're

00:15:12,290 --> 00:15:15,230
bringing your own data to the table if

00:15:13,819 --> 00:15:16,610
you have data it's already hosted out

00:15:15,230 --> 00:15:20,300
there somewhere we can always point to

00:15:16,610 --> 00:15:25,120
it but for the processes of this so

00:15:20,300 --> 00:15:25,120
we're going to add a new container

00:15:25,279 --> 00:15:34,970
Jules test really one seven and we will

00:15:32,329 --> 00:15:36,949
submit it great so now we've got an s3

00:15:34,970 --> 00:15:39,259
bucket right everyone who's used Amazon

00:15:36,949 --> 00:15:41,170
or anything that I've used s3 you're

00:15:39,259 --> 00:15:44,240
familiar with that Ness three buck is

00:15:41,170 --> 00:15:45,800
all right so the next thing we'll do is

00:15:44,240 --> 00:15:48,649
we'll go verify I'm not lying to

00:15:45,800 --> 00:15:49,879
everyone here with so some things that's

00:15:48,649 --> 00:15:51,980
already been done here again I've

00:15:49,879 --> 00:15:53,720
already logged into the system you can

00:15:51,980 --> 00:15:57,559
from that system obviously you'll need

00:15:53,720 --> 00:15:59,029
access to your individual API keys in

00:15:57,559 --> 00:16:01,160
order to get access to those buckets

00:15:59,029 --> 00:16:02,629
right that's all taken care of and again

00:16:01,160 --> 00:16:04,699
because this is live streaming I'm not

00:16:02,629 --> 00:16:06,980
actually gonna click and show you my API

00:16:04,699 --> 00:16:08,660
access keys but understand that you

00:16:06,980 --> 00:16:10,670
click that button it gives you your keys

00:16:08,660 --> 00:16:14,360
and you can copy them and you know use

00:16:10,670 --> 00:16:16,160
them how you need to so the next thing

00:16:14,360 --> 00:16:19,759
you will do you all want to download the

00:16:16,160 --> 00:16:22,040
UC s3 AWS client so you can go in and

00:16:19,759 --> 00:16:24,769
then actually command-line upload your

00:16:22,040 --> 00:16:28,189
data so from there you would do a AWS

00:16:24,769 --> 00:16:29,779
configure here again I've already pasted

00:16:28,189 --> 00:16:32,000
my keys in here but if you wanted to pay

00:16:29,779 --> 00:16:33,920
some you could paste it in enter paste

00:16:32,000 --> 00:16:35,720
in your next key enter and we're just

00:16:33,920 --> 00:16:38,990
gonna leave the region and format

00:16:35,720 --> 00:16:41,809
defaults for now so that will then have

00:16:38,990 --> 00:16:43,639
now tell your command-line client on

00:16:41,809 --> 00:16:46,850
your machine here's how I get access to

00:16:43,639 --> 00:16:48,319
the AWS here's how I get access to AWS

00:16:46,850 --> 00:16:51,529
now we're gonna go and we're gonna do

00:16:48,319 --> 00:16:54,079
something with that bucket all right so

00:16:51,529 --> 00:16:55,519
the first thing we're gonna do and just

00:16:54,079 --> 00:16:57,139
you guys don't have to watch me type

00:16:55,519 --> 00:16:59,059
over and over again we're just gonna cut

00:16:57,139 --> 00:17:00,259
and paste these commands so first we're

00:16:59,059 --> 00:17:01,910
gonna go up and look and see that our

00:17:00,259 --> 00:17:03,320
bucket actually did get created out

00:17:01,910 --> 00:17:06,230
there

00:17:03,320 --> 00:17:09,679
and sure enough there we see s eul's

00:17:06,230 --> 00:17:11,209
test sitting up there alright so the

00:17:09,679 --> 00:17:14,179
next thing I want to do is upload my

00:17:11,209 --> 00:17:15,169
data so in this directory here I have

00:17:14,179 --> 00:17:18,380
this data file

00:17:15,169 --> 00:17:21,410
it's a JSON formatted file I think this

00:17:18,380 --> 00:17:22,680
is actually weather data so we will

00:17:21,410 --> 00:17:31,130
upload that

00:17:22,680 --> 00:17:32,510
[Music]

00:17:31,130 --> 00:17:34,250
and again for those that aren't familiar

00:17:32,510 --> 00:17:36,110
with the AWS commands is pretty basic

00:17:34,250 --> 00:17:37,730
stuff right so you've got you're

00:17:36,110 --> 00:17:39,289
uploading it to s3 you're telling it

00:17:37,730 --> 00:17:41,179
what bucket to put it in if you want it

00:17:39,289 --> 00:17:42,770
in a subdirectory under that bucket and

00:17:41,179 --> 00:17:44,660
then you're giving at the end point that

00:17:42,770 --> 00:17:51,200
you're loading it to so this guy's an

00:17:44,660 --> 00:17:53,330
this is the MOC environment alright so

00:17:51,200 --> 00:17:54,890
there we have uploaded it and then just

00:17:53,330 --> 00:18:02,660
to prove you that it actually is

00:17:54,890 --> 00:18:04,760
uploaded we will view it and so here we

00:18:02,660 --> 00:18:06,260
are looking again at that s eul's test

00:18:04,760 --> 00:18:07,909
bucket and we can see the date has been

00:18:06,260 --> 00:18:09,350
uploaded if you have more data it would

00:18:07,909 --> 00:18:10,970
take a little bit more time but it's as

00:18:09,350 --> 00:18:13,669
simple as that to get the data into the

00:18:10,970 --> 00:18:15,169
environment itself so from here this is

00:18:13,669 --> 00:18:17,090
now where we would go we're gonna go

00:18:15,169 --> 00:18:20,240
into Jupiter hub and start to analyze

00:18:17,090 --> 00:18:21,650
some data and I'm gonna bring up a fresh

00:18:20,240 --> 00:18:22,780
one just so you can see it from the

00:18:21,650 --> 00:18:25,080
get-go here

00:18:22,780 --> 00:18:27,269
[Music]

00:18:25,080 --> 00:18:30,090
let me log out so you can see it from

00:18:27,269 --> 00:18:31,619
the start okay so this is what it would

00:18:30,090 --> 00:18:33,690
look like when you first come to the

00:18:31,619 --> 00:18:34,250
open data hub Jupiter hub on hopefully

00:18:33,690 --> 00:18:39,630
yep

00:18:34,250 --> 00:18:43,500
[Music]

00:18:39,630 --> 00:18:45,750
no it's the s3 protocol using object

00:18:43,500 --> 00:18:47,700
storage in the MOC environment so the

00:18:45,750 --> 00:18:49,650
storage is all in the MOC environment

00:18:47,700 --> 00:18:54,750
it's just using the s3 protocol for the

00:18:49,650 --> 00:18:59,039
storage so when you first come in well

00:18:54,750 --> 00:19:03,450
click sign in again it assumes you know

00:18:59,039 --> 00:19:04,860
we've actually have access then you

00:19:03,450 --> 00:19:07,440
would get that credential at the same

00:19:04,860 --> 00:19:08,970
time you sign up for saying I want to

00:19:07,440 --> 00:19:10,440
access to the MOC that's the same set of

00:19:08,970 --> 00:19:15,530
credentials to get you into this project

00:19:10,440 --> 00:19:18,090
right so by default when we come in

00:19:15,530 --> 00:19:23,030
let's run the sparklin first so let me

00:19:18,090 --> 00:19:26,130
stop my server I'm gonna start a new one

00:19:23,030 --> 00:19:28,350
and we'll start with the spark example

00:19:26,130 --> 00:19:30,330
that we have out here so when you first

00:19:28,350 --> 00:19:32,340
come in you should be presented with hey

00:19:30,330 --> 00:19:35,039
which notebook image do you want to

00:19:32,340 --> 00:19:36,120
actually run then how many people are

00:19:35,039 --> 00:19:39,000
familiar with Jupiter

00:19:36,120 --> 00:19:41,850
I guess fantastic I'm not gonna bore you

00:19:39,000 --> 00:19:43,890
with what these things are so all of the

00:19:41,850 --> 00:19:45,210
notebook images here that that you see

00:19:43,890 --> 00:19:47,250
listed these are things that we're

00:19:45,210 --> 00:19:49,470
hosting out in the community obviously

00:19:47,250 --> 00:19:51,090
as we need to grow and do support more

00:19:49,470 --> 00:19:52,470
things then we'll add those types of

00:19:51,090 --> 00:19:54,360
notebooks and make them available so

00:19:52,470 --> 00:19:57,210
we've started again with some simple

00:19:54,360 --> 00:19:59,100
ones around using pi spar spark and

00:19:57,210 --> 00:20:00,840
tensor flow and there's a couple more

00:19:59,100 --> 00:20:04,120
generic ones in there I think just using

00:20:00,840 --> 00:20:10,380
like regular scikit-learn

00:20:04,120 --> 00:20:10,380
so this should spawn is pending

00:20:10,850 --> 00:20:20,190
[Music]

00:20:16,770 --> 00:20:21,240
let's go back to it there we go so now

00:20:20,190 --> 00:20:24,870
we're up and running

00:20:21,240 --> 00:20:26,880
alright so we will open the spark MOC

00:20:24,870 --> 00:20:33,990
can you guys read this let me make this

00:20:26,880 --> 00:20:35,220
a little bigger okay so I'm not gonna go

00:20:33,990 --> 00:20:36,510
into the details of what's in this

00:20:35,220 --> 00:20:38,070
notebook this was written by another

00:20:36,510 --> 00:20:40,410
individual might be in the room who's

00:20:38,070 --> 00:20:42,600
giving a talk later about analyzing time

00:20:40,410 --> 00:20:45,300
series data so this is data that's

00:20:42,600 --> 00:20:47,280
monitoring kubernetes operations on a

00:20:45,300 --> 00:20:50,280
running cluster and then reports about

00:20:47,280 --> 00:20:52,260
the like the various statistics on those

00:20:50,280 --> 00:20:54,690
operations I think he's giving a talk

00:20:52,260 --> 00:20:57,570
later today but the important thing in

00:20:54,690 --> 00:20:59,610
here is basically that for your spark

00:20:57,570 --> 00:21:01,860
configuration that spark is already up

00:20:59,610 --> 00:21:03,750
and running inside the MOC environment

00:21:01,860 --> 00:21:05,520
you don't have to worry about hosting

00:21:03,750 --> 00:21:07,380
spark yourself staining it up yourself

00:21:05,520 --> 00:21:09,150
and configuring yourself you can

00:21:07,380 --> 00:21:10,920
override configurations if you want more

00:21:09,150 --> 00:21:12,990
memory or you need a ah special

00:21:10,920 --> 00:21:14,850
configurations but by default all you

00:21:12,990 --> 00:21:16,290
have to do is come in take advantage of

00:21:14,850 --> 00:21:18,510
an environment variable it's been set up

00:21:16,290 --> 00:21:20,610
and that is your spark server right

00:21:18,510 --> 00:21:22,110
that's been done for you over there we

00:21:20,610 --> 00:21:24,600
do have keys some going to edit that out

00:21:22,110 --> 00:21:26,040
on the recording sorry and then

00:21:24,600 --> 00:21:29,640
basically you just point it off to the

00:21:26,040 --> 00:21:34,080
data and that is again pre-configured so

00:21:29,640 --> 00:21:36,420
we know where the MOC data is and we can

00:21:34,080 --> 00:21:38,530
execute against it and so now we'll just

00:21:36,420 --> 00:21:41,620
run all of it

00:21:38,530 --> 00:21:46,659
this takes about a minute or so to get

00:21:41,620 --> 00:21:49,570
all the way through or so we'll give it

00:21:46,659 --> 00:21:51,909
a minute so again all this stuff is

00:21:49,570 --> 00:21:53,380
built-in so that we're trying to ease

00:21:51,909 --> 00:21:54,789
the operation right I don't know how

00:21:53,380 --> 00:21:56,530
many of you have ever tried to stand up

00:21:54,789 --> 00:21:58,390
spar try to stand up all of your storage

00:21:56,530 --> 00:22:00,010
get all this configured and then

00:21:58,390 --> 00:22:01,299
actually get to the value-add part which

00:22:00,010 --> 00:22:03,549
is actually writing the notebook and

00:22:01,299 --> 00:22:05,620
running that notebook but this makes

00:22:03,549 --> 00:22:07,390
that process a lot faster and again if

00:22:05,620 --> 00:22:09,370
you had if you had data already out

00:22:07,390 --> 00:22:11,559
there in Amazon s3 you can point to it

00:22:09,370 --> 00:22:16,059
it's the same set of keys same set of

00:22:11,559 --> 00:22:19,070
access this is where like we just wait

00:22:16,059 --> 00:22:22,500
and see how fast the machine runs

00:22:19,070 --> 00:22:25,020
[Music]

00:22:22,500 --> 00:22:26,640
should take less than a minute so I

00:22:25,020 --> 00:22:30,810
guess all that's going any questions on

00:22:26,640 --> 00:22:33,540
anything you've seen thus far it's a

00:22:30,810 --> 00:22:36,860
good segue not even one question to help

00:22:33,540 --> 00:22:36,860
me with the time this is taking

00:22:41,250 --> 00:22:45,380
I'm sorry a little bit louder

00:22:52,240 --> 00:22:58,210
yes yeah yeah their greatest gateway

00:22:55,950 --> 00:23:01,090
service that you can stand up with stuff

00:22:58,210 --> 00:23:03,390
we have that it's a pretty standard

00:23:01,090 --> 00:23:03,390
thing yeah

00:23:07,040 --> 00:23:18,080
[Music]

00:23:15,000 --> 00:23:18,080
done work

00:23:18,460 --> 00:23:30,809
[Music]

00:23:27,919 --> 00:23:33,270
all right thank you for the questions

00:23:30,809 --> 00:23:36,000
it helped now everything is run here the

00:23:33,270 --> 00:23:38,070
results from all of our analysis again

00:23:36,000 --> 00:23:40,200
sewage it's gonna talk about this later

00:23:38,070 --> 00:23:42,330
in the week so

00:23:40,200 --> 00:23:43,860
but basically point is to prove sparks

00:23:42,330 --> 00:23:47,850
out there running data was processed

00:23:43,860 --> 00:23:48,929
everything work just as designed the

00:23:47,850 --> 00:23:53,360
next one then we're going to talk about

00:23:48,929 --> 00:23:56,400
here is tensorflow

00:23:53,360 --> 00:23:59,630
leave that page that's fine

00:23:56,400 --> 00:23:59,630
stop my server

00:23:59,760 --> 00:24:03,840
[Music]

00:24:02,160 --> 00:24:08,070
all right now we'll restart it and we'll

00:24:03,840 --> 00:24:10,140
do tensorflow this go-round and I

00:24:08,070 --> 00:24:12,270
believe them so the tensorflow we're

00:24:10,140 --> 00:24:14,160
gonna show right now is non GPU but we

00:24:12,270 --> 00:24:17,310
have GPUs in the environment and we can

00:24:14,160 --> 00:24:18,750
take advantage of those as well but

00:24:17,310 --> 00:24:20,400
again it's just as simple as if you're

00:24:18,750 --> 00:24:22,830
coming and doing a tensor flow project

00:24:20,400 --> 00:24:26,910
once that this list shows up we will

00:24:22,830 --> 00:24:28,080
select tensor flow image and execute

00:24:26,910 --> 00:24:39,120
against that

00:24:28,080 --> 00:24:42,010
[Music]

00:24:39,120 --> 00:24:44,730
it's normally a lot

00:24:42,010 --> 00:24:53,050
must be this room

00:24:44,730 --> 00:24:54,610
[Music]

00:24:53,050 --> 00:24:56,080
so the experiments we're going out there

00:24:54,610 --> 00:24:59,800
tonight there weren't that many students

00:24:56,080 --> 00:25:01,270
who will look at what it was yeah yes a

00:24:59,800 --> 00:25:03,850
we have sort of relatively modest

00:25:01,270 --> 00:25:05,500
feeling very sorry do what type of the

00:25:03,850 --> 00:25:08,309
scale we're rolling out to in the next

00:25:05,500 --> 00:25:10,390
well that might not be a bad idea yeah

00:25:08,309 --> 00:25:12,220
yeah so right now this is running on a

00:25:10,390 --> 00:25:13,570
limited number of notes a lot of the

00:25:12,220 --> 00:25:16,179
efforts being to just get this up and

00:25:13,570 --> 00:25:17,920
running and make this available we've

00:25:16,179 --> 00:25:20,860
got a new environment that's coming up

00:25:17,920 --> 00:25:23,440
which will be a couple hundred notes by

00:25:20,860 --> 00:25:24,670
the end and this will be rolled out

00:25:23,440 --> 00:25:26,710
we'll make this available to a broader

00:25:24,670 --> 00:25:30,429
community it's fine when we have that

00:25:26,710 --> 00:25:32,140
larger scale and so this is just kind of

00:25:30,429 --> 00:25:35,380
a proven concept in some sense do you

00:25:32,140 --> 00:25:37,110
want to yeah exactly so we you'll see I

00:25:35,380 --> 00:25:39,010
now put the slide up at the end

00:25:37,110 --> 00:25:40,330
basically right now like that first

00:25:39,010 --> 00:25:42,250
slide said that we're kind of the early

00:25:40,330 --> 00:25:44,050
adopter face so it's not been opened up

00:25:42,250 --> 00:25:46,030
for the masses just to sign up and move

00:25:44,050 --> 00:25:47,260
forward with what we'd like to do is if

00:25:46,030 --> 00:25:49,929
you have an interest if your community

00:25:47,260 --> 00:25:51,970
has an interest the academia whatever

00:25:49,929 --> 00:25:53,740
we'd like to talk to you let's see make

00:25:51,970 --> 00:25:55,750
sure it's a good fit for your

00:25:53,740 --> 00:25:56,380
perspective from like understanding what

00:25:55,750 --> 00:25:58,540
you're going to get out of the

00:25:56,380 --> 00:26:00,010
environment to start make sure to go

00:25:58,540 --> 00:26:01,210
down we understand exactly what we're

00:26:00,010 --> 00:26:03,280
gonna look from you from an early

00:26:01,210 --> 00:26:04,840
adopter and then we can get you plugged

00:26:03,280 --> 00:26:06,920
into the environment and we can start

00:26:04,840 --> 00:26:14,410
working on it

00:26:06,920 --> 00:26:16,390
[Music]

00:26:14,410 --> 00:26:19,300
it's out there and running but right now

00:26:16,390 --> 00:26:21,190
we're getting access to it until one

00:26:19,300 --> 00:26:23,380
we've we make sure we have all of the

00:26:21,190 --> 00:26:25,570
right requirements for what most people

00:26:23,380 --> 00:26:27,340
are asking for we made some assumptions

00:26:25,570 --> 00:26:29,050
based on the common use cases we've been

00:26:27,340 --> 00:26:30,820
presented with to date around data

00:26:29,050 --> 00:26:33,670
science and the type of work so people

00:26:30,820 --> 00:26:35,140
want to see supported and we want to

00:26:33,670 --> 00:26:38,320
make sure that's valid before we just

00:26:35,140 --> 00:26:40,030
say hey here it is the second part is we

00:26:38,320 --> 00:26:42,310
do want to put it on a larger scale

00:26:40,030 --> 00:26:43,420
environment and knowing that once you

00:26:42,310 --> 00:26:45,160
open it up you're gonna get a lot of

00:26:43,420 --> 00:26:47,620
things coming in and hammering away on

00:26:45,160 --> 00:26:50,110
it and the EEA environment is not

00:26:47,620 --> 00:26:53,020
designed for that level of interactivity

00:26:50,110 --> 00:26:57,609
so that upgrades gonna be going on

00:26:53,020 --> 00:26:57,609
[Music]

00:26:57,610 --> 00:27:03,190
so so again the MOC is not intended to

00:27:01,210 --> 00:27:04,990
sort of compete with Amazon or anything

00:27:03,190 --> 00:27:06,820
what we want to do is be an environment

00:27:04,990 --> 00:27:08,470
where first of all though we can support

00:27:06,820 --> 00:27:11,080
all these research juices and stuff like

00:27:08,470 --> 00:27:12,550
that and secondly we're the open source

00:27:11,080 --> 00:27:14,650
community the research community can

00:27:12,550 --> 00:27:17,260
actually work together on things so this

00:27:14,650 --> 00:27:19,270
is going to be the one you know platform

00:27:17,260 --> 00:27:21,340
like this where the information about

00:27:19,270 --> 00:27:22,510
how to runs and can come back to all the

00:27:21,340 --> 00:27:24,520
different open source communities and

00:27:22,510 --> 00:27:26,710
stuff like that so yes we are building a

00:27:24,520 --> 00:27:28,000
charging model right now we don't

00:27:26,710 --> 00:27:29,590
actually have that integrated into it

00:27:28,000 --> 00:27:30,850
because at the end you got to charge for

00:27:29,590 --> 00:27:33,430
things if you can open it to a large

00:27:30,850 --> 00:27:36,040
population and we will be opening it up

00:27:33,430 --> 00:27:38,140
but we sort of intend for it to be more

00:27:36,040 --> 00:27:40,870
for the open source community the

00:27:38,140 --> 00:27:43,240
research community and startups and

00:27:40,870 --> 00:27:45,130
stuff in the region we don't our goal is

00:27:43,240 --> 00:27:47,850
not to be the competitor to Amazon or

00:27:45,130 --> 00:27:50,380
anything off that does that make sense

00:27:47,850 --> 00:27:52,450
all right and so this is now loaded so

00:27:50,380 --> 00:27:54,430
this is the in this sample you can

00:27:52,450 --> 00:27:55,690
download from Thames flow again no magic

00:27:54,430 --> 00:27:57,310
in the code if you want to know it's in

00:27:55,690 --> 00:28:01,570
the code I can give you a code you can

00:27:57,310 --> 00:28:05,080
read through it but here we will just do

00:28:01,570 --> 00:28:07,110
a run all this is gonna go download some

00:28:05,080 --> 00:28:07,110
data

00:28:08,100 --> 00:28:12,600
and it runs through it pretty quick here

00:28:09,900 --> 00:28:15,590
at the end we'll see some

00:28:12,600 --> 00:28:17,870
[Music]

00:28:15,590 --> 00:28:19,910
total which one are we doing where we

00:28:17,870 --> 00:28:23,059
still running oh downloading

00:28:19,910 --> 00:28:23,059
[Music]

00:28:23,460 --> 00:28:27,380
and importing dupe dude right so we're

00:28:25,619 --> 00:28:30,309
training models right now

00:28:27,380 --> 00:28:31,989
[Music]

00:28:30,309 --> 00:28:34,840
and then it goes through pretty quick

00:28:31,989 --> 00:28:36,489
and at the bottom so here the various

00:28:34,840 --> 00:28:39,369
runs through the neural network in the

00:28:36,489 --> 00:28:42,599
training accuracy and then voila it's

00:28:39,369 --> 00:28:44,210
finished right so access to tensorflow

00:28:42,599 --> 00:28:47,040
sure

00:28:44,210 --> 00:28:48,570
[Music]

00:28:47,040 --> 00:28:51,030
so

00:28:48,570 --> 00:28:55,270
once news

00:28:51,030 --> 00:28:58,270
[Music]

00:28:55,270 --> 00:28:58,270
family

00:28:58,500 --> 00:29:04,750
is everything

00:28:59,960 --> 00:29:08,230
[Music]

00:29:04,750 --> 00:29:10,400
absolutely so fantastic question so

00:29:08,230 --> 00:29:13,220
we've seen that and guys don't believe

00:29:10,400 --> 00:29:17,630
me it works and it's real right so I

00:29:13,220 --> 00:29:21,220
will go back to this real quick

00:29:17,630 --> 00:29:26,349
[Music]

00:29:21,220 --> 00:29:27,909
maybe present there we go okay so that's

00:29:26,349 --> 00:29:28,629
your point if you want to stand the same

00:29:27,909 --> 00:29:31,629
thing up

00:29:28,629 --> 00:29:33,879
open data hub dot IO this is the

00:29:31,629 --> 00:29:36,759
upstream community where all of the

00:29:33,879 --> 00:29:39,249
APB's operators to actually deploy this

00:29:36,759 --> 00:29:40,210
are being pushed the use case that's up

00:29:39,249 --> 00:29:42,129
there today is the one we just

00:29:40,210 --> 00:29:44,139
demonstrated on how to actually you can

00:29:42,129 --> 00:29:46,119
take that deployed on open shift that's

00:29:44,139 --> 00:29:47,499
gonna continue to grow we're looking for

00:29:46,119 --> 00:29:50,349
people to help contribute to that

00:29:47,499 --> 00:29:53,019
collaborate with us there's a lot that

00:29:50,349 --> 00:29:55,479
goes into what it takes to actually run

00:29:53,019 --> 00:29:57,190
this at scale so there's a lot of trial

00:29:55,479 --> 00:29:58,690
of you know we have it running internal

00:29:57,190 --> 00:30:00,639
Red Hat I think you saw Daniel talk

00:29:58,690 --> 00:30:02,470
about that we have a specific scale

00:30:00,639 --> 00:30:04,450
we're operating in and that's continuing

00:30:02,470 --> 00:30:07,269
to grow and change and we're adapting to

00:30:04,450 --> 00:30:08,289
that MOC is a completely another scale

00:30:07,269 --> 00:30:09,639
compared to what we're running

00:30:08,289 --> 00:30:11,590
internally and we're learning from that

00:30:09,639 --> 00:30:13,989
and I'm sure there's lots and lots of

00:30:11,590 --> 00:30:15,340
experience elsewhere you know in the

00:30:13,989 --> 00:30:16,720
audience and out there that we want to

00:30:15,340 --> 00:30:18,669
take advantage of to make sure that what

00:30:16,720 --> 00:30:20,559
we have is a truly hardened environment

00:30:18,669 --> 00:30:22,779
that can stand up to everyone poking at

00:30:20,559 --> 00:30:25,119
it but then yes you can take those APB's

00:30:22,779 --> 00:30:28,779
hit the Go button and it deploys and so

00:30:25,119 --> 00:30:31,179
so many good things to sort of what we

00:30:28,779 --> 00:30:32,840
found where we've been working really

00:30:31,179 --> 00:30:35,330
closely with Red Hat and

00:30:32,840 --> 00:30:37,100
and we've been finding a lot of problems

00:30:35,330 --> 00:30:39,559
as we stand up OpenStack and openshift

00:30:37,100 --> 00:30:41,870
on OpenStack and we have users using

00:30:39,559 --> 00:30:43,190
this because you know a lot of times the

00:30:41,870 --> 00:30:44,960
development community the open source

00:30:43,190 --> 00:30:47,299
community aren't in a position of

00:30:44,960 --> 00:30:49,940
operating things themselves at the kind

00:30:47,299 --> 00:30:52,100
of scale so what I think the experience

00:30:49,940 --> 00:30:53,659
of doing that or at those layers has led

00:30:52,100 --> 00:30:55,039
to now that the data hub is going

00:30:53,659 --> 00:30:57,169
forward and that's a really important

00:30:55,039 --> 00:30:59,450
initiative so instead of you know having

00:30:57,169 --> 00:31:01,070
a decoupled effort of red have and then

00:30:59,450 --> 00:31:03,590
we'll see working together to make it

00:31:01,070 --> 00:31:06,169
one deployment and get it a much tighter

00:31:03,590 --> 00:31:09,500
loop on that feedback of what has to

00:31:06,169 --> 00:31:11,870
change and if you're interested in being

00:31:09,500 --> 00:31:13,940
an early adopter there's my information

00:31:11,870 --> 00:31:16,159
just contact me and we'll start the

00:31:13,940 --> 00:31:17,750
conversation about getting what's gonna

00:31:16,159 --> 00:31:19,820
be involved in the early adopter cycle

00:31:17,750 --> 00:31:21,049
and get you guys access one of the other

00:31:19,820 --> 00:31:24,380
things and I didn't mean to gloss over

00:31:21,049 --> 00:31:26,000
it but there again data bringing

00:31:24,380 --> 00:31:27,649
together all the other open-source

00:31:26,000 --> 00:31:29,690
communities where we're actually taking

00:31:27,649 --> 00:31:31,820
these bits from one of the bits of the

00:31:29,690 --> 00:31:33,649
SPARC components that actually comes

00:31:31,820 --> 00:31:35,510
from the rad analytics I oh I think you

00:31:33,649 --> 00:31:36,409
guys probably are familiar with that or

00:31:35,510 --> 00:31:38,480
at least I've heard of mentioned a

00:31:36,409 --> 00:31:40,370
number of times so for anyone sitting in

00:31:38,480 --> 00:31:42,140
those workshops this week that's the

00:31:40,370 --> 00:31:43,850
exact same set of bits that we're

00:31:42,140 --> 00:31:45,140
deploying up here right so we're

00:31:43,850 --> 00:31:47,680
consuming all the same stuff we're

00:31:45,140 --> 00:31:51,010
talking about this week here

00:31:47,680 --> 00:31:53,290
all right and that is all I have for

00:31:51,010 --> 00:31:54,910
slides and demo so we finished like

00:31:53,290 --> 00:31:57,480
perfectly for questions if there are

00:31:54,910 --> 00:31:57,480
more questions

00:32:00,880 --> 00:32:04,350
oh you have a mic

00:32:04,600 --> 00:32:08,090
[Music]

00:32:06,590 --> 00:32:10,480
it was that I could put here the

00:32:08,090 --> 00:32:10,480
question

00:32:11,190 --> 00:32:16,770
oh well I mean OpenStack is as a

00:32:14,940 --> 00:32:19,140
virtualized environment with KBM and

00:32:16,770 --> 00:32:21,170
it's you run VMs on top of it

00:32:19,140 --> 00:32:23,580
openshift is kubernetes environment

00:32:21,170 --> 00:32:25,740
which runs containers and we run

00:32:23,580 --> 00:32:28,830
actually the open shift on top OpenStack

00:32:25,740 --> 00:32:32,880
and and data hub on top of OpenShift on

00:32:28,830 --> 00:32:36,079
top of open stack on top of hardware

00:32:32,880 --> 00:32:36,079
[Music]

00:32:36,299 --> 00:32:39,349
any other questions

00:32:39,850 --> 00:32:44,520
no great oh yes

00:32:44,800 --> 00:32:48,630
[Music]

00:32:46,120 --> 00:32:48,630
Billy

00:32:52,320 --> 00:33:00,740
[Music]

00:33:08,310 --> 00:33:14,400
correct but we're gonna buy having this

00:33:12,300 --> 00:33:15,960
here right instead of it

00:33:14,400 --> 00:33:17,790
Red Hat only gave the experience of

00:33:15,960 --> 00:33:19,500
their eternal users the hub conducts

00:33:17,790 --> 00:33:21,330
appearance from a whole bunch of outside

00:33:19,500 --> 00:33:23,790
users using this some ways they didn't

00:33:21,330 --> 00:33:25,350
envision which will be a lot better for

00:33:23,790 --> 00:33:28,080
companies later on deploying that

00:33:25,350 --> 00:33:29,460
because you know the project will be and

00:33:28,080 --> 00:33:31,200
I don't want understate that point like

00:33:29,460 --> 00:33:32,940
I don't know how many folks in here like

00:33:31,200 --> 00:33:34,590
work in operations RIT where you've

00:33:32,940 --> 00:33:36,720
tried to stand one of these platforms of

00:33:34,590 --> 00:33:38,820
service up for your users and have gone

00:33:36,720 --> 00:33:40,830
through the the growing pains that come

00:33:38,820 --> 00:33:43,650
along with that I mean the the data hub

00:33:40,830 --> 00:33:45,480
that you just saw demoed is not at all

00:33:43,650 --> 00:33:47,130
like what the data hub looked like a

00:33:45,480 --> 00:33:48,720
year and a half ago and we first started

00:33:47,130 --> 00:33:50,700
standing this up internally there is a

00:33:48,720 --> 00:33:54,030
lot involved a lot of learning that goes

00:33:50,700 --> 00:33:55,380
into it so to think you certainly could

00:33:54,030 --> 00:33:57,120
just take it and do it but it really

00:33:55,380 --> 00:33:58,650
does come from the benefit of the masses

00:33:57,120 --> 00:34:00,810
of people contributing to it to help

00:33:58,650 --> 00:34:02,820
harden it make it more scalable make it

00:34:00,810 --> 00:34:04,680
reliable and start to work toward like

00:34:02,820 --> 00:34:06,750
even that self-healing model we're gonna

00:34:04,680 --> 00:34:08,669
be deploying the AI library that Daniel

00:34:06,750 --> 00:34:10,980
referenced in here as well so there's

00:34:08,669 --> 00:34:12,510
gonna be a set of pre-configured models

00:34:10,980 --> 00:34:13,800
that you can just download and they'll

00:34:12,510 --> 00:34:16,350
be available for you to start calling

00:34:13,800 --> 00:34:17,610
into so there's all of that's going to

00:34:16,350 --> 00:34:20,220
be in here and that all benefits from

00:34:17,610 --> 00:34:21,780
the open source community approach so so

00:34:20,220 --> 00:34:24,179
just to go back to what I said the very

00:34:21,780 --> 00:34:26,100
beginning I mean open source we've all

00:34:24,179 --> 00:34:28,020
been a part of that community of these

00:34:26,100 --> 00:34:30,300
many of us have for many many years

00:34:28,020 --> 00:34:32,310
right but you know open source isn't

00:34:30,300 --> 00:34:33,330
enough anymore right the clubs are

00:34:32,310 --> 00:34:35,120
deploying a lot of open source software

00:34:33,330 --> 00:34:36,860
but the

00:34:35,120 --> 00:34:38,600
learnings of how to deploy these things

00:34:36,860 --> 00:34:40,520
and how to operate these things and the

00:34:38,600 --> 00:34:42,650
diversity of service is something which

00:34:40,520 --> 00:34:45,350
is actually locked into these clouds and

00:34:42,650 --> 00:34:46,730
what we're trying to do is being a model

00:34:45,350 --> 00:34:48,230
where we can actually start offering

00:34:46,730 --> 00:34:49,700
these since it's scale the open source

00:34:48,230 --> 00:34:52,220
community operating limited scale and

00:34:49,700 --> 00:34:54,200
have with real users so that both we can

00:34:52,220 --> 00:34:56,570
replicate them to other you know

00:34:54,200 --> 00:34:59,390
regional data centers and even back to

00:34:56,570 --> 00:35:01,070
the enterprise and without that you know

00:34:59,390 --> 00:35:02,330
these clouds are gonna be the way we

00:35:01,070 --> 00:35:03,380
locked ourselves into the big

00:35:02,330 --> 00:35:06,439
proprietary clouds

00:35:03,380 --> 00:35:06,439
[Music]

00:35:06,480 --> 00:35:10,820
all right oh well thank you

00:35:19,370 --> 00:35:29,569
[Music]

00:35:26,190 --> 00:35:29,569

YouTube URL: https://www.youtube.com/watch?v=iUJ6RGfY0JQ


