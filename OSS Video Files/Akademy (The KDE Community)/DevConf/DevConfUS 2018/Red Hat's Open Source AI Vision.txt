Title: Red Hat's Open Source AI Vision
Publication date: 2019-02-21
Playlist: DevConfUS 2018
Description: 
	Analytics, Machine Learning, and AI represent a fundamental transformation that over the coming decade will affect every aspect of society, business and industry. It will fundamentally change, how we interact with Computers - and how we develop, maintain, and operate systems. It's impact will be visible in our part of the universe much sooner than for the analog world. This deeply affects both Open Source in general, as well as Red Hat, its ecosystem and customer base.

This talk will provide a perspective on Red Hat's thinking around AI in the broadest sense.
Captions: 
	00:00:03,780 --> 00:00:06,960
[Music]

00:00:07,700 --> 00:00:14,450
so I apologize for the delay

00:00:09,960 --> 00:00:17,100
thank you for coming as I said we are

00:00:14,450 --> 00:00:20,820
still figuring out the video streaming

00:00:17,100 --> 00:00:23,010
and that took some precedence my name is

00:00:20,820 --> 00:00:26,520
Daniel reek I work in the office of the

00:00:23,010 --> 00:00:28,230
CTO at ratted on the topic of AI running

00:00:26,520 --> 00:00:30,119
the artificial intelligence center of

00:00:28,230 --> 00:00:38,260
excellence at ratted are we talking

00:00:30,119 --> 00:00:43,149
about our open source AI vision

00:00:38,260 --> 00:00:46,020
[Music]

00:00:43,149 --> 00:00:46,020
if I can

00:00:48,760 --> 00:00:59,920
[Music]

00:00:57,940 --> 00:01:10,060
all right so what are we talking about

00:00:59,920 --> 00:01:11,740
here great now it works so what are we

00:01:10,060 --> 00:01:15,130
talking about a I I'll use a is a

00:01:11,740 --> 00:01:19,510
shorthand for the whole broad sense of

00:01:15,130 --> 00:01:23,020
the buzzword big data analytics machine

00:01:19,510 --> 00:01:24,580
learning cognitive systems we've talked

00:01:23,020 --> 00:01:27,630
primarily about machine learning but

00:01:24,580 --> 00:01:33,850
I'll just simply fight by calling it AI

00:01:27,630 --> 00:01:37,180
overall so we see AI in red as one of

00:01:33,850 --> 00:01:38,410
the biggest changes in industry probably

00:01:37,180 --> 00:01:43,590
the biggest change since the Industrial

00:01:38,410 --> 00:01:47,229
Revolution because we are we see a new

00:01:43,590 --> 00:01:54,160
way of automation coming with it

00:01:47,229 --> 00:01:56,649
specifically applies to IT itself the

00:01:54,160 --> 00:01:59,289
keys that every human task will be

00:01:56,649 --> 00:02:02,740
automated you can describe input to

00:01:59,289 --> 00:02:04,450
output in a probabilistic way and you're

00:02:02,740 --> 00:02:06,369
specific in the software industry what

00:02:04,450 --> 00:02:09,280
that means is that you're moving from

00:02:06,369 --> 00:02:11,980
humans understanding data and

00:02:09,280 --> 00:02:15,069
relationships and then encoding their

00:02:11,980 --> 00:02:18,180
conclusions in code to machine learning

00:02:15,069 --> 00:02:20,560
models learning from the data and

00:02:18,180 --> 00:02:22,390
autonomously coming to conclusions so

00:02:20,560 --> 00:02:26,140
you're taking the might they stood

00:02:22,390 --> 00:02:30,069
humans involved in defining the models

00:02:26,140 --> 00:02:32,260
or getting the data you know at least in

00:02:30,069 --> 00:02:35,400
the initial data engineering setting it

00:02:32,260 --> 00:02:37,920
up but the decisions it

00:02:35,400 --> 00:02:40,610
deriving decisions from the data itself

00:02:37,920 --> 00:02:43,409
is something that the software does

00:02:40,610 --> 00:02:46,590
autonomously and even in areas where you

00:02:43,409 --> 00:02:50,489
still so we call the dynamic an example

00:02:46,590 --> 00:02:51,989
with dynamic rules model and what you

00:02:50,489 --> 00:02:54,450
might not want to do that everywhere

00:02:51,989 --> 00:02:57,110
right we will see that in many areas we

00:02:54,450 --> 00:02:59,280
already see that in many areas today

00:02:57,110 --> 00:03:01,530
even if you don't want to do that

00:02:59,280 --> 00:03:03,989
because you need an audit will be a very

00:03:01,530 --> 00:03:07,769
strict rule system what we are seeing

00:03:03,989 --> 00:03:11,459
this that the rule development itself is

00:03:07,769 --> 00:03:14,000
employing AI technologies to make sense

00:03:11,459 --> 00:03:16,290
of the data so even if there are humans

00:03:14,000 --> 00:03:19,709
writing the routes often they will use

00:03:16,290 --> 00:03:21,329
AI tools to you know make sense of data

00:03:19,709 --> 00:03:23,640
to the data engineering which is data

00:03:21,329 --> 00:03:26,459
analysis so we see a lot of AI being

00:03:23,640 --> 00:03:27,840
used in many things that computers to in

00:03:26,459 --> 00:03:31,230
automation and we'll go into some

00:03:27,840 --> 00:03:32,879
examples of that so it's it's this

00:03:31,230 --> 00:03:36,019
transformation changes how we interact

00:03:32,879 --> 00:03:38,640
with software changes the role of

00:03:36,019 --> 00:03:47,730
software itself of code itself and the

00:03:38,640 --> 00:03:51,180
role of the data science and its overall

00:03:47,730 --> 00:03:52,680
what we see we have a name for these

00:03:51,180 --> 00:03:55,379
kind of applications we call them

00:03:52,680 --> 00:03:57,720
intelligent applications so applications

00:03:55,379 --> 00:04:04,440
that you ultimately collect and learn

00:03:57,720 --> 00:04:07,199
from data and typically gather more data

00:04:04,440 --> 00:04:09,989
when you use them right that's what you

00:04:07,199 --> 00:04:13,919
you have a couple of common exams that

00:04:09,989 --> 00:04:17,190
all of us use today it's how we use AI

00:04:13,919 --> 00:04:19,620
and ml today throughout the software

00:04:17,190 --> 00:04:23,370
industry and all the industries the use

00:04:19,620 --> 00:04:25,190
of the software bound which is most most

00:04:23,370 --> 00:04:29,680
industry so being from Bank

00:04:25,190 --> 00:04:32,360
through you know anything with security

00:04:29,680 --> 00:04:35,510
automation production automation all of

00:04:32,360 --> 00:04:37,840
that and well interestingly is that most

00:04:35,510 --> 00:04:41,780
of the big advances recently in

00:04:37,840 --> 00:04:44,440
artificial intelligence are based on a

00:04:41,780 --> 00:04:47,180
use case a business use case driven

00:04:44,440 --> 00:04:48,860
application of AI and the combination of

00:04:47,180 --> 00:04:51,110
the compute power we have with the

00:04:48,860 --> 00:04:53,960
availability of real life data and a

00:04:51,110 --> 00:04:57,080
couple of examples where big big

00:04:53,960 --> 00:04:59,260
advances have been made like we all knew

00:04:57,080 --> 00:05:02,540
it was well understood that you could do

00:04:59,260 --> 00:05:04,970
handwriting recognition but it became

00:05:02,540 --> 00:05:09,290
really pretty usable when the post

00:05:04,970 --> 00:05:11,750
office provided data to researchers yeah

00:05:09,290 --> 00:05:14,480
that's large amounts of data to solve

00:05:11,750 --> 00:05:17,750
their problem of the letter address

00:05:14,480 --> 00:05:19,250
recognition and then it was solved and

00:05:17,750 --> 00:05:21,140
we all know like all these ratings

00:05:19,250 --> 00:05:22,880
systems right they are they are they're

00:05:21,140 --> 00:05:25,130
machine learning I wasn't behind that

00:05:22,880 --> 00:05:27,490
more and more and it's a lot of data

00:05:25,130 --> 00:05:31,580
image recognition is like as an example

00:05:27,490 --> 00:05:32,990
where it was in principle was it was

00:05:31,580 --> 00:05:35,390
well understood that it could be done

00:05:32,990 --> 00:05:38,540
right we suddenly had to compute power

00:05:35,390 --> 00:05:40,760
to do it in the last five years five to

00:05:38,540 --> 00:05:42,919
eight years and then the data became

00:05:40,760 --> 00:05:44,780
available and was made available and it

00:05:42,919 --> 00:05:46,580
was driven by business use case was a

00:05:44,780 --> 00:05:49,520
speculative application of the

00:05:46,580 --> 00:05:51,890
understood theoretical capabilities that

00:05:49,520 --> 00:05:53,960
got us to where we are today and you

00:05:51,890 --> 00:05:56,210
have to in that light see things like

00:05:53,960 --> 00:05:58,040
when when Amazon offers a service like

00:05:56,210 --> 00:06:00,020
recognition which is a facial

00:05:58,040 --> 00:06:01,820
recognition service that you can use

00:06:00,020 --> 00:06:04,280
they provide that ready to use and

00:06:01,820 --> 00:06:06,020
they're going to towns and police

00:06:04,280 --> 00:06:08,450
departments and trying to get them to

00:06:06,020 --> 00:06:12,530
connect their surveillance cameras to

00:06:08,450 --> 00:06:14,630
that facial recognition system like so

00:06:12,530 --> 00:06:17,600
they provide a free service and they get

00:06:14,630 --> 00:06:20,000
free training data back and that's it

00:06:17,600 --> 00:06:23,080
was a dynamic that's driving the

00:06:20,000 --> 00:06:28,520
advancement of technology here

00:06:23,080 --> 00:06:30,830
and it's you can't it's incredible how

00:06:28,520 --> 00:06:33,470
fast this is moving right now how fast

00:06:30,830 --> 00:06:35,900
new applications are what the boundaries

00:06:33,470 --> 00:06:39,620
are pushed algorithm or train models get

00:06:35,900 --> 00:06:43,700
better we see this right now in in the

00:06:39,620 --> 00:06:45,350
continuum of like the recent changes of

00:06:43,700 --> 00:06:49,400
the industry from a hardware centric

00:06:45,350 --> 00:06:53,210
model we went to it's about the software

00:06:49,400 --> 00:06:56,600
right software eating the world to cloud

00:06:53,210 --> 00:06:59,720
native and then from cloud native we are

00:06:56,600 --> 00:07:01,730
going to data root the world in

00:06:59,720 --> 00:07:05,830
important point here is that when you

00:07:01,730 --> 00:07:08,420
look at AI right so some code models

00:07:05,830 --> 00:07:12,380
algorithms are really important but

00:07:08,420 --> 00:07:14,300
because it's all driven by the data no

00:07:12,380 --> 00:07:16,550
amount of algorithmic sophistication can

00:07:14,300 --> 00:07:19,700
overcome the lack of of data and data is

00:07:16,550 --> 00:07:23,650
at the end and equal in this to code now

00:07:19,700 --> 00:07:26,810
you now need two halves to make a

00:07:23,650 --> 00:07:29,300
program function if I write software

00:07:26,810 --> 00:07:31,820
let's say I use AI in my development

00:07:29,300 --> 00:07:36,610
process in a development process for an

00:07:31,820 --> 00:07:40,040
open source project right now I I need

00:07:36,610 --> 00:07:42,620
the training data and the code to make

00:07:40,040 --> 00:07:44,570
it functional and and so now we are not

00:07:42,620 --> 00:07:47,360
software eating the world it's it's it's

00:07:44,570 --> 00:07:50,510
a i eating software that's what we're

00:07:47,360 --> 00:07:52,460
seeing right now because everyone using

00:07:50,510 --> 00:07:54,410
everyone with a business use case where

00:07:52,460 --> 00:07:58,340
you have any kind of automation you have

00:07:54,410 --> 00:08:00,230
data and you can derive the the actions

00:07:58,340 --> 00:08:02,750
the software's to take probabilistically

00:08:00,230 --> 00:08:04,550
from the data you will see training

00:08:02,750 --> 00:08:07,220
models being used either indirectly or

00:08:04,550 --> 00:08:10,130
directly in in the user direction taking

00:08:07,220 --> 00:08:13,220
direct action an interesting aspect of

00:08:10,130 --> 00:08:15,740
opens a ice is that it's very open

00:08:13,220 --> 00:08:17,750
source friendly on the technology side

00:08:15,740 --> 00:08:19,580
most of the big things that people are

00:08:17,750 --> 00:08:21,650
using are available in open source

00:08:19,580 --> 00:08:23,900
most of the research even the leading

00:08:21,650 --> 00:08:29,030
companies in the space like Google

00:08:23,900 --> 00:08:33,400
Facebook Microsoft Tesla some others are

00:08:29,030 --> 00:08:36,680
publishing contributing to open source

00:08:33,400 --> 00:08:38,210
the problem is if you don't have the

00:08:36,680 --> 00:08:40,099
data that doesn't help you because the

00:08:38,210 --> 00:08:42,020
code is non-functional if you don't have

00:08:40,099 --> 00:08:43,310
two training data so that's an important

00:08:42,020 --> 00:08:44,540
aspect what we have to think about what

00:08:43,310 --> 00:08:46,460
does it mean for them sauce

00:08:44,540 --> 00:08:49,730
right what does it mean for example from

00:08:46,460 --> 00:08:51,740
a copyleft point of view if you are if

00:08:49,730 --> 00:08:54,290
you're publishing software but it's not

00:08:51,740 --> 00:08:56,120
functional then you are potentially in

00:08:54,290 --> 00:08:59,660
conflict at least with the spirit of

00:08:56,120 --> 00:09:02,960
copyleft license and we see right now

00:08:59,660 --> 00:09:06,260
that a lot of companies are willing to

00:09:02,960 --> 00:09:08,240
share as a code but they think they see

00:09:06,260 --> 00:09:10,880
the propriety differentiation in the

00:09:08,240 --> 00:09:14,030
data right that's a so what does it

00:09:10,880 --> 00:09:18,880
mean from a ratchet point of view so we

00:09:14,030 --> 00:09:21,620
invited CAI in like five perspective

00:09:18,880 --> 00:09:23,540
first it's of course a work load for a

00:09:21,620 --> 00:09:27,910
platform be an operating system platform

00:09:23,540 --> 00:09:31,010
company to large degree and AI being

00:09:27,910 --> 00:09:33,620
such a big transformation some things

00:09:31,010 --> 00:09:35,960
that every business has to has to do is

00:09:33,620 --> 00:09:38,690
dealing with of course we want to

00:09:35,960 --> 00:09:42,530
provide the best platform for that for

00:09:38,690 --> 00:09:45,560
that use case we also applying ai in our

00:09:42,530 --> 00:09:47,720
internal processes specifically in our

00:09:45,560 --> 00:09:49,580
software development process so a lot of

00:09:47,720 --> 00:09:53,390
the talks are going to see today are

00:09:49,580 --> 00:09:56,000
looking at how can we use AI for example

00:09:53,390 --> 00:09:59,570
to improve software quality by doing

00:09:56,000 --> 00:10:01,210
flake analysis or how can we use AI in

00:09:59,570 --> 00:10:04,150
systems operations

00:10:01,210 --> 00:10:09,010
you know you could say that there's a

00:10:04,150 --> 00:10:11,200
fancy very very fleshy use case like

00:10:09,010 --> 00:10:13,090
self-driving cars which has you know

00:10:11,200 --> 00:10:15,490
it's very interesting it's a big deal

00:10:13,090 --> 00:10:17,680
but you know it's also very hard because

00:10:15,490 --> 00:10:18,970
you know your challenge is interacting

00:10:17,680 --> 00:10:20,830
with the physical world and it really

00:10:18,970 --> 00:10:22,480
matters whether that white thing in

00:10:20,830 --> 00:10:25,120
front of you is a track cutting you off

00:10:22,480 --> 00:10:27,190
or our traffic sign right and like you

00:10:25,120 --> 00:10:29,950
know it got it wrong and the drive

00:10:27,190 --> 00:10:31,840
unfortunately died in that scenario all

00:10:29,950 --> 00:10:34,780
right so that's a really hard problem at

00:10:31,840 --> 00:10:37,840
the same time you know basically that

00:10:34,780 --> 00:10:39,940
car is the data center on wheels right

00:10:37,840 --> 00:10:41,830
like all this AI is running in the car

00:10:39,940 --> 00:10:44,230
and you probably don't want to admin

00:10:41,830 --> 00:10:46,180
into the trunk so you want the

00:10:44,230 --> 00:10:48,400
self-driving cluster to run your

00:10:46,180 --> 00:10:50,110
self-driving car and that's a

00:10:48,400 --> 00:10:51,790
low-hanging fruit because it's supposed

00:10:50,110 --> 00:10:53,230
to be your machine readable already

00:10:51,790 --> 00:10:55,180
right we're dealing about machine

00:10:53,230 --> 00:10:57,640
generated information interpreted by

00:10:55,180 --> 00:11:00,850
machines and then machines need to take

00:10:57,640 --> 00:11:03,460
action today if you're in automation and

00:11:00,850 --> 00:11:08,980
your systems automation you're doing

00:11:03,460 --> 00:11:11,680
anything in sre you're writing a lot of

00:11:08,980 --> 00:11:13,840
automation scripts a lot of what we are

00:11:11,680 --> 00:11:17,890
looking at with AI right now is how can

00:11:13,840 --> 00:11:21,040
we automate IT processes automation of

00:11:17,890 --> 00:11:24,660
computers how can we move from static

00:11:21,040 --> 00:11:27,550
heuristics to learned models in core

00:11:24,660 --> 00:11:29,800
into core products like you're busy in

00:11:27,550 --> 00:11:30,940
every device in Dantes are carnally

00:11:29,800 --> 00:11:33,610
eventually we're not there yet but

00:11:30,940 --> 00:11:36,070
that's gonna that's gonna happen and

00:11:33,610 --> 00:11:39,850
then you're in systems management lock

00:11:36,070 --> 00:11:43,240
analysis and interestingly a lot of the

00:11:39,850 --> 00:11:45,310
same the same algorithms that everyone

00:11:43,240 --> 00:11:47,870
else uses you can apply here right so so

00:11:45,310 --> 00:11:49,670
it's anomaly detection clustering

00:11:47,870 --> 00:11:55,550
you can use the same things that people

00:11:49,670 --> 00:11:57,920
in trading in finance are are doing so

00:11:55,550 --> 00:12:00,350
and like at this point like when we use

00:11:57,920 --> 00:12:02,600
AI internally of course like it's a salt

00:12:00,350 --> 00:12:05,450
we follow our open-source development

00:12:02,600 --> 00:12:09,680
model so it will be available to the

00:12:05,450 --> 00:12:11,510
community and in general but the

00:12:09,680 --> 00:12:13,220
customers don't necessarily know that

00:12:11,510 --> 00:12:15,800
we're using AI write the products are

00:12:13,220 --> 00:12:17,600
still the same y-you get you get your L

00:12:15,800 --> 00:12:20,750
subscrip you get your security fixes

00:12:17,600 --> 00:12:24,950
code quality should improve reactiveness

00:12:20,750 --> 00:12:26,690
should improve things like that but then

00:12:24,950 --> 00:12:28,850
you know we embed that actually in the

00:12:26,690 --> 00:12:30,800
product and we create services that are

00:12:28,850 --> 00:12:32,330
AI based at which point the customer

00:12:30,800 --> 00:12:35,270
actually becomes aware that they're

00:12:32,330 --> 00:12:38,060
being supported by AI an example is

00:12:35,270 --> 00:12:39,650
right at insights it's it's a predictive

00:12:38,060 --> 00:12:43,040
support service that looks at your

00:12:39,650 --> 00:12:45,980
system configuration and it will tell

00:12:43,040 --> 00:12:47,180
you if you're if you have problems

00:12:45,980 --> 00:12:48,950
they're the rules is there that

00:12:47,180 --> 00:12:51,380
human-generated their routes in there

00:12:48,950 --> 00:12:54,380
that are human generated with AI

00:12:51,380 --> 00:12:56,260
enablement and there are automatic

00:12:54,380 --> 00:12:58,400
decisions that happen based on AI

00:12:56,260 --> 00:13:01,580
something we demo'd addressed somewhat

00:12:58,400 --> 00:13:03,680
for example ways to look so it a grits

00:13:01,580 --> 00:13:07,790
data from customers right it reports

00:13:03,680 --> 00:13:10,340
your system status and what we demoed at

00:13:07,790 --> 00:13:12,560
that summit was that the system then

00:13:10,340 --> 00:13:14,600
looked at your configuration and your

00:13:12,560 --> 00:13:17,150
performance data versus all the other

00:13:14,600 --> 00:13:21,170
customers we see and the exam was a

00:13:17,150 --> 00:13:23,150
degraded performance in a cluster and a

00:13:21,170 --> 00:13:24,800
system to do your performance is out of

00:13:23,150 --> 00:13:26,600
bounds compared to everyone else you're

00:13:24,800 --> 00:13:28,850
an outlier and your configuration is an

00:13:26,600 --> 00:13:31,010
outlier why don't you change this and

00:13:28,850 --> 00:13:32,840
then your performance might get better

00:13:31,010 --> 00:13:34,490
and then we press the button it changes

00:13:32,840 --> 00:13:37,010
in the performance got better all right

00:13:34,490 --> 00:13:39,620
but it's basically using AI and the key

00:13:37,010 --> 00:13:41,720
here is that it's not fundamentally

00:13:39,620 --> 00:13:43,520
different from our support service today

00:13:41,720 --> 00:13:44,860
right you you know if if you have a

00:13:43,520 --> 00:13:47,470
problem

00:13:44,860 --> 00:13:48,850
in production you call redhead support

00:13:47,470 --> 00:13:50,350
and they have a lot of knowledge and

00:13:48,850 --> 00:13:51,670
they have our knowledge phase we're

00:13:50,350 --> 00:13:54,190
really good support people they know how

00:13:51,670 --> 00:13:56,860
to dye diagnose systems but we're trying

00:13:54,190 --> 00:13:59,500
to augment them with AI that can

00:13:56,860 --> 00:14:03,490
basically process more data at long more

00:13:59,500 --> 00:14:07,450
vectors more quickly and then give you a

00:14:03,490 --> 00:14:09,550
faster or even predictive before you

00:14:07,450 --> 00:14:11,380
call an answer - you have a problem

00:14:09,550 --> 00:14:14,050
there right it doesn't replace the human

00:14:11,380 --> 00:14:16,060
support but it gives you a lot of value

00:14:14,050 --> 00:14:17,589
before you have to escalate the human

00:14:16,060 --> 00:14:20,110
review support human support can focus

00:14:17,589 --> 00:14:22,779
on the real hard problems where you

00:14:20,110 --> 00:14:25,870
can't extrapolate from statistical input

00:14:22,779 --> 00:14:27,779
right things one example like a lot of

00:14:25,870 --> 00:14:29,829
this is basically herd immunity right

00:14:27,779 --> 00:14:31,240
we're gonna be able to predict the

00:14:29,829 --> 00:14:33,220
problems based on what we have seen

00:14:31,240 --> 00:14:34,660
before the things with that we haven't

00:14:33,220 --> 00:14:35,920
seen before that we still need human

00:14:34,660 --> 00:14:37,690
creativity to physically figure out

00:14:35,920 --> 00:14:39,399
what's really going on right but again

00:14:37,690 --> 00:14:43,779
we can augment them with a lot of

00:14:39,399 --> 00:14:45,459
content so so we'll basically put a I

00:14:43,779 --> 00:14:49,120
into the platform products themselves

00:14:45,459 --> 00:14:51,070
and in our support services to make new

00:14:49,120 --> 00:14:54,100
turn our platforms into intelligent

00:14:51,070 --> 00:14:58,410
platforms and then in the intelligent

00:14:54,100 --> 00:15:01,300
apps that we we are providing the same

00:14:58,410 --> 00:15:02,770
capabilities that we are using right we

00:15:01,300 --> 00:15:04,420
are running this on our own stack was

00:15:02,770 --> 00:15:07,149
our own tool chain we're working with

00:15:04,420 --> 00:15:08,470
our ecosystem the broader Corp and

00:15:07,149 --> 00:15:11,620
source community and the commercial

00:15:08,470 --> 00:15:13,690
ecosystem to create and to end AI

00:15:11,620 --> 00:15:15,550
solutions that we use to build this and

00:15:13,690 --> 00:15:17,170
we make them available to our customers

00:15:15,550 --> 00:15:19,029
so they can go and build their own

00:15:17,170 --> 00:15:23,380
intelligent applications to serve their

00:15:19,029 --> 00:15:26,230
customers so it so in in we are a user

00:15:23,380 --> 00:15:28,420
of AI and then become not event of AI in

00:15:26,230 --> 00:15:29,360
the sense of like an AI whenever we've

00:15:28,420 --> 00:15:31,699
come and

00:15:29,360 --> 00:15:34,819
by providing open source technologies

00:15:31,699 --> 00:15:36,679
that lets you build AI and all of that

00:15:34,819 --> 00:15:39,889
is based of the foundation of data right

00:15:36,679 --> 00:15:42,170
it says the recognition and the culture

00:15:39,889 --> 00:15:44,989
a culture shift from treating from being

00:15:42,170 --> 00:15:46,339
code centric which we are like most

00:15:44,989 --> 00:15:48,649
software companies and the open source

00:15:46,339 --> 00:15:50,689
community today it's all about code our

00:15:48,649 --> 00:15:52,730
values in the code that's our our

00:15:50,689 --> 00:15:55,670
mindset and that has to shift to treat

00:15:52,730 --> 00:15:59,989
data as an equal to code it's data and

00:15:55,670 --> 00:16:04,220
code going forward so what we're doing

00:15:59,989 --> 00:16:06,049
there is basically we're doing the usual

00:16:04,220 --> 00:16:08,119
things in enablement AI is an

00:16:06,049 --> 00:16:09,920
interesting topic because it's very hard

00:16:08,119 --> 00:16:11,629
we're about suddenly hardware

00:16:09,920 --> 00:16:13,449
performance matters again right in the

00:16:11,629 --> 00:16:15,889
cloud everything was about scale and

00:16:13,449 --> 00:16:18,110
individual vertical performance wasn't

00:16:15,889 --> 00:16:19,879
the key differentiator now it becomes a

00:16:18,110 --> 00:16:21,889
key differentiator again which is great

00:16:19,879 --> 00:16:24,670
for us because we have this in a

00:16:21,889 --> 00:16:27,439
hardware ableman capability and trend

00:16:24,670 --> 00:16:30,949
there's a lot of work to integrate

00:16:27,439 --> 00:16:33,769
because you know a high writes on the

00:16:30,949 --> 00:16:35,749
shoulders of clouds of micro services of

00:16:33,769 --> 00:16:38,660
containers and I'll talk a little bit

00:16:35,749 --> 00:16:40,220
more about how that looks in detail but

00:16:38,660 --> 00:16:42,829
so there's a lot of work going into

00:16:40,220 --> 00:16:45,709
integrating able in an ecosystem so

00:16:42,829 --> 00:16:52,100
things can work together right and we'll

00:16:45,709 --> 00:16:53,720
get we'll get to that we have now we

00:16:52,100 --> 00:16:56,179
have a talk later and I'll go a little

00:16:53,720 --> 00:16:57,589
bit more detail we have a project called

00:16:56,179 --> 00:17:00,799
the data hub which is basically a

00:16:57,589 --> 00:17:02,360
reference architecture for an end to end

00:17:00,799 --> 00:17:06,860
a high platform built on top of

00:17:02,360 --> 00:17:10,250
kubernetes and Kafka and s3 as a storage

00:17:06,860 --> 00:17:13,000
interface with SAS as the storage in the

00:17:10,250 --> 00:17:15,889
redhead world and we're actually

00:17:13,000 --> 00:17:17,510
operating that inside wretched and we're

00:17:15,889 --> 00:17:19,399
going to announce of operating it in the

00:17:17,510 --> 00:17:23,689
Massachusetts open cloud for the

00:17:19,399 --> 00:17:27,139
community as a project so a eyes

00:17:23,689 --> 00:17:29,389
workload you know as I said it's really

00:17:27,139 --> 00:17:29,790
interesting from a heart point of view

00:17:29,389 --> 00:17:34,770
you need

00:17:29,790 --> 00:17:36,780
to entrant enablement you need not only

00:17:34,770 --> 00:17:39,900
performance right you have depends if

00:17:36,780 --> 00:17:41,790
you want you need data security and and

00:17:39,900 --> 00:17:44,790
right a lot of because data becomes too

00:17:41,790 --> 00:17:47,790
important in DevOps we have figured out

00:17:44,790 --> 00:17:50,100
how to manage application like the code

00:17:47,790 --> 00:17:52,830
lifecycle management kubernetes based

00:17:50,100 --> 00:17:55,200
platforms containers are thriving now we

00:17:52,830 --> 00:17:57,780
have to figure out how to manage the

00:17:55,200 --> 00:18:01,200
data lifecycle because when you're

00:17:57,780 --> 00:18:04,200
training a model you want you need to

00:18:01,200 --> 00:18:05,850
keep the training data for completeness

00:18:04,200 --> 00:18:08,190
of your source code for reproducibility

00:18:05,850 --> 00:18:10,590
but you also need it for orders because

00:18:08,190 --> 00:18:15,480
the code on its own doesn't explain

00:18:10,590 --> 00:18:18,090
anymore what the software is doing so a

00:18:15,480 --> 00:18:19,920
lot of our customers that are regulated

00:18:18,090 --> 00:18:22,080
industries or have potential ability

00:18:19,920 --> 00:18:23,730
need to need order the ability for them

00:18:22,080 --> 00:18:25,650
it's really important to in the

00:18:23,730 --> 00:18:28,860
application lifecycle management also

00:18:25,650 --> 00:18:30,750
captures a training data things like

00:18:28,860 --> 00:18:36,750
that you need compliance when you train

00:18:30,750 --> 00:18:40,860
feeding data back for exam all of its

00:18:36,750 --> 00:18:42,840
data that that model inherits knowledge

00:18:40,860 --> 00:18:45,480
from the data so if there's confidential

00:18:42,840 --> 00:18:47,250
information in that data it potentially

00:18:45,480 --> 00:18:49,200
can end up in your model right it can be

00:18:47,250 --> 00:18:53,870
disclosed that way so you need proper

00:18:49,200 --> 00:18:55,740
separation of compliance and access

00:18:53,870 --> 00:18:57,630
consistent between data and trained

00:18:55,740 --> 00:19:00,570
models I know an example would be you

00:18:57,630 --> 00:19:04,500
have let's say you're trading stock

00:19:00,570 --> 00:19:06,570
trading company you have general data

00:19:04,500 --> 00:19:08,880
market data trainer model on and then

00:19:06,570 --> 00:19:10,860
you have customers specific data you for

00:19:08,880 --> 00:19:12,750
your large customers you want to provide

00:19:10,860 --> 00:19:15,120
customized models that are trained on

00:19:12,750 --> 00:19:18,600
their specific data and the behavior of

00:19:15,120 --> 00:19:20,940
their data that model will be considered

00:19:18,600 --> 00:19:22,500
proprietary information confidential by

00:19:20,940 --> 00:19:24,030
your customer they don't want you to

00:19:22,500 --> 00:19:26,700
share that with other customers because

00:19:24,030 --> 00:19:30,410
it might disclose aspects of their

00:19:26,700 --> 00:19:34,140
portfolio and so you need a very complex

00:19:30,410 --> 00:19:35,590
consistent compliance model to ensure

00:19:34,140 --> 00:19:38,860
that code

00:19:35,590 --> 00:19:40,629
the entanglement of data and code gets

00:19:38,860 --> 00:19:42,789
handled so they're really interesting

00:19:40,629 --> 00:19:46,360
problems that you have to manage

00:19:42,789 --> 00:19:48,850
throughout the whole stack on the

00:19:46,360 --> 00:19:52,749
hardware side quick announcement and

00:19:48,850 --> 00:19:57,639
it's a good example we we just an

00:19:52,749 --> 00:20:00,700
average of 310 start supporting device

00:19:57,639 --> 00:20:03,759
plugins which is all you need to get the

00:20:00,700 --> 00:20:06,190
GPUs and we right now for in video but

00:20:03,759 --> 00:20:10,450
it's it's the generic feature in

00:20:06,190 --> 00:20:13,360
kubernetes that lets you expose hardware

00:20:10,450 --> 00:20:17,519
capabilities to kubernetes or schedule a

00:20:13,360 --> 00:20:20,679
severe and also figures out how to make

00:20:17,519 --> 00:20:21,970
the right drivers available to your

00:20:20,679 --> 00:20:24,700
application which is a bit challenging

00:20:21,970 --> 00:20:26,470
in containers right you need to know

00:20:24,700 --> 00:20:28,600
which versions to drive isms a host to

00:20:26,470 --> 00:20:30,700
load the right version of the user space

00:20:28,600 --> 00:20:32,379
low-level user space so that's really

00:20:30,700 --> 00:20:36,340
important there's a block if you want to

00:20:32,379 --> 00:20:38,649
run machine learning performance for

00:20:36,340 --> 00:20:40,450
complex machine learning proceed this

00:20:38,649 --> 00:20:41,950
from most use case you need GPU

00:20:40,450 --> 00:20:43,840
offloading and that's possible now in

00:20:41,950 --> 00:20:46,360
kubernetes which is a big deal from our

00:20:43,840 --> 00:20:49,480
point of view because it gives you this

00:20:46,360 --> 00:20:53,830
ability to do the integrated life cycle

00:20:49,480 --> 00:20:56,889
in the death of smaadahl so on the

00:20:53,830 --> 00:20:58,629
course system we're looking at enabling

00:20:56,889 --> 00:21:00,429
AI in the course system so basically

00:20:58,629 --> 00:21:02,679
what that means is we're trying to train

00:21:00,429 --> 00:21:06,669
developers to look at learning instead

00:21:02,679 --> 00:21:08,409
of static curious heuristics that's a

00:21:06,669 --> 00:21:11,350
research area and i think we got to talk

00:21:08,409 --> 00:21:17,310
about that a little bit today or

00:21:11,350 --> 00:21:20,770
tomorrow so think of you know augmenting

00:21:17,310 --> 00:21:24,400
there was a scheduler a good example one

00:21:20,770 --> 00:21:26,620
thing that's being discussed is in

00:21:24,400 --> 00:21:30,640
communities you have a scheduler near a

00:21:26,620 --> 00:21:32,530
verde scheduler that will evacuate no it

00:21:30,640 --> 00:21:34,750
says they don't like if there's a

00:21:32,530 --> 00:21:36,280
performance issue or something right now

00:21:34,750 --> 00:21:37,540
they don't know about each other so you

00:21:36,280 --> 00:21:39,190
can have a situation where something

00:21:37,540 --> 00:21:42,040
gets D scheduled and then the scheduler

00:21:39,190 --> 00:21:44,140
puts it back on the same note perfect

00:21:42,040 --> 00:21:45,970
example where you can like you can apply

00:21:44,140 --> 00:21:48,250
statistical multiple you can also very

00:21:45,970 --> 00:21:52,000
quickly get benefits from learning

00:21:48,250 --> 00:21:55,360
models because they can factor in more

00:21:52,000 --> 00:21:57,520
vectors then like static rules can you

00:21:55,360 --> 00:21:59,320
can have schedulers that focus amble

00:21:57,520 --> 00:22:00,670
learns from the behavior of the d

00:21:59,320 --> 00:22:03,040
scheduler it's a pretty low hanging

00:22:00,670 --> 00:22:05,260
fruit pretty straightforward idea that

00:22:03,040 --> 00:22:08,260
will we think will improve system

00:22:05,260 --> 00:22:10,660
performance significantly over time and

00:22:08,260 --> 00:22:14,250
so that's where we would move from

00:22:10,660 --> 00:22:17,520
static heuristics to a learn model

00:22:14,250 --> 00:22:22,740
[Music]

00:22:17,520 --> 00:22:27,690
another another aspect is is AI ops and

00:22:22,740 --> 00:22:31,770
AR def we're just complexity complexity

00:22:27,690 --> 00:22:33,690
grows so much example would be flake

00:22:31,770 --> 00:22:38,279
analysis right if you're running if

00:22:33,690 --> 00:22:40,230
you're running a DevOps CI CD system you

00:22:38,279 --> 00:22:43,350
have a lot of tests what happens is that

00:22:40,230 --> 00:22:45,510
in in many cases you'll see failure and

00:22:43,350 --> 00:22:48,029
next time the test is run it goes green

00:22:45,510 --> 00:22:49,919
again it works right and most developers

00:22:48,029 --> 00:22:51,390
will just call that a flake it's a test

00:22:49,919 --> 00:22:53,429
like it's something in the system was

00:22:51,390 --> 00:22:55,500
the test was broken so let's move on

00:22:53,429 --> 00:22:57,980
because it's working again now there are

00:22:55,500 --> 00:23:01,620
situations where these are actually not

00:22:57,980 --> 00:23:03,059
flakes not one offs it's just via

00:23:01,620 --> 00:23:07,080
failure of the system it could be a hard

00:23:03,059 --> 00:23:09,750
to deep sitting problem in your code

00:23:07,080 --> 00:23:11,610
that just only happens on a full moon

00:23:09,750 --> 00:23:14,250
you know if someone at midnight if

00:23:11,610 --> 00:23:20,100
someone you know torture the black cat

00:23:14,250 --> 00:23:25,080
on a graveyard not endorsing that I like

00:23:20,100 --> 00:23:26,850
black cats but situations that are

00:23:25,080 --> 00:23:28,850
really hard for humans to reproduce

00:23:26,850 --> 00:23:33,000
because they depend on these complex

00:23:28,850 --> 00:23:36,570
intersections of of data streams and

00:23:33,000 --> 00:23:37,350
system failures in complex micro service

00:23:36,570 --> 00:23:40,409
systems and the underlying

00:23:37,350 --> 00:23:43,740
infrastructure with AI we are able to

00:23:40,409 --> 00:23:46,440
process more of these vectors and see if

00:23:43,740 --> 00:23:49,169
there are if there's a clustering right

00:23:46,440 --> 00:23:52,200
so the same thing happens and somewhere

00:23:49,169 --> 00:23:56,510
deep in this vector of inputs you see a

00:23:52,200 --> 00:23:59,940
clustering of of situations that like

00:23:56,510 --> 00:24:01,440
coincide with with these failures and it

00:23:59,940 --> 00:24:03,899
will tell you oh they're not actually

00:24:01,440 --> 00:24:07,000
flakes because you know there is it's

00:24:03,899 --> 00:24:09,250
it's really it's a full moon right and

00:24:07,000 --> 00:24:11,289
the law tells you oh it was a full moon

00:24:09,250 --> 00:24:12,940
every time this happened and then we can

00:24:11,289 --> 00:24:15,730
inform the developers they all here is

00:24:12,940 --> 00:24:19,539
this is actually a problem in your code

00:24:15,730 --> 00:24:23,049
right it has it has a problem in the in

00:24:19,539 --> 00:24:25,480
the moon cycle algorithms right and and

00:24:23,049 --> 00:24:30,760
it like goes off and does something

00:24:25,480 --> 00:24:40,030
stupid so we're helping deal with

00:24:30,760 --> 00:24:41,860
complexity in intelligence application

00:24:40,030 --> 00:24:44,380
space what we're doing from malli right

00:24:41,860 --> 00:24:47,620
now is integration work integrating

00:24:44,380 --> 00:24:50,340
existing Retta program and projects as

00:24:47,620 --> 00:24:52,990
well as community project nice vs the

00:24:50,340 --> 00:24:56,140
website called red analytics ILO where

00:24:52,990 --> 00:25:03,419
you can find some inputs some pointers

00:24:56,140 --> 00:25:06,039
to what we're doing there you know

00:25:03,419 --> 00:25:09,240
example where we are doing some work

00:25:06,039 --> 00:25:12,010
today is for business process automation

00:25:09,240 --> 00:25:14,530
so there's the idea of robotic process

00:25:12,010 --> 00:25:17,260
automation is kind of see oh I'll learn

00:25:14,530 --> 00:25:19,809
what the humans do is doing and I'll

00:25:17,260 --> 00:25:22,120
repeat it but we're trying to help with

00:25:19,809 --> 00:25:23,740
music and you can put artificial

00:25:22,120 --> 00:25:27,520
intelligence into business process

00:25:23,740 --> 00:25:30,460
automation to enable that we think

00:25:27,520 --> 00:25:33,059
that's a valuable target I talked about

00:25:30,460 --> 00:25:33,059
date already

00:25:35,070 --> 00:25:47,910
one of the key things we are seeing is

00:25:39,240 --> 00:25:50,340
in the change in mindset and in that

00:25:47,910 --> 00:25:52,620
conduct right we if you want to change

00:25:50,340 --> 00:25:55,110
the mindset and you want to give people

00:25:52,620 --> 00:25:57,570
the ability to for example put like

00:25:55,110 --> 00:26:00,540
three data like code you need to figure

00:25:57,570 --> 00:26:04,400
out a way how to how to manage that and

00:26:00,540 --> 00:26:06,990
you need to find a way how to give them

00:26:04,400 --> 00:26:09,000
it gives them tooling and workflows

00:26:06,990 --> 00:26:11,220
which today don't exist right this is no

00:26:09,000 --> 00:26:12,690
new there's a lot of a lot of startups

00:26:11,220 --> 00:26:15,750
in the space a lot of projects in the

00:26:12,690 --> 00:26:19,470
space but there is no common workflow so

00:26:15,750 --> 00:26:23,310
we are putting up the data hub it's open

00:26:19,470 --> 00:26:26,370
data have i/o as a project to incubate

00:26:23,310 --> 00:26:27,780
and integrate technologies to get to an

00:26:26,370 --> 00:26:29,970
end-to-end solution that's completely

00:26:27,780 --> 00:26:31,980
open source and we're gonna operate that

00:26:29,970 --> 00:26:34,320
for the community to give you a place to

00:26:31,980 --> 00:26:36,420
experiment that to put data to also

00:26:34,320 --> 00:26:39,240
exchange data in the open source

00:26:36,420 --> 00:26:44,550
community so we can start seriously

00:26:39,240 --> 00:26:46,200
putting AI into open source projects the

00:26:44,550 --> 00:26:49,520
problem we are trying to solve here is

00:26:46,200 --> 00:26:52,950
the complexity threshold right because

00:26:49,520 --> 00:26:54,540
so you know you could say oh everyone

00:26:52,950 --> 00:26:57,360
can just get like all the code is open

00:26:54,540 --> 00:27:00,930
source so I get a lot of AI tools put

00:26:57,360 --> 00:27:03,360
them together and then I'll use my data

00:27:00,930 --> 00:27:06,330
the problem is that you know in order to

00:27:03,360 --> 00:27:10,230
do that you have to run very complex

00:27:06,330 --> 00:27:12,950
stack so you know if I want to just use

00:27:10,230 --> 00:27:12,950
AI

00:27:13,010 --> 00:27:18,590
I probably don't want to put up the

00:27:16,370 --> 00:27:21,470
underlying infrastructure figure out how

00:27:18,590 --> 00:27:24,320
to manage the GPU hardware things like

00:27:21,470 --> 00:27:29,600
that so it's it's a pretty high

00:27:24,320 --> 00:27:32,299
threshold to quickly put up a build

00:27:29,600 --> 00:27:34,640
service and application platform for AI

00:27:32,299 --> 00:27:36,290
right so it's very easy to just put up a

00:27:34,640 --> 00:27:38,330
Jupiter notebook on your laptop and do

00:27:36,290 --> 00:27:40,880
it once but if you want to run an extra

00:27:38,330 --> 00:27:43,130
project on it you run into this and this

00:27:40,880 --> 00:27:45,290
is just to show the complex is just a

00:27:43,130 --> 00:27:47,840
simplified view of our internal stacks

00:27:45,290 --> 00:27:51,950
that we are running to do AI experiments

00:27:47,840 --> 00:27:56,000
and putting all of that together for an

00:27:51,950 --> 00:27:58,490
open source project is probably not you

00:27:56,000 --> 00:27:59,960
know it it's interesting but it's not

00:27:58,490 --> 00:28:02,720
what you want to do if you want to like

00:27:59,960 --> 00:28:06,290
be like up there in the in the top and

00:28:02,720 --> 00:28:08,059
define research AI models or you know

00:28:06,290 --> 00:28:11,360
maybe you just want to apply some well

00:28:08,059 --> 00:28:12,950
understood like anomaly detection only

00:28:11,360 --> 00:28:17,020
say I'm home assistance the home

00:28:12,950 --> 00:28:17,020
assistant project and I want to put in

00:28:17,350 --> 00:28:23,299
kind of nests like an open source

00:28:20,150 --> 00:28:26,450
alternative to nests and learns my users

00:28:23,299 --> 00:28:28,309
behavior with a climate Ava HVAC control

00:28:26,450 --> 00:28:31,309
in the home on to open source home

00:28:28,309 --> 00:28:33,650
automation right do you want to have to

00:28:31,309 --> 00:28:35,990
put all of that up no so rather we were

00:28:33,650 --> 00:28:39,049
trying to provide this as an open source

00:28:35,990 --> 00:28:45,460
platform the project's can use to

00:28:39,049 --> 00:28:49,429
develop in that space so the promise of

00:28:45,460 --> 00:28:52,400
going there quickly so the problem we

00:28:49,429 --> 00:28:54,620
have is right now that ever just goes to

00:28:52,400 --> 00:29:00,440
the cloud right because they they they

00:28:54,620 --> 00:29:02,299
overcome the threshold right Amazon sage

00:29:00,440 --> 00:29:03,710
maker is awesome right it gives you

00:29:02,299 --> 00:29:05,850
everything you need if you just want to

00:29:03,710 --> 00:29:08,640
do an AI experiment you can

00:29:05,850 --> 00:29:11,100
your data they're like it's you'll give

00:29:08,640 --> 00:29:13,289
give it up but you can even put data

00:29:11,100 --> 00:29:14,760
there and share it with the world but

00:29:13,289 --> 00:29:17,340
the problem is that at the end that's a

00:29:14,760 --> 00:29:19,799
black box it's a they reinvented the

00:29:17,340 --> 00:29:22,200
mainframe right you're running black box

00:29:19,799 --> 00:29:25,049
services on the hardware and you have

00:29:22,200 --> 00:29:27,570
very limited reproducibility right you

00:29:25,049 --> 00:29:29,340
don't know what they're doing it's the

00:29:27,570 --> 00:29:31,320
service abstraction is awesome because

00:29:29,340 --> 00:29:33,059
you don't have to learn how to do it but

00:29:31,320 --> 00:29:34,770
you will not be able to actually do it

00:29:33,059 --> 00:29:37,049
on your own which for open sources was a

00:29:34,770 --> 00:29:39,750
problem for the reasons I talked about

00:29:37,049 --> 00:29:40,890
earlier so you know our it's a risk yes

00:29:39,750 --> 00:29:44,159
and that's a start

00:29:40,890 --> 00:29:49,740
you know the risk is that we are

00:29:44,159 --> 00:29:52,740
starving open source if we go and follow

00:29:49,740 --> 00:29:55,799
the black box service abstraction model

00:29:52,740 --> 00:29:59,220
and so we want to enable open source to

00:29:55,799 --> 00:30:02,730
basically run this with a commitment to

00:29:59,220 --> 00:30:05,100
have full transparency on the code and

00:30:02,730 --> 00:30:07,200
on the data that's used in open source

00:30:05,100 --> 00:30:08,640
development and the place to do that

00:30:07,200 --> 00:30:08,940
without having to do everything on your

00:30:08,640 --> 00:30:10,919
own

00:30:08,940 --> 00:30:11,960
that's what we are trying to incubate

00:30:10,919 --> 00:30:14,040
with the data

00:30:11,960 --> 00:30:17,990
[Music]

00:30:14,040 --> 00:30:20,370
where do we expect reuse and a Galgo

00:30:17,990 --> 00:30:22,350
bottom to the top right so if you know

00:30:20,370 --> 00:30:24,930
it's a bottom tier it was that flat for

00:30:22,350 --> 00:30:27,750
microfiber like they are building and

00:30:24,930 --> 00:30:31,550
running containers Jenkins pipelines

00:30:27,750 --> 00:30:34,800
Kafka as a streaming access control

00:30:31,550 --> 00:30:37,860
policy the goal of that right now

00:30:34,800 --> 00:30:41,370
everyone who is doing AI platforms this

00:30:37,860 --> 00:30:45,450
building's the same thing I mean you you

00:30:41,370 --> 00:30:50,520
can modern so and back in the days it

00:30:45,450 --> 00:30:53,130
was just recently the standard was like

00:30:50,520 --> 00:30:56,400
a Hadoop model where data analytics was

00:30:53,130 --> 00:30:58,320
a special case standalone cluster we are

00:30:56,400 --> 00:31:00,120
moving very quickly to converge the

00:30:58,320 --> 00:31:02,310
application platform because everything

00:31:00,120 --> 00:31:04,070
is a I base right all applications are

00:31:02,310 --> 00:31:07,230
intelligent applications going forward

00:31:04,070 --> 00:31:08,220
so we never convert flat form which

00:31:07,230 --> 00:31:10,890
means that you're running your

00:31:08,220 --> 00:31:13,320
applications and your data analytics in

00:31:10,890 --> 00:31:15,420
the same cluster kubernetes has already

00:31:13,320 --> 00:31:17,940
established itself as a default solution

00:31:15,420 --> 00:31:19,490
for that use case so most people who are

00:31:17,940 --> 00:31:22,740
doing this are doing it with kubernetes

00:31:19,490 --> 00:31:26,250
Kafka is the data transport s3 support

00:31:22,740 --> 00:31:27,750
for data protocol for data address SPARC

00:31:26,250 --> 00:31:30,690
is pretty common so they're they're

00:31:27,750 --> 00:31:34,410
really common things that everyone is

00:31:30,690 --> 00:31:35,880
doing in that space and we expect a lot

00:31:34,410 --> 00:31:38,400
of collaboration of like integrating

00:31:35,880 --> 00:31:42,090
that creating operators to make this

00:31:38,400 --> 00:31:44,340
easy to run on kubernetes a lot of

00:31:42,090 --> 00:31:46,500
standardization to standard products in

00:31:44,340 --> 00:31:53,430
the space

00:31:46,500 --> 00:31:56,820
the second tier is well understood

00:31:53,430 --> 00:32:02,700
AI functions like anomaly detection I'm

00:31:56,820 --> 00:32:06,600
like clustering where we think you can

00:32:02,700 --> 00:32:08,550
actually pre 10 models generically

00:32:06,600 --> 00:32:12,660
enough so they're useful for many people

00:32:08,550 --> 00:32:14,580
so we will could have a predefined

00:32:12,660 --> 00:32:17,610
library of AI functions that you can

00:32:14,580 --> 00:32:19,530
directly connect to you can still take

00:32:17,610 --> 00:32:23,100
the model and train it further for your

00:32:19,530 --> 00:32:24,780
own purposes or or retrain it completely

00:32:23,100 --> 00:32:26,400
but they're gonna be pre trained model

00:32:24,780 --> 00:32:28,230
and we see a lot of interest even in the

00:32:26,400 --> 00:32:30,750
industry to collaborate on some of that

00:32:28,230 --> 00:32:33,360
and then one level up you have the extra

00:32:30,750 --> 00:32:36,480
business use case where you aggregate

00:32:33,360 --> 00:32:38,520
different models into an actual customer

00:32:36,480 --> 00:32:40,770
function that's where people usually

00:32:38,520 --> 00:32:42,750
cease their their differentiation right

00:32:40,770 --> 00:32:45,990
an example would be fraud detection if

00:32:42,750 --> 00:32:47,670
you're in the financial business if

00:32:45,990 --> 00:32:49,260
you're a big bank you have your own

00:32:47,670 --> 00:32:50,850
fault detection service and you're gonna

00:32:49,260 --> 00:32:53,160
you're gonna treat that as a trade

00:32:50,850 --> 00:32:55,050
secret as a differentiator if you're a

00:32:53,160 --> 00:32:56,910
small bank you're probably contracting

00:32:55,050 --> 00:32:59,340
in external service that does it for you

00:32:56,910 --> 00:33:03,780
but they will treated the model itself

00:32:59,340 --> 00:33:06,300
and to date data as a trade secret so we

00:33:03,780 --> 00:33:08,570
see less collaboration up there but

00:33:06,300 --> 00:33:10,860
there are still options for

00:33:08,570 --> 00:33:12,870
collaboration and you know any way you

00:33:10,860 --> 00:33:14,550
can look at Amazon recognitions of

00:33:12,870 --> 00:33:17,610
facial recognition service I mentioned

00:33:14,550 --> 00:33:19,260
as an example something where they're

00:33:17,610 --> 00:33:22,050
not providing the transparency right

00:33:19,260 --> 00:33:23,790
then not doing it all in open source and

00:33:22,050 --> 00:33:27,120
publishing it back like we would but

00:33:23,790 --> 00:33:29,040
they do get collaboration from all the

00:33:27,120 --> 00:33:32,040
people who same exact model better right

00:33:29,040 --> 00:33:33,960
so you you see some generalization

00:33:32,040 --> 00:33:36,780
commoditization of use cases even at

00:33:33,960 --> 00:33:40,020
that level but that's much less and no I

00:33:36,780 --> 00:33:43,280
understand the common pattern we see you

00:33:40,020 --> 00:33:45,650
know it's better you have a secure

00:33:43,280 --> 00:33:49,730
data platform that abstracts from the

00:33:45,650 --> 00:33:52,580
hybrid cloud basic cabinet is an

00:33:49,730 --> 00:33:58,760
accessory and Kafka we are using Seth

00:33:52,580 --> 00:34:00,530
they're open shift you know our Kafka to

00:33:58,760 --> 00:34:02,960
provide that on top of that you have a

00:34:00,530 --> 00:34:07,400
DevOps application lifecycle management

00:34:02,960 --> 00:34:09,800
that expands to data so you want so

00:34:07,400 --> 00:34:12,320
you're gonna treat basic data as and as

00:34:09,800 --> 00:34:14,990
an experiment to code in this and for

00:34:12,320 --> 00:34:17,840
example in your you know when you when

00:34:14,990 --> 00:34:19,580
you train a model you know or retrain a

00:34:17,840 --> 00:34:21,649
model you'll package up not only

00:34:19,580 --> 00:34:26,540
software your package up the data with

00:34:21,649 --> 00:34:30,800
the software basically today we do that

00:34:26,540 --> 00:34:32,750
for reproducibility most most project do

00:34:30,800 --> 00:34:35,179
that like windermere when you build code

00:34:32,750 --> 00:34:37,250
you store the source code that you build

00:34:35,179 --> 00:34:39,619
the code from our store reference or

00:34:37,250 --> 00:34:42,260
package of a source rpm or a debian

00:34:39,619 --> 00:34:44,899
source package so you can recreate that

00:34:42,260 --> 00:34:46,490
we expanding that into containers now

00:34:44,899 --> 00:34:48,200
with the concept called source container

00:34:46,490 --> 00:34:50,089
and think someone's talking at DEFCON 4

00:34:48,200 --> 00:34:51,800
about that because you know you want to

00:34:50,089 --> 00:34:54,470
have the aggregate concept and then we

00:34:51,800 --> 00:34:57,550
are gonna add the model for tracing data

00:34:54,470 --> 00:34:59,869
so you can reproduce the exact function

00:34:57,550 --> 00:35:01,760
based on the training data used

00:34:59,869 --> 00:35:03,670
originally on top of it then you have

00:35:01,760 --> 00:35:07,820
common things like language runtimes

00:35:03,670 --> 00:35:10,280
food processing to a kids like spark nor

00:35:07,820 --> 00:35:15,589
flink and then some common services that

00:35:10,280 --> 00:35:18,650
everyone uses like messaging we see

00:35:15,589 --> 00:35:20,810
usually most customers and most larger

00:35:18,650 --> 00:35:23,240
projects having a predefined library of

00:35:20,810 --> 00:35:26,300
AI functions like we are doing that

00:35:23,240 --> 00:35:29,030
internally so that would be for example

00:35:26,300 --> 00:35:32,150
flake detection there's a service we

00:35:29,030 --> 00:35:34,070
have in inside rat head that teams can

00:35:32,150 --> 00:35:36,810
just use your connect to an endpoint we

00:35:34,070 --> 00:35:38,280
are a REST API and then it tells you it

00:35:36,810 --> 00:35:40,740
you put your data and gives you results

00:35:38,280 --> 00:35:43,050
back in an analysis of your data so you

00:35:40,740 --> 00:35:45,480
don't have to so the use case here is

00:35:43,050 --> 00:35:47,700
basically you are developed or QA person

00:35:45,480 --> 00:35:49,530
and you don't want to learn a I just

00:35:47,700 --> 00:35:51,480
want to benefit from it so you use this

00:35:49,530 --> 00:35:55,290
predefined service you know equivalent

00:35:51,480 --> 00:36:00,120
to Amazon's recognition right you can

00:35:55,290 --> 00:36:02,940
use that because you have data with

00:36:00,120 --> 00:36:04,440
faces pictures of faces right you can

00:36:02,940 --> 00:36:05,100
use it you don't have to learn how it

00:36:04,440 --> 00:36:09,590
doesn't

00:36:05,100 --> 00:36:12,690
so very simple enablement the analytics

00:36:09,590 --> 00:36:15,780
private microcytic that's what if you're

00:36:12,690 --> 00:36:18,120
a data scientist or AI developer you

00:36:15,780 --> 00:36:19,680
create your own services right you could

00:36:18,120 --> 00:36:21,330
create generalized services or you

00:36:19,680 --> 00:36:23,640
create your own private micro services

00:36:21,330 --> 00:36:26,250
and then there's a data science and

00:36:23,640 --> 00:36:29,700
developer tool chain that you you would

00:36:26,250 --> 00:36:33,450
use to do that like Jupiter and so on on

00:36:29,700 --> 00:36:38,130
top of that you know just general API

00:36:33,450 --> 00:36:41,490
routing and of course identity access

00:36:38,130 --> 00:36:43,790
control so what we're seeing talking to

00:36:41,490 --> 00:36:45,930
customers looking at what everyone in

00:36:43,790 --> 00:36:47,490
startups is doing what's happening in

00:36:45,930 --> 00:36:51,360
the community this is pretty much a

00:36:47,490 --> 00:36:53,280
pattern that everyone is doing and we we

00:36:51,360 --> 00:36:57,930
think we think we can get the

00:36:53,280 --> 00:37:01,050
collaboration the idea is create a meta

00:36:57,930 --> 00:37:02,760
project so it's not going to we're not

00:37:01,050 --> 00:37:06,300
in that project open data we're not

00:37:02,760 --> 00:37:08,730
gonna drive individual projects deep in

00:37:06,300 --> 00:37:10,740
AI it's gonna be focused on making it

00:37:08,730 --> 00:37:13,170
easily accessible in an open source

00:37:10,740 --> 00:37:15,030
context and then operate instance

00:37:13,170 --> 00:37:17,190
building up operational knowledge about

00:37:15,030 --> 00:37:18,960
it feed that back into the project with

00:37:17,190 --> 00:37:20,930
the goal to get access to the community

00:37:18,960 --> 00:37:23,760
and suppose the academic community

00:37:20,930 --> 00:37:26,100
that's today using the Massachusetts

00:37:23,760 --> 00:37:27,990
open cloud and we expect with the goal

00:37:26,100 --> 00:37:30,540
for Reta districts pander to the open

00:37:27,990 --> 00:37:32,010
source community so provides the fedora

00:37:30,540 --> 00:37:33,690
and centrist community to begin with

00:37:32,010 --> 00:37:37,320
another redhead communities with the

00:37:33,690 --> 00:37:40,300
capability to use AI tools at different

00:37:37,320 --> 00:37:42,820
entry points right so flaky analysis for

00:37:40,300 --> 00:37:45,220
or anyone in the Fedora community would

00:37:42,820 --> 00:37:47,980
be something that's pretty close but

00:37:45,220 --> 00:37:49,870
then also the ability for you to do your

00:37:47,980 --> 00:37:52,150
own experiments that develop your own AI

00:37:49,870 --> 00:37:55,480
solutions and here's the entry point

00:37:52,150 --> 00:37:58,240
basically could be data only so an s3

00:37:55,480 --> 00:38:00,340
entry point look at it again with some

00:37:58,240 --> 00:38:03,670
governance around it's like a github for

00:38:00,340 --> 00:38:06,570
data and then build up from there

00:38:03,670 --> 00:38:11,050
container platform you can run things

00:38:06,570 --> 00:38:15,400
streaming services in AI toolchain tends

00:38:11,050 --> 00:38:18,520
to flow availability other AI tool

00:38:15,400 --> 00:38:22,780
chains up to a full full workflow or

00:38:18,520 --> 00:38:24,790
predefined services example so you know

00:38:22,780 --> 00:38:27,790
just I talked a little bit about that

00:38:24,790 --> 00:38:30,310
already but you know just a quick

00:38:27,790 --> 00:38:31,150
example we have keeper talks during the

00:38:30,310 --> 00:38:34,000
day and tomorrow

00:38:31,150 --> 00:38:39,190
onyx Sun and visor people who are doing

00:38:34,000 --> 00:38:41,170
these experiments right for example

00:38:39,190 --> 00:38:46,540
we're looking at for our own operations

00:38:41,170 --> 00:38:49,180
teams that run our cloud services we are

00:38:46,540 --> 00:38:52,540
working with them to do anomaly

00:38:49,180 --> 00:38:55,590
anomalies in their clusters I promise

00:38:52,540 --> 00:38:58,570
that traditional systems monitoring

00:38:55,590 --> 00:39:01,960
doesn't doesn't help you anymore right

00:38:58,570 --> 00:39:03,640
you can try to create manual rules to

00:39:01,960 --> 00:39:06,040
filter down but you like either you're

00:39:03,640 --> 00:39:08,530
getting too many alerts or you're gonna

00:39:06,040 --> 00:39:09,820
not get alert you either way you're

00:39:08,530 --> 00:39:13,120
gonna miss the alert that you actually

00:39:09,820 --> 00:39:15,040
was waiting for because because either

00:39:13,120 --> 00:39:16,660
it's a loss to the noise or your filters

00:39:15,040 --> 00:39:19,360
too tight and you're not getting it at

00:39:16,660 --> 00:39:20,830
all there's a common problem it is too

00:39:19,360 --> 00:39:22,990
complex right there are too many things

00:39:20,830 --> 00:39:27,070
too many inter dependencies so the idea

00:39:22,990 --> 00:39:31,620
is let's take some well understood AI

00:39:27,070 --> 00:39:35,590
algorithms machine learning based tools

00:39:31,620 --> 00:39:38,290
to train it on the data to for example

00:39:35,590 --> 00:39:41,170
find anomalies right so if I train it

00:39:38,290 --> 00:39:43,840
with the data of a cluster

00:39:41,170 --> 00:39:46,390
and I have enough data I can identify

00:39:43,840 --> 00:39:48,670
when unusual things are happening and it

00:39:46,390 --> 00:39:50,650
can alert on those which is much more

00:39:48,670 --> 00:39:53,920
powerful than a static root system for

00:39:50,650 --> 00:39:56,370
learning flake analysis I talked about

00:39:53,920 --> 00:39:59,440
that right can I like just get so much

00:39:56,370 --> 00:40:02,080
the complexity of these systems are so

00:39:59,440 --> 00:40:04,840
legit for human it's hard to understand

00:40:02,080 --> 00:40:09,100
the complex chain why something happen

00:40:04,840 --> 00:40:12,730
or even recognize that two things two

00:40:09,100 --> 00:40:17,860
failures are related because the

00:40:12,730 --> 00:40:20,350
relation is you know deep in some some

00:40:17,860 --> 00:40:22,780
conditions that both shares that is not

00:40:20,350 --> 00:40:24,370
obvious for the human the computer can

00:40:22,780 --> 00:40:31,110
find these things because it can just

00:40:24,370 --> 00:40:32,850
shifter all the data and we are we doing

00:40:31,110 --> 00:40:34,870
[Music]

00:40:32,850 --> 00:40:37,270
associative rule learning so this is

00:40:34,870 --> 00:40:41,920
where we we still exist for humans who

00:40:37,270 --> 00:40:45,130
write rules but we are helping them to

00:40:41,920 --> 00:40:48,100
visualize relationships between things

00:40:45,130 --> 00:40:50,790
so they can on and give them rule

00:40:48,100 --> 00:40:55,030
examples so they can more efficiently

00:40:50,790 --> 00:40:59,170
derive knowledge derive rules another

00:40:55,030 --> 00:41:01,240
example is that when you open a support

00:40:59,170 --> 00:41:04,270
ticket going forward your supporter will

00:41:01,240 --> 00:41:06,190
know your your state of mind because

00:41:04,270 --> 00:41:08,710
we're gonna do we're experimenting with

00:41:06,190 --> 00:41:10,240
sentiment analysis but it's pretty

00:41:08,710 --> 00:41:12,250
obvious that you would do that right

00:41:10,240 --> 00:41:15,090
it's really important to know how pissed

00:41:12,250 --> 00:41:15,090
off the customers

00:41:15,190 --> 00:41:22,640
right so the idea is basically derived

00:41:20,510 --> 00:41:29,650
more information from the information we

00:41:22,640 --> 00:41:35,840
already give it go deeper into that so

00:41:29,650 --> 00:41:39,830
recap so

00:41:35,840 --> 00:41:45,350
for a ted-like overall we think AI is is

00:41:39,830 --> 00:41:46,670
an extremely important trend right it's

00:41:45,350 --> 00:41:48,800
more than it is a fundamental shift of

00:41:46,670 --> 00:41:50,540
paradigm rig we think I'm not joking

00:41:48,800 --> 00:41:52,580
when I say this because the Industrial

00:41:50,540 --> 00:41:55,310
Revolution and you can go beyond so we

00:41:52,580 --> 00:41:57,080
are we are focusing very much on like on

00:41:55,310 --> 00:42:00,740
the technology aspect and the

00:41:57,080 --> 00:42:02,840
application to AI but overall it's a big

00:42:00,740 --> 00:42:06,190
shift because it's a different kind of

00:42:02,840 --> 00:42:10,070
automation I it's a big it's instead of

00:42:06,190 --> 00:42:11,720
traditional automation is just instead

00:42:10,070 --> 00:42:14,660
of like swinging a hammer

00:42:11,720 --> 00:42:16,910
on my you know on my kernel now I've

00:42:14,660 --> 00:42:19,400
ansible to swing many hammers at the

00:42:16,910 --> 00:42:21,650
same time on many nodes right but it's

00:42:19,400 --> 00:42:23,540
still like a press a button now instead

00:42:21,650 --> 00:42:27,110
of swinging the hammer myself but it's

00:42:23,540 --> 00:42:30,740
still a hammer being swung in the same

00:42:27,110 --> 00:42:34,190
predictable setup right it's just doing

00:42:30,740 --> 00:42:36,230
what I told it to do here we are now the

00:42:34,190 --> 00:42:38,990
machine is learning to do something

00:42:36,230 --> 00:42:42,080
based on data I give it and and and

00:42:38,990 --> 00:42:45,050
parameters I give it and that means I

00:42:42,080 --> 00:42:47,150
don't exactly know how like I don't know

00:42:45,050 --> 00:42:49,970
how it's bringing the hammer and I don't

00:42:47,150 --> 00:42:53,180
necessarily exact now why choose that

00:42:49,970 --> 00:42:55,160
specific hammer I like it's not a

00:42:53,180 --> 00:42:57,470
hundred percent predictable for me

00:42:55,160 --> 00:42:59,510
anymore I'm not between the Machine and

00:42:57,470 --> 00:43:01,730
the action anymore I'm just on the

00:42:59,510 --> 00:43:06,230
outside putting input into the machine

00:43:01,730 --> 00:43:08,870
and it's a big change it also it means

00:43:06,230 --> 00:43:11,060
that certain types of tasks probably we

00:43:08,870 --> 00:43:15,650
won't have to do any more fundamentally

00:43:11,060 --> 00:43:17,690
so on a society level it's a big big

00:43:15,650 --> 00:43:19,490
change because you know in the past you

00:43:17,690 --> 00:43:20,990
could always just move from strings

00:43:19,490 --> 00:43:22,610
hammer to pushing the button but now

00:43:20,990 --> 00:43:25,180
there might not be a button to push the

00:43:22,610 --> 00:43:27,910
button result to make it away so it's it

00:43:25,180 --> 00:43:32,319
the big deal we think that everyone has

00:43:27,910 --> 00:43:34,329
to be aware of it like as a business as

00:43:32,319 --> 00:43:36,160
a software project developer because

00:43:34,329 --> 00:43:38,200
it's changing how you interact the

00:43:36,160 --> 00:43:40,089
systems are Integris often it's going to

00:43:38,200 --> 00:43:44,520
change how for your customers expect

00:43:40,089 --> 00:43:44,520
what the users expect from the software

00:43:45,480 --> 00:43:51,579
we see a very strong trend towards this

00:43:49,240 --> 00:43:54,190
hybrid cloud container platform which we

00:43:51,579 --> 00:43:56,140
are fairly happy because with kubernetes

00:43:54,190 --> 00:43:59,170
OpenShift we have done a lot of that in

00:43:56,140 --> 00:44:00,880
its space and so biggest priority for us

00:43:59,170 --> 00:44:04,359
is to make OpenShift the ideal platform

00:44:00,880 --> 00:44:06,730
to run AI machine learning workloads and

00:44:04,359 --> 00:44:08,920
enable the broader ecosystem and the

00:44:06,730 --> 00:44:12,010
open source community because there's

00:44:08,920 --> 00:44:13,599
Retta is an open source company we

00:44:12,010 --> 00:44:15,819
depend on the open source community

00:44:13,599 --> 00:44:16,869
picking this up right we are not going

00:44:15,819 --> 00:44:20,500
to do this on our own

00:44:16,869 --> 00:44:24,609
we only one one part of the overall

00:44:20,500 --> 00:44:27,940
equation and so we want to enable the

00:44:24,609 --> 00:44:31,510
open source community to get on board

00:44:27,940 --> 00:44:33,190
with a int application of AI within the

00:44:31,510 --> 00:44:37,690
scope of the open source projects to

00:44:33,190 --> 00:44:39,819
make them better so if you wanna finding

00:44:37,690 --> 00:44:42,250
out we have we're going to publish a

00:44:39,819 --> 00:44:47,020
blog and next or the ratchet come and

00:44:42,250 --> 00:44:49,809
you can go to the open now you can go to

00:44:47,020 --> 00:44:52,510
open data hub il which is updated that

00:44:49,809 --> 00:44:53,920
page and read analytics REO and as a

00:44:52,510 --> 00:44:55,809
good place to find out what's going on

00:44:53,920 --> 00:44:58,990
with AI dratted and get some you know

00:44:55,809 --> 00:45:03,160
quick starts and tools there is gonna be

00:44:58,990 --> 00:45:06,640
we have this whole today in this room

00:45:03,160 --> 00:45:08,500
and tomorrow in medical small I think an

00:45:06,640 --> 00:45:12,430
AI track was a whole bunch of good talks

00:45:08,500 --> 00:45:15,400
and on Saturday there is also a data

00:45:12,430 --> 00:45:18,450
science workshop run by by Mike

00:45:15,400 --> 00:45:21,519
we'll Benton my cousins are back there

00:45:18,450 --> 00:45:25,329
which I can really recommend is really

00:45:21,519 --> 00:45:27,549
great great workshop on how to run it's

00:45:25,329 --> 00:45:29,890
built around spar and how to run data

00:45:27,549 --> 00:45:34,329
science and machine learning on top of

00:45:29,890 --> 00:45:36,099
kubernetes you can spark so really good

00:45:34,329 --> 00:45:38,769
if you have any I don't know how much

00:45:36,099 --> 00:45:41,050
time we have for questions think we're

00:45:38,769 --> 00:45:43,099
five minutes is that right

00:45:41,050 --> 00:45:45,109
[Music]

00:45:43,099 --> 00:45:48,279
ten minutes excellent with ten minutes

00:45:45,109 --> 00:45:51,349
for questions discussion any questions

00:45:48,279 --> 00:45:53,089
in the back I think we should have a

00:45:51,349 --> 00:45:55,329
microwave to the second microphone back

00:45:53,089 --> 00:45:55,329
there

00:45:56,619 --> 00:46:04,279
note to self as the next talk get out

00:45:59,299 --> 00:46:05,150
the hand microphone I'm just wondering

00:46:04,279 --> 00:46:08,119
will you make this presentation

00:46:05,150 --> 00:46:11,390
available yes so we actually live

00:46:08,119 --> 00:46:12,979
streamed it and the recording will be

00:46:11,390 --> 00:46:15,130
available and we will make the slides

00:46:12,979 --> 00:46:15,130
available

00:46:16,320 --> 00:46:23,870
[Music]

00:46:18,300 --> 00:46:23,870
any other questions

00:46:25,120 --> 00:46:29,810
by let me out even who have you asked

00:46:27,370 --> 00:46:34,739
done anything with machine learning

00:46:29,810 --> 00:46:34,739
[Music]

00:46:34,960 --> 00:46:43,240
have you have you usages on your laptop

00:46:41,470 --> 00:46:50,640
or done it like in a we know in a

00:46:43,240 --> 00:46:50,640
workflow already with both

00:46:52,410 --> 00:47:02,030
is who have used using Amazon for that

00:46:57,540 --> 00:47:05,680
[Music]

00:47:02,030 --> 00:47:05,680
maybe it's not as bad as I thought

00:47:06,930 --> 00:47:11,420
while directed people are saying Amazon

00:47:09,299 --> 00:47:11,420
this

00:47:16,080 --> 00:47:21,080
[Music]

00:47:17,330 --> 00:47:21,980
well said no questions I hope this was

00:47:21,080 --> 00:47:27,790
fun

00:47:21,980 --> 00:47:27,790
[Music]

00:47:29,270 --> 00:47:38,100
hi I found the your perspective quite

00:47:33,090 --> 00:47:40,410
refreshing I have seen some quite

00:47:38,100 --> 00:47:45,110
chilling things that are coming out of

00:47:40,410 --> 00:47:49,230
the land of proprietary software from

00:47:45,110 --> 00:47:54,320
companies such as Salesforce when it

00:47:49,230 --> 00:47:58,320
comes to to AI can you expand more on

00:47:54,320 --> 00:48:03,450
the importance of doing this the free

00:47:58,320 --> 00:48:07,350
software way thank you so why does free

00:48:03,450 --> 00:48:09,780
sauce in a meta you know it's um I think

00:48:07,350 --> 00:48:11,790
they're like they're multiple layers to

00:48:09,780 --> 00:48:13,740
that to that discussion right the first

00:48:11,790 --> 00:48:17,490
one it says why if we want to do it in

00:48:13,740 --> 00:48:19,260
open source we want to enable open

00:48:17,490 --> 00:48:20,610
source to be an AI enable like

00:48:19,260 --> 00:48:22,800
kubernetes becomes a self-driving

00:48:20,610 --> 00:48:24,960
cluster you can own like we need to do

00:48:22,800 --> 00:48:26,370
it all in open source and otherwise it's

00:48:24,960 --> 00:48:29,640
not open so right so it's kind of

00:48:26,370 --> 00:48:31,290
self-evident that for applying it to

00:48:29,640 --> 00:48:34,770
open source software we have to do it in

00:48:31,290 --> 00:48:37,440
open source and there's you know in that

00:48:34,770 --> 00:48:39,000
for the code and the data when you go

00:48:37,440 --> 00:48:40,500
into oh it needs to be functionally

00:48:39,000 --> 00:48:41,910
complete right if we don't have the

00:48:40,500 --> 00:48:45,410
training data then we haven't provided

00:48:41,910 --> 00:48:48,390
an open source solution to the problem

00:48:45,410 --> 00:48:50,820
so you like I think I think like in our

00:48:48,390 --> 00:48:55,200
world we'll see kind of this separation

00:48:50,820 --> 00:48:57,600
of like data domains in community data

00:48:55,200 --> 00:48:59,400
and community data will always go back

00:48:57,600 --> 00:49:00,900
to the community and will develop will

00:48:59,400 --> 00:49:04,740
see development of some licensing

00:49:00,900 --> 00:49:05,240
schemes similar to copyleft for that for

00:49:04,740 --> 00:49:07,230
data

00:49:05,240 --> 00:49:10,500
[Music]

00:49:07,230 --> 00:49:12,630
we then have your own data like Cerreta

00:49:10,500 --> 00:49:14,790
create a lot of data some of that will

00:49:12,630 --> 00:49:16,859
be open source data some of us that will

00:49:14,790 --> 00:49:19,220
not that depends on a lot of factors and

00:49:16,859 --> 00:49:21,510
then we have customer data right that

00:49:19,220 --> 00:49:25,109
belongs to the customer always gonna be

00:49:21,510 --> 00:49:26,640
private because just by requirement in

00:49:25,109 --> 00:49:28,980
many cases by even regulatory

00:49:26,640 --> 00:49:31,170
requirement unless the customer donates

00:49:28,980 --> 00:49:33,950
the data into open source which of

00:49:31,170 --> 00:49:37,349
course there's a possibility for that so

00:49:33,950 --> 00:49:39,450
but for us it's really important that

00:49:37,349 --> 00:49:41,490
this is complete right you need open

00:49:39,450 --> 00:49:43,829
source needs to be complete self hosting

00:49:41,490 --> 00:49:46,560
reproducible that means the data you use

00:49:43,829 --> 00:49:48,030
to develop open source to put a I open

00:49:46,560 --> 00:49:49,410
source needs to be part of open source

00:49:48,030 --> 00:49:52,950
otherwise you haven't done open source

00:49:49,410 --> 00:49:55,920
it's very straightforward there now you

00:49:52,950 --> 00:49:57,900
can take it a step further look up you

00:49:55,920 --> 00:49:59,730
know it's this general trend right if

00:49:57,900 --> 00:50:02,220
you if you're using black box services

00:49:59,730 --> 00:50:05,869
you're giving up control right and

00:50:02,220 --> 00:50:08,820
that's true is anything you do in a

00:50:05,869 --> 00:50:10,890
proprietary software right you have less

00:50:08,820 --> 00:50:12,390
control than an open source that's why

00:50:10,890 --> 00:50:15,180
open source matters right open source

00:50:12,390 --> 00:50:16,770
about enabling you to understand what

00:50:15,180 --> 00:50:18,329
software is doing reproduce what the

00:50:16,770 --> 00:50:21,960
surface students and redistribute that

00:50:18,329 --> 00:50:24,030
software now if you go into cloud

00:50:21,960 --> 00:50:26,550
services black box services that operate

00:50:24,030 --> 00:50:29,280
in the cloud that's the extreme case of

00:50:26,550 --> 00:50:31,220
the proprietary software because you

00:50:29,280 --> 00:50:33,950
don't know

00:50:31,220 --> 00:50:35,540
you not only can't you change the

00:50:33,950 --> 00:50:37,400
software you don't have input on the

00:50:35,540 --> 00:50:40,579
operation side now if you go into data

00:50:37,400 --> 00:50:42,380
services we are now decisions are being

00:50:40,579 --> 00:50:43,940
taken based on data and you don't even

00:50:42,380 --> 00:50:45,920
control the data you can put your own

00:50:43,940 --> 00:50:48,700
data in it but you lose control over

00:50:45,920 --> 00:50:51,020
your own data when you do that

00:50:48,700 --> 00:50:53,119
extrapolate so it's a control problem

00:50:51,020 --> 00:50:54,770
you know you get into a very strong

00:50:53,119 --> 00:50:57,560
dependency when you use these kind of

00:50:54,770 --> 00:51:00,290
black box services you lose

00:50:57,560 --> 00:51:02,089
reproducibility I on top of that let's

00:51:00,290 --> 00:51:04,730
say if you're in research where you're

00:51:02,089 --> 00:51:06,920
doing scientific research and you want

00:51:04,730 --> 00:51:10,819
to do publications you need how do you

00:51:06,920 --> 00:51:12,710
do peer review if you are dependent on

00:51:10,819 --> 00:51:14,569
the black box service that you don't

00:51:12,710 --> 00:51:16,040
know how is it going you don't have to

00:51:14,569 --> 00:51:18,050
reproducibility anymore

00:51:16,040 --> 00:51:21,380
it's a business from a regulatory

00:51:18,050 --> 00:51:23,030
problem an audit problem in many cases

00:51:21,380 --> 00:51:26,800
you can probably offload it

00:51:23,030 --> 00:51:29,060
right if you're your service provider is

00:51:26,800 --> 00:51:31,700
HIPAA compliant you don't have a problem

00:51:29,060 --> 00:51:34,280
with zipper compliance anymore but

00:51:31,700 --> 00:51:37,460
you're also completely dependent on that

00:51:34,280 --> 00:51:40,700
that doesn't work everywhere right that

00:51:37,460 --> 00:51:44,150
doesn't work in research and it goes

00:51:40,700 --> 00:51:47,450
deeper in where your of course your

00:51:44,150 --> 00:51:50,300
results are dependent on what goes into

00:51:47,450 --> 00:51:52,339
them right there this is I don't like

00:51:50,300 --> 00:51:53,960
the term algorithmic bias because I

00:51:52,339 --> 00:51:56,599
think you think it's misleading because

00:51:53,960 --> 00:51:58,460
it I think it's primarily just the old

00:51:56,599 --> 00:52:00,440
garbage in garbage out problem right

00:51:58,460 --> 00:52:03,380
it's not that the algorithm has the map

00:52:00,440 --> 00:52:05,270
doesn't have a bias but if you put data

00:52:03,380 --> 00:52:09,520
into the training model and the data as

00:52:05,270 --> 00:52:12,800
a certain statistics or statistical

00:52:09,520 --> 00:52:15,360
aspects characteristic of the data will

00:52:12,800 --> 00:52:17,610
show up in the model right

00:52:15,360 --> 00:52:19,560
and so if you have an imbalance and in

00:52:17,610 --> 00:52:21,780
the data you put in you will see the

00:52:19,560 --> 00:52:27,630
imbalance most likely in the decisions

00:52:21,780 --> 00:52:30,810
and model takes and the problem is that

00:52:27,630 --> 00:52:32,490
if your if you if you have a model part

00:52:30,810 --> 00:52:36,480
of your decision process and something

00:52:32,490 --> 00:52:39,660
with it and you don't know you can't

00:52:36,480 --> 00:52:41,640
validate the data you fully dependent on

00:52:39,660 --> 00:52:44,100
the people who select the data to train

00:52:41,640 --> 00:52:46,460
the model to do it right right so so

00:52:44,100 --> 00:52:50,400
even like the correctness of the results

00:52:46,460 --> 00:52:51,690
depends on training the model right so

00:52:50,400 --> 00:52:55,040
if you're using someone else's train

00:52:51,690 --> 00:52:58,140
model or it could depend on on real

00:52:55,040 --> 00:53:00,180
things in the platform right if you if

00:52:58,140 --> 00:53:02,070
you I can't reproduce a binary platform

00:53:00,180 --> 00:53:05,100
that are trained to model on I can't

00:53:02,070 --> 00:53:07,020
guarantee that I can recreate the same

00:53:05,100 --> 00:53:11,190
behavior let's say I validated was

00:53:07,020 --> 00:53:13,290
correct but it was correct but there was

00:53:11,190 --> 00:53:17,840
like a rounding error somewhere in the

00:53:13,290 --> 00:53:19,980
GPU because of a micro code problem or

00:53:17,840 --> 00:53:21,510
it's actually a hard one let's take it

00:53:19,980 --> 00:53:24,990
simpler like in the driver driver round

00:53:21,510 --> 00:53:26,730
were just a parameter setting right if I

00:53:24,990 --> 00:53:28,740
have no control over that I can't

00:53:26,730 --> 00:53:30,920
reproduce it I might not be able to

00:53:28,740 --> 00:53:35,130
reproduce the results so that's why I

00:53:30,920 --> 00:53:38,400
think it's extremely important just for

00:53:35,130 --> 00:53:42,180
consistency both for for businesses and

00:53:38,400 --> 00:53:43,980
for researchers to control or have

00:53:42,180 --> 00:53:45,750
transparency in the full stack and have

00:53:43,980 --> 00:53:47,970
the ability to get control over the full

00:53:45,750 --> 00:53:49,620
stack right you can use services but

00:53:47,970 --> 00:53:51,780
don't use services that will not tell

00:53:49,620 --> 00:53:53,460
you what they're doing would be my life

00:53:51,780 --> 00:53:57,780
and then you can take it a step further

00:53:53,460 --> 00:53:59,810
where now we are you know these systems

00:53:57,780 --> 00:54:02,660
become more and more important

00:53:59,810 --> 00:54:05,960
and then you can get quite philosophical

00:54:02,660 --> 00:54:08,420
or political on that but obviously I

00:54:05,960 --> 00:54:11,570
think it's the old Laura Lawrence Larry

00:54:08,420 --> 00:54:15,410
Lawrence Lessig I think he wrote this

00:54:11,570 --> 00:54:18,470
Larry Lessig a Harvard professor he

00:54:15,410 --> 00:54:20,510
wrote this book of codes and it was like

00:54:18,470 --> 00:54:23,360
probably 20 years ago or sometime 15

00:54:20,510 --> 00:54:27,740
years ago but it all about the how codes

00:54:23,360 --> 00:54:30,890
becomes law because in the way we

00:54:27,740 --> 00:54:34,670
interact with with the world today our

00:54:30,890 --> 00:54:38,420
interaction with the world is limited by

00:54:34,670 --> 00:54:40,430
the cold that we used to interact with

00:54:38,420 --> 00:54:41,900
the world right you know a common exam

00:54:40,430 --> 00:54:44,480
like we are all in this room that's

00:54:41,900 --> 00:54:46,550
great we can talk unfiltered at the

00:54:44,480 --> 00:54:48,230
moment where I'm posting this on Twitter

00:54:46,550 --> 00:54:52,220
or on Facebook there are already

00:54:48,230 --> 00:54:53,960
algorithms between us and you know if

00:54:52,220 --> 00:54:57,010
protocols don't talk to each other they

00:54:53,960 --> 00:54:59,480
don't talk to each other you know if

00:54:57,010 --> 00:55:01,700
filters tone the filter things and don't

00:54:59,480 --> 00:55:05,210
show them they don't show up and that's

00:55:01,700 --> 00:55:07,460
another like bigger transparency problem

00:55:05,210 --> 00:55:10,730
that I think only open-source can

00:55:07,460 --> 00:55:13,330
overcome right like at the end you want

00:55:10,730 --> 00:55:17,060
to make sure that there's transparency

00:55:13,330 --> 00:55:19,640
in these kind of decisions right there's

00:55:17,060 --> 00:55:22,070
transparency in and you don't have to go

00:55:19,640 --> 00:55:24,320
to the big question for self-driving car

00:55:22,070 --> 00:55:26,600
right the dilemma like do I kill one or

00:55:24,320 --> 00:55:29,990
five people right which is hard for

00:55:26,600 --> 00:55:31,730
humans right Nick there's a just listen

00:55:29,990 --> 00:55:36,859
to

00:55:31,730 --> 00:55:38,390
Sam Harris book on that music so for

00:55:36,859 --> 00:55:40,460
humans it depends the answer depends on

00:55:38,390 --> 00:55:44,390
how you ask the question will you kill

00:55:40,460 --> 00:55:47,540
one or five people in that environment

00:55:44,390 --> 00:55:49,790
serene in testa psychologically right

00:55:47,540 --> 00:55:51,140
and four machines will have like we will

00:55:49,790 --> 00:55:54,920
have to figure that out self-driving

00:55:51,140 --> 00:55:57,500
cars are not possible without taking

00:55:54,920 --> 00:55:59,090
that decision they will take that

00:55:57,500 --> 00:56:02,030
decision and I think that kind of

00:55:59,090 --> 00:56:03,590
decision needs to be transparent and the

00:56:02,030 --> 00:56:06,650
only way to do that is with open source

00:56:03,590 --> 00:56:10,490
and open source treating data as part of

00:56:06,650 --> 00:56:11,330
the code so was that was a long answer I

00:56:10,490 --> 00:56:14,690
hope it was

00:56:11,330 --> 00:56:14,690
[Music]

00:56:16,060 --> 00:56:20,490
one more question two more questions

00:56:17,770 --> 00:56:23,640
okay three

00:56:20,490 --> 00:56:23,640
[Music]

00:56:24,270 --> 00:56:28,350
sighs very interesting the idea of a

00:56:26,790 --> 00:56:30,660
trusted aggregator of

00:56:28,350 --> 00:56:33,300
data being a third party can you talk

00:56:30,660 --> 00:56:36,900
about some examples or what some really

00:56:33,300 --> 00:56:39,960
promising areas that might be yes so

00:56:36,900 --> 00:56:44,400
right now the focus it's it's for open

00:56:39,960 --> 00:56:46,320
source projects to share data that's

00:56:44,400 --> 00:56:47,910
where we're starting well right now it

00:56:46,320 --> 00:56:54,360
would be like operational data for

00:56:47,910 --> 00:56:56,970
example for you know your cluster or you

00:56:54,360 --> 00:56:58,770
know let's say you want to do it might

00:56:56,970 --> 00:57:00,360
be my favorite example it's something if

00:56:58,770 --> 00:57:02,460
no one is doing it I will do it I'm

00:57:00,360 --> 00:57:03,900
running my home automation with a home

00:57:02,460 --> 00:57:06,750
assistant which is awesome on the

00:57:03,900 --> 00:57:08,880
Raspberry Pi on Fedora on the Raspberry

00:57:06,750 --> 00:57:12,870
Pi some partners is cutting the Debian

00:57:08,880 --> 00:57:16,500
is great too we don't like and like

00:57:12,870 --> 00:57:18,180
right now I have to for my climate

00:57:16,500 --> 00:57:21,180
control have to write manual rules and

00:57:18,180 --> 00:57:24,120
like with three thermostats and and a

00:57:21,180 --> 00:57:26,910
bunch of like like day/night season

00:57:24,120 --> 00:57:29,400
people home like it's already too much

00:57:26,910 --> 00:57:31,290
right I can't keep up with that right so

00:57:29,400 --> 00:57:33,150
it's it's very low hanging fruit to just

00:57:31,290 --> 00:57:36,110
train that or that would then what was

00:57:33,150 --> 00:57:38,340
nest you do right like it it learns from

00:57:36,110 --> 00:57:39,990
well you I have no idea how they do that

00:57:38,340 --> 00:57:42,630
I never owned the nest because you know

00:57:39,990 --> 00:57:46,440
that like this is the black box service

00:57:42,630 --> 00:57:48,840
so I'm doing it myself and with the open

00:57:46,440 --> 00:57:51,690
data you could create that very easily a

00:57:48,840 --> 00:57:54,810
place where you can put the data with

00:57:51,690 --> 00:57:58,370
trust we can ensure compliance around it

00:57:54,810 --> 00:58:01,680
you know to make sure that data gets

00:57:58,370 --> 00:58:04,070
managed properly and the open sore open

00:58:01,680 --> 00:58:06,360
an open source project can now

00:58:04,070 --> 00:58:09,870
collaborate on it without having to

00:58:06,360 --> 00:58:10,730
build up the stack on therefore in so it

00:58:09,870 --> 00:58:14,269
would

00:58:10,730 --> 00:58:16,579
probably fall under gdpr because of

00:58:14,269 --> 00:58:20,329
personal identifying information so you

00:58:16,579 --> 00:58:21,769
will need compliance with immunization I

00:58:20,329 --> 00:58:25,339
can't say that in English but you know

00:58:21,769 --> 00:58:27,230
what I mean and and and so we can work

00:58:25,339 --> 00:58:30,650
together to just make that easier

00:58:27,230 --> 00:58:32,720
available now with the codes like we're

00:58:30,650 --> 00:58:33,619
gonna enable you to do it on your own if

00:58:32,720 --> 00:58:36,079
you want to write and you can

00:58:33,619 --> 00:58:37,640
participate in the project and just it's

00:58:36,079 --> 00:58:39,950
gonna provide all the tools to make this

00:58:37,640 --> 00:58:41,390
very easy but if you just want to use it

00:58:39,950 --> 00:58:43,119
we are trying to create an

00:58:41,390 --> 00:58:49,519
implementation that you can just use

00:58:43,119 --> 00:58:52,910
while being transparent I think we're

00:58:49,519 --> 00:58:54,950
out of time but two minutes so one more

00:58:52,910 --> 00:58:57,339
question that was in the back someone

00:58:54,950 --> 00:58:57,339
who wanted

00:58:57,620 --> 00:59:07,090
[Music]

00:59:04,120 --> 00:59:09,190
so I had a question about the the

00:59:07,090 --> 00:59:14,080
practical approach of dealing with these

00:59:09,190 --> 00:59:15,850
large data sets I can use AWS and I can

00:59:14,080 --> 00:59:18,220
write my code that's open source and I

00:59:15,850 --> 00:59:20,320
can use pipe torch which is also open

00:59:18,220 --> 00:59:24,760
source and and I can provide my data and

00:59:20,320 --> 00:59:27,250
just use AWS as a service and and still

00:59:24,760 --> 00:59:29,140
meet all of your requirements but when

00:59:27,250 --> 00:59:30,640
we're talking about nested data and

00:59:29,140 --> 00:59:32,940
we're talking about self-driving cars

00:59:30,640 --> 00:59:35,860
and we're talking about medical data

00:59:32,940 --> 00:59:37,390
we've seen from a very simple example

00:59:35,860 --> 00:59:39,420
you know Netflix a couple of years ago

00:59:37,390 --> 00:59:42,850
when they at their million-dollar

00:59:39,420 --> 00:59:45,340
recommendation challenge even the

00:59:42,850 --> 00:59:47,800
identified data in a very limited source

00:59:45,340 --> 00:59:49,860
is enough oftentimes to re-identify

00:59:47,800 --> 00:59:54,460
people so when we're dealing with

00:59:49,860 --> 00:59:57,640
petabytes of large datasets how do you

00:59:54,460 --> 01:00:00,730
envision that people without encroaching

00:59:57,640 --> 01:00:03,490
on the privacy of whoever it's contained

01:00:00,730 --> 01:00:05,730
that dataset would even start to think

01:00:03,490 --> 01:00:07,900
about making that data open source

01:00:05,730 --> 01:00:11,110
because what you need I mean the whole

01:00:07,900 --> 01:00:13,120
premise of machine learning is the more

01:00:11,110 --> 01:00:15,250
data that you have the better right data

01:00:13,120 --> 01:00:17,260
is far more important than the model

01:00:15,250 --> 01:00:18,970
that you throw at it or you know if you

01:00:17,260 --> 01:00:23,140
have enough data you'll get somewhere

01:00:18,970 --> 01:00:25,030
right but inherently seems to seems to

01:00:23,140 --> 01:00:26,740
conflicted with the idea of making that

01:00:25,030 --> 01:00:28,690
open source

01:00:26,740 --> 01:00:30,940
specifically for these kinds of models

01:00:28,690 --> 01:00:34,420
like you know text to speech or speech

01:00:30,940 --> 01:00:36,400
to text and everything else right so I

01:00:34,420 --> 01:00:41,190
don't know if the audio was strong

01:00:36,400 --> 01:00:47,050
enough so I'll repeat I'll summarize the

01:00:41,190 --> 01:00:49,540
data is the key rated we all agree and

01:00:47,050 --> 01:00:52,920
you need more and more data the problem

01:00:49,540 --> 01:00:55,630
is that often you can identify

01:00:52,920 --> 01:00:58,060
individuals even with with very little

01:00:55,630 --> 01:00:59,740
data right and for what we're trying to

01:00:58,060 --> 01:01:02,290
do you're gonna we're gonna try to

01:00:59,740 --> 01:01:05,260
aggregate a lot of data right wherever

01:01:02,290 --> 01:01:06,460
we are doing it with AI and the problem

01:01:05,260 --> 01:01:09,010
you know how can you do that with

01:01:06,460 --> 01:01:10,780
open-source without compromising privacy

01:01:09,010 --> 01:01:13,539
so I think

01:01:10,780 --> 01:01:16,359
[Music]

01:01:13,539 --> 01:01:18,009
so we don't have an answer to that yet

01:01:16,359 --> 01:01:21,819
right there are some techniques you can

01:01:18,009 --> 01:01:24,119
do with zoo demonization that get you

01:01:21,819 --> 01:01:24,119
there

01:01:25,199 --> 01:01:29,939
ultimately it's you know it's it's gonna

01:01:28,479 --> 01:01:32,259
be hard

01:01:29,939 --> 01:01:34,239
it depends what you're doing right when

01:01:32,259 --> 01:01:36,099
we start with our data is fairly simple

01:01:34,239 --> 01:01:38,169
still right so where we are starting out

01:01:36,099 --> 01:01:41,939
now when you get to medical data and

01:01:38,169 --> 01:01:45,009
which you know it's it's already a big

01:01:41,939 --> 01:01:47,229
deal right there's a lot of medical data

01:01:45,009 --> 01:01:49,149
out there already and it's being shared

01:01:47,229 --> 01:01:52,059
and people are not actually not aware

01:01:49,149 --> 01:01:54,789
how well how identifying it is today

01:01:52,059 --> 01:01:56,889
that it's a problem today where you know

01:01:54,789 --> 01:01:58,839
MRIs actually are identifying

01:01:56,889 --> 01:02:00,939
information I don't think they're

01:01:58,839 --> 01:02:06,569
covered in the regulation yet to that

01:02:00,939 --> 01:02:06,569
degree and the problem I think

01:02:06,790 --> 01:02:11,750
it's over

01:02:08,720 --> 01:02:15,220
they're gonna be techniques to improve

01:02:11,750 --> 01:02:17,770
how you put it separate the

01:02:15,220 --> 01:02:21,319
identification from the data that works

01:02:17,770 --> 01:02:23,750
for a lot of the simple use cases I

01:02:21,319 --> 01:02:27,339
think for the harder use cases we have

01:02:23,750 --> 01:02:29,510
to get better secure compute

01:02:27,339 --> 01:02:33,020
capabilities so things like you know

01:02:29,510 --> 01:02:35,060
multi secure multi-part compute research

01:02:33,020 --> 01:02:38,599
like that I think is where with we're

01:02:35,060 --> 01:02:41,390
gonna see as it's growing so you get to

01:02:38,599 --> 01:02:45,680
kind of an escrow model for data where

01:02:41,390 --> 01:02:47,690
like data is stored but not disseminated

01:02:45,680 --> 01:02:54,349
to everyone and you have a secure

01:02:47,690 --> 01:02:56,300
environment to do something wizard it

01:02:54,349 --> 01:02:58,069
isn't conflict with the concept of open

01:02:56,300 --> 01:03:02,450
source right so there's going to be

01:02:58,069 --> 01:03:04,900
compromise somewhere there in some areas

01:03:02,450 --> 01:03:07,339
you probably will have to decide whether

01:03:04,900 --> 01:03:10,010
you're gonna go with privacy or you're

01:03:07,339 --> 01:03:11,070
gonna go with transparency and you know

01:03:10,010 --> 01:03:13,450
in a way I think

01:03:11,070 --> 01:03:16,599
[Music]

01:03:13,450 --> 01:03:17,890
it's it's an it could be an opt opt-in

01:03:16,599 --> 01:03:21,309
model like so for something like a

01:03:17,890 --> 01:03:25,270
self-driving car I don't see a reason to

01:03:21,309 --> 01:03:32,799
have private data there like I think you

01:03:25,270 --> 01:03:37,869
can probably make it anonymous enough to

01:03:32,799 --> 01:03:39,579
train the decision systems or you know

01:03:37,869 --> 01:03:41,079
it becomes irrelevant enough because

01:03:39,579 --> 01:03:43,809
there's so much data about who was there

01:03:41,079 --> 01:03:46,079
sure like individually there might be

01:03:43,809 --> 01:03:50,410
things in that data that are

01:03:46,079 --> 01:03:53,349
compromising individual privacy but if

01:03:50,410 --> 01:03:55,510
it's everyone I think that that washes

01:03:53,349 --> 01:03:57,549
out a little bit this medical data gets

01:03:55,510 --> 01:04:00,010
more a bit more like so location data is

01:03:57,549 --> 01:04:02,849
one thing but medical data I think is a

01:04:00,010 --> 01:04:02,849
more programmatic

01:04:08,440 --> 01:04:20,149
[Music]

01:04:23,790 --> 01:04:26,989
[Music]

01:04:35,750 --> 01:04:44,170
[Music]

01:04:40,820 --> 01:04:44,170

YouTube URL: https://www.youtube.com/watch?v=NFlSkjFPLAc


