Title: Hybrid Cloud Storage
Publication date: 2020-10-07
Playlist: DevConfUS 2020
Description: 
	Speaker: Emine Ugur Kaynar

The values offered by public cloud services are clear for analytic workloads. Specialized hardware such as GPUs for doing AI/ML may make more sense to effectively lease with Opex rather than invest Capex on infrastructure that is not continually utilized. However, it may not make sense to build large data sets inside public clouds due both to the cost multiple compared to building out and maintaining private infrastructure and the lock-in nature of using public cloud services. These drivers then lead toward a hybrid architecture where large data sets are built and maintained in private clouds but compute/analytic clusters are spun up in public clouds to the actual analytics on these data sets.

Maintaining a hybrid architecture as described introduces challenges with latency and bandwidth to the public cloud compute cluster from the private data lake. In this presentation we describe research being done at by Mass Open Cloud and Red Hat researchers to build caching solutions to maximize throughput of these leased analytics clusters and avoid re-reading the same data from the external private data lake.
Captions: 
	00:00:00,320 --> 00:00:06,799
i think we can get started so

00:00:03,040 --> 00:00:10,160
because it's one thing so okay everybody

00:00:06,799 --> 00:00:12,639
uh the next dog is by

00:00:10,160 --> 00:00:13,360
is it amin i hope i'm pronouncing your

00:00:12,639 --> 00:00:15,360
name correct

00:00:13,360 --> 00:00:16,640
i'm actually using the middle name or

00:00:15,360 --> 00:00:18,400
box oh

00:00:16,640 --> 00:00:21,920
okay yeah all right so we'll have or

00:00:18,400 --> 00:00:25,199
talk about um hybrid cloud storage

00:00:21,920 --> 00:00:26,400
okay go ahead thank you very much uh hi

00:00:25,199 --> 00:00:29,840
everyone um

00:00:26,400 --> 00:00:31,439
my name is orr i am a phd student at

00:00:29,840 --> 00:00:33,520
boston university

00:00:31,439 --> 00:00:34,559
and also doing an internship internship

00:00:33,520 --> 00:00:37,920
with red hat

00:00:34,559 --> 00:00:38,640
um team at the cto's office so today i

00:00:37,920 --> 00:00:40,239
will um

00:00:38,640 --> 00:00:41,920
talk about the hybrid class storage

00:00:40,239 --> 00:00:43,680
caching projects um

00:00:41,920 --> 00:00:46,079
uh so we design and implement a cache

00:00:43,680 --> 00:00:46,480
architecture to improve the performance

00:00:46,079 --> 00:00:50,559
of

00:00:46,480 --> 00:00:54,079
big data analytical um workloads

00:00:50,559 --> 00:00:55,680
so um in our own data center we didn't

00:00:54,079 --> 00:00:57,520
have a full bisection bandwidth

00:00:55,680 --> 00:00:59,280
which is the case for many other data

00:00:57,520 --> 00:01:01,120
centers out there today

00:00:59,280 --> 00:01:04,239
and we have a tremendous amount of data

00:01:01,120 --> 00:01:06,400
reuse so we built a cache called dtm

00:01:04,239 --> 00:01:07,920
for a single data center and the main

00:01:06,400 --> 00:01:11,600
idea behind

00:01:07,920 --> 00:01:13,760
um the cache that we built is that it

00:01:11,600 --> 00:01:15,200
caches the data at the access side of

00:01:13,760 --> 00:01:17,280
network bottlenecks

00:01:15,200 --> 00:01:18,240
it is a multi-layer cache as you see in

00:01:17,280 --> 00:01:21,200
the fixed

00:01:18,240 --> 00:01:23,280
figure where we store the data on local

00:01:21,200 --> 00:01:26,159
racks and we forward to request to the

00:01:23,280 --> 00:01:29,119
upper layers using consistent hashing

00:01:26,159 --> 00:01:29,680
so um unlike other solutions out there

00:01:29,119 --> 00:01:32,799
today

00:01:29,680 --> 00:01:35,119
like alexio our solution is not a single

00:01:32,799 --> 00:01:37,360
cluster cache it's actually as an

00:01:35,119 --> 00:01:39,040
extension to the existing data lake

00:01:37,360 --> 00:01:41,119
and it's designed in a way that it's

00:01:39,040 --> 00:01:43,759
shared among multiple clusters

00:01:41,119 --> 00:01:44,560
so we put everything in the rgw code and

00:01:43,759 --> 00:01:46,880
the code is

00:01:44,560 --> 00:01:48,240
like upstream now by the red hat

00:01:46,880 --> 00:01:52,240
engineers

00:01:48,240 --> 00:01:55,040
um so we run bunch of experiments

00:01:52,240 --> 00:01:55,840
and we have a paper about this work um

00:01:55,040 --> 00:01:58,799
but overall

00:01:55,840 --> 00:02:00,640
um the implementation imposes minimum

00:01:58,799 --> 00:02:01,920
overhead and it's significantly improved

00:02:00,640 --> 00:02:05,280
the performance of

00:02:01,920 --> 00:02:08,399
um big data analytical workloads we run

00:02:05,280 --> 00:02:12,319
experiments on one of the facebook's um

00:02:08,399 --> 00:02:15,360
mapreduce cluster traces and we see

00:02:12,319 --> 00:02:18,720
a reduction on the back-end traffic and

00:02:15,360 --> 00:02:22,080
improvements on the performance

00:02:18,720 --> 00:02:25,040
so um everything so far um what

00:02:22,080 --> 00:02:26,640
we've done is for a single data center

00:02:25,040 --> 00:02:29,120
but now we want to take

00:02:26,640 --> 00:02:30,560
this work uh and extend it for a hybrid

00:02:29,120 --> 00:02:33,840
cloud use case

00:02:30,560 --> 00:02:34,959
so the value offered by public cloud

00:02:33,840 --> 00:02:37,519
services are

00:02:34,959 --> 00:02:38,959
clear for many workloads however today

00:02:37,519 --> 00:02:40,800
many organizations

00:02:38,959 --> 00:02:42,400
want to keep their data sets in their

00:02:40,800 --> 00:02:42,959
private data center for different

00:02:42,400 --> 00:02:46,800
reasons

00:02:42,959 --> 00:02:50,239
could be calls or security for instance

00:02:46,800 --> 00:02:52,000
two sigma uh financial hedge funds

00:02:50,239 --> 00:02:54,800
and one of our collaborators they use

00:02:52,000 --> 00:02:56,560
spot instances to run their computation

00:02:54,800 --> 00:02:58,080
and they create compute cluster in

00:02:56,560 --> 00:03:00,480
multiple regions and

00:02:58,080 --> 00:03:02,159
however due to the security issues they

00:03:00,480 --> 00:03:04,959
want to keep their data sets

00:03:02,159 --> 00:03:07,440
in their private data sensor and because

00:03:04,959 --> 00:03:09,599
of the current isometric network prices

00:03:07,440 --> 00:03:10,720
companies like two sigma has a strong

00:03:09,599 --> 00:03:14,080
incentive

00:03:10,720 --> 00:03:19,040
for on-premise storage and cache data

00:03:14,080 --> 00:03:22,080
locally in different cloud regions

00:03:19,040 --> 00:03:25,760
um so here is our

00:03:22,080 --> 00:03:28,239
new uh proposed um architecture

00:03:25,760 --> 00:03:29,440
for a hybrid cloud scenario and i'm

00:03:28,239 --> 00:03:33,360
gonna go over

00:03:29,440 --> 00:03:36,400
all of the components um so

00:03:33,360 --> 00:03:39,440
what we did is um

00:03:36,400 --> 00:03:41,360
instead of like in in our previous

00:03:39,440 --> 00:03:42,879
design it was only for read-only and

00:03:41,360 --> 00:03:45,440
intermediate data sets

00:03:42,879 --> 00:03:47,200
however now if we want to cache the data

00:03:45,440 --> 00:03:48,319
on the other side of the wide area in

00:03:47,200 --> 00:03:51,200
networks

00:03:48,319 --> 00:03:52,879
write cache is important so therefore we

00:03:51,200 --> 00:03:55,599
also

00:03:52,879 --> 00:03:57,680
deploy a write cache however rather than

00:03:55,599 --> 00:03:58,239
implementing a replicated durable write

00:03:57,680 --> 00:04:00,400
cache

00:03:58,239 --> 00:04:01,840
we use the existing ceph code and send

00:04:00,400 --> 00:04:05,040
up a local osd

00:04:01,840 --> 00:04:06,400
cluster as a cache layer in each public

00:04:05,040 --> 00:04:09,840
cloud region

00:04:06,400 --> 00:04:12,560
and also as you see we have read caches

00:04:09,840 --> 00:04:15,760
collocated with them so read cache in

00:04:12,560 --> 00:04:18,320
this in our design stores data in like

00:04:15,760 --> 00:04:20,400
block granularity um however in the

00:04:18,320 --> 00:04:23,520
right cache we store data in object

00:04:20,400 --> 00:04:25,680
granularity and any data coming from

00:04:23,520 --> 00:04:27,600
the client is first written into the

00:04:25,680 --> 00:04:30,960
right cache and once the

00:04:27,600 --> 00:04:34,560
data is aged um after some time

00:04:30,960 --> 00:04:36,960
um rados gateway uh flash the data

00:04:34,560 --> 00:04:38,800
to the back end so we have also like

00:04:36,960 --> 00:04:40,320
inclusive cache model here where the

00:04:38,800 --> 00:04:43,440
same objects

00:04:40,320 --> 00:04:44,000
can be present in baltery than a right

00:04:43,440 --> 00:04:47,360
cache

00:04:44,000 --> 00:04:50,560
and in the right cache we also use um

00:04:47,360 --> 00:04:52,000
erasure coding uh we are still exploring

00:04:50,560 --> 00:04:55,440
its performance and

00:04:52,000 --> 00:04:56,800
um the right uh redundancy uh in the

00:04:55,440 --> 00:05:00,080
right cache

00:04:56,800 --> 00:05:02,400
the second thing we've done is um

00:05:00,080 --> 00:05:04,479
in our previous design we were using

00:05:02,400 --> 00:05:05,840
consistent hashing to locate the objects

00:05:04,479 --> 00:05:08,320
in the caches

00:05:05,840 --> 00:05:09,199
because it was simple it doesn't require

00:05:08,320 --> 00:05:11,520
any protocol

00:05:09,199 --> 00:05:13,520
changes and it was like easily upstream

00:05:11,520 --> 00:05:15,039
however now we have a right cache we

00:05:13,520 --> 00:05:17,120
need a directory to

00:05:15,039 --> 00:05:19,440
know where the data is stored and to

00:05:17,120 --> 00:05:21,840
prevent any data loss

00:05:19,440 --> 00:05:24,240
directory must be durable and reliable

00:05:21,840 --> 00:05:27,199
so in the implementation we are using

00:05:24,240 --> 00:05:28,160
redis as a directory and a radar's

00:05:27,199 --> 00:05:31,440
gateways

00:05:28,160 --> 00:05:35,039
uh contact like talk to the redis

00:05:31,440 --> 00:05:37,680
and get the location of each um objects

00:05:35,039 --> 00:05:38,960
and forward their request to retrieve

00:05:37,680 --> 00:05:43,039
that objects

00:05:38,960 --> 00:05:46,160
so the directory stores um information

00:05:43,039 --> 00:05:48,560
for each blocks objects um

00:05:46,160 --> 00:05:49,919
and this is just an example it acts as a

00:05:48,560 --> 00:05:53,759
database

00:05:49,919 --> 00:05:56,000
um and also other um information

00:05:53,759 --> 00:05:57,840
in the system like cash service itself

00:05:56,000 --> 00:05:58,319
what is their capacity what is the hit

00:05:57,840 --> 00:06:01,600
rate

00:05:58,319 --> 00:06:05,520
heat count what is the bandwidth um

00:06:01,600 --> 00:06:08,960
so and the other thing is like um

00:06:05,520 --> 00:06:10,720
rgw's like doesn't aware of

00:06:08,960 --> 00:06:13,120
like how the data is indexed in

00:06:10,720 --> 00:06:15,600
directory so directory really act like a

00:06:13,120 --> 00:06:17,919
database and it just serves the queries

00:06:15,600 --> 00:06:20,319
and in the future not just like our

00:06:17,919 --> 00:06:22,080
cache services but we also want

00:06:20,319 --> 00:06:24,560
other components in like analytic

00:06:22,080 --> 00:06:25,520
clusters to talk to the directory for

00:06:24,560 --> 00:06:28,560
example

00:06:25,520 --> 00:06:30,960
cluster schedulers like yarn or uh

00:06:28,560 --> 00:06:31,919
to allocate the jobs based on where the

00:06:30,960 --> 00:06:35,360
data is like

00:06:31,919 --> 00:06:38,080
cached right or your kubernetes

00:06:35,360 --> 00:06:39,680
or your like dns server then they

00:06:38,080 --> 00:06:42,000
forward to the request

00:06:39,680 --> 00:06:44,240
um based on i don't know like cache

00:06:42,000 --> 00:06:46,639
servers load for example or

00:06:44,240 --> 00:06:48,240
certain damage information so that

00:06:46,639 --> 00:06:50,720
directory like really

00:06:48,240 --> 00:06:51,360
in the in the future will provide us a

00:06:50,720 --> 00:06:53,680
lot of

00:06:51,360 --> 00:06:54,880
information which not just the cache but

00:06:53,680 --> 00:06:59,440
other components

00:06:54,880 --> 00:07:01,759
of this entire ecosystem can benefit

00:06:59,440 --> 00:07:03,919
and finally when you're in a single data

00:07:01,759 --> 00:07:05,360
center you usually have a fix

00:07:03,919 --> 00:07:07,039
not usually but all the time you have a

00:07:05,360 --> 00:07:09,039
fixed network topology

00:07:07,039 --> 00:07:10,080
and in our previous design we were using

00:07:09,039 --> 00:07:12,000
any caspase

00:07:10,080 --> 00:07:14,639
lookup service to locate the cast

00:07:12,000 --> 00:07:15,360
services however when we are in a public

00:07:14,639 --> 00:07:16,960
cloud

00:07:15,360 --> 00:07:18,400
you know we cannot take advantage of the

00:07:16,960 --> 00:07:20,800
topology in the same way

00:07:18,400 --> 00:07:21,440
because there is no topology so

00:07:20,800 --> 00:07:25,199
therefore

00:07:21,440 --> 00:07:27,360
uh we are uh we will use the kubernetes

00:07:25,199 --> 00:07:29,039
dns servers to forward the client's

00:07:27,360 --> 00:07:33,520
request to the nearest

00:07:29,039 --> 00:07:33,520
cache um in the in the region

00:07:34,080 --> 00:07:42,240
and finally um most of the

00:07:37,599 --> 00:07:44,000
object stores today um use s3 protocol

00:07:42,240 --> 00:07:45,360
and we want to generalize our cache

00:07:44,000 --> 00:07:47,759
implementation we just

00:07:45,360 --> 00:07:48,720
want to support you know multiple data

00:07:47,759 --> 00:07:51,759
lakes not just

00:07:48,720 --> 00:07:54,400
sev um therefore um

00:07:51,759 --> 00:07:55,039
we are using s3 for this purpose and

00:07:54,400 --> 00:07:57,039
this way

00:07:55,039 --> 00:07:58,080
you know we can deploy these cache

00:07:57,039 --> 00:08:00,240
caches

00:07:58,080 --> 00:08:01,360
not only in front of the cef but any

00:08:00,240 --> 00:08:05,680
other um

00:08:01,360 --> 00:08:07,520
data lake like s3 or mineo or

00:08:05,680 --> 00:08:09,520
nothing comes to my mind right now but

00:08:07,520 --> 00:08:13,840
whatever support s3

00:08:09,520 --> 00:08:13,840
and um

00:08:16,479 --> 00:08:24,000
so what we have in here is

00:08:20,080 --> 00:08:24,560
um there's like the there has been over

00:08:24,000 --> 00:08:27,759
like

00:08:24,560 --> 00:08:30,319
you know um

00:08:27,759 --> 00:08:31,199
half a century of research into the

00:08:30,319 --> 00:08:34,080
caching

00:08:31,199 --> 00:08:37,200
techniques in multi-processors file

00:08:34,080 --> 00:08:39,599
system web caches right now however

00:08:37,200 --> 00:08:40,640
we have this like huge opportunity with

00:08:39,599 --> 00:08:42,880
the global

00:08:40,640 --> 00:08:44,640
uh or with the share this directory

00:08:42,880 --> 00:08:45,120
right and we want to look at we are

00:08:44,640 --> 00:08:47,519
right

00:08:45,120 --> 00:08:49,360
right now currently looking at how can

00:08:47,519 --> 00:08:52,560
we use this directory to

00:08:49,360 --> 00:08:52,959
do better cash management right because

00:08:52,560 --> 00:08:54,720
as i

00:08:52,959 --> 00:08:56,560
mentioned in earlier sliders in the

00:08:54,720 --> 00:08:58,160
directory you know we store

00:08:56,560 --> 00:09:00,800
huge amount of information about the

00:08:58,160 --> 00:09:04,000
data we store who is accessing data

00:09:00,800 --> 00:09:05,680
what um you know what is the access size

00:09:04,000 --> 00:09:07,920
how frequently they are accessing

00:09:05,680 --> 00:09:09,600
what applications they are accessing

00:09:07,920 --> 00:09:12,480
like and

00:09:09,600 --> 00:09:14,240
basically we have like the information

00:09:12,480 --> 00:09:16,000
about like the entire system what's

00:09:14,240 --> 00:09:18,240
going on in our system

00:09:16,000 --> 00:09:20,080
the second thing is when we are in the

00:09:18,240 --> 00:09:21,519
when we are dealing with object source

00:09:20,080 --> 00:09:24,560
it's different than

00:09:21,519 --> 00:09:25,440
for example like cpus right like in here

00:09:24,560 --> 00:09:27,600
we are

00:09:25,440 --> 00:09:28,800
dealing with like large granularity

00:09:27,600 --> 00:09:30,880
object accesses

00:09:28,800 --> 00:09:32,640
for instance in ceph i can say it's like

00:09:30,880 --> 00:09:34,480
formic each object is forming

00:09:32,640 --> 00:09:36,160
every time you're reading or writing for

00:09:34,480 --> 00:09:39,600
make chunks right

00:09:36,160 --> 00:09:43,360
and these are also immutable so

00:09:39,600 --> 00:09:46,560
these these these unique uh

00:09:43,360 --> 00:09:48,399
these unique features um provide us the

00:09:46,560 --> 00:09:50,480
opportunity to explore

00:09:48,399 --> 00:09:52,720
uh different caching techniques

00:09:50,480 --> 00:09:54,399
different than prior works like on cpus

00:09:52,720 --> 00:09:56,720
or other web caches right

00:09:54,399 --> 00:09:57,519
so we can now run simple heuristic or

00:09:56,720 --> 00:09:59,120
even like

00:09:57,519 --> 00:10:00,800
machine learning techniques to find

00:09:59,120 --> 00:10:02,480
common access patterns

00:10:00,800 --> 00:10:04,000
for example we know that like our

00:10:02,480 --> 00:10:06,800
objects which are written many

00:10:04,000 --> 00:10:07,360
times never reads or hot objects or cold

00:10:06,800 --> 00:10:10,480
objects

00:10:07,360 --> 00:10:12,160
and can we detect these patterns and so

00:10:10,480 --> 00:10:13,279
our key idea right now that we are

00:10:12,160 --> 00:10:16,240
working on this

00:10:13,279 --> 00:10:18,000
cash management scheme is that um we

00:10:16,240 --> 00:10:20,000
want to make sure objects spend enough

00:10:18,000 --> 00:10:22,560
time in the cache and then we learn

00:10:20,000 --> 00:10:23,760
about uh each objects and each each

00:10:22,560 --> 00:10:25,680
accesses

00:10:23,760 --> 00:10:27,279
and then we can find the right

00:10:25,680 --> 00:10:29,360
candidates for eviction

00:10:27,279 --> 00:10:30,560
we also want to use this information

00:10:29,360 --> 00:10:33,760
store in directory

00:10:30,560 --> 00:10:37,920
and use this like historical based

00:10:33,760 --> 00:10:41,040
approach to predict feature accesses

00:10:37,920 --> 00:10:43,360
so um where are we going now um

00:10:41,040 --> 00:10:45,040
so this design and implementation allow

00:10:43,360 --> 00:10:47,920
us to do all interesting

00:10:45,040 --> 00:10:48,880
research um as i mentioned directory

00:10:47,920 --> 00:10:51,760
provide us

00:10:48,880 --> 00:10:53,360
now a global cache view and we want to

00:10:51,760 --> 00:10:55,519
build a platform

00:10:53,360 --> 00:10:57,279
for other researchers to use the

00:10:55,519 --> 00:11:00,160
directory and explore different cache

00:10:57,279 --> 00:11:03,279
management algorithms different policies

00:11:00,160 --> 00:11:05,600
um we want to build a cache not for a

00:11:03,279 --> 00:11:06,079
single data lake but for multiple data

00:11:05,600 --> 00:11:08,640
lakes

00:11:06,079 --> 00:11:10,240
geo distributed data lakes for instance

00:11:08,640 --> 00:11:13,040
the open storage network

00:11:10,240 --> 00:11:14,480
deploy one petabyte data lakes all

00:11:13,040 --> 00:11:16,560
around the country and one of the

00:11:14,480 --> 00:11:19,600
problem they are facing today is

00:11:16,560 --> 00:11:21,680
there each user has to define which uh

00:11:19,600 --> 00:11:23,360
where to store their data which data

00:11:21,680 --> 00:11:25,680
like they have to store data

00:11:23,360 --> 00:11:27,519
so can we use the caching and do this

00:11:25,680 --> 00:11:29,600
more automatically and

00:11:27,519 --> 00:11:31,839
can we place the data on behalf of the

00:11:29,600 --> 00:11:34,079
user without user telling us like

00:11:31,839 --> 00:11:36,640
can we place i don't know user ace data

00:11:34,079 --> 00:11:39,760
in data like a user

00:11:36,640 --> 00:11:41,120
b data in data lake and for instance

00:11:39,760 --> 00:11:44,560
right

00:11:41,120 --> 00:11:45,200
also we want to explore like how erasure

00:11:44,560 --> 00:11:48,079
coding

00:11:45,200 --> 00:11:48,560
works in the cache layer and this hasn't

00:11:48,079 --> 00:11:51,200
done

00:11:48,560 --> 00:11:53,279
much in in the literature as well and

00:11:51,200 --> 00:11:57,120
not redundantly store the data

00:11:53,279 --> 00:12:00,959
in cache um we are also interesting

00:11:57,120 --> 00:12:03,040
in uh looking um where do we

00:12:00,959 --> 00:12:04,320
run the computation of the data for

00:12:03,040 --> 00:12:07,440
example

00:12:04,320 --> 00:12:08,240
um you know one example is that if you

00:12:07,440 --> 00:12:10,959
have the

00:12:08,240 --> 00:12:13,360
data cache in region one then can we

00:12:10,959 --> 00:12:15,760
spin up the cluster in region one

00:12:13,360 --> 00:12:16,399
or the other way around right you spin

00:12:15,760 --> 00:12:18,880
up your

00:12:16,399 --> 00:12:19,760
clusters post instances in let's say

00:12:18,880 --> 00:12:21,519
region and

00:12:19,760 --> 00:12:23,360
then can we prefetch data before

00:12:21,519 --> 00:12:25,839
computation starts

00:12:23,360 --> 00:12:27,279
uh so we are looking at these uh these

00:12:25,839 --> 00:12:30,399
techniques as well

00:12:27,279 --> 00:12:34,320
and um to finally to

00:12:30,399 --> 00:12:37,279
realistically you know um design

00:12:34,320 --> 00:12:38,079
all the things that we mentioned uh we

00:12:37,279 --> 00:12:41,200
need

00:12:38,079 --> 00:12:43,920
real system traces right and because

00:12:41,200 --> 00:12:45,040
these traces these logs will help us

00:12:43,920 --> 00:12:48,800
understand better

00:12:45,040 --> 00:12:52,000
each application each user of

00:12:48,800 --> 00:12:54,399
each like jobs and this way we can

00:12:52,000 --> 00:12:55,519
provide uh we can develop better

00:12:54,399 --> 00:12:58,399
algorithms

00:12:55,519 --> 00:12:59,600
and improve the cash management um

00:12:58,399 --> 00:13:02,240
efficiency

00:12:59,600 --> 00:13:04,240
so you know if anyone who is listening

00:13:02,240 --> 00:13:06,000
this talk has such a traces or would

00:13:04,240 --> 00:13:07,920
like to talk about more about that i

00:13:06,000 --> 00:13:11,680
will be happy to chat

00:13:07,920 --> 00:13:15,600
um also as i mentioned um

00:13:11,680 --> 00:13:19,600
um the the first version of the cache

00:13:15,600 --> 00:13:22,880
the chan is um upstream and you can

00:13:19,600 --> 00:13:25,440
find the details from our link for

00:13:22,880 --> 00:13:27,120
the hybrid cloud cache implementation is

00:13:25,440 --> 00:13:30,720
also on github

00:13:27,120 --> 00:13:33,440
it's like um you can download and

00:13:30,720 --> 00:13:35,200
um play with it we are still like

00:13:33,440 --> 00:13:36,639
updating the github repo

00:13:35,200 --> 00:13:38,800
whenever like we have new

00:13:36,639 --> 00:13:41,360
functionalities um

00:13:38,800 --> 00:13:43,040
and also um we are right now working on

00:13:41,360 --> 00:13:44,959
a simulation for this like cash

00:13:43,040 --> 00:13:47,279
management algorithm um

00:13:44,959 --> 00:13:49,040
that code is not available right now but

00:13:47,279 --> 00:13:50,560
hopefully it will be available soon on

00:13:49,040 --> 00:13:53,040
our guitar people as well

00:13:50,560 --> 00:13:54,480
and if you want to learn more about uh

00:13:53,040 --> 00:13:58,800
our projects

00:13:54,480 --> 00:14:02,000
uh please visit our webpages um

00:13:58,800 --> 00:14:02,399
so i believe that's all i'm happy to you

00:14:02,000 --> 00:14:17,839
know

00:14:02,399 --> 00:14:17,839
answer any questions um you have

00:14:19,279 --> 00:14:27,519
i am just going through the chats

00:14:23,519 --> 00:14:31,279
and i don't see any questions

00:14:27,519 --> 00:14:34,399
um so maybe we can give

00:14:31,279 --> 00:14:34,399
folks a few minutes

00:14:35,440 --> 00:14:42,800
okay sure and see if anything should

00:14:39,040 --> 00:14:44,800
come through otherwise we'll just uh

00:14:42,800 --> 00:14:45,839
we'll just move over to the break room

00:14:44,800 --> 00:14:51,279
break out sure

00:14:45,839 --> 00:14:51,279
yeah oh okay somebody shared the

00:14:55,760 --> 00:15:00,880
oh so i have to leave if i um

00:14:58,880 --> 00:15:02,160
should i stop sharing you can stop

00:15:00,880 --> 00:15:04,639
sharing them okay

00:15:02,160 --> 00:15:04,639
great

00:15:10,839 --> 00:15:13,839
yes

00:15:14,959 --> 00:15:19,920
all right people um

00:15:18,240 --> 00:15:21,440
i guess we don't have questions okay

00:15:19,920 --> 00:15:24,800
that's fine we're very

00:15:21,440 --> 00:15:26,399
clear or oh that's good we appreciate

00:15:24,800 --> 00:15:28,079
your time so much thank you

00:15:26,399 --> 00:15:29,680
no problem so i have to move to the

00:15:28,079 --> 00:15:32,399
breakout room right now right

00:15:29,680 --> 00:15:32,959
yes yes okay all right thanks for

00:15:32,399 --> 00:15:38,480
listening

00:15:32,959 --> 00:15:38,480

YouTube URL: https://www.youtube.com/watch?v=JXbdm359q4E


