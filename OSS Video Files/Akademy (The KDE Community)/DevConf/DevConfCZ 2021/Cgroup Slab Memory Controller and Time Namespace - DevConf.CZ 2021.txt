Title: Cgroup Slab Memory Controller and Time Namespace - DevConf.CZ 2021
Publication date: 2021-03-12
Playlist: DevConfCZ 2021
Description: 
	Speaker: Waiman Long


Control group (cgroup) and namespace are the two major features in the Linux kernel that make containers possible.

There are some exciting new cgroup and namespace features in the latest Linux kernel that can improve the container experience. This talk will focus on two major features that are being back-ported to the RHEL8 kernel, namely the new cgroup slab memory controller and time namespace. This talk will describe what these features are and some discussion on their underlying implementation as well as what improvement they will bring to the container experience. 


Schedule: https://sched.co/gmMn
Captions: 
	00:00:01,120 --> 00:00:05,120
good afternoon uh ladies and gentlemen

00:00:03,199 --> 00:00:08,960
uh my name is um

00:00:05,120 --> 00:00:12,639
women law i'm a software engineer

00:00:08,960 --> 00:00:15,839
in the webhead core kernel group

00:00:12,639 --> 00:00:18,960
my main responsibility is

00:00:15,839 --> 00:00:21,039
to maintain the uh the c group

00:00:18,960 --> 00:00:22,960
as well as the locking subsystem in the

00:00:21,039 --> 00:00:26,080
kernel

00:00:22,960 --> 00:00:29,599
um so today uh the topic is about

00:00:26,080 --> 00:00:31,679
the um this the news

00:00:29,599 --> 00:00:33,120
two major new features uh in the

00:00:31,679 --> 00:00:36,000
upcoming release of

00:00:33,120 --> 00:00:38,960
well uh which is uh we paper from the

00:00:36,000 --> 00:00:38,960
upstream kernel

00:00:41,040 --> 00:00:46,960
so uh

00:00:44,160 --> 00:00:48,960
you know that that within the the linux

00:00:46,960 --> 00:00:51,760
kernel there are two main features

00:00:48,960 --> 00:00:53,840
that enable uh make container possible

00:00:51,760 --> 00:00:56,000
the two features are the

00:00:53,840 --> 00:00:56,879
control group or we usually call it

00:00:56,000 --> 00:01:00,000
seagull

00:00:56,879 --> 00:01:00,399
as well as the namespace without these

00:01:00,000 --> 00:01:04,400
two

00:01:00,399 --> 00:01:08,479
um we don't we won't have any

00:01:04,400 --> 00:01:11,040
linux container and

00:01:08,479 --> 00:01:12,000
the two new features i'm planning to

00:01:11,040 --> 00:01:16,320
elaborate a bit

00:01:12,000 --> 00:01:18,479
more on today is the the new segment

00:01:16,320 --> 00:01:20,560
c group slab memory controller that i

00:01:18,479 --> 00:01:23,680
introduced in the

00:01:20,560 --> 00:01:26,720
version 5.9 kernel

00:01:23,680 --> 00:01:27,360
as well as the the time namespace which

00:01:26,720 --> 00:01:30,400
are

00:01:27,360 --> 00:01:34,960
i think introduced earlier

00:01:30,400 --> 00:01:38,799
maybe five six or seven um

00:01:34,960 --> 00:01:40,479
and and besides these two main features

00:01:38,799 --> 00:01:43,920
there are also other

00:01:40,479 --> 00:01:46,960
worldwide um important features that um

00:01:43,920 --> 00:01:47,920
i would definitely talk about um that

00:01:46,960 --> 00:01:50,079
include

00:01:47,920 --> 00:01:51,280
that will be included in the the next

00:01:50,079 --> 00:01:54,320
release of the

00:01:51,280 --> 00:01:57,520
well kernel that include the ability

00:01:54,320 --> 00:01:58,560
to um to limit memory allocation when

00:01:57,520 --> 00:02:02,079
you are

00:01:58,560 --> 00:02:05,520
when your your memory controller

00:02:02,079 --> 00:02:09,039
is reaching the memory limit

00:02:05,520 --> 00:02:12,080
and that can have uh

00:02:09,039 --> 00:02:13,120
they can try they can avoid the our

00:02:12,080 --> 00:02:15,280
memory kill

00:02:13,120 --> 00:02:16,640
that may sometimes happen if the

00:02:15,280 --> 00:02:18,400
application within the con

00:02:16,640 --> 00:02:20,239
container just happened to be using too

00:02:18,400 --> 00:02:23,280
much memory then

00:02:20,239 --> 00:02:27,280
is allocated to the container um

00:02:23,280 --> 00:02:29,760
and and also um

00:02:27,280 --> 00:02:30,480
we are now able to account the use of

00:02:29,760 --> 00:02:34,000
the per

00:02:30,480 --> 00:02:36,480
cpu memory in in the kernel

00:02:34,000 --> 00:02:38,560
as well as the other regular slab memory

00:02:36,480 --> 00:02:41,360
or pay cash memory

00:02:38,560 --> 00:02:42,560
and we also integrate some better web

00:02:41,360 --> 00:02:47,120
back control

00:02:42,560 --> 00:02:49,200
that will help to limit in the number of

00:02:47,120 --> 00:02:50,480
unexpected hand that can happen because

00:02:49,200 --> 00:02:54,239
of the

00:02:50,480 --> 00:02:57,440
i o imbalance inherently in some of the

00:02:54,239 --> 00:02:57,440
application use cases

00:02:57,840 --> 00:03:05,040
so um before doing

00:03:01,040 --> 00:03:07,440
deeper i would like to talk about that

00:03:05,040 --> 00:03:08,319
you know about the control group in the

00:03:07,440 --> 00:03:10,319
business kernel

00:03:08,319 --> 00:03:12,080
there actually two different versions

00:03:10,319 --> 00:03:13,440
there's the weaving version and then the

00:03:12,080 --> 00:03:15,840
v2 version

00:03:13,440 --> 00:03:17,200
the real lesson is what we call the

00:03:15,840 --> 00:03:20,800
legacy

00:03:17,200 --> 00:03:24,000
implementation and

00:03:20,800 --> 00:03:26,080
and then the v2 is the newer one

00:03:24,000 --> 00:03:28,239
and most of the new feature

00:03:26,080 --> 00:03:31,280
[Music]

00:03:28,239 --> 00:03:33,760
will go to sql v2 because this is the

00:03:31,280 --> 00:03:36,959
one that under attack development

00:03:33,760 --> 00:03:38,000
v1 is kind of in the maintenance mode we

00:03:36,959 --> 00:03:40,480
tried

00:03:38,000 --> 00:03:41,280
to make sure that nothing breaks but we

00:03:40,480 --> 00:03:46,080
are

00:03:41,280 --> 00:03:48,480
less likely to add new feature into it

00:03:46,080 --> 00:03:50,080
and the major difference between the two

00:03:48,480 --> 00:03:53,120
uh version is that i

00:03:50,080 --> 00:03:55,439
in simultaneous um each

00:03:53,120 --> 00:03:56,319
different controller can have its own

00:03:55,439 --> 00:03:58,319
hierarchy

00:03:56,319 --> 00:04:00,080
so every controller can have hierarchy

00:03:58,319 --> 00:04:02,720
that are completely different from

00:04:00,080 --> 00:04:02,720
from the other

00:04:03,519 --> 00:04:09,040
it appear well from

00:04:07,360 --> 00:04:11,120
from the top level it seems like that

00:04:09,040 --> 00:04:12,879
can be more flexible

00:04:11,120 --> 00:04:14,319
but on the hand that increase the

00:04:12,879 --> 00:04:16,320
capacity

00:04:14,319 --> 00:04:18,420
especially when you need to coordination

00:04:16,320 --> 00:04:20,000
between different controller

00:04:18,420 --> 00:04:22,479
[Music]

00:04:20,000 --> 00:04:23,440
so that is the main reason why we have a

00:04:22,479 --> 00:04:26,560
separate v2

00:04:23,440 --> 00:04:28,800
and in single v2 the the

00:04:26,560 --> 00:04:30,560
major theme is that there is only one

00:04:28,800 --> 00:04:31,759
unified hierarchy for all the

00:04:30,560 --> 00:04:35,040
controllers that are

00:04:31,759 --> 00:04:37,040
supported in the v2 mode so instead of

00:04:35,040 --> 00:04:39,040
different hierarchy for each controller

00:04:37,040 --> 00:04:40,160
we have one single hierarchy for all the

00:04:39,040 --> 00:04:43,600
controllers that are running

00:04:40,160 --> 00:04:46,960
in single v2 mode by the way um

00:04:43,600 --> 00:04:48,240
a controller can be running in either v1

00:04:46,960 --> 00:04:50,639
or v2 but not both

00:04:48,240 --> 00:04:52,240
so when you set up the system you have

00:04:50,639 --> 00:04:54,840
to choose whether you want

00:04:52,240 --> 00:04:56,320
a given controller to be used in v1 or

00:04:54,840 --> 00:04:59,520
v2

00:04:56,320 --> 00:05:02,160
and currently

00:04:59,520 --> 00:05:02,800
i think most distribution are still

00:05:02,160 --> 00:05:05,680
using

00:05:02,800 --> 00:05:07,039
v1 as a default because this is what

00:05:05,680 --> 00:05:10,080
people used to be

00:05:07,039 --> 00:05:13,680
using in the past but the trend

00:05:10,080 --> 00:05:16,960
is over time more and more um

00:05:13,680 --> 00:05:18,080
this show will switch to v2 as the

00:05:16,960 --> 00:05:20,880
default

00:05:18,080 --> 00:05:21,360
because uh this is where the the new

00:05:20,880 --> 00:05:24,479
feature

00:05:21,360 --> 00:05:26,240
are coming from and so if uh

00:05:24,479 --> 00:05:28,639
if you want to get some new feature

00:05:26,240 --> 00:05:30,960
they're only in v2 but not in v1

00:05:28,639 --> 00:05:38,320
the only way is you switched it to

00:05:30,960 --> 00:05:41,360
sequel v2 instead of v1

00:05:38,320 --> 00:05:45,120
okay um now i talk about the

00:05:41,360 --> 00:05:48,240
the new secret uh slap moment controller

00:05:45,120 --> 00:05:50,720
um you know within the kernel um

00:05:48,240 --> 00:05:52,560
besides the the page cache that i use

00:05:50,720 --> 00:05:56,080
for

00:05:52,560 --> 00:05:59,360
to caching enormous

00:05:56,080 --> 00:06:01,360
memory or also the file file data

00:05:59,360 --> 00:06:02,720
there's also another set of kernel

00:06:01,360 --> 00:06:05,759
memory that used

00:06:02,720 --> 00:06:09,039
by all the internal data structure that

00:06:05,759 --> 00:06:09,039
are created in the kernel

00:06:09,840 --> 00:06:14,960
and the the origin

00:06:13,120 --> 00:06:16,160
the current implementation not the

00:06:14,960 --> 00:06:19,520
current um the

00:06:16,160 --> 00:06:21,759
the old implementation of this slab

00:06:19,520 --> 00:06:23,280
controller is that whenever you create a

00:06:21,759 --> 00:06:27,520
new memory system

00:06:23,280 --> 00:06:30,479
um you have to create a parallel set of

00:06:27,520 --> 00:06:32,639
slab cache so for instance you want to

00:06:30,479 --> 00:06:34,960
create a new process you need a

00:06:32,639 --> 00:06:37,039
task structure in the kernel for each of

00:06:34,960 --> 00:06:39,199
the new

00:06:37,039 --> 00:06:40,880
new thread on the process that you

00:06:39,199 --> 00:06:43,759
created in the kernel

00:06:40,880 --> 00:06:44,160
and the memory for that structure come

00:06:43,759 --> 00:06:48,639
from

00:06:44,160 --> 00:06:52,080
a slab cache they are created by

00:06:48,639 --> 00:06:53,520
uh when the systems are up and there are

00:06:52,080 --> 00:06:57,360
many different types of structure

00:06:53,520 --> 00:07:01,440
uh in the kernel um

00:06:57,360 --> 00:07:02,800
and from a look of the number of caches

00:07:01,440 --> 00:07:06,080
available

00:07:02,800 --> 00:07:09,110
there i the kind is

00:07:06,080 --> 00:07:10,240
around 250 or so

00:07:09,110 --> 00:07:13,520
[Music]

00:07:10,240 --> 00:07:16,080
more or less so

00:07:13,520 --> 00:07:17,360
that means that whenever you create a

00:07:16,080 --> 00:07:20,560
new controller

00:07:17,360 --> 00:07:24,080
um when i create a new sql

00:07:20,560 --> 00:07:28,479
and you try to use this the slap cache

00:07:24,080 --> 00:07:33,039
then you create and pair set of

00:07:28,479 --> 00:07:36,319
slack whenever the process within the

00:07:33,039 --> 00:07:38,960
container use that type of structure

00:07:36,319 --> 00:07:39,840
of need to create or allocate those

00:07:38,960 --> 00:07:43,360
structure

00:07:39,840 --> 00:07:46,400
in the kernel and

00:07:43,360 --> 00:07:47,520
associated with each slab cache you can

00:07:46,400 --> 00:07:49,540
see from the diagram

00:07:47,520 --> 00:07:51,039
that each

00:07:49,540 --> 00:07:54,080
[Music]

00:07:51,039 --> 00:07:55,440
each sql have an associative subcash and

00:07:54,080 --> 00:07:57,759
when you slap cash because of

00:07:55,440 --> 00:08:01,440
performance reason

00:07:57,759 --> 00:08:01,440
each slab cash has

00:08:01,520 --> 00:08:05,360
have a type of per node as well per cpu

00:08:04,720 --> 00:08:10,160
cash

00:08:05,360 --> 00:08:13,440
so with so each cpu that use the um

00:08:10,160 --> 00:08:16,720
that used within the container

00:08:13,440 --> 00:08:20,160
um you create a cache of

00:08:16,720 --> 00:08:24,080
usually about a field slab

00:08:20,160 --> 00:08:27,120
that are dedicated to each cpu

00:08:24,080 --> 00:08:29,759
as a cache and but within that those lab

00:08:27,120 --> 00:08:30,639
not all the um available objects are

00:08:29,759 --> 00:08:33,039
allocated

00:08:30,639 --> 00:08:34,399
some are waiting to be allocated uh when

00:08:33,039 --> 00:08:37,519
they need advices

00:08:34,399 --> 00:08:40,560
um and because of that each cpu will

00:08:37,519 --> 00:08:44,399
kind of hold up a

00:08:40,560 --> 00:08:47,040
number of pages or pages of memory

00:08:44,399 --> 00:08:48,320
that are aside for that cpu but not

00:08:47,040 --> 00:08:51,519
fully utilized

00:08:48,320 --> 00:08:53,600
as a result um if you

00:08:51,519 --> 00:08:54,560
if there's a need or create many

00:08:53,600 --> 00:08:57,600
containers

00:08:54,560 --> 00:08:59,279
or many memory sequels in the system a

00:08:57,600 --> 00:09:02,800
lot of memory can get held up

00:08:59,279 --> 00:09:04,580
by those slab cache and

00:09:02,800 --> 00:09:07,440
is estimated

00:09:04,580 --> 00:09:09,920
[Music]

00:09:07,440 --> 00:09:10,560
in in the modern system uh modern

00:09:09,920 --> 00:09:14,080
digital

00:09:10,560 --> 00:09:16,560
like um well about roughly half

00:09:14,080 --> 00:09:18,399
megabyte of memory we will consume uh

00:09:16,560 --> 00:09:19,760
for each of the cpu that are used in a

00:09:18,399 --> 00:09:22,160
given membership

00:09:19,760 --> 00:09:24,959
uh give or take depending on the

00:09:22,160 --> 00:09:29,839
acceptable lawyer that you're running

00:09:24,959 --> 00:09:29,839
so that can be quite a lot of memory

00:09:32,240 --> 00:09:36,560
so the now i'm going to talk about the

00:09:35,760 --> 00:09:40,000
neo

00:09:36,560 --> 00:09:42,720
seagull slap memory controller the major

00:09:40,000 --> 00:09:45,120
difference between the new controller

00:09:42,720 --> 00:09:47,120
versus the one is that

00:09:45,120 --> 00:09:48,959
all the memory sequel will share the

00:09:47,120 --> 00:09:53,440
same set of slab cache

00:09:48,959 --> 00:09:56,880
so instead of um and slapcast for n

00:09:53,440 --> 00:10:00,640
um membership now we have a single set

00:09:56,880 --> 00:10:04,160
of slot cash share by all the membership

00:10:00,640 --> 00:10:08,000
but in order to manage the accounting

00:10:04,160 --> 00:10:11,040
of the memory allocated to each of the

00:10:08,000 --> 00:10:11,600
c group uh we have we now have a new

00:10:11,040 --> 00:10:14,720
structure

00:10:11,600 --> 00:10:16,000
that at a pitch between the the slab

00:10:14,720 --> 00:10:18,959
cast and the c group

00:10:16,000 --> 00:10:19,920
we call that the object sql structure so

00:10:18,959 --> 00:10:21,600
the

00:10:19,920 --> 00:10:23,440
the objective the purpose of that

00:10:21,600 --> 00:10:27,200
structure is

00:10:23,440 --> 00:10:29,519
to do the the accounting um

00:10:27,200 --> 00:10:30,800
of memory that they are dedicated to

00:10:29,519 --> 00:10:35,519
each of the

00:10:30,800 --> 00:10:35,519
dc group and the way it does that is um

00:10:35,760 --> 00:10:41,760
in in the old controller um

00:10:39,040 --> 00:10:42,800
the use the mem the usage of memory by

00:10:41,760 --> 00:10:45,760
each of the

00:10:42,800 --> 00:10:47,360
c group is accounted in in pages number

00:10:45,760 --> 00:10:50,640
of pages that are used

00:10:47,360 --> 00:10:53,760
by uh is sequel but

00:10:50,640 --> 00:10:57,200
with the new um select controller is

00:10:53,760 --> 00:10:59,360
content by itself pages so

00:10:57,200 --> 00:11:00,480
and the pie counting is done in the

00:10:59,360 --> 00:11:02,880
object sequel

00:11:00,480 --> 00:11:03,839
so if there if the number by um

00:11:02,880 --> 00:11:06,399
accumulate

00:11:03,839 --> 00:11:07,760
a count in the objective which more than

00:11:06,399 --> 00:11:11,040
a page

00:11:07,760 --> 00:11:14,720
it will the the

00:11:11,040 --> 00:11:18,800
resulting page number will be um

00:11:14,720 --> 00:11:21,680
will be allocated in in another

00:11:18,800 --> 00:11:23,760
sql structure and and then the object

00:11:21,680 --> 00:11:26,240
sql is mainly used for keeping

00:11:23,760 --> 00:11:28,560
keeping check of the number by data

00:11:26,240 --> 00:11:30,720
within less than a page

00:11:28,560 --> 00:11:32,160
so because uh each of the kernel data

00:11:30,720 --> 00:11:34,800
structure the size

00:11:32,160 --> 00:11:36,160
actually varies they vary from uh as

00:11:34,800 --> 00:11:39,760
little as egg by

00:11:36,160 --> 00:11:43,839
or can be more than a page

00:11:39,760 --> 00:11:46,079
4k 8k and so on so

00:11:43,839 --> 00:11:47,600
there are wide variety of range in size

00:11:46,079 --> 00:11:49,279
of each of those

00:11:47,600 --> 00:11:51,040
objects in the slab cache depending on

00:11:49,279 --> 00:11:54,839
what type of object you are

00:11:51,040 --> 00:11:59,040
going to to be created

00:11:54,839 --> 00:12:01,600
and the optic signal structure besides

00:11:59,040 --> 00:12:03,680
maintaining the by accounting it also

00:12:01,600 --> 00:12:06,240
maintains the reference scan

00:12:03,680 --> 00:12:06,880
um so each object in the slab cache

00:12:06,240 --> 00:12:08,839
there is an

00:12:06,880 --> 00:12:11,839
for each object in the slab cast is an

00:12:08,839 --> 00:12:11,839
associated

00:12:12,240 --> 00:12:15,839
a way of associated reference that pawn

00:12:15,279 --> 00:12:17,760
to the

00:12:15,839 --> 00:12:19,120
object single structure they are

00:12:17,760 --> 00:12:22,720
currently using it

00:12:19,120 --> 00:12:26,160
so if if a slab

00:12:22,720 --> 00:12:29,120
has let's say a 10 object

00:12:26,160 --> 00:12:29,839
then there will be a way of 10 pointer

00:12:29,120 --> 00:12:33,200
there

00:12:29,839 --> 00:12:34,079
will be allocated as a reference to

00:12:33,200 --> 00:12:35,760
point to the

00:12:34,079 --> 00:12:37,680
the corresponding object stroke

00:12:35,760 --> 00:12:40,800
structure so uh

00:12:37,680 --> 00:12:43,120
this new sql do have a little bit over

00:12:40,800 --> 00:12:44,160
memory overhead which will be for each

00:12:43,120 --> 00:12:46,079
of the

00:12:44,160 --> 00:12:47,760
object that you need to allocate one

00:12:46,079 --> 00:12:50,800
pointer for that

00:12:47,760 --> 00:12:54,959
to know to check which c group is

00:12:50,800 --> 00:12:54,959
um is associated with

00:12:56,720 --> 00:13:02,160
so uh what actually are the benefit of

00:12:59,200 --> 00:13:05,279
the new slab memory controller

00:13:02,160 --> 00:13:06,079
um with the new slab controller um we

00:13:05,279 --> 00:13:09,279
tend to use

00:13:06,079 --> 00:13:14,079
a lot less economy for for slab

00:13:09,279 --> 00:13:15,040
and and that can save quite a bit of

00:13:14,079 --> 00:13:18,560
memory when you

00:13:15,040 --> 00:13:21,200
need to stop a lot of um

00:13:18,560 --> 00:13:21,680
c memory sequel for instance uh when you

00:13:21,200 --> 00:13:25,040
create

00:13:21,680 --> 00:13:28,160
a law of a container and

00:13:25,040 --> 00:13:31,360
and the memory reduction actually are

00:13:28,160 --> 00:13:34,639
more prominent in in architecture like

00:13:31,360 --> 00:13:37,600
a power pc and i'm 64 because those

00:13:34,639 --> 00:13:39,680
architecture currently will support 64k

00:13:37,600 --> 00:13:43,279
pages

00:13:39,680 --> 00:13:47,040
while on 886 system

00:13:43,279 --> 00:13:48,959
um the page size is 4k so

00:13:47,040 --> 00:13:50,399
the general rule of thumb is that the

00:13:48,959 --> 00:13:52,639
smaller the page size

00:13:50,399 --> 00:13:55,519
the smaller will be the size of each of

00:13:52,639 --> 00:13:59,600
a slab because this

00:13:55,519 --> 00:13:59,600
the slab we created usually

00:14:00,160 --> 00:14:06,000
a multiple number of pages and usually

00:14:03,600 --> 00:14:07,360
uh the number here is a simple power of

00:14:06,000 --> 00:14:09,920
two

00:14:07,360 --> 00:14:10,720
so uh the smaller page size the smaller

00:14:09,920 --> 00:14:12,880
slab this

00:14:10,720 --> 00:14:14,800
the less memory will be wasted uh

00:14:12,880 --> 00:14:17,760
because they're used at the

00:14:14,800 --> 00:14:19,519
cash for for the cpu or for them for

00:14:17,760 --> 00:14:23,760
each of the nodes

00:14:19,519 --> 00:14:27,040
and someone had won some benchmark

00:14:23,760 --> 00:14:29,920
um on a power cp system

00:14:27,040 --> 00:14:30,880
that contained running one pop would

00:14:29,920 --> 00:14:33,920
turn the container

00:14:30,880 --> 00:14:36,079
executing some uh some kind of workload

00:14:33,920 --> 00:14:36,959
on the two different kernels with the o

00:14:36,079 --> 00:14:40,000
and the news

00:14:36,959 --> 00:14:43,360
uh selectmen controller so

00:14:40,000 --> 00:14:45,920
uh by running that you measure the

00:14:43,360 --> 00:14:47,279
the amount of the kernel memory as

00:14:45,920 --> 00:14:50,000
they're used up by

00:14:47,279 --> 00:14:51,360
by the by the whole pot and as well each

00:14:50,000 --> 00:14:55,600
of the container

00:14:51,360 --> 00:14:59,600
and it turned out that with the new

00:14:55,600 --> 00:15:00,720
memory controller at the port level the

00:14:59,600 --> 00:15:04,639
main consumption

00:15:00,720 --> 00:15:06,880
go from that mean is specific to

00:15:04,639 --> 00:15:08,959
the memory that are used by the slab

00:15:06,880 --> 00:15:11,120
cache

00:15:08,959 --> 00:15:12,320
and the consumption go from up from

00:15:11,120 --> 00:15:16,240
three gigabytes

00:15:12,320 --> 00:15:19,279
to 400 megapixel which is about

00:15:16,240 --> 00:15:20,480
more than 7x improvement and at the

00:15:19,279 --> 00:15:23,600
container level

00:15:20,480 --> 00:15:26,959
i mean within each of the the container

00:15:23,600 --> 00:15:30,480
the dmr memory used

00:15:26,959 --> 00:15:33,680
was reduced from 112 megabytes

00:15:30,480 --> 00:15:37,440
to 90 megabytes which is around

00:15:33,680 --> 00:15:38,800
six times smaller and also and actually

00:15:37,440 --> 00:15:41,360
the

00:15:38,800 --> 00:15:42,079
execution time they measure also improve

00:15:41,360 --> 00:15:45,440
a bit

00:15:42,079 --> 00:15:48,480
um by 17 that is uh

00:15:45,440 --> 00:15:49,600
quite noticeable um because of probably

00:15:48,480 --> 00:15:53,120
because they

00:15:49,600 --> 00:15:56,320
they have less overhead in stock the um

00:15:53,120 --> 00:15:59,120
the creating of the new uh slab cache

00:15:56,320 --> 00:16:00,959
and and that can and also because they

00:15:59,120 --> 00:16:04,320
use up less memory there's

00:16:00,959 --> 00:16:07,279
less cash footprint and so that can

00:16:04,320 --> 00:16:07,920
probably the reason why the performance

00:16:07,279 --> 00:16:10,880
improve

00:16:07,920 --> 00:16:10,880
a bit also

00:16:13,920 --> 00:16:17,199
so another feature that i want to talk

00:16:16,720 --> 00:16:21,279
about

00:16:17,199 --> 00:16:23,600
is time name space so

00:16:21,279 --> 00:16:24,399
the the purpose of a time name space is

00:16:23,600 --> 00:16:27,440
to

00:16:24,399 --> 00:16:29,199
virtualize uh two system calls that are

00:16:27,440 --> 00:16:32,240
supported by

00:16:29,199 --> 00:16:32,639
the linux kernel the cod monotonic and

00:16:32,240 --> 00:16:35,680
also

00:16:32,639 --> 00:16:38,480
the corporate time monotony time

00:16:35,680 --> 00:16:39,120
monotony is a cork that always

00:16:38,480 --> 00:16:42,399
increment

00:16:39,120 --> 00:16:45,120
and you you will never go back

00:16:42,399 --> 00:16:46,880
and boot time is just uh used for

00:16:45,120 --> 00:16:49,600
accounting the

00:16:46,880 --> 00:16:50,000
the amount of time elapsed since the

00:16:49,600 --> 00:16:53,360
system

00:16:50,000 --> 00:16:55,920
pulled up there's another car

00:16:53,360 --> 00:16:58,720
called clock wheel time is that is used

00:16:55,920 --> 00:17:02,079
to measure the actual one clock time

00:16:58,720 --> 00:17:04,799
there's no virtual line in in the timing

00:17:02,079 --> 00:17:07,120
space because of the capacity and also

00:17:04,799 --> 00:17:09,120
um there's their performance over here

00:17:07,120 --> 00:17:12,319
involved you want to visualize it

00:17:09,120 --> 00:17:13,520
and depend and the use case isn't that

00:17:12,319 --> 00:17:16,799
um

00:17:13,520 --> 00:17:19,839
that that useful and that's why

00:17:16,799 --> 00:17:21,439
it isn't um the timeline doesn't support

00:17:19,839 --> 00:17:23,439
the virtualization of the clock

00:17:21,439 --> 00:17:25,760
real-time

00:17:23,439 --> 00:17:28,079
and a new timeline space is created by

00:17:25,760 --> 00:17:31,280
calling the unshared

00:17:28,079 --> 00:17:33,120
system call with the new kung nil time

00:17:31,280 --> 00:17:36,000
flat

00:17:33,120 --> 00:17:37,520
and when you when do unsure actually the

00:17:36,000 --> 00:17:41,440
the caller itself

00:17:37,520 --> 00:17:43,840
won't be living in the new timelines way

00:17:41,440 --> 00:17:44,799
is the the new children that are created

00:17:43,840 --> 00:17:47,600
that will be

00:17:44,799 --> 00:17:49,600
they will go to the new time name space

00:17:47,600 --> 00:17:52,160
and

00:17:49,600 --> 00:17:52,880
the way that the kernel maintain the

00:17:52,160 --> 00:17:54,720
night

00:17:52,880 --> 00:17:56,640
the names time names place is by

00:17:54,720 --> 00:18:00,799
maintaining an offset

00:17:56,640 --> 00:18:03,919
to the kernel internal time

00:18:00,799 --> 00:18:04,240
that offset is maintained in what we

00:18:03,919 --> 00:18:07,919
call

00:18:04,240 --> 00:18:13,440
a viewer page that i used

00:18:07,919 --> 00:18:13,440
used by the virtual dsl dynamics

00:18:13,600 --> 00:18:18,799
they object maintained by kernel and use

00:18:15,760 --> 00:18:20,720
in user space application

00:18:18,799 --> 00:18:23,360
and timeline phase support is currently

00:18:20,720 --> 00:18:26,559
only available for a86

00:18:23,360 --> 00:18:27,360
and arm 64. um support for the other

00:18:26,559 --> 00:18:30,480
architecture

00:18:27,360 --> 00:18:34,160
haven't been submitted upstream yet

00:18:30,480 --> 00:18:36,080
so um so

00:18:34,160 --> 00:18:38,960
so these two are the the one that are

00:18:36,080 --> 00:18:41,840
currently supported in time name sway

00:18:38,960 --> 00:18:42,320
and actually the the major motivation of

00:18:41,840 --> 00:18:45,600
why

00:18:42,320 --> 00:18:48,480
using adding the timing space to allow

00:18:45,600 --> 00:18:49,039
the monotonic and boot time clock to

00:18:48,480 --> 00:18:50,880
maintain

00:18:49,039 --> 00:18:53,200
a consistent value during continuous

00:18:50,880 --> 00:18:57,039
migration and checkpoint restore

00:18:53,200 --> 00:19:00,559
so that is the reason why we have that

00:18:57,039 --> 00:19:01,120
uh the new feature and and that is used

00:19:00,559 --> 00:19:04,320
to

00:19:01,120 --> 00:19:06,400
support the container so you can see

00:19:04,320 --> 00:19:09,679
that all these

00:19:06,400 --> 00:19:12,400
all the work upstream uh are done to

00:19:09,679 --> 00:19:14,320
to provide better support for for the

00:19:12,400 --> 00:19:16,640
container ecosystem

00:19:14,320 --> 00:19:16,640
and

00:19:17,679 --> 00:19:22,400
and that is the uh the end of my

00:19:21,600 --> 00:19:26,240
presentation

00:19:22,400 --> 00:19:30,160
um in the just at the 20-minute mark

00:19:26,240 --> 00:19:33,679
oh uh there is one question from uh

00:19:30,160 --> 00:19:36,480
okay this is from david

00:19:33,679 --> 00:19:38,160
is there any significant variation in

00:19:36,480 --> 00:19:41,200
the implementation from

00:19:38,160 --> 00:19:43,919
x 86 to arm

00:19:41,200 --> 00:19:43,919
00:19:45,840 --> 00:19:50,480
maybe you could better understand the

00:19:48,000 --> 00:19:50,480
context

00:19:50,880 --> 00:19:53,840
e

00:20:02,240 --> 00:20:09,360
so um are you referring to time space

00:20:05,600 --> 00:20:13,760
or for time name space

00:20:09,360 --> 00:20:16,400
um the yes david just replied

00:20:13,760 --> 00:20:17,520
in the timeline space yeah there's some

00:20:16,400 --> 00:20:21,840
similar differences

00:20:17,520 --> 00:20:21,840
in the implementation

00:20:22,720 --> 00:20:29,200
they are all done within the vdsl

00:20:25,919 --> 00:20:30,720
layer so what they need to do is to

00:20:29,200 --> 00:20:33,679
create

00:20:30,720 --> 00:20:35,360
a dedicated pages that contain offset

00:20:33,679 --> 00:20:36,240
for different time name space so when

00:20:35,360 --> 00:20:39,440
you

00:20:36,240 --> 00:20:40,240
switch to it to a new time namespace uh

00:20:39,440 --> 00:20:42,400
you

00:20:40,240 --> 00:20:43,360
you kind of swap in the the other page

00:20:42,400 --> 00:20:45,760
corresponding

00:20:43,360 --> 00:20:46,640
the code corresponding to that time

00:20:45,760 --> 00:20:49,200
namespace

00:20:46,640 --> 00:20:51,039
um the actual implementation differ a

00:20:49,200 --> 00:20:54,720
little bit because um

00:20:51,039 --> 00:20:55,200
the time the architecture specific code

00:20:54,720 --> 00:20:57,679
for

00:20:55,200 --> 00:20:58,400
for for time management is a little bit

00:20:57,679 --> 00:21:02,320
different

00:20:58,400 --> 00:21:02,799
so they they have windy um each of the

00:21:02,320 --> 00:21:05,760
arc

00:21:02,799 --> 00:21:06,880
directory um they have their own code to

00:21:05,760 --> 00:21:10,000
to manage the

00:21:06,880 --> 00:21:12,080
the mapping but then um they they use a

00:21:10,000 --> 00:21:14,480
common set of core clock to handle

00:21:12,080 --> 00:21:15,200
uh all the rest there's some so there's

00:21:14,480 --> 00:21:17,120
some

00:21:15,200 --> 00:21:19,200
architecture specifically for each of

00:21:17,120 --> 00:21:26,640
the architecture and the west is handled

00:21:19,200 --> 00:21:26,640

YouTube URL: https://www.youtube.com/watch?v=UAtgmmfc9Sw


