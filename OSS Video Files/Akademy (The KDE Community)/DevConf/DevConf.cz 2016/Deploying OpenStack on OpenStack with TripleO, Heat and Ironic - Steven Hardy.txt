Title: Deploying OpenStack on OpenStack with TripleO, Heat and Ironic - Steven Hardy
Publication date: 2016-02-11
Playlist: DevConf.cz 2016
Description: 
	In this session you will learn about the latest developments in the OpenStack deployment project, TripleO, which uses OpenStack services including Heat (orchestration) and Ironic (baremetal provisioning) to deploy your production OpenStack Cloud.

The session will cover an introduction to the OpenStack components involved, the main components of TripleO, and a deep-dive into the TripleO Heat Templates, explaining how to modify them to suit your enviroment, and a demonstration of TripleO deploying OpenStack, on OpenStack!

Some prior knowledge of Heat, and of OpenStack services will be beneficial for the deep-dive part of this talk, but no prior knowledge of TripleO or OpenStack deployment is required.

Presentation: http://bit.ly/1WhVMz7
Captions: 
	00:00:40,280 --> 00:00:45,610
okay I needed to be able to see the

00:00:43,370 --> 00:00:45,610
slides

00:01:02,519 --> 00:01:24,909
okay just things to remember in case we

00:01:21,850 --> 00:01:28,289
preach the person asking questions if

00:01:24,909 --> 00:01:28,289
you can read it yeah

00:01:44,770 --> 00:01:56,340
yes it's kind of follows on for that so

00:01:53,409 --> 00:01:56,340
people have seen the earlier

00:02:13,430 --> 00:02:17,930
this is funny one of the advanced use

00:02:15,870 --> 00:02:17,930
cases

00:02:35,819 --> 00:02:41,370
in meetings but have you seen him yet

00:02:38,189 --> 00:02:43,790
today I'm not quite sure if he around he

00:02:41,370 --> 00:02:43,790
was here yesterday

00:02:58,220 --> 00:03:05,940
hello guys just it's already time for

00:03:03,570 --> 00:03:08,880
our next presentation I'm pleased to

00:03:05,940 --> 00:03:11,510
welcome Steven Hardy principal software

00:03:08,880 --> 00:03:14,790
engineer from Red Hat United Kingdom

00:03:11,510 --> 00:03:18,060
this next presentation will be about

00:03:14,790 --> 00:03:21,180
main components of free pillow and we

00:03:18,060 --> 00:03:23,250
will have deep dive into heat templates

00:03:21,180 --> 00:03:26,430
so it's kind of a follow up on the

00:03:23,250 --> 00:03:29,720
previous J's presentation so please let

00:03:26,430 --> 00:03:29,720
me welcome Steven Hardy

00:04:01,920 --> 00:04:07,020
no house I can hear me now okay let's

00:04:05,050 --> 00:04:12,070
try that again

00:04:07,020 --> 00:04:14,200
so as you heard in the introduction I am

00:04:12,070 --> 00:04:16,150
Steve Hardy software engineer at Red Hat

00:04:14,200 --> 00:04:19,209
and I've been working full-time on

00:04:16,150 --> 00:04:20,290
OpenStack for nearly four years quite a

00:04:19,209 --> 00:04:22,110
lot has happened during that time

00:04:20,290 --> 00:04:26,230
OpenStack is very very fast-moving

00:04:22,110 --> 00:04:28,300
project and I'm going to try and give

00:04:26,230 --> 00:04:30,280
you a bit of an overview of OpenStack

00:04:28,300 --> 00:04:33,460
the various components and we'll go into

00:04:30,280 --> 00:04:35,410
a bit of detail in particular on heat

00:04:33,460 --> 00:04:36,910
and trip low which are the two projects

00:04:35,410 --> 00:04:40,810
that I'm currently most heavily involved

00:04:36,910 --> 00:04:42,640
with so what are we going to talk about

00:04:40,810 --> 00:04:45,910
here the majority of it is going to be

00:04:42,640 --> 00:04:47,919
talking about OpenStack so it might be

00:04:45,910 --> 00:04:50,110
worth considering what OpenStack is for

00:04:47,919 --> 00:04:52,060
a moment obviously it's cloud software

00:04:50,110 --> 00:04:53,740
which a lot of people have heard about

00:04:52,060 --> 00:04:55,660
but really it provides you with an

00:04:53,740 --> 00:04:56,770
abstraction layer so if you have a data

00:04:55,660 --> 00:04:58,870
center and you want to be able to

00:04:56,770 --> 00:05:02,200
provide on-demand access to all kinds of

00:04:58,870 --> 00:05:04,330
different resources not only compute

00:05:02,200 --> 00:05:05,620
resources running VMs which is the use

00:05:04,330 --> 00:05:07,840
case most people tend to think of when

00:05:05,620 --> 00:05:10,510
it comes to OpenStack but also storage

00:05:07,840 --> 00:05:12,820
and virtual networking and various other

00:05:10,510 --> 00:05:16,180
things which we're going to talk about

00:05:12,820 --> 00:05:17,560
in a moment so we're going to try and

00:05:16,180 --> 00:05:18,220
give you a bit of an overview of

00:05:17,560 --> 00:05:19,630
OpenStack

00:05:18,220 --> 00:05:22,060
we're going to do a bit of a deep dive

00:05:19,630 --> 00:05:23,740
into some more advanced capabilities of

00:05:22,060 --> 00:05:26,110
heat and this will follow on somewhat

00:05:23,740 --> 00:05:28,690
from Jay's introductory talk earlier on

00:05:26,110 --> 00:05:30,100
so it would be good if anyone has seen

00:05:28,690 --> 00:05:32,770
that if not you might want to check out

00:05:30,100 --> 00:05:34,150
the recording later date and then we're

00:05:32,770 --> 00:05:35,979
also going to talk a bit about ironic

00:05:34,150 --> 00:05:39,669
which is the bare metal provisioning

00:05:35,979 --> 00:05:41,650
piece of OpenStack and how that can help

00:05:39,669 --> 00:05:44,800
us with the triple o vision which is

00:05:41,650 --> 00:05:48,130
using OpenStack components to deploy

00:05:44,800 --> 00:05:51,580
OpenStack in a production environment so

00:05:48,130 --> 00:05:53,260
a few years ago OpenStack was very much

00:05:51,580 --> 00:05:56,560
smaller than it is now it was primarily

00:05:53,260 --> 00:05:59,560
focused around abstractions for compute

00:05:56,560 --> 00:06:02,320
and that is mostly running VMs across

00:05:59,560 --> 00:06:05,229
multiple hypervisors and block and

00:06:02,320 --> 00:06:07,660
object storage now a few short years

00:06:05,229 --> 00:06:09,010
later there are a large number

00:06:07,660 --> 00:06:10,660
of different projects this may not even

00:06:09,010 --> 00:06:13,980
be accurate as I did this a few weeks

00:06:10,660 --> 00:06:16,240
ago but as you can see there are

00:06:13,980 --> 00:06:18,040
everything as a service is the way I

00:06:16,240 --> 00:06:20,230
like to think of it any conceivable

00:06:18,040 --> 00:06:23,140
abstraction in your data center is

00:06:20,230 --> 00:06:25,600
likely to have someone working on REST

00:06:23,140 --> 00:06:29,440
API and allows people to more easily

00:06:25,600 --> 00:06:32,050
interact with those resources so we're

00:06:29,440 --> 00:06:33,880
going to focus on ironic which allows

00:06:32,050 --> 00:06:37,000
you to do provisioning of actual bare

00:06:33,880 --> 00:06:39,220
metal hardware so dedicated bare metal

00:06:37,000 --> 00:06:40,930
machines for your workload rather than

00:06:39,220 --> 00:06:44,020
VMs and then we're going to talk about

00:06:40,930 --> 00:06:45,400
the heat orchestration component which

00:06:44,020 --> 00:06:47,500
allows you to have a more declarative

00:06:45,400 --> 00:06:49,570
interface to all of these different

00:06:47,500 --> 00:06:51,670
tools you can see that if you've got

00:06:49,570 --> 00:06:54,790
this proliferation of different HTTP

00:06:51,670 --> 00:06:55,930
api's they all follow some common

00:06:54,790 --> 00:06:59,080
patterns but they're not necessarily

00:06:55,930 --> 00:07:00,490
100% consistent there are different

00:06:59,080 --> 00:07:04,000
command-line tools although there is a

00:07:00,490 --> 00:07:06,160
common OpenStack client effort going on

00:07:04,000 --> 00:07:08,230
as well but really you need some way

00:07:06,160 --> 00:07:11,020
which is less imperative to define your

00:07:08,230 --> 00:07:13,300
resources in your cloud and as Jays talk

00:07:11,020 --> 00:07:16,630
introduced earlier on there's a template

00:07:13,300 --> 00:07:18,910
model which he accepts which allows you

00:07:16,630 --> 00:07:21,820
to define relationships between your

00:07:18,910 --> 00:07:23,530
different resources and instantiate them

00:07:21,820 --> 00:07:24,820
in the right order for you without you

00:07:23,530 --> 00:07:26,500
necessarily having to worry about

00:07:24,820 --> 00:07:30,190
dependencies between components

00:07:26,500 --> 00:07:31,600
explicitly yourself so before we get

00:07:30,190 --> 00:07:33,370
into the details of the orchestration

00:07:31,600 --> 00:07:35,130
features themselves it's worth kind of

00:07:33,370 --> 00:07:38,590
differentiating a little bit between

00:07:35,130 --> 00:07:39,880
orchestration and config management this

00:07:38,590 --> 00:07:42,370
is kind of a bit of a blurry line

00:07:39,880 --> 00:07:44,650
particularly in the cloud world because

00:07:42,370 --> 00:07:46,290
there's a number of different conflict

00:07:44,650 --> 00:07:48,460
management tools that provide some

00:07:46,290 --> 00:07:50,530
orchestration capabilities and then

00:07:48,460 --> 00:07:53,080
there's some more orchestration focused

00:07:50,530 --> 00:07:55,540
tools which do have built-in conflict

00:07:53,080 --> 00:07:58,419
management capabilities so he tries to

00:07:55,540 --> 00:08:02,200
draw a fairly define line between those

00:07:58,419 --> 00:08:05,770
two features we don't have any built-in

00:08:02,200 --> 00:08:09,340
software configuration capability but we

00:08:05,770 --> 00:08:11,050
have implementation agnostic way to

00:08:09,340 --> 00:08:12,340
drive existing conflict management tools

00:08:11,050 --> 00:08:14,350
so we'll get into a bit more detail

00:08:12,340 --> 00:08:16,630
about that but I just wanted to clarify

00:08:14,350 --> 00:08:18,940
that you know it's not a replacement for

00:08:16,630 --> 00:08:21,719
puppet or ansible or anything like that

00:08:18,940 --> 00:08:23,620
it's really about organizing and

00:08:21,719 --> 00:08:27,639
managing your interactions between

00:08:23,620 --> 00:08:29,919
different services and OpenStack so to

00:08:27,639 --> 00:08:34,779
follow on from from Jai's introduction

00:08:29,919 --> 00:08:38,079
earlier on the instantiated environment

00:08:34,779 --> 00:08:39,610
for he is is a stack and so that's the

00:08:38,079 --> 00:08:42,430
name for the resources which have been

00:08:39,610 --> 00:08:45,370
deployed for you by heat based on the

00:08:42,430 --> 00:08:46,750
yam all template that you have fed in if

00:08:45,370 --> 00:08:49,690
you have to at all familiar with cloud

00:08:46,750 --> 00:08:52,089
formation similar kind of concept we

00:08:49,690 --> 00:08:54,660
have a native template language in

00:08:52,089 --> 00:08:59,769
addition to capabilities to drive from

00:08:54,660 --> 00:09:01,779
cloud formation templates another really

00:08:59,769 --> 00:09:03,519
nice feature of heat is that there's a

00:09:01,779 --> 00:09:05,740
very easy way to compose multiple

00:09:03,519 --> 00:09:08,370
fragments of your environment so you can

00:09:05,740 --> 00:09:10,899
define a heat template that contains say

00:09:08,370 --> 00:09:13,360
some particular piece of software and

00:09:10,899 --> 00:09:15,339
the server resource that is going to

00:09:13,360 --> 00:09:17,680
host it perhaps some networking to

00:09:15,339 --> 00:09:19,480
support it some particular type of

00:09:17,680 --> 00:09:22,120
storage and that can be a unit that is

00:09:19,480 --> 00:09:24,430
then easily reused the templates are all

00:09:22,120 --> 00:09:25,660
parameterised and as Jay introduced

00:09:24,430 --> 00:09:27,310
earlier on there's a concept of an

00:09:25,660 --> 00:09:29,019
environment so say if you need a staging

00:09:27,310 --> 00:09:31,480
workflow and you need some different

00:09:29,019 --> 00:09:32,949
parameters or or even nested different

00:09:31,480 --> 00:09:35,170
let's do stack implementations between

00:09:32,949 --> 00:09:37,180
say pre-production and development and

00:09:35,170 --> 00:09:39,940
production environments it's very easy

00:09:37,180 --> 00:09:43,510
to do that with a maximum amount of

00:09:39,940 --> 00:09:44,079
reuse so this is just a very quick

00:09:43,510 --> 00:09:45,610
example

00:09:44,079 --> 00:09:47,709
try not to overlap too much with the

00:09:45,610 --> 00:09:51,519
earlier talk but it's gonna help with

00:09:47,709 --> 00:09:53,440
the concepts we could discuss later when

00:09:51,519 --> 00:09:56,140
we talk about composability we're really

00:09:53,440 --> 00:09:57,880
talking about referencing one heat

00:09:56,140 --> 00:10:00,310
template in another template so it's

00:09:57,880 --> 00:10:02,320
kind of a parent-child relationship so

00:10:00,310 --> 00:10:03,850
in this case we've got a parent template

00:10:02,320 --> 00:10:07,660
which is referencing an OpenStack

00:10:03,850 --> 00:10:09,579
controller type alias and that is just a

00:10:07,660 --> 00:10:12,190
way of referencing this server with

00:10:09,579 --> 00:10:13,750
controller configure more and the way

00:10:12,190 --> 00:10:16,029
which you will create that is to

00:10:13,750 --> 00:10:19,180
reference the resource registry which is

00:10:16,029 --> 00:10:22,149
just a mapping between an alias and an

00:10:19,180 --> 00:10:25,300
implementation so you do your stack

00:10:22,149 --> 00:10:27,370
create pass in template and an

00:10:25,300 --> 00:10:29,079
environment file on those two combine to

00:10:27,370 --> 00:10:33,550
fully define what's going to be deployed

00:10:29,079 --> 00:10:34,990
in your cloud so once you've got your

00:10:33,550 --> 00:10:36,459
unit of the

00:10:34,990 --> 00:10:38,170
and sorted out and you've got something

00:10:36,459 --> 00:10:39,370
that works really really well pretty

00:10:38,170 --> 00:10:41,080
much immediately the next thing you're

00:10:39,370 --> 00:10:43,180
going to need to do is to build lots of

00:10:41,080 --> 00:10:45,220
them you know you're gonna need to scale

00:10:43,180 --> 00:10:46,660
out horizontally when your application

00:10:45,220 --> 00:10:48,820
becomes successful because you're going

00:10:46,660 --> 00:10:49,930
to need to handle an increased load so

00:10:48,820 --> 00:10:52,690
there's a couple of different ways of

00:10:49,930 --> 00:10:54,160
doing that within heat the one which I'm

00:10:52,690 --> 00:10:56,350
going to talk about primarily today is

00:10:54,160 --> 00:10:58,149
the resource group abstraction and this

00:10:56,350 --> 00:11:01,120
just provides a really easy way of

00:10:58,149 --> 00:11:03,190
saying make me however many of a

00:11:01,120 --> 00:11:05,350
particular resource type and so you can

00:11:03,190 --> 00:11:07,120
combine that with the composability we

00:11:05,350 --> 00:11:10,120
just talked about and just scale out a

00:11:07,120 --> 00:11:11,800
heat template to any number depending on

00:11:10,120 --> 00:11:13,570
the capabilities if the cards are

00:11:11,800 --> 00:11:16,020
deploying onto there's also an auto

00:11:13,570 --> 00:11:20,080
scaling group resource which has

00:11:16,020 --> 00:11:21,279
integration with ceilometer alarms and

00:11:20,080 --> 00:11:24,010
that allows you to do much more

00:11:21,279 --> 00:11:26,110
event-driven scale-out but we're going

00:11:24,010 --> 00:11:31,089
to talk about the more static grouping

00:11:26,110 --> 00:11:32,980
method today so you've got your server

00:11:31,089 --> 00:11:35,350
stood up perhaps you've got some storage

00:11:32,980 --> 00:11:36,760
you've got some networking set up the

00:11:35,350 --> 00:11:38,290
next thing you're going to need to do as

00:11:36,760 --> 00:11:40,510
we discussed earlier on in terms of

00:11:38,290 --> 00:11:43,709
conflict management is deploy some

00:11:40,510 --> 00:11:46,630
application onto the onto the hardware

00:11:43,709 --> 00:11:48,610
the way you do this in the heat model is

00:11:46,630 --> 00:11:50,350
basically you define a software

00:11:48,610 --> 00:11:52,660
configure your s-- in your llaman

00:11:50,350 --> 00:11:55,329
template and this doesn't care what tool

00:11:52,660 --> 00:11:56,770
you use it just accepts for example a

00:11:55,329 --> 00:11:59,290
poppet manifest or an answerable

00:11:56,770 --> 00:12:00,880
playbook or a shell scripts or a Python

00:11:59,290 --> 00:12:03,790
script or whatever it is that you want

00:12:00,880 --> 00:12:05,649
to run on your server you then reference

00:12:03,790 --> 00:12:06,940
that from a software deployment resource

00:12:05,649 --> 00:12:08,440
and this is the thing that actually runs

00:12:06,940 --> 00:12:10,000
your config this is the thing that knows

00:12:08,440 --> 00:12:12,160
how to associate that piece of

00:12:10,000 --> 00:12:14,410
configuration with a particular server

00:12:12,160 --> 00:12:16,660
and there's a single admit mechanism

00:12:14,410 --> 00:12:19,750
which is using some agents inside the

00:12:16,660 --> 00:12:22,690
instance which basically knows how to

00:12:19,750 --> 00:12:24,940
click that configuration run it on on

00:12:22,690 --> 00:12:26,770
the the node in question and then send a

00:12:24,940 --> 00:12:28,690
signal back when it's done or if it

00:12:26,770 --> 00:12:30,910
fails and we click the standardout the

00:12:28,690 --> 00:12:33,730
standard and the return code of whatever

00:12:30,910 --> 00:12:35,500
is that you run and the nice thing then

00:12:33,730 --> 00:12:37,870
is you know it's well integrated with

00:12:35,500 --> 00:12:39,730
the templates you don't have to do a

00:12:37,870 --> 00:12:41,290
handoff to another tool although you

00:12:39,730 --> 00:12:42,760
could do if you wanted to you could

00:12:41,290 --> 00:12:44,770
deploy with heat and then configure with

00:12:42,760 --> 00:12:46,720
ansible or a puppet master or whatever

00:12:44,770 --> 00:12:48,610
but particularly in the case where you

00:12:46,720 --> 00:12:49,959
want to scale out it's more convenient

00:12:48,610 --> 00:12:51,700
you can define everything in one place

00:12:49,959 --> 00:12:56,110
and then just multiply up the

00:12:51,700 --> 00:12:58,870
environment as it grows so another

00:12:56,110 --> 00:13:00,399
common requirement if you're deploying a

00:12:58,870 --> 00:13:02,230
more complex application and in

00:13:00,399 --> 00:13:04,329
particular OpenStack which is what we're

00:13:02,230 --> 00:13:07,750
going to be talking about deploying in a

00:13:04,329 --> 00:13:09,190
moment or two is configuring each of an

00:13:07,750 --> 00:13:11,140
individual node is not enough

00:13:09,190 --> 00:13:12,279
each individual node can be set up but

00:13:11,140 --> 00:13:14,170
then they need to be configured to know

00:13:12,279 --> 00:13:15,269
about all of the other nodes and so I'm

00:13:14,170 --> 00:13:17,290
calling this cluster configuration

00:13:15,269 --> 00:13:19,170
because that's effectively what we're

00:13:17,290 --> 00:13:22,089
talking about you deploy a cluster of

00:13:19,170 --> 00:13:24,100
near-identical nodes or completely

00:13:22,089 --> 00:13:25,920
identical and then they need to be wired

00:13:24,100 --> 00:13:28,360
up so they can talk to each other and

00:13:25,920 --> 00:13:30,940
the example we're going to talk about

00:13:28,360 --> 00:13:32,769
today is OpenStack controller nodes

00:13:30,940 --> 00:13:35,860
where you install a bunch of API

00:13:32,769 --> 00:13:37,480
services and a bunch of RPC and database

00:13:35,860 --> 00:13:38,920
components and all of them need to be

00:13:37,480 --> 00:13:41,019
wired together otherwise they're not

00:13:38,920 --> 00:13:45,610
going to cooperate and increase your

00:13:41,019 --> 00:13:48,040
capacity as a whole so you've got this

00:13:45,610 --> 00:13:50,100
nice configuration method you've got

00:13:48,040 --> 00:13:52,480
your template sorted out you can deploy

00:13:50,100 --> 00:13:54,850
your workload on a virtual environment

00:13:52,480 --> 00:13:57,190
and you're happy that it works great but

00:13:54,850 --> 00:13:59,829
a lot of people have requirements for

00:13:57,190 --> 00:14:02,260
better performance and this is where

00:13:59,829 --> 00:14:05,610
ironic bare metal provisioning comes in

00:14:02,260 --> 00:14:08,860
so this is an OpenStack API that

00:14:05,610 --> 00:14:10,570
basically makes bare-metal provisioning

00:14:08,860 --> 00:14:13,240
possible in a way that's very very

00:14:10,570 --> 00:14:15,339
similar to deploying virtual machines

00:14:13,240 --> 00:14:17,290
via the Nova compute service and in fact

00:14:15,339 --> 00:14:19,269
it has a driver such that you deploy

00:14:17,290 --> 00:14:21,490
something in the exact same way that you

00:14:19,269 --> 00:14:25,660
deploy a VM and then what you end up

00:14:21,490 --> 00:14:26,709
with is a bare-metal machine so the key

00:14:25,660 --> 00:14:29,350
difference between this and more

00:14:26,709 --> 00:14:31,420
traditional provisioning methods is that

00:14:29,350 --> 00:14:33,880
you don't run an installer you prepare

00:14:31,420 --> 00:14:36,250
an image ahead of time and then you

00:14:33,880 --> 00:14:40,000
basically deploy that image onto the

00:14:36,250 --> 00:14:42,850
bare metal mode and then you're

00:14:40,000 --> 00:14:44,140
basically ready to go the advantages are

00:14:42,850 --> 00:14:47,410
there are you know in some cases

00:14:44,140 --> 00:14:48,760
performance but in terms of trying to

00:14:47,410 --> 00:14:50,860
make sure that all the nodes are exactly

00:14:48,760 --> 00:14:52,570
the same and managing drift between

00:14:50,860 --> 00:14:56,470
different nodes this can be a nice

00:14:52,570 --> 00:14:58,060
method as well so there's quite a lot of

00:14:56,470 --> 00:15:01,120
support from the hardware vendor

00:14:58,060 --> 00:15:02,560
community ionic is proving to be quite a

00:15:01,120 --> 00:15:04,540
successful project

00:15:02,560 --> 00:15:06,550
and so that's quite a good motivator if

00:15:04,540 --> 00:15:08,050
you wanted to build a deployment tool if

00:15:06,550 --> 00:15:10,540
you already have built-in support for a

00:15:08,050 --> 00:15:13,060
bunch of different hardware and so

00:15:10,540 --> 00:15:14,470
that's one reason why triple-a uses

00:15:13,060 --> 00:15:16,449
ironic for bare metal provisioning

00:15:14,470 --> 00:15:19,269
because it has very good pluggable

00:15:16,449 --> 00:15:24,300
support for different different Hardware

00:15:19,269 --> 00:15:26,730
types so hopefully you can see that okay

00:15:24,300 --> 00:15:28,990
this is just a diagram which tries to

00:15:26,730 --> 00:15:31,689
give you a bit more of a granular view

00:15:28,990 --> 00:15:33,970
of how things work inside ironic and so

00:15:31,689 --> 00:15:36,720
as I mentioned so the Nova API in

00:15:33,970 --> 00:15:38,230
OpenStack is the compute interface

00:15:36,720 --> 00:15:42,029
traditionally you would use that to

00:15:38,230 --> 00:15:44,379
launch VMs on say KVM or Xen hypervisor

00:15:42,029 --> 00:15:46,480
compute node but in this case it's

00:15:44,379 --> 00:15:49,350
configured instead so the Nova scheduler

00:15:46,480 --> 00:15:52,689
knows how to talk to the ironic API and

00:15:49,350 --> 00:15:56,110
the user comes along and says okay I

00:15:52,689 --> 00:15:59,290
want a server running this image and the

00:15:56,110 --> 00:16:02,829
flavor is a configuration that points to

00:15:59,290 --> 00:16:04,180
a bare-metal resource type and so it

00:16:02,829 --> 00:16:06,670
works in a very similar way to starting

00:16:04,180 --> 00:16:08,829
a VM only we have an extra step because

00:16:06,670 --> 00:16:10,629
the ironic conductor needs to know how

00:16:08,829 --> 00:16:14,769
to power on the physical hardware and

00:16:10,629 --> 00:16:16,720
then we do that via a plug-in of some

00:16:14,769 --> 00:16:20,259
sort and in this case I'm illustrating

00:16:16,720 --> 00:16:21,639
you might have an IP mi interface that's

00:16:20,259 --> 00:16:23,589
quite quite obviously quite a common

00:16:21,639 --> 00:16:26,740
standard which would know how to talk to

00:16:23,589 --> 00:16:29,259
your hardware and turn it on perhaps do

00:16:26,740 --> 00:16:32,829
some other actions as well so you power

00:16:29,259 --> 00:16:35,470
on your node and then the ionic service

00:16:32,829 --> 00:16:37,209
is able to PXE boot around it gone to

00:16:35,470 --> 00:16:38,439
that node which then pulls down the

00:16:37,209 --> 00:16:40,779
image which you want to put onto the

00:16:38,439 --> 00:16:42,220
node there's some code in the round disk

00:16:40,779 --> 00:16:44,829
that knows how to deploy that onto the

00:16:42,220 --> 00:16:46,089
local disk then it reboots the node and

00:16:44,829 --> 00:16:47,889
then it comes up with the image that you

00:16:46,089 --> 00:16:50,559
want to be running so that in a nutshell

00:16:47,889 --> 00:16:52,540
is what ironic does for you and the key

00:16:50,559 --> 00:16:54,730
advantages as I mentioned are the plug

00:16:52,540 --> 00:16:56,529
ability and the driver support that you

00:16:54,730 --> 00:16:59,769
get for free if you choose to use it

00:16:56,529 --> 00:17:02,889
so triple-a is choosing to use ironic

00:16:59,769 --> 00:17:05,799
several other deployment tools inside

00:17:02,889 --> 00:17:09,159
the OpenStack space and elsewhere such

00:17:05,799 --> 00:17:11,039
as Bifrost are using it as well and so

00:17:09,159 --> 00:17:13,600
it's proving to be quite a nice solution

00:17:11,039 --> 00:17:15,329
for these sorts of bare metal

00:17:13,600 --> 00:17:21,029
provisioning cases

00:17:15,329 --> 00:17:25,049
so this brings me on to the integration

00:17:21,029 --> 00:17:28,739
of these these two pieces so when you

00:17:25,049 --> 00:17:32,220
have heat environment and bare metal

00:17:28,739 --> 00:17:35,700
provisioning capability you can then

00:17:32,220 --> 00:17:38,279
deploy a complex workload and OpenStack

00:17:35,700 --> 00:17:40,139
is one of the more complex workloads you

00:17:38,279 --> 00:17:42,179
couldn't consider as I mentioned at the

00:17:40,139 --> 00:17:46,970
start of the talk things are moving very

00:17:42,179 --> 00:17:46,970
very fast and there's a lot of

00:17:47,989 --> 00:17:51,480
relatively complex distributed

00:17:50,129 --> 00:17:53,039
applications that all need to be

00:17:51,480 --> 00:17:54,779
configured in subtly different ways and

00:17:53,039 --> 00:17:57,600
so you need a flexible and repeatable

00:17:54,779 --> 00:17:59,369
way to deploy and that workload the

00:17:57,600 --> 00:18:01,499
exact same problem exists for many other

00:17:59,369 --> 00:18:04,769
kinds of workloads but triple o is

00:18:01,499 --> 00:18:08,850
focused solely on deploying OpenStack on

00:18:04,769 --> 00:18:10,230
physical hardware so it's a bit of a

00:18:08,850 --> 00:18:12,539
weird concept it's kind of the chicken

00:18:10,230 --> 00:18:14,100
and the egg kind of thing you start off

00:18:12,539 --> 00:18:15,389
with an open stack environment and you

00:18:14,100 --> 00:18:18,149
end up with another OpenStack

00:18:15,389 --> 00:18:19,259
environment you can reasonably ask the

00:18:18,149 --> 00:18:21,960
question how do you get the first

00:18:19,259 --> 00:18:24,239
OpenStack environment the answer is at

00:18:21,960 --> 00:18:26,369
the moment we have some scripts that do

00:18:24,239 --> 00:18:28,980
a single node install and configure

00:18:26,369 --> 00:18:31,200
OpenStack on one node using puppet and

00:18:28,980 --> 00:18:33,389
then the exact same puppet

00:18:31,200 --> 00:18:34,980
implementation is used to configure the

00:18:33,389 --> 00:18:37,320
OpenStack services on the production

00:18:34,980 --> 00:18:40,529
cloud and so we've adopted some

00:18:37,320 --> 00:18:42,690
terminology here which is worth kind of

00:18:40,529 --> 00:18:44,820
remembering because it ends up being in

00:18:42,690 --> 00:18:47,269
quite a lot of documentation and blog

00:18:44,820 --> 00:18:49,980
posts and things related to triple o so

00:18:47,269 --> 00:18:52,649
the deployment cloud is called the under

00:18:49,980 --> 00:18:54,720
cloud and this is basically the small

00:18:52,649 --> 00:18:56,970
OpenStack that is used to bootstrap your

00:18:54,720 --> 00:18:59,639
production OpenStack and then the over

00:18:56,970 --> 00:19:03,149
cloud is the production cloud that you

00:18:59,639 --> 00:19:04,889
would then deploy at the moment and the

00:19:03,149 --> 00:19:07,590
tooling expects you to only deploy one

00:19:04,889 --> 00:19:09,779
production cloud in the future there's

00:19:07,590 --> 00:19:11,429
no technical reason why other than it

00:19:09,779 --> 00:19:14,070
probably a few hard-coded assumptions

00:19:11,429 --> 00:19:15,480
that you couldn't deploy multiple over

00:19:14,070 --> 00:19:17,609
clouds and that's definitely something

00:19:15,480 --> 00:19:19,980
which we would be looking to support

00:19:17,609 --> 00:19:21,179
more completely in the future you can

00:19:19,980 --> 00:19:23,309
imagine that would be particularly nice

00:19:21,179 --> 00:19:25,169
in a developer environment where you

00:19:23,309 --> 00:19:26,669
know developers might want their own

00:19:25,169 --> 00:19:28,620
test environment which is separate from

00:19:26,669 --> 00:19:30,630
other other users doing

00:19:28,620 --> 00:19:31,980
testing or in a pre-production test

00:19:30,630 --> 00:19:35,430
environment I think that could be very

00:19:31,980 --> 00:19:36,809
useful in terms of the sort staging

00:19:35,430 --> 00:19:39,900
workflow that you end up needing before

00:19:36,809 --> 00:19:40,860
rolling out things to production so you

00:19:39,900 --> 00:19:43,320
have your deployment and management

00:19:40,860 --> 00:19:46,320
tooling in your small open stack and

00:19:43,320 --> 00:19:48,780
then you have your open stack production

00:19:46,320 --> 00:19:53,300
cloud which is the thing that is

00:19:48,780 --> 00:19:55,470
actually deployed by your under cloud so

00:19:53,300 --> 00:19:57,330
if we go back to some of the heat

00:19:55,470 --> 00:19:59,790
concepts we kind of looked at very

00:19:57,330 --> 00:20:03,140
briefly a few minutes ago that is

00:19:59,790 --> 00:20:06,150
grouping of resources composability

00:20:03,140 --> 00:20:07,890
which is the nested stacks of stack

00:20:06,150 --> 00:20:11,160
which references another stack and

00:20:07,890 --> 00:20:12,690
software configuration we can see a bit

00:20:11,160 --> 00:20:15,210
more concretely how those features

00:20:12,690 --> 00:20:19,740
combine to make this kind of deployment

00:20:15,210 --> 00:20:22,050
possible so the under cloud is deploying

00:20:19,740 --> 00:20:24,270
groups of nodes and unsurprisingly

00:20:22,050 --> 00:20:26,250
seeing as I've already talked about this

00:20:24,270 --> 00:20:28,170
resource group abstraction inside heat

00:20:26,250 --> 00:20:30,300
we make use of that in order to deploy

00:20:28,170 --> 00:20:31,830
however many controllers you want for

00:20:30,300 --> 00:20:34,890
instance you'll probably deploy three if

00:20:31,830 --> 00:20:36,690
you want an H a deployment and however

00:20:34,890 --> 00:20:38,820
many computes you want which is

00:20:36,690 --> 00:20:41,300
basically the hypervisor nodes that

00:20:38,820 --> 00:20:43,470
support the deployment of VMs and

00:20:41,300 --> 00:20:46,140
there's three different types of storage

00:20:43,470 --> 00:20:49,730
node so you can deploy safe storage

00:20:46,140 --> 00:20:52,710
nodes which have the Ceph the Ceph OSD

00:20:49,730 --> 00:20:54,660
component on it Swift storage nodes

00:20:52,710 --> 00:20:57,720
which allow you to scale out your object

00:20:54,660 --> 00:21:00,360
storage and block storage nodes which is

00:20:57,720 --> 00:21:03,000
basically if you have a requirement for

00:21:00,360 --> 00:21:07,170
a basic cinder storage implementation

00:21:03,000 --> 00:21:12,570
and you choose not to back cinder by by

00:21:07,170 --> 00:21:14,850
SEF so we've now got multiple resource

00:21:12,570 --> 00:21:17,610
groups and you can imagine these are all

00:21:14,850 --> 00:21:19,500
in one template and that's actually how

00:21:17,610 --> 00:21:21,900
we do to it we've gone over cloud yeah

00:21:19,500 --> 00:21:23,640
more template which defines a number of

00:21:21,900 --> 00:21:26,429
groups of nodes and you say how many of

00:21:23,640 --> 00:21:28,740
each you want and then we create some

00:21:26,429 --> 00:21:33,360
nested stack templates which define each

00:21:28,740 --> 00:21:35,730
node and that goes away and it creates

00:21:33,360 --> 00:21:37,620
an ice Nova server and as we've

00:21:35,730 --> 00:21:39,690
discovered if you have Nova configured

00:21:37,620 --> 00:21:42,240
to create bare metal nodes via ironic

00:21:39,690 --> 00:21:45,059
you can just go away and

00:21:42,240 --> 00:21:48,270
deploy on bare metal so we're making use

00:21:45,059 --> 00:21:49,590
of that integration and then we're

00:21:48,270 --> 00:21:52,950
making use of this software

00:21:49,590 --> 00:21:55,260
configuration interface of heat to in

00:21:52,950 --> 00:21:57,990
some cases run scripts to prepare the

00:21:55,260 --> 00:22:01,410
network and in a lot of cases run puppet

00:21:57,990 --> 00:22:02,940
in standalone masterless mode so that's

00:22:01,410 --> 00:22:03,690
kind of a weird concept until you get

00:22:02,940 --> 00:22:05,820
your head around it

00:22:03,690 --> 00:22:09,510
there is no puppet master and all of the

00:22:05,820 --> 00:22:11,940
data used for puppet is coming from heat

00:22:09,510 --> 00:22:13,380
and the way we handle that is basically

00:22:11,940 --> 00:22:15,809
the first thing we do before running any

00:22:13,380 --> 00:22:18,890
puppet on the nodes is we deploy some

00:22:15,809 --> 00:22:21,960
horror data and if anyone knows puppet

00:22:18,890 --> 00:22:24,240
you probably will know more about the

00:22:21,960 --> 00:22:27,660
details of horrid ater than I do but we

00:22:24,240 --> 00:22:30,450
deploy a big map of pyro data key value

00:22:27,660 --> 00:22:33,630
pairs and then we run puppet in a series

00:22:30,450 --> 00:22:36,420
of passes on the nodes in order to get

00:22:33,630 --> 00:22:38,610
the services fully configured so this is

00:22:36,420 --> 00:22:41,460
an illustration of that process this is

00:22:38,610 --> 00:22:43,170
not every step that we run because I

00:22:41,460 --> 00:22:46,110
wouldn't be able to fit on one slide but

00:22:43,170 --> 00:22:48,750
it hopefully gives you an idea of the

00:22:46,110 --> 00:22:50,880
conceptual process so the first step as

00:22:48,750 --> 00:22:52,380
on the previous slide is you deploy the

00:22:50,880 --> 00:22:54,720
server you do the initial configuration

00:22:52,380 --> 00:22:58,320
of each unit and which is being scaled

00:22:54,720 --> 00:23:00,090
out and then the next step is you do a

00:22:58,320 --> 00:23:03,420
number of configuration passes doing the

00:23:00,090 --> 00:23:05,070
cluster wide configuration which is the

00:23:03,420 --> 00:23:07,080
interface which I described earlier on

00:23:05,070 --> 00:23:09,600
using the OS heat software deployment

00:23:07,080 --> 00:23:11,910
group and each one of those accepts a

00:23:09,600 --> 00:23:13,820
configuration which is in most cases a

00:23:11,910 --> 00:23:16,080
puppet manifest

00:23:13,820 --> 00:23:18,960
everything is widen in a bit of a kind

00:23:16,080 --> 00:23:20,790
of puppet centric way in the default

00:23:18,960 --> 00:23:22,350
implementation but we've been careful to

00:23:20,790 --> 00:23:25,440
keep the abstractions in place such that

00:23:22,350 --> 00:23:27,480
other deployment solutions would be

00:23:25,440 --> 00:23:29,130
easily plugged in and in fact there's an

00:23:27,480 --> 00:23:32,429
effort going on at the moment to deploy

00:23:29,130 --> 00:23:35,100
a via docker containers using the caller

00:23:32,429 --> 00:23:36,830
containers which is the one of the

00:23:35,100 --> 00:23:41,700
container communities within OpenStack

00:23:36,830 --> 00:23:44,220
and there they've been very easily able

00:23:41,700 --> 00:23:45,809
to wire in deploying via docker instead

00:23:44,220 --> 00:23:48,809
of having to use puppet to configure the

00:23:45,809 --> 00:23:50,460
services so the point being that if

00:23:48,809 --> 00:23:52,740
people are sufficiently motivated they

00:23:50,460 --> 00:23:54,960
could wire in using any config tool they

00:23:52,740 --> 00:23:56,940
are they are invested in

00:23:54,960 --> 00:23:58,770
but we've chosen to use puppet as a

00:23:56,940 --> 00:24:03,240
first step because of prior experience

00:23:58,770 --> 00:24:06,570
using that tool so this is a slightly

00:24:03,240 --> 00:24:08,549
more granular model which kind of

00:24:06,570 --> 00:24:12,390
combines the workflow we described for

00:24:08,549 --> 00:24:16,230
ironic and the triple a deployment

00:24:12,390 --> 00:24:19,470
workflow so you have an interface to

00:24:16,230 --> 00:24:21,510
deploy your cloud that passes in some

00:24:19,470 --> 00:24:23,760
templates and some puppet manifests into

00:24:21,510 --> 00:24:26,159
heat and heat then basically builds a

00:24:23,760 --> 00:24:29,730
big dependency graph and this is kind of

00:24:26,159 --> 00:24:31,020
the main thing that heat does it really

00:24:29,730 --> 00:24:33,510
cares about dependencies between

00:24:31,020 --> 00:24:37,320
different components and it passes the

00:24:33,510 --> 00:24:39,330
llamó model and then inside the heat

00:24:37,320 --> 00:24:41,399
engine you end up with a dependency

00:24:39,330 --> 00:24:43,350
graph which we then know how to walk in

00:24:41,399 --> 00:24:46,230
a certain order such that you create

00:24:43,350 --> 00:24:48,390
things in the right sequence but as a

00:24:46,230 --> 00:24:50,730
user or operator you don't have to care

00:24:48,390 --> 00:24:53,429
about that explicitly unless there is

00:24:50,730 --> 00:24:55,830
nothing in the template which references

00:24:53,429 --> 00:24:58,049
between those two resources so jellyroll

00:24:55,830 --> 00:24:59,760
mentioned this depends on directive if

00:24:58,049 --> 00:25:01,679
for example you were just creating two

00:24:59,760 --> 00:25:02,940
completely independent servers and for

00:25:01,679 --> 00:25:04,529
some reason you knew they had to be

00:25:02,940 --> 00:25:06,090
created in a certain order you can

00:25:04,529 --> 00:25:09,299
control that but in most cases you don't

00:25:06,090 --> 00:25:11,460
have to care about that explicitly and

00:25:09,299 --> 00:25:13,770
so the other thing that we're making

00:25:11,460 --> 00:25:16,200
quite heavy use of in triple o at its

00:25:13,770 --> 00:25:18,120
point in time is Neutron we're primarily

00:25:16,200 --> 00:25:21,120
using that as an IP address management

00:25:18,120 --> 00:25:24,240
solution there's been some really good

00:25:21,120 --> 00:25:25,590
work done on network isolation so this

00:25:24,240 --> 00:25:28,830
is quite a common requirement for

00:25:25,590 --> 00:25:30,840
production OpenStack workloads where you

00:25:28,830 --> 00:25:32,279
want to deploy it and keep say the

00:25:30,840 --> 00:25:34,830
storage traffic separate from the

00:25:32,279 --> 00:25:36,600
computer affic or the management traffic

00:25:34,830 --> 00:25:37,890
separate from some other category of

00:25:36,600 --> 00:25:40,049
traffic and so there are a number of

00:25:37,890 --> 00:25:43,080
predefined overlay networks that can be

00:25:40,049 --> 00:25:48,059
defined and we use Neutron and to handle

00:25:43,080 --> 00:25:50,130
that so I've got a few minutes left I'm

00:25:48,059 --> 00:25:51,390
going to attempt to run a demo this is

00:25:50,130 --> 00:25:54,210
going to be live and I'm running

00:25:51,390 --> 00:25:57,390
bleeding-edge upstream Cove so there's

00:25:54,210 --> 00:25:59,399
every chance it could go wrong but I'm

00:25:57,390 --> 00:26:01,770
gonna run this it also runs quite slowly

00:25:59,399 --> 00:26:03,120
on my laptop so what I might do is talk

00:26:01,770 --> 00:26:04,590
through a few things and get it up and

00:26:03,120 --> 00:26:07,080
running and then we can break for

00:26:04,590 --> 00:26:07,770
questions and then providing it doesn't

00:26:07,080 --> 00:26:08,460
fail horribly

00:26:07,770 --> 00:26:09,930
we can go back

00:26:08,460 --> 00:26:12,140
look at the result I'm at the end of the

00:26:09,930 --> 00:26:12,140
talk

00:26:25,470 --> 00:26:31,450
so as you noticed I didn't come in with

00:26:28,990 --> 00:26:33,910
a rack of bare metal hardware so my

00:26:31,450 --> 00:26:35,860
workaround for that is to use virtual

00:26:33,910 --> 00:26:38,500
machines which are configured to pretend

00:26:35,860 --> 00:26:41,710
to be bare metal and ironic has been

00:26:38,500 --> 00:26:44,200
configured to drive these basically by

00:26:41,710 --> 00:26:46,870
PXE and then there's a PXE ssh driver

00:26:44,200 --> 00:26:49,960
which basically uses ssh between the

00:26:46,870 --> 00:26:51,970
round disk and the ironic service to

00:26:49,960 --> 00:26:53,410
control things so this is not

00:26:51,970 --> 00:26:55,690
representative of how you would do a

00:26:53,410 --> 00:26:57,280
real Hardware deployment but it's a

00:26:55,690 --> 00:26:59,800
reasonable approximation for these

00:26:57,280 --> 00:27:01,360
purposes and this is also the same

00:26:59,800 --> 00:27:02,890
environment that most pokes would use

00:27:01,360 --> 00:27:04,660
for development unless they happen to

00:27:02,890 --> 00:27:07,210
have access to a bare metal testing that

00:27:04,660 --> 00:27:08,740
and you'll notice that this is one VM

00:27:07,210 --> 00:27:10,780
already up and running so we've talked

00:27:08,740 --> 00:27:13,300
about the under cloud the management

00:27:10,780 --> 00:27:15,880
node the small OpenStack however you

00:27:13,300 --> 00:27:18,160
want to think about it just so happens

00:27:15,880 --> 00:27:20,650
that for reasons related to the tooling

00:27:18,160 --> 00:27:22,900
we used to create it and we call that in

00:27:20,650 --> 00:27:25,660
stack and if you create a default

00:27:22,900 --> 00:27:29,500
environment using up steep upstream trip

00:27:25,660 --> 00:27:31,210
low or also the audio community have the

00:27:29,500 --> 00:27:34,360
Audio Manager tool which is based on

00:27:31,210 --> 00:27:34,930
trip low they're both nice ways to get

00:27:34,360 --> 00:27:38,740
up and running

00:27:34,930 --> 00:27:40,210
easing using trip load depending on how

00:27:38,740 --> 00:27:43,840
beading edge you feel like you want to

00:27:40,210 --> 00:27:47,290
be and in this case the in stack node is

00:27:43,840 --> 00:27:49,720
the on the cloud so I've got a shell

00:27:47,290 --> 00:27:51,190
window on here and let's have a quick

00:27:49,720 --> 00:27:53,640
look at some of the services which are

00:27:51,190 --> 00:27:53,640
running on here

00:27:59,940 --> 00:28:07,210
so ironic represents the bare-metal

00:28:04,330 --> 00:28:10,450
nodes we've registered three nodes here

00:28:07,210 --> 00:28:13,690
and these are these three VMs which are

00:28:10,450 --> 00:28:15,520
pretending to be their metal at the

00:28:13,690 --> 00:28:17,770
moment they're all in state of power off

00:28:15,520 --> 00:28:20,230
and provisioning state available so that

00:28:17,770 --> 00:28:22,210
basically means they can be accessed by

00:28:20,230 --> 00:28:27,070
the Nova scheduler and there are

00:28:22,210 --> 00:28:30,070
available to be provisioned T we can see

00:28:27,070 --> 00:28:32,440
there's nothing running in Nova yet and

00:28:30,070 --> 00:28:35,050
so as we talked about earlier on there's

00:28:32,440 --> 00:28:36,610
this flow between Nova as the user

00:28:35,050 --> 00:28:38,020
facing abstraction and the API that

00:28:36,610 --> 00:28:39,940
launches the nodes even though they're

00:28:38,020 --> 00:28:41,620
bare metal and ironic which is the

00:28:39,940 --> 00:28:48,310
backend that manages the actual hardware

00:28:41,620 --> 00:28:49,810
deployment itself and so he is the

00:28:48,310 --> 00:28:51,700
orchestration tool that's used to drive

00:28:49,810 --> 00:28:53,530
the whole process and we haven't got any

00:28:51,700 --> 00:28:56,140
stacks up and running at the moment so

00:28:53,530 --> 00:28:58,300
in order to make life easier for

00:28:56,140 --> 00:29:00,220
operators you can drive this directly

00:28:58,300 --> 00:29:02,920
via a heat command is a bit inconvenient

00:29:00,220 --> 00:29:05,560
unless you're a developer so there's an

00:29:02,920 --> 00:29:06,700
open stack client plug-in and it's as

00:29:05,560 --> 00:29:09,700
simple as doing this if you want to

00:29:06,700 --> 00:29:15,520
deploy a nova cloud you do open stack /

00:29:09,700 --> 00:29:18,100
cloud deploy and then in my case I've

00:29:15,520 --> 00:29:19,570
made a copy of the heap templates used

00:29:18,100 --> 00:29:21,640
to do the deployment to my local

00:29:19,570 --> 00:29:23,770
directory if you don't specify a

00:29:21,640 --> 00:29:26,410
location it will just use the default

00:29:23,770 --> 00:29:31,630
location which is user share OpenStack

00:29:26,410 --> 00:29:33,010
trip low heat templates okay

00:29:31,630 --> 00:29:39,430
so this is why I cross my fingers and

00:29:33,010 --> 00:29:41,530
hope it all works fine so you can see

00:29:39,430 --> 00:29:45,430
there there is a warning because I

00:29:41,530 --> 00:29:46,870
haven't told I haven't tagged any of

00:29:45,430 --> 00:29:48,280
these nodes in ironic to say that

00:29:46,870 --> 00:29:49,770
they're going to be a controller or

00:29:48,280 --> 00:29:53,440
compute they're just generic nodes

00:29:49,770 --> 00:29:54,610
that's actually just a warning and so

00:29:53,440 --> 00:29:56,230
it's going to go through and it's going

00:29:54,610 --> 00:29:58,570
to pick at random

00:29:56,230 --> 00:30:01,000
two of these nodes the default is one

00:29:58,570 --> 00:30:04,450
controller and one compute I would run

00:30:01,000 --> 00:30:06,880
more but I'll run out of RAM and then we

00:30:04,450 --> 00:30:08,260
get a lot of fairly verbose event

00:30:06,880 --> 00:30:10,010
listing so these are events that are

00:30:08,260 --> 00:30:12,350
coming straight out of heat

00:30:10,010 --> 00:30:16,070
and it gives you a nice view of the

00:30:12,350 --> 00:30:17,690
progress of the deployment unfortunately

00:30:16,070 --> 00:30:19,400
they're getting a bit chopped by the

00:30:17,690 --> 00:30:20,840
resolution of the screen so I don't as

00:30:19,400 --> 00:30:23,450
much I can do about that without making

00:30:20,840 --> 00:30:25,490
it too small but basically it's going to

00:30:23,450 --> 00:30:28,340
go through and it's going to create a

00:30:25,490 --> 00:30:29,780
group of nested stacks each one contains

00:30:28,340 --> 00:30:32,000
one server and some software

00:30:29,780 --> 00:30:33,830
configuration and then it's going to

00:30:32,000 --> 00:30:36,440
create a bunch of resources in Neutron

00:30:33,830 --> 00:30:37,820
and then it's going to do a bunch of

00:30:36,440 --> 00:30:40,010
configuration passes through the puppet

00:30:37,820 --> 00:30:41,240
and then if nothing goes wrong it will

00:30:40,010 --> 00:30:44,450
all be completed and we'll have a

00:30:41,240 --> 00:30:45,890
running OpenStack environment so I've

00:30:44,450 --> 00:30:49,450
got another window here so we can just

00:30:45,890 --> 00:30:49,450
watch things as they progress

00:30:58,410 --> 00:31:04,320
so we can see now that OpenStack over

00:31:01,650 --> 00:31:07,110
cloud deploy command has gone through

00:31:04,320 --> 00:31:08,430
and it's great at a heat stack and this

00:31:07,110 --> 00:31:10,410
is going to stay create in progress

00:31:08,430 --> 00:31:12,600
until such time as all of those nested

00:31:10,410 --> 00:31:15,300
stacks and all the configuration steps

00:31:12,600 --> 00:31:16,620
have been completed and when it goes to

00:31:15,300 --> 00:31:18,540
create complete that means that

00:31:16,620 --> 00:31:29,130
basically your OpenStack deployment is

00:31:18,540 --> 00:31:31,050
completed so similar to J's

00:31:29,130 --> 00:31:33,420
demonstration earlier on he did a

00:31:31,050 --> 00:31:35,970
resource listing of the heat stack and

00:31:33,420 --> 00:31:38,970
so you can see there's quite a lot more

00:31:35,970 --> 00:31:43,200
in this case because it's a much bigger

00:31:38,970 --> 00:31:46,350
template and you can see that there's a

00:31:43,200 --> 00:31:49,710
bunch of random script string resources

00:31:46,350 --> 00:31:52,290
a bunch of virtual IP and resources and

00:31:49,710 --> 00:31:55,680
a series of config resources that are

00:31:52,290 --> 00:31:58,400
used to configure the nodes if you now

00:31:55,680 --> 00:31:58,400
look in Nova

00:32:03,730 --> 00:32:10,570
so we can see that Nova has launched two

00:32:07,899 --> 00:32:12,010
nodes which ordinarily you would expect

00:32:10,570 --> 00:32:13,720
to be VMs but because of the way which

00:32:12,010 --> 00:32:15,700
we've configured things it's talking to

00:32:13,720 --> 00:32:18,880
ironic and it's going to some form to

00:32:15,700 --> 00:32:21,490
bare metal nodes which are again these

00:32:18,880 --> 00:32:25,750
two nodes which are configured to the

00:32:21,490 --> 00:32:28,870
dummy bare-metal better description so

00:32:25,750 --> 00:32:32,889
we've started these two nodes they're

00:32:28,870 --> 00:32:37,120
currently boosting they have already

00:32:32,889 --> 00:32:39,580
booted the round disk and have deployed

00:32:37,120 --> 00:32:43,710
a CentOS image which contains all of the

00:32:39,580 --> 00:32:43,710
OpenStack packages so

00:32:54,360 --> 00:33:00,820
so here we can see an ironic has powered

00:32:57,580 --> 00:33:04,420
on two of the nodes picked by the Nova

00:33:00,820 --> 00:33:05,950
scheduler and we're gonna have to wait a

00:33:04,420 --> 00:33:09,250
few minutes whilst this goes through and

00:33:05,950 --> 00:33:11,230
then the public configuration and other

00:33:09,250 --> 00:33:14,320
resources within the heat stack get

00:33:11,230 --> 00:33:16,840
created so thank you very much we've got

00:33:14,320 --> 00:33:18,760
ten minutes to go and I know having

00:33:16,840 --> 00:33:21,309
tested this earlier on that it's likely

00:33:18,760 --> 00:33:23,410
to take most of the remaining ten

00:33:21,309 --> 00:33:24,309
minutes so I would suggest maybe we

00:33:23,410 --> 00:33:28,150
break for a few minutes for questions

00:33:24,309 --> 00:33:43,540
now and then if we have time I'll come

00:33:28,150 --> 00:33:44,200
back to this in a minute yeah that's a

00:33:43,540 --> 00:33:48,070
very good question

00:33:44,200 --> 00:33:49,750
so in this case there's a tool a script

00:33:48,070 --> 00:33:51,250
called in stack vert setup it's in the

00:33:49,750 --> 00:33:53,559
triple o documentation and the audio

00:33:51,250 --> 00:33:55,960
manager documentation it goes through

00:33:53,559 --> 00:33:58,360
and basically uses verge to create the

00:33:55,960 --> 00:34:00,669
VMS and then it creates a configuration

00:33:58,360 --> 00:34:03,100
file which is just a JSON map which

00:34:00,669 --> 00:34:05,500
contains the details required an SSH key

00:34:03,100 --> 00:34:07,419
and an IP address basically for real

00:34:05,500 --> 00:34:09,490
bare metal you would create that JSON

00:34:07,419 --> 00:34:11,619
file manually and it would create a you

00:34:09,490 --> 00:34:13,899
would need things like a minimum you

00:34:11,619 --> 00:34:15,460
need the IPMI credentials but you may

00:34:13,899 --> 00:34:17,560
well choose to put other details such as

00:34:15,460 --> 00:34:19,210
MAC addresses and things in there in

00:34:17,560 --> 00:34:21,310
terms of discovery you need to be a bit

00:34:19,210 --> 00:34:23,980
careful about the definition so we can't

00:34:21,310 --> 00:34:26,440
just go out and automatically discover

00:34:23,980 --> 00:34:28,090
and random nodes on the network you need

00:34:26,440 --> 00:34:30,340
to at least provide the IPMI credentials

00:34:28,090 --> 00:34:31,720
but having done that there's another

00:34:30,340 --> 00:34:33,159
part of the process that I haven't

00:34:31,720 --> 00:34:36,070
talked about today which is doing node

00:34:33,159 --> 00:34:38,429
introspection and this uses the ironic

00:34:36,070 --> 00:34:41,200
Discoverer d sorry ironic inspector

00:34:38,429 --> 00:34:43,419
service and so this has been developed

00:34:41,200 --> 00:34:45,310
so closely with the ironic community and

00:34:43,419 --> 00:34:47,020
it uses a similar process to the

00:34:45,310 --> 00:34:49,899
deployment where it boots a special

00:34:47,020 --> 00:34:51,609
round disk and then it runs a bunch of

00:34:49,899 --> 00:34:53,770
introspection tests and then pushes the

00:34:51,609 --> 00:34:55,210
bait that the data back which is then

00:34:53,770 --> 00:34:58,780
used to populate things like the amount

00:34:55,210 --> 00:35:00,880
of RAM in ironic so the answer is yes in

00:34:58,780 --> 00:35:04,600
terms of introspection but you do need

00:35:00,880 --> 00:35:06,780
to manually input the inventory for the

00:35:04,600 --> 00:35:06,780
nodes

00:35:22,410 --> 00:35:28,420
yep so Demetri is is one of the main

00:35:26,500 --> 00:35:30,520
developers on the Aaronic inspector

00:35:28,420 --> 00:35:32,680
project and thanks for the clarification

00:35:30,520 --> 00:35:35,079
it sounds like discovery will be a

00:35:32,680 --> 00:35:40,650
feature feature so that's something to

00:35:35,079 --> 00:35:40,650
keep an eye out for any more questions

00:35:42,839 --> 00:35:47,740
do you do any kind of fan-out to keep

00:35:46,089 --> 00:35:51,040
like the glance images and the Pixies

00:35:47,740 --> 00:35:52,869
from all saturating nodes I mean is that

00:35:51,040 --> 00:35:55,930
part of the orchestration you do yes I'm

00:35:52,869 --> 00:35:57,880
not sure if ironic will put in like a

00:35:55,930 --> 00:35:59,470
random factor itself it's not something

00:35:57,880 --> 00:36:01,480
that we do within the triple o code

00:35:59,470 --> 00:36:03,309
itself again that's something which M to

00:36:01,480 --> 00:36:07,240
meet you may maybe I'll talk just like

00:36:03,309 --> 00:36:09,220
cascade yeah when you're booting like a

00:36:07,240 --> 00:36:10,839
hundred nodes or 200 nodes from a

00:36:09,220 --> 00:36:12,309
certain amount of images through a

00:36:10,839 --> 00:36:14,290
certain number of pixels you can

00:36:12,309 --> 00:36:17,079
overwhelm them unless you do some kind

00:36:14,290 --> 00:36:19,599
of cascading or is there any kind of

00:36:17,079 --> 00:36:22,049
clever way to not overwhelm some of the

00:36:19,599 --> 00:36:22,049
source nodes

00:36:26,950 --> 00:36:30,950
Thanks

00:36:28,070 --> 00:36:33,260
I mean overloading network for big C

00:36:30,950 --> 00:36:35,780
requests or overloading landline service

00:36:33,260 --> 00:36:38,630
so first of all we'll use an IP XE my

00:36:35,780 --> 00:36:39,260
default which is HTTP based so it's not

00:36:38,630 --> 00:36:44,450
that bad

00:36:39,260 --> 00:36:46,160
it's G FTP based P XE this process

00:36:44,450 --> 00:36:49,850
itself doesn't have any batching other

00:36:46,160 --> 00:36:52,190
than that and as to deployment process

00:36:49,850 --> 00:36:54,020
itself two options actually narrow Nick

00:36:52,190 --> 00:36:57,080
you can't directly deploy every node

00:36:54,020 --> 00:36:59,120
from glance which is essentially not

00:36:57,080 --> 00:37:01,580
from glance but from Swift amp URL and

00:36:59,120 --> 00:37:03,080
you can scale Swift pretty well or the

00:37:01,580 --> 00:37:08,240
second option which is default for

00:37:03,080 --> 00:37:10,160
tupelo is each node is exposed as an ice

00:37:08,240 --> 00:37:15,170
guys this year and is deployed from

00:37:10,160 --> 00:37:16,640
ionic conductor so as a former option

00:37:15,170 --> 00:37:18,560
which is not default is probably but

00:37:16,640 --> 00:37:21,470
much better at scaling that's I know

00:37:18,560 --> 00:37:25,160
some people using we can separate boss

00:37:21,470 --> 00:37:26,630
we just don't reconfigure it I mean in

00:37:25,160 --> 00:37:27,860
my experience the way which people tend

00:37:26,630 --> 00:37:29,090
to want to deploy is start off with a

00:37:27,860 --> 00:37:30,740
relatively small deployment and then

00:37:29,090 --> 00:37:32,120
scale out but you're right if you wanted

00:37:30,740 --> 00:37:34,340
to deploy hundreds or thousands of

00:37:32,120 --> 00:37:35,720
compute nodes for example at once you

00:37:34,340 --> 00:37:38,210
might need to there are several

00:37:35,720 --> 00:37:41,050
interfaces to the triple heat templates

00:37:38,210 --> 00:37:43,520
that allow you to override and provide

00:37:41,050 --> 00:37:45,410
custom configuration and you might do

00:37:43,520 --> 00:37:47,210
something like having a script that runs

00:37:45,410 --> 00:37:49,520
on all the nodes and waits for you know

00:37:47,210 --> 00:37:50,960
random amount of time so that there's

00:37:49,520 --> 00:37:53,660
certainly you know in addition to the

00:37:50,960 --> 00:37:54,890
scalability configuration that Dimitri

00:37:53,660 --> 00:37:57,050
mention there's there's ways that you

00:37:54,890 --> 00:37:59,090
could do that if you you know if you had

00:37:57,050 --> 00:38:02,990
a reason to deploy very very large

00:37:59,090 --> 00:38:06,430
environment in one go okay so only a few

00:38:02,990 --> 00:38:06,430
minutes left any more questions

00:38:13,630 --> 00:38:20,260
yeah yes so the question was if the

00:38:17,690 --> 00:38:23,539
under cloud the in stacked node fails

00:38:20,260 --> 00:38:26,720
will the over cloud be impacted and the

00:38:23,539 --> 00:38:27,559
answer is no it will be fine although if

00:38:26,720 --> 00:38:29,180
you were in the middle of doing a

00:38:27,559 --> 00:38:31,849
deployment you know you probably

00:38:29,180 --> 00:38:33,410
wouldn't be in a pink of the state but

00:38:31,849 --> 00:38:35,990
we've got documented procedures for

00:38:33,410 --> 00:38:37,339
backing up the under cloud node and if

00:38:35,990 --> 00:38:38,829
you have some kind of disaster you would

00:38:37,339 --> 00:38:41,329
restore everything from backups

00:38:38,829 --> 00:38:42,349
including the database contents and then

00:38:41,329 --> 00:38:44,329
you would be able to continue managing

00:38:42,349 --> 00:38:47,480
the cloud which is currently deployed

00:38:44,329 --> 00:38:49,609
there are no requirements for the under

00:38:47,480 --> 00:38:52,339
cloud to be continually running whilst

00:38:49,609 --> 00:38:53,599
the over cloud is deployed so providing

00:38:52,339 --> 00:38:55,160
you haven't got an in progress action

00:38:53,599 --> 00:38:56,809
you can take the under cloud down for

00:38:55,160 --> 00:38:58,039
maintenance perhaps if you need to do an

00:38:56,809 --> 00:38:59,839
upgrade of the under cloud to a new

00:38:58,039 --> 00:39:02,210
version that's perfectly fine you just

00:38:59,839 --> 00:39:03,829
need to schedule an outage window make

00:39:02,210 --> 00:39:05,599
sure that no one's doing anything in

00:39:03,829 --> 00:39:07,039
terms of configuring the over cloud and

00:39:05,599 --> 00:39:21,470
then you can take it down and everything

00:39:07,039 --> 00:39:23,690
will keep running absolutely fine so by

00:39:21,470 --> 00:39:25,279
default they are but they don't have to

00:39:23,690 --> 00:39:27,619
be so in case anyone didn't hear the

00:39:25,279 --> 00:39:29,119
question was is the image deployed on

00:39:27,619 --> 00:39:31,190
the nose the same for all the different

00:39:29,119 --> 00:39:33,170
all the different types so you can

00:39:31,190 --> 00:39:34,400
specify a different image per role so

00:39:33,170 --> 00:39:36,589
for example all the OpenStack

00:39:34,400 --> 00:39:39,440
controllers versus that opens that

00:39:36,589 --> 00:39:41,599
computes you do expect to be able to use

00:39:39,440 --> 00:39:43,099
the same image within a given group so

00:39:41,599 --> 00:39:46,160
if you had completely different

00:39:43,099 --> 00:39:47,510
architectures of hardware within say

00:39:46,160 --> 00:39:49,789
your compute group that could be a

00:39:47,510 --> 00:39:51,619
problem so we don't currently support

00:39:49,789 --> 00:39:53,660
mixing you know totally different

00:39:51,619 --> 00:39:54,799
architectures but if you had a

00:39:53,660 --> 00:39:56,930
requirement for a different image

00:39:54,799 --> 00:39:59,349
between say the controller knows and the

00:39:56,930 --> 00:40:02,000
computes that would be perfectly fine

00:39:59,349 --> 00:40:05,270
by default we just build one which

00:40:02,000 --> 00:40:07,990
contains everything though any more

00:40:05,270 --> 00:40:07,990
questions

00:40:08,180 --> 00:40:12,180
okay that's probably the last one on

00:40:10,710 --> 00:40:14,670
there more quickly see whether this is

00:40:12,180 --> 00:40:19,260
it possible to associate before the over

00:40:14,670 --> 00:40:21,870
cloud deploy an ironic node to a host

00:40:19,260 --> 00:40:25,860
name so I to say this MAC address or the

00:40:21,870 --> 00:40:29,580
CPM inode is over cloud controller 0 1

00:40:25,860 --> 00:40:31,890
yeah yeah yeah is I've actually got a

00:40:29,580 --> 00:40:34,470
documentation patch up at the moment for

00:40:31,890 --> 00:40:36,120
upload Docs which hasn't yet landed so

00:40:34,470 --> 00:40:37,800
there's two different ways of achieving

00:40:36,120 --> 00:40:41,460
that depending on how much control you

00:40:37,800 --> 00:40:43,680
require you can either tag a subset of

00:40:41,460 --> 00:40:44,910
the nodes in ironic with say this is a

00:40:43,680 --> 00:40:46,320
controller and then you can guarantee

00:40:44,910 --> 00:40:48,090
it's always going to be a controller

00:40:46,320 --> 00:40:50,070
perhaps because you know your controller

00:40:48,090 --> 00:40:51,750
nodes have more or less memory or

00:40:50,070 --> 00:40:54,030
something or you know your SEF nodes

00:40:51,750 --> 00:40:55,890
have a particular disk configuration and

00:40:54,030 --> 00:40:58,500
that is data that can be derived from

00:40:55,890 --> 00:40:59,670
the node introspection process and then

00:40:58,500 --> 00:41:01,920
we've got some tools that allow you to

00:40:59,670 --> 00:41:04,050
have matching rules so you can have some

00:41:01,920 --> 00:41:05,460
automatically apply for tags but I think

00:41:04,050 --> 00:41:06,990
your question is more granular if you

00:41:05,460 --> 00:41:09,030
want to say this node will always be

00:41:06,990 --> 00:41:12,270
controller 0 and the way which we do

00:41:09,030 --> 00:41:15,240
that is you again assign a capability to

00:41:12,270 --> 00:41:17,430
each node in ionic which might be node

00:41:15,240 --> 00:41:19,770
controller 0 and then you use Nova

00:41:17,430 --> 00:41:22,560
scheduler hints to basically force Nova

00:41:19,770 --> 00:41:23,970
to always pick that mode and yeah we've

00:41:22,560 --> 00:41:26,730
got a documentation patch up for that at

00:41:23,970 --> 00:41:27,990
the moment in the future there might be

00:41:26,730 --> 00:41:29,640
a more direct way of doing it but no

00:41:27,990 --> 00:41:32,970
bashad Euler hints provides a workable

00:41:29,640 --> 00:41:34,230
solution at this point so I've only got

00:41:32,970 --> 00:41:36,150
a couple of minutes left I'm going to

00:41:34,230 --> 00:41:38,910
have a quick look and see whether this

00:41:36,150 --> 00:41:40,170
is progressed enough for us to see any

00:41:38,910 --> 00:41:42,830
more unfortunately I think it may be

00:41:40,170 --> 00:41:42,830
running too slowly

00:41:52,600 --> 00:41:56,110
okay well I'm sorry but it looks like

00:41:54,520 --> 00:41:58,450
the the demo is gonna take a bit too

00:41:56,110 --> 00:42:01,060
long to run due to being uh overloading

00:41:58,450 --> 00:42:02,350
my poor laptop we could probably take

00:42:01,060 --> 00:42:04,240
well I think we're actually out of time

00:42:02,350 --> 00:42:05,590
so I think we'll leave it at that but

00:42:04,240 --> 00:42:37,180
thank you for listening and I hope that

00:42:05,590 --> 00:42:40,090
was useful we got the same issue we we

00:42:37,180 --> 00:42:46,210
have laptops and just you know it's not

00:42:40,090 --> 00:42:52,290
easy memory it's not even I mean the

00:42:46,210 --> 00:42:52,290
physics for the minimum and then you

00:42:59,010 --> 00:43:06,080
we're looking at places on the reduce to

00:43:01,020 --> 00:43:06,080
the ground we have some happy guy

00:43:17,100 --> 00:43:21,260
copy of the presentation

00:46:43,470 --> 00:46:49,940
I was like we don't discussion about

00:46:54,820 --> 00:47:12,750
without debating which is better yeah

00:46:57,010 --> 00:47:29,200
we're not going to do that nice medium

00:47:12,750 --> 00:47:31,630
think we're in the phone before it's a

00:47:29,200 --> 00:47:34,590
little last I mean he will use this and

00:47:31,630 --> 00:47:34,590

YouTube URL: https://www.youtube.com/watch?v=-khoXlRAE1w


