Title: KubeFed, an Elegant Tool for Hybrid Cloud
Publication date: 2019-10-02
Playlist: DevConfUS 2019
Description: 
	Speakers: Chandler Wilkerson and Davis Phillips

Overwhelmed by the overhead of managing the same application in multiple clusters manually? This talk introduces namespace-scoped multi-cluster federation, guiding attendees through employing the KubeFed operator to propagate Kubernetes API objects across the same namespace in multiple clusters while maintaining the ability to adjust configurations on a per cluster basis.
Captions: 
	00:00:08,710 --> 00:00:20,030
today my name is Davis Phillips and this

00:00:11,510 --> 00:00:22,010
is Chandler Wilson called cubed Q

00:00:20,030 --> 00:00:25,720
federal s is allow you to two decimal

00:00:22,010 --> 00:00:25,720
multiple clusters and manage them as one

00:00:27,620 --> 00:00:34,100
it's a federation of the product

00:00:29,570 --> 00:00:36,530
impurities coming to redone there was a

00:00:34,100 --> 00:00:38,989
v1 now there's a v2 of the product it's

00:00:36,530 --> 00:00:43,070
still kinda tech review for urban shift

00:00:38,989 --> 00:00:45,050
as a product that kubernetes basically

00:00:43,070 --> 00:00:47,570
the the lease offending allows you to

00:00:45,050 --> 00:00:50,629
manage multiple clusters from a single

00:00:47,570 --> 00:00:51,520
control plan now how does it work with

00:00:50,629 --> 00:00:54,680
get ops

00:00:51,520 --> 00:00:57,830
get ups is a relatively new concept that

00:00:54,680 --> 00:01:00,020
uses lead that was a source of truth for

00:00:57,830 --> 00:01:01,610
your infrastructure and deployments the

00:01:00,020 --> 00:01:04,250
son of your concept of kubernetes are on

00:01:01,610 --> 00:01:04,820
open shift but it's a newer concept from

00:01:04,250 --> 00:01:09,830
an infrastructure perspective

00:01:04,820 --> 00:01:13,300
perspective to a demo at some point and

00:01:09,830 --> 00:01:13,300
lastly a Q&A session

00:01:17,810 --> 00:01:22,650
I'm ready alright so we just managed to

00:01:20,880 --> 00:01:26,510
keep that still working progress it is

00:01:22,650 --> 00:01:28,650
very much still a products than beta yet

00:01:26,510 --> 00:01:31,590
there may be some changes over the how

00:01:28,650 --> 00:01:33,180
the product works today that's the idea

00:01:31,590 --> 00:01:35,940
is the same but the inception may be

00:01:33,180 --> 00:01:37,440
changing over time and then last the

00:01:35,940 --> 00:01:41,480
backwards compatibility is not assured

00:01:37,440 --> 00:01:41,480
until its beta and 0 1 0

00:01:43,210 --> 00:01:49,300
so our protection them except this

00:01:46,440 --> 00:01:52,570
cluster a bunch of clusters on different

00:01:49,300 --> 00:01:58,330
platforms I provided a could be vSphere

00:01:52,570 --> 00:01:59,790
OpenStack AWS GCP even better metal all

00:01:58,330 --> 00:02:02,530
these clusters are managed independently

00:01:59,790 --> 00:02:05,020
and typically you'd have infrastructure

00:02:02,530 --> 00:02:06,910
endpoints harder to get traffic into the

00:02:05,020 --> 00:02:08,860
clusters or to let down surround the

00:02:06,910 --> 00:02:10,810
clusters but never will know where the

00:02:08,860 --> 00:02:13,560
sync disasters or SiC applications

00:02:10,810 --> 00:02:13,560
around the clusters

00:02:14,790 --> 00:02:19,560
so Tamara's idea is a hybrid cloud with

00:02:17,549 --> 00:02:23,040
kubernetes having a control plane that

00:02:19,560 --> 00:02:26,519
manages all three clusters the control

00:02:23,040 --> 00:02:27,870
plane will ready to roll out in migrate

00:02:26,519 --> 00:02:31,440
applications between the clusters

00:02:27,870 --> 00:02:34,069
seamlessly using kirino's concepts like

00:02:31,440 --> 00:02:34,069
deployments

00:02:37,880 --> 00:02:41,990
some of the problems are trying to sell

00:02:39,620 --> 00:02:43,670
the Federation is having a unified

00:02:41,990 --> 00:02:45,500
control plan for all applications

00:02:43,670 --> 00:02:47,420
because right now like I said it's all

00:02:45,500 --> 00:02:49,220
independently managed somehow

00:02:47,420 --> 00:02:50,960
availability for applications being able

00:02:49,220 --> 00:02:54,530
to move from data center and data center

00:02:50,960 --> 00:02:57,530
with limited or no downtime disaster

00:02:54,530 --> 00:02:59,360
recovery Geographic is first thing

00:02:57,530 --> 00:03:01,550
they're balancing between applications

00:02:59,360 --> 00:03:03,470
and data centers and then application

00:03:01,550 --> 00:03:04,610
portability and being able to move your

00:03:03,470 --> 00:03:08,110
application around where you need it

00:03:04,610 --> 00:03:08,110
when you need it and based on demand

00:03:09,420 --> 00:03:14,550
so let had the people working on the

00:03:12,150 --> 00:03:16,980
Federation product we have an

00:03:14,550 --> 00:03:19,440
involvement from CTO the systems

00:03:16,980 --> 00:03:22,319
engineering our group the engineering

00:03:19,440 --> 00:03:23,970
group writing the binaries for the

00:03:22,319 --> 00:03:27,420
storage team for our storage back-end

00:03:23,970 --> 00:03:29,010
and the networking in other verbs for

00:03:27,420 --> 00:03:30,690
both interconnects between the clusters

00:03:29,010 --> 00:03:32,580
and then ingress egress points from

00:03:30,690 --> 00:03:35,760
clustering

00:03:32,580 --> 00:03:38,840
unless a direction BT was a seven-story

00:03:35,760 --> 00:03:38,840
source upstream product

00:03:41,680 --> 00:03:47,739
it's okay the Federation essentially

00:03:45,280 --> 00:03:52,420
kind of cover leaders before but nothing

00:03:47,739 --> 00:03:54,760
Fester's or lots of success towards each

00:03:52,420 --> 00:03:56,590
other there's no Road management that

00:03:54,760 --> 00:03:58,120
could be ci City pipelines that manage

00:03:56,590 --> 00:04:00,189
between those clusters but for the most

00:03:58,120 --> 00:04:03,430
part they're all completely independent

00:04:00,189 --> 00:04:05,200
of one another we explored the idea of

00:04:03,430 --> 00:04:07,209
stretch cluster which is taking a single

00:04:05,200 --> 00:04:10,450
cluster and stretching across multiple

00:04:07,209 --> 00:04:14,139
data centers so you're SCD and points

00:04:10,450 --> 00:04:17,019
are located and kind of some storage and

00:04:14,139 --> 00:04:23,949
performance issues with this most

00:04:17,019 --> 00:04:26,199
scenarios you have metro connectivity to

00:04:23,949 --> 00:04:29,590
the cluster which is multiple clusters

00:04:26,199 --> 00:04:31,240
can make a bias in the control climb and

00:04:29,590 --> 00:04:33,430
then our first tester is the requester

00:04:31,240 --> 00:04:34,900
actually running the control plane it's

00:04:33,430 --> 00:04:36,190
kind of the manager of all the testers

00:04:34,900 --> 00:04:40,020
and then lastly the member of clusters

00:04:36,190 --> 00:04:40,020
are those joined to the control plan

00:04:45,820 --> 00:04:52,480
so y cube then the control plan to

00:04:50,080 --> 00:04:55,390
manage resources across multiple under

00:04:52,480 --> 00:04:57,580
and testers its that are agnostic which

00:04:55,390 --> 00:04:59,410
is an important aesthetic factor for the

00:04:57,580 --> 00:05:02,560
application portability she's not gonna

00:04:59,410 --> 00:05:03,490
be locked into AWS GCP OpenStack or V

00:05:02,560 --> 00:05:05,200
storm you undergoing to move your

00:05:03,490 --> 00:05:06,910
application around as you need to in

00:05:05,200 --> 00:05:10,420
stand up and move data centers as you

00:05:06,910 --> 00:05:12,520
need to the best part about it is that

00:05:10,420 --> 00:05:13,840
basically any of the API resources and

00:05:12,520 --> 00:05:16,620
communities can be federated

00:05:13,840 --> 00:05:19,690
this means that deployments config Maps

00:05:16,620 --> 00:05:22,240
secrets service accounts your standard

00:05:19,690 --> 00:05:24,480
kubernetes resources can be federated

00:05:22,240 --> 00:05:28,120
and applied across multiple clusters

00:05:24,480 --> 00:05:31,600
there's no latency requirements it could

00:05:28,120 --> 00:05:33,870
be a long long range latency low

00:05:31,600 --> 00:05:33,870
connectivity

00:05:35,870 --> 00:05:42,310
here's an example I said it's a departed

00:05:39,160 --> 00:05:44,530
so your typical deployment

00:05:42,310 --> 00:05:47,320
a couple instruction to deploy the

00:05:44,530 --> 00:05:49,540
application secrets and all the things

00:05:47,320 --> 00:05:51,790
for a standard determination converting

00:05:49,540 --> 00:05:53,380
into a federated deployment it adds some

00:05:51,790 --> 00:05:55,510
placements you can put this application

00:05:53,380 --> 00:05:56,950
across multiple testers and then do

00:05:55,510 --> 00:06:00,880
other ads and move it between the

00:05:56,950 --> 00:06:03,340
clusters the cube fed CTL which is the

00:06:00,880 --> 00:06:05,620
CLI for cube fed allows you to convert

00:06:03,340 --> 00:06:08,700
to a standard resource types into

00:06:05,620 --> 00:06:08,700
federal resource types

00:06:14,790 --> 00:06:19,920
so the federal resources are comprised

00:06:17,610 --> 00:06:24,230
of three main properties it's gonna be

00:06:19,920 --> 00:06:24,230
your template placement and overrides

00:06:25,670 --> 00:06:32,970
this is Sigma so if you look here at the

00:06:30,780 --> 00:06:34,410
spec is a template file so this is the

00:06:32,970 --> 00:06:36,690
template that gets applied to all three

00:06:34,410 --> 00:06:39,540
clusters or for any reason in this case

00:06:36,690 --> 00:06:41,420
we have placement for to the config map

00:06:39,540 --> 00:06:44,790
supplied to the tester one accessory to

00:06:41,420 --> 00:06:47,010
and then you can actually do over adds

00:06:44,790 --> 00:06:49,050
four tests for individual professors of

00:06:47,010 --> 00:06:51,150
any be customized so in this case

00:06:49,050 --> 00:06:55,760
success for two has an override for the

00:06:51,150 --> 00:06:55,760
data path and the values obviously

00:06:59,219 --> 00:07:05,180
Ola has a cat and then Allah has a dog

00:07:02,180 --> 00:07:05,180
polish

00:07:09,300 --> 00:07:16,200
so one of the young going discussions

00:07:12,540 --> 00:07:17,970
for keep that in federation initially

00:07:16,200 --> 00:07:19,920
there was a cluster wide federation

00:07:17,970 --> 00:07:23,190
which basically read the entire cluster

00:07:19,920 --> 00:07:24,330
and all the resources since then there's

00:07:23,190 --> 00:07:26,760
been discussion to move it into a

00:07:24,330 --> 00:07:29,220
namespace federation so that only a

00:07:26,760 --> 00:07:32,150
single main space is saturated this kind

00:07:29,220 --> 00:07:34,920
of matches the multi-tenant kubernetes

00:07:32,150 --> 00:07:37,410
ideology about keeping an independent of

00:07:34,920 --> 00:07:41,660
the entire cluster and being applied

00:07:37,410 --> 00:07:41,660
specifically to namespaces each roster

00:07:47,820 --> 00:07:53,070
so the cluster scope cube that is gonna

00:07:51,090 --> 00:07:56,610
handle resources and namespaces cluster

00:07:53,070 --> 00:07:58,020
well like I was saying this thing we

00:07:56,610 --> 00:07:59,730
required if you trying to feather that

00:07:58,020 --> 00:08:02,510
cluster resources that are cluster wide

00:07:59,730 --> 00:08:04,470
like a cholesterol cluster roll binding

00:08:02,510 --> 00:08:07,090
cluster storage classes

00:08:04,470 --> 00:08:08,919
[Music]

00:08:07,090 --> 00:08:11,410
basically you control multiple names

00:08:08,919 --> 00:08:13,980
versus with one set of cluster wide

00:08:11,410 --> 00:08:13,980
relationships

00:08:17,240 --> 00:08:22,970
the names best step keep that last for

00:08:20,960 --> 00:08:25,220
multiple instances of Cupid operating

00:08:22,970 --> 00:08:26,900
independently this is going to provide

00:08:25,220 --> 00:08:29,599
lesser role privilege for service

00:08:26,900 --> 00:08:32,539
accounts cluster ride only for specific

00:08:29,599 --> 00:08:36,310
namespaces and each instance will handle

00:08:32,539 --> 00:08:36,310
the cluster relationship evidently

00:08:42,330 --> 00:08:44,930
Jemma

00:08:44,960 --> 00:08:50,500
okay well I've trying to federate

00:08:47,480 --> 00:08:52,820
multiple clusters together one of the

00:08:50,500 --> 00:08:56,390
issues that we've run into in addition

00:08:52,820 --> 00:08:58,640
to trying to get the objects between the

00:08:56,390 --> 00:08:59,990
clusters is trying to figure out how to

00:08:58,640 --> 00:09:02,180
get the networking working between the

00:08:59,990 --> 00:09:05,440
clusters so this is mostly just work in

00:09:02,180 --> 00:09:08,150
progress and identifying key points

00:09:05,440 --> 00:09:09,590
basically one of the first things that

00:09:08,150 --> 00:09:12,110
you need to figure out is actually how

00:09:09,590 --> 00:09:13,730
to get a tunnel going between service

00:09:12,110 --> 00:09:16,400
networks back in service networks of the

00:09:13,730 --> 00:09:19,010
clusters one of the issues that we've

00:09:16,400 --> 00:09:22,300
run into that with that is of named

00:09:19,010 --> 00:09:25,550
curve actually the cider ranges the

00:09:22,300 --> 00:09:28,340
actual IP ranges between those they tend

00:09:25,550 --> 00:09:31,460
to overlap when you just blindly deploy

00:09:28,340 --> 00:09:35,930
clusters and so one of the things you

00:09:31,460 --> 00:09:37,430
have to do is if you want to tunnel

00:09:35,930 --> 00:09:40,550
between clusters you have to think about

00:09:37,430 --> 00:09:43,550
that at the front end and make sure that

00:09:40,550 --> 00:09:46,520
the the internet the IP ranges are

00:09:43,550 --> 00:09:47,780
distinct between the clusters so that

00:09:46,520 --> 00:09:50,720
you can actually get some routing rules

00:09:47,780 --> 00:09:52,880
and so you have some tunneling routings

00:09:50,720 --> 00:09:57,140
and additional issue because you may

00:09:52,880 --> 00:09:59,540
have some semester networks or servers

00:09:57,140 --> 00:10:02,270
network like VX land and an open ship

00:09:59,540 --> 00:10:04,460
cluster that's who you have to get into

00:10:02,270 --> 00:10:08,300
the rules and adjust how the traffic

00:10:04,460 --> 00:10:09,980
goes between the clusters and once

00:10:08,300 --> 00:10:11,000
you've figured out tunneling and routing

00:10:09,980 --> 00:10:13,940
then you have an additional problem

00:10:11,000 --> 00:10:16,340
where you actually want to be able to

00:10:13,940 --> 00:10:18,680
use the services from in one cluster in

00:10:16,340 --> 00:10:23,750
another cluster and you start to realize

00:10:18,680 --> 00:10:27,740
that whenever you do lookups of clusters

00:10:23,750 --> 00:10:30,620
DNS like Forest Service that it's

00:10:27,740 --> 00:10:32,600
usually clustered local and so putting

00:10:30,620 --> 00:10:35,090
some sort of naming into that some sort

00:10:32,600 --> 00:10:37,210
of cluster identity into that there's

00:10:35,090 --> 00:10:41,630
there's some work to be done there and

00:10:37,210 --> 00:10:43,610
finally once you get your dev set cops

00:10:41,630 --> 00:10:46,400
going then you need to make sure that

00:10:43,610 --> 00:10:48,590
your your network security people are

00:10:46,400 --> 00:10:51,650
involved and there's some way to put

00:10:48,590 --> 00:10:55,670
actual network policies into this kind

00:10:51,650 --> 00:10:57,260
of control so that you when you do have

00:10:55,670 --> 00:11:00,200
data going off cluster you're not

00:10:57,260 --> 00:11:02,620
violating some sort of policies said we

00:11:00,200 --> 00:11:02,620
want to avoid

00:11:03,120 --> 00:11:07,769
so we're just looking at the

00:11:05,399 --> 00:11:10,110
technologies right now one of the ones

00:11:07,769 --> 00:11:13,050
were kind of fast falling right now is

00:11:10,110 --> 00:11:15,720
Submariner and Submariner essentially

00:11:13,050 --> 00:11:19,079
has this concept of setting up a bunch

00:11:15,720 --> 00:11:20,730
of member clusters and laying what they

00:11:19,079 --> 00:11:24,720
call undersea cables between them which

00:11:20,730 --> 00:11:28,110
are actually just VPN connections

00:11:24,720 --> 00:11:29,790
and so we're trying to discuss whether

00:11:28,110 --> 00:11:32,070
this should move into the kubernetes

00:11:29,790 --> 00:11:34,350
multi-gesture sig special interest group

00:11:32,070 --> 00:11:36,300
which also handles coop debt at the

00:11:34,350 --> 00:11:41,040
moment

00:11:36,300 --> 00:11:46,380
and all my gosh we've left in sorry that

00:11:41,040 --> 00:11:48,210
was another Def Con apologies okay the

00:11:46,380 --> 00:11:51,780
cup that operators how we're deploying

00:11:48,210 --> 00:11:54,240
in open ship for and pretty much

00:11:51,780 --> 00:11:56,370
operator hub is what we're trying to

00:11:54,240 --> 00:11:59,760
move to for deploying anything that's

00:11:56,370 --> 00:12:05,370
complex and so there was an operator for

00:11:59,760 --> 00:12:07,860
coop that may still be in the operator

00:12:05,370 --> 00:12:11,750
hub and the old version which was called

00:12:07,860 --> 00:12:14,520
federation we're moving to coop fed now

00:12:11,750 --> 00:12:16,710
this is as I said it's the supported way

00:12:14,520 --> 00:12:20,430
when you're going into open ship for and

00:12:16,710 --> 00:12:22,260
beyond and it allows you to do both

00:12:20,430 --> 00:12:25,650
namespace and cluster scope of the

00:12:22,260 --> 00:12:28,230
Federation which put that in because it

00:12:25,650 --> 00:12:32,220
wasn't it at first it was only names

00:12:28,230 --> 00:12:38,460
face at first and as a slide writing

00:12:32,220 --> 00:12:40,740
time where it's not quite the full beta

00:12:38,460 --> 00:12:43,860
version just yet I think we're still on

00:12:40,740 --> 00:12:46,320
like a release candidate five or so but

00:12:43,860 --> 00:12:48,780
we're very close to full beta once we

00:12:46,320 --> 00:12:51,070
once the the team works out some

00:12:48,780 --> 00:12:52,959
additional issues

00:12:51,070 --> 00:12:54,850
and so there there was one kind of

00:12:52,959 --> 00:12:57,820
gotcha I wanted to point out here

00:12:54,850 --> 00:13:00,790
because when you're talking about single

00:12:57,820 --> 00:13:03,310
name space versus cluster wide when you

00:13:00,790 --> 00:13:05,139
saw the operator it actually makes more

00:13:03,310 --> 00:13:07,420
sense to install the operator to watch a

00:13:05,139 --> 00:13:10,029
single name space if you want your cube

00:13:07,420 --> 00:13:13,990
then to do cluster wide and vice versa

00:13:10,029 --> 00:13:15,670
if you want your crew Fed to be in

00:13:13,990 --> 00:13:17,769
multiple different namespaces doing

00:13:15,670 --> 00:13:19,600
single name space then you have to make

00:13:17,769 --> 00:13:22,300
your operator watch all namespaces so

00:13:19,600 --> 00:13:25,899
there's just kind of a naming kind of

00:13:22,300 --> 00:13:28,410
disconnect there but here's the link for

00:13:25,899 --> 00:13:28,410
the operator

00:13:30,650 --> 00:13:33,850
sorry couldn't quite hear

00:13:38,220 --> 00:13:46,470
we can you want to see like in the

00:13:42,730 --> 00:13:46,470
cluster or just

00:13:53,399 --> 00:13:57,510
so we mentioned that we could install

00:13:55,589 --> 00:14:01,440
the opera in such a way that it watches

00:13:57,510 --> 00:14:04,290
one namespace does that mean we Fed rate

00:14:01,440 --> 00:14:07,889
there is object in that names face

00:14:04,290 --> 00:14:09,540
across to another cluster okay so so

00:14:07,889 --> 00:14:11,279
there's the disconnect and that's why

00:14:09,540 --> 00:14:15,410
the naming gets kind of confusing the

00:14:11,279 --> 00:14:18,420
operator watches for a specific see our

00:14:15,410 --> 00:14:20,880
customers horse called coop vet which

00:14:18,420 --> 00:14:23,339
then instantiates the actual coop fed

00:14:20,880 --> 00:14:24,899
controller manager and so the operator

00:14:23,339 --> 00:14:28,740
is doing is waiting for you to drop that

00:14:24,899 --> 00:14:31,290
coop fed file in either for a tester

00:14:28,740 --> 00:14:35,279
wide version or a specific namespace and

00:14:31,290 --> 00:14:38,240
so if you want to do Chester Wynkoop fed

00:14:35,279 --> 00:14:41,519
then you want a single coop fed see are

00:14:38,240 --> 00:14:44,519
usually in the coop - Federation -

00:14:41,519 --> 00:14:47,399
system namespace because that's the one

00:14:44,519 --> 00:14:51,690
that the CLI automatically goes to when

00:14:47,399 --> 00:14:52,889
it expects to find it so that's why it's

00:14:51,690 --> 00:14:54,480
there's a little bit of confusion

00:14:52,889 --> 00:14:56,750
between the operator thanks for calling

00:14:54,480 --> 00:14:56,750
thank you

00:14:58,900 --> 00:15:04,029
okay so like I said we have a lot of

00:15:01,420 --> 00:15:06,880
teams who are kind of looking into this

00:15:04,029 --> 00:15:08,820
and we've identified some challenge

00:15:06,880 --> 00:15:13,210
spaces that were still working through

00:15:08,820 --> 00:15:16,480
one of them is trying to get DNS and

00:15:13,210 --> 00:15:18,910
ingress of services into federated

00:15:16,480 --> 00:15:23,920
clusters with the ability to then switch

00:15:18,910 --> 00:15:25,690
around regions pretty quickly so we just

00:15:23,920 --> 00:15:28,690
have kind of the typical problems that

00:15:25,690 --> 00:15:33,430
everybody has with DNS that the time to

00:15:28,690 --> 00:15:35,140
live and trying to shorten the amount of

00:15:33,430 --> 00:15:38,910
time that it takes for changes to happen

00:15:35,140 --> 00:15:42,220
but DNS is not cooperative with that

00:15:38,910 --> 00:15:45,370
trying to get mint accessor of storage

00:15:42,220 --> 00:15:48,400
going is a challenge because if you're

00:15:45,370 --> 00:15:50,320
thinking about moving apps around of

00:15:48,400 --> 00:15:53,290
course everybody you know it's always

00:15:50,320 --> 00:15:55,690
easy if your apps are stateless it's not

00:15:53,290 --> 00:15:57,130
so much if they're stay full so we're

00:15:55,690 --> 00:15:59,920
still trying to work out exactly how

00:15:57,130 --> 00:16:04,790
Federation looks with actual storage

00:15:59,920 --> 00:16:08,040
rather than just flinging types around

00:16:04,790 --> 00:16:09,450
federating operators themselves would be

00:16:08,040 --> 00:16:10,740
a really powerful concept that's

00:16:09,450 --> 00:16:11,190
something we're still exploring right

00:16:10,740 --> 00:16:14,460
now

00:16:11,190 --> 00:16:16,680
and because operators kind of imply a

00:16:14,460 --> 00:16:18,600
sort of an ordering to things happening

00:16:16,680 --> 00:16:22,380
or you know just the ability to do

00:16:18,600 --> 00:16:25,529
whatever code that you need it's harder

00:16:22,380 --> 00:16:27,149
for it to work and they slap it down and

00:16:25,529 --> 00:16:30,660
expect it to be eventually consistent

00:16:27,149 --> 00:16:32,010
kind of model like kubernetes which part

00:16:30,660 --> 00:16:35,130
of the reason my offerors came into

00:16:32,010 --> 00:16:39,660
existence anyway so trying to federate

00:16:35,130 --> 00:16:42,899
that is as a challenge as far as just

00:16:39,660 --> 00:16:45,060
trying to work out how going beyond

00:16:42,899 --> 00:16:47,730
something that's in an operator trying

00:16:45,060 --> 00:16:49,230
to federate applications themselves and

00:16:47,730 --> 00:16:52,110
how you do that in the right order so

00:16:49,230 --> 00:16:55,640
said it works and then can migrate we've

00:16:52,110 --> 00:16:58,420
got some work in that we have some demos

00:16:55,640 --> 00:17:00,970
and then trying to work out what kind of

00:16:58,420 --> 00:17:04,610
infrastructure concerns like can you get

00:17:00,970 --> 00:17:07,040
coop said to actually

00:17:04,610 --> 00:17:09,410
federates some of the more principle

00:17:07,040 --> 00:17:14,330
things behind kubernetes cluster and

00:17:09,410 --> 00:17:16,790
allow more admin kind of roles to be

00:17:14,330 --> 00:17:20,750
federated still working on that as well

00:17:16,790 --> 00:17:22,460
and the final one is kind of a sticky

00:17:20,750 --> 00:17:25,070
point of day to operations we like to

00:17:22,460 --> 00:17:26,870
spin up quick demo clusters say hey look

00:17:25,070 --> 00:17:29,900
it works and shut everything down

00:17:26,870 --> 00:17:31,640
and forget about tomorrow and so we

00:17:29,900 --> 00:17:33,530
always have to come back and write like

00:17:31,640 --> 00:17:35,510
okay how do you ensure that

00:17:33,530 --> 00:17:38,810
authorization works how do you ensure

00:17:35,510 --> 00:17:41,450
that backup and recovery are working

00:17:38,810 --> 00:17:42,890
what do you do if you need to move a

00:17:41,450 --> 00:17:45,400
data center what do you you know how

00:17:42,890 --> 00:17:45,400
does this all work

00:17:48,640 --> 00:17:56,080
so as I was saying earlier the get-ups

00:17:52,299 --> 00:17:57,910
is kind of a shift from the source of

00:17:56,080 --> 00:18:00,429
truth being a pile of the animal in an

00:17:57,910 --> 00:18:05,380
admins directory to the source of truth

00:18:00,429 --> 00:18:09,309
being in a git repo with proper full

00:18:05,380 --> 00:18:12,130
requests and you know kind of the chain

00:18:09,309 --> 00:18:13,630
of events that have happened and sign

00:18:12,130 --> 00:18:15,790
offs and all that kind of stuff

00:18:13,630 --> 00:18:17,590
and so there are a number of tools

00:18:15,790 --> 00:18:21,309
coming out right now and we've been

00:18:17,590 --> 00:18:26,110
looking at a few of these just trying to

00:18:21,309 --> 00:18:28,540
work on get offs workflow and so what

00:18:26,110 --> 00:18:31,360
we've found so far is that you know

00:18:28,540 --> 00:18:32,860
obviously this looks different from what

00:18:31,360 --> 00:18:35,919
we're doing with coop fed because it's a

00:18:32,860 --> 00:18:40,630
full modality rather than a push kind of

00:18:35,919 --> 00:18:44,500
idea although some get-ups tools do

00:18:40,630 --> 00:18:46,059
multi cluster and some of them push and

00:18:44,500 --> 00:18:48,190
some of them pull to the remote cluster

00:18:46,059 --> 00:18:50,340
so there's not even quite consensus on

00:18:48,190 --> 00:18:50,340
that

00:18:51,740 --> 00:18:58,210
and you can you can kind of basically

00:18:54,770 --> 00:19:00,100
you know think of get offs as

00:18:58,210 --> 00:19:02,980
just running over and over and over

00:19:00,100 --> 00:19:08,249
again a crew-cut will apply or you know

00:19:02,980 --> 00:19:08,249
an OSI apply on a set of yeah Mille

00:19:09,960 --> 00:19:14,429
and so you get the kind of workflow

00:19:11,789 --> 00:19:15,600
where you're just putting Emmalyn to get

00:19:14,429 --> 00:19:17,610
repos somewhere and then there's a

00:19:15,600 --> 00:19:21,360
container that makes sure that it gets

00:19:17,610 --> 00:19:23,940
blasted out to the fester what we're

00:19:21,360 --> 00:19:25,710
thinking of with coop fed is to put coop

00:19:23,940 --> 00:19:28,259
fed kind of in between so you have the

00:19:25,710 --> 00:19:31,710
get-ups model but the get-ups is feeding

00:19:28,259 --> 00:19:34,259
not resources but federated resources

00:19:31,710 --> 00:19:38,039
into your cluster and then that handles

00:19:34,259 --> 00:19:39,360
the amount of cluster we'd like to do

00:19:38,039 --> 00:19:42,240
that and that's just because we're

00:19:39,360 --> 00:19:46,740
trying to vet on coop fed but because

00:19:42,240 --> 00:19:48,570
we're we see some value in putting coop

00:19:46,740 --> 00:19:50,399
fed into the middle of that one of them

00:19:48,570 --> 00:19:53,100
is that you can set up overrides for the

00:19:50,399 --> 00:19:58,110
clusters so that the multi cluster piece

00:19:53,100 --> 00:20:00,179
of this is more handled and so another

00:19:58,110 --> 00:20:04,640
part of that is replica scheduling

00:20:00,179 --> 00:20:08,450
preferences so rather than

00:20:04,640 --> 00:20:11,140
trying to do your your kind of replica

00:20:08,450 --> 00:20:14,630
count per cluster who fed actually can

00:20:11,140 --> 00:20:17,440
manage to say something along the lines

00:20:14,630 --> 00:20:20,150
of of this set of professors that I am

00:20:17,440 --> 00:20:22,370
propagating this resource to I want to

00:20:20,150 --> 00:20:25,490
ensure that in copies across these

00:20:22,370 --> 00:20:28,400
clusters are there rather than each

00:20:25,490 --> 00:20:30,590
cluster should have five copies or maybe

00:20:28,400 --> 00:20:32,240
that cluster should have three so that's

00:20:30,590 --> 00:20:34,730
that's what our demos look like right

00:20:32,240 --> 00:20:37,299
now we're still working towards exactly

00:20:34,730 --> 00:20:37,299
what that would look like

00:20:37,320 --> 00:20:41,210
what you want to drive them over

00:20:45,130 --> 00:20:50,409
so we're going to show you here is a

00:20:47,309 --> 00:20:53,440
federated application running across

00:20:50,409 --> 00:20:56,470
three different AWS festers one in u.s.

00:20:53,440 --> 00:20:59,950
least one and east two and then one in

00:20:56,470 --> 00:21:03,250
West to Chandlers set it up earlier and

00:20:59,950 --> 00:21:04,360
there's a proxy listening at a URL and

00:21:03,250 --> 00:21:05,519
it's set to automatically do a

00:21:04,360 --> 00:21:08,139
round-robin

00:21:05,519 --> 00:21:10,029
distribution of the application so we're

00:21:08,139 --> 00:21:11,799
going to do is we're gonna and then

00:21:10,029 --> 00:21:13,600
we're going to open up again I'm going

00:21:11,799 --> 00:21:14,679
to show you in the application now it

00:21:13,600 --> 00:21:18,509
shows you which is owned in which

00:21:14,679 --> 00:21:18,509
availability zones in Hudson

00:21:32,790 --> 00:21:36,780
so we were having some ongoing issues

00:21:34,560 --> 00:21:40,040
earlier he said he got some of that

00:21:36,780 --> 00:21:40,040
stuff fixed instead he did

00:21:48,970 --> 00:21:54,730
no matter Stone said it's all the

00:21:53,350 --> 00:21:57,880
availability distribution it was

00:21:54,730 --> 00:22:00,480
important so you see here in AWS and

00:21:57,880 --> 00:22:00,480
missus East one

00:22:30,970 --> 00:22:34,600
this is kind of how that's one of the

00:22:32,470 --> 00:22:37,930
big issues with a Multi cluster in

00:22:34,600 --> 00:22:39,730
Federation as ingress points really in a

00:22:37,930 --> 00:22:41,620
great solution to be able to go heavy

00:22:39,730 --> 00:22:43,420
you're coming in from here let's push

00:22:41,620 --> 00:22:45,370
you over here and there's there's

00:22:43,420 --> 00:22:47,320
several proprietor and let balancing

00:22:45,370 --> 00:22:49,660
solutions that offers capabilities

00:22:47,320 --> 00:22:53,290
similar to this but nothing is kind of

00:22:49,660 --> 00:22:54,220
open source cloud agnostic the location

00:22:53,290 --> 00:22:56,760
that's one of the stories were working

00:22:54,220 --> 00:22:56,760
on here

00:23:20,180 --> 00:23:26,150
so this is basically what we're looking

00:23:21,890 --> 00:23:27,290
at with the demo environment and so as

00:23:26,150 --> 00:23:30,460
ever supposed to mention we have the

00:23:27,290 --> 00:23:34,690
u.s. kosher comes out and screen their

00:23:30,460 --> 00:23:37,850
Us East one these two east and west

00:23:34,690 --> 00:23:41,210
sides here and so we're running the same

00:23:37,850 --> 00:23:44,480
set of database pods across each

00:23:41,210 --> 00:23:47,450
they're using Amazon TLB storage

00:23:44,480 --> 00:23:49,850
essentially and we have a pacman pod

00:23:47,450 --> 00:23:54,040
that's designed to work with the

00:23:49,850 --> 00:23:57,560
database for the high score system so

00:23:54,040 --> 00:24:01,130
the demo is cooperating what you'll find

00:23:57,560 --> 00:24:04,130
is that you can rent on any of the

00:24:01,130 --> 00:24:06,380
region's save your high score and then

00:24:04,130 --> 00:24:08,750
high scores are all saved to the same

00:24:06,380 --> 00:24:11,470
database regardless of which region

00:24:08,750 --> 00:24:15,950
you're running in and so that's our

00:24:11,470 --> 00:24:18,890
federated kind of slash data

00:24:15,950 --> 00:24:21,500
replication kind of setup so essentially

00:24:18,890 --> 00:24:26,050
the Mangler pods within these are all in

00:24:21,500 --> 00:24:26,050
a replication set it's a replica set

00:24:26,910 --> 00:24:31,550
which is more specifically don't mind

00:24:28,650 --> 00:24:31,550
him the following slides

00:24:32,010 --> 00:24:38,940
and there's the a check foxy with the

00:24:35,570 --> 00:24:42,059
essentially just a route 53 DNS entry

00:24:38,940 --> 00:24:45,240
that says okay well pac-man missus

00:24:42,059 --> 00:24:48,600
Desson calm is over there or in this

00:24:45,240 --> 00:24:51,000
case we used pac-man - call anybody

00:24:48,600 --> 00:24:52,710
wants to play what's important to notice

00:24:51,000 --> 00:24:55,260
the SA proxies run on the Federative

00:24:52,710 --> 00:24:57,179
control plan so there is a single single

00:24:55,260 --> 00:25:00,320
and rest point for it it's a distributed

00:24:57,179 --> 00:25:00,320
between all three data centers

00:25:03,230 --> 00:25:09,380
okay so this is a number of our demos if

00:25:07,580 --> 00:25:12,049
you want to go and try this out yourself

00:25:09,380 --> 00:25:15,200
we have some to kind of outline the

00:25:12,049 --> 00:25:17,090
difference between the scopes the

00:25:15,200 --> 00:25:20,120
namespace scope versus cluster scope we

00:25:17,090 --> 00:25:22,269
have the the and the pac-man as

00:25:20,120 --> 00:25:22,269
well

00:25:23,730 --> 00:25:29,340
and a bunch of useful links essentially

00:25:27,389 --> 00:25:31,679
there's the upstream project for coop

00:25:29,340 --> 00:25:37,080
fed which is in the kubernetes special

00:25:31,679 --> 00:25:40,110
interest groups Confed github repo once

00:25:37,080 --> 00:25:43,110
again with our federation dev for for

00:25:40,110 --> 00:25:44,940
open shifts specific demos we have a

00:25:43,110 --> 00:25:47,690
couple of presentations that went

00:25:44,940 --> 00:25:52,160
through and we've gone around

00:25:47,690 --> 00:25:55,130
federación Confed 1 from 2018 problem

00:25:52,160 --> 00:25:57,320
refers to a deceleration v2 we have a

00:25:55,130 --> 00:26:01,010
cat a CODIS scenario which lets you

00:25:57,320 --> 00:26:02,900
stand up three kind of test cluster or

00:26:01,010 --> 00:26:07,300
two or three test clusters and then

00:26:02,900 --> 00:26:09,630
federated them real quickly under the

00:26:07,300 --> 00:26:12,980
kind of the cover of cata code of

00:26:09,630 --> 00:26:15,950
learning experience

00:26:12,980 --> 00:26:17,960
and we have a couple of blog entries one

00:26:15,950 --> 00:26:20,179
of them describing the process that

00:26:17,960 --> 00:26:24,620
happened with the coop fed renamed and

00:26:20,179 --> 00:26:26,529
then actually the mixing open-shut

00:26:24,620 --> 00:26:28,909
versions is kind of nice

00:26:26,529 --> 00:26:30,620
we kind of assumed it would work but

00:26:28,909 --> 00:26:32,600
then we actually tested it out so you

00:26:30,620 --> 00:26:35,330
can take a three dot X cluster and a

00:26:32,600 --> 00:26:37,399
four dot X cluster federate both and

00:26:35,330 --> 00:26:40,490
move applications between them it does

00:26:37,399 --> 00:26:41,690
work as mostly as expected which is very

00:26:40,490 --> 00:26:44,799
things like migration if you're

00:26:41,690 --> 00:26:44,799
migrating from 3x to 4x

00:26:45,530 --> 00:26:53,440
all your stateless your team on the

00:26:50,240 --> 00:26:53,440
stateful side of that as well

00:26:55,740 --> 00:27:01,070
that will say thanks and turn it over

00:26:59,429 --> 00:27:03,100
for questions

00:27:01,070 --> 00:27:05,639
which are saying that

00:27:03,100 --> 00:27:05,639
Wow

00:27:07,210 --> 00:27:11,790
so that it's on the same cluster as the

00:27:09,460 --> 00:27:13,480
federated control plane is what we meant

00:27:11,790 --> 00:27:14,800
exactly

00:27:13,480 --> 00:27:16,510
so basically there's got there's a

00:27:14,800 --> 00:27:18,910
federation Gress point it has to exist

00:27:16,510 --> 00:27:20,590
and it has to point somewhere which is

00:27:18,910 --> 00:27:22,420
kind of like the whole ingress dilemma

00:27:20,590 --> 00:27:23,980
right is it you still while you have

00:27:22,420 --> 00:27:26,320
three writing points you still have a

00:27:23,980 --> 00:27:27,340
single ingress so you still have a vet

00:27:26,320 --> 00:27:30,100
vet point of failure

00:27:27,340 --> 00:27:33,220
yes so that goes away then you're some

00:27:30,100 --> 00:27:35,410
cow that's cystic --all right find

00:27:33,220 --> 00:27:36,750
finding a solution that we can just read

00:27:35,410 --> 00:27:41,530
that between and then it going away

00:27:36,750 --> 00:27:43,630
within a venous TTL kind of window yes

00:27:41,530 --> 00:27:45,220
there's a great project where they try

00:27:43,630 --> 00:27:47,590
to do something like this told external

00:27:45,220 --> 00:27:51,010
DNS which is the korean plugin and lets

00:27:47,590 --> 00:27:52,960
you create a service IP or a load

00:27:51,010 --> 00:27:55,060
balancer IP and it'll take that

00:27:52,960 --> 00:27:58,150
automatically created dns record if your

00:27:55,060 --> 00:28:01,600
dns subscribe using route 53 GCP bind

00:27:58,150 --> 00:28:04,560
whatever it gets in a wreck for at all

00:28:01,600 --> 00:28:04,560
welcome thank you

00:28:08,179 --> 00:28:13,320
you mentioned that you're also working

00:28:11,490 --> 00:28:17,250
on figuring out how to federate

00:28:13,320 --> 00:28:18,809
operators what exactly are you trying to

00:28:17,250 --> 00:28:20,460
attempt therefore like is it have a

00:28:18,809 --> 00:28:22,860
single controller running on the cluster

00:28:20,460 --> 00:28:24,900
a and have the same controller watch

00:28:22,860 --> 00:28:27,059
resources on some other customers well

00:28:24,900 --> 00:28:31,830
that's that's the basic idea

00:28:27,059 --> 00:28:34,770
right so the logic dictates that you

00:28:31,830 --> 00:28:37,830
should just be able to do this but we're

00:28:34,770 --> 00:28:40,770
trying to figure out where the where the

00:28:37,830 --> 00:28:42,299
corner cases are so we're still trying

00:28:40,770 --> 00:28:45,360
to figure out you know there's something

00:28:42,299 --> 00:28:47,610
that we should be changing within coop

00:28:45,360 --> 00:28:50,179
fed to make this work or you know does

00:28:47,610 --> 00:28:50,179
this just work

00:28:50,190 --> 00:28:55,200
so the other Cydonia

00:28:52,620 --> 00:29:00,650
anniversary hundreds of valleys set up

00:28:55,200 --> 00:29:04,380
Federation across multiple clusters does

00:29:00,650 --> 00:29:08,430
sets up the Federation also validate avi

00:29:04,380 --> 00:29:11,300
compatibility between different clusters

00:29:08,430 --> 00:29:15,470
between the clusters

00:29:11,300 --> 00:29:17,570
like there's some validation that takes

00:29:15,470 --> 00:29:19,130
place because we're setting up early you

00:29:17,570 --> 00:29:22,450
can't create a service for us unless you

00:29:19,130 --> 00:29:25,130
have a cluster wide Federation

00:29:22,450 --> 00:29:27,290
cholesterol cholesterol bindings without

00:29:25,130 --> 00:29:29,680
having a fully federated but for

00:29:27,290 --> 00:29:33,890
specific resource types I'm not sure

00:29:29,680 --> 00:29:35,540
yeah I'd have to defer to the upstream

00:29:33,890 --> 00:29:39,310
project I imagine that there is

00:29:35,540 --> 00:29:42,140
something but the so far most of the

00:29:39,310 --> 00:29:44,390
validation errors that we had our local

00:29:42,140 --> 00:29:46,160
cluster saying something is wrong with

00:29:44,390 --> 00:29:48,530
the yellow it's still very much a work

00:29:46,160 --> 00:29:49,850
in progress actually before we were in

00:29:48,530 --> 00:29:53,300
here we were just trying to fix the demo

00:29:49,850 --> 00:29:56,720
and our old EML files were pointing to a

00:29:53,300 --> 00:29:59,690
cluster context that didn't exist I'm

00:29:56,720 --> 00:30:01,460
sorry so they reported contact

00:29:59,690 --> 00:30:02,810
especially kind of didn't exist and we

00:30:01,460 --> 00:30:04,220
reran it and everything around found

00:30:02,810 --> 00:30:06,110
that an error and we're like it's not

00:30:04,220 --> 00:30:07,550
working it's strange and there's no

00:30:06,110 --> 00:30:09,620
cluster roll being created all the

00:30:07,550 --> 00:30:11,390
questions going on here so that mean

00:30:09,620 --> 00:30:13,590
like I'm saying it's like it's it's it's

00:30:11,390 --> 00:30:15,690
still coming along right now

00:30:13,590 --> 00:30:18,510
so the last question we have is so you

00:30:15,690 --> 00:30:21,480
showed that you have MongoDB replication

00:30:18,510 --> 00:30:23,760
across the three clusters it's that cube

00:30:21,480 --> 00:30:26,730
that managed replication or is that a

00:30:23,760 --> 00:30:28,230
MongoDB that's a MongoDB replica said

00:30:26,730 --> 00:30:30,660
right I mean this couldn't be done with

00:30:28,230 --> 00:30:33,419
masks you all you need back in storage

00:30:30,660 --> 00:30:34,860
for the replicated across so and it's

00:30:33,419 --> 00:30:36,330
one of those corner cases like he was

00:30:34,860 --> 00:30:38,309
saying right so how many applications

00:30:36,330 --> 00:30:38,970
especially enterprise applications use a

00:30:38,309 --> 00:30:44,330
MongoDB

00:30:38,970 --> 00:30:44,330
overmask you all or whatever thank you

00:30:47,320 --> 00:30:52,970
it looked like the Cupid operator is in

00:30:51,049 --> 00:30:55,610
one of the data centers in one of the

00:30:52,970 --> 00:30:57,770
clusters what happens when the cluster

00:30:55,610 --> 00:31:02,559
which is hosting the Cupid operator goes

00:30:57,770 --> 00:31:02,559
down so essentially the

00:31:03,100 --> 00:31:07,600
the reconcile accepted no longer be

00:31:05,650 --> 00:31:09,430
happening essentially but the other two

00:31:07,600 --> 00:31:11,980
testers will continue to run with

00:31:09,430 --> 00:31:14,320
whatever criminalities objects have

00:31:11,980 --> 00:31:16,030
already been deployed so for instance in

00:31:14,320 --> 00:31:19,810
article scenario if we just knocked out

00:31:16,030 --> 00:31:23,260
East one then East to and West two would

00:31:19,810 --> 00:31:25,070
still have pac-man they still this is

00:31:23,260 --> 00:31:26,700
the important point have their own

00:31:25,070 --> 00:31:29,260
[Music]

00:31:26,700 --> 00:31:31,870
reconciled going on making sure that

00:31:29,260 --> 00:31:33,940
those deployments stay so if they also

00:31:31,870 --> 00:31:35,410
suffered like a node failures it would

00:31:33,940 --> 00:31:37,120
ensure that the number of pods are kept

00:31:35,410 --> 00:31:38,770
up-to-date and everything so that's kind

00:31:37,120 --> 00:31:41,650
of the cool thing about coop fed is that

00:31:38,770 --> 00:31:48,630
it it sits on top of you know the

00:31:41,650 --> 00:31:48,630
kubernetes reconciler second question is

00:31:48,880 --> 00:31:54,220
could be your recommendation for admins

00:31:51,880 --> 00:31:58,409
who are going to use this should they

00:31:54,220 --> 00:32:01,539
use only cube fed for all the objects or

00:31:58,409 --> 00:32:03,669
only for the objects that they want to

00:32:01,539 --> 00:32:06,100
have federated they go through Cupid and

00:32:03,669 --> 00:32:08,860
for the rest they just do OC created

00:32:06,100 --> 00:32:10,410
using the API master for one of the

00:32:08,860 --> 00:32:14,190
clusters

00:32:10,410 --> 00:32:17,730
I think it's probably safe to say that

00:32:14,190 --> 00:32:19,670
you should use cook fed for the ones

00:32:17,730 --> 00:32:22,950
that you want to actually Feder ate

00:32:19,670 --> 00:32:25,590
because at any point in time you could

00:32:22,950 --> 00:32:27,360
also decide okay well I you know I

00:32:25,590 --> 00:32:30,300
thought I didn't want to federate this

00:32:27,360 --> 00:32:33,080
but I do you know that scenario you can

00:32:30,300 --> 00:32:36,270
actually just run the coop type cuddle

00:32:33,080 --> 00:32:38,910
federate command and then basically lift

00:32:36,270 --> 00:32:42,090
that application into Federation and

00:32:38,910 --> 00:32:44,370
then she was as destinations that may be

00:32:42,090 --> 00:32:47,100
a good case for the cluster wide versus

00:32:44,370 --> 00:32:48,510
namespace pet addition right so if you

00:32:47,100 --> 00:32:50,280
have a specific namespace you wanted a

00:32:48,510 --> 00:32:52,640
federated versus better than the whole

00:32:50,280 --> 00:32:52,640
cluster

00:32:57,540 --> 00:33:04,710
great talk by the way thank you so with

00:33:01,770 --> 00:33:06,120
this allow pods to communicate inter

00:33:04,710 --> 00:33:07,380
cluster as if they're in the same

00:33:06,120 --> 00:33:09,870
namespace or is that not what the

00:33:07,380 --> 00:33:12,420
Federation's goal is that's not what

00:33:09,870 --> 00:33:14,490
coupe Fed is doing that's why we kind of

00:33:12,420 --> 00:33:16,800
tack on all these other things before we

00:33:14,490 --> 00:33:21,840
actually say we're done with Federation

00:33:16,800 --> 00:33:23,580
right that's actually from the the

00:33:21,840 --> 00:33:26,160
networking slide where we were talking

00:33:23,580 --> 00:33:28,020
about establishing tunnels between the

00:33:26,160 --> 00:33:29,970
clusters you got to do that you have to

00:33:28,020 --> 00:33:33,770
have the routing working and then you

00:33:29,970 --> 00:33:35,880
have to have the service discovery

00:33:33,770 --> 00:33:37,560
that's where the sub-mariner project he

00:33:35,880 --> 00:33:39,840
was talking about comes into play now

00:33:37,560 --> 00:33:41,370
it'll kind of create those routes as LT

00:33:39,840 --> 00:33:43,130
TLT TV ports

00:33:41,370 --> 00:33:46,410
Vivienne's and everything for you for

00:33:43,130 --> 00:33:48,650
process communication with the SDM cool

00:33:46,410 --> 00:33:48,650
thank you

00:34:02,780 --> 00:34:08,359
if you have Federation at the namespace

00:34:06,350 --> 00:34:10,429
level only

00:34:08,359 --> 00:34:13,700
what kind of permission is required on

00:34:10,429 --> 00:34:16,460
each one of the member clusters is being

00:34:13,700 --> 00:34:20,030
project admin enough for when you

00:34:16,460 --> 00:34:22,270
cluster admin privilege for that okay

00:34:20,030 --> 00:34:25,429
when you're joining the clusters it

00:34:22,270 --> 00:34:28,099
establishes a service account and when

00:34:25,429 --> 00:34:30,590
you are using namespace Scopes

00:34:28,099 --> 00:34:33,379
Federation it only establishes that

00:34:30,590 --> 00:34:35,679
service account with namespace admin

00:34:33,379 --> 00:34:35,679
permissions

00:34:47,399 --> 00:34:52,069
ever again no other questions cool

00:34:49,799 --> 00:34:52,069
what's up

00:34:56,440 --> 00:35:00,000
this might be this might be easiest to

00:34:58,480 --> 00:35:03,460
describe if you go back to your

00:35:00,000 --> 00:35:05,319
infrastructure and slide so I totally

00:35:03,460 --> 00:35:07,299
get the use case and it seems very easy

00:35:05,319 --> 00:35:09,039
to me and make sense to me when I had

00:35:07,299 --> 00:35:10,450
like a unified application that I want

00:35:09,039 --> 00:35:12,130
to run kind of globally like this

00:35:10,450 --> 00:35:14,410
pac-man service get it highly available

00:35:12,130 --> 00:35:16,869
we share state in some sense across

00:35:14,410 --> 00:35:19,569
these with MongoDB as you said across

00:35:16,869 --> 00:35:22,660
these clusters what if I kind of wanted

00:35:19,569 --> 00:35:24,910
these to be private pacman instances so

00:35:22,660 --> 00:35:26,260
I was kind of maybe admitting three

00:35:24,910 --> 00:35:28,329
different pac-man's for my three

00:35:26,260 --> 00:35:28,960
different friends and I want to keep

00:35:28,329 --> 00:35:31,059
things in sync

00:35:28,960 --> 00:35:32,740
not necessarily the data I want each

00:35:31,059 --> 00:35:35,680
friend to have their own copy of the

00:35:32,740 --> 00:35:37,150
data is that a use keys for cube fed I'm

00:35:35,680 --> 00:35:38,650
managing multiple committees clusters

00:35:37,150 --> 00:35:40,900
does that make sense is it easy to do

00:35:38,650 --> 00:35:42,099
yeah I think that's a much simpler use

00:35:40,900 --> 00:35:43,539
case than the one we're trying to get to

00:35:42,099 --> 00:35:44,770
exactly okay so you think it would be

00:35:43,539 --> 00:35:46,510
easy to do with the cube that something

00:35:44,770 --> 00:35:48,720
like that right so so rather than all

00:35:46,510 --> 00:35:51,309
the work that we had to do to make

00:35:48,720 --> 00:35:53,400
do this replica set you just have a

00:35:51,309 --> 00:35:55,470
mongrel pod

00:35:53,400 --> 00:35:57,590
exactly okay thanks yeah I just want to

00:35:55,470 --> 00:35:57,590
make sure

00:36:07,180 --> 00:36:11,620
good go yeah any more questions

00:36:12,600 --> 00:36:16,310

YouTube URL: https://www.youtube.com/watch?v=Dgld03xuOLc


