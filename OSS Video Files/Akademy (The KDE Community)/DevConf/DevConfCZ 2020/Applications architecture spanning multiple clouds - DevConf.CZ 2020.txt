Title: Applications architecture spanning multiple clouds - DevConf.CZ 2020
Publication date: 2020-03-25
Playlist: DevConfCZ 2020
Description: 
	Speakers: Jaroslaw Stakun

Cloud Native development is driving an innovation renaissance, however many organizations are struggling to transition and adapt to public clouds due to organizational, process and technical capabilities, as well as data privacy constraints.
In this session, we'll discuss how Red Hat has helped its customers with these types of challenges, presenting real-world customer examples of applications architectures which are deployed in multiple clouds or private and cloud data centers and serve users traffic transparently across them. We'll focus on solving major challenges like federated CI/CD for applications deployed in multi cloud or hybrid cloud environments, how to manage multi cloud networking for application traffic ingress and data synchronization. We'll also touch on day 2 operations including application management, monitoring and security.

[ https://sched.co/YOsX ]

--
Recordings of talks at DevConf are a community effort. Unfortunately not everything works perfectly every time. If you're interested in helping us improve, let us know.
Captions: 
	00:00:00,540 --> 00:00:08,340
I good afternoon welcome to my

00:00:04,859 --> 00:00:09,990
presentation first of all it's gonna be

00:00:08,340 --> 00:00:12,269
a little more high-level presentation

00:00:09,990 --> 00:00:16,560
and one you have seen before you have

00:00:12,269 --> 00:00:19,620
been in this room in my presentation I

00:00:16,560 --> 00:00:23,570
will share with you the experience I

00:00:19,620 --> 00:00:26,700
have collected together with my team in

00:00:23,570 --> 00:00:29,910
building and implementing the

00:00:26,700 --> 00:00:33,330
applications which were deployed across

00:00:29,910 --> 00:00:36,200
multiple either public clouds or in a

00:00:33,330 --> 00:00:40,070
hybrid cloud model so where we had some

00:00:36,200 --> 00:00:46,740
private clouds and public clouds

00:00:40,070 --> 00:00:48,780
connectivity my name is Yaroslav however

00:00:46,740 --> 00:00:51,540
you can call me Eric as well

00:00:48,780 --> 00:00:54,239
I'm with Red Hat for almost seven years

00:00:51,540 --> 00:00:58,890
now however I must admit with shame that

00:00:54,239 --> 00:01:02,790
this is my first time on Def Con so I'm

00:00:58,890 --> 00:01:04,680
very happy to be here and before we get

00:01:02,790 --> 00:01:08,700
started I would like just to ask you who

00:01:04,680 --> 00:01:16,049
of you is from Red Hat in the room okay

00:01:08,700 --> 00:01:19,320
so we have like how good so so this

00:01:16,049 --> 00:01:21,770
journey with this kind of architecture

00:01:19,320 --> 00:01:24,860
has started for me around five years ago

00:01:21,770 --> 00:01:27,780
and if you can recall this was the time

00:01:24,860 --> 00:01:34,670
when a Red Hat has released openshift

00:01:27,780 --> 00:01:39,330
three actually some customers were

00:01:34,670 --> 00:01:44,450
involved earlier in in in OpenShift so

00:01:39,330 --> 00:01:44,450
they they started together with us

00:01:44,900 --> 00:01:50,310
implementations of this kind of

00:01:46,470 --> 00:01:52,710
architecture just shortly before open

00:01:50,310 --> 00:01:55,350
chivalry was released and in this

00:01:52,710 --> 00:01:57,659
presentation I will try to share with

00:01:55,350 --> 00:01:59,970
you some findings or some interesting

00:01:57,659 --> 00:02:02,430
aspects of building this kind of

00:01:59,970 --> 00:02:04,280
architectures so when we started finding

00:02:02,430 --> 00:02:07,909
five years ago it was like kind of

00:02:04,280 --> 00:02:11,459
totally new space for for everyone

00:02:07,909 --> 00:02:14,109
however now if you

00:02:11,459 --> 00:02:16,540
Lucan for example this this kind of

00:02:14,109 --> 00:02:20,260
research you can see that actually

00:02:16,540 --> 00:02:23,379
nowadays most of the customers who are

00:02:20,260 --> 00:02:26,799
willing to deploy some applications in

00:02:23,379 --> 00:02:29,519
in the public cloud they will use some

00:02:26,799 --> 00:02:33,700
sort of either multi or hybrid cloud

00:02:29,519 --> 00:02:36,250
strategies so it now it's more like the

00:02:33,700 --> 00:02:38,260
mainstream and also the the tooling the

00:02:36,250 --> 00:02:42,099
software I will talk about has matured

00:02:38,260 --> 00:02:44,829
over these five years - to make this

00:02:42,099 --> 00:02:48,250
kind of projects much easier than than

00:02:44,829 --> 00:02:50,500
it was in the past so that there are

00:02:48,250 --> 00:02:52,569
quite a lot of good reasons why why

00:02:50,500 --> 00:02:57,040
customers are using this kind of

00:02:52,569 --> 00:02:58,659
architectures that three major group I

00:02:57,040 --> 00:03:03,579
would say the first one is weighted to

00:02:58,659 --> 00:03:05,040
the cost management so public cloud is

00:03:03,579 --> 00:03:08,319
not is not for free

00:03:05,040 --> 00:03:12,370
in fact it's it could be quite expensive

00:03:08,319 --> 00:03:14,620
in some scenario so so this this kind of

00:03:12,370 --> 00:03:18,040
architectures might be a good way to to

00:03:14,620 --> 00:03:20,199
contain that kind of cost there are some

00:03:18,040 --> 00:03:25,000
you know some some technical reasons

00:03:20,199 --> 00:03:27,310
like increasing availability reduced

00:03:25,000 --> 00:03:31,829
latency and so on and also there might

00:03:27,310 --> 00:03:34,870
be some compliance or regulatory

00:03:31,829 --> 00:03:36,989
requirements especially related to data

00:03:34,870 --> 00:03:42,400
management and data transfer across

00:03:36,989 --> 00:03:46,930
different different years so these are

00:03:42,400 --> 00:03:51,220
the most typical topologies that I was

00:03:46,930 --> 00:03:55,060
working with within this five years

00:03:51,220 --> 00:03:57,989
journey so the most project they started

00:03:55,060 --> 00:03:59,889
in a way that people who are

00:03:57,989 --> 00:04:03,400
experimenting with public cloud they

00:03:59,889 --> 00:04:06,040
typically started to put some non

00:04:03,400 --> 00:04:09,370
production workloads into into public

00:04:06,040 --> 00:04:12,980
cloud and and later on they they moved

00:04:09,370 --> 00:04:15,050
also with production but typical the the

00:04:12,980 --> 00:04:18,100
starting point for many customers was to

00:04:15,050 --> 00:04:20,600
run some non production systems in

00:04:18,100 --> 00:04:24,700
systems and environments in in public

00:04:20,600 --> 00:04:30,880
cloud and running production in-house

00:04:24,700 --> 00:04:34,250
the second the second use case was were

00:04:30,880 --> 00:04:37,400
we wanted to build a solution or system

00:04:34,250 --> 00:04:40,550
that was distributed across multiple geo

00:04:37,400 --> 00:04:42,260
so if you if you were if you are working

00:04:40,550 --> 00:04:45,070
for some global companies or you were

00:04:42,260 --> 00:04:47,419
involved in some global projects

00:04:45,070 --> 00:04:49,700
sometimes you know they have some

00:04:47,419 --> 00:04:51,979
applications that they want to be

00:04:49,700 --> 00:04:55,729
available across the globe so they want

00:04:51,979 --> 00:04:58,250
to serve customers from Europe Asia a US

00:04:55,729 --> 00:04:59,870
and typically this means that they might

00:04:58,250 --> 00:05:01,880
want to deploy the instances of the

00:04:59,870 --> 00:05:06,010
applications across the GOC in different

00:05:01,880 --> 00:05:09,650
clubs the other use case is about

00:05:06,010 --> 00:05:13,970
scaling so there are some types of

00:05:09,650 --> 00:05:15,860
applications which typically requires

00:05:13,970 --> 00:05:19,930
some limited resources but there are

00:05:15,860 --> 00:05:24,039
some points of time some peaks or some

00:05:19,930 --> 00:05:27,890
other events where they need

00:05:24,039 --> 00:05:32,120
dramatically to scale up and this is

00:05:27,890 --> 00:05:35,120
also a kind of good case for for

00:05:32,120 --> 00:05:38,150
leveraging public cloud where we have

00:05:35,120 --> 00:05:42,320
this additional resources available on

00:05:38,150 --> 00:05:44,780
demand and the other the other scenario

00:05:42,320 --> 00:05:48,380
is when we are layering our application

00:05:44,780 --> 00:05:51,080
so this is typically done in the way

00:05:48,380 --> 00:05:53,000
that we have some data layer that sits

00:05:51,080 --> 00:05:56,539
in our private cloud but then we have

00:05:53,000 --> 00:06:00,050
some some API source um front ends that

00:05:56,539 --> 00:06:02,510
could be deployed in public clouds and

00:06:00,050 --> 00:06:05,620
they communicate with with the backend

00:06:02,510 --> 00:06:10,720
that are running in in the private cloud

00:06:05,620 --> 00:06:15,110
so this is more or less the the kind of

00:06:10,720 --> 00:06:18,230
set up for formal presentation and this

00:06:15,110 --> 00:06:24,139
is what I will be talking about

00:06:18,230 --> 00:06:27,770
in the in the in my presentation so that

00:06:24,139 --> 00:06:31,880
essentially two parts one is more for

00:06:27,770 --> 00:06:35,930
developers so how to how to architect

00:06:31,880 --> 00:06:38,470
the application how to manage CI CD and

00:06:35,930 --> 00:06:41,660
application deployments across multiple

00:06:38,470 --> 00:06:43,880
or hybrid clouds and the other one is

00:06:41,660 --> 00:06:46,190
more about the operations of how to

00:06:43,880 --> 00:06:49,730
manage things like networking data

00:06:46,190 --> 00:06:53,780
replication management more entering a

00:06:49,730 --> 00:06:58,400
security one more question for you who

00:06:53,780 --> 00:07:01,880
of you is more like developers and who

00:06:58,400 --> 00:07:07,160
is the operations okay so we have like

00:07:01,880 --> 00:07:12,770
50/50 so good mix I guess they also some

00:07:07,160 --> 00:07:14,479
DevOps ooh all right so let's get start

00:07:12,770 --> 00:07:19,040
with the application so as I mentioned

00:07:14,479 --> 00:07:21,800
the beginning this journey started at

00:07:19,040 --> 00:07:22,610
the time when when Red Hat was releasing

00:07:21,800 --> 00:07:25,610
OpenShift

00:07:22,610 --> 00:07:28,370
version 3 based on based on docker at

00:07:25,610 --> 00:07:31,760
the time so the containers are really

00:07:28,370 --> 00:07:35,810
the key component of those application

00:07:31,760 --> 00:07:40,490
architectures and in this kind of

00:07:35,810 --> 00:07:45,800
projects there was always a requirement

00:07:40,490 --> 00:07:50,510
to containerize the application in order

00:07:45,800 --> 00:07:53,360
to achieve maximum portability which is

00:07:50,510 --> 00:07:55,789
needed for this kind of multi or hybrid

00:07:53,360 --> 00:07:58,970
cloud deployments and of course we had

00:07:55,789 --> 00:08:00,200
like two types of situations so either

00:07:58,970 --> 00:08:03,400
we wanted to migrate existing

00:08:00,200 --> 00:08:08,330
application or we wanted to develop

00:08:03,400 --> 00:08:10,430
completely new one so in regard to

00:08:08,330 --> 00:08:13,490
existing application there are basically

00:08:10,430 --> 00:08:16,400
three strategies that that works were

00:08:13,490 --> 00:08:19,789
well in a in a real life so the first

00:08:16,400 --> 00:08:21,710
one at first wrote this code we hosting

00:08:19,789 --> 00:08:24,770
and this is where we simply try to lift

00:08:21,710 --> 00:08:27,560
and shift our application so in essence

00:08:24,770 --> 00:08:31,370
what that means we take our application

00:08:27,560 --> 00:08:33,990
assist and we containerize

00:08:31,370 --> 00:08:35,580
the layers or the application itself

00:08:33,990 --> 00:08:37,800
depending what is the architecture

00:08:35,580 --> 00:08:41,700
whether it is mono lit or it has some

00:08:37,800 --> 00:08:46,110
more layers and this this work well this

00:08:41,700 --> 00:08:50,640
works well for for some some types of

00:08:46,110 --> 00:08:52,680
the application so especially for

00:08:50,640 --> 00:08:58,830
technologies that that'll kind of modern

00:08:52,680 --> 00:09:03,780
and not really legacy stuff for other

00:08:58,830 --> 00:09:07,290
applications other possible strategy to

00:09:03,780 --> 00:09:12,200
to migrate was the strategical tree

00:09:07,290 --> 00:09:17,580
platform and this is where we basically

00:09:12,200 --> 00:09:23,450
keep existing application as this but we

00:09:17,580 --> 00:09:26,850
try to build with the containers any new

00:09:23,450 --> 00:09:29,220
capabilities that are introduced to the

00:09:26,850 --> 00:09:31,020
application over time and those new

00:09:29,220 --> 00:09:35,700
capabilities are built using the

00:09:31,020 --> 00:09:38,880
containers and and they are designed to

00:09:35,700 --> 00:09:40,560
run in in containerized environments and

00:09:38,880 --> 00:09:42,780
then of course we need to build some

00:09:40,560 --> 00:09:45,870
kind of integration layer as you can see

00:09:42,780 --> 00:09:49,530
on the slide between our existing system

00:09:45,870 --> 00:09:53,880
and and the new new layers new

00:09:49,530 --> 00:09:57,240
components that we introduced this is of

00:09:53,880 --> 00:10:03,750
course more complex approach then than

00:09:57,240 --> 00:10:06,240
the previous one but still works well in

00:10:03,750 --> 00:10:08,700
many scenarios and then we have the

00:10:06,240 --> 00:10:10,760
third approach which is refactoring

00:10:08,700 --> 00:10:14,060
these are typically the most complex

00:10:10,760 --> 00:10:16,680
projects where we where we are really

00:10:14,060 --> 00:10:20,520
taking the effort to rewrite our

00:10:16,680 --> 00:10:22,860
application into into the new

00:10:20,520 --> 00:10:25,050
containerized architecture so this might

00:10:22,860 --> 00:10:27,000
also mean that we migrated from

00:10:25,050 --> 00:10:31,220
monolithic architecture to micro

00:10:27,000 --> 00:10:33,420
services or we do any other needed

00:10:31,220 --> 00:10:36,410
architecture changes so these are

00:10:33,420 --> 00:10:41,570
typically big and complex projects that

00:10:36,410 --> 00:10:43,890
that take a lot of time and are costly

00:10:41,570 --> 00:10:44,810
especially compared to their previous

00:10:43,890 --> 00:10:50,400
two

00:10:44,810 --> 00:10:56,510
approaches when we talk about developing

00:10:50,400 --> 00:11:00,150
new applications we we standardize on

00:10:56,510 --> 00:11:03,420
cloud native uploads so what it really

00:11:00,150 --> 00:11:05,240
means that we of course standardize on

00:11:03,420 --> 00:11:08,220
the containers as a runtime

00:11:05,240 --> 00:11:10,350
micro-services as the architecture the

00:11:08,220 --> 00:11:13,710
API as a standard of communication

00:11:10,350 --> 00:11:20,550
between microservices and devops as a

00:11:13,710 --> 00:11:27,660
processes to to manage the CI cd44

00:11:20,550 --> 00:11:31,620
applications and when we had when we had

00:11:27,660 --> 00:11:35,430
a containerized application we need a

00:11:31,620 --> 00:11:39,180
platform to to manage and deploy the

00:11:35,430 --> 00:11:42,870
application in our multi or hybrid cloud

00:11:39,180 --> 00:11:48,750
environments and of course the the

00:11:42,870 --> 00:11:50,250
platform is openshift so in openshift by

00:11:48,750 --> 00:11:55,080
the way whoever is familiar with Appa

00:11:50,250 --> 00:11:56,400
shift okay so most of you so not

00:11:55,080 --> 00:12:00,180
surprised

00:11:56,400 --> 00:12:07,440
so what opposite give gives us it gives

00:12:00,180 --> 00:12:11,130
us flexibility of the platforms and it

00:12:07,440 --> 00:12:16,370
gives us basically the consistent user

00:12:11,130 --> 00:12:20,190
experience across different different

00:12:16,370 --> 00:12:22,470
clubs so if we combine open ship with

00:12:20,190 --> 00:12:24,900
with portability of containers we have

00:12:22,470 --> 00:12:26,670
pretty good foundation to to be

00:12:24,900 --> 00:12:31,050
successful in in deploying our

00:12:26,670 --> 00:12:38,240
applications into into multiple in in

00:12:31,050 --> 00:12:42,330
multi or hybrid cloud environments but

00:12:38,240 --> 00:12:46,050
containerization however it works in

00:12:42,330 --> 00:12:48,870
many scenarios it doesn't work in in in

00:12:46,050 --> 00:12:50,490
all scenarios they are still and there

00:12:48,870 --> 00:12:53,430
will be still some workloads that are

00:12:50,490 --> 00:12:55,090
running in virtual machines and we find

00:12:53,430 --> 00:13:00,830
it really

00:12:55,090 --> 00:13:05,390
complex or too expensive to to take the

00:13:00,830 --> 00:13:10,460
effort to migrate those workloads to two

00:13:05,390 --> 00:13:13,790
containers however on the other on the

00:13:10,460 --> 00:13:15,950
other hand we want to we want to

00:13:13,790 --> 00:13:19,250
leverage the benefits of having open

00:13:15,950 --> 00:13:23,420
shipped as a consistent platform for for

00:13:19,250 --> 00:13:27,020
running applications and there is an

00:13:23,420 --> 00:13:31,610
effort in the community to to build a

00:13:27,020 --> 00:13:33,830
platform that will that will let you run

00:13:31,610 --> 00:13:37,850
virtual machines natively in the

00:13:33,830 --> 00:13:41,480
openshift at the moment it is still a

00:13:37,850 --> 00:13:44,990
community effort but if you are

00:13:41,480 --> 00:13:47,840
interested in this kind of use cases I

00:13:44,990 --> 00:13:50,960
encourage you especially to have a look

00:13:47,840 --> 00:13:54,920
on queue view projects also on metal

00:13:50,960 --> 00:13:59,660
cube which are the main projects which

00:13:54,920 --> 00:14:02,720
will provide us the kappa which will

00:13:59,660 --> 00:14:07,730
provide the capabilities for kubernetes

00:14:02,720 --> 00:14:12,170
and for OpenShift to run natively KVM

00:14:07,730 --> 00:14:16,880
based virtual machines so there is the

00:14:12,170 --> 00:14:18,790
hope and that also container natively

00:14:16,880 --> 00:14:21,790
container sorry

00:14:18,790 --> 00:14:27,380
natively virtual machine based workers

00:14:21,790 --> 00:14:32,030
will be able to to leverage that the

00:14:27,380 --> 00:14:35,890
benefits of open shoe ok so so we have

00:14:32,030 --> 00:14:40,490
we have the containers we have the

00:14:35,890 --> 00:14:44,270
platform to run our application now the

00:14:40,490 --> 00:14:50,150
first thing we need to implement is EC

00:14:44,270 --> 00:14:52,880
ICD so our first attempt to to see ICD 4

00:14:50,150 --> 00:14:57,770
in multi or hybrid cloud environment was

00:14:52,880 --> 00:15:00,640
really to leverage existing tools and

00:14:57,770 --> 00:15:05,330
knowledge so in our case this was

00:15:00,640 --> 00:15:07,540
Jenkins and the only only change we made

00:15:05,330 --> 00:15:13,460
initially in our

00:15:07,540 --> 00:15:17,270
pipelines was to introduce the multi

00:15:13,460 --> 00:15:20,900
cluster deployment of images that were

00:15:17,270 --> 00:15:23,660
that were tested created and tested

00:15:20,900 --> 00:15:29,840
during during a pipeline pipeline

00:15:23,660 --> 00:15:34,010
execution this this worked for us pretty

00:15:29,840 --> 00:15:39,170
well but at some point we had number of

00:15:34,010 --> 00:15:43,900
situations were the deployments to to

00:15:39,170 --> 00:15:49,970
some of clusters that that we that were

00:15:43,900 --> 00:15:51,890
part of the platform has failed and

00:15:49,970 --> 00:15:54,110
because this step was part of our

00:15:51,890 --> 00:15:57,320
pipeline this this this man this mean

00:15:54,110 --> 00:16:02,270
really that dub that our pipeline has

00:15:57,320 --> 00:16:07,570
failed and we started building some you

00:16:02,270 --> 00:16:10,340
know some some solutions in Jenkins to

00:16:07,570 --> 00:16:11,810
to handle this kind of situation but but

00:16:10,340 --> 00:16:14,510
really at some point we realize that

00:16:11,810 --> 00:16:17,090
this is pretty much the road to nowhere

00:16:14,510 --> 00:16:19,820
because there will be always some new

00:16:17,090 --> 00:16:23,320
issues with the networking that we

00:16:19,820 --> 00:16:27,980
didn't cover and you know jenkees is not

00:16:23,320 --> 00:16:35,150
the platform to to replicate container

00:16:27,980 --> 00:16:40,840
images across different different clouds

00:16:35,150 --> 00:16:44,090
or environments so this is where we

00:16:40,840 --> 00:16:47,930
actually may be a bit of coincidentally

00:16:44,090 --> 00:16:50,270
at the same time pretty much the same

00:16:47,930 --> 00:16:54,790
time rest had made the acquisition of

00:16:50,270 --> 00:17:00,400
Korres and with Korres we acquired also

00:16:54,790 --> 00:17:03,230
container registry called Quay and Quay

00:17:00,400 --> 00:17:06,260
provided for us

00:17:03,230 --> 00:17:08,930
one functionality which was really the

00:17:06,260 --> 00:17:12,500
one we needed which is the geo

00:17:08,930 --> 00:17:14,839
replication so with quad your

00:17:12,500 --> 00:17:19,240
application as you can see here on the

00:17:14,839 --> 00:17:20,900
on the picture you can basically deploy

00:17:19,240 --> 00:17:27,589
image

00:17:20,900 --> 00:17:31,250
to an instance in your distributed quay

00:17:27,589 --> 00:17:33,440
environment and then Kauai will

00:17:31,250 --> 00:17:39,380
distribute the images across all

00:17:33,440 --> 00:17:45,910
registered or connected instances so

00:17:39,380 --> 00:17:50,630
this was the way how we moved forward so

00:17:45,910 --> 00:17:56,510
we started to leverage Quay which was

00:17:50,630 --> 00:18:01,970
deployed across multiple clouds in

00:17:56,510 --> 00:18:05,960
different Gio's and Quay was we give a

00:18:01,970 --> 00:18:11,179
Quay responsibility to to replicate the

00:18:05,960 --> 00:18:13,300
images across across the across data

00:18:11,179 --> 00:18:13,300
centers

00:18:13,630 --> 00:18:22,300
another challenge here was to was the

00:18:19,790 --> 00:18:28,370
management of the application

00:18:22,300 --> 00:18:33,890
configurations across different data

00:18:28,370 --> 00:18:38,870
centers so so we had open shift cluster

00:18:33,890 --> 00:18:41,360
in each data center deployed and we and

00:18:38,870 --> 00:18:44,450
we needed to replicate application

00:18:41,360 --> 00:18:48,470
configurations across those clusters in

00:18:44,450 --> 00:18:50,720
a consistent manner and now it's

00:18:48,470 --> 00:18:53,660
probably pretty obvious that that for

00:18:50,720 --> 00:18:58,280
this kind of challenge you will leverage

00:18:53,660 --> 00:19:00,740
github but when we when we when we when

00:18:58,280 --> 00:19:02,420
we have been facing that problem three

00:19:00,740 --> 00:19:03,820
four years ago it was not not that

00:19:02,420 --> 00:19:08,540
obvious

00:19:03,820 --> 00:19:12,290
so probably now you know what what what

00:19:08,540 --> 00:19:16,610
was the idea behind get up so we keep

00:19:12,290 --> 00:19:19,070
our application configurations which are

00:19:16,610 --> 00:19:22,040
young base in GT repo and then we have

00:19:19,070 --> 00:19:25,380
an engine that can replicate those

00:19:22,040 --> 00:19:30,029
configuration across

00:19:25,380 --> 00:19:34,929
multiple registered gubernatorial

00:19:30,029 --> 00:19:38,049
clusters and at the time we made a

00:19:34,929 --> 00:19:41,830
decision that we will leverage we will

00:19:38,049 --> 00:19:45,809
leverage our go as the engine an Argo

00:19:41,830 --> 00:19:51,159
actually gave us a very very nice

00:19:45,809 --> 00:19:54,820
functionalities so first of all it would

00:19:51,159 --> 00:19:57,820
you can register multiple clusters that

00:19:54,820 --> 00:20:04,570
can be deployed anywhere across

00:19:57,820 --> 00:20:07,059
different data centers clouds Geo's it

00:20:04,570 --> 00:20:10,600
of course synchronized the application

00:20:07,059 --> 00:20:13,659
configuration with the G 3po what was

00:20:10,600 --> 00:20:18,789
also very important it gives us gives us

00:20:13,659 --> 00:20:20,860
possibility to make some overlay

00:20:18,789 --> 00:20:23,649
configurations which could be specific

00:20:20,860 --> 00:20:28,059
only to some data center so if you think

00:20:23,649 --> 00:20:31,029
about kubernetes or openshift

00:20:28,059 --> 00:20:33,460
application there are a number of

00:20:31,029 --> 00:20:36,700
configurations that are specific for

00:20:33,460 --> 00:20:39,580
your for your data center so things like

00:20:36,700 --> 00:20:43,830
some credentials so typical config map

00:20:39,580 --> 00:20:50,760
secrets ingress configurations there

00:20:43,830 --> 00:20:55,179
they are specific to - - every - every

00:20:50,760 --> 00:20:58,240
cluster or application instance so we we

00:20:55,179 --> 00:21:01,380
needed and and we got it with our go we

00:20:58,240 --> 00:21:03,520
needed the ability to make some Overlake

00:21:01,380 --> 00:21:08,549
configuration specific for for the

00:21:03,520 --> 00:21:12,640
clusters then of course our go can

00:21:08,549 --> 00:21:14,950
synchronize for us the configuration -

00:21:12,640 --> 00:21:16,899
to each of the cluster and what is also

00:21:14,950 --> 00:21:22,080
very very important and very useful

00:21:16,899 --> 00:21:26,110
about Argo is the this last thing so

00:21:22,080 --> 00:21:28,419
Argo will also monitor the configuration

00:21:26,110 --> 00:21:31,330
of your application on each of the

00:21:28,419 --> 00:21:33,010
clusters and will detect if someone

00:21:31,330 --> 00:21:36,580
locally makes some changes to the

00:21:33,010 --> 00:21:39,100
configuration and will revert that

00:21:36,580 --> 00:21:42,549
change - to the configuration

00:21:39,100 --> 00:21:46,240
that is defined in G triple so this well

00:21:42,549 --> 00:21:49,000
this also makes you know it reversed a

00:21:46,240 --> 00:21:52,090
little bit the way how we manage the

00:21:49,000 --> 00:21:56,380
configuration because we don't manage

00:21:52,090 --> 00:22:00,100
the configuration via command line or

00:21:56,380 --> 00:22:04,450
web console of operation or kubernetes

00:22:00,100 --> 00:22:14,890
but we we leverage as a single source of

00:22:04,450 --> 00:22:20,230
true the G to G triple over the time so

00:22:14,890 --> 00:22:24,190
get-ups might become even even easier

00:22:20,230 --> 00:22:27,549
because we have our community have

00:22:24,190 --> 00:22:31,049
introduced concept of operators so with

00:22:27,549 --> 00:22:34,679
operators you can basically package

00:22:31,049 --> 00:22:42,490
together the application configuration

00:22:34,679 --> 00:22:45,940
and this makes nowadays some application

00:22:42,490 --> 00:22:51,460
configuration easier so there is you can

00:22:45,940 --> 00:22:53,530
you can transfer some or you can package

00:22:51,460 --> 00:22:58,840
some application configurations into

00:22:53,530 --> 00:23:04,900
operators so so that your your app

00:22:58,840 --> 00:23:07,659
configuration becomes becomes easier and

00:23:04,900 --> 00:23:11,320
there is a there is a community effort

00:23:07,659 --> 00:23:17,200
to to build kind of standardized

00:23:11,320 --> 00:23:22,000
solution for for for this use case so

00:23:17,200 --> 00:23:24,760
for Federation for federated deployments

00:23:22,000 --> 00:23:31,440
and of applications but this is still

00:23:24,760 --> 00:23:36,870
kind of working progress so early days

00:23:31,440 --> 00:23:41,650
and I don't see like this is moving

00:23:36,870 --> 00:23:43,600
forward fast so I think still the the

00:23:41,650 --> 00:23:45,880
approach with the get-ups is the best

00:23:43,600 --> 00:23:47,480
way how we can manage application

00:23:45,880 --> 00:23:54,010
configuration in

00:23:47,480 --> 00:24:02,360
Multi multi or hybrid cloud environments

00:23:54,010 --> 00:24:04,120
okay so now the the second part might be

00:24:02,360 --> 00:24:08,570
a bit more related to operational

00:24:04,120 --> 00:24:12,680
operations an infrastructure so the

00:24:08,570 --> 00:24:16,120
networking so so so from the networking

00:24:12,680 --> 00:24:20,450
point of view hybrid and multi-cloud

00:24:16,120 --> 00:24:22,370
introduces number of challenges the

00:24:20,450 --> 00:24:28,250
first challenge is how you manage the

00:24:22,370 --> 00:24:30,230
traffic ingress so you have instead of

00:24:28,250 --> 00:24:31,940
one cluster with some ingress load

00:24:30,230 --> 00:24:35,420
balancer in front you you have like

00:24:31,940 --> 00:24:39,080
multiple clusters each of them will have

00:24:35,420 --> 00:24:40,700
their own local load balancer and what

00:24:39,080 --> 00:24:44,090
you will need here you will need some

00:24:40,700 --> 00:24:49,060
global traffic manager which will be

00:24:44,090 --> 00:24:55,370
able to distribute the traffic between

00:24:49,060 --> 00:24:58,820
between this multiple clusters so GTM

00:24:55,370 --> 00:25:02,720
typically is a DNS server so it doesn't

00:24:58,820 --> 00:25:06,770
really so the traffic don't do not

00:25:02,720 --> 00:25:09,790
really go by a voyage atm it is a DNS

00:25:06,770 --> 00:25:13,250
also with some advanced capabilities

00:25:09,790 --> 00:25:19,240
related to geo localization for example

00:25:13,250 --> 00:25:23,510
so it might as a DNS it might give you

00:25:19,240 --> 00:25:26,480
different IP address IP address of one

00:25:23,510 --> 00:25:29,680
of these load balancers depending on

00:25:26,480 --> 00:25:33,020
from where you are sending your request

00:25:29,680 --> 00:25:35,320
and this is quite quite important in

00:25:33,020 --> 00:25:40,130
some scenarios especially if you want to

00:25:35,320 --> 00:25:47,300
distribute the traffic according to a

00:25:40,130 --> 00:25:53,540
Gio from of the of the requester the

00:25:47,300 --> 00:25:55,990
other the other challenge is the service

00:25:53,540 --> 00:25:58,870
mash in

00:25:55,990 --> 00:26:02,980
multi-and a hybrid cloud so who of you

00:25:58,870 --> 00:26:05,290
is familiar with service mesh okay some

00:26:02,980 --> 00:26:08,770
of you are so service mesh is very

00:26:05,290 --> 00:26:12,809
useful in a situation when you have when

00:26:08,770 --> 00:26:16,300
you have the micro services architecture

00:26:12,809 --> 00:26:19,570
with service mesh you can manage all the

00:26:16,300 --> 00:26:23,350
aspect of the network communication

00:26:19,570 --> 00:26:29,970
between between the the micro services

00:26:23,350 --> 00:26:34,179
so think of security think of some

00:26:29,970 --> 00:26:38,590
policy based routing also it gives you

00:26:34,179 --> 00:26:45,850
some very very nice observer monitoring

00:26:38,590 --> 00:26:49,330
or observability but on the other hand

00:26:45,850 --> 00:26:55,390
it's it is quite heavy and complex

00:26:49,330 --> 00:27:01,660
component of of the kubernetes rubbish

00:26:55,390 --> 00:27:03,309
architecture and service match has gives

00:27:01,660 --> 00:27:07,860
you at least three options how you can

00:27:03,309 --> 00:27:12,130
how you can deploy it and manage it in

00:27:07,860 --> 00:27:18,150
multi cluster environment so the first

00:27:12,130 --> 00:27:21,040
two options you can use if you have

00:27:18,150 --> 00:27:23,650
completely separate networks between

00:27:21,040 --> 00:27:27,400
your data centers so for example if you

00:27:23,650 --> 00:27:30,010
if you have if you deploy your

00:27:27,400 --> 00:27:33,040
application in different clouds in

00:27:30,010 --> 00:27:40,780
multiple clouds this this might be a

00:27:33,040 --> 00:27:43,059
case and the first app show of the first

00:27:40,780 --> 00:27:46,600
approach requires that the photo option

00:27:43,059 --> 00:27:49,120
requires that you have that you have a

00:27:46,600 --> 00:27:53,980
single network between the between

00:27:49,120 --> 00:27:57,870
between your clusters so so there are

00:27:53,980 --> 00:28:03,150
some some tweaks

00:27:57,870 --> 00:28:05,730
in in each of the approach so it's it's

00:28:03,150 --> 00:28:09,570
not easy really to analyze and decide

00:28:05,730 --> 00:28:13,350
with which option to use in my

00:28:09,570 --> 00:28:18,210
experience we typically use the the the

00:28:13,350 --> 00:28:22,500
second the second option were we wanted

00:28:18,210 --> 00:28:26,220
to avoid to have multiple control planes

00:28:22,500 --> 00:28:29,040
in the mesh so we wanted to keep service

00:28:26,220 --> 00:28:33,990
watch configuration in single location

00:28:29,040 --> 00:28:37,590
and we wanted to to be to have the

00:28:33,990 --> 00:28:42,810
service managed in the central way and

00:28:37,590 --> 00:28:47,250
this is how it looks like in a this

00:28:42,810 --> 00:28:48,900
image shows you this scenario so in

00:28:47,250 --> 00:28:51,900
regards to networking there there is

00:28:48,900 --> 00:28:56,000
some also some some community effort to

00:28:51,900 --> 00:29:00,110
make it easier to connect multiple

00:28:56,000 --> 00:29:05,430
multiple clusters so the one project

00:29:00,110 --> 00:29:09,870
where we also as a Red Hat contribute is

00:29:05,430 --> 00:29:14,670
submariner with these projects they try

00:29:09,870 --> 00:29:16,860
to build kind of VPN that runs on on top

00:29:14,670 --> 00:29:21,450
of open she sort of on top of kubernetes

00:29:16,860 --> 00:29:26,100
so that you can easily connect different

00:29:21,450 --> 00:29:29,280
networks and you don't need to go deeply

00:29:26,100 --> 00:29:32,880
into the infrastructure layer to open

00:29:29,280 --> 00:29:35,040
some tunnels and so on there are other

00:29:32,880 --> 00:29:39,260
projects lighthouse and Coast Guard

00:29:35,040 --> 00:29:46,100
which are also aiming at building the

00:29:39,260 --> 00:29:49,860
networking for multi cluster scenarios

00:29:46,100 --> 00:29:56,910
easier but this is still still community

00:29:49,860 --> 00:30:01,350
effort so it's not yet available next

00:29:56,910 --> 00:30:04,590
Fink data data replication so data

00:30:01,350 --> 00:30:06,940
replication basically

00:30:04,590 --> 00:30:11,650
[Music]

00:30:06,940 --> 00:30:16,490
has to complexity so the first one is

00:30:11,650 --> 00:30:20,510
the technical one so how you can how you

00:30:16,490 --> 00:30:23,810
can send the data in efficient way

00:30:20,510 --> 00:30:28,160
between you know between different

00:30:23,810 --> 00:30:30,980
continents even or between different

00:30:28,160 --> 00:30:36,160
networks the other one is about the cost

00:30:30,980 --> 00:30:40,970
so the cost of of data replication

00:30:36,160 --> 00:30:44,210
between public clouds can be very very

00:30:40,970 --> 00:30:47,210
substantial so you cannot underestimate

00:30:44,210 --> 00:30:53,650
that factor and you should always think

00:30:47,210 --> 00:30:58,390
and analyze whether this won't make your

00:30:53,650 --> 00:31:02,390
architecture or your use case an

00:30:58,390 --> 00:31:05,650
unacceptable so in regards to data

00:31:02,390 --> 00:31:09,950
replication there are basically three

00:31:05,650 --> 00:31:12,050
three possible scenarios of course if if

00:31:09,950 --> 00:31:16,640
you don't have to the best way is to do

00:31:12,050 --> 00:31:18,200
not to do not replicate the data but if

00:31:16,640 --> 00:31:20,870
you have to you can theoretically

00:31:18,200 --> 00:31:23,570
consider three options so either you

00:31:20,870 --> 00:31:28,270
will use some infrastructure layer so

00:31:23,570 --> 00:31:31,100
storage layer replication solutions or

00:31:28,270 --> 00:31:34,960
you have two options on the applications

00:31:31,100 --> 00:31:38,420
layer so either you replicate the data

00:31:34,960 --> 00:31:42,200
using some application level technology

00:31:38,420 --> 00:31:44,420
or you leverage the data partitioning

00:31:42,200 --> 00:31:45,980
and and you don't really replicate but

00:31:44,420 --> 00:31:52,000
you just partition your data across

00:31:45,980 --> 00:31:55,280
different clouds the infrastructure base

00:31:52,000 --> 00:31:59,000
synchronization of course especially in

00:31:55,280 --> 00:32:01,460
public cloud scenarios might be

00:31:59,000 --> 00:32:04,030
impossible especially if you are

00:32:01,460 --> 00:32:08,360
thinking about some hardware level

00:32:04,030 --> 00:32:09,170
applications however there is a there is

00:32:08,360 --> 00:32:10,510
a

00:32:09,170 --> 00:32:13,210
[Music]

00:32:10,510 --> 00:32:16,880
development and progress in in building

00:32:13,210 --> 00:32:23,000
software-defined solutions to replicate

00:32:16,880 --> 00:32:27,799
the data the one which which is now a

00:32:23,000 --> 00:32:31,010
part of red card offering is nuba cloud

00:32:27,799 --> 00:32:35,529
object gateway so these solutions let

00:32:31,010 --> 00:32:39,850
you replicate the the object storage

00:32:35,529 --> 00:32:45,590
between different different cloud or

00:32:39,850 --> 00:32:48,940
private and public cloud the kind of

00:32:45,590 --> 00:32:53,690
downside of the solution is that it it

00:32:48,940 --> 00:32:56,720
exposes the data using the s3 API so

00:32:53,690 --> 00:32:59,000
this is not feasible for any kind of

00:32:56,720 --> 00:33:00,889
applications you need to your

00:32:59,000 --> 00:33:05,590
application to be to be able to leverage

00:33:00,889 --> 00:33:07,880
a3 API but once you have this this

00:33:05,590 --> 00:33:13,159
immediate requirement

00:33:07,880 --> 00:33:16,510
Noba can replicate for you the the

00:33:13,159 --> 00:33:20,690
object storage across different

00:33:16,510 --> 00:33:27,769
different clouds in a transparent away

00:33:20,690 --> 00:33:31,279
from the application point of view so

00:33:27,769 --> 00:33:35,179
but this is this is quite new so even

00:33:31,279 --> 00:33:38,169
even in Red Hat we just introduced this

00:33:35,179 --> 00:33:41,179
as part of our new container storage

00:33:38,169 --> 00:33:44,630
version 4 which was released I know

00:33:41,179 --> 00:33:48,620
week or two weeks ago so what we

00:33:44,630 --> 00:33:50,450
typically used to do in in the past in

00:33:48,620 --> 00:33:54,340
our project we used to leverage some

00:33:50,450 --> 00:33:59,470
application based replication solutions

00:33:54,340 --> 00:34:02,360
so this is example of the multi cloud

00:33:59,470 --> 00:34:05,480
architecture of a red card single

00:34:02,360 --> 00:34:10,819
sign-on platform which is based on the

00:34:05,480 --> 00:34:14,329
key clock project so this platform as

00:34:10,819 --> 00:34:18,470
you can see is using to persistent

00:34:14,329 --> 00:34:21,030
layers so one is relational database

00:34:18,470 --> 00:34:26,130
which in this example is a

00:34:21,030 --> 00:34:30,120
is a my sequel database with with Galera

00:34:26,130 --> 00:34:32,310
for multi master replication and the

00:34:30,120 --> 00:34:34,920
other one is data grid so this is

00:34:32,310 --> 00:34:38,190
in-memory cache to offload some some

00:34:34,920 --> 00:34:44,340
data from from the grid and as you can

00:34:38,190 --> 00:34:48,660
see here both Galera and jdg they they

00:34:44,340 --> 00:34:51,840
have built-in cross data center

00:34:48,660 --> 00:34:57,870
replication functionality which is built

00:34:51,840 --> 00:35:04,170
using some custom protocols running on

00:34:57,870 --> 00:35:06,620
layer layer 4 so tcp or UDP and this is

00:35:04,170 --> 00:35:09,090
this is typically the most feasible

00:35:06,620 --> 00:35:15,450
scenario to implement that data

00:35:09,090 --> 00:35:17,310
replication in in whenever one of your

00:35:15,450 --> 00:35:22,410
data center is ena in a public cloud

00:35:17,310 --> 00:35:24,780
because as I said before you won't be

00:35:22,410 --> 00:35:28,740
able to replicate data using some some

00:35:24,780 --> 00:35:33,630
infrastructure solutions similar

00:35:28,740 --> 00:35:41,010
approach is to use the messaging

00:35:33,630 --> 00:35:46,410
platform so a MQ offers the interconnect

00:35:41,010 --> 00:35:51,470
functionality which lets you exchange

00:35:46,410 --> 00:35:56,030
the messages between the distributed

00:35:51,470 --> 00:35:59,100
data centers without so that users can

00:35:56,030 --> 00:36:02,730
send a message into one data center and

00:35:59,100 --> 00:36:06,240
and some consumers might consume the

00:36:02,730 --> 00:36:08,730
same messages in in different data

00:36:06,240 --> 00:36:12,600
center and this is again based on some

00:36:08,730 --> 00:36:19,770
layer for replication solution which is

00:36:12,600 --> 00:36:21,870
built in into a MQ interconnect so the

00:36:19,770 --> 00:36:25,440
next thing is management so nowadays

00:36:21,870 --> 00:36:31,110
multi cluster multi cloud management is

00:36:25,440 --> 00:36:35,070
very hot topic so many vendors started

00:36:31,110 --> 00:36:40,080
to build or to offer some solutions in

00:36:35,070 --> 00:36:42,840
that area so in case of in case of red

00:36:40,080 --> 00:36:47,070
card so what what we what we did and

00:36:42,840 --> 00:36:53,250
what we are doing so first of all we

00:36:47,070 --> 00:36:55,770
have significantly improved the process

00:36:53,250 --> 00:36:58,620
of installing and upgrading common shift

00:36:55,770 --> 00:37:02,010
so I'm referring here to to opera for

00:36:58,620 --> 00:37:04,590
which nowadays you can install using the

00:37:02,010 --> 00:37:10,950
full stack automation strategy were

00:37:04,590 --> 00:37:14,640
basically you need to provide like five

00:37:10,950 --> 00:37:19,020
up to ten parameters and you will have a

00:37:14,640 --> 00:37:22,590
cluster deployed automatically in let's

00:37:19,020 --> 00:37:26,280
say half hour there are also two hosts

00:37:22,590 --> 00:37:28,830
across set offerings one dedicated which

00:37:26,280 --> 00:37:33,650
is which is hosted on AWS the other one

00:37:28,830 --> 00:37:38,250
is hosted offering on Azure

00:37:33,650 --> 00:37:42,000
so from the installation and upgrades

00:37:38,250 --> 00:37:48,210
point of view there is not much more

00:37:42,000 --> 00:37:52,400
effort to to manage the multi cluster

00:37:48,210 --> 00:37:57,500
OpenShift environment versus some single

00:37:52,400 --> 00:38:01,410
or private cloud environment we are also

00:37:57,500 --> 00:38:04,710
offering in a software-as-a-service

00:38:01,410 --> 00:38:08,550
model the opposite cluster manager

00:38:04,710 --> 00:38:12,480
console but this console is not really

00:38:08,550 --> 00:38:16,170
for the to manage the the platform is

00:38:12,480 --> 00:38:18,570
more for us to offer you and provide you

00:38:16,170 --> 00:38:21,470
some services like subscription

00:38:18,570 --> 00:38:21,470
management or

00:38:21,800 --> 00:38:28,430
or updates some proactive support

00:38:24,910 --> 00:38:32,540
services and I think this platform is

00:38:28,430 --> 00:38:40,250
built to meet this this this kind of use

00:38:32,540 --> 00:38:44,270
cases however because we we join the the

00:38:40,250 --> 00:38:47,780
the IBM family there is also there is

00:38:44,270 --> 00:38:54,350
one more product which looks like will

00:38:47,780 --> 00:38:57,020
be our go-to platform for the the multi

00:38:54,350 --> 00:39:01,130
cloud management or multi cluster

00:38:57,020 --> 00:39:05,840
management it is IBM cloud multi cloud

00:39:01,130 --> 00:39:07,400
manager the significant part of its

00:39:05,840 --> 00:39:10,340
functionality is the management of

00:39:07,400 --> 00:39:13,610
kubernetes clusters and it already

00:39:10,340 --> 00:39:16,280
offers quite advanced capabilities in

00:39:13,610 --> 00:39:19,130
regards to the visibility of your

00:39:16,280 --> 00:39:22,630
cluster so you can register multiple

00:39:19,130 --> 00:39:25,670
clusters to the console and and and

00:39:22,630 --> 00:39:31,370
monitor them from from the matrix from

00:39:25,670 --> 00:39:34,270
single instance it also has some some

00:39:31,370 --> 00:39:37,580
nice functionalities related to the

00:39:34,270 --> 00:39:41,780
world hall deployments so this might at

00:39:37,580 --> 00:39:44,480
some point complement what we are doing

00:39:41,780 --> 00:39:47,480
currently with G tops

00:39:44,480 --> 00:39:49,190
it offers user also some functionalities

00:39:47,480 --> 00:39:52,220
for the to operations so updates

00:39:49,190 --> 00:39:54,860
patching and so on and I think that over

00:39:52,220 --> 00:39:58,280
the time this will be integrated with

00:39:54,860 --> 00:40:00,020
open ship for capabilities this platform

00:39:58,280 --> 00:40:06,170
itself can be deployed on top of open

00:40:00,020 --> 00:40:09,560
shift so and I'm expecting that soon you

00:40:06,170 --> 00:40:13,190
will hear more about that that product

00:40:09,560 --> 00:40:15,910
as our solution for multi cloud or multi

00:40:13,190 --> 00:40:22,630
cluster management

00:40:15,910 --> 00:40:28,460
both in on-premise and in in in sus

00:40:22,630 --> 00:40:32,240
offering offerings next week is

00:40:28,460 --> 00:40:34,490
monitoring so our per shift comes with

00:40:32,240 --> 00:40:38,660
building monitoring stack so based on

00:40:34,490 --> 00:40:43,609
the based on the primitives and and

00:40:38,660 --> 00:40:45,730
Ravana and that there are basically two

00:40:43,609 --> 00:40:50,810
scenarios how we can leverage that

00:40:45,730 --> 00:40:55,280
monitoring stark in the multi cloud or

00:40:50,810 --> 00:41:01,190
multi cluster environment so the first

00:40:55,280 --> 00:41:05,869
approach which I I have experience with

00:41:01,190 --> 00:41:14,210
was to deploy a separate graph on ax

00:41:05,869 --> 00:41:16,540
instance which which where we define

00:41:14,210 --> 00:41:20,680
some dashboard that connects with

00:41:16,540 --> 00:41:25,990
Prometheus instances running on separate

00:41:20,680 --> 00:41:30,230
on separate on different in different

00:41:25,990 --> 00:41:35,300
clusters or clouds the other approach

00:41:30,230 --> 00:41:38,200
which is pretty new is to leverage the

00:41:35,300 --> 00:41:42,770
Prometheus Federation capabilities so

00:41:38,200 --> 00:41:46,100
you can have a Prometheus instance that

00:41:42,770 --> 00:41:48,740
will that will replicate

00:41:46,100 --> 00:41:51,220
the matrix from will pull the matrix

00:41:48,740 --> 00:41:54,860
from prometheus instances running

00:41:51,220 --> 00:42:00,320
running on your on your clusters and

00:41:54,860 --> 00:42:06,830
then used Ravana to to create some some

00:42:00,320 --> 00:42:10,660
dashboards however in these two

00:42:06,830 --> 00:42:15,920
scenarios the the big concern was really

00:42:10,660 --> 00:42:19,100
a cost of getting the data from

00:42:15,920 --> 00:42:22,430
especially in public life scenarios

00:42:19,100 --> 00:42:26,810
getting the data from the the public

00:42:22,430 --> 00:42:31,460
clouds to to to to graph an ax or here

00:42:26,810 --> 00:42:33,380
from one from interest to other I was

00:42:31,460 --> 00:42:36,380
involved in one project where we did

00:42:33,380 --> 00:42:40,130
some tests to compare the volumes of

00:42:36,380 --> 00:42:44,360
data for some dashboards that were built

00:42:40,130 --> 00:42:47,690
in Griffin ax at this time in this

00:42:44,360 --> 00:42:52,700
project I cannot say this is a general

00:42:47,690 --> 00:42:58,930
rule but we find out that using graph on

00:42:52,700 --> 00:43:04,100
ax to to collect metrics from Prometheus

00:42:58,930 --> 00:43:09,410
was cheaper than then done letting

00:43:04,100 --> 00:43:14,150
promit use to to to further write with

00:43:09,410 --> 00:43:16,790
with other parameters instances but I

00:43:14,150 --> 00:43:20,080
cannot say if this is a general rule

00:43:16,790 --> 00:43:22,850
maybe if you somehow optimize

00:43:20,080 --> 00:43:28,160
reconfigure parameters you will be more

00:43:22,850 --> 00:43:33,710
efficient with the second scenario and

00:43:28,160 --> 00:43:39,050
the last topic is a security so very

00:43:33,710 --> 00:43:44,960
important thing so openshift is by

00:43:39,050 --> 00:43:47,270
design very very secure platform so I

00:43:44,960 --> 00:43:49,010
never layer starting from the operating

00:43:47,270 --> 00:43:51,670
system you heard today maybe the

00:43:49,010 --> 00:43:55,089
presentations

00:43:51,670 --> 00:43:58,479
which cover this this operating

00:43:55,089 --> 00:44:00,099
system-level security throughout all the

00:43:58,479 --> 00:44:03,219
older layers openshift

00:44:00,099 --> 00:44:08,369
you have built-in security controls that

00:44:03,219 --> 00:44:12,969
let you run it in a very secure matter

00:44:08,369 --> 00:44:17,499
also from the container images point of

00:44:12,969 --> 00:44:19,779
view there is very nice container

00:44:17,499 --> 00:44:25,900
scanning functionality which is part of

00:44:19,779 --> 00:44:28,509
Quay container registry but what was

00:44:25,900 --> 00:44:34,059
really a missing part in operation was

00:44:28,509 --> 00:44:37,739
to the ability to to define some and Ana

00:44:34,059 --> 00:44:45,759
force definer and for some multi cluster

00:44:37,739 --> 00:44:48,640
security policies that would be enforced

00:44:45,759 --> 00:44:53,859
and deployed and enforce across multiple

00:44:48,640 --> 00:44:57,069
clusters at once so we have been playing

00:44:53,859 --> 00:45:00,039
with open policy agent which is pretty

00:44:57,069 --> 00:45:02,799
cool solution to define some security

00:45:00,039 --> 00:45:04,420
policies it runs as an admission

00:45:02,799 --> 00:45:08,199
controller so if you know admission

00:45:04,420 --> 00:45:10,509
controllers they are kind of low-level

00:45:08,199 --> 00:45:15,400
interceptors of requests to kubernetes

00:45:10,509 --> 00:45:19,199
api so they have access to all the data

00:45:15,400 --> 00:45:21,880
that is sent to the etcd database so

00:45:19,199 --> 00:45:28,059
with those admission controllers you can

00:45:21,880 --> 00:45:31,559
easily analyze anything any data and the

00:45:28,059 --> 00:45:35,859
young content that is sent to to the API

00:45:31,559 --> 00:45:38,890
but open policy agent has no multi

00:45:35,859 --> 00:45:41,440
cluster support so if you will use that

00:45:38,890 --> 00:45:43,380
solution in multi cluster environment

00:45:41,440 --> 00:45:48,489
most probably you will need to leverage

00:45:43,380 --> 00:45:53,339
JIT ops tool or any other replication

00:45:48,489 --> 00:45:58,749
tool to to manage in a centralized way

00:45:53,339 --> 00:46:01,130
the security policies the IBM multi

00:45:58,749 --> 00:46:04,519
cloud manager the tool I mentioned

00:46:01,130 --> 00:46:06,559
in regards to management has also quite

00:46:04,519 --> 00:46:11,019
nice compliance module where you can

00:46:06,559 --> 00:46:13,939
define compliance policies and with that

00:46:11,019 --> 00:46:17,019
it has also built-in capability to

00:46:13,939 --> 00:46:21,829
replicate the data across across

00:46:17,019 --> 00:46:23,359
multiple clusters so this is also if we

00:46:21,829 --> 00:46:26,359
look on the products available on the

00:46:23,359 --> 00:46:33,499
market I think this is the the best

00:46:26,359 --> 00:46:36,679
solution for for this charge so I I live

00:46:33,499 --> 00:46:43,119
I put a couple of links for you so if

00:46:36,679 --> 00:46:47,209
you want to go deeper with some of the

00:46:43,119 --> 00:46:53,569
topics I I briefly discuss here at the

00:46:47,209 --> 00:46:57,709
links I leave the presentation here for

00:46:53,569 --> 00:47:00,559
for you to download so feel free to to

00:46:57,709 --> 00:47:04,189
learn more about the the stuff and I

00:47:00,559 --> 00:47:11,539
think that's pretty all from my side

00:47:04,189 --> 00:47:13,699
I almost taken my time but if you have

00:47:11,539 --> 00:47:19,900
any question I think I can have now one

00:47:13,699 --> 00:47:19,900
or two anybody

00:47:20,949 --> 00:47:36,140
so again can you repeat the ride I don't

00:47:26,449 --> 00:47:40,069
give you download page well I uploaded

00:47:36,140 --> 00:47:42,979
this presentation to to this to the

00:47:40,069 --> 00:47:46,309
conference schedule page so I think if

00:47:42,979 --> 00:47:47,779
you go to to come to my presentation in

00:47:46,309 --> 00:47:50,229
the schedule you should have some link

00:47:47,779 --> 00:47:50,229
hopefully

00:47:55,480 --> 00:48:18,740
okay any more questions please for data

00:48:06,200 --> 00:48:23,480
transfer it you know it's it's also a

00:48:18,740 --> 00:48:25,760
matter of optimizing but at the time

00:48:23,480 --> 00:48:29,800
when we did some tests it was probably

00:48:25,760 --> 00:48:34,640
two times more expensive to to let

00:48:29,800 --> 00:48:37,280
Prometheus get the data from the other

00:48:34,640 --> 00:48:40,250
Prometheus instances versus letting

00:48:37,280 --> 00:48:44,140
graph Anna to execute the prom QR

00:48:40,250 --> 00:48:44,140
queries to compromise

00:48:49,650 --> 00:48:57,090
okay I don't see any more questions okay

00:48:55,019 --> 00:49:05,079
so thank you very much for your time

00:48:57,090 --> 00:49:05,079

YouTube URL: https://www.youtube.com/watch?v=n3HTKIKV7c4


