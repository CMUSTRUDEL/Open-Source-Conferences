Title: OpenCue BoF, SIGGRAPH 2019
Publication date: 2019-08-22
Playlist: SIGGRAPH 2019: Open Source Day
Description: 
	Learn more about roadmap plans for OpenCue, an open source, high-performance render manager for visual effects and animation, hosted at the Academy Software Foundation. 

Part of Open Source Day at SIGGRAPH 2019, hosted by Academy Software Foundation.

Speakers:
Todd Prives, Google
Brian Cipriano, Google
Ben Dines, Sony Pictures Imageworks
Captions: 
	00:00:00,030 --> 00:00:04,170
good morning everyone welcome to the

00:00:02,280 --> 00:00:07,350
open queue birds of a feather here at

00:00:04,170 --> 00:00:08,790
SIGGRAPH 2019 my name is todd previs I'm

00:00:07,350 --> 00:00:10,710
a product manager at Google I'm just

00:00:08,790 --> 00:00:11,940
gonna be giving a very brief overview

00:00:10,710 --> 00:00:13,469
and then turning it over to the people

00:00:11,940 --> 00:00:15,870
that have been doing the the real work

00:00:13,469 --> 00:00:18,210
on this both Ben Dean's from Sony

00:00:15,870 --> 00:00:19,980
Imageworks who's been working with open

00:00:18,210 --> 00:00:21,689
queue for close to 10 years and Bryan

00:00:19,980 --> 00:00:24,510
Cipriano who's a software engineer at

00:00:21,689 --> 00:00:28,439
Google who's been leading our open queue

00:00:24,510 --> 00:00:29,939
efforts on the TSC so again this is just

00:00:28,439 --> 00:00:32,040
gonna be very quick to intro from me but

00:00:29,939 --> 00:00:33,450
before I get started I would love to get

00:00:32,040 --> 00:00:38,430
a quick show of hands how many of you

00:00:33,450 --> 00:00:39,960
have downloaded open queue suite how

00:00:38,430 --> 00:00:41,370
many of you have used it on shots not

00:00:39,960 --> 00:00:45,420
even in production but just used it in

00:00:41,370 --> 00:00:48,000
shots not as sweet ok but again this is

00:00:45,420 --> 00:00:50,219
a you know that it's a very new product

00:00:48,000 --> 00:00:51,360
our new software offering for the

00:00:50,219 --> 00:00:52,559
Academy Software Foundation very

00:00:51,360 --> 00:00:53,910
different from a lot of the libraries

00:00:52,559 --> 00:00:55,590
that typically have been adopted and we

00:00:53,910 --> 00:00:57,899
understand it's gonna take time to ramp

00:00:55,590 --> 00:00:59,460
up and gain adoption so again it's just

00:00:57,899 --> 00:01:01,620
very exciting to see the progress we've

00:00:59,460 --> 00:01:03,600
made over the last year that Bryan's

00:01:01,620 --> 00:01:06,680
going to talk about and the fact that we

00:01:03,600 --> 00:01:10,530
have so many people here actually

00:01:06,680 --> 00:01:11,790
engaging with us and chatting so I'm

00:01:10,530 --> 00:01:13,710
gonna turn over to Ben who's gonna give

00:01:11,790 --> 00:01:15,780
a history of open cue from Sony

00:01:13,710 --> 00:01:17,430
Imageworks then he'll turn it over to

00:01:15,780 --> 00:01:18,869
Bryan who's gonna talk more about the

00:01:17,430 --> 00:01:21,000
the current status the work that was

00:01:18,869 --> 00:01:22,860
done to get it to an open-source product

00:01:21,000 --> 00:01:24,150
and then Bryan I'll talk about the

00:01:22,860 --> 00:01:26,490
roadmap we do want to leave a lot of

00:01:24,150 --> 00:01:27,810
time at the end for QA to get everyone's

00:01:26,490 --> 00:01:29,310
feedback on where they would like to see

00:01:27,810 --> 00:01:31,920
improvements whether I see the roadmap

00:01:29,310 --> 00:01:33,360
go and so on so with that again thanks

00:01:31,920 --> 00:01:42,150
for joining and I'll turn it over to Ben

00:01:33,360 --> 00:01:43,259
dine Smithsonian which works yeah so to

00:01:42,150 --> 00:01:45,600
get some started with some of the

00:01:43,259 --> 00:01:47,070
history of open queue it um these are

00:01:45,600 --> 00:01:48,180
some of the movies that it's worked on

00:01:47,070 --> 00:01:49,560
starting all the way back at the

00:01:48,180 --> 00:01:52,350
beginning with Cloudy with a Chance of

00:01:49,560 --> 00:01:58,079
Meatballs and recognize spider-verse and

00:01:52,350 --> 00:02:00,030
some other ones so yeah as mentioned the

00:01:58,079 --> 00:02:02,219
open queue started as a project called

00:02:00,030 --> 00:02:04,290
q3 it was the third iteration of

00:02:02,219 --> 00:02:07,799
rendering queuing software that we had

00:02:04,290 --> 00:02:09,539
at image works and it first became her

00:02:07,799 --> 00:02:11,580
first went into use about ten years ago

00:02:09,539 --> 00:02:13,010
and that was on Cloudy with a Chance of

00:02:11,580 --> 00:02:14,390
Meatballs

00:02:13,010 --> 00:02:17,300
Cloudy with a Chance of Meatballs was

00:02:14,390 --> 00:02:20,090
still using q3 while it was in

00:02:17,300 --> 00:02:21,980
development and so they were very much

00:02:20,090 --> 00:02:24,410
sort of stress testing it and and

00:02:21,980 --> 00:02:27,970
everything else as it went along and and

00:02:24,410 --> 00:02:31,850
that show delivered in July of 2009 and

00:02:27,970 --> 00:02:36,200
they peaked at if you can imagine 2500

00:02:31,850 --> 00:02:38,810
running cores so many what's interesting

00:02:36,200 --> 00:02:40,760
that was the first show to deliver on q3

00:02:38,810 --> 00:02:42,920
was not Cloudy with a Chance of

00:02:40,760 --> 00:02:45,440
Meatballs it was actually g-force who

00:02:42,920 --> 00:02:48,860
was scheduled to deliver in May of that

00:02:45,440 --> 00:02:51,980
year and in the last three weeks before

00:02:48,860 --> 00:02:54,530
delivery basically pulled a crazy Hail

00:02:51,980 --> 00:02:58,490
Mary and switched the entire show over

00:02:54,530 --> 00:03:00,830
to q3 from the old system at you know

00:02:58,490 --> 00:03:02,660
peaking at about 2200 cores and actually

00:03:00,830 --> 00:03:09,110
it it worked out for them it was a

00:03:02,660 --> 00:03:11,330
smooth landing so some of the more

00:03:09,110 --> 00:03:14,690
recent improvements we've had have been

00:03:11,330 --> 00:03:17,480
adding cloud capability to q3 and so the

00:03:14,690 --> 00:03:20,000
the first the first cloud rendering that

00:03:17,480 --> 00:03:22,330
we were able to do with q3 was in 2017

00:03:20,000 --> 00:03:27,290
that was during Smurfs lost village and

00:03:22,330 --> 00:03:30,250
and that was entirely on AWS cores and

00:03:27,290 --> 00:03:32,630
it peaked around 6500 running on that

00:03:30,250 --> 00:03:37,160
and it was about a year later that we

00:03:32,630 --> 00:03:40,400
then added GCP capability Google cloud

00:03:37,160 --> 00:03:42,080
to the to the to the queue and into our

00:03:40,400 --> 00:03:45,290
software that integrates everything and

00:03:42,080 --> 00:03:46,780
on Hotel Transylvania 3 which was the

00:03:45,290 --> 00:03:50,750
first to actually take advantage of

00:03:46,780 --> 00:03:54,170
Google cloud processing we we actually

00:03:50,750 --> 00:03:56,630
peaked at about 16,000 running running

00:03:54,170 --> 00:03:58,280
course for of the Google cores

00:03:56,630 --> 00:04:00,110
themselves and that was actually still

00:03:58,280 --> 00:04:04,160
in addition to another 6000 running

00:04:00,110 --> 00:04:07,190
Amazon cores currently where we are are

00:04:04,160 --> 00:04:09,860
our q3 software our render farm has

00:04:07,190 --> 00:04:13,010
about 55 thousand local cores in it but

00:04:09,860 --> 00:04:14,540
our peak total running in our q3

00:04:13,010 --> 00:04:16,280
software was actually about a hundred

00:04:14,540 --> 00:04:19,220
thousand and that was during the emoji

00:04:16,280 --> 00:04:23,210
movie if you can imagine in in May of

00:04:19,220 --> 00:04:25,990
2017 and that included about forty

00:04:23,210 --> 00:04:31,190
thousand Amazon cores running along

00:04:25,990 --> 00:04:34,600
on-prem course and uh so that's just of

00:04:31,190 --> 00:04:34,600
the history I'll pass it on right now

00:04:35,110 --> 00:04:45,139
hey thanks so yeah so we started so we

00:04:42,860 --> 00:04:46,940
started working with Sony a few years

00:04:45,139 --> 00:04:49,130
ago kind of kicking the idea around

00:04:46,940 --> 00:04:52,789
about open sourcing their in-house

00:04:49,130 --> 00:04:55,190
scheduler and things kind of went from

00:04:52,789 --> 00:04:56,990
there so we did a lot of work to kind of

00:04:55,190 --> 00:05:00,590
pull out some components and get it

00:04:56,990 --> 00:05:02,419
ready for an open source release we when

00:05:00,590 --> 00:05:05,030
it first kind of further arrived

00:05:02,419 --> 00:05:06,289
it only supported Oracle that we kind of

00:05:05,030 --> 00:05:09,169
knew that we had to support our database

00:05:06,289 --> 00:05:12,830
options going forward so we added a

00:05:09,169 --> 00:05:15,470
second database option in Postgres I was

00:05:12,830 --> 00:05:17,810
also using a network layer called ice

00:05:15,470 --> 00:05:20,030
that had some licensing problems so we

00:05:17,810 --> 00:05:23,240
had to replace that with G RPC as well

00:05:20,030 --> 00:05:25,039
for for networking and then we did a

00:05:23,240 --> 00:05:26,599
whole bunch of other kind of code code

00:05:25,039 --> 00:05:28,430
cleanup and general prep and

00:05:26,599 --> 00:05:31,430
documentation and getting it ready for

00:05:28,430 --> 00:05:34,909
release so that happens in January or

00:05:31,430 --> 00:05:37,099
this year and yeah then a few months

00:05:34,909 --> 00:05:40,220
later it was you know we proposed it as

00:05:37,099 --> 00:05:42,530
an SWF project and it was accepted

00:05:40,220 --> 00:05:44,780
shortly after that so we've been we've

00:05:42,530 --> 00:05:47,810
been doing a lot of work to kind of get

00:05:44,780 --> 00:05:51,830
it get it going since then and and move

00:05:47,810 --> 00:05:53,750
it over into the a SWF so and the s Toby

00:05:51,830 --> 00:05:56,000
F is great for that sort of stuff just

00:05:53,750 --> 00:05:58,520
kind of providing like a lot of the

00:05:56,000 --> 00:06:00,020
stuff that new projects needs so you

00:05:58,520 --> 00:06:03,320
know the whole technical steering

00:06:00,020 --> 00:06:05,780
committee structure even the process of

00:06:03,320 --> 00:06:07,009
like you know taking notes and checking

00:06:05,780 --> 00:06:09,050
them into your github repo so other

00:06:07,009 --> 00:06:10,969
folks can can join in laters Ben has

00:06:09,050 --> 00:06:14,180
been nice to have as well it was you

00:06:10,969 --> 00:06:16,460
know big stuff like CI infrastructure so

00:06:14,180 --> 00:06:18,919
we have we have a bunch of folks on the

00:06:16,460 --> 00:06:21,860
on the on the TSC now folks from Google

00:06:18,919 --> 00:06:24,199
Cloud Sony Netflix

00:06:21,860 --> 00:06:30,440
we've got mattchambers who wrote q3

00:06:24,199 --> 00:06:31,909
originally at Sony and and we've had so

00:06:30,440 --> 00:06:33,919
we've had some pretty good momentum

00:06:31,909 --> 00:06:36,139
we've had about you know you can see the

00:06:33,919 --> 00:06:38,210
stats up here we've had a pretty steady

00:06:36,139 --> 00:06:42,020
amount of changes coming in per week

00:06:38,210 --> 00:06:46,550
you know new new issues being reported

00:06:42,020 --> 00:06:51,949
and bugs being fixed since since it's

00:06:46,550 --> 00:06:54,110
been open sourced and yeah so so so far

00:06:51,949 --> 00:06:58,460
our development has been pretty focused

00:06:54,110 --> 00:07:00,530
on ace the a SWF stuff getting CI in

00:06:58,460 --> 00:07:02,570
place like steady like stable CI in

00:07:00,530 --> 00:07:04,699
place and all that and now we're kind of

00:07:02,570 --> 00:07:08,150
turning our attention to the future so

00:07:04,699 --> 00:07:09,470
we're kind of seeing where the TAC is in

00:07:08,150 --> 00:07:11,630
the process of building a road map

00:07:09,470 --> 00:07:13,460
basically and ands were excited to hear

00:07:11,630 --> 00:07:16,550
what folks have to say and want to see

00:07:13,460 --> 00:07:18,080
on that roadmap so I can shake it pull

00:07:16,550 --> 00:07:21,919
up a full draft if we have time later

00:07:18,080 --> 00:07:25,310
but the kind of main main big things

00:07:21,919 --> 00:07:27,350
that are coming up our windows support

00:07:25,310 --> 00:07:29,470
so right now it's pretty much Linux

00:07:27,350 --> 00:07:33,289
Linux only for a lot of the components

00:07:29,470 --> 00:07:34,729
got general resource limits so that

00:07:33,289 --> 00:07:36,620
includes things like software licenses

00:07:34,729 --> 00:07:38,780
that aren't taken account into the

00:07:36,620 --> 00:07:40,010
schedule right now that's been a popular

00:07:38,780 --> 00:07:41,960
request I think that that one is

00:07:40,010 --> 00:07:43,400
actually in in review right now and

00:07:41,960 --> 00:07:47,030
should be out released within the next

00:07:43,400 --> 00:07:48,800
probably week or so built-in user

00:07:47,030 --> 00:07:51,440
management so right now it kind of

00:07:48,800 --> 00:07:53,479
operates on a pretty open permissions

00:07:51,440 --> 00:07:55,789
model where folks can kind of you know

00:07:53,479 --> 00:07:57,110
launch jobs and access whatever jobs

00:07:55,789 --> 00:08:00,110
they want as long as they have access to

00:07:57,110 --> 00:08:02,530
the system so you know that we want to

00:08:00,110 --> 00:08:04,550
build in a full kind of user system that

00:08:02,530 --> 00:08:06,110
integrates with what you got in-house

00:08:04,550 --> 00:08:08,450
ideally you know things like Active

00:08:06,110 --> 00:08:11,620
Directory and LDAP and stuff like that

00:08:08,450 --> 00:08:14,090
and once we have the user management

00:08:11,620 --> 00:08:15,410
this opens up a whole bunch of other

00:08:14,090 --> 00:08:17,450
stuff we can do in particular having

00:08:15,410 --> 00:08:20,060
like a fine-grained permissions model

00:08:17,450 --> 00:08:24,889
for different resources within your with

00:08:20,060 --> 00:08:26,240
your near open queue deployment and then

00:08:24,889 --> 00:08:27,770
we want we want to expand a lot of the

00:08:26,240 --> 00:08:30,110
host app plugins that we have so right

00:08:27,770 --> 00:08:32,870
now technically you you can run any

00:08:30,110 --> 00:08:34,610
software with open queue the the way

00:08:32,870 --> 00:08:37,490
that it works is you know they're your

00:08:34,610 --> 00:08:40,580
job submission constructs a basically

00:08:37,490 --> 00:08:43,339
what's a bash command he sent through to

00:08:40,580 --> 00:08:45,200
the render nodes at the end so any

00:08:43,339 --> 00:08:47,870
software that you are using can work but

00:08:45,200 --> 00:08:49,339
it is not the easiest thing to do if you

00:08:47,870 --> 00:08:51,460
don't have a plugin for your for your

00:08:49,339 --> 00:08:54,850
host app we have

00:08:51,460 --> 00:08:56,320
my Anouk right now that you know

00:08:54,850 --> 00:09:00,070
basically what it does is it's a light

00:08:56,320 --> 00:09:02,380
layer that you know talks to the the DCC

00:09:00,070 --> 00:09:04,300
app and prepopulates a lot of the things

00:09:02,380 --> 00:09:07,240
builds the command for you and then and

00:09:04,300 --> 00:09:08,560
then submits the job so we wanted we

00:09:07,240 --> 00:09:10,660
want to do a lot of work to expand that

00:09:08,560 --> 00:09:12,459
and we'd love to have other folks you

00:09:10,660 --> 00:09:13,570
know contributing for the for the apps

00:09:12,459 --> 00:09:15,670
that they'd like to see I think

00:09:13,570 --> 00:09:17,560
blenders pretty far out at the top of

00:09:15,670 --> 00:09:19,089
our list I think that's been in progress

00:09:17,560 --> 00:09:21,029
we've made some steps toward that unless

00:09:19,089 --> 00:09:23,080
the last few weeks

00:09:21,029 --> 00:09:24,880
Houdini's on the list as well and

00:09:23,080 --> 00:09:29,260
there's a whole other there's a long

00:09:24,880 --> 00:09:30,820
list of them as well and then kind of

00:09:29,260 --> 00:09:34,690
the the biggest bit of development work

00:09:30,820 --> 00:09:36,010
that's coming up is the a big revamp of

00:09:34,690 --> 00:09:39,070
the sketch of the actual scheduler

00:09:36,010 --> 00:09:40,870
within the system right now you know if

00:09:39,070 --> 00:09:43,690
you've taken a look at the open cue code

00:09:40,870 --> 00:09:46,630
basically a lot of the a lot of the

00:09:43,690 --> 00:09:48,399
scheduling is done in kind of it's all

00:09:46,630 --> 00:09:50,200
database driven so complex queries

00:09:48,399 --> 00:09:53,529
stored procedures that sort of thing

00:09:50,200 --> 00:09:56,230
it's pretty hard to debug and expand and

00:09:53,529 --> 00:09:58,630
maintain so we're gonna be doing or a

00:09:56,230 --> 00:10:02,620
big revamp that that moves a lot of that

00:09:58,630 --> 00:10:04,270
scheduling into into memory and this is

00:10:02,620 --> 00:10:06,610
gonna this will open up a lot of kind of

00:10:04,270 --> 00:10:09,760
advanced features that we can add such

00:10:06,610 --> 00:10:11,440
as you know kind of adapt looks adaptive

00:10:09,760 --> 00:10:18,790
scheduling customizable schedule or

00:10:11,440 --> 00:10:20,380
logic stuff like that and yeah so that's

00:10:18,790 --> 00:10:22,839
that's kind of what we're working on

00:10:20,380 --> 00:10:24,790
that's what the the high-level view of

00:10:22,839 --> 00:10:28,060
the roadmap looks like it is definitely

00:10:24,790 --> 00:10:30,400
a draft right now and you know we'd love

00:10:28,060 --> 00:10:32,050
to get feedback from from folks to see

00:10:30,400 --> 00:10:36,640
what here what they'd like to see on

00:10:32,050 --> 00:10:39,579
there so I think yeah we'll just kind of

00:10:36,640 --> 00:10:43,270
open it up to open up to a QA right now

00:10:39,579 --> 00:10:45,579
and if there's you know if anyone has an

00:10:43,270 --> 00:10:48,579
EVE any feedback anything that they've

00:10:45,579 --> 00:10:51,209
seen with open queue so far yeah we

00:10:48,579 --> 00:10:51,209
thought to hear about it

00:10:56,950 --> 00:11:00,580
not yet but we'll publish it yeah at the

00:10:59,019 --> 00:11:02,200
end of this meeting and then we'll be

00:11:00,580 --> 00:11:05,010
working on it we have a TSC meeting

00:11:02,200 --> 00:11:07,180
tomorrow actually where we'll be kind of

00:11:05,010 --> 00:11:08,620
incorporating the stuff we've we've

00:11:07,180 --> 00:11:10,480
heard over the past few days and today

00:11:08,620 --> 00:11:12,630
and then yeah we'll publish it at that

00:11:10,480 --> 00:11:12,630
point

00:11:24,780 --> 00:11:32,340
yeah so I would say we're about probably

00:11:30,290 --> 00:11:35,100
sorry it's a little hard to say it's

00:11:32,340 --> 00:11:37,740
probably a month or two away from

00:11:35,100 --> 00:11:41,000
Windows support the big the biggest kind

00:11:37,740 --> 00:11:44,790
of problem that we ran into was the

00:11:41,000 --> 00:11:48,180
Python 3 we had to you know do to kind

00:11:44,790 --> 00:11:50,040
of lack of lack of some of the binaries

00:11:48,180 --> 00:11:53,130
that we were using for particularly PI

00:11:50,040 --> 00:11:54,120
side in Windows we had to kind of go

00:11:53,130 --> 00:11:57,290
through and start to convert everything

00:11:54,120 --> 00:12:01,160
to Python 3 as a as a prerequisite to

00:11:57,290 --> 00:12:03,360
you know I'm blocking that but there is

00:12:01,160 --> 00:12:06,030
there is a lot of code in the system

00:12:03,360 --> 00:12:08,460
that already handles windows and windows

00:12:06,030 --> 00:12:10,500
scheduling so it's there shouldn't be a

00:12:08,460 --> 00:12:12,540
lot of work after that to get done and

00:12:10,500 --> 00:12:14,070
it's it doesn't really shouldn't really

00:12:12,540 --> 00:12:20,940
place any any limitations on the

00:12:14,070 --> 00:12:23,690
scheduler as far as we know yeah that's

00:12:20,940 --> 00:12:23,690
right yeah

00:12:41,370 --> 00:12:45,210
yeah I mean it's it's ready now you know

00:12:43,500 --> 00:12:46,830
so many so many folks are using it in

00:12:45,210 --> 00:12:49,560
production we've got a few different

00:12:46,830 --> 00:12:50,700
ways that you can deploy it that or we

00:12:49,560 --> 00:12:52,680
have a user guide that we've published

00:12:50,700 --> 00:12:54,720
or an admin guide that outlines them

00:12:52,680 --> 00:12:57,390
it's we do publish docker images of all

00:12:54,720 --> 00:12:58,710
the main components so you can deploy

00:12:57,390 --> 00:13:00,420
that if you're looking to or we also

00:12:58,710 --> 00:13:02,640
have you know kind of basic build

00:13:00,420 --> 00:13:05,280
instructions as well there's a you know

00:13:02,640 --> 00:13:10,160
a few different steps that you a few

00:13:05,280 --> 00:13:10,160
different components you need but

00:13:19,540 --> 00:13:24,250
Johnson can you repeat the question

00:13:35,879 --> 00:13:42,990
it's a combination it's uh all sorts of

00:13:39,819 --> 00:13:47,019
different I think mostly Dell PowerEdge

00:13:42,990 --> 00:13:50,620
render nodes and those are all connected

00:13:47,019 --> 00:13:54,100
you know through our our network looking

00:13:50,620 --> 00:13:58,329
at our systems right there um it's about

00:13:54,100 --> 00:14:00,370
I think big network but then we have NFS

00:13:58,329 --> 00:14:01,720
mounts where all the production data is

00:14:00,370 --> 00:14:02,829
stored and so everything accesses it

00:14:01,720 --> 00:14:05,879
through that so it's sort of a central

00:14:02,829 --> 00:14:08,019
pool of data where where everything

00:14:05,879 --> 00:14:12,220
reads everything else from it's it's

00:14:08,019 --> 00:14:21,040
very network based that answers your

00:14:12,220 --> 00:14:25,060
question okay okay yeah most of the

00:14:21,040 --> 00:14:27,399
hosts are sixteen physical cores

00:14:25,060 --> 00:14:35,110
thirty-two thread I think we have some

00:14:27,399 --> 00:14:43,800
that are twenty forty Oh though you're

00:14:35,110 --> 00:14:43,800
asking about the oh the server-side yeah

00:14:45,029 --> 00:14:51,720
what does it take to run open here yeah

00:14:53,550 --> 00:15:01,949
okay well it depends on the scale

00:14:56,500 --> 00:15:04,750
I mean oh for fifty-five thousand I

00:15:01,949 --> 00:15:07,350
would have to get back to you on some of

00:15:04,750 --> 00:15:07,350
the specifics

00:15:51,920 --> 00:15:54,459
yeah

00:15:58,470 --> 00:16:04,020
yeah yeah we I think almost never have

00:16:01,110 --> 00:16:05,580
server load related issues with with the

00:16:04,020 --> 00:16:08,210
queue even with 55,000 even with a

00:16:05,580 --> 00:16:08,210
hundred thousand

00:16:19,960 --> 00:16:24,040
yeah definitely it's it's you know

00:16:22,180 --> 00:16:28,050
something that we have in minds but it's

00:16:24,040 --> 00:16:30,460
there are enough benefits to the

00:16:28,050 --> 00:16:32,200
development to doing that kind of

00:16:30,460 --> 00:16:35,050
transition that it's something worth it

00:16:32,200 --> 00:16:36,820
but the yeah there could there could

00:16:35,050 --> 00:16:39,370
definitely be some increased resource

00:16:36,820 --> 00:16:48,730
requirements as a result of that but

00:16:39,370 --> 00:16:49,240
sorry right now it's basically multiple

00:16:48,730 --> 00:16:50,530
master

00:16:49,240 --> 00:16:52,810
so because everything is kind of

00:16:50,530 --> 00:16:54,490
database focused everyone can kind of

00:16:52,810 --> 00:16:57,460
you know play the same role in the

00:16:54,490 --> 00:16:58,600
process yeah when we change it a memory

00:16:57,460 --> 00:17:00,520
focus it'll get a little bit more

00:16:58,600 --> 00:17:02,230
complicated where they'll probably be a

00:17:00,520 --> 00:17:04,210
single scheduling node and the others

00:17:02,230 --> 00:17:06,070
will be able to pick pick up the work if

00:17:04,210 --> 00:17:09,910
that one drops off or or something like

00:17:06,070 --> 00:17:10,840
that but definitely the you know we

00:17:09,910 --> 00:17:14,740
always want to be able to support

00:17:10,840 --> 00:17:17,800
multiple multiple servers here obviously

00:17:14,740 --> 00:17:19,720
like reliance and reliability and

00:17:17,800 --> 00:17:22,230
redundancy is it was pretty important

00:17:19,720 --> 00:17:22,230
here for us

00:17:32,220 --> 00:17:36,890
yeah definitely Greg do you want

00:17:37,160 --> 00:17:43,200
Greg's muscle did working on that piece

00:17:39,980 --> 00:17:46,500
how's it going I'm Greg software

00:17:43,200 --> 00:17:49,170
engineer at Google yeah so the resource

00:17:46,500 --> 00:17:50,940
management stuff is mostly about you

00:17:49,170 --> 00:17:53,340
know imposing arbitrary limits on jobs

00:17:50,940 --> 00:17:56,130
but particularly at the layer level so

00:17:53,340 --> 00:17:59,070
open queue kind of has three tiers of

00:17:56,130 --> 00:18:02,040
job structure you have a job which is a

00:17:59,070 --> 00:18:04,290
large container of multiple layers a

00:18:02,040 --> 00:18:07,380
layer is kind of a command that's

00:18:04,290 --> 00:18:09,480
running against a frame range and then

00:18:07,380 --> 00:18:12,600
you have individual frames running each

00:18:09,480 --> 00:18:17,640
so you can impose any kind of limit you

00:18:12,600 --> 00:18:20,790
want on the layer level and basically

00:18:17,640 --> 00:18:23,370
it's just going to look at how many

00:18:20,790 --> 00:18:25,320
types of jobs are running with that

00:18:23,370 --> 00:18:29,100
limit what the resources are available

00:18:25,320 --> 00:18:31,340
and do scheduling appropriately based on

00:18:29,100 --> 00:18:31,340
that

00:18:49,980 --> 00:18:57,120
I know I think I'm following you

00:18:54,360 --> 00:18:58,679
correctly it's more for the the first

00:18:57,120 --> 00:19:01,320
scenario you described we're basically

00:18:58,679 --> 00:19:02,940
being able to do scheduling based on

00:19:01,320 --> 00:19:05,720
license limitations is one of the main

00:19:02,940 --> 00:19:05,720
priorities of a

00:19:20,750 --> 00:19:26,730
no we'd love to talk about the about

00:19:23,400 --> 00:19:28,260
advanced features yeah you know if we

00:19:26,730 --> 00:19:32,460
want chat here or we also have a

00:19:28,260 --> 00:19:33,900
developer's list as well which we can we

00:19:32,460 --> 00:19:35,309
can share with you as well that'd be a

00:19:33,900 --> 00:19:36,720
great place to start chatting about it

00:19:35,309 --> 00:19:40,980
and and so what you'd like to see and

00:19:36,720 --> 00:19:42,780
OPIC you yeah yeah and there's also that

00:19:40,980 --> 00:19:45,030
we also have our public TSE meeting

00:19:42,780 --> 00:19:46,740
tomorrow if you want to we're happy to

00:19:45,030 --> 00:19:48,980
hear any any new proposals as well as

00:19:46,740 --> 00:19:48,980
there

00:19:58,809 --> 00:20:03,230
well they can probably talk a little bit

00:20:01,100 --> 00:20:05,809
more about the specifics of it the Sony

00:20:03,230 --> 00:20:07,249
folks but I will say that there there

00:20:05,809 --> 00:20:09,679
isn't too much especially you need to do

00:20:07,249 --> 00:20:10,909
you know once there's a there's a

00:20:09,679 --> 00:20:13,190
component that runs on each of the

00:20:10,909 --> 00:20:15,440
router notes called rqd when it's when

00:20:13,190 --> 00:20:17,659
RTD starts up its gonna phone home back

00:20:15,440 --> 00:20:19,759
to the back to the server back to the

00:20:17,659 --> 00:20:21,529
Cuba it's called and those nodes will

00:20:19,759 --> 00:20:23,929
basically be registered and ready to go

00:20:21,529 --> 00:20:28,490
so as long as as long as you're on the

00:20:23,929 --> 00:20:30,230
same network as Bucky bought then there

00:20:28,490 --> 00:20:31,909
isn't really too much too much else that

00:20:30,230 --> 00:20:38,029
he need to do but you do want to talk

00:20:31,909 --> 00:20:39,619
about the specifics at all yeah I think

00:20:38,029 --> 00:20:41,480
that covers most of it yeah in our case

00:20:39,619 --> 00:20:43,850
you know we we peer to our network to

00:20:41,480 --> 00:20:46,249
let's say Google's network in order to

00:20:43,850 --> 00:20:48,919
have you know nice direct connection so

00:20:46,249 --> 00:20:52,129
that everything was fast but but yeah

00:20:48,919 --> 00:20:53,480
otherwise everything the the structure

00:20:52,129 --> 00:20:55,460
of the queue itself the huge

00:20:53,480 --> 00:20:58,789
infrastructure was still running exactly

00:20:55,460 --> 00:21:01,090
as it was you know when everything is on

00:20:58,789 --> 00:21:01,090
print

00:21:12,100 --> 00:21:21,940
oh we did actually yes that's actually a

00:21:19,870 --> 00:21:23,400
good question we are using preemptable

00:21:21,940 --> 00:21:27,520
because it's about a quarter of a price

00:21:23,400 --> 00:21:29,950
I think most of them have a policy of a

00:21:27,520 --> 00:21:31,780
24-hour automatic reboot and that's in

00:21:29,950 --> 00:21:34,330
addition to being able to have it

00:21:31,780 --> 00:21:36,750
preempted in our case that was

00:21:34,330 --> 00:21:39,940
implemented in the the renderer itself

00:21:36,750 --> 00:21:42,820
we have our own version of Arnold which

00:21:39,940 --> 00:21:45,039
has the ability to sort of you know

00:21:42,820 --> 00:21:47,919
write out a periodic checkpoint and so

00:21:45,039 --> 00:21:50,470
you can start and restart stop restart

00:21:47,919 --> 00:21:52,179
and and so that gave us the ability to

00:21:50,470 --> 00:21:54,100
say okay well as long as they can give

00:21:52,179 --> 00:21:57,130
us about you know 30-second warning

00:21:54,100 --> 00:21:59,289
before pre-empting the the host then we

00:21:57,130 --> 00:22:01,960
can write out the temporary data and

00:21:59,289 --> 00:22:04,539
then start it again somewhere else

00:22:01,960 --> 00:22:08,049
and then which actually at that point

00:22:04,539 --> 00:22:09,730
then the 24-hour limit was less of a big

00:22:08,049 --> 00:22:13,030
deal because of that one you could at

00:22:09,730 --> 00:22:14,620
least predict so yeah we've dealt with

00:22:13,030 --> 00:22:17,740
it but it that's actually happening on

00:22:14,620 --> 00:22:21,659
the software and of our renderer as

00:22:17,740 --> 00:22:21,659
opposed to the actual queue itself

00:22:29,720 --> 00:22:35,820
demand-based yeah we would we had a set

00:22:33,450 --> 00:22:38,790
of scripts that would sort of scale up

00:22:35,820 --> 00:22:40,920
and down our our cloud allocation as we

00:22:38,790 --> 00:22:43,590
needed and so it was sort of based on

00:22:40,920 --> 00:22:44,670
what the production itself would say you

00:22:43,590 --> 00:22:46,710
know hey you know we're gonna have a

00:22:44,670 --> 00:22:47,580
really busy render night you know let's

00:22:46,710 --> 00:22:51,360
go up to you

00:22:47,580 --> 00:22:54,210
you know from 8,000 to 10,000 15,000 or

00:22:51,360 --> 00:22:57,210
something like that but but but yeah

00:22:54,210 --> 00:23:01,230
everything was based on sort of the the

00:22:57,210 --> 00:23:04,730
load as it was on the cue and we had it

00:23:01,230 --> 00:23:04,730
yeah we had it scaling alongside that

00:23:19,400 --> 00:23:23,550
was those scripts separate from the

00:23:21,510 --> 00:23:25,230
process of open cue code open cue

00:23:23,550 --> 00:23:26,940
potentially in the future say oh I have

00:23:25,230 --> 00:23:31,710
a lot of jobs I'm allowed to open up

00:23:26,940 --> 00:23:35,400
more on GC GC P or whatever and get more

00:23:31,710 --> 00:23:37,560
render nodes yeah I remember those

00:23:35,400 --> 00:23:40,470
scripts were running alongside the cue

00:23:37,560 --> 00:23:43,530
software as opposed to directly inside

00:23:40,470 --> 00:23:47,610
of the cue system itself so it was kind

00:23:43,530 --> 00:23:52,980
of more of a outside monitoring and yeah

00:23:47,610 --> 00:23:55,350
tweaking the settings yeah yeah so

00:23:52,980 --> 00:23:56,910
there's no that isn't built Adobe q yet

00:23:55,350 --> 00:23:57,660
it is kind of an external process but

00:23:56,910 --> 00:23:59,490
that's don't need something that we

00:23:57,660 --> 00:24:02,370
haven't our eye on I think it comes up

00:23:59,490 --> 00:24:03,510
comes up a lot with folks who'd like you

00:24:02,370 --> 00:24:05,250
know all that data is in your schedule

00:24:03,510 --> 00:24:07,160
already there's no reason why you need

00:24:05,250 --> 00:24:09,300
someone making those manual decisions so

00:24:07,160 --> 00:24:12,810
yeah that's something that we're looking

00:24:09,300 --> 00:24:15,060
at yeah and also for the honored to say

00:24:12,810 --> 00:24:16,320
about the preemptable event is that it

00:24:15,060 --> 00:24:17,760
is kind of reliant on the software

00:24:16,320 --> 00:24:20,820
itself to do any check pointing right

00:24:17,760 --> 00:24:23,850
now the the system does handle knows

00:24:20,820 --> 00:24:26,040
disappearing very well it's you know if

00:24:23,850 --> 00:24:27,600
the node gets preempted then it's the

00:24:26,040 --> 00:24:31,380
system flags that pretty quickly and it

00:24:27,600 --> 00:24:33,030
gets removed from the pool so there

00:24:31,380 --> 00:24:34,830
isn't really anything special you need

00:24:33,030 --> 00:24:37,380
to do to deal with preemptable is it

00:24:34,830 --> 00:24:38,610
just kind of you know the tasks will

00:24:37,380 --> 00:24:40,470
fail and the nodes will drop off and

00:24:38,610 --> 00:24:43,410
then those tasks get reviewed later

00:24:40,470 --> 00:24:45,870
and if you do have checkpointing in use

00:24:43,410 --> 00:24:47,490
with your software then you know the

00:24:45,870 --> 00:24:52,230
software elves make use of that resume

00:24:47,490 --> 00:24:54,420
the task for you it is sorry it is my

00:24:52,230 --> 00:24:56,490
understanding that open queue has quite

00:24:54,420 --> 00:24:58,220
a bit different from queue like you

00:24:56,490 --> 00:25:00,750
mentioned change in the network protocol

00:24:58,220 --> 00:25:03,840
may be running post-grad and open-source

00:25:00,750 --> 00:25:05,400
version is Sony running open queue or

00:25:03,840 --> 00:25:06,470
queue and are there plans to like

00:25:05,400 --> 00:25:08,880
keeping

00:25:06,470 --> 00:25:12,180
migrating SONET open queue and have that

00:25:08,880 --> 00:25:13,590
rolling with the open source release yes

00:25:12,180 --> 00:25:16,620
so they're in the process of migrating

00:25:13,590 --> 00:25:18,420
over but they soon will be fully on the

00:25:16,620 --> 00:25:20,010
open queue release and all of the it

00:25:18,420 --> 00:25:21,960
actually kind of worked out because all

00:25:20,010 --> 00:25:24,570
those components that we removed and

00:25:21,960 --> 00:25:26,250
replaced we're all all mapped pretty

00:25:24,570 --> 00:25:28,140
well to their replacements you know gr

00:25:26,250 --> 00:25:31,230
PC and ice share a lot of similarities

00:25:28,140 --> 00:25:33,630
Oracle and Postgres were almost entirely

00:25:31,230 --> 00:25:36,240
compatible there were very few like code

00:25:33,630 --> 00:25:38,100
changes we actually needed to to get all

00:25:36,240 --> 00:25:40,260
that stuff working so the the transition

00:25:38,100 --> 00:25:41,580
process should be should be pretty

00:25:40,260 --> 00:25:45,600
smooth we haven't really run into any

00:25:41,580 --> 00:25:47,940
any big problems in hi could you talk

00:25:45,600 --> 00:25:52,080
about some of the maybe performance edge

00:25:47,940 --> 00:25:53,460
cases just in terms of submitting a lot

00:25:52,080 --> 00:25:55,980
of jobs for oh thank you to consider

00:25:53,460 --> 00:25:57,960
sort of limits around that space and

00:25:55,980 --> 00:26:00,330
what you did to kind of mitigate them or

00:25:57,960 --> 00:26:02,610
as you move to the cloud and maybe

00:26:00,330 --> 00:26:04,980
introduce more latency and and having

00:26:02,610 --> 00:26:05,790
hosts and sort of weird locations or

00:26:04,980 --> 00:26:09,900
things like that

00:26:05,790 --> 00:26:12,390
Thanks yeah sure so when it comes to

00:26:09,900 --> 00:26:14,730
moving to the cloud we have we have run

00:26:12,390 --> 00:26:17,100
into too many problems actually but the

00:26:14,730 --> 00:26:18,390
kind of network demands of our QDR are

00:26:17,100 --> 00:26:20,520
pretty low and haven't really been

00:26:18,390 --> 00:26:24,030
affected much by the latency involved I

00:26:20,520 --> 00:26:26,430
think the I think file storage which

00:26:24,030 --> 00:26:29,460
open queue doesn't really touch at all

00:26:26,430 --> 00:26:30,720
is is much more of a concern than any

00:26:29,460 --> 00:26:34,530
anything that comes up with the

00:26:30,720 --> 00:26:38,570
scheduling itself or the render nodes in

00:26:34,530 --> 00:26:38,570
terms of like lots of jobs

00:26:42,960 --> 00:26:45,960
yeah

00:26:52,859 --> 00:26:57,759
yeah do I don't talk about some of the

00:26:55,570 --> 00:27:00,159
load-testing he did as part of the last

00:26:57,759 --> 00:27:02,320
week conferences hi my name is Brennan

00:27:00,159 --> 00:27:05,019
Doyle I'm a solution architect at Google

00:27:02,320 --> 00:27:06,789
so the tool is not really intended to be

00:27:05,019 --> 00:27:08,379
cloud only like we're trying we have

00:27:06,789 --> 00:27:10,809
released an open-source tool that can

00:27:08,379 --> 00:27:13,629
run anywhere but as a solution architect

00:27:10,809 --> 00:27:15,549
with a background in visual effects that

00:27:13,629 --> 00:27:17,589
we've been running a lot of we've been

00:27:15,549 --> 00:27:20,379
stress testing it at Google ourselves

00:27:17,589 --> 00:27:21,399
and as you mentioned a lot of what you

00:27:20,379 --> 00:27:22,330
try to do when you're moving to the

00:27:21,399 --> 00:27:23,950
cloud is make sure that the

00:27:22,330 --> 00:27:26,679
infrastructure behind it is strong and

00:27:23,950 --> 00:27:28,809
storage and Google has a great story

00:27:26,679 --> 00:27:30,159
around networking we have a great story

00:27:28,809 --> 00:27:31,779
around storage as well this is not a

00:27:30,159 --> 00:27:35,469
Google presentation all the other clouds

00:27:31,779 --> 00:27:37,299
are doing a great job as well but you

00:27:35,469 --> 00:27:38,710
would want to connect with solution

00:27:37,299 --> 00:27:40,419
architect or someone from the cloud that

00:27:38,710 --> 00:27:47,879
you're running on to design your system

00:27:40,419 --> 00:27:50,679
oh I think so would we we were we've run

00:27:47,879 --> 00:27:53,019
some processes primarily through blender

00:27:50,679 --> 00:27:56,049
and running jobs we've had upwards of

00:27:53,019 --> 00:28:00,190
6,000 cores running at a time like on on

00:27:56,049 --> 00:28:01,719
our scenarios oh yeah sorry that that

00:28:00,190 --> 00:28:04,419
would be instances which would be

00:28:01,719 --> 00:28:05,739
somewhere between a virtual cords and

00:28:04,419 --> 00:28:08,169
sixteen depending on what we were doing

00:28:05,739 --> 00:28:09,849
so the system should scale quite well

00:28:08,169 --> 00:28:11,830
but you will want to talk to somebody

00:28:09,849 --> 00:28:13,539
with cloud experience about like your

00:28:11,830 --> 00:28:14,950
filers and what type of networking

00:28:13,539 --> 00:28:20,440
you're using because that's likely to be

00:28:14,950 --> 00:28:22,960
where you're gonna run into issues yeah

00:28:20,440 --> 00:28:25,179
but in terms of we did throw a you know

00:28:22,960 --> 00:28:27,599
I think thousands of jobs and tap a

00:28:25,179 --> 00:28:29,830
simultaneous asset at the same time and

00:28:27,599 --> 00:28:33,190
you know I think we've we uncovered a

00:28:29,830 --> 00:28:35,739
few bugs in the process but once we made

00:28:33,190 --> 00:28:38,710
a few a few small efficiency efficiency

00:28:35,739 --> 00:28:40,419
changes things you know handle it pretty

00:28:38,710 --> 00:28:43,979
well so it can handle a lot of

00:28:40,419 --> 00:28:43,979
simultaneous work right now

00:28:44,480 --> 00:28:53,170
I forget the exact it was thousands of

00:28:48,040 --> 00:28:53,170
of tasks running at the same time right

00:28:54,370 --> 00:29:00,110
we published some solutions around this

00:28:58,220 --> 00:29:02,450
that you could find on the GCP website

00:29:00,110 --> 00:29:03,680
by just looking up open Q and G CP and

00:29:02,450 --> 00:29:05,450
there's like scene files that you can

00:29:03,680 --> 00:29:07,160
download and examples of how to run

00:29:05,450 --> 00:29:08,990
those so we've done a couple of things

00:29:07,160 --> 00:29:10,850
one is like very small jobs and a lot of

00:29:08,990 --> 00:29:13,730
them and then others are very big jobs

00:29:10,850 --> 00:29:20,960
and not as many and open q does it's

00:29:13,730 --> 00:29:23,660
been keeping up I don't plot number of

00:29:20,960 --> 00:29:31,040
my manner remembering was about six or

00:29:23,660 --> 00:29:32,840
eight thousand at a time are there are

00:29:31,040 --> 00:29:35,090
there any design decisions being made to

00:29:32,840 --> 00:29:37,010
help push forward things in a like a

00:29:35,090 --> 00:29:38,270
multi-site workflow way where different

00:29:37,010 --> 00:29:40,820
sites could actually share a single

00:29:38,270 --> 00:29:42,170
supervisor and manage the work between

00:29:40,820 --> 00:29:44,000
them and have some sort of native

00:29:42,170 --> 00:29:45,800
understanding even of things like the

00:29:44,000 --> 00:29:47,780
bandwidth between sites how much data

00:29:45,800 --> 00:29:49,880
could actually travel across those tubes

00:29:47,780 --> 00:29:52,280
and just actually like manage the

00:29:49,880 --> 00:29:53,690
resources in a more holistic worldwide

00:29:52,280 --> 00:29:55,250
kind of way mmm

00:29:53,690 --> 00:29:57,020
yeah good coach so they're kind of like

00:29:55,250 --> 00:29:59,750
to two parts that question right so it

00:29:57,020 --> 00:30:01,430
currently with the obq does support a

00:29:59,750 --> 00:30:04,010
multi-site deployment this is kind of

00:30:01,430 --> 00:30:05,600
you know one of the benefits to this the

00:30:04,010 --> 00:30:07,340
the current database driven model is you

00:30:05,600 --> 00:30:10,460
to spin up more key box where ever

00:30:07,340 --> 00:30:12,620
assign them different facilities and you

00:30:10,460 --> 00:30:15,650
kind of are on your right each each

00:30:12,620 --> 00:30:20,360
facility a term within open queue

00:30:15,650 --> 00:30:22,540
operates independently so it just so it

00:30:20,360 --> 00:30:24,830
takes care of its own facility and

00:30:22,540 --> 00:30:26,000
you're all good so that is that's

00:30:24,830 --> 00:30:28,400
something we'll have to maintain as they

00:30:26,000 --> 00:30:29,600
move to more in memory approach and

00:30:28,400 --> 00:30:32,030
makes make sure it that kind of system

00:30:29,600 --> 00:30:34,400
still still works well because it's

00:30:32,030 --> 00:30:37,570
important for a lot of folks are using a

00:30:34,400 --> 00:30:40,100
system this kind of second part is like

00:30:37,570 --> 00:30:42,170
yeah communicating requirements between

00:30:40,100 --> 00:30:43,910
the two that is not really something

00:30:42,170 --> 00:30:46,190
that open kudos right now I think a lot

00:30:43,910 --> 00:30:47,510
of that comes down to file storage as

00:30:46,190 --> 00:30:49,310
well like making sure your assets are in

00:30:47,510 --> 00:30:52,250
the right place at the right time that

00:30:49,310 --> 00:30:55,910
is really right now outside of the open

00:30:52,250 --> 00:30:58,920
queue domain but it it definitely does

00:30:55,910 --> 00:31:00,300
play into the scheduling store

00:30:58,920 --> 00:31:01,970
various different requirements that need

00:31:00,300 --> 00:31:04,820
to be in place for the job start so

00:31:01,970 --> 00:31:09,360
that's something we'll be looking at

00:31:04,820 --> 00:31:11,160
Tampa just around that how how much

00:31:09,360 --> 00:31:12,900
history you can keep in the database if

00:31:11,160 --> 00:31:14,580
it recommended like when you would

00:31:12,900 --> 00:31:16,200
actually have to move records out of the

00:31:14,580 --> 00:31:18,660
the Postgres database or is it seem like

00:31:16,200 --> 00:31:20,370
it scales pretty well I don't think

00:31:18,660 --> 00:31:21,840
right now that that ever really needs to

00:31:20,370 --> 00:31:24,330
happen so there is a kind of auto

00:31:21,840 --> 00:31:26,280
archiving built in so the database is

00:31:24,330 --> 00:31:28,980
kind of split between primary tables and

00:31:26,280 --> 00:31:30,690
history tables and as jobs finish they

00:31:28,980 --> 00:31:31,920
get kind of moved all their data gets

00:31:30,690 --> 00:31:33,360
kind of moved to the history table so

00:31:31,920 --> 00:31:36,090
it's still there and accessible but the

00:31:33,360 --> 00:31:37,800
as the actual scheduling is running it

00:31:36,090 --> 00:31:39,990
is only working on the primary tables so

00:31:37,800 --> 00:31:43,110
it stays quite fast so there's no there

00:31:39,990 --> 00:31:44,940
should be no real like you know

00:31:43,110 --> 00:31:49,620
archiving stuff that has to happen right

00:31:44,940 --> 00:31:51,390
now with regard to local rendering could

00:31:49,620 --> 00:31:54,810
you talk a little bit about any approach

00:31:51,390 --> 00:31:56,190
that you already have to rendering

00:31:54,810 --> 00:31:58,590
through the same code path so in other

00:31:56,190 --> 00:32:00,570
words an artist wants to use their local

00:31:58,590 --> 00:32:01,800
machine but still go through the same

00:32:00,570 --> 00:32:03,720
code path so you say have a little say

00:32:01,800 --> 00:32:05,340
blogging Resource Management cetera is

00:32:03,720 --> 00:32:06,600
there something built in already to

00:32:05,340 --> 00:32:08,850
handle that or is that something you'd

00:32:06,600 --> 00:32:11,070
have to develop on top of oh thank you

00:32:08,850 --> 00:32:13,140
yes I mean you can run an archaeon on

00:32:11,070 --> 00:32:15,450
you know your local workstation and have

00:32:13,140 --> 00:32:17,130
it read to register as a as a render

00:32:15,450 --> 00:32:19,110
node and then it'll basically function

00:32:17,130 --> 00:32:23,910
as a as a normal worker within the

00:32:19,110 --> 00:32:25,890
system oh that's right yeah there's also

00:32:23,910 --> 00:32:28,110
a kind of local scheduled feature that's

00:32:25,890 --> 00:32:29,310
that's built into the job submission as

00:32:28,110 --> 00:32:36,480
well so you can sketch you can schedule

00:32:29,310 --> 00:32:39,960
work directly to your machine as well so

00:32:36,480 --> 00:32:44,460
when and when rqd registers a render

00:32:39,960 --> 00:32:47,790
node does it sort of introspect all of

00:32:44,460 --> 00:32:51,510
its sort of properties and then report

00:32:47,790 --> 00:32:55,410
those so so does that include local

00:32:51,510 --> 00:32:59,040
storage as well yeah so it includes yeah

00:32:55,410 --> 00:33:01,110
cores Ram local storage scratch storage

00:32:59,040 --> 00:33:04,200
there are a few of other fields GPU

00:33:01,110 --> 00:33:05,790
GPUs as well yep and that all gets kind

00:33:04,200 --> 00:33:08,670
of bundled into this host report that

00:33:05,790 --> 00:33:10,680
gets sent back to the cubot so and then

00:33:08,670 --> 00:33:12,600
the cue bottle use that to kind of break

00:33:10,680 --> 00:33:14,940
you know if you've configured it it'll

00:33:12,600 --> 00:33:18,270
it can break that host up into different

00:33:14,940 --> 00:33:23,040
slots for work basically so you know

00:33:18,270 --> 00:33:24,930
core is a rammer whatever do you is

00:33:23,040 --> 00:33:28,890
there any management of CPU affinity on

00:33:24,930 --> 00:33:39,450
Linux I don't think we do any of that

00:33:28,890 --> 00:33:40,290
right now how often does the host

00:33:39,450 --> 00:33:42,300
connects

00:33:40,290 --> 00:33:45,360
since that report to the database and

00:33:42,300 --> 00:33:47,309
often how often does it sketchily works

00:33:45,360 --> 00:33:50,790
what's the cycle I guess it's my

00:33:47,309 --> 00:33:55,400
question hmm so the the report gets sent

00:33:50,790 --> 00:33:55,400
is every 30 seconds something like that

00:34:01,190 --> 00:34:05,970
yeah I say so so it's got this kind of

00:34:04,200 --> 00:34:07,890
fallback method so it can be every three

00:34:05,970 --> 00:34:10,110
seconds and then it kind of that'll fall

00:34:07,890 --> 00:34:12,780
back is it as it stops working on stuff

00:34:10,110 --> 00:34:15,710
and reports less less frequently and

00:34:12,780 --> 00:34:19,379
sorry what was the the second part that

00:34:15,710 --> 00:34:20,790
the scheduling cycle yeah so we're

00:34:19,379 --> 00:34:22,620
finding that things gets so the

00:34:20,790 --> 00:34:24,600
scheduling cycle is pretty much running

00:34:22,620 --> 00:34:26,700
pretty much running constantly it'll

00:34:24,600 --> 00:34:28,710
just finish the loop and keep working so

00:34:26,700 --> 00:34:30,090
we're finding that even with when we

00:34:28,710 --> 00:34:32,149
were up until the thousands of tasks

00:34:30,090 --> 00:34:36,860
things were getting scheduled within I

00:34:32,149 --> 00:34:36,860
don't know a few seconds I think right

00:34:38,870 --> 00:34:43,290
we hope to actually improve that with

00:34:41,070 --> 00:34:44,879
the with the in-memory scheduler we

00:34:43,290 --> 00:34:46,620
think that we could do up do a much

00:34:44,879 --> 00:34:48,450
quicker full pass of the farm and

00:34:46,620 --> 00:34:53,540
basically schedule the entire farm in a

00:34:48,450 --> 00:34:53,540
single pass like like within a second

00:35:01,520 --> 00:35:07,980
yeah 6000 scheduled tasks in 20 seconds

00:35:05,630 --> 00:35:09,690
can you talk a little bit about the fair

00:35:07,980 --> 00:35:12,210
share mechanism like how you break up

00:35:09,690 --> 00:35:14,040
the farm and how that's allocated and

00:35:12,210 --> 00:35:17,040
how you decide what the most important

00:35:14,040 --> 00:35:18,360
thing to get going is yeah Gregory are

00:35:17,040 --> 00:35:24,240
you you're a little bit more familiar

00:35:18,360 --> 00:35:25,530
with what that stuff right sorry you

00:35:24,240 --> 00:35:27,890
talk a little bit about the fair share

00:35:25,530 --> 00:35:30,510
mechanism like how you break up a

00:35:27,890 --> 00:35:32,520
resource like a render farm into

00:35:30,510 --> 00:35:34,440
multiple shows multiple departments and

00:35:32,520 --> 00:35:36,740
talk about how you allocate those

00:35:34,440 --> 00:35:47,690
resources across all of these

00:35:36,740 --> 00:35:51,090
essentially competing shows so I

00:35:47,690 --> 00:35:56,010
basically all of those are pretty much

00:35:51,090 --> 00:35:57,330
features of a job right and I the

00:35:56,010 --> 00:36:00,000
scheduler is gonna look at those

00:35:57,330 --> 00:36:04,740
features and the available resources and

00:36:00,000 --> 00:36:07,980
determine whether or not it will work on

00:36:04,740 --> 00:36:09,800
the resources that are available pretty

00:36:07,980 --> 00:36:14,130
much hosts are broken down into

00:36:09,800 --> 00:36:17,580
available procs procs is not a term for

00:36:14,130 --> 00:36:22,890
processors in this case but it's

00:36:17,580 --> 00:36:24,990
basically a work slot and so you know

00:36:22,890 --> 00:36:27,300
going to bin packing and stuff like that

00:36:24,990 --> 00:36:30,780
that's the the mechanism for bin packing

00:36:27,300 --> 00:36:34,020
there so is there like something

00:36:30,780 --> 00:36:35,280
specific as far as the well so there's a

00:36:34,020 --> 00:36:37,230
bunch of different ways to do fair share

00:36:35,280 --> 00:36:39,390
right like there's just one big queue

00:36:37,230 --> 00:36:43,350
and everybody's ranked in priority order

00:36:39,390 --> 00:36:45,690
or you break up your farm into loose

00:36:43,350 --> 00:36:47,369
allocations across the shows or you

00:36:45,690 --> 00:36:48,810
break them up in hard allocations across

00:36:47,369 --> 00:36:51,480
the shows like I'm curious what the

00:36:48,810 --> 00:36:56,490
mechanism is for that got it yeah so

00:36:51,480 --> 00:36:59,220
there's actually allocations and a show

00:36:56,490 --> 00:37:02,310
can subscribe to particular allocations

00:36:59,220 --> 00:37:05,210
of hosts so allocations being a bucket

00:37:02,310 --> 00:37:06,980
for hosts and show

00:37:05,210 --> 00:37:10,790
subscribe to multiple of those

00:37:06,980 --> 00:37:12,380
allocations and it's really up to you as

00:37:10,790 --> 00:37:14,240
far as how you want to configure your

00:37:12,380 --> 00:37:16,520
breakdown to the farm so you can have it

00:37:14,240 --> 00:37:19,520
be just one big flat pool that's shared

00:37:16,520 --> 00:37:23,450
evenly and prioritized across everyone

00:37:19,520 --> 00:37:25,280
or if you have you know a certain amount

00:37:23,450 --> 00:37:29,059
of like quick jobs that you want to have

00:37:25,280 --> 00:37:31,520
scheduled and you know a separate pool

00:37:29,059 --> 00:37:36,470
reserved for those you can obviously set

00:37:31,520 --> 00:37:39,859
that what type of Python MPI external

00:37:36,470 --> 00:37:42,230
Python API do you have for open queue

00:37:39,859 --> 00:37:44,480
and also okay the metrics and statistics

00:37:42,230 --> 00:37:48,079
can we get back for completed jobs and

00:37:44,480 --> 00:37:50,450
tasks yeah so the in terms of API there

00:37:48,079 --> 00:37:52,880
is you know there's a Python API that we

00:37:50,450 --> 00:37:55,390
publish all of the it's part of the main

00:37:52,880 --> 00:37:58,250
the main repository that's up on github

00:37:55,390 --> 00:37:59,900
all of our basically all of our

00:37:58,250 --> 00:38:03,980
client-side tools are going through that

00:37:59,900 --> 00:38:05,569
same Python API so the GUI uses that the

00:38:03,980 --> 00:38:06,920
submission tools use that all the hosts

00:38:05,569 --> 00:38:10,940
app plugins that we have right now is

00:38:06,920 --> 00:38:12,619
that as well so there's a lot of new the

00:38:10,940 --> 00:38:14,450
API is there as well as you know a bunch

00:38:12,619 --> 00:38:16,880
of other kind of code samples of use if

00:38:14,450 --> 00:38:19,040
you look at the what the existing Python

00:38:16,880 --> 00:38:23,569
components are using to call into that

00:38:19,040 --> 00:38:31,700
API in terms of like metrics that are

00:38:23,569 --> 00:38:34,250
available so based on the information

00:38:31,700 --> 00:38:36,859
that's stored in the history table you'd

00:38:34,250 --> 00:38:39,770
be able to you know compile all of that

00:38:36,859 --> 00:38:41,750
that there isn't actually there's

00:38:39,770 --> 00:38:44,329
nothing built-in and not in the API for

00:38:41,750 --> 00:38:45,920
for actually putting together kind of

00:38:44,329 --> 00:38:48,200
rolled up metrics based on things like

00:38:45,920 --> 00:38:50,960
that but I mean I've I've done a lot of

00:38:48,200 --> 00:38:53,510
work just pulling the data using you

00:38:50,960 --> 00:38:54,980
know the pandas and the data science

00:38:53,510 --> 00:38:59,079
stack and just running everything

00:38:54,980 --> 00:38:59,079
through that and that works very well

00:39:00,700 --> 00:39:05,809
another blender question I assume you're

00:39:04,130 --> 00:39:07,190
sending to blender instances and you're

00:39:05,809 --> 00:39:09,140
rendering and cycles is that what you're

00:39:07,190 --> 00:39:11,930
doing you said you were dispatching from

00:39:09,140 --> 00:39:13,970
blender I know some of the studios I

00:39:11,930 --> 00:39:15,619
work with we randomly get black frames

00:39:13,970 --> 00:39:16,790
I think somebody wrote a script at one

00:39:15,619 --> 00:39:18,860
of the studios to detect the black

00:39:16,790 --> 00:39:20,300
frames is there any management of bad

00:39:18,860 --> 00:39:21,980
frames it all built into the system

00:39:20,300 --> 00:39:23,840
where it automatically does a turd we

00:39:21,980 --> 00:39:25,340
have to rely upon Python scripts and

00:39:23,840 --> 00:39:26,420
stuff like that yeah I don't think

00:39:25,340 --> 00:39:29,150
there's anything like that built in

00:39:26,420 --> 00:39:30,980
right now yeah I would be a though there

00:39:29,150 --> 00:39:34,880
is you know the when you're submitting

00:39:30,980 --> 00:39:36,350
jobs you can basically break your job as

00:39:34,880 --> 00:39:37,940
many different stages as you want so you

00:39:36,350 --> 00:39:39,950
can have a job structure that does like

00:39:37,940 --> 00:39:41,780
preflight main render or some sort of

00:39:39,950 --> 00:39:43,130
post process so that's probably what

00:39:41,780 --> 00:39:44,660
you'd want to do is have a post process

00:39:43,130 --> 00:39:46,550
that that doesn't check for bad frames

00:39:44,660 --> 00:39:50,450
and you can then call into the Python

00:39:46,550 --> 00:39:55,760
API to either submit a new job or or req

00:39:50,450 --> 00:39:57,710
certain frames so this is a kind of

00:39:55,760 --> 00:39:59,450
multi-tiered and it might be just say

00:39:57,710 --> 00:40:01,130
the answer might be just hey it's just

00:39:59,450 --> 00:40:03,470
how you configure it but um so for

00:40:01,130 --> 00:40:06,260
example you have software that sometimes

00:40:03,470 --> 00:40:08,360
it's licensed per user per machine so if

00:40:06,260 --> 00:40:10,730
you're running you you want to benefit

00:40:08,360 --> 00:40:11,810
from being able to use one license per

00:40:10,730 --> 00:40:16,610
machine even though you have it broken

00:40:11,810 --> 00:40:18,980
up into multiple instances but then also

00:40:16,610 --> 00:40:21,020
if you remove the user from it then you

00:40:18,980 --> 00:40:23,990
don't know who's doing the actual job so

00:40:21,020 --> 00:40:31,880
can you talk a little bit about how you

00:40:23,990 --> 00:40:34,010
guys configure those kind of things and

00:40:31,880 --> 00:40:36,110
then also sorry also permissions on the

00:40:34,010 --> 00:40:37,900
files at the end is that all client code

00:40:36,110 --> 00:40:40,580
or do you have any mechanism around that

00:40:37,900 --> 00:40:42,500
yeah so for the permissions on the files

00:40:40,580 --> 00:40:44,270
there's not

00:40:42,500 --> 00:40:47,480
I think there's any management of that

00:40:44,270 --> 00:40:50,180
right now it does be so rqd will run as

00:40:47,480 --> 00:40:52,040
the will run as the user that submitted

00:40:50,180 --> 00:40:54,080
the job right yes I'm users model works

00:40:52,040 --> 00:40:57,620
so when it writes it out it'll be owned

00:40:54,080 --> 00:40:59,450
by the that user okay so you would have

00:40:57,620 --> 00:41:01,310
the problem with a software that is

00:40:59,450 --> 00:41:02,650
license per user that you'd be pulling

00:41:01,310 --> 00:41:05,480
multiple license for a single machine

00:41:02,650 --> 00:41:08,930
okay and there's no way to manipulate

00:41:05,480 --> 00:41:10,550
that in the system to modify it going in

00:41:08,930 --> 00:41:14,390
and out of the system I

00:41:10,550 --> 00:41:16,850
so it's either one way or the other

00:41:14,390 --> 00:41:18,500
right now so basically you could

00:41:16,850 --> 00:41:21,710
configure all your jobs to run as a

00:41:18,500 --> 00:41:23,390
single user a generic morning but you

00:41:21,710 --> 00:41:25,880
can't do that on like a per job level

00:41:23,390 --> 00:41:28,460
okay and there's no way going in and out

00:41:25,880 --> 00:41:30,970
like to reassign it and then going back

00:41:28,460 --> 00:41:34,329
out not at the

00:41:30,970 --> 00:41:48,760
like open cue level yeah so are ya just

00:41:34,329 --> 00:41:51,190
it was more curiosity mmm thanks thanks

00:41:48,760 --> 00:41:52,539
I wanted if you can from a like a render

00:41:51,190 --> 00:41:54,930
Wrangler perspective if you could talk

00:41:52,539 --> 00:41:58,359
about what tools you make available for

00:41:54,930 --> 00:42:02,200
job variation or exception or error

00:41:58,359 --> 00:42:03,910
handling what what sort of mechanisms do

00:42:02,200 --> 00:42:08,859
you provide for either scripts to do

00:42:03,910 --> 00:42:10,329
that or sort of automatic detection yeah

00:42:08,859 --> 00:42:13,150
so we do have kind of two in the GUI

00:42:10,329 --> 00:42:14,980
there are two different sections really

00:42:13,150 --> 00:42:16,270
there is a kind of artist view and then

00:42:14,980 --> 00:42:18,400
there's a Wrangler view as well and this

00:42:16,270 --> 00:42:20,140
is kind of pre-configured with a bunch

00:42:18,400 --> 00:42:22,059
of different tools that help make it

00:42:20,140 --> 00:42:23,380
easy to kind of drill down into

00:42:22,059 --> 00:42:26,799
different parts of the farm see what's

00:42:23,380 --> 00:42:29,079
happening where see you know quickly see

00:42:26,799 --> 00:42:31,329
what kind of frames might be bad or

00:42:29,079 --> 00:42:33,069
taking too much resources kind of stuff

00:42:31,329 --> 00:42:37,510
so there are that is kind of built into

00:42:33,069 --> 00:42:39,670
the GUI right now the GUI also is has a

00:42:37,510 --> 00:42:42,250
very kind of extensible plug-in system

00:42:39,670 --> 00:42:44,049
so like each panel in the GUI is

00:42:42,250 --> 00:42:46,420
technically a plug-in that's that's

00:42:44,049 --> 00:42:48,940
being run and it's a pretty simple

00:42:46,420 --> 00:42:50,319
process to basically script up new new

00:42:48,940 --> 00:42:51,849
panels and that as well so there's

00:42:50,319 --> 00:42:54,279
something specific you'd like to see

00:42:51,849 --> 00:42:56,410
then you know it's a few lines of code

00:42:54,279 --> 00:43:01,510
and you can add a panel to the GUI to

00:42:56,410 --> 00:43:03,490
see that sort of thing hi I should like

00:43:01,510 --> 00:43:05,349
to ask about the submission API or the

00:43:03,490 --> 00:43:07,299
job descriptions it seems to me that

00:43:05,349 --> 00:43:10,450
with a project like this there's either

00:43:07,299 --> 00:43:12,339
going to happen by accident or

00:43:10,450 --> 00:43:14,920
intentionally a common Job Description

00:43:12,339 --> 00:43:16,839
format for people to submit render jobs

00:43:14,920 --> 00:43:19,210
can you talk about the submission API

00:43:16,839 --> 00:43:23,319
how high or low level you're choosing to

00:43:19,210 --> 00:43:25,510
place that yeah so there is so in terms

00:43:23,319 --> 00:43:27,730
of like the job description itself there

00:43:25,510 --> 00:43:29,950
are a few different layers at at its

00:43:27,730 --> 00:43:32,500
base it does use a kind of XML

00:43:29,950 --> 00:43:34,210
description you don't really have to

00:43:32,500 --> 00:43:36,369
work with that directly we do have a

00:43:34,210 --> 00:43:38,589
whole Python layer so it's basically

00:43:36,369 --> 00:43:41,079
you're basically constructing Python

00:43:38,589 --> 00:43:43,020
classes that represent pieces of the job

00:43:41,079 --> 00:43:44,520
and then the

00:43:43,020 --> 00:43:56,760
the system basically handles baking that

00:43:44,520 --> 00:43:59,040
out into his XML later looking how high

00:43:56,760 --> 00:44:01,290
or low level are those sort of pieces

00:43:59,040 --> 00:44:03,060
then are you are you talking run this

00:44:01,290 --> 00:44:05,700
command or are you talking do this

00:44:03,060 --> 00:44:08,970
render against the script or do the

00:44:05,700 --> 00:44:11,400
series of frames or right right so it's

00:44:08,970 --> 00:44:13,770
basically run this commands it it passes

00:44:11,400 --> 00:44:15,060
in a full a full commands with and there

00:44:13,770 --> 00:44:16,440
are a few different placeholders that

00:44:15,060 --> 00:44:19,530
you could put in that command like frame

00:44:16,440 --> 00:44:22,470
number for example is the big one but

00:44:19,530 --> 00:44:23,730
yeah there's really no there's really no

00:44:22,470 --> 00:44:24,960
translation that's happening on the

00:44:23,730 --> 00:44:27,180
server side for that it all gets

00:44:24,960 --> 00:44:28,910
constructed client-side and that those

00:44:27,180 --> 00:44:31,620
commands get pretty get passed through a

00:44:28,910 --> 00:44:34,320
you know almost exactly to the to the

00:44:31,620 --> 00:44:35,730
render nodes so that the the kind of

00:44:34,320 --> 00:44:37,440
nice thing about that is there's you

00:44:35,730 --> 00:44:39,180
know you don't really have to wait for

00:44:37,440 --> 00:44:41,820
open queue to support any specific

00:44:39,180 --> 00:44:43,410
software you can just you know construct

00:44:41,820 --> 00:44:44,970
the the Job Description with the command

00:44:43,410 --> 00:44:47,430
that you want to run whatever that is

00:44:44,970 --> 00:44:49,350
you know you can do file are copying or

00:44:47,430 --> 00:44:52,610
just whatever bash commands that are

00:44:49,350 --> 00:44:52,610
available on the on those machines

00:45:00,160 --> 00:45:04,850
right so we do have some kind of higher

00:45:02,960 --> 00:45:06,290
level like kind of abstraction layers

00:45:04,850 --> 00:45:09,410
for that in our it's called the PI

00:45:06,290 --> 00:45:11,210
outline library which lets you is that

00:45:09,410 --> 00:45:13,570
Python abstraction layer so you can kind

00:45:11,210 --> 00:45:15,710
of work at a higher level in Python but

00:45:13,570 --> 00:45:18,470
yeah that's not not strictly necessary

00:45:15,710 --> 00:45:20,930
hi I had a question about user

00:45:18,470 --> 00:45:24,550
interaction with the database and with

00:45:20,930 --> 00:45:28,220
the queue bots is there any kind of

00:45:24,550 --> 00:45:29,720
concern about users interacting with the

00:45:28,220 --> 00:45:32,119
queue bots to get information about

00:45:29,720 --> 00:45:34,310
their jobs while the queue bots are

00:45:32,119 --> 00:45:35,930
still trying to schedule like I've seen

00:45:34,310 --> 00:45:38,600
other queueing systems that will mirror

00:45:35,930 --> 00:45:39,800
that database or maybe you spin up a

00:45:38,600 --> 00:45:43,670
separate queue bought for their

00:45:39,800 --> 00:45:44,720
interaction right so that is one of the

00:45:43,670 --> 00:45:46,520
nice things about being able to have

00:45:44,720 --> 00:45:48,770
multiple multiple qubits is you can kind

00:45:46,520 --> 00:45:51,170
of as as load increases you can kind of

00:45:48,770 --> 00:45:54,140
spin up more to deal with that because

00:45:51,170 --> 00:45:56,240
the scheduling runs mostly separate from

00:45:54,140 --> 00:45:58,490
the actual like API serving we haven't

00:45:56,240 --> 00:46:00,890
really seen any any problems with like

00:45:58,490 --> 00:46:04,340
API load slowing down scheduling as long

00:46:00,890 --> 00:46:07,100
as it's more about API load competing

00:46:04,340 --> 00:46:09,410
with other API calls but spending up

00:46:07,100 --> 00:46:10,880
more key BOTS can alleviate that and one

00:46:09,410 --> 00:46:15,380
of the nice one of the kind of benefits

00:46:10,880 --> 00:46:16,820
of is migrating to in-memory scheduling

00:46:15,380 --> 00:46:18,140
is then we could have one queue bought

00:46:16,820 --> 00:46:19,220
that basically is dedicated to

00:46:18,140 --> 00:46:21,290
scheduling and others that are dedicated

00:46:19,220 --> 00:46:24,260
to API and I'm going to make sure that

00:46:21,290 --> 00:46:26,090
there's no conflict there I think you

00:46:24,260 --> 00:46:27,740
mentioned license management being a

00:46:26,090 --> 00:46:29,510
future thing but I just don't know if

00:46:27,740 --> 00:46:32,359
there's any mechanisms or any thoughts

00:46:29,510 --> 00:46:34,820
about how to maximize license usage for

00:46:32,359 --> 00:46:36,770
things that are like per node so for

00:46:34,820 --> 00:46:38,030
example you know you pay one license per

00:46:36,770 --> 00:46:40,340
node and then you want to be in all

00:46:38,030 --> 00:46:42,770
those jobs from that kind in that node

00:46:40,340 --> 00:46:44,660
but we felt really micromanaging it

00:46:42,770 --> 00:46:45,980
which you know to have the licenses so

00:46:44,660 --> 00:46:48,950
just want to enforce anything there or

00:46:45,980 --> 00:46:51,680
any thoughts yeah I don't I don't think

00:46:48,950 --> 00:46:54,500
we do licensing right now is that

00:46:51,680 --> 00:46:59,030
correct because of this kind of

00:46:54,500 --> 00:47:01,160
scheduling problems like right now our

00:46:59,030 --> 00:47:04,700
QD isn't registering like what licenses

00:47:01,160 --> 00:47:06,260
are available automatically based on you

00:47:04,700 --> 00:47:08,330
know being able to collect information

00:47:06,260 --> 00:47:09,660
from the node it would have to be

00:47:08,330 --> 00:47:12,180
configured

00:47:09,660 --> 00:47:16,490
by the user for that individual node and

00:47:12,180 --> 00:47:23,430
basically that node added to a pool for

00:47:16,490 --> 00:47:25,140
license consumption so the GUI for the

00:47:23,430 --> 00:47:27,180
interface is all written in PI site if I

00:47:25,140 --> 00:47:28,590
remember correctly yeah that's right

00:47:27,180 --> 00:47:30,630
I'm just curious when you have like a

00:47:28,590 --> 00:47:33,000
hundred thousand nodes updating that

00:47:30,630 --> 00:47:35,280
table is that how slow does that get

00:47:33,000 --> 00:47:37,230
because usually people go to C++ for

00:47:35,280 --> 00:47:40,830
that instead of you relying on Python

00:47:37,230 --> 00:47:42,810
right yeah so it is the GUI right now

00:47:40,830 --> 00:47:44,490
was not really designed to view like the

00:47:42,810 --> 00:47:46,380
entire list at once in fact it doesn't

00:47:44,490 --> 00:47:48,030
even load the load the full list when

00:47:46,380 --> 00:47:50,070
you post so you just don't do that in

00:47:48,030 --> 00:47:53,280
the first day and there's a so there's

00:47:50,070 --> 00:47:54,900
basically a search field so you so you

00:47:53,280 --> 00:47:56,310
can basically search for whatever nodes

00:47:54,900 --> 00:47:58,830
that you're looking for and you can just

00:47:56,310 --> 00:48:00,240
put up put a star there and just let and

00:47:58,830 --> 00:48:02,460
see the full list or you can kind of

00:48:00,240 --> 00:48:05,160
drill down and there are cut there are a

00:48:02,460 --> 00:48:06,540
few different panels for for viewing for

00:48:05,160 --> 00:48:09,750
viewing the full farm structure as well

00:48:06,540 --> 00:48:10,890
so you know there's a like there's one

00:48:09,750 --> 00:48:12,270
tree view where you can see the

00:48:10,890 --> 00:48:14,430
breakdown per facility and then

00:48:12,270 --> 00:48:15,900
allocation you can you know view the

00:48:14,430 --> 00:48:17,220
full list for whatever bucket of nodes

00:48:15,900 --> 00:48:21,060
that you're looking for at the time as

00:48:17,220 --> 00:48:23,490
well so and so you mentioned Python API

00:48:21,060 --> 00:48:27,270
to communicate over the system is there

00:48:23,490 --> 00:48:29,070
any event-driven API like you will get

00:48:27,270 --> 00:48:30,560
notified when the job complete or here

00:48:29,070 --> 00:48:32,490
or something you could subscribe to

00:48:30,560 --> 00:48:34,680
another at the moment but that's coming

00:48:32,490 --> 00:48:41,310
very soon that's in development right

00:48:34,680 --> 00:48:43,440
now sorry another question as far as

00:48:41,310 --> 00:48:45,390
matrix goals we went to a lot of talks

00:48:43,440 --> 00:48:47,520
yesterday that people are talking about

00:48:45,390 --> 00:48:49,650
matrix pipeline matrix and whatnot and

00:48:47,520 --> 00:48:52,980
with Google having some machine learning

00:48:49,650 --> 00:48:54,930
frameworks I wonder if it any thought

00:48:52,980 --> 00:48:59,340
being put there like what matrix does

00:48:54,930 --> 00:49:04,740
open queue currently retrieve and you

00:48:59,340 --> 00:49:06,510
know there's fun stuff yeah I mean we've

00:49:04,740 --> 00:49:08,930
we've been to a lot of those talks as

00:49:06,510 --> 00:49:12,150
well and we're definitely attend shinto

00:49:08,930 --> 00:49:13,770
what folks are asking for you know it's

00:49:12,150 --> 00:49:14,850
the kind of metrics collection right now

00:49:13,770 --> 00:49:17,610
is pretty basic

00:49:14,850 --> 00:49:19,110
as it stands but we you know we kind of

00:49:17,610 --> 00:49:19,820
understand how important that stuff is

00:49:19,110 --> 00:49:20,870
and yeah

00:49:19,820 --> 00:49:25,160
we definitely we definitely wanna do

00:49:20,870 --> 00:49:27,740
more with that in the future so question

00:49:25,160 --> 00:49:31,190
about composing the submissions itself

00:49:27,740 --> 00:49:33,200
like is there is there any plan to build

00:49:31,190 --> 00:49:35,060
a GUI or something where and I can

00:49:33,200 --> 00:49:36,680
compose the submission graph and then

00:49:35,060 --> 00:49:38,570
submit it to the open queue or do you

00:49:36,680 --> 00:49:40,610
want to leave that to the this is the

00:49:38,570 --> 00:49:43,550
application itself to compose using the

00:49:40,610 --> 00:49:45,860
Python API the court is right so we do

00:49:43,550 --> 00:49:48,260
have a an application right now it's

00:49:45,860 --> 00:49:50,000
called queue submit it's part of in the

00:49:48,260 --> 00:49:53,090
main repo just kind of what you're

00:49:50,000 --> 00:49:55,580
looking for you can you know basically

00:49:53,090 --> 00:49:57,140
add add various layers to your jobs you

00:49:55,580 --> 00:49:59,390
can build up some you know kind of

00:49:57,140 --> 00:50:01,130
linear job structure of maybe pre fly it

00:49:59,390 --> 00:50:03,440
and render and comp kind of thing it

00:50:01,130 --> 00:50:06,350
doesn't right now it doesn't do the full

00:50:03,440 --> 00:50:08,540
like the full complex tree structure

00:50:06,350 --> 00:50:09,680
that you're talking about but we're

00:50:08,540 --> 00:50:11,180
definitely will definitely looking at

00:50:09,680 --> 00:50:14,770
like expanding and building on that tool

00:50:11,180 --> 00:50:14,770
in the future for for doing that so

00:50:39,349 --> 00:50:44,040
do you want to build a complex workflow

00:50:41,790 --> 00:50:45,869
Verena like you take the inputs and spit

00:50:44,040 --> 00:50:47,280
the outputs from one DCC application

00:50:45,869 --> 00:50:48,660
into the another one and you want to see

00:50:47,280 --> 00:50:51,900
everything in a single submission graph

00:50:48,660 --> 00:50:54,859
it depends on that so yeah as you

00:50:51,900 --> 00:50:58,170
rightly said it is it can be studio

00:50:54,859 --> 00:51:00,540
specific but I can see general patterns

00:50:58,170 --> 00:51:02,520
for like the workflows because like all

00:51:00,540 --> 00:51:05,810
the studios try to do the same kind of

00:51:02,520 --> 00:51:05,810
workflow sets at some point

00:51:18,700 --> 00:51:23,809
yeah basically having her having our Job

00:51:21,650 --> 00:51:24,980
Description come with a lot of having

00:51:23,809 --> 00:51:26,599
pie outline come with a lot of different

00:51:24,980 --> 00:51:27,710
examples for how to get started but that

00:51:26,599 --> 00:51:31,460
kind of thing

00:51:27,710 --> 00:51:34,180
is there a language agnostic API like a

00:51:31,460 --> 00:51:37,160
restful endpoints for interrogating jobs

00:51:34,180 --> 00:51:39,530
yes so at all so we don't have a REST

00:51:37,160 --> 00:51:40,970
API yet that's kind of planned for the

00:51:39,530 --> 00:51:44,690
future right now it's all going through

00:51:40,970 --> 00:51:47,150
G RPC so the the Python API is calling

00:51:44,690 --> 00:51:48,799
those G RPC endpoints so yeah there's no

00:51:47,150 --> 00:51:53,059
there's no reason that needs to be

00:51:48,799 --> 00:51:55,089
Python specific exactly yeah you can

00:51:53,059 --> 00:51:58,339
call Jay RPC directly there's also the

00:51:55,089 --> 00:51:59,809
you know be the proto files that that

00:51:58,339 --> 00:52:01,369
get used for that communication are

00:51:59,809 --> 00:52:02,690
published along with alongside with the

00:52:01,369 --> 00:52:03,920
code so that could get compiled into

00:52:02,690 --> 00:52:07,190
whatever whatever language you're using

00:52:03,920 --> 00:52:09,430
i guess i'm for maybe one more one or

00:52:07,190 --> 00:52:11,299
two more

00:52:09,430 --> 00:52:13,280
all right thanks

00:52:11,299 --> 00:52:16,640
is there anything in built where you can

00:52:13,280 --> 00:52:18,290
tell a job at a submission time to kill

00:52:16,640 --> 00:52:21,140
itself after a certain amount of time or

00:52:18,290 --> 00:52:22,490
to retry is that built in or is that

00:52:21,140 --> 00:52:25,480
something that's going to be deferred to

00:52:22,490 --> 00:52:27,829
some kind of monitoring that's external

00:52:25,480 --> 00:52:31,700
let's see so we do have the we do have

00:52:27,829 --> 00:52:33,890
auto retry built in configurable in

00:52:31,700 --> 00:52:34,970
terms of killing itself after certain

00:52:33,890 --> 00:52:39,849
out of time that's not that's not

00:52:34,970 --> 00:52:42,380
something I've seen I think so right now

00:52:39,849 --> 00:52:43,970
I'm just getting back to the render

00:52:42,380 --> 00:52:46,490
wrangling aspect of things do you guys

00:52:43,970 --> 00:52:48,410
have live log streaming with regular

00:52:46,490 --> 00:52:51,200
expression analysis of it to be able to

00:52:48,410 --> 00:52:53,809
do customer warnings or errors for

00:52:51,200 --> 00:52:55,940
example yeah so we have so one of the

00:52:53,809 --> 00:52:57,950
panels in the GUI will will stream the

00:52:55,940 --> 00:53:01,549
log file of the of the task that you

00:52:57,950 --> 00:53:03,020
have selected and you could do you can

00:53:01,549 --> 00:53:04,490
do search within that there's a search

00:53:03,020 --> 00:53:07,839
field within that panel I don't know

00:53:04,490 --> 00:53:09,710
exactly how complex the like regex

00:53:07,839 --> 00:53:12,549
expressions that can handle our over

00:53:09,710 --> 00:53:14,599
it's just doing a kind of basic search

00:53:12,549 --> 00:53:16,250
but that's the kind of thing we would

00:53:14,599 --> 00:53:18,859
build out in the future yeah in terms of

00:53:16,250 --> 00:53:20,299
like automatic alerting based on what's

00:53:18,859 --> 00:53:25,480
coming from that log nothing like that

00:53:20,299 --> 00:53:27,650
right now yeah that would be a probably

00:53:25,480 --> 00:53:30,050
configured

00:53:27,650 --> 00:53:31,820
your job description kind of have a

00:53:30,050 --> 00:53:35,630
separate process that runs and watches

00:53:31,820 --> 00:53:37,490
watches log files so in the event like a

00:53:35,630 --> 00:53:39,320
network partition where your where your

00:53:37,490 --> 00:53:41,870
render nodes no longer can communicate

00:53:39,320 --> 00:53:44,330
with your with your server what what is

00:53:41,870 --> 00:53:46,430
is there any particular behavior that if

00:53:44,330 --> 00:53:48,260
there is there like a heartbeat do they

00:53:46,430 --> 00:53:52,040
do they shutdown or do they just keep

00:53:48,260 --> 00:53:54,380
rendering happily yeah so if they if

00:53:52,040 --> 00:53:57,970
they lose connection to the server there

00:53:54,380 --> 00:54:00,230
is a regular heartbeat that happens the

00:53:57,970 --> 00:54:01,580
not sure exactly what the behavior on

00:54:00,230 --> 00:54:03,380
the on the render node side is on the

00:54:01,580 --> 00:54:04,910
server side those nodes will drop

00:54:03,380 --> 00:54:07,940
they'll be flagged and then removed from

00:54:04,910 --> 00:54:09,230
the pool after I don't know 30 seconds

00:54:07,940 --> 00:54:11,960
or minute or something like that after

00:54:09,230 --> 00:54:13,490
it misses a few heartbeats in terms of

00:54:11,960 --> 00:54:16,220
how the how the actual render node

00:54:13,490 --> 00:54:17,900
handles that I I believe it'll kind of

00:54:16,220 --> 00:54:20,060
just keep keep going until it finishes

00:54:17,900 --> 00:54:21,920
its current task and then it'll they

00:54:20,060 --> 00:54:23,630
won't receive any new reports from the

00:54:21,920 --> 00:54:32,000
queue bot so I'll just stop at that

00:54:23,630 --> 00:54:34,400
point yes yeah if the heartbeat picks

00:54:32,000 --> 00:54:35,690
back up it'll be added back in yeah this

00:54:34,400 --> 00:54:37,370
kind of yeah this kind of happens a lot

00:54:35,690 --> 00:54:38,990
in a especially in a cloud environment

00:54:37,370 --> 00:54:40,190
we have preemptable is coming and going

00:54:38,990 --> 00:54:43,310
and then they share the same name or

00:54:40,190 --> 00:54:48,110
same IP address that this will get

00:54:43,310 --> 00:54:50,120
handled fine yeah I have a question so

00:54:48,110 --> 00:54:53,030
is there a mechanism to add in a pre

00:54:50,120 --> 00:54:55,010
process and post process mechanism into

00:54:53,030 --> 00:54:56,990
it or are we responsible for adding that

00:54:55,010 --> 00:54:58,670
into our own scripts so you'd configure

00:54:56,990 --> 00:55:00,860
that as part of as another layer in your

00:54:58,670 --> 00:55:01,970
job basically because it's all using you

00:55:00,860 --> 00:55:04,070
know because it has this kind of

00:55:01,970 --> 00:55:06,020
low-level just build a command and pass

00:55:04,070 --> 00:55:07,820
it to the render node there's not much

00:55:06,020 --> 00:55:09,530
difference between a render itself and a

00:55:07,820 --> 00:55:11,840
pre or post process so you would just

00:55:09,530 --> 00:55:13,960
kind of add that as a other layer thank

00:55:11,840 --> 00:55:13,960
you

00:55:33,549 --> 00:55:38,150
yes yeah it is

00:55:35,630 --> 00:55:39,799
so you can yeah oh just we yeah we're

00:55:38,150 --> 00:55:42,859
being told me we need to wrap it up so

00:55:39,799 --> 00:55:44,660
but we'll all be around so anyone with

00:55:42,859 --> 00:55:47,599
any more questions definitely a more

00:55:44,660 --> 00:55:48,859
technical side feel free to oh yeah and

00:55:47,599 --> 00:55:50,450
our teeth we have our TSC meeting

00:55:48,859 --> 00:55:52,339
tomorrow if folks want to show up to

00:55:50,450 --> 00:55:57,079
that but it's supposed to posted on our

00:55:52,339 --> 00:55:59,299
on our website on open q dot io CSC is

00:55:57,079 --> 00:56:02,480
in room in room 3 tomorrow from 10:00 to

00:55:59,299 --> 00:56:06,580
11:00 olympic room three ten to eleven

00:56:02,480 --> 00:56:09,380
thanks Emily thanks everyone

00:56:06,580 --> 00:56:09,380

YouTube URL: https://www.youtube.com/watch?v=0gXT3sntiFg


