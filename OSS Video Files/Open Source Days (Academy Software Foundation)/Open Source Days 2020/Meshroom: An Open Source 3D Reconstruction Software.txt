Title: Meshroom: An Open Source 3D Reconstruction Software
Publication date: 2020-08-24
Playlist: Open Source Days 2020
Description: 
	Meshroom: An Open Source 3D Reconstruction Software
Speakers: Fabien Castan, Benoit Maujean

For more information about the Academy Software Foundation go to: https://www.aswf.io/

We will invite users to discuss AliceVision, an open source Photogrammetric Computer Vision framework and Meshroom, that allow artists and scientists to customize 3D reconstruction and camera tracking pipelines.
We will be sharing with the community the latest evolutions of Meshroom: the improvements of the 3D reconstruction and the UI as well as the new HDRI pipeline.
alicevision.org
Captions: 
	00:00:00,320 --> 00:00:06,480
okay let's start yes hi everyone

00:00:04,080 --> 00:00:08,080
thank you for joining us at this

00:00:06,480 --> 00:00:11,519
mushroom analysis vision

00:00:08,080 --> 00:00:13,679
session at the open source days 2020.

00:00:11,519 --> 00:00:16,320
uh first of all first we would like to

00:00:13,679 --> 00:00:19,600
thank the academy software foundation

00:00:16,320 --> 00:00:22,240
for having inviting us to these panels

00:00:19,600 --> 00:00:24,160
of prestigious open source software

00:00:22,240 --> 00:00:27,039
so i'm bernard mojon and i'm here with

00:00:24,160 --> 00:00:29,840
uh fabian custom

00:00:27,039 --> 00:00:31,039
so uh to uh to give you a little bit of

00:00:29,840 --> 00:00:34,399
context

00:00:31,039 --> 00:00:34,960
uh then oh yeah the agenda of the the

00:00:34,399 --> 00:00:37,040
session

00:00:34,960 --> 00:00:38,640
so we'll start with an overview of

00:00:37,040 --> 00:00:40,800
mushroom analysis vision

00:00:38,640 --> 00:00:41,920
then we'll go to uh the recent evolution

00:00:40,800 --> 00:00:45,200
of mushrooms

00:00:41,920 --> 00:00:48,079
regarding the next release

00:00:45,200 --> 00:00:48,800
we'll go through also the next steps to

00:00:48,079 --> 00:00:50,960
come

00:00:48,800 --> 00:00:52,079
we figure out and then we'll talk a

00:00:50,960 --> 00:00:54,239
little bit about

00:00:52,079 --> 00:00:55,840
our community and then we'll switch to

00:00:54,239 --> 00:00:57,920
the q a

00:00:55,840 --> 00:00:59,440
that you can do with the zoom

00:00:57,920 --> 00:01:02,719
application

00:00:59,440 --> 00:01:05,920
so uh as a start uh so we

00:01:02,719 --> 00:01:09,840
fabian and i are working at microsimage

00:01:05,920 --> 00:01:11,680
so micros is a vfx studio an animation

00:01:09,840 --> 00:01:14,799
studio

00:01:11,680 --> 00:01:17,759
we are part of the technicolor group and

00:01:14,799 --> 00:01:18,880
mikros is positioned across the three

00:01:17,759 --> 00:01:21,520
service lines of

00:01:18,880 --> 00:01:23,280
the production services of technicolor

00:01:21,520 --> 00:01:25,119
on the left hand side you can see that

00:01:23,280 --> 00:01:26,479
we are positioned on the advertisement

00:01:25,119 --> 00:01:28,479
service slide under the brand name

00:01:26,479 --> 00:01:30,320
because npc advertising

00:01:28,479 --> 00:01:33,280
in the middle you can see that we are

00:01:30,320 --> 00:01:36,079
positioned also on the visual effects

00:01:33,280 --> 00:01:37,759
industry for films and on the right hand

00:01:36,079 --> 00:01:39,520
side you can see that we are positioned

00:01:37,759 --> 00:01:41,119
on the animation

00:01:39,520 --> 00:01:43,040
service line for feature feeds and

00:01:41,119 --> 00:01:45,759
cereals

00:01:43,040 --> 00:01:46,960
so we are located in paris but we also

00:01:45,759 --> 00:01:50,000
have premises

00:01:46,960 --> 00:01:50,720
in belgium in brussels and liege and in

00:01:50,000 --> 00:01:54,159
canada

00:01:50,720 --> 00:01:55,920
in montreal and we have some facilities

00:01:54,159 --> 00:01:58,799
with our friends of technicolor in

00:01:55,920 --> 00:02:01,600
london and in india too

00:01:58,799 --> 00:02:03,680
so to illustrate this uh we're gonna

00:02:01,600 --> 00:02:09,840
show you our demo reel

00:02:03,680 --> 00:02:09,840
on this screen

00:02:14,860 --> 00:02:18,089
[Music]

00:03:08,890 --> 00:03:13,589
[Music]

00:03:16,240 --> 00:03:19,800
[Music]

00:03:48,560 --> 00:03:51,599
so that that that was to give you a bit

00:03:50,319 --> 00:03:53,680
of context of

00:03:51,599 --> 00:03:54,879
the project within microsimage and now

00:03:53,680 --> 00:03:57,120
we're gonna have uh

00:03:54,879 --> 00:03:57,920
an overview of mushroom analysis vision

00:03:57,120 --> 00:03:59,519
so

00:03:57,920 --> 00:04:01,360
uh what are the motivations of the

00:03:59,519 --> 00:04:03,599
project uh

00:04:01,360 --> 00:04:04,799
the the motivation was to improve inside

00:04:03,599 --> 00:04:07,840
the productivity on

00:04:04,799 --> 00:04:10,799
3d assets creation

00:04:07,840 --> 00:04:11,920
for visual effects so that concerns the

00:04:10,799 --> 00:04:14,480
real world objects

00:04:11,920 --> 00:04:15,519
that need to be changed by visual

00:04:14,480 --> 00:04:17,440
effects

00:04:15,519 --> 00:04:19,120
it also deals with shooting set

00:04:17,440 --> 00:04:21,840
extensions or it could

00:04:19,120 --> 00:04:25,840
also deal with a set survey that serves

00:04:21,840 --> 00:04:27,919
as a reference for the camera tracking

00:04:25,840 --> 00:04:29,040
so in fact we can see that

00:04:27,919 --> 00:04:30,800
photogrammetry is

00:04:29,040 --> 00:04:32,720
the kind of root of all the visual

00:04:30,800 --> 00:04:36,240
effects uh to achieve

00:04:32,720 --> 00:04:39,600
this kind of uh of uh photorealistic

00:04:36,240 --> 00:04:42,720
matching between the real world and um

00:04:39,600 --> 00:04:45,199
the computer graphic worlds so you have

00:04:42,720 --> 00:04:48,160
these examples for the different

00:04:45,199 --> 00:04:51,440
activities we have at micros

00:04:48,160 --> 00:04:53,919
so what is the main concept of mushroom

00:04:51,440 --> 00:04:54,880
so meshu is the front-end application

00:04:53,919 --> 00:04:57,120
and

00:04:54,880 --> 00:04:59,759
as a reminder this is a photography

00:04:57,120 --> 00:05:02,880
pipeline which is made basically of uh

00:04:59,759 --> 00:05:05,840
three steps the first steps concern the

00:05:02,880 --> 00:05:07,759
analysis of the input images

00:05:05,840 --> 00:05:10,160
and then the second step is uh

00:05:07,759 --> 00:05:13,360
destination of the cameras

00:05:10,160 --> 00:05:13,919
that provides a sparse phone cloud with

00:05:13,360 --> 00:05:16,080
the

00:05:13,919 --> 00:05:18,160
intrinsic parameters of the camera and

00:05:16,080 --> 00:05:20,080
the camera positioning

00:05:18,160 --> 00:05:21,199
and the third step is a dense phone

00:05:20,080 --> 00:05:23,759
cloud with

00:05:21,199 --> 00:05:24,560
the estimation of the object surfaces

00:05:23,759 --> 00:05:27,120
and

00:05:24,560 --> 00:05:28,160
the result is a match which is textured

00:05:27,120 --> 00:05:30,320
by the

00:05:28,160 --> 00:05:31,440
the input images so this is the

00:05:30,320 --> 00:05:33,120
classical

00:05:31,440 --> 00:05:35,840
three steps of the photogrammetry

00:05:33,120 --> 00:05:38,880
pipeline so mushroom again is the

00:05:35,840 --> 00:05:41,440
is the front-end application

00:05:38,880 --> 00:05:44,080
the user interface is made of two parts

00:05:41,440 --> 00:05:46,639
the high-level ui

00:05:44,080 --> 00:05:47,280
is what is used for the automatic

00:05:46,639 --> 00:05:49,680
process

00:05:47,280 --> 00:05:51,039
the the end user the computer graphic

00:05:49,680 --> 00:05:52,720
artist can drop

00:05:51,039 --> 00:05:54,960
drag and drop the images on the on the

00:05:52,720 --> 00:05:57,919
left hand side and then

00:05:54,960 --> 00:06:00,000
launch and submit the the process of the

00:05:57,919 --> 00:06:02,319
3d reconstruction

00:06:00,000 --> 00:06:03,680
and on the lower end of the graphic the

00:06:02,319 --> 00:06:06,560
user interface

00:06:03,680 --> 00:06:07,680
you have the nodal pipeline for expert

00:06:06,560 --> 00:06:10,800
users where you can

00:06:07,680 --> 00:06:13,020
tweak your parameters or you can play

00:06:10,800 --> 00:06:14,160
around with your nodes you can

00:06:13,020 --> 00:06:16,960
[Music]

00:06:14,160 --> 00:06:18,479
customize your pipeline and so on we we

00:06:16,960 --> 00:06:22,560
give you some details on that

00:06:18,479 --> 00:06:23,440
later on so what are the key points of

00:06:22,560 --> 00:06:25,919
meshroom

00:06:23,440 --> 00:06:28,880
so as i said there is a default workflow

00:06:25,919 --> 00:06:32,080
for all the standard use case

00:06:28,880 --> 00:06:32,960
but meshum is not a black box so it's a

00:06:32,080 --> 00:06:36,400
it's a

00:06:32,960 --> 00:06:38,639
nodal editor where you can uh

00:06:36,400 --> 00:06:40,639
tweak the different nodes and also you

00:06:38,639 --> 00:06:43,280
can have the results of each node

00:06:40,639 --> 00:06:45,039
in a file with a caching mechanism and

00:06:43,280 --> 00:06:47,919
you can also

00:06:45,039 --> 00:06:49,360
view the results of each node within the

00:06:47,919 --> 00:06:53,199
interface of mushroom

00:06:49,360 --> 00:06:55,680
whether it is 2d or images or 3d results

00:06:53,199 --> 00:06:56,560
this nodal pipeline enables you also to

00:06:55,680 --> 00:06:58,240
build up

00:06:56,560 --> 00:07:00,400
some custom pipelines we will show you

00:06:58,240 --> 00:07:02,639
some examples

00:07:00,400 --> 00:07:05,120
you can also augment your construction

00:07:02,639 --> 00:07:07,680
uh to iterate the scene

00:07:05,120 --> 00:07:08,800
reconstruction with a couple of edited

00:07:07,680 --> 00:07:11,120
image

00:07:08,800 --> 00:07:12,479
uh one other key point also is that we

00:07:11,120 --> 00:07:14,720
are able to submit

00:07:12,479 --> 00:07:16,720
the the computing on the render farm you

00:07:14,720 --> 00:07:19,360
can submit it on locally but

00:07:16,720 --> 00:07:21,360
you can use a render farm because

00:07:19,360 --> 00:07:24,479
photogrammetry is uh

00:07:21,360 --> 00:07:26,080
needs a lot of resource uh there's also

00:07:24,479 --> 00:07:28,880
in the pipeline

00:07:26,080 --> 00:07:30,000
mesh post processing uh for instance we

00:07:28,880 --> 00:07:33,039
can

00:07:30,000 --> 00:07:36,160
simplify or we can smooth the match

00:07:33,039 --> 00:07:37,759
and another cool feature also is that if

00:07:36,160 --> 00:07:38,479
you do read topology in third part

00:07:37,759 --> 00:07:41,599
software

00:07:38,479 --> 00:07:44,800
you can retexture your your

00:07:41,599 --> 00:07:47,120
simplified mesh with input images

00:07:44,800 --> 00:07:48,960
and you can see the results within the

00:07:47,120 --> 00:07:52,319
same 3d reference word

00:07:48,960 --> 00:07:55,360
in a mushroom interface

00:07:52,319 --> 00:07:57,520
so here we have an example of of the

00:07:55,360 --> 00:08:00,160
render farm video

00:07:57,520 --> 00:08:01,039
fact what you can see is that on the on

00:08:00,160 --> 00:08:03,520
the

00:08:01,039 --> 00:08:04,639
right hand side that some nodes are

00:08:03,520 --> 00:08:07,759
parallelized

00:08:04,639 --> 00:08:09,280
onto the the render nodes uh here in

00:08:07,759 --> 00:08:13,680
fact it's an implementation

00:08:09,280 --> 00:08:15,680
with our dispatcher which is a tractor

00:08:13,680 --> 00:08:17,039
and the other cool thing is that you can

00:08:15,680 --> 00:08:18,879
follow

00:08:17,039 --> 00:08:21,520
the rendering process within measuring

00:08:18,879 --> 00:08:24,160
for each node

00:08:21,520 --> 00:08:25,520
so regarding the the technology stack so

00:08:24,160 --> 00:08:27,199
as i said the mesh measurement is the

00:08:25,520 --> 00:08:30,720
frontal application

00:08:27,199 --> 00:08:34,560
uh it's a it's a script mode uh ui

00:08:30,720 --> 00:08:36,800
so that enables it to be more evolutive

00:08:34,560 --> 00:08:39,839
and to be tested more rapidly

00:08:36,800 --> 00:08:41,360
in python and qt and the back end is at

00:08:39,839 --> 00:08:43,039
each vision framework with all the

00:08:41,360 --> 00:08:45,600
secrets priests and

00:08:43,039 --> 00:08:46,800
cuda libraries uh to perform the

00:08:45,600 --> 00:08:50,399
computation with

00:08:46,800 --> 00:08:53,680
the best performance

00:08:50,399 --> 00:08:56,880
we also have uh we rely in fact uh

00:08:53,680 --> 00:08:59,680
intensively on uh standard file formats

00:08:56,880 --> 00:09:00,880
uh like alembic or obg for the for the

00:08:59,680 --> 00:09:04,720
3d files and

00:09:00,880 --> 00:09:07,760
exr for the the 2d files um

00:09:04,720 --> 00:09:09,440
we also uh we have built the backbone on

00:09:07,760 --> 00:09:12,480
the other open source project

00:09:09,440 --> 00:09:12,959
this is uh a few of them that are being

00:09:12,480 --> 00:09:16,880
used

00:09:12,959 --> 00:09:18,640
within his vision uh

00:09:16,880 --> 00:09:20,480
we have to mention on top of it the

00:09:18,640 --> 00:09:23,839
vcpkg initiative as well

00:09:20,480 --> 00:09:26,640
which is not on this list and

00:09:23,839 --> 00:09:27,519
regarding the the architecture we have

00:09:26,640 --> 00:09:30,399
developed also

00:09:27,519 --> 00:09:32,240
a couple of plugins one is for maya

00:09:30,399 --> 00:09:36,000
which you can see

00:09:32,240 --> 00:09:37,519
in this video so we can export

00:09:36,000 --> 00:09:39,200
the machines and the camera from

00:09:37,519 --> 00:09:43,120
mushroom and

00:09:39,200 --> 00:09:46,480
use them uh into maya so that

00:09:43,120 --> 00:09:47,839
the cg artist can see within maya what

00:09:46,480 --> 00:09:51,120
are the different parts of the pawn

00:09:47,839 --> 00:09:53,120
clouds that are provided by these images

00:09:51,120 --> 00:09:54,160
where are the camera located within the

00:09:53,120 --> 00:09:56,959
3d scene

00:09:54,160 --> 00:09:58,959
so it's a great tool to help for them to

00:09:56,959 --> 00:10:02,000
do the rhythmology for instance

00:09:58,959 --> 00:10:04,320
in maya so

00:10:02,000 --> 00:10:05,839
this so this my uh tool has been

00:10:04,320 --> 00:10:06,959
developed at micros but uh what's

00:10:05,839 --> 00:10:09,120
interesting is the

00:10:06,959 --> 00:10:10,959
community of meshum has developed other

00:10:09,120 --> 00:10:12,720
plugins for instance

00:10:10,959 --> 00:10:14,399
the guy from side effects have

00:10:12,720 --> 00:10:17,519
implemented an integration of

00:10:14,399 --> 00:10:21,040
his vision pipeline into houdini with

00:10:17,519 --> 00:10:24,160
the game development tool set uh

00:10:21,040 --> 00:10:26,560
another community uh

00:10:24,160 --> 00:10:28,320
add-on has been done for some guys of

00:10:26,560 --> 00:10:31,839
two in blender

00:10:28,320 --> 00:10:33,600
in fact these plugins uh

00:10:31,839 --> 00:10:35,600
the import of mushroom and the

00:10:33,600 --> 00:10:38,000
management of the data of mushroom

00:10:35,600 --> 00:10:40,240
into blender or to clean the mesh or to

00:10:38,000 --> 00:10:43,839
do your topology whatever so

00:10:40,240 --> 00:10:46,720
we give you here two examples

00:10:43,839 --> 00:10:47,440
so that was a quick overview of national

00:10:46,720 --> 00:10:50,000
analysis

00:10:47,440 --> 00:10:50,560
and now fadia is taking over to speak

00:10:50,000 --> 00:10:53,839
about

00:10:50,560 --> 00:10:56,000
the evolutions of mushroom and the new

00:10:53,839 --> 00:10:59,519
version coming

00:10:56,000 --> 00:11:00,480
hello so i will present the new features

00:10:59,519 --> 00:11:03,839
that will

00:11:00,480 --> 00:11:07,279
arrive in the new version

00:11:03,839 --> 00:11:09,600
so first of all we in this new version

00:11:07,279 --> 00:11:13,200
there will be a new pipeline for

00:11:09,600 --> 00:11:15,920
the creation of hdr panorama

00:11:13,200 --> 00:11:18,160
and so it's a support standard optics

00:11:15,920 --> 00:11:20,079
but it's also a specific support for

00:11:18,160 --> 00:11:23,600
full fisheye images

00:11:20,079 --> 00:11:28,560
and and also it can take advantage of a

00:11:23,600 --> 00:11:31,680
motorized head system and

00:11:28,560 --> 00:11:32,640
so this new pipeline there we will see

00:11:31,680 --> 00:11:34,560
the two parts

00:11:32,640 --> 00:11:35,920
so the first part is the creation of the

00:11:34,560 --> 00:11:39,519
hdr images

00:11:35,920 --> 00:11:41,120
so we will have the multi-marketing ldr

00:11:39,519 --> 00:11:44,240
images and we have to

00:11:41,120 --> 00:11:47,200
analyze them and fuse them into hdm

00:11:44,240 --> 00:11:49,120
so in our implementation in mushroom

00:11:47,200 --> 00:11:52,160
it's splitted in three nodes

00:11:49,120 --> 00:11:54,240
the first step is the sampling is the

00:11:52,160 --> 00:11:56,800
analysis of the images and selection of

00:11:54,240 --> 00:11:58,320
the most focused pixels to extract

00:11:56,800 --> 00:12:00,720
information

00:11:58,320 --> 00:12:03,040
uh when we have done that we can do the

00:12:00,720 --> 00:12:04,959
calibration

00:12:03,040 --> 00:12:07,279
and in this calibration the idea is to

00:12:04,959 --> 00:12:10,560
recover the camera response function

00:12:07,279 --> 00:12:13,760
from the multi-packeting and

00:12:10,560 --> 00:12:14,959
and finally we have to we use this

00:12:13,760 --> 00:12:18,399
calibration

00:12:14,959 --> 00:12:21,760
to fuse our input images

00:12:18,399 --> 00:12:25,200
into a single hdr image

00:12:21,760 --> 00:12:27,920
and so it's it's quite standard and

00:12:25,200 --> 00:12:29,120
but we have a specific option to be able

00:12:27,920 --> 00:12:31,040
to uh

00:12:29,120 --> 00:12:32,639
analyze the highlights so the idea is

00:12:31,040 --> 00:12:35,279
that one of the use case

00:12:32,639 --> 00:12:36,720
is the creation of images for the

00:12:35,279 --> 00:12:39,519
lighting

00:12:36,720 --> 00:12:41,040
and in the lighting the most important

00:12:39,519 --> 00:12:42,240
aspect is to be able to make a big

00:12:41,040 --> 00:12:44,320
difference between

00:12:42,240 --> 00:12:45,440
the wheel source of the lighting so if

00:12:44,320 --> 00:12:50,399
you have the sun

00:12:45,440 --> 00:12:50,399
in your images for instance and

00:12:51,279 --> 00:12:54,639
and so when you do that it's not

00:12:52,880 --> 00:12:55,839
possible during the acquisition to be

00:12:54,639 --> 00:12:58,399
able to recover

00:12:55,839 --> 00:12:59,360
the real value of the sun you you are

00:12:58,399 --> 00:13:02,160
never able to

00:12:59,360 --> 00:13:02,160
make the um

00:13:02,800 --> 00:13:07,200
with your camera you are not able to

00:13:04,480 --> 00:13:08,160
capture the amount of light you get from

00:13:07,200 --> 00:13:10,480
the sun

00:13:08,160 --> 00:13:12,480
and so we detect those pixels that are

00:13:10,480 --> 00:13:15,519
saturated in all images and provide some

00:13:12,480 --> 00:13:15,519
post-processing stuff

00:13:19,040 --> 00:13:23,839
we have also input the image viewer of

00:13:21,760 --> 00:13:27,279
mushroom to be able to

00:13:23,839 --> 00:13:29,440
see those images so we can uh visualize

00:13:27,279 --> 00:13:30,560
them with a floating point visualization

00:13:29,440 --> 00:13:32,800
and

00:13:30,560 --> 00:13:34,079
interactively adjust gain and gamma to

00:13:32,800 --> 00:13:36,240
be able to

00:13:34,079 --> 00:13:37,680
see the values and also the color picker

00:13:36,240 --> 00:13:40,720
to really

00:13:37,680 --> 00:13:40,720
analyze what we get

00:13:41,680 --> 00:13:46,240
and and then we have the other part of

00:13:44,320 --> 00:13:50,000
this pipeline

00:13:46,240 --> 00:13:54,560
for the creation of the 360 images

00:13:50,000 --> 00:13:56,240
um so for that so in our implementation

00:13:54,560 --> 00:13:56,880
it's splitted in four nodes so the first

00:13:56,240 --> 00:14:00,240
step

00:13:56,880 --> 00:14:02,079
uh is when we are using fisheye images

00:14:00,240 --> 00:14:04,480
we have to detect the fisheye circle or

00:14:02,079 --> 00:14:08,079
we can manually manually adjust it as

00:14:04,480 --> 00:14:11,279
as we can see on the video and

00:14:08,079 --> 00:14:13,440
and in the case of uh when we have a

00:14:11,279 --> 00:14:13,839
motorized system with a lot of images we

00:14:13,440 --> 00:14:17,360
can

00:14:13,839 --> 00:14:20,160
retrieve the files from the motorized

00:14:17,360 --> 00:14:23,360
head system and unuse that to initialize

00:14:20,160 --> 00:14:23,360
the position of the camera

00:14:23,600 --> 00:14:27,920
then the other step the estimation will

00:14:26,480 --> 00:14:30,160
recover

00:14:27,920 --> 00:14:31,920
the relative rotation between all the

00:14:30,160 --> 00:14:34,000
cameras

00:14:31,920 --> 00:14:36,160
then the warping we convert all our

00:14:34,000 --> 00:14:39,279
input images into the

00:14:36,160 --> 00:14:42,839
360 coordinate system and finally

00:14:39,279 --> 00:14:46,160
we have the compositing

00:14:42,839 --> 00:14:47,760
and we use the standard multiband

00:14:46,160 --> 00:14:49,839
blending algorithm to be able to

00:14:47,760 --> 00:14:52,880
compensate for slight variation

00:14:49,839 --> 00:14:56,320
of illumination and being able to

00:14:52,880 --> 00:14:57,519
keep the pixel precision and we have

00:14:56,320 --> 00:15:00,880
also implemented the

00:14:57,519 --> 00:15:03,600
graph cad to be able to select the

00:15:00,880 --> 00:15:06,399
best area to make the transition between

00:15:03,600 --> 00:15:09,680
your different input images

00:15:06,399 --> 00:15:11,040
so that's it for the hdr panorama

00:15:09,680 --> 00:15:13,120
pipeline

00:15:11,040 --> 00:15:16,000
and now we can switch to the features

00:15:13,120 --> 00:15:18,480
regarding the photogrammetry guideline

00:15:16,000 --> 00:15:20,880
so first of all for the photogrammetry

00:15:18,480 --> 00:15:24,240
pipeline we have improved the texturing

00:15:20,880 --> 00:15:25,600
in the context of topology so usually

00:15:24,240 --> 00:15:28,639
when you have the

00:15:25,600 --> 00:15:31,680
you get a really dense mesh

00:15:28,639 --> 00:15:32,240
with thousands of vertices and after

00:15:31,680 --> 00:15:35,600
manual

00:15:32,240 --> 00:15:37,600
topology uh here in this uh really

00:15:35,600 --> 00:15:40,240
extreme example we have just a few

00:15:37,600 --> 00:15:42,639
triangles and it's really challenging to

00:15:40,240 --> 00:15:43,600
texturate properly from the raw input

00:15:42,639 --> 00:15:46,399
images

00:15:43,600 --> 00:15:48,079
and so we have improved the solution to

00:15:46,399 --> 00:15:50,000
be able to

00:15:48,079 --> 00:15:52,000
better propagate the visibility to be

00:15:50,000 --> 00:15:57,360
able to generate

00:15:52,000 --> 00:15:57,360
more proper texture on these cases

00:15:58,000 --> 00:16:07,040
and we have also added a new 3d gizmo

00:16:02,160 --> 00:16:07,040
on the meshing node this allows to

00:16:07,360 --> 00:16:12,880
define a bonding box from your sfm so

00:16:10,560 --> 00:16:14,480
uh in output of the sfm you have the

00:16:12,880 --> 00:16:16,639
sparseline cloud

00:16:14,480 --> 00:16:17,759
and you can use that to put a bonding

00:16:16,639 --> 00:16:19,360
box and select the

00:16:17,759 --> 00:16:20,880
part of your scene that you want to

00:16:19,360 --> 00:16:24,720
reconstruct

00:16:20,880 --> 00:16:27,199
um and it you can also

00:16:24,720 --> 00:16:28,720
duplicate the mesh the machine node and

00:16:27,199 --> 00:16:29,440
put different bonding box so you can

00:16:28,720 --> 00:16:32,000
make a

00:16:29,440 --> 00:16:32,480
kind of set survey of the full location

00:16:32,000 --> 00:16:35,440
uh

00:16:32,480 --> 00:16:37,440
with a certain amount of density and

00:16:35,440 --> 00:16:39,279
then you are able to just

00:16:37,440 --> 00:16:40,720
put another bonding box on a small

00:16:39,279 --> 00:16:43,440
detail to be able to

00:16:40,720 --> 00:16:44,560
generate a more precise reconstruction

00:16:43,440 --> 00:16:47,519
of one object

00:16:44,560 --> 00:16:49,680
in this place and this gizmo is also

00:16:47,519 --> 00:16:50,560
integrated in the sfm transform to make

00:16:49,680 --> 00:16:52,880
a

00:16:50,560 --> 00:16:55,079
manual transformation or manual change

00:16:52,880 --> 00:16:58,079
of the coordinate system in the

00:16:55,079 --> 00:16:58,079
output.csf

00:17:00,399 --> 00:17:04,480
in terms of visualization we have also

00:17:02,480 --> 00:17:06,880
added a tool to be able to

00:17:04,480 --> 00:17:08,000
look for the 3d camera that we have

00:17:06,880 --> 00:17:11,280
found

00:17:08,000 --> 00:17:14,559
and we can overlay the original

00:17:11,280 --> 00:17:19,839
input images and distorted images

00:17:14,559 --> 00:17:19,839
to see in detail the variation

00:17:21,120 --> 00:17:27,039
on the more technical side we have also

00:17:24,240 --> 00:17:28,880
new visualization tools so here for

00:17:27,039 --> 00:17:30,559
instance we can visualize the feature

00:17:28,880 --> 00:17:32,960
points that we have extracted on the 2d

00:17:30,559 --> 00:17:36,000
images so we can see on the left

00:17:32,960 --> 00:17:38,320
the blue and green

00:17:36,000 --> 00:17:40,960
feature points are two two different

00:17:38,320 --> 00:17:43,679
kind of features we extract on the image

00:17:40,960 --> 00:17:45,679
and then we can see in orange the points

00:17:43,679 --> 00:17:47,840
that have been matched to other images

00:17:45,679 --> 00:17:48,720
and finally in red we can see the points

00:17:47,840 --> 00:17:51,120
that are really

00:17:48,720 --> 00:17:52,240
in the 3d space at the end and that are

00:17:51,120 --> 00:17:55,360
really used

00:17:52,240 --> 00:17:57,840
to solve the camera positions and

00:17:55,360 --> 00:17:59,200
on the right if you if when we zoom in

00:17:57,840 --> 00:18:02,080
detail of the

00:17:59,200 --> 00:18:04,320
image we can see in blue the feature

00:18:02,080 --> 00:18:07,520
point with the scale and orientation

00:18:04,320 --> 00:18:10,640
and we can see the in red the 3d

00:18:07,520 --> 00:18:14,080
projection of the same point and this

00:18:10,640 --> 00:18:17,679
small segment in red between the two is

00:18:14,080 --> 00:18:17,679
the projection error that we get

00:18:18,720 --> 00:18:24,799
there are also some widgets to

00:18:21,760 --> 00:18:28,559
visualize the statistics of the

00:18:24,799 --> 00:18:28,880
sfm it can we have some statistical view

00:18:28,559 --> 00:18:32,400
on

00:18:28,880 --> 00:18:34,480
some global statistics we have also

00:18:32,400 --> 00:18:38,480
added some visualization

00:18:34,480 --> 00:18:38,480
for the resource usages

00:18:39,120 --> 00:18:43,440
and another point that we have in

00:18:41,120 --> 00:18:47,120
photogrammetry is that we don't know the

00:18:43,440 --> 00:18:50,240
coordinate system in output all our

00:18:47,120 --> 00:18:53,520
geometric information is relative and

00:18:50,240 --> 00:18:56,320
so there is a new option in the sfm

00:18:53,520 --> 00:18:58,320
transform that allows to change the

00:18:56,320 --> 00:19:02,240
coordinate system at the end

00:18:58,320 --> 00:19:04,640
and we scale it so if we put marker

00:19:02,240 --> 00:19:06,400
in our setup we can automatically

00:19:04,640 --> 00:19:08,080
rescale it to the correct scale and this

00:19:06,400 --> 00:19:12,080
allows to make measurement

00:19:08,080 --> 00:19:12,080
from from that

00:19:13,360 --> 00:19:19,120
and we have also added new nodes to make

00:19:16,960 --> 00:19:20,799
alignment between scene and transfer

00:19:19,120 --> 00:19:23,760
poses between scenes

00:19:20,799 --> 00:19:26,480
so if you have an acquisition rig with

00:19:23,760 --> 00:19:28,960
multi-camera system

00:19:26,480 --> 00:19:30,880
you are now able to make a first

00:19:28,960 --> 00:19:33,840
reconstruction with

00:19:30,880 --> 00:19:35,520
with the calibration for instance and

00:19:33,840 --> 00:19:37,679
and then we use that

00:19:35,520 --> 00:19:39,120
as an initialization for other

00:19:37,679 --> 00:19:42,720
reconstructions

00:19:39,120 --> 00:19:43,120
and and it's also useful for research to

00:19:42,720 --> 00:19:45,120
make

00:19:43,120 --> 00:19:46,320
alignment between scene to be able to

00:19:45,120 --> 00:19:49,039
align to grand truths and make

00:19:46,320 --> 00:19:49,039
evaluations

00:19:50,960 --> 00:19:54,640
we have also improved a little bit the

00:19:52,559 --> 00:19:56,400
command line so now

00:19:54,640 --> 00:19:58,000
you can create your scene in mesh room

00:19:56,400 --> 00:20:00,640
save it um

00:19:58,000 --> 00:20:02,480
as a standard mg file and then use that

00:20:00,640 --> 00:20:05,679
as an input pipeline

00:20:02,480 --> 00:20:09,120
uh for the command line and

00:20:05,679 --> 00:20:13,200
and few other adjustments that could be

00:20:09,120 --> 00:20:13,840
really useful there is also a new node

00:20:13,200 --> 00:20:16,640
to

00:20:13,840 --> 00:20:20,720
export the result directly from mesh

00:20:16,640 --> 00:20:24,880
room to sketchfab

00:20:20,720 --> 00:20:27,440
and and also

00:20:24,880 --> 00:20:29,039
there is a new option to directly from

00:20:27,440 --> 00:20:31,440
the 2d viewer

00:20:29,039 --> 00:20:34,080
being able to visualize the intermediate

00:20:31,440 --> 00:20:36,799
steps or the depth map

00:20:34,080 --> 00:20:40,880
so here we can see depth map in 2d and

00:20:36,799 --> 00:20:40,880
then we can also import it in 3d

00:20:41,360 --> 00:20:46,159
so here we see the depth map after

00:20:44,559 --> 00:20:49,200
featuring

00:20:46,159 --> 00:20:49,600
but we can select the node that we want

00:20:49,200 --> 00:20:51,840
to

00:20:49,600 --> 00:20:53,679
see so if we have multiple depth map

00:20:51,840 --> 00:20:55,440
with different parameters etc

00:20:53,679 --> 00:20:57,760
and here we can see the depth map b for

00:20:55,440 --> 00:20:59,280
featuring and after filtering so we can

00:20:57,760 --> 00:21:01,919
see that before filtering we

00:20:59,280 --> 00:21:03,360
we have a lot of noise and a lot of

00:21:01,919 --> 00:21:05,760
input candidates

00:21:03,360 --> 00:21:06,960
and that are selected to get the

00:21:05,760 --> 00:21:08,480
filtered version

00:21:06,960 --> 00:21:10,080
and then when all the depth map are

00:21:08,480 --> 00:21:16,480
fused all together

00:21:10,080 --> 00:21:18,720
we get final mesh

00:21:16,480 --> 00:21:20,880
and there is also a new node for image

00:21:18,720 --> 00:21:21,919
processing so it's a preliminary work to

00:21:20,880 --> 00:21:25,360
be able to

00:21:21,919 --> 00:21:29,039
make some pre-processing of your images

00:21:25,360 --> 00:21:30,559
directly within the mesh pipeline and

00:21:29,039 --> 00:21:33,840
but this that can also be used on its

00:21:30,559 --> 00:21:33,840
own to make some conversion

00:21:35,679 --> 00:21:39,280
we have also improved the parameter

00:21:37,520 --> 00:21:42,640
system so now the parameters are

00:21:39,280 --> 00:21:45,919
dynamic so when you change one parameter

00:21:42,640 --> 00:21:49,200
you you see only the uh

00:21:45,919 --> 00:21:53,200
the relevant one for the on your nodes

00:21:49,200 --> 00:21:54,960
and it's also changing validation system

00:21:53,200 --> 00:21:56,799
so now

00:21:54,960 --> 00:21:58,480
only the parameters that are really used

00:21:56,799 --> 00:22:02,159
by the process

00:21:58,480 --> 00:22:02,159
are used in the invalidation system

00:22:03,679 --> 00:22:09,520
if we go more deeper in the library

00:22:07,919 --> 00:22:11,360
there is a new option on the feature

00:22:09,520 --> 00:22:14,559
matching to be able to

00:22:11,360 --> 00:22:17,679
directly estimate

00:22:14,559 --> 00:22:20,000
some distortion directly during the

00:22:17,679 --> 00:22:21,919
feature matching so this allows to

00:22:20,000 --> 00:22:22,960
recover more feature points when you

00:22:21,919 --> 00:22:25,919
have some

00:22:22,960 --> 00:22:28,880
images with large distortion like gopro

00:22:25,919 --> 00:22:28,880
images for instance

00:22:31,120 --> 00:22:34,720
and there is a lot of really small

00:22:34,080 --> 00:22:38,240
improvement

00:22:34,720 --> 00:22:40,480
in many places and

00:22:38,240 --> 00:22:42,159
in particular regarding the metadata

00:22:40,480 --> 00:22:44,799
support and the support of

00:22:42,159 --> 00:22:46,559
more war images so i i would like to

00:22:44,799 --> 00:22:48,720
take this opportunity to thank

00:22:46,559 --> 00:22:50,480
the the team from openimagerio for all

00:22:48,720 --> 00:22:54,640
the fixes they have made for us

00:22:50,480 --> 00:22:57,760
and that's really useful

00:22:54,640 --> 00:23:01,120
and so everything is uh is

00:22:57,760 --> 00:23:04,480
on github and so it's under the mozilla

00:23:01,120 --> 00:23:08,559
license and we provide the

00:23:04,480 --> 00:23:12,000
windows and linux binaries and so

00:23:08,559 --> 00:23:15,280
the next release will be uh

00:23:12,000 --> 00:23:16,720
coming in the few weeks i think i'm sure

00:23:15,280 --> 00:23:18,159
that that will be a question

00:23:16,720 --> 00:23:20,640
that we raised when will be the next

00:23:18,159 --> 00:23:23,200
release so now we're gonna take

00:23:20,640 --> 00:23:24,640
talk a little bit of the further steps

00:23:23,200 --> 00:23:27,760
of the project

00:23:24,640 --> 00:23:29,919
as we can see it from now so

00:23:27,760 --> 00:23:31,360
one of the extension could be the

00:23:29,919 --> 00:23:33,600
possibility of having

00:23:31,360 --> 00:23:35,200
an automatic camera tracking after the

00:23:33,600 --> 00:23:37,200
shooting

00:23:35,200 --> 00:23:38,880
because in fact the evaluation of the

00:23:37,200 --> 00:23:40,960
live action camera

00:23:38,880 --> 00:23:42,320
can take advantage of the structure from

00:23:40,960 --> 00:23:45,600
motion algorithm

00:23:42,320 --> 00:23:48,400
so the idea is to uh uh

00:23:45,600 --> 00:23:50,080
based the first structural motion of on

00:23:48,400 --> 00:23:51,520
the pawn clouds of the three-liter

00:23:50,080 --> 00:23:54,640
construction of the set

00:23:51,520 --> 00:23:56,159
and then to add the analysis of the

00:23:54,640 --> 00:23:58,480
live-action camera

00:23:56,159 --> 00:23:59,919
so this is only a premium test on our

00:23:58,480 --> 00:24:03,200
production shots

00:23:59,919 --> 00:24:06,000
but as you can see this we can already

00:24:03,200 --> 00:24:08,480
get some interesting results so we'll be

00:24:06,000 --> 00:24:10,720
working on that

00:24:08,480 --> 00:24:12,960
the the the main idea behind all this is

00:24:10,720 --> 00:24:13,600
to combine all the data acquisition on

00:24:12,960 --> 00:24:16,080
set

00:24:13,600 --> 00:24:17,600
uh within meshroom so we have the 3d

00:24:16,080 --> 00:24:19,679
reconstruction of the set

00:24:17,600 --> 00:24:21,679
we have the hd panorama which is now

00:24:19,679 --> 00:24:22,880
available in the next release and the

00:24:21,679 --> 00:24:25,360
idea is to augment

00:24:22,880 --> 00:24:26,240
this process with the live action camera

00:24:25,360 --> 00:24:28,799
tracking

00:24:26,240 --> 00:24:30,880
all done within the same tools with the

00:24:28,799 --> 00:24:33,120
random farm possibility

00:24:30,880 --> 00:24:35,440
and all the nodes that are available uh

00:24:33,120 --> 00:24:38,000
within a mesh room

00:24:35,440 --> 00:24:39,360
that the idea is to improve even better

00:24:38,000 --> 00:24:42,400
the productivity

00:24:39,360 --> 00:24:44,799
of the data acquisition on set and

00:24:42,400 --> 00:24:47,840
to facilitate the integration within the

00:24:44,799 --> 00:24:47,840
vfx pipeline

00:24:49,440 --> 00:24:53,360
you want to talk about the test mode and

00:24:51,279 --> 00:24:55,279
yeah the hub is one really

00:24:53,360 --> 00:24:56,559
critical step of the pipeline because we

00:24:55,279 --> 00:24:59,760
are we have

00:24:56,559 --> 00:25:00,400
that's where we have most of the data to

00:24:59,760 --> 00:25:01,919
process

00:25:00,400 --> 00:25:04,400
so it's critical both in terms of

00:25:01,919 --> 00:25:06,400
performances and in terms of quality

00:25:04,400 --> 00:25:07,600
so we have made a lot of experimentation

00:25:06,400 --> 00:25:09,440
during this year

00:25:07,600 --> 00:25:10,799
and but it's still challenging to

00:25:09,440 --> 00:25:12,240
improve the performance while keeping

00:25:10,799 --> 00:25:15,279
compatibility with

00:25:12,240 --> 00:25:16,799
old cab so but that's something that

00:25:15,279 --> 00:25:21,279
definitely

00:25:16,799 --> 00:25:23,760
needs to be continued this year

00:25:21,279 --> 00:25:25,520
and on the more research side of the

00:25:23,760 --> 00:25:28,080
project

00:25:25,520 --> 00:25:29,360
we have finalized the phd thesis this

00:25:28,080 --> 00:25:33,039
year

00:25:29,360 --> 00:25:35,520
so we provide a first prototype for the

00:25:33,039 --> 00:25:37,279
estimation of the lighting of the scene

00:25:35,520 --> 00:25:40,400
and being able to use this lighting

00:25:37,279 --> 00:25:42,880
information to refine the geometry

00:25:40,400 --> 00:25:45,919
and and we will continue this work with

00:25:42,880 --> 00:25:48,400
a new partnership between nicos and evie

00:25:45,919 --> 00:25:49,360
to integrate this prototype into

00:25:48,400 --> 00:25:52,000
mushroom

00:25:49,360 --> 00:25:53,039
and and in the more long term go further

00:25:52,000 --> 00:25:55,039
and uh

00:25:53,039 --> 00:25:57,840
and try to analyze surface material

00:25:55,039 --> 00:25:57,840
properties

00:25:58,000 --> 00:26:03,840
okay now we're going to say a few words

00:26:01,520 --> 00:26:06,640
on our community

00:26:03,840 --> 00:26:07,679
so measure the night vision in fact is

00:26:06,640 --> 00:26:10,080
being used by

00:26:07,679 --> 00:26:11,520
various industries not only the vfx

00:26:10,080 --> 00:26:12,799
industry

00:26:11,520 --> 00:26:14,400
it's being used by the medical

00:26:12,799 --> 00:26:15,919
industries on the left-hand side you can

00:26:14,400 --> 00:26:18,320
see that there are some guys

00:26:15,919 --> 00:26:19,440
in claremont doing some surgical

00:26:18,320 --> 00:26:21,360
augmented reality

00:26:19,440 --> 00:26:23,200
what they do is they do the the

00:26:21,360 --> 00:26:24,000
three-year construction of the organ

00:26:23,200 --> 00:26:26,799
that has been scanned

00:26:24,000 --> 00:26:27,360
before in order to help the the camera

00:26:26,799 --> 00:26:30,000
tracking

00:26:27,360 --> 00:26:31,279
during the operation uh in the middle

00:26:30,000 --> 00:26:33,440
you have the classical

00:26:31,279 --> 00:26:35,200
usage of photogrammetry for cultural

00:26:33,440 --> 00:26:36,320
heritage for instance we give you here

00:26:35,200 --> 00:26:39,919
an example

00:26:36,320 --> 00:26:42,000
or for the architecture design uh

00:26:39,919 --> 00:26:43,440
with a an interesting integration of

00:26:42,000 --> 00:26:45,600
machine pipeline

00:26:43,440 --> 00:26:47,279
and on the right hand side we have uh

00:26:45,600 --> 00:26:48,799
the people in nanter digital that we

00:26:47,279 --> 00:26:51,360
know pretty well

00:26:48,799 --> 00:26:52,240
we are making this digital double

00:26:51,360 --> 00:26:53,919
project

00:26:52,240 --> 00:26:55,440
here we can see what they are doing for

00:26:53,919 --> 00:26:58,480
the the

00:26:55,440 --> 00:27:00,400
face acquisition the face 3d scanning

00:26:58,480 --> 00:27:01,919
and what's interesting here we can see

00:27:00,400 --> 00:27:03,919
that they've used

00:27:01,919 --> 00:27:05,200
the possibility of integrating their

00:27:03,919 --> 00:27:08,080
production pipeline

00:27:05,200 --> 00:27:10,240
into mesh room to be able to design

00:27:08,080 --> 00:27:11,840
their custom nodes

00:27:10,240 --> 00:27:14,000
regarding the interaction with

00:27:11,840 --> 00:27:14,880
third-party software or acquisition or

00:27:14,000 --> 00:27:16,480
whatever

00:27:14,880 --> 00:27:19,120
so it's a pretty good that's a good

00:27:16,480 --> 00:27:21,919
example of why we have built

00:27:19,120 --> 00:27:23,360
software on the notable pipeline because

00:27:21,919 --> 00:27:24,480
there is a lot of use cases for

00:27:23,360 --> 00:27:26,240
photogrammetry

00:27:24,480 --> 00:27:28,320
a lot of different constraints depending

00:27:26,240 --> 00:27:30,480
on your acquisition setup

00:27:28,320 --> 00:27:31,440
your acquisition condition also in terms

00:27:30,480 --> 00:27:35,440
of lighting

00:27:31,440 --> 00:27:38,960
etc and so your input can change a lot

00:27:35,440 --> 00:27:41,760
so you may have to create some

00:27:38,960 --> 00:27:43,279
specific processing or specific way to

00:27:41,760 --> 00:27:44,720
declare the relationship and your

00:27:43,279 --> 00:27:48,000
constraints you have

00:27:44,720 --> 00:27:51,039
and and also in output

00:27:48,000 --> 00:27:54,559
you get the first mesh from this

00:27:51,039 --> 00:27:57,200
measurement you can add an extra layer

00:27:54,559 --> 00:28:00,399
of interpretation to use that

00:27:57,200 --> 00:28:01,679
in for specific needs so that's why

00:28:00,399 --> 00:28:04,320
it's really important to have this

00:28:01,679 --> 00:28:06,080
pipeline so people can build their own

00:28:04,320 --> 00:28:08,559
they can adjust the input and address

00:28:06,080 --> 00:28:08,559
the output

00:28:09,360 --> 00:28:12,960
the community also has been for a great

00:28:11,120 --> 00:28:14,080
help to build up the online

00:28:12,960 --> 00:28:16,559
documentations

00:28:14,080 --> 00:28:18,080
which is made around the redux framework

00:28:16,559 --> 00:28:20,080
so we we have we

00:28:18,080 --> 00:28:21,679
can take the opportunity today to thanks

00:28:20,080 --> 00:28:24,720
again the people who have been

00:28:21,679 --> 00:28:27,520
helping us for setting up this con this

00:28:24,720 --> 00:28:29,200
documentation uh of course more

00:28:27,520 --> 00:28:30,000
contributions are welcome and we give

00:28:29,200 --> 00:28:32,480
you here the link

00:28:30,000 --> 00:28:34,799
to if you want to contribute to the

00:28:32,480 --> 00:28:38,080
documentation of mushroom

00:28:34,799 --> 00:28:40,000
um so uh the the

00:28:38,080 --> 00:28:42,159
the project is a collaborative project

00:28:40,000 --> 00:28:42,880
since the beginning uh here we remind

00:28:42,159 --> 00:28:45,039
you

00:28:42,880 --> 00:28:47,120
the academic partners that have been

00:28:45,039 --> 00:28:50,559
helping us for years

00:28:47,120 --> 00:28:52,720
to start up this project but of course

00:28:50,559 --> 00:28:54,880
more people are welcome whether you are

00:28:52,720 --> 00:28:57,520
a researcher whether you are a developer

00:28:54,880 --> 00:28:59,440
you are 3d photogrammetry expert

00:28:57,520 --> 00:29:02,159
you are more than welcome to join us

00:28:59,440 --> 00:29:04,640
because we are always interested in

00:29:02,159 --> 00:29:06,000
in sharing new ideas start new

00:29:04,640 --> 00:29:08,080
collaboration

00:29:06,000 --> 00:29:11,039
because this is the way the project has

00:29:08,080 --> 00:29:13,520
been started from the beginning

00:29:11,039 --> 00:29:14,559
and today we have an announcement to to

00:29:13,520 --> 00:29:16,799
do so

00:29:14,559 --> 00:29:19,360
after these ten years of collaboration

00:29:16,799 --> 00:29:21,600
uh with uh the 3d computer vision people

00:29:19,360 --> 00:29:22,799
we have decided to create a non-profit

00:29:21,600 --> 00:29:25,440
organization

00:29:22,799 --> 00:29:26,799
around mesh room builder under the

00:29:25,440 --> 00:29:30,240
founding members of

00:29:26,799 --> 00:29:31,200
of the project um we have seen also that

00:29:30,240 --> 00:29:33,520
over the years

00:29:31,200 --> 00:29:34,480
the the project has received a lot of

00:29:33,520 --> 00:29:37,600
interest

00:29:34,480 --> 00:29:39,360
and requests from other industries

00:29:37,600 --> 00:29:41,600
that go in fact beyond the initial

00:29:39,360 --> 00:29:43,919
objectives

00:29:41,600 --> 00:29:44,640
that makes a lot of different use cases

00:29:43,919 --> 00:29:47,279
different

00:29:44,640 --> 00:29:47,679
acquisition systems like fabia mentioned

00:29:47,279 --> 00:29:49,919
and

00:29:47,679 --> 00:29:51,919
so this is challenging to address within

00:29:49,919 --> 00:29:54,080
the same solution but

00:29:51,919 --> 00:29:54,960
we think there is a great convergence

00:29:54,080 --> 00:29:58,399
opportunity

00:29:54,960 --> 00:30:00,640
uh regarding the needs of

00:29:58,399 --> 00:30:02,000
the low-level blocks that are building

00:30:00,640 --> 00:30:05,120
uh um

00:30:02,000 --> 00:30:07,919
uh alice vision framework and uh

00:30:05,120 --> 00:30:10,640
we think uh meshum can be a good help to

00:30:07,919 --> 00:30:13,120
to build up these different pipelines

00:30:10,640 --> 00:30:14,159
so that's what it's important for us to

00:30:13,120 --> 00:30:17,440
continue build up

00:30:14,159 --> 00:30:19,760
this open source ecosystem uh to take

00:30:17,440 --> 00:30:22,320
advantage of the different use case

00:30:19,760 --> 00:30:24,080
and the different data sets to improve

00:30:22,320 --> 00:30:26,640
the the software

00:30:24,080 --> 00:30:28,000
of course when you the objective of the

00:30:26,640 --> 00:30:31,679
association is to

00:30:28,000 --> 00:30:34,840
participate to the financing of

00:30:31,679 --> 00:30:36,000
extra resources with donations and

00:30:34,840 --> 00:30:39,360
sponsorships

00:30:36,000 --> 00:30:42,080
and globally the the objective of the

00:30:39,360 --> 00:30:45,120
association is to help us to build

00:30:42,080 --> 00:30:45,120
a better software

00:30:45,760 --> 00:30:51,440
okay i think it's time

00:30:49,120 --> 00:30:53,440
we got the yeah we got we've got a

00:30:51,440 --> 00:30:56,080
plenty of time to have uh

00:30:53,440 --> 00:30:58,240
to answer to some of your questions uh

00:30:56,080 --> 00:31:01,760
so we're gonna get through

00:30:58,240 --> 00:31:04,960
the q a of the zoom

00:31:01,760 --> 00:31:06,720
uh the first question is yeah yeah do

00:31:04,960 --> 00:31:08,080
you plan to support aces is there a

00:31:06,720 --> 00:31:09,840
roadmap to combine

00:31:08,080 --> 00:31:11,200
leader and photography so that's two

00:31:09,840 --> 00:31:14,640
questions so

00:31:11,200 --> 00:31:16,320
for the first question so regarding acs

00:31:14,640 --> 00:31:17,760
so there are some things that we have

00:31:16,320 --> 00:31:20,399
looked at but

00:31:17,760 --> 00:31:21,120
that's not so easy regarding dslr

00:31:20,399 --> 00:31:24,080
because

00:31:21,120 --> 00:31:26,159
in our case we are for photogrammetry we

00:31:24,080 --> 00:31:29,200
are working from the sla

00:31:26,159 --> 00:31:32,320
and and

00:31:29,200 --> 00:31:35,360
there are some projects to use

00:31:32,320 --> 00:31:37,919
convert dslr images to acs

00:31:35,360 --> 00:31:39,279
but that's not straightforward because

00:31:37,919 --> 00:31:42,799
the

00:31:39,279 --> 00:31:43,550
acs rely on on the manufacturer to

00:31:42,799 --> 00:31:46,630
provide the

00:31:43,550 --> 00:31:46,630
[Music]

00:31:49,039 --> 00:31:52,159
and so it's not provided for the seller

00:31:51,120 --> 00:31:53,679
so um

00:31:52,159 --> 00:31:55,600
so that's something that we would be

00:31:53,679 --> 00:31:59,039
interested to discuss with uh

00:31:55,600 --> 00:32:00,240
people from aces obviously and there was

00:31:59,039 --> 00:32:02,000
a second question because

00:32:00,240 --> 00:32:04,320
there was two issues in one regarding

00:32:02,000 --> 00:32:07,679
the leader integration which has been

00:32:04,320 --> 00:32:08,640
raised for a long time so we have a few

00:32:07,679 --> 00:32:11,840
bits of answers

00:32:08,640 --> 00:32:13,919
around this yeah we have made some

00:32:11,840 --> 00:32:15,440
experimentation we have implemented a

00:32:13,919 --> 00:32:19,360
different approach to make the

00:32:15,440 --> 00:32:21,519
alignments and and now we need to

00:32:19,360 --> 00:32:23,279
to make the proper integration the user

00:32:21,519 --> 00:32:25,600
interface to uh

00:32:23,279 --> 00:32:29,840
to connect all that together and make it

00:32:25,600 --> 00:32:29,840
usable by a graphic artist station

00:32:30,000 --> 00:32:33,840
next question is when the next version

00:32:32,640 --> 00:32:36,960
build will be released

00:32:33,840 --> 00:32:37,600
and it's an estimation that's a good

00:32:36,960 --> 00:32:40,320
question

00:32:37,600 --> 00:32:41,519
and it's always difficult to to answer

00:32:40,320 --> 00:32:44,880
that because uh

00:32:41,519 --> 00:32:46,480
always at the end we have all the tiny

00:32:44,880 --> 00:32:49,679
things that need to be fixed

00:32:46,480 --> 00:32:51,840
to provide a proper release

00:32:49,679 --> 00:32:53,200
but we hope that we will be able to do

00:32:51,840 --> 00:32:55,039
that in a few weeks

00:32:53,200 --> 00:32:56,320
and of course we are testing this next

00:32:55,039 --> 00:32:59,360
release with

00:32:56,320 --> 00:33:02,240
within technical production services now

00:32:59,360 --> 00:33:03,679
that's also important for us to test it

00:33:02,240 --> 00:33:05,919
in production before

00:33:03,679 --> 00:33:07,679
using it in open source so this is where

00:33:05,919 --> 00:33:10,000
we are now

00:33:07,679 --> 00:33:12,559
next question is does mission prefer

00:33:10,000 --> 00:33:16,720
undistorted or distorted

00:33:12,559 --> 00:33:16,720
original rectilinear images

00:33:17,440 --> 00:33:22,640
so it depends on your quality of your

00:33:20,000 --> 00:33:22,640
own distortion

00:33:22,799 --> 00:33:27,840
but uh so basically both will work uh

00:33:26,000 --> 00:33:29,600
if you have already undistorted your

00:33:27,840 --> 00:33:32,880
images you you may

00:33:29,600 --> 00:33:34,720
want to lock your um

00:33:32,880 --> 00:33:36,640
your parameters because you have already

00:33:34,720 --> 00:33:39,840
solved it and then it will try to solve

00:33:36,640 --> 00:33:39,840
it again

00:33:42,000 --> 00:33:49,279
okay what else i just answer live um

00:33:46,320 --> 00:33:50,640
this one you already answered uh have

00:33:49,279 --> 00:33:52,320
you already noticed this

00:33:50,640 --> 00:33:54,480
this is one of the questions now this

00:33:52,320 --> 00:33:57,600
it's a it's a facebook research uh

00:33:54,480 --> 00:34:00,799
linked to consistent depth uh estimation

00:33:57,600 --> 00:34:02,080
uh with the code release yeah we know

00:34:00,799 --> 00:34:03,600
this paper

00:34:02,080 --> 00:34:05,120
yeah we have seen the release it's

00:34:03,600 --> 00:34:06,320
really interesting we have not tested it

00:34:05,120 --> 00:34:08,560
yet but

00:34:06,320 --> 00:34:11,679
it would be really cool to test and see

00:34:08,560 --> 00:34:11,679
how it reacts

00:34:12,000 --> 00:34:16,800
is there any plan planned to support

00:34:15,000 --> 00:34:21,839
non-nvidia cards

00:34:16,800 --> 00:34:21,839
he's asking an anonymous attendee

00:34:22,079 --> 00:34:30,320
so that's so

00:34:25,359 --> 00:34:30,320
non-nvidia would mean maybe nd

00:34:30,720 --> 00:34:34,639
so i don't know if you mean a cpu

00:34:33,440 --> 00:34:38,240
version or if you mean

00:34:34,639 --> 00:34:38,240
a gpu version for the cards

00:34:38,560 --> 00:34:41,760
so the point is that the depth map is

00:34:40,159 --> 00:34:43,760
really

00:34:41,760 --> 00:34:44,800
a critical step in terms of performance

00:34:43,760 --> 00:34:46,879
so

00:34:44,800 --> 00:34:48,240
with the algorithm that we have

00:34:46,879 --> 00:34:51,679
implemented now

00:34:48,240 --> 00:34:54,159
it would make no sense to do that on cpu

00:34:51,679 --> 00:34:55,359
because it's too computational intensive

00:34:54,159 --> 00:34:57,839
but it's also

00:34:55,359 --> 00:35:00,320
what why it gives this robustness to the

00:34:57,839 --> 00:35:00,320
results

00:35:00,560 --> 00:35:05,359
so yeah so as i said we don't have any

00:35:02,800 --> 00:35:05,680
plan soon to make a non-nvidia version

00:35:05,359 --> 00:35:08,480
but

00:35:05,680 --> 00:35:10,240
uh but obviously if there is some

00:35:08,480 --> 00:35:11,839
initiative from the community we will be

00:35:10,240 --> 00:35:15,280
really happy to support it and

00:35:11,839 --> 00:35:17,119
uh and also what would make sense in my

00:35:15,280 --> 00:35:20,320
opinion would be to

00:35:17,119 --> 00:35:22,240
integrate other implementation and other

00:35:20,320 --> 00:35:25,680
alternatives for cpu

00:35:22,240 --> 00:35:27,359
with a completely different method and

00:35:25,680 --> 00:35:29,040
and that would be also interesting to be

00:35:27,359 --> 00:35:32,400
able to compare them

00:35:29,040 --> 00:35:33,280
in the same system there's maybe an

00:35:32,400 --> 00:35:35,599
answer in it

00:35:33,280 --> 00:35:35,599
yes

00:35:40,800 --> 00:35:49,040
gpu yeah no

00:35:45,760 --> 00:35:51,760
short-term size right because

00:35:49,040 --> 00:35:53,839
it's it's uh it's really a different way

00:35:51,760 --> 00:35:56,640
to fund the problems yes open sale

00:35:53,839 --> 00:35:58,079
could be a way but it's also really

00:35:56,640 --> 00:36:01,200
complex to to

00:35:58,079 --> 00:36:01,760
transfer it another question is do you

00:36:01,200 --> 00:36:04,920
support

00:36:01,760 --> 00:36:08,400
3d protocol free like a free

00:36:04,920 --> 00:36:10,720
freed protocol to motorize ptz camera

00:36:08,400 --> 00:36:10,720
heads

00:36:10,839 --> 00:36:17,760
uh yes i'm not aware of it so

00:36:14,480 --> 00:36:20,160
if you can uh add an issue on the

00:36:17,760 --> 00:36:22,480
repository that would be cool with the

00:36:20,160 --> 00:36:25,359
link so we can look at it

00:36:22,480 --> 00:36:26,079
and that would be quite easy to add we

00:36:25,359 --> 00:36:28,240
can say

00:36:26,079 --> 00:36:30,960
that we are supporting the the motorized

00:36:28,240 --> 00:36:34,480
head used for the round shots

00:36:30,960 --> 00:36:38,160
which is uh which has a specific xml

00:36:34,480 --> 00:36:41,359
experience x drive or something

00:36:38,160 --> 00:36:43,839
x driver yeah but not this one yeah yeah

00:36:41,359 --> 00:36:45,040
this is uh if you put an issue on the

00:36:43,839 --> 00:36:46,720
github with the link

00:36:45,040 --> 00:36:48,560
that would be interesting to support

00:36:46,720 --> 00:36:51,119
sure

00:36:48,560 --> 00:36:53,680
uh does measurement follow the vfx

00:36:51,119 --> 00:36:57,040
reference platform good question

00:36:53,680 --> 00:37:00,079
yes we are trying to follow it

00:36:57,040 --> 00:37:00,560
as much as possible so not for qt

00:37:00,079 --> 00:37:03,359
because

00:37:00,560 --> 00:37:03,359
we have too much

00:37:03,839 --> 00:37:07,520
needs to have the latest versions but

00:37:06,800 --> 00:37:10,320
for

00:37:07,520 --> 00:37:11,440
all the steps for the compiler for the

00:37:10,320 --> 00:37:14,720
environment

00:37:11,440 --> 00:37:17,040
etc we are we are relying on it

00:37:14,720 --> 00:37:17,040
okay

00:37:18,079 --> 00:37:21,440
is it possible to use measuring with

00:37:20,640 --> 00:37:25,200
video

00:37:21,440 --> 00:37:27,200
with video inputs yeah that's rude yeah

00:37:25,200 --> 00:37:29,040
so in the new version when you drop a

00:37:27,200 --> 00:37:29,440
video in mushroom it will create a new

00:37:29,040 --> 00:37:33,040
node

00:37:29,440 --> 00:37:34,480
for extracting keyframe for your video

00:37:33,040 --> 00:37:37,440
[Music]

00:37:34,480 --> 00:37:38,000
so it's not a magic solution so you may

00:37:37,440 --> 00:37:40,079
have to

00:37:38,000 --> 00:37:41,680
make some adjustments on the keyframe

00:37:40,079 --> 00:37:44,560
selection because it's really difficult

00:37:41,680 --> 00:37:44,560
to find um

00:37:44,720 --> 00:37:48,560
systems that work for all kind of video

00:37:46,640 --> 00:37:52,640
it really depends if your video are

00:37:48,560 --> 00:37:55,119
really high quality if you are um

00:37:52,640 --> 00:37:55,680
if you have a lot of uncheck or or not

00:37:55,119 --> 00:37:58,400
if you

00:37:55,680 --> 00:38:00,000
if you are on the jaw and etc so you may

00:37:58,400 --> 00:38:01,520
have to adjust some parameters but it

00:38:00,000 --> 00:38:03,440
will extra keyframes

00:38:01,520 --> 00:38:05,359
and and then from that you have to put

00:38:03,440 --> 00:38:07,280
them back into mushroom again so it's

00:38:05,359 --> 00:38:09,760
not

00:38:07,280 --> 00:38:11,599
fully transparent yeah but we can say

00:38:09,760 --> 00:38:13,119
that some people using drones have been

00:38:11,599 --> 00:38:15,920
using mushroom already

00:38:13,119 --> 00:38:16,880
even to make a rough camera tracking of

00:38:15,920 --> 00:38:20,400
the drone so

00:38:16,880 --> 00:38:21,359
everything is possible does measure will

00:38:20,400 --> 00:38:23,760
create

00:38:21,359 --> 00:38:26,000
auto photo in the future yeah that's a

00:38:23,760 --> 00:38:28,000
request

00:38:26,000 --> 00:38:29,839
we have a lot so that's something we

00:38:28,000 --> 00:38:31,440
don't really need

00:38:29,839 --> 00:38:33,359
so but that's something that would

00:38:31,440 --> 00:38:36,320
really make sense

00:38:33,359 --> 00:38:38,000
and i hope that will be the association

00:38:36,320 --> 00:38:40,079
with the new association we will have

00:38:38,000 --> 00:38:44,839
resources to do this kind of

00:38:40,079 --> 00:38:48,000
features that are a bit out of our scope

00:38:44,839 --> 00:38:48,400
okay uh i don't think i don't know if we

00:38:48,000 --> 00:38:50,000
have

00:38:48,400 --> 00:38:51,839
some other questions in the live chat

00:38:50,000 --> 00:38:54,720
but because uh

00:38:51,839 --> 00:38:56,000
uh we're gonna check just just in case

00:38:54,720 --> 00:38:59,119
uh where

00:38:56,000 --> 00:39:00,240
why fabian is doing that of course we

00:38:59,119 --> 00:39:03,599
have a channel

00:39:00,240 --> 00:39:06,720
in the academy software slack

00:39:03,599 --> 00:39:08,880
so if anybody wants to ask for the

00:39:06,720 --> 00:39:10,720
question or if we miss something

00:39:08,880 --> 00:39:12,720
it's a good time for us to say that we

00:39:10,720 --> 00:39:15,839
can we can catch up

00:39:12,720 --> 00:39:19,680
later on in this channel of

00:39:15,839 --> 00:39:19,680
aswf slack

00:39:20,320 --> 00:39:24,320
another one would it be possible to

00:39:22,480 --> 00:39:27,680
pre-filter input images by

00:39:24,320 --> 00:39:30,640
quality as in detect noise as in

00:39:27,680 --> 00:39:32,160
detect motion blur out of focus remove

00:39:30,640 --> 00:39:35,280
or decrease the weight

00:39:32,160 --> 00:39:37,839
of images in the solver this is a

00:39:35,280 --> 00:39:39,920
question from a check yeah so that's

00:39:37,839 --> 00:39:43,520
really a good question

00:39:39,920 --> 00:39:44,400
so there are two things uh so it would

00:39:43,520 --> 00:39:48,400
make sense to

00:39:44,400 --> 00:39:52,400
uh to have a pre-filter step in input to

00:39:48,400 --> 00:39:54,880
really remove the images that are really

00:39:52,400 --> 00:39:56,320
too low quality but then it will also

00:39:54,880 --> 00:40:00,960
make sense to

00:39:56,320 --> 00:40:00,960
really take into account the blur

00:40:01,680 --> 00:40:06,720
and so there are some some researchers

00:40:04,960 --> 00:40:10,000
that are working on

00:40:06,720 --> 00:40:13,119
on focus stacking using mushroom

00:40:10,000 --> 00:40:15,280
and so i hope that with this

00:40:13,119 --> 00:40:16,480
collaboration we will be able to improve

00:40:15,280 --> 00:40:19,839
that

00:40:16,480 --> 00:40:19,839
some people from australia yeah

00:40:19,920 --> 00:40:26,560
do you have any questions if not again

00:40:23,440 --> 00:40:30,800
you can use the slack channel

00:40:26,560 --> 00:40:39,839
i think let me check back again

00:40:30,800 --> 00:40:39,839
this one is done yeah

00:40:42,319 --> 00:40:45,520
okay i think that's it thank you

00:40:44,800 --> 00:40:48,800
everyone for

00:40:45,520 --> 00:40:51,760
joining us yes uh again

00:40:48,800 --> 00:40:52,800
good update guys thank you thank you for

00:40:51,760 --> 00:40:54,160
the compliment

00:40:52,800 --> 00:40:56,000
again we want to thank you the academy

00:40:54,160 --> 00:40:57,040
software foundation to invite us to this

00:40:56,000 --> 00:41:00,400
uh

00:40:57,040 --> 00:41:02,560
open source panel uh because it's been a

00:41:00,400 --> 00:41:04,839
an interesting year as everybody says

00:41:02,560 --> 00:41:07,920
for everybody

00:41:04,839 --> 00:41:08,880
um uh we have we have another one we can

00:41:07,920 --> 00:41:11,119
take another one because

00:41:08,880 --> 00:41:13,359
does it affect mushroom if the images

00:41:11,119 --> 00:41:15,359
are optically or digitally stabilized on

00:41:13,359 --> 00:41:17,359
the camera level that's a good one

00:41:15,359 --> 00:41:19,200
yeah yeah it will uh it will affect

00:41:17,359 --> 00:41:22,720
there

00:41:19,200 --> 00:41:26,000
so yeah as much as possible we try to

00:41:22,720 --> 00:41:27,839
get the raw images yeah yeah if you have

00:41:26,000 --> 00:41:30,640
a solution to disable it that

00:41:27,839 --> 00:41:32,319
that would uh help i know that on the

00:41:30,640 --> 00:41:35,680
other side you will get more motion blur

00:41:32,319 --> 00:41:37,760
and uh but yeah it will affect the

00:41:35,680 --> 00:41:39,760
geometric estimation but uh i have not

00:41:37,760 --> 00:41:42,720
made an intensive test to see

00:41:39,760 --> 00:41:43,760
how far it will decrease but in

00:41:42,720 --> 00:41:47,280
principle it will

00:41:43,760 --> 00:41:50,960
decrease really okay

00:41:47,280 --> 00:41:53,599
i think we are good uh so

00:41:50,960 --> 00:41:55,520
thanks again take care of yourself take

00:41:53,599 --> 00:41:57,839
care of your beloved and uh

00:41:55,520 --> 00:41:59,839
we'll catch you up online uh due over

00:41:57,839 --> 00:42:02,960
the the different uh channels

00:41:59,839 --> 00:42:06,880
you have here the links to join us

00:42:02,960 --> 00:42:12,240
and we can pick up the good work

00:42:06,880 --> 00:42:12,240

YouTube URL: https://www.youtube.com/watch?v=oa_FofFYiYo


