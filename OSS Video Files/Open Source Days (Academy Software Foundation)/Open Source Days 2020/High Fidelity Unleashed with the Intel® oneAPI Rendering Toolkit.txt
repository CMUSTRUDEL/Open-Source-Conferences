Title: High Fidelity Unleashed with the Intel® oneAPI Rendering Toolkit
Publication date: 2020-08-24
Playlist: Open Source Days 2020
Description: 
	High Fidelity Unleashed with the Intel® oneAPI Rendering Toolkit
Speakers: Sean Mcduffee, Greg Johnson, Attila Afra, Jefferson Amstutz

For more information about the Academy Software Foundation go to: https://www.aswf.io/

Intel will present the oneAPI Rendering Toolkit product updates of their suite of open source libraries for high performance ray tracing. Hear more about their Open Volume Kernel library which provides high performance volume traversal and sampling functionality for a variety of volume types for a variety of computations optimized for the latest processors featuring SSE, AVX, AVX2, and AVX512 instructions enabling extreme performance for volume rendering engineers. Also hear about Open Image Denoise, which provides an open, high-quality, efficient and easy-to-use denoising library for path traced images. In conclusion this talk will discuss the collaboration with ANARI relating to the Analytic Rendering Interface project under the Khronos Group governance. This is a cross industry, open project aimed at cleanly separating the scene descriptions that Digital Content Creators (DCC’s) provide and the various backend rendering implementations which then generate images.
Captions: 
	00:00:00,320 --> 00:00:05,120
okay i think we can start um

00:00:03,199 --> 00:00:07,520
welcome to the second day of open source

00:00:05,120 --> 00:00:08,160
days we're happy to be here with you

00:00:07,520 --> 00:00:10,000
today

00:00:08,160 --> 00:00:11,200
and we're from intel we're going to be

00:00:10,000 --> 00:00:15,679
sharing with you the

00:00:11,200 --> 00:00:16,640
open source uh intel one api rendering

00:00:15,679 --> 00:00:19,039
toolkit

00:00:16,640 --> 00:00:20,160
um just a little bit about who we are

00:00:19,039 --> 00:00:21,039
there's gonna be a number of speakers

00:00:20,160 --> 00:00:22,880
today

00:00:21,039 --> 00:00:25,199
we're part of the advanced rendering and

00:00:22,880 --> 00:00:27,359
visualization architecture group or arba

00:00:25,199 --> 00:00:29,359
inside of intel we're responsible for

00:00:27,359 --> 00:00:31,439
a number of products all fully open

00:00:29,359 --> 00:00:33,040
sourced some of which

00:00:31,439 --> 00:00:34,399
this audience may be already familiar

00:00:33,040 --> 00:00:35,360
with and other ones that were today

00:00:34,399 --> 00:00:38,559
we're going to present

00:00:35,360 --> 00:00:41,200
are a bit newer we're

00:00:38,559 --> 00:00:42,800
known for the embry open image denoise

00:00:41,200 --> 00:00:45,840
open bkl

00:00:42,800 --> 00:00:48,320
offspring open swerve and uh

00:00:45,840 --> 00:00:50,239
inari in part with a number of other

00:00:48,320 --> 00:00:52,640
partners from the cronus group

00:00:50,239 --> 00:00:55,199
once again like i said we're fully open

00:00:52,640 --> 00:00:57,440
sourced every project we work on

00:00:55,199 --> 00:00:59,520
um just quickly we're going to do a

00:00:57,440 --> 00:01:02,480
quick update for emory for people

00:00:59,520 --> 00:01:04,640
that may already be using embry and just

00:01:02,480 --> 00:01:07,200
updates over the last year

00:01:04,640 --> 00:01:08,320
for people that just a quick overview

00:01:07,200 --> 00:01:11,119
for embry embry

00:01:08,320 --> 00:01:12,799
is essentially a bounty volume hierarchy

00:01:11,119 --> 00:01:15,840
that offers ray geometry

00:01:12,799 --> 00:01:16,320
intersections optimized for all the

00:01:15,840 --> 00:01:18,400
intel

00:01:16,320 --> 00:01:21,360
instruction set architectures from sse

00:01:18,400 --> 00:01:24,240
through avx-512

00:01:21,360 --> 00:01:26,080
over the last year we've added a number

00:01:24,240 --> 00:01:26,960
of new curved geometry types such as

00:01:26,080 --> 00:01:29,920
capital rom

00:01:26,960 --> 00:01:31,600
round linear curves cone curves a new

00:01:29,920 --> 00:01:34,000
compact poly's

00:01:31,600 --> 00:01:36,799
cmake option allows double index index

00:01:34,000 --> 00:01:39,200
quad leaves reduces memory

00:01:36,799 --> 00:01:40,799
added support for multi-level instancing

00:01:39,200 --> 00:01:42,720
we've also added support for point

00:01:40,799 --> 00:01:44,399
queries so closest point nearest

00:01:42,720 --> 00:01:46,720
neighbors

00:01:44,399 --> 00:01:47,920
implemented a new min width feature for

00:01:46,720 --> 00:01:49,280
curves and points

00:01:47,920 --> 00:01:50,880
allows the tracker to increase the

00:01:49,280 --> 00:01:51,280
radius in a distance dependent way this

00:01:50,880 --> 00:01:54,320
is

00:01:51,280 --> 00:01:57,759
helpful for anti-aliasing techniques

00:01:54,320 --> 00:01:58,799
added quaternion motion blur the rtc

00:01:57,759 --> 00:02:00,399
commit scene

00:01:58,799 --> 00:02:02,000
function can now get called during

00:02:00,399 --> 00:02:03,040
rendering for multiple threads to lazily

00:02:02,000 --> 00:02:05,280
build geometry

00:02:03,040 --> 00:02:07,119
this improves on the previous

00:02:05,280 --> 00:02:08,879
implementation we had

00:02:07,119 --> 00:02:11,120
geometries can also now get attached to

00:02:08,879 --> 00:02:12,879
multiple scenes at the same time

00:02:11,120 --> 00:02:14,239
and we've added collision detection

00:02:12,879 --> 00:02:16,720
support so now embry

00:02:14,239 --> 00:02:20,400
supports collision detection broad phase

00:02:16,720 --> 00:02:21,920
collision detection for user geometries

00:02:20,400 --> 00:02:23,920
and there's been numerous performance

00:02:21,920 --> 00:02:24,640
and robustness improvements and coming

00:02:23,920 --> 00:02:27,760
very soon

00:02:24,640 --> 00:02:29,680
in the next the next release will be uh

00:02:27,760 --> 00:02:32,239
morton code and refilling builders for

00:02:29,680 --> 00:02:34,160
instance geometry

00:02:32,239 --> 00:02:36,400
um that's pretty much all we wanted to

00:02:34,160 --> 00:02:37,440
talk about with embry today if there are

00:02:36,400 --> 00:02:39,200
questions though

00:02:37,440 --> 00:02:40,480
um feel free to ask any questions on

00:02:39,200 --> 00:02:42,800
embry we can get to the

00:02:40,480 --> 00:02:44,800
to the end we want to concentrate on a

00:02:42,800 --> 00:02:47,200
number of other projects that we do

00:02:44,800 --> 00:02:48,800
uh first will be up attila afra with

00:02:47,200 --> 00:02:51,920
open image denoise

00:02:48,800 --> 00:02:54,959
and then greg johnson with openvkl

00:02:51,920 --> 00:02:56,640
and then jeff absence with anari so i'll

00:02:54,959 --> 00:02:59,920
just hand it off to

00:02:56,640 --> 00:03:03,120
attila for open image denoise

00:02:59,920 --> 00:03:06,319
thanks sean so i will quickly

00:03:03,120 --> 00:03:08,159
introduce openmhd noise a library for

00:03:06,319 --> 00:03:10,480
denoising for ray tracing

00:03:08,159 --> 00:03:11,519
i will briefly go into some details how

00:03:10,480 --> 00:03:14,800
it works

00:03:11,519 --> 00:03:17,599
uh how the api works as well and

00:03:14,800 --> 00:03:20,400
what's planned for the future so let's

00:03:17,599 --> 00:03:20,400
get started

00:03:25,920 --> 00:03:30,000
so denoising nowadays is getting more

00:03:28,879 --> 00:03:32,080
and more popular

00:03:30,000 --> 00:03:33,920
because noise is pretty much inevitable

00:03:32,080 --> 00:03:34,959
in monte carlo ray tracing path tracing

00:03:33,920 --> 00:03:37,200
solutions

00:03:34,959 --> 00:03:38,959
um so this means essentially that in

00:03:37,200 --> 00:03:40,879
many cases rendering fully converged

00:03:38,959 --> 00:03:43,040
images is just too expensive

00:03:40,879 --> 00:03:44,640
so the solution is basically rendering

00:03:43,040 --> 00:03:45,920
partially converged images and then

00:03:44,640 --> 00:03:46,720
denoising them with some kind of

00:03:45,920 --> 00:03:48,799
algorithm

00:03:46,720 --> 00:03:49,840
the movie industry is also already using

00:03:48,799 --> 00:03:54,480
this approach

00:03:49,840 --> 00:03:57,599
where it's possible to get um it seems

00:03:54,480 --> 00:03:58,959
the slides are going forward without me

00:03:57,599 --> 00:04:02,239
clicking on them

00:03:58,959 --> 00:04:05,439
sorry about that okay so

00:04:02,239 --> 00:04:08,799
um it's possible to get um two to 10x

00:04:05,439 --> 00:04:09,280
improvements uh with denoising without

00:04:08,799 --> 00:04:11,840
losing

00:04:09,280 --> 00:04:13,439
a significant amount of quality and it's

00:04:11,840 --> 00:04:16,560
also actually crucial

00:04:13,439 --> 00:04:18,479
for um real-time applications like games

00:04:16,560 --> 00:04:19,919
where it's only possible to render only

00:04:18,479 --> 00:04:21,600
a few samples per pixel

00:04:19,919 --> 00:04:23,600
so without denoising the results will be

00:04:21,600 --> 00:04:25,120
just completely unusable

00:04:23,600 --> 00:04:27,199
so the solution is to use some kind of

00:04:25,120 --> 00:04:29,440
denoising solution and interopen which

00:04:27,199 --> 00:04:32,320
denoise is a denoising library which

00:04:29,440 --> 00:04:35,440
solves this problem so this library is

00:04:32,320 --> 00:04:37,840
specifically targeted for ray tracing

00:04:35,440 --> 00:04:39,919
it provides a set of high quality deep

00:04:37,840 --> 00:04:42,160
learning based denoising filters

00:04:39,919 --> 00:04:44,240
and these filters are suitable for both

00:04:42,160 --> 00:04:47,360
interactive and offline rendering

00:04:44,240 --> 00:04:49,360
and it's also possible um to uh

00:04:47,360 --> 00:04:50,880
train the deep learning based filters

00:04:49,360 --> 00:04:52,880
shipped with the library

00:04:50,880 --> 00:04:54,400
using the included uh training toolkit

00:04:52,880 --> 00:04:55,199
which is based on pi torch i will

00:04:54,400 --> 00:04:58,639
mention this

00:04:55,199 --> 00:05:01,919
a bit later the library

00:04:58,639 --> 00:05:02,880
runs uh on basically almost any modern

00:05:01,919 --> 00:05:05,440
cpu

00:05:02,880 --> 00:05:07,840
the only requirement is having ssc 4.1

00:05:05,440 --> 00:05:09,520
and it of course takes advantage of

00:05:07,840 --> 00:05:11,199
more advanced instructions such up to

00:05:09,520 --> 00:05:13,840
avx 512 as well

00:05:11,199 --> 00:05:16,479
it runs on all three major popular

00:05:13,840 --> 00:05:19,600
platforms linux windows and mac os

00:05:16,479 --> 00:05:22,000
and the api was designed to be clean

00:05:19,600 --> 00:05:22,880
and minimal so it can be integrated very

00:05:22,000 --> 00:05:24,639
easily into

00:05:22,880 --> 00:05:26,880
existing rendering solutions in many

00:05:24,639 --> 00:05:30,080
cases the integration could be completed

00:05:26,880 --> 00:05:30,080
in just a few hours

00:05:31,520 --> 00:05:37,360
so let's see the denoising filters that

00:05:35,280 --> 00:05:39,199
the library contains so the library

00:05:37,360 --> 00:05:41,759
contains currently two

00:05:39,199 --> 00:05:42,960
filters all retracing oriented one of

00:05:41,759 --> 00:05:46,160
them is a generic

00:05:42,960 --> 00:05:46,960
filter called rt which uh it aims for

00:05:46,160 --> 00:05:50,000
denoising

00:05:46,960 --> 00:05:51,919
um generic path raised final frames

00:05:50,000 --> 00:05:53,120
and there's also dedicated uh lightmap

00:05:51,919 --> 00:05:56,319
denoising filter called

00:05:53,120 --> 00:05:57,280
alt-rt light map which provides higher

00:05:56,319 --> 00:06:00,639
quality for

00:05:57,280 --> 00:06:03,520
um ray traced light maps

00:06:00,639 --> 00:06:04,720
these filters specifically the generic

00:06:03,520 --> 00:06:06,720
filter

00:06:04,720 --> 00:06:08,240
accepts potentially multiple input

00:06:06,720 --> 00:06:09,600
buffers of course there's the color

00:06:08,240 --> 00:06:13,280
buffer which could be either

00:06:09,600 --> 00:06:16,319
hdr or ldr and there are also

00:06:13,280 --> 00:06:16,960
ways to provide auxiliary uh feature

00:06:16,319 --> 00:06:18,639
buffers

00:06:16,960 --> 00:06:21,199
which are completely optional for

00:06:18,639 --> 00:06:22,720
example it's possible to provide albedo

00:06:21,199 --> 00:06:24,479
and normal buffers which can

00:06:22,720 --> 00:06:25,280
significantly improve the denoising

00:06:24,479 --> 00:06:27,280
quality

00:06:25,280 --> 00:06:29,039
these buffers can be noisy as well just

00:06:27,280 --> 00:06:29,520
like the color so this doesn't have to

00:06:29,039 --> 00:06:35,840
be

00:06:29,520 --> 00:06:35,840
noise free

00:06:41,680 --> 00:06:46,000
so let's see uh the input and output

00:06:44,160 --> 00:06:48,720
buffers for the filters

00:06:46,000 --> 00:06:50,080
so there's um of the color buffer and

00:06:48,720 --> 00:06:51,120
then the option will be the normal

00:06:50,080 --> 00:06:53,039
buffers

00:06:51,120 --> 00:06:55,039
so here we can see an example for a

00:06:53,039 --> 00:06:56,639
scene rendered with patch tracing and

00:06:55,039 --> 00:06:57,039
providing these three input buffers

00:06:56,639 --> 00:06:58,720
where

00:06:57,039 --> 00:07:00,400
the color is the most the noisiest one

00:06:58,720 --> 00:07:01,840
but the other two buffers are also noisy

00:07:00,400 --> 00:07:03,120
just they are not really visible in this

00:07:01,840 --> 00:07:04,720
small size

00:07:03,120 --> 00:07:06,240
providing these buffers to the library

00:07:04,720 --> 00:07:11,039
will create the denoised

00:07:06,240 --> 00:07:13,919
image on the right so basically this is

00:07:11,039 --> 00:07:15,440
how it works now just to mention a

00:07:13,919 --> 00:07:16,800
little bit about the actual algorithm

00:07:15,440 --> 00:07:19,360
this is based on so

00:07:16,800 --> 00:07:19,919
the algorithms in openmhd noise are

00:07:19,360 --> 00:07:22,800
based on

00:07:19,919 --> 00:07:25,360
uh deep learning approaches specifically

00:07:22,800 --> 00:07:27,360
it uses a convolutional neural network

00:07:25,360 --> 00:07:29,680
which has in this case a unit

00:07:27,360 --> 00:07:31,759
architecture

00:07:29,680 --> 00:07:33,599
it provides a good balance between

00:07:31,759 --> 00:07:35,840
quality and performance

00:07:33,599 --> 00:07:37,599
so it's it provides a quality that is

00:07:35,840 --> 00:07:38,160
suitable for final frame rendering but

00:07:37,599 --> 00:07:40,720
also

00:07:38,160 --> 00:07:42,840
it's fast enough to use it in

00:07:40,720 --> 00:07:45,039
interactive applications on many core

00:07:42,840 --> 00:07:46,879
cpus

00:07:45,039 --> 00:07:49,120
since this is a deep learning based

00:07:46,879 --> 00:07:51,919
filter so it needs to

00:07:49,120 --> 00:07:53,280
have a trained model as well for it and

00:07:51,919 --> 00:07:54,560
the library ships with a set of

00:07:53,280 --> 00:07:58,160
pre-trained models but

00:07:54,560 --> 00:08:00,000
it's not necessary to use them users can

00:07:58,160 --> 00:08:02,160
simply train these models with their own

00:08:00,000 --> 00:08:02,879
data sets and these can train models can

00:08:02,160 --> 00:08:06,160
be

00:08:02,879 --> 00:08:06,160
specified through the api

00:08:07,280 --> 00:08:11,599
so let's see a quick example of how open

00:08:09,840 --> 00:08:13,120
image denoise works what kind of results

00:08:11,599 --> 00:08:14,240
it can produce so here we can see a

00:08:13,120 --> 00:08:17,680
frame from

00:08:14,240 --> 00:08:20,479
um the spring open blender

00:08:17,680 --> 00:08:24,560
open movie this was rendered with the

00:08:20,479 --> 00:08:28,240
cycles render at 32 samples per pixel

00:08:24,560 --> 00:08:31,759
it's quite noisy as we can see let's see

00:08:28,240 --> 00:08:34,159
what's the denoising output uh if we use

00:08:31,759 --> 00:08:34,800
uh i'll be the normal buffers as well so

00:08:34,159 --> 00:08:40,320
with this

00:08:34,800 --> 00:08:42,719
um we can achieve the ssim of 9.0.9

00:08:40,320 --> 00:08:44,159
and just to see how well how the

00:08:42,719 --> 00:08:48,000
reference looks like

00:08:44,159 --> 00:08:48,000
this is this is the ground truth

00:08:48,480 --> 00:08:53,920
um let's see another example so

00:08:51,760 --> 00:08:55,200
this image was rendered with the corona

00:08:53,920 --> 00:08:58,560
renderer

00:08:55,200 --> 00:09:00,560
at 16 samples per pixel let's

00:08:58,560 --> 00:09:04,000
see the denoised version also using

00:09:00,560 --> 00:09:04,000
albedo normal buffers as well

00:09:04,160 --> 00:09:08,560
so this is the denoised version as a sim

00:09:06,160 --> 00:09:11,839
of 0.91

00:09:08,560 --> 00:09:13,519
roughly and finally

00:09:11,839 --> 00:09:16,000
this is the reference image so that

00:09:13,519 --> 00:09:18,800
there is a difference of course

00:09:16,000 --> 00:09:20,399
but it's still an acceptable compromise

00:09:18,800 --> 00:09:22,720
in many cases despite the fact that it's

00:09:20,399 --> 00:09:24,480
just 16 samples per pixel

00:09:22,720 --> 00:09:26,640
of course the library works well with

00:09:24,480 --> 00:09:29,600
higher sample counts as well it's just

00:09:26,640 --> 00:09:30,000
more visible in presentations like this

00:09:29,600 --> 00:09:32,160
to

00:09:30,000 --> 00:09:33,680
see lower sample counts just a quick

00:09:32,160 --> 00:09:35,360
mention about the performance

00:09:33,680 --> 00:09:37,200
just to give you a rough idea of the

00:09:35,360 --> 00:09:40,959
ballpark performance that

00:09:37,200 --> 00:09:43,040
open which dns can achieve on a 56 core

00:09:40,959 --> 00:09:44,000
machine with avx 512 support it's

00:09:43,040 --> 00:09:46,399
possible

00:09:44,000 --> 00:09:48,399
to denoise a 4k image in around 400

00:09:46,399 --> 00:09:49,680
milliseconds a full hd image in around

00:09:48,399 --> 00:09:53,839
100 milliseconds

00:09:49,680 --> 00:09:57,360
and a 720p imaging around 50 to 60

00:09:53,839 --> 00:10:00,480
milliseconds so given enough cores

00:09:57,360 --> 00:10:04,640
uh it's possible to use um open image

00:10:00,480 --> 00:10:06,720
dns for interactive applications as well

00:10:04,640 --> 00:10:07,680
i will just give a quick overview of the

00:10:06,720 --> 00:10:09,680
api

00:10:07,680 --> 00:10:11,279
so the api is quite similar to the embry

00:10:09,680 --> 00:10:14,880
api in design

00:10:11,279 --> 00:10:17,040
and philosophy it's um it has c and c

00:10:14,880 --> 00:10:19,519
plus plus versions as well so it has a c

00:10:17,040 --> 00:10:22,160
plus wrapper included too

00:10:19,519 --> 00:10:23,839
um the api is object oriented and there

00:10:22,160 --> 00:10:26,160
are basically only three

00:10:23,839 --> 00:10:28,240
uh objects available in the api there's

00:10:26,160 --> 00:10:30,320
a device object similar to embry

00:10:28,240 --> 00:10:32,240
a buffer object and a filter object

00:10:30,320 --> 00:10:35,519
these are all reference counted

00:10:32,240 --> 00:10:37,760
and this means that the library is

00:10:35,519 --> 00:10:39,040
is quite compact and should be quite

00:10:37,760 --> 00:10:41,360
easy to use

00:10:39,040 --> 00:10:43,040
so let's see a quick example how this

00:10:41,360 --> 00:10:45,040
works

00:10:43,040 --> 00:10:46,959
the images can be denoised with these

00:10:45,040 --> 00:10:47,839
filter objects and those can be created

00:10:46,959 --> 00:10:50,880
by first

00:10:47,839 --> 00:10:52,480
creating a device object um after the

00:10:50,880 --> 00:10:54,000
creation of the device object we can

00:10:52,480 --> 00:10:54,640
just create the filter selecting what

00:10:54,000 --> 00:10:56,640
kind of

00:10:54,640 --> 00:10:58,720
filter would like to use in this case we

00:10:56,640 --> 00:11:00,000
use the generic rt filter

00:10:58,720 --> 00:11:01,600
next we have to set the filter

00:11:00,000 --> 00:11:02,399
parameters which i will show in the next

00:11:01,600 --> 00:11:04,000
slide

00:11:02,399 --> 00:11:06,320
we have to commit the changes before

00:11:04,000 --> 00:11:09,040
using the filter and we just executed

00:11:06,320 --> 00:11:09,839
and then finally we clean up um so this

00:11:09,040 --> 00:11:12,079
is the basic

00:11:09,839 --> 00:11:14,640
um step these are the basic steps needed

00:11:12,079 --> 00:11:16,480
to denoise an image

00:11:14,640 --> 00:11:17,760
let's see what happens in the filter

00:11:16,480 --> 00:11:22,399
setup

00:11:17,760 --> 00:11:22,399
so the filter setup is also quite simple

00:11:26,839 --> 00:11:29,839
sorry

00:11:40,839 --> 00:11:43,839
oops

00:11:52,880 --> 00:11:57,839
okay sorry about this

00:12:07,519 --> 00:12:14,480
okay so first um either we need to use

00:12:11,920 --> 00:12:16,240
normal buffer objects or so called

00:12:14,480 --> 00:12:17,680
shared buffers where we don't create any

00:12:16,240 --> 00:12:20,160
buffer objects just

00:12:17,680 --> 00:12:21,200
pass pointers that the application

00:12:20,160 --> 00:12:24,480
manages

00:12:21,200 --> 00:12:25,279
um just like with embry we provide what

00:12:24,480 --> 00:12:27,760
type of

00:12:25,279 --> 00:12:29,920
buffer we specify the color albedo

00:12:27,760 --> 00:12:32,320
normal or the output itself

00:12:29,920 --> 00:12:33,279
and we can also specify offsets and

00:12:32,320 --> 00:12:35,760
strides

00:12:33,279 --> 00:12:38,480
so it's quite flexible and different

00:12:35,760 --> 00:12:40,399
image layouts are possible

00:12:38,480 --> 00:12:42,079
there is also a way to specify whether

00:12:40,399 --> 00:12:43,920
the images hdr ldr and some other

00:12:42,079 --> 00:12:47,760
parameters so this is the basic

00:12:43,920 --> 00:12:49,760
idea of how to use the library

00:12:47,760 --> 00:12:51,279
i would also like to mention the

00:12:49,760 --> 00:12:52,240
training toolkit which was introduced

00:12:51,279 --> 00:12:55,680
quite recently

00:12:52,240 --> 00:12:57,360
to the library uh it um the source code

00:12:55,680 --> 00:12:59,120
ships with a pytorch-based neural

00:12:57,360 --> 00:13:01,519
network training toolkit which consists

00:12:59,120 --> 00:13:03,680
of multiple python based scripts

00:13:01,519 --> 00:13:06,079
with these the users can train the

00:13:03,680 --> 00:13:07,839
filters with their own data sets which

00:13:06,079 --> 00:13:09,600
has the advantage that it's possible to

00:13:07,839 --> 00:13:11,680
optimize the filters

00:13:09,600 --> 00:13:13,680
for custom renderers sample counts

00:13:11,680 --> 00:13:16,320
content types or scenes

00:13:13,680 --> 00:13:16,880
so it can potentially improve quality

00:13:16,320 --> 00:13:19,040
and

00:13:16,880 --> 00:13:20,160
these user trained filters can be either

00:13:19,040 --> 00:13:22,160
built into the library

00:13:20,160 --> 00:13:23,200
or is these can be loaded at runtime

00:13:22,160 --> 00:13:24,880
through the api

00:13:23,200 --> 00:13:26,320
so there are multiple ways to use these

00:13:24,880 --> 00:13:30,720
custom uh

00:13:26,320 --> 00:13:30,720
custom uhly trained filter models

00:13:31,440 --> 00:13:36,399
um also i would like to mention uh

00:13:34,320 --> 00:13:37,839
what's what is planned in the future for

00:13:36,399 --> 00:13:40,560
openmhd noise

00:13:37,839 --> 00:13:42,959
so we're continuously uh improving the

00:13:40,560 --> 00:13:45,120
quality and performance as well

00:13:42,959 --> 00:13:46,000
um one of the next features that we'll

00:13:45,120 --> 00:13:47,839
introduce is

00:13:46,000 --> 00:13:50,079
directional lightmap denoising so we

00:13:47,839 --> 00:13:52,160
have dedicated

00:13:50,079 --> 00:13:54,560
filters for not just regular lightness

00:13:52,160 --> 00:13:56,720
but directional ones as well for example

00:13:54,560 --> 00:13:58,000
uh using spherical harmonic basis or

00:13:56,720 --> 00:14:00,560
some other bases

00:13:58,000 --> 00:14:01,360
um we're also working on adding temporal

00:14:00,560 --> 00:14:04,079
coherence

00:14:01,360 --> 00:14:04,880
where denoising animations would result

00:14:04,079 --> 00:14:08,160
in

00:14:04,880 --> 00:14:11,199
much better temporal stability and

00:14:08,160 --> 00:14:12,639
finally we are also working on gpu

00:14:11,199 --> 00:14:16,000
support as well

00:14:12,639 --> 00:14:19,279
the api is hardware agnostic so

00:14:16,000 --> 00:14:21,040
uh basically adding a new type of device

00:14:19,279 --> 00:14:23,279
will not require changes on the

00:14:21,040 --> 00:14:25,440
application site perhaps only just

00:14:23,279 --> 00:14:26,320
picking which device to use which could

00:14:25,440 --> 00:14:30,160
be also

00:14:26,320 --> 00:14:31,839
using a default one so it shouldn't

00:14:30,160 --> 00:14:35,519
cause any disruption in the

00:14:31,839 --> 00:14:38,480
applications um so as a conclusion

00:14:35,519 --> 00:14:39,920
um so op intel openmhd noise is as we've

00:14:38,480 --> 00:14:40,959
seen an open source denoising library

00:14:39,920 --> 00:14:42,639
for retracing

00:14:40,959 --> 00:14:44,079
it's suitable for both interactive and

00:14:42,639 --> 00:14:46,160
final frame rendering

00:14:44,079 --> 00:14:47,680
it runs on all modern cpus that support

00:14:46,160 --> 00:14:50,720
ssc 4.1

00:14:47,680 --> 00:14:54,240
it has a simple clean api and

00:14:50,720 --> 00:14:56,519
you can download it from github and

00:14:54,240 --> 00:14:58,000
multiple resources are available at

00:14:56,519 --> 00:15:00,480
openimagedenoise.org where you can

00:14:58,000 --> 00:15:01,440
find the detailed api documentation

00:15:00,480 --> 00:15:03,360
example code

00:15:01,440 --> 00:15:05,600
and a gallery as well for more example

00:15:03,360 --> 00:15:13,510
images

00:15:05,600 --> 00:15:17,669
thank you

00:15:13,510 --> 00:15:17,669
[Music]

00:15:23,839 --> 00:15:27,120
okay i am greg johnson i will be

00:15:26,160 --> 00:15:29,600
presenting

00:15:27,120 --> 00:15:31,040
intel open volume kernel library or

00:15:29,600 --> 00:15:34,320
openvkl

00:15:31,040 --> 00:15:37,120
so this is the the newest component of

00:15:34,320 --> 00:15:39,680
rendering toolkit so today i'll give a

00:15:37,120 --> 00:15:42,880
brief overview of openpkl

00:15:39,680 --> 00:15:44,720
including describing its design goals

00:15:42,880 --> 00:15:47,600
i'll talk in some detail about its

00:15:44,720 --> 00:15:50,720
supported volume types as well as the

00:15:47,600 --> 00:15:52,880
apis supported on those volume types

00:15:50,720 --> 00:15:54,480
and then wrap up with resources where

00:15:52,880 --> 00:15:57,680
you could find

00:15:54,480 --> 00:16:00,000
additional information so openvkl

00:15:57,680 --> 00:16:00,800
is part of intel one api rendering

00:16:00,000 --> 00:16:03,120
toolkit

00:16:00,800 --> 00:16:03,839
which is an open source set of libraries

00:16:03,120 --> 00:16:06,560
for

00:16:03,839 --> 00:16:08,959
advanced rendering and visualization in

00:16:06,560 --> 00:16:09,519
terms of a typical application software

00:16:08,959 --> 00:16:11,759
stack

00:16:09,519 --> 00:16:13,120
uh openvkl sits at the same level as

00:16:11,759 --> 00:16:15,519
embry um

00:16:13,120 --> 00:16:16,399
as a low-level kernel library uh so

00:16:15,519 --> 00:16:19,120
today

00:16:16,399 --> 00:16:20,560
uh vkl is used extensively within osprey

00:16:19,120 --> 00:16:23,199
which is our scalable

00:16:20,560 --> 00:16:24,480
ray tracing based rendering engine and

00:16:23,199 --> 00:16:27,360
there it provides

00:16:24,480 --> 00:16:28,240
all of its volume functionality enabling

00:16:27,360 --> 00:16:32,399
all of its

00:16:28,240 --> 00:16:35,440
volume rendering features

00:16:32,399 --> 00:16:38,079
so open vkl can also be used within

00:16:35,440 --> 00:16:39,839
any renderer or any application to

00:16:38,079 --> 00:16:43,680
improve volume rendering features

00:16:39,839 --> 00:16:46,560
or performance it has a cmd focused

00:16:43,680 --> 00:16:48,240
internal implementation with most

00:16:46,560 --> 00:16:50,320
kernels written in ispc

00:16:48,240 --> 00:16:52,079
and so we're able to take a very good

00:16:50,320 --> 00:16:55,399
advantage of

00:16:52,079 --> 00:16:58,240
cpu vector instructions uh up through uh

00:16:55,399 --> 00:17:01,040
avx-512

00:16:58,240 --> 00:17:02,079
so intel has announced the intel xe

00:17:01,040 --> 00:17:04,720
architecture

00:17:02,079 --> 00:17:06,000
gpus and so we won't talk in detail

00:17:04,720 --> 00:17:08,640
about that here

00:17:06,000 --> 00:17:10,559
uh other than to say that open vkl and

00:17:08,640 --> 00:17:13,199
the other libraries shown here

00:17:10,559 --> 00:17:15,039
uh will support uh those libraries in

00:17:13,199 --> 00:17:18,240
the future

00:17:15,039 --> 00:17:21,280
uh so what are the goals of openvkl

00:17:18,240 --> 00:17:22,319
so put very briefly open dkl intends to

00:17:21,280 --> 00:17:25,760
be

00:17:22,319 --> 00:17:28,000
an embry-like library for volumes and so

00:17:25,760 --> 00:17:30,559
as part of this one of bkl's goals to

00:17:28,000 --> 00:17:32,720
support a diverse set of volume types

00:17:30,559 --> 00:17:34,080
just like embry supports a diverse set

00:17:32,720 --> 00:17:36,559
of geometries

00:17:34,080 --> 00:17:37,679
and so this enables applications and

00:17:36,559 --> 00:17:40,160
renderers

00:17:37,679 --> 00:17:42,400
to support many types of volumes through

00:17:40,160 --> 00:17:45,280
a single coherent api

00:17:42,400 --> 00:17:46,000
and generically written renderers and so

00:17:45,280 --> 00:17:48,000
this allows

00:17:46,000 --> 00:17:49,840
applications to more easily make runtime

00:17:48,000 --> 00:17:51,440
decisions about uh which volume

00:17:49,840 --> 00:17:53,280
representation to use

00:17:51,440 --> 00:17:55,120
uh and as we'll see there are trade-offs

00:17:53,280 --> 00:17:56,480
between uh between these different

00:17:55,120 --> 00:17:58,559
volume types

00:17:56,480 --> 00:18:00,160
so it's important to allow applications

00:17:58,559 --> 00:18:03,200
uh to make those

00:18:00,160 --> 00:18:04,320
switches between volumes with minimal or

00:18:03,200 --> 00:18:07,520
no changes

00:18:04,320 --> 00:18:08,080
to application code so open vkl does

00:18:07,520 --> 00:18:10,960
provide

00:18:08,080 --> 00:18:13,679
a flexible set of apis primarily

00:18:10,960 --> 00:18:16,720
targeted at rendering applications

00:18:13,679 --> 00:18:19,760
and so very specifically authoring and

00:18:16,720 --> 00:18:22,720
volume manipulation workflows

00:18:19,760 --> 00:18:24,880
are out of scope for openpkl we are

00:18:22,720 --> 00:18:27,200
really laser focused on

00:18:24,880 --> 00:18:28,720
supporting rendering applications in the

00:18:27,200 --> 00:18:32,880
apis those need

00:18:28,720 --> 00:18:35,520
uh specifically uh so we can talk about

00:18:32,880 --> 00:18:36,400
open bkl's features both in terms of its

00:18:35,520 --> 00:18:39,120
supported

00:18:36,400 --> 00:18:42,080
volume types as well as the apis

00:18:39,120 --> 00:18:44,080
supported on those volumes and so uh for

00:18:42,080 --> 00:18:45,440
volumes we support uh many different

00:18:44,080 --> 00:18:48,160
representations

00:18:45,440 --> 00:18:49,520
ranging from dense structured uh in vdb

00:18:48,160 --> 00:18:51,280
sparse structured

00:18:49,520 --> 00:18:53,360
uh all the way through uh fully

00:18:51,280 --> 00:18:54,559
unstructured volumes and and particle

00:18:53,360 --> 00:18:56,640
volumes

00:18:54,559 --> 00:18:58,400
and then for apis we support uh

00:18:56,640 --> 00:19:00,960
volumetric sampling

00:18:58,400 --> 00:19:03,039
uh gradient computation uh ray-based

00:19:00,960 --> 00:19:03,760
interval iteration which i'll talk more

00:19:03,039 --> 00:19:06,640
about

00:19:03,760 --> 00:19:07,600
uh implicit iso surfacing or surface hit

00:19:06,640 --> 00:19:10,240
iteration

00:19:07,600 --> 00:19:12,559
uh and volume observers where i'll also

00:19:10,240 --> 00:19:14,960
show an example of that

00:19:12,559 --> 00:19:16,480
so the first volume type is structured

00:19:14,960 --> 00:19:19,360
regular volumes

00:19:16,480 --> 00:19:19,679
so here the domain is a regular grid and

00:19:19,360 --> 00:19:23,360
the

00:19:19,679 --> 00:19:26,559
the volume data is essentially a 3d

00:19:23,360 --> 00:19:28,880
array of dense voxels and so

00:19:26,559 --> 00:19:29,679
this volume type provides extremely fast

00:19:28,880 --> 00:19:32,000
access

00:19:29,679 --> 00:19:33,200
but does have a relatively large

00:19:32,000 --> 00:19:36,320
footprint in memory

00:19:33,200 --> 00:19:37,120
and so this volume type is is very good

00:19:36,320 --> 00:19:40,240
for

00:19:37,120 --> 00:19:42,000
fast rendering when data fits into

00:19:40,240 --> 00:19:44,160
memory

00:19:42,000 --> 00:19:46,240
uh the next volume type is is very

00:19:44,160 --> 00:19:47,520
similar so the domain isn't a regular

00:19:46,240 --> 00:19:49,280
grid but

00:19:47,520 --> 00:19:50,880
but now on spherical coordinates on

00:19:49,280 --> 00:19:54,080
radius azimuth and

00:19:50,880 --> 00:19:56,160
elevation and so this has similar

00:19:54,080 --> 00:19:58,559
advantages and disadvantages

00:19:56,160 --> 00:19:59,679
uh to the previous volume type uh but of

00:19:58,559 --> 00:20:02,400
course this volume

00:19:59,679 --> 00:20:04,159
is very well suited to problems with a

00:20:02,400 --> 00:20:07,200
natively spherical structure

00:20:04,159 --> 00:20:09,440
and so um applications or

00:20:07,200 --> 00:20:12,000
simulations that use this volume type

00:20:09,440 --> 00:20:14,320
can pass it to decal directly and

00:20:12,000 --> 00:20:16,320
there's no need to transform the volume

00:20:14,320 --> 00:20:20,000
or resample it onto a

00:20:16,320 --> 00:20:22,240
a less efficient volume type

00:20:20,000 --> 00:20:24,159
so we then have adaptive mesh refinement

00:20:22,240 --> 00:20:26,880
volumes or more specifically

00:20:24,159 --> 00:20:28,559
block structured amr so we have some

00:20:26,880 --> 00:20:29,440
more flexibility here where we could

00:20:28,559 --> 00:20:32,559
provide data

00:20:29,440 --> 00:20:33,600
as nested structure structured regular

00:20:32,559 --> 00:20:36,240
grids

00:20:33,600 --> 00:20:37,919
so these nested grids must fit neatly

00:20:36,240 --> 00:20:39,600
into their parent but otherwise we're

00:20:37,919 --> 00:20:42,799
free to have

00:20:39,600 --> 00:20:44,320
as many levels of refinement as we want

00:20:42,799 --> 00:20:46,480
and so

00:20:44,320 --> 00:20:49,440
a very flexible volume type the

00:20:46,480 --> 00:20:51,840
traversal is somewhat more expensive

00:20:49,440 --> 00:20:53,200
one important note is this is often used

00:20:51,840 --> 00:20:56,240
in in large-scale

00:20:53,200 --> 00:20:58,240
uh scientific simulations so again

00:20:56,240 --> 00:20:59,679
uh can pass that volume type directly to

00:20:58,240 --> 00:21:03,120
bkl without

00:20:59,679 --> 00:21:05,760
needing to transform it

00:21:03,120 --> 00:21:07,679
another volume type we support is fully

00:21:05,760 --> 00:21:08,960
unstructured volumes and so here we

00:21:07,679 --> 00:21:11,280
support

00:21:08,960 --> 00:21:12,000
arbitrary combinations of multiple cell

00:21:11,280 --> 00:21:15,760
types so

00:21:12,000 --> 00:21:17,679
tetrahedra hexahedra wedges and pyramid

00:21:15,760 --> 00:21:18,880
and there's really no regular structure

00:21:17,679 --> 00:21:21,600
and so we can

00:21:18,880 --> 00:21:22,799
place ourselves wherever we want really

00:21:21,600 --> 00:21:26,400
adapt to

00:21:22,799 --> 00:21:28,400
a regular forms put our resolution and

00:21:26,400 --> 00:21:30,799
cell data where we need it

00:21:28,400 --> 00:21:32,480
because of this um you know no regular

00:21:30,799 --> 00:21:35,520
structure uh traversal is

00:21:32,480 --> 00:21:36,960
uh moderately more uh expensive um

00:21:35,520 --> 00:21:39,200
so this is another volume type

00:21:36,960 --> 00:21:40,080
extensively used in in large-scale

00:21:39,200 --> 00:21:42,840
simulations

00:21:40,080 --> 00:21:44,080
uh finite element modeling and and so

00:21:42,840 --> 00:21:46,960
forth

00:21:44,080 --> 00:21:48,400
um and our our newest volume type uh

00:21:46,960 --> 00:21:48,960
which is somewhat different from the

00:21:48,400 --> 00:21:52,000
previous

00:21:48,960 --> 00:21:53,919
uh cell and voxel-based volumes is our

00:21:52,000 --> 00:21:56,400
particle volumes and so

00:21:53,919 --> 00:21:57,760
uh here a volume is is made up of many

00:21:56,400 --> 00:22:00,559
individual particles

00:21:57,760 --> 00:22:01,039
where each particle has its own position

00:22:00,559 --> 00:22:03,679
weight

00:22:01,039 --> 00:22:05,840
and radius of influence and so when you

00:22:03,679 --> 00:22:08,960
sample a volume here at a point location

00:22:05,840 --> 00:22:11,520
uh any number of particles are able to

00:22:08,960 --> 00:22:12,480
contribute to that sample value via

00:22:11,520 --> 00:22:15,760
gaussian

00:22:12,480 --> 00:22:16,880
radial basis functions so so this volume

00:22:15,760 --> 00:22:20,240
type is used

00:22:16,880 --> 00:22:21,280
extensively in large-scale cosmological

00:22:20,240 --> 00:22:27,280
simulations

00:22:21,280 --> 00:22:29,039
molecular dynamics and and other domains

00:22:27,280 --> 00:22:31,039
and then last but not least we have our

00:22:29,039 --> 00:22:34,960
our bdb volumes and so these

00:22:31,039 --> 00:22:36,159
are really pervasive throughout vfx and

00:22:34,960 --> 00:22:39,600
professional rendering

00:22:36,159 --> 00:22:42,559
and so here the domain is a regular grid

00:22:39,600 --> 00:22:43,200
and it supports sparse storage through

00:22:42,559 --> 00:22:46,400
nested

00:22:43,200 --> 00:22:47,280
uh regular grids where each level is a

00:22:46,400 --> 00:22:50,080
power of two

00:22:47,280 --> 00:22:52,080
in in resolution and so uh because of

00:22:50,080 --> 00:22:53,600
this regular structure we have a

00:22:52,080 --> 00:22:56,880
relatively fast

00:22:53,600 --> 00:22:58,159
traversal and fast access and of course

00:22:56,880 --> 00:23:01,600
a huge advantage

00:22:58,159 --> 00:23:05,200
is an efficient use of memory

00:23:01,600 --> 00:23:07,200
through this sparse representation

00:23:05,200 --> 00:23:08,320
so some more detail on our vdb

00:23:07,200 --> 00:23:11,200
implementation

00:23:08,320 --> 00:23:12,320
so vkl does have a compile-time

00:23:11,200 --> 00:23:14,080
configurable

00:23:12,320 --> 00:23:16,559
topology for the different levels of the

00:23:14,080 --> 00:23:18,080
tree and we do have a custom

00:23:16,559 --> 00:23:20,480
implementation for

00:23:18,080 --> 00:23:23,280
tree build and traversal so this is

00:23:20,480 --> 00:23:25,600
implemented in isbc so we're able to do

00:23:23,280 --> 00:23:27,520
a full vector-wide you know build

00:23:25,600 --> 00:23:29,120
traversal sampling and so forth to make

00:23:27,520 --> 00:23:31,440
that very fast

00:23:29,120 --> 00:23:32,559
we support multiple reconstruction modes

00:23:31,440 --> 00:23:34,480
so today that's

00:23:32,559 --> 00:23:35,600
nearest filtering and tri-linear

00:23:34,480 --> 00:23:38,159
filtering

00:23:35,600 --> 00:23:40,000
and then we have a hierarchical dda

00:23:38,159 --> 00:23:42,080
implementation which we use in

00:23:40,000 --> 00:23:43,200
interval iterators which i'll talk about

00:23:42,080 --> 00:23:45,039
shortly

00:23:43,200 --> 00:23:46,240
the animation you're seeing here is an

00:23:45,039 --> 00:23:49,440
example of

00:23:46,240 --> 00:23:50,080
bkl's volume observers and so volume

00:23:49,440 --> 00:23:52,960
observers

00:23:50,080 --> 00:23:54,320
are a flexible component of the api that

00:23:52,960 --> 00:23:56,640
allow volumes

00:23:54,320 --> 00:23:57,679
uh to essentially communicate arbitrary

00:23:56,640 --> 00:24:00,960
metadata um

00:23:57,679 --> 00:24:02,720
about their uh usage and and statistics

00:24:00,960 --> 00:24:06,159
and and so forth and so

00:24:02,720 --> 00:24:08,720
in this example um the uh the the white

00:24:06,159 --> 00:24:10,720
parts of the of the cloud are uh

00:24:08,720 --> 00:24:13,120
internodes of the the vdb

00:24:10,720 --> 00:24:14,880
tree and uh through volume observers

00:24:13,120 --> 00:24:16,880
we're able to communicate back to the

00:24:14,880 --> 00:24:18,480
application uh which regions of the

00:24:16,880 --> 00:24:20,240
volume

00:24:18,480 --> 00:24:21,520
where sampling is occurring and then

00:24:20,240 --> 00:24:24,880
we're able to

00:24:21,520 --> 00:24:25,760
dynamically load leaf data on demand and

00:24:24,880 --> 00:24:28,480
so

00:24:25,760 --> 00:24:30,080
this is a flexible mechanism for

00:24:28,480 --> 00:24:33,840
application side

00:24:30,080 --> 00:24:33,840
on-demand loading

00:24:34,400 --> 00:24:37,840
um so with our vdb support we also ship

00:24:37,120 --> 00:24:40,000
a vdb

00:24:37,840 --> 00:24:41,600
utility library so this integrates

00:24:40,000 --> 00:24:45,120
directly with openvdb

00:24:41,600 --> 00:24:46,159
and allows for a very simple essentially

00:24:45,120 --> 00:24:49,520
one line loading

00:24:46,159 --> 00:24:50,000
of uh vdb data sets uh so one important

00:24:49,520 --> 00:24:52,880
point

00:24:50,000 --> 00:24:55,279
is that um the the leaf format that

00:24:52,880 --> 00:24:55,600
openvkl uses is completely compatible

00:24:55,279 --> 00:24:58,880
with

00:24:55,600 --> 00:25:01,679
openvdb so you can pass those pointers

00:24:58,880 --> 00:25:03,600
directly to vkl and through through our

00:25:01,679 --> 00:25:06,559
shared buffer objects

00:25:03,600 --> 00:25:07,360
vkl doesn't even need to make a copy of

00:25:06,559 --> 00:25:10,720
those so

00:25:07,360 --> 00:25:11,840
memory efficient and zero copy today we

00:25:10,720 --> 00:25:14,799
are limited to

00:25:11,840 --> 00:25:17,679
scalar flow fields but that will likely

00:25:14,799 --> 00:25:20,240
change in the future

00:25:17,679 --> 00:25:22,559
um so openvkl supports many of these

00:25:20,240 --> 00:25:26,960
rendering based apis shown at the top

00:25:22,559 --> 00:25:28,159
the api overall is a c99 based api which

00:25:26,960 --> 00:25:30,720
is very similar

00:25:28,159 --> 00:25:31,679
to the other render kit components we do

00:25:30,720 --> 00:25:33,760
provide

00:25:31,679 --> 00:25:35,279
ispc bindings and so if you're writing

00:25:33,760 --> 00:25:38,320
code in isbc

00:25:35,279 --> 00:25:40,080
and using uh those uniform and varying

00:25:38,320 --> 00:25:44,000
constructs you're able to

00:25:40,080 --> 00:25:47,120
also call directly into vkl we do have

00:25:44,000 --> 00:25:47,840
multiple supported api modes for most of

00:25:47,120 --> 00:25:50,320
the api

00:25:47,840 --> 00:25:51,039
shown and so taking sampling is an

00:25:50,320 --> 00:25:53,279
example

00:25:51,039 --> 00:25:54,320
so we support scalar sampling where you

00:25:53,279 --> 00:25:56,799
can sample a

00:25:54,320 --> 00:25:57,360
single point location at a time we

00:25:56,799 --> 00:25:58,960
support

00:25:57,360 --> 00:26:00,720
vector-wide sampling where you could

00:25:58,960 --> 00:26:03,840
sample

00:26:00,720 --> 00:26:05,120
four eight or 16 locations at the same

00:26:03,840 --> 00:26:06,320
time and under the hood we'll make

00:26:05,120 --> 00:26:11,279
efficient use of

00:26:06,320 --> 00:26:13,279
sse avx avx-2 or abx-512 as appropriate

00:26:11,279 --> 00:26:15,039
and then we also have a stream-wide

00:26:13,279 --> 00:26:17,679
sampling where we can sample

00:26:15,039 --> 00:26:19,120
arbitrary numbers of points at the same

00:26:17,679 --> 00:26:20,400
time and under the hood that will

00:26:19,120 --> 00:26:22,840
efficiently map

00:26:20,400 --> 00:26:24,240
to the most appropriate vector-wide

00:26:22,840 --> 00:26:27,440
interface

00:26:24,240 --> 00:26:30,559
vkl does have fairly flexible data

00:26:27,440 --> 00:26:32,720
interfaces for providing data to it so

00:26:30,559 --> 00:26:34,000
i already mentioned shared data buffers

00:26:32,720 --> 00:26:36,960
we also support

00:26:34,000 --> 00:26:38,159
strided input data for which can make it

00:26:36,960 --> 00:26:41,360
easier to work

00:26:38,159 --> 00:26:43,440
directly with data as it exists in

00:26:41,360 --> 00:26:44,880
application memory or maybe some custom

00:26:43,440 --> 00:26:48,080
structs

00:26:44,880 --> 00:26:51,600
and then we have a module implementation

00:26:48,080 --> 00:26:54,000
that does support user extensions and so

00:26:51,600 --> 00:26:56,240
if you had your own volume type you

00:26:54,000 --> 00:26:59,200
wanted to implement that is possible uh

00:26:56,240 --> 00:26:59,200
within vko

00:26:59,279 --> 00:27:03,039
so one of the apis i wanted to focus a

00:27:01,279 --> 00:27:06,000
little more in on is our

00:27:03,039 --> 00:27:08,159
ray-based interval iteration or interval

00:27:06,000 --> 00:27:10,720
iterators and so this allows

00:27:08,159 --> 00:27:11,840
you to iterate over meaningful intervals

00:27:10,720 --> 00:27:14,320
along array

00:27:11,840 --> 00:27:16,960
and what i mean by meaningful is that

00:27:14,320 --> 00:27:18,559
you are able to tell openvkl

00:27:16,960 --> 00:27:20,000
the volume values of interest through

00:27:18,559 --> 00:27:22,960
what we call a value

00:27:20,000 --> 00:27:24,080
selector object and so that means that

00:27:22,960 --> 00:27:27,440
when you start

00:27:24,080 --> 00:27:30,640
iterating let's see

00:27:27,440 --> 00:27:33,360
we accidentally went forward a slide

00:27:30,640 --> 00:27:35,279
so that means when you start iterating

00:27:33,360 --> 00:27:37,360
along array you're able to

00:27:35,279 --> 00:27:39,840
skip any intervals that are known to to

00:27:37,360 --> 00:27:42,640
not contain those values of interest so

00:27:39,840 --> 00:27:44,159
that's in a very efficient form of empty

00:27:42,640 --> 00:27:45,679
space skipping

00:27:44,159 --> 00:27:47,200
and then the intervals you get back are

00:27:45,679 --> 00:27:49,039
not necessarily boxes

00:27:47,200 --> 00:27:50,480
so this is somewhat configurable per

00:27:49,039 --> 00:27:53,279
volume and so

00:27:50,480 --> 00:27:53,919
as an example for bdb volumes you could

00:27:53,279 --> 00:27:56,799
configure

00:27:53,919 --> 00:27:57,840
the the depth of the bdb tree at which

00:27:56,799 --> 00:28:00,559
you intersect

00:27:57,840 --> 00:28:01,919
to find these intervals and then finally

00:28:00,559 --> 00:28:04,720
with the interval data you

00:28:01,919 --> 00:28:06,799
do get back additional metadata so one

00:28:04,720 --> 00:28:09,360
one piece of information

00:28:06,799 --> 00:28:10,960
is the volume value range that you can

00:28:09,360 --> 00:28:11,679
encounter when sampling along that

00:28:10,960 --> 00:28:15,440
interval

00:28:11,679 --> 00:28:17,840
and so this this value min max is useful

00:28:15,440 --> 00:28:20,559
for rendering methods such as delta

00:28:17,840 --> 00:28:22,159
tracking where a very tight bound on on

00:28:20,559 --> 00:28:23,919
volume majority

00:28:22,159 --> 00:28:25,360
can make your overall rendering much

00:28:23,919 --> 00:28:29,360
more efficient through

00:28:25,360 --> 00:28:31,120
requiring less sampling for example

00:28:29,360 --> 00:28:32,799
um so that's that's the overview i

00:28:31,120 --> 00:28:34,080
wanted to give uh there's more

00:28:32,799 --> 00:28:37,760
information available

00:28:34,080 --> 00:28:40,559
at openvcl.org uh api documentation

00:28:37,760 --> 00:28:41,120
uh tutorials uh in the code base example

00:28:40,559 --> 00:28:44,399
renderer

00:28:41,120 --> 00:28:46,000
showing uh ways to integrate open vkl

00:28:44,399 --> 00:28:48,240
we are part of render kit so you could

00:28:46,000 --> 00:28:50,000
find information there

00:28:48,240 --> 00:28:51,360
and then if you are attending siggraph i

00:28:50,000 --> 00:28:54,159
encourage you to

00:28:51,360 --> 00:28:56,000
check out our demos and so we have

00:28:54,159 --> 00:28:57,039
several demos coming from our group one

00:28:56,000 --> 00:29:00,240
of these is a

00:28:57,039 --> 00:29:02,399
large scale cloudscape interactive demo

00:29:00,240 --> 00:29:03,360
where you see images there on the right

00:29:02,399 --> 00:29:06,399
so

00:29:03,360 --> 00:29:08,960
this makes heavy use of openvkl

00:29:06,399 --> 00:29:11,600
osprey and osprey studio and i believe

00:29:08,960 --> 00:29:14,960
those those demos are going live on

00:29:11,600 --> 00:29:18,080
august 24th okay

00:29:14,960 --> 00:29:20,880
thank you and i will turn it over to

00:29:18,080 --> 00:29:20,880
jeff amsters

00:29:22,320 --> 00:29:28,559
all right and i have control great

00:29:25,919 --> 00:29:29,360
so i'm going to talk about anari which

00:29:28,559 --> 00:29:31,520
um

00:29:29,360 --> 00:29:33,279
is a chrono standard so it's it's

00:29:31,520 --> 00:29:37,039
obviously not an intel

00:29:33,279 --> 00:29:40,720
project it's uh it's cross cross vendor

00:29:37,039 --> 00:29:43,200
um standard that's emerging it has been

00:29:40,720 --> 00:29:44,000
in uh it was at first in an exploratory

00:29:43,200 --> 00:29:46,000
group and then

00:29:44,000 --> 00:29:47,440
um middle of this year we transitioned

00:29:46,000 --> 00:29:48,240
to a full working group working on a

00:29:47,440 --> 00:29:50,320
spec

00:29:48,240 --> 00:29:52,080
so i'm going to just give a very brief

00:29:50,320 --> 00:29:54,080
overview of what it is and what we're

00:29:52,080 --> 00:29:56,320
working on

00:29:54,080 --> 00:29:58,080
knowing that we just had a webinar

00:29:56,320 --> 00:30:00,559
yesterday that

00:29:58,080 --> 00:30:02,240
got on youtube really quickly so if you

00:30:00,559 --> 00:30:05,120
search onari webinar

00:30:02,240 --> 00:30:06,799
we have an entire hour length

00:30:05,120 --> 00:30:07,840
presentation on it so this is going to

00:30:06,799 --> 00:30:09,679
be

00:30:07,840 --> 00:30:11,440
condensed even from that so hopefully

00:30:09,679 --> 00:30:12,080
this what's your appetite for what an re

00:30:11,440 --> 00:30:15,279
is

00:30:12,080 --> 00:30:17,600
and what it isn't so first anari

00:30:15,279 --> 00:30:18,559
is it stands for the analytic rendering

00:30:17,600 --> 00:30:21,600
interface

00:30:18,559 --> 00:30:24,960
and the the word analytic came from

00:30:21,600 --> 00:30:27,039
a largely that the uh the api

00:30:24,960 --> 00:30:28,799
uh that we're working on emerged from

00:30:27,039 --> 00:30:30,320
scientific visualization

00:30:28,799 --> 00:30:32,240
but just know that what we're working on

00:30:30,320 --> 00:30:34,080
is not actually domain specific

00:30:32,240 --> 00:30:35,679
so hopefully that the analytic part

00:30:34,080 --> 00:30:37,440
doesn't get too distracting from

00:30:35,679 --> 00:30:39,279
from what we're working on but the goal

00:30:37,440 --> 00:30:42,159
is to provide a

00:30:39,279 --> 00:30:44,159
a commoditized interface to talk to a

00:30:42,159 --> 00:30:46,480
live software rendering system

00:30:44,159 --> 00:30:48,559
and so all that means is a lot of us

00:30:46,480 --> 00:30:50,399
have have data we have file i o scene

00:30:48,559 --> 00:30:52,880
graphs um

00:30:50,399 --> 00:30:53,679
applications that have their their scene

00:30:52,880 --> 00:30:55,440
ready to go

00:30:53,679 --> 00:30:58,000
but we have uh there and you'll there'll

00:30:55,440 --> 00:31:00,399
be an image to describe this later but

00:30:58,000 --> 00:31:02,480
we have the problem of having to talk to

00:31:00,399 --> 00:31:05,440
everyone's custom api to

00:31:02,480 --> 00:31:06,720
translate that data from the application

00:31:05,440 --> 00:31:08,159
and share it with the renderer so the

00:31:06,720 --> 00:31:11,120
renderer can make an image of it

00:31:08,159 --> 00:31:13,279
so an aria is seeking to commoditize

00:31:11,120 --> 00:31:15,120
specifying the what needs to be rendered

00:31:13,279 --> 00:31:17,760
and then how to get an image back still

00:31:15,120 --> 00:31:18,720
letting the render define all of the why

00:31:17,760 --> 00:31:20,559
and the how

00:31:18,720 --> 00:31:21,919
that that rendering gets gets done so

00:31:20,559 --> 00:31:23,600
the the the

00:31:21,919 --> 00:31:25,360
illustration at the bottom is you have

00:31:23,600 --> 00:31:27,760
some input scene

00:31:25,360 --> 00:31:29,120
uh you have some camera position and you

00:31:27,760 --> 00:31:30,880
plumb that through inari to let

00:31:29,120 --> 00:31:31,840
someone's renderer then make you an

00:31:30,880 --> 00:31:35,039
image

00:31:31,840 --> 00:31:38,399
that is desirable

00:31:35,039 --> 00:31:40,480
so uh the this emerged from scientific

00:31:38,399 --> 00:31:42,480
visualization where there were a number

00:31:40,480 --> 00:31:46,000
of uh software packages

00:31:42,480 --> 00:31:47,919
like vtk and paraview um that

00:31:46,000 --> 00:31:49,360
every time there was a desire to use

00:31:47,919 --> 00:31:51,120
like a new ray tracing

00:31:49,360 --> 00:31:52,960
renderer that was shipped from a vendor

00:31:51,120 --> 00:31:54,720
such as osprey or

00:31:52,960 --> 00:31:56,799
there's viz rtx from nvidia there's a

00:31:54,720 --> 00:31:57,919
number of great renders out in the wild

00:31:56,799 --> 00:32:01,360
every single time

00:31:57,919 --> 00:32:02,880
that was desired to be brought into the

00:32:01,360 --> 00:32:03,840
the software package that you have to do

00:32:02,880 --> 00:32:06,320
an integration

00:32:03,840 --> 00:32:07,440
with that even though that that level of

00:32:06,320 --> 00:32:09,760
translation to say

00:32:07,440 --> 00:32:11,120
this is my application scene and i want

00:32:09,760 --> 00:32:14,159
you to make me a frame

00:32:11,120 --> 00:32:15,760
that that uh from the uh

00:32:14,159 --> 00:32:17,440
the technical standpoint was largely

00:32:15,760 --> 00:32:18,880
still saying the same thing that we had

00:32:17,440 --> 00:32:20,799
to spell it with different

00:32:18,880 --> 00:32:22,720
different apis over and over and over

00:32:20,799 --> 00:32:25,360
again uh so to get to the

00:32:22,720 --> 00:32:27,840
the lower level goods of what a renderer

00:32:25,360 --> 00:32:29,600
vendor might provide

00:32:27,840 --> 00:32:31,919
we're trying to commoditize that to go

00:32:29,600 --> 00:32:34,480
from the left to then the right

00:32:31,919 --> 00:32:35,760
where we have all of these packages

00:32:34,480 --> 00:32:38,240
talking to a single

00:32:35,760 --> 00:32:38,799
um a single render api and then let let

00:32:38,240 --> 00:32:40,080
vendors

00:32:38,799 --> 00:32:41,200
worry about the renderer with the

00:32:40,080 --> 00:32:43,360
applications worry about their

00:32:41,200 --> 00:32:45,360
application

00:32:43,360 --> 00:32:47,760
so more concretely to put some names to

00:32:45,360 --> 00:32:48,240
this uh this is the the very high level

00:32:47,760 --> 00:32:50,399
stack

00:32:48,240 --> 00:32:52,080
of where nre sits and nr is very thin

00:32:50,399 --> 00:32:54,159
this is not trying to actually

00:32:52,080 --> 00:32:56,640
implement a lot but instead standardize

00:32:54,159 --> 00:32:58,320
the way the top level applications talk

00:32:56,640 --> 00:33:00,799
to the lower level renderers

00:32:58,320 --> 00:33:03,919
so we have some examples of renderers

00:33:00,799 --> 00:33:06,720
we've been working with in cybez osprey

00:33:03,919 --> 00:33:07,919
viz rtx and then we we've even had amd

00:33:06,720 --> 00:33:09,039
participation

00:33:07,919 --> 00:33:11,760
in the working group with radeon

00:33:09,039 --> 00:33:14,080
prorender but at the end of the day

00:33:11,760 --> 00:33:14,799
you could substitute your renderer

00:33:14,080 --> 00:33:16,720
commercial or

00:33:14,799 --> 00:33:18,960
open source uh you could insert that

00:33:16,720 --> 00:33:20,799
there that takes advantage of lower

00:33:18,960 --> 00:33:22,080
level apis like we've talked about embry

00:33:20,799 --> 00:33:24,000
and openvkl

00:33:22,080 --> 00:33:25,120
there's optics all of these things to

00:33:24,000 --> 00:33:27,440
make a renderer

00:33:25,120 --> 00:33:29,760
um but and then of course the hardware

00:33:27,440 --> 00:33:32,320
underneath it but inari is trying to

00:33:29,760 --> 00:33:32,880
not um take on the entire scene graph

00:33:32,320 --> 00:33:34,720
problem

00:33:32,880 --> 00:33:38,480
which deals with file i o structural

00:33:34,720 --> 00:33:40,080
updates uh metadata custom to a domain

00:33:38,480 --> 00:33:41,760
all kinds of different concerns we're

00:33:40,080 --> 00:33:43,760
trying to let that be

00:33:41,760 --> 00:33:45,919
domain specific but once you boil down

00:33:43,760 --> 00:33:47,200
to want to render an image

00:33:45,919 --> 00:33:50,159
that that generally looks the same

00:33:47,200 --> 00:33:52,399
that's what we're trying to commoditize

00:33:50,159 --> 00:33:53,760
so succinctly this ends up being a

00:33:52,399 --> 00:33:56,159
viewport rendering api

00:33:53,760 --> 00:33:57,039
uh so not a scene graph there's so much

00:33:56,159 --> 00:34:00,320
uh both

00:33:57,039 --> 00:34:03,120
um application specific domain specific

00:34:00,320 --> 00:34:03,679
um uh libraries and tools out there that

00:34:03,120 --> 00:34:06,080
exist

00:34:03,679 --> 00:34:07,600
and uh standardizing on all of those is

00:34:06,080 --> 00:34:10,399
really ambitious and difficult

00:34:07,600 --> 00:34:11,440
so we're trying to make sure that what

00:34:10,399 --> 00:34:14,159
remains in scope

00:34:11,440 --> 00:34:15,040
is um going to actually serve us uh to

00:34:14,159 --> 00:34:17,679
benefit

00:34:15,040 --> 00:34:19,839
um uh to con basically manage

00:34:17,679 --> 00:34:22,399
expectations is what that boils down to

00:34:19,839 --> 00:34:23,440
for an re um and then also to to help

00:34:22,399 --> 00:34:25,839
with this

00:34:23,440 --> 00:34:27,119
uh to maintain that separation is our

00:34:25,839 --> 00:34:29,119
goal is to remain

00:34:27,119 --> 00:34:30,960
maximally unidirectional and what that

00:34:29,119 --> 00:34:33,520
means is all that structure

00:34:30,960 --> 00:34:34,960
data arrays where parameters come from

00:34:33,520 --> 00:34:37,200
where they're queried remains in the

00:34:34,960 --> 00:34:40,000
application and you share it with an re

00:34:37,200 --> 00:34:41,839
and ari is not uh not trying to be a

00:34:40,000 --> 00:34:42,560
framework to go build all of those

00:34:41,839 --> 00:34:44,480
things

00:34:42,560 --> 00:34:45,839
um instead it's how do you share that

00:34:44,480 --> 00:34:47,280
information with a renderer so this

00:34:45,839 --> 00:34:48,159
gives us lots of freedom to do

00:34:47,280 --> 00:34:50,639
interesting things

00:34:48,159 --> 00:34:51,520
as renderer implementers uh to be

00:34:50,639 --> 00:34:54,079
divorced from

00:34:51,520 --> 00:34:55,520
from all of that complexity while still

00:34:54,079 --> 00:34:57,280
dealing with the complexity we have by

00:34:55,520 --> 00:35:00,480
implementing renderers

00:34:57,280 --> 00:35:01,520
and one cool example of this there's

00:35:00,480 --> 00:35:03,760
there's a ton of

00:35:01,520 --> 00:35:04,640
possibilities there what what freedom

00:35:03,760 --> 00:35:07,599
helps us with as

00:35:04,640 --> 00:35:10,000
implementers of rendering systems but um

00:35:07,599 --> 00:35:12,240
just diverse execution topologies is

00:35:10,000 --> 00:35:13,920
one that is a big deal in cybiz and one

00:35:12,240 --> 00:35:17,359
we're taking very seriously with

00:35:13,920 --> 00:35:18,320
with an re i think most of us probably

00:35:17,359 --> 00:35:20,640
think when we

00:35:18,320 --> 00:35:22,560
we want to render something we think of

00:35:20,640 --> 00:35:24,240
the the left-hand side we have a single

00:35:22,560 --> 00:35:25,760
application running on a single machine

00:35:24,240 --> 00:35:27,359
talking to an api

00:35:25,760 --> 00:35:29,040
that has a single implementation with

00:35:27,359 --> 00:35:30,000
some cpus and gpus under it that's

00:35:29,040 --> 00:35:32,079
absolutely

00:35:30,000 --> 00:35:34,400
like a huge part of what an r is going

00:35:32,079 --> 00:35:37,680
for but there are these others that

00:35:34,400 --> 00:35:40,079
um that when you have a standard

00:35:37,680 --> 00:35:40,720
semantic capture of what the scene is

00:35:40,079 --> 00:35:43,280
and then

00:35:40,720 --> 00:35:44,960
how to the desire to get frames back

00:35:43,280 --> 00:35:45,599
from a certain vantage point of that

00:35:44,960 --> 00:35:46,880
scene

00:35:45,599 --> 00:35:48,880
you can do interesting things like an

00:35:46,880 --> 00:35:51,359
implementation can farm off

00:35:48,880 --> 00:35:54,079
even subparts of the same image to

00:35:51,359 --> 00:35:56,320
multiple nodes in like an mpi cluster

00:35:54,079 --> 00:35:57,839
or the far right side you could have an

00:35:56,320 --> 00:36:00,960
existing distributed memory

00:35:57,839 --> 00:36:02,560
application like an mpi simulation

00:36:00,960 --> 00:36:04,320
where bits of the scene are on different

00:36:02,560 --> 00:36:05,280
nodes and they all talk to the same

00:36:04,320 --> 00:36:07,040
inaudi api

00:36:05,280 --> 00:36:09,040
and then the underlying implementation

00:36:07,040 --> 00:36:10,079
can take that and make a single image of

00:36:09,040 --> 00:36:11,280
all of the data

00:36:10,079 --> 00:36:13,200
these are things that we've been doing

00:36:11,280 --> 00:36:16,160
in cybiz for a while now

00:36:13,200 --> 00:36:18,079
but uh being able to um lower the bar to

00:36:16,160 --> 00:36:19,920
be able to access those renderers is

00:36:18,079 --> 00:36:23,200
is something that we're we're keeping in

00:36:19,920 --> 00:36:25,040
mind as we're working on an re

00:36:23,200 --> 00:36:26,480
so the current status is where we've

00:36:25,040 --> 00:36:28,000
been a uh

00:36:26,480 --> 00:36:29,760
a working group for just a couple of

00:36:28,000 --> 00:36:31,599
months now um

00:36:29,760 --> 00:36:33,839
it's it's very early on but we've got

00:36:31,599 --> 00:36:34,800
some really cool examples already we

00:36:33,839 --> 00:36:38,000
have

00:36:34,800 --> 00:36:40,400
an early first light of vtk with some of

00:36:38,000 --> 00:36:42,560
its infrastructure for uh

00:36:40,400 --> 00:36:44,079
rendering uh vtk for those of you that

00:36:42,560 --> 00:36:45,520
don't know is the visualization toolkit

00:36:44,079 --> 00:36:48,240
is a very ubiquitous

00:36:45,520 --> 00:36:48,640
package from kit where um to to deal

00:36:48,240 --> 00:36:50,240
with

00:36:48,640 --> 00:36:52,160
filtering and then rendering of

00:36:50,240 --> 00:36:54,560
scientific data

00:36:52,160 --> 00:36:55,200
or simulation data and we have a first

00:36:54,560 --> 00:36:57,200
light of it

00:36:55,200 --> 00:36:59,359
uh given that it was part of the

00:36:57,200 --> 00:37:00,000
participating reason and cause for an

00:36:59,359 --> 00:37:03,200
ari to

00:37:00,000 --> 00:37:04,960
to start as an effort and then also vmd

00:37:03,200 --> 00:37:08,160
is a visualization um

00:37:04,960 --> 00:37:11,359
package for molecular dynamics vfd

00:37:08,160 --> 00:37:14,000
and both both of those have been

00:37:11,359 --> 00:37:14,800
early adopters to help drive some of the

00:37:14,000 --> 00:37:16,720
the changes

00:37:14,800 --> 00:37:18,480
or the the design decisions we're making

00:37:16,720 --> 00:37:20,400
at inari and we have a number of

00:37:18,480 --> 00:37:22,400
implementers as well

00:37:20,400 --> 00:37:24,000
which has been very exciting we're still

00:37:22,400 --> 00:37:27,839
exploring lots of

00:37:24,000 --> 00:37:29,359
um possibilities uh we we

00:37:27,839 --> 00:37:31,440
from a technical perspective we're

00:37:29,359 --> 00:37:33,760
trying to write the software first

00:37:31,440 --> 00:37:35,680
and then write the spec because talking

00:37:33,760 --> 00:37:37,119
about a spec outside of

00:37:35,680 --> 00:37:39,839
what we're going to do in practice is

00:37:37,119 --> 00:37:41,520
really difficult

00:37:39,839 --> 00:37:44,720
to keep the discussion focused so what

00:37:41,520 --> 00:37:47,440
we what we did is we took the osprey api

00:37:44,720 --> 00:37:48,960
and we have have taken it and started

00:37:47,440 --> 00:37:50,640
working with that

00:37:48,960 --> 00:37:52,000
as like a concrete starting point and

00:37:50,640 --> 00:37:54,079
there's a number of

00:37:52,000 --> 00:37:55,200
of of good changes that we've been

00:37:54,079 --> 00:37:58,320
working on there to

00:37:55,200 --> 00:38:00,400
to make sure it best fits all of those

00:37:58,320 --> 00:38:03,200
execution topologies different renderers

00:38:00,400 --> 00:38:05,440
different shading models different

00:38:03,200 --> 00:38:07,119
volume types uh surface types all of

00:38:05,440 --> 00:38:08,800
these things are properly handled

00:38:07,119 --> 00:38:10,640
um but we're making a lot of exciting

00:38:08,800 --> 00:38:13,760
progress there

00:38:10,640 --> 00:38:15,839
um and so this this showcases uh

00:38:13,760 --> 00:38:17,280
not that we're all trying to implement

00:38:15,839 --> 00:38:20,320
the same renderer

00:38:17,280 --> 00:38:22,079
but rather vmd um has

00:38:20,320 --> 00:38:23,440
you know all this this scene loaded in

00:38:22,079 --> 00:38:26,000
memory ready to go

00:38:23,440 --> 00:38:27,280
and was able to hand it to the nr api

00:38:26,000 --> 00:38:30,640
and just by virtue of

00:38:27,280 --> 00:38:31,839
of selecting what back end uh anari was

00:38:30,640 --> 00:38:35,520
was being

00:38:31,839 --> 00:38:36,480
used um we could get a a great image

00:38:35,520 --> 00:38:37,920
from a gl

00:38:36,480 --> 00:38:40,240
implementation that nvidia's working on

00:38:37,920 --> 00:38:44,160
called nvgl osprey

00:38:40,240 --> 00:38:44,560
nrx is a optics-based implementation

00:38:44,160 --> 00:38:46,480
that

00:38:44,560 --> 00:38:47,760
videos was working with and of course

00:38:46,480 --> 00:38:50,960
the far right is

00:38:47,760 --> 00:38:53,359
all of the code that uh was hand written

00:38:50,960 --> 00:38:55,680
inside of vmd what it's looking

00:38:53,359 --> 00:38:57,359
it's looking like we even have uh

00:38:55,680 --> 00:39:01,119
efforts from john stone who works

00:38:57,359 --> 00:39:03,119
about uh who leads the vmd effort to um

00:39:01,119 --> 00:39:05,280
work on his rendering code also be in

00:39:03,119 --> 00:39:06,640
terms of the nra api so then there's so

00:39:05,280 --> 00:39:08,480
much

00:39:06,640 --> 00:39:10,000
code that can get removed from vmd to

00:39:08,480 --> 00:39:11,680
dispatch to these different rendering

00:39:10,000 --> 00:39:12,079
packages without having to re-implement

00:39:11,680 --> 00:39:14,079
them

00:39:12,079 --> 00:39:15,839
so it's it's an exciting uh gamut of

00:39:14,079 --> 00:39:16,400
possibilities and this is just a first

00:39:15,839 --> 00:39:19,440
light

00:39:16,400 --> 00:39:20,800
but all of that being said um i just

00:39:19,440 --> 00:39:21,680
wanted to wet your appetite with some

00:39:20,800 --> 00:39:23,760
things that

00:39:21,680 --> 00:39:25,440
when you commoditize how you talk to a

00:39:23,760 --> 00:39:26,640
rendering system we're not trying to

00:39:25,440 --> 00:39:29,760
standardize on

00:39:26,640 --> 00:39:31,839
necessarily uh the limits of of what is

00:39:29,760 --> 00:39:33,200
the perfect material model what is the

00:39:31,839 --> 00:39:35,599
perfect lighting model

00:39:33,200 --> 00:39:36,640
what we're trying to do is is say if you

00:39:35,599 --> 00:39:39,200
have um

00:39:36,640 --> 00:39:40,240
like osl or materialx or you have a

00:39:39,200 --> 00:39:43,040
bunch of like the

00:39:40,240 --> 00:39:44,480
like the disney principled uh brdf

00:39:43,040 --> 00:39:46,400
shaders in your renderer

00:39:44,480 --> 00:39:48,320
that we want to standardize the way you

00:39:46,400 --> 00:39:48,720
express that to your live system and

00:39:48,320 --> 00:39:51,680
then

00:39:48,720 --> 00:39:52,400
uh encode that to the renderer instead

00:39:51,680 --> 00:39:54,400
of um

00:39:52,400 --> 00:39:55,760
saying like there's only one answer and

00:39:54,400 --> 00:39:56,880
everyone should use that still a good

00:39:55,760 --> 00:39:58,320
discussion but not

00:39:56,880 --> 00:40:00,160
it's outside of the scope of what we're

00:39:58,320 --> 00:40:02,640
doing meaning uh with

00:40:00,160 --> 00:40:04,000
with the the principled brdf and car

00:40:02,640 --> 00:40:06,960
paint shaders and

00:40:04,000 --> 00:40:08,319
uh and osprey um an ari can can make

00:40:06,960 --> 00:40:10,400
images like this

00:40:08,319 --> 00:40:11,680
or make images like this where we

00:40:10,400 --> 00:40:13,440
combine um

00:40:11,680 --> 00:40:15,440
you know volume rendering and surfaces

00:40:13,440 --> 00:40:18,400
together uh the api

00:40:15,440 --> 00:40:20,079
lets us still express all kinds of of

00:40:18,400 --> 00:40:21,599
details that we find in professional

00:40:20,079 --> 00:40:24,000
content creation so

00:40:21,599 --> 00:40:25,040
i guess the call to participation here

00:40:24,000 --> 00:40:27,760
is that

00:40:25,040 --> 00:40:29,839
anari is yes emerging from scientific

00:40:27,760 --> 00:40:30,720
visualization but absolutely something

00:40:29,839 --> 00:40:33,680
that

00:40:30,720 --> 00:40:36,720
could be very relevant and useful in the

00:40:33,680 --> 00:40:40,160
professional rendering space as well

00:40:36,720 --> 00:40:42,160
we have a lot of people participating um

00:40:40,160 --> 00:40:43,920
it's it's been exciting to see lots of

00:40:42,160 --> 00:40:46,880
people want to get on board with

00:40:43,920 --> 00:40:48,560
um helping craft what an re uh is

00:40:46,880 --> 00:40:51,200
starting to look like

00:40:48,560 --> 00:40:52,720
but we we are absolutely looking for as

00:40:51,200 --> 00:40:54,560
many people who want to come participate

00:40:52,720 --> 00:40:57,520
as possible

00:40:54,560 --> 00:40:57,920
and so we we are a working group uh we

00:40:57,520 --> 00:41:01,520
do

00:40:57,920 --> 00:41:04,640
now have a um an email

00:41:01,520 --> 00:41:06,000
list or an email address that we you can

00:41:04,640 --> 00:41:08,160
send questions to if you're not

00:41:06,000 --> 00:41:09,599
a participating work group member and of

00:41:08,160 --> 00:41:12,400
course the um

00:41:09,599 --> 00:41:12,800
the feedback is always welcome uh things

00:41:12,400 --> 00:41:14,720
that

00:41:12,800 --> 00:41:16,800
you would like to see in something like

00:41:14,720 --> 00:41:18,319
inari uh and then of course

00:41:16,800 --> 00:41:20,400
uh we would love it if you come

00:41:18,319 --> 00:41:23,680
participate in the working group itself

00:41:20,400 --> 00:41:24,880
we have lots of ideas and and would love

00:41:23,680 --> 00:41:26,880
to know if they're

00:41:24,880 --> 00:41:30,000
relevant and of course your ideas that

00:41:26,880 --> 00:41:30,000
you have that we haven't thought of

00:41:30,960 --> 00:41:49,839
and with that i'll turn it back to

00:41:35,119 --> 00:41:49,839
i guess sean

00:42:30,640 --> 00:42:51,040
now unfortunately we can't hear you sean

00:42:45,680 --> 00:42:51,040
can you hear me now a little bit

00:42:52,720 --> 00:42:57,280
well it's great thank you very much if

00:42:55,599 --> 00:42:59,599
you have any questions please feel free

00:42:57,280 --> 00:43:02,640
to use the question and answer box here

00:42:59,599 --> 00:43:05,520
or if um have a couple minutes left

00:43:02,640 --> 00:43:07,359
but if you're watching this record later

00:43:05,520 --> 00:43:09,200
um please feel free to go on github for

00:43:07,359 --> 00:43:10,960
any of these projects and to

00:43:09,200 --> 00:43:13,680
engage with the mailing lists everybody

00:43:10,960 --> 00:43:13,680
on this team is

00:43:30,720 --> 00:43:34,480
sean i think we we lost you again but

00:43:32,480 --> 00:43:38,000
maybe i can

00:43:34,480 --> 00:43:40,160
facilitate the q a uh

00:43:38,000 --> 00:43:42,000
uh so the art we do have our first

00:43:40,160 --> 00:43:43,920
question that is does open vk have

00:43:42,000 --> 00:43:46,880
support for motion blur volumes

00:43:43,920 --> 00:43:48,960
and greg and we have johannesburg as

00:43:46,880 --> 00:43:51,839
well i guess could take that

00:43:48,960 --> 00:43:52,640
uh yes so today open vkl does not

00:43:51,839 --> 00:43:54,960
currently

00:43:52,640 --> 00:43:56,720
support motion blur volumes through

00:43:54,960 --> 00:43:59,680
through our api

00:43:56,720 --> 00:44:01,200
this is something we are looking into i

00:43:59,680 --> 00:44:04,400
would say if you have

00:44:01,200 --> 00:44:06,800
specific needs regarding motion blur on

00:44:04,400 --> 00:44:08,880
specific volume types and so forth

00:44:06,800 --> 00:44:11,200
you know feel free to reach out to us

00:44:08,880 --> 00:44:13,280
via github and so forth and

00:44:11,200 --> 00:44:15,760
that will help us prioritize our

00:44:13,280 --> 00:44:15,760
development

00:44:20,800 --> 00:44:25,040
great um do we have any other any other

00:44:24,000 --> 00:44:37,839
questions from

00:44:25,040 --> 00:44:37,839
the audience while we're on the line

00:45:04,560 --> 00:45:08,960
yeah so um looks like we're getting

00:45:07,520 --> 00:45:11,119
close to the end today and i don't know

00:45:08,960 --> 00:45:14,160
if there's any other questions that um

00:45:11,119 --> 00:45:16,960
that may be out there we do have uh

00:45:14,160 --> 00:45:18,960
we have github is where you can find all

00:45:16,960 --> 00:45:20,800
of our projects and always feel free to

00:45:18,960 --> 00:45:22,000
reach out to us there with specific

00:45:20,800 --> 00:45:24,000
concerns about

00:45:22,000 --> 00:45:25,760
um each project probably using github

00:45:24,000 --> 00:45:27,760
issues you can also find

00:45:25,760 --> 00:45:30,319
mailing lists as well associated with

00:45:27,760 --> 00:45:32,400
with those projects to contact us and

00:45:30,319 --> 00:45:33,760
we'd love to hear from you about things

00:45:32,400 --> 00:45:36,319
you're you're interested in

00:45:33,760 --> 00:45:37,680
things you're doing uh with our projects

00:45:36,319 --> 00:45:39,119
or things that uh

00:45:37,680 --> 00:45:42,560
our projects aren't yet doing that are

00:45:39,119 --> 00:45:42,560
interested to you um

00:45:45,040 --> 00:45:51,599
cool we do have a question um we'll

00:45:48,240 --> 00:45:52,319
uh the charts here and the seminar be

00:45:51,599 --> 00:45:52,690
available

00:45:52,319 --> 00:45:55,359
um

00:45:52,690 --> 00:45:57,280
[Music]

00:45:55,359 --> 00:46:01,040
and it is being recorded and so this

00:45:57,280 --> 00:46:03,440
talk will be up on youtube

00:46:01,040 --> 00:46:04,400
and i'm not sure about the slides

00:46:03,440 --> 00:46:07,599
themselves

00:46:04,400 --> 00:46:15,839
but you can at least see this talk again

00:46:07,599 --> 00:46:15,839
up on youtube after after today

00:46:23,920 --> 00:46:28,400
okay thanks everyone we appreciate your

00:46:26,560 --> 00:46:30,720
attention being with us and

00:46:28,400 --> 00:46:31,440
hope to see you in the future have a

00:46:30,720 --> 00:46:35,200
good one

00:46:31,440 --> 00:46:35,200

YouTube URL: https://www.youtube.com/watch?v=lK0jHoXmU9E


