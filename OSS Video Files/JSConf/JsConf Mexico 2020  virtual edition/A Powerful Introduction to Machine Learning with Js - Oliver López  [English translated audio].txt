Title: A Powerful Introduction to Machine Learning with Js - Oliver LÃ³pez  [English translated audio]
Publication date: 2021-02-09
Playlist: JsConf Mexico 2020  virtual edition
Description: 
	-How to Train Your Browser: A Powerful Introduction to Machine Learning with JavaScript-

Through Tensorflow.js and ESNext you will learn briefly and dynamically the most important principles about creating web applications based on incredible pre-trained Machine Learning models.
Captions: 
	00:00:04,560 --> 00:00:07,440
i'm

00:00:05,359 --> 00:00:10,080
i'm the one that i'm going to talk about

00:00:07,440 --> 00:00:12,960
machine learning with the javascript

00:00:10,080 --> 00:00:13,519
but i needed i needed to think about

00:00:12,960 --> 00:00:18,240
this

00:00:13,519 --> 00:00:18,240
the title of this talk

00:00:18,880 --> 00:00:24,480
so our second speaker francisco sevilla

00:00:22,240 --> 00:00:25,680
he talked about the concept of machine

00:00:24,480 --> 00:00:28,320
learning it was a

00:00:25,680 --> 00:00:29,119
pretty interesting talk but now i'm

00:00:28,320 --> 00:00:32,079
going to talk

00:00:29,119 --> 00:00:33,040
more about this concept but at the same

00:00:32,079 --> 00:00:36,880
time

00:00:33,040 --> 00:00:38,079
to land it or how can we start or what

00:00:36,880 --> 00:00:41,360
can be our

00:00:38,079 --> 00:00:45,840
first steps of machine learning with a

00:00:41,360 --> 00:00:45,840
javascript and with this

00:00:48,320 --> 00:00:56,160
i will start and avoid confusions

00:00:52,079 --> 00:00:59,600
so that's why i'm going to start

00:00:56,160 --> 00:01:02,160
to with deep learning versus machine

00:00:59,600 --> 00:01:02,879
learning and this is a different concept

00:01:02,160 --> 00:01:06,720
because we

00:01:02,879 --> 00:01:08,960
listen this concept but we we confuse

00:01:06,720 --> 00:01:10,720
e-learning or deep learning or machine

00:01:08,960 --> 00:01:14,159
learning and we think it's the same

00:01:10,720 --> 00:01:16,080
but with this slide we get we have this

00:01:14,159 --> 00:01:19,600
a very clear example

00:01:16,080 --> 00:01:20,640
of how these are these the relation of

00:01:19,600 --> 00:01:24,159
this concept

00:01:20,640 --> 00:01:26,880
so the biggest concept is in

00:01:24,159 --> 00:01:28,000
artificial intelligence so this is a

00:01:26,880 --> 00:01:31,040
very huge

00:01:28,000 --> 00:01:35,119
area and of course in

00:01:31,040 --> 00:01:38,960
this area of the computer science

00:01:35,119 --> 00:01:43,600
there is a lot of implication not only

00:01:38,960 --> 00:01:46,880
machine learning as a concept but

00:01:43,600 --> 00:01:50,159
cognitive methods and many

00:01:46,880 --> 00:01:54,640
other scientific areas

00:01:50,159 --> 00:01:58,560
that can be outside of the computer part

00:01:54,640 --> 00:02:00,640
and also in a intelligence art

00:01:58,560 --> 00:02:02,560
artificial intelligence intelligence we

00:02:00,640 --> 00:02:05,680
have machine learning

00:02:02,560 --> 00:02:07,360
and maybe you are developers in this

00:02:05,680 --> 00:02:10,479
area and maybe you've been

00:02:07,360 --> 00:02:13,360
hearing this word for many many years

00:02:10,479 --> 00:02:15,520
and i think it's a trending well not

00:02:13,360 --> 00:02:18,640
trending but i will tell you

00:02:15,520 --> 00:02:22,000
later my ideas about it so machine

00:02:18,640 --> 00:02:25,440
learning you can see a lot

00:02:22,000 --> 00:02:28,720
of methodologies that are used

00:02:25,440 --> 00:02:32,319
to to

00:02:28,720 --> 00:02:33,680
make automatization and machine learning

00:02:32,319 --> 00:02:37,040
as a science is

00:02:33,680 --> 00:02:40,319
how you train your machine

00:02:37,040 --> 00:02:40,879
to learn something we can define it like

00:02:40,319 --> 00:02:44,160
that

00:02:40,879 --> 00:02:47,680
i know that the definition is longer

00:02:44,160 --> 00:02:51,120
there's more technicalities but

00:02:47,680 --> 00:02:51,360
i also need to mention you that i'm not

00:02:51,120 --> 00:02:53,519
an

00:02:51,360 --> 00:02:54,560
expert in machine learning or deep

00:02:53,519 --> 00:02:58,159
learning but

00:02:54,560 --> 00:03:02,239
i love to explore these two concepts

00:02:58,159 --> 00:03:03,200
and understand it then we have another

00:03:02,239 --> 00:03:06,319
concept

00:03:03,200 --> 00:03:10,000
which is neural networks

00:03:06,319 --> 00:03:13,040
which are tools

00:03:10,000 --> 00:03:14,800
that are introduced and you will see

00:03:13,040 --> 00:03:18,000
that this concept is

00:03:14,800 --> 00:03:20,959
very important inside the machine

00:03:18,000 --> 00:03:22,720
learning area so a neural network is

00:03:20,959 --> 00:03:27,120
like a structure

00:03:22,720 --> 00:03:30,640
where we we have an input

00:03:27,120 --> 00:03:33,760
it can be data information

00:03:30,640 --> 00:03:34,159
and then there is a middle layer it can

00:03:33,760 --> 00:03:37,360
be

00:03:34,159 --> 00:03:40,400
simple or complex where

00:03:37,360 --> 00:03:43,760
the magic of course

00:03:40,400 --> 00:03:43,760
all this part of

00:03:44,159 --> 00:03:50,640
the algorithms take place

00:03:47,599 --> 00:03:54,319
so we change for a central uh

00:03:50,640 --> 00:03:56,560
information to uh output information

00:03:54,319 --> 00:03:58,000
and with these we arrive to deep

00:03:56,560 --> 00:04:01,519
learning

00:03:58,000 --> 00:04:05,280
and basically is

00:04:01,519 --> 00:04:08,799
or it's not as deep learning

00:04:05,280 --> 00:04:11,280
because you are in a deep way learning

00:04:08,799 --> 00:04:12,720
or the machine is in a deep way learning

00:04:11,280 --> 00:04:17,600
no it's more like

00:04:12,720 --> 00:04:21,519
or i read somewhere it's more like

00:04:17,600 --> 00:04:25,440
this data that i are like input

00:04:21,519 --> 00:04:28,479
can be more and more bigger

00:04:25,440 --> 00:04:32,320
and that's why it's deep

00:04:28,479 --> 00:04:34,880
so we can have a better output

00:04:32,320 --> 00:04:37,199
it's more or less like that i hope

00:04:34,880 --> 00:04:40,560
hopefully i will not confuse you

00:04:37,199 --> 00:04:41,680
so very fast i'm showing this slide and

00:04:40,560 --> 00:04:44,000
we have this

00:04:41,680 --> 00:04:45,759
information and what is important here

00:04:44,000 --> 00:04:49,680
is

00:04:45,759 --> 00:04:53,040
a difference of a classical programming

00:04:49,680 --> 00:04:55,680
versus machine learning

00:04:53,040 --> 00:04:56,400
in the first one classical programming

00:04:55,680 --> 00:05:00,639
we

00:04:56,400 --> 00:05:04,240
we have rules and data the rules

00:05:00,639 --> 00:05:06,479
just imagine a program with

00:05:04,240 --> 00:05:08,880
conditionals or other things and that's

00:05:06,479 --> 00:05:11,759
the program and the information

00:05:08,880 --> 00:05:12,720
is parameters of the information and

00:05:11,759 --> 00:05:15,680
with this

00:05:12,720 --> 00:05:16,960
we can trigger something answers as you

00:05:15,680 --> 00:05:20,320
can see in this

00:05:16,960 --> 00:05:21,199
layout and then we have machine learning

00:05:20,320 --> 00:05:24,800
where

00:05:21,199 --> 00:05:28,880
we add the data the input data

00:05:24,800 --> 00:05:32,080
and then output or answers

00:05:28,880 --> 00:05:32,800
and with these programs we arrive to

00:05:32,080 --> 00:05:36,320
rules

00:05:32,800 --> 00:05:40,720
and this is important rules are inside

00:05:36,320 --> 00:05:43,360
machine learning and these rules define

00:05:40,720 --> 00:05:46,479
how the algorithm learns and the

00:05:43,360 --> 00:05:50,080
classical example is

00:05:46,479 --> 00:05:52,160
image images classification just imagine

00:05:50,080 --> 00:05:55,440
this type of algorithm

00:05:52,160 --> 00:05:59,280
and with one image

00:05:55,440 --> 00:06:02,639
it's transformed to a micro

00:05:59,280 --> 00:06:06,160
micro units smaller micro units

00:06:02,639 --> 00:06:07,199
and there are like a matrix and a matrix

00:06:06,160 --> 00:06:10,000
you can see it

00:06:07,199 --> 00:06:10,720
with the length of the the mathematics

00:06:10,000 --> 00:06:14,000
or

00:06:10,720 --> 00:06:17,120
a set of data that

00:06:14,000 --> 00:06:20,319
will define the structure of the image

00:06:17,120 --> 00:06:24,000
so with all this matrix we can

00:06:20,319 --> 00:06:27,919
identify the colors in each region

00:06:24,000 --> 00:06:31,280
and this algorithm detect colors

00:06:27,919 --> 00:06:37,199
interpret them and with that

00:06:31,280 --> 00:06:40,960
the understanding of patterns of colors

00:06:37,199 --> 00:06:41,600
those patterns can have like a shape of

00:06:40,960 --> 00:06:45,759
a

00:06:41,600 --> 00:06:48,880
cat and if you

00:06:45,759 --> 00:06:52,080
show a lot of images of cats

00:06:48,880 --> 00:06:53,440
this algorithm will find a common

00:06:52,080 --> 00:06:56,479
pattern

00:06:53,440 --> 00:07:00,240
with this characteristics

00:06:56,479 --> 00:07:01,680
maybe shapes or colors and inside of the

00:07:00,240 --> 00:07:06,479
image and with this

00:07:01,680 --> 00:07:06,479
you are training your machine

00:07:09,840 --> 00:07:17,599
and about the theory the question is

00:07:13,440 --> 00:07:20,800
why deep learning why right now

00:07:17,599 --> 00:07:24,160
so this area

00:07:20,800 --> 00:07:27,039
well it's been for a lot of years

00:07:24,160 --> 00:07:28,479
there's several models that are

00:07:27,039 --> 00:07:31,840
currently

00:07:28,479 --> 00:07:35,919
used that have this origin

00:07:31,840 --> 00:07:35,919
in the 80s so why now

00:07:36,400 --> 00:07:40,639
or in the recent years we've been

00:07:38,639 --> 00:07:42,400
hearing a lot of this topic and it's

00:07:40,639 --> 00:07:45,840
because of three things

00:07:42,400 --> 00:07:45,840
the first one is hardware

00:07:48,080 --> 00:07:51,680
and for example nowadays in cloud

00:07:50,639 --> 00:07:55,039
computing

00:07:51,680 --> 00:07:58,960
we have these uh computers with more

00:07:55,039 --> 00:07:59,520
power and so something that is important

00:07:58,960 --> 00:08:02,800
when you

00:07:59,520 --> 00:08:06,479
train is that you need a lot of

00:08:02,800 --> 00:08:08,240
power of computing so uh the cp the

00:08:06,479 --> 00:08:11,759
normal cpu

00:08:08,240 --> 00:08:15,919
is not something that will

00:08:11,759 --> 00:08:19,360
give us the best performance or to run

00:08:15,919 --> 00:08:22,160
data big data sets you need a

00:08:19,360 --> 00:08:23,199
smaller servers but in parallel one to

00:08:22,160 --> 00:08:26,800
the other

00:08:23,199 --> 00:08:30,319
and this is the gpus and the these video

00:08:26,800 --> 00:08:33,919
cards so with this

00:08:30,319 --> 00:08:36,959
we can see nowadays that we can have a

00:08:33,919 --> 00:08:39,279
a cloud service or a cloud computer with

00:08:36,959 --> 00:08:43,200
a lot of gpus

00:08:39,279 --> 00:08:45,040
that work in a parallel way you rent it

00:08:43,200 --> 00:08:47,920
for hours and that's it

00:08:45,040 --> 00:08:50,959
so some years ago it was very expensive

00:08:47,920 --> 00:08:50,959
or impossible

00:08:51,279 --> 00:08:57,760
so this was the first step

00:08:54,959 --> 00:08:58,880
and so the machine learning can be more

00:08:57,760 --> 00:09:02,640
like there

00:08:58,880 --> 00:09:05,279
then we have the data set and benchmark

00:09:02,640 --> 00:09:06,080
that is all the information that is in

00:09:05,279 --> 00:09:08,399
the last

00:09:06,080 --> 00:09:11,200
years we're talking about that in the

00:09:08,399 --> 00:09:15,200
last 15 or 20 years

00:09:11,200 --> 00:09:16,000
with the boost of internet social media

00:09:15,200 --> 00:09:21,120
apps

00:09:16,000 --> 00:09:24,160
that are recovering data

00:09:21,120 --> 00:09:27,279
of ourself of our families or

00:09:24,160 --> 00:09:30,000
friends all that information is

00:09:27,279 --> 00:09:31,040
very useful not only in a corporate

00:09:30,000 --> 00:09:34,240
level

00:09:31,040 --> 00:09:37,440
but it's important

00:09:34,240 --> 00:09:40,800
how people

00:09:37,440 --> 00:09:44,000
developer companies

00:09:40,800 --> 00:09:47,519
or omgs manipulate

00:09:44,000 --> 00:09:51,360
the information to interpret those

00:09:47,519 --> 00:09:54,640
patterns for example the

00:09:51,360 --> 00:09:57,360
favorite food of a region of the

00:09:54,640 --> 00:10:00,399
population

00:09:57,360 --> 00:10:04,240
and the advances in

00:10:00,399 --> 00:10:07,839
algorithm not only the ones that we

00:10:04,240 --> 00:10:11,279
already have but a lot of these

00:10:07,839 --> 00:10:14,959
advances in a research level

00:10:11,279 --> 00:10:18,800
have been in the last 20 years

00:10:14,959 --> 00:10:22,079
so they are not private algorithm but

00:10:18,800 --> 00:10:27,120
public and are part of the models

00:10:22,079 --> 00:10:27,120
in libraries or in the community

00:10:27,920 --> 00:10:34,959
and in general or

00:10:31,360 --> 00:10:37,279
another thing that i want to mention

00:10:34,959 --> 00:10:38,160
is the importance of deep learning in

00:10:37,279 --> 00:10:41,200
the

00:10:38,160 --> 00:10:42,160
browser so one can think that with java

00:10:41,200 --> 00:10:45,560
script

00:10:42,160 --> 00:10:46,800
is not possible due to the language

00:10:45,560 --> 00:10:49,760
performance

00:10:46,800 --> 00:10:52,079
or there are not enough tools or

00:10:49,760 --> 00:10:56,000
ecosystems such as python

00:10:52,079 --> 00:10:57,360
but precisely an advantage or several

00:10:56,000 --> 00:11:01,040
advantages

00:10:57,360 --> 00:11:04,480
of deep learning based in the browser

00:11:01,040 --> 00:11:06,800
are the discussed reduced cost

00:11:04,480 --> 00:11:08,880
in the server so you don't have to

00:11:06,800 --> 00:11:12,240
process

00:11:08,880 --> 00:11:15,279
all your algorithm in a server you can

00:11:12,240 --> 00:11:16,800
do it in the user or in the client or

00:11:15,279 --> 00:11:20,079
customer part

00:11:16,800 --> 00:11:23,440
so tensorflowy.js library

00:11:20,079 --> 00:11:29,040
allowed us to to

00:11:23,440 --> 00:11:31,920
train this in the browser

00:11:29,040 --> 00:11:33,760
your algorithm is running in google

00:11:31,920 --> 00:11:36,959
chrome

00:11:33,760 --> 00:11:40,480
so we have that accessibility so

00:11:36,959 --> 00:11:43,839
you can run this algorithm

00:11:40,480 --> 00:11:46,800
inside mob mobile and with that

00:11:43,839 --> 00:11:49,279
with that we have a lot of versatility

00:11:46,800 --> 00:11:56,240
and then we have

00:11:49,279 --> 00:11:59,680
for example the the privacy of the data

00:11:56,240 --> 00:12:03,120
and and also we have the gpu

00:11:59,680 --> 00:12:06,160
instantan acceleration and with this

00:12:03,120 --> 00:12:06,800
we do not need gpu in a cloud service

00:12:06,160 --> 00:12:10,399
but

00:12:06,800 --> 00:12:14,160
in the same browser of course the

00:12:10,399 --> 00:12:16,959
data privacy is that we

00:12:14,160 --> 00:12:18,560
we are in the browser and we can do face

00:12:16,959 --> 00:12:21,519
recognition

00:12:18,560 --> 00:12:23,600
and identify i don't know a feeling or

00:12:21,519 --> 00:12:26,639
emotion

00:12:23,600 --> 00:12:30,639
this imaging classification is

00:12:26,639 --> 00:12:32,560
through the client so with these we have

00:12:30,639 --> 00:12:35,839
the privacy of the data

00:12:32,560 --> 00:12:36,720
and also or last we have this instant

00:12:35,839 --> 00:12:40,320
access

00:12:36,720 --> 00:12:41,120
through url and with the internet

00:12:40,320 --> 00:12:44,399
connection

00:12:41,120 --> 00:12:47,160
you can have it so let's

00:12:44,399 --> 00:12:49,519
start with this i want to talk about

00:12:47,160 --> 00:12:52,720
tensorflow.js this

00:12:49,519 --> 00:12:56,480
google library in

00:12:52,720 --> 00:13:00,240
tensorflow you need to remember

00:12:56,480 --> 00:13:06,880
that tensorflow is built for python

00:13:00,240 --> 00:13:09,440
mainly for python is like a getaway

00:13:06,880 --> 00:13:10,240
that are trained in tensorflow and they

00:13:09,440 --> 00:13:14,399
are read

00:13:10,240 --> 00:13:17,519
ready in in this port and

00:13:14,399 --> 00:13:21,360
we can run it with

00:13:17,519 --> 00:13:22,079
javascript with the language in the

00:13:21,360 --> 00:13:25,760
customer

00:13:22,079 --> 00:13:29,600
and and using gs

00:13:25,760 --> 00:13:35,040
so we can train those node gas and

00:13:29,600 --> 00:13:38,480
offer cdn with the pre-trained models

00:13:35,040 --> 00:13:41,680
and you can ask why is

00:13:38,480 --> 00:13:47,040
this operation in gpu is

00:13:41,680 --> 00:13:47,040
using webgo is a technology

00:13:47,360 --> 00:13:54,800
in this browser and what is important

00:13:51,600 --> 00:13:57,839
is webgl it was not the best

00:13:54,800 --> 00:14:01,760
idea it was not so good and with this

00:13:57,839 --> 00:14:03,279
the apps will need more memory will be

00:14:01,760 --> 00:14:06,560
heavy apps

00:14:03,279 --> 00:14:09,760
and they are using uh looking for

00:14:06,560 --> 00:14:13,839
alternatives and to change with

00:14:09,760 --> 00:14:17,440
gl we can think

00:14:13,839 --> 00:14:20,720
i don't remember

00:14:17,440 --> 00:14:24,399
with other future alternatives better

00:14:20,720 --> 00:14:28,800
than webgl but right now is with this

00:14:24,399 --> 00:14:29,440
library and before we start with the

00:14:28,800 --> 00:14:32,160
code

00:14:29,440 --> 00:14:32,720
i just want to mention three concept

00:14:32,160 --> 00:14:36,720
tensor

00:14:32,720 --> 00:14:40,320
is the first one it's just a

00:14:36,720 --> 00:14:44,639
computer's concept

00:14:40,320 --> 00:14:46,880
with a lot of net or an array with a lot

00:14:44,639 --> 00:14:46,880
of

00:14:47,199 --> 00:14:54,240
input and this is a statistical

00:14:50,800 --> 00:14:57,680
term where we have rules

00:14:54,240 --> 00:15:01,600
with data rules

00:14:57,680 --> 00:15:05,199
given to data and then this neural

00:15:01,600 --> 00:15:06,880
network that we can have this logic of

00:15:05,199 --> 00:15:10,480
the algorithm so we can

00:15:06,880 --> 00:15:14,079
interpret this data and with this

00:15:10,480 --> 00:15:14,079
we can define the rules

00:15:15,040 --> 00:15:18,560
now let's see the code

00:15:20,160 --> 00:15:27,680
just to start very quickly

00:15:24,560 --> 00:15:32,079
you can see how easy

00:15:27,680 --> 00:15:37,199
is starting with this

00:15:32,079 --> 00:15:37,199
language so this is the first model base

00:15:37,839 --> 00:15:45,199
the name is mobile net is very

00:15:41,440 --> 00:15:45,920
popular in tensor gas and this is to

00:15:45,199 --> 00:15:51,040
classify

00:15:45,920 --> 00:15:55,360
images so the first step

00:15:51,040 --> 00:15:58,720
and this comes from tensorflow.js

00:15:55,360 --> 00:16:01,279
is we can use all these models from a

00:15:58,720 --> 00:16:01,279
cdn

00:16:01,360 --> 00:16:06,480
we have this three imported models

00:16:06,839 --> 00:16:13,199
gs and then we

00:16:09,680 --> 00:16:17,759
have mobile net and a classifier

00:16:13,199 --> 00:16:20,320
chi-n and i will not

00:16:17,759 --> 00:16:21,440
go deeper in this but this is a

00:16:20,320 --> 00:16:25,720
classifier

00:16:21,440 --> 00:16:28,639
model based on data and

00:16:25,720 --> 00:16:32,000
francisco in his

00:16:28,639 --> 00:16:35,360
talk he explained about

00:16:32,000 --> 00:16:37,440
what was a k-n-n and a classifier and

00:16:35,360 --> 00:16:40,880
it's the same concept

00:16:37,440 --> 00:16:45,360
so here we have the find

00:16:40,880 --> 00:16:49,519
this tags for buttons

00:16:45,360 --> 00:16:54,480
with these ids and a video that will

00:16:49,519 --> 00:16:54,480
allowed us to the webcam

00:16:55,680 --> 00:17:02,720
here we connect mobilenet and

00:16:58,959 --> 00:17:06,000
this is where it's interesting mobilenet

00:17:02,720 --> 00:17:09,839
has inside this code

00:17:06,000 --> 00:17:13,039
that i will give it to you

00:17:09,839 --> 00:17:16,880
so if you want to look it further

00:17:13,039 --> 00:17:20,000
and then you will see how this behaves

00:17:16,880 --> 00:17:22,959
what happens here is

00:17:20,000 --> 00:17:23,600
we started with this function which is

00:17:22,959 --> 00:17:27,039
act

00:17:23,600 --> 00:17:30,799
as a synchronous and what happened

00:17:27,039 --> 00:17:34,000
here is you change the model

00:17:30,799 --> 00:17:34,000
through mobile net

00:17:35,360 --> 00:17:40,559
we are having this information from the

00:17:39,600 --> 00:17:43,919
server

00:17:40,559 --> 00:17:43,919
and then the webcam

00:17:44,799 --> 00:17:47,840
this is the tensor

00:17:47,919 --> 00:17:51,520
that will take the data from the images

00:17:50,799 --> 00:17:55,280
this is an

00:17:51,520 --> 00:17:56,640
api that is inside tensorflow.js and

00:17:55,280 --> 00:18:00,080
allowed us

00:17:56,640 --> 00:18:03,360
what what is in the video then

00:18:00,080 --> 00:18:07,520
we have in this example

00:18:03,360 --> 00:18:12,320
another function which is a scene a sink

00:18:07,520 --> 00:18:15,440
and is at example and capture the image

00:18:12,320 --> 00:18:19,039
is a python frame

00:18:15,440 --> 00:18:21,440
frame by frame in the webcam

00:18:19,039 --> 00:18:21,440
and

00:18:22,080 --> 00:18:29,679
here this is a activation variable

00:18:26,559 --> 00:18:33,200
and this allowed us to

00:18:29,679 --> 00:18:36,400
use the k-a-n classifier

00:18:33,200 --> 00:18:39,679
in this case it's an image and

00:18:36,400 --> 00:18:42,720
each captured image is

00:18:39,679 --> 00:18:45,039
with this variable through the webcam

00:18:42,720 --> 00:18:47,520
and the true parameter with this

00:18:45,039 --> 00:18:47,520
condition

00:18:48,320 --> 00:18:57,840
this classifier which is an

00:18:51,840 --> 00:18:57,840
outside variable already defined

00:19:00,400 --> 00:19:06,000
through this method

00:19:04,000 --> 00:19:07,360
receive this parameter which is

00:19:06,000 --> 00:19:10,799
classified

00:19:07,360 --> 00:19:11,280
and then activation and class id we will

00:19:10,799 --> 00:19:14,480
see it

00:19:11,280 --> 00:19:17,600
later is

00:19:14,480 --> 00:19:19,679
the bottom that we have here for

00:19:17,600 --> 00:19:22,480
different one

00:19:19,679 --> 00:19:23,200
but let's continue with the code this

00:19:22,480 --> 00:19:26,720
method

00:19:23,200 --> 00:19:30,320
is very important this release

00:19:26,720 --> 00:19:32,960
memory with these methods is that when

00:19:30,320 --> 00:19:35,679
is running with the client remember this

00:19:32,960 --> 00:19:39,600
is client not server

00:19:35,679 --> 00:19:42,640
they use a lot of gpu

00:19:39,600 --> 00:19:45,919
and they well they need this

00:19:42,640 --> 00:19:49,120
so that's why they need a lot of

00:19:45,919 --> 00:19:52,400
resources so with these we

00:19:49,120 --> 00:19:55,679
free memory

00:19:52,400 --> 00:19:57,120
release memory so there will be not a

00:19:55,679 --> 00:20:00,240
memory link

00:19:57,120 --> 00:20:03,760
and here we have more

00:20:00,240 --> 00:20:07,039
we can we select the four tags and we

00:20:03,760 --> 00:20:10,480
add with a click and we called an

00:20:07,039 --> 00:20:10,880
event at example and as i mentioned with

00:20:10,480 --> 00:20:13,840
ad

00:20:10,880 --> 00:20:15,360
example it's already here receive the

00:20:13,840 --> 00:20:18,480
class id

00:20:15,360 --> 00:20:22,480
and how the bottom is a tag one

00:20:18,480 --> 00:20:25,120
zero one and two and then we

00:20:22,480 --> 00:20:28,080
have this other loop infinity loop is

00:20:25,120 --> 00:20:31,600
the image classifier

00:20:28,080 --> 00:20:32,320
so frame by frame each image of the

00:20:31,600 --> 00:20:35,840
video

00:20:32,320 --> 00:20:38,480
is captured while the video is running

00:20:35,840 --> 00:20:39,039
so with this classifier if the classes

00:20:38,480 --> 00:20:42,159
is

00:20:39,039 --> 00:20:45,280
higher than zero we take this image

00:20:42,159 --> 00:20:49,120
with a webcam it's a webcam

00:20:45,280 --> 00:20:50,400
capture so several images that are

00:20:49,120 --> 00:20:54,240
running

00:20:50,400 --> 00:20:57,760
like in a real time and later

00:20:54,240 --> 00:21:02,080
again we have this variable activation

00:20:57,760 --> 00:21:07,840
is very similar of what is running here

00:21:02,080 --> 00:21:07,840
that is uploading one of the models

00:21:08,240 --> 00:21:15,360
with these parameters and image and

00:21:12,320 --> 00:21:17,840
last what we do

00:21:15,360 --> 00:21:17,840
is

00:21:18,640 --> 00:21:27,679
we have the result from the prediction

00:21:24,080 --> 00:21:31,520
that has that makes the classifier

00:21:27,679 --> 00:21:35,360
so in this example is this preload

00:21:31,520 --> 00:21:38,720
model and then give it with this result

00:21:35,360 --> 00:21:42,559
and we have an

00:21:38,720 --> 00:21:45,600
array of classes from a to d

00:21:42,559 --> 00:21:48,880
and we return throughout through

00:21:45,600 --> 00:21:48,880
console tag

00:21:50,320 --> 00:21:56,400
with this upper results

00:21:53,360 --> 00:21:59,679
and with this string

00:21:56,400 --> 00:22:03,120
prediction and probability and

00:21:59,679 --> 00:22:07,120
the values are here

00:22:03,120 --> 00:22:09,679
in the dom each tag that exists

00:22:07,120 --> 00:22:10,640
in the class and the probability that in

00:22:09,679 --> 00:22:14,080
this

00:22:10,640 --> 00:22:18,880
in this example is the result value

00:22:14,080 --> 00:22:22,400
of the of this model so each time

00:22:18,880 --> 00:22:23,919
we we load the model and we activate the

00:22:22,400 --> 00:22:27,840
model

00:22:23,919 --> 00:22:30,480
we need to have this this pose

00:22:27,840 --> 00:22:32,400
because with this we will have a release

00:22:30,480 --> 00:22:36,720
of memory

00:22:32,400 --> 00:22:39,360
and then this mentioned to tensorflow

00:22:36,720 --> 00:22:40,080
to take one of the frames of the video

00:22:39,360 --> 00:22:43,520
and then we

00:22:40,080 --> 00:22:47,200
execute this up function so with this

00:22:43,520 --> 00:22:50,880
small files well this is not so small

00:22:47,200 --> 00:22:55,280
we have this model and client model

00:22:50,880 --> 00:23:09,840
and let's see the result

00:22:55,280 --> 00:23:09,840
so let's enter here

00:23:25,200 --> 00:23:32,000
this is our the name of our file

00:23:28,400 --> 00:23:32,000
index we open it

00:23:33,360 --> 00:23:51,840
and here let's wait a little bit

00:24:11,120 --> 00:24:18,159
as you can see this access

00:24:14,480 --> 00:24:21,279
the weekend access to the camera

00:24:18,159 --> 00:24:24,080
and i hopefully this would not slow down

00:24:21,279 --> 00:24:25,919
because my camera needs a lot of

00:24:24,080 --> 00:24:28,720
resources but

00:24:25,919 --> 00:24:29,919
we let's inspect what is happening right

00:24:28,720 --> 00:24:33,200
now

00:24:29,919 --> 00:24:33,760
yes the model is right there and now

00:24:33,200 --> 00:24:37,039
it's

00:24:33,760 --> 00:24:39,520
waiting to to create the frame for the

00:24:37,039 --> 00:24:39,520
camera

00:24:40,159 --> 00:24:45,360
well normally it's not this slow

00:24:43,200 --> 00:24:46,880
i don't know if it's my internet

00:24:45,360 --> 00:24:51,360
connection i don't think

00:24:46,880 --> 00:24:51,360
maybe is the ram consumption

00:24:58,000 --> 00:25:01,120
now i have access to the camera and the

00:25:00,320 --> 00:25:04,159
model

00:25:01,120 --> 00:25:06,400
so i have here the four bottoms that i

00:25:04,159 --> 00:25:07,679
already mentioned and each and every one

00:25:06,400 --> 00:25:11,360
of them can read one

00:25:07,679 --> 00:25:14,400
image in the a i will

00:25:11,360 --> 00:25:17,440
say for for example my face

00:25:14,400 --> 00:25:21,840
this is model a and

00:25:17,440 --> 00:25:21,840
i can have multiple frames

00:25:21,919 --> 00:25:26,320
the idea is just to have a lot of frames

00:25:24,720 --> 00:25:29,919
of any object

00:25:26,320 --> 00:25:33,760
and then i can move from the image

00:25:29,919 --> 00:25:36,400
and put my phone here

00:25:33,760 --> 00:25:36,400
and save it

00:25:38,960 --> 00:25:44,799
in b or in the model that is

00:25:42,640 --> 00:25:44,799
b

00:25:50,640 --> 00:25:57,840
then i can have another object like this

00:25:55,440 --> 00:25:57,840
booklet

00:25:58,720 --> 00:26:02,320
this will be in model c

00:26:02,720 --> 00:26:11,840
and way to react and

00:26:05,840 --> 00:26:11,840
in model d anything else i don't know

00:26:19,120 --> 00:26:27,440
my mouse

00:26:24,640 --> 00:26:27,440
and save it

00:26:30,799 --> 00:26:38,080
with this model has four type of

00:26:34,240 --> 00:26:41,840
inputs and as you can see

00:26:38,080 --> 00:26:45,760
the prediction is here is a

00:26:41,840 --> 00:26:49,120
with all the photos or pictures

00:26:45,760 --> 00:26:52,480
i'm in a group then b group is

00:26:49,120 --> 00:26:55,039
phone and if i move and i put this

00:26:52,480 --> 00:26:56,080
object will be b as you can see in the

00:26:55,039 --> 00:26:59,600
slide

00:26:56,080 --> 00:27:03,120
and then uh notepad

00:26:59,600 --> 00:27:07,840
c but what happens if

00:27:03,120 --> 00:27:07,840
for example i have a book

00:27:08,080 --> 00:27:16,000
the prediction is c so it's okay

00:27:11,679 --> 00:27:20,159
it's working and i don't know with d

00:27:16,000 --> 00:27:23,760
and the mouse

00:27:20,159 --> 00:27:27,360
a little bit confusing

00:27:23,760 --> 00:27:30,399
if it's a mobile or a mouse

00:27:27,360 --> 00:27:32,559
so this is one of the very

00:27:30,399 --> 00:27:33,600
uh one of the applications that mobile

00:27:32,559 --> 00:27:37,520
native has

00:27:33,600 --> 00:27:39,760
you don't have to worry to pre-train

00:27:37,520 --> 00:27:42,240
in the server it's directly in the

00:27:39,760 --> 00:27:42,240
browser

00:27:43,919 --> 00:27:49,840
and now i will go back to the slide

00:27:54,080 --> 00:27:57,679
well here is mobile net this is the

00:27:56,240 --> 00:28:00,799
first algorithm

00:27:57,679 --> 00:28:01,200
and the second one is coco ssd this is a

00:28:00,799 --> 00:28:03,919
very

00:28:01,200 --> 00:28:04,880
this is another example is image

00:28:03,919 --> 00:28:08,000
classification

00:28:04,880 --> 00:28:11,600
algorithm but the difference

00:28:08,000 --> 00:28:15,600
is is it does not classify

00:28:11,600 --> 00:28:18,559
through the frame but with objects

00:28:15,600 --> 00:28:19,919
in other words this is an image

00:28:18,559 --> 00:28:22,240
classification

00:28:19,919 --> 00:28:23,600
and this is an object specific

00:28:22,240 --> 00:28:27,840
classification

00:28:23,600 --> 00:28:32,960
and osd is pre-loaded

00:28:27,840 --> 00:28:36,000
in several models like this for example

00:28:32,960 --> 00:28:37,039
there are different objects in just one

00:28:36,000 --> 00:28:40,480
image

00:28:37,039 --> 00:28:44,159
and with a lot of confidence

00:28:40,480 --> 00:28:47,440
it can be detected and how

00:28:44,159 --> 00:28:51,440
proxima is one to the other and i

00:28:47,440 --> 00:28:53,840
will show you another example

00:28:51,440 --> 00:28:58,960
and remember that all these examples

00:28:53,840 --> 00:29:02,960
will be in ihop and

00:28:58,960 --> 00:29:06,640
let's go to html in objects

00:29:02,960 --> 00:29:09,360
and we can omit this very fast it's just

00:29:06,640 --> 00:29:12,399
an html with a presentation

00:29:09,360 --> 00:29:12,880
text for you but what is important is

00:29:12,399 --> 00:29:16,559
this

00:29:12,880 --> 00:29:20,080
section where i have this button for

00:29:16,559 --> 00:29:23,600
webcam and the video remember as the

00:29:20,080 --> 00:29:29,679
other example is to pre-load

00:29:23,600 --> 00:29:29,679
the webcam and this is very simple

00:29:30,559 --> 00:29:38,840
and how to connect it from the cd cnn

00:29:34,960 --> 00:29:41,360
or yarn a package manager

00:29:38,840 --> 00:29:45,200
and

00:29:41,360 --> 00:29:48,080
here is uh for you to know the path

00:29:45,200 --> 00:29:48,880
and we have the tensorflow gs which is

00:29:48,080 --> 00:29:51,919
the general

00:29:48,880 --> 00:29:56,799
library and each model load

00:29:51,919 --> 00:29:59,679
separately this in this case is coco ssd

00:29:56,799 --> 00:30:01,440
and here is where the script is

00:29:59,679 --> 00:30:05,120
connected

00:30:01,440 --> 00:30:05,120
for the object detector

00:30:05,840 --> 00:30:12,320
there's not much time to explain

00:30:09,200 --> 00:30:15,679
all this code but

00:30:12,320 --> 00:30:19,200
let's go only to the important areas

00:30:15,679 --> 00:30:23,120
this upper part is a general part

00:30:19,200 --> 00:30:26,640
so we can read the content for example

00:30:23,120 --> 00:30:30,080
this allowed us to access for example

00:30:26,640 --> 00:30:30,080
demos and webcam

00:30:30,240 --> 00:30:36,960
in this case is the video and this small

00:30:34,000 --> 00:30:39,039
function is just to verify if we have

00:30:36,960 --> 00:30:42,320
access to the web

00:30:39,039 --> 00:30:45,760
webcam and if we have

00:30:42,320 --> 00:30:50,799
the permissions if if it's uh

00:30:45,760 --> 00:30:54,159
if we have the permission we enable

00:30:50,799 --> 00:30:57,200
the access to webcam this is not

00:30:54,159 --> 00:30:58,159
tensor gs but it's uh something that is

00:30:57,200 --> 00:31:00,960
internal

00:30:58,159 --> 00:31:02,080
so we can access to the permission of

00:31:00,960 --> 00:31:06,720
the browser

00:31:02,080 --> 00:31:10,240
and here is an important thing

00:31:06,720 --> 00:31:13,679
here is where you enable the webcam

00:31:10,240 --> 00:31:17,120
and what you do is to receive this event

00:31:13,679 --> 00:31:20,880
this function that is enable cam that is

00:31:17,120 --> 00:31:25,279
connected with this button and

00:31:20,880 --> 00:31:25,279
then through target

00:31:25,840 --> 00:31:30,799
what is in this button there is a remove

00:31:31,039 --> 00:31:38,000
once we made a click the button will

00:31:34,880 --> 00:31:41,919
disappear and right here

00:31:38,000 --> 00:31:45,840
there are parameters for the user media

00:31:41,919 --> 00:31:46,720
and to activate again the stream to the

00:31:45,840 --> 00:31:49,600
webcam

00:31:46,720 --> 00:31:53,760
this is very important to do it before

00:31:49,600 --> 00:31:56,720
capturing the model so we can read

00:31:53,760 --> 00:31:57,320
what is happening through this video so

00:31:56,720 --> 00:31:58,960
we can

00:31:57,320 --> 00:32:02,480
[Music]

00:31:58,960 --> 00:32:02,480
we can have all this frame

00:32:03,679 --> 00:32:09,279
then we have another function predict

00:32:07,039 --> 00:32:12,880
webcam

00:32:09,279 --> 00:32:15,279
and start classifying each frame of the

00:32:12,880 --> 00:32:18,559
stream

00:32:15,279 --> 00:32:21,279
maybe well the code is not so beautiful

00:32:18,559 --> 00:32:21,279
right here

00:32:21,519 --> 00:32:28,080
i didn't have the time to clean it up

00:32:24,960 --> 00:32:33,039
a little bit but you can see or what you

00:32:28,080 --> 00:32:33,039
what does is to take this model

00:32:35,919 --> 00:32:41,120
so the fact well i have very little time

00:32:40,640 --> 00:32:44,080
but

00:32:41,120 --> 00:32:44,960
what is important is to take each

00:32:44,080 --> 00:32:48,320
prediction

00:32:44,960 --> 00:32:51,679
and the percentage of each frame and

00:32:48,320 --> 00:32:54,880
if it happens it's there so

00:32:51,679 --> 00:32:58,320
the last area is to where we charge

00:32:54,880 --> 00:33:01,039
this model and

00:32:58,320 --> 00:33:03,279
through these parameters is this is the

00:33:01,039 --> 00:33:06,640
core of this model

00:33:03,279 --> 00:33:11,840
and let's run this function or

00:33:06,640 --> 00:33:11,840
sorry this program in html

00:33:14,240 --> 00:33:20,320
and you will find this detection of some

00:33:17,440 --> 00:33:23,519
objects with tensorflow and i say

00:33:20,320 --> 00:33:26,720
some of them so we

00:33:23,519 --> 00:33:26,720
enable the webcam

00:33:30,080 --> 00:33:37,760
let me show you finally how this

00:33:34,720 --> 00:33:40,399
once you run

00:33:37,760 --> 00:33:42,960
once the client have this active you

00:33:40,399 --> 00:33:47,360
will have something very similar to this

00:33:42,960 --> 00:33:47,360
the percentage of everything and that's

00:33:50,039 --> 00:33:53,039

YouTube URL: https://www.youtube.com/watch?v=on15riL66SE


