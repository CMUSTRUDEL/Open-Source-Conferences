Title: Yoga Pose - Andy Ruestow & Bryan Donovan - JSConf US 2019
Publication date: 2019-09-12
Playlist: JSConf US 2019
Description: 
	Let's have some fun with TensorFlow and React. Not familiar with TensorFlow? No problem, you will get a fast crash course and learn how to track faces and add silly adornments (I bet you would look good with a new set of reading frames) entirely in the browser with TensorFlow and React. With a good background in the tech let's expand to tracking multiple limbs and evaluating and scoring some yoga positions. We will look at a couple different scoring algorithms, and finally challenge the audience to beat our high score for ultimate bragging rights.
Captions: 
	00:00:00,160 --> 00:00:02,139
Yoga Pose - Andy Ruestow and Bryan Donovan

00:00:02,139 --> 00:00:03,139
Hello?

00:00:03,139 --> 00:00:04,139
Hi!

00:00:04,139 --> 00:00:05,139
Welcome back!

00:00:05,139 --> 00:00:06,139
We made it to 5:00.

00:00:06,139 --> 00:00:07,139
Oh, my gosh!

00:00:07,139 --> 00:00:08,139
Woohoo!!

00:00:08,139 --> 00:00:09,139
Having a great day so far?

00:00:09,139 --> 00:00:10,139
Yeah?

00:00:10,139 --> 00:00:11,139
The weather is beautiful?

00:00:11,139 --> 00:00:12,139
Awesome.

00:00:12,139 --> 00:00:13,139
So this is going to be our last talk in this room, so after this talk is done, I'm going

00:00:13,139 --> 00:00:14,139
to encourage everyone to head over to the SitePen Track to watch our last talk of the

00:00:14,139 --> 00:00:15,139
day, and then there's an awesome party, of course, so our last talk is going to be by

00:00:15,139 --> 00:00:16,139
Andy Ruestow and Bryan Donovan, and this is kinda cool, actually, they are going to show

00:00:16,139 --> 00:00:17,139
us how to use TensorFlow to rate yoga poses.

00:00:17,139 --> 00:00:18,139
So the fun fact for both of them is kind of funny because it's like the exact opposite.

00:00:18,139 --> 00:00:19,139
So Andy actually is going to be the one doing the yoga and he doesn't really do yoga.

00:00:19,139 --> 00:00:20,139
He's climbed a lot more mountains than he's done yoga, but Bryan has done a lot more yoga

00:00:20,139 --> 00:00:21,139
than he's climbed mountains, so they complement each other very nicely.

00:00:21,139 --> 00:00:22,139
So let's give it up for Bryan and for Andy.

00:00:22,139 --> 00:00:23,139
[applause]

00:00:23,139 --> 00:00:24,139
Hey, everybody, thanks for coming.

00:00:24,139 --> 00:00:25,139
>> Hello.

00:00:25,139 --> 00:00:26,139
My computer is locked here, so you can watch me type my password.

00:00:26,139 --> 00:00:27,139
All right, so we're going to get started here with the yoga pose and if you've been in this

00:00:27,139 --> 00:00:28,139
room earlier today, you've probably seen a lot of really great presentations.

00:00:28,139 --> 00:00:29,139
David just gave a really great one about Imposter Syndrome which I think we're both feeling

00:00:29,139 --> 00:00:30,139
a little bit right now.

00:00:30,139 --> 00:00:31,139
>> Absolutely.

00:00:31,139 --> 00:00:32,770
>> And he also mentioned some things about confirmation bias and a quick little story

00:00:32,770 --> 00:00:33,770
about that.

00:00:33,770 --> 00:00:38,039
I've got a wife and two kids, and they were lucky enough to come along with us on the

00:00:38,039 --> 00:00:40,300
trip here today.

00:00:40,300 --> 00:00:46,309
And any time I go on a work conference, my wife calls it a work vacation.

00:00:46,309 --> 00:00:50,870
So I always explain, no, it's -- we're actually, we're learning, it's, you know, very dedicated,

00:00:50,870 --> 00:00:57,170
we are spending a lot of learning new technologies, not learning people, so when we're driving

00:00:57,170 --> 00:01:02,449
up to the resort yesterday and we saw the palm trees and the beautiful son, I think

00:01:02,449 --> 00:01:08,630
the confirmation bias set in and this is in fact a work vacation.

00:01:08,630 --> 00:01:09,630
>> She needs a vacation.

00:01:09,630 --> 00:01:10,630
>> Well.

00:01:10,630 --> 00:01:13,590
She's at the beach today.

00:01:13,590 --> 00:01:16,290
>> So just a little bit about Bryan and myself.

00:01:16,290 --> 00:01:20,240
Buyian is a software lead at Lockheed Martin.

00:01:20,240 --> 00:01:24,350
He's been developing software for pretty much his whole life but over the last 20 years,

00:01:24,350 --> 00:01:30,340
really as a lead developer, chief architect of a lot of cool systems.

00:01:30,340 --> 00:01:36,970
He is really the driving force, like the conductor and really the engine to drive a lot of our

00:01:36,970 --> 00:01:42,280
programs forward and that's where my train analogy runs out of steam.

00:01:42,280 --> 00:01:48,350
Myself, I'm a DevOps tech lead which means that I'm not good as a developer and not good

00:01:48,350 --> 00:01:55,640
at relations, but what I'm really good at is to be able to enable developers to be the

00:01:55,640 --> 00:02:02,610
best at what they're at and for humans it is being creative and we're best at solving

00:02:02,610 --> 00:02:07,600
problems and a problem we're not really good at solving is doing repetitive tasks over

00:02:07,600 --> 00:02:12,820
and over again.

00:02:12,820 --> 00:02:18,160
I take a lot of joy in automating all of those things, so that the creative people, especially

00:02:18,160 --> 00:02:21,220
like Bryan, can do what they're best at.

00:02:21,220 --> 00:02:27,409
>> Yeah, DevOps makes our life better, absolutely.

00:02:27,409 --> 00:02:33,150
>> Andy: I little bit more on the personal side.

00:02:33,150 --> 00:02:36,780
And to highlight how we're opposites.

00:02:36,780 --> 00:02:46,070
I live in Upstate New York and that means that I enjoy winter and I have two small humans

00:02:46,070 --> 00:02:49,160
as roommates and like I mentioned, they're at the beach today.

00:02:49,160 --> 00:02:55,200
They say that you should try everything at least once once in life just to see what it's

00:02:55,200 --> 00:02:56,200
like.

00:02:56,200 --> 00:02:59,400
I've done the science on this next one, you guys -- don't get hit by a car.

00:02:59,400 --> 00:03:02,980
It's not so much fun.

00:03:02,980 --> 00:03:05,010
And am primarily a carnivore.

00:03:05,010 --> 00:03:12,810
>> Bryan: For myself, I live in Los Angeles, where we experience zero months of winter

00:03:12,810 --> 00:03:13,930
each year.

00:03:13,930 --> 00:03:22,320
I live near a beach, Venice Beach, I have two roommates, wife and dog and I've been

00:03:22,320 --> 00:03:25,959
hit by zero cars, a much better experience.

00:03:25,959 --> 00:03:32,450
Herbivore, so no meat and what we can both agree on it beer and coffee.

00:03:32,450 --> 00:03:34,250
>> Andy: I think that's what make us such great friends.

00:03:34,250 --> 00:03:35,250
>> Bryan: That's right.

00:03:35,250 --> 00:03:39,980
>> Andy: So why are you here?

00:03:39,980 --> 00:03:43,040
Primarily to see us make fools of ourselves.

00:03:43,040 --> 00:03:47,100
Bryan called me up a few months and said hey, why don't you come to Southern California

00:03:47,100 --> 00:03:55,030
and go to a conference and a couple weeks later I said, hey, Bryan, why don't we present

00:03:55,030 --> 00:03:57,460
at that conference.

00:03:57,460 --> 00:04:00,040
So a few of the technologies we use for yoga possess.

00:04:00,040 --> 00:04:09,570
Node.js, I don't think they'd let us in the door if we didn't use.

00:04:09,570 --> 00:04:17,799
>> React, TensorFlow one of the fun toys that we don't get to play a whole lot with our

00:04:17,799 --> 00:04:20,340
day jobs.

00:04:20,340 --> 00:04:25,260
Some pose estimation that happens in real time in the browser and then some of the deployment

00:04:25,260 --> 00:04:29,570
things that I find pretty interesting.

00:04:29,570 --> 00:04:41,070
>> Bryan: So React, yes, the one with hooks, really great if new tech in 16: 8 I'm sure

00:04:41,070 --> 00:04:45,090
you've seen a lot of those, and great, we're moving over to hooks, we're going to use hooks

00:04:45,090 --> 00:04:46,820
for this whole thing.

00:04:46,820 --> 00:04:57,780
Look how great use state is and then I'm off using use effect and then I want to share

00:04:57,780 --> 00:05:03,030
some global states and now I'm using use context and then I have this mutable thing that I

00:05:03,030 --> 00:05:13,340
want to keep track of and so now I'm into useRef and then you want to use the set interval.

00:05:13,340 --> 00:05:16,130
So you're using a custom hook called useInterval.

00:05:16,130 --> 00:05:18,750
And it's super interesting.

00:05:18,750 --> 00:05:27,320
Dan wrote a blogpost on how it can be used instead of set interval.

00:05:27,320 --> 00:05:34,150
>> Yeah, it's really interesting how the underlying hook technology allows you to take the ones

00:05:34,150 --> 00:05:36,590
that React has published and use them.

00:05:36,590 --> 00:05:41,050
But also extend them in ways that you can be creative about and find new uses about,

00:05:41,050 --> 00:05:44,669
like the one that Dan published for handling intervals.

00:05:44,669 --> 00:05:51,930
TensorFlow, how many people have heard of TensorFlow?

00:05:51,930 --> 00:05:52,930
Several.

00:05:52,930 --> 00:05:55,430
How many have used it before?

00:05:55,430 --> 00:05:57,560
Fewer, great.

00:05:57,560 --> 00:06:00,650
So TensorFlow.js is cool.

00:06:00,650 --> 00:06:08,340
It allows you to train and deploy models in a browser or in a node environment.

00:06:08,340 --> 00:06:10,810
I think it makes machine learning easy.

00:06:10,810 --> 00:06:17,090
We work with a lot of data scientists, and they're really big nerds and they make machine

00:06:17,090 --> 00:06:21,760
learning actually easy, like the things that they do is really impressive and it makes

00:06:21,760 --> 00:06:27,530
our life as more front-end and application developers, easy to take what they've done

00:06:27,530 --> 00:06:32,850
and really just implement it, so it was fun for us to jump into TensorFlow and actually

00:06:32,850 --> 00:06:39,840
start playing with some of the models, creating our own and seeing how we can work with them.

00:06:39,840 --> 00:06:42,120
Another great thing about TensorFlow is the docs.

00:06:42,120 --> 00:06:45,620
There's a handful of tools that I think have really amazing docs.

00:06:45,620 --> 00:06:48,800
Docker is one of them.

00:06:48,800 --> 00:06:50,330
TensorFlow had really great docs.

00:06:50,330 --> 00:06:52,150
Bootstrap is amazing that stuff.

00:06:52,150 --> 00:06:56,780
So when a tool has really great docs, I think it makes it easier to understand it or at

00:06:56,780 --> 00:07:00,800
least how to use it.

00:07:00,800 --> 00:07:08,710
>> Bryan: Specifically out of TensorFlow there's a model called pose net and what it's used

00:07:08,710 --> 00:07:16,150
for is to determining pose information in real time or you'll feed it a video or image

00:07:16,150 --> 00:07:20,360
and what that model will give back to you are 17 different body parts, it will show

00:07:20,360 --> 00:07:28,300
you where somebody's eyes are, where the nose is, shoulders and you can take that pose then

00:07:28,300 --> 00:07:33,949
and basically run your algorithm against those 17 different body parts to do whatever you

00:07:33,949 --> 00:07:34,949
want.

00:07:34,949 --> 00:07:40,240
In our case, we're going to be scoring some yoga poses, but the pretty cool thing about

00:07:40,240 --> 00:07:46,380
PoseNet where we get to see the browser and how far it's come is it runs completely in

00:07:46,380 --> 00:07:52,410
the browser, so there isn't any data being sent out to some external server.

00:07:52,410 --> 00:07:59,580
That pose estimation, that neural network is all running exclusively with your browser

00:07:59,580 --> 00:08:08,190
and just use a convolutional neural net to basically return those pose and there's a

00:08:08,190 --> 00:08:15,500
neural net under the hood that's using to determine oh, a human is in this image, these

00:08:15,500 --> 00:08:23,400
are the parts of that human and then mapping out the XY coordinates that you can then use.

00:08:23,400 --> 00:08:31,180
Andy: So out of the box, PoseNet ships with a handful of models.

00:08:31,180 --> 00:08:34,310
It's a mobile mold.

00:08:34,310 --> 00:08:41,329
It gives a lot less accuracy when coming up with the key point positions and confidence

00:08:41,329 --> 00:08:43,019
in each of those.

00:08:43,019 --> 00:08:50,190
There's a beefier one, called ResNet 50 which I really wanted to work and it really crushed

00:08:50,190 --> 00:08:55,279
the processer, to the point where we were getting like 10 to 15 frames a second, which

00:08:55,279 --> 00:09:01,769
sucks, so we couldn't go with that one.

00:09:01,769 --> 00:09:08,079
So we used mobile net v1.

00:09:08,079 --> 00:09:13,850
Then like Bryan mentioned, out of the box it can detect multiple people which is kind

00:09:13,850 --> 00:09:20,639
of cool and could have some implications for different ways that you could use Posenet.

00:09:20,639 --> 00:09:27,709
So let's have some fun with the first toy that we created.

00:09:27,709 --> 00:09:31,220
Face detection and tracking so here's Will with some really cool glasses on.

00:09:31,220 --> 00:09:35,100
Bryan, I don't know if you want to step out and show some code here.

00:09:35,100 --> 00:09:37,369
>> Bryan: Absolutely so basically here ... >> Andy: Did you hit the go button?

00:09:37,369 --> 00:09:38,369
You have to -- perfect.

00:09:38,369 --> 00:09:39,369
There we go.

00:09:39,369 --> 00:09:40,369
>> Bryan: Thank you.

00:09:40,369 --> 00:09:45,029
Basically see we're grabbing that pose, the pose consists of those -- I'm 17 points that

00:09:45,029 --> 00:09:48,899
we talked about before, and we're basically going to go into that pose, look at the key

00:09:48,899 --> 00:09:56,540
points and say where is the nose, where is the eye, and just do some simple math here

00:09:56,540 --> 00:10:03,459
to determine how wide the glasses are, we'll do a ratio of the image that we're going to

00:10:03,459 --> 00:10:04,459
be using.

00:10:04,459 --> 00:10:11,600
We'll do a calculation so just doing the inverse tangent of looking to calculate the angle

00:10:11,600 --> 00:10:18,089
of the face so we can apply the glasses in the correct orientation and just doing a quick

00:10:18,089 --> 00:10:25,009
translation based on the nose so we can place them in the correct spot, applying the rotation

00:10:25,009 --> 00:10:31,379
based on the angle and we're going to draw that image onto the canvas.

00:10:31,379 --> 00:10:32,709
So what does that look like?

00:10:32,709 --> 00:10:33,709
Sorry, Andy.

00:10:33,709 --> 00:10:34,709
>> Andy: Yeah, no worries.

00:10:34,709 --> 00:10:35,709
So you can see we fully embraced the saved by the bell theme here.

00:10:35,709 --> 00:10:37,939
Do you want to talk about how you added some key press magic here?

00:10:37,939 --> 00:10:42,350
>> Yeah, so basically what we do, there's Andy.

00:10:42,350 --> 00:10:49,649
Bryan: We wrapped the Pose net model in the React and basically we're hooking the keyboard

00:10:49,649 --> 00:10:57,079
and we can do some simple logic to say we want to render this canvas on top of the video

00:10:57,079 --> 00:10:58,079
we're seeing.

00:10:58,079 --> 00:11:08,059
This harsh light is a little rough, but -- hahahaha [applause]

00:11:08,059 --> 00:11:13,990
Andy: So I think we also learned something pretty important about users by coming here

00:11:13,990 --> 00:11:15,670
and being on this stage.

00:11:15,670 --> 00:11:21,199
It's super-easy as developers to build something in a way that you expect your users to interact

00:11:21,199 --> 00:11:22,459
with it.

00:11:22,459 --> 00:11:25,529
So for Bryan and I sitting in an office, sitting in our desks in our homes.

00:11:25,529 --> 00:11:29,699
>> Andy Bryan: Nice ambient lighting Andy: Yeah, and then you come up here and

00:11:29,699 --> 00:11:36,660
you have white background and harsh lighting so I think it's great to think that users

00:11:36,660 --> 00:11:42,029
are going to abuse your systems, so here's a great example.

00:11:42,029 --> 00:11:45,769
There we got Bob there.

00:11:45,769 --> 00:11:47,850
Here's another one of the technologies that we used.

00:11:47,850 --> 00:11:49,239
It's the Canvas API.

00:11:49,239 --> 00:11:50,759
This is pretty need.

00:11:50,759 --> 00:11:56,860
You're able to do basic drawing manipulations just with JavaScript.

00:11:56,860 --> 00:12:00,670
It's native to what, all browsers?

00:12:00,670 --> 00:12:03,889
And there's a bunch of libraries that wrap that, that make things easier.

00:12:03,889 --> 00:12:09,230
I guess we did it the hard way just by manipulating Canvas directly but there's always a break

00:12:09,230 --> 00:12:12,130
point where you realize, do I need this additional library?

00:12:12,130 --> 00:12:14,300
Do I not need it?

00:12:14,300 --> 00:12:20,649
And I think it's a good practice to try and do things yourself first, insofar as you can

00:12:20,649 --> 00:12:21,649
still make progress.

00:12:21,649 --> 00:12:25,929
As soon as you find yourself running into a brick wall and the progress is slowed, it's

00:12:25,929 --> 00:12:30,739
a great opportunity to bring in some of those other tools, but because we had this simple

00:12:30,739 --> 00:12:35,040
use case, we decided to use Canvas just directly.

00:12:35,040 --> 00:12:42,209
A few other things we did here related to Canvas and also having access to user media

00:12:42,209 --> 00:12:49,449
is to grab the camera that user might have available.

00:12:49,449 --> 00:12:55,249
So there's a few different ways that that can be tuned to inspect which devices a user

00:12:55,249 --> 00:13:02,420
has available to them whether it's a front-facing or rear-facing camera.

00:13:02,420 --> 00:13:13,579
Bryan: So once you have those 17 key points to actually start being able to understand

00:13:13,579 --> 00:13:19,639
or how to score how that those body parts are in relation to something else, we need

00:13:19,639 --> 00:13:25,809
to turn those into vectors, so just basically taking each one of the 17 key points, iterating

00:13:25,809 --> 00:13:31,949
through those, creating vectors through an additional key point and basically we're creating

00:13:31,949 --> 00:13:38,189
a bunch of XY vectors in that space that we can start to say, OK, based on this vector,

00:13:38,189 --> 00:13:42,759
how is it going to compare to some other vector that you're expecting?

00:13:42,759 --> 00:13:49,109
And the way we did that is we created basically like a gold standard of a yoga pose and we

00:13:49,109 --> 00:13:54,510
said, OK, if we were to look at that yoga pose, what would it look like in X-Y vector

00:13:54,510 --> 00:13:57,499
space and create that model.

00:13:57,499 --> 00:14:03,679
So that's a algorithm that's running that says let's compare that vector to another

00:14:03,679 --> 00:14:06,930
vector and use something called cosine similarity.

00:14:06,930 --> 00:14:20,249
If you're at 1 that means you're perfect, those vectors are completely on top of one

00:14:20,249 --> 00:14:28,489
another, or if it's 0, it's going to be basically 90 degrees away from that if it's -1 it's

00:14:28,489 --> 00:14:33,639
180, so you're going to be doing exactly the opposite of what you expect.

00:14:33,639 --> 00:14:39,970
Andy: Any time you're talking to a data scientist, and you come up with a model, you can just

00:14:39,970 --> 00:14:45,910
tell them that it's a neural net, just use your brain for it, so ...

00:14:45,910 --> 00:14:54,109
>> Bryan: So this is basically how we did this.

00:14:54,109 --> 00:14:56,139
This image has nothing to do with this slide.

00:14:56,139 --> 00:15:02,209
I just wanted to get a slide of ZachG on there.

00:15:02,209 --> 00:15:09,540
Bryan: So where Posenet gives you the pose, what we're doing is adding some additional

00:15:09,540 --> 00:15:13,509
information to that pose so we're going to look and say we're going to create this list

00:15:13,509 --> 00:15:20,119
of vectors, we're just going to give it the index of one part and the part index of another

00:15:20,119 --> 00:15:25,069
part and then basically define what's that -- so the right side then is the expected

00:15:25,069 --> 00:15:30,970
vector, so in this case we're expecting the left eye and the right eye to just be one

00:15:30,970 --> 00:15:38,910
in the positive of X and so essentially we're looking for both of your eyeballs are level.

00:15:38,910 --> 00:15:53,879
>> Andy: Can I jump out here and show an example of one of the models?

00:15:53,879 --> 00:15:58,299
>> Bryan: Yeah.

00:15:58,299 --> 00:16:05,199
So if you're familiar with mountain pose, maybe you can demo what a mountain pose.

00:16:05,199 --> 00:16:12,009
>> Andy: Bonus points if I don't fall off the stage.

00:16:12,009 --> 00:16:15,379
>> Just stand there literally just stand there.

00:16:15,379 --> 00:16:17,959
>> I can climb one, I can't pose one.

00:16:17,959 --> 00:16:20,739
>> So this is what mountain pose looks like.

00:16:20,739 --> 00:16:22,619
We're taking every line here.

00:16:22,619 --> 00:16:29,639
Basically lines 21-30 we're saying these are the expected vectors of that and it's actually

00:16:29,639 --> 00:16:36,059
really simple when you define that, basically you're looking for how is that represented,

00:16:36,059 --> 00:16:39,429
and it's basically translation invariant.

00:16:39,429 --> 00:16:42,619
You're just looking for the direction of that vector.

00:16:42,619 --> 00:16:51,060
Maybe if we can show -- do you mind stepping in front we can show those points?

00:16:51,060 --> 00:16:57,679
So what you basically get from Posenet -- >> Andy: I am not here.

00:16:57,679 --> 00:17:00,399
Where did I go?

00:17:00,399 --> 00:17:01,399
Lost the camera.

00:17:01,399 --> 00:17:02,399
Well, how about this: Production to the rescue?

00:17:02,399 --> 00:17:03,399
>> Bryan: Call in the DevOps guy.

00:17:03,399 --> 00:17:04,399
>> Andy: Might have lost the network here.

00:17:04,399 --> 00:17:05,399
Can't use the internet for anything!

00:17:05,399 --> 00:17:06,399
Well, we've lost network

00:17:06,399 --> 00:17:07,399
Bryan: We'll come back ... A

00:17:07,399 --> 00:17:08,399
>> AUDIENCE: Try Internet Explorer.

00:17:08,399 --> 00:17:09,399
Andy: Oh, no!

00:17:09,399 --> 00:17:10,399
Oh, I just died a little.

00:17:10,399 --> 00:17:11,399
[laughter]

00:17:11,399 --> 00:17:12,399
AUDIENCE: Check that the camera is still authorized?

00:17:12,399 --> 00:17:13,399
Andy: Camera still authorized.

00:17:13,399 --> 00:17:14,399
AUDIENCE: Top right.

00:17:14,399 --> 00:17:15,399
Andy: Take all my permissions! [laughter]

00:17:15,399 --> 00:17:16,399
Well, this is the most disappointing thing to happen today.

00:17:16,399 --> 00:17:17,399
Well, let's go through the slides and then try and resurrect things.

00:17:17,399 --> 00:17:18,399
man, what a fraud.

00:17:18,399 --> 00:17:19,399
These people came for yoga poses.

00:17:19,399 --> 00:17:20,399
>> Bryan: That's right, confidence just plummets.

00:17:20,399 --> 00:17:30,000
Yeah, so basically for all the math people out there, this is the cosine similarity scoring

00:17:30,000 --> 00:17:31,000
that we're using again.

00:17:31,000 --> 00:17:35,460
It's really just taking a look at those angles of the two vectors and we go across, so if

00:17:35,460 --> 00:17:40,740
you have, like in mountain pose it's going to look across those possible 10 vectors,

00:17:40,740 --> 00:17:45,080
look at the one -- >> Andy: The camera is back up?

00:17:45,080 --> 00:17:46,810
>> Bryan: Oh, it is.

00:17:46,810 --> 00:17:47,980
>> Andy: And now it's off.

00:17:47,980 --> 00:17:48,980
Oh!

00:17:48,980 --> 00:17:49,980
That is cruel.

00:17:49,980 --> 00:17:50,980
Yeah, all right.

00:17:50,980 --> 00:17:51,980
[applause]

00:17:51,980 --> 00:17:52,980
Bryan: Oh!

00:17:52,980 --> 00:17:53,980
Andy: Come on!

00:17:53,980 --> 00:18:06,040
I do not exist!

00:18:06,040 --> 00:18:16,370
AUDIENCE: Restart the camera.

00:18:16,370 --> 00:18:18,470
Andy: Different ports, everything.

00:18:18,470 --> 00:18:20,570
What have we got?

00:18:20,570 --> 00:18:21,570
[applause]

00:18:21,570 --> 00:18:23,410
So there's our key points.

00:18:23,410 --> 00:18:27,560
Bryan: 17 magical key points.

00:18:27,560 --> 00:18:30,380
Who knows how they show up.

00:18:30,380 --> 00:18:37,950
Andy: Well, since the thing is working, why don't we go through the vectors.

00:18:37,950 --> 00:18:44,820
Bryan: If in your poses you want to look across, say compare the shoulder to the foot, you

00:18:44,820 --> 00:18:47,580
would have that vector available to you.

00:18:47,580 --> 00:18:49,670
All right.

00:18:49,670 --> 00:18:56,390
So I say at this point we need to make Andy do some yoga poses.

00:18:56,390 --> 00:18:57,530
AUDIENCE: Yeah!

00:18:57,530 --> 00:19:03,510
Bryan: So we're going to be looking at every pose from 0 to 10, 10 being the best, we'll

00:19:03,510 --> 00:19:06,260
second him through five levels of yoga poses.

00:19:06,260 --> 00:19:11,330
So first one, Andy, we'll be starting off with mountain pose.

00:19:11,330 --> 00:19:16,910
Good job, 9 on mountain pose, that's good.

00:19:16,910 --> 00:19:22,790
Next one is -- hands up.

00:19:22,790 --> 00:19:26,100
Andy: I can do better.

00:19:26,100 --> 00:19:29,140
Nope, I can't do better.

00:19:29,140 --> 00:19:32,040
Bryan: Yoga pose says you can do better.

00:19:32,040 --> 00:19:36,570
We're going on to warrior II now.

00:19:36,570 --> 00:19:44,360
Looking good, Andy, don't fall off the stage.

00:19:44,360 --> 00:19:46,740
Three.

00:19:46,740 --> 00:19:50,470
Good, get that back foot up a little bit.

00:19:50,470 --> 00:19:54,610
Oh, looking good, looking good.

00:19:54,610 --> 00:19:56,580
And then chair pose.

00:19:56,580 --> 00:20:01,470
Oh, nice chair pose, maybe bring those arms up a little bit more.

00:20:01,470 --> 00:20:04,750
Lean forward a little bit more?

00:20:04,750 --> 00:20:07,270
Andy: Nope!

00:20:07,270 --> 00:20:13,580
Bryan: All right, 38! [applause]

00:20:13,580 --> 00:20:15,540
So 38 is pretty good.

00:20:15,540 --> 00:20:19,210
Wonder if anybody could beat 38?

00:20:19,210 --> 00:20:24,990
Andy: Anyone feel like they can beat 38?

00:20:24,990 --> 00:20:26,440
Any volunteers?

00:20:26,440 --> 00:20:27,440
>>

00:20:27,440 --> 00:20:32,860
I can do it.

00:20:32,860 --> 00:20:35,300
So what do I do first?

00:20:35,300 --> 00:20:36,300
Mountain?

00:20:36,300 --> 00:20:37,300
Mountain pose.

00:20:37,300 --> 00:20:41,060
Yes, please, watch the edge.

00:20:41,060 --> 00:20:48,390
And next up will be warrior I. Oh, that's nice warrior.

00:20:48,390 --> 00:20:51,120
I do yoga.

00:20:51,120 --> 00:21:02,050
All right, next up warrior II.

00:21:02,050 --> 00:21:03,050
Looking good.

00:21:03,050 --> 00:21:05,300
Andy still might be in the lead somehow.

00:21:05,300 --> 00:21:06,490
Doesn't make any sense.

00:21:06,490 --> 00:21:07,490
It's these pants!

00:21:07,490 --> 00:21:09,590
Bryan: All right, warrior 3.

00:21:09,590 --> 00:21:14,860
>> I don't want to fall! [laughter]

00:21:14,860 --> 00:21:18,900
Bryan: Looking good, and now chair pose.

00:21:18,900 --> 00:21:23,500
Utkatasana Oh, looking good.

00:21:23,500 --> 00:21:27,890
Pull two points out of it.

00:21:27,890 --> 00:21:31,950
>> Andy: I think she was handicapped there.

00:21:31,950 --> 00:21:36,140
>> Bryan: Thank you.

00:21:36,140 --> 00:21:38,930
Thanks, Katie.

00:21:38,930 --> 00:21:44,520
>> Andy: Thank you, Katie.

00:21:44,520 --> 00:21:45,910
Bryan.

00:21:45,910 --> 00:21:56,981
I recode we coded it to make Andy win, by the way.

00:21:56,981 --> 00:22:06,920
Andy: That's how to boost myself confidence, don't think I'm so good.

00:22:06,920 --> 00:22:13,320
Oh, sure, so a few things here about design.

00:22:13,320 --> 00:22:20,880
You tell from the slides to the actual application, we tried to embrace the Saved By the Bell

00:22:20,880 --> 00:22:24,230
theme.

00:22:24,230 --> 00:22:30,350
It gives them clear direction and purpose of what they're supposed to be doing.

00:22:30,350 --> 00:22:36,200
It can convey a mood, you can tell this was not supposed to be an overly serious application

00:22:36,200 --> 00:22:40,130
that we built, and it's -- it adds value.

00:22:40,130 --> 00:22:46,600
When you look at like an application that doesn't have a coherent design, it just doesn't

00:22:46,600 --> 00:22:48,700
feel as fun to interact with.

00:22:48,700 --> 00:22:55,660
So because I haven't learned my lesson -- Bryan: Real quick while Andy brings tup, one

00:22:55,660 --> 00:23:04,210
of our graphic designers, Eian did all the work, so a big shout-out to Eian.

00:23:04,210 --> 00:23:14,170
Andy: Yeah, he did a great job.

00:23:14,170 --> 00:23:19,420
Bryan: This is when you ask a developer to build you something.

00:23:19,420 --> 00:23:26,770
Andy: And of course the camera won't work, but as you can tell, there's absolutely no

00:23:26,770 --> 00:23:28,310
design here.

00:23:28,310 --> 00:23:33,510
We had a canvas displaying the image with the camera and it was not fun to interact

00:23:33,510 --> 00:23:34,590
with.

00:23:34,590 --> 00:23:45,720
Didn't let anyone know what to do and without that design, you can be quite lost.

00:23:45,720 --> 00:23:53,660
I'll cut my losses on that.

00:23:53,660 --> 00:23:59,060
So some potential next steps we might want to take if we chose to be even more serious

00:23:59,060 --> 00:24:00,060
than we are right now.

00:24:00,060 --> 00:24:02,260
Bryan: We missed fix the camera on this list.

00:24:02,260 --> 00:24:05,510
>> Andy: Yes, support cameras?

00:24:05,510 --> 00:24:08,150
So we could improve the model.

00:24:08,150 --> 00:24:13,870
Obviously the model that Posenet model is the mobile version, a lot of the parameters

00:24:13,870 --> 00:24:17,830
are tweaked just to be able to run on a MacBook.

00:24:17,830 --> 00:24:22,950
Considering the wide array of devices that a user are likely to use you want to be able

00:24:22,950 --> 00:24:26,230
to accommodate them as much as possible.

00:24:26,230 --> 00:24:30,930
We could up our modeling game of the actual yoga poses by doing some real machine learning

00:24:30,930 --> 00:24:40,030
TensorFlow of known good yoga poses and bad ones, as well.

00:24:40,030 --> 00:24:41,380
Tests are extremely important.

00:24:41,380 --> 00:24:56,760
Tim this morning gave an amazing talk this morning on test driven development.

00:24:56,760 --> 00:25:01,030
>> Bryan: But we have no tests.

00:25:01,030 --> 00:25:02,890
Andy: None at all.

00:25:02,890 --> 00:25:07,650
The more costly to a user any change would be, the more valuable having tests against

00:25:07,650 --> 00:25:11,000
those changes are.

00:25:11,000 --> 00:25:12,000
And then some optimization.

00:25:12,000 --> 00:25:14,610
We again did absolutely none.

00:25:14,610 --> 00:25:20,150
Is and I don't know, adapt the Peloton model and become rich by New Year's rush.

00:25:20,150 --> 00:25:21,150
And with that, have a super-nice night, San Diego.

00:25:21,150 --> 00:25:22,150
[applause]

00:25:22,150 --> 00:25:23,150
>> Thank you.

00:25:23,150 --> 00:25:24,150
Thank you, aren't computers wonderful?

00:25:24,150 --> 00:25:25,150
They always work perfectly when we expect them to.

00:25:25,150 --> 00:25:26,150
All right.

00:25:26,150 --> 00:25:27,150
So thank you everyone.

00:25:27,150 --> 00:25:28,150
This is our last talk of the day, in this room, so if we could head on over next door,

00:25:28,150 --> 00:25:29,150
starting at 5:45 is going to be the last talk of the day.

00:25:29,150 --> 00:25:30,150
She's going to talk about who's not in the room, how to build better products by engaging

00:25:30,150 --> 00:25:31,150
hard to reach users and it sounds like it's going to be a great talk and I will see you

00:25:31,150 --> 00:25:32,150
over there.

00:25:32,150 --> 00:25:32,152

YouTube URL: https://www.youtube.com/watch?v=aGBnDhDI-Ds


