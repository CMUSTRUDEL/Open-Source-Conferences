Title: The (Full)stack Trace: Understand Your App with Distributed Tracing - Will Klein - JSConf US 2019
Publication date: 2019-09-10
Playlist: JSConf US 2019
Description: 
	Original Title: Follow the (full)stack trace: understand your app with distributed tracing

What if we could follow a user request, from a page load in the browser, to our backend, through our services, to the database, and back? What does it look like to see how our UI receives data and renders its views across a timeline? What happens when we put these traces together?!

Distributed tracing is a collection of timings across the entire stack, for any given interaction. Whether itâ€™s a page load or a button click, we can measure time for all of the work in the browser, server, and database. In this talk, we will learn the basics of distributed tracing, and how to get started with instrumenting both our frontend and backend in a real world application. You will walk away with the tools you need to setup distributed tracing from scratch, and ultimately, understand everything that happens when someone uses your app!

https://2019.jsconf.us/speakers/will-klein
Captions: 
	00:00:04,220 --> 00:00:09,450
oops I am extremely nervous right now I

00:00:07,500 --> 00:00:13,950
feel like I can't breathe but I'm

00:00:09,450 --> 00:00:19,529
extremely excited but first I have

00:00:13,950 --> 00:00:23,880
something to share warning right now

00:00:19,529 --> 00:00:26,699
your users are at risk users of the web

00:00:23,880 --> 00:00:28,230
everywhere are frustrated in this very

00:00:26,699 --> 00:00:31,560
moment with the applications that

00:00:28,230 --> 00:00:33,809
they're forced used every day this is a

00:00:31,560 --> 00:00:35,510
review from the internet somebody wrote

00:00:33,809 --> 00:00:37,410
about their application hey Amelia

00:00:35,510 --> 00:00:39,950
somebody wrote about their application

00:00:37,410 --> 00:00:42,899
the new version sometimes slows down

00:00:39,950 --> 00:00:44,820
this is a real user of a real web app

00:00:42,899 --> 00:00:46,230
there's a real review it's from the

00:00:44,820 --> 00:00:49,950
Internet so we know we can trust it

00:00:46,230 --> 00:00:52,199
and here's another review sometimes it

00:00:49,950 --> 00:00:58,140
takes a lot of time for loading the

00:00:52,199 --> 00:01:02,640
contents someone else simply wrote it's

00:00:58,140 --> 00:01:06,210
too slow this could happen to you and

00:01:02,640 --> 00:01:08,280
this could happen to your users but I'm

00:01:06,210 --> 00:01:10,799
here today to tell you that there is

00:01:08,280 --> 00:01:12,750
hope my name is Wil Klein I'm from

00:01:10,799 --> 00:01:14,850
Boulder Colorado where I work at workday

00:01:12,750 --> 00:01:18,390
as a full stack engineer this is my

00:01:14,850 --> 00:01:21,299
family and I also have a confession to

00:01:18,390 --> 00:01:25,140
share I have built apps that have

00:01:21,299 --> 00:01:28,470
reviews like these and when approached

00:01:25,140 --> 00:01:31,700
with these complaints I will initially

00:01:28,470 --> 00:01:35,909
reply well it works fast on my machine

00:01:31,700 --> 00:01:39,180
but what about their machine what about

00:01:35,909 --> 00:01:40,320
their browser I use Chrome but it turns

00:01:39,180 --> 00:01:45,869
out there's this other browser out there

00:01:40,320 --> 00:01:47,579
called Internet Explorer 11 and users

00:01:45,869 --> 00:01:49,530
everywhere are forced by their IT

00:01:47,579 --> 00:01:51,570
departments to use it to use

00:01:49,530 --> 00:01:53,420
applications like mine and it makes my

00:01:51,570 --> 00:01:55,500
life a living hell

00:01:53,420 --> 00:01:57,570
what about their connection I have a

00:01:55,500 --> 00:02:00,659
very fast internet connection at home

00:01:57,570 --> 00:02:03,630
and at work but not everyone has that

00:02:00,659 --> 00:02:05,909
and not everyone has a fast VPN either

00:02:03,630 --> 00:02:08,069
sometimes their internet is fast when

00:02:05,909 --> 00:02:11,310
they dial into a VPN across the world

00:02:08,069 --> 00:02:13,930
everything slows down a little bit and

00:02:11,310 --> 00:02:18,189
what about their data have you ever

00:02:13,930 --> 00:02:19,659
seen a defect or a bug where the the

00:02:18,189 --> 00:02:21,430
complaint is that they're they're rich

00:02:19,659 --> 00:02:25,739
text doesn't actually render as rich

00:02:21,430 --> 00:02:25,739
text but as HTML in a plain text field

00:02:25,769 --> 00:02:30,099
users do interesting things with our app

00:02:28,209 --> 00:02:33,819
that we don't quite anticipate all the

00:02:30,099 --> 00:02:36,489
time and what about their data some of

00:02:33,819 --> 00:02:38,769
our applications are configurable to the

00:02:36,489 --> 00:02:42,280
user or their organization where they

00:02:38,769 --> 00:02:44,590
can change their data model to have any

00:02:42,280 --> 00:02:47,590
type of Ire have different types of

00:02:44,590 --> 00:02:49,989
hierarchy and this can lead to lots of

00:02:47,590 --> 00:02:53,139
performance woes that we can't very well

00:02:49,989 --> 00:02:55,900
anticipate so there are many variables

00:02:53,139 --> 00:02:58,419
that work their way into our web app

00:02:55,900 --> 00:03:01,060
performance and our user experience and

00:02:58,419 --> 00:03:03,189
this is a full-stack problem we can't

00:03:01,060 --> 00:03:04,569
just look at the front end or the back

00:03:03,189 --> 00:03:06,900
end we need to look at the full picture

00:03:04,569 --> 00:03:10,409
and see what's happening throughout the

00:03:06,900 --> 00:03:13,450
system to know what we might need to do

00:03:10,409 --> 00:03:16,030
and there are tools we can use we can do

00:03:13,450 --> 00:03:17,680
performance audits on our application we

00:03:16,030 --> 00:03:21,069
can do performance testing on our micro

00:03:17,680 --> 00:03:23,919
services we can monitor our services and

00:03:21,069 --> 00:03:25,479
look at their response times and we can

00:03:23,919 --> 00:03:27,699
even do application profiling on the

00:03:25,479 --> 00:03:29,979
front end and the back end to look for

00:03:27,699 --> 00:03:33,280
memory leaks and anything that might be

00:03:29,979 --> 00:03:35,439
slowing down but none of these things

00:03:33,280 --> 00:03:38,590
look at what's actually happening for

00:03:35,439 --> 00:03:41,199
our users in the wild so how do we

00:03:38,590 --> 00:03:43,540
observe our users applications in the

00:03:41,199 --> 00:03:45,549
wild how do we observe their actual user

00:03:43,540 --> 00:03:47,769
experience to know what's really

00:03:45,549 --> 00:03:50,709
happening in their conditions when they

00:03:47,769 --> 00:03:52,329
use our application we're going to talk

00:03:50,709 --> 00:03:54,340
about that today and follow the full

00:03:52,329 --> 00:03:55,810
stack trace and learn how we can

00:03:54,340 --> 00:03:59,919
understand our app with the distributed

00:03:55,810 --> 00:04:02,560
tracing my cursor is in the middle

00:03:59,919 --> 00:04:04,979
screen I hate that so this is a

00:04:02,560 --> 00:04:07,150
daredevil from the Netflix series and

00:04:04,979 --> 00:04:11,169
daredevil is a very interesting Marvel

00:04:07,150 --> 00:04:12,729
superhero he's blind but he had his

00:04:11,169 --> 00:04:15,639
superpowers that he can sense everything

00:04:12,729 --> 00:04:18,759
around him with his other senses so much

00:04:15,639 --> 00:04:21,669
so that he's able to observe an

00:04:18,759 --> 00:04:24,159
unprecedented way despite lacking any

00:04:21,669 --> 00:04:26,380
vision so I wonder if there's something

00:04:24,159 --> 00:04:27,790
that we can tap into that would give us

00:04:26,380 --> 00:04:29,110
Bella / superpower

00:04:27,790 --> 00:04:34,270
so we can observe what's actually

00:04:29,110 --> 00:04:37,450
happening in the wild I believe we can

00:04:34,270 --> 00:04:40,420
get that with distributed tracing zoom

00:04:37,450 --> 00:04:41,890
is a little bit so this is a trace we're

00:04:40,420 --> 00:04:44,920
gonna jump right into what this looks

00:04:41,890 --> 00:04:49,080
like a trace is essentially a series of

00:04:44,920 --> 00:04:51,730
timings and each row in this is a

00:04:49,080 --> 00:04:53,620
specific timing where a specific thing

00:04:51,730 --> 00:04:56,170
happens and each of those things is

00:04:53,620 --> 00:04:59,350
called the span in this case the whole

00:04:56,170 --> 00:05:02,380
trace is following a user request the

00:04:59,350 --> 00:05:04,510
user request is going to hit slash

00:05:02,380 --> 00:05:06,150
dispatch with the HTTP GET request and

00:05:04,510 --> 00:05:09,160
then a bunch of things happen after that

00:05:06,150 --> 00:05:11,620
there's other HTTP requests associated

00:05:09,160 --> 00:05:13,870
with it to other endpoints there's

00:05:11,620 --> 00:05:16,330
database calls to my sequel there's

00:05:13,870 --> 00:05:18,280
access to Redis there's a bunch of

00:05:16,330 --> 00:05:22,060
things that we can see happening when

00:05:18,280 --> 00:05:23,830
this request processes now some of these

00:05:22,060 --> 00:05:25,300
things happen in parallel the the first

00:05:23,830 --> 00:05:26,560
four things and the blue and the yellow

00:05:25,300 --> 00:05:28,870
on the brown they're happening in

00:05:26,560 --> 00:05:31,120
parallel and that's that's good they can

00:05:28,870 --> 00:05:33,400
happen at the same time and then you see

00:05:31,120 --> 00:05:35,230
the next set of things happen afterwards

00:05:33,400 --> 00:05:38,100
so some things are happening in parallel

00:05:35,230 --> 00:05:40,180
some things are happening sequentially

00:05:38,100 --> 00:05:42,220
and this is interesting because then we

00:05:40,180 --> 00:05:44,020
can start to see with this trace at

00:05:42,220 --> 00:05:45,970
least in our back in here we can see

00:05:44,020 --> 00:05:48,040
what is happening how long is it taking

00:05:45,970 --> 00:05:50,470
what can happen at the same time and

00:05:48,040 --> 00:05:51,790
what's being blocked and this is where

00:05:50,470 --> 00:05:53,950
we can start to see where bottlenecks

00:05:51,790 --> 00:05:56,020
are happening it's also where we can

00:05:53,950 --> 00:06:00,640
start to see what actually happens when

00:05:56,020 --> 00:06:04,230
you use a request happens so this was

00:06:00,640 --> 00:06:07,510
shown with Yaeger UI from Yaeger tracing

00:06:04,230 --> 00:06:09,160
Iger is a open source project that is

00:06:07,510 --> 00:06:12,360
managed by the cloud native computing

00:06:09,160 --> 00:06:15,220
foundation there's several members of

00:06:12,360 --> 00:06:17,200
the cloud native computing foundation

00:06:15,220 --> 00:06:19,030
that are sponsoring and supporting this

00:06:17,200 --> 00:06:21,040
project so hopefully it'll be around

00:06:19,030 --> 00:06:22,480
awhile they have a number of other

00:06:21,040 --> 00:06:23,020
projects like kubernetes so they're

00:06:22,480 --> 00:06:25,990
doing pretty well

00:06:23,020 --> 00:06:27,580
I was listening in this podcast last

00:06:25,990 --> 00:06:28,510
week and was interviewed with Yura

00:06:27,580 --> 00:06:30,280
Shakur Oh

00:06:28,510 --> 00:06:36,030
one of the main authors behind the Jager

00:06:30,280 --> 00:06:38,860
and about 12 minutes in the podcast

00:06:36,030 --> 00:06:42,300
interviewer made a statement

00:06:38,860 --> 00:06:44,650
everybody wants distributed tracing I

00:06:42,300 --> 00:06:47,349
stop right there for a moment and I

00:06:44,650 --> 00:06:48,849
started to wonder how many of you have

00:06:47,349 --> 00:06:52,210
heard of distributed tracing before this

00:06:48,849 --> 00:06:55,270
conference whew that's pretty good

00:06:52,210 --> 00:06:57,759
but maybe like maybe half not everyone

00:06:55,270 --> 00:06:59,919
and what I've found in my travels

00:06:57,759 --> 00:07:02,919
particularly in front-end development is

00:06:59,919 --> 00:07:04,150
a lot of people haven't heard of it and

00:07:02,919 --> 00:07:06,250
if you don't work in enterprise software

00:07:04,150 --> 00:07:08,500
or an organization that maybe already

00:07:06,250 --> 00:07:11,620
has this on the back end you might not

00:07:08,500 --> 00:07:14,259
have had exposure or the need to look at

00:07:11,620 --> 00:07:16,180
this and the other interesting thing

00:07:14,259 --> 00:07:17,710
about this podcast is this was about 12

00:07:16,180 --> 00:07:19,449
minutes in they talked about micro

00:07:17,710 --> 00:07:20,919
servers for the first 12 minutes and

00:07:19,449 --> 00:07:22,569
that's actually where I think a lot of

00:07:20,919 --> 00:07:25,060
the content around distributed tracing

00:07:22,569 --> 00:07:27,250
is focused is on the back end and how we

00:07:25,060 --> 00:07:29,110
handle the requests to our micro

00:07:27,250 --> 00:07:31,930
services I want to look at that in a

00:07:29,110 --> 00:07:35,409
different way today when I look at these

00:07:31,930 --> 00:07:37,629
front end spans the the blue that you

00:07:35,409 --> 00:07:39,250
see here at the top where it doesn't has

00:07:37,629 --> 00:07:41,469
a front end before it these are

00:07:39,250 --> 00:07:43,419
basically identifying when the request

00:07:41,469 --> 00:07:45,880
came in from the front end there's no

00:07:43,419 --> 00:07:48,550
other information about what happened in

00:07:45,880 --> 00:07:50,110
the browser to kick off that request I

00:07:48,550 --> 00:07:52,990
want to go a little deeper there if we

00:07:50,110 --> 00:07:56,440
can so how do we apply this to the front

00:07:52,990 --> 00:07:58,719
end the first thing to think about is

00:07:56,440 --> 00:08:01,090
well what makes up a trace when do we

00:07:58,719 --> 00:08:03,880
have a trace what do we consider a user

00:08:01,090 --> 00:08:07,029
request so I think about two things

00:08:03,880 --> 00:08:09,279
really when we're loading a page or

00:08:07,029 --> 00:08:11,529
doing a route change we're loading a

00:08:09,279 --> 00:08:13,750
whole view essentially or when there's

00:08:11,529 --> 00:08:15,969
any UI interaction of any kind maybe

00:08:13,750 --> 00:08:18,460
they're doing an inline edit or they're

00:08:15,969 --> 00:08:20,319
doing a button click basically any time

00:08:18,460 --> 00:08:22,000
the user interacts with the application

00:08:20,319 --> 00:08:24,400
whether they're pulling it down for the

00:08:22,000 --> 00:08:27,520
first time or navigating to another page

00:08:24,400 --> 00:08:29,080
or clicking on a button that is when we

00:08:27,520 --> 00:08:33,130
want to start thinking about what's

00:08:29,080 --> 00:08:34,779
happening and that's a user action the

00:08:33,130 --> 00:08:36,550
other way the other side to think about

00:08:34,779 --> 00:08:39,399
is the feedback that we're giving to the

00:08:36,550 --> 00:08:41,589
user when does the page render when has

00:08:39,399 --> 00:08:43,630
your eye state updated when does the

00:08:41,589 --> 00:08:46,660
user consider it to have finished when

00:08:43,630 --> 00:08:48,699
they did something this comprises the

00:08:46,660 --> 00:08:50,589
user experience from page load to the

00:08:48,699 --> 00:08:51,520
page rendering from the button being

00:08:50,589 --> 00:08:54,100
clicked

00:08:51,520 --> 00:08:55,480
to the view updating this is what I want

00:08:54,100 --> 00:08:59,470
to measure and what I want to capture

00:08:55,480 --> 00:09:03,490
with my distributed traces so I go back

00:08:59,470 --> 00:09:06,130
to this I want to take those blue

00:09:03,490 --> 00:09:09,280
front-end bars and enrich them with more

00:09:06,130 --> 00:09:12,940
child spans more things that comprise

00:09:09,280 --> 00:09:14,830
those components so I can know what did

00:09:12,940 --> 00:09:16,660
they click what happened in the browser

00:09:14,830 --> 00:09:18,910
before the request happened when did it

00:09:16,660 --> 00:09:22,750
request it in the browser and not just

00:09:18,910 --> 00:09:25,360
when did we get on the back end so how

00:09:22,750 --> 00:09:28,180
do we instrument our code we're going to

00:09:25,360 --> 00:09:29,740
start with how we time stuff now when I

00:09:28,180 --> 00:09:31,300
walk through some code examples here I

00:09:29,740 --> 00:09:34,870
don't want you to get too hung up on the

00:09:31,300 --> 00:09:36,850
nuances of the Samiha of the code or any

00:09:34,870 --> 00:09:39,700
specific semantics it's intentionally

00:09:36,850 --> 00:09:41,800
abstracted just to have the main idea of

00:09:39,700 --> 00:09:43,420
what is a trace was a span how do we

00:09:41,800 --> 00:09:46,870
time things and how we might bring that

00:09:43,420 --> 00:09:48,580
into our application so our first

00:09:46,870 --> 00:09:50,740
example is how do we start a trace we

00:09:48,580 --> 00:09:52,840
need some API that lets us well start a

00:09:50,740 --> 00:09:55,240
trace and give it a description did we

00:09:52,840 --> 00:09:58,720
load a page or do we navigate to a new

00:09:55,240 --> 00:10:00,040
URL it might look something like this

00:09:58,720 --> 00:10:01,450
might give a description that we have a

00:10:00,040 --> 00:10:03,490
route change and then we give it the

00:10:01,450 --> 00:10:08,560
slug where's that window location that

00:10:03,490 --> 00:10:11,200
we're navigating to and to record a span

00:10:08,560 --> 00:10:14,260
within that trace more specific work

00:10:11,200 --> 00:10:16,540
that's happening in the system for any

00:10:14,260 --> 00:10:20,020
of work that we do we want to time it

00:10:16,540 --> 00:10:22,420
again and here we're starting a span

00:10:20,020 --> 00:10:25,390
instead of starting a trace and then we

00:10:22,420 --> 00:10:29,260
want to do the work we want to see

00:10:25,390 --> 00:10:31,660
whatever it is that we need to do could

00:10:29,260 --> 00:10:35,680
be anything right now and then when that

00:10:31,660 --> 00:10:37,210
work is done we want to stop the span a

00:10:35,680 --> 00:10:39,250
quick example of that is maybe we're

00:10:37,210 --> 00:10:41,380
making a network request maybe we're

00:10:39,250 --> 00:10:43,840
making a request to a web service and we

00:10:41,380 --> 00:10:48,090
need to start a span and record that

00:10:43,840 --> 00:10:50,290
it's request and take a specific request

00:10:48,090 --> 00:10:55,390
what's behind the API I've start tracing

00:10:50,290 --> 00:10:56,650
start span not too much basic idea is

00:10:55,390 --> 00:10:59,260
you want to keep track of the trace

00:10:56,650 --> 00:11:00,970
that's active so I have a let for the

00:10:59,260 --> 00:11:03,400
current trace and then my start trace

00:11:00,970 --> 00:11:04,760
function sets that current trace to be a

00:11:03,400 --> 00:11:07,100
new object

00:11:04,760 --> 00:11:09,620
and then it has a start time and a

00:11:07,100 --> 00:11:11,089
unique ID with those two things those

00:11:09,620 --> 00:11:12,949
are the main components of the trace we

00:11:11,089 --> 00:11:14,630
need to know when it started and what is

00:11:12,949 --> 00:11:16,639
that what is its identifier because

00:11:14,630 --> 00:11:18,680
we're going to need that later and start

00:11:16,639 --> 00:11:21,110
fist ban is very similar we just need to

00:11:18,680 --> 00:11:24,380
start the time for a given span and

00:11:21,110 --> 00:11:26,180
maintain a reference to it for stopping

00:11:24,380 --> 00:11:28,790
the trace we just record the stop time

00:11:26,180 --> 00:11:32,839
we're just doing a new date get the time

00:11:28,790 --> 00:11:34,550
and putting that on the trace and then

00:11:32,839 --> 00:11:35,510
when we're done with that trace when

00:11:34,550 --> 00:11:39,199
we've stopped it

00:11:35,510 --> 00:11:42,260
we need to persist it in some way this

00:11:39,199 --> 00:11:44,810
could be an HTTP request but do have a

00:11:42,260 --> 00:11:46,760
warning there initially when you getting

00:11:44,810 --> 00:11:48,800
started with this making an HTTP request

00:11:46,760 --> 00:11:50,779
is great just to see what's happening

00:11:48,800 --> 00:11:52,430
seeing that on the wire making sure you

00:11:50,779 --> 00:11:54,350
can thread that through to the eager

00:11:52,430 --> 00:11:56,930
back end and that it pulls up in their

00:11:54,350 --> 00:11:58,370
UI but eventually you're going to want

00:11:56,930 --> 00:12:00,649
to have strategies to not create

00:11:58,370 --> 00:12:03,199
additional user web requests every time

00:12:00,649 --> 00:12:04,699
the user does something so batching is a

00:12:03,199 --> 00:12:06,709
really good strategy to roll those up

00:12:04,699 --> 00:12:11,720
somehow and then send them all at once

00:12:06,709 --> 00:12:13,850
so what does this look like in a real

00:12:11,720 --> 00:12:17,569
application maybe we're using react or

00:12:13,850 --> 00:12:20,269
view or angular this gets a little bit

00:12:17,569 --> 00:12:22,579
tricky it will vary per application I've

00:12:20,269 --> 00:12:23,120
done a lot with react and even with

00:12:22,579 --> 00:12:25,399
react

00:12:23,120 --> 00:12:27,589
there's react with redux there's react

00:12:25,399 --> 00:12:29,899
with state manage by react context I

00:12:27,589 --> 00:12:32,269
might even be using Apollo client with

00:12:29,899 --> 00:12:34,010
graph QL and what this looks like in

00:12:32,269 --> 00:12:35,540
each specific implementation looks a

00:12:34,010 --> 00:12:37,010
little bit different so we need to roll

00:12:35,540 --> 00:12:39,980
up our sleeves a little bit to see how

00:12:37,010 --> 00:12:41,889
we apply those api's I suggested into a

00:12:39,980 --> 00:12:44,360
given application

00:12:41,889 --> 00:12:47,720
but there's one common strategy that I

00:12:44,360 --> 00:12:49,610
advocate for we could approach all of

00:12:47,720 --> 00:12:52,370
our UI components and all of our

00:12:49,610 --> 00:12:55,430
requests code and instrument each one

00:12:52,370 --> 00:12:58,010
specifically but then it's easy to miss

00:12:55,430 --> 00:13:00,949
things so I like to opt into middleware

00:12:58,010 --> 00:13:02,810
or plugins wherever possible so that way

00:13:00,949 --> 00:13:04,790
when I develop a new feature it just

00:13:02,810 --> 00:13:07,060
gets picked up by the system and

00:13:04,790 --> 00:13:09,440
middleware handles and timings for me

00:13:07,060 --> 00:13:12,110
I'll show you a light example and Redux

00:13:09,440 --> 00:13:14,720
for this the bit I want to focus on here

00:13:12,110 --> 00:13:16,250
is in in redox or really a lot of

00:13:14,720 --> 00:13:17,170
middlewares there's this concept of a

00:13:16,250 --> 00:13:19,329
next function

00:13:17,170 --> 00:13:21,850
and the idea is that you can do things

00:13:19,329 --> 00:13:23,230
in your middleware when you're

00:13:21,850 --> 00:13:25,380
processing requests when the event has

00:13:23,230 --> 00:13:28,540
happened you can do it before actually

00:13:25,380 --> 00:13:31,269
acting on that action and you do things

00:13:28,540 --> 00:13:33,730
afterwards so in the case of tracing we

00:13:31,269 --> 00:13:35,560
want to start a span before say hey we

00:13:33,730 --> 00:13:37,930
got a Redux action here's its type and

00:13:35,560 --> 00:13:39,459
then we call next and when we call next

00:13:37,930 --> 00:13:40,839
it's going to process it it's going to

00:13:39,459 --> 00:13:42,850
actually pass it through the system

00:13:40,839 --> 00:13:46,089
although middlewares can act and

00:13:42,850 --> 00:13:47,709
eventually redux state can update it's

00:13:46,089 --> 00:13:50,560
the same for other state management

00:13:47,709 --> 00:13:52,839
systems and then after that we can stop

00:13:50,560 --> 00:13:58,810
the span and record when we finish that

00:13:52,839 --> 00:14:00,610
we also need to make this full stack I

00:13:58,810 --> 00:14:02,649
talked about not just having the

00:14:00,610 --> 00:14:05,529
back-end spans but connecting it to the

00:14:02,649 --> 00:14:06,699
front-end to do that we need to share

00:14:05,529 --> 00:14:10,449
the trace that we create on the front

00:14:06,699 --> 00:14:12,850
end with the back end I'm gonna use a

00:14:10,449 --> 00:14:16,149
plug-in example here I'm using super

00:14:12,850 --> 00:14:17,980
agent super agent has an API similar to

00:14:16,149 --> 00:14:19,839
I think Redux middleware and Express and

00:14:17,980 --> 00:14:21,640
Khoa have something similar when you

00:14:19,839 --> 00:14:23,410
plug in a middleware you say hey use

00:14:21,640 --> 00:14:25,839
this middleware well with super agent

00:14:23,410 --> 00:14:29,769
use a plug-in you can define hey here's

00:14:25,839 --> 00:14:31,269
what my get request is and I can say use

00:14:29,769 --> 00:14:34,510
for a number of plugins and I will say

00:14:31,269 --> 00:14:37,390
use my tracing plug-in and then here's

00:14:34,510 --> 00:14:40,000
the response body pass that back now

00:14:37,390 --> 00:14:41,860
tracing plugins similar to the Redux

00:14:40,000 --> 00:14:44,199
example the middle of our example a

00:14:41,860 --> 00:14:46,870
little bit simpler though we take in the

00:14:44,199 --> 00:14:49,779
request for it and we can set things on

00:14:46,870 --> 00:14:51,990
the request like headers so we can go

00:14:49,779 --> 00:14:55,209
and get the trace that we manage and

00:14:51,990 --> 00:14:57,910
then get the trace ID and put that on as

00:14:55,209 --> 00:14:59,380
a request header for the request so we

00:14:57,910 --> 00:15:00,850
send that to the backend our back-end

00:14:59,380 --> 00:15:03,940
code can say hey is there already or a

00:15:00,850 --> 00:15:05,829
trace ID existing and if it is will

00:15:03,940 --> 00:15:11,740
create spans and associate it as

00:15:05,829 --> 00:15:13,510
children of that does this work what

00:15:11,740 --> 00:15:16,649
does this look like in a full stack

00:15:13,510 --> 00:15:19,060
application in a real world example I

00:15:16,649 --> 00:15:20,170
have another confession I've been

00:15:19,060 --> 00:15:22,750
working really hard to come up with a

00:15:20,170 --> 00:15:26,370
deal for this but I wasn't able to do

00:15:22,750 --> 00:15:29,019
that in time it's not trivial

00:15:26,370 --> 00:15:30,290
but the value is incredibly high I'm

00:15:29,019 --> 00:15:34,339
pretty close I'm very

00:15:30,290 --> 00:15:36,110
to share this with you soon in fact the

00:15:34,339 --> 00:15:39,380
current state of tracing in the front

00:15:36,110 --> 00:15:42,019
end doing at full stack is well this

00:15:39,380 --> 00:15:43,850
Help Wanted there's a repository called

00:15:42,019 --> 00:15:46,310
year client JavaScript that's under the

00:15:43,850 --> 00:15:49,880
Jaeger tracing project and there's no

00:15:46,310 --> 00:15:51,649
code there's one issue extract the base

00:15:49,880 --> 00:15:54,529
JavaScript client from Jaeger client

00:15:51,649 --> 00:15:57,620
node so your client node is an existing

00:15:54,529 --> 00:16:00,230
NPM module that you can pull in a node

00:15:57,620 --> 00:16:01,819
back-end and get a bunch of utilities

00:16:00,230 --> 00:16:04,790
for starting traces and starting spans

00:16:01,819 --> 00:16:07,819
but it's right now coupled to node and

00:16:04,790 --> 00:16:09,259
so there's some help wanted to take out

00:16:07,819 --> 00:16:12,709
the node bits and make something that's

00:16:09,259 --> 00:16:14,329
browser friendly the current state of

00:16:12,709 --> 00:16:16,190
that is that nobody is working on this

00:16:14,329 --> 00:16:17,930
at the moment right now but there's

00:16:16,190 --> 00:16:20,389
multiple people before this and after

00:16:17,930 --> 00:16:23,240
this comment saying hey we need this we

00:16:20,389 --> 00:16:25,790
want this so I think is I think this is

00:16:23,240 --> 00:16:28,250
gonna come up more and more of very

00:16:25,790 --> 00:16:29,779
common cases that you already have this

00:16:28,250 --> 00:16:31,670
in your back end or that your back end

00:16:29,779 --> 00:16:34,459
developers will bring this into the

00:16:31,670 --> 00:16:35,870
application first and you see that

00:16:34,459 --> 00:16:37,459
opportunity there already solved on the

00:16:35,870 --> 00:16:39,199
infrastructure problem and it's

00:16:37,459 --> 00:16:41,990
something to look at bringing into the

00:16:39,199 --> 00:16:44,290
front-end there's there's more benefit

00:16:41,990 --> 00:16:47,269
that I think is behind this than just

00:16:44,290 --> 00:16:50,420
finishing what the back-end developers

00:16:47,269 --> 00:16:54,769
might be starting trust me it is

00:16:50,420 --> 00:16:56,899
possible so five years ago I was at a

00:16:54,769 --> 00:17:00,380
company that had this they had full

00:16:56,899 --> 00:17:02,569
stack traces with a pre react legacy

00:17:00,380 --> 00:17:04,189
front-end framework and when we migrated

00:17:02,569 --> 00:17:06,020
from that framework to react we were

00:17:04,189 --> 00:17:09,470
able to look at racism and the old

00:17:06,020 --> 00:17:12,049
framework and then react as well and and

00:17:09,470 --> 00:17:13,819
see the differences and see what was

00:17:12,049 --> 00:17:16,449
improving and even what was taking a

00:17:13,819 --> 00:17:19,339
step back so we were able to when we

00:17:16,449 --> 00:17:20,720
migrated into flux and eventually redox

00:17:19,339 --> 00:17:23,089
were able to look at where our

00:17:20,720 --> 00:17:26,870
bottlenecks in the front-end and address

00:17:23,089 --> 00:17:28,760
those things it is definitely possible I

00:17:26,870 --> 00:17:30,620
know a number of companies have handled

00:17:28,760 --> 00:17:32,150
their own but right now we're starting

00:17:30,620 --> 00:17:34,940
to see this come out and open source

00:17:32,150 --> 00:17:37,960
with Yaeger tracing and now we're gonna

00:17:34,940 --> 00:17:40,640
see it soon in the front end I believe

00:17:37,960 --> 00:17:43,210
there's another project out there called

00:17:40,640 --> 00:17:46,210
real-world i/o and this is

00:17:43,210 --> 00:17:47,770
basically it's like a new to MVC it's

00:17:46,210 --> 00:17:50,710
been a couple years but they basically

00:17:47,770 --> 00:17:52,419
have implemented react examples and

00:17:50,710 --> 00:17:53,830
angular examples and view examples they

00:17:52,419 --> 00:17:54,820
basically take in any of the frameworks

00:17:53,830 --> 00:17:57,570
that are out there and tried to

00:17:54,820 --> 00:18:00,059
implement a medium blog clone and

00:17:57,570 --> 00:18:03,340
they've not only done the front-end

00:18:00,059 --> 00:18:06,100
clones front-end implementation examples

00:18:03,340 --> 00:18:10,240
but they've done back in examples so I'm

00:18:06,100 --> 00:18:12,070
actually working on a real-world IO fork

00:18:10,240 --> 00:18:17,970
right now and trying to create examples

00:18:12,070 --> 00:18:20,860
of this with a full stack so stay tuned

00:18:17,970 --> 00:18:22,419
so I think again about our users and how

00:18:20,860 --> 00:18:25,899
we can observe what's really happening

00:18:22,419 --> 00:18:28,750
in the wild I can tell you it's amazing

00:18:25,899 --> 00:18:30,909
being able to see an actual trace that

00:18:28,750 --> 00:18:32,890
shows like this didn't perform the way I

00:18:30,909 --> 00:18:36,450
expected and being able to see things

00:18:32,890 --> 00:18:39,460
that happen that I didn't expect as well

00:18:36,450 --> 00:18:41,289
because when we look at our traces is

00:18:39,460 --> 00:18:44,559
it's actually not just about performance

00:18:41,289 --> 00:18:47,140
when I look at this I can see everything

00:18:44,559 --> 00:18:49,179
happening in the system and if I include

00:18:47,140 --> 00:18:51,279
the front-end activities as well then

00:18:49,179 --> 00:18:53,529
everything in a potentially complex

00:18:51,279 --> 00:18:56,350
distributed system is apparent in one

00:18:53,529 --> 00:18:58,809
view not just what is happening how long

00:18:56,350 --> 00:19:01,330
what's blocking what and what can I

00:18:58,809 --> 00:19:03,309
improve about this and being able to see

00:19:01,330 --> 00:19:07,960
this happen in the wild actually user

00:19:03,309 --> 00:19:10,179
requests that is amazing and with that

00:19:07,960 --> 00:19:11,770
we can better understand our apps this

00:19:10,179 --> 00:19:13,750
can be an incredible tool not just for

00:19:11,770 --> 00:19:16,360
debugging performance but for onboarding

00:19:13,750 --> 00:19:17,710
new developers for seeing how different

00:19:16,360 --> 00:19:21,789
parts of the system that we haven't

00:19:17,710 --> 00:19:23,620
worked with yet work so checkout yogurt

00:19:21,789 --> 00:19:25,570
racing IO there's a really good place to

00:19:23,620 --> 00:19:27,640
start there they have an all-in-one

00:19:25,570 --> 00:19:30,460
docker image that you can pull down and

00:19:27,640 --> 00:19:34,059
when you run it it runs all the things

00:19:30,460 --> 00:19:36,760
you need to to to aggragate and receive

00:19:34,059 --> 00:19:40,809
requests for tracing and then see view

00:19:36,760 --> 00:19:42,520
them in their UI and I'll share some

00:19:40,809 --> 00:19:44,260
updates on Twitter follow me at Wills

00:19:42,520 --> 00:19:46,539
lab we're kin hunting that real-world

00:19:44,260 --> 00:19:48,370
example to share with you all and I'll

00:19:46,539 --> 00:19:49,870
be around for any questions thank you

00:19:48,370 --> 00:19:51,159
all for listening it's been a blast to

00:19:49,870 --> 00:19:52,480
to share this with you and I hope to

00:19:51,159 --> 00:19:53,540
discuss this more with you in the future

00:19:52,480 --> 00:19:56,800
thanks

00:19:53,540 --> 00:20:10,180
[Applause]

00:19:56,800 --> 00:20:10,180

YouTube URL: https://www.youtube.com/watch?v=n4oIrB4_pCA


