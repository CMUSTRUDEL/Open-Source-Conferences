Title: Strike a Pose - Gesture recognition in JavaScript w  ML & Arduino - Charlie Gerard - JSConf US 2019
Publication date: 2019-09-16
Playlist: JSConf US 2019
Description: 
	Most of our interactions with technology aren’t really intuitive. We’ve had to adapt to it by learning to type, swipe, execute specific voice commands, etc… but what if we could train technology to adapt to us?

Programming for hardware in JavaScript has already been made accessible with frameworks like Johnny-five, but, combining it with machine learning, we have the opportunity to create new and smarter interactions.

In this presentation, I will talk about how to build a simple gesture recognition system using JavaScript, Arduino and Machine learning.
Captions: 
	00:00:00,140 --> 00:00:01,140
Strike a pose  gesture recognition in JavaScript with Machine Learning & Arduino

00:00:01,140 --> 00:00:02,140
Charlie Gerard PARISS: I have been enjoying all of these

00:00:02,140 --> 00:00:03,140
presentations from backstage and I'm like reading everything backwards.

00:00:03,140 --> 00:00:04,140
But it's cool.

00:00:04,140 --> 00:00:05,140
All right.

00:00:05,140 --> 00:00:06,140
So, next we have strike a pose  gesture recognition in JavaScript with Charlie Gerard.

00:00:06,140 --> 00:00:07,140
So, can we give some encouragement and give some clapping and  whoo!

00:00:07,140 --> 00:00:08,140
Charlie!

00:00:08,140 --> 00:00:09,140
[ Applause ] CHARLIE: Thank you.

00:00:09,140 --> 00:00:10,140
Thanks so much for the introduction.

00:00:10,140 --> 00:00:11,140
And thanks, everybody, for the warm welcome.

00:00:11,140 --> 00:00:14,110
We'll see if you feel the same way at the end of the talk.

00:00:14,110 --> 00:00:15,110
But that was nice.

00:00:15,110 --> 00:00:16,619
So, yes, my name is Charlie.

00:00:16,619 --> 00:00:18,320
I'm a developer at Atlassian.

00:00:18,320 --> 00:00:20,599
I live in Sydney in Australia.

00:00:20,599 --> 00:00:25,340
You might not know Atlassian, but maybe the product, Jira.

00:00:25,340 --> 00:00:29,079
But what I'm going to talk about today has nothing to do with Jira.

00:00:29,079 --> 00:00:34,890
And outside of my job as well, I'm a Google developer expert in web technologies and a

00:00:34,890 --> 00:00:36,050
Mozilla TechSpeaker.

00:00:36,050 --> 00:00:40,719
There's been a few other speakers part of these groups in the past few days.

00:00:40,719 --> 00:00:43,800
If you have questions, feel free to ask us.

00:00:43,800 --> 00:00:48,329
But the title of this talk was strike a pose.

00:00:48,329 --> 00:00:50,559
And I don't know if there's any Madonna fans.

00:00:50,559 --> 00:00:51,559
I forgot.

00:00:51,559 --> 00:00:52,810
I should say that first.

00:00:52,810 --> 00:00:57,379
So, I really like human computer interaction.

00:00:57,379 --> 00:00:58,859
With Jira, nothing to do with that.

00:00:58,859 --> 00:01:05,920
But at home, I like to explore ways to interact with technology and interface with devices

00:01:05,920 --> 00:01:08,000
in ha different way.

00:01:08,000 --> 00:01:11,680
Maybe not with your computer or your phone, or maybe using the phone a different way.

00:01:11,680 --> 00:01:16,979
So, this is why I called this talk strike a pose because it's from the song Vogue.

00:01:16,979 --> 00:01:21,490
And I don't know if you know it, but vogueing is a type of dance where you don't follow

00:01:21,490 --> 00:01:22,680
certain steps.

00:01:22,680 --> 00:01:28,880
You just express yourself in different gestures and it's who you are and mow with dance.

00:01:28,880 --> 00:01:30,290
But we're not going to dance today.

00:01:30,290 --> 00:01:31,619
Not what we're gonna do.

00:01:31,619 --> 00:01:36,219
But we are going use our gestures to play a game of Street Fighter.

00:01:36,219 --> 00:01:40,090
At the end, that's the goal.

00:01:40,090 --> 00:01:41,090
Yes.

00:01:41,090 --> 00:01:43,060
So, to do this, there's a few different ways.

00:01:43,060 --> 00:01:46,780
But the way we're going to talk about today, you need this to get started.

00:01:46,780 --> 00:01:48,979
So, we're going to use Arduino.

00:01:48,979 --> 00:01:52,539
I'm really glad some of you did workshops yesterday to use hardware.

00:01:52,539 --> 00:01:55,340
You already know a little bit what I'm going to talk about.

00:01:55,340 --> 00:01:56,909
This is probably not the one you use.

00:01:56,909 --> 00:02:01,609
This is a maker 1000 that connects via Wi Fi.

00:02:01,609 --> 00:02:06,009
On top that have, we're going to be holding that piece of hardware and using machine learning

00:02:06,009 --> 00:02:10,399
to find patterns in the data that we're tracking in our movements and we're going to do absolutely

00:02:10,399 --> 00:02:11,900
everything in JavaScript.

00:02:11,900 --> 00:02:13,540
So, for Arduino, yay!

00:02:13,540 --> 00:02:15,260
For Arduino, Johnny Five.

00:02:15,260 --> 00:02:18,500
And for TensorFlow, we're going to use TensorFlow JS.

00:02:18,500 --> 00:02:23,720
So, step one, gathering data.

00:02:23,720 --> 00:02:24,980
At first we have nothing.

00:02:24,980 --> 00:02:25,980
We have an idea.

00:02:25,980 --> 00:02:29,540
We want to be able to play Street Fighter with our body movements.

00:02:29,540 --> 00:02:34,890
What I mean by that is when I want to punch I'm going to actual punch.

00:02:34,890 --> 00:02:35,890
There's three movements.

00:02:35,890 --> 00:02:41,520
I have punch, and  let's just call them like that.

00:02:41,520 --> 00:02:43,460
So, gathering data.

00:02:43,460 --> 00:02:46,370
We're going to do that with the Arduino.

00:02:46,370 --> 00:02:51,852
So, I used a Wi Fi board because if you use a basic board like the UNO, it has to be timed

00:02:51,852 --> 00:02:54,630
to the computer and I want to be able to move around.

00:02:54,630 --> 00:02:55,630
Play from anywhere.

00:02:55,630 --> 00:02:58,090
If I wanted to, I could play from the back of the room as well.

00:02:58,090 --> 00:03:03,959
But the Arduino is going to render the program, but there's no built in sensor to track motion.

00:03:03,959 --> 00:03:11,090
We are going to add an NPU1650, an accelerometer and gyro scope.

00:03:11,090 --> 00:03:15,490
This is good to track movements.

00:03:15,490 --> 00:03:19,150
I'm going to become an NPU1650 right now.

00:03:19,150 --> 00:03:20,799
How does an accelerometer work?

00:03:20,799 --> 00:03:25,379
If you can track motions in three different axis, X, Y and Z.

00:03:25,379 --> 00:03:33,510
And accelerometer, left to right, that would be the X axis and then the Y axis and then

00:03:33,510 --> 00:03:34,510
the Z axis.

00:03:34,510 --> 00:03:38,549
But if you use the accelerometer just by itself, you're not walking like this through life.

00:03:38,549 --> 00:03:42,140
We use the gyro scope to get the changes of rotation.

00:03:42,140 --> 00:03:47,900
We have to track three more axis, but with rotation.

00:03:47,900 --> 00:03:50,990
X axis, rotation, and Y and Z.

00:03:50,990 --> 00:03:56,909
And in the end, we're going to have six points of data to track over time as we are moving.

00:03:56,909 --> 00:04:01,720
But there is one last thing that I did as well, which is, oh, sorry, a button.

00:04:01,720 --> 00:04:07,060
And I did a button because I want to track the data only when I am doing a gesture.

00:04:07,060 --> 00:04:11,920
You don't have to do that, but as a first prototype, it was easier to only get the data

00:04:11,920 --> 00:04:17,580
from my gesture to train the algorithm to only  to only find patterns in the data when

00:04:17,580 --> 00:04:18,890
I'm holding the button.

00:04:18,890 --> 00:04:21,320
When I'm gonna hold the button, do the gesture.

00:04:21,320 --> 00:04:26,470
And when I release it, take into consideration that data coming from the sensor.

00:04:26,470 --> 00:04:29,160
So, this is for the hardware.

00:04:29,160 --> 00:04:33,970
But in terms of code we start by always requiring a few normal.

00:04:33,970 --> 00:04:39,680
Johnny Five, the system, and the client to set up our board.

00:04:39,680 --> 00:04:43,410
As it is a Wi Fi board, you have to connect to the IP address of the Arduino and a certain

00:04:43,410 --> 00:04:46,720
board to communicate with your computer.

00:04:46,720 --> 00:04:52,600
And then once the board is ready, once that is set up, we set the pin that you want, in

00:04:52,600 --> 00:04:57,980
this case, A0, and then we create a file, like a stream, to be able to write data to

00:04:57,980 --> 00:04:58,980
that file.

00:04:58,980 --> 00:05:03,800
In this code sample, I had coded a name of the file, example punch zero.

00:05:03,800 --> 00:05:07,470
Because you have to record data a lot of times.

00:05:07,470 --> 00:05:10,720
So, punch zero, punch one, punch two.

00:05:10,720 --> 00:05:12,840
And this is how I spend my personal time.

00:05:12,840 --> 00:05:14,740
I do that at home.

00:05:14,740 --> 00:05:20,770
After you open the stream to write to a file, you have to instantiate with a sensor the

00:05:20,770 --> 00:05:24,390
NPU1650, give it the pins to which it's connected.

00:05:24,390 --> 00:05:29,430
And as soon as you have change of data from the, as soon as you're moving, you can track

00:05:29,430 --> 00:05:32,440
the file.

00:05:32,440 --> 00:05:39,780
And when you're holding the button down and writing that data to the file.

00:05:39,780 --> 00:05:44,960
Once we release the button, we end that stream, meaning that the rest of the data coming from

00:05:44,960 --> 00:05:48,300
the sensor, we're not adding it to any files.

00:05:48,300 --> 00:05:52,290
In the end, we expect stuff that look like this.

00:05:52,290 --> 00:05:55,190
And I say expect because this is not exactly what I got.

00:05:55,190 --> 00:05:56,600
But this is what I wanted.

00:05:56,600 --> 00:05:59,310
So, this is real data, but not come from the Arduino.

00:05:59,310 --> 00:06:02,160
And I will talk about that a little bit later.

00:06:02,160 --> 00:06:03,950
This is actually not at all what I got.

00:06:03,950 --> 00:06:08,120
But I really wanted that because I knew that it kind of work when the I built the really

00:06:08,120 --> 00:06:10,210
first prototype of this.

00:06:10,210 --> 00:06:11,640
What I got instead was something like this.

00:06:11,640 --> 00:06:16,270
So, we still have six points of data from the accelerometer in the gyroscope.

00:06:16,270 --> 00:06:19,330
But it's not personalized enough.

00:06:19,330 --> 00:06:24,740
Don't worry about reading it, but looking at it later, you see that the points of data

00:06:24,740 --> 00:06:25,850
look exactly the same.

00:06:25,850 --> 00:06:32,670
And over time, there's not that much of a change coming from the sensor.

00:06:32,670 --> 00:06:34,420
Maybe it's my sensor or code, I'm not sure.

00:06:34,420 --> 00:06:39,970
I just know in the end you can train the algorithm, you get your model.

00:06:39,970 --> 00:06:44,150
But the thing is the accuracy of this data is not good.

00:06:44,150 --> 00:06:47,600
I have to copy that later.

00:06:47,600 --> 00:06:52,780
And this is one thing if you get into machine learning, it's not only about how much data

00:06:52,780 --> 00:06:55,170
you get, it's also about how good it is.

00:06:55,170 --> 00:06:57,100
I was getting a lot of data from the Arduino.

00:06:57,100 --> 00:07:01,820
But the quality of it was not good enough for the model to be accurate.

00:07:01,820 --> 00:07:02,820
Okay.

00:07:02,820 --> 00:07:07,530
So, now we recorded our data many times in other files.

00:07:07,530 --> 00:07:11,840
But you can't really feed that to TensorFlow yet because at the moment it's just lines

00:07:11,840 --> 00:07:12,840
in files.

00:07:12,840 --> 00:07:13,910
So, it's not really useful.

00:07:13,910 --> 00:07:18,400
So, we have to do a bit of data processing to transfer the data into a way that TensorFlow

00:07:18,400 --> 00:07:19,770
can work with.

00:07:19,770 --> 00:07:24,890
So, if we imagined that I have the nice file that I wanted.

00:07:24,890 --> 00:07:27,930
And start with lines.

00:07:27,930 --> 00:07:33,000
But the first step to transform it into something that we can use it.

00:07:33,000 --> 00:07:37,140
And change it from features and label.

00:07:37,140 --> 00:07:41,740
I think this is probably one of like the main terms in machine learning.

00:07:41,740 --> 00:07:43,400
Features will be the characteristic of your gesture.

00:07:43,400 --> 00:07:46,490
So, all the data that's in the file.

00:07:46,490 --> 00:07:50,170
And the label will be  so, you can't really work with the strings.

00:07:50,170 --> 00:07:51,280
And it has to be numbers.

00:07:51,280 --> 00:07:54,710
So, we're just converting the name of the gesture to the number.

00:07:54,710 --> 00:08:00,380
If you have a gesture array with the punch and punch is index zero.

00:08:00,380 --> 00:08:02,690
You set the label to zero.

00:08:02,690 --> 00:08:05,190
But that's only for one file.

00:08:05,190 --> 00:08:07,220
So, one sample.

00:08:07,220 --> 00:08:08,840
What we want is to do that with all our files.

00:08:08,840 --> 00:08:14,020
So, we're going to end up with a massive array of objects that represent our gestures in

00:08:14,020 --> 00:08:16,080
features and label.

00:08:16,080 --> 00:08:18,700
But that's not it neither.

00:08:18,700 --> 00:08:22,910
Because that's the first step to kind of put the data in a way that we understand it a

00:08:22,910 --> 00:08:23,910
bit better.

00:08:23,910 --> 00:08:24,910
We can work with objects.

00:08:24,910 --> 00:08:26,580
But TensorFlow doesn't work with objects.

00:08:26,580 --> 00:08:30,990
TensorFlow works more with stuff that look like arrays, but it's more take tensors, but

00:08:30,990 --> 00:08:33,360
let's just talk about arrays.

00:08:33,360 --> 00:08:35,159
And at the moment, we have objects, that's not good.

00:08:35,159 --> 00:08:38,190
We need to split between features and label.

00:08:38,190 --> 00:08:40,410
So, we're going to have here.

00:08:40,410 --> 00:08:42,030
We're going to end up with something like this.

00:08:42,030 --> 00:08:47,460
I'm going to go line by line, that's like what?

00:08:47,460 --> 00:08:55,070
The labels have zero, one or two, three gestures, punch, round, and upper cut.

00:08:55,070 --> 00:09:01,930
And we will have a multidimensional array of features to map gestures to each other.

00:09:01,930 --> 00:09:06,450
So, the first level of our multidimensional array for labels is going to be mapped to

00:09:06,450 --> 00:09:11,030
our first level of features as well.

00:09:11,030 --> 00:09:14,840
And if we go a bit deeper, it means that the first punch that I record is going to be mapped

00:09:14,840 --> 00:09:19,070
to the data that I get from an in features array.

00:09:19,070 --> 00:09:22,650
And you're going in, the second one mapped to the second one in the first level of the

00:09:22,650 --> 00:09:23,650
array.

00:09:23,650 --> 00:09:26,370
And you go through that one by one.

00:09:26,370 --> 00:09:30,940
So, we're getting a bit  I don't know if you noticed, I didn't show you any code to

00:09:30,940 --> 00:09:34,140
transfer the data because it has nothing to do with TensorFlow yet.

00:09:34,140 --> 00:09:39,420
At moment, it's if you know lots of array methods and pushing objects and stuff like

00:09:39,420 --> 00:09:40,620
that.

00:09:40,620 --> 00:09:42,320
You do that with normal JavaScript functions.

00:09:42,320 --> 00:09:46,810
We're not using any TensorFlow methods.

00:09:46,810 --> 00:09:51,910
But we are getting more towards something that TensorFlow can work with because it's

00:09:51,910 --> 00:09:55,250
only multidimensional arrays and just numbers.

00:09:55,250 --> 00:09:56,430
No strings, no numbers.

00:09:56,430 --> 00:09:57,950
We're getting closer.

00:09:57,950 --> 00:10:03,580
And now the thing  now we need to move on to converting to tensors.

00:10:03,580 --> 00:10:08,290
Think of tensors as a data type that TensorFlow can work with.

00:10:08,290 --> 00:10:13,400
This is where I'm going to show a little bit more of code that is TensorFlow specific because

00:10:13,400 --> 00:10:17,460
we have to use the built in methods to be able to transform our multidimensional arrays

00:10:17,460 --> 00:10:21,860
into tensors.

00:10:21,860 --> 00:10:28,260
We don't opt to look at the labels and features.

00:10:28,260 --> 00:10:32,990
And I had an array of zeros and two, and one to map all the gestures.

00:10:32,990 --> 00:10:39,550
But with this, the algorithm is not going to really try to really look at the data and

00:10:39,550 --> 00:10:40,550
think of a gesture.

00:10:40,550 --> 00:10:43,770
It's probably going to look at, well, treat previous ones that you gave me were punches,

00:10:43,770 --> 00:10:45,800
I'm going to assume this is a punch.

00:10:45,800 --> 00:10:52,700
But if you shuffle the data, you can force the algorithm to try to understand  what

00:10:52,700 --> 00:10:55,820
makes a punch and an upper cut and things like that.

00:10:55,820 --> 00:11:03,770
So, once the data is shuffled, we start using  well, in this case it's a tensor 2D from TensorFlow

00:11:03,770 --> 00:11:08,430
where what is going on here is that we're using our shuffled features in the second

00:11:08,430 --> 00:11:12,440
parameter of the function is going to be the shape of the tensor.

00:11:12,440 --> 00:11:17,430
And that means that it's going to be expecting the data to be coming in a certain way.

00:11:17,430 --> 00:11:20,790
And our first argument is the number of samples by gesture.

00:11:20,790 --> 00:11:25,250
If a punch gesture 20 times, I'm going to use the number 20.

00:11:25,250 --> 00:11:31,350
And the total number of data per file, the second one in the array is the number of,

00:11:31,350 --> 00:11:34,420
let's say, data input in a file.

00:11:34,420 --> 00:11:40,220
So, you know how I'm tracking six different values for my gestures, X, Y, Z for accelerometer

00:11:40,220 --> 00:11:41,950
and gyroscope.

00:11:41,950 --> 00:11:49,250
You have to multiply the two numbers and that will be the shape of your tensor.

00:11:49,250 --> 00:11:54,170
Specifically the amount of data in one gesture that it's going to be looking for.

00:11:54,170 --> 00:11:55,860
And then labels, tensor.

00:11:55,860 --> 00:12:03,420
So, this is gonna be a tensor 2D because the label is an integer, zero, one or two.

00:12:03,420 --> 00:12:07,920
And we move from a tensor 2D to a tensor 1D.

00:12:07,920 --> 00:12:12,310
Really we have the data type that TensorFlow can work with.

00:12:12,310 --> 00:12:14,590
We have tensors.

00:12:14,590 --> 00:12:19,440
But what we need to do is the next step, splitting between the training and the test set.

00:12:19,440 --> 00:12:23,460
What we want food is we know our data is already labeled.

00:12:23,460 --> 00:12:27,640
We already recorded it in files and we named them with the right gesture.

00:12:27,640 --> 00:12:31,260
We're going to use 80% of our dataset to give the algorithm, to learn patterns.

00:12:31,260 --> 00:12:39,180
And we're going to keep 20% to validate the predictions are right.

00:12:39,180 --> 00:12:46,570
We have the algorithm, so, if it says it's a punch, but you know from a data file it's

00:12:46,570 --> 00:12:51,230
an upper cut, you can retrain until the accuracy gets a bit better.

00:12:51,230 --> 00:12:55,720
To do this, we're just calculating what 20% of our sample is.

00:12:55,720 --> 00:12:58,070
But then we're just slicing tensors.

00:12:58,070 --> 00:13:03,750
So, I'm not going too much into that because I think that's not the part that matters the

00:13:03,750 --> 00:13:04,750
most.

00:13:04,750 --> 00:13:07,540
But it's just like, you don't dare how it slices, you can use the slice method.

00:13:07,540 --> 00:13:12,500
But we have a training set and a test set of features and labels.

00:13:12,500 --> 00:13:17,200
So, now that we have this, we really have our data kind of ready.

00:13:17,200 --> 00:13:19,450
So, what we have to do next is we create the model.

00:13:19,450 --> 00:13:21,560
At the moment we just prepared our data.

00:13:21,560 --> 00:13:23,110
But we don't have the model yet.

00:13:23,110 --> 00:13:27,980
So, to create the model, this is where it kind of becomes  it's not really a science.

00:13:27,980 --> 00:13:29,760
It's like a try things until it works.

00:13:29,760 --> 00:13:31,290
That's what I do.

00:13:31,290 --> 00:13:35,180
Where I create a sequential model and add layers.

00:13:35,180 --> 00:13:38,170
Have two or four or six and change parameters.

00:13:38,170 --> 00:13:40,630
I'm not quite there to understand what everything does.

00:13:40,630 --> 00:13:41,630
When it works.

00:13:41,630 --> 00:13:42,740
I don't touch it anymore.

00:13:42,740 --> 00:13:46,070
Let's just pretend that it's fine.

00:13:46,070 --> 00:13:50,540
And before fitting the model, before launching the training, you have to pass a few different

00:13:50,540 --> 00:13:55,540
parameters of the optimizer that you want to pick and what you want to track and things

00:13:55,540 --> 00:13:57,470
like that.

00:13:57,470 --> 00:14:01,430
If you want to create your own, you could copy and paste, but you could also play around

00:14:01,430 --> 00:14:05,670
with different features and see what makes your accuracy better.

00:14:05,670 --> 00:14:12,450
So, once we have that, we have to fit training features and training labels inside our model

00:14:12,450 --> 00:14:14,160
and we just pass it.

00:14:14,160 --> 00:14:18,260
The number of steps for the training and the validation data is our test features that

00:14:18,260 --> 00:14:21,160
we're going to validate against.

00:14:21,160 --> 00:14:24,360
Once the training is done, we save our file.

00:14:24,360 --> 00:14:27,450
So, the actual model is going to be saved as a file in your application.

00:14:27,450 --> 00:14:29,490
So, you can just use it later.

00:14:29,490 --> 00:14:32,290
So, now we created our model.

00:14:32,290 --> 00:14:33,290
It's there.

00:14:33,290 --> 00:14:34,290
With all our data.

00:14:34,290 --> 00:14:35,290
But we want to use it, right?

00:14:35,290 --> 00:14:37,589
So, this is going to be to predict.

00:14:37,589 --> 00:14:41,420
To do this, we require TensorFlow.

00:14:41,420 --> 00:14:42,570
We probably don't need to look at it.

00:14:42,570 --> 00:14:48,160
But we require TensorFlow and then we have an array of classes or gestures.

00:14:48,160 --> 00:14:50,550
We load our model to be able to use it.

00:14:50,550 --> 00:14:55,279
And we have the same code as before recording the data, but this time using it to predict

00:14:55,279 --> 00:14:59,940
where the data changes from the Arduino in the sensor.

00:14:59,940 --> 00:15:05,560
And when the button is held, we are kind of keeping all of our data into a variable.

00:15:05,560 --> 00:15:08,279
We're pushing it into an array.

00:15:08,279 --> 00:15:12,339
Once we release the button, I want to use the new live data that the model has never

00:15:12,339 --> 00:15:17,610
seen before to match it against one of the gestures that it's been trained against.

00:15:17,610 --> 00:15:23,440
Once we release, we keep the data that we just recorded and  but at the moment we also

00:15:23,440 --> 00:15:27,100
need to transform that into a tensor because it's just an array and TensorFlow can't work

00:15:27,100 --> 00:15:28,900
with just arrays.

00:15:28,900 --> 00:15:33,029
So, we create a tensor 2D as well with our new sample data.

00:15:33,029 --> 00:15:36,730
But this time the shape is going to be different because we're giving it only one input.

00:15:36,730 --> 00:15:39,690
The first number is going to be one.

00:15:39,690 --> 00:15:40,980
And 300, that's kind of arbitrary.

00:15:40,980 --> 00:15:42,040
You can change it.

00:15:42,040 --> 00:15:45,620
It's basically because I used 50 lines in each file.

00:15:45,620 --> 00:15:48,200
6 times 50 is 300.

00:15:48,200 --> 00:15:53,600
So, the model is expecting 300 points of data to work.

00:15:53,600 --> 00:15:54,600
You can change that.

00:15:54,600 --> 00:15:55,800
It's fine.

00:15:55,800 --> 00:16:00,960
And once our live data has been transformed into a tensor, we can just call the predict

00:16:00,960 --> 00:16:05,870
method on the model and it will give us back a label, so, a number.

00:16:05,870 --> 00:16:07,260
And so, zero, one or two.

00:16:07,260 --> 00:16:13,620
And then you can look at that in your gesture classes array to get the actual label of the

00:16:13,620 --> 00:16:15,220
live prediction.

00:16:15,220 --> 00:16:20,500
This is like  what is really cool about it, is the way  every time I do a punch, there

00:16:20,500 --> 00:16:23,760
is no way I could do the exact same punch I did before.

00:16:23,760 --> 00:16:28,360
Because if we have 300 or more points of data, there's no way that the value from my accelerometer

00:16:28,360 --> 00:16:33,120
would be exactly the same even if you tried, like, I don't know, a hundred times.

00:16:33,120 --> 00:16:38,030
So, it means that you are more free to do whatever gesture as long as it looks like

00:16:38,030 --> 00:16:39,200
a punch to the algorithm.

00:16:39,200 --> 00:16:44,080
So, the way it learns the pattern from data, it would probably understand the values and

00:16:44,080 --> 00:16:48,610
the stuff from the accelerometer and understand it and match it to one of the gestures that

00:16:48,610 --> 00:16:49,610
you attract.

00:16:49,610 --> 00:16:50,610
Okay.

00:16:50,610 --> 00:16:52,620
I feel like that was heavy.

00:16:52,620 --> 00:16:53,620
Okay.

00:16:53,620 --> 00:17:00,649
So, now that I talked about how it is supposed to work, I'm gonna try to show hopefully that

00:17:00,649 --> 00:17:01,649
it works.

00:17:01,649 --> 00:17:02,649
I mean, I know it works.

00:17:02,649 --> 00:17:04,010
But I don't know if it will work here.

00:17:04,010 --> 00:17:05,650
[ Laughter ] Yes.

00:17:05,650 --> 00:17:06,650
Okay.

00:17:06,650 --> 00:17:11,500
So, you know how at the beginning of the talk I told you about the data that wasn't really

00:17:11,500 --> 00:17:14,350
good because it was  well, I don't know yet why.

00:17:14,350 --> 00:17:16,400
But it wasn't really good.

00:17:16,400 --> 00:17:18,319
So, this is the sketch.

00:17:18,319 --> 00:17:22,439
This is how I put the sensor button in the Arduino together.

00:17:22,439 --> 00:17:25,160
But the thing is I knew I wanted to do a demo.

00:17:25,160 --> 00:17:29,350
So, I actually switched senors because I didn't want to come on stage knowing it wouldn't

00:17:29,350 --> 00:17:30,970
work.

00:17:30,970 --> 00:17:32,570
Maybe it will work because I switched.

00:17:32,570 --> 00:17:39,000
It works the same way which is really cool because I was just able to not even change

00:17:39,000 --> 00:17:40,000
the code that much.

00:17:40,000 --> 00:17:42,160
Just change where the data is coming from.

00:17:42,160 --> 00:17:48,680
I used a daydream controller that you usually use with the VR headset from Google.

00:17:48,680 --> 00:17:52,060
And I use that one because it has a built in accelerometer and gyroscope.

00:17:52,060 --> 00:17:57,260
And an Arduino.

00:17:57,260 --> 00:18:01,490
And it gives me the precise data and makes it quite accurate.

00:18:01,490 --> 00:18:03,060
It was like, awesome.

00:18:03,060 --> 00:18:06,340
So, what is supposed to happen now is something like this.

00:18:06,340 --> 00:18:07,340
I have a game.

00:18:07,340 --> 00:18:11,020
I put a GIF because if it doesn't work, at least you can show it works.

00:18:11,020 --> 00:18:12,290
I'm going for the punch.

00:18:12,290 --> 00:18:15,920
Try the three gestures and it's supposed to be doing this.

00:18:15,920 --> 00:18:17,020
Okay.

00:18:17,020 --> 00:18:19,210
My god.

00:18:19,210 --> 00:18:28,010
I'm going to try to demo it a little bit, last time it did not quite work as planned.

00:18:28,010 --> 00:18:29,010
okay.

00:18:29,010 --> 00:18:31,940
If anybody has Bluetooth on right now, feel free to disconnect it.

00:18:31,940 --> 00:18:33,820
I've had issues in the past.

00:18:33,820 --> 00:18:34,820
Okay.

00:18:34,820 --> 00:18:41,280
Let me just have a sip and  okay.

00:18:41,280 --> 00:18:43,480
A predict file.

00:18:43,480 --> 00:18:44,480
There's an error.

00:18:44,480 --> 00:18:45,480
Don't worry.

00:18:45,480 --> 00:18:46,929
It still works anyways so I didn't fix it.

00:18:46,929 --> 00:18:48,570
[ Laughter ] Okay.

00:18:48,570 --> 00:18:51,840
I need  come on.

00:18:51,840 --> 00:18:55,120
Don't let me down.

00:18:55,120 --> 00:18:56,120
It's not on.

00:18:56,120 --> 00:18:57,820
Oh, I knew  don't  okay.

00:18:57,820 --> 00:19:00,190
I'm waiting for the message that tells me that this  okay.

00:19:00,190 --> 00:19:01,530
It's on, it's on, it's on.

00:19:01,530 --> 00:19:02,650
I want to be quick.

00:19:02,650 --> 00:19:03,770
I haven't done anything yet.

00:19:03,770 --> 00:19:06,220
So, I'm going to go like this.

00:19:06,220 --> 00:19:12,070
Okay, don't let me down.

00:19:12,070 --> 00:19:15,559
You fucking let me down.

00:19:15,559 --> 00:19:16,559
Okay.

00:19:16,559 --> 00:19:17,559
No!

00:19:17,559 --> 00:19:22,220
No, no, no, no... never try Bluetooth ever.

00:19:22,220 --> 00:19:23,220
Okay.

00:19:23,220 --> 00:19:24,220
It's  okay.

00:19:24,220 --> 00:19:25,220
Okay.

00:19:25,220 --> 00:19:27,130
You're on, you're on.

00:19:27,130 --> 00:19:28,130
Refresh.

00:19:28,130 --> 00:19:29,580
Oh, why not?

00:19:29,580 --> 00:19:33,270
It's not even going to refresh?

00:19:33,270 --> 00:19:34,270
I have other demos.

00:19:34,270 --> 00:19:43,420
So, I have two like  is there a  okay, okay, we're in.

00:19:43,420 --> 00:19:45,420
Come on.

00:19:45,420 --> 00:19:49,570
Give me the notification on.

00:19:49,570 --> 00:19:50,610
Okay.

00:19:50,610 --> 00:20:02,890
I'll try one more time and then I have to move on to the next.

00:20:02,890 --> 00:20:03,890
Okay.

00:20:03,890 --> 00:20:05,640
So, we'll try that.

00:20:05,640 --> 00:20:06,640
Yay!

00:20:06,640 --> 00:20:07,640
[ Applause ] Whoo!

00:20:07,640 --> 00:20:12,790
[ Applause ] I was supposed to have  I was supposed to

00:20:12,790 --> 00:20:13,890
have sound.

00:20:13,890 --> 00:20:17,720
I don't know if you need to turn it on.

00:20:17,720 --> 00:20:19,890
Or if it's my thing.

00:20:19,890 --> 00:20:21,480
[Ack sound] Try it again?

00:20:21,480 --> 00:20:22,480
That's cool.

00:20:22,480 --> 00:20:23,570
I'm done with this one.

00:20:23,570 --> 00:20:24,570
Okay.

00:20:24,570 --> 00:20:29,270
So, but the thing is, then I started thinking, okay, I have a gesture recognition system

00:20:29,270 --> 00:20:31,580
in JavaScript.

00:20:31,580 --> 00:20:32,760
What else can I do with it?

00:20:32,760 --> 00:20:35,200
So, this is where it's gonna get even more lame.

00:20:35,200 --> 00:20:39,230
It's supposed to  is there sound?

00:20:39,230 --> 00:20:46,630
[harry Potter music] What you can do as well is wand movements.

00:20:46,630 --> 00:20:51,050
So, if there is any Harry Potter fans  I know there's a few because we talked about

00:20:51,050 --> 00:20:53,760
it.

00:20:53,760 --> 00:20:59,240
If you don't know Harry Potter, you're supposed to tell the spell, expelliarmus and stuff

00:20:59,240 --> 00:21:01,010
like that.

00:21:01,010 --> 00:21:05,230
As you grow, you don't have to say the spell, no movement.

00:21:05,230 --> 00:21:07,700
And there's a third level, you can just think the spell.

00:21:07,700 --> 00:21:09,810
We're not going to do that today.

00:21:09,810 --> 00:21:13,660
I'm going the one where you move.

00:21:13,660 --> 00:21:15,760
I just trained two gestures.

00:21:15,760 --> 00:21:18,340
And it's supposed to do it on the screen.

00:21:18,340 --> 00:21:19,340
I hope it's going to work.

00:21:19,340 --> 00:21:21,610
It's going to be very embarrassing if it doesn't.

00:21:21,610 --> 00:21:22,720
I trained lumos and expelliarmus.

00:21:22,720 --> 00:21:27,630
I really like that demo.

00:21:27,630 --> 00:21:32,570
So, you've got to work.

00:21:32,570 --> 00:21:34,820
Oh, nope.

00:21:34,820 --> 00:21:37,059
Hold on.

00:21:37,059 --> 00:21:38,190
Wait.

00:21:38,190 --> 00:21:44,929
Give me the second most  okay.

00:21:44,929 --> 00:21:50,280
I just need it to work once.

00:21:50,280 --> 00:21:51,280
Just work once.

00:21:51,280 --> 00:21:52,910
Oh, why are you crashed?

00:21:52,910 --> 00:21:54,640
I don't know why this is crashing.

00:21:54,640 --> 00:21:57,000
It's happening  it's fine in my room.

00:21:57,000 --> 00:22:00,520
And never fine on stage ever.

00:22:00,520 --> 00:22:15,620
Come on, I want the Harry Potter one to work.

00:22:15,620 --> 00:22:21,660
This is really weird.

00:22:21,660 --> 00:22:23,170
Hello?

00:22:23,170 --> 00:22:27,490
Well, I haven't even done anything.

00:22:27,490 --> 00:22:28,490
Okay.

00:22:28,490 --> 00:22:32,880
Maybe third time is the right time again?

00:22:32,880 --> 00:22:34,130
Oh  no!

00:22:34,130 --> 00:22:36,130
You were listening.

00:22:36,130 --> 00:22:37,130
Dude.

00:22:37,130 --> 00:22:39,130
Come on.

00:22:39,130 --> 00:22:41,170
I really like that one.

00:22:41,170 --> 00:22:42,170
It didn't do anything.

00:22:42,170 --> 00:22:43,170
What?

00:22:43,170 --> 00:22:44,170
All right.

00:22:44,170 --> 00:22:45,170
Oh, okay.

00:22:45,170 --> 00:22:46,170
So, okay.

00:22:46,170 --> 00:22:47,170
That's the thing is like the shape of I'm gonna talk when I try to do it again.

00:22:47,170 --> 00:22:48,920
The error here is the thing, it's like the model is making the shape go a certain way.

00:22:48,920 --> 00:22:50,850
And if there's in the enough data, it will crash.

00:22:50,850 --> 00:22:52,920
I just haven't done that yet.

00:22:52,920 --> 00:22:57,670
Come on, I need to do the expelliarmus.

00:22:57,670 --> 00:23:05,450
Otherwise I'll just move on.

00:23:05,450 --> 00:23:08,790
This is like not even  that has nothing to do with Bluetooth.

00:23:08,790 --> 00:23:15,420
Come on, come on, come on, come on... no.

00:23:15,420 --> 00:23:16,420
No.

00:23:16,420 --> 00:23:17,420
Okay.

00:23:17,420 --> 00:23:20,210
Well, I'm just gonna go back to my room and cry.

00:23:20,210 --> 00:23:21,210
That's fine.

00:23:21,210 --> 00:23:22,210
I need to move on.

00:23:22,210 --> 00:23:23,210
That's cool.

00:23:23,210 --> 00:23:24,830
Another time.

00:23:24,830 --> 00:23:26,470
So, but what else?

00:23:26,470 --> 00:23:32,390
So, what I was really  as I got into kind of like that rabbit hole of trying with stuff,

00:23:32,390 --> 00:23:34,650
I was thinking, well, okay.

00:23:34,650 --> 00:23:37,299
I'm having fun, but I want more people to have fun.

00:23:37,299 --> 00:23:39,250
Like that's boring to play by yourself.

00:23:39,250 --> 00:23:43,140
So, I was like, okay, it works with an Arduino and it works with a daydream controller.

00:23:43,140 --> 00:23:47,600
But, you know, what else has a built in accelerometer and gyroscope?

00:23:47,600 --> 00:23:50,620
Your phone.

00:23:50,620 --> 00:23:57,270
It has a built in sensor to track post, you know, direction and orientation as well.

00:23:57,270 --> 00:24:01,520
And you can access that stuff in JavaScript with the generic sensor API.

00:24:01,520 --> 00:24:07,840
What we can do is replace the code that gets the data from the piece of hardware.

00:24:07,840 --> 00:24:10,120
In this case, obviously just pseudo code.

00:24:10,120 --> 00:24:18,360
But you would create the gyroscope and with the event listener reading and you can do

00:24:18,360 --> 00:24:24,980
whatever you want with web sockets or lining up hardware.

00:24:24,980 --> 00:24:28,390
When I thought you could  why say you can and not do it?

00:24:28,390 --> 00:24:29,700
I'm going to try to do it?

00:24:29,700 --> 00:24:33,100
Actually I could do the Harry Potter one with my phone.

00:24:33,100 --> 00:24:36,549
Because it will work.

00:24:36,549 --> 00:24:39,210
I'm going to do the game one with my phone.

00:24:39,210 --> 00:24:41,130
This is just running locally.

00:24:41,130 --> 00:24:47,410
I have  I'm using ngrok to be able to communicate with my phone on the same port.

00:24:47,410 --> 00:24:51,540
So, if I  I'm gonna do the game one just to show that it's working.

00:24:51,540 --> 00:24:53,260
It should be working.

00:24:53,260 --> 00:24:54,780
That would be easier because it's not Bluetooth.

00:24:54,780 --> 00:24:56,440
I have the game here.

00:24:56,440 --> 00:24:59,450
And I have the page on my phone.

00:24:59,450 --> 00:25:11,710
Connected  oh, yeah, okay, that's fine, that's fine, that's fine.

00:25:11,710 --> 00:25:15,190
oh, the Wi Fi on my phone.

00:25:15,190 --> 00:25:16,190
No!

00:25:16,190 --> 00:25:17,380
Are you for real?

00:25:17,380 --> 00:25:20,460
Oh, I'm back, I'm back, I'm back.

00:25:20,460 --> 00:25:21,460
Okay.

00:25:21,460 --> 00:25:22,460
I'm on.

00:25:22,460 --> 00:25:23,460
All right.

00:25:23,460 --> 00:25:24,460
Okay.

00:25:24,460 --> 00:25:28,580
So, what's gonna happen is I'm gonna do the thing, press on my screen.

00:25:28,580 --> 00:25:34,670
And record data, and when I release my thumb on the screen, it should do the thing.

00:25:34,670 --> 00:25:39,880
Well, that wasn't the one I tried.

00:25:39,880 --> 00:25:40,880
But that's fine.

00:25:40,880 --> 00:25:44,049
Let me try  if I do that?

00:25:44,049 --> 00:25:46,420
That wasn't the one I tried neither.

00:25:46,420 --> 00:25:53,980
But it's doing something, so, yeah.

00:25:53,980 --> 00:25:58,220
[ Applause ] It really didn't go as planned from beginning

00:25:58,220 --> 00:25:59,220
to end.

00:25:59,220 --> 00:26:04,210
I probably won't have the time to do the Harry Potter one.

00:26:04,210 --> 00:26:06,970
I can try it later with you if you want.

00:26:06,970 --> 00:26:07,970
So, yeah.

00:26:07,970 --> 00:26:12,020
Just before I finish, just a little recap, if you want to know how to build that kind

00:26:12,020 --> 00:26:13,020
of stuff.

00:26:13,020 --> 00:26:14,230
You have to start by getting the data.

00:26:14,230 --> 00:26:18,809
I use sensors, but if you have others, you can use whatever you have with data.

00:26:18,809 --> 00:26:25,620
I used an accelerometer and gyroscope, but you can use a sensor.

00:26:25,620 --> 00:26:33,910
You need to change the data to work with TensorFlow and split it between the training set and

00:26:33,910 --> 00:26:35,650
the test set.

00:26:35,650 --> 00:26:39,580
Train your algorithm, and finally you can run the predictions.

00:26:39,580 --> 00:26:44,130
Just before I finish, I'm going to say something I've said it before, but I usually say useless

00:26:44,130 --> 00:26:45,130
is not worthless.

00:26:45,130 --> 00:26:50,100
You're not going back to work and say, fuck everything, let's just do recognition.

00:26:50,100 --> 00:26:52,760
But I learned a allot.

00:26:52,760 --> 00:26:59,140
I learned a lot about Bluetooth  you shouldn't use it.

00:26:59,140 --> 00:27:03,380
But doing that, and that's something that really gets my super excited about just building

00:27:03,380 --> 00:27:07,410
stuff because I think there's so many different ways we could interact with technology in

00:27:07,410 --> 00:27:08,760
ways that we want.

00:27:08,760 --> 00:27:13,710
Because the thing is I train it with my gestures, but I could let anybody actually use the sensor,

00:27:13,710 --> 00:27:18,700
but anything that look like a punch, it's your gesture.

00:27:18,700 --> 00:27:24,360
It's going to be mapped to something it's been trained with.

00:27:24,360 --> 00:27:26,120
Sorry for the bad demos.

00:27:26,120 --> 00:27:27,120
That's all I had to do.

00:27:27,120 --> 00:27:29,450
I'm going to share the slides and the resources probably tomorrow.

00:27:29,450 --> 00:27:32,750
I need to clean up some stuff first.

00:27:32,750 --> 00:27:33,750
But thank you very much for your time.

00:27:33,750 --> 00:27:33,870

YouTube URL: https://www.youtube.com/watch?v=HvtlRMpDbnQ


