Title: Tim Slatcher: Interactive Visualisations at Scale | JSConf EU 2015
Publication date: 2015-10-13
Playlist: JSConf EU 2015
Description: 
	As data scale increases and browser capabilities grow, it’s becoming increasingly possible to build rich, interactive visualisations on the web. Join us as we explore some of our powerful browser-based analytic tools designed to visualise time-series data and network graphs. In this session we’ll talk about how to use the DOM, Canvas and some smart Javascript tricks to build interactive user experiences designed to scale with the data.

Intro music by @halfbyte
Captions: 
	00:00:24,939 --> 00:00:25,960
Thank you.

00:00:25,960 --> 00:00:30,099
A recurring theme over the last decade or so in the software industry is the

00:00:30,099 --> 00:00:31,960
growth of data.

00:00:31,960 --> 00:00:33,390
Some estimates say we've been doubling the total

00:00:33,390 --> 00:00:38,120
amount of data in as little as every 2 years, and to

00:00:38,120 --> 00:00:39,640
start with, we didn't really know what to do with all

00:00:39,640 --> 00:00:41,469
the data we've been recording.

00:00:41,469 --> 00:00:43,420
As people started to figure out the questions they wanted to ask

00:00:43,420 --> 00:00:47,079
of their data the software industry reacted to this,

00:00:47,079 --> 00:00:49,630
we develop backends and databases to scale that was able

00:00:49,630 --> 00:00:53,129
to process this data in realtime.

00:00:53,129 --> 00:00:57,559
Technology like Hadoop, Spark and Cassandra are now doing it in the scale.

00:00:57,559 --> 00:01:02,989
This enables us, as front-end developers, to build

00:01:02,989 --> 00:01:08,660
front ends to visualise and explore this data in realtime.

00:01:08,660 --> 00:01:11,970
In this talk I'm going to show you a couple of talks

00:01:11,970 --> 00:01:15,800
we have built out, and but first I want to explore

00:01:15,800 --> 00:01:18,580
what is a good user experience.

00:01:18,580 --> 00:01:20,890
In my eyes, it is two things, and there's many different ways of cutting

00:01:20,890 --> 00:01:24,450
it, but I'm going to talk about intuitive and responsive

00:01:24,450 --> 00:01:27,229
but intuitive, I'm talking about a user should

00:01:27,229 --> 00:01:29,030
quickly be able to get a good understanding of what their

00:01:29,030 --> 00:01:32,130
data is and how they should obviously ask questions

00:01:32,130 --> 00:01:33,580
of it.

00:01:33,580 --> 00:01:35,830
This is by no means an easy problem.

00:01:35,830 --> 00:01:40,160
It requires a lot of studying by designers and front end engineers,

00:01:40,160 --> 00:01:43,330
but it basically requires a good grasp of what your

00:01:43,330 --> 00:01:45,550
users are, and the kind of questions they ask.

00:01:45,550 --> 00:01:48,560
It can be dependent on the industry you're developing for as the

00:01:48,560 --> 00:01:51,810
shape of the data.

00:01:51,810 --> 00:01:54,340
And responsive, I'm not talking about responsive web

00:01:54,340 --> 00:01:57,450
design but a responsive application when a user asks

00:01:57,450 --> 00:01:59,810
a question of the application, it should be easy for

00:01:59,810 --> 00:02:01,849
that user to get the answer they're looking for.

00:02:01,849 --> 00:02:05,470
It should be very fast and responsive.

00:02:05,470 --> 00:02:08,300
In the enterprise software industry, we've seen a lot of software

00:02:08,300 --> 00:02:10,500
where these ask a straightforward question of the

00:02:10,500 --> 00:02:13,480
data and it can take minutes, hours or even days to get

00:02:13,480 --> 00:02:15,170
a response.

00:02:15,170 --> 00:02:18,700
We don't want our users to switch between asking

00:02:18,700 --> 00:02:20,530
questions and receiving an answer.

00:02:20,530 --> 00:02:22,020
Let's talk about earthquakes.

00:02:22,020 --> 00:02:27,909
Around 30 to 40 years ago, the traditional ways of measuring them was using seismological

00:02:27,909 --> 00:02:28,909
data.

00:02:28,909 --> 00:02:36,500
This pen would scribble on the page.

00:02:36,500 --> 00:02:40,250
These days, pretty much all of the data is digitised so there

00:02:40,250 --> 00:02:43,720
are websites like this one which have a tonne of data spanning

00:02:43,720 --> 00:02:47,200
about last week for thousands of sensor groups all

00:02:47,200 --> 00:02:48,200
around the world.

00:02:48,200 --> 00:02:49,780
Here we're going to look at an earthquake that

00:02:49,780 --> 00:02:54,370
happened earlier in the month off the coast of Chilli,

00:02:54,370 --> 00:02:57,580
it was kind of a big one, 8.3 on the Richter Scale.

00:02:57,580 --> 00:03:00,270
So here we can see it happened around 11 pm,

00:03:00,270 --> 00:03:02,640
maybe we want to see if there are any aftershocks, so we'll

00:03:02,640 --> 00:03:05,700
plug in the next day, click update, wait for the spinners

00:03:05,700 --> 00:03:08,640
to go away and we'll see that kind of information.

00:03:08,640 --> 00:03:12,951
That isn't exactly unintuitive, but I can't zoom in

00:03:12,951 --> 00:03:16,820
and see more of the data, I can't pan around and compare

00:03:16,820 --> 00:03:19,069
the aftershocks with the initial quake.

00:03:19,069 --> 00:03:22,360
I'm not able to do that side by sight analysis and there are

00:03:22,360 --> 00:03:24,540
free charts on the screen all showing slightly different

00:03:24,540 --> 00:03:27,340
data, but at this level of detail it is not discernible,

00:03:27,340 --> 00:03:29,820
you can't make out what they're trying to show.

00:03:29,820 --> 00:03:36,380
Now I want to show you something we've built.

00:03:36,380 --> 00:03:39,080
This is chronicle, an application we built for

00:03:39,080 --> 00:03:41,820
analysing time series data.

00:03:41,820 --> 00:03:43,420
Seismological data is one example.

00:03:43,420 --> 00:03:46,700
I'll search for Alaska.

00:03:46,700 --> 00:03:52,810
In early September there was a swarm of earthquakes off the islands in Alaska,

00:03:52,810 --> 00:03:57,050
this isn't a particularly part of the interesting work

00:03:57,050 --> 00:03:59,370
for earthquakes, the US geological survey has

00:03:59,370 --> 00:04:03,180
a bunch of things for recording activity.

00:04:03,180 --> 00:04:05,810
We can see a big spike.

00:04:05,810 --> 00:04:11,290
Select this and zoom in.

00:04:11,290 --> 00:04:13,190
A huge cluster of earthquakes.

00:04:13,190 --> 00:04:15,150
Zoom in.

00:04:15,150 --> 00:04:17,799
It gets blocky here, and we'll talk about that

00:04:17,799 --> 00:04:18,799
later on.

00:04:18,799 --> 00:04:21,549
I have enough screen real estate, so I can split

00:04:21,549 --> 00:04:24,002
these up as well, make it easier to figure out what is

00:04:24,002 --> 00:04:26,220
going on if we don't have them clashing all on top of

00:04:26,220 --> 00:04:28,629
each other.

00:04:28,629 --> 00:04:36,560
We can now pan and zoom around like you'd

00:04:36,560 --> 00:04:37,560
expect.

00:04:37,560 --> 00:04:42,810
This is a responsive intuitive application, I can zoom in and see what's going on, hide

00:04:42,810 --> 00:04:47,090
these axes, and we can see that this sensor recording

00:04:47,090 --> 00:04:52,050
the earthquake a few minutes, a few seconds, maybe, after

00:04:52,050 --> 00:04:54,960
the other sensors.

00:04:54,960 --> 00:04:58,700
And that's actually because this particularly sensor is on a different island further away.

00:04:58,700 --> 00:05:00,650
We can use that to maybe triangulate the position

00:05:00,650 --> 00:05:03,520
of the epicentre of the earthquake.

00:05:03,520 --> 00:05:06,730
If you remember your high school university or geology classes, you'll

00:05:06,730 --> 00:05:10,650
know it's made up of two component waves and a bunch

00:05:10,650 --> 00:05:13,210
of the smaller ones too, the P1 at the start, the

00:05:13,210 --> 00:05:15,550
S wave is the higher frequency one that comes in probably

00:05:15,550 --> 00:05:17,310
around here.

00:05:17,310 --> 00:05:19,660
If we wanted to compare this particular quake with the

00:05:19,660 --> 00:05:23,580
others, we could offset it maybe and interact with these

00:05:23,580 --> 00:05:26,060
charts individually, but we have a common scrub bar

00:05:26,060 --> 00:05:28,720
across all three, so we can get a good idea of what's

00:05:28,720 --> 00:05:31,000
going on.

00:05:31,000 --> 00:05:34,690
What I'm trying to show you here is not actually anything to do with earthquakes or seismology,

00:05:34,690 --> 00:05:37,050
they're both interesting and not terribly relevant

00:05:37,050 --> 00:05:38,050
to the conference.

00:05:38,050 --> 00:05:47,050
What I'm trying to show you a is a good way of measuring a large act of data.

00:05:47,050 --> 00:05:50,880
That's key as an engineer, a lot of that is very interesting

00:05:50,880 --> 00:05:54,169
to me, although as a user you can't really tell.

00:05:54,169 --> 00:05:56,250
There is no indication of how much is on the screen.

00:05:56,250 --> 00:05:58,960
Our users don't really care how much they have, they

00:05:58,960 --> 00:06:02,419
just care about being access and asking questions.

00:06:02,419 --> 00:06:05,540
For reference, there are four different series each recorded

00:06:05,540 --> 00:06:08,920
at 100-hertz, so over the entire week, that's

00:06:08,920 --> 00:06:11,610
around 300 million data points and all running on

00:06:11,610 --> 00:06:14,300
my laptop and I'm able to interact with it intuitively and

00:06:14,300 --> 00:06:16,669
responsibly.

00:06:16,669 --> 00:06:18,919
This was developed for an industry customer, they

00:06:18,919 --> 00:06:21,480
didn't care about data quite as dense as this, what they

00:06:21,480 --> 00:06:27,320
cared about was -- they had data of across tens of

00:06:27,320 --> 00:06:31,800
thousands of different series, spanning multiple years,

00:06:31,800 --> 00:06:35,729
and it is used in critical safety of life operations

00:06:35,729 --> 00:06:38,140
where they need to be able to look at up to 40 series at

00:06:38,140 --> 00:06:44,200
once of live, incoming realtime data.

00:06:44,200 --> 00:06:49,300
So in total, with the tens of thousands of series over many,

00:06:49,300 --> 00:06:52,080
many years, they have around 300 billion data points and

00:06:52,080 --> 00:06:54,800
they're able to interact with it as if it was one.

00:06:54,800 --> 00:06:57,370
They don't really care about the data skill.

00:06:57,370 --> 00:07:00,770
And this is just one way of visualising large amounts of data.

00:07:00,770 --> 00:07:05,040
I'm now going to show you another, and this is something

00:07:05,040 --> 00:07:07,530
we built during hack week this year at Palantir.

00:07:07,530 --> 00:07:13,120
It is a week Palantir has every year where we get to basically

00:07:13,120 --> 00:07:15,220
work on whatever we want for an entire week.

00:07:15,220 --> 00:07:17,509
Anyone in the company is allowed to work on any project

00:07:17,509 --> 00:07:19,750
completely unrelated to their usual work, maybe a feature

00:07:19,750 --> 00:07:22,660
to add to an app, maybe an entirely new prototype of

00:07:22,660 --> 00:07:25,930
an application, and that's what we built up.

00:07:25,930 --> 00:07:30,020
It's my favourite week because it gives anyone the

00:07:30,020 --> 00:07:32,650
opportunity to build something cool and form a team around

00:07:32,650 --> 00:07:34,300
it.

00:07:34,300 --> 00:07:36,081
Many of our great products and features have come

00:07:36,081 --> 00:07:37,199
out of this week.

00:07:37,199 --> 00:07:40,320
What we're looking at is a network graph.

00:07:40,320 --> 00:07:44,740
I have US presidential election data from campaign finance

00:07:44,740 --> 00:07:45,800
data.

00:07:45,800 --> 00:07:47,740
This was taken from the last two weeks running up to the

00:07:47,740 --> 00:07:49,830
US election, and this dataset is entirely available

00:07:49,830 --> 00:07:52,080
online and is one of the largest I know of of these

00:07:52,080 --> 00:07:54,190
relational datasets.

00:07:54,190 --> 00:07:58,100
We can see in the middle we have Art Robinson for congress, a political action

00:07:58,100 --> 00:07:59,570
for committee.

00:07:59,570 --> 00:08:03,789
This one particularly supports Art Robinson, but however these committees can support a

00:08:03,789 --> 00:08:06,320
candidate or particular interest group.

00:08:06,320 --> 00:08:10,500
Around it we can see payments and the green dots are

00:08:10,500 --> 00:08:12,570
the donors.

00:08:12,570 --> 00:08:17,520
So we can evaluate who is giving money to who.

00:08:17,520 --> 00:08:24,819
In this particular case, we can see that William Brady here is donating $200 to Robinson for

00:08:24,819 --> 00:08:25,819
congress.

00:08:25,819 --> 00:08:28,060
What's interesting about this is that while we only took

00:08:28,060 --> 00:08:30,360
about two weeks of the data and we only took it for

00:08:30,360 --> 00:08:32,340
California, there is actually a whole tonne of data.

00:08:32,340 --> 00:08:35,560
These are all the transactions in the last two weeks,

00:08:35,560 --> 00:08:37,719
and maybe this is a comment on the US political system.

00:08:37,719 --> 00:08:41,440
I'm allowed to do that; I'm in Europe.

00:08:41,440 --> 00:08:45,000
So as we zoom out, we see a good view of the entire

00:08:45,000 --> 00:08:47,740
data and we can see some visual artifacts going on and

00:08:47,740 --> 00:08:50,399
I'm going to explain why these are later on.

00:08:50,399 --> 00:08:54,380
So here we have the entire set of data.

00:08:54,380 --> 00:08:56,680
There's two large blobs in the middle and then two to

00:08:56,680 --> 00:08:57,910
the bottom right.

00:08:57,910 --> 00:09:00,339
It won't surprise you if we use this little tool

00:09:00,339 --> 00:09:04,860
to jump in and analyse what's going on in a given area,

00:09:04,860 --> 00:09:08,390
we can find Mr Obama's political action commits and,

00:09:08,390 --> 00:09:12,110
woah, that way too far.

00:09:12,110 --> 00:09:14,339
Zoom out now.

00:09:14,339 --> 00:09:16,580
It's thinking hard.

00:09:16,580 --> 00:09:17,830
Traditionally at Palantir we've been dealing with

00:09:17,830 --> 00:09:20,430
these large datasets for a while, and we didn't think

00:09:20,430 --> 00:09:23,230
there was too much value in a graph of this scale.

00:09:23,230 --> 00:09:25,730
It is so much data that we didn't think you could

00:09:25,730 --> 00:09:26,990
visualise what was going.

00:09:26,990 --> 00:09:30,520
However, when we built and took advantage of these features like the loop

00:09:30,520 --> 00:09:32,120
I was just showing you, and hope to show you again in

00:09:32,120 --> 00:09:37,279
a minute, when this has decided it's going to behave,

00:09:37,279 --> 00:09:40,140
and through some clever node colouring, I suppose I can

00:09:40,140 --> 00:09:42,940
fit it to screen, we're able to analyse this large amount

00:09:42,940 --> 00:09:46,300
of data in a realistic and easy way.

00:09:46,300 --> 00:09:50,520
We're basically allowed to see what's going on here, zoom in for more

00:09:50,520 --> 00:09:52,980
information, we can use the loop tool to figure out this

00:09:52,980 --> 00:09:57,410
one of Romney's parks, it is kind of unsurprising

00:09:57,410 --> 00:10:01,540
these large groups are both related to Obama and Romney.

00:10:01,540 --> 00:10:06,800
So this is a whole tonne of data and that's kind of interesting

00:10:06,800 --> 00:10:07,800
to me.

00:10:07,800 --> 00:10:09,071
It's probably not as interesting to our users how

00:10:09,071 --> 00:10:11,810
much data we have here, but we're able to interact

00:10:11,810 --> 00:10:14,380
with it in a realistic way, we're able to interact with

00:10:14,380 --> 00:10:17,870
it, move nodes around as we see fit, apply layouts,

00:10:17,870 --> 00:10:21,740
follow the lengths so here I can expand my selection to

00:10:21,740 --> 00:10:25,620
all of the related lengths, and we can select all and we

00:10:25,620 --> 00:10:27,380
can throw them in a stupid grid.

00:10:27,380 --> 00:10:28,380
We can do it.

00:10:28,380 --> 00:10:32,100
It is a very interactive application and we can

00:10:32,100 --> 00:10:34,450
easily get a good visualisation over this data.

00:10:34,450 --> 00:10:39,110
It uses a tool in the right-hand corner, we have 168,000 objects

00:10:39,110 --> 00:10:40,820
on this graph.

00:10:40,820 --> 00:10:44,430
And that's 999,000 donations for some reason one

00:10:44,430 --> 00:10:46,930
shy of 100,000 donations here.

00:10:46,930 --> 00:10:51,300
So in total we have 168,000 nodes with 200,000 edges going between

00:10:51,300 --> 00:10:53,080
them.

00:10:53,080 --> 00:10:56,050
And this is the kind of commonality I see between

00:10:56,050 --> 00:10:58,690
this and chronicle, the one I showed you a minute ago,

00:10:58,690 --> 00:11:00,610
we're dealing with a scale of data that has not

00:11:00,610 --> 00:11:02,920
traditionally been easy to interact with on the front

00:11:02,920 --> 00:11:03,920
end.

00:11:03,920 --> 00:11:06,320
The big difference is this is entirely front end

00:11:06,320 --> 00:11:07,320
driven.

00:11:07,320 --> 00:11:11,040
Once I loaded the file from a flat JSON file it

00:11:11,040 --> 00:11:13,190
is entirely stored on the front end, there's no back

00:11:13,190 --> 00:11:14,190
end.

00:11:14,190 --> 00:11:16,290
This is entirely client side JavaScript project.

00:11:16,290 --> 00:11:20,310
I'll jump back to the presentation.

00:11:20,310 --> 00:11:27,589
There's the demos we don't need to use.

00:11:27,589 --> 00:11:32,290
At the heart of these applications is a visual display of our data, in one case this was

00:11:32,290 --> 00:11:34,610
a series of line charts and then in the other a set of

00:11:34,610 --> 00:11:35,649
nodes and edges.

00:11:35,649 --> 00:11:38,510
Both are rendered on to a 2D canvas.

00:11:38,510 --> 00:11:40,660
Now for those of you familiar with canvas programming,

00:11:40,660 --> 00:11:43,149
you'll know there's a tonn of drawbacks to using

00:11:43,149 --> 00:11:48,140
canvas.

00:11:48,140 --> 00:11:53,100
In HTML we can position elements using CSS, we

00:11:53,100 --> 00:11:54,560
can use tables, alternatives, take advantage of all

00:11:54,560 --> 00:11:56,550
the fancy reactive components we've built to easily

00:11:56,550 --> 00:11:58,170
build together an application.

00:11:58,170 --> 00:12:02,510
We can use mouse event listeners on individual elements to figure out what the

00:12:02,510 --> 00:12:04,450
user is trying to do at a given point.

00:12:04,450 --> 00:12:08,700
In canvas we get these pretty primitive APIs and

00:12:08,700 --> 00:12:11,120
have to use pixel math to work out where we're trying to

00:12:11,120 --> 00:12:14,840
render and when a user interacts with the scene we

00:12:14,840 --> 00:12:17,930
simply get an event callback saying it was an X and Y

00:12:17,930 --> 00:12:19,490
coordinate, and we have to work out what the user was

00:12:19,490 --> 00:12:21,160
trying to do at this point in time.

00:12:21,160 --> 00:12:27,440
It is hard to do anything incremental, as soon as

00:12:27,440 --> 00:12:29,370
you paint a node on to it, it's there for good.

00:12:29,370 --> 00:12:31,529
The only way to get rid of it is to paint something

00:12:31,529 --> 00:12:35,519
on top or close the whole canvas down.

00:12:35,519 --> 00:12:38,350
If I'm trying to render a graph that size and want to move a node

00:12:38,350 --> 00:12:41,301
across the screen, I have to do a lot of work to make

00:12:41,301 --> 00:12:43,320
that happen.

00:12:43,320 --> 00:12:47,190
The question is, why did we use canvas for this?

00:12:47,190 --> 00:12:49,890
Why didn't we use SVG, 3G?

00:12:49,890 --> 00:12:55,260
I'm sure we've all seen this demo online, a lot of tune, or why didn't

00:12:55,260 --> 00:12:57,860
we use ploddable for synchronised line charts?

00:12:57,860 --> 00:13:01,040
This is the open source charting library we announced

00:13:01,040 --> 00:13:03,459
here last year and are still actively developing.

00:13:03,459 --> 00:13:07,420
They even have an example of synchronised chart on the website

00:13:07,420 --> 00:13:09,959
as if it was trying to tempt me to talk about them.

00:13:09,959 --> 00:13:13,959
It all comes back to performance at scale.

00:13:13,959 --> 00:13:17,210
The DOM simply wasn't designed to have tens of thousands,

00:13:17,210 --> 00:13:23,700
hundreds of thousands of nodes in it all animating either independently or in sync, it just doesn't

00:13:23,700 --> 00:13:24,700
work.

00:13:24,700 --> 00:13:28,390
So for earlier versions we did use this, we wanted to

00:13:28,390 --> 00:13:32,640
use this, however when you start to move nodes individually independent from the rest of

00:13:32,640 --> 00:13:35,162
the scene, things start to slow down.

00:13:35,162 --> 00:13:40,019
They get pretty sluggish.

00:13:40,019 --> 00:13:42,519
One of the drawbacks that I was discussing was

00:13:42,519 --> 00:13:45,290
having to rerender everything every frame and we can

00:13:45,290 --> 00:13:47,530
find a work around for this.

00:13:47,530 --> 00:13:51,250
We can stack multiple canvases on top of each other, for example

00:13:51,250 --> 00:13:53,959
in chronicle, we had a different canvas for each of the

00:13:53,959 --> 00:13:59,260
different series, the line graphs, we had a canvas for

00:13:59,260 --> 00:14:02,690
the axis and a canvas for the controls and the hover.

00:14:02,690 --> 00:14:04,709
This meant that as a user was hovering over the chart

00:14:04,709 --> 00:14:08,720
we only need to re-render one of canvases, not the entire

00:14:08,720 --> 00:14:09,720
scene every time.

00:14:09,720 --> 00:14:11,899
The graph was even more decomposed.

00:14:11,899 --> 00:14:14,640
We have a different layer for the selected edges,

00:14:14,640 --> 00:14:16,930
nodes selecting nodes, this drag rectangle box and

00:14:16,930 --> 00:14:18,769
so on.

00:14:18,769 --> 00:14:21,370
This meant that if a user clicks on a node or if they do

00:14:21,370 --> 00:14:23,839
a simple operation, we only needed to re-render one or

00:14:23,839 --> 00:14:27,150
two, not the entire scene.

00:14:27,150 --> 00:14:29,680
This trick extends to DOM elements too.

00:14:29,680 --> 00:14:33,680
We can use absolute positioning to position DOM elements on top of the canvas.

00:14:33,680 --> 00:14:36,779
This was how the loop tool I showed you earlier worked.

00:14:36,779 --> 00:14:40,889
We positioned it to the left of the cursor, and

00:14:40,889 --> 00:14:43,940
then we were able to program in however we wanted

00:14:43,940 --> 00:14:47,360
the content, so we had this object previews with a table

00:14:47,360 --> 00:14:48,360
of donations.

00:14:48,360 --> 00:14:51,140
We can use normal HTML CSS for that.

00:14:51,140 --> 00:14:53,110
This makes things flexible.

00:14:53,110 --> 00:14:58,230
We can easily add extra hints and information about our scene.

00:14:58,230 --> 00:15:01,610
In an earlier version of the graph we used that for every node.

00:15:01,610 --> 00:15:03,750
Every node was a DOM element, positioned absolutely on

00:15:03,750 --> 00:15:07,650
the scene, then we used CSS translations to move the

00:15:07,650 --> 00:15:10,889
scene around as the user interacted and dragged around.

00:15:10,889 --> 00:15:13,870
This worked out well, we had a single canvas for edges

00:15:13,870 --> 00:15:15,670
and all of our nodes were easy to programme.

00:15:15,670 --> 00:15:18,720
It was all very clean code.

00:15:18,720 --> 00:15:21,130
The downside was that as we started to move nodes

00:15:21,130 --> 00:15:23,220
independently as we started to push the node scale up to

00:15:23,220 --> 00:15:26,329
tens of thousands, things slowed down.

00:15:26,329 --> 00:15:29,089
It isn't designed for this behaviour.

00:15:29,089 --> 00:15:33,120
This technique of layering canvas and DOM is really powerful.

00:15:33,120 --> 00:15:37,260
Really flexible, but don't expect it to scale with the data.

00:15:37,260 --> 00:15:39,670
The biggest problem we faced when we tried to scale

00:15:39,670 --> 00:15:42,389
our graph out to hundreds of thousands of nodes was

00:15:42,389 --> 00:15:46,070
simply the time it took to render a single frame.

00:15:46,070 --> 00:15:48,660
Using tools like the Firefox performance tools and

00:15:48,660 --> 00:15:51,510
the Chrome timeline we were able to get a good understanding

00:15:51,510 --> 00:15:54,170
of what is happening each frame.

00:15:54,170 --> 00:15:56,149
And I'm not actually going to go into them too much here, there's

00:15:56,149 --> 00:15:58,779
a load of great resources online about to how to use

00:15:58,779 --> 00:15:59,779
them.

00:15:59,779 --> 00:16:02,180
There is also a lot about how to do specific canvas

00:16:02,180 --> 00:16:04,010
profiling and optimisations.

00:16:04,010 --> 00:16:06,949
However, do take them with a pinch of salt.

00:16:06,949 --> 00:16:12,440
You'll often find advice like this: avoid shadow blur, which is great, it has a good

00:16:12,440 --> 00:16:13,440
intent behind.

00:16:13,440 --> 00:16:14,670
It can be expensive.

00:16:14,670 --> 00:16:16,720
Rendering drop shadows turns out to be one of the more expensive

00:16:16,720 --> 00:16:18,290
operations you can do on a canvas.

00:16:18,290 --> 00:16:23,310
However, if you want to drop shadow on something it is bad advice, it doesn't

00:16:23,310 --> 00:16:25,860
tell me what to do instead.

00:16:25,860 --> 00:16:30,790
We wanted to drop shadow on to the nodes because it looks cool, so how do we do that?

00:16:30,790 --> 00:16:33,120
How do we go about doing this?

00:16:33,120 --> 00:16:36,520
We came up with the jsperf test to see if we can compare the standard rendering

00:16:36,520 --> 00:16:38,680
of drop shadows to some other technique of getting

00:16:38,680 --> 00:16:41,720
the same effect.

00:16:41,720 --> 00:16:43,149
This is what we're trying to render.

00:16:43,149 --> 00:16:44,360
There's a subtle drop shadow.

00:16:44,360 --> 00:16:51,570
You can just about see it.

00:16:51,570 --> 00:16:54,070
We write our test, start with the width and height

00:16:54,070 --> 00:16:55,899
of the node and the number to render.

00:16:55,899 --> 00:16:59,841
We used to render a bunch because of the drawback of drop shadow

00:16:59,841 --> 00:17:04,569
is when you render them on top of them the anti-aliasing

00:17:04,569 --> 00:17:07,439
is what causes the slowdown to happen.

00:17:07,439 --> 00:17:10,699
Then we have this render function, it takes a canvas context and renders

00:17:10,699 --> 00:17:13,639
a node to it takes an X and Y position.

00:17:13,639 --> 00:17:18,880
First of all make radius, set the style using this red, and

00:17:18,880 --> 00:17:22,579
have a shadow blur of depth one.

00:17:22,579 --> 00:17:25,639
For reference, this is what we're trying to render.

00:17:25,639 --> 00:17:30,619
So we're making an arc and fill that with firebrick red and then stroke this to

00:17:30,619 --> 00:17:34,090
get the white ring round, and add an orange stroke, this

00:17:34,090 --> 00:17:36,529
represents the selection, as you select them they get

00:17:36,529 --> 00:17:39,039
this orange halo.

00:17:39,039 --> 00:17:41,519
What we're going to do is rendering directly to

00:17:41,519 --> 00:17:44,739
the canvas, a thousand of these nodes versus first

00:17:44,739 --> 00:17:46,909
rendering to an image essentially rasterising the node

00:17:46,909 --> 00:17:50,669
down to an image and using that everywhere.

00:17:50,669 --> 00:17:53,039
This looks like this, make a canvas, make it slightly

00:17:53,039 --> 00:17:57,269
bigger to allow for the drop shadow, and we never attach

00:17:57,269 --> 00:17:59,980
this to the DOM, it is purely held in memory, then

00:17:59,980 --> 00:18:02,710
we call render note passing in with the canvas with

00:18:02,710 --> 00:18:04,950
the H width and height in the middle.

00:18:04,950 --> 00:18:08,440
Our two test cases look like this: we have a canvas

00:18:08,440 --> 00:18:10,200
and pull out the context.

00:18:10,200 --> 00:18:15,429
We clear it, JS perf uses the same HTML for the tests and it runs another

00:18:15,429 --> 00:18:19,919
one to get a good aggregate of the number of time spent,

00:18:19,919 --> 00:18:22,869
then we iterate through the thousand nodes calling

00:18:22,869 --> 00:18:24,190
render note on to the canvas.

00:18:24,190 --> 00:18:26,749
Our second test case looks almost identical.

00:18:26,749 --> 00:18:31,193
The only line that changes is this, instead of calling it the node, we call it the draw

00:18:31,193 --> 00:18:33,049
image.

00:18:33,049 --> 00:18:35,389
And this is what it looks like.

00:18:35,389 --> 00:18:38,389
You'd be hard pressed to tell the difference between the two if I didn't

00:18:38,389 --> 00:18:41,149
say which was which, you'd probably have a guess,

00:18:41,149 --> 00:18:42,330
but maybe not.

00:18:42,330 --> 00:18:45,090
However, the time it takes to render each is

00:18:45,090 --> 00:18:46,340
hugely different.

00:18:46,340 --> 00:18:51,461
15.1 milliseconds, for reference if you want a 60FPS frame rate you need to be

00:18:51,461 --> 00:18:55,049
rendering every frame in under 16.6, so at a thousand

00:18:55,049 --> 00:18:57,690
nodes we can just about do the old technique, with this

00:18:57,690 --> 00:18:59,580
we can scale it up more.

00:18:59,580 --> 00:19:06,379
The drawback of this approach is that we need a raster image for every node size, not quite

00:19:06,379 --> 00:19:09,629
every one, but we can choose a few sizes we care about

00:19:09,629 --> 00:19:11,330
and then always scale them down.

00:19:11,330 --> 00:19:15,429
It doesn't look too bad, and this way the memory impact isn't too high

00:19:15,429 --> 00:19:17,320
and we can compute this as a one-off at the start when

00:19:17,320 --> 00:19:20,960
we initialise our scene.

00:19:20,960 --> 00:19:24,729
So the take away from this is not to avoid shadow blur.

00:19:24,729 --> 00:19:28,370
If you just add it to one or two objects, the cost might not be too high.

00:19:28,370 --> 00:19:30,321
What you should do is profile every change you're planning

00:19:30,321 --> 00:19:32,259
on making, if you plan on making shadow blur,

00:19:32,259 --> 00:19:33,259
profile it.

00:19:33,259 --> 00:19:34,539
Does it make a meaningful impact?

00:19:34,539 --> 00:19:39,289
If so, are there ways to find round this?

00:19:39,289 --> 00:19:41,139
Another technique to push the scale a little bit

00:19:41,139 --> 00:19:44,419
more was reducing the amount of detail rendered as the

00:19:44,419 --> 00:19:46,399
scene -- as we zoomed out.

00:19:46,399 --> 00:19:52,259
In this example, we render the -- we lower the opacity on our node labels

00:19:52,259 --> 00:19:55,700
as we zoom out, once you get beyond a certain zoom

00:19:55,700 --> 00:19:58,899
level the labels aren't useful, you can't read them.

00:19:58,899 --> 00:20:00,950
So there is no reason to go to all the trouble of rendering

00:20:00,950 --> 00:20:02,029
the text, which is expensive.

00:20:02,029 --> 00:20:05,580
We do a similar thing with the icons too.

00:20:05,580 --> 00:20:10,450
After a certain point, is all that matters is having a purple circle that's the

00:20:10,450 --> 00:20:11,450
right size.

00:20:11,450 --> 00:20:13,529
This allows you to pick up -- oh look, there's a lot of

00:20:13,529 --> 00:20:15,909
interesting things going on without having to think too

00:20:15,909 --> 00:20:17,889
much about each individual data point.

00:20:17,889 --> 00:20:20,570
This gives us the aggregation of the data.

00:20:20,570 --> 00:20:23,379
Again, we profile each of these changes, does it

00:20:23,379 --> 00:20:25,940
actually make a meaningful difference to the performance?

00:20:25,940 --> 00:20:28,609
In this case it actually did.

00:20:28,609 --> 00:20:31,080
Another trick was, as we moved even further out once

00:20:31,080 --> 00:20:33,399
each node was taking up less than a pixel, we render

00:20:33,399 --> 00:20:36,580
them as rectangles because they're quicker and better

00:20:36,580 --> 00:20:37,960
than circles.

00:20:37,960 --> 00:20:42,909
We figured if the user can't tell it's a circle, why bother spending all of our GPU

00:20:42,909 --> 00:20:45,239
time making these circles?

00:20:45,239 --> 00:20:50,600
The final thing is debounce.

00:20:50,600 --> 00:20:53,440
This is a function that lets you split your rendering pipeline

00:20:53,440 --> 00:20:54,440
into two.

00:20:54,440 --> 00:20:58,029
The problem we faced as we kind of tried to scale up our

00:20:58,029 --> 00:21:01,539
node scale even higher and higher, was that every time,

00:21:01,539 --> 00:21:04,409
every frame, we were iterating through hundreds of

00:21:04,409 --> 00:21:08,479
thousands of edges and nodes and spending the time to

00:21:08,479 --> 00:21:13,850
iterate through each was pretty expensive, basically it

00:21:13,850 --> 00:21:15,960
meant that our application didn't feel responsive, as

00:21:15,960 --> 00:21:19,080
a user was dragging and planning across the scene, we

00:21:19,080 --> 00:21:22,440
had to iterate through all these nodes and edges and do

00:21:22,440 --> 00:21:25,710
some basic rendering, but this still took up a lot of

00:21:25,710 --> 00:21:29,929
time, we ended up with the frame rate way too high --

00:21:29,929 --> 00:21:34,869
sorry, way too low, and this was just -- it didn't feel

00:21:34,869 --> 00:21:36,289
responsive.

00:21:36,289 --> 00:21:37,490
We used debounce.

00:21:37,490 --> 00:21:40,320
We debounced the interactions and only call render when the

00:21:40,320 --> 00:21:42,409
user stops interacting.

00:21:42,409 --> 00:21:46,349
That sounds insane.

00:21:46,349 --> 00:21:50,330
We pushed back the expensive render on this debounce, and we

00:21:50,330 --> 00:21:53,159
need to find a way of updating our scene without incurring

00:21:53,159 --> 00:21:56,039
the expensive cost of a render.

00:21:56,039 --> 00:21:57,570
How?

00:21:57,570 --> 00:22:01,169
We can take advantage of the fact that we've just rendered the scene, and the scene we

00:22:01,169 --> 00:22:04,139
rendered looks almost identical to the new scene, apart from

00:22:04,139 --> 00:22:05,139
a few pixels.

00:22:05,139 --> 00:22:10,889
So every time we rendered the scene we take a snapshot and save it to a an offscreen canvas.

00:22:10,889 --> 00:22:15,769
It holds the entire screen.

00:22:15,769 --> 00:22:20,440
It's not too bad, the bigger it was, the more expensive, but for our purposes

00:22:20,440 --> 00:22:21,580
it works.

00:22:21,580 --> 00:22:25,220
Ah, the user zooms out, we take the image, render it

00:22:25,220 --> 00:22:27,330
on to the screen to render it down.

00:22:27,330 --> 00:22:30,639
You get white boxes round the edge where we don't know the stated

00:22:30,639 --> 00:22:33,840
of the world.

00:22:33,840 --> 00:22:35,990
It doesn't really matter.

00:22:35,990 --> 00:22:39,640
As you saw earlier, you'll get the white boxes, but you don't

00:22:39,640 --> 00:22:42,230
really notice if you're going pretty slowly, and you're

00:22:42,230 --> 00:22:45,129
going fast, as soon as you stop, the full render kicks in,

00:22:45,129 --> 00:22:47,360
you see the whole state again.

00:22:47,360 --> 00:22:50,389
As you zoom in, things get a bit blurry.

00:22:50,389 --> 00:22:52,679
Again, it doesn't really detract.

00:22:52,679 --> 00:22:54,169
You know where you're tying to zoom in to, you can

00:22:54,169 --> 00:22:57,629
see where you're going to, it doesn't matter, and as

00:22:57,629 --> 00:23:00,480
soon as you stop interacting, the full state of the graph

00:23:00,480 --> 00:23:01,940
is available.

00:23:01,940 --> 00:23:03,549
We do the same for planning as well.

00:23:03,549 --> 00:23:06,330
We simply translate the gym.

00:23:06,330 --> 00:23:07,599
This is even more noticeable.

00:23:07,599 --> 00:23:11,580
Generally you pan quite fast, but it doesn't really stop

00:23:11,580 --> 00:23:13,990
the interaction, you're still able to figure out what

00:23:13,990 --> 00:23:16,159
you're doing with the scene.

00:23:16,159 --> 00:23:19,399
And it is not long before the full render kicks in, so you're able to

00:23:19,399 --> 00:23:21,600
see the full scene again.

00:23:21,600 --> 00:23:23,639
This allowed us to push that node scale all the way

00:23:23,639 --> 00:23:26,899
up, so that each frame render was no longer dependent on

00:23:26,899 --> 00:23:29,650
the number of nodes and edges we were trying to render.

00:23:29,650 --> 00:23:32,960
Our limitation was now the amount of stuff to store in

00:23:32,960 --> 00:23:34,220
the JavaScript memory.

00:23:34,220 --> 00:23:38,499
We actually do a similar trick in chronicle.

00:23:38,499 --> 00:23:40,970
If you remember, as we panned left and right occasionally

00:23:40,970 --> 00:23:42,970
things would get blocky, as we zoomed in, or as we

00:23:42,970 --> 00:23:46,710
panned the B section was missing, and the reason is we

00:23:46,710 --> 00:23:49,269
have to request data from our back end every time we

00:23:49,269 --> 00:23:52,820
want to view data because we're talking about millions

00:23:52,820 --> 00:23:55,650
maybe billions of data points, we need to use a back end

00:23:55,650 --> 00:23:56,650
to aggregate this data for us.

00:23:56,650 --> 00:23:59,499
We simply can't do it on the front end.

00:23:59,499 --> 00:24:01,999
So instead of debouncing the render call, we

00:24:01,999 --> 00:24:04,519
debounce our request data call.

00:24:04,519 --> 00:24:05,950
The render is cheap enough, actually.

00:24:05,950 --> 00:24:09,830
This is not too much data by the time it makes the front end, but the request data

00:24:09,830 --> 00:24:12,239
call puts a tonne of work on to the server.

00:24:12,239 --> 00:24:14,890
It has to load the stuff into the memory and do aggregations.

00:24:14,890 --> 00:24:17,420
It is fast but it's not the thing where you want to be

00:24:17,420 --> 00:24:19,590
thrashing the server making it do a load of work where

00:24:19,590 --> 00:24:24,389
no one will see this, so we debounce this.

00:24:24,389 --> 00:24:27,700
In the meantime, we have the data from the previous scene on the front

00:24:27,700 --> 00:24:30,730
end, so we don't do the canvas tricks instead, we do

00:24:30,730 --> 00:24:32,989
it with the raw data, we re-render the data we already

00:24:32,989 --> 00:24:35,879
have for the subset of the scene we're going to know about,

00:24:35,879 --> 00:24:37,970
so as you zoomed we can render the same data, just small

00:24:37,970 --> 00:24:39,110
smaller and in the middle.

00:24:39,110 --> 00:24:44,340
You as zoom in, we can render the data and that's why it gets blocky.

00:24:44,340 --> 00:24:48,269
As I pan to the left, there's some data missing and the same

00:24:48,269 --> 00:24:49,269
with the right.

00:24:49,269 --> 00:24:50,880
It interacts the same with the graph and as we

00:24:50,880 --> 00:24:52,499
zoom in, it gets blocky.

00:24:52,499 --> 00:24:53,679
It doesn't detract.

00:24:53,679 --> 00:24:57,320
You still have the same information as you had before,

00:24:57,320 --> 00:24:58,749
but the back end is snappy.

00:24:58,749 --> 00:25:04,549
So in no time the real data kicks in and you can continue the analysis.

00:25:04,549 --> 00:25:06,309
This is very similar to how Google Maps works with

00:25:06,309 --> 00:25:10,429
vector tiles.

00:25:10,429 --> 00:25:13,019
To quickly sum up, we talked about what makes a good

00:25:13,019 --> 00:25:16,472
user experience and this is the idea of making a good

00:25:16,472 --> 00:25:20,499
intuitive and responsive user experience.

00:25:20,499 --> 00:25:23,059
We talked a bit about decomposing the scene using layering

00:25:23,059 --> 00:25:27,809
canvases or DOM on top, and to cover those of those

00:25:27,809 --> 00:25:31,799
limitations, although there is still a lot to get over,

00:25:31,799 --> 00:25:36,529
we can profile to figure out where time is being spent,

00:25:36,529 --> 00:25:38,830
and we covered a few of the more commonplace and more

00:25:38,830 --> 00:25:42,500
basic performance techniques, such as reusing objects

00:25:42,500 --> 00:25:45,399
wherever you can, reusing the canvas, and pre-empting

00:25:45,399 --> 00:25:46,399
the next state.

00:25:46,399 --> 00:25:48,269
That's all I have.

00:25:48,269 --> 00:25:51,129
So thanks a lot for listening and please come through with any questions,

00:25:51,129 --> 00:25:52,129
please find me afterwards.

00:25:52,129 --> 00:25:52,419

YouTube URL: https://www.youtube.com/watch?v=6FRURtW5qXI


