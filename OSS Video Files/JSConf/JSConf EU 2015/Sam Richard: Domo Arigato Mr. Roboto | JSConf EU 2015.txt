Title: Sam Richard: Domo Arigato Mr. Roboto | JSConf EU 2015
Publication date: 2015-10-17
Playlist: JSConf EU 2015
Description: 
	How would your message change if your email client told you your phrasing is likely to be perceived as negative? What would you cook if you could explore ingredient and culinary style pairings you’ve never encountered? How could your research improve if answers came with confidence levels and supporting evidence you can explore?

Welcome to the world of Cognitive Computing, the next wave of computing technology bridging the gap between computers and humans. While these possibilities may seem far off, you can build all of these today! Let’s explore.

Intro music by @halfbyte
Captions: 
	00:00:26,920 --> 00:00:32,590
Good morning everyone, so I am talking today about cognitive computing, the name of my

00:00:32,590 --> 00:00:38,900
talk is Domo Arigato, Mr Roboto, I do not speak Japanese, I copied that straight from

00:00:38,900 --> 00:00:52,120
Wikipedia, I'll talk about cognitive computing, my slides are 

00:00:52,120 --> 00:00:57,710
available online, ‘snugug’ is the bit that's important, that's where I'm on the

00:00:57,710 --> 00:01:01,940
internet, Github, Twitter, you can find me there.

00:01:01,940 --> 00:01:07,380
So let's talk about the world of cognitive computing, shall we.

00:01:07,380 --> 00:01:10,159
This is Pepper.

00:01:10,159 --> 00:01:19,950
Pepper is a robot, built by Soft Bank a Japanese company, pepper is designed to be one of the

00:01:19,950 --> 00:01:26,450
worlds first human computer interactive Android type things.

00:01:26,450 --> 00:01:30,850
It's using the power of cognitive computing to make this interaction between humans and

00:01:30,850 --> 00:01:37,700
computers a little bit easier something not like the programming we do everyday.

00:01:37,700 --> 00:01:44,409
If we talk about cognitive computing we should probably define what cognitive computing is.

00:01:44,409 --> 00:01:50,250
So cognitive computing is a new field of computing, the types of problem that cognitive computing

00:01:50,250 --> 00:01:56,719
can solve are unlike any problems we have been able to try and work on before.

00:01:56,719 --> 00:02:01,759
It's for working with human complex problems, so the type of problems that were normally

00:02:01,759 --> 00:02:07,880
used to be solving in computer science are not really human complex problems, being problems

00:02:07,880 --> 00:02:13,000
that really require a human to solve, usually things that can be solved with just maths

00:02:13,000 --> 00:02:19,200
or just data analysis, but cognitive computing aims to be able to solve problems that otherwise

00:02:19,200 --> 00:02:20,790
we wouldn't be able to do.

00:02:20,790 --> 00:02:24,680
It does this by using machine learning and artificial intelligence.

00:02:24,680 --> 00:02:29,770
So not a single path towards a cynical solution, but rather, single solution, but rather a

00:02:29,770 --> 00:02:34,540
problem is tick solution to problems.

00:02:34,540 --> 00:02:40,400
It's a very different way to thinking about computing than we are normally used to it.

00:02:40,400 --> 00:02:48,410
It works with human natural input and output, so think instead of putting in numbers and

00:02:48,410 --> 00:02:54,150
getting numbers back or putting in key word searches, think rather putting in long form

00:02:54,150 --> 00:02:59,540
text, like whole webpages and being able to answer questions on whole webpages without

00:02:59,540 --> 00:03:04,950
converting it into anything, or speaking into them computing and getting things back, or

00:03:04,950 --> 00:03:12,190
having the computer understand audio, video or images and being able to output audio,

00:03:12,190 --> 00:03:16,140
video ipages, other forms of long form text.

00:03:16,140 --> 00:03:19,910
This is the type of problem solving and the type of solutions we can do with cognitive

00:03:19,910 --> 00:03:25,170
computing it's why it's the new type of computing and problem solving, I think it's really cool

00:03:25,170 --> 00:03:30,790
and lends itself to new types of applications.

00:03:30,790 --> 00:03:41,489
Yah, what does that mean, I bet you have all used a cognitive application, if not today,

00:03:41,489 --> 00:03:42,569
recently.

00:03:42,569 --> 00:03:53,750
Who here has used Google Now, or Siri, they are all cognitive applications, they are called

00:03:53,750 --> 00:03:59,510
the personal assistant, it's one of the patterns that we find at Watson that people use all

00:03:59,510 --> 00:04:01,050
the time.

00:04:01,050 --> 00:04:04,670
Let's breakdown what that personal assistant cognitive application is.

00:04:04,670 --> 00:04:10,150
It's speech in, speech gets transformed into text.

00:04:10,150 --> 00:04:16,940
That text is then run through usually what we call a natural language classifier to figure

00:04:16,940 --> 00:04:19,769
out what the subject of the

00:04:19,769 --> 00:04:25,120
sentence is or the subject of the text is pool out the individual pieces, then runs

00:04:25,120 --> 00:04:29,600
the business logic underneath it to figure out if you are talking about the weather and

00:04:29,600 --> 00:04:36,130
you have your location, what is go and find the weather application, then runs a Speech-to-Text

00:04:36,130 --> 00:04:40,190
to transform that into synthesized speech and tells you what it is, or if you are doing

00:04:40,190 --> 00:04:46,610
a Google search or web search it will go and find what that is and possibly pull back here

00:04:46,610 --> 00:04:52,800
are the results for you, or look in alpha and pull out the individual pieces, these

00:04:52,800 --> 00:04:57,730
are all different types of speech input and then business logic and output.

00:04:57,730 --> 00:05:02,560
So not everything inside of a cognitive application needs to be cognitive or fit the cognitive

00:05:02,560 --> 00:05:09,041
paradigm the application as a whole becomes cognitive when we provide it, when we use

00:05:09,041 --> 00:05:14,020
these types of cognitive input and output to work with it.

00:05:14,020 --> 00:05:17,380
That's what I want - yeah.

00:05:17,380 --> 00:05:21,780
So... let's talk about, let's see what some of these examples are.

00:05:21,780 --> 00:05:22,970
Let's play a little bit.

00:05:22,970 --> 00:05:27,140
I like pepper dancing, pepper is fun.

00:05:27,140 --> 00:05:33,220
So, the first application that we're going to talk about is this little thing that I

00:05:33,220 --> 00:05:39,630
built, a little tiny Chrome extension, using Watson's text analysis tool.

00:05:39,630 --> 00:05:46,700
What it does, it's a Chrome extension for Github, whereas you are typing it analyses

00:05:46,700 --> 00:05:52,220
the speech that you, the actual long form text you are writing in the comment box if

00:05:52,220 --> 00:05:56,970
it finds the text is negative, if the content of your text is negative, it switches the

00:05:56,970 --> 00:06:05,170
comment submit button from green to red, if it becomes angry it disables the comment button,

00:06:05,170 --> 00:06:06,650
right!

00:06:06,650 --> 00:06:10,470
That's pretty fun!

00:06:10,470 --> 00:06:13,720
{Applause}.

00:06:13,720 --> 00:06:18,410
So it's also about this, one of the reasons why I'm talking to you about this, even though

00:06:18,410 --> 00:06:23,500
you might be able, you might not think well this is probably really super expensive and

00:06:23,500 --> 00:06:28,870
probably something that I get access to because I'm Watson, this is built with a single publicly

00:06:28,870 --> 00:06:34,190
available API that you can go and use right now.

00:06:34,190 --> 00:06:39,700
Watson isn't the only group doing this, we happen to have a whole lot of cognitive APIs

00:06:39,700 --> 00:06:46,030
that you can use right now by searching the Watson developer cloud, this is one called

00:06:46,030 --> 00:06:53,190
tone analyser, what winds up happening here, as you type on key up, the Chrome extension

00:06:53,190 --> 00:07:00,960
sends all of your text off to a little tiny server I made, that runs through tone analyser,

00:07:00,960 --> 00:07:09,360
comes back and tone analyser splits your text into one of three different tones, happy,

00:07:09,360 --> 00:07:12,220
negative or angry.

00:07:12,220 --> 00:07:18,780
If negative is one or above, I tell you that you probably shouldn't send that and if angry

00:07:18,780 --> 00:07:21,430
is one or above I disable it.

00:07:21,430 --> 00:07:25,509
Usually you are angry and negative, but you can be negative without being angry, that's

00:07:25,509 --> 00:07:27,700
why it's kind of that three layer thing.

00:07:27,700 --> 00:07:33,470
So this is the first type of cognitive application you can build.

00:07:33,470 --> 00:07:37,200
The second one gets a little bit more complex.

00:07:37,200 --> 00:07:46,741
So, this is something I wrote called 'Babel Fish', those of you that don't know, it's

00:07:46,741 --> 00:07:51,990
the weirdest thing in the universe, you put it in your ear and it translates all speech

00:07:51,990 --> 00:08:00,250
into other speech, it's from hitchhikers guide to the galaxy, Watson as three, Speech-to-Text,

00:08:00,250 --> 00:08:07,680
language translation API and text to speech API, when it's combined you can create a Babel

00:08:07,680 --> 00:08:19,540
fish, I will use media to get text input, it will run through the Speech-to-Text algorithm,

00:08:19,540 --> 00:08:26,210
it is then going to translate that text using text or language translation, then going to

00:08:26,210 --> 00:08:28,130
spit it out in that native language.

00:08:28,130 --> 00:08:31,230
Unfortunate German isn't supported, but French is.

00:08:31,230 --> 00:08:38,680
What I'm going to do is say English and go to go to French, I'm going to do it not on

00:08:38,680 --> 00:08:39,680
my speaker

00:08:39,680 --> 00:08:54,010
notes... hello JSConf.

00:08:54,010 --> 00:08:57,959
Live demos are always fun!

00:08:57,959 --> 00:09:07,310
{Laughter} {French} close...!

00:09:07,310 --> 00:09:10,430
{Laughter}.

00:09:10,430 --> 00:09:13,550
{Applause}.

00:09:13,550 --> 00:09:19,629
I guess JSConf isn't something that Speech-to-Text understands, so let's try something else.

00:09:19,629 --> 00:09:43,139
'The breakfast this morning was fantastic'... {French} that's a little bit better I think.

00:09:43,139 --> 00:09:49,550
What do the APIs look like under the hood, is the way that - what you get back from Speech-to-Text

00:09:49,550 --> 00:09:51,600
is you get a confidence meter.

00:09:51,600 --> 00:09:58,120
This is where cognitive applications sort of differ from normal APIs that you may wind

00:09:58,120 --> 00:09:59,720
up working with.

00:09:59,720 --> 00:10:08,459
Speech-to-Text is a little bit iffy it's working of probability, not confidence, you get the

00:10:08,459 --> 00:10:16,500
translated text but you also get a confidence meter from 0 - 1, 0 to 100% basically.

00:10:16,500 --> 00:10:19,140
That is going to tell you how confident it is in your results.

00:10:19,140 --> 00:10:24,720
The first one not so confident, this is pretty confident, this is more or less spot on.

00:10:24,720 --> 00:10:28,230
Then language translation does a one-to-one translation.

00:10:28,230 --> 00:10:34,300
Translation happened between different domains, you could have - right now there is a news

00:10:34,300 --> 00:10:39,949
domain and a medical and a travel domain, but one of the great things about this is

00:10:39,949 --> 00:10:45,720
because cognitive computing is based off of artificial intelligence and machine learning,

00:10:45,720 --> 00:10:51,689
you can learn, you can train it, you can have it understand your specific domain, if you

00:10:51,689 --> 00:10:57,529
wanted to create, let's say a food application, you could train these APIs, you can train

00:10:57,529 --> 00:11:01,019
cognitive systems to understand the domain of food.

00:11:01,019 --> 00:11:09,680
So you don't have to know, necessarily, what a croissant is in English or French, you don't

00:11:09,680 --> 00:11:15,480
have to know what the words are, but you are able to translate them by training the applications

00:11:15,480 --> 00:11:20,350
with APIs I'm using a standard news domain.

00:11:20,350 --> 00:11:27,439
Text to speech synth sizes text in one of a variety of different languages, that just

00:11:27,439 --> 00:11:33,829
takes what ever text and goes straight off, so it's cognitive input, human natural input,

00:11:33,829 --> 00:11:38,770
with language translation which is trainable to understand the different domains you are

00:11:38,770 --> 00:11:49,689
working in, then text to speech, a human understandable output, it makes a new way of working and

00:11:49,689 --> 00:11:58,790
interacting with your user, there are only really three APIs being used here.

00:11:58,790 --> 00:12:08,230
The final bit that we have is a little bit more fun, it's cognitive computing.

00:12:08,230 --> 00:12:14,950
So, the first example that we showed is something that you can build today with a single API,

00:12:14,950 --> 00:12:23,699
it's a simple example of what cognitive computing can be, one API, one natural language text

00:12:23,699 --> 00:12:27,540
input, goes off to server, comes back, you do stuff.

00:12:27,540 --> 00:12:34,480
The second one a little bit more complex, three APIs being used, one turns speech into

00:12:34,480 --> 00:12:38,230
text, then it does stuff in the back ground and gives you speech out.

00:12:38,230 --> 00:12:43,309
Be able to hold full conversations with other people that you otherwise couldn't.

00:12:43,309 --> 00:12:48,189
That's also available as three public APIs, this a little bit future state, it's available

00:12:48,189 --> 00:12:56,449
now, just not as APIs, Watson is built on what we call Watson Discovery Advisor, it's

00:12:56,449 --> 00:13:01,970
a system for understanding connections and being able to find connections between things

00:13:01,970 --> 00:13:07,569
you wouldn't otherwise be able to see, in this case food.

00:13:07,569 --> 00:13:16,009
So what we have done here, we have ingested all of the recipes that bon appetite magazine

00:13:16,009 --> 00:13:17,939
has written.

00:13:17,939 --> 00:13:29,410
We have ingested all of thinkers, like artificial intelligence, machine learning and deep learning,

00:13:29,410 --> 00:13:37,139
kind of do its thing on them, what you get out of this, you get food pairings or recipes

00:13:37,139 --> 00:13:41,600
you wouldn't otherwise know or be able to see.

00:13:41,600 --> 00:13:47,579
So one example of this, when we talk about food and we talk about cooking, normally the

00:13:47,579 --> 00:13:54,269
food and the recipes that we have, those ingredients go together {sirens outside}, I guess the

00:13:54,269 --> 00:13:56,269
police don't like me talking about food!

00:13:56,269 --> 00:14:01,199
{Laughter} So food and recipes they generally go together and the ingredients in recipes

00:14:01,199 --> 00:14:03,819
generally go together because they grow together.

00:14:03,819 --> 00:14:06,790
They come from the same region of the world

00:14:06,790 --> 00:14:14,670
but things like apples and olives don't grow in the same place but it turns out that when

00:14:14,670 --> 00:14:20,269
you look at the types of recipes they are used in and their chemical compounds and how

00:14:20,269 --> 00:14:24,819
other things relate to those 2 ingredients, apples and olives turn out to pair really

00:14:24,819 --> 00:14:28,309
well together, even though it's something you would never think to pair together because

00:14:28,309 --> 00:14:30,339
they don't grow together.

00:14:30,339 --> 00:14:35,509
What cognitive computing and what Chef Watson is able to do is able to find these underlying

00:14:35,509 --> 00:14:36,509
connections.

00:14:36,509 --> 00:14:42,810
It also have applications in other things, think law enforcement, we have this demo where

00:14:42,810 --> 00:14:49,240
we ingested all of Wikipedia, and you ask it questions about Wikipedia like what are

00:14:49,240 --> 00:14:52,839
the planets in the solar system it's able to actual what all the planets are with all

00:14:52,839 --> 00:14:54,889
the evidence and all the confidence.

00:14:54,889 --> 00:15:00,230
You can actually trace back all the evidence and all the different pieces that connect

00:15:00,230 --> 00:15:05,230
together this is how cognitive computing is a bit different than normal key word search

00:15:05,230 --> 00:15:08,790
you can actually see the full evidence tree of how got somewhere.

00:15:08,790 --> 00:15:13,660
Let's build a recipe.

00:15:13,660 --> 00:15:17,209
Chef Watson, starts with ingredients.

00:15:17,209 --> 00:15:22,410
Someone yell out an ingredient.

00:15:22,410 --> 00:15:24,740
Bacon!

00:15:24,740 --> 00:15:27,070
Bacon.

00:15:27,070 --> 00:15:32,230
It starts to think, we know it has bacon, it makes some suggestions for us of other

00:15:32,230 --> 00:15:39,839
types of ingredients that are known to pair well with bacon, smoked turkey, some navy

00:15:39,839 --> 00:15:44,100
beans.

00:15:44,100 --> 00:15:50,569
Soy sauce.

00:15:50,569 --> 00:15:56,520
Dark soy sauce, dark soy sauce.

00:15:56,520 --> 00:15:57,520
Undefined dumplings.

00:15:57,520 --> 00:15:58,520
Yes!

00:15:58,520 --> 00:16:10,529
{applause} {laughter} I think chef has decided to pair Bacon with

00:16:10,529 --> 00:16:13,579
more Bacon.

00:16:13,579 --> 00:16:22,839
{laughter} {applause} anyway, so cognitive computing and specifically chef Watson it

00:16:22,839 --> 00:16:28,309
goes beyond just ingredients we can talk about dishes and styles as well.

00:16:28,309 --> 00:16:31,940
So let's choose a dish.

00:16:31,940 --> 00:16:38,620
Let us do a bacon and soy sauce bloody Mary.

00:16:38,620 --> 00:16:46,369
How about a Caesar salad?

00:16:46,369 --> 00:16:53,380
Get rid of the bloody Mary.

00:16:53,380 --> 00:17:02,279
Maybe it won't do a dish or a style, back to school.

00:17:02,279 --> 00:17:09,380
{laughter} there we go, so back to school bacon dumplings.

00:17:09,380 --> 00:17:19,390
{laughter} if we load this up, we wind up seeing is we wind up getting a brand new recipe

00:17:19,390 --> 00:17:22,459
that has never existed before.

00:17:22,459 --> 00:17:29,530
So chef Watson didn't go do a search on the internet to find back to school bacon dumplings,

00:17:29,530 --> 00:17:36,210
what it's done it's used the that training of all the recipes and used the training of

00:17:36,210 --> 00:17:43,450
all the different ingredients and the chemical compounds of all the ingredients to build

00:17:43,450 --> 00:17:49,680
a new recipe for you a new human output recipe for you based on other thing that, but this

00:17:49,680 --> 00:17:52,050
has never existed before.

00:17:52,050 --> 00:17:59,420
This is kind of, to me the power of cognitive computing it's being able to not replace humans,

00:17:59,420 --> 00:18:05,870
but empower humans to find connections and be able to interact with computers in ways

00:18:05,870 --> 00:18:08,480
that they would never have been able to interact with before.

00:18:08,480 --> 00:18:12,630
In ways you wouldn't have been able to see or use before.

00:18:12,630 --> 00:18:16,920
The best part about this for me anyway, I am a little bit biased because I work for

00:18:16,920 --> 00:18:22,260
Watson but all of these APIs that we have are for free, Chef Watson you can go play

00:18:22,260 --> 00:18:25,360
with right now, and we're not the only company

00:18:25,360 --> 00:18:26,360
doing it.

00:18:26,360 --> 00:18:28,380
Which is awesome.

00:18:28,380 --> 00:18:33,820
Artificial intelligence, deep learning the foundation of cognitive computing has got

00:18:33,820 --> 00:18:42,530
too point where it's coming out of research for the first time ever the APIs the ability

00:18:42,530 --> 00:18:51,270
to dive deep into our data beyond what we think of as deep data, beyond deep understandable

00:18:51,270 --> 00:18:56,400
content is something that is available for everyone to start using and everyone to go

00:18:56,400 --> 00:18:58,960
play with now.

00:18:58,960 --> 00:19:08,140
Which to me, means a big win for the future of applications and the future of our work

00:19:08,140 --> 00:19:14,000
and I have I would have been better had it worked the first time, yes.

00:19:14,000 --> 00:19:18,280
To me that means it's a big win for us, it means it's a big win for users, like we said

00:19:18,280 --> 00:19:23,860
I am part of the design team I am an engineer, a UI architect on the design team at Watson.

00:19:23,860 --> 00:19:32,310
To me what this provides is away for us to design the next generation of applications.

00:19:32,310 --> 00:19:36,140
Screw your JavaScript frameworks, use whatever one you want.

00:19:36,140 --> 00:19:40,310
To me that's not what matters I appreciate I am a JavaScript conference I just gave an

00:19:40,310 --> 00:19:45,080
entire talk not talking about JavaScript, but this is what is important.

00:19:45,080 --> 00:19:51,310
Our users are important, cognitive computing and cognitive applications will provide us

00:19:51,310 --> 00:19:57,070
with the means of producing the next great user experience, not react not angular, not

00:19:57,070 --> 00:20:04,490
ES6, they are tools to build them but cognitive computing is what will let us actually create

00:20:04,490 --> 00:20:08,940
them thank you.

00:20:08,940 --> 00:20:21,400
{applause} Ok can I have the slides back again?

00:20:21,400 --> 00:20:28,440
Those are the links, the link to slide deck, links to all of the source code for the first

00:20:28,440 --> 00:20:35,490
2 applications are available online, I am snugug that's my website, that's Twitter,

00:20:35,490 --> 00:20:36,910
that's the slide deck again.

00:20:36,910 --> 00:20:39,880
All the links to everything are available online including all the source code for all

00:20:39,880 --> 00:20:42,920
the applications.

00:20:42,920 --> 00:20:47,820
Thank you.

00:20:47,820 --> 00:20:50,280

YouTube URL: https://www.youtube.com/watch?v=pKtG4dO-9Tw


