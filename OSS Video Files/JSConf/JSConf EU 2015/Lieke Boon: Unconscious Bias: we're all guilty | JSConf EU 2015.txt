Title: Lieke Boon: Unconscious Bias: we're all guilty | JSConf EU 2015
Publication date: 2015-10-12
Playlist: JSConf EU 2015
Description: 
	We probably all know that diverse teams are effective teams. Teams with more gender diversity have been proven to be more creative, productive, innovative. Nevertheless, the technology industry, has been showing a recent and steady decline regarding women who find and pursue degrees in what should be a growing pool of opportunity. In this talk we’ll examine the reasons behind the gender­gap in IT by going on a small trip and we’ll figure out what we can do to make our community better in only a couple days!

Intro music by @halfbyte
Captions: 
	00:00:24,150 --> 00:00:25,550
Thank you everyone.

00:00:25,550 --> 00:00:30,730
I'm glad you are still here and have some energy left for the last two talks.

00:00:30,730 --> 00:00:35,280
I'm starting this slide empty because I want to

00:00:35,280 --> 00:00:36,960
ask you something first.

00:00:36,960 --> 00:00:42,540
The next slide will have a riddle on it, and I want to ask you if you already know

00:00:42,540 --> 00:00:46,620
this one, please don't shout the answer out loud, just

00:00:46,620 --> 00:00:50,510
let everyone try and figure this out by themselves.

00:00:50,510 --> 00:00:53,690
So be quiet.

00:00:53,690 --> 00:00:55,940
It is a bit depressing, but I hope you can read

00:00:55,940 --> 00:00:56,940
it.

00:00:56,940 --> 00:00:59,510
A father and his son are in a car accident, the

00:00:59,510 --> 00:01:03,269
father dies at the scene and the son, badly injured, is

00:01:03,269 --> 00:01:04,650
rushed to the hospital.

00:01:04,650 --> 00:01:08,480
In the operating room the surgeon looks at the boy and says, "I can't

00:01:08,480 --> 00:01:09,670
operate on this boy.

00:01:09,670 --> 00:01:10,670
He is my son."

00:01:10,670 --> 00:01:16,170
Just read it and I'll give you ten seconds.

00:01:16,170 --> 00:01:19,250
I'm not giving you the answer.

00:01:19,250 --> 00:01:23,040
Oh, you're super quiet.

00:01:23,040 --> 00:01:27,370
That's nice.

00:01:27,370 --> 00:01:32,040
My name is Lieke, I'm from Amsterdam and I notice

00:01:32,040 --> 00:01:35,011
there are a lot of cat pictures at this conference, so

00:01:35,011 --> 00:01:40,650
I added one a black cat cycling through Amsterdam on an

00:01:40,650 --> 00:01:42,380
orange bike with tulips.

00:01:42,380 --> 00:01:46,830
What more do you want?

00:01:46,830 --> 00:01:53,380
You probably know me, maybe not, maybe not.

00:01:53,380 --> 00:01:56,490
I'm involved in the real skills summer of code,

00:01:56,490 --> 00:01:59,560
also a Dutch ambassador for the code week, if you don't

00:01:59,560 --> 00:02:02,110
know, Google it and participate, because it is awesome.

00:02:02,110 --> 00:02:06,740
I have my own website called codepancake.com, where

00:02:06,740 --> 00:02:11,110
you can find a lot of resources on coding and I'm proud

00:02:11,110 --> 00:02:15,730
of the spotlight series, there are a lot of amazing

00:02:15,730 --> 00:02:19,170
interviews.

00:02:19,170 --> 00:02:23,560
I work at an organisation on girls and women in

00:02:23,560 --> 00:02:25,590
science and technology.

00:02:25,590 --> 00:02:29,500
Our mission is to involve the increasing of girls and women in science,

00:02:29,500 --> 00:02:32,470
mathematics, engineering and IT.

00:02:32,470 --> 00:02:38,439
We do research but also organise activities throughout the education chain,

00:02:38,439 --> 00:02:41,810
so primary, secondary and higher education.

00:02:41,810 --> 00:02:43,799
You can see four role models.

00:02:43,799 --> 00:02:51,790
We have a large database with over 2,000 female IT professionals and students, and I think

00:02:51,790 --> 00:02:54,040
that is amazing because we can always count on them

00:02:54,040 --> 00:02:55,379
if we have activities.

00:02:55,379 --> 00:02:58,659
But the question is, why are we doing this?

00:02:58,659 --> 00:03:00,450
Why do we need more women in tech?

00:03:00,450 --> 00:03:04,269
Well I think Brenna already mentioned it a bit, but diversity.

00:03:04,269 --> 00:03:08,019
Things in more general in diversity have proved to be

00:03:08,019 --> 00:03:11,079
more innovative and creative and effective in teams.

00:03:11,079 --> 00:03:14,909
If you're interested in this project, go online,

00:03:14,909 --> 00:03:17,760
there are lots of resources online.

00:03:17,760 --> 00:03:24,499
And another thing, the lack of women entering the tech field is also a

00:03:24,499 --> 00:03:27,639
loss of talent with the IT industry, and a loss of

00:03:27,639 --> 00:03:30,389
opportunity for the women and entering the job market.

00:03:30,389 --> 00:03:36,510
So a lot of talent is wasted, actually.

00:03:36,510 --> 00:03:40,971
Girls and females are underrepresented in tech, if

00:03:40,971 --> 00:03:43,709
you compare them to the male counterparts, and in the

00:03:43,709 --> 00:03:46,090
Netherlands it is somewhat exceptional because we are

00:03:46,090 --> 00:03:50,170
last, actually Tunisia is below us, and then the

00:03:50,170 --> 00:03:51,170
Netherlands.

00:03:51,170 --> 00:03:56,230
Less than 10 per cent of the females are working in IT and in the Netherlands, and

00:03:56,230 --> 00:04:00,959
you can see Germany is below average for the 35, and we

00:04:00,959 --> 00:04:04,150
have 23 per cent, and the rest of the European

00:04:04,150 --> 00:04:07,400
Union is 37.

00:04:07,400 --> 00:04:08,400
So why is this?

00:04:08,400 --> 00:04:12,139
Well, the choice for science and technology by Dutch girls is far below the

00:04:12,139 --> 00:04:13,790
average, like I said.

00:04:13,790 --> 00:04:18,109
Well, it is true that brains of boys and girls are not the same.

00:04:18,109 --> 00:04:24,610
But these differences is not the reason why there are many more boys choosing

00:04:24,610 --> 00:04:27,900
a career in tech, because both of the brains are full

00:04:27,900 --> 00:04:30,690
with potential, but to what extent, the potential

00:04:30,690 --> 00:04:35,270
is for fields and which is highly dependent on stimulation

00:04:35,270 --> 00:04:37,690
that parents and teachers offer.

00:04:37,690 --> 00:04:42,669
Next is also that girls think they perform worse

00:04:42,669 --> 00:04:45,800
than they actually do in STEM related subjects.

00:04:45,800 --> 00:04:48,479
I'm not sure what your grading system is, but in the

00:04:48,479 --> 00:04:52,770
Netherlands it is from one to ten, but if you have a 5.5

00:04:52,770 --> 00:04:55,360
then you've passed your exams.

00:04:55,360 --> 00:05:00,050
We always ask students if they think they're good in mathematics, and boys normally

00:05:00,050 --> 00:05:02,590
raise their hands if they have a six, because it's

00:05:02,590 --> 00:05:05,090
good they passed our test, right?

00:05:05,090 --> 00:05:08,680
And girls are more like: no, I should have eight or nine.

00:05:08,680 --> 00:05:12,590
So they're too hard on themselves and it is not necessary at all.

00:05:12,590 --> 00:05:15,770
Secondly, environment, like I said, girls are less

00:05:15,770 --> 00:05:19,330
stimulated by teachers and parents to choose a career in

00:05:19,330 --> 00:05:22,540
IT, and this is a cartoon, I don't think you can read it

00:05:22,540 --> 00:05:26,759
but it is a teacher, and he says: "Well, your child is

00:05:26,759 --> 00:05:30,360
has very good grades in maths and science, but she's

00:05:30,360 --> 00:05:31,360
a girl."

00:05:31,360 --> 00:05:35,199
And then the parents reply "Oh shit, that's too bad."

00:05:35,199 --> 00:05:39,130
So that's not an option to consider a career in IT.

00:05:39,130 --> 00:05:41,980
Last but not least, there's unfamiliarity.

00:05:41,980 --> 00:05:45,740
Girls have no good image of STEM medications and professions

00:05:45,740 --> 00:05:49,470
and there's a huge lack of role models.

00:05:49,470 --> 00:05:53,699
So I just want to conclude this with a quote, it is from unlocking

00:05:53,699 --> 00:05:57,110
in the clubhouse, very early in life computing is

00:05:57,110 --> 00:06:00,490
claimed as male territory at each sustainable early childhood

00:06:00,490 --> 00:06:03,770
through college, computing is both claimed as guy stuff

00:06:03,770 --> 00:06:08,210
by boys and men and passively ceded by girls and women.

00:06:08,210 --> 00:06:10,340
Question observation shows that disinterest and

00:06:10,340 --> 00:06:13,259
dissatisfaction are neither genetic nor accidental, nor

00:06:13,259 --> 00:06:17,750
inherent to the field, but are the bitter fruit of

00:06:17,750 --> 00:06:19,990
external influences.

00:06:19,990 --> 00:06:22,490
This is important because if you think there are

00:06:22,490 --> 00:06:25,720
less girls in IT because of disinterest, then you're

00:06:25,720 --> 00:06:28,439
wrong.

00:06:28,439 --> 00:06:32,139
One of the external interests is unconscious bias.

00:06:32,139 --> 00:06:36,389
Evolution has taught us to mathematically process

00:06:36,389 --> 00:06:39,220
information without critical thinking, so we're

00:06:39,220 --> 00:06:41,990
constantly overlooking much of the world around us and

00:06:41,990 --> 00:06:44,220
there's actually nothing serious about this.

00:06:44,220 --> 00:06:47,969
We receive 11 million bits of information every day,

00:06:47,969 --> 00:06:52,139
and we can only consciously process 40 bits.

00:06:52,139 --> 00:06:55,790
The conclusion is stuff gets broken while our brain is storing

00:06:55,790 --> 00:06:59,180
information, and our objectives are certainly clouded

00:06:59,180 --> 00:07:02,129
because our brain is taking shortcuts and relies on our

00:07:02,129 --> 00:07:04,349
earlier assumptions.

00:07:04,349 --> 00:07:09,300
So even a tiny bit of bias can have big consequences, for example, these

00:07:09,300 --> 00:07:14,240
biases can prevent introduction of diversity into workplaces.

00:07:14,240 --> 00:07:16,240
I think this is a great example.

00:07:16,240 --> 00:07:18,199
Blind auditions.

00:07:18,199 --> 00:07:21,050
I just add another picture of a cat behind the curtain,

00:07:21,050 --> 00:07:24,550
because that's the way it is supposed to be.

00:07:24,550 --> 00:07:25,550
Laughter].

00:07:25,550 --> 00:07:29,700
Well, it is a research from Princeton, and they

00:07:29,700 --> 00:07:32,759
found other that since the 1970s the number of women in

00:07:32,759 --> 00:07:37,419
orchestras went up from five to 25 per cent, and due to

00:07:37,419 --> 00:07:40,509
the fact that they asked them to audition behind the

00:07:40,509 --> 00:07:43,789
screen or curtain so they couldn't see if it was a male

00:07:43,789 --> 00:07:45,060
or female.

00:07:45,060 --> 00:07:50,819
So I think that is -- well, that's a lot of bias going on right there.

00:07:50,819 --> 00:07:53,770
Well, most people would agree that gender bias

00:07:53,770 --> 00:07:56,349
exists in others.

00:07:56,349 --> 00:07:58,800
All of us, myself included, are biased.

00:07:58,800 --> 00:08:02,499
So you should take a look around, I think you

00:08:02,499 --> 00:08:04,330
know the cartoon, maybe.

00:08:04,330 --> 00:08:09,409
A guy says, "Well you suck at math" and then a girl has to answer wrong,

00:08:09,409 --> 00:08:13,199
and it's like Girls suck at math."

00:08:13,199 --> 00:08:15,420
If you're curious about your own biases, you can

00:08:15,420 --> 00:08:18,659
take the implicit associations test, it is called

00:08:18,659 --> 00:08:22,350
project implicit from Harvard University, and it

00:08:22,350 --> 00:08:25,620
measures actually how quickly words like math and

00:08:25,620 --> 00:08:29,060
physics are associated with boys or men, you can also

00:08:29,060 --> 00:08:33,940
take this test with a career and family, but this is

00:08:33,940 --> 00:08:37,630
a gender science test, and I took it, and I have to be

00:08:37,630 --> 00:08:41,130
honest, I worked in IT, I've been a developer, and these

00:08:41,130 --> 00:08:43,290
were my results.

00:08:43,290 --> 00:08:47,720
So it says "Your data suggests a strong automatic association of male with

00:08:47,720 --> 00:08:50,810
science, and female with liberal arts."

00:08:50,810 --> 00:08:58,260
So yeah, I just added that, because it's also something you should do, and I felt terrible

00:08:58,260 --> 00:09:01,600
because I work in IT and I should have known better,

00:09:01,600 --> 00:09:02,600
right?

00:09:02,600 --> 00:09:05,820
So this is something I should take home.

00:09:05,820 --> 00:09:07,910
Now it gets me back to the riddle.

00:09:07,910 --> 00:09:11,500
I think you know the answer by now, probably, I hope.

00:09:11,500 --> 00:09:14,030
So who is the surgeon?

00:09:14,030 --> 00:09:15,030
You can shout.

00:09:15,030 --> 00:09:16,790
Yeah, the mother.

00:09:16,790 --> 00:09:17,790
It is true.

00:09:17,790 --> 00:09:21,390
Actually, two days ago I learned that in German "surgeon"

00:09:21,390 --> 00:09:25,750
is a female word, so it could be that most of you already

00:09:25,750 --> 00:09:27,230
know the answer right away.

00:09:27,230 --> 00:09:30,930
I don't know, but in English and Dutch it is different.

00:09:30,930 --> 00:09:36,250
In 80 per cent of the time, it is when we ask or tell people about this riddle,

00:09:36,250 --> 00:09:37,250
they don't know the answer.

00:09:37,250 --> 00:09:42,890
Or they are more likely to think that it is a gay couple, or that the father

00:09:42,890 --> 00:09:46,190
is a step father, or that they magically live again,

00:09:46,190 --> 00:09:48,630
but nobody thinks it is the mother.

00:09:48,630 --> 00:09:50,020
This is true.

00:09:50,020 --> 00:09:53,140
I have to admit, I had it wrong the first time.

00:09:53,140 --> 00:09:55,520
So don't feel bad about it.

00:09:55,520 --> 00:10:01,140
Don't feel bad about being biased, because it is just the -- because

00:10:01,140 --> 00:10:04,720
of our culture that we're biased.

00:10:04,720 --> 00:10:09,590
So, notice not about football.

00:10:09,590 --> 00:10:16,570
But yeah, when it comes to implicit and explicit associations,

00:10:16,570 --> 00:10:20,210
the Netherlands are highest in gender stereotyping

00:10:20,210 --> 00:10:23,260
because a lot of -- I think a couple million people

00:10:23,260 --> 00:10:26,020
took the test, and you could fill in your country and

00:10:26,020 --> 00:10:28,320
these were the results, and I think that is shocking

00:10:28,320 --> 00:10:31,270
because I always think of the Netherlands as modern

00:10:31,270 --> 00:10:37,290
and open minded, and well, it turns out it is quite

00:10:37,290 --> 00:10:39,960
-- we are quite old-fashioned when it comes to gender

00:10:39,960 --> 00:10:41,910
stereotyping.

00:10:41,910 --> 00:10:48,340
So I was shocked, and I decide to take a look around, and I notice some things.

00:10:48,340 --> 00:10:51,530
I think you all know the girl and boy department at toy

00:10:51,530 --> 00:10:52,630
stores, yeah.

00:10:52,630 --> 00:11:00,470
Well on the left it is pink, it is advertisement for girls, so you learn a bit of Dutch now,

00:11:00,470 --> 00:11:05,780
and on the right it is boys, it's blue.

00:11:05,780 --> 00:11:10,080
This is actually for the girls, it is a dish washing set.

00:11:10,080 --> 00:11:13,730
I don't know why, it is a stupid gift anyway because nobody likes

00:11:13,730 --> 00:11:18,710
doing the dishes, right?

00:11:18,710 --> 00:11:21,830
But yeah.

00:11:21,830 --> 00:11:23,390
[applause].

00:11:23,390 --> 00:11:24,390
It is pink.

00:11:24,390 --> 00:11:27,890
It has a pink sink, it has a real working tap, it is like amazing.

00:11:27,890 --> 00:11:33,660
And on the right is for boys, it is a microscope, it has 23 parts,

00:11:33,660 --> 00:11:36,339
it has glasses, everything.

00:11:36,339 --> 00:11:40,390
So these are associations, and you come across them when you're already 3 years

00:11:40,390 --> 00:11:42,680
old or something.

00:11:42,680 --> 00:11:44,730
This is another one, that's also induction.

00:11:44,730 --> 00:11:46,390
It's from a children magazine.

00:11:46,390 --> 00:11:51,440
It is a test, and it defines who you are, and on the left, it is

00:11:51,440 --> 00:11:56,190
for boys of course, because it is blue, it says, "What

00:11:56,190 --> 00:11:57,190
are you?"

00:11:57,190 --> 00:12:00,010
Well, the results are: you are a tough guy, you are

00:12:00,010 --> 00:12:03,680
a smart guy, or you are a funny guy, and on the right it

00:12:03,680 --> 00:12:06,720
is pink, and it is for girls and it says, "You are

00:12:06,720 --> 00:12:10,070
a sweet girl", and the description is horrible.

00:12:10,070 --> 00:12:12,690
It says, "You think about others before you think

00:12:12,690 --> 00:12:13,790
about yourself.

00:12:13,790 --> 00:12:15,910
That's amazing."

00:12:15,910 --> 00:12:17,430
Okay.

00:12:17,430 --> 00:12:22,950
Second -- well, you're a sporty girl, and third you are [Dutch], which is non-translatable

00:12:22,950 --> 00:12:27,600
which means cosy, fun to be around.

00:12:27,600 --> 00:12:35,890
I think it is a bit like a German word, if I pronounce it right.

00:12:35,890 --> 00:12:37,340
Gizelle(?).

00:12:37,340 --> 00:12:38,800
Okay.

00:12:38,800 --> 00:12:40,250
Well.

00:12:40,250 --> 00:12:46,320
Anyway, I think this gender bias could be a major threat, and it is a major threat,

00:12:46,320 --> 00:12:49,330
because it is one of the key reasons why few girls study

00:12:49,330 --> 00:12:50,980
computer science.

00:12:50,980 --> 00:12:53,890
The good news is bias can be weakened.

00:12:53,890 --> 00:12:55,980
The bad news is you cannot do it alone.

00:12:55,980 --> 00:12:58,300
We should all do it together.

00:12:58,300 --> 00:13:01,050
So, what should we do first?

00:13:01,050 --> 00:13:05,440
Well, be aware that you're bias, because believe me, you are.

00:13:05,440 --> 00:13:09,620
Just take the test when you have time, and you learn about

00:13:09,620 --> 00:13:12,350
your biases and how you can address them.

00:13:12,350 --> 00:13:16,050
Second, I think it is important, use inclusive language.

00:13:16,050 --> 00:13:20,570
Because a couple weeks ago I was at a conference, a Dutch conference, and it was

00:13:20,570 --> 00:13:25,160
about the future programmer, and someone got to the

00:13:25,160 --> 00:13:27,940
stage and started talking about the future programmer

00:13:27,940 --> 00:13:32,930
and he said: well, he is this and he is that, and he should

00:13:32,930 --> 00:13:34,910
be this and he should be like that.

00:13:34,910 --> 00:13:36,720
And I felt offended, come on.

00:13:36,720 --> 00:13:40,510
I am obviously not a future programmer then.

00:13:40,510 --> 00:13:44,011
So I don't think he meant it that way, but it

00:13:44,011 --> 00:13:47,810
is good to be aware of what you're saying.

00:13:47,810 --> 00:13:51,970
I think this is from a social media platform and they removed the

00:13:51,970 --> 00:13:55,310
word hacker" from their job titles, and they noticed

00:13:55,310 --> 00:13:57,350
the change in who was applying.

00:13:57,350 --> 00:14:01,070
So they decided to write an article about it and how gender inclusive

00:14:01,070 --> 00:14:06,220
they were, they attached an e-mail they sent to the employees,

00:14:06,220 --> 00:14:09,200
and the e-mail started with "Hi guys".

00:14:09,200 --> 00:14:12,060
It is not very gender inclusive.

00:14:12,060 --> 00:14:17,810
So just for some people this is offending, so just be aware of what you're

00:14:17,810 --> 00:14:19,180
saying.

00:14:19,180 --> 00:14:22,350
Well, this is important.

00:14:22,350 --> 00:14:25,920
If you're male or female, doesn't matter, hold yourself and others accountable

00:14:25,920 --> 00:14:29,430
and point it out, because by the simple act of

00:14:29,430 --> 00:14:32,510
talking openly about behavioural patterns it makes

00:14:32,510 --> 00:14:36,040
the subconscious conscious, so talking transforms

00:14:36,040 --> 00:14:38,490
minds which transforms behaviour and communities,

00:14:38,490 --> 00:14:43,370
and which can result in a better environment, for example,

00:14:43,370 --> 00:14:44,370
women in tech.

00:14:44,370 --> 00:14:49,530
So we should all share this and talk about it.

00:14:49,530 --> 00:14:54,820
Last but not least, use your imagination.

00:14:54,820 --> 00:14:56,730
Counter-program your brain.

00:14:56,730 --> 00:15:00,680
I Googled for "programmer" and these were the results I got.

00:15:00,680 --> 00:15:05,040
I really like the right one, below it says, "Do not wake up

00:15:05,040 --> 00:15:07,440
a programmer, he is working, not sleeping."

00:15:07,440 --> 00:15:10,650
It is important, important lesson.

00:15:10,650 --> 00:15:15,320
But you can only see one female and there is a black guy and the rest of them

00:15:15,320 --> 00:15:16,880
are all white males.

00:15:16,880 --> 00:15:20,770
And I think you should be aware of the images you have in your head.

00:15:20,770 --> 00:15:25,450
If I ask you to picture an architect or programmer, I think most of the

00:15:25,450 --> 00:15:28,490
time it will be a white male with glasses or something

00:15:28,490 --> 00:15:29,490
like that.

00:15:29,490 --> 00:15:33,050
Just be aware this is not always true ... I think

00:15:33,050 --> 00:15:35,650
you probably all know this one.

00:15:35,650 --> 00:15:38,130
Hashtag I look like an engineer.

00:15:38,130 --> 00:15:42,710
I think this a great way of bias busting.

00:15:42,710 --> 00:15:48,500
It started with this girl, she works at 1 lodge

00:15:48,500 --> 00:15:53,110
Inn, and I don't know if I'm supposed to say that, but

00:15:53,110 --> 00:15:57,701
she was an advertising campaign for a company, and they

00:15:57,701 --> 00:16:00,500
were looking for developers, and then she got a

00:16:00,500 --> 00:16:03,350
lot of responses on her picture like "oh, I didn't

00:16:03,350 --> 00:16:04,760
know that you were an engineer.

00:16:04,760 --> 00:16:07,710
You don't look like an engineer" and so on.

00:16:07,710 --> 00:16:13,740
And she was a bit fed up and started the hashtag actually, and she asked everyone to

00:16:13,740 --> 00:16:14,850
spread the word.

00:16:14,850 --> 00:16:18,620
And I think these are all engineers, you should remember.

00:16:18,620 --> 00:16:25,240
This is some great bias busting, like I said, and it is a great way of breaking down gender

00:16:25,240 --> 00:16:27,230
stereotypes.

00:16:27,230 --> 00:16:33,480
So in short, be aware that you're bias.

00:16:33,480 --> 00:16:35,240
Use inclusive language.

00:16:35,240 --> 00:16:38,940
Hold yourself and others accountable and use your imagination.

00:16:38,940 --> 00:16:41,350
So counter programme your brain.

00:16:41,350 --> 00:16:46,770
I know we are at JSconf and it should be about coding and programming, but

00:16:46,770 --> 00:16:49,670
the thing is it is not about the programming, it is about

00:16:49,670 --> 00:16:52,750
the way you're programmed.

00:16:52,750 --> 00:16:56,760
I know it has been a challenging day today, but I'd like to ask you to take this

00:16:56,760 --> 00:17:01,201
home and to look past your initial perceptions, because

00:17:01,201 --> 00:17:03,570
I bet you they're probably wrong.

00:17:03,570 --> 00:17:04,570
So thank you.

00:17:04,570 --> 00:17:04,571

YouTube URL: https://www.youtube.com/watch?v=5mcyUUf20Ng


