Title: Building a high performance financial web application with JavaScript - JS Monthly - May 2021
Publication date: 2021-07-02
Playlist: JS Monthly London
Description: 
	@JSMonthlyLondon
Building a high performance financial web application with JavaScript
Pawel Badenski

A short summary of one team's journey to run a real-time financial calculation engine in the browser using JavaScript. Buffet 🍔 🍟 🥤 style (as in food, not Warren) presentation with something for everyone - React & Redux, V8 optimisations, monads and evolving simple design.

Pawel is a cofounder & CTO @ Pricing Monkey and has been a coder for nearly 15 years. Performance engineering has been one of his biggest passions in software. He got hooked many years ago when working on a Java-based airline scheduling system. Then he switched his focus to JavaScript and the world of browsers. One thing stays the same, as my former colleague said to me many years ago "Contrary to what many people think - performance engineering is hard."

Intro & About me [00:00:00]
Don't get distracted by other people problems [00:02:24] 
Javascript - Faster than you thought [00:11:10]
Pick your battles [00:20:49] 
Great performance starts with great design [00:23:09] 
Summary [00:29:09] 

_________________________________________________________________

About Pusher Sessions:

We're bringing the meetup to you. With Sessions, you can watch recordings of top-notch talks from developer meetups -- wherever and whenever you want.

Meetups are a great way to learn from our peers and to keep up with the latest trends and technologies. As developers ourselves, we at Pusher wanted to bring this great content to more people... So we built Sessions. On Sessions, you can watch talks that interest you and subscribe to be notified when new content gets added.

If you run a meetup and want to get involved, kindly get in touch.

_________________________________________________________________

About Pusher:

Pusher is a hosted service with APIs, developer tools and open source libraries that greatly simplify integrating real-time functionality into web and mobile applications. 

Pusher will automatically scale when required, removing all the pain of setting up and maintaining a secure, real-time infrastructure. 

Pusher is already trusted to do so by thousands of developers and companies like GitHub, MailChimp, the Financial Times, Buffer and many more. 

Getting started takes just a few seconds: simply go to pusher.com and create a free account. Happy hacking!
Captions: 
	00:00:01,660 --> 00:00:02,848
Yeah, thanks for having me here.

00:00:03,670 --> 00:00:04,870
My name is Paul Badesnki.

00:00:06,405 --> 00:00:11,980
And today I wanted to chat about building high-performance web application,

00:00:11,980 --> 00:00:14,680
specifically financial application with JavaScript, something that.

00:00:15,525 --> 00:00:18,615
We've been doing for the past over 10 sorry.

00:00:18,615 --> 00:00:19,935
Over 10, over four years.

00:00:23,435 --> 00:00:26,835
In our startup we started the journey actually four years

00:00:27,015 --> 00:00:28,005
more than four years ago.

00:00:28,366 --> 00:00:30,034
And yeah I've been going.

00:00:30,525 --> 00:00:31,695
I'm a CTO at pricing monkey.

00:00:31,695 --> 00:00:34,964
I'm not one of the co-founders I've been in since day zero.

00:00:35,655 --> 00:00:40,014
So this is going to be a journey of experience from, that journey.

00:00:40,935 --> 00:00:44,714
You can see my Twitter email you can reach me out on those channels.

00:00:44,714 --> 00:00:47,216
I'm also a mentor at me to mentor.

00:00:47,445 --> 00:00:51,555
If you haven't heard about it yet go ahead and check it out.

00:00:51,935 --> 00:00:55,044
It was a really cool and free community.

00:00:55,530 --> 00:00:58,320
I have nearly 15 years, of experience in building software.

00:00:58,620 --> 00:01:04,830
I come from Java background where I spent quite a bit of my my past.

00:01:04,830 --> 00:01:08,949
And I became a JavaScript developer five years ago.

00:01:09,390 --> 00:01:15,498
When when we started the business, we we're still going.

00:01:15,996 --> 00:01:17,789
Now I do love design.

00:01:19,960 --> 00:01:24,820
Software philosophy or like all the different programming

00:01:24,820 --> 00:01:26,530
languages and all sort of problems.

00:01:26,530 --> 00:01:28,660
But I do love performance engineering.

00:01:28,760 --> 00:01:31,900
My love of performance engineering started relatively early in my career.

00:01:31,900 --> 00:01:38,184
And since I it's really heavy now I think I, I kept being drawn to, so yeah,

00:01:38,184 --> 00:01:42,535
so this presentation is our journey in four points stopping to say is my

00:01:42,535 --> 00:01:46,975
self presentation is that I do tend to overwhelm people with information.

00:01:47,335 --> 00:01:50,304
So do take notes things that you find interesting.

00:01:50,634 --> 00:01:51,535
So do take notes.

00:01:51,535 --> 00:01:56,035
If you find something interesting and feel free to reach, out to

00:01:56,035 --> 00:01:59,425
me for from our retail story.

00:01:59,425 --> 00:02:03,565
If you want to hear more about any, -, I was I'm going to talk about.

00:02:05,175 --> 00:02:10,035
It's going to be a bit of, like I said in the on the meetup page, I was going

00:02:10,035 --> 00:02:13,035
to be a bit of a buffet of, information.

00:02:13,065 --> 00:02:14,114
I was trying to kind of cover.

00:02:15,210 --> 00:02:17,340
For people who are just beginning the journey and people

00:02:17,370 --> 00:02:18,570
who are quite experienced.

00:02:18,570 --> 00:02:19,680
So yeah.

00:02:19,770 --> 00:02:21,450
Get ready for a bit of a roller coaster.

00:02:21,540 --> 00:02:24,060
It's the first one don't get distracted by other people problems.

00:02:24,960 --> 00:02:27,930
This presentation included, I think it's quite relevant

00:02:27,930 --> 00:02:28,965
when you go to all sorts of...

00:02:31,200 --> 00:02:34,470
and that's certainly been a victim to all sort of conferences and presentations, you

00:02:34,470 --> 00:02:38,880
see, oh, the new cool thing and the new technology and you immediately jump into

00:02:38,880 --> 00:02:43,095
it and it's, actually not necessarily the.

00:02:43,851 --> 00:02:44,640
Solving the problem.

00:02:44,640 --> 00:02:48,720
You your project, your projects might want to be solving.

00:02:48,720 --> 00:02:51,480
Everybody has, their own problems and their own challenges.

00:02:51,480 --> 00:02:58,830
And the solutions might not work across, the different contexts.

00:02:59,399 --> 00:03:02,570
Now we are a specialized software as a service platform for financial analytics.

00:03:02,660 --> 00:03:03,810
And what that means is that.

00:03:06,929 --> 00:03:11,565
Our main JavaScript bundle is six megabytes and that's 1.5 megs

00:03:11,565 --> 00:03:16,545
compressed, and everybody will probably run away screaming at this point.

00:03:16,755 --> 00:03:17,745
We're not bothered at all.

00:03:18,135 --> 00:03:20,685
We failed a Google lighthouse tests.

00:03:21,495 --> 00:03:24,435
This screenshot here is from Google lighthouse, a tool that Google

00:03:24,435 --> 00:03:29,895
has in Chrome that can measure how well behaved your website is.

00:03:30,129 --> 00:03:32,265
We got nine out of nine out of hundred.

00:03:32,265 --> 00:03:35,145
First Contentful paint five seconds for some of you, this

00:03:35,145 --> 00:03:36,675
might be absolutely horrible.

00:03:36,675 --> 00:03:37,185
Horrific.

00:03:38,613 --> 00:03:45,795
Our customers go onto our we have a small number of high paying customers.

00:03:45,825 --> 00:03:50,625
They go on our platform and they open the page and they stay there for their

00:03:50,625 --> 00:03:52,385
day and maybe refreshing a few times.

00:03:53,130 --> 00:03:57,269
It's really doesn't matter that the page takes a little longer too, loud.

00:03:57,299 --> 00:04:02,600
So yeah, I know that 99% of the internet does or care about that.

00:04:03,000 --> 00:04:03,630
We don't.

00:04:04,051 --> 00:04:07,440
So a lot of information that we find about performance when we build performance

00:04:07,470 --> 00:04:11,655
website performance or things like that in Chrome, I actually find things that

00:04:12,779 --> 00:04:14,880
are not necessarily as interesting to us.

00:04:15,179 --> 00:04:15,420
Yeah.

00:04:15,450 --> 00:04:17,870
Majority of performance suggestions didn't apply to our project.

00:04:18,050 --> 00:04:22,250
So that screenshot you see here is about permit use client.

00:04:22,280 --> 00:04:23,420
We do use permit use.

00:04:24,080 --> 00:04:29,357
Interestingly actually we do report metrics from permit use to

00:04:29,960 --> 00:04:31,580
metrics from each of our users.

00:04:31,580 --> 00:04:34,940
We report to permit use to use I'll, say a bit more about that later.

00:04:35,210 --> 00:04:38,729
So we basically track every single customer instance.

00:04:38,960 --> 00:04:41,450
We treat it as a separate note because we do computation.

00:04:42,728 --> 00:04:44,370
Some competition on the machines.

00:04:44,730 --> 00:04:48,840
We do also track you need visibility in performance of how

00:04:48,840 --> 00:04:50,310
it behaves on each user's computer.

00:04:50,310 --> 00:04:57,210
So we, push metrics from our users browsers to permit use with a prom

00:04:57,210 --> 00:05:02,160
client library, which actually we forked in order to deploy it in the

00:05:02,160 --> 00:05:05,130
browser permit use does not encourage.

00:05:05,130 --> 00:05:08,250
And they say it's an anti-pattern, but you know, it has worked for us.

00:05:09,090 --> 00:05:12,630
For years, we have been recently looking at under another technology that I do

00:05:12,630 --> 00:05:16,560
recommend you to check out if you're using permit to use and struggling,

00:05:16,560 --> 00:05:21,210
you might be interested in a tool called Victoria metrics which we've

00:05:21,210 --> 00:05:23,370
been recently looking to migrating to.

00:05:24,750 --> 00:05:29,100
And it looks very, promising and it's among other things does support

00:05:29,100 --> 00:05:31,080
the push that we've been missing.

00:05:31,590 --> 00:05:36,060
So, yeah, I mean, first I guess first thing that I would like to

00:05:36,180 --> 00:05:40,380
emphasize here is a lot of the time you might be using an anti-pattern

00:05:40,440 --> 00:05:42,480
and induction works for a long, time.

00:05:42,480 --> 00:05:49,350
So we've been doing this for almost four years and only now with scale.

00:05:50,380 --> 00:05:52,870
Are looking into a different solution.

00:05:52,870 --> 00:05:55,750
So context also have a longer longevity.

00:05:55,780 --> 00:05:59,740
I mean, Facebook is using, has been using PHP and for a long, time.

00:06:00,219 --> 00:06:04,310
So everything every, performance suggestion will apply

00:06:04,330 --> 00:06:08,109
differently and might have a different context span as well.

00:06:08,757 --> 00:06:11,919
Our performance challenge, as I mentioned is thousands of financial

00:06:11,919 --> 00:06:13,090
computations inside the browser.

00:06:13,859 --> 00:06:15,719
So here's a screenshot from Grafana.

00:06:15,719 --> 00:06:20,789
So these are the metrics we get from our users.

00:06:20,849 --> 00:06:25,580
And what you can see on this screenshot is that we calculate.

00:06:27,659 --> 00:06:32,490
Calculations on users in the user's browsers on their computers, CA

00:06:32,926 --> 00:06:36,990
it's around 200 calculations each taking a few milliseconds, but

00:06:37,320 --> 00:06:39,480
200 calculations every second.

00:06:39,480 --> 00:06:40,800
And that's something that we worry about.

00:06:40,800 --> 00:06:43,219
So we worry about what happeafter.

00:06:43,609 --> 00:06:47,265
User wait up to 10, 15 15 seconds for the website's too loud.

00:06:47,355 --> 00:06:49,215
We worry about the next few hours.

00:06:49,215 --> 00:06:51,315
What's going to be happening.

00:06:51,375 --> 00:06:56,325
As our financial data gets pools and new life information has

00:06:56,325 --> 00:06:58,335
to recalculate and recalculate.

00:06:58,845 --> 00:06:59,805
So what is our problem?

00:06:59,805 --> 00:07:04,155
Our problem is called for us it's optimization for a CPU bounded

00:07:04,585 --> 00:07:06,625
situation with high event throughput.

00:07:07,451 --> 00:07:12,215
So what we deal with is 500 to 1000 Redux functions per second.

00:07:13,370 --> 00:07:17,360
That's both system UI and non UI, as you might guess, there's

00:07:17,360 --> 00:07:18,500
not going to be a lot of Redux.

00:07:18,890 --> 00:07:21,440
There's not going to be as many reductions coming from the user.

00:07:21,800 --> 00:07:27,650
A lot of it is actually being triggered by the system in order to manage incoming

00:07:27,650 --> 00:07:34,730
data and all sorts of book keeping that is connected to handling live market

00:07:34,790 --> 00:07:39,570
exchange updates, be talking a bit more about how Redux handles that later.

00:07:40,576 --> 00:07:41,670
But this is our reality.

00:07:42,030 --> 00:07:45,300
And another one is the 10 to two competitions per second.

00:07:45,300 --> 00:07:49,980
So that's each one runs 10 to 15 milliseconds, which takes two, may take

00:07:49,980 --> 00:07:52,860
around a hundred million seconds to five seconds to perform a full sweep.

00:07:52,860 --> 00:07:58,361
So to recalculate hundred computations per second with this throughput it calculates

00:08:00,045 --> 00:08:06,765
the whole users context, the whole users workbook we might need up to five seconds.

00:08:06,765 --> 00:08:07,965
So obviouslu of course.

00:08:08,855 --> 00:08:10,245
We, offloaded to a web worker.

00:08:10,920 --> 00:08:13,440
And that's something that's very specific to our use case as well.

00:08:14,010 --> 00:08:18,930
I'm using web workers and the floating that CPU bounded problem to a web

00:08:18,930 --> 00:08:25,470
worker otherwise some of you as some of the NodeJS is single threaded.

00:08:25,470 --> 00:08:28,980
So otherwise we would have absolutely no time for the user to be able to

00:08:28,980 --> 00:08:31,200
interact with the UI, the user interface.

00:08:31,230 --> 00:08:34,200
So we need to move that to a separate thread and a separate

00:08:34,200 --> 00:08:36,360
thread is in the web worker.

00:08:37,590 --> 00:08:41,669
So what CPU bound to CPU bound is a fancy terminal when I've

00:08:41,669 --> 00:08:42,849
heard it a few years ago.

00:08:44,021 --> 00:08:46,680
I was really, I could never really get it.

00:08:46,680 --> 00:08:48,720
That sounded very exotic to me.

00:08:48,930 --> 00:08:50,910
But it's actually quite simple concept basically means.

00:08:51,810 --> 00:08:57,450
Your program was, this mostly bounded by by CPU.

00:08:57,480 --> 00:09:02,910
So your program is prime will go faster if you get more CPU or if you get your

00:09:02,910 --> 00:09:10,290
program run faster on those on the CPU you have it means that the emphasis in

00:09:10,290 --> 00:09:15,645
CPU bounded In comparison to any other resource in the computer, like memory

00:09:15,645 --> 00:09:17,745
or drive or network, they don't matter.

00:09:17,745 --> 00:09:21,945
So you could have, if you have a CPU bonded problem, you could buy hundred

00:09:21,945 --> 00:09:25,395
terabytes, extra Ram, but your program will actually still run the same

00:09:25,395 --> 00:09:29,550
speed because the problem with this is that with the CPU rather than with.

00:09:29,895 --> 00:09:30,045
with.

00:09:31,585 --> 00:09:39,944
Resources a lot of, so to to, connect it back to the reality that many, of

00:09:39,944 --> 00:09:42,549
us have every day is most problems.

00:09:42,911 --> 00:09:47,265
The 99% problems that I mentioned earlier, a lot of those problems are

00:09:47,265 --> 00:09:52,465
actuallynetwork Part network bounded part CPU partC part CPU bounded.

00:09:52,885 --> 00:09:55,655
So the faster your network.

00:09:55,824 --> 00:10:00,330
So the faster your network is the faster the website might render off.

00:10:00,360 --> 00:10:06,060
Of course the, story is not as simple because another thing with boundedness

00:10:06,090 --> 00:10:11,290
is that things kind of tend to, one problem as, in general in softwarel

00:10:11,310 --> 00:10:14,190
in software development, when you fix one problem, another problem arises.

00:10:14,670 --> 00:10:18,825
So what happens is when you fix the network, You often

00:10:18,825 --> 00:10:20,055
introduce another boundedness.

00:10:20,055 --> 00:10:22,185
So that happens with websites often, right?

00:10:22,185 --> 00:10:25,995
Like, so you make your JavaScript to be delivered to the customer really

00:10:25,995 --> 00:10:30,015
quickly, but once it's delivered, they open it on it's mobile.

00:10:30,345 --> 00:10:33,705
And then the mobile has a CPU that is too slow to load it quickly.

00:10:33,705 --> 00:10:35,385
So now you have a CPU bounded problem.

00:10:36,015 --> 00:10:41,145
So something to, say here is it's going to sound pretty obvious, but it's like.

00:10:42,470 --> 00:10:46,430
60% of success in performance optimization is to understand what's bounding your

00:10:46,430 --> 00:10:49,820
problem and, every specific time.

00:10:50,540 --> 00:10:54,680
So you actually spending your time smart solving a boundedness.

00:10:54,680 --> 00:10:55,310
That's interesting.

00:10:55,310 --> 00:11:01,760
So there's no point optimizing how speed of your website, if it actually

00:11:02,060 --> 00:11:04,220
takes long to load over the network.

00:11:04,819 --> 00:11:08,750
So that's something to to remember it's like essential thing in

00:11:08,750 --> 00:11:10,189
performance optimizations.

00:11:10,330 --> 00:11:10,660
Yeah.

00:11:10,780 --> 00:11:12,400
So a bit of a JavaScript.

00:11:12,510 --> 00:11:15,100
Javascript is faster than you thought, but slower than you want it.

00:11:15,340 --> 00:11:20,380
And what I mean by that is JavaScript actually, there's a lot of optimization

00:11:20,380 --> 00:11:23,050
that went into JavaScript and it's actually much different story when we

00:11:23,050 --> 00:11:24,790
started four years ago than it is now.

00:11:25,090 --> 00:11:25,840
It's faster than you think.

00:11:26,802 --> 00:11:28,465
Because there's a lot of optimizations.

00:11:28,525 --> 00:11:33,385
So the JavaScript that you load actually gets optimized to a lot of

00:11:33,385 --> 00:11:39,895
the time to assembly code and to see so things can run especially when you

00:11:39,895 --> 00:11:45,535
run smaller bits of code similarly to what you could achieve with CN languages

00:11:45,535 --> 00:11:47,245
like that it's slower than you want.

00:11:47,245 --> 00:11:47,935
It is because.

00:11:48,535 --> 00:11:49,550
Codebase grows.

00:11:49,550 --> 00:11:54,440
And as the size of a project grows, it's much easy to break those optimizations

00:11:54,440 --> 00:11:57,950
or make those optimizations more difficult for the JavaScript engine.

00:11:58,790 --> 00:11:59,360
So, yeah.

00:11:59,360 --> 00:12:02,048
So as you can see here, these days, JavaScript is pretty fast.

00:12:03,315 --> 00:12:08,425
Unfortunately G.I.T, which means just in time optimization

00:12:09,525 --> 00:12:11,595
comes with with, caveats.

00:12:11,625 --> 00:12:12,045
Oh yeah.

00:12:12,585 --> 00:12:13,755
A bit about the Git.

00:12:13,755 --> 00:12:18,285
So the thing that I said that JavaScript gets loaded as JavaScript and then

00:12:18,285 --> 00:12:22,455
gets compiled to assembly coding and to byte code and to see that's

00:12:22,455 --> 00:12:26,055
called Java just in time optimization and Java does the same thing.

00:12:26,055 --> 00:12:28,995
So actually behind the scenes, the code gets.

00:12:29,865 --> 00:12:33,555
Sped up gets compiled into very fast machine code and

00:12:33,555 --> 00:12:34,815
that's happening on the fly.

00:12:34,815 --> 00:12:36,265
That's why it's called just in time.

00:12:37,352 --> 00:12:41,415
In comparison in the languages like --- to go see CC + plus they get

00:12:41,415 --> 00:12:45,915
compiled to bite to machine code and that's it they're super optimized.

00:12:46,405 --> 00:12:47,125
At that point.

00:12:47,295 --> 00:12:49,215
So they don't go for this intermediary step.

00:12:49,465 --> 00:12:53,415
And the Git, the just implementation happens when you run the code.

00:12:53,445 --> 00:12:56,265
So that's important to remember when you run your JavaScript when the

00:12:56,265 --> 00:13:01,605
user loads it on their computer, does the optimization happens.

00:13:01,935 --> 00:13:06,885
So something that you see on this screen is just merely assigning a function,

00:13:06,885 --> 00:13:12,405
math power function to a variable, and then calling it will slow it down.

00:13:12,795 --> 00:13:13,635
And that's called

00:13:13,875 --> 00:13:19,905
----. I I get up from a blog from 2014, 15, so this might not be a case.

00:13:20,817 --> 00:13:23,364
But that was case, and there's a a lot of things like that still

00:13:24,392 --> 00:13:27,045
in in VA, does things get fixed?

00:13:28,185 --> 00:13:33,195
But, those are the type of challenges that you get that some things

00:13:33,195 --> 00:13:38,204
just are totally unintuitive, but unfortunately, no, the byte code.

00:13:38,204 --> 00:13:43,155
When, JavaScript compiled the byte code changes and the engine is not able

00:13:43,155 --> 00:13:45,825
to optimize optimize it out anymore.

00:13:45,825 --> 00:13:50,355
And in this example, you can see that the slowdown is one order of magnitude.

00:13:50,355 --> 00:13:52,275
So it's 10 times slower.

00:13:52,395 --> 00:13:54,345
There's some more practical caveats.

00:13:54,945 --> 00:14:01,052
There was it was pretty big a few years ago when V8 update

00:14:01,075 --> 00:14:03,355
accidentally broke react.

00:14:03,445 --> 00:14:07,645
There was some interaction between between different functionalities in

00:14:07,645 --> 00:14:13,285
different features, prevent extension back in V8 and suddenly react when

00:14:13,285 --> 00:14:18,205
executed on a complex use case would run.

00:14:19,342 --> 00:14:19,505
W...

00:14:19,645 --> 00:14:20,575
would run slower.

00:14:20,665 --> 00:14:21,985
You can read more about this.

00:14:22,165 --> 00:14:24,925
It's a pretty in depth in the problem.

00:14:25,865 --> 00:14:30,065
But also what's what's important to kind of mention here is that you might not

00:14:30,065 --> 00:14:34,345
have to deal with this sort of problems day to day, but they do matter in terms

00:14:34,475 --> 00:14:36,365
in case of frameworks or libraries.

00:14:36,815 --> 00:14:39,515
So things that get called a lot under the hood.

00:14:39,875 --> 00:14:44,585
So where your business code in your business code in your domain code,

00:14:44,615 --> 00:14:47,315
new high-level code is not going to be super that's super important.

00:14:47,805 --> 00:14:51,725
The lower you go in terms of your architecture, the

00:14:51,725 --> 00:14:52,855
more relevant that might be.

00:14:54,055 --> 00:14:57,045
Of course as usual, it will depend on your project.

00:14:58,850 --> 00:14:59,745
Other challenges.

00:14:59,775 --> 00:15:04,814
So here's going to be a big mish-mash and big all you can eat buffet of examples.

00:15:05,295 --> 00:15:08,295
So there's a lot of string representations in JavaScript.

00:15:08,314 --> 00:15:09,885
I mean, I found this on stack overflow.

00:15:10,885 --> 00:15:14,154
I'm not sure if I, haven't been aware before that, but actually

00:15:14,625 --> 00:15:17,865
you have one string in JavaScript, but this can, depending on the

00:15:17,865 --> 00:15:20,605
context, be represented actual V8.

00:15:21,235 --> 00:15:22,765
In 10 or 15 different ways.

00:15:22,795 --> 00:15:26,545
And you, actually, it's very difficult to know which way it is and all

00:15:26,545 --> 00:15:29,055
those representations, different performance characteristics.

00:15:29,535 --> 00:15:34,245
So something that I wanted to really like put a warning here is be careful.

00:15:34,485 --> 00:15:39,045
That's, another point to be careful with your micro benchmarks, because, so

00:15:39,045 --> 00:15:43,875
what we notice a lot as we run our micro benchmark, totally different performance

00:15:44,325 --> 00:15:45,615
characteristics than production.

00:15:46,444 --> 00:15:49,685
Because production code might run on a different string and you don't even know

00:15:49,685 --> 00:15:52,354
that it's running on a different string because it's very difficult to inspect.

00:15:52,864 --> 00:15:57,105
So you have to be very careful when you try to optimize production code and

00:15:57,105 --> 00:15:58,535
you try to create a micro benchmark.

00:15:58,535 --> 00:16:01,805
And you're like, oh, I optimized the hell out of it 10 times faster.

00:16:01,805 --> 00:16:06,425
And then you deploy it actually didn't change because it is a different

00:16:06,454 --> 00:16:09,875
presentation and it was a different behavior in the Git optimization.

00:16:11,660 --> 00:16:19,045
So be very, careful of the micro benchmark I can't emphasize it, but enough, like 99,

00:16:19,045 --> 00:16:22,860
90 5% of the time I see micro benchmark.

00:16:22,860 --> 00:16:23,680
I'm like, no, it's wrong.

00:16:24,910 --> 00:16:27,699
This might sound a bit arrogant, but unfortunately it isn't the reality.

00:16:27,699 --> 00:16:29,560
It's very difficult to do these things.

00:16:30,520 --> 00:16:34,900
There's other things that I've heard asked a lot is there is no hashcode in string

00:16:34,959 --> 00:16:36,970
and just no interning interning is...

00:16:38,910 --> 00:16:42,210
a process when you can flatten a representation into faster

00:16:42,210 --> 00:16:44,382
representation, something that Java has.

00:16:45,586 --> 00:16:52,380
And hasg code is a very important feature when you use and data structures like maps

00:16:52,380 --> 00:16:57,150
and sets it for us it's it helps us a lot.

00:16:58,327 --> 00:17:01,780
elder Array representations, again, this comes with the same caveat be careful.

00:17:02,715 --> 00:17:05,670
You, think you have one array, you think you did your micro benchmark, but

00:17:05,670 --> 00:17:08,190
actually youall these representations and actuallytually they will run with

00:17:08,190 --> 00:17:09,450
different performance characteristics.

00:17:09,450 --> 00:17:12,600
They be, they can be up to five times performance difference

00:17:12,600 --> 00:17:16,050
between them something that many people are not quite aware about.

00:17:16,190 --> 00:17:17,940
Object polymorphism, mega morphism.

00:17:18,450 --> 00:17:21,390
So this is that Java doesn't have.

00:17:21,540 --> 00:17:27,150
And this is one of the, if there's one thing to remember from this

00:17:27,150 --> 00:17:28,260
presentation, might be this.

00:17:29,730 --> 00:17:35,100
So because JavaScript is dynamic it optimizes based on execution.

00:17:35,670 --> 00:17:41,430
So JavaScript will optimize your code based on the shape of the

00:17:41,760 --> 00:17:43,470
data that comes into the function.

00:17:43,740 --> 00:17:47,820
So if you call your function with just numbers, JavaScript

00:17:47,820 --> 00:17:49,080
will notice it over time.

00:17:49,080 --> 00:17:50,550
And it will say, oh, amazing.

00:17:50,550 --> 00:17:52,410
You're just giving me numbers to this function.

00:17:52,410 --> 00:17:52,840
add.

00:17:53,480 --> 00:17:57,050
That I'm going to optimize it into very efficient machine code, because

00:17:57,050 --> 00:17:58,070
you're just giving me numbers.

00:17:58,520 --> 00:18:03,230
But if you have these multifunction methods, are you actually not,

00:18:03,350 --> 00:18:06,260
are you actually using your methods a bit haphazardly and you

00:18:06,260 --> 00:18:07,970
give a string, you get a number.

00:18:07,970 --> 00:18:11,420
You give a bullian, you get an object, JavaScript will be like, okay, dude,

00:18:11,510 --> 00:18:12,440
I don't know what you're giving me.

00:18:12,440 --> 00:18:13,610
You're giving me different objects.

00:18:13,850 --> 00:18:16,460
I'm just going to use the least efficient code so I can handle

00:18:16,700 --> 00:18:18,530
all these different cases.

00:18:18,800 --> 00:18:20,450
So that's something to do.

00:18:20,450 --> 00:18:22,510
Remember things are optimized based on usage.

00:18:22,760 --> 00:18:28,340
So making it obvious how you're using it well will make it faster.

00:18:28,340 --> 00:18:31,400
We'll make it faster for another programmer as well, because having

00:18:31,400 --> 00:18:36,260
things that are like a Swiss knife are actually difficult to understand

00:18:36,260 --> 00:18:38,490
by other developers on the team.

00:18:40,310 --> 00:18:44,120
And a tool that's really, cool to check out for this if you're interested, but

00:18:44,300 --> 00:18:47,950
be careful because you can get stuck for days and days with this and might...

00:18:48,440 --> 00:18:50,700
For your project is called the deoptigate it's.

00:18:50,700 --> 00:18:56,210
It's a really cool tool to see how your objects how your code gets.

00:18:57,225 --> 00:18:58,815
I guess optimised or re optimized.

00:18:59,145 --> 00:18:59,445
Oh yeah.

00:18:59,445 --> 00:19:03,165
Something that I wanted to add here very quickly is the mega morphism also

00:19:03,165 --> 00:19:05,625
applies to dictionaries and objects.

00:19:05,685 --> 00:19:10,065
So a bit of trivia, I don't know how much a bit of trivia is.

00:19:10,065 --> 00:19:14,325
Like, if you line your keys in an object different way, this will be

00:19:14,325 --> 00:19:16,045
actually considered a different, object

00:19:16,250 --> 00:19:17,030
in JavaScript.

00:19:17,389 --> 00:19:22,790
So if you say first name and last name and your object, and then you spread it and

00:19:22,790 --> 00:19:26,690
then you add first name, second, this will actually be different to presentation.

00:19:26,690 --> 00:19:31,790
So if you're using spreading a lot in your and you have large objects and

00:19:31,790 --> 00:19:37,399
you're spreading a lot in your project, this will have impact on performance.

00:19:39,490 --> 00:19:42,169
Something more relevant to us against low date implementation.

00:19:42,200 --> 00:19:45,430
Something that is kind of interesting because there's a bit of a tension

00:19:45,430 --> 00:19:46,750
between us and the rest of the world.

00:19:46,750 --> 00:19:50,409
Like I mentioned earlier, we want JavaScript running really fast

00:19:50,409 --> 00:19:53,854
and the CPU's, the rest of the world is kind of like happy with.

00:19:55,264 --> 00:19:58,450
And, rightly so is we're assembling an alternative.

00:19:58,629 --> 00:20:03,820
Everybody keeps asking me that maybe I'm very skeptical about

00:20:03,820 --> 00:20:04,490
it's something to really.

00:20:06,030 --> 00:20:10,110
Emphasize here is web assembly is still JavaScript.

00:20:10,500 --> 00:20:10,770
Sorry.

00:20:10,770 --> 00:20:12,120
It's still the same engine.

00:20:12,120 --> 00:20:14,430
So WebAssembly still runs in a V8 engine.

00:20:14,900 --> 00:20:20,559
There is some opportunities for writing more optimized code in web assembly.

00:20:21,180 --> 00:20:26,820
You can maybe scale your code base better to be able to leverage the

00:20:26,820 --> 00:20:32,760
just in time compiler and optimizer optimizations, but it's not a it's not a.

00:20:33,990 --> 00:20:35,820
This is a per bullet that everybody's visited.

00:20:36,150 --> 00:20:40,188
And also there's still a lot of things about assembly that aren't quite there.

00:20:43,330 --> 00:20:46,530
For, more details, there's a presentation that explains it in depth, half an

00:20:46,530 --> 00:20:49,740
hour presentation just focused on this topic that was JavaScript being fast.

00:20:49,740 --> 00:20:50,620
Now, pick your battles.

00:20:50,916 --> 00:20:52,200
We chose react and Redux.

00:20:52,620 --> 00:20:54,489
Maybe you could have chosen something more lightweight.

00:20:55,509 --> 00:20:56,320
We're quite happy.

00:20:57,360 --> 00:20:58,170
Something to kind of.

00:21:00,330 --> 00:21:01,320
What's the takeaway for me.

00:21:01,320 --> 00:21:01,949
It's okay.

00:21:01,949 --> 00:21:03,209
To just a popular solution.

00:21:03,570 --> 00:21:07,350
We have evolved some of the popular libraries.

00:21:08,320 --> 00:21:12,179
We, use we have evolved our synchronis management, for example, a lot.

00:21:12,179 --> 00:21:13,590
We used to redux saga for awhile.

00:21:13,590 --> 00:21:15,511
We used, we [tanks].

00:21:16,290 --> 00:21:19,900
Now we use some half semi grown, homegrown solution based on RXJS.

00:21:19,919 --> 00:21:20,040
Yeah.

00:21:20,560 --> 00:21:23,530
But redux, react and Redux stayed with us for a long time.

00:21:23,860 --> 00:21:25,530
And it kind of is just an object.

00:21:25,530 --> 00:21:27,190
You can get used to living with it.

00:21:28,180 --> 00:21:30,880
We use on top of redux, we optimize for performance.

00:21:30,880 --> 00:21:31,210
Of course.

00:21:31,210 --> 00:21:36,100
So we use immutable GS, which we still use it, even though I know the rest of the

00:21:36,100 --> 00:21:39,190
world, just kind of walking away from it, but we do really need it for performance.

00:21:39,700 --> 00:21:42,670
I mean, we're quite sad that it's half abandoned.

00:21:43,180 --> 00:21:49,900
I reselect quite extensively for, creating our transformers and, a few other tools.

00:21:51,229 --> 00:21:52,459
Some people will end up react.

00:21:52,490 --> 00:21:54,590
It's not necessarily very reactive.

00:21:55,969 --> 00:21:57,050
I'm very sad about this.

00:21:57,050 --> 00:21:59,030
No, there's no built in debouncing of rendering.

00:21:59,050 --> 00:22:04,129
So you basically can't say, okay, if this component gets called a lot just

00:22:04,129 --> 00:22:12,450
ignore ignore 90% of the renders and just render every 200 milliseconds or even

00:22:13,219 --> 00:22:14,689
there's no debouncing the probe updates.

00:22:14,750 --> 00:22:16,639
Many of you may have not even come across it.

00:22:17,000 --> 00:22:18,229
It's very specific to us.

00:22:18,290 --> 00:22:21,615
If you're calculating props is very expensive.

00:22:22,455 --> 00:22:24,225
You actually do want to calculate your price.

00:22:26,240 --> 00:22:32,030
For example, every half a second or every one second we use lazy data

00:22:32,030 --> 00:22:34,070
structures to, to facilitate that.

00:22:34,070 --> 00:22:35,009
So it's a bit of a hack.

00:22:35,780 --> 00:22:37,820
I've read recently that apparently somebody come up with

00:22:37,820 --> 00:22:39,170
a solution with react hooks.

00:22:39,530 --> 00:22:41,240
So maybe, we're getting there.

00:22:41,720 --> 00:22:46,490
But this one was very frustrating to us for for a long time, because

00:22:47,247 --> 00:22:50,930
there's, a way to debounce and other people do this, debounce of rendering.

00:22:52,395 --> 00:22:55,575
But many don't, get this problem of like, okay, but what if I need

00:22:55,575 --> 00:22:59,145
to debounce my pro updates as well overall we're quite happy with react

00:22:59,175 --> 00:23:06,015
and it's with the, what were the few workarounds that we have it's, working

00:23:06,015 --> 00:23:07,905
out very well for, our use case.

00:23:09,625 --> 00:23:09,865
Okay.

00:23:09,875 --> 00:23:13,805
So interestingly not least great performance will always

00:23:13,805 --> 00:23:14,795
start with great design.

00:23:15,155 --> 00:23:16,415
And this is a massive topic.

00:23:16,415 --> 00:23:18,485
So I'm only going to mention a few things here.

00:23:20,325 --> 00:23:24,495
But first of all right, focus on great, good architecture, good design first.

00:23:25,695 --> 00:23:29,835
I see some people optimizing their angular teams and making it like

00:23:29,835 --> 00:23:33,314
in a really efficient solution and saying, Hey, look, it's really fast.

00:23:33,794 --> 00:23:37,935
And you can't really then maintain it or read it.

00:23:38,835 --> 00:23:43,605
And there's a lot of like hacks and tweaks and really was important.

00:23:43,605 --> 00:23:46,875
If you want the long lift solution you want to, optimize

00:23:46,875 --> 00:23:48,254
for fast feature delivery.

00:23:48,254 --> 00:23:48,524
Right?

00:23:48,945 --> 00:23:49,152
So.

00:23:50,159 --> 00:23:52,080
Performance is just one of the requirements.

00:23:52,110 --> 00:23:56,010
So you want to write a performance obligation as performance

00:23:56,010 --> 00:23:57,719
as possible, but not more.

00:23:57,780 --> 00:24:01,919
So you kind of want to, you kind of want to make sure that you can ride

00:24:01,919 --> 00:24:03,510
your features as fast as possible.

00:24:03,750 --> 00:24:07,979
And at the same time optimize when it's, where it's necessary

00:24:08,370 --> 00:24:09,929
and not even one inch.

00:24:12,005 --> 00:24:16,805
So, so yeah, [unclear] make it work first refactor and on the,

00:24:16,805 --> 00:24:18,665
after you measure, make it fast.

00:24:18,935 --> 00:24:22,655
And when we optimize, we always we always optimize systemically

00:24:22,655 --> 00:24:24,275
first and tactically second.

00:24:24,875 --> 00:24:29,675
So what I mean by that is you want to do optimizations that

00:24:29,765 --> 00:24:32,345
re redesign change your design.

00:24:33,075 --> 00:24:34,545
In a way that's still very readable.

00:24:34,545 --> 00:24:37,035
But faster rather than doing one of these.

00:24:37,065 --> 00:24:37,395
Okay.

00:24:37,395 --> 00:24:40,395
Let me use this tricks to make me algorithm go really fast.

00:24:40,845 --> 00:24:47,925
Those you should always be very careful and do as few those tactical local

00:24:48,325 --> 00:24:50,005
optimizations of make your code look.

00:24:50,835 --> 00:24:53,935
No, of course you should be very careful with those because they will hurt you.

00:24:54,918 --> 00:24:56,895
This is a screenshot from the optgate.

00:24:57,075 --> 00:24:57,985
This is what it looks like.

00:24:58,755 --> 00:24:59,355
Try it out.

00:24:59,415 --> 00:25:06,270
It looks a bit cryptic, but it's it's, a very, useful tool to

00:25:06,270 --> 00:25:08,130
understand how your code is optimized.

00:25:08,640 --> 00:25:12,030
And you can see there's a very complicated code from, some parser

00:25:12,030 --> 00:25:13,830
babbler or something like that.

00:25:13,830 --> 00:25:18,580
And you can see the code that's complex to read by your fellow developer actually

00:25:18,580 --> 00:25:23,610
will be difficult for the machine to execute a lot of people don't or [unclear]

00:25:23,680 --> 00:25:25,371
you don't even think about that a lot every day.

00:25:27,600 --> 00:25:31,710
The simplicity of the code translates to simplicity, to read, but also

00:25:31,710 --> 00:25:35,070
translates to simplicity, to optimize.

00:25:36,389 --> 00:25:37,379
So you keep your.

00:25:38,445 --> 00:25:39,396
They're relatively short.

00:25:40,455 --> 00:25:45,995
If you keep your objects simple if you keep your design well, well

00:25:46,005 --> 00:25:51,225
factored you're, probably potentially just getting a faster application.

00:25:51,765 --> 00:25:54,195
They've all been great design topic of dozen presentations.

00:25:54,195 --> 00:25:55,395
So we use TypeScript.

00:25:56,415 --> 00:25:56,685
Perfect.

00:25:57,449 --> 00:26:03,560
Best tool for fast code because it deals with poly megamorphis but

00:26:03,570 --> 00:26:09,159
they mentioned earlier it helps to create predictable design It helps

00:26:09,179 --> 00:26:10,679
you manage a complex code base.

00:26:11,220 --> 00:26:14,370
So if you follow the patterns that typescript advice is actually, you're

00:26:14,370 --> 00:26:20,939
much more likely to get a nice performing a nice well-performing application

00:26:21,764 --> 00:26:25,900
something that we took a lot to learn and I will definitely record.

00:26:27,725 --> 00:26:32,045
You don't make the same mistakes as us that the book effective taps with wasn't

00:26:32,045 --> 00:26:37,205
there when we started it's there now if using TypeScript is it's an amazing source

00:26:37,205 --> 00:26:45,003
of knowledge we had to learn a lot of it through through our mistakes Monads

00:26:46,115 --> 00:26:47,865
really useful for managing complexity.

00:26:49,215 --> 00:26:55,275
So I think that we use to handle too a lot of the time to represent exceptions.

00:26:55,275 --> 00:27:00,555
So we use either monads rather than exceptions, we use option type to deal

00:27:00,555 --> 00:27:06,765
with no immutibility and other monads to basically encapsulate the complexity.

00:27:07,695 --> 00:27:10,545
Something that's, I've not seen as popular in JavaScript community,

00:27:10,545 --> 00:27:15,195
but it's kind of been quite popular in Java is especially for us, our,

00:27:15,225 --> 00:27:19,785
we have a monolith because most of our apps applications, a big client

00:27:19,785 --> 00:27:21,165
that's got declined on user browsers.

00:27:21,195 --> 00:27:26,024
So it's very important for us to manage dependencies in

00:27:26,024 --> 00:27:27,645
this monolift very carefully.

00:27:27,975 --> 00:27:32,375
So we use dependency cruiser which basically allows you to manage

00:27:32,385 --> 00:27:33,825
dependencies between different modules.

00:27:34,771 --> 00:27:34,965
And then.

00:27:35,585 --> 00:27:39,725
For it not to get out of hand and become a spaghetti code of

00:27:39,725 --> 00:27:40,925
everything, talking to everything.

00:27:41,885 --> 00:27:48,155
We built a thin layer on top of it, which we got inspired by arc unit archeologist

00:27:48,155 --> 00:27:52,764
solution in Java, which is much, much more extensive, but you can borrow from,

00:27:52,774 --> 00:28:00,155
the tool in order to build your simple domain specific language for dependencies.

00:28:00,545 --> 00:28:00,845
Yeah.

00:28:00,845 --> 00:28:02,405
And we do leverage domain driven design.

00:28:04,074 --> 00:28:09,795
[domain] for a way to keep making sure that our code base is close

00:28:09,795 --> 00:28:12,855
to the actual problem and domain.

00:28:13,830 --> 00:28:17,580
And for, to manage architecture at scale.

00:28:17,790 --> 00:28:24,780
So in order to factor our app, our modules to manage the dependency between them in

00:28:24,780 --> 00:28:27,270
the same way, I mean, something that's really useful with domain-driven design

00:28:27,270 --> 00:28:32,080
is if you have a, your modules structure or on-demand concepts that it would,

00:28:32,080 --> 00:28:36,240
there is is a dependency between modules in the code, there should be a dependency

00:28:36,240 --> 00:28:37,680
between modules in the real life.

00:28:37,680 --> 00:28:43,045
So when, you see there is dependency in, the code, Well when you look at

00:28:43,045 --> 00:28:47,665
the real life, that doesn't seem to be a relationship, you should say,

00:28:47,665 --> 00:28:49,195
okay, something is wrong with our code.

00:28:49,525 --> 00:28:50,575
So it's really useful in that.

00:28:50,995 --> 00:28:53,215
That's one way how domain-driven design is useful.

00:28:54,857 --> 00:28:58,525
This many, other ways, if you want to start simple, the best way to start,

00:28:58,525 --> 00:29:07,255
I think personally is to check out ducks which is a a library for helps

00:29:07,255 --> 00:29:08,545
you start this journey to Redux.

00:29:09,055 --> 00:29:09,235
So.

00:29:10,784 --> 00:29:13,995
Don't get distracted by other people problems, including this presentation.

00:29:14,295 --> 00:29:18,025
You might have a different problem than other people and that's okay.

00:29:18,645 --> 00:29:22,065
Java script faster than you thought, because a lot of things get optimized

00:29:22,095 --> 00:29:26,085
for you, but slower than you want it, because if you're not careful of

00:29:26,085 --> 00:29:27,915
the things will not get optimized.

00:29:29,590 --> 00:29:30,740
And w we'll remain slow.

00:29:31,040 --> 00:29:31,790
Pick your battles.

00:29:31,850 --> 00:29:34,969
You don't always have to have a new shiny technology.

00:29:34,969 --> 00:29:37,370
You don't always build something yourself.

00:29:37,760 --> 00:29:42,169
You can just pick the most popular thing first and then iterate and last but not

00:29:42,169 --> 00:29:44,330
least remember that great performance.

00:29:44,330 --> 00:29:45,889
There's a lot of tricks to great performance.

00:29:45,889 --> 00:29:50,090
There's a lot of knowledge how to optimize things, but start,

00:29:50,120 --> 00:29:51,320
you start with great design.

00:29:51,469 --> 00:29:54,500
Actually, things might just get optimized for you most of the time.

00:29:55,975 --> 00:29:59,665
And even as you go, optimizing things is going to be, it's

00:29:59,665 --> 00:30:01,284
going to be much, much, easier.

00:30:01,825 --> 00:30:02,335
Thank you.

00:30:02,365 --> 00:30:07,465
That's that's it really for the for the all you can eat buffet of tips

00:30:07,465 --> 00:30:08,635

YouTube URL: https://www.youtube.com/watch?v=EPhArG3It18


