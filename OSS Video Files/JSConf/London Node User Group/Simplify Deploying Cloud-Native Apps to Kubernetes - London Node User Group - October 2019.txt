Title: Simplify Deploying Cloud-Native Apps to Kubernetes - London Node User Group - October 2019
Publication date: 2019-11-13
Playlist: London Node User Group
Description: 
	@enriquel8: Simplify deploying cloud-native apps to Kubernetes

_

About Pusher Sessions:

We're bringing the meetup to you. With Sessions, you can watch recordings of top-notch talks from developer meetups -- wherever and whenever you want.

Meetups are a great way to learn from our peers and to keep up with the latest trends and technologies. As developers ourselves, we at Pusher wanted to bring this great content to more people... So we built Sessions. On Sessions, you can watch talks that interest you and subscribe to be notified when new content gets added.

If you run a meetup and want to get involved, kindly get in touch.

_

About Pusher:

Pusher is a hosted service with APIs, developer tools and open source libraries that greatly simplify integrating real-time functionality into web and mobile applications. 

Pusher will automatically scale when required, removing all the pain of setting up and maintaining a secure, real-time infrastructure. 

Pusher is already trusted to do so by thousands of developers and companies like GitHub, MailChimp, the Financial Times, Buffer and many more. 

Getting started takes just a few seconds: simply go to pusher.com and create a free account. Happy hacking!
Captions: 
	00:00:00,030 --> 00:00:04,440
hi everyone I'm Enrique I'm a software

00:00:02,370 --> 00:00:06,480
the word IBM and I'm here to talk about

00:00:04,440 --> 00:00:08,700
simplifying deployment cloud native apps

00:00:06,480 --> 00:00:10,290
to communities so now what about client

00:00:08,700 --> 00:00:13,610
if you have apps they're just a simple

00:00:10,290 --> 00:00:15,690
application which leverages cloud

00:00:13,610 --> 00:00:19,020
technologies when they point to clouds

00:00:15,690 --> 00:00:20,880
such as metrics or tracing so talking

00:00:19,020 --> 00:00:22,050
with enterprises at IBM it's quite

00:00:20,880 --> 00:00:23,939
difficult to deploy a cloud native

00:00:22,050 --> 00:00:26,580
applications within a within a huge

00:00:23,939 --> 00:00:28,980
company so here I'm gonna introduce two

00:00:26,580 --> 00:00:31,019
personas one is Jane let's say our lead

00:00:28,980 --> 00:00:32,239
no developer in a team and then we have

00:00:31,019 --> 00:00:36,030
champ which is a solution architect

00:00:32,239 --> 00:00:38,399
champ specifies the distributive systems

00:00:36,030 --> 00:00:40,320
specifies to what cloud environments we

00:00:38,399 --> 00:00:42,120
need to deploy this means that Jane

00:00:40,320 --> 00:00:43,739
needs to learn all of these different

00:00:42,120 --> 00:00:44,760
technologies we were talking about

00:00:43,739 --> 00:00:47,010
different languages different

00:00:44,760 --> 00:00:48,870
micro-service architectures different

00:00:47,010 --> 00:00:51,840
databases or even when you're building

00:00:48,870 --> 00:00:54,180
and deploying how I'm CUBAN et's etc so

00:00:51,840 --> 00:00:56,070
it's a lot for Jane to learn so that IBM

00:00:54,180 --> 00:00:58,530
will decided to build a tool to simplify

00:00:56,070 --> 00:01:00,870
this so with something called @ab city

00:00:58,530 --> 00:01:03,239
which enables you to create and compose

00:01:00,870 --> 00:01:05,850
cloud native applications to summarize

00:01:03,239 --> 00:01:07,950
this in one line one simple line it's a

00:01:05,850 --> 00:01:10,290
developer tooling to create develop and

00:01:07,950 --> 00:01:12,810
deploy cloud native applications using

00:01:10,290 --> 00:01:14,520
cloud optimized application stacks so

00:01:12,810 --> 00:01:16,290
you may answer asked what are stacks

00:01:14,520 --> 00:01:18,509
that's what the heart of apps key is

00:01:16,290 --> 00:01:21,240
stacks are pre-configured applications

00:01:18,509 --> 00:01:23,430
that use your solutions architects will

00:01:21,240 --> 00:01:26,310
configure for the developer so we have a

00:01:23,430 --> 00:01:28,350
look at a simple node.js application

00:01:26,310 --> 00:01:30,119
with Express we'll have an express

00:01:28,350 --> 00:01:32,369
server connect and then some application

00:01:30,119 --> 00:01:33,750
functions and some business logic if

00:01:32,369 --> 00:01:36,030
then we want to deploy this tree to the

00:01:33,750 --> 00:01:37,530
cloud with for example how to package it

00:01:36,030 --> 00:01:39,570
within a dark container so we can

00:01:37,530 --> 00:01:40,920
appoint to any environment and this is

00:01:39,570 --> 00:01:44,009
really what we call nowadays in the

00:01:40,920 --> 00:01:46,079
distributed system a micro service so

00:01:44,009 --> 00:01:48,570
from our Rhapsody we provide a series of

00:01:46,079 --> 00:01:51,540
stacks in order to help you get started

00:01:48,570 --> 00:01:53,189
with our wither 2 so on their left hand

00:01:51,540 --> 00:01:55,409
side we have a traditional micro service

00:01:53,189 --> 00:01:57,270
using Express yes we then provide a

00:01:55,409 --> 00:01:58,890
node.js stack already with docker files

00:01:57,270 --> 00:02:01,469
and node.js versions for you to deploy

00:01:58,890 --> 00:02:03,390
your Express applications on top we then

00:02:01,469 --> 00:02:05,430
also provide a node.js Express stack

00:02:03,390 --> 00:02:07,110
which already house cloud native

00:02:05,430 --> 00:02:09,000
function is built in Express so

00:02:07,110 --> 00:02:12,180
endpoints that metrics for Prometheus or

00:02:09,000 --> 00:02:13,740
any sorts of add metrics dashboards for

00:02:12,180 --> 00:02:15,660
you to be doing in development

00:02:13,740 --> 00:02:17,130
and we also provide a node.js function

00:02:15,660 --> 00:02:19,350
stack will provide server less

00:02:17,130 --> 00:02:21,000
functionalities for developers for them

00:02:19,350 --> 00:02:23,400
to only need to worry about the business

00:02:21,000 --> 00:02:26,880
logic and easily deploy in Turkey on a

00:02:23,400 --> 00:02:28,200
DS so we've seen what stacks are and

00:02:26,880 --> 00:02:30,300
receive that normally your solution

00:02:28,200 --> 00:02:32,160
architect defined these standards and

00:02:30,300 --> 00:02:34,560
developers will build on top of that so

00:02:32,160 --> 00:02:36,780
how does the developer use this we have

00:02:34,560 --> 00:02:40,410
build a CLI well developer can pull this

00:02:36,780 --> 00:02:42,080
tax down test a locally debug build and

00:02:40,410 --> 00:02:44,810
then when she's ready she can deploy and

00:02:42,080 --> 00:02:47,940
the deploy considerations are also

00:02:44,810 --> 00:02:49,470
specified by your architect so we're

00:02:47,940 --> 00:02:51,900
going to quickly go through the workflow

00:02:49,470 --> 00:02:53,580
of how this works so your solutions

00:02:51,900 --> 00:02:55,380
architect filters and customizes your

00:02:53,580 --> 00:02:57,750
stacks you can be no J's can be any

00:02:55,380 --> 00:02:59,700
language we can then configure these

00:02:57,750 --> 00:03:01,260
requirements if for the clouds the way

00:02:59,700 --> 00:03:03,870
where they point to the cloud may be the

00:03:01,260 --> 00:03:06,600
amount of replicas we then have we can

00:03:03,870 --> 00:03:09,090
post it to a hub or registry and we have

00:03:06,600 --> 00:03:11,340
our developer using the CLI she can pull

00:03:09,090 --> 00:03:14,280
any of the stacks that the Advocate has

00:03:11,340 --> 00:03:17,160
chosen to use she can then develop her

00:03:14,280 --> 00:03:20,160
app using any ID issue once and debug

00:03:17,160 --> 00:03:22,110
locally then she can save her changes to

00:03:20,160 --> 00:03:24,450
a github repository and when she's ready

00:03:22,110 --> 00:03:26,130
she can build her final docker image

00:03:24,450 --> 00:03:28,080
with all the specifications of her

00:03:26,130 --> 00:03:30,900
architect's blasto application on top

00:03:28,080 --> 00:03:33,090
pro microservice finally she can deploy

00:03:30,900 --> 00:03:36,060
it to any orchestration environment that

00:03:33,090 --> 00:03:37,350
her architect has specified so I like

00:03:36,060 --> 00:03:38,640
you I know you guys like to look at code

00:03:37,350 --> 00:03:41,130
and like to look at demos so I've

00:03:38,640 --> 00:03:43,680
prepared a very short demo to really

00:03:41,130 --> 00:03:45,720
show this and see we can fit it so we

00:03:43,680 --> 00:03:48,780
create a simple another directory with

00:03:45,720 --> 00:03:51,270
my node application I just sped this up

00:03:48,780 --> 00:03:53,220
proceeded into it we using our app so

00:03:51,270 --> 00:03:56,040
the CLI we're gonna initialize one of

00:03:53,220 --> 00:03:58,470
the node.js Express stacks where we have

00:03:56,040 --> 00:04:00,930
a series of endpoints already built so

00:03:58,470 --> 00:04:03,900
we're downloading a docker image were

00:04:00,930 --> 00:04:06,420
then opening this in RVs code we can

00:04:03,900 --> 00:04:07,410
keep any editor of choice and if we look

00:04:06,420 --> 00:04:09,420
at the left hand side we have a

00:04:07,410 --> 00:04:12,020
traditional package JSON and app with a

00:04:09,420 --> 00:04:14,520
with a root that says hello from Absa d

00:04:12,020 --> 00:04:15,840
so we have expressed where we've we've

00:04:14,520 --> 00:04:18,120
using Express and then we also have a

00:04:15,840 --> 00:04:20,400
series of tests already pre-built in

00:04:18,120 --> 00:04:23,190
that we can use this is just a simple

00:04:20,400 --> 00:04:25,770
test for our route endpoint and then we

00:04:23,190 --> 00:04:27,150
can go ahead and through our ID we can

00:04:25,770 --> 00:04:30,840
run our application

00:04:27,150 --> 00:04:33,720
so we have a series already CLI enabled

00:04:30,840 --> 00:04:35,250
in our ID and we can go ahead and run so

00:04:33,720 --> 00:04:38,479
this would actually pull down the doctor

00:04:35,250 --> 00:04:40,919
image and run our Express application

00:04:38,479 --> 00:04:42,870
with the doctor image / architect with

00:04:40,919 --> 00:04:45,240
all his tools that he's had made

00:04:42,870 --> 00:04:48,240
available for us so now we go on our

00:04:45,240 --> 00:04:51,949
localhost 3000 we should see our

00:04:48,240 --> 00:04:51,949
application saying hello from app city

00:04:52,580 --> 00:04:58,380
then we can see and hit the endpoints

00:04:55,290 --> 00:05:00,330
that our architect has defined or for

00:04:58,380 --> 00:05:02,720
example we can change code we can say hi

00:05:00,330 --> 00:05:06,090
hello from London user group for example

00:05:02,720 --> 00:05:08,190
we can save our file and this

00:05:06,090 --> 00:05:10,650
automatically launches our application

00:05:08,190 --> 00:05:12,479
inside docker container so hot reload

00:05:10,650 --> 00:05:15,330
and we can have it again in a browser so

00:05:12,479 --> 00:05:16,680
we can do all development locally in a

00:05:15,330 --> 00:05:18,630
dog container that our solutions

00:05:16,680 --> 00:05:19,949
architect has defined we can then here

00:05:18,630 --> 00:05:22,229
the series of endpoints such as our help

00:05:19,949 --> 00:05:24,419
our metrics endpoint for Prometheus in

00:05:22,229 --> 00:05:25,919
the clouds a cloud native function we

00:05:24,419 --> 00:05:28,020
can hit for example our health endpoints

00:05:25,919 --> 00:05:30,570
for kubernetes when we deploying inside

00:05:28,020 --> 00:05:33,330
a pod and we even have enabled a

00:05:30,570 --> 00:05:35,720
dashboard for metrics so we have a

00:05:33,330 --> 00:05:39,990
simple dashboard so if we open our

00:05:35,720 --> 00:05:44,310
application in another tab and we give a

00:05:39,990 --> 00:05:45,780
few requests we should see some HTTP

00:05:44,310 --> 00:05:48,210
requests coming and can have some some

00:05:45,780 --> 00:05:51,240
chasing and metrics or application o2

00:05:48,210 --> 00:05:52,770
development in a docker image so then we

00:05:51,240 --> 00:05:54,690
can also enable profiling for more

00:05:52,770 --> 00:05:57,060
details of the stack traces and where

00:05:54,690 --> 00:06:01,889
we're losing our metrics we hit again

00:05:57,060 --> 00:06:03,270
our application ID specification and we

00:06:01,889 --> 00:06:05,849
should see a series of flame graphs

00:06:03,270 --> 00:06:08,280
where we can see our stack stack details

00:06:05,849 --> 00:06:11,669
for that cause we're making so once

00:06:08,280 --> 00:06:14,580
we're ready to predication we can then

00:06:11,669 --> 00:06:17,820
go ahead and stop to the to the vs code

00:06:14,580 --> 00:06:20,310
and we can then go ahead and run a

00:06:17,820 --> 00:06:22,740
series of tests these are tests defined

00:06:20,310 --> 00:06:24,120
by architects so test for all the

00:06:22,740 --> 00:06:26,610
endpoints or solution architect has

00:06:24,120 --> 00:06:29,460
defined and our own tests in this case

00:06:26,610 --> 00:06:30,960
we're using mock so once we've tests and

00:06:29,460 --> 00:06:32,820
everything as fast we can then build a

00:06:30,960 --> 00:06:36,140
final doctor image which will be used to

00:06:32,820 --> 00:06:39,639
deploy so we go ahead again into our our

00:06:36,140 --> 00:06:42,250
CLI and we build a final doctor image

00:06:39,639 --> 00:06:44,289
with the whole application in it once

00:06:42,250 --> 00:06:46,509
the courageous Milt we can then deploy

00:06:44,289 --> 00:06:48,370
it so locally for this demo I've set up

00:06:46,509 --> 00:06:52,870
a Cuban ETS cluster and docker for

00:06:48,370 --> 00:06:56,830
desktop running at localhost and we can

00:06:52,870 --> 00:06:58,539
go ahead and deploy this application so

00:06:56,830 --> 00:07:04,689
again through a CLI will you play the

00:06:58,539 --> 00:07:08,319
application so you see now so now this

00:07:04,689 --> 00:07:09,909
will give us an endpoint since we're

00:07:08,319 --> 00:07:12,009
running our communities on localhost

00:07:09,909 --> 00:07:16,270
we'll get a localhost endpoint we can go

00:07:12,009 --> 00:07:18,669
ahead and copy this look at our our

00:07:16,270 --> 00:07:19,569
application running inside to Benitez in

00:07:18,669 --> 00:07:22,180
a matter of minutes

00:07:19,569 --> 00:07:25,240
I've only sped up that by 2x by the way

00:07:22,180 --> 00:07:27,490
so it's quite fast so then we can hit

00:07:25,240 --> 00:07:29,560
our endpoints or metric test points for

00:07:27,490 --> 00:07:31,689
for Prometheus our health endpoints and

00:07:29,560 --> 00:07:33,279
we don't have our dashboard here because

00:07:31,689 --> 00:07:35,830
we wouldn't need it one with one where

00:07:33,279 --> 00:07:37,270
the point in production so you verify

00:07:35,830 --> 00:07:39,310
that with the point okay when it is we

00:07:37,270 --> 00:07:41,139
can use a cube City or command get our

00:07:39,310 --> 00:07:44,560
pods and we should have our node up

00:07:41,139 --> 00:07:47,169
there so that's just a quick demo of

00:07:44,560 --> 00:07:48,520
what AB city is and how you can deploy

00:07:47,169 --> 00:07:51,610
applications and cloud native

00:07:48,520 --> 00:07:53,800
applications in a whole company with the

00:07:51,610 --> 00:07:54,890
same configurations thank you for

00:07:53,800 --> 00:07:58,350
listening

00:07:54,890 --> 00:07:58,350

YouTube URL: https://www.youtube.com/watch?v=eUPrf6XzEm4


