Title: Create and Deploy Cloud Native Node.js Applications - London Node User Group - October 2018
Publication date: 2018-11-02
Playlist: London Node User Group
Description: 
	Presented by Beth Griggs and Neeraj Laad.

The CloudNativeJS.io community project provides a number of assets, tools and core modules for building Cloud Native Node.js applications. This session will show users how to use those to easily take an existing application and deploy it to Kubernetes with full support for liveness checks, metrics and request tracking.

_

About Pusher Sessions:

We're bringing the meetup to you. With Sessions, you can watch recordings of top-notch talks from developer meetups -- wherever and whenever you want.

Meetups are a great way to learn from our peers and to keep up with the latest trends and technologies. As developers ourselves, we at Pusher wanted to bring this great content to more people... So we built Sessions. On Sessions, you can watch talks that interest you and subscribe to be notified when new content gets added.

If you run a meetup and want to get involved, kindly get in touch.

_

About Pusher:

Pusher is a hosted service with APIs, developer tools and open source libraries that greatly simplify integrating real-time functionality into web and mobile applications. 

Pusher will automatically scale when required, removing all the pain of setting up and maintaining a secure, real-time infrastructure. 

Pusher is already trusted to do so by thousands of developers and companies like GitHub, MailChimp, the Financial Times, Buffer and many more. 

Getting started takes just a few seconds: simply go to pusher.com and create a free account. Happy hacking!
Captions: 
	00:00:00,000 --> 00:00:04,770
hi everyone my name is Beth and I'm here

00:00:02,760 --> 00:00:07,350
today with Niraj from my team we both

00:00:04,770 --> 00:00:09,330
work IBM and we're in the node runtime

00:00:07,350 --> 00:00:12,599
team and what we'd like to talk to you

00:00:09,330 --> 00:00:14,400
about today is cloud native no Jess so a

00:00:12,599 --> 00:00:15,870
cloud native application is just an

00:00:14,400 --> 00:00:20,160
application it's designed to leverage

00:00:15,870 --> 00:00:22,289
cloud capabilities first a bit of

00:00:20,160 --> 00:00:25,199
background as to why node is so good in

00:00:22,289 --> 00:00:27,840
the cloud and also for micro services so

00:00:25,199 --> 00:00:29,699
high speed very important when you're

00:00:27,840 --> 00:00:31,560
deploying in a cloud because most of the

00:00:29,699 --> 00:00:32,550
time you're pinging a REST API or

00:00:31,560 --> 00:00:34,380
something like that

00:00:32,550 --> 00:00:36,239
pausing adjacent an object and getting

00:00:34,380 --> 00:00:39,570
it back so the speed in which you can

00:00:36,239 --> 00:00:43,800
pause that is perfect so in JavaScript

00:00:39,570 --> 00:00:45,120
this is an Express app we get 1150 the

00:00:43,800 --> 00:00:47,430
higher the number the better normally

00:00:45,120 --> 00:00:49,800
with IO speed and then we're comparing

00:00:47,430 --> 00:00:53,160
this to a spring brute app which really

00:00:49,800 --> 00:00:54,420
gets 897 so immediately know it's a good

00:00:53,160 --> 00:00:58,350
choice because you're getting faster

00:00:54,420 --> 00:00:59,670
rate speed then a startup time so when

00:00:58,350 --> 00:01:02,190
you're deploying inside something like

00:00:59,670 --> 00:01:04,049
Cuba Nettie's or docker you really want

00:01:02,190 --> 00:01:05,850
things to scale up and scale down very

00:01:04,049 --> 00:01:08,520
quickly so the amount of time it takes

00:01:05,850 --> 00:01:09,930
for your app to start is important we've

00:01:08,520 --> 00:01:12,270
expressed you're getting less than a

00:01:09,930 --> 00:01:14,610
second for a spring boot you'll get at

00:01:12,270 --> 00:01:16,740
about 14 seconds so when you want to add

00:01:14,610 --> 00:01:18,060
a new note you've gotta wait 14 seconds

00:01:16,740 --> 00:01:21,030
before it can actually start handling

00:01:18,060 --> 00:01:22,650
requests and then you have memory so

00:01:21,030 --> 00:01:25,049
when you deploy to a cloud

00:01:22,650 --> 00:01:26,310
you often paper you'll never research so

00:01:25,049 --> 00:01:29,280
you can either have small medium or

00:01:26,310 --> 00:01:31,799
large or maybe even a monetary value so

00:01:29,280 --> 00:01:34,020
less memory you use while executing your

00:01:31,799 --> 00:01:38,490
app better so when you compare that with

00:01:34,020 --> 00:01:41,159
Java or spring boot up 23 big versus 422

00:01:38,490 --> 00:01:46,350
much so again white notice they're great

00:01:41,159 --> 00:01:48,119
for matrices and clouds so there's been

00:01:46,350 --> 00:01:50,640
a few surveys of cloud developers

00:01:48,119 --> 00:01:52,380
recently and we we looked at them to try

00:01:50,640 --> 00:01:54,210
and find out what are people doing with

00:01:52,380 --> 00:01:55,979
their apps in the cloud so a lot of

00:01:54,210 --> 00:01:58,469
people hundred percent is saying we're

00:01:55,979 --> 00:02:00,479
deploying our app in the cloud but only

00:01:58,469 --> 00:02:03,719
30 percent say they're using cloud

00:02:00,479 --> 00:02:06,390
services so that's instead of using a

00:02:03,719 --> 00:02:07,680
cloud service database they're actually

00:02:06,390 --> 00:02:11,190
just getting their database put in the

00:02:07,680 --> 00:02:12,690
end of VM and deploying it and only 12%

00:02:11,190 --> 00:02:13,650
it's saying they're writing fully cloud

00:02:12,690 --> 00:02:15,450
native apps so

00:02:13,650 --> 00:02:19,409
native apps leveraging all of those

00:02:15,450 --> 00:02:21,390
cloud functions and things like that the

00:02:19,409 --> 00:02:23,159
node.js foundation also did a survey and

00:02:21,390 --> 00:02:26,909
again similar similar kind of feedback

00:02:23,159 --> 00:02:28,260
certainly 90 cents a cloud hosted 48

00:02:26,909 --> 00:02:30,000
cents a docker so that's quite good a

00:02:28,260 --> 00:02:32,400
lot of people were saying doc is the way

00:02:30,000 --> 00:02:34,859
to go the way to deploy your apps but

00:02:32,400 --> 00:02:36,569
only 12 cent are using kubernetes so

00:02:34,859 --> 00:02:38,310
only 12% are actually managing those

00:02:36,569 --> 00:02:42,209
docker containers scaling them up and

00:02:38,310 --> 00:02:44,489
down when they need to so the cloud

00:02:42,209 --> 00:02:45,989
native computing foundation have a set

00:02:44,489 --> 00:02:48,359
of projects which they believe all

00:02:45,989 --> 00:02:50,010
linked to creating cloud native apps you

00:02:48,359 --> 00:02:52,650
have Cloud Foundry communities for

00:02:50,010 --> 00:02:54,349
managing your dog containers Prometheus

00:02:52,650 --> 00:02:58,769
and open tracing for monitoring and

00:02:54,349 --> 00:03:00,930
tracing and helmet docker what we've

00:02:58,769 --> 00:03:03,090
done at IBM we started this initiative

00:03:00,930 --> 00:03:04,349
is completely open source is we've

00:03:03,090 --> 00:03:07,170
announced a project called cloud native

00:03:04,349 --> 00:03:09,359
Jas and the idea is that it provides you

00:03:07,170 --> 00:03:11,819
a set of resources where you can go if

00:03:09,359 --> 00:03:14,329
you're a node developer and you can pull

00:03:11,819 --> 00:03:16,920
them in and start writing clowny to that

00:03:14,329 --> 00:03:18,599
so this is just our website we've gone

00:03:16,920 --> 00:03:20,340
for a few redesigns but it's all open

00:03:18,599 --> 00:03:24,540
source so if you'd like to help us out

00:03:20,340 --> 00:03:27,569
very great and what it's comprised of is

00:03:24,540 --> 00:03:29,370
a few sections so we have module

00:03:27,569 --> 00:03:31,680
insights which is all about how you

00:03:29,370 --> 00:03:34,769
choose modules to a good use inside your

00:03:31,680 --> 00:03:36,389
cloud application we have docker

00:03:34,769 --> 00:03:39,299
where we provide some dock or template

00:03:36,389 --> 00:03:41,190
files we have kubernetes and in there we

00:03:39,299 --> 00:03:44,310
provide some sample helm charts for you

00:03:41,190 --> 00:03:47,579
to use to deploy inside Kuban lessees we

00:03:44,310 --> 00:03:49,409
have a health checking app open tracing

00:03:47,579 --> 00:03:50,430
and Prometheus we have some modules that

00:03:49,409 --> 00:03:53,310
you can pull in so you can easily

00:03:50,430 --> 00:03:55,949
connect to those services so the first

00:03:53,310 --> 00:03:59,129
is module insights so what we started

00:03:55,949 --> 00:04:01,199
doing here is listing top modules for

00:03:59,129 --> 00:04:03,359
now we've just taken like the top 40 or

00:04:01,199 --> 00:04:05,639
a selection of 40 but we aim to grow it

00:04:03,359 --> 00:04:08,069
and we're trying to gather some data so

00:04:05,639 --> 00:04:10,739
you have somewhere to go to work out

00:04:08,069 --> 00:04:12,989
what should I be using in my app so if

00:04:10,739 --> 00:04:14,669
you're just building a prototype it's

00:04:12,989 --> 00:04:17,039
probably not a problem just to go to NPM

00:04:14,669 --> 00:04:18,419
and find a suitable module you know have

00:04:17,039 --> 00:04:21,060
some fun hiking it together and that's

00:04:18,419 --> 00:04:23,219
fine but when we're looking at our IBM

00:04:21,060 --> 00:04:24,719
from enterprise customers and enterprise

00:04:23,219 --> 00:04:26,930
deployments we need to look at these

00:04:24,719 --> 00:04:29,389
modules and work out

00:04:26,930 --> 00:04:31,130
supported are they well-maintained do

00:04:29,389 --> 00:04:34,430
they run all of architectures because

00:04:31,130 --> 00:04:36,620
IBM you can choose to deploy on power

00:04:34,430 --> 00:04:39,410
Rosie doesn't want you actually work on

00:04:36,620 --> 00:04:41,930
those platforms so this is all callate

00:04:39,410 --> 00:04:44,120
of data the green and red tiles that

00:04:41,930 --> 00:04:46,130
just mean what we're doing there is each

00:04:44,120 --> 00:04:48,590
module provides its test suite on github

00:04:46,130 --> 00:04:51,710
and we pull in that modules test suite

00:04:48,590 --> 00:04:54,020
run it and report back whether it passes

00:04:51,710 --> 00:04:55,820
or fails its own test suite and we do

00:04:54,020 --> 00:04:58,130
like across a variety of architectures

00:04:55,820 --> 00:05:01,479
so you can drop down a bit like it does

00:04:58,130 --> 00:05:04,310
Express work on power or what have you

00:05:01,479 --> 00:05:06,050
we also give license information if

00:05:04,310 --> 00:05:07,699
you're working at an enterprise you

00:05:06,050 --> 00:05:09,530
probably have to take a look at the

00:05:07,699 --> 00:05:13,639
licenses and make sure there's no GP or

00:05:09,530 --> 00:05:15,320
what have you in your papaya tree the

00:05:13,639 --> 00:05:16,910
idea is just so you have somewhere to go

00:05:15,320 --> 00:05:18,889
to try and get a bit more information

00:05:16,910 --> 00:05:21,470
than what you get on NPM or something

00:05:18,889 --> 00:05:25,419
like that again it's all open source we

00:05:21,470 --> 00:05:25,419
could planning to expand it as well

00:05:25,639 --> 00:05:29,750
one of the columns there you'll see

00:05:27,289 --> 00:05:32,120
stability what we started looking at

00:05:29,750 --> 00:05:35,060
recently is long term support of modules

00:05:32,120 --> 00:05:38,750
so a lot of modules don't actually have

00:05:35,060 --> 00:05:41,000
LTS policies like node does and what

00:05:38,750 --> 00:05:43,130
they are are people were very expressed

00:05:41,000 --> 00:05:45,620
for 2x that will be supported for 2

00:05:43,130 --> 00:05:49,699
years so you know that as a developer

00:05:45,620 --> 00:05:51,770
using Express you won't have to take in

00:05:49,699 --> 00:05:54,830
any breaking changes for at least two

00:05:51,770 --> 00:05:56,570
years a lot of modules don't do this so

00:05:54,830 --> 00:05:58,520
you could be stuck in a position where

00:05:56,570 --> 00:06:01,490
you have to either accept a breaking

00:05:58,520 --> 00:06:04,759
change or not get the latest security

00:06:01,490 --> 00:06:07,099
fixes so a lot of modules have started

00:06:04,759 --> 00:06:09,080
to sign up to these happy house terrain

00:06:07,099 --> 00:06:12,050
1 and things like that it's just a way

00:06:09,080 --> 00:06:14,900
of making sure that much of your using

00:06:12,050 --> 00:06:18,190
will continue what you're not going to

00:06:14,900 --> 00:06:21,560
be broken by them updating whenever a

00:06:18,190 --> 00:06:23,180
loop backs another example we say Dave

00:06:21,560 --> 00:06:24,680
agreed to support two two-door X

00:06:23,180 --> 00:06:32,139
released line for the lifetime we have

00:06:24,680 --> 00:06:32,139
node 6 and then we have docker so

00:06:33,129 --> 00:06:37,999
what we're doing here is as part of

00:06:35,990 --> 00:06:41,569
colony guess we provide sample docker

00:06:37,999 --> 00:06:42,949
files so these files firstly just assume

00:06:41,569 --> 00:06:44,749
you've got an express our running on

00:06:42,949 --> 00:06:47,360
port 3000 but that's some configurable

00:06:44,749 --> 00:06:49,459
and what we've done is provide the best

00:06:47,360 --> 00:06:51,169
so you can just pull it into your app do

00:06:49,459 --> 00:06:55,610
a docker build and then you've got your

00:06:51,169 --> 00:06:57,770
node application pointed up and we've

00:06:55,610 --> 00:07:00,889
ordered this in a specific way because

00:06:57,770 --> 00:07:03,229
when you do docker belts where actually

00:07:00,889 --> 00:07:05,509
does is it does it layer by layer so

00:07:03,229 --> 00:07:07,309
step one will be from node 8 so that

00:07:05,509 --> 00:07:09,619
builds pulsing the node 8 docker image

00:07:07,309 --> 00:07:12,559
and then we do some operating system

00:07:09,619 --> 00:07:16,520
updates and then we copy in your package

00:07:12,559 --> 00:07:17,629
Jason and do the NPM install so install

00:07:16,520 --> 00:07:19,669
production so we didn't get dev

00:07:17,629 --> 00:07:21,979
dependencies the reason we do the

00:07:19,669 --> 00:07:23,509
install in the docker file itself is

00:07:21,979 --> 00:07:25,999
because you might be developing on Mac

00:07:23,509 --> 00:07:27,949
and if you do your NPM install Mac and

00:07:25,999 --> 00:07:32,179
you have native code it might not work

00:07:27,949 --> 00:07:35,209
inside a open to Linux docker container

00:07:32,179 --> 00:07:37,369
so you do it in this idea and then you

00:07:35,209 --> 00:07:40,669
copy your app in so what is said about

00:07:37,369 --> 00:07:42,830
ordering chances are you're rarely going

00:07:40,669 --> 00:07:45,229
to change the node 8 image so that would

00:07:42,830 --> 00:07:47,509
be cached you're rarely going to change

00:07:45,229 --> 00:07:49,430
OS updates weren't often changed so that

00:07:47,509 --> 00:07:51,949
will also be cached so she worked

00:07:49,430 --> 00:07:53,300
through because it's all cache then only

00:07:51,949 --> 00:07:55,069
rebuilding at the point something

00:07:53,300 --> 00:07:56,629
changes you're actually saving time

00:07:55,069 --> 00:07:58,610
doing your docker builds that's why the

00:07:56,629 --> 00:08:03,800
app copying into the container is at the

00:07:58,610 --> 00:08:07,610
end and then it just starts your app but

00:08:03,800 --> 00:08:12,199
actually what the node 8 image supplied

00:08:07,610 --> 00:08:15,969
by the node foundation is actually 716

00:08:12,199 --> 00:08:19,610
Meg because it uses weird al' coin

00:08:15,969 --> 00:08:21,430
notice debian is of w an image so it's

00:08:19,610 --> 00:08:23,689
quite full-fledged it's got all of the

00:08:21,430 --> 00:08:25,279
thinking it's got no chip and python

00:08:23,689 --> 00:08:28,099
insider because that's what you need for

00:08:25,279 --> 00:08:30,110
compiling native modules docker actually

00:08:28,099 --> 00:08:32,449
provides something called multistage

00:08:30,110 --> 00:08:34,370
builds so we've actually provided a

00:08:32,449 --> 00:08:35,949
template if you'd like to use those and

00:08:34,370 --> 00:08:38,689
what it essentially does is step one is

00:08:35,949 --> 00:08:41,329
produce a full-fledged container that

00:08:38,689 --> 00:08:44,120
can do your build so it can install your

00:08:41,329 --> 00:08:46,040
modules handle all of that and then it

00:08:44,120 --> 00:08:48,320
builds a much slimmer container

00:08:46,040 --> 00:08:50,720
a very lightweight container without the

00:08:48,320 --> 00:08:52,880
Python or no Chapel anything like that

00:08:50,720 --> 00:08:54,980
so this is the monk stage bell just goes

00:08:52,880 --> 00:08:57,470
through copies everything from the

00:08:54,980 --> 00:09:00,709
container you first started with into

00:08:57,470 --> 00:09:03,110
the second one and as a result you end

00:09:00,709 --> 00:09:05,600
up with a much lighter image so the

00:09:03,110 --> 00:09:07,399
first one was about 700 Meg this one is

00:09:05,600 --> 00:09:11,500
about 200 Meg no just need a smaller

00:09:07,399 --> 00:09:16,069
image the quicker it is to build and

00:09:11,500 --> 00:09:18,170
transport so that's fine so you can

00:09:16,069 --> 00:09:20,180
package your application up put it in a

00:09:18,170 --> 00:09:22,970
docker container and deploy it but often

00:09:20,180 --> 00:09:24,230
with high availability and scaling what

00:09:22,970 --> 00:09:27,410
you want to do is you want to have

00:09:24,230 --> 00:09:31,910
multiple of them so at that point you

00:09:27,410 --> 00:09:33,920
kind of want to go into cuba Nettie's

00:09:31,910 --> 00:09:36,110
where you can scale up and down and

00:09:33,920 --> 00:09:37,699
let's point out cross over to nourish

00:09:36,110 --> 00:09:40,190
thank you for introducing the cloud

00:09:37,699 --> 00:09:42,019
native just at i/o I mean I believe

00:09:40,190 --> 00:09:44,870
you've got the background on why we

00:09:42,019 --> 00:09:47,029
believe node is such an ideal platform

00:09:44,870 --> 00:09:49,190
for building things and deploying them

00:09:47,029 --> 00:09:50,569
to the cloud what we're trying to do

00:09:49,190 --> 00:09:52,760
with this initiative at the moment is

00:09:50,569 --> 00:09:55,339
try and provide as many resources as we

00:09:52,760 --> 00:09:57,829
can and help people onboard and adopt as

00:09:55,339 --> 00:10:00,680
many of these cloud native computing

00:09:57,829 --> 00:10:03,829
foundation technologies as we can the

00:10:00,680 --> 00:10:05,569
next one that will go from what we've

00:10:03,829 --> 00:10:09,949
covered so far is deploying to

00:10:05,569 --> 00:10:12,410
communities once you have docker app

00:10:09,949 --> 00:10:15,350
what we're trying to do is be providing

00:10:12,410 --> 00:10:18,139
a set of templates along with that there

00:10:15,350 --> 00:10:21,829
are two key ml files chart dot e ml and

00:10:18,139 --> 00:10:22,910
values dot llamo inside the helm by the

00:10:21,829 --> 00:10:24,829
way people who are not familiar with

00:10:22,910 --> 00:10:27,440
helm helm is it is a packaging tool

00:10:24,829 --> 00:10:29,269
which helps you deploy any application

00:10:27,440 --> 00:10:32,420
into communities you can configure and

00:10:29,269 --> 00:10:33,709
tell communities how it is supposed to

00:10:32,420 --> 00:10:35,810
manage your application how many

00:10:33,709 --> 00:10:38,329
instances do you want how you want to be

00:10:35,810 --> 00:10:41,120
scaling up and down and all of that and

00:10:38,329 --> 00:10:43,009
what we've provided are are what we

00:10:41,120 --> 00:10:44,689
believe are is is a good standard to

00:10:43,009 --> 00:10:48,860
start with and you can always tweak them

00:10:44,689 --> 00:10:51,139
around as you want if I look at chart

00:10:48,860 --> 00:10:53,600
but Hamill mainly it covers information

00:10:51,139 --> 00:10:57,079
about your application itself say what

00:10:53,600 --> 00:10:58,720
origin you using a description name of

00:10:57,079 --> 00:11:00,399
the application and things like that

00:10:58,720 --> 00:11:02,470
you can just provide any meta

00:11:00,399 --> 00:11:04,089
information about the app there are lots

00:11:02,470 --> 00:11:05,709
of other things that you can provide but

00:11:04,089 --> 00:11:10,060
these are the bare minimum to get going

00:11:05,709 --> 00:11:11,740
on the next day's values the camel and

00:11:10,060 --> 00:11:13,420
essentially all of these values feed

00:11:11,740 --> 00:11:15,519
into the templates that are provided

00:11:13,420 --> 00:11:16,839
alongside but you just added the values

00:11:15,519 --> 00:11:20,889
file and then you've got all your

00:11:16,839 --> 00:11:22,930
configuration in one place if I call out

00:11:20,889 --> 00:11:25,810
few specific things here

00:11:22,930 --> 00:11:27,910
there's obviously the repository which

00:11:25,810 --> 00:11:30,459
is the place from where you want to

00:11:27,910 --> 00:11:32,259
fetch your docker image it could be a

00:11:30,459 --> 00:11:33,339
local image that you've built up or it

00:11:32,259 --> 00:11:35,550
could be something that you've pushed

00:11:33,339 --> 00:11:41,110
your docker hub or your enterprise

00:11:35,550 --> 00:11:43,120
doctor report then we've got CPU and

00:11:41,110 --> 00:11:45,009
memory so what kind of CPU memory you

00:11:43,120 --> 00:11:48,670
want to be allocated to this instance of

00:11:45,009 --> 00:11:50,529
the application and you got how many

00:11:48,670 --> 00:11:52,779
instances of this application do you

00:11:50,529 --> 00:11:55,509
want so we mostly set minimum one

00:11:52,779 --> 00:11:58,420
maximum to where you could do five and

00:11:55,509 --> 00:12:00,040
ten or whatever values suit appropriate

00:11:58,420 --> 00:12:01,720
for your application in terms of scaling

00:12:00,040 --> 00:12:03,670
them up and down so when you deploy

00:12:01,720 --> 00:12:08,500
it'll start with one in this case and

00:12:03,670 --> 00:12:09,910
we'll go back to know what - are - one

00:12:08,500 --> 00:12:12,850
more thing I wanted to call out here is

00:12:09,910 --> 00:12:15,490
the target utilization output the CPU

00:12:12,850 --> 00:12:17,199
and memory values here and those are the

00:12:15,490 --> 00:12:19,329
values that will data mine then it

00:12:17,199 --> 00:12:21,879
should actually scale up and then scale

00:12:19,329 --> 00:12:23,500
down based on the upper and lower limits

00:12:21,879 --> 00:12:25,240
that put and all of these could be

00:12:23,500 --> 00:12:26,740
tweaked again we don't believe all

00:12:25,240 --> 00:12:29,350
applications are going to use exactly

00:12:26,740 --> 00:12:30,850
this but it's a good place to get going

00:12:29,350 --> 00:12:33,699
and then once you're familiar with it

00:12:30,850 --> 00:12:38,050
you can tweak it to make it best suit

00:12:33,699 --> 00:12:39,910
your application in terms of how do we

00:12:38,050 --> 00:12:42,309
use the assets that we've got so if you

00:12:39,910 --> 00:12:45,699
go into you the the chart node server

00:12:42,309 --> 00:12:47,170
directory in to help install and give it

00:12:45,699 --> 00:12:49,509
a name node server is the name of the

00:12:47,170 --> 00:12:51,160
application in this instance and pointed

00:12:49,509 --> 00:12:53,559
to current directory where the chart dot

00:12:51,160 --> 00:12:56,439
llamo and the values of yonghwa then

00:12:53,559 --> 00:12:58,449
that's all you need to do I made an

00:12:56,439 --> 00:13:00,100
assumption here that you've got a Cuban

00:12:58,449 --> 00:13:02,800
it is environment running on your your

00:13:00,100 --> 00:13:04,540
laptop or whichever environment you're

00:13:02,800 --> 00:13:06,279
pointing it to but that's pretty

00:13:04,540 --> 00:13:06,920
standard you can do it with the docker

00:13:06,279 --> 00:13:12,620
on a Mac

00:13:06,920 --> 00:13:14,300
or anything like that and I said as an

00:13:12,620 --> 00:13:16,579
example if this was to start with let's

00:13:14,300 --> 00:13:19,850
say five then it'll start with that and

00:13:16,579 --> 00:13:23,540
then he it could scale up based on but

00:13:19,850 --> 00:13:28,010
the memory and resources are used moving

00:13:23,540 --> 00:13:30,170
on to you health check not that we've

00:13:28,010 --> 00:13:32,630
got an application running inside

00:13:30,170 --> 00:13:34,699
kubernetes we can scale it up and down

00:13:32,630 --> 00:13:36,649
but we're not really still using all the

00:13:34,699 --> 00:13:39,620
power that communities can provide it's

00:13:36,649 --> 00:13:41,209
just me using it for scaling so what we

00:13:39,620 --> 00:13:42,380
need to do is try and see if we can

00:13:41,209 --> 00:13:44,779
leverage some of the built-in

00:13:42,380 --> 00:13:46,820
capabilities a bit more and assist in

00:13:44,779 --> 00:13:48,980
the environment or the platform to work

00:13:46,820 --> 00:13:52,490
better with us so as an example you've

00:13:48,980 --> 00:13:54,740
got to express apps deployed on

00:13:52,490 --> 00:13:57,260
communities and you would have

00:13:54,740 --> 00:13:59,300
kubernetes environment act like a load

00:13:57,260 --> 00:14:04,160
balancer and routing requests to both

00:13:59,300 --> 00:14:08,089
the applications what we could do is

00:14:04,160 --> 00:14:10,430
have a specific endpoint already which

00:14:08,089 --> 00:14:12,649
tells communities whether I'm ready to

00:14:10,430 --> 00:14:15,290
receive the requests or not so that's

00:14:12,649 --> 00:14:17,959
basically telling you from the time it's

00:14:15,290 --> 00:14:20,120
deployed is your application ready some

00:14:17,959 --> 00:14:22,190
of the applications might have to

00:14:20,120 --> 00:14:24,110
connect the databases read some other

00:14:22,190 --> 00:14:26,480
configuration files do some other

00:14:24,110 --> 00:14:28,370
initial set up so you can do all of that

00:14:26,480 --> 00:14:31,550
and during that time as long as you

00:14:28,370 --> 00:14:33,769
return a non non okay value on this

00:14:31,550 --> 00:14:36,190
ready endpoint communities is not gonna

00:14:33,769 --> 00:14:39,320
send requests to your instance in a way

00:14:36,190 --> 00:14:42,740
and once it's ready it will start

00:14:39,320 --> 00:14:45,529
sending the request over that the other

00:14:42,740 --> 00:14:47,540
one is health which is indicating

00:14:45,529 --> 00:14:50,029
communities when do we want the

00:14:47,540 --> 00:14:54,079
application to be restarted so as an

00:14:50,029 --> 00:14:55,850
example if you are trying to do

00:14:54,079 --> 00:14:58,880
something and you encounter issues and

00:14:55,850 --> 00:15:00,560
you want a signal the environment itself

00:14:58,880 --> 00:15:02,690
to say restart to something gone wrong

00:15:00,560 --> 00:15:07,339
and I don't think we can recover then

00:15:02,690 --> 00:15:10,730
you can use that health endpoint as an

00:15:07,339 --> 00:15:12,680
example if this was being deployed in

00:15:10,730 --> 00:15:15,350
communities and one of the applications

00:15:12,680 --> 00:15:17,300
started returning nonzero values then

00:15:15,350 --> 00:15:19,260
the environment will basically send a

00:15:17,300 --> 00:15:22,020
sector signal to the other

00:15:19,260 --> 00:15:26,220
it'll give us about 30 seconds before it

00:15:22,020 --> 00:15:28,860
sends a sickle and then it'll try and

00:15:26,220 --> 00:15:34,680
restart the app itself when the app

00:15:28,860 --> 00:15:37,320
starts oops it should start coming up

00:15:34,680 --> 00:15:39,000
with ready and health obviously they

00:15:37,320 --> 00:15:43,020
should have been two stages there to say

00:15:39,000 --> 00:15:45,180
ready first and then it becomes ready

00:15:43,020 --> 00:15:50,520
okay and then it starts routing the

00:15:45,180 --> 00:15:53,040
request to the other app as well to do

00:15:50,520 --> 00:15:56,850
this we provided a unknown module under

00:15:53,040 --> 00:16:01,220
the cloud native J's initiative and all

00:15:56,850 --> 00:16:04,520
you need to do is add that one line

00:16:01,220 --> 00:16:09,840
which is the health connect module and

00:16:04,520 --> 00:16:12,660
once you've added that module you can

00:16:09,840 --> 00:16:15,240
basically register specific endpoints

00:16:12,660 --> 00:16:17,790
here you've got app that he's ready and

00:16:15,240 --> 00:16:19,920
app dot he is health and then we've

00:16:17,790 --> 00:16:22,440
provided the health check object that

00:16:19,920 --> 00:16:24,720
we've created using that the other thing

00:16:22,440 --> 00:16:26,790
you can do if you use this module is you

00:16:24,720 --> 00:16:29,700
can have your own listeners or you can

00:16:26,790 --> 00:16:31,650
do your own stuff as a promise when

00:16:29,700 --> 00:16:34,470
these checks are executed so if you look

00:16:31,650 --> 00:16:37,290
at line three there we've created a

00:16:34,470 --> 00:16:38,760
promise and that form is basically we

00:16:37,290 --> 00:16:41,280
are passing that back to the ready

00:16:38,760 --> 00:16:44,250
object which is used in the ready check

00:16:41,280 --> 00:16:47,010
so every time the slash ready endpoint

00:16:44,250 --> 00:16:48,990
is is hid it will basically execute that

00:16:47,010 --> 00:16:50,220
promise and you can do whatever you want

00:16:48,990 --> 00:16:51,900
to do to understand whether you're

00:16:50,220 --> 00:16:53,520
really ready or not and you can do

00:16:51,900 --> 00:16:59,970
similar things and you can have as many

00:16:53,520 --> 00:17:03,420
of those endpoints as you want moving on

00:16:59,970 --> 00:17:05,280
to tracing and distributed tracing

00:17:03,420 --> 00:17:07,740
specifically because we are moving to a

00:17:05,280 --> 00:17:10,650
world where all the apps are split into

00:17:07,740 --> 00:17:12,900
small micro services and deployed and

00:17:10,650 --> 00:17:16,920
tied together to achieve and create a

00:17:12,900 --> 00:17:21,030
function this is just a sample app that

00:17:16,920 --> 00:17:23,820
I have just created here as you there's

00:17:21,030 --> 00:17:26,190
a request coming from the browser it

00:17:23,820 --> 00:17:27,720
goes to the load balancer the load

00:17:26,190 --> 00:17:30,520
balancer routes the request to the

00:17:27,720 --> 00:17:34,570
back-end which is serving the

00:17:30,520 --> 00:17:36,400
the web interface and that calls up

00:17:34,570 --> 00:17:38,170
another microservices which is

00:17:36,400 --> 00:17:41,590
fulfilling the orders which uses a

00:17:38,170 --> 00:17:43,330
MongoDB database but to do the order I

00:17:41,590 --> 00:17:45,070
might need to check the inventory which

00:17:43,330 --> 00:17:46,650
might be using a separate database I

00:17:45,070 --> 00:17:49,030
mean this is just a hypothetical

00:17:46,650 --> 00:17:53,200
application but you can see the point

00:17:49,030 --> 00:17:55,420
that if the request is served and it is

00:17:53,200 --> 00:17:56,920
taking let's say 20 seconds to serve

00:17:55,420 --> 00:17:59,590
this request back then how do I know

00:17:56,920 --> 00:18:01,990
where the problem is which one of these

00:17:59,590 --> 00:18:04,210
steps is taking longer than expected and

00:18:01,990 --> 00:18:06,570
how do I go about identifying and then

00:18:04,210 --> 00:18:09,250
trying to see if I can fix the problem

00:18:06,570 --> 00:18:14,710
and this is where distributor tracing

00:18:09,250 --> 00:18:17,530
comes in what we've provided here is a

00:18:14,710 --> 00:18:19,630
module called app metrics Zipkin zip

00:18:17,530 --> 00:18:23,950
king being an implementation of the open

00:18:19,630 --> 00:18:28,150
tracing specification all you need to do

00:18:23,950 --> 00:18:30,520
is add that one line in your application

00:18:28,150 --> 00:18:33,670
and that module basically starts

00:18:30,520 --> 00:18:35,410
injecting some header values so which

00:18:33,670 --> 00:18:36,790
allows this distributed tracing to be

00:18:35,410 --> 00:18:38,440
worked out essentially it generates a

00:18:36,790 --> 00:18:40,750
new token on every request and then

00:18:38,440 --> 00:18:43,480
passes it on as it goes from one micro

00:18:40,750 --> 00:18:45,700
service to another and then you can use

00:18:43,480 --> 00:18:49,300
the Zipkin user interface this is a

00:18:45,700 --> 00:18:52,630
screenshot from the second web UI which

00:18:49,300 --> 00:18:55,270
gives you a full stack trace of which

00:18:52,630 --> 00:18:57,250
services called at what time when we

00:18:55,270 --> 00:19:00,010
started when we finished how the call

00:18:57,250 --> 00:19:01,630
went from one service to another and the

00:19:00,010 --> 00:19:03,220
bars indicate how long it took

00:19:01,630 --> 00:19:05,620
essentially so you can start looking at

00:19:03,220 --> 00:19:07,780
in my entire application in the mesh

00:19:05,620 --> 00:19:10,929
which one is taking longer what's going

00:19:07,780 --> 00:19:14,860
on another thing that you get along with

00:19:10,929 --> 00:19:17,470
that is it's a visual representation of

00:19:14,860 --> 00:19:20,170
which micro service uses which one and

00:19:17,470 --> 00:19:21,520
what endpoints it's been calling and

00:19:20,170 --> 00:19:23,380
that might be very useful when you're

00:19:21,520 --> 00:19:24,760
trying to react you take one pace to

00:19:23,380 --> 00:19:27,900
understand what are the external

00:19:24,760 --> 00:19:27,900
interfaces and things like that

00:19:29,860 --> 00:19:37,760
moving on to prometheus monitoring again

00:19:35,450 --> 00:19:43,070
Prometheus is a cloud native computing

00:19:37,760 --> 00:19:45,110
Foundation project and what we're doing

00:19:43,070 --> 00:19:50,390
there is adding a third endpoint called

00:19:45,110 --> 00:19:54,560
slash metrics what Prometheus does is

00:19:50,390 --> 00:19:57,140
basically it'll start returning some

00:19:54,560 --> 00:19:59,510
values on that matrix into a endpoint

00:19:57,140 --> 00:20:02,690
and start aggregating those values over

00:19:59,510 --> 00:20:04,340
time what we've done is we've provided a

00:20:02,690 --> 00:20:08,300
particular module called at metrics

00:20:04,340 --> 00:20:10,340
Prometheus again app matrix is a is a

00:20:08,300 --> 00:20:12,200
collector it's an open source module

00:20:10,340 --> 00:20:15,380
that collects simple information from

00:20:12,200 --> 00:20:18,080
your node module a node project and like

00:20:15,380 --> 00:20:21,470
CPU resource to tell ization blah blah

00:20:18,080 --> 00:20:22,850
blah and then we are exposing that in a

00:20:21,470 --> 00:20:24,440
specific format that permittees

00:20:22,850 --> 00:20:26,270
understands here essentially so we are

00:20:24,440 --> 00:20:27,770
manipulating the format of the metrics

00:20:26,270 --> 00:20:31,040
that we are getting from app metrics and

00:20:27,770 --> 00:20:32,630
presenting it to Prometheus Kuban ladies

00:20:31,040 --> 00:20:34,160
already knows about slash metrics

00:20:32,630 --> 00:20:36,470
endpoints so it basically hits that

00:20:34,160 --> 00:20:38,060
endpoint every 30 seconds every 10

00:20:36,470 --> 00:20:40,640
seconds whatever interval you configure

00:20:38,060 --> 00:20:43,450
and then use these days I mean this

00:20:40,640 --> 00:20:47,210
itself isn't very usable and consumable

00:20:43,450 --> 00:20:49,280
but what you can do is Prometheus has

00:20:47,210 --> 00:20:52,370
its own graphing capability but they are

00:20:49,280 --> 00:20:54,440
fairly limited most people how they use

00:20:52,370 --> 00:20:56,540
it is they install graph Anna on top of

00:20:54,440 --> 00:20:58,880
it and then either you can create graphs

00:20:56,540 --> 00:21:00,860
like this for your application again

00:20:58,880 --> 00:21:03,110
this is a sample you can choose whatever

00:21:00,860 --> 00:21:05,150
things you are interested in and drag

00:21:03,110 --> 00:21:06,980
and drop particular metrics and create a

00:21:05,150 --> 00:21:09,410
graph over time so you when there's a

00:21:06,980 --> 00:21:11,570
problem you can figure out Oh at this

00:21:09,410 --> 00:21:13,430
point this resource utilization peaked

00:21:11,570 --> 00:21:18,410
out so I need to go and look at this and

00:21:13,430 --> 00:21:20,210
go that way Prometheus can also be

00:21:18,410 --> 00:21:22,040
integrated very well with alerting

00:21:20,210 --> 00:21:23,930
system so you can start and have some

00:21:22,040 --> 00:21:26,900
alerting mechanism to save in the unity

00:21:23,930 --> 00:21:30,760
resource utilization goes over 90% or

00:21:26,900 --> 00:21:30,760
whatever then I'm honored to be doing it

00:21:32,950 --> 00:21:37,540
and these are just the basic things that

00:21:35,600 --> 00:21:41,360
I said but there is a full-fledged

00:21:37,540 --> 00:21:42,770
tutorial to which takes you step by step

00:21:41,360 --> 00:21:44,300
on what did you where to get the

00:21:42,770 --> 00:21:47,330
resources what commands to run how do

00:21:44,300 --> 00:21:49,970
you use them in your in a basic hello

00:21:47,330 --> 00:21:53,050
world Express app essentially at the

00:21:49,970 --> 00:21:55,220
cloud native Jaso Conn get up and

00:21:53,050 --> 00:21:56,900
basically if you follow the instructions

00:21:55,220 --> 00:22:00,410
you will be able to create an expose app

00:21:56,900 --> 00:22:03,290
and add held at cube entities deploy

00:22:00,410 --> 00:22:05,120
monitor all of that so if you want to

00:22:03,290 --> 00:22:08,750
get started on any of that then please

00:22:05,120 --> 00:22:10,490
follow this by no means this is

00:22:08,750 --> 00:22:13,040
everything we want to do and this is not

00:22:10,490 --> 00:22:14,780
just these five things on I'm going to

00:22:13,040 --> 00:22:17,810
make your application completely cloud

00:22:14,780 --> 00:22:19,790
native but this is a start and we've

00:22:17,810 --> 00:22:21,470
started this initiative in July so it's

00:22:19,790 --> 00:22:24,350
not been very long since we've done this

00:22:21,470 --> 00:22:26,930
but if you want to participate this is

00:22:24,350 --> 00:22:28,730
completely open source look at things

00:22:26,930 --> 00:22:31,400
raise issues if you find something that

00:22:28,730 --> 00:22:34,280
doesn't work submit PRS if you want to

00:22:31,400 --> 00:22:38,020
fix something or find us some slack and

00:22:34,280 --> 00:22:40,820
tweet and just join in the fun thank you

00:22:38,020 --> 00:22:41,380
if there are any questions you can do

00:22:40,820 --> 00:22:45,089
them in the break

00:22:41,380 --> 00:22:45,089

YouTube URL: https://www.youtube.com/watch?v=e0OTorF2XlI


