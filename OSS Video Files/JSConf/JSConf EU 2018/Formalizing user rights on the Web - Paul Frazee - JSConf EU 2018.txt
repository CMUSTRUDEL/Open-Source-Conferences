Title: Formalizing user rights on the Web - Paul Frazee - JSConf EU 2018
Publication date: 2018-07-23
Playlist: JSConf EU 2018
Description: 
	How should we think about harassment, bullying, bots, and misinformation on the Web? Have we failed as an industry to protect users, and do we need to aggressively police our spaces? If so, how do we respond to concerns about censorship by big business?

In this talk, I’ll propose a formal framework for user rights on the Web. I’ll explore the idea that the rights of users on the Web are not all legal, instead most are founded in the architecture of the Web itself, and by modifying the Web’s architecture, we can build the political foundation for democratic representation, community moderation, and social responsibility in an online society.

OMG JSConf EU is coming back in 2019 https://2019.jsconf.eu/
Captions: 
	00:00:09,760 --> 00:00:11,080
Thanks so much.

00:00:11,090 --> 00:00:15,350
I'm incredibly honoured to be here.

00:00:15,350 --> 00:00:20,280
Today I'm talking about formalising former right on the web.

00:00:20,280 --> 00:00:24,170
Let me give context who I am.

00:00:24,170 --> 00:00:27,700
I'm in Austin Texas, a JavaScript developer.

00:00:27,700 --> 00:00:33,570
I've been working with Node.js for five years, making websites and applications for just

00:00:33,570 --> 00:00:35,249
about all my life.

00:00:35,249 --> 00:00:42,030
I have an enormous amount of passion for distributed systems and peer-to-peer technology.

00:00:42,030 --> 00:00:46,960
I think they are technically fascinating but there's an incredible potential in these kind

00:00:46,960 --> 00:00:52,069
of technologies that haven't been leveraged in the web, so that is what I pursue a lot

00:00:52,069 --> 00:00:53,579
in my daily life.

00:00:53,579 --> 00:01:00,299
I was one of the people who helped start the secure scuttlebutt project which is a secure

00:01:00,299 --> 00:01:04,589
peer-to-peer network.

00:01:04,589 --> 00:01:07,940
I spend my days now working on the Beaker browser.

00:01:07,940 --> 00:01:13,580
It is an experimental peer-to-peer web browser.

00:01:13,580 --> 00:01:19,180
We want to see if it is possible to let users publish websites without having to use servers

00:01:19,180 --> 00:01:20,720
at all.

00:01:20,720 --> 00:01:25,600
We want to see if you could have a button perhaps if the browser, you can click that,

00:01:25,600 --> 00:01:30,421
then public the site from your laptop or a mobile device, and then you don't have to

00:01:30,421 --> 00:01:34,680
worry about operations and things are much easier for you.

00:01:34,680 --> 00:01:44,980
Curious to hear how that works, you should listen to Tara Vancil's talk tonight.

00:01:44,980 --> 00:01:50,220
What I'm going to be talking about is a little bit about animates us to work on this project,

00:01:50,220 --> 00:01:55,170
why we care so much about this idea, and we think it can have a positive effect on the

00:01:55,170 --> 00:01:56,450
web.

00:01:56,450 --> 00:02:00,280
Now, we are huge advocate for the open web.

00:02:00,280 --> 00:02:04,320
I think it's incredible that we have this shared platform that's not encumbered by patents

00:02:04,320 --> 00:02:11,379
or licences, and it isn't owned by any one corps ratings, but lately the web has been

00:02:11,379 --> 00:02:13,579
struggling with systemic problems.

00:02:13,579 --> 00:02:19,409
Issues with things like bullying, harassment online, misinformation campaigns that affect

00:02:19,409 --> 00:02:25,440
our elections, and infringement of personal privacy, and honestly, the list goes on.

00:02:25,440 --> 00:02:31,150
Now, I think in a way, all of these systemic problems stem or have some kind of relationship

00:02:31,150 --> 00:02:38,620
to one basic question, and that question is: who is in charge?

00:02:38,620 --> 00:02:43,319
I don't mean this in a petty sense like who happens to be the market leader from one moment

00:02:43,319 --> 00:02:49,359
to another, but in a profound sense: who has the authority to govern or communities and

00:02:49,359 --> 00:02:52,290
our applications, and our online lives?

00:02:52,290 --> 00:02:56,200
More importantly than that, perhaps, what gives them that right to be the people that

00:02:56,200 --> 00:02:59,209
govern our experiences?

00:02:59,209 --> 00:03:03,810
On top of that, I think we also should understand what kind of rights we have as users.

00:03:03,810 --> 00:03:06,249
What rights do we have to control the software we use?

00:03:06,249 --> 00:03:10,620
What rights do we have to control the algorithms that affect our perception of the world.

00:03:10,620 --> 00:03:14,840
What rights do we have to control the moderation policies that affect these issues that affect

00:03:14,840 --> 00:03:16,599
us every day?

00:03:16,599 --> 00:03:20,639
And so, you can talk about political rights.

00:03:20,639 --> 00:03:26,939
In fact, there's been amazing work with the GDPR, but there's something else, a kind of

00:03:26,939 --> 00:03:31,499
right that emerges, I believe, specifically from the technical design of the web, and

00:03:31,499 --> 00:03:34,330
the architectures of networks in general.

00:03:34,330 --> 00:03:39,269
And this technical right is derived from what everybody is able to do.

00:03:39,269 --> 00:03:43,010
So that is the right that we are going to be talking about here today.

00:03:43,010 --> 00:03:46,930
Now, I think it is important that we go through some of the stuff that is the problem right

00:03:46,930 --> 00:03:51,769
now which means we are going to have to go through some offensive content — I tried

00:03:51,769 --> 00:03:52,889
to censor it a little bit.

00:03:52,889 --> 00:03:56,030
It's kind of annoying.

00:03:56,030 --> 00:03:57,830
Let's talk about harassment.

00:03:57,830 --> 00:04:01,840
Well, mostly talk about Twitter, but Twitter of course is not the only community that has

00:04:01,840 --> 00:04:02,870
this problem.

00:04:02,870 --> 00:04:06,989
Here is Susan Fowler talking about anti-Semitism filling her notifications.

00:04:06,989 --> 00:04:10,500
Lately, Jessica had a death threat.

00:04:10,500 --> 00:04:17,730
She had to struggle a lit bit to get Twitter's moderation teams to take it seriously.

00:04:17,730 --> 00:04:22,530
You don't have to go far to find this kind of stuff.

00:04:22,530 --> 00:04:23,830
I don't think this is news to anybody.

00:04:23,830 --> 00:04:26,890
The internet is full of trolls, right?

00:04:26,890 --> 00:04:31,340
The running joke at this point is that Twitter is a cesspool.

00:04:31,340 --> 00:04:35,690
Well, you could say that this is just how it goes.

00:04:35,690 --> 00:04:39,900
We should develop a thick skin, and perhaps this kind of behaviour is just the cost of

00:04:39,900 --> 00:04:42,420
free speech.

00:04:42,420 --> 00:04:45,950
Perhaps that's the case, except that I'm beginning to believe that this kind of behaviour is

00:04:45,950 --> 00:04:48,690
affecting our culture, and our political systems.

00:04:48,690 --> 00:04:51,280
I don't think I'm the only one to think that.

00:04:51,280 --> 00:04:56,220
At the end of last year, Reid Hoffman weighed in on this issue, how he would save the problems

00:04:56,220 --> 00:05:01,620
of hate speech, abuse on our social media platforms.

00:05:01,620 --> 00:05:05,840
Reid Hoffman is the co-founder of LinkedIn.

00:05:05,840 --> 00:05:12,070
In this interview, he gave his prescription, and it was this: these are private businesses.

00:05:12,070 --> 00:05:15,670
All these social media platforms are private businesses, and they can set policies about

00:05:15,670 --> 00:05:21,290
what kind of behaviour they expect from their users, from their participants on the platform.

00:05:21,290 --> 00:05:25,850
The metaphor he uses it's like a hotel or restaurant.

00:05:25,850 --> 00:05:29,000
You can set a policy, no shirt, no service.

00:05:29,000 --> 00:05:31,240
The same thing here.

00:05:31,240 --> 00:05:37,650
Project a more opinionated view about what kind of speech is permissible on your platform.

00:05:37,650 --> 00:05:39,070
That's what he is putting out.

00:05:39,070 --> 00:05:43,750
Now, to some degree, I think he has a fair point.

00:05:43,750 --> 00:05:50,440
But what he is suggesting really highlights what I think is kind of a constant probably

00:05:50,440 --> 00:05:51,750
with how the web works.

00:05:51,750 --> 00:05:56,920
It kind of highlights how we are stuck between a rock and a hard place on this matter.

00:05:56,920 --> 00:06:02,490
Because, on the one hand, I'm not the sort of person who is animated by concerns about

00:06:02,490 --> 00:06:04,270
censorship.

00:06:04,270 --> 00:06:05,300
That's not my day-to-day.

00:06:05,300 --> 00:06:10,520
My concern is more about bullying or death threats to somebody I love, or misinformation

00:06:10,520 --> 00:06:13,990
campaigns that might affect the elections in my country.

00:06:13,990 --> 00:06:16,000
That bothers me a lot more.

00:06:16,000 --> 00:06:21,810
At the same time, I think you can't ignore the fact that we had a very serious conversation

00:06:21,810 --> 00:06:25,350
about the possibility that Mark Zuckerberg could run for president.

00:06:25,350 --> 00:06:30,260
This guy runs one of the most powerful information-sharing platforms in the world — over 2 billion

00:06:30,260 --> 00:06:34,290
users use Facebook to get their daily news.

00:06:34,290 --> 00:06:39,160
So the idea that we at this juncture would start to ask corporations more proactively

00:06:39,160 --> 00:06:45,210
to police our speech is I think a slightly bad idea.

00:06:45,210 --> 00:06:48,020
So it seems like we're stuck between these two options.

00:06:48,020 --> 00:06:52,560
On the one hand, you have trolltopia where everything is permissible, and, on the other

00:06:52,560 --> 00:06:59,490
hand, you have a corporate hegemony where speech is being policed by big businesses.

00:06:59,490 --> 00:07:05,020
There ought to be something in between this, something driven perhaps by users.

00:07:05,020 --> 00:07:06,620
Yet it's not there.

00:07:06,620 --> 00:07:13,080
Assess it happens, Mark Zuckerberg is not particularly interested in Reid Hoffman's

00:07:13,080 --> 00:07:14,080
suggestion.

00:07:14,080 --> 00:07:17,960
He's extremely adamant that Facebook is not a media company.

00:07:17,960 --> 00:07:20,000
They're just a tools company.

00:07:20,000 --> 00:07:23,900
If they were a media company, they would control what kind of media is put on Facebook.

00:07:23,900 --> 00:07:24,900
That's his point.

00:07:24,900 --> 00:07:26,150
That's not their job.

00:07:26,150 --> 00:07:30,730
He says this because, to be honest, he want Facebook to be popular.

00:07:30,730 --> 00:07:34,000
As soon as they start getting into these hard decisions about what sort of behaviour is

00:07:34,000 --> 00:07:42,260
per missable, they get into partisan fights and using losers because they are seen as

00:07:42,260 --> 00:07:43,260
biased.

00:07:43,260 --> 00:07:45,720
This sort of dove-tails nicely into a conversation about misinformation.

00:07:45,720 --> 00:07:50,610
We are still in our systemic problems of the talk here.

00:07:50,610 --> 00:07:56,420
Let's talk a little bit what happens in the 2016 American election.

00:07:56,420 --> 00:08:00,720
This is a Washington Post article and we will go through some of the ads that were run illegally

00:08:00,720 --> 00:08:06,950
by a Russian propaganda arm using Facebook's ad-targeting platform.

00:08:06,950 --> 00:08:11,250
If you were opposed to Muslim immigration, you get this law from this Russian propaganda

00:08:11,250 --> 00:08:15,590
organisation saying Shari'ah law should the not be debatable.

00:08:15,590 --> 00:08:19,360
If you were a Christian Conservative, you got Jesus arm wrestling the devil, and if

00:08:19,360 --> 00:08:26,610
Clinton won, the devil won the election.

00:08:26,610 --> 00:08:30,180
If you were a southern conservative, you got a fake tea-party endorsement for trump.

00:08:30,180 --> 00:08:37,060
If you're an LGBT supporter, you got this ad against the west borough Baptist church.

00:08:37,060 --> 00:08:45,560
If you are were a Hillary Clinton supporter, you got — the strategy they were pursuing

00:08:45,560 --> 00:08:49,900
is getting to you click like, because then they could push more propaganda to you.

00:08:49,900 --> 00:08:53,930
The strategy was to strengthen trump's base and divide Clinton's.

00:08:53,930 --> 00:09:00,790
There is a lot of examples of what happened and what went wrong in the 2016 election with

00:09:00,790 --> 00:09:01,880
misinformation.

00:09:01,880 --> 00:09:05,860
If you want more, look being at Reddit, and Twitter has its own problems.

00:09:05,860 --> 00:09:11,890
The next to fit in with the time I have was important to illustrate because it cuts to

00:09:11,890 --> 00:09:14,380
the heart of how this sort of stuff happens.

00:09:14,380 --> 00:09:20,130
That's this one: this is an article published by ProPublica last year.

00:09:20,130 --> 00:09:25,750
There's an advertising demographic on Facebook of Jew-haters.

00:09:25,750 --> 00:09:27,900
You could target them with your ads.

00:09:27,900 --> 00:09:32,990
It was apparently 2,274 people who put this as their field of study.

00:09:32,990 --> 00:09:36,740
Now, I don't know if they thought they were being funny or being serious — it doesn't

00:09:36,740 --> 00:09:38,170
really matter.

00:09:38,170 --> 00:09:43,270
But, somehow, Facebook's algorithms picked up on this and made it a group you could advertise

00:09:43,270 --> 00:09:44,270
to.

00:09:44,270 --> 00:09:46,990
I want to point out the UI element underneath there.

00:09:46,990 --> 00:09:49,470
Yes, I think so.

00:09:49,470 --> 00:09:53,120
Okay, why is this happening?

00:09:53,120 --> 00:09:59,600
Is Facebook intentionally setting out to collude with the Russians, to mess with our elections

00:09:59,600 --> 00:10:01,120
in America?

00:10:01,120 --> 00:10:05,310
Is there some Facebook employee that is adding that Jew-hater entry into the database?

00:10:05,310 --> 00:10:06,810
I don't think so.

00:10:06,810 --> 00:10:07,810
I don't think that is what happened.

00:10:07,810 --> 00:10:11,490
I don't know, but I doubt it.

00:10:11,490 --> 00:10:14,420
What I think is happening here is the same thing that happens with every Silicon Valley

00:10:14,420 --> 00:10:20,480
company trying to achieve enormous amounts of scale: they're just using algorithms.

00:10:20,480 --> 00:10:28,690
They're accepting user data without considering just how problematic that user data can be.

00:10:28,690 --> 00:10:30,980
This is a screen shot of YouTube.

00:10:30,980 --> 00:10:33,192
David Hogg is one of the Parkland Shoot be survivors.

00:10:33,192 --> 00:10:38,130
He survived a high school shooting.

00:10:38,130 --> 00:10:45,920
He decided to become vocal about his opposition, or his support, rather, for gun control.

00:10:45,920 --> 00:10:49,430
People who didn't like his politics decided to spread a conspiracy theory that he's a

00:10:49,430 --> 00:10:53,360
paid political actor, a crisis actor.

00:10:53,360 --> 00:10:57,482
And so I guess enough people searched for that on YouTube because that started to show

00:10:57,482 --> 00:11:01,680
up as the only thing when you type into his names that you should look into him being

00:11:01,680 --> 00:11:02,870
a crisis actor.

00:11:02,870 --> 00:11:09,620
It is a combination of these algorithms, and then, what I could only describe as I suppose

00:11:09,620 --> 00:11:14,740
the political weaponisation that is occurring on the web, and will continue to occur, because

00:11:14,740 --> 00:11:16,930
these platforms have the power to push an agenda.

00:11:16,930 --> 00:11:22,800
And every time you have one of these algorithms, that blindly trust user input, that's another

00:11:22,800 --> 00:11:23,800
vector.

00:11:23,800 --> 00:11:27,580
It's another opportunity to push propaganda.

00:11:27,580 --> 00:11:34,050
Okay, these are problems.

00:11:34,050 --> 00:11:38,710
They're problems in how we govern our communities online.

00:11:38,710 --> 00:11:45,230
And, when you see problems like this, you naturally have to ask who is in charge?

00:11:45,230 --> 00:11:48,830
Whose job is it to solve these kinds of problems?

00:11:48,830 --> 00:11:54,930
And I think this is where we see technology and civics collide in an incredibly specific

00:11:54,930 --> 00:11:55,930
way.

00:11:55,930 --> 00:12:00,850
Because, we are talking about the system of authority, and the system of governance.

00:12:00,850 --> 00:12:07,440
Whose job is it to maintain these communities online?

00:12:07,440 --> 00:12:11,080
If you look at Reddit, it's ostensibly designed to be a democracy.

00:12:11,080 --> 00:12:14,589
In fact, it's probably one of the most democratic websites online.

00:12:14,589 --> 00:12:18,430
The users submit stories and vote what shows up on the front page.

00:12:18,430 --> 00:12:20,320
It is great.

00:12:20,320 --> 00:12:24,760
But if you actually look at the civic structure of Reddit, it is not actually a democracy.

00:12:24,760 --> 00:12:29,270
It is actually more like a monarch can I because you have the — monarchy, because you have

00:12:29,270 --> 00:12:35,940
users submitting on comments, and above that, you have moderator users, and they have the

00:12:35,940 --> 00:12:40,710
power to remove content and users, and things like that, and on top, you have the Reddit

00:12:40,710 --> 00:12:44,960
staff who are basically the kings of this community.

00:12:44,960 --> 00:12:46,830
They have total control.

00:12:46,830 --> 00:12:49,380
They can change the code, they can change the data, they can do anything.

00:12:49,380 --> 00:12:56,030
And, in fact, they highlighted this about a year ago when the CEO of Reddit decided

00:12:56,030 --> 00:13:00,220
to jump into TheDonald and manually edit some of the users.

00:13:00,220 --> 00:13:02,290
He trolled the trolls, right?

00:13:02,290 --> 00:13:07,060
He figured it would be funny.

00:13:07,060 --> 00:13:11,090
If you don't know how websites work, you might be shocked to realise that somebody on the

00:13:11,090 --> 00:13:14,310
Reddit staff can change people's comments.

00:13:14,310 --> 00:13:19,330
But I think probably most of us here are technologists, and intuitively aware of course they can do

00:13:19,330 --> 00:13:23,390
that — they run the server, right?

00:13:23,390 --> 00:13:29,000
That dove-tails into this next question: what is it about the web that makes it like this?

00:13:29,000 --> 00:13:33,580
Why do the Reddit staff act as the king and have total authority?

00:13:33,580 --> 00:13:38,399
I think it flows directly from this thick server design, the architecture of applications

00:13:38,399 --> 00:13:39,399
on the web.

00:13:39,399 --> 00:13:46,290
Fixed server is a technical term meaning we put the business logic into the server, and,

00:13:46,290 --> 00:13:48,790
as a result, all the authority.

00:13:48,790 --> 00:13:51,420
If you diagram it, it looks like this.

00:13:51,420 --> 00:13:55,649
You got the thick server up at the to be, and you have the database in there.

00:13:55,649 --> 00:13:57,360
You have all the code.

00:13:57,360 --> 00:14:00,480
And you have all the authority placed in the server.

00:14:00,480 --> 00:14:06,620
And then you have the web browsers, the clients, and you actually call them a thin client.

00:14:06,620 --> 00:14:08,360
Thick server, thin client.

00:14:08,360 --> 00:14:13,090
And the thin client is just a few of this data, just a rendering of what is occurring

00:14:13,090 --> 00:14:14,150
on the server.

00:14:14,150 --> 00:14:17,690
Any time you want to do something as one of the clients, you actually have to ask the

00:14:17,690 --> 00:14:19,920
server to do it for you.

00:14:19,920 --> 00:14:23,600
So all the authority lives in the server, and, if you have any authority as a user,

00:14:23,600 --> 00:14:28,680
you're borrowing it from the server in a way.

00:14:28,680 --> 00:14:31,500
What is it about the web that makes it like that?

00:14:31,500 --> 00:14:33,140
Why are the servers king?

00:14:33,140 --> 00:14:36,760
There is nothing in the nature of computers that make it this way.

00:14:36,760 --> 00:14:42,070
If you look at computers in a state of nature, hanging out next to each other, look at a

00:14:42,070 --> 00:14:49,140
server, you look at a normal desktop computer, or a laptop, sure, the server is more powerful,

00:14:49,140 --> 00:14:52,750
but that doesn't necessarily meaning that the server ought to be king.

00:14:52,750 --> 00:14:56,700
Server doesn't have to be in charge but that is what it is.

00:14:56,700 --> 00:15:00,300
Why is it that if it is not in the hardware?

00:15:00,300 --> 00:15:02,890
The answer has to do with this.

00:15:02,890 --> 00:15:08,490
It has to do with the specifications and the standards that define the web — HTTP, HTML,

00:15:08,490 --> 00:15:11,220
all the web APIs.

00:15:11,220 --> 00:15:17,760
They encode this set of behaviours.

00:15:17,760 --> 00:15:24,240
This is a very clear example of how technology doesn't just interact with civics, but it

00:15:24,240 --> 00:15:27,250
actually drives civics.

00:15:27,250 --> 00:15:32,380
It defines what the civic structure of a community is going to be.

00:15:32,380 --> 00:15:36,331
In a way you could say that these specifications are like a shared contract between us, or

00:15:36,331 --> 00:15:40,580
perhaps even like a constitution.

00:15:40,580 --> 00:15:46,560
Because they define how our online society of computers are going to work with each other.

00:15:46,560 --> 00:15:49,200
There's nothing in the hardware that does this.

00:15:49,200 --> 00:15:50,200
It's in the specification.

00:15:50,200 --> 00:15:55,050
It's in the shared agreement, these rules that bind us together and define how our computers

00:15:55,050 --> 00:15:56,960
relate to each other.

00:15:56,960 --> 00:16:03,200
It is a contract or constitution because it is just an agreement between the devices to

00:16:03,200 --> 00:16:06,100
follow these rules.

00:16:06,100 --> 00:16:11,330
It is in the constitution of the kind that these people made but the kind made by people

00:16:11,330 --> 00:16:14,920
like this, the hackers that set the web in motion.

00:16:14,920 --> 00:16:20,720
They produce documents that look like this but it produce specs like this.

00:16:20,720 --> 00:16:26,020
There is a parallel there, because all of our computers, everybody here, we use the

00:16:26,020 --> 00:16:28,490
image tag.

00:16:28,490 --> 00:16:30,450
That's how that happens.

00:16:30,450 --> 00:16:36,149
So, when we ask what gives the server the right to be king over our application, well,

00:16:36,149 --> 00:16:38,100
the answer is that it's in the architecture.

00:16:38,100 --> 00:16:40,450
It is how the web is designed.

00:16:40,450 --> 00:16:46,110
Now, it is not just the authority model that is encoded in these architectures, it is also

00:16:46,110 --> 00:16:49,840
the individual capabilities of everybody in the network.

00:16:49,840 --> 00:16:53,170
What can my computer do on the web?

00:16:53,170 --> 00:16:59,160
Those questions are answered in the specifications, and this gets us back to that idea of a right.

00:16:59,160 --> 00:17:00,660
What rights does my machine have?

00:17:00,660 --> 00:17:02,430
What rights do the server have?

00:17:02,430 --> 00:17:07,959
I'm going to try to give us a term here — an ark technical architectural right, a right

00:17:07,959 --> 00:17:14,770
that gives me on my device encoded in the web, or in any network.

00:17:14,770 --> 00:17:17,220
Let's go through examples to make it intuitive.

00:17:17,220 --> 00:17:19,390
Here we have a local area network.

00:17:19,390 --> 00:17:22,880
We will go with the natural design.

00:17:22,880 --> 00:17:24,270
Everybody can connect to everybody else.

00:17:24,270 --> 00:17:26,620
So we have Alice, Bob, and Carla.

00:17:26,620 --> 00:17:29,360
Their machines can talk to each other.

00:17:29,360 --> 00:17:34,309
You might technology there's a architectural right in this design, a right for everybody

00:17:34,309 --> 00:17:39,799
to connect to everybody else.

00:17:39,799 --> 00:17:44,630
You might decide that Alice is more important and you maybe can't trust Bob and Carla in

00:17:44,630 --> 00:17:48,260
your architecture, so you could do it like this where only Al-shortlist allowed to create

00:17:48,260 --> 00:17:52,430
new connections, and Bob and Carla just have to listen.

00:17:52,430 --> 00:17:58,090
You have to do it this way but then you would have two kinds of citizens — Alice who has

00:17:58,090 --> 00:18:03,310
the right to connect, and Bob and Carla who can't.

00:18:03,310 --> 00:18:04,310
Let's look at another example of the internet.

00:18:04,310 --> 00:18:09,110
The internet is like our land because the internet has the same basic principle: everybody

00:18:09,110 --> 00:18:11,090
should be able to connect to everybody else.

00:18:11,090 --> 00:18:13,040
Should be able to connect to everybody else.

00:18:13,040 --> 00:18:17,750
You could say that there is a right to connect globally encoded in the design of the internet,

00:18:17,750 --> 00:18:20,350
in the architecture of the internet.

00:18:20,350 --> 00:18:23,980
Again, you didn't have to do it this way.

00:18:23,980 --> 00:18:28,260
You could do it like China has done it — excuse me, I just want to point out, sometimes, the

00:18:28,260 --> 00:18:31,760
internet doesn't work quite so well because there aren't enough IP addresses in their

00:18:31,760 --> 00:18:33,150
firewalls.

00:18:33,150 --> 00:18:36,110
That's what that slide is about.

00:18:36,110 --> 00:18:37,200
You don't have to do it this way.

00:18:37,200 --> 00:18:42,830
You could do it like China, set up a global government firewall, or you could set up something

00:18:42,830 --> 00:18:46,930
like a municipal server somewhere that you have to talk to and ask permission to make

00:18:46,930 --> 00:18:48,770
a connection.

00:18:48,770 --> 00:18:51,760
That is how you could do the internet.

00:18:51,760 --> 00:18:53,420
We chose not to.

00:18:53,420 --> 00:18:56,710
We chose to make it so that everybody can connect to everybody else, and I think that

00:18:56,710 --> 00:18:57,850
is important.

00:18:57,850 --> 00:19:03,290
It means there is a value set encoded in that standard in all the standards that define

00:19:03,290 --> 00:19:04,290
the web.

00:19:04,290 --> 00:19:06,220
A right to connect globally.

00:19:06,220 --> 00:19:13,100
It's not a neutral decision.

00:19:13,100 --> 00:19:19,640
So we have an idea about how architectural rights work.

00:19:19,640 --> 00:19:21,280
Let's take a look at the web.

00:19:21,280 --> 00:19:25,750
You might say there are two kinds of establishes on the web, like we were talking about before:

00:19:25,750 --> 00:19:27,650
the client and the server.

00:19:27,650 --> 00:19:31,870
The client is your browser or user agent, so let's step through some of the rights that

00:19:31,870 --> 00:19:34,280
each of these citizens on the web has.

00:19:34,280 --> 00:19:39,710
The client of course has the right to browse, go from one website to another and visit content.

00:19:39,710 --> 00:19:41,450
Of course they can do that.

00:19:41,450 --> 00:19:43,380
Clients have the right to filter as well.

00:19:43,380 --> 00:19:44,970
You can run an ad blocker.

00:19:44,970 --> 00:19:48,770
You might call this a right to mutate because you can run extensions and change things once

00:19:48,770 --> 00:19:51,179
you receive them.

00:19:51,179 --> 00:19:53,870
This is open to interpretation, but I would say those are the two.

00:19:53,870 --> 00:19:57,530
This is what a client is allowed to do on the web.

00:19:57,530 --> 00:20:00,810
Let's look at a server.

00:20:00,810 --> 00:20:02,230
Servers have the right to an identity.

00:20:02,230 --> 00:20:05,230
An accuracy, a .com.

00:20:05,230 --> 00:20:07,700
Only servers have that on the web.

00:20:07,700 --> 00:20:15,500
Browsers don't have addresses or identified — you need to ask a server

00:20:15,500 --> 00:20:19,441
to make an identity for you because they are the only ones with the right to do that, that's

00:20:19,441 --> 00:20:22,030
why I'm twitter.com/username.

00:20:22,030 --> 00:20:27,570
A right to publish.

00:20:27,570 --> 00:20:31,760
This is what a server is designed to do on the web.

00:20:31,760 --> 00:20:34,020
They're publishing that content.

00:20:34,020 --> 00:20:35,990
That's a right that only the server has.

00:20:35,990 --> 00:20:37,220
The client can't do that.

00:20:37,220 --> 00:20:41,960
If I want to publish something, I either need to be a server, or I need to ask a server

00:20:41,960 --> 00:20:47,380
to do something, and that's why I do my tweets on twitter.com.

00:20:47,380 --> 00:20:52,200
Because they control the publishing, servers have a right to moderate as well.

00:20:52,200 --> 00:20:54,470
They can choose what they publish.

00:20:54,470 --> 00:20:58,680
Sort of falls naturally out from having been dominate right to publishing, and then servers

00:20:58,680 --> 00:21:01,330
can also choose what they had they deploy.

00:21:01,330 --> 00:21:11,280
They get to choose the data model, where the data goes been when you look at this citizenship

00:21:11,280 --> 00:21:18,400
on the web it's unsurprising that there is an asymmetrical power here, not only do servers

00:21:18,400 --> 00:21:22,090
have more rights but way better rights.

00:21:22,090 --> 00:21:24,620
That's the hurry to describe how the web applications work.

00:21:24,620 --> 00:21:26,750
The clients are passive.

00:21:26,750 --> 00:21:31,610
The best they can do is make a choice about where they go.

00:21:31,610 --> 00:21:35,120
When you're talking about these problems of governance online, how do we solve these tough

00:21:35,120 --> 00:21:41,480
questions about moderation policies and the truth of information?

00:21:41,480 --> 00:21:44,280
How can we make governance better?

00:21:44,280 --> 00:21:49,790
How can we give new rights to clients so that the civic structure is no longer being constrained

00:21:49,790 --> 00:21:55,950
by the design of the web, and the architecture can have a more perhaps even democratic design

00:21:55,950 --> 00:21:57,460
in how it is governed?

00:21:57,460 --> 00:22:01,850
Can we make it so that the client has the right to publish instead of always depending

00:22:01,850 --> 00:22:03,350
on a server to do it for them?

00:22:03,350 --> 00:22:08,270
Can we make it even so that the client has the right to having an identity so that my

00:22:08,270 --> 00:22:12,990
personal identity is no longer tied to whatever happens to Twitter?

00:22:12,990 --> 00:22:17,550
Could we even give clients the right to deploy the code so they can decide how their application

00:22:17,550 --> 00:22:19,700
should work?

00:22:19,700 --> 00:22:28,940
Now I mentioned at the beginning of that talk that I work on peer-to-peer networks.

00:22:28,940 --> 00:22:33,460
In this context, peer-to-peer networks really fascinate me, because, unlike client server

00:22:33,460 --> 00:22:39,360
networks, they connect nodes in a way such that they have the same capabilities.

00:22:39,360 --> 00:22:43,130
The rights are completely evenly distributed in a peer-to-peer network.

00:22:43,130 --> 00:22:48,600
That's implicit in the name — we're all just peers.

00:22:48,600 --> 00:22:52,980
I think that has an equalising force across the network.

00:22:52,980 --> 00:23:00,640
It would be easy in a way to make this talk largely about free software because in a lot

00:23:00,640 --> 00:23:05,600
of ways, it is deeply connected, this ability to control our right to modify how the experience

00:23:05,600 --> 00:23:08,740
works, but I actually think it is a little bit bigger than that.

00:23:08,740 --> 00:23:13,580
I think it's about our ability to decide how code works as a community.

00:23:13,580 --> 00:23:21,960
That makes it a question of civics, not just free software.

00:23:21,960 --> 00:23:31,240
Every time we ask Facebook to make a change to their interfaces, it's kind of a big deal.

00:23:31,240 --> 00:23:35,440
It requires those companies to take a risk to potentially loose users, or change something

00:23:35,440 --> 00:23:38,680
that's fundamental to their success in the past, and, as a result, they might not be

00:23:38,680 --> 00:23:42,179
able to make those kind of risks.

00:23:42,179 --> 00:23:46,990
When users have the option to develop the software on their own, to pursue their own

00:23:46,990 --> 00:23:50,470
needs, problems, and idea, they don't need to be afraid that it might hurt their bottom

00:23:50,470 --> 00:23:55,700
line, don't need to think in terms of maximising engagement numbers but can think about solve

00:23:55,700 --> 00:23:59,289
their own problems.

00:23:59,289 --> 00:24:03,150
As technologists, it is our job not to solve problems for people but to give them the tools

00:24:03,150 --> 00:24:08,000
to solve those problems so they can decide what is best for them, especially in these

00:24:08,000 --> 00:24:12,730
contexts of these global society the like the web is.

00:24:12,730 --> 00:24:16,590
I think perhaps it's easy to think of the web as being fixed and a stable place where

00:24:16,590 --> 00:24:20,630
we've experienced the full history of the web but the web has only been around for 30

00:24:20,630 --> 00:24:21,630
years.

00:24:21,630 --> 00:24:23,980
What will the next 30 years be like?

00:24:23,980 --> 00:24:28,350
Will we continue to use Facebook and Twitter?

00:24:28,350 --> 00:24:30,040
Is it going to be the same governance model?

00:24:30,040 --> 00:24:32,140
Still have servers as king?

00:24:32,140 --> 00:24:36,600
Or are we as users going to be defining much more of our experience in the future?

00:24:36,600 --> 00:24:41,190
Think about it, 30 years from now, is it going to be like this?

00:24:41,190 --> 00:24:45,110
I believe in civic engagement.

00:24:45,110 --> 00:24:50,260
I believe in all kinds — legal rights and regulations are powerful, and I'm extremely

00:24:50,260 --> 00:24:54,800
excited about what the GDPR will do for our industry.

00:24:54,800 --> 00:24:57,980
But the legal system is not our own option.

00:24:57,980 --> 00:25:05,340
As people who shape technology, and shape the web, we have powerful tools at our disposal.

00:25:05,340 --> 00:25:07,730
Technology is not neutral.

00:25:07,730 --> 00:25:12,380
It encodes a set of values, and, as a political system, it encodes a set of rights, so it

00:25:12,380 --> 00:25:17,280
will be up to us to decide what our online civic structures will be like.

00:25:17,280 --> 00:25:22,710
I hope you take this time to consider which structures of power and which rights you're

00:25:22,710 --> 00:25:24,650
enabling in the architectures that you build.

00:25:24,650 --> 00:25:26,030
Thank you all very much.

00:25:26,030 --> 00:25:26,860

YouTube URL: https://www.youtube.com/watch?v=x-ffpAkviM0


