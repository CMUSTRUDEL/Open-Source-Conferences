Title: Metro: Scaling JavaScript Build Systems - Miguel Jiménez Esún - JSConf EU 2018
Publication date: 2018-06-26
Playlist: JSConf EU 2018
Description: 
	React Native ships its own development server and bundler, which is both externally and internally used at Facebook. Making this process scalable and reliable is a hard process when you have a large codebase. We will be presenting and explaining its architecture, as well as the ideas behind it in order to make it fast; and we will roughly introduce the different output formats it is able to provide for maximum performance both on development and on iOS and Android production environments.

OMG JSConf EU is coming back in 2019 https://2019.jsconf.eu/
Captions: 
	00:00:09,500 --> 00:00:10,269
So, hello, everyone.

00:00:10,269 --> 00:00:15,909
My name is Miguel Jimenez and I work for the JavaScript Foundation team for Facebook London.

00:00:15,909 --> 00:00:20,490
And I'm going to be talking to you today about scaling JavaScript build systems.

00:00:20,490 --> 00:00:23,519
And more specifically, I'm going to be talking about Metro.

00:00:23,519 --> 00:00:31,080
I would like to show you a video about what the development process of React Native is.

00:00:31,080 --> 00:00:38,690
For those who don't know what React Native is, it's a framework by Facebook to use JavaScript

00:00:38,690 --> 00:00:45,199
to create hybrid mobile applications and uses React as well in order to represent the layout.

00:00:45,199 --> 00:00:46,949
This is the process.

00:00:46,949 --> 00:00:49,219
You change things into your editor.

00:00:49,219 --> 00:00:53,500
We have the iOS and the emulator catching it immediately.

00:00:53,500 --> 00:00:58,910
You can change layouts and colors.

00:00:58,910 --> 00:01:02,539
Those emulators will reflect your changes almost immediately.

00:01:02,539 --> 00:01:08,450
And the piece of infrastructure that is powering off of these interactions is actually Metro.

00:01:08,450 --> 00:01:14,420
So, to define it in a more formal way, we can say it's the development platform for

00:01:14,420 --> 00:01:15,420
React Native.

00:01:15,420 --> 00:01:23,650
And does that by exposing an HTTP server so client, layers can communicate and exposes

00:01:23,650 --> 00:01:26,520
a web socket server.

00:01:26,520 --> 00:01:33,110
It can build JavaScript and does other stuff.

00:01:33,110 --> 00:01:34,880
It deals with assets.

00:01:34,880 --> 00:01:40,899
When you want to add a photo or video, Metra adds this.

00:01:40,899 --> 00:01:47,520
It provides hot loading and it's extensible because the main interface is a function that

00:01:47,520 --> 00:01:49,829
works with Node's callback.

00:01:49,829 --> 00:01:55,070
Use that on the Node project or an express object.

00:01:55,070 --> 00:01:59,090
And last, but not least, it's used in the building process.

00:01:59,090 --> 00:02:04,450
If you have the app ready and you want to ship to the building source.

00:02:04,450 --> 00:02:14,610
Part of the building process whether it's X code for iOS or Android Studio, the process

00:02:14,610 --> 00:02:22,640
of taking your JavaScript application and putting that inside already done by Metra.

00:02:22,640 --> 00:02:27,630
Based on what we just explained, it look like there are a lot of alternatives in the open

00:02:27,630 --> 00:02:31,770
source world that pretty much fulfill all of these goals.

00:02:31,770 --> 00:02:33,990
Why is Facebook building Metro?

00:02:33,990 --> 00:02:35,230
There are a couple of reasons.

00:02:35,230 --> 00:02:38,360
We to want make it fast.

00:02:38,360 --> 00:02:40,890
And by fast, I mean, really fast.

00:02:40,890 --> 00:02:45,140
Our scale currently is at the tens of thousands of JavaScript modules.

00:02:45,140 --> 00:02:49,010
And we're aiming to be able to perform reloads on a sub second basis.

00:02:49,010 --> 00:02:54,500
So, dealing with such a large amount of code in so small time requires you to have a specific

00:02:54,500 --> 00:02:58,010
setup that we'll discuss in a minute.

00:02:58,010 --> 00:03:00,870
The second thing is we want it to be scalable.

00:03:00,870 --> 00:03:04,120
You're probably aware that JavaScript is kind of a trending language.

00:03:04,120 --> 00:03:05,780
You can see that based on the audience.

00:03:05,780 --> 00:03:10,900
So, the amount of times we have at Facebook just keeps growing.

00:03:10,900 --> 00:03:15,420
It has to work not only for today's requirements for these tens of thousands of JavaScript

00:03:15,420 --> 00:03:20,220
modules, but it also has to work for tomorrow.

00:03:20,220 --> 00:03:23,170
And the third reason is we want it to be integrated.

00:03:23,170 --> 00:03:32,120
So, Metra shaped a set of cool features that are integrated into the system.

00:03:32,120 --> 00:03:37,650
And my preferred one to explain this is the ability of red loading your React Native applications

00:03:37,650 --> 00:03:41,860
with command RR.

00:03:41,860 --> 00:03:48,200
The way it works is it brings up a global hot key listener.

00:03:48,200 --> 00:03:54,410
This gets inside and pushes toward the emulator, so they have to reload.

00:03:54,410 --> 00:03:58,010
This is for developers in most of the web.

00:03:58,010 --> 00:04:00,730
It gives them a seamless experience.

00:04:00,730 --> 00:04:06,540
And you need to have specific control on what your bundler is doing.

00:04:06,540 --> 00:04:09,650
And last, there's also a little bit of history.

00:04:09,650 --> 00:04:12,480
React Native was a project started five years ago.

00:04:12,480 --> 00:04:15,770
And back then, there weren't that many open source solutions.

00:04:15,770 --> 00:04:20,380
The first iteration for Metra was JS app server.

00:04:20,380 --> 00:04:31,430
Which was the React Native packager and we made it into what Metra is today.

00:04:31,430 --> 00:04:37,160
Now that we know what Metra is doing and why we're building it, I would like to get into

00:04:37,160 --> 00:04:39,590
the technical details of it.

00:04:39,590 --> 00:04:43,980
We're going to do that by covering all the different processes that are involved in creating

00:04:43,980 --> 00:04:44,980
a bundle.

00:04:44,980 --> 00:04:49,340
From the point where you have your code up until you get your app shipped into the app

00:04:49,340 --> 00:04:52,220
stores and executed by your customers.

00:04:52,220 --> 00:04:58,070
So, the first part is about monitoring the files on a project.

00:04:58,070 --> 00:05:01,220
As we said, we have quite a large code base at Facebook.

00:05:01,220 --> 00:05:04,160
And dealing with such number of files can be slow.

00:05:04,160 --> 00:05:08,200
Imagine that every single time you had to change a file you needed to re traverse your

00:05:08,200 --> 00:05:10,130
whole dependency graph.

00:05:10,130 --> 00:05:14,510
If we're talking about big code bases, this can take quite a lot of time.

00:05:14,510 --> 00:05:25,720
So, the way it works inside Metra is by using the module from a front project, which is

00:05:25,720 --> 00:05:26,720
Jest.

00:05:26,720 --> 00:05:27,720
We use Jest haste map.

00:05:27,720 --> 00:05:32,590
One of the features is it has the ability of monitoring your file changes and telling

00:05:32,590 --> 00:05:37,560
you of changes every time it detects something on your file system.

00:05:37,560 --> 00:05:42,410
Now, in order to achieve this, it uses Watchman as much as possible.

00:05:42,410 --> 00:05:48,410
This is another open source project from Facebook that monitors the file systems, but as a daemon

00:05:48,410 --> 00:05:51,060
process.

00:05:51,060 --> 00:05:56,900
If Metra gets killed and you restart, you don't have to query all of it again.

00:05:56,900 --> 00:06:02,570
You can query Watchman and get the changes that happened since the last time it was live

00:06:02,570 --> 00:06:06,740
which dramatically reduces the startup time.

00:06:06,740 --> 00:06:13,360
However, like all open source projects and general development, people do not have Watchman

00:06:13,360 --> 00:06:14,530
installed.

00:06:14,530 --> 00:06:18,330
If we don't see it on the file system, we fall back.

00:06:18,330 --> 00:06:24,250
This has a startup cost overhead, but after that, they're pretty much the same.

00:06:24,250 --> 00:06:29,310
So, now that we know all the files that are going to get into our project, the next thing

00:06:29,310 --> 00:06:32,500
is to transform them.

00:06:32,500 --> 00:06:39,800
And in that aspect Metra does what any other bundler will do, which is we use Babel.

00:06:39,800 --> 00:06:44,030
The thing that is a bit different in Metra compared to other bundling systems is the

00:06:44,030 --> 00:06:45,840
way we execute Metra.

00:06:45,840 --> 00:06:50,380
Transformation is an expensive process and it can take a lot of time.

00:06:50,380 --> 00:06:56,740
So, most bundlers will have their main process and they will execute the transpilation process

00:06:56,740 --> 00:06:58,870
one after another.

00:06:58,870 --> 00:07:03,580
Take A and B and so on and so forth.

00:07:03,580 --> 00:07:09,360
If you have a very large code base, this can take actually minutes to happen.

00:07:09,360 --> 00:07:12,110
Metra uses a different approach.

00:07:12,110 --> 00:07:18,480
Instead the main process doesn't transform a file, but spawns child professions called

00:07:18,480 --> 00:07:19,480
workers.

00:07:19,480 --> 00:07:22,040
Files are sent to the workers.

00:07:22,040 --> 00:07:28,190
The transpilation happens at the same time and then we return the result back.

00:07:28,190 --> 00:07:34,980
Now, we spawn approximately one worker per core, meaning a time reduction of 6 7X on

00:07:34,980 --> 00:07:37,150
a Macbook with eight cores.

00:07:37,150 --> 00:07:40,960
This cuts building time from minutes to seconds.

00:07:40,960 --> 00:07:44,680
Which is pretty good.

00:07:44,680 --> 00:07:49,050
The problem of transpilation has now problems.

00:07:49,050 --> 00:07:53,871
Imagine worker number one is dealing with a complex file and it turns out you change

00:07:53,871 --> 00:07:56,639
again A.JS.

00:07:56,639 --> 00:08:02,260
The naive approach is taking A and sending it to the first available worker which turns

00:08:02,260 --> 00:08:05,240
out to be worker number two.

00:08:05,240 --> 00:08:10,449
Part of the transpilation process, they tend to have intermediate caches to make further

00:08:10,449 --> 00:08:13,300
transpilations faster.

00:08:13,300 --> 00:08:19,000
If you remember, A was transformed by worker number one, we set the cache on worker number

00:08:19,000 --> 00:08:20,190
one.

00:08:20,190 --> 00:08:25,730
If you send A.JS to worker two, you have the same cache on worker two.

00:08:25,730 --> 00:08:29,250
This is bad in terms of space and time.

00:08:29,250 --> 00:08:30,880
Bad in terms of space.

00:08:30,880 --> 00:08:32,710
Memory between workers is not shared.

00:08:32,710 --> 00:08:35,330
You are going to duplicate the same data structure.

00:08:35,330 --> 00:08:37,560
And bad in terms of time.

00:08:37,560 --> 00:08:42,370
Because you didn't have a cache, you are going to re transpile from scratch.

00:08:42,370 --> 00:08:47,010
Instead, Metra has a queue for the workers.

00:08:47,010 --> 00:08:50,180
Once you transpile a file, it's sent to the worker.

00:08:50,180 --> 00:08:56,050
And once it's returned, it will stick to the worker that transformed it.

00:08:56,050 --> 00:09:01,520
If you want to retransform it, put it into the queue of worker number one and wait for

00:09:01,520 --> 00:09:06,820
it finish to send to the right worker.

00:09:06,820 --> 00:09:14,480
This is an oversimplification, it looks like worker two and three are idling and we could

00:09:14,480 --> 00:09:16,750
have taken that one.

00:09:16,750 --> 00:09:21,380
In real life what happens is that worker number two and three, they're busy with their own

00:09:21,380 --> 00:09:22,680
set of files.

00:09:22,680 --> 00:09:27,420
It is not that we just have one worker super busy and the rest idling, but the load is

00:09:27,420 --> 00:09:29,900
actually distributed across all of them.

00:09:29,900 --> 00:09:35,070
And the module that powers this, once again, borrowed from another project.

00:09:35,070 --> 00:09:41,280
It's just a worker that has a very simple API to create these kinds of forms of workers.

00:09:41,280 --> 00:09:45,120
We have an example on the repository about paralyzing left part.

00:09:45,120 --> 00:09:50,040
Which is not interesting from the practical point of view but shows how easy you can do

00:09:50,040 --> 00:09:51,330
things.

00:09:51,330 --> 00:09:52,620
Cool.

00:09:52,620 --> 00:09:58,730
So, we've transformed our files and with the prioritization, it becomes pretty fast.

00:09:58,730 --> 00:10:02,240
But we want to be faster than this.

00:10:02,240 --> 00:10:07,000
And in order to achieve this, Metra shapes with an internal cache.

00:10:07,000 --> 00:10:13,400
This cache is a multi layer cache and it is located inside the main process.

00:10:13,400 --> 00:10:16,260
The way it works with you go into the first cache layer.

00:10:16,260 --> 00:10:18,240
If the as a result there, you will return it.

00:10:18,240 --> 00:10:25,080
If not, go to the second cache layer and repeat the process through all the layers.

00:10:25,080 --> 00:10:29,120
Every time you want to transform something inside of Metra, you will go through a function

00:10:29,120 --> 00:10:31,270
called transform.

00:10:31,270 --> 00:10:34,730
And this transform will got go into the caching layers.

00:10:34,730 --> 00:10:37,120
The first is a local cache.

00:10:37,120 --> 00:10:43,670
This lives inside your laptop and used in both open source and internally at Facebook.

00:10:43,670 --> 00:10:47,460
Now, it could be that the thing you're looking for is not on that cache.

00:10:47,460 --> 00:10:53,130
For instance, you just checked out the code and you have never seen that file, so it was

00:10:53,130 --> 00:10:54,480
never transpiled.

00:10:54,480 --> 00:10:59,040
So, for that, we have a second cache layer, a centralized database.

00:10:59,040 --> 00:11:01,770
That one is only available at Facebook.

00:11:01,770 --> 00:11:06,690
But the code is open source, so you could in theory use that as well.

00:11:06,690 --> 00:11:10,940
And this centralized cache is accessed by all developers.

00:11:10,940 --> 00:11:13,970
We go into the cache and look for the file.

00:11:13,970 --> 00:11:21,029
Could be the file is not there because it's a local change you have just done.

00:11:21,029 --> 00:11:25,510
The only thing we can do there is go into the worker and transpile the file.

00:11:25,510 --> 00:11:30,680
Once the file is transpiled, we put that into the local cache.

00:11:30,680 --> 00:11:32,940
But we don't write to the global cache.

00:11:32,940 --> 00:11:36,820
And the reason for that is that if we save every change that every developer is doing

00:11:36,820 --> 00:11:39,200
through the day, we're going to end up loading the cache.

00:11:39,200 --> 00:11:41,160
And there is no benefit for that.

00:11:41,160 --> 00:11:46,030
No other person makes the same modification over the same file and in approximately the

00:11:46,030 --> 00:11:47,030
same commit.

00:11:47,030 --> 00:11:52,399
Instead, at Facebook, the centralized cache is fulfilled by a continuous integration job

00:11:52,399 --> 00:11:53,710
that runs on master.

00:11:53,710 --> 00:12:01,530
Which every time we see a new file, or a modified file and restore the file.

00:12:01,530 --> 00:12:05,830
In order to restore something, you need a cache key and a value.

00:12:05,830 --> 00:12:09,560
The cache key is built by Metra by combining two parts.

00:12:09,560 --> 00:12:12,370
We take your source file and we hash it.

00:12:12,370 --> 00:12:17,610
But we also take every single part involved into the process of transpiling the file and

00:12:17,610 --> 00:12:19,339
we also hash it.

00:12:19,339 --> 00:12:23,680
And the result, the cache that we use, is the union of both.

00:12:23,680 --> 00:12:28,610
The cool thing about this is whether if you change the file itself or change the way you

00:12:28,610 --> 00:12:31,470
transpile, you don't have to worry about invalidating the cache.

00:12:31,470 --> 00:12:35,980
So, if you didn't have the second part and you changed the way you transformed, either

00:12:35,980 --> 00:12:40,660
you had to invalidate the whole cache, which can suck for people that is not yet on to

00:12:40,660 --> 00:12:47,010
that commit, or you would be serving state results for some time, which is not good either.

00:12:47,010 --> 00:12:50,830
So, that was for the key.

00:12:50,830 --> 00:12:51,830
For the value.

00:12:51,830 --> 00:12:54,200
The value is the result of the transpilation process.

00:12:54,200 --> 00:12:58,750
If we take this model, for instance, and we transpile it, it would end up looking something

00:12:58,750 --> 00:12:59,930
like that.

00:12:59,930 --> 00:13:03,399
So, converted into var.

00:13:03,399 --> 00:13:06,220
It got wrapped into the function.

00:13:06,220 --> 00:13:10,800
And we got the define coal, et cetera.

00:13:10,800 --> 00:13:16,680
Now, inside Metra we do not use string identifiers for modules.

00:13:16,680 --> 00:13:20,060
Instead we use numeric identifiers.

00:13:20,060 --> 00:13:27,160
Other bundling systems like Webpack or Browserify can do that, but in Metra this is built in

00:13:27,160 --> 00:13:28,160
the core.

00:13:28,160 --> 00:13:32,180
For performance reasons, it's faster to do a lookup through a number.

00:13:32,180 --> 00:13:33,340
And for size reasons.

00:13:33,340 --> 00:13:36,160
A number is always smaller than a string.

00:13:36,160 --> 00:13:41,910
Now, if you cache this, you're going to have some issues because these numbers are local

00:13:41,910 --> 00:13:42,910
to your build.

00:13:42,910 --> 00:13:47,350
So, while this could work for your local cache, for the centralized cache when someone else

00:13:47,350 --> 00:13:52,740
is going to pick that module, they're built with crash because left pad could be a complete

00:13:52,740 --> 00:13:55,089
different module than number 42.

00:13:55,089 --> 00:13:58,420
So, Metra does not really hard code numbers.

00:13:58,420 --> 00:14:03,850
It adds one layer of indirection by using an array of numbers.

00:14:03,850 --> 00:14:08,410
And each of the modules is changed each of the reference of the modules is changed into

00:14:08,410 --> 00:14:10,880
a position into this array.

00:14:10,880 --> 00:14:16,360
Now, side to the module, we also store that position number zero is left pad and position

00:14:16,360 --> 00:14:18,520
number one is five.

00:14:18,520 --> 00:14:21,720
And when you build, we make a lookup into the table.

00:14:21,720 --> 00:14:26,350
We extract which is your local number for these modules and we add this array to the

00:14:26,350 --> 00:14:28,550
defined call.

00:14:28,550 --> 00:14:30,240
Okay.

00:14:30,240 --> 00:14:36,760
So, we've got all the files transpiled and we're ready to produce a bundle.

00:14:36,760 --> 00:14:43,959
Metra produces bundles sorry through something called serializers where you receive the graph

00:14:43,959 --> 00:14:46,250
and you can manipulate it any way you want.

00:14:46,250 --> 00:14:49,320
Now, there are two default serializers shipped with Metra.

00:14:49,320 --> 00:14:51,840
The first is a plain JavaScript bundle.

00:14:51,840 --> 00:14:57,600
When you're developing in native and open source, it is the one you're most likely using.

00:14:57,600 --> 00:15:00,670
It produces the same format of any other bundling system.

00:15:00,670 --> 00:15:06,760
Take one module, one another, concatenate them and at the end, add a startup code.

00:15:06,760 --> 00:15:11,410
The startup code is 99% of the time requiring zero.

00:15:11,410 --> 00:15:18,510
Because we assign numbers in the look alike when we traverse the graph and the entry point

00:15:18,510 --> 00:15:22,450
is almost always the first module.

00:15:22,450 --> 00:15:27,430
Now, there is a second form which is called random access module bundles, and this is

00:15:27,430 --> 00:15:31,340
not a text file, but a binary file.

00:15:31,340 --> 00:15:33,250
This file is sections.

00:15:33,250 --> 00:15:37,950
The first one is the magic number.

00:15:37,950 --> 00:15:49,140
[audio is echoing for captioner] it stands for something like that.

00:15:49,140 --> 00:15:50,270
Of the code.

00:15:50,270 --> 00:15:53,330
Now, after that, we have a table of contents.

00:15:53,330 --> 00:15:58,820
The table of contents has the amount of modules that are shipped into this big block.

00:15:58,820 --> 00:16:03,420
The startup length, remember the startup code was this require zero.

00:16:03,420 --> 00:16:10,060
And references to where each of the modules are located into this giant and after that,

00:16:10,060 --> 00:16:11,710
we just write the code.

00:16:11,710 --> 00:16:14,120
Starting with the startup section and each of the modules.

00:16:14,120 --> 00:16:18,690
And we put after them a new character and I'll explain to you in a second why we do

00:16:18,690 --> 00:16:19,690
that.

00:16:19,690 --> 00:16:23,589
Now, the amount of modules let us know how big the table of contents is.

00:16:23,589 --> 00:16:26,560
The startup length is how big the initial length is.

00:16:26,560 --> 00:16:33,000
And each of the five are there in within the file.

00:16:33,000 --> 00:16:39,279
The format might look cumbersome, but thanks to the table of contents, we can access in

00:16:39,279 --> 00:16:42,920
real time and where it is located.

00:16:42,920 --> 00:16:48,110
and this is especially relevant to execute code on devices.

00:16:48,110 --> 00:16:49,980
This is very specific to React native as well.

00:16:49,980 --> 00:16:51,480
And it's a little bit tricky.

00:16:51,480 --> 00:16:56,040
I'm going to explain first how we execute, how we require modules that are previously

00:16:56,040 --> 00:17:00,300
required and then thousand load a module for the first time.

00:17:00,300 --> 00:17:05,329
So, when the module was previously required, you will have into memory you require implementation

00:17:05,329 --> 00:17:08,600
and all the files, all the modules that were previously loaded.

00:17:08,600 --> 00:17:13,389
Now, when you want to require something, you will call into the require implementation

00:17:13,389 --> 00:17:16,799
and the require implementation has its own internal cache.

00:17:16,799 --> 00:17:21,859
For instance, because requiring twice the same module has to return the same instance.

00:17:21,859 --> 00:17:24,360
It can query the cache.

00:17:24,360 --> 00:17:27,539
And since the module is there, it will just return it.

00:17:27,539 --> 00:17:30,159
Now, this is a pretty straightforward process.

00:17:30,159 --> 00:17:34,549
And, again, literally every single bundling system does the same.

00:17:34,549 --> 00:17:40,519
Now, when you require something that was never required, the process gets a little bit trickier.

00:17:40,519 --> 00:17:45,020
We have once again a require and the modules that were previously loaded and our require

00:17:45,020 --> 00:17:47,399
call to something that we've never seen.

00:17:47,399 --> 00:17:49,379
The process starts in the same way.

00:17:49,379 --> 00:17:51,129
We go into require.

00:17:51,129 --> 00:17:53,629
We make a lookup into the cache.

00:17:53,629 --> 00:17:56,410
And then 622 in this case is not there.

00:17:56,410 --> 00:17:59,279
So, we've got to load it.

00:17:59,279 --> 00:18:03,639
And this happens with a little trick.

00:18:03,639 --> 00:18:08,200
For loading 622 in the case of React Native, we do not use JavaScript.

00:18:08,200 --> 00:18:10,110
We use the Native sign.

00:18:10,110 --> 00:18:13,269
The native sign has native require.

00:18:13,269 --> 00:18:20,270
Hey, can you load that into the Java virtual machine?

00:18:20,270 --> 00:18:28,549
It will go into the disk, look at the gigantic blob, do the maths, take the first number

00:18:28,549 --> 00:18:34,450
622, will extract where it is located and inject it in the virtual machine.

00:18:34,450 --> 00:18:39,880
Now, this is the reason why there is a byte at the end of every module.

00:18:39,880 --> 00:18:45,470
Because all implementations of JavaScript built in machines are C++ based, or at least

00:18:45,470 --> 00:18:47,360
they use ASCIIs and strings.

00:18:47,360 --> 00:18:51,539
By putting the character at the end of the module, we don't have to worry about the length

00:18:51,539 --> 00:18:54,059
nor coping it into a separate buffer.

00:18:54,059 --> 00:18:59,480
We can tell the virtual machine to load JavaScript from there.

00:18:59,480 --> 00:19:04,289
Once the model is loaded inside of the virtual machine, it will self register inside the

00:19:04,289 --> 00:19:08,460
require implementation and it will appear into the cache.

00:19:08,460 --> 00:19:12,090
And the only thing that it's left is the release the need if require.

00:19:12,090 --> 00:19:16,480
And now require will be able to return that module.

00:19:16,480 --> 00:19:24,330
This process pretty much like the format looks a little bit cumbersome, but it has some benefits.

00:19:24,330 --> 00:19:28,490
You have to pay off every single time that you cross from the JavaScript side into the

00:19:28,490 --> 00:19:29,950
native side.

00:19:29,950 --> 00:19:33,779
But on the other side, you are only loading the minimum amount of JavaScript that you

00:19:33,779 --> 00:19:34,830
need.

00:19:34,830 --> 00:19:39,830
And you're not consuming as much memory as you would consume otherwise.

00:19:39,830 --> 00:19:44,179
Loading a plain JavaScript bundle will still be possible, but it will take a lot of time

00:19:44,179 --> 00:19:45,710
and a lot of memory.

00:19:45,710 --> 00:19:48,549
And not all devices are capable to handle this.

00:19:48,549 --> 00:19:53,529
You're only putting inside the inside the virtual machine the code that you really need

00:19:53,529 --> 00:19:56,280
to execute.

00:19:56,280 --> 00:20:01,529
So, we've talked a lot about how we bundle code.

00:20:01,529 --> 00:20:02,809
How we execute code.

00:20:02,809 --> 00:20:04,179
A lot of the building process.

00:20:04,179 --> 00:20:06,690
But what happens with developers?

00:20:06,690 --> 00:20:11,239
Because we said that we're looking for sub second reloads for our developers.

00:20:11,239 --> 00:20:15,130
So, how have we made this work internally?

00:20:15,130 --> 00:20:21,090
A couple of months ago, approximately four months ago, we developed something that is

00:20:21,090 --> 00:20:22,720
called a Dev bundler.

00:20:22,720 --> 00:20:26,429
This is open source and it is part of Metra.

00:20:26,429 --> 00:20:30,970
In order to figure out how that works, let's take this graph as an example where your entry

00:20:30,970 --> 00:20:32,970
point is module number one.

00:20:32,970 --> 00:20:35,940
And the arrows mean the first one is requiring the second one.

00:20:35,940 --> 00:20:40,740
Module number one requires the seconds and sixth, module two requires three and four,

00:20:40,740 --> 00:20:42,009
so on and so forth.

00:20:42,009 --> 00:20:46,809
The first time you want to load this inside the device you will take all the files, put

00:20:46,809 --> 00:20:49,679
them all together and send to the device.

00:20:49,679 --> 00:20:57,320
Now, if you change module number six, but most do, they will re traverse to number one,

00:20:57,320 --> 00:20:58,549
get all the dependencies.

00:20:58,549 --> 00:21:01,710
Create a new bundle and ship that to the client.

00:21:01,710 --> 00:21:05,940
But the truth is, out of the six modules, only number six changed.

00:21:05,940 --> 00:21:11,970
The delta bundler creates a delta just with that module and sends that into the client.

00:21:11,970 --> 00:21:14,100
Now, the difference is massive.

00:21:14,100 --> 00:21:20,009
Because of instead of having an open operation every time you have a reload, you have an

00:21:20,009 --> 00:21:21,029
O1.

00:21:21,029 --> 00:21:27,139
Once it's loaded on the device, you don't have to worry about sending everything over

00:21:27,139 --> 00:21:31,379
and over through the network.

00:21:31,379 --> 00:21:34,100
The process works like this for most of the changes.

00:21:34,100 --> 00:21:37,590
There are slight modifications when you add or remove a require.

00:21:37,590 --> 00:21:42,799
So, when you add a require, we have to extract that require and start crawling again from

00:21:42,799 --> 00:21:44,460
that require.

00:21:44,460 --> 00:21:49,429
And through the through the crawling process, we only extract the modules, that is the first

00:21:49,429 --> 00:21:50,429
time we visit.

00:21:50,429 --> 00:21:52,820
So, for instance, module number one required number seven.

00:21:52,820 --> 00:21:56,119
And seven requires four, eight and nine to work.

00:21:56,119 --> 00:22:05,049
One was in the virtual machine, so, it will only contain one, seven, eight and nine.

00:22:05,049 --> 00:22:11,239
In a similar fashion, when we are move a require, we have to verify this was the last require

00:22:11,239 --> 00:22:12,289
going into the file.

00:22:12,289 --> 00:22:17,340
In that case, module number three stopped requiring module number five.

00:22:17,340 --> 00:22:20,059
But module four depends on it.

00:22:20,059 --> 00:22:23,970
What it means is that the delta that we can send is only module number three.

00:22:23,970 --> 00:22:29,789
Now, if we change module number four and remove the require, five becomes an orphan module

00:22:29,789 --> 00:22:31,909
and we can safely delete it.

00:22:31,909 --> 00:22:37,990
And the resulting delta for this is patching module number four, but also deleting module

00:22:37,990 --> 00:22:39,610
number five.

00:22:39,610 --> 00:22:46,169
So, to summarize this, most code changes only require patching a single file.

00:22:46,169 --> 00:22:51,379
So, we've gone through having to create a gigantic bundle with megabytes of JavaScript

00:22:51,379 --> 00:22:55,639
into filling just a few kilobytes.

00:22:55,639 --> 00:23:00,350
We just triggered that search through all the new requires that we might visit and take

00:23:00,350 --> 00:23:04,029
only the ones that is the first time we see.

00:23:04,029 --> 00:23:08,409
On the other side, removing a require does the inverse operations.

00:23:08,409 --> 00:23:13,289
So, instead of depending on direct dependencies, we depend on what we call inverse dependencies.

00:23:13,289 --> 00:23:17,809
So, we look at who is depending on a module in order to know if we can safely delete it

00:23:17,809 --> 00:23:18,809
or not.

00:23:18,809 --> 00:23:22,899
If no one is depending on the module, you can safely delete it.

00:23:22,899 --> 00:23:32,500
Now, as a quick recap, we can say that Metra is a building platform where the scaling issues

00:23:32,500 --> 00:23:35,150
are put on every part of the process.

00:23:35,150 --> 00:23:37,250
We made transformations in parallel.

00:23:37,250 --> 00:23:43,299
We have multi cache systems in order to avoid re transpiling files that someone else transpiled

00:23:43,299 --> 00:23:44,830
before.

00:23:44,830 --> 00:23:51,799
And then we have the code execution in the most optimal way both in development and in

00:23:51,799 --> 00:23:53,239
production.

00:23:53,239 --> 00:23:59,269
So, if you want to try Metra, if you're developing a React Native application you're already

00:23:59,269 --> 00:24:01,690
trying it.

00:24:01,690 --> 00:24:09,009
All the parts except for the global cache because we cannot ship the global public cache.

00:24:09,009 --> 00:24:14,139
All the features I described are in there.

00:24:14,139 --> 00:24:19,279
And we're also working into making it for suitable or other platforms.

00:24:19,279 --> 00:24:21,580
There are really cool examples about this.

00:24:21,580 --> 00:24:27,029
This is a video of a React Native application working on a browser.

00:24:27,029 --> 00:24:30,399
The thing that is powering this, I would totally recommend you to check the video.

00:24:30,399 --> 00:24:32,309
This is just 5 seconds.

00:24:32,309 --> 00:24:34,899
This is also powered by Metra.

00:24:34,899 --> 00:24:41,510
And in fact, we're currently working in making Metra suitable as well for web.

00:24:41,510 --> 00:24:46,659
And for that, we have a very simple application that a colleague of my team made.

00:24:46,659 --> 00:24:49,519
So, you can just go and download it.

00:24:49,519 --> 00:24:52,289
Everything works on that app except for the delta bundler.

00:24:52,289 --> 00:24:56,309
We are still figuring out how we're going implement this on the web.

00:24:56,309 --> 00:24:57,960
Might be service workers.

00:24:57,960 --> 00:25:00,080
But this is definitely not there yet.

00:25:00,080 --> 00:25:05,320
But in any case, it's actually powered by Metra.

00:25:05,320 --> 00:25:06,320
And that was all for today.

00:25:06,320 --> 00:25:07,320
Thank you very much.

00:25:07,320 --> 00:25:07,820

YouTube URL: https://www.youtube.com/watch?v=99QyAz3Wfqc


