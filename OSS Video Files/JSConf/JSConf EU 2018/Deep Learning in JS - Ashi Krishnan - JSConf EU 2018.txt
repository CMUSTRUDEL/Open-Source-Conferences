Title: Deep Learning in JS - Ashi Krishnan - JSConf EU 2018
Publication date: 2018-06-06
Playlist: JSConf EU 2018
Description: 
	It’s clear by now that the robots are coming for us.

Breakthroughs in AI fill our streams and news feeds, themselves the products of AI, the echoing algorithmic screams of a new kind of mind being born.

Using deeplearn.js, we’ll find out how deep learning systems learn and examine how they think. The fundamental building blocks of AI have never been more accessible. Let’s explore the architecture of these new minds, which are growing to mediate our every interaction.

JSConf EU is coming back in 2019 https://2019.jsconf.eu/
Captions: 
	00:00:09,800 --> 00:00:13,761
Hi, everyone. I'm Ashi, and I will be your guide today as we describe explore the deep

00:00:13,761 --> 00:00:24,009
world of world of learning and JavaScript. I'm not a machine-learning expert, sorry about

00:00:24,009 --> 00:00:34,330
that, but my mom is. She's an audiologist by training, and she did work in digital filters

00:00:34,330 --> 00:00:39,430
for hearing aids, and then later worked on the acoustic model of a speech recogniser.

00:00:39,430 --> 00:00:46,980
I remember working in her lab one summer and people were saying these strange and intimidating

00:00:46,980 --> 00:00:53,881
words, and there were all of these odd things up on the wall, and I was overwhelmed. At

00:00:53,881 --> 00:00:58,460
the time I didn't understand basically any of it. So this process has also been impressive

00:00:58,460 --> 00:01:04,920
- a process of getting closer to her where I can go to her and say, "I know what cross

00:01:04,920 --> 00:01:12,780
entropy is", and she's like, "That's great, can you explain it to me?!" I think I can,

00:01:12,780 --> 00:01:21,149
explain it to you and well enough for you to use it. I've been learning deep learning

00:01:21,149 --> 00:01:28,890
out of curiosity with some excitement for the future, and also with the sense of existential

00:01:28,890 --> 00:01:34,140
terror that the robots are coming and they're going to consume all of our jobs, and possibly

00:01:34,140 --> 00:01:39,549
our societies, and maybe ourselves. There might be this matrix-pod situation that's

00:01:39,549 --> 00:01:46,850
going to happen. I have some exciting news which is that the robots are very, very impressive,

00:01:46,850 --> 00:01:52,399
and they're also kind of stupid. Like stupid in really fundamental ways. And so they're

00:01:52,399 --> 00:01:57,399
probably not going to take your job - at least not within the next year or two - but they're

00:01:57,399 --> 00:02:02,679
going to change it, and change it quite dramatically. And so now, it's a really exciting time to

00:02:02,679 --> 00:02:06,459
be getting into this field. There's a huge amount of research and a lot of new tooling

00:02:06,459 --> 00:02:12,430
available to us. Let's dive in. Before we dive in, I want to give a single definition.

00:02:12,430 --> 00:02:19,599
I gave this talk, and a student was like, "So you said tensor like 100 times, and that's

00:02:19,599 --> 00:02:32,540
a scary word. I feel tense right now." A tensor, if you look it up on Wikipedia, it is a numeric

00:02:32,540 --> 00:02:40,030
field that is closed over some free operation. I would say that a tensor is a block of numbers.

00:02:40,030 --> 00:02:44,879
We can have a block of numbers that is actually just a single number, that is a ranked zero

00:02:44,879 --> 00:02:53,739
tensor or a scaler. We can have a block of numbers, a line of numbers, a vector, a rink

00:02:53,739 --> 00:03:01,780
1 tensor, matrices, newspaper of squares or rectangles are ranked to tensors, we can have

00:03:01,780 --> 00:03:10,600
the prisms ranked to tensors, and on and on that become progressively harder to draw,

00:03:10,600 --> 00:03:16,260
so I'm not going to draw them. I've just defined tensors for you because I'm about to talk

00:03:16,260 --> 00:03:25,969
about Tensor Flow which is the state of the art machine learning framework. And now, available

00:03:25,969 --> 00:03:37,069
in JavaScript. So, let's break down what is available in the available, so, in using the

00:03:37,069 --> 00:03:48,300
C++ API, I'm using the pipeline API, large grasp of math operations on the CPU, on the

00:03:48,300 --> 00:03:55,120
GPU, to be able to do more operations at a slightly lower precision in parallel, and,

00:03:55,120 --> 00:04:01,709
then on the TPU, which is like a GPU but with even more, even crappier compute units. It

00:04:01,709 --> 00:04:08,540
is a special-purpose hardware that Google made that is optimised for doing machine-learning

00:04:08,540 --> 00:04:15,709
particularly. It turns out that machine-learning is a large stack of really simple operations,

00:04:15,709 --> 00:04:23,100
and so being able to parallelise over simple operations is ideal. The JavaScript bindings

00:04:23,100 --> 00:04:32,889
currently give us CPU computation under Node, and then the web bindings use WebGL to perform

00:04:32,889 --> 00:04:40,010
math. Soon, the node bindings, the Tensorflow team promises will use the C++ backend which

00:04:40,010 --> 00:04:46,530
means we should have performance parity with the Python libraries. Currently, the web bindings

00:04:46,530 --> 00:04:53,110
that use the GPU are half the performance of the C++ library which is unfortunate, but

00:04:53,110 --> 00:04:58,550
you can do it in a browser, so that's pretty cool. The other important part about doing

00:04:58,550 --> 00:05:05,770
machine-learning research and developing these models is the ecosystem around the core processing

00:05:05,770 --> 00:05:11,060
libraries that we are using, and the ecosystem in Python is enormous, and the ecosystem in

00:05:11,060 --> 00:05:20,460
JavaScript is sad. And, that's okay. If any of the Propel folks or anyone doing scientific

00:05:20,460 --> 00:05:24,700
computation in JavaScript is here, I want to say your work is wonderful, and I'm really

00:05:24,700 --> 00:05:32,040
looking forward to it, and the size of the community is currently small, but, if the

00:05:32,040 --> 00:05:38,260
history of JavaScript frameworks is any indication, we will quickly build up a large and interesting,

00:05:38,260 --> 00:05:44,009
and powerful ecosystem of software. It's just currently the case that, if you want to build

00:05:44,009 --> 00:05:50,040
your own extremely large deep-learning models and train them on the kinds of data sets that

00:05:50,040 --> 00:05:56,460
you might need to train on multiple computers in order to access, then you're probably going

00:05:56,460 --> 00:06:02,660
to be doing that in Python in the cloud, but you can take those models, and this is the

00:06:02,660 --> 00:06:08,180
exciting thing about tensorflow.js - you can take them and run them in the browser. It

00:06:08,180 --> 00:06:14,720
means you can leverage the power of machine-learning in the browser without sending all of your

00:06:14,720 --> 00:06:21,460
user's data off to some provider in the sky, and you can also continue to train those models

00:06:21,460 --> 00:06:26,910
locally. We can do something called "transfer learning" where we cut off the last bit of

00:06:26,910 --> 00:06:33,660
the model, and we adapt it while not having to retrain all of the model's deep layers

00:06:33,660 --> 00:06:39,790
in order to give users machine learning, the advantages of machine-learning without the

00:06:39,790 --> 00:06:49,280
privacy implications or the entanglement of surveillance. I just said "model", like, 500

00:06:49,280 --> 00:06:55,750
times. What exactly are models? Let's say we've got this phenomena happening in the

00:06:55,750 --> 00:07:04,150
world and this is a snake or it's a drawing of a snake. We want to model it. We want to

00:07:04,150 --> 00:07:09,052
understand it in some way. We want a simplified version of it. That's what a model is: it

00:07:09,052 --> 00:07:14,220
is a simplified version of the world turned into math. So, in this case, we are going

00:07:14,220 --> 00:07:21,550
to turn our snake into a squiggle. With machine-learning, we go through there training process where

00:07:21,550 --> 00:07:29,349
we want to find the set of model parameters that lets us fit the world as best we can.

00:07:29,349 --> 00:07:35,750
We can imagine trying different sets of parameters, like different squiggles, kind of at random

00:07:35,750 --> 00:07:45,199
until we find one that works on this snake. It is not ideal. We could sit here all day.

00:07:45,199 --> 00:07:50,200
We don't have a great metric for how well we are doing, and we don't have a sense that

00:07:50,200 --> 00:07:55,360
we are making forward progress. So what we would really like is to find a way to pick

00:07:55,360 --> 00:08:00,141
some set of parameters, squiggle, and its iteratively improve it, and do what he what

00:08:00,141 --> 00:08:06,990
we do naturally while improving on our own knowledge of the situation until we find a

00:08:06,990 --> 00:08:17,780
good fit. We can do that through a process called stochastic gradient descent. If you're

00:08:17,780 --> 00:08:22,610
a machine-learning expert in the audience, there are a variety of gradient descent techniques.

00:08:22,610 --> 00:08:29,020
Let's look at the simplest now. Let's say a splatter of paint and I with a n't to model

00:08:29,020 --> 00:08:35,190
it. If I want to model a splatter of paint, I would almost certainly not do it as a line,

00:08:35,190 --> 00:08:41,380
but I will do it as a line because there are two parameters that makes it easy to visualise

00:08:41,380 --> 00:08:46,140
all the various things we need to visualise for them. So I'm going to model the splatter

00:08:46,140 --> 00:08:50,720
of paint as a line, and we're going to be happy about it. First, I'm going to throw

00:08:50,720 --> 00:08:56,440
a co-ordinate system under it, and I've turned these into X, Y points. I'm going to dig back

00:08:56,440 --> 00:09:02,019
into my suppressed memories of high school algebra to remember that the equation for

00:09:02,019 --> 00:09:17,360
a line is Y=MXB. I have Y, the line, B is the line intercept. If I pick random values

00:09:17,360 --> 00:09:22,410
for those two parameters, I'm going to get a line. I need - any two random values will

00:09:22,410 --> 00:09:30,190
get me a line. This line is not a very good line. So, at this point, it is way off, and

00:09:30,190 --> 00:09:38,200
these two points are pretty off, and, if we go through and figure out that off-ness for

00:09:38,200 --> 00:09:48,470
the entire set of examples, then what we are looking at is a quantity called "loss". Loss,

00:09:48,470 --> 00:09:54,510
like that sensation you feel at the end of a long relationship is a measure of how badly

00:09:54,510 --> 00:10:03,240
we did, how poorly, our model fit the data. It is a machine-learning self-flagellation.

00:10:03,240 --> 00:10:08,839
A common kind of loss that we use, particularly for regression, which is what we are doing

00:10:08,839 --> 00:10:14,779
right now, called mean-squared error, means we take the average of the difference between

00:10:14,779 --> 00:10:20,800
the model and the ground true squared. If we were to write it in JavaScript, it would

00:10:20,800 --> 00:10:26,740
look something like this. We can reduce over data, find the difference between that data

00:10:26,740 --> 00:10:31,781
point as our model predicted it, and the actual value of that data point, square it, divide

00:10:31,781 --> 00:10:41,520
it by length, and then that gives us this function that we can pass in - we have in

00:10:41,520 --> 00:10:48,510
line function. We can pass in model parameters here. And any two model parameters are going

00:10:48,510 --> 00:10:54,610
to yield a particular loss with respect to this data. It means, because we have two of

00:10:54,610 --> 00:11:00,220
them, I can visualise it on a plane, and say this is going to be the slope of our line

00:11:00,220 --> 00:11:08,279
- the slopiness - and how high up the X axis it is, and, for some given set of model parameters,

00:11:08,279 --> 00:11:13,480
in fact, for every given set of model parameters, there will be some loss. So what we can do

00:11:13,480 --> 00:11:20,250
now is figure out what that loss is and poke around with that there, and what if my line

00:11:20,250 --> 00:11:27,800
was slopier? What if it is less slopy. What about higher up or lower up? In one of those

00:11:27,800 --> 00:11:33,680
directions, we will be reducing loss, and so we're going to take a step in that direction

00:11:33,680 --> 00:11:41,831
along both axis. We will do it again. More slopy, less slopy, higher or lower. Again

00:11:41,831 --> 00:11:55,930
and again. Each step, we're using loss to point us in the direction of movement. Loss

00:11:55,930 --> 00:12:04,470
is showing us where to go. And it's revealing for us a landscape of loss. So that, what

00:12:04,470 --> 00:12:09,631
we are kind of doing is we are finning the slope of this landscape at each point, the

00:12:09,631 --> 00:12:14,830
general mapping term for the slope of the landscape is its gradient, so the process

00:12:14,830 --> 00:12:21,510
that we are doing is gradient descent. We are rolling down this landscape like rain

00:12:21,510 --> 00:12:29,649
drops into the valleys that are closest to the ground truth. So there are a lot of ways

00:12:29,649 --> 00:12:35,460
we might tweak this process. One is to notice that, if we are computing loss against all

00:12:35,460 --> 00:12:41,670
of the examples, all of the splatters of paint, then it's going to take a while. It's not

00:12:41,670 --> 00:12:47,100
going to take that long for a line and X, Y points, but, if we have much larger models,

00:12:47,100 --> 00:12:54,240
then it can quite expensive to compute loss, so we might just grab a handful of examples,

00:12:54,240 --> 00:13:03,930
randomly. Stochastically, you might say if you're to say stochastically rather than randomly,

00:13:03,930 --> 00:13:10,079
so that gives us stochastic gradients of descent. Other parameters we might choose are for example

00:13:10,079 --> 00:13:18,920
the size of the step we take. That's called the learning rate. These quantities, the size

00:13:18,920 --> 00:13:23,150
of the batch, like the number of examples we look at, or the learning rate, they're

00:13:23,150 --> 00:13:29,370
not learned, we don't train them, and so they're not called model parameters, but rather hyper

00:13:29,370 --> 00:13:34,010
parameters which is a very exciting word, I think, and the model doesn't learn them

00:13:34,010 --> 00:13:39,810
during training, and we set it manually when we train the model, typically by running hundreds

00:13:39,810 --> 00:13:48,650
of experiments, and staring at graphs until our eyeballs bleed. Okay. So that is a line.

00:13:48,650 --> 00:13:55,490
It's like a very simple, very simple function, probably not very useful, right? There are

00:13:55,490 --> 00:14:00,410
other functions that we might use for deep learning. For example, we might use one of

00:14:00,410 --> 00:14:11,769
a set of sigmoidal functions. These simulate the neuron. Down here, the neuron is firing,

00:14:11,769 --> 00:14:19,070
here, it is not. And they're smooth because they - because that way, they're different

00:14:19,070 --> 00:14:54,980
essential at every point.. [Sound distortion]. It's a hard function and

00:14:54,980 --> 00:15:21,230
a complicated function. It's the

00:15:21,230 --> 00:15:29,470
maths of X and zero. That's it. That function is pretty easy to think about. We could imagine

00:15:29,470 --> 00:15:35,300
right it, and - writing it in less than one line of JavaScript. It turns out that that

00:15:35,300 --> 00:15:40,420
simplicity, and that ease of computability makes it perfect for deep learning, where,

00:15:40,420 --> 00:15:46,089
again, we're not doing very interesting or complicated operations, we sure are doing

00:15:46,089 --> 00:15:53,269
a lot of them. We can imagine stacking up these rectifiers, and here we are going to

00:15:53,269 --> 00:16:03,040
have four layers, four neurons densely interconnected in two layers. Because they're densely interconnected,

00:16:03,040 --> 00:16:10,149
we're going to say that each of the neurons in the second layer gets fed by all of the

00:16:10,149 --> 00:16:16,079
neurons in the first layer. So this one, for example, its input is going to be the weighted

00:16:16,079 --> 00:16:21,339
sum of inputs from all of the neurons in the previous layer, which, if you think about

00:16:21,339 --> 00:16:28,449
it, because of the shape of this function, what we are really doing is nesting if statements.

00:16:28,449 --> 00:16:33,759
We're nesting if statements with conditionals whose values depend on the output of previous

00:16:33,759 --> 00:16:41,509
if statements, and whose thresholds are basically entirely hard-coded. Next time you see reservers

00:16:41,509 --> 00:16:46,759
at Google have created a deep neural network that does some impressive thing, just think

00:16:46,759 --> 00:16:52,250
researchers at Google have figured out how to hard code 50 million random values in order

00:16:52,250 --> 00:16:57,310
to do some impressive thing, which is basically what is going on. The impressive part is obviously

00:16:57,310 --> 00:17:04,370
that the training process figures out those hard-coded values for ourselves, but, at the

00:17:04,370 --> 00:17:09,390
end, the thing the model is doing is basically a giant pile of spaghetti code which fortunately

00:17:09,390 --> 00:17:16,761
models our brains pretty well. Even for a model like this, a relatively small one, if

00:17:16,761 --> 00:17:22,580
we think about the number of interconnections between these two layers of neurons, we see

00:17:22,580 --> 00:17:28,930
that we've got 16 of them. For a line, we had two parameters, and we were able to think

00:17:28,930 --> 00:17:36,680
about its loss landscape. This model has 16 parameters, and I don't know about you, but

00:17:36,680 --> 00:17:48,320
I have a really hard time visualising 17-dimensional surfaces. It gets worse. What we are seeing

00:17:48,320 --> 00:17:58,080
revealed here is a visualisation of the loss landscape for Resnet, which is an image classifier.

00:17:58,080 --> 00:18:08,281
Resnet has about 60 million parameters. It means this is a heavy approximation. These

00:18:08,281 --> 00:18:12,910
folks have done some interesting projection in order to get it even to resemble something

00:18:12,910 --> 00:18:18,800
three-dimensional. It has been said of the terrifying things that live at the base of

00:18:18,800 --> 00:18:23,690
the sea and will one day wake to consume the world that they have length, width, depth,

00:18:23,690 --> 00:18:32,280
and several other things, and perhaps this is what Lovecraft was talking about. The good

00:18:32,280 --> 00:18:36,480
news is that you don't have to train those models. You don't even have to think about

00:18:36,480 --> 00:18:44,410
them or hold their loss landscapes in your head, because you can MPM install them! And

00:18:44,410 --> 00:18:51,190
it looks like - of course, if you want to train those models, I highly encourage it.

00:18:51,190 --> 00:18:55,700
We're going to look at an example of transfer learning where we take a pretrained model

00:18:55,700 --> 00:19:02,590
and then train it to do something else. It lets us leverage all of the training time

00:19:02,590 --> 00:19:10,320
on the larger, in this case, image-recognition model, and then use it for a different problem

00:19:10,320 --> 00:19:17,210
space. So we're going to do transfer learning, and what we're going to do, this is an example,

00:19:17,210 --> 00:19:26,410
you can pull it up on GitHub. I'm going to play Pac-Man using my elephant friend Tallula.

00:19:26,410 --> 00:19:34,640
The way this works is I pick a bunch of examples using my webcam that represent the images

00:19:34,640 --> 00:19:39,370
for up, down, left, and right. I'm rotating to the left. I'm trying to be in the frame,

00:19:39,370 --> 00:19:45,080
trying not to be in the frame, get a representative sense, or give the network a representative

00:19:45,080 --> 00:19:50,760
sense of where and how I'm going to be holding her, which as you can see, I do not. We're

00:19:50,760 --> 00:19:59,330
going to train it. It is pretty low. Then, when I play, the network is going to highlight

00:19:59,330 --> 00:20:05,810
in yellow which direction it thinks I'm moving in, and we can see that it works pretty well,

00:20:05,810 --> 00:20:12,270
at least until I start getting stressed about Pac-Man and not holding Tallula in the same

00:20:12,270 --> 00:20:19,360
way I was during training. If you want to ruin a friendship, using your friend as a

00:20:19,360 --> 00:20:26,860
controller is a pretty good way to do it! Now I'm eaten. I've been eaten. And I'm happy

00:20:26,860 --> 00:20:38,930
to report that we are still friends! Thing we do is, things zero we do is MPM install

00:20:38,930 --> 00:20:51,090
everything including Tensorflow. Thing one we do is install Tensorflow. And then, we

00:20:51,090 --> 00:20:58,340
are going to load up the model. Our model that you can also MPM install, this particular

00:20:58,340 --> 00:21:04,251
model is served off the web somewhere. And because we are doing transfer learning, we're

00:21:04,251 --> 00:21:10,030
going to do a little bit of surgery on the model, so we're going to pull out this layer

00:21:10,030 --> 00:21:18,400
conPW13relu, whatever that means, and then we are going to construct a new model that

00:21:18,400 --> 00:21:26,630
has the maim inputs as mobile net but outputs that low but not final layer. The actual final

00:21:26,630 --> 00:21:35,190
layer of mobile net is going to be, like, 200 probabilities, namely, the probability

00:21:35,190 --> 00:21:40,510
that this photo contains a cat. The probability that this photo contains a cow. The probability

00:21:40,510 --> 00:21:45,070
that this photo contains a laptop, and on and on throughout whatever class of images

00:21:45,070 --> 00:21:50,970
mobile net has been trained to recognise. We want something before that, something where

00:21:50,970 --> 00:21:58,140
the image has been kind of reshaped into some arbitrary chunk of interesting data, but has

00:21:58,140 --> 00:22:09,221
not yet been winnowed down to what it contains. We loo look at that more in a second. When

00:22:09,221 --> 00:22:14,170
I'm adding examples, this is what is happening, it's controlling the data set, which is building

00:22:14,170 --> 00:22:22,780
up a data set of examples. Then we construct our model. Our model is going to take the

00:22:22,780 --> 00:22:27,480
output of that layer of Tensorflow, it's going to flatten it, and it's going to run it through

00:22:27,480 --> 00:22:35,560
a configurable number - let's call this 100 - densely interconnected relu neurons, and,

00:22:35,560 --> 00:22:41,630
then, at the end, we will have a soft Max layer. It is a different activation function

00:22:41,630 --> 00:22:47,000
which is useful for when you want a probability distribution, so, in this case, we want the

00:22:47,000 --> 00:22:55,430
probability distribution. Num classes is going to be four, because we have up, down, left,

00:22:55,430 --> 00:22:58,950
and right, and that's all we are trying to decide between. The output of our network

00:22:58,950 --> 00:23:08,080
is going to be the relative probabilities that I am holding her up, left, right, or

00:23:08,080 --> 00:23:16,280
so on. So then we configure an optimiser. We're not using stochastic gradient descent,

00:23:16,280 --> 00:23:24,460
we are using Adam which is a stochastic gradient technique which is better. It is a little

00:23:24,460 --> 00:23:32,430
bit smarter about how it decides the steps it takes. We are going to compile this model

00:23:32,430 --> 00:23:43,680
with a loss function, and that loss function is " Cross-functional entropy. The reason

00:23:43,680 --> 00:23:48,640
being, if we have this example, an example of me holding Tallula upside-down to indicate

00:23:48,640 --> 00:23:53,730
down, and the network predicts this - which is technically predicting that I'm holding

00:23:53,730 --> 00:24:03,280
her right - how bad is that, really? Because, this is, like, it's pretty close - the prediction

00:24:03,280 --> 00:24:08,550
is wrong. If these were flipped, it would still be kind of wrong that it thought that

00:24:08,550 --> 00:24:13,240
there was a ten per cent chance that I was holding her correctly, you know? Answering

00:24:13,240 --> 00:24:20,980
that question is what categorical cross-entropy does. It is how much did this model confuse

00:24:20,980 --> 00:24:27,310
different probability classes? And now you know. And then finally, we call fit this this

00:24:27,310 --> 00:24:33,381
actually goes in start dispatching stuff off on the GPU, and we get these callbacks every

00:24:33,381 --> 00:24:39,250
time a batch is finished. So every time we have computed our loss for something would

00:24:39,250 --> 00:24:47,630
be we have updated the weights, and then we've taken a step. All right. To play the game,

00:24:47,630 --> 00:24:54,160
we ask mobile net to do its prediction, we run our model to give us one of four probability

00:24:54,160 --> 00:25:01,830
classes, and then we figure out which one is the most likely, and we do it. And that's

00:25:01,830 --> 00:25:08,680
packman. That is transfer learning with tense or flow.js. I would like us to go back and

00:25:08,680 --> 00:25:14,630
understand what it is we are getting out of mobile net, and, do to do, I'm going to load

00:25:14,630 --> 00:25:21,950
up mobile net, load up that JSON file we loaded up earlier in the browser. Here, we will see

00:25:21,950 --> 00:25:30,920
that this is a Caris model that let's us describe a deep-learning system as a bunch of layers,

00:25:30,920 --> 00:25:43,400
and here, it is layers. Come on. Click. So a deep-learning network that recognises images

00:25:43,400 --> 00:25:49,140
typically looks something like this. We've got convolutional layers, and normalisation

00:25:49,140 --> 00:25:53,130
layers, and activation layers. The activation layers we know what they look like - those

00:25:53,130 --> 00:26:00,900
are the relu layers we saw earlier. Normalisation make sure our values are between zero and

00:26:00,900 --> 00:26:08,401
one-ish, and they do it across single batches, which is why they're call batch layers. Convolutional

00:26:08,401 --> 00:26:13,130
layers have the configuration parameters, and, like many things in machine-learning,

00:26:13,130 --> 00:26:20,400
they sound hard but they're not very hard. Convolutions are basically Photoshop filters.

00:26:20,400 --> 00:26:25,770
If we have a whole bunch of input pixels, a convolutional layer will grab some chunk

00:26:25,770 --> 00:26:33,400
of those pixels, run it through a filter, and output it. It will walk the filter over

00:26:33,400 --> 00:26:40,090
the entire image producing an output image. You will notice if we do this without allowing

00:26:40,090 --> 00:26:44,240
the filter to slide off the edge, then we will get something slightly smaller. We can

00:26:44,240 --> 00:26:49,800
decide what it is we want. That's one of the many tuneable parameters. Convolutions come

00:26:49,800 --> 00:26:56,230
in all kinds of shapes and sizes. This one is three by three. The key thing here is this

00:26:56,230 --> 00:27:03,220
filter which is the same across the entire image, and it is trainable, which means that

00:27:03,220 --> 00:27:10,670
actually, let's just see what it means. So I've gone and gutted mobile net. Put it here.

00:27:10,670 --> 00:27:15,610
This is what is happening in each of those many, many convolutional layers that we saw

00:27:15,610 --> 00:27:20,590
before. Yes, it looks like a bunch of crappy Photoshop filters, because it is a bunch of

00:27:20,590 --> 00:27:29,790
crappy Photoshop filters. The interesting thing here is that it has started to do edge-detection

00:27:29,790 --> 00:27:36,300
and other processes that will mimic the visual distraction things that happens in our visual

00:27:36,300 --> 00:27:43,700
core twelve. This happens naturally when you train a system that is able to create these

00:27:43,700 --> 00:27:50,720
isolated filters on an image classification task that mimics the kinds of image classes

00:27:50,720 --> 00:27:55,430
that we ourselves recognise, as it starts to do the same kind of processing that we

00:27:55,430 --> 00:28:03,500
do, which is an interesting validation of the model, I think. So I hope this makes deep

00:28:03,500 --> 00:28:09,020
learning a little bit less scary, the realisation that it is just a big pile of operations,

00:28:09,020 --> 00:28:24,390
a bunch of spaghetti code that has been tweaked by a very simple but big process. Our world

00:28:24,390 --> 00:28:30,360
is fleshed with information, and our interaction with it is heavily mediated increasingly by

00:28:30,360 --> 00:28:35,380
machine-learning systems. The systems are not perfect. They've been trained on whatever

00:28:35,380 --> 00:28:40,980
data we've given them, and, like us, they internalise the biases of that data, and,

00:28:40,980 --> 00:28:46,770
just like us, they can be pressed into the service of whoever wants to wield them. There

00:28:46,770 --> 00:28:52,440
is this proof that neural networks are universal approximators, which means any function you

00:28:52,440 --> 00:29:01,710
give them, they can approximate to some level of precision. If you believe our own cognition

00:29:01,710 --> 00:29:06,450
is a computable function, then we're moving into the world where the fundamental tasks

00:29:06,450 --> 00:29:14,200
of cognition are now a thing that we can train a machine to do. So these are not real faces.

00:29:14,200 --> 00:29:22,600
These were dreamt up by a deep-learning network whose loss function is another network. The

00:29:22,600 --> 00:29:30,910
two networks improve each other, learning to dream up things that appear to be people.

00:29:30,910 --> 00:29:38,260
And this is not Barak Obama. This is machine-learning Obama, synced to a recording of an actual

00:29:38,260 --> 00:29:45,390
Obama speech. There exist systems that can generate speech that sounds like anyone as

00:29:45,390 --> 00:29:53,260
well. So, how do we cope with this? With the world where we can't trust our own eyes and

00:29:53,260 --> 00:29:59,360
ears? One way is to ignore it, and to say that these technologies are not that good

00:29:59,360 --> 00:30:07,640
- yet. But, if cognition is a computable function, then our societies and ourselves are games,

00:30:07,640 --> 00:30:14,950
and robots will be it turns out, are very good at playing games. In the history of computation,

00:30:14,950 --> 00:30:21,450
we see these tides. So, first, all-important work was done on big main frames. And then

00:30:21,450 --> 00:30:27,851
processors improved, and work moved to personal computers. Then networks improved, and we

00:30:27,851 --> 00:30:33,510
put everything in the cloud. And now we are seeing the tide go out again as we begin to

00:30:33,510 --> 00:30:40,080
realise what we've given away, how much power there is in knowing everything about everyone,

00:30:40,080 --> 00:30:45,390
and how much danger there is in us relying on pick boxes outside of our control to feed

00:30:45,390 --> 00:30:51,590
us with knowledge. So my message to you is that these technologies don't have to be opaque,

00:30:51,590 --> 00:30:56,830
and they don't have to be centralised, and we can hold the power of robot minds in our

00:30:56,830 --> 00:31:05,510
pockets. We can use them to create, not just to create forgeries but to discern truth before

00:31:05,510 --> 00:31:09,780
so this is just the beginning. Everything we've seen here today, I think it's quite

00:31:09,780 --> 00:31:15,870
impressive, and I think it is going to look downright embarrassing in a few years when

00:31:15,870 --> 00:31:21,980
you can talk with euro bot -- your robot assistant, and the pattern of your voice will never leave

00:31:21,980 --> 00:31:24,480
your wrist. Thank you. [Cheering and Applause]. Here are some folks to follow if you're interested

00:31:24,480 --> 00:31:24,980

YouTube URL: https://www.youtube.com/watch?v=SV-cgdobtTA


