Title: Photorealistic Real Time Computer Graphics with Javascript - Ivan Moreno - JSConf EU 2018
Publication date: 2018-07-17
Playlist: JSConf EU 2018
Description: 
	Photorealism has been the holy grail of computer graphics for many years. With the introduction of WebGL and hardware accelerated API’s on the browser, Web designers and developers were given a powerful tool to enlarge their creative scope and communication options. In this talk Ivan will demo and explain the concepts behind his creations, the tools he uses; from basic 3D modeling and texturization tips, to how to assemble a complete application, wether a small game, a product configurator, a cinematic experience, an augmented reality ad, or a virtual reality tour, your imagination will be the limit.

OMG JSConf EU is coming back in 2019 https://2019.jsconf.eu/
Captions: 
	00:00:08,640 --> 00:00:11,760
It's a great honour for me to be here on this stage.

00:00:11,769 --> 00:00:18,660
My name is Ivan Moreno, I'm the co-founder of Plus 360 Degrees, based in Bremen here

00:00:18,670 --> 00:00:19,780
in Germany.

00:00:19,780 --> 00:00:26,820
In this talk, you're going to see what is the relationship and the similarities between

00:00:26,820 --> 00:00:29,650
these two images.

00:00:29,650 --> 00:00:32,780
The correlations between art, science, and engineering, what they have in concert during

00:00:32,780 --> 00:00:41,390
real time projects, share tips on managing large amounts of data, the downsides of distribution

00:00:41,390 --> 00:00:47,640
landscape, and what having so many option s how it can overwhelm us as creatives and

00:00:47,640 --> 00:00:49,059
how best to overcome them.

00:00:49,059 --> 00:00:55,679
A little bit about myself: I studied fine art, design, and engineering.

00:00:55,679 --> 00:01:02,649
I did two specialisations: one in digital and media, and another one is digital media

00:01:02,649 --> 00:01:06,440
infomatics.

00:01:06,440 --> 00:01:13,370
We have been building tools in our studio to help us to create our projects, and help

00:01:13,370 --> 00:01:19,060
us with the e-commerce tools of some of our clients.

00:01:19,060 --> 00:01:26,510
We have been working across different industries, and make some prototypes of WebGL for the

00:01:26,510 --> 00:01:27,510
community.

00:01:27,510 --> 00:01:34,400
Coming back to these two images, how do you think they are in any way similar?

00:01:34,400 --> 00:01:37,680
Any ideas?

00:01:37,680 --> 00:01:43,370
They both start with black canvasses.

00:01:43,370 --> 00:01:49,830
The machine forms 60 or 120 times what it took a Renaissance, a Mannerist or Baroque

00:01:49,830 --> 00:01:53,420
painter three to six years to succeed.

00:01:53,420 --> 00:02:00,820
I like to treat it this way because it gives me a scope of how far we can get in these

00:02:00,820 --> 00:02:01,820
centuries.

00:02:01,820 --> 00:02:08,860
It reminds me that WebGL frameworks and use, in fact, many of the math developed since

00:02:08,860 --> 00:02:12,220
then in concepts and geometry.

00:02:12,220 --> 00:02:17,830
Vanishing point used for many years placed within the math systems.

00:02:17,830 --> 00:02:25,120
The introduction of the camera obscura and optics made us reach here.

00:02:25,120 --> 00:02:31,500
Created with those new developments, thanks to the development at the time in optics.

00:02:31,500 --> 00:02:39,310
Modelling appeared inspired by Greek models, and we've been using them since the introduction

00:02:39,310 --> 00:02:44,260
of painting, images, and films since the Renaissance.

00:02:44,260 --> 00:02:48,540
The art of creating volume by placing light on dark.

00:02:48,540 --> 00:02:53,770
Also called "light modelling," "lied shading" or simply "shading" is where we have to look

00:02:53,770 --> 00:02:59,720
to understand computer graphics.

00:02:59,720 --> 00:03:05,620
You take a carbon or an oil paint and stain on the white canvas.

00:03:05,620 --> 00:03:14,760
The works of Da Vinci, Rubens, Velázquez, Rembrandt, Caravaggio, you will find these

00:03:14,760 --> 00:03:18,380
concepts and among other parents.

00:03:18,380 --> 00:03:27,160
We have they had a understanding of the craft generally, and how to create that imagery.

00:03:27,160 --> 00:03:32,330
How to mix the colours, and how the light behaves; what brushes to use depending on

00:03:32,330 --> 00:03:36,630
the material, they needed to be reassembled.

00:03:36,630 --> 00:03:46,489
Caravaggio managed to create art on big canvasses, something that was not possible due to the

00:03:46,489 --> 00:03:50,230
technology that was used at the time.

00:03:50,230 --> 00:03:57,070
This doesn't mean that all the classical periods were not continuing with the development of

00:03:57,070 --> 00:04:07,060
their art, they continued until the industrial revolution when the introduction of the photography

00:04:07,060 --> 00:04:17,030
and film was introduced in society, and painters stuck, they transferred their art forms in

00:04:17,030 --> 00:04:21,050
different mediums.

00:04:21,050 --> 00:04:30,380
In the 1970s, a group of artists created hyper-realism to resist the mainstream photography in the

00:04:30,380 --> 00:04:37,220
arts, and GPU used that precisely with maths and physics.

00:04:37,220 --> 00:04:43,580
Knowing what brush or paint texture to take and to use in your art will define your final

00:04:43,580 --> 00:04:48,300
imagery output and your audience.

00:04:48,300 --> 00:04:54,870
But how you use do all this, a little explanation of how you can produce work might be relevant

00:04:54,870 --> 00:04:56,130
in this case.

00:04:56,130 --> 00:05:04,180
There are two sides that you need to take care, the geometry buffer and the fragment

00:05:04,180 --> 00:05:06,669
buffer, or pixel buffer.

00:05:06,669 --> 00:05:11,570
As the name described in one, one handles the geometry better and the other one handles

00:05:11,570 --> 00:05:14,240
the fragments better.

00:05:14,240 --> 00:05:17,150
Both are interconnected by uniform and attributes that move, data.

00:05:17,150 --> 00:05:22,710
They move data between both buffers.

00:05:22,710 --> 00:05:27,930
You can transform them every single time in virtual space and in virtual time.

00:05:27,930 --> 00:05:32,080
The amount of Kate that is loaded to these buffers -- the amount of data that is loaded

00:05:32,080 --> 00:05:33,590
to the buffers charges the performance budget.

00:05:33,590 --> 00:05:39,169
You will have to be careful how you create your assets and display it in their application.

00:05:39,169 --> 00:05:44,460
A fine balance between them, otherwise the application might suffer the risk to get blocked

00:05:44,460 --> 00:05:50,430
by the browser, or user security, or user experience issues.

00:05:50,430 --> 00:05:54,580
How do we create those assets to have that balance in your application?

00:05:54,580 --> 00:05:59,430
First, I'm going to explain about 3D modelling capturing.

00:05:59,430 --> 00:06:06,060
There are multiple methods to create but one of the most popular ones is where you surround

00:06:06,060 --> 00:06:13,790
your audience with multiple cameras and capture the images of that object and then get all

00:06:13,790 --> 00:06:20,530
the data points, and put it into your modelling.

00:06:20,530 --> 00:06:35,160
This is a hexagonal surround.

00:06:35,160 --> 00:06:41,550
This is a complex environment, racing games, they are done this way for video game consoles,

00:06:41,550 --> 00:06:49,160
for example, and cylindrical ones are done for human bodies or more complex shapes.

00:06:49,160 --> 00:06:54,550
Another way is to laser scan the object.

00:06:54,550 --> 00:07:03,889
This method is pretty great for reverse engineering on some objects, and it's used for decoration

00:07:03,889 --> 00:07:10,100
of cars or other objects that are industrial production.

00:07:10,100 --> 00:07:18,419
The most classical one to create the objects is by volumetric from blueprint.

00:07:18,419 --> 00:07:25,920
It gives less noise in the correction but it takes a lot of time to optimise, so it's

00:07:25,920 --> 00:07:30,039
not cost-effective compared with the other two methods.

00:07:30,039 --> 00:07:36,660
Once you have all that, with you're ready to remove the excesses by running the 3D model

00:07:36,660 --> 00:07:47,449
tools and you take out the - manually, your team is required to arrange - misarray, and

00:07:47,449 --> 00:07:57,530
place the normal vector perpendicular to the triangle in order to have accurate lights

00:07:57,530 --> 00:08:02,300
and reflections in the object.

00:08:02,300 --> 00:08:05,310
The creation of textures is also important.

00:08:05,310 --> 00:08:09,330
It is used methods like analysis as well.

00:08:09,330 --> 00:08:17,169
When you take the photograph of the texture that you want to replicate, and just in an

00:08:17,169 --> 00:08:24,360
image-processing tool like Photoshop, or something like that, and just adjust the value of the

00:08:24,360 --> 00:08:29,139
pixels and accommodate it for being able to be scaleable.

00:08:29,139 --> 00:08:35,250
Once you have that texture, you can reduce some information from the channels and then

00:08:35,250 --> 00:08:40,610
you can create other textures like the normal maps, and so on.

00:08:40,610 --> 00:08:46,110
The way how you arrange these textures in your programme are going to transform the

00:08:46,110 --> 00:08:50,380
different visual output, so you have to be careful how you arrange them and you have

00:08:50,380 --> 00:08:56,670
to play with those textures and adjust them, and you will see how the final material is

00:08:56,670 --> 00:08:59,890
going to be represented in your display.

00:08:59,890 --> 00:09:08,630
For that, it's necessary to have knowledge of shading programme and 3D renders, whatever

00:09:08,630 --> 00:09:09,630
it is.

00:09:09,630 --> 00:09:10,630
It's important.

00:09:10,630 --> 00:09:21,290
Realistic 3D are large applications, so you have to treat them like big applications in

00:09:21,290 --> 00:09:22,550
JavaScript.

00:09:22,550 --> 00:09:29,410
They require much data, so the loading process can be long.

00:09:29,410 --> 00:09:35,040
There are many presentations already in this video conference where you can take information

00:09:35,040 --> 00:09:40,600
into of how to create the large applications.

00:09:40,600 --> 00:09:46,740
Generally speaking, the advice would be the same: you have to reduce the server calls

00:09:46,740 --> 00:09:54,380
when loading scripts and assets as much as possible, load first scripts and styles, load

00:09:54,380 --> 00:09:55,399
then textures.

00:09:55,399 --> 00:10:01,450
I like to initialise the fragment shaders right after I finish loading the textures.

00:10:01,450 --> 00:10:07,760
And create the materials, and, right after that, I will load the geometry data, and initialise

00:10:07,760 --> 00:10:14,279
the shaders, and grab those geometries with the fragment shaders previously created.

00:10:14,279 --> 00:10:20,600
I like to follow this path because the declaration of both buffers is very heavy for the machine,

00:10:20,600 --> 00:10:25,709
so you can crush the application, and your experience can get broken at that point.

00:10:25,709 --> 00:10:31,500
Once all this process is over, the rest of the journey is going to be very smooth.

00:10:31,500 --> 00:10:37,600
Creating lighting is important, because it adds volume to the objects to the scene.

00:10:37,600 --> 00:10:44,380
And you need to have a lighting model that is going to be uniform in all the materials.

00:10:44,380 --> 00:10:51,570
As smart as it is, it's not as smart as dragging and dropping, having a AAA graphics out the

00:10:51,570 --> 00:10:52,570
box.

00:10:52,570 --> 00:10:59,430
Indeed, it gives you some advances but you have to play with the values of your materials

00:10:59,430 --> 00:11:03,010
until you find the right balance of it.

00:11:03,010 --> 00:11:07,269
You will see that some materials, when the light is getting too close, the material is

00:11:07,269 --> 00:11:12,459
going to get over illuminated, and going to burn, and in other materials, they're going

00:11:12,459 --> 00:11:18,450
to get back, and be flat, looking very flat.

00:11:18,450 --> 00:11:23,680
So, play with those values, and you're going to be finding your balance in there.

00:11:23,680 --> 00:11:28,610
Other good things about TVR is that it case-by-case basis previous model like lambda illumination

00:11:28,610 --> 00:11:37,690
or - those illuminations give some visual artefacts for you to play when you are required

00:11:37,690 --> 00:11:41,260
to have the textures in there.

00:11:41,260 --> 00:11:45,110
- that it requires.

00:11:45,110 --> 00:11:53,010
The computed illumination and textures is known as back illumination.

00:11:53,010 --> 00:12:02,940
Usually, we use that in level design where the camera is not going to get so close to

00:12:02,940 --> 00:12:09,950
the environment, or the area that is going to be displayed, and it's a great way to save

00:12:09,950 --> 00:12:16,399
the resources that you can use in other areas of your application like the object that it

00:12:16,399 --> 00:12:22,220
requires to look realistic.

00:12:22,220 --> 00:12:27,750
In configurators, the lighting model is fixed, and it's a little bit more easier than the

00:12:27,750 --> 00:12:35,140
work-throughs, for example, in game and level design, because light is fixed and you can

00:12:35,140 --> 00:12:40,360
surround it with your camera all the time, so, there's no need to move the cameras for

00:12:40,360 --> 00:12:43,709
the lights all the time when the camera moves.

00:12:43,709 --> 00:12:52,100
So some engines, the geometries and the lights, others just code the geometries, so, depending

00:12:52,100 --> 00:12:56,550
on that, you choose what illumination to take.

00:12:56,550 --> 00:13:03,740
My recommendation is that you have to target, a minimum of three lights, and the maximum

00:13:03,740 --> 00:13:13,399
of six lights, including its own light if you're building ... .

00:13:13,399 --> 00:13:22,589
Balance this with a material properties, and that will give you more performance space

00:13:22,589 --> 00:13:25,860
for the geometries and textures.

00:13:25,860 --> 00:13:28,140
Post-processing is important.

00:13:28,140 --> 00:13:32,060
It's the second layer of the process in the pipeline.

00:13:32,060 --> 00:13:34,000
But it's expensive for the machine.

00:13:34,000 --> 00:13:39,120
But it gives you another advantage because you can have a layer of colour correction

00:13:39,120 --> 00:13:43,540
or illumination, and adjustment of pixels.

00:13:43,540 --> 00:13:49,050
You can transform at this point with the fragment shaders your image, since it's rasterized

00:13:49,050 --> 00:13:52,000
already by the renderer.

00:13:52,000 --> 00:14:00,110
It's one single image, and you can apply any models in there like neighbouring pixels,

00:14:00,110 --> 00:14:07,181
and you can transform and make it more bright, move them into the dimensions, and create

00:14:07,181 --> 00:14:10,970
all the effects that developers like to do.

00:14:10,970 --> 00:14:17,920
Play with those values until you find your final imagery and you're happy with the visual

00:14:17,920 --> 00:14:21,079
look that you have.

00:14:21,079 --> 00:14:30,570
Now, there was diversification of hardware has brought us great opportunities but also

00:14:30,570 --> 00:14:35,570
stillness because finding the next path to take is hard.

00:14:35,570 --> 00:14:45,170
The ways to information through these many mediums we are expecting to happen, and we're

00:14:45,170 --> 00:14:51,110
a little bit confused in how to move around in the development process.

00:14:51,110 --> 00:14:55,170
There is an order of development that needs to be addressed.

00:14:55,170 --> 00:15:02,880
I recommend first to step the first step to target mobile and desktop, and, based on that,

00:15:02,880 --> 00:15:05,210
move to other mediums.

00:15:05,210 --> 00:15:12,970
I'm going to speak about it precisely with augmented reality with mobile devices, because

00:15:12,970 --> 00:15:18,230
it's what it might come faster, and reaches more audience.

00:15:18,230 --> 00:15:26,800
The reason why it is this order that I recommend, is because if the application doesn't perform

00:15:26,800 --> 00:15:31,920
okay with your basic configuration options, it's not going to perform or look the same

00:15:31,920 --> 00:15:39,029
either in your augmented reality application.

00:15:39,029 --> 00:15:44,820
All my previous comments that I have done with modelling and creating textures, and

00:15:44,820 --> 00:15:50,839
how to arrange your application, are useful for all these mediums.

00:15:50,839 --> 00:15:58,519
Computer reality is not that easy as just to divide the screen for each eye.

00:15:58,519 --> 00:16:03,250
That comes with attacks - with a tax, and you have to play with your application requirements

00:16:03,250 --> 00:16:08,329
how high that that task could be, and make some compromises.

00:16:08,329 --> 00:16:20,540
Mirrors, for example, is another complex part of the virtual reality, and augmented reality.

00:16:20,540 --> 00:16:26,889
Because you have to have many cameras in rendering, and it's not going to support that.

00:16:26,889 --> 00:16:33,260
All the 3D rendering frameworks that exist, they come with controls for easy integration,

00:16:33,260 --> 00:16:39,449
so, you can programme it otherwise it can create those controls easily.

00:16:39,449 --> 00:16:48,310
In the case of AR, reflections can be hard as well, because we can have access to all

00:16:48,310 --> 00:16:55,699
the dimensions of the environment once the user is on a specific geographical position.

00:16:55,699 --> 00:17:03,930
You don't have access to that, so most of these applications, they have their reflections,

00:17:03,930 --> 00:17:12,029
textures, so the visuals are not going to look as great as if the application were going

00:17:12,029 --> 00:17:22,139
to be developed indoors environment.

00:17:22,139 --> 00:17:26,259
We cannot have access to the illumination that is happening in the outside environments,

00:17:26,259 --> 00:17:32,409
it's cloudy, not cloud which, or the sun, it is a specific time.

00:17:32,409 --> 00:17:35,889
That affects the final output.

00:17:35,889 --> 00:17:43,440
And that is something that it can take some time to reach, to have high fidelity, like

00:17:43,440 --> 00:17:52,070
indoors development where you have control of the illumination and control of how the

00:17:52,070 --> 00:17:58,259
environment looks, so the application looks okay with it.

00:17:58,259 --> 00:18:07,109
This approach works, for example, with advertisement billboards.

00:18:07,109 --> 00:18:13,269
Art works in art galleries, or dealership presentations in dealership stores, or retail

00:18:13,269 --> 00:18:15,779
stores, and so on.

00:18:15,779 --> 00:18:21,009
Be careful with the amount of data that you're going to use in your virtual reality application

00:18:21,009 --> 00:18:26,799
because you have to allocate memory for the camera rendering which is going to be in high

00:18:26,799 --> 00:18:30,769
definition, so that is some cost in there as well.

00:18:30,769 --> 00:18:36,799
You cannot use for your treaty data, plus the geographical position tracking system.

00:18:36,799 --> 00:18:42,580
It will take some memory, and that system, we are going to get the plain ground where

00:18:42,580 --> 00:18:47,720
we are going to address our development of the scene.

00:18:47,720 --> 00:18:59,549
As conclusions, Chiaroscuro is deeply embedded in computer graphics.

00:18:59,549 --> 00:19:11,190
The art influence ing colour, typography for the interfaces.

00:19:11,190 --> 00:19:16,529
... that opens space for more data to be computed, and more space for data to be computed means

00:19:16,529 --> 00:19:20,669
you have more room to improve your graphics.

00:19:20,669 --> 00:19:26,970
The way to learn is getting information from other tools, whether by books, documentaries,

00:19:26,970 --> 00:19:29,639
presentations, scientific papers, et cetera.

00:19:29,639 --> 00:19:33,830
And apply those concepts with trial and error experimentation.

00:19:33,830 --> 00:19:40,909
Target mobile first, desktop after, and later other mediums.

00:19:40,909 --> 00:19:45,159
What is next for photorealism?

00:19:45,159 --> 00:19:48,630
We're following closely what video game consoles can do.

00:19:48,630 --> 00:19:53,850
We expect to have better retracing methods and more accurate illumination models in the

00:19:53,850 --> 00:20:01,200
future, more virtual reality and augmented reality is happening, and it's expected to

00:20:01,200 --> 00:20:02,200
increase.

00:20:02,200 --> 00:20:08,700
Use WebGL or hardware accelerated APIs for 2D and 3D rendering as much as possible, because

00:20:08,700 --> 00:20:15,049
with that power at your disposal to be used, you can render or analyse more data.

00:20:15,049 --> 00:20:17,509
Don't be afraid of it.

00:20:17,509 --> 00:20:21,460
Dig into it, and use that power to extend your design and artist ic abilities.

00:20:21,460 --> 00:20:26,889
I hope that I wrote some using information for you today, and I clear some questions

00:20:26,889 --> 00:20:28,010
that you might have.

00:20:28,010 --> 00:20:33,309
This is the a long topic and hard to fill it in a 25-minute talk.

00:20:33,309 --> 00:20:40,781
If you want to keep talking, drop me a line at my email address or you can write to me

00:20:40,781 --> 00:20:42,679
on Twitter.

00:20:42,679 --> 00:20:49,950
We can talk about this, or something that I call .NET hyper realism.

00:20:49,950 --> 00:20:56,960
Thank you so much for your attention, and for being here after the great party last

00:20:56,960 --> 00:20:57,960
night!

00:20:57,960 --> 00:20:58,460

YouTube URL: https://www.youtube.com/watch?v=YHVKME6vYjY


