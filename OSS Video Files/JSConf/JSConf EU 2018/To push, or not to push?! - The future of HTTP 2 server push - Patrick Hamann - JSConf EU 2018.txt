Title: To push, or not to push?! - The future of HTTP 2 server push - Patrick Hamann - JSConf EU 2018
Publication date: 2018-06-15
Playlist: JSConf EU 2018
Description: 
	HTTP/2 server push gives us the ability to proactively send assets to a browser without waiting for them to be requested. Sounds great, right?!

However, is this new mechanism really the silver bullet we all thought it was? Is it time to abandon our build systems and stop bundling our assets entirely? Or are lack of server support and browser inconsistencies holding us back? Lastly, what are new specifications such as cache digests and the 103 status code doing to improve the situation?

Using new research and real-world examples, this talk will take a deep dive into HTTP/2 server push, exploring the current and future best practices for loading assets in the browser. Giving us the knowledge to make better decisions when loading our web pages and ultimately leading to faster, more resilient user experiences.

OMG JSConf EU is coming back in 2019 https://2019.jsconf.eu/
Captions: 
	00:00:09,800 --> 00:00:10,720
Hello, Berlin?

00:00:10,720 --> 00:00:11,820
How is everyone?

00:00:11,820 --> 00:00:15,340
It's a pleasure to be here on the stage.

00:00:15,340 --> 00:00:19,180
I've been coming to JSConf for years and so privileged, and it's a pleasure to be back

00:00:19,180 --> 00:00:22,340
on the stage and give back to the community.

00:00:22,340 --> 00:00:27,769
Sad that I'm not here with my family because coming back to JSConf every time feels like

00:00:27,769 --> 00:00:32,660
coming back to see my family, and I think that's because of the amazing community we

00:00:32,660 --> 00:00:34,350
have built here, and the organisers built.

00:00:34,350 --> 00:00:40,430
A massive round of applause for the organisers for allows us all to be here to do this.

00:00:40,430 --> 00:00:41,430
[Applause].

00:00:41,430 --> 00:00:42,480
My name is Patrick Hamann.

00:00:42,480 --> 00:00:51,790
I work for the Edge Cloud provider Fastly where we specialise in real time content delivery

00:00:51,790 --> 00:00:53,070
for the world's leading brands.

00:00:53,070 --> 00:00:58,740
I there get a lot of time to sit, think about, and research how we can make our customers'

00:00:58,740 --> 00:01:04,330
websites load as fast as possible, and that's what I'm here to talk to you about today.

00:01:04,330 --> 00:01:10,369
Why am I actually here and what does the clickbait-y Buzzfeed headline of to push or not to push

00:01:10,369 --> 00:01:11,450
mean?

00:01:11,450 --> 00:01:16,350
I'm not going to quote Hamlet to you now.

00:01:16,350 --> 00:01:19,130
The reason I'm here is because of this.

00:01:19,130 --> 00:01:20,930
I hear this all the tile.

00:01:20,930 --> 00:01:26,759
I've sat on stages and said exactly this that HTTP/2 is going to solve this problem, literally

00:01:26,759 --> 00:01:27,759
everyone.

00:01:27,759 --> 00:01:30,340
The problem is that it's not.

00:01:30,340 --> 00:01:35,770
Resource diabetic loading in the browser is very, very hard.

00:01:35,770 --> 00:01:39,369
After this talk, hopefully, you will have a better understanding of why it's hard and

00:01:39,369 --> 00:01:45,149
the techniques we have today to overcome the problems it produces.

00:01:45,149 --> 00:01:46,990
Why is it hard?

00:01:46,990 --> 00:01:52,340
Performance is coupled to latency.

00:01:52,340 --> 00:01:54,900
Connection s costs are high.

00:01:54,900 --> 00:02:01,539
TCP's congestion control algorithm is there for very good reasons but penalises us at

00:02:01,539 --> 00:02:04,189
the beginning after connection when it's most important.

00:02:04,189 --> 00:02:07,409
Our critical resources can be hidden to the browsers.

00:02:07,409 --> 00:02:11,599
Browsers are extremely powerful things and have speculative parses but they simply are

00:02:11,599 --> 00:02:17,430
not magic enough to know the resources that you as an application developer want to load.

00:02:17,430 --> 00:02:22,069
Because of that, bandwidth is often under utilised, leaving idle connections open where

00:02:22,069 --> 00:02:27,099
we could be sending resources but we can't do that yet because of the way that browsers

00:02:27,099 --> 00:02:29,150
and servers interact with each other.

00:02:29,150 --> 00:02:36,900
Finally, once we do get it down script, it is extremely to expensive to parse and execute

00:02:36,900 --> 00:02:40,790
and we waste idle time on the network again because of that.

00:02:40,790 --> 00:02:44,180
How can we load our resources mostly?

00:02:44,180 --> 00:02:48,599
What patterns and techniques can we use today and what is coming up in the future to enable

00:02:48,599 --> 00:02:54,459
us to do in the most efficient and speedy way?

00:02:54,459 --> 00:02:58,000
Think about the product or website that you're designing today.

00:02:58,000 --> 00:03:02,840
If you are only allowed to send three resources down the wire, would what they be?

00:03:02,840 --> 00:03:04,299
Is it your fonts?

00:03:04,299 --> 00:03:10,019
The lazy-loaded related comments on the bottom of this ft.com home page or adverts?

00:03:10,019 --> 00:03:11,739
I don't think so.

00:03:11,739 --> 00:03:16,019
What did the user come here for?

00:03:16,019 --> 00:03:22,909
Bench wars from Calibre, who is sitting with us here today, when we talk about loading,

00:03:22,909 --> 00:03:28,049
we talk about a critical request path, and he defines a critical request as one that

00:03:28,049 --> 00:03:33,040
contains an asset that is essential to the content to the user's view port.

00:03:33,040 --> 00:03:36,790
What are your critical resources.

00:03:36,790 --> 00:03:41,049
I want you really to take this away from my talk as I want you to think about what are

00:03:41,049 --> 00:03:45,470
the two or three things you need to send down as soon as possible so that browser can get

00:03:45,470 --> 00:03:49,090
on with rendering and creating a good user experience for your users.

00:03:49,090 --> 00:03:52,250
A critical CSS for your initial route?

00:03:52,250 --> 00:03:54,609
Font or hero images.

00:03:54,609 --> 00:03:57,599
One we don't discuss enough is the application bootstrap data.

00:03:57,599 --> 00:04:03,859
A lot of client-side rendered applications probably make a JSON request that is hidden

00:04:03,859 --> 00:04:04,859
to the browser.

00:04:04,859 --> 00:04:08,879
It is known as a hidden sub resource and the browser doesn't know about it upfront.

00:04:08,879 --> 00:04:13,319
We need to be able to tell the browser what the resource is specifically to our need,

00:04:13,319 --> 00:04:17,259
and to create the delightful user experiences.

00:04:17,259 --> 00:04:21,989
Once you've determined what your critical requests are, you need to think about how

00:04:21,989 --> 00:04:24,150
they contribute to the user's experience.

00:04:24,150 --> 00:04:27,180
After all, performance is a user experience problem.

00:04:27,180 --> 00:04:30,260
What resources do you need to get a first meaningful paint?

00:04:30,260 --> 00:04:34,710
What resources do you have to deliver so that users can start interacting with your website

00:04:34,710 --> 00:04:36,540
as fast as possible.

00:04:36,540 --> 00:04:41,280
It's this section here we will focus on today, this initial loading experience, and how we

00:04:41,280 --> 00:04:46,970
can tell the browser, make, allow the browser to make informed decisions about what it load

00:04:46,970 --> 00:04:49,990
so we can have delightful users' experience.

00:04:49,990 --> 00:04:54,540
So I summarise a good loading strategy as one that prioritises above the file rendering,

00:04:54,540 --> 00:04:55,880
prioritising interactivity.

00:04:55,880 --> 00:05:01,410
It is easy to use because some we look at today aren't necessarily, and innovate importantly,

00:05:01,410 --> 00:05:02,410
measurable.

00:05:02,410 --> 00:05:08,130
The first solution to overcoming a performance problem is to measure your current performance,

00:05:08,130 --> 00:05:11,340
if then optimise for it.

00:05:11,340 --> 00:05:14,150
So the first technique that we are doing, now that we've identified what we should be

00:05:14,150 --> 00:05:16,919
loading, let's see how we can do this efficiently.

00:05:16,919 --> 00:05:19,800
The first I'm going to discuss is the preload API.

00:05:19,800 --> 00:05:24,030
What if we could tell the browser ahead of time what the critical resources are required

00:05:24,030 --> 00:05:25,069
for this?

00:05:25,069 --> 00:05:31,940
The problem is earlier on we identified fonts, and application bootstrap data, as being critical

00:05:31,940 --> 00:05:32,940
resources.

00:05:32,940 --> 00:05:34,270
However, they're hidden from the browser.

00:05:34,270 --> 00:05:35,270
Why is this?

00:05:35,270 --> 00:05:40,690
First, you make a get request for the home page been we wait for the response of that.

00:05:40,690 --> 00:05:45,460
HTML can be parsed I can be mentally so, as the bytes come down the wire, the browser

00:05:45,460 --> 00:05:50,180
can start constructing the DOM without waiting for the HTML file to be delivered.

00:05:50,180 --> 00:05:57,570
They have speculative parses that goes ahead while it's constructing the DOM, finds the

00:05:57,570 --> 00:06:02,830
file sheets and script tags references in the page and initiates fetches for them ahead

00:06:02,830 --> 00:06:04,180
of time.

00:06:04,180 --> 00:06:08,639
But with CSS, unfortunately, it is render-blocking and can't be parsed incrementally.

00:06:08,639 --> 00:06:12,669
We have to wait for all the bytes to come down first because if we didn't, there would

00:06:12,669 --> 00:06:16,520
be lots of painting flashing on the screen because of the way the cascade works.

00:06:16,520 --> 00:06:21,229
Eventually, it is only until this point that the CSS object it model and the document object

00:06:21,229 --> 00:06:23,770
model combine to form the render tree.

00:06:23,770 --> 00:06:28,240
It is only at this point when we have the render tree and we've done the networking

00:06:28,240 --> 00:06:32,639
first which is when the browser will dispatch the font request.

00:06:32,639 --> 00:06:37,919
Your CSS may reference five or six font files but only two are being used for the initial

00:06:37,919 --> 00:06:38,919
load.

00:06:38,919 --> 00:06:42,610
This is why fonts are known as criticals hidden sub resources.

00:06:42,610 --> 00:06:45,069
The browser can't know about them up front.

00:06:45,069 --> 00:06:50,470
The idea of preload is what if we could provide a declarative fetch primitive that initiates

00:06:50,470 --> 00:06:58,229
an early fetch, decoupling that logic, saying to the browser, "I know you're going to find

00:06:58,229 --> 00:07:02,090
the font later on, and I know you need it, or for your JavaScript application, I know

00:07:02,090 --> 00:07:07,430
you're going to make a request about a JSON file to the user, you won't find it later

00:07:07,430 --> 00:07:11,570
in the process," I know about it, perform the networking for it now.

00:07:11,570 --> 00:07:14,110
That's why it is extremely powerful.

00:07:14,110 --> 00:07:23,150
Here, we have three new primitives, one via HTML, and one by JavaScript, by our HTTP link

00:07:23,150 --> 00:07:24,150
headers.

00:07:24,150 --> 00:07:32,060
We also have had module preload specification for those shipping the native browsers already.

00:07:32,060 --> 00:07:37,960
Fonts have to be requested as non-origin, so this is really powerful.

00:07:37,960 --> 00:07:44,580
By adding three HTTP headers, we can tell the browser upfront about our critical resources.

00:07:44,580 --> 00:07:48,300
So if we were to look at the network waterfall for featherweight dominate, for instance,

00:07:48,300 --> 00:07:53,250
before applying this, you will see that the font files are really low priority here, and

00:07:53,250 --> 00:07:58,310
because they haven't been discovered until the CSS file has been parsed, but just by

00:07:58,310 --> 00:08:04,160
adding the preload headers, we can instantly prioritise and initiate those fetches early,

00:08:04,160 --> 00:08:07,729
and so the browser can get on with it.

00:08:07,729 --> 00:08:17,030
Customers saw they had 50 per cent, 1.2 seconds, improvement by adding preload headers for

00:08:17,030 --> 00:08:19,660
their font files and hidden sub roars.

00:08:19,660 --> 00:08:26,530
I've never known a single technique that's one line of code that can have a two-second

00:08:26,530 --> 00:08:31,979
average improvement on the user experience of loading up a page.

00:08:31,979 --> 00:08:37,180
The question that I want to ask, and propose to you, is: is indicating resource hints via

00:08:37,180 --> 00:08:43,360
the HTML like this, in fact, too late in the connection flow, too late in the loading experience

00:08:43,360 --> 00:08:44,360
of the page?

00:08:44,360 --> 00:08:50,880
And that is what HTTP/2 server push comes in, or was specifically designed to solve.

00:08:50,880 --> 00:08:53,170
Let's look at how it can help us.

00:08:53,170 --> 00:08:59,490
First, let's look at the traditional request flow that you to make when you're loading

00:08:59,490 --> 00:09:00,490
a page.

00:09:00,490 --> 00:09:02,130
You perform a get request to your server.

00:09:02,130 --> 00:09:08,060
The server has server think time and perform a database action, or render some template.

00:09:08,060 --> 00:09:15,560
All of the time this is thinking, and, then eventually, it will respond with your index.html.

00:09:15,560 --> 00:09:18,940
Then the browser stars parsing it.

00:09:18,940 --> 00:09:24,821
This makes me sad because we've left the connection open for so long whilst the browser, the server

00:09:24,821 --> 00:09:25,940
was doing that think time.

00:09:25,940 --> 00:09:31,350
At Fastly, we see an average server think time of 200 to 400 milliseconds wasted on

00:09:31,350 --> 00:09:38,029
the wire here, and round-trip can be 800 to 1,000 milliseconds on a good 3G connection.

00:09:38,029 --> 00:09:44,700
What if the server could predict the next thing the client is going to request is that

00:09:44,700 --> 00:09:51,940
main CSS file and flush the bytes for it down as soon as it receives that get request.

00:09:51,940 --> 00:09:53,420
How soon can I use push?

00:09:53,420 --> 00:10:03,050
If you have an HTTP/2 server enabled today, Node natively supports it, we've converged

00:10:03,050 --> 00:10:09,620
using our link preload header to use as the semantic of "I want to push this resource,"

00:10:09,620 --> 00:10:16,490
so if your server is HTTP/2 enabled, it will read these and initiate pushes for you.

00:10:16,490 --> 00:10:18,200
Really super quick win.

00:10:18,200 --> 00:10:23,290
If you don't want to push and you still want the semantics of preload, you can add the

00:10:23,290 --> 00:10:28,630
no-push attribute there, and at Fastly, we realise that you might only want to push and

00:10:28,630 --> 00:10:33,480
not have a race between push and preload, and we allow you to say that and will strip

00:10:33,480 --> 00:10:35,380
the header on the way out.

00:10:35,380 --> 00:10:38,570
What benefit does this actually give us?

00:10:38,570 --> 00:10:43,500
If we look to our common waterfall for loading a page, we've got the index file, then we

00:10:43,500 --> 00:10:48,180
look for the CSS, we find that, and then perform the networking for the JavaScript, and the

00:10:48,180 --> 00:10:49,180
CSS.

00:10:49,180 --> 00:10:53,660
By pushing the resource, we are saving one round trip here, the light-shaded bit.

00:10:53,660 --> 00:10:59,380
The round-trip time is the time it takes for the client to send the request to hit the

00:10:59,380 --> 00:11:02,190
server and back again until we start receiving the first bytes.

00:11:02,190 --> 00:11:08,760
Again, on a 3G connection in Europe, that could be as about 800 milliseconds, in some

00:11:08,760 --> 00:11:10,639
other developing areas, that could be seconds.

00:11:10,639 --> 00:11:12,130
So it's great.

00:11:12,130 --> 00:11:17,930
It gives us a one round-trip time saving to improve our loading experience.

00:11:17,930 --> 00:11:22,660
But in the here it's idle time still left on the connection.

00:11:22,660 --> 00:11:26,889
This makes me really, really sad.

00:11:26,889 --> 00:11:27,889
Why is this?

00:11:27,889 --> 00:11:29,940
Let's look again at this request flow.

00:11:29,940 --> 00:11:34,810
As a server push is indicated via the link header, we have to wait for the server to

00:11:34,810 --> 00:11:40,100
do its think time in responding before we as a server, or your proxy layer, your CDN,

00:11:40,100 --> 00:11:48,410
if you use Apache is only until we've received all of the HTML bytes that we initiate that

00:11:48,410 --> 00:11:49,410
push.

00:11:49,410 --> 00:11:52,891
That is far too late in the connection flow because we've still got this idle connection

00:11:52,891 --> 00:11:54,600
time.

00:11:54,600 --> 00:11:55,769
This makes me really sad.

00:11:55,769 --> 00:11:59,680
Wasn't this what push was designed to solve?

00:11:59,680 --> 00:12:05,579
To summarise, push gives us a round trip saving, I would argue the fact that, if you need,

00:12:05,579 --> 00:12:09,029
with , you have got no that long server think time, you should be optimising your servers

00:12:09,029 --> 00:12:10,470
instead.

00:12:10,470 --> 00:12:14,089
Is link header far too late in the connection flow?

00:12:14,089 --> 00:12:19,310
And this is where asynch push comes in.

00:12:19,310 --> 00:12:24,029
To be able to truly utilise push, we need to decouple the pushing behaviour from our

00:12:24,029 --> 00:12:29,339
applications HTML response, and do it right at the beginning of the connection flow.

00:12:29,339 --> 00:12:35,770
So a more common architecture as I discussed you may have a CDN or a proxy as it receives

00:12:35,770 --> 00:12:40,960
that request it is only there and then whilst we have that server think time, we can push

00:12:40,960 --> 00:12:42,250
the bytes down the wire.

00:12:42,250 --> 00:12:47,440
I forgot to mention earlier on that the way that push works is HTTP/2 has a binary data

00:12:47,440 --> 00:12:48,710
framing layer.

00:12:48,710 --> 00:12:53,880
This is a magical thing that allows us no longer just plain text on the wire, on our

00:12:53,880 --> 00:12:59,019
TCP connection, now we have binary frames allowing us to interleave separate data frames

00:12:59,019 --> 00:13:03,070
for subsequent requests or multiple questions at the same time, called multiplexing.

00:13:03,070 --> 00:13:08,850
This is why we can have a single HTTP/2 open and deliver hundreds of resources at the same

00:13:08,850 --> 00:13:09,850
time.

00:13:09,850 --> 00:13:15,029
Push works by sending a push promise frame, as you can see here, a data frame sent to

00:13:15,029 --> 00:13:23,040
the client saying I'm going to send you these bytes, and here they are, go and have them.

00:13:23,040 --> 00:13:26,660
Utilising idle connection time like this makes me extremely happy.

00:13:26,660 --> 00:13:28,800
Again you're wondering how you can do this.

00:13:28,800 --> 00:13:32,670
This is using Node standard HTTP/2 standard library.

00:13:32,670 --> 00:13:34,190
I've got a request handler here.

00:13:34,190 --> 00:13:36,889
I checked to see if the URL matches.

00:13:36,889 --> 00:13:42,449
If it does, I want to initiate a push, here is where you can flush down your critical

00:13:42,449 --> 00:13:46,529
resources that you've identified, piping they think them down a extreme, and then you can,

00:13:46,529 --> 00:13:54,850
down a stream, and then you can — so let's see the benefits that this has on our waterfall.

00:13:54,850 --> 00:13:59,370
As you can see here, when our push example, we had the one round-trip saving when using

00:13:59,370 --> 00:14:00,519
the link header.

00:14:00,519 --> 00:14:06,529
By using asynch push, we've hit the Holy Grail that we are pushing the styles that JavaScript

00:14:06,529 --> 00:14:10,399
required to render the screen before the HTML is even consumed.

00:14:10,399 --> 00:14:15,310
Now the browser has all of the information it needs instantly to render as soon as the

00:14:15,310 --> 00:14:16,560
HTML is finished.

00:14:16,560 --> 00:14:19,450
That makes Patrick extremely happy!

00:14:19,450 --> 00:14:22,660
But what about the repeat view I hear you asking?

00:14:22,660 --> 00:14:24,839
I definitely ask this a lot.

00:14:24,839 --> 00:14:30,709
We have already sent the assets to the clients.

00:14:30,709 --> 00:14:34,820
The client should have that asset in its patch.

00:14:34,820 --> 00:14:38,800
The problem is that we've got no way of indicating that the serve questioner and what is in its

00:14:38,800 --> 00:14:39,860
cache.

00:14:39,860 --> 00:14:48,160
What will happen is on the repeat view and will be detrimental here and create tension

00:14:48,160 --> 00:14:54,230
on the underlying network link and end up worse than when you [sound feed distorted].

00:14:54,230 --> 00:15:23,389
The request

00:15:23,389 --> 00:15:28,940
never even goes out to the network, and so we don't have to push, so we benefit from

00:15:28,940 --> 00:15:35,100
not having to worry about the cache state.

00:15:35,100 --> 00:15:38,560
But that's only if you have a service worker, and a lot of us may not have.

00:15:38,560 --> 00:15:42,170
So the server has got no knowledge of the class state, and this is a really, really

00:15:42,170 --> 00:15:45,090
big problem.

00:15:45,090 --> 00:15:46,090
What is the problem?

00:15:46,090 --> 00:15:49,430
The theory there is great: push should be amazing.

00:15:49,430 --> 00:15:54,310
We should be able to give the client all of the information it needs before I've even

00:15:54,310 --> 00:15:57,970
received the HTML but the adoption is extremely low.

00:15:57,970 --> 00:15:58,970
Why is that?

00:15:58,970 --> 00:15:59,970
What is the problem?

00:15:59,970 --> 00:16:04,270
I also want to make a poll here: who is using H2 in production right now?

00:16:04,270 --> 00:16:09,180
Leave your hands up if you're also using push.

00:16:09,180 --> 00:16:14,149
So only about ten per cent of the people that were using push, and there was only probably

00:16:14,149 --> 00:16:17,079
only about 20 per cent of the room using H2 at all.

00:16:17,079 --> 00:16:18,079
What is the problem?

00:16:18,079 --> 00:16:21,130
Why is no-one adopting it?

00:16:21,130 --> 00:16:23,470
To do that, let's take a look at the request flow again.

00:16:23,470 --> 00:16:27,920
Once we've sent the get requests, and we start pushing the bytes down the wire, I lied to

00:16:27,920 --> 00:16:29,010
you earlier on.

00:16:29,010 --> 00:16:34,389
Even though the browser doesn't have a mechanism for telling its cache state, it has a mechanism

00:16:34,389 --> 00:16:39,490
to reset that stream, so you can send a reset stream saying I don't want those bytes any

00:16:39,490 --> 00:16:42,449
more, I've got it in my cache.

00:16:42,449 --> 00:16:47,910
Unfortunately, we've got a race condition here that, by the time the client has initiated

00:16:47,910 --> 00:16:52,660
the reset stream but by the time that gets to the server, because our critical resources

00:16:52,660 --> 00:16:58,149
are normally small, we have flushed the bytes down the wire already, or, if more importantly,

00:16:58,149 --> 00:17:04,630
they left the user space, it's inside their TCP buffer, and once something is in the kernel's

00:17:04,630 --> 00:17:10,660
TCP space, there's no way for an application to prevent those being flushed down the physical

00:17:10,660 --> 00:17:11,660
listening.

00:17:11,660 --> 00:17:17,360
We've got a race conditions here which isn't a good thing.

00:17:17,360 --> 00:17:24,100
The new quick protocol that was — QUIC protocol is going to hopefully solve a lot of those

00:17:24,100 --> 00:17:30,630
problems by moving a lot of the application layer out of the kernel into user space and

00:17:30,630 --> 00:17:34,300
allow us to do amazing things here.

00:17:34,300 --> 00:17:40,880
Another common area of misconception of HTTP/2 server push is how the servers cache that

00:17:40,880 --> 00:17:42,210
resource.

00:17:42,210 --> 00:17:47,530
Once I pushed all the bytes down, still a request that is initiated from your page needs

00:17:47,530 --> 00:17:52,790
to claim that resource from the HTTP/2's push cache.

00:17:52,790 --> 00:17:57,610
A push cache is not connected to the HTTP cache, it is connected to the lifetime of

00:17:57,610 --> 00:18:01,890
that single HTTP/2 connection, so, for every H2 connection you have to an origin, you're

00:18:01,890 --> 00:18:04,440
going to have a dedicated push cache for that.

00:18:04,440 --> 00:18:08,040
One of the problems is that the push cache is the last to be requested.

00:18:08,040 --> 00:18:12,720
As the request leaves the page, first it will go to the memory cache attached to that document,

00:18:12,720 --> 00:18:16,780
it's all of the resources that document has already requested.

00:18:16,780 --> 00:18:21,140
Then it will be looked up in the service worker cache, then the HTTP cache, the service worker

00:18:21,140 --> 00:18:26,550
caches are shared globally where the memory caches are pushed, and finally, it will try

00:18:26,550 --> 00:18:28,550
and look inside the push cache.

00:18:28,550 --> 00:18:32,620
It's highly likely a lot of the time the push cache will never be claimed, and therefore

00:18:32,620 --> 00:18:37,290
therefore you've wasted sending bytes down the wire.

00:18:37,290 --> 00:18:42,820
The other tricky thing here to note is that HTTP/2 connections are credentialed or non-credentialed

00:18:42,820 --> 00:18:48,470
which is why a font file has to be served as a non-credentialed resource.

00:18:48,470 --> 00:18:55,300
If a CSS file was to push a font file, the CSS file is credentialed and so actually won't

00:18:55,300 --> 00:18:58,890
be able to claim the font file request.

00:18:58,890 --> 00:19:04,280
So to summarise, the problem here is the push cache is hats to be authoritative for it,

00:19:04,280 --> 00:19:06,630
a single cache per connection.

00:19:06,630 --> 00:19:10,700
The items can only be claimed once, so, if you have multiple tabs open for the single

00:19:10,700 --> 00:19:14,700
one, the push can only be sent once, and you have to repeat that push.

00:19:14,700 --> 00:19:25,600
The thing that I find is that the cache behaviour is not specced as part of the implementation.

00:19:25,600 --> 00:19:30,510
If you do consider using HTTP/2 push, I urge you to read this blog post by Jake Archbold,

00:19:30,510 --> 00:19:35,090
where he goes into great detail and the browser inconsistencies, and it's tougher than we

00:19:35,090 --> 00:19:36,090
thought it was.

00:19:36,090 --> 00:19:49,720
A tl;dr summarisation of that, we can only ably use it in Chrome and Firefox.

00:19:49,720 --> 00:19:54,800
The networking stack is — Edge have done great work.

00:19:54,800 --> 00:20:00,560
One of the great things that Jake did in this post was to document all the problems and

00:20:00,560 --> 00:20:04,960
create tickets on all of the browsers bug trackers, so my hat's off to Jake for doing

00:20:04,960 --> 00:20:05,960
that.

00:20:05,960 --> 00:20:09,130
Edge are improving but not yet.

00:20:09,130 --> 00:20:12,270
Still one connection per tag.

00:20:12,270 --> 00:20:15,090
This leaves us to UA sniff for push.

00:20:15,090 --> 00:20:19,100
That's really, really bad, and we know what happens when we start going down that route

00:20:19,100 --> 00:20:20,960
of UA sniffing.

00:20:20,960 --> 00:20:24,220
The race of adoption.

00:20:24,220 --> 00:20:30,410
For instance as at Fastly, we only see 0.008 requests — that's 800 questions out of a

00:20:30,410 --> 00:20:35,500
million, we do around 6 million requests a second, that we see a push initiated.

00:20:35,500 --> 00:20:39,680
If it was so good, everybody should be using it, but they're not.

00:20:39,680 --> 00:20:44,880
This lack of adoption has got so bad that certain vendors have considered ripping push

00:20:44,880 --> 00:20:48,630
out of the HTTP/2 specification entirely.

00:20:48,630 --> 00:20:49,740
When should you push?

00:20:49,740 --> 00:20:54,700
Only if you have long round-trip times or an app shell architecture and you could use

00:20:54,700 --> 00:21:00,460
the purple appear or if you could manage your own cache state natively, or if you've got

00:21:00,460 --> 00:21:04,260
a native application or an electron app.

00:21:04,260 --> 00:21:10,650
Is that round-trip worth the complexity of the benefits it gives us, and are there simple

00:21:10,650 --> 00:21:12,770
solutions out there that we can use?

00:21:12,770 --> 00:21:20,060
This is why I want to talk about what is ahead for us in the future.

00:21:20,060 --> 00:21:26,480
Can we just fix the HTTP push problems?

00:21:26,480 --> 00:21:27,950
They're quite simple.

00:21:27,950 --> 00:21:29,390
What can we do to fix that?

00:21:29,390 --> 00:21:32,900
That is where the cached digest specification comes in.

00:21:32,900 --> 00:21:36,950
What if the browser, whenever it created a new connection could send a frame called a

00:21:36,950 --> 00:21:43,000
cache digest that contained a cuckoo filter which is a probabilistic data structure representing

00:21:43,000 --> 00:21:46,630
all the items the browser has for the clash of that host name?

00:21:46,630 --> 00:21:50,420
Then the server can be much more intelligent about what it wants to push.

00:21:50,420 --> 00:21:56,840
It's I'm not going to push main.css but I will send you the new version of my JavaScript

00:21:56,840 --> 00:22:00,990
application because you don't have the latest version of that.

00:22:00,990 --> 00:22:06,050
I'm excited by not just for solving push, this opens up a lot of great opportunity for

00:22:06,050 --> 00:22:10,600
us for instance in the JavaScript bundling and modules world that we could choose and

00:22:10,600 --> 00:22:15,140
be more intelligence of what we bundle and what we send down and we have a bit more knowledge

00:22:15,140 --> 00:22:17,970
about the client cache state.

00:22:17,970 --> 00:22:22,560
Going back to the repeat view, if we had cache digests for our first view we could push and

00:22:22,560 --> 00:22:27,280
on the subsequent view, the client says I've got that in my resource and we wouldn't have

00:22:27,280 --> 00:22:30,130
to push it.

00:22:30,130 --> 00:22:34,080
Cache digest specification is an experimental in ITF at the moment.

00:22:34,080 --> 00:22:39,850
It was proposed by my colleague, and it's been worked on, but I think we're going to

00:22:39,850 --> 00:22:42,280
see implementations land in browsers soon.

00:22:42,280 --> 00:22:46,260
Fastly have got the first implementation of the server side as that of that in that you

00:22:46,260 --> 00:22:51,970
are open source server, but this seems too complicated.

00:22:51,970 --> 00:22:56,550
Like we are still having to maintain a lot of logic to manage state between the client

00:22:56,550 --> 00:22:57,890
and the server.

00:22:57,890 --> 00:23:01,780
Http after all is a stateless protocol, why it's so beautiful.

00:23:01,780 --> 00:23:03,460
It is complicated.

00:23:03,460 --> 00:23:06,980
This is where the 103 early-hint specification comes in.

00:23:06,980 --> 00:23:09,160
This is again pursued by my colleague.

00:23:09,160 --> 00:23:13,090
Who has heard of 100 informational ranges at all?

00:23:13,090 --> 00:23:15,610
I hadn't at all until this came out.

00:23:15,610 --> 00:23:20,890
New HTTP response code that allows the server to indicate to the client the resource that

00:23:20,890 --> 00:23:25,550
is are going to be required for the 200 response that is coming.

00:23:25,550 --> 00:23:30,920
It looks like this, when we perform a Get request, we then send down an initial response

00:23:30,920 --> 00:23:37,370
just containing headers using our friend link preload and the browser gets to decide I've

00:23:37,370 --> 00:23:41,940
got this and don't have that, and initiates the fetches early during the think time.

00:23:41,940 --> 00:23:44,170
This is what it would look like on the wire.

00:23:44,170 --> 00:23:47,180
It is as simple as that.

00:23:47,180 --> 00:23:51,650
This is why it's more powerful than push because we are moving that logic and decision process

00:23:51,650 --> 00:23:56,670
back to the browser where it belongs, so the server can send down a 103 response saying

00:23:56,670 --> 00:24:01,790
here are the critical resources for this page, you decide what you want to do with it and

00:24:01,790 --> 00:24:03,440
follow up with a 200.

00:24:03,440 --> 00:24:06,950
Again, this has been accepted by ITF in experimental mode.

00:24:06,950 --> 00:24:11,380
We've got a working implementation on the server side but the problem is at the moment,

00:24:11,380 --> 00:24:15,580
many browser are worried about the complexity this adds to the networking stack and worried

00:24:15,580 --> 00:24:20,670
we will break the internet because middle proxies don't understand the 100 range but

00:24:20,670 --> 00:24:24,080
only served over TLS to overcome the problems.

00:24:24,080 --> 00:24:28,051
Early hints gives us all the same benefits as push but possession simpler and we can

00:24:28,051 --> 00:24:34,260
leverage the browser cache now not have the complexities of the H2 server push cache and

00:24:34,260 --> 00:24:40,160
it's great because it allows the client to do the decision-making.

00:24:40,160 --> 00:24:47,790
We've got preload to do the headers, and new specification coming out that allows us to

00:24:47,790 --> 00:24:53,860
decorate our HTML with resources saying I know this hero image is high priority but

00:24:53,860 --> 00:24:55,030
this fetch request is low.

00:24:55,030 --> 00:25:00,020
I urge you to go and check out the specification and add to the GitHub page here.

00:25:00,020 --> 00:25:04,410
So, in closing, I've run out of time, so I've got to wrap up.

00:25:04,410 --> 00:25:08,660
Eve only scratched the surface here of methodologies but I hope I've given you techniques to use

00:25:08,660 --> 00:25:09,680
today.

00:25:09,680 --> 00:25:14,430
HTTP/2 doesn't solve everything but there are a lot of things to solve this.

00:25:14,430 --> 00:25:19,310
Resource-loading in the browser is hard but I'm excited by the future.

00:25:19,310 --> 00:25:22,160
Most importantly, performance is for humans.

00:25:22,160 --> 00:25:26,200
Optimise for a good user experience, not for the networking stack.

00:25:26,200 --> 00:25:29,350
Measure your experience and optimise for that.

00:25:29,350 --> 00:25:34,970
So, the checklist, if I was going to do today, identify your critical resources, preload

00:25:34,970 --> 00:25:40,050
any hidden sub resources, avoid push for possible and the future is looking great.

00:25:40,050 --> 00:25:44,470
We can use early hints when they become available.

00:25:44,470 --> 00:25:45,470
Thank you very much.

00:25:45,470 --> 00:25:45,970

YouTube URL: https://www.youtube.com/watch?v=cznVISavm-k


