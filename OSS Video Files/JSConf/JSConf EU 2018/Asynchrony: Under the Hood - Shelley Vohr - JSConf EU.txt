Title: Asynchrony: Under the Hood - Shelley Vohr - JSConf EU
Publication date: 2018-06-27
Playlist: JSConf EU 2018
Description: 
	This talk will explore the conceptual underpinnings of asynchronous programming options, and the drawbacks and advantages to each. JS has supported callbacks since 2009, and as years have gone by it’s added support for promises, generators, and now async/await. On a surface level, each of these techniques seeks to answer a question of how to access data not immediately available, but a deeper look into how each works on a granular level will show their implementation differences and how these differences affect usage. We’ll also take a look at how intermediate values, and errors are affected by each method. I’ll walk through a series of scenarios so you can better visualize performance differences, and how each method propagates data through the stack and the event loop. Finally, I’ll talk about where the future of async may be headed. Armed with new knowledge from this deep dive, the potentially treacherous road to fully understanding async will hopefully become a smoother ride!

OMG JSConf EU is coming back in 2019 https://2019.jsconf.eu/
Captions: 
	00:00:09,040 --> 00:00:13,360
Hi everybody ! Thank you again for the introduction

00:00:13,660 --> 00:00:18,740
I'm Shelley, a software engineer at GitHub working on open source.

00:00:18,980 --> 00:00:24,000
Today, I would like to do a deep dive into the mechanics of asynchronous programming

00:00:24,009 --> 00:00:25,939
in JavaScript.

00:00:25,939 --> 00:00:31,610
To make sure we're all on the same page, before I get started, I will go over basic principles

00:00:31,610 --> 00:00:37,680
of asynch, and then we will launch into the different methodologies and nuances of what

00:00:37,680 --> 00:00:43,680
exactly differentiates them, and, finally, we will compare over the spectrum of options

00:00:43,680 --> 00:00:48,949
to discuss which situations require which approaches.

00:00:48,949 --> 00:00:53,399
Let's say you have a programme detained within a contained within a final file.

00:00:53,399 --> 00:00:54,969
It's mate up of functions.

00:00:54,969 --> 00:01:00,609
At any given time, only one of these is going to be executing now.

00:01:00,609 --> 00:01:04,629
The rest will execute later at some point in the future.

00:01:04,629 --> 00:01:08,360
That, there, is the crux of asynch.

00:01:08,360 --> 00:01:13,770
It's the relationship between now and later, and the way in which you manage this relationship

00:01:13,770 --> 00:01:15,520
with your code.

00:01:15,520 --> 00:01:20,970
What is key here, however, and what causes some of the most difficulties for developers

00:01:20,970 --> 00:01:26,750
when they're just starting out, is that later does not mean strictly and immediately after

00:01:26,750 --> 00:01:28,330
now.

00:01:28,330 --> 00:01:32,120
It could be at any point in the future, and you don't necessarily know when that will

00:01:32,120 --> 00:01:33,120
be.

00:01:33,120 --> 00:01:38,750
Now, let's move on to some of the technical underpinnings of how code is executed in the

00:01:38,750 --> 00:01:40,970
JavaScript environment.

00:01:40,970 --> 00:01:45,000
In pursuit of this understanding, it's best to start with the event loop.

00:01:45,000 --> 00:01:51,360
The event loop can best be conceptualised as an endlessly running singly threaded loop

00:01:51,360 --> 00:01:56,280
where each iteration runs a small chunk of code in the programme.

00:01:56,280 --> 00:02:01,890
If you want to run a chunk of code at a later time, that chunk would simply be added to

00:02:01,890 --> 00:02:04,390
the queue for the event loop.

00:02:04,390 --> 00:02:10,340
When the time came that you desired it to execute, it would be dequeued and executed.

00:02:10,340 --> 00:02:15,580
With ES6 came a new concept called the microtasks queue, but we will save that for a little

00:02:15,580 --> 00:02:16,770
bit later.

00:02:16,770 --> 00:02:24,330
It is also important to mention that JavaScript has what is known as run-to-completion semantics.

00:02:24,330 --> 00:02:30,780
This means that the current task always finishes before the next task begins.

00:02:30,780 --> 00:02:35,420
Or until it explicitly yields control back to the event loop.

00:02:35,420 --> 00:02:41,360
As a result of this, each task has complete control over all current states, and does

00:02:41,360 --> 00:02:47,050
not need to worry about another task modifying things at the exact same time.

00:02:47,050 --> 00:02:52,910
Looking at the code here, running this will always print first and then second, because

00:02:52,910 --> 00:03:00,170
the function, starting in setTimeout is added to the task queue immediately but only executed

00:03:00,170 --> 00:03:04,740
after the current piece of code is down since it yielded control.

00:03:04,740 --> 00:03:07,480
Now let's look at the call stack.

00:03:07,480 --> 00:03:15,770
When a function foo calls a function bar, bar needs to know where inside foo to return

00:03:15,770 --> 00:03:18,319
to after it's done.

00:03:18,319 --> 00:03:21,900
This information is managed with the call stack.

00:03:21,900 --> 00:03:26,910
Take a look at the set of three functions on the left-hand side of the slide.

00:03:26,910 --> 00:03:30,970
Let's walk through how the stack will look as the programme executes.

00:03:30,970 --> 00:03:37,160
Initially, when the programme above has started, the call stack is empty.

00:03:37,160 --> 00:03:42,590
After foo is called, the stack has one entry: location and global scope.

00:03:42,590 --> 00:03:47,690
As I mentioned before, foo knows where to return to when it has finished.

00:03:47,690 --> 00:03:52,030
Next, after bar is called, the stack has two entries.

00:03:52,030 --> 00:03:56,690
It's now stored at the location that bar needs to return to when it has finished executing

00:03:56,690 --> 00:03:59,690
in addition to global scope.

00:03:59,690 --> 00:04:05,800
The trend continues as bas is called, containing the previous return address and the previous

00:04:05,800 --> 00:04:09,690
return addresses from previous calls.

00:04:09,690 --> 00:04:15,210
When console.log is called in bas, the call stack is... the console.

00:04:15,210 --> 00:04:21,000
Next, each of the functions terminates, and, each time, the top entry is removed from the

00:04:21,000 --> 00:04:22,400
stack.

00:04:22,400 --> 00:04:27,849
After foo is done, we're back in global scope and the call stack is empty.

00:04:27,849 --> 00:04:34,820
At the end, we return, and the programme is terminated.

00:04:34,820 --> 00:04:40,430
In looking at this, you can see a handful of the things I previously mentioned.

00:04:40,430 --> 00:04:44,560
The event loop, the task queue, and the stack.

00:04:44,560 --> 00:04:50,810
The current task comes off of the event queue and its location is stored in memory while

00:04:50,810 --> 00:04:54,200
irrelevant variables populate the heap.

00:04:54,200 --> 00:05:00,620
The task queue is populated by task sources, any one of which would be a particular chunk

00:05:00,620 --> 00:05:04,050
of code in an executing programme.

00:05:04,050 --> 00:05:09,560
This snapshot would represent the moment after the all functions in the previous slide had

00:05:09,560 --> 00:05:15,910
executed and before locations had begun to pop off of the stack.

00:05:15,910 --> 00:05:21,600
Most of you have likely encountered callbacks, so I'm going to focus more on how they fit

00:05:21,600 --> 00:05:24,110
into the asynch landscape as a whole.

00:05:24,110 --> 00:05:29,470
Let's start by looking at some functions and discussing them in context.

00:05:29,470 --> 00:05:35,080
Here, you can see I have two programmes side by side.

00:05:35,080 --> 00:05:41,180
On the left, the function names are alphabetical from top down, and, on the right side, I've

00:05:41,180 --> 00:05:45,870
mapped the functions to the order in which they run.

00:05:45,870 --> 00:05:52,300
Most likely, your eyes have to do a significant amount of jumping around in order to discern

00:05:52,300 --> 00:05:57,320
the order in which the functions are executing for the programme on the left.

00:05:57,320 --> 00:06:01,730
Since they're not running in the top-down sequential order you might expect.

00:06:01,730 --> 00:06:07,280
By following the Cardinal number of words on the right side, you probably had an easier

00:06:07,280 --> 00:06:08,450
time.

00:06:08,450 --> 00:06:11,040
Let's talk about why that is.

00:06:11,040 --> 00:06:13,810
Your brain operates sequentially.

00:06:13,810 --> 00:06:19,290
It places it at odds with the inherent functionality of callbacks.

00:06:19,290 --> 00:06:24,419
This is a comparatively simpler example, but when callbacks start to next significantly,

00:06:24,419 --> 00:06:30,020
you enter what is known colloquially as callback hell which becomes more difficult for your

00:06:30,020 --> 00:06:32,750
brain to reason of through.

00:06:32,750 --> 00:06:38,630
What is happening here in terms of the call stack, and, by extension, the event loop?

00:06:38,630 --> 00:06:43,729
Assuming all these functions are asynch, first we will begin, and then immediately yield

00:06:43,729 --> 00:06:46,490
control, and, then second, execute.

00:06:46,490 --> 00:06:52,820
A callback was registered by first so the next available task will be that callback.

00:06:52,820 --> 00:06:56,700
Next, third will execute, followed by fourth.

00:06:56,700 --> 00:07:01,350
Fourth registers a callback, at then returns control, so that fifth executes.

00:07:01,350 --> 00:07:05,340
The callback registered by fourth will come off the Q and execute, and — the queue and

00:07:05,340 --> 00:07:09,410
execute, and finally, six will execute.

00:07:09,410 --> 00:07:15,759
For each of these functions taking a callback, the callback itself is a black box for the

00:07:15,759 --> 00:07:16,889
function.

00:07:16,889 --> 00:07:23,230
The continuation of the programme is dependent on our handing that callback off to another

00:07:23,230 --> 00:07:27,560
part of the code and then essentially just praying that it will do the correct thing

00:07:27,560 --> 00:07:30,370
whether the callback is invoked.

00:07:30,370 --> 00:07:38,100
This paradigm is known as inversion of control, and can create significant trust issues.

00:07:38,100 --> 00:07:44,229
In the previous code snippet I had up, you could see that your eyes had to skip around,

00:07:44,229 --> 00:07:49,199
even though they most likely wanted to read the code in a top-down fashion.

00:07:49,199 --> 00:07:53,979
When you sometimes struggle to understand how and when each part of a piece of code

00:07:53,979 --> 00:08:00,020
is working, it's undoubtedly hard to deal with errors in that code been within the callback

00:08:00,020 --> 00:08:06,419
landscape, there are two ways in which errors are reported: via callbacks and via exceptions.

00:08:06,419 --> 00:08:09,660
You need to combine both properly.

00:08:09,660 --> 00:08:14,410
This is because the most obvious, but occasionally overlooked aspect of dealing with errors in

00:08:14,410 --> 00:08:18,440
callbacks, is to make sure that they've actually all been handled.

00:08:18,440 --> 00:08:23,850
However, there's a caveat to this advice, and it lies specifically in how errors are

00:08:23,850 --> 00:08:29,650
caught: can you see how, in the snippet above, I returned and didn't throw an error.

00:08:29,650 --> 00:08:35,630
That is intentional.

00:08:35,630 --> 00:08:40,899
In an asynchronous environment, the exception could be thrown, and, when the lock is out

00:08:40,899 --> 00:08:45,430
of scope, the error would be rendered meaningless.

00:08:45,430 --> 00:08:52,820
The next big innovation in asynchronous programming promises hit JavaScript with ES6.

00:08:52,820 --> 00:08:57,820
Before this, there was no direct notion of asynch built directly into the JavaScript

00:08:57,820 --> 00:08:59,310
engine.

00:08:59,310 --> 00:09:04,890
All it ever did was execute a single chunk of your programme at any given moment when

00:09:04,890 --> 00:09:06,040
asked to.

00:09:06,040 --> 00:09:12,330
You, the developer, asked it to by means of callbacks or timeouts, in order to shuffle

00:09:12,330 --> 00:09:15,170
its place in the event loop.

00:09:15,170 --> 00:09:20,510
With promises came a change to the JS engine which took a form of the queue that I mentioned

00:09:20,510 --> 00:09:24,970
briefly at the beginning — the microtask queue.

00:09:24,970 --> 00:09:30,510
Before I delve into how exactly this changes the form of the stack queue event loop diagram

00:09:30,510 --> 00:09:36,230
I showed you a few slides ago, let's look at an example of a programme utilising promises

00:09:36,230 --> 00:09:41,160
and then discuss what is happening and why.

00:09:41,160 --> 00:09:44,060
Promises act as placeholders.

00:09:44,060 --> 00:09:49,550
They allow us to reason about future values without necessarily knowing their outcomes,

00:09:49,550 --> 00:09:52,620
making them functionally extemporaneous.

00:09:52,620 --> 00:09:56,500
When the future value is settled, it might succeed or fail.

00:09:56,500 --> 00:10:02,680
Then, at that point, the promise is no longer a placeholder and becomes an immutable value.

00:10:02,680 --> 00:10:11,730
A few slides ago, I referenced the paradigm, the version of control.

00:10:11,730 --> 00:10:23,180
Promises confer to us a capability to know when a given task finishes.

00:10:23,180 --> 00:10:28,580
Promises may seem like an entirely different paradigm, but they don't get rid of callbacks

00:10:28,580 --> 00:10:29,830
at all.

00:10:29,830 --> 00:10:35,230
They just change with the callback has passed to, and remove the black box effect we saw

00:10:35,230 --> 00:10:36,820
previously.

00:10:36,820 --> 00:10:42,330
We get back from a function when it is completed, and then perform new passes from there, as

00:10:42,330 --> 00:10:44,050
I said.

00:10:44,050 --> 00:10:53,760
Promises are not just the mechanism for single-step operations that follow with this then that

00:10:53,760 --> 00:11:01,630
flow.

00:11:01,630 --> 00:11:17,360
[Sound distorted].

00:11:17,360 --> 00:11:40,230
From the — calls for

00:11:40,230 --> 00:11:47,529
the second then would create then another promise.

00:11:47,529 --> 00:11:51,840
So, how does this look under the hood?

00:11:51,840 --> 00:11:58,260
Promises utilise the microtask queue by allows us to say, "Here is this thing that I need

00:11:58,260 --> 00:12:06,060
to do later but I need to ensure it happens immediately later from the — the microtask

00:12:06,060 --> 00:12:11,870
queue can best be thought of as attached to each tech in the event loop.

00:12:11,870 --> 00:12:17,050
Some asynch actions will be added to the end of the current microtask queue instead of

00:12:17,050 --> 00:12:19,390
creating a whole new tick as a whole.

00:12:19,390 --> 00:12:27,880
When a promise is resolved or rejected, the associated handlers will be called asynchronously

00:12:27,880 --> 00:12:33,329
as microtasks, and then added to the queue for the current tick.

00:12:33,329 --> 00:12:38,430
This diagram looks nearly identical to the diagram I showed you a few slides back.

00:12:38,430 --> 00:12:41,750
One key difference from the microtask queue.

00:12:41,750 --> 00:12:48,920
Once a promise settles or already settling, it queues a microtask.

00:12:48,920 --> 00:12:55,020
This ensures promise callbacks are asynch even if the promise has already settled, so

00:12:55,020 --> 00:13:01,860
calling it then would resolve a reject against the settled promise immediately queues a microtask.

00:13:01,860 --> 00:13:07,399
Any additional microtasks queued during a given microtask are added to the end of the

00:13:07,399 --> 00:13:09,100
queue and also processed.

00:13:09,100 --> 00:13:15,660
So, in looking at the diagram, you see that the current task can come off the task queue

00:13:15,660 --> 00:13:18,000
or the microtask queue.

00:13:18,000 --> 00:13:21,720
All promised callbacks are queued as microtasks.

00:13:21,720 --> 00:13:27,450
A microtask can also cause one or more microtasks to be added to the end of the same queue.

00:13:27,450 --> 00:13:32,600
So it's theoretically possible that a microtask loop could spin indefinitely thus starving

00:13:32,600 --> 00:13:37,550
the programme of its ability to move on to the next event loop tick.

00:13:37,550 --> 00:13:44,290
This would conceptually be almost the same as expressing an infinite loop in your code.

00:13:44,290 --> 00:13:46,769
What happens if something goes wrong in a promise.

00:13:46,769 --> 00:13:48,150
How do we deal with those errors?

00:13:48,150 --> 00:13:53,889
By default, it turns out, promises are swallowed if unhandled.

00:13:53,889 --> 00:14:01,510
More specifically, any exception which is thrown inside a dot.then handler, or within

00:14:01,510 --> 00:14:08,209
a function path, a new promise will be soundly disposed of unless manually handled.

00:14:08,209 --> 00:14:13,350
The standard way to handle errors from promises is to add a catch handler at the end of your

00:14:13,350 --> 00:14:15,440
promise chain.

00:14:15,440 --> 00:14:19,580
You can also chain these handlers so that you can throw errors into progressively more

00:14:19,580 --> 00:14:21,430
outer level scopes.

00:14:21,430 --> 00:14:27,130
Catching and rethrowing errors in this way will tell you what led to the error more effectively

00:14:27,130 --> 00:14:31,100
so that you can later debug the issue more efficiently.

00:14:31,100 --> 00:14:37,990
If exceptions are thrown inside the callbacks of dot then and dot catch, it's not a method

00:14:37,990 --> 00:14:41,560
because these two can revert them to rejections.

00:14:41,560 --> 00:14:46,019
Let's look at an example and talk about what would work and what wouldn't in more concrete

00:14:46,019 --> 00:14:47,800
terms.

00:14:47,800 --> 00:14:50,200
This is a simple promise example.

00:14:50,200 --> 00:14:56,209
From looking, you can see that from is going to reject with an error, no matter what.

00:14:56,209 --> 00:15:00,180
So, what happens in the first example versus the second?

00:15:00,180 --> 00:15:02,060
The first has a catch.

00:15:02,060 --> 00:15:05,850
So it's going to print the error followed by the error message which in this case is

00:15:05,850 --> 00:15:07,360
rejected.

00:15:07,360 --> 00:15:11,800
You can also see the associated call stack by printing error.stack.

00:15:11,800 --> 00:15:13,850
The second one doesn't have a catch.

00:15:13,850 --> 00:15:19,070
So even though we threw an error, it will simply fail silently.

00:15:19,070 --> 00:15:24,790
This next type of asynch approach — generators — sits a little on the edge of the overall

00:15:24,790 --> 00:15:29,140
asynch landscape but is nevertheless important to touch on.

00:15:29,140 --> 00:15:34,240
The first thing to observe as we talk about generators, is how they differ from normal

00:15:34,240 --> 00:15:35,620
functions.

00:15:35,620 --> 00:15:40,110
There are several notable differences but key to generators is their behaviour with

00:15:40,110 --> 00:15:44,170
respect to the run to completion expectation.

00:15:44,170 --> 00:15:48,899
With generators, we have a different kind of function which can be paused in the middle

00:15:48,899 --> 00:15:51,990
either once or several times.

00:15:51,990 --> 00:15:57,360
It is resumed later which allows other code to run during these pause periods between

00:15:57,360 --> 00:15:59,260
runs.

00:15:59,260 --> 00:16:03,980
The main strength of generators is that they provide a single threaded synchronous-looking

00:16:03,980 --> 00:16:11,130
code style but allow us to hide the asynchrony away as an implementation detail.

00:16:11,130 --> 00:16:17,080
This lets us express naturally what a programme step and statement flow is without navigating

00:16:17,080 --> 00:16:22,070
the asynchronous gotchas and syntax at the same time.

00:16:22,070 --> 00:16:27,110
To get an idea of how this looks in practice, let's see a function.

00:16:27,110 --> 00:16:32,699
Here, you will see immediately that there's a little star next to the function in the

00:16:32,699 --> 00:16:33,820
signature.

00:16:33,820 --> 00:16:38,089
This is the syntactical indicator that you're looking at a generator function.

00:16:38,089 --> 00:16:42,899
The key word "yield" will send out a value whenever the function is run.

00:16:42,899 --> 00:16:49,410
So, here, the yield index plus plus expression will send the index value out when pausing

00:16:49,410 --> 00:16:51,750
the generator function at that point.

00:16:51,750 --> 00:16:57,779
If ever the generator is restarted, whatever value it was sent in will be the result of

00:16:57,779 --> 00:16:58,779
that expression.

00:16:58,779 --> 00:17:03,140
It will then get added to one and assigned to the index variable.

00:17:03,140 --> 00:17:06,709
When we start, index is zero.

00:17:06,709 --> 00:17:10,889
So this will be yielded and then 1 will be added to the index as a result of the plus

00:17:10,889 --> 00:17:12,309
plus.

00:17:12,309 --> 00:17:18,110
This will occur each time as the value of index is passed out and then in again, and

00:17:18,110 --> 00:17:21,100
so that it increments by one every time.

00:17:21,100 --> 00:17:26,069
To see this a little more clearly, let's look at a diagrammatical representation.

00:17:26,069 --> 00:17:29,269
On the left, you will see a traditional non-generator function.

00:17:29,269 --> 00:17:34,470
It adheres to the run to completion behaviour we expect from functions with no interruptions

00:17:34,470 --> 00:17:36,760
from beginning to end.

00:17:36,760 --> 00:17:39,190
On the right is the generator function.

00:17:39,190 --> 00:17:43,369
With multiple stops and starts between beginning and end.

00:17:43,369 --> 00:17:48,470
It's important to note that there is no real official end per se in the generator function.

00:17:48,470 --> 00:17:53,460
The end in this case will be the last time that that yield is called.

00:17:53,460 --> 00:17:58,720
When the generator function is initialised, an iterator is returned, and then the generator

00:17:58,720 --> 00:18:02,690
starts with the first call to next on the function.

00:18:02,690 --> 00:18:07,370
This function pauses when yield is called, and then would restart with the next call

00:18:07,370 --> 00:18:10,029
to next, and so on, and so forth.

00:18:10,029 --> 00:18:14,690
To recap, with normal functions, you get parameters at the beginning, and a return value at the

00:18:14,690 --> 00:18:20,029
end, but generator functions, you send messages out with yield, and you send messages back

00:18:20,029 --> 00:18:22,500
in with each restart.

00:18:22,500 --> 00:18:28,730
One of the most powerful parts of ES6 generator design is that the semantics of the code inside

00:18:28,730 --> 00:18:30,979
the generator are synchronous.

00:18:30,979 --> 00:18:34,129
Even if the external iteration control proceeds asynchronously.

00:18:34,129 --> 00:18:38,549
That's a fancy way of saying that you can use a very simple error-handling technique

00:18:38,549 --> 00:18:41,269
you're probably familiar with — the tri catch mechanism.

00:18:41,269 --> 00:18:49,690
If even if the function will pause at the yield expression, the tri catch with catch

00:18:49,690 --> 00:18:50,830
it.

00:18:50,830 --> 00:18:55,739
With normal asynch capabilities like callbacks, that's almost impossible to do.

00:18:55,739 --> 00:19:01,440
The generator itself has a throw function to throw an error into the generator at its

00:19:01,440 --> 00:19:08,090
pause position which of course can also be caught by a try catch inside the generator.

00:19:08,090 --> 00:19:11,870
Asynch await is a new way to write asynchronous code.

00:19:11,870 --> 00:19:14,450
Previous options are callbacks and promises.

00:19:14,450 --> 00:19:21,539
Asynch await was created to simplify the process of working with and writing chained promises.

00:19:21,539 --> 00:19:25,109
And so asynch await functions themselves return promises.

00:19:25,109 --> 00:19:27,179
They cannot be used with plain callbacks.

00:19:27,179 --> 00:19:34,289
Asynch await is thus like promises non-blocking, and makes asynchronous code look and behave

00:19:34,289 --> 00:19:36,399
more like synchronous code.

00:19:36,399 --> 00:19:39,009
This is where all the power lies.

00:19:39,009 --> 00:19:44,989
Since any asynch await function returns a promise implicitly, the resolve value of the

00:19:44,989 --> 00:19:50,440
promise will be whatever you return from the function to ill straight, let's look at.

00:19:50,440 --> 00:19:57,149
Here, we are returning a string that returns several components of a street address.

00:19:57,149 --> 00:20:03,450
The function has the asynch key word before it and the await key word can only be used

00:20:03,450 --> 00:20:06,980
in function s defined with asynch.

00:20:06,980 --> 00:20:12,720
All four variables must be resolved before the function will return the desired string.

00:20:12,720 --> 00:20:17,460
Also important to note here is that if we did not use the await key cord before each

00:20:17,460 --> 00:20:22,090
of the address component functions, this would not necessarily fail.

00:20:22,090 --> 00:20:26,119
It would just mean that the variables would be set to promises and from the values returned

00:20:26,119 --> 00:20:27,119
from them.

00:20:27,119 --> 00:20:34,399
There is it also an oft overlooked gotcha.

00:20:34,399 --> 00:20:37,509
Await calls operate sequentially.

00:20:37,509 --> 00:20:44,720
What this means is that the call to get.city won't kick off until we have a value for get.street

00:20:44,720 --> 00:20:45,720
address.

00:20:45,720 --> 00:20:53,520
In some, this depends on a call from results of a previous call.

00:20:53,520 --> 00:20:59,929
Here, we want to get the address components simultaneously, so we should not be blocking

00:20:59,929 --> 00:21:02,029
each on the previous one.

00:21:02,029 --> 00:21:06,519
Instead, we should rewrite it like this.

00:21:06,519 --> 00:21:12,279
Under the hood, asynch await works almost exactly the same as promises, utilising the

00:21:12,279 --> 00:21:16,710
new microtask queue introduced to handle asynch operations.

00:21:16,710 --> 00:21:23,489
If you're familiar with promises, you know that, if a promise is rejected, you need to

00:21:23,489 --> 00:21:26,440
handle that error inside a catch.

00:21:26,440 --> 00:21:31,539
If a handle be errors for synchronous and asynchronous code, you will likely have to

00:21:31,539 --> 00:21:33,080
duplicate your error-handler.

00:21:33,080 --> 00:21:40,190
In the above snippet, we can see there is duplicate code on lines 6 and 8.

00:21:40,190 --> 00:21:45,099
The catch statement on line 7 will handle any errors that the synchronous function do

00:21:45,099 --> 00:21:50,879
synchronous things may throw, but it won't handle any errors thrown by do something since

00:21:50,879 --> 00:21:54,909
it's asynchronous.

00:21:54,909 --> 00:22:00,509
This example may seem palatable, since all it's doing is printing the error to console,

00:22:00,509 --> 00:22:06,899
but if there is any kind of complex error-handle be logic, we want to avoid duplicating it.

00:22:06,899 --> 00:22:10,769
Asynch await let's us do exactly that.

00:22:10,769 --> 00:22:16,460
But looking at the code snippet on the top right, you will see that we only catch once.

00:22:16,460 --> 00:22:24,210
When we use asynch await, we can catch errors in a single handler.

00:22:24,210 --> 00:22:29,760
Here, we can both minimise the total amount of code that we write and catch errors in

00:22:29,760 --> 00:22:32,669
a more readable and clear way.

00:22:32,669 --> 00:22:43,909
So, wrapping up: our brains plan things out in sequential blocking singly threaded semantic

00:22:43,909 --> 00:22:44,909
ways.

00:22:44,909 --> 00:22:52,479
But callbacks express asynchronous flow in a rather non-linear and non-sequential way.

00:22:52,479 --> 00:22:57,809
Which makes reasoning properly about such code much more difficult.

00:22:57,809 --> 00:23:03,019
Callbacks suffer from lack of sequentiality and lack of trustability, but they're good

00:23:03,019 --> 00:23:09,359
in situations where you may just be performing a simple request that is always asynchronous.

00:23:09,359 --> 00:23:14,450
They're just plain functions, so they also don't require any additional understanding

00:23:14,450 --> 00:23:17,929
beyond knowing how asynchronous operations work.

00:23:17,929 --> 00:23:22,629
They also at the end to be more verbose, so co-ordinating multiple asynchronous requests

00:23:22,629 --> 00:23:28,340
with them concurrently can lead to callback hell if you're not actively modularising your

00:23:28,340 --> 00:23:29,770
functions.

00:23:29,770 --> 00:23:34,519
Dealing with errors also tends to be more confusing, since there could be many error

00:23:34,519 --> 00:23:40,320
objects that all go back to a single error further down the call stack.

00:23:40,320 --> 00:23:43,690
Promises are easier to reason of about.

00:23:43,690 --> 00:23:45,200
Although they still have their downsides.

00:23:45,200 --> 00:23:52,599
There are they are especially useful for co-ordinating multiple asynchronous operations, propagating

00:23:52,599 --> 00:23:59,039
errors from nested asynch operations, and dynamically chaining asynchronous operation

00:23:59,039 --> 00:24:04,639
s, i.e., those where you would do something asynch, examine output, and then do something

00:24:04,639 --> 00:24:08,450
else asynch, based on the intermediate values.

00:24:08,450 --> 00:24:15,559
Errors and error stacks in promises can also be a challenge, because they behave unintuitively

00:24:15,559 --> 00:24:20,200
in the way that they print errors when those errors are thrown.

00:24:20,200 --> 00:24:24,799
They brought new changes to the JavaScript engine and paved the way for later innovations

00:24:24,799 --> 00:24:27,380
like asynch await.

00:24:27,380 --> 00:24:33,759
This latest asynch pattern is basically syntactical sugar on promises, but it allows for more

00:24:33,759 --> 00:24:36,729
intuitive reeled of asynchronous code.

00:24:36,729 --> 00:24:42,259
It improves error handling compared to traditional promises and can be handled with simple try

00:24:42,259 --> 00:24:43,379
catch blocks.

00:24:43,379 --> 00:24:48,989
It is so easy to use asynch await that one of its slight dangers that you forget you're

00:24:48,989 --> 00:24:52,019
writing asynchronous code at all.

00:24:52,019 --> 00:24:58,379
Ultimately, the best tool to use for a job is going to be the one that is most specific

00:24:58,379 --> 00:25:00,190
to the job that you're doing.

00:25:00,190 --> 00:25:06,559
Now, I hope you'll have a firmer grasp on what exactly makes each of these tools a best

00:25:06,559 --> 00:25:08,730
fit for certain jobs.

00:25:08,730 --> 00:25:13,840
And be able to use them with the deeper understanding of what is going on at a granular level.

00:25:13,840 --> 00:25:15,549
Thank you very much.

00:25:15,549 --> 00:25:16,049

YouTube URL: https://www.youtube.com/watch?v=SrNQS8J67zc


