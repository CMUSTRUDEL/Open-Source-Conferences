Title: Look mum, no hands! — Brain controlled JavaScript - Charlie Gerard - JSConf EU 2018
Publication date: 2018-06-13
Playlist: JSConf EU 2018
Description: 
	A typical interaction with a device or interface involves touching it. Either you’re pressing buttons on a controller, swiping on a touchscreen or clicking on your laptop’s trackpad. But what if you could control things without the use of your hands? What if you could use… your thoughts?

I have been tinkering with a brain sensor and developed an open source JavaScript framework for it to allow me (or anyone else) to control interfaces or robots using facial expressions and mental commands.

OMG JSConf EU is coming back in 2019 https://2019.jsconf.eu/
Captions: 
	00:00:11,219 --> 00:00:13,450
Thanks everybody for being here this morning.

00:00:13,450 --> 00:00:17,930
I thought I would start by - it's not working any more.

00:00:17,930 --> 00:00:18,930
That's great.

00:00:18,930 --> 00:00:19,930
Hello.

00:00:19,930 --> 00:00:21,080
I will do without.

00:00:21,080 --> 00:00:22,080
That's fine.

00:00:22,080 --> 00:00:27,070
So, again, I thought I will start, and it's not working, either.

00:00:27,070 --> 00:00:28,070
Wow.

00:00:28,070 --> 00:00:31,070
All right, let me my something.

00:00:31,070 --> 00:00:32,439
And then again.

00:00:32,439 --> 00:00:34,180
And maybe that then.

00:00:34,180 --> 00:00:35,460
Cool.

00:00:35,460 --> 00:00:39,610
I want to share the link to the slides, because, if you want to follow along, if I'm going

00:00:39,610 --> 00:00:46,120
to fast or too small, I tried to use the biggest font size I could fit and the right colour

00:00:46,120 --> 00:00:47,879
contrast, so I might have missed something.

00:00:47,879 --> 00:00:51,589
If you want to follow along, this is the short link.

00:00:51,589 --> 00:00:54,449
I tried to make it pretty simple.

00:00:54,449 --> 00:00:56,890
But so let's move on to the actual topic.

00:00:56,890 --> 00:00:59,540
So I want to start with a pretty simple slide.

00:00:59,540 --> 00:01:04,070
I would assume that, if you're here, you know what these represent, but just in case, on

00:01:04,070 --> 00:01:08,030
the left, you have a laptop, and, on the right, you have a mobile phone.

00:01:08,030 --> 00:01:12,630
And the reason I started with that is because I want to talk about interaction.

00:01:12,630 --> 00:01:17,790
I find that very weird that you have the internet which is like this giant network where you

00:01:17,790 --> 00:01:23,470
can access information anywhere by almost anybody, and we decide to interact with it

00:01:23,470 --> 00:01:28,950
in a small screen that's like our phone, or our laptop, and the way we interact with it

00:01:28,950 --> 00:01:35,190
is that we have to learn these new gestures like swiping and tap it up on your keyboard,

00:01:35,190 --> 00:01:40,080
and it became part of what we do, and we accepted it.

00:01:40,080 --> 00:01:46,170
Personally, I don't really believe in the keyboard like that being around for that much

00:01:46,170 --> 00:01:47,170
longer.

00:01:47,170 --> 00:01:51,230
I think that there's probably other types of interacts that are a lot more natural that

00:01:51,230 --> 00:01:52,740
we should focus on.

00:01:52,740 --> 00:01:58,760
And this is what I like to do on my personal time, so, by day, I'm a software dev, so I

00:01:58,760 --> 00:02:04,400
probably work on the same type of stuff as you like websites or apps, and, in my personal

00:02:04,400 --> 00:02:08,640
time, I like to explore alternative interactions.

00:02:08,640 --> 00:02:13,330
I like to play around with technology and see how I can interact with stuff outside

00:02:13,330 --> 00:02:15,730
the typical keyboard and phone.

00:02:15,730 --> 00:02:18,780
Let's talk about these interactive technologies.

00:02:18,780 --> 00:02:21,940
When you - especially the new stuff, you can start with the wearables.

00:02:21,940 --> 00:02:25,340
Some of you are probably wearing a FitBit.

00:02:25,340 --> 00:02:31,010
Yes, you have to interact with the dashboard later on on your phone or laptop, but the

00:02:31,010 --> 00:02:34,340
whole tracking of your steps is done quite freely.

00:02:34,340 --> 00:02:35,830
You can move around and it will count.

00:02:35,830 --> 00:02:37,910
You don't have to hold your phone and say one step, two steps, three steps.

00:02:37,910 --> 00:02:39,570
It is free.

00:02:39,570 --> 00:02:43,910
It kind of does it, and you don't have to think about it.

00:02:43,910 --> 00:02:45,700
Then you have also voice UI.

00:02:45,700 --> 00:02:51,090
Some of you probably have an Amazon Echo, or Google Home, or other device that I don't

00:02:51,090 --> 00:02:52,090
know about.

00:02:52,090 --> 00:02:54,390
The same thing: it is a lot more free.

00:02:54,390 --> 00:02:59,120
You can move around your house, and you have to say a certain comment and access information

00:02:59,120 --> 00:03:05,640
without being in front of a laptop or having to take your phone out of your pocket.

00:03:05,640 --> 00:03:06,880
I think that's quite powerful.

00:03:06,880 --> 00:03:10,830
Maybe it doesn't work as well right now, but I think it is really important to be working

00:03:10,830 --> 00:03:13,240
on that kind of interaction.

00:03:13,240 --> 00:03:17,690
Motion: some of you might be working in offices where you walk around and the lights turn

00:03:17,690 --> 00:03:18,690
on.

00:03:18,690 --> 00:03:22,710
The same thing, if nobody is in the office after a certain time, the lights turn off,

00:03:22,710 --> 00:03:23,989
and you do vent to think about it.

00:03:23,989 --> 00:03:28,020
It's all around us but it's disappearing.

00:03:28,020 --> 00:03:33,070
This one is quite funny, like facial recognition.

00:03:33,070 --> 00:03:37,420
In China, you can pay at KFC with your face.

00:03:37,420 --> 00:03:41,290
I find that quite interesting, because I can't even imagine the interaction you go to the

00:03:41,290 --> 00:03:48,740
shop, and, "Would you like to play by card, cash or face today?"

00:03:48,740 --> 00:03:53,220
I don't really want to pay with my face, but they're already doing it, so, maybe in a few

00:03:53,220 --> 00:03:55,800
years, we will all have to do it.

00:03:55,800 --> 00:03:58,970
I want to focus on biofeedback today.

00:03:58,970 --> 00:04:05,989
So, biofeedback is just having the data coming like getting data of physiological functions

00:04:05,989 --> 00:04:10,400
using devices that track the activity of different systems in the body.

00:04:10,400 --> 00:04:16,159
And especially, I'm working with the Epoch which is a brain sensor.

00:04:16,159 --> 00:04:21,060
Before talking about how the device works, I thought we should go back to how the brain

00:04:21,060 --> 00:04:22,060
actually works.

00:04:22,060 --> 00:04:27,330
I'm not a neuroscientist, so I can't explain in depth how the brain actually works, and

00:04:27,330 --> 00:04:32,650
I don't think we really know, but I'm going to do a high-level and brief intro so we can

00:04:32,650 --> 00:04:34,350
understand what is going afterwards.

00:04:34,350 --> 00:04:39,880
You start with a subject, could be anybody, and, with an intent of doing something.

00:04:39,880 --> 00:04:42,340
It triggers a certain part of the brain.

00:04:42,340 --> 00:04:46,530
Different parts of the brain are in control of different activities.

00:04:46,530 --> 00:04:49,389
And then the - let's say you want to talk.

00:04:49,389 --> 00:04:51,770
You don't think about walking, you just kind of do.

00:04:51,770 --> 00:04:58,610
You have a trigger in a think actions are in the prefrontal cortex but I don't remember

00:04:58,610 --> 00:04:59,930
exactly.

00:04:59,930 --> 00:05:04,260
But then, this part of the brain is going to send a signal to a body part.

00:05:04,260 --> 00:05:09,990
So that is a hand, because I was looking for an icon of legs, and it's either strong men

00:05:09,990 --> 00:05:14,650
legs for a sexy woman legs, and I was fuck this, I will get a hand, it's the same thing,

00:05:14,650 --> 00:05:15,650
and it's gender-neutral.

00:05:15,650 --> 00:05:16,650
[Applause].

00:05:16,650 --> 00:05:24,470
And, yes, so, and then, so the part of the brain that is responsible for actions of walking

00:05:24,470 --> 00:05:29,780
send a signal to your little hands, and you end up walking like that, that ends up being

00:05:29,780 --> 00:05:31,240
an action.

00:05:31,240 --> 00:05:35,030
All it does is basically just signals from the brain to the rest of the body.

00:05:35,030 --> 00:05:37,970
And now, how does the emotive work?

00:05:37,970 --> 00:05:39,759
It has 14 different sensors.

00:05:39,759 --> 00:05:45,360
On the left, you have where these channels are placed around the head.

00:05:45,360 --> 00:05:54,530
And, in the middle, you have how more high-level, high-definition brain sensor works, and in

00:05:54,530 --> 00:05:59,150
green and orange, you have where the emotive is placed around is to that so trying to cover

00:05:59,150 --> 00:06:04,660
a broad rake of the face and head without having to have too many sensors.

00:06:04,660 --> 00:06:09,040
When I got this brain sensor, of course I wanted to play with it, but the only thing

00:06:09,040 --> 00:06:15,150
available was an SDK in C++ and Java.

00:06:15,150 --> 00:06:20,530
I learned Ruby and JavaScript and I thought that was not going to work for me.

00:06:20,530 --> 00:06:21,820
I didn't want to give up.

00:06:21,820 --> 00:06:25,680
That's a piece of device that's quite, you know, it can be a bit expensive - it's a lot

00:06:25,680 --> 00:06:30,199
cheaper than something you find in hospitals - but it's like a bit money.

00:06:30,199 --> 00:06:31,660
I didn't want to give up.

00:06:31,660 --> 00:06:37,440
So I decided to try and build something in JavaScript to allow other JavaScript devs

00:06:37,440 --> 00:06:41,670
not to go through the struggle I went through but use the device and use JavaScript with

00:06:41,670 --> 00:06:42,670
it.

00:06:42,670 --> 00:06:52,720
So I built epoch.js that allows you to interact with the brain sensor in JavaScript.

00:06:52,720 --> 00:06:58,780
And so the features, when you get this sensor, you can download what is called the composer

00:06:58,780 --> 00:07:03,139
which is an emulator, so you don't have to actually set up the sensor all the tile, you

00:07:03,139 --> 00:07:06,190
don't have to carry it around, it can be fragile.

00:07:06,190 --> 00:07:09,580
You can actually open the - write your programme.

00:07:09,580 --> 00:07:13,110
If you can send programmes from the emulator to your programme, you can do what you want.

00:07:13,110 --> 00:07:16,210
It's sweet and working.

00:07:16,210 --> 00:07:18,370
You can have access to the live data.

00:07:18,370 --> 00:07:24,289
The device has a gyro scope to you can get the head movements.

00:07:24,289 --> 00:07:30,770
You can get the performance metrics, get your level of performance, focus, excitement, stress.

00:07:30,770 --> 00:07:35,699
You can also get facial expressions with the sensors around the front of the face, so,

00:07:35,699 --> 00:07:41,520
for example, smiling, or looking right, looking left, up, down, and, a few others.

00:07:41,520 --> 00:07:45,180
But the most exciting part is that you can get some mental comments.

00:07:45,180 --> 00:07:50,110
So they have to be related to a thought of action, and I would assume — but I'm not

00:07:50,110 --> 00:07:55,289
sure — because it is easier to recognise as a pattern than thinking about a chair or

00:07:55,289 --> 00:07:56,289
something like that.

00:07:56,289 --> 00:08:00,490
When you think about an action, the signals that come from the brain are easier to recognise

00:08:00,490 --> 00:08:03,400
in different people than thinking about the beach.

00:08:03,400 --> 00:08:10,380
In terms of technical Stack, I had to use the C++ SDK in the background — probably

00:08:10,380 --> 00:08:18,639
badly written but it works — and then created a Node.js add-on and I used these three modules

00:08:18,639 --> 00:08:19,639
there.

00:08:19,639 --> 00:08:26,020
Now, I know there's a new way to create — I think it is called NAPI, but at the time,

00:08:26,020 --> 00:08:30,491
when I started, it wasn't there, so I haven't updated it, but for now, it works, so, when

00:08:30,491 --> 00:08:33,120
I get time, I will probably try to, like, move over.

00:08:33,120 --> 00:08:34,190
Okay.

00:08:34,190 --> 00:08:40,610
All right, so, with , demo time.

00:08:40,610 --> 00:08:47,240
I always like to start my demo with a little reminder that it might not work.

00:08:47,240 --> 00:08:48,550
It's supposed to work.

00:08:48,550 --> 00:08:50,959
It was working a few days ago.

00:08:50,959 --> 00:08:52,119
[Applause].

00:08:52,119 --> 00:08:54,449
But ... yeah.

00:08:54,449 --> 00:08:56,779
All right.

00:08:56,779 --> 00:08:59,839
So, I was already nervous.

00:08:59,839 --> 00:09:04,399
So the first thing that I build is a brain keyboard.

00:09:04,399 --> 00:09:08,110
So it's just an interface of, well, a keyboard.

00:09:08,110 --> 00:09:13,739
I wanted to be able to interact with it just by moving my eyes.

00:09:13,739 --> 00:09:21,100
This demo is not not limited to thought but to actions and stuff.

00:09:21,100 --> 00:09:27,989
The little bit annoying thing with the sensor is that you have to put some kind of gel on

00:09:27,989 --> 00:09:32,982
all of them to conduct properly, so I did it before the talk to make sure that I will

00:09:32,982 --> 00:09:36,279
be fine but I will just redo it quickly.

00:09:36,279 --> 00:09:42,660
It's not that much of a pain but just a little bit.

00:09:42,660 --> 00:09:51,319
All right, I should be all right.

00:09:51,319 --> 00:09:55,420
The thing is, you do look stupid when you're wearing it, so just get used to it.

00:09:55,420 --> 00:10:03,370
As it is a demo, you might want to take a picture, which is fine.

00:10:03,370 --> 00:10:06,100
I don't know if I turn it on and off?

00:10:06,100 --> 00:10:08,819
So, you might want to take a picture, which is fine.

00:10:08,819 --> 00:10:11,129
Just make sure shy eyes are open because I really look stupid.

00:10:11,129 --> 00:10:15,749
If my eyes are closed on top of that, don't take a picture.

00:10:15,749 --> 00:10:18,759
Don't take a picture when my owes are closed, please!

00:10:18,759 --> 00:10:21,899
That's already quite hard.

00:10:21,899 --> 00:10:28,259
So I'm here, and then — let me check something first.

00:10:28,259 --> 00:10:31,399
I want to check if it's green everywhere.

00:10:31,399 --> 00:10:34,709
So I have to launch another of the programmes.

00:10:34,709 --> 00:10:37,339
I'm missing one.

00:10:37,339 --> 00:10:45,320
So I did turn it on?

00:10:45,320 --> 00:10:46,690
That is interesting.

00:10:46,690 --> 00:10:48,380
So that is not great.

00:10:48,380 --> 00:10:50,829
But it should be all right.

00:10:50,829 --> 00:10:51,829
Let's try.

00:10:51,829 --> 00:10:57,420
So, I have my server, and I just have — okay.

00:10:57,420 --> 00:11:02,290
So if I look right, and I blink, blink.

00:11:02,290 --> 00:11:03,290
It doesn't get the blink.

00:11:03,290 --> 00:11:05,339
So I look right.

00:11:05,339 --> 00:11:08,769
And oh, I did look left.

00:11:08,769 --> 00:11:09,769
Okay.

00:11:09,769 --> 00:11:10,769
Right.

00:11:10,769 --> 00:11:11,769
Blink.

00:11:11,769 --> 00:11:12,769
Left.

00:11:12,769 --> 00:11:15,519
Oh, damn ... . Okay, let me try a bit more.

00:11:15,519 --> 00:11:18,769
Oh, well, I did blink.

00:11:18,769 --> 00:11:20,720
Yes, okay.

00:11:20,720 --> 00:11:23,639
So, right, okay.

00:11:23,639 --> 00:11:26,569
Blink, blink, blink.

00:11:26,569 --> 00:11:28,689
That's working really well, isn't it!

00:11:28,689 --> 00:11:29,689
[Applause].

00:11:29,689 --> 00:11:30,689
Damn!

00:11:30,689 --> 00:11:34,600
I knew it.

00:11:34,600 --> 00:11:39,259
It's letting me down all the time.

00:11:39,259 --> 00:11:43,389
I know I'm moving — well, now you want to work.

00:11:43,389 --> 00:11:48,980
All right, so, I was supposed to be working fine, but it doesn't, so I'm going to move

00:11:48,980 --> 00:11:50,509
on to the other demo, then.

00:11:50,509 --> 00:11:55,110
Hopefully, this one will work better — probably not.

00:11:55,110 --> 00:12:01,860
So the other demo that I built, the aim at the end is to have mind-controlling in web

00:12:01,860 --> 00:12:07,069
VR, I realise has not web VR but 3D in a browser.

00:12:07,069 --> 00:12:12,009
As I'm pretty sure it is going to let me down, I record something so I have the proof that

00:12:12,009 --> 00:12:13,559
it does work.

00:12:13,559 --> 00:12:20,309
So I for now, just trained the thoughts of thinking about the direction right, left,

00:12:20,309 --> 00:12:24,720
pushing and pulling, so I will try and go back and forth.

00:12:24,720 --> 00:12:26,339
So, let's see.

00:12:26,339 --> 00:12:34,749
The thing is as well, you have to focus quite a lot, and — yes, we are still tracking.

00:12:34,749 --> 00:12:40,329
The state of mind in like now, I know what you mean thinking about other stuff, nervous.

00:12:40,329 --> 00:12:48,149
Server again, and then, I will go to localhost.

00:12:48,149 --> 00:12:55,310
We're back.

00:12:55,310 --> 00:13:06,050
Man, I'm struggling.

00:13:06,050 --> 00:13:07,359
It doesn't want to go right.

00:13:07,359 --> 00:13:08,459
But that's fine.

00:13:08,459 --> 00:13:10,610
Let me try again.

00:13:10,610 --> 00:13:15,149
I will try again.

00:13:15,149 --> 00:13:16,629
[Applause].

00:13:16,629 --> 00:13:18,119
Okay.

00:13:18,119 --> 00:13:21,790
Maybe I need to — ah, missing some in the middle.

00:13:21,790 --> 00:13:23,470
I don't have time to redo it.

00:13:23,470 --> 00:13:24,660
All right.

00:13:24,660 --> 00:13:30,699
I really want to go right.

00:13:30,699 --> 00:13:35,170
Okay.

00:13:35,170 --> 00:13:42,930
Okay, I went right.

00:13:42,930 --> 00:13:47,699
Well, all right.

00:13:47,699 --> 00:13:52,101
So I'm going to take that off because now I have gel all over my hair.

00:13:52,101 --> 00:13:53,949
This is great.

00:13:53,949 --> 00:13:55,989
Forget about having a cool hair cut!

00:13:55,989 --> 00:13:58,670
All right, so what is next?

00:13:58,670 --> 00:13:59,670
Code samples.

00:13:59,670 --> 00:14:03,189
Just to show you very quickly how it works, this is a very, very short code sample.

00:14:03,189 --> 00:14:04,619
There are more lines than that.

00:14:04,619 --> 00:14:06,949
I tried to make it quite big.

00:14:06,949 --> 00:14:11,009
If we start from just taking it as pseudo code because there is a lot of code missing,

00:14:11,009 --> 00:14:15,480
because it's about understanding the process of the Node.js module.

00:14:15,480 --> 00:14:20,939
At the bottom, you want a module that we're going to call the module, and the entry point

00:14:20,939 --> 00:14:25,489
is the init function which is right here.

00:14:25,489 --> 00:14:30,679
We are going to create a function that we want to have access to in JavaScript that

00:14:30,679 --> 00:14:34,589
I called connect to composer.

00:14:34,589 --> 00:14:38,449
When we require the module in JavaScript, we will be able to call that to start the

00:14:38,449 --> 00:14:40,259
whole thing.

00:14:40,259 --> 00:14:45,329
What this method is going to do is that it is actually going to be connected to our connect

00:14:45,329 --> 00:14:46,869
function that is here.

00:14:46,869 --> 00:14:53,290
What this one does, and this is where you use the C++ SDK, you start to use an emo state

00:14:53,290 --> 00:15:01,009
handle, data from the brain sensor, and you use that handle to check what expressions

00:15:01,009 --> 00:15:03,149
or thought you get.

00:15:03,149 --> 00:15:07,230
If it wants to know you're blinking, it comes back as an integer, 01, and then you keep

00:15:07,230 --> 00:15:17,220
checking, and an object called event, and I add a property "blink" on the event object

00:15:17,220 --> 00:15:21,379
and the value of it will be the integer coming back checking from whether I'm blinking or

00:15:21,379 --> 00:15:22,379
not.

00:15:22,379 --> 00:15:24,249
So, very poorly written.

00:15:24,249 --> 00:15:29,440
I don't know if it is poorly written or not, because I don't do C++, so that is fine for

00:15:29,440 --> 00:15:30,440
me.

00:15:30,440 --> 00:15:38,899
This is like the C++ file, and then you have the bind ing jit file.

00:15:38,899 --> 00:15:45,040
But this is what it does, that you take your C++ as the source file and say the target

00:15:45,040 --> 00:15:47,899
name is module.

00:15:47,899 --> 00:15:49,529
I just wanted to call it module.

00:15:49,529 --> 00:15:57,269
You compile, and, in JavaScript, you can require that module, and then we have access to connect

00:15:57,269 --> 00:16:02,709
to composer, and then we get our object with the data coming back, and I have connect to

00:16:02,709 --> 00:16:08,389
live data function where you record your brain patterns.

00:16:08,389 --> 00:16:12,269
Painfully, when you run the pattern, you have the access to this object with the properties

00:16:12,269 --> 00:16:15,759
blinking, looking left or right, whatever you want.

00:16:15,759 --> 00:16:21,399
So, very convincing, this is how it — so, very quickly, it's not that bad.

00:16:21,399 --> 00:16:26,259
It took me a while to figure it out, because not knowing C++, it was hard to know where

00:16:26,259 --> 00:16:27,259
I was going.

00:16:27,259 --> 00:16:28,439
In the end, I got there.

00:16:28,439 --> 00:16:30,389
It definitely needs to be refactored.

00:16:30,389 --> 00:16:33,019
I did refactor it a few times.

00:16:33,019 --> 00:16:37,919
I remember once I realised I had two files of a few hundred lines and they were doing

00:16:37,919 --> 00:16:39,470
exactly the same thing!

00:16:39,470 --> 00:16:42,750
So I could delete everything, I felt so productive, it was awesome.

00:16:42,750 --> 00:16:47,899
So the limits: of course, you need training for each user, not for the facial expressions

00:16:47,899 --> 00:16:52,290
but for the mental comments which in a way is a good thing because it means we would

00:16:52,290 --> 00:16:54,220
all be exactly the same.

00:16:54,220 --> 00:17:00,470
It means that, when a user tries it for the first time, you do have to train it before

00:17:00,470 --> 00:17:01,999
being able to use it.

00:17:01,999 --> 00:17:03,480
You can't track everything.

00:17:03,480 --> 00:17:08,150
That kind of like makes sense to me but sometimes, you see people complaining about it is not

00:17:08,150 --> 00:17:09,610
good enough, doesn't know what I want.

00:17:09,610 --> 00:17:12,380
It is a brain sensor that you can buy object line.

00:17:12,380 --> 00:17:15,339
It has around 15 actions that you can track.

00:17:15,339 --> 00:17:17,789
What else do you want!

00:17:17,789 --> 00:17:20,549
And latency.

00:17:20,549 --> 00:17:25,740
As it has to focus and check all the time difference between the current brainwaves

00:17:25,740 --> 00:17:32,360
and the patterns that it knows, there is a delay between thinking and focusing and then

00:17:32,360 --> 00:17:33,519
it detects it.

00:17:33,519 --> 00:17:36,600
Depending what you want to build with it, it may not be the right thing.

00:17:36,600 --> 00:17:41,009
If you want to build a control car, you might not want to use that.

00:17:41,009 --> 00:17:44,370
There are limits in terms of user experience.

00:17:44,370 --> 00:17:51,980
I think the tech is actually quite cool, but as users, we like to have a seamless interaction,

00:17:51,980 --> 00:17:57,110
be able to use technology, do whatever we want it to without having to think about it.

00:17:57,110 --> 00:18:00,320
There is a bit of a limit in terms of how we are building technology right now.

00:18:00,320 --> 00:18:08,549
A lot of the time, we build innovation and think the innovation is amazing but people

00:18:08,549 --> 00:18:09,580
don't want to use it.

00:18:09,580 --> 00:18:11,289
Like it won't work.

00:18:11,289 --> 00:18:14,840
We have trust issues with technology.

00:18:14,840 --> 00:18:19,539
When a new product comes in, we are super excited, and we use it, but then it fails

00:18:19,539 --> 00:18:22,580
once, and it's over, and we don't use it any more.

00:18:22,580 --> 00:18:23,799
Which is also interesting.

00:18:23,799 --> 00:18:27,070
If you wanted to develop products like that, you also have to think about that.

00:18:27,070 --> 00:18:32,410
As a user, we should probably be a bit more like nice to tech because you have to remember

00:18:32,410 --> 00:18:37,059
that we build this, not this magical thing that you buy and it works.

00:18:37,059 --> 00:18:42,080
Real value: to, when, if you would want people to actually use new interactions and stuff

00:18:42,080 --> 00:18:49,019
like the brain sensor, you have to find a way to make it bring value.

00:18:49,019 --> 00:18:53,360
We kind of like, we have habits and we like to use the habits so you don't have to think,

00:18:53,360 --> 00:18:58,210
so you have to make sure what you're building is good enough for people to want to switch.

00:18:58,210 --> 00:19:04,350
Even if this brain sensor was like super powerful, and it works really well, I'm not sure I would

00:19:04,350 --> 00:19:07,309
walk around with that on.

00:19:07,309 --> 00:19:10,130
In terms of social acceptance, it doesn't really work!

00:19:10,130 --> 00:19:13,559
Those are the three points that I could think about.

00:19:13,559 --> 00:19:18,769
I'm sure there is more because I was researching interactions and technology, and this talk

00:19:18,769 --> 00:19:25,170
is cool, so this person, these students from MIT, built a device where you have a camera

00:19:25,170 --> 00:19:31,960
and projector and have things projected on to your environment rather than your phone.

00:19:31,960 --> 00:19:37,160
You could point to a newspaper, and have videos like if you were in Harry Potter, stuff like

00:19:37,160 --> 00:19:38,160
that.

00:19:38,160 --> 00:19:41,769
Or make a gesture like this and take a picture for you.

00:19:41,769 --> 00:19:45,710
The tech was cooled and worked well in the demo at least.

00:19:45,710 --> 00:19:50,429
Then I scold down and I saw that it was made ten years ago.

00:19:50,429 --> 00:19:56,389
I was surprised that, I'm like, so now, ten years ago, so we've, like, ten years have

00:19:56,389 --> 00:19:58,840
passed, and we have nothing close to that.

00:19:58,840 --> 00:20:00,880
We are still using the exact same thing.

00:20:00,880 --> 00:20:02,539
I find that quite crazy.

00:20:02,539 --> 00:20:07,799
At the end of the talk, the speaker actually said, "We never know, maybe in ten years,

00:20:07,799 --> 00:20:11,899
we will come back and talk about the ultimate brain implant."

00:20:11,899 --> 00:20:15,070
We are now ten years, and we're not there at all.

00:20:15,070 --> 00:20:16,070
So that's quite interesting.

00:20:16,070 --> 00:20:20,429
It's like you have to figure out why exactly are we not there?

00:20:20,429 --> 00:20:24,149
And I think that we are working so hard on making the tech good that we forget to think

00:20:24,149 --> 00:20:25,549
about the user.

00:20:25,549 --> 00:20:28,789
I think we need to think about — we need to think more about people.

00:20:28,789 --> 00:20:32,370
Possibilities: accessibility, of course.

00:20:32,370 --> 00:20:36,690
My demo is small, but I think it could useful to some people.

00:20:36,690 --> 00:20:41,250
You have people working on trying to control a wheelchair with that sensor.

00:20:41,250 --> 00:20:45,659
I think that's a uni project but that's still pretty cool.

00:20:45,659 --> 00:20:51,980
Mental health: the He pock is not the only — Epoch is not the only brain sensor.

00:20:51,980 --> 00:20:56,909
They have other ones making you deal with stress and attention a bit better.

00:20:56,909 --> 00:21:02,330
I think that's a cool space also to have that as a useful thing.

00:21:02,330 --> 00:21:03,890
And art: my favourite.

00:21:03,890 --> 00:21:05,669
So I had to put it in there.

00:21:05,669 --> 00:21:09,799
I like mixing technology and art, because you can explore things that you don't get

00:21:09,799 --> 00:21:15,600
to do at work, and it might seem useless for some people, but I would like to remind everybody

00:21:15,600 --> 00:21:17,590
that useless is not worthless.

00:21:17,590 --> 00:21:23,690
A lot of the things that I do are useless, but I learn so much from doing it, and I learn

00:21:23,690 --> 00:21:29,309
stuff that I can apply on other projects, and like when I started with the brain sensor,

00:21:29,309 --> 00:21:33,070
I didn't want to do brain keyboard, I was thinking would did be cool if I could have

00:21:33,070 --> 00:21:35,080
graphics with my brain?

00:21:35,080 --> 00:21:39,419
Then it ended up as beak something that could be useful and I learned a lot.

00:21:39,419 --> 00:21:43,070
Yes, useless is definitely not worthless.

00:21:43,070 --> 00:21:49,450
I just wanted to quickly show something else that I didn't build but thought the next establish

00:21:49,450 --> 00:21:50,980
would be incredible.

00:21:50,980 --> 00:21:57,009
I don't know if you've heard of this from the MIT Media Lab.

00:21:57,009 --> 00:22:03,200
This device can actually track internal speech and translate into words.

00:22:03,200 --> 00:22:07,230
So, you know when you talk to yourself in your head, so you create the words, like I

00:22:07,230 --> 00:22:14,789
can hear myself talk in my head, but they managed to — they managed to sense the electrical

00:22:14,789 --> 00:22:20,279
signals that happen in your jaw when you think about speaking, and to translate into words.

00:22:20,279 --> 00:22:25,530
There's an interview where this student could Google things and answer questions by just

00:22:25,530 --> 00:22:28,879
kind of like thinking about the words, so of course I'm sure they polished that demo

00:22:28,879 --> 00:22:30,009
for the interview!

00:22:30,009 --> 00:22:32,450
But it is like, it's amazing.

00:22:32,450 --> 00:22:37,470
I'm just like, "You know, it's like electrodes, I have them at home.

00:22:37,470 --> 00:22:38,470
Maybe I could try it."

00:22:38,470 --> 00:22:41,320
Maybe we will try it, we will see.

00:22:41,320 --> 00:22:43,389
I wanted to show quickly something funny.

00:22:43,389 --> 00:22:50,090
Like the first prototype was that, and it reminded me of an MIT Epoch but upside-down.

00:22:50,090 --> 00:22:55,970
I thought I could use that, you know?

00:22:55,970 --> 00:23:00,540
I'm getting to the end of my talk, but I have a few links if you want to have a look.

00:23:00,540 --> 00:23:02,100
There's probably more that I can add in there.

00:23:02,100 --> 00:23:05,990
If you're interested in technology, there is a Slack channel that is global where people

00:23:05,990 --> 00:23:08,409
talk about that.

00:23:08,409 --> 00:23:10,399
I wanted to finish on that point.

00:23:10,399 --> 00:23:16,220
You know, when sometimes you look at a piece of art, and you're, "I could have made this,"

00:23:16,220 --> 00:23:20,429
and this is exactly how I want you to feel about that talk, because, when you think about

00:23:20,429 --> 00:23:27,559
the tech, all I did was write some bad C++, and then I wrapped it into a Node.js add-on.

00:23:27,559 --> 00:23:32,419
The tech is the sensor which I bought.

00:23:32,419 --> 00:23:36,440
If I can do that, I can assure you that anybody here can do that.

00:23:36,440 --> 00:23:44,059
You need maybe to take a step back and don't think about making something useful straightaway.

00:23:44,059 --> 00:23:45,470
Have fun.

00:23:45,470 --> 00:23:47,039
Release your inner child.

00:23:47,039 --> 00:23:49,920
Don't be scared of just trying and building something.

00:23:49,920 --> 00:23:53,240
I can assure you that you're going to have a lot of fun doing this.

00:23:53,240 --> 00:23:56,559
So, this is the end of my talk.

00:23:56,559 --> 00:23:59,110
I am on Twitter.

00:23:59,110 --> 00:24:01,980
You can of course always come and talk to me if you want.

00:24:01,980 --> 00:24:03,230
I will be walking around.

00:24:03,230 --> 00:24:06,570
If you have any questions, no worries.

00:24:06,570 --> 00:24:14,240
Unfortunately, I have to leave the conference this afternoon because I have to take flights

00:24:14,240 --> 00:24:16,090
back to Australia.

00:24:16,090 --> 00:24:19,820
I have to speak at another conference so I won't be there to be honest, but I think maybe

00:24:19,820 --> 00:24:23,549
I will leave around three, so I will be walking around if you have any questions.

00:24:23,549 --> 00:24:27,470
Thank you very much for listening, and thanks so much JSConf EU for having me!

00:24:27,470 --> 00:24:27,590

YouTube URL: https://www.youtube.com/watch?v=7KhFO-qCVyg


